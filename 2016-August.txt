From yhbrent at yahoo.com  Mon Aug  1 04:20:47 2016
From: yhbrent at yahoo.com (Brent)
Date: Mon, 1 Aug 2016 02:20:47 +0000 (UTC)
Subject: [R] Has R recently made performance improvements in
 accumulation?
In-Reply-To: <CAJ4QxaN92Rtd5UjQQGV5suPvN_TczCbTLaKqoy-LPRYQhT=reA@mail.gmail.com>
References: <mailman.6.1468922401.11334.r-help@r-project.org>
	<843397525.1408616.1468935651020.JavaMail.yahoo@mail.yahoo.com>
	<CAJuCY5zy7TuTLZAajctNv1qny7QUnREaG-LpEL-6cNHnWkUzNw@mail.gmail.com>
	<CAJ4QxaN92Rtd5UjQQGV5suPvN_TczCbTLaKqoy-LPRYQhT=reA@mail.gmail.com>
Message-ID: <1418410172.7313686.1470018047403.JavaMail.yahoo@mail.yahoo.com>

Thierry: thanks much for your feedback, and apologies for this tardy response.

You pointed me in the right direction.  I did not appreciate how even if the algorithm ultimately has O(n^2) behavior, it can take a big n to overcome large coefficents on lower order terms (e.g. the O(1) and O(n) parts).

A quick fix to my original code is to simply have 100 columns in each row instead of 10, and to look at bigger numbers of rows as well:

    n = 20
    numRows = seq(from = 1*1000, to = 20*1000, length = n)
    nCol = 50
    execTimes = vector(mode = "numeric", length = n)
    for (i in 1:n) {
        nRow = numRows[i]
        
        t1 = Sys.time()
        mkFrameForLoop(nRow, nCol)
        t2 = Sys.time()
        execTimes[i] = difftime(t2, t1, units = "secs")    # CRITICAL: must use difftime (instead of t2 - t1) to ensure that units are always seconds
    }

A simple plot shows obvious nonlinearity now:
    plot(numRows, execTimes)

For you guys reading this text email, a human readable table can be gotten from this code
    df = data.frame(numRows = numRows, execTimes = execTimes)
    df
which yields
       numRows  execTimes
    1     1000   3.564204
    2     2000   8.268473
    3     3000  14.923853
    4     4000  23.506344
    5     5000  31.379795
    6     6000  43.820506
    7     7000  56.720244
    8     8000  72.979174
    9     9000  97.328567
    10   10000 113.404486
    11   11000 141.113071
    12   12000 145.597327
    13   13000 168.967664
    14   14000 196.135218
    15   15000 219.662564
    16   16000 237.763599
    17   17000 275.018730
    18   18000 305.647482
    19   19000 327.215715
    20   20000 359.673572

Finally, a quick simple power law fit using
    lm( log(execTimes) ~ log(numRows), data = df )
yields
    Coefficients:
     (Intercept)  log(numRows)  
         -10.065         1.605  
(i.e. the power over this range of data is 1.605 which is obviously > 1).


boB Rudis: thanks much for the functional elegance suggestion.


From jfox at mcmaster.ca  Mon Aug  1 05:30:40 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 1 Aug 2016 03:30:40 +0000
Subject: [R] Arcsine Tranformation.
In-Reply-To: <CAGzhwenRdy1rrPhO7+XAzwgvxxjPUnYdrfc_DS6xicx350FqHA@mail.gmail.com>
References: <CAGzhwenRdy1rrPhO7+XAzwgvxxjPUnYdrfc_DS6xicx350FqHA@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836547C64@FHSDB2D11-2.csu.mcmaster.ca>

Dear Samsad,

The usual use of the arcsine transformation for proportions is arcsine-squareroot. Thus, in R, for proportions in p,  you can use asin(sqrt(p)).

You could have found the asin() function yourself in several ways, including help.search("arcsin"), which turns up the help page for trigonometric functions. 

As well, the logit transformation, log(p/(1 - p)), is usually preferred to the arcsine-squareroot transformation for proportions because the former is unbounded.

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Samsad Afrin
> Himi
> Sent: July 31, 2016 4:55 AM
> To: r-help at r-project.org
> Subject: [R] Arcsine Tranformation.
> 
> Dear R-Team,
> 
> How can I do arcsine tzransformation in R?  My data is proportional score.
> 
> Could you please help me out?
> 
> Best,
> Samsad
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mli at pivotal.io  Mon Aug  1 08:05:54 2016
From: mli at pivotal.io (Ming Li)
Date: Mon, 1 Aug 2016 14:05:54 +0800
Subject: [R] Fwd: Help: malloc/free deadlock in unsafe signal handler
	'Rf_onsigusr1'
In-Reply-To: <CA+F1ufkY+=gUBwGJFLdb+yCYyoqHHmQ3xJ_4zaiNo-084pmEoQ@mail.gmail.com>
References: <CA+F1ufkY+=gUBwGJFLdb+yCYyoqHHmQ3xJ_4zaiNo-084pmEoQ@mail.gmail.com>
Message-ID: <CA+F1ufmmoqieSC_UiVfnoVAE_FvFZt10hDsKM=KMzR8s_VBaYA@mail.gmail.com>

Hi all,

I am working on a bug,  which running PLR on HAWQ. The process hung and
can't be terminated.

>From my investigation, it seems signal handler 'Rf_onsigusr1' trigger a
malloc/free deadlock.

The calling stack is below.

Thread 1 (Thread 0x7f4c93af48e0 (LWP 431263)):
#0  0x00007f4c9015805e in __lll_lock_wait_private () from /lib64/libc.so.6
#1  0x00007f4c900dd16b in _L_lock_9503 () from /lib64/libc.so.6
#2  0x00007f4c900da6a6 in malloc () from /lib64/libc.so.6
#3  0x00007f4c9008fb39 in _nl_make_l10nflist () from /lib64/libc.so.6
#4  0x00007f4c9008ddf5 in _nl_find_domain () from /lib64/libc.so.6
#5  0x00007f4c9008d6e0 in __dcigettext () from /lib64/libc.so.6
#6  0x00007f4c6fabcfe3 in Rf_onsigusr1 () from /usr/local/lib64/R/lib/libR.so
#7  <signal handler called>
#8  0x00007f4c9014079a in brk () from /lib64/libc.so.6
#9  0x00007f4c90140845 in sbrk () from /lib64/libc.so.6
#10 0x00007f4c900dd769 in __default_morecore () from /lib64/libc.so.6
#11 0x00007f4c900d87a2 in _int_free () from /lib64/libc.so.6
#12 0x0000000000b3ff24 in gp_free2 ()
#13 0x0000000000b356fc in AllocSetDelete ()
#14 0x0000000000b38391 in MemoryContextDeleteImpl ()
#15 0x000000000077c851 in ExecEndAgg ()
#16 0x00000000007592ad in ExecEndNode ()
#17 0x000000000075186c in ExecEndPlan ()
#18 0x000000000079dffa in ExecEndSubqueryScan ()
#19 0x000000000075921d in ExecEndNode ()
#20 0x000000000075186c in ExecEndPlan ()
#21 0x0000000000752565 in ExecutorEnd ()
#22 0x00000000006dd9bd in PortalCleanup ()
#23 0x0000000000b3f077 in AtCommit_Portals ()
#24 0x000000000051abe5 in CommitTransaction ()
#25 0x000000000051f1d5 in CommitTransactionCommand ()
#26 0x000000000099809e in PostgresMain ()
#27 0x00000000008f1031 in BackendStartup ()
#28 0x00000000008f70e0 in PostmasterMain ()
#29 0x00000000007f63da in main ()


I googled and found below info maybe useful to fix it: The best way to
avoid this kind of deadlock is to Call only asynchronous-safe functions
within signal handlers.

https://www.securecoding.cert.org/confluence/display/c/SIG30-C.+Call+only+asynchronous-safe+functions+within+signal+handlers

Thanks a lot.

	[[alternative HTML version deleted]]


From roslinaump at gmail.com  Mon Aug  1 11:27:35 2016
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Mon, 1 Aug 2016 17:27:35 +0800
Subject: [R] Repeat matrices
Message-ID: <CANTvJZJW6=izoM99p1brgGcACVK_VG2vcC25xVr=ChDnBm=ELQ@mail.gmail.com>

Dear r-users,

I have a set of numbers that I would like to repeat for let say 10 times
and each number is repeated by vertically.

I tried this:

a <-  c(5.78, 5.79,5.86)
tran_a <- t(matrix(rep.int(a, 10),3))
dput(tran_a)

structure(c(5.78, 5.78, 5.78, 5.78, 5.78, 5.78, 5.78, 5.78, 5.78,
5.78, 5.79, 5.79, 5.79, 5.79, 5.79, 5.79, 5.79, 5.79, 5.79, 5.79,
5.86, 5.86, 5.86, 5.86, 5.86, 5.86, 5.86, 5.86, 5.86, 5.86), .Dim = c(10L,
3L))

Or is there any smarter way?

Best regards,
-- 
*Dr. Roslinazairimah Binti Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Deputy Dean (Academic & Student Affairs)
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From marco.scutari at gmail.com  Mon Aug  1 11:35:35 2016
From: marco.scutari at gmail.com (Marco Scutari)
Date: Mon, 1 Aug 2016 10:35:35 +0100
Subject: [R] cpquery problem
In-Reply-To: <9a0d19b8a05d0ae5c8676569bbfe96d2.squirrel@ecogeonomix.com>
References: <9a0d19b8a05d0ae5c8676569bbfe96d2.squirrel@ecogeonomix.com>
Message-ID: <CA+RJqXUqPN+X+XZ75h_WUUn8taswHp1GwThkwn-j3e9wcpyqGA@mail.gmail.com>

Hi Ross,

On 31 July 2016 at 09:11, Ross Chapman <ross.chapman at ecogeonomix.com> wrote:
> I have tried running the cpquery in the debug mode, and found that it
> typically returns the following for instances where the conditional
> probability is returned as 0:
>
>    > event matches 0 samples out of 0 (p = 0)
>
> Am I right in understanding that the Monte Carlo sampling has been unable
> to create any cases that match the query?  If so, why would this be if the
> evidence used is very typical of an average case in the data used to train
> the network?

Yes, that is what is happening. As to the reason why, I guess that the
dependencies in the data may not be adequately represented in the
fitted Bayesian network for some reason. What is apparent is that
(EST=='y' & TR>9 & BU>15819 &  RF>2989) has an associated probability
low enough that you do not observe any such sample in rejection
sampling. Now, that being the case, you have two options:

1) use a much larger "n" with a smaller "batch = 10^6" to generate a
lot more particles;
2) switch to likelihood weighting, i.e.

cpquery(fitted,event=(ABW<=11), evidence=list(EST ='y', TR = c(9,
max(data$TR)), BU = c(15819, max(data$BU)), RF = c(2989,
max(data$RF)), n=10^6, method = "lw")

3) look at the parameters in your fitted network and diagnose why this
is happening.

Cheers,
    Marco

-- 
Marco Scutari, Ph.D.
Lecturer in Statistics, Department of Statistics
University of Oxford, United Kingdom


From ivan.calandra at univ-reims.fr  Mon Aug  1 11:49:57 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Mon, 1 Aug 2016 11:49:57 +0200
Subject: [R] Repeat matrices
In-Reply-To: <CANTvJZJW6=izoM99p1brgGcACVK_VG2vcC25xVr=ChDnBm=ELQ@mail.gmail.com>
References: <CANTvJZJW6=izoM99p1brgGcACVK_VG2vcC25xVr=ChDnBm=ELQ@mail.gmail.com>
Message-ID: <97dfff2e-9a27-569b-d831-b1235c7ff123@univ-reims.fr>

Not sure it would be any smarter, but what about:

a <- c(5.78, 5.79,5.86)
n <- 10
matrix(rep(a,each=n), nrow=n)

That way, it would be easy to build a function with 'a' and 'n' as 
arguments.

HTH,
Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 01/08/2016 ? 11:27, roslinazairimah zakaria a ?crit :
> Dear r-users,
>
> I have a set of numbers that I would like to repeat for let say 10 times
> and each number is repeated by vertically.
>
> I tried this:
>
> a <-  c(5.78, 5.79,5.86)
> tran_a <- t(matrix(rep.int(a, 10),3))
> dput(tran_a)
>
> structure(c(5.78, 5.78, 5.78, 5.78, 5.78, 5.78, 5.78, 5.78, 5.78,
> 5.78, 5.79, 5.79, 5.79, 5.79, 5.79, 5.79, 5.79, 5.79, 5.79, 5.79,
> 5.86, 5.86, 5.86, 5.86, 5.86, 5.86, 5.86, 5.86, 5.86, 5.86), .Dim = c(10L,
> 3L))
>
> Or is there any smarter way?
>
> Best regards,


From tb.christos at gmail.com  Mon Aug  1 09:08:37 2016
From: tb.christos at gmail.com (christos tb)
Date: Mon, 1 Aug 2016 10:08:37 +0300
Subject: [R] funnel plot asymmetry
Message-ID: <CAFZWObLfi7BBceyuDUnR_fbmNx5y-U2K_ChxdEmuSVMaSYdmyg@mail.gmail.com>

Hi, I am conducting a meta analysis of continuous data and I cant find the
code to curry out Egger?s test, for testing the funnel plot asymmetry.

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Mon Aug  1 12:21:27 2016
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Mon, 1 Aug 2016 10:21:27 +0000
Subject: [R] funnel plot asymmetry
In-Reply-To: <CAFZWObLfi7BBceyuDUnR_fbmNx5y-U2K_ChxdEmuSVMaSYdmyg@mail.gmail.com>
References: <CAFZWObLfi7BBceyuDUnR_fbmNx5y-U2K_ChxdEmuSVMaSYdmyg@mail.gmail.com>
Message-ID: <a9e7a39517bf4489a9752bb1eb3b6963@UM-MAIL3216.unimaas.nl>

The 'meta' and 'metafor' packages provide this. See also the meta-analysis task view: https://cran.r-project.org/web/views/MetaAnalysis.html (especially: "Investigating small study bias").

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of christos
> tb
> Sent: Monday, August 01, 2016 09:09
> To: r-help at r-project.org
> Subject: [R] funnel plot asymmetry
> 
> Hi, I am conducting a meta analysis of continuous data and I cant find
> the
> code to curry out Egger?s test, for testing the funnel plot asymmetry.

From stefan.kruger at gmail.com  Mon Aug  1 13:52:28 2016
From: stefan.kruger at gmail.com (Stefan Kruger)
Date: Mon, 1 Aug 2016 12:52:28 +0100
Subject: [R] Reduce woes
In-Reply-To: <002B3B27-01C3-4898-A9CD-4E02CA4633E0@dcn.davis.ca.us>
References: <CAG7vnkwrzkFiDcekL71hA4PbneszyCX4k0Akj2+1X-KbvTWaDA@mail.gmail.com>
	<32E02587-D727-46B0-9978-6DBC90209DEC@comcast.net>
	<CAG7vnkx3nD8n7kRk0FtqjTxGz44TNHT9h+kHx+E+ao6g1GUTDw@mail.gmail.com>
	<CAKVAULMxngqm8YNp_4FautnQUOTKFuPB43BBrtXWXxR=sQTixg@mail.gmail.com>
	<CAG7vnkyKwkXY-5J1svBK=xot_iDdrdBq5+ryUzAqahg0TAKGEQ@mail.gmail.com>
	<CAOjnRsZ8nODDbCe4Xns8AqSo8KDukh97AzQOkemAxpK=i0ATDA@mail.gmail.com>
	<CAOjnRsYoLQbhPTePt9J-th4O56GOEDroSB-NZ+qwmnGdveyr2A@mail.gmail.com>
	<CAG7vnky2boUP9t1nrYfPbWjNSUd6DBvX8cNfvO3hPAK0xCDu_Q@mail.gmail.com>
	<CAF8bMcZRAJngoECE31QKQnF6frgJc5n_gXAK7XxQ5kTsHB8C+Q@mail.gmail.com>
	<CAG7vnkwiygX59pAXRoSHs6LizSDomEJsmGjqpeiN6K+Zdu=BKQ@mail.gmail.com>
	<002B3B27-01C3-4898-A9CD-4E02CA4633E0@dcn.davis.ca.us>
Message-ID: <CAG7vnky8ME9KmbqWvzwBds1B2AeA6SAceiReEVr-OKp=7Vmj3A@mail.gmail.com>

That seems like sage advise :)

Thanks

Stefan

On 29 July 2016 at 22:06, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> Having experienced some frustration myself when I first started with R
> many years ago, I can relate to your apparent frustration. However, if you
> would like to succeed in using R I strongly recommend learning R and not
> trying to write Haskell or Erlang or C or Fortran or any other language
> when writing in R. I am sure there are many things R could do better, and
> once you understand how R actually works you might even be in a position to
> contribute some improvements. But thinking in those other languages with an
> R interpreter on front of you is going to just make you more frustrated.
>
> For one thing, everything in R is a vector... even lists. Appending to a
> list is not O(1) as it would be for a linked list. Thus it is preferred to
> find algorithms that pre-allocate memory for results. Map (lapply) is 1:1
> to encourage that.  Reduce is N:1 because it is simpler that way. Use Map
> to    make a grouping vector that you can use to select which elements you
> want to process and then map over that subset of your input data or
> aggregate over the whole thing.
>
> Also, names are attributes of the list vector... one name per element.
> Not all list operations maintain that attribute so you often have to
> explicitly copy names from source to destination.
>
> Oh and "source" is a common base R function... and so it is generally
> advised to not re-use common names in the global environment.
> --
> Sent from my phone. Please excuse my brevity.
>
> On July 29, 2016 8:43:16 AM PDT, Stefan Kruger <stefan.kruger at gmail.com>
> wrote:
> >>> I still don't understand why you want Reduce to to lapply's
> >>> job.   Reduce maps many to one and lapply maps many to
> >>> many.
> >
> >Say you want to map a function over a subset of a vector or list? With
> >the
> >generalised version of Reduce you map many-to-one, but the one can be a
> >'complex' structure. lapply() and friends not only map many-to-many,
> >but
> >X-to-X - the resulting list will be the same length as the source. This
> >frequently gets used in Elixir, Erlang, Haskell etc as a means of
> >processing a pipeline or stream - start with a vector, select a subset
> >based on some predicate, turn this subset into an entirely different
> >object/list/
> >
> >In iterative-fashion pseudo code
> >
> >source = list(c(1,2,3,4), c(8,7,6,5,4,3,7), c(5,4))
> >result = { }
> >foreach (item in source) {
> >    if (length(item) > 2) {
> >        result[generate_some_name()] = length(item)
> >    }
> >}
> >
> >That's and example of what I want to do. It maps many (a subset of the
> >vectors in source) to one (the result named list). It's a map-filter -
> >but
> >even more general than your typical map-filter in that you can change
> >the
> >data structure - e.g. map a function over a vector, use a subset of the
> >results, and turn those into a list or S3 object.
> >
> >
> >Stefan
> >
> >
> >
> >On 29 July 2016 at 15:54, William Dunlap <wdunlap at tibco.com> wrote:
> >
> >> Reduce (like lapply) apparently uses the [[ operator to
> >> extract components from the list given to it. X[[i]] does
> >> not attach names(X)[i] to its output (where would it put it?).
> >> Hence your se
> >>
> >> To help understand what these functions are doing try
> >> putting print statements in your test functions:
> >> > data <- list(one = c(1, 1), three = c(3), two = c(2, 2))
> >> > r <- Reduce(function(acc, item) { cat("acc="); str(acc) ;
> >cat("item=");
> >> str(item); length(item) }, data, init=list())
> >> acc= list()
> >> item= num [1:2] 1 1
> >> acc= int 2
> >> item= num 3
> >> acc= int 1
> >> item= num [1:2] 2 2
> >> > data2 <- list(one = c(oneA=1, onB=1), three = c(threeA=3), two =
> >> c(twoA=2, twoB=2))
> >> > r <- Reduce(function(acc, item) { cat("acc="); str(acc) ;
> >cat("item=");
> >> str(item); length(item) }, data2, init=list())
> >> acc= list()
> >> item= Named num [1:2] 1 1
> >>  - attr(*, "names")= chr [1:2] "oneA" "onB"
> >> acc= int 2
> >> item= Named num 3
> >>  - attr(*, "names")= chr "threeA"
> >> acc= int 1
> >> item= Named num [1:2] 2 2
> >>  - attr(*, "names")= chr [1:2] "twoA" "twoB"
> >>
> >>
> >> I still don't understand why you want Reduce to to lapply's
> >> job.   Reduce maps many to one and lapply maps many to
> >> many.
> >>
> >>
> >>
> >> Bill Dunlap
> >> TIBCO Software
> >> wdunlap tibco.com
> >>
> >> On Fri, Jul 29, 2016 at 1:37 AM, Stefan Kruger
> ><stefan.kruger at gmail.com>
> >> wrote:
> >>
> >>> Jeremiah -
> >>>
> >>> neat - that's one step closer, but one small thing I still don't
> >>> understand:
> >>>
> >>> > data <- list(one = c(1, 1), three = c(3), two = c(2, 2))
> >>> > r = Reduce(function(acc, item) { append(acc,
> >setNames(length(item),
> >>> names(item))) }, data, list())
> >>> > str(r)
> >>> List of 3
> >>>  $ : int 2
> >>>  $ : int 1
> >>>  $ : int 2
> >>>
> >>> I wanted the names to remain, but it seems like the "data" parameter
> >loses
> >>> its names when consumed by the Reduce()? If I print "item" inside
> >the
> >>> reducing function, it's not got the names. I'm probably missing some
> >>> central tenet of R here.
> >>>
> >>> As to your comment of this being lapply() implemented by Reduce() -
> >as I
> >>> understand lapply()  (or map() in other functional languages), it's
> >>> limited
> >>> to returning a list/vector of the same length as the original.
> >Consider
> >>> this contrived example:
> >>>
> >>> > r = Reduce(function(acc, item) { if (length(item) > 1)
> >{append(acc,
> >>> setNames(length(item), names(item)))} }, data, list())
> >>> > str(r)
> >>>  int 2
> >>> > r
> >>> [1] 2
> >>>
> >>> I don't think you could achieve that with lapply()?
> >>>
> >>> Thanks
> >>>
> >>> Stefan
> >>>
> >>>
> >>> On 28 July 2016 at 20:19, jeremiah rounds <roundsjeremiah at gmail.com>
> >>> wrote:
> >>>
> >>> > Basically using Reduce as an lapply in that example, but I think
> >that
> >>> was
> >>> > caused by how people started talking about things in the first
> >place =)
> >>> But
> >>> > the point is the accumulator can be anything as far as I can tell.
> >>> >
> >>> > On Thu, Jul 28, 2016 at 12:14 PM, jeremiah rounds <
> >>> > roundsjeremiah at gmail.com> wrote:
> >>> >
> >>> >> Re:
> >>> >> "What I'm trying to
> >>> >> work out is how to have the accumulator in Reduce not be the same
> >type
> >>> as
> >>> >> the elements of the vector/list being reduced - ideally it could
> >be an
> >>> S3
> >>> >> instance, list, vector, or data frame."
> >>> >>
> >>> >> Pretty sure that is not true.  See code that follows.  I would
> >never
> >>> >> solve this task in this way though so no comment on the use of
> >Reduce
> >>> for
> >>> >> what you described.  (Note the accumulation of "functions" in a
> >list is
> >>> >> just a demo of possibilities).  You could accumulate in an
> >environment
> >>> too
> >>> >> and potentially gain a lot of copy efficiency.
> >>> >>
> >>> >>
> >>> >> lookup = list()
> >>> >> lookup[[as.character(1)]] = function() print("1")
> >>> >> lookup[[as.character(2)]] = function() print("2")
> >>> >> lookup[[as.character(3)]] = function() print("3")
> >>> >>
> >>> >> data = list(c(1,2), c(1,4), c(3,3), c(2,30))
> >>> >>
> >>> >>
> >>> >> r = Reduce(function(acc, item) {
> >>> >> append(acc, list(lookup[[as.character(min(item))]]))
> >>> >> }, data,list())
> >>> >> r
> >>> >> for(f in r) f()
> >>> >>
> >>> >>
> >>> >> On Thu, Jul 28, 2016 at 5:09 AM, Stefan Kruger <
> >>> stefan.kruger at gmail.com>
> >>> >> wrote:
> >>> >>
> >>> >>> Ulrik - many thanks for your reply.
> >>> >>>
> >>> >>> I'm aware of many simple solutions as the one you suggest, both
> >>> iterative
> >>> >>> and functional style - but I'm trying to learn how to bend
> >Reduce()
> >>> for
> >>> >>> the
> >>> >>> purpose of using it in more complex processing tasks. What I'm
> >trying
> >>> to
> >>> >>> work out is how to have the accumulator in Reduce not be the
> >same
> >>> type as
> >>> >>> the elements of the vector/list being reduced - ideally it could
> >be
> >>> an S3
> >>> >>> instance, list, vector, or data frame.
> >>> >>>
> >>> >>> Here's a more realistic example (in Elixir, sorry)
> >>> >>>
> >>> >>> Given two lists:
> >>> >>>
> >>> >>> 1. data: maps an id string to a vector of revision strings
> >>> >>> 2. dict: maps known id/revision pairs as a string to true (or 1)
> >>> >>>
> >>> >>> find the items in data not already in dict, returned as a named
> >list.
> >>> >>>
> >>> >>> ```elixir
> >>> >>> data = %{
> >>> >>>     "id1" => ["rev1.1", "rev1.2"],
> >>> >>>     "id2" => ["rev2.1"],
> >>> >>>     "id3" => ["rev3.1", "rev3.2", "rev3.3"]
> >>> >>> }
> >>> >>>
> >>> >>> dict = %{
> >>> >>>     "id1/rev1.1" => 1,
> >>> >>>     "id1/rev1.2" => 1,
> >>> >>>     "id3/rev3.1" => 1
> >>> >>> }
> >>> >>>
> >>> >>> # Find the items in data not already in dict. Return as a
> >grouped map
> >>> >>>
> >>> >>> Map.keys(data)
> >>> >>>     |> Enum.flat_map(fn id -> Enum.map(data[id], fn rev -> {id,
> >rev}
> >>> end)
> >>> >>> end)
> >>> >>>     |> Enum.filter(fn {id, rev} -> !Dict.has_key?(dict,
> >>> "#{id}/#{rev}")
> >>> >>> end)
> >>> >>>     |> Enum.reduce(%{}, fn ({k, v}, d) -> Map.update(d, k, [v],
> >>> &[v|&1])
> >>> >>> end)
> >>> >>> ```
> >>> >>>
> >>> >>>
> >>> >>>
> >>> >>>
> >>> >>> On 28 July 2016 at 12:03, Ulrik Stervbo
> ><ulrik.stervbo at gmail.com>
> >>> wrote:
> >>> >>>
> >>> >>> > Hi Stefan,
> >>> >>> >
> >>> >>> > in that case,lapply(data, length) should do the trick.
> >>> >>> >
> >>> >>> > Best wishes,
> >>> >>> > Ulrik
> >>> >>> >
> >>> >>> > On Thu, 28 Jul 2016 at 12:57 Stefan Kruger
> ><stefan.kruger at gmail.com
> >>> >
> >>> >>> > wrote:
> >>> >>> >
> >>> >>> >> David - many thanks for your response.
> >>> >>> >>
> >>> >>> >> What I tried to do was to turn
> >>> >>> >>
> >>> >>> >> data <- list(one = c(1, 1), three = c(3), two = c(2, 2))
> >>> >>> >>
> >>> >>> >> into
> >>> >>> >>
> >>> >>> >> result <- list(one = 2, three = 1, two = 2)
> >>> >>> >>
> >>> >>> >> that is creating a new list which has the same names as the
> >first,
> >>> but
> >>> >>> >> where the values are the vector lengths.
> >>> >>> >>
> >>> >>> >> I know there are many other (and better) trivial ways of
> >achieving
> >>> >>> this -
> >>> >>> >> my aim is less the task itself, and more figuring out if this
> >can
> >>> be
> >>> >>> done
> >>> >>> >> using Reduce() in the fashion I showed in the other examples
> >I
> >>> gave.
> >>> >>> It's
> >>> >>> >> a
> >>> >>> >> building block of doing map-filter-reduce type pipelines that
> >I'd
> >>> >>> like to
> >>> >>> >> understand how to do in R.
> >>> >>> >>
> >>> >>> >> Fumbling in the dark, I tried:
> >>> >>> >>
> >>> >>> >> Reduce(function(acc, item) { setNames(c(acc,
> >length(data[item])),
> >>> >>> item },
> >>> >>> >> names(data), accumulate=TRUE)
> >>> >>> >>
> >>> >>> >> but setNames sets all the names, not adding one - and acc is
> >still
> >>> a
> >>> >>> >> vector, not a list.
> >>> >>> >>
> >>> >>> >> It looks like 'lambda.tools.fold()' and possibly
> >'purrr.reduce()'
> >>> aim
> >>> >>> at
> >>> >>> >> doing what I'd like to do - but I've not been able to figure
> >out
> >>> quite
> >>> >>> >> how.
> >>> >>> >>
> >>> >>> >> Thanks
> >>> >>> >>
> >>> >>> >> Stefan
> >>> >>> >>
> >>> >>> >>
> >>> >>> >>
> >>> >>> >> On 27 July 2016 at 20:35, David Winsemius
> ><dwinsemius at comcast.net>
> >>> >>> wrote:
> >>> >>> >>
> >>> >>> >> >
> >>> >>> >> > > On Jul 27, 2016, at 8:20 AM, Stefan Kruger <
> >>> >>> stefan.kruger at gmail.com>
> >>> >>> >> > wrote:
> >>> >>> >> > >
> >>> >>> >> > > Hi -
> >>> >>> >> > >
> >>> >>> >> > > I'm new to R.
> >>> >>> >> > >
> >>> >>> >> > > In other functional languages I'm familiar with you can
> >often
> >>> >>> seed a
> >>> >>> >> call
> >>> >>> >> > > to reduce() with a custom accumulator. Here's an example
> >in
> >>> >>> Elixir:
> >>> >>> >> > >
> >>> >>> >> > > map = %{"one" => [1, 1], "three" => [3], "two" => [2, 2]}
> >>> >>> >> > > map |> Enum.reduce(%{}, fn ({k,v}, acc) ->
> >Map.update(acc, k,
> >>> >>> >> > > Enum.count(v), nil) end)
> >>> >>> >> > > # %{"one" => 2, "three" => 1, "two" => 2}
> >>> >>> >> > >
> >>> >>> >> > > In R-terms that's reducing a list of vectors to become a
> >new
> >>> list
> >>> >>> >> mapping
> >>> >>> >> > > the names to the vector lengths.
> >>> >>> >> > >
> >>> >>> >> > > Even in JavaScript, you can do similar things:
> >>> >>> >> > >
> >>> >>> >> > > list = { one: [1, 1], three: [3], two: [2, 2] };
> >>> >>> >> > > var result = Object.keys(list).reduceRight(function (acc,
> >>> item) {
> >>> >>> >> > >  acc[item] = list[item].length;
> >>> >>> >> > >  return acc;
> >>> >>> >> > > }, {});
> >>> >>> >> > > // result == { two: 2, three: 1, one: 2 }
> >>> >>> >> > >
> >>> >>> >> > > In R, from what I can gather, Reduce() is restricted such
> >that
> >>> any
> >>> >>> >> init
> >>> >>> >> > > value you feed it is required to be of the same type as
> >the
> >>> >>> elements
> >>> >>> >> of
> >>> >>> >> > the
> >>> >>> >> > > vector you're reducing -- so I can't build up. So whilst
> >I can
> >>> >>> do, say
> >>> >>> >> > >
> >>> >>> >> > >> Reduce(function(acc, item) { acc + item }, c(1,2,3,4,5),
> >96)
> >>> >>> >> > > [1] 111
> >>> >>> >> > >
> >>> >>> >> > > I can't use Reduce to build up a list, vector or data
> >frame?
> >>> >>> >> > >
> >>> >>> >> > > What am I missing?
> >>> >>> >> > >
> >>> >>> >> > > Many thanks for any pointers,
> >>> >>> >> >
> >>> >>> >> > This builds a list:
> >>> >>> >> >
> >>> >>> >> > > Reduce(function(acc, item) { c(acc , item) },
> >c(1,2,3,4,5), 96,
> >>> >>> >> > accumulate=TRUE)
> >>> >>> >> > [[1]]
> >>> >>> >> > [1] 96
> >>> >>> >> >
> >>> >>> >> > [[2]]
> >>> >>> >> > [1] 96  1
> >>> >>> >> >
> >>> >>> >> > [[3]]
> >>> >>> >> > [1] 96  1  2
> >>> >>> >> >
> >>> >>> >> > [[4]]
> >>> >>> >> > [1] 96  1  2  3
> >>> >>> >> >
> >>> >>> >> > [[5]]
> >>> >>> >> > [1] 96  1  2  3  4
> >>> >>> >> >
> >>> >>> >> > [[6]]
> >>> >>> >> > [1] 96  1  2  3  4  5
> >>> >>> >> >
> >>> >>> >> > But you are not saying what you want. The other examples
> >were
> >>> doing
> >>> >>> >> > something with names but you provided no names for the R
> >example.
> >>> >>> >> >
> >>> >>> >> > This would return a list of named vectors:
> >>> >>> >> >
> >>> >>> >> > > Reduce(function(acc, item) { setNames( c(acc,item),
> >1:(item+1))
> >>> >>> },
> >>> >>> >> > c(1,2,3,4,5), 96, accumulate=TRUE)
> >>> >>> >> > [[1]]
> >>> >>> >> > [1] 96
> >>> >>> >> >
> >>> >>> >> > [[2]]
> >>> >>> >> >  1  2
> >>> >>> >> > 96  1
> >>> >>> >> >
> >>> >>> >> > [[3]]
> >>> >>> >> >  1  2  3
> >>> >>> >> > 96  1  2
> >>> >>> >> >
> >>> >>> >> > [[4]]
> >>> >>> >> >  1  2  3  4
> >>> >>> >> > 96  1  2  3
> >>> >>> >> >
> >>> >>> >> > [[5]]
> >>> >>> >> >  1  2  3  4  5
> >>> >>> >> > 96  1  2  3  4
> >>> >>> >> >
> >>> >>> >> > [[6]]
> >>> >>> >> >  1  2  3  4  5  6
> >>> >>> >> > 96  1  2  3  4  5
> >>> >>> >> >
> >>> >>> >> >
> >>> >>> >> >
> >>> >>> >> >
> >>> >>> >> > > Stefan
> >>> >>> >> > >
> >>> >>> >> > >
> >>> >>> >> > >
> >>> >>> >> > > --
> >>> >>> >> > > Stefan Kruger <stefan.kruger at gmail.com>
> >>> >>> >> > >
> >>> >>> >> > >       [[alternative HTML version deleted]]
> >>> >>> >> > >
> >>> >>> >> > > ______________________________________________
> >>> >>> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> >more,
> >>> see
> >>> >>> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >>> >> > > PLEASE do read the posting guide
> >>> >>> >> > http://www.R-project.org/posting-guide.html
> >>> >>> >> > > and provide commented, minimal, self-contained,
> >reproducible
> >>> code.
> >>> >>> >> >
> >>> >>> >> > David Winsemius
> >>> >>> >> > Alameda, CA, USA
> >>> >>> >> >
> >>> >>> >> >
> >>> >>> >>
> >>> >>> >>
> >>> >>> >> --
> >>> >>> >> Stefan Kruger <stefan.kruger at gmail.com>
> >>> >>> >>
> >>> >>> >>         [[alternative HTML version deleted]]
> >>> >>> >>
> >>> >>> >> ______________________________________________
> >>> >>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >see
> >>> >>> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >>> >> PLEASE do read the posting guide
> >>> >>> >> http://www.R-project.org/posting-guide.html
> >>> >>> >> and provide commented, minimal, self-contained, reproducible
> >code.
> >>> >>> >>
> >>> >>> >
> >>> >>>
> >>> >>>
> >>> >>> --
> >>> >>> Stefan Kruger <stefan.kruger at gmail.com>
> >>> >>>
> >>> >>>         [[alternative HTML version deleted]]
> >>> >>>
> >>> >>> ______________________________________________
> >>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >see
> >>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >>> PLEASE do read the posting guide
> >>> >>> http://www.R-project.org/posting-guide.html
> >>> >>> and provide commented, minimal, self-contained, reproducible
> >code.
> >>> >>>
> >>> >>
> >>> >>
> >>> >
> >>>
> >>>
> >>> --
> >>> Stefan Kruger <stefan.kruger at gmail.com>
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
>
>


-- 
Stefan Kruger <stefan.kruger at gmail.com>

	[[alternative HTML version deleted]]


From marco.prado.bs at gmail.com  Mon Aug  1 15:28:02 2016
From: marco.prado.bs at gmail.com (Marco Silva)
Date: Mon, 01 Aug 2016 10:28:02 -0300
Subject: [R] type of objects in last session
Message-ID: <1470057852-sup-9607@ubatuba>

Sometimes I comeback with a session months later. I would like to know
the type of variables I have in. So I tried:


> sapply(ls(), typeof)
        ago_ts       ago_ts.1       ago_ts.2        annualy           conn 
   "character"    "character"    "character"    "character"    "character" 
         d_jul             df          diffs              f            fit 
   "character"    "character"    "character"    "character"    "character" 
             i            ibm        ibm_url     increments increments_jul 
   "character"    "character"    "character"    "character"    "character" 
        jul_ts           lago       lnkd_url          model      model_jul 
   "character"    "character"    "character"    "character"    "character" 
            op           rain              t             t2            ts_ 
   "character"    "character"    "character"    "character"    "character" 

And I noticed everything is type "character".
Obviously wrong answer. So How can I have the right answer ?

Thanks

-- 
Marco Arthur @ (M)arco Creatives


From ivan.calandra at univ-reims.fr  Mon Aug  1 15:45:53 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Mon, 1 Aug 2016 15:45:53 +0200
Subject: [R] type of objects in last session
In-Reply-To: <1470057852-sup-9607@ubatuba>
References: <1470057852-sup-9607@ubatuba>
Message-ID: <1b30619a-7b95-8921-c8e0-512a3c85b9d3@univ-reims.fr>

Maybe "mode" or "class" instead of "typeof"?

Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 01/08/2016 ? 15:28, Marco Silva a ?crit :
> Sometimes I comeback with a session months later. I would like to know
> the type of variables I have in. So I tried:
>
>
>> sapply(ls(), typeof)
>          ago_ts       ago_ts.1       ago_ts.2        annualy           conn
>     "character"    "character"    "character"    "character"    "character"
>           d_jul             df          diffs              f            fit
>     "character"    "character"    "character"    "character"    "character"
>               i            ibm        ibm_url     increments increments_jul
>     "character"    "character"    "character"    "character"    "character"
>          jul_ts           lago       lnkd_url          model      model_jul
>     "character"    "character"    "character"    "character"    "character"
>              op           rain              t             t2            ts_
>     "character"    "character"    "character"    "character"    "character"
>
> And I noticed everything is type "character".
> Obviously wrong answer. So How can I have the right answer ?
>
> Thanks
>


From murdoch.duncan at gmail.com  Mon Aug  1 15:47:33 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 1 Aug 2016 09:47:33 -0400
Subject: [R] type of objects in last session
In-Reply-To: <1470057852-sup-9607@ubatuba>
References: <1470057852-sup-9607@ubatuba>
Message-ID: <1d354b49-499b-df60-ca48-fac1d30f531e@gmail.com>

On 01/08/2016 9:28 AM, Marco Silva wrote:
> Sometimes I comeback with a session months later. I would like to know
> the type of variables I have in. So I tried:
>
>
>> sapply(ls(), typeof)
>         ago_ts       ago_ts.1       ago_ts.2        annualy           conn
>    "character"    "character"    "character"    "character"    "character"
>          d_jul             df          diffs              f            fit
>    "character"    "character"    "character"    "character"    "character"
>              i            ibm        ibm_url     increments increments_jul
>    "character"    "character"    "character"    "character"    "character"
>         jul_ts           lago       lnkd_url          model      model_jul
>    "character"    "character"    "character"    "character"    "character"
>             op           rain              t             t2            ts_
>    "character"    "character"    "character"    "character"    "character"
>
> And I noticed everything is type "character".
> Obviously wrong answer. So How can I have the right answer ?
>
> Thanks
>

The ls.str() function probably does what you want.

If you wanted to do it with sapply (e.g. because you want just typeof(), 
not everything else), you need to take account of the fact that ls() 
returns a character vector, so you have to get the objects with those 
names before calling typeof.  For example,

sapply(ls(), function(name) typeof(get(name)))

Duncan Murdoch


From ivan.calandra at univ-reims.fr  Mon Aug  1 15:55:38 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Mon, 1 Aug 2016 15:55:38 +0200
Subject: [R] type of objects in last session
In-Reply-To: <12479_1470059292_579F531C_12479_2525_1_1b30619a-7b95-8921-c8e0-512a3c85b9d3@univ-reims.fr>
References: <1470057852-sup-9607@ubatuba>
	<12479_1470059292_579F531C_12479_2525_1_1b30619a-7b95-8921-c8e0-512a3c85b9d3@univ-reims.fr>
Message-ID: <063433ef-753a-9420-1490-52ed71ac89a0@univ-reims.fr>

That's what happens when I answer too fast... Sorry for that. Next time 
I'll read more carefully!

Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 01/08/2016 ? 15:45, Ivan Calandra a ?crit :
> Maybe "mode" or "class" instead of "typeof"?
>
> Ivan
>
> -- 
> Ivan Calandra, PhD
> Scientific Mediator
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> -- 
> https://www.researchgate.net/profile/Ivan_Calandra
> https://publons.com/author/705639/
>
> Le 01/08/2016 ? 15:28, Marco Silva a ?crit :
>> Sometimes I comeback with a session months later. I would like to know
>> the type of variables I have in. So I tried:
>>
>>
>>> sapply(ls(), typeof)
>>          ago_ts       ago_ts.1       ago_ts.2 annualy           conn
>>     "character"    "character"    "character"    "character" "character"
>>           d_jul             df          diffs f            fit
>>     "character"    "character"    "character"    "character" "character"
>>               i            ibm        ibm_url     increments 
>> increments_jul
>>     "character"    "character"    "character"    "character" "character"
>>          jul_ts           lago       lnkd_url model      model_jul
>>     "character"    "character"    "character"    "character" "character"
>>              op           rain              t t2            ts_
>>     "character"    "character"    "character"    "character" "character"
>>
>> And I noticed everything is type "character".
>> Obviously wrong answer. So How can I have the right answer ?
>>
>> Thanks
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From milujisb at gmail.com  Mon Aug  1 16:06:18 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Mon, 1 Aug 2016 16:06:18 +0200
Subject: [R] Climate data in R
Message-ID: <CAMLwc7Od_CEOEkVnQtKaR0LRuxoOtXpLXgC5h6T6hZiUvfBsuA@mail.gmail.com>

Dear all,

I have a set of coordinates. Is it possible to extract climate data
(temperature and precipitation) by coordinates using the R packages such as
rnoaa?

For example;

out <- ncdc(datasetid='ANNUAL', stationid='GHCND:USW00014895',
datatypeid='TEMP')

But instead of stationid can I pass a list of coordinates through it?
Thanks a lot!

Sincerely,

Milu

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Aug  1 15:55:21 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 1 Aug 2016 13:55:21 +0000
Subject: [R] type of objects in last session
In-Reply-To: <1d354b49-499b-df60-ca48-fac1d30f531e@gmail.com>
References: <1470057852-sup-9607@ubatuba>
	<1d354b49-499b-df60-ca48-fac1d30f531e@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50375CD@SRVEXCHMBX.precheza.cz>

Hi

Long time ago I (with some help from R help list) made following function, which is maybe less comprehensive as ls.str but I find it quite handy.

ls.objects <- function (pos = 1, pattern, order.by)
{
    napply <- function(names, fn) sapply(names, function(x) fn(get(x,
        pos = pos)))
    names <- ls(pos = pos, pattern = pattern)
    obj.class <- napply(names, function(x) as.character(class(x))[1])
    obj.mode <- napply(names, mode)
    obj.type <- ifelse(is.na(obj.class), obj.mode, obj.class)
    obj.size <- napply(names, object.size)
    obj.dim <- t(napply(names, function(x) as.numeric(dim(x))[1:2]))
    vec <- is.na(obj.dim)[, 1] & (obj.type != "function")
    obj.dim[vec, 1] <- napply(names, length)[vec]
    out <- data.frame(obj.type, obj.size, obj.dim)
    names(out) <- c("Type", "Size", "Rows", "Columns")
    if (!missing(order.by))
        out <- out[order(out[[order.by]]), ]
    out
}

Just issue
ls.objects()

in your working directory.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan
> Murdoch
> Sent: Monday, August 1, 2016 3:48 PM
> To: Marco Silva <marco.prado.bs at gmail.com>; r-help <r-help at r-
> project.org>
> Subject: Re: [R] type of objects in last session
>
> On 01/08/2016 9:28 AM, Marco Silva wrote:
> > Sometimes I comeback with a session months later. I would like to know
> > the type of variables I have in. So I tried:
> >
> >
> >> sapply(ls(), typeof)
> >         ago_ts       ago_ts.1       ago_ts.2        annualy           conn
> >    "character"    "character"    "character"    "character"    "character"
> >          d_jul             df          diffs              f            fit
> >    "character"    "character"    "character"    "character"    "character"
> >              i            ibm        ibm_url     increments increments_jul
> >    "character"    "character"    "character"    "character"    "character"
> >         jul_ts           lago       lnkd_url          model      model_jul
> >    "character"    "character"    "character"    "character"    "character"
> >             op           rain              t             t2            ts_
> >    "character"    "character"    "character"    "character"    "character"
> >
> > And I noticed everything is type "character".
> > Obviously wrong answer. So How can I have the right answer ?
> >
> > Thanks
> >
>
> The ls.str() function probably does what you want.
>
> If you wanted to do it with sapply (e.g. because you want just typeof(), not
> everything else), you need to take account of the fact that ls() returns a
> character vector, so you have to get the objects with those names before
> calling typeof.  For example,
>
> sapply(ls(), function(name) typeof(get(name)))
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From cryan at binghamton.edu  Mon Aug  1 17:04:34 2016
From: cryan at binghamton.edu (Christopher W Ryan)
Date: Mon, 1 Aug 2016 11:04:34 -0400
Subject: [R] what happened to inside-r? [possibly OT]
In-Reply-To: <8D2B3139-903F-4140-B68C-B72533ECE9DF@comcast.net>
References: <579BA0CF.9050406@binghamton.edu>
	<8D2B3139-903F-4140-B68C-B72533ECE9DF@comcast.net>
Message-ID: <CAM+rpYm4N05BtDvv=tJyen4yOp+vHoC5LFEH-_511kLLLvRjEA@mail.gmail.com>

No, not off the grid. I just don't follow developments with Revolution
or with Microsoft.

I was merely lamenting that inside-r URLs, that used to get me quickly
to the R help pages (even if I was at a computer that did not have R),
now re-direct to the corporate MRAN homepage, with the help pages
nowhere to be found. Alas!

But thanks anyway.

--Chris

On Fri, Jul 29, 2016 at 3:54 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> Been off the grid for the last year? MS bought Revolution R.
>
>
> Sent from my iPhone
>
>> On Jul 29, 2016, at 11:30 AM, Christopher W. Ryan <cryan at binghamton.edu> wrote:
>>
>> This might be a bit off-topic, but up until recently (a day or so ago?) I loved using inside-r.org as a quick and easy way to access help pages on R commands. Took me to what I needed without any fuss. Now that URL redirects to the "Microsoft R Application Network"?  Looks to be something related to Revolution R.  What happened?
>>
>> Thanks.
>>
>> --Chris Ryan
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From justinthong93 at gmail.com  Mon Aug  1 18:01:37 2016
From: justinthong93 at gmail.com (Justin Thong)
Date: Mon, 1 Aug 2016 17:01:37 +0100
Subject: [R] Ways to understand C code (like debug function)
Message-ID: <CAEtAGeoK_bVEkSO-D9oYwm8oROaHhcHOKrxaCXmzQj5JEyZx6A@mail.gmail.com>

Hi

I need some advice. Note: I do not know anything from C apart from my 2
days of research.

I am currently trying to make meaning of the modelmatrix function (written
in C) and called from R function model.matrix() via .External2.

In trying to view the source code (in R) for model.matrix(), I have been
reasonably succesful thanks to the debug command. This command was good
because I was able to check line-by-line what the code was doing and obtain
an output within my R console. Furthermore, checking the values of each of
my variables while sequentially moving through the lines was also very
useful. However, just by looking at the R source code, it is insufficient
in understanding most of the computation. I have to look within the C code.
In particular, within model.matrix(), a .External2 call is executed to a C
function named modelmatrix. I downloaded the source from the website and
can view the function modelmatrix(in model.c) in a text editor. I am now
finding a way to play with the code so I understand whats going on and I
don't know what's the best way to do this.

I* was wondering whether there is an equivalent way as the debug function
to check C code line by line. ie each line of code are typed in, and an
output is obtained*. I know a package "inline" allows you to build C
functions and use them in R. But I can't find anything which does what I
want. * If this is not possible, is there an alternative good, easy way to
run through and understand the commands in C that anyone knows about.*

-- 
Yours sincerely,
Justin

*I check my email at 9AM and 4PM everyday*
*If you have an EMERGENCY, contact me at +447938674419(UK) or
+60125056192(Malaysia)*

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon Aug  1 18:11:56 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 1 Aug 2016 18:11:56 +0200
Subject: [R] what happened to inside-r? [possibly OT]
In-Reply-To: <CAM+rpYm4N05BtDvv=tJyen4yOp+vHoC5LFEH-_511kLLLvRjEA@mail.gmail.com>
References: <579BA0CF.9050406@binghamton.edu>
	<8D2B3139-903F-4140-B68C-B72533ECE9DF@comcast.net>
	<CAM+rpYm4N05BtDvv=tJyen4yOp+vHoC5LFEH-_511kLLLvRjEA@mail.gmail.com>
Message-ID: <5724A4F5-9FF9-45CB-83B8-B9AA6E4146CC@gmail.com>

"When giants move, they don't move lightly"

Presumably, Revolution's portfolio of web-domains got assimilated and redirected to the corporate homepage. There are valid concerns that might explain such a move. You might as some of the Revolution/Microsoft about the possibility of a resurrection (or, perhaps, whether the same information is now available at a different location).

-pd

> On 01 Aug 2016, at 17:04 , Christopher W Ryan <cryan at binghamton.edu> wrote:
> 
> No, not off the grid. I just don't follow developments with Revolution
> or with Microsoft.
> 
> I was merely lamenting that inside-r URLs, that used to get me quickly
> to the R help pages (even if I was at a computer that did not have R),
> now re-direct to the corporate MRAN homepage, with the help pages
> nowhere to be found. Alas!
> 
> But thanks anyway.
> 
> --Chris
> 
> On Fri, Jul 29, 2016 at 3:54 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> Been off the grid for the last year? MS bought Revolution R.
>> 
>> 
>> Sent from my iPhone
>> 
>>> On Jul 29, 2016, at 11:30 AM, Christopher W. Ryan <cryan at binghamton.edu> wrote:
>>> 
>>> This might be a bit off-topic, but up until recently (a day or so ago?) I loved using inside-r.org as a quick and easy way to access help pages on R commands. Took me to what I needed without any fuss. Now that URL redirects to the "Microsoft R Application Network"?  Looks to be something related to Revolution R.  What happened?
>>> 
>>> Thanks.
>>> 
>>> --Chris Ryan
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Mon Aug  1 18:41:51 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 1 Aug 2016 09:41:51 -0700
Subject: [R] what happened to inside-r? [possibly OT]
In-Reply-To: <CAM+rpYm4N05BtDvv=tJyen4yOp+vHoC5LFEH-_511kLLLvRjEA@mail.gmail.com>
References: <579BA0CF.9050406@binghamton.edu>
	<8D2B3139-903F-4140-B68C-B72533ECE9DF@comcast.net>
	<CAM+rpYm4N05BtDvv=tJyen4yOp+vHoC5LFEH-_511kLLLvRjEA@mail.gmail.com>
Message-ID: <2E751482-C601-40D5-A86E-D917A5971A70@comcast.net>

If I prepend with "R" and an R function name in a Google search I generally see a link to a manual page at https://stat.ethz.ch/R-manual/R-devel/library/base/html/

David

Sent from my iPhone

> On Aug 1, 2016, at 8:04 AM, Christopher W Ryan <cryan at binghamton.edu> wrote:
> 
> No, not off the grid. I just don't follow developments with Revolution
> or with Microsoft.
> 
> I was merely lamenting that inside-r URLs, that used to get me quickly
> to the R help pages (even if I was at a computer that did not have R),
> now re-direct to the corporate MRAN homepage, with the help pages
> nowhere to be found. Alas!
> 
> But thanks anyway.
> 
> --Chris
> 
>> On Fri, Jul 29, 2016 at 3:54 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> Been off the grid for the last year? MS bought Revolution R.
>> 
>> 
>> Sent from my iPhone
>> 
>>> On Jul 29, 2016, at 11:30 AM, Christopher W. Ryan <cryan at binghamton.edu> wrote:
>>> 
>>> This might be a bit off-topic, but up until recently (a day or so ago?) I loved using inside-r.org as a quick and easy way to access help pages on R commands. Took me to what I needed without any fuss. Now that URL redirects to the "Microsoft R Application Network"?  Looks to be something related to Revolution R.  What happened?
>>> 
>>> Thanks.
>>> 
>>> --Chris Ryan
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 


From dcarlson at tamu.edu  Mon Aug  1 19:24:44 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 1 Aug 2016 17:24:44 +0000
Subject: [R] what happened to inside-r? [possibly OT]
In-Reply-To: <2E751482-C601-40D5-A86E-D917A5971A70@comcast.net>
References: <579BA0CF.9050406@binghamton.edu>
	<8D2B3139-903F-4140-B68C-B72533ECE9DF@comcast.net>
	<CAM+rpYm4N05BtDvv=tJyen4yOp+vHoC5LFEH-_511kLLLvRjEA@mail.gmail.com>
	<2E751482-C601-40D5-A86E-D917A5971A70@comcast.net>
Message-ID: <853525f079874d4b92c1f10d4f9ea6a3@exch-2p-mbx-t2.ads.tamu.edu>

Microsoft's version of CRAN (called of course, MRAN) has hyperlinked listings of

packages at https://mran.microsoft.com/packages/ and
Task Views at https://mran.microsoft.com/taskview/ 

DataCamp.com has a search engine for functions in CRAN and BioConductor (11095 packages) at

http://www.rdocumentation.org/

and Task Views at http://www.rdocumentation.org/taskviews

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David Winsemius
Sent: Monday, August 1, 2016 11:42 AM
To: Christopher W Ryan
Cc: R-help at r-project.org
Subject: Re: [R] what happened to inside-r? [possibly OT]

If I prepend with "R" and an R function name in a Google search I generally see a link to a manual page at https://stat.ethz.ch/R-manual/R-devel/library/base/html/

David

Sent from my iPhone

> On Aug 1, 2016, at 8:04 AM, Christopher W Ryan <cryan at binghamton.edu> wrote:
> 
> No, not off the grid. I just don't follow developments with Revolution
> or with Microsoft.
> 
> I was merely lamenting that inside-r URLs, that used to get me quickly
> to the R help pages (even if I was at a computer that did not have R),
> now re-direct to the corporate MRAN homepage, with the help pages
> nowhere to be found. Alas!
> 
> But thanks anyway.
> 
> --Chris
> 
>> On Fri, Jul 29, 2016 at 3:54 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> Been off the grid for the last year? MS bought Revolution R.
>> 
>> 
>> Sent from my iPhone
>> 
>>> On Jul 29, 2016, at 11:30 AM, Christopher W. Ryan <cryan at binghamton.edu> wrote:
>>> 
>>> This might be a bit off-topic, but up until recently (a day or so ago?) I loved using inside-r.org as a quick and easy way to access help pages on R commands. Took me to what I needed without any fuss. Now that URL redirects to the "Microsoft R Application Network"?  Looks to be something related to Revolution R.  What happened?
>>> 
>>> Thanks.
>>> 
>>> --Chris Ryan
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Mon Aug  1 19:35:23 2016
From: chocold12 at gmail.com (lily li)
Date: Mon, 1 Aug 2016 11:35:23 -0600
Subject: [R] about netcdf files
In-Reply-To: <CAN5afy9NeYPbG_B=KH3+pp2Dg9ytt9W5MJ+ApjFTRK2bVThSRA@mail.gmail.com>
References: <CAN5afy_MqYxSGuoqEwKHEn3N9X7q9XYJDHAga-e1M8dR30Q2FA@mail.gmail.com>
	<843d58d8-c1c9-a1b4-0480-3f727c55bff1@jrc.ec.europa.eu>
	<CAN5afy9NeYPbG_B=KH3+pp2Dg9ytt9W5MJ+ApjFTRK2bVThSRA@mail.gmail.com>
Message-ID: <CAN5afy9w_mKsQjGNu59Dum+0ULCXi5saa+He8Rq+GVqfe+vz1Q@mail.gmail.com>

Hi all,

I can read the data, but how to plot it using ggplot or something? In this
case, x-axis should be longitude, and y-axis should be latitude. I tried to
plot using raster function, but the x and y axes are from 0 to 1.
Thanks again.

The code is like this:
pre1 = nc_open('sample_precip_daily.nc')
pre.3d = ncvar_get(pre1, 'precipitation')

require(raster)
rplot = t(pre.3d[, , 1])
r = raster(rplot[nrow(rplot):1, ]
plot(r)


On Tue, Jul 26, 2016 at 1:07 PM, lily li <chocold12 at gmail.com> wrote:

> Thanks for your reply. But it says "Error in (function (classes, fdef,
> mtable)):
> unable to find an inherited method for function 'brick' for signature
> 'ncdf4' "
>
> The dataset is attached. It contains daily precipitation data for 20
> years, within a rectangle, so that there are several grid points. I use the
> code to open it, but don't know how to get csv files, while each file
> contains continuous daily precipitation data for each grid cell.
> pre1 = nc_open('sample_precip_daily.nc')
> pre1
> pre1_rd = ncvar_get(pre1, 'precipitation')
> nc_close(pre1)
>
> Thanks for your help.
>
> On Tue, Jul 26, 2016 at 4:08 AM, Jon Skoien <jon.skoien at jrc.ec.europa.eu>
> wrote:
>
>> You could try with the brick function from the raster package.
>>
>> bvar = brick(netcdfName)
>>
>> This uses the ncdf4 functions for opening and reading the netcdf, but
>> makes it easier to extract data for each day:
>>
>> p1 = rasterToPoints(bvar[[1]])
>> and write p1 to csv.
>>
>> Best,
>> Jon
>>
>>
>>
>> On 7/26/2016 6:54 AM, lily li wrote:
>>
>>> Hi all,
>>>
>>> I have a problem in opening netcdf files. If one netcdf file contains
>>> longitude, latitude, and daily precipitation. How to relate each
>>> precipitation record to its associated location, and export them as csv
>>> files? Thanks.
>>>
>>> I just use nc_open(), ncvar_get(), but it is not very helpful. Thanks for
>>> any ideas.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> --
>> Jon Olav Sk?ien
>> Joint Research Centre - European Commission
>> Institute for Space, Security & Migration
>> Disaster Risk Management Unit
>>
>> Via E. Fermi 2749, TP 122,  I-21027 Ispra (VA), ITALY
>>
>> jon.skoien at jrc.ec.europa.eu
>> Tel:  +39 0332 789205
>>
>> Disclaimer: Views expressed in this email are those of the individual and
>> do not necessarily represent official views of the European Commission.
>>
>
>

	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Mon Aug  1 19:46:14 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Mon, 1 Aug 2016 10:46:14 -0700
Subject: [R] about netcdf files
In-Reply-To: <CAN5afy9w_mKsQjGNu59Dum+0ULCXi5saa+He8Rq+GVqfe+vz1Q@mail.gmail.com>
References: <CAN5afy_MqYxSGuoqEwKHEn3N9X7q9XYJDHAga-e1M8dR30Q2FA@mail.gmail.com>
	<843d58d8-c1c9-a1b4-0480-3f727c55bff1@jrc.ec.europa.eu>
	<CAN5afy9NeYPbG_B=KH3+pp2Dg9ytt9W5MJ+ApjFTRK2bVThSRA@mail.gmail.com>
	<CAN5afy9w_mKsQjGNu59Dum+0ULCXi5saa+He8Rq+GVqfe+vz1Q@mail.gmail.com>
Message-ID: <EBDEA4CE-C886-48E3-B44B-45780D754CFE@noaa.gov>

Hi Lily:

If you download the vignette to my xtractomatic package  (http://coastwatch.pfeg.noaa.gov/xtracto/index.html) there are any number of examples using ggplot2 to make maps from netcdf data,

HTH,

-Roy

> On Aug 1, 2016, at 10:35 AM, lily li <chocold12 at gmail.com> wrote:
> 
> Hi all,
> 
> I can read the data, but how to plot it using ggplot or something? In this
> case, x-axis should be longitude, and y-axis should be latitude. I tried to
> plot using raster function, but the x and y axes are from 0 to 1.
> Thanks again.
> 
> The code is like this:
> pre1 = nc_open('sample_precip_daily.nc')
> pre.3d = ncvar_get(pre1, 'precipitation')
> 
> require(raster)
> rplot = t(pre.3d[, , 1])
> r = raster(rplot[nrow(rplot):1, ]
> plot(r)
> 
> 
> On Tue, Jul 26, 2016 at 1:07 PM, lily li <chocold12 at gmail.com> wrote:
> 
>> Thanks for your reply. But it says "Error in (function (classes, fdef,
>> mtable)):
>> unable to find an inherited method for function 'brick' for signature
>> 'ncdf4' "
>> 
>> The dataset is attached. It contains daily precipitation data for 20
>> years, within a rectangle, so that there are several grid points. I use the
>> code to open it, but don't know how to get csv files, while each file
>> contains continuous daily precipitation data for each grid cell.
>> pre1 = nc_open('sample_precip_daily.nc')
>> pre1
>> pre1_rd = ncvar_get(pre1, 'precipitation')
>> nc_close(pre1)
>> 
>> Thanks for your help.
>> 
>> On Tue, Jul 26, 2016 at 4:08 AM, Jon Skoien <jon.skoien at jrc.ec.europa.eu>
>> wrote:
>> 
>>> You could try with the brick function from the raster package.
>>> 
>>> bvar = brick(netcdfName)
>>> 
>>> This uses the ncdf4 functions for opening and reading the netcdf, but
>>> makes it easier to extract data for each day:
>>> 
>>> p1 = rasterToPoints(bvar[[1]])
>>> and write p1 to csv.
>>> 
>>> Best,
>>> Jon
>>> 
>>> 
>>> 
>>> On 7/26/2016 6:54 AM, lily li wrote:
>>> 
>>>> Hi all,
>>>> 
>>>> I have a problem in opening netcdf files. If one netcdf file contains
>>>> longitude, latitude, and daily precipitation. How to relate each
>>>> precipitation record to its associated location, and export them as csv
>>>> files? Thanks.
>>>> 
>>>> I just use nc_open(), ncvar_get(), but it is not very helpful. Thanks for
>>>> any ideas.
>>>> 
>>>>        [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>>> --
>>> Jon Olav Sk?ien
>>> Joint Research Centre - European Commission
>>> Institute for Space, Security & Migration
>>> Disaster Risk Management Unit
>>> 
>>> Via E. Fermi 2749, TP 122,  I-21027 Ispra (VA), ITALY
>>> 
>>> jon.skoien at jrc.ec.europa.eu
>>> Tel:  +39 0332 789205
>>> 
>>> Disclaimer: Views expressed in this email are those of the individual and
>>> do not necessarily represent official views of the European Commission.
>>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From chocold12 at gmail.com  Mon Aug  1 19:50:50 2016
From: chocold12 at gmail.com (lily li)
Date: Mon, 1 Aug 2016 11:50:50 -0600
Subject: [R] about netcdf files
In-Reply-To: <EBDEA4CE-C886-48E3-B44B-45780D754CFE@noaa.gov>
References: <CAN5afy_MqYxSGuoqEwKHEn3N9X7q9XYJDHAga-e1M8dR30Q2FA@mail.gmail.com>
	<843d58d8-c1c9-a1b4-0480-3f727c55bff1@jrc.ec.europa.eu>
	<CAN5afy9NeYPbG_B=KH3+pp2Dg9ytt9W5MJ+ApjFTRK2bVThSRA@mail.gmail.com>
	<CAN5afy9w_mKsQjGNu59Dum+0ULCXi5saa+He8Rq+GVqfe+vz1Q@mail.gmail.com>
	<EBDEA4CE-C886-48E3-B44B-45780D754CFE@noaa.gov>
Message-ID: <CAN5afy9fZOK-AZyqtHGWK2G10WS6f5NPrctfAif9XpPwXvrT9A@mail.gmail.com>

Thanks, Roy. I will do a search. In addition, how to look at spatial
patterns from this netcdf file? Thanks again.

On Mon, Aug 1, 2016 at 11:46 AM, Roy Mendelssohn - NOAA Federal <
roy.mendelssohn at noaa.gov> wrote:

> Hi Lily:
>
> If you download the vignette to my xtractomatic package  (
> http://coastwatch.pfeg.noaa.gov/xtracto/index.html) there are any number
> of examples using ggplot2 to make maps from netcdf data,
>
> HTH,
>
> -Roy
>
> > On Aug 1, 2016, at 10:35 AM, lily li <chocold12 at gmail.com> wrote:
> >
> > Hi all,
> >
> > I can read the data, but how to plot it using ggplot or something? In
> this
> > case, x-axis should be longitude, and y-axis should be latitude. I tried
> to
> > plot using raster function, but the x and y axes are from 0 to 1.
> > Thanks again.
> >
> > The code is like this:
> > pre1 = nc_open('sample_precip_daily.nc')
> > pre.3d = ncvar_get(pre1, 'precipitation')
> >
> > require(raster)
> > rplot = t(pre.3d[, , 1])
> > r = raster(rplot[nrow(rplot):1, ]
> > plot(r)
> >
> >
> > On Tue, Jul 26, 2016 at 1:07 PM, lily li <chocold12 at gmail.com> wrote:
> >
> >> Thanks for your reply. But it says "Error in (function (classes, fdef,
> >> mtable)):
> >> unable to find an inherited method for function 'brick' for signature
> >> 'ncdf4' "
> >>
> >> The dataset is attached. It contains daily precipitation data for 20
> >> years, within a rectangle, so that there are several grid points. I use
> the
> >> code to open it, but don't know how to get csv files, while each file
> >> contains continuous daily precipitation data for each grid cell.
> >> pre1 = nc_open('sample_precip_daily.nc')
> >> pre1
> >> pre1_rd = ncvar_get(pre1, 'precipitation')
> >> nc_close(pre1)
> >>
> >> Thanks for your help.
> >>
> >> On Tue, Jul 26, 2016 at 4:08 AM, Jon Skoien <
> jon.skoien at jrc.ec.europa.eu>
> >> wrote:
> >>
> >>> You could try with the brick function from the raster package.
> >>>
> >>> bvar = brick(netcdfName)
> >>>
> >>> This uses the ncdf4 functions for opening and reading the netcdf, but
> >>> makes it easier to extract data for each day:
> >>>
> >>> p1 = rasterToPoints(bvar[[1]])
> >>> and write p1 to csv.
> >>>
> >>> Best,
> >>> Jon
> >>>
> >>>
> >>>
> >>> On 7/26/2016 6:54 AM, lily li wrote:
> >>>
> >>>> Hi all,
> >>>>
> >>>> I have a problem in opening netcdf files. If one netcdf file contains
> >>>> longitude, latitude, and daily precipitation. How to relate each
> >>>> precipitation record to its associated location, and export them as
> csv
> >>>> files? Thanks.
> >>>>
> >>>> I just use nc_open(), ncvar_get(), but it is not very helpful. Thanks
> for
> >>>> any ideas.
> >>>>
> >>>>        [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>>
> >>> --
> >>> Jon Olav Sk?ien
> >>> Joint Research Centre - European Commission
> >>> Institute for Space, Security & Migration
> >>> Disaster Risk Management Unit
> >>>
> >>> Via E. Fermi 2749, TP 122,  I-21027 Ispra (VA), ITALY
> >>>
> >>> jon.skoien at jrc.ec.europa.eu
> >>> Tel:  +39 0332 789205
> >>>
> >>> Disclaimer: Views expressed in this email are those of the individual
> and
> >>> do not necessarily represent official views of the European Commission.
> >>>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> **********************
> "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK
> Jr.
>
>

	[[alternative HTML version deleted]]


From 538280 at gmail.com  Mon Aug  1 20:01:10 2016
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 1 Aug 2016 12:01:10 -0600
Subject: [R] Climate data in R
In-Reply-To: <CAMLwc7Od_CEOEkVnQtKaR0LRuxoOtXpLXgC5h6T6hZiUvfBsuA@mail.gmail.com>
References: <CAMLwc7Od_CEOEkVnQtKaR0LRuxoOtXpLXgC5h6T6hZiUvfBsuA@mail.gmail.com>
Message-ID: <CAFEqCdzy+Y8yK0Mie1q9H=0CWQhcKsOZQOm5PMT1QKKGg5kdUg@mail.gmail.com>

The rnoaa package has the function ncdc_stations which can be used to
search for stations in a region.  You could use that giving it an
extent around the coordinates that you are interested in (add and
subtract a small amount from the coordinates), then pass the results
from that function (possibly subsetted) into the ncdc function.

On Mon, Aug 1, 2016 at 8:06 AM, Miluji Sb <milujisb at gmail.com> wrote:
> Dear all,
>
> I have a set of coordinates. Is it possible to extract climate data
> (temperature and precipitation) by coordinates using the R packages such as
> rnoaa?
>
> For example;
>
> out <- ncdc(datasetid='ANNUAL', stationid='GHCND:USW00014895',
> datatypeid='TEMP')
>
> But instead of stationid can I pass a list of coordinates through it?
> Thanks a lot!
>
> Sincerely,
>
> Milu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From luke-tierney at uiowa.edu  Mon Aug  1 22:02:43 2016
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Mon, 1 Aug 2016 15:02:43 -0500
Subject: [R] Fwd: Help: malloc/free deadlock in unsafe signal handler
 'Rf_onsigusr1'
In-Reply-To: <CA+F1ufmmoqieSC_UiVfnoVAE_FvFZt10hDsKM=KMzR8s_VBaYA@mail.gmail.com>
References: <CA+F1ufkY+=gUBwGJFLdb+yCYyoqHHmQ3xJ_4zaiNo-084pmEoQ@mail.gmail.com>
	<CA+F1ufmmoqieSC_UiVfnoVAE_FvFZt10hDsKM=KMzR8s_VBaYA@mail.gmail.com>
Message-ID: <alpine.OSX.2.20.1608011459480.801@lukes-macbook-air.local>

The handlers for SIGUSR1 and SIGUSR2 are really intended as an
emergency break, not for ordinary programming. These could be
rewritten to be safer but that would make them less immediate.

Followups would be more appropriate on R-devel.

Best,

luke

On Mon, 1 Aug 2016, Ming Li wrote:

> Hi all,
>
> I am working on a bug,  which running PLR on HAWQ. The process hung and
> can't be terminated.
>
>> From my investigation, it seems signal handler 'Rf_onsigusr1' trigger a
> malloc/free deadlock.
>
> The calling stack is below.
>
> Thread 1 (Thread 0x7f4c93af48e0 (LWP 431263)):
> #0  0x00007f4c9015805e in __lll_lock_wait_private () from /lib64/libc.so.6
> #1  0x00007f4c900dd16b in _L_lock_9503 () from /lib64/libc.so.6
> #2  0x00007f4c900da6a6 in malloc () from /lib64/libc.so.6
> #3  0x00007f4c9008fb39 in _nl_make_l10nflist () from /lib64/libc.so.6
> #4  0x00007f4c9008ddf5 in _nl_find_domain () from /lib64/libc.so.6
> #5  0x00007f4c9008d6e0 in __dcigettext () from /lib64/libc.so.6
> #6  0x00007f4c6fabcfe3 in Rf_onsigusr1 () from /usr/local/lib64/R/lib/libR.so
> #7  <signal handler called>
> #8  0x00007f4c9014079a in brk () from /lib64/libc.so.6
> #9  0x00007f4c90140845 in sbrk () from /lib64/libc.so.6
> #10 0x00007f4c900dd769 in __default_morecore () from /lib64/libc.so.6
> #11 0x00007f4c900d87a2 in _int_free () from /lib64/libc.so.6
> #12 0x0000000000b3ff24 in gp_free2 ()
> #13 0x0000000000b356fc in AllocSetDelete ()
> #14 0x0000000000b38391 in MemoryContextDeleteImpl ()
> #15 0x000000000077c851 in ExecEndAgg ()
> #16 0x00000000007592ad in ExecEndNode ()
> #17 0x000000000075186c in ExecEndPlan ()
> #18 0x000000000079dffa in ExecEndSubqueryScan ()
> #19 0x000000000075921d in ExecEndNode ()
> #20 0x000000000075186c in ExecEndPlan ()
> #21 0x0000000000752565 in ExecutorEnd ()
> #22 0x00000000006dd9bd in PortalCleanup ()
> #23 0x0000000000b3f077 in AtCommit_Portals ()
> #24 0x000000000051abe5 in CommitTransaction ()
> #25 0x000000000051f1d5 in CommitTransactionCommand ()
> #26 0x000000000099809e in PostgresMain ()
> #27 0x00000000008f1031 in BackendStartup ()
> #28 0x00000000008f70e0 in PostmasterMain ()
> #29 0x00000000007f63da in main ()
>
>
> I googled and found below info maybe useful to fix it: The best way to
> avoid this kind of deadlock is to Call only asynchronous-safe functions
> within signal handlers.
>
> https://www.securecoding.cert.org/confluence/display/c/SIG30-C.+Call+only+asynchronous-safe+functions+within+signal+handlers
>
> Thanks a lot.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From roslinaump at gmail.com  Tue Aug  2 08:30:42 2016
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Tue, 2 Aug 2016 14:30:42 +0800
Subject: [R] Read output:
Message-ID: <CANTvJZKZJML+4FYGiuCJbsHeO5BCtzLrdQ+-5Mw-QZES3KQfig@mail.gmail.com>

Dear r-usersl,

I don't understand this comment:

> gambang <- read.csv("G:/A_backup 11 mei 2015/DATA (D)/1 Universiti
Malaysia Pahang/ISM-3 2016 UM/Data/Hourly
Rainfall/gambang2.csv",header=TRUE)
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'G:/A_backup 11 mei 2015/DATA (D)/1 Universiti Malaysia
Pahang/ISM-3 2016 UM/Data/Hourly Rainfall/gambang2.csv': No such file or
directory

Thank you for helping.
-- 
*Dr. Roslinazairimah Binti Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Deputy Dean (Academic & Student Affairs)
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Aug  2 09:42:57 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 2 Aug 2016 17:42:57 +1000
Subject: [R] Read output:
In-Reply-To: <CANTvJZKZJML+4FYGiuCJbsHeO5BCtzLrdQ+-5Mw-QZES3KQfig@mail.gmail.com>
References: <CANTvJZKZJML+4FYGiuCJbsHeO5BCtzLrdQ+-5Mw-QZES3KQfig@mail.gmail.com>
Message-ID: <CA+8X3fWfBDRcbFO96ta=TkLE8a__QSLFOq6Km38S9W4ASrNdLw@mail.gmail.com>

Hi Roslina,
As we do not know whether the file actually exists, all I can do is to
suggest that you look in your file manager (Windows Explorer,
probably) and see if the file is where you think it is. The problem is
most likely a spelling error somewhere in the path or filename.

Jim


On Tue, Aug 2, 2016 at 4:30 PM, roslinazairimah zakaria
<roslinaump at gmail.com> wrote:
> Dear r-usersl,
>
> I don't understand this comment:
>
>> gambang <- read.csv("G:/A_backup 11 mei 2015/DATA (D)/1 Universiti
> Malaysia Pahang/ISM-3 2016 UM/Data/Hourly
> Rainfall/gambang2.csv",header=TRUE)
> Error in file(file, "rt") : cannot open the connection
> In addition: Warning message:
> In file(file, "rt") :
>   cannot open file 'G:/A_backup 11 mei 2015/DATA (D)/1 Universiti Malaysia
> Pahang/ISM-3 2016 UM/Data/Hourly Rainfall/gambang2.csv': No such file or
> directory
>
> Thank you for helping.
> --
> *Dr. Roslinazairimah Binti Zakaria*
> *Tel: +609-5492370; Fax. No.+609-5492766*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Deputy Dean (Academic & Student Affairs)
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lorenzo.isella at gmail.com  Tue Aug  2 10:05:24 2016
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Tue, 2 Aug 2016 10:05:24 +0200
Subject: [R] DEA -- Extract the Frontier and ggplot2
Message-ID: <20160802080524.GA1928@chicca2>

Dear All,
Please consider the code at the end of the email.
Everything is fine in this little example, just I do not know how to
extract the DEA frontier (solid line in the plot).
The reason is that I want to reproduce a more complicated DEA frontier
plot using ggplot2 and I need to understand how I can extract the
frontier data. Alternatively: can anyone reproduce the same plot with ggplot2?
Many thanks

Lorenzo

###########################################?



library(Benchmarking) # load the Benchmarking library

x <- matrix(c(20, 40, 40, 60, 70, 50),ncol=1) #define inputs
y <- matrix(c(20, 30, 50, 40, 60, 20),ncol=1) #define outputs

e_vrs <- dea(x,y, RTS="vrs", ORIENTATION="in")#solve LP problem
eff_dea <- eff(e_vrs) #select efficiency scores from the results in e




dd <- as.data.frame(cbind(x,y))

names(dd) <- c("Input", "Output")
dd$Firm <- LETTERS[1:length(x)]

dd$Input <- as.integer(dd$Input)
dd$Output <- as.integer(dd$Output)

pdf("dea-frontier-vrs.pdf")
par( mar = c(4.5,5, 1, 1) + 0.1)
dea.plot(x,y,RTS="vrs",ORIENTATION="in",txt=LETTERS[1:length(x)],lty="dashed",
         xlab="Input", ylab="Output", fex=2,
	 cex=2,cex.lab=2,cex.axis=2)
	 dea.plot.frontier(x,y, RTS="vrs", add=T)
	 text(10,60, "VRS", cex=2)
	 dev.off()


From marc_grt at yahoo.fr  Tue Aug  2 10:07:55 2016
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Tue, 2 Aug 2016 10:07:55 +0200
Subject: [R] about netcdf files
In-Reply-To: <CAN5afy_MqYxSGuoqEwKHEn3N9X7q9XYJDHAga-e1M8dR30Q2FA@mail.gmail.com>
References: <CAN5afy_MqYxSGuoqEwKHEn3N9X7q9XYJDHAga-e1M8dR30Q2FA@mail.gmail.com>
Message-ID: <c11a5de6-c2ff-643e-f18e-59276739ede3@yahoo.fr>

You can find many tutorials in internet. For example, I did one here:
http://max2.ese.u-psud.fr/epc/conservation/Girondot/Publications/Blog_r/Entrees/2014/4/27_Comparison_between_packages_RnetCDF%2C_ncdf4_and_ncdf.html
Without any reproducibl example, it is impossible to help you further.

Sincerely

Marc


From lorenzo.isella at gmail.com  Tue Aug  2 11:11:50 2016
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Tue, 2 Aug 2016 11:11:50 +0200
Subject: [R] DEA -- Extract the Frontier and ggplot2
In-Reply-To: <AM4PR05MB168135006B067BDD4D82D2F6D9050@AM4PR05MB1681.eurprd05.prod.outlook.com>
References: <20160802080524.GA1928@chicca2>
	<AM4PR05MB168135006B067BDD4D82D2F6D9050@AM4PR05MB1681.eurprd05.prod.outlook.com>
Message-ID: <20160802091150.GA2111@chicca2>

Hello,
Thanks for your suggestion, but it is does not help me much.
Indeed, in this case where RTS="vrs", things are easy as you say.
However, try for instance to change the technology assumption
(e.g. replace it with RTS="drs" everywhere in my script) and you'll
see that things are not that simple.
I really need a way to extract the frontier -- it is plotted, so it is
calculated and it has to be buried somewhere in the package, just I do
not know where.
Cheers

Lorenzo

On Tue, Aug 02, 2016 at 09:05:15AM +0000, Jose Iparraguirre wrote:
>Lorenzo,
>
>dea.plot plots the vectors x and y, which you already have:
>data.frame(x,y)
>   x  y
>1 20 20
>2 40 30
>3 40 50
>4 60 40
>5 70 60
>6 50 20
>
>dea.plot.frontier plots the highest values of y for each value of x. Therefore, for x=20, the plot goes through y=20 but for X=40, where you have Y=30 and Y=50, the plot goes through the latter.
>
>Others in the list may give you an easier and better answer, but it's not difficult to plot all the X and Y in a scatterplot in ggplot and then to add a line along the highest values of Y per each X.
>
>I'm assuming you want an input orientation as in your example, of course.
>
>Hope it helps,
>
>Jos?
>
>
>Prof. Jos? Iparraguirre
>Chief Economist
>Age UK
>
>Age UK
>Tavis House, 1- 6 Tavistock Square
>London, WC1H 9NB
>
>T 020 303 31482
>E Jose.Iparraguirre at ageuk.org.uk<mailto:Jose.Iparraguirre at ageuk.org.uk>
>Twitter @jose.iparraguirre at ageuk
>
>www.ageuk.org.uk<http://www.ageuk.org.uk/> | ageukblog.org.uk | @ageukcampaigns
>
>
>Interested in our Policy and Research publications? Sign up to our monthly bulletin at http://www.ageuk.org.uk/professional-resources-home/research/
>
>For evidence and statistics on the older population, visit the Age UK Knowledge Hub http://www.ageuk.org.uk/professional-resources-home/knowledge-hub-evidence-statistics/
>
>
>
>
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Lorenzo Isella
>Sent: 02 August 2016 09:05
>To: r-help at r-project.org
>Cc: ggplot2 at googlegroups.com
>Subject: [R] DEA -- Extract the Frontier and ggplot2
>
>Dear All,
>Please consider the code at the end of the email.
>Everything is fine in this little example, just I do not know how to
>extract the DEA frontier (solid line in the plot).
>The reason is that I want to reproduce a more complicated DEA frontier
>plot using ggplot2 and I need to understand how I can extract the
>frontier data. Alternatively: can anyone reproduce the same plot with ggplot2?
>Many thanks
>
>Lorenzo
>
>###########################################?
>
>
>
>library(Benchmarking) # load the Benchmarking library
>
>x <- matrix(c(20, 40, 40, 60, 70, 50),ncol=1) #define inputs
>y <- matrix(c(20, 30, 50, 40, 60, 20),ncol=1) #define outputs
>
>e_vrs <- dea(x,y, RTS="vrs", ORIENTATION="in")#solve LP problem
>eff_dea <- eff(e_vrs) #select efficiency scores from the results in e
>
>
>
>
>dd <- as.data.frame(cbind(x,y))
>
>names(dd) <- c("Input", "Output")
>dd$Firm <- LETTERS[1:length(x)]
>
>dd$Input <- as.integer(dd$Input)
>dd$Output <- as.integer(dd$Output)
>
>pdf("dea-frontier-vrs.pdf")
>par( mar = c(4.5,5, 1, 1) + 0.1)
>dea.plot(x,y,RTS="vrs",ORIENTATION="in",txt=LETTERS[1:length(x)],lty="dashed",
>xlab="Input", ylab="Output", fex=2,
>cex=2,cex.lab=2,cex.axis=2)
>dea.plot.frontier(x,y, RTS="vrs", add=T)
>text(10,60, "VRS", cex=2)
>dev.off()
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
>and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
>Age UK
>
>Together, we can help everyone make the most of later life.
>
>Get involved and find out how you can donate, volunteer or give your support to help more people love later life at www.ageuk.org.uk
>
>-------------------------------------------------------------------------------------------------------
>Age UK is a registered charity and company limited by guarantee, (registered charity number 1128267, registered company number 6825798) Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA
>Charitable Services are offered through Age UK (the Charity) and commercial products and services are offered by the Charity?s subsidiary companies. The Age UK Group comprises of Age UK, and its subsidiary companies and charities, dedicated to helping more people make the most of later life. Our network includes the three national charities Age Cymru, Age NI and Age Scotland and more than 150 local Age UK charities.
>-------------------------------------------------------------------------------------------------------
>This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are addressed. If you receive a message in error, please advise the sender and delete immediately.
>Except where this email is sent in the usual course of our business, any opinions expressed in this email are those of the author and do not necessarily reflect the opinions of Age UK or its subsidiaries and associated companies. Age UK monitors all e-mail transmissions passing through its network and may block or modify mails which are deemed to be unsuitable.


From roman.lustrik at gmail.com  Tue Aug  2 12:13:47 2016
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Tue, 2 Aug 2016 12:13:47 +0200
Subject: [R] DEA -- Extract the Frontier and ggplot2
In-Reply-To: <20160802091150.GA2111@chicca2>
References: <20160802080524.GA1928@chicca2>
	<AM4PR05MB168135006B067BDD4D82D2F6D9050@AM4PR05MB1681.eurprd05.prod.outlook.com>
	<20160802091150.GA2111@chicca2>
Message-ID: <CAHT1vpjyqkMTnpJMV-SbSHg2nmFE8WmTghVCfOMNh1JY9r-99w@mail.gmail.com>

Hi,

this is not really a ggplot2 issue, but here goes.

If you look at the source code of the Benchmarking package (here
<https://github.com/cran/Benchmarking/blob/master/R/dea.plot.R>) you will
notice that the function is not very explicit about what to return - so the
returned thing is actually a plotting line (lines()). What you could do is
fork the repository, add your own return statement to include the `hpts`
<https://github.com/cran/Benchmarking/blob/master/R/dea.plot.R#L227> which
could be used to find the correct values in `x` (see for example here
<https://github.com/cran/Benchmarking/blob/master/R/dea.plot.R#L231> how
plotting is done).

After you have the formed repository ready (and pushed to your account),
you can install it through
devtools::install_github("yourname/Benchmarking"). Blesssed thee, open
source.

Cheers,
Roman

On Tue, Aug 2, 2016 at 11:11 AM, Lorenzo Isella <lorenzo.isella at gmail.com>
wrote:

> Hello,
> Thanks for your suggestion, but it is does not help me much.
> Indeed, in this case where RTS="vrs", things are easy as you say.
> However, try for instance to change the technology assumption
> (e.g. replace it with RTS="drs" everywhere in my script) and you'll
> see that things are not that simple.
> I really need a way to extract the frontier -- it is plotted, so it is
> calculated and it has to be buried somewhere in the package, just I do
> not know where.
> Cheers
>
> Lorenzo
>
> On Tue, Aug 02, 2016 at 09:05:15AM +0000, Jose Iparraguirre wrote:
>
>> Lorenzo,
>>
>> dea.plot plots the vectors x and y, which you already have:
>> data.frame(x,y)
>>   x  y
>> 1 20 20
>> 2 40 30
>> 3 40 50
>> 4 60 40
>> 5 70 60
>> 6 50 20
>>
>> dea.plot.frontier plots the highest values of y for each value of x.
>> Therefore, for x=20, the plot goes through y=20 but for X=40, where you
>> have Y=30 and Y=50, the plot goes through the latter.
>>
>> Others in the list may give you an easier and better answer, but it's not
>> difficult to plot all the X and Y in a scatterplot in ggplot and then to
>> add a line along the highest values of Y per each X.
>>
>> I'm assuming you want an input orientation as in your example, of course.
>>
>> Hope it helps,
>>
>> Jos?
>>
>>
>> Prof. Jos? Iparraguirre
>> Chief Economist
>> Age UK
>>
>> Age UK
>> Tavis House, 1- 6 Tavistock Square
>> London, WC1H 9NB
>>
>> T 020 303 31482
>> E Jose.Iparraguirre at ageuk.org.uk<mailto:Jose.Iparraguirre at ageuk.org.uk>
>> Twitter @jose.iparraguirre at ageuk
>>
>> www.ageuk.org.uk<http://www.ageuk.org.uk/> | ageukblog.org.uk |
>> @ageukcampaigns
>>
>>
>> Interested in our Policy and Research publications? Sign up to our
>> monthly bulletin at
>> http://www.ageuk.org.uk/professional-resources-home/research/
>>
>> For evidence and statistics on the older population, visit the Age UK
>> Knowledge Hub
>> http://www.ageuk.org.uk/professional-resources-home/knowledge-hub-evidence-statistics/
>>
>>
>>
>>
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Lorenzo
>> Isella
>> Sent: 02 August 2016 09:05
>> To: r-help at r-project.org
>> Cc: ggplot2 at googlegroups.com
>> Subject: [R] DEA -- Extract the Frontier and ggplot2
>>
>> Dear All,
>> Please consider the code at the end of the email.
>> Everything is fine in this little example, just I do not know how to
>> extract the DEA frontier (solid line in the plot).
>> The reason is that I want to reproduce a more complicated DEA frontier
>> plot using ggplot2 and I need to understand how I can extract the
>> frontier data. Alternatively: can anyone reproduce the same plot with
>> ggplot2?
>> Many thanks
>>
>> Lorenzo
>>
>> ###########################################?
>>
>>
>>
>> library(Benchmarking) # load the Benchmarking library
>>
>> x <- matrix(c(20, 40, 40, 60, 70, 50),ncol=1) #define inputs
>> y <- matrix(c(20, 30, 50, 40, 60, 20),ncol=1) #define outputs
>>
>> e_vrs <- dea(x,y, RTS="vrs", ORIENTATION="in")#solve LP problem
>> eff_dea <- eff(e_vrs) #select efficiency scores from the results in e
>>
>>
>>
>>
>> dd <- as.data.frame(cbind(x,y))
>>
>> names(dd) <- c("Input", "Output")
>> dd$Firm <- LETTERS[1:length(x)]
>>
>> dd$Input <- as.integer(dd$Input)
>> dd$Output <- as.integer(dd$Output)
>>
>> pdf("dea-frontier-vrs.pdf")
>> par( mar = c(4.5,5, 1, 1) + 0.1)
>>
>> dea.plot(x,y,RTS="vrs",ORIENTATION="in",txt=LETTERS[1:length(x)],lty="dashed",
>> xlab="Input", ylab="Output", fex=2,
>> cex=2,cex.lab=2,cex.axis=2)
>> dea.plot.frontier(x,y, RTS="vrs", add=T)
>> text(10,60, "VRS", cex=2)
>> dev.off()
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
>> UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help<
>> https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html<
>> http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>
>>
>> Age UK
>>
>> Together, we can help everyone make the most of later life.
>>
>> Get involved and find out how you can donate, volunteer or give your
>> support to help more people love later life at www.ageuk.org.uk
>>
>>
>> -------------------------------------------------------------------------------------------------------
>> Age UK is a registered charity and company limited by guarantee,
>> (registered charity number 1128267, registered company number 6825798)
>> Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA
>> Charitable Services are offered through Age UK (the Charity) and
>> commercial products and services are offered by the Charity?s subsidiary
>> companies. The Age UK Group comprises of Age UK, and its subsidiary
>> companies and charities, dedicated to helping more people make the most of
>> later life. Our network includes the three national charities Age Cymru,
>> Age NI and Age Scotland and more than 150 local Age UK charities.
>>
>> -------------------------------------------------------------------------------------------------------
>> This email and any files transmitted with it are confidential and
>> intended solely for the use of the individual or entity to whom they are
>> addressed. If you receive a message in error, please advise the sender and
>> delete immediately.
>> Except where this email is sent in the usual course of our business, any
>> opinions expressed in this email are those of the author and do not
>> necessarily reflect the opinions of Age UK or its subsidiaries and
>> associated companies. Age UK monitors all e-mail transmissions passing
>> through its network and may block or modify mails which are deemed to be
>> unsuitable.
>>
>
>
> --
> --
> You received this message because you are subscribed to the ggplot2
> mailing list.
> Please provide a reproducible example:
> https://github.com/hadley/devtools/wiki/Reproducibility
>
> To post: email ggplot2 at googlegroups.com
> To unsubscribe: email ggplot2+unsubscribe at googlegroups.com
> More options: http://groups.google.com/group/ggplot2
>
> --- You received this message because you are subscribed to the Google
> Groups "ggplot2" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to ggplot2+unsubscribe at googlegroups.com.
> For more options, visit https://groups.google.com/d/optout.
>



-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Aug  2 13:09:43 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 2 Aug 2016 07:09:43 -0400
Subject: [R] Read output:
In-Reply-To: <CANTvJZKZJML+4FYGiuCJbsHeO5BCtzLrdQ+-5Mw-QZES3KQfig@mail.gmail.com>
References: <CANTvJZKZJML+4FYGiuCJbsHeO5BCtzLrdQ+-5Mw-QZES3KQfig@mail.gmail.com>
Message-ID: <591962ff-9233-c3bb-240f-d6bc935ac091@gmail.com>

On 02/08/2016 2:30 AM, roslinazairimah zakaria wrote:
> Dear r-usersl,
>
> I don't understand this comment:
>
>> gambang <- read.csv("G:/A_backup 11 mei 2015/DATA (D)/1 Universiti
> Malaysia Pahang/ISM-3 2016 UM/Data/Hourly
> Rainfall/gambang2.csv",header=TRUE)
> Error in file(file, "rt") : cannot open the connection
> In addition: Warning message:
> In file(file, "rt") :
>   cannot open file 'G:/A_backup 11 mei 2015/DATA (D)/1 Universiti Malaysia
> Pahang/ISM-3 2016 UM/Data/Hourly Rainfall/gambang2.csv': No such file or
> directory
>

It says that the file doesn't exist.  It's got a long name, so you may 
have made an error typing it.  I recommend using

f <- file.choose()

to put the correct filename into f, then

read.csv(f, header = TRUE)

to read it.

Duncan Murdoch


From G.Maubach at weinwolf.de  Tue Aug  2 15:13:09 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 2 Aug 2016 15:13:09 +0200
Subject: [R] Antwort: Re: Re:  Spread data.frame on 2 variables (SOLVED)
In-Reply-To: <CAKVAULMUPn0pcMMaurYD-n9H2wwXXfvdNR4niGOBDcDGFs0mLw@mail.gmail.com>
References: <OFEF3872D0.FF96D82C-ONC1257FFE.00390EC0-C1257FFE.0039ED76@lotus.hawesko.de>
	<CAKVAULNG9E89v+gP0iTgX+03uw4SdnW4kKxvHD7yqkYk=zaYww@mail.gmail.com>
	<OF2307C174.58155947-ONC1257FFE.0040A46E-C1257FFE.00415453@lotus.hawesko.de>
	<CAKVAULMUPn0pcMMaurYD-n9H2wwXXfvdNR4niGOBDcDGFs0mLw@mail.gmail.com>
Message-ID: <OF499DAD8C.BF19B689-ONC1258003.0046B720-C1258003.00489DDD@lotus.hawesko.de>

Hi Ulrik,

many thanks for your help.

The problem was that R regards a dataset with a combination like

caseID          custID          channel         unit
1               1000            10              10
2               1000            20              10
3               1000            20              30

as two diffrenet sets of cases: 1 set = case 1, 2 set = case 2 and 3 due 
to the different values of unit in case 3 value 30, althought all cases 
should be restructured based just on custID.

To get a dataset like

caseID          custID          channel -10     channel-20      unit-10 
unit-30
1               1000            1               1               1 1

instead of

caseID          custID          channel -10     channel-20      unit-10 
unit-30
1               1000            1               1               1 NA
2               1000            NA              1               NA 1

I used the approach you suggested:

1. I created a subset of my data with the first variable to be 
restructured:

d_temp1 <- dataset[ , c("custID", "channel"))

2. I deleted all the cases the were dupliates

d_temp1 <- duplicated(d_temp1, c("custID", "channel")

3. I introduced a dummy variable delivering the values for the new 
variables created by dplyr:spread()

d_temp1$dummy <- 1 

4. Then I restructured the subset
d_temp1 <- dplyr::spread(d_temp1, key_variable = "channel", value = 
d_temp1$dummy)

5. I repeaed steps 1 to 4 with the other variable "unit" (instead of 
"channel") creating a new dataset named d_temp2.

6. I deleted the variables used for restructuring in steps 1 to 5 
"channel" and "unit" from the original dataset "dataset".

dataset$channel <- NULL
dataset$unit <- NULL

7. I checked if I still had duplicates

duplicates <- duplicated(dataset, key_variable = c("Debitor"))

sum(duplicates)  # was 0 it this time

8. I merged the datasets back together

dataset_2 <- merge(x = dataset, y = d_temp1, by.x = "Debitor", by.y = 
"Debitor", all.x = TRUE, all.y = TRUE)  # leaving out all.y would be fine
dataset_2 <- merge(x = dataset2, y = d_temp2, by.x = "Debitor", by.y = 
"Debitor", all.x = TRUE, all.y = TRUE)  # leaving out all.y would be fine

There might be a combination of commands and functions doing the same 
thing in one step but I find that this is clear, comprehensible and 
reproducable even at a later date or by other readers willing to use base 
R for their work.

Many thanks again for your help.

Kind regards

Georg





Von:    Ulrik Stervbo <ulrik.stervbo at gmail.com>
An:     G.Maubach at weinwolf.de, R-help <r-help at r-project.org>, 
Datum:  28.07.2016 14:20
Betreff:        Re: Re: [R] Spread data.frame on 2 variables



Hi Georg,

it is difficult to figure out what happens between your expectation and 
the outcome if we cannot see a minimal dataset.

Based on your description I did this

library(tidyr)
library(dplyr)

test_df <- data_frame(channel = LETTERS[1:5], unit = letters[1:5], custID 
= c(1:5), dummy = 1)
test_df %>% spread(channel, dummy) %>% mutate(dummy = 1) %>% spread(unit, 
dummy) 

which seems to be working fine as I get wide data. If a combination is 
missing in the long form it will also be missing in the wide form. Maybe 
you are looking for something like this:

channel_wide <- test_df  %>% select(channel, custID) %>% spread(channel, 
custID) 
unit_wide <- test_df  %>% select(unit, custID) %>% spread(unit, custID) 
bind_cols(channel_wide, unit_wide)

Apologies for the HTML - it's gmail

Best wishes,
Ulrik

On Thu, 28 Jul 2016 at 13:54 <G.Maubach at weinwolf.de> wrote:
Hi Ulrik,

I have included a reproducable example. I ran the code and it did exactly
what I wanted to show you.

You are right: the solution shall merge cases in the end cause the values
on the variables are either missing or the same.

Example 1: Values are the same
If you look at 6 and 7 and variable 70 the value is 1 in both cases. This
is in this context the same information and cases 6 and 7 with custID can
be merged to 1 for variable 70.

Example 2: Values are missing and not missing
If you look at cases 8 and 9 the value for case 8 at variable 40, 50 and
2000 is missing whereas the variables 40, 50 and 2000 have all 1 for case
9. Case 8 and 9 could be merged together cause the missing values are
overwritten what is correct in this case.

The solution I am looking for is to transform the data from long into wide
form and keep all but missing value information.

Did I explain my problem in a comprehensible way? Are there any further
questions?

Kind regards

Georg





Von:    Ulrik Stervbo <ulrik.stervbo at gmail.com>
An:     G.Maubach at weinwolf.de, r-help at r-project.org,
Datum:  28.07.2016 12:59
Betreff:        Re: [R] Spread data.frame on 2 variables



Hi Georg,

it's hard to tell without a reproducible example.

Should spread really merge elements? Does spread know anything about
CustID? Maybe you need to make a useful key of the CustIDs first and
spread on that?

Maybe I'm all off, because I'm really just guessing.

Best,
Ulrik

On Thu, 28 Jul 2016 at 12:36 <G.Maubach at weinwolf.de> wrote:
Hi All,

I need to spread a data.frame on 2 variables, e. g. "channel" and "unit".

If I do it in two steps spreads keeps all cases that does not look like
the one before although it contains the same values for a specific case.

Here is what I have right now:

-- cut --

test1$dummy <- 1
test2 <- spread(data = test1, key = 'channel', value = "dummy")
test2
cat("First spread is OK!")

test2$dummy <- 1
test3 <- spread(data = test2, key = 'unit', value = 'dummy')

test1
# test2
test3
warning(paste0("Second spread is not OK cause spread does not merge
cases\n",
               "with CustID 700 and 800 into one case,\n",
               "cause they have values on different variables,\n",
               "although the corresponding values of the cases with",
               "custID 700 and 800 are missing."))

cat("What I would like to have is:\n")
target4 <- structure(list(custID = c(100, 200, 300, 500, 600, 700, 800,
900),
  `10` = c(1, NA, NA, NA, NA, NA, NA, NA),
  `20` = c(1, NA, NA, NA, NA, NA, NA, NA),
  `30` = c(NA, NA, NA, NA, NA, NA, 1, 1),
  `40` = c(NA, NA, NA, NA, 1, NA, 1, 1),
  `50` = c(NA, NA, 1, NA, NA, NA, 1, 1),
  `60` = c(NA, NA, NA, NA, NA, 1, NA, NA),
  `70` = c(NA, NA, NA, NA, NA, 1, NA, NA),
  `99` = c(NA, 1, NA, 1, NA, NA, NA, NA),
  `1000` = c(1, NA, NA, NA, NA, NA, 1, 1),
  `2000` = c(NA, NA, NA, NA, 1, 1, 1, NA),
  `3000` = c(NA, NA, 1, NA, NA, 1, NA, NA),
  `4000` = c(NA, NA, 1, NA, NA, NA, NA, NA),
  `6000` = c(NA, NA, NA, NA, 1, NA, NA, NA),
  `9999` = c(NA, 1, NA, 1, NA, NA, NA, NA)),
.Names = c("custID",
 "10",  "20",  "30",  "40",  "50",  "60",  "70",  "99",
 "1000",  "2000",  "3000",  "4000",  "6000",  "9999"),
row.names = c(NA, 8L), class = "data.frame")

target4

cat("What would be a proper way to create target4 from test1?")

-- cut --

What would be the proper way to create target4 from test1?

Kind regards

Georg

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Aug  2 15:53:20 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 02 Aug 2016 06:53:20 -0700
Subject: [R] Read output:
In-Reply-To: <CANTvJZKZJML+4FYGiuCJbsHeO5BCtzLrdQ+-5Mw-QZES3KQfig@mail.gmail.com>
References: <CANTvJZKZJML+4FYGiuCJbsHeO5BCtzLrdQ+-5Mw-QZES3KQfig@mail.gmail.com>
Message-ID: <110F2EDC-3AA0-4F75-9291-FD20DBA7E077@dcn.davis.ca.us>

R could not find the specified file. Either it is not there or file system permissions (off topic here) prevented access to the file. 
-- 
Sent from my phone. Please excuse my brevity.

On August 1, 2016 11:30:42 PM PDT, roslinazairimah zakaria <roslinaump at gmail.com> wrote:
>Dear r-usersl,
>
>I don't understand this comment:
>
>> gambang <- read.csv("G:/A_backup 11 mei 2015/DATA (D)/1 Universiti
>Malaysia Pahang/ISM-3 2016 UM/Data/Hourly
>Rainfall/gambang2.csv",header=TRUE)
>Error in file(file, "rt") : cannot open the connection
>In addition: Warning message:
>In file(file, "rt") :
>cannot open file 'G:/A_backup 11 mei 2015/DATA (D)/1 Universiti
>Malaysia
>Pahang/ISM-3 2016 UM/Data/Hourly Rainfall/gambang2.csv': No such file
>or
>directory
>
>Thank you for helping.


From roslinaump at gmail.com  Tue Aug  2 16:22:26 2016
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Tue, 2 Aug 2016 22:22:26 +0800
Subject: [R] Read output:
In-Reply-To: <110F2EDC-3AA0-4F75-9291-FD20DBA7E077@dcn.davis.ca.us>
References: <CANTvJZKZJML+4FYGiuCJbsHeO5BCtzLrdQ+-5Mw-QZES3KQfig@mail.gmail.com>
	<110F2EDC-3AA0-4F75-9291-FD20DBA7E077@dcn.davis.ca.us>
Message-ID: <CANTvJZJzb4Gs5OYj7huJMVj-a9pg63TnvcQbpbQ0=PBB+gsimw@mail.gmail.com>

Dear all, All of you are right.  I use the external hard drive and
yesterday my laptop screen went blackout.  So I guess that is the cause.

Thank you for your help.

On Tue, Aug 2, 2016 at 9:53 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> R could not find the specified file. Either it is not there or file system
> permissions (off topic here) prevented access to the file.
> --
> Sent from my phone. Please excuse my brevity.
>
> On August 1, 2016 11:30:42 PM PDT, roslinazairimah zakaria <
> roslinaump at gmail.com> wrote:
> >Dear r-usersl,
> >
> >I don't understand this comment:
> >
> >> gambang <- read.csv("G:/A_backup 11 mei 2015/DATA (D)/1 Universiti
> >Malaysia Pahang/ISM-3 2016 UM/Data/Hourly
> >Rainfall/gambang2.csv",header=TRUE)
> >Error in file(file, "rt") : cannot open the connection
> >In addition: Warning message:
> >In file(file, "rt") :
> >cannot open file 'G:/A_backup 11 mei 2015/DATA (D)/1 Universiti
> >Malaysia
> >Pahang/ISM-3 2016 UM/Data/Hourly Rainfall/gambang2.csv': No such file
> >or
> >directory
> >
> >Thank you for helping.
>
>


-- 
*Dr. Roslinazairimah Binti Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Deputy Dean (Academic & Student Affairs)
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From mli at pivotal.io  Tue Aug  2 04:22:55 2016
From: mli at pivotal.io (Ming Li)
Date: Tue, 2 Aug 2016 10:22:55 +0800
Subject: [R] Fwd: Help: malloc/free deadlock in unsafe signal handler
	'Rf_onsigusr1'
In-Reply-To: <alpine.OSX.2.20.1608011459480.801@lukes-macbook-air.local>
References: <CA+F1ufkY+=gUBwGJFLdb+yCYyoqHHmQ3xJ_4zaiNo-084pmEoQ@mail.gmail.com>
	<CA+F1ufmmoqieSC_UiVfnoVAE_FvFZt10hDsKM=KMzR8s_VBaYA@mail.gmail.com>
	<alpine.OSX.2.20.1608011459480.801@lukes-macbook-air.local>
Message-ID: <CA+F1ufn=6DcGMYaR--o-BrSjOWR+xO3xqU__NR3X4kCXVKmEug@mail.gmail.com>

Thanks luke. cc hawq dev team.

I sent this email to R-devel 2 days before forwarding it to R-help, but no
one reply.

Is there any workaround? When were SIGUSR1 and SIGUSR2 sent in R? Or maybe
we should move all operations not too emergency out of signal handler?

Thanks.


On Tue, Aug 2, 2016 at 4:02 AM, <luke-tierney at uiowa.edu> wrote:

> The handlers for SIGUSR1 and SIGUSR2 are really intended as an
> emergency break, not for ordinary programming. These could be
> rewritten to be safer but that would make them less immediate.
>
> Followups would be more appropriate on R-devel.
>
> Best,
>
> luke
>
>
> On Mon, 1 Aug 2016, Ming Li wrote:
>
> Hi all,
>>
>> I am working on a bug,  which running PLR on HAWQ. The process hung and
>> can't be terminated.
>>
>> From my investigation, it seems signal handler 'Rf_onsigusr1' trigger a
>>>
>> malloc/free deadlock.
>>
>> The calling stack is below.
>>
>> Thread 1 (Thread 0x7f4c93af48e0 (LWP 431263)):
>> #0  0x00007f4c9015805e in __lll_lock_wait_private () from /lib64/libc.so.6
>> #1  0x00007f4c900dd16b in _L_lock_9503 () from /lib64/libc.so.6
>> #2  0x00007f4c900da6a6 in malloc () from /lib64/libc.so.6
>> #3  0x00007f4c9008fb39 in _nl_make_l10nflist () from /lib64/libc.so.6
>> #4  0x00007f4c9008ddf5 in _nl_find_domain () from /lib64/libc.so.6
>> #5  0x00007f4c9008d6e0 in __dcigettext () from /lib64/libc.so.6
>> #6  0x00007f4c6fabcfe3 in Rf_onsigusr1 () from
>> /usr/local/lib64/R/lib/libR.so
>> #7  <signal handler called>
>> #8  0x00007f4c9014079a in brk () from /lib64/libc.so.6
>> #9  0x00007f4c90140845 in sbrk () from /lib64/libc.so.6
>> #10 0x00007f4c900dd769 in __default_morecore () from /lib64/libc.so.6
>> #11 0x00007f4c900d87a2 in _int_free () from /lib64/libc.so.6
>> #12 0x0000000000b3ff24 in gp_free2 ()
>> #13 0x0000000000b356fc in AllocSetDelete ()
>> #14 0x0000000000b38391 in MemoryContextDeleteImpl ()
>> #15 0x000000000077c851 in ExecEndAgg ()
>> #16 0x00000000007592ad in ExecEndNode ()
>> #17 0x000000000075186c in ExecEndPlan ()
>> #18 0x000000000079dffa in ExecEndSubqueryScan ()
>> #19 0x000000000075921d in ExecEndNode ()
>> #20 0x000000000075186c in ExecEndPlan ()
>> #21 0x0000000000752565 in ExecutorEnd ()
>> #22 0x00000000006dd9bd in PortalCleanup ()
>> #23 0x0000000000b3f077 in AtCommit_Portals ()
>> #24 0x000000000051abe5 in CommitTransaction ()
>> #25 0x000000000051f1d5 in CommitTransactionCommand ()
>> #26 0x000000000099809e in PostgresMain ()
>> #27 0x00000000008f1031 in BackendStartup ()
>> #28 0x00000000008f70e0 in PostmasterMain ()
>> #29 0x00000000007f63da in main ()
>>
>>
>> I googled and found below info maybe useful to fix it: The best way to
>> avoid this kind of deadlock is to Call only asynchronous-safe functions
>> within signal handlers.
>>
>>
>> https://www.securecoding.cert.org/confluence/display/c/SIG30-C.+Call+only+asynchronous-safe+functions+within+signal+handlers
>>
>> Thanks a lot.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>

	[[alternative HTML version deleted]]


From jake.andrae at adelaide.edu.au  Tue Aug  2 05:02:03 2016
From: jake.andrae at adelaide.edu.au (Jake William Andrae)
Date: Tue, 2 Aug 2016 03:02:03 +0000
Subject: [R] Colour gradients in ggtern
Message-ID: <15E1D0623AFA794999C09BE1916D7A8C06BBA642@mailmb10.ad.adelaide.edu.au>

Hello,

This is my first time posting to the r-help mailing list and I'm a relative amateur using R, so forgive my naivety. I am constructing a ternary diagram using the ggtern extension of the ggplot package, and I'm having some trouble with the colour gradient I want it to display. I have attached the output plot, where a rainbow colour gradient can be seen, but I really need these colours to be in reverse order. This is the command I used to construct the plot;


#Plot construction

> ggtern(data= C27_C29_C31, aes(x=C27,y=C29,z=C31))+geom_point(aes(colour= GST),size=3)+theme_light()+theme_nogrid_minor()+scale_colour_gradientn(colours = rainbow(5.5))


Is there a simple way to reverse the colours in the scale_colour_gradientn command?

Kind regards,
Jake Andrae



-------------- next part --------------
A non-text attachment was scrubbed...
Name: C27,C29,C31 GST.png
Type: image/png
Size: 8748 bytes
Desc: C27,C29,C31 GST.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160802/2d080638/attachment.png>

From arthur.stilben at gmail.com  Tue Aug  2 16:51:11 2016
From: arthur.stilben at gmail.com (Arthur Stilben)
Date: Tue, 2 Aug 2016 11:51:11 -0300
Subject: [R] Fuzzy variable universe
In-Reply-To: <CAM_vjunimoHHECWOm+R1qNckxb7UNfvHW-PtBoeJPxMX0a-dcA@mail.gmail.com>
References: <CAE9uMN8DAg9U8mJe3XB8+U6EzecumGS3y8GW74-uhxAypFx6rQ@mail.gmail.com>
	<C1119D79-8AA3-422E-99CA-3F08EE3B91FF@dcn.davis.ca.us>
	<579A4AEF.2030508@gmail.com>
	<CAM_vjun+yfcNkv6WnimzndfmZYNuOoEvfmwtOnYEjqqDcm-KfQ@mail.gmail.com>
	<579A52B1.1000101@gmail.com> <579A530C.6080708@gmail.com>
	<CAM_vjunimoHHECWOm+R1qNckxb7UNfvHW-PtBoeJPxMX0a-dcA@mail.gmail.com>
Message-ID: <CAE9uMN9tk5XeT_4_5YoKK5Wsv0ZVX+98U9r0QmZr5Ev0G18DxA@mail.gmail.com>

Thanks, Sarah, for the reply. It really works.

2016-07-28 15:50 GMT-03:00 Sarah Goslee <sarah.goslee at gmail.com>:
> On Thu, Jul 28, 2016 at 2:46 PM, Arthur Rodrigues Stilben
> <arthur.stilben at gmail.com> wrote:
>>
>>
>> Em 28-07-2016 15:45, Arthur Rodrigues Stilben escreveu:
>>>
>>> Sarah,
>>>
>>> First of all, thanks for reply.
>>>
>>> Second, It really works, but in fact I would to like to set individuals
>>> universe groups for each fuzzy_variable. Something like this:
>>>
>>> > test1 = fuzzy_variable( a = fuzzy_trapezoid( corners = c( 0, 1, 2, 3 )
>>> > ), universe = seq( from = 0, to = 10, by = 0.1 ) )
>>> > test2 = fuzzy_variable( b = fuzzy_trapezoid( corners = c( 4, 5, 6, 7 )
>>> > ), universe = seq( from = 0, to = 5, by = 0.1 ) )
>
> You have to do it as two steps. fuzzy_variable() doesn't accept a
> universe argument.
>
> sets_options("universe", seq(from = 0, to = 10, by = 0.1))
> test1 = fuzzy_variable( a = fuzzy_trapezoid( corners = c( 0, 1, 2, 3 )))
>
> sets_options("universe",  seq( from = 0, to = 5, by = 0.1 ))
> test2 = fuzzy_variable( b = fuzzy_trapezoid( corners = c( 4, 5, 6, 7 )))
>
> But there's no reason you can't set it as many times as you want.
>
>>> Em 28-07-2016 15:25, Sarah Goslee escreveu:
>>>>
>>>> As Jeff suggested, I read the help for you.
>>>>
>>>> Based on the examples, you need:
>>>>
>>>>
>>>>       ## set universe
>>>>       sets_options("universe", seq(from = 0, to = 10, by = 0.1))
>>>>       teste2 = fuzzy_variable( a = fuzzy_trapezoid( corners = c( 0, 1, 2,
>>>> 3 ) ) )
>>>>
>>>> comparing
>>>> plot(teste) # complete with Warning
>>>> and
>>>> plot(teste2)
>>>> makes me think this did what you wanted. At least, it did something.
>>>>
>>>> Sarah
>>>>
>>>> On Thu, Jul 28, 2016 at 2:11 PM, Arthur Rodrigues Stilben
>>>> <arthur.stilben at gmail.com> wrote:
>>>>>
>>>>> Sorry, I forgot to mention:
>>>>>
>>>>>> install.packages("sets")
>>>>>
>>>>> ...
>>>>>>
>>>>>> library(sets)
>>>>>> teste = fuzzy_variable( a = fuzzy_trapezoid( corners = c( 0, 1, 2, 3 )
>>>>>> ),
>>>>>> universe = seq( from = 0, to = 10, by = 0.1 ) )
>>>>>> teste
>>>>>
>>>>> A fuzzy variable with values: a, universe
>>>>>
>>>>> The ideia is to set the universe group for the fuzzy variable, but it
>>>>> didn't
>>>>> work.
>>>>>
>>>>> PS.: I'm newbie here, so I apologize for some mistakes :P.
>>>>>
>>>>> Att,
>>>>>
>>>>> Em 28-07-2016 11:23, Jeff Newmiller escreveu:
>>>>>>
>>>>>> This appears to be a question about a contributed package, though you
>>>>>> have
>>>>>> not specified which one (so your example code is not reproducible).
>>>>>>
>>>>>> Be warned that I have never seen discussion of fuzzy logic on this
>>>>>> list,
>>>>>> so any help you get here is likely to be from someone reading the
>>>>>> documentation for you. Please be sure to read it carefully yourself
>>>>>> first,
>>>>>> and read about reproducibility and support for contributed packages in
>>>>>> the
>>>>>> Posting Guide.
>>>>>
>>>>>
>>>>> --
>>>>> Arthur Rodrigues Stilben
>>>>>



-- 
Arthur Rodrigues Stilben
Geoinform?tica - LENEP
(22) 2765-6555


From ulrik.stervbo at gmail.com  Tue Aug  2 17:00:16 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 02 Aug 2016 15:00:16 +0000
Subject: [R] Colour gradients in ggtern
In-Reply-To: <15E1D0623AFA794999C09BE1916D7A8C06BBA642@mailmb10.ad.adelaide.edu.au>
References: <15E1D0623AFA794999C09BE1916D7A8C06BBA642@mailmb10.ad.adelaide.edu.au>
Message-ID: <CAKVAULNwvTb+Qv-4Ku2Ta8TDhoVn1_MBhCa=eMbk804GOm=s2w@mail.gmail.com>

Hi Jake,

maybe you can just revet the colours given to the scale:

scale_colour_gradientn(colours = rev(rainbow(5.5)))

Best,
Ulrik

On Tue, 2 Aug 2016 at 16:41 Jake William Andrae <jake.andrae at adelaide.edu.au>
wrote:

> Hello,
>
> This is my first time posting to the r-help mailing list and I'm a
> relative amateur using R, so forgive my naivety. I am constructing a
> ternary diagram using the ggtern extension of the ggplot package, and I'm
> having some trouble with the colour gradient I want it to display. I have
> attached the output plot, where a rainbow colour gradient can be seen, but
> I really need these colours to be in reverse order. This is the command I
> used to construct the plot;
>
>
> #Plot construction
>
> > ggtern(data= C27_C29_C31, aes(x=C27,y=C29,z=C31))+geom_point(aes(colour=
> GST),size=3)+theme_light()+theme_nogrid_minor()+scale_colour_gradientn(colours
> = rainbow(5.5))
>
>
> Is there a simple way to reverse the colours in the scale_colour_gradientn
> command?
>
> Kind regards,
> Jake Andrae
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From arthur.stilben at gmail.com  Tue Aug  2 17:14:13 2016
From: arthur.stilben at gmail.com (Arthur Stilben)
Date: Tue, 2 Aug 2016 12:14:13 -0300
Subject: [R] Fuzzy_partition with fuzzy_trapezoid
Message-ID: <CAE9uMN8t4uK=dP74z9S5tQSxFuAp0-G47ws9xEM60C3Cr-DJzg@mail.gmail.com>

I already made this question, but I was not subscribed and not
received any reply. I tried this:

> install.packages("sets")
...
> library(sets)
> teste = fuzzy_partition(varnames = c('a', 'b'), FUN = fuzzy_trapezoid, corners = c(1,2,3,4), height = c(1,1), corners = c(5,6,7,8), height = c(1,1) )

But I got this error:

Error in FUN(i, ...) :
  formal argument "corners" represents multiples specified arguments

Is it possible to combine fuzzy_partition with fuzzy_trapezoid?

Att,

-- 
Arthur Rodrigues Stilben
Geoinform?tica - LENEP
(22) 2765-6555


From 538280 at gmail.com  Tue Aug  2 17:41:47 2016
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 2 Aug 2016 09:41:47 -0600
Subject: [R] questions about co-linearity in logistic regression from
	Stefano Sofia
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F3DBCF6A6@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F3DBCF6A6@ESINO.regionemarche.intra>
Message-ID: <CAFEqCdxtvjfpDjabi-K8hCM3t7cT8GGc4w_4miPcfaBeThZBHA@mail.gmail.com>

Stefano,

It is usually best to keep these discussions on R-help.  People there
may be quicker to respond and could have better answers. Keeping the
discussion on the list also means that if others in the future find
your question, they will also find the answers and discussion.  And
some of us can spend some time answering questions on the list as a
community stewardship contribution, but when asked directly it turns
into consulting and we would need to start charging a fee (and I
expect that sharing your answer with the community as a whole is lot
cheaper than what my employer would insist that I charge you as a
consultant).

Quick answers to your questions:

1. an example of the data:

> tmp.dat <- data.frame(color=factor(c('red','green','blue'),
+ levels=c('red','green','blue'))
+ )
> model.matrix(~color-1, data=tmp.dat)
  colorred colorgreen colorblue
1        1          0         0
2        0          1         0
3        0          0         1
attr(,"assign")
[1] 1 1 1
attr(,"contrasts")
attr(,"contrasts")$color
[1] "contr.treatment"


2.  There is co-linearity with the intercept because the intercept is
represented by a column of 1's and you can see that if you add the 3
columns above you also will see a column of 1's.

3. There are 3 pieces of information (3 colors) so you need 3 columns
to represent those, you can reconstruct the "blue" column by
subtracting "red" and "green" from the column of 1's that represent
the intercept.  Dropping the last 2 columns only leaves 2 pieces left
which will not contain all the information (just "red" and the
intercept, "blue" and "green" would be combined in that case).  Any
column could be dropped (including the intercept), R/S just chose to
drop the last one by default.

4.  The full answer to this would involve studying the reparameterized
cell-means model:
Bryce, G. Rex, Del T. Scott, and M. W. Carter. "ESTIMATION AND
HYPOTHESIS-TESTING IN LINEAR-MODELS-REPARAMETERIZATION APPROACH TO THE
CELL MEANS MODEL." COMMUNICATIONS IN STATISTICS PART A-THEORY AND
METHODS 9.2 (1980): 131-150.

but the quick answer can be seen by the parameterization using the
intercept and dropping a column for "blue":

> tmp.dat <- data.frame(color=factor(c('red','green','blue')))
> model.matrix(~color, data=tmp.dat)
  (Intercept) colorgreen colorred
1           1          0        1
2           1          1        0
3           1          0        0
attr(,"assign")
[1] 0 1 1
attr(,"contrasts")
attr(,"contrasts")$color
[1] "contr.treatment"

> solve(.Last.value)
                 1 2  3
(Intercept)   0 0  1
colorgreen   0 1 -1
colorred      1 0 -1

You can see that the rows corresponding to "blue" have only the
intercept as non-zero while the other rows have the intercept plus
another column as 1's, In the contrast matrix (the result of `solve`)
the intercept corresponds exactly to 3/blue and the others are the
difference between blue and the other 2 colors.  Even with the dummy
variables you can see that when predicting red you take the intercept
plus the coefficient for red, when predicting green you take the
intercept plus the coefficient for green, and when predicting for blue
you just use the intercept.  This should intuitively suggest that the
intercept is the mean/prediction for blue and the other coefficients
are the differences to be added to "blue" to get the other values.

5. see answer to 4




On Mon, Aug 1, 2016 at 4:18 AM, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
> Dear Dr. Snow,
> my name is Stefano Sofia (I am a meteorologist), I always read posts on the
> r-mailing list.
>
> Few days ago I read with great interest your answer about "Why the order of
> parameters in a logistic regression affects results significantly?"
>
> I am very interested in regression, I have some basis about it but not so
> solid to understand the considerations you mentioned.
> Therefore may I ask you some questions (only if you have got time), or a
> reference text where I can find the answers?
>
> Sorry for the disturb, and thank you for your help.
> Stefano Sofia PhD
>
> Here my questions.
>
> 1. Could you please give me a very short example of three predictors (red,
> green and blue) that are indicators variables with a 1 in exactly one of
> those variables?
> 2. Why in this case there is co-linearity with the intercept?
> 3. Why in case of co-linearity only the last variable is removed (the blue)
> and not the last two ones?
> 4. Why the intercept is the average for blue?
> 5. And finally why the coefficients are the differences between red/green
> and blue on average?
>
> Here there is your original e-mail:
> "...
> The fact that the last coefficient is NA in both outputs suggests that
> there was some co-linearity in your predictor variables and R chose to
> drop one of the offending variables from the model (the last one in
> each case).  Depending on the nature of the co-linearity, the
> interpretation (and therefore the estimates) can change.
>
> For example lets say that you have 3 predictors, red, green, and blue
> that are indicator variables (0/1) and that every subject has a 1 in
> exactly one of those variables (so they are co-linear with the
> intercept).  If you put the 3 variables into a model with the
> intercept in the above order, then R will drop the blue variable and
> the interpretation of the coefficients is that the intercept is the
> average for blue subjects and the other coefficients are the
> differences between red/green and blue on average.  If you refit the
> model with the order blue, green, red, then R will drop red from the
> model and now the interpretation is that the intercept is the mean for
> red subjects and the others are the differences from red on average, a
> very different interpretation and therefore different estimates.
>
> I expect something along those lines is going on here."
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
> informazioni confidenziali, pertanto ? destinato solo a persone autorizzate
> alla ricezione. I messaggi di posta elettronica per i client di Regione
> Marche possono contenere informazioni confidenziali e con privilegi legali.
> Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o
> archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore,
> inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio
> computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in
> caso di necessit? ed urgenza, la risposta al presente messaggio di posta
> elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by
> persons entitled to receive the confidential information it may contain.
> E-mail messages to clients of Regione Marche may contain information that is
> confidential and legally privileged. Please do not read, copy, forward, or
> store this message unless you are an intended recipient of it. If you have
> received this message in error, please forward it to the sender and delete
> it completely from your computer system.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From sarah.goslee at gmail.com  Tue Aug  2 17:51:50 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 2 Aug 2016 11:51:50 -0400
Subject: [R] Fuzzy_partition with fuzzy_trapezoid
In-Reply-To: <CAE9uMN8t4uK=dP74z9S5tQSxFuAp0-G47ws9xEM60C3Cr-DJzg@mail.gmail.com>
References: <CAE9uMN8t4uK=dP74z9S5tQSxFuAp0-G47ws9xEM60C3Cr-DJzg@mail.gmail.com>
Message-ID: <CAM_vjukqWw8hrQ+hhMZxuRq40c_vFiqpUYF1AhMbMSk2_3BELw@mail.gmail.com>

As already discussed, yes, but you can't specify corners and height
twice in a single call.
Please do read the help for the functions you're interested in, and
perhaps go back to refresh yourself on some basic R.

> sets_options("universe", seq(from = 0, to = 10, by = 0.1))
> test1 = fuzzy_variable( a = fuzzy_trapezoid( corners = c( 0, 1, 2, 3 )))
>
> sets_options("universe",  seq( from = 0, to = 5, by = 0.1 ))
> test2 = fuzzy_variable( b = fuzzy_trapezoid( corners = c( 4, 5, 6, 7 )))
>

On Tue, Aug 2, 2016 at 11:14 AM, Arthur Stilben
<arthur.stilben at gmail.com> wrote:
> I already made this question, but I was not subscribed and not
> received any reply. I tried this:
>
>> install.packages("sets")
> ...
>> library(sets)
>> teste = fuzzy_partition(varnames = c('a', 'b'), FUN = fuzzy_trapezoid, corners = c(1,2,3,4), height = c(1,1), corners = c(5,6,7,8), height = c(1,1) )
>
> But I got this error:
>
> Error in FUN(i, ...) :
>   formal argument "corners" represents multiples specified arguments
>
> Is it possible to combine fuzzy_partition with fuzzy_trapezoid?
>
> Att,
>


From justinthong93 at gmail.com  Tue Aug  2 18:06:55 2016
From: justinthong93 at gmail.com (Justin Thong)
Date: Tue, 2 Aug 2016 17:06:55 +0100
Subject: [R] What is "args" in this function?
Message-ID: <CAEtAGeooez21kp+a7T=Y-2j1qe_+PBkNeX_FPonucq0PCEA7iw@mail.gmail.com>

Hi again I need help

*R-code*
debug(model.matrix)
model.matrix(~S)

*model.matrix code*
ans <- .External2(C_modelmatrix, t, data) #t =terms(object) , data="data
frame of object"

*modelframe C-code*
SEXP modelframe(SEXP call, SEXP op, SEXP args, SEXP rho)
{
    SEXP terms, data, names, variables, varnames, dots, dotnames, na_action;
    SEXP ans, row_names, subset, tmp;
    char buf[256];
    int i, j, nr, nc;
    int nvars, ndots, nactualdots;
    const void *vmax = vmaxget();

    args = CDR(args);
    terms = CAR(args); args = CDR(args);
    row_names = CAR(args); args = CDR(args);
    variables = CAR(args); args = CDR(args);
    varnames = CAR(args); args = CDR(args);
    dots = CAR(args); args = CDR(args);
    dotnames = CAR(args); args = CDR(args);
    subset = CAR(args); args = CDR(args);
    na_action = CAR(args);

. . . .

I am sorry I virtually have no experience in C.
Can someone explain to me what "args" is at the point when it enters the
function? I know CAR points to the first element of an object, and CDR
points to the complement of the first element of an object.

Does "args" represent the list of t and data?
or
Does "args" represent the thrid argument in .External2 which is data?
or
something else

I am guessing this whole process of playing CAR and CDR is just a way of
extracting variables from "args" until everything thing in "args" is
assigned to.

For instance, if args=(1,2,3,4,5,6) then below correspond in square
brackets

  args = CDR(args); [(1,2,3,4,5,6)]
  terms = CAR(args) ;[(1)] args = CDR(args);[(2,3,4,5,6)]
    row_names = CAR(args);[(2)] args = CDR(args);[(3,4,5,6)]
    variables = CAR(args);[(3)] args = CDR(args);[(4,5,6)]
    varnames = CAR(args);[(4)] args = CDR(args);[(5,6)]
   etc

Is this correct?

I am sorry if I am asking too many questions on C. Please advise if I am
posting inappropriately.



-- 
Yours sincerely,
Justin

*I check my email at 9AM and 4PM everyday*
*If you have an EMERGENCY, contact me at +447938674419(UK) or
+60125056192(Malaysia)*

	[[alternative HTML version deleted]]


From roslinaump at gmail.com  Tue Aug  2 18:37:22 2016
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Wed, 3 Aug 2016 00:37:22 +0800
Subject: [R] Anderson Darling Goodness of fit test
Message-ID: <CANTvJZLnEBgTdp+b0ESPXj8VD1kU4YiShhvp8mg13XRVMEnqrw@mail.gmail.com>

Dear r-users,

I would like to perform Anderson Darling Goodness of fit test as such:

install.packages("adk")
library(adk)
x3 <- list(stn_all[,1], balok_gen); x3
adk.test(x3)

#x3 <- list(jun_data1_pos,jun_gen); x3
#adk.test(x3)

However, I got this reply:

> adk.test(x3)
Error: could not find function "adk.test"


Thank you so much for any help given.

-- 
*Dr. Roslinazairimah Binti Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Deputy Dean (Academic & Student Affairs)
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From fisher at plessthan.com  Tue Aug  2 18:46:15 2016
From: fisher at plessthan.com (Dennis Fisher)
Date: Tue, 2 Aug 2016 09:46:15 -0700
Subject: [R] Regression expression to delete one or more spaces at end of
	string
Message-ID: <DDE9660F-AB7E-4E18-9102-D86CD9B0AA2D@plessthan.com>

R 3.3.1
OS X

Colleagues, 

I have encountered an unexpected regex problem

I have read an Excel file into R using the readxl package.  Columns names are:

COLNAMES	<- c("Study ID", "Test and Biological Matrix", "Subject No. ", "Collection Date", 
"Collection Time", "Scheduled Time Point", "Concentration", "Concentration Units", 
"LLOQ", "ULOQ", "Comment?)

As you can see, there is a trailing space in ?Subject No. ?.  I would like to delete that space.  The following works:
	sub(? $?, ??, COLNAMES)
However, I would like a more general approach that removes any trailing whitespace.

I tried variations such as:
	sub("[:blank:]$", "", COLNAMES)
(also, without the $ and ?space' instead of ?blank') without success ? to my surprise, characters other than the trailing space were deleted but the trailing space remained.

Guidance on the correct syntax would be appreciated.

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone / Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com


From arthur.stilben at gmail.com  Tue Aug  2 18:54:39 2016
From: arthur.stilben at gmail.com (Arthur Stilben)
Date: Tue, 2 Aug 2016 13:54:39 -0300
Subject: [R] Fuzzy_partition with fuzzy_trapezoid
In-Reply-To: <CAM_vjukqWw8hrQ+hhMZxuRq40c_vFiqpUYF1AhMbMSk2_3BELw@mail.gmail.com>
References: <CAE9uMN8t4uK=dP74z9S5tQSxFuAp0-G47ws9xEM60C3Cr-DJzg@mail.gmail.com>
	<CAM_vjukqWw8hrQ+hhMZxuRq40c_vFiqpUYF1AhMbMSk2_3BELw@mail.gmail.com>
Message-ID: <CAE9uMN-Oo5bHwzvi=QFabDH-0txE7wNMmf6RVTn0PV2SbD29kw@mail.gmail.com>

Thanks, Sarah, for response. But you showed me an example with
fuzzy_variable. I'd like to use fuzzy_partition. I also tried:

> teste = fuzzy_partition(varnames = c('a', 'b'), FUN = fuzzy_trapezoid, corners = c(1,2,3,4), height = c(1,1) )

But the trapezoids 'a' and 'b' were overlap. Is there a way to
construct two separeted trapezoids with fuzzy_partitions?

2016-08-02 12:51 GMT-03:00 Sarah Goslee <sarah.goslee at gmail.com>:
> As already discussed, yes, but you can't specify corners and height
> twice in a single call.
> Please do read the help for the functions you're interested in, and
> perhaps go back to refresh yourself on some basic R.
>
>> sets_options("universe", seq(from = 0, to = 10, by = 0.1))
>> test1 = fuzzy_variable( a = fuzzy_trapezoid( corners = c( 0, 1, 2, 3 )))
>>
>> sets_options("universe",  seq( from = 0, to = 5, by = 0.1 ))
>> test2 = fuzzy_variable( b = fuzzy_trapezoid( corners = c( 4, 5, 6, 7 )))
>>
>
> On Tue, Aug 2, 2016 at 11:14 AM, Arthur Stilben
> <arthur.stilben at gmail.com> wrote:
>> I already made this question, but I was not subscribed and not
>> received any reply. I tried this:
>>
>>> install.packages("sets")
>> ...
>>> library(sets)
>>> teste = fuzzy_partition(varnames = c('a', 'b'), FUN = fuzzy_trapezoid, corners = c(1,2,3,4), height = c(1,1), corners = c(5,6,7,8), height = c(1,1) )
>>
>> But I got this error:
>>
>> Error in FUN(i, ...) :
>>   formal argument "corners" represents multiples specified arguments
>>
>> Is it possible to combine fuzzy_partition with fuzzy_trapezoid?
>>
>> Att,
>>



-- 
Arthur Rodrigues Stilben
Geoinform?tica - LENEP
(22) 2765-6555


From marc_schwartz at me.com  Tue Aug  2 18:55:46 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 2 Aug 2016 11:55:46 -0500
Subject: [R] Regression expression to delete one or more spaces at end
	of	string
In-Reply-To: <DDE9660F-AB7E-4E18-9102-D86CD9B0AA2D@plessthan.com>
References: <DDE9660F-AB7E-4E18-9102-D86CD9B0AA2D@plessthan.com>
Message-ID: <46B6F922-E948-4ACE-85A6-DF7BBA598CEE@me.com>


> On Aug 2, 2016, at 11:46 AM, Dennis Fisher <fisher at plessthan.com> wrote:
> 
> R 3.3.1
> OS X
> 
> Colleagues, 
> 
> I have encountered an unexpected regex problem
> 
> I have read an Excel file into R using the readxl package.  Columns names are:
> 
> COLNAMES	<- c("Study ID", "Test and Biological Matrix", "Subject No. ", "Collection Date", 
> "Collection Time", "Scheduled Time Point", "Concentration", "Concentration Units", 
> "LLOQ", "ULOQ", "Comment?)
> 
> As you can see, there is a trailing space in ?Subject No. ?.  I would like to delete that space.  The following works:
> 	sub(? $?, ??, COLNAMES)
> However, I would like a more general approach that removes any trailing whitespace.
> 
> I tried variations such as:
> 	sub("[:blank:]$", "", COLNAMES)
> (also, without the $ and ?space' instead of ?blank') without success ? to my surprise, characters other than the trailing space were deleted but the trailing space remained.
> 
> Guidance on the correct syntax would be appreciated.
> 
> Dennis


Dennis, 

There is actually an example in ?gsub:

## trim trailing white space
str <- "Now is the time      "
sub(" +$", "", str)  ## spaces only

The '+' sign will match the preceding space one or more times at the end of the character string.

Note that as per ?regex, it is [:space:], not [:blank:] and the brackets need to be doubled in the regex to define the enclosing character group. An example would be:

sub("[[:space:]]+$", "", str) ## white space, POSIX-style

which is also in ?gsub.

Regards,

Marc Schwartz


From wdunlap at tibco.com  Tue Aug  2 18:57:12 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 2 Aug 2016 09:57:12 -0700
Subject: [R] Regression expression to delete one or more spaces at end
	of string
In-Reply-To: <DDE9660F-AB7E-4E18-9102-D86CD9B0AA2D@plessthan.com>
References: <DDE9660F-AB7E-4E18-9102-D86CD9B0AA2D@plessthan.com>
Message-ID: <CAF8bMcavAJwinSMMj3WMxp7T3-t8KW_m7G7vqXDkZ0WQh+DS=Q@mail.gmail.com>

First, use [[:blank:]] instead of [:blank:]. that latter matches colon, b,
l,
a, n, and k, the former whitespace.

Second, put + after [[:blank:]] to match one or more of them.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Aug 2, 2016 at 9:46 AM, Dennis Fisher <fisher at plessthan.com> wrote:

> R 3.3.1
> OS X
>
> Colleagues,
>
> I have encountered an unexpected regex problem
>
> I have read an Excel file into R using the readxl package.  Columns names
> are:
>
> COLNAMES        <- c("Study ID", "Test and Biological Matrix", "Subject
> No. ", "Collection Date",
> "Collection Time", "Scheduled Time Point", "Concentration", "Concentration
> Units",
> "LLOQ", "ULOQ", "Comment?)
>
> As you can see, there is a trailing space in ?Subject No. ?.  I would like
> to delete that space.  The following works:
>         sub(? $?, ??, COLNAMES)
> However, I would like a more general approach that removes any trailing
> whitespace.
>
> I tried variations such as:
>         sub("[:blank:]$", "", COLNAMES)
> (also, without the $ and ?space' instead of ?blank') without success ? to
> my surprise, characters other than the trailing space were deleted but the
> trailing space remained.
>
> Guidance on the correct syntax would be appreciated.
>
> Dennis
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drf at vims.edu  Tue Aug  2 19:00:36 2016
From: drf at vims.edu (David R Forrest)
Date: Tue, 2 Aug 2016 17:00:36 +0000
Subject: [R] Regression expression to delete one or more spaces at end
 of	string
In-Reply-To: <DDE9660F-AB7E-4E18-9102-D86CD9B0AA2D@plessthan.com>
References: <DDE9660F-AB7E-4E18-9102-D86CD9B0AA2D@plessthan.com>
Message-ID: <E0FF1E96-F31E-4F5E-9C1C-C3332677455B@vims.edu>

Double the [[]] and add a + for one-or-more characters: 

sub("[[:blank:]]+$", "", COLNAMES)



> On Aug 2, 2016, at 12:46 PM, Dennis Fisher <fisher at plessthan.com> wrote:
> 
> R 3.3.1
> OS X
> 
> Colleagues, 
> 
> I have encountered an unexpected regex problem
> 
> I have read an Excel file into R using the readxl package.  Columns names are:
> 
> COLNAMES	<- c("Study ID", "Test and Biological Matrix", "Subject No. ", "Collection Date", 
> "Collection Time", "Scheduled Time Point", "Concentration", "Concentration Units", 
> "LLOQ", "ULOQ", "Comment?)
> 
> As you can see, there is a trailing space in ?Subject No. ?.  I would like to delete that space.  The following works:
> 	sub(? $?, ??, COLNAMES)
> However, I would like a more general approach that removes any trailing whitespace.
> 
> I tried variations such as:
> 	sub("[:blank:]$", "", COLNAMES)
> (also, without the $ and ?space' instead of ?blank') without success ? to my surprise, characters other than the trailing space were deleted but the trailing space remained.
> 
> Guidance on the correct syntax would be appreciated.
> 
> Dennis
> 
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Dr. David Forrest
drf at vims.edu
804-684-7900w
757-968-5509h
804-413-7125c
#240 Andrews Hall
Virginia Institute of Marine Science
Route 1208, Greate Road
PO Box 1346
Gloucester Point, VA, 23062-1346











From dcarlson at tamu.edu  Tue Aug  2 19:01:40 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 2 Aug 2016 17:01:40 +0000
Subject: [R] Anderson Darling Goodness of fit test
In-Reply-To: <CANTvJZLnEBgTdp+b0ESPXj8VD1kU4YiShhvp8mg13XRVMEnqrw@mail.gmail.com>
References: <CANTvJZLnEBgTdp+b0ESPXj8VD1kU4YiShhvp8mg13XRVMEnqrw@mail.gmail.com>
Message-ID: <af802ee00a02419bac2998f76814627a@exch-2p-mbx-t2.ads.tamu.edu>

I think you did not include the other error messages you got while running your code. Package adk was removed from CRAN a while ago:

> install.packages("adk")
Warning message:
package 'adk' is not available (for R version 3.3.1)
> library(adk)
Error in library(adk) : there is no package called 'adk'

The error you included says that adk.test could not be found since the package was never installed.

There are many implementations of the Anderson Darling test. A quick search using Google turned up versions in packages nortest, kSamples, and DescTools.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of roslinazairimah zakaria
Sent: Tuesday, August 2, 2016 11:37 AM
To: r-help mailing list
Subject: [R] Anderson Darling Goodness of fit test

Dear r-users,

I would like to perform Anderson Darling Goodness of fit test as such:

install.packages("adk")
library(adk)
x3 <- list(stn_all[,1], balok_gen); x3
adk.test(x3)

#x3 <- list(jun_data1_pos,jun_gen); x3
#adk.test(x3)

However, I got this reply:

> adk.test(x3)
Error: could not find function "adk.test"


Thank you so much for any help given.

-- 
*Dr. Roslinazairimah Binti Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Deputy Dean (Academic & Student Affairs)
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Tue Aug  2 19:02:52 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 02 Aug 2016 12:02:52 -0500
Subject: [R] Anderson Darling Goodness of fit test
In-Reply-To: <CANTvJZLnEBgTdp+b0ESPXj8VD1kU4YiShhvp8mg13XRVMEnqrw@mail.gmail.com>
References: <CANTvJZLnEBgTdp+b0ESPXj8VD1kU4YiShhvp8mg13XRVMEnqrw@mail.gmail.com>
Message-ID: <D8067F2D-01F2-43BB-9BE0-FFA954B5A988@me.com>


> On Aug 2, 2016, at 11:37 AM, roslinazairimah zakaria <roslinaump at gmail.com> wrote:
> 
> Dear r-users,
> 
> I would like to perform Anderson Darling Goodness of fit test as such:
> 
> install.packages("adk")
> library(adk)
> x3 <- list(stn_all[,1], balok_gen); x3
> adk.test(x3)
> 
> #x3 <- list(jun_data1_pos,jun_gen); x3
> #adk.test(x3)
> 
> However, I got this reply:
> 
>> adk.test(x3)
> Error: could not find function "adk.test"
> 
> 
> Thank you so much for any help given.


According to CRAN:

  https://cran.r-project.org/web/packages/adk/index.html

The 'adk' package has been archived, so it is likely that you did not actually install the package and should have received an error message:

Warning message:
package ?adk? is not available (for R version 3.3.1) 

presuming that you are using the current stable release of R.

A search using http://rseek.org would suggest that the test is available in other packages on CRAN.

You may also wish to search the R-Help archives to see frequent discussions on the utility (or primarily the lack thereof) of normality tests...

Regards,

Marc Schwartz


From jdnewmil at dcn.davis.ca.us  Tue Aug  2 19:35:01 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 02 Aug 2016 10:35:01 -0700
Subject: [R] What is "args" in this function?
In-Reply-To: <CAEtAGeooez21kp+a7T=Y-2j1qe_+PBkNeX_FPonucq0PCEA7iw@mail.gmail.com>
References: <CAEtAGeooez21kp+a7T=Y-2j1qe_+PBkNeX_FPonucq0PCEA7iw@mail.gmail.com>
Message-ID: <91BB884C-8D97-490E-95E4-78A5F5B27E12@dcn.davis.ca.us>

Unfortunately for you, this email list is about R (not C), and while the Posting Guide indicates that questions discussing how to interface with C belong in R-devel, that is not a forum for learning C.

On the plus side,  the data types and macros you are asking questions about are highly specific to the implementation of R, so if you spend some time filling in your gaps in C on your own or in another forum, you ought be able to get answers to your questions on R-devel.

FWIW the R code you show does not appear (to me) to be what calls the C code you show... at least not directly. There should be a much more straightforward correspondence between the caller and callee than you imply here. 

-- 
Sent from my phone. Please excuse my brevity.

On August 2, 2016 9:06:55 AM PDT, Justin Thong <justinthong93 at gmail.com> wrote:
>Hi again I need help
>
>*R-code*
>debug(model.matrix)
>model.matrix(~S)
>
>*model.matrix code*
>ans <- .External2(C_modelmatrix, t, data) #t =terms(object) ,
>data="data
>frame of object"
>
>*modelframe C-code*
>SEXP modelframe(SEXP call, SEXP op, SEXP args, SEXP rho)
>{
>SEXP terms, data, names, variables, varnames, dots, dotnames,
>na_action;
>    SEXP ans, row_names, subset, tmp;
>    char buf[256];
>    int i, j, nr, nc;
>    int nvars, ndots, nactualdots;
>    const void *vmax = vmaxget();
>
>    args = CDR(args);
>    terms = CAR(args); args = CDR(args);
>    row_names = CAR(args); args = CDR(args);
>    variables = CAR(args); args = CDR(args);
>    varnames = CAR(args); args = CDR(args);
>    dots = CAR(args); args = CDR(args);
>    dotnames = CAR(args); args = CDR(args);
>    subset = CAR(args); args = CDR(args);
>    na_action = CAR(args);
>
>. . . .
>
>I am sorry I virtually have no experience in C.
>Can someone explain to me what "args" is at the point when it enters
>the
>function? I know CAR points to the first element of an object, and CDR
>points to the complement of the first element of an object.
>
>Does "args" represent the list of t and data?
>or
>Does "args" represent the thrid argument in .External2 which is data?
>or
>something else
>
>I am guessing this whole process of playing CAR and CDR is just a way
>of
>extracting variables from "args" until everything thing in "args" is
>assigned to.
>
>For instance, if args=(1,2,3,4,5,6) then below correspond in square
>brackets
>
>  args = CDR(args); [(1,2,3,4,5,6)]
>  terms = CAR(args) ;[(1)] args = CDR(args);[(2,3,4,5,6)]
>    row_names = CAR(args);[(2)] args = CDR(args);[(3,4,5,6)]
>    variables = CAR(args);[(3)] args = CDR(args);[(4,5,6)]
>    varnames = CAR(args);[(4)] args = CDR(args);[(5,6)]
>   etc
>
>Is this correct?
>
>I am sorry if I am asking too many questions on C. Please advise if I
>am
>posting inappropriately.


From chocold12 at gmail.com  Tue Aug  2 20:10:26 2016
From: chocold12 at gmail.com (lily li)
Date: Tue, 2 Aug 2016 12:10:26 -0600
Subject: [R] how to plot annual values directly
Message-ID: <CAN5afy_VJ1g0ONe4c=_J8bO9DhCBKHkpdT8iy5sdA8+U+2Jsrg@mail.gmail.com>

Hi R users,

I have a dataframe, with daily precipitation data, is it possible to plot
annual mean or annual sum values directly? Thanks for your help.

df
year   month   day   precip       time
2010     1          1        0.5     2010-01-01
2010     1          2        0.8     2010-01-02
2010     1          3        1.0     2010-01-03
2010     1          4        0.9     2010-01-04
...

fig1 = ggplot()+ geom_path(data=df, aes(x=time, y= precip)
show(fig1)

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Tue Aug  2 20:50:41 2016
From: chocold12 at gmail.com (lily li)
Date: Tue, 2 Aug 2016 12:50:41 -0600
Subject: [R] plot many dfs in ggplot
Message-ID: <CAN5afy_de9kE8N+GiM+wN0HGryYdd=gNkb-Eh1=17yxdc6y5ng@mail.gmail.com>

Hi all,

I have another question. There are several dataframes, each has the same
columns: time, varA, varB, varC, etc. If I want to plot time ~ varA of each
dataframe, where different dataframe names use different colors. How to do
this in ggplot? Thanks for your help.

Right now, I tried to use the code below, but very laborious, and needs
colors manually.

fig1 = ggplot()+
    geom_path(data=df1, aes(x=time, y= varA, color= 'df1'))+
    geom_path(data=df2, aes(x=time, y= varA, color= 'df2'))+
    geom_path(data=df3, aes(x=time, y= varA, color= 'df3'))+
    ...
    scale_color_manual('', limits=c('df1', 'df2', 'df3', ...),
values=c('blue', red', 'green', ...))
show(fig1)

	[[alternative HTML version deleted]]


From oriolebaltimore at gmail.com  Tue Aug  2 20:56:35 2016
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Tue, 2 Aug 2016 14:56:35 -0400
Subject: [R] generate a vector of random numbers within confines of certain
	parameters
Message-ID: <CAL2fYnMFX6OBj7Lms5--NHT489eS+pLZBHcPdF-bzSDTPHKDyA@mail.gmail.com>

Dear group,

I am trying to generate a vector of random numbers for 20K observation.

however, I want to generate numbers (with 6 decimal places) within the range of
Std. Dev : 2-3
mean  : 4-6

Is there a method to generate numbers with 6 decimal places under
these parameters

thank you.
Adrian


From dcarlson at tamu.edu  Tue Aug  2 21:39:40 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 2 Aug 2016 19:39:40 +0000
Subject: [R] generate a vector of random numbers within confines of
 certain	parameters
In-Reply-To: <CAL2fYnMFX6OBj7Lms5--NHT489eS+pLZBHcPdF-bzSDTPHKDyA@mail.gmail.com>
References: <CAL2fYnMFX6OBj7Lms5--NHT489eS+pLZBHcPdF-bzSDTPHKDyA@mail.gmail.com>
Message-ID: <3e64db1f99ce45a1859443137bc16eee@exch-2p-mbx-t2.ads.tamu.edu>

Try

> set.seed(42)
> x1 <- round(rnorm(20000, 4, 2), 6)
> head(x1)
[1] 6.741917 2.870604 4.726257 5.265725 4.808537 3.787751

Setting the seed makes the sequence reproducible, but if that is not important, you can leave it out. This assumes you want a normal distribution and you want to specify the mean and standard deviation. If you want those to be selected randomly. The following does that using uniform distributions so each mean and standard deviation is equally likely within the range:

> x2 <- round(rnorm(20000, runif(1, 4, 6), runif(1, 2, 3)), 6)
> head(x2)
[1] 4.054289 4.745569 5.795536 6.316750 4.370713 5.586646

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Adrian Johnson
Sent: Tuesday, August 2, 2016 1:57 PM
To: r-help
Subject: [R] generate a vector of random numbers within confines of certain parameters

Dear group,

I am trying to generate a vector of random numbers for 20K observation.

however, I want to generate numbers (with 6 decimal places) within the range of
Std. Dev : 2-3
mean  : 4-6

Is there a method to generate numbers with 6 decimal places under
these parameters

thank you.
Adrian

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Tue Aug  2 21:48:11 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 2 Aug 2016 19:48:11 +0000
Subject: [R] generate a vector of random numbers within confines of
 certain	parameters
In-Reply-To: <3e64db1f99ce45a1859443137bc16eee@exch-2p-mbx-t2.ads.tamu.edu>
References: <CAL2fYnMFX6OBj7Lms5--NHT489eS+pLZBHcPdF-bzSDTPHKDyA@mail.gmail.com>
	<3e64db1f99ce45a1859443137bc16eee@exch-2p-mbx-t2.ads.tamu.edu>
Message-ID: <bddbd52125f445699cedbee23eaa06b7@exch-2p-mbx-t2.ads.tamu.edu>

The second one (x2) uses the same mean/sd for the 20000 variates. If you want to change the mean/sd for each variate:

> x3 <- round(replicate(20000, rnorm(1, runif(1, 4, 6), runif(1, 2, 3))), 6)
> head(x3)
[1] 5.648530 5.689563 2.945512 3.915723 8.527447 0.298535

-------
David C

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
Sent: Tuesday, August 2, 2016 2:40 PM
To: Adrian Johnson; r-help
Subject: Re: [R] generate a vector of random numbers within confines of certain parameters

Try

> set.seed(42)
> x1 <- round(rnorm(20000, 4, 2), 6)
> head(x1)
[1] 6.741917 2.870604 4.726257 5.265725 4.808537 3.787751

Setting the seed makes the sequence reproducible, but if that is not important, you can leave it out. This assumes you want a normal distribution and you want to specify the mean and standard deviation. If you want those to be selected randomly. The following does that using uniform distributions so each mean and standard deviation is equally likely within the range:

> x2 <- round(rnorm(20000, runif(1, 4, 6), runif(1, 2, 3)), 6)
> head(x2)
[1] 4.054289 4.745569 5.795536 6.316750 4.370713 5.586646

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Adrian Johnson
Sent: Tuesday, August 2, 2016 1:57 PM
To: r-help
Subject: [R] generate a vector of random numbers within confines of certain parameters

Dear group,

I am trying to generate a vector of random numbers for 20K observation.

however, I want to generate numbers (with 6 decimal places) within the range of
Std. Dev : 2-3
mean  : 4-6

Is there a method to generate numbers with 6 decimal places under
these parameters

thank you.
Adrian

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From suparna.mitra.sm at gmail.com  Tue Aug  2 21:58:05 2016
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Tue, 2 Aug 2016 20:58:05 +0100
Subject: [R] Three way correspondence analyses?
Message-ID: <CAFdg=fXxfR+26m1gR5fcNyLsadDvbsxkngcrGjaS4pHwhHGuzA@mail.gmail.com>

Hello R experts,
   have some data for microbiome, metabolome and cytokine from the same
sample. Now I want to do a three-way correspondence analyses. From three
normalised data I was trying,
#Now CCA

with two data it works good like:
Metab.Cytok.Microb.cca <- cca(normMicrobiome_NEC,normCytok_and_ProInf)
 plot(Metab.Cytok.Microb.cca )
Metab.Cytok.Microb.cca <- cca(normMicrobiome_NEC,normMetab_NEC)
plot(Metab.Cytok.Microb.cca )

But when I tried with three
Metab.Cytok.Microb.cca <-
cca(normMicrobiome_NEC,normMetab_NEC,normCytok_and_ProInf)
plot(Metab.Cytok.Microb.cca )
But this is not displaying all three variables.
Sorry, I am very new in this. Can anybody please help me?
Thanks a lot,
Mitra

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Aug  2 22:08:16 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 02 Aug 2016 13:08:16 -0700
Subject: [R] generate a vector of random numbers within confines of
	certain	parameters
In-Reply-To: <CAL2fYnMFX6OBj7Lms5--NHT489eS+pLZBHcPdF-bzSDTPHKDyA@mail.gmail.com>
References: <CAL2fYnMFX6OBj7Lms5--NHT489eS+pLZBHcPdF-bzSDTPHKDyA@mail.gmail.com>
Message-ID: <D62AFCF7-9237-40EB-8983-E379CB886625@dcn.davis.ca.us>

x <- rnorm( 20000, 5, 2.5 )

The requirement for "random" is ill-specified because it omits mention of which random distribution you want (I assumed normal distribution above).

The requirement for "decimal places" is ill-defined because floating point numbers are internally represented with mantissa and exponent ("scientific notation"), so large numbers have fewer significant "decimal places" in the fraction than small numbers do. For most purposes double precision IEEE754 numbers have more precision than you will need. What gets sticky is if you want to LIMIT the number of decimals... you may need to use the sprintf function and export the data as character values if that is important (which I doubt).

Note that the default behavior of the R console is to PRINT values with four decimals, but the rest of the significant digits are really still there. 
-- 
Sent from my phone. Please excuse my brevity.

On August 2, 2016 11:56:35 AM PDT, Adrian Johnson <oriolebaltimore at gmail.com> wrote:
>Dear group,
>
>I am trying to generate a vector of random numbers for 20K observation.
>
>however, I want to generate numbers (with 6 decimal places) within the
>range of
>Std. Dev : 2-3
>mean  : 4-6
>
>Is there a method to generate numbers with 6 decimal places under
>these parameters
>
>thank you.
>Adrian
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Aug  2 23:01:43 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 2 Aug 2016 14:01:43 -0700
Subject: [R] generate a vector of random numbers within confines of
 certain parameters
In-Reply-To: <CAL2fYnMFX6OBj7Lms5--NHT489eS+pLZBHcPdF-bzSDTPHKDyA@mail.gmail.com>
References: <CAL2fYnMFX6OBj7Lms5--NHT489eS+pLZBHcPdF-bzSDTPHKDyA@mail.gmail.com>
Message-ID: <CAGxFJbTm1Zj9oiqpv2pone4ReHqrCQP-JXcwQxYLX==G9ds66Q@mail.gmail.com>

All floating point operations are done to machine precision -- roughly
16 digits. See ?.Machine . You can choose to round, truncate, or
display to anything less than that that you care to. See also the
digits parameter of  ?options

The rest of your post is ambiguous to me. But note that (all?/most?)
rng's are vectorized, so e.g.

> set.seed(1123)

> rnorm(10,mean= runif(10,2,3), sd = runif(10,4,6))

 [1]  4.369411  1.944876  3.143913  6.489048 -1.093468  1.330675
-3.936239 11.740755
 [9] -2.260413 -1.748759

... if that's what you meant.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 2, 2016 at 11:56 AM, Adrian Johnson
<oriolebaltimore at gmail.com> wrote:
> Dear group,
>
> I am trying to generate a vector of random numbers for 20K observation.
>
> however, I want to generate numbers (with 6 decimal places) within the range of
> Std. Dev : 2-3
> mean  : 4-6
>
> Is there a method to generate numbers with 6 decimal places under
> these parameters
>
> thank you.
> Adrian
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Wed Aug  3 00:21:16 2016
From: chocold12 at gmail.com (lily li)
Date: Tue, 2 Aug 2016 16:21:16 -0600
Subject: [R] plot many dfs in ggplot
In-Reply-To: <CAN5afy_de9kE8N+GiM+wN0HGryYdd=gNkb-Eh1=17yxdc6y5ng@mail.gmail.com>
References: <CAN5afy_de9kE8N+GiM+wN0HGryYdd=gNkb-Eh1=17yxdc6y5ng@mail.gmail.com>
Message-ID: <CAN5afy81J-G=sDLiApf8ygn4Wa294cX+x2d=oGc3rPTBvoLYmw@mail.gmail.com>

Another question is, if I want to shade the range between the maximum and
minimum values for daily or annual values, how to do it? Thanks again.


On Tue, Aug 2, 2016 at 12:50 PM, lily li <chocold12 at gmail.com> wrote:

> Hi all,
>
> I have another question. There are several dataframes, each has the same
> columns: time, varA, varB, varC, etc. If I want to plot time ~ varA of each
> dataframe, where different dataframe names use different colors. How to do
> this in ggplot? Thanks for your help.
>
> Right now, I tried to use the code below, but very laborious, and needs
> colors manually.
>
> fig1 = ggplot()+
>     geom_path(data=df1, aes(x=time, y= varA, color= 'df1'))+
>     geom_path(data=df2, aes(x=time, y= varA, color= 'df2'))+
>     geom_path(data=df3, aes(x=time, y= varA, color= 'df3'))+
>     ...
>     scale_color_manual('', limits=c('df1', 'df2', 'df3', ...),
> values=c('blue', red', 'green', ...))
> show(fig1)
>
>
>

	[[alternative HTML version deleted]]


From roslinaump at gmail.com  Wed Aug  3 01:34:24 2016
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Wed, 3 Aug 2016 07:34:24 +0800
Subject: [R] Anderson Darling Goodness of fit test
In-Reply-To: <af802ee00a02419bac2998f76814627a@exch-2p-mbx-t2.ads.tamu.edu>
References: <CANTvJZLnEBgTdp+b0ESPXj8VD1kU4YiShhvp8mg13XRVMEnqrw@mail.gmail.com>
	<af802ee00a02419bac2998f76814627a@exch-2p-mbx-t2.ads.tamu.edu>
Message-ID: <CANTvJZJiRn9XEff12roEQLANWosa7dhv9asjRqe-O0AhZ8VaTQ@mail.gmail.com>

Hi david,

I will try again. Thank you..

On Wed, Aug 3, 2016 at 1:01 AM, David L Carlson <dcarlson at tamu.edu> wrote:

> I think you did not include the other error messages you got while running
> your code. Package adk was removed from CRAN a while ago:
>
> > install.packages("adk")
> Warning message:
> package 'adk' is not available (for R version 3.3.1)
> > library(adk)
> Error in library(adk) : there is no package called 'adk'
>
> The error you included says that adk.test could not be found since the
> package was never installed.
>
> There are many implementations of the Anderson Darling test. A quick
> search using Google turned up versions in packages nortest, kSamples, and
> DescTools.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> roslinazairimah zakaria
> Sent: Tuesday, August 2, 2016 11:37 AM
> To: r-help mailing list
> Subject: [R] Anderson Darling Goodness of fit test
>
> Dear r-users,
>
> I would like to perform Anderson Darling Goodness of fit test as such:
>
> install.packages("adk")
> library(adk)
> x3 <- list(stn_all[,1], balok_gen); x3
> adk.test(x3)
>
> #x3 <- list(jun_data1_pos,jun_gen); x3
> #adk.test(x3)
>
> However, I got this reply:
>
> > adk.test(x3)
> Error: could not find function "adk.test"
>
>
> Thank you so much for any help given.
>
> --
> *Dr. Roslinazairimah Binti Zakaria*
> *Tel: +609-5492370; Fax. No.+609-5492766*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Deputy Dean (Academic & Student Affairs)
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
*Dr. Roslinazairimah Binti Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Deputy Dean (Academic & Student Affairs)
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From roslinaump at gmail.com  Wed Aug  3 01:34:44 2016
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Wed, 3 Aug 2016 07:34:44 +0800
Subject: [R] Anderson Darling Goodness of fit test
In-Reply-To: <D8067F2D-01F2-43BB-9BE0-FFA954B5A988@me.com>
References: <CANTvJZLnEBgTdp+b0ESPXj8VD1kU4YiShhvp8mg13XRVMEnqrw@mail.gmail.com>
	<D8067F2D-01F2-43BB-9BE0-FFA954B5A988@me.com>
Message-ID: <CANTvJZKUTbeJX-MHEQKZs6+y9fT8WBfz2Uzyh6JJOczw8z2Kjw@mail.gmail.com>

Hi Marc,

I will try again. Thank you.

On Wed, Aug 3, 2016 at 1:02 AM, Marc Schwartz <marc_schwartz at me.com> wrote:

>
> > On Aug 2, 2016, at 11:37 AM, roslinazairimah zakaria <
> roslinaump at gmail.com> wrote:
> >
> > Dear r-users,
> >
> > I would like to perform Anderson Darling Goodness of fit test as such:
> >
> > install.packages("adk")
> > library(adk)
> > x3 <- list(stn_all[,1], balok_gen); x3
> > adk.test(x3)
> >
> > #x3 <- list(jun_data1_pos,jun_gen); x3
> > #adk.test(x3)
> >
> > However, I got this reply:
> >
> >> adk.test(x3)
> > Error: could not find function "adk.test"
> >
> >
> > Thank you so much for any help given.
>
>
> According to CRAN:
>
>   https://cran.r-project.org/web/packages/adk/index.html
>
> The 'adk' package has been archived, so it is likely that you did not
> actually install the package and should have received an error message:
>
> Warning message:
> package ?adk? is not available (for R version 3.3.1)
>
> presuming that you are using the current stable release of R.
>
> A search using http://rseek.org would suggest that the test is available
> in other packages on CRAN.
>
> You may also wish to search the R-Help archives to see frequent
> discussions on the utility (or primarily the lack thereof) of normality
> tests...
>
> Regards,
>
> Marc Schwartz
>
>
>


-- 
*Dr. Roslinazairimah Binti Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Deputy Dean (Academic & Student Affairs)
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From roslinaump at gmail.com  Wed Aug  3 07:44:16 2016
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Wed, 3 Aug 2016 13:44:16 +0800
Subject: [R] Multiple plot in a page
Message-ID: <CANTvJZLWtOEyq6qV1ZovSz3F-6DOtiur5r1Um7oejh+iJUyJyQ@mail.gmail.com>

Dear r-users,

I would like to plot 4 graphs arranged as 2 by 2 and follows are my codes.
However, it only shows one graph.

par(mfrow=c(1,2))

par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")  ## To control
white space around and between the plots
hist(stn_all[,1],prob=TRUE, main ="Balok ",col="yellowgreen", cex.axis=1.2,
xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
xlim=c(0,1200))
lines(x, dgam1,col="red",lwd=3)
legend("topright", legend = c("observed","fitted"),
       col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
       lwd=c(0,3),bty="n", pt.cex=2)
text(100,.012 , expression(paste(beta==64.64)))
box()

par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")  ## To control
white space around and between the plots
hist(stn_all[,2],prob=TRUE, main ="Gambang ",col="yellowgreen",
cex.axis=1.2,
xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
xlim=c(0,1200))
lines(x, dgam2,col="red",lwd=3)
legend("topright", legend = c("observed","fitted"),
       col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
       lwd=c(0,3),bty="n", pt.cex=2)
text(100,.012 , expression(paste(beta==64.64)))
box()


Thank you for your help.

-- 
*Dr. Roslinazairimah Binti Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Deputy Dean (Academic & Student Affairs)
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Aug  3 10:55:56 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 3 Aug 2016 18:55:56 +1000
Subject: [R] Multiple plot in a page
In-Reply-To: <CANTvJZLWtOEyq6qV1ZovSz3F-6DOtiur5r1Um7oejh+iJUyJyQ@mail.gmail.com>
References: <CANTvJZLWtOEyq6qV1ZovSz3F-6DOtiur5r1Um7oejh+iJUyJyQ@mail.gmail.com>
Message-ID: <CA+8X3fU6dEZ7UxnDC_UC7JmYFJ2ipxbZgO0sXNzFr5jcsF=ObQ@mail.gmail.com>

Hi Roslina,
You only specify space for two plots in:

par(mfrow=c(1,2))

However, you only try to plot two plots, so I will assume that you
only want two. You haven't defined "x" in the above code, which will
cause an error. The code below gives me two plots as I would expect (I
made up the data that you didn't supply).

par(mfrow=c(1,2))
stn_all<-matrix(400*rnorm(20)+4,ncol=2)
par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")
hist(stn_all[,1],prob=TRUE, main ="Balok ",col="yellowgreen", cex.axis=1.2,
xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
xlim=c(0,1200))
x<-c(400,600,800,1000)
dgam1<-(rnorm(4)+4)/2000
lines(x, dgam1,col="red",lwd=3)
legend("topright", legend = c("observed","fitted"),
       col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
       lwd=c(0,3),bty="n", pt.cex=2)
text(100,.012 , expression(paste(beta==64.64)))
box()

par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")
hist(stn_all[,2],prob=TRUE, main ="Gambang ",col="yellowgreen",
cex.axis=1.2,
xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
xlim=c(0,1200))
dgam2<-(rnorm(4)+4)/2000
lines(x, dgam2,col="red",lwd=3)
legend("topright", legend = c("observed","fitted"),
       col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
       lwd=c(0,3),bty="n", pt.cex=2)
text(100,.012 , expression(paste(beta==64.64)))
box()

Jim


On Wed, Aug 3, 2016 at 3:44 PM, roslinazairimah zakaria
<roslinaump at gmail.com> wrote:
> Dear r-users,
>
> I would like to plot 4 graphs arranged as 2 by 2 and follows are my codes.
> However, it only shows one graph.
>
> par(mfrow=c(1,2))
>
> par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")  ## To control
> white space around and between the plots
> hist(stn_all[,1],prob=TRUE, main ="Balok ",col="yellowgreen", cex.axis=1.2,
> xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
> xlim=c(0,1200))
> lines(x, dgam1,col="red",lwd=3)
> legend("topright", legend = c("observed","fitted"),
>        col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
>        lwd=c(0,3),bty="n", pt.cex=2)
> text(100,.012 , expression(paste(beta==64.64)))
> box()
>
> par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")  ## To control
> white space around and between the plots
> hist(stn_all[,2],prob=TRUE, main ="Gambang ",col="yellowgreen",
> cex.axis=1.2,
> xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
> xlim=c(0,1200))
> lines(x, dgam2,col="red",lwd=3)
> legend("topright", legend = c("observed","fitted"),
>        col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
>        lwd=c(0,3),bty="n", pt.cex=2)
> text(100,.012 , expression(paste(beta==64.64)))
> box()
>
>
> Thank you for your help.
>
> --
> *Dr. Roslinazairimah Binti Zakaria*
> *Tel: +609-5492370; Fax. No.+609-5492766*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Deputy Dean (Academic & Student Affairs)
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Wed Aug  3 11:33:42 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 3 Aug 2016 10:33:42 +0100
Subject: [R] Multiple plot in a page
In-Reply-To: <CANTvJZLWtOEyq6qV1ZovSz3F-6DOtiur5r1Um7oejh+iJUyJyQ@mail.gmail.com>
References: <CANTvJZLWtOEyq6qV1ZovSz3F-6DOtiur5r1Um7oejh+iJUyJyQ@mail.gmail.com>
Message-ID: <d26401e5-1bbf-724d-ee13-ac2457c3f2bc@dewey.myzen.co.uk>

Dear Rosalina

I do not think par(mfrow(c(1, 2)) does what you think it does although 
mfrow(c(2, 2)) might.

You could consider using layout() instead

On 03/08/2016 06:44, roslinazairimah zakaria wrote:
> Dear r-users,
>
> I would like to plot 4 graphs arranged as 2 by 2 and follows are my codes.
> However, it only shows one graph.
>
> par(mfrow=c(1,2))
>
> par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")  ## To control
> white space around and between the plots
> hist(stn_all[,1],prob=TRUE, main ="Balok ",col="yellowgreen", cex.axis=1.2,
> xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
> xlim=c(0,1200))
> lines(x, dgam1,col="red",lwd=3)
> legend("topright", legend = c("observed","fitted"),
>        col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
>        lwd=c(0,3),bty="n", pt.cex=2)
> text(100,.012 , expression(paste(beta==64.64)))
> box()
>
> par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")  ## To control
> white space around and between the plots
> hist(stn_all[,2],prob=TRUE, main ="Gambang ",col="yellowgreen",
> cex.axis=1.2,
> xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
> xlim=c(0,1200))
> lines(x, dgam2,col="red",lwd=3)
> legend("topright", legend = c("observed","fitted"),
>        col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
>        lwd=c(0,3),bty="n", pt.cex=2)
> text(100,.012 , expression(paste(beta==64.64)))
> box()
>
>
> Thank you for your help.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From alicia.m.ellis at gmail.com  Tue Aug  2 21:36:08 2016
From: alicia.m.ellis at gmail.com (Alicia Ellis)
Date: Tue, 2 Aug 2016 15:36:08 -0400
Subject: [R] p.adjust not working correctly?
Message-ID: <CAPUn7Bc0xvLLX95w+QG5Ok9wpdwrz6tNc73E3UkAq5_xb31t+g@mail.gmail.com>

p.adjust for bonferroni p value correction does not appear to be working
correctly:

> p <- runif(50)
>
> p
 [1] 0.08280254 0.08955706 0.19754389 0.52812033 0.68907772 0.21849696
0.02774784 0.23923562 0.03482480 0.76437481 0.87236155 0.76438604
[13] 0.37432032 0.89630318 0.01626565 0.08152060 0.55715478 0.47736921
0.77968275 0.17388127 0.37212900 0.18363170 0.51655538 0.14526733
[25] 0.60870820 0.13752392 0.92412799 0.73045115 0.89887453 0.33744577
0.84966571 0.97797283 0.20571554 0.29115022 0.75928867 0.12929511
[37] 0.64923057 0.68168196 0.19311014 0.83818106 0.85592243 0.56276287
0.80822911 0.53377044 0.44691466 0.59198417 0.36114259 0.35431768
[49] 0.10381694 0.57738429

> p.adjust(p, method = "bonferroni", n=50)
 [1] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
[15] 0.8132824 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
[29] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
[43] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
1.0000000

for the one corrected pvalue that is less than 1, it seems to have been
divided by 0.02 and not 50.

I can do this one manually but would be nice if it worked:)

	[[alternative HTML version deleted]]


From guillermo.olmedo at gmail.com  Tue Aug  2 00:35:06 2016
From: guillermo.olmedo at gmail.com (Guillermo Federico Olmedo)
Date: Mon, 1 Aug 2016 19:35:06 -0300
Subject: [R] [R-pkgs] new version of package water: Actual
 Evapotranspiration with Energy Balance Models
Message-ID: <CABOAaB1FnDL8BHDA0TRArwaxFqsADKNKF5bBKsKvWtw+MRx54A@mail.gmail.com>

Dear R users,

I'm glad to announce the new version of water package (0.5).

As this is my first message to the list, I want to add that this
package provides tools to estimate actual evapotranspiration from
surface energy balance models.

Right now you can run the well-know METRIC model using it. This model
allows to estimate the energy balance using landsat (7 or 5) images
and a weather station.

I'll be happy to discuss or provide more information.

Regards,

Guillermo.

#########################

The changes since the last version are:

* Added maxit parameter to calcH to control the maximun number of iterations.
* Added an optional constrain to the selection of anchors pixels using the
  location of the weather station and a 30km buffer.
* Changed default value for Z.om.ws in calcH. (From 0.0018 to 0.03)
* Added a new parameter to calcAnchors, available for both methods: buffer.
  buffer allow to set the minimun distance between two anchor pixels of the same
  kind
* Added a new method for calcAnchors = "CITRA-MCBbc". This method chooses the
  coldest and hottest anchors pixels availables. Previous method ("CITRA-MCBr")
  chooses random pixel who meets the conditions. CITRA-MCBbc is now the default
  method for calcAnchors
* General remote sensing functions moved to a separate file
* loadImage detects when there is more than 1 image on the working folder
* Rn, G, H, LE are restricted to values > 0
* Improvements to anchors pixels selection: more releaxed hot
  temperature criterium, distance, mean of many pixels, etc
* Added two methods for land surface estimation: single channel and
split windows.
  Split windows only works for Landsat 8.
* loadImage now loads thermal data also: low gain for L7 and both bands for L8
* Fixed big bug when estimating ETo with a large weather station file

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From martiv at qio.uji.es  Wed Aug  3 10:57:11 2016
From: martiv at qio.uji.es (=?UTF-8?Q?Vicente_Mart=C3=AD_Centelles?=)
Date: Wed, 3 Aug 2016 09:57:11 +0100
Subject: [R] It is possible to use "input parameters" with "standard error"
 in fitting function nls
Message-ID: <CAEcPzfBs-2d7rEjQ+v3CF2-1FZQA9wkSnQ9tL2F9M91ygfBEGA@mail.gmail.com>

Dear all,

I would like to introduce an input parameter with an associated standard
error to perform a fitting using the nls function (or any similar function):

parameter1 = 9.00 +/- 0.20  (parameter 1 has a value of 9.00 and standard
error of 0.20)

fittingResults <- nls(y ~ function(xdata, ydata, parameter1,
fittingparameter),start=list(parameter1=9.00, fittingparameter=5.00))
summary(fittingResults)

Does anyone know how to  introduce the associated standard error of the
parameter to the fitting function?

Many thanks for your help,

Best regards

Vicente


-- 
_______________________________________
*Dr. Vicente Mart? Centelles*
*Postdoctoral Researcher (VALi+d Generalitat Valenciana, Spain)*


*Universitat Jaume I*Departamento de Qu?mica Inorg?nica y Org?nica
Avda Sos Baynat s/n
E-12071-Castell?n (Spain)
Tel.: +34 964728235
Fax: +34 964728214
e-mail: martiv at qio.uji.es

*web page*: www.vmarti.es

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Aug  3 12:16:08 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 3 Aug 2016 10:16:08 +0000
Subject: [R] how to plot annual values directly
In-Reply-To: <CAN5afy_VJ1g0ONe4c=_J8bO9DhCBKHkpdT8iy5sdA8+U+2Jsrg@mail.gmail.com>
References: <CAN5afy_VJ1g0ONe4c=_J8bO9DhCBKHkpdT8iy5sdA8+U+2Jsrg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5037A4F@SRVEXCHMBX.precheza.cz>

Hi

What do you mean to plot annual mean/sum directly? You can compute it by aggregate function and add it to your plot, but I am not sure if it is enough direct.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
> Sent: Tuesday, August 2, 2016 8:10 PM
> To: R mailing list <r-help at r-project.org>
> Subject: [R] how to plot annual values directly
>
> Hi R users,
>
> I have a dataframe, with daily precipitation data, is it possible to plot annual
> mean or annual sum values directly? Thanks for your help.
>
> df
> year   month   day   precip       time
> 2010     1          1        0.5     2010-01-01
> 2010     1          2        0.8     2010-01-02
> 2010     1          3        1.0     2010-01-03
> 2010     1          4        0.9     2010-01-04
> ...
>
> fig1 = ggplot()+ geom_path(data=df, aes(x=time, y= precip)
> show(fig1)
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Wed Aug  3 12:20:16 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 3 Aug 2016 10:20:16 +0000
Subject: [R] plot many dfs in ggplot
In-Reply-To: <CAN5afy_de9kE8N+GiM+wN0HGryYdd=gNkb-Eh1=17yxdc6y5ng@mail.gmail.com>
References: <CAN5afy_de9kE8N+GiM+wN0HGryYdd=gNkb-Eh1=17yxdc6y5ng@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5037A62@SRVEXCHMBX.precheza.cz>

Hi.

Hm. I would add a column indicating data frame and merge/rbind all data frames.

Something like

df1$fr <- 1
df2$fr <- 2

dfkompl <- rbind(df1, df2)

ggplot(dfkompl, aes(x=time, y=varA, colour=factor(fr))

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
> Sent: Tuesday, August 2, 2016 8:51 PM
> To: R mailing list <r-help at r-project.org>
> Subject: [R] plot many dfs in ggplot
>
> Hi all,
>
> I have another question. There are several dataframes, each has the same
> columns: time, varA, varB, varC, etc. If I want to plot time ~ varA of each
> dataframe, where different dataframe names use different colors. How to
> do this in ggplot? Thanks for your help.
>
> Right now, I tried to use the code below, but very laborious, and needs colors
> manually.
>
> fig1 = ggplot()+
>     geom_path(data=df1, aes(x=time, y= varA, color= 'df1'))+
>     geom_path(data=df2, aes(x=time, y= varA, color= 'df2'))+
>     geom_path(data=df3, aes(x=time, y= varA, color= 'df3'))+
>     ...
>     scale_color_manual('', limits=c('df1', 'df2', 'df3', ...), values=c('blue', red',
> 'green', ...))
> show(fig1)
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From S.Ellison at LGCGroup.com  Wed Aug  3 13:05:24 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 3 Aug 2016 12:05:24 +0100
Subject: [R] p.adjust not working correctly?
In-Reply-To: <CAPUn7Bc0xvLLX95w+QG5Ok9wpdwrz6tNc73E3UkAq5_xb31t+g@mail.gmail.com>
References: <CAPUn7Bc0xvLLX95w+QG5Ok9wpdwrz6tNc73E3UkAq5_xb31t+g@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403F0F2643D@GBTEDVPEXCMB04.corp.lgc-group.com>

> p.adjust for bonferroni p value correction does not appear to be working
> correctly:
You should re-check what a Bonferroni correction does, or at least reboot your intuition (mine needs rebooting all the time). All the p-values should _increase_ by a factor of n, with a ceiling of 1.0. Dividing by n would imply incorrectly that individual events have become less probable as the number increases.

The result you have obtained is what is supposed to happen.

S Ellison

> > p <- runif(50)
> >
> > p
>  [1] 0.08280254 0.08955706 0.19754389 0.52812033 0.68907772 0.21849696
> 0.02774784 0.23923562 0.03482480 0.76437481 0.87236155 0.76438604 [13]
> 0.37432032 0.89630318 0.01626565 0.08152060 0.55715478 0.47736921
> 0.77968275 0.17388127 0.37212900 0.18363170 0.51655538 0.14526733 [25]
> 0.60870820 0.13752392 0.92412799 0.73045115 0.89887453 0.33744577
> 0.84966571 0.97797283 0.20571554 0.29115022 0.75928867 0.12929511 [37]
> 0.64923057 0.68168196 0.19311014 0.83818106 0.85592243 0.56276287
> 0.80822911 0.53377044 0.44691466 0.59198417 0.36114259 0.35431768 [49]
> 0.10381694 0.57738429
> 
> > p.adjust(p, method = "bonferroni", n=50)
>  [1] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
> 1.0000000
> 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
> [15] 0.8132824 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
> 1.0000000
> 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
> [29] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
> 1.0000000
> 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
> [43] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
> 1.0000000
> 1.0000000
> 
> for the one corrected pvalue that is less than 1, it seems to have been divided
> by 0.02 and not 50.
> 
> I can do this one manually but would be nice if it worked:)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From roslinaump at gmail.com  Wed Aug  3 14:01:15 2016
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Wed, 3 Aug 2016 20:01:15 +0800
Subject: [R] Multiple plot in a page
In-Reply-To: <CA+8X3fU6dEZ7UxnDC_UC7JmYFJ2ipxbZgO0sXNzFr5jcsF=ObQ@mail.gmail.com>
References: <CANTvJZLWtOEyq6qV1ZovSz3F-6DOtiur5r1Um7oejh+iJUyJyQ@mail.gmail.com>
	<CA+8X3fU6dEZ7UxnDC_UC7JmYFJ2ipxbZgO0sXNzFr5jcsF=ObQ@mail.gmail.com>
Message-ID: <CANTvJZLz168F0_DN9swf9SAv02fHqM7a1R5TUCbSnFKbn1ic3g@mail.gmail.com>

Hi Jim,

I tried your code, however it still gives me only one plot.  I don't
understand what is going on.  Any clue?

On Wed, Aug 3, 2016 at 4:55 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Roslina,
> You only specify space for two plots in:
>
> par(mfrow=c(1,2))
>
> However, you only try to plot two plots, so I will assume that you
> only want two. You haven't defined "x" in the above code, which will
> cause an error. The code below gives me two plots as I would expect (I
> made up the data that you didn't supply).
>
> par(mfrow=c(1,2))
> stn_all<-matrix(400*rnorm(20)+4,ncol=2)
> par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")
> hist(stn_all[,1],prob=TRUE, main ="Balok ",col="yellowgreen", cex.axis=1.2,
> xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
> xlim=c(0,1200))
> x<-c(400,600,800,1000)
> dgam1<-(rnorm(4)+4)/2000
> lines(x, dgam1,col="red",lwd=3)
> legend("topright", legend = c("observed","fitted"),
>        col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
>        lwd=c(0,3),bty="n", pt.cex=2)
> text(100,.012 , expression(paste(beta==64.64)))
> box()
>
> par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")
> hist(stn_all[,2],prob=TRUE, main ="Gambang ",col="yellowgreen",
> cex.axis=1.2,
> xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
> xlim=c(0,1200))
> dgam2<-(rnorm(4)+4)/2000
> lines(x, dgam2,col="red",lwd=3)
> legend("topright", legend = c("observed","fitted"),
>        col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
>        lwd=c(0,3),bty="n", pt.cex=2)
> text(100,.012 , expression(paste(beta==64.64)))
> box()
>
> Jim
>
>
> On Wed, Aug 3, 2016 at 3:44 PM, roslinazairimah zakaria
> <roslinaump at gmail.com> wrote:
> > Dear r-users,
> >
> > I would like to plot 4 graphs arranged as 2 by 2 and follows are my
> codes.
> > However, it only shows one graph.
> >
> > par(mfrow=c(1,2))
> >
> > par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")  ## To control
> > white space around and between the plots
> > hist(stn_all[,1],prob=TRUE, main ="Balok ",col="yellowgreen",
> cex.axis=1.2,
> > xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
> > xlim=c(0,1200))
> > lines(x, dgam1,col="red",lwd=3)
> > legend("topright", legend = c("observed","fitted"),
> >        col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
> >        lwd=c(0,3),bty="n", pt.cex=2)
> > text(100,.012 , expression(paste(beta==64.64)))
> > box()
> >
> > par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")  ## To control
> > white space around and between the plots
> > hist(stn_all[,2],prob=TRUE, main ="Gambang ",col="yellowgreen",
> > cex.axis=1.2,
> > xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
> > xlim=c(0,1200))
> > lines(x, dgam2,col="red",lwd=3)
> > legend("topright", legend = c("observed","fitted"),
> >        col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
> >        lwd=c(0,3),bty="n", pt.cex=2)
> > text(100,.012 , expression(paste(beta==64.64)))
> > box()
> >
> >
> > Thank you for your help.
> >
> > --
> > *Dr. Roslinazairimah Binti Zakaria*
> > *Tel: +609-5492370; Fax. No.+609-5492766*
> >
> > *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> > roslinaump at gmail.com <roslinaump at gmail.com>*
> > Deputy Dean (Academic & Student Affairs)
> > Faculty of Industrial Sciences & Technology
> > University Malaysia Pahang
> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
*Dr. Roslinazairimah Binti Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Deputy Dean (Academic & Student Affairs)
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Aug  3 14:14:46 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 3 Aug 2016 08:14:46 -0400
Subject: [R] Multiple plot in a page
In-Reply-To: <CANTvJZLz168F0_DN9swf9SAv02fHqM7a1R5TUCbSnFKbn1ic3g@mail.gmail.com>
References: <CANTvJZLWtOEyq6qV1ZovSz3F-6DOtiur5r1Um7oejh+iJUyJyQ@mail.gmail.com>
	<CA+8X3fU6dEZ7UxnDC_UC7JmYFJ2ipxbZgO0sXNzFr5jcsF=ObQ@mail.gmail.com>
	<CANTvJZLz168F0_DN9swf9SAv02fHqM7a1R5TUCbSnFKbn1ic3g@mail.gmail.com>
Message-ID: <e37e20bd-a148-4bff-949e-604464305dbe@gmail.com>

On 03/08/2016 8:01 AM, roslinazairimah zakaria wrote:
> Hi Jim,
>
> I tried your code, however it still gives me only one plot.  I don't
> understand what is going on.  Any clue?

The third par() call tells R that you want to start a new page. (So did 
the second one, but it wasn't a problem there.) Just drop it.

Duncan Murdoch

>
> On Wed, Aug 3, 2016 at 4:55 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Roslina,
>> You only specify space for two plots in:
>>
>> par(mfrow=c(1,2))
>>
>> However, you only try to plot two plots, so I will assume that you
>> only want two. You haven't defined "x" in the above code, which will
>> cause an error. The code below gives me two plots as I would expect (I
>> made up the data that you didn't supply).
>>
>> par(mfrow=c(1,2))
>> stn_all<-matrix(400*rnorm(20)+4,ncol=2)
>> par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")
>> hist(stn_all[,1],prob=TRUE, main ="Balok ",col="yellowgreen", cex.axis=1.2,
>> xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
>> xlim=c(0,1200))
>> x<-c(400,600,800,1000)
>> dgam1<-(rnorm(4)+4)/2000
>> lines(x, dgam1,col="red",lwd=3)
>> legend("topright", legend = c("observed","fitted"),
>>        col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
>>        lwd=c(0,3),bty="n", pt.cex=2)
>> text(100,.012 , expression(paste(beta==64.64)))
>> box()
>>
>> par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")
>> hist(stn_all[,2],prob=TRUE, main ="Gambang ",col="yellowgreen",
>> cex.axis=1.2,
>> xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
>> xlim=c(0,1200))
>> dgam2<-(rnorm(4)+4)/2000
>> lines(x, dgam2,col="red",lwd=3)
>> legend("topright", legend = c("observed","fitted"),
>>        col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
>>        lwd=c(0,3),bty="n", pt.cex=2)
>> text(100,.012 , expression(paste(beta==64.64)))
>> box()
>>
>> Jim
>>
>>
>> On Wed, Aug 3, 2016 at 3:44 PM, roslinazairimah zakaria
>> <roslinaump at gmail.com> wrote:
>>> Dear r-users,
>>>
>>> I would like to plot 4 graphs arranged as 2 by 2 and follows are my
>> codes.
>>> However, it only shows one graph.
>>>
>>> par(mfrow=c(1,2))
>>>
>>> par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")  ## To control
>>> white space around and between the plots
>>> hist(stn_all[,1],prob=TRUE, main ="Balok ",col="yellowgreen",
>> cex.axis=1.2,
>>> xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
>>> xlim=c(0,1200))
>>> lines(x, dgam1,col="red",lwd=3)
>>> legend("topright", legend = c("observed","fitted"),
>>>        col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
>>>        lwd=c(0,3),bty="n", pt.cex=2)
>>> text(100,.012 , expression(paste(beta==64.64)))
>>> box()
>>>
>>> par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")  ## To control
>>> white space around and between the plots
>>> hist(stn_all[,2],prob=TRUE, main ="Gambang ",col="yellowgreen",
>>> cex.axis=1.2,
>>> xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
>>> xlim=c(0,1200))
>>> lines(x, dgam2,col="red",lwd=3)
>>> legend("topright", legend = c("observed","fitted"),
>>>        col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
>>>        lwd=c(0,3),bty="n", pt.cex=2)
>>> text(100,.012 , expression(paste(beta==64.64)))
>>> box()
>>>
>>>
>>> Thank you for your help.
>>>
>>> --
>>> *Dr. Roslinazairimah Binti Zakaria*
>>> *Tel: +609-5492370; Fax. No.+609-5492766*
>>>
>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>>> roslinaump at gmail.com <roslinaump at gmail.com>*
>>> Deputy Dean (Academic & Student Affairs)
>>> Faculty of Industrial Sciences & Technology
>>> University Malaysia Pahang
>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>


From roslinaump at gmail.com  Wed Aug  3 15:19:59 2016
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Wed, 3 Aug 2016 21:19:59 +0800
Subject: [R] Multiple plot in a page
In-Reply-To: <e37e20bd-a148-4bff-949e-604464305dbe@gmail.com>
References: <CANTvJZLWtOEyq6qV1ZovSz3F-6DOtiur5r1Um7oejh+iJUyJyQ@mail.gmail.com>
	<CA+8X3fU6dEZ7UxnDC_UC7JmYFJ2ipxbZgO0sXNzFr5jcsF=ObQ@mail.gmail.com>
	<CANTvJZLz168F0_DN9swf9SAv02fHqM7a1R5TUCbSnFKbn1ic3g@mail.gmail.com>
	<e37e20bd-a148-4bff-949e-604464305dbe@gmail.com>
Message-ID: <CANTvJZ+-y01frX7ecAMWnzC26w=HAWyjQhnE0=wVhAg6i3Fm8w@mail.gmail.com>

Hi Duncan and Jim,

Yes, definitely you are right.  I should comment the third par().

par(mfrow=c(1,2))
stn_all<-matrix(400*rnorm(20)+4,ncol=2)

par(mar=c(4,4,2,1.2),oma = c(1, 1, 1, 1),xaxs="i", yaxs="i")
hist(stn_all[,1],prob=TRUE, main ="Balok ",col="yellowgreen", cex.axis=1.2,
xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
xlim=c(0,1200))
x<-c(400,600,800,1000)
dgam1<-(rnorm(4)+4)/2000
lines(x, dgam1,col="red",lwd=3)
legend("topright", legend = c("observed","fitted"),
       col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
       lwd=c(0,3),bty="n", pt.cex=2)
text(100,.012 , expression(paste(beta==64.64)))
box()

#par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")
hist(stn_all[,2],prob=TRUE, main ="Gambang ",col="yellowgreen",
cex.axis=1.2,
xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
xlim=c(0,1200))
dgam2<-(rnorm(4)+4)/2000
lines(x, dgam2,col="red",lwd=3)
legend("topright", legend = c("observed","fitted"),
       col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
       lwd=c(0,3),bty="n", pt.cex=2)
text(100,.012 , expression(paste(beta==64.64)))
box()

Thank you.

On Wed, Aug 3, 2016 at 8:14 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 03/08/2016 8:01 AM, roslinazairimah zakaria wrote:
>
>> Hi Jim,
>>
>> I tried your code, however it still gives me only one plot.  I don't
>> understand what is going on.  Any clue?
>>
>
> The third par() call tells R that you want to start a new page. (So did
> the second one, but it wasn't a problem there.) Just drop it.
>
> Duncan Murdoch
>
>
>
>> On Wed, Aug 3, 2016 at 4:55 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Roslina,
>>> You only specify space for two plots in:
>>>
>>> par(mfrow=c(1,2))
>>>
>>> However, you only try to plot two plots, so I will assume that you
>>> only want two. You haven't defined "x" in the above code, which will
>>> cause an error. The code below gives me two plots as I would expect (I
>>> made up the data that you didn't supply).
>>>
>>> par(mfrow=c(1,2))
>>> stn_all<-matrix(400*rnorm(20)+4,ncol=2)
>>> par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")
>>> hist(stn_all[,1],prob=TRUE, main ="Balok ",col="yellowgreen",
>>> cex.axis=1.2,
>>> xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
>>> xlim=c(0,1200))
>>> x<-c(400,600,800,1000)
>>> dgam1<-(rnorm(4)+4)/2000
>>> lines(x, dgam1,col="red",lwd=3)
>>> legend("topright", legend = c("observed","fitted"),
>>>        col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
>>>        lwd=c(0,3),bty="n", pt.cex=2)
>>> text(100,.012 , expression(paste(beta==64.64)))
>>> box()
>>>
>>> par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")
>>> hist(stn_all[,2],prob=TRUE, main ="Gambang ",col="yellowgreen",
>>> cex.axis=1.2,
>>> xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
>>> xlim=c(0,1200))
>>> dgam2<-(rnorm(4)+4)/2000
>>> lines(x, dgam2,col="red",lwd=3)
>>> legend("topright", legend = c("observed","fitted"),
>>>        col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
>>>        lwd=c(0,3),bty="n", pt.cex=2)
>>> text(100,.012 , expression(paste(beta==64.64)))
>>> box()
>>>
>>> Jim
>>>
>>>
>>> On Wed, Aug 3, 2016 at 3:44 PM, roslinazairimah zakaria
>>> <roslinaump at gmail.com> wrote:
>>>
>>>> Dear r-users,
>>>>
>>>> I would like to plot 4 graphs arranged as 2 by 2 and follows are my
>>>>
>>> codes.
>>>
>>>> However, it only shows one graph.
>>>>
>>>> par(mfrow=c(1,2))
>>>>
>>>> par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")  ## To control
>>>> white space around and between the plots
>>>> hist(stn_all[,1],prob=TRUE, main ="Balok ",col="yellowgreen",
>>>>
>>> cex.axis=1.2,
>>>
>>>> xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
>>>> xlim=c(0,1200))
>>>> lines(x, dgam1,col="red",lwd=3)
>>>> legend("topright", legend = c("observed","fitted"),
>>>>        col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
>>>>        lwd=c(0,3),bty="n", pt.cex=2)
>>>> text(100,.012 , expression(paste(beta==64.64)))
>>>> box()
>>>>
>>>> par(mar=c(4,4,2,1.2),oma=c(0,0,0,0),xaxs="i", yaxs="i")  ## To control
>>>> white space around and between the plots
>>>> hist(stn_all[,2],prob=TRUE, main ="Gambang ",col="yellowgreen",
>>>> cex.axis=1.2,
>>>> xlab="Rain (mm)", ylab="Relative frequency", ylim= c(0,.004),
>>>> xlim=c(0,1200))
>>>> lines(x, dgam2,col="red",lwd=3)
>>>> legend("topright", legend = c("observed","fitted"),
>>>>        col = c("yellowgreen", "red"), pch=c(15,NA), lty = c(0, 1),
>>>>        lwd=c(0,3),bty="n", pt.cex=2)
>>>> text(100,.012 , expression(paste(beta==64.64)))
>>>> box()
>>>>
>>>>
>>>> Thank you for your help.
>>>>
>>>> --
>>>> *Dr. Roslinazairimah Binti Zakaria*
>>>> *Tel: +609-5492370; Fax. No.+609-5492766*
>>>>
>>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>>>> roslinaump at gmail.com <roslinaump at gmail.com>*
>>>> Deputy Dean (Academic & Student Affairs)
>>>> Faculty of Industrial Sciences & Technology
>>>> University Malaysia Pahang
>>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>>
>>> http://www.R-project.org/posting-guide.html
>>>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>>
>>
>


-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Aug  3 15:50:14 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 3 Aug 2016 13:50:14 +0000
Subject: [R] p.adjust not working correctly?
In-Reply-To: <1A8C1289955EF649A09086A153E2672403F0F2643D@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <CAPUn7Bc0xvLLX95w+QG5Ok9wpdwrz6tNc73E3UkAq5_xb31t+g@mail.gmail.com>
	<1A8C1289955EF649A09086A153E2672403F0F2643D@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <3665c86f3e85469aa86eb68fe83d1b49@exch-2p-mbx-t2.ads.tamu.edu>

Part of the confusion is that Bonferroni is often described as an adjustment to the significance level (sig-level) not the p-value. For example, to evaluate p-values when there are 8 tests, we compare the p-value to the sig-level/8 so the sig-level decreases. The p.adjust() function adjusts the p-value instead of the sig-level so we multiply the p-value by the number of tests (p-value * 8). As a result the p-values increase.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of S Ellison
Sent: Wednesday, August 3, 2016 6:05 AM
To: Alicia Ellis; r-help at r-project.org
Subject: Re: [R] p.adjust not working correctly?

> p.adjust for bonferroni p value correction does not appear to be working
> correctly:
You should re-check what a Bonferroni correction does, or at least reboot your intuition (mine needs rebooting all the time). All the p-values should _increase_ by a factor of n, with a ceiling of 1.0. Dividing by n would imply incorrectly that individual events have become less probable as the number increases.

The result you have obtained is what is supposed to happen.

S Ellison

> > p <- runif(50)
> >
> > p
>  [1] 0.08280254 0.08955706 0.19754389 0.52812033 0.68907772 0.21849696
> 0.02774784 0.23923562 0.03482480 0.76437481 0.87236155 0.76438604 [13]
> 0.37432032 0.89630318 0.01626565 0.08152060 0.55715478 0.47736921
> 0.77968275 0.17388127 0.37212900 0.18363170 0.51655538 0.14526733 [25]
> 0.60870820 0.13752392 0.92412799 0.73045115 0.89887453 0.33744577
> 0.84966571 0.97797283 0.20571554 0.29115022 0.75928867 0.12929511 [37]
> 0.64923057 0.68168196 0.19311014 0.83818106 0.85592243 0.56276287
> 0.80822911 0.53377044 0.44691466 0.59198417 0.36114259 0.35431768 [49]
> 0.10381694 0.57738429
> 
> > p.adjust(p, method = "bonferroni", n=50)
>  [1] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
> 1.0000000
> 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
> [15] 0.8132824 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
> 1.0000000
> 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
> [29] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
> 1.0000000
> 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
> [43] 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000
> 1.0000000
> 1.0000000
> 
> for the one corrected pvalue that is less than 1, it seems to have been divided
> by 0.02 and not 50.
> 
> I can do this one manually but would be nice if it worked:)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:9}}


From dcarlson at tamu.edu  Wed Aug  3 16:25:13 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 3 Aug 2016 14:25:13 +0000
Subject: [R] Three way correspondence analyses?
In-Reply-To: <CAFdg=fXxfR+26m1gR5fcNyLsadDvbsxkngcrGjaS4pHwhHGuzA@mail.gmail.com>
References: <CAFdg=fXxfR+26m1gR5fcNyLsadDvbsxkngcrGjaS4pHwhHGuzA@mail.gmail.com>
Message-ID: <77ae1a2d03284e9f86b5c9fd60d2a17d@exch-2p-mbx-t2.ads.tamu.edu>

There are at least two canonical correspondence analysis functions named cca() in different R packages so we don't have enough information to begin. The posting guide encourages providing a reproducible example using dput() to provide enough data so that we can run your code. If we don't know anything about your data and cannot run your code, we cannot do more than guess.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Suparna Mitra
Sent: Tuesday, August 2, 2016 2:58 PM
To: R help
Subject: [R] Three way correspondence analyses?

Hello R experts,
   have some data for microbiome, metabolome and cytokine from the same
sample. Now I want to do a three-way correspondence analyses. From three
normalised data I was trying,
#Now CCA

with two data it works good like:
Metab.Cytok.Microb.cca <- cca(normMicrobiome_NEC,normCytok_and_ProInf)
 plot(Metab.Cytok.Microb.cca )
Metab.Cytok.Microb.cca <- cca(normMicrobiome_NEC,normMetab_NEC)
plot(Metab.Cytok.Microb.cca )

But when I tried with three
Metab.Cytok.Microb.cca <-
cca(normMicrobiome_NEC,normMetab_NEC,normCytok_and_ProInf)
plot(Metab.Cytok.Microb.cca )
But this is not displaying all three variables.
Sorry, I am very new in this. Can anybody please help me?
Thanks a lot,
Mitra

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mak.hholly at gmail.com  Wed Aug  3 16:26:30 2016
From: mak.hholly at gmail.com (greg holly)
Date: Wed, 3 Aug 2016 10:26:30 -0400
Subject: [R] (no subject)
Message-ID: <CAM9Qe4jTstr-88+EPwVwXF_o+nnZELTUWxE2_dUeYd8N-7k3fA@mail.gmail.com>

Hi all;


I am going to run models for variable selection using elastic-net. Because
I have about 1500 descriptive (independent) variables which they are highly
correlated. Before running elastic-net and even single regressions (~1500)
I need get fitted values for dependent variables using MIXED model. My
question is:

Should I used the fitted values or residuals as dependent variable for run
elastic-net (even single regressions which is not main purpose)?

Your helps are highly appreciated,

Greg

	[[alternative HTML version deleted]]


From mak.hholly at gmail.com  Wed Aug  3 16:31:25 2016
From: mak.hholly at gmail.com (greg holly)
Date: Wed, 3 Aug 2016 10:31:25 -0400
Subject: [R] Predicted values VS residuals
Message-ID: <CAM9Qe4iD59uRhnVn=pcFfNkXsrgpnCBFZndMQvhXfH=yZDFRkQ@mail.gmail.com>

Dear all;

I am sorry for my earlier post without subject. My question in earlier mail
was:

I am going to run models for variable selection using elastic-net. Because
I have about 1500 descriptive (independent) variables which they are highly
correlated. Before running elastic-net and even single regressions (~1500)
I need get fitted values for dependent variables using MIXED model. My
question is:

Should I used the fitted values or residuals as dependent variable for run
elastic-net (even single regressions which is not main purpose)?

Your helps are highly appreciated,

Greg

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Wed Aug  3 17:27:32 2016
From: chocold12 at gmail.com (lily li)
Date: Wed, 3 Aug 2016 09:27:32 -0600
Subject: [R] how to plot annual values directly
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5037A4F@SRVEXCHMBX.precheza.cz>
References: <CAN5afy_VJ1g0ONe4c=_J8bO9DhCBKHkpdT8iy5sdA8+U+2Jsrg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5037A4F@SRVEXCHMBX.precheza.cz>
Message-ID: <CAN5afy9hDtWkNWHnDL18hF8rN3iivXPX3LemkYitNkoWR0paoA@mail.gmail.com>

I meant that my dataframe has daily data, but how to plot annual mean/sum
directly? Thanks.

On Wed, Aug 3, 2016 at 4:16 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> What do you mean to plot annual mean/sum directly? You can compute it by
> aggregate function and add it to your plot, but I am not sure if it is
> enough direct.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
> > Sent: Tuesday, August 2, 2016 8:10 PM
> > To: R mailing list <r-help at r-project.org>
> > Subject: [R] how to plot annual values directly
> >
> > Hi R users,
> >
> > I have a dataframe, with daily precipitation data, is it possible to
> plot annual
> > mean or annual sum values directly? Thanks for your help.
> >
> > df
> > year   month   day   precip       time
> > 2010     1          1        0.5     2010-01-01
> > 2010     1          2        0.8     2010-01-02
> > 2010     1          3        1.0     2010-01-03
> > 2010     1          4        0.9     2010-01-04
> > ...
> >
> > fig1 = ggplot()+ geom_path(data=df, aes(x=time, y= precip)
> > show(fig1)
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Wed Aug  3 17:39:39 2016
From: chocold12 at gmail.com (lily li)
Date: Wed, 3 Aug 2016 09:39:39 -0600
Subject: [R] plot many dfs in ggplot
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5037A62@SRVEXCHMBX.precheza.cz>
References: <CAN5afy_de9kE8N+GiM+wN0HGryYdd=gNkb-Eh1=17yxdc6y5ng@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5037A62@SRVEXCHMBX.precheza.cz>
Message-ID: <CAN5afy9WRFcQ=3e3wJCCcDaURmu6X5=_pBGDV0yyJbUKM5+KLg@mail.gmail.com>

Thanks, but rbind/merge function only combines two dataframes each time,
how to work on multiple dataframes? Thanks again.


On Wed, Aug 3, 2016 at 4:20 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi.
>
> Hm. I would add a column indicating data frame and merge/rbind all data
> frames.
>
> Something like
>
> df1$fr <- 1
> df2$fr <- 2
>
> dfkompl <- rbind(df1, df2)
>
> ggplot(dfkompl, aes(x=time, y=varA, colour=factor(fr))
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
> > Sent: Tuesday, August 2, 2016 8:51 PM
> > To: R mailing list <r-help at r-project.org>
> > Subject: [R] plot many dfs in ggplot
> >
> > Hi all,
> >
> > I have another question. There are several dataframes, each has the same
> > columns: time, varA, varB, varC, etc. If I want to plot time ~ varA of
> each
> > dataframe, where different dataframe names use different colors. How to
> > do this in ggplot? Thanks for your help.
> >
> > Right now, I tried to use the code below, but very laborious, and needs
> colors
> > manually.
> >
> > fig1 = ggplot()+
> >     geom_path(data=df1, aes(x=time, y= varA, color= 'df1'))+
> >     geom_path(data=df2, aes(x=time, y= varA, color= 'df2'))+
> >     geom_path(data=df3, aes(x=time, y= varA, color= 'df3'))+
> >     ...
> >     scale_color_manual('', limits=c('df1', 'df2', 'df3', ...),
> values=c('blue', red',
> > 'green', ...))
> > show(fig1)
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Aug  3 18:41:43 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 3 Aug 2016 09:41:43 -0700
Subject: [R] It is possible to use "input parameters" with "standard
 error" in fitting function nls
In-Reply-To: <CAEcPzfBs-2d7rEjQ+v3CF2-1FZQA9wkSnQ9tL2F9M91ygfBEGA@mail.gmail.com>
References: <CAEcPzfBs-2d7rEjQ+v3CF2-1FZQA9wkSnQ9tL2F9M91ygfBEGA@mail.gmail.com>
Message-ID: <CAGxFJbS+zYocSyNrFhN8qEcwF-X=Nk6mPwvXKQfOZyF1+rP1jQ@mail.gmail.com>

Vicente:

You have not received a reply. I think it is because your post appears
to reveal a profound lack of understanding about how empirical
modeling works: the uncertainty in parameter estimates derives from
the uncertainty in the data (via the modeling process, of course). You
cannot set them independently as "input."

I urge that you consult a local statistical expert, take a statistics
course or two, and/or do some studying before proceeding further.


Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 3, 2016 at 1:57 AM, Vicente Mart? Centelles
<martiv at qio.uji.es> wrote:
> Dear all,
>
> I would like to introduce an input parameter with an associated standard
> error to perform a fitting using the nls function (or any similar function):
>
> parameter1 = 9.00 +/- 0.20  (parameter 1 has a value of 9.00 and standard
> error of 0.20)
>
> fittingResults <- nls(y ~ function(xdata, ydata, parameter1,
> fittingparameter),start=list(parameter1=9.00, fittingparameter=5.00))
> summary(fittingResults)
>
> Does anyone know how to  introduce the associated standard error of the
> parameter to the fitting function?
>
> Many thanks for your help,
>
> Best regards
>
> Vicente
>
>
> --
> _______________________________________
> *Dr. Vicente Mart? Centelles*
> *Postdoctoral Researcher (VALi+d Generalitat Valenciana, Spain)*
>
>
> *Universitat Jaume I*Departamento de Qu?mica Inorg?nica y Org?nica
> Avda Sos Baynat s/n
> E-12071-Castell?n (Spain)
> Tel.: +34 964728235
> Fax: +34 964728214
> e-mail: martiv at qio.uji.es
>
> *web page*: www.vmarti.es
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ulrik.stervbo at gmail.com  Wed Aug  3 21:03:11 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 03 Aug 2016 19:03:11 +0000
Subject: [R] how to plot annual values directly
In-Reply-To: <CAN5afy9hDtWkNWHnDL18hF8rN3iivXPX3LemkYitNkoWR0paoA@mail.gmail.com>
References: <CAN5afy_VJ1g0ONe4c=_J8bO9DhCBKHkpdT8iy5sdA8+U+2Jsrg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5037A4F@SRVEXCHMBX.precheza.cz>
	<CAN5afy9hDtWkNWHnDL18hF8rN3iivXPX3LemkYitNkoWR0paoA@mail.gmail.com>
Message-ID: <CAKVAULOaxS7T568Zht920hrE-46m3kdhy=Q3miZx5gUagcneuw@mail.gmail.com>

You could use dplyr:

library(plyr)
ddply(df, .variables = "year", summarise, mean.precip = mean(precip))

Hope this helps
Ulrik


On Wed, 3 Aug 2016 at 17:29 lily li <chocold12 at gmail.com> wrote:

> I meant that my dataframe has daily data, but how to plot annual mean/sum
> directly? Thanks.
>
> On Wed, Aug 3, 2016 at 4:16 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> > Hi
> >
> > What do you mean to plot annual mean/sum directly? You can compute it by
> > aggregate function and add it to your plot, but I am not sure if it is
> > enough direct.
> >
> > Cheers
> > Petr
> >
> > > -----Original Message-----
> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily
> li
> > > Sent: Tuesday, August 2, 2016 8:10 PM
> > > To: R mailing list <r-help at r-project.org>
> > > Subject: [R] how to plot annual values directly
> > >
> > > Hi R users,
> > >
> > > I have a dataframe, with daily precipitation data, is it possible to
> > plot annual
> > > mean or annual sum values directly? Thanks for your help.
> > >
> > > df
> > > year   month   day   precip       time
> > > 2010     1          1        0.5     2010-01-01
> > > 2010     1          2        0.8     2010-01-02
> > > 2010     1          3        1.0     2010-01-03
> > > 2010     1          4        0.9     2010-01-04
> > > ...
> > >
> > > fig1 = ggplot()+ geom_path(data=df, aes(x=time, y= precip)
> > > show(fig1)
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > > guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> > ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie
> > vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email
> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> > ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout;
> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> > p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n
> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
> tohoto
> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and are
> > intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> > sender. Delete the contents of this e-mail with all attachments and its
> > copies from your system.
> > If you are not the intended recipient of this e-mail, you are not
> > authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> > The sender of this e-mail shall not be liable for any possible damage
> > caused by modifications of the e-mail or by delay with transfer of the
> > email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering into a
> > contract in any time, for any reason, and without stating any reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to
> > immediately accept such offer; The sender of this e-mail (offer) excludes
> > any acceptance of the offer on the part of the recipient containing any
> > amendment or variation.
> > - the sender insists on that the respective contract is concluded only
> > upon an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to
> enter
> > into any contracts on behalf of the company except for cases in which
> > he/she is expressly authorized to do so in writing, and such
> authorization
> > or power of attorney is submitted to the recipient or the person
> > represented by the recipient, or the existence of such authorization is
> > known to the recipient of the person represented by the recipient.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Wed Aug  3 21:06:56 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 03 Aug 2016 19:06:56 +0000
Subject: [R] plot many dfs in ggplot
In-Reply-To: <CAN5afy9WRFcQ=3e3wJCCcDaURmu6X5=_pBGDV0yyJbUKM5+KLg@mail.gmail.com>
References: <CAN5afy_de9kE8N+GiM+wN0HGryYdd=gNkb-Eh1=17yxdc6y5ng@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5037A62@SRVEXCHMBX.precheza.cz>
	<CAN5afy9WRFcQ=3e3wJCCcDaURmu6X5=_pBGDV0yyJbUKM5+KLg@mail.gmail.com>
Message-ID: <CAKVAULM28SXgAnKp_qnkPvdsVhS72Z5E-JR+W6xe3MpVN67FJA@mail.gmail.com>

Not quite - this works: rbind(df1, df2, df3, df1, df2, df3)

Or if the have your data.frames in a list, use do.call:

df.lst <- list(df1, df2, df3, df1, df2, df3)
do.call(rbind, df.lst)

You might take a look at the facet functionality in ggplot once you are
ready to build your plots.

Best,
Ulrik

On Wed, 3 Aug 2016 at 17:42 lily li <chocold12 at gmail.com> wrote:

> Thanks, but rbind/merge function only combines two dataframes each time,
> how to work on multiple dataframes? Thanks again.
>
>
> On Wed, Aug 3, 2016 at 4:20 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> > Hi.
> >
> > Hm. I would add a column indicating data frame and merge/rbind all data
> > frames.
> >
> > Something like
> >
> > df1$fr <- 1
> > df2$fr <- 2
> >
> > dfkompl <- rbind(df1, df2)
> >
> > ggplot(dfkompl, aes(x=time, y=varA, colour=factor(fr))
> >
> > Cheers
> > Petr
> >
> >
> > > -----Original Message-----
> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily
> li
> > > Sent: Tuesday, August 2, 2016 8:51 PM
> > > To: R mailing list <r-help at r-project.org>
> > > Subject: [R] plot many dfs in ggplot
> > >
> > > Hi all,
> > >
> > > I have another question. There are several dataframes, each has the
> same
> > > columns: time, varA, varB, varC, etc. If I want to plot time ~ varA of
> > each
> > > dataframe, where different dataframe names use different colors. How to
> > > do this in ggplot? Thanks for your help.
> > >
> > > Right now, I tried to use the code below, but very laborious, and needs
> > colors
> > > manually.
> > >
> > > fig1 = ggplot()+
> > >     geom_path(data=df1, aes(x=time, y= varA, color= 'df1'))+
> > >     geom_path(data=df2, aes(x=time, y= varA, color= 'df2'))+
> > >     geom_path(data=df3, aes(x=time, y= varA, color= 'df3'))+
> > >     ...
> > >     scale_color_manual('', limits=c('df1', 'df2', 'df3', ...),
> > values=c('blue', red',
> > > 'green', ...))
> > > show(fig1)
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > > guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> > ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie
> > vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email
> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> > ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout;
> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> > p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n
> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
> tohoto
> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and are
> > intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> > sender. Delete the contents of this e-mail with all attachments and its
> > copies from your system.
> > If you are not the intended recipient of this e-mail, you are not
> > authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> > The sender of this e-mail shall not be liable for any possible damage
> > caused by modifications of the e-mail or by delay with transfer of the
> > email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering into a
> > contract in any time, for any reason, and without stating any reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to
> > immediately accept such offer; The sender of this e-mail (offer) excludes
> > any acceptance of the offer on the part of the recipient containing any
> > amendment or variation.
> > - the sender insists on that the respective contract is concluded only
> > upon an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to
> enter
> > into any contracts on behalf of the company except for cases in which
> > he/she is expressly authorized to do so in writing, and such
> authorization
> > or power of attorney is submitted to the recipient or the person
> > represented by the recipient, or the existence of such authorization is
> > known to the recipient of the person represented by the recipient.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Wed Aug  3 21:09:19 2016
From: chocold12 at gmail.com (lily li)
Date: Wed, 3 Aug 2016 13:09:19 -0600
Subject: [R] plot many dfs in ggplot
In-Reply-To: <CAKVAULM28SXgAnKp_qnkPvdsVhS72Z5E-JR+W6xe3MpVN67FJA@mail.gmail.com>
References: <CAN5afy_de9kE8N+GiM+wN0HGryYdd=gNkb-Eh1=17yxdc6y5ng@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5037A62@SRVEXCHMBX.precheza.cz>
	<CAN5afy9WRFcQ=3e3wJCCcDaURmu6X5=_pBGDV0yyJbUKM5+KLg@mail.gmail.com>
	<CAKVAULM28SXgAnKp_qnkPvdsVhS72Z5E-JR+W6xe3MpVN67FJA@mail.gmail.com>
Message-ID: <CAN5afy9pTy5-di4C2W-BD2QGNXcAKr48eMj7uMs8=mGs80T2vA@mail.gmail.com>

Thanks. How to add an additional column, with the name of each dataframe's
name?

On Wed, Aug 3, 2016 at 1:06 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
wrote:

> Not quite - this works: rbind(df1, df2, df3, df1, df2, df3)
>
> Or if the have your data.frames in a list, use do.call:
>
> df.lst <- list(df1, df2, df3, df1, df2, df3)
> do.call(rbind, df.lst)
>
> You might take a look at the facet functionality in ggplot once you are
> ready to build your plots.
>
> Best,
> Ulrik
>
> On Wed, 3 Aug 2016 at 17:42 lily li <chocold12 at gmail.com> wrote:
>
>> Thanks, but rbind/merge function only combines two dataframes each time,
>> how to work on multiple dataframes? Thanks again.
>>
>>
>> On Wed, Aug 3, 2016 at 4:20 AM, PIKAL Petr <petr.pikal at precheza.cz>
>> wrote:
>>
>> > Hi.
>> >
>> > Hm. I would add a column indicating data frame and merge/rbind all data
>> > frames.
>> >
>> > Something like
>> >
>> > df1$fr <- 1
>> > df2$fr <- 2
>> >
>> > dfkompl <- rbind(df1, df2)
>> >
>> > ggplot(dfkompl, aes(x=time, y=varA, colour=factor(fr))
>> >
>> > Cheers
>> > Petr
>> >
>> >
>> > > -----Original Message-----
>> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily
>> li
>> > > Sent: Tuesday, August 2, 2016 8:51 PM
>> > > To: R mailing list <r-help at r-project.org>
>> > > Subject: [R] plot many dfs in ggplot
>> > >
>> > > Hi all,
>> > >
>> > > I have another question. There are several dataframes, each has the
>> same
>> > > columns: time, varA, varB, varC, etc. If I want to plot time ~ varA of
>> > each
>> > > dataframe, where different dataframe names use different colors. How
>> to
>> > > do this in ggplot? Thanks for your help.
>> > >
>> > > Right now, I tried to use the code below, but very laborious, and
>> needs
>> > colors
>> > > manually.
>> > >
>> > > fig1 = ggplot()+
>> > >     geom_path(data=df1, aes(x=time, y= varA, color= 'df1'))+
>> > >     geom_path(data=df2, aes(x=time, y= varA, color= 'df2'))+
>> > >     geom_path(data=df3, aes(x=time, y= varA, color= 'df3'))+
>> > >     ...
>> > >     scale_color_manual('', limits=c('df1', 'df2', 'df3', ...),
>> > values=c('blue', red',
>> > > 'green', ...))
>> > > show(fig1)
>> > >
>> > >       [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide http://www.R-project.org/posting-
>> > > guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ________________________________
>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> > ur?eny pouze jeho adres?t?m.
>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>> kopie
>> > vyma?te ze sv?ho syst?mu.
>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>> email
>> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>> modifikacemi
>> > ?i zpo?d?n?m p?enosu e-mailu.
>> >
>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>> p?ijmout;
>> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>> > p??jemce s dodatkem ?i odchylkou.
>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>> zmocn?n
>> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
>> tohoto
>> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>> >
>> > This e-mail and any documents attached to it may be confidential and are
>> > intended only for its intended recipients.
>> > If you received this e-mail by mistake, please immediately inform its
>> > sender. Delete the contents of this e-mail with all attachments and its
>> > copies from your system.
>> > If you are not the intended recipient of this e-mail, you are not
>> > authorized to use, disseminate, copy or disclose this e-mail in any
>> manner.
>> > The sender of this e-mail shall not be liable for any possible damage
>> > caused by modifications of the e-mail or by delay with transfer of the
>> > email.
>> >
>> > In case that this e-mail forms part of business dealings:
>> > - the sender reserves the right to end negotiations about entering into
>> a
>> > contract in any time, for any reason, and without stating any reasoning.
>> > - if the e-mail contains an offer, the recipient is entitled to
>> > immediately accept such offer; The sender of this e-mail (offer)
>> excludes
>> > any acceptance of the offer on the part of the recipient containing any
>> > amendment or variation.
>> > - the sender insists on that the respective contract is concluded only
>> > upon an express mutual agreement on all its aspects.
>> > - the sender of this e-mail informs that he/she is not authorized to
>> enter
>> > into any contracts on behalf of the company except for cases in which
>> > he/she is expressly authorized to do so in writing, and such
>> authorization
>> > or power of attorney is submitted to the recipient or the person
>> > represented by the recipient, or the existence of such authorization is
>> > known to the recipient of the person represented by the recipient.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Wed Aug  3 21:20:52 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 03 Aug 2016 19:20:52 +0000
Subject: [R] plot many dfs in ggplot
In-Reply-To: <CAN5afy9pTy5-di4C2W-BD2QGNXcAKr48eMj7uMs8=mGs80T2vA@mail.gmail.com>
References: <CAN5afy_de9kE8N+GiM+wN0HGryYdd=gNkb-Eh1=17yxdc6y5ng@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5037A62@SRVEXCHMBX.precheza.cz>
	<CAN5afy9WRFcQ=3e3wJCCcDaURmu6X5=_pBGDV0yyJbUKM5+KLg@mail.gmail.com>
	<CAKVAULM28SXgAnKp_qnkPvdsVhS72Z5E-JR+W6xe3MpVN67FJA@mail.gmail.com>
	<CAN5afy9pTy5-di4C2W-BD2QGNXcAKr48eMj7uMs8=mGs80T2vA@mail.gmail.com>
Message-ID: <CAKVAULPs1cCuTVEbswtuMAeyXNWfGdqsU6CqOHkPQ1ED7gCc_w@mail.gmail.com>

That Petr already showed. Please read his email again.

lily li <chocold12 at gmail.com> schrieb am Mi., 3. Aug. 2016 21:09:

> Thanks. How to add an additional column, with the name of each dataframe's
> name?
>
> On Wed, Aug 3, 2016 at 1:06 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> wrote:
>
>> Not quite - this works: rbind(df1, df2, df3, df1, df2, df3)
>>
>> Or if the have your data.frames in a list, use do.call:
>>
>> df.lst <- list(df1, df2, df3, df1, df2, df3)
>> do.call(rbind, df.lst)
>>
>> You might take a look at the facet functionality in ggplot once you are
>> ready to build your plots.
>>
>> Best,
>> Ulrik
>>
>> On Wed, 3 Aug 2016 at 17:42 lily li <chocold12 at gmail.com> wrote:
>>
>>> Thanks, but rbind/merge function only combines two dataframes each time,
>>> how to work on multiple dataframes? Thanks again.
>>>
>>>
>>> On Wed, Aug 3, 2016 at 4:20 AM, PIKAL Petr <petr.pikal at precheza.cz>
>>> wrote:
>>>
>>> > Hi.
>>> >
>>> > Hm. I would add a column indicating data frame and merge/rbind all data
>>> > frames.
>>> >
>>> > Something like
>>> >
>>> > df1$fr <- 1
>>> > df2$fr <- 2
>>> >
>>> > dfkompl <- rbind(df1, df2)
>>> >
>>> > ggplot(dfkompl, aes(x=time, y=varA, colour=factor(fr))
>>> >
>>> > Cheers
>>> > Petr
>>> >
>>> >
>>> > > -----Original Message-----
>>> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>> lily li
>>> > > Sent: Tuesday, August 2, 2016 8:51 PM
>>> > > To: R mailing list <r-help at r-project.org>
>>> > > Subject: [R] plot many dfs in ggplot
>>> > >
>>> > > Hi all,
>>> > >
>>> > > I have another question. There are several dataframes, each has the
>>> same
>>> > > columns: time, varA, varB, varC, etc. If I want to plot time ~ varA
>>> of
>>> > each
>>> > > dataframe, where different dataframe names use different colors. How
>>> to
>>> > > do this in ggplot? Thanks for your help.
>>> > >
>>> > > Right now, I tried to use the code below, but very laborious, and
>>> needs
>>> > colors
>>> > > manually.
>>> > >
>>> > > fig1 = ggplot()+
>>> > >     geom_path(data=df1, aes(x=time, y= varA, color= 'df1'))+
>>> > >     geom_path(data=df2, aes(x=time, y= varA, color= 'df2'))+
>>> > >     geom_path(data=df3, aes(x=time, y= varA, color= 'df3'))+
>>> > >     ...
>>> > >     scale_color_manual('', limits=c('df1', 'df2', 'df3', ...),
>>> > values=c('blue', red',
>>> > > 'green', ...))
>>> > > show(fig1)
>>> > >
>>> > >       [[alternative HTML version deleted]]
>>> > >
>>> > > ______________________________________________
>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > PLEASE do read the posting guide http://www.R-project.org/posting-
>>> > > guide.html
>>> > > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> > ________________________________
>>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>>> > ur?eny pouze jeho adres?t?m.
>>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>>> kopie
>>> > vyma?te ze sv?ho syst?mu.
>>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>>> email
>>> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>> modifikacemi
>>> > ?i zpo?d?n?m p?enosu e-mailu.
>>> >
>>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>>> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>>> p?ijmout;
>>> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>>> > p??jemce s dodatkem ?i odchylkou.
>>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>>> zmocn?n
>>> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
>>> tohoto
>>> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>>> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>> >
>>> > This e-mail and any documents attached to it may be confidential and
>>> are
>>> > intended only for its intended recipients.
>>> > If you received this e-mail by mistake, please immediately inform its
>>> > sender. Delete the contents of this e-mail with all attachments and its
>>> > copies from your system.
>>> > If you are not the intended recipient of this e-mail, you are not
>>> > authorized to use, disseminate, copy or disclose this e-mail in any
>>> manner.
>>> > The sender of this e-mail shall not be liable for any possible damage
>>> > caused by modifications of the e-mail or by delay with transfer of the
>>> > email.
>>> >
>>> > In case that this e-mail forms part of business dealings:
>>> > - the sender reserves the right to end negotiations about entering
>>> into a
>>> > contract in any time, for any reason, and without stating any
>>> reasoning.
>>> > - if the e-mail contains an offer, the recipient is entitled to
>>> > immediately accept such offer; The sender of this e-mail (offer)
>>> excludes
>>> > any acceptance of the offer on the part of the recipient containing any
>>> > amendment or variation.
>>> > - the sender insists on that the respective contract is concluded only
>>> > upon an express mutual agreement on all its aspects.
>>> > - the sender of this e-mail informs that he/she is not authorized to
>>> enter
>>> > into any contracts on behalf of the company except for cases in which
>>> > he/she is expressly authorized to do so in writing, and such
>>> authorization
>>> > or power of attorney is submitted to the recipient or the person
>>> > represented by the recipient, or the existence of such authorization is
>>> > known to the recipient of the person represented by the recipient.
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Aug  4 00:21:12 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 3 Aug 2016 15:21:12 -0700
Subject: [R] It is possible to use "input parameters" with "standard
 error" in fitting function nls
In-Reply-To: <CAEcPzfB8HsObaefgNKXJP6CM6X3xHrFzj_ne-_Dneu+OrFRY=w@mail.gmail.com>
References: <CAEcPzfBs-2d7rEjQ+v3CF2-1FZQA9wkSnQ9tL2F9M91ygfBEGA@mail.gmail.com>
	<CAGxFJbS+zYocSyNrFhN8qEcwF-X=Nk6mPwvXKQfOZyF1+rP1jQ@mail.gmail.com>
	<CAEcPzfB8HsObaefgNKXJP6CM6X3xHrFzj_ne-_Dneu+OrFRY=w@mail.gmail.com>
Message-ID: <CAGxFJbTx1m1tk=ONSWYezHk0AxRW+tjVhopE0aYi=aq4uOsQaA@mail.gmail.com>

Unless there is good reason to do otherwise, you should cc the list to
allow others to provide perhaps better responses or to correct my
possible errors. I have done so here.

If your "parameter" is fixed in the modeling it cannot contribute to
the uncertainty of estimation of the remaining model parameters. It
would presumably contribute to the uncertainty in the fitted model,
however.

One approach to deal with the situation might be to combine the data
from your prior modeling and your current data and estimate *all*
parameters. Another might be to put appropriate priors on all your
model parameters -- including an informative prior on the one you
wanted to hold fixed, but won't -- and fit a full Bayesian model. Or
maybe hold hold it fixed and do some sort of propagation of errors
analysis. Or...

The point is that the approach you take depends on the details of what
you have and what your purpose is. You need to consult with a local
statistician for this. And, in any case, statistical questions are
generally OT here, and this appears to be a fairly complicated one.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 3, 2016 at 2:06 PM, Vicente Mart? Centelles
<martiv at qio.uji.es> wrote:
> Hello Bert,
>
> Thanks for your message.
>
> The parameter that I want to input with the standard error is a value form
> another experiment and therefore it has an associated error, this parameter
> will not change during the fitting, it has to be fixed.
>
> Best regards
>
> Vicente
>
> 2016-08-03 17:41 GMT+01:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>
>> Vicente:
>>
>> You have not received a reply. I think it is because your post appears
>> to reveal a profound lack of understanding about how empirical
>> modeling works: the uncertainty in parameter estimates derives from
>> the uncertainty in the data (via the modeling process, of course). You
>> cannot set them independently as "input."
>>
>> I urge that you consult a local statistical expert, take a statistics
>> course or two, and/or do some studying before proceeding further.
>>
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Aug 3, 2016 at 1:57 AM, Vicente Mart? Centelles
>> <martiv at qio.uji.es> wrote:
>> > Dear all,
>> >
>> > I would like to introduce an input parameter with an associated standard
>> > error to perform a fitting using the nls function (or any similar
>> > function):
>> >
>> > parameter1 = 9.00 +/- 0.20  (parameter 1 has a value of 9.00 and
>> > standard
>> > error of 0.20)
>> >
>> > fittingResults <- nls(y ~ function(xdata, ydata, parameter1,
>> > fittingparameter),start=list(parameter1=9.00, fittingparameter=5.00))
>> > summary(fittingResults)
>> >
>> > Does anyone know how to  introduce the associated standard error of the
>> > parameter to the fitting function?
>> >
>> > Many thanks for your help,
>> >
>> > Best regards
>> >
>> > Vicente
>> >
>> >
>> > --
>> > _______________________________________
>> > *Dr. Vicente Mart? Centelles*
>> > *Postdoctoral Researcher (VALi+d Generalitat Valenciana, Spain)*
>> >
>> >
>> > *Universitat Jaume I*Departamento de Qu?mica Inorg?nica y Org?nica
>> > Avda Sos Baynat s/n
>> > E-12071-Castell?n (Spain)
>> > Tel.: +34 964728235
>> > Fax: +34 964728214
>> > e-mail: martiv at qio.uji.es
>> >
>> > *web page*: www.vmarti.es
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> _______________________________________
> Dr. Vicente Mart? Centelles
> Postdoctoral Researcher (VALi+d Generalitat Valenciana, Spain)
>
> Universitat Jaume I
> Departamento de Qu?mica Inorg?nica y Org?nica
> Avda Sos Baynat s/n
> E-12071-Castell?n (Spain)
> Tel.: +34 964728235
> Fax: +34 964728214
> e-mail: martiv at qio.uji.es
>
> web page: www.vmarti.es


From Michael.Laviolette at dhhs.nh.gov  Wed Aug  3 15:08:52 2016
From: Michael.Laviolette at dhhs.nh.gov (Laviolette, Michael)
Date: Wed, 3 Aug 2016 13:08:52 +0000
Subject: [R] Odds ratios in logistic regression models with interaction
Message-ID: <1ef0e1f6c9244fbb8e57f552585fb81c@dhhs.nh.gov>

I'm trying to reproduce some results from Hosmer & Lemeshow's "Applied Logistic Regression" second edition, pp. 74-79. The objective is to estimate odds ratios for low weight births with interaction between mother's age and weight (dichotomized at 110 lb.). I can get the point estimates, but I can't find an interval option. Can anyone provide guidance on computing the confidence intervals? Thanks. -Mike L.

library(dplyr)
data(birthwt, package = "MASS")
birthwt <- birthwt %>%
  mutate(low = factor(low, 0:1, c("Not low", "Low")),
         lwd = cut(lwt, c(0, 110, Inf), right = FALSE,
                   labels = c("Less than 110", "At least 110")),
         lwd = relevel(lwd, "At least 110"))

# p. 77, Table 3.16, Model 3
fit3.16 <- glm(low ~ lwd * age, binomial, birthwt)
# p. 78, interaction plot
visreg::visreg(fit3.16, "age", by = "lwd", xlab = "Age",
               ylab = "Estimated logit")
# p. 78, covariance matrix
vcov(fit3.16)
# odds ratios for ages 15, 20, 25, 30
age0 <- seq(15, 30, 5)
df1 <- data.frame(lwd = "Less than 110", age = age0)
df2 <- data.frame(lwd = "At least 110", age = age0)
a1 <- predict(fit3.16, df1, se.fit = TRUE)
a2 <- predict(fit3.16, df2, se.fit = TRUE)
# p. 79, point estimates
exp(a1$fit - a2$fit)

# How to get CI's?
# Age    OR     (95% CI)
# ----------------------
# 15   1.04 (0.29, 3.79)
# 20   2.01 (0.91, 4.44)
# 25   3.90 (1.71, 8.88)
# 30   7.55 (1.95, 29.19)




	[[alternative HTML version deleted]]


From zpsimpso at gmail.com  Wed Aug  3 19:58:26 2016
From: zpsimpso at gmail.com (Zach Simpson)
Date: Wed, 3 Aug 2016 12:58:26 -0500
Subject: [R] plot many dfs in ggplot (and other ggplot questions)
Message-ID: <CAJByKzonh2_pprjtin2YjR0QN7av9_t8cUZiZLJt8zN1RROpUQ@mail.gmail.com>

Hi,

In regards to your first question:

>Hi R users,

>I have a dataframe, with daily precipitation data, is it possible to plot
>annual mean or annual sum values directly? Thanks for your help.

>df
>year   month   day   precip       time
>2010     1          1        0.5     2010-01-01
>2010     1          2        0.8     2010-01-02
>2010     1          3        1.0     2010-01-03
>2010     1          4        0.9     2010-01-04

>fig1 = ggplot()+ geom_path(data=df, aes(x=time, y= precip)
>show(fig1)

I could not find a nice/simple solution (there may be one out there
though). However I made a quick example using some simple for loops
and ggplot's annotate function. Perhaps someone else here has a more
elegant method.
####
#create sample dataset
start <- as.POSIXct("2010-01-01")
end <- as.POSIXct("2010-12-31")

dates <- seq.POSIXt(start,end,"day")
rain <- rnorm(365, mean = 3.5, sd =1)#pretend this is Vietnam
df <- data.frame(dates,rain)

movec <- strftime(dates, format="%m") #get vector of months
movec <- as.numeric(movec) #character to numeric
#initialize monthly dataframe
moframe <- data.frame(xmins=as.POSIXct(character()),
                      xmaxs=as.POSIXct(character()),
                      momean=numeric())

for (ii in 1:12){
  moframe[ii,3] <- mean(df[which(movec == ii),2])
  moframe[ii,1] <- min(df[which(movec ==ii),1])
  moframe[ii,2] <- max(df[which(movec ==ii),1])
}

p <- ggplot(df, aes(x=dates, y=rain))+geom_path()
for (jj in 1:12){
  p <- p + annotate("segment", x = moframe[jj,1], xend =
moframe[jj,2], y=moframe[jj,3], yend=moframe[jj,3])
}
p #voila!
######

As to your other questions:

>I have another question. There are several dataframes, each has the same
>columns: time, varA, varB, varC, etc. If I want to plot time ~ varA of each
>dataframe, where different dataframe names use different colors. How to do
>this in ggplot? Thanks for your help.

You can "melt" these dataframes into one frame that identifies each
dataset with some ID variable. Then, when you make your plot, you can
use "colour=ID.var" in the aes() call. The below link is a good
example:

http://stackoverflow.com/questions/6525864/multiple-lines-each-based-on-a-different-dataframe-in-ggplot2-automatic-colori#6526160

Your last question:

>Another question is, if I want to shade the range between the maximum and
>minimum values for daily or annual values, how to do it? Thanks again.

Check out the following which shows how to use geom_area and geom_ribbon:
http://r-statistics.co/ggplot2-cheatsheet.html#Ribbons

Another great ggplot resource is the R graphics cookbook
(http://www.cookbook-r.com/Graphs/)

One quick note, in future posts to the list it may be better to
compile your (related questions) into just one message to avoid
cluttering the list.

Hope this helps,

Zach Simpson


From iluwinga at yahoo.com  Wed Aug  3 21:07:06 2016
From: iluwinga at yahoo.com (Isaac Singini)
Date: Wed, 3 Aug 2016 19:07:06 +0000 (UTC)
Subject: [R] Martingale residuals warning
References: <200127131.8644592.1470251226798.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <200127131.8644592.1470251226798.JavaMail.yahoo@mail.yahoo.com>

Dear AllI am new to R, ?I am struggling to figure out and resolve warning.I have fitted a joint model for survival and longitudinal data using the "JM" library using the syntax below.
# Longitudinal submodellmeFit.p1_constr <- lme(sqrtcd4wk ~ cd4tpt ?+ pred:cd4tpt, data = cd4long_constr,? ? ? ? ? ? ? ? ? random = ~cd4tpt|id1, na.action = na.omit)?
# Survival submodel for constrictionsurvFit.p1Constr <- coxph(Surv(surv6mon_constr, var6mon_constr) ~ pred, data = surv_full_constr, x = TRUE)

# Joint model for constrictionjointFit.p1Constr <- jointModel(lmeFit.p1_constr, survFit.p1Constr, timeVar = "cd4tpt",? ? ? ? ? ? ? ? ? ? ? ? ? method = "piecewise-PH-aGH")summary(jointFit.p1Constr)
I am able to get my desired results i.e. estimates and 95% C.I.?I am however not able to calculate ?Martingale residuals from the event process submodel using the following syntax despite being able to calculate Cox-Snell residuals using the following syntax
resMartT <- residuals(jointFit.p1Constr, process = "Event", type = "Martingale")
#resMartT<-resid(survFit.p1Constr,type='martingale')fitSubY <- fitted(jointFit.p1Constr, process = "Longitudinal", type = "EventTime")plot(fitSubY, resMartT, xlab = "Fitted Values", ylab = "Residuals",main = "Martingale Residuals vs Fitted Values")
I get a warning : Warning message: In events - fits : ?longer object length is not a multiple of shorter object length
# Cox-Snell residualsresCST <- residuals(jointFit.p1Constr, process = "Event", type = "CoxSnell")
sfit <- survfit(Surv(resCST, var6mon_constr) ~ 1, data = surv_full_constr)plot(sfit, mark.time = FALSE, conf.int = TRUE, lty = 1:2, xlab = "Cox-Snell Residuals", ylab = "Survival Probability",?? ? ?main = "Survival Function of Cox-Snell Residuals")curve(exp(-x), from = 0, to = max(surv_full_constr$var6mon_constr), add = TRUE, col = "red", lwd = 2)
I will appreciate any assistance rendered

ThanksIsaac


	[[alternative HTML version deleted]]


From tuffery.stephane at gmail.com  Wed Aug  3 21:37:13 2016
From: tuffery.stephane at gmail.com (=?iso-8859-1?Q?St=E9phane_Tuff=E9ry?=)
Date: Wed, 3 Aug 2016 21:37:13 +0200
Subject: [R] Effect of an optimized BLAS library on lm() function
Message-ID: <002b01d1edbe$6fd87180$4f895480$@gmail.com>

Dear All,

 

My question is simple (but the answer perhaps less): how does R lm()
function benefit from an optimized BLAS library (such as ATLAS, OpenBLAS, or
the MKL library in R Open)? I suppose that these BLAS optimizations
concentrate on the level-3 BLAS, and lm() function relies on level-1 BLAS
LINPACK? Nevertheless, the following test on my laptop seems to indicate
slighter faster calculations with lm() when using MKL library.

 

> set.seed(123)

> m <- 100000

> n <- 100

> matest <- matrix(rnorm(m*n,0,2), m, n)

> y <- rnorm(m) 

> x <- cbind(1, matest)

> test <- data.frame(matest, y = y)

> n <- names(test)

> f <- as.formula(paste("y ~", paste(n[!n %in% "y"], collapse = " + ")))

> bigtest <- as.big.matrix(cbind(matest, y))

> options(bigmemory.allow.dimnames=TRUE)

> colnames(bigtest) <- names(test)

> compare <- microbenchmark(lm(y ~ ., data=test), lm.fit(x,y), biglm(f,
data=test),

+ bigglm(f, data=test, family=gaussian()), speedglm(y ~ ., data=test,
family=gaussian()),

+ fastLm(y ~ ., data=test, family=gaussian()),

+ biglm.big.matrix(f, data=bigtest, chunksize=100000),

+ solve(crossprod(x), crossprod(x,y)),

+ solve(t(x)%*%x, t(x)%*%y),

+ qr.coef(qr(x, LAPACK = T), y),

+ qr.coef(qr(x, LAPACK = F), y), times=30, unit="ms")

 

# on R base

> compare

Unit: milliseconds

                                                   expr       min        lq
mean    median        uq       max neval

                                 lm(y ~ ., data = test) 2423.4618 2497.0986
2587.6717 2528.4108 2605.8664 3245.0846    30

                                           lm.fit(x, y) 1785.2536 1816.0466
1864.9683 1841.6295 1868.1580 2166.6797    30

                                  biglm(f, data = test) 1947.5808 2001.2834
2044.3119 2021.8473 2084.5147 2304.7108    30

            bigglm(f, data = test, family = gaussian()) 4461.9307 4544.2631
4726.1232 4629.1442 4705.2304 6240.9467    30

      speedglm(y ~ ., data = test, family = gaussian()) 1651.4826 1670.5076
1727.1039 1696.9502 1771.4395 1946.8591    30

        fastLm(y ~ ., data = test, family = gaussian()) 3939.3955 4051.2525
4214.4684 4149.4943 4301.5698 5037.1337    30

biglm.big.matrix(f, data = bigtest, chunksize = 1e+05) 2176.9082 2283.2670
2336.6303 2345.2608 2383.1442 2478.3213    30

                   solve(crossprod(x), crossprod(x, y))  839.3229  844.4637
867.8926  856.9103  882.7036  949.5098    30

                          solve(t(x) %*% x, t(x) %*% y) 1436.7063 1464.4559
1531.5375 1494.3093 1532.6056 1916.9786    30

                          qr.coef(qr(x, LAPACK = T), y) 1989.8013 2031.9686
2091.0366 2063.0931 2128.2705 2317.7407    30

                          qr.coef(qr(x, LAPACK = F), y) 1752.9953 1809.3616
1856.6803 1826.0688 1887.2954 2111.4479    30

 

# on R Open (2 threads)

> getMKLthreads()

[1] 2

> compare

Unit: milliseconds

                                                   expr        min
lq       mean     median        uq       max neval

                                 lm(y ~ ., data = test) 1788.61291
1875.63929 1976.74912 1928.96796 2082.2125 2371.3407    30

                                           lm.fit(x, y) 1097.40423
1194.82479 1256.65020 1263.27286 1299.7869 1451.5524    30

                                  biglm(f, data = test) 1936.05859
1983.08455 2041.44009 2019.54653 2103.5658 2211.2873    30

            bigglm(f, data = test, family = gaussian()) 4707.12674
4795.69165 5005.35978 5023.22328 5193.1482 5340.9577    30

      speedglm(y ~ ., data = test, family = gaussian())  881.47945
934.77104  996.59551  975.93888 1038.1470 1212.8197    30

        fastLm(y ~ ., data = test, family = gaussian()) 1671.48208
1810.42245 1883.39515 1880.31249 1936.2377 2324.2279    30

biglm.big.matrix(f, data = bigtest, chunksize = 1e+05) 2196.43003 2266.86705
2339.93722 2355.17538 2401.8879 2585.1069    30

                   solve(crossprod(x), crossprod(x, y))   63.50803
70.25601   92.00605   74.73306  101.0346  363.4992    30

                          solve(t(x) %*% x, t(x) %*% y)  269.83961
298.29031  340.11531  320.85419  350.4334  541.5970    30

                          qr.coef(qr(x, LAPACK = T), y)  864.66990
941.90109 1000.73358  985.70631 1030.5733 1341.8595    30

                          qr.coef(qr(x, LAPACK = F), y) 1155.82456
1253.15555 1309.30060 1299.67349 1354.4523 1556.7010    30

 

# on R Open (1 thread)

> getMKLthreads()

[1] 1

> compare

Unit: milliseconds

                                                   expr       min        lq
mean    median        uq       max neval

                                 lm(y ~ ., data = test) 1991.4313 2034.4098
2111.0498 2104.9173 2182.6686 2379.2731    30

                                           lm.fit(x, y) 1329.0017 1347.4155
1437.7724 1409.5693 1519.5183 1690.3965    30

                                  biglm(f, data = test) 1922.7935 1979.4146
2030.7355 2008.3577 2066.5151 2265.3957    30

            bigglm(f, data = test, family = gaussian()) 4474.7666 4534.6946
4589.0903 4594.6761 4637.1702 4744.8987    30

      speedglm(y ~ ., data = test, family = gaussian())  918.9388  959.5755
1015.1099 1000.7063 1066.6677 1178.5648    30

        fastLm(y ~ ., data = test, family = gaussian()) 1737.4001 1785.1347
1908.2960 1905.7776 1992.8247 2188.0665    30

biglm.big.matrix(f, data = bigtest, chunksize = 1e+05) 2172.3621 2242.7618
2309.5848 2317.5166 2362.6432 2434.8259    30

                   solve(crossprod(x), crossprod(x, y))  122.5138  125.0064
132.2125  128.8345  137.1886  157.8529    30

                          solve(t(x) %*% x, t(x) %*% y)  330.3578  336.0520
390.2391  379.9801  413.4324  530.6566    30

                          qr.coef(qr(x, LAPACK = T), y)  917.1596  943.9504
987.5824  971.1059 1001.2241 1231.8204    30

                          qr.coef(qr(x, LAPACK = F), y) 1313.7414 1348.3933
1439.4807 1480.5955 1518.4831 1569.0909    30

 

We notice that solve(crossprod(x), crossprod(x, y)) is faster than
solve(t(x) %*% x, t(x) %*% y), because the function crossprod(x) exploits
the fact that the matrix t(x) %*% x is symmetric to calculate only half of
the matrix.
We notice that solve(t(x) %*% x, t(x) %*% y) is faster than qr.coef(qr(x),
y), because the function solve() relies on the Cholevsky decomposition,
which is approximately twice as fast as the QR decomposition.
We notice that qr.coef(qr(x, LAPACK = T), y) is faster than qr.coef(qr(x,
LAPACK = F), y), at least with an optimized BLAS library which allows a
saving of time with regard to the use of LINPACK.
We notice that the calculation time of qr.coef(qr(x, LAPACK = F), y) is of
the same order as that of lm.fit() which also uses a QR decomposition based
on LINPACK.
Of course, the calculation time of lm() is more important than that of
lm.fit(), because lm() has to estimate the formula and make additional
calculations.
We also notice that the functions biglm() and bigglm() of package biglm do
not benefit from the optimized library BLAS MKL, but that all other
functions benefit from it, including lm() and lm.fit(), and even with only
one thread.

 

Sincerely,

St?phane

 


	[[alternative HTML version deleted]]


From ecstasia1 at gmail.com  Wed Aug  3 23:20:17 2016
From: ecstasia1 at gmail.com (Ecstasia Tisiphoni)
Date: Wed, 3 Aug 2016 23:20:17 +0200
Subject: [R] Plotting in LaTeX with ggplot2 in R and using tikzdevice
Message-ID: <CAMBjWT0fcBb=gEvbOMza3A7VqJcPMB5aAaM4wtz6=Lsi7Uvg0Q@mail.gmail.com>

Hello,
not totally sure if this is a R or a LaTeX topic...

I am a total newbie to R and LaTeX, and trying to write my masters
thesis right now... I tried to get this answered via
https://cran.r-project.org/web/packages/tikzDevice/vignettes/tikzDevice.pdf
 ...but I failed... :(

I am creating plots in R via ggplot2, and converting them to TeX
format via tikzDevice.

Now many of my plots have a legend on the right, which differs in size
(depending of course on the legend title and text).

If I now convert my Rplot using tikz() it only scales the size for the
whole image it creates.

What I want is: the rectangular plot itself to always be the same size
for all my plots (no matter how big/small the legend and the axis
numbers are)...

My Rscript with some test Data:

library(ggplot2)
library(scales)
require(grid)
library(tikzDevice)


#setting time zone
options(tz="Europe/Berlin")

tikz(file = "my_output_file.tex", standAlone=F,width = 6, height = 3)


cars['dt'] = seq(Sys.Date(),Sys.Date()-980,-20)
plot <- ggplot(cars,aes(y=speed,x=dist,color=as.integer(dt)))+
               geom_point(size=2,alpha=0.7)+
               xlab("distance")+
               ylab("speed")+
               scale_color_gradientn("dt",
                                     colours=rainbow(6)
                                     )+

#textsize
theme_bw()+
theme(legend.position="right",
      legend.key.height=unit(2,"lines"),
      legend.title=element_text(size=rel(0.8)),
      legend.text=element_text(size=rel(0.8)),
      axis.text.y=element_text(angle=90,
                               hjust=0.5),
      axis.title=element_text(size=rel(0.8))
 )

print(plot)

dev.off()


If I change now the legend text to a slightly longer text, the output
of course has a completely different plot-size.
Is there a way to maintain the plot size?

I hope somebody can help me, or lead me to the information I need...


From dwinsemius at comcast.net  Thu Aug  4 01:40:30 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 3 Aug 2016 16:40:30 -0700
Subject: [R] Martingale residuals warning
In-Reply-To: <200127131.8644592.1470251226798.JavaMail.yahoo@mail.yahoo.com>
References: <200127131.8644592.1470251226798.JavaMail.yahoo.ref@mail.yahoo.com>
	<200127131.8644592.1470251226798.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <29188B08-6BC8-4C77-A67B-BE907E89FF0A@comcast.net>


> On Aug 3, 2016, at 12:07 PM, Isaac Singini via R-help <r-help at r-project.org> wrote:
> 
> Dear AllI am new to R,  I am struggling to figure out and resolve warning.I have fitted a joint model for survival and longitudinal data using the "JM" library using the syntax below.
> # Longitudinal submodellmeFit.p1_constr <- lme(sqrtcd4wk ~ cd4tpt  + pred:cd4tpt, data = cd4long_constr,                  random = ~cd4tpt|id1, na.action = na.omit) 
> # Survival submodel for constrictionsurvFit.p1Constr <- coxph(Surv(surv6mon_constr, var6mon_constr) ~ pred, data = surv_full_constr, x = TRUE)
> 
> # Joint model for constrictionjointFit.p1Constr <- jointModel(lmeFit.p1_constr, survFit.p1Constr, timeVar = "cd4tpt",                          method = "piecewise-PH-aGH")summary(jointFit.p1Constr)
> I am able to get my desired results i.e. estimates and 95% C.I. I am however not able to calculate  Martingale residuals from the event process submodel using the following syntax despite being able to calculate Cox-Snell residuals using the following syntax
> resMartT <- residuals(jointFit.p1Constr, process = "Event", type = "Martingale")
> #resMartT<-resid(survFit.p1Constr,type='martingale')fitSubY <- fitted(jointFit.p1Constr, process = "Longitudinal", type = "EventTime")plot(fitSubY, resMartT, xlab = "Fitted Values", ylab = "Residuals",main = "Martingale Residuals vs Fitted Values")
> I get a warning : Warning message: In events - fits :  longer object length is not a multiple of shorter object length
> # Cox-Snell residualsresCST <- residuals(jointFit.p1Constr, process = "Event", type = "CoxSnell")
> sfit <- survfit(Surv(resCST, var6mon_constr) ~ 1, data = surv_full_constr)plot(sfit, mark.time = FALSE, conf.int = TRUE, lty = 1:2, xlab = "Cox-Snell Residuals", ylab = "Survival Probability",      main = "Survival Function of Cox-Snell Residuals")curve(exp(-x), from = 0, to = max(surv_full_constr$var6mon_constr), add = TRUE, col = "red", lwd = 2)
> I will appreciate any assistance rendered

That code comes across as missing almost all carriage returns. Learn to post in plain text (as per the Posting Guide.)
> 
> ThanksIsaac
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Thu Aug  4 02:57:21 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 03 Aug 2016 17:57:21 -0700
Subject: [R] Plotting in LaTeX with ggplot2 in R and using tikzdevice
In-Reply-To: <CAMBjWT0fcBb=gEvbOMza3A7VqJcPMB5aAaM4wtz6=Lsi7Uvg0Q@mail.gmail.com>
References: <CAMBjWT0fcBb=gEvbOMza3A7VqJcPMB5aAaM4wtz6=Lsi7Uvg0Q@mail.gmail.com>
Message-ID: <A2EE2506-5DA1-4E5A-A6C9-AF594DFF3B91@dcn.davis.ca.us>

I would think knitr package would be useful in this endeavor. And possibly RStudio....

If that doesn't do it,  someone here may have a better hint, but solving this kind of question can require studying both the input (R code) and output (tikz/LaTeX code). While the R code belongs here, details of the rest get OT pretty quick. 
-- 
Sent from my phone. Please excuse my brevity.

On August 3, 2016 2:20:17 PM PDT, Ecstasia Tisiphoni <ecstasia1 at gmail.com> wrote:
>Hello,
>not totally sure if this is a R or a LaTeX topic...
>
>I am a total newbie to R and LaTeX, and trying to write my masters
>thesis right now... I tried to get this answered via
>https://cran.r-project.org/web/packages/tikzDevice/vignettes/tikzDevice.pdf
> ...but I failed... :(
>
>I am creating plots in R via ggplot2, and converting them to TeX
>format via tikzDevice.
>
>Now many of my plots have a legend on the right, which differs in size
>(depending of course on the legend title and text).
>
>If I now convert my Rplot using tikz() it only scales the size for the
>whole image it creates.
>
>What I want is: the rectangular plot itself to always be the same size
>for all my plots (no matter how big/small the legend and the axis
>numbers are)...
>
>My Rscript with some test Data:
>
>library(ggplot2)
>library(scales)
>require(grid)
>library(tikzDevice)
>
>
>#setting time zone
>options(tz="Europe/Berlin")
>
>tikz(file = "my_output_file.tex", standAlone=F,width = 6, height = 3)
>
>
>cars['dt'] = seq(Sys.Date(),Sys.Date()-980,-20)
>plot <- ggplot(cars,aes(y=speed,x=dist,color=as.integer(dt)))+
>               geom_point(size=2,alpha=0.7)+
>               xlab("distance")+
>               ylab("speed")+
>               scale_color_gradientn("dt",
>                                     colours=rainbow(6)
>                                     )+
>
>#textsize
>theme_bw()+
>theme(legend.position="right",
>      legend.key.height=unit(2,"lines"),
>      legend.title=element_text(size=rel(0.8)),
>      legend.text=element_text(size=rel(0.8)),
>      axis.text.y=element_text(angle=90,
>                               hjust=0.5),
>      axis.title=element_text(size=rel(0.8))
> )
>
>print(plot)
>
>dev.off()
>
>
>If I change now the legend text to a slightly longer text, the output
>of course has a completely different plot-size.
>Is there a way to maintain the plot size?
>
>I hope somebody can help me, or lead me to the information I need...
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Alexander.Herr at csiro.au  Thu Aug  4 03:32:14 2016
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Thu, 4 Aug 2016 01:32:14 +0000
Subject: [R] foreach {parallel} nested with for loop to update data.frame
	column
Message-ID: <5f65366dad444941b3c38763f1d5777a@exch1-mel.nexus.csiro.au>

Hi List,

Trying to update a data.frame column within a foreach nested for loop

### trial data
set.seed(666)
xyz<-as.data.frame(cbind(x=rep(rpois(5000,10),2)+1, y=rep(rpois(5000,10),2)+1,z=round(runif(10000, min=-3, max=40),2)))
xyz$mins<-rep(NA, nrow(xyz)) 

cl<-makeCluster(16)  #adjust to your cluster number
registerDoParallel(cl)

counter=0
foreach(i=unique(xyz[,1]), .combine=data.frame, .verbose=T) %dopar% {
        for( j in unique(xyz[,2])) {
                xyz[xyz[,2] == j ,4]<-min(xyz[xyz[,2] == j ,2]) 
        }

}

stopCluster(cl)

This is obviously not working. Any hints?

Thanx
Herry


From paul at stat.auckland.ac.nz  Thu Aug  4 03:48:09 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Thu, 4 Aug 2016 13:48:09 +1200
Subject: [R] [FORGED] Plotting in LaTeX with ggplot2 in R and using
 tikzdevice
In-Reply-To: <CAMBjWT0fcBb=gEvbOMza3A7VqJcPMB5aAaM4wtz6=Lsi7Uvg0Q@mail.gmail.com>
References: <CAMBjWT0fcBb=gEvbOMza3A7VqJcPMB5aAaM4wtz6=Lsi7Uvg0Q@mail.gmail.com>
Message-ID: <0c923808-4cee-4547-a2d7-3cee7d0874c8@stat.auckland.ac.nz>

Hi

You might need an approach that converts the ggplot object to a gtable 
and then either combine the gtables as here ...

http://stackoverflow.com/questions/16255579/how-can-i-make-consistent-width-plots-in-ggplot-with-legends

... or explicitly control the width of the plot within the gtable layout 
as here ...

http://stackoverflow.com/questions/30571198/how-achieve-identical-facet-sizes-and-scales-in-several-multi-facet-ggplot2-grah/30571289#30571289

Hope that helps

Paul

On 04/08/16 09:20, Ecstasia Tisiphoni wrote:
> Hello,
> not totally sure if this is a R or a LaTeX topic...
>
> I am a total newbie to R and LaTeX, and trying to write my masters
> thesis right now... I tried to get this answered via
> https://cran.r-project.org/web/packages/tikzDevice/vignettes/tikzDevice.pdf
>  ...but I failed... :(
>
> I am creating plots in R via ggplot2, and converting them to TeX
> format via tikzDevice.
>
> Now many of my plots have a legend on the right, which differs in size
> (depending of course on the legend title and text).
>
> If I now convert my Rplot using tikz() it only scales the size for the
> whole image it creates.
>
> What I want is: the rectangular plot itself to always be the same size
> for all my plots (no matter how big/small the legend and the axis
> numbers are)...
>
> My Rscript with some test Data:
>
> library(ggplot2)
> library(scales)
> require(grid)
> library(tikzDevice)
>
>
> #setting time zone
> options(tz="Europe/Berlin")
>
> tikz(file = "my_output_file.tex", standAlone=F,width = 6, height = 3)
>
>
> cars['dt'] = seq(Sys.Date(),Sys.Date()-980,-20)
> plot <- ggplot(cars,aes(y=speed,x=dist,color=as.integer(dt)))+
>                geom_point(size=2,alpha=0.7)+
>                xlab("distance")+
>                ylab("speed")+
>                scale_color_gradientn("dt",
>                                      colours=rainbow(6)
>                                      )+
>
> #textsize
> theme_bw()+
> theme(legend.position="right",
>       legend.key.height=unit(2,"lines"),
>       legend.title=element_text(size=rel(0.8)),
>       legend.text=element_text(size=rel(0.8)),
>       axis.text.y=element_text(angle=90,
>                                hjust=0.5),
>       axis.title=element_text(size=rel(0.8))
>  )
>
> print(plot)
>
> dev.off()
>
>
> If I change now the legend text to a slightly longer text, the output
> of course has a completely different plot-size.
> Is there a way to maintain the plot size?
>
> I hope somebody can help me, or lead me to the information I need...
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From ulrik.stervbo at gmail.com  Thu Aug  4 06:51:16 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 04 Aug 2016 04:51:16 +0000
Subject: [R] [FORGED] Plotting in LaTeX with ggplot2 in R and using
	tikzdevice
In-Reply-To: <0c923808-4cee-4547-a2d7-3cee7d0874c8@stat.auckland.ac.nz>
References: <CAMBjWT0fcBb=gEvbOMza3A7VqJcPMB5aAaM4wtz6=Lsi7Uvg0Q@mail.gmail.com>
	<0c923808-4cee-4547-a2d7-3cee7d0874c8@stat.auckland.ac.nz>
Message-ID: <CAKVAULN9UrgC0B9SinxNuYzOhuQfHQ6a5V_7JjqgnyVe_Ymzig@mail.gmail.com>

I saved my plots as pdf and used pdflatex. It's a few years ago and now you
can even use the r-package cowplot to create panels with subfigures. That
means more work with r, less manual work.

I believe kable from the knitr package can export tables for latex too.

Hope this helps.
Ulrik

Paul Murrell <paul at stat.auckland.ac.nz> schrieb am Do., 4. Aug. 2016 03:50:

> Hi
>
> You might need an approach that converts the ggplot object to a gtable
> and then either combine the gtables as here ...
>
>
> http://stackoverflow.com/questions/16255579/how-can-i-make-consistent-width-plots-in-ggplot-with-legends
>
> ... or explicitly control the width of the plot within the gtable layout
> as here ...
>
>
> http://stackoverflow.com/questions/30571198/how-achieve-identical-facet-sizes-and-scales-in-several-multi-facet-ggplot2-grah/30571289#30571289
>
> Hope that helps
>
> Paul
>
> On 04/08/16 09:20, Ecstasia Tisiphoni wrote:
> > Hello,
> > not totally sure if this is a R or a LaTeX topic...
> >
> > I am a total newbie to R and LaTeX, and trying to write my masters
> > thesis right now... I tried to get this answered via
> >
> https://cran.r-project.org/web/packages/tikzDevice/vignettes/tikzDevice.pdf
> >  ...but I failed... :(
> >
> > I am creating plots in R via ggplot2, and converting them to TeX
> > format via tikzDevice.
> >
> > Now many of my plots have a legend on the right, which differs in size
> > (depending of course on the legend title and text).
> >
> > If I now convert my Rplot using tikz() it only scales the size for the
> > whole image it creates.
> >
> > What I want is: the rectangular plot itself to always be the same size
> > for all my plots (no matter how big/small the legend and the axis
> > numbers are)...
> >
> > My Rscript with some test Data:
> >
> > library(ggplot2)
> > library(scales)
> > require(grid)
> > library(tikzDevice)
> >
> >
> > #setting time zone
> > options(tz="Europe/Berlin")
> >
> > tikz(file = "my_output_file.tex", standAlone=F,width = 6, height = 3)
> >
> >
> > cars['dt'] = seq(Sys.Date(),Sys.Date()-980,-20)
> > plot <- ggplot(cars,aes(y=speed,x=dist,color=as.integer(dt)))+
> >                geom_point(size=2,alpha=0.7)+
> >                xlab("distance")+
> >                ylab("speed")+
> >                scale_color_gradientn("dt",
> >                                      colours=rainbow(6)
> >                                      )+
> >
> > #textsize
> > theme_bw()+
> > theme(legend.position="right",
> >       legend.key.height=unit(2,"lines"),
> >       legend.title=element_text(size=rel(0.8)),
> >       legend.text=element_text(size=rel(0.8)),
> >       axis.text.y=element_text(angle=90,
> >                                hjust=0.5),
> >       axis.title=element_text(size=rel(0.8))
> >  )
> >
> > print(plot)
> >
> > dev.off()
> >
> >
> > If I change now the legend text to a slightly longer text, the output
> > of course has a completely different plot-size.
> > Is there a way to maintain the plot size?
> >
> > I hope somebody can help me, or lead me to the information I need...
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Aug  4 08:36:31 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 4 Aug 2016 06:36:31 +0000
Subject: [R] how to plot annual values directly
In-Reply-To: <CAKVAULOaxS7T568Zht920hrE-46m3kdhy=Q3miZx5gUagcneuw@mail.gmail.com>
References: <CAN5afy_VJ1g0ONe4c=_J8bO9DhCBKHkpdT8iy5sdA8+U+2Jsrg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5037A4F@SRVEXCHMBX.precheza.cz>
	<CAN5afy9hDtWkNWHnDL18hF8rN3iivXPX3LemkYitNkoWR0paoA@mail.gmail.com>
	<CAKVAULOaxS7T568Zht920hrE-46m3kdhy=Q3miZx5gUagcneuw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5037C33@SRVEXCHMBX.precheza.cz>

Hi

Other option is aggregate or ave, depending on how do you want to plot mean/sum values.

You should think about posting an example of what do you have and what do you want to achieve (at least partly). Without that we are just guessing your real intention.

Cheers
Petr

From: Ulrik Stervbo [mailto:ulrik.stervbo at gmail.com]
Sent: Wednesday, August 3, 2016 9:03 PM
To: lily li <chocold12 at gmail.com>; PIKAL Petr <petr.pikal at precheza.cz>
Cc: R mailing list <r-help at r-project.org>
Subject: Re: [R] how to plot annual values directly

You could use dplyr:

library(plyr)
ddply(df, .variables = "year", summarise, mean.precip = mean(precip))

Hope this helps
Ulrik


On Wed, 3 Aug 2016 at 17:29 lily li <chocold12 at gmail.com<mailto:chocold12 at gmail.com>> wrote:
I meant that my dataframe has daily data, but how to plot annual mean/sum
directly? Thanks.

On Wed, Aug 3, 2016 at 4:16 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:

> Hi
>
> What do you mean to plot annual mean/sum directly? You can compute it by
> aggregate function and add it to your plot, but I am not sure if it is
> enough direct.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of lily li
> > Sent: Tuesday, August 2, 2016 8:10 PM
> > To: R mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> > Subject: [R] how to plot annual values directly
> >
> > Hi R users,
> >
> > I have a dataframe, with daily precipitation data, is it possible to
> plot annual
> > mean or annual sum values directly? Thanks for your help.
> >
> > df
> > year   month   day   precip       time
> > 2010     1          1        0.5     2010-01-01
> > 2010     1          2        0.8     2010-01-02
> > 2010     1          3        1.0     2010-01-03
> > 2010     1          4        0.9     2010-01-04
> > ...
> >
> > fig1 = ggplot()+ geom_path(data=df, aes(x=time, y= precip)
> > show(fig1)
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Aug  4 08:49:11 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 4 Aug 2016 06:49:11 +0000
Subject: [R] plot many dfs in ggplot
In-Reply-To: <CAKVAULPs1cCuTVEbswtuMAeyXNWfGdqsU6CqOHkPQ1ED7gCc_w@mail.gmail.com>
References: <CAN5afy_de9kE8N+GiM+wN0HGryYdd=gNkb-Eh1=17yxdc6y5ng@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5037A62@SRVEXCHMBX.precheza.cz>
	<CAN5afy9WRFcQ=3e3wJCCcDaURmu6X5=_pBGDV0yyJbUKM5+KLg@mail.gmail.com>
	<CAKVAULM28SXgAnKp_qnkPvdsVhS72Z5E-JR+W6xe3MpVN67FJA@mail.gmail.com>
	<CAN5afy9pTy5-di4C2W-BD2QGNXcAKr48eMj7uMs8=mGs80T2vA@mail.gmail.com>
	<CAKVAULPs1cCuTVEbswtuMAeyXNWfGdqsU6CqOHkPQ1ED7gCc_w@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5037C49@SRVEXCHMBX.precheza.cz>

Hi

And if you have your data frames in list you could add easily a name of those data frames to rbinded result as R automagically uses data frame names as row names.

> lll<- list(df1=data.frame(a=1), df2=data.frame(a=2), df3= data.frame(a=56))
> lll
$df1
  a
1 1

$df2
  a
1 2

$df3
   a
1 56

> do.call(rbind, lll)
     a
df1  1
df2  2
df3 56
>

So you can add them as new column.

> res.df<-do.call(rbind, lll)
> res.df$dat <- row.names(res.df)
> res.df
     a dat
df1  1 df1
df2  2 df2
df3 56 df3
>

Cheers
Petr



From: Ulrik Stervbo [mailto:ulrik.stervbo at gmail.com]
Sent: Wednesday, August 3, 2016 9:21 PM
To: lily li <chocold12 at gmail.com>
Cc: PIKAL Petr <petr.pikal at precheza.cz>; R mailing list <r-help at r-project.org>
Subject: Re: [R] plot many dfs in ggplot


That Petr already showed. Please read his email again.

lily li <chocold12 at gmail.com<mailto:chocold12 at gmail.com>> schrieb am Mi., 3. Aug. 2016 21:09:
Thanks. How to add an additional column, with the name of each dataframe's name?

On Wed, Aug 3, 2016 at 1:06 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com<mailto:ulrik.stervbo at gmail.com>> wrote:
Not quite - this works: rbind(df1, df2, df3, df1, df2, df3)

Or if the have your data.frames in a list, use do.call:

df.lst <- list(df1, df2, df3, df1, df2, df3)
do.call(rbind, df.lst)

You might take a look at the facet functionality in ggplot once you are ready to build your plots.

Best,
Ulrik

On Wed, 3 Aug 2016 at 17:42 lily li <chocold12 at gmail.com<mailto:chocold12 at gmail.com>> wrote:
Thanks, but rbind/merge function only combines two dataframes each time,
how to work on multiple dataframes? Thanks again.


On Wed, Aug 3, 2016 at 4:20 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:

> Hi.
>
> Hm. I would add a column indicating data frame and merge/rbind all data
> frames.
>
> Something like
>
> df1$fr <- 1
> df2$fr <- 2
>
> dfkompl <- rbind(df1, df2)
>
> ggplot(dfkompl, aes(x=time, y=varA, colour=factor(fr))
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of lily li
> > Sent: Tuesday, August 2, 2016 8:51 PM
> > To: R mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> > Subject: [R] plot many dfs in ggplot
> >
> > Hi all,
> >
> > I have another question. There are several dataframes, each has the same
> > columns: time, varA, varB, varC, etc. If I want to plot time ~ varA of
> each
> > dataframe, where different dataframe names use different colors. How to
> > do this in ggplot? Thanks for your help.
> >
> > Right now, I tried to use the code below, but very laborious, and needs
> colors
> > manually.
> >
> > fig1 = ggplot()+
> >     geom_path(data=df1, aes(x=time, y= varA, color= 'df1'))+
> >     geom_path(data=df2, aes(x=time, y= varA, color= 'df2'))+
> >     geom_path(data=df3, aes(x=time, y= varA, color= 'df3'))+
> >     ...
> >     scale_color_manual('', limits=c('df1', 'df2', 'df3', ...),
> values=c('blue', red',
> > 'green', ...))
> > show(fig1)
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Aug  4 09:01:04 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 4 Aug 2016 07:01:04 +0000
Subject: [R] foreach {parallel} nested with for loop to update
	data.frame	column
In-Reply-To: <5f65366dad444941b3c38763f1d5777a@exch1-mel.nexus.csiro.au>
References: <5f65366dad444941b3c38763f1d5777a@exch1-mel.nexus.csiro.au>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5037C8A@SRVEXCHMBX.precheza.cz>

Hi

I may be completely wrong but isn't it work for ave? With your example I get

> fac<-interaction(xyz[,1], xyz[,2], drop=TRUE)
> xyz[,4]<-ave(xyz$z, fac, FUN= min)
> head(xyz)
   x  y     z  mins
1 13 15  1.97 -2.91
2 17  9 14.90 -2.81
3  9 10 34.68 -1.97
4 17  6  4.26 -2.63
5  3 12  0.12  0.12
6 19 11  7.91  7.91
>

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Alexander.Herr at csiro.au
> Sent: Thursday, August 4, 2016 3:32 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] foreach {parallel} nested with for loop to update data.frame
> column
>
> Hi List,
>
> Trying to update a data.frame column within a foreach nested for loop
>
> ### trial data
> set.seed(666)
> xyz<-as.data.frame(cbind(x=rep(rpois(5000,10),2)+1,
> y=rep(rpois(5000,10),2)+1,z=round(runif(10000, min=-3, max=40),2)))
> xyz$mins<-rep(NA, nrow(xyz))
>
> cl<-makeCluster(16)  #adjust to your cluster number
> registerDoParallel(cl)
>
> counter=0
> foreach(i=unique(xyz[,1]), .combine=data.frame, .verbose=T) %dopar% {
>         for( j in unique(xyz[,2])) {
>                 xyz[xyz[,2] == j ,4]<-min(xyz[xyz[,2] == j ,2])
>         }
>
> }
>
> stopCluster(cl)
>
> This is obviously not working. Any hints?
>
> Thanx
> Herry
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ross.chapman at ecogeonomix.com  Thu Aug  4 10:37:50 2016
From: ross.chapman at ecogeonomix.com (Ross Chapman)
Date: Thu, 4 Aug 2016 18:37:50 +1000
Subject: [R] cpquery problem
In-Reply-To: <CA+RJqXUqPN+X+XZ75h_WUUn8taswHp1GwThkwn-j3e9wcpyqGA@mail.gmail.com>
References: <9a0d19b8a05d0ae5c8676569bbfe96d2.squirrel@ecogeonomix.com>
	<CA+RJqXUqPN+X+XZ75h_WUUn8taswHp1GwThkwn-j3e9wcpyqGA@mail.gmail.com>
Message-ID: <ef9b32ac28ea74e69d194bd5865a628a.squirrel@ecogeonomix.com>

Hi Marco

Thank you very much for your helpful advice.

I have tried you suggestion of using method = 'lw' with cpquery and can
now obtain conditional probabilities.

However, I am still puzzled over the outputs from the predict() and
cpquery functions.

The network that I am working on has the following coefficients for the
node that I am interested in (ABW):

  Parameters of node ABW (conditional Gaussian distribution)

Conditional density: ABW | EST + TR + FFB + RF
Coefficients:
                        0             1             2
(Intercept)  -0.480612729  -5.834617332   0.809011487
TR       1.857271045   1.584331230   1.964198638
FFB    0.182533645   0.066891147   0.028620951
RF     -0.002822838   0.002155205  -0.001608243

Standard deviation of the residuals:
        0          1          2
1.5140402  1.1764351  0.9675918
Discrete parents' configurations:
     EST
0     K1
1     M1
2     M2

If I run predict() using this fitted network I get ABW results very close
to those expected.  For example, for test case 1, I get a predicted ABW of
15.022, which is very close to the actual ABW value for this case
(14.871).

However, running cpquery() using the values for this test case returns a
conditional probability of 0 for all levels of ABW observed in the
training data. For example, the conditional probability returned for a
event where ABW<15 is 0; similarly the conditional probability for an
event where ABW is between the minimum and maximum ABW values observed  in
the data is again zero; while the conditional probability of an ABW event
>24 (which is in excess of all observed values) is 1.

Why does cpquery not return a high conditional probability for an event
which is predicted from the same coefficients?

Many thanks for your assistance with these queries.

Regards

Ross

On Mon, August 1, 2016 7:35 pm, Marco Scutari wrote:
> Hi Ross,
>
>
> On 31 July 2016 at 09:11, Ross Chapman <ross.chapman at ecogeonomix.com>
> wrote:
>
>> I have tried running the cpquery in the debug mode, and found that it
>> typically returns the following for instances where the conditional
>> probability is returned as 0:
>>
>>> event matches 0 samples out of 0 (p = 0)
>>
>> Am I right in understanding that the Monte Carlo sampling has been
>> unable to create any cases that match the query?  If so, why would this
>> be if the evidence used is very typical of an average case in the data
>> used to train the network?
>
> Yes, that is what is happening. As to the reason why, I guess that the
> dependencies in the data may not be adequately represented in the fitted
> Bayesian network for some reason. What is apparent is that
> (EST=='y' & TR>9 & BU>15819 &  RF>2989) has an associated probability
> low enough that you do not observe any such sample in rejection sampling.
> Now, that being the case, you have two options:
>
>
> 1) use a much larger "n" with a smaller "batch = 10^6" to generate a
> lot more particles; 2) switch to likelihood weighting, i.e.
>
>
> cpquery(fitted,event=(ABW<=11), evidence=list(EST ='y', TR = c(9,
> max(data$TR)), BU = c(15819, max(data$BU)), RF = c(2989, max(data$RF)),
> n=10^6, method = "lw")
>
> 3) look at the parameters in your fitted network and diagnose why this
> is happening.
>
> Cheers,
> Marco
>
>
> --
> Marco Scutari, Ph.D.
> Lecturer in Statistics, Department of Statistics
> University of Oxford, United Kingdom
>
>


From lists at dewey.myzen.co.uk  Thu Aug  4 14:32:20 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 04 Aug 2016 12:32:20 +0000
Subject: [R] Odds ratios in logistic regression models with interaction
Message-ID: <Zen-1bVHoy-000GIt-Dh@smarthost01c.mail.zen.net.uk>

Laviolette, Michael <Michael.Laviolette at dhhs.nh.gov> wrote :

> I'm trying to reproduce some results from Hosmer & Lemeshow's "Applied Logistic
> Regression" second edition, pp. 74-79. The objective is to estimate odds ratios
> for low weight births with interaction between mother's age and weight
> (dichotomized at 110 lb.). I can get the point estimates, but I can't find an
> interval option. Can anyone provide guidance on computing the confidence
> intervals?

There is always confint. Not sure if you need MASS first from memory, not got a copy of R running to hand.


 Thanks. -Mike L.
> 
> library(dplyr)
> data(birthwt, package = "MASS")
> birthwt %
>   mutate(low = factor(low, 0:1, c("Not low", "Low")),
>          lwd = cut(lwt, c(0, 110, Inf), right = FALSE,
>                    labels = c("Less than 110", "At least 110")),
>          lwd = relevel(lwd, "At least 110"))
> 
> # p. 77, Table 3.16, Model 3
> fit3.16


From shivipmp82 at gmail.com  Thu Aug  4 15:09:49 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Thu, 4 Aug 2016 18:39:49 +0530
Subject: [R] Help with the RMD Output & rCharts Package
Message-ID: <CAB=p7SpiEEpNsFEqOgXji3wo-ittvXoaS=8LC+C_suexTrRB6g@mail.gmail.com>

Dear Team,

I am in need of urgent help on RMD output in html.

A) I am working on a sentiment analysis problem and have built a sentiment
model which works perfectly on R Studio however the same on the RMD shows
all the processing steps and details.

I have used echo= FALSE but i still the see the output as below:
Loading required package: stringr
Attaching package: 'stringr'
The following object is masked from 'package:qdap':
The following object is masked from 'package:igraph':%>%

B) i am also using rcharts to create charts on the above but as mentioned
above i dont see output in RMD whereas i see the output in R studio. The
code for the same is"
p4 <- nPlot(~ score, data = abc.sentiments, type = 'pieChart')
p4$chart(donut = TRUE)
p4


Please let me know if i need to share the sentiment code in a text file.

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Aug  4 15:12:06 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 4 Aug 2016 15:12:06 +0200
Subject: [R] Odds ratios in logistic regression models with interaction
In-Reply-To: <1ef0e1f6c9244fbb8e57f552585fb81c@dhhs.nh.gov>
References: <1ef0e1f6c9244fbb8e57f552585fb81c@dhhs.nh.gov>
Message-ID: <958AA24C-1FB2-4FBF-BB3C-37A4524F941D@gmail.com>

I suspect that "you can't get there from here"... a1$fit and a2$fit are not independent, so you can't work out the s.e. of their difference using sqrt(a1$se.fit^2+a2$se.fit^2). 

You need to backtrack a bit and figure out how a1$fit-a2$fit relates to coef(fit3.16). I suspect it is actually just the age times the interaction term, but since you give no output and your code uses a bunch of stuff that I haven't got installed, I can't be bothered to check....  

Once you have your desired value in the form t(a) %*% coef(...), then use the result that V(t(a) %*% betahat) == t(a) %*% vcov() %*% a  (asymptotically).

-pd

On 03 Aug 2016, at 15:08 , Laviolette, Michael <Michael.Laviolette at dhhs.nh.gov> wrote:

> I'm trying to reproduce some results from Hosmer & Lemeshow's "Applied Logistic Regression" second edition, pp. 74-79. The objective is to estimate odds ratios for low weight births with interaction between mother's age and weight (dichotomized at 110 lb.). I can get the point estimates, but I can't find an interval option. Can anyone provide guidance on computing the confidence intervals? Thanks. -Mike L.
> 
> library(dplyr)
> data(birthwt, package = "MASS")
> birthwt <- birthwt %>%
>  mutate(low = factor(low, 0:1, c("Not low", "Low")),
>         lwd = cut(lwt, c(0, 110, Inf), right = FALSE,
>                   labels = c("Less than 110", "At least 110")),
>         lwd = relevel(lwd, "At least 110"))
> 
> # p. 77, Table 3.16, Model 3
> fit3.16 <- glm(low ~ lwd * age, binomial, birthwt)
> # p. 78, interaction plot
> visreg::visreg(fit3.16, "age", by = "lwd", xlab = "Age",
>               ylab = "Estimated logit")
> # p. 78, covariance matrix
> vcov(fit3.16)
> # odds ratios for ages 15, 20, 25, 30
> age0 <- seq(15, 30, 5)
> df1 <- data.frame(lwd = "Less than 110", age = age0)
> df2 <- data.frame(lwd = "At least 110", age = age0)
> a1 <- predict(fit3.16, df1, se.fit = TRUE)
> a2 <- predict(fit3.16, df2, se.fit = TRUE)
> # p. 79, point estimates
> exp(a1$fit - a2$fit)
> 
> # How to get CI's?
> # Age    OR     (95% CI)
> # ----------------------
> # 15   1.04 (0.29, 3.79)
> # 20   2.01 (0.91, 4.44)
> # 25   3.90 (1.71, 8.88)
> # 30   7.55 (1.95, 29.19)
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From friendly at yorku.ca  Thu Aug  4 15:25:13 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 4 Aug 2016 09:25:13 -0400
Subject: [R] Three way correspondence analyses?
In-Reply-To: <CAFdg=fXxfR+26m1gR5fcNyLsadDvbsxkngcrGjaS4pHwhHGuzA@mail.gmail.com>
References: <CAFdg=fXxfR+26m1gR5fcNyLsadDvbsxkngcrGjaS4pHwhHGuzA@mail.gmail.com>
Message-ID: <09108d9a-c6de-8871-6079-8b73a8df4032@yorku.ca>

You haven't supplied any data, and we can only guess which cca() 
function you are using (ade4::cca, ..., vegan::cca(), yacca::cca), and 
the term 'cca' generally refers to canonical correspondence analysis,
which is not quite the same thing as 'three-way correspondence analysis'.

For three-way tables, there are several variations of standard
correspondence analysis that generalize CA for two-way tables
in reasonable, but different ways.
You may find more joy using the mjca() in the ca package
which provides these alternatives.

best,
-Michael

On 8/2/2016 3:58 PM, Suparna Mitra wrote:
> Hello R experts,
>    have some data for microbiome, metabolome and cytokine from the same
> sample. Now I want to do a three-way correspondence analyses. From three
> normalised data I was trying,
> #Now CCA
>
> with two data it works good like:
> Metab.Cytok.Microb.cca <- cca(normMicrobiome_NEC,normCytok_and_ProInf)
>  plot(Metab.Cytok.Microb.cca )
> Metab.Cytok.Microb.cca <- cca(normMicrobiome_NEC,normMetab_NEC)
> plot(Metab.Cytok.Microb.cca )
>
> But when I tried with three
> Metab.Cytok.Microb.cca <-
> cca(normMicrobiome_NEC,normMetab_NEC,normCytok_and_ProInf)
> plot(Metab.Cytok.Microb.cca )
> But this is not displaying all three variables.
> Sorry, I am very new in this. Can anybody please help me?
> Thanks a lot,
> Mitra
>
> 	[[alternative HTML version deleted]]
>


From Michael.Laviolette at dhhs.nh.gov  Thu Aug  4 16:24:35 2016
From: Michael.Laviolette at dhhs.nh.gov (Laviolette, Michael)
Date: Thu, 4 Aug 2016 14:24:35 +0000
Subject: [R] Odds ratios in logistic regression models with interaction
Message-ID: <3c81270be621469db930bcedb1d34706@dhhs.nh.gov>

Thanks. I ended up doing it as a contrast directly from the covariance matrix. There's probably a package that provides a better way, maybe the "contrast" package. For now, this works.

a <- 25   # age
# contrast for estimating OR's for given age
d <- c(1, 1, a, a) - c(1, 0, a, 0)
# estimate of log OR with standard error 
est.ln.or <- crossprod(coef(fit3.14c), d)
se.ln.or <- sqrt(t(d) %*% vcov(fit3.14c) %*% d)
# exponentiate for OR and CI
est.or <- exp(est.ln.or)
lci.or <- exp(est.ln.or - 1.96 * se.ln.or)
uci.or <- exp(est.ln.or + 1.96 * se.ln.or)


-----Original Message-----
From: Michael Dewey [mailto:lists at dewey.myzen.co.uk] 
Sent: Thursday, August 04, 2016 8:32 AM
To: Laviolette, Michael; r-help at r-project.org
Subject: Re: [R] Odds ratios in logistic regression models with interaction

Laviolette, Michael <Michael.Laviolette at dhhs.nh.gov> wrote :

> I'm trying to reproduce some results from Hosmer & Lemeshow's "Applied 
> Logistic Regression" second edition, pp. 74-79. The objective is to 
> estimate odds ratios for low weight births with interaction between 
> mother's age and weight (dichotomized at 110 lb.). I can get the point 
> estimates, but I can't find an interval option. Can anyone provide 
> guidance on computing the confidence intervals?

There is always confint. Not sure if you need MASS first from memory, not got a copy of R running to hand.


 Thanks. -Mike L.
> 
> library(dplyr)
> data(birthwt, package = "MASS")
> birthwt %
>   mutate(low = factor(low, 0:1, c("Not low", "Low")),
>          lwd = cut(lwt, c(0, 110, Inf), right = FALSE,
>                    labels = c("Less than 110", "At least 110")),
>          lwd = relevel(lwd, "At least 110"))
> 
> # p. 77, Table 3.16, Model 3
> fit3.16


From nell.redu at hotmail.fr  Thu Aug  4 01:42:05 2016
From: nell.redu at hotmail.fr (Nelly Reduan)
Date: Wed, 3 Aug 2016 23:42:05 +0000
Subject: [R] =?windows-1252?q?Error_code_100_when_using_the_function_=93fi?=
 =?windows-1252?q?tdist=94_from_the_fitdistrplus_package?=
In-Reply-To: <CY1PR05MB273009CDE13950D9A4E9B9E199060@CY1PR05MB2730.namprd05.prod.outlook.com>
References: <CY1PR05MB273009CDE13950D9A4E9B9E199060@CY1PR05MB2730.namprd05.prod.outlook.com>
Message-ID: <CY1PR05MB273096661508FB9CC810988A99060@CY1PR05MB2730.namprd05.prod.outlook.com>

Nelly Reduan has shared OneDrive?files with you. To view them, click the link or image below.


<https://1drv.ms/u/s!Apkg2VlgfYyDgQo8BnoB_Ds4KXgR>
[https://bzmvxw.by3301.livefilestore.com/y3mor2T_TYssPck9iMngzQsuiM_z140uCxN_MOvDhcRAILsrvwtWQ8cMMtzUvEuWjFYFytobNNvH8TJGzIrV7tjUHcKnVG_E76ru3RJEpGNPM3v-gKVJgYLhZPb9gLcQST6h-N6UtMumzrF9xVxCaWwJjLJ7amvLtDs816OaSSttsA?width=200&height=150&cropmode=center]<https://1drv.ms/u/s!Apkg2VlgfYyDgQo8BnoB_Ds4KXgR>


<https://1drv.ms/u/s!Apkg2VlgfYyDgQmEe6HOjP3d_4e2>
[https://r1.res.office365.com/owa/prem/images/dc-jpg_20.png]<https://1drv.ms/u/s!Apkg2VlgfYyDgQmEe6HOjP3d_4e2>

Figure_1.jpeg<https://1drv.ms/u/s!Apkg2VlgfYyDgQmEe6HOjP3d_4e2>




Hello,

I?m trying to fit distributions to data. To do this, I used the function ?fitdist? from the fitdistrplus package and I drew a Cullen and Frey graph (attached Figure 1). From this graph, I am attempting to fit different distributions: Beta, Gamma and Weibull. The function ?fitdist? works with Gamma distribution from this code:

Fit.dist <- fitdist(x[x!=0], distr="gamma", method="mle",lower=c(0, 0),start=list(scale=1,shape=1))

However, with Beta and Weibull distributions, I obtain this error message:

  the function mle failed to estimate the parameters,

                with the error code 100



Here is my code to fit Beta and Weibull distributions:

fit.dist <- fitdist(x_scaled, distr="beta", method = "mle")

fit.dist <- fitdist(x, distr="weibull", method="mle", lower=c(0, 0))

For the Beta distribution, I transformed the variable to have values between 0 and 1 as follows:

x_scaled  <- (x-min(x))/max(x)

Here are some information about data (summary() and attached Figure 2)

> summary(x)

   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.

    0.0    90.4   244.8   437.4   549.4  4904.0

 How can I fit Gamma and Weibull distributions to my data without having the error message ?

Thank you very much for your time.

Nell


	[[alternative HTML version deleted]]


From yinzun2000 at gmail.com  Thu Aug  4 10:51:22 2016
From: yinzun2000 at gmail.com (Zun Yin)
Date: Thu, 4 Aug 2016 10:51:22 +0200
Subject: [R] Fwd: only plot borders of a region in a scatter plot
In-Reply-To: <CA+cZ=YqeKtuNvmYLVPnt_xSmaH5PHwQNy3WW2MpftscB+U49oA@mail.gmail.com>
References: <CA+cZ=YqeKtuNvmYLVPnt_xSmaH5PHwQNy3WW2MpftscB+U49oA@mail.gmail.com>
Message-ID: <CA+cZ=Yo_RVG18+==rcN8gfTnf1OG_dV1p=Za5_q3kTSyvd-dNQ@mail.gmail.com>

?D?
ear all,

I have a matrix with ID of river basins (integer numbers). Now I want to
highlight one river basin in a map by plotting only the border. Like the
attached figure. Two river basins are highlighted by polygons. It is
created by ferret, but I prefer to implement it by R. Anybody know how to
do it? Thanks a lot.

Cheers,

Zun Yin
-------------- next part --------------
A non-text attachment was scrubbed...
Name: RiverBasin.pdf
Type: application/pdf
Size: 206726 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160804/748038ed/attachment.pdf>

From alain.guillet at uclouvain.be  Thu Aug  4 11:08:23 2016
From: alain.guillet at uclouvain.be (Alain Guillet)
Date: Thu, 4 Aug 2016 11:08:23 +0200
Subject: [R] ggplot2 - unexpected beahviour with facet_grid
Message-ID: <6f2e4513-e098-297c-ad2b-4f7e8d7aeda9@uclouvain.be>

Hello,

I use ggplot2 in order to represent the same data during 3 periods so I 
call facet_grid to get one subgraph by period. But when I do so, I get 
different results between the call on the whole data and the one on only 
one period (I expect to get one of the subgraphs to be identical to the 
graph obtained when using only one period).

I added the code and my session info hereunder. Could you explain me 
what I do worng or if there is a bug? Thank you.

Kind regards,
Alain

------------------------------

library(ggplot2)

# data
tmp <- 
data.frame(x=rnorm(9000),y=rnorm(9000),color=factor(rep(1:3,each=3000)),period=factor(rep(1:3,3000)),ligne=factor(rep(1:2,4500)))

# plot with the three periods
ggplot(tmp,aes(x=x,y=y,col=color,linetype=ligne))+geom_smooth()+scale_colour_manual(values=c("black","blue","yellow"))+guides(linetype=FALSE,col=FALSE)+facet_grid(period~.)

#plot with only the first period
ggplot(tmp[tmp$period=="1",],aes(x=x,y=y,col=color,linetype=ligne))+geom_smooth()+scale_colour_manual(values=c("black","blue","yellow"))+guides(linetype=FALSE,col=FALSE)+facet_grid(period~.)

------------------------------

R version 3.3.1 (2016-06-21)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux 8 (jessie)

locale:
  [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C LC_TIME=en_GB.UTF-8
  [4] LC_COLLATE=en_GB.UTF-8     LC_MONETARY=en_GB.UTF-8 
LC_MESSAGES=en_GB.UTF-8
  [7] LC_PAPER=en_GB.UTF-8       LC_NAME=C LC_ADDRESS=C
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_GB.UTF-8 
LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

other attached packages:
[1] doBy_4.5-15   ggplot2_2.1.0

loaded via a namespace (and not attached):
  [1] Rcpp_0.12.5      lattice_0.20-33  digest_0.6.9 MASS_7.3-45   
grid_3.3.1
  [6] plyr_1.8.4       nlme_3.1-128     gtable_0.2.0 magrittr_1.5   
  scales_0.4.0
[11] stringi_1.1.1    reshape2_1.4.1   Matrix_1.2-6 labeling_0.3   
  tools_3.3.1
[16] stringr_1.0.0    munsell_0.4.3    colorspace_1.2-6 mgcv_1.8-12


-- 
Alain Guillet
Statistician and Computer Scientist

SMCS - IMMAQ - Universit? catholique de Louvain
http://www.uclouvain.be/smcs

Bureau c.316
Voie du Roman Pays, 20 (bte L1.04.01)
B-1348 Louvain-la-Neuve
Belgium

Tel: +32 10 47 30 50

Acc?s: http://www.uclouvain.be/323631.html


From zhaoju.deng2014 at gmail.com  Thu Aug  4 15:43:32 2016
From: zhaoju.deng2014 at gmail.com (Zhaoju Deng)
Date: Thu, 4 Aug 2016 06:43:32 -0700 (PDT)
Subject: [R] Homals: Nonlinear PCA
In-Reply-To: <DUB115-W57BEC3681A373A6A777D11F5AC0@phx.gbl>
References: <DUB115-W3192D36982059B83C13A74F5AC0@phx.gbl>
	<DUB115-W57BEC3681A373A6A777D11F5AC0@phx.gbl>
Message-ID: <3e464912-dfd7-4893-9dcd-034f1166c00d@googlegroups.com>

Hi Lucia,
It is another problem with Homals on my own data. Have you ever got a 
eigenvalue above one? Because in my analysis homals consistently gave me 
very small eigenvalues(far below 1), I compared the eigenvalues in Homals 
and Psych, there were different, Psych always gave me high eigenvalues. you 
can find the code in attachment.
Thanks,
Zhaoju

? 2013?5?17???? UTC+2??2:16:00?l. calciano???
>
> Hello!
>
> I'm
> using the NLPCA to reduce the
> dimensionality of nine variables
> (4 nominal /
> 3 ordinal /2 numeric)
> to obtain the object-scores to be used as dependent variable in a 
> regression model. 
>
> I'm using the package homals (http://www.jstatsoft.org/v31/i04/paper). 
>
> The output is:
>
> Call: homals (date = date, Ndim = 1, rank = 1, level = c ("numerical", rep 
> ("ordinal", 3), "numerical",
> rep ("nominal", 4), active = TRUE) 
>
> Loss: 0.0002050824 
>
> Eigenvalues??: D1 0.0212
>
> I'm having
> the following questions:
>
> 1)
> Is it best to consider Ndim = rank = 1 or Ndim = rank = max (rank)  to 
> reduce the dimensionality of data? 
>
> 2) Is there a command to automatically calculate
> the proportion of variance explained
> by the first component? Otherwise, how can I calculate it by hand?3) Is it 
> necessary to standardize numeric variables before perfoming "homals"? 
>
>
>
> If anyone
> has any thoughts for this, responses would be greatly appreciated.
>
> Thanks.
>
> Lucia
>
>                                                
>                                                
>         [[alternative HTML version deleted]]
>
>

From wdunlap at tibco.com  Thu Aug  4 17:03:28 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 4 Aug 2016 08:03:28 -0700
Subject: [R] Fwd: only plot borders of a region in a scatter plot
In-Reply-To: <CA+cZ=Yo_RVG18+==rcN8gfTnf1OG_dV1p=Za5_q3kTSyvd-dNQ@mail.gmail.com>
References: <CA+cZ=YqeKtuNvmYLVPnt_xSmaH5PHwQNy3WW2MpftscB+U49oA@mail.gmail.com>
	<CA+cZ=Yo_RVG18+==rcN8gfTnf1OG_dV1p=Za5_q3kTSyvd-dNQ@mail.gmail.com>
Message-ID: <CAF8bMcbNVgHbZhBJG1+DeR8w_0nyPDyR6HR-i4Dn3bw2SO9=yw@mail.gmail.com>

If 'basinID' is the matrix of basin identifiers you could draw an outline
of the basin with identifier 'ID' with
   coutour( basiinID == ID, level=0.5)
Add 'add=TRUE' if you are overlaying this on an existing plot.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Aug 4, 2016 at 1:51 AM, Zun Yin <yinzun2000 at gmail.com> wrote:

> ?D?
> ear all,
>
> I have a matrix with ID of river basins (integer numbers). Now I want to
> highlight one river basin in a map by plotting only the border. Like the
> attached figure. Two river basins are highlighted by polygons. It is
> created by ferret, but I prefer to implement it by R. Anybody know how to
> do it? Thanks a lot.
>
> Cheers,
>
> Zun Yin
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Aug  4 17:08:25 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 4 Aug 2016 11:08:25 -0400
Subject: [R] Fwd: only plot borders of a region in a scatter plot
In-Reply-To: <CAF8bMcbNVgHbZhBJG1+DeR8w_0nyPDyR6HR-i4Dn3bw2SO9=yw@mail.gmail.com>
References: <CA+cZ=YqeKtuNvmYLVPnt_xSmaH5PHwQNy3WW2MpftscB+U49oA@mail.gmail.com>
	<CA+cZ=Yo_RVG18+==rcN8gfTnf1OG_dV1p=Za5_q3kTSyvd-dNQ@mail.gmail.com>
	<CAF8bMcbNVgHbZhBJG1+DeR8w_0nyPDyR6HR-i4Dn3bw2SO9=yw@mail.gmail.com>
Message-ID: <6ab6d706-90e9-d0b0-03bb-ab6913203f88@gmail.com>

On 04/08/2016 11:03 AM, William Dunlap via R-help wrote:
> If 'basinID' is the matrix of basin identifiers you could draw an outline
> of the basin with identifier 'ID' with
>    coutour( basiinID == ID, level=0.5)

Note the typo:  that should be

contour( basiinID == ID, level=0.5)

Duncan Murdoch

> Add 'add=TRUE' if you are overlaying this on an existing plot.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Aug 4, 2016 at 1:51 AM, Zun Yin <yinzun2000 at gmail.com> wrote:
>
>> ?D?
>> ear all,
>>
>> I have a matrix with ID of river basins (integer numbers). Now I want to
>> highlight one river basin in a map by plotting only the border. Like the
>> attached figure. Two river basins are highlighted by polygons. It is
>> created by ferret, but I prefer to implement it by R. Anybody know how to
>> do it? Thanks a lot.
>>
>> Cheers,
>>
>> Zun Yin
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Thu Aug  4 17:09:52 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 4 Aug 2016 08:09:52 -0700
Subject: [R] Fwd: only plot borders of a region in a scatter plot
In-Reply-To: <CAF8bMcbNVgHbZhBJG1+DeR8w_0nyPDyR6HR-i4Dn3bw2SO9=yw@mail.gmail.com>
References: <CA+cZ=YqeKtuNvmYLVPnt_xSmaH5PHwQNy3WW2MpftscB+U49oA@mail.gmail.com>
	<CA+cZ=Yo_RVG18+==rcN8gfTnf1OG_dV1p=Za5_q3kTSyvd-dNQ@mail.gmail.com>
	<CAF8bMcbNVgHbZhBJG1+DeR8w_0nyPDyR6HR-i4Dn3bw2SO9=yw@mail.gmail.com>
Message-ID: <CAGxFJbRAqz8Bieg2Gcp+TFQV-xbXH=PftbZBu5OArhqd6u_c6Q@mail.gmail.com>

... note the typo. It's:

contour( basiinID == ID, level=0.5)

:-)


-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Aug 4, 2016 at 8:03 AM, William Dunlap via R-help
<r-help at r-project.org> wrote:
> If 'basinID' is the matrix of basin identifiers you could draw an outline
> of the basin with identifier 'ID' with
>    coutour( basiinID == ID, level=0.5)
> Add 'add=TRUE' if you are overlaying this on an existing plot.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Aug 4, 2016 at 1:51 AM, Zun Yin <yinzun2000 at gmail.com> wrote:
>
>> D
>> ear all,
>>
>> I have a matrix with ID of river basins (integer numbers). Now I want to
>> highlight one river basin in a map by plotting only the border. Like the
>> attached figure. Two river basins are highlighted by polygons. It is
>> created by ferret, but I prefer to implement it by R. Anybody know how to
>> do it? Thanks a lot.
>>
>> Cheers,
>>
>> Zun Yin
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Aug  4 17:45:01 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 4 Aug 2016 08:45:01 -0700
Subject: [R]
 =?utf-8?q?Error_code_100_when_using_the_function_=E2=80=9Cfit?=
 =?utf-8?q?dist=E2=80=9D_from_the_fitdistrplus_package?=
In-Reply-To: <CY1PR05MB273096661508FB9CC810988A99060@CY1PR05MB2730.namprd05.prod.outlook.com>
References: <CY1PR05MB273009CDE13950D9A4E9B9E199060@CY1PR05MB2730.namprd05.prod.outlook.com>
	<CY1PR05MB273096661508FB9CC810988A99060@CY1PR05MB2730.namprd05.prod.outlook.com>
Message-ID: <5A08DA14-BDB0-4F2E-9AD9-3A2AAE38BEC3@comcast.net>


> On Aug 3, 2016, at 4:42 PM, Nelly Reduan <nell.redu at hotmail.fr> wrote:
> 
> Nelly Reduan has shared OneDrive?files with you. To view them, click the link or image below.
> 
> 
> <https://1drv.ms/u/s!Apkg2VlgfYyDgQo8BnoB_Ds4KXgR>
> [https://bzmvxw.by3301.livefilestore.com/y3mor2T_TYssPck9iMngzQsuiM_z140uCxN_MOvDhcRAILsrvwtWQ8cMMtzUvEuWjFYFytobNNvH8TJGzIrV7tjUHcKnVG_E76ru3RJEpGNPM3v-gKVJgYLhZPb9gLcQST6h-N6UtMumzrF9xVxCaWwJjLJ7amvLtDs816OaSSttsA?width=200&height=150&cropmode=center]<https://1drv.ms/u/s!Apkg2VlgfYyDgQo8BnoB_Ds4KXgR>
> 

Cannot get anything useful from that URL.

> 
> <https://1drv.ms/u/s!Apkg2VlgfYyDgQmEe6HOjP3d_4e2>
> [https://r1.res.office365.com/owa/prem/images/dc-jpg_20.png]<https://1drv.ms/u/s!Apkg2VlgfYyDgQmEe6HOjP3d_4e2>
> 
> Figure_1.jpeg<https://1drv.ms/u/s!Apkg2VlgfYyDgQmEe6HOjP3d_4e2>
> 
> 
> 
> 
> Hello,
> 
> I?m trying to fit distributions to data. To do this, I used the function ?fitdist? from the fitdistrplus package and I drew a Cullen and Frey graph (attached Figure 1). From this graph, I am attempting to fit different distributions: Beta, Gamma and Weibull. The function ?fitdist? works with Gamma distribution from this code:
> 
> Fit.dist <- fitdist(x[x!=0], distr="gamma", method="mle",lower=c(0, 0),start=list(scale=1,shape=1))
> 
> However, with Beta and Weibull distributions, I obtain this error message:
> 
>  the function mle failed to estimate the parameters,
> 
>                with the error code 100

A bit of searching produces this:

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+fitdistrplus+error+code+100#query:list%3Aorg.r-project.r-help%20fitdistrplus%20error%20code%20100+page:1+mid:esp2okcorrdichtj+state:results



-- 
David.
> 
> 
> 
> Here is my code to fit Beta and Weibull distributions:
> 
> fit.dist <- fitdist(x_scaled, distr="beta", method = "mle")
> 
> fit.dist <- fitdist(x, distr="weibull", method="mle", lower=c(0, 0))
> 
> For the Beta distribution, I transformed the variable to have values between 0 and 1 as follows:
> 
> x_scaled  <- (x-min(x))/max(x)
> 
> Here are some information about data (summary() and attached Figure 2)
> 
>> summary(x)
> 
>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> 
>    0.0    90.4   244.8   437.4   549.4  4904.0
> 
> How can I fit Gamma and Weibull distributions to my data without having the error message ?
> 
> Thank you very much for your time.
> 
> Nell
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From shivipmp82 at gmail.com  Thu Aug  4 18:50:53 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Thu, 4 Aug 2016 22:20:53 +0530
Subject: [R] Help with the RMD Output & rCharts Package
In-Reply-To: <CAB=p7SpiEEpNsFEqOgXji3wo-ittvXoaS=8LC+C_suexTrRB6g@mail.gmail.com>
References: <CAB=p7SpiEEpNsFEqOgXji3wo-ittvXoaS=8LC+C_suexTrRB6g@mail.gmail.com>
Message-ID: <CAB=p7Sq3ZFyRcfHzGEJRp99AUxAamvYddypDqbihCygd=GBy-w@mail.gmail.com>

Found an alternative,

error A) was because the score.sentiment was calling the stringr package so
called it at the start of the RMD file
error B) looked for other alternative as rcharts didnt worked

On Thu, Aug 4, 2016 at 6:39 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:

> Dear Team,
>
> I am in need of urgent help on RMD output in html.
>
> A) I am working on a sentiment analysis problem and have built a sentiment
> model which works perfectly on R Studio however the same on the RMD shows
> all the processing steps and details.
>
> I have used echo= FALSE but i still the see the output as below:
> Loading required package: stringr
> Attaching package: 'stringr'
> The following object is masked from 'package:qdap':
> The following object is masked from 'package:igraph':%>%
>
> B) i am also using rcharts to create charts on the above but as mentioned
> above i dont see output in RMD whereas i see the output in R studio. The
> code for the same is"
> p4 <- nPlot(~ score, data = abc.sentiments, type = 'pieChart')
> p4$chart(donut = TRUE)
> p4
>
>
> Please let me know if i need to share the sentiment code in a text file.
>
>
>

	[[alternative HTML version deleted]]


From tgs77m at yahoo.com  Thu Aug  4 20:05:55 2016
From: tgs77m at yahoo.com (Thomas Subia)
Date: Thu, 4 Aug 2016 18:05:55 +0000 (UTC)
Subject: [R] difftime in years
References: <262747620.11329813.1470333955573.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <262747620.11329813.1470333955573.JavaMail.yahoo@mail.yahoo.com>

Colleagues,

age_days <- difftime(Date,DOM,units="days")
date_vals$age_yrs <-  age_days/365.242

I'm trying to calculate the number of years between DOM and Date.
The output reads

             DOM               Date                 age_yrs
1 2005-04-04   2015-05-13           10.10563 days

How does one not output days?


From yinzun2000 at gmail.com  Thu Aug  4 17:46:18 2016
From: yinzun2000 at gmail.com (Zun Yin)
Date: Thu, 4 Aug 2016 17:46:18 +0200
Subject: [R] Fwd: only plot borders of a region in a scatter plot
In-Reply-To: <CAGxFJbRAqz8Bieg2Gcp+TFQV-xbXH=PftbZBu5OArhqd6u_c6Q@mail.gmail.com>
References: <CA+cZ=YqeKtuNvmYLVPnt_xSmaH5PHwQNy3WW2MpftscB+U49oA@mail.gmail.com>
	<CA+cZ=Yo_RVG18+==rcN8gfTnf1OG_dV1p=Za5_q3kTSyvd-dNQ@mail.gmail.com>
	<CAF8bMcbNVgHbZhBJG1+DeR8w_0nyPDyR6HR-i4Dn3bw2SO9=yw@mail.gmail.com>
	<CAGxFJbRAqz8Bieg2Gcp+TFQV-xbXH=PftbZBu5OArhqd6u_c6Q@mail.gmail.com>
Message-ID: <CA+cZ=YoY05=umeqPGXC44Bjkn4SX-9P2L1qc3+K5NbNNx5aOWg@mail.gmail.com>

Dear William, Duncan and Bert,

Thanks a lot for your help and tips :D In fact the contour() plot still
cannot solve my problem perfectly. As the resolution of my plot is very
coarse, I want to a contour perfectly surround all grid cells in the river
basin. In another word, I want all angle of the contour to be 90 degree.
Another problem for the contour() is that the contour line doesn't close at
where the value of neighbouring grid cell is NA. See the right side of the
two contour lines (attachment). Do you know how I can get what I want?
Thanks a lot :P

Cheers,


Zun Yin

On Thu, Aug 4, 2016 at 5:09 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> ... note the typo. It's:
>
> contour( basiinID == ID, level=0.5)
>
> :-)
>
>
> -- Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Aug 4, 2016 at 8:03 AM, William Dunlap via R-help
> <r-help at r-project.org> wrote:
> > If 'basinID' is the matrix of basin identifiers you could draw an outline
> > of the basin with identifier 'ID' with
> >    coutour( basiinID == ID, level=0.5)
> > Add 'add=TRUE' if you are overlaying this on an existing plot.
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Thu, Aug 4, 2016 at 1:51 AM, Zun Yin <yinzun2000 at gmail.com> wrote:
> >
> >> D
> >> ear all,
> >>
> >> I have a matrix with ID of river basins (integer numbers). Now I want to
> >> highlight one river basin in a map by plotting only the border. Like the
> >> attached figure. Two river basins are highlighted by polygons. It is
> >> created by ferret, but I prefer to implement it by R. Anybody know how
> to
> >> do it? Thanks a lot.
> >>
> >> Cheers,
> >>
> >> Zun Yin
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: basin.pdf
Type: application/pdf
Size: 21661 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160804/23029b7a/attachment.pdf>

From Michael.Laviolette at dhhs.nh.gov  Thu Aug  4 22:00:55 2016
From: Michael.Laviolette at dhhs.nh.gov (Laviolette, Michael)
Date: Thu, 4 Aug 2016 20:00:55 +0000
Subject: [R] Odds ratios in logistic regression models with interaction
In-Reply-To: <958AA24C-1FB2-4FBF-BB3C-37A4524F941D@gmail.com>
References: <1ef0e1f6c9244fbb8e57f552585fb81c@dhhs.nh.gov>
	<958AA24C-1FB2-4FBF-BB3C-37A4524F941D@gmail.com>
Message-ID: <bbe5f5c8bc47415b8cd83207ac9d3f94@dhhs.nh.gov>

Thanks. I came to the same realization after the original post and was able to get the correct results with the coefficient vector and covariance matrix by setting up as a contrast. Linear model contrast estimation in R doesn't seem straightforward. I turned up several packages, but any recommendations you might have would be very useful. Thanks again. --M.L.

a <- 25   # age for which to compute OR's
d <- c(1, 1, a, a) - c(1, 0, a, 0)   # contrast
est.ln.or <- crossprod(coef(fit3.16), d)
se.ln.or <- sqrt(t(d) %*% vcov(fit3.16) %*% d)
exp(est.ln.or)
# [1,] 3.899427
exp(est.ln.or - 1.96 * se.ln.or)
# [1,] 1.712885
exp(est.ln.or + 1.96 * se.ln.or)
# [1,] 8.877148

-----Original Message-----
From: peter dalgaard [mailto:pdalgd at gmail.com] 
Sent: Thursday, August 04, 2016 9:12 AM
To: Laviolette, Michael
Cc: r-help at r-project.org
Subject: Re: [R] Odds ratios in logistic regression models with interaction

I suspect that "you can't get there from here"... a1$fit and a2$fit are not independent, so you can't work out the s.e. of their difference using sqrt(a1$se.fit^2+a2$se.fit^2). 

You need to backtrack a bit and figure out how a1$fit-a2$fit relates to coef(fit3.16). I suspect it is actually just the age times the interaction term, but since you give no output and your code uses a bunch of stuff that I haven't got installed, I can't be bothered to check....  

Once you have your desired value in the form t(a) %*% coef(...), then use the result that V(t(a) %*% betahat) == t(a) %*% vcov() %*% a  (asymptotically).

-pd

On 03 Aug 2016, at 15:08 , Laviolette, Michael <Michael.Laviolette at dhhs.nh.gov> wrote:

> I'm trying to reproduce some results from Hosmer & Lemeshow's "Applied Logistic Regression" second edition, pp. 74-79. The objective is to estimate odds ratios for low weight births with interaction between mother's age and weight (dichotomized at 110 lb.). I can get the point estimates, but I can't find an interval option. Can anyone provide guidance on computing the confidence intervals? Thanks. -Mike L.
> 
> library(dplyr)
> data(birthwt, package = "MASS")
> birthwt <- birthwt %>%
>  mutate(low = factor(low, 0:1, c("Not low", "Low")),
>         lwd = cut(lwt, c(0, 110, Inf), right = FALSE,
>                   labels = c("Less than 110", "At least 110")),
>         lwd = relevel(lwd, "At least 110"))
> 
> # p. 77, Table 3.16, Model 3
> fit3.16 <- glm(low ~ lwd * age, binomial, birthwt) # p. 78, 
> interaction plot visreg::visreg(fit3.16, "age", by = "lwd", xlab = 
> "Age",
>               ylab = "Estimated logit") # p. 78, covariance matrix
> vcov(fit3.16)
> # odds ratios for ages 15, 20, 25, 30
> age0 <- seq(15, 30, 5)
> df1 <- data.frame(lwd = "Less than 110", age = age0)
> df2 <- data.frame(lwd = "At least 110", age = age0)
> a1 <- predict(fit3.16, df1, se.fit = TRUE)
> a2 <- predict(fit3.16, df2, se.fit = TRUE) # p. 79, point estimates 
> exp(a1$fit - a2$fit)
> 
> # How to get CI's?
> # Age    OR     (95% CI)
> # ----------------------
> # 15   1.04 (0.29, 3.79)
> # 20   2.01 (0.91, 4.44)
> # 25   3.90 (1.71, 8.88)
> # 30   7.55 (1.95, 29.19)
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Thu Aug  4 22:08:17 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 4 Aug 2016 16:08:17 -0400
Subject: [R] Fwd: only plot borders of a region in a scatter plot
In-Reply-To: <CA+cZ=YoY05=umeqPGXC44Bjkn4SX-9P2L1qc3+K5NbNNx5aOWg@mail.gmail.com>
References: <CA+cZ=YqeKtuNvmYLVPnt_xSmaH5PHwQNy3WW2MpftscB+U49oA@mail.gmail.com>
	<CA+cZ=Yo_RVG18+==rcN8gfTnf1OG_dV1p=Za5_q3kTSyvd-dNQ@mail.gmail.com>
	<CAF8bMcbNVgHbZhBJG1+DeR8w_0nyPDyR6HR-i4Dn3bw2SO9=yw@mail.gmail.com>
	<CAGxFJbRAqz8Bieg2Gcp+TFQV-xbXH=PftbZBu5OArhqd6u_c6Q@mail.gmail.com>
	<CA+cZ=YoY05=umeqPGXC44Bjkn4SX-9P2L1qc3+K5NbNNx5aOWg@mail.gmail.com>
Message-ID: <153086f7-16fa-f18f-324a-4ad70bf8eb6d@gmail.com>

On 04/08/2016 11:46 AM, Zun Yin wrote:
> Dear William, Duncan and Bert,
>
> Thanks a lot for your help and tips :D In fact the contour() plot still
> cannot solve my problem perfectly. As the resolution of my plot is very
> coarse, I want to a contour perfectly surround all grid cells in the river
> basin. In another word, I want all angle of the contour to be 90 degree.
> Another problem for the contour() is that the contour line doesn't close at
> where the value of neighbouring grid cell is NA. See the right side of the
> two contour lines (attachment). Do you know how I can get what I want?
> Thanks a lot :P

The second problem is easy:  just change your NA values to some new ID 
value, or change the test from

basiinID == ID

to

!is.na(basiinID) & basiinID == ID

The first one looks harder.

Duncan Murdoch

>
> Cheers,
>
>
> Zun Yin
>
> On Thu, Aug 4, 2016 at 5:09 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>> ... note the typo. It's:
>>
>> contour( basiinID == ID, level=0.5)
>>
>> :-)
>>
>>
>> -- Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Aug 4, 2016 at 8:03 AM, William Dunlap via R-help
>> <r-help at r-project.org> wrote:
>>> If 'basinID' is the matrix of basin identifiers you could draw an outline
>>> of the basin with identifier 'ID' with
>>>    coutour( basiinID == ID, level=0.5)
>>> Add 'add=TRUE' if you are overlaying this on an existing plot.
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>> On Thu, Aug 4, 2016 at 1:51 AM, Zun Yin <yinzun2000 at gmail.com> wrote:
>>>
>>>> D
>>>> ear all,
>>>>
>>>> I have a matrix with ID of river basins (integer numbers). Now I want to
>>>> highlight one river basin in a map by plotting only the border. Like the
>>>> attached figure. Two river basins are highlighted by polygons. It is
>>>> created by ferret, but I prefer to implement it by R. Anybody know how
>> to
>>>> do it? Thanks a lot.
>>>>
>>>> Cheers,
>>>>
>>>> Zun Yin
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu Aug  4 22:35:16 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 4 Aug 2016 13:35:16 -0700
Subject: [R] difftime in years
In-Reply-To: <262747620.11329813.1470333955573.JavaMail.yahoo@mail.yahoo.com>
References: <262747620.11329813.1470333955573.JavaMail.yahoo.ref@mail.yahoo.com>
	<262747620.11329813.1470333955573.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAF8bMcb0JK2e3Fa8+keZ6WeAESq=bQERbVbqdKZod2fbFby9JA@mail.gmail.com>

difftime objects do not accept 'years' as a value for 'units', so you have
to change it to numeric.

    as.numeric(age_days, units="days") / 365.242

The units="days" is not needed since you specified it in the call
to difftime, but it needs to be in one of those places.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Aug 4, 2016 at 11:05 AM, Thomas Subia via R-help <
r-help at r-project.org> wrote:

> Colleagues,
>
> age_days <- difftime(Date,DOM,units="days")
> date_vals$age_yrs <-  age_days/365.242
>
> I'm trying to calculate the number of years between DOM and Date.
> The output reads
>
>              DOM               Date                 age_yrs
> 1 2005-04-04   2015-05-13           10.10563 days
>
> How does one not output days?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From nell.redu at hotmail.fr  Thu Aug  4 22:56:25 2016
From: nell.redu at hotmail.fr (Nelly Reduan)
Date: Thu, 4 Aug 2016 20:56:25 +0000
Subject: [R]
 =?windows-1252?q?Error_code_100_when_using_the_function_=93fi?=
 =?windows-1252?q?tdist=94_from_the_fitdistrplus_package?=
In-Reply-To: <5A08DA14-BDB0-4F2E-9AD9-3A2AAE38BEC3@comcast.net>
References: <CY1PR05MB273009CDE13950D9A4E9B9E199060@CY1PR05MB2730.namprd05.prod.outlook.com>
	<CY1PR05MB273096661508FB9CC810988A99060@CY1PR05MB2730.namprd05.prod.outlook.com>,
	<5A08DA14-BDB0-4F2E-9AD9-3A2AAE38BEC3@comcast.net>
Message-ID: <CY1PR05MB27309B388709ADB84BF5E71899070@CY1PR05MB2730.namprd05.prod.outlook.com>

Hello,


Thanks David for your answer. I tested different parameters for Beta and Weibull distributions based on forums but I didn't find solutions.


Thank you very much for your time.

Have a nice day

Nell

________________________________
De : David Winsemius <dwinsemius at comcast.net>
Envoy? : jeudi 4 ao?t 2016 08:45:01
? : Nelly Reduan
Cc : r-help at r-project.org
Objet : Re: [R] Error code 100 when using the function ?fitdist? from the fitdistrplus package


> On Aug 3, 2016, at 4:42 PM, Nelly Reduan <nell.redu at hotmail.fr> wrote:
>
> Nelly Reduan has shared OneDrive?files with you. To view them, click the link or image below.
>
>
> <https://1drv.ms/u/s!Apkg2VlgfYyDgQo8BnoB_Ds4KXgR>
> [https://bzmvxw.by3301.livefilestore.com/y3mor2T_TYssPck9iMngzQsuiM_z140uCxN_MOvDhcRAILsrvwtWQ8cMMtzUvEuWjFYFytobNNvH8TJGzIrV7tjUHcKnVG_E76ru3RJEpGNPM3v-gKVJgYLhZPb9gLcQST6h-N6UtMumzrF9xVxCaWwJjLJ7amvLtDs816OaSSttsA?width=200&height=150&cropmode=center]<https://1drv.ms/u/s!Apkg2VlgfYyDgQo8BnoB_Ds4KXgR>
>

Cannot get anything useful from that URL.

>
> <https://1drv.ms/u/s!Apkg2VlgfYyDgQmEe6HOjP3d_4e2>
> [https://r1.res.office365.com/owa/prem/images/dc-jpg_20.png]<https://1drv.ms/u/s!Apkg2VlgfYyDgQmEe6HOjP3d_4e2>
>
> Figure_1.jpeg<https://1drv.ms/u/s!Apkg2VlgfYyDgQmEe6HOjP3d_4e2>
>
>
>
>
> Hello,
>
> I?m trying to fit distributions to data. To do this, I used the function ?fitdist? from the fitdistrplus package and I drew a Cullen and Frey graph (attached Figure 1). From this graph, I am attempting to fit different distributions: Beta, Gamma and Weibull. The function ?fitdist? works with Gamma distribution from this code:
>
> Fit.dist <- fitdist(x[x!=0], distr="gamma", method="mle",lower=c(0, 0),start=list(scale=1,shape=1))
>
> However, with Beta and Weibull distributions, I obtain this error message:
>
>  the function mle failed to estimate the parameters,
>
>                with the error code 100

A bit of searching produces this:

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+fitdistrplus+error+code+100#query:list%3Aorg.r-project.r-help%20fitdistrplus%20error%20code%20100+page:1+mid:esp2okcorrdichtj+state:results



--
David.
>
>
>
> Here is my code to fit Beta and Weibull distributions:
>
> fit.dist <- fitdist(x_scaled, distr="beta", method = "mle")
>
> fit.dist <- fitdist(x, distr="weibull", method="mle", lower=c(0, 0))
>
> For the Beta distribution, I transformed the variable to have values between 0 and 1 as follows:
>
> x_scaled  <- (x-min(x))/max(x)
>
> Here are some information about data (summary() and attached Figure 2)
>
>> summary(x)
>
>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>
>    0.0    90.4   244.8   437.4   549.4  4904.0
>
> How can I fit Gamma and Weibull distributions to my data without having the error message ?
>
> Thank you very much for your time.
>
> Nell
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Aug  4 23:36:34 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 4 Aug 2016 23:36:34 +0200
Subject: [R] Odds ratios in logistic regression models with interaction
In-Reply-To: <bbe5f5c8bc47415b8cd83207ac9d3f94@dhhs.nh.gov>
References: <1ef0e1f6c9244fbb8e57f552585fb81c@dhhs.nh.gov>
	<958AA24C-1FB2-4FBF-BB3C-37A4524F941D@gmail.com>
	<bbe5f5c8bc47415b8cd83207ac9d3f94@dhhs.nh.gov>
Message-ID: <31DCFB5F-BC80-42DD-AA40-D4D09DB02D83@gmail.com>


> On 04 Aug 2016, at 22:00 , Laviolette, Michael <Michael.Laviolette at dhhs.nh.gov> wrote:
> 
> Thanks. I came to the same realization after the original post and was able to get the correct results with the coefficient vector and covariance matrix by setting up as a contrast. Linear model contrast estimation in R doesn't seem straightforward. I turned up several packages, but any recommendations you might have would be very useful. Thanks again. --M.L.

For full generality contrasts, it doesn't really get much simpler that what you do below. Any "smart" way of specifying your "d" vector ends up with some "d" not specifiable.

The only neat thing I can think of is that you can do multiple contrasts with a matrix D instead of a vector D as

z <- D %*% coef(fit)

and then, although correct, you do not want to get se.fit as sqrt(diag(D %*% vcov(fit) %*% t(D))) if D has a substantial number of rows. Rather, you do it as 

rowSums((D %*% vcov(fit)) * D).

-ps

> 
> a <- 25   # age for which to compute OR's
> d <- c(1, 1, a, a) - c(1, 0, a, 0)   # contrast
> est.ln.or <- crossprod(coef(fit3.16), d)
> se.ln.or <- sqrt(t(d) %*% vcov(fit3.16) %*% d)
> exp(est.ln.or)
> # [1,] 3.899427
> exp(est.ln.or - 1.96 * se.ln.or)
> # [1,] 1.712885
> exp(est.ln.or + 1.96 * se.ln.or)
> # [1,] 8.877148
> 
> -----Original Message-----
> From: peter dalgaard [mailto:pdalgd at gmail.com] 
> Sent: Thursday, August 04, 2016 9:12 AM
> To: Laviolette, Michael
> Cc: r-help at r-project.org
> Subject: Re: [R] Odds ratios in logistic regression models with interaction
> 
> I suspect that "you can't get there from here"... a1$fit and a2$fit are not independent, so you can't work out the s.e. of their difference using sqrt(a1$se.fit^2+a2$se.fit^2). 
> 
> You need to backtrack a bit and figure out how a1$fit-a2$fit relates to coef(fit3.16). I suspect it is actually just the age times the interaction term, but since you give no output and your code uses a bunch of stuff that I haven't got installed, I can't be bothered to check....  
> 
> Once you have your desired value in the form t(a) %*% coef(...), then use the result that V(t(a) %*% betahat) == t(a) %*% vcov() %*% a  (asymptotically).
> 
> -pd
> 
> On 03 Aug 2016, at 15:08 , Laviolette, Michael <Michael.Laviolette at dhhs.nh.gov> wrote:
> 
>> I'm trying to reproduce some results from Hosmer & Lemeshow's "Applied Logistic Regression" second edition, pp. 74-79. The objective is to estimate odds ratios for low weight births with interaction between mother's age and weight (dichotomized at 110 lb.). I can get the point estimates, but I can't find an interval option. Can anyone provide guidance on computing the confidence intervals? Thanks. -Mike L.
>> 
>> library(dplyr)
>> data(birthwt, package = "MASS")
>> birthwt <- birthwt %>%
>> mutate(low = factor(low, 0:1, c("Not low", "Low")),
>>        lwd = cut(lwt, c(0, 110, Inf), right = FALSE,
>>                  labels = c("Less than 110", "At least 110")),
>>        lwd = relevel(lwd, "At least 110"))
>> 
>> # p. 77, Table 3.16, Model 3
>> fit3.16 <- glm(low ~ lwd * age, binomial, birthwt) # p. 78, 
>> interaction plot visreg::visreg(fit3.16, "age", by = "lwd", xlab = 
>> "Age",
>>              ylab = "Estimated logit") # p. 78, covariance matrix
>> vcov(fit3.16)
>> # odds ratios for ages 15, 20, 25, 30
>> age0 <- seq(15, 30, 5)
>> df1 <- data.frame(lwd = "Less than 110", age = age0)
>> df2 <- data.frame(lwd = "At least 110", age = age0)
>> a1 <- predict(fit3.16, df1, se.fit = TRUE)
>> a2 <- predict(fit3.16, df2, se.fit = TRUE) # p. 79, point estimates 
>> exp(a1$fit - a2$fit)
>> 
>> # How to get CI's?
>> # Age    OR     (95% CI)
>> # ----------------------
>> # 15   1.04 (0.29, 3.79)
>> # 20   2.01 (0.91, 4.44)
>> # 25   3.90 (1.71, 8.88)
>> # 30   7.55 (1.95, 29.19)
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From drjimlemon at gmail.com  Fri Aug  5 01:21:47 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 5 Aug 2016 09:21:47 +1000
Subject: [R]
	=?utf-8?q?Error_code_100_when_using_the_function_=E2=80=9Cfit?=
	=?utf-8?q?dist=E2=80=9D_from_the_fitdistrplus_package?=
In-Reply-To: <CY1PR05MB27309B388709ADB84BF5E71899070@CY1PR05MB2730.namprd05.prod.outlook.com>
References: <CY1PR05MB273009CDE13950D9A4E9B9E199060@CY1PR05MB2730.namprd05.prod.outlook.com>
	<CY1PR05MB273096661508FB9CC810988A99060@CY1PR05MB2730.namprd05.prod.outlook.com>
	<5A08DA14-BDB0-4F2E-9AD9-3A2AAE38BEC3@comcast.net>
	<CY1PR05MB27309B388709ADB84BF5E71899070@CY1PR05MB2730.namprd05.prod.outlook.com>
Message-ID: <CA+8X3fWmG4GkqFfe0BOUfbwd1p_vZLLzD8OJ09djTPs_f5cdNw@mail.gmail.com>

Hi Nelly,
The message David suggested was about scaling the values, not
adjusting the parameters. It is quite possible that the empirical
distribution is nothing like beta or Weibull. Have you tried plotting
the values with "density"?

Jim


On Fri, Aug 5, 2016 at 6:56 AM, Nelly Reduan <nell.redu at hotmail.fr> wrote:
> Hello,
>
>
> Thanks David for your answer. I tested different parameters for Beta and Weibull distributions based on forums but I didn't find solutions.
>
>
> Thank you very much for your time.
>
> Have a nice day
>
> Nell
>
> ________________________________
> De : David Winsemius <dwinsemius at comcast.net>
> Envoy? : jeudi 4 ao?t 2016 08:45:01
> ? : Nelly Reduan
> Cc : r-help at r-project.org
> Objet : Re: [R] Error code 100 when using the function ?fitdist? from the fitdistrplus package
>
>
>> On Aug 3, 2016, at 4:42 PM, Nelly Reduan <nell.redu at hotmail.fr> wrote:
>>
>> Nelly Reduan has shared OneDrive?files with you. To view them, click the link or image below.
>>
>>
>> <https://1drv.ms/u/s!Apkg2VlgfYyDgQo8BnoB_Ds4KXgR>
>> [https://bzmvxw.by3301.livefilestore.com/y3mor2T_TYssPck9iMngzQsuiM_z140uCxN_MOvDhcRAILsrvwtWQ8cMMtzUvEuWjFYFytobNNvH8TJGzIrV7tjUHcKnVG_E76ru3RJEpGNPM3v-gKVJgYLhZPb9gLcQST6h-N6UtMumzrF9xVxCaWwJjLJ7amvLtDs816OaSSttsA?width=200&height=150&cropmode=center]<https://1drv.ms/u/s!Apkg2VlgfYyDgQo8BnoB_Ds4KXgR>
>>
>
> Cannot get anything useful from that URL.
>
>>
>> <https://1drv.ms/u/s!Apkg2VlgfYyDgQmEe6HOjP3d_4e2>
>> [https://r1.res.office365.com/owa/prem/images/dc-jpg_20.png]<https://1drv.ms/u/s!Apkg2VlgfYyDgQmEe6HOjP3d_4e2>
>>
>> Figure_1.jpeg<https://1drv.ms/u/s!Apkg2VlgfYyDgQmEe6HOjP3d_4e2>
>>
>>
>>
>>
>> Hello,
>>
>> I?m trying to fit distributions to data. To do this, I used the function ?fitdist? from the fitdistrplus package and I drew a Cullen and Frey graph (attached Figure 1). From this graph, I am attempting to fit different distributions: Beta, Gamma and Weibull. The function ?fitdist? works with Gamma distribution from this code:
>>
>> Fit.dist <- fitdist(x[x!=0], distr="gamma", method="mle",lower=c(0, 0),start=list(scale=1,shape=1))
>>
>> However, with Beta and Weibull distributions, I obtain this error message:
>>
>>  the function mle failed to estimate the parameters,
>>
>>                with the error code 100
>
> A bit of searching produces this:
>
> http://markmail.org/search/?q=list%3Aorg.r-project.r-help+fitdistrplus+error+code+100#query:list%3Aorg.r-project.r-help%20fitdistrplus%20error%20code%20100+page:1+mid:esp2okcorrdichtj+state:results
>
>
>
> --
> David.
>>
>>
>>
>> Here is my code to fit Beta and Weibull distributions:
>>
>> fit.dist <- fitdist(x_scaled, distr="beta", method = "mle")
>>
>> fit.dist <- fitdist(x, distr="weibull", method="mle", lower=c(0, 0))
>>
>> For the Beta distribution, I transformed the variable to have values between 0 and 1 as follows:
>>
>> x_scaled  <- (x-min(x))/max(x)
>>
>> Here are some information about data (summary() and attached Figure 2)
>>
>>> summary(x)
>>
>>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>
>>    0.0    90.4   244.8   437.4   549.4  4904.0
>>
>> How can I fit Gamma and Weibull distributions to my data without having the error message ?
>>
>> Thank you very much for your time.
>>
>> Nell
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Alexander.Herr at csiro.au  Fri Aug  5 01:29:01 2016
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Thu, 4 Aug 2016 23:29:01 +0000
Subject: [R] foreach {parallel} nested with for loop to update
 data.frame column
Message-ID: <6429e494e198487fb4fb6c5bcf368a6d@exch1-mel.nexus.csiro.au>

Hiya,
Yes that would work, also an aggregate with merge can work, but I really would like to make this a parallel calculation with farming out the first loop to different workers and put the output together again into the data.frame with additional columns. This will speed up work with very large files and avoid running out of memory issues

Cheers
H
XXXXXXXXXXXXXXXXXXXXXX Petr wrote XXXXXXXXXXXXXXXXXXXXXXXXXXXX
Hi 

I may be completely wrong but isn't it work for ave? With your example I get 

> fac<-interaction(xyz[,1], xyz[,2], drop=TRUE) 
> xyz[,4]<-ave(xyz$z, fac, FUN= min) 
> head(xyz) 
? ?x ?y ? ? z ?mins 
1 13 15 ?1.97 -2.91 
2 17 ?9 14.90 -2.81 
3 ?9 10 34.68 -1.97 
4 17 ?6 ?4.26 -2.63 
5 ?3 12 ?0.12 ?0.12 
6 19 11 ?7.91 ?7.91 
> 

Cheers 
Petr 

> -----Original Message----- 
> From: R-help [mailto:[hidden email]] On Behalf Of 
> [hidden email] 
> Sent: Thursday, August 4, 2016 3:32 AM 
> To: [hidden email] 
> Subject: [R] foreach {parallel} nested with for loop to update data.frame 
> column 
> 
> Hi List, 
> 
> Trying to update a data.frame column within a foreach nested for loop 
> 
> ### trial data 
> set.seed(666) 
> xyz<-as.data.frame(cbind(x=rep(rpois(5000,10),2)+1, 
> y=rep(rpois(5000,10),2)+1,z=round(runif(10000, min=-3, max=40),2))) 
> xyz$mins<-rep(NA, nrow(xyz)) 
> 
> cl<-makeCluster(16) ?#adjust to your cluster number 
> registerDoParallel(cl) 
> 
> counter=0 
> foreach(i=unique(xyz[,1]), .combine=data.frame, .verbose=T) %dopar% { 
> ? ? ? ? for( j in unique(xyz[,2])) { 
> ? ? ? ? ? ? ? ? xyz[xyz[,2] == j ,4]<-min(xyz[xyz[,2] == j ,2]) 
> ? ? ? ? } 
> 
> } 
> 
> stopCluster(cl) 
> 
> This is obviously not working. Any hints? 
> 
> Thanx 
> Herry 


From drjimlemon at gmail.com  Fri Aug  5 01:34:25 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 5 Aug 2016 09:34:25 +1000
Subject: [R] difftime in years
In-Reply-To: <CAF8bMcb0JK2e3Fa8+keZ6WeAESq=bQERbVbqdKZod2fbFby9JA@mail.gmail.com>
References: <262747620.11329813.1470333955573.JavaMail.yahoo.ref@mail.yahoo.com>
	<262747620.11329813.1470333955573.JavaMail.yahoo@mail.yahoo.com>
	<CAF8bMcb0JK2e3Fa8+keZ6WeAESq=bQERbVbqdKZod2fbFby9JA@mail.gmail.com>
Message-ID: <CA+8X3fXRu6pawZHza9cO3=S2iOFFSMjRj5SYAsJox_U5aHFjpA@mail.gmail.com>

Hi Thomas,
Be aware that if you are attempting to calculate "birthday age", it is
probably better to do it like this:

bdage<-function(dob,now) {
 dobbits<-as.numeric(unlist(strsplit(dob,"/")))
 nowbits<-as.numeric(unlist(strsplit(now,"/")))
 return(nowbits[3]-dobbits[3]-
  (nowbits[2]<dobbits[2] || (nowbits[2]==dobbits[2] && nowbits[1]<dobbits[1])))
}
bdage("20/09/1945","5/8/2016")

You can also do this with date objects, just add the appropriate
format arguments.

Jim


Jim

On Fri, Aug 5, 2016 at 6:35 AM, William Dunlap via R-help
<r-help at r-project.org> wrote:
> difftime objects do not accept 'years' as a value for 'units', so you have
> to change it to numeric.
>
>     as.numeric(age_days, units="days") / 365.242
>
> The units="days" is not needed since you specified it in the call
> to difftime, but it needs to be in one of those places.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Aug 4, 2016 at 11:05 AM, Thomas Subia via R-help <
> r-help at r-project.org> wrote:
>
>> Colleagues,
>>
>> age_days <- difftime(Date,DOM,units="days")
>> date_vals$age_yrs <-  age_days/365.242
>>
>> I'm trying to calculate the number of years between DOM and Date.
>> The output reads
>>
>>              DOM               Date                 age_yrs
>> 1 2005-04-04   2015-05-13           10.10563 days
>>
>> How does one not output days?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Alexander.Herr at csiro.au  Fri Aug  5 02:23:46 2016
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Fri, 5 Aug 2016 00:23:46 +0000
Subject: [R] foreach {parallel} nested with for loop to update
 data.frame column
Message-ID: <7d0f97a821e4428b9beb0b19597e7b60@exch1-mel.nexus.csiro.au>


Hiya,

This now works...

test<-foreach(i=unique(xyz[,1]), .combine=rbind, .verbose=T) %dopar% {
         for( j in unique(xyz[,2])) {
         xyz[xyz[,2] == j & xyz[,1] == i ,4]<-min(xyz[xyz[,2] == j & xyz[,1] == i,3]) 
	nr=nrow(xyz[xyz[,2] == j & xyz[,1] == i ,4])
        }
        return(xyz[xyz[,1]== i,])  # you must return what you are farming out...
}
head(test)

-----Original Message-----
From: Herr, Alexander Herr - Herry (L&W, Black Mountain)
Sent: Friday, 5 August 2016 9:29 AM
To: 'R-Help (r-help at stat.math.ethz.ch)' <r-help at stat.math.ethz.ch>
Subject: Re: foreach {parallel} nested with for loop to update data.frame column 

Hiya,
Yes that would work, also an aggregate with merge can work, but I really would like to make this a parallel calculation with farming out the first loop to different workers and put the output together again into the data.frame with additional columns. This will speed up work with very large files and avoid running out of memory issues

Cheers
H
XXXXXXXXXXXXXXXXXXXXXX Petr wrote XXXXXXXXXXXXXXXXXXXXXXXXXXXX Hi 

I may be completely wrong but isn't it work for ave? With your example I get 

> fac<-interaction(xyz[,1], xyz[,2], drop=TRUE) xyz[,4]<-ave(xyz$z, fac, 
> FUN= min)
> head(xyz)
? ?x ?y ? ? z ?mins
1 13 15 ?1.97 -2.91
2 17 ?9 14.90 -2.81
3 ?9 10 34.68 -1.97
4 17 ?6 ?4.26 -2.63
5 ?3 12 ?0.12 ?0.12
6 19 11 ?7.91 ?7.91 
> 

Cheers
Petr 

> -----Original Message-----
> From: R-help [mailto:[hidden email]] On Behalf Of [hidden email]
> Sent: Thursday, August 4, 2016 3:32 AM
> To: [hidden email]
> Subject: [R] foreach {parallel} nested with for loop to update 
> data.frame column
> 
> Hi List,
> 
> Trying to update a data.frame column within a foreach nested for loop
> 
> ### trial data
> set.seed(666)
> xyz<-as.data.frame(cbind(x=rep(rpois(5000,10),2)+1,
> y=rep(rpois(5000,10),2)+1,z=round(runif(10000, min=-3, max=40),2))) 
> xyz$mins<-rep(NA, nrow(xyz))
> 
> cl<-makeCluster(16) ?#adjust to your cluster number
> registerDoParallel(cl)
> 
> counter=0
> foreach(i=unique(xyz[,1]), .combine=data.frame, .verbose=T) %dopar% {
> ? ? ? ? for( j in unique(xyz[,2])) {
> ? ? ? ? ? ? ? ? xyz[xyz[,2] == j ,4]<-min(xyz[xyz[,2] == j ,2])
> ? ? ? ? }
> 
> }
> 
> stopCluster(cl)
> 
> This is obviously not working. Any hints? 
> 
> Thanx
> Herry


From drjimlemon at gmail.com  Fri Aug  5 03:40:11 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 5 Aug 2016 11:40:11 +1000
Subject: [R] Fwd: only plot borders of a region in a scatter plot
In-Reply-To: <153086f7-16fa-f18f-324a-4ad70bf8eb6d@gmail.com>
References: <CA+cZ=YqeKtuNvmYLVPnt_xSmaH5PHwQNy3WW2MpftscB+U49oA@mail.gmail.com>
	<CA+cZ=Yo_RVG18+==rcN8gfTnf1OG_dV1p=Za5_q3kTSyvd-dNQ@mail.gmail.com>
	<CAF8bMcbNVgHbZhBJG1+DeR8w_0nyPDyR6HR-i4Dn3bw2SO9=yw@mail.gmail.com>
	<CAGxFJbRAqz8Bieg2Gcp+TFQV-xbXH=PftbZBu5OArhqd6u_c6Q@mail.gmail.com>
	<CA+cZ=YoY05=umeqPGXC44Bjkn4SX-9P2L1qc3+K5NbNNx5aOWg@mail.gmail.com>
	<153086f7-16fa-f18f-324a-4ad70bf8eb6d@gmail.com>
Message-ID: <CA+8X3fUu1i_zQQ5XBrg4udnA6ATw2hrVRHG+t=KA8uqSKRzfgg@mail.gmail.com>

Hi Zun Yin,
The first problem requires something like this:

pixel8<-function(x,y,pixsize=1) {
 nsteps<-length(x)-1
 newx<-x[1]
 newy<-y[1]
 for(i in 1:nsteps) {
  dx<-diff(x[i:(i+1)])
  dy<-diff(y[i:(i+1)])
  if(dx && dy) {
   newx<-c(newx,x[i]+dx,x[i]+dx)
   newy<-c(newy,y[i],y[i]+dy)
  }
  else {
   newx<-c(newx,x[i+1])
   newy<-c(newy,y[i+1])
  }
 }
 return(list(x=newx,y=newy))
}

I think that this does part of what you want. Your points seem to be
in the middle of a pixel edge, so an offset would have to be added to
align the resulting points with the corners. The other thing to work
out is the order of changing x and y on a slope, which I think is a
function of whether the line is "inside" or "outside" the overall area
enclosed. I'll post again if I have any brilliant ideas.

Jim


On Fri, Aug 5, 2016 at 6:08 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 04/08/2016 11:46 AM, Zun Yin wrote:
>>
>> Dear William, Duncan and Bert,
>>
>> Thanks a lot for your help and tips :D In fact the contour() plot still
>> cannot solve my problem perfectly. As the resolution of my plot is very
>> coarse, I want to a contour perfectly surround all grid cells in the river
>> basin. In another word, I want all angle of the contour to be 90 degree.
>> Another problem for the contour() is that the contour line doesn't close
>> at
>> where the value of neighbouring grid cell is NA. See the right side of the
>> two contour lines (attachment). Do you know how I can get what I want?
>> Thanks a lot :P
>
>
> The second problem is easy:  just change your NA values to some new ID
> value, or change the test from
>
> basiinID == ID
>
> to
>
> !is.na(basiinID) & basiinID == ID
>
> The first one looks harder.
>
> Duncan Murdoch
>
>
>>
>> Cheers,
>>
>>
>> Zun Yin
>>
>> On Thu, Aug 4, 2016 at 5:09 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>
>>> ... note the typo. It's:
>>>
>>> contour( basiinID == ID, level=0.5)
>>>
>>> :-)
>>>
>>>
>>> -- Bert
>>>
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Thu, Aug 4, 2016 at 8:03 AM, William Dunlap via R-help
>>> <r-help at r-project.org> wrote:
>>>>
>>>> If 'basinID' is the matrix of basin identifiers you could draw an
>>>> outline
>>>> of the basin with identifier 'ID' with
>>>>    coutour( basiinID == ID, level=0.5)
>>>> Add 'add=TRUE' if you are overlaying this on an existing plot.
>>>>
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>> On Thu, Aug 4, 2016 at 1:51 AM, Zun Yin <yinzun2000 at gmail.com> wrote:
>>>>
>>>>> D
>>>>> ear all,
>>>>>
>>>>> I have a matrix with ID of river basins (integer numbers). Now I want
>>>>> to
>>>>> highlight one river basin in a map by plotting only the border. Like
>>>>> the
>>>>> attached figure. Two river basins are highlighted by polygons. It is
>>>>> created by ferret, but I prefer to implement it by R. Anybody know how
>>>
>>> to
>>>>>
>>>>> do it? Thanks a lot.
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Zun Yin
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>
>>> http://www.R-project.org/posting-guide.html
>>>>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Fri Aug  5 04:36:34 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 5 Aug 2016 12:36:34 +1000
Subject: [R] how to plot annual values directly
In-Reply-To: <CAN5afy_VJ1g0ONe4c=_J8bO9DhCBKHkpdT8iy5sdA8+U+2Jsrg@mail.gmail.com>
References: <CAN5afy_VJ1g0ONe4c=_J8bO9DhCBKHkpdT8iy5sdA8+U+2Jsrg@mail.gmail.com>
Message-ID: <001c01d1eec2$2f24ebf0$8d6ec3d0$@bigpond.com>

Hi

By coincidence I will very soon have to  do something similar. So I thought
this would be a practice run

Data is 10 years of daily rainfall data
str(arm)
'data.frame':   3640 obs. of  7 variables:
 $ date : Date, format: "1990-01-01" "1990-01-02" "1990-01-03" "1990-01-04"
...
 $ year : int  1990 1990 1990 1990 1990 1990 1990 1990 1990 1990 ...
 $ month: int  1 1 1 1 1 1 1 1 1 1 ...
 $ day  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ rain : num  0 19 0 0 0 0 0 8.2 5.6 1 ...
 $ doy  : num  1 2 3 4 5 6 7 8 9 10 ...
 $ ym   : Date, format: "1990-01-01" "1990-01-01" "1990-01-01" "1990-01-01"
...

head(arm)
            date year month day rain doy         ym
48578 1990-01-01 1990     1   1    0   1 1990-01-01
48579 1990-01-02 1990     1   2   19   2 1990-01-01
48580 1990-01-03 1990     1   3    0   3 1990-01-01
48581 1990-01-04 1990     1   4    0   4 1990-01-01
48582 1990-01-05 1990     1   5    0   5 1990-01-01
48583 1990-01-06 1990     1   6    0   6 1990-01-01

The ym is calculated using ?as.yearmon from the zoo package. 
The zoo package may be useful because of its aggregating functions

Need mean daily rain - use whatever aggregation factor/function that you
need

arm.A <- aggregate(rain ~ year, arm, function(x) mean(x[x>0]) )

library(lattice)

xyplot(rain ~ date, arm,
       groups = factor(arm$year),
       ylim  = c(0,60),
       avg   = arm.A$rain, # 
       panel = panel.superpose,
       panel.groups = function(x, y,  type, col,group.number,avg, ...) {
                  
                 # plot daily values
                  panel.xyplot(x, y, col = "grey80", type = "h") # delete if
necessary
                 # plot average
                  panel.xyplot(x, avg[group.number],  type = "l", col =
"black")

       }
)

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
Sent: Wednesday, 3 August 2016 04:10
To: R mailing list
Subject: [R] how to plot annual values directly

Hi R users,

I have a dataframe, with daily precipitation data, is it possible to plot
annual mean or annual sum values directly? Thanks for your help.

df
year   month   day   precip       time
2010     1          1        0.5     2010-01-01
2010     1          2        0.8     2010-01-02
2010     1          3        1.0     2010-01-03
2010     1          4        0.9     2010-01-04
...

fig1 = ggplot()+ geom_path(data=df, aes(x=time, y= precip)
show(fig1)

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Fri Aug  5 05:01:48 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 5 Aug 2016 13:01:48 +1000
Subject: [R] Fwd: only plot borders of a region in a scatter plot
In-Reply-To: <CA+8X3fUu1i_zQQ5XBrg4udnA6ATw2hrVRHG+t=KA8uqSKRzfgg@mail.gmail.com>
References: <CA+cZ=YqeKtuNvmYLVPnt_xSmaH5PHwQNy3WW2MpftscB+U49oA@mail.gmail.com>
	<CA+cZ=Yo_RVG18+==rcN8gfTnf1OG_dV1p=Za5_q3kTSyvd-dNQ@mail.gmail.com>
	<CAF8bMcbNVgHbZhBJG1+DeR8w_0nyPDyR6HR-i4Dn3bw2SO9=yw@mail.gmail.com>
	<CAGxFJbRAqz8Bieg2Gcp+TFQV-xbXH=PftbZBu5OArhqd6u_c6Q@mail.gmail.com>
	<CA+cZ=YoY05=umeqPGXC44Bjkn4SX-9P2L1qc3+K5NbNNx5aOWg@mail.gmail.com>
	<153086f7-16fa-f18f-324a-4ad70bf8eb6d@gmail.com>
	<CA+8X3fUu1i_zQQ5XBrg4udnA6ATw2hrVRHG+t=KA8uqSKRzfgg@mail.gmail.com>
Message-ID: <CA+8X3fUPcYpettdRO3OTeR=dkGDw7xH32tyGmz5XHUFDkNtAAw@mail.gmail.com>

Hi Zun Yin,
A slight improvement follows, which tries to "inflate" the pixellation
locally. This, in addition to the offset, might do it for you.

pixel8<-function(x,y) {
 nsteps<-length(x)-1
 newx<-x[1]
 newy<-y[1]
 lastdx<-lastdy<-0
 for(i in 1:nsteps) {
  dx<-diff(x[i:(i+1)])
  dy<-diff(y[i:(i+1)])
  if(dx && dy) {
   if((dx+lastdx)/(dy+lastdy) < 0) {
    newx<-c(newx,x[i]+dx,x[i]+dx)
    newy<-c(newy,y[i],y[i]+dy)
   }
   else {
    newx<-c(newx,x[i],x[i]+dx)
    newy<-c(newy,y[i]+dy,y[i]+dy)
   }
  }
  else {
   newx<-c(newx,x[i+1])
   newy<-c(newy,y[i+1])
  }
  lastdx<-dx
  lastdy<-dy
 }
 return(list(x=newx,y=newy))
}

x<-c(5,4,4,3,2,2,1,1,2,2,3,4,5,5,6,6,7,8,8,9,8,7,7,6,6,5,5)
y<-c(1,2,2,3,4,4,5,6,6,7,8,8,9,8,8,7,7,6,6,5,5,4,3,3,2,2,1)
plot(1:9,type="n")
lines(x,y)
newxy<-pixel8(x,y)
lines(newxy$x,newxy$y,col="red")

Jim


On Fri, Aug 5, 2016 at 11:40 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Zun Yin,
> The first problem requires something like this:
>
> pixel8<-function(x,y,pixsize=1) {
>  nsteps<-length(x)-1
>  newx<-x[1]
>  newy<-y[1]
>  for(i in 1:nsteps) {
>   dx<-diff(x[i:(i+1)])
>   dy<-diff(y[i:(i+1)])
>   if(dx && dy) {
>    newx<-c(newx,x[i]+dx,x[i]+dx)
>    newy<-c(newy,y[i],y[i]+dy)
>   }
>   else {
>    newx<-c(newx,x[i+1])
>    newy<-c(newy,y[i+1])
>   }
>  }
>  return(list(x=newx,y=newy))
> }
>
> I think that this does part of what you want. Your points seem to be
> in the middle of a pixel edge, so an offset would have to be added to
> align the resulting points with the corners. The other thing to work
> out is the order of changing x and y on a slope, which I think is a
> function of whether the line is "inside" or "outside" the overall area
> enclosed. I'll post again if I have any brilliant ideas.
>
> Jim
>
>
> On Fri, Aug 5, 2016 at 6:08 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 04/08/2016 11:46 AM, Zun Yin wrote:
>>>
>>> Dear William, Duncan and Bert,
>>>
>>> Thanks a lot for your help and tips :D In fact the contour() plot still
>>> cannot solve my problem perfectly. As the resolution of my plot is very
>>> coarse, I want to a contour perfectly surround all grid cells in the river
>>> basin. In another word, I want all angle of the contour to be 90 degree.
>>> Another problem for the contour() is that the contour line doesn't close
>>> at
>>> where the value of neighbouring grid cell is NA. See the right side of the
>>> two contour lines (attachment). Do you know how I can get what I want?
>>> Thanks a lot :P
>>
>>
>> The second problem is easy:  just change your NA values to some new ID
>> value, or change the test from
>>
>> basiinID == ID
>>
>> to
>>
>> !is.na(basiinID) & basiinID == ID
>>
>> The first one looks harder.
>>
>> Duncan Murdoch
>>
>>
>>>
>>> Cheers,
>>>
>>>
>>> Zun Yin
>>>
>>> On Thu, Aug 4, 2016 at 5:09 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>>
>>>> ... note the typo. It's:
>>>>
>>>> contour( basiinID == ID, level=0.5)
>>>>
>>>> :-)
>>>>
>>>>
>>>> -- Bert
>>>>
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Thu, Aug 4, 2016 at 8:03 AM, William Dunlap via R-help
>>>> <r-help at r-project.org> wrote:
>>>>>
>>>>> If 'basinID' is the matrix of basin identifiers you could draw an
>>>>> outline
>>>>> of the basin with identifier 'ID' with
>>>>>    coutour( basiinID == ID, level=0.5)
>>>>> Add 'add=TRUE' if you are overlaying this on an existing plot.
>>>>>
>>>>> Bill Dunlap
>>>>> TIBCO Software
>>>>> wdunlap tibco.com
>>>>>
>>>>> On Thu, Aug 4, 2016 at 1:51 AM, Zun Yin <yinzun2000 at gmail.com> wrote:
>>>>>
>>>>>> D
>>>>>> ear all,
>>>>>>
>>>>>> I have a matrix with ID of river basins (integer numbers). Now I want
>>>>>> to
>>>>>> highlight one river basin in a map by plotting only the border. Like
>>>>>> the
>>>>>> attached figure. Two river basins are highlighted by polygons. It is
>>>>>> created by ferret, but I prefer to implement it by R. Anybody know how
>>>>
>>>> to
>>>>>>
>>>>>> do it? Thanks a lot.
>>>>>>
>>>>>> Cheers,
>>>>>>
>>>>>> Zun Yin
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>
>>>> http://www.R-project.org/posting-guide.html
>>>>>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Fri Aug  5 06:19:43 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 5 Aug 2016 00:19:43 -0400
Subject: [R] Plotting in LaTeX with ggplot2 in R and using tikzdevice
In-Reply-To: <CAMBjWT0fcBb=gEvbOMza3A7VqJcPMB5aAaM4wtz6=Lsi7Uvg0Q@mail.gmail.com>
References: <CAMBjWT0fcBb=gEvbOMza3A7VqJcPMB5aAaM4wtz6=Lsi7Uvg0Q@mail.gmail.com>
Message-ID: <CAGx1TMB_=9m9rdktJX8eh7mWD0tvuN4m+fyBRtHBAThM+A2z_Q@mail.gmail.com>

I suggest the microplot package that I placed on CRAN several weeks ago.

Description:

     Prepare lists of R graphics files to be used as microplots
     (sparklines) in tables in either LaTeX or HTML files.  For LaTeX
     use the Hmisc::latex() function or xtable::xtable() with Sweave,
     knitr, rmarkdown, or Emacs org-mode to construct latex tabular
     environments which include the graphs.  For HTML files use either
     Emacs org-mode or the htmlTable::htmlTable() function to construct
     an HTML file containing tables which include the graphs.  Examples
     are shown with lattice graphics, base graphics, and ggplot2
     graphics.  Examples for LaTeX include Sweave (both LaTeX-style and
     Noweb-style), knitr, emacs org-mode, and rmarkdown input files and
     their pdf output files.  Examples for HTML include org-mode and
     Rmd input files and their webarchive HTML output files.  In
     addition, the as.orgtable function can display a data.frame in an
     org-mode document.

For your task, the idea would be to construct a multi-panel plot using ggplot
and then capture each panel into a separate pdf file.
The files would then all be scaled identically.
Capture the legend material into a separate pdf file.
Use the as.includegraphics function on each pdf filename
and place the resulting strings into a LaTeX table with the
Hmisc::latex function.

Please see the vignette included with the microplot package for details.
    vignette("rmhPoster", package="microplot")
The vignette is my poster session from the useR conference last month
at Stanford.
The complete R code for all examples in the vignette is in file
    paste0(system.file(package="microplot"), "/doc/rmhPoster.R")

The vignette and the examples use lattice.

A simple working example using ggplot is included in the ?microplot help file.
Simple working examples are also shown for base graphics and for all the
output options listed in the Description.

Rich


On Wed, Aug 3, 2016 at 5:20 PM, Ecstasia Tisiphoni <ecstasia1 at gmail.com> wrote:
> Hello,
> not totally sure if this is a R or a LaTeX topic...
>
> I am a total newbie to R and LaTeX, and trying to write my masters
> thesis right now... I tried to get this answered via
> https://cran.r-project.org/web/packages/tikzDevice/vignettes/tikzDevice.pdf
>  ...but I failed... :(
>
> I am creating plots in R via ggplot2, and converting them to TeX
> format via tikzDevice.
>
> Now many of my plots have a legend on the right, which differs in size
> (depending of course on the legend title and text).
>
> If I now convert my Rplot using tikz() it only scales the size for the
> whole image it creates.
>
> What I want is: the rectangular plot itself to always be the same size
> for all my plots (no matter how big/small the legend and the axis
> numbers are)...
>
> My Rscript with some test Data:
>
> library(ggplot2)
> library(scales)
> require(grid)
> library(tikzDevice)
>
>
> #setting time zone
> options(tz="Europe/Berlin")
>
> tikz(file = "my_output_file.tex", standAlone=F,width = 6, height = 3)
>
>
> cars['dt'] = seq(Sys.Date(),Sys.Date()-980,-20)
> plot <- ggplot(cars,aes(y=speed,x=dist,color=as.integer(dt)))+
>                geom_point(size=2,alpha=0.7)+
>                xlab("distance")+
>                ylab("speed")+
>                scale_color_gradientn("dt",
>                                      colours=rainbow(6)
>                                      )+
>
> #textsize
> theme_bw()+
> theme(legend.position="right",
>       legend.key.height=unit(2,"lines"),
>       legend.title=element_text(size=rel(0.8)),
>       legend.text=element_text(size=rel(0.8)),
>       axis.text.y=element_text(angle=90,
>                                hjust=0.5),
>       axis.title=element_text(size=rel(0.8))
>  )
>
> print(plot)
>
> dev.off()
>
>
> If I change now the legend text to a slightly longer text, the output
> of course has a completely different plot-size.
> Is there a way to maintain the plot size?
>
> I hope somebody can help me, or lead me to the information I need...
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From suparna.mitra.sm at gmail.com  Fri Aug  5 11:00:59 2016
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Fri, 5 Aug 2016 10:00:59 +0100
Subject: [R] Three way correspondence analyses?
In-Reply-To: <09108d9a-c6de-8871-6079-8b73a8df4032@yorku.ca>
References: <CAFdg=fXxfR+26m1gR5fcNyLsadDvbsxkngcrGjaS4pHwhHGuzA@mail.gmail.com>
	<09108d9a-c6de-8871-6079-8b73a8df4032@yorku.ca>
Message-ID: <CAFdg=fVwTNBfPp2ynLFQY0L_yDqF5ivKeasX+wYeUtbJ-GgEEQ@mail.gmail.com>

Sorry somehow the mail was buried in my spam folder and I was waiting for
any reply. Now when I searched specifically then found in spam. Sorry about
this.
This is my data format.


I have three data matrix. Samples are matched
> dput(Cytok_and_ProInf)
structure(list(IFN._ = c(3.412082432, 3.052252998, 5.142508722,
12.70932318, 1.861206813, 0.993497776, 0.836846636, 4.125564372,
1.385344616, 1.292459442, 0.11649863, 0.150193815, 27.86121845,
1.725385265, 1.715598671, 0.017175222, 1e-06, 1e-06, 6.668275976,
0.790970336, 4.03583889, 0.971457745, 1.059011154, 0.637639199,
0.48875513, 0.301263118, 0.272641165, 0.343154282, 1e-06, 1e-06,
1.282052844, 1.080656696, 1.302848316, 6.22346499, 0.329317838,
1e-06, 0.437037978, 0.287027959, 0.960397988, 0.098872923, 1.06984553,
0.836846636, 1.302848316, 0.904683816), IL.10 = c(0.115021123,
0.150136084, 0.205984417, 0.16364998, 0.099053965, 0.152406978,
0.107718618, 0.180196098, 0.073236511, 0.101546531, 0.233120615,
0.097802351, 0.67071499, 0.159174453, 0.226924759, 0.042082686,
1e-06, 1e-06, 0.242345366, 0.250478861, 0.170311925, 0.079862061,
0.083777663, 0.062337816, 0.026139707, 0.088935013, 0.158051134,
0.178010445, 0.19103657, 0.178010445, 0.186717539, 0.066471894,
0.263570447, 0.403324556, 1e-06, 0.15467023, 0.096547094, 0.131672017,
0.085073597, 0.1877994, 0.182375762, 0.115021123, 0.117431784,
0.158051134), IL.12p70 = c(0.070763998, 0.090748695, 0.208540497,
1e-06, 0.100363261, 1e-06, 0.049381659, 0.278572877, 0.359093222,
0.236327042, 1e-06, 1e-06, 1.730678237, 1e-06, 1e-06, 1e-06,
1e-06, 1e-06, 1e-06, 0.228467277, 0.355528037, 0.150149937, 1e-06,
0.100363261, 1e-06, 1e-06, 0.351954745, 0.236327042, 0.167289445,
1e-06, 0.297291961, 0.208540497, 1e-06, 1e-06, 0.240234706, 0.025530181,
0.114409102, 1e-06, 1e-06, 0.031847909, 0.228467277, 1e-06, 0.212559242,
0.30100342), IL.13 = c(1.704419932, 1.112298247, 2.285765956,
4.633806398, 0.642126976, 0.746932456, 0.363434771, 2.340450899,
2.074555897, 1.244106163, 1e-06, 1.820132354, 74.41151063, 2.034099156,
20.68036347, 1e-06, 1e-06, 4.101483243, 0.794749267, 1e-06, 2.805396078,
1.077152785, 1.179818983, 1.581359427, 1.077152785, 1.529718601,
1e-06, 1e-06, 0.58364863, 1e-06, 1.421542399, 0.965068178, 2.836027955,
5.571883643, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1.449249978,
1.146494964, 1e-06, 1e-06), IL.1_ = c(1e-06, 2.307704109, 25.26088067,
572.801725, 0.510013312, 0.362017284, 0.031608863, 3.870488003,
0.01290693, 1.838427599, 7.097086101, 3.272835372, 10406.43981,
1e-06, 81.64973722, 1.070281402, 9.682079245, 10.80856769, 167.0831603,
0.397080631, 128.7969178, 0.995448576, 14.26930517, 0.69205361,
2.304314695, 0.579468482, 1e-06, 1.304363973, 3.759936213, 0.589889298,
0.299325951, 0.291769643, 15.20223699, 271.2112448, 17.88589268,
0.377847524, 0.142551711, 2.042925614, 17.63920898, 0.954063427,
0.841909578, 0.791637687, 2.719932082, 0.612547139), IL.2 = c(0.310017477,
0.639550623, 0.364921535, 0.90788638, 1e-06, 1e-06, 1e-06, 0.479461553,
0.153405415, 0.456098215, 0.659233077, 0.019421531, 2.581092035,
0.60647104, 0.374719897, 0.198939483, 1e-06, 1e-06, 0.420590306,
0.637356204, 0.650500136, 0.187772403, 0.234414214, 0.135640615,
0.167896217, 0.043668, 0.543715428, 0.491057054, 0.104904788,
0.268833496, 0.394164323, 0.153405415, 0.511791782, 1.40318585,
0.162131403, 0.386895823, 0.207232191, 0.234414214, 0.129616074,
0.465471829, 0.411020666, 0.374719897, 0.302383698, 0.266218696
), IL.4 = c(1e-06, 0.061134995, 0.033725716, 0.176628741, 0.036390669,
0.016385835, 0.02963346, 0.0912511, 0.044136184, 0.007841464,
1e-06, 1e-06, 0.555602008, 0.201038117, 1e-06, 0.016385835, 1e-06,
1e-06, 0.05520647, 0.014779363, 0.0453956, 0.019496483, 0.066933632,
1e-06, 1e-06, 1e-06, 0.040306406, 0.077093341, 1e-06, 0.02963346,
0.042868427, 0.088031622, 0.041591965, 0.039011321, 1e-06, 0.013131473,
1e-06, 1e-06, 1e-06, 1e-06, 0.009676617, 0.023961259, 1e-06,
0.025405987), IL.6 = c(0.132069931, 0.205121881, 0.266403938,
0.357044807, 0.175675816, 0.135299256, 0.160466529, 0.801623905,
0.219429811, 0.178675804, 1e-06, 1e-06, 1.946693297, 0.00336273,
0.260996547, 1e-06, 1e-06, 1e-06, 0.101959817, 0.148023004, 0.522793842,
0.166593645, 0.098477711, 0.122253955, 0.184636758, 0.076829582,
1e-06, 1e-06, 1e-06, 0.065400292, 0.144869779, 0.151158758, 0.175675816,
1.136760714, 0.031581939, 0.049271129, 1e-06, 0.036206361, 1e-06,
1e-06, 0.154277589, 0.163537592, 0.101959817, 0.166593645), IL.8 =
c(0.263813623,
0.176968743, 21.45511221, 41.02244667, 0.325779267, 0.19875696,
0.191549828, 5.874233467, 0.162143262, 0.254734152, 0.424914919,
0.83134713, 615.7282871, 0.222420019, 11.71507301, 0.254734152,
0.48778161, 0.459603466, 9.245098493, 0.937998793, 158.7036736,
1.052601593, 7.398795984, 0.517616924, 0.842129973, 0.049980916,
0.091283798, 0.703339445, 0.353738394, 0.12114101, 0.189135463,
0.272831114, 2.577264558, 1e-06, 6.92155151, 0.099598586, 0.126403393,
0.519593589, 2.999681278, 0.279555285, 4.425047545, 0.203532755,
0.829547294, 0.159646452), TNF._ = c(1e-06, 1e-06, 0.497412481,
2.502977176, 1e-06, 1e-06, 1e-06, 0.663152793, 0.115785465, 0.112196976,
3.296149665, 1.103455361, 13.43259911, 1e-06, 4.62646124, 0.17981792,
0.561262449, 1e-06, 6.979610188, 0.104932683, 3.077428626, 1e-06,
0.140201934, 0.256307354, 0.104932683, 1e-06, 1e-06, 0.014627633,
1.016512746, 1e-06, 1e-06, 1e-06, 0.086184523, 4.778283885, 0.46726225,
1e-06, 0.049369295, 0.049369295, 1e-06, 1e-06, 0.074442943, 0.070428387,
1e-06, 0.040326195), GM.CSF = c(0.540900573, 0.42223301, 0.202804186,
1.956298248, 0.06647775, 0.175295758, 0.123620468, 0.66961417,
1e-06, 0.010627992, 1e-06, 0.025094065, 1.791958029, 1e-06, 0.313611726,
0.129677511, 1e-06, 1e-06, 0.072451697, 0.472115537, 2.438178508,
1e-06, 0.341470499, 0.267309423, 0.016380207, 1e-06, 0.072451697,
1e-06, 1e-06, 1e-06, 0.416006909, 0.150926695, 1e-06, 0.86531761,
1e-06, 0.184454916, 1e-06, 0.004950137, 1e-06, 0.160055214, 0.057540307,
0.072451697, 0.484605677, 0.227328934), IL.12p40 = c(3.449523303,
1.253952318, 1.153628772, 24.66757728, 0.281211388, 0.45621453,
0.577190569, 6.035154458, 0.248565664, 0.303009219, 0.489162441,
0.335752283, 4.483277375, 1e-06, 7.754198316, 0.610258154, 0.259440413,
0.183488862, 7.811612719, 3.596931106, 39.86410464, 1e-06, 19.81040921,
0.687524342, 0.194312525, 1e-06, 0.303009219, 0.787068241, 0.401386775,
0.324832028, 1.187055113, 0.478175762, 1.533272067, 6.012282081,
0.313917608, 0.259440413, 0.08662882, 0.129536365, 2.263026136,
0.478175762, 0.248565664, 0.215988153, 1.120217824, 0.720681708
), IL.15 = c(3.663956797, 0.229437717, 0.949300626, 1.401070403,
0.287497045, 1e-06, 0.049717539, 3.216577943, 0.000801684, 0.039236284,
0.044490955, 0.000801684, 0.47768266, 1e-06, 0.548030419, 1e-06,
0.028624659, 1e-06, 1e-06, 2.722888088, 5.4735116, 1e-06, 0.548030419,
1e-06, 1e-06, 1e-06, 1e-06, 0.075522355, 0.150922499, 1e-06,
0.229437717, 0.378377969, 1e-06, 5.831002955, 1e-06, 1e-06, 0.439974635,
1e-06, 2.04484964, 1e-06, 1e-06, 1e-06, 0.18054264, 0.190365246
), IL.16 = c(20.5193362, 4.328836648, 8.255914035, 16.13264058,
1.268642287, 1e-06, 1e-06, 11.8242623, 1e-06, 1e-06, 1e-06, 1e-06,
4.092029806, 1e-06, 3.67041693, 1e-06, 1e-06, 1e-06, 0.301180818,
14.7673695, 20.3213016, 1e-06, 6.82449294, 1e-06, 1e-06, 1e-06,
1e-06, 0.401190562, 0.55732358, 1e-06, 1.444064455, 0.433320317,
1e-06, 28.06557331, 1e-06, 0.301180818, 2.015806139, 1e-06, 4.485194079,
1.59090159, 1e-06, 0.335201656, 0.873203993, 1.035154141), IL.17 =
c(4.977017713,
2.570719348, 2.015098932, 3.992319128, 1.06226368, 0.885436394,
1.3153313, 2.244935789, 0.874075666, 0.908175994, 0.896803194,
0.755173959, 4.459228138, 0.862721083, 1.142538479, 1.292234665,
0.806042993, 0.857046119, 1.09663731, 3.877447052, 12.35812507,
0.942329724, 1.570454586, 1.171265948, 1.200022785, 0.806042993,
0.970830673, 1.073716485, 2.52322014, 0.885436394, 1.587915828,
1.803905178, 0.789071362, 5.466413978, 0.755173959, 1.251857053,
0.698820169, 0.936633804, 1.20577762, 1.010790396, 0.930939325,
0.868397602, 1.523930998, 1.745417659), IL.1_.1 = c(118.208659,
114.7568995, 99.56142647, 517.2879232, 100.3722434, 96.93543486,
81.64662024, 70.27819582, 17.13820342, 82.52992205, 81.78590123,
92.43171819, 1053.37885, 65.5820605, 363.635418, 45.79361892,
33.21789883, 29.57769534, 311.8625878, 40.79704867, 851.3943098,
55.1196921, 239.9686999, 38.15064699, 45.53416821, 28.63008947,
18.15241505, 20.64297024, 32.5135396, 20.39305218, 28.46271279,
6.469080388, 41.24452118, 297.4003248, 102.2122555, 10.96668006,
22.48696243, 23.15105529, 25.04798574, 25.01122998, 77.30344367,
79.36764816, 45.54090693, 35.20462575), IL.5 = c(1.044231313,
0.573092875, 0.584075265, 0.598727834, 1e-06, 1e-06, 1e-06, 0.372977066,
1e-06, 0.291939134, 1e-06, 1e-06, 1e-06, 0.161982214, 1e-06,
1e-06, 0.048963445, 0.088502876, 1e-06, 0.232920333, 1.023752123,
1e-06, 0.04556126, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 0.338690819,
0.067789042, 0.657440756, 0.282972479, 1e-06, 10.196604, 1e-06,
1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 0.154932764, 0.086770774,
1e-06, 0.29373344), IL.7 = c(0.480830602, 0.669397614, 0.056955049,
0.645772623, 0.085416118, 0.157189302, 1e-06, 0.669397614, 0.037168535,
0.039986238, 1e-06, 1e-06, 0.054120296, 0.003790123, 0.162959026,
0.270215723, 1e-06, 0.028737802, 1e-06, 0.212128061, 0.947919977,
1e-06, 0.244047658, 1e-06, 0.296425864, 1e-06, 0.168732133, 0.157189302,
0.168732133, 0.111169917, 0.194750148, 0.678260571, 1e-06, 0.873693001,
1e-06, 0.082561887, 1e-06, 0.025936126, 1e-06, 0.174508512, 0.068316418,
0.206332705, 0.051287998, 0.572039147), TNF._.1 = c(3.419068944,
0.774614576, 1.778032483, 3.677555816, 0.09525377, 0.045152852,
0.203310769, 2.480647474, 0.035471915, 0.018965724, 0.064189143,
0.082908763, 0.91606112, 0.20625602, 0.264708971, 0.250170556,
0.393803487, 0.125749131, 0.235584535, 2.600828984, 3.532130347,
0.235584535, 0.728067967, 0.038713645, 1e-06, 1e-06, 0.086004142,
0.008673406, 0.921475662, 1e-06, 0.170745502, 0.012155505, 0.152838242,
4.753887357, 0.035471915, 0.155830622, 0.048352721, 0.045152852,
1.058973116, 0.09525377, 0.140835049, 0.250170556, 0.170745502,
0.110560669), VEGF = c(4087.981219, 3715.552662, 3944.604398,
3844.577145, 396.5302176, 299.8314501, 207.394422, 3933.745405,
14.78051963, 321.5135099, 297.4382786, 561.2753232, 3050.364368,
116.7615841, 3145.523924, 212.8841604, 44.27057474, 44.58276978,
2020.429602, 4128.947066, 4073.070344, 1691.91391, 3758.767261,
889.8387076, 644.4912406, 250.6067383, 590.6027003, 716.7750862,
404.9555583, 204.2231031, 71.38985829, 36.15359803, 1329.165521,
4009.740565, 2903.460055, 889.1034558, 1417.808231, 480.7677475,
3696.819676, 1455.555265, 998.5832238, 1637.63334, 1149.828041,
55.667355)), .Names = c("IFN._", "IL.10", "IL.12p70", "IL.13",
"IL.1_", "IL.2", "IL.4", "IL.6", "IL.8", "TNF._", "GM.CSF", "IL.12p40",
"IL.15", "IL.16", "IL.17", "IL.1_.1", "IL.5", "IL.7", "TNF._.1",
"VEGF"), class = "data.frame", row.names = c("I100A", "I100B",
"I100C", "I100D", "I100E", "I100F", "I100G", "I123A", "I143A",
"I143B", "I14A", "I14B", "I14C", "I14D", "I17A", "I17B", "I17C",
"I17D", "I17E", "I185A", "I185B", "I185C", "I185D", "I185E",
"I185F", "I185G", "I20A", "I20B", "I20C", "I215A", "I215B", "I215C",
"I215D", "I50A", "I50B", "I50C", "I50D", "I50E", "I78A", "I78B",
"I88A", "I88B", "I88C", "I88D"))

> dput(Microbiome_NEC)
structure(list(environmental.samples..Bacteria. = c(0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), Rhizobiales = c(0L, 0L,
0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 2L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 8L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 3L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), Burkholderiales = c(0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L,
0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L), Enterobacteriales = c(3636L,
3574L, 5908L, 5358L, 3067L, 2392L, 1876L, 40L, 109L, 1182L, 2741L,
3660L, 1716L, 5282L, 1242L, 3570L, 3065L, 3270L, 4023L, 67L,
8361L, 4743L, 10080L, 6857L, 6164L, 3580L, 11L, 3L, 1064L, 1L,
323L, 45L, 1730L, 32L, 5376L, 3002L, 2164L, 3111L, 586L, 4023L,
22L, 110L, 41L, 67L), Pasteurellales = c(0L, 0L, 0L, 0L, 0L,
0L, 0L, 5L, 46L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 172L, 425L, 1L, 2L, 0L, 0L, 0L,
0L, 10L, 0L, 0L, 0L, 5L, 6L, 121L, 831L), Pseudomonadales = c(0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), Actinomycetales = c(0L,
0L, 0L, 0L, 1L, 0L, 53L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 12L, 68L), Bifidobacteriales =
c(6L,
2L, 437L, 925L, 748L, 1569L, 1459L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), Corynebacteriales
= c(0L,
0L, 0L, 0L, 0L, 0L, 0L, 27L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 163L, 0L, 0L, 0L), Micrococcales = c(0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 36L, 23L, 0L), Propionibacteriales = c(0L,
0L, 0L, 0L, 0L, 1L, 28L, 10L, 1205L, 24L, 0L, 2L, 0L, 3L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 30L,
0L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 18L, 3L, 2166L, 441L, 5L),
    Eggerthellales = c(0L, 0L, 1L, 0L, 1L, 4L, 3L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L), Bacillales = c(1573L, 1121L, 1077L, 366L,
    304L, 136L, 3L, 2087L, 1378L, 91L, 1L, 8L, 6L, 19L, 732L,
    130L, 2L, 0L, 1L, 5374L, 2L, 811L, 22L, 40L, 23L, 4L, 79L,
    20L, 717L, 1285L, 503L, 1525L, 151L, 0L, 0L, 0L, 45L, 16L,
    2778L, 249L, 3370L, 973L, 231L, 32L), Lactobacillales = c(0L,
    0L, 93L, 2L, 2L, 38L, 12L, 596L, 318L, 38L, 1L, 2L, 14L,
    18L, 1L, 47L, 1L, 1L, 24L, 13L, 27L, 1L, 335L, 96L, 321L,
    444L, 1797L, 3668L, 714L, 2L, 2775L, 2830L, 1202L, 3224L,
    465L, 605L, 57L, 92L, 1315L, 58L, 1L, 2L, 7L, 167L), Clostridiales =
c(0L,
    0L, 0L, 0L, 1L, 0L, 0L, 4L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), Negativicoccus =
c(0L,
    0L, 0L, 0L, 0L, 0L, 2L, 0L, 0L, 12L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 5L),
    Veillonella = c(0L, 0L, 1L, 0L, 5L, 158L, 61L, 6L, 25L, 93L,
    1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 2037L, 327L, 108L, 910L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 2L, 33L), Tissierellales = c(0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 37L, 1L, 4L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 5L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 3121L, 576L)), .Names =
c("environmental.samples..Bacteria.",
"Rhizobiales", "Burkholderiales", "Enterobacteriales", "Pasteurellales",
"Pseudomonadales", "Actinomycetales", "Bifidobacteriales",
"Corynebacteriales",
"Micrococcales", "Propionibacteriales", "Eggerthellales", "Bacillales",
"Lactobacillales", "Clostridiales", "Negativicoccus", "Veillonella",
"Tissierellales"), class = "data.frame", row.names = c("I100A",
"I100B", "I100C", "I100D", "I100E", "I100F", "I100G", "I123A",
"I143A", "I143B", "I14A", "I14B", "I14C", "I14D", "I17A", "I17B",
"I17C", "I17D", "I17E", "I185A", "I185B", "I185C", "I185D", "I185E",
"I185F", "I185G", "I20A", "I20B", "I20C", "I215A", "I215B", "I215C",
"I215D", "I50A", "I50B", "I50C", "I50D", "I50E", "I78A", "I78B",
"I88A", "I88B", "I88C", "I88D"))


> dput(Metab_NEC)
structure(list(fatty.acids = c(0.97, 1.96, 2.15, 10.06, 5.87,
3.57, 3, 18.36, 4.6, 3.55, 2.44, 1.69, 2.88, 0.76, 6.05, 1.93,
2.02, 1.99, 2.77, 1.76, 1.4, 3.48, 2.24, 0.95, 1.1, 2.32, 0.27,
1.16, 5.32, 4.37, 3.27, 3.02, 2.19, 2.37, 1.38, 0.95, 1.08, 2.79,
3.26, 2.7, 1.26, 5.14, 5.13, 11.56), aldehydes = c(0.25, 0, 0.36,
0.07, 0, 0, 0.18, 0, 0.08, 0.11, 0.13, 0.24, 0, 0.04, 1.45, 0.12,
0.03, 0.05, 0.02, 0.11, 0.02, 0, 0.12, 0.14, 0, 0.17, 0, 0.05,
0, 0.02, 0.03, 0.23, 0, 0.06, 0, 0.02, 0, 0, 0.59, 0.05, 0.19,
0.17, 0, 0.1), alcohol = c(1.91, 0.21, 0.86, 3.29, 0.9, 0.37,
0.39, 6.98, 1.31, 1.52, 1.34, 1.88, 4.31, 1.03, 4.85, 0.82, 0.44,
0.91, 1.32, 2.18, 1.01, 2.9, 4.68, 1.26, 1.6, 0.99, 1.39, 1.04,
2.86, 2.25, 1.71, 1.55, 1.01, 1.22, 1.04, 1.1, 1.64, 1.31, 4.53,
1.57, 1.69, 3.81, 3.32, 3.25), amines = c(0.06, 0.08, 0.01, 2.04,
6.06, 2.67, 4.04, 2.2, 0.75, 0.2, 0.94, 0.39, 0.51, 0.1, 0.11,
0.19, 0.16, 0.12, 0.16, 0, 0.16, 0, 0, 0.53, 0.13, 2.48, 0.29,
0.47, 0.19, 0.66, 0.09, 0.28, 1.25, 0, 0.26, 0.11, 0, 0.16, 0,
0, 0, 1.17, 1.17, 1.86), phenolic.acid = c(0.01, 0.01, 0.04,
0, 0, 0, 0.21, 0.22, 0.04, 0.65, 0, 0.01, 0.03, 0, 0.01, 0, 0.01,
0.01, 0.04, 0, 0, 0, 0.01, 0, 0, 0.02, 0, 0.09, 0.03, 0, 0, 0,
0.06, 0.03, 0, 0.06, 0, 0, 0, 0, 0.03, 0.01, 0, 0.48), sugars = c(50.98,
37.78, 18, 4.38, 23.55, 22.65, 15.63, 14.5, 15.89, 11.24, 8.37,
20.22, 10.21, 18.5, 61.92, 16.1, 30.24, 26.1, 3.09, 41.16, 34.96,
19.03, 28.68, 37.19, 41.9, 16.35, 43.77, 32.99, 15.54, 17.47,
31.21, 12.99, 21.59, 31.59, 51.64, 45.92, 47.17, 31.55, 45.51,
45.3, 56.08, 21.79, 31.22, 4.28), amino.acids = c(4.24, 4.31,
6.27, 9.1, 4.75, 2.31, 2.49, 13.22, 4.27, 5.34, 5.44, 2.35, 3.46,
2.05, 9.41, 4.23, 2.85, 2.65, 3.69, 5.67, 3.01, 4.33, 3.99, 1.84,
2.88, 2.52, 2.14, 5.25, 6.18, 9.02, 3.07, 1.4, 2.25, 9.52, 4.04,
2.94, 2.91, 4.84, 6.34, 4.88, 3.31, 6.29, 4.86, 4.23), osmolytes = c(7.1,
2.15, 1.59, 2.91, 0.56, 4.04, 0.3, 2.05, 0.24, 1.06, 4.54, 4.19,
1.16, 0.41, 8.52, 3.28, 7.27, 2.38, 2.65, 3.04, 1.52, 3.55, 2.69,
3.21, 0.67, 0.98, 1.6, 0.83, 0.99, 4.64, 3.38, 12.2, 0.42, 1.28,
4.64, 2.5, 3.36, 1.08, 5.32, 1.7, 2.01, 1.89, 2.72, 1.04),
energy.related.acid = c(0.55,
1.52, 0.6, 1.9, 0.63, 0.74, 0.46, 2.67, 1.08, 4.22, 7.69, 2.09,
7.31, 1.07, 1.19, 1.78, 0.43, 0.3, 11.11, 1.52, 1.67, 4.21, 1.76,
2.84, 3.06, 3.13, 0.04, 2.7, 3.01, 5.15, 2.31, 0.29, 2.16, 4.09,
1.21, 0.59, 0.55, 2.88, 1, 1.22, 0.7, 1.09, 1.5, 1.12), nucleobase = c(0,
0, 0.05, 0.11, 0.05, 0, 0.24, 0.2, 0.04, 0.04, 0.02, 0.02, 0.08,
0.01, 0.17, 0.02, 0.02, 0.03, 0.03, 0, 0.03, 0.09, 0.02, 0.02,
0.02, 0.01, 0.11, 0.03, 0.03, 0.05, 0.04, 0.02, 0.28, 0.06, 0.04,
0.03, 0, 0.01, 0.05, 0.05, 0.01, 0.07, 0.05, 0.09)), .Names =
c("fatty.acids",
"aldehydes", "alcohol", "amines", "phenolic.acid", "sugars",
"amino.acids", "osmolytes", "energy.related.acid", "nucleobase"
), class = "data.frame", row.names = c("I100A", "I100B", "I100C",
"I100D", "I100E", "I100F", "I100G", "I123A", "I143A", "I143B",
"I14A", "I14B", "I14C", "I14D", "I17A", "I17B", "I17C", "I17D",
"I17E", "I185A", "I185B", "I185C", "I185D", "I185E", "I185F",
"I185G", "I20A", "I20B", "I20C", "I215A", "I215B", "I215C", "I215D",
"I50A", "I50B", "I50C", "I50D", "I50E", "I78A", "I78B", "I88A",
"I88B", "I88C", "I88D"))


Now I normalised them all by % and tried cca in vegan package.

normCytok_and_ProInf <- (Cytok_and_ProInf/rowSums(Cytok_and_ProInf))*100
normMetab_NEC <- (Metab_NEC/rowSums(Metab_NEC))*100
normMicrobiome_NEC <- (Microbiome_NEC/rowSums(Microbiome_NEC))*100
#Now CCA
Metab.Cytok.Microb.cca <-
cca(normMicrobiome_NEC,normMetab_NEC,normCytok_and_ProInf)
plot(Metab.Cytok.Microb.cca )
Metab.Cytok.Microb.cca <- cca(normMicrobiome_NEC,normCytok_and_ProInf)
 plot(Metab.Cytok.Microb.cca )
Metab.Cytok.Microb.cca <- cca(normMicrobiome_NEC,normMetab_NEC)
plot(Metab.Cytok.Microb.cca )


Any help will be really great.
Thank you very much.
Mitra



On 4 August 2016 at 14:25, Michael Friendly <friendly at yorku.ca> wrote:

> You haven't supplied any data, and we can only guess which cca() function
> you are using (ade4::cca, ..., vegan::cca(), yacca::cca), and the term
> 'cca' generally refers to canonical correspondence analysis,
> which is not quite the same thing as 'three-way correspondence analysis'.
>
> For three-way tables, there are several variations of standard
> correspondence analysis that generalize CA for two-way tables
> in reasonable, but different ways.
> You may find more joy using the mjca() in the ca package
> which provides these alternatives.
>
> best,
> -Michael
>
>
> On 8/2/2016 3:58 PM, Suparna Mitra wrote:
>
>> Hello R experts,
>>    have some data for microbiome, metabolome and cytokine from the same
>> sample. Now I want to do a three-way correspondence analyses. From three
>> normalised data I was trying,
>> #Now CCA
>>
>> with two data it works good like:
>> Metab.Cytok.Microb.cca <- cca(normMicrobiome_NEC,normCytok_and_ProInf)
>>  plot(Metab.Cytok.Microb.cca )
>> Metab.Cytok.Microb.cca <- cca(normMicrobiome_NEC,normMetab_NEC)
>> plot(Metab.Cytok.Microb.cca )
>>
>> But when I tried with three
>> Metab.Cytok.Microb.cca <-
>> cca(normMicrobiome_NEC,normMetab_NEC,normCytok_and_ProInf)
>> plot(Metab.Cytok.Microb.cca )
>> But this is not displaying all three variables.
>> Sorry, I am very new in this. Can anybody please help me?
>> Thanks a lot,
>> Mitra
>>
>>         [[alternative HTML version deleted]]
>>
>>
>

	[[alternative HTML version deleted]]


From M.Tripoli at aifa.gov.it  Fri Aug  5 11:43:43 2016
From: M.Tripoli at aifa.gov.it (Tripoli Massimiliano)
Date: Fri, 5 Aug 2016 09:43:43 +0000
Subject: [R] Freq in dataframe
Message-ID: <876CEB8A3E7326488D0125D8D973B5DC19A2F947@SRVMBX02.aifa.lan>

Dear R users,

# This is my data:

ddat <- array(c(8,10,7,13,8,15,
              7,9,6,9,7,10,
               11,13,7,16,8,16
               ),
              dim = c(2,3,3),
               dimnames = list(
              Time = c("Week 32","Week 52"),
               Dose = c("Dose 1","Dose 2","Dose 3"),
             Group = c("A","B","C")))
ddat

# and I'd like to have data like that:

as.data.frame(UCBAdmissions)

# I tried with 

as.data.frame(ddat) 

# and this is the result:

> as.data.frame(ddat)
        Dose 1.A Dose 2.A Dose 3.A Dose 1.B Dose 2.B Dose 3.B Dose 1.C Dose 2.C Dose 3.C
Week 32        8        7        8        7        6        7       11        7        8
Week 52       10       13       15        9        9       10       13       16       16

Someone could help me ?
Thanks in advance,

M. Tripoli
_________________________

Dott. Massimiliano Tripoli
Ufficio Assessment Europeo - European Assessment Office 
Agenzia Italiana del farmaco - Italian Medicine Agency
Via del Tritone 181 - 00187 Roma
Tel. +39-06-59784643
E-mail: m.tripoli at aifa.gov.it


From sm.najafi92 at gmail.com  Fri Aug  5 06:52:57 2016
From: sm.najafi92 at gmail.com (Mehdi Najafi)
Date: Fri, 5 Aug 2016 09:22:57 +0430
Subject: [R] Fwd: pubmed.mineR
In-Reply-To: <CABfCpgroGiWnAaudJa_uwNXkGS_Mqw5-AhHjz7h5BqOYTsA7_A@mail.gmail.com>
References: <CABfCpgroGiWnAaudJa_uwNXkGS_Mqw5-AhHjz7h5BqOYTsA7_A@mail.gmail.com>
Message-ID: <CABfCpgpfhDv7EufPXXGrJCejnE2tLPrK-7s+tYiKVCy1AGuUag@mail.gmail.com>

---------- Forwarded message ----------
From: Mehdi Najafi <sm.najafi92 at gmail.com>
Date: Fri, Aug 5, 2016 at 9:17 AM
Subject: pubmed.mineR
To: ramu at igib.in


Hi dear helper, it has been a pleasure to read magnificat paper titled
"pubmed.mineR: An R package with text-mining algorithms to analyse PubMed
abstracts".
I encuntered a problem using it.I wish you could help me with that.
favorite
<http://stackoverflow.com/questions/38781115/cant-find-objects-using-pubmed-miner-package#>


I have downloaded abstracts of interest from pubmed.com then read them
using pubmed.mineR package with readabs() function, which is supposed to
create object of class "Abstracs", but when I type in ls(), it gives me
character(0), which as far as i know implies that there is no object in the
memory. I want to search abstracts using searchabsL(x,include="term"), Here
x is the object of class Abstracts containing data.though i don't know how?

after readabs() i face these lines:

> readabs("b.txt")

An object of class "Abstracts"

Slot "Journal":

[1] "1. Alzheimers Res Ther. 2015 Dec 18;7(1):75. doi:
10.1186/s13195-015-0159-5."

[2] "2. J Cereb Blood Flow Metab. 2016 Mar;36(3):621-8. doi:
10.1177/0271678X15606141."


Slot "Abstract":

[1] " Diagnostic value of cerebrospinal fluid A?? ratios in preclinical
Alzheimer's disease.  Adamczuk K(1,)(2), Schaeverbeke J(3,)(4),
Vanderstichele HM(5), Lilja J(6,)(7), Nelissen N(8,)(9), Van Laere
K(10,)(11), Dupont P(12,)(13), Hilven K(14), Poesen  K(15,)(16),
Vandenberghe R(17,)(18,)(19).  Author information:  (1)Laboratory for
Cognitive Neurology, KU Leuven, Herestraat 49, 3000, Leuven, Belgium.
kate.adamczuk at med.kuleuven.be. (2)Alzheimer Research Centre KU Leuven,
Leuven Institute of Neuroscience and Disease, Herestraat 49, 3000, Leuven,
Belgium. kate.adamczuk at med.kuleuven.be. (3)Laboratory for Cognitive
Neurology, KU Leuven, Herestraat 49, 3000, Leuven, Belgium.
jolien.schaeverbeke at med.kuleuven.be. (4)Alzheimer Research Centre KU
Leuven, Leuven Institute of Neuroscience and Disease, Herestraat 49, 3000,
Leuven, Belgium. jolien.schaeverbeke at med.kuleuven.be. (5)ADx NeuroSciences,
Technologiepark 4, 9052, Gent, Belgium. hugo.vanderstichele@
adxneurosciences.com. (6)GE Healthcare, Bj??rkgatan 30, 751 25, Uppsala,
Sweden. johan.lilja at radiol.uu.se. (7)Nuclear Medicine and PET, Department
of Surgical Sciences, Uppsala University, 751 85, Uppsala, Sweden.
johan.lilja at radiol.uu.se.  (8)Laboratory for Cognitive Neurology, KU
Leuven, Herestraat 49, 3000, Leuven, Belgium. natalie.nelissen at psych.ox.ac.
uk. (9)Department of Psychiatry, Oxford University, Oxford, OX3 7JX, UK.
natalie.nelissen at psych.ox.ac.uk. (10)Alzheimer Research Centre KU Leuven,
Leuven Institute of Neuroscience and Disease, Herestraat 49, 3000, Leuven,
Belgium. koen.vanlaere at uzleuven.be. (11)Nuclear Medicine and Molecular
Imaging Department, KU Leuven and University Hospitals Leuven, Herestraat
49, 3000, Leuven, Belgium. koen.vanlaere at uzleuven.be. (12)Laboratory for
Cognitive Neurology, KU Leuven, Herestraat 49, 3000, Leuven, Belgium.
patrick.dupont at med.kuleuven.be. (13)Alzheimer Research Centre KU Leuven,
Leuven Institute of Neuroscience and Disease, Herestraat 49, 3000, Leuven,
Belgium. patrick.dupont at med.kuleuven.be. (14)Laboratory for
Neuroimmunology, KU Leuven, Herestraat 49, 3000, Leuven, Belgium.
kelly.hilven at med.kuleuven.be. (15)Laboratory for Molecular Neurobiomarker
Research, KU Leuven, Herestraat 49, 3000, Leuven, Belgium.
koen.poesen at uzleuven.be. (16)Laboratory Medicine, UZ Leuven, Herestraat 49,
3000, Leuven, Belgium. koen.poesen at uzleuven.be. (17)Laboratory for
Cognitive Neurology, KU Leuven, Herestraat 49, 3000, Leuven, Belgium.
rik.vandenberghe at uz.kuleuven.ac.be. (18)Alzheimer Research Centre KU
Leuven, Leuven Institute of Neuroscience and Disease, Herestraat 49, 3000,
Leuven, Belgium. rik.vandenberghe at uz.kuleuven.ac.be. (19)Neurology
Department, University Hospitals Leuven, Herestraat 49, 3000, Leuven,
Belgium. rik.vandenberghe at uz.kuleuven.ac.be.  INTRODUCTION: In this study
of preclinical Alzheimer's disease (AD) we assessed the added diagnostic
value of using cerebrospinal fluid (CSF) A?? ratios rather than A??42 in
isolation for detecting individuals who are positive on amyloid positron
emission tomography (PET). METHODS: Thirty-eight community-recruited
cognitively intact older adults (mean age 73, range 65-80 years) underwent
(18)F-flutemetamol PET and CSF measurement of A??1-42, A??1-40, A??1-38,
and total tau (ttau). (18)F-flutemetamol retention was quantified using
standardized uptake value ratios in a composite cortical region  (SUVRcomp)
with reference to cerebellar grey matter. Based on a prior autopsy
validation study, the SUVRcomp cut-off was 1.57. Sensitivities,
specificities and cut-offs were defined based on receiver operating
characteristic analysis with CSF analytes as variables of interest and
(18)F-flutemetamol positivity as the classifier. We also determined
sensitivities and CSF cut-off values at fixed specificities of 90? % and
95? %. RESULTS: Seven out of 38 subjects (18? %) were positive on amyloid
PET. A??42/ttau, A??42/A??40, A??42/A??38, and A??42 had the highest
accuracy to identify amyloid-positive subjects (area under the curve
(AUC)?????????0.908). A??40 and A??38 had significantly lower
discriminative power (AUC???=???0.571). When specificity was fixed at 90? %
and 95? %, A??42/ttau had the highest sensitivity among the different CSF
markers (85.71? % and 71.43? %, respectively). Sensitivity of A??42 alone
was significantly lower under these conditions (57.14? % and 42.86? %,
respectively). CONCLUSION: For the CSF-based definition of preclinical AD,
if a high specificity is required, our data support the use of A??42/ttau
rather than using A??42 in isolation.  DOI: 10.1186/s13195-015-0159-5
 PMCID: PMC4683859"

[2] "Epub 2015 Sep 30.  Cerebrospinal fluid profiles with increasing number
of cerebral microbleeds in a  continuum of cognitive impairment.  Shams
S(1), Granberg T(2), Martola J(2), Li X(3), Shams M(2), Fereshtehnejad
SM(3), Cavallin L(2), Aspelin P(2), Kristoffersen-Wiberg M(2), Wahlund
LO(3).  Author information:  (1)Department of Clinical Science,
Intervention, and Technology, Division of Medical Imaging and Technology,
Karolinska Institutet, Stockholm, Sweden Department of Radiology,
Karolinska University Hospital, Stockholm, Sweden sara.shams at ki.se.
(2)Department of Clinical Science, Intervention, and Technology, Division
of Medical Imaging and Technology, Karolinska Institutet, Stockholm, Sweden
Department of Radiology, Karolinska University Hospital, Stockholm, Sweden.
(3)Department of Neurobiology, Care Sciences, and Society, Karolinska
Institutet, Stockholm, Sweden Division of Clinical Geriatrics, Karolinska
University Hospital, Stockholm, Sweden.  Cerebral microbleeds (CMBs) are
hypothesised to have an important yet unknown role in the dementia disease
pathology. In this study we analysed increasing number of CMBs and their
independent associations with routine cerebrospinal fluid (CSF) biomarkers
in a continuum of cognitive impairment. A total of 1039 patients undergoing
dementia investigation were analysed and underwent lumbar puncture, and an
MRI scan. CSF samples were analysed for amyloid ?? (A??) 42, total tau
(T-tau), tau phosphorylated at threonine 18 (P-tau) and CSF/serum albumin
ratios. Increasing number of CMBs were independently associated with low
A??42 levels, in the whole cohort, Alzheimer's disease and mild cognitive
impairment (p???<???0.05). CSF/serum albumin ratios were high with multiple
CMBs (p???<???0.001), reflecting accompanying blood-brain barrier
dysfunction. T-tau and P-tau levels were lower in Alzheimer's patients with
multiple CMBs when compared to zero CMBs, but did not change in the rest of
the cohort. White matter hyperintensities were  associated with low A??42
in the whole cohort and Alzheimer's disease (p???<???0.05).  A??42 is the
routine CSF-biomarker mainly associated with CMBs in cognitive impairment,
and there is an accumulative effect with increasing number of CMBs.  ?? The
Author(s) 2015.  DOI: 10.1177/0271678X15606141  PMCID: PMC4794093
[Available on 2017-03-01]"































Slot "PMID":

[1] 26677842 26661151
I would be glad to hear from you. sincerely,Mehdi Najafi.

	[[alternative HTML version deleted]]


From jayuan2008 at yahoo.com  Fri Aug  5 12:10:13 2016
From: jayuan2008 at yahoo.com (Yuan Jian)
Date: Fri, 5 Aug 2016 10:10:13 +0000 (UTC)
Subject: [R] SAS file
References: <279353458.11938525.1470391813760.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <279353458.11938525.1470391813760.JavaMail.yahoo@mail.yahoo.com>

Hello,I have a SAS formatted file as attached, when I use lookup.xport i got error below> lookup.xport("patient.ssd01")Error in lookup.xport.inner(file) :?? unable to open file: 'No such file or directory'

can anyone please help me to figure it out?
thanksyuan

From rcorak at deloitte.com  Fri Aug  5 14:28:16 2016
From: rcorak at deloitte.com (Corak, Robert (US - Newton))
Date: Fri, 5 Aug 2016 12:28:16 +0000
Subject: [R] Segmentation Fault on Unix box with nloptr, works on Windows
Message-ID: <DM3PR85MB01231DFD8AB5F7A217DB5CF1BD180@DM3PR85MB0123.NAMPRD85.PROD.OUTLOOK.COM>

I have an R script that is giving me a Segmentation Fault depending on the size of the dataset.  It is only happening on our Unix installation of R Server.  I am able to run it against a Windows server with the exact same data and script successfully.

The Segmentation Fault occurs when I call nloptr.  The data I am passing in only has about 1350 records.  I have a print level of 2 set for the nloptr call.  I have been trying different record counts and was able to get to a point where I would either:


1)      1395 Recs: Fault immediately after calling the nloptr function

2)      1394 Recs: Start the optimization iteration inside nloptr for 1 iteration then fault

3)      1393 Recs: Get the optimization to iterate around 130 times before faulting

4)      1392 Recs: Getting the optimization to succeed

I am running the script from the command line using "Rscript myscript.R"

I have a tryCatch around the call but it just crashes with no additional info and is never caught.

I would assume that this is memory related but it looks like there is plenty of memory resources available (at least within the JVM).  I also tried to call:

options(java.parameters = "-Xmx8192m")

but it didn't seem to help.

These are the libraries I am installing:

*         library(rJava)

*         library(RJDBC)

*         library(RCurl)

*         library(stringr)

*         library(nloptr)

*         library(gsubfn)

Below is the setup snippet for the nloptr call:

# 4) Pick Algorithm to be used
                local_opts <- list (
                                "algorithm"   = "NLOPT_LD_MMA",
                                "xtol_rel"    = 1.0e-7
                )
                opts <- list (
                                "algorithm"   = "NLOPT_LD_AUGLAG",
                                "xtol_rel"    = 1.0e-7,
                                "maxeval"     = 1000,
                                "print_level" = 2,
                                "local_opts"  = local_opts
                )

# 5) Do optimization
                optRes <- nloptr (
                                x0          = x0,
                                eval_f      = eval_f,
                                lb          = lb,
                                ub          = ub,
                                eval_g_ineq = eval_g_ineq,
                                opts        = opts
                )

Does anyone have any thoughts or ideas on what might be happening here?

Thanks

Rob





This message (including any attachments) contains confid...{{dropped:18}}


From pdalgd at gmail.com  Fri Aug  5 15:08:48 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 5 Aug 2016 15:08:48 +0200
Subject: [R] Freq in dataframe
In-Reply-To: <876CEB8A3E7326488D0125D8D973B5DC19A2F947@SRVMBX02.aifa.lan>
References: <876CEB8A3E7326488D0125D8D973B5DC19A2F947@SRVMBX02.aifa.lan>
Message-ID: <9A4663E0-128C-4BE3-9944-628903FD15E4@gmail.com>

You want to use the as.data.frame method for tables, so

> ddat <- as.table(ddat)
> as.data.frame(ddat)
      Time   Dose Group Freq
1  Week 32 Dose 1     A    8
2  Week 52 Dose 1     A   10
3  Week 32 Dose 2     A    7
4  Week 52 Dose 2     A   13
5  Week 32 Dose 3     A    8
6  Week 52 Dose 3     A   15
7  Week 32 Dose 1     B    7
8  Week 52 Dose 1     B    9
9  Week 32 Dose 2     B    6
10 Week 52 Dose 2     B    9
11 Week 32 Dose 3     B    7
12 Week 52 Dose 3     B   10
13 Week 32 Dose 1     C   11
14 Week 52 Dose 1     C   13
15 Week 32 Dose 2     C    7
16 Week 52 Dose 2     C   16
17 Week 32 Dose 3     C    8
18 Week 52 Dose 3     C   16

-pd

On 05 Aug 2016, at 11:43 , Tripoli Massimiliano <M.Tripoli at aifa.gov.it> wrote:

> Dear R users,
> 
> # This is my data:
> 
> ddat <- array(c(8,10,7,13,8,15,
>              7,9,6,9,7,10,
>               11,13,7,16,8,16
>               ),
>              dim = c(2,3,3),
>               dimnames = list(
>              Time = c("Week 32","Week 52"),
>               Dose = c("Dose 1","Dose 2","Dose 3"),
>             Group = c("A","B","C")))
> ddat
> 
> # and I'd like to have data like that:
> 
> as.data.frame(UCBAdmissions)
> 
> # I tried with 
> 
> as.data.frame(ddat) 
> 
> # and this is the result:
> 
>> as.data.frame(ddat)
>        Dose 1.A Dose 2.A Dose 3.A Dose 1.B Dose 2.B Dose 3.B Dose 1.C Dose 2.C Dose 3.C
> Week 32        8        7        8        7        6        7       11        7        8
> Week 52       10       13       15        9        9       10       13       16       16
> 
> Someone could help me ?
> Thanks in advance,
> 
> M. Tripoli
> _________________________
> 
> Dott. Massimiliano Tripoli
> Ufficio Assessment Europeo - European Assessment Office 
> Agenzia Italiana del farmaco - Italian Medicine Agency
> Via del Tritone 181 - 00187 Roma
> Tel. +39-06-59784643
> E-mail: m.tripoli at aifa.gov.it
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From marc_schwartz at me.com  Fri Aug  5 15:12:34 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 05 Aug 2016 08:12:34 -0500
Subject: [R] Freq in dataframe
In-Reply-To: <876CEB8A3E7326488D0125D8D973B5DC19A2F947@SRVMBX02.aifa.lan>
References: <876CEB8A3E7326488D0125D8D973B5DC19A2F947@SRVMBX02.aifa.lan>
Message-ID: <92069042-E3C8-487D-8289-29D40B98DED0@me.com>


> On Aug 5, 2016, at 4:43 AM, Tripoli Massimiliano <M.Tripoli at aifa.gov.it> wrote:
> 
> Dear R users,
> 
> # This is my data:
> 
> ddat <- array(c(8,10,7,13,8,15,
>              7,9,6,9,7,10,
>               11,13,7,16,8,16
>               ),
>              dim = c(2,3,3),
>               dimnames = list(
>              Time = c("Week 32","Week 52"),
>               Dose = c("Dose 1","Dose 2","Dose 3"),
>             Group = c("A","B","C")))
> ddat
> 
> # and I'd like to have data like that:
> 
> as.data.frame(UCBAdmissions)
> 
> # I tried with 
> 
> as.data.frame(ddat) 
> 
> # and this is the result:
> 
>> as.data.frame(ddat)
>        Dose 1.A Dose 2.A Dose 3.A Dose 1.B Dose 2.B Dose 3.B Dose 1.C Dose 2.C Dose 3.C
> Week 32        8        7        8        7        6        7       11        7        8
> Week 52       10       13       15        9        9       10       13       16       16
> 
> Someone could help me ?
> Thanks in advance,
> 
> M. Tripoli


This has to do with method dispatch.

UCBAdmissions is a table:

> class(UCBAdmissions)
[1] "table"

ddat is an array as you created it:

> class(ddat)
[1] "array"


There is an as.data.frame() method for arrays (as.data.frame.array()) which results in a flattening of the object and this is defined in ?as.data.frame in the Details section:

"Arrays can be converted to data frames. One-dimensional arrays are treated like vectors and two-dimensional arrays like matrices. Arrays with more than two dimensions are converted to matrices by ?flattening? all dimensions after the first and creating suitable column labels."

In the case of UCBAdmissions, as.data.frame.table() is called yielding the alternative result that you observe.

If you want to get the same result from ddat, you can either coerce it to a table first:

> as.data.frame(as.table(ddat))
      Time   Dose Group Freq
1  Week 32 Dose 1     A    8
2  Week 52 Dose 1     A   10
3  Week 32 Dose 2     A    7
4  Week 52 Dose 2     A   13
5  Week 32 Dose 3     A    8
6  Week 52 Dose 3     A   15
7  Week 32 Dose 1     B    7
8  Week 52 Dose 1     B    9
9  Week 32 Dose 2     B    6
10 Week 52 Dose 2     B    9
11 Week 32 Dose 3     B    7
12 Week 52 Dose 3     B   10
13 Week 32 Dose 1     C   11
14 Week 52 Dose 1     C   13
15 Week 32 Dose 2     C    7
16 Week 52 Dose 2     C   16
17 Week 32 Dose 3     C    8
18 Week 52 Dose 3     C   16

or explicitly call as.data.frame.table():

> as.data.frame.table(ddat)
      Time   Dose Group Freq
1  Week 32 Dose 1     A    8
2  Week 52 Dose 1     A   10
3  Week 32 Dose 2     A    7
4  Week 52 Dose 2     A   13
5  Week 32 Dose 3     A    8
6  Week 52 Dose 3     A   15
7  Week 32 Dose 1     B    7
8  Week 52 Dose 1     B    9
9  Week 32 Dose 2     B    6
10 Week 52 Dose 2     B    9
11 Week 32 Dose 3     B    7
12 Week 52 Dose 3     B   10
13 Week 32 Dose 1     C   11
14 Week 52 Dose 1     C   13
15 Week 32 Dose 2     C    7
16 Week 52 Dose 2     C   16
17 Week 32 Dose 3     C    8
18 Week 52 Dose 3     C   16

Regards,

Marc Schwartz


From v.grabarnik at gmail.com  Fri Aug  5 16:07:19 2016
From: v.grabarnik at gmail.com (=?UTF-8?B?0JLQvtCy0LAg0JPRgNCw0LHQsNGA0L3QuNC6?=)
Date: Fri, 5 Aug 2016 15:07:19 +0100
Subject: [R] R help
Message-ID: <CAJfT-mUvb3ZWw2WXvGFm8OA7PjGK2oPFrQ4gexpZ1vv7JHf3bQ@mail.gmail.com>

Dear R command,

I was wondering if I could ask you recommendations on my problem if that is
fine with you.
Basically, I have a data frame with 5 columns and 10 000 tweets
recorded(rows). Those columns are: numberofatweet(number), tweet (actual
textual tweet), locations(from where tweet sent), badwords(words that
should not be used on twitter, that is just a column irrespective the
number of a tweet and it contains only 80 rows with one word recorded in
one cell.
My question is whether it is possible to select only the rows which would
contain such tweets, where in column "tweet"(actual text) there was one of
those words from badwords column present. I tried to use grep and grepl,
but nothing seems to be working.

Thank you in advance,
Vladimir

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Fri Aug  5 17:17:52 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Fri, 05 Aug 2016 16:17:52 +0100
Subject: [R] R help
In-Reply-To: <CAJfT-mUvb3ZWw2WXvGFm8OA7PjGK2oPFrQ4gexpZ1vv7JHf3bQ@mail.gmail.com>
Message-ID: <20160805161752.Horde.nqDqNbxRRFla7Jg53IdI7mF@mail.sapo.pt>

Hello,

Please use ?dput to post a data example. Use something like the  
following, where 'dat' is the name of your data.frame.

dput(head(dat, 30))? # paste the output of this in a mail

Hope this helps,

Rui Barradas
?

Citando ???? ????????? <v.grabarnik at gmail.com>:

> Dear R command,
>
> I was wondering if I could ask you recommendations on my problem if that is
> fine with you.
> Basically, I have a data frame with 5 columns and 10 000 tweets
> recorded(rows). Those columns are: numberofatweet(number), tweet (actual
> textual tweet), locations(from where tweet sent), badwords(words that
> should not be used on twitter, that is just a column irrespective the
> number of a tweet and it contains only 80 rows with one word recorded in
> one cell.
> My question is whether it is possible to select only the rows which would
> contain such tweets, where in column "tweet"(actual text) there was one of
> those words from badwords column present. I tried to use grep and grepl,
> but nothing seems to be working.
>
> Thank you in advance,
> Vladimir
>
> ? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Aug  5 17:48:20 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 5 Aug 2016 08:48:20 -0700
Subject: [R] (Solved] Re:  pubmed.mineR
In-Reply-To: <CABfCpgpfhDv7EufPXXGrJCejnE2tLPrK-7s+tYiKVCy1AGuUag@mail.gmail.com>
References: <CABfCpgroGiWnAaudJa_uwNXkGS_Mqw5-AhHjz7h5BqOYTsA7_A@mail.gmail.com>
	<CABfCpgpfhDv7EufPXXGrJCejnE2tLPrK-7s+tYiKVCy1AGuUag@mail.gmail.com>
Message-ID: <557F9D75-1345-43B4-A388-7B5A18570D53@comcast.net>


> On Aug 4, 2016, at 9:52 PM, Mehdi Najafi <sm.najafi92 at gmail.com> wrote:
> 
> ---------- Forwarded message ----------
> From: Mehdi Najafi <sm.najafi92 at gmail.com>
> Date: Fri, Aug 5, 2016 at 9:17 AM
> Subject: pubmed.mineR
> To: ramu at igib.in
> 
> 
> Hi dear helper, it has been a pleasure to read magnificat paper titled
> "pubmed.mineR: An R package with text-mining algorithms to analyse PubMed
> abstracts".
> I encuntered a problem using it.I wish you could help me with that.
> favorite
> <http://stackoverflow.com/questions/38781115/cant-find-objects-using-pubmed-miner-package#>
> 

I think it would have been courteous of you to post a solved message since you did so 10 hours ago on the crossposting.

Also please realize that crossposting is specifically deprecated on Rhelp.

-- 
David.
> 
> I have downloaded abstracts of interest from pubmed.com then read them
> using pubmed.mineR package with readabs() function, which is supposed to
> create object of class "Abstracs", but when I type in ls(), it gives me
> character(0), which as far as i know implies that there is no object in the
> memory. I want to search abstracts using searchabsL(x,include="term"), Here
> x is the object of class Abstracts containing data.though i don't know how?
> 
> after readabs() i face these lines:
> 
>> readabs("b.txt")
> 
> An object of class "Abstracts"
> 
> Slot "Journal":
> 
> [1] "1. Alzheimers Res Ther. 2015 Dec 18;7(1):75. doi:
> 10.1186/s13195-015-0159-5."
> 
> [2] "2. J Cereb Blood Flow Metab. 2016 Mar;36(3):621-8. doi:
> 10.1177/0271678X15606141."
> 
> 
> Slot "Abstract":
> 
> [1] " Diagnostic value of cerebrospinal fluid A?? ratios in preclinical
> Alzheimer's disease.  Adamczuk K(1,)(2), Schaeverbeke J(3,)(4),
> Vanderstichele HM(5), Lilja J(6,)(7), Nelissen N(8,)(9), Van Laere
> K(10,)(11), Dupont P(12,)(13), Hilven K(14), Poesen  K(15,)(16),
> Vandenberghe R(17,)(18,)(19).  Author information:  (1)Laboratory for
> Cognitive Neurology, KU Leuven, Herestraat 49, 3000, Leuven, Belgium.
> kate.adamczuk at med.kuleuven.be. (2)Alzheimer Research Centre KU Leuven,
> Leuven Institute of Neuroscience and Disease, Herestraat 49, 3000, Leuven,
> Belgium. kate.adamczuk at med.kuleuven.be. (3)Laboratory for Cognitive
> Neurology, KU Leuven, Herestraat 49, 3000, Leuven, Belgium.
> jolien.schaeverbeke at med.kuleuven.be. (4)Alzheimer Research Centre KU
> Leuven, Leuven Institute of Neuroscience and Disease, Herestraat 49, 3000,
> Leuven, Belgium. jolien.schaeverbeke at med.kuleuven.be. (5)ADx NeuroSciences,
> Technologiepark 4, 9052, Gent, Belgium. hugo.vanderstichele@
> adxneurosciences.com. (6)GE Healthcare, Bj??rkgatan 30, 751 25, Uppsala,
> Sweden. johan.lilja at radiol.uu.se. (7)Nuclear Medicine and PET, Department
> of Surgical Sciences, Uppsala University, 751 85, Uppsala, Sweden.
> johan.lilja at radiol.uu.se.  (8)Laboratory for Cognitive Neurology, KU
> Leuven, Herestraat 49, 3000, Leuven, Belgium. natalie.nelissen at psych.ox.ac.
> uk. (9)Department of Psychiatry, Oxford University, Oxford, OX3 7JX, UK.
> natalie.nelissen at psych.ox.ac.uk. (10)Alzheimer Research Centre KU Leuven,
> Leuven Institute of Neuroscience and Disease, Herestraat 49, 3000, Leuven,
> Belgium. koen.vanlaere at uzleuven.be. (11)Nuclear Medicine and Molecular
> Imaging Department, KU Leuven and University Hospitals Leuven, Herestraat
> 49, 3000, Leuven, Belgium. koen.vanlaere at uzleuven.be. (12)Laboratory for
> Cognitive Neurology, KU Leuven, Herestraat 49, 3000, Leuven, Belgium.
> patrick.dupont at med.kuleuven.be. (13)Alzheimer Research Centre KU Leuven,
> Leuven Institute of Neuroscience and Disease, Herestraat 49, 3000, Leuven,
> Belgium. patrick.dupont at med.kuleuven.be. (14)Laboratory for
> Neuroimmunology, KU Leuven, Herestraat 49, 3000, Leuven, Belgium.
> kelly.hilven at med.kuleuven.be. (15)Laboratory for Molecular Neurobiomarker
> Research, KU Leuven, Herestraat 49, 3000, Leuven, Belgium.
> koen.poesen at uzleuven.be. (16)Laboratory Medicine, UZ Leuven, Herestraat 49,
> 3000, Leuven, Belgium. koen.poesen at uzleuven.be. (17)Laboratory for
> Cognitive Neurology, KU Leuven, Herestraat 49, 3000, Leuven, Belgium.
> rik.vandenberghe at uz.kuleuven.ac.be. (18)Alzheimer Research Centre KU
> Leuven, Leuven Institute of Neuroscience and Disease, Herestraat 49, 3000,
> Leuven, Belgium. rik.vandenberghe at uz.kuleuven.ac.be. (19)Neurology
> Department, University Hospitals Leuven, Herestraat 49, 3000, Leuven,
> Belgium. rik.vandenberghe at uz.kuleuven.ac.be.  INTRODUCTION: In this study
> of preclinical Alzheimer's disease (AD) we assessed the added diagnostic
> value of using cerebrospinal fluid (CSF) A?? ratios rather than A??42 in
> isolation for detecting individuals who are positive on amyloid positron
> emission tomography (PET). METHODS: Thirty-eight community-recruited
> cognitively intact older adults (mean age 73, range 65-80 years) underwent
> (18)F-flutemetamol PET and CSF measurement of A??1-42, A??1-40, A??1-38,
> and total tau (ttau). (18)F-flutemetamol retention was quantified using
> standardized uptake value ratios in a composite cortical region  (SUVRcomp)
> with reference to cerebellar grey matter. Based on a prior autopsy
> validation study, the SUVRcomp cut-off was 1.57. Sensitivities,
> specificities and cut-offs were defined based on receiver operating
> characteristic analysis with CSF analytes as variables of interest and
> (18)F-flutemetamol positivity as the classifier. We also determined
> sensitivities and CSF cut-off values at fixed specificities of 90? % and
> 95? %. RESULTS: Seven out of 38 subjects (18? %) were positive on amyloid
> PET. A??42/ttau, A??42/A??40, A??42/A??38, and A??42 had the highest
> accuracy to identify amyloid-positive subjects (area under the curve
> (AUC)?????????0.908). A??40 and A??38 had significantly lower
> discriminative power (AUC???=???0.571). When specificity was fixed at 90? %
> and 95? %, A??42/ttau had the highest sensitivity among the different CSF
> markers (85.71? % and 71.43? %, respectively). Sensitivity of A??42 alone
> was significantly lower under these conditions (57.14? % and 42.86? %,
> respectively). CONCLUSION: For the CSF-based definition of preclinical AD,
> if a high specificity is required, our data support the use of A??42/ttau
> rather than using A??42 in isolation.  DOI: 10.1186/s13195-015-0159-5
> PMCID: PMC4683859"
> 
> [2] "Epub 2015 Sep 30.  Cerebrospinal fluid profiles with increasing number
> of cerebral microbleeds in a  continuum of cognitive impairment.  Shams
> S(1), Granberg T(2), Martola J(2), Li X(3), Shams M(2), Fereshtehnejad
> SM(3), Cavallin L(2), Aspelin P(2), Kristoffersen-Wiberg M(2), Wahlund
> LO(3).  Author information:  (1)Department of Clinical Science,
> Intervention, and Technology, Division of Medical Imaging and Technology,
> Karolinska Institutet, Stockholm, Sweden Department of Radiology,
> Karolinska University Hospital, Stockholm, Sweden sara.shams at ki.se.
> (2)Department of Clinical Science, Intervention, and Technology, Division
> of Medical Imaging and Technology, Karolinska Institutet, Stockholm, Sweden
> Department of Radiology, Karolinska University Hospital, Stockholm, Sweden.
> (3)Department of Neurobiology, Care Sciences, and Society, Karolinska
> Institutet, Stockholm, Sweden Division of Clinical Geriatrics, Karolinska
> University Hospital, Stockholm, Sweden.  Cerebral microbleeds (CMBs) are
> hypothesised to have an important yet unknown role in the dementia disease
> pathology. In this study we analysed increasing number of CMBs and their
> independent associations with routine cerebrospinal fluid (CSF) biomarkers
> in a continuum of cognitive impairment. A total of 1039 patients undergoing
> dementia investigation were analysed and underwent lumbar puncture, and an
> MRI scan. CSF samples were analysed for amyloid ?? (A??) 42, total tau
> (T-tau), tau phosphorylated at threonine 18 (P-tau) and CSF/serum albumin
> ratios. Increasing number of CMBs were independently associated with low
> A??42 levels, in the whole cohort, Alzheimer's disease and mild cognitive
> impairment (p???<???0.05). CSF/serum albumin ratios were high with multiple
> CMBs (p???<???0.001), reflecting accompanying blood-brain barrier
> dysfunction. T-tau and P-tau levels were lower in Alzheimer's patients with
> multiple CMBs when compared to zero CMBs, but did not change in the rest of
> the cohort. White matter hyperintensities were  associated with low A??42
> in the whole cohort and Alzheimer's disease (p???<???0.05).  A??42 is the
> routine CSF-biomarker mainly associated with CMBs in cognitive impairment,
> and there is an accumulative effect with increasing number of CMBs.  ?? The
> Author(s) 2015.  DOI: 10.1177/0271678X15606141  PMCID: PMC4794093
> [Available on 2017-03-01]"
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> Slot "PMID":
> 
> [1] 26677842 26661151
> I would be glad to hear from you. sincerely,Mehdi Najafi.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From marine.regis at hotmail.fr  Fri Aug  5 17:52:41 2016
From: marine.regis at hotmail.fr (Marine Regis)
Date: Fri, 5 Aug 2016 15:52:41 +0000
Subject: [R] Graphical output of density for the function gammamixEM
 (package mixtools)
Message-ID: <AMSPR07MB470F30CA09A2A9B87D0DA9EE2180@AMSPR07MB470.eurprd07.prod.outlook.com>

Hello,

I'm using the function gammamixEM from the package mixtools. How can I return the graphical output of density as in the function normalmixEM (i.e., the second plot in plot(x, density=TRUE)) ?

Thank you very much for your time.

Have a nice day.

Marine


	[[alternative HTML version deleted]]


From 9add2 at queensu.ca  Fri Aug  5 18:51:54 2016
From: 9add2 at queensu.ca (Alice Domalik)
Date: Fri, 5 Aug 2016 16:51:54 +0000
Subject: [R] adding a date column with dplyr
Message-ID: <MWHPR07MB292509D721C5F621DD116B80D0180@MWHPR07MB2925.namprd07.prod.outlook.com>

Hi all,


I'm having some difficulties adding a conditional element to my code.

I have a time series data set that contains GPS tracking coordinates for a population of animals.


ID                Date                                   Latitude           Longitude
15K12         2014-05-22 04:33:00     50.67675        -129.6553

15K12         2014-05-22 04:35:00     50.45613        -129.4566
15K19         2014-05-24 06:44:00     50.34611        -129.5678    (and so on)

I added a new column to this dataset, called "Night", which is the day of tracking for each animal, but with the time of 21:30.


ID                Date                                  Latitude           Longitude       Night
15K12         2014-05-22 04:33:00     50.67675        -129.6553       2014-05-22 21:30:00

15K12         2014-05-22 04:35:00     50.45613        -129.4566       2014-05-22 21:30:00
15K19         2014-05-24 06:44:00     50.34611        -129.5678       2015-05-24 21:30:00

I used the following code to do this:
library(dplyr)
library(lubridate)
Sys.setenv(TZ="Canada/Pacific")
df<-df%>%
  group_by(ID) %>%
  mutate(Night=as.POSIXct(date(min(Date)) + days(0) + hours(21) + minutes(30), tz="Canada/Pacific"))

However, I need to add a conditional element, because for one animal, "Night" needs to be 1 day later. I tried this code...

df<-df%>%
  group_by(ID) %>%
  mutate(Night=ifelse(test=(id=='M16c'),yes=as.POSIXct(date(min(Date)) + days(1) + hours(21) + minutes(30), tz="Canada/Pacific"), no=as.POSIXct(date(min(Date)) + days(0) + hours(21) + minutes(30), tz="Canada/Pacific")))

The code runs, but instead of having a date, I get a string of numbers like "1403497200" in the column "Night".
Any ideas what the problem could be?

Thanks, Alice




	[[alternative HTML version deleted]]


From gkraemer at bgc-jena.mpg.de  Fri Aug  5 18:07:39 2016
From: gkraemer at bgc-jena.mpg.de (Guido Kraemer)
Date: Fri, 5 Aug 2016 18:07:39 +0200
Subject: [R] makePSOCKcluster launches different version of R
Message-ID: <ed331160-bea9-7deb-8540-6053f531b7b5@bgc-jena.mpg.de>

Hi everyone,

we are running R on a Linux Cluster with several R versions installed in 
parallel.

If I run:

library(parallel)
cl <- makePSOCKcluster(
   rep('nodeX', 24),
   homogeneous = FALSE,
   rscript = '/usr/local/apps/R/R-3.2.2/bin/Rscript'
)

then still R-3.0.0 gets launched on nodeX. Version 3.0.0 is the default 
R version, which is started when I just type R in the terminal without 
any further configuration.

Cheers,
Guido


From oriolebaltimore at gmail.com  Fri Aug  5 19:04:20 2016
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Fri, 5 Aug 2016 13:04:20 -0400
Subject: [R] RGL library loading issues
Message-ID: <CAL2fYnNs0wp1=12n3jHCK048k6HWcOR_ejL4+ZK278LR=ueSUQ@mail.gmail.com>

Dear group:
I installed rgl on my mac through terminal.   I used
install.packages(rgl) and selected 118 server option.
Installation went well until, I get message checking if installed
packages working  and nothing happens.
I opened another terminal window and types library(rgl)  and I see my
X11quartz starts open.. and thats it.
Nothing happens after that - meaning I don't get > prompt in R window.
ctrl-c does not work, ctrl-d does not work.

> library(rgl)
^C
^D




Finally I had to kill -1 <PID>.

what could be the issue? appreciate your help.

Thanks
Adrian


X window systemm X quartz 2.7.9 (xorg-server 1.17.4)

> R.Version()
$platform
[1] "x86_64-apple-darwin12.5.0"

$arch
[1] "x86_64"

$os
[1] "darwin12.5.0"

$system
[1] "x86_64, darwin12.5.0"

$status
[1] ""

$major
[1] "3"

$minor
[1] "1.2"

$year
[1] "2014"

$month
[1] "10"

$day
[1] "31"

$`svn rev`
[1] "66913"

$language
[1] "R"

$version.string
[1] "R version 3.1.2 (2014-10-31)"

$nickname
[1] "Pumpkin Helmet"


From ulrik.stervbo at gmail.com  Fri Aug  5 19:14:59 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 05 Aug 2016 17:14:59 +0000
Subject: [R] R help
In-Reply-To: <20160805161752.Horde.nqDqNbxRRFla7Jg53IdI7mF@mail.sapo.pt>
References: <CAJfT-mUvb3ZWw2WXvGFm8OA7PjGK2oPFrQ4gexpZ1vv7JHf3bQ@mail.gmail.com>
	<20160805161752.Horde.nqDqNbxRRFla7Jg53IdI7mF@mail.sapo.pt>
Message-ID: <CAKVAULPT+bEXdLWSsU7mHpM-ySGQO+kpeWfa5PPgr8_UFC+hQQ@mail.gmail.com>

I'm not quite sure if this is what you are looking for:

example.df <- data.frame(words= c("A T", "Z H", "B E", "C P H"), badwords =
c("A|I|J|H|K|L"))

# Extract the column with bad words
badwords <- example.df$badwords
badwords <- as.character(badwords[1])

# Subset the data.frame
subset(example.df, grepl(badwords, words))

As I understand your email the badwords column contains all bad words in
each cell, so I assume they are separated somehow. In my example I use |
because it used to signify OR in grep. Since all elements of the bad word
column are equal I just get the first element, make sure it is a character,
and use grepl to subset the entire data.frame

HTH
Ulrik

On Fri, 5 Aug 2016 at 17:19 <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Please use ?dput to post a data example. Use something like the
> following, where 'dat' is the name of your data.frame.
>
> dput(head(dat, 30))  # paste the output of this in a mail
>
> Hope this helps,
>
> Rui Barradas
>
>
> Citando ???? ????????? <v.grabarnik at gmail.com>:
>
> > Dear R command,
> >
> > I was wondering if I could ask you recommendations on my problem if that
> is
> > fine with you.
> > Basically, I have a data frame with 5 columns and 10 000 tweets
> > recorded(rows). Those columns are: numberofatweet(number), tweet (actual
> > textual tweet), locations(from where tweet sent), badwords(words that
> > should not be used on twitter, that is just a column irrespective the
> > number of a tweet and it contains only 80 rows with one word recorded in
> > one cell.
> > My question is whether it is possible to select only the rows which would
> > contain such tweets, where in column "tweet"(actual text) there was one
> of
> > those words from badwords column present. I tried to use grep and grepl,
> > but nothing seems to be working.
> >
> > Thank you in advance,
> > Vladimir
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.htmland provide commented,
> > minimal, self-contained, reproducible code.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From shivipmp82 at gmail.com  Fri Aug  5 20:50:05 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Sat, 6 Aug 2016 00:20:05 +0530
Subject: [R] Creating Dummy Var in R for regression?
Message-ID: <CAB=p7Sr5tgNRy+c5DNKmXZqOqEy=jKoXd3KjHDkzi5Mb0h3Kig@mail.gmail.com>

Dear Team,

I need help with the below code in R:

gender_rec<- c('Dr','Father','Mr'=1, 'Miss','MS','Mrs'=2, 3)

reasons$salutation<- gender_rec[reasons$salutation].

This code gives me the correct output but it overwrites the
reason$salutation variable. I need to create a new variable gender to
capture gender details and leave salutation as it is.

i tried the below syntax but it is converting all to 1.

reasons$gender<- ifelse(reasons$salutation== "Mr" & reasons$salutation==
"Father","Male", ifelse(reasons$salutation=="Mrs" & reasons$salutation==
"Miss","Female",1))

Please suggest.

	[[alternative HTML version deleted]]


From martin.morgan at roswellpark.org  Fri Aug  5 20:58:47 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Fri, 5 Aug 2016 14:58:47 -0400
Subject: [R] makePSOCKcluster launches different version of R
In-Reply-To: <ed331160-bea9-7deb-8540-6053f531b7b5@bgc-jena.mpg.de>
References: <ed331160-bea9-7deb-8540-6053f531b7b5@bgc-jena.mpg.de>
Message-ID: <86dbc097-92dd-2a59-a737-e0c5b2d5396e@roswellpark.org>

On 08/05/2016 12:07 PM, Guido Kraemer wrote:
> Hi everyone,
>
> we are running R on a Linux Cluster with several R versions installed in
> parallel.
>
> If I run:
>
> library(parallel)
> cl <- makePSOCKcluster(
>   rep('nodeX', 24),
>   homogeneous = FALSE,
>   rscript = '/usr/local/apps/R/R-3.2.2/bin/Rscript'
> )

from ?makePSOCKcluster

      'homogeneous' Logical.  Are all the hosts running identical
           setups, so 'Rscript' can be launched using the same path on
           each?  Otherwise 'Rscript' has to be in the default path on
           the workers.

      'rscript' The path to 'Rscript' on the workers, used if
           'homogeneous' is true. Defaults to the full path on the
           master.

so homogeneous = FALSE and rscript = ... are incompatible. From your 
description it seems like you mean homogeneous = TRUE.

Martin

>
> then still R-3.0.0 gets launched on nodeX. Version 3.0.0 is the default
> R version, which is started when I just type R in the terminal without
> any further configuration.
>
> Cheers,
> Guido
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


This email message may contain legally privileged and/or...{{dropped:2}}


From murdoch.duncan at gmail.com  Fri Aug  5 22:34:29 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 5 Aug 2016 16:34:29 -0400
Subject: [R] RGL library loading issues
In-Reply-To: <CAL2fYnNs0wp1=12n3jHCK048k6HWcOR_ejL4+ZK278LR=ueSUQ@mail.gmail.com>
References: <CAL2fYnNs0wp1=12n3jHCK048k6HWcOR_ejL4+ZK278LR=ueSUQ@mail.gmail.com>
Message-ID: <fdedf965-4581-427d-ec87-f2b20c4525b6@gmail.com>

On 05/08/2016 1:04 PM, Adrian Johnson wrote:
> Dear group:
> I installed rgl on my mac through terminal.   I used
> install.packages(rgl) and selected 118 server option.
> Installation went well until, I get message checking if installed
> packages working  and nothing happens.
> I opened another terminal window and types library(rgl)  and I see my
> X11quartz starts open.. and thats it.
> Nothing happens after that - meaning I don't get > prompt in R window.
> ctrl-c does not work, ctrl-d does not work.

I haven't seen these symptoms before.  You're using a fairly old version 
of R, and of MacOS; I don't do any testing on those versions any more. 
Did you install from source?  Which version of rgl did you install?

Duncan Murdoch

>
>> library(rgl)
> ^C
> ^D
>
>
>
>
> Finally I had to kill -1 <PID>.
>
> what could be the issue? appreciate your help.
>
> Thanks
> Adrian
>
>
> X window systemm X quartz 2.7.9 (xorg-server 1.17.4)
>
>> R.Version()
> $platform
> [1] "x86_64-apple-darwin12.5.0"
>
> $arch
> [1] "x86_64"
>
> $os
> [1] "darwin12.5.0"
>
> $system
> [1] "x86_64, darwin12.5.0"
>
> $status
> [1] ""
>
> $major
> [1] "3"
>
> $minor
> [1] "1.2"
>
> $year
> [1] "2014"
>
> $month
> [1] "10"
>
> $day
> [1] "31"
>
> $`svn rev`
> [1] "66913"
>
> $language
> [1] "R"
>
> $version.string
> [1] "R version 3.1.2 (2014-10-31)"
>
> $nickname
> [1] "Pumpkin Helmet"
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Fri Aug  5 22:49:55 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Fri, 05 Aug 2016 21:49:55 +0100
Subject: [R] Creating Dummy Var in R for regression?
In-Reply-To: <CAB=p7Sr5tgNRy+c5DNKmXZqOqEy=jKoXd3KjHDkzi5Mb0h3Kig@mail.gmail.com>
Message-ID: <20160805214955.Horde.igroAepdmk6g1btHdi-_jcC@mail.sapo.pt>

Hello,

Your ifelse will never work because
reasons$salutation== "Mr" & reasons$salutation=="Father" is always FALSE
and so is reasons$salutation=="Mrs" & reasons$salutation=="Miss".
Try instead | (or), not & (and).

Hope this helps,

Rui Barradas

?

Citando Shivi Bhatia <shivipmp82 at gmail.com>:

> Dear Team,
>
> I need help with the below code in R:
>
> gender_rec<- c('Dr','Father','Mr'=1, 'Miss','MS','Mrs'=2, 3)
>
> reasons$salutation<- gender_rec[reasons$salutation].
>
> This code gives me the correct output but it overwrites the
> reason$salutation variable. I need to create a new variable gender to
> capture gender details and leave salutation as it is.
>
> i tried the below syntax but it is converting all to 1.
>
> reasons$gender<- ifelse(reasons$salutation== "Mr" & reasons$salutation==
> "Father","Male", ifelse(reasons$salutation=="Mrs" & reasons$salutation==
> "Miss","Female",1))
>
> Please suggest.
>
> ? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Aug  5 23:00:06 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 5 Aug 2016 14:00:06 -0700
Subject: [R] Creating Dummy Var in R for regression?
In-Reply-To: <20160805214955.Horde.igroAepdmk6g1btHdi-_jcC@mail.sapo.pt>
References: <CAB=p7Sr5tgNRy+c5DNKmXZqOqEy=jKoXd3KjHDkzi5Mb0h3Kig@mail.gmail.com>
	<20160805214955.Horde.igroAepdmk6g1btHdi-_jcC@mail.sapo.pt>
Message-ID: <CAGxFJbRtkq30bx+zseCTytkTJAaK+fEdrfWMF78JmvAkOpmQwQ@mail.gmail.com>

Just commenting on the email subject, not the content (which you have
already been helped with): there is no need to *ever* create a dummy
variable for regression in R if what you mean by this is what is
conventionally meant. R will create the model matrix with appropriate
"dummy variables" for factors as needed. See ?contrasts and ?C for
relevant details and/or consult an appropriate R tutorial.

Of course, if this is not what you meant, than ignore.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 5, 2016 at 1:49 PM,  <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> Your ifelse will never work because
> reasons$salutation== "Mr" & reasons$salutation=="Father" is always FALSE
> and so is reasons$salutation=="Mrs" & reasons$salutation=="Miss".
> Try instead | (or), not & (and).
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> Citando Shivi Bhatia <shivipmp82 at gmail.com>:
>
>> Dear Team,
>>
>> I need help with the below code in R:
>>
>> gender_rec<- c('Dr','Father','Mr'=1, 'Miss','MS','Mrs'=2, 3)
>>
>> reasons$salutation<- gender_rec[reasons$salutation].
>>
>> This code gives me the correct output but it overwrites the
>> reason$salutation variable. I need to create a new variable gender to
>> capture gender details and leave salutation as it is.
>>
>> i tried the below syntax but it is converting all to 1.
>>
>> reasons$gender<- ifelse(reasons$salutation== "Mr" & reasons$salutation==
>> "Father","Male", ifelse(reasons$salutation=="Mrs" & reasons$salutation==
>> "Miss","Female",1))
>>
>> Please suggest.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.htmland provide commented,
>> minimal, self-contained, reproducible code.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Fri Aug  5 23:18:16 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 5 Aug 2016 21:18:16 +0000
Subject: [R] adding a date column with dplyr
In-Reply-To: <MWHPR07MB292509D721C5F621DD116B80D0180@MWHPR07MB2925.namprd07.prod.outlook.com>
References: <MWHPR07MB292509D721C5F621DD116B80D0180@MWHPR07MB2925.namprd07.prod.outlook.com>
Message-ID: <D3CA4E33.18144F%macqueen1@llnl.gov>

What's wrong with this?

df$Night <- as.POSIXct( paste(format(df$Date,'%Y-%m-%d'),'21:30'))
  or
df$Night <- trunc(df$Date,'day') + 21*60*60 + 30*60

I believe both of those satisfy "the day of tracking for each animal, but
with the time of 21:30". But perhaps you meant the day that tracking
started, when tracking lasted more than one day...


And then just add 24 hours ("one day later") to that one special case

df$Night[df$ID=='M16c'] <- df$Night[df$ID=='M16c'] + 24*60*60

-Don


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/5/16, 9:51 AM, "R-help on behalf of Alice Domalik"
<r-help-bounces at r-project.org on behalf of 9add2 at queensu.ca> wrote:

>Hi all,
>
>
>I'm having some difficulties adding a conditional element to my code.
>
>I have a time series data set that contains GPS tracking coordinates for
>a population of animals.
>
>
>ID                Date                                   Latitude
>  Longitude
>15K12         2014-05-22 04:33:00     50.67675        -129.6553
>
>15K12         2014-05-22 04:35:00     50.45613        -129.4566
>15K19         2014-05-24 06:44:00     50.34611        -129.5678    (and
>so on)
>
>I added a new column to this dataset, called "Night", which is the day of
>tracking for each animal, but with the time of 21:30.
>
>
>ID                Date                                  Latitude
> Longitude       Night
>15K12         2014-05-22 04:33:00     50.67675        -129.6553
>2014-05-22 21:30:00
>
>15K12         2014-05-22 04:35:00     50.45613        -129.4566
>2014-05-22 21:30:00
>15K19         2014-05-24 06:44:00     50.34611        -129.5678
>2015-05-24 21:30:00
>
>I used the following code to do this:
>library(dplyr)
>library(lubridate)
>Sys.setenv(TZ="Canada/Pacific")
>df<-df%>%
>  group_by(ID) %>%
>  mutate(Night=as.POSIXct(date(min(Date)) + days(0) + hours(21) +
>minutes(30), tz="Canada/Pacific"))
>
>However, I need to add a conditional element, because for one animal,
>"Night" needs to be 1 day later. I tried this code...
>
>df<-df%>%
>  group_by(ID) %>%
>  mutate(Night=ifelse(test=(id=='M16c'),yes=as.POSIXct(date(min(Date)) +
>days(1) + hours(21) + minutes(30), tz="Canada/Pacific"),
>no=as.POSIXct(date(min(Date)) + days(0) + hours(21) + minutes(30),
>tz="Canada/Pacific")))
>
>The code runs, but instead of having a date, I get a string of numbers
>like "1403497200" in the column "Night".
>Any ideas what the problem could be?
>
>Thanks, Alice
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Aug  5 23:32:51 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 5 Aug 2016 14:32:51 -0700
Subject: [R] RGL library loading issues
In-Reply-To: <fdedf965-4581-427d-ec87-f2b20c4525b6@gmail.com>
References: <CAL2fYnNs0wp1=12n3jHCK048k6HWcOR_ejL4+ZK278LR=ueSUQ@mail.gmail.com>
	<fdedf965-4581-427d-ec87-f2b20c4525b6@gmail.com>
Message-ID: <596ED8B1-C31F-4B08-AF80-420E04A0E2D3@comcast.net>


> On Aug 5, 2016, at 1:34 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 05/08/2016 1:04 PM, Adrian Johnson wrote:
>> Dear group:
>> I installed rgl on my mac through terminal.   I used
>> install.packages(rgl) and selected 118 server option.
>> Installation went well until, I get message checking if installed
>> packages working  and nothing happens.
>> I opened another terminal window and types library(rgl)  and I see my
>> X11quartz starts open.. and thats it.
>> Nothing happens after that - meaning I don't get > prompt in R window.
>> ctrl-c does not work, ctrl-d does not work.
> 
> I haven't seen these symptoms before.  You're using a fairly old version of R, and of MacOS; I don't do any testing on those versions any more. Did you install from source? Which version of rgl did you install?

Also could be an incompatibility with XQuartz. That is the most recent version and I suspect the matching version of XQuartz for Yosemite was at least two versions earlier.

Might want to look: at https://www.xquartz.org/releases/XQuartz-2.7.7.html

-- 
David.
> 
> Duncan Murdoch
> 
>> 
>>> library(rgl)
>> ^C
>> ^D
>> 
>> 
>> 
>> 
>> Finally I had to kill -1 <PID>.
>> 
>> what could be the issue? appreciate your help.
>> 
>> Thanks
>> Adrian
>> 
>> 
>> X window systemm X quartz 2.7.9 (xorg-server 1.17.4)
>> 
>>> R.Version()
>> $platform
>> [1] "x86_64-apple-darwin12.5.0"
>> 
>> $arch
>> [1] "x86_64"
>> 
>> $os
>> [1] "darwin12.5.0"
>> 
>> $system
>> [1] "x86_64, darwin12.5.0"
>> 
>> $status
>> [1] ""
>> 
>> $major
>> [1] "3"
>> 
>> $minor
>> [1] "1.2"
>> 
>> $year
>> [1] "2014"
>> 
>> $month
>> [1] "10"
>> 
>> $day
>> [1] "31"
>> 
>> $`svn rev`
>> [1] "66913"
>> 
>> $language
>> [1] "R"
>> 
>> $version.string
>> [1] "R version 3.1.2 (2014-10-31)"
>> 
>> $nickname
>> [1] "Pumpkin Helmet"
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From shivipmp82 at gmail.com  Sat Aug  6 00:23:59 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Sat, 6 Aug 2016 03:53:59 +0530
Subject: [R] Creating Dummy Var in R for regression?
In-Reply-To: <CAGxFJbRtkq30bx+zseCTytkTJAaK+fEdrfWMF78JmvAkOpmQwQ@mail.gmail.com>
References: <CAB=p7Sr5tgNRy+c5DNKmXZqOqEy=jKoXd3KjHDkzi5Mb0h3Kig@mail.gmail.com>
	<20160805214955.Horde.igroAepdmk6g1btHdi-_jcC@mail.sapo.pt>
	<CAGxFJbRtkq30bx+zseCTytkTJAaK+fEdrfWMF78JmvAkOpmQwQ@mail.gmail.com>
Message-ID: <CAB=p7SocDqYK8dkg757B0eNdguKMfxbhxHoBimaUAMA6-fUnNg@mail.gmail.com>

Thanks you all for the assistance. This really helps.

Hi Bert: While searching nabble i got to know R with factors variables
there is no need to create dummy variable. However please consider this
situation:
I am in the process of building a logistic regression model on NPS data.
The outcome variable is CE i.e. customer experience which has 3 rating so
ordinal logistic regression will be used. However most of my variables are
categorical. For instance one of the variable is agent knowledge which is a
10 point scale.

This agent knowledge is again a 3 rated scale: high medium low hence i need
to group these 10 values into 3 groups & then as you suggested i can
directly enter them in the model without creating n-1 categories.

I have worked on SAS extensively hence found this a bit confusing.

Thanks for the help.

On Sat, Aug 6, 2016 at 2:30 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Just commenting on the email subject, not the content (which you have
> already been helped with): there is no need to *ever* create a dummy
> variable for regression in R if what you mean by this is what is
> conventionally meant. R will create the model matrix with appropriate
> "dummy variables" for factors as needed. See ?contrasts and ?C for
> relevant details and/or consult an appropriate R tutorial.
>
> Of course, if this is not what you meant, than ignore.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Aug 5, 2016 at 1:49 PM,  <ruipbarradas at sapo.pt> wrote:
> > Hello,
> >
> > Your ifelse will never work because
> > reasons$salutation== "Mr" & reasons$salutation=="Father" is always FALSE
> > and so is reasons$salutation=="Mrs" & reasons$salutation=="Miss".
> > Try instead | (or), not & (and).
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> >
> > Citando Shivi Bhatia <shivipmp82 at gmail.com>:
> >
> >> Dear Team,
> >>
> >> I need help with the below code in R:
> >>
> >> gender_rec<- c('Dr','Father','Mr'=1, 'Miss','MS','Mrs'=2, 3)
> >>
> >> reasons$salutation<- gender_rec[reasons$salutation].
> >>
> >> This code gives me the correct output but it overwrites the
> >> reason$salutation variable. I need to create a new variable gender to
> >> capture gender details and leave salutation as it is.
> >>
> >> i tried the below syntax but it is converting all to 1.
> >>
> >> reasons$gender<- ifelse(reasons$salutation== "Mr" & reasons$salutation==
> >> "Father","Male", ifelse(reasons$salutation=="Mrs" &
> reasons$salutation==
> >> "Miss","Female",1))
> >>
> >> Please suggest.
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.htmland provide commented,
> >> minimal, self-contained, reproducible code.
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From roundsjeremiah at gmail.com  Sat Aug  6 01:31:12 2016
From: roundsjeremiah at gmail.com (jeremiah rounds)
Date: Fri, 5 Aug 2016 16:31:12 -0700
Subject: [R] Creating Dummy Var in R for regression?
In-Reply-To: <CAB=p7SocDqYK8dkg757B0eNdguKMfxbhxHoBimaUAMA6-fUnNg@mail.gmail.com>
References: <CAB=p7Sr5tgNRy+c5DNKmXZqOqEy=jKoXd3KjHDkzi5Mb0h3Kig@mail.gmail.com>
	<20160805214955.Horde.igroAepdmk6g1btHdi-_jcC@mail.sapo.pt>
	<CAGxFJbRtkq30bx+zseCTytkTJAaK+fEdrfWMF78JmvAkOpmQwQ@mail.gmail.com>
	<CAB=p7SocDqYK8dkg757B0eNdguKMfxbhxHoBimaUAMA6-fUnNg@mail.gmail.com>
Message-ID: <CAOjnRsZNif-vye=RFUU1AkkwTyynqDF39AXFKY+3cY+EtcooBA@mail.gmail.com>

Something like:

d  =  data.frame(score = sample(1:10, 100, replace=TRUE))
d$score_t = "low"
d$score_t[d$score > 3] = "medium"
d$score_t[d$score >7 ] = "high"
d$score_t = factor(d$score_t, levels = c("low", "medium", "high"),
ordered=TRUE)  #set ordered = FALSE for dummy variables
X = model.matrix(~score_t, data=d)
X



On Fri, Aug 5, 2016 at 3:23 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:

> Thanks you all for the assistance. This really helps.
>
> Hi Bert: While searching nabble i got to know R with factors variables
> there is no need to create dummy variable. However please consider this
> situation:
> I am in the process of building a logistic regression model on NPS data.
> The outcome variable is CE i.e. customer experience which has 3 rating so
> ordinal logistic regression will be used. However most of my variables are
> categorical. For instance one of the variable is agent knowledge which is a
> 10 point scale.
>
> This agent knowledge is again a 3 rated scale: high medium low hence i need
> to group these 10 values into 3 groups & then as you suggested i can
> directly enter them in the model without creating n-1 categories.
>
> I have worked on SAS extensively hence found this a bit confusing.
>
> Thanks for the help.
>
> On Sat, Aug 6, 2016 at 2:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
> > Just commenting on the email subject, not the content (which you have
> > already been helped with): there is no need to *ever* create a dummy
> > variable for regression in R if what you mean by this is what is
> > conventionally meant. R will create the model matrix with appropriate
> > "dummy variables" for factors as needed. See ?contrasts and ?C for
> > relevant details and/or consult an appropriate R tutorial.
> >
> > Of course, if this is not what you meant, than ignore.
> >
> > Cheers,
> > Bert
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Fri, Aug 5, 2016 at 1:49 PM,  <ruipbarradas at sapo.pt> wrote:
> > > Hello,
> > >
> > > Your ifelse will never work because
> > > reasons$salutation== "Mr" & reasons$salutation=="Father" is always
> FALSE
> > > and so is reasons$salutation=="Mrs" & reasons$salutation=="Miss".
> > > Try instead | (or), not & (and).
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > >
> > >
> > > Citando Shivi Bhatia <shivipmp82 at gmail.com>:
> > >
> > >> Dear Team,
> > >>
> > >> I need help with the below code in R:
> > >>
> > >> gender_rec<- c('Dr','Father','Mr'=1, 'Miss','MS','Mrs'=2, 3)
> > >>
> > >> reasons$salutation<- gender_rec[reasons$salutation].
> > >>
> > >> This code gives me the correct output but it overwrites the
> > >> reason$salutation variable. I need to create a new variable gender to
> > >> capture gender details and leave salutation as it is.
> > >>
> > >> i tried the below syntax but it is converting all to 1.
> > >>
> > >> reasons$gender<- ifelse(reasons$salutation== "Mr" &
> reasons$salutation==
> > >> "Father","Male", ifelse(reasons$salutation=="Mrs" &
> > reasons$salutation==
> > >> "Miss","Female",1))
> > >>
> > >> Please suggest.
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.htmland provide commented,
> > >> minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Aug  6 08:58:09 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 6 Aug 2016 16:58:09 +1000
Subject: [R] SAS file
In-Reply-To: <279353458.11938525.1470391813760.JavaMail.yahoo@mail.yahoo.com>
References: <279353458.11938525.1470391813760.JavaMail.yahoo.ref@mail.yahoo.com>
	<279353458.11938525.1470391813760.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fWMPLBLVn5aoEdHmZoik=Ykhy7afxE=us2AwLcQTsgXjw@mail.gmail.com>

Hi Yuan,
Your file didn't make it. The error message you got is generally due
to a misspelt filename or to the file not being where you think it is.

Jim


On Fri, Aug 5, 2016 at 8:10 PM, Yuan Jian via R-help
<r-help at r-project.org> wrote:
> Hello,I have a SAS formatted file as attached, when I use lookup.xport i got error below> lookup.xport("patient.ssd01")Error in lookup.xport.inner(file) :   unable to open file: 'No such file or directory'
>
> can anyone please help me to figure it out?
> thanksyuan
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hblasdel at gmail.com  Fri Aug  5 22:11:36 2016
From: hblasdel at gmail.com (Hugo Blasdel)
Date: Fri, 5 Aug 2016 16:11:36 -0400
Subject: [R] Jackknife for scacofIndDiff ? Parallel?
Message-ID: <CAPTnJi4JR787UB26VCRHwNPgJ8NTNT3tmatd1UG=aM-+a6fgww@mail.gmail.com>

How can a smacofIndDiff result be evaluated by a jackknife?  If not now,
can it be expected?

The alternative seems to be a trip to Monte Carlo many gigaflops away,
hence a third question, is there experience and a model for parallel
running multiple smacofIndDiffs, using all available threads rather than
the one used without such.

	[[alternative HTML version deleted]]


From adomalik at sfu.ca  Sat Aug  6 02:59:45 2016
From: adomalik at sfu.ca (Alice Domalik)
Date: Fri, 5 Aug 2016 17:59:45 -0700 (PDT)
Subject: [R] adding a date column with dplyr
In-Reply-To: <D3CA4E33.18144F%macqueen1@llnl.gov>
References: <MWHPR07MB292509D721C5F621DD116B80D0180@MWHPR07MB2925.namprd07.prod.outlook.com>
	<D3CA4E33.18144F%macqueen1@llnl.gov>
Message-ID: <814551769.13967424.1470445185755.JavaMail.zimbra@sfu.ca>

Thanks so much, that worked! 

----- Original Message -----

From: "Don MacQueen" <macqueen1 at llnl.gov> 
To: "Alice Domalik" <9add2 at queensu.ca>, r-help at r-project.org 
Sent: Friday, August 5, 2016 2:18:16 PM 
Subject: Re: [R] adding a date column with dplyr 

What's wrong with this? 

df$Night <- as.POSIXct( paste(format(df$Date,'%Y-%m-%d'),'21:30')) 
or 
df$Night <- trunc(df$Date,'day') + 21*60*60 + 30*60 

I believe both of those satisfy "the day of tracking for each animal, but 
with the time of 21:30". But perhaps you meant the day that tracking 
started, when tracking lasted more than one day... 


And then just add 24 hours ("one day later") to that one special case 

df$Night[df$ID=='M16c'] <- df$Night[df$ID=='M16c'] + 24*60*60 

-Don 


-- 
Don MacQueen 

Lawrence Livermore National Laboratory 
7000 East Ave., L-627 
Livermore, CA 94550 
925-423-1062 





On 8/5/16, 9:51 AM, "R-help on behalf of Alice Domalik" 
<r-help-bounces at r-project.org on behalf of 9add2 at queensu.ca> wrote: 

>Hi all, 
> 
> 
>I'm having some difficulties adding a conditional element to my code. 
> 
>I have a time series data set that contains GPS tracking coordinates for 
>a population of animals. 
> 
> 
>ID Date Latitude 
> Longitude 
>15K12 2014-05-22 04:33:00 50.67675 -129.6553 
> 
>15K12 2014-05-22 04:35:00 50.45613 -129.4566 
>15K19 2014-05-24 06:44:00 50.34611 -129.5678 (and 
>so on) 
> 
>I added a new column to this dataset, called "Night", which is the day of 
>tracking for each animal, but with the time of 21:30. 
> 
> 
>ID Date Latitude 
> Longitude Night 
>15K12 2014-05-22 04:33:00 50.67675 -129.6553 
>2014-05-22 21:30:00 
> 
>15K12 2014-05-22 04:35:00 50.45613 -129.4566 
>2014-05-22 21:30:00 
>15K19 2014-05-24 06:44:00 50.34611 -129.5678 
>2015-05-24 21:30:00 
> 
>I used the following code to do this: 
>library(dplyr) 
>library(lubridate) 
>Sys.setenv(TZ="Canada/Pacific") 
>df<-df%>% 
> group_by(ID) %>% 
> mutate(Night=as.POSIXct(date(min(Date)) + days(0) + hours(21) + 
>minutes(30), tz="Canada/Pacific")) 
> 
>However, I need to add a conditional element, because for one animal, 
>"Night" needs to be 1 day later. I tried this code... 
> 
>df<-df%>% 
> group_by(ID) %>% 
> mutate(Night=ifelse(test=(id=='M16c'),yes=as.POSIXct(date(min(Date)) + 
>days(1) + hours(21) + minutes(30), tz="Canada/Pacific"), 
>no=as.POSIXct(date(min(Date)) + days(0) + hours(21) + minutes(30), 
>tz="Canada/Pacific"))) 
> 
>The code runs, but instead of having a date, I get a string of numbers 
>like "1403497200" in the column "Night". 
>Any ideas what the problem could be? 
> 
>Thanks, Alice 
> 
> 
> 
> 
> [[alternative HTML version deleted]] 
> 
>______________________________________________ 
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help 
>PLEASE do read the posting guide 
>http://www.R-project.org/posting-guide.html 
>and provide commented, minimal, self-contained, reproducible code. 



	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Aug  7 01:19:53 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 7 Aug 2016 09:19:53 +1000
Subject: [R] R help
In-Reply-To: <CAJfT-mUvb3ZWw2WXvGFm8OA7PjGK2oPFrQ4gexpZ1vv7JHf3bQ@mail.gmail.com>
References: <CAJfT-mUvb3ZWw2WXvGFm8OA7PjGK2oPFrQ4gexpZ1vv7JHf3bQ@mail.gmail.com>
Message-ID: <CA+8X3fVE0ky0qf3KKJc7A1zLKySChWws_g_M-4NqGwkEDu+Mdg@mail.gmail.com>

Hi Vladimir,
Do you want something like this?

vdat<-read.table(text="numberoftweet,tweet,locations,badwords
1,My cat is asleep,London,glum
2,My cat is flying,Paris,dashed
3,My cat is dancing,Berlin,mopey
4,My cat is singing,Rome,ill
5,My cat is reading,Budapest,sad
6,My cat is eating,Amsterdam,annoyed
7,My cat is hiding,Copenhagen,crazy
8,My cat is fluffy,Vilnius,terrified
9,My cat is annoyed,Athens,sick
10,My cat is exercising,Ankara,mortified
11,My cat is dreaming,Kracow,irked
12,My cat is mopey,Vienna,uneasy
13,My cat is glum,Brussels,upset",
sep=",",header=TRUE,stringsAsFactors=FALSE)

badwords<-paste(vdat$badwords,collapse="|")

names(unlist(sapply(vdat$tweet,grep,pattern=badwords)))

Jim


On Sat, Aug 6, 2016 at 12:07 AM, ???? ????????? <v.grabarnik at gmail.com> wrote:
> Dear R command,
>
> I was wondering if I could ask you recommendations on my problem if that is
> fine with you.
> Basically, I have a data frame with 5 columns and 10 000 tweets
> recorded(rows). Those columns are: numberofatweet(number), tweet (actual
> textual tweet), locations(from where tweet sent), badwords(words that
> should not be used on twitter, that is just a column irrespective the
> number of a tweet and it contains only 80 rows with one word recorded in
> one cell.
> My question is whether it is possible to select only the rows which would
> contain such tweets, where in column "tweet"(actual text) there was one of
> those words from badwords column present. I tried to use grep and grepl,
> but nothing seems to be working.
>
> Thank you in advance,
> Vladimir
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mohsen.sharafatmandrad at gmail.com  Sun Aug  7 11:34:47 2016
From: mohsen.sharafatmandrad at gmail.com (Mohsen Sharafatmandrad)
Date: Sun, 7 Aug 2016 02:34:47 -0700
Subject: [R] changing x and y ranges in a PCA plot created by library(labdsv)
Message-ID: <CAERY0-qrLpoWBoNif-M6ukvEPZy4MtoY96Apv6B-MnawDMK_KQ@mail.gmail.com>

Hi,

I want to change x and y ranges in a PCA plot created by library(labdsv).
When I run "plot(o.pca, xlim=c(-2, 3), ylim=c(-2, 4))", nothing will
change. I really appreciate if somebody can help on this.

Cheers

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Sun Aug  7 16:49:36 2016
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 7 Aug 2016 06:49:36 -0800
Subject: [R] SAS file
In-Reply-To: <279353458.11938525.1470391813760.JavaMail.yahoo@mail.yahoo.com>
References: <279353458.11938525.1470391813760.javamail.yahoo.ref@mail.yahoo.com>
Message-ID: <E8EFEE4A63A.00000141jrkrideau@inbox.com>

As Jim says the file did not arrive. R-help is very fussy about what kind of files it accepts. If you are still having a problem it would be a good idea to upload it to file-sharing place such as Dropbox or Mediafire and just post the link here.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: r-help at r-project.org
> Sent: Fri, 5 Aug 2016 10:10:13 +0000 (UTC)
> To: r-help at r-project.org
> Subject: [R] SAS file
> 
> Hello,I have a SAS formatted file as attached, when I use lookup.xport i
> got error below> lookup.xport("patient.ssd01")Error in
> lookup.xport.inner(file) :?? unable to open file: 'No such file or
> directory'
> 
> can anyone please help me to figure it out?
> thanksc
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From ssefick at gmail.com  Sun Aug  7 18:05:10 2016
From: ssefick at gmail.com (stephen sefick)
Date: Sun, 7 Aug 2016 11:05:10 -0500
Subject: [R] changing x and y ranges in a PCA plot created by
	library(labdsv)
In-Reply-To: <CAERY0-qrLpoWBoNif-M6ukvEPZy4MtoY96Apv6B-MnawDMK_KQ@mail.gmail.com>
References: <CAERY0-qrLpoWBoNif-M6ukvEPZy4MtoY96Apv6B-MnawDMK_KQ@mail.gmail.com>
Message-ID: <CADKEMqhwrtWWqbOeKZt=BHew=KvFnZHFBiQK-vgUX0CQtoKZfA@mail.gmail.com>

Can you provide code and data (with dput)? You will likely get an answer
more quickly.

On Sun, Aug 7, 2016 at 4:34 AM, Mohsen Sharafatmandrad <
mohsen.sharafatmandrad at gmail.com> wrote:

> Hi,
>
> I want to change x and y ranges in a PCA plot created by library(labdsv).
> When I run "plot(o.pca, xlim=c(-2, 3), ylim=c(-2, 4))", nothing will
> change. I really appreciate if somebody can help on this.
>
> Cheers
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From cjrinconr at unal.edu.co  Sun Aug  7 18:13:12 2016
From: cjrinconr at unal.edu.co (Carlos Javier Rincon Rodriguez)
Date: Sun, 7 Aug 2016 11:13:12 -0500
Subject: [R] metaprop
Message-ID: <CABeLv6jUWf9HfgiC710M572TsQ01p1eUBwpYOafVVvqpNAPHoQ@mail.gmail.com>

hi,

i am using the funtion metaprop but when i try to save the proportion
estimation by subgrup using the option "byvar", the value in TE.fixed.w are
the transformed proportion, and i need the untranformed proportion. I try
with the option backtranf=true, but doesn`t change anithing.

 I have so many subgroup that i need to be able to save my result but i can
find where the untranformed proportion keep saving.

thanks for the help.

bye

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sun Aug  7 18:53:45 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 7 Aug 2016 09:53:45 -0700
Subject: [R] changing x and y ranges in a PCA plot created by
	library(labdsv)
In-Reply-To: <CAERY0-qrLpoWBoNif-M6ukvEPZy4MtoY96Apv6B-MnawDMK_KQ@mail.gmail.com>
References: <CAERY0-qrLpoWBoNif-M6ukvEPZy4MtoY96Apv6B-MnawDMK_KQ@mail.gmail.com>
Message-ID: <CAF8bMcYTvSm=ce6p60Y+PJEb9xvYSFb-+GRTxifi3DYPXWSkMA@mail.gmail.com>

labdsv::plot.pca() does not pass its unrecognized arguments (in ...)
to plot().  You can fix this by adding the argument ... to its call to
plot(),
right after 'main = title', in plot.pca
or by mailing the maintainer
  > maintainer("labdsv")
  [1] "David W. Roberts <droberts at montana.edu>"
and asking him to change it.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, Aug 7, 2016 at 2:34 AM, Mohsen Sharafatmandrad <
mohsen.sharafatmandrad at gmail.com> wrote:

> Hi,
>
> I want to change x and y ranges in a PCA plot created by library(labdsv).
> When I run "plot(o.pca, xlim=c(-2, 3), ylim=c(-2, 4))", nothing will
> change. I really appreciate if somebody can help on this.
>
> Cheers
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From shivipmp82 at gmail.com  Sun Aug  7 20:10:49 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Sun, 7 Aug 2016 23:40:49 +0530
Subject: [R] Creating Dummy Var in R for regression?
In-Reply-To: <CAOjnRsZNif-vye=RFUU1AkkwTyynqDF39AXFKY+3cY+EtcooBA@mail.gmail.com>
References: <CAB=p7Sr5tgNRy+c5DNKmXZqOqEy=jKoXd3KjHDkzi5Mb0h3Kig@mail.gmail.com>
	<20160805214955.Horde.igroAepdmk6g1btHdi-_jcC@mail.sapo.pt>
	<CAGxFJbRtkq30bx+zseCTytkTJAaK+fEdrfWMF78JmvAkOpmQwQ@mail.gmail.com>
	<CAB=p7SocDqYK8dkg757B0eNdguKMfxbhxHoBimaUAMA6-fUnNg@mail.gmail.com>
	<CAOjnRsZNif-vye=RFUU1AkkwTyynqDF39AXFKY+3cY+EtcooBA@mail.gmail.com>
Message-ID: <CAB=p7SoCe4aoJOohkT9S2kkccCY1+kzyikY0fkaQ+MpxoOjZwg@mail.gmail.com>

Thank you Jeremiah and all others for the assistance. This really helped.

On Sat, Aug 6, 2016 at 5:01 AM, jeremiah rounds <roundsjeremiah at gmail.com>
wrote:

> Something like:
>
> d  =  data.frame(score = sample(1:10, 100, replace=TRUE))
> d$score_t = "low"
> d$score_t[d$score > 3] = "medium"
> d$score_t[d$score >7 ] = "high"
> d$score_t = factor(d$score_t, levels = c("low", "medium", "high"),
> ordered=TRUE)  #set ordered = FALSE for dummy variables
> X = model.matrix(~score_t, data=d)
> X
>
>
>
> On Fri, Aug 5, 2016 at 3:23 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
>
>> Thanks you all for the assistance. This really helps.
>>
>> Hi Bert: While searching nabble i got to know R with factors variables
>> there is no need to create dummy variable. However please consider this
>> situation:
>> I am in the process of building a logistic regression model on NPS data.
>> The outcome variable is CE i.e. customer experience which has 3 rating so
>> ordinal logistic regression will be used. However most of my variables are
>> categorical. For instance one of the variable is agent knowledge which is
>> a
>> 10 point scale.
>>
>> This agent knowledge is again a 3 rated scale: high medium low hence i
>> need
>> to group these 10 values into 3 groups & then as you suggested i can
>> directly enter them in the model without creating n-1 categories.
>>
>> I have worked on SAS extensively hence found this a bit confusing.
>>
>> Thanks for the help.
>>
>> On Sat, Aug 6, 2016 at 2:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>
>> > Just commenting on the email subject, not the content (which you have
>> > already been helped with): there is no need to *ever* create a dummy
>> > variable for regression in R if what you mean by this is what is
>> > conventionally meant. R will create the model matrix with appropriate
>> > "dummy variables" for factors as needed. See ?contrasts and ?C for
>> > relevant details and/or consult an appropriate R tutorial.
>> >
>> > Of course, if this is not what you meant, than ignore.
>> >
>> > Cheers,
>> > Bert
>> >
>> >
>> > Bert Gunter
>> >
>> > "The trouble with having an open mind is that people keep coming along
>> > and sticking things into it."
>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> > On Fri, Aug 5, 2016 at 1:49 PM,  <ruipbarradas at sapo.pt> wrote:
>> > > Hello,
>> > >
>> > > Your ifelse will never work because
>> > > reasons$salutation== "Mr" & reasons$salutation=="Father" is always
>> FALSE
>> > > and so is reasons$salutation=="Mrs" & reasons$salutation=="Miss".
>> > > Try instead | (or), not & (and).
>> > >
>> > > Hope this helps,
>> > >
>> > > Rui Barradas
>> > >
>> > >
>> > >
>> > > Citando Shivi Bhatia <shivipmp82 at gmail.com>:
>> > >
>> > >> Dear Team,
>> > >>
>> > >> I need help with the below code in R:
>> > >>
>> > >> gender_rec<- c('Dr','Father','Mr'=1, 'Miss','MS','Mrs'=2, 3)
>> > >>
>> > >> reasons$salutation<- gender_rec[reasons$salutation].
>> > >>
>> > >> This code gives me the correct output but it overwrites the
>> > >> reason$salutation variable. I need to create a new variable gender to
>> > >> capture gender details and leave salutation as it is.
>> > >>
>> > >> i tried the below syntax but it is converting all to 1.
>> > >>
>> > >> reasons$gender<- ifelse(reasons$salutation== "Mr" &
>> reasons$salutation==
>> > >> "Father","Male", ifelse(reasons$salutation=="Mrs" &
>> > reasons$salutation==
>> > >> "Miss","Female",1))
>> > >>
>> > >> Please suggest.
>> > >>
>> > >>         [[alternative HTML version deleted]]
>> > >>
>> > >> ______________________________________________
>> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >> PLEASE do read the posting guide
>> > >> http://www.R-project.org/posting-guide.htmland provide commented,
>> > >> minimal, self-contained, reproducible code.
>> > >
>> > >
>> > >
>> > >         [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide http://www.R-project.org/
>> > posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Aug  8 01:22:21 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 8 Aug 2016 09:22:21 +1000
Subject: [R] R help
In-Reply-To: <CAJfT-mWX4qXR1Kuv0VZbgm3PX2-LUGvAF3u2ChRFA-U1uD7b+Q@mail.gmail.com>
References: <CAJfT-mUvb3ZWw2WXvGFm8OA7PjGK2oPFrQ4gexpZ1vv7JHf3bQ@mail.gmail.com>
	<CA+8X3fVE0ky0qf3KKJc7A1zLKySChWws_g_M-4NqGwkEDu+Mdg@mail.gmail.com>
	<CAJfT-mWX4qXR1Kuv0VZbgm3PX2-LUGvAF3u2ChRFA-U1uD7b+Q@mail.gmail.com>
Message-ID: <CA+8X3fXp-adY4k5H5AJ=G9=kw0Qe3640xZzWDuYrFHLVftNryg@mail.gmail.com>

Hi Vladimir,
This may fix the NA problem:

vdat<-read.table(text="numberoftweet,tweet,locations,badwords
1,My cat is asleep,London,glum
2,My cat is flying,Paris,dashed
3,My cat is dancing,Berlin,mopey
4,My cat is singing,Rome,ill
5,My cat is reading,Budapest,sad
6,My cat is eating,Amsterdam,annoyed
7,My cat is hiding,Copenhagen,crazy
8,My cat is fluffy,Vilnius,terrified
9,My cat is annoyed,Athens,sick
10,My cat is exercising,Ankara,mortified
11,My cat is dreaming,Kracow,irked
12,My cat is mopey,Vienna,uneasy
13,My cat is glum,Brussels,upset
14,My cat is swinging,Madrid,
15,My cat is crazy,Ljubljana,",
sep=",",header=TRUE,stringsAsFactors=FALSE)

vdat$badwords[!nchar(vdat$badwords)]<-NA

badwords<-paste(vdat$badwords[!is.na(vdat$badwords)],collapse="|")

names(unlist(sapply(vdat$tweet,grep,pattern=badwords)))

Jim


On Sun, Aug 7, 2016 at 6:43 PM, ???? ????????? <v.grabarnik at gmail.com> wrote:
> Hi Jim!
>
> That is exactly what I mean. Your example does the job I was looking for.
> If I refer to your example, my badwords column is not completed for all
> rows, like yours. For example it has only 10 values, but there are much more
> rows. When I try to introduce NA for blanks and write
> badwords<-paste(vdat$badwords,collapse="|")
> it collapses all values and writes smth like: word|word|NA|NA
> and if I dont introduce NAs when reading data, the outcome is still like:
> word|word|word|word||||||||||||||||
> and when I try to
> names(unlist(sapply(vdat$tweet,grep,pattern=badwords))) there is a mistake.
> I had this question before but do you know by any chance how to separate
> just those words in a column badwords and not include NA's or blanks.
>
> Thank you,
> Vladimir
>
> 2016-08-07 0:19 GMT+01:00 Jim Lemon <drjimlemon at gmail.com>:
>>
>> Hi Vladimir,
>> Do you want something like this?
>>
>> vdat<-read.table(text="numberoftweet,tweet,locations,badwords
>> 1,My cat is asleep,London,glum
>> 2,My cat is flying,Paris,dashed
>> 3,My cat is dancing,Berlin,mopey
>> 4,My cat is singing,Rome,ill
>> 5,My cat is reading,Budapest,sad
>> 6,My cat is eating,Amsterdam,annoyed
>> 7,My cat is hiding,Copenhagen,crazy
>> 8,My cat is fluffy,Vilnius,terrified
>> 9,My cat is annoyed,Athens,sick
>> 10,My cat is exercising,Ankara,mortified
>> 11,My cat is dreaming,Kracow,irked
>> 12,My cat is mopey,Vienna,uneasy
>> 13,My cat is glum,Brussels,upset",
>> sep=",",header=TRUE,stringsAsFactors=FALSE)
>>
>> badwords<-paste(vdat$badwords,collapse="|")
>>
>> names(unlist(sapply(vdat$tweet,grep,pattern=badwords)))
>>
>> Jim
>>
>>
>> On Sat, Aug 6, 2016 at 12:07 AM, ???? ????????? <v.grabarnik at gmail.com>
>> wrote:
>> > Dear R command,
>> >
>> > I was wondering if I could ask you recommendations on my problem if that
>> > is
>> > fine with you.
>> > Basically, I have a data frame with 5 columns and 10 000 tweets
>> > recorded(rows). Those columns are: numberofatweet(number), tweet (actual
>> > textual tweet), locations(from where tweet sent), badwords(words that
>> > should not be used on twitter, that is just a column irrespective the
>> > number of a tweet and it contains only 80 rows with one word recorded in
>> > one cell.
>> > My question is whether it is possible to select only the rows which
>> > would
>> > contain such tweets, where in column "tweet"(actual text) there was one
>> > of
>> > those words from badwords column present. I tried to use grep and grepl,
>> > but nothing seems to be working.
>> >
>> > Thank you in advance,
>> > Vladimir
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> ? ?????????,
> ?????? ?????????


From glennmschultz at me.com  Mon Aug  8 03:42:32 2016
From: glennmschultz at me.com (Glenn Schultz)
Date: Sun, 07 Aug 2016 20:42:32 -0500
Subject: [R] open a zip file
Message-ID: <35A53331-BDDD-4140-B555-6365FE092910@me.com>

All I have this code

 #=============== Function Downloads the Factor File
  #' A function to download FNMA Pool Factors
  #' 
  #' @importFrom httr GET
  #' @importFrom httr write_disk
  #' @importFrom httr http_status
  #' @importFrom httr progress
  #' @export
  FNMAPoolFactor <- function(){
    Year <- format(Sys.Date(), "%Y")
    Month <- format(Sys.Date(), "%m")
    response <- 
      httr::GET(
        paste("https://mbsdisclosure.fanniemae.com/disclosure-docs/monthly/",
            "mbs", 
            as.character(Month), 
            as.character(Year),
            ".zip", 
            sep = ""),
      httr::write_disk(paste("~/FNMA/mbs/",
                       as.character(Month), 
                       as.character(Year),
                       ".zip", 
                       sep = ""), overwrite = FALSE), httr::progress())
  httr::http_status(response)
  }

Which results in a zip file but I cannot open the file with unzip or any other R functions what have I done wrong?

Glenn


From roy.mendelssohn at noaa.gov  Mon Aug  8 04:07:20 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Sun, 7 Aug 2016 19:07:20 -0700
Subject: [R] open a zip file
In-Reply-To: <35A53331-BDDD-4140-B555-6365FE092910@me.com>
References: <35A53331-BDDD-4140-B555-6365FE092910@me.com>
Message-ID: <030FFF5C-6F64-4305-8E83-55193B6CEBF3@noaa.gov>

If I break it into parts, I find that the "GET" fails.

>   Year <- format(Sys.Date(), "%Y")
>    Month <- format(Sys.Date(), "%m")
> junk <- paste("https://mbsdisclosure.fanniemae.com/disclosure-docs/monthly/",
+            "mbs", 
+            as.character(Month), 
+            as.character(Year),
+            ".zip", 
+            sep = "")
> junk
[1] "https://mbsdisclosure.fanniemae.com/disclosure-docs/monthly/mbs082016.zip"
> httr::GET("https://mbsdisclosure.fanniemae.com/disclosure-docs/monthly/mbs082016.zip")
Response [https://mbsdisclosure.fanniemae.com/disclosure-docs/monthly/mbs082016.zip]
  Date: 2016-08-08 02:02
  Status: 404
  Content-Type: text/html; charset=iso-8859-1
  Size: 235 B
<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN">
<html><head>
<title>404 Not Found</title>
</head><body>
<h1>Not Found</h1>
<p>The requested URL /disclosure-docs/monthly/mbs082016.zip was not found on this server.</p>
</body></html>


Your saved file will have the ending ".zip" no matter what, because that is what you called it, but I wouldn't be surprised if it just a txt file with the error message.

HTH,

-Roy

> On Aug 7, 2016, at 6:42 PM, Glenn Schultz <glennmschultz at me.com> wrote:
> 
> paste("https://mbsdisclosure.fanniemae.com/disclosure-docs/monthly/",
>            "mbs", 
>            as.character(Month), 
>            as.character(Year),
>            ".zip", 
>            sep = "")
> junk <- paste("https://mbsdisclosure.fanniemae.com/disclosure-docs/monthly/",
+            "mbs", 
+            as.character(Month), 
+            as.character(Year),
+            ".zip", 
+            sep = "")
> junk
[1] "https://mbsdisclosure.fanniemae.com/disclosure-docs/monthly/mbs082016.zip"
> httr::GET("https://mbsdisclosure.fanniemae.com/disclosure-docs/monthly/mbs082016.zip")
Response [https://mbsdisclosure.fanniemae.com/disclosure-docs/monthly/mbs082016.zip]
  Date: 2016-08-08 02:02
  Status: 404
  Content-Type: text/html; charset=iso-8859-1
  Size: 235 B
<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN">
<html><head>
<title>404 Not Found</title>
</head><body>
<h1>Not Found</h1>
<p>The requested URL /disclosure-docs/monthly/mbs082016.zip was not found on this server.</p>
</body></html>

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From djnordlund at gmail.com  Mon Aug  8 08:17:32 2016
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Sun, 7 Aug 2016 23:17:32 -0700
Subject: [R] SAS file
In-Reply-To: <E8EFEE4A63A.00000141jrkrideau@inbox.com>
References: <279353458.11938525.1470391813760.javamail.yahoo.ref@mail.yahoo.com>
	<E8EFEE4A63A.00000141jrkrideau@inbox.com>
Message-ID: <47fe1661-216f-fcc9-1a2c-ba65bf5715ce@gmail.com>

On 8/7/2016 7:49 AM, John Kane wrote:
> As Jim says the file did not arrive. R-help is very fussy about what kind of files it accepts. If you are still having a problem it would be a good idea to upload it to file-sharing place such as Dropbox or Mediafire and just post the link here.
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: r-help at r-project.org
>> Sent: Fri, 5 Aug 2016 10:10:13 +0000 (UTC)
>> To: r-help at r-project.org
>> Subject: [R] SAS file
>>
>> Hello,I have a SAS formatted file as attached, when I use lookup.xport i
>> got error below> lookup.xport("patient.ssd01")Error in
>> lookup.xport.inner(file) :   unable to open file: 'No such file or
>> directory'
>>
>> can anyone please help me to figure it out?
>> thanksc
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

The file extension, '.ssd01' is typically used for a standard Unix SAS 
dataset.  the R function, lookup.xport(), is for examining SAS XPORT 
files.  So, you are using the wrong approach to read the file.

You will need to get an XPORT format file, or have SAS available, or get 
some 3rd party software that will read SAS datasets.


Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From dargosch at gmail.com  Mon Aug  8 08:43:32 2016
From: dargosch at gmail.com (Fredrik Karlsson)
Date: Mon, 8 Aug 2016 08:43:32 +0200
Subject: [R] Creating Dummy Var in R for regression?
In-Reply-To: <CAB=p7SoCe4aoJOohkT9S2kkccCY1+kzyikY0fkaQ+MpxoOjZwg@mail.gmail.com>
References: <CAB=p7Sr5tgNRy+c5DNKmXZqOqEy=jKoXd3KjHDkzi5Mb0h3Kig@mail.gmail.com>
	<20160805214955.Horde.igroAepdmk6g1btHdi-_jcC@mail.sapo.pt>
	<CAGxFJbRtkq30bx+zseCTytkTJAaK+fEdrfWMF78JmvAkOpmQwQ@mail.gmail.com>
	<CAB=p7SocDqYK8dkg757B0eNdguKMfxbhxHoBimaUAMA6-fUnNg@mail.gmail.com>
	<CAOjnRsZNif-vye=RFUU1AkkwTyynqDF39AXFKY+3cY+EtcooBA@mail.gmail.com>
	<CAB=p7SoCe4aoJOohkT9S2kkccCY1+kzyikY0fkaQ+MpxoOjZwg@mail.gmail.com>
Message-ID: <CANO=oh+uqef-cQOJwHqdUYEczVXuWAeWBmEFfPmzoG_vBXisWQ@mail.gmail.com>

Hi,

please also have a look at the 'cut' function.Very handa function for these
types of situations.

Best,

Fredrik

On Sun, Aug 7, 2016 at 8:10 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:

> Thank you Jeremiah and all others for the assistance. This really helped.
>
> On Sat, Aug 6, 2016 at 5:01 AM, jeremiah rounds <roundsjeremiah at gmail.com>
> wrote:
>
> > Something like:
> >
> > d  =  data.frame(score = sample(1:10, 100, replace=TRUE))
> > d$score_t = "low"
> > d$score_t[d$score > 3] = "medium"
> > d$score_t[d$score >7 ] = "high"
> > d$score_t = factor(d$score_t, levels = c("low", "medium", "high"),
> > ordered=TRUE)  #set ordered = FALSE for dummy variables
> > X = model.matrix(~score_t, data=d)
> > X
> >
> >
> >
> > On Fri, Aug 5, 2016 at 3:23 PM, Shivi Bhatia <shivipmp82 at gmail.com>
> wrote:
> >
> >> Thanks you all for the assistance. This really helps.
> >>
> >> Hi Bert: While searching nabble i got to know R with factors variables
> >> there is no need to create dummy variable. However please consider this
> >> situation:
> >> I am in the process of building a logistic regression model on NPS data.
> >> The outcome variable is CE i.e. customer experience which has 3 rating
> so
> >> ordinal logistic regression will be used. However most of my variables
> are
> >> categorical. For instance one of the variable is agent knowledge which
> is
> >> a
> >> 10 point scale.
> >>
> >> This agent knowledge is again a 3 rated scale: high medium low hence i
> >> need
> >> to group these 10 values into 3 groups & then as you suggested i can
> >> directly enter them in the model without creating n-1 categories.
> >>
> >> I have worked on SAS extensively hence found this a bit confusing.
> >>
> >> Thanks for the help.
> >>
> >> On Sat, Aug 6, 2016 at 2:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
> >> wrote:
> >>
> >> > Just commenting on the email subject, not the content (which you have
> >> > already been helped with): there is no need to *ever* create a dummy
> >> > variable for regression in R if what you mean by this is what is
> >> > conventionally meant. R will create the model matrix with appropriate
> >> > "dummy variables" for factors as needed. See ?contrasts and ?C for
> >> > relevant details and/or consult an appropriate R tutorial.
> >> >
> >> > Of course, if this is not what you meant, than ignore.
> >> >
> >> > Cheers,
> >> > Bert
> >> >
> >> >
> >> > Bert Gunter
> >> >
> >> > "The trouble with having an open mind is that people keep coming along
> >> > and sticking things into it."
> >> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >> >
> >> >
> >> > On Fri, Aug 5, 2016 at 1:49 PM,  <ruipbarradas at sapo.pt> wrote:
> >> > > Hello,
> >> > >
> >> > > Your ifelse will never work because
> >> > > reasons$salutation== "Mr" & reasons$salutation=="Father" is always
> >> FALSE
> >> > > and so is reasons$salutation=="Mrs" & reasons$salutation=="Miss".
> >> > > Try instead | (or), not & (and).
> >> > >
> >> > > Hope this helps,
> >> > >
> >> > > Rui Barradas
> >> > >
> >> > >
> >> > >
> >> > > Citando Shivi Bhatia <shivipmp82 at gmail.com>:
> >> > >
> >> > >> Dear Team,
> >> > >>
> >> > >> I need help with the below code in R:
> >> > >>
> >> > >> gender_rec<- c('Dr','Father','Mr'=1, 'Miss','MS','Mrs'=2, 3)
> >> > >>
> >> > >> reasons$salutation<- gender_rec[reasons$salutation].
> >> > >>
> >> > >> This code gives me the correct output but it overwrites the
> >> > >> reason$salutation variable. I need to create a new variable gender
> to
> >> > >> capture gender details and leave salutation as it is.
> >> > >>
> >> > >> i tried the below syntax but it is converting all to 1.
> >> > >>
> >> > >> reasons$gender<- ifelse(reasons$salutation== "Mr" &
> >> reasons$salutation==
> >> > >> "Father","Male", ifelse(reasons$salutation=="Mrs" &
> >> > reasons$salutation==
> >> > >> "Miss","Female",1))
> >> > >>
> >> > >> Please suggest.
> >> > >>
> >> > >>         [[alternative HTML version deleted]]
> >> > >>
> >> > >> ______________________________________________
> >> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> > >> PLEASE do read the posting guide
> >> > >> http://www.R-project.org/posting-guide.htmland provide commented,
> >> > >> minimal, self-contained, reproducible code.
> >> > >
> >> > >
> >> > >
> >> > >         [[alternative HTML version deleted]]
> >> > >
> >> > > ______________________________________________
> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > > PLEASE do read the posting guide http://www.R-project.org/
> >> > posting-guide.html
> >> > > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posti
> >> ng-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
"Life is like a trumpet - if you don't put anything into it, you don't get
anything out of it."

	[[alternative HTML version deleted]]


From jennifer.sheng2002 at gmail.com  Mon Aug  8 00:21:22 2016
From: jennifer.sheng2002 at gmail.com (Jennifer Sheng)
Date: Sun, 7 Aug 2016 18:21:22 -0400
Subject: [R] Conditionally remove rows with logic
Message-ID: <CALvAKX+UVAcNxh8VVfpQ-LQip8pgVR-eNyb6LtvaYYJ=sefhrQ@mail.gmail.com>

Dear all,

I need to remove any rows AFTER the label becomes 1.  For example, for ID
1, the two rows with TIME of 15 & 18 should be removed; for ID 2, any rows
after time 6, i.e., rows of time 9-18, should be removed.  Any
suggestions?  Thank you very much!

The current dataset looks like the following:
ID     TIME     LABEL
1        0            0
1        3            0
1        6            0
1        9            0
1        12          1
1        15          0
1        18           0
2        0            0
2        3            0
2        6            1
2        9            0
2        12          0
2        15          0
2        18          0

Thanks a lot!
Jennifer

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Aug  8 09:11:52 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 8 Aug 2016 17:11:52 +1000
Subject: [R] Conditionally remove rows with logic
In-Reply-To: <CALvAKX+UVAcNxh8VVfpQ-LQip8pgVR-eNyb6LtvaYYJ=sefhrQ@mail.gmail.com>
References: <CALvAKX+UVAcNxh8VVfpQ-LQip8pgVR-eNyb6LtvaYYJ=sefhrQ@mail.gmail.com>
Message-ID: <CA+8X3fX-Q9b7DGdemq4jEn3uXuHXZTh2wWNnD2v_o=zgG_6tXw@mail.gmail.com>

Hi Jennifer,
A very pedestrian method, but I think it does what you want.

remove_rows_after_1<-function(x) {
 nrows<-dim(x)[1]
 rtr<-NA
 rtrcount<-1
 got1<-FALSE
 thisID<-x$ID[1]
 for(i in 1:nrows) {
  if(x$ID[i] == thisID && got1) {
   rtr[rtrcount]<-i
   rtrcount<-rtrcount+1
  }
  if(x$ID[i] != thisID) {
   thisID<-x$ID[i]
   got1<-FALSE
  }
  if(x$ID[i] == thisID && x$LABEL[i]) got1<-TRUE
 }
 return(rtr)
}

The function returns the indices of rows to be removed.

Jim


On Mon, Aug 8, 2016 at 8:21 AM, Jennifer Sheng
<jennifer.sheng2002 at gmail.com> wrote:
> Dear all,
>
> I need to remove any rows AFTER the label becomes 1.  For example, for ID
> 1, the two rows with TIME of 15 & 18 should be removed; for ID 2, any rows
> after time 6, i.e., rows of time 9-18, should be removed.  Any
> suggestions?  Thank you very much!
>
> The current dataset looks like the following:
> ID     TIME     LABEL
> 1        0            0
> 1        3            0
> 1        6            0
> 1        9            0
> 1        12          1
> 1        15          0
> 1        18           0
> 2        0            0
> 2        3            0
> 2        6            1
> 2        9            0
> 2        12          0
> 2        15          0
> 2        18          0
>
> Thanks a lot!
> Jennifer
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Erich.Striessnig at wu.ac.at  Mon Aug  8 10:08:19 2016
From: Erich.Striessnig at wu.ac.at (Striessnig, Erich)
Date: Mon, 8 Aug 2016 08:08:19 +0000
Subject: [R] pgmm - how to properly specify lag term?
Message-ID: <5b2cb5c005534c48abc641f362cdb886@mbx8.ad.wu-wien.ac.at>

Dear R-users,

I want to reproduce "a dynamic panel data model, autoregressive of order 1, with fixed effects" that was originally estimated with 2-step GMM in STATA. Reproducing the model in R shouldn't be a big deal, however, unfortunately I don't have the original STATA code and the lagged dependent variable is not "free-standing", but rather subtracted from another independent variable like this:

Y(t) - Y(t-1) = b1 * [X(t) - X(t-1)] + b2 * [X(t-1)-Y(t-1)]

So my question is on how to specify the instruments. The model I am trying to reproduce is instrumenting the endogenous lagged term by its 4th and the 5th lag. Do I need dynformula() for that or does one of the following specifications work as well?


form1 <- diff(value.y) ~ diff(value.x) + lag(I(value.x-value.y),1) | lag(value.y,4:5)
form2 <- diff(value.y) ~ diff(value.x) + lag(I(value.x-value.y),4:5) | lag(value.y,4:5)
form3 <- diff(value.y) ~ diff(value.x) + diff.xy | lag(diff.xy,4:5)
form4 <- diff(value.y) ~ diff(value.x) + lag(diff.xy,1) | lag(diff.xy,4:5)
form5 <- diff(value.y) ~ diff(value.x) + lag(diff.xy,1) | lag(I(value.x-value.y),4:5)

library(plm)

value.x <- rnorm(336)
value.y <- rnorm(336)
diff.xy <- value.x - value.y
my.data <- data.frame(expand.grid(ids=1:28,times=1:12),value.x,value.y,diff.xy)

mod1 <- pgmm(formula=form1,data=my.data,index=c('ids','times'),
             effect="individual", model="twosteps")
summary(mod1)


Kind regards,
Erich

	[[alternative HTML version deleted]]


From loris.bennett at fu-berlin.de  Mon Aug  8 10:12:05 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Mon, 8 Aug 2016 10:12:05 +0200
Subject: [R] Visualising multiple temporal periods each with an associated
	value
Message-ID: <87vazbptm2.fsf@hornfels.zedat.fu-berlin.de>

Hi,

I want to visualise temporal events as rectangles, one side of the
rectangle being the length of the event, the other being the size of an
integer variable.  The position of the rectangle along the time axis
would be determined by the time of the even, the position on the other
axis is essentially arbitrary. This would look like the graph in the
lower right of the following image:

http://apps.fz-juelich.de/jsc/llview/html/images/llview_snapshot1.png

I can probably cobble something together in raw R to do this, but I
assume that this kind of plot has a name and that there may already be
packages to do this.

Can anyone suggest what one would call this sort of plot?

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From loris.bennett at fu-berlin.de  Mon Aug  8 11:37:33 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Mon, 8 Aug 2016 11:37:33 +0200
Subject: [R] No "number of days" format for 'difftime'?
Message-ID: <87k2frppnm.fsf@hornfels.zedat.fu-berlin.de>

Hi,

When I try

  d <- as.difftime("6-08:18:33",format=%d-%H:%M:%S")

I get:

  Error: unexpected SPECIAL in "as.difftime("6-08:18:33",format=%d-%"

Am I correct in thinking that it is not possible to do something like
this, because there is no character string for the format which
corresponds to "number of days"?

I could misuse "%j" for "day of the year as a decimal number", but
ultimately the "difftime" object is still a data, rather than a length
of time and I should be looking at a package like 'lubridate' instead.
Is that the case?

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From jrkrideau at inbox.com  Mon Aug  8 11:50:51 2016
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 8 Aug 2016 01:50:51 -0800
Subject: [R] No "number of days" format for 'difftime'?
In-Reply-To: <87k2frppnm.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <F2E6D592E51.000000A1jrkrideau@inbox.com>

Try 
d <- as.difftime("6-08:18:33","%d-%H:%M:%S")

John Kane
Kingston ON Canada


> -----Original Message-----
> From: loris.bennett at fu-berlin.de
> Sent: Mon, 8 Aug 2016 11:37:33 +0200
> To: r-help at stat.math.ethz.ch
> Subject: [R] No "number of days" format for 'difftime'?
> 
> Hi,
> 
> When I try
> 
>   d <- as.difftime("6-08:18:33",format=%d-%H:%M:%S")
> 
> I get:
> 
>   Error: unexpected SPECIAL in "as.difftime("6-08:18:33",format=%d-%"
> 
> Am I correct in thinking that it is not possible to do something like
> this, because there is no character string for the format which
> corresponds to "number of days"?
> 
> I could misuse "%j" for "day of the year as a decimal number", but
> ultimately the "difftime" object is still a data, rather than a length
> of time and I should be looking at a package like 'lubridate' instead.
> Is that the case?
> 
> Cheers,
> 
> Loris
> 
> --
> Dr. Loris Bennett (Mr.)
> ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From ruipbarradas at sapo.pt  Mon Aug  8 11:56:11 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Mon, 8 Aug 2016 10:56:11 +0100
Subject: [R] No "number of days" format for 'difftime'?
In-Reply-To: <87k2frppnm.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <20160808105611.Horde.oKASgQXZFf49ugkyjX-BEIl@mail.sapo.pt>

Hello,

You're missing a double quotes. Right after format=

Hope this helps,

Rui Barradas
?

Citando Loris Bennett <loris.bennett at fu-berlin.de>:

> Hi,
>
> When I try
>
> d <- as.difftime("6-08:18:33",format=%d-%H:%M:%S")
>
> I get:
>
> Error: unexpected SPECIAL in "as.difftime("6-08:18:33",format=%d-%"
>
> Am I correct in thinking that it is not possible to do something like
> this, because there is no character string for the format which
> corresponds to "number of days"?
>
> I could misuse "%j" for "day of the year as a decimal number", but
> ultimately the "difftime" object is still a data, rather than a length
> of time and I should be looking at a package like 'lubridate' instead.
> Is that the case?
>
> Cheers,
>
> Loris
>
> --
> Dr. Loris Bennett (Mr.)
> ZEDAT, Freie Universit?t Berlin? ? ? ? ?Email loris.bennett at fu-berlin.de
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From loris.bennett at fu-berlin.de  Mon Aug  8 12:07:43 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Mon, 8 Aug 2016 12:07:43 +0200
Subject: [R] No "number of days" format for 'difftime'?
References: <87k2frppnm.fsf@hornfels.zedat.fu-berlin.de>
	<20160808105611.Horde.oKASgQXZFf49ugkyjX-BEIl@mail.sapo.pt>
Message-ID: <87d1ljpo9c.fsf@hornfels.zedat.fu-berlin.de>

Hi,

I was probably misled by the, to my mind, esoteric error message into
thinking the error was more subtle.  Something like "unmatched quotes"
might have helped me recognise that I was just being dopey.

Thanks to John and Rui.

Loris

<ruipbarradas at sapo.pt> writes:

> Hello,
>
> You're missing a double quotes. Right after format=
>
> Hope this helps,
>
> Rui Barradas
> ?
>
> Citando Loris Bennett <loris.bennett at fu-berlin.de>:
>
>> Hi,
>>
>> When I try
>>
>> d <- as.difftime("6-08:18:33",format=%d-%H:%M:%S")
>>
>> I get:
>>
>> Error: unexpected SPECIAL in "as.difftime("6-08:18:33",format=%d-%"
>>
>> Am I correct in thinking that it is not possible to do something like
>> this, because there is no character string for the format which
>> corresponds to "number of days"?
>>
>> I could misuse "%j" for "day of the year as a decimal number", but
>> ultimately the "difftime" object is still a data, rather than a length
>> of time and I should be looking at a package like 'lubridate' instead.
>> Is that the case?
>>
>> Cheers,
>>
>> Loris
>>
>> --
>> Dr. Loris Bennett (Mr.)
>> ZEDAT, Freie Universit?t Berlin? ? ? ? ?Email loris.bennett at fu-berlin.de
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide  
>> http://www.R-project.org/posting-guide.htmland provide commented,  
>> minimal, self-contained, reproducible code.
>
> ?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From jrkrideau at inbox.com  Mon Aug  8 12:48:13 2016
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 8 Aug 2016 02:48:13 -0800
Subject: [R] No "number of days" format for 'difftime'?
In-Reply-To: <87d1ljpo9c.fsf@hornfels.zedat.fu-berlin.de>
References: <87k2frppnm.fsf@hornfels.zedat.fu-berlin.de>
	<20160808105611.horde.okasgqxzff49ugkyjx-beil@mail.sapo.pt>
Message-ID: <F36712675EB.0000010Bjrkrideau@inbox.com>

http://www.dummies.com/how-to/content/how-to-read-errors and-warnings-in-r.html
If something goes wrong with your code, R tells you. We have to admit it: These error messages can range from mildly confusing to completely incomprehensible if you?re not used to them.


fortune(350) regarding the on-line help is also inspiring

You need to get the hang of reading the online help. The information required is actually therein ?dotchart --- it's just tersely and obscurely expressed. A certain degree of optimism is required. You need to ***believe*** that the information is there; then ask yourself "What could they possibly mean by what they have written that would tell me what I need to know?".
   -- Rolf Turner (on reading the help pages)
      R-help (June 2013)


John Kane
Kingston ON Canada


> -----Original Message-----
> From: loris.bennett at fu-berlin.de
> Sent: Mon, 8 Aug 2016 12:07:43 +0200
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] No "number of days" format for 'difftime'?
> 
> Hi,
> 
> I was probably misled by the, to my mind, esoteric error message into
> thinking the error was more subtle.  Something like "unmatched quotes"
> might have helped me recognise that I was just being dopey.
> 
> Thanks to John and Rui.
> 
> Loris
> 
> <ruipbarradas at sapo.pt> writes:
> 
>> Hello,
>> 
>> You're missing a double quotes. Right after format=
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> 
>> Citando Loris Bennett <loris.bennett at fu-berlin.de>:
>> 
>>> Hi,
>>> 
>>> When I try
>>> 
>>> d <- as.difftime("6-08:18:33",format=%d-%H:%M:%S")
>>> 
>>> I get:
>>> 
>>> Error: unexpected SPECIAL in "as.difftime("6-08:18:33",format=%d-%"
>>> 
>>> Am I correct in thinking that it is not possible to do something like
>>> this, because there is no character string for the format which
>>> corresponds to "number of days"?
>>> 
>>> I could misuse "%j" for "day of the year as a decimal number", but
>>> ultimately the "difftime" object is still a data, rather than a length
>>> of time and I should be looking at a package like 'lubridate' instead.
>>> Is that the case?
>>> 
>>> Cheers,
>>> 
>>> Loris
>>> 
>>> --
>>> Dr. Loris Bennett (Mr.)
>>> ZEDAT, Freie Universit?t Berlin? ? ? ? ?Email
>>> loris.bennett at fu-berlin.de
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.htmland provide commented,
>>> minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Dr. Loris Bennett (Mr.)
> ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From loris.bennett at fu-berlin.de  Mon Aug  8 13:19:03 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Mon, 8 Aug 2016 13:19:03 +0200
Subject: [R] No "number of days" format for 'difftime'?
References: <87k2frppnm.fsf@hornfels.zedat.fu-berlin.de>
	<20160808105611.horde.okasgqxzff49ugkyjx-beil@mail.sapo.pt>
	<F36712675EB.0000010Bjrkrideau@inbox.com>
Message-ID: <87wpjro6e0.fsf@hornfels.zedat.fu-berlin.de>

Thanks for the link, John.  However, there is a hyphen missing.  It
should be:

  http://www.dummies.com/how-to/content/how-to-read-errors-and-warnings-in-r.html

Appropriately, with the correct URL we find the too often forgotten
pearl of wisdom:

 "Chances are, you just typed something wrong there."

I think I need this on my coffee cup.

Cheers,

Loris


John Kane <jrkrideau at inbox.com> writes:

> http://www.dummies.com/how-to/content/how-to-read-errors and-warnings-in-r.html

> If something goes wrong with your code, R tells you. We have to admit
> it: These error messages can range from mildly confusing to completely
> incomprehensible if you?re not used to them.
>
>
> fortune(350) regarding the on-line help is also inspiring
>
> You need to get the hang of reading the online help. The information
> required is actually therein ?dotchart --- it's just tersely and
> obscurely expressed. A certain degree of optimism is required. You
> need to ***believe*** that the information is there; then ask yourself
> "What could they possibly mean by what they have written that would
> tell me what I need to know?".
>    -- Rolf Turner (on reading the help pages)
>       R-help (June 2013)
>
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: loris.bennett at fu-berlin.de
>> Sent: Mon, 8 Aug 2016 12:07:43 +0200
>> To: r-help at stat.math.ethz.ch
>> Subject: Re: [R] No "number of days" format for 'difftime'?
>> 
>> Hi,
>> 
>> I was probably misled by the, to my mind, esoteric error message into
>> thinking the error was more subtle.  Something like "unmatched quotes"
>> might have helped me recognise that I was just being dopey.
>> 
>> Thanks to John and Rui.
>> 
>> Loris
>> 
>> <ruipbarradas at sapo.pt> writes:
>> 
>>> Hello,
>>> 
>>> You're missing a double quotes. Right after format=
>>> 
>>> Hope this helps,
>>> 
>>> Rui Barradas
>>> 
>>> 
>>> Citando Loris Bennett <loris.bennett at fu-berlin.de>:
>>> 
>>>> Hi,
>>>> 
>>>> When I try
>>>> 
>>>> d <- as.difftime("6-08:18:33",format=%d-%H:%M:%S")
>>>> 
>>>> I get:
>>>> 
>>>> Error: unexpected SPECIAL in "as.difftime("6-08:18:33",format=%d-%"
>>>> 
>>>> Am I correct in thinking that it is not possible to do something like
>>>> this, because there is no character string for the format which
>>>> corresponds to "number of days"?
>>>> 
>>>> I could misuse "%j" for "day of the year as a decimal number", but
>>>> ultimately the "difftime" object is still a data, rather than a length
>>>> of time and I should be looking at a package like 'lubridate' instead.
>>>> Is that the case?
>>>> 
>>>> Cheers,
>>>> 
>>>> Loris
>>>> 
>>>> --
>>>> Dr. Loris Bennett (Mr.)
>>>> ZEDAT, Freie Universit?t Berlin? ? ? ? ?Email
>>>> loris.bennett at fu-berlin.de
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.htmland provide commented,
>>>> minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Dr. Loris Bennett (Mr.)
>> ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From lists at dewey.myzen.co.uk  Mon Aug  8 13:30:51 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 8 Aug 2016 12:30:51 +0100
Subject: [R] metaprop
In-Reply-To: <CABeLv6jUWf9HfgiC710M572TsQ01p1eUBwpYOafVVvqpNAPHoQ@mail.gmail.com>
References: <CABeLv6jUWf9HfgiC710M572TsQ01p1eUBwpYOafVVvqpNAPHoQ@mail.gmail.com>
Message-ID: <1ff132a3-9ef6-e7cb-0be2-9e56979f6243@dewey.myzen.co.uk>

Dear Carlos

If you use functions from a contributed package it is best to tell us 
which package. There are nearly 9000 of them.

On 07/08/2016 17:13, Carlos Javier Rincon Rodriguez wrote:
> hi,
>
> i am using the funtion metaprop but when i try to save the proportion
> estimation by subgrup using the option "byvar", the value in TE.fixed.w are
> the transformed proportion, and i need the untranformed proportion. I try
> with the option backtranf=true, but doesn`t change anithing.
>

As the documentation says it applies to printing and plotting. Why not 
take the values it does return and back-transform them yourself? None of 
the transformations it uses are that tricky to reverse.

>  I have so many subgroup that i need to be able to save my result but i can
> find where the untranformed proportion keep saving.
>
> thanks for the help.
>
> bye
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From loris.bennett at fu-berlin.de  Mon Aug  8 14:12:47 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Mon, 8 Aug 2016 14:12:47 +0200
Subject: [R] No "number of days" format for 'difftime'?
References: <87k2frppnm.fsf@hornfels.zedat.fu-berlin.de>
	<20160808105611.horde.okasgqxzff49ugkyjx-beil@mail.sapo.pt>
	<F36712675EB.0000010Bjrkrideau@inbox.com>
	<87wpjro6e0.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <87shufo3wg.fsf@hornfels.zedat.fu-berlin.de>

Loris Bennett <loris.bennett at fu-berlin.de> writes:

> Thanks for the link, John.  However, there is a hyphen missing.  It
> should be:
>
>   http://www.dummies.com/how-to/content/how-to-read-errors-and-warnings-in-r.html
>
> Appropriately, with the correct URL we find the too often forgotten
> pearl of wisdom:
>
>  "Chances are, you just typed something wrong there."
>
> I think I need this on my coffee cup.
>
> Cheers,
>
> Loris

Continuing the topic for my future self and others equally poorly versed
in The Art and Dark Science of Interpreting R Error Messages, if I have
the following in the file "my_data"

1094165      2016-07-24T09:40:02 13-23:03:28          1  COMPLETED 
1112076      2016-08-01T14:45:49 6-13:26:15          1  COMPLETED 

and do

> d <- read.table("my_data")
> colnames(d) <- c("jobid","start","elapsed","alloccpus","state")
> df <- transform(d,start = as.POSIXct(start,format="%Y-%m-%dT%H:%M:%S"),elapsed = as.difftime(elapsed,format="%d-%H:%M:%S"))

I get the following:

Error in as.difftime(elapsed, format = "%d-%H:%M:%S") : 
  'tim' is not character or numeric

Remembering that if something is not what you think it is, it is
probably a factor, I find that

> d <- read.table(data_file,stringsAsFactors=FALSE)

causes the error to go away.

So what's all this 'tim' business?  A quick squint at the source code of
datetime.R reveals the following line:

  if (!is.numeric(tim)) stop("'tim' is not character or numeric")

So the error message tells me something about the arbitrary name of the
variable 'tim', which could also have been 'tom', 'dick', or 'harriet',
but nothing about the value.

So follow Rolf Turner's fortune(350) advice, then look at the source
code, and then realise that you weren't being totally dopey in not
understanding the error message.

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From maechler at stat.math.ethz.ch  Mon Aug  8 15:53:55 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 8 Aug 2016 15:53:55 +0200
Subject: [R] No "number of days" format for 'difftime'?
In-Reply-To: <87shufo3wg.fsf@hornfels.zedat.fu-berlin.de>
References: <87k2frppnm.fsf@hornfels.zedat.fu-berlin.de>
	<20160808105611.horde.okasgqxzff49ugkyjx-beil@mail.sapo.pt>
	<F36712675EB.0000010Bjrkrideau@inbox.com>
	<87wpjro6e0.fsf@hornfels.zedat.fu-berlin.de>
	<87shufo3wg.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <22440.36595.75184.349287@stat.math.ethz.ch>

>>>>> Loris Bennett <loris.bennett at fu-berlin.de>
>>>>>     on Mon, 8 Aug 2016 14:12:47 +0200 writes:

    > Loris Bennett <loris.bennett at fu-berlin.de> writes:
    >> Thanks for the link, John.  However, there is a hyphen missing.  It
    >> should be:
    >> 
    >> http://www.dummies.com/how-to/content/how-to-read-errors-and-warnings-in-r.html
    >> 
    >> Appropriately, with the correct URL we find the too often forgotten
    >> pearl of wisdom:
    >> 
    >> "Chances are, you just typed something wrong there."
    >> 
    >> I think I need this on my coffee cup.
    >> 
    >> Cheers,
    >> 
    >> Loris

    > Continuing the topic for my future self and others equally poorly versed
    > in The Art and Dark Science of Interpreting R Error Messages, if I have
    > the following in the file "my_data"

    > 1094165      2016-07-24T09:40:02 13-23:03:28          1  COMPLETED 
    > 1112076      2016-08-01T14:45:49 6-13:26:15          1  COMPLETED 

    > and do

    >> d <- read.table("my_data")
    >> colnames(d) <- c("jobid","start","elapsed","alloccpus","state")
    >> df <- transform(d,start = as.POSIXct(start,format="%Y-%m-%dT%H:%M:%S"),elapsed = as.difftime(elapsed,format="%d-%H:%M:%S"))

    > I get the following:

    > Error in as.difftime(elapsed, format = "%d-%H:%M:%S") : 
    > 'tim' is not character or numeric

Well, let me argue that you should have found this to be a *helpful*
error message. You are no complete beginner anymore, right,
so

1) the error is in your use of  as.difftime().

2) ?as.difftime  or  str(difftime)
   both clearly indicate that  'tim' is the first argument of as.difftime,

and I really do wonder why you continued with the infamous
"trial-and-error programming technique" instead of reading or at
least quickly browsing the relevant reference, i.e., help page

Martin


    > Remembering that if something is not what you think it is, it is
    > probably a factor, I find that

    >> d <- read.table(data_file,stringsAsFactors=FALSE)

    > causes the error to go away.

    > So what's all this 'tim' business?  A quick squint at the source code of
    > datetime.R reveals the following line:

    > if (!is.numeric(tim)) stop("'tim' is not character or numeric")

    > So the error message tells me something about the arbitrary name of the
    > variable 'tim', which could also have been 'tom', 'dick', or 'harriet',
    > but nothing about the value.

    > So follow Rolf Turner's fortune(350) advice, then look at the source
    > code, and then realise that you weren't being totally dopey in not
    > understanding the error message.


    > Loris

    > -- 
    > Dr. Loris Bennett (Mr.)
    > ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From loris.bennett at fu-berlin.de  Mon Aug  8 16:43:10 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Mon, 8 Aug 2016 16:43:10 +0200
Subject: [R] No "number of days" format for 'difftime'?
References: <87k2frppnm.fsf@hornfels.zedat.fu-berlin.de>
	<20160808105611.horde.okasgqxzff49ugkyjx-beil@mail.sapo.pt>
	<F36712675EB.0000010Bjrkrideau@inbox.com>
	<87wpjro6e0.fsf@hornfels.zedat.fu-berlin.de>
	<87shufo3wg.fsf@hornfels.zedat.fu-berlin.de>
	<22440.36595.75184.349287@stat.math.ethz.ch>
Message-ID: <87oa53nwxt.fsf@hornfels.zedat.fu-berlin.de>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

>>>>>> Loris Bennett <loris.bennett at fu-berlin.de>
>>>>>>     on Mon, 8 Aug 2016 14:12:47 +0200 writes:
>
>     > Loris Bennett <loris.bennett at fu-berlin.de> writes:
>     >> Thanks for the link, John.  However, there is a hyphen missing.  It
>     >> should be:
>     >> 
>     >> http://www.dummies.com/how-to/content/how-to-read-errors-and-warnings-in-r.html
>     >> 
>     >> Appropriately, with the correct URL we find the too often forgotten
>     >> pearl of wisdom:
>     >> 
>     >> "Chances are, you just typed something wrong there."
>     >> 
>     >> I think I need this on my coffee cup.
>     >> 
>     >> Cheers,
>     >> 
>     >> Loris
>
>     > Continuing the topic for my future self and others equally poorly versed
>     > in The Art and Dark Science of Interpreting R Error Messages, if I have
>     > the following in the file "my_data"
>
>     > 1094165      2016-07-24T09:40:02 13-23:03:28          1  COMPLETED 
>     > 1112076      2016-08-01T14:45:49 6-13:26:15          1  COMPLETED 
>
>     > and do
>
>     >> d <- read.table("my_data")
>     >> colnames(d) <- c("jobid","start","elapsed","alloccpus","state")
>     >> df <- transform(d,start = as.POSIXct(start,format="%Y-%m-%dT%H:%M:%S"),elapsed = as.difftime(elapsed,format="%d-%H:%M:%S"))
>
>     > I get the following:
>
>     > Error in as.difftime(elapsed, format = "%d-%H:%M:%S") : 
>     > 'tim' is not character or numeric
>
> Well, let me argue that you should have found this to be a *helpful*
> error message. You are no complete beginner anymore, right,
> so
>
> 1) the error is in your use of  as.difftime().
>
> 2) ?as.difftime  or  str(difftime)
>    both clearly indicate that  'tim' is the first argument of as.difftime,
>
> and I really do wonder why you continued with the infamous
> "trial-and-error programming technique" instead of reading or at
> least quickly browsing the relevant reference, i.e., help page
>
> Martin

My apologies, you are absolutely right - I see the error of my ways.
The only feeble defence I can mount is that the usage example from
?as.difftime

  as.difftime(tim, format = "%X", units = "auto")

superficially disguises the fact that the first argument is also a named
argument with the name 'tim'.  I think I had assumed that the initial
argument were always positional, e.g. as for paste0

  paste0(..., collapse = NULL)

However, I now realise that '...' also generates named arguments, e.g.

  paste0(..1='a',..2='b')

So as a non-beginner but infrequent R user, in future I shall try use
the explicit form more often, e.g.

  as.difftime(tim = "4-03:02:01", format = "%d-%H:%M:%S")

to remind myself what I am doing.

So fortune(350) really is true.  I just didn't believe enough to read
enough. 

Loris
-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From dcarlson at tamu.edu  Mon Aug  8 16:59:15 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 8 Aug 2016 14:59:15 +0000
Subject: [R] Three way correspondence analyses?
In-Reply-To: <CAFdg=fVwTNBfPp2ynLFQY0L_yDqF5ivKeasX+wYeUtbJ-GgEEQ@mail.gmail.com>
References: <CAFdg=fXxfR+26m1gR5fcNyLsadDvbsxkngcrGjaS4pHwhHGuzA@mail.gmail.com>
	<09108d9a-c6de-8871-6079-8b73a8df4032@yorku.ca>
	<CAFdg=fVwTNBfPp2ynLFQY0L_yDqF5ivKeasX+wYeUtbJ-GgEEQ@mail.gmail.com>
Message-ID: <d5488a64df1c48958c311856f249db7c@exch-2p-mbx-t2.ads.tamu.edu>

Your code runs without errors so there is no issue with R. The function you are using is for [Partial] [Constrained] Correspondence Analysis. You have not defined 3-way correspondence analysis, but my understanding is that it involves correspondence analysis of a 3-way crosstabulation array. Your examples include 2 constrained correspondence analyses and one partial constrained correspondence analysis. You should try contacting someone with more experience in correspondence analysis who can help you identify the question you are attempting to answer.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Suparna Mitra
Sent: Friday, August 5, 2016 4:01 AM
To: Michael Friendly
Cc: R help
Subject: Re: [R] Three way correspondence analyses?

Sorry somehow the mail was buried in my spam folder and I was waiting for
any reply. Now when I searched specifically then found in spam. Sorry about
this.
This is my data format.


I have three data matrix. Samples are matched
> dput(Cytok_and_ProInf)
structure(list(IFN._ = c(3.412082432, 3.052252998, 5.142508722,
12.70932318, 1.861206813, 0.993497776, 0.836846636, 4.125564372,
1.385344616, 1.292459442, 0.11649863, 0.150193815, 27.86121845,
1.725385265, 1.715598671, 0.017175222, 1e-06, 1e-06, 6.668275976,
0.790970336, 4.03583889, 0.971457745, 1.059011154, 0.637639199,
0.48875513, 0.301263118, 0.272641165, 0.343154282, 1e-06, 1e-06,
1.282052844, 1.080656696, 1.302848316, 6.22346499, 0.329317838,
1e-06, 0.437037978, 0.287027959, 0.960397988, 0.098872923, 1.06984553,
0.836846636, 1.302848316, 0.904683816), IL.10 = c(0.115021123,
0.150136084, 0.205984417, 0.16364998, 0.099053965, 0.152406978,
0.107718618, 0.180196098, 0.073236511, 0.101546531, 0.233120615,
0.097802351, 0.67071499, 0.159174453, 0.226924759, 0.042082686,
1e-06, 1e-06, 0.242345366, 0.250478861, 0.170311925, 0.079862061,
0.083777663, 0.062337816, 0.026139707, 0.088935013, 0.158051134,
0.178010445, 0.19103657, 0.178010445, 0.186717539, 0.066471894,
0.263570447, 0.403324556, 1e-06, 0.15467023, 0.096547094, 0.131672017,
0.085073597, 0.1877994, 0.182375762, 0.115021123, 0.117431784,
0.158051134), IL.12p70 = c(0.070763998, 0.090748695, 0.208540497,
1e-06, 0.100363261, 1e-06, 0.049381659, 0.278572877, 0.359093222,
0.236327042, 1e-06, 1e-06, 1.730678237, 1e-06, 1e-06, 1e-06,
1e-06, 1e-06, 1e-06, 0.228467277, 0.355528037, 0.150149937, 1e-06,
0.100363261, 1e-06, 1e-06, 0.351954745, 0.236327042, 0.167289445,
1e-06, 0.297291961, 0.208540497, 1e-06, 1e-06, 0.240234706, 0.025530181,
0.114409102, 1e-06, 1e-06, 0.031847909, 0.228467277, 1e-06, 0.212559242,
0.30100342), IL.13 = c(1.704419932, 1.112298247, 2.285765956,
4.633806398, 0.642126976, 0.746932456, 0.363434771, 2.340450899,
2.074555897, 1.244106163, 1e-06, 1.820132354, 74.41151063, 2.034099156,
20.68036347, 1e-06, 1e-06, 4.101483243, 0.794749267, 1e-06, 2.805396078,
1.077152785, 1.179818983, 1.581359427, 1.077152785, 1.529718601,
1e-06, 1e-06, 0.58364863, 1e-06, 1.421542399, 0.965068178, 2.836027955,
5.571883643, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 1.449249978,
1.146494964, 1e-06, 1e-06), IL.1_ = c(1e-06, 2.307704109, 25.26088067,
572.801725, 0.510013312, 0.362017284, 0.031608863, 3.870488003,
0.01290693, 1.838427599, 7.097086101, 3.272835372, 10406.43981,
1e-06, 81.64973722, 1.070281402, 9.682079245, 10.80856769, 167.0831603,
0.397080631, 128.7969178, 0.995448576, 14.26930517, 0.69205361,
2.304314695, 0.579468482, 1e-06, 1.304363973, 3.759936213, 0.589889298,
0.299325951, 0.291769643, 15.20223699, 271.2112448, 17.88589268,
0.377847524, 0.142551711, 2.042925614, 17.63920898, 0.954063427,
0.841909578, 0.791637687, 2.719932082, 0.612547139), IL.2 = c(0.310017477,
0.639550623, 0.364921535, 0.90788638, 1e-06, 1e-06, 1e-06, 0.479461553,
0.153405415, 0.456098215, 0.659233077, 0.019421531, 2.581092035,
0.60647104, 0.374719897, 0.198939483, 1e-06, 1e-06, 0.420590306,
0.637356204, 0.650500136, 0.187772403, 0.234414214, 0.135640615,
0.167896217, 0.043668, 0.543715428, 0.491057054, 0.104904788,
0.268833496, 0.394164323, 0.153405415, 0.511791782, 1.40318585,
0.162131403, 0.386895823, 0.207232191, 0.234414214, 0.129616074,
0.465471829, 0.411020666, 0.374719897, 0.302383698, 0.266218696
), IL.4 = c(1e-06, 0.061134995, 0.033725716, 0.176628741, 0.036390669,
0.016385835, 0.02963346, 0.0912511, 0.044136184, 0.007841464,
1e-06, 1e-06, 0.555602008, 0.201038117, 1e-06, 0.016385835, 1e-06,
1e-06, 0.05520647, 0.014779363, 0.0453956, 0.019496483, 0.066933632,
1e-06, 1e-06, 1e-06, 0.040306406, 0.077093341, 1e-06, 0.02963346,
0.042868427, 0.088031622, 0.041591965, 0.039011321, 1e-06, 0.013131473,
1e-06, 1e-06, 1e-06, 1e-06, 0.009676617, 0.023961259, 1e-06,
0.025405987), IL.6 = c(0.132069931, 0.205121881, 0.266403938,
0.357044807, 0.175675816, 0.135299256, 0.160466529, 0.801623905,
0.219429811, 0.178675804, 1e-06, 1e-06, 1.946693297, 0.00336273,
0.260996547, 1e-06, 1e-06, 1e-06, 0.101959817, 0.148023004, 0.522793842,
0.166593645, 0.098477711, 0.122253955, 0.184636758, 0.076829582,
1e-06, 1e-06, 1e-06, 0.065400292, 0.144869779, 0.151158758, 0.175675816,
1.136760714, 0.031581939, 0.049271129, 1e-06, 0.036206361, 1e-06,
1e-06, 0.154277589, 0.163537592, 0.101959817, 0.166593645), IL.8 =
c(0.263813623,
0.176968743, 21.45511221, 41.02244667, 0.325779267, 0.19875696,
0.191549828, 5.874233467, 0.162143262, 0.254734152, 0.424914919,
0.83134713, 615.7282871, 0.222420019, 11.71507301, 0.254734152,
0.48778161, 0.459603466, 9.245098493, 0.937998793, 158.7036736,
1.052601593, 7.398795984, 0.517616924, 0.842129973, 0.049980916,
0.091283798, 0.703339445, 0.353738394, 0.12114101, 0.189135463,
0.272831114, 2.577264558, 1e-06, 6.92155151, 0.099598586, 0.126403393,
0.519593589, 2.999681278, 0.279555285, 4.425047545, 0.203532755,
0.829547294, 0.159646452), TNF._ = c(1e-06, 1e-06, 0.497412481,
2.502977176, 1e-06, 1e-06, 1e-06, 0.663152793, 0.115785465, 0.112196976,
3.296149665, 1.103455361, 13.43259911, 1e-06, 4.62646124, 0.17981792,
0.561262449, 1e-06, 6.979610188, 0.104932683, 3.077428626, 1e-06,
0.140201934, 0.256307354, 0.104932683, 1e-06, 1e-06, 0.014627633,
1.016512746, 1e-06, 1e-06, 1e-06, 0.086184523, 4.778283885, 0.46726225,
1e-06, 0.049369295, 0.049369295, 1e-06, 1e-06, 0.074442943, 0.070428387,
1e-06, 0.040326195), GM.CSF = c(0.540900573, 0.42223301, 0.202804186,
1.956298248, 0.06647775, 0.175295758, 0.123620468, 0.66961417,
1e-06, 0.010627992, 1e-06, 0.025094065, 1.791958029, 1e-06, 0.313611726,
0.129677511, 1e-06, 1e-06, 0.072451697, 0.472115537, 2.438178508,
1e-06, 0.341470499, 0.267309423, 0.016380207, 1e-06, 0.072451697,
1e-06, 1e-06, 1e-06, 0.416006909, 0.150926695, 1e-06, 0.86531761,
1e-06, 0.184454916, 1e-06, 0.004950137, 1e-06, 0.160055214, 0.057540307,
0.072451697, 0.484605677, 0.227328934), IL.12p40 = c(3.449523303,
1.253952318, 1.153628772, 24.66757728, 0.281211388, 0.45621453,
0.577190569, 6.035154458, 0.248565664, 0.303009219, 0.489162441,
0.335752283, 4.483277375, 1e-06, 7.754198316, 0.610258154, 0.259440413,
0.183488862, 7.811612719, 3.596931106, 39.86410464, 1e-06, 19.81040921,
0.687524342, 0.194312525, 1e-06, 0.303009219, 0.787068241, 0.401386775,
0.324832028, 1.187055113, 0.478175762, 1.533272067, 6.012282081,
0.313917608, 0.259440413, 0.08662882, 0.129536365, 2.263026136,
0.478175762, 0.248565664, 0.215988153, 1.120217824, 0.720681708
), IL.15 = c(3.663956797, 0.229437717, 0.949300626, 1.401070403,
0.287497045, 1e-06, 0.049717539, 3.216577943, 0.000801684, 0.039236284,
0.044490955, 0.000801684, 0.47768266, 1e-06, 0.548030419, 1e-06,
0.028624659, 1e-06, 1e-06, 2.722888088, 5.4735116, 1e-06, 0.548030419,
1e-06, 1e-06, 1e-06, 1e-06, 0.075522355, 0.150922499, 1e-06,
0.229437717, 0.378377969, 1e-06, 5.831002955, 1e-06, 1e-06, 0.439974635,
1e-06, 2.04484964, 1e-06, 1e-06, 1e-06, 0.18054264, 0.190365246
), IL.16 = c(20.5193362, 4.328836648, 8.255914035, 16.13264058,
1.268642287, 1e-06, 1e-06, 11.8242623, 1e-06, 1e-06, 1e-06, 1e-06,
4.092029806, 1e-06, 3.67041693, 1e-06, 1e-06, 1e-06, 0.301180818,
14.7673695, 20.3213016, 1e-06, 6.82449294, 1e-06, 1e-06, 1e-06,
1e-06, 0.401190562, 0.55732358, 1e-06, 1.444064455, 0.433320317,
1e-06, 28.06557331, 1e-06, 0.301180818, 2.015806139, 1e-06, 4.485194079,
1.59090159, 1e-06, 0.335201656, 0.873203993, 1.035154141), IL.17 =
c(4.977017713,
2.570719348, 2.015098932, 3.992319128, 1.06226368, 0.885436394,
1.3153313, 2.244935789, 0.874075666, 0.908175994, 0.896803194,
0.755173959, 4.459228138, 0.862721083, 1.142538479, 1.292234665,
0.806042993, 0.857046119, 1.09663731, 3.877447052, 12.35812507,
0.942329724, 1.570454586, 1.171265948, 1.200022785, 0.806042993,
0.970830673, 1.073716485, 2.52322014, 0.885436394, 1.587915828,
1.803905178, 0.789071362, 5.466413978, 0.755173959, 1.251857053,
0.698820169, 0.936633804, 1.20577762, 1.010790396, 0.930939325,
0.868397602, 1.523930998, 1.745417659), IL.1_.1 = c(118.208659,
114.7568995, 99.56142647, 517.2879232, 100.3722434, 96.93543486,
81.64662024, 70.27819582, 17.13820342, 82.52992205, 81.78590123,
92.43171819, 1053.37885, 65.5820605, 363.635418, 45.79361892,
33.21789883, 29.57769534, 311.8625878, 40.79704867, 851.3943098,
55.1196921, 239.9686999, 38.15064699, 45.53416821, 28.63008947,
18.15241505, 20.64297024, 32.5135396, 20.39305218, 28.46271279,
6.469080388, 41.24452118, 297.4003248, 102.2122555, 10.96668006,
22.48696243, 23.15105529, 25.04798574, 25.01122998, 77.30344367,
79.36764816, 45.54090693, 35.20462575), IL.5 = c(1.044231313,
0.573092875, 0.584075265, 0.598727834, 1e-06, 1e-06, 1e-06, 0.372977066,
1e-06, 0.291939134, 1e-06, 1e-06, 1e-06, 0.161982214, 1e-06,
1e-06, 0.048963445, 0.088502876, 1e-06, 0.232920333, 1.023752123,
1e-06, 0.04556126, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 0.338690819,
0.067789042, 0.657440756, 0.282972479, 1e-06, 10.196604, 1e-06,
1e-06, 1e-06, 1e-06, 1e-06, 1e-06, 0.154932764, 0.086770774,
1e-06, 0.29373344), IL.7 = c(0.480830602, 0.669397614, 0.056955049,
0.645772623, 0.085416118, 0.157189302, 1e-06, 0.669397614, 0.037168535,
0.039986238, 1e-06, 1e-06, 0.054120296, 0.003790123, 0.162959026,
0.270215723, 1e-06, 0.028737802, 1e-06, 0.212128061, 0.947919977,
1e-06, 0.244047658, 1e-06, 0.296425864, 1e-06, 0.168732133, 0.157189302,
0.168732133, 0.111169917, 0.194750148, 0.678260571, 1e-06, 0.873693001,
1e-06, 0.082561887, 1e-06, 0.025936126, 1e-06, 0.174508512, 0.068316418,
0.206332705, 0.051287998, 0.572039147), TNF._.1 = c(3.419068944,
0.774614576, 1.778032483, 3.677555816, 0.09525377, 0.045152852,
0.203310769, 2.480647474, 0.035471915, 0.018965724, 0.064189143,
0.082908763, 0.91606112, 0.20625602, 0.264708971, 0.250170556,
0.393803487, 0.125749131, 0.235584535, 2.600828984, 3.532130347,
0.235584535, 0.728067967, 0.038713645, 1e-06, 1e-06, 0.086004142,
0.008673406, 0.921475662, 1e-06, 0.170745502, 0.012155505, 0.152838242,
4.753887357, 0.035471915, 0.155830622, 0.048352721, 0.045152852,
1.058973116, 0.09525377, 0.140835049, 0.250170556, 0.170745502,
0.110560669), VEGF = c(4087.981219, 3715.552662, 3944.604398,
3844.577145, 396.5302176, 299.8314501, 207.394422, 3933.745405,
14.78051963, 321.5135099, 297.4382786, 561.2753232, 3050.364368,
116.7615841, 3145.523924, 212.8841604, 44.27057474, 44.58276978,
2020.429602, 4128.947066, 4073.070344, 1691.91391, 3758.767261,
889.8387076, 644.4912406, 250.6067383, 590.6027003, 716.7750862,
404.9555583, 204.2231031, 71.38985829, 36.15359803, 1329.165521,
4009.740565, 2903.460055, 889.1034558, 1417.808231, 480.7677475,
3696.819676, 1455.555265, 998.5832238, 1637.63334, 1149.828041,
55.667355)), .Names = c("IFN._", "IL.10", "IL.12p70", "IL.13",
"IL.1_", "IL.2", "IL.4", "IL.6", "IL.8", "TNF._", "GM.CSF", "IL.12p40",
"IL.15", "IL.16", "IL.17", "IL.1_.1", "IL.5", "IL.7", "TNF._.1",
"VEGF"), class = "data.frame", row.names = c("I100A", "I100B",
"I100C", "I100D", "I100E", "I100F", "I100G", "I123A", "I143A",
"I143B", "I14A", "I14B", "I14C", "I14D", "I17A", "I17B", "I17C",
"I17D", "I17E", "I185A", "I185B", "I185C", "I185D", "I185E",
"I185F", "I185G", "I20A", "I20B", "I20C", "I215A", "I215B", "I215C",
"I215D", "I50A", "I50B", "I50C", "I50D", "I50E", "I78A", "I78B",
"I88A", "I88B", "I88C", "I88D"))

> dput(Microbiome_NEC)
structure(list(environmental.samples..Bacteria. = c(0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), Rhizobiales = c(0L, 0L,
0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 2L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 8L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 3L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), Burkholderiales = c(0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L,
0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L), Enterobacteriales = c(3636L,
3574L, 5908L, 5358L, 3067L, 2392L, 1876L, 40L, 109L, 1182L, 2741L,
3660L, 1716L, 5282L, 1242L, 3570L, 3065L, 3270L, 4023L, 67L,
8361L, 4743L, 10080L, 6857L, 6164L, 3580L, 11L, 3L, 1064L, 1L,
323L, 45L, 1730L, 32L, 5376L, 3002L, 2164L, 3111L, 586L, 4023L,
22L, 110L, 41L, 67L), Pasteurellales = c(0L, 0L, 0L, 0L, 0L,
0L, 0L, 5L, 46L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 172L, 425L, 1L, 2L, 0L, 0L, 0L,
0L, 10L, 0L, 0L, 0L, 5L, 6L, 121L, 831L), Pseudomonadales = c(0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), Actinomycetales = c(0L,
0L, 0L, 0L, 1L, 0L, 53L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 12L, 68L), Bifidobacteriales =
c(6L,
2L, 437L, 925L, 748L, 1569L, 1459L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), Corynebacteriales
= c(0L,
0L, 0L, 0L, 0L, 0L, 0L, 27L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
0L, 0L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 2L, 0L, 163L, 0L, 0L, 0L), Micrococcales = c(0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 36L, 23L, 0L), Propionibacteriales = c(0L,
0L, 0L, 0L, 0L, 1L, 28L, 10L, 1205L, 24L, 0L, 2L, 0L, 3L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 30L,
0L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 18L, 3L, 2166L, 441L, 5L),
    Eggerthellales = c(0L, 0L, 1L, 0L, 1L, 4L, 3L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L), Bacillales = c(1573L, 1121L, 1077L, 366L,
    304L, 136L, 3L, 2087L, 1378L, 91L, 1L, 8L, 6L, 19L, 732L,
    130L, 2L, 0L, 1L, 5374L, 2L, 811L, 22L, 40L, 23L, 4L, 79L,
    20L, 717L, 1285L, 503L, 1525L, 151L, 0L, 0L, 0L, 45L, 16L,
    2778L, 249L, 3370L, 973L, 231L, 32L), Lactobacillales = c(0L,
    0L, 93L, 2L, 2L, 38L, 12L, 596L, 318L, 38L, 1L, 2L, 14L,
    18L, 1L, 47L, 1L, 1L, 24L, 13L, 27L, 1L, 335L, 96L, 321L,
    444L, 1797L, 3668L, 714L, 2L, 2775L, 2830L, 1202L, 3224L,
    465L, 605L, 57L, 92L, 1315L, 58L, 1L, 2L, 7L, 167L), Clostridiales =
c(0L,
    0L, 0L, 0L, 1L, 0L, 0L, 4L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), Negativicoccus =
c(0L,
    0L, 0L, 0L, 0L, 0L, 2L, 0L, 0L, 12L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 5L),
    Veillonella = c(0L, 0L, 1L, 0L, 5L, 158L, 61L, 6L, 25L, 93L,
    1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 2037L, 327L, 108L, 910L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 2L, 33L), Tissierellales = c(0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 37L, 1L, 4L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 5L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 3121L, 576L)), .Names =
c("environmental.samples..Bacteria.",
"Rhizobiales", "Burkholderiales", "Enterobacteriales", "Pasteurellales",
"Pseudomonadales", "Actinomycetales", "Bifidobacteriales",
"Corynebacteriales",
"Micrococcales", "Propionibacteriales", "Eggerthellales", "Bacillales",
"Lactobacillales", "Clostridiales", "Negativicoccus", "Veillonella",
"Tissierellales"), class = "data.frame", row.names = c("I100A",
"I100B", "I100C", "I100D", "I100E", "I100F", "I100G", "I123A",
"I143A", "I143B", "I14A", "I14B", "I14C", "I14D", "I17A", "I17B",
"I17C", "I17D", "I17E", "I185A", "I185B", "I185C", "I185D", "I185E",
"I185F", "I185G", "I20A", "I20B", "I20C", "I215A", "I215B", "I215C",
"I215D", "I50A", "I50B", "I50C", "I50D", "I50E", "I78A", "I78B",
"I88A", "I88B", "I88C", "I88D"))


> dput(Metab_NEC)
structure(list(fatty.acids = c(0.97, 1.96, 2.15, 10.06, 5.87,
3.57, 3, 18.36, 4.6, 3.55, 2.44, 1.69, 2.88, 0.76, 6.05, 1.93,
2.02, 1.99, 2.77, 1.76, 1.4, 3.48, 2.24, 0.95, 1.1, 2.32, 0.27,
1.16, 5.32, 4.37, 3.27, 3.02, 2.19, 2.37, 1.38, 0.95, 1.08, 2.79,
3.26, 2.7, 1.26, 5.14, 5.13, 11.56), aldehydes = c(0.25, 0, 0.36,
0.07, 0, 0, 0.18, 0, 0.08, 0.11, 0.13, 0.24, 0, 0.04, 1.45, 0.12,
0.03, 0.05, 0.02, 0.11, 0.02, 0, 0.12, 0.14, 0, 0.17, 0, 0.05,
0, 0.02, 0.03, 0.23, 0, 0.06, 0, 0.02, 0, 0, 0.59, 0.05, 0.19,
0.17, 0, 0.1), alcohol = c(1.91, 0.21, 0.86, 3.29, 0.9, 0.37,
0.39, 6.98, 1.31, 1.52, 1.34, 1.88, 4.31, 1.03, 4.85, 0.82, 0.44,
0.91, 1.32, 2.18, 1.01, 2.9, 4.68, 1.26, 1.6, 0.99, 1.39, 1.04,
2.86, 2.25, 1.71, 1.55, 1.01, 1.22, 1.04, 1.1, 1.64, 1.31, 4.53,
1.57, 1.69, 3.81, 3.32, 3.25), amines = c(0.06, 0.08, 0.01, 2.04,
6.06, 2.67, 4.04, 2.2, 0.75, 0.2, 0.94, 0.39, 0.51, 0.1, 0.11,
0.19, 0.16, 0.12, 0.16, 0, 0.16, 0, 0, 0.53, 0.13, 2.48, 0.29,
0.47, 0.19, 0.66, 0.09, 0.28, 1.25, 0, 0.26, 0.11, 0, 0.16, 0,
0, 0, 1.17, 1.17, 1.86), phenolic.acid = c(0.01, 0.01, 0.04,
0, 0, 0, 0.21, 0.22, 0.04, 0.65, 0, 0.01, 0.03, 0, 0.01, 0, 0.01,
0.01, 0.04, 0, 0, 0, 0.01, 0, 0, 0.02, 0, 0.09, 0.03, 0, 0, 0,
0.06, 0.03, 0, 0.06, 0, 0, 0, 0, 0.03, 0.01, 0, 0.48), sugars = c(50.98,
37.78, 18, 4.38, 23.55, 22.65, 15.63, 14.5, 15.89, 11.24, 8.37,
20.22, 10.21, 18.5, 61.92, 16.1, 30.24, 26.1, 3.09, 41.16, 34.96,
19.03, 28.68, 37.19, 41.9, 16.35, 43.77, 32.99, 15.54, 17.47,
31.21, 12.99, 21.59, 31.59, 51.64, 45.92, 47.17, 31.55, 45.51,
45.3, 56.08, 21.79, 31.22, 4.28), amino.acids = c(4.24, 4.31,
6.27, 9.1, 4.75, 2.31, 2.49, 13.22, 4.27, 5.34, 5.44, 2.35, 3.46,
2.05, 9.41, 4.23, 2.85, 2.65, 3.69, 5.67, 3.01, 4.33, 3.99, 1.84,
2.88, 2.52, 2.14, 5.25, 6.18, 9.02, 3.07, 1.4, 2.25, 9.52, 4.04,
2.94, 2.91, 4.84, 6.34, 4.88, 3.31, 6.29, 4.86, 4.23), osmolytes = c(7.1,
2.15, 1.59, 2.91, 0.56, 4.04, 0.3, 2.05, 0.24, 1.06, 4.54, 4.19,
1.16, 0.41, 8.52, 3.28, 7.27, 2.38, 2.65, 3.04, 1.52, 3.55, 2.69,
3.21, 0.67, 0.98, 1.6, 0.83, 0.99, 4.64, 3.38, 12.2, 0.42, 1.28,
4.64, 2.5, 3.36, 1.08, 5.32, 1.7, 2.01, 1.89, 2.72, 1.04),
energy.related.acid = c(0.55,
1.52, 0.6, 1.9, 0.63, 0.74, 0.46, 2.67, 1.08, 4.22, 7.69, 2.09,
7.31, 1.07, 1.19, 1.78, 0.43, 0.3, 11.11, 1.52, 1.67, 4.21, 1.76,
2.84, 3.06, 3.13, 0.04, 2.7, 3.01, 5.15, 2.31, 0.29, 2.16, 4.09,
1.21, 0.59, 0.55, 2.88, 1, 1.22, 0.7, 1.09, 1.5, 1.12), nucleobase = c(0,
0, 0.05, 0.11, 0.05, 0, 0.24, 0.2, 0.04, 0.04, 0.02, 0.02, 0.08,
0.01, 0.17, 0.02, 0.02, 0.03, 0.03, 0, 0.03, 0.09, 0.02, 0.02,
0.02, 0.01, 0.11, 0.03, 0.03, 0.05, 0.04, 0.02, 0.28, 0.06, 0.04,
0.03, 0, 0.01, 0.05, 0.05, 0.01, 0.07, 0.05, 0.09)), .Names =
c("fatty.acids",
"aldehydes", "alcohol", "amines", "phenolic.acid", "sugars",
"amino.acids", "osmolytes", "energy.related.acid", "nucleobase"
), class = "data.frame", row.names = c("I100A", "I100B", "I100C",
"I100D", "I100E", "I100F", "I100G", "I123A", "I143A", "I143B",
"I14A", "I14B", "I14C", "I14D", "I17A", "I17B", "I17C", "I17D",
"I17E", "I185A", "I185B", "I185C", "I185D", "I185E", "I185F",
"I185G", "I20A", "I20B", "I20C", "I215A", "I215B", "I215C", "I215D",
"I50A", "I50B", "I50C", "I50D", "I50E", "I78A", "I78B", "I88A",
"I88B", "I88C", "I88D"))


Now I normalised them all by % and tried cca in vegan package.

normCytok_and_ProInf <- (Cytok_and_ProInf/rowSums(Cytok_and_ProInf))*100
normMetab_NEC <- (Metab_NEC/rowSums(Metab_NEC))*100
normMicrobiome_NEC <- (Microbiome_NEC/rowSums(Microbiome_NEC))*100
#Now CCA
Metab.Cytok.Microb.cca <-
cca(normMicrobiome_NEC,normMetab_NEC,normCytok_and_ProInf)
plot(Metab.Cytok.Microb.cca )
Metab.Cytok.Microb.cca <- cca(normMicrobiome_NEC,normCytok_and_ProInf)
 plot(Metab.Cytok.Microb.cca )
Metab.Cytok.Microb.cca <- cca(normMicrobiome_NEC,normMetab_NEC)
plot(Metab.Cytok.Microb.cca )


Any help will be really great.
Thank you very much.
Mitra



On 4 August 2016 at 14:25, Michael Friendly <friendly at yorku.ca> wrote:

> You haven't supplied any data, and we can only guess which cca() function
> you are using (ade4::cca, ..., vegan::cca(), yacca::cca), and the term
> 'cca' generally refers to canonical correspondence analysis,
> which is not quite the same thing as 'three-way correspondence analysis'.
>
> For three-way tables, there are several variations of standard
> correspondence analysis that generalize CA for two-way tables
> in reasonable, but different ways.
> You may find more joy using the mjca() in the ca package
> which provides these alternatives.
>
> best,
> -Michael
>
>
> On 8/2/2016 3:58 PM, Suparna Mitra wrote:
>
>> Hello R experts,
>>    have some data for microbiome, metabolome and cytokine from the same
>> sample. Now I want to do a three-way correspondence analyses. From three
>> normalised data I was trying,
>> #Now CCA
>>
>> with two data it works good like:
>> Metab.Cytok.Microb.cca <- cca(normMicrobiome_NEC,normCytok_and_ProInf)
>>  plot(Metab.Cytok.Microb.cca )
>> Metab.Cytok.Microb.cca <- cca(normMicrobiome_NEC,normMetab_NEC)
>> plot(Metab.Cytok.Microb.cca )
>>
>> But when I tried with three
>> Metab.Cytok.Microb.cca <-
>> cca(normMicrobiome_NEC,normMetab_NEC,normCytok_and_ProInf)
>> plot(Metab.Cytok.Microb.cca )
>> But this is not displaying all three variables.
>> Sorry, I am very new in this. Can anybody please help me?
>> Thanks a lot,
>> Mitra
>>
>>         [[alternative HTML version deleted]]
>>
>>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From roy.mendelssohn at noaa.gov  Mon Aug  8 17:09:48 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Mon, 8 Aug 2016 08:09:48 -0700
Subject: [R] Update to the xtractomatic package
Message-ID: <4282DCE0-F20B-44D6-B5CD-CA3627D9D136@noaa.gov>

xtractomatic is an R package developed to subset and extract satellite and other oceanographic related data from a remote server. The program can extract data for a moving point in time along a user-supplied set of longitude, latitude and time points; in a 3D bounding box; or within a polygon (through time).  An update to the package has been released.  The major change (besides some minor bug fixes and prettifying of code) is the inclusion of some 20 new datasets.  These include the reprocessed SeaWIFS chlorophyll data (R2014.0), MUR SST v4.1, a MUR-based SST anomaly, a 750m VIIIRS chlorophyll dataset for the North Pacific, a HYCOM-based estimate of sea surface height,  and an estimate of frontal probability.

I am slowly working on getting xtractomatic suitable for submission to CRAN,  in the meantime the instructions for installing the package can be found on the Github site https://github.com/rmendels/xtractomatic.  Also there is the wonderful "rerddap" package from the rOpenSci  folk which is available from CRAN.

-Roy
 


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From faradj.g at gmail.com  Mon Aug  8 17:42:52 2016
From: faradj.g at gmail.com (Faradj Koliev)
Date: Mon, 8 Aug 2016 17:42:52 +0200
Subject: [R] How to create marginal effects tables in R?
Message-ID: <B188FF1C-E21D-469F-BECC-1065877B3069@gmail.com>

Hi everyone, 

I have three ordered regression models where the ordered dependent variable ranges from 0 to 2. What I want to do is create marginal effects tables (not a plot) at each level (0, 1, and 2) for all three models. So, three tables with each showing the marginal effects at level 0, 1, and 2. 


## create a random data that is similar to my dataset
set.seed(987)
mydata <- data.frame(
  x1    = sample(c(0, 1, 2), 100, replace = TRUE),
  x2    = sample(c(0, 1, 2, 3, 4), 100, replace = TRUE),
  x3    = sample(c(0, 1, 2, 3, 5), 100, replace = TRUE),
  x4    = sample(c(1:100), 100, replace = TRUE),
  x5    = sample(c(10:1000), 100, replace = TRUE),
  Y1 = sample(c(0, 1, 2), 100, replace = TRUE)
)
head(mydata)

## makeit factor
mydata$Y1 <- as.factor(mydata$Y1)

## My models
M1<- polr(Y1 ~x1+x2+x3+x4, data=mydata, Hess = TRUE,  method="logistic")

M2<- polr(Y1 ~x2+x3+x4+x5, data=mydata, Hess = TRUE,  method="logistic")

M3<- polr(Y1 ~x1+x2+x3+x4+x5, data=mydata, Hess = TRUE,  method="logistic")

## Calculate marginal effects using the erer package

M1ME<- ocME(M1)

M2ME <- ocME(M2)

M3ME <- ocME(M3)


Usually I would use the package stargazer to create proper tables, for example: 
stargazer(M1,M2, M3, type = ?text?)  

However, the output from the OcME()  does not generate the same type of tables and nor can I generate tables at each level. stargazer(M1ME$out,M2ME$out, M3ME$out,  type = "text" )

Do you have any suggestion as to how to generate these types of tables?



	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Mon Aug  8 17:52:07 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 8 Aug 2016 15:52:07 +0000
Subject: [R] Conditionally remove rows with logic
In-Reply-To: <CALvAKX+UVAcNxh8VVfpQ-LQip8pgVR-eNyb6LtvaYYJ=sefhrQ@mail.gmail.com>
References: <CALvAKX+UVAcNxh8VVfpQ-LQip8pgVR-eNyb6LtvaYYJ=sefhrQ@mail.gmail.com>
Message-ID: <D3CDF5A3.1815F1%macqueen1@llnl.gov>

Assuming that within each ID the data is sorted by increasing TIME, and
that LABEL==1 occours only once within each ID. Then I would try something
like this.

Suppose that your data is in a data frame named "df".


df.keep <- logical()

for (id in unique(df$ID)) {
  df.tmp <- subset(df, df$ID==id)
  tmp.keep <- rep(TRUE, nrow(df.tmp))
  tmp.keep[df.tmp$TIME > df.tmp$TIME[df.tmp$LABEL==1]] <- FALSE
  df.keep <- c(df.keep, tmp.keep)
}

newdf <- df[df.keep , ]

I have not tested this.

I'm sure it could be made more efficient, and probably with a bit of
cleverness one could avoid creating temporary subsets of the input. But I
tend to find such subsets handy for testing and debugging.

Unless your input data is huge, it should be fast enough that you won't
notice the inefficiencies.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/7/16, 3:21 PM, "R-help on behalf of Jennifer Sheng"
<r-help-bounces at r-project.org on behalf of jennifer.sheng2002 at gmail.com>
wrote:

>Dear all,
>
>I need to remove any rows AFTER the label becomes 1.  For example, for ID
>1, the two rows with TIME of 15 & 18 should be removed; for ID 2, any rows
>after time 6, i.e., rows of time 9-18, should be removed.  Any
>suggestions?  Thank you very much!
>
>The current dataset looks like the following:
>ID     TIME     LABEL
>1        0            0
>1        3            0
>1        6            0
>1        9            0
>1        12          1
>1        15          0
>1        18           0
>2        0            0
>2        3            0
>2        6            1
>2        9            0
>2        12          0
>2        15          0
>2        18          0
>
>Thanks a lot!
>Jennifer
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mohsen.sharafatmandrad at gmail.com  Mon Aug  8 09:48:57 2016
From: mohsen.sharafatmandrad at gmail.com (Mohsen Sharafatmandrad)
Date: Mon, 8 Aug 2016 00:48:57 -0700
Subject: [R] changing x and y ranges in a PCA plot created by library(labdsv)
Message-ID: <CAERY0-pDQGmOtPppHx60eNF13+op8ziS9F+V70D3OGakpgTFvQ@mail.gmail.com>

I want to change x and y ranges in a PCA plot created by library(labdsv).
When I run "plot(o.pca, xlim=c(-2, 3), ylim=c(-2, 4))", nothing will
change. Script is as fallow:



raw<- matrix(c(1,2,2.5,2.5,1,0.5,0,1,2,4,3,1),nrow=6)

colnames(raw)<- c("s1","s2")

rownames(raw)<- c("r1","r2","r3","r4","r5","r6")

cent<- scale(raw,scale=FALSE)

o.pca <- pca(cent)

plot(o.pca)

plot(o.pca, xlim=c(-2,3), ylim=c(-2,4))


-- 
Cheers

Mohsen Sharafatmandrad

	[[alternative HTML version deleted]]


From rpkg at jcarroll.com.au  Mon Aug  8 14:56:08 2016
From: rpkg at jcarroll.com.au (Jonathan Carroll)
Date: Mon, 8 Aug 2016 22:26:08 +0930
Subject: [R] [R-pkgs] New package: ggghost 0.1.0 - Capture the spirit of
	your	ggplot2 calls
Message-ID: <CAAjDRigRHmiPSBEoY7h3rCXD7FF7_Bk2x_PenDoBT4t0LXKBQQ@mail.gmail.com>

Greetings, R users!

I am pleased to announce the release of my first CRAN package: ggghost.

https://cran.r-project.org/web/packages/ggghost
https://github.com/jonocarroll/ggghost

Features:

 - Minimal user-space overhead for implementation; p %g<% ggplot(dat,
aes(x,y))
 - ggplot2 components added to the plot object (p <- p + geom_point()) are
stored in a list within p, and evaluation delayed
 - The incoming data is captured and retained for reproducibility
 - The list of calls can be added to (+), subtracted from (-, via regex),
and subset
 - The list of calls can be inspected (via summary)
 - The data and calls can be recovered from the object p even if removed
from the workspace.

Provides a solution to a question posed here:
https://twitter.com/JennyBryan/status/755417584359632896

Whether the pun name or the R code came first is a secret that dies with me.

I welcome any feedback or suggestions you may have.

Kind regards,

- Jonathan Carroll.

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From Jacob.Strunk at dnr.wa.gov  Mon Aug  8 18:07:52 2016
From: Jacob.Strunk at dnr.wa.gov (Strunk, Jacob (DNR))
Date: Mon, 8 Aug 2016 16:07:52 +0000
Subject: [R] interaction between clusterMap(),
 read.csv() and try() - try does not catch error
Message-ID: <72D7DF49EFB92E4A9BE47205A0F4F03222C1197A@WAXMXOLYMB016.WAX.wa.lcl>

Hello I am attempting to process a list of csv files in parallel, some of which may be empty and fail with read.csv. I tend to use clusterMap as my go-to parallel function but have run into an interesting behavior. The behavior is that try(read.csv(x)) does not catch read errors resulting from having an empty csv file inside of clusterMap. I have not tested this with other functions (e.g. read.table, mean, etc.). The parLapply function does, it appears, correctly catch the errors. Any suggestions on how I should code with clusterMap such that try is guaranteed to catch the error?


I am working on windows server 2012
I have the latest version of R and parallel
I am executing the code from within the rstudio ide Version 0.99.896

Here is a demonstration of the failure

R code used in demonstration:
#prepare csv files - an empty file and a file with data
close(file("c:/temp/badcsv.csv",open="w"))
write.table(data.frame(x=2),"c:/temp/goodcsv.csv")

#prepare a parallel cluster
clus0=makeCluster(1, rscript_args = "--no-site-file")

#read good / bad files in parallel with parLapply - which succeeds: try Does catch err
x1=parLapply(clus0,c("c:/temp/badcsv.csv","c:/temp/goodcsv.csv"),function(...)try(read.csv(...)))
print(x1)

#read good / bad files in parallel with clusterMap - which fails: try does Not catch error
x0=clusterMap(clus0,function(...)try(read.csv(...)),c("c:/temp/badcsv.csv","c:/temp/goodcsv.csv"),SIMPLIFY=F)
print(x0)

R output:

> #prepare csv files - an empty file and a file with data
> close(file("c:/temp/badcsv.csv",open="w"))
> write.table(data.frame(x=2),"c:/temp/goodcsv.csv")
>
> #prepare a parallel cluster
> clus0=makeCluster(1, rscript_args = "--no-site-file")
>
> #read good / bad files in parallel with parLapply - which succeeds: try Does catch err
> x1=parLapply(clus0,c("c:/temp/badcsv.csv","c:/temp/goodcsv.csv"),function(...)try(read.csv(...)))
> print(x1)
[[1]]
[1] "Error in read.table(file = file, header = header, sep = sep, quote = quote,  : \n  no lines available in input\n"
attr(,"class")
[1] "try-error"
attr(,"condition")
<simpleError in read.table(file = file, header = header, sep = sep, quote = quote,     dec = dec, fill = fill, comment.char = comment.char, ...): no lines available in input>

[[2]]
    x
1 1 2

>
> #read good / bad files in parallel with clusterMap - which fails: try does Not catch error
> x0=clusterMap(clus0,function(...)try(read.csv(...)),c("c:/temp/badcsv.csv","c:/temp/goodcsv.csv"),SIMPLIFY=F)
Error in checkForRemoteErrors(val) :
  one node produced an error: Error in read.table(file = file, header = header, sep = sep, quote = quote,  :
  no lines available in input
> print(x0)
Error in print(x0) : object 'x0' not found
>


Thanks for any help,
Jacob


	[[alternative HTML version deleted]]


From farnoosh_81 at yahoo.com  Mon Aug  8 19:16:11 2016
From: farnoosh_81 at yahoo.com (Farnoosh Sheikhi)
Date: Mon, 8 Aug 2016 17:16:11 +0000 (UTC)
Subject: [R] Extracting dates to create a new variable
References: <1412270801.12953575.1470676571031.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1412270801.12953575.1470676571031.JavaMail.yahoo@mail.yahoo.com>

Hi there,?
I have a data set like below and wanted to create a new date variable by extracting the dates for specific departments.I want to extract the dates for departments CC, DD, FF, ?put it in a new column and repeat it for other unique IDs.
Subject<- c("2", "2", "2", "3", "3", "3", "4", "4", "5", "5", "5", "5")dates<-seq(as.Date('2011-01-01'),as.Date('2011-01-12'),by = 1)?deps<-c("A", "B", "CC", "C", "CC", "A", "F", "DD", "A", "F", "FF", "D")df <- data.frame(Subject, dates, deps)df
The final data set should look like this:newdate<-c(" 2011-01-03", ?"2011-01-03", ?"2011-01-03", "2011-01-05", "2011-01-05", "2011-01-05" , "2011-01-08", "2011-01-08", "2011-01-08", "2011-01-11", "2011-01-11", "2011-01-11")final<-data.frame(Subject, dates, deps, newdate)final
I really appreciate any help.
?Best,Farnoosh


	[[alternative HTML version deleted]]


From luke-tierney at uiowa.edu  Mon Aug  8 21:17:50 2016
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Mon, 8 Aug 2016 14:17:50 -0500
Subject: [R] interaction between clusterMap(),
 read.csv() and try() - try does not catch error
In-Reply-To: <72D7DF49EFB92E4A9BE47205A0F4F03222C1197A@WAXMXOLYMB016.WAX.wa.lcl>
References: <72D7DF49EFB92E4A9BE47205A0F4F03222C1197A@WAXMXOLYMB016.WAX.wa.lcl>
Message-ID: <alpine.OSX.2.20.1608081414220.801@lukes-macbook-air.local>

try is working fine. The problem is that your remote function is
returning the try-error result, which the parallel infrastructure is
interpreting as an error on the remote node, since the remote calling
infrastructure is using try as well. This could be implemented more
robustly, but it would probably be better in any case your code to use
can use tryCatch and have the error. function return something easier
to work with, like NULL.

Best,

luke

On Mon, 8 Aug 2016, Strunk, Jacob (DNR) wrote:

> Hello I am attempting to process a list of csv files in parallel, some of which may be empty and fail with read.csv. I tend to use clusterMap as my go-to parallel function but have run into an interesting behavior. The behavior is that try(read.csv(x)) does not catch read errors resulting from having an empty csv file inside of clusterMap. I have not tested this with other functions (e.g. read.table, mean, etc.). The parLapply function does, it appears, correctly catch the errors. Any suggestions on how I should code with clusterMap such that try is guaranteed to catch the error?
>
>
> I am working on windows server 2012
> I have the latest version of R and parallel
> I am executing the code from within the rstudio ide Version 0.99.896
>
> Here is a demonstration of the failure
>
> R code used in demonstration:
> #prepare csv files - an empty file and a file with data
> close(file("c:/temp/badcsv.csv",open="w"))
> write.table(data.frame(x=2),"c:/temp/goodcsv.csv")
>
> #prepare a parallel cluster
> clus0=makeCluster(1, rscript_args = "--no-site-file")
>
> #read good / bad files in parallel with parLapply - which succeeds: try Does catch err
> x1=parLapply(clus0,c("c:/temp/badcsv.csv","c:/temp/goodcsv.csv"),function(...)try(read.csv(...)))
> print(x1)
>
> #read good / bad files in parallel with clusterMap - which fails: try does Not catch error
> x0=clusterMap(clus0,function(...)try(read.csv(...)),c("c:/temp/badcsv.csv","c:/temp/goodcsv.csv"),SIMPLIFY=F)
> print(x0)
>
> R output:
>
>> #prepare csv files - an empty file and a file with data
>> close(file("c:/temp/badcsv.csv",open="w"))
>> write.table(data.frame(x=2),"c:/temp/goodcsv.csv")
>>
>> #prepare a parallel cluster
>> clus0=makeCluster(1, rscript_args = "--no-site-file")
>>
>> #read good / bad files in parallel with parLapply - which succeeds: try Does catch err
>> x1=parLapply(clus0,c("c:/temp/badcsv.csv","c:/temp/goodcsv.csv"),function(...)try(read.csv(...)))
>> print(x1)
> [[1]]
> [1] "Error in read.table(file = file, header = header, sep = sep, quote = quote,  : \n  no lines available in input\n"
> attr(,"class")
> [1] "try-error"
> attr(,"condition")
> <simpleError in read.table(file = file, header = header, sep = sep, quote = quote,     dec = dec, fill = fill, comment.char = comment.char, ...): no lines available in input>
>
> [[2]]
>    x
> 1 1 2
>
>>
>> #read good / bad files in parallel with clusterMap - which fails: try does Not catch error
>> x0=clusterMap(clus0,function(...)try(read.csv(...)),c("c:/temp/badcsv.csv","c:/temp/goodcsv.csv"),SIMPLIFY=F)
> Error in checkForRemoteErrors(val) :
>  one node produced an error: Error in read.table(file = file, header = header, sep = sep, quote = quote,  :
>  no lines available in input
>> print(x0)
> Error in print(x0) : object 'x0' not found
>>
>
>
> Thanks for any help,
> Jacob
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From ulrik.stervbo at gmail.com  Mon Aug  8 21:25:36 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Mon, 08 Aug 2016 19:25:36 +0000
Subject: [R] Extracting dates to create a new variable
In-Reply-To: <1412270801.12953575.1470676571031.JavaMail.yahoo@mail.yahoo.com>
References: <1412270801.12953575.1470676571031.JavaMail.yahoo.ref@mail.yahoo.com>
	<1412270801.12953575.1470676571031.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAKVAULOLc7OjikbydGkeGnRmOpYKivqfJB3EjmSRQf_8i0-W9g@mail.gmail.com>

Getting the dates of the departments CC, DD, FF can be done with

subset(df, deps %in% c("CC", "DD", "FF"))

I am not sure how you intend to match these identified dates with other
departments? From your example you sometimes replace earlier dates,
sometimes later dates.

HTH
Ulrik

On Mon, 8 Aug 2016 at 20:23 Farnoosh Sheikhi via R-help <
r-help at r-project.org> wrote:

> Hi there,
> I have a data set like below and wanted to create a new date variable by
> extracting the dates for specific departments.I want to extract the dates
> for departments CC, DD, FF,  put it in a new column and repeat it for other
> unique IDs.
> Subject<- c("2", "2", "2", "3", "3", "3", "4", "4", "5", "5", "5",
> "5")dates<-seq(as.Date('2011-01-01'),as.Date('2011-01-12'),by =
> 1) deps<-c("A", "B", "CC", "C", "CC", "A", "F", "DD", "A", "F", "FF",
> "D")df <- data.frame(Subject, dates, deps)df
> The final data set should look like this:newdate<-c(" 2011-01-03",
>  "2011-01-03",  "2011-01-03", "2011-01-05", "2011-01-05", "2011-01-05" ,
> "2011-01-08", "2011-01-08", "2011-01-08", "2011-01-11", "2011-01-11",
> "2011-01-11")final<-data.frame(Subject, dates, deps, newdate)final
> I really appreciate any help.
>  Best,Farnoosh
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From davidsmi at microsoft.com  Mon Aug  8 22:29:06 2016
From: davidsmi at microsoft.com (David Smith)
Date: Mon, 8 Aug 2016 20:29:06 +0000
Subject: [R] Revolutions blog: July 2016 roundup
Message-ID: <BN6PR03MB285005F4D927154291550BCEC81B0@BN6PR03MB2850.namprd03.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests have written about R every weekday at the
Revolutions blog: http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month of particular interest to readers of r-help.

And in case you missed them, here are some articles related to R from the month of July:

R moves up to 5th place in the annual IEEE Spectrum programming language rankings:
http://blog.revolutionanalytics.com/2016/07/r-moves-up-to-5th-place-in-ieee-language-rankings.html

A guide to R-related presentations at the JSM 2016 conference:
http://blog.revolutionanalytics.com/2016/07/an-r-users-guide-to-jsm-2016.html

FiveThirtyEight uses R extensively for data journalism, as explained in a presentation at useR!2016:
http://blog.revolutionanalytics.com/2016/07/data-journalism-with-r-at-538.html

An in-depth look at DeployR's enterprise security model when calling R functions via the web services API:
http://blog.revolutionanalytics.com/2016/07/deployr-enterprise-security-model.html

Microsoft R Open 3.3.0 is now available for Windows, Mac and PC:
http://blog.revolutionanalytics.com/2016/07/microsoft-r-open-330-now-available.html

A survey of quantitative business professionals ranks R in top position by usage (followed by SAS and Python):
http://blog.revolutionanalytics.com/2016/07/burtch-survey.html

Microsoft is hosting its first Data Science Summit: a conference for data scientists in Atlanta GA, September 26-27:
http://blog.revolutionanalytics.com/2016/07/microsoft-ds-summit.html

An interactive tree map of Pokemon Go characters, created with R:
http://blog.revolutionanalytics.com/2016/07/an-analysis-of-pok%C3%A9mon-go-types-created-with-r.html

Using R to manage energy usage on the Microsoft campus:
http://blog.revolutionanalytics.com/2016/07/energy-load-shaping.html

Why does NA^0 equal 1 in R? http://blog.revolutionanalytics.com/2016/07/understanding-na-in-r.html

Two presentations by me, recorded at useR!2016: How Microsoft uses data science to improve the lives of people with
disabilities, and how R is integrated into Microsoft products:
http://blog.revolutionanalytics.com/2016/07/r-at-microsoft-user-2016.html

A review of some recently-released R packages, by Joe Rickert:
http://blog.revolutionanalytics.com/2016/07/some-new-r-packages.html

How to create a Power BI dashboard based on SQL Server and R:
http://blog.revolutionanalytics.com/2016/06/sql-server-power-bi-and-r.html

Microsoft R Client is a desktop-based version of Microsoft R Server, includes the big-data ScaleR package, and free to
download and use: http://blog.revolutionanalytics.com/2016/07/microsoft-r-client.html

Resources (code and slides) from the tutorials presented at the useR!2016 conference:
http://blog.revolutionanalytics.com/2016/07/user-2016-tutorials-part-2-.html

Rick Becker presents the birth of the S language at Bell Labs:
http://blog.revolutionanalytics.com/2016/07/rick-becker-s-talk.html

Using Microsoft R Server within the Data Science Virtual Machine to graph airline delays from 14Gb of flight
records: http://blog.revolutionanalytics.com/2016/07/dplyrxdf-flight-arrival-delays.html

General interest stories (not related to R) in the past month included: bad maps
(http://blog.revolutionanalytics.com/2016/07/because-its-friday-bad-maps.html), bird migration
(http://blog.revolutionanalytics.com/2016/07/because-its-friday-bird-migration.html), how to tell a B737 from an A320
(http://blog.revolutionanalytics.com/2016/07/because-its-friday-b373-a320.html), a beginner's introduction to data
science (http://blog.revolutionanalytics.com/2016/06/data-science-for-beginners.html), animal 'facts'
(http://blog.revolutionanalytics.com/2016/07/fake-animal-facts.html), and animals and fairness
(http://blog.revolutionanalytics.com/2016/07/because-its-friday-animal-intelligence-animal-fairness.html).

If you're looking for more articles about R, you can find summaries from previous months at
http://blog.revolutionanalytics.com/roundups/. You can receive daily blog posts via email using services like
blogtrottr.com.

As always, thanks for the comments and please keep sending suggestions to me at davidsmi at microsoft.com or via Twitter
(I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From Alicia.Ellis at med.uvm.edu  Mon Aug  8 20:49:49 2016
From: Alicia.Ellis at med.uvm.edu (Ellis, Alicia M)
Date: Mon, 8 Aug 2016 18:49:49 +0000
Subject: [R] Help with big data and parallel computing:  500,
 000 x 4 linear models
Message-ID: <1B1D3757C30EA641A0D591B0C30CB1863C4B1CDB@MED18a.med.uvm>

I have a large dataset with ~500,000 columns and 1264 rows.  Each column represents the percent methylation at a given location in the genome.  I need to run 500,000 linear models for each of 4 predictors of interest in the form of:
Methylation.stie1 ~ predictor1 + covariate1+ covariate2 + ... covariate9
...and save only the pvalue for the predictor

The original methylation data file had methylation sites as row labels and the individuals as columns so I read the data in chunks and transposed it so I now have 5 csv files (chunks) with columns representing methylation sites and rows as individuals.

I was able to get results for all of the regressions by running each chunk of methylation data separately on our supercomputer using the code below.  However, I'm going to have to do this again for another project and I would really like to accomplish two things to make the whole process more computationally efficient:


1)      Work with data.tables instead of data.frames (reading and manipulating will be much easier and faster)

2)      Do the work in parallel using say 12 cores at once and having the program divide the work up on the cores rather than me having to split the data and run 5 separate jobs on the supercomputer.

I have some basic knowledge of the data.table package but I wasn't able to modify the foreach code below to get it to work and the code using data.frames didn't seem to be using all 12 cores that I created in the cluster.

Can anyone suggest some modifications to the foreach code below that will allow me to do this in parallel with datatables and not have to do it in chunks?


############# Set up cluster
clus = makeCluster(12, type = "SOCK")
registerDoSNOW(clus)
getDoParWorkers()
getDoParName()


################### Following code needs to be modified to run the full dataset (batch1-batch5) in parallel
### Currently I read in the following chunks, and run each predictor separately for each chunk of data

############### Methylation data in batches
batch1=read.csv("/home/alicia.m.ellis/batch1.csv")  ###### #Each batch has about 100,000 columns and 1264 rows; want to alter this to:
## batch1=fread(file= )
batch2=read.csv(file="/home/alicia.m.ellis/batch2.csv")
batch3=read.csv(file="/home/alicia.m.ellis/batch3.csv")
batch4=read.csv(file="/home/alicia.m.ellis/batch4.csv")
batch5=read.csv(file="/home/alicia.m.ellis/batch5.csv")

predictors  ## this is a data.frame with 4 columns and 1264 rows

covariates ## this is a data.frame with 9 columns and 1264 rows

fits <- as.data.table(batch1)[, list(MyFits = lapply(1:ncol(batch1), function(x) summary(lm(batch1[, x] ~ predictors[,1] +
                                                                                              covariates[,1]+
                                                                                              covariates[,2]+
                                                                                              covariates[,3]+
                                                                                              covariates[,4]+
                                                                                              covariates[,5]+
                                                                                              covariates[,6]+
                                                                                              covariates[,7]+
                                                                                              covariates[,8]+
                                                                                              covariates[,9]
)
)$coefficients[2,4]
)
)
]


######################################  This is what I was trying but wasn't having much luck
#### I'm having trouble getting the data merged as a single data.frame and the code below doesn't seem to be dividing the work among the 12 cores in the cluster

all. fits = foreach (j=1:ncol(predictors), i=1:ncol(meth1), combine='rbind', .inorder=TRUE) %dopar% {

  model = lm(meth[, i] ~ predictors[,j] +
               covariates[,1]+
               covariates[,2]+
               covariates[,3]+
               covariates[,4]+
               covariates[,5]+
               covariates[,6]+
               covariates[,7]+
               covariates[,8]+
               covariates[,9])
  summary(model)$coefficients[2,4]
}


Alicia Ellis, Ph.D
Biostatistician
Pathology & Laboratory Medicine
Colchester Research Facility
360 South Park Drive, Room 209C
Colchester, VT  05446
802-656-9840


	[[alternative HTML version deleted]]


From Jacob.Strunk at dnr.wa.gov  Mon Aug  8 22:06:51 2016
From: Jacob.Strunk at dnr.wa.gov (Strunk, Jacob (DNR))
Date: Mon, 8 Aug 2016 20:06:51 +0000
Subject: [R] interaction between clusterMap(),
 read.csv() and try() - try does not catch error
In-Reply-To: <alpine.OSX.2.20.1608081414220.801@lukes-macbook-air.local>
References: <72D7DF49EFB92E4A9BE47205A0F4F03222C1197A@WAXMXOLYMB016.WAX.wa.lcl>,
	<alpine.OSX.2.20.1608081414220.801@lukes-macbook-air.local>
Message-ID: <72D7DF49EFB92E4A9BE47205A0F4F03222C119D5@WAXMXOLYMB016.WAX.wa.lcl>

Ok - got it, I can handle that. Thank you Luke!


Jacob L Strunk
_______________________________________
From: luke-tierney at uiowa.edu [luke-tierney at uiowa.edu]
Sent: Monday, August 08, 2016 12:17 PM
To: Strunk, Jacob (DNR)
Cc: r-help at r-project.org
Subject: Re: [R] interaction between clusterMap(), read.csv() and try() - try does not catch error

try is working fine. The problem is that your remote function is
returning the try-error result, which the parallel infrastructure is
interpreting as an error on the remote node, since the remote calling
infrastructure is using try as well. This could be implemented more
robustly, but it would probably be better in any case your code to use
can use tryCatch and have the error. function return something easier
to work with, like NULL.

Best,

luke

On Mon, 8 Aug 2016, Strunk, Jacob (DNR) wrote:

> Hello I am attempting to process a list of csv files in parallel, some of which may be empty and fail with read.csv. I tend to use clusterMap as my go-to parallel function but have run into an interesting behavior. The behavior is that try(read.csv(x)) does not catch read errors resulting from having an empty csv file inside of clusterMap. I have not tested this with other functions (e.g. read.table, mean, etc.). The parLapply function does, it appears, correctly catch the errors. Any suggestions on how I should code with clusterMap such that try is guaranteed to catch the error?
>
>
> I am working on windows server 2012
> I have the latest version of R and parallel
> I am executing the code from within the rstudio ide Version 0.99.896
>
> Here is a demonstration of the failure
>
> R code used in demonstration:
> #prepare csv files - an empty file and a file with data
> close(file("c:/temp/badcsv.csv",open="w"))
> write.table(data.frame(x=2),"c:/temp/goodcsv.csv")
>
> #prepare a parallel cluster
> clus0=makeCluster(1, rscript_args = "--no-site-file")
>
> #read good / bad files in parallel with parLapply - which succeeds: try Does catch err
> x1=parLapply(clus0,c("c:/temp/badcsv.csv","c:/temp/goodcsv.csv"),function(...)try(read.csv(...)))
> print(x1)
>
> #read good / bad files in parallel with clusterMap - which fails: try does Not catch error
> x0=clusterMap(clus0,function(...)try(read.csv(...)),c("c:/temp/badcsv.csv","c:/temp/goodcsv.csv"),SIMPLIFY=F)
> print(x0)
>
> R output:
>
>> #prepare csv files - an empty file and a file with data
>> close(file("c:/temp/badcsv.csv",open="w"))
>> write.table(data.frame(x=2),"c:/temp/goodcsv.csv")
>>
>> #prepare a parallel cluster
>> clus0=makeCluster(1, rscript_args = "--no-site-file")
>>
>> #read good / bad files in parallel with parLapply - which succeeds: try Does catch err
>> x1=parLapply(clus0,c("c:/temp/badcsv.csv","c:/temp/goodcsv.csv"),function(...)try(read.csv(...)))
>> print(x1)
> [[1]]
> [1] "Error in read.table(file = file, header = header, sep = sep, quote = quote,  : \n  no lines available in input\n"
> attr(,"class")
> [1] "try-error"
> attr(,"condition")
> <simpleError in read.table(file = file, header = header, sep = sep, quote = quote,     dec = dec, fill = fill, comment.char = comment.char, ...): no lines available in input>
>
> [[2]]
>    x
> 1 1 2
>
>>
>> #read good / bad files in parallel with clusterMap - which fails: try does Not catch error
>> x0=clusterMap(clus0,function(...)try(read.csv(...)),c("c:/temp/badcsv.csv","c:/temp/goodcsv.csv"),SIMPLIFY=F)
> Error in checkForRemoteErrors(val) :
>  one node produced an error: Error in read.table(file = file, header = header, sep = sep, quote = quote,  :
>  no lines available in input
>> print(x0)
> Error in print(x0) : object 'x0' not found
>>
>
>
> Thanks for any help,
> Jacob
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

--
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From dwinsemius at comcast.net  Mon Aug  8 23:22:33 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 8 Aug 2016 14:22:33 -0700
Subject: [R] changing x and y ranges in a PCA plot created by
	library(labdsv)
In-Reply-To: <CAERY0-pDQGmOtPppHx60eNF13+op8ziS9F+V70D3OGakpgTFvQ@mail.gmail.com>
References: <CAERY0-pDQGmOtPppHx60eNF13+op8ziS9F+V70D3OGakpgTFvQ@mail.gmail.com>
Message-ID: <AE4EEC9E-3CAC-4FCE-B778-65FDF78DFDF1@comcast.net>


> On Aug 8, 2016, at 12:48 AM, Mohsen Sharafatmandrad <mohsen.sharafatmandrad at gmail.com> wrote:
> 
> I want to change x and y ranges in a PCA plot created by library(labdsv).
> When I run "plot(o.pca, xlim=c(-2, 3), ylim=c(-2, 4))", nothing will
> change. Script is as fallow:
> 
> 
> 
> raw<- matrix(c(1,2,2.5,2.5,1,0.5,0,1,2,4,3,1),nrow=6)
> 
> colnames(raw)<- c("s1","s2")
> 
> rownames(raw)<- c("r1","r2","r3","r4","r5","r6")
> 
> cent<- scale(raw,scale=FALSE)
> 
> o.pca <- pca(cent)
> 
> plot(o.pca)
> 
> plot(o.pca, xlim=c(-2,3), ylim=c(-2,4))

You got a response yesterday telling you that xlim and ylim are not passed to the plot call from plot.

You can see this yourself by examining the code:

labdsv::plot.pca
function (x, ax = 1, ay = 2, col = 1, title = "", pch = 1, ...) 
{
    if (class(x) != "pca") 
        stop("You must specify a an object of class pca")
    plot(x$scores[, ax], x$scores[, ay], asp = 1, col = col, 
        xlab = paste("PCA", ax), ylab = paste("PCA", ay), pch = pch, 
        main = title)
    invisible()
}
<environment: namespace:labdsv>



> -- 
> Cheers
> 
> Mohsen Sharafatmandrad
> 
> 	[[alternative HTML version deleted]]

Please read the Posting guide and post any follow-ups in plain text.


-- 

David Winsemius
Alameda, CA, USA


From ajmackey at gmail.com  Mon Aug  8 23:33:29 2016
From: ajmackey at gmail.com (Aaron Mackey)
Date: Mon, 8 Aug 2016 17:33:29 -0400
Subject: [R] Help with big data and parallel computing: 500,
 000 x 4 linear models
In-Reply-To: <1B1D3757C30EA641A0D591B0C30CB1863C4B1CDB@MED18a.med.uvm>
References: <1B1D3757C30EA641A0D591B0C30CB1863C4B1CDB@MED18a.med.uvm>
Message-ID: <CAErFSoh7=DEJfvqS11wnTricVd_8N_JyHo6jF--74NTV4n1qtQ@mail.gmail.com>

Don't run 500K separate models. Use the limma package to fit one model that
can learn the variance parameters jointly. Run it on your laptop. And don't
use %methylation as your Y variable, use logit(percent), i.e. the Beta
value.

-Aaron

On Mon, Aug 8, 2016 at 2:49 PM, Ellis, Alicia M <Alicia.Ellis at med.uvm.edu>
wrote:

> I have a large dataset with ~500,000 columns and 1264 rows.  Each column
> represents the percent methylation at a given location in the genome.  I
> need to run 500,000 linear models for each of 4 predictors of interest in
> the form of:
> Methylation.stie1 ~ predictor1 + covariate1+ covariate2 + ... covariate9
> ...and save only the pvalue for the predictor
>
> The original methylation data file had methylation sites as row labels and
> the individuals as columns so I read the data in chunks and transposed it
> so I now have 5 csv files (chunks) with columns representing methylation
> sites and rows as individuals.
>
> I was able to get results for all of the regressions by running each chunk
> of methylation data separately on our supercomputer using the code below.
> However, I'm going to have to do this again for another project and I would
> really like to accomplish two things to make the whole process more
> computationally efficient:
>
>
> 1)      Work with data.tables instead of data.frames (reading and
> manipulating will be much easier and faster)
>
> 2)      Do the work in parallel using say 12 cores at once and having the
> program divide the work up on the cores rather than me having to split the
> data and run 5 separate jobs on the supercomputer.
>
> I have some basic knowledge of the data.table package but I wasn't able to
> modify the foreach code below to get it to work and the code using
> data.frames didn't seem to be using all 12 cores that I created in the
> cluster.
>
> Can anyone suggest some modifications to the foreach code below that will
> allow me to do this in parallel with datatables and not have to do it in
> chunks?
>
>
> ############# Set up cluster
> clus = makeCluster(12, type = "SOCK")
> registerDoSNOW(clus)
> getDoParWorkers()
> getDoParName()
>
>
> ################### Following code needs to be modified to run the full
> dataset (batch1-batch5) in parallel
> ### Currently I read in the following chunks, and run each predictor
> separately for each chunk of data
>
> ############### Methylation data in batches
> batch1=read.csv("/home/alicia.m.ellis/batch1.csv")  ###### #Each batch
> has about 100,000 columns and 1264 rows; want to alter this to:
> ## batch1=fread(file= )
> batch2=read.csv(file="/home/alicia.m.ellis/batch2.csv")
> batch3=read.csv(file="/home/alicia.m.ellis/batch3.csv")
> batch4=read.csv(file="/home/alicia.m.ellis/batch4.csv")
> batch5=read.csv(file="/home/alicia.m.ellis/batch5.csv")
>
> predictors  ## this is a data.frame with 4 columns and 1264 rows
>
> covariates ## this is a data.frame with 9 columns and 1264 rows
>
> fits <- as.data.table(batch1)[, list(MyFits = lapply(1:ncol(batch1),
> function(x) summary(lm(batch1[, x] ~ predictors[,1] +
>
>                     covariates[,1]+
>
>                     covariates[,2]+
>
>                     covariates[,3]+
>
>                     covariates[,4]+
>
>                     covariates[,5]+
>
>                     covariates[,6]+
>
>                     covariates[,7]+
>
>                     covariates[,8]+
>
>                     covariates[,9]
> )
> )$coefficients[2,4]
> )
> )
> ]
>
>
> ######################################  This is what I was trying but
> wasn't having much luck
> #### I'm having trouble getting the data merged as a single data.frame and
> the code below doesn't seem to be dividing the work among the 12 cores in
> the cluster
>
> all. fits = foreach (j=1:ncol(predictors), i=1:ncol(meth1),
> combine='rbind', .inorder=TRUE) %dopar% {
>
>   model = lm(meth[, i] ~ predictors[,j] +
>                covariates[,1]+
>                covariates[,2]+
>                covariates[,3]+
>                covariates[,4]+
>                covariates[,5]+
>                covariates[,6]+
>                covariates[,7]+
>                covariates[,8]+
>                covariates[,9])
>   summary(model)$coefficients[2,4]
> }
>
>
> Alicia Ellis, Ph.D
> Biostatistician
> Pathology & Laboratory Medicine
> Colchester Research Facility
> 360 South Park Drive, Room 209C
> Colchester, VT  05446
> 802-656-9840
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Aug  9 00:19:55 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 9 Aug 2016 08:19:55 +1000
Subject: [R] Visualising multiple temporal periods each with an
	associated value
In-Reply-To: <87vazbptm2.fsf@hornfels.zedat.fu-berlin.de>
References: <87vazbptm2.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <CA+8X3fU1oFs40oQ8FS4XtPgyAU3LBBWLgHOG=L=KuRpsUNi2Wg@mail.gmail.com>

Hi Loris,
This looks a lot like a Gantt chart with variable bar widths. I'll
check it when I have a bit of time and repost.

JIm


On Mon, Aug 8, 2016 at 6:12 PM, Loris Bennett
<loris.bennett at fu-berlin.de> wrote:
> Hi,
>
> I want to visualise temporal events as rectangles, one side of the
> rectangle being the length of the event, the other being the size of an
> integer variable.  The position of the rectangle along the time axis
> would be determined by the time of the even, the position on the other
> axis is essentially arbitrary. This would look like the graph in the
> lower right of the following image:
>
> http://apps.fz-juelich.de/jsc/llview/html/images/llview_snapshot1.png
>
> I can probably cobble something together in raw R to do this, but I
> assume that this kind of plot has a name and that there may already be
> packages to do this.
>
> Can anyone suggest what one would call this sort of plot?
>
> Cheers,
>
> Loris
>
> --
> Dr. Loris Bennett (Mr.)
> ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Aug  9 02:04:30 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 9 Aug 2016 10:04:30 +1000
Subject: [R] Visualising multiple temporal periods each with an
	associated value
In-Reply-To: <CA+8X3fU1oFs40oQ8FS4XtPgyAU3LBBWLgHOG=L=KuRpsUNi2Wg@mail.gmail.com>
References: <87vazbptm2.fsf@hornfels.zedat.fu-berlin.de>
	<CA+8X3fU1oFs40oQ8FS4XtPgyAU3LBBWLgHOG=L=KuRpsUNi2Wg@mail.gmail.com>
Message-ID: <CA+8X3fVEvqdzoG6_pqv3ah8i1W7M2oYk2Zx9EVfKD8-x8nKPeg@mail.gmail.com>

Hi Loris,
If I understand what you want, it seems to be a combination of a Gantt
chart and a sizetree. The Gantt chart provides the horizontal extent
of the rectangles and the sizetree the vertical extent by assigning
relative heights to the initial rectangles and dividing these into
subsets as time evolves. That approach would not allow rectangles to
expand over time, but that could be accommodated. It's more
complicated than either of the two, but I think it can be done.

Jim


On Tue, Aug 9, 2016 at 8:19 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Loris,
> This looks a lot like a Gantt chart with variable bar widths. I'll
> check it when I have a bit of time and repost.
>
> JIm
>
>
> On Mon, Aug 8, 2016 at 6:12 PM, Loris Bennett
> <loris.bennett at fu-berlin.de> wrote:
>> Hi,
>>
>> I want to visualise temporal events as rectangles, one side of the
>> rectangle being the length of the event, the other being the size of an
>> integer variable.  The position of the rectangle along the time axis
>> would be determined by the time of the even, the position on the other
>> axis is essentially arbitrary. This would look like the graph in the
>> lower right of the following image:
>>
>> http://apps.fz-juelich.de/jsc/llview/html/images/llview_snapshot1.png
>>
>> I can probably cobble something together in raw R to do this, but I
>> assume that this kind of plot has a name and that there may already be
>> packages to do this.
>>
>> Can anyone suggest what one would call this sort of plot?
>>
>> Cheers,
>>
>> Loris
>>
>> --
>> Dr. Loris Bennett (Mr.)
>> ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ccberry at ucsd.edu  Tue Aug  9 04:03:06 2016
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Mon, 8 Aug 2016 19:03:06 -0700
Subject: [R] Help with big data and parallel computing:  500,
 000 x 4 linear models
In-Reply-To: <1B1D3757C30EA641A0D591B0C30CB1863C4B1CDB@MED18a.med.uvm>
References: <1B1D3757C30EA641A0D591B0C30CB1863C4B1CDB@MED18a.med.uvm>
Message-ID: <alpine.OSX.2.20.1608081824130.5417@charles-berrys-macbook.local>

On Mon, 8 Aug 2016, Ellis, Alicia M wrote:

> I have a large dataset with ~500,000 columns and 1264 rows.  Each column 
> represents the percent methylation at a given location in the genome. 
> I need to run 500,000 linear models for each of 4 predictors of interest 
> in the form of:

> Methylation.stie1 ~ predictor1 + covariate1+ covariate2 + ... covariate9
> ...and save only the pvalue for the predictor
>
> The original methylation data file had methylation sites as row labels 
> and the individuals as columns so I read the data in chunks and 
> transposed it so I now have 5 csv files (chunks) with columns 
> representing methylation sites and rows as individuals.
>
> I was able to get results for all of the regressions by running each 
> chunk of methylation data separately on our supercomputer using the code 
> below.

This sounds like a problem for my old laptop, not a supercomputer.

You might want to review the algebra and geometry of least squares.

In particular, covariate1 ... covariate9 are the same 1264 x 9 matrix for 
every problem IIUC. So, you can compute the QR decomposition for that 
matrix (and the unit vector `intercept') *once* and use it in all the 
problems.

Using that decomposition, find the residuals for the regressands and for 
`predictor1' (etc) regressors. The rest is simple least squares. You 
compute the correlation coefficient of the residuals of a regressand and 
those of a regressor, for each combination. Make a table of critical 
values for the p-value(s) you require - remember to get the degrees of 
freedom right (i.e. account for the covariates). These correlations of 
residuals are the partial correlations given the covariates, and a test on 
one of them is algebraically equal to the test on regression coefficient 
for corresponding regressand and regressor in a modelthat also includes 
those 9 covariates.

See:

  ?qr
  ?lm.fit

HTH,

Chuck


From Alexander.Herr at csiro.au  Tue Aug  9 07:38:11 2016
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Tue, 9 Aug 2016 05:38:11 +0000
Subject: [R] foreach {parallel} nested with for loop to update
 data.frame column
Message-ID: <cb21ce63049c41b0ba9080118acfebdf@exch1-mel.nexus.csiro.au>

Actually, you'll need to identify the values of the foreach loop in the for loop for it to work...

require(doParallel)
require(foreach)
set.seed(666)
xyz<-as.data.frame(cbind(x=rep(rpois(50000,10),2)+1, y=rep(rpois(50000,10),2)+1,z=round(runif(100000, min=-3, max=40),2)))
xyz$mins<-rep(NA, nrow(xyz))
xyz[order(xyz[,1],xyz[,2], xyz[,3]),]->xyz

cl<-makeCluster(4)  #adjust to your cluster number
registerDoParallel(cl)
test<-foreach(i=unique(xyz[,1]), .combine=rbind, .verbose=T) %dopar% {
     for(j in unique(xyz[xyz[,1] == i,2] )) {                                                                           # here ensure you pass on the right data 
         xyz[xyz[,2] == j & xyz[,1] == i ,4]<-min(xyz[xyz[,2] == j & xyz[,1] == i,3])  # otherwise there are inf values here
        nr=nrow(xyz[xyz[,2] == j & xyz[,1] == i ,4])
        }
        return(xyz[xyz[,1]== i,])  # you must return what you are farming out...
}
test[1:15,]
stopCluster(cl)


XXXXXXXXXXXXXXXXXXXXX Herry wrote XXXXXXXXXXXXXXXXXX

Hiya,

This now works...

test<-foreach(i=unique(xyz[,1]), .combine=rbind, .verbose=T) %dopar% {
         for( j in unique(xyz[,2])) {
         xyz[xyz[,2] == j & xyz[,1] == i ,4]<-min(xyz[xyz[,2] == j & xyz[,1] == i,3])
        nr=nrow(xyz[xyz[,2] == j & xyz[,1] == i ,4])
        }
        return(xyz[xyz[,1]== i,])  # you must return what you are farming out...
}
head(test)


From ferri.leberl at gmx.at  Tue Aug  9 14:39:50 2016
From: ferri.leberl at gmx.at (Ferri Leberl)
Date: Tue, 9 Aug 2016 14:39:50 +0200
Subject: [R] BaseX
Message-ID: <trinity-b9f53935-42c3-4b6f-868d-1490827b31d8-1470746390842@3capp-gmx-bs76>

Dear everyone,
Is there an R-command to change the expression of a number into hexadecimal, base58 base62 or any other common encoding with a high base of signs?
Thank you in advance for your answers.
Yours,
Mag. Ferri Leberl


From bob at rud.is  Mon Aug  8 16:52:40 2016
From: bob at rud.is (Bob Rudis)
Date: Mon, 8 Aug 2016 10:52:40 -0400
Subject: [R] [R-pkgs] New package uaparserjs 0.1.0 - Slice up browser user
	agent	strings
Message-ID: <CAA-FpKUF-5mJNLCVG_3ATWNSAoV3zhp3Y4N+oZnQZs1M9OOS3w@mail.gmail.com>

I keep forgetting I can announce things here.

[Insert witty/standard boilerplate introductory verbiage here]

CRAN: <https://cran.rstudio.com/web/packages/uaparserjs/index.html>
GitHub: <https://github.com/hrbrmstr/uaparserjs>

Until Oliver and/or I figure out a way to get uap-r
<https://github.com/ua-parser/uap-r> working w/o Boost, this package
provides a way to parse browser user agent strings that are found in
web logs, proxy logs, PCAPs, etc.

This is about 100x slower than uap-r as it's based on javascript
modules that I've built a V8-wrapper around.

It doesn't work on i386 Windows due to v8-library (not the V8-package)
limitations but it works on 64-bit Windows (prbly better off
installing from github for that as CRAN is marking this non-Windows
due to the i386 incompatibility).

If you're on Linux and can deal with a full Boost install and have
need of user agent parsing, use uap-r (it still won't work on Windows
or macOS). Otherwise, give this a go.

I've tested in on a number of OSes but welcome feedback and I'm sure
both Oliver & I would welcome hints on alternatives to Boost regex
that work on all OSes for uap-r since I'd eventually like to replace
this with that.

-Bob

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From isaudin at gmail.com  Tue Aug  9 15:30:18 2016
From: isaudin at gmail.com (Isaudin Ismail)
Date: Tue, 9 Aug 2016 14:30:18 +0100
Subject: [R] Error while fitting gumbel copula
Message-ID: <CAE1aWa_AJRovvq9sZU2LWA3VaBCWAC_mxLoK4L7kzy=HkjgEHQ@mail.gmail.com>

Dear R experts,

I have 5 time series of data (A, B, C, D and E) with all same lengths. All
series exhibit gamma distribution except for B which is lognormal
distribution. I am using copula package to model the joint-distribution of
these 5 times series.

I have selected Archimedean copula and successfully fitted  Frank and
Clayton copula. The problem is when trying to fit Gumbel copula.

The following are the codes I used to run in R.

# Data of 5 time series
A <- A
B <- B
C <- C
D <- D
E <- E

# Combined between A and C
A+C <- A + C

gumbel.copula <- gumbelCopula(dim = 5)
m <- pobs(as.matrix(cbind(A+C, B, D, E)))
fit.gumbel<- fitCopula(gumbel.copula, m, method = 'ml')

And the error while trying to fit gumbel copula:

Error in optim(start, loglikCopula, lower = lower, upper = upper, method =
method,  :
  non-finite finite-difference value [1]
In addition: Warning message:
In .local(copula, tau, ...) : tau is out of the range [0, 1]

Appreciate all help!

Many thanks,
Isaudin

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Tue Aug  9 16:42:30 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Tue, 9 Aug 2016 15:42:30 +0100
Subject: [R] BaseX
In-Reply-To: <trinity-b9f53935-42c3-4b6f-868d-1490827b31d8-1470746390842@3capp-gmx-bs76>
Message-ID: <20160809154230.Horde.ZqXzMpPOD8bPTwMgrPOSAkT@mail.sapo.pt>

Hello,

As for base 58 or base 62 I don't know, but for base 16 see  
?as.hexmode. See also ?strtoi.

Hope this helps,

Rui Barradas
?

Citando Ferri Leberl <ferri.leberl at gmx.at>:

> Dear everyone,
> Is there an R-command to change the expression of a number into  
> hexadecimal, base58 base62 or any other common encoding with a high  
> base of signs?
> Thank you in advance for your answers.
> Yours,
> Mag. Ferri Leberl
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From rmh at temple.edu  Tue Aug  9 17:49:35 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 9 Aug 2016 11:49:35 -0400
Subject: [R] BaseX
In-Reply-To: <20160809154230.Horde.ZqXzMpPOD8bPTwMgrPOSAkT@mail.sapo.pt>
References: <trinity-b9f53935-42c3-4b6f-868d-1490827b31d8-1470746390842@3capp-gmx-bs76>
	<20160809154230.Horde.ZqXzMpPOD8bPTwMgrPOSAkT@mail.sapo.pt>
Message-ID: <CAGx1TMC-giH7=cTFMdJRcvV99EZX-p_4+OSPEDdqHRO2Pibx9Q@mail.gmail.com>

The Rmpfr package handles base up to and including 62


> install.packages("Rmpfr")
> library(Rmpfr)
> ?mpfr
> ?formatMpfr
> formatMpfr(mpfr(1e6, precBits=53), base=62)
[1] "4C92.000000"
>

On Tue, Aug 9, 2016 at 10:42 AM,  <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> As for base 58 or base 62 I don't know, but for base 16 see
> ?as.hexmode. See also ?strtoi.
>
> Hope this helps,
>
> Rui Barradas
>
>
> Citando Ferri Leberl <ferri.leberl at gmx.at>:
>
>> Dear everyone,
>> Is there an R-command to change the expression of a number into
>> hexadecimal, base58 base62 or any other common encoding with a high
>> base of signs?
>> Thank you in advance for your answers.
>> Yours,
>> Mag. Ferri Leberl
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.htmland provide commented,
>> minimal, self-contained, reproducible code.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Tue Aug  9 18:45:18 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 9 Aug 2016 12:45:18 -0400
Subject: [R] BaseX
In-Reply-To: <CAGx1TMC-giH7=cTFMdJRcvV99EZX-p_4+OSPEDdqHRO2Pibx9Q@mail.gmail.com>
References: <trinity-b9f53935-42c3-4b6f-868d-1490827b31d8-1470746390842@3capp-gmx-bs76>
	<20160809154230.Horde.ZqXzMpPOD8bPTwMgrPOSAkT@mail.sapo.pt>
	<CAGx1TMC-giH7=cTFMdJRcvV99EZX-p_4+OSPEDdqHRO2Pibx9Q@mail.gmail.com>
Message-ID: <67ff8c37-1b95-e211-655c-90c31e7eb391@gmail.com>

On 09/08/2016 11:49 AM, Richard M. Heiberger wrote:
> The Rmpfr package handles base up to and including 62
>
>
> > install.packages("Rmpfr")
> > library(Rmpfr)
> > ?mpfr
> > ?formatMpfr
> > formatMpfr(mpfr(1e6, precBits=53), base=62)
> [1] "4C92.000000"
> >

Neat: it's quite striking that all "digits" are 12 or less -- I 
suspected an error at first.  But it's right:  sum(c(4, 12, 9, 
2)*62^(3:0)) is 1e6.

Duncan Murdoch
>
> On Tue, Aug 9, 2016 at 10:42 AM,  <ruipbarradas at sapo.pt> wrote:
> > Hello,
> >
> > As for base 58 or base 62 I don't know, but for base 16 see
> > ?as.hexmode. See also ?strtoi.
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> > Citando Ferri Leberl <ferri.leberl at gmx.at>:
> >
> >> Dear everyone,
> >> Is there an R-command to change the expression of a number into
> >> hexadecimal, base58 base62 or any other common encoding with a high
> >> base of signs?
> >> Thank you in advance for your answers.
> >> Yours,
> >> Mag. Ferri Leberl
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.htmland provide commented,
> >> minimal, self-contained, reproducible code.
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mstojovic at hotmail.co.uk  Tue Aug  9 20:04:12 2016
From: mstojovic at hotmail.co.uk (Marko Stojovic)
Date: Tue, 9 Aug 2016 18:04:12 +0000
Subject: [R] Residual plots and residual deviance in the SURVEY package when
 only 'working deviance' available
Message-ID: <HE1PR05MB14507F234F966770DF8A24BDEE1C0@HE1PR05MB1450.eurprd05.prod.outlook.com>

Hello -


I am analysing some survey data using the svyglm() command in the survey package. Since I am doing binomial regression, the family I'm choosing is 'quasibinomial', since this suppresses the warning that comes about from the inclusion of non-integer outcomes due to weights.


I am looking at doing some proper diagnostics of my model. However, the only goodness-of-fit method I can see from the mailing list is regtermtest(), which essentially tests the significance of additional terms, or the hypothesis that the model is better than the intercept.


My questions are:

- is it possible to obtain residual 'working' deviance after the Rao-Scott method, which would indicate deviance with respect to the saturated model?

- by way of corrollary (or substitute), can deviance residuals be obtained?

- given that svyglm appears to give the raw residuals through the residuals([svyglm object]) command, does anyone know of a good reference on how to effectively use pearson residuals for model diagnostics (on the basis that deviance ones are unavailable).


Many thanks.

Marko Stojovic

MSc Applied Statistics student, Birkbeck College, London

	[[alternative HTML version deleted]]


From choid at ohsu.edu  Tue Aug  9 22:05:14 2016
From: choid at ohsu.edu (Dongseok Choi)
Date: Tue, 9 Aug 2016 20:05:14 +0000
Subject: [R] R on Bash on Ubuntu on Windows 10
Message-ID: <8DA6CBAD72D8BE4C8E0059A022CD830D694E7BDC@EXMB07.ohsu.edu>

Hi all,

Now, one more interesting option seems to be possible with the recent Windows 10 anniversary update. I activated Bash on Ubuntu on Windows and then I could installed r-base and update to the latest version (3.3.0). I also MRO 3.3.0. So far, it is working good. I could install several packages from CRAN/MRAN/Bioconductor including ggplot2 and rgl. All examples I have tried so far seem to be working OK. Have anyone tried and test R under the new Bash on Ubuntu on Windows?

Dongseok


	[[alternative HTML version deleted]]


From lars52r at gmail.com  Wed Aug 10 01:35:44 2016
From: lars52r at gmail.com (Lars Bishop)
Date: Tue, 9 Aug 2016 19:35:44 -0400
Subject: [R] R Server - Resource Manager
Message-ID: <CAO7OmOhH8qEMTakbTCN2v2_Waxs3V5yZx--fCkEe07qxL2HJzg@mail.gmail.com>

Hi All,

I'd appreciate if you can point me to any good open source (and free)
Resource Manager for R installed on a unix server. Essentially, I'm looking
to have the ability to selectively allocate computational resources to
individuals or groups who have access to this server.

I understand R Studio Server Pro and MS R Server have this capability but
they are not free. I'm looking for a free equivalent if available.

Thank you,

Lars.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Aug 10 02:09:34 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 09 Aug 2016 17:09:34 -0700
Subject: [R] R Server - Resource Manager
In-Reply-To: <CAO7OmOhH8qEMTakbTCN2v2_Waxs3V5yZx--fCkEe07qxL2HJzg@mail.gmail.com>
References: <CAO7OmOhH8qEMTakbTCN2v2_Waxs3V5yZx--fCkEe07qxL2HJzg@mail.gmail.com>
Message-ID: <ECD107A1-4072-436F-9077-48642B801664@dcn.davis.ca.us>

This service is normally implemented by the operating system against the logins, irrespective of the application those users choose to use. It is not part of R... so you should be looking for OS tools not R tools. 
-- 
Sent from my phone. Please excuse my brevity.

On August 9, 2016 4:35:44 PM PDT, Lars Bishop <lars52r at gmail.com> wrote:
>Hi All,
>
>I'd appreciate if you can point me to any good open source (and free)
>Resource Manager for R installed on a unix server. Essentially, I'm
>looking
>to have the ability to selectively allocate computational resources to
>individuals or groups who have access to this server.
>
>I understand R Studio Server Pro and MS R Server have this capability
>but
>they are not free. I'm looking for a free equivalent if available.
>
>Thank you,
>
>Lars.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mailund at birc.au.dk  Tue Aug  9 21:57:05 2016
From: mailund at birc.au.dk (Thomas Mailund)
Date: Tue, 9 Aug 2016 19:57:05 +0000
Subject: [R] Continuation-parsing / trampoline / infinite recursion problem
Message-ID: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>

[I?m really sorry if you receive this mail twice. I just noticed I had sent it from a different account that the one I signed up to the mailing list on and I don?t know if that means it will be filtered; at least I haven?t received it myself yet.]


I am playing around with continuation-passing style recursions and want to use the trampoline approach to avoiding too deep recursions. I want to do recursions on a tree so I cannot simply simulate a tail-recursion with a loop and need something else, and rather than simulating my own stack I want to use the method that solves this in general.

I cannot seem to get out of problems with the

  Error: evaluation nested too deeply: infinite recursion / options(expressions=)?
  Error during wrapup: evaluation nested too deeply: infinite recursion / options(expressions=)?

error, so I reduced the problem to just computing factorials to see if I could at least get it to work there, but here I get the problem as well, and in the example below I am completely stumped as to why.

trampoline <- function(thunk) {
    while (is.function(thunk)) thunk <- thunk()
    thunk
}

thunk_factorial <- function(n, continuation = identity, acc = 1) {
    force(continuation) # if I remove this line I get an error
    cat("call: ", n, " : ", acc, "\n") # same for this line
    if (n == 1) {
        continuation(acc)
    } else {
        make_thunk(thunk_factorial, n - 1, continuation, n * acc)
    }
}
trampoline(thunk_factorial(10000))

This version works for me. If I remove the ?force(continuation)? it doesn?t ? even though I never modify the contination in this function (in the tree I want to do recursion on I will have to). I get all the way down the simulated recursion to the final call of the continuation and then I get the error. So as far as I would expect I should just get the identity of the final accumulator at the end, but instead I get the error.

If I remove the cat-call I also get the error. That *really* puzzles me. What is cat doing that lets me complete the function when it is involved but not when I comment out that line?

There is clearly something about this infinite recursion error I am completely missing. Any help would be greatly appreciated.

Cheers
Thomas


	[[alternative HTML version deleted]]


From sriram at navgathi.com  Wed Aug 10 06:58:10 2016
From: sriram at navgathi.com (Sriram Kumar)
Date: Wed, 10 Aug 2016 10:28:10 +0530
Subject: [R] Calendar embedded for event scheduling
Message-ID: <CAKXaSfrbWXGL7z3TSht_7ag8s-RUTX4cg+=wbjDd+5uODL+sSA@mail.gmail.com>

Dear all,

 i am presently doing the r codes for developing  the shiny app fro my
professional ,i need to add the calendar for event scheduling and marking
the different in different color .i search a lot for doing so but still i
didn't get any idea so far. please any expect help to get out of this . its
very important and urgent .


Thank you

Warm Regards,

*SRI RAM KUMAR K *
* Naval Architect*



*Navgathi Marine Design & Constructions Pvt Ltd*

 0484-6492607
 +918891425212
sriram at navgathi.com <alby at navgathi.com>
 www.navgathi.com
 III/131, North Kalamassery, Kochi, India 683104

P *Please consider the environment before printing this e-mail.*

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Aug 10 08:05:01 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 10 Aug 2016 16:05:01 +1000
Subject: [R] Calendar embedded for event scheduling
In-Reply-To: <CAKXaSfrbWXGL7z3TSht_7ag8s-RUTX4cg+=wbjDd+5uODL+sSA@mail.gmail.com>
References: <CAKXaSfrbWXGL7z3TSht_7ag8s-RUTX4cg+=wbjDd+5uODL+sSA@mail.gmail.com>
Message-ID: <CA+8X3fXEeZFZpnyCOJCR1Q=L=AbNu6hvuTtEXapBUXsn2h7YxA@mail.gmail.com>

Hi Sri Ram,
Do you mean that you want to produce a Gantt chart? Have a look at the
example for gantt.chart in the plotrix package.

Jim


On Wed, Aug 10, 2016 at 2:58 PM, Sriram Kumar <sriram at navgathi.com> wrote:
> Dear all,
>
>  i am presently doing the r codes for developing  the shiny app fro my
> professional ,i need to add the calendar for event scheduling and marking
> the different in different color .i search a lot for doing so but still i
> didn't get any idea so far. please any expect help to get out of this . its
> very important and urgent .
>
>
> Thank you
>
> Warm Regards,
>
> *SRI RAM KUMAR K *
> * Naval Architect*
>
>
>
> *Navgathi Marine Design & Constructions Pvt Ltd*
>
>  0484-6492607
>  +918891425212
> sriram at navgathi.com <alby at navgathi.com>
>  www.navgathi.com
>  III/131, North Kalamassery, Kochi, India 683104
>
> P *Please consider the environment before printing this e-mail.*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maechler at stat.math.ethz.ch  Wed Aug 10 09:59:17 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 10 Aug 2016 09:59:17 +0200
Subject: [R] Diethelm Wuertz (founder 'Rmetrics')
Message-ID: <20160810075917.F1B971A75DF@lynne.stat.math.ethz.ch>

Dear colleagues

We are deeply saddened to inform you that Diethelm and his wife Barbara W?rtz
(ascii-fied 'Wuertz') died in a car accident during their vacation in
Hungary last week. 

Both, Diethelm and Barbara worked at the ETH Zurich,
Diethelm as a researcher and teacher in the Institute for Theoretical
Physics and Barbara as an advisor in the Human Resources division.

In the "R world", Diethelm has been known as an enthousiastic
entrepreneur, having built the "Rmetrics" project (http://www.rmetrics.org) 
quite early in the history of R.  He organized much-liked
workshops / summer schools about "R in Finance" at Meielisalp in
the Swiss mountains, and in cities such as Zurich, Paris or Mumbay. 

Many of us have known Barbara and Diethelm as generous and amiable people
who've enjoyed hosting others both at such workshops or privately.
They leave their son, Fabian, and their daughter-in-law Viktoria.
Our thoughts are with them. 

Sincerely,

Martin Maechler, ETH Zurich (Seminar for Statistics)
Adrian Trapletti, Uster Metrics


From sriram at navgathi.com  Wed Aug 10 08:45:13 2016
From: sriram at navgathi.com (Sriram Kumar)
Date: Wed, 10 Aug 2016 12:15:13 +0530
Subject: [R] Calendar embedded for event scheduling
In-Reply-To: <CA+8X3fXEeZFZpnyCOJCR1Q=L=AbNu6hvuTtEXapBUXsn2h7YxA@mail.gmail.com>
References: <CAKXaSfrbWXGL7z3TSht_7ag8s-RUTX4cg+=wbjDd+5uODL+sSA@mail.gmail.com>
	<CA+8X3fXEeZFZpnyCOJCR1Q=L=AbNu6hvuTtEXapBUXsn2h7YxA@mail.gmail.com>
Message-ID: <CAKXaSfo5+hPTMNr_qOz_b6by6y+RfVu_5n9ipUs1HBtyWn2yzw@mail.gmail.com>

Dear jim ,

          Thanks jim lemon  for your reply but i need a calendar for
marking my event for a period or for a day  not the gantt chart  because
the calendar event means can also  update by user .and view by anyone but
not in gantt chart..please can you provide any widgets or any other way to
do that.i already wasted a lot of man hour time on this .

On Wed, Aug 10, 2016 at 11:35 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Sri Ram,
> Do you mean that you want to produce a Gantt chart? Have a look at the
> example for gantt.chart in the plotrix package.
>
> Jim
>
>
> On Wed, Aug 10, 2016 at 2:58 PM, Sriram Kumar <sriram at navgathi.com> wrote:
> > Dear all,
> >
> >  i am presently doing the r codes for developing  the shiny app fro my
> > professional ,i need to add the calendar for event scheduling and marking
> > the different in different color .i search a lot for doing so but still i
> > didn't get any idea so far. please any expect help to get out of this .
> its
> > very important and urgent .
> >
> >
> > Thank you
> >
> > Warm Regards,
> >
> > *SRI RAM KUMAR K *
> > * Naval Architect*
> >
> >
> >
> > *Navgathi Marine Design & Constructions Pvt Ltd*
> >
> >  0484-6492607
> >  +918891425212
> > sriram at navgathi.com <alby at navgathi.com>
> >  www.navgathi.com
> >  III/131, North Kalamassery, Kochi, India 683104
> >
> > P *Please consider the environment before printing this e-mail.*
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 

Warm Regards,

*SRI RAM KUMAR K *
* Naval Architect*



*Navgathi Marine Design & Constructions Pvt Ltd*

 0484-6492607
 +918891425212
sriram at navgathi.com <alby at navgathi.com>
 www.navgathi.com
 III/131, North Kalamassery, Kochi, India 683104

P *Please consider the environment before printing this e-mail.*

	[[alternative HTML version deleted]]


From marco.scutari at gmail.com  Wed Aug 10 10:35:27 2016
From: marco.scutari at gmail.com (Marco Scutari)
Date: Wed, 10 Aug 2016 09:35:27 +0100
Subject: [R] cpquery problem
In-Reply-To: <ef9b32ac28ea74e69d194bd5865a628a.squirrel@ecogeonomix.com>
References: <9a0d19b8a05d0ae5c8676569bbfe96d2.squirrel@ecogeonomix.com>
	<CA+RJqXUqPN+X+XZ75h_WUUn8taswHp1GwThkwn-j3e9wcpyqGA@mail.gmail.com>
	<ef9b32ac28ea74e69d194bd5865a628a.squirrel@ecogeonomix.com>
Message-ID: <CA+RJqXWOFZh5oj14edqwOdjHuOug2A76VjvWArz7T4NTXWaBYg@mail.gmail.com>

Hi Ross,

On 4 August 2016 at 09:37, Ross Chapman <ross.chapman at ecogeonomix.com> wrote:
> The network that I am working on has the following coefficients for the
> node that I am interested in (ABW):
>
>   Parameters of node ABW (conditional Gaussian distribution)
>
> Conditional density: ABW | EST + TR + FFB + RF
> Coefficients:
>                         0             1             2
> (Intercept)  -0.480612729 -5.834617332   0.809011487
> TR       1.857271045   1.584331230   1.964198638
> FFB    0.182533645   0.066891147   0.028620951
> RF     -0.002822838   0.002155205  -0.001608243
>
> Standard deviation of the residuals:
>         0          1          2
> 1.5140402  1.1764351  0.9675918
> Discrete parents' configurations:
>      EST
> 0     K1
> 1     M1
> 2     M2

This puzzles me: EST can take values "K1", "M1" and "M2", so why did
your original query have EST == "y"? That does not seem to be a valid
value.

> However, running cpquery() using the values for this test case returns a
> conditional probability of 0 for all levels of ABW observed in the training
> data.

> Why does cpquery not return a high conditional probability for an event
> which is predicted from the same coefficients?

predict() performs a maximum a posteriori prediction conditional on
all the variables in the data, while your query only conditions on 3-4
variables; it is not surprising that results may differ. Conditioning
on he whole Markov blanket of the variable you are predicting should
give you results that are more comparable.

Also, you should consider that with if you substitute the values you
are conditioning on in your query in the regression equations you
showed above, I get an average an average of ~= 13 without considering
FFB. If I assume FFB is positive, then I can easily see E(y) ~= 15 and
E(y) - 1.96 * 0.96 s.d. ~= 13.5. So ABW < 11 has zero or almost zero
probability mass.

Cheers,
    Marco

-- 
Marco Scutari, Ph.D.
Lecturer in Statistics, Department of Statistics
University of Oxford, United Kingdom


From abhinabaroy09 at gmail.com  Wed Aug 10 11:22:53 2016
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Wed, 10 Aug 2016 14:52:53 +0530
Subject: [R] Calculate mileage at each 'faildate'
Message-ID: <CANtKHPUadWAL_F=hba_7TKgHK4b0_doYcwcKL_qb3fx549LsrA@mail.gmail.com>

Hi R-helpers,


   - I have a dataframe similar to 'simD'.

> dput(simD)
structure(list(ID = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
2L, 2L), .Label = c("A", "B"), class = "factor"), PRODDATE =
structure(c(14655,
14655, 14655, 14655, 14664, 14664, 14664, 14664, 14664, 14664
), class = "Date"), FAILDATE = structure(c(15053, 15054, 15057,
15058, 14844, 14875, 14876, 14905, 14936, 14966), class = "Date"),
    MILEAGE = c(21548L, 22578L, 22868L, 23654L, 30245L, 32148L,
    34128L, 35879L, 39874L, 40125L)), .Names = c("ID", "PRODDATE",
"FAILDATE", "MILEAGE"), row.names = c(NA, -10L), class = "data.frame")


   - I have split the dataset by 'ID' and sorted the dataframe by
   'faildate' (oldest to newest).



   - Now, for each of the splits I want to calculate the 'Mileage' at each
   of the 'faildate'.



   - The output I desire is 'outD'.


> dput(outD)
structure(list(ID = structure(1:2, .Label = c("A", "B"), class = "factor"),
    PRODDATE = structure(c(14655, 14664), class = "Date"), MIL_1 =
c(21548L,
    30245L), MIL_2 = c(1030L, 1903L), MIL_3 = c(290L, 1980L),
    MIL_4 = c(786L, 1751L), MIL_5 = c(NA, 3995L), MIL_6 = c(NA,
    251L)), .Names = c("ID", "PRODDATE", "MIL_1", "MIL_2", "MIL_3",
"MIL_4", "MIL_5", "MIL_6"), row.names = c(NA, -2L), class = "data.frame")

***Please note that I have MIL_6 because the max(# failures) in data by ID
is 6 (6 failures for 'B')*


   - And I would like to extend it to other numeric and date variable as
   well.


How can I do this in R?

Best,
Abhinaba

	[[alternative HTML version deleted]]


From spencer.graves at effectivedefense.org  Wed Aug 10 12:03:53 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Wed, 10 Aug 2016 05:03:53 -0500
Subject: [R] Diethelm Wuertz (founder 'Rmetrics')
In-Reply-To: <20160810075917.F1B971A75DF@lynne.stat.math.ethz.ch>
References: <20160810075917.F1B971A75DF@lynne.stat.math.ethz.ch>
Message-ID: <f03a1f5b-9b7e-35ea-3778-b5967f09009f@effectivedefense.org>

       Diethelm and Barbara very generously invited me into their home 
after I had contacted Diethelm asking about Rmetrics prior to visiting 
Z?rich years ago.  I agree with Martin.  His legacy will live on via the 
Rmetrics code and companion books.  I don't know if anyone else will be 
able to take over maintaining and extended or if future workshops / 
summer schools will continue to attract an audience.


       Spencer


On 8/10/2016 2:59 AM, Martin Maechler wrote:
> Dear colleagues
>
> We are deeply saddened to inform you that Diethelm and his wife Barbara W?rtz
> (ascii-fied 'Wuertz') died in a car accident during their vacation in
> Hungary last week.
>
> Both, Diethelm and Barbara worked at the ETH Zurich,
> Diethelm as a researcher and teacher in the Institute for Theoretical
> Physics and Barbara as an advisor in the Human Resources division.
>
> In the "R world", Diethelm has been known as an enthousiastic
> entrepreneur, having built the "Rmetrics" project (http://www.rmetrics.org)
> quite early in the history of R.  He organized much-liked
> workshops / summer schools about "R in Finance" at Meielisalp in
> the Swiss mountains, and in cities such as Zurich, Paris or Mumbay.
>
> Many of us have known Barbara and Diethelm as generous and amiable people
> who've enjoyed hosting others both at such workshops or privately.
> They leave their son, Fabian, and their daughter-in-law Viktoria.
> Our thoughts are with them.
>
> Sincerely,
>
> Martin Maechler, ETH Zurich (Seminar for Statistics)
> Adrian Trapletti, Uster Metrics
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Wed Aug 10 12:07:04 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 10 Aug 2016 10:07:04 +0000
Subject: [R] Calculate mileage at each 'faildate'
In-Reply-To: <CANtKHPUadWAL_F=hba_7TKgHK4b0_doYcwcKL_qb3fx549LsrA@mail.gmail.com>
References: <CANtKHPUadWAL_F=hba_7TKgHK4b0_doYcwcKL_qb3fx549LsrA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5038C57@SRVEXCHMBX.precheza.cz>

Hi

I wonder what do you want to do with intended output. You can get required numbers by

lll <- split(simD, simD$ID)
lapply(lll, function(x) c(min(x[, "MILEAGE"]), diff(x[,"MILEAGE"])))

$A
[1] 21548  1030   290   786

$B
[1] 30245  1903  1980  1751  3995   251

Then pad it with NA

max.l<-max(sapply(res, length))
res2<-lapply(res, function(x) c(x, rep(NA, max.l-length(x))))

$A
[1] 21548  1030   290   786    NA    NA

$B
[1] 30245  1903  1980  1751  3995   251

> t(as.data.frame(res2))
   [,1] [,2] [,3] [,4] [,5] [,6]
A 21548 1030  290  786   NA   NA
B 30245 1903 1980 1751 3995  251
>

After that you should combine it with required values from first data frame and of course you need to name new columns e.g. by loop.

If you had it as a list you could work with it easily by R functions or convert it back to your data frame

> library (plyr)
data.frame(ldply(lll, data.frame), fMileage=unlist(res))
   .id ID   PRODDATE   FAILDATE MILEAGE fMileage
A1   A  A 2010-02-15 2011-03-20   21548    21548
A2   A  A 2010-02-15 2011-03-21   22578     1030
A3   A  A 2010-02-15 2011-03-24   22868      290
A4   A  A 2010-02-15 2011-03-25   23654      786
B1   B  B 2010-02-24 2010-08-23   30245    30245
B2   B  B 2010-02-24 2010-09-23   32148     1903
B3   B  B 2010-02-24 2010-09-24   34128     1980
B4   B  B 2010-02-24 2010-10-23   35879     1751
B5   B  B 2010-02-24 2010-11-23   39874     3995
B6   B  B 2010-02-24 2010-12-23   40125      251

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Abhinaba
> Roy
> Sent: Wednesday, August 10, 2016 11:23 AM
> To: r-help <r-help at r-project.org>
> Subject: [R] Calculate mileage at each 'faildate'
>
> Hi R-helpers,
>
>
>    - I have a dataframe similar to 'simD'.
>
> > dput(simD)
> structure(list(ID = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L), .Label =
> c("A", "B"), class = "factor"), PRODDATE = structure(c(14655, 14655, 14655,
> 14655, 14664, 14664, 14664, 14664, 14664, 14664 ), class = "Date"), FAILDATE =
> structure(c(15053, 15054, 15057, 15058, 14844, 14875, 14876, 14905, 14936,
> 14966), class = "Date"),
>     MILEAGE = c(21548L, 22578L, 22868L, 23654L, 30245L, 32148L,
>     34128L, 35879L, 39874L, 40125L)), .Names = c("ID", "PRODDATE",
> "FAILDATE", "MILEAGE"), row.names = c(NA, -10L), class = "data.frame")
>
>
>    - I have split the dataset by 'ID' and sorted the dataframe by
>    'faildate' (oldest to newest).
>
>
>
>    - Now, for each of the splits I want to calculate the 'Mileage' at each
>    of the 'faildate'.
>
>
>
>    - The output I desire is 'outD'.
>
>
> > dput(outD)
> structure(list(ID = structure(1:2, .Label = c("A", "B"), class = "factor"),
>     PRODDATE = structure(c(14655, 14664), class = "Date"), MIL_1 = c(21548L,
>     30245L), MIL_2 = c(1030L, 1903L), MIL_3 = c(290L, 1980L),
>     MIL_4 = c(786L, 1751L), MIL_5 = c(NA, 3995L), MIL_6 = c(NA,
>     251L)), .Names = c("ID", "PRODDATE", "MIL_1", "MIL_2", "MIL_3",
> "MIL_4", "MIL_5", "MIL_6"), row.names = c(NA, -2L), class = "data.frame")
>
> ***Please note that I have MIL_6 because the max(# failures) in data by ID is
> 6 (6 failures for 'B')*
>
>
>    - And I would like to extend it to other numeric and date variable as
>    well.
>
>
> How can I do this in R?
>
> Best,
> Abhinaba
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From adriens_cachan at yahoo.fr  Wed Aug 10 14:52:16 2016
From: adriens_cachan at yahoo.fr (BONACHE Adrien)
Date: Wed, 10 Aug 2016 12:52:16 +0000 (UTC)
Subject: [R] funnel plot asymmetry
In-Reply-To: <CAFZWObLfi7BBceyuDUnR_fbmNx5y-U2K_ChxdEmuSVMaSYdmyg@mail.gmail.com>
References: <CAFZWObLfi7BBceyuDUnR_fbmNx5y-U2K_ChxdEmuSVMaSYdmyg@mail.gmail.com>
Message-ID: <545222235.20867462.1470833536480.JavaMail.yahoo@mail.yahoo.com>

Dear Christos,
Maybe you should read it before using Egger's test : http://www.cienciasinseso.com/en/tag/eggers-test/If you still want to perform Egger's test, use metafor : R: Test for funnel plot asymmetry

| ? |
| ? | ? | ? | ? | ? |
| R: Test for funnel plot asymmetrymetabias.meta {meta} R Documentation Test for funnel plot asymmetry Description Test for funnel plot asymmetry, based on rank correlation or linearregression method. Usage  |
|  |
| Afficher sur artax.karlin.mff.cuni.cz | Aper?u par Yahoo |
|  |
| ? |


Kind regards,
Adrien.

      De?: christos tb <tb.christos at gmail.com>
 ??: r-help at r-project.org 
 Envoy? le : Lundi 1 ao?t 2016 9h08
 Objet?: [R] funnel plot asymmetry
   
Hi, I am conducting a meta analysis of continuous data and I cant find the
code to curry out Egger?s test, for testing the funnel plot asymmetry.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Wed Aug 10 18:08:03 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 10 Aug 2016 18:08:03 +0200
Subject: [R] Error while fitting gumbel copula
In-Reply-To: <CAE1aWa_AJRovvq9sZU2LWA3VaBCWAC_mxLoK4L7kzy=HkjgEHQ@mail.gmail.com>
References: <CAE1aWa_AJRovvq9sZU2LWA3VaBCWAC_mxLoK4L7kzy=HkjgEHQ@mail.gmail.com>
Message-ID: <22443.20835.731336.772515@stat.math.ethz.ch>

>>>>> Isaudin Ismail <isaudin at gmail.com>
>>>>>     on Tue, 9 Aug 2016 14:30:18 +0100 writes:

    > Dear R experts,
    > I have 5 time series of data (A, B, C, D and E) with all same lengths. All
    > series exhibit gamma distribution except for B which is lognormal
    > distribution. I am using copula package to model the joint-distribution of
    > these 5 times series.

    > I have selected Archimedean copula and successfully fitted  Frank and
    > Clayton copula. The problem is when trying to fit Gumbel copula.

    > The following are the codes I used to run in R.

    > # Data of 5 time series

    > A <- A
    > B <- B
    > C <- C
    > D <- D
    > E <- E

well, the above is really an "interesting" block of R code ;-)

--

More seriously, please learn to use reproducible examples,
e.g., from here
  http://bit.ly/MRE_R (nice to remember: MRE = Minimal Reproducible Example)
or here
  http://adv-r.had.co.nz/Reproducibility.html

then we will be glad to help you,
notably I as maintainer of the package 'copula' which you are
using (without saying so).

With regards,
Martin Maechler


    > # Combined between A and C
    > A+C <- A + C

    > gumbel.copula <- gumbelCopula(dim = 5)
    > m <- pobs(as.matrix(cbind(A+C, B, D, E)))
    > fit.gumbel<- fitCopula(gumbel.copula, m, method = 'ml')

    > And the error while trying to fit gumbel copula:

    > Error in optim(start, loglikCopula, lower = lower, upper = upper, method =
    > method,  :
    > non-finite finite-difference value [1]
    > In addition: Warning message:
    > In .local(copula, tau, ...) : tau is out of the range [0, 1]

    > Appreciate all help!

    > Many thanks,
    > Isaudin

    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From dom at inik.ch  Wed Aug 10 12:22:05 2016
From: dom at inik.ch (Dominik Marti)
Date: Wed, 10 Aug 2016 12:22:05 +0200
Subject: [R] Proving (instead of rejecting) that two groups are actually
	equal
Message-ID: <e83eda53861416cbe08d8e1cf29c9535@drine.ch>

Hej R helpers

The standard in statistical hypothesis testing is to reject the null 
hypothesis that there is a difference between groups, i.e. to "prove" 
the alternative. However, failing to reject the null hypothesis does not 
prove it; its rejection just fails.

Now, as stated in the article "Unicorns do exist: a tutorial on 
"proving" the null hypothesis." by David L Streiner (Canadian Journal of 
Psychiatry, 48(11) 2003), we can define the null hypothesis to be that 
there IS a difference (exceeding a certain value, delta), the 
alternative hypothesis being that there is none (or it is at least 
smaller than delta). If the data now manages to reject the null 
hypothesis (of there being a difference exceeding delta), we can say 
with a certain probability that there is none.

Can I do this test in R? And if yes, any leads?

(In my actual dataset I deal with paired data.)

Best
    Dominik


From mailund at birc.au.dk  Wed Aug 10 13:56:19 2016
From: mailund at birc.au.dk (Thomas Mailund)
Date: Wed, 10 Aug 2016 11:56:19 +0000
Subject: [R] Continuation-parsing / trampoline / infinite recursion
	problem
In-Reply-To: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>
References: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>
Message-ID: <etPan.57ab1663.496f94a7.13177@birc.au.dk>

?
Oh, I see that the make_thunk function is missing in my example. It is just this one

make_thunk <- function(f, ...) f(...)  



On 9 August 2016 at 21:57:05, Thomas Mailund (mailund at birc.au.dk(mailto:mailund at birc.au.dk)) wrote:

> [I?m really sorry if you receive this mail twice. I just noticed I had sent it from a different account that the one I signed up to the mailing list on and I don?t know if that means it will be filtered; at least I haven?t received it myself yet.]
>  
>  
> I am playing around with continuation-passing style recursions and want to use the trampoline approach to avoiding too deep recursions. I want to do recursions on a tree so I cannot simply simulate a tail-recursion with a loop and need something else, and rather than simulating my own stack I want to use the method that solves this in general.  
>  
> I cannot seem to get out of problems with the  
>  
> Error: evaluation nested too deeply: infinite recursion / options(expressions=)?  
> Error during wrapup: evaluation nested too deeply: infinite recursion / options(expressions=)?  
>  
> error, so I reduced the problem to just computing factorials to see if I could at least get it to work there, but here I get the problem as well, and in the example below I am completely stumped as to why.  
>  
> trampoline <- function(thunk) {  
> while (is.function(thunk)) thunk <- thunk()  
> thunk  
> }  
>  
> thunk_factorial <- function(n, continuation = identity, acc = 1) {  
> force(continuation) # if I remove this line I get an error  
> cat("call: ", n, " : ", acc, "\n") # same for this line  
> if (n == 1) {  
> continuation(acc)  
> } else {  
> make_thunk(thunk_factorial, n - 1, continuation, n * acc)  
> }  
> }  
> trampoline(thunk_factorial(10000))  
>  
> This version works for me. If I remove the ?force(continuation)? it doesn?t ? even though I never modify the contination in this function (in the tree I want to do recursion on I will have to). I get all the way down the simulated recursion to the final call of the continuation and then I get the error. So as far as I would expect I should just get the identity of the final accumulator at the end, but instead I get the error.  
>  
> If I remove the cat-call I also get the error. That *really* puzzles me. What is cat doing that lets me complete the function when it is involved but not when I comment out that line?  
>  
> There is clearly something about this infinite recursion error I am completely missing. Any help would be greatly appreciated.  
>  
> Cheers  
> Thomas  
>  

From martiv at qio.uji.es  Wed Aug 10 16:00:04 2016
From: martiv at qio.uji.es (=?UTF-8?Q?Vicente_Mart=C3=AD_Centelles?=)
Date: Wed, 10 Aug 2016 15:00:04 +0100
Subject: [R] It is possible to use "input parameters" with "standard
 error" in fitting function nls
In-Reply-To: <CAEcPzfBs-2d7rEjQ+v3CF2-1FZQA9wkSnQ9tL2F9M91ygfBEGA@mail.gmail.com>
References: <CAEcPzfBs-2d7rEjQ+v3CF2-1FZQA9wkSnQ9tL2F9M91ygfBEGA@mail.gmail.com>
Message-ID: <CAEcPzfCwPtnYeJnS3C-dABf6zCdHG6OF_fDqwzPiFfKB+kr-7w@mail.gmail.com>

Dear all,

I found the solution to my question on internet:

https://www.r-bloggers.com/introducing-propagate/

The ?propagate? package on CRAN can do this It has one single purpose:
propagation of uncertainties (?error propagation?).

predictNLS: The propagate function is used to calculate the propagated
error to the fitted values of a nonlinear model of type nls or nlsLM.
Please refer to my post here:
http://rmazing.wordpress.com/2013/08/26/predictnls-part-2-taylor-approximation-confidence-intervals-for-nls-models/
.

Best regards

Vicente

2016-08-03 9:57 GMT+01:00 Vicente Mart? Centelles <martiv at qio.uji.es>:

>
> Dear all,
>
> I would like to introduce an input parameter with an associated standard
> error to perform a fitting using the nls function (or any similar function):
>
> parameter1 = 9.00 +/- 0.20  (parameter 1 has a value of 9.00 and standard
> error of 0.20)
>
> fittingResults <- nls(y ~ function(xdata, ydata, parameter1,
> fittingparameter),start=list(parameter1=9.00, fittingparameter=5.00))
> summary(fittingResults)
>
> Does anyone know how to  introduce the associated standard error of the
> parameter to the fitting function?
>
> Many thanks for your help,
>
> Best regards
>
> Vicente
>
>
> --
> _______________________________________
> *Dr. Vicente Mart? Centelles*
> *Postdoctoral Researcher (VALi+d Generalitat Valenciana, Spain)*
>
>
> *Universitat Jaume I*Departamento de Qu?mica Inorg?nica y Org?nica
> Avda Sos Baynat s/n
> E-12071-Castell?n (Spain)
> Tel.: +34 964728235
> Fax: +34 964728214
> e-mail: martiv at qio.uji.es
>
> *web page*: www.vmarti.es
>



-- 
_______________________________________
*Dr. Vicente Mart? Centelles*
*Postdoctoral Researcher (VALi+d Generalitat Valenciana, Spain)*


*Universitat Jaume I*Departamento de Qu?mica Inorg?nica y Org?nica
Avda Sos Baynat s/n
E-12071-Castell?n (Spain)
Tel.: +34 964728235
Fax: +34 964728214
e-mail: martiv at qio.uji.es

*web page*: www.vmarti.es

	[[alternative HTML version deleted]]


From mailund at birc.au.dk  Wed Aug 10 18:53:29 2016
From: mailund at birc.au.dk (Thomas Mailund)
Date: Wed, 10 Aug 2016 16:53:29 +0000
Subject: [R] Continuation-parsing / trampoline / infinite
	recursion	problem
In-Reply-To: <etPan.57ab1663.496f94a7.13177@birc.au.dk>
References: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>
	<etPan.57ab1663.496f94a7.13177@birc.au.dk>
Message-ID: <0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>


> On 10 Aug 2016, at 13:56, Thomas Mailund <mailund at birc.au.dk> wrote:
> 
> make_thunk <- function(f, ...) f(...)  

Doh!  It is of course this one:

make_thunk <- function(f, ...) function() f(?)

It just binds a function call into a thunk so I can delay its evaluation.

Sorry
	Thomas




From mailund at birc.au.dk  Wed Aug 10 18:59:20 2016
From: mailund at birc.au.dk (Thomas Mailund)
Date: Wed, 10 Aug 2016 16:59:20 +0000
Subject: [R] Continuation-parsing / trampoline /
	infinite	recursion	problem
In-Reply-To: <0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>
References: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>
	<etPan.57ab1663.496f94a7.13177@birc.au.dk>
	<0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>
Message-ID: <7E95FFD1-0C40-4C13-B932-9EA0001BE413@birc.au.dk>

An alternative implementation, closer to what I need when I have more than one recursion in each step, but still using factorial as the example, is this one:

thunk_factorial <- function(n, continuation = identity) {
  force(continuation) # if I remove this line I get an error
  cat("call: ", n, "\n") # same for this line
  if (n == 1) {
    continuation(1)
  } else {
    new_continuation <- function(result) {
      cat("thunk: ", result, "\n?) # remove this line and it fails, keep it and it works
      make_thunk(continuation, n * result)
    }
    make_thunk(thunk_factorial, n - 1, new_continuation)
  }
}
trampoline(thunk_factorial(10000))

Here I am making a continuation instead of passing along an accumulator, which I need to do for more complex cases, and with that continuation I can also get it to complete without errors if I output the text inside it. Removing the `cat` line and I get the recursion error?

Cheers
	Thomas



> On 10 Aug 2016, at 18:53, Thomas Mailund <mailund at birc.au.dk> wrote:
> 
> 
>> On 10 Aug 2016, at 13:56, Thomas Mailund <mailund at birc.au.dk> wrote:
>> 
>> make_thunk <- function(f, ...) f(...)  
> 
> Doh!  It is of course this one:
> 
> make_thunk <- function(f, ...) function() f(?)
> 
> It just binds a function call into a thunk so I can delay its evaluation.
> 
> Sorry
> 	Thomas
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mike at hsm.org.uk  Wed Aug 10 19:00:48 2016
From: mike at hsm.org.uk (Mike Smith)
Date: Wed, 10 Aug 2016 18:00:48 +0100
Subject: [R] TIF Mean pixel values
Message-ID: <1852953389.20160810180048@hsm.org.uk>

Hi 

Im experimenting with mean pixel values for a series of images from a DSLR. I import 16-bit TIFs (RGB) from a directory using the following code, then loop through adding each TIF before dividing by the total number of files to give an image of mean pixel values. Some quick questions:

-having checked pixel values, this does what I expect it to do in that it creates the mean for each RGB layer in each image. It is pretty quick, but is a function that calculates both the mean and median pixel values for stacked layers like this?

-do all the calculations take place in 32 bit space? The tiff package lets me export as 16 bit tiffs, but is there anything that supports 32 bit tiffs??

-I get the following writeTIFF error (and the number has been scaled from the original 16 bit to 0-1):
"The input contains values outside the [0, 1] range - storage of such values is undefined"

-is there a more elegant/memory efficient way of doing this?!

Any help much appreciated!

best wishes


mike

PS Two sample images here:
http://www.hsm.org.uk/1.tif
http://www.hsm.org.uk/2.tif 

#Scan directory and store filenames in string, then count total files
files <- as.character(list.files(path="./mean/input/"))
n <- length(files)

#Use first TIF as loop file, then add all together
m_image_tiff <- readTIFF(paste("./mean/input/",files[1],sep=""))
for (i in 2:n){
  test<-paste("./mean/input/",files[i],sep="")
  tiff <- readTIFF(paste("./mean/input/",files[i],sep=""))
  m_image_tiff <- (tiff+m_image_tiff)
}

#Calculate mean and write TIF
m_image_tiff <- (m_image_tiff/n)
writeTIFF(m_image_tiff,"./mean/mean_tiff.tif",bits.per.sample=16L)
---
Mike Smith


From murdoch.duncan at gmail.com  Wed Aug 10 19:04:17 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 10 Aug 2016 13:04:17 -0400
Subject: [R] Continuation-parsing / trampoline / infinite recursion
 problem
In-Reply-To: <0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>
References: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>
	<etPan.57ab1663.496f94a7.13177@birc.au.dk>
	<0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>
Message-ID: <bc6c569e-32c2-eea5-f291-de13344b96d8@gmail.com>

On 10/08/2016 12:53 PM, Thomas Mailund wrote:
> > On 10 Aug 2016, at 13:56, Thomas Mailund <mailund at birc.au.dk> wrote:
> >
> > make_thunk <- function(f, ...) f(...)
>
> Doh!  It is of course this one:
>
> make_thunk <- function(f, ...) function() f(?)
>
> It just binds a function call into a thunk so I can delay its evaluation.

I haven't looked closely at the full set of functions, but this comment:

force(continuation) # if I remove this line I get an error

makes it sound as though you're being caught by lazy evaluation. The 
"make_thunk" doesn't appear to evaluate ..., so its value can change 
between the time you make the thunk and the time you evaluate it.  I 
think you could force the evaluation within make_thunk by changing it to

make_thunk <- function(f, ...) { list(...); function() f(?) }

and then would be able to skip the force() in your thunk_factorial function.

Duncan Murdoch


From bgunter.4567 at gmail.com  Wed Aug 10 19:05:19 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 10 Aug 2016 10:05:19 -0700
Subject: [R] Proving (instead of rejecting) that two groups are actually
	equal
In-Reply-To: <e83eda53861416cbe08d8e1cf29c9535@drine.ch>
References: <e83eda53861416cbe08d8e1cf29c9535@drine.ch>
Message-ID: <CAGxFJbQMaq=96cGq_BOqq88FDDS9GRP4ScWS-y6P62fRo+ofPA@mail.gmail.com>

Rejecting a null of "inequality" is the standard setup for equivalence
testing in medical contexts. Search on "equivalence testing in R" and
you will find what you need.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 10, 2016 at 3:22 AM, Dominik Marti <dom at inik.ch> wrote:
> Hej R helpers
>
> The standard in statistical hypothesis testing is to reject the null
> hypothesis that there is a difference between groups, i.e. to "prove" the
> alternative. However, failing to reject the null hypothesis does not prove
> it; its rejection just fails.
>
> Now, as stated in the article "Unicorns do exist: a tutorial on "proving"
> the null hypothesis." by David L Streiner (Canadian Journal of Psychiatry,
> 48(11) 2003), we can define the null hypothesis to be that there IS a
> difference (exceeding a certain value, delta), the alternative hypothesis
> being that there is none (or it is at least smaller than delta). If the data
> now manages to reject the null hypothesis (of there being a difference
> exceeding delta), we can say with a certain probability that there is none.
>
> Can I do this test in R? And if yes, any leads?
>
> (In my actual dataset I deal with paired data.)
>
> Best
>    Dominik
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mailund at birc.au.dk  Wed Aug 10 19:10:43 2016
From: mailund at birc.au.dk (Thomas Mailund)
Date: Wed, 10 Aug 2016 17:10:43 +0000
Subject: [R] Continuation-parsing / trampoline / infinite recursion
 problem
In-Reply-To: <bc6c569e-32c2-eea5-f291-de13344b96d8@gmail.com>
References: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>
	<etPan.57ab1663.496f94a7.13177@birc.au.dk>
	<0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>
	<bc6c569e-32c2-eea5-f291-de13344b96d8@gmail.com>
Message-ID: <42A8876E-E948-4196-BD6E-0A3B841FA333@birc.au.dk>


That did the trick! 

I was so focused on not evaluating the continuation that I completely forgot that the thunk could hold an unevaluated value? now it seems to be working for all the various implementations I have been playing around with.

I think I still need to wrap my head around *why* the forced evaluation is necessary there, but I will figure that out when my tired brain has had a little rest.

Thanks a lot!

	Thomas


> On 10 Aug 2016, at 19:04, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 10/08/2016 12:53 PM, Thomas Mailund wrote:
>> > On 10 Aug 2016, at 13:56, Thomas Mailund <mailund at birc.au.dk> wrote:
>> >
>> > make_thunk <- function(f, ...) f(...)
>> 
>> Doh!  It is of course this one:
>> 
>> make_thunk <- function(f, ...) function() f(?)
>> 
>> It just binds a function call into a thunk so I can delay its evaluation.
> 
> I haven't looked closely at the full set of functions, but this comment:
> 
> force(continuation) # if I remove this line I get an error
> 
> makes it sound as though you're being caught by lazy evaluation. The "make_thunk" doesn't appear to evaluate ..., so its value can change between the time you make the thunk and the time you evaluate it.  I think you could force the evaluation within make_thunk by changing it to
> 
> make_thunk <- function(f, ...) { list(...); function() f(?) }
> 
> and then would be able to skip the force() in your thunk_factorial function.
> 
> Duncan Murdoch
> 
> 


From marc_schwartz at me.com  Wed Aug 10 19:12:02 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 10 Aug 2016 12:12:02 -0500
Subject: [R] Proving (instead of rejecting) that two groups are
	actually	equal
In-Reply-To: <e83eda53861416cbe08d8e1cf29c9535@drine.ch>
References: <e83eda53861416cbe08d8e1cf29c9535@drine.ch>
Message-ID: <D29D34EB-150A-44C3-A21A-0EF95C4D7123@me.com>


> On Aug 10, 2016, at 5:22 AM, Dominik Marti <dom at inik.ch> wrote:
> 
> Hej R helpers
> 
> The standard in statistical hypothesis testing is to reject the null hypothesis that there is a difference between groups, i.e. to "prove" the alternative. However, failing to reject the null hypothesis does not prove it; its rejection just fails.
> 
> Now, as stated in the article "Unicorns do exist: a tutorial on "proving" the null hypothesis." by David L Streiner (Canadian Journal of Psychiatry, 48(11) 2003), we can define the null hypothesis to be that there IS a difference (exceeding a certain value, delta), the alternative hypothesis being that there is none (or it is at least smaller than delta). If the data now manages to reject the null hypothesis (of there being a difference exceeding delta), we can say with a certain probability that there is none.
> 
> Can I do this test in R? And if yes, any leads?
> 
> (In my actual dataset I deal with paired data.)
> 
> Best
>   Dominik


Bear in mind that we are not "proving" anything with statistics. There is still a level of uncertainty in everything we do.

In the scenario above, you are, in essence, reversing the normal approach to testing a null versus alternative hypothesis. The null, in this case, is that there is a difference and the alternative being that there is none, within some pre-defined, acceptable, margin. 

In clinical studies, these are called "equivalence" studies or "bioequivalence" studies, a subset of which are called "non-inferiority" studies, which are one-sided versions. This is typically done, for example, when testing a generic version of a drug versus the pre-existing "brand name" version of the drug to demonstrate that they have equivalent efficacy and safety profiles, within a clinically acceptable range.

There is at least one R package that is relevant, conveniently called "equivalence":

  https://cran.r-project.org/web/packages/equivalence/

that addresses these scenarios.

Regards,

Marc Schwartz


From jholtman at gmail.com  Wed Aug 10 19:13:53 2016
From: jholtman at gmail.com (jim holtman)
Date: Wed, 10 Aug 2016 13:13:53 -0400
Subject: [R] Conditionally remove rows with logic
In-Reply-To: <CALvAKX+UVAcNxh8VVfpQ-LQip8pgVR-eNyb6LtvaYYJ=sefhrQ@mail.gmail.com>
References: <CALvAKX+UVAcNxh8VVfpQ-LQip8pgVR-eNyb6LtvaYYJ=sefhrQ@mail.gmail.com>
Message-ID: <CAAxdm-70yN5C+6pCfcuaV_3m--fKOeyVeDLyUs_=Ma3bTa85VA@mail.gmail.com>

try this:

> input <- read.table(text = "ID     TIME     LABEL
+  1        0            0
+  1        3            0
+  1        6            0
+  1        9            0
+  1        12          1
+  1        15          0
+  1        18           0
+  2        0            0
+  2        3            0
+  2        6            1
+  2        9            0
+  2        12          0
+  2        15          0
+  2        18          0", header = TRUE)
>
>  result <- do.call(rbind,
+     lapply(split(input, input$ID), function(.id){
+         indx <- which(.id$LABEL == 1)
+         if (length(indx) == 1) .id <- .id[1:indx, ]  # keep upto the '1'
+         .id
+     })
+ )
>
>
> result
     ID TIME LABEL
1.1   1    0     0
1.2   1    3     0
1.3   1    6     0
1.4   1    9     0
1.5   1   12     1
2.8   2    0     0
2.9   2    3     0
2.10  2    6     1
>


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Aug 7, 2016 at 6:21 PM, Jennifer Sheng <jennifer.sheng2002 at gmail.com
> wrote:

> Dear all,
>
> I need to remove any rows AFTER the label becomes 1.  For example, for ID
> 1, the two rows with TIME of 15 & 18 should be removed; for ID 2, any rows
> after time 6, i.e., rows of time 9-18, should be removed.  Any
> suggestions?  Thank you very much!
>
> The current dataset looks like the following:
> ID     TIME     LABEL
> 1        0            0
> 1        3            0
> 1        6            0
> 1        9            0
> 1        12          1
> 1        15          0
> 1        18           0
> 2        0            0
> 2        3            0
> 2        6            1
> 2        9            0
> 2        12          0
> 2        15          0
> 2        18          0
>
> Thanks a lot!
> Jennifer
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Aug 10 19:15:50 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 10 Aug 2016 10:15:50 -0700
Subject: [R] Continuation-parsing / trampoline / infinite recursion
	problem
In-Reply-To: <0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>
References: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>
	<etPan.57ab1663.496f94a7.13177@birc.au.dk>
	<0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>
Message-ID: <CAGxFJbR56N_vWdk82YTSfgMG675CjdkrP4geDb=h2c-0Zkg30A@mail.gmail.com>

make_thunk is probably unnecessary and apparently problematic. I think
you could use do.call()  instead, as do.call(f,list(...))  .



-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 10, 2016 at 9:53 AM, Thomas Mailund <mailund at birc.au.dk> wrote:
>
>> On 10 Aug 2016, at 13:56, Thomas Mailund <mailund at birc.au.dk> wrote:
>>
>> make_thunk <- function(f, ...) f(...)
>
> Doh!  It is of course this one:
>
> make_thunk <- function(f, ...) function() f(?)
>
> It just binds a function call into a thunk so I can delay its evaluation.
>
> Sorry
>         Thomas
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mailund at birc.au.dk  Wed Aug 10 19:17:05 2016
From: mailund at birc.au.dk (Thomas Mailund)
Date: Wed, 10 Aug 2016 17:17:05 +0000
Subject: [R] Continuation-parsing / trampoline / infinite recursion
 problem
In-Reply-To: <42A8876E-E948-4196-BD6E-0A3B841FA333@birc.au.dk>
References: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>
	<etPan.57ab1663.496f94a7.13177@birc.au.dk>
	<0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>
	<bc6c569e-32c2-eea5-f291-de13344b96d8@gmail.com>
	<42A8876E-E948-4196-BD6E-0A3B841FA333@birc.au.dk>
Message-ID: <1A50802E-6231-43C5-BB7F-E995C60996AD@birc.au.dk>

But wait, how is it actually changing? And how did calling `cat` make the problem go away? 

Ok, I will go think about it?

Thanks anyway, it seems to do the trick.


> On 10 Aug 2016, at 19:10, Thomas Mailund <mailund at birc.au.dk> wrote:
> 
> 
> That did the trick! 
> 
> I was so focused on not evaluating the continuation that I completely forgot that the thunk could hold an unevaluated value? now it seems to be working for all the various implementations I have been playing around with.
> 
> I think I still need to wrap my head around *why* the forced evaluation is necessary there, but I will figure that out when my tired brain has had a little rest.
> 
> Thanks a lot!
> 
> 	Thomas
> 
> 
>> On 10 Aug 2016, at 19:04, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> 
>> On 10/08/2016 12:53 PM, Thomas Mailund wrote:
>>>> On 10 Aug 2016, at 13:56, Thomas Mailund <mailund at birc.au.dk> wrote:
>>>> 
>>>> make_thunk <- function(f, ...) f(...)
>>> 
>>> Doh!  It is of course this one:
>>> 
>>> make_thunk <- function(f, ...) function() f(?)
>>> 
>>> It just binds a function call into a thunk so I can delay its evaluation.
>> 
>> I haven't looked closely at the full set of functions, but this comment:
>> 
>> force(continuation) # if I remove this line I get an error
>> 
>> makes it sound as though you're being caught by lazy evaluation. The "make_thunk" doesn't appear to evaluate ..., so its value can change between the time you make the thunk and the time you evaluate it.  I think you could force the evaluation within make_thunk by changing it to
>> 
>> make_thunk <- function(f, ...) { list(...); function() f(?) }
>> 
>> and then would be able to skip the force() in your thunk_factorial function.
>> 
>> Duncan Murdoch
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mailund at birc.au.dk  Wed Aug 10 19:20:14 2016
From: mailund at birc.au.dk (Thomas Mailund)
Date: Wed, 10 Aug 2016 17:20:14 +0000
Subject: [R] Continuation-parsing / trampoline / infinite recursion
 problem
In-Reply-To: <CAGxFJbR56N_vWdk82YTSfgMG675CjdkrP4geDb=h2c-0Zkg30A@mail.gmail.com>
References: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>
	<etPan.57ab1663.496f94a7.13177@birc.au.dk>
	<0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>
	<CAGxFJbR56N_vWdk82YTSfgMG675CjdkrP4geDb=h2c-0Zkg30A@mail.gmail.com>
Message-ID: <16135A5C-C65B-46EB-A628-04764809DACE@birc.au.dk>


On 10 Aug 2016, at 19:15, Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>> wrote:

make_thunk is probably unnecessary and apparently problematic. I think
you could use do.call()  instead, as do.call(f,list(...))  .

Yes,

make_thunk <- function(f, ...) function() do.call(f, list(...))

also works as far as I can see, yes. I do need to turn it into a thunk, though, as far as I can see.

Thanks
Thomas


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Aug 10 19:28:31 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 10 Aug 2016 13:28:31 -0400
Subject: [R] Continuation-parsing / trampoline / infinite recursion
 problem
In-Reply-To: <42A8876E-E948-4196-BD6E-0A3B841FA333@birc.au.dk>
References: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>
	<etPan.57ab1663.496f94a7.13177@birc.au.dk>
	<0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>
	<bc6c569e-32c2-eea5-f291-de13344b96d8@gmail.com>
	<42A8876E-E948-4196-BD6E-0A3B841FA333@birc.au.dk>
Message-ID: <51c27e91-a8d7-d4e8-a5a2-d7994b27b763@gmail.com>

On 10/08/2016 1:10 PM, Thomas Mailund wrote:
> That did the trick!
>
> I was so focused on not evaluating the continuation that I completely forgot that the thunk could hold an unevaluated value? now it seems to be working for all the various implementations I have been playing around with.
>
> I think I still need to wrap my head around *why* the forced evaluation is necessary there, but I will figure that out when my tired brain has had a little rest.

The original version

make_thunk <- function(f, ...) function() f(?)

says to construct a new function whose body evaluates the expression 
f(...).  It never evaluates f nor ... , so they don't get evaluated 
until the first time you evaluate that new function.

My version containing list(...) forces evaluation of ... .  It would 
have been even better to use

make_thunk <- function(f, ...) { list(f, ...); function() f(?) }

because that forces evaluation of both arguments.

I suspect you would have problems with

make_thunk <- function(f, ...) function() do.call(f, list(...))

for exactly the same reasons as the original; I'm surprised that you 
found it appears to work.

Duncan Murdoch

>
> Thanks a lot!
>
> 	Thomas
>
>
> > On 10 Aug 2016, at 19:04, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> >
> > On 10/08/2016 12:53 PM, Thomas Mailund wrote:
> >> > On 10 Aug 2016, at 13:56, Thomas Mailund <mailund at birc.au.dk> wrote:
> >> >
> >> > make_thunk <- function(f, ...) f(...)
> >>
> >> Doh!  It is of course this one:
> >>
> >> make_thunk <- function(f, ...) function() f(?)
> >>
> >> It just binds a function call into a thunk so I can delay its evaluation.
> >
> > I haven't looked closely at the full set of functions, but this comment:
> >
> > force(continuation) # if I remove this line I get an error
> >
> > makes it sound as though you're being caught by lazy evaluation. The "make_thunk" doesn't appear to evaluate ..., so its value can change between the time you make the thunk and the time you evaluate it.  I think you could force the evaluation within make_thunk by changing it to
> >
> > make_thunk <- function(f, ...) { list(...); function() f(?) }
> >
> > and then would be able to skip the force() in your thunk_factorial function.
> >
> > Duncan Murdoch
> >
> >
>


From mailund at birc.au.dk  Wed Aug 10 19:42:31 2016
From: mailund at birc.au.dk (Thomas Mailund)
Date: Wed, 10 Aug 2016 17:42:31 +0000
Subject: [R] Continuation-parsing / trampoline / infinite recursion
 problem
In-Reply-To: <51c27e91-a8d7-d4e8-a5a2-d7994b27b763@gmail.com>
References: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>
	<etPan.57ab1663.496f94a7.13177@birc.au.dk>
	<0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>
	<bc6c569e-32c2-eea5-f291-de13344b96d8@gmail.com>
	<42A8876E-E948-4196-BD6E-0A3B841FA333@birc.au.dk>
	<51c27e91-a8d7-d4e8-a5a2-d7994b27b763@gmail.com>
Message-ID: <etPan.57ab6787.2102c48f.1496c@birc.au.dk>

?
I am not sure I can see exactly how the parameters are changing at all, regardless of which of the versions I am using. Nowhere in the code do I ever modify assign to a variable (except for defining the global-level functions).

I think my problem is that I don?t really understand ... here.

I would expect these two cases, with and without a thunk, to give me the same output, but they clearly do not.

x <- function(...) eval(substitute(alist(...)))
x(a = 2, b = 3)
x(c = 4, d = 5)

xx <- function(...) function() eval(substitute(alist(...)))
xx(a = 2, b = 3)()
xx(c = 4, d = 5)()

The first gives me the parameters and the second just ? back.

How is the thunk actually seeing ... and why does it work with do.call and not with direct call?

library(pryr)
xxx <- function(...) function() do.call(eval %.% substitute %.% alist, list(...))
xxx(a = 2, b = 3)()
xxx(c = 4, d = 5)()

gives me the same results as the xx case, so it is not the do.call that does it, even though that works in my examples.

With

xxxx <- function(...) { list(...) ; function() eval(substitute(alist(...))) }
xxxx(a = 2, b = 3)()
xxxx(c = 4, d = 5)()

it is the same.


Explicitly naming the parameters, of course works fine

y <- function( ...) { params <- list(...) ; function() params }
y(a = 2, b = 3)()
y(c = 4, d = 5)()

Here I get the expected lists out.

I guess I just shouldn?t be using ... in an inner function that refers to the parameters in an outer function. I?m not even sure what that should be expected to do and I certainly do not understand what is happening :)

Explicitly remembering the parameters seems to work fine, though.

Cheers
	Thomas




On 10 August 2016 at 19:28:43, Duncan Murdoch (murdoch.duncan at gmail.com(mailto:murdoch.duncan at gmail.com)) wrote:

> On 10/08/2016 1:10 PM, Thomas Mailund wrote:
> > That did the trick!
> >
> > I was so focused on not evaluating the continuation that I completely forgot that the thunk could hold an unevaluated value? now it seems to be working for all the various implementations I have been playing around with.
> >
> > I think I still need to wrap my head around *why* the forced evaluation is necessary there, but I will figure that out when my tired brain has had a little rest.
>  
> The original version
>  
> make_thunk <- function(f, ...) function() f(?)
>  
> says to construct a new function whose body evaluates the expression
> f(...). It never evaluates f nor ... , so they don't get evaluated
> until the first time you evaluate that new function.
>  
> My version containing list(...) forces evaluation of ... . It would
> have been even better to use
>  
> make_thunk <- function(f, ...) { list(f, ...); function() f(?) }
>  
> because that forces evaluation of both arguments.
>  
> I suspect you would have problems with
>  
> make_thunk <- function(f, ...) function() do.call(f, list(...))
>  
> for exactly the same reasons as the original; I'm surprised that you
> found it appears to work.
>  
> Duncan Murdoch
>  
> >
> > Thanks a lot!
> >
> > Thomas
> >
> >
> > > On 10 Aug 2016, at 19:04, Duncan Murdoch wrote:
> > >
> > > On 10/08/2016 12:53 PM, Thomas Mailund wrote:
> > >> > On 10 Aug 2016, at 13:56, Thomas Mailund wrote:
> > >> >
> > >> > make_thunk <- function(f, ...) f(...)
> > >>
> > >> Doh! It is of course this one:
> > >>
> > >> make_thunk <- function(f, ...) function() f(?)
> > >>
> > >> It just binds a function call into a thunk so I can delay its evaluation.
> > >
> > > I haven't looked closely at the full set of functions, but this comment:
> > >
> > > force(continuation) # if I remove this line I get an error
> > >
> > > makes it sound as though you're being caught by lazy evaluation. The "make_thunk" doesn't appear to evaluate ..., so its value can change between the time you make the thunk and the time you evaluate it. I think you could force the evaluation within make_thunk by changing it to
> > >
> > > make_thunk <- function(f, ...) { list(...); function() f(?) }
> > >
> > > and then would be able to skip the force() in your thunk_factorial function.
> > >
> > > Duncan Murdoch
> > >
> > >
> >
>  

From wdunlap at tibco.com  Wed Aug 10 19:48:23 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 10 Aug 2016 10:48:23 -0700
Subject: [R] Continuation-parsing / trampoline / infinite recursion
	problem
In-Reply-To: <7E95FFD1-0C40-4C13-B932-9EA0001BE413@birc.au.dk>
References: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>
	<etPan.57ab1663.496f94a7.13177@birc.au.dk>
	<0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>
	<7E95FFD1-0C40-4C13-B932-9EA0001BE413@birc.au.dk>
Message-ID: <CAF8bMcYu3GD=KuoR1G4k0yza+oEUnpe3R9DxNqYgk8o-73k5Tg@mail.gmail.com>

You may gain some understanding of what is going on by adding
the output of sys.nframe() or length(sys.calls()) to the cat() statement.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Aug 10, 2016 at 9:59 AM, Thomas Mailund <mailund at birc.au.dk> wrote:

> An alternative implementation, closer to what I need when I have more than
> one recursion in each step, but still using factorial as the example, is
> this one:
>
> thunk_factorial <- function(n, continuation = identity) {
>   force(continuation) # if I remove this line I get an error
>   cat("call: ", n, "\n") # same for this line
>   if (n == 1) {
>     continuation(1)
>   } else {
>     new_continuation <- function(result) {
>       cat("thunk: ", result, "\n?) # remove this line and it fails, keep
> it and it works
>       make_thunk(continuation, n * result)
>     }
>     make_thunk(thunk_factorial, n - 1, new_continuation)
>   }
> }
> trampoline(thunk_factorial(10000))
>
> Here I am making a continuation instead of passing along an accumulator,
> which I need to do for more complex cases, and with that continuation I can
> also get it to complete without errors if I output the text inside it.
> Removing the `cat` line and I get the recursion error?
>
> Cheers
>         Thomas
>
>
>
> > On 10 Aug 2016, at 18:53, Thomas Mailund <mailund at birc.au.dk> wrote:
> >
> >
> >> On 10 Aug 2016, at 13:56, Thomas Mailund <mailund at birc.au.dk> wrote:
> >>
> >> make_thunk <- function(f, ...) f(...)
> >
> > Doh!  It is of course this one:
> >
> > make_thunk <- function(f, ...) function() f(?)
> >
> > It just binds a function call into a thunk so I can delay its evaluation.
> >
> > Sorry
> >       Thomas
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mailund at birc.au.dk  Wed Aug 10 19:54:35 2016
From: mailund at birc.au.dk (Thomas Mailund)
Date: Wed, 10 Aug 2016 17:54:35 +0000
Subject: [R] Continuation-parsing / trampoline / infinite recursion
 problem
In-Reply-To: <CAF8bMcYu3GD=KuoR1G4k0yza+oEUnpe3R9DxNqYgk8o-73k5Tg@mail.gmail.com>
References: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>
	<etPan.57ab1663.496f94a7.13177@birc.au.dk>
	<0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>
	<7E95FFD1-0C40-4C13-B932-9EA0001BE413@birc.au.dk>
	<CAF8bMcYu3GD=KuoR1G4k0yza+oEUnpe3R9DxNqYgk8o-73k5Tg@mail.gmail.com>
Message-ID: <etPan.57ab6a5b.540be9fb.1496c@birc.au.dk>

?
Well, they stay at 3 when I call cat (except for the final step going down in they recursion where `identity` is called, where they are 4). They do that both when I evaluate ... in the `make_thunk` function and when I don?t. But then, when I call `cat` it also worked before. I cannot keep `cat` in there and still get the error, something that is *really* puzzling me.



On 10 August 2016 at 19:48:47, William Dunlap (wdunlap at tibco.com(mailto:wdunlap at tibco.com)) wrote:

> You may gain some understanding of what is going on by adding  
> the output of sys.nframe() or length(sys.calls()) to the cat() statement.
>  


From mailund at birc.au.dk  Wed Aug 10 20:39:03 2016
From: mailund at birc.au.dk (Thomas Mailund)
Date: Wed, 10 Aug 2016 18:39:03 +0000
Subject: [R] Continuation-parsing / trampoline / infinite recursion
 problem
In-Reply-To: <42A8876E-E948-4196-BD6E-0A3B841FA333@birc.au.dk>
References: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>
	<etPan.57ab1663.496f94a7.13177@birc.au.dk>
	<0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>
	<bc6c569e-32c2-eea5-f291-de13344b96d8@gmail.com>
	<42A8876E-E948-4196-BD6E-0A3B841FA333@birc.au.dk>
Message-ID: <etPan.57ab74c7.1e71047f.1496c@birc.au.dk>

?
Ok, I think maybe I am beginning to see what is going wrong...

Explicitly remembering the thunk parameters in a list works fine, as far as I can see.

make_thunk <- function(f, ...) {
? remembered <- list(...)
? function(...) do.call(f, as.list(remembered))
}

thunk_factorial <- function(n, continuation = identity) {
? if (n == 1) {
? ? continuation(1)
? } else {
? ? new_continuation <- function(result) {
? ? ? make_thunk(continuation, n * result)
? ? }
? ? make_thunk(thunk_factorial, n - 1, new_continuation)
? }
}

trampoline <- function(thunk) {
? while (is.function(thunk)) thunk <- thunk()
? thunk
}

trampoline(thunk_factorial(100))


But if I delay the evaluation of the parameters to thunk I get an error

make_thunk <- function(f, ...) {
? remembered <- eval(substitute(alist(...))) # not evaluating parameters yet
? function(...) do.call(f, as.list(remembered))
}

thunk_factorial <- function(n, continuation = identity) {
? if (n == 1) {
? ? continuation(1)
? } else {
? ? new_continuation <- function(result) {
? ? ? make_thunk(continuation, n * result)
? ? }
? ? make_thunk(thunk_factorial, n - 1, new_continuation)
? }
}

trampoline(thunk_factorial(100))

Running this version I am told, when applying the function, that it doesn?t see variable `n`.


As far as I can see, the thunk remembers the parameters just fine. At least this gives me the parameters I made it remember

x <- 1
f <- make_thunk(list, a = 1 * x, b = 2 * x)
g <- make_thunk(list, c = 3 * x)
f()
g()

Here I just get the parameters back in a list because the wrapped function is `list`. (The reason I have `x` as a global variable and use it in the arguments is so I get call objects that needs to be evaluated lazily instead of just values).

These values contain the expressions I gave the `make_thunk` function, of course, and they are not evaluated. So in the factorial function the missing `n` is because I give it the expression `n - 1` that it of course cannot evaluate in the thunk.

So I cannot really delay evaluation.

Does this sound roughly correct?

Now why I can still get it to work when I call `cat` remains a mystery?

Cheers
	Thomas



On 10 August 2016 at 19:12:41, Thomas Mailund (mailund at birc.au.dk(mailto:mailund at birc.au.dk)) wrote:

>  
> That did the trick!
>  
> I was so focused on not evaluating the continuation that I completely forgot that the thunk could hold an unevaluated value? now it seems to be working for all the various implementations I have been playing around with.
>  
> I think I still need to wrap my head around *why* the forced evaluation is necessary there, but I will figure that out when my tired brain has had a little rest.
>  
> Thanks a lot!
>  
> Thomas
>  
>  
> > On 10 Aug 2016, at 19:04, Duncan Murdoch wrote:
> >
> > On 10/08/2016 12:53 PM, Thomas Mailund wrote:
> >> > On 10 Aug 2016, at 13:56, Thomas Mailund wrote:
> >> >
> >> > make_thunk <- function(f, ...) f(...)
> >>
> >> Doh! It is of course this one:
> >>
> >> make_thunk <- function(f, ...) function() f(?)
> >>
> >> It just binds a function call into a thunk so I can delay its evaluation.
> >
> > I haven't looked closely at the full set of functions, but this comment:
> >
> > force(continuation) # if I remove this line I get an error
> >
> > makes it sound as though you're being caught by lazy evaluation. The "make_thunk" doesn't appear to evaluate ..., so its value can change between the time you make the thunk and the time you evaluate it. I think you could force the evaluation within make_thunk by changing it to
> >
> > make_thunk <- function(f, ...) { list(...); function() f(?) }
> >
> > and then would be able to skip the force() in your thunk_factorial function.
> >
> > Duncan Murdoch
> >
> >
>  
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From glenn at kdsglobal.com  Wed Aug 10 21:18:04 2016
From: glenn at kdsglobal.com (Glenn Schultz)
Date: Wed, 10 Aug 2016 14:18:04 -0500
Subject: [R] R Listen to a Web GUI
Message-ID: <571B8EB9-181E-4814-AE53-0E8E94E386AA@kdsglobal.com>

All,

I need to create a function that listens to a web GUI interface and then responds by running the needed R function.  How can I do that with R?  Can anyone recommend what packages I should consider.

Glenn

From farnoosh_81 at yahoo.com  Wed Aug 10 17:58:55 2016
From: farnoosh_81 at yahoo.com (Farnoosh Sheikhi)
Date: Wed, 10 Aug 2016 15:58:55 +0000 (UTC)
Subject: [R] Extracting dates to create a new variable
In-Reply-To: <1412270801.12953575.1470676571031.JavaMail.yahoo@mail.yahoo.com>
References: <1412270801.12953575.1470676571031.JavaMail.yahoo.ref@mail.yahoo.com>
	<1412270801.12953575.1470676571031.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1120230244.14743910.1470844735061.JavaMail.yahoo@mail.yahoo.com>

 blockquote, div.yahoo_quoted { margin-left: 0 !important; border-left:1px #715FFA solid !important; padding-left:1ex !important; background-color:white !important; } 

Hi?
I have a data set like below and wanted to create a new date variable by extracting the dates for specific departments.I want to extract the dates for departments CC, DD, FF, ?put it in a new column and repeat it for other unique IDs.
Subject<- c("2", "2", "2", "3", "3", "3", "4", "4", "5", "5", "5", "5")dates<-seq(as.Date('2011-01-01'),as.Date('2011-01-12'),by = 1)?deps<-c("A", "B", "CC", "C", "CC", "A", "F", "DD", "A", "F", "FF", "D")df <- data.frame(Subject, dates, deps)df
The final data set should look like this:newdate<-c(" 2011-01-03", ?"2011-01-03", ?"2011-01-03", "2011-01-05", "2011-01-05", "2011-01-05" , "2011-01-08", "2011-01-08", "2011-01-08", "2011-01-11", "2011-01-11", "2011-01-11")final<-data.frame(Subject, dates, deps, newdate)final
I really appreciate any help.
?Best,Farnoosh


 


	[[alternative HTML version deleted]]


From apoema.asa at gmail.com  Wed Aug 10 19:54:38 2016
From: apoema.asa at gmail.com (=?UTF-8?Q?Caio_Guimar=C3=A3es_Figueiredo?=)
Date: Wed, 10 Aug 2016 14:54:38 -0300
Subject: [R] Unexpected behavior with cbind.ts
Message-ID: <CANvpEyi0PYStLzLdxDSQ_23mVqsWi-O0uN=b1uXPuoVqOWrtyA@mail.gmail.com>

I got two ts variables (w and y) that I want to cbind into a mts matrix
variable.

w is a simple ts object with some random data, length=40, start = 2005, end
= 2014.75, frequency = 4, class = "ts".

y is a collection of 2 ts, nrow = 40, ncol=2, start = 2005, end = 2014.75,
frequency = 4, class = "mts", "ts", "matrix"

I was expecting that the result of cbind(w,y) to be a mts matrix with 3
columns, 40 rows, same start and frequency as the originals, and finally to
be of class "mts", "ts", "matrix.

What I get is a single ts variable with length = 120, start = 2005 but end
= 2034,75, frequency = 4, class = "ts". This behavior is what i would
expect from ts.union, but not from cbind.

I, unsuccessfully,  tried to replicated this result with different
variables. For example, cbind(ts(c(0,1), ts(matrix(c(2,3,4,5), 2,2))),
returns exactly what I was expecting a ts matrix, with 2 rows and 3 columns.

Anyone has any idea of what is happening? What kind of attribute my
variables could have to imply this behavior? I have the felling that I am
simply calling two different function, but don't know why.

Thank you in advance

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Wed Aug 10 22:08:29 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 10 Aug 2016 20:08:29 +0000
Subject: [R] R Listen to a Web GUI
In-Reply-To: <571B8EB9-181E-4814-AE53-0E8E94E386AA@kdsglobal.com>
References: <571B8EB9-181E-4814-AE53-0E8E94E386AA@kdsglobal.com>
Message-ID: <CAKVAULOOKup910NBWeZ1cNzJEMsW+sX-Na0Ojs95t3UPwviaeQ@mail.gmail.com>

Hi Glenn,

Shiny and shinydashboards might be what you are looking for.

Best,
Ulrik

On Wed, 10 Aug 2016, 22:03 Glenn Schultz, <glenn at kdsglobal.com> wrote:

> All,
>
> I need to create a function that listens to a web GUI interface and then
> responds by running the needed R function.  How can I do that with R?  Can
> anyone recommend what packages I should consider.
>
> Glenn
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Aug 10 22:22:32 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 10 Aug 2016 16:22:32 -0400
Subject: [R] Continuation-parsing / trampoline / infinite recursion
 problem
In-Reply-To: <etPan.57ab74c7.1e71047f.1496c@birc.au.dk>
References: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>
	<etPan.57ab1663.496f94a7.13177@birc.au.dk>
	<0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>
	<bc6c569e-32c2-eea5-f291-de13344b96d8@gmail.com>
	<42A8876E-E948-4196-BD6E-0A3B841FA333@birc.au.dk>
	<etPan.57ab74c7.1e71047f.1496c@birc.au.dk>
Message-ID: <bf527dd7-45c6-7c71-dbb7-e3b9a4add121@gmail.com>

On 10/08/2016 2:39 PM, Thomas Mailund wrote:
>
> Ok, I think maybe I am beginning to see what is going wrong...
>
> Explicitly remembering the thunk parameters in a list works fine, as far as I can see.
>
> make_thunk <- function(f, ...) {
>   remembered <- list(...)
>   function(...) do.call(f, as.list(remembered))
> }

Where that will fail is in a situation like this:

thunklist <- list(thunk_factorial, thunk_somethingelse)
for (i in seq_along(thunklist))
   thunklist[[i]] <- make_thunk(thunklist[[i]])

The problem is that the first time thunklist[[1]] is evaluated, it will 
call the function thunklist[[2]] (or something else if i has been 
modified in the meantime), and things will go bad.  That's why it's 
important to force both f and ... in make_thunk.

Duncan Murdoch

>
> thunk_factorial <- function(n, continuation = identity) {
>   if (n == 1) {
>     continuation(1)
>   } else {
>     new_continuation <- function(result) {
>       make_thunk(continuation, n * result)
>     }
>     make_thunk(thunk_factorial, n - 1, new_continuation)
>   }
> }
>
> trampoline <- function(thunk) {
>   while (is.function(thunk)) thunk <- thunk()
>   thunk
> }
>
> trampoline(thunk_factorial(100))
>
>
> But if I delay the evaluation of the parameters to thunk I get an error
>
> make_thunk <- function(f, ...) {
>   remembered <- eval(substitute(alist(...))) # not evaluating parameters yet
>   function(...) do.call(f, as.list(remembered))
> }
>
> thunk_factorial <- function(n, continuation = identity) {
>   if (n == 1) {
>     continuation(1)
>   } else {
>     new_continuation <- function(result) {
>       make_thunk(continuation, n * result)
>     }
>     make_thunk(thunk_factorial, n - 1, new_continuation)
>   }
> }
>
> trampoline(thunk_factorial(100))
>
> Running this version I am told, when applying the function, that it doesn?t see variable `n`.
>
>
> As far as I can see, the thunk remembers the parameters just fine. At least this gives me the parameters I made it remember
>
> x <- 1
> f <- make_thunk(list, a = 1 * x, b = 2 * x)
> g <- make_thunk(list, c = 3 * x)
> f()
> g()
>
> Here I just get the parameters back in a list because the wrapped function is `list`. (The reason I have `x` as a global variable and use it in the arguments is so I get call objects that needs to be evaluated lazily instead of just values).
>
> These values contain the expressions I gave the `make_thunk` function, of course, and they are not evaluated. So in the factorial function the missing `n` is because I give it the expression `n - 1` that it of course cannot evaluate in the thunk.
>
> So I cannot really delay evaluation.
>
> Does this sound roughly correct?
>
> Now why I can still get it to work when I call `cat` remains a mystery?
>
> Cheers
> 	Thomas
>
>
>
> On 10 August 2016 at 19:12:41, Thomas Mailund (mailund at birc.au.dk(mailto:mailund at birc.au.dk)) wrote:
>
>>
>> That did the trick!
>>
>> I was so focused on not evaluating the continuation that I completely forgot that the thunk could hold an unevaluated value? now it seems to be working for all the various implementations I have been playing around with.
>>
>> I think I still need to wrap my head around *why* the forced evaluation is necessary there, but I will figure that out when my tired brain has had a little rest.
>>
>> Thanks a lot!
>>
>> Thomas
>>
>>
>>> On 10 Aug 2016, at 19:04, Duncan Murdoch wrote:
>>>
>>> On 10/08/2016 12:53 PM, Thomas Mailund wrote:
>>>>> On 10 Aug 2016, at 13:56, Thomas Mailund wrote:
>>>>>
>>>>> make_thunk <- function(f, ...) f(...)
>>>>
>>>> Doh! It is of course this one:
>>>>
>>>> make_thunk <- function(f, ...) function() f(?)
>>>>
>>>> It just binds a function call into a thunk so I can delay its evaluation.
>>>
>>> I haven't looked closely at the full set of functions, but this comment:
>>>
>>> force(continuation) # if I remove this line I get an error
>>>
>>> makes it sound as though you're being caught by lazy evaluation. The "make_thunk" doesn't appear to evaluate ..., so its value can change between the time you make the thunk and the time you evaluate it. I think you could force the evaluation within make_thunk by changing it to
>>>
>>> make_thunk <- function(f, ...) { list(...); function() f(?) }
>>>
>>> and then would be able to skip the force() in your thunk_factorial function.
>>>
>>> Duncan Murdoch
>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jvadams at usgs.gov  Thu Aug 11 00:13:51 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 10 Aug 2016 17:13:51 -0500
Subject: [R] Extracting dates to create a new variable
In-Reply-To: <1120230244.14743910.1470844735061.JavaMail.yahoo@mail.yahoo.com>
References: <1412270801.12953575.1470676571031.JavaMail.yahoo.ref@mail.yahoo.com>
	<1412270801.12953575.1470676571031.JavaMail.yahoo@mail.yahoo.com>
	<1120230244.14743910.1470844735061.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAN5YmCGW2k_3DtJi9OT7vrXUhfu8aB2bc6JWgBskv0acpSm2pQ@mail.gmail.com>

Try this.

dfsub <- df[df$deps %in% c("CC", "DD", "FF"), ]
names(dfsub) <- c("Subject", "newdate", "origdep")
final <- merge(df, dfsub)

Jean

On Wed, Aug 10, 2016 at 10:58 AM, Farnoosh Sheikhi via R-help <
r-help at r-project.org> wrote:

>  blockquote, div.yahoo_quoted { margin-left: 0 !important; border-left:1px
> #715FFA solid !important; padding-left:1ex !important;
> background-color:white !important; }
>
> Hi
> I have a data set like below and wanted to create a new date variable by
> extracting the dates for specific departments.I want to extract the dates
> for departments CC, DD, FF,  put it in a new column and repeat it for other
> unique IDs.
> Subject<- c("2", "2", "2", "3", "3", "3", "4", "4", "5", "5", "5",
> "5")dates<-seq(as.Date('2011-01-01'),as.Date('2011-01-12'),by =
> 1) deps<-c("A", "B", "CC", "C", "CC", "A", "F", "DD", "A", "F", "FF",
> "D")df <- data.frame(Subject, dates, deps)df
> The final data set should look like this:newdate<-c(" 2011-01-03",
>  "2011-01-03",  "2011-01-03", "2011-01-05", "2011-01-05", "2011-01-05" ,
> "2011-01-08", "2011-01-08", "2011-01-08", "2011-01-11", "2011-01-11",
> "2011-01-11")final<-data.frame(Subject, dates, deps, newdate)final
> I really appreciate any help.
>  Best,Farnoosh
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Thu Aug 11 02:17:56 2016
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 10 Aug 2016 16:17:56 -0800
Subject: [R] Unexpected behavior with cbind.ts
In-Reply-To: <CANvpEyi0PYStLzLdxDSQ_23mVqsWi-O0uN=b1uXPuoVqOWrtyA@mail.gmail.com>
Message-ID: <139E398B312.000008D0jrkrideau@inbox.com>

It would help if you showed us the code you have been using so far plus some sample data (use dput() to produce it) can really help.

See ttp://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

http://adv-r.had.co.nz/Reproducibility.html


John Kane
Kingston ON Canada


> -----Original Message-----
> From: apoema.asa at gmail.com
> Sent: Wed, 10 Aug 2016 14:54:38 -0300
> To: r-help at r-project.org
> Subject: [R] Unexpected behavior with cbind.ts
> 
> I got two ts variables (w and y) that I want to cbind into a mts matrix
> variable.
> 
> w is a simple ts object with some random data, length=40, start = 2005,
> end
> = 2014.75, frequency = 4, class = "ts".
> 
> y is a collection of 2 ts, nrow = 40, ncol=2, start = 2005, end =
> 2014.75,
> frequency = 4, class = "mts", "ts", "matrix"
> 
> I was expecting that the result of cbind(w,y) to be a mts matrix with 3
> columns, 40 rows, same start and frequency as the originals, and finally
> to
> be of class "mts", "ts", "matrix.
> 
> What I get is a single ts variable with length = 120, start = 2005 but
> end
> = 2034,75, frequency = 4, class = "ts". This behavior is what i would
> expect from ts.union, but not from cbind.
> 
> I, unsuccessfully,  tried to replicated this result with different
> variables. For example, cbind(ts(c(0,1), ts(matrix(c(2,3,4,5), 2,2))),
> returns exactly what I was expecting a ts matrix, with 2 rows and 3
> columns.
> 
> Anyone has any idea of what is happening? What kind of attribute my
> variables could have to imply this behavior? I have the felling that I am
> simply calling two different function, but don't know why.
> 
> Thank you in advance
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From mailund at birc.au.dk  Thu Aug 11 06:39:14 2016
From: mailund at birc.au.dk (Thomas Mailund)
Date: Thu, 11 Aug 2016 04:39:14 +0000
Subject: [R] Continuation-parsing / trampoline / infinite recursion
 problem
In-Reply-To: <bf527dd7-45c6-7c71-dbb7-e3b9a4add121@gmail.com>
References: <bf527dd7-45c6-7c71-dbb7-e3b9a4add121@gmail.com>
Message-ID: <etPan.57ac0172.327b23c6.ab1@birc.au.dk>

Yes, I am aware of this situation and I agree that it is better to force f. I was simply trying to figure out why it was necessary in this particular program where the only repeated assignment anywhere in the code is in trampoline, in a scope none of the thunks can see.

What ever my problem was, it was not that the binding of f changes. The code works correctly if I output info with cat, so unless cat could affect this it can't be.

I still don't quite understand that but I suspect it is ... that is doing something I don't understand. Either that or my understanding of in which scope lazy parameters get evaluated is completely wrong.

Anyway, that being said, you are of course right that it is better to force f in my actual program, and I will.


Thanks


On 10 August 2016 at 22:22:32, Duncan Murdoch (murdoch.duncan at gmail.com<mailto:murdoch.duncan at gmail.com>) wrote:

On 10/08/2016 2:39 PM, Thomas Mailund wrote:

Ok, I think maybe I am beginning to see what is going wrong...

Explicitly remembering the thunk parameters in a list works fine, as far as I can see.

make_thunk <- function(f, ...) {
remembered <- list(...)
function(...) do.call(f, as.list(remembered))
}

Where that will fail is in a situation like this:

thunklist <- list(thunk_factorial, thunk_somethingelse)
for (i in seq_along(thunklist))
thunklist[[i]] <- make_thunk(thunklist[[i]])

The problem is that the first time thunklist[[1]] is evaluated, it will
call the function thunklist[[2]] (or something else if i has been
modified in the meantime), and things will go bad. That's why it's
important to force both f and ... in make_thunk.

Duncan Murdoch


thunk_factorial <- function(n, continuation = identity) {
if (n == 1) {
continuation(1)
} else {
new_continuation <- function(result) {
make_thunk(continuation, n * result)
}
make_thunk(thunk_factorial, n - 1, new_continuation)
}
}

trampoline <- function(thunk) {
while (is.function(thunk)) thunk <- thunk()
thunk
}

trampoline(thunk_factorial(100))


But if I delay the evaluation of the parameters to thunk I get an error

make_thunk <- function(f, ...) {
remembered <- eval(substitute(alist(...))) # not evaluating parameters yet
function(...) do.call(f, as.list(remembered))
}

thunk_factorial <- function(n, continuation = identity) {
if (n == 1) {
continuation(1)
} else {
new_continuation <- function(result) {
make_thunk(continuation, n * result)
}
make_thunk(thunk_factorial, n - 1, new_continuation)
}
}

trampoline(thunk_factorial(100))

Running this version I am told, when applying the function, that it doesn?t see variable `n`.


As far as I can see, the thunk remembers the parameters just fine. At least this gives me the parameters I made it remember

x <- 1
f <- make_thunk(list, a = 1 * x, b = 2 * x)
g <- make_thunk(list, c = 3 * x)
f()
g()

Here I just get the parameters back in a list because the wrapped function is `list`. (The reason I have `x` as a global variable and use it in the arguments is so I get call objects that needs to be evaluated lazily instead of just values).

These values contain the expressions I gave the `make_thunk` function, of course, and they are not evaluated. So in the factorial function the missing `n` is because I give it the expression `n - 1` that it of course cannot evaluate in the thunk.

So I cannot really delay evaluation.

Does this sound roughly correct?

Now why I can still get it to work when I call `cat` remains a mystery?

Cheers
Thomas



On 10 August 2016 at 19:12:41, Thomas Mailund (mailund at birc.au.dk(mailto:mailund at birc.au.dk)) wrote:


That did the trick!

I was so focused on not evaluating the continuation that I completely forgot that the thunk could hold an unevaluated value? now it seems to be working for all the various implementations I have been playing around with.

I think I still need to wrap my head around *why* the forced evaluation is necessary there, but I will figure that out when my tired brain has had a little rest.

Thanks a lot!

Thomas


On 10 Aug 2016, at 19:04, Duncan Murdoch wrote:

On 10/08/2016 12:53 PM, Thomas Mailund wrote:
On 10 Aug 2016, at 13:56, Thomas Mailund wrote:

make_thunk <- function(f, ...) f(...)

Doh! It is of course this one:

make_thunk <- function(f, ...) function() f(?)

It just binds a function call into a thunk so I can delay its evaluation.

I haven't looked closely at the full set of functions, but this comment:

force(continuation) # if I remove this line I get an error

makes it sound as though you're being caught by lazy evaluation. The "make_thunk" doesn't appear to evaluate ..., so its value can change between the time you make the thunk and the time you evaluate it. I think you could force the evaluation within make_thunk by changing it to

make_thunk <- function(f, ...) { list(...); function() f(?) }

and then would be able to skip the force() in your thunk_factorial function.

Duncan Murdoch



______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From nell.redu at hotmail.fr  Thu Aug 11 17:19:54 2016
From: nell.redu at hotmail.fr (Nelly Reduan)
Date: Thu, 11 Aug 2016 15:19:54 +0000
Subject: [R] Sort a data table
Message-ID: <SN2PR05MB273436673D9C1DE730EC12CA991E0@SN2PR05MB2734.namprd05.prod.outlook.com>

Hello,

I have some problems to sort a large data table. In particular, I would like to sort a data table in such a way that the duplicated values in two columns are disposed one below the other and if possible in an ascending order (especially for the column "Date"). An example with a short data table and associated responses are showed in  http://stackoverflow.com/questions/38879961/sort-a-data-table-with-specific-value-order) . However, the proposed solutions don't work with this data table. For example, the line 24 with the value 318880 for Tag1 is not below the line 8.

[http://cdn.sstatic.net/Sites/stackoverflow/img/apple-touch-icon at 2.png?v=73d79a89bded&a]<http://stackoverflow.com/questions/38879961/sort-a-data-table-with-specific-value-order>

Sort a data table with specific value order<http://stackoverflow.com/questions/38879961/sort-a-data-table-with-specific-value-order>
stackoverflow.com
I have a data table: DT <- data.table(Tag1 = c(22,253,6219,6219,252862,252864,312786,312812), Tag2 = c(22,255,6220,252857,252863,252865,251191,252863), Date= a...



DT <- data.table(Tag1 = c(252860, 252862, 312812, 252864, 252866, 252868, 252870, 318880, 252872, 252874, 252876, 252878, 252880, 252880, 252881, 252883,252885, 252887, 311264, 252889, 252889, 252892, 318879, 318880, 318881), Tag2 = c(252861, 252863, 252863, 252865, 252867, 252869, 252871, 252871, 252873,252875, 252877, 252879, 414611, 905593, 252882, 252884, 252886, 252888, 252888, 252890, 318904, 252893, 318878, 414547, 318882), Date = as.Date(as.character(c("9/6/2002","9/6/2002", "9/5/2003", "9/6/2002", "9/6/2002", "9/6/2002", "9/6/2002", "10/8/2003", "9/6/2002", "9/6/2002", "9/6/2002", "9/6/2002", "10/5/2004",

"9/6/2002", "9/6/2002", "9/6/2002", "9/10/2002", "9/10/2002", "7/15/2003", "9/10/2002", "10/15/2003", "9/10/2002", "10/8/2003", "9/29/2004","10/8/2003")),format = "%m/%d/%Y"))

setcolorder(dt1 <- DT[order(-Date)][order(Tag1), .SD, by = Tag2], colnames(DT))

> dt1

      Tag1   Tag2       Date

 1: 252860 252861 2002-09-06

 2: 252862 252863 2002-09-06

 3: 312812 252863 2003-09-05

 4: 252864 252865 2002-09-06

 5: 252866 252867 2002-09-06

 6: 252868 252869 2002-09-06

 7: 252870 252871 2002-09-06

 8: 318880 252871 2003-10-08

 9: 252872 252873 2002-09-06

10: 252874 252875 2002-09-06

11: 252876 252877 2002-09-06

12: 252878 252879 2002-09-06

13: 252880 414611 2004-10-05

14: 252880 905593 2002-09-06

15: 252881 252882 2002-09-06

16: 252883 252884 2002-09-06

17: 252885 252886 2002-09-10

18: 252887 252888 2002-09-10

19: 311264 252888 2003-07-15

20: 252889 318904 2003-10-15

21: 252889 252890 2002-09-10

22: 252892 252893 2002-09-10

23: 318879 318878 2003-10-08

24: 318880 414547 2004-09-29

25: 318881 318882 2003-10-08


Thanks a lot for your time.

Have a nice day

Nell


	[[alternative HTML version deleted]]


From wsp at uwm.edu  Thu Aug 11 18:34:36 2016
From: wsp at uwm.edu (Walker Pedersen)
Date: Thu, 11 Aug 2016 11:34:36 -0500
Subject: [R] Reporting results from phia
Message-ID: <CAAb_rUm0AoH0iALr=_1NuDfMv361TJmfYYp8cmMrUmff0QZ4-w@mail.gmail.com>

Hi R community,

I submitted this question to cross validate, but didn't get any
answers.  Hoping someone on here can give me some clarification.

If I understand the phia documentation correctly, when using
testInteractions for factors, the value it returns is a contrast of
adjusted means, but if the "slope" argument is included, it is then
returning a contrast between two slopes, which I interpret to mean a
parameter coefficient. Is this correct?

So if I run:

testInteractions(model, pairwise="Factor")

and get:


P-value adjustment method: holm
                                       Value Df Chisq Pr(>Chisq)
ConditionA-ConditionB 0.059987  1 1.453     0.2281

The correct way to report this would be: Condition A was not
significantly higher than condition B, m = .06, X^2(1) = 1.45, p =
.23.


But if I run:


testInteractions(model, slope="Covariate", pairwise="Factor")


and get:


Adjusted slope for Covariate
Chisq Test:
P-value adjustment method: holm
                                          Value Df  Chisq Pr(>Chisq)
ConditionA-ConditionB -0.0094811  1 1.3427     0.2466


Then the correct way to report this would be: The slope for Covariate
was not significantly different for condition A and condition B, b =
-.009, X^2(1) = 1.34, p = .25.

Is this correct? The fact that they both are simply labelled "Value"
makes me second guess this interpretation as it seems to me to be
implying that they represent the same type of statistic...

I am using the lmer function in lme4 to fit this model, if that makes
any difference.

Thanks!


From Mihai.Mirauta at bafin.de  Thu Aug 11 19:45:48 2016
From: Mihai.Mirauta at bafin.de (Mihai.Mirauta at bafin.de)
Date: Thu, 11 Aug 2016 17:45:48 +0000
Subject: [R] Appending Data to a .csv File
Message-ID: <87A0221A59DE694A9C954687E34E740A6CB3C334@BABWNA05.office.dir>

Hallo,

For the moment I have a relatively large number of portfolios of different companies (say, company A with portfolios 1 to 10, company B with portfolio1 1 to 15 and so on to company Z with Portfolios 1 to 5). What I am doing, is loading these simulations out of csv  (relatively large amount of data) for each of the company and calculating the quantiles, for example. I write the data for company A (say write.csv(quantiles, ?Quantiles.csv?).

Now I want to write the quantile results for company B into the same file, adding thus to the data for company A. I have tried to use write.csv(quantilesB, ?Quantiles.csv?, append=TRUE) but I receive the error   ?Versuch ignoriert 'append' zu setzen? ? it seems to ignore the append. It is not so important to me if that is a csv data or an RData format, as long as I can run the program for company A, put the results for A in file ?Quantiles?, than run the program for B, add the results for B in the file and so on for company C, D etc.

Thank you for your help,

Mihai


F?r die rechtswirksame ?bermittlung elektronischer Dokumente im Sinne des ? 3a VwVfG er?ffnet die BaFin den Zugang ausschlie?lich ?ber folgende Kommunikationsadressen:

? F?r die ?bermittlung qualifiziert elektronisch signierter Dokumente per E-Mail: qes-posteingang at bafin.de
? F?r die ?bermittlung per De-Mail: poststelle at bafin.de-mail.de

Andere E-Mail-Adressen der BaFin stehen lediglich f?r die allgemeine Kommunikation, jedoch ausdr?cklich nicht f?r eine rechtsverbindliche, die gesetzliche Schriftform ersetzende Kommunikation zur Verf?gung.

Eingehende elektronische Dokumente m?ssen l?ngere Zeit archiviert werden (Langzeitaufbewahrung). Deshalb bittet die BaFin darum, bei der rechtsverbindlichen, die gesetzliche Schriftform ersetzenden Kommunikation ?ber die E-Mail-Adresse qes-posteingang at bafin.de ausschlie?lich qualifiziert elektronisch signierte PDF-Dokumente der Spezifikation PDF/A mit eingebetteter Signatur zu ?bersenden.

Diese E-Mail kann vertrauliche und/oder rechtlich gesch?tzte Informationen enthalten. Sollten Sie nicht der richtige Adressat sein oder diese E-Mail irrt?mlich erhalten haben, informieren Sie bitte sofort den Absender und vernichten diese E-Mail. Das unerlaubte Kopieren sowie die unbefugte Weitergabe dieser E-Mail ist nicht gestattet. Der Inhalt dieser E-Mail kann nicht zu einer irgendwie gearteten Verpflichtung zu Lasten der BaFin ausgelegt werden.

This e-mail may contain confidential and/or privileged information. If you are not the intended recipient or have received this e-mail in error, please notify the sender immediately and destroy this e-mail. Any unauthorized copying, disclosure or distribution of the material in this e-mail is strictly forbidden. The content of this e-mail shall not be construed as constituting any kind of obligation on the part of BaFin.

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Thu Aug 11 20:29:02 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Thu, 11 Aug 2016 19:29:02 +0100
Subject: [R] Appending Data to a .csv File
In-Reply-To: <87A0221A59DE694A9C954687E34E740A6CB3C334@BABWNA05.office.dir>
References: <87A0221A59DE694A9C954687E34E740A6CB3C334@BABWNA05.office.dir>
Message-ID: <20160811192902.Horde.nJ_GGTouEOJXrMPuBDKxClA@mail.sapo.pt>

Hello,

Have you tried ?write.table?
write.csv is a wrapper for write.table with the appropriate settings  
such as sep = ",", etc.
 From the help page for write.csv:

"These wrappers are deliberately inflexible: they are designed to  
ensure that the correct conventions are used to write a valid file.  
Attempts to change append, col.names, sep, dec or qmethod are ignored,  
with a warning. "

So you must use write.table, with a call for file A, with col.names  
set to TRUE, then subsequent calls with col.names = FALSE.

Read the help page carefully, and try the different options.

Hope this helps,

Rui Barradas


Quoting Mihai.Mirauta at bafin.de:

> Hallo,
>
> For the moment I have a relatively large number of portfolios of  
> different companies (say, company A with portfolios 1 to 10, company  
> B with portfolio1 1 to 15 and so on to company Z with Portfolios 1  
> to 5). What I am doing, is loading these simulations out of csv   
> (relatively large amount of data) for each of the company and  
> calculating the quantiles, for example. I write the data for company  
> A (say write.csv(quantiles, ?Quantiles.csv?).
>
> Now I want to write the quantile results for company B into the same  
> file, adding thus to the data for company A. I have tried to use  
> write.csv(quantilesB, ?Quantiles.csv?, append=TRUE) but I receive  
> the error   ?Versuch ignoriert 'append' zu setzen? ? it seems to  
> ignore the append. It is not so important to me if that is a csv  
> data or an RData format, as long as I can run the program for  
> company A, put the results for A in file ?Quantiles?, than run the  
> program for B, add the results for B in the file and so on for  
> company C, D etc.
>
> Thank you for your help,
>
> Mihai
>
>
> F?r die rechtswirksame ?bermittlung elektronischer Dokumente im  
> Sinne des ? 3a VwVfG er?ffnet die BaFin den Zugang ausschlie?lich  
> ?ber folgende Kommunikationsadressen:
>
> ? F?r die ?bermittlung qualifiziert elektronisch signierter  
> Dokumente per E-Mail: qes-posteingang at bafin.de
> ? F?r die ?bermittlung per De-Mail: poststelle at bafin.de-mail.de
>
> Andere E-Mail-Adressen der BaFin stehen lediglich f?r die allgemeine  
> Kommunikation, jedoch ausdr?cklich nicht f?r eine  
> rechtsverbindliche, die gesetzliche Schriftform ersetzende  
> Kommunikation zur Verf?gung.
>
> Eingehende elektronische Dokumente m?ssen l?ngere Zeit archiviert  
> werden (Langzeitaufbewahrung). Deshalb bittet die BaFin darum, bei  
> der rechtsverbindlichen, die gesetzliche Schriftform ersetzenden  
> Kommunikation ?ber die E-Mail-Adresse qes-posteingang at bafin.de  
> ausschlie?lich qualifiziert elektronisch signierte PDF-Dokumente der  
> Spezifikation PDF/A mit eingebetteter Signatur zu ?bersenden.
>
> Diese E-Mail kann vertrauliche und/oder rechtlich gesch?tzte  
> Informationen enthalten. Sollten Sie nicht der richtige Adressat  
> sein oder diese E-Mail irrt?mlich erhalten haben, informieren Sie  
> bitte sofort den Absender und vernichten diese E-Mail. Das  
> unerlaubte Kopieren sowie die unbefugte Weitergabe dieser E-Mail ist  
> nicht gestattet. Der Inhalt dieser E-Mail kann nicht zu einer  
> irgendwie gearteten Verpflichtung zu Lasten der BaFin ausgelegt  
> werden.
>
> This e-mail may contain confidential and/or privileged...{{dropped:22}}


From smurray444 at hotmail.com  Thu Aug 11 22:24:38 2016
From: smurray444 at hotmail.com (Steve Murray)
Date: Thu, 11 Aug 2016 20:24:38 +0000
Subject: [R] Conditional Execution Error
Message-ID: <VI1PR02MB11990DEBC0EB0054120C6B3A881E0@VI1PR02MB1199.eurprd02.prod.outlook.com>

Dear all,


Please could someone explain why 'Version 1' of the code below works, but 'Version 2' produces an error (albeit following the correct output)?


#Version 1

h <- 10
j <- -5

if(h < j) {
print("statement is true")
} else {
while (h >= j) {
print(h)
h <- h - 1
}
}


#Version 2

h <- 10
j <- -5

ifelse(h < j, "statement is true", while(h >= j) {
print(h)
h <- h - 1
}
)



If anyone has an explanation and solution (for avoiding the error), then I'd be pleased to hear it.


Many thanks,

Steve


	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Thu Aug 11 22:39:21 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 11 Aug 2016 20:39:21 +0000
Subject: [R] Conditional Execution Error
Message-ID: <D3D22FB3.182EC2%macqueen1@llnl.gov>

The simplest explanation is that
  ifelse( , , )
is not designed or intended to be an alternative way to do
  if () {} else {}

ifelse is not designed for conditional execution.

Read the help page for ifelse for an explanation of what it IS designed to
do.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/11/16, 1:24 PM, "R-help on behalf of Steve Murray"
<r-help-bounces at r-project.org on behalf of smurray444 at hotmail.com> wrote:

>Dear all,
>
>
>Please could someone explain why 'Version 1' of the code below works, but
>'Version 2' produces an error (albeit following the correct output)?
>
>
>#Version 1
>
>h <- 10
>j <- -5
>
>if(h < j) {
>print("statement is true")
>} else {
>while (h >= j) {
>print(h)
>h <- h - 1
>}
>}
>
>
>#Version 2
>
>h <- 10
>j <- -5
>
>ifelse(h < j, "statement is true", while(h >= j) {
>print(h)
>h <- h - 1
>}
>)
>
>
>
>If anyone has an explanation and solution (for avoiding the error), then
>I'd be pleased to hear it.
>
>
>Many thanks,
>
>Steve
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu Aug 11 22:59:40 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 11 Aug 2016 20:59:40 +0000
Subject: [R] Conditional Execution Error
In-Reply-To: <D3D22FB3.182EC2%macqueen1@llnl.gov>
References: <D3D22FB3.182EC2%macqueen1@llnl.gov>
Message-ID: <455b55f9389940daab9bfe0f49889675@exch-2p-mbx-t2.ads.tamu.edu>

And as a function, ifelse() wants to return a replacement value and when h < j is FALSE, your code does not return anything. Like most things in R, you can bend it to your will, but there will probably be consequences:

> h <- 10
> j <- -5
> ifelse(h < j, "statement is true", {while(h >= j) {
+ print(h)
+ h <- h - 1 }
+ "done"}
+ )
[1] 10
[1] 9
[1] 8
[1] 7
[1] 6
[1] 5
[1] 4
[1] 3
[1] 2
[1] 1
[1] 0
[1] -1
[1] -2
[1] -3
[1] -4
[1] -5
[1] "done"


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of MacQueen, Don
Sent: Thursday, August 11, 2016 3:39 PM
To: Steve Murray; r-help at r-project.org
Subject: Re: [R] Conditional Execution Error

The simplest explanation is that
  ifelse( , , )
is not designed or intended to be an alternative way to do
  if () {} else {}

ifelse is not designed for conditional execution.

Read the help page for ifelse for an explanation of what it IS designed to
do.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/11/16, 1:24 PM, "R-help on behalf of Steve Murray"
<r-help-bounces at r-project.org on behalf of smurray444 at hotmail.com> wrote:

>Dear all,
>
>
>Please could someone explain why 'Version 1' of the code below works, but
>'Version 2' produces an error (albeit following the correct output)?
>
>
>#Version 1
>
>h <- 10
>j <- -5
>
>if(h < j) {
>print("statement is true")
>} else {
>while (h >= j) {
>print(h)
>h <- h - 1
>}
>}
>
>
>#Version 2
>
>h <- 10
>j <- -5
>
>ifelse(h < j, "statement is true", while(h >= j) {
>print(h)
>h <- h - 1
>}
>)
>
>
>
>If anyone has an explanation and solution (for avoiding the error), then
>I'd be pleased to hear it.
>
>
>Many thanks,
>
>Steve
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Aug 11 23:05:22 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 11 Aug 2016 17:05:22 -0400
Subject: [R] Continuation-parsing / trampoline / infinite recursion
 problem
In-Reply-To: <51c27e91-a8d7-d4e8-a5a2-d7994b27b763@gmail.com>
References: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>
	<etPan.57ab1663.496f94a7.13177@birc.au.dk>
	<0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>
	<bc6c569e-32c2-eea5-f291-de13344b96d8@gmail.com>
	<42A8876E-E948-4196-BD6E-0A3B841FA333@birc.au.dk>
	<51c27e91-a8d7-d4e8-a5a2-d7994b27b763@gmail.com>
Message-ID: <4837b9b4-1d17-fbb5-3d88-699d2acbbe83@gmail.com>

On 10/08/2016 1:28 PM, Duncan Murdoch wrote:
> On 10/08/2016 1:10 PM, Thomas Mailund wrote:
>> That did the trick!
>>
>> I was so focused on not evaluating the continuation that I completely forgot that the thunk could hold an unevaluated value? now it seems to be working for all the various implementations I have been playing around with.
>>
>> I think I still need to wrap my head around *why* the forced evaluation is necessary there, but I will figure that out when my tired brain has had a little rest.
>
> The original version
>
> make_thunk <- function(f, ...) function() f(?)
>
> says to construct a new function whose body evaluates the expression
> f(...).  It never evaluates f nor ... , so they don't get evaluated
> until the first time you evaluate that new function.
>
> My version containing list(...) forces evaluation of ... .  It would
> have been even better to use
>
> make_thunk <- function(f, ...) { list(f, ...); function() f(?) }
>
> because that forces evaluation of both arguments.
>
> I suspect you would have problems with
>
> make_thunk <- function(f, ...) function() do.call(f, list(...))
>
> for exactly the same reasons as the original; I'm surprised that you
> found it appears to work.

I have done some experimentation, and am unable to reproduce the 
behaviour you described.  Using do.call() doesn't affect things.

Duncan Murdoch


From farzana.akbari2013 at gmail.com  Thu Aug 11 23:13:25 2016
From: farzana.akbari2013 at gmail.com (farzana akbari)
Date: Thu, 11 Aug 2016 11:13:25 -1000
Subject: [R] structure breakpoint for panel data
Message-ID: <CAL3rq9hzNnrW38eiABC0-g4JPManM-5C9WGkbBPXe0nz5hpdsQ@mail.gmail.com>

in the name of God

hi

can you help me and tell which package and function can calculate structure
breakpoint for panel data

best regards

	[[alternative HTML version deleted]]


From mailund at birc.au.dk  Thu Aug 11 23:15:38 2016
From: mailund at birc.au.dk (Thomas Mailund)
Date: Thu, 11 Aug 2016 21:15:38 +0000
Subject: [R] Continuation-parsing / trampoline / infinite recursion
 problem
In-Reply-To: <4837b9b4-1d17-fbb5-3d88-699d2acbbe83@gmail.com>
References: <etPan.57aa3591.69c463b8.1304f@birc.au.dk>
	<etPan.57ab1663.496f94a7.13177@birc.au.dk>
	<0549BE4C-6017-484D-8C2C-D08BE510CD42@birc.au.dk>
	<bc6c569e-32c2-eea5-f291-de13344b96d8@gmail.com>
	<42A8876E-E948-4196-BD6E-0A3B841FA333@birc.au.dk>
	<51c27e91-a8d7-d4e8-a5a2-d7994b27b763@gmail.com>
	<4837b9b4-1d17-fbb5-3d88-699d2acbbe83@gmail.com>
Message-ID: <etPan.57aceaf9.24bfc93b.135@birc.au.dk>

I don?t know? that was the behaviour I had yesterday, but on the laptop where I was doing the experiments I updated R from 3.2 to 3.3 earlier today and now the original make_thunk

make_thunk <- function(f, ?) function() f(?)

also works for me.

I don?t know what else I can say to that :)

Cheers
Thomas




On 11 August 2016 at 23:05:29, Duncan Murdoch (murdoch.duncan at gmail.com<mailto:murdoch.duncan at gmail.com>) wrote:

On 10/08/2016 1:28 PM, Duncan Murdoch wrote:
> On 10/08/2016 1:10 PM, Thomas Mailund wrote:
>> That did the trick!
>>
>> I was so focused on not evaluating the continuation that I completely forgot that the thunk could hold an unevaluated value? now it seems to be working for all the various implementations I have been playing around with.
>>
>> I think I still need to wrap my head around *why* the forced evaluation is necessary there, but I will figure that out when my tired brain has had a little rest.
>
> The original version
>
> make_thunk <- function(f, ...) function() f(?)
>
> says to construct a new function whose body evaluates the expression
> f(...). It never evaluates f nor ... , so they don't get evaluated
> until the first time you evaluate that new function.
>
> My version containing list(...) forces evaluation of ... . It would
> have been even better to use
>
> make_thunk <- function(f, ...) { list(f, ...); function() f(?) }
>
> because that forces evaluation of both arguments.
>
> I suspect you would have problems with
>
> make_thunk <- function(f, ...) function() do.call(f, list(...))
>
> for exactly the same reasons as the original; I'm surprised that you
> found it appears to work.

I have done some experimentation, and am unable to reproduce the
behaviour you described. Using do.call() doesn't affect things.

Duncan Murdoch


	[[alternative HTML version deleted]]


From ross.chapman at ecogeonomix.com  Fri Aug 12 09:24:04 2016
From: ross.chapman at ecogeonomix.com (ross.chapman at ecogeonomix.com)
Date: Fri, 12 Aug 2016 17:24:04 +1000
Subject: [R] cpquery problem
Message-ID: <005a01d1f46a$82b02e30$88108a90$@ecogeonomix.com>

Hi Marco

 

Thanks again for your comments.

 

First, I used the term "EST = y" in my original query as a shorthand, I have
used the terms "K1", "M1", and "M2" for all actual queries.

 

If I might expand on the outputs I am getting, I have run predict for the
term "ABW" on a data vector with the following values

 

EST M1, TR 9,  FFB 24.625, BN 67549,  NDM 2.75,  PDM 0.156, KDM 0.65, RF
2297, RF.1 3203, RN.2 1939, NPKM 517.8402, NPKM.1 492.8674, NPKM.2 525.6392

I obtain a predicted output of 15.022 for the node ABW, which is good.

 

I then entered the same data into cpquery and with an expected value for ABW
that spans the predicted value as follows:

cpquery(fullFitted,event=((ABW>10) & (ABW<20)), evidence=list(EST = "M1",
TR = 9,

FFB = 24.625,

BN = 67549,

PDM = 0.156,

NDM = 2.75,

KDM = 0.65,

NPKM = 517.8402,

NPKM.2 = 525.6392, 

NPKM.1 = 492.8674,

RF = 2297, 

RF.1 = 3203,

RF.2 = 1939),

n=10^6, method =  "lw")

 

and cpquery returned a probability  of 0.

 

However, if I change the query to a data vector where EST = K1 (EST can take
three values, K1, M1, M2) I get comparable results from predict and cpquery.

 

For example running predict returns a value of 11.382 from the following
values:

 

EST K1, TR 9,  FFB 19.638, BN 95942,  NDM 3,  PDM 0.171, KDM 0.84, RF 2989,
RF.1 2482, RN.2 2169, NPKM 497.2858, NPKM.1 446.3927, NPKM.2 492.6883

In this instance, running a cpquery for an event that spans the predicted
ABW value returns a high probability of 0.73.

cpquery(fullFitted,event=((ABW>10) & (ABW<13)), evidence=list(EST = "K1",
TREEAGE = 9,

FFB = 19.63884,

BN = 95942,

PDM = 0.171,

NDM = 3,

KDM = 0.84,

NPKM = 497.2858,

NPKMg = 492.6883, SUM_NPKMg_IN.1=446.3927,

RN = 2989, 

RF.1 = 2482,

RF.2 = 2169),

n=10^6, method =  "lw")

 

 

I am clearly missing something about the way that cpquery is computed or
deployed.  Can you advise me how I might deconstruct the cpquery analyses to
better understand the results that I am getting?  In particular, I would
like to know why the cpquery is not giving a probability that I expect with
EST = M1.  Is there something wrong with my use of the cpquery function? Are
there steps that I can take to trace the source of the observed behaviour
and perhaps understand the output of the cpquery when EST = M1?

Thanks for your  continued assistance.

Ross

 


	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Fri Aug 12 09:50:35 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 12 Aug 2016 08:50:35 +0100
Subject: [R] structure breakpoint for panel data
In-Reply-To: <CAL3rq9hzNnrW38eiABC0-g4JPManM-5C9WGkbBPXe0nz5hpdsQ@mail.gmail.com>
References: <CAL3rq9hzNnrW38eiABC0-g4JPManM-5C9WGkbBPXe0nz5hpdsQ@mail.gmail.com>
Message-ID: <b7a0a9e6-5739-2028-3b8a-aa86bca7bda9@dewey.myzen.co.uk>

There are many packages with names like breakpoint, segmented, 
strucchange, ....

I have no idea which of them if any will meet your use case.

On 11/08/2016 22:13, farzana akbari wrote:
> in the name of God
>
> hi
>
> can you help me and tell which package and function can calculate structure
> breakpoint for panel data
>
> best regards
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From shivipmp82 at gmail.com  Fri Aug 12 11:10:49 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Fri, 12 Aug 2016 14:40:49 +0530
Subject: [R] glm.fit: fitted probabilities numerically 0 or 1 occurred &
 glm.fit: algorithm did not converge
Message-ID: <CAB=p7SreQJRULZ-j3mDmJk5vWAMRaM1b66WYy5k9Kd=sWD3rDQ@mail.gmail.com>

Hi Team,

I am creating *my first* Logistic regression on R Studio. I am working on a
C-SAT data where rating (score) 0-8 is a dis-sat whereas 9-10 are SAT. As
these were in numeric form so i had as below created 2 classes:

new$survey[new$score>=0 & new$score<=8]<- 0
new$survey[new$score>=9]<- 1
This works fine however the class still shows as "numeric" and levels shows
as "NULL". Do i still need to use "as.factor" to let R know these are
categorical variables.

Also i have used the below code to run a logistic regression with all the
possible predictor variables:
glm.fit= glm(survey ~ support_cat + region+ support_lvl+ skill_group+
application_area+ functional_area+
          repS+ case_age+ case_status+ severity_level+
          sla_status+ delivery_segmentation, data = SFDC, family = binomial)

But it throws an error:-
Warning messages:
1: glm.fit: algorithm did not converge
2: glm.fit: fitted probabilities numerically 0 or 1 occurred

I checked online for the error and it says:
"glm() uses an iterative re-weighted least squares algorithm. The algorithm
hit the maximum number of allowed iterations before signalling convergence.
The default,
documented in ?glm.control is 25."

Kindly suggest on the above case and if i have to change my outcome var as
as.factor.

Thank you, Shivi

	[[alternative HTML version deleted]]


From unger at helmholtz-muenchen.de  Fri Aug 12 12:36:19 2016
From: unger at helmholtz-muenchen.de (Dr. Kristian Unger)
Date: Fri, 12 Aug 2016 12:36:19 +0200
Subject: [R] curl problem in install.packages
Message-ID: <CD67F5DF-9871-4BC2-9100-433B78B0E9B1@helmholtz-muenchen.de>

Hi there,

I have just compiled R 3.3.1 on my SuSE SLES 11 SP2 server. All works fine but I cannot use the install.packages function since there is an issue with the underlying curl command which requires a ca certificate in order to download files. 

1: In download.file(url, destfile = f, quiet = TRUE) :
  URL 'https://cran.r-project.org/CRAN_mirrors.csv': status was 'Peer certificate cannot be authenticated with given CA certificates'

Of course, the problem can be bypassed by manually installing packages by only using http:// instead of https:// links but I am hoping there is a more efficient solution for this problem.

Can you help?

Best wishes

Kristian

Arbeitsgruppenleiter Integrative Biologie / Head of Integrative Biology Group
Stellvertretender Abteilungsleiter / Deputy Head of Research Unit
Abteilung Strahlenzytogenetik / Research Unit Radiation Cytogenetics 

Tel.: +49-89-3187-3515
Skype: kristian.unger


Helmholtz Zentrum Muenchen

Deutsches Forschungszentrum fuer Gesundheit und Umwelt (GmbH)

Ingolstaedter Landstr. 1

85764 Neuherberg

www.helmholtz-muenchen.de

Aufsichtsratsvorsitzende: MinDir'in Baerbel Brumme-Bothe

Geschaeftsfuehrer: Prof. Dr. Guenther Wess, Dr. Alfons Enhsen

Registergericht: Amtsgericht Muenchen HRB 6466

USt-IdNr: DE 129521671


	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Fri Aug 12 16:00:58 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 12 Aug 2016 15:00:58 +0100
Subject: [R] glm.fit: fitted probabilities numerically 0 or 1 occurred &
 glm.fit: algorithm did not converge
In-Reply-To: <CAB=p7SreQJRULZ-j3mDmJk5vWAMRaM1b66WYy5k9Kd=sWD3rDQ@mail.gmail.com>
References: <CAB=p7SreQJRULZ-j3mDmJk5vWAMRaM1b66WYy5k9Kd=sWD3rDQ@mail.gmail.com>
Message-ID: <7a804ec9-ea4f-8c83-1104-01f3f7959b99@dewey.myzen.co.uk>

Dear Shivi

Can you show us the output?

And please do not post in HTML as it will mangle your post into 
unreadability.

On 12/08/2016 10:10, Shivi Bhatia wrote:
> Hi Team,
>
> I am creating *my first* Logistic regression on R Studio. I am working on a
> C-SAT data where rating (score) 0-8 is a dis-sat whereas 9-10 are SAT. As
> these were in numeric form so i had as below created 2 classes:
>
> new$survey[new$score>=0 & new$score<=8]<- 0
> new$survey[new$score>=9]<- 1
> This works fine however the class still shows as "numeric" and levels shows
> as "NULL". Do i still need to use "as.factor" to let R know these are
> categorical variables.
>
> Also i have used the below code to run a logistic regression with all the
> possible predictor variables:
> glm.fit= glm(survey ~ support_cat + region+ support_lvl+ skill_group+
> application_area+ functional_area+
>           repS+ case_age+ case_status+ severity_level+
>           sla_status+ delivery_segmentation, data = SFDC, family = binomial)
>
> But it throws an error:-
> Warning messages:
> 1: glm.fit: algorithm did not converge
> 2: glm.fit: fitted probabilities numerically 0 or 1 occurred
>
> I checked online for the error and it says:
> "glm() uses an iterative re-weighted least squares algorithm. The algorithm
> hit the maximum number of allowed iterations before signalling convergence.
> The default,
> documented in ?glm.control is 25."
>
> Kindly suggest on the above case and if i have to change my outcome var as
> as.factor.
>
> Thank you, Shivi
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From nithya.dayalan at merck.com  Fri Aug 12 12:53:03 2016
From: nithya.dayalan at merck.com (Dayalan, Nithya)
Date: Fri, 12 Aug 2016 06:53:03 -0400
Subject: [R] R Package installation
Message-ID: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C31F@USCTMXP51002.merck.com>

Hi Team,

We are receiving the below message while updating the package. Please help.

> install.packages("parallel", lib="D:/Program Files/R/R-3.2.5/library")
Warning: unable to access index for repository https://cran.fhcrc.org/src/contrib:
  cannot open URL 'https://cran.fhcrc.org/src/contrib/PACKAGES'
Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES'
Warning: unable to access index for repository https://cran.fhcrc.org/bin/windows/contrib/3.2:
  cannot open URL 'https://cran.fhcrc.org/bin/windows/contrib/3.2/PACKAGES'
Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2:
  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/PACKAGES'
Warning messages:
1: package 'parallel' is not available (for R version 3.2.5)
2: package 'parallel' is a base package, and should not be updated
>


Thanks & Regards,
Nithya Dayalan
AMS MRL DPS | HCL @ Merck
E-mail: nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com>
Tel#+91 44 61053951| Mobile +91 8754232975

Notice:  This e-mail message, together with any attachme...{{dropped:14}}


From jdnewmil at dcn.davis.ca.us  Fri Aug 12 16:43:21 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 12 Aug 2016 07:43:21 -0700
Subject: [R] R Package installation
In-Reply-To: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C31F@USCTMXP51002.merck.com>
References: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C31F@USCTMXP51002.merck.com>
Message-ID: <DB1B79CC-A933-4EC2-956B-C78D060349CC@dcn.davis.ca.us>

Choose

A

Different

Mirror
-- 
Sent from my phone. Please excuse my brevity.

On August 12, 2016 3:53:03 AM PDT, "Dayalan, Nithya" <nithya.dayalan at merck.com> wrote:
>Hi Team,
>
>We are receiving the below message while updating the package. Please
>help.
>
>> install.packages("parallel", lib="D:/Program
>Files/R/R-3.2.5/library")
>Warning: unable to access index for repository
>https://cran.fhcrc.org/src/contrib:
>  cannot open URL 'https://cran.fhcrc.org/src/contrib/PACKAGES'
>Warning: unable to access index for repository
>http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
>cannot open URL
>'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES'
>Warning: unable to access index for repository
>https://cran.fhcrc.org/bin/windows/contrib/3.2:
>cannot open URL
>'https://cran.fhcrc.org/bin/windows/contrib/3.2/PACKAGES'
>Warning: unable to access index for repository
>http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2:
>cannot open URL
>'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/PACKAGES'
>Warning messages:
>1: package 'parallel' is not available (for R version 3.2.5)
>2: package 'parallel' is a base package, and should not be updated
>>
>
>
>Thanks & Regards,
>Nithya Dayalan
>AMS MRL DPS | HCL @ Merck
>E-mail: nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com>
>Tel#+91 44 61053951| Mobile +91 8754232975
>
>Notice:  This e-mail message, together with any
>attachme...{{dropped:14}}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Aug 12 16:51:24 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 Aug 2016 07:51:24 -0700
Subject: [R] R Package installation
In-Reply-To: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C31F@USCTMXP51002.merck.com>
References: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C31F@USCTMXP51002.merck.com>
Message-ID: <C1E2CED8-B282-40CF-81E5-7C7A5E73DEFB@comcast.net>


> On Aug 12, 2016, at 3:53 AM, Dayalan, Nithya <nithya.dayalan at merck.com> wrote:
> 
> Hi Team,
> 
> We are receiving the below message while updating the package. Please help.
> 
>> install.packages("parallel", lib="D:/Program Files/R/R-3.2.5/library")
> Warning: unable to access index for repository https://cran.fhcrc.org/src/contrib:
>  cannot open URL 'https://cran.fhcrc.org/src/contrib/PACKAGES'
> Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
>  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES'
> Warning: unable to access index for repository https://cran.fhcrc.org/bin/windows/contrib/3.2:
>  cannot open URL 'https://cran.fhcrc.org/bin/windows/contrib/3.2/PACKAGES'
> Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2:
>  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/PACKAGES'
> Warning messages:
> 1: package 'parallel' is not available (for R version 3.2.5)
> 2: package 'parallel' is a base package, and should not be updated


In most case it is the first warning or error that is most meaningful, but in this case it is the last one.

The `installed.packages` function can tell you which packages are in the Bases" category:

plic <- installed.packages( .Library, priority = "base")

> rownames(plic)
 [1] "base"      "compiler"  "datasets"  "graphics"  "grDevices" "grid"      "methods"  
 [8] "parallel"  "splines"   "stats"     "stats4"    "tcltk"     "tools"     "utils"    


Updating them requires updating your R version, which is what you should do now.

-- 
David.



>> 
> 
> 
> Thanks & Regards,
> Nithya Dayalan
> AMS MRL DPS | HCL @ Merck
> E-mail: nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com>
> Tel#+91 44 61053951| Mobile +91 8754232975
> 
> Notice:  This e-mail message, together with any attachme...{{dropped:14}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From shivipmp82 at gmail.com  Fri Aug 12 16:58:54 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Fri, 12 Aug 2016 20:28:54 +0530
Subject: [R] glm.fit: fitted probabilities numerically 0 or 1 occurred &
 glm.fit: algorithm did not converge
In-Reply-To: <7a804ec9-ea4f-8c83-1104-01f3f7959b99@dewey.myzen.co.uk>
References: <CAB=p7SreQJRULZ-j3mDmJk5vWAMRaM1b66WYy5k9Kd=sWD3rDQ@mail.gmail.com>
	<7a804ec9-ea4f-8c83-1104-01f3f7959b99@dewey.myzen.co.uk>
Message-ID: <CAB=p7SoRxiW4EQvAr3K2aGXBknMu_Y7xoFbdefrJfS=jRfmdug@mail.gmail.com>

Hi Michael,

There is no output as the model does not generate any coefficients and
simply throws this error.

I hope you are not asking for a reproducible example.

On Fri, Aug 12, 2016 at 7:30 PM, Michael Dewey <lists at dewey.myzen.co.uk>
wrote:

> Dear Shivi
>
> Can you show us the output?
>
> And please do not post in HTML as it will mangle your post into
> unreadability.
>
> On 12/08/2016 10:10, Shivi Bhatia wrote:
>
>> Hi Team,
>>
>> I am creating *my first* Logistic regression on R Studio. I am working on
>> a
>>
>> C-SAT data where rating (score) 0-8 is a dis-sat whereas 9-10 are SAT. As
>> these were in numeric form so i had as below created 2 classes:
>>
>> new$survey[new$score>=0 & new$score<=8]<- 0
>> new$survey[new$score>=9]<- 1
>> This works fine however the class still shows as "numeric" and levels
>> shows
>> as "NULL". Do i still need to use "as.factor" to let R know these are
>> categorical variables.
>>
>> Also i have used the below code to run a logistic regression with all the
>> possible predictor variables:
>> glm.fit= glm(survey ~ support_cat + region+ support_lvl+ skill_group+
>> application_area+ functional_area+
>>           repS+ case_age+ case_status+ severity_level+
>>           sla_status+ delivery_segmentation, data = SFDC, family =
>> binomial)
>>
>> But it throws an error:-
>> Warning messages:
>> 1: glm.fit: algorithm did not converge
>> 2: glm.fit: fitted probabilities numerically 0 or 1 occurred
>>
>> I checked online for the error and it says:
>> "glm() uses an iterative re-weighted least squares algorithm. The
>> algorithm
>> hit the maximum number of allowed iterations before signalling
>> convergence.
>> The default,
>> documented in ?glm.control is 25."
>>
>> Kindly suggest on the above case and if i have to change my outcome var as
>> as.factor.
>>
>> Thank you, Shivi
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Aug 12 17:06:50 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 12 Aug 2016 08:06:50 -0700
Subject: [R] glm.fit: fitted probabilities numerically 0 or 1 occurred &
 glm.fit: algorithm did not converge
In-Reply-To: <CAB=p7SoRxiW4EQvAr3K2aGXBknMu_Y7xoFbdefrJfS=jRfmdug@mail.gmail.com>
References: <CAB=p7SreQJRULZ-j3mDmJk5vWAMRaM1b66WYy5k9Kd=sWD3rDQ@mail.gmail.com>
	<7a804ec9-ea4f-8c83-1104-01f3f7959b99@dewey.myzen.co.uk>
	<CAB=p7SoRxiW4EQvAr3K2aGXBknMu_Y7xoFbdefrJfS=jRfmdug@mail.gmail.com>
Message-ID: <CAGxFJbSW3YrXuOHHS-t_05VzeetWLNbaH_cfVe76_cgR-UrRcA@mail.gmail.com>

1. No, changing to factor will make no difference.

2. I think that most likely your problem is your model is not
estimable/your design matrix is singular.  You should resolve this by
consulting with a local statistical expert or, if your data set is not
too large or confidential, posting your full dataset using dput() (see
?dput for how to do this).

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 12, 2016 at 7:58 AM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
> Hi Michael,
>
> There is no output as the model does not generate any coefficients and
> simply throws this error.
>
> I hope you are not asking for a reproducible example.
>
> On Fri, Aug 12, 2016 at 7:30 PM, Michael Dewey <lists at dewey.myzen.co.uk>
> wrote:
>
>> Dear Shivi
>>
>> Can you show us the output?
>>
>> And please do not post in HTML as it will mangle your post into
>> unreadability.
>>
>> On 12/08/2016 10:10, Shivi Bhatia wrote:
>>
>>> Hi Team,
>>>
>>> I am creating *my first* Logistic regression on R Studio. I am working on
>>> a
>>>
>>> C-SAT data where rating (score) 0-8 is a dis-sat whereas 9-10 are SAT. As
>>> these were in numeric form so i had as below created 2 classes:
>>>
>>> new$survey[new$score>=0 & new$score<=8]<- 0
>>> new$survey[new$score>=9]<- 1
>>> This works fine however the class still shows as "numeric" and levels
>>> shows
>>> as "NULL". Do i still need to use "as.factor" to let R know these are
>>> categorical variables.
>>>
>>> Also i have used the below code to run a logistic regression with all the
>>> possible predictor variables:
>>> glm.fit= glm(survey ~ support_cat + region+ support_lvl+ skill_group+
>>> application_area+ functional_area+
>>>           repS+ case_age+ case_status+ severity_level+
>>>           sla_status+ delivery_segmentation, data = SFDC, family =
>>> binomial)
>>>
>>> But it throws an error:-
>>> Warning messages:
>>> 1: glm.fit: algorithm did not converge
>>> 2: glm.fit: fitted probabilities numerically 0 or 1 occurred
>>>
>>> I checked online for the error and it says:
>>> "glm() uses an iterative re-weighted least squares algorithm. The
>>> algorithm
>>> hit the maximum number of allowed iterations before signalling
>>> convergence.
>>> The default,
>>> documented in ?glm.control is 25."
>>>
>>> Kindly suggest on the above case and if i have to change my outcome var as
>>> as.factor.
>>>
>>> Thank you, Shivi
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> --
>> Michael
>> http://www.dewey.myzen.co.uk/home.html
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Aug 12 17:18:19 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 Aug 2016 08:18:19 -0700
Subject: [R] R Package installation
In-Reply-To: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C32A@USCTMXP51002.merck.com>
References: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C31F@USCTMXP51002.merck.com>
	<C1E2CED8-B282-40CF-81E5-7C7A5E73DEFB@comcast.net>
	<91DFE13BB89B4F49ADA450B375D0A5AC91A974C32A@USCTMXP51002.merck.com>
Message-ID: <1808A1E0-96E9-4E08-9270-8B00489376C5@comcast.net>


> On Aug 12, 2016, at 7:53 AM, Dayalan, Nithya <nithya.dayalan at merck.com> wrote:
> 
> Hi David,
> 
> Okay thank you, but the error message receiving for other packages.
> 
>> install.packages("Rtsne", lib="D:/Program Files/R/R-3.2.5/library")
> --- Please select a CRAN mirror for use in this session ---
> Error in download.file(url, destfile = f, quiet = TRUE) : 
>  cannot open URL 'https://cran.r-project.org/CRAN_mirrors.csv'
> In addition: Warning message:
> In
>  InternetOpenUrl failed: 'A connection with the server could not be established'
> Warning: unable to access index for repository https://cran.uni-muenster.de/src/contrib:
>  cannot open URL 'https://cran.uni-muenster.de/src/contrib/PACKAGES'
> Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
>  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES'
> Warning: unable to access index for repository https://cran.uni-muenster.de/bin/windows/contrib/3.2:
>  cannot open URL 'https://cran.uni-muenster.de/bin/windows/contrib/3.2/PACKAGES'
> Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2:
>  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/PACKAGES'
> Warning message:
> package 'Rtsne' is not available (for R version 3.2.5)

So you need to address your system access issues. Review the R Windows FAQ.

https://cran.r-project.org/bin/windows/base/rw-FAQ.html#The-Internet-download-functions-fail_002e

> 
> Thanks & Regards,
> Nithya Dayalan
> AMS MRL DPS | HCL @ Merck
> E-mail: nithya.dayalan at merck.com
> Tel#+91 44 61053951| Mobile +91 8754232975
> 
> 
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net] 
> Sent: Friday, August 12, 2016 10:51 AM
> To: Dayalan, Nithya
> Cc: r-help at R-project.org; Radhakrishan, Balaji
> Subject: Re: [R] R Package installation
> 
> 
>> On Aug 12, 2016, at 3:53 AM, Dayalan, Nithya <nithya.dayalan at merck.com> wrote:
>> 
>> Hi Team,
>> 
>> We are receiving the below message while updating the package. Please help.
>> 
>>> install.packages("parallel", lib="D:/Program Files/R/R-3.2.5/library")
>> Warning: unable to access index for repository https://cran.fhcrc.org/src/contrib:
>> cannot open URL 'https://cran.fhcrc.org/src/contrib/PACKAGES'
>> Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
>> cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES'
>> Warning: unable to access index for repository https://cran.fhcrc.org/bin/windows/contrib/3.2:
>> cannot open URL 'https://cran.fhcrc.org/bin/windows/contrib/3.2/PACKAGES'
>> Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2:
>> cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/PACKAGES'
>> Warning messages:
>> 1: package 'parallel' is not available (for R version 3.2.5)
>> 2: package 'parallel' is a base package, and should not be updated
> 
> 
> In most case it is the first warning or error that is most meaningful, but in this case it is the last one.
> 
> The `installed.packages` function can tell you which packages are in the Bases" category:
> 
> plic <- installed.packages( .Library, priority = "base")
> 
>> rownames(plic)
> [1] "base"      "compiler"  "datasets"  "graphics"  "grDevices" "grid"      "methods"  
> [8] "parallel"  "splines"   "stats"     "stats4"    "tcltk"     "tools"     "utils"    
> 
> 
> Updating them requires updating your R version, which is what you should do now.
> 
> -- 
> David.
> 
> 
> 
>>> 
>> 
>> 
>> Thanks & Regards,
>> Nithya Dayalan
>> AMS MRL DPS | HCL @ Merck
>> E-mail: nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com>
>> Tel#+91 44 61053951| Mobile +91 8754232975
>> 
>> Notice:  This e-mail message, together with any attachme...{{dropped:14}}
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> Notice:  This e-mail message, together with any attach...{{dropped:20}}


From shivipmp82 at gmail.com  Fri Aug 12 17:20:04 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Fri, 12 Aug 2016 20:50:04 +0530
Subject: [R] glm.fit: fitted probabilities numerically 0 or 1 occurred &
 glm.fit: algorithm did not converge
In-Reply-To: <CAGxFJbSW3YrXuOHHS-t_05VzeetWLNbaH_cfVe76_cgR-UrRcA@mail.gmail.com>
References: <CAB=p7SreQJRULZ-j3mDmJk5vWAMRaM1b66WYy5k9Kd=sWD3rDQ@mail.gmail.com>
	<7a804ec9-ea4f-8c83-1104-01f3f7959b99@dewey.myzen.co.uk>
	<CAB=p7SoRxiW4EQvAr3K2aGXBknMu_Y7xoFbdefrJfS=jRfmdug@mail.gmail.com>
	<CAGxFJbSW3YrXuOHHS-t_05VzeetWLNbaH_cfVe76_cgR-UrRcA@mail.gmail.com>
Message-ID: <CAB=p7Sq2zV4PaNVXwZbQCbzVjfLL9We-zSixxzpr_c52aYYKhQ@mail.gmail.com>

Sure Burt, i will share the data after masking it.  it isn't big

regards, Shivi

On Fri, Aug 12, 2016 at 8:36 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> 1. No, changing to factor will make no difference.
>
> 2. I think that most likely your problem is your model is not
> estimable/your design matrix is singular.  You should resolve this by
> consulting with a local statistical expert or, if your data set is not
> too large or confidential, posting your full dataset using dput() (see
> ?dput for how to do this).
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Aug 12, 2016 at 7:58 AM, Shivi Bhatia <shivipmp82 at gmail.com>
> wrote:
> > Hi Michael,
> >
> > There is no output as the model does not generate any coefficients and
> > simply throws this error.
> >
> > I hope you are not asking for a reproducible example.
> >
> > On Fri, Aug 12, 2016 at 7:30 PM, Michael Dewey <lists at dewey.myzen.co.uk>
> > wrote:
> >
> >> Dear Shivi
> >>
> >> Can you show us the output?
> >>
> >> And please do not post in HTML as it will mangle your post into
> >> unreadability.
> >>
> >> On 12/08/2016 10:10, Shivi Bhatia wrote:
> >>
> >>> Hi Team,
> >>>
> >>> I am creating *my first* Logistic regression on R Studio. I am working
> on
> >>> a
> >>>
> >>> C-SAT data where rating (score) 0-8 is a dis-sat whereas 9-10 are SAT.
> As
> >>> these were in numeric form so i had as below created 2 classes:
> >>>
> >>> new$survey[new$score>=0 & new$score<=8]<- 0
> >>> new$survey[new$score>=9]<- 1
> >>> This works fine however the class still shows as "numeric" and levels
> >>> shows
> >>> as "NULL". Do i still need to use "as.factor" to let R know these are
> >>> categorical variables.
> >>>
> >>> Also i have used the below code to run a logistic regression with all
> the
> >>> possible predictor variables:
> >>> glm.fit= glm(survey ~ support_cat + region+ support_lvl+ skill_group+
> >>> application_area+ functional_area+
> >>>           repS+ case_age+ case_status+ severity_level+
> >>>           sla_status+ delivery_segmentation, data = SFDC, family =
> >>> binomial)
> >>>
> >>> But it throws an error:-
> >>> Warning messages:
> >>> 1: glm.fit: algorithm did not converge
> >>> 2: glm.fit: fitted probabilities numerically 0 or 1 occurred
> >>>
> >>> I checked online for the error and it says:
> >>> "glm() uses an iterative re-weighted least squares algorithm. The
> >>> algorithm
> >>> hit the maximum number of allowed iterations before signalling
> >>> convergence.
> >>> The default,
> >>> documented in ?glm.control is 25."
> >>>
> >>> Kindly suggest on the above case and if i have to change my outcome
> var as
> >>> as.factor.
> >>>
> >>> Thank you, Shivi
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posti
> >>> ng-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >> --
> >> Michael
> >> http://www.dewey.myzen.co.uk/home.html
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From luca.cerone at gmail.com  Fri Aug 12 17:57:48 2016
From: luca.cerone at gmail.com (Luca Cerone)
Date: Fri, 12 Aug 2016 17:57:48 +0200
Subject: [R] Help with non standard evaluation and require function
Message-ID: <CAFnz2-_biFmzaf0EPwV+BPN8oFq-Fa4nz7X=ONjrQzbaVR-Yzw@mail.gmail.com>

Hi everybody,
I am having a hard time in understanding how to deal with non standard
evaluation and the require function.

I asked about it on Stackoverflow at
http://stackoverflow.com/questions/38922012/r-function-to-install-missing-packages,
below you can find my question.

Thanks a lot for the help!
Cheers,
Luca

For one of my scripts I want to write an R function that checks if a
package is already installed: if so it should use library() to import
it in the namespace, otherwise it should install it and import it.

I assumed that pkgname is a string and tried to write something like:

ensure_library <- function(pkgname) {
  if (!require(pkgname)) {
    install.packages(pkgname, dependencies = TRUE)
  }
  require(pkgname)
}

As simple as is this function does not work. If I try to run it like
ensure_library("dplyr") it installs the package dplyr but then it
fails because it trys to import pkgname rather than dplyr in the
namespace.

ensure_library("dplyr")
Loading required package: pkgname
Installing package into ?/home/luca/R-dev?
(as ?lib? is unspecified)
trying URL 'https://cran.rstudio.com/src/contrib/dplyr_0.5.0.tar.gz'
Content type 'application/x-gzip' length 708476 bytes (691 KB)
==================================================
downloaded 691 KB

* installing *source* package ?dplyr? ...
** package ?dplyr? successfully unpacked and MD5 sums checked
** libs

.... a lot of compiling here....

installing to /home/luca/R-dev/dplyr/libs
** R
** data
*** moving datasets to lazyload DB
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded
* DONE (dplyr)

The downloaded source packages are in
    ?/tmp/Rtmpfd2Lep/downloaded_packages?
Loading required package: pkgname
Warning messages:
1: In library(package, lib.loc = lib.loc, character.only = TRUE,
logical.return = TRUE,  :
  there is no package called ?pkgname?
2: In library(package, lib.loc = lib.loc, character.only = TRUE,
logical.return = TRUE,  :
  there is no package called ?pkgname?

Also, if I now re-run it it will install dplyr once again.

I realize this is probably due to R non-standard-evaluation and I have
tried several combination of eval/substitute/quote in order to make it
work with require but I couldn't succeed.

Can somebody help me understanding what is going on and if there is
some easy-fix?

If a function already implementing this exists I would like to know,
but what I am really interested is understanding why my code does not
work as intended.


From nithya.dayalan at merck.com  Fri Aug 12 16:45:05 2016
From: nithya.dayalan at merck.com (Dayalan, Nithya)
Date: Fri, 12 Aug 2016 10:45:05 -0400
Subject: [R] R Package installation
In-Reply-To: <DB1B79CC-A933-4EC2-956B-C78D060349CC@dcn.davis.ca.us>
References: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C31F@USCTMXP51002.merck.com>
	<DB1B79CC-A933-4EC2-956B-C78D060349CC@dcn.davis.ca.us>
Message-ID: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C327@USCTMXP51002.merck.com>

Yes Jeff,  I tried it with 10 mirrors.

Thanks & Regards,
Nithya Dayalan
AMS MRL DPS | HCL @ Merck
E-mail: nithya.dayalan at merck.com
Tel#+91 44 61053951| Mobile +91 8754232975

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Friday, August 12, 2016 10:43 AM
To: Dayalan, Nithya; 'r-help at R-project.org'
Cc: Radhakrishan, Balaji
Subject: Re: [R] R Package installation

Choose

A

Different

Mirror
-- 
Sent from my phone. Please excuse my brevity.

On August 12, 2016 3:53:03 AM PDT, "Dayalan, Nithya" <nithya.dayalan at merck.com> wrote:
>Hi Team,
>
>We are receiving the below message while updating the package. Please
>help.
>
>> install.packages("parallel", lib="D:/Program
>Files/R/R-3.2.5/library")
>Warning: unable to access index for repository
>https://cran.fhcrc.org/src/contrib:
>  cannot open URL 'https://cran.fhcrc.org/src/contrib/PACKAGES'
>Warning: unable to access index for repository
>http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
>cannot open URL
>'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES'
>Warning: unable to access index for repository
>https://cran.fhcrc.org/bin/windows/contrib/3.2:
>cannot open URL
>'https://cran.fhcrc.org/bin/windows/contrib/3.2/PACKAGES'
>Warning: unable to access index for repository
>http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2:
>cannot open URL
>'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/PACKAGES'
>Warning messages:
>1: package 'parallel' is not available (for R version 3.2.5)
>2: package 'parallel' is a base package, and should not be updated
>>
>
>
>Thanks & Regards,
>Nithya Dayalan
>AMS MRL DPS | HCL @ Merck
>E-mail: nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com>
>Tel#+91 44 61053951| Mobile +91 8754232975
>
>Notice:  This e-mail message, together with any
>attachme...{{dropped:14}}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

Notice:  This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (2000 Galloping Hill Road, Kenilworth,
New Jersey, USA 07033), and/or its affiliates Direct contact information
for affiliates is available at 
http://www.merck.com/contact/contacts.html) that may be confidential,
proprietary copyrighted and/or legally privileged. It is intended solely
for the use of the individual or entity named on this message. If you are
not the intended recipient, and have received this message in error,
please notify us immediately by reply e-mail and then delete it from 
your system.

From nithya.dayalan at merck.com  Fri Aug 12 16:48:50 2016
From: nithya.dayalan at merck.com (Dayalan, Nithya)
Date: Fri, 12 Aug 2016 10:48:50 -0400
Subject: [R] R Package installation
In-Reply-To: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C327@USCTMXP51002.merck.com>
References: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C31F@USCTMXP51002.merck.com>
	<DB1B79CC-A933-4EC2-956B-C78D060349CC@dcn.davis.ca.us>
	<91DFE13BB89B4F49ADA450B375D0A5AC91A974C327@USCTMXP51002.merck.com>
Message-ID: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C328@USCTMXP51002.merck.com>

Hi Jeff,

Before selecting the mirror I am receiving the error: I can able connect internet in server and also I have already done this package installation before 2 weeks.

Error in download.file(url, destfile = f, quiet = TRUE) :
  cannot open URL 'https://cran.r-project.org/CRAN_mirrors.csv'
In addition: Warning message:
In download.file(url, destfile = f, quiet = TRUE) :
  InternetOpenUrl failed: 'A connection with the server could not be established'
Warning: unable to access index for repository https://cran.uni-muenster.de/src/contrib:
  cannot open URL 'https://cran.uni-muenster.de/src/contrib/PACKAGES'
Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES'
Warning: unable to access index for repository https://cran.uni-muenster.de/bin/windows/contrib/3.2:
  cannot open URL 'https://cran.uni-muenster.de/bin/windows/contrib/3.2/PACKAGES'
Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2:
  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/PACKAGES'
Warning message:
package ?Rtsne? is not available (for R version 3.2.5)



Thanks & Regards,
Nithya Dayalan
AMS MRL DPS | HCL @ Merck
E-mail: nithya.dayalan at merck.com
Tel#+91 44 61053951| Mobile +91 8754232975


-----Original Message-----
From: Dayalan, Nithya
Sent: Friday, August 12, 2016 10:45 AM
To: 'Jeff Newmiller'; 'r-help at R-project.org'
Cc: Radhakrishan, Balaji
Subject: RE: [R] R Package installation

Yes Jeff,  I tried it with 10 mirrors.

Thanks & Regards,
Nithya Dayalan
AMS MRL DPS | HCL @ Merck
E-mail: nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com>
Tel#+91 44 61053951| Mobile +91 8754232975

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
Sent: Friday, August 12, 2016 10:43 AM
To: Dayalan, Nithya; 'r-help at R-project.org'
Cc: Radhakrishan, Balaji
Subject: Re: [R] R Package installation

Choose

A

Different

Mirror
--
Sent from my phone. Please excuse my brevity.

On August 12, 2016 3:53:03 AM PDT, "Dayalan, Nithya" <nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com>> wrote:
>Hi Team,
>
>We are receiving the below message while updating the package. Please
>help.
>
>> install.packages("parallel", lib="D:/Program
>Files/R/R-3.2.5/library")
>Warning: unable to access index for repository
>https://cran.fhcrc.org/src/contrib:
>  cannot open URL 'https://cran.fhcrc.org/src/contrib/PACKAGES'
>Warning: unable to access index for repository
>http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
>cannot open URL
>'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES'
>Warning: unable to access index for repository
>https://cran.fhcrc.org/bin/windows/contrib/3.2:
>cannot open URL
>'https://cran.fhcrc.org/bin/windows/contrib/3.2/PACKAGES'
>Warning: unable to access index for repository
>http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2:
>cannot open URL
>'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/PACKAGES'
>Warning messages:
>1: package 'parallel' is not available (for R version 3.2.5)
>2: package 'parallel' is a base package, and should not be updated
>>
>
>
>Thanks & Regards,
>Nithya Dayalan
>AMS MRL DPS | HCL @ Merck
>E-mail: nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com>>
>Tel#+91 44 61053951| Mobile +91 8754232975
>
>Notice:  This e-mail message, together with any
>attachme...{{dropped:14}}
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


Notice:  This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (2000 Galloping Hill Road, Kenilworth,
New Jersey, USA 07033), and/or its affiliates Direct contact information
for affiliates is available at 
http://www.merck.com/contact/contacts.html) that may be confidential,
proprietary copyrighted and/or legally privileged. It is intended solely
for the use of the individual or entity named on this message. If you are
not the intended recipient, and have received this message in error,
please notify us immediately by reply e-mail and then delete it from 
your system.

	[[alternative HTML version deleted]]


From nithya.dayalan at merck.com  Fri Aug 12 16:53:42 2016
From: nithya.dayalan at merck.com (Dayalan, Nithya)
Date: Fri, 12 Aug 2016 10:53:42 -0400
Subject: [R] R Package installation
In-Reply-To: <C1E2CED8-B282-40CF-81E5-7C7A5E73DEFB@comcast.net>
References: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C31F@USCTMXP51002.merck.com>
	<C1E2CED8-B282-40CF-81E5-7C7A5E73DEFB@comcast.net>
Message-ID: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C32A@USCTMXP51002.merck.com>

Hi David,

Okay thank you, but the error message receiving for other packages.

> install.packages("Rtsne", lib="D:/Program Files/R/R-3.2.5/library")
--- Please select a CRAN mirror for use in this session ---
Error in download.file(url, destfile = f, quiet = TRUE) : 
  cannot open URL 'https://cran.r-project.org/CRAN_mirrors.csv'
In addition: Warning message:
In
  InternetOpenUrl failed: 'A connection with the server could not be established'
Warning: unable to access index for repository https://cran.uni-muenster.de/src/contrib:
  cannot open URL 'https://cran.uni-muenster.de/src/contrib/PACKAGES'
Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES'
Warning: unable to access index for repository https://cran.uni-muenster.de/bin/windows/contrib/3.2:
  cannot open URL 'https://cran.uni-muenster.de/bin/windows/contrib/3.2/PACKAGES'
Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2:
  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/PACKAGES'
Warning message:
package 'Rtsne' is not available (for R version 3.2.5)

Thanks & Regards,
Nithya Dayalan
AMS MRL DPS | HCL @ Merck
E-mail: nithya.dayalan at merck.com
Tel#+91 44 61053951| Mobile +91 8754232975


-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Friday, August 12, 2016 10:51 AM
To: Dayalan, Nithya
Cc: r-help at R-project.org; Radhakrishan, Balaji
Subject: Re: [R] R Package installation


> On Aug 12, 2016, at 3:53 AM, Dayalan, Nithya <nithya.dayalan at merck.com> wrote:
> 
> Hi Team,
> 
> We are receiving the below message while updating the package. Please help.
> 
>> install.packages("parallel", lib="D:/Program Files/R/R-3.2.5/library")
> Warning: unable to access index for repository https://cran.fhcrc.org/src/contrib:
>  cannot open URL 'https://cran.fhcrc.org/src/contrib/PACKAGES'
> Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
>  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES'
> Warning: unable to access index for repository https://cran.fhcrc.org/bin/windows/contrib/3.2:
>  cannot open URL 'https://cran.fhcrc.org/bin/windows/contrib/3.2/PACKAGES'
> Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2:
>  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/PACKAGES'
> Warning messages:
> 1: package 'parallel' is not available (for R version 3.2.5)
> 2: package 'parallel' is a base package, and should not be updated


In most case it is the first warning or error that is most meaningful, but in this case it is the last one.

The `installed.packages` function can tell you which packages are in the Bases" category:

plic <- installed.packages( .Library, priority = "base")

> rownames(plic)
 [1] "base"      "compiler"  "datasets"  "graphics"  "grDevices" "grid"      "methods"  
 [8] "parallel"  "splines"   "stats"     "stats4"    "tcltk"     "tools"     "utils"    


Updating them requires updating your R version, which is what you should do now.

-- 
David.



>> 
> 
> 
> Thanks & Regards,
> Nithya Dayalan
> AMS MRL DPS | HCL @ Merck
> E-mail: nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com>
> Tel#+91 44 61053951| Mobile +91 8754232975
> 
> Notice:  This e-mail message, together with any attachme...{{dropped:14}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

Notice:  This e-mail message, together with any attachme...{{dropped:11}}


From beire55 at yahoo.es  Fri Aug 12 18:10:31 2016
From: beire55 at yahoo.es (Juan Perez)
Date: Fri, 12 Aug 2016 16:10:31 +0000 (UTC)
Subject: [R] Adding loess lines subsetting to each panel in lattice plot
References: <676905760.22528506.1471018231218.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <676905760.22528506.1471018231218.JavaMail.yahoo@mail.yahoo.com>

Hello, I've created an xyplot and I want to add a loess line for x (Age)? <=40 and another for values >40. In a way it is similar to this https://stat.ethz.ch/pipermail/r-help/2009-May/390502.html but still not succcessful.
This is my try:

xyplot(MOE~Age|Species, groups=Site, 
?????? panel = function(x, y, groups=groups,...) {
??????? panel.xyplot(x, y, groups=groups,...)
??? ? ? panel.loess(x,y,subset = x <= 40, col="black") ????????panel.loess(x,y,subset = x >40, col="red")? 
????????????? })
When I run the code it "works" but it plots the loess line for all the data, without subsetting.Any suggestion?
Thank you

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Aug 12 18:18:48 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 12 Aug 2016 12:18:48 -0400
Subject: [R] Help with non standard evaluation and require function
In-Reply-To: <CAFnz2-_biFmzaf0EPwV+BPN8oFq-Fa4nz7X=ONjrQzbaVR-Yzw@mail.gmail.com>
References: <CAFnz2-_biFmzaf0EPwV+BPN8oFq-Fa4nz7X=ONjrQzbaVR-Yzw@mail.gmail.com>
Message-ID: <fa476481-36ea-500a-8a76-fad20b7cb1db@gmail.com>

On 12/08/2016 11:57 AM, Luca Cerone wrote:
> Hi everybody,
> I am having a hard time in understanding how to deal with non standard
> evaluation and the require function.
>
> I asked about it on Stackoverflow at
> http://stackoverflow.com/questions/38922012/r-function-to-install-missing-packages,
> below you can find my question.
>
> Thanks a lot for the help!
> Cheers,
> Luca
>
> For one of my scripts I want to write an R function that checks if a
> package is already installed: if so it should use library() to import
> it in the namespace, otherwise it should install it and import it.
>
> I assumed that pkgname is a string and tried to write something like:
>
> ensure_library <- function(pkgname) {
>    if (!require(pkgname)) {

Should be

   if (!require(pkgname, character.only = TRUE)) {

>      install.packages(pkgname, dependencies = TRUE)
>    }
>    require(pkgname)

Similarly here.  You won't need this for the install.packages call.

You should have been able to figure this out from the ?require help 
page.  It is mentioned twice, and is used in one of the examples.

Duncan Murdoch


From lists at dewey.myzen.co.uk  Fri Aug 12 19:35:25 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 12 Aug 2016 18:35:25 +0100
Subject: [R] glm.fit: fitted probabilities numerically 0 or 1 occurred &
 glm.fit: algorithm did not converge
In-Reply-To: <CAB=p7SrfaKJ43ZXew4SnkOFcv+PGRqi6ZowROm_s7W+mvZUD=g@mail.gmail.com>
References: <CAB=p7SreQJRULZ-j3mDmJk5vWAMRaM1b66WYy5k9Kd=sWD3rDQ@mail.gmail.com>
	<7a804ec9-ea4f-8c83-1104-01f3f7959b99@dewey.myzen.co.uk>
	<CAB=p7SoRxiW4EQvAr3K2aGXBknMu_Y7xoFbdefrJfS=jRfmdug@mail.gmail.com>
	<CAGxFJbSW3YrXuOHHS-t_05VzeetWLNbaH_cfVe76_cgR-UrRcA@mail.gmail.com>
	<CAB=p7Sq2zV4PaNVXwZbQCbzVjfLL9We-zSixxzpr_c52aYYKhQ@mail.gmail.com>
	<CAB=p7SrfaKJ43ZXew4SnkOFcv+PGRqi6ZowROm_s7W+mvZUD=g@mail.gmail.com>
Message-ID: <d8c87fd4-a8c8-5640-490d-3a8d28d9b671@dewey.myzen.co.uk>

Your example code refers to a variable which is not in your dataset 
(repS) so I get an error message. If I assume repS is in fact rep_score 
I get another variable not found (delivery_segmentation).

I am afraid that I am unable to sort that one out so this is going to 
remain a mystery. I endorse Bert's suggestion of getting local help.

On 12/08/2016 17:24, Shivi Bhatia wrote:
> Hi Bert,
>
> Does this text file help. Apologies if this does not help as i have a
> hard time on many occasions to get a reproducible example.
>
> If this doesn't work a CSV with only 100kb of data i can share.
>
> Regards, Shivi
>
> On Fri, Aug 12, 2016 at 8:50 PM, Shivi Bhatia <shivipmp82 at gmail.com
> <mailto:shivipmp82 at gmail.com>> wrote:
>
>     Sure Burt, i will share the data after masking it.  it isn't big
>
>     regards, Shivi
>
>     On Fri, Aug 12, 2016 at 8:36 PM, Bert Gunter <bgunter.4567 at gmail.com
>     <mailto:bgunter.4567 at gmail.com>> wrote:
>
>         1. No, changing to factor will make no difference.
>
>         2. I think that most likely your problem is your model is not
>         estimable/your design matrix is singular.  You should resolve
>         this by
>         consulting with a local statistical expert or, if your data set
>         is not
>         too large or confidential, posting your full dataset using
>         dput() (see
>         ?dput for how to do this).
>
>         Cheers,
>         Bert
>         Bert Gunter
>
>         "The trouble with having an open mind is that people keep coming
>         along
>         and sticking things into it."
>         -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>         On Fri, Aug 12, 2016 at 7:58 AM, Shivi Bhatia
>         <shivipmp82 at gmail.com <mailto:shivipmp82 at gmail.com>> wrote:
>         > Hi Michael,
>         >
>         > There is no output as the model does not generate any
>         coefficients and
>         > simply throws this error.
>         >
>         > I hope you are not asking for a reproducible example.
>         >
>         > On Fri, Aug 12, 2016 at 7:30 PM, Michael Dewey
>         <lists at dewey.myzen.co.uk <mailto:lists at dewey.myzen.co.uk>>
>         > wrote:
>         >
>         >> Dear Shivi
>         >>
>         >> Can you show us the output?
>         >>
>         >> And please do not post in HTML as it will mangle your post into
>         >> unreadability.
>         >>
>         >> On 12/08/2016 10:10, Shivi Bhatia wrote:
>         >>
>         >>> Hi Team,
>         >>>
>         >>> I am creating *my first* Logistic regression on R Studio. I
>         am working on
>         >>> a
>         >>>
>         >>> C-SAT data where rating (score) 0-8 is a dis-sat whereas
>         9-10 are SAT. As
>         >>> these were in numeric form so i had as below created 2 classes:
>         >>>
>         >>> new$survey[new$score>=0 & new$score<=8]<- 0
>         >>> new$survey[new$score>=9]<- 1
>         >>> This works fine however the class still shows as "numeric"
>         and levels
>         >>> shows
>         >>> as "NULL". Do i still need to use "as.factor" to let R know
>         these are
>         >>> categorical variables.
>         >>>
>         >>> Also i have used the below code to run a logistic regression
>         with all the
>         >>> possible predictor variables:
>         >>> glm.fit= glm(survey ~ support_cat + region+ support_lvl+
>         skill_group+
>         >>> application_area+ functional_area+
>         >>>           repS+ case_age+ case_status+ severity_level+
>         >>>           sla_status+ delivery_segmentation, data = SFDC,
>         family =
>         >>> binomial)
>         >>>
>         >>> But it throws an error:-
>         >>> Warning messages:
>         >>> 1: glm.fit: algorithm did not converge
>         >>> 2: glm.fit: fitted probabilities numerically 0 or 1 occurred
>         >>>
>         >>> I checked online for the error and it says:
>         >>> "glm() uses an iterative re-weighted least squares
>         algorithm. The
>         >>> algorithm
>         >>> hit the maximum number of allowed iterations before signalling
>         >>> convergence.
>         >>> The default,
>         >>> documented in ?glm.control is 25."
>         >>>
>         >>> Kindly suggest on the above case and if i have to change my
>         outcome var as
>         >>> as.factor.
>         >>>
>         >>> Thank you, Shivi
>         >>>
>         >>>         [[alternative HTML version deleted]]
>         >>>
>         >>> ______________________________________________
>         >>> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>         list -- To UNSUBSCRIBE and more, see
>         >>> https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         >>> PLEASE do read the posting guide http://www.R-project.org/posti
>         >>> ng-guide.html
>         >>> and provide commented, minimal, self-contained, reproducible
>         code.
>         >>>
>         >>>
>         >> --
>         >> Michael
>         >> http://www.dewey.myzen.co.uk/home.html
>         <http://www.dewey.myzen.co.uk/home.html>
>         >>
>         >
>         >         [[alternative HTML version deleted]]
>         >
>         > ______________________________________________
>         > R-help at r-project.org <mailto:R-help at r-project.org> mailing
>         list -- To UNSUBSCRIBE and more, see
>         > https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         > PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         > and provide commented, minimal, self-contained, reproducible code.
>
>
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From dwinsemius at comcast.net  Fri Aug 12 20:06:38 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 Aug 2016 11:06:38 -0700
Subject: [R] R Package installation
In-Reply-To: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C328@USCTMXP51002.merck.com>
References: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C31F@USCTMXP51002.merck.com>
	<DB1B79CC-A933-4EC2-956B-C78D060349CC@dcn.davis.ca.us>
	<91DFE13BB89B4F49ADA450B375D0A5AC91A974C327@USCTMXP51002.merck.com>
	<91DFE13BB89B4F49ADA450B375D0A5AC91A974C328@USCTMXP51002.merck.com>
Message-ID: <D330FA5D-AEAD-480E-B1D8-15CC2EC4B6B6@comcast.net>


> On Aug 12, 2016, at 7:48 AM, Dayalan, Nithya <nithya.dayalan at merck.com> wrote:
> 
> Hi Jeff,
> 
> Before selecting the mirror I am receiving the error: I can able connect internet in server and also I have already done this package installation before 2 weeks.
> 
> Error in download.file(url, destfile = f, quiet = TRUE) :
>  cannot open URL 'https://cran.r-project.org/CRAN_mirrors.csv'
> In addition: Warning message:
> In download.file(url, destfile = f, quiet = TRUE) :
>  InternetOpenUrl failed: 'A connection with the server could not be established'
> Warning: unable to access index for repository https://cran.uni-muenster.de/src/contrib:
>  cannot open URL 'https://cran.uni-muenster.de/src/contrib/PACKAGES'
> Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
>  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES'
> Warning: unable to access index for repository https://cran.uni-muenster.de/bin/windows/contrib/3.2:
>  cannot open URL 'https://cran.uni-muenster.de/bin/windows/contrib/3.2/PACKAGES'
> Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2:
>  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/PACKAGES'
> Warning message:
> package ?Rtsne? is not available (for R version 3.2.5)





> Thanks & Regards,
> Nithya Dayalan
> AMS MRL DPS | HCL @ Merck
> E-mail: nithya.dayalan at merck.com
> Tel#+91 44 61053951| Mobile +91 8754232975
> 
> 
> -----Original Message-----
> From: Dayalan, Nithya
> Sent: Friday, August 12, 2016 10:45 AM
> To: 'Jeff Newmiller'; 'r-help at R-project.org'
> Cc: Radhakrishan, Balaji
> Subject: RE: [R] R Package installation
> 
> Yes Jeff,  I tried it with 10 mirrors.
> 
> Thanks & Regards,
> Nithya Dayalan
> AMS MRL DPS | HCL @ Merck
> E-mail: nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com>
> Tel#+91 44 61053951| Mobile +91 8754232975
> 
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Friday, August 12, 2016 10:43 AM
> To: Dayalan, Nithya; 'r-help at R-project.org'
> Cc: Radhakrishan, Balaji
> Subject: Re: [R] R Package installation
> 
> Choose
> 
> A
> 
> Different
> 
> Mirror
> --
> Sent from my phone. Please excuse my brevity.
> 
> On August 12, 2016 3:53:03 AM PDT, "Dayalan, Nithya" <nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com>> wrote:
>> Hi Team,
>> 
>> We are receiving the below message while updating the package. Please
>> help.
>> 
>>> install.packages("parallel", lib="D:/Program
>> Files/R/R-3.2.5/library")
>> Warning: unable to access index for repository
>> https://cran.fhcrc.org/src/contrib:
>> cannot open URL 'https://cran.fhcrc.org/src/contrib/PACKAGES'
>> Warning: unable to access index for repository
>> http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
>> cannot open URL
>> 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES'
>> Warning: unable to access index for repository
>> https://cran.fhcrc.org/bin/windows/contrib/3.2:
>> cannot open URL
>> 'https://cran.fhcrc.org/bin/windows/contrib/3.2/PACKAGES'
>> Warning: unable to access index for repository
>> http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2:
>> cannot open URL
>> 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/PACKAGES'
>> Warning messages:
>> 1: package 'parallel' is not available (for R version 3.2.5)
>> 2: package 'parallel' is a base package, and should not be updated
>>> 
>> 
>> 
>> Thanks & Regards,
>> Nithya Dayalan
>> AMS MRL DPS | HCL @ Merck
>> E-mail: nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com>>
>> Tel#+91 44 61053951| Mobile +91 8754232975
>> 
>> Notice:  This e-mail message, together with any
>> attachme...{{dropped:14}}
>> 
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> Notice:  This e-mail message, together with any attach...{{dropped:28}}


From dwinsemius at comcast.net  Fri Aug 12 20:09:55 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 Aug 2016 11:09:55 -0700
Subject: [R] R Package installation
In-Reply-To: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C328@USCTMXP51002.merck.com>
References: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C31F@USCTMXP51002.merck.com>
	<DB1B79CC-A933-4EC2-956B-C78D060349CC@dcn.davis.ca.us>
	<91DFE13BB89B4F49ADA450B375D0A5AC91A974C327@USCTMXP51002.merck.com>
	<91DFE13BB89B4F49ADA450B375D0A5AC91A974C328@USCTMXP51002.merck.com>
Message-ID: <8EA54518-D002-480F-BA7E-8354D751F20F@comcast.net>


> On Aug 12, 2016, at 7:48 AM, Dayalan, Nithya <nithya.dayalan at merck.com> wrote:
> 
> Hi Jeff,
> 
> Before selecting the mirror I am receiving the error: I can able connect internet in server

Sorry for the blank message just now, but it appears that this is some ambiguity in your statement that you can connect to the Internet with R. The evidence below says that you _cannot_ do so. Those files exist and at least some of those mirrors have binaries of that package for the outdated version of R that you are using.

Perhaps you need to talk to your IT staff for support in getting through your corporate securioty layers, whatever they might be in whatever unstated setup you have.

-- 
David.


> and also I have already done this package installation before 2 weeks.
> 
> Error in download.file(url, destfile = f, quiet = TRUE) :
>  cannot open URL 'https://cran.r-project.org/CRAN_mirrors.csv'
> In addition: Warning message:
> In download.file(url, destfile = f, quiet = TRUE) :
>  InternetOpenUrl failed: 'A connection with the server could not be established'
> Warning: unable to access index for repository https://cran.uni-muenster.de/src/contrib:
>  cannot open URL 'https://cran.uni-muenster.de/src/contrib/PACKAGES'
> Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
>  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES'
> Warning: unable to access index for repository https://cran.uni-muenster.de/bin/windows/contrib/3.2:
>  cannot open URL 'https://cran.uni-muenster.de/bin/windows/contrib/3.2/PACKAGES'
> Warning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2:
>  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/PACKAGES'
> Warning message:
> package ?Rtsne? is not available (for R version 3.2.5)
> 
> 
> 
> Thanks & Regards,
> Nithya Dayalan
> AMS MRL DPS | HCL @ Merck
> E-mail: nithya.dayalan at merck.com
> Tel#+91 44 61053951| Mobile +91 8754232975
> 
> 
> -----Original Message-----
> From: Dayalan, Nithya
> Sent: Friday, August 12, 2016 10:45 AM
> To: 'Jeff Newmiller'; 'r-help at R-project.org'
> Cc: Radhakrishan, Balaji
> Subject: RE: [R] R Package installation
> 
> Yes Jeff,  I tried it with 10 mirrors.
> 
> Thanks & Regards,
> Nithya Dayalan
> AMS MRL DPS | HCL @ Merck
> E-mail: nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com>
> Tel#+91 44 61053951| Mobile +91 8754232975
> 
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Friday, August 12, 2016 10:43 AM
> To: Dayalan, Nithya; 'r-help at R-project.org'
> Cc: Radhakrishan, Balaji
> Subject: Re: [R] R Package installation
> 
> Choose
> 
> A
> 
> Different
> 
> Mirror
> --
> Sent from my phone. Please excuse my brevity.
> 
> On August 12, 2016 3:53:03 AM PDT, "Dayalan, Nithya" <nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com>> wrote:
>> Hi Team,
>> 
>> We are receiving the below message while updating the package. Please
>> help.
>> 
>>> install.packages("parallel", lib="D:/Program
>> Files/R/R-3.2.5/library")
>> Warning: unable to access index for repository
>> https://cran.fhcrc.org/src/contrib:
>> cannot open URL 'https://cran.fhcrc.org/src/contrib/PACKAGES'
>> Warning: unable to access index for repository
>> http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
>> cannot open URL
>> 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES'
>> Warning: unable to access index for repository
>> https://cran.fhcrc.org/bin/windows/contrib/3.2:
>> cannot open URL
>> 'https://cran.fhcrc.org/bin/windows/contrib/3.2/PACKAGES'
>> Warning: unable to access index for repository
>> http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2:
>> cannot open URL
>> 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/PACKAGES'
>> Warning messages:
>> 1: package 'parallel' is not available (for R version 3.2.5)
>> 2: package 'parallel' is a base package, and should not be updated
>>> 
>> 
>> 
>> Thanks & Regards,
>> Nithya Dayalan
>> AMS MRL DPS | HCL @ Merck
>> E-mail: nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com>>
>> Tel#+91 44 61053951| Mobile +91 8754232975
>> 
>> Notice:  This e-mail message, together with any
>> attachme...{{dropped:14}}
>> 
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> Notice:  This e-mail message, together with any attach...{{dropped:28}}


From dwinsemius at comcast.net  Fri Aug 12 20:14:37 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 Aug 2016 11:14:37 -0700
Subject: [R] Help with non standard evaluation and require function
In-Reply-To: <CAFnz2-_biFmzaf0EPwV+BPN8oFq-Fa4nz7X=ONjrQzbaVR-Yzw@mail.gmail.com>
References: <CAFnz2-_biFmzaf0EPwV+BPN8oFq-Fa4nz7X=ONjrQzbaVR-Yzw@mail.gmail.com>
Message-ID: <6B4D2CEE-595E-4D44-9DFE-229997A9FB9F@comcast.net>


> On Aug 12, 2016, at 8:57 AM, Luca Cerone <luca.cerone at gmail.com> wrote:
> 
> Hi everybody,
> I am having a hard time in understanding how to deal with non standard
> evaluation and the require function.
> 
> I asked about it on Stackoverflow at
> http://stackoverflow.com/questions/38922012/r-function-to-install-missing-packages,
> below you can find my question.

It was already explained and teh code of `require provided: `substitute` does not lookup values in the symbol table so the symbol: `pkgname` is converted by `as.character` to "pkgname", .... unless 'character.only' is TRUE.

What part of that is not understood?

-- 
David.
> 
> Thanks a lot for the help!
> Cheers,
> Luca
> 
> For one of my scripts I want to write an R function that checks if a
> package is already installed: if so it should use library() to import
> it in the namespace, otherwise it should install it and import it.
> 
> I assumed that pkgname is a string and tried to write something like:
> 
> ensure_library <- function(pkgname) {
>  if (!require(pkgname)) {
>    install.packages(pkgname, dependencies = TRUE)
>  }
>  require(pkgname)
> }
> 
> As simple as is this function does not work. If I try to run it like
> ensure_library("dplyr") it installs the package dplyr but then it
> fails because it trys to import pkgname rather than dplyr in the
> namespace.
> 
> ensure_library("dplyr")
> Loading required package: pkgname
> Installing package into ?/home/luca/R-dev?
> (as ?lib? is unspecified)
> trying URL 'https://cran.rstudio.com/src/contrib/dplyr_0.5.0.tar.gz'
> Content type 'application/x-gzip' length 708476 bytes (691 KB)
> ==================================================
> downloaded 691 KB
> 
> * installing *source* package ?dplyr? ...
> ** package ?dplyr? successfully unpacked and MD5 sums checked
> ** libs
> 
> .... a lot of compiling here....
> 
> installing to /home/luca/R-dev/dplyr/libs
> ** R
> ** data
> *** moving datasets to lazyload DB
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** installing vignettes
> ** testing if installed package can be loaded
> * DONE (dplyr)
> 
> The downloaded source packages are in
>    ?/tmp/Rtmpfd2Lep/downloaded_packages?
> Loading required package: pkgname
> Warning messages:
> 1: In library(package, lib.loc = lib.loc, character.only = TRUE,
> logical.return = TRUE,  :
>  there is no package called ?pkgname?
> 2: In library(package, lib.loc = lib.loc, character.only = TRUE,
> logical.return = TRUE,  :
>  there is no package called ?pkgname?
> 
> Also, if I now re-run it it will install dplyr once again.
> 
> I realize this is probably due to R non-standard-evaluation and I have
> tried several combination of eval/substitute/quote in order to make it
> work with require but I couldn't succeed.
> 
> Can somebody help me understanding what is going on and if there is
> some easy-fix?
> 
> If a function already implementing this exists I would like to know,
> but what I am really interested is understanding why my code does not
> work as intended.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From shivipmp82 at gmail.com  Fri Aug 12 18:24:36 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Fri, 12 Aug 2016 21:54:36 +0530
Subject: [R] glm.fit: fitted probabilities numerically 0 or 1 occurred &
 glm.fit: algorithm did not converge
In-Reply-To: <CAB=p7Sq2zV4PaNVXwZbQCbzVjfLL9We-zSixxzpr_c52aYYKhQ@mail.gmail.com>
References: <CAB=p7SreQJRULZ-j3mDmJk5vWAMRaM1b66WYy5k9Kd=sWD3rDQ@mail.gmail.com>
	<7a804ec9-ea4f-8c83-1104-01f3f7959b99@dewey.myzen.co.uk>
	<CAB=p7SoRxiW4EQvAr3K2aGXBknMu_Y7xoFbdefrJfS=jRfmdug@mail.gmail.com>
	<CAGxFJbSW3YrXuOHHS-t_05VzeetWLNbaH_cfVe76_cgR-UrRcA@mail.gmail.com>
	<CAB=p7Sq2zV4PaNVXwZbQCbzVjfLL9We-zSixxzpr_c52aYYKhQ@mail.gmail.com>
Message-ID: <CAB=p7SrfaKJ43ZXew4SnkOFcv+PGRqi6ZowROm_s7W+mvZUD=g@mail.gmail.com>

Hi Bert,

Does this text file help. Apologies if this does not help as i have a hard
time on many occasions to get a reproducible example.

If this doesn't work a CSV with only 100kb of data i can share.

Regards, Shivi

On Fri, Aug 12, 2016 at 8:50 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:

> Sure Burt, i will share the data after masking it.  it isn't big
>
> regards, Shivi
>
> On Fri, Aug 12, 2016 at 8:36 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> 1. No, changing to factor will make no difference.
>>
>> 2. I think that most likely your problem is your model is not
>> estimable/your design matrix is singular.  You should resolve this by
>> consulting with a local statistical expert or, if your data set is not
>> too large or confidential, posting your full dataset using dput() (see
>> ?dput for how to do this).
>>
>> Cheers,
>> Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Fri, Aug 12, 2016 at 7:58 AM, Shivi Bhatia <shivipmp82 at gmail.com>
>> wrote:
>> > Hi Michael,
>> >
>> > There is no output as the model does not generate any coefficients and
>> > simply throws this error.
>> >
>> > I hope you are not asking for a reproducible example.
>> >
>> > On Fri, Aug 12, 2016 at 7:30 PM, Michael Dewey <lists at dewey.myzen.co.uk
>> >
>> > wrote:
>> >
>> >> Dear Shivi
>> >>
>> >> Can you show us the output?
>> >>
>> >> And please do not post in HTML as it will mangle your post into
>> >> unreadability.
>> >>
>> >> On 12/08/2016 10:10, Shivi Bhatia wrote:
>> >>
>> >>> Hi Team,
>> >>>
>> >>> I am creating *my first* Logistic regression on R Studio. I am
>> working on
>> >>> a
>> >>>
>> >>> C-SAT data where rating (score) 0-8 is a dis-sat whereas 9-10 are
>> SAT. As
>> >>> these were in numeric form so i had as below created 2 classes:
>> >>>
>> >>> new$survey[new$score>=0 & new$score<=8]<- 0
>> >>> new$survey[new$score>=9]<- 1
>> >>> This works fine however the class still shows as "numeric" and levels
>> >>> shows
>> >>> as "NULL". Do i still need to use "as.factor" to let R know these are
>> >>> categorical variables.
>> >>>
>> >>> Also i have used the below code to run a logistic regression with all
>> the
>> >>> possible predictor variables:
>> >>> glm.fit= glm(survey ~ support_cat + region+ support_lvl+ skill_group+
>> >>> application_area+ functional_area+
>> >>>           repS+ case_age+ case_status+ severity_level+
>> >>>           sla_status+ delivery_segmentation, data = SFDC, family =
>> >>> binomial)
>> >>>
>> >>> But it throws an error:-
>> >>> Warning messages:
>> >>> 1: glm.fit: algorithm did not converge
>> >>> 2: glm.fit: fitted probabilities numerically 0 or 1 occurred
>> >>>
>> >>> I checked online for the error and it says:
>> >>> "glm() uses an iterative re-weighted least squares algorithm. The
>> >>> algorithm
>> >>> hit the maximum number of allowed iterations before signalling
>> >>> convergence.
>> >>> The default,
>> >>> documented in ?glm.control is 25."
>> >>>
>> >>> Kindly suggest on the above case and if i have to change my outcome
>> var as
>> >>> as.factor.
>> >>>
>> >>> Thank you, Shivi
>> >>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide http://www.R-project.org/posti
>> >>> ng-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >>>
>> >>>
>> >> --
>> >> Michael
>> >> http://www.dewey.myzen.co.uk/home.html
>> >>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>
-------------- next part --------------
structure(list(support_cat = structure(c(1L, 2L, 3L, 2L, 4L, 
5L, 5L, 3L, 5L, 2L, 3L, 6L, 5L, 2L, 2L, 5L, 2L, 2L, 2L, 2L, 2L, 
2L, 7L, 2L, 7L, 2L, 2L, 2L, 2L, 2L, 2L, 7L, 2L, 5L, 7L, 7L, 2L, 
2L, 2L, 4L, 2L, 2L, 7L, 7L, 2L, 2L, 8L, 9L, 5L, 2L, 2L, 5L, 4L, 
2L, 2L, 7L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 7L, 7L, 2L, 8L, 8L, 9L, 
9L, 5L, 9L, 5L, 4L, 5L, 5L, 2L, 2L, 5L, 5L, 2L, 5L, 2L, 2L, 2L, 
7L, 2L, 2L, 10L, 7L, 5L, 7L, 2L, 2L, 2L, 2L, 3L, 2L, 3L, 9L, 
5L, 7L, 2L, 2L, 2L, 5L, 7L, 7L, 2L, 2L, 2L, 2L, 2L, 2L, 7L, 2L, 
7L, 2L, 2L, 1L, 2L, 4L, 2L, 4L, 2L, 2L, 2L, 2L, 5L, 2L, 9L, 5L, 
2L, 5L, 5L, 2L, 7L, 5L, 2L, 4L, 2L, 7L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 9L, 2L, 8L, 8L, 8L, 8L, 5L, 9L, 5L, 5L, 2L, 5L, 2L, 2L, 
7L, 2L, 2L, 4L, 5L, 2L, 2L, 2L, 2L, 10L, 5L, 7L, 2L, 1L, 2L, 
9L, 8L, 9L, 9L, 2L, 9L, 9L, 7L, 5L, 5L, 9L, 5L, 7L, 2L, 7L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 8L, 7L, 2L, 3L, 9L, 5L, 8L, 2L, 
2L, 11L, 3L, 5L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 9L, 2L, 9L, 3L, 
8L, 8L, 2L, 2L, 2L, 5L, 5L, 2L, 2L, 5L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 4L, 2L, 2L, 7L, 2L, 2L, 3L, 7L, 2L, 3L, 9L, 3L, 3L, 
9L, 7L, 2L, 3L, 2L, 2L, 5L, 5L, 2L, 7L, 2L, 5L, 2L, 2L, 2L, 5L, 
2L, 6L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 7L, 2L, 5L, 
2L, 2L, 2L, 2L, 9L, 3L, 7L, 10L, 2L, 10L, 9L, 7L, 2L, 9L, 5L, 
2L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 5L, 2L, 2L, 2L, 
2L, 4L, 2L, 2L, 3L, 5L, 2L, 3L, 9L, 8L, 2L, 9L, 7L, 12L, 5L, 
5L, 7L, 7L, 5L, 10L, 2L, 7L, 2L, 2L, 7L, 7L, 2L, 2L, 2L, 2L, 
2L, 7L, 1L, 2L, 2L, 9L, 2L, 9L, 9L, 7L, 9L, 7L, 8L, 2L, 5L, 8L, 
2L, 5L, 5L, 5L, 5L, 2L, 5L, 2L, 7L, 2L, 2L, 5L, 7L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 9L, 8L, 2L, 2L, 10L, 8L, 5L, 7L, 2L, 
5L, 5L, 10L, 2L, 2L, 5L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 5L, 
10L, 2L, 10L, 2L, 3L, 3L, 3L, 2L, 3L, 2L, 5L, 5L, 2L, 2L, 5L, 
2L, 2L, 2L, 7L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 13L, 10L, 7L, 
2L, 2L, 2L, 2L, 3L, 2L, 7L, 9L, 9L, 9L, 5L, 9L, 10L, 1L, 5L, 
2L, 5L, 2L, 5L, 13L, 7L, 2L, 2L, 2L, 7L, 2L, 2L, 2L, 7L, 2L, 
2L, 2L, 1L, 9L, 9L, 9L, 9L, 9L, 8L, 8L, 5L, 3L, 2L, 2L, 2L, 4L, 
2L, 2L, 5L, 2L, 2L, 2L, 2L, 2L, 2L, 5L, 2L, 2L, 2L, 2L, 2L, 3L, 
5L, 7L, 2L, 3L, 3L, 5L, 2L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 3L, 2L, 
3L, 8L, 5L, 5L, 5L, 2L, 5L, 2L, 3L, 9L, 2L, 2L, 7L, 3L, 1L, 9L, 
9L, 7L, 2L, 3L, 5L, 2L, 2L, 3L, 5L, 2L, 5L, 5L, 5L, 5L, 2L, 2L, 
5L, 5L, 2L, 6L, 1L, 6L, 5L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 5L, 10L, 5L, 7L, 11L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 2L, 5L, 
9L, 2L, 2L, 7L, 5L, 2L, 11L, 5L, 2L, 2L, 2L, 2L, 2L, 2L, 9L, 
2L, 6L, 8L, 8L, 9L, 2L, 8L, 8L, 6L, 5L, 7L, 5L, 5L, 5L, 2L, 2L, 
5L, 5L, 2L, 2L, 2L, 14L, 7L, 2L, 2L, 7L, 2L, 2L, 9L, 3L, 9L, 
9L, 5L, 5L, 5L, 5L, 2L, 7L, 5L, 12L, 2L, 2L, 2L, 2L, 5L, 5L, 
2L, 9L, 9L, 8L, 2L, 5L, 5L, 9L, 2L, 7L, 5L, 2L, 10L, 2L, 5L, 
2L, 2L, 2L, 10L, 2L, 2L, 2L, 7L, 9L, 3L, 3L, 3L, 5L, 2L, 7L, 
7L, 5L, 5L, 5L, 4L, 2L, 2L, 2L, 2L, 2L, 3L, 4L, 2L, 5L, 2L, 2L, 
7L, 3L, 2L, 3L, 9L, 3L, 9L, 9L, 9L, 9L, 9L, 2L, 2L, 2L, 7L, 2L, 
9L, 9L, 9L, 5L, 9L, 5L, 2L, 2L, 2L, 7L, 2L, 2L, 2L, 2L, 9L, 2L, 
2L, 10L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 7L, 1L, 8L, 
9L, 2L, 2L, 7L, 7L, 3L, 2L, 2L, 4L, 5L, 2L, 5L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 7L, 2L, 2L, 2L, 3L, 7L, 2L, 7L, 2L, 9L, 2L, 3L, 9L, 
2L, 8L, 8L, 9L, 5L, 5L, 5L, 2L, 5L, 7L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 3L, 
10L, 9L, 8L, 9L, 9L, 4L, 3L, 9L, 9L, 2L, 7L, 2L, 2L, 2L, 5L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 3L, 3L, 5L, 5L, 9L, 4L, 1L, 4L, 5L, 2L, 2L, 2L, 
2L, 2L, 5L, 2L, 2L, 2L, 2L, 4L, 2L, 9L, 9L, 9L, 5L, 9L, 2L, 9L, 
10L, 2L, 5L, 5L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 
7L, 9L, 9L, 3L, 3L, 3L, 2L, 9L, 2L, 9L, 5L, 5L, 4L, 2L, 2L, 2L, 
2L, 10L, 5L, 2L, 2L, 2L, 7L, 2L, 2L, 2L, 2L, 14L, 2L, 2L, 2L, 
2L, 2L, 10L, 2L, 10L, 2L, 9L, 9L, 3L, 5L, 2L, 2L, 2L, 2L, 2L, 
2L, 5L, 2L, 5L, 5L, 2L, 2L, 2L, 5L, 2L, 2L, 7L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 3L, 3L, 3L, 4L, 5L, 3L, 7L, 2L, 2L, 2L, 2L, 5L, 2L, 
2L, 2L, 10L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
3L, 3L, 9L, 3L, 9L, 3L, 8L, 8L, 3L, 9L, 5L, 2L, 2L, 2L, 2L, 5L, 
2L, 2L, 2L, 7L, 2L, 10L, 2L, 2L, 2L, 2L, 2L, 4L, 3L, 3L, 3L, 
2L, 14L, 4L, 5L, 2L, 2L, 2L, 7L, 7L, 4L, 2L, 2L, 2L, 2L, 7L, 
2L, 7L, 2L, 2L, 2L, 2L, 2L, 7L, 10L, 5L, 2L, 4L, 5L, 2L, 2L, 
2L, 2L, 9L, 10L, 5L, 5L, 8L, 3L, 5L, 5L, 5L, 2L, 2L, 2L, 7L, 
7L, 7L, 2L, 5L, 2L, 2L, 2L, 4L, 2L, 2L, 9L, 10L, 2L, 2L, 10L, 
10L, 1L, 2L, 2L, 4L, 5L, 2L, 7L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
10L, 7L, 15L, 5L, 9L, 5L, 2L, 2L, 5L, 5L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 10L, 1L, 2L, 7L, 2L, 
3L, 2L, 2L, 5L, 2L, 4L, 2L, 2L, 2L, 3L, 3L, 5L, 8L, 5L, 5L, 2L, 
2L, 5L, 5L, 2L, 2L, 2L, 2L, 14L, 4L, 7L, 2L, 2L, 2L, 2L, 2L, 
2L, 3L, 3L, 3L, 2L, 2L, 9L, 9L, 2L, 9L, 7L, 2L, 5L, 7L, 5L, 5L, 
9L, 10L, 5L, 2L, 2L, 7L, 5L, 2L, 5L, 2L, 2L, 2L, 2L, 2L, 2L, 
3L, 3L, 2L, 8L, 2L, 2L, 2L, 2L, 5L, 2L, 5L, 5L, 5L, 7L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 16L, 3L, 8L, 
9L, 2L, 2L, 4L, 8L, 2L, 5L, 3L, 2L, 2L, 9L, 5L, 5L, 4L, 5L, 2L, 
5L, 6L, 5L, 7L, 2L, 3L, 2L, 2L, 2L, 5L, 2L, 2L, 2L, 2L, 2L, 2L, 
4L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 7L, 7L, 1L, 7L, 1L, 3L, 2L, 3L, 
2L, 2L, 7L, 5L, 5L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
7L, 2L, 2L, 4L, 2L, 3L, 2L, 5L, 2L, 2L, 7L, 2L, 5L, 2L, 2L, 2L, 
5L, 10L, 2L, 2L, 2L, 2L, 7L, 2L, 2L, 16L, 2L, 2L, 3L, 2L, 2L, 
5L, 2L, 10L, 10L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 7L, 2L, 3L, 
2L, 16L, 3L, 9L, 9L, 7L, 8L, 2L, 5L, 5L, 7L, 2L, 7L, 2L, 5L, 
2L, 5L, 7L, 2L, 2L, 2L, 7L, 2L, 2L, 7L, 7L, 2L, 2L, 8L, 8L, 5L, 
7L, 2L, 7L, 2L, 2L, 5L, 2L, 2L, 2L, 2L, 10L, 2L, 2L, 9L, 8L, 
9L, 3L, 7L, 2L, 7L, 5L, 5L, 2L, 5L, 2L, 2L, 10L, 2L, 2L, 4L, 
2L, 2L, 7L, 2L, 2L, 2L, 2L, 7L, 2L, 2L, 1L, 3L, 2L, 2L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 3L, 5L, 5L, 5L, 2L, 8L, 3L, 5L, 5L, 2L, 2L, 
5L, 2L, 4L, 2L, 2L, 7L, 2L, 3L, 2L, 5L, 2L, 5L, 7L, 2L, 4L, 2L, 
5L, 2L, 11L, 2L, 3L, 7L, 2L, 2L, 2L, 2L, 3L, 2L, 9L, 9L, 9L, 
4L, 3L, 2L, 9L, 2L, 9L, 5L, 5L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 9L, 9L, 3L, 
3L, 9L, 3L, 5L, 8L, 2L, 5L, 2L, 7L, 7L, 7L, 2L, 2L, 2L, 2L, 2L, 
2L, 10L, 2L, 10L, 2L, 7L, 2L, 2L, 9L, 2L, 2L, 3L, 7L, 9L, 7L, 
2L, 3L, 9L, 5L, 7L, 2L, 2L, 5L, 2L, 2L, 2L, 2L, 2L, 7L, 2L, 2L, 
2L, 7L, 5L, 14L, 2L, 2L, 10L, 6L, 2L, 2L, 2L, 2L, 2L, 2L, 11L, 
2L, 2L, 2L, 2L, 2L, 9L, 2L, 2L, 4L, 9L, 3L, 8L, 5L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 3L, 9L, 5L, 5L, 5L, 10L, 5L, 2L, 1L, 5L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 5L, 7L, 5L, 5L, 
5L, 2L, 2L, 2L, 2L, 14L, 6L, 4L, 2L, 2L, 2L, 2L, 2L, 4L, 4L, 
2L, 2L, 5L, 3L, 3L, 2L, 2L, 5L, 5L, 5L, 5L, 3L, 10L, 2L, 5L, 
5L, 5L, 2L, 2L, 6L, 5L, 2L, 2L, 2L, 16L, 2L, 2L, 2L, 2L, 2L, 
4L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 10L, 
5L, 5L, 2L, 2L, 3L, 2L, 5L, 2L, 5L, 5L, 2L, 2L, 7L, 2L, 5L, 2L, 
2L, 2L, 4L, 2L, 2L, 2L, 2L, 7L, 2L, 2L, 2L, 7L, 9L, 1L, 3L, 9L, 
9L, 9L, 9L, 9L, 2L, 10L, 5L, 5L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
4L, 16L, 2L, 3L, 3L, 2L, 9L, 2L, 9L, 2L, 3L, 9L, 5L, 5L, 5L, 
2L, 5L, 5L, 2L, 5L, 2L, 2L, 4L, 10L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 9L, 9L, 9L, 10L, 9L, 7L, 5L, 2L, 5L, 5L, 5L, 5L, 7L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 
5L, 9L, 2L, 1L, 3L, 2L, 2L, 2L, 5L, 5L, 9L, 5L, 3L, 10L, 2L, 
3L, 2L, 2L, 7L, 6L, 5L, 7L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 
2L, 9L, 2L, 9L, 5L, 10L, 5L, 5L, 5L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 9L, 2L, 3L, 2L, 2L, 9L, 5L, 5L, 5L, 5L, 3L, 3L, 2L, 
2L, 5L, 2L, 2L, 2L, 2L, 2L, 10L, 2L, 7L, 2L, 2L, 2L, 2L, 2L, 
2L, 9L, 9L, 2L, 3L, 9L, 3L, 2L, 5L, 5L, 7L, 5L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 14L, 2L, 2L, 2L, 16L, 2L, 5L, 2L, 5L, 2L, 
2L, 5L, 10L, 5L, 5L, 2L, 5L, 4L, 2L, 2L, 2L, 5L, 2L, 2L, 2L, 
2L, 1L, 10L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 10L, 2L, 4L, 
3L, 5L, 2L, 9L, 2L, 9L, 5L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 7L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 7L, 2L, 2L, 7L, 
9L, 2L, 2L, 2L, 5L, 5L, 5L, 2L, 2L, 2L, 8L, 3L, 3L, 7L, 8L, 2L, 
9L, 10L, 5L, 5L, 5L, 5L, 5L, 2L, 2L, 2L, 5L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 2L, 3L, 2L, 2L, 7L, 9L, 3L, 3L, 
5L, 5L, 5L, 5L, 5L, 2L), .Label = c("a", "b", "c", "d", "e", 
"f", "g", "h", "i", "j", "k", "l", "m", "n", "o", "p", "q"), class = "factor"), 
    region = structure(c(1L, 2L, 3L, 2L, 2L, 4L, 4L, 3L, 4L, 
    2L, 3L, 4L, 4L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 
    1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 4L, 1L, 1L, 2L, 2L, 2L, 
    1L, 2L, 2L, 1L, 1L, 2L, 2L, 5L, 5L, 4L, 2L, 2L, 4L, 1L, 2L, 
    2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 5L, 5L, 5L, 
    5L, 4L, 5L, 4L, 4L, 4L, 4L, 2L, 2L, 4L, 4L, 2L, 4L, 2L, 2L, 
    2L, 1L, 2L, 2L, 1L, 1L, 4L, 1L, 2L, 2L, 2L, 2L, 3L, 2L, 3L, 
    5L, 4L, 1L, 2L, 2L, 2L, 4L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 
    1L, 2L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 4L, 
    2L, 5L, 4L, 2L, 4L, 4L, 2L, 1L, 4L, 2L, 1L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 5L, 2L, 5L, 5L, 5L, 5L, 4L, 5L, 4L, 
    4L, 2L, 4L, 2L, 2L, 1L, 2L, 2L, 1L, 4L, 2L, 2L, 2L, 2L, 1L, 
    4L, 1L, 2L, 1L, 2L, 5L, 5L, 5L, 5L, 2L, 5L, 5L, 1L, 4L, 4L, 
    5L, 4L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 5L, 
    1L, 2L, 3L, 5L, 4L, 5L, 2L, 2L, 1L, 3L, 4L, 2L, 1L, 2L, 2L, 
    2L, 2L, 2L, 5L, 2L, 5L, 3L, 5L, 5L, 2L, 2L, 2L, 4L, 4L, 2L, 
    2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 
    2L, 2L, 3L, 2L, 2L, 3L, 5L, 3L, 3L, 5L, 4L, 2L, 3L, 2L, 2L, 
    4L, 4L, 2L, 1L, 2L, 4L, 2L, 2L, 2L, 4L, 2L, 4L, 2L, 2L, 2L, 
    2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 4L, 2L, 2L, 2L, 2L, 
    5L, 3L, 1L, 1L, 2L, 1L, 5L, 2L, 2L, 5L, 4L, 2L, 2L, 2L, 2L, 
    2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 1L, 2L, 
    2L, 3L, 4L, 2L, 3L, 5L, 5L, 2L, 5L, 2L, 4L, 4L, 4L, 1L, 1L, 
    4L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 
    2L, 2L, 5L, 2L, 5L, 5L, 2L, 5L, 2L, 5L, 2L, 4L, 5L, 2L, 4L, 
    4L, 4L, 4L, 2L, 4L, 2L, 1L, 2L, 2L, 4L, 1L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 5L, 5L, 2L, 2L, 1L, 5L, 4L, 2L, 2L, 4L, 
    4L, 4L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 1L, 
    2L, 1L, 2L, 3L, 3L, 3L, 2L, 3L, 2L, 4L, 4L, 2L, 2L, 4L, 2L, 
    2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 
    2L, 2L, 2L, 3L, 2L, 1L, 5L, 5L, 5L, 4L, 5L, 1L, 1L, 4L, 2L, 
    4L, 2L, 4L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 4L, 3L, 2L, 2L, 2L, 1L, 
    2L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 
    3L, 4L, 1L, 2L, 3L, 3L, 4L, 2L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    3L, 2L, 3L, 5L, 4L, 4L, 4L, 2L, 4L, 2L, 3L, 5L, 2L, 2L, 2L, 
    3L, 1L, 5L, 5L, 1L, 2L, 3L, 4L, 2L, 2L, 3L, 4L, 2L, 4L, 4L, 
    4L, 4L, 2L, 2L, 4L, 4L, 2L, 4L, 1L, 4L, 4L, 2L, 2L, 1L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 4L, 4L, 
    4L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 
    3L, 3L, 3L, 3L, 2L, 4L, 5L, 2L, 2L, 1L, 4L, 2L, 1L, 4L, 2L, 
    2L, 2L, 2L, 2L, 2L, 5L, 2L, 1L, 5L, 5L, 5L, 2L, 5L, 5L, 1L, 
    4L, 1L, 4L, 4L, 4L, 2L, 2L, 4L, 4L, 2L, 2L, 2L, 6L, 1L, 2L, 
    2L, 1L, 2L, 2L, 5L, 3L, 5L, 5L, 4L, 4L, 4L, 4L, 2L, 1L, 4L, 
    1L, 2L, 2L, 2L, 2L, 4L, 4L, 2L, 5L, 5L, 5L, 2L, 4L, 4L, 5L, 
    2L, 1L, 4L, 2L, 1L, 2L, 4L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 
    5L, 3L, 3L, 3L, 4L, 2L, 1L, 1L, 4L, 1L, 4L, 4L, 2L, 2L, 2L, 
    2L, 2L, 3L, 1L, 2L, 4L, 2L, 2L, 1L, 3L, 2L, 3L, 5L, 3L, 5L, 
    5L, 5L, 5L, 5L, 2L, 2L, 2L, 1L, 2L, 5L, 5L, 5L, 4L, 5L, 1L, 
    2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 5L, 2L, 2L, 1L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 5L, 5L, 2L, 2L, 2L, 1L, 
    3L, 2L, 2L, 4L, 4L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 
    2L, 2L, 2L, 3L, 1L, 2L, 1L, 2L, 5L, 2L, 3L, 5L, 2L, 5L, 5L, 
    5L, 4L, 4L, 4L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 3L, 1L, 
    5L, 5L, 5L, 5L, 1L, 3L, 5L, 5L, 2L, 1L, 2L, 2L, 2L, 4L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 3L, 3L, 4L, 4L, 5L, 4L, 1L, 1L, 4L, 2L, 2L, 
    2L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 1L, 2L, 5L, 5L, 5L, 4L, 5L, 
    2L, 5L, 1L, 2L, 4L, 4L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 1L, 1L, 5L, 5L, 3L, 3L, 3L, 2L, 5L, 2L, 5L, 4L, 4L, 1L, 
    2L, 2L, 2L, 2L, 1L, 4L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 
    2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 5L, 5L, 3L, 4L, 2L, 2L, 
    2L, 2L, 2L, 2L, 4L, 2L, 4L, 4L, 2L, 2L, 2L, 4L, 2L, 2L, 1L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 4L, 4L, 3L, 1L, 2L, 
    2L, 2L, 2L, 4L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 3L, 3L, 5L, 3L, 5L, 3L, 5L, 5L, 3L, 5L, 
    4L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 
    2L, 2L, 4L, 3L, 3L, 3L, 2L, 6L, 1L, 4L, 2L, 2L, 2L, 1L, 1L, 
    1L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 
    4L, 2L, 4L, 1L, 2L, 2L, 2L, 2L, 5L, 1L, 4L, 4L, 5L, 3L, 4L, 
    4L, 4L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 4L, 2L, 2L, 2L, 1L, 2L, 
    2L, 5L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 4L, 2L, 1L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 7L, 4L, 5L, 4L, 2L, 2L, 4L, 
    1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 1L, 1L, 2L, 1L, 2L, 3L, 2L, 2L, 4L, 2L, 4L, 2L, 2L, 2L, 
    3L, 3L, 4L, 5L, 4L, 4L, 2L, 2L, 4L, 4L, 2L, 2L, 2L, 2L, 1L, 
    1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 2L, 2L, 5L, 5L, 
    2L, 5L, 1L, 2L, 4L, 4L, 4L, 4L, 5L, 1L, 4L, 2L, 2L, 1L, 4L, 
    2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 2L, 5L, 2L, 2L, 2L, 
    2L, 1L, 2L, 4L, 4L, 4L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 1L, 2L, 1L, 3L, 5L, 5L, 2L, 2L, 2L, 5L, 2L, 
    4L, 3L, 2L, 2L, 5L, 4L, 4L, 1L, 4L, 2L, 4L, 4L, 4L, 1L, 2L, 
    3L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 
    2L, 2L, 2L, 3L, 2L, 1L, 1L, 1L, 1L, 3L, 2L, 3L, 2L, 2L, 1L, 
    4L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 
    2L, 2L, 2L, 3L, 2L, 4L, 2L, 2L, 1L, 2L, 4L, 2L, 2L, 2L, 4L, 
    1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 3L, 2L, 2L, 1L, 
    2L, 4L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 3L, 2L, 
    1L, 3L, 5L, 5L, 1L, 5L, 2L, 4L, 4L, 1L, 2L, 1L, 2L, 4L, 2L, 
    4L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 5L, 5L, 4L, 
    1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 5L, 5L, 
    5L, 3L, 1L, 2L, 1L, 4L, 4L, 2L, 4L, 2L, 2L, 1L, 2L, 2L, 1L, 
    2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 3L, 2L, 2L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 3L, 1L, 4L, 4L, 2L, 5L, 3L, 4L, 4L, 
    2L, 2L, 4L, 2L, 1L, 2L, 2L, 2L, 2L, 3L, 2L, 4L, 2L, 4L, 1L, 
    2L, 1L, 2L, 4L, 2L, 1L, 2L, 3L, 1L, 2L, 2L, 2L, 2L, 3L, 2L, 
    5L, 5L, 5L, 1L, 3L, 2L, 5L, 2L, 5L, 4L, 4L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    3L, 2L, 5L, 5L, 3L, 3L, 5L, 3L, 4L, 5L, 2L, 4L, 2L, 1L, 1L, 
    1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L, 5L, 
    2L, 2L, 3L, 1L, 5L, 1L, 2L, 3L, 5L, 4L, 1L, 2L, 2L, 4L, 2L, 
    2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 4L, 6L, 2L, 2L, 1L, 4L, 
    2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 5L, 2L, 2L, 
    1L, 5L, 3L, 5L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 
    5L, 4L, 4L, 4L, 4L, 4L, 2L, 1L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 3L, 2L, 4L, 1L, 4L, 4L, 4L, 2L, 2L, 2L, 2L, 
    6L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 4L, 3L, 3L, 
    2L, 2L, 4L, 4L, 4L, 4L, 3L, 1L, 2L, 4L, 4L, 4L, 2L, 2L, 1L, 
    4L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 1L, 4L, 4L, 2L, 2L, 3L, 
    2L, 4L, 2L, 4L, 4L, 2L, 2L, 1L, 2L, 4L, 2L, 2L, 2L, 1L, 2L, 
    2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 5L, 1L, 3L, 5L, 5L, 5L, 5L, 
    5L, 2L, 1L, 4L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 
    3L, 3L, 2L, 5L, 2L, 5L, 2L, 3L, 5L, 4L, 4L, 1L, 2L, 4L, 4L, 
    2L, 4L, 2L, 2L, 4L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 5L, 5L, 
    5L, 1L, 5L, 1L, 4L, 2L, 4L, 4L, 4L, 4L, 1L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 4L, 5L, 
    2L, 1L, 3L, 2L, 2L, 2L, 4L, 4L, 5L, 4L, 3L, 4L, 2L, 3L, 2L, 
    2L, 1L, 4L, 4L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 
    5L, 2L, 5L, 4L, 1L, 4L, 4L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 5L, 2L, 3L, 2L, 2L, 5L, 4L, 4L, 4L, 4L, 3L, 3L, 2L, 
    2L, 4L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 
    2L, 5L, 5L, 2L, 3L, 5L, 3L, 2L, 4L, 4L, 1L, 4L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, 4L, 2L, 4L, 
    2L, 2L, 4L, 1L, 4L, 4L, 2L, 4L, 1L, 2L, 2L, 2L, 4L, 2L, 2L, 
    2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 
    1L, 3L, 4L, 2L, 5L, 2L, 5L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 5L, 2L, 2L, 2L, 4L, 4L, 4L, 2L, 2L, 2L, 5L, 3L, 
    3L, 2L, 5L, 2L, 5L, 1L, 4L, 4L, 4L, 4L, 4L, 2L, 2L, 2L, 4L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 3L, 2L, 
    2L, 2L, 5L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 2L), .Label = c("a", 
    "b", "c", "d", "e", "f", "g"), class = "factor"), support_lvl = structure(c(2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 
    2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L), .Label = c("basc12", "basic1", "Other"), class = "factor"), 
    skill_group = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 
    1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
    2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    2L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 
    2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 
    2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 
    1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 
    1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 
    1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 
    2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 
    2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 
    2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 
    2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 
    1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
    1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 
    1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 
    1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 
    1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 
    2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 
    2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 
    1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 
    2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 
    2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 
    2L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 
    1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 
    2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 
    1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 
    2L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 
    2L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
    1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 
    1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 
    1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 
    2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 
    2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 
    2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 
    2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 
    1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    2L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 
    1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 
    2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 
    2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
    1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 
    1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 
    2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 
    1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 
    1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 
    2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 
    1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 
    1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("one", 
    "two"), class = "factor"), application_area = structure(c(1L, 
    10L, 1L, 7L, 1L, 1L, 1L, 2L, 1L, 3L, 2L, 3L, 1L, 7L, 1L, 
    1L, 3L, 3L, 1L, 2L, 15L, 3L, 3L, 7L, 1L, 1L, 3L, 1L, 1L, 
    1L, 7L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 14L, 
    1L, 2L, 3L, 3L, 1L, 1L, 2L, 2L, 3L, 1L, 1L, 1L, 1L, 1L, 5L, 
    9L, 3L, 3L, 3L, 9L, 2L, 7L, 3L, 1L, 1L, 1L, 13L, 3L, 3L, 
    1L, 1L, 2L, 1L, 1L, 1L, 5L, 1L, 1L, 3L, 3L, 1L, 1L, 9L, 1L, 
    2L, 1L, 1L, 1L, 2L, 1L, 3L, 1L, 1L, 2L, 9L, 1L, 1L, 1L, 3L, 
    2L, 1L, 3L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 3L, 1L, 1L, 3L, 1L, 
    1L, 1L, 3L, 3L, 2L, 2L, 1L, 15L, 2L, 1L, 3L, 7L, 1L, 3L, 
    1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 3L, 2L, 1L, 3L, 
    1L, 1L, 1L, 1L, 2L, 1L, 3L, 1L, 3L, 13L, 3L, 1L, 2L, 7L, 
    3L, 2L, 1L, 1L, 1L, 1L, 11L, 1L, 1L, 2L, 1L, 1L, 1L, 3L, 
    2L, 3L, 3L, 1L, 1L, 3L, 1L, 3L, 15L, 1L, 1L, 1L, 1L, 3L, 
    1L, 1L, 1L, 1L, 1L, 2L, 1L, 10L, 3L, 1L, 1L, 1L, 1L, 3L, 
    1L, 3L, 1L, 2L, 1L, 2L, 1L, 7L, 2L, 3L, 2L, 1L, 1L, 1L, 3L, 
    2L, 7L, 2L, 1L, 3L, 2L, 3L, 9L, 1L, 7L, 1L, 3L, 1L, 1L, 12L, 
    2L, 1L, 1L, 3L, 1L, 1L, 1L, 3L, 12L, 1L, 13L, 3L, 1L, 2L, 
    3L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 12L, 
    3L, 1L, 1L, 3L, 1L, 2L, 1L, 1L, 3L, 1L, 9L, 9L, 1L, 1L, 1L, 
    1L, 2L, 5L, 2L, 1L, 3L, 1L, 1L, 2L, 3L, 1L, 2L, 5L, 10L, 
    1L, 1L, 1L, 2L, 1L, 1L, 5L, 1L, 2L, 1L, 3L, 1L, 3L, 3L, 1L, 
    7L, 3L, 9L, 1L, 1L, 1L, 2L, 1L, 1L, 3L, 2L, 2L, 1L, 3L, 1L, 
    7L, 1L, 3L, 3L, 3L, 1L, 12L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 
    1L, 1L, 3L, 1L, 3L, 2L, 2L, 1L, 1L, 2L, 1L, 2L, 15L, 12L, 
    3L, 3L, 1L, 3L, 1L, 12L, 1L, 7L, 3L, 1L, 1L, 1L, 3L, 1L, 
    2L, 1L, 1L, 1L, 7L, 2L, 2L, 3L, 1L, 3L, 1L, 14L, 1L, 9L, 
    9L, 1L, 1L, 1L, 2L, 9L, 2L, 7L, 9L, 2L, 2L, 3L, 3L, 1L, 15L, 
    2L, 1L, 3L, 1L, 1L, 1L, 13L, 3L, 1L, 2L, 2L, 2L, 15L, 7L, 
    1L, 3L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 3L, 1L, 7L, 1L, 
    1L, 2L, 1L, 1L, 3L, 1L, 1L, 2L, 3L, 3L, 2L, 15L, 7L, 2L, 
    2L, 3L, 2L, 1L, 15L, 6L, 1L, 1L, 1L, 3L, 3L, 2L, 1L, 1L, 
    3L, 1L, 3L, 1L, 3L, 3L, 1L, 1L, 1L, 3L, 1L, 1L, 1L, 16L, 
    3L, 1L, 1L, 15L, 2L, 1L, 12L, 1L, 3L, 1L, 1L, 2L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 3L, 2L, 1L, 1L, 
    1L, 9L, 3L, 3L, 1L, 1L, 1L, 2L, 7L, 2L, 2L, 3L, 1L, 1L, 9L, 
    3L, 1L, 2L, 2L, 1L, 3L, 3L, 1L, 3L, 1L, 1L, 13L, 1L, 1L, 
    5L, 5L, 3L, 3L, 1L, 1L, 1L, 3L, 2L, 2L, 3L, 2L, 2L, 1L, 1L, 
    1L, 1L, 3L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 3L, 1L, 1L, 1L, 
    2L, 3L, 1L, 9L, 1L, 1L, 2L, 3L, 11L, 1L, 2L, 3L, 3L, 9L, 
    2L, 3L, 3L, 1L, 5L, 1L, 1L, 9L, 3L, 2L, 1L, 3L, 7L, 7L, 2L, 
    1L, 1L, 2L, 3L, 3L, 9L, 10L, 1L, 9L, 3L, 1L, 10L, 1L, 15L, 
    3L, 2L, 1L, 2L, 1L, 1L, 2L, 3L, 2L, 1L, 1L, 1L, 1L, 2L, 13L, 
    1L, 1L, 1L, 3L, 1L, 7L, 3L, 1L, 3L, 1L, 1L, 1L, 3L, 1L, 3L, 
    3L, 3L, 1L, 14L, 1L, 3L, 2L, 3L, 1L, 3L, 3L, 2L, 1L, 1L, 
    1L, 7L, 1L, 1L, 1L, 5L, 1L, 2L, 1L, 1L, 14L, 9L, 15L, 1L, 
    3L, 1L, 2L, 3L, 12L, 2L, 1L, 2L, 2L, 2L, 2L, 7L, 1L, 3L, 
    1L, 2L, 1L, 1L, 2L, 1L, 1L, 3L, 14L, 3L, 1L, 1L, 3L, 1L, 
    9L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 7L, 1L, 2L, 
    1L, 3L, 9L, 1L, 1L, 15L, 11L, 1L, 1L, 1L, 1L, 5L, 5L, 3L, 
    1L, 1L, 1L, 1L, 3L, 3L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 
    1L, 1L, 1L, 9L, 1L, 2L, 9L, 9L, 2L, 1L, 9L, 1L, 3L, 1L, 1L, 
    1L, 2L, 2L, 1L, 2L, 5L, 1L, 1L, 3L, 1L, 3L, 14L, 7L, 1L, 
    1L, 1L, 1L, 3L, 2L, 3L, 7L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 
    3L, 1L, 3L, 1L, 1L, 2L, 3L, 1L, 3L, 1L, 1L, 1L, 2L, 7L, 7L, 
    1L, 2L, 3L, 3L, 9L, 1L, 1L, 10L, 1L, 1L, 1L, 2L, 1L, 3L, 
    12L, 3L, 1L, 1L, 1L, 3L, 3L, 9L, 2L, 13L, 1L, 7L, 1L, 3L, 
    15L, 3L, 1L, 12L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 
    2L, 3L, 1L, 1L, 1L, 1L, 2L, 1L, 7L, 1L, 1L, 3L, 2L, 2L, 3L, 
    1L, 1L, 1L, 1L, 1L, 5L, 2L, 2L, 5L, 2L, 2L, 13L, 1L, 2L, 
    1L, 1L, 2L, 1L, 1L, 15L, 3L, 1L, 1L, 1L, 2L, 1L, 5L, 9L, 
    2L, 12L, 3L, 1L, 1L, 2L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 15L, 3L, 9L, 1L, 3L, 1L, 3L, 1L, 2L, 13L, 13L, 1L, 
    1L, 2L, 1L, 1L, 3L, 1L, 1L, 5L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 
    1L, 3L, 9L, 3L, 3L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 5L, 1L, 2L, 
    1L, 3L, 1L, 15L, 1L, 2L, 3L, 12L, 1L, 1L, 2L, 3L, 9L, 1L, 
    1L, 3L, 1L, 13L, 1L, 3L, 2L, 3L, 1L, 9L, 3L, 7L, 3L, 2L, 
    1L, 2L, 1L, 1L, 1L, 13L, 1L, 2L, 1L, 2L, 1L, 13L, 1L, 15L, 
    1L, 9L, 1L, 2L, 1L, 12L, 3L, 1L, 1L, 3L, 1L, 1L, 2L, 1L, 
    1L, 2L, 3L, 1L, 2L, 2L, 1L, 3L, 3L, 1L, 1L, 1L, 1L, 9L, 7L, 
    1L, 1L, 1L, 3L, 2L, 9L, 3L, 5L, 2L, 7L, 1L, 3L, 2L, 1L, 3L, 
    3L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 1L, 1L, 
    9L, 2L, 2L, 3L, 1L, 3L, 13L, 15L, 1L, 9L, 1L, 1L, 7L, 1L, 
    1L, 3L, 1L, 3L, 3L, 15L, 15L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 
    1L, 7L, 1L, 12L, 1L, 1L, 2L, 9L, 1L, 2L, 1L, 1L, 1L, 9L, 
    2L, 2L, 2L, 3L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 3L, 3L, 2L, 7L, 
    1L, 2L, 2L, 1L, 1L, 2L, 3L, 9L, 1L, 2L, 3L, 12L, 1L, 1L, 
    1L, 1L, 3L, 2L, 3L, 1L, 1L, 2L, 2L, 13L, 1L, 3L, 3L, 1L, 
    15L, 1L, 2L, 2L, 9L, 13L, 1L, 1L, 2L, 1L, 12L, 3L, 1L, 2L, 
    1L, 1L, 1L, 1L, 2L, 3L, 9L, 1L, 3L, 7L, 3L, 2L, 1L, 1L, 3L, 
    3L, 3L, 15L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 
    3L, 9L, 2L, 1L, 1L, 1L, 2L, 7L, 1L, 1L, 1L, 1L, 1L, 7L, 1L, 
    3L, 12L, 9L, 1L, 2L, 2L, 2L, 3L, 1L, 3L, 9L, 3L, 1L, 1L, 
    1L, 1L, 1L, 12L, 3L, 1L, 1L, 7L, 3L, 1L, 3L, 1L, 3L, 3L, 
    3L, 1L, 1L, 9L, 5L, 2L, 2L, 1L, 15L, 5L, 15L, 1L, 1L, 2L, 
    3L, 2L, 7L, 3L, 1L, 3L, 3L, 1L, 1L, 1L, 2L, 7L, 1L, 1L, 2L, 
    2L, 1L, 1L, 3L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 9L, 
    2L, 1L, 3L, 3L, 1L, 15L, 13L, 2L, 1L, 1L, 1L, 3L, 1L, 3L, 
    2L, 9L, 2L, 1L, 1L, 2L, 1L, 5L, 1L, 13L, 2L, 5L, 2L, 9L, 
    1L, 1L, 2L, 1L, 3L, 12L, 7L, 3L, 1L, 1L, 2L, 7L, 1L, 1L, 
    7L, 7L, 2L, 1L, 15L, 1L, 3L, 1L, 3L, 1L, 1L, 9L, 12L, 1L, 
    3L, 1L, 2L, 7L, 2L, 3L, 1L, 9L, 2L, 2L, 1L, 3L, 2L, 1L, 1L, 
    2L, 1L, 1L, 5L, 1L, 1L, 3L, 15L, 5L, 1L, 1L, 1L, 1L, 1L, 
    5L, 2L, 1L, 13L, 1L, 1L, 1L, 7L, 3L, 1L, 3L, 9L, 1L, 1L, 
    13L, 3L, 12L, 2L, 1L, 15L, 1L, 3L, 2L, 16L, 1L, 3L, 1L, 1L, 
    15L, 1L, 1L, 7L, 3L, 2L, 2L, 2L, 7L, 2L, 1L, 1L, 9L, 3L, 
    1L, 15L, 7L, 3L, 1L, 3L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 
    1L, 13L, 1L, 2L, 2L, 1L, 1L, 3L, 2L, 5L, 1L, 1L, 2L, 1L, 
    1L, 3L, 1L, 2L, 3L, 3L, 9L, 3L, 1L, 1L, 1L, 3L, 3L, 1L, 1L, 
    1L, 2L, 7L, 2L, 1L, 1L, 2L, 2L, 1L, 13L, 3L, 11L, 1L, 1L, 
    1L, 3L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 3L, 3L, 13L, 2L, 1L, 
    2L, 1L, 2L, 1L, 14L, 2L, 9L, 2L, 2L, 7L, 1L, 3L, 1L, 1L, 
    1L, 2L, 1L, 1L, 1L, 1L, 13L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 
    12L, 3L, 2L, 2L, 3L, 1L, 3L, 2L, 1L, 2L, 7L, 3L, 2L, 2L, 
    1L, 3L, 1L, 1L, 1L, 1L, 3L, 7L, 3L, 15L, 1L, 1L, 2L, 7L, 
    2L, 2L, 3L, 12L, 1L, 2L, 2L, 1L, 2L, 2L, 3L, 2L, 3L, 1L, 
    7L, 1L, 3L, 1L, 3L, 1L, 7L, 1L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 2L, 1L, 3L, 1L, 1L, 2L, 1L, 3L, 3L, 1L, 2L, 1L, 
    1L, 9L, 9L, 1L, 1L, 3L, 10L, 2L, 2L, 1L, 3L, 1L, 1L, 12L, 
    1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 7L, 1L, 1L, 1L, 
    3L, 1L, 1L, 3L, 2L, 1L, 3L, 3L, 1L, 2L, 3L, 2L, 1L, 7L, 2L, 
    2L, 1L, 1L, 1L, 2L, 5L, 3L, 1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L, 
    3L, 2L, 2L, 2L, 3L, 1L, 3L, 13L, 3L, 1L, 1L, 1L, 3L, 2L, 
    3L, 15L, 9L, 5L, 1L, 1L, 1L, 7L, 3L, 3L, 2L, 15L, 1L, 1L, 
    3L, 1L, 1L, 1L, 1L, 1L, 3L, 1L, 1L, 1L, 9L, 1L, 2L, 1L, 13L, 
    2L, 5L, 3L, 1L, 12L, 3L, 7L, 2L, 3L, 11L, 2L, 3L, 2L, 2L, 
    1L, 2L, 1L, 3L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 
    1L, 1L, 2L, 1L, 2L, 3L, 1L, 9L, 9L, 1L, 7L, 2L, 3L, 7L, 3L, 
    1L, 3L, 2L, 1L, 1L, 5L, 15L, 2L, 1L, 2L, 1L, 3L, 3L, 2L, 
    2L, 7L, 2L, 1L, 1L, 1L, 2L, 3L, 2L, 1L, 1L, 15L, 1L, 1L, 
    3L, 12L, 1L, 2L, 3L, 3L, 1L, 9L, 1L, 1L, 2L, 3L, 1L, 2L, 
    1L, 1L, 1L, 1L, 2L, 1L, 3L, 1L, 9L, 1L, 2L, 3L, 15L, 2L, 
    1L, 2L, 1L, 1L, 7L, 1L, 3L, 7L, 1L, 1L, 3L, 1L, 3L, 7L, 1L, 
    1L, 7L, 2L, 3L, 11L, 3L, 3L, 5L, 1L, 5L, 1L, 2L, 3L, 4L, 
    1L, 3L, 2L, 9L, 1L, 9L, 7L, 13L, 3L, 1L, 1L, 3L, 1L, 1L, 
    12L, 2L, 13L, 1L, 1L, 3L, 2L, 1L, 3L, 1L, 3L, 1L, 2L, 1L, 
    1L, 9L, 1L, 1L, 3L, 1L, 7L, 2L, 1L, 1L, 2L, 11L, 1L, 1L, 
    1L, 1L, 3L, 1L, 2L, 2L, 2L, 1L, 3L, 2L, 2L, 7L, 1L, 14L, 
    1L, 2L, 1L, 1L, 1L, 3L, 2L, 2L, 3L, 1L, 3L, 1L, 2L, 10L, 
    2L, 3L, 2L, 12L, 1L, 1L, 1L, 3L, 3L, 12L, 1L, 2L, 2L, 2L, 
    13L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 3L, 1L, 1L, 3L, 2L, 
    2L, 1L, 1L, 3L, 2L, 12L, 1L, 1L, 3L, 2L, 3L, 14L, 1L, 1L, 
    3L, 7L, 1L, 13L, 3L, 1L, 2L, 2L, 13L, 5L, 3L, 1L, 3L, 2L, 
    2L, 3L, 3L, 2L, 2L, 9L, 2L, 2L, 1L, 1L, 3L, 3L, 2L, 7L, 1L, 
    3L, 2L, 2L, 1L, 1L, 2L, 3L, 1L, 3L, 1L, 2L, 3L, 1L, 2L, 15L, 
    2L, 7L, 15L, 1L, 2L, 1L, 1L, 1L, 9L, 1L, 1L, 2L, 2L, 2L, 
    2L, 2L, 13L, 2L, 10L, 2L, 5L, 3L, 1L, 1L, 5L, 2L, 2L, 2L, 
    2L, 9L, 1L, 3L, 1L, 2L, 13L, 1L, 15L, 1L, 15L, 1L, 15L, 1L, 
    1L, 2L, 1L, 3L, 1L, 13L, 16L, 1L, 2L, 1L, 3L, 1L, 3L, 2L, 
    3L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 15L, 1L, 2L, 1L, 2L, 2L, 
    1L, 1L, 1L, 2L), .Label = c("a", "b", "c", "d", "e", "f", 
    "g", "h", "i", "j", "k", "l", "m", "n", "o", "p"), class = "factor"), 
    functional_area = structure(c(5L, 38L, 23L, 28L, 23L, 59L, 
    23L, 17L, 1L, 10L, 17L, 51L, 23L, 28L, 23L, 5L, 8L, 8L, 23L, 
    5L, 61L, 30L, 2L, 22L, 23L, 23L, 45L, 5L, 23L, 23L, 28L, 
    23L, 23L, 5L, 23L, 23L, 23L, 23L, 23L, 1L, 23L, 23L, 23L, 
    1L, 23L, 17L, 7L, 7L, 23L, 23L, 17L, 17L, 16L, 59L, 23L, 
    1L, 23L, 23L, 50L, 19L, 21L, 41L, 21L, 19L, 17L, 28L, 45L, 
    61L, 23L, 5L, 22L, 52L, 12L, 23L, 23L, 17L, 61L, 23L, 23L, 
    64L, 23L, 5L, 16L, 8L, 23L, 23L, 19L, 5L, 17L, 23L, 23L, 
    23L, 17L, 23L, 7L, 23L, 43L, 17L, 19L, 23L, 23L, 1L, 51L, 
    17L, 23L, 42L, 23L, 17L, 23L, 23L, 9L, 23L, 17L, 51L, 23L, 
    23L, 51L, 23L, 23L, 23L, 21L, 57L, 5L, 17L, 23L, 63L, 9L, 
    23L, 8L, 22L, 1L, 7L, 5L, 23L, 23L, 5L, 23L, 9L, 61L, 5L, 
    23L, 23L, 23L, 51L, 17L, 61L, 8L, 23L, 23L, 23L, 23L, 17L, 
    61L, 8L, 43L, 8L, 36L, 7L, 1L, 17L, 28L, 35L, 17L, 23L, 23L, 
    5L, 23L, 60L, 43L, 23L, 17L, 23L, 23L, 23L, 8L, 17L, 51L, 
    21L, 23L, 5L, 7L, 23L, 7L, 61L, 23L, 5L, 23L, 23L, 21L, 23L, 
    43L, 23L, 5L, 1L, 9L, 1L, 53L, 8L, 23L, 5L, 23L, 1L, 51L, 
    43L, 51L, 23L, 17L, 5L, 17L, 43L, 22L, 17L, 51L, 9L, 5L, 
    23L, 5L, 8L, 9L, 28L, 17L, 23L, 45L, 17L, 16L, 19L, 23L, 
    28L, 23L, 8L, 23L, 23L, 6L, 9L, 1L, 61L, 21L, 1L, 23L, 61L, 
    21L, 29L, 23L, 36L, 8L, 23L, 17L, 8L, 23L, 5L, 5L, 43L, 17L, 
    9L, 23L, 5L, 23L, 23L, 59L, 23L, 6L, 8L, 23L, 23L, 45L, 43L, 
    17L, 23L, 23L, 16L, 23L, 19L, 19L, 61L, 23L, 61L, 23L, 17L, 
    66L, 39L, 23L, 50L, 23L, 23L, 17L, 51L, 5L, 17L, 11L, 33L, 
    23L, 43L, 23L, 17L, 23L, 23L, 21L, 23L, 17L, 23L, 45L, 49L, 
    7L, 7L, 23L, 28L, 8L, 19L, 5L, 5L, 23L, 17L, 23L, 5L, 51L, 
    17L, 9L, 23L, 50L, 23L, 22L, 23L, 51L, 45L, 21L, 23L, 44L, 
    5L, 1L, 5L, 43L, 23L, 23L, 57L, 23L, 1L, 51L, 23L, 16L, 5L, 
    17L, 5L, 23L, 17L, 23L, 17L, 61L, 6L, 51L, 8L, 23L, 7L, 43L, 
    6L, 23L, 22L, 50L, 1L, 23L, 43L, 2L, 61L, 17L, 61L, 61L, 
    23L, 28L, 17L, 39L, 51L, 5L, 21L, 23L, 59L, 23L, 19L, 19L, 
    5L, 1L, 1L, 9L, 19L, 9L, 28L, 19L, 17L, 17L, 8L, 8L, 61L, 
    63L, 17L, 23L, 7L, 43L, 1L, 43L, 22L, 21L, 23L, 17L, 17L, 
    17L, 63L, 28L, 61L, 51L, 23L, 17L, 23L, 5L, 23L, 59L, 23L, 
    23L, 23L, 8L, 23L, 22L, 23L, 1L, 17L, 23L, 23L, 50L, 23L, 
    5L, 17L, 8L, 51L, 17L, 61L, 22L, 32L, 17L, 7L, 9L, 23L, 63L, 
    2L, 23L, 5L, 23L, 52L, 35L, 17L, 5L, 5L, 35L, 1L, 8L, 49L, 
    7L, 8L, 23L, 23L, 23L, 57L, 1L, 43L, 23L, 29L, 51L, 23L, 
    23L, 61L, 9L, 23L, 29L, 5L, 51L, 23L, 23L, 17L, 59L, 23L, 
    61L, 61L, 61L, 23L, 23L, 61L, 61L, 17L, 23L, 17L, 17L, 8L, 
    17L, 23L, 61L, 1L, 19L, 8L, 35L, 23L, 1L, 23L, 9L, 28L, 9L, 
    17L, 8L, 23L, 23L, 19L, 7L, 23L, 17L, 17L, 59L, 8L, 57L, 
    23L, 21L, 23L, 5L, 36L, 23L, 23L, 66L, 50L, 8L, 42L, 5L, 
    23L, 5L, 45L, 5L, 17L, 51L, 17L, 17L, 5L, 43L, 23L, 23L, 
    51L, 23L, 17L, 9L, 17L, 23L, 23L, 23L, 17L, 51L, 23L, 23L, 
    1L, 17L, 51L, 23L, 19L, 1L, 23L, 17L, 8L, 37L, 23L, 17L, 
    8L, 21L, 19L, 17L, 8L, 57L, 23L, 66L, 1L, 23L, 19L, 21L, 
    9L, 5L, 50L, 22L, 28L, 17L, 23L, 23L, 17L, 8L, 51L, 19L, 
    53L, 61L, 19L, 7L, 23L, 14L, 23L, 61L, 8L, 17L, 23L, 17L, 
    23L, 5L, 17L, 51L, 17L, 23L, 59L, 23L, 23L, 17L, 36L, 23L, 
    23L, 61L, 8L, 23L, 28L, 8L, 23L, 8L, 43L, 23L, 23L, 8L, 43L, 
    8L, 8L, 50L, 23L, 59L, 43L, 12L, 17L, 16L, 23L, 12L, 8L, 
    17L, 23L, 23L, 1L, 22L, 23L, 23L, 1L, 50L, 5L, 17L, 23L, 
    5L, 59L, 19L, 61L, 1L, 52L, 61L, 17L, 35L, 29L, 17L, 23L, 
    17L, 17L, 17L, 17L, 28L, 5L, 8L, 5L, 5L, 1L, 5L, 17L, 61L, 
    23L, 7L, 2L, 16L, 23L, 5L, 7L, 59L, 19L, 23L, 1L, 23L, 23L, 
    5L, 17L, 23L, 43L, 23L, 5L, 23L, 28L, 61L, 17L, 61L, 51L, 
    19L, 5L, 5L, 63L, 60L, 5L, 61L, 23L, 23L, 21L, 66L, 45L, 
    23L, 5L, 23L, 23L, 51L, 16L, 17L, 23L, 23L, 61L, 23L, 17L, 
    23L, 23L, 27L, 5L, 5L, 5L, 19L, 61L, 17L, 19L, 19L, 17L, 
    1L, 19L, 23L, 21L, 23L, 5L, 23L, 17L, 17L, 23L, 17L, 66L, 
    23L, 23L, 21L, 1L, 8L, 24L, 22L, 5L, 23L, 43L, 23L, 10L, 
    5L, 16L, 28L, 23L, 23L, 23L, 17L, 1L, 5L, 1L, 17L, 51L, 5L, 
    51L, 23L, 1L, 17L, 21L, 23L, 57L, 5L, 23L, 5L, 9L, 28L, 22L, 
    5L, 17L, 8L, 51L, 19L, 61L, 23L, 53L, 23L, 43L, 23L, 17L, 
    61L, 57L, 29L, 51L, 23L, 23L, 23L, 8L, 8L, 19L, 17L, 36L, 
    23L, 22L, 5L, 51L, 61L, 8L, 23L, 6L, 43L, 17L, 17L, 49L, 
    23L, 23L, 23L, 23L, 23L, 7L, 17L, 51L, 23L, 23L, 23L, 5L, 
    9L, 23L, 28L, 61L, 5L, 52L, 17L, 17L, 8L, 23L, 23L, 23L, 
    5L, 1L, 66L, 9L, 17L, 21L, 5L, 17L, 36L, 23L, 17L, 23L, 23L, 
    17L, 23L, 23L, 61L, 57L, 61L, 23L, 23L, 9L, 23L, 21L, 19L, 
    17L, 29L, 8L, 23L, 23L, 17L, 7L, 51L, 51L, 23L, 43L, 5L, 
    23L, 23L, 23L, 23L, 62L, 8L, 19L, 23L, 42L, 23L, 8L, 1L, 
    17L, 22L, 36L, 23L, 1L, 17L, 1L, 5L, 8L, 5L, 23L, 66L, 5L, 
    23L, 5L, 17L, 23L, 23L, 23L, 23L, 8L, 19L, 51L, 12L, 23L, 
    61L, 17L, 1L, 23L, 23L, 23L, 50L, 61L, 17L, 23L, 51L, 59L, 
    63L, 23L, 17L, 8L, 6L, 23L, 23L, 17L, 8L, 19L, 23L, 23L, 
    30L, 23L, 22L, 23L, 8L, 17L, 57L, 5L, 19L, 21L, 22L, 51L, 
    17L, 5L, 17L, 23L, 23L, 5L, 36L, 23L, 9L, 23L, 17L, 23L, 
    55L, 23L, 63L, 23L, 19L, 43L, 17L, 5L, 6L, 21L, 43L, 5L, 
    51L, 23L, 43L, 17L, 61L, 5L, 17L, 16L, 43L, 17L, 17L, 23L, 
    51L, 8L, 23L, 5L, 43L, 5L, 19L, 28L, 43L, 23L, 5L, 56L, 32L, 
    19L, 51L, 4L, 17L, 22L, 23L, 8L, 9L, 1L, 7L, 8L, 23L, 17L, 
    17L, 5L, 5L, 43L, 5L, 23L, 23L, 23L, 1L, 52L, 23L, 43L, 19L, 
    17L, 17L, 45L, 1L, 26L, 48L, 63L, 23L, 19L, 23L, 5L, 28L, 
    23L, 23L, 8L, 23L, 35L, 51L, 61L, 63L, 23L, 17L, 23L, 23L, 
    1L, 5L, 23L, 23L, 22L, 43L, 6L, 23L, 23L, 17L, 19L, 1L, 34L, 
    23L, 23L, 23L, 19L, 9L, 32L, 17L, 57L, 23L, 17L, 17L, 23L, 
    17L, 5L, 23L, 51L, 35L, 9L, 22L, 23L, 17L, 17L, 23L, 23L, 
    17L, 50L, 19L, 23L, 5L, 8L, 44L, 1L, 23L, 23L, 1L, 10L, 17L, 
    8L, 23L, 23L, 17L, 17L, 2L, 23L, 16L, 8L, 5L, 61L, 23L, 9L, 
    17L, 19L, 22L, 23L, 61L, 17L, 23L, 29L, 21L, 23L, 17L, 23L, 
    23L, 23L, 23L, 17L, 51L, 19L, 23L, 8L, 28L, 8L, 17L, 23L, 
    23L, 7L, 51L, 8L, 61L, 17L, 23L, 23L, 23L, 5L, 61L, 17L, 
    23L, 17L, 23L, 5L, 8L, 19L, 17L, 23L, 1L, 23L, 17L, 22L, 
    23L, 43L, 23L, 43L, 1L, 22L, 59L, 8L, 6L, 19L, 1L, 17L, 9L, 
    17L, 8L, 23L, 8L, 19L, 7L, 5L, 61L, 5L, 43L, 1L, 29L, 57L, 
    23L, 23L, 28L, 8L, 61L, 8L, 23L, 16L, 21L, 8L, 23L, 5L, 19L, 
    66L, 17L, 17L, 23L, 61L, 21L, 61L, 23L, 23L, 17L, 8L, 17L, 
    28L, 7L, 23L, 51L, 8L, 43L, 23L, 23L, 5L, 28L, 23L, 61L, 
    17L, 17L, 23L, 1L, 7L, 17L, 17L, 23L, 5L, 17L, 17L, 17L, 
    17L, 17L, 21L, 19L, 17L, 23L, 51L, 42L, 1L, 63L, 22L, 17L, 
    23L, 23L, 23L, 21L, 23L, 57L, 17L, 19L, 9L, 23L, 61L, 17L, 
    23L, 64L, 23L, 22L, 17L, 66L, 9L, 19L, 23L, 61L, 17L, 23L, 
    51L, 29L, 22L, 51L, 23L, 23L, 9L, 22L, 23L, 5L, 22L, 22L, 
    34L, 23L, 63L, 23L, 7L, 5L, 21L, 23L, 43L, 19L, 6L, 1L, 8L, 
    1L, 32L, 22L, 5L, 35L, 23L, 19L, 17L, 17L, 59L, 52L, 17L, 
    61L, 23L, 17L, 23L, 23L, 26L, 59L, 23L, 8L, 61L, 66L, 5L, 
    23L, 23L, 5L, 23L, 66L, 17L, 61L, 22L, 23L, 23L, 23L, 28L, 
    16L, 61L, 8L, 19L, 23L, 23L, 36L, 51L, 44L, 17L, 23L, 61L, 
    61L, 8L, 17L, 29L, 23L, 21L, 23L, 5L, 63L, 23L, 23L, 28L, 
    7L, 17L, 17L, 17L, 28L, 17L, 5L, 23L, 19L, 51L, 23L, 63L, 
    28L, 21L, 23L, 45L, 1L, 1L, 1L, 5L, 5L, 17L, 23L, 1L, 23L, 
    22L, 23L, 17L, 17L, 23L, 23L, 51L, 5L, 11L, 61L, 5L, 17L, 
    23L, 61L, 8L, 23L, 5L, 35L, 35L, 19L, 7L, 23L, 23L, 5L, 21L, 
    21L, 23L, 61L, 23L, 17L, 28L, 9L, 61L, 1L, 9L, 5L, 23L, 36L, 
    35L, 60L, 23L, 23L, 23L, 10L, 23L, 23L, 23L, 23L, 5L, 5L, 
    23L, 8L, 8L, 36L, 17L, 5L, 5L, 23L, 17L, 61L, 1L, 17L, 19L, 
    17L, 17L, 22L, 23L, 7L, 23L, 43L, 23L, 17L, 61L, 23L, 61L, 
    23L, 36L, 5L, 17L, 23L, 59L, 5L, 1L, 34L, 18L, 8L, 9L, 17L, 
    8L, 23L, 8L, 17L, 23L, 17L, 28L, 51L, 17L, 17L, 43L, 51L, 
    23L, 5L, 23L, 49L, 8L, 28L, 51L, 63L, 23L, 3L, 9L, 28L, 17L, 
    9L, 16L, 6L, 23L, 17L, 17L, 23L, 17L, 17L, 51L, 17L, 51L, 
    5L, 22L, 43L, 8L, 1L, 51L, 23L, 22L, 23L, 43L, 8L, 43L, 23L, 
    23L, 23L, 23L, 1L, 23L, 5L, 17L, 23L, 8L, 23L, 23L, 17L, 
    59L, 21L, 51L, 61L, 17L, 5L, 23L, 19L, 19L, 1L, 23L, 16L, 
    38L, 17L, 17L, 23L, 21L, 1L, 43L, 29L, 1L, 5L, 23L, 23L, 
    43L, 5L, 23L, 23L, 23L, 5L, 23L, 22L, 23L, 1L, 23L, 8L, 5L, 
    1L, 21L, 17L, 23L, 8L, 21L, 43L, 17L, 16L, 17L, 5L, 2L, 17L, 
    17L, 23L, 23L, 23L, 9L, 21L, 8L, 23L, 23L, 17L, 1L, 9L, 17L, 
    1L, 23L, 21L, 17L, 9L, 17L, 8L, 23L, 8L, 36L, 8L, 23L, 23L, 
    23L, 51L, 5L, 51L, 63L, 19L, 21L, 23L, 5L, 43L, 28L, 8L, 
    21L, 17L, 62L, 23L, 23L, 8L, 23L, 23L, 23L, 23L, 61L, 45L, 
    23L, 23L, 1L, 19L, 23L, 17L, 23L, 22L, 5L, 66L, 7L, 23L, 
    29L, 8L, 28L, 5L, 51L, 60L, 9L, 51L, 17L, 17L, 46L, 32L, 
    43L, 57L, 17L, 9L, 23L, 23L, 5L, 17L, 17L, 17L, 23L, 23L, 
    5L, 23L, 23L, 17L, 43L, 17L, 21L, 23L, 19L, 19L, 23L, 28L, 
    17L, 8L, 22L, 50L, 5L, 51L, 17L, 23L, 1L, 66L, 61L, 17L, 
    23L, 9L, 23L, 51L, 30L, 17L, 17L, 22L, 5L, 23L, 61L, 23L, 
    17L, 8L, 17L, 2L, 5L, 63L, 23L, 23L, 50L, 29L, 23L, 17L, 
    8L, 57L, 23L, 19L, 1L, 23L, 17L, 35L, 23L, 17L, 23L, 23L, 
    23L, 23L, 17L, 1L, 21L, 23L, 19L, 23L, 17L, 51L, 61L, 17L, 
    5L, 17L, 23L, 23L, 28L, 5L, 51L, 28L, 5L, 59L, 35L, 23L, 
    51L, 22L, 23L, 1L, 22L, 17L, 35L, 40L, 8L, 8L, 11L, 23L, 
    11L, 59L, 17L, 51L, 65L, 23L, 8L, 17L, 19L, 23L, 19L, 22L, 
    22L, 51L, 23L, 61L, 51L, 23L, 61L, 44L, 17L, 36L, 61L, 5L, 
    51L, 9L, 23L, 52L, 23L, 8L, 23L, 17L, 23L, 23L, 19L, 23L, 
    1L, 51L, 5L, 28L, 17L, 23L, 23L, 17L, 60L, 23L, 23L, 5L, 
    1L, 8L, 23L, 17L, 2L, 17L, 23L, 51L, 17L, 17L, 22L, 23L, 
    1L, 61L, 32L, 23L, 61L, 23L, 52L, 17L, 17L, 8L, 23L, 8L, 
    23L, 17L, 38L, 32L, 8L, 17L, 6L, 23L, 5L, 23L, 21L, 21L, 
    29L, 23L, 17L, 17L, 17L, 22L, 7L, 23L, 23L, 23L, 61L, 23L, 
    23L, 17L, 57L, 23L, 1L, 35L, 17L, 5L, 5L, 1L, 51L, 17L, 6L, 
    61L, 23L, 51L, 17L, 7L, 1L, 43L, 38L, 51L, 22L, 1L, 22L, 
    50L, 23L, 17L, 17L, 36L, 21L, 8L, 23L, 8L, 17L, 17L, 51L, 
    21L, 17L, 17L, 19L, 17L, 17L, 23L, 23L, 35L, 51L, 17L, 22L, 
    23L, 51L, 17L, 2L, 5L, 23L, 17L, 51L, 23L, 51L, 61L, 5L, 
    52L, 23L, 17L, 63L, 5L, 28L, 62L, 5L, 17L, 1L, 23L, 23L, 
    19L, 23L, 23L, 17L, 17L, 17L, 9L, 17L, 22L, 5L, 38L, 17L, 
    21L, 45L, 23L, 23L, 21L, 17L, 17L, 17L, 17L, 19L, 5L, 45L, 
    23L, 17L, 36L, 43L, 61L, 23L, 61L, 1L, 63L, 1L, 23L, 9L, 
    23L, 51L, 1L, 22L, 29L, 23L, 9L, 5L, 8L, 23L, 51L, 17L, 45L, 
    17L, 23L, 17L, 23L, 17L, 5L, 17L, 61L, 5L, 9L, 23L, 5L, 17L, 
    23L, 23L, 23L, 5L), .Label = c(".COM", "A", "aaa", "ab", 
    "abc", "ACT", "aoap", "api", "API", "app", "APP", "AUTH", 
    "B", "bbb", "BROWSER", "BULK", "C", "Canvas", "CCC", "cccc", 
    "cert", "Change Sets", "CODE", "Community", "COMMUNITY", 
    "CONNECT", "DATABASE", "DEPLOYMENT", "DESIGN", "DEV", "Development", 
    "DOMAIN", "Email", "hello", "hmm", "IDE", "ISP", "LLM", "LOG", 
    "maintain", "manager", "message", "NEW", "NEW1", "new11", 
    "new11111", "New2", "new3", "no", "Oauth", "on", "open", 
    "Other", "post", "quick", "REST", "SAML", "secure", "Site.com", 
    "SLOWNES", "soo", "SOSL", "sql", "sso", "TOKEN", "YES"), class = "factor"), 
    score = c(9L, 10L, 2L, 10L, 10L, 2L, 8L, 10L, 10L, 10L, 10L, 
    10L, 10L, 2L, 10L, 4L, 4L, 10L, 9L, 10L, 10L, 10L, 10L, 5L, 
    9L, 10L, 8L, 10L, 10L, 10L, 10L, 10L, 10L, 1L, 9L, 8L, 10L, 
    10L, 10L, 10L, 9L, 10L, 10L, 10L, 9L, 10L, 8L, 8L, 10L, 9L, 
    8L, 7L, 8L, 9L, 10L, 10L, 8L, 10L, 10L, 10L, 8L, 10L, 10L, 
    8L, 8L, 10L, 10L, 10L, 10L, 10L, 10L, 8L, 5L, 8L, 9L, 10L, 
    10L, 10L, 10L, 8L, 10L, 9L, 7L, 8L, 10L, 10L, 10L, 6L, 9L, 
    10L, 10L, 10L, 9L, 9L, 10L, 10L, 10L, 6L, 8L, 10L, 10L, 9L, 
    6L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 8L, 1L, 10L, 9L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 7L, 
    10L, 0L, 10L, 10L, 6L, 0L, 8L, 10L, 10L, 10L, 10L, 1L, 8L, 
    1L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 6L, 10L, 9L, 10L, 9L, 4L, 8L, 10L, 10L, 
    10L, 10L, 10L, 0L, 9L, 8L, 10L, 10L, 10L, 9L, 10L, 10L, 8L, 
    9L, 10L, 10L, 10L, 6L, 9L, 8L, 10L, 10L, 10L, 10L, 10L, 10L, 
    9L, 6L, 9L, 10L, 10L, 9L, 7L, 8L, 10L, 10L, 10L, 10L, 10L, 
    8L, 0L, 10L, 8L, 9L, 10L, 10L, 10L, 10L, 10L, 8L, 9L, 9L, 
    10L, 9L, 9L, 8L, 10L, 10L, 9L, 10L, 10L, 7L, 10L, 10L, 10L, 
    9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 6L, 10L, 10L, 10L, 10L, 10L, 1L, 9L, 7L, 10L, 
    2L, 9L, 9L, 6L, 8L, 8L, 10L, 10L, 10L, 10L, 9L, 9L, 10L, 
    10L, 8L, 8L, 10L, 10L, 8L, 8L, 10L, 4L, 10L, 8L, 10L, 9L, 
    9L, 10L, 10L, 7L, 10L, 4L, 10L, 8L, 10L, 10L, 9L, 9L, 6L, 
    10L, 10L, 10L, 10L, 10L, 10L, 9L, 10L, 8L, 10L, 10L, 10L, 
    8L, 10L, 10L, 10L, 10L, 8L, 10L, 10L, 10L, 10L, 9L, 6L, 10L, 
    9L, 10L, 10L, 10L, 8L, 10L, 10L, 10L, 10L, 10L, 3L, 10L, 
    10L, 10L, 10L, 2L, 10L, 10L, 0L, 10L, 0L, 10L, 10L, 10L, 
    10L, 10L, 10L, 9L, 10L, 10L, 9L, 10L, 10L, 10L, 8L, 9L, 10L, 
    9L, 0L, 10L, 10L, 8L, 10L, 7L, 10L, 10L, 10L, 10L, 10L, 10L, 
    8L, 9L, 9L, 10L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 9L, 10L, 6L, 7L, 10L, 10L, 10L, 10L, 
    10L, 10L, 8L, 10L, 8L, 10L, 10L, 10L, 8L, 10L, 10L, 10L, 
    10L, 10L, 10L, 8L, 9L, 10L, 10L, 1L, 10L, 9L, 10L, 10L, 10L, 
    9L, 10L, 10L, 6L, 9L, 9L, 8L, 10L, 10L, 10L, 9L, 10L, 10L, 
    10L, 10L, 0L, 0L, 10L, 8L, 8L, 10L, 10L, 8L, 9L, 9L, 10L, 
    10L, 10L, 10L, 10L, 2L, 8L, 10L, 8L, 10L, 8L, 10L, 8L, 10L, 
    10L, 8L, 8L, 0L, 8L, 8L, 10L, 10L, 10L, 8L, 1L, 8L, 10L, 
    2L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 4L, 8L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 3L, 10L, 10L, 10L, 10L, 8L, 
    10L, 10L, 10L, 7L, 9L, 9L, 10L, 10L, 8L, 10L, 9L, 10L, 10L, 
    10L, 10L, 10L, 10L, 9L, 10L, 10L, 10L, 10L, 8L, 10L, 10L, 
    10L, 8L, 10L, 10L, 10L, 10L, 10L, 10L, 9L, 10L, 10L, 0L, 
    6L, 9L, 10L, 9L, 7L, 8L, 10L, 10L, 7L, 9L, 10L, 10L, 10L, 
    10L, 0L, 10L, 10L, 10L, 7L, 10L, 10L, 8L, 10L, 10L, 10L, 
    9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 9L, 10L, 
    9L, 10L, 8L, 10L, 9L, 10L, 10L, 10L, 9L, 8L, 10L, 10L, 10L, 
    6L, 10L, 10L, 9L, 10L, 8L, 10L, 0L, 10L, 8L, 9L, 9L, 9L, 
    10L, 10L, 10L, 10L, 10L, 8L, 2L, 10L, 10L, 8L, 10L, 9L, 10L, 
    9L, 10L, 0L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 5L, 
    10L, 10L, 10L, 8L, 7L, 10L, 10L, 9L, 7L, 10L, 5L, 8L, 9L, 
    10L, 10L, 8L, 10L, 10L, 9L, 10L, 10L, 10L, 9L, 10L, 10L, 
    10L, 10L, 10L, 1L, 7L, 10L, 7L, 10L, 0L, 9L, 7L, 10L, 10L, 
    10L, 10L, 10L, 10L, 9L, 10L, 10L, 8L, 10L, 8L, 10L, 8L, 10L, 
    9L, 9L, 8L, 9L, 10L, 9L, 10L, 10L, 2L, 10L, 10L, 10L, 10L, 
    10L, 0L, 10L, 8L, 10L, 10L, 9L, 10L, 10L, 10L, 9L, 8L, 8L, 
    9L, 9L, 7L, 7L, 5L, 9L, 10L, 10L, 10L, 10L, 9L, 10L, 10L, 
    9L, 5L, 10L, 8L, 10L, 10L, 8L, 10L, 10L, 10L, 10L, 10L, 8L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 7L, 10L, 10L, 6L, 6L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 9L, 10L, 10L, 9L, 10L, 
    8L, 10L, 10L, 10L, 9L, 10L, 8L, 10L, 9L, 9L, 10L, 9L, 9L, 
    10L, 10L, 10L, 10L, 10L, 6L, 8L, 10L, 10L, 9L, 10L, 10L, 
    10L, 10L, 10L, 10L, 8L, 10L, 10L, 9L, 10L, 2L, 10L, 9L, 9L, 
    10L, 10L, 10L, 9L, 10L, 10L, 10L, 9L, 10L, 10L, 10L, 10L, 
    10L, 8L, 10L, 10L, 8L, 7L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 9L, 10L, 10L, 9L, 8L, 8L, 9L, 10L, 0L, 0L, 2L, 9L, 10L, 
    10L, 8L, 10L, 6L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    5L, 10L, 8L, 10L, 10L, 9L, 0L, 10L, 10L, 10L, 9L, 1L, 9L, 
    10L, 8L, 2L, 10L, 10L, 8L, 10L, 10L, 10L, 10L, 10L, 9L, 9L, 
    2L, 10L, 8L, 8L, 10L, 10L, 3L, 10L, 10L, 10L, 9L, 10L, 10L, 
    8L, 10L, 7L, 10L, 10L, 10L, 10L, 10L, 10L, 6L, 0L, 4L, 9L, 
    8L, 10L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 9L, 
    10L, 10L, 10L, 10L, 10L, 9L, 9L, 7L, 8L, 10L, 8L, 10L, 8L, 
    10L, 8L, 7L, 10L, 10L, 8L, 9L, 10L, 10L, 9L, 10L, 9L, 10L, 
    10L, 10L, 9L, 10L, 9L, 9L, 10L, 10L, 8L, 9L, 10L, 10L, 0L, 
    10L, 10L, 10L, 9L, 10L, 10L, 9L, 10L, 10L, 10L, 6L, 10L, 
    10L, 10L, 10L, 10L, 9L, 4L, 9L, 10L, 1L, 9L, 9L, 10L, 7L, 
    9L, 10L, 10L, 10L, 10L, 9L, 10L, 9L, 10L, 2L, 10L, 9L, 7L, 
    9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 1L, 10L, 9L, 
    10L, 10L, 3L, 9L, 10L, 10L, 8L, 10L, 10L, 4L, 10L, 8L, 10L, 
    10L, 10L, 9L, 8L, 10L, 10L, 9L, 10L, 7L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 6L, 10L, 
    9L, 9L, 8L, 5L, 10L, 10L, 7L, 9L, 10L, 10L, 0L, 10L, 10L, 
    10L, 10L, 10L, 10L, 8L, 10L, 10L, 10L, 9L, 10L, 10L, 10L, 
    9L, 10L, 10L, 7L, 8L, 10L, 10L, 10L, 10L, 10L, 9L, 10L, 10L, 
    10L, 10L, 10L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 0L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 9L, 10L, 10L, 10L, 9L, 3L, 10L, 9L, 10L, 10L, 6L, 8L, 
    7L, 10L, 10L, 10L, 10L, 10L, 10L, 8L, 10L, 10L, 10L, 10L, 
    10L, 8L, 10L, 10L, 10L, 10L, 10L, 2L, 7L, 10L, 10L, 10L, 
    9L, 2L, 9L, 0L, 10L, 10L, 10L, 10L, 9L, 10L, 8L, 10L, 9L, 
    10L, 10L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 8L, 
    10L, 9L, 9L, 10L, 10L, 8L, 10L, 10L, 5L, 10L, 9L, 10L, 9L, 
    10L, 9L, 10L, 8L, 9L, 10L, 10L, 3L, 9L, 10L, 7L, 10L, 9L, 
    10L, 10L, 10L, 8L, 10L, 10L, 5L, 10L, 8L, 10L, 9L, 10L, 10L, 
    10L, 10L, 9L, 9L, 10L, 10L, 10L, 10L, 8L, 10L, 9L, 9L, 10L, 
    10L, 10L, 10L, 10L, 9L, 9L, 10L, 9L, 9L, 10L, 5L, 10L, 9L, 
    10L, 6L, 10L, 10L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 3L, 9L, 
    9L, 10L, 9L, 10L, 0L, 10L, 10L, 10L, 10L, 9L, 10L, 7L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 8L, 10L, 10L, 10L, 10L, 9L, 
    10L, 10L, 10L, 10L, 8L, 10L, 10L, 9L, 10L, 8L, 9L, 10L, 9L, 
    10L, 0L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 7L, 8L, 10L, 
    10L, 7L, 8L, 10L, 10L, 9L, 10L, 10L, 5L, 10L, 10L, 10L, 10L, 
    10L, 10L, 6L, 10L, 10L, 10L, 10L, 10L, 8L, 7L, 10L, 9L, 10L, 
    10L, 9L, 10L, 10L, 10L, 10L, 9L, 10L, 6L, 9L, 10L, 10L, 10L, 
    10L, 7L, 10L, 10L, 10L, 10L, 7L, 10L, 6L, 8L, 10L, 10L, 10L, 
    10L, 10L, 9L, 9L, 10L, 10L, 9L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 0L, 0L, 10L, 10L, 8L, 10L, 10L, 10L, 9L, 10L, 10L, 
    10L, 10L, 10L, 0L, 10L, 10L, 9L, 9L, 5L, 8L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 8L, 10L, 10L, 10L, 10L, 10L, 10L, 9L, 
    10L, 10L, 10L, 10L, 0L, 10L, 10L, 6L, 8L, 10L, 10L, 10L, 
    8L, 10L, 10L, 8L, 10L, 8L, 10L, 0L, 8L, 10L, 10L, 10L, 10L, 
    10L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 9L, 0L, 8L, 
    10L, 10L, 9L, 6L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 8L, 5L, 10L, 10L, 10L, 10L, 3L, 10L, 9L, 10L, 10L, 10L, 
    10L, 8L, 9L, 10L, 10L, 10L, 10L, 6L, 10L, 9L, 10L, 7L, 10L, 
    10L, 9L, 8L, 8L, 0L, 10L, 8L, 9L, 10L, 10L, 9L, 5L, 8L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 8L, 2L, 10L, 8L, 10L, 
    9L, 10L, 10L, 10L, 10L, 6L, 10L, 10L, 10L, 10L, 9L, 10L, 
    8L, 10L, 10L, 10L, 8L, 10L, 0L, 10L, 9L, 9L, 10L, 10L, 10L, 
    10L, 10L, 9L, 10L, 10L, 7L, 6L, 10L, 5L, 10L, 8L, 10L, 10L, 
    10L, 10L, 10L, 10L, 3L, 9L, 10L, 10L, 10L, 3L, 2L, 10L, 9L, 
    0L, 10L, 6L, 0L, 10L, 10L, 10L, 10L, 9L, 10L, 10L, 10L, 10L, 
    6L, 10L, 7L, 0L, 3L, 10L, 10L, 6L, 9L, 8L, 10L, 9L, 8L, 10L, 
    7L, 10L, 10L, 10L, 10L, 9L, 10L, 8L, 8L, 9L, 10L, 9L, 5L, 
    9L, 9L, 10L, 10L, 10L, 0L, 10L, 9L, 10L, 10L, 10L, 9L, 8L, 
    10L, 10L, 10L, 10L, 10L, 10L, 8L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 9L, 10L, 9L, 10L, 9L, 10L, 10L, 9L, 10L, 8L, 
    10L, 9L, 10L, 10L, 10L, 10L, 9L, 10L, 10L, 10L, 9L, 10L, 
    9L, 10L, 9L, 9L, 10L, 10L, 10L, 8L, 8L, 10L, 10L, 10L, 10L, 
    9L, 10L, 10L, 10L, 3L, 10L, 10L, 10L, 10L, 10L, 9L, 10L, 
    10L, 10L, 10L, 6L, 7L, 10L, 10L, 8L, 10L, 10L, 10L, 10L, 
    10L, 10L, 5L, 6L, 3L, 10L, 2L, 5L, 9L, 9L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 2L, 10L, 10L, 10L, 
    10L, 10L, 9L, 8L, 10L, 10L, 10L, 10L, 10L, 10L, 8L, 6L, 10L, 
    10L, 9L, 10L, 10L, 10L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 7L, 10L, 10L, 8L, 10L, 8L, 10L, 10L, 10L, 
    9L, 10L, 10L, 10L, 9L, 10L, 9L, 10L, 0L, 8L, 10L, 10L, 6L, 
    8L, 10L, 10L, 8L, 8L, 8L, 8L, 10L, 10L, 10L, 10L, 9L, 2L, 
    10L, 10L, 10L, 9L, 10L, 8L, 10L, 10L, 10L, 10L, 10L, 9L, 
    10L, 10L, 10L, 10L, 5L, 10L, 10L, 10L, 10L, 9L, 10L, 10L, 
    10L, 9L, 8L, 9L, 8L, 10L, 9L, 10L, 8L, 10L, 10L, 9L, 10L, 
    9L, 8L, 10L, 9L, 7L, 10L, 10L, 7L, 10L, 10L, 9L, 8L, 8L, 
    8L, 8L, 2L, 8L, 10L, 10L, 10L, 10L, 9L, 9L, 10L, 10L, 8L, 
    8L, 8L, 10L, 8L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 6L, 
    10L, 10L, 10L, 8L, 10L, 10L, 8L, 10L, 10L, 10L, 8L, 10L, 
    10L, 10L, 10L, 10L, 0L, 9L, 9L, 8L, 10L, 7L, 10L, 10L, 10L, 
    10L, 8L, 10L, 10L, 8L, 10L, 8L, 10L, 10L, 10L, 9L, 10L, 9L, 
    10L, 10L, 10L, 10L, 7L, 8L, 10L, 10L, 10L, 10L, 4L, 10L, 
    10L, 10L, 6L, 7L, 10L, 10L, 10L, 8L, 10L, 10L, 10L, 0L, 9L, 
    10L, 9L, 6L, 10L, 8L, 10L, 10L, 10L, 0L, 10L, 10L, 9L, 10L, 
    8L, 10L, 8L, 9L, 10L, 10L, 10L, 10L, 9L, 10L, 10L, 9L, 10L, 
    10L, 10L, 10L, 10L, 8L, 10L, 10L, 10L, 10L, 9L, 9L, 10L, 
    10L, 6L, 10L, 6L, 10L, 10L, 10L, 10L, 9L, 4L, 9L, 9L, 9L, 
    10L, 10L, 0L, 10L, 10L, 10L, 9L, 10L, 10L, 10L, 10L, 9L, 
    10L, 10L, 9L, 9L, 9L, 10L, 10L, 0L, 10L, 10L, 9L, 3L, 8L, 
    10L, 9L, 10L, 9L, 3L, 8L, 10L, 10L, 10L, 10L, 10L, 9L, 10L, 
    8L, 4L, 8L, 10L, 10L, 10L, 10L, 10L, 0L, 4L), rep_score = c(9.5, 
    10, 2, 10, 10, 3.5, 7.5, 10, 10, 10, 10, 10, 10, 2, 10, 7.5, 
    6, 10, 9.5, 10, 9, 10, 10, 5.5, 9, 10, 8, 10, 10, 10, 10, 
    10, 9.5, 1.5, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 9.5, 
    10, 10, 8, 10, 10, 9.5, 6, 9, 9, 10, 10, 7.5, 10, 10, 10, 
    7.5, 10, 10, 8, 9, 10, 10, 10, 10, 10, 10, 7.5, 7.5, 7.5, 
    9, 10, 10, 10, 10, 7.5, 10, 9, 7.5, 8, 10, 10, 10, 7.5, 9.5, 
    10, 9.5, 10, 10, 8.5, 10, 9, 9.5, 9.5, 8, 10, 10, 9, 9, 10, 
    10, 9, 10, 10, 10, 10, 9.5, 2, 10, 9, 10, 10, 10, 10, 10, 
    10, 10, 10, 10, 10, 10, 10, 8, 10, 9.3, 10, 10, 7.5, 9.3, 
    8, 9, 10, 10, 9.5, 6.5, 7.5, 6, 10, 10, 10, 10, 10, 10, 10, 
    10, 10, 10, 10, 10, 10, 10, 10, 6, 7, 8.5, 9.5, 9.5, 5, 7.5, 
    10, 10, 10, 8, 10, 6, 8, 6.5, 10, 10, 10, 9, 10, 10, 8, 8.5, 
    10, 10, 10, 7.5, 9, 8, 10, 10, 10, 10, 10, 10, 9, 7, 10, 
    10, 10, 9, 7.5, 9.5, 10, 9, 10, 10, 10, 8, 9.3, 10, 9, 10, 
    10, 10, 9.5, 10, 10, 8, 9, 9, 10, 10, 10, 8, 10, 10, 9.5, 
    10, 9, 7.5, 10, 10, 10, 8.5, 10, 9.5, 10, 10, 10, 10, 10, 
    10, 9, 10, 10, 10, 10, 10, 5, 10, 10, 10, 10, 10, 4, 9, 7, 
    10, 4, 8.5, 8.5, 6.5, 7.5, 8.5, 10, 10, 10, 10, 8.5, 8, 9, 
    10, 9, 8, 10, 10, 8, 10, 10, 8.5, 10, 8, 10, 9, 9.5, 10, 
    9, 7.5, 10, 4.5, 9.5, 8, 10, 10, 9.5, 8.5, 8, 10, 10, 10, 
    10, 10, 10, 9, 10, 9, 10, 9.5, 8, 8, 10, 10, 9.5, 10, 8.5, 
    10, 9, 10, 10, 7.5, 7, 10, 9.5, 10, 10, 10, 7, 9.5, 10, 10, 
    10, 10, 4, 10, 10, 10, 10, 7, 10, 10, 10, 10, 9.3, 10, 10, 
    10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 7.5, 10, 10, 9, 
    6, 10, 10, 9.5, 10, 8.5, 10, 10, 10, 10, 10, 10, 10, 9.5, 
    9.5, 10, 9, 10, 9.5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 
    9.5, 9, 10, 6, 9, 10, 10, 9.5, 10, 10, 10, 9.5, 10, 8, 10, 
    10, 10, 8.5, 10, 9.5, 10, 10, 10, 10, 8, 10, 10, 10, 4.5, 
    10, 10, 10, 10, 10, 9, 9, 10, 6, 10, 9.5, 8, 10, 10, 10, 
    9, 10, 10, 10, 9.5, 7, 9.3, 10, 10, 8.5, 10, 10, 8, 10, 9.5, 
    10, 10, 10, 10, 9.5, 5.5, 8, 10, 7.5, 10, 7.5, 10, 8, 10, 
    10, 8, 8.5, 9.3, 8, 8, 10, 10, 10, 9.5, 1.5, 8, 10, 7, 10, 
    10, 10, 10, 10, 10, 10, 7.5, 8, 10, 10, 10, 10, 10, 10, 10, 
    10, 7.5, 10, 10, 10, 10, 7.5, 10, 10, 10, 8, 9, 9, 10, 10, 
    9, 10, 9.5, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 8, 
    10, 10, 8.5, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 7, 7, 
    9, 10, 9, 10, 8, 10, 10, 7.5, 10, 10, 10, 10, 10, 6.5, 10, 
    10, 10, 9.5, 10, 10, 9, 10, 10, 10, 9, 10, 9.5, 10, 10, 10, 
    10, 10, 10, 10, 9.5, 10, 9, 10, 9, 10, 9, 10, 10, 10, 9.5, 
    7.5, 10, 10, 10, 4.5, 10, 9, 9.5, 10, 8, 10, 1, 10, 8, 8, 
    10, 10, 10, 10, 10, 10, 10, 8, 3.5, 10, 10, 8.5, 10, 9.5, 
    10, 10, 10, 3, 10, 10, 10, 10, 10, 10, 10, 10, 5, 10, 10, 
    10, 8, 7, 10, 10, 9, 5.5, 8, 5, 5, 9, 10, 10, 8, 9, 10, 9, 
    10, 10, 10, 9.5, 10, 10, 10, 10, 10, 1, 7.5, 10, 9, 10, 9.3, 
    10, 10, 10, 8.5, 10, 10, 10, 10, 9, 10, 10, 8, 7.5, 8, 10, 
    8.5, 10, 9, 8.5, 7.5, 8.5, 10, 9, 10, 10, 3.5, 10, 10, 10, 
    10, 10, 6, 10, 8, 10, 10, 10, 10, 10, 10, 10, 8, 8.5, 9, 
    9, 8, 8.5, 5.5, 7.5, 10, 10, 10, 10, 9, 10, 9.5, 8, 5, 10, 
    10, 10, 10, 8, 10, 9, 10, 10, 10, 9, 10, 10, 10, 10, 10, 
    10, 10, 5.5, 10, 10, 9, 4.5, 10, 10, 10, 10, 10, 9.5, 10, 
    10, 10, 9, 10, 10, 10, 9.5, 10, 10, 10, 10, 10, 10, 9.5, 
    10, 10, 8.5, 10, 8.5, 10, 10, 10, 9.5, 10, 8, 10, 9.5, 9.5, 
    10, 9.5, 10, 10, 10, 10, 10, 10, 5.5, 8, 10, 10, 9, 10, 10, 
    10, 10, 10, 10, 8.5, 9.5, 10, 8.5, 10, 5, 10, 9.5, 9.5, 10, 
    10, 10, 8, 10, 10, 10, 8.5, 10, 10, 10, 10, 10, 6, 10, 10, 
    7.5, 8.5, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 8.5, 8, 
    9.5, 10, 10, 9.3, 9.3, 8, 9, 10, 10, 8, 10, 8, 10, 10, 10, 
    10, 8.5, 10, 10, 10, 5, 10, 9, 10, 10, 9, 9.3, 10, 10, 10, 
    10, 2.5, 9, 10, 10, 2, 9.5, 10, 8, 10, 10, 10, 10, 10, 9, 
    8.5, 5.5, 10, 8, 9.5, 10, 10, 6, 10, 10, 10, 9.5, 10, 9.5, 
    6.5, 10, 10, 10, 10, 10, 10, 10, 10, 6, 9.3, 8, 8.5, 9, 10, 
    9.5, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 
    9.5, 9.5, 8.5, 9, 10, 8, 10, 9, 10, 10, 9, 10, 10, 8.5, 9.5, 
    10, 10, 9.5, 10, 9, 8, 10, 10, 9, 10, 8, 9, 10, 10, 6, 9.5, 
    9.5, 10, 9.3, 10, 10, 10, 9, 10, 10, 10, 9.5, 10, 10, 6, 
    10, 10, 10, 10, 10, 9, 4.5, 8.5, 10, 5, 9, 9, 10, 6, 9, 10, 
    9.5, 9.5, 10, 9.5, 10, 7.5, 10, 3, 10, 9.5, 10, 9, 9, 9.5, 
    10, 10, 10, 10, 10, 10, 10, 2, 10, 9.5, 10, 10, 6, 9, 10, 
    10, 8, 10, 10, 6, 10, 8.5, 10, 10, 10, 9, 7.5, 10, 10, 9, 
    10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9.5, 10, 10, 
    10, 6, 10, 9, 10, 8, 5.5, 10, 10, 8.5, 9, 10, 9.5, 6, 10, 
    10, 10, 10, 10, 10, 8, 10, 10, 10, 9, 10, 10, 10, 9, 9, 10, 
    7, 8.5, 10, 10, 8.5, 10, 10, 9, 9.5, 10, 10, 10, 10, 9, 9.3, 
    10, 10, 10, 10, 9.5, 10, 10, 10, 10, 9.3, 10, 10, 10, 10, 
    10, 10, 10, 10, 10, 10, 7.5, 10, 10, 10, 9, 4, 10, 10, 10, 
    10, 5.5, 8.5, 7.5, 10, 10, 10, 10, 10, 10, 8.5, 10, 10, 10, 
    10, 10, 9, 10, 10, 10, 10, 10, 7, 7, 10, 10, 10, 9, 6, 9.5, 
    5.5, 10, 10, 10, 10, 10, 10, 9, 10, 8, 10, 10, 9, 10, 10, 
    10, 10, 10, 10, 10, 10, 9.5, 10, 10, 9, 10, 10, 8, 10, 10, 
    10, 10, 9, 10, 8.5, 10, 9, 10, 8, 9, 10, 10, 8, 9, 10, 7.5, 
    10, 9.5, 10, 9, 10, 8, 10, 10, 10, 10, 8.5, 10, 9.5, 10, 
    10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 9.5, 9.5, 10, 
    10, 10, 10, 10, 9.5, 10, 10, 10, 9, 10, 4.5, 10, 9, 10, 9.5, 
    10, 10, 10, 10, 10, 10, 9.5, 10, 10, 2.5, 4.5, 10, 10, 10, 
    10, 3, 10, 10, 10, 10, 8.5, 10, 8, 10, 10, 10, 10, 10, 10, 
    10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 
    10, 8, 10, 10, 10, 10, 9.3, 10, 10, 10, 10, 10, 10, 10, 7.5, 
    8, 10, 10, 6.5, 8, 10, 10, 9.5, 10, 10, 6.5, 10, 10, 10, 
    10, 10, 10, 6, 10, 10, 10, 10, 8, 9, 7, 10, 8, 10, 10, 9, 
    10, 9, 10, 9.5, 9.5, 10, 10, 9, 10, 10, 10, 10, 7, 10, 9.5, 
    10, 10, 8, 10, 6.5, 7.5, 10, 10, 10, 9.5, 10, 9, 10, 10, 
    10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 9.3, 10, 10, 8.5, 
    10, 10, 10, 7.5, 10, 10, 10, 10, 10, 7.5, 10, 10, 8.5, 9, 
    6, 8, 10, 10, 10, 10, 10, 10, 10, 8.5, 10, 10, 10, 10, 10, 
    10, 9, 10, 10, 10, 10, 9.3, 10, 10, 7.5, 10, 10, 10, 10, 
    8, 10, 10, 8, 10, 8, 10, 5, 7, 10, 10, 10, 10, 10, 8.5, 10, 
    10, 10, 10, 10, 10, 10, 10, 9, 9.3, 8, 10, 10, 7.5, 7, 9, 
    9, 3, 10, 8.5, 10, 10, 9.5, 10, 9, 8, 10, 10, 10, 10, 6, 
    10, 9, 10, 10, 10, 10, 8, 9, 10, 10, 10, 10, 6, 10, 9.5, 
    10, 9, 10, 10, 10, 9, 8.5, 3, 10, 7.5, 9, 10, 10, 9.5, 6, 
    10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 1, 10, 8, 10, 10, 
    10, 10, 10, 10, 7.5, 10, 10, 10, 10, 9, 10, 9, 10, 10, 10, 
    8, 10, 6, 10, 8.5, 9, 9.5, 10, 9.5, 10, 10, 8.5, 10, 10, 
    7, 5.5, 10, 6, 10, 9, 10, 10, 10, 9.5, 10, 10, 6, 7, 10, 
    9.5, 10, 2, 4, 10, 10, 3.5, 10, 8, 4, 10, 10, 10, 10, 8.5, 
    10, 10, 10, 10, 5.5, 9.5, 10, 9.3, 5, 9.3, 10, 8, 10, 8, 
    10, 9, 6.5, 10, 8.5, 9, 10, 9.5, 10, 9, 8.5, 10, 8, 8, 10, 
    9, 6, 9, 9.5, 10, 10, 10, 1.5, 10, 10, 10, 10, 10, 9, 8, 
    10, 10, 10, 10, 9, 10, 6.5, 10, 10, 10, 10, 10, 8, 10, 10, 
    9.5, 10, 10, 10, 9.5, 9, 9.5, 9, 10, 8, 10, 9, 10, 10, 10, 
    10, 9.5, 10, 10, 10, 9, 10, 10, 10, 10, 9.5, 10, 10, 9.5, 
    7, 9, 10, 10, 10, 10, 9.5, 10, 10, 10, 1.5, 10, 10, 9.5, 
    10, 10, 10, 10, 10, 10, 10, 6.5, 8, 10, 10, 9, 10, 10, 10, 
    10, 10, 10, 9, 4.5, 6, 10, 4, 5, 8, 9, 10, 10, 10, 10, 10, 
    10, 10, 10, 10, 10, 10, 4, 10, 10, 10, 10, 10, 10, 4, 10, 
    10, 10, 10, 9.5, 10, 8, 3.5, 10, 10, 9, 10, 10, 10, 10, 10, 
    10, 10, 10, 10, 10, 9, 10, 10, 9, 10, 10, 7.5, 10, 8, 10, 
    10, 10, 9, 10, 9, 10, 9, 10, 9.5, 10, 9.3, 9.5, 10, 9.5, 
    6, 8, 10, 10, 8, 8, 8.5, 9, 10, 10, 10, 9.5, 10, 6, 10, 10, 
    10, 10, 10, 8.5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 
    10, 10, 10, 10, 10, 9.5, 10, 10, 10, 9, 7.5, 9, 8.5, 10, 
    9, 10, 9, 10, 10, 9.5, 10, 9, 8.5, 10, 9.5, 8, 10, 10, 9, 
    10, 10, 10, 8.5, 8, 8, 5.5, 6, 7.5, 10, 10, 10, 10, 10, 9, 
    10, 10, 8, 8, 8, 10, 10, 8, 9, 10, 9.5, 10, 10, 10, 10, 10, 
    10, 10, 10, 9.5, 10, 10, 10, 10, 10, 10, 9.5, 10, 10, 10, 
    10, 10, 9.3, 9, 9, 8.5, 10, 8.5, 10, 10, 10, 10, 8, 8, 10, 
    10, 10, 9, 10, 10, 10, 9, 10, 9, 10, 10, 10, 10, 8.5, 8, 
    10, 10, 10, 10, 5.5, 10, 10, 10, 5.5, 7, 10, 10, 10, 8.5, 
    10, 10, 10, 6, 9.5, 10, 9, 8, 10, 9, 10, 9, 10, 9.3, 10, 
    10, 9.5, 10, 8, 10, 8.5, 9, 10, 7.5, 10, 10, 9, 10, 10, 9, 
    10, 10, 10, 10, 10, 8.5, 9, 10, 10, 10, 9, 9, 9.5, 10, 5, 
    10, 6, 10, 9.5, 10, 10, 9.5, 2.5, 10, 9.5, 9, 10, 10, 2, 
    10, 10, 10, 9.5, 10, 10, 10, 10, 9, 10, 10, 10, 9.5, 9, 10, 
    10, 5, 10, 10, 9, 8, 8, 10, 8.5, 10, 7.5, 2, 8, 10, 10, 10, 
    10, 10, 8.5, 10, 8, 10, 10, 10, 10, 10, 10, 9.5, 9.3, 8.5
    ), product_know = structure(c(4L, 4L, 5L, 4L, 1L, 3L, 11L, 
    4L, 4L, 4L, 4L, 4L, 4L, 5L, 4L, 10L, 9L, 4L, 4L, 4L, 11L, 
    4L, 4L, 9L, 12L, 4L, 11L, 4L, 4L, 4L, 4L, 4L, 12L, 3L, 12L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 4L, 
    4L, 4L, 9L, 12L, 12L, 4L, 4L, 11L, 4L, 4L, 4L, 11L, 4L, 4L, 
    12L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 8L, 12L, 12L, 4L, 
    4L, 4L, 4L, 11L, 4L, 12L, 10L, 11L, 4L, 4L, 4L, 10L, 12L, 
    4L, 12L, 4L, 4L, 11L, 4L, 11L, 12L, 12L, 11L, 4L, 4L, 12L, 
    12L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 12L, 5L, 4L, 12L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 4L, 2L, 4L, 
    4L, 10L, 2L, 11L, 12L, 4L, 4L, 12L, 9L, 12L, 5L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 9L, 10L, 
    11L, 4L, 4L, 9L, 10L, 4L, 4L, 4L, 11L, 4L, 9L, 11L, 8L, 4L, 
    4L, 4L, 12L, 4L, 4L, 11L, 12L, 4L, 4L, 4L, 11L, 12L, 11L, 
    4L, 4L, 4L, 4L, 4L, 4L, 12L, 10L, 4L, 4L, 4L, 11L, 11L, 12L, 
    4L, 12L, 4L, 4L, 4L, 11L, 2L, 4L, 11L, 4L, 4L, 4L, 12L, 4L, 
    4L, 11L, 4L, 12L, 4L, 4L, 4L, 11L, 4L, 4L, 12L, 4L, 4L, 12L, 
    4L, 4L, 4L, 10L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 4L, 11L, 4L, 
    4L, 4L, 4L, 4L, 11L, 4L, 4L, 4L, 4L, 4L, 8L, 12L, 10L, 4L, 
    7L, 12L, 12L, 9L, 10L, 11L, 4L, 4L, 4L, 4L, 12L, 11L, 12L, 
    4L, 12L, 11L, 4L, 4L, 11L, 4L, 4L, 10L, 4L, 1L, 4L, 12L, 
    12L, 4L, 4L, 11L, 4L, 8L, 12L, 11L, 4L, 4L, 12L, 12L, 9L, 
    4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 12L, 4L, 12L, 10L, 11L, 
    4L, 4L, 4L, 4L, 12L, 4L, 12L, 4L, 4L, 12L, 11L, 4L, 12L, 
    4L, 4L, 4L, 11L, 12L, 4L, 4L, 4L, 4L, 6L, 4L, 4L, 4L, 4L, 
    11L, 4L, 4L, 4L, 4L, 2L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 10L, 4L, 4L, 12L, 9L, 4L, 4L, 12L, 4L, 
    11L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 12L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 9L, 11L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 4L, 4L, 4L, 12L, 4L, 
    12L, 4L, 4L, 4L, 4L, 1L, 4L, 4L, 4L, 9L, 4L, 4L, 4L, 4L, 
    4L, 12L, 12L, 4L, 9L, 4L, 12L, 11L, 4L, 4L, 4L, 12L, 4L, 
    4L, 4L, 12L, 9L, 2L, 4L, 4L, 12L, 4L, 4L, 11L, 4L, 12L, 4L, 
    4L, 1L, 4L, 12L, 12L, 12L, 4L, 11L, 4L, 11L, 4L, 11L, 4L, 
    4L, 11L, 12L, 2L, 11L, 11L, 4L, 4L, 4L, 12L, 5L, 11L, 4L, 
    11L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 11L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 9L, 4L, 4L, 4L, 4L, 10L, 4L, 4L, 4L, 11L, 
    12L, 11L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 
    4L, 4L, 4L, 4L, 11L, 4L, 4L, 4L, 11L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 1L, 11L, 10L, 12L, 4L, 12L, 4L, 11L, 4L, 4L, 
    11L, 4L, 4L, 4L, 4L, 4L, 9L, 4L, 4L, 4L, 12L, 4L, 4L, 12L, 
    4L, 4L, 4L, 12L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 12L, 4L, 12L, 4L, 12L, 4L, 4L, 4L, 12L, 10L, 4L, 4L, 
    4L, 9L, 4L, 12L, 4L, 4L, 11L, 4L, 2L, 4L, 11L, 11L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 11L, 5L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 
    4L, 6L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 8L, 4L, 4L, 4L, 11L, 
    10L, 4L, 4L, 12L, 6L, 9L, 8L, 9L, 12L, 4L, 4L, 11L, 11L, 
    4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 3L, 11L, 4L, 
    12L, 4L, 2L, 4L, 4L, 4L, 11L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 
    11L, 10L, 11L, 4L, 11L, 4L, 12L, 12L, 10L, 12L, 4L, 12L, 
    4L, 4L, 9L, 4L, 4L, 4L, 4L, 4L, 9L, 4L, 11L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 11L, 12L, 12L, 12L, 11L, 12L, 8L, 11L, 4L, 
    4L, 4L, 4L, 12L, 4L, 12L, 12L, 8L, 4L, 4L, 4L, 4L, 11L, 4L, 
    12L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 7L, 4L, 
    4L, 12L, 10L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 11L, 4L, 
    4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 12L, 4L, 
    11L, 4L, 4L, 4L, 4L, 4L, 11L, 4L, 12L, 4L, 4L, 12L, 4L, 4L, 
    4L, 4L, 4L, 4L, 8L, 11L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 
    4L, 12L, 12L, 4L, 11L, 4L, 9L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 
    4L, 4L, 4L, 11L, 4L, 4L, 4L, 4L, 4L, 9L, 4L, 4L, 10L, 10L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 12L, 11L, 12L, 4L, 
    4L, 2L, 2L, 12L, 12L, 4L, 4L, 11L, 4L, 11L, 4L, 4L, 4L, 4L, 
    11L, 4L, 4L, 4L, 9L, 4L, 4L, 4L, 4L, 12L, 2L, 4L, 4L, 4L, 
    4L, 5L, 12L, 4L, 4L, 5L, 4L, 4L, 11L, 4L, 4L, 4L, 4L, 4L, 
    12L, 12L, 6L, 4L, 12L, 12L, 4L, 4L, 5L, 4L, 4L, 4L, 12L, 
    4L, 4L, 10L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 9L, 2L, 11L, 
    12L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 
    4L, 4L, 4L, 4L, 12L, 4L, 10L, 12L, 4L, 11L, 4L, 12L, 4L, 
    4L, 12L, 4L, 4L, 11L, 12L, 4L, 4L, 4L, 4L, 11L, 4L, 4L, 4L, 
    12L, 4L, 12L, 11L, 4L, 4L, 9L, 4L, 12L, 4L, 2L, 4L, 4L, 4L, 
    12L, 4L, 4L, 4L, 4L, 4L, 4L, 9L, 4L, 4L, 4L, 4L, 4L, 12L, 
    8L, 12L, 4L, 7L, 12L, 12L, 4L, 9L, 12L, 4L, 12L, 4L, 4L, 
    12L, 4L, 10L, 4L, 5L, 4L, 12L, 4L, 12L, 12L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 6L, 4L, 12L, 4L, 4L, 9L, 12L, 4L, 4L, 
    11L, 4L, 4L, 9L, 4L, 11L, 4L, 4L, 4L, 12L, 11L, 4L, 4L, 12L, 
    4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 
    4L, 4L, 9L, 4L, 12L, 4L, 11L, 8L, 4L, 4L, 11L, 4L, 4L, 4L, 
    6L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 4L, 4L, 4L, 12L, 4L, 4L, 
    4L, 12L, 12L, 4L, 10L, 12L, 4L, 4L, 11L, 4L, 4L, 12L, 4L, 
    4L, 4L, 4L, 4L, 12L, 1L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 
    4L, 2L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 10L, 4L, 
    4L, 4L, 12L, 9L, 4L, 4L, 4L, 4L, 9L, 11L, 10L, 4L, 4L, 4L, 
    4L, 4L, 4L, 10L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 
    4L, 2L, 10L, 4L, 4L, 4L, 12L, 9L, 12L, 9L, 4L, 4L, 4L, 4L, 
    4L, 4L, 12L, 4L, 10L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 11L, 4L, 4L, 4L, 4L, 4L, 
    4L, 11L, 4L, 12L, 4L, 11L, 12L, 4L, 4L, 11L, 12L, 4L, 10L, 
    4L, 4L, 4L, 11L, 4L, 11L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 4L, 12L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 8L, 4L, 12L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 7L, 6L, 4L, 4L, 4L, 
    4L, 7L, 4L, 4L, 4L, 4L, 11L, 4L, 10L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 11L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 4L, 
    4L, 4L, 4L, 11L, 4L, 4L, 4L, 4L, 2L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 11L, 11L, 4L, 4L, 10L, 11L, 4L, 4L, 12L, 4L, 4L, 
    10L, 4L, 4L, 4L, 4L, 4L, 4L, 9L, 4L, 4L, 4L, 4L, 4L, 12L, 
    11L, 4L, 9L, 4L, 4L, 12L, 4L, 12L, 4L, 4L, 12L, 4L, 4L, 12L, 
    4L, 4L, 4L, 4L, 10L, 4L, 4L, 4L, 4L, 11L, 4L, 8L, 11L, 4L, 
    4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 2L, 4L, 4L, 11L, 4L, 4L, 4L, 10L, 4L, 4L, 4L, 
    4L, 4L, 8L, 4L, 4L, 11L, 12L, 9L, 12L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 11L, 4L, 4L, 4L, 1L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    2L, 4L, 4L, 10L, 4L, 4L, 4L, 4L, 11L, 4L, 4L, 11L, 4L, 11L, 
    4L, 8L, 10L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 12L, 2L, 11L, 4L, 4L, 11L, 9L, 11L, 12L, 6L, 
    4L, 10L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    12L, 4L, 4L, 4L, 4L, 11L, 12L, 4L, 4L, 4L, 4L, 9L, 4L, 12L, 
    4L, 12L, 4L, 4L, 4L, 12L, 11L, 6L, 4L, 10L, 12L, 4L, 4L, 
    12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 3L, 4L, 
    11L, 4L, 4L, 4L, 4L, 4L, 4L, 10L, 4L, 4L, 4L, 4L, 11L, 4L, 
    12L, 4L, 4L, 4L, 11L, 4L, 9L, 4L, 12L, 12L, 12L, 4L, 12L, 
    4L, 4L, 12L, 4L, 4L, 11L, 7L, 4L, 9L, 4L, 11L, 4L, 4L, 4L, 
    4L, 4L, 4L, 9L, 10L, 4L, 4L, 4L, 5L, 5L, 4L, 4L, 3L, 4L, 
    9L, 7L, 4L, 4L, 4L, 4L, 11L, 4L, 4L, 4L, 4L, 7L, 12L, 4L, 
    2L, 9L, 1L, 4L, 10L, 4L, 11L, 4L, 12L, 10L, 4L, 12L, 12L, 
    4L, 12L, 4L, 12L, 12L, 4L, 11L, 11L, 4L, 4L, 9L, 12L, 12L, 
    4L, 4L, 4L, 3L, 4L, 4L, 4L, 4L, 4L, 12L, 11L, 4L, 4L, 4L, 
    4L, 4L, 4L, 10L, 4L, 4L, 4L, 4L, 4L, 9L, 4L, 4L, 4L, 4L, 
    4L, 4L, 12L, 11L, 4L, 12L, 4L, 11L, 4L, 12L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    11L, 11L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 5L, 4L, 4L, 4L, 
    4L, 4L, 1L, 4L, 4L, 4L, 4L, 9L, 12L, 4L, 4L, 11L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 3L, 9L, 4L, 3L, 9L, 11L, 12L, 1L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 8L, 4L, 4L, 4L, 4L, 4L, 
    4L, 9L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 3L, 4L, 4L, 12L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    11L, 4L, 12L, 4L, 4L, 4L, 12L, 4L, 12L, 4L, 12L, 4L, 4L, 
    4L, 2L, 12L, 4L, 12L, 8L, 11L, 4L, 4L, 12L, 11L, 11L, 12L, 
    4L, 4L, 4L, 12L, 4L, 9L, 4L, 4L, 4L, 4L, 4L, 11L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 12L, 11L, 12L, 12L, 4L, 12L, 4L, 12L, 4L, 4L, 12L, 
    4L, 12L, 11L, 4L, 12L, 11L, 4L, 4L, 12L, 4L, 4L, 4L, 11L, 
    11L, 11L, 12L, 9L, 10L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 
    11L, 11L, 11L, 4L, 4L, 9L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 
    4L, 4L, 1L, 12L, 12L, 11L, 4L, 12L, 4L, 4L, 4L, 4L, 11L, 
    11L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 12L, 4L, 12L, 4L, 4L, 4L, 
    4L, 11L, 11L, 4L, 4L, 4L, 4L, 10L, 4L, 4L, 4L, 8L, 10L, 4L, 
    4L, 4L, 11L, 4L, 4L, 4L, 9L, 12L, 4L, 12L, 9L, 4L, 12L, 4L, 
    12L, 4L, 2L, 4L, 4L, 12L, 4L, 10L, 4L, 11L, 12L, 4L, 9L, 
    4L, 4L, 11L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 12L, 12L, 4L, 
    4L, 4L, 12L, 12L, 4L, 4L, 9L, 4L, 9L, 4L, 4L, 4L, 4L, 4L, 
    5L, 4L, 4L, 12L, 4L, 4L, 6L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 12L, 4L, 4L, 4L, 12L, 12L, 4L, 4L, 7L, 4L, 4L, 12L, 12L, 
    11L, 4L, 12L, 4L, 9L, 6L, 11L, 4L, 4L, 4L, 4L, 4L, 11L, 4L, 
    11L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L, 12L), .Label = c("-", 
    "0", "1", "10", "2", "3", "4", "5", "6", "7", "8", "9"), class = "factor"), 
    understanding_issue = structure(c(12L, 4L, 5L, 4L, 4L, 9L, 
    10L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 4L, 11L, 9L, 4L, 12L, 4L, 
    4L, 4L, 4L, 8L, 12L, 4L, 11L, 1L, 4L, 4L, 4L, 4L, 4L, 5L, 
    12L, 11L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 4L, 12L, 4L, 4L, 11L, 
    4L, 4L, 12L, 9L, 12L, 12L, 4L, 4L, 10L, 4L, 4L, 4L, 10L, 
    4L, 4L, 10L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 10L, 4L, 9L, 12L, 
    4L, 4L, 4L, 4L, 10L, 4L, 12L, 11L, 11L, 4L, 4L, 4L, 11L, 
    4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 11L, 4L, 4L, 12L, 
    12L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 5L, 4L, 12L, 4L, 1L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 4L, 2L, 4L, 
    1L, 11L, 2L, 11L, 12L, 4L, 4L, 4L, 10L, 9L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 4L, 9L, 1L, 12L, 
    12L, 12L, 7L, 11L, 4L, 4L, 1L, 11L, 4L, 9L, 11L, 11L, 4L, 
    4L, 4L, 12L, 4L, 4L, 11L, 11L, 4L, 4L, 4L, 10L, 12L, 11L, 
    4L, 4L, 4L, 4L, 4L, 4L, 12L, 10L, 4L, 4L, 4L, 4L, 10L, 4L, 
    4L, 12L, 4L, 4L, 4L, 11L, 2L, 4L, 4L, 1L, 4L, 4L, 4L, 4L, 
    4L, 11L, 11L, 12L, 4L, 4L, 4L, 11L, 4L, 4L, 4L, 4L, 11L, 
    9L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 5L, 4L, 4L, 4L, 4L, 4L, 6L, 12L, 10L, 
    4L, 7L, 11L, 11L, 10L, 11L, 12L, 4L, 4L, 4L, 4L, 11L, 11L, 
    12L, 4L, 12L, 11L, 4L, 4L, 11L, 4L, 4L, 4L, 4L, 11L, 4L, 
    12L, 4L, 4L, 11L, 10L, 4L, 7L, 4L, 11L, 4L, 4L, 4L, 11L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 12L, 4L, 4L, 12L, 1L, 
    4L, 4L, 12L, 4L, 11L, 4L, 12L, 4L, 4L, 9L, 9L, 4L, 4L, 4L, 
    4L, 4L, 9L, 4L, 4L, 4L, 4L, 4L, 8L, 4L, 4L, 4L, 4L, 9L, 4L, 
    4L, 4L, 4L, 2L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 4L, 4L, 4L, 
    4L, 4L, 4L, 11L, 4L, 4L, 12L, 2L, 4L, 4L, 4L, 4L, 12L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 1L, 12L, 4L, 12L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 12L, 4L, 9L, 4L, 4L, 4L, 
    12L, 4L, 4L, 4L, 12L, 4L, 1L, 1L, 4L, 4L, 11L, 4L, 4L, 4L, 
    4L, 4L, 4L, 11L, 4L, 4L, 4L, 6L, 4L, 4L, 4L, 4L, 4L, 12L, 
    1L, 4L, 9L, 4L, 4L, 11L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 
    11L, 2L, 4L, 4L, 11L, 4L, 4L, 11L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 5L, 10L, 4L, 10L, 4L, 10L, 4L, 11L, 4L, 1L, 11L, 11L, 
    2L, 11L, 11L, 4L, 4L, 4L, 4L, 3L, 11L, 4L, 9L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 10L, 11L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    12L, 4L, 4L, 4L, 4L, 11L, 1L, 4L, 4L, 11L, 12L, 4L, 4L, 4L, 
    12L, 4L, 12L, 1L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 
    11L, 4L, 4L, 10L, 11L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    9L, 10L, 12L, 4L, 12L, 4L, 11L, 4L, 4L, 10L, 4L, 4L, 4L, 
    4L, 4L, 10L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 12L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 12L, 4L, 12L, 
    4L, 12L, 4L, 4L, 1L, 4L, 11L, 4L, 4L, 4L, 6L, 4L, 12L, 12L, 
    4L, 11L, 4L, 3L, 4L, 11L, 11L, 4L, 4L, 1L, 4L, 4L, 4L, 4L, 
    11L, 8L, 4L, 4L, 11L, 4L, 12L, 4L, 4L, 4L, 6L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 8L, 4L, 4L, 4L, 11L, 10L, 4L, 4L, 12L, 
    11L, 4L, 8L, 7L, 12L, 4L, 4L, 11L, 4L, 4L, 12L, 4L, 4L, 4L, 
    12L, 4L, 4L, 4L, 4L, 4L, 3L, 10L, 4L, 12L, 4L, 2L, 4L, 4L, 
    4L, 12L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 11L, 11L, 11L, 4L, 
    12L, 4L, 12L, 11L, 11L, 11L, 4L, 12L, 4L, 4L, 3L, 4L, 4L, 
    4L, 4L, 4L, 9L, 4L, 11L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 
    11L, 12L, 12L, 11L, 11L, 9L, 10L, 4L, 4L, 4L, 4L, 12L, 4L, 
    4L, 10L, 8L, 4L, 4L, 4L, 4L, 11L, 4L, 12L, 4L, 4L, 4L, 12L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 10L, 4L, 4L, 12L, 5L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 11L, 4L, 12L, 4L, 4L, 4L, 12L, 1L, 
    11L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 9L, 11L, 
    4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 4L, 4L, 12L, 4L, 
    7L, 4L, 12L, 12L, 4L, 4L, 4L, 11L, 4L, 4L, 4L, 12L, 4L, 4L, 
    4L, 4L, 4L, 9L, 4L, 4L, 11L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 12L, 4L, 11L, 11L, 4L, 4L, 4L, 2L, 2L, 10L, 12L, 
    4L, 4L, 11L, 4L, 11L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 7L, 
    4L, 11L, 4L, 4L, 12L, 2L, 4L, 4L, 4L, 4L, 6L, 1L, 4L, 4L, 
    5L, 12L, 4L, 11L, 4L, 4L, 4L, 4L, 4L, 12L, 11L, 11L, 4L, 
    10L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 9L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 9L, 2L, 11L, 11L, 12L, 4L, 12L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 
    12L, 4L, 12L, 4L, 11L, 4L, 12L, 4L, 4L, 12L, 4L, 4L, 12L, 
    4L, 4L, 4L, 12L, 4L, 4L, 9L, 4L, 4L, 12L, 4L, 10L, 4L, 4L, 
    4L, 9L, 12L, 4L, 4L, 2L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 12L, 
    4L, 4L, 1L, 4L, 4L, 4L, 4L, 4L, 12L, 7L, 11L, 4L, 9L, 12L, 
    12L, 4L, 9L, 12L, 4L, 4L, 12L, 1L, 4L, 4L, 11L, 4L, 7L, 4L, 
    4L, 4L, 12L, 12L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 3L, 4L, 
    4L, 4L, 4L, 9L, 12L, 4L, 4L, 11L, 4L, 4L, 9L, 4L, 12L, 4L, 
    4L, 4L, 12L, 10L, 4L, 4L, 12L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 9L, 4L, 12L, 4L, 11L, 
    9L, 4L, 4L, 12L, 11L, 4L, 12L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 
    11L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 12L, 12L, 4L, 10L, 11L, 
    4L, 4L, 12L, 4L, 4L, 12L, 12L, 4L, 4L, 4L, 4L, 12L, 1L, 1L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L, 4L, 4L, 4L, 1L, 
    4L, 4L, 4L, 4L, 11L, 4L, 4L, 4L, 12L, 5L, 4L, 4L, 4L, 4L, 
    8L, 12L, 11L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 1L, 4L, 4L, 4L, 4L, 4L, 10L, 10L, 4L, 4L, 4L, 12L, 2L, 
    4L, 8L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 12L, 4L, 4L, 12L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 12L, 4L, 4L, 
    11L, 4L, 4L, 4L, 4L, 11L, 4L, 12L, 4L, 12L, 4L, 11L, 12L, 
    4L, 4L, 11L, 12L, 4L, 11L, 4L, 12L, 4L, 4L, 4L, 11L, 4L, 
    4L, 4L, 4L, 11L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 11L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 
    4L, 12L, 4L, 7L, 4L, 12L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 
    12L, 4L, 4L, 3L, 9L, 4L, 4L, 4L, 4L, 5L, 4L, 4L, 4L, 4L, 
    12L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 11L, 4L, 4L, 4L, 4L, 11L, 4L, 4L, 
    4L, 4L, 2L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 10L, 11L, 4L, 4L, 
    9L, 11L, 4L, 4L, 4L, 4L, 4L, 9L, 4L, 4L, 4L, 4L, 4L, 4L, 
    9L, 4L, 4L, 4L, 4L, 9L, 12L, 9L, 4L, 4L, 4L, 4L, 12L, 1L, 
    1L, 4L, 12L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 2L, 4L, 12L, 
    4L, 4L, 11L, 4L, 11L, 10L, 4L, 4L, 4L, 12L, 4L, 12L, 4L, 
    4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 4L, 
    12L, 4L, 4L, 4L, 11L, 4L, 4L, 4L, 1L, 4L, 4L, 4L, 4L, 12L, 
    12L, 9L, 10L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 
    4L, 4L, 4L, 11L, 4L, 4L, 4L, 4L, 2L, 4L, 4L, 11L, 4L, 4L, 
    4L, 4L, 11L, 4L, 4L, 11L, 4L, 11L, 4L, 2L, 10L, 4L, 4L, 4L, 
    4L, 4L, 11L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 2L, 11L, 
    4L, 4L, 10L, 11L, 4L, 12L, 6L, 4L, 4L, 4L, 4L, 12L, 4L, 12L, 
    9L, 4L, 4L, 4L, 4L, 5L, 4L, 12L, 4L, 4L, 4L, 4L, 11L, 12L, 
    4L, 4L, 4L, 4L, 9L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 12L, 12L, 
    6L, 4L, 11L, 12L, 4L, 4L, 4L, 5L, 4L, 4L, 1L, 4L, 4L, 4L, 
    4L, 4L, 4L, 11L, 3L, 4L, 11L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 
    4L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 11L, 4L, 2L, 4L, 
    11L, 12L, 4L, 4L, 4L, 4L, 4L, 11L, 4L, 4L, 9L, 10L, 4L, 9L, 
    4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 9L, 10L, 4L, 12L, 4L, 1L, 
    9L, 4L, 4L, 9L, 4L, 4L, 2L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 
    4L, 4L, 10L, 4L, 4L, 2L, 7L, 1L, 4L, 12L, 4L, 11L, 4L, 12L, 
    9L, 4L, 11L, 12L, 4L, 4L, 4L, 12L, 11L, 4L, 11L, 11L, 4L, 
    11L, 2L, 12L, 4L, 4L, 4L, 4L, 5L, 4L, 4L, 4L, 4L, 4L, 12L, 
    11L, 4L, 4L, 4L, 4L, 11L, 4L, 9L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 12L, 12L, 4L, 11L, 4L, 12L, 
    4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 12L, 
    4L, 4L, 12L, 9L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 3L, 
    4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 10L, 10L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 11L, 9L, 4L, 10L, 7L, 11L, 
    12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 6L, 4L, 
    4L, 4L, 4L, 4L, 4L, 5L, 4L, 4L, 4L, 4L, 12L, 4L, 1L, 9L, 
    4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 11L, 
    4L, 4L, 11L, 4L, 4L, 10L, 4L, 10L, 4L, 4L, 4L, 12L, 4L, 12L, 
    4L, 12L, 4L, 12L, 4L, 2L, 4L, 4L, 4L, 10L, 11L, 4L, 4L, 10L, 
    11L, 12L, 12L, 4L, 4L, 4L, 4L, 4L, 9L, 4L, 4L, 4L, 4L, 4L, 
    12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 4L, 4L, 
    4L, 4L, 12L, 4L, 4L, 4L, 12L, 10L, 12L, 11L, 4L, 12L, 4L, 
    12L, 4L, 4L, 4L, 4L, 12L, 12L, 4L, 4L, 11L, 4L, 4L, 12L, 
    4L, 4L, 4L, 12L, 11L, 11L, 5L, 9L, 11L, 4L, 4L, 4L, 4L, 4L, 
    12L, 4L, 4L, 1L, 11L, 11L, 4L, 4L, 4L, 12L, 4L, 12L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 1L, 12L, 12L, 12L, 4L, 11L, 4L, 4L, 4L, 
    4L, 11L, 11L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 12L, 4L, 12L, 
    4L, 4L, 4L, 4L, 12L, 11L, 4L, 4L, 4L, 4L, 7L, 4L, 4L, 4L, 
    9L, 10L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 2L, 4L, 4L, 12L, 4L, 
    4L, 12L, 4L, 12L, 4L, 2L, 4L, 4L, 4L, 4L, 12L, 4L, 12L, 12L, 
    4L, 12L, 4L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 4L, 11L, 
    12L, 4L, 4L, 4L, 12L, 12L, 12L, 4L, 7L, 4L, 9L, 4L, 12L, 
    4L, 4L, 12L, 6L, 4L, 12L, 12L, 4L, 4L, 3L, 4L, 4L, 4L, 12L, 
    4L, 4L, 4L, 4L, 12L, 4L, 4L, 4L, 4L, 12L, 4L, 4L, 9L, 4L, 
    4L, 12L, 10L, 11L, 4L, 11L, 4L, 12L, 3L, 11L, 4L, 4L, 4L, 
    4L, 4L, 12L, 4L, 11L, 4L, 4L, 4L, 4L, 4L, 4L, 12L, 2L, 11L
    ), .Label = c("-", "0", "1", "10", "2", "3", "4", "5", "6", 
    "7", "8", "9"), class = "factor"), case_age = c(24.84, 0.05, 
    13.38, 0.15, 11.11, 4.16, 8.13, 0.07, 3.61, 0, 3.11, 20.94, 
    0.21, 17.49, 1.11, 6.15, 4.32, 4.03, 0.08, 3.06, 4.74, 12.07, 
    4.79, 5.29, 0.21, 0.06, 3.95, 0.12, 7.27, 4.18, 2.49, 20.95, 
    0.15, 10.96, 6.99, 47.42, 4.96, 0.06, 4.92, 0.06, 6.84, 0.3, 
    0.01, 0.07, 15.74, 5.8, 2.85, 0.17, 16.02, 1.33, 7.91, 5.95, 
    1.48, 14.7, 1.98, 0.07, 12.89, 0.09, 0.11, 6.96, 0.19, 6.23, 
    5.62, 6.81, 6.98, 0.03, 0.12, 9.21, 0.8, 8.93, 1.87, 6.01, 
    0.34, 28.06, 16.36, 0.74, 5.82, 2.23, 0.18, 1.21, 0.06, 22.21, 
    1.97, 0.88, 0.21, 0.86, 6.02, 8.9, 1.75, 0.1, 1.15, 0.01, 
    0.17, 0.03, 7.99, 0.08, 0.05, 2.92, 1.02, 0.1, 0.86, 18.07, 
    0.06, 10.22, 1.1, 1.25, 0.03, 0.03, 0.96, 0.88, 0.96, 16.42, 
    1.06, 10.11, 0.97, 0.02, 0.12, 2.12, 7.29, 0.06, 0.27, 10.01, 
    1.96, 0.27, 0.04, 2.1, 9.34, 2.05, 22.29, 0, 6.98, 9.17, 
    15.55, 31.06, 0.06, 2.96, 11.04, 0.14, 17.36, 24.16, 41.89, 
    0.07, 0.01, 0.09, 5.1, 3.26, 1.85, 19.09, 10.88, 3.05, 0.87, 
    0.01, 2.78, 26.05, 14.23, 19.27, 0.09, 4.16, 3.77, 1.84, 
    11.06, 12.54, 3.26, 0.19, 0.15, 3.89, 19.85, 0.04, 13.18, 
    2.05, 0.89, 1.04, 0.09, 20.2, 0.82, 0.94, 4.99, 4.15, 0.04, 
    5.84, 15.75, 0.78, 1.92, 4.28, 6.08, 0.15, 83.05, 13.9, 2.75, 
    2.05, 0.02, 4.14, 6.72, 11.12, 1.82, 0.79, 0.12, 7.91, 0.16, 
    2.07, 2.1, 0.09, 0.14, 2.04, 2.22, 1.01, 0.06, 1.07, 1.98, 
    2.42, 6.39, 0.52, 6.93, 1.28, 2.02, 3.74, 34.86, 0.01, 7.15, 
    2.97, 1.15, 0.17, 0.18, 7.25, 2.98, 1.11, 85.99, 2.34, 0.67, 
    45.13, 1.03, 0.04, 0.13, 9.87, 7.03, 4.29, 0.1, 0.04, 0.07, 
    8.26, 0.2, 1.21, 1.81, 0.12, 1.12, 20.28, 0.05, 18.29, 2.78, 
    15.36, 4, 6.12, 0.04, 9.14, 0, 7.1, 19.07, 4.04, 3.9, 4.01, 
    11.22, 0, 0.09, 2.1, 3.05, 3.86, 15.21, 0.54, 0.01, 31.19, 
    2.17, 4.07, 20.07, 3.17, 14.38, 0.27, 13.89, 3.29, 2.82, 
    0.01, 2.58, 5.15, 9.85, 1.06, 14.24, 3.05, 5.96, 0.05, 0.01, 
    0.04, 0.07, 0.16, 49.02, 10.89, 4.91, 0.02, 5.31, 0.01, 0.02, 
    0.04, 3.99, 1.02, 6.18, 1.15, 6.18, 27.18, 5.16, 3.29, 3.97, 
    4.79, 0, 19.92, 0, 18.3, 11.01, 0.01, 4.09, 6.44, 10.98, 
    13.02, 0.1, 2.04, 1.3, 7.22, 1.82, 7.02, 0.91, 0.31, 0.95, 
    0.01, 12.09, 0.04, 0.84, 0.91, 28.75, 0.99, 1.12, 0.22, 5.12, 
    26.98, 1.01, 1.27, 1.29, 7.16, 0.07, 0.05, 1.01, 2.35, 0.17, 
    0.4, 0.89, 2.26, 6.1, 0.89, 1.16, 0.07, 5.69, 9.1, 1.88, 
    0.03, 15.21, 1.76, 14.14, 15.33, 1.02, 13.18, 0.09, 19.76, 
    1.99, 8.79, 2.81, 0.73, 0.24, 22.85, 0.12, 0.2, 0.18, 0.84, 
    20.92, 15.8, 0.04, 21.58, 0.04, 1.06, 1.06, 15.76, 9.29, 
    16.2, 0.09, 2.81, 10.82, 0.02, 41.96, 1.17, 0.35, 1.99, 4.93, 
    0.14, 0.95, 16.02, 4.05, 0.09, 0.02, 2.05, 2.02, 3.01, 0.02, 
    8.05, 0.17, 3.08, 0.99, 0.91, 1.31, 7.13, 1.05, 9.14, 36.25, 
    3.92, 3, 2.02, 11.14, 17.04, 1.08, 5.85, 4.27, 29.07, 25.07, 
    2.74, 24.28, 15.11, 0.85, 0.97, 38.02, 0.08, 102.44, 19.36, 
    3.77, 3.32, 0.04, 3.01, 3.86, 8.27, 7.11, 11.95, 1.21, 3.33, 
    0.15, 0, 4.68, 4.16, 12.94, 0.79, 7.81, 5.82, 6.29, 0.96, 
    13.75, 0.89, 0.97, 35.83, 1.03, 9.24, 0.08, 41.18, 0.79, 
    0.07, 1.19, 6.96, 6.9, 3.25, 2.28, 8.81, 1.21, 0.04, 5.94, 
    0.04, 3.95, 3.72, 1.72, 3.73, 0.12, 8.52, 41.09, 0.74, 0.02, 
    15.16, 2.03, 0.03, 4.1, 4.3, 0.01, 2.05, 0.02, 154.08, 6.11, 
    1.04, 1.01, 0.17, 2.43, 8.18, 77.15, 0.09, 4.97, 6.04, 44.74, 
    0.08, 6.94, 2.39, 2.11, 1.13, 5.33, 4.88, 2.78, 8.07, 1.63, 
    0, 0.18, 24.09, 0.04, 1.08, 7.91, 2.11, 1.32, 6.86, 8.04, 
    1.12, 21.89, 1.22, 18.03, 0.98, 1.8, 9.34, 8.25, 2.87, 0.03, 
    6.12, 27.89, 1.78, 3.82, 0, 21.36, 5.86, 0.01, 0.01, 0.02, 
    0.07, 38.29, 89.9, 4.99, 4, 6.14, 0.02, 0, 6.06, 5.44, 0.01, 
    0.07, 0.03, 27.24, 0, 4.22, 0.04, 5.98, 0.02, 10.12, 95.08, 
    0.11, 0.17, 0.08, 12.87, 6.31, 10.89, 0.25, 0, 1.08, 0.26, 
    0, 61.47, 0.21, 3.92, 6.18, 11.4, 11.27, 0.97, 0.08, 1.17, 
    7.73, 7.02, 0.08, 1.43, 0.26, 1.14, 21.26, 0.01, 0.3, 1.22, 
    0.01, 7.24, 7.4, 0.07, 1.86, 15.29, 5.43, 1.05, 4.2, 0.04, 
    6.12, 6.96, 0.05, 0.01, 78.46, 25.93, 1.8, 0.04, 1.58, 8.24, 
    22.1, 6.67, 43.13, 2.77, 4.29, 23.01, 3.05, 0.17, 70.22, 
    23.22, 0.07, 2.07, 1.89, 13.61, 21.64, 3.74, 0.18, 18.29, 
    12.23, 8.09, 7.01, 0.92, 8.86, 9.15, 15.14, 8.16, 1.27, 0.85, 
    0.06, 0.24, 2.11, 5.3, 78.17, 1.81, 0.13, 0.37, 0.01, 20.66, 
    49.08, 3.73, 2.77, 0.32, 0.12, 36.77, 0.03, 21.49, 5.65, 
    4.74, 26.99, 0.04, 12.56, 2.25, 4.24, 1.87, 5.32, 49.12, 
    1.99, 3.98, 1.16, 0.16, 5.02, 0.1, 2.92, 34.15, 57.01, 0.29, 
    0.84, 0, 0.82, 15.27, 0.01, 5.09, 205.09, 12.02, 5.94, 0.05, 
    3.01, 2.23, 0.19, 4.97, 4.89, 0.75, 6.18, 0.88, 26.17, 7.43, 
    32.88, 1.67, 10.28, 1.08, 0.23, 11.5, 0, 4.81, 1.83, 33.09, 
    0.33, 8.75, 1.97, 0.08, 1.03, 33.74, 0.03, 4.61, 40.9, 14.69, 
    5.26, 4.72, 5.68, 0.24, 1.31, 5.86, 0.16, 0.13, 0.95, 2.23, 
    1.22, 13.94, 5.31, 0.1, 2.14, 0.16, 0.16, 5.14, 2.82, 0, 
    0.15, 7.9, 0.19, 1.12, 0.02, 22.05, 0.05, 2.12, 0, 0.31, 
    0.05, 2.84, 0.9, 5.08, 15.07, 2.21, 0.1, 0.01, 19.88, 0.02, 
    13, 20.92, 2.02, 1.15, 6.37, 0.83, 3.1, 0.85, 1.22, 0.87, 
    1.95, 7.21, 0.12, 0.11, 8.15, 0.01, 6.11, 3.01, 3.61, 0.01, 
    0.13, 0.03, 3.1, 0.08, 1, 46.36, 0.29, 21.17, 1.84, 1.01, 
    29.89, 0.98, 2.18, 0.13, 17, 3.33, 0.02, 1.01, 1.03, 0.91, 
    4.02, 0.78, 0, 8.24, 0.13, 0.05, 2.17, 1.02, 2.07, 0.07, 
    0.15, 1.36, 8.01, 1.8, 0.01, 7.13, 0, 3.9, 3.71, 3.75, 4.98, 
    36.27, 6.96, 2.88, 0.14, 4.07, 3.74, 6.4, 9.15, 8.53, 67, 
    16.3, 29.12, 10.39, 15.83, 0.35, 0.33, 28.21, 0.05, 0.01, 
    54.93, 0.17, 4.04, 3.03, 0.02, 12.07, 10.4, 0.05, 6.26, 5.75, 
    4.86, 15, 40.39, 20.11, 0.03, 0.95, 17.69, 2.43, 10.4, 3.82, 
    26.37, 5.36, 0, 0.12, 19.32, 5.25, 0.05, 0.01, 0.12, 7.01, 
    1.01, 3.87, 4.05, 5.86, 1.25, 7.22, 1.11, 0.69, 8.94, 13.89, 
    0.07, 1.05, 1.22, 0.07, 0.02, 12.85, 0.04, 12.03, 8.84, 0.99, 
    0.02, 0.14, 0.01, 5.04, 1.23, 27.99, 8.97, 24.05, 113.85, 
    20.15, 10.06, 1.15, 0.05, 12.79, 10.04, 0.1, 2.19, 0.01, 
    0.01, 18.23, 1.94, 0.31, 0.03, 7.83, 0.09, 3.41, 1.16, 0.12, 
    2.16, 2.99, 13.87, 1.15, 1, 0.96, 3.08, 6.13, 1.05, 0.06, 
    0.23, 0.07, 0.89, 1.94, 0.04, 1.01, 19.78, 1.9, 1.01, 7.11, 
    0.02, 0, 0.03, 0.07, 0.06, 8.01, 3.44, 16.77, 1.76, 1.06, 
    13.07, 1.01, 52.08, 1.02, 0.27, 0.04, 0.85, 4.15, 0.01, 0.1, 
    0.02, 10.14, 5.88, 0.01, 4.22, 53.82, 4.96, 0.1, 14.1, 0.05, 
    0.07, 32.79, 0.03, 1.4, 7.01, 15.21, 18.44, 0.07, 9.02, 6.9, 
    25.62, 2.58, 5.93, 15.02, 0.01, 16.89, 4.96, 10.14, 7.11, 
    0.11, 2.7, 4.07, 1.09, 0.06, 0.25, 0.88, 21.88, 0, 0.04, 
    23.18, 14.93, 17.38, 0.12, 17.95, 66.21, 2.8, 4.99, 0, 0.12, 
    0.03, 1.41, 3.36, 1.46, 3, 0.05, 3.79, 1.24, 0.1, 1.19, 4.97, 
    0.11, 11.93, 0.1, 1.1, 0.29, 0.02, 0.07, 1.2, 0.02, 64.81, 
    0.13, 14.53, 0.09, 0.04, 2, 1.18, 0.06, 1.01, 1.17, 0.03, 
    0.01, 0.05, 9.29, 1.84, 1.97, 159.11, 0.02, 13.81, 0.01, 
    15.03, 16.1, 0.02, 0.97, 0.06, 0.05, 12.97, 7.95, 10.86, 
    0, 205.09, 4.93, 2.36, 15.08, 19.17, 0.02, 14.32, 0.17, 0.59, 
    13.14, 4.93, 6.19, 0.28, 6.29, 0.14, 0.08, 0.77, 0, 0.05, 
    0.22, 7.83, 0.01, 12.23, 0.08, 1.13, 0.08, 0.06, 0.82, 0.13, 
    5.94, 0.24, 0.45, 0.03, 0.86, 0.02, 0.15, 1.46, 83.05, 0.81, 
    0.06, 0.07, 20.11, 0.05, 125.08, 2.01, 0.15, 0.07, 0.59, 
    1.1, 27.35, 18.75, 0.26, 0.03, 0.79, 1.94, 12.95, 2.12, 0.06, 
    0.9, 0.95, 0.04, 20.2, 0.13, 42.57, 0.09, 30.17, 0, 0.01, 
    0.18, 2.77, 0.01, 0.02, 50.26, 0.43, 0.25, 39.14, 6.41, 0.12, 
    26.87, 0, 9.21, 21.3, 50.29, 15.4, 0.1, 1, 0, 0.01, 0.16, 
    0.13, 31.76, 0.04, 28.03, 0.17, 5.08, 7.06, 0.18, 19.35, 
    1.52, 0.88, 0, 12.02, 0, 10.69, 19.06, 0.02, 20.19, 13.7, 
    16.96, 14, 0.89, 0.12, 27.98, 8.27, 0.06, 0.2, 6.04, 1.06, 
    0.3, 0.33, 13.04, 99.27, 0.13, 0.06, 26.15, 5.29, 0.23, 0.15, 
    2.04, 0, 0.84, 20.12, 2.04, 7.01, 2.07, 0.03, 0.05, 13.97, 
    0.22, 0.02, 9.74, 22.18, 0.95, 0.78, 0.89, 4.47, 1.06, 0.92, 
    0.07, 0.08, 0.05, 2.1, 1.99, 28.13, 0.09, 1.89, 0.03, 0.03, 
    50.89, 0.61, 0, 0.14, 2.02, 0.02, 9.84, 1, 0.04, 1.8, 7.84, 
    1.39, 13.71, 0.93, 0.05, 2.08, 1.02, 0.02, 1.85, 37.04, 17.15, 
    28.25, 0.1, 26.03, 20.77, 0.1, 0.09, 38.07, 0.02, 2.12, 0.7, 
    14.24, 8.89, 84.15, 0.77, 1.05, 0.15, 0.05, 2.14, 2.26, 0.06, 
    1, 0.1, 0.19, 17.1, 36.1, 4.04, 0.1, 0.17, 10.97, 2.32, 3.36, 
    146.99, 0.14, 21.86, 1.15, 0.06, 2.02, 2.95, 0.84, 28.28, 
    0.03, 0.15, 0.02, 4.17, 29.98, 0.64, 1.04, 5.8, 0.03, 0, 
    4.01, 21.03, 2.95, 6.3, 3.13, 17.2, 3.14, 0.02, 0.04, 0.17, 
    0.05, 3.98, 1.23, 0.13, 4.81, 0, 0.17, 3.25, 15.83, 3.96, 
    3.29, 14.35, 0, 0.06, 6.37, 3.26, 20.88, 1.02, 4.8, 0.91, 
    0.05, 0.95, 0.01, 6.13, 1.04, 0.08, 26.77, 4.11, 0.24, 0.01, 
    1.21, 14.11, 1.1, 0.93, 1.11, 0.9, 5.12, 31.12, 0.01, 5.09, 
    15.19, 28.27, 4.49, 7.84, 7.19, 1.1, 0.09, 0, 0.02, 1.06, 
    0.02, 1.06, 0.03, 2.15, 0.03, 1.12, 0.06, 1.04, 57.98, 7.98, 
    0.07, 3.66, 0, 0.01, 1.03, 1.79, 8.78, 0.09, 1.8, 0.16, 0.02, 
    0.14, 0.22, 0, 0.97, 8.8, 1.1, 1.11, 2.12, 1.28, 1.04, 1.13, 
    1.1, 1.08, 10.96, 1.1, 0.02, 2.66, 3.07, 1.79, 0.84, 0.09, 
    17.9, 1.86, 1.02, 11.05, 0.15, 4.2, 2.24, 0.3, 15.93, 8.18, 
    1.07, 8.42, 8.43, 19.8, 2.88, 23.03, 9.99, 3.98, 3.05, 2.69, 
    3.34, 4.28, 4.07, 8.16, 11.13, 4.03, 0.06, 1.64, 3.08, 0.02, 
    0.06, 2.85, 1.19, 24.44, 6.08, 0.04, 10.76, 4.86, 5.13, 16.21, 
    4.74, 7.04, 6.1, 5.1, 7.31, 42.93, 1.19, 0.17, 4.26, 0.83, 
    25.89, 0.04, 0.82, 0.01, 4.98, 7.98, 0.1, 1.28, 0.16, 0.79, 
    4.75, 3.92, 2.08, 0.57, 7.91, 1.09, 0, 0.89, 1.19, 1.22, 
    0.68, 2.11, 1.81, 0.09, 11.87, 0.02, 0.92, 29.11, 6.05, 0.87, 
    2.06, 13.07, 12.13, 4.96, 49.13, 0.05, 12.55, 0.13, 0.13, 
    0.11, 1.01, 6, 1.03, 2.08, 0.01, 2.17, 0.11, 1.28, 9.02, 
    12.82, 0.19, 12.28, 34.37, 1.18, 1.57, 8.85, 2, 0.97, 0.74, 
    0.06, 8.88, 14.23, 1.5, 14.12, 0.05, 0.82, 1.92, 1.76, 0.77, 
    0.11, 12.26, 0.95, 0.93, 0.74, 9.57, 0.01, 7.06, 7.18, 2.96, 
    2.88, 6.17, 0.01, 14.69, 3.03, 1.04, 1.26, 2.02, 8.83, 0.03, 
    17, 4.08, 0.09, 2.98, 0.22, 14.82, 2.84, 1.02, 1.93, 17.18, 
    0.01, 0.09, 0.97, 14.06, 3.23, 16.07, 8.24, 3.13, 7.32, 0.02, 
    0.56, 105.51, 4.73, 0.02, 5.17, 3.97, 5.94, 4.01, 6.83, 2.6, 
    0.16, 4.29, 2.93, 93.53, 30.24, 2.27, 0.02, 0, 16.04, 4.99, 
    0.13, 6.01, 1.33, 6.97, 4.09, 1.11, 0.17, 48.05, 21.09, 10.93, 
    2.93, 3.68, 4.19, 4.25, 8.1, 0.88, 2.25, 19.76, 0.05, 6.91, 
    0.85, 13.31, 0.04, 60.28, 0.04, 4.34, 0.05, 0.09, 4.99, 0.03, 
    7.71, 0.31, 6.33, 0.97, 0.03, 55.03, 14.1, 2.22, 5.02, 0.89, 
    4.98, 0.04, 0.17, 0.12, 0.23, 13.95, 1.05, 40.94, 1.93, 0.07, 
    0.15, 0.92, 6.21, 37.76, 0.05, 0, 13.22, 17.28, 2, 39.14, 
    7.26, 0.01, 0.82, 2.08, 15.96, 0.09, 2.01, 0.04, 0, 0.02, 
    0.94, 3.88, 37.32, 0.11, 3.34, 0.18, 0.05, 3.11, 0.08, 1.84, 
    0.06, 11.04, 8, 0.32, 18.18, 18, 0.04, 1.05, 0.26, 0.9, 3.17, 
    77.15, 4.06, 2.89, 5.23, 1.74, 12.3, 2.81, 0.17, 0.04, 15.16, 
    25.04, 0, 4.02, 18.94, 6.91, 9.98, 8.29, 19.83, 18.17, 3.57, 
    9.47, 18.6, 1.2, 0.07, 3.32, 0.03, 3.78, 0.06, 9.83, 0.15, 
    2.96, 10.06, 2.2, 4.23, 7.24, 12.9, 0.04, 20.93, 10.25, 1.13, 
    0.73, 4.98, 31.28, 4.03, 1.02, 17.29, 8.91, 25.07, 1.03, 
    24.33, 8.31, 34.02, 40.03, 0.86, 0.86, 0.02, 6.21, 0.99, 
    1.29, 2.03, 5.12, 0.12, 6.85, 1.92, 7.03, 0.03, 0, 1.98, 
    0.82, 0.71, 48.98, 0.07, 5.24, 0.16, 1.09, 1.15, 53.73, 0.05, 
    0.11, 1.82, 0.2, 43.04, 0.94, 0.06, 4.89, 4.1, 22.9, 16.91, 
    8.65, 8.71, 1.33, 6.76, 0.02, 0.18, 7.31, 0.22, 2.73, 0.86, 
    0.05, 2.01, 21.23, 0.22, 2.13, 0.08, 0.81, 0.8, 0.12, 1.02, 
    1, 0.04, 0.09, 1.98, 0.05, 2.13, 0.2, 3.32, 7.95, 0.25, 1.81, 
    15.31, 0.21, 2.12, 0.71, 8.12, 1.89, 0.99, 2.01, 17.28, 8.81, 
    1.28, 1.7, 0.22, 6.83, 0, 0.28, 0.08, 4.21, 18.07, 0.11, 
    7.1, 2.13, 0.02, 2.04, 22.03, 4.22, 0.43, 14.87, 0.01, 0.24, 
    2.95, 0.18, 0.12, 10.27, 8.4, 9.99, 3.9, 0.08, 3.24, 4.08, 
    0.07, 17.2, 0.12, 6.01, 4.02, 0.06, 13.32, 3.61, 0.12, 0.25, 
    18.78, 0.06, 4.25, 1, 0.05, 0.06, 0.89, 0.04, 1.83, 0.24, 
    0.02, 0.06, 0.07, 0.03, 0.87, 10.87, 4.19, 0.03, 1.14, 5.21, 
    0.18, 7.13, 4.93, 0.04, 4.92, 1.3, 4.98, 0.1, 7.12, 0.83, 
    2.27, 0.22, 0.01, 7.08, 11.31, 12.05, 6.86, 0.08, 0.68, 0, 
    8.23, 2.23, 0.09, 13.17, 1.04, 0.01, 1.01, 2.39, 0.91, 0.08, 
    5.06, 23.23, 0.06, 0.01, 0.04, 8.38, 0.18, 70.22, 22.05, 
    0.03, 0.08, 54.6, 11.23, 0.01, 1.01, 0.02, 31.07, 0.03, 2.18, 
    0.06, 33.81, 0.07, 0.05, 7.16, 0.13, 1.89, 6.01, 1.03, 2.78, 
    1.91, 0.01, 1.02, 1.35, 2.17, 0.26, 21.07, 0.01, 1.18, 9.06, 
    1.88, 1.89, 0.25, 0.86, 0.06, 0.05, 37.94, 10.97, 21.06, 
    2.07, 5.26, 1.23, 0.05, 10.01, 0.98, 4.05, 0.39, 1.17, 2.26, 
    3.18, 30.22, 0.52, 9.2, 17.05, 0.09, 0.14, 3.08, 1.97, 0.14, 
    9.69, 22.38, 5.08, 2.98, 0.03, 0.02, 4.27, 16.94, 0.1, 3.2, 
    18.94, 0.14, 2.49, 1.04, 0.33, 4.84, 0.06, 10.23, 0.14, 3.69, 
    5.95, 0.09, 0.02, 0.25, 17.12, 0.94, 0.09, 0, 0.18, 0.83, 
    4.05, 0.18, 0.05, 13.2, 14.01, 5.95, 0.96, 0, 1.17, 14.22, 
    0.98, 21.14, 0.14, 6.1, 4.62, 6.1, 0.06, 0.96, 6.66, 1.72, 
    0.05, 22.12, 1.43), severity_level = structure(c(1L, 1L, 
    4L, 2L, 1L, 4L, 4L, 1L, 1L, 1L, 4L, 4L, 4L, 2L, 2L, 2L, 2L, 
    2L, 4L, 1L, 2L, 2L, 4L, 2L, 1L, 2L, 4L, 1L, 4L, 1L, 4L, 2L, 
    1L, 1L, 2L, 2L, 2L, 2L, 4L, 2L, 1L, 4L, 4L, 4L, 1L, 1L, 1L, 
    2L, 2L, 2L, 2L, 4L, 2L, 4L, 1L, 2L, 2L, 2L, 4L, 1L, 2L, 4L, 
    2L, 1L, 4L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 4L, 2L, 
    2L, 2L, 2L, 2L, 1L, 4L, 1L, 2L, 4L, 1L, 2L, 1L, 2L, 2L, 1L, 
    4L, 2L, 2L, 4L, 4L, 2L, 2L, 1L, 2L, 4L, 2L, 1L, 2L, 4L, 2L, 
    4L, 4L, 2L, 2L, 1L, 2L, 4L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 1L, 
    2L, 4L, 2L, 4L, 2L, 2L, 1L, 2L, 2L, 2L, 4L, 2L, 4L, 4L, 1L, 
    4L, 4L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 4L, 
    4L, 2L, 2L, 2L, 4L, 4L, 2L, 1L, 2L, 4L, 1L, 1L, 2L, 2L, 1L, 
    4L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 1L, 4L, 1L, 1L, 2L, 2L, 
    2L, 4L, 2L, 1L, 2L, 2L, 1L, 4L, 4L, 2L, 1L, 4L, 2L, 4L, 4L, 
    2L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 4L, 2L, 2L, 4L, 
    2L, 4L, 4L, 1L, 2L, 1L, 4L, 2L, 4L, 2L, 2L, 2L, 2L, 4L, 4L, 
    2L, 2L, 4L, 4L, 1L, 2L, 4L, 4L, 2L, 1L, 2L, 2L, 2L, 4L, 4L, 
    4L, 1L, 1L, 4L, 4L, 4L, 4L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 
    2L, 2L, 2L, 2L, 2L, 4L, 1L, 4L, 1L, 2L, 4L, 2L, 1L, 1L, 2L, 
    2L, 4L, 4L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 
    2L, 2L, 2L, 1L, 2L, 1L, 4L, 4L, 2L, 1L, 2L, 4L, 2L, 2L, 1L, 
    2L, 1L, 4L, 4L, 1L, 4L, 4L, 2L, 1L, 2L, 2L, 2L, 2L, 4L, 2L, 
    1L, 1L, 2L, 4L, 2L, 2L, 2L, 2L, 4L, 1L, 2L, 2L, 2L, 2L, 4L, 
    2L, 1L, 1L, 2L, 1L, 4L, 1L, 4L, 1L, 2L, 2L, 4L, 2L, 2L, 4L, 
    2L, 1L, 4L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 1L, 2L, 4L, 1L, 2L, 
    2L, 2L, 4L, 1L, 2L, 2L, 1L, 4L, 1L, 4L, 2L, 2L, 1L, 2L, 1L, 
    1L, 1L, 1L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 4L, 
    1L, 4L, 2L, 2L, 1L, 4L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, 4L, 1L, 
    1L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 4L, 4L, 4L, 1L, 2L, 4L, 1L, 
    2L, 1L, 2L, 4L, 1L, 2L, 1L, 4L, 2L, 4L, 2L, 2L, 2L, 4L, 4L, 
    2L, 4L, 1L, 2L, 2L, 2L, 4L, 4L, 4L, 4L, 2L, 1L, 1L, 2L, 4L, 
    2L, 1L, 1L, 1L, 1L, 2L, 4L, 1L, 2L, 2L, 4L, 1L, 4L, 2L, 2L, 
    1L, 4L, 1L, 4L, 1L, 2L, 4L, 2L, 4L, 1L, 1L, 1L, 1L, 1L, 2L, 
    2L, 4L, 2L, 2L, 4L, 4L, 4L, 2L, 2L, 4L, 2L, 1L, 1L, 2L, 2L, 
    1L, 1L, 4L, 2L, 2L, 2L, 4L, 2L, 2L, 4L, 4L, 2L, 2L, 1L, 1L, 
    2L, 4L, 1L, 2L, 1L, 2L, 1L, 1L, 4L, 4L, 2L, 1L, 2L, 2L, 1L, 
    2L, 4L, 2L, 2L, 4L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 
    1L, 4L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 4L, 2L, 4L, 4L, 4L, 2L, 
    2L, 1L, 2L, 4L, 2L, 4L, 2L, 1L, 2L, 2L, 4L, 4L, 2L, 2L, 4L, 
    4L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 4L, 1L, 1L, 4L, 
    1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 2L, 1L, 2L, 3L, 4L, 1L, 1L, 
    2L, 1L, 1L, 4L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 1L, 2L, 1L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 
    2L, 4L, 2L, 2L, 1L, 2L, 2L, 4L, 2L, 2L, 4L, 2L, 1L, 2L, 2L, 
    4L, 1L, 4L, 4L, 4L, 2L, 4L, 4L, 1L, 4L, 2L, 1L, 1L, 4L, 4L, 
    4L, 2L, 2L, 4L, 4L, 2L, 2L, 1L, 4L, 4L, 4L, 2L, 1L, 4L, 1L, 
    1L, 2L, 2L, 4L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, 1L, 1L, 4L, 
    4L, 2L, 4L, 2L, 2L, 1L, 2L, 4L, 4L, 2L, 1L, 4L, 2L, 2L, 1L, 
    2L, 1L, 4L, 1L, 1L, 1L, 4L, 4L, 1L, 2L, 1L, 1L, 4L, 1L, 1L, 
    4L, 2L, 2L, 2L, 4L, 2L, 4L, 2L, 2L, 1L, 2L, 1L, 4L, 1L, 1L, 
    2L, 2L, 4L, 2L, 2L, 4L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 
    2L, 2L, 2L, 4L, 4L, 2L, 4L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 
    2L, 2L, 2L, 4L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 4L, 2L, 1L, 2L, 
    2L, 1L, 1L, 2L, 4L, 2L, 2L, 2L, 4L, 2L, 2L, 1L, 4L, 1L, 1L, 
    2L, 2L, 4L, 2L, 1L, 2L, 2L, 2L, 1L, 4L, 4L, 4L, 2L, 2L, 1L, 
    2L, 2L, 1L, 4L, 1L, 4L, 2L, 2L, 2L, 2L, 1L, 1L, 4L, 2L, 2L, 
    1L, 1L, 1L, 2L, 1L, 4L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 
    1L, 2L, 2L, 1L, 2L, 4L, 1L, 1L, 1L, 2L, 1L, 4L, 4L, 2L, 2L, 
    2L, 4L, 4L, 1L, 2L, 4L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 4L, 
    1L, 4L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 4L, 2L, 
    4L, 2L, 1L, 4L, 2L, 4L, 4L, 2L, 4L, 2L, 4L, 2L, 1L, 2L, 2L, 
    4L, 2L, 2L, 1L, 1L, 2L, 4L, 2L, 2L, 4L, 2L, 2L, 1L, 4L, 2L, 
    4L, 4L, 2L, 1L, 2L, 2L, 1L, 4L, 2L, 2L, 1L, 2L, 2L, 4L, 1L, 
    2L, 2L, 2L, 4L, 1L, 4L, 1L, 1L, 2L, 2L, 2L, 1L, 4L, 4L, 4L, 
    1L, 2L, 1L, 1L, 4L, 2L, 4L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    1L, 2L, 4L, 2L, 4L, 1L, 2L, 2L, 4L, 2L, 2L, 4L, 4L, 2L, 2L, 
    2L, 2L, 2L, 4L, 2L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 
    1L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 
    2L, 4L, 1L, 2L, 4L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 1L, 4L, 2L, 
    2L, 2L, 1L, 4L, 2L, 1L, 4L, 2L, 2L, 1L, 4L, 1L, 4L, 1L, 4L, 
    1L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 4L, 2L, 1L, 1L, 2L, 2L, 1L, 
    2L, 1L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 1L, 
    2L, 2L, 1L, 4L, 1L, 2L, 4L, 2L, 4L, 2L, 2L, 4L, 2L, 2L, 1L, 
    4L, 1L, 2L, 2L, 2L, 4L, 2L, 2L, 4L, 2L, 2L, 4L, 4L, 1L, 2L, 
    2L, 2L, 1L, 2L, 2L, 4L, 4L, 4L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 
    2L, 2L, 1L, 4L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 4L, 2L, 2L, 4L, 
    1L, 2L, 2L, 1L, 1L, 2L, 1L, 4L, 4L, 4L, 2L, 2L, 2L, 2L, 2L, 
    2L, 4L, 2L, 4L, 1L, 4L, 1L, 4L, 2L, 2L, 1L, 4L, 1L, 1L, 4L, 
    1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 
    2L, 4L, 1L, 1L, 4L, 1L, 4L, 4L, 4L, 2L, 1L, 2L, 4L, 1L, 2L, 
    4L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 1L, 1L, 
    2L, 2L, 4L, 1L, 2L, 1L, 1L, 2L, 4L, 2L, 4L, 2L, 1L, 2L, 2L, 
    1L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 4L, 2L, 4L, 2L, 2L, 4L, 
    2L, 4L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 4L, 2L, 4L, 2L, 1L, 4L, 
    2L, 4L, 2L, 4L, 2L, 1L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 1L, 
    1L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 4L, 2L, 4L, 2L, 4L, 2L, 2L, 
    2L, 2L, 2L, 1L, 2L, 2L, 4L, 2L, 4L, 4L, 2L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 2L, 4L, 1L, 2L, 1L, 2L, 1L, 4L, 2L, 2L, 2L, 1L, 
    1L, 4L, 2L, 2L, 2L, 1L, 2L, 4L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 
    4L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 2L, 4L, 2L, 1L, 2L, 2L, 
    4L, 4L, 1L, 2L, 1L, 2L, 4L, 2L, 4L, 2L, 1L, 2L, 2L, 2L, 4L, 
    1L, 2L, 4L, 2L, 4L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 2L, 
    2L, 2L, 4L, 2L, 4L, 4L, 2L, 1L, 1L, 4L, 2L, 2L, 1L, 2L, 1L, 
    2L, 4L, 2L, 1L, 4L, 4L, 4L, 4L, 2L, 4L, 4L, 2L, 2L, 1L, 1L, 
    4L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 4L, 2L, 4L, 4L, 4L, 2L, 4L, 
    1L, 2L, 2L, 1L, 4L, 2L, 4L, 2L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 
    2L, 4L, 1L, 4L, 1L, 4L, 2L, 1L, 4L, 4L, 1L, 4L, 2L, 2L, 2L, 
    2L, 1L, 4L, 2L, 4L, 1L, 2L, 2L, 4L, 1L, 1L, 2L, 1L, 2L, 2L, 
    2L, 2L, 4L, 1L, 1L, 1L, 4L, 1L, 2L, 4L, 1L, 2L, 2L, 1L, 1L, 
    2L, 4L, 4L, 4L, 4L, 1L, 1L, 2L, 2L, 2L, 4L, 1L, 2L, 2L, 1L, 
    4L, 2L, 1L, 2L, 2L, 1L, 1L, 4L, 1L, 4L, 2L, 1L, 1L, 2L, 2L, 
    1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 4L, 2L, 1L, 
    2L, 2L, 1L, 2L, 2L, 1L, 1L, 4L, 4L, 1L, 2L, 2L, 1L, 2L, 4L, 
    1L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 2L, 1L, 
    4L, 1L, 4L, 1L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 
    1L, 2L, 2L, 2L, 1L, 4L, 2L, 1L, 2L, 2L, 2L, 1L, 4L, 1L, 1L, 
    2L, 1L, 1L, 2L, 2L, 1L, 4L, 2L, 4L, 1L, 2L, 1L, 2L, 4L, 2L, 
    1L, 4L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 4L, 2L, 1L, 2L, 2L, 
    2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 4L, 2L, 2L, 1L, 1L, 1L, 4L, 
    4L, 2L, 2L, 1L, 2L, 2L, 4L, 4L, 2L, 1L, 4L, 2L, 2L, 1L, 2L, 
    1L, 2L, 1L, 1L, 1L, 4L, 4L, 4L, 2L, 2L, 2L, 1L, 4L, 4L, 2L, 
    4L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 1L, 1L, 
    2L, 2L, 4L, 2L, 2L, 4L, 4L, 2L, 1L, 1L, 2L, 4L, 4L, 2L, 4L, 
    4L, 2L, 1L, 4L, 4L, 4L, 4L, 2L, 4L, 1L, 2L, 2L, 4L, 4L, 2L, 
    1L, 2L, 4L, 2L, 4L, 1L, 2L, 4L, 1L, 2L, 1L, 2L, 2L, 4L, 2L, 
    2L, 2L, 4L, 2L, 1L, 2L, 4L, 2L, 2L, 2L, 1L, 4L, 1L, 4L, 2L, 
    4L, 2L, 4L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 4L, 4L, 2L, 2L, 
    4L, 2L, 4L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 4L, 1L, 4L, 1L, 
    2L, 2L, 2L, 4L, 4L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 
    4L, 2L, 1L, 2L, 4L, 4L, 2L, 2L, 4L, 2L, 2L, 1L, 1L, 2L, 4L, 
    2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 4L, 2L, 1L, 4L, 2L, 2L, 2L, 
    2L, 1L, 4L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 4L, 
    4L, 2L, 4L, 2L, 2L, 4L, 4L, 2L, 2L, 1L, 4L, 1L, 2L, 1L, 2L, 
    4L, 2L, 2L, 4L, 1L, 1L, 4L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 
    2L, 1L, 4L, 2L, 2L, 2L, 1L, 1L, 1L, 4L, 1L, 2L, 1L, 4L, 1L, 
    1L, 2L, 2L, 2L, 4L, 1L, 2L, 2L, 4L, 1L, 2L, 2L, 2L, 4L, 1L, 
    2L, 2L, 2L, 4L, 2L, 2L, 1L, 1L, 4L, 2L, 2L, 2L, 1L, 1L, 2L, 
    2L, 2L, 1L, 2L, 2L, 2L, 2L, 4L, 4L, 2L, 1L, 1L, 2L, 1L, 1L, 
    2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 4L, 1L, 2L, 1L, 2L, 
    1L, 2L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 4L, 2L, 4L, 2L, 
    4L, 4L, 4L, 2L, 2L, 4L, 1L, 4L, 4L, 1L, 2L, 2L, 1L, 1L, 1L, 
    2L, 2L, 1L, 4L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 4L, 4L, 1L, 2L, 
    1L, 2L, 2L, 4L, 1L, 1L, 1L, 2L, 4L, 2L, 2L, 4L, 2L, 1L, 1L, 
    2L, 4L, 2L, 1L, 2L, 4L, 4L, 4L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 
    4L, 4L, 2L), .Label = c("high", "medium", "no", "none"), class = "factor"), 
    case_status = structure(c(1L, 5L, 2L, 5L, 5L, 5L, 5L, 5L, 
    7L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 2L, 2L, 5L, 7L, 5L, 5L, 7L, 
    3L, 5L, 5L, 5L, 3L, 5L, 5L, 5L, 5L, 5L, 3L, 7L, 5L, 5L, 7L, 
    5L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 7L, 5L, 7L, 5L, 5L, 9L, 
    5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 2L, 5L, 5L, 5L, 7L, 2L, 
    7L, 5L, 7L, 7L, 5L, 5L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 7L, 5L, 5L, 5L, 5L, 3L, 7L, 5L, 5L, 5L, 3L, 5L, 3L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 3L, 5L, 2L, 5L, 
    2L, 5L, 7L, 2L, 5L, 1L, 5L, 7L, 5L, 5L, 3L, 5L, 5L, 5L, 3L, 
    7L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 7L, 7L, 7L, 7L, 5L, 7L, 
    5L, 5L, 5L, 3L, 5L, 5L, 5L, 7L, 5L, 5L, 2L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 7L, 5L, 7L, 7L, 5L, 3L, 
    3L, 7L, 5L, 9L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    7L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 1L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 3L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 3L, 5L, 5L, 5L, 3L, 5L, 5L, 5L, 2L, 5L, 5L, 5L, 
    3L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 7L, 
    5L, 2L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 2L, 5L, 5L, 
    5L, 3L, 5L, 5L, 5L, 1L, 5L, 5L, 5L, 7L, 9L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 7L, 3L, 5L, 5L, 7L, 5L, 5L, 5L, 2L, 5L, 5L, 5L, 
    5L, 7L, 5L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 7L, 5L, 7L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 3L, 5L, 3L, 5L, 5L, 7L, 7L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 3L, 7L, 5L, 5L, 5L, 5L, 5L, 3L, 5L, 
    9L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 3L, 5L, 5L, 5L, 7L, 5L, 
    3L, 5L, 5L, 5L, 5L, 5L, 1L, 5L, 5L, 5L, 5L, 3L, 5L, 5L, 5L, 
    3L, 1L, 5L, 5L, 5L, 3L, 5L, 1L, 7L, 5L, 5L, 7L, 7L, 5L, 5L, 
    5L, 5L, 5L, 3L, 5L, 5L, 3L, 5L, 5L, 5L, 3L, 5L, 5L, 7L, 5L, 
    5L, 5L, 5L, 5L, 2L, 5L, 5L, 7L, 7L, 7L, 7L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 7L, 5L, 1L, 5L, 5L, 7L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 3L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 2L, 3L, 5L, 
    5L, 5L, 2L, 7L, 5L, 5L, 5L, 5L, 3L, 5L, 5L, 7L, 5L, 2L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 3L, 5L, 5L, 5L, 
    5L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 3L, 
    9L, 5L, 5L, 5L, 3L, 5L, 5L, 5L, 5L, 1L, 5L, 5L, 5L, 5L, 1L, 
    5L, 3L, 5L, 5L, 9L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 1L, 5L, 
    5L, 5L, 5L, 5L, 7L, 5L, 5L, 9L, 5L, 2L, 5L, 3L, 5L, 7L, 7L, 
    5L, 3L, 5L, 5L, 5L, 7L, 5L, 7L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 2L, 3L, 5L, 7L, 5L, 7L, 7L, 1L, 3L, 5L, 5L, 3L, 5L, 
    5L, 5L, 5L, 5L, 3L, 5L, 5L, 5L, 5L, 7L, 2L, 7L, 3L, 5L, 5L, 
    7L, 3L, 5L, 1L, 3L, 7L, 5L, 5L, 3L, 5L, 5L, 7L, 1L, 5L, 5L, 
    5L, 7L, 7L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 9L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 
    7L, 7L, 5L, 7L, 7L, 5L, 5L, 5L, 5L, 5L, 7L, 7L, 7L, 3L, 2L, 
    5L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 3L, 5L, 5L, 5L, 5L, 5L, 
    3L, 5L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 7L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 
    3L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 7L, 7L, 5L, 7L, 
    7L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 7L, 5L, 5L, 3L, 5L, 5L, 
    5L, 5L, 3L, 5L, 5L, 5L, 5L, 9L, 5L, 3L, 7L, 5L, 5L, 5L, 5L, 
    5L, 7L, 7L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 1L, 5L, 5L, 2L, 2L, 
    9L, 5L, 3L, 5L, 5L, 5L, 1L, 5L, 5L, 3L, 5L, 3L, 5L, 5L, 3L, 
    5L, 9L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 1L, 
    5L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 3L, 2L, 7L, 7L, 5L, 
    7L, 5L, 5L, 5L, 5L, 5L, 3L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 3L, 5L, 5L, 5L, 5L, 7L, 5L, 7L, 5L, 5L, 
    5L, 5L, 5L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 3L, 5L, 5L, 1L, 
    5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 7L, 7L, 3L, 5L, 7L, 
    5L, 5L, 5L, 5L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 1L, 5L, 7L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 3L, 7L, 5L, 3L, 9L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 7L, 5L, 7L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 7L, 7L, 5L, 
    5L, 1L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 3L, 7L, 
    5L, 7L, 5L, 3L, 7L, 5L, 5L, 5L, 7L, 5L, 3L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 3L, 3L, 5L, 5L, 3L, 1L, 
    5L, 7L, 5L, 5L, 5L, 5L, 5L, 3L, 5L, 7L, 5L, 5L, 1L, 2L, 7L, 
    5L, 5L, 5L, 3L, 3L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 7L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 3L, 1L, 3L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 
    5L, 5L, 5L, 7L, 3L, 1L, 3L, 5L, 5L, 7L, 3L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 1L, 9L, 5L, 7L, 5L, 5L, 2L, 5L, 3L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 3L, 5L, 7L, 
    7L, 5L, 7L, 5L, 5L, 5L, 7L, 7L, 3L, 7L, 3L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 1L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 
    7L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 3L, 5L, 5L, 5L, 5L, 7L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 7L, 5L, 7L, 5L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    1L, 7L, 5L, 7L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 1L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 2L, 5L, 
    5L, 5L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 3L, 5L, 7L, 5L, 5L, 5L, 3L, 5L, 5L, 5L, 5L, 
    1L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 
    7L, 5L, 5L, 7L, 7L, 7L, 7L, 5L, 5L, 5L, 5L, 5L, 1L, 5L, 1L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 3L, 5L, 7L, 5L, 5L, 5L, 7L, 
    5L, 2L, 5L, 5L, 7L, 5L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 
    7L, 7L, 5L, 5L, 5L, 1L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 3L, 3L, 5L, 5L, 3L, 5L, 
    7L, 7L, 2L, 7L, 7L, 7L, 5L, 5L, 2L, 5L, 2L, 5L, 7L, 5L, 5L, 
    5L, 5L, 5L, 5L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 3L, 7L, 5L, 5L, 
    5L, 5L, 2L, 5L, 7L, 5L, 9L, 5L, 5L, 5L, 5L, 5L, 5L, 3L, 5L, 
    5L, 7L, 7L, 7L, 5L, 7L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 3L, 7L, 5L, 5L, 5L, 
    5L, 5L, 7L, 7L, 7L, 5L, 5L, 7L, 5L, 5L, 7L, 5L, 5L, 3L, 5L, 
    5L, 5L, 1L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 7L, 5L, 
    7L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 3L, 7L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 9L, 
    5L, 5L, 5L, 5L, 5L, 1L, 5L, 5L, 1L, 3L, 5L, 5L, 2L, 5L, 5L, 
    5L, 5L, 7L, 5L, 2L, 5L, 5L, 3L, 5L, 5L, 2L, 7L, 5L, 5L, 5L, 
    5L, 5L, 5L, 3L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 2L, 5L, 5L, 5L, 
    5L, 5L, 3L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 3L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 8L, 5L, 2L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 3L, 5L, 5L, 5L, 3L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 
    5L, 5L, 2L, 3L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 3L, 5L, 5L, 5L, 
    5L, 5L, 5L, 1L, 7L, 3L, 7L, 5L, 5L, 7L, 5L, 5L, 5L, 7L, 5L, 
    7L, 7L, 1L, 5L, 5L, 7L, 5L, 3L, 5L, 5L, 3L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 3L, 5L, 5L, 5L, 7L, 5L, 
    5L, 5L, 5L, 7L, 5L, 3L, 5L, 5L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 7L, 5L, 5L, 5L, 3L, 5L, 5L, 7L, 5L, 7L, 5L, 5L, 3L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 3L, 5L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 
    7L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 3L, 
    5L, 3L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 1L, 2L, 5L, 1L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 3L, 5L, 5L, 1L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 3L, 
    5L, 7L, 5L, 3L, 5L, 5L, 5L, 3L, 5L, 3L, 5L, 5L, 5L, 5L, 5L, 
    5L, 7L, 5L, 5L, 3L, 5L, 2L, 5L, 5L, 5L, 5L, 1L, 5L, 5L, 5L, 
    5L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 2L, 5L, 5L, 5L, 
    5L, 5L, 7L, 7L, 5L, 5L, 5L, 3L, 5L, 3L, 5L, 5L, 1L, 5L, 5L, 
    5L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 3L, 5L, 7L, 5L, 
    7L, 5L, 5L, 5L, 5L, 5L, 5L, 2L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    9L, 5L, 5L, 5L, 5L, 5L, 9L, 5L, 3L, 5L, 5L, 9L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 3L, 3L, 5L, 5L, 5L, 5L, 5L, 3L, 5L, 5L, 7L, 
    9L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 2L, 5L, 
    5L, 5L, 5L, 5L, 3L, 7L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 2L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 2L, 3L), .Label = c("closed", 
    "no resp", "oos", "pending", "Resolved", "routed", "self closed", 
    "Working", "yes"), class = "factor"), account_segment = structure(c(3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 5L, 3L, 10L, 10L, 5L, 11L, 5L, 7L, 10L, 10L, 
    11L, 5L, 9L, 5L, 5L, 9L, 3L, 9L, 9L, 6L, 3L, 9L, 10L, 10L, 
    3L, 5L, 10L, 9L, 3L, 9L, 10L, 9L, 9L, 5L, 5L, 7L, 3L, 5L, 
    6L, 10L, 1L, 3L, 9L, 11L, 3L, 3L, 3L, 5L, 9L, 11L, 1L, 3L, 
    9L, 3L, 5L, 5L, 3L, 3L, 11L, 5L, 5L, 5L, 3L, 10L, 10L, 6L, 
    9L, 5L, 3L, 3L, 2L, 10L, 7L, 5L, 3L, 5L, 10L, 11L, 9L, 10L, 
    10L, 9L, 3L, 3L, 9L, 3L, 3L, 3L, 5L, 7L, 3L, 9L, 11L, 10L, 
    9L, 3L, 9L, 5L, 3L, 3L, 5L, 3L, 5L, 3L, 5L, 11L, 11L, 5L, 
    11L, 10L, 10L, 3L, 3L, 5L, 3L, 11L, 10L, 3L, 10L, 10L, 7L, 
    5L, 10L, 5L, 5L, 11L, 9L, 5L, 5L, 11L, 5L, 5L, 5L, 10L, 3L, 
    11L, 10L, 9L, 5L, 3L, 5L, 10L, 10L, 10L, 3L, 11L, 11L, 5L, 
    3L, 3L, 5L, 10L, 10L, 3L, 11L, 3L, 10L, 9L, 10L, 3L, 10L, 
    11L, 10L, 5L, 10L, 10L, 3L, 10L, 11L, 3L, 5L, 1L, 3L, 9L, 
    11L, 11L, 5L, 9L, 10L, 3L, 10L, 5L, 10L, 11L, 10L, 5L, 5L, 
    3L, 3L, 1L, 10L, 3L, 11L, 2L, 3L, 3L, 5L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 7L, 10L, 9L, 10L, 5L, 9L, 3L, 10L, 3L, 10L, 3L, 
    5L, 3L, 3L, 3L, 10L, 5L, 3L, 5L, 5L, 3L, 10L, 10L, 10L, 10L, 
    9L, 5L, 5L, 3L, 3L, 9L, 7L, 3L, 5L, 9L, 10L, 9L, 5L, 10L, 
    10L, 3L, 3L, 3L, 10L, 3L, 10L, 3L, 3L, 3L, 9L, 9L, 10L, 11L, 
    9L, 10L, 10L, 3L, 5L, 3L, 10L, 3L, 11L, 5L, 2L, 3L, 10L, 
    5L, 10L, 11L, 3L, 3L, 11L, 10L, 10L, 5L, 9L, 10L, 10L, 3L, 
    10L, 3L, 3L, 5L, 10L, 10L, 9L, 2L, 10L, 3L, 3L, 3L, 10L, 
    10L, 3L, 3L, 10L, 10L, 3L, 10L, 3L, 10L, 10L, 3L, 10L, 10L, 
    10L, 5L, 9L, 10L, 3L, 10L, 3L, 10L, 9L, 3L, 10L, 10L, 10L, 
    5L, 5L, 9L, 3L, 3L, 10L, 3L, 5L, 10L, 2L, 9L, 3L, 10L, 3L, 
    10L, 3L, 3L, 9L, 10L, 3L, 10L, 9L, 9L, 5L, 3L, 11L, 10L, 
    9L, 3L, 5L, 5L, 3L, 5L, 3L, 5L, 3L, 10L, 9L, 10L, 10L, 5L, 
    3L, 5L, 5L, 2L, 3L, 10L, 3L, 11L, 3L, 9L, 3L, 7L, 3L, 2L, 
    3L, 8L, 9L, 5L, 5L, 3L, 11L, 3L, 1L, 10L, 9L, 11L, 5L, 9L, 
    9L, 11L, 3L, 3L, 10L, 5L, 9L, 5L, 10L, 11L, 3L, 3L, 10L, 
    3L, 7L, 5L, 11L, 5L, 3L, 3L, 10L, 10L, 3L, 9L, 10L, 9L, 3L, 
    1L, 10L, 9L, 3L, 9L, 3L, 11L, 5L, 5L, 5L, 11L, 5L, 3L, 10L, 
    10L, 3L, 11L, 2L, 10L, 10L, 10L, 5L, 3L, 11L, 11L, 5L, 6L, 
    10L, 3L, 3L, 10L, 2L, 5L, 9L, 11L, 7L, 9L, 1L, 11L, 10L, 
    5L, 9L, 11L, 9L, 9L, 5L, 5L, 5L, 3L, 3L, 9L, 3L, 3L, 2L, 
    9L, 5L, 9L, 5L, 5L, 5L, 5L, 5L, 10L, 10L, 3L, 3L, 3L, 11L, 
    3L, 3L, 3L, 6L, 3L, 10L, 3L, 9L, 5L, 10L, 5L, 7L, 9L, 5L, 
    10L, 9L, 1L, 11L, 3L, 3L, 5L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    9L, 5L, 9L, 5L, 5L, 10L, 3L, 10L, 3L, 3L, 3L, 3L, 10L, 5L, 
    3L, 10L, 9L, 10L, 10L, 9L, 10L, 3L, 3L, 11L, 7L, 9L, 9L, 
    10L, 3L, 3L, 3L, 3L, 5L, 3L, 10L, 2L, 10L, 3L, 3L, 3L, 3L, 
    5L, 10L, 5L, 10L, 11L, 11L, 10L, 5L, 9L, 11L, 3L, 5L, 10L, 
    10L, 10L, 3L, 5L, 10L, 9L, 5L, 9L, 3L, 10L, 3L, 3L, 7L, 3L, 
    10L, 3L, 11L, 9L, 10L, 10L, 9L, 10L, 5L, 3L, 5L, 10L, 3L, 
    9L, 10L, 10L, 5L, 9L, 3L, 5L, 3L, 3L, 11L, 3L, 3L, 10L, 9L, 
    7L, 5L, 10L, 3L, 3L, 5L, 3L, 9L, 10L, 3L, 3L, 3L, 5L, 3L, 
    3L, 10L, 3L, 5L, 5L, 2L, 3L, 11L, 10L, 7L, 3L, 10L, 10L, 
    3L, 11L, 5L, 10L, 5L, 5L, 5L, 11L, 9L, 9L, 9L, 9L, 5L, 10L, 
    3L, 10L, 11L, 3L, 11L, 11L, 9L, 3L, 6L, 2L, 3L, 3L, 10L, 
    3L, 5L, 3L, 3L, 5L, 9L, 5L, 11L, 9L, 10L, 9L, 3L, 5L, 10L, 
    9L, 5L, 3L, 3L, 3L, 2L, 10L, 3L, 3L, 3L, 11L, 11L, 3L, 5L, 
    6L, 9L, 3L, 5L, 10L, 3L, 10L, 3L, 3L, 3L, 11L, 7L, 3L, 9L, 
    11L, 5L, 10L, 10L, 11L, 11L, 3L, 1L, 9L, 3L, 5L, 5L, 10L, 
    11L, 3L, 10L, 5L, 3L, 3L, 5L, 7L, 11L, 5L, 3L, 3L, 3L, 3L, 
    5L, 3L, 9L, 3L, 10L, 3L, 10L, 3L, 5L, 10L, 3L, 3L, 9L, 5L, 
    9L, 9L, 9L, 9L, 5L, 3L, 5L, 7L, 9L, 3L, 10L, 11L, 3L, 9L, 
    3L, 9L, 7L, 3L, 3L, 3L, 9L, 11L, 3L, 9L, 11L, 5L, 5L, 9L, 
    9L, 3L, 11L, 5L, 9L, 9L, 9L, 5L, 10L, 9L, 5L, 3L, 3L, 5L, 
    3L, 3L, 10L, 9L, 2L, 9L, 10L, 3L, 5L, 11L, 5L, 5L, 9L, 9L, 
    10L, 3L, 11L, 10L, 11L, 7L, 11L, 9L, 3L, 3L, 7L, 10L, 11L, 
    3L, 9L, 3L, 9L, 1L, 5L, 9L, 3L, 9L, 10L, 5L, 3L, 11L, 3L, 
    3L, 10L, 9L, 10L, 10L, 5L, 10L, 10L, 5L, 5L, 10L, 3L, 3L, 
    10L, 10L, 5L, 10L, 3L, 3L, 9L, 9L, 10L, 3L, 11L, 3L, 10L, 
    3L, 3L, 10L, 3L, 9L, 10L, 9L, 10L, 5L, 5L, 7L, 5L, 5L, 2L, 
    3L, 3L, 10L, 3L, 10L, 5L, 11L, 7L, 5L, 10L, 9L, 3L, 3L, 10L, 
    10L, 3L, 5L, 3L, 5L, 5L, 3L, 5L, 9L, 10L, 10L, 3L, 11L, 3L, 
    10L, 3L, 11L, 10L, 9L, 9L, 3L, 10L, 3L, 5L, 10L, 5L, 10L, 
    3L, 3L, 11L, 3L, 3L, 3L, 3L, 9L, 3L, 5L, 5L, 6L, 9L, 11L, 
    10L, 11L, 10L, 9L, 10L, 11L, 9L, 5L, 3L, 3L, 5L, 5L, 11L, 
    5L, 5L, 5L, 10L, 5L, 3L), .Label = c("-", "Flagship", "Large", 
    "Low", "Medium", "Mega", "N/A", "Platinum", "Small", "Top", 
    "Very Small"), class = "factor"), sla_status = structure(c(1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 4L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 4L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("Met", "Missed", "N/A", "Pending"
    ), class = "factor")), .Names = c("support_cat", "region", 
"support_lvl", "skill_group", "application_area", "functional_area", 
"score", "rep_score", "product_know", "understanding_issue", 
"case_age", "severity_level", "case_status", "account_segment", 
"sla_status"), row.names = c(NA, 2000L), class = "data.frame")

From shivipmp82 at gmail.com  Fri Aug 12 20:32:09 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Sat, 13 Aug 2016 00:02:09 +0530
Subject: [R] glm.fit: fitted probabilities numerically 0 or 1 occurred &
 glm.fit: algorithm did not converge
In-Reply-To: <d8c87fd4-a8c8-5640-490d-3a8d28d9b671@dewey.myzen.co.uk>
References: <CAB=p7SreQJRULZ-j3mDmJk5vWAMRaM1b66WYy5k9Kd=sWD3rDQ@mail.gmail.com>
	<7a804ec9-ea4f-8c83-1104-01f3f7959b99@dewey.myzen.co.uk>
	<CAB=p7SoRxiW4EQvAr3K2aGXBknMu_Y7xoFbdefrJfS=jRfmdug@mail.gmail.com>
	<CAGxFJbSW3YrXuOHHS-t_05VzeetWLNbaH_cfVe76_cgR-UrRcA@mail.gmail.com>
	<CAB=p7Sq2zV4PaNVXwZbQCbzVjfLL9We-zSixxzpr_c52aYYKhQ@mail.gmail.com>
	<CAB=p7SrfaKJ43ZXew4SnkOFcv+PGRqi6ZowROm_s7W+mvZUD=g@mail.gmail.com>
	<d8c87fd4-a8c8-5640-490d-3a8d28d9b671@dewey.myzen.co.uk>
Message-ID: <CAB=p7So=nDpoDHB7KoC8SM3+LfBUJ5=XnYV7iOdH9wjCTYyKAQ@mail.gmail.com>

Hi Michael,

In all the masking process some of the variables were missed. Please find
the updated file.

Also here is the updated code: (i am removed one of the var as it had
missing information):

glm.fit= glm(survey ~ support_cat + region+ support_lvl+ skill_group+
application_area+ functional_area+
          repS+ case_age+ case_status+ severity_level+
          sla_status, data = new, family = binomial)

Kindly assist with the same.

On Fri, Aug 12, 2016 at 11:05 PM, Michael Dewey <lists at dewey.myzen.co.uk>
wrote:

> Your example code refers to a variable which is not in your dataset (repS)
> so I get an error message. If I assume repS is in fact rep_score I get
> another variable not found (delivery_segmentation).
>
> I am afraid that I am unable to sort that one out so this is going to
> remain a mystery. I endorse Bert's suggestion of getting local help.
>
> On 12/08/2016 17:24, Shivi Bhatia wrote:
>
>> Hi Bert,
>>
>> Does this text file help. Apologies if this does not help as i have a
>> hard time on many occasions to get a reproducible example.
>>
>> If this doesn't work a CSV with only 100kb of data i can share.
>>
>> Regards, Shivi
>>
>> On Fri, Aug 12, 2016 at 8:50 PM, Shivi Bhatia <shivipmp82 at gmail.com
>> <mailto:shivipmp82 at gmail.com>> wrote:
>>
>>     Sure Burt, i will share the data after masking it.  it isn't big
>>
>>     regards, Shivi
>>
>>     On Fri, Aug 12, 2016 at 8:36 PM, Bert Gunter <bgunter.4567 at gmail.com
>>     <mailto:bgunter.4567 at gmail.com>> wrote:
>>
>>         1. No, changing to factor will make no difference.
>>
>>         2. I think that most likely your problem is your model is not
>>         estimable/your design matrix is singular.  You should resolve
>>         this by
>>         consulting with a local statistical expert or, if your data set
>>         is not
>>         too large or confidential, posting your full dataset using
>>         dput() (see
>>         ?dput for how to do this).
>>
>>         Cheers,
>>         Bert
>>         Bert Gunter
>>
>>         "The trouble with having an open mind is that people keep coming
>>         along
>>         and sticking things into it."
>>         -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>>         On Fri, Aug 12, 2016 at 7:58 AM, Shivi Bhatia
>>         <shivipmp82 at gmail.com <mailto:shivipmp82 at gmail.com>> wrote:
>>         > Hi Michael,
>>         >
>>         > There is no output as the model does not generate any
>>         coefficients and
>>         > simply throws this error.
>>         >
>>         > I hope you are not asking for a reproducible example.
>>         >
>>         > On Fri, Aug 12, 2016 at 7:30 PM, Michael Dewey
>>         <lists at dewey.myzen.co.uk <mailto:lists at dewey.myzen.co.uk>>
>>
>>         > wrote:
>>         >
>>         >> Dear Shivi
>>         >>
>>         >> Can you show us the output?
>>         >>
>>         >> And please do not post in HTML as it will mangle your post into
>>         >> unreadability.
>>         >>
>>         >> On 12/08/2016 10:10, Shivi Bhatia wrote:
>>         >>
>>         >>> Hi Team,
>>         >>>
>>         >>> I am creating *my first* Logistic regression on R Studio. I
>>         am working on
>>         >>> a
>>         >>>
>>         >>> C-SAT data where rating (score) 0-8 is a dis-sat whereas
>>         9-10 are SAT. As
>>         >>> these were in numeric form so i had as below created 2
>> classes:
>>         >>>
>>         >>> new$survey[new$score>=0 & new$score<=8]<- 0
>>         >>> new$survey[new$score>=9]<- 1
>>         >>> This works fine however the class still shows as "numeric"
>>         and levels
>>         >>> shows
>>         >>> as "NULL". Do i still need to use "as.factor" to let R know
>>         these are
>>         >>> categorical variables.
>>         >>>
>>         >>> Also i have used the below code to run a logistic regression
>>         with all the
>>         >>> possible predictor variables:
>>         >>> glm.fit= glm(survey ~ support_cat + region+ support_lvl+
>>         skill_group+
>>         >>> application_area+ functional_area+
>>         >>>           repS+ case_age+ case_status+ severity_level+
>>         >>>           sla_status+ delivery_segmentation, data = SFDC,
>>         family =
>>         >>> binomial)
>>         >>>
>>         >>> But it throws an error:-
>>         >>> Warning messages:
>>         >>> 1: glm.fit: algorithm did not converge
>>         >>> 2: glm.fit: fitted probabilities numerically 0 or 1 occurred
>>         >>>
>>         >>> I checked online for the error and it says:
>>         >>> "glm() uses an iterative re-weighted least squares
>>         algorithm. The
>>         >>> algorithm
>>         >>> hit the maximum number of allowed iterations before signalling
>>         >>> convergence.
>>         >>> The default,
>>         >>> documented in ?glm.control is 25."
>>         >>>
>>         >>> Kindly suggest on the above case and if i have to change my
>>         outcome var as
>>         >>> as.factor.
>>         >>>
>>         >>> Thank you, Shivi
>>         >>>
>>         >>>         [[alternative HTML version deleted]]
>>         >>>
>>         >>> ______________________________________________
>>         >>> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>         list -- To UNSUBSCRIBE and more, see
>>         >>> https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>         >>> PLEASE do read the posting guide
>> http://www.R-project.org/posti
>>         >>> ng-guide.html
>>         >>> and provide commented, minimal, self-contained, reproducible
>>         code.
>>         >>>
>>         >>>
>>         >> --
>>         >> Michael
>>         >> http://www.dewey.myzen.co.uk/home.html
>>         <http://www.dewey.myzen.co.uk/home.html>
>>         >>
>>         >
>>         >         [[alternative HTML version deleted]]
>>         >
>>         > ______________________________________________
>>         > R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>         list -- To UNSUBSCRIBE and more, see
>>         > https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>         > PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>         > and provide commented, minimal, self-contained, reproducible
>> code.
>>
>>
>>
>>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
-------------- next part --------------
structure(list(support_cat = structure(c(2L, 3L, 4L, 3L, 5L, 
6L, 6L, 4L, 6L, 3L, 4L, 7L, 6L, 3L, 3L, 6L, 3L, 3L, 3L, 3L, 3L, 
3L, 8L, 3L, 8L, 3L, 3L, 3L, 3L, 3L, 3L, 8L, 3L, 6L, 8L, 8L, 3L, 
3L, 3L, 5L, 3L, 3L, 8L, 8L, 3L, 3L, 9L, 10L, 6L, 3L, 3L, 6L, 
5L, 3L, 3L, 8L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 8L, 8L, 3L, 9L, 9L, 
10L, 10L, 6L, 10L, 6L, 5L, 6L, 6L, 3L, 3L, 6L, 6L, 3L, 6L, 3L, 
3L, 3L, 8L, 3L, 3L, 11L, 8L, 6L, 8L, 3L, 3L, 3L, 3L, 4L, 3L, 
4L, 10L, 6L, 8L, 3L, 3L, 3L, 6L, 8L, 8L, 3L, 3L, 3L, 3L, 3L, 
3L, 8L, 3L, 8L, 3L, 3L, 2L, 3L, 5L, 3L, 5L, 3L, 3L, 3L, 3L, 6L, 
3L, 10L, 6L, 3L, 6L, 6L, 3L, 8L, 6L, 3L, 5L, 3L, 8L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 10L, 3L, 9L, 9L, 9L, 9L, 6L, 10L, 6L, 
6L, 3L, 6L, 3L, 3L, 8L, 3L, 3L, 5L, 6L, 3L, 3L, 3L, 3L, 11L, 
6L, 8L, 3L, 2L, 3L, 10L, 9L, 10L, 10L, 3L, 10L, 10L, 8L, 6L, 
6L, 10L, 6L, 8L, 3L, 8L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
9L, 8L, 3L, 4L, 10L, 6L, 9L, 3L, 3L, 12L, 4L, 6L, 3L, 5L, 3L, 
3L, 3L, 3L, 3L, 10L, 3L, 10L, 4L, 9L, 9L, 3L, 3L, 3L, 6L, 6L, 
3L, 3L, 6L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 5L, 3L, 3L, 8L, 
3L, 3L, 4L, 8L, 3L, 4L, 10L, 4L, 4L, 10L, 8L, 3L, 4L, 3L, 3L, 
6L, 6L, 3L, 8L, 3L, 6L, 3L, 3L, 3L, 6L, 3L, 7L, 3L, 3L, 3L, 3L, 
5L, 3L, 3L, 3L, 3L, 3L, 3L, 8L, 3L, 6L, 3L, 3L, 3L, 3L, 10L, 
4L, 8L, 11L, 3L, 11L, 10L, 8L, 3L, 10L, 6L, 3L, 3L, 3L, 3L, 3L, 
5L, 3L, 3L, 3L, 3L, 3L, 3L, 6L, 3L, 3L, 3L, 3L, 5L, 3L, 3L, 4L, 
6L, 3L, 4L, 10L, 9L, 3L, 10L, 8L, 13L, 6L, 6L, 8L, 8L, 6L, 11L, 
3L, 8L, 3L, 3L, 8L, 8L, 3L, 3L, 3L, 3L, 3L, 8L, 2L, 3L, 3L, 10L, 
3L, 10L, 10L, 8L, 10L, 8L, 9L, 3L, 6L, 9L, 3L, 6L, 6L, 6L, 6L, 
3L, 6L, 3L, 8L, 3L, 3L, 6L, 8L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 10L, 9L, 3L, 3L, 11L, 9L, 6L, 8L, 3L, 6L, 6L, 11L, 3L, 3L, 
6L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 6L, 11L, 3L, 11L, 3L, 4L, 
4L, 4L, 3L, 4L, 3L, 6L, 6L, 3L, 3L, 6L, 3L, 3L, 3L, 8L, 3L, 3L, 
3L, 3L, 5L, 3L, 3L, 3L, 14L, 11L, 8L, 3L, 3L, 3L, 3L, 4L, 3L, 
8L, 10L, 10L, 10L, 6L, 10L, 11L, 2L, 6L, 3L, 6L, 3L, 6L, 14L, 
8L, 3L, 3L, 3L, 8L, 3L, 3L, 3L, 8L, 3L, 3L, 3L, 2L, 10L, 10L, 
10L, 10L, 10L, 9L, 9L, 6L, 4L, 3L, 3L, 3L, 5L, 3L, 3L, 6L, 3L, 
3L, 3L, 3L, 3L, 3L, 6L, 3L, 3L, 3L, 3L, 3L, 4L, 6L, 8L, 3L, 4L, 
4L, 6L, 3L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 4L, 3L, 4L, 9L, 6L, 6L, 
6L, 3L, 6L, 3L, 4L, 10L, 3L, 3L, 8L, 4L, 2L, 10L, 10L, 8L, 3L, 
4L, 6L, 3L, 3L, 4L, 6L, 3L, 6L, 6L, 6L, 6L, 3L, 3L, 6L, 6L, 3L, 
7L, 2L, 7L, 6L, 3L, 3L, 5L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 2L, 
3L, 3L, 4L, 4L, 4L, 6L, 11L, 6L, 8L, 12L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 4L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 3L, 6L, 10L, 3L, 
3L, 8L, 6L, 3L, 12L, 6L, 3L, 3L, 3L, 3L, 3L, 3L, 10L, 3L, 7L, 
9L, 9L, 10L, 3L, 9L, 9L, 7L, 6L, 8L, 6L, 6L, 6L, 3L, 3L, 6L, 
6L, 3L, 3L, 3L, 15L, 8L, 3L, 3L, 8L, 3L, 3L, 10L, 4L, 10L, 10L, 
6L, 6L, 6L, 6L, 3L, 8L, 6L, 13L, 3L, 3L, 3L, 3L, 6L, 6L, 3L, 
10L, 10L, 9L, 3L, 6L, 6L, 10L, 3L, 8L, 6L, 3L, 11L, 3L, 6L, 3L, 
3L, 3L, 11L, 3L, 3L, 3L, 8L, 10L, 4L, 4L, 4L, 6L, 3L, 8L, 8L, 
6L, 6L, 6L, 5L, 3L, 3L, 3L, 3L, 3L, 4L, 5L, 3L, 6L, 3L, 3L, 8L, 
4L, 3L, 4L, 10L, 4L, 10L, 10L, 10L, 10L, 10L, 3L, 3L, 3L, 8L, 
3L, 10L, 10L, 10L, 6L, 10L, 6L, 3L, 3L, 3L, 8L, 3L, 3L, 3L, 3L, 
10L, 3L, 3L, 11L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 8L, 
2L, 9L, 10L, 3L, 3L, 8L, 8L, 4L, 3L, 3L, 5L, 6L, 3L, 6L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 8L, 3L, 3L, 3L, 4L, 8L, 3L, 8L, 3L, 10L, 
3L, 4L, 10L, 3L, 9L, 9L, 10L, 6L, 6L, 6L, 3L, 6L, 8L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 5L, 3L, 3L, 3L, 3L, 3L, 3L, 5L, 
3L, 3L, 3L, 4L, 11L, 10L, 9L, 10L, 10L, 5L, 4L, 10L, 10L, 3L, 
8L, 3L, 3L, 3L, 6L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 6L, 6L, 10L, 5L, 
2L, 5L, 6L, 3L, 3L, 3L, 3L, 3L, 6L, 3L, 3L, 3L, 3L, 5L, 3L, 10L, 
10L, 10L, 6L, 10L, 3L, 10L, 11L, 3L, 6L, 6L, 3L, 2L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 5L, 8L, 10L, 10L, 4L, 4L, 4L, 3L, 10L, 
3L, 10L, 6L, 6L, 5L, 3L, 3L, 3L, 3L, 11L, 6L, 3L, 3L, 3L, 8L, 
3L, 3L, 3L, 3L, 15L, 3L, 3L, 3L, 3L, 3L, 11L, 3L, 11L, 3L, 10L, 
10L, 4L, 6L, 3L, 3L, 3L, 3L, 3L, 3L, 6L, 3L, 6L, 6L, 3L, 3L, 
3L, 6L, 3L, 3L, 8L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 5L, 
6L, 4L, 8L, 3L, 3L, 3L, 3L, 6L, 3L, 3L, 3L, 11L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 10L, 4L, 10L, 4L, 
9L, 9L, 4L, 10L, 6L), .Label = c("", "a", "b", "c", "d", "e", 
"f", "g", "h", "i", "j", "k", "l", "m", "n", "o", "p", "q"), class = "factor"), 
    region = structure(c(2L, 3L, 4L, 3L, 3L, 5L, 5L, 4L, 5L, 
    3L, 4L, 5L, 5L, 3L, 3L, 5L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 3L, 
    2L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 3L, 5L, 2L, 2L, 3L, 3L, 3L, 
    2L, 3L, 3L, 2L, 2L, 3L, 3L, 6L, 6L, 5L, 3L, 3L, 5L, 2L, 3L, 
    3L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 6L, 6L, 6L, 
    6L, 5L, 6L, 5L, 5L, 5L, 5L, 3L, 3L, 5L, 5L, 3L, 5L, 3L, 3L, 
    3L, 2L, 3L, 3L, 2L, 2L, 5L, 2L, 3L, 3L, 3L, 3L, 4L, 3L, 4L, 
    6L, 5L, 2L, 3L, 3L, 3L, 5L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 
    2L, 3L, 2L, 3L, 3L, 2L, 3L, 2L, 3L, 2L, 3L, 3L, 3L, 3L, 5L, 
    3L, 6L, 5L, 3L, 5L, 5L, 3L, 2L, 5L, 3L, 2L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 6L, 3L, 6L, 6L, 6L, 6L, 5L, 6L, 5L, 
    5L, 3L, 5L, 3L, 3L, 2L, 3L, 3L, 2L, 5L, 3L, 3L, 3L, 3L, 2L, 
    5L, 2L, 3L, 2L, 3L, 6L, 6L, 6L, 6L, 3L, 6L, 6L, 2L, 5L, 5L, 
    6L, 5L, 2L, 3L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 6L, 
    2L, 3L, 4L, 6L, 5L, 6L, 3L, 3L, 2L, 4L, 5L, 3L, 2L, 3L, 3L, 
    3L, 3L, 3L, 6L, 3L, 6L, 4L, 6L, 6L, 3L, 3L, 3L, 5L, 5L, 3L, 
    3L, 5L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 
    3L, 3L, 4L, 3L, 3L, 4L, 6L, 4L, 4L, 6L, 5L, 3L, 4L, 3L, 3L, 
    5L, 5L, 3L, 2L, 3L, 5L, 3L, 3L, 3L, 5L, 3L, 5L, 3L, 3L, 3L, 
    3L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 3L, 5L, 3L, 3L, 3L, 3L, 
    6L, 4L, 2L, 2L, 3L, 2L, 6L, 3L, 3L, 6L, 5L, 3L, 3L, 3L, 3L, 
    3L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 5L, 3L, 3L, 3L, 3L, 2L, 3L, 
    3L, 4L, 5L, 3L, 4L, 6L, 6L, 3L, 6L, 3L, 5L, 5L, 5L, 2L, 2L, 
    5L, 2L, 3L, 2L, 3L, 3L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 2L, 2L, 
    3L, 3L, 6L, 3L, 6L, 6L, 3L, 6L, 3L, 6L, 3L, 5L, 6L, 3L, 5L, 
    5L, 5L, 5L, 3L, 5L, 3L, 2L, 3L, 3L, 5L, 2L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 6L, 6L, 3L, 3L, 2L, 6L, 5L, 3L, 3L, 5L, 
    5L, 5L, 3L, 3L, 5L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 5L, 2L, 
    3L, 2L, 3L, 4L, 4L, 4L, 3L, 4L, 3L, 5L, 5L, 3L, 3L, 5L, 3L, 
    3L, 3L, 2L, 3L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 2L, 2L, 2L, 3L, 
    3L, 3L, 3L, 4L, 3L, 2L, 6L, 6L, 6L, 5L, 6L, 2L, 2L, 5L, 3L, 
    5L, 3L, 5L, 2L, 2L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 2L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 5L, 4L, 3L, 3L, 3L, 2L, 
    3L, 3L, 5L, 3L, 3L, 3L, 3L, 3L, 3L, 5L, 3L, 3L, 3L, 3L, 3L, 
    4L, 5L, 2L, 3L, 4L, 4L, 5L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    4L, 3L, 4L, 6L, 5L, 5L, 5L, 3L, 5L, 3L, 4L, 6L, 3L, 3L, 3L, 
    4L, 2L, 6L, 6L, 2L, 3L, 4L, 5L, 3L, 3L, 4L, 5L, 3L, 5L, 5L, 
    5L, 5L, 3L, 3L, 5L, 5L, 3L, 5L, 2L, 5L, 5L, 3L, 3L, 2L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 2L, 2L, 3L, 3L, 4L, 4L, 4L, 5L, 5L, 
    5L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 3L, 3L, 3L, 3L, 
    4L, 4L, 4L, 4L, 3L, 5L, 6L, 3L, 3L, 2L, 5L, 3L, 2L, 5L, 3L, 
    3L, 3L, 3L, 3L, 3L, 6L, 3L, 2L, 6L, 6L, 6L, 3L, 6L, 6L, 2L, 
    5L, 2L, 5L, 5L, 5L, 3L, 3L, 5L, 5L, 3L, 3L, 3L, 7L, 2L, 3L, 
    3L, 2L, 3L, 3L, 6L, 4L, 6L, 6L, 5L, 5L, 5L, 5L, 3L, 2L, 5L, 
    2L, 3L, 3L, 3L, 3L, 5L, 5L, 3L, 6L, 6L, 6L, 3L, 5L, 5L, 6L, 
    3L, 2L, 5L, 3L, 2L, 3L, 5L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 2L, 
    6L, 4L, 4L, 4L, 5L, 3L, 2L, 2L, 5L, 2L, 5L, 5L, 3L, 3L, 3L, 
    3L, 3L, 4L, 2L, 3L, 5L, 3L, 3L, 2L, 4L, 3L, 4L, 6L, 4L, 6L, 
    6L, 6L, 6L, 6L, 3L, 3L, 3L, 2L, 3L, 6L, 6L, 6L, 5L, 6L, 2L, 
    3L, 3L, 3L, 2L, 3L, 3L, 3L, 3L, 6L, 3L, 3L, 2L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 6L, 6L, 3L, 3L, 3L, 2L, 
    4L, 3L, 3L, 5L, 5L, 3L, 5L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 
    3L, 3L, 3L, 4L, 2L, 3L, 2L, 3L, 6L, 3L, 4L, 6L, 3L, 6L, 6L, 
    6L, 5L, 5L, 5L, 3L, 5L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 4L, 2L, 
    6L, 6L, 6L, 6L, 2L, 4L, 6L, 6L, 3L, 2L, 3L, 3L, 3L, 5L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 4L, 4L, 5L, 5L, 6L, 5L, 2L, 2L, 5L, 3L, 3L, 
    3L, 3L, 3L, 5L, 3L, 3L, 3L, 3L, 2L, 3L, 6L, 6L, 6L, 5L, 6L, 
    3L, 6L, 2L, 3L, 5L, 5L, 3L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 2L, 2L, 6L, 6L, 4L, 4L, 4L, 3L, 6L, 3L, 6L, 5L, 5L, 2L, 
    3L, 3L, 3L, 3L, 2L, 5L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 3L, 2L, 
    3L, 3L, 3L, 3L, 3L, 2L, 3L, 2L, 3L, 6L, 6L, 4L, 5L, 3L, 3L, 
    3L, 3L, 3L, 3L, 5L, 3L, 5L, 5L, 3L, 3L, 3L, 5L, 3L, 3L, 2L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 5L, 5L, 4L, 2L, 3L, 
    3L, 3L, 3L, 5L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 4L, 4L, 6L, 4L, 6L, 4L, 6L, 6L, 4L, 6L, 
    5L), .Label = c("", "a", "b", "c", "d", "e", "f", "g"), class = "factor"), 
    support_lvl = structure(c(3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L), .Label = c("", "basc12", "basic1", "Other"), class = "factor"), 
    skill_group = structure(c(2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 3L, 2L, 3L, 2L, 2L, 2L, 2L, 3L, 3L, 2L, 2L, 2L, 2L, 3L, 
    2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 2L, 2L, 2L, 2L, 3L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 3L, 2L, 2L, 2L, 3L, 2L, 
    2L, 2L, 2L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 
    3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 3L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    3L, 2L, 2L, 3L, 2L, 2L, 2L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 
    3L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    3L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 3L, 2L, 3L, 
    2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 3L, 2L, 3L, 3L, 2L, 2L, 3L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 
    3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 3L, 
    2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 3L, 
    2L, 2L, 2L, 2L, 3L, 2L, 3L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 
    2L, 2L, 2L, 3L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 3L, 2L, 2L, 3L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 
    2L, 3L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 3L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 3L, 3L, 2L, 2L, 3L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 3L, 
    3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 3L, 2L, 
    3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 2L, 3L, 2L, 
    2L, 2L, 2L, 3L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 3L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 3L, 3L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 
    3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 
    3L, 3L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    3L, 3L, 2L, 2L, 2L, 3L, 2L, 3L, 2L, 3L, 3L, 2L, 2L, 2L, 3L, 
    2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 
    2L, 2L, 2L, 2L, 2L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 
    2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 3L, 3L, 2L, 3L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 3L, 3L, 2L, 2L, 2L, 3L, 2L, 2L, 3L, 2L, 2L, 
    2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 
    2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 3L, 3L, 
    2L, 2L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 3L, 2L, 2L, 
    2L, 2L, 2L, 2L, 3L, 3L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 
    3L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 3L, 2L, 2L, 3L, 2L, 3L, 2L, 2L, 2L, 3L, 2L, 3L, 
    3L, 3L, 2L, 2L, 2L, 3L, 2L, 3L, 2L, 3L, 3L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 
    2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 3L, 2L, 3L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 3L, 
    3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 3L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 3L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 3L, 2L, 2L, 2L, 
    3L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 3L, 2L, 2L, 2L, 3L, 3L, 
    2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 3L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 3L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 3L, 3L, 3L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 3L, 2L, 3L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 3L, 2L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 3L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 3L, 2L, 2L, 3L, 2L, 3L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 
    3L, 2L, 2L, 2L, 2L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 3L), .Label = c("", "one", "two"), class = "factor"), 
    application_area = structure(c(2L, 11L, 2L, 8L, 2L, 2L, 2L, 
    3L, 2L, 4L, 3L, 4L, 2L, 8L, 2L, 2L, 4L, 4L, 2L, 3L, 16L, 
    4L, 4L, 8L, 2L, 2L, 4L, 2L, 2L, 2L, 8L, 2L, 2L, 3L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 15L, 2L, 3L, 4L, 4L, 2L, 2L, 
    3L, 3L, 4L, 2L, 2L, 2L, 2L, 2L, 6L, 10L, 4L, 4L, 4L, 10L, 
    3L, 8L, 4L, 2L, 2L, 2L, 14L, 4L, 4L, 2L, 2L, 3L, 2L, 2L, 
    2L, 6L, 2L, 2L, 4L, 4L, 2L, 2L, 10L, 2L, 3L, 2L, 2L, 2L, 
    3L, 2L, 4L, 2L, 2L, 3L, 10L, 2L, 2L, 2L, 4L, 3L, 2L, 4L, 
    2L, 3L, 2L, 2L, 3L, 2L, 3L, 4L, 2L, 2L, 4L, 2L, 2L, 2L, 4L, 
    4L, 3L, 3L, 2L, 16L, 3L, 2L, 4L, 8L, 2L, 4L, 2L, 2L, 2L, 
    3L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 4L, 3L, 2L, 4L, 2L, 2L, 2L, 
    2L, 3L, 2L, 4L, 2L, 4L, 14L, 4L, 2L, 3L, 8L, 4L, 3L, 2L, 
    2L, 2L, 2L, 12L, 2L, 2L, 3L, 2L, 2L, 2L, 4L, 3L, 4L, 4L, 
    2L, 2L, 4L, 2L, 4L, 16L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 
    2L, 2L, 3L, 2L, 11L, 4L, 2L, 2L, 2L, 2L, 4L, 2L, 4L, 2L, 
    3L, 2L, 3L, 2L, 8L, 3L, 4L, 3L, 2L, 2L, 2L, 4L, 3L, 8L, 3L, 
    2L, 4L, 3L, 4L, 10L, 2L, 8L, 2L, 4L, 2L, 2L, 13L, 3L, 2L, 
    2L, 4L, 2L, 2L, 2L, 4L, 13L, 2L, 14L, 4L, 2L, 3L, 4L, 2L, 
    2L, 2L, 2L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 13L, 4L, 2L, 
    2L, 4L, 2L, 3L, 2L, 2L, 4L, 2L, 10L, 10L, 2L, 2L, 2L, 2L, 
    3L, 6L, 3L, 2L, 4L, 2L, 2L, 3L, 4L, 2L, 3L, 6L, 11L, 2L, 
    2L, 2L, 3L, 2L, 2L, 6L, 2L, 3L, 2L, 4L, 2L, 4L, 4L, 2L, 8L, 
    4L, 10L, 2L, 2L, 2L, 3L, 2L, 2L, 4L, 3L, 3L, 2L, 4L, 2L, 
    8L, 2L, 4L, 4L, 4L, 2L, 13L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 
    2L, 2L, 4L, 2L, 4L, 3L, 3L, 2L, 2L, 3L, 2L, 3L, 16L, 13L, 
    4L, 4L, 2L, 4L, 2L, 13L, 2L, 8L, 4L, 2L, 2L, 2L, 4L, 2L, 
    3L, 2L, 2L, 2L, 8L, 3L, 3L, 4L, 2L, 4L, 2L, 15L, 2L, 10L, 
    10L, 2L, 2L, 2L, 3L, 10L, 3L, 8L, 10L, 3L, 3L, 4L, 4L, 2L, 
    16L, 3L, 2L, 4L, 2L, 2L, 2L, 14L, 4L, 2L, 3L, 3L, 3L, 16L, 
    8L, 2L, 4L, 2L, 3L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 4L, 2L, 8L, 
    2L, 2L, 3L, 2L, 2L, 4L, 2L, 2L, 3L, 4L, 4L, 3L, 16L, 8L, 
    3L, 3L, 4L, 3L, 2L, 16L, 7L, 2L, 2L, 2L, 4L, 4L, 3L, 2L, 
    2L, 4L, 2L, 4L, 2L, 4L, 4L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 17L, 
    4L, 2L, 2L, 16L, 3L, 2L, 13L, 2L, 4L, 2L, 2L, 3L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 3L, 3L, 4L, 3L, 2L, 2L, 
    2L, 10L, 4L, 4L, 2L, 2L, 2L, 3L, 8L, 3L, 3L, 4L, 2L, 2L, 
    10L, 4L, 2L, 3L, 3L, 2L, 4L, 4L, 2L, 4L, 2L, 2L, 14L, 2L, 
    2L, 6L, 6L, 4L, 4L, 2L, 2L, 2L, 4L, 3L, 3L, 4L, 3L, 3L, 2L, 
    2L, 2L, 2L, 4L, 2L, 3L, 3L, 3L, 2L, 2L, 2L, 3L, 4L, 2L, 2L, 
    2L, 3L, 4L, 2L, 10L, 2L, 2L, 3L, 4L, 12L, 2L, 3L, 4L, 4L, 
    10L, 3L, 4L, 4L, 2L, 6L, 2L, 2L, 10L, 4L, 3L, 2L, 4L, 8L, 
    8L, 3L, 2L, 2L, 3L, 4L, 4L, 10L, 11L, 2L, 10L, 4L, 2L, 11L, 
    2L, 16L, 4L, 3L, 2L, 3L, 2L, 2L, 3L, 4L, 3L, 2L, 2L, 2L, 
    2L, 3L, 14L, 2L, 2L, 2L, 4L, 2L, 8L, 4L, 2L, 4L, 2L, 2L, 
    2L, 4L, 2L, 4L, 4L, 4L, 2L, 15L, 2L, 4L, 3L, 4L, 2L, 4L, 
    4L, 3L, 2L, 2L, 2L, 8L, 2L, 2L, 2L, 6L, 2L, 3L, 2L, 2L, 15L, 
    10L, 16L, 2L, 4L, 2L, 3L, 4L, 13L, 3L, 2L, 3L, 3L, 3L, 3L, 
    8L, 2L, 4L, 2L, 3L, 2L, 2L, 3L, 2L, 2L, 4L, 15L, 4L, 2L, 
    2L, 4L, 2L, 10L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 
    2L, 8L, 2L, 3L, 2L, 4L, 10L, 2L, 2L, 16L, 12L, 2L, 2L, 2L, 
    2L, 6L, 6L, 4L, 2L, 2L, 2L, 2L, 4L, 4L, 3L, 2L, 2L, 2L, 2L, 
    3L, 2L, 2L, 2L, 2L, 2L, 2L, 10L, 2L, 3L, 10L, 10L, 3L, 2L, 
    10L, 2L, 4L, 2L, 2L, 2L, 3L, 3L, 2L, 3L, 6L, 2L, 2L, 4L, 
    2L, 4L, 15L, 8L, 2L, 2L, 2L, 2L, 4L, 3L, 4L, 8L, 2L, 2L, 
    2L, 3L, 2L, 2L, 2L, 3L, 4L, 2L, 4L, 2L, 2L, 3L, 4L, 2L, 4L, 
    2L, 2L, 2L, 3L, 8L, 8L, 2L, 3L, 4L, 4L, 10L, 2L, 2L, 11L, 
    2L, 2L, 2L, 3L, 2L, 4L, 13L, 4L, 2L, 2L, 2L, 4L, 4L, 10L, 
    3L, 14L, 2L, 8L, 2L, 4L, 16L, 4L, 2L, 13L, 2L, 3L, 3L, 2L, 
    2L, 2L, 2L, 2L, 2L, 4L, 3L, 4L, 2L, 2L, 2L, 2L, 3L, 2L, 8L, 
    2L, 2L, 4L, 3L, 3L, 4L, 2L, 2L, 2L, 2L, 2L, 6L, 3L, 3L, 6L, 
    3L, 3L, 14L, 2L, 3L, 2L, 2L, 3L, 2L, 2L, 16L, 4L, 2L, 2L, 
    2L, 3L, 2L, 6L, 10L, 3L, 13L, 4L, 2L, 2L, 3L, 4L, 4L, 4L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 16L, 4L, 10L, 2L, 4L, 2L, 4L, 
    2L, 3L, 14L, 14L, 2L, 2L, 3L, 2L, 2L, 4L, 2L, 2L, 6L, 2L, 
    2L, 2L, 3L, 2L, 2L, 2L, 2L, 4L, 10L, 4L, 4L, 2L, 2L, 3L, 
    2L, 2L, 2L, 2L, 6L, 2L, 3L, 2L, 4L, 2L, 16L, 2L, 3L, 4L, 
    13L, 2L, 2L, 3L, 4L, 10L, 2L, 2L, 4L, 2L, 14L, 2L, 4L, 3L, 
    4L, 2L, 10L, 4L, 8L, 4L, 3L, 2L, 3L, 2L, 2L, 2L, 14L, 2L, 
    3L, 2L, 3L, 2L, 14L, 2L, 16L, 2L, 10L, 2L, 3L, 2L, 13L, 4L, 
    2L, 2L, 4L, 2L, 2L, 3L, 2L, 2L, 3L, 4L, 2L, 3L, 3L, 2L, 4L, 
    4L, 2L, 2L, 2L, 2L, 10L, 8L, 2L, 2L, 2L, 4L), .Label = c("", 
    "a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l", 
    "m", "n", "o", "p"), class = "factor"), functional_area = structure(c(6L, 
    39L, 24L, 29L, 24L, 60L, 24L, 18L, 2L, 11L, 18L, 52L, 24L, 
    29L, 24L, 6L, 9L, 9L, 24L, 6L, 62L, 31L, 3L, 23L, 24L, 24L, 
    46L, 6L, 24L, 24L, 29L, 24L, 24L, 6L, 24L, 24L, 24L, 24L, 
    24L, 2L, 24L, 24L, 24L, 2L, 24L, 18L, 8L, 8L, 24L, 24L, 18L, 
    18L, 17L, 60L, 24L, 2L, 24L, 24L, 51L, 20L, 22L, 42L, 22L, 
    20L, 18L, 29L, 46L, 62L, 24L, 6L, 23L, 53L, 13L, 24L, 24L, 
    18L, 62L, 24L, 24L, 65L, 24L, 6L, 17L, 9L, 24L, 24L, 20L, 
    6L, 18L, 24L, 24L, 24L, 18L, 24L, 8L, 24L, 44L, 18L, 20L, 
    24L, 24L, 2L, 52L, 18L, 24L, 43L, 24L, 18L, 24L, 24L, 10L, 
    24L, 18L, 52L, 24L, 24L, 52L, 24L, 24L, 24L, 22L, 58L, 6L, 
    18L, 24L, 64L, 10L, 24L, 9L, 23L, 2L, 8L, 6L, 24L, 24L, 6L, 
    24L, 10L, 62L, 6L, 24L, 24L, 24L, 52L, 18L, 62L, 9L, 24L, 
    24L, 24L, 24L, 18L, 62L, 9L, 44L, 9L, 37L, 8L, 2L, 18L, 29L, 
    36L, 18L, 24L, 24L, 6L, 24L, 61L, 44L, 24L, 18L, 24L, 24L, 
    24L, 9L, 18L, 52L, 22L, 24L, 6L, 8L, 24L, 8L, 62L, 24L, 6L, 
    24L, 24L, 22L, 24L, 44L, 24L, 6L, 2L, 10L, 2L, 54L, 9L, 24L, 
    6L, 24L, 2L, 52L, 44L, 52L, 24L, 18L, 6L, 18L, 44L, 23L, 
    18L, 52L, 10L, 6L, 24L, 6L, 9L, 10L, 29L, 18L, 24L, 46L, 
    18L, 17L, 20L, 24L, 29L, 24L, 9L, 24L, 24L, 7L, 10L, 2L, 
    62L, 22L, 2L, 24L, 62L, 22L, 30L, 24L, 37L, 9L, 24L, 18L, 
    9L, 24L, 6L, 6L, 44L, 18L, 10L, 24L, 6L, 24L, 24L, 60L, 24L, 
    7L, 9L, 24L, 24L, 46L, 44L, 18L, 24L, 24L, 17L, 24L, 20L, 
    20L, 62L, 24L, 62L, 24L, 18L, 67L, 40L, 24L, 51L, 24L, 24L, 
    18L, 52L, 6L, 18L, 12L, 34L, 24L, 44L, 24L, 18L, 24L, 24L, 
    22L, 24L, 18L, 24L, 46L, 50L, 8L, 8L, 24L, 29L, 9L, 20L, 
    6L, 6L, 24L, 18L, 24L, 6L, 52L, 18L, 10L, 24L, 51L, 24L, 
    23L, 24L, 52L, 46L, 22L, 24L, 45L, 6L, 2L, 6L, 44L, 24L, 
    24L, 58L, 24L, 2L, 52L, 24L, 17L, 6L, 18L, 6L, 24L, 18L, 
    24L, 18L, 62L, 7L, 52L, 9L, 24L, 8L, 44L, 7L, 24L, 23L, 51L, 
    2L, 24L, 44L, 3L, 62L, 18L, 62L, 62L, 24L, 29L, 18L, 40L, 
    52L, 6L, 22L, 24L, 60L, 24L, 20L, 20L, 6L, 2L, 2L, 10L, 20L, 
    10L, 29L, 20L, 18L, 18L, 9L, 9L, 62L, 64L, 18L, 24L, 8L, 
    44L, 2L, 44L, 23L, 22L, 24L, 18L, 18L, 18L, 64L, 29L, 62L, 
    52L, 24L, 18L, 24L, 6L, 24L, 60L, 24L, 24L, 24L, 9L, 24L, 
    23L, 24L, 2L, 18L, 24L, 24L, 51L, 24L, 6L, 18L, 9L, 52L, 
    18L, 62L, 23L, 33L, 18L, 8L, 10L, 24L, 64L, 3L, 24L, 6L, 
    24L, 53L, 36L, 18L, 6L, 6L, 36L, 2L, 9L, 50L, 8L, 9L, 24L, 
    24L, 24L, 58L, 2L, 44L, 24L, 30L, 52L, 24L, 24L, 62L, 10L, 
    24L, 30L, 6L, 52L, 24L, 24L, 18L, 60L, 24L, 62L, 62L, 62L, 
    24L, 24L, 62L, 62L, 18L, 24L, 18L, 18L, 9L, 18L, 24L, 62L, 
    2L, 20L, 9L, 36L, 24L, 2L, 24L, 10L, 29L, 10L, 18L, 9L, 24L, 
    24L, 20L, 8L, 24L, 18L, 18L, 60L, 9L, 58L, 24L, 22L, 24L, 
    6L, 37L, 24L, 24L, 67L, 51L, 9L, 43L, 6L, 24L, 6L, 46L, 6L, 
    18L, 52L, 18L, 18L, 6L, 44L, 24L, 24L, 52L, 24L, 18L, 10L, 
    18L, 24L, 24L, 24L, 18L, 52L, 24L, 24L, 2L, 18L, 52L, 24L, 
    20L, 2L, 24L, 18L, 9L, 38L, 24L, 18L, 9L, 22L, 20L, 18L, 
    9L, 58L, 24L, 67L, 2L, 24L, 20L, 22L, 10L, 6L, 51L, 23L, 
    29L, 18L, 24L, 24L, 18L, 9L, 52L, 20L, 54L, 62L, 20L, 8L, 
    24L, 15L, 24L, 62L, 9L, 18L, 24L, 18L, 24L, 6L, 18L, 52L, 
    18L, 24L, 60L, 24L, 24L, 18L, 37L, 24L, 24L, 62L, 9L, 24L, 
    29L, 9L, 24L, 9L, 44L, 24L, 24L, 9L, 44L, 9L, 9L, 51L, 24L, 
    60L, 44L, 13L, 18L, 17L, 24L, 13L, 9L, 18L, 24L, 24L, 2L, 
    23L, 24L, 24L, 2L, 51L, 6L, 18L, 24L, 6L, 60L, 20L, 62L, 
    2L, 53L, 62L, 18L, 36L, 30L, 18L, 24L, 18L, 18L, 18L, 18L, 
    29L, 6L, 9L, 6L, 6L, 2L, 6L, 18L, 62L, 24L, 8L, 3L, 17L, 
    24L, 6L, 8L, 60L, 20L, 24L, 2L, 24L, 24L, 6L, 18L, 24L, 44L, 
    24L, 6L, 24L, 29L, 62L, 18L, 62L, 52L, 20L, 6L, 6L, 64L, 
    61L, 6L, 62L, 24L, 24L, 22L, 67L, 46L, 24L, 6L, 24L, 24L, 
    52L, 17L, 18L, 24L, 24L, 62L, 24L, 18L, 24L, 24L, 28L, 6L, 
    6L, 6L, 20L, 62L, 18L, 20L, 20L, 18L, 2L, 20L, 24L, 22L, 
    24L, 6L, 24L, 18L, 18L, 24L, 18L, 67L, 24L, 24L, 22L, 2L, 
    9L, 25L, 23L, 6L, 24L, 44L, 24L, 11L, 6L, 17L, 29L, 24L, 
    24L, 24L, 18L, 2L, 6L, 2L, 18L, 52L, 6L, 52L, 24L, 2L, 18L, 
    22L, 24L, 58L, 6L, 24L, 6L, 10L, 29L, 23L, 6L, 18L, 9L, 52L, 
    20L, 62L, 24L, 54L, 24L, 44L, 24L, 18L, 62L, 58L, 30L, 52L, 
    24L, 24L, 24L, 9L, 9L, 20L, 18L, 37L, 24L, 23L, 6L, 52L, 
    62L, 9L, 24L, 7L, 44L, 18L, 18L, 50L, 24L, 24L, 24L, 24L, 
    24L, 8L, 18L, 52L, 24L, 24L, 24L, 6L, 10L, 24L, 29L, 62L, 
    6L, 53L, 18L, 18L, 9L, 24L, 24L, 24L, 6L, 2L, 67L, 10L, 18L, 
    22L, 6L, 18L, 37L, 24L, 18L, 24L, 24L, 18L, 24L, 24L, 62L, 
    58L, 62L, 24L, 24L, 10L, 24L, 22L, 20L, 18L, 30L, 9L, 24L, 
    24L, 18L, 8L, 52L, 52L, 24L, 44L, 6L, 24L, 24L, 24L, 24L, 
    63L, 9L, 20L, 24L, 43L, 24L, 9L, 2L, 18L, 23L, 37L, 24L, 
    2L, 18L, 2L, 6L, 9L, 6L, 24L, 67L, 6L, 24L, 6L, 18L, 24L, 
    24L, 24L, 24L, 9L, 20L, 52L, 13L, 24L, 62L, 18L, 2L, 24L, 
    24L, 24L, 51L, 62L, 18L, 24L, 52L, 60L, 64L, 24L, 18L, 9L, 
    7L, 24L, 24L, 18L, 9L, 20L, 24L, 24L, 31L, 24L, 23L, 24L, 
    9L, 18L, 58L, 6L, 20L, 22L, 23L, 52L, 18L, 6L, 18L, 24L, 
    24L, 6L, 37L, 24L, 10L, 24L, 18L, 24L, 56L, 24L, 64L, 24L, 
    20L, 44L, 18L, 6L, 7L, 22L, 44L, 6L, 52L, 24L, 44L, 18L, 
    62L, 6L, 18L, 17L, 44L, 18L, 18L, 24L, 52L, 9L, 24L, 6L, 
    44L, 6L, 20L, 29L, 44L, 24L, 6L, 57L), .Label = c("", ".COM", 
    "A", "aaa", "ab", "abc", "ACT", "aoap", "api", "API", "app", 
    "APP", "AUTH", "B", "bbb", "BROWSER", "BULK", "C", "Canvas", 
    "CCC", "cccc", "cert", "Change Sets", "CODE", "Community", 
    "COMMUNITY", "CONNECT", "DATABASE", "DEPLOYMENT", "DESIGN", 
    "DEV", "Development", "DOMAIN", "Email", "hello", "hmm", 
    "IDE", "ISP", "LLM", "LOG", "maintain", "manager", "message", 
    "NEW", "NEW1", "new11", "new11111", "New2", "new3", "no", 
    "Oauth", "on", "open", "Other", "post", "quick", "REST", 
    "SAML", "secure", "Site.com", "SLOWNES", "soo", "SOSL", "sql", 
    "sso", "TOKEN", "YES"), class = "factor"), score = c(9L, 
    10L, 2L, 10L, 10L, 2L, 8L, 10L, 10L, 10L, 10L, 10L, 10L, 
    2L, 10L, 4L, 4L, 10L, 9L, 10L, 10L, 10L, 10L, 5L, 9L, 10L, 
    8L, 10L, 10L, 10L, 10L, 10L, 10L, 1L, 9L, 8L, 10L, 10L, 10L, 
    10L, 9L, 10L, 10L, 10L, 9L, 10L, 8L, 8L, 10L, 9L, 8L, 7L, 
    8L, 9L, 10L, 10L, 8L, 10L, 10L, 10L, 8L, 10L, 10L, 8L, 8L, 
    10L, 10L, 10L, 10L, 10L, 10L, 8L, 5L, 8L, 9L, 10L, 10L, 10L, 
    10L, 8L, 10L, 9L, 7L, 8L, 10L, 10L, 10L, 6L, 9L, 10L, 10L, 
    10L, 9L, 9L, 10L, 10L, 10L, 6L, 8L, 10L, 10L, 9L, 6L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 8L, 1L, 10L, 9L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 7L, 10L, 
    0L, 10L, 10L, 6L, 0L, 8L, 10L, 10L, 10L, 10L, 1L, 8L, 1L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 6L, 10L, 9L, 10L, 9L, 4L, 8L, 10L, 10L, 10L, 
    10L, 10L, 0L, 9L, 8L, 10L, 10L, 10L, 9L, 10L, 10L, 8L, 9L, 
    10L, 10L, 10L, 6L, 9L, 8L, 10L, 10L, 10L, 10L, 10L, 10L, 
    9L, 6L, 9L, 10L, 10L, 9L, 7L, 8L, 10L, 10L, 10L, 10L, 10L, 
    8L, 0L, 10L, 8L, 9L, 10L, 10L, 10L, 10L, 10L, 8L, 9L, 9L, 
    10L, 9L, 9L, 8L, 10L, 10L, 9L, 10L, 10L, 7L, 10L, 10L, 10L, 
    9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 6L, 10L, 10L, 10L, 10L, 10L, 1L, 9L, 7L, 10L, 
    2L, 9L, 9L, 6L, 8L, 8L, 10L, 10L, 10L, 10L, 9L, 9L, 10L, 
    10L, 8L, 8L, 10L, 10L, 8L, 8L, 10L, 4L, 10L, 8L, 10L, 9L, 
    9L, 10L, 10L, 7L, 10L, 4L, 10L, 8L, 10L, 10L, 9L, 9L, 6L, 
    10L, 10L, 10L, 10L, 10L, 10L, 9L, 10L, 8L, 10L, 10L, 10L, 
    8L, 10L, 10L, 10L, 10L, 8L, 10L, 10L, 10L, 10L, 9L, 6L, 10L, 
    9L, 10L, 10L, 10L, 8L, 10L, 10L, 10L, 10L, 10L, 3L, 10L, 
    10L, 10L, 10L, 2L, 10L, 10L, 0L, 10L, 0L, 10L, 10L, 10L, 
    10L, 10L, 10L, 9L, 10L, 10L, 9L, 10L, 10L, 10L, 8L, 9L, 10L, 
    9L, 0L, 10L, 10L, 8L, 10L, 7L, 10L, 10L, 10L, 10L, 10L, 10L, 
    8L, 9L, 9L, 10L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 9L, 10L, 6L, 7L, 10L, 10L, 10L, 10L, 
    10L, 10L, 8L, 10L, 8L, 10L, 10L, 10L, 8L, 10L, 10L, 10L, 
    10L, 10L, 10L, 8L, 9L, 10L, 10L, 1L, 10L, 9L, 10L, 10L, 10L, 
    9L, 10L, 10L, 6L, 9L, 9L, 8L, 10L, 10L, 10L, 9L, 10L, 10L, 
    10L, 10L, 0L, 0L, 10L, 8L, 8L, 10L, 10L, 8L, 9L, 9L, 10L, 
    10L, 10L, 10L, 10L, 2L, 8L, 10L, 8L, 10L, 8L, 10L, 8L, 10L, 
    10L, 8L, 8L, 0L, 8L, 8L, 10L, 10L, 10L, 8L, 1L, 8L, 10L, 
    2L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 4L, 8L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 3L, 10L, 10L, 10L, 10L, 8L, 
    10L, 10L, 10L, 7L, 9L, 9L, 10L, 10L, 8L, 10L, 9L, 10L, 10L, 
    10L, 10L, 10L, 10L, 9L, 10L, 10L, 10L, 10L, 8L, 10L, 10L, 
    10L, 8L, 10L, 10L, 10L, 10L, 10L, 10L, 9L, 10L, 10L, 0L, 
    6L, 9L, 10L, 9L, 7L, 8L, 10L, 10L, 7L, 9L, 10L, 10L, 10L, 
    10L, 0L, 10L, 10L, 10L, 7L, 10L, 10L, 8L, 10L, 10L, 10L, 
    9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 9L, 10L, 
    9L, 10L, 8L, 10L, 9L, 10L, 10L, 10L, 9L, 8L, 10L, 10L, 10L, 
    6L, 10L, 10L, 9L, 10L, 8L, 10L, 0L, 10L, 8L, 9L, 9L, 9L, 
    10L, 10L, 10L, 10L, 10L, 8L, 2L, 10L, 10L, 8L, 10L, 9L, 10L, 
    9L, 10L, 0L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 5L, 
    10L, 10L, 10L, 8L, 7L, 10L, 10L, 9L, 7L, 10L, 5L, 8L, 9L, 
    10L, 10L, 8L, 10L, 10L, 9L, 10L, 10L, 10L, 9L, 10L, 10L, 
    10L, 10L, 10L, 1L, 7L, 10L, 7L, 10L, 0L, 9L, 7L, 10L, 10L, 
    10L, 10L, 10L, 10L, 9L, 10L, 10L, 8L, 10L, 8L, 10L, 8L, 10L, 
    9L, 9L, 8L, 9L, 10L, 9L, 10L, 10L, 2L, 10L, 10L, 10L, 10L, 
    10L, 0L, 10L, 8L, 10L, 10L, 9L, 10L, 10L, 10L, 9L, 8L, 8L, 
    9L, 9L, 7L, 7L, 5L, 9L, 10L, 10L, 10L, 10L, 9L, 10L, 10L, 
    9L, 5L, 10L, 8L, 10L, 10L, 8L, 10L, 10L, 10L, 10L, 10L, 8L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 7L, 10L, 10L, 6L, 6L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 9L, 10L, 10L, 9L, 10L, 
    8L, 10L, 10L, 10L, 9L, 10L, 8L, 10L, 9L, 9L, 10L, 9L, 9L, 
    10L, 10L, 10L, 10L, 10L, 6L, 8L, 10L, 10L, 9L, 10L, 10L, 
    10L, 10L, 10L, 10L, 8L, 10L, 10L, 9L, 10L, 2L, 10L, 9L, 9L, 
    10L, 10L, 10L, 9L, 10L, 10L, 10L, 9L, 10L, 10L, 10L, 10L, 
    10L, 8L, 10L, 10L, 8L, 7L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 9L, 10L, 10L, 9L, 8L, 8L, 9L, 10L, 0L, 0L, 2L, 9L, 10L, 
    10L, 8L, 10L, 6L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    5L, 10L, 8L, 10L, 10L, 9L, 0L, 10L, 10L, 10L, 9L, 1L, 9L, 
    10L, 8L, 2L, 10L, 10L, 8L, 10L, 10L, 10L, 10L, 10L, 9L, 9L, 
    2L, 10L, 8L, 8L, 10L, 10L, 3L, 10L, 10L, 10L, 9L, 10L, 10L, 
    8L, 10L, 7L, 10L, 10L, 10L, 10L, 10L, 10L, 6L, 0L, 4L, 9L, 
    8L, 10L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 9L, 
    10L, 10L, 10L, 10L, 10L, 9L, 9L, 7L, 8L, 10L, 8L, 10L, 8L, 
    10L, 8L, 7L, 10L, 10L, 8L, 9L, 10L, 10L, 9L, 10L, 9L, 10L, 
    10L, 10L, 9L, 10L, 9L, 9L, 10L, 10L, 8L, 9L, 10L, 10L, 0L, 
    10L, 10L, 10L, 9L, 10L, 10L, 9L, 10L, 10L, 10L, 6L, 10L, 
    10L, 10L, 10L, 10L, 9L, 4L, 9L, 10L, 1L, 9L, 9L, 10L, 7L, 
    9L, 10L, 10L, 10L, 10L, 9L, 10L, 9L, 10L, 2L, 10L, 9L, 7L, 
    9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 1L), rep_score = c(9.5, 
    10, 2, 10, 10, 3.5, 7.5, 10, 10, 10, 10, 10, 10, 2, 10, 7.5, 
    6, 10, 9.5, 10, 9, 10, 10, 5.5, 9, 10, 8, 10, 10, 10, 10, 
    10, 9.5, 1.5, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 9.5, 
    10, 10, 8, 10, 10, 9.5, 6, 9, 9, 10, 10, 7.5, 10, 10, 10, 
    7.5, 10, 10, 8, 9, 10, 10, 10, 10, 10, 10, 7.5, 7.5, 7.5, 
    9, 10, 10, 10, 10, 7.5, 10, 9, 7.5, 8, 10, 10, 10, 7.5, 9.5, 
    10, 9.5, 10, 10, 8.5, 10, 9, 9.5, 9.5, 8, 10, 10, 9, 9, 10, 
    10, 9, 10, 10, 10, 10, 9.5, 2, 10, 9, 10, 10, 10, 10, 10, 
    10, 10, 10, 10, 10, 10, 10, 8, 10, 9.3, 10, 10, 7.5, 9.3, 
    8, 9, 10, 10, 9.5, 6.5, 7.5, 6, 10, 10, 10, 10, 10, 10, 10, 
    10, 10, 10, 10, 10, 10, 10, 10, 6, 7, 8.5, 9.5, 9.5, 5, 7.5, 
    10, 10, 10, 8, 10, 6, 8, 6.5, 10, 10, 10, 9, 10, 10, 8, 8.5, 
    10, 10, 10, 7.5, 9, 8, 10, 10, 10, 10, 10, 10, 9, 7, 10, 
    10, 10, 9, 7.5, 9.5, 10, 9, 10, 10, 10, 8, 9.3, 10, 9, 10, 
    10, 10, 9.5, 10, 10, 8, 9, 9, 10, 10, 10, 8, 10, 10, 9.5, 
    10, 9, 7.5, 10, 10, 10, 8.5, 10, 9.5, 10, 10, 10, 10, 10, 
    10, 9, 10, 10, 10, 10, 10, 5, 10, 10, 10, 10, 10, 4, 9, 7, 
    10, 4, 8.5, 8.5, 6.5, 7.5, 8.5, 10, 10, 10, 10, 8.5, 8, 9, 
    10, 9, 8, 10, 10, 8, 10, 10, 8.5, 10, 8, 10, 9, 9.5, 10, 
    9, 7.5, 10, 4.5, 9.5, 8, 10, 10, 9.5, 8.5, 8, 10, 10, 10, 
    10, 10, 10, 9, 10, 9, 10, 9.5, 8, 8, 10, 10, 9.5, 10, 8.5, 
    10, 9, 10, 10, 7.5, 7, 10, 9.5, 10, 10, 10, 7, 9.5, 10, 10, 
    10, 10, 4, 10, 10, 10, 10, 7, 10, 10, 10, 10, 9.3, 10, 10, 
    10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 7.5, 10, 10, 9, 
    6, 10, 10, 9.5, 10, 8.5, 10, 10, 10, 10, 10, 10, 10, 9.5, 
    9.5, 10, 9, 10, 9.5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 
    9.5, 9, 10, 6, 9, 10, 10, 9.5, 10, 10, 10, 9.5, 10, 8, 10, 
    10, 10, 8.5, 10, 9.5, 10, 10, 10, 10, 8, 10, 10, 10, 4.5, 
    10, 10, 10, 10, 10, 9, 9, 10, 6, 10, 9.5, 8, 10, 10, 10, 
    9, 10, 10, 10, 9.5, 7, 9.3, 10, 10, 8.5, 10, 10, 8, 10, 9.5, 
    10, 10, 10, 10, 9.5, 5.5, 8, 10, 7.5, 10, 7.5, 10, 8, 10, 
    10, 8, 8.5, 9.3, 8, 8, 10, 10, 10, 9.5, 1.5, 8, 10, 7, 10, 
    10, 10, 10, 10, 10, 10, 7.5, 8, 10, 10, 10, 10, 10, 10, 10, 
    10, 7.5, 10, 10, 10, 10, 7.5, 10, 10, 10, 8, 9, 9, 10, 10, 
    9, 10, 9.5, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 8, 
    10, 10, 8.5, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 7, 7, 
    9, 10, 9, 10, 8, 10, 10, 7.5, 10, 10, 10, 10, 10, 6.5, 10, 
    10, 10, 9.5, 10, 10, 9, 10, 10, 10, 9, 10, 9.5, 10, 10, 10, 
    10, 10, 10, 10, 9.5, 10, 9, 10, 9, 10, 9, 10, 10, 10, 9.5, 
    7.5, 10, 10, 10, 4.5, 10, 9, 9.5, 10, 8, 10, 1, 10, 8, 8, 
    10, 10, 10, 10, 10, 10, 10, 8, 3.5, 10, 10, 8.5, 10, 9.5, 
    10, 10, 10, 3, 10, 10, 10, 10, 10, 10, 10, 10, 5, 10, 10, 
    10, 8, 7, 10, 10, 9, 5.5, 8, 5, 5, 9, 10, 10, 8, 9, 10, 9, 
    10, 10, 10, 9.5, 10, 10, 10, 10, 10, 1, 7.5, 10, 9, 10, 9.3, 
    10, 10, 10, 8.5, 10, 10, 10, 10, 9, 10, 10, 8, 7.5, 8, 10, 
    8.5, 10, 9, 8.5, 7.5, 8.5, 10, 9, 10, 10, 3.5, 10, 10, 10, 
    10, 10, 6, 10, 8, 10, 10, 10, 10, 10, 10, 10, 8, 8.5, 9, 
    9, 8, 8.5, 5.5, 7.5, 10, 10, 10, 10, 9, 10, 9.5, 8, 5, 10, 
    10, 10, 10, 8, 10, 9, 10, 10, 10, 9, 10, 10, 10, 10, 10, 
    10, 10, 5.5, 10, 10, 9, 4.5, 10, 10, 10, 10, 10, 9.5, 10, 
    10, 10, 9, 10, 10, 10, 9.5, 10, 10, 10, 10, 10, 10, 9.5, 
    10, 10, 8.5, 10, 8.5, 10, 10, 10, 9.5, 10, 8, 10, 9.5, 9.5, 
    10, 9.5, 10, 10, 10, 10, 10, 10, 5.5, 8, 10, 10, 9, 10, 10, 
    10, 10, 10, 10, 8.5, 9.5, 10, 8.5, 10, 5, 10, 9.5, 9.5, 10, 
    10, 10, 8, 10, 10, 10, 8.5, 10, 10, 10, 10, 10, 6, 10, 10, 
    7.5, 8.5, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 8.5, 8, 
    9.5, 10, 10, 9.3, 9.3, 8, 9, 10, 10, 8, 10, 8, 10, 10, 10, 
    10, 8.5, 10, 10, 10, 5, 10, 9, 10, 10, 9, 9.3, 10, 10, 10, 
    10, 2.5, 9, 10, 10, 2, 9.5, 10, 8, 10, 10, 10, 10, 10, 9, 
    8.5, 5.5, 10, 8, 9.5, 10, 10, 6, 10, 10, 10, 9.5, 10, 9.5, 
    6.5, 10, 10, 10, 10, 10, 10, 10, 10, 6, 9.3, 8, 8.5, 9, 10, 
    9.5, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 
    9.5, 9.5, 8.5, 9, 10, 8, 10, 9, 10, 10, 9, 10, 10, 8.5, 9.5, 
    10, 10, 9.5, 10, 9, 8, 10, 10, 9, 10, 8, 9, 10, 10, 6, 9.5, 
    9.5, 10, 9.3, 10, 10, 10, 9, 10, 10, 10, 9.5, 10, 10, 6, 
    10, 10, 10, 10, 10, 9, 4.5, 8.5, 10, 5, 9, 9, 10, 6, 9, 10, 
    9.5, 9.5, 10, 9.5, 10, 7.5, 10, 3, 10, 9.5, 10, 9, 9, 9.5, 
    10, 10, 10, 10, 10, 10, 10, 2), product_know = structure(c(5L, 
    5L, 6L, 5L, 2L, 4L, 12L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 5L, 
    11L, 10L, 5L, 5L, 5L, 12L, 5L, 5L, 10L, 13L, 5L, 12L, 5L, 
    5L, 5L, 5L, 5L, 13L, 4L, 13L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 12L, 5L, 5L, 5L, 10L, 13L, 13L, 5L, 5L, 
    12L, 5L, 5L, 5L, 12L, 5L, 5L, 13L, 13L, 5L, 5L, 5L, 5L, 5L, 
    5L, 12L, 9L, 13L, 13L, 5L, 5L, 5L, 5L, 12L, 5L, 13L, 11L, 
    12L, 5L, 5L, 5L, 11L, 13L, 5L, 13L, 5L, 5L, 12L, 5L, 12L, 
    13L, 13L, 12L, 5L, 5L, 13L, 13L, 5L, 5L, 13L, 5L, 5L, 5L, 
    5L, 13L, 6L, 5L, 13L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 12L, 5L, 3L, 5L, 5L, 11L, 3L, 12L, 13L, 5L, 5L, 
    13L, 10L, 13L, 6L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 10L, 11L, 12L, 5L, 5L, 10L, 11L, 5L, 
    5L, 5L, 12L, 5L, 10L, 12L, 9L, 5L, 5L, 5L, 13L, 5L, 5L, 12L, 
    13L, 5L, 5L, 5L, 12L, 13L, 12L, 5L, 5L, 5L, 5L, 5L, 5L, 13L, 
    11L, 5L, 5L, 5L, 12L, 12L, 13L, 5L, 13L, 5L, 5L, 5L, 12L, 
    3L, 5L, 12L, 5L, 5L, 5L, 13L, 5L, 5L, 12L, 5L, 13L, 5L, 5L, 
    5L, 12L, 5L, 5L, 13L, 5L, 5L, 13L, 5L, 5L, 5L, 11L, 5L, 5L, 
    5L, 5L, 5L, 5L, 2L, 5L, 12L, 5L, 5L, 5L, 5L, 5L, 12L, 5L, 
    5L, 5L, 5L, 5L, 9L, 13L, 11L, 5L, 8L, 13L, 13L, 10L, 11L, 
    12L, 5L, 5L, 5L, 5L, 13L, 12L, 13L, 5L, 13L, 12L, 5L, 5L, 
    12L, 5L, 5L, 11L, 5L, 2L, 5L, 13L, 13L, 5L, 5L, 12L, 5L, 
    9L, 13L, 12L, 5L, 5L, 13L, 13L, 10L, 5L, 5L, 5L, 5L, 5L, 
    5L, 13L, 5L, 13L, 5L, 13L, 11L, 12L, 5L, 5L, 5L, 5L, 13L, 
    5L, 13L, 5L, 5L, 13L, 12L, 5L, 13L, 5L, 5L, 5L, 12L, 13L, 
    5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 12L, 5L, 5L, 5L, 5L, 
    3L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 11L, 
    5L, 5L, 13L, 10L, 5L, 5L, 13L, 5L, 12L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 13L, 5L, 13L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 13L, 5L, 10L, 12L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 12L, 5L, 5L, 5L, 13L, 5L, 13L, 5L, 5L, 5L, 5L, 2L, 
    5L, 5L, 5L, 10L, 5L, 5L, 5L, 5L, 5L, 13L, 13L, 5L, 10L, 5L, 
    13L, 12L, 5L, 5L, 5L, 13L, 5L, 5L, 5L, 13L, 10L, 3L, 5L, 
    5L, 13L, 5L, 5L, 12L, 5L, 13L, 5L, 5L, 2L, 5L, 13L, 13L, 
    13L, 5L, 12L, 5L, 12L, 5L, 12L, 5L, 5L, 12L, 13L, 3L, 12L, 
    12L, 5L, 5L, 5L, 13L, 6L, 12L, 5L, 12L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 12L, 12L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 10L, 5L, 
    5L, 5L, 5L, 11L, 5L, 5L, 5L, 12L, 13L, 12L, 5L, 5L, 13L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 13L, 5L, 5L, 5L, 5L, 12L, 
    5L, 5L, 5L, 12L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 2L, 12L, 
    11L, 13L, 5L, 13L, 5L, 12L, 5L, 5L, 12L, 5L, 5L, 5L, 5L, 
    5L, 10L, 5L, 5L, 5L, 13L, 5L, 5L, 13L, 5L, 5L, 5L, 13L, 5L, 
    13L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 13L, 5L, 13L, 5L, 
    13L, 5L, 5L, 5L, 13L, 11L, 5L, 5L, 5L, 10L, 5L, 13L, 5L, 
    5L, 12L, 5L, 3L, 5L, 12L, 12L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    12L, 6L, 5L, 5L, 13L, 5L, 5L, 5L, 5L, 5L, 7L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 9L, 5L, 5L, 5L, 12L, 11L, 5L, 5L, 13L, 
    7L, 10L, 9L, 10L, 13L, 5L, 5L, 12L, 12L, 5L, 13L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 4L, 12L, 5L, 13L, 5L, 3L, 5L, 
    5L, 5L, 12L, 5L, 5L, 5L, 5L, 13L, 5L, 5L, 12L, 11L, 12L, 
    5L, 12L, 5L, 13L, 13L, 11L, 13L, 5L, 13L, 5L, 5L, 10L, 5L, 
    5L, 5L, 5L, 5L, 10L, 5L, 12L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    12L, 13L, 13L, 13L, 12L, 13L, 9L, 12L, 5L, 5L, 5L, 5L, 13L, 
    5L, 13L, 13L, 9L, 5L, 5L, 5L, 5L, 12L, 5L, 13L, 5L, 5L, 5L, 
    13L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 8L, 5L, 5L, 13L, 11L, 5L, 
    5L, 5L, 5L, 5L, 13L, 5L, 5L, 5L, 12L, 5L, 5L, 5L, 13L, 5L, 
    5L, 5L, 5L, 5L, 5L, 13L, 5L, 5L, 13L, 5L, 12L, 5L, 5L, 5L, 
    5L, 5L, 12L, 5L, 13L, 5L, 5L, 13L, 5L, 5L, 5L, 5L, 5L, 5L, 
    9L, 12L, 5L, 5L, 13L, 5L, 5L, 5L, 5L, 5L, 5L, 13L, 13L, 5L, 
    12L, 5L, 10L, 5L, 5L, 5L, 5L, 5L, 5L, 12L, 5L, 5L, 5L, 12L, 
    5L, 5L, 5L, 5L, 5L, 10L, 5L, 5L, 11L, 11L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 13L, 5L, 13L, 12L, 13L, 5L, 5L, 3L, 3L, 13L, 
    13L, 5L, 5L, 12L, 5L, 12L, 5L, 5L, 5L, 5L, 12L, 5L, 5L, 5L, 
    10L, 5L, 5L, 5L, 5L, 13L, 3L, 5L, 5L, 5L, 5L, 6L, 13L, 5L, 
    5L, 6L, 5L, 5L, 12L, 5L, 5L, 5L, 5L, 5L, 13L, 13L, 7L, 5L, 
    13L, 13L, 5L, 5L, 6L, 5L, 5L, 5L, 13L, 5L, 5L, 11L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 10L, 3L, 12L, 13L, 13L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 13L, 5L, 5L, 5L, 5L, 5L, 13L, 
    5L, 11L, 13L, 5L, 12L, 5L, 13L, 5L, 5L, 13L, 5L, 5L, 12L, 
    13L, 5L, 5L, 5L, 5L, 12L, 5L, 5L, 5L, 13L, 5L, 13L, 12L, 
    5L, 5L, 10L, 5L, 13L, 5L, 3L, 5L, 5L, 5L, 13L, 5L, 5L, 5L, 
    5L, 5L, 5L, 10L, 5L, 5L, 5L, 5L, 5L, 13L, 9L, 13L, 5L, 8L, 
    13L, 13L, 5L, 10L, 13L, 5L, 13L, 5L, 5L, 13L, 5L, 11L, 5L, 
    6L, 5L, 13L, 5L, 13L, 13L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    7L), .Label = c("", "-", "0", "1", "10", "2", "3", "4", "5", 
    "6", "7", "8", "9"), class = "factor"), understanding_issue = structure(c(13L, 
    5L, 6L, 5L, 5L, 10L, 11L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 5L, 
    12L, 10L, 5L, 13L, 5L, 5L, 5L, 5L, 9L, 13L, 5L, 12L, 2L, 
    5L, 5L, 5L, 5L, 5L, 6L, 13L, 12L, 5L, 5L, 5L, 5L, 5L, 5L, 
    2L, 5L, 13L, 5L, 5L, 12L, 5L, 5L, 13L, 10L, 13L, 13L, 5L, 
    5L, 11L, 5L, 5L, 5L, 11L, 5L, 5L, 11L, 13L, 5L, 5L, 5L, 5L, 
    5L, 5L, 11L, 5L, 10L, 13L, 5L, 5L, 5L, 5L, 11L, 5L, 13L, 
    12L, 12L, 5L, 5L, 5L, 12L, 5L, 5L, 5L, 5L, 5L, 13L, 5L, 5L, 
    5L, 5L, 12L, 5L, 5L, 13L, 13L, 5L, 5L, 13L, 5L, 5L, 5L, 5L, 
    5L, 6L, 5L, 13L, 5L, 2L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 12L, 5L, 3L, 5L, 2L, 12L, 3L, 12L, 13L, 5L, 5L, 5L, 
    11L, 10L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 2L, 5L, 10L, 2L, 13L, 13L, 13L, 8L, 12L, 5L, 5L, 
    2L, 12L, 5L, 10L, 12L, 12L, 5L, 5L, 5L, 13L, 5L, 5L, 12L, 
    12L, 5L, 5L, 5L, 11L, 13L, 12L, 5L, 5L, 5L, 5L, 5L, 5L, 13L, 
    11L, 5L, 5L, 5L, 5L, 11L, 5L, 5L, 13L, 5L, 5L, 5L, 12L, 3L, 
    5L, 5L, 2L, 5L, 5L, 5L, 5L, 5L, 12L, 12L, 13L, 5L, 5L, 5L, 
    12L, 5L, 5L, 5L, 5L, 12L, 10L, 5L, 5L, 5L, 5L, 5L, 13L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 5L, 5L, 5L, 
    5L, 5L, 7L, 13L, 11L, 5L, 8L, 12L, 12L, 11L, 12L, 13L, 5L, 
    5L, 5L, 5L, 12L, 12L, 13L, 5L, 13L, 12L, 5L, 5L, 12L, 5L, 
    5L, 5L, 5L, 12L, 5L, 13L, 5L, 5L, 12L, 11L, 5L, 8L, 5L, 12L, 
    5L, 5L, 5L, 12L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 13L, 5L, 13L, 
    5L, 5L, 13L, 2L, 5L, 5L, 13L, 5L, 12L, 5L, 13L, 5L, 5L, 10L, 
    10L, 5L, 5L, 5L, 5L, 5L, 10L, 5L, 5L, 5L, 5L, 5L, 9L, 5L, 
    5L, 5L, 5L, 10L, 5L, 5L, 5L, 5L, 3L, 5L, 5L, 5L, 5L, 5L, 
    5L, 12L, 5L, 5L, 5L, 5L, 5L, 5L, 12L, 5L, 5L, 13L, 3L, 5L, 
    5L, 5L, 5L, 13L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 13L, 5L, 2L, 
    13L, 5L, 13L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 13L, 13L, 
    5L, 10L, 5L, 5L, 5L, 13L, 5L, 5L, 5L, 13L, 5L, 2L, 2L, 5L, 
    5L, 12L, 5L, 5L, 5L, 5L, 5L, 5L, 12L, 5L, 5L, 5L, 7L, 5L, 
    5L, 5L, 5L, 5L, 13L, 2L, 5L, 10L, 5L, 5L, 12L, 5L, 5L, 5L, 
    13L, 5L, 5L, 5L, 5L, 12L, 3L, 5L, 5L, 12L, 5L, 5L, 12L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 6L, 11L, 5L, 11L, 5L, 11L, 5L, 12L, 
    5L, 2L, 12L, 12L, 3L, 12L, 12L, 5L, 5L, 5L, 5L, 4L, 12L, 
    5L, 10L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 11L, 12L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 13L, 5L, 5L, 5L, 5L, 12L, 2L, 5L, 5L, 
    12L, 13L, 5L, 5L, 5L, 13L, 5L, 13L, 2L, 5L, 5L, 5L, 5L, 5L, 
    13L, 5L, 5L, 5L, 5L, 12L, 5L, 5L, 11L, 12L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 10L, 11L, 13L, 5L, 13L, 5L, 12L, 5L, 
    5L, 11L, 5L, 5L, 5L, 5L, 5L, 11L, 5L, 5L, 5L, 5L, 5L, 5L, 
    13L, 5L, 5L, 5L, 13L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    13L, 5L, 13L, 5L, 13L, 5L, 13L, 5L, 5L, 2L, 5L, 12L, 5L, 
    5L, 5L, 7L, 5L, 13L, 13L, 5L, 12L, 5L, 4L, 5L, 12L, 12L, 
    5L, 5L, 2L, 5L, 5L, 5L, 5L, 12L, 9L, 5L, 5L, 12L, 5L, 13L, 
    5L, 5L, 5L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 9L, 5L, 5L, 
    5L, 12L, 11L, 5L, 5L, 13L, 12L, 5L, 9L, 8L, 13L, 5L, 5L, 
    12L, 5L, 5L, 13L, 5L, 5L, 5L, 13L, 5L, 5L, 5L, 5L, 5L, 4L, 
    11L, 5L, 13L, 5L, 3L, 5L, 5L, 5L, 13L, 5L, 5L, 5L, 5L, 13L, 
    5L, 5L, 12L, 12L, 12L, 5L, 13L, 5L, 13L, 12L, 12L, 12L, 5L, 
    13L, 5L, 5L, 4L, 5L, 5L, 5L, 5L, 5L, 10L, 5L, 12L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 12L, 12L, 13L, 13L, 12L, 12L, 10L, 11L, 
    5L, 5L, 5L, 5L, 13L, 5L, 5L, 11L, 9L, 5L, 5L, 5L, 5L, 12L, 
    5L, 13L, 5L, 5L, 5L, 13L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 11L, 
    5L, 5L, 13L, 6L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 12L, 
    5L, 13L, 5L, 5L, 5L, 13L, 2L, 12L, 5L, 5L, 13L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 10L, 12L, 5L, 5L, 13L, 5L, 5L, 5L, 5L, 
    5L, 5L, 12L, 5L, 5L, 13L, 5L, 8L, 5L, 13L, 13L, 5L, 5L, 5L, 
    12L, 5L, 5L, 5L, 13L, 5L, 5L, 5L, 5L, 5L, 10L, 5L, 5L, 12L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 13L, 5L, 12L, 12L, 5L, 
    5L, 5L, 3L, 3L, 11L, 13L, 5L, 5L, 12L, 5L, 12L, 5L, 5L, 5L, 
    5L, 13L, 5L, 5L, 5L, 8L, 5L, 12L, 5L, 5L, 13L, 3L, 5L, 5L, 
    5L, 5L, 7L, 2L, 5L, 5L, 6L, 13L, 5L, 12L, 5L, 5L, 5L, 5L, 
    5L, 13L, 12L, 12L, 5L, 11L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 13L, 10L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 10L, 3L, 12L, 
    12L, 13L, 5L, 13L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 13L, 5L, 
    5L, 5L, 5L, 5L, 5L, 13L, 5L, 13L, 5L, 12L, 5L, 13L, 5L, 5L, 
    13L, 5L, 5L, 13L, 5L, 5L, 5L, 13L, 5L, 5L, 10L, 5L, 5L, 13L, 
    5L, 11L, 5L, 5L, 5L, 10L, 13L, 5L, 5L, 3L, 5L, 5L, 5L, 13L, 
    5L, 5L, 5L, 13L, 5L, 5L, 2L, 5L, 5L, 5L, 5L, 5L, 13L, 8L, 
    12L, 5L, 10L, 13L, 13L, 5L, 10L, 13L, 5L, 5L, 13L, 2L, 5L, 
    5L, 12L, 5L, 8L, 5L, 5L, 5L, 13L, 13L, 13L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 4L), .Label = c("", "-", "0", "1", "10", "2", 
    "3", "4", "5", "6", "7", "8", "9"), class = "factor"), case_age = c(24.84, 
    0.05, 13.38, 0.15, 11.11, 4.16, 8.13, 0.07, 3.61, 0, 3.11, 
    20.94, 0.21, 17.49, 1.11, 6.15, 4.32, 4.03, 0.08, 3.06, 4.74, 
    12.07, 4.79, 5.29, 0.21, 0.06, 3.95, 0.12, 7.27, 4.18, 2.49, 
    20.95, 0.15, 10.96, 6.99, 47.42, 4.96, 0.06, 4.92, 0.06, 
    6.84, 0.3, 0.01, 0.07, 15.74, 5.8, 2.85, 0.17, 16.02, 1.33, 
    7.91, 5.95, 1.48, 14.7, 1.98, 0.07, 12.89, 0.09, 0.11, 6.96, 
    0.19, 6.23, 5.62, 6.81, 6.98, 0.03, 0.12, 9.21, 0.8, 8.93, 
    1.87, 6.01, 0.34, 28.06, 16.36, 0.74, 5.82, 2.23, 0.18, 1.21, 
    0.06, 22.21, 1.97, 0.88, 0.21, 0.86, 6.02, 8.9, 1.75, 0.1, 
    1.15, 0.01, 0.17, 0.03, 7.99, 0.08, 0.05, 2.92, 1.02, 0.1, 
    0.86, 18.07, 0.06, 10.22, 1.1, 1.25, 0.03, 0.03, 0.96, 0.88, 
    0.96, 16.42, 1.06, 10.11, 0.97, 0.02, 0.12, 2.12, 7.29, 0.06, 
    0.27, 10.01, 1.96, 0.27, 0.04, 2.1, 9.34, 2.05, 22.29, 0, 
    6.98, 9.17, 15.55, 31.06, 0.06, 2.96, 11.04, 0.14, 17.36, 
    24.16, 41.89, 0.07, 0.01, 0.09, 5.1, 3.26, 1.85, 19.09, 10.88, 
    3.05, 0.87, 0.01, 2.78, 26.05, 14.23, 19.27, 0.09, 4.16, 
    3.77, 1.84, 11.06, 12.54, 3.26, 0.19, 0.15, 3.89, 19.85, 
    0.04, 13.18, 2.05, 0.89, 1.04, 0.09, 20.2, 0.82, 0.94, 4.99, 
    4.15, 0.04, 5.84, 15.75, 0.78, 1.92, 4.28, 6.08, 0.15, 83.05, 
    13.9, 2.75, 2.05, 0.02, 4.14, 6.72, 11.12, 1.82, 0.79, 0.12, 
    7.91, 0.16, 2.07, 2.1, 0.09, 0.14, 2.04, 2.22, 1.01, 0.06, 
    1.07, 1.98, 2.42, 6.39, 0.52, 6.93, 1.28, 2.02, 3.74, 34.86, 
    0.01, 7.15, 2.97, 1.15, 0.17, 0.18, 7.25, 2.98, 1.11, 85.99, 
    2.34, 0.67, 45.13, 1.03, 0.04, 0.13, 9.87, 7.03, 4.29, 0.1, 
    0.04, 0.07, 8.26, 0.2, 1.21, 1.81, 0.12, 1.12, 20.28, 0.05, 
    18.29, 2.78, 15.36, 4, 6.12, 0.04, 9.14, 0, 7.1, 19.07, 4.04, 
    3.9, 4.01, 11.22, 0, 0.09, 2.1, 3.05, 3.86, 15.21, 0.54, 
    0.01, 31.19, 2.17, 4.07, 20.07, 3.17, 14.38, 0.27, 13.89, 
    3.29, 2.82, 0.01, 2.58, 5.15, 9.85, 1.06, 14.24, 3.05, 5.96, 
    0.05, 0.01, 0.04, 0.07, 0.16, 49.02, 10.89, 4.91, 0.02, 5.31, 
    0.01, 0.02, 0.04, 3.99, 1.02, 6.18, 1.15, 6.18, 27.18, 5.16, 
    3.29, 3.97, 4.79, 0, 19.92, 0, 18.3, 11.01, 0.01, 4.09, 6.44, 
    10.98, 13.02, 0.1, 2.04, 1.3, 7.22, 1.82, 7.02, 0.91, 0.31, 
    0.95, 0.01, 12.09, 0.04, 0.84, 0.91, 28.75, 0.99, 1.12, 0.22, 
    5.12, 26.98, 1.01, 1.27, 1.29, 7.16, 0.07, 0.05, 1.01, 2.35, 
    0.17, 0.4, 0.89, 2.26, 6.1, 0.89, 1.16, 0.07, 5.69, 9.1, 
    1.88, 0.03, 15.21, 1.76, 14.14, 15.33, 1.02, 13.18, 0.09, 
    19.76, 1.99, 8.79, 2.81, 0.73, 0.24, 22.85, 0.12, 0.2, 0.18, 
    0.84, 20.92, 15.8, 0.04, 21.58, 0.04, 1.06, 1.06, 15.76, 
    9.29, 16.2, 0.09, 2.81, 10.82, 0.02, 41.96, 1.17, 0.35, 1.99, 
    4.93, 0.14, 0.95, 16.02, 4.05, 0.09, 0.02, 2.05, 2.02, 3.01, 
    0.02, 8.05, 0.17, 3.08, 0.99, 0.91, 1.31, 7.13, 1.05, 9.14, 
    36.25, 3.92, 3, 2.02, 11.14, 17.04, 1.08, 5.85, 4.27, 29.07, 
    25.07, 2.74, 24.28, 15.11, 0.85, 0.97, 38.02, 0.08, 102.44, 
    19.36, 3.77, 3.32, 0.04, 3.01, 3.86, 8.27, 7.11, 11.95, 1.21, 
    3.33, 0.15, 0, 4.68, 4.16, 12.94, 0.79, 7.81, 5.82, 6.29, 
    0.96, 13.75, 0.89, 0.97, 35.83, 1.03, 9.24, 0.08, 41.18, 
    0.79, 0.07, 1.19, 6.96, 6.9, 3.25, 2.28, 8.81, 1.21, 0.04, 
    5.94, 0.04, 3.95, 3.72, 1.72, 3.73, 0.12, 8.52, 41.09, 0.74, 
    0.02, 15.16, 2.03, 0.03, 4.1, 4.3, 0.01, 2.05, 0.02, 154.08, 
    6.11, 1.04, 1.01, 0.17, 2.43, 8.18, 77.15, 0.09, 4.97, 6.04, 
    44.74, 0.08, 6.94, 2.39, 2.11, 1.13, 5.33, 4.88, 2.78, 8.07, 
    1.63, 0, 0.18, 24.09, 0.04, 1.08, 7.91, 2.11, 1.32, 6.86, 
    8.04, 1.12, 21.89, 1.22, 18.03, 0.98, 1.8, 9.34, 8.25, 2.87, 
    0.03, 6.12, 27.89, 1.78, 3.82, 0, 21.36, 5.86, 0.01, 0.01, 
    0.02, 0.07, 38.29, 89.9, 4.99, 4, 6.14, 0.02, 0, 6.06, 5.44, 
    0.01, 0.07, 0.03, 27.24, 0, 4.22, 0.04, 5.98, 0.02, 10.12, 
    95.08, 0.11, 0.17, 0.08, 12.87, 6.31, 10.89, 0.25, 0, 1.08, 
    0.26, 0, 61.47, 0.21, 3.92, 6.18, 11.4, 11.27, 0.97, 0.08, 
    1.17, 7.73, 7.02, 0.08, 1.43, 0.26, 1.14, 21.26, 0.01, 0.3, 
    1.22, 0.01, 7.24, 7.4, 0.07, 1.86, 15.29, 5.43, 1.05, 4.2, 
    0.04, 6.12, 6.96, 0.05, 0.01, 78.46, 25.93, 1.8, 0.04, 1.58, 
    8.24, 22.1, 6.67, 43.13, 2.77, 4.29, 23.01, 3.05, 0.17, 70.22, 
    23.22, 0.07, 2.07, 1.89, 13.61, 21.64, 3.74, 0.18, 18.29, 
    12.23, 8.09, 7.01, 0.92, 8.86, 9.15, 15.14, 8.16, 1.27, 0.85, 
    0.06, 0.24, 2.11, 5.3, 78.17, 1.81, 0.13, 0.37, 0.01, 20.66, 
    49.08, 3.73, 2.77, 0.32, 0.12, 36.77, 0.03, 21.49, 5.65, 
    4.74, 26.99, 0.04, 12.56, 2.25, 4.24, 1.87, 5.32, 49.12, 
    1.99, 3.98, 1.16, 0.16, 5.02, 0.1, 2.92, 34.15, 57.01, 0.29, 
    0.84, 0, 0.82, 15.27, 0.01, 5.09, 205.09, 12.02, 5.94, 0.05, 
    3.01, 2.23, 0.19, 4.97, 4.89, 0.75, 6.18, 0.88, 26.17, 7.43, 
    32.88, 1.67, 10.28, 1.08, 0.23, 11.5, 0, 4.81, 1.83, 33.09, 
    0.33, 8.75, 1.97, 0.08, 1.03, 33.74, 0.03, 4.61, 40.9, 14.69, 
    5.26, 4.72, 5.68, 0.24, 1.31, 5.86, 0.16, 0.13, 0.95, 2.23, 
    1.22, 13.94, 5.31, 0.1, 2.14, 0.16, 0.16, 5.14, 2.82, 0, 
    0.15, 7.9, 0.19, 1.12, 0.02, 22.05, 0.05, 2.12, 0, 0.31, 
    0.05, 2.84, 0.9, 5.08, 15.07, 2.21, 0.1, 0.01, 19.88, 0.02, 
    13, 20.92, 2.02, 1.15, 6.37, 0.83, 3.1, 0.85, 1.22, 0.87, 
    1.95, 7.21, 0.12, 0.11, 8.15, 0.01, 6.11, 3.01, 3.61, 0.01, 
    0.13, 0.03, 3.1, 0.08, 1, 46.36, 0.29, 21.17, 1.84, 1.01, 
    29.89, 0.98, 2.18, 0.13, 17, 3.33, 0.02, 1.01, 1.03, 0.91, 
    4.02, 0.78, 0, 8.24, 0.13, 0.05, 2.17, 1.02, 2.07, 0.07, 
    0.15, 1.36, 8.01, 1.8, 0.01, 7.13, 0, 3.9, 3.71, 3.75, 4.98, 
    36.27, 6.96, 2.88, 0.14, 4.07, 3.74, 6.4, 9.15, 8.53, 67, 
    16.3, 29.12, 10.39, 15.83, 0.35, 0.33, 28.21, 0.05, 0.01, 
    54.93, 0.17, 4.04, 3.03, 0.02, 12.07, 10.4, 0.05, 6.26, 5.75, 
    4.86, 15, 40.39, 20.11, 0.03, 0.95, 17.69, 2.43, 10.4, 3.82, 
    26.37, 5.36, 0, 0.12, 19.32, 5.25, 0.05, 0.01, 0.12, 7.01, 
    1.01, 3.87, 4.05, 5.86, 1.25, 7.22, 1.11, 0.69, 8.94, 13.89, 
    0.07, 1.05, 1.22, 0.07, 0.02, 12.85, 0.04, 12.03, 8.84, 0.99, 
    0.02, 0.14, 0.01, 5.04, 1.23, 27.99, 8.97, 24.05, 113.85, 
    20.15, 10.06, 1.15, 0.05, 12.79, 10.04, 0.1, 2.19, 0.01, 
    0.01, 18.23, 1.94, 0.31, 0.03, 7.83, 0.09, 3.41, 1.16, 0.12, 
    2.16, 2.99, 13.87, 1.15, 1, 0.96, 3.08, 6.13, 1.05, 0.06, 
    0.23, 0.07, 0.89, 1.94, 0.04, 1.01, 19.78, 1.9, 1.01, 7.11, 
    0.02, 0, 0.03, 0.07, 0.06, 8.01, 3.44, 16.77, 1.76, 1.06, 
    13.07, 1.01, 52.08, 1.02, 0.27, 0.04, 0.85, 4.15, 0.01, 0.1, 
    0.02, 10.14, 5.88, 0.01, 4.22, 53.82, 4.96, 0.1, 14.1, 0.05, 
    0.07, 32.79, 0.03, 1.4, 7.01, 15.21, 18.44, 0.07, 9.02, 6.9, 
    25.62, 2.58, 5.93, 15.02, 0.01, 16.89, 4.96, 10.14, 7.11, 
    0.11, 2.7, 4.07, 1.09, 0.06, 0.25, 0.88, 21.88, 0, 0.04, 
    23.18), severity_level = structure(c(2L, 2L, 5L, 3L, 2L, 
    5L, 5L, 2L, 2L, 2L, 5L, 5L, 5L, 3L, 3L, 3L, 3L, 3L, 5L, 2L, 
    3L, 3L, 5L, 3L, 2L, 3L, 5L, 2L, 5L, 2L, 5L, 3L, 2L, 2L, 3L, 
    3L, 3L, 3L, 5L, 3L, 2L, 5L, 5L, 5L, 2L, 2L, 2L, 3L, 3L, 3L, 
    3L, 5L, 3L, 5L, 2L, 3L, 3L, 3L, 5L, 2L, 3L, 5L, 3L, 2L, 5L, 
    3L, 2L, 3L, 3L, 2L, 2L, 2L, 3L, 2L, 2L, 5L, 3L, 3L, 3L, 3L, 
    3L, 2L, 5L, 2L, 3L, 5L, 2L, 3L, 2L, 3L, 3L, 2L, 5L, 3L, 3L, 
    5L, 5L, 3L, 3L, 2L, 3L, 5L, 3L, 2L, 3L, 5L, 3L, 5L, 5L, 3L, 
    3L, 2L, 3L, 5L, 3L, 3L, 3L, 5L, 3L, 3L, 3L, 2L, 3L, 5L, 3L, 
    5L, 3L, 3L, 2L, 3L, 3L, 3L, 5L, 3L, 5L, 5L, 2L, 5L, 5L, 2L, 
    3L, 2L, 3L, 3L, 2L, 3L, 2L, 2L, 2L, 2L, 3L, 5L, 5L, 3L, 3L, 
    3L, 5L, 5L, 3L, 2L, 3L, 5L, 2L, 2L, 3L, 3L, 2L, 5L, 5L, 3L, 
    3L, 3L, 3L, 3L, 3L, 5L, 2L, 5L, 2L, 2L, 3L, 3L, 3L, 5L, 3L, 
    2L, 3L, 3L, 2L, 5L, 5L, 3L, 2L, 5L, 3L, 5L, 5L, 3L, 3L, 2L, 
    3L, 2L, 3L, 2L, 3L, 3L, 2L, 3L, 5L, 3L, 3L, 5L, 3L, 5L, 5L, 
    2L, 3L, 2L, 5L, 3L, 5L, 3L, 3L, 3L, 3L, 5L, 5L, 3L, 3L, 5L, 
    5L, 2L, 3L, 5L, 5L, 3L, 2L, 3L, 3L, 3L, 5L, 5L, 5L, 2L, 2L, 
    5L, 5L, 5L, 5L, 3L, 2L, 3L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 3L, 
    3L, 3L, 5L, 2L, 5L, 2L, 3L, 5L, 3L, 2L, 2L, 3L, 3L, 5L, 5L, 
    2L, 3L, 3L, 2L, 3L, 2L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 3L, 3L, 
    2L, 3L, 2L, 5L, 5L, 3L, 2L, 3L, 5L, 3L, 3L, 2L, 3L, 2L, 5L, 
    5L, 2L, 5L, 5L, 3L, 2L, 3L, 3L, 3L, 3L, 5L, 3L, 2L, 2L, 3L, 
    5L, 3L, 3L, 3L, 3L, 5L, 2L, 3L, 3L, 3L, 3L, 5L, 3L, 2L, 2L, 
    3L, 2L, 5L, 2L, 5L, 2L, 3L, 3L, 5L, 3L, 3L, 5L, 3L, 2L, 5L, 
    3L, 3L, 3L, 3L, 5L, 3L, 3L, 2L, 3L, 5L, 2L, 3L, 3L, 3L, 5L, 
    2L, 3L, 3L, 2L, 5L, 2L, 5L, 3L, 3L, 2L, 3L, 2L, 2L, 2L, 2L, 
    3L, 3L, 3L, 5L, 3L, 3L, 3L, 5L, 3L, 3L, 3L, 5L, 2L, 5L, 3L, 
    3L, 2L, 5L, 2L, 3L, 2L, 2L, 3L, 3L, 3L, 5L, 2L, 2L, 3L, 3L, 
    3L, 3L, 3L, 3L, 5L, 5L, 5L, 5L, 2L, 3L, 5L, 2L, 3L, 2L, 3L, 
    5L, 2L, 3L, 2L, 5L, 3L, 5L, 3L, 3L, 3L, 5L, 5L, 3L, 5L, 2L, 
    3L, 3L, 3L, 5L, 5L, 5L, 5L, 3L, 2L, 2L, 3L, 5L, 3L, 2L, 2L, 
    2L, 2L, 3L, 5L, 2L, 3L, 3L, 5L, 2L, 5L, 3L, 3L, 2L, 5L, 2L, 
    5L, 2L, 3L, 5L, 3L, 5L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 5L, 3L, 
    3L, 5L, 5L, 5L, 3L, 3L, 5L, 3L, 2L, 2L, 3L, 3L, 2L, 2L, 5L, 
    3L, 3L, 3L, 5L, 3L, 3L, 5L, 5L, 3L, 3L, 2L, 2L, 3L, 5L, 2L, 
    3L, 2L, 3L, 2L, 2L, 5L, 5L, 3L, 2L, 3L, 3L, 2L, 3L, 5L, 3L, 
    3L, 5L, 3L, 2L, 3L, 3L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 5L, 3L, 
    3L, 2L, 3L, 3L, 2L, 3L, 5L, 3L, 5L, 5L, 5L, 3L, 3L, 2L, 3L, 
    5L, 3L, 5L, 3L, 2L, 3L, 3L, 5L, 5L, 3L, 3L, 5L, 5L, 3L, 3L, 
    3L, 3L, 2L, 3L, 2L, 2L, 2L, 2L, 5L, 2L, 2L, 5L, 2L, 2L, 2L, 
    3L, 2L, 3L, 2L, 3L, 3L, 2L, 3L, 4L, 5L, 2L, 2L, 3L, 2L, 2L, 
    5L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 5L, 2L, 3L, 2L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 2L, 3L, 3L, 2L, 3L, 5L, 3L, 
    3L, 2L, 3L, 3L, 5L, 3L, 3L, 5L, 3L, 2L, 3L, 3L, 5L, 2L, 5L, 
    5L, 5L, 3L, 5L, 5L, 2L, 5L, 3L, 2L, 2L, 5L, 5L, 5L, 3L, 3L, 
    5L, 5L, 3L, 3L, 2L, 5L, 5L, 5L, 3L, 2L, 5L, 2L, 2L, 3L, 3L, 
    5L, 3L, 3L, 2L, 3L, 3L, 3L, 2L, 3L, 2L, 2L, 5L, 5L, 3L, 5L, 
    3L, 3L, 2L, 3L, 5L, 5L, 3L, 2L, 5L, 3L, 3L, 2L, 3L, 2L, 5L, 
    2L, 2L, 2L, 5L, 5L, 2L, 3L, 2L, 2L, 5L, 2L, 2L, 5L, 3L, 3L, 
    3L, 5L, 3L, 5L, 3L, 3L, 2L, 3L, 2L, 5L, 2L, 2L, 3L, 3L, 5L, 
    3L, 3L, 5L, 3L, 2L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 
    5L, 5L, 3L, 5L, 3L, 2L, 3L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 
    5L, 2L, 3L, 3L, 2L, 3L, 2L, 3L, 5L, 3L, 2L, 3L, 3L, 2L, 2L, 
    3L, 5L, 3L, 3L, 3L, 5L, 3L, 3L, 2L, 5L, 2L, 2L, 3L, 3L, 5L, 
    3L, 2L, 3L, 3L, 3L, 2L, 5L, 5L, 5L, 3L, 3L, 2L, 3L, 3L, 2L, 
    5L, 2L, 5L, 3L, 3L, 3L, 3L, 2L, 2L, 5L, 3L, 3L, 2L, 2L, 2L, 
    3L, 2L, 5L, 2L, 3L, 2L, 2L, 3L, 3L, 2L, 2L, 3L, 2L, 3L, 3L, 
    2L, 3L, 5L, 2L, 2L, 2L, 3L, 2L, 5L, 5L, 3L, 3L, 3L, 5L, 5L, 
    2L, 3L, 5L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 3L, 5L, 2L, 5L, 3L, 
    3L, 3L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 5L, 3L, 5L, 3L, 2L, 
    5L, 3L, 5L, 5L, 3L, 5L, 3L, 5L, 3L, 2L, 3L, 3L, 5L, 3L, 3L, 
    2L, 2L, 3L, 5L, 3L, 3L, 5L, 3L, 3L, 2L, 5L, 3L, 5L, 5L, 3L, 
    2L, 3L, 3L, 2L, 5L, 3L, 3L, 2L, 3L, 3L, 5L, 2L, 3L, 3L, 3L, 
    5L, 2L, 5L, 2L, 2L, 3L, 3L, 3L, 2L, 5L, 5L, 5L, 2L, 3L, 2L, 
    2L, 5L, 3L, 5L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 3L, 5L, 
    3L, 5L, 2L, 3L, 3L, 5L, 3L, 3L, 5L, 5L, 3L, 3L, 3L, 3L, 3L, 
    5L, 3L, 3L, 3L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 
    3L, 3L, 2L, 3L, 2L), .Label = c("", "high", "medium", "no", 
    "none"), class = "factor"), case_status = structure(c(2L, 
    6L, 3L, 6L, 6L, 6L, 6L, 6L, 8L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
    3L, 3L, 6L, 8L, 6L, 6L, 8L, 4L, 6L, 6L, 6L, 4L, 6L, 6L, 6L, 
    6L, 6L, 4L, 8L, 6L, 6L, 8L, 6L, 8L, 6L, 6L, 6L, 6L, 6L, 6L, 
    8L, 8L, 6L, 8L, 6L, 6L, 10L, 6L, 6L, 6L, 8L, 6L, 6L, 6L, 
    6L, 6L, 3L, 6L, 6L, 6L, 8L, 3L, 8L, 6L, 8L, 8L, 6L, 6L, 2L, 
    6L, 6L, 6L, 6L, 6L, 6L, 6L, 8L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
    6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 8L, 6L, 6L, 6L, 6L, 4L, 
    8L, 6L, 6L, 6L, 4L, 6L, 4L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
    6L, 6L, 6L, 8L, 4L, 6L, 3L, 6L, 3L, 6L, 8L, 3L, 6L, 2L, 6L, 
    8L, 6L, 6L, 4L, 6L, 6L, 6L, 4L, 8L, 6L, 6L, 6L, 6L, 6L, 6L, 
    8L, 6L, 8L, 8L, 8L, 8L, 6L, 8L, 6L, 6L, 6L, 4L, 6L, 6L, 6L, 
    8L, 6L, 6L, 3L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
    8L, 6L, 8L, 6L, 8L, 8L, 6L, 4L, 4L, 8L, 6L, 10L, 8L, 6L, 
    6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 8L, 6L, 6L, 6L, 8L, 6L, 
    6L, 6L, 8L, 6L, 6L, 6L, 6L, 2L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
    8L, 6L, 6L, 8L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
    6L, 6L, 4L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 4L, 
    6L, 8L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 4L, 6L, 6L, 
    6L, 4L, 6L, 6L, 6L, 3L, 6L, 6L, 6L, 4L, 6L, 6L, 6L, 6L, 6L, 
    6L, 6L, 8L, 6L, 6L, 6L, 6L, 6L, 8L, 6L, 3L, 6L, 6L, 6L, 6L, 
    6L, 6L, 6L, 6L, 8L, 6L, 3L, 6L, 6L, 6L, 4L, 6L, 6L, 6L, 2L, 
    6L, 6L, 6L, 8L, 10L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 8L, 4L, 
    6L, 6L, 8L, 6L, 6L, 6L, 3L, 6L, 6L, 6L, 6L, 8L, 6L, 4L, 6L, 
    6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
    8L, 6L, 6L, 8L, 6L, 8L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 8L, 6L, 
    6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 4L, 6L, 4L, 6L, 
    6L, 8L, 8L, 6L, 6L, 6L, 8L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
    6L, 4L, 8L, 6L, 6L, 6L, 6L, 6L, 4L, 6L, 10L, 6L, 6L, 6L, 
    6L, 6L, 6L, 6L, 6L, 4L, 6L, 6L, 6L, 8L, 6L, 4L, 6L, 6L, 6L, 
    6L, 6L, 2L, 6L, 6L, 6L, 6L, 4L, 6L, 6L, 6L, 4L, 2L, 6L, 6L, 
    6L, 4L, 6L, 2L, 8L, 6L, 6L, 8L, 8L, 6L, 6L, 6L, 6L, 6L, 4L, 
    6L, 6L, 4L, 6L, 6L, 6L, 4L, 6L, 6L, 8L, 6L, 6L, 6L, 6L, 6L, 
    3L, 6L, 6L, 8L, 8L, 8L, 8L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
    6L, 6L, 8L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 8L, 6L, 2L, 
    6L, 6L, 8L, 6L, 6L, 8L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 4L, 6L, 
    8L, 6L, 6L, 6L, 6L, 6L, 8L, 6L, 3L, 4L, 6L, 6L, 6L, 3L, 8L, 
    6L, 6L, 6L, 6L, 4L, 6L, 6L, 8L, 6L, 3L, 6L, 6L, 6L, 6L, 6L, 
    6L, 6L, 6L, 6L, 6L, 6L, 6L, 4L, 6L, 6L, 6L, 6L, 8L, 6L, 6L, 
    6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 4L, 10L, 6L, 6L, 
    6L, 4L, 6L, 6L, 6L, 6L, 2L, 6L, 6L, 6L, 6L, 2L, 6L, 4L, 6L, 
    6L, 10L, 6L, 6L, 8L, 6L, 6L, 6L, 6L, 6L, 2L, 6L, 6L, 6L, 
    6L, 6L, 8L, 6L, 6L, 10L, 6L, 3L, 6L, 4L, 6L, 8L, 8L, 6L, 
    4L, 6L, 6L, 6L, 8L, 6L, 8L, 4L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
    6L, 3L, 4L, 6L, 8L, 6L, 8L, 8L, 2L, 4L, 6L, 6L, 4L, 6L, 6L, 
    6L, 6L, 6L, 4L, 6L, 6L, 6L, 6L, 8L, 3L, 8L, 4L, 6L, 6L, 8L, 
    4L, 6L, 2L, 4L, 8L, 6L, 6L, 4L, 6L, 6L, 8L, 2L, 6L, 6L, 6L, 
    8L, 8L, 6L, 6L, 6L, 8L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
    6L, 10L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 8L, 6L, 
    8L, 8L, 6L, 8L, 8L, 6L, 6L, 6L, 6L, 6L, 8L, 8L, 8L, 4L, 3L, 
    6L, 6L, 6L, 6L, 6L, 8L, 6L, 6L, 6L, 4L, 6L, 6L, 6L, 6L, 6L, 
    4L, 6L, 4L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 8L, 8L, 6L, 6L, 6L, 
    6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 8L, 6L, 6L, 6L, 6L, 
    4L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 8L, 6L, 8L, 8L, 6L, 8L, 
    8L, 6L, 6L, 6L, 6L, 6L, 8L, 6L, 6L, 8L, 6L, 6L, 4L, 6L, 6L, 
    6L, 6L, 4L, 6L, 6L, 6L, 6L, 10L, 6L, 4L, 8L, 6L, 6L, 6L, 
    6L, 6L, 8L, 8L, 8L, 6L, 6L, 6L, 6L, 6L, 6L, 2L, 6L, 6L, 3L, 
    3L, 10L, 6L, 4L, 6L, 6L, 6L, 2L, 6L, 6L, 4L, 6L, 4L, 6L, 
    6L, 4L, 6L, 10L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 8L, 6L, 6L, 
    6L, 6L, 2L, 6L, 4L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 4L, 3L, 
    8L, 8L, 6L, 8L, 6L, 6L, 6L, 6L, 6L, 4L, 6L, 6L, 8L, 6L, 6L, 
    6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 4L, 6L, 6L, 6L, 6L, 8L, 6L, 
    8L, 6L, 6L, 6L, 6L, 6L, 4L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 4L, 
    6L, 6L, 2L, 6L, 6L, 6L, 6L, 6L, 6L, 8L, 6L, 6L, 6L, 8L, 8L, 
    4L, 6L, 8L, 6L, 6L, 6L, 6L, 2L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
    2L, 6L, 8L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
    6L, 6L, 6L, 6L, 6L, 6L, 4L, 8L, 6L, 4L, 10L, 6L, 6L, 6L, 
    6L, 6L, 6L, 6L, 6L, 6L, 8L, 6L, 8L, 6L, 6L, 6L, 8L, 6L, 6L, 
    6L, 8L, 8L, 6L, 6L, 2L), .Label = c("", "closed", "no resp", 
    "oos", "pending", "Resolved", "routed", "self closed", "Working", 
    "yes"), class = "factor"), account_segment = structure(c(4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
    6L, 6L, 6L, 6L, 6L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
    5L, 5L, 5L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L), .Label = c("", "-", "Flagship", 
    "Large", "Low", "Medium", "Mega", "N/A", "Platinum", "Small", 
    "Top", "Very Small"), class = "factor"), sla_status = structure(c(2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("", "Met", 
    "Missed", "N/A", "Pending"), class = "factor"), survey = c(1L, 
    1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 
    0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 
    1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    0L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 
    1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 
    1L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 
    1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 
    1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 
    1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 
    1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 
    1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 
    0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 
    1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 
    1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 
    0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 
    1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 
    1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 
    1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 
    1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 
    1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 
    1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 
    1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 
    1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 
    1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 
    1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 
    1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 
    0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 
    0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 
    1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 
    1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 
    0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 
    1L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 
    1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L), repS = c(1L, 1L, 0L, 
    1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 
    1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 
    0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 
    1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 
    0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 
    1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 
    NA, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 
    0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 0L, 0L, NA, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 
    0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, NA, 1L, 1L, 1L, 0L, 
    1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 
    1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 
    1L, 1L, NA, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, NA, NA, 
    0L, 0L, NA, 1L, 1L, 1L, 1L, NA, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 
    0L, 1L, 1L, NA, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 
    0L, 1L, 1L, 1L, NA, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, NA, 1L, 1L, 1L, 1L, 0L, 0L, 
    1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 
    1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, NA, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, NA, 1L, 1L, 1L, 1L, 1L, 
    1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 
    1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 
    NA, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 
    1L, 0L, 1L, 0L, 1L, 1L, 0L, NA, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 
    0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 
    0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 0L, 1L, 1L, NA, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 
    1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 
    1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 
    1L, NA, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 1L, 
    1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, NA, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 0L, 0L, 0L, 1L, NA, 1L, 1L, NA, 0L, NA, 1L, 1L, 1L, 
    1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 0L, NA, 1L, 1L, 0L, NA, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, NA, 1L, NA, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, NA, 1L, 1L, NA, 1L, 0L, 1L, 1L, 1L, 
    1L, 1L, 1L, 0L, 1L, 1L, 1L, NA, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 
    1L, 0L, NA, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, NA, 0L, 
    1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 
    1L, NA, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 
    NA, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, NA, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, NA, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, NA, 1L, 1L, 
    1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 
    1L, 1L, 1L, 1L, 1L, 0L, NA, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 0L)), .Names = c("support_cat", "region", 
"support_lvl", "skill_group", "application_area", "functional_area", 
"score", "rep_score", "product_know", "understanding_issue", 
"case_age", "severity_level", "case_status", "account_segment", 
"sla_status", "survey", "repS"), row.names = c(NA, 1000L), class = "data.frame")

From chiarosscuro at gmail.com  Fri Aug 12 20:42:21 2016
From: chiarosscuro at gmail.com (chiarosscuro)
Date: Fri, 12 Aug 2016 14:42:21 -0400
Subject: [R] Parallelize lme4
Message-ID: <CAD0Owz2uDLNxAWUVve_B_=Dg_+phzgxaSzXpOq5VbC+Up4Kb+w@mail.gmail.com>

Hi all,

In using the lme4 package to construct multi-level models, I notice that
for large datasets (~300000 data points, >100 groups, possibly cross/nested
effects) model fitting can be very slow (>2 hours).  I have even larger
data sets that I'd like to model, but hesitate due to concerns about run
time.

To that end, is it possible to parallelize/multithread lme4?
Alternatively, can SparkR be configured to run lme4?  Finally, if neither
is possible, what can be done to speed up lme4?

Thanks,
Sue

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Aug 12 21:37:00 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 Aug 2016 12:37:00 -0700
Subject: [R] glm.fit: fitted probabilities numerically 0 or 1 occurred &
	glm.fit: algorithm did not converge
In-Reply-To: <CAB=p7So=nDpoDHB7KoC8SM3+LfBUJ5=XnYV7iOdH9wjCTYyKAQ@mail.gmail.com>
References: <CAB=p7SreQJRULZ-j3mDmJk5vWAMRaM1b66WYy5k9Kd=sWD3rDQ@mail.gmail.com>
	<7a804ec9-ea4f-8c83-1104-01f3f7959b99@dewey.myzen.co.uk>
	<CAB=p7SoRxiW4EQvAr3K2aGXBknMu_Y7xoFbdefrJfS=jRfmdug@mail.gmail.com>
	<CAGxFJbSW3YrXuOHHS-t_05VzeetWLNbaH_cfVe76_cgR-UrRcA@mail.gmail.com>
	<CAB=p7Sq2zV4PaNVXwZbQCbzVjfLL9We-zSixxzpr_c52aYYKhQ@mail.gmail.com>
	<CAB=p7SrfaKJ43ZXew4SnkOFcv+PGRqi6ZowROm_s7W+mvZUD=g@mail.gmail.com>
	<d8c87fd4-a8c8-5640-490d-3a8d28d9b671@dewey.myzen.co.uk>
	<CAB=p7So=nDpoDHB7KoC8SM3+LfBUJ5=XnYV7iOdH9wjCTYyKAQ@mail.gmail.com>
Message-ID: <BE31807D-4085-44EE-92B2-AA983B84868D@comcast.net>


> On Aug 12, 2016, at 11:32 AM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
> 
> Hi Michael,
> 
> In all the masking process some of the variables were missed. Please find
> the updated file.
> 
> Also here is the updated code: (i am removed one of the var as it had
> missing information):
> 
> glm.fit= glm(survey ~ support_cat + region+ support_lvl+ skill_group+
> application_area+ functional_area+
>          repS+ case_age+ case_status+ severity_level+
>          sla_status, data = new, family = binomial)

I think you need to do some more data cleaning:

> with(new, table(survey, repS, severity_level) )
, , severity_level = 

      repS
survey   0   1
     0   0   0
     1   0   0

, , severity_level = high

      repS
survey   0   1
     0  52  18
     1   4 193

, , severity_level = medium

      repS
survey   0   1
     0  69  16
     1   7 367

, , severity_level = no

      repS
survey   0   1
     0   0   0
     1   0   1

, , severity_level = none

      repS
survey   0   1
     0  31  19
     1   4 183

-- 
David.


> Kindly assist with the same.
> 
> On Fri, Aug 12, 2016 at 11:05 PM, Michael Dewey <lists at dewey.myzen.co.uk>
> wrote:
> 
>> Your example code refers to a variable which is not in your dataset (repS)
>> so I get an error message. If I assume repS is in fact rep_score I get
>> another variable not found (delivery_segmentation).
>> 
>> I am afraid that I am unable to sort that one out so this is going to
>> remain a mystery. I endorse Bert's suggestion of getting local help.
>> 
>> On 12/08/2016 17:24, Shivi Bhatia wrote:
>> 
>>> Hi Bert,
>>> 
>>> Does this text file help. Apologies if this does not help as i have a
>>> hard time on many occasions to get a reproducible example.
>>> 
>>> If this doesn't work a CSV with only 100kb of data i can share.
>>> 
>>> Regards, Shivi
>>> 
>>> On Fri, Aug 12, 2016 at 8:50 PM, Shivi Bhatia <shivipmp82 at gmail.com
>>> <mailto:shivipmp82 at gmail.com>> wrote:
>>> 
>>>    Sure Burt, i will share the data after masking it.  it isn't big
>>> 
>>>    regards, Shivi
>>> 
>>>    On Fri, Aug 12, 2016 at 8:36 PM, Bert Gunter <bgunter.4567 at gmail.com
>>>    <mailto:bgunter.4567 at gmail.com>> wrote:
>>> 
>>>        1. No, changing to factor will make no difference.
>>> 
>>>        2. I think that most likely your problem is your model is not
>>>        estimable/your design matrix is singular.  You should resolve
>>>        this by
>>>        consulting with a local statistical expert or, if your data set
>>>        is not
>>>        too large or confidential, posting your full dataset using
>>>        dput() (see
>>>        ?dput for how to do this).
>>> 
>>>        Cheers,
>>>        Bert
>>>        Bert Gunter
>>> 
>>>        "The trouble with having an open mind is that people keep coming
>>>        along
>>>        and sticking things into it."
>>>        -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>>        On Fri, Aug 12, 2016 at 7:58 AM, Shivi Bhatia
>>>        <shivipmp82 at gmail.com <mailto:shivipmp82 at gmail.com>> wrote:
>>>> Hi Michael,
>>>> 
>>>> There is no output as the model does not generate any
>>>        coefficients and
>>>> simply throws this error.
>>>> 
>>>> I hope you are not asking for a reproducible example.
>>>> 
>>>> On Fri, Aug 12, 2016 at 7:30 PM, Michael Dewey
>>>        <lists at dewey.myzen.co.uk <mailto:lists at dewey.myzen.co.uk>>
>>> 
>>>> wrote:
>>>> 
>>>>> Dear Shivi
>>>>> 
>>>>> Can you show us the output?
>>>>> 
>>>>> And please do not post in HTML as it will mangle your post into
>>>>> unreadability.
>>>>> 
>>>>> On 12/08/2016 10:10, Shivi Bhatia wrote:
>>>>> 
>>>>>> Hi Team,
>>>>>> 
>>>>>> I am creating *my first* Logistic regression on R Studio. I
>>>        am working on
>>>>>> a
>>>>>> 
>>>>>> C-SAT data where rating (score) 0-8 is a dis-sat whereas
>>>        9-10 are SAT. As
>>>>>> these were in numeric form so i had as below created 2
>>> classes:
>>>>>> 
>>>>>> new$survey[new$score>=0 & new$score<=8]<- 0
>>>>>> new$survey[new$score>=9]<- 1
>>>>>> This works fine however the class still shows as "numeric"
>>>        and levels
>>>>>> shows
>>>>>> as "NULL". Do i still need to use "as.factor" to let R know
>>>        these are
>>>>>> categorical variables.
>>>>>> 
>>>>>> Also i have used the below code to run a logistic regression
>>>        with all the
>>>>>> possible predictor variables:
>>>>>> glm.fit= glm(survey ~ support_cat + region+ support_lvl+
>>>        skill_group+
>>>>>> application_area+ functional_area+
>>>>>>          repS+ case_age+ case_status+ severity_level+
>>>>>>          sla_status+ delivery_segmentation, data = SFDC,
>>>        family =
>>>>>> binomial)
>>>>>> 
>>>>>> But it throws an error:-
>>>>>> Warning messages:
>>>>>> 1: glm.fit: algorithm did not converge
>>>>>> 2: glm.fit: fitted probabilities numerically 0 or 1 occurred
>>>>>> 
>>>>>> I checked online for the error and it says:
>>>>>> "glm() uses an iterative re-weighted least squares
>>>        algorithm. The
>>>>>> algorithm
>>>>>> hit the maximum number of allowed iterations before signalling
>>>>>> convergence.
>>>>>> The default,
>>>>>> documented in ?glm.control is 25."
>>>>>> 
>>>>>> Kindly suggest on the above case and if i have to change my
>>>        outcome var as
>>>>>> as.factor.
>>>>>> 
>>>>>> Thank you, Shivi
>>>>>> 
>>>>>>        [[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>>        list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>        <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posti
>>>>>> ng-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible
>>>        code.
>>>>>> 
>>>>>> 
>>>>> --
>>>>> Michael
>>>>> http://www.dewey.myzen.co.uk/home.html
>>>        <http://www.dewey.myzen.co.uk/home.html>
>>>>> 
>>>> 
>>>>        [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>>        list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>        <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>> PLEASE do read the posting guide
>>>        http://www.R-project.org/posting-guide.html
>>>        <http://www.R-project.org/posting-guide.html>
>>>> and provide commented, minimal, self-contained, reproducible
>>> code.
>>> 
>>> 
>>> 
>>> 
>> --
>> Michael
>> http://www.dewey.myzen.co.uk/home.html
>> 
> <saved.txt>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Fri Aug 12 22:10:15 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 12 Aug 2016 13:10:15 -0700
Subject: [R] Adding loess lines subsetting to each panel in lattice plot
In-Reply-To: <676905760.22528506.1471018231218.JavaMail.yahoo@mail.yahoo.com>
References: <676905760.22528506.1471018231218.JavaMail.yahoo.ref@mail.yahoo.com>
	<676905760.22528506.1471018231218.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbScd9c0JFRqoO8T0WB3SzD4Nc0jkpVT8TmwwVs8j+MVAg@mail.gmail.com>

Try reading ?panel.loess. There is no "subset" argument, so it is of
course ignored.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 12, 2016 at 9:10 AM, Juan Perez via R-help
<r-help at r-project.org> wrote:
> Hello, I've created an xyplot and I want to add a loess line for x (Age)  <=40 and another for values >40. In a way it is similar to this https://stat.ethz.ch/pipermail/r-help/2009-May/390502.html but still not succcessful.
> This is my try:
>
> xyplot(MOE~Age|Species, groups=Site,
>        panel = function(x, y, groups=groups,...) {
>         panel.xyplot(x, y, groups=groups,...)
>         panel.loess(x,y,subset = x <= 40, col="black")         panel.loess(x,y,subset = x >40, col="red")
>               })
> When I run the code it "works" but it plots the loess line for all the data, without subsetting.Any suggestion?
> Thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jwd at surewest.net  Sat Aug 13 01:50:22 2016
From: jwd at surewest.net (John Dougherty)
Date: Fri, 12 Aug 2016 16:50:22 -0700
Subject: [R] R Package installation
In-Reply-To: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C31F@USCTMXP51002.merck.com>
References: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C31F@USCTMXP51002.merck.com>
Message-ID: <20160812165022.2cf3a7d0@draco>

On Fri, 12 Aug 2016 06:53:03 -0400
"Dayalan, Nithya" <nithya.dayalan at merck.com> wrote:

You don't say what OS you are using, though the packages you were
trying to obtain are apparently for Windows.  You also don't say
whether you are using something like R-Studio, or whether you are on a
company network behind a firewall.

If you have a sysop, you probably should be going through him or her.
There's a very good chance that your system is lacking in permissions.
Your network's settings are problem, or Windows or a recent update may
be causing your trouble. You should also simply try opening the specific
mirror URL sans the package info to see if you can see the page.  

-- 

John


From jdnewmil at dcn.davis.ca.us  Sat Aug 13 02:07:17 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 12 Aug 2016 17:07:17 -0700
Subject: [R] R Package installation
In-Reply-To: <20160812165022.2cf3a7d0@draco>
References: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C31F@USCTMXP51002.merck.com>
	<20160812165022.2cf3a7d0@draco>
Message-ID: <652C2502-C5A4-40A4-95BC-BD2DC72B8A24@dcn.davis.ca.us>

This may not have anything to do with the OP's problem, but if permissions are an issue then it should be mentioned. 

One problem that some windows users encounter is thinking they should "Run As"  administrator when installing or running R, rather than letting Windows UAE prompt them for privilege escalation as needed. 

The side effect of such an action is that (most? all?) files touched by R then become usable only by R running as administrator, and all sorts of weird problems ensue. It is much better to avoid ever running as administrator and updating all packages into the user-specific package library as needed, with the system-wide package library updated only when R is upgraded. 
-- 
Sent from my phone. Please excuse my brevity.

On August 12, 2016 4:50:22 PM PDT, John Dougherty <jwd at surewest.net> wrote:
>On Fri, 12 Aug 2016 06:53:03 -0400
>"Dayalan, Nithya" <nithya.dayalan at merck.com> wrote:
>
>You don't say what OS you are using, though the packages you were
>trying to obtain are apparently for Windows.  You also don't say
>whether you are using something like R-Studio, or whether you are on a
>company network behind a firewall.
>
>If you have a sysop, you probably should be going through him or her.
>There's a very good chance that your system is lacking in permissions.
>Your network's settings are problem, or Windows or a recent update may
>be causing your trouble. You should also simply try opening the
>specific
>mirror URL sans the package info to see if you can see the page.


From divakarreddy.a at gmail.com  Sat Aug 13 02:44:55 2016
From: divakarreddy.a at gmail.com (Divakar Reddy)
Date: Fri, 12 Aug 2016 17:44:55 -0700
Subject: [R] R Package installation
In-Reply-To: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C31F@USCTMXP51002.merck.com>
References: <91DFE13BB89B4F49ADA450B375D0A5AC91A974C31F@USCTMXP51002.merck.com>
Message-ID: <CALEm3d1Jxdqj6JoDLdtFLswPY-jQ5ArOM+Y4=D9WxT+dX_fn+A@mail.gmail.com>

parallel is R's base package and it's already installed with base R.

 check in below location:
/usr/lib64/R/library/

Thanks,
Divakar

On Fri, Aug 12, 2016 at 3:53 AM, Dayalan, Nithya <nithya.dayalan at merck.com>
wrote:

> Hi Team,
>
> We are receiving the below message while updating the package. Please help.
>
> > install.packages("parallel", lib="D:/Program Files/R/R-3.2.5/library")
> Warning: unable to access index for repository https://cran.fhcrc.org/src/
> contrib:
>   cannot open URL 'https://cran.fhcrc.org/src/contrib/PACKAGES'
> Warning: unable to access index for repository
> http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
>   cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES
> '
> Warning: unable to access index for repository https://cran.fhcrc.org/bin/
> windows/contrib/3.2:
>   cannot open URL 'https://cran.fhcrc.org/bin/windows/contrib/3.2/PACKAGES
> '
> Warning: unable to access index for repository
> http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2:
>   cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/
> 3.2/PACKAGES'
> Warning messages:
> 1: package 'parallel' is not available (for R version 3.2.5)
> 2: package 'parallel' is a base package, and should not be updated
> >
>
>
> Thanks & Regards,
> Nithya Dayalan
> AMS MRL DPS | HCL @ Merck
> E-mail: nithya.dayalan at merck.com<mailto:nithya.dayalan at merck.com>
> Tel#+91 44 61053951| Mobile +91 8754232975
>
> Notice:  This e-mail message, together with any attachme...{{dropped:14}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ranjanagirish30 at gmail.com  Sat Aug 13 12:38:42 2016
From: ranjanagirish30 at gmail.com (Ranjana Girish)
Date: Sat, 13 Aug 2016 16:08:42 +0530
Subject: [R] regarding Fselector package in R
Message-ID: <CAF5P65==1L8vgeGtu336K8_aCDZF4C8hNXjcD1zACaWjXCLv3Q@mail.gmail.com>

I need to calculate information gain using Fselector package for feature
selection ti classify document
i executed the code below

library(tm)
library(NLP)
 library(FSelector)
doc<-c( "The sky is blue.", "The sun is bright today.",
          "The sun in the sky is bright.","We can see the shining sun, the
bright sun.")
doc_corpus <- Corpus( VectorSource( doc ) )
control_list <- list( removePunctuation = TRUE, stopwords = TRUE, tolower =
TRUE )
tdm <- TermDocumentMatrix( doc_corpus, control = control_list )
( tf <- as.matrix(tdm ) )
tf
tf1<-t(tf)
tfdataframe<-data.frame(tf1)
tfdataframe
tfdataframe$doc<-c("1","2","3","4")
tfdataframe
#information gain based on term frequency
infgain <- information.gain(doc~.,tfdataframe )
infgain

and i got output

> infgain
        attr_importance
blue          0.0000000
bright        0.0000000
can           0.0000000
see           0.0000000
shining       0.0000000
sky           0.6931472
sun           0.0000000
today         0.0000000
>
is this output is logically correct??

I am totally confused!!!!!!!!!

could anyone help me please

Thanks in advance

	[[alternative HTML version deleted]]


From beire55 at yahoo.es  Sat Aug 13 15:31:50 2016
From: beire55 at yahoo.es (Juan Perez)
Date: Sat, 13 Aug 2016 13:31:50 +0000 (UTC)
Subject: [R] Adding loess lines subsetting to each panel in lattice plot
In-Reply-To: <CAGxFJbScd9c0JFRqoO8T0WB3SzD4Nc0jkpVT8TmwwVs8j+MVAg@mail.gmail.com>
References: <676905760.22528506.1471018231218.JavaMail.yahoo.ref@mail.yahoo.com>
	<676905760.22528506.1471018231218.JavaMail.yahoo@mail.yahoo.com>
	<CAGxFJbScd9c0JFRqoO8T0WB3SzD4Nc0jkpVT8TmwwVs8j+MVAg@mail.gmail.com>
Message-ID: <1279776472.23625175.1471095110158.JavaMail.yahoo@mail.yahoo.com>

Thanks Bert
I am not sure what you meant by reading though.
I managed to sort this out, although ideally would exist a better solution. I have created a column in my dataset, and given two codes depending whether older or younger than 40. Afterwards I have applied
xyplot(MOE~Age|Species, groups=Old,
?????? panel= function(x,y,...){? ## custom panel function to add an overall loess line
???????? panel.superpose(x,y,...)
???????? panel.loess(x,y,col="black",lwd=2,...)
?????? },
?????? panel.groups = function(x,y,...){
???????? panel.xyplot(x,y,...)
???????? panel.loess(x,y,...)
?????? }) 

This gives a loess line for data younger than 40, another for the ones older, and a third one for all the data. I hope this helps to someone else. Unfortunately, the dataset needs to be modified everytime we want to make a new or different subset.
Best regards
 

    El Viernes 12 de agosto de 2016 21:10, Bert Gunter <bgunter.4567 at gmail.com> escribi?:
 

 Try reading ?panel.loess. There is no "subset" argument, so it is of
course ignored.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 12, 2016 at 9:10 AM, Juan Perez via R-help
<r-help at r-project.org> wrote:
> Hello, I've created an xyplot and I want to add a loess line for x (Age)? <=40 and another for values >40. In a way it is similar to this https://stat.ethz.ch/pipermail/r-help/2009-May/390502.html but still not succcessful.
> This is my try:
>
> xyplot(MOE~Age|Species, groups=Site,
>? ? ? ? panel = function(x, y, groups=groups,...) {
>? ? ? ? panel.xyplot(x, y, groups=groups,...)
>? ? ? ? panel.loess(x,y,subset = x <= 40, col="black")? ? ? ? panel.loess(x,y,subset = x >40, col="red")
>? ? ? ? ? ? ? })
> When I run the code it "works" but it plots the loess line for all the data, without subsetting.Any suggestion?
> Thank you
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From jan.kacaba at gmail.com  Sat Aug 13 22:02:57 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Sat, 13 Aug 2016 22:02:57 +0200
Subject: [R] R Studio: Run script upon saving or exiting
Message-ID: <CAHby=D1qb7pGtFyHgrx3U1aB_n5Xmj9pbzvy95Ty8Q69Ykmz-w@mail.gmail.com>

Dear R help,

I would like to run script upon saving project files or exiting the R Studio.
For example I would like to backup whole project in another directory.
The backup directory should be named such that incremental version
number will added to project name.

Is it somehow possible?  Even better would be if someone can also
quickly go through file versions.


From murdoch.duncan at gmail.com  Sat Aug 13 22:07:19 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 13 Aug 2016 16:07:19 -0400
Subject: [R] R Studio: Run script upon saving or exiting
In-Reply-To: <CAHby=D1qb7pGtFyHgrx3U1aB_n5Xmj9pbzvy95Ty8Q69Ykmz-w@mail.gmail.com>
References: <CAHby=D1qb7pGtFyHgrx3U1aB_n5Xmj9pbzvy95Ty8Q69Ykmz-w@mail.gmail.com>
Message-ID: <f3c0d91b-1d51-9039-4755-b6771986c609@gmail.com>

On 13/08/2016 4:02 PM, Jan Kacaba wrote:
> Dear R help,
>
> I would like to run script upon saving project files or exiting the R Studio.
> For example I would like to backup whole project in another directory.
> The backup directory should be named such that incremental version
> number will added to project name.
>
> Is it somehow possible?  Even better would be if someone can also
> quickly go through file versions.
>

You should be asking RStudio questions on one of their support forums.

Regarding the backups:  I recommend that you use a version control 
system (e.g. svn or git) as an efficient way to do that.

Duncan Murdoch


From luca.cerone at gmail.com  Sun Aug 14 11:23:24 2016
From: luca.cerone at gmail.com (Luca Cerone)
Date: Sun, 14 Aug 2016 11:23:24 +0200
Subject: [R] Help with non standard evaluation and require function
In-Reply-To: <6B4D2CEE-595E-4D44-9DFE-229997A9FB9F@comcast.net>
References: <CAFnz2-_biFmzaf0EPwV+BPN8oFq-Fa4nz7X=ONjrQzbaVR-Yzw@mail.gmail.com>
	<6B4D2CEE-595E-4D44-9DFE-229997A9FB9F@comcast.net>
Message-ID: <CAFnz2-_m65CJBwu0Sk2ncSKmp_ied9jZ5K9-iO_L0GQoUy_WAQ@mail.gmail.com>

Hi David and Duncan,
thanks for your answers!

I think what is not clear to me is actually how "substitute" works.

If I run require (dplyr) or require("dplyr") in the R console everything
works as I expect even without the character.only=T (actually because of
this I always interpreted that character.only=F means you can either use
nse or strings while with character.only=T you can only use strings).

What I don't understand is why in the require function

as.character (substitute(package))

returns "pkgname" (the name of the variable I use in my function) rather
than substituting the value of pkgname i.e. dplyr in my example.

I have no access to my laptop so I can't double check but I think in one of
Wickham's book there was an example like

f <- function (y) {
  substitute (x + y)
}

f(4)
[1] x + 4

i.e. where substitute inside a function was substituting the value of y and
returned the expression replacing y with 4, which is what I would expect to
happen.

It is probaby a very trivial problem but I find hard to figure out ho
substitute works.

Thanks a lot again for the help!
Cheers,
Luca

On Aug 12, 2016 20:14, "David Winsemius" <dwinsemius at comcast.net> wrote:

>
> > On Aug 12, 2016, at 8:57 AM, Luca Cerone <luca.cerone at gmail.com> wrote:
> >
> > Hi everybody,
> > I am having a hard time in understanding how to deal with non standard
> > evaluation and the require function.
> >
> > I asked about it on Stackoverflow at
> > http://stackoverflow.com/questions/38922012/r-function-
> to-install-missing-packages,
> > below you can find my question.
>
> It was already explained and teh code of `require provided: `substitute`
> does not lookup values in the symbol table so the symbol: `pkgname` is
> converted by `as.character` to "pkgname", .... unless 'character.only' is
> TRUE.
>
> What part of that is not understood?
>
> --
> David.
> >
> > Thanks a lot for the help!
> > Cheers,
> > Luca
> >
> > For one of my scripts I want to write an R function that checks if a
> > package is already installed: if so it should use library() to import
> > it in the namespace, otherwise it should install it and import it.
> >
> > I assumed that pkgname is a string and tried to write something like:
> >
> > ensure_library <- function(pkgname) {
> >  if (!require(pkgname)) {
> >    install.packages(pkgname, dependencies = TRUE)
> >  }
> >  require(pkgname)
> > }
> >
> > As simple as is this function does not work. If I try to run it like
> > ensure_library("dplyr") it installs the package dplyr but then it
> > fails because it trys to import pkgname rather than dplyr in the
> > namespace.
> >
> > ensure_library("dplyr")
> > Loading required package: pkgname
> > Installing package into ?/home/luca/R-dev?
> > (as ?lib? is unspecified)
> > trying URL 'https://cran.rstudio.com/src/contrib/dplyr_0.5.0.tar.gz'
> > Content type 'application/x-gzip' length 708476 bytes (691 KB)
> > ==================================================
> > downloaded 691 KB
> >
> > * installing *source* package ?dplyr? ...
> > ** package ?dplyr? successfully unpacked and MD5 sums checked
> > ** libs
> >
> > .... a lot of compiling here....
> >
> > installing to /home/luca/R-dev/dplyr/libs
> > ** R
> > ** data
> > *** moving datasets to lazyload DB
> > ** inst
> > ** preparing package for lazy loading
> > ** help
> > *** installing help indices
> > ** building package indices
> > ** installing vignettes
> > ** testing if installed package can be loaded
> > * DONE (dplyr)
> >
> > The downloaded source packages are in
> >    ?/tmp/Rtmpfd2Lep/downloaded_packages?
> > Loading required package: pkgname
> > Warning messages:
> > 1: In library(package, lib.loc = lib.loc, character.only = TRUE,
> > logical.return = TRUE,  :
> >  there is no package called ?pkgname?
> > 2: In library(package, lib.loc = lib.loc, character.only = TRUE,
> > logical.return = TRUE,  :
> >  there is no package called ?pkgname?
> >
> > Also, if I now re-run it it will install dplyr once again.
> >
> > I realize this is probably due to R non-standard-evaluation and I have
> > tried several combination of eval/substitute/quote in order to make it
> > work with require but I couldn't succeed.
> >
> > Can somebody help me understanding what is going on and if there is
> > some easy-fix?
> >
> > If a function already implementing this exists I would like to know,
> > but what I am really interested is understanding why my code does not
> > work as intended.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sun Aug 14 11:46:59 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 14 Aug 2016 11:46:59 +0200
Subject: [R] Help with non standard evaluation and require function
In-Reply-To: <CAFnz2-_m65CJBwu0Sk2ncSKmp_ied9jZ5K9-iO_L0GQoUy_WAQ@mail.gmail.com>
References: <CAFnz2-_biFmzaf0EPwV+BPN8oFq-Fa4nz7X=ONjrQzbaVR-Yzw@mail.gmail.com>
	<6B4D2CEE-595E-4D44-9DFE-229997A9FB9F@comcast.net>
	<CAFnz2-_m65CJBwu0Sk2ncSKmp_ied9jZ5K9-iO_L0GQoUy_WAQ@mail.gmail.com>
Message-ID: <6F9503E1-41A0-4FE1-9498-71DCBE5FFE2A@gmail.com>


> On 14 Aug 2016, at 11:23 , Luca Cerone <luca.cerone at gmail.com> wrote:
> 
> I have no access to my laptop so I can't double check but I think in one of
> Wickham's book there was an example like
> 
> f <- function (y) {
>  substitute (x + y)
> }
> 
> f(4)
> [1] x + 4
> 
> i.e. where substitute inside a function was substituting the value of y and
> returned the expression replacing y with 4, which is what I would expect to
> happen.
> 

In a word: no.

> f <- function (y) {
+  substitute (x + y)
+ }
> 
> f(4)
x + 4
> f(z)
x + z

i.e., it is not the value of y, but the expression passed for y that gets substituted.

There are subtleties: If y is computed inside the function, the connection to the argument expression is lost, and then the value is in fact used:

> z <- pi
> f <- function (y) { y <- y
+  substitute (x + y)
+ }
> f(z)
x + 3.14159265358979

It is usually a better idea to handle these issues with bquote(), though.


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Sun Aug 14 12:23:08 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 14 Aug 2016 06:23:08 -0400
Subject: [R] Help with non standard evaluation and require function
In-Reply-To: <CAFnz2-_m65CJBwu0Sk2ncSKmp_ied9jZ5K9-iO_L0GQoUy_WAQ@mail.gmail.com>
References: <CAFnz2-_biFmzaf0EPwV+BPN8oFq-Fa4nz7X=ONjrQzbaVR-Yzw@mail.gmail.com>
	<6B4D2CEE-595E-4D44-9DFE-229997A9FB9F@comcast.net>
	<CAFnz2-_m65CJBwu0Sk2ncSKmp_ied9jZ5K9-iO_L0GQoUy_WAQ@mail.gmail.com>
Message-ID: <ef7b85d3-5362-e822-2a91-8c32499ba5a2@gmail.com>

On 14/08/2016 5:23 AM, Luca Cerone wrote:
> Hi David and Duncan,
> thanks for your answers!
>
> I think what is not clear to me is actually how "substitute" works.

Arguments passed to R functions become a special kind of object known as 
a "promise".  Promises contain two things:  the expression to evaluate, 
and the value of the expression.  The value isn't set at first.  It is 
set by evaluating the expression when you use the argument as a regular 
variable in an expression for the first time.  After that every use of 
it returns the same value, but the expression is retained.

When you call substitute() on an argument "arg", it returns the 
expression.  substitute() also works on other kinds of objects that 
aren't promises; it generally returns their value.  When you use it on a 
complex expression, it returns a new expression with undefined variables 
left alone, recognized variables substituted.

>
> If I run require (dplyr) or require("dplyr") in the R console everything
> works as I expect even without the character.only=T (actually because of
> this I always interpreted that character.only=F means you can either use
> nse or strings while with character.only=T you can only use strings).

I think your interpretation is right.

>
> What I don't understand is why in the require function
>
> as.character (substitute(package))
>
> returns "pkgname" (the name of the variable I use in my function) rather
> than substituting the value of pkgname i.e. dplyr in my example.

The expression in the promise "package" is the expression "pkgname" 
(without quotes).

>
> I have no access to my laptop so I can't double check but I think in one of
> Wickham's book there was an example like
>
> f <- function (y) {
>   substitute (x + y)
> }
>
> f(4)
> [1] x + 4
>
> i.e. where substitute inside a function was substituting the value of y and
> returned the expression replacing y with 4, which is what I would expect to
> happen.

That's not the value of y, it's the expression in y (which will be the 
same once it is evaluated).  Peter gave an example where they differ, 
here's another:

 > f(1+2)
x + (1 + 2)

Duncan Murdoch

>
> It is probaby a very trivial problem but I find hard to figure out ho
> substitute works.
>
> Thanks a lot again for the help!
> Cheers,
> Luca
>
> On Aug 12, 2016 20:14, "David Winsemius" <dwinsemius at comcast.net> wrote:
>
>>
>>> On Aug 12, 2016, at 8:57 AM, Luca Cerone <luca.cerone at gmail.com> wrote:
>>>
>>> Hi everybody,
>>> I am having a hard time in understanding how to deal with non standard
>>> evaluation and the require function.
>>>
>>> I asked about it on Stackoverflow at
>>> http://stackoverflow.com/questions/38922012/r-function-
>> to-install-missing-packages,
>>> below you can find my question.
>>
>> It was already explained and teh code of `require provided: `substitute`
>> does not lookup values in the symbol table so the symbol: `pkgname` is
>> converted by `as.character` to "pkgname", .... unless 'character.only' is
>> TRUE.
>>
>> What part of that is not understood?
>>
>> --
>> David.
>>>
>>> Thanks a lot for the help!
>>> Cheers,
>>> Luca
>>>
>>> For one of my scripts I want to write an R function that checks if a
>>> package is already installed: if so it should use library() to import
>>> it in the namespace, otherwise it should install it and import it.
>>>
>>> I assumed that pkgname is a string and tried to write something like:
>>>
>>> ensure_library <- function(pkgname) {
>>>  if (!require(pkgname)) {
>>>    install.packages(pkgname, dependencies = TRUE)
>>>  }
>>>  require(pkgname)
>>> }
>>>
>>> As simple as is this function does not work. If I try to run it like
>>> ensure_library("dplyr") it installs the package dplyr but then it
>>> fails because it trys to import pkgname rather than dplyr in the
>>> namespace.
>>>
>>> ensure_library("dplyr")
>>> Loading required package: pkgname
>>> Installing package into ?/home/luca/R-dev?
>>> (as ?lib? is unspecified)
>>> trying URL 'https://cran.rstudio.com/src/contrib/dplyr_0.5.0.tar.gz'
>>> Content type 'application/x-gzip' length 708476 bytes (691 KB)
>>> ==================================================
>>> downloaded 691 KB
>>>
>>> * installing *source* package ?dplyr? ...
>>> ** package ?dplyr? successfully unpacked and MD5 sums checked
>>> ** libs
>>>
>>> .... a lot of compiling here....
>>>
>>> installing to /home/luca/R-dev/dplyr/libs
>>> ** R
>>> ** data
>>> *** moving datasets to lazyload DB
>>> ** inst
>>> ** preparing package for lazy loading
>>> ** help
>>> *** installing help indices
>>> ** building package indices
>>> ** installing vignettes
>>> ** testing if installed package can be loaded
>>> * DONE (dplyr)
>>>
>>> The downloaded source packages are in
>>>    ?/tmp/Rtmpfd2Lep/downloaded_packages?
>>> Loading required package: pkgname
>>> Warning messages:
>>> 1: In library(package, lib.loc = lib.loc, character.only = TRUE,
>>> logical.return = TRUE,  :
>>>  there is no package called ?pkgname?
>>> 2: In library(package, lib.loc = lib.loc, character.only = TRUE,
>>> logical.return = TRUE,  :
>>>  there is no package called ?pkgname?
>>>
>>> Also, if I now re-run it it will install dplyr once again.
>>>
>>> I realize this is probably due to R non-standard-evaluation and I have
>>> tried several combination of eval/substitute/quote in order to make it
>>> work with require but I couldn't succeed.
>>>
>>> Can somebody help me understanding what is going on and if there is
>>> some easy-fix?
>>>
>>> If a function already implementing this exists I would like to know,
>>> but what I am really interested is understanding why my code does not
>>> work as intended.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Sun Aug 14 13:29:19 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 14 Aug 2016 04:29:19 -0700
Subject: [R] Adding loess lines subsetting to each panel in lattice plot
In-Reply-To: <CAGxFJbSuxpxoGtEy1WmtMU31hGWzgeN_=iHE2f6uWSKjZK0esg@mail.gmail.com>
References: <676905760.22528506.1471018231218.JavaMail.yahoo.ref@mail.yahoo.com>
	<676905760.22528506.1471018231218.JavaMail.yahoo@mail.yahoo.com>
	<CAGxFJbScd9c0JFRqoO8T0WB3SzD4Nc0jkpVT8TmwwVs8j+MVAg@mail.gmail.com>
	<1279776472.23625175.1471095110158.JavaMail.yahoo@mail.yahoo.com>
	<CAGxFJbSuxpxoGtEy1WmtMU31hGWzgeN_=iHE2f6uWSKjZK0esg@mail.gmail.com>
Message-ID: <CAGxFJbQ31Q=uccuhhPYpftVS6x89u2XgpvqUseBGR=7tditpvg@mail.gmail.com>

Juan:

What I gave you previously was correct, but not "nice". The subscripts
= TRUE argument should have been in the xyplot() call, not the pnl
function. However, it is actually not explicitly needed there either,
because it will default to TRUE if the panel function has a subscripts
argument, which it does (and did -- that's why it worked before). Here
is the more sensible version (cc'ed to the list, which I fortunately
failed to do before):

## set up example
x <- runif(100)
 y <- rnorm(100)
 fac <- rep(LETTERS[1:4], e= 25)
 age <- sample(1:2,50,rep=TRUE)
 x <- runif(100)
 y <- rnorm(100)
 fac <- rep(LETTERS[1:4], e= 25)
 age <- runif(100,20,60)

#panel function
 pnl <- function(x, y, age, subscripts, ...){
     age <- age[subscripts]
     old <- age<=40
     panel.xyplot(x,y,...)
     panel.loess(x,y,col.line = "green")
     panel.loess(x[old],y[old],col.line = "red")
     panel.loess(x[!old],y[!old],col.line = "blue")
 }

 xyplot(y~x|fac, age=age,  panel=pnl, lay=c(2,2))


Note that my prior comments about moviing the creation of the groups
to the panel function instead of the data still hold, of course.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Aug 13, 2016 at 7:49 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Inline.
>
> -- Bert
>
>
>
> On Sat, Aug 13, 2016 at 6:31 AM, Juan Perez <beire55 at yahoo.es> wrote:
>> Thanks Bert
>>
>> I am not sure what you meant by reading though.
>>
>> I managed to sort this out, although ideally would exist a better solution.
>> I have created a column in my dataset, and given two codes depending whether
>> older or younger than 40. Afterwards I have applied
>>
>> xyplot(MOE~Age|Species, groups=Old,
>>        panel= function(x,y,...){  ## custom panel function to add an overall
>> loess line
>>          panel.superpose(x,y,...)
>>          panel.loess(x,y,col="black",lwd=2,...)
>>        },
>>        panel.groups = function(x,y,...){
>>          panel.xyplot(x,y,...)
>>          panel.loess(x,y,...)
>>        })
>>
>> This gives a loess line for data younger than 40, another for the ones
>> older, and a third one for all the data. I hope this helps to someone else.
>> Unfortunately, the dataset needs to be modified everytime we want to make a
>> new or different subset.
>
> Not true. Creating a grouping factor and using panel.groups is
> certainly one way to do it, but it's not the only way. You could
> alternatively create the groups in the panel function by using the
> 'subscripts' argument, something like:
>
> x <- runif(100)
> y <- rnorm(100)
> fac <- rep(LETTERS[1:4], e= 25)
> age <- runif(100,20,60)
> pnl <- function(x,y,age, subscripts=TRUE,...){
>   age <- age[subscripts]
>   old <- age<=40
>   panel.xyplot(x,y,...)
>   panel.loess(x,y,col.line = "black")
>   panel.loess(x[old],y[old],col.line = "red")
>   panel.loess(x[!old],y[!old],col.line = "green")
> }
>
> xyplot(y~x| fac, panel = pnl, age=age,lay=c(2,2))
>
> Cheers,
> Bert
>
>>
>> Best regards
>>
>>
>> El Viernes 12 de agosto de 2016 21:10, Bert Gunter <bgunter.4567 at gmail.com>
>> escribi?:
>>
>>
>> Try reading ?panel.loess. There is no "subset" argument, so it is of
>> course ignored.
>>
>> -- Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Fri, Aug 12, 2016 at 9:10 AM, Juan Perez via R-help
>> <r-help at r-project.org> wrote:
>>> Hello, I've created an xyplot and I want to add a loess line for x (Age)
>>> <=40 and another for values >40. In a way it is similar to this
>>> https://stat.ethz.ch/pipermail/r-help/2009-May/390502.html but still not
>>> succcessful.
>>> This is my try:
>>>
>>> xyplot(MOE~Age|Species, groups=Site,
>>>        panel = function(x, y, groups=groups,...) {
>>>        panel.xyplot(x, y, groups=groups,...)
>>>        panel.loess(x,y,subset = x <= 40, col="black")
>>> panel.loess(x,y,subset = x >40, col="red")
>>>              })
>>> When I run the code it "works" but it plots the loess line for all the
>>> data, without subsetting.Any suggestion?
>>> Thank you
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>


From nunesijg at gmail.com  Sun Aug 14 21:57:49 2016
From: nunesijg at gmail.com (=?UTF-8?Q?Itamar_Jos=C3=A9_G=2E_Nunes?=)
Date: Sun, 14 Aug 2016 16:57:49 -0300
Subject: [R] R bug when started in Windows 10
Message-ID: <CAKVb3JH06xOXnVm9nGtSZbyHT_kqJ7ccVUFP-OLcu8whok51Pg@mail.gmail.com>

Greetings, CRAN supporter. I am Itamar Jos?, a Brazilian programmer and
biotechnology student.
I'm using R from some time ago, most of the time working with it in Windows
7, but since I changed to Windows 10, I'm having some bugs when R platform
particularly in this new operational system. If there's not problem, I
would like some help from you for what I can do about this issue.
I have asked about this problem in StarkOverflow, but no resolution was
suggested until now. As I said there, I'm working with a software project
that requires the portable version of R platform and my intention is to use
R in any version of Windows and in any compatible computer. I'm copying
here my answer, as shown below:



*From
[http://stackoverflow.com/questions/37173431/r-platform-failed-to-start-in-windows-10-when-inside-directory-containing-white
<http://stackoverflow.com/questions/37173431/r-platform-failed-to-start-in-windows-10-when-inside-directory-containing-white>]Problem:*
In Windows 7, R works fine without any worries, even in portable version.
However, in Windows 10 (and probably also in Windows 8), R does not start
when put the entire folder inside a directory containing whitespaces (ex.:
"C:/Users/Main/Documents/My Folder/RVersion").

In Windows 10, with the absence of spaces, R runs fine. In the presence of
spaces, all executable (Rscript.exe, R.exe, etc) except Rgui.exe just open
a console and closes instantly. The problem is: I really need that R works
in any folder (this is a important part of the project).

*Additional information:*

   -

   I found that R does not work well in directories without the 8dot3
   format - and it think that Windows 10 lost this property, which was present
   in Windows 7. Also, the problem is clear when I run Rgui.exe in a
   whitespace-containing directory and try to run system("R.exe", intern=TRUE)
   function: It throws an error indicating that only the part before the first
   space in directory name was taken into account. Here is the message:

   > system("R.exe", intern=TRUE)

   [1] "'C:\\Users\\Main\\DOCUME~1\\My' n?o ? reconhecido como um comando
   interno" [2] "ou externo, um programa oper vel ou um arquivo em lotes."
   attr(,"status") [1] 1 Warning message: running command 'R.exe' had status 1

*Translation of messages [1] and [2]: "'C:\...\My'" not recognized as a
internal or external command, nor a program operation or dataset*

   -

   The same occurs with non-portable version of R, as I already tested.
   -

   When I run with a .bat file with the corrected (quoted) directory as
   input, R.exe runs, but in a disfunctional form and looking like cmd.exe (no
   R command worked).
   -

   I have no ideia how to change variables such as R_HOME to a readable
   version before R prompt starts.

*System/Resources:*

   - Windows 10 Home 64-bit with the last update.
   - Dell Notebook with Intel i7-5500U 2.40 GHz (not so relevant, I think)
   - R and R portable 3.3 (last version until this post), downloaded here: [
   https://sourceforge.net/projects/rportable/]
   <https://sourceforge.net/projects/rportable/%5D>


I believe that, with the popularity of Windows 10, many other users could
face this problem (specially those who depend of R portability). Because no
answers were made, and since it remains as a little known issue, I think
the CRAN support is the only one that knows, most than everyone, how to
reach the resolution.

Thanks in advance!

-- 
"I am a firm believer that without speculation there is no good and
original observation." - Charles Darwin

	[[alternative HTML version deleted]]


From janire13 at gmail.com  Sun Aug 14 17:43:49 2016
From: janire13 at gmail.com (=?UTF-8?Q?Janire_Pe=C3=B1alba?=)
Date: Sun, 14 Aug 2016 17:43:49 +0200
Subject: [R] question please
Message-ID: <CAFS0z=KS2AsUX79rUMRqvjG-yVLmZVdULo_Ckaph88yF-RTsew@mail.gmail.com>

What is the R code for neuralnet for time series forecasting?
<http://stats.stackexchange.com/questions/229783/what-is-the-r-code-for-neuralnet-for-time-series-forecasting>

This question might seem very basic but I can?t seem to get the code right.
I have the data for the Pound/Euro Exchange rate for 143 days. I use the
first 115 days of data as my traning set.

And I am trying to train the neuralnetwork by using:

neuralnet(formula, data, hidden layers...)

But I cannot make it work. My question is, fot this kind of data and taking
into account that I only want to do a one step ahead prediction x(t+1) what
would the code look like to then be able to test the rest of the data on
the model given?

Thank you so much in advance

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Aug 14 23:14:03 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 14 Aug 2016 14:14:03 -0700
Subject: [R] R bug when started in Windows 10
In-Reply-To: <CAKVb3JH06xOXnVm9nGtSZbyHT_kqJ7ccVUFP-OLcu8whok51Pg@mail.gmail.com>
References: <CAKVb3JH06xOXnVm9nGtSZbyHT_kqJ7ccVUFP-OLcu8whok51Pg@mail.gmail.com>
Message-ID: <CAGxFJbSyGtLiaWdEzbR0MW31faPaxbbqPwZzYP1sOVzgrt8RYQ@mail.gmail.com>

I'm not on Windows and cannot help directly. But you might consider
downloading Rstudio ( https://www.rstudio.com/ ) and running R through
that. Their website should contain the info you need to get things up
and running.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Aug 14, 2016 at 12:57 PM, Itamar Jos? G. Nunes
<nunesijg at gmail.com> wrote:
> Greetings, CRAN supporter. I am Itamar Jos?, a Brazilian programmer and
> biotechnology student.
> I'm using R from some time ago, most of the time working with it in Windows
> 7, but since I changed to Windows 10, I'm having some bugs when R platform
> particularly in this new operational system. If there's not problem, I
> would like some help from you for what I can do about this issue.
> I have asked about this problem in StarkOverflow, but no resolution was
> suggested until now. As I said there, I'm working with a software project
> that requires the portable version of R platform and my intention is to use
> R in any version of Windows and in any compatible computer. I'm copying
> here my answer, as shown below:
>
>
>
> *From
> [http://stackoverflow.com/questions/37173431/r-platform-failed-to-start-in-windows-10-when-inside-directory-containing-white
> <http://stackoverflow.com/questions/37173431/r-platform-failed-to-start-in-windows-10-when-inside-directory-containing-white>]Problem:*
> In Windows 7, R works fine without any worries, even in portable version.
> However, in Windows 10 (and probably also in Windows 8), R does not start
> when put the entire folder inside a directory containing whitespaces (ex.:
> "C:/Users/Main/Documents/My Folder/RVersion").
>
> In Windows 10, with the absence of spaces, R runs fine. In the presence of
> spaces, all executable (Rscript.exe, R.exe, etc) except Rgui.exe just open
> a console and closes instantly. The problem is: I really need that R works
> in any folder (this is a important part of the project).
>
> *Additional information:*
>
>    -
>
>    I found that R does not work well in directories without the 8dot3
>    format - and it think that Windows 10 lost this property, which was present
>    in Windows 7. Also, the problem is clear when I run Rgui.exe in a
>    whitespace-containing directory and try to run system("R.exe", intern=TRUE)
>    function: It throws an error indicating that only the part before the first
>    space in directory name was taken into account. Here is the message:
>
>    > system("R.exe", intern=TRUE)
>
>    [1] "'C:\\Users\\Main\\DOCUME~1\\My' n?o ? reconhecido como um comando
>    interno" [2] "ou externo, um programa oper vel ou um arquivo em lotes."
>    attr(,"status") [1] 1 Warning message: running command 'R.exe' had status 1
>
> *Translation of messages [1] and [2]: "'C:\...\My'" not recognized as a
> internal or external command, nor a program operation or dataset*
>
>    -
>
>    The same occurs with non-portable version of R, as I already tested.
>    -
>
>    When I run with a .bat file with the corrected (quoted) directory as
>    input, R.exe runs, but in a disfunctional form and looking like cmd.exe (no
>    R command worked).
>    -
>
>    I have no ideia how to change variables such as R_HOME to a readable
>    version before R prompt starts.
>
> *System/Resources:*
>
>    - Windows 10 Home 64-bit with the last update.
>    - Dell Notebook with Intel i7-5500U 2.40 GHz (not so relevant, I think)
>    - R and R portable 3.3 (last version until this post), downloaded here: [
>    https://sourceforge.net/projects/rportable/]
>    <https://sourceforge.net/projects/rportable/%5D>
>
>
> I believe that, with the popularity of Windows 10, many other users could
> face this problem (specially those who depend of R portability). Because no
> answers were made, and since it remains as a little known issue, I think
> the CRAN support is the only one that knows, most than everyone, how to
> reach the resolution.
>
> Thanks in advance!
>
> --
> "I am a firm believer that without speculation there is no good and
> original observation." - Charles Darwin
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Aug 14 23:25:18 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 14 Aug 2016 14:25:18 -0700
Subject: [R] question please
In-Reply-To: <CAFS0z=KS2AsUX79rUMRqvjG-yVLmZVdULo_Ckaph88yF-RTsew@mail.gmail.com>
References: <CAFS0z=KS2AsUX79rUMRqvjG-yVLmZVdULo_Ckaph88yF-RTsew@mail.gmail.com>
Message-ID: <3141DCE6-FA67-4511-A76A-49158B580E6C@comcast.net>


> On Aug 14, 2016, at 8:43 AM, Janire Pe?alba <janire13 at gmail.com> wrote:
> 
> What is the R code for neuralnet for time series forecasting?
> <http://stats.stackexchange.com/questions/229783/what-is-the-r-code-for-neuralnet-for-time-series-forecasting>

Page Not Found
This question was removed from Cross Validated for reasons of moderation. 

I've never seen such an action before. Normally CrossValidated is very tolerant of posters not reading their help pages and advice about posting. Did you do something really strange?

> 
> This question might seem very basic but I can?t seem to get the code right.
> I have the data for the Pound/Euro Exchange rate for 143 days. I use the
> first 115 days of data as my traning set.
> 
> And I am trying to train the neuralnetwork by using:
> 
> neuralnet(formula, data, hidden layers...)

There were other question on CV.com that offered code doing neuralnet predictions on timeseries.
> 
> But I cannot make it work. My question is, fot this kind of data and taking
> into account that I only want to do a one step ahead prediction x(t+1) what
> would the code look like to then be able to test the rest of the data on
> the model given?

For R-help, you are expected to post code that creates a dataset ...
> 
> Thank you so much in advance
> 
> 	[[alternative HTML version deleted]]

... and do it in plain text.

-- 
David.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Sun Aug 14 23:47:59 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 14 Aug 2016 14:47:59 -0700
Subject: [R] R bug when started in Windows 10
In-Reply-To: <CAKVb3JGHw2PFO4npgVL2C_PYsqOfbb3Fr14zRcvGAJOCw4z26g@mail.gmail.com>
References: <CAKVb3JH06xOXnVm9nGtSZbyHT_kqJ7ccVUFP-OLcu8whok51Pg@mail.gmail.com>
	<CAGxFJbSyGtLiaWdEzbR0MW31faPaxbbqPwZzYP1sOVzgrt8RYQ@mail.gmail.com>
	<CAKVb3JGHw2PFO4npgVL2C_PYsqOfbb3Fr14zRcvGAJOCw4z26g@mail.gmail.com>
Message-ID: <CAGxFJbQJ-K-cgdand43ZrsiKhg6PZp3OtkrubFvP_2Nyzqd2Ww@mail.gmail.com>

I have cc'ed this to r-help. As I said, I am not on Windows and so
cannot help directly.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Aug 14, 2016 at 2:32 PM, Itamar Jos? G. Nunes
<nunesijg at gmail.com> wrote:
> Hello, Bert Gunter. Firstly, thanks for the response.
> As you recommended, I tried to check if RStudio could run a R version inside
> a whitespace-containing directory. In fact, it takes effect, and this
> problem appears to not affect RStudio.
> However, I don't have any idea of how it worked. The application that I'm
> developing also cannot depend on RStudio, since it requires a portable
> version of R. The resolution can be something trivial, such as a correction
> of the commas when the inner machinery of R calls the base libraries or
> something like that (the Batch language in Windows has such mistakes when
> running, and putting commas can solve it). Or else it can be nothing
> trivial, such as error that can compromise the executable. If you don't
> matter to ask, is there something that I can do about it? Like a correction
> in some part of the code.
>
> Cheers,
> Itamar Jos?
>
> 2016-08-14 18:14 GMT-03:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>
>> I'm not on Windows and cannot help directly. But you might consider
>> downloading Rstudio ( https://www.rstudio.com/ ) and running R through
>> that. Their website should contain the info you need to get things up
>> and running.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Aug 14, 2016 at 12:57 PM, Itamar Jos? G. Nunes
>> <nunesijg at gmail.com> wrote:
>> > Greetings, CRAN supporter. I am Itamar Jos?, a Brazilian programmer and
>> > biotechnology student.
>> > I'm using R from some time ago, most of the time working with it in
>> > Windows
>> > 7, but since I changed to Windows 10, I'm having some bugs when R
>> > platform
>> > particularly in this new operational system. If there's not problem, I
>> > would like some help from you for what I can do about this issue.
>> > I have asked about this problem in StarkOverflow, but no resolution was
>> > suggested until now. As I said there, I'm working with a software
>> > project
>> > that requires the portable version of R platform and my intention is to
>> > use
>> > R in any version of Windows and in any compatible computer. I'm copying
>> > here my answer, as shown below:
>> >
>> >
>> >
>> > *From
>> >
>> > [http://stackoverflow.com/questions/37173431/r-platform-failed-to-start-in-windows-10-when-inside-directory-containing-white
>> >
>> > <http://stackoverflow.com/questions/37173431/r-platform-failed-to-start-in-windows-10-when-inside-directory-containing-white>]Problem:*
>> > In Windows 7, R works fine without any worries, even in portable
>> > version.
>> > However, in Windows 10 (and probably also in Windows 8), R does not
>> > start
>> > when put the entire folder inside a directory containing whitespaces
>> > (ex.:
>> > "C:/Users/Main/Documents/My Folder/RVersion").
>> >
>> > In Windows 10, with the absence of spaces, R runs fine. In the presence
>> > of
>> > spaces, all executable (Rscript.exe, R.exe, etc) except Rgui.exe just
>> > open
>> > a console and closes instantly. The problem is: I really need that R
>> > works
>> > in any folder (this is a important part of the project).
>> >
>> > *Additional information:*
>> >
>> >    -
>> >
>> >    I found that R does not work well in directories without the 8dot3
>> >    format - and it think that Windows 10 lost this property, which was
>> > present
>> >    in Windows 7. Also, the problem is clear when I run Rgui.exe in a
>> >    whitespace-containing directory and try to run system("R.exe",
>> > intern=TRUE)
>> >    function: It throws an error indicating that only the part before the
>> > first
>> >    space in directory name was taken into account. Here is the message:
>> >
>> >    > system("R.exe", intern=TRUE)
>> >
>> >    [1] "'C:\\Users\\Main\\DOCUME~1\\My' n?o ? reconhecido como um
>> > comando
>> >    interno" [2] "ou externo, um programa oper vel ou um arquivo em
>> > lotes."
>> >    attr(,"status") [1] 1 Warning message: running command 'R.exe' had
>> > status 1
>> >
>> > *Translation of messages [1] and [2]: "'C:\...\My'" not recognized as a
>> > internal or external command, nor a program operation or dataset*
>> >
>> >    -
>> >
>> >    The same occurs with non-portable version of R, as I already tested.
>> >    -
>> >
>> >    When I run with a .bat file with the corrected (quoted) directory as
>> >    input, R.exe runs, but in a disfunctional form and looking like
>> > cmd.exe (no
>> >    R command worked).
>> >    -
>> >
>> >    I have no ideia how to change variables such as R_HOME to a readable
>> >    version before R prompt starts.
>> >
>> > *System/Resources:*
>> >
>> >    - Windows 10 Home 64-bit with the last update.
>> >    - Dell Notebook with Intel i7-5500U 2.40 GHz (not so relevant, I
>> > think)
>> >    - R and R portable 3.3 (last version until this post), downloaded
>> > here: [
>> >    https://sourceforge.net/projects/rportable/]
>> >    <https://sourceforge.net/projects/rportable/%5D>
>> >
>> >
>> > I believe that, with the popularity of Windows 10, many other users
>> > could
>> > face this problem (specially those who depend of R portability). Because
>> > no
>> > answers were made, and since it remains as a little known issue, I think
>> > the CRAN support is the only one that knows, most than everyone, how to
>> > reach the resolution.
>> >
>> > Thanks in advance!
>> >
>> > --
>> > "I am a firm believer that without speculation there is no good and
>> > original observation." - Charles Darwin
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> "I am a firm believer that without speculation there is no good and original
> observation." - Charles Darwin


From glennmschultz at me.com  Mon Aug 15 00:40:23 2016
From: glennmschultz at me.com (Glenn Schultz)
Date: Sun, 14 Aug 2016 17:40:23 -0500
Subject: [R] need some help with date
Message-ID: <88CC5188-B65A-478A-9946-43B1DEA94D38@me.com>

Here is a sample of the data that I am working with.  Dates may go back as far as 1930?s.  When I use as.Date() I noticed that any data < 12/31/68 returns as the new century.  So I wrote this function below to be applied to the data which I dput below the function.  If I use the function DateCentury(Date = df[1,?TERM DATE?) it will return the correct date.  However, if I use the function as follows DateCentury[,?TERM DATE?]) it does not work.  Anyhow, I have been at this awhile and I am totally stumped.  I need to refactor the below date vectors across just under 50,000 observations.  Any suggestions would be greatly appreciated.

Best,
Glenn

 DateCentury <- function(Date = "character"){
    ThisDate = as.Date(Date, format = "%m/%d/%y", origin = "1900-01-01")
    CurrDate = as.Date(Sys.Date())
    Century = as.Date("1999-12-31", format = "%Y-%m-%d", origin = "1900-01-01")
    NewDate <- if(ThisDate > CurrDate){
                
      if(nchar(Date) == 6){
        paste(substr(Date,1,4),"19", substr(Date,5,6),sep ="")
                  } else {
                if(nchar(Date) == 7){paste(substr(Date,1,5),"19", substr(Date,6,7),sep ="")
                  } else {
                paste(substr(Date,1,6),"19", substr(Date,7,8),sep ="")
                  }
                    }
                  
      } else {
        
        if(ThisDate <= Century){
          
                    if(nchar(Date) == 6){
                      paste(substr(Date,1,4),"19", substr(Date,5,6),sep ="")
                    } else {
                      if(nchar(Date) == 7){paste(substr(Date,1,5),"19", substr(Date,6,7),sep ="")
                      } else {
                        paste(substr(Date,1,6),"19", substr(Date,7,8),sep ="")  
                        }
                      }
            }  else {
                        if(nchar(Date) == 6){paste(substr(Date,1,4),"20", substr(Date,5,6),sep ="")
                          } else {
                        if(nchar(Date) == 7){paste(substr(Date,1,5),"20", substr(Date,6,7),sep ="")
                        } else {
                            paste(substr(Date,1,6),"20", substr(Date,7,8),sep ="")
                          }
                      }
                    }
          }

    return(NewDate)}





Data
structure(list(`HUD PROJECT NUMBER` = c(1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 39L, 43L, 46L, 47L, 49L, 50L, 51L, 52L, 53L, 
54L, 55L, 58L, 59L, 60L, 61L, 62L, 66L, 68L, 69L, 74L, 77L, 78L, 
82L, 83L, 84L, 87L, 88L, 89L, 90L, 91L, 98L, 99L, 100L, 101L, 
102L, 103L, 104L, 105L, 107L, 108L, 110L, 111L, 112L, 113L, 114L, 
116L, 118L, 119L, 120L, 121L, 122L, 123L, 125L, 135L, 140L, 141L, 
144L, 146L, 9001L, 9002L, 10001L, 10004L, 10005L, 10007L, 10008L, 
10010L, 10011L, 10501L, 10502L, 10503L, 10504L, 10505L, 10506L, 
10507L, 10508L, 10510L, 10515L, 10516L, 10517L, 10518L, 10519L, 
10520L, 10521L, 10522L, 10523L, 10525L, 10526L, 10527L, 10528L, 
10529L), `PROPERTY NAME` = c("COLONIAL VILLAGE APTS", "COLONIAL VILLAGE APTS", 
"FALKLAND APTS", "COLONIAL VILLAGE APTS", "BRENTWOOD VILLAGE", 
"FALKLAND APTS", "BUCKINGHAM II", "FIRST BUCKINGHAM", "PARKBELT HOMES", 
"BUCKINGHAM III", "SKYLAND APTS", "BUCKINGHAM IV", "WESTOVER APTS", 
"MT VERNON DEV", "ARLINGTON VILLAGE APTS", "FAIRFAX VILLAGE III", 
"BUCKINGHAM V", "SUBURBAN GARDENS", "BUCKINGHAM III", "PINEY BRANCH APTS", 
"AUBURN GARDENS", "BUCKINGHAM V", "BUCKINGHAM IV", "GLEBE COURT APTS", 
"BARCROFT APTS", "FAIRFAX VILLAGE IV", "BELLEVUE GARDENS", "FILLMORE CO INC", 
"BRADLEY BLVD APTS", "2702 WISCONSIN", "WINCHESTER SUMMIT", "BUCKINGHAM II", 
"ARLINGTON TOWERS", "ARLINGTON TOWERS", "ARLINGTON TOWERS", "BRADDOCK LEE APT I", 
"BRADDOCK LEE APT II", "BRADDOCK LEE APT III", "BRADDOCK LEE APT IV", 
"BRADDOCK LEE APT V", "4600 CONN COOP", "GARFIELD APTS", "CATHEDERAL PK TOW", 
"SECOND PKSIDE APT", "THE ENVOY", "CARDINAL HOUSE", "TUNLAW PARK APTS", 
"RAVENWOOD TOWERS", "PARKSIDE APTS", "PARK BERKSHIRE APTS", "JOHN MARSHALL APTS", 
"MATTAPONY MANOR", "MOSBY VILLAGE APTS", "RIVER TOWERS", "", 
"BARNETT HOUSE", "RIVERS TOWERS II", "FAIRHAVEN GARDENS", "CIRCLE APARTMENTS", 
"HYBLA VALLEY MOBLE HMS", "PARK PLAZA APTS", "ENVOY TOWERS", 
"C H HOUSTON APTS", "DUMFRIES MOBILE HM VLG", "SKYLINE TOWERS APTS I", 
"SKYLINE CENTER APTS", "CHESTNUT GROVE APTS", "BRENTANA GARDENS", 
"GREGORY ESTATES", "BARNABY GARDENS", "C H HOUSTON APTS", "HIGHVIEW TERRACE", 
"CHESTNUT GROVE APTS", "ROCKVILLE NRSNG HOME", "STANTON-WELLINGTON APTS. DBA F", 
"COLLINSWOOD NURSING HOME", "SHADY GROVE ADVENTIST NURSING", 
"GLENDALE LAKE APTS", "GARFIELD COURT", "COUNTRYSIDE APTS", "INVIEW HOUSE", 
"TOP OF THE PARK", "SUMMIT CREST APTS", "BRADFORD PLACE", "HILLSIDE TERR APTS", 
"OAK HILL APTS", "PARK BERKSHIRE APTS I", "CARROLLAN MANOR", 
"LANSDOWNE VILLAGE APTS", "GATEWAY SQUARE", "KIRKWOOD VILLAGE APTS", 
"GOODACRE APTS", "PENN SOUTHERN APTS.", "WOODMONT PARK APTS", 
"FINIANS CT", "ROCKFORDTHE", "ISABELLA PARK APARTMENTS", "GREENTREE III", 
"", "MARLOW HEIGHTS SECTION A"), `PROPERTY STREET` = c("1913 WILSON BLVD", 
"1913 WILSON BLVD", "8305 16TH STREET", "1913 WILSON BLVD", "1287 BRENTWOOD RD NE", 
"8305 16TH STREET", "313 N GLEBE RD", "313 N GLEBE RD", "", "313 N GLEBE RD", 
"2307 SKYLAND PL SE", "313 N GLEBE RD", "1649 N LONGFELLOW", 
"", "1021 S BARTON", "2019 37TH ST SE", "313 N GLEBE RD", "4904 JAY ST NE", 
"313 N GLEBE RD", "8400 PINEY BRANCH RD", "101 GLEBE ROAD E", 
"313 N GLEBE RD", "313 N GLEBE RD", "", "1130 S GEORGE MASON DR", 
"2019 37TH ST SE", "", "", "", "2702 WISCONSIN AVE", "", "313 N GLEBE RD", 
"1101 ARLINGTON BLVD", "1011 ARLINGTON BLVD", "1011 ARLINGTON BLVD", 
"3810 KING ST", "3810 KING ST", "3810 KING ST", "3810 KING ST", 
"3810 KING ST", "4600 CONNECTICUT AVE NW", "5410 CONNECTICUT AVE NW", 
"3100 CONNECTICUT AVE NW", "", "2144 CALIFORNIA ST  NW", "3000 SPOUT RUN PKWY", 
"3850 TUNLAW RD NW", "6166 LEESBURG PIKE", "10520 MONTROSE AVE", 
"6317 PENNSYLVANIA AVE", "", "5002 57TH AVE", "10560 MAIN ST", 
"6631 WAKEFIELD DRIVE", "", "201 MASSACHUSETTS AVE NE", "6631 WAKEFIELD DRIVE", 
"JERMANTOWN ROAD", "2030 N ADAMS ST", "BARGIN CITY-HYBLA VALLEY", 
"1629 COLUMBIA RD NW", "2400 16TH ST NW", "1712 16TH ST NW", 
"DUMFRIES", "5601 SEMINARY ROAD", "5600 SEMINARY ROAD", "11200 CHESTNUT GROVE SQ", 
"", "7618 GEORGE PALMER HGWY", "3876 9TH ST SE", "1714 16TH ST NW", 
"6800-7021 HIGHVIEW TER", "11200 CHESTNUT GROVE SQ", "303 ADCLARE ROAD", 
"2549 ELVANS RD SE", "299 HURLEY AVENUE", "9701 MEDICAL CENTER DRIVE", 
"10001 GREENBELT RD", "5701 43RD AVE", "9971 GOODLUCK RD", "6161 EDSALL ROAD", 
"4009 GALLATIN ST", "38 N SUMMIT AVE", "3506 SILVER PARK RD", 
"1805-1910 23RD ST SE", "11497 COLUMBIA PIKE", "6301 PENNSYLVANIA AVE", 
"8621 ANNAPOLIS RD", "1720 BRIGHTSEAT RD", "4855 ST. BARNABAS RD", 
"2731 NICHOLSON", "8619 PINEY BRANCH RD", "", "1001 ROCKVILLE PIKE", 
"7756 FINNS LANE", "1444 ROCK CREEK FORD RD", "2214 PHELPS ROAD", 
"8051 GREENLEAF TERR", "", "4223 28TH AVE"), `PROPERTY CITY` = c("ARLINGTON", 
"ARLINGTON", "SILVER SPRING", "ARLINGTON", "WASHINGTON", "SILVER SPRING", 
"ARLINGTON", "ARLINGTON", "GREENBELT", "ARLINGTON", "WASHINGTON", 
"ARLINGTON", "ARLINGTON", "ALEXANDRIA", "ARLINGTON", "WASHINGTON", 
"ARLINGTON", "WASHINGTON", "ARLINGTON", "SILVER SPRING", "ALEXANDRIA", 
"ARLINGTON", "ARLINGTON", "ARLINGTON", "ARLINGTON", "WASHINGTON", 
"WASHINGTON", "ARLINGTON", "BETHESDA", "WASHINGTON", "WASHINGTON", 
"ARLINGTON", "ARLINGTON", "ARLINGTON", "ARLINGTON", "ALEXANDRIA", 
"ALEXANDRIA", "ALEXANDRIA", "ALEXANDRIA", "ALEXANDRIA", "WASHINGTON", 
"WASHINGTON", "WASHINGTON", "ROCKVILLE", "WASHINGTON", "ARLINGTON", 
"WASHINGTON", "SEVEN CORNERS", "BETHESDA", "SUITLAND-SILVER HI", 
"WASHINGTON", "BLADENSBURG", "FAIRFAX", "ALEXANDRIA", "", "WASHINGTON", 
"ALEXANDRIA", "FAIRFAX", "ARLINGTON", "FAIRFAX", "WASHINGTON", 
"WASHINGTON", "WASHINGTON", "DUMFRIES", "BAILEY'S CROSSROAD", 
"BAILEY'S CROSSROAD", "RESTON", "RESTON", "SEAT PLEASANT", "WASHINGTON", 
"WASHINGTON", "HYATTSVILLE", "RESTON", "ROCKVILLE", "WASHINGTON", 
"ROCKVILLE", "ROCKVLLE", "LANHAM-SEABROOK", "HYATTSVILLE", "HYATTSVILLE", 
"ALEXANDRIA", "HYATTSVILLE", "GAITHERSBURG", "SUITLAND-SILVER HI", 
"WASHINGTON", "SILVER SPRING", "FORESTVILLE", "LANHAM-SEABROOK", 
"LANDOVER", "PRINCE GEORGE'S CO", "HYATTSVILLE", "SILVER SPRING", 
"SILVER SPRING", "PURCELLVILLE", "LANHAM-SEABROOK", "WASHINGTON", 
"ADELPHI", "GLEN BURNIE", "", "SUITLAND-SILVER HI"), `PROPERTY STATE` = c("VA", 
"VA", "MD", "VA", "DC", "MD", "VA", "VA", "MD", "VA", "DC", "VA", 
"VA", "VA", "VA", "DC", "VA", "DC", "VA", "MD", "VA", "VA", "VA", 
"VA", "VA", "DC", "DC", "VA", "MD", "DC", "DC", "VA", "VA", "VA", 
"VA", "VA", "VA", "VA", "VA", "VA", "DC", "DC", "DC", "MD", "DC", 
"VA", "DC", "VA", "MD", "MD", "DC", "MD", "VA", "VA", "", "DC", 
"VA", "VA", "VA", "VA", "DC", "DC", "DC", "VA", "00", "VA", "VA", 
"VA", "MD", "DC", "DC", "MD", "VA", "MD", "DC", "MD", "MD", "MD", 
"MD", "MD", "VA", "MD", "MD", "MD", "DC", "MD", "MD", "MD", "MD", 
"MD", "MD", "MD", "MD", "VA", "MD", "DC", "MD", "MD", "", "MD"
), `PROPERTY ZIP` = c("22201", "22201", "20910", "22201", "20018", 
"20910", "22203", "22203", "20770", "22203", "20020", "22203", 
"22205", "00000", "22204", "20020", "22203", "20019", "22203", 
"20901", "22305", "22203", "22203", "00000", "22204", "20020", 
"00000", "00000", "20014", "20007", "00000", "22203", "22209", 
"22209", "22209", "22302", "22302", "22302", "22302", "22302", 
"20008", "20015", "20008", "00000", "20008", "22201", "20007", 
"22044", "20014", "20023", "00000", "20710", "22030", "22037", 
"00000", "20002", "22307", "22030", "22201", "22030", "20009", 
"20009", "20009", "22026", "22041", "22041", "22090", "22037", 
"20027", "20032", "20005", "20782", "22090", "20850", "20020", 
"20850", "20850", "20801", "20781", "20706", "22304", "20785", 
"20877", "20746", "20020", "20904", "20747", "20706", "20785", 
"20748", "20782", "20901", "20910", "20850", "20801", "20011", 
"20783", "00000", "00000", "20748"), UNITS = c(274L, 464L, 181L, 
237L, 440L, 303L, 98L, 524L, 10L, 200L, 223L, 192L, 153L, 57L, 
655L, 207L, 276L, 204L, 112L, 214L, 304L, 176L, 248L, 77L, 423L, 
214L, 251L, 181L, 161L, 80L, 41L, 98L, 366L, 415L, 434L, 40L, 
58L, 80L, 40L, 40L, 267L, 166L, 323L, 120L, 113L, 229L, 284L, 
304L, 170L, 336L, 30L, 154L, 205L, 168L, 0L, 95L, 175L, 76L, 
116L, 250L, 274L, 332L, 45L, 156L, 470L, 470L, 225L, 240L, 503L, 
79L, 46L, 306L, 224L, 100L, 398L, 160L, 170L, 443L, 62L, 451L, 
207L, 106L, 232L, 213L, 192L, 281L, 336L, 187L, 345L, 297L, 750L, 
156L, 308L, 414L, 57L, 66L, 445L, 1122L, 0L, 0L), `INITIAL ENDORSEMENT DATE` = c("4/20/35", 
"12/9/35", "9/11/36", "2/8/37", "8/3/37", "8/19/37", "3/15/40", 
"8/3/37", "5/13/38", "4/13/38", "3/7/39", "8/26/38", "8/24/39", 
"8/18/39", "1/4/39", "2/24/40", "1/4/39", "4/11/41", "5/9/39", 
"7/10/40", "8/19/40", "7/15/40", "4/14/41", "7/15/41", "10/23/41", 
"9/30/41", "7/16/43", "4/23/42", "3/13/42", "6/8/42", "1/18/43", 
"9/23/44", "1/29/54", "4/30/54", "1/14/54", "9/28/54", "12/1/54", 
"2/8/55", "1/4/55", "11/4/54", "4/16/59", "5/1/58", "6/10/59", 
"10/1/58", "9/20/60", "12/4/58", "2/17/60", "4/13/61", "1/18/61", 
"6/2/61", "6/19/61", "1/25/62", "11/26/62", "3/14/62", "5/4/62", 
"9/26/62", "8/10/62", "6/3/63", "11/6/63", "8/15/63", "10/11/63", 
"12/11/63", "8/26/65", "10/27/71", "10/10/72", "1/10/73", "8/3/71", 
"2/7/72", "7/1/70", "5/1/73", "2/24/78", "8/31/81", "9/17/80", 
"4/16/82", "1/19/89", "5/21/08", "4/4/08", "5/26/83", "7/11/83", 
"11/16/83", "6/30/83", "5/26/83", "5/26/83", "6/27/83", "5/13/83", 
"6/29/83", "1/30/84", "10/25/84", "10/25/84", "10/25/84", "7/28/83", 
"7/28/83", "10/31/85", "7/14/83", "1/31/84", "4/10/84", "8/1/83", 
"7/28/83", "6/20/85", "6/20/85"), `FINAL ENDORSEMENT DATE` = c("", 
"", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
"", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
"", "", "", "", "", "", "", "", "", "", "", "9/20/60", "", "", 
"", "", "", "", "", "", "", "", "11/25/64", "", "", "", "", "8/24/65", 
"", "2/14/67", "", "1/10/73", "1/10/73", "", "", "", "12/6/82", 
"2/24/78", "8/31/81", "", "4/16/82", "5/24/91", "7/14/09", "4/4/08", 
"5/26/83", "7/11/83", "11/16/83", "", "5/26/83", "5/26/83", "6/27/83", 
"5/16/83", "6/29/83", "1/31/84", "10/25/84", "10/25/84", "10/25/84", 
"7/28/83", "7/28/83", "10/31/85", "7/14/83", "1/31/84", "4/10/84", 
"8/1/83", "7/28/83", "6/20/85", "6/20/85"), `ORIGINAL MORTGAGE AMOUNT` = c("875,000", 
"1,480,000", "840,000", "725,000", "1,650,000", "1,225,000", 
"319,000", "1,825,000", "35,000", "650,000", "760,000", "725,000", 
"410,000", "165,000", "2,385,000", "701,000", "1,035,000", "692,000", 
"490,000", "815,000", "942,000", "610,000", "935,000", "260,000", 
"1,500,000", "830,000", "980,000", "660,000", "630,000", "265,000", 
"139,000", "283,000", "4,301,100", "3,831,000", "4,482,200", 
"313,700", "462,200", "641,800", "312,000", "312,100", "4,103,600", 
"2,313,100", "5,626,500", "1,271,600", "1,447,200", "2,838,400", 
"4,434,100", "3,640,900", "1,905,700", "2,893,200", "270,300", 
"1,480,000", "3,048,165", "2,365,427", "1,138,600", "1,129,200", 
"2,436,300", "752,500", "1,691,900", "450,000", "3,799,363", 
"4,626,400", "484,500", "561,600", "10,795,600", "11,081,000", 
"4,248,400", "3,714,938", "1,909,441", "436,825", "25,000", "348,700", 
"173,400", "55,100", "4,311,301", "462,300", "1,170,000", "8,499,800", 
"1,065,700", "13,387,500", "5,880,000", "1,500,000", "3,846,600", 
"5,300,000", "1,750,000", "4,600,000", "5,653,000", "3,000,000", 
"5,000,000", "5,000,000", "7,500,000", "1,600,000", "6,500,000", 
"7,300,000", "1,350,000", "1,260,900", "8,081,100", "21,988,600", 
"10,675,000", "4,600,000"), `FIRST PAYMENT DATE` = c("1/1/36", 
"3/1/37", "4/1/38", "5/1/38", "10/1/38", "6/1/39", "12/1/39", 
"2/1/39", "9/1/38", "11/1/39", "9/1/40", "3/1/40", "2/1/41", 
"2/1/41", "7/1/40", "8/1/41", "8/1/40", "7/1/42", "12/1/40", 
"2/1/42", "5/1/41", "2/1/42", "11/1/42", "1/1/43", "11/1/43", 
"7/1/43", "5/1/44", "4/1/44", "3/1/44", "7/1/44", "3/1/44", "10/1/44", 
"6/1/56", "6/1/56", "6/1/56", "10/1/54", "1/1/55", "3/1/55", 
"2/1/55", "12/1/54", "6/1/59", "8/1/59", "12/1/60", "10/1/59", 
"10/1/60", "6/1/60", "2/1/62", "1/1/63", "4/1/62", "6/1/63", 
"3/1/62", "10/1/63", "4/1/65", "6/1/63", "1/1/64", "9/1/64", 
"5/1/64", "9/1/64", "7/1/65", "6/1/64", "1/1/65", "9/1/65", "12/1/66", 
"12/1/71", "4/1/73", "4/1/73", "2/1/73", "9/1/73", "7/1/70", 
"5/1/73", "5/1/78", "10/1/81", "1/1/81", "7/1/82", "9/1/91", 
"2/1/09", "6/1/08", "7/1/83", "9/1/83", "1/1/84", "8/1/83", "7/1/83", 
"7/1/83", "8/1/83", "7/1/83", "8/1/83", "3/1/84", "12/1/84", 
"12/1/84", "12/1/84", "9/1/83", "9/1/83", "12/1/85", "9/1/83", 
"3/1/84", "6/1/84", "9/1/83", "9/1/83", "7/1/85", "7/1/85"), 
    `MATURITY DATE` = c("4/1/50", "12/1/55", "7/1/64", "2/1/57", 
    "7/1/52", "3/1/59", "1/1/65", "4/1/65", "12/1/63", "1/1/66", 
    "11/1/61", "5/1/66", "11/1/68", "12/1/67", "7/1/72", "8/1/67", 
    "10/1/66", "1/1/75", "2/1/67", "8/1/69", "7/1/68", "8/1/69", 
    "5/1/70", "7/1/70", "5/1/71", "10/1/70", "8/1/71", "11/1/71", 
    "10/1/71", "2/1/72", "10/1/71", "9/1/69", "12/1/94", "3/1/95", 
    "11/1/94", "12/1/93", "3/1/94", "5/1/94", "4/1/94", "2/1/94", 
    "10/1/91", "10/1/98", "2/1/00", "12/1/98", "9/1/99", "2/1/99", 
    "9/1/00", "12/1/01", "3/1/01", "8/1/01", "6/1/97", "9/1/02", 
    "2/1/03", "5/1/02", "12/1/02", "5/1/03", "4/1/03", "5/1/03", 
    "6/1/04", "5/1/79", "12/1/03", "8/1/04", "11/1/05", "11/1/11", 
    "3/1/13", "3/1/13", "1/1/13", "8/1/13", "4/1/00", "12/1/11", 
    "2/1/04", "4/1/12", "1/1/13", "12/1/89", "8/1/21", "1/1/42", 
    "5/1/36", "6/1/18", "8/1/18", "12/1/18", "7/1/18", "6/1/18", 
    "6/1/18", "7/1/18", "6/1/18", "7/1/18", "2/1/19", "11/1/19", 
    "11/1/19", "11/1/19", "8/1/18", "8/1/18", "11/1/20", "8/1/18", 
    "2/1/19", "5/1/19", "8/1/18", "8/1/18", "7/1/20", "7/1/20"
    ), `TERM IN MONTHS` = c(172L, 226L, 316L, 226L, 166L, 238L, 
    302L, 315L, 304L, 315L, 255L, 315L, 334L, 323L, 385L, 313L, 
    315L, 391L, 315L, 331L, 327L, 331L, 331L, 331L, 331L, 328L, 
    328L, 332L, 332L, 332L, 332L, 300L, 463L, 466L, 462L, 471L, 
    471L, 471L, 471L, 471L, 389L, 471L, 471L, 471L, 468L, 465L, 
    464L, 468L, 468L, 459L, 424L, 468L, 455L, 468L, 468L, 465L, 
    468L, 465L, 468L, 180L, 468L, 468L, 468L, 480L, 480L, 480L, 
    480L, 480L, 358L, 464L, 310L, 367L, 385L, 90L, 360L, 396L, 
    336L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 
    420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 
    420L, 420L, 421L, 421L), `INTEREST RATE` = c(4.5, 4.5, 4.5, 
    4.5, 4.5, 4.5, 4, 3.5, 4.5, 3.5, 3.75, 3.5, 4, 4.25, 4.25, 
    4, 3.5, 4, 3.5, 4, 4, 3.5, 3.5, 4, 4, 4, 4, 4, 4, 4, 4, 3.5, 
    4.25, 4.25, 4.25, 4.25, 4.25, 4.25, 4.25, 4.25, 4.5, 4.5, 
    4.5, 4.5, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 
    5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 
    5.25, 8.5, 7.5, 7.5, 7.5, 7.5, 5.25, 6, 9, 14.5, 13, 16.5, 
    10.75, 6.95, 5.95, 12.25, 12.5, 13, 12.5, 12.25, 12.25, 12.5, 
    12, 12.5, 13, 13.5, 13.5, 13.5, 13, 13, 11.5, 12.5, 13, 13.5, 
    13, 13, 12, 12), `HOLDER NAME` = c("NEW YORK LIFE INSURANCE CO", 
    "NEW YORK LIFE INSURANCE CO", "UNION CENTRAL LIFE INS CO", 
    "NEW YORK LIFE INSURANCE CO", "NEW YORK LIFE INSURANCE CO", 
    "UNION CENTRAL LIFE INS CO", "NAVY MUTUAL AID ASSN", "WELLS FARGO BANK NA-PRUDENTIAL", 
    "", "WELLS FARGO BANK NA-PRUDENTIAL", "LIFE INSURANCE CO OF VIRGINIA", 
    "WELLS FARGO BANK NA-PRUDENTIAL", "SECURITY MUTUAL LIFE INS CO", 
    "NAVY MUTUAL AID ASSN", "NEW YORK LIFE INSURANCE CO", "NATIONAL LIFE INSURANCE CO", 
    "WELLS FARGO BANK NA-PRUDENTIAL", "NATIONAL LIFE INSURANCE CO", 
    "WELLS FARGO BANK NA-PRUDENTIAL", "", "NEW YORK LIFE INSURANCE CO", 
    "WELLS FARGO BANK NA-PRUDENTIAL", "WELLS FARGO BANK NA-PRUDENTIAL", 
    "KEY BANK CENTRAL NY", "NATIONAL LIFE INSURANCE CO", "NATIONAL LIFE INSURANCE CO", 
    "NEW YORK LIFE INSURANCE CO", "UNION CENTRAL LIFE INS CO", 
    "CONNECTICUT GEN LIFE INS CO", "SAN JUAN COUNTY BK", "SECURITY MUTUAL LIFE INS CO", 
    "WELLS FARGO BANK NA-PRUDENTIAL", "SEAMENS BANK SAVINGS FSB-FDIC", 
    "REPUBLIC NATIONAL BANK OF NEW", "LINCOLN SAVINGS BANK", 
    "LIBERTY LENDING INC", "EMIGRANT BANK", "PROVIDENT BANK", 
    "EMIGRANT BANK", "NEW YORK COMMUNITY BANK", "", "", "", "", 
    "PFC CORPORATION", "DOLLAR-DRY DOCK BANK", "PHILADELPHIA SAVINGS FUND SOC", 
    "PHILADELPHIA SAVINGS FUND SOC", "AMERICAN GEN LIFE AND ACCDT IN", 
    "", "", "", "", "PHILADELPHIA SAVINGS FUND SOC", "SOVRAN BANK MARYLAND", 
    "SWISS RE LIFE AND HEALTH AMERI", "", "", "AMERICAN SECURITY CORPORATION", 
    "PUEBLO MORTGAGE INC", "JOHN HANCOCK LIFE INSURANCE CO", 
    "CHASE MANHATTAN BANK", "RIGGS BANK NA", "FANNIE MAE", "STATE TEACHERS RT BOARD OHIO", 
    "STATE TEACHERS RT BOARD OHIO", "FANNIE MAE", "RIGGS BANK NA", 
    "PEOPLES LIFE INS CO WASHINGTON", "WHITE MOUNTAINS SERVICES CORP", 
    "RIGGS BANK NA", "DRG FUNDING CORPORATION", "FANNIE MAE", 
    "ALLFIRST BANK", "USGI INC", "WELLS FARGO BANK NA", "ZIEGLER FINANCING CORP", 
    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
    "YORK ASSOCIATES INC", "DRG FUNDING CORPORATION", "YORK ASSOCIATES INC", 
    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC"), `HOLDER CITY` = c("NEW YORK", 
    "NEW YORK", "CINCINNATI", "NEW YORK", "NEW YORK", "CINCINNATI", 
    "ARLINGTON", "FREDERICK", "", "FREDERICK", "RICHMOND", "FREDERICK", 
    "BINGHAMTON", "ARLINGTON", "NEW YORK", "MONTPELIER", "FREDERICK", 
    "MONTPELIER", "FREDERICK", "", "NEW YORK", "FREDERICK", "FREDERICK", 
    "BUFFALO", "MONTPELIER", "MONTPELIER", "NEW YORK", "CINCINNATI", 
    "HARTFORD", "FRIDAY HARBOR", "BINGHAMTON", "FREDERICK", "EAST HARTFORD", 
    "NEW YORK", "JERICHO", "BARTLETT", "NEW YORK", "ISELIN", 
    "NEW YORK", "CLEVELAND", "", "", "", "", "TUSTIN", "WHITE PLAINS", 
    "PHILADELPHIA", "PHILADELPHIA", "NASHVILLE", "", "", "", 
    "", "PHILADELPHIA", "BETHESDA", "NEW YORK", "", "", "BALTIMORE", 
    "TUCSON", "BOSTON", "NEW YORK", "RIVERDALE", "PHILADELPHIA", 
    "COLUMBUS", "COLUMBUS", "ATLANTA", "RIVERDALE", "LOUISVILLE", 
    "FARMINGTON HILLS", "RIVERDALE", "WASHINGTON", "ATLANTA", 
    "FREDERICK", "LA PLATA", "MC LEAN", "NEW ALBANY", "BETHESDA", 
    "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", 
    "BETHESDA", "WASHINGTON", "BETHESDA", "BETHESDA", "BETHESDA", 
    "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", 
    "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", 
    "BETHESDA", "BETHESDA"), `HOLDER STATE` = c("NY", "NY", "OH", 
    "NY", "NY", "OH", "VA", "MD", "", "MD", "VA", "MD", "NY", 
    "VA", "NY", "VT", "MD", "VT", "MD", "", "NY", "MD", "MD", 
    "NY", "VT", "VT", "NY", "OH", "CT", "WA", "NY", "MD", "CT", 
    "NY", "NY", "TN", "NY", "NJ", "NY", "OH", "", "", "", "", 
    "CA", "NY", "PA", "PA", "TN", "", "", "", "", "PA", "MD", 
    "NY", "", "", "MD", "AZ", "MA", "NY", "MD", "PA", "OH", "OH", 
    "GA", "MD", "KY", "MI", "MD", "DC", "GA", "MD", "MD", "VA", 
    "OH", "MD", "MD", "MD", "MD", "MD", "MD", "MD", "DC", "MD", 
    "MD", "MD", "MD", "MD", "MD", "MD", "MD", "MD", "MD", "MD", 
    "MD", "MD", "MD", "MD"), `SERVICER NAME` = c("No Data Available", 
    "No Data Available", "No Data Available", "No Data Available", 
    "No Data Available", "No Data Available", "No Data Available", 
    "No Data Available", "No Data Available", "No Data Available", 
    "No Data Available", "No Data Available", "No Data Available", 
    "No Data Available", "No Data Available", "No Data Available", 
    "No Data Available", "No Data Available", "No Data Available", 
    "No Data Available", "No Data Available", "No Data Available", 
    "No Data Available", "No Data Available", "No Data Available", 
    "No Data Available", "No Data Available", "No Data Available", 
    "No Data Available", "No Data Available", "No Data Available", 
    "No Data Available", "No Data Available", "No Data Available", 
    "No Data Available", "", "", "", "", "", "", "", "", "No Data Available", 
    "", "No Data Available", "No Data Available", "", "No Data Available", 
    "No Data Available", "", "", "No Data Available", "", "", 
    "", "", "", "No Data Available", "", "", "No Data Available", 
    "", "", "", "", "", "", "", "WHITE MOUNTAINS SERVICES CORP", 
    "", "", "", "", "USGI INC", "WELLS FARGO BANK NA", "ZIEGLER FINANCING CORP", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", ""), `SERVICER CITY` = c("", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "FARMINGTON HILLS", "", "", 
    "", "", "LA PLATA", "MC LEAN", "NEW ALBANY", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", ""), `SERVICER STATE` = c("", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "MI", "", "", "", "", "MD", "VA", "OH", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", ""), `SECTION OF ACT CODE` = c("HRB", 
    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", 
    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", 
    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", 
    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", 
    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRP", "HRB", 
    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", 
    "HRP", "HRB", "HRB", "HRB", "HRB", "HRP", "HRB", "HRP", "HRB", 
    "HRP", "HRP", "HRB", "HRB", "HRP", "HRP", "ZSB", "ZSB", "ZSB", 
    "ZSB", "ZSJ", "ZSQ", "ZSQ", "HRL", "HRL", "HRL", "HRL", "HRL", 
    "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", 
    "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL"
    ), `SOA CATEGORY Sub Category` = c("207 Apartments", "207 Apartments", 
    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
    "207 Apartments", "207 Apartments", "207 Rental Projects", 
    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
    "207 Apartments", "207 Apartments", "207 Rental Projects", 
    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
    "207 Rental Projects", "207 Apartments", "207 Rental Projects", 
    "207 Apartments", "207 Rental Projects", "207 Rental Projects", 
    "207 Apartments", "207 Apartments", "207 Rental Projects", 
    "207 Rental Projects", "241(a)/ 207 Improvements & Additions", 
    "241(a)/ 207 Improvements & Additions", "241(a)/ 207 Improvements & Additions", 
    "241(a)/ 207 Improvements & Additions", "241(a)/ 221-MIR(d)(3)&(d)(4) Improvements & Additions", 
    "241(a)/ 232 /Improvements & Additions / Nursing Homes", 
    "241(a)/ 232 /Improvements & Additions / Nursing Homes", 
    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
    "207/ 223(f)/ 244 Co-Insurance"), `TERM TYPE` = c("11", "11", 
    "11", "11", "11", "11", "12", "11", "11", "11", "11", "11", 
    "11", "11", "11", "11", "11", "11", "11", "11", "11", "11", 
    "11", "11", "11", "11", "11", "11", "11", "11", "11", "11", 
    "11", "11", "11", "11", "11", "11", "11", "11", "11", "11", 
    "11", "11", "18", "21", "21", "21", "11", "19", "11", "11", 
    "20", "21", "19", "11", "21", "11", "11", "11", "11", "15", 
    "11", "11", "11", "11", "11", "21", "19", "11", "11", "11", 
    "11", "11", "19", "11", "11", "11", "11", "11", "11", "11", 
    "11", "11", "11", "11", "11", "11", "11", "11", "11", "11", 
    "14", "11", "11", "11", "11", "11", "11", "11"), `TERMINATION TYPE DESCRIPTION` = c("Prepayment", 
    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
    "SUPERSESSION", "Prepayment", "Prepayment", "Prepayment", 
    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Maturity", 
    "VOLUNTARY", "VOLUNTARY", "VOLUNTARY", "Prepayment", "Assignment", 
    "Prepayment", "Prepayment", "Acquired", "VOLUNTARY", "Assignment", 
    "Prepayment", "VOLUNTARY", "Prepayment", "Prepayment", "Prepayment", 
    "Prepayment", "Conveyance", "Prepayment", "Prepayment", "Prepayment", 
    "Prepayment", "Prepayment", "VOLUNTARY", "Assignment", "Prepayment", 
    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Assignment", 
    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
    "Prepayment", "Prepayment", "CANCELLED", "Prepayment", "Prepayment", 
    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment"
    ), `TYPE  Claim Non Claim ` = c("NONCLAIM", "NONCLAIM", "NONCLAIM", 
    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
    "NONCLAIM", "CLAIM", "NONCLAIM", "NONCLAIM", "CLAIM", "NONCLAIM", 
    "CLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
    "NONCLAIM", "NONCLAIM", "CLAIM", "NONCLAIM", "NONCLAIM", 
    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "CLAIM", 
    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
    "CLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
    "NONCLAIM"), `TERM DATE` = c("4/1/39", "4/1/39", "9/1/40", 
    "4/1/39", "2/1/49", "9/1/40", "9/1/44", "8/1/46", "1/1/50", 
    "11/1/44", "7/1/54", "8/1/46", "11/1/41", "7/1/54", "12/1/39", 
    "3/1/46", "8/1/46", "12/1/45", "11/1/44", "7/1/45", "11/1/45", 
    "8/1/46", "8/1/46", "8/1/46", "10/1/46", "7/1/46", "9/1/47", 
    "12/1/43", "7/1/46", "12/1/42", "5/1/44", "8/1/46", "8/1/65", 
    "8/1/65", "8/1/65", "1/31/83", "1/31/83", "2/3/83", "1/31/83", 
    "1/31/83", "12/7/72", "1/3/79", "12/4/79", "10/1/67", "10/1/99", 
    "5/1/71", "4/1/70", "10/16/79", "10/1/67", "8/1/66", "2/27/75", 
    "1/29/82", "12/1/66", "12/3/79", "4/4/75", "10/25/85", "1/30/80", 
    "6/25/74", "12/19/72", "5/31/73", "7/1/94", "4/1/67", "3/19/87", 
    "3/16/73", "2/13/86", "2/13/86", "5/24/82", "7/12/73", "12/8/76", 
    "3/10/89", "3/19/87", "10/31/85", "5/24/82", "1/21/85", "8/30/95", 
    "1/28/11", "11/30/10", "5/31/86", "5/31/86", "4/30/86", "11/20/84", 
    "6/30/86", "6/30/86", "3/31/86", "1/16/87", "10/31/86", "12/31/85", 
    "4/1/86", "4/1/86", "4/1/86", "3/31/86", "3/31/86", "8/3/90", 
    "10/31/86", "6/30/86", "1/30/87", "4/30/86", "4/30/86", "2/27/87", 
    "8/31/86"), TE = c("", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", ""
    ), TC = c("", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
    "", "", "", "", "", "", "", "", "", "", "", "", ""), Status = c(TRUE, 
    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE)), .Names = c("HUD PROJECT NUMBER", 
"PROPERTY NAME", "PROPERTY STREET", "PROPERTY CITY", "PROPERTY STATE", 
"PROPERTY ZIP", "UNITS", "INITIAL ENDORSEMENT DATE", "FINAL ENDORSEMENT DATE", 
"ORIGINAL MORTGAGE AMOUNT", "FIRST PAYMENT DATE", "MATURITY DATE", 
"TERM IN MONTHS", "INTEREST RATE", "HOLDER NAME", "HOLDER CITY", 
"HOLDER STATE", "SERVICER NAME", "SERVICER CITY", "SERVICER STATE", 
"SECTION OF ACT CODE", "SOA CATEGORY Sub Category", "TERM TYPE", 
"TERMINATION TYPE DESCRIPTION", "TYPE  Claim Non Claim ", "TERM DATE", 
"TE", "TC", "Status"), row.names = c(NA, 100L), class = "data.frame")
  


From dwinsemius at comcast.net  Mon Aug 15 02:20:12 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 14 Aug 2016 17:20:12 -0700
Subject: [R] need some help with date
In-Reply-To: <88CC5188-B65A-478A-9946-43B1DEA94D38@me.com>
References: <88CC5188-B65A-478A-9946-43B1DEA94D38@me.com>
Message-ID: <C8FBF03A-0C7F-456E-B8F9-CEA612FC65F0@comcast.net>


> On Aug 14, 2016, at 3:40 PM, Glenn Schultz <glennmschultz at me.com> wrote:
> 
> Here is a sample of the data that I am working with.  Dates may go back as far as 1930?s.  When I use as.Date() I noticed that any data < 12/31/68 returns as the new century.  So I wrote this function below to be applied to the data which I dput below the function.  If I use the function DateCentury(Date = df[1,?TERM DATE?) it will return the correct date.

I seriously doubt that is true since that is not parseable withoput a) correction of the "smart-quotes" and b) a closing "]".


>  However, if I use the function as follows DateCentury[,?TERM DATE?]) it does not work.

That's kind of crazy. How should the DateCentury function know where to get any data without naming the Data object. Actaully the error is thrown by the parser which is unable to deal with DateCentury being called with the smart-quotes but even if you fix that, you get this error:

Error: unexpected ')' in "DateCentury[,"TERM DATE"])"

DateCentury is a function so you need to have an open paren after its name and then the items inside the matching parens need to be data objects.

This shows the function to be "working" with a full column, albeit with a warning related to improper use of the `if` function:

> str(DateCentury(Data[, 'TERM DATE']) )
 chr [1:100] "4/1/1939" "4/1/1939" "9/1/1940" "4/1/1939" "2/1/1949" ...
Warning messages:
1: In if (ThisDate > CurrDate) { :
  the condition has length > 1 and only the first element will be used
2: In if (nchar(Date) == 6) { :
  the condition has length > 1 and only the first element will be used
-- 
David.

>  Anyhow, I have been at this awhile and I am totally stumped.  I need to refactor the below date vectors across just under 50,000 observations.  Any suggestions would be greatly appreciated.
> 
> Best,
> Glenn
> 
> DateCentury <- function(Date = "character"){
>    ThisDate = as.Date(Date, format = "%m/%d/%y", origin = "1900-01-01")
>    CurrDate = as.Date(Sys.Date())
>    Century = as.Date("1999-12-31", format = "%Y-%m-%d", origin = "1900-01-01")
>    NewDate <- if(ThisDate > CurrDate){
> 
>      if(nchar(Date) == 6){
>        paste(substr(Date,1,4),"19", substr(Date,5,6),sep ="")
>                  } else {
>                if(nchar(Date) == 7){paste(substr(Date,1,5),"19", substr(Date,6,7),sep ="")
>                  } else {
>                paste(substr(Date,1,6),"19", substr(Date,7,8),sep ="")
>                  }
>                    }
> 
>      } else {
> 
>        if(ThisDate <= Century){
> 
>                    if(nchar(Date) == 6){
>                      paste(substr(Date,1,4),"19", substr(Date,5,6),sep ="")
>                    } else {
>                      if(nchar(Date) == 7){paste(substr(Date,1,5),"19", substr(Date,6,7),sep ="")
>                      } else {
>                        paste(substr(Date,1,6),"19", substr(Date,7,8),sep ="")  
>                        }
>                      }
>            }  else {
>                        if(nchar(Date) == 6){paste(substr(Date,1,4),"20", substr(Date,5,6),sep ="")
>                          } else {
>                        if(nchar(Date) == 7){paste(substr(Date,1,5),"20", substr(Date,6,7),sep ="")
>                        } else {
>                            paste(substr(Date,1,6),"20", substr(Date,7,8),sep ="")
>                          }
>                      }
>                    }
>          }
> 
>    return(NewDate)}
> 
> 
> 
> 
> 
> Data
> structure(list(`HUD PROJECT NUMBER` = c(1L, 2L, 3L, 4L, 5L, 6L, 
> 7L, 8L, 9L, 10L, 39L, 43L, 46L, 47L, 49L, 50L, 51L, 52L, 53L, 
> 54L, 55L, 58L, 59L, 60L, 61L, 62L, 66L, 68L, 69L, 74L, 77L, 78L, 
> 82L, 83L, 84L, 87L, 88L, 89L, 90L, 91L, 98L, 99L, 100L, 101L, 
> 102L, 103L, 104L, 105L, 107L, 108L, 110L, 111L, 112L, 113L, 114L, 
> 116L, 118L, 119L, 120L, 121L, 122L, 123L, 125L, 135L, 140L, 141L, 
> 144L, 146L, 9001L, 9002L, 10001L, 10004L, 10005L, 10007L, 10008L, 
> 10010L, 10011L, 10501L, 10502L, 10503L, 10504L, 10505L, 10506L, 
> 10507L, 10508L, 10510L, 10515L, 10516L, 10517L, 10518L, 10519L, 
> 10520L, 10521L, 10522L, 10523L, 10525L, 10526L, 10527L, 10528L, 
> 10529L), `PROPERTY NAME` = c("COLONIAL VILLAGE APTS", "COLONIAL VILLAGE APTS", 
> "FALKLAND APTS", "COLONIAL VILLAGE APTS", "BRENTWOOD VILLAGE", 
> "FALKLAND APTS", "BUCKINGHAM II", "FIRST BUCKINGHAM", "PARKBELT HOMES", 
> "BUCKINGHAM III", "SKYLAND APTS", "BUCKINGHAM IV", "WESTOVER APTS", 
> "MT VERNON DEV", "ARLINGTON VILLAGE APTS", "FAIRFAX VILLAGE III", 
> "BUCKINGHAM V", "SUBURBAN GARDENS", "BUCKINGHAM III", "PINEY BRANCH APTS", 
> "AUBURN GARDENS", "BUCKINGHAM V", "BUCKINGHAM IV", "GLEBE COURT APTS", 
> "BARCROFT APTS", "FAIRFAX VILLAGE IV", "BELLEVUE GARDENS", "FILLMORE CO INC", 
> "BRADLEY BLVD APTS", "2702 WISCONSIN", "WINCHESTER SUMMIT", "BUCKINGHAM II", 
> "ARLINGTON TOWERS", "ARLINGTON TOWERS", "ARLINGTON TOWERS", "BRADDOCK LEE APT I", 
> "BRADDOCK LEE APT II", "BRADDOCK LEE APT III", "BRADDOCK LEE APT IV", 
> "BRADDOCK LEE APT V", "4600 CONN COOP", "GARFIELD APTS", "CATHEDERAL PK TOW", 
> "SECOND PKSIDE APT", "THE ENVOY", "CARDINAL HOUSE", "TUNLAW PARK APTS", 
> "RAVENWOOD TOWERS", "PARKSIDE APTS", "PARK BERKSHIRE APTS", "JOHN MARSHALL APTS", 
> "MATTAPONY MANOR", "MOSBY VILLAGE APTS", "RIVER TOWERS", "", 
> "BARNETT HOUSE", "RIVERS TOWERS II", "FAIRHAVEN GARDENS", "CIRCLE APARTMENTS", 
> "HYBLA VALLEY MOBLE HMS", "PARK PLAZA APTS", "ENVOY TOWERS", 
> "C H HOUSTON APTS", "DUMFRIES MOBILE HM VLG", "SKYLINE TOWERS APTS I", 
> "SKYLINE CENTER APTS", "CHESTNUT GROVE APTS", "BRENTANA GARDENS", 
> "GREGORY ESTATES", "BARNABY GARDENS", "C H HOUSTON APTS", "HIGHVIEW TERRACE", 
> "CHESTNUT GROVE APTS", "ROCKVILLE NRSNG HOME", "STANTON-WELLINGTON APTS. DBA F", 
> "COLLINSWOOD NURSING HOME", "SHADY GROVE ADVENTIST NURSING", 
> "GLENDALE LAKE APTS", "GARFIELD COURT", "COUNTRYSIDE APTS", "INVIEW HOUSE", 
> "TOP OF THE PARK", "SUMMIT CREST APTS", "BRADFORD PLACE", "HILLSIDE TERR APTS", 
> "OAK HILL APTS", "PARK BERKSHIRE APTS I", "CARROLLAN MANOR", 
> "LANSDOWNE VILLAGE APTS", "GATEWAY SQUARE", "KIRKWOOD VILLAGE APTS", 
> "GOODACRE APTS", "PENN SOUTHERN APTS.", "WOODMONT PARK APTS", 
> "FINIANS CT", "ROCKFORDTHE", "ISABELLA PARK APARTMENTS", "GREENTREE III", 
> "", "MARLOW HEIGHTS SECTION A"), `PROPERTY STREET` = c("1913 WILSON BLVD", 
> "1913 WILSON BLVD", "8305 16TH STREET", "1913 WILSON BLVD", "1287 BRENTWOOD RD NE", 
> "8305 16TH STREET", "313 N GLEBE RD", "313 N GLEBE RD", "", "313 N GLEBE RD", 
> "2307 SKYLAND PL SE", "313 N GLEBE RD", "1649 N LONGFELLOW", 
> "", "1021 S BARTON", "2019 37TH ST SE", "313 N GLEBE RD", "4904 JAY ST NE", 
> "313 N GLEBE RD", "8400 PINEY BRANCH RD", "101 GLEBE ROAD E", 
> "313 N GLEBE RD", "313 N GLEBE RD", "", "1130 S GEORGE MASON DR", 
> "2019 37TH ST SE", "", "", "", "2702 WISCONSIN AVE", "", "313 N GLEBE RD", 
> "1101 ARLINGTON BLVD", "1011 ARLINGTON BLVD", "1011 ARLINGTON BLVD", 
> "3810 KING ST", "3810 KING ST", "3810 KING ST", "3810 KING ST", 
> "3810 KING ST", "4600 CONNECTICUT AVE NW", "5410 CONNECTICUT AVE NW", 
> "3100 CONNECTICUT AVE NW", "", "2144 CALIFORNIA ST  NW", "3000 SPOUT RUN PKWY", 
> "3850 TUNLAW RD NW", "6166 LEESBURG PIKE", "10520 MONTROSE AVE", 
> "6317 PENNSYLVANIA AVE", "", "5002 57TH AVE", "10560 MAIN ST", 
> "6631 WAKEFIELD DRIVE", "", "201 MASSACHUSETTS AVE NE", "6631 WAKEFIELD DRIVE", 
> "JERMANTOWN ROAD", "2030 N ADAMS ST", "BARGIN CITY-HYBLA VALLEY", 
> "1629 COLUMBIA RD NW", "2400 16TH ST NW", "1712 16TH ST NW", 
> "DUMFRIES", "5601 SEMINARY ROAD", "5600 SEMINARY ROAD", "11200 CHESTNUT GROVE SQ", 
> "", "7618 GEORGE PALMER HGWY", "3876 9TH ST SE", "1714 16TH ST NW", 
> "6800-7021 HIGHVIEW TER", "11200 CHESTNUT GROVE SQ", "303 ADCLARE ROAD", 
> "2549 ELVANS RD SE", "299 HURLEY AVENUE", "9701 MEDICAL CENTER DRIVE", 
> "10001 GREENBELT RD", "5701 43RD AVE", "9971 GOODLUCK RD", "6161 EDSALL ROAD", 
> "4009 GALLATIN ST", "38 N SUMMIT AVE", "3506 SILVER PARK RD", 
> "1805-1910 23RD ST SE", "11497 COLUMBIA PIKE", "6301 PENNSYLVANIA AVE", 
> "8621 ANNAPOLIS RD", "1720 BRIGHTSEAT RD", "4855 ST. BARNABAS RD", 
> "2731 NICHOLSON", "8619 PINEY BRANCH RD", "", "1001 ROCKVILLE PIKE", 
> "7756 FINNS LANE", "1444 ROCK CREEK FORD RD", "2214 PHELPS ROAD", 
> "8051 GREENLEAF TERR", "", "4223 28TH AVE"), `PROPERTY CITY` = c("ARLINGTON", 
> "ARLINGTON", "SILVER SPRING", "ARLINGTON", "WASHINGTON", "SILVER SPRING", 
> "ARLINGTON", "ARLINGTON", "GREENBELT", "ARLINGTON", "WASHINGTON", 
> "ARLINGTON", "ARLINGTON", "ALEXANDRIA", "ARLINGTON", "WASHINGTON", 
> "ARLINGTON", "WASHINGTON", "ARLINGTON", "SILVER SPRING", "ALEXANDRIA", 
> "ARLINGTON", "ARLINGTON", "ARLINGTON", "ARLINGTON", "WASHINGTON", 
> "WASHINGTON", "ARLINGTON", "BETHESDA", "WASHINGTON", "WASHINGTON", 
> "ARLINGTON", "ARLINGTON", "ARLINGTON", "ARLINGTON", "ALEXANDRIA", 
> "ALEXANDRIA", "ALEXANDRIA", "ALEXANDRIA", "ALEXANDRIA", "WASHINGTON", 
> "WASHINGTON", "WASHINGTON", "ROCKVILLE", "WASHINGTON", "ARLINGTON", 
> "WASHINGTON", "SEVEN CORNERS", "BETHESDA", "SUITLAND-SILVER HI", 
> "WASHINGTON", "BLADENSBURG", "FAIRFAX", "ALEXANDRIA", "", "WASHINGTON", 
> "ALEXANDRIA", "FAIRFAX", "ARLINGTON", "FAIRFAX", "WASHINGTON", 
> "WASHINGTON", "WASHINGTON", "DUMFRIES", "BAILEY'S CROSSROAD", 
> "BAILEY'S CROSSROAD", "RESTON", "RESTON", "SEAT PLEASANT", "WASHINGTON", 
> "WASHINGTON", "HYATTSVILLE", "RESTON", "ROCKVILLE", "WASHINGTON", 
> "ROCKVILLE", "ROCKVLLE", "LANHAM-SEABROOK", "HYATTSVILLE", "HYATTSVILLE", 
> "ALEXANDRIA", "HYATTSVILLE", "GAITHERSBURG", "SUITLAND-SILVER HI", 
> "WASHINGTON", "SILVER SPRING", "FORESTVILLE", "LANHAM-SEABROOK", 
> "LANDOVER", "PRINCE GEORGE'S CO", "HYATTSVILLE", "SILVER SPRING", 
> "SILVER SPRING", "PURCELLVILLE", "LANHAM-SEABROOK", "WASHINGTON", 
> "ADELPHI", "GLEN BURNIE", "", "SUITLAND-SILVER HI"), `PROPERTY STATE` = c("VA", 
> "VA", "MD", "VA", "DC", "MD", "VA", "VA", "MD", "VA", "DC", "VA", 
> "VA", "VA", "VA", "DC", "VA", "DC", "VA", "MD", "VA", "VA", "VA", 
> "VA", "VA", "DC", "DC", "VA", "MD", "DC", "DC", "VA", "VA", "VA", 
> "VA", "VA", "VA", "VA", "VA", "VA", "DC", "DC", "DC", "MD", "DC", 
> "VA", "DC", "VA", "MD", "MD", "DC", "MD", "VA", "VA", "", "DC", 
> "VA", "VA", "VA", "VA", "DC", "DC", "DC", "VA", "00", "VA", "VA", 
> "VA", "MD", "DC", "DC", "MD", "VA", "MD", "DC", "MD", "MD", "MD", 
> "MD", "MD", "VA", "MD", "MD", "MD", "DC", "MD", "MD", "MD", "MD", 
> "MD", "MD", "MD", "MD", "VA", "MD", "DC", "MD", "MD", "", "MD"
> ), `PROPERTY ZIP` = c("22201", "22201", "20910", "22201", "20018", 
> "20910", "22203", "22203", "20770", "22203", "20020", "22203", 
> "22205", "00000", "22204", "20020", "22203", "20019", "22203", 
> "20901", "22305", "22203", "22203", "00000", "22204", "20020", 
> "00000", "00000", "20014", "20007", "00000", "22203", "22209", 
> "22209", "22209", "22302", "22302", "22302", "22302", "22302", 
> "20008", "20015", "20008", "00000", "20008", "22201", "20007", 
> "22044", "20014", "20023", "00000", "20710", "22030", "22037", 
> "00000", "20002", "22307", "22030", "22201", "22030", "20009", 
> "20009", "20009", "22026", "22041", "22041", "22090", "22037", 
> "20027", "20032", "20005", "20782", "22090", "20850", "20020", 
> "20850", "20850", "20801", "20781", "20706", "22304", "20785", 
> "20877", "20746", "20020", "20904", "20747", "20706", "20785", 
> "20748", "20782", "20901", "20910", "20850", "20801", "20011", 
> "20783", "00000", "00000", "20748"), UNITS = c(274L, 464L, 181L, 
> 237L, 440L, 303L, 98L, 524L, 10L, 200L, 223L, 192L, 153L, 57L, 
> 655L, 207L, 276L, 204L, 112L, 214L, 304L, 176L, 248L, 77L, 423L, 
> 214L, 251L, 181L, 161L, 80L, 41L, 98L, 366L, 415L, 434L, 40L, 
> 58L, 80L, 40L, 40L, 267L, 166L, 323L, 120L, 113L, 229L, 284L, 
> 304L, 170L, 336L, 30L, 154L, 205L, 168L, 0L, 95L, 175L, 76L, 
> 116L, 250L, 274L, 332L, 45L, 156L, 470L, 470L, 225L, 240L, 503L, 
> 79L, 46L, 306L, 224L, 100L, 398L, 160L, 170L, 443L, 62L, 451L, 
> 207L, 106L, 232L, 213L, 192L, 281L, 336L, 187L, 345L, 297L, 750L, 
> 156L, 308L, 414L, 57L, 66L, 445L, 1122L, 0L, 0L), `INITIAL ENDORSEMENT DATE` = c("4/20/35", 
> "12/9/35", "9/11/36", "2/8/37", "8/3/37", "8/19/37", "3/15/40", 
> "8/3/37", "5/13/38", "4/13/38", "3/7/39", "8/26/38", "8/24/39", 
> "8/18/39", "1/4/39", "2/24/40", "1/4/39", "4/11/41", "5/9/39", 
> "7/10/40", "8/19/40", "7/15/40", "4/14/41", "7/15/41", "10/23/41", 
> "9/30/41", "7/16/43", "4/23/42", "3/13/42", "6/8/42", "1/18/43", 
> "9/23/44", "1/29/54", "4/30/54", "1/14/54", "9/28/54", "12/1/54", 
> "2/8/55", "1/4/55", "11/4/54", "4/16/59", "5/1/58", "6/10/59", 
> "10/1/58", "9/20/60", "12/4/58", "2/17/60", "4/13/61", "1/18/61", 
> "6/2/61", "6/19/61", "1/25/62", "11/26/62", "3/14/62", "5/4/62", 
> "9/26/62", "8/10/62", "6/3/63", "11/6/63", "8/15/63", "10/11/63", 
> "12/11/63", "8/26/65", "10/27/71", "10/10/72", "1/10/73", "8/3/71", 
> "2/7/72", "7/1/70", "5/1/73", "2/24/78", "8/31/81", "9/17/80", 
> "4/16/82", "1/19/89", "5/21/08", "4/4/08", "5/26/83", "7/11/83", 
> "11/16/83", "6/30/83", "5/26/83", "5/26/83", "6/27/83", "5/13/83", 
> "6/29/83", "1/30/84", "10/25/84", "10/25/84", "10/25/84", "7/28/83", 
> "7/28/83", "10/31/85", "7/14/83", "1/31/84", "4/10/84", "8/1/83", 
> "7/28/83", "6/20/85", "6/20/85"), `FINAL ENDORSEMENT DATE` = c("", 
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
> "", "", "", "", "", "", "", "", "", "", "", "9/20/60", "", "", 
> "", "", "", "", "", "", "", "", "11/25/64", "", "", "", "", "8/24/65", 
> "", "2/14/67", "", "1/10/73", "1/10/73", "", "", "", "12/6/82", 
> "2/24/78", "8/31/81", "", "4/16/82", "5/24/91", "7/14/09", "4/4/08", 
> "5/26/83", "7/11/83", "11/16/83", "", "5/26/83", "5/26/83", "6/27/83", 
> "5/16/83", "6/29/83", "1/31/84", "10/25/84", "10/25/84", "10/25/84", 
> "7/28/83", "7/28/83", "10/31/85", "7/14/83", "1/31/84", "4/10/84", 
> "8/1/83", "7/28/83", "6/20/85", "6/20/85"), `ORIGINAL MORTGAGE AMOUNT` = c("875,000", 
> "1,480,000", "840,000", "725,000", "1,650,000", "1,225,000", 
> "319,000", "1,825,000", "35,000", "650,000", "760,000", "725,000", 
> "410,000", "165,000", "2,385,000", "701,000", "1,035,000", "692,000", 
> "490,000", "815,000", "942,000", "610,000", "935,000", "260,000", 
> "1,500,000", "830,000", "980,000", "660,000", "630,000", "265,000", 
> "139,000", "283,000", "4,301,100", "3,831,000", "4,482,200", 
> "313,700", "462,200", "641,800", "312,000", "312,100", "4,103,600", 
> "2,313,100", "5,626,500", "1,271,600", "1,447,200", "2,838,400", 
> "4,434,100", "3,640,900", "1,905,700", "2,893,200", "270,300", 
> "1,480,000", "3,048,165", "2,365,427", "1,138,600", "1,129,200", 
> "2,436,300", "752,500", "1,691,900", "450,000", "3,799,363", 
> "4,626,400", "484,500", "561,600", "10,795,600", "11,081,000", 
> "4,248,400", "3,714,938", "1,909,441", "436,825", "25,000", "348,700", 
> "173,400", "55,100", "4,311,301", "462,300", "1,170,000", "8,499,800", 
> "1,065,700", "13,387,500", "5,880,000", "1,500,000", "3,846,600", 
> "5,300,000", "1,750,000", "4,600,000", "5,653,000", "3,000,000", 
> "5,000,000", "5,000,000", "7,500,000", "1,600,000", "6,500,000", 
> "7,300,000", "1,350,000", "1,260,900", "8,081,100", "21,988,600", 
> "10,675,000", "4,600,000"), `FIRST PAYMENT DATE` = c("1/1/36", 
> "3/1/37", "4/1/38", "5/1/38", "10/1/38", "6/1/39", "12/1/39", 
> "2/1/39", "9/1/38", "11/1/39", "9/1/40", "3/1/40", "2/1/41", 
> "2/1/41", "7/1/40", "8/1/41", "8/1/40", "7/1/42", "12/1/40", 
> "2/1/42", "5/1/41", "2/1/42", "11/1/42", "1/1/43", "11/1/43", 
> "7/1/43", "5/1/44", "4/1/44", "3/1/44", "7/1/44", "3/1/44", "10/1/44", 
> "6/1/56", "6/1/56", "6/1/56", "10/1/54", "1/1/55", "3/1/55", 
> "2/1/55", "12/1/54", "6/1/59", "8/1/59", "12/1/60", "10/1/59", 
> "10/1/60", "6/1/60", "2/1/62", "1/1/63", "4/1/62", "6/1/63", 
> "3/1/62", "10/1/63", "4/1/65", "6/1/63", "1/1/64", "9/1/64", 
> "5/1/64", "9/1/64", "7/1/65", "6/1/64", "1/1/65", "9/1/65", "12/1/66", 
> "12/1/71", "4/1/73", "4/1/73", "2/1/73", "9/1/73", "7/1/70", 
> "5/1/73", "5/1/78", "10/1/81", "1/1/81", "7/1/82", "9/1/91", 
> "2/1/09", "6/1/08", "7/1/83", "9/1/83", "1/1/84", "8/1/83", "7/1/83", 
> "7/1/83", "8/1/83", "7/1/83", "8/1/83", "3/1/84", "12/1/84", 
> "12/1/84", "12/1/84", "9/1/83", "9/1/83", "12/1/85", "9/1/83", 
> "3/1/84", "6/1/84", "9/1/83", "9/1/83", "7/1/85", "7/1/85"), 
>    `MATURITY DATE` = c("4/1/50", "12/1/55", "7/1/64", "2/1/57", 
>    "7/1/52", "3/1/59", "1/1/65", "4/1/65", "12/1/63", "1/1/66", 
>    "11/1/61", "5/1/66", "11/1/68", "12/1/67", "7/1/72", "8/1/67", 
>    "10/1/66", "1/1/75", "2/1/67", "8/1/69", "7/1/68", "8/1/69", 
>    "5/1/70", "7/1/70", "5/1/71", "10/1/70", "8/1/71", "11/1/71", 
>    "10/1/71", "2/1/72", "10/1/71", "9/1/69", "12/1/94", "3/1/95", 
>    "11/1/94", "12/1/93", "3/1/94", "5/1/94", "4/1/94", "2/1/94", 
>    "10/1/91", "10/1/98", "2/1/00", "12/1/98", "9/1/99", "2/1/99", 
>    "9/1/00", "12/1/01", "3/1/01", "8/1/01", "6/1/97", "9/1/02", 
>    "2/1/03", "5/1/02", "12/1/02", "5/1/03", "4/1/03", "5/1/03", 
>    "6/1/04", "5/1/79", "12/1/03", "8/1/04", "11/1/05", "11/1/11", 
>    "3/1/13", "3/1/13", "1/1/13", "8/1/13", "4/1/00", "12/1/11", 
>    "2/1/04", "4/1/12", "1/1/13", "12/1/89", "8/1/21", "1/1/42", 
>    "5/1/36", "6/1/18", "8/1/18", "12/1/18", "7/1/18", "6/1/18", 
>    "6/1/18", "7/1/18", "6/1/18", "7/1/18", "2/1/19", "11/1/19", 
>    "11/1/19", "11/1/19", "8/1/18", "8/1/18", "11/1/20", "8/1/18", 
>    "2/1/19", "5/1/19", "8/1/18", "8/1/18", "7/1/20", "7/1/20"
>    ), `TERM IN MONTHS` = c(172L, 226L, 316L, 226L, 166L, 238L, 
>    302L, 315L, 304L, 315L, 255L, 315L, 334L, 323L, 385L, 313L, 
>    315L, 391L, 315L, 331L, 327L, 331L, 331L, 331L, 331L, 328L, 
>    328L, 332L, 332L, 332L, 332L, 300L, 463L, 466L, 462L, 471L, 
>    471L, 471L, 471L, 471L, 389L, 471L, 471L, 471L, 468L, 465L, 
>    464L, 468L, 468L, 459L, 424L, 468L, 455L, 468L, 468L, 465L, 
>    468L, 465L, 468L, 180L, 468L, 468L, 468L, 480L, 480L, 480L, 
>    480L, 480L, 358L, 464L, 310L, 367L, 385L, 90L, 360L, 396L, 
>    336L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 
>    420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 
>    420L, 420L, 421L, 421L), `INTEREST RATE` = c(4.5, 4.5, 4.5, 
>    4.5, 4.5, 4.5, 4, 3.5, 4.5, 3.5, 3.75, 3.5, 4, 4.25, 4.25, 
>    4, 3.5, 4, 3.5, 4, 4, 3.5, 3.5, 4, 4, 4, 4, 4, 4, 4, 4, 3.5, 
>    4.25, 4.25, 4.25, 4.25, 4.25, 4.25, 4.25, 4.25, 4.5, 4.5, 
>    4.5, 4.5, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 
>    5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 
>    5.25, 8.5, 7.5, 7.5, 7.5, 7.5, 5.25, 6, 9, 14.5, 13, 16.5, 
>    10.75, 6.95, 5.95, 12.25, 12.5, 13, 12.5, 12.25, 12.25, 12.5, 
>    12, 12.5, 13, 13.5, 13.5, 13.5, 13, 13, 11.5, 12.5, 13, 13.5, 
>    13, 13, 12, 12), `HOLDER NAME` = c("NEW YORK LIFE INSURANCE CO", 
>    "NEW YORK LIFE INSURANCE CO", "UNION CENTRAL LIFE INS CO", 
>    "NEW YORK LIFE INSURANCE CO", "NEW YORK LIFE INSURANCE CO", 
>    "UNION CENTRAL LIFE INS CO", "NAVY MUTUAL AID ASSN", "WELLS FARGO BANK NA-PRUDENTIAL", 
>    "", "WELLS FARGO BANK NA-PRUDENTIAL", "LIFE INSURANCE CO OF VIRGINIA", 
>    "WELLS FARGO BANK NA-PRUDENTIAL", "SECURITY MUTUAL LIFE INS CO", 
>    "NAVY MUTUAL AID ASSN", "NEW YORK LIFE INSURANCE CO", "NATIONAL LIFE INSURANCE CO", 
>    "WELLS FARGO BANK NA-PRUDENTIAL", "NATIONAL LIFE INSURANCE CO", 
>    "WELLS FARGO BANK NA-PRUDENTIAL", "", "NEW YORK LIFE INSURANCE CO", 
>    "WELLS FARGO BANK NA-PRUDENTIAL", "WELLS FARGO BANK NA-PRUDENTIAL", 
>    "KEY BANK CENTRAL NY", "NATIONAL LIFE INSURANCE CO", "NATIONAL LIFE INSURANCE CO", 
>    "NEW YORK LIFE INSURANCE CO", "UNION CENTRAL LIFE INS CO", 
>    "CONNECTICUT GEN LIFE INS CO", "SAN JUAN COUNTY BK", "SECURITY MUTUAL LIFE INS CO", 
>    "WELLS FARGO BANK NA-PRUDENTIAL", "SEAMENS BANK SAVINGS FSB-FDIC", 
>    "REPUBLIC NATIONAL BANK OF NEW", "LINCOLN SAVINGS BANK", 
>    "LIBERTY LENDING INC", "EMIGRANT BANK", "PROVIDENT BANK", 
>    "EMIGRANT BANK", "NEW YORK COMMUNITY BANK", "", "", "", "", 
>    "PFC CORPORATION", "DOLLAR-DRY DOCK BANK", "PHILADELPHIA SAVINGS FUND SOC", 
>    "PHILADELPHIA SAVINGS FUND SOC", "AMERICAN GEN LIFE AND ACCDT IN", 
>    "", "", "", "", "PHILADELPHIA SAVINGS FUND SOC", "SOVRAN BANK MARYLAND", 
>    "SWISS RE LIFE AND HEALTH AMERI", "", "", "AMERICAN SECURITY CORPORATION", 
>    "PUEBLO MORTGAGE INC", "JOHN HANCOCK LIFE INSURANCE CO", 
>    "CHASE MANHATTAN BANK", "RIGGS BANK NA", "FANNIE MAE", "STATE TEACHERS RT BOARD OHIO", 
>    "STATE TEACHERS RT BOARD OHIO", "FANNIE MAE", "RIGGS BANK NA", 
>    "PEOPLES LIFE INS CO WASHINGTON", "WHITE MOUNTAINS SERVICES CORP", 
>    "RIGGS BANK NA", "DRG FUNDING CORPORATION", "FANNIE MAE", 
>    "ALLFIRST BANK", "USGI INC", "WELLS FARGO BANK NA", "ZIEGLER FINANCING CORP", 
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
>    "YORK ASSOCIATES INC", "DRG FUNDING CORPORATION", "YORK ASSOCIATES INC", 
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC"), `HOLDER CITY` = c("NEW YORK", 
>    "NEW YORK", "CINCINNATI", "NEW YORK", "NEW YORK", "CINCINNATI", 
>    "ARLINGTON", "FREDERICK", "", "FREDERICK", "RICHMOND", "FREDERICK", 
>    "BINGHAMTON", "ARLINGTON", "NEW YORK", "MONTPELIER", "FREDERICK", 
>    "MONTPELIER", "FREDERICK", "", "NEW YORK", "FREDERICK", "FREDERICK", 
>    "BUFFALO", "MONTPELIER", "MONTPELIER", "NEW YORK", "CINCINNATI", 
>    "HARTFORD", "FRIDAY HARBOR", "BINGHAMTON", "FREDERICK", "EAST HARTFORD", 
>    "NEW YORK", "JERICHO", "BARTLETT", "NEW YORK", "ISELIN", 
>    "NEW YORK", "CLEVELAND", "", "", "", "", "TUSTIN", "WHITE PLAINS", 
>    "PHILADELPHIA", "PHILADELPHIA", "NASHVILLE", "", "", "", 
>    "", "PHILADELPHIA", "BETHESDA", "NEW YORK", "", "", "BALTIMORE", 
>    "TUCSON", "BOSTON", "NEW YORK", "RIVERDALE", "PHILADELPHIA", 
>    "COLUMBUS", "COLUMBUS", "ATLANTA", "RIVERDALE", "LOUISVILLE", 
>    "FARMINGTON HILLS", "RIVERDALE", "WASHINGTON", "ATLANTA", 
>    "FREDERICK", "LA PLATA", "MC LEAN", "NEW ALBANY", "BETHESDA", 
>    "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", 
>    "BETHESDA", "WASHINGTON", "BETHESDA", "BETHESDA", "BETHESDA", 
>    "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", 
>    "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", 
>    "BETHESDA", "BETHESDA"), `HOLDER STATE` = c("NY", "NY", "OH", 
>    "NY", "NY", "OH", "VA", "MD", "", "MD", "VA", "MD", "NY", 
>    "VA", "NY", "VT", "MD", "VT", "MD", "", "NY", "MD", "MD", 
>    "NY", "VT", "VT", "NY", "OH", "CT", "WA", "NY", "MD", "CT", 
>    "NY", "NY", "TN", "NY", "NJ", "NY", "OH", "", "", "", "", 
>    "CA", "NY", "PA", "PA", "TN", "", "", "", "", "PA", "MD", 
>    "NY", "", "", "MD", "AZ", "MA", "NY", "MD", "PA", "OH", "OH", 
>    "GA", "MD", "KY", "MI", "MD", "DC", "GA", "MD", "MD", "VA", 
>    "OH", "MD", "MD", "MD", "MD", "MD", "MD", "MD", "DC", "MD", 
>    "MD", "MD", "MD", "MD", "MD", "MD", "MD", "MD", "MD", "MD", 
>    "MD", "MD", "MD", "MD"), `SERVICER NAME` = c("No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "", "", "", "", "", "", "", "", "No Data Available", 
>    "", "No Data Available", "No Data Available", "", "No Data Available", 
>    "No Data Available", "", "", "No Data Available", "", "", 
>    "", "", "", "No Data Available", "", "", "No Data Available", 
>    "", "", "", "", "", "", "", "WHITE MOUNTAINS SERVICES CORP", 
>    "", "", "", "", "USGI INC", "WELLS FARGO BANK NA", "ZIEGLER FINANCING CORP", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", ""), `SERVICER CITY` = c("", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "FARMINGTON HILLS", "", "", 
>    "", "", "LA PLATA", "MC LEAN", "NEW ALBANY", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", ""), `SERVICER STATE` = c("", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "MI", "", "", "", "", "MD", "VA", "OH", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", ""), `SECTION OF ACT CODE` = c("HRB", 
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", 
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", 
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", 
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", 
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRP", "HRB", 
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", 
>    "HRP", "HRB", "HRB", "HRB", "HRB", "HRP", "HRB", "HRP", "HRB", 
>    "HRP", "HRP", "HRB", "HRB", "HRP", "HRP", "ZSB", "ZSB", "ZSB", 
>    "ZSB", "ZSJ", "ZSQ", "ZSQ", "HRL", "HRL", "HRL", "HRL", "HRL", 
>    "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", 
>    "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL"
>    ), `SOA CATEGORY Sub Category` = c("207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Rental Projects", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Rental Projects", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Rental Projects", "207 Apartments", "207 Rental Projects", 
>    "207 Apartments", "207 Rental Projects", "207 Rental Projects", 
>    "207 Apartments", "207 Apartments", "207 Rental Projects", 
>    "207 Rental Projects", "241(a)/ 207 Improvements & Additions", 
>    "241(a)/ 207 Improvements & Additions", "241(a)/ 207 Improvements & Additions", 
>    "241(a)/ 207 Improvements & Additions", "241(a)/ 221-MIR(d)(3)&(d)(4) Improvements & Additions", 
>    "241(a)/ 232 /Improvements & Additions / Nursing Homes", 
>    "241(a)/ 232 /Improvements & Additions / Nursing Homes", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance"), `TERM TYPE` = c("11", "11", 
>    "11", "11", "11", "11", "12", "11", "11", "11", "11", "11", 
>    "11", "11", "11", "11", "11", "11", "11", "11", "11", "11", 
>    "11", "11", "11", "11", "11", "11", "11", "11", "11", "11", 
>    "11", "11", "11", "11", "11", "11", "11", "11", "11", "11", 
>    "11", "11", "18", "21", "21", "21", "11", "19", "11", "11", 
>    "20", "21", "19", "11", "21", "11", "11", "11", "11", "15", 
>    "11", "11", "11", "11", "11", "21", "19", "11", "11", "11", 
>    "11", "11", "19", "11", "11", "11", "11", "11", "11", "11", 
>    "11", "11", "11", "11", "11", "11", "11", "11", "11", "11", 
>    "14", "11", "11", "11", "11", "11", "11", "11"), `TERMINATION TYPE DESCRIPTION` = c("Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "SUPERSESSION", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Maturity", 
>    "VOLUNTARY", "VOLUNTARY", "VOLUNTARY", "Prepayment", "Assignment", 
>    "Prepayment", "Prepayment", "Acquired", "VOLUNTARY", "Assignment", 
>    "Prepayment", "VOLUNTARY", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Conveyance", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "VOLUNTARY", "Assignment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Assignment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "CANCELLED", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment"
>    ), `TYPE  Claim Non Claim ` = c("NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "CLAIM", "NONCLAIM", "NONCLAIM", "CLAIM", "NONCLAIM", 
>    "CLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "CLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "CLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "CLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM"), `TERM DATE` = c("4/1/39", "4/1/39", "9/1/40", 
>    "4/1/39", "2/1/49", "9/1/40", "9/1/44", "8/1/46", "1/1/50", 
>    "11/1/44", "7/1/54", "8/1/46", "11/1/41", "7/1/54", "12/1/39", 
>    "3/1/46", "8/1/46", "12/1/45", "11/1/44", "7/1/45", "11/1/45", 
>    "8/1/46", "8/1/46", "8/1/46", "10/1/46", "7/1/46", "9/1/47", 
>    "12/1/43", "7/1/46", "12/1/42", "5/1/44", "8/1/46", "8/1/65", 
>    "8/1/65", "8/1/65", "1/31/83", "1/31/83", "2/3/83", "1/31/83", 
>    "1/31/83", "12/7/72", "1/3/79", "12/4/79", "10/1/67", "10/1/99", 
>    "5/1/71", "4/1/70", "10/16/79", "10/1/67", "8/1/66", "2/27/75", 
>    "1/29/82", "12/1/66", "12/3/79", "4/4/75", "10/25/85", "1/30/80", 
>    "6/25/74", "12/19/72", "5/31/73", "7/1/94", "4/1/67", "3/19/87", 
>    "3/16/73", "2/13/86", "2/13/86", "5/24/82", "7/12/73", "12/8/76", 
>    "3/10/89", "3/19/87", "10/31/85", "5/24/82", "1/21/85", "8/30/95", 
>    "1/28/11", "11/30/10", "5/31/86", "5/31/86", "4/30/86", "11/20/84", 
>    "6/30/86", "6/30/86", "3/31/86", "1/16/87", "10/31/86", "12/31/85", 
>    "4/1/86", "4/1/86", "4/1/86", "3/31/86", "3/31/86", "8/3/90", 
>    "10/31/86", "6/30/86", "1/30/87", "4/30/86", "4/30/86", "2/27/87", 
>    "8/31/86"), TE = c("", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", ""
>    ), TC = c("", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", ""), Status = c(TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE)), .Names = c("HUD PROJECT NUMBER", 
> "PROPERTY NAME", "PROPERTY STREET", "PROPERTY CITY", "PROPERTY STATE", 
> "PROPERTY ZIP", "UNITS", "INITIAL ENDORSEMENT DATE", "FINAL ENDORSEMENT DATE", 
> "ORIGINAL MORTGAGE AMOUNT", "FIRST PAYMENT DATE", "MATURITY DATE", 
> "TERM IN MONTHS", "INTEREST RATE", "HOLDER NAME", "HOLDER CITY", 
> "HOLDER STATE", "SERVICER NAME", "SERVICER CITY", "SERVICER STATE", 
> "SECTION OF ACT CODE", "SOA CATEGORY Sub Category", "TERM TYPE", 
> "TERMINATION TYPE DESCRIPTION", "TYPE  Claim Non Claim ", "TERM DATE", 
> "TE", "TC", "Status"), row.names = c(NA, 100L), class = "data.frame")
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Mon Aug 15 02:32:33 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 15 Aug 2016 02:32:33 +0200
Subject: [R] need some help with date
In-Reply-To: <88CC5188-B65A-478A-9946-43B1DEA94D38@me.com>
References: <88CC5188-B65A-478A-9946-43B1DEA94D38@me.com>
Message-ID: <F4BBA025-42FD-4AEB-BAB2-5FF04D20DC9A@gmail.com>


> On 15 Aug 2016, at 00:40 , Glenn Schultz <glennmschultz at me.com> wrote:
> 
> Here is a sample of the data that I am working with.  Dates may go back as far as 1930?s.  When I use as.Date() I noticed that any data < 12/31/68 returns as the new century.  So I wrote this function below to be applied to the data which I dput below the function.  If I use the function DateCentury(Date = df[1,?TERM DATE?) it will return the correct date.  However, if I use the function as follows DateCentury[,?TERM DATE?]) it does not work. 

I suppose you intended DateCentury(Date = df[,?TERM DATE?]) there

>  Anyhow, I have been at this awhile and I am totally stumped.  I need to refactor the below date vectors across just under 50,000 observations.  Any suggestions would be greatly appreciated.

Your code isn't vectorized; a vector argument will cause trouble as soon as you get to the if() statements inside the function. 

A quick (but slow...) way out is to use Vectorize(DateCentury)(...) (or a for loop, or sapply()).  A better way is to learn how to write code in a vectorized fashion. This typically involves replacing if() with indexing ([...]) or maybe ifelse() constructions (sorry, fixing your actual code would take a bit too much time).

A couple of other hints:

- Don't write code that relies on current date. You'll regret it when you need to run it again in 20 years and 2035 is no longer in the future.

- The string manipulation looks like it would be more conveniently done by converting the dates to POSIXlt objects, manipulate the year field directly, and then convert to character using a suitable format. Or, can't you just add/subtract 100 years = 36525 days? That should work as long as you don't need to go back further than March 1, 1900 (when you'll get bitten by the fact that 1900 was not a leap year but 2000 was...). 

-pd

> 
> Best,
> Glenn
> 
> DateCentury <- function(Date = "character"){
>    ThisDate = as.Date(Date, format = "%m/%d/%y", origin = "1900-01-01")
>    CurrDate = as.Date(Sys.Date())
>    Century = as.Date("1999-12-31", format = "%Y-%m-%d", origin = "1900-01-01")
>    NewDate <- if(ThisDate > CurrDate){
> 
>      if(nchar(Date) == 6){
>        paste(substr(Date,1,4),"19", substr(Date,5,6),sep ="")
>                  } else {
>                if(nchar(Date) == 7){paste(substr(Date,1,5),"19", substr(Date,6,7),sep ="")
>                  } else {
>                paste(substr(Date,1,6),"19", substr(Date,7,8),sep ="")
>                  }
>                    }
> 
>      } else {
> 
>        if(ThisDate <= Century){
> 
>                    if(nchar(Date) == 6){
>                      paste(substr(Date,1,4),"19", substr(Date,5,6),sep ="")
>                    } else {
>                      if(nchar(Date) == 7){paste(substr(Date,1,5),"19", substr(Date,6,7),sep ="")
>                      } else {
>                        paste(substr(Date,1,6),"19", substr(Date,7,8),sep ="")  
>                        }
>                      }
>            }  else {
>                        if(nchar(Date) == 6){paste(substr(Date,1,4),"20", substr(Date,5,6),sep ="")
>                          } else {
>                        if(nchar(Date) == 7){paste(substr(Date,1,5),"20", substr(Date,6,7),sep ="")
>                        } else {
>                            paste(substr(Date,1,6),"20", substr(Date,7,8),sep ="")
>                          }
>                      }
>                    }
>          }
> 
>    return(NewDate)}
> 
> 
> 
> 
> 
> Data
> structure(list(`HUD PROJECT NUMBER` = c(1L, 2L, 3L, 4L, 5L, 6L, 
> 7L, 8L, 9L, 10L, 39L, 43L, 46L, 47L, 49L, 50L, 51L, 52L, 53L, 
> 54L, 55L, 58L, 59L, 60L, 61L, 62L, 66L, 68L, 69L, 74L, 77L, 78L, 
> 82L, 83L, 84L, 87L, 88L, 89L, 90L, 91L, 98L, 99L, 100L, 101L, 
> 102L, 103L, 104L, 105L, 107L, 108L, 110L, 111L, 112L, 113L, 114L, 
> 116L, 118L, 119L, 120L, 121L, 122L, 123L, 125L, 135L, 140L, 141L, 
> 144L, 146L, 9001L, 9002L, 10001L, 10004L, 10005L, 10007L, 10008L, 
> 10010L, 10011L, 10501L, 10502L, 10503L, 10504L, 10505L, 10506L, 
> 10507L, 10508L, 10510L, 10515L, 10516L, 10517L, 10518L, 10519L, 
> 10520L, 10521L, 10522L, 10523L, 10525L, 10526L, 10527L, 10528L, 
> 10529L), `PROPERTY NAME` = c("COLONIAL VILLAGE APTS", "COLONIAL VILLAGE APTS", 
> "FALKLAND APTS", "COLONIAL VILLAGE APTS", "BRENTWOOD VILLAGE", 
> "FALKLAND APTS", "BUCKINGHAM II", "FIRST BUCKINGHAM", "PARKBELT HOMES", 
> "BUCKINGHAM III", "SKYLAND APTS", "BUCKINGHAM IV", "WESTOVER APTS", 
> "MT VERNON DEV", "ARLINGTON VILLAGE APTS", "FAIRFAX VILLAGE III", 
> "BUCKINGHAM V", "SUBURBAN GARDENS", "BUCKINGHAM III", "PINEY BRANCH APTS", 
> "AUBURN GARDENS", "BUCKINGHAM V", "BUCKINGHAM IV", "GLEBE COURT APTS", 
> "BARCROFT APTS", "FAIRFAX VILLAGE IV", "BELLEVUE GARDENS", "FILLMORE CO INC", 
> "BRADLEY BLVD APTS", "2702 WISCONSIN", "WINCHESTER SUMMIT", "BUCKINGHAM II", 
> "ARLINGTON TOWERS", "ARLINGTON TOWERS", "ARLINGTON TOWERS", "BRADDOCK LEE APT I", 
> "BRADDOCK LEE APT II", "BRADDOCK LEE APT III", "BRADDOCK LEE APT IV", 
> "BRADDOCK LEE APT V", "4600 CONN COOP", "GARFIELD APTS", "CATHEDERAL PK TOW", 
> "SECOND PKSIDE APT", "THE ENVOY", "CARDINAL HOUSE", "TUNLAW PARK APTS", 
> "RAVENWOOD TOWERS", "PARKSIDE APTS", "PARK BERKSHIRE APTS", "JOHN MARSHALL APTS", 
> "MATTAPONY MANOR", "MOSBY VILLAGE APTS", "RIVER TOWERS", "", 
> "BARNETT HOUSE", "RIVERS TOWERS II", "FAIRHAVEN GARDENS", "CIRCLE APARTMENTS", 
> "HYBLA VALLEY MOBLE HMS", "PARK PLAZA APTS", "ENVOY TOWERS", 
> "C H HOUSTON APTS", "DUMFRIES MOBILE HM VLG", "SKYLINE TOWERS APTS I", 
> "SKYLINE CENTER APTS", "CHESTNUT GROVE APTS", "BRENTANA GARDENS", 
> "GREGORY ESTATES", "BARNABY GARDENS", "C H HOUSTON APTS", "HIGHVIEW TERRACE", 
> "CHESTNUT GROVE APTS", "ROCKVILLE NRSNG HOME", "STANTON-WELLINGTON APTS. DBA F", 
> "COLLINSWOOD NURSING HOME", "SHADY GROVE ADVENTIST NURSING", 
> "GLENDALE LAKE APTS", "GARFIELD COURT", "COUNTRYSIDE APTS", "INVIEW HOUSE", 
> "TOP OF THE PARK", "SUMMIT CREST APTS", "BRADFORD PLACE", "HILLSIDE TERR APTS", 
> "OAK HILL APTS", "PARK BERKSHIRE APTS I", "CARROLLAN MANOR", 
> "LANSDOWNE VILLAGE APTS", "GATEWAY SQUARE", "KIRKWOOD VILLAGE APTS", 
> "GOODACRE APTS", "PENN SOUTHERN APTS.", "WOODMONT PARK APTS", 
> "FINIANS CT", "ROCKFORDTHE", "ISABELLA PARK APARTMENTS", "GREENTREE III", 
> "", "MARLOW HEIGHTS SECTION A"), `PROPERTY STREET` = c("1913 WILSON BLVD", 
> "1913 WILSON BLVD", "8305 16TH STREET", "1913 WILSON BLVD", "1287 BRENTWOOD RD NE", 
> "8305 16TH STREET", "313 N GLEBE RD", "313 N GLEBE RD", "", "313 N GLEBE RD", 
> "2307 SKYLAND PL SE", "313 N GLEBE RD", "1649 N LONGFELLOW", 
> "", "1021 S BARTON", "2019 37TH ST SE", "313 N GLEBE RD", "4904 JAY ST NE", 
> "313 N GLEBE RD", "8400 PINEY BRANCH RD", "101 GLEBE ROAD E", 
> "313 N GLEBE RD", "313 N GLEBE RD", "", "1130 S GEORGE MASON DR", 
> "2019 37TH ST SE", "", "", "", "2702 WISCONSIN AVE", "", "313 N GLEBE RD", 
> "1101 ARLINGTON BLVD", "1011 ARLINGTON BLVD", "1011 ARLINGTON BLVD", 
> "3810 KING ST", "3810 KING ST", "3810 KING ST", "3810 KING ST", 
> "3810 KING ST", "4600 CONNECTICUT AVE NW", "5410 CONNECTICUT AVE NW", 
> "3100 CONNECTICUT AVE NW", "", "2144 CALIFORNIA ST  NW", "3000 SPOUT RUN PKWY", 
> "3850 TUNLAW RD NW", "6166 LEESBURG PIKE", "10520 MONTROSE AVE", 
> "6317 PENNSYLVANIA AVE", "", "5002 57TH AVE", "10560 MAIN ST", 
> "6631 WAKEFIELD DRIVE", "", "201 MASSACHUSETTS AVE NE", "6631 WAKEFIELD DRIVE", 
> "JERMANTOWN ROAD", "2030 N ADAMS ST", "BARGIN CITY-HYBLA VALLEY", 
> "1629 COLUMBIA RD NW", "2400 16TH ST NW", "1712 16TH ST NW", 
> "DUMFRIES", "5601 SEMINARY ROAD", "5600 SEMINARY ROAD", "11200 CHESTNUT GROVE SQ", 
> "", "7618 GEORGE PALMER HGWY", "3876 9TH ST SE", "1714 16TH ST NW", 
> "6800-7021 HIGHVIEW TER", "11200 CHESTNUT GROVE SQ", "303 ADCLARE ROAD", 
> "2549 ELVANS RD SE", "299 HURLEY AVENUE", "9701 MEDICAL CENTER DRIVE", 
> "10001 GREENBELT RD", "5701 43RD AVE", "9971 GOODLUCK RD", "6161 EDSALL ROAD", 
> "4009 GALLATIN ST", "38 N SUMMIT AVE", "3506 SILVER PARK RD", 
> "1805-1910 23RD ST SE", "11497 COLUMBIA PIKE", "6301 PENNSYLVANIA AVE", 
> "8621 ANNAPOLIS RD", "1720 BRIGHTSEAT RD", "4855 ST. BARNABAS RD", 
> "2731 NICHOLSON", "8619 PINEY BRANCH RD", "", "1001 ROCKVILLE PIKE", 
> "7756 FINNS LANE", "1444 ROCK CREEK FORD RD", "2214 PHELPS ROAD", 
> "8051 GREENLEAF TERR", "", "4223 28TH AVE"), `PROPERTY CITY` = c("ARLINGTON", 
> "ARLINGTON", "SILVER SPRING", "ARLINGTON", "WASHINGTON", "SILVER SPRING", 
> "ARLINGTON", "ARLINGTON", "GREENBELT", "ARLINGTON", "WASHINGTON", 
> "ARLINGTON", "ARLINGTON", "ALEXANDRIA", "ARLINGTON", "WASHINGTON", 
> "ARLINGTON", "WASHINGTON", "ARLINGTON", "SILVER SPRING", "ALEXANDRIA", 
> "ARLINGTON", "ARLINGTON", "ARLINGTON", "ARLINGTON", "WASHINGTON", 
> "WASHINGTON", "ARLINGTON", "BETHESDA", "WASHINGTON", "WASHINGTON", 
> "ARLINGTON", "ARLINGTON", "ARLINGTON", "ARLINGTON", "ALEXANDRIA", 
> "ALEXANDRIA", "ALEXANDRIA", "ALEXANDRIA", "ALEXANDRIA", "WASHINGTON", 
> "WASHINGTON", "WASHINGTON", "ROCKVILLE", "WASHINGTON", "ARLINGTON", 
> "WASHINGTON", "SEVEN CORNERS", "BETHESDA", "SUITLAND-SILVER HI", 
> "WASHINGTON", "BLADENSBURG", "FAIRFAX", "ALEXANDRIA", "", "WASHINGTON", 
> "ALEXANDRIA", "FAIRFAX", "ARLINGTON", "FAIRFAX", "WASHINGTON", 
> "WASHINGTON", "WASHINGTON", "DUMFRIES", "BAILEY'S CROSSROAD", 
> "BAILEY'S CROSSROAD", "RESTON", "RESTON", "SEAT PLEASANT", "WASHINGTON", 
> "WASHINGTON", "HYATTSVILLE", "RESTON", "ROCKVILLE", "WASHINGTON", 
> "ROCKVILLE", "ROCKVLLE", "LANHAM-SEABROOK", "HYATTSVILLE", "HYATTSVILLE", 
> "ALEXANDRIA", "HYATTSVILLE", "GAITHERSBURG", "SUITLAND-SILVER HI", 
> "WASHINGTON", "SILVER SPRING", "FORESTVILLE", "LANHAM-SEABROOK", 
> "LANDOVER", "PRINCE GEORGE'S CO", "HYATTSVILLE", "SILVER SPRING", 
> "SILVER SPRING", "PURCELLVILLE", "LANHAM-SEABROOK", "WASHINGTON", 
> "ADELPHI", "GLEN BURNIE", "", "SUITLAND-SILVER HI"), `PROPERTY STATE` = c("VA", 
> "VA", "MD", "VA", "DC", "MD", "VA", "VA", "MD", "VA", "DC", "VA", 
> "VA", "VA", "VA", "DC", "VA", "DC", "VA", "MD", "VA", "VA", "VA", 
> "VA", "VA", "DC", "DC", "VA", "MD", "DC", "DC", "VA", "VA", "VA", 
> "VA", "VA", "VA", "VA", "VA", "VA", "DC", "DC", "DC", "MD", "DC", 
> "VA", "DC", "VA", "MD", "MD", "DC", "MD", "VA", "VA", "", "DC", 
> "VA", "VA", "VA", "VA", "DC", "DC", "DC", "VA", "00", "VA", "VA", 
> "VA", "MD", "DC", "DC", "MD", "VA", "MD", "DC", "MD", "MD", "MD", 
> "MD", "MD", "VA", "MD", "MD", "MD", "DC", "MD", "MD", "MD", "MD", 
> "MD", "MD", "MD", "MD", "VA", "MD", "DC", "MD", "MD", "", "MD"
> ), `PROPERTY ZIP` = c("22201", "22201", "20910", "22201", "20018", 
> "20910", "22203", "22203", "20770", "22203", "20020", "22203", 
> "22205", "00000", "22204", "20020", "22203", "20019", "22203", 
> "20901", "22305", "22203", "22203", "00000", "22204", "20020", 
> "00000", "00000", "20014", "20007", "00000", "22203", "22209", 
> "22209", "22209", "22302", "22302", "22302", "22302", "22302", 
> "20008", "20015", "20008", "00000", "20008", "22201", "20007", 
> "22044", "20014", "20023", "00000", "20710", "22030", "22037", 
> "00000", "20002", "22307", "22030", "22201", "22030", "20009", 
> "20009", "20009", "22026", "22041", "22041", "22090", "22037", 
> "20027", "20032", "20005", "20782", "22090", "20850", "20020", 
> "20850", "20850", "20801", "20781", "20706", "22304", "20785", 
> "20877", "20746", "20020", "20904", "20747", "20706", "20785", 
> "20748", "20782", "20901", "20910", "20850", "20801", "20011", 
> "20783", "00000", "00000", "20748"), UNITS = c(274L, 464L, 181L, 
> 237L, 440L, 303L, 98L, 524L, 10L, 200L, 223L, 192L, 153L, 57L, 
> 655L, 207L, 276L, 204L, 112L, 214L, 304L, 176L, 248L, 77L, 423L, 
> 214L, 251L, 181L, 161L, 80L, 41L, 98L, 366L, 415L, 434L, 40L, 
> 58L, 80L, 40L, 40L, 267L, 166L, 323L, 120L, 113L, 229L, 284L, 
> 304L, 170L, 336L, 30L, 154L, 205L, 168L, 0L, 95L, 175L, 76L, 
> 116L, 250L, 274L, 332L, 45L, 156L, 470L, 470L, 225L, 240L, 503L, 
> 79L, 46L, 306L, 224L, 100L, 398L, 160L, 170L, 443L, 62L, 451L, 
> 207L, 106L, 232L, 213L, 192L, 281L, 336L, 187L, 345L, 297L, 750L, 
> 156L, 308L, 414L, 57L, 66L, 445L, 1122L, 0L, 0L), `INITIAL ENDORSEMENT DATE` = c("4/20/35", 
> "12/9/35", "9/11/36", "2/8/37", "8/3/37", "8/19/37", "3/15/40", 
> "8/3/37", "5/13/38", "4/13/38", "3/7/39", "8/26/38", "8/24/39", 
> "8/18/39", "1/4/39", "2/24/40", "1/4/39", "4/11/41", "5/9/39", 
> "7/10/40", "8/19/40", "7/15/40", "4/14/41", "7/15/41", "10/23/41", 
> "9/30/41", "7/16/43", "4/23/42", "3/13/42", "6/8/42", "1/18/43", 
> "9/23/44", "1/29/54", "4/30/54", "1/14/54", "9/28/54", "12/1/54", 
> "2/8/55", "1/4/55", "11/4/54", "4/16/59", "5/1/58", "6/10/59", 
> "10/1/58", "9/20/60", "12/4/58", "2/17/60", "4/13/61", "1/18/61", 
> "6/2/61", "6/19/61", "1/25/62", "11/26/62", "3/14/62", "5/4/62", 
> "9/26/62", "8/10/62", "6/3/63", "11/6/63", "8/15/63", "10/11/63", 
> "12/11/63", "8/26/65", "10/27/71", "10/10/72", "1/10/73", "8/3/71", 
> "2/7/72", "7/1/70", "5/1/73", "2/24/78", "8/31/81", "9/17/80", 
> "4/16/82", "1/19/89", "5/21/08", "4/4/08", "5/26/83", "7/11/83", 
> "11/16/83", "6/30/83", "5/26/83", "5/26/83", "6/27/83", "5/13/83", 
> "6/29/83", "1/30/84", "10/25/84", "10/25/84", "10/25/84", "7/28/83", 
> "7/28/83", "10/31/85", "7/14/83", "1/31/84", "4/10/84", "8/1/83", 
> "7/28/83", "6/20/85", "6/20/85"), `FINAL ENDORSEMENT DATE` = c("", 
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
> "", "", "", "", "", "", "", "", "", "", "", "9/20/60", "", "", 
> "", "", "", "", "", "", "", "", "11/25/64", "", "", "", "", "8/24/65", 
> "", "2/14/67", "", "1/10/73", "1/10/73", "", "", "", "12/6/82", 
> "2/24/78", "8/31/81", "", "4/16/82", "5/24/91", "7/14/09", "4/4/08", 
> "5/26/83", "7/11/83", "11/16/83", "", "5/26/83", "5/26/83", "6/27/83", 
> "5/16/83", "6/29/83", "1/31/84", "10/25/84", "10/25/84", "10/25/84", 
> "7/28/83", "7/28/83", "10/31/85", "7/14/83", "1/31/84", "4/10/84", 
> "8/1/83", "7/28/83", "6/20/85", "6/20/85"), `ORIGINAL MORTGAGE AMOUNT` = c("875,000", 
> "1,480,000", "840,000", "725,000", "1,650,000", "1,225,000", 
> "319,000", "1,825,000", "35,000", "650,000", "760,000", "725,000", 
> "410,000", "165,000", "2,385,000", "701,000", "1,035,000", "692,000", 
> "490,000", "815,000", "942,000", "610,000", "935,000", "260,000", 
> "1,500,000", "830,000", "980,000", "660,000", "630,000", "265,000", 
> "139,000", "283,000", "4,301,100", "3,831,000", "4,482,200", 
> "313,700", "462,200", "641,800", "312,000", "312,100", "4,103,600", 
> "2,313,100", "5,626,500", "1,271,600", "1,447,200", "2,838,400", 
> "4,434,100", "3,640,900", "1,905,700", "2,893,200", "270,300", 
> "1,480,000", "3,048,165", "2,365,427", "1,138,600", "1,129,200", 
> "2,436,300", "752,500", "1,691,900", "450,000", "3,799,363", 
> "4,626,400", "484,500", "561,600", "10,795,600", "11,081,000", 
> "4,248,400", "3,714,938", "1,909,441", "436,825", "25,000", "348,700", 
> "173,400", "55,100", "4,311,301", "462,300", "1,170,000", "8,499,800", 
> "1,065,700", "13,387,500", "5,880,000", "1,500,000", "3,846,600", 
> "5,300,000", "1,750,000", "4,600,000", "5,653,000", "3,000,000", 
> "5,000,000", "5,000,000", "7,500,000", "1,600,000", "6,500,000", 
> "7,300,000", "1,350,000", "1,260,900", "8,081,100", "21,988,600", 
> "10,675,000", "4,600,000"), `FIRST PAYMENT DATE` = c("1/1/36", 
> "3/1/37", "4/1/38", "5/1/38", "10/1/38", "6/1/39", "12/1/39", 
> "2/1/39", "9/1/38", "11/1/39", "9/1/40", "3/1/40", "2/1/41", 
> "2/1/41", "7/1/40", "8/1/41", "8/1/40", "7/1/42", "12/1/40", 
> "2/1/42", "5/1/41", "2/1/42", "11/1/42", "1/1/43", "11/1/43", 
> "7/1/43", "5/1/44", "4/1/44", "3/1/44", "7/1/44", "3/1/44", "10/1/44", 
> "6/1/56", "6/1/56", "6/1/56", "10/1/54", "1/1/55", "3/1/55", 
> "2/1/55", "12/1/54", "6/1/59", "8/1/59", "12/1/60", "10/1/59", 
> "10/1/60", "6/1/60", "2/1/62", "1/1/63", "4/1/62", "6/1/63", 
> "3/1/62", "10/1/63", "4/1/65", "6/1/63", "1/1/64", "9/1/64", 
> "5/1/64", "9/1/64", "7/1/65", "6/1/64", "1/1/65", "9/1/65", "12/1/66", 
> "12/1/71", "4/1/73", "4/1/73", "2/1/73", "9/1/73", "7/1/70", 
> "5/1/73", "5/1/78", "10/1/81", "1/1/81", "7/1/82", "9/1/91", 
> "2/1/09", "6/1/08", "7/1/83", "9/1/83", "1/1/84", "8/1/83", "7/1/83", 
> "7/1/83", "8/1/83", "7/1/83", "8/1/83", "3/1/84", "12/1/84", 
> "12/1/84", "12/1/84", "9/1/83", "9/1/83", "12/1/85", "9/1/83", 
> "3/1/84", "6/1/84", "9/1/83", "9/1/83", "7/1/85", "7/1/85"), 
>    `MATURITY DATE` = c("4/1/50", "12/1/55", "7/1/64", "2/1/57", 
>    "7/1/52", "3/1/59", "1/1/65", "4/1/65", "12/1/63", "1/1/66", 
>    "11/1/61", "5/1/66", "11/1/68", "12/1/67", "7/1/72", "8/1/67", 
>    "10/1/66", "1/1/75", "2/1/67", "8/1/69", "7/1/68", "8/1/69", 
>    "5/1/70", "7/1/70", "5/1/71", "10/1/70", "8/1/71", "11/1/71", 
>    "10/1/71", "2/1/72", "10/1/71", "9/1/69", "12/1/94", "3/1/95", 
>    "11/1/94", "12/1/93", "3/1/94", "5/1/94", "4/1/94", "2/1/94", 
>    "10/1/91", "10/1/98", "2/1/00", "12/1/98", "9/1/99", "2/1/99", 
>    "9/1/00", "12/1/01", "3/1/01", "8/1/01", "6/1/97", "9/1/02", 
>    "2/1/03", "5/1/02", "12/1/02", "5/1/03", "4/1/03", "5/1/03", 
>    "6/1/04", "5/1/79", "12/1/03", "8/1/04", "11/1/05", "11/1/11", 
>    "3/1/13", "3/1/13", "1/1/13", "8/1/13", "4/1/00", "12/1/11", 
>    "2/1/04", "4/1/12", "1/1/13", "12/1/89", "8/1/21", "1/1/42", 
>    "5/1/36", "6/1/18", "8/1/18", "12/1/18", "7/1/18", "6/1/18", 
>    "6/1/18", "7/1/18", "6/1/18", "7/1/18", "2/1/19", "11/1/19", 
>    "11/1/19", "11/1/19", "8/1/18", "8/1/18", "11/1/20", "8/1/18", 
>    "2/1/19", "5/1/19", "8/1/18", "8/1/18", "7/1/20", "7/1/20"
>    ), `TERM IN MONTHS` = c(172L, 226L, 316L, 226L, 166L, 238L, 
>    302L, 315L, 304L, 315L, 255L, 315L, 334L, 323L, 385L, 313L, 
>    315L, 391L, 315L, 331L, 327L, 331L, 331L, 331L, 331L, 328L, 
>    328L, 332L, 332L, 332L, 332L, 300L, 463L, 466L, 462L, 471L, 
>    471L, 471L, 471L, 471L, 389L, 471L, 471L, 471L, 468L, 465L, 
>    464L, 468L, 468L, 459L, 424L, 468L, 455L, 468L, 468L, 465L, 
>    468L, 465L, 468L, 180L, 468L, 468L, 468L, 480L, 480L, 480L, 
>    480L, 480L, 358L, 464L, 310L, 367L, 385L, 90L, 360L, 396L, 
>    336L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 
>    420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 
>    420L, 420L, 421L, 421L), `INTEREST RATE` = c(4.5, 4.5, 4.5, 
>    4.5, 4.5, 4.5, 4, 3.5, 4.5, 3.5, 3.75, 3.5, 4, 4.25, 4.25, 
>    4, 3.5, 4, 3.5, 4, 4, 3.5, 3.5, 4, 4, 4, 4, 4, 4, 4, 4, 3.5, 
>    4.25, 4.25, 4.25, 4.25, 4.25, 4.25, 4.25, 4.25, 4.5, 4.5, 
>    4.5, 4.5, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 
>    5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 
>    5.25, 8.5, 7.5, 7.5, 7.5, 7.5, 5.25, 6, 9, 14.5, 13, 16.5, 
>    10.75, 6.95, 5.95, 12.25, 12.5, 13, 12.5, 12.25, 12.25, 12.5, 
>    12, 12.5, 13, 13.5, 13.5, 13.5, 13, 13, 11.5, 12.5, 13, 13.5, 
>    13, 13, 12, 12), `HOLDER NAME` = c("NEW YORK LIFE INSURANCE CO", 
>    "NEW YORK LIFE INSURANCE CO", "UNION CENTRAL LIFE INS CO", 
>    "NEW YORK LIFE INSURANCE CO", "NEW YORK LIFE INSURANCE CO", 
>    "UNION CENTRAL LIFE INS CO", "NAVY MUTUAL AID ASSN", "WELLS FARGO BANK NA-PRUDENTIAL", 
>    "", "WELLS FARGO BANK NA-PRUDENTIAL", "LIFE INSURANCE CO OF VIRGINIA", 
>    "WELLS FARGO BANK NA-PRUDENTIAL", "SECURITY MUTUAL LIFE INS CO", 
>    "NAVY MUTUAL AID ASSN", "NEW YORK LIFE INSURANCE CO", "NATIONAL LIFE INSURANCE CO", 
>    "WELLS FARGO BANK NA-PRUDENTIAL", "NATIONAL LIFE INSURANCE CO", 
>    "WELLS FARGO BANK NA-PRUDENTIAL", "", "NEW YORK LIFE INSURANCE CO", 
>    "WELLS FARGO BANK NA-PRUDENTIAL", "WELLS FARGO BANK NA-PRUDENTIAL", 
>    "KEY BANK CENTRAL NY", "NATIONAL LIFE INSURANCE CO", "NATIONAL LIFE INSURANCE CO", 
>    "NEW YORK LIFE INSURANCE CO", "UNION CENTRAL LIFE INS CO", 
>    "CONNECTICUT GEN LIFE INS CO", "SAN JUAN COUNTY BK", "SECURITY MUTUAL LIFE INS CO", 
>    "WELLS FARGO BANK NA-PRUDENTIAL", "SEAMENS BANK SAVINGS FSB-FDIC", 
>    "REPUBLIC NATIONAL BANK OF NEW", "LINCOLN SAVINGS BANK", 
>    "LIBERTY LENDING INC", "EMIGRANT BANK", "PROVIDENT BANK", 
>    "EMIGRANT BANK", "NEW YORK COMMUNITY BANK", "", "", "", "", 
>    "PFC CORPORATION", "DOLLAR-DRY DOCK BANK", "PHILADELPHIA SAVINGS FUND SOC", 
>    "PHILADELPHIA SAVINGS FUND SOC", "AMERICAN GEN LIFE AND ACCDT IN", 
>    "", "", "", "", "PHILADELPHIA SAVINGS FUND SOC", "SOVRAN BANK MARYLAND", 
>    "SWISS RE LIFE AND HEALTH AMERI", "", "", "AMERICAN SECURITY CORPORATION", 
>    "PUEBLO MORTGAGE INC", "JOHN HANCOCK LIFE INSURANCE CO", 
>    "CHASE MANHATTAN BANK", "RIGGS BANK NA", "FANNIE MAE", "STATE TEACHERS RT BOARD OHIO", 
>    "STATE TEACHERS RT BOARD OHIO", "FANNIE MAE", "RIGGS BANK NA", 
>    "PEOPLES LIFE INS CO WASHINGTON", "WHITE MOUNTAINS SERVICES CORP", 
>    "RIGGS BANK NA", "DRG FUNDING CORPORATION", "FANNIE MAE", 
>    "ALLFIRST BANK", "USGI INC", "WELLS FARGO BANK NA", "ZIEGLER FINANCING CORP", 
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
>    "YORK ASSOCIATES INC", "DRG FUNDING CORPORATION", "YORK ASSOCIATES INC", 
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", 
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC"), `HOLDER CITY` = c("NEW YORK", 
>    "NEW YORK", "CINCINNATI", "NEW YORK", "NEW YORK", "CINCINNATI", 
>    "ARLINGTON", "FREDERICK", "", "FREDERICK", "RICHMOND", "FREDERICK", 
>    "BINGHAMTON", "ARLINGTON", "NEW YORK", "MONTPELIER", "FREDERICK", 
>    "MONTPELIER", "FREDERICK", "", "NEW YORK", "FREDERICK", "FREDERICK", 
>    "BUFFALO", "MONTPELIER", "MONTPELIER", "NEW YORK", "CINCINNATI", 
>    "HARTFORD", "FRIDAY HARBOR", "BINGHAMTON", "FREDERICK", "EAST HARTFORD", 
>    "NEW YORK", "JERICHO", "BARTLETT", "NEW YORK", "ISELIN", 
>    "NEW YORK", "CLEVELAND", "", "", "", "", "TUSTIN", "WHITE PLAINS", 
>    "PHILADELPHIA", "PHILADELPHIA", "NASHVILLE", "", "", "", 
>    "", "PHILADELPHIA", "BETHESDA", "NEW YORK", "", "", "BALTIMORE", 
>    "TUCSON", "BOSTON", "NEW YORK", "RIVERDALE", "PHILADELPHIA", 
>    "COLUMBUS", "COLUMBUS", "ATLANTA", "RIVERDALE", "LOUISVILLE", 
>    "FARMINGTON HILLS", "RIVERDALE", "WASHINGTON", "ATLANTA", 
>    "FREDERICK", "LA PLATA", "MC LEAN", "NEW ALBANY", "BETHESDA", 
>    "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", 
>    "BETHESDA", "WASHINGTON", "BETHESDA", "BETHESDA", "BETHESDA", 
>    "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", 
>    "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", 
>    "BETHESDA", "BETHESDA"), `HOLDER STATE` = c("NY", "NY", "OH", 
>    "NY", "NY", "OH", "VA", "MD", "", "MD", "VA", "MD", "NY", 
>    "VA", "NY", "VT", "MD", "VT", "MD", "", "NY", "MD", "MD", 
>    "NY", "VT", "VT", "NY", "OH", "CT", "WA", "NY", "MD", "CT", 
>    "NY", "NY", "TN", "NY", "NJ", "NY", "OH", "", "", "", "", 
>    "CA", "NY", "PA", "PA", "TN", "", "", "", "", "PA", "MD", 
>    "NY", "", "", "MD", "AZ", "MA", "NY", "MD", "PA", "OH", "OH", 
>    "GA", "MD", "KY", "MI", "MD", "DC", "GA", "MD", "MD", "VA", 
>    "OH", "MD", "MD", "MD", "MD", "MD", "MD", "MD", "DC", "MD", 
>    "MD", "MD", "MD", "MD", "MD", "MD", "MD", "MD", "MD", "MD", 
>    "MD", "MD", "MD", "MD"), `SERVICER NAME` = c("No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "No Data Available", "No Data Available", 
>    "No Data Available", "", "", "", "", "", "", "", "", "No Data Available", 
>    "", "No Data Available", "No Data Available", "", "No Data Available", 
>    "No Data Available", "", "", "No Data Available", "", "", 
>    "", "", "", "No Data Available", "", "", "No Data Available", 
>    "", "", "", "", "", "", "", "WHITE MOUNTAINS SERVICES CORP", 
>    "", "", "", "", "USGI INC", "WELLS FARGO BANK NA", "ZIEGLER FINANCING CORP", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", ""), `SERVICER CITY` = c("", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "FARMINGTON HILLS", "", "", 
>    "", "", "LA PLATA", "MC LEAN", "NEW ALBANY", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", ""), `SERVICER STATE` = c("", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "MI", "", "", "", "", "MD", "VA", "OH", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", ""), `SECTION OF ACT CODE` = c("HRB", 
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", 
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", 
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", 
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", 
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRP", "HRB", 
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", 
>    "HRP", "HRB", "HRB", "HRB", "HRB", "HRP", "HRB", "HRP", "HRB", 
>    "HRP", "HRP", "HRB", "HRB", "HRP", "HRP", "ZSB", "ZSB", "ZSB", 
>    "ZSB", "ZSJ", "ZSQ", "ZSQ", "HRL", "HRL", "HRL", "HRL", "HRL", 
>    "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", 
>    "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL"
>    ), `SOA CATEGORY Sub Category` = c("207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Rental Projects", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Apartments", "207 Apartments", "207 Rental Projects", 
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments", 
>    "207 Rental Projects", "207 Apartments", "207 Rental Projects", 
>    "207 Apartments", "207 Rental Projects", "207 Rental Projects", 
>    "207 Apartments", "207 Apartments", "207 Rental Projects", 
>    "207 Rental Projects", "241(a)/ 207 Improvements & Additions", 
>    "241(a)/ 207 Improvements & Additions", "241(a)/ 207 Improvements & Additions", 
>    "241(a)/ 207 Improvements & Additions", "241(a)/ 221-MIR(d)(3)&(d)(4) Improvements & Additions", 
>    "241(a)/ 232 /Improvements & Additions / Nursing Homes", 
>    "241(a)/ 232 /Improvements & Additions / Nursing Homes", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance", 
>    "207/ 223(f)/ 244 Co-Insurance"), `TERM TYPE` = c("11", "11", 
>    "11", "11", "11", "11", "12", "11", "11", "11", "11", "11", 
>    "11", "11", "11", "11", "11", "11", "11", "11", "11", "11", 
>    "11", "11", "11", "11", "11", "11", "11", "11", "11", "11", 
>    "11", "11", "11", "11", "11", "11", "11", "11", "11", "11", 
>    "11", "11", "18", "21", "21", "21", "11", "19", "11", "11", 
>    "20", "21", "19", "11", "21", "11", "11", "11", "11", "15", 
>    "11", "11", "11", "11", "11", "21", "19", "11", "11", "11", 
>    "11", "11", "19", "11", "11", "11", "11", "11", "11", "11", 
>    "11", "11", "11", "11", "11", "11", "11", "11", "11", "11", 
>    "14", "11", "11", "11", "11", "11", "11", "11"), `TERMINATION TYPE DESCRIPTION` = c("Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "SUPERSESSION", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Maturity", 
>    "VOLUNTARY", "VOLUNTARY", "VOLUNTARY", "Prepayment", "Assignment", 
>    "Prepayment", "Prepayment", "Acquired", "VOLUNTARY", "Assignment", 
>    "Prepayment", "VOLUNTARY", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Conveyance", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "VOLUNTARY", "Assignment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Assignment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "CANCELLED", "Prepayment", "Prepayment", 
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment"
>    ), `TYPE  Claim Non Claim ` = c("NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "CLAIM", "NONCLAIM", "NONCLAIM", "CLAIM", "NONCLAIM", 
>    "CLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "CLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "CLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "CLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", 
>    "NONCLAIM"), `TERM DATE` = c("4/1/39", "4/1/39", "9/1/40", 
>    "4/1/39", "2/1/49", "9/1/40", "9/1/44", "8/1/46", "1/1/50", 
>    "11/1/44", "7/1/54", "8/1/46", "11/1/41", "7/1/54", "12/1/39", 
>    "3/1/46", "8/1/46", "12/1/45", "11/1/44", "7/1/45", "11/1/45", 
>    "8/1/46", "8/1/46", "8/1/46", "10/1/46", "7/1/46", "9/1/47", 
>    "12/1/43", "7/1/46", "12/1/42", "5/1/44", "8/1/46", "8/1/65", 
>    "8/1/65", "8/1/65", "1/31/83", "1/31/83", "2/3/83", "1/31/83", 
>    "1/31/83", "12/7/72", "1/3/79", "12/4/79", "10/1/67", "10/1/99", 
>    "5/1/71", "4/1/70", "10/16/79", "10/1/67", "8/1/66", "2/27/75", 
>    "1/29/82", "12/1/66", "12/3/79", "4/4/75", "10/25/85", "1/30/80", 
>    "6/25/74", "12/19/72", "5/31/73", "7/1/94", "4/1/67", "3/19/87", 
>    "3/16/73", "2/13/86", "2/13/86", "5/24/82", "7/12/73", "12/8/76", 
>    "3/10/89", "3/19/87", "10/31/85", "5/24/82", "1/21/85", "8/30/95", 
>    "1/28/11", "11/30/10", "5/31/86", "5/31/86", "4/30/86", "11/20/84", 
>    "6/30/86", "6/30/86", "3/31/86", "1/16/87", "10/31/86", "12/31/85", 
>    "4/1/86", "4/1/86", "4/1/86", "3/31/86", "3/31/86", "8/3/90", 
>    "10/31/86", "6/30/86", "1/30/87", "4/30/86", "4/30/86", "2/27/87", 
>    "8/31/86"), TE = c("", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", ""
>    ), TC = c("", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
>    "", "", "", "", "", "", "", "", "", "", "", "", ""), Status = c(TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE)), .Names = c("HUD PROJECT NUMBER", 
> "PROPERTY NAME", "PROPERTY STREET", "PROPERTY CITY", "PROPERTY STATE", 
> "PROPERTY ZIP", "UNITS", "INITIAL ENDORSEMENT DATE", "FINAL ENDORSEMENT DATE", 
> "ORIGINAL MORTGAGE AMOUNT", "FIRST PAYMENT DATE", "MATURITY DATE", 
> "TERM IN MONTHS", "INTEREST RATE", "HOLDER NAME", "HOLDER CITY", 
> "HOLDER STATE", "SERVICER NAME", "SERVICER CITY", "SERVICER STATE", 
> "SECTION OF ACT CODE", "SOA CATEGORY Sub Category", "TERM TYPE", 
> "TERMINATION TYPE DESCRIPTION", "TYPE  Claim Non Claim ", "TERM DATE", 
> "TE", "TC", "Status"), row.names = c(NA, 100L), class = "data.frame")
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From drjimlemon at gmail.com  Mon Aug 15 02:48:42 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 15 Aug 2016 10:48:42 +1000
Subject: [R] need some help with date
In-Reply-To: <CA+8X3fV_wjfHn3R5sj-o7KwAX5HnE41t8j42JWOdZybeOjHQwQ@mail.gmail.com>
References: <88CC5188-B65A-478A-9946-43B1DEA94D38@me.com>
	<CA+8X3fV_wjfHn3R5sj-o7KwAX5HnE41t8j42JWOdZybeOjHQwQ@mail.gmail.com>
Message-ID: <CA+8X3fVqZ=Y0WPjsGhmhX+Tr1YsJ-wJhksQsu79XKO30AQQFAQ@mail.gmail.com>

Hi Glenn,
Perhaps this will help:

dateCentury<-function(x,new_century=20) {
 xbits<-strsplit(x,"/")
 long_year<-function(x,new_century) {
  x[3]<-ifelse(as.numeric(x[3]) <= new_century,
   paste(20,x[3],sep=""),
   paste(19,x[3],sep=""))
  xdate<-paste(x,collapse="/")
  return(xdate)
 }
 newx<-as.Date(sapply(xbits,long_year,new_century),"%m/%d/%Y")
 return(newx)
}

Jim

On Mon, Aug 15, 2016 at 10:47 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Glenn,
> Perhaps this will help:
>
> dateCentury<-function(x,new_century=20) {
>  xbits<-strsplit(x,"/")
>  long_year<-function(x,new_century) {
>   x[3]<-ifelse(as.numeric(x[3]) <= new_century,
>    paste(20,x[3],sep=""),
>    paste(19,x[3],sep=""))
>   xdate<-paste(x,collapse="/")
>   return(xdate)
>  }
>  newx<-as.Date(sapply(xbits,long_year,new_century),"%m/%d/%Y")
>  return(newx)
> }
>
> Jim
>
>
> On Mon, Aug 15, 2016 at 8:40 AM, Glenn Schultz <glennmschultz at me.com> wrote:
>> Here is a sample of the data that I am working with.  Dates may go back as far as 1930?s.  When I use as.Date() I noticed that any data < 12/31/68 returns as the new century.  So I wrote this function below to be applied to the data which I dput below the function.  If I use the function DateCentury(Date = df[1,?TERM DATE?) it will return the correct date.  However, if I use the function as follows DateCentury[,?TERM DATE?]) it does not work.  Anyhow, I have been at this awhile and I am totally stumped.  I need to refactor the below date vectors across just under 50,000 observations.  Any suggestions would be greatly appreciated.
>>
>> Best,
>> Glenn
>>
>>  DateCentury <- function(Date = "character"){
>>     ThisDate = as.Date(Date, format = "%m/%d/%y", origin = "1900-01-01")
>>     CurrDate = as.Date(Sys.Date())
>>     Century = as.Date("1999-12-31", format = "%Y-%m-%d", origin = "1900-01-01")
>>     NewDate <- if(ThisDate > CurrDate){
>>
>>       if(nchar(Date) == 6){
>>         paste(substr(Date,1,4),"19", substr(Date,5,6),sep ="")
>>                   } else {
>>                 if(nchar(Date) == 7){paste(substr(Date,1,5),"19", substr(Date,6,7),sep ="")
>>                   } else {
>>                 paste(substr(Date,1,6),"19", substr(Date,7,8),sep ="")
>>                   }
>>                     }
>>
>>       } else {
>>
>>         if(ThisDate <= Century){
>>
>>                     if(nchar(Date) == 6){
>>                       paste(substr(Date,1,4),"19", substr(Date,5,6),sep ="")
>>                     } else {
>>                       if(nchar(Date) == 7){paste(substr(Date,1,5),"19", substr(Date,6,7),sep ="")
>>                       } else {
>>                         paste(substr(Date,1,6),"19", substr(Date,7,8),sep ="")
>>                         }
>>                       }
>>             }  else {
>>                         if(nchar(Date) == 6){paste(substr(Date,1,4),"20", substr(Date,5,6),sep ="")
>>                           } else {
>>                         if(nchar(Date) == 7){paste(substr(Date,1,5),"20", substr(Date,6,7),sep ="")
>>                         } else {
>>                             paste(substr(Date,1,6),"20", substr(Date,7,8),sep ="")
>>                           }
>>                       }
>>                     }
>>           }
>>
>>     return(NewDate)}
>>
>>
>>
>>
>>
>> Data
>> structure(list(`HUD PROJECT NUMBER` = c(1L, 2L, 3L, 4L, 5L, 6L,
>> 7L, 8L, 9L, 10L, 39L, 43L, 46L, 47L, 49L, 50L, 51L, 52L, 53L,
>> 54L, 55L, 58L, 59L, 60L, 61L, 62L, 66L, 68L, 69L, 74L, 77L, 78L,
>> 82L, 83L, 84L, 87L, 88L, 89L, 90L, 91L, 98L, 99L, 100L, 101L,
>> 102L, 103L, 104L, 105L, 107L, 108L, 110L, 111L, 112L, 113L, 114L,
>> 116L, 118L, 119L, 120L, 121L, 122L, 123L, 125L, 135L, 140L, 141L,
>> 144L, 146L, 9001L, 9002L, 10001L, 10004L, 10005L, 10007L, 10008L,
>> 10010L, 10011L, 10501L, 10502L, 10503L, 10504L, 10505L, 10506L,
>> 10507L, 10508L, 10510L, 10515L, 10516L, 10517L, 10518L, 10519L,
>> 10520L, 10521L, 10522L, 10523L, 10525L, 10526L, 10527L, 10528L,
>> 10529L), `PROPERTY NAME` = c("COLONIAL VILLAGE APTS", "COLONIAL VILLAGE APTS",
>> "FALKLAND APTS", "COLONIAL VILLAGE APTS", "BRENTWOOD VILLAGE",
>> "FALKLAND APTS", "BUCKINGHAM II", "FIRST BUCKINGHAM", "PARKBELT HOMES",
>> "BUCKINGHAM III", "SKYLAND APTS", "BUCKINGHAM IV", "WESTOVER APTS",
>> "MT VERNON DEV", "ARLINGTON VILLAGE APTS", "FAIRFAX VILLAGE III",
>> "BUCKINGHAM V", "SUBURBAN GARDENS", "BUCKINGHAM III", "PINEY BRANCH APTS",
>> "AUBURN GARDENS", "BUCKINGHAM V", "BUCKINGHAM IV", "GLEBE COURT APTS",
>> "BARCROFT APTS", "FAIRFAX VILLAGE IV", "BELLEVUE GARDENS", "FILLMORE CO INC",
>> "BRADLEY BLVD APTS", "2702 WISCONSIN", "WINCHESTER SUMMIT", "BUCKINGHAM II",
>> "ARLINGTON TOWERS", "ARLINGTON TOWERS", "ARLINGTON TOWERS", "BRADDOCK LEE APT I",
>> "BRADDOCK LEE APT II", "BRADDOCK LEE APT III", "BRADDOCK LEE APT IV",
>> "BRADDOCK LEE APT V", "4600 CONN COOP", "GARFIELD APTS", "CATHEDERAL PK TOW",
>> "SECOND PKSIDE APT", "THE ENVOY", "CARDINAL HOUSE", "TUNLAW PARK APTS",
>> "RAVENWOOD TOWERS", "PARKSIDE APTS", "PARK BERKSHIRE APTS", "JOHN MARSHALL APTS",
>> "MATTAPONY MANOR", "MOSBY VILLAGE APTS", "RIVER TOWERS", "",
>> "BARNETT HOUSE", "RIVERS TOWERS II", "FAIRHAVEN GARDENS", "CIRCLE APARTMENTS",
>> "HYBLA VALLEY MOBLE HMS", "PARK PLAZA APTS", "ENVOY TOWERS",
>> "C H HOUSTON APTS", "DUMFRIES MOBILE HM VLG", "SKYLINE TOWERS APTS I",
>> "SKYLINE CENTER APTS", "CHESTNUT GROVE APTS", "BRENTANA GARDENS",
>> "GREGORY ESTATES", "BARNABY GARDENS", "C H HOUSTON APTS", "HIGHVIEW TERRACE",
>> "CHESTNUT GROVE APTS", "ROCKVILLE NRSNG HOME", "STANTON-WELLINGTON APTS. DBA F",
>> "COLLINSWOOD NURSING HOME", "SHADY GROVE ADVENTIST NURSING",
>> "GLENDALE LAKE APTS", "GARFIELD COURT", "COUNTRYSIDE APTS", "INVIEW HOUSE",
>> "TOP OF THE PARK", "SUMMIT CREST APTS", "BRADFORD PLACE", "HILLSIDE TERR APTS",
>> "OAK HILL APTS", "PARK BERKSHIRE APTS I", "CARROLLAN MANOR",
>> "LANSDOWNE VILLAGE APTS", "GATEWAY SQUARE", "KIRKWOOD VILLAGE APTS",
>> "GOODACRE APTS", "PENN SOUTHERN APTS.", "WOODMONT PARK APTS",
>> "FINIANS CT", "ROCKFORDTHE", "ISABELLA PARK APARTMENTS", "GREENTREE III",
>> "", "MARLOW HEIGHTS SECTION A"), `PROPERTY STREET` = c("1913 WILSON BLVD",
>> "1913 WILSON BLVD", "8305 16TH STREET", "1913 WILSON BLVD", "1287 BRENTWOOD RD NE",
>> "8305 16TH STREET", "313 N GLEBE RD", "313 N GLEBE RD", "", "313 N GLEBE RD",
>> "2307 SKYLAND PL SE", "313 N GLEBE RD", "1649 N LONGFELLOW",
>> "", "1021 S BARTON", "2019 37TH ST SE", "313 N GLEBE RD", "4904 JAY ST NE",
>> "313 N GLEBE RD", "8400 PINEY BRANCH RD", "101 GLEBE ROAD E",
>> "313 N GLEBE RD", "313 N GLEBE RD", "", "1130 S GEORGE MASON DR",
>> "2019 37TH ST SE", "", "", "", "2702 WISCONSIN AVE", "", "313 N GLEBE RD",
>> "1101 ARLINGTON BLVD", "1011 ARLINGTON BLVD", "1011 ARLINGTON BLVD",
>> "3810 KING ST", "3810 KING ST", "3810 KING ST", "3810 KING ST",
>> "3810 KING ST", "4600 CONNECTICUT AVE NW", "5410 CONNECTICUT AVE NW",
>> "3100 CONNECTICUT AVE NW", "", "2144 CALIFORNIA ST  NW", "3000 SPOUT RUN PKWY",
>> "3850 TUNLAW RD NW", "6166 LEESBURG PIKE", "10520 MONTROSE AVE",
>> "6317 PENNSYLVANIA AVE", "", "5002 57TH AVE", "10560 MAIN ST",
>> "6631 WAKEFIELD DRIVE", "", "201 MASSACHUSETTS AVE NE", "6631 WAKEFIELD DRIVE",
>> "JERMANTOWN ROAD", "2030 N ADAMS ST", "BARGIN CITY-HYBLA VALLEY",
>> "1629 COLUMBIA RD NW", "2400 16TH ST NW", "1712 16TH ST NW",
>> "DUMFRIES", "5601 SEMINARY ROAD", "5600 SEMINARY ROAD", "11200 CHESTNUT GROVE SQ",
>> "", "7618 GEORGE PALMER HGWY", "3876 9TH ST SE", "1714 16TH ST NW",
>> "6800-7021 HIGHVIEW TER", "11200 CHESTNUT GROVE SQ", "303 ADCLARE ROAD",
>> "2549 ELVANS RD SE", "299 HURLEY AVENUE", "9701 MEDICAL CENTER DRIVE",
>> "10001 GREENBELT RD", "5701 43RD AVE", "9971 GOODLUCK RD", "6161 EDSALL ROAD",
>> "4009 GALLATIN ST", "38 N SUMMIT AVE", "3506 SILVER PARK RD",
>> "1805-1910 23RD ST SE", "11497 COLUMBIA PIKE", "6301 PENNSYLVANIA AVE",
>> "8621 ANNAPOLIS RD", "1720 BRIGHTSEAT RD", "4855 ST. BARNABAS RD",
>> "2731 NICHOLSON", "8619 PINEY BRANCH RD", "", "1001 ROCKVILLE PIKE",
>> "7756 FINNS LANE", "1444 ROCK CREEK FORD RD", "2214 PHELPS ROAD",
>> "8051 GREENLEAF TERR", "", "4223 28TH AVE"), `PROPERTY CITY` = c("ARLINGTON",
>> "ARLINGTON", "SILVER SPRING", "ARLINGTON", "WASHINGTON", "SILVER SPRING",
>> "ARLINGTON", "ARLINGTON", "GREENBELT", "ARLINGTON", "WASHINGTON",
>> "ARLINGTON", "ARLINGTON", "ALEXANDRIA", "ARLINGTON", "WASHINGTON",
>> "ARLINGTON", "WASHINGTON", "ARLINGTON", "SILVER SPRING", "ALEXANDRIA",
>> "ARLINGTON", "ARLINGTON", "ARLINGTON", "ARLINGTON", "WASHINGTON",
>> "WASHINGTON", "ARLINGTON", "BETHESDA", "WASHINGTON", "WASHINGTON",
>> "ARLINGTON", "ARLINGTON", "ARLINGTON", "ARLINGTON", "ALEXANDRIA",
>> "ALEXANDRIA", "ALEXANDRIA", "ALEXANDRIA", "ALEXANDRIA", "WASHINGTON",
>> "WASHINGTON", "WASHINGTON", "ROCKVILLE", "WASHINGTON", "ARLINGTON",
>> "WASHINGTON", "SEVEN CORNERS", "BETHESDA", "SUITLAND-SILVER HI",
>> "WASHINGTON", "BLADENSBURG", "FAIRFAX", "ALEXANDRIA", "", "WASHINGTON",
>> "ALEXANDRIA", "FAIRFAX", "ARLINGTON", "FAIRFAX", "WASHINGTON",
>> "WASHINGTON", "WASHINGTON", "DUMFRIES", "BAILEY'S CROSSROAD",
>> "BAILEY'S CROSSROAD", "RESTON", "RESTON", "SEAT PLEASANT", "WASHINGTON",
>> "WASHINGTON", "HYATTSVILLE", "RESTON", "ROCKVILLE", "WASHINGTON",
>> "ROCKVILLE", "ROCKVLLE", "LANHAM-SEABROOK", "HYATTSVILLE", "HYATTSVILLE",
>> "ALEXANDRIA", "HYATTSVILLE", "GAITHERSBURG", "SUITLAND-SILVER HI",
>> "WASHINGTON", "SILVER SPRING", "FORESTVILLE", "LANHAM-SEABROOK",
>> "LANDOVER", "PRINCE GEORGE'S CO", "HYATTSVILLE", "SILVER SPRING",
>> "SILVER SPRING", "PURCELLVILLE", "LANHAM-SEABROOK", "WASHINGTON",
>> "ADELPHI", "GLEN BURNIE", "", "SUITLAND-SILVER HI"), `PROPERTY STATE` = c("VA",
>> "VA", "MD", "VA", "DC", "MD", "VA", "VA", "MD", "VA", "DC", "VA",
>> "VA", "VA", "VA", "DC", "VA", "DC", "VA", "MD", "VA", "VA", "VA",
>> "VA", "VA", "DC", "DC", "VA", "MD", "DC", "DC", "VA", "VA", "VA",
>> "VA", "VA", "VA", "VA", "VA", "VA", "DC", "DC", "DC", "MD", "DC",
>> "VA", "DC", "VA", "MD", "MD", "DC", "MD", "VA", "VA", "", "DC",
>> "VA", "VA", "VA", "VA", "DC", "DC", "DC", "VA", "00", "VA", "VA",
>> "VA", "MD", "DC", "DC", "MD", "VA", "MD", "DC", "MD", "MD", "MD",
>> "MD", "MD", "VA", "MD", "MD", "MD", "DC", "MD", "MD", "MD", "MD",
>> "MD", "MD", "MD", "MD", "VA", "MD", "DC", "MD", "MD", "", "MD"
>> ), `PROPERTY ZIP` = c("22201", "22201", "20910", "22201", "20018",
>> "20910", "22203", "22203", "20770", "22203", "20020", "22203",
>> "22205", "00000", "22204", "20020", "22203", "20019", "22203",
>> "20901", "22305", "22203", "22203", "00000", "22204", "20020",
>> "00000", "00000", "20014", "20007", "00000", "22203", "22209",
>> "22209", "22209", "22302", "22302", "22302", "22302", "22302",
>> "20008", "20015", "20008", "00000", "20008", "22201", "20007",
>> "22044", "20014", "20023", "00000", "20710", "22030", "22037",
>> "00000", "20002", "22307", "22030", "22201", "22030", "20009",
>> "20009", "20009", "22026", "22041", "22041", "22090", "22037",
>> "20027", "20032", "20005", "20782", "22090", "20850", "20020",
>> "20850", "20850", "20801", "20781", "20706", "22304", "20785",
>> "20877", "20746", "20020", "20904", "20747", "20706", "20785",
>> "20748", "20782", "20901", "20910", "20850", "20801", "20011",
>> "20783", "00000", "00000", "20748"), UNITS = c(274L, 464L, 181L,
>> 237L, 440L, 303L, 98L, 524L, 10L, 200L, 223L, 192L, 153L, 57L,
>> 655L, 207L, 276L, 204L, 112L, 214L, 304L, 176L, 248L, 77L, 423L,
>> 214L, 251L, 181L, 161L, 80L, 41L, 98L, 366L, 415L, 434L, 40L,
>> 58L, 80L, 40L, 40L, 267L, 166L, 323L, 120L, 113L, 229L, 284L,
>> 304L, 170L, 336L, 30L, 154L, 205L, 168L, 0L, 95L, 175L, 76L,
>> 116L, 250L, 274L, 332L, 45L, 156L, 470L, 470L, 225L, 240L, 503L,
>> 79L, 46L, 306L, 224L, 100L, 398L, 160L, 170L, 443L, 62L, 451L,
>> 207L, 106L, 232L, 213L, 192L, 281L, 336L, 187L, 345L, 297L, 750L,
>> 156L, 308L, 414L, 57L, 66L, 445L, 1122L, 0L, 0L), `INITIAL ENDORSEMENT DATE` = c("4/20/35",
>> "12/9/35", "9/11/36", "2/8/37", "8/3/37", "8/19/37", "3/15/40",
>> "8/3/37", "5/13/38", "4/13/38", "3/7/39", "8/26/38", "8/24/39",
>> "8/18/39", "1/4/39", "2/24/40", "1/4/39", "4/11/41", "5/9/39",
>> "7/10/40", "8/19/40", "7/15/40", "4/14/41", "7/15/41", "10/23/41",
>> "9/30/41", "7/16/43", "4/23/42", "3/13/42", "6/8/42", "1/18/43",
>> "9/23/44", "1/29/54", "4/30/54", "1/14/54", "9/28/54", "12/1/54",
>> "2/8/55", "1/4/55", "11/4/54", "4/16/59", "5/1/58", "6/10/59",
>> "10/1/58", "9/20/60", "12/4/58", "2/17/60", "4/13/61", "1/18/61",
>> "6/2/61", "6/19/61", "1/25/62", "11/26/62", "3/14/62", "5/4/62",
>> "9/26/62", "8/10/62", "6/3/63", "11/6/63", "8/15/63", "10/11/63",
>> "12/11/63", "8/26/65", "10/27/71", "10/10/72", "1/10/73", "8/3/71",
>> "2/7/72", "7/1/70", "5/1/73", "2/24/78", "8/31/81", "9/17/80",
>> "4/16/82", "1/19/89", "5/21/08", "4/4/08", "5/26/83", "7/11/83",
>> "11/16/83", "6/30/83", "5/26/83", "5/26/83", "6/27/83", "5/13/83",
>> "6/29/83", "1/30/84", "10/25/84", "10/25/84", "10/25/84", "7/28/83",
>> "7/28/83", "10/31/85", "7/14/83", "1/31/84", "4/10/84", "8/1/83",
>> "7/28/83", "6/20/85", "6/20/85"), `FINAL ENDORSEMENT DATE` = c("",
>> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>> "", "", "", "", "", "", "", "", "", "", "", "9/20/60", "", "",
>> "", "", "", "", "", "", "", "", "11/25/64", "", "", "", "", "8/24/65",
>> "", "2/14/67", "", "1/10/73", "1/10/73", "", "", "", "12/6/82",
>> "2/24/78", "8/31/81", "", "4/16/82", "5/24/91", "7/14/09", "4/4/08",
>> "5/26/83", "7/11/83", "11/16/83", "", "5/26/83", "5/26/83", "6/27/83",
>> "5/16/83", "6/29/83", "1/31/84", "10/25/84", "10/25/84", "10/25/84",
>> "7/28/83", "7/28/83", "10/31/85", "7/14/83", "1/31/84", "4/10/84",
>> "8/1/83", "7/28/83", "6/20/85", "6/20/85"), `ORIGINAL MORTGAGE AMOUNT` = c("875,000",
>> "1,480,000", "840,000", "725,000", "1,650,000", "1,225,000",
>> "319,000", "1,825,000", "35,000", "650,000", "760,000", "725,000",
>> "410,000", "165,000", "2,385,000", "701,000", "1,035,000", "692,000",
>> "490,000", "815,000", "942,000", "610,000", "935,000", "260,000",
>> "1,500,000", "830,000", "980,000", "660,000", "630,000", "265,000",
>> "139,000", "283,000", "4,301,100", "3,831,000", "4,482,200",
>> "313,700", "462,200", "641,800", "312,000", "312,100", "4,103,600",
>> "2,313,100", "5,626,500", "1,271,600", "1,447,200", "2,838,400",
>> "4,434,100", "3,640,900", "1,905,700", "2,893,200", "270,300",
>> "1,480,000", "3,048,165", "2,365,427", "1,138,600", "1,129,200",
>> "2,436,300", "752,500", "1,691,900", "450,000", "3,799,363",
>> "4,626,400", "484,500", "561,600", "10,795,600", "11,081,000",
>> "4,248,400", "3,714,938", "1,909,441", "436,825", "25,000", "348,700",
>> "173,400", "55,100", "4,311,301", "462,300", "1,170,000", "8,499,800",
>> "1,065,700", "13,387,500", "5,880,000", "1,500,000", "3,846,600",
>> "5,300,000", "1,750,000", "4,600,000", "5,653,000", "3,000,000",
>> "5,000,000", "5,000,000", "7,500,000", "1,600,000", "6,500,000",
>> "7,300,000", "1,350,000", "1,260,900", "8,081,100", "21,988,600",
>> "10,675,000", "4,600,000"), `FIRST PAYMENT DATE` = c("1/1/36",
>> "3/1/37", "4/1/38", "5/1/38", "10/1/38", "6/1/39", "12/1/39",
>> "2/1/39", "9/1/38", "11/1/39", "9/1/40", "3/1/40", "2/1/41",
>> "2/1/41", "7/1/40", "8/1/41", "8/1/40", "7/1/42", "12/1/40",
>> "2/1/42", "5/1/41", "2/1/42", "11/1/42", "1/1/43", "11/1/43",
>> "7/1/43", "5/1/44", "4/1/44", "3/1/44", "7/1/44", "3/1/44", "10/1/44",
>> "6/1/56", "6/1/56", "6/1/56", "10/1/54", "1/1/55", "3/1/55",
>> "2/1/55", "12/1/54", "6/1/59", "8/1/59", "12/1/60", "10/1/59",
>> "10/1/60", "6/1/60", "2/1/62", "1/1/63", "4/1/62", "6/1/63",
>> "3/1/62", "10/1/63", "4/1/65", "6/1/63", "1/1/64", "9/1/64",
>> "5/1/64", "9/1/64", "7/1/65", "6/1/64", "1/1/65", "9/1/65", "12/1/66",
>> "12/1/71", "4/1/73", "4/1/73", "2/1/73", "9/1/73", "7/1/70",
>> "5/1/73", "5/1/78", "10/1/81", "1/1/81", "7/1/82", "9/1/91",
>> "2/1/09", "6/1/08", "7/1/83", "9/1/83", "1/1/84", "8/1/83", "7/1/83",
>> "7/1/83", "8/1/83", "7/1/83", "8/1/83", "3/1/84", "12/1/84",
>> "12/1/84", "12/1/84", "9/1/83", "9/1/83", "12/1/85", "9/1/83",
>> "3/1/84", "6/1/84", "9/1/83", "9/1/83", "7/1/85", "7/1/85"),
>>     `MATURITY DATE` = c("4/1/50", "12/1/55", "7/1/64", "2/1/57",
>>     "7/1/52", "3/1/59", "1/1/65", "4/1/65", "12/1/63", "1/1/66",
>>     "11/1/61", "5/1/66", "11/1/68", "12/1/67", "7/1/72", "8/1/67",
>>     "10/1/66", "1/1/75", "2/1/67", "8/1/69", "7/1/68", "8/1/69",
>>     "5/1/70", "7/1/70", "5/1/71", "10/1/70", "8/1/71", "11/1/71",
>>     "10/1/71", "2/1/72", "10/1/71", "9/1/69", "12/1/94", "3/1/95",
>>     "11/1/94", "12/1/93", "3/1/94", "5/1/94", "4/1/94", "2/1/94",
>>     "10/1/91", "10/1/98", "2/1/00", "12/1/98", "9/1/99", "2/1/99",
>>     "9/1/00", "12/1/01", "3/1/01", "8/1/01", "6/1/97", "9/1/02",
>>     "2/1/03", "5/1/02", "12/1/02", "5/1/03", "4/1/03", "5/1/03",
>>     "6/1/04", "5/1/79", "12/1/03", "8/1/04", "11/1/05", "11/1/11",
>>     "3/1/13", "3/1/13", "1/1/13", "8/1/13", "4/1/00", "12/1/11",
>>     "2/1/04", "4/1/12", "1/1/13", "12/1/89", "8/1/21", "1/1/42",
>>     "5/1/36", "6/1/18", "8/1/18", "12/1/18", "7/1/18", "6/1/18",
>>     "6/1/18", "7/1/18", "6/1/18", "7/1/18", "2/1/19", "11/1/19",
>>     "11/1/19", "11/1/19", "8/1/18", "8/1/18", "11/1/20", "8/1/18",
>>     "2/1/19", "5/1/19", "8/1/18", "8/1/18", "7/1/20", "7/1/20"
>>     ), `TERM IN MONTHS` = c(172L, 226L, 316L, 226L, 166L, 238L,
>>     302L, 315L, 304L, 315L, 255L, 315L, 334L, 323L, 385L, 313L,
>>     315L, 391L, 315L, 331L, 327L, 331L, 331L, 331L, 331L, 328L,
>>     328L, 332L, 332L, 332L, 332L, 300L, 463L, 466L, 462L, 471L,
>>     471L, 471L, 471L, 471L, 389L, 471L, 471L, 471L, 468L, 465L,
>>     464L, 468L, 468L, 459L, 424L, 468L, 455L, 468L, 468L, 465L,
>>     468L, 465L, 468L, 180L, 468L, 468L, 468L, 480L, 480L, 480L,
>>     480L, 480L, 358L, 464L, 310L, 367L, 385L, 90L, 360L, 396L,
>>     336L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L,
>>     420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L,
>>     420L, 420L, 421L, 421L), `INTEREST RATE` = c(4.5, 4.5, 4.5,
>>     4.5, 4.5, 4.5, 4, 3.5, 4.5, 3.5, 3.75, 3.5, 4, 4.25, 4.25,
>>     4, 3.5, 4, 3.5, 4, 4, 3.5, 3.5, 4, 4, 4, 4, 4, 4, 4, 4, 3.5,
>>     4.25, 4.25, 4.25, 4.25, 4.25, 4.25, 4.25, 4.25, 4.5, 4.5,
>>     4.5, 4.5, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25,
>>     5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25,
>>     5.25, 8.5, 7.5, 7.5, 7.5, 7.5, 5.25, 6, 9, 14.5, 13, 16.5,
>>     10.75, 6.95, 5.95, 12.25, 12.5, 13, 12.5, 12.25, 12.25, 12.5,
>>     12, 12.5, 13, 13.5, 13.5, 13.5, 13, 13, 11.5, 12.5, 13, 13.5,
>>     13, 13, 12, 12), `HOLDER NAME` = c("NEW YORK LIFE INSURANCE CO",
>>     "NEW YORK LIFE INSURANCE CO", "UNION CENTRAL LIFE INS CO",
>>     "NEW YORK LIFE INSURANCE CO", "NEW YORK LIFE INSURANCE CO",
>>     "UNION CENTRAL LIFE INS CO", "NAVY MUTUAL AID ASSN", "WELLS FARGO BANK NA-PRUDENTIAL",
>>     "", "WELLS FARGO BANK NA-PRUDENTIAL", "LIFE INSURANCE CO OF VIRGINIA",
>>     "WELLS FARGO BANK NA-PRUDENTIAL", "SECURITY MUTUAL LIFE INS CO",
>>     "NAVY MUTUAL AID ASSN", "NEW YORK LIFE INSURANCE CO", "NATIONAL LIFE INSURANCE CO",
>>     "WELLS FARGO BANK NA-PRUDENTIAL", "NATIONAL LIFE INSURANCE CO",
>>     "WELLS FARGO BANK NA-PRUDENTIAL", "", "NEW YORK LIFE INSURANCE CO",
>>     "WELLS FARGO BANK NA-PRUDENTIAL", "WELLS FARGO BANK NA-PRUDENTIAL",
>>     "KEY BANK CENTRAL NY", "NATIONAL LIFE INSURANCE CO", "NATIONAL LIFE INSURANCE CO",
>>     "NEW YORK LIFE INSURANCE CO", "UNION CENTRAL LIFE INS CO",
>>     "CONNECTICUT GEN LIFE INS CO", "SAN JUAN COUNTY BK", "SECURITY MUTUAL LIFE INS CO",
>>     "WELLS FARGO BANK NA-PRUDENTIAL", "SEAMENS BANK SAVINGS FSB-FDIC",
>>     "REPUBLIC NATIONAL BANK OF NEW", "LINCOLN SAVINGS BANK",
>>     "LIBERTY LENDING INC", "EMIGRANT BANK", "PROVIDENT BANK",
>>     "EMIGRANT BANK", "NEW YORK COMMUNITY BANK", "", "", "", "",
>>     "PFC CORPORATION", "DOLLAR-DRY DOCK BANK", "PHILADELPHIA SAVINGS FUND SOC",
>>     "PHILADELPHIA SAVINGS FUND SOC", "AMERICAN GEN LIFE AND ACCDT IN",
>>     "", "", "", "", "PHILADELPHIA SAVINGS FUND SOC", "SOVRAN BANK MARYLAND",
>>     "SWISS RE LIFE AND HEALTH AMERI", "", "", "AMERICAN SECURITY CORPORATION",
>>     "PUEBLO MORTGAGE INC", "JOHN HANCOCK LIFE INSURANCE CO",
>>     "CHASE MANHATTAN BANK", "RIGGS BANK NA", "FANNIE MAE", "STATE TEACHERS RT BOARD OHIO",
>>     "STATE TEACHERS RT BOARD OHIO", "FANNIE MAE", "RIGGS BANK NA",
>>     "PEOPLES LIFE INS CO WASHINGTON", "WHITE MOUNTAINS SERVICES CORP",
>>     "RIGGS BANK NA", "DRG FUNDING CORPORATION", "FANNIE MAE",
>>     "ALLFIRST BANK", "USGI INC", "WELLS FARGO BANK NA", "ZIEGLER FINANCING CORP",
>>     "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC",
>>     "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC",
>>     "YORK ASSOCIATES INC", "DRG FUNDING CORPORATION", "YORK ASSOCIATES INC",
>>     "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC",
>>     "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC",
>>     "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC",
>>     "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC",
>>     "YORK ASSOCIATES INC", "YORK ASSOCIATES INC"), `HOLDER CITY` = c("NEW YORK",
>>     "NEW YORK", "CINCINNATI", "NEW YORK", "NEW YORK", "CINCINNATI",
>>     "ARLINGTON", "FREDERICK", "", "FREDERICK", "RICHMOND", "FREDERICK",
>>     "BINGHAMTON", "ARLINGTON", "NEW YORK", "MONTPELIER", "FREDERICK",
>>     "MONTPELIER", "FREDERICK", "", "NEW YORK", "FREDERICK", "FREDERICK",
>>     "BUFFALO", "MONTPELIER", "MONTPELIER", "NEW YORK", "CINCINNATI",
>>     "HARTFORD", "FRIDAY HARBOR", "BINGHAMTON", "FREDERICK", "EAST HARTFORD",
>>     "NEW YORK", "JERICHO", "BARTLETT", "NEW YORK", "ISELIN",
>>     "NEW YORK", "CLEVELAND", "", "", "", "", "TUSTIN", "WHITE PLAINS",
>>     "PHILADELPHIA", "PHILADELPHIA", "NASHVILLE", "", "", "",
>>     "", "PHILADELPHIA", "BETHESDA", "NEW YORK", "", "", "BALTIMORE",
>>     "TUCSON", "BOSTON", "NEW YORK", "RIVERDALE", "PHILADELPHIA",
>>     "COLUMBUS", "COLUMBUS", "ATLANTA", "RIVERDALE", "LOUISVILLE",
>>     "FARMINGTON HILLS", "RIVERDALE", "WASHINGTON", "ATLANTA",
>>     "FREDERICK", "LA PLATA", "MC LEAN", "NEW ALBANY", "BETHESDA",
>>     "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA",
>>     "BETHESDA", "WASHINGTON", "BETHESDA", "BETHESDA", "BETHESDA",
>>     "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA",
>>     "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA",
>>     "BETHESDA", "BETHESDA"), `HOLDER STATE` = c("NY", "NY", "OH",
>>     "NY", "NY", "OH", "VA", "MD", "", "MD", "VA", "MD", "NY",
>>     "VA", "NY", "VT", "MD", "VT", "MD", "", "NY", "MD", "MD",
>>     "NY", "VT", "VT", "NY", "OH", "CT", "WA", "NY", "MD", "CT",
>>     "NY", "NY", "TN", "NY", "NJ", "NY", "OH", "", "", "", "",
>>     "CA", "NY", "PA", "PA", "TN", "", "", "", "", "PA", "MD",
>>     "NY", "", "", "MD", "AZ", "MA", "NY", "MD", "PA", "OH", "OH",
>>     "GA", "MD", "KY", "MI", "MD", "DC", "GA", "MD", "MD", "VA",
>>     "OH", "MD", "MD", "MD", "MD", "MD", "MD", "MD", "DC", "MD",
>>     "MD", "MD", "MD", "MD", "MD", "MD", "MD", "MD", "MD", "MD",
>>     "MD", "MD", "MD", "MD"), `SERVICER NAME` = c("No Data Available",
>>     "No Data Available", "No Data Available", "No Data Available",
>>     "No Data Available", "No Data Available", "No Data Available",
>>     "No Data Available", "No Data Available", "No Data Available",
>>     "No Data Available", "No Data Available", "No Data Available",
>>     "No Data Available", "No Data Available", "No Data Available",
>>     "No Data Available", "No Data Available", "No Data Available",
>>     "No Data Available", "No Data Available", "No Data Available",
>>     "No Data Available", "No Data Available", "No Data Available",
>>     "No Data Available", "No Data Available", "No Data Available",
>>     "No Data Available", "No Data Available", "No Data Available",
>>     "No Data Available", "No Data Available", "No Data Available",
>>     "No Data Available", "", "", "", "", "", "", "", "", "No Data Available",
>>     "", "No Data Available", "No Data Available", "", "No Data Available",
>>     "No Data Available", "", "", "No Data Available", "", "",
>>     "", "", "", "No Data Available", "", "", "No Data Available",
>>     "", "", "", "", "", "", "", "WHITE MOUNTAINS SERVICES CORP",
>>     "", "", "", "", "USGI INC", "WELLS FARGO BANK NA", "ZIEGLER FINANCING CORP",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", ""), `SERVICER CITY` = c("",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "FARMINGTON HILLS", "", "",
>>     "", "", "LA PLATA", "MC LEAN", "NEW ALBANY", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", ""), `SERVICER STATE` = c("", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "MI", "", "", "", "", "MD", "VA", "OH",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", ""), `SECTION OF ACT CODE` = c("HRB",
>>     "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB",
>>     "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB",
>>     "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB",
>>     "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB",
>>     "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRP", "HRB",
>>     "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB",
>>     "HRP", "HRB", "HRB", "HRB", "HRB", "HRP", "HRB", "HRP", "HRB",
>>     "HRP", "HRP", "HRB", "HRB", "HRP", "HRP", "ZSB", "ZSB", "ZSB",
>>     "ZSB", "ZSJ", "ZSQ", "ZSQ", "HRL", "HRL", "HRL", "HRL", "HRL",
>>     "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL",
>>     "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL"
>>     ), `SOA CATEGORY Sub Category` = c("207 Apartments", "207 Apartments",
>>     "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>>     "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>>     "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>>     "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>>     "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>>     "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>>     "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>>     "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>>     "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>>     "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>>     "207 Apartments", "207 Apartments", "207 Rental Projects",
>>     "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>>     "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>>     "207 Apartments", "207 Apartments", "207 Rental Projects",
>>     "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>>     "207 Rental Projects", "207 Apartments", "207 Rental Projects",
>>     "207 Apartments", "207 Rental Projects", "207 Rental Projects",
>>     "207 Apartments", "207 Apartments", "207 Rental Projects",
>>     "207 Rental Projects", "241(a)/ 207 Improvements & Additions",
>>     "241(a)/ 207 Improvements & Additions", "241(a)/ 207 Improvements & Additions",
>>     "241(a)/ 207 Improvements & Additions", "241(a)/ 221-MIR(d)(3)&(d)(4) Improvements & Additions",
>>     "241(a)/ 232 /Improvements & Additions / Nursing Homes",
>>     "241(a)/ 232 /Improvements & Additions / Nursing Homes",
>>     "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>>     "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>>     "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>>     "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>>     "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>>     "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>>     "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>>     "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>>     "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>>     "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>>     "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>>     "207/ 223(f)/ 244 Co-Insurance"), `TERM TYPE` = c("11", "11",
>>     "11", "11", "11", "11", "12", "11", "11", "11", "11", "11",
>>     "11", "11", "11", "11", "11", "11", "11", "11", "11", "11",
>>     "11", "11", "11", "11", "11", "11", "11", "11", "11", "11",
>>     "11", "11", "11", "11", "11", "11", "11", "11", "11", "11",
>>     "11", "11", "18", "21", "21", "21", "11", "19", "11", "11",
>>     "20", "21", "19", "11", "21", "11", "11", "11", "11", "15",
>>     "11", "11", "11", "11", "11", "21", "19", "11", "11", "11",
>>     "11", "11", "19", "11", "11", "11", "11", "11", "11", "11",
>>     "11", "11", "11", "11", "11", "11", "11", "11", "11", "11",
>>     "14", "11", "11", "11", "11", "11", "11", "11"), `TERMINATION TYPE DESCRIPTION` = c("Prepayment",
>>     "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>>     "SUPERSESSION", "Prepayment", "Prepayment", "Prepayment",
>>     "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>>     "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>>     "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>>     "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>>     "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>>     "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>>     "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Maturity",
>>     "VOLUNTARY", "VOLUNTARY", "VOLUNTARY", "Prepayment", "Assignment",
>>     "Prepayment", "Prepayment", "Acquired", "VOLUNTARY", "Assignment",
>>     "Prepayment", "VOLUNTARY", "Prepayment", "Prepayment", "Prepayment",
>>     "Prepayment", "Conveyance", "Prepayment", "Prepayment", "Prepayment",
>>     "Prepayment", "Prepayment", "VOLUNTARY", "Assignment", "Prepayment",
>>     "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Assignment",
>>     "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>>     "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>>     "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>>     "Prepayment", "Prepayment", "CANCELLED", "Prepayment", "Prepayment",
>>     "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment"
>>     ), `TYPE  Claim Non Claim ` = c("NONCLAIM", "NONCLAIM", "NONCLAIM",
>>     "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>>     "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>>     "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>>     "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>>     "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>>     "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>>     "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>>     "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>>     "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>>     "NONCLAIM", "CLAIM", "NONCLAIM", "NONCLAIM", "CLAIM", "NONCLAIM",
>>     "CLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>>     "NONCLAIM", "NONCLAIM", "CLAIM", "NONCLAIM", "NONCLAIM",
>>     "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "CLAIM",
>>     "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>>     "CLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>>     "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>>     "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>>     "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>>     "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>>     "NONCLAIM"), `TERM DATE` = c("4/1/39", "4/1/39", "9/1/40",
>>     "4/1/39", "2/1/49", "9/1/40", "9/1/44", "8/1/46", "1/1/50",
>>     "11/1/44", "7/1/54", "8/1/46", "11/1/41", "7/1/54", "12/1/39",
>>     "3/1/46", "8/1/46", "12/1/45", "11/1/44", "7/1/45", "11/1/45",
>>     "8/1/46", "8/1/46", "8/1/46", "10/1/46", "7/1/46", "9/1/47",
>>     "12/1/43", "7/1/46", "12/1/42", "5/1/44", "8/1/46", "8/1/65",
>>     "8/1/65", "8/1/65", "1/31/83", "1/31/83", "2/3/83", "1/31/83",
>>     "1/31/83", "12/7/72", "1/3/79", "12/4/79", "10/1/67", "10/1/99",
>>     "5/1/71", "4/1/70", "10/16/79", "10/1/67", "8/1/66", "2/27/75",
>>     "1/29/82", "12/1/66", "12/3/79", "4/4/75", "10/25/85", "1/30/80",
>>     "6/25/74", "12/19/72", "5/31/73", "7/1/94", "4/1/67", "3/19/87",
>>     "3/16/73", "2/13/86", "2/13/86", "5/24/82", "7/12/73", "12/8/76",
>>     "3/10/89", "3/19/87", "10/31/85", "5/24/82", "1/21/85", "8/30/95",
>>     "1/28/11", "11/30/10", "5/31/86", "5/31/86", "4/30/86", "11/20/84",
>>     "6/30/86", "6/30/86", "3/31/86", "1/16/87", "10/31/86", "12/31/85",
>>     "4/1/86", "4/1/86", "4/1/86", "3/31/86", "3/31/86", "8/3/90",
>>     "10/31/86", "6/30/86", "1/30/87", "4/30/86", "4/30/86", "2/27/87",
>>     "8/31/86"), TE = c("", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", ""
>>     ), TC = c("", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>>     "", "", "", "", "", "", "", "", "", "", "", "", ""), Status = c(TRUE,
>>     TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>>     TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>>     TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>>     TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>>     TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>>     TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>>     TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>>     TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>>     TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>>     TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE)), .Names = c("HUD PROJECT NUMBER",
>> "PROPERTY NAME", "PROPERTY STREET", "PROPERTY CITY", "PROPERTY STATE",
>> "PROPERTY ZIP", "UNITS", "INITIAL ENDORSEMENT DATE", "FINAL ENDORSEMENT DATE",
>> "ORIGINAL MORTGAGE AMOUNT", "FIRST PAYMENT DATE", "MATURITY DATE",
>> "TERM IN MONTHS", "INTEREST RATE", "HOLDER NAME", "HOLDER CITY",
>> "HOLDER STATE", "SERVICER NAME", "SERVICER CITY", "SERVICER STATE",
>> "SECTION OF ACT CODE", "SOA CATEGORY Sub Category", "TERM TYPE",
>> "TERMINATION TYPE DESCRIPTION", "TYPE  Claim Non Claim ", "TERM DATE",
>> "TE", "TC", "Status"), row.names = c(NA, 100L), class = "data.frame")
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon Aug 15 03:01:36 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 14 Aug 2016 18:01:36 -0700 (PDT)
Subject: [R] need some help with date
In-Reply-To: <88CC5188-B65A-478A-9946-43B1DEA94D38@me.com>
References: <88CC5188-B65A-478A-9946-43B1DEA94D38@me.com>
Message-ID: <alpine.BSF.2.00.1608141709440.28855@pedal.dcn.davis.ca.us>

Thank you for the (not quite working) example.

a) your '= "character"' bit is a bit anti-productive, since on the one 
hand you are indicating that a default value can be used (so omitting any 
argument is okay) yet the default value you are specifying is invalid.

b) The origin argument is rarely needed when converting from character 
strings. It is usually needed when you plan to convert to or from the 
underlying numeric value, which is primarily useful when interfacing with 
broken data formats such as XLS.

c) You really need to study the help pages for ?if and ?ifelse, or 
perhaps the "Introduction to R" document that comes with R. The "if" 
programming control construct is not designed for manipulating vectors.


DateCentury2 <- function( Dt ) {
   # strsplit returns a list of "rows" of values
   # do.call passes that list to the rbind function as arguments
   #  to make a matrix
   # conversion to numeric loses the matrix dimensions, have to
   #  re-convert to matrix
   parts <- matrix( as.numeric( do.call( rbind
                                       , strsplit( Dt, "/", fixed = TRUE )
                                       )
                              )
                  , nrow = length( Dt )
                  )
   # extract two digit year from current Date
   CurrYr <- as.POSIXlt( Sys.Date() )$year %% 100
   # TRUE values for rows where year value needs to be 1900
   idx <- parts[ , 3 ] > CurrYr
   # push two-digit years to appropriate century
   parts[ , 3 ] <- parts[ , 3 ] + ifelse( idx, 1900, 2000 )
   # create a date, note ISOdate returns POSIXct rather than Date type
   result <- as.Date( ISOdate( parts[ , 3 ], parts[ , 1 ], parts[ , 2 ] ) )
   result
}


On Sun, 14 Aug 2016, Glenn Schultz wrote:

> Here is a sample of the data that I am working with.  Dates may go back as far as 1930?s.  When I use as.Date() I noticed that any data < 12/31/68 returns as the new century.  So I wrote this function below to be applied to the data which I dput below the function.  If I use the function DateCentury(Date = df[1,?TERM DATE?) it will return the correct date.  However, if I use the function as follows DateCentury[,?TERM DATE?]) it does not work.  Anyhow, I have been at this awhile and I am totally stumped.  I need to refactor the below date vectors across just under 50,000 observations.  Any suggestions would be greatly appreciated.
>
> Best,
> Glenn
>
> DateCentury <- function(Date = "character"){
>    ThisDate = as.Date(Date, format = "%m/%d/%y", origin = "1900-01-01")
>    CurrDate = as.Date(Sys.Date())
>    Century = as.Date("1999-12-31", format = "%Y-%m-%d", origin = "1900-01-01")
>    NewDate <- if(ThisDate > CurrDate){
>
>      if(nchar(Date) == 6){
>        paste(substr(Date,1,4),"19", substr(Date,5,6),sep ="")
>                  } else {
>                if(nchar(Date) == 7){paste(substr(Date,1,5),"19", substr(Date,6,7),sep ="")
>                  } else {
>                paste(substr(Date,1,6),"19", substr(Date,7,8),sep ="")
>                  }
>                    }
>
>      } else {
>
>        if(ThisDate <= Century){
>
>                    if(nchar(Date) == 6){
>                      paste(substr(Date,1,4),"19", substr(Date,5,6),sep ="")
>                    } else {
>                      if(nchar(Date) == 7){paste(substr(Date,1,5),"19", substr(Date,6,7),sep ="")
>                      } else {
>                        paste(substr(Date,1,6),"19", substr(Date,7,8),sep ="")
>                        }
>                      }
>            }  else {
>                        if(nchar(Date) == 6){paste(substr(Date,1,4),"20", substr(Date,5,6),sep ="")
>                          } else {
>                        if(nchar(Date) == 7){paste(substr(Date,1,5),"20", substr(Date,6,7),sep ="")
>                        } else {
>                            paste(substr(Date,1,6),"20", substr(Date,7,8),sep ="")
>                          }
>                      }
>                    }
>          }
>
>    return(NewDate)}
>
>
>
>
>
> Data
> structure(list(`HUD PROJECT NUMBER` = c(1L, 2L, 3L, 4L, 5L, 6L, 
> 7L, 8L, 9L, 10L, 39L, 43L, 46L, 47L, 49L, 50L, 51L, 52L, 53L, 
> 54L, 55L, 58L, 59L, 60L, 61L, 62L, 66L, 68L, 69L, 74L, 77L, 78L, 
> 82L, 83L, 84L, 87L, 88L, 89L, 90L, 91L, 98L, 99L, 100L, 101L, 
> 102L, 103L, 104L, 105L, 107L, 108L, 110L, 111L, 112L, 113L, 114L, 
> 116L, 118L, 119L, 120L, 121L, 122L, 123L, 125L, 135L, 140L, 141L, 
> 144L, 146L, 9001L, 9002L, 10001L, 10004L, 10005L, 10007L, 10008L, 
> 10010L, 10011L, 10501L, 10502L, 10503L, 10504L, 10505L, 10506L, 
> 10507L, 10508L, 10510L, 10515L, 10516L, 10517L, 10518L, 10519L, 
> 10520L, 10521L, 10522L, 10523L, 10525L, 10526L, 10527L, 10528L, 
> 10529L), `PROPERTY NAME` = c("COLONIAL VILLAGE APTS", "COLONIAL VILLAGE APTS", 
> "FALKLAND APTS", "COLONIAL VILLAGE APTS", "BRENTWOOD VILLAGE", 
> "FALKLAND APTS", "BUCKINGHAM II", "FIRST BUCKINGHAM", "PARKBELT HOMES", 
> "BUCKINGHAM III", "SKYLAND APTS", "BUCKINGHAM IV", "WESTOVER APTS", 
> "MT VERNON DEV", "ARLINGTON VILLAGE APTS", "FAIRFAX VILLAGE III", 
> "BUCKINGHAM V", "SUBURBAN GARDENS", "BUCKINGHAM III", "PINEY BRANCH APTS", 
> "AUBURN GARDENS", "BUCKINGHAM V", "BUCKINGHAM IV", "GLEBE COURT APTS", 
> "BARCROFT APTS", "FAIRFAX VILLAGE IV", "BELLEVUE GARDENS", "FILLMORE CO INC", 
> "BRADLEY BLVD APTS", "2702 WISCONSIN", "WINCHESTER SUMMIT", "BUCKINGHAM II", 
> "ARLINGTON TOWERS", "ARLINGTON TOWERS", "ARLINGTON TOWERS", "BRADDOCK LEE APT I", 
> "BRADDOCK LEE APT II", "BRADDOCK LEE APT III", "BRADDOCK LEE APT IV", 
> "BRADDOCK LEE APT V", "4600 CONN COOP", "GARFIELD APTS", "CATHEDERAL PK TOW", 
> "SECOND PKSIDE APT", "THE ENVOY", "CARDINAL HOUSE", "TUNLAW PARK APTS", 
> "RAVENWOOD TOWERS", "PARKSIDE APTS", "PARK BERKSHIRE APTS", "JOHN MARSHALL APTS", 
> "MATTAPONY MANOR", "MOSBY VILLAGE APTS", "RIVER TOWERS", "", 
> "BARNETT HOUSE", "RIVERS TOWERS II", "FAIRHAVEN GARDENS", "CIRCLE APARTMENTS", 
> "HYBLA VALLEY MOBLE HMS", "PARK PLAZA APTS", "ENVOY TOWERS", 
> "C H HOUSTON APTS", "DUMFRIES MOBILE HM VLG", "SKYLINE TOWERS APTS I", 
> "SKYLINE CENTER APTS", "CHESTNUT GROVE APTS", "BRENTANA GARDENS", 
> "GREGORY ESTATES", "BARNABY GARDENS", "C H HOUSTON APTS", "HIGHVIEW TERRACE", 
> "CHESTNUT GROVE APTS", "ROCKVILLE NRSNG HOME", "STANTON-WELLINGTON APTS. DBA F", 
> "COLLINSWOOD NURSING HOME", "SHADY GROVE ADVENTIST NURSING", 
> "GLENDALE LAKE APTS", "GARFIELD COURT", "COUNTRYSIDE APTS", "INVIEW HOUSE", 
> "TOP OF THE PARK", "SUMMIT CREST APTS", "BRADFORD PLACE", "HILLSIDE TERR APTS", 
> "OAK HILL APTS", "PARK BERKSHIRE APTS I", "CARROLLAN MANOR", 
> "LANSDOWNE VILLAGE APTS", "GATEWAY SQUARE", "KIRKWOOD VILLAGE APTS", 
> "GOODACRE APTS", "PENN SOUTHERN APTS.", "WOODMONT PARK APTS", 
> "FINIANS CT", "ROCKFORDTHE", "ISABELLA PARK APARTMENTS", "GREENTREE III", 
> "", "MARLOW HEIGHTS SECTION A"), `PROPERTY STREET` = c("1913 WILSON BLVD", 
> "1913 WILSON BLVD", "8305 16TH STREET", "1913 WILSON BLVD", "1287 BRENTWOOD RD NE", 
> "8305 16TH STREET", "313 N GLEBE RD", "313 N GLEBE RD", "", "313 N GLEBE RD", 
> "2307 SKYLAND PL SE", "313 N GLEBE RD", "1649 N LONGFELLOW", 
> "", "1021 S BARTON", "2019 37TH ST SE", "313 N GLEBE RD", "4904 JAY ST NE", 
> "313 N GLEBE RD", "8400 PINEY BRANCH RD", "101 GLEBE ROAD E", 
> "313 N GLEBE RD", "313 N GLEBE RD", "", "1130 S GEORGE MASON DR", 
> "2019 37TH ST SE", "", "", "", "2702 WISCONSIN AVE", "", "313 N GLEBE RD", 
> "1101 ARLINGTON BLVD", "1011 ARLINGTON BLVD", "1011 ARLINGTON BLVD", 
> "3810 KING ST", "3810 KING ST", "3810 KING ST", "3810 KING ST", 
> "3810 KING ST", "4600 CONNECTICUT AVE NW", "5410 CONNECTICUT AVE NW", 
> "3100 CONNECTICUT AVE NW", "", "2144 CALIFORNIA ST  NW", "3000 SPOUT RUN PKWY", 
> "3850 TUNLAW RD NW", "6166 LEESBURG PIKE", "10520 MONTROSE AVE", 
> "6317 PENNSYLVANIA AVE", "", "5002 57TH AVE", "10560 MAIN ST", 
> "6631 WAKEFIELD DRIVE", "", "201 MASSACHUSETTS AVE NE", "6631 WAKEFIELD DRIVE", 
> "JERMANTOWN ROAD", "2030 N ADAMS ST", "BARGIN CITY-HYBLA VALLEY", 
> "1629 COLUMBIA RD NW", "2400 16TH ST NW", "1712 16TH ST NW", 
> "DUMFRIES", "5601 SEMINARY ROAD", "5600 SEMINARY ROAD", "11200 CHESTNUT GROVE SQ", 
> "", "7618 GEORGE PALMER HGWY", "3876 9TH ST SE", "1714 16TH ST NW", 
> "6800-7021 HIGHVIEW TER", "11200 CHESTNUT GROVE SQ", "303 ADCLARE ROAD", 
> "2549 ELVANS RD SE", "299 HURLEY AVENUE", "9701 MEDICAL CENTER DRIVE", 
> "10001 GREENBELT RD", "5701 43RD AVE", "9971 GOODLUCK RD", "6161 EDSALL ROAD", 
> "4009 GALLATIN ST", "38 N SUMMIT AVE", "3506 SILVER PARK RD", 
> "1805-1910 23RD ST SE", "11497 COLUMBIA PIKE", "6301 PENNSYLVANIA AVE", 
> "8621 ANNAPOLIS RD", "1720 BRIGHTSEAT RD", "4855 ST. BARNABAS RD", 
> "2731 NICHOLSON", "8619 PINEY BRANCH RD", "", "1001 ROCKVILLE PIKE", 
> "7756 FINNS LANE", "1444 ROCK CREEK FORD RD", "2214 PHELPS ROAD", 
> "8051 GREENLEAF TERR", "", "4223 28TH AVE"), `PROPERTY CITY` = c("ARLINGTON", 
> "ARLINGTON", "SILVER SPRING", "ARLINGTON", "WASHINGTON", "SILVER SPRING", 
> "ARLINGTON", "ARLINGTON", "GREENBELT", "ARLINGTON", "WASHINGTON", 
> "ARLINGTON", "ARLINGTON", "ALEXANDRIA", "ARLINGTON", "WASHINGTON", 
> "ARLINGTON", "WASHINGTON", "ARLINGTON", "SILVER SPRING", "ALEXANDRIA", 
> "ARLINGTON", "ARLINGTON", "ARLINGTON", "ARLINGTON", "WASHINGTON", 
> "WASHINGTON", "ARLINGTON", "BETHESDA", "WASHINGTON", "WASHINGTON", 
> "ARLINGTON", "ARLINGTON", "ARLINGTON", "ARLINGTON", "ALEXANDRIA", 
> "ALEXANDRIA", "ALEXANDRIA", "ALEXANDRIA", "ALEXANDRIA", "WASHINGTON", 
> "WASHINGTON", "WASHINGTON", "ROCKVILLE", "WASHINGTON", "ARLINGTON", 
> "WASHINGTON", "SEVEN CORNERS", "BETHESDA", "SUITLAND-SILVER HI", 
> "WASHINGTON", "BLADENSBURG", "FAIRFAX", "ALEXANDRIA", "", "WASHINGTON", 
> "ALEXANDRIA", "FAIRFAX", "ARLINGTON", "FAIRFAX", "WASHINGTON", 
> "WASHINGTON", "WASHINGTON", "DUMFRIES", "BAILEY'S CROSSROAD", 
> "BAILEY'S CROSSROAD", "RESTON", "RESTON", "SEAT PLEASANT", "WASHINGTON", 
> "WASHINGTON", "HYATTSVILLE", "RESTON", "ROCKVILLE", "WASHINGTON", 
> "ROCKVILLE", "ROCKVLLE", "LANHAM-SEABROOK", "HYATTSVILLE", "HYATTSVILLE", 
> "ALEXANDRIA", "HYATTSVILLE", "GAITHERSBURG", "SUITLAND-SILVER HI", 
> "WASHINGTON", "SILVER SPRING", "FORESTVILLE", "LANHAM-SEABROOK", 
> "LANDOVER", "PRINCE GEORGE'S CO", "HYATTSVILLE", "SILVER SPRING", 
> "SILVER SPRING", "PURCELLVILLE", "LANHAM-SEABROOK", "WASHINGTON", 
> "ADELPHI", "GLEN BURNIE", "", "SUITLAND-SILVER HI"), `PROPERTY STATE` = c("VA", 
> "VA", "MD", "VA", "DC", "MD", "VA", "VA", "MD", "VA", "DC", "VA", 
> "VA", "VA", "VA", "DC", "VA", "DC", "VA", "MD", "VA", "VA", "VA", 
> "VA", "VA", "DC", "DC", "VA", "MD", "DC", "DC", "VA", "VA", "VA", 
> "VA", "VA", "VA", "VA", "VA", "VA", "DC", "DC", "DC", "MD", "DC", 
> "VA", "DC", "VA", "MD", "MD", "DC", "MD", "VA", "VA", "", "DC", 
> "VA", "VA", "VA", "VA", "DC", "DC", "DC", "VA", "00", "VA", "VA", 
> "VA", "MD", "DC", "DC", "MD", "VA", "MD", "DC", "MD", "MD", "MD", 
> "MD", "MD", "VA", "MD", "MD", "MD", "DC", "MD", "MD", "MD", "MD", 
> "MD", "MD", "MD", "MD", "VA", "MD", "DC", "MD", "MD", "", "MD"
> ), `PROPERTY ZIP` = c("22201", "22201", "20910", "22201", "20018", 
> "20910", "22203", "22203", "20770", "22203", "20020", "22203", 
> "22205", "00000", "22204", "20020", "22203", "20019", "22203", 
> "20901", "22305", "22203", "22203", "00000", "22204", "20020", 
> "00000", "00000", "20014", "20007", "00000", "22203", "22209", 
> "22209", "22209", "22302", "22302", "22302", "22302", "22302", 
> "20008", "20015", "20008", "00000", "20008", "22201", "20007", 
> "22044", "20014", "20023", "00000", "20710", "22030", "22037", 
> "00000", "20002", "22307", "22030", "22201", "22030", "20009", 
> "20009", "20009", "22026", "22041", "22041", "22090", "22037", 
> "20027", "20032", "20005", "20782", "22090", "20850", "20020", 
> "20850", "20850", "20801", "20781", "20706", "22304", "20785", 
> "20877", "20746", "20020", "20904", "20747", "20706", "20785", 
> "20748", "20782", "20901", "20910", "20850", "20801", "20011", 
> "20783", "00000", "00000", "20748"), UNITS = c(274L, 464L, 181L, 
> 237L, 440L, 303L, 98L, 524L, 10L, 200L, 223L, 192L, 153L, 57L, 
> 655L, 207L, 276L, 204L, 112L, 214L, 304L, 176L, 248L, 77L, 423L, 
> 214L, 251L, 181L, 161L, 80L, 41L, 98L, 366L, 415L, 434L, 40L, 
> 58L, 80L, 40L, 40L, 267L, 166L, 323L, 120L, 113L, 229L, 284L, 
> 304L, 170L, 336L, 30L, 154L, 205L, 168L, 0L, 95L, 175L, 76L, 
> 116L, 250L, 274L, 332L, 45L, 156L, 470L, 470L, 225L, 240L, 503L, 
> 79L, 46L, 306L, 224L, 100L, 398L, 160L, 170L, 443L, 62L, 451L, 
> 207L, 106L, 232L, 213L, 192L, 281L, 336L, 187L, 345L, 297L, 750L, 
> 156L, 308L, 414L, 57L, 66L, 445L, 1122L, 0L, 0L), `INITIAL ENDORSEMENT DATE` = c("4/20/35", 
> "12/9/35", "9/11/36", "2/8/37", "8/3/37", "8/19/37", "3/15/40", 
> "8/3/37", "5/13/38", "4/13/38", "3/7/39", "8/26/38", "8/24/39", 
> "8/18/39", "1/4/39", "2/24/40", "1/4/39", "4/11/41", "5/9/39", 
> "7/10/40", "8/19/40", "7/15/40", "4/14/41", "7/15/41", "10/23/41", 
> "9/30/41", "7/16/43", "4/23/42", "3/13/42", "6/8/42", "1/18/43", 
> "9/23/44", "1/29/54", "4/30/54", "1/14/54", "9/28/54", "12/1/54", 
> "2/8/55", "1/4/55", "11/4/54", "4/16/59", "5/1/58", "6/10/59", 
> "10/1/58", "9/20/60", "12/4/58", "2/17/60", "4/13/61", "1/18/61", 
> "6/2/61", "6/19/61", "1/25/62", "11/26/62", "3/14/62", "5/4/62", 
> "9/26/62", "8/10/62", "6/3/63", "11/6/63", "8/15/63", "10/11/63", 
> "12/11/63", "8/26/65", "10/27/71", "10/10/72", "1/10/73", "8/3/71", 
> "2/7/72", "7/1/70", "5/1/73", "2/24/78", "8/31/81", "9/17/80", 
> "4/16/82", "1/19/89", "5/21/08", "4/4/08", "5/26/83", "7/11/83", 
> "11/16/83", "6/30/83", "5/26/83", "5/26/83", "6/27/83", "5/13/83", 
> "6/29/83", "1/30/84", "10/25/84", "10/25/84", "10/25/84", "7/28/83", 
> "7/28/83", "10/31/85", "7/14/83", "1/31/84", "4/10/84", "8/1/83", 
> "7/28/83", "6/20/85", "6/20/85"), `FINAL ENDORSEMENT DATE` = c("", 
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
> "", "", "", "", "", "", "", "", "", "", "", "9/20/60", "", "", 
> "", "", "", "", "", "", "", "", "11/25/64", "", "", "", "", "8/24/65", 
> "", "2/14/67", "", "1/10/73", "1/10/73", "", "", "", "12/6/82", 
> "2/24/78", "8/31/81", "", "4/16/82", "5/24/91", "7/14/09", "4/4/08", 
> "5/26/83", "7/11/83", "11/16/83", "", "5/26/83", "5/26/83", "6/27/83", 
> "5/16/83", "6/29/83", "1/31/84", "10/25/84", "10/25/84", "10/25/84", 
> "7/28/83", "7/28/83", "10/31/85", "7/14/83", "1/31/84", "4/10/84", 
> "8/1/83", "7/28/83", "6/20/85", "6/20/85"), `ORIGINAL MORTGAGE AMOUNT` = c("875,000", 
> "1,480,000", "840,000", "725,000", "1,650,000", "1,225,000", 
> "319,000", "1,825,000", "35,000", "650,000", "760,000", "725,000", 
> "410,000", "165,000", "2,385,000", "701,000", "1,035,000", "692,000", 
> "490,000", "815,000", "942,000", "610,000", "935,000", "260,000", 
> "1,500,000", "830,000", "980,000", "660,000", "630,000", "265,000", 
> "139,000", "283,000", "4,301,100", "3,831,000", "4,482,200", 
> "313,700", "462,200", "641,800", "312,000", "312,100", "4,103,600", 
> "2,313,100", "5,626,500", "1,271,600", "1,447,200", "2,838,400", 
> "4,434,100", "3,640,900", "1,905,700", "2,893,200", "270,300", 
> "1,480,000", "3,048,165", "2,365,427", "1,138,600", "1,129,200", 
> "2,436,300", "752,500", "1,691,900", "450,000", "3,799,363", 
> "4,626,400", "484,500", "561,600", "10,795,600", "11,081,000", 
> "4,248,400", "3,714,938", "1,909,441", "436,825", "25,000", "348,700", 
> "173,400", "55,100", "4,311,301", "462,300", "1,170,000", "8,499,800", 
> "1,065,700", "13,387,500", "5,880,000", "1,500,000", "3,846,600", 
> "5,300,000", "1,750,000", "4,600,000", "5,653,000", "3,000,000", 
> "5,000,000", "5,000,000", "7,500,000", "1,600,000", "6,500,000", 
> "7,300,000", "1,350,000", "1,260,900", "8,081,100", "21,988,600", 
> "10,675,000", "4,600,000"), `FIRST PAYMENT DATE` = c("1/1/36", 
> "3/1/37", "4/1/38", "5/1/38", "10/1/38", "6/1/39", "12/1/39", 
> "2/1/39", "9/1/38", "11/1/39", "9/1/40", "3/1/40", "2/1/41", 
> "2/1/41", "7/1/40", "8/1/41", "8/1/40", "7/1/42", "12/1/40", 
> "2/1/42", "5/1/41", "2/1/42", "11/1/42", "1/1/43", "11/1/43", 
> "7/1/43", "5/1/44", "4/1/44", "3/1/44", "7/1/44", "3/1/44", "10/1/44", 
> "6/1/56", "6/1/56", "6/1/56", "10/1/54", "1/1/55", "3/1/55", 
> "2/1/55", "12/1/54", "6/1/59", "8/1/59", "12/1/60", "10/1/59", 
> "10/1/60", "6/1/60", "2/1/62", "1/1/63", "4/1/62", "6/1/63", 
> "3/1/62", "10/1/63", "4/1/65", "6/1/63", "1/1/64", "9/1/64", 
> "5/1/64", "9/1/64", "7/1/65", "6/1/64", "1/1/65", "9/1/65", "12/1/66", 
> "12/1/71", "4/1/73", "4/1/73", "2/1/73", "9/1/73", "7/1/70", 
> "5/1/73", "5/1/78", "10/1/81", "1/1/81", "7/1/82", "9/1/91", 
> "2/1/09", "6/1/08", "7/1/83", "9/1/83", "1/1/84", "8/1/83", "7/1/83", 
> "7/1/83", "8/1/83", "7/1/83", "8/1/83", "3/1/84", "12/1/84", 
> "12/1/84", "12/1/84", "9/1/83", "9/1/83", "12/1/85", "9/1/83", 
> "3/1/84", "6/1/84", "9/1/83", "9/1/83", "7/1/85", "7/1/85"),
>    `MATURITY DATE` = c("4/1/50", "12/1/55", "7/1/64", "2/1/57",
>    "7/1/52", "3/1/59", "1/1/65", "4/1/65", "12/1/63", "1/1/66",
>    "11/1/61", "5/1/66", "11/1/68", "12/1/67", "7/1/72", "8/1/67",
>    "10/1/66", "1/1/75", "2/1/67", "8/1/69", "7/1/68", "8/1/69",
>    "5/1/70", "7/1/70", "5/1/71", "10/1/70", "8/1/71", "11/1/71",
>    "10/1/71", "2/1/72", "10/1/71", "9/1/69", "12/1/94", "3/1/95",
>    "11/1/94", "12/1/93", "3/1/94", "5/1/94", "4/1/94", "2/1/94",
>    "10/1/91", "10/1/98", "2/1/00", "12/1/98", "9/1/99", "2/1/99",
>    "9/1/00", "12/1/01", "3/1/01", "8/1/01", "6/1/97", "9/1/02",
>    "2/1/03", "5/1/02", "12/1/02", "5/1/03", "4/1/03", "5/1/03",
>    "6/1/04", "5/1/79", "12/1/03", "8/1/04", "11/1/05", "11/1/11",
>    "3/1/13", "3/1/13", "1/1/13", "8/1/13", "4/1/00", "12/1/11",
>    "2/1/04", "4/1/12", "1/1/13", "12/1/89", "8/1/21", "1/1/42",
>    "5/1/36", "6/1/18", "8/1/18", "12/1/18", "7/1/18", "6/1/18",
>    "6/1/18", "7/1/18", "6/1/18", "7/1/18", "2/1/19", "11/1/19",
>    "11/1/19", "11/1/19", "8/1/18", "8/1/18", "11/1/20", "8/1/18",
>    "2/1/19", "5/1/19", "8/1/18", "8/1/18", "7/1/20", "7/1/20"
>    ), `TERM IN MONTHS` = c(172L, 226L, 316L, 226L, 166L, 238L,
>    302L, 315L, 304L, 315L, 255L, 315L, 334L, 323L, 385L, 313L,
>    315L, 391L, 315L, 331L, 327L, 331L, 331L, 331L, 331L, 328L,
>    328L, 332L, 332L, 332L, 332L, 300L, 463L, 466L, 462L, 471L,
>    471L, 471L, 471L, 471L, 389L, 471L, 471L, 471L, 468L, 465L,
>    464L, 468L, 468L, 459L, 424L, 468L, 455L, 468L, 468L, 465L,
>    468L, 465L, 468L, 180L, 468L, 468L, 468L, 480L, 480L, 480L,
>    480L, 480L, 358L, 464L, 310L, 367L, 385L, 90L, 360L, 396L,
>    336L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L,
>    420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L, 420L,
>    420L, 420L, 421L, 421L), `INTEREST RATE` = c(4.5, 4.5, 4.5,
>    4.5, 4.5, 4.5, 4, 3.5, 4.5, 3.5, 3.75, 3.5, 4, 4.25, 4.25,
>    4, 3.5, 4, 3.5, 4, 4, 3.5, 3.5, 4, 4, 4, 4, 4, 4, 4, 4, 3.5,
>    4.25, 4.25, 4.25, 4.25, 4.25, 4.25, 4.25, 4.25, 4.5, 4.5,
>    4.5, 4.5, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25,
>    5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25,
>    5.25, 8.5, 7.5, 7.5, 7.5, 7.5, 5.25, 6, 9, 14.5, 13, 16.5,
>    10.75, 6.95, 5.95, 12.25, 12.5, 13, 12.5, 12.25, 12.25, 12.5,
>    12, 12.5, 13, 13.5, 13.5, 13.5, 13, 13, 11.5, 12.5, 13, 13.5,
>    13, 13, 12, 12), `HOLDER NAME` = c("NEW YORK LIFE INSURANCE CO",
>    "NEW YORK LIFE INSURANCE CO", "UNION CENTRAL LIFE INS CO",
>    "NEW YORK LIFE INSURANCE CO", "NEW YORK LIFE INSURANCE CO",
>    "UNION CENTRAL LIFE INS CO", "NAVY MUTUAL AID ASSN", "WELLS FARGO BANK NA-PRUDENTIAL",
>    "", "WELLS FARGO BANK NA-PRUDENTIAL", "LIFE INSURANCE CO OF VIRGINIA",
>    "WELLS FARGO BANK NA-PRUDENTIAL", "SECURITY MUTUAL LIFE INS CO",
>    "NAVY MUTUAL AID ASSN", "NEW YORK LIFE INSURANCE CO", "NATIONAL LIFE INSURANCE CO",
>    "WELLS FARGO BANK NA-PRUDENTIAL", "NATIONAL LIFE INSURANCE CO",
>    "WELLS FARGO BANK NA-PRUDENTIAL", "", "NEW YORK LIFE INSURANCE CO",
>    "WELLS FARGO BANK NA-PRUDENTIAL", "WELLS FARGO BANK NA-PRUDENTIAL",
>    "KEY BANK CENTRAL NY", "NATIONAL LIFE INSURANCE CO", "NATIONAL LIFE INSURANCE CO",
>    "NEW YORK LIFE INSURANCE CO", "UNION CENTRAL LIFE INS CO",
>    "CONNECTICUT GEN LIFE INS CO", "SAN JUAN COUNTY BK", "SECURITY MUTUAL LIFE INS CO",
>    "WELLS FARGO BANK NA-PRUDENTIAL", "SEAMENS BANK SAVINGS FSB-FDIC",
>    "REPUBLIC NATIONAL BANK OF NEW", "LINCOLN SAVINGS BANK",
>    "LIBERTY LENDING INC", "EMIGRANT BANK", "PROVIDENT BANK",
>    "EMIGRANT BANK", "NEW YORK COMMUNITY BANK", "", "", "", "",
>    "PFC CORPORATION", "DOLLAR-DRY DOCK BANK", "PHILADELPHIA SAVINGS FUND SOC",
>    "PHILADELPHIA SAVINGS FUND SOC", "AMERICAN GEN LIFE AND ACCDT IN",
>    "", "", "", "", "PHILADELPHIA SAVINGS FUND SOC", "SOVRAN BANK MARYLAND",
>    "SWISS RE LIFE AND HEALTH AMERI", "", "", "AMERICAN SECURITY CORPORATION",
>    "PUEBLO MORTGAGE INC", "JOHN HANCOCK LIFE INSURANCE CO",
>    "CHASE MANHATTAN BANK", "RIGGS BANK NA", "FANNIE MAE", "STATE TEACHERS RT BOARD OHIO",
>    "STATE TEACHERS RT BOARD OHIO", "FANNIE MAE", "RIGGS BANK NA",
>    "PEOPLES LIFE INS CO WASHINGTON", "WHITE MOUNTAINS SERVICES CORP",
>    "RIGGS BANK NA", "DRG FUNDING CORPORATION", "FANNIE MAE",
>    "ALLFIRST BANK", "USGI INC", "WELLS FARGO BANK NA", "ZIEGLER FINANCING CORP",
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC",
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC",
>    "YORK ASSOCIATES INC", "DRG FUNDING CORPORATION", "YORK ASSOCIATES INC",
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC",
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC",
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC",
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC", "YORK ASSOCIATES INC",
>    "YORK ASSOCIATES INC", "YORK ASSOCIATES INC"), `HOLDER CITY` = c("NEW YORK",
>    "NEW YORK", "CINCINNATI", "NEW YORK", "NEW YORK", "CINCINNATI",
>    "ARLINGTON", "FREDERICK", "", "FREDERICK", "RICHMOND", "FREDERICK",
>    "BINGHAMTON", "ARLINGTON", "NEW YORK", "MONTPELIER", "FREDERICK",
>    "MONTPELIER", "FREDERICK", "", "NEW YORK", "FREDERICK", "FREDERICK",
>    "BUFFALO", "MONTPELIER", "MONTPELIER", "NEW YORK", "CINCINNATI",
>    "HARTFORD", "FRIDAY HARBOR", "BINGHAMTON", "FREDERICK", "EAST HARTFORD",
>    "NEW YORK", "JERICHO", "BARTLETT", "NEW YORK", "ISELIN",
>    "NEW YORK", "CLEVELAND", "", "", "", "", "TUSTIN", "WHITE PLAINS",
>    "PHILADELPHIA", "PHILADELPHIA", "NASHVILLE", "", "", "",
>    "", "PHILADELPHIA", "BETHESDA", "NEW YORK", "", "", "BALTIMORE",
>    "TUCSON", "BOSTON", "NEW YORK", "RIVERDALE", "PHILADELPHIA",
>    "COLUMBUS", "COLUMBUS", "ATLANTA", "RIVERDALE", "LOUISVILLE",
>    "FARMINGTON HILLS", "RIVERDALE", "WASHINGTON", "ATLANTA",
>    "FREDERICK", "LA PLATA", "MC LEAN", "NEW ALBANY", "BETHESDA",
>    "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA",
>    "BETHESDA", "WASHINGTON", "BETHESDA", "BETHESDA", "BETHESDA",
>    "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA",
>    "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA", "BETHESDA",
>    "BETHESDA", "BETHESDA"), `HOLDER STATE` = c("NY", "NY", "OH",
>    "NY", "NY", "OH", "VA", "MD", "", "MD", "VA", "MD", "NY",
>    "VA", "NY", "VT", "MD", "VT", "MD", "", "NY", "MD", "MD",
>    "NY", "VT", "VT", "NY", "OH", "CT", "WA", "NY", "MD", "CT",
>    "NY", "NY", "TN", "NY", "NJ", "NY", "OH", "", "", "", "",
>    "CA", "NY", "PA", "PA", "TN", "", "", "", "", "PA", "MD",
>    "NY", "", "", "MD", "AZ", "MA", "NY", "MD", "PA", "OH", "OH",
>    "GA", "MD", "KY", "MI", "MD", "DC", "GA", "MD", "MD", "VA",
>    "OH", "MD", "MD", "MD", "MD", "MD", "MD", "MD", "DC", "MD",
>    "MD", "MD", "MD", "MD", "MD", "MD", "MD", "MD", "MD", "MD",
>    "MD", "MD", "MD", "MD"), `SERVICER NAME` = c("No Data Available",
>    "No Data Available", "No Data Available", "No Data Available",
>    "No Data Available", "No Data Available", "No Data Available",
>    "No Data Available", "No Data Available", "No Data Available",
>    "No Data Available", "No Data Available", "No Data Available",
>    "No Data Available", "No Data Available", "No Data Available",
>    "No Data Available", "No Data Available", "No Data Available",
>    "No Data Available", "No Data Available", "No Data Available",
>    "No Data Available", "No Data Available", "No Data Available",
>    "No Data Available", "No Data Available", "No Data Available",
>    "No Data Available", "No Data Available", "No Data Available",
>    "No Data Available", "No Data Available", "No Data Available",
>    "No Data Available", "", "", "", "", "", "", "", "", "No Data Available",
>    "", "No Data Available", "No Data Available", "", "No Data Available",
>    "No Data Available", "", "", "No Data Available", "", "",
>    "", "", "", "No Data Available", "", "", "No Data Available",
>    "", "", "", "", "", "", "", "WHITE MOUNTAINS SERVICES CORP",
>    "", "", "", "", "USGI INC", "WELLS FARGO BANK NA", "ZIEGLER FINANCING CORP",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", ""), `SERVICER CITY` = c("",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "FARMINGTON HILLS", "", "",
>    "", "", "LA PLATA", "MC LEAN", "NEW ALBANY", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", ""), `SERVICER STATE` = c("", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "MI", "", "", "", "", "MD", "VA", "OH",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", ""), `SECTION OF ACT CODE` = c("HRB",
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB",
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB",
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB",
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB",
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRP", "HRB",
>    "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB", "HRB",
>    "HRP", "HRB", "HRB", "HRB", "HRB", "HRP", "HRB", "HRP", "HRB",
>    "HRP", "HRP", "HRB", "HRB", "HRP", "HRP", "ZSB", "ZSB", "ZSB",
>    "ZSB", "ZSJ", "ZSQ", "ZSQ", "HRL", "HRL", "HRL", "HRL", "HRL",
>    "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL",
>    "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL", "HRL"
>    ), `SOA CATEGORY Sub Category` = c("207 Apartments", "207 Apartments",
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>    "207 Apartments", "207 Apartments", "207 Rental Projects",
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>    "207 Apartments", "207 Apartments", "207 Rental Projects",
>    "207 Apartments", "207 Apartments", "207 Apartments", "207 Apartments",
>    "207 Rental Projects", "207 Apartments", "207 Rental Projects",
>    "207 Apartments", "207 Rental Projects", "207 Rental Projects",
>    "207 Apartments", "207 Apartments", "207 Rental Projects",
>    "207 Rental Projects", "241(a)/ 207 Improvements & Additions",
>    "241(a)/ 207 Improvements & Additions", "241(a)/ 207 Improvements & Additions",
>    "241(a)/ 207 Improvements & Additions", "241(a)/ 221-MIR(d)(3)&(d)(4) Improvements & Additions",
>    "241(a)/ 232 /Improvements & Additions / Nursing Homes",
>    "241(a)/ 232 /Improvements & Additions / Nursing Homes",
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>    "207/ 223(f)/ 244 Co-Insurance", "207/ 223(f)/ 244 Co-Insurance",
>    "207/ 223(f)/ 244 Co-Insurance"), `TERM TYPE` = c("11", "11",
>    "11", "11", "11", "11", "12", "11", "11", "11", "11", "11",
>    "11", "11", "11", "11", "11", "11", "11", "11", "11", "11",
>    "11", "11", "11", "11", "11", "11", "11", "11", "11", "11",
>    "11", "11", "11", "11", "11", "11", "11", "11", "11", "11",
>    "11", "11", "18", "21", "21", "21", "11", "19", "11", "11",
>    "20", "21", "19", "11", "21", "11", "11", "11", "11", "15",
>    "11", "11", "11", "11", "11", "21", "19", "11", "11", "11",
>    "11", "11", "19", "11", "11", "11", "11", "11", "11", "11",
>    "11", "11", "11", "11", "11", "11", "11", "11", "11", "11",
>    "14", "11", "11", "11", "11", "11", "11", "11"), `TERMINATION TYPE DESCRIPTION` = c("Prepayment",
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>    "SUPERSESSION", "Prepayment", "Prepayment", "Prepayment",
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Maturity",
>    "VOLUNTARY", "VOLUNTARY", "VOLUNTARY", "Prepayment", "Assignment",
>    "Prepayment", "Prepayment", "Acquired", "VOLUNTARY", "Assignment",
>    "Prepayment", "VOLUNTARY", "Prepayment", "Prepayment", "Prepayment",
>    "Prepayment", "Conveyance", "Prepayment", "Prepayment", "Prepayment",
>    "Prepayment", "Prepayment", "VOLUNTARY", "Assignment", "Prepayment",
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Assignment",
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment",
>    "Prepayment", "Prepayment", "CANCELLED", "Prepayment", "Prepayment",
>    "Prepayment", "Prepayment", "Prepayment", "Prepayment", "Prepayment"
>    ), `TYPE  Claim Non Claim ` = c("NONCLAIM", "NONCLAIM", "NONCLAIM",
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>    "NONCLAIM", "CLAIM", "NONCLAIM", "NONCLAIM", "CLAIM", "NONCLAIM",
>    "CLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>    "NONCLAIM", "NONCLAIM", "CLAIM", "NONCLAIM", "NONCLAIM",
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "CLAIM",
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>    "CLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>    "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM", "NONCLAIM",
>    "NONCLAIM"), `TERM DATE` = c("4/1/39", "4/1/39", "9/1/40",
>    "4/1/39", "2/1/49", "9/1/40", "9/1/44", "8/1/46", "1/1/50",
>    "11/1/44", "7/1/54", "8/1/46", "11/1/41", "7/1/54", "12/1/39",
>    "3/1/46", "8/1/46", "12/1/45", "11/1/44", "7/1/45", "11/1/45",
>    "8/1/46", "8/1/46", "8/1/46", "10/1/46", "7/1/46", "9/1/47",
>    "12/1/43", "7/1/46", "12/1/42", "5/1/44", "8/1/46", "8/1/65",
>    "8/1/65", "8/1/65", "1/31/83", "1/31/83", "2/3/83", "1/31/83",
>    "1/31/83", "12/7/72", "1/3/79", "12/4/79", "10/1/67", "10/1/99",
>    "5/1/71", "4/1/70", "10/16/79", "10/1/67", "8/1/66", "2/27/75",
>    "1/29/82", "12/1/66", "12/3/79", "4/4/75", "10/25/85", "1/30/80",
>    "6/25/74", "12/19/72", "5/31/73", "7/1/94", "4/1/67", "3/19/87",
>    "3/16/73", "2/13/86", "2/13/86", "5/24/82", "7/12/73", "12/8/76",
>    "3/10/89", "3/19/87", "10/31/85", "5/24/82", "1/21/85", "8/30/95",
>    "1/28/11", "11/30/10", "5/31/86", "5/31/86", "4/30/86", "11/20/84",
>    "6/30/86", "6/30/86", "3/31/86", "1/16/87", "10/31/86", "12/31/85",
>    "4/1/86", "4/1/86", "4/1/86", "3/31/86", "3/31/86", "8/3/90",
>    "10/31/86", "6/30/86", "1/30/87", "4/30/86", "4/30/86", "2/27/87",
>    "8/31/86"), TE = c("", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", ""
>    ), TC = c("", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
>    "", "", "", "", "", "", "", "", "", "", "", "", ""), Status = c(TRUE,
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,
>    TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE)), .Names = c("HUD PROJECT NUMBER", 
> "PROPERTY NAME", "PROPERTY STREET", "PROPERTY CITY", "PROPERTY STATE", 
> "PROPERTY ZIP", "UNITS", "INITIAL ENDORSEMENT DATE", "FINAL ENDORSEMENT DATE", 
> "ORIGINAL MORTGAGE AMOUNT", "FIRST PAYMENT DATE", "MATURITY DATE", 
> "TERM IN MONTHS", "INTEREST RATE", "HOLDER NAME", "HOLDER CITY", 
> "HOLDER STATE", "SERVICER NAME", "SERVICER CITY", "SERVICER STATE", 
> "SECTION OF ACT CODE", "SOA CATEGORY Sub Category", "TERM TYPE", 
> "TERMINATION TYPE DESCRIPTION", "TYPE  Claim Non Claim ", "TERM DATE", 
> "TE", "TC", "Status"), row.names = c(NA, 100L), class = "data.frame")
> 
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From dulcalma at bigpond.com  Mon Aug 15 03:32:27 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Mon, 15 Aug 2016 11:32:27 +1000
Subject: [R] Adding loess lines subsetting to each panel in lattice plot
In-Reply-To: <1279776472.23625175.1471095110158.JavaMail.yahoo@mail.yahoo.com>
References: <676905760.22528506.1471018231218.JavaMail.yahoo.ref@mail.yahoo.com>	<676905760.22528506.1471018231218.JavaMail.yahoo@mail.yahoo.com>	<CAGxFJbScd9c0JFRqoO8T0WB3SzD4Nc0jkpVT8TmwwVs8j+MVAg@mail.gmail.com>
	<1279776472.23625175.1471095110158.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <000001d1f694$e26a8740$a73f95c0$@bigpond.com>

Hi

A slightly different approach

xyplot(y~x|fac,
       groups = ifelse(age < 40,1,2),
       par.settings = list(strip.background = list(col = "transparent"),
                           superpose.symbol = list(col = c("red","blue","green")),
                           superpose.line = list(col = c("red","blue","green"))
                           ),
       auto.key = TRUE,
       panel = function(x, y, ..., groups) {
                   panel.superpose(x, y, ..., groups, panel = panel.points)
                   panel.superpose(x, y, ..., groups, panel = panel.loess)
                   panel.xyplot(x,y, type = "smooth", col = "green")
               }
)

This gives the colours to the panel function as well as the key

If you want a more elaborate key

xyplot(y~x|fac,
       groups = ifelse(age < 40,1,2),
       par.settings = list(strip.background = list(col = "transparent"),
                           superpose.symbol = list(col = c("red","blue","green")),
                           superpose.line = list(col = c("red","blue","green"))
                           ),
       key = list(text = list(labels = c("young","old","all")),
                       points = list(pch = 1, col = c("red","blue","transparent")),
                       lines = list(col = c("red","blue","green"))),
       panel = function(x, y, ..., groups) {
                   panel.superpose(x, y, ..., groups, panel = panel.points)
                   panel.superpose(x, y, ..., groups, panel = panel.loess)
                   panel.xyplot(x,y, type = "smooth", col = "green")
               }
)

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Juan Perez via R-help
Sent: Saturday, 13 August 2016 23:32
To: Bert Gunter
Cc: r-help at r-project.org
Subject: Re: [R] Adding loess lines subsetting to each panel in lattice plot

Thanks Bert
I am not sure what you meant by reading though.
I managed to sort this out, although ideally would exist a better solution. I have created a column in my dataset, and given two codes depending whether older or younger than 40. Afterwards I have applied
xyplot(MOE~Age|Species, groups=Old,
       panel= function(x,y,...){  ## custom panel function to add an overall loess line
         panel.superpose(x,y,...)
         panel.loess(x,y,col="black",lwd=2,...)
       },
       panel.groups = function(x,y,...){
         panel.xyplot(x,y,...)
         panel.loess(x,y,...)
       }) 

This gives a loess line for data younger than 40, another for the ones older, and a third one for all the data. I hope this helps to someone else. Unfortunately, the dataset needs to be modified everytime we want to make a new or different subset.
Best regards
 

    El Viernes 12 de agosto de 2016 21:10, Bert Gunter <bgunter.4567 at gmail.com> escribi?:
 

 Try reading ?panel.loess. There is no "subset" argument, so it is of
course ignored.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 12, 2016 at 9:10 AM, Juan Perez via R-help
<r-help at r-project.org> wrote:
> Hello, I've created an xyplot and I want to add a loess line for x (Age)  <=40 and another for values >40. In a way it is similar to this https://stat.ethz.ch/pipermail/r-help/2009-May/390502.html but still not succcessful.
> This is my try:
>
> xyplot(MOE~Age|Species, groups=Site,
>        panel = function(x, y, groups=groups,...) {
>        panel.xyplot(x, y, groups=groups,...)
>        panel.loess(x,y,subset = x <= 40, col="black")        panel.loess(x,y,subset = x >40, col="red")
>              })
> When I run the code it "works" but it plots the loess line for all the data, without subsetting.Any suggestion?
> Thank you
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From djnordlund at gmail.com  Mon Aug 15 04:07:22 2016
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Sun, 14 Aug 2016 19:07:22 -0700
Subject: [R] R bug when started in Windows 10
In-Reply-To: <CAKVb3JH06xOXnVm9nGtSZbyHT_kqJ7ccVUFP-OLcu8whok51Pg@mail.gmail.com>
References: <CAKVb3JH06xOXnVm9nGtSZbyHT_kqJ7ccVUFP-OLcu8whok51Pg@mail.gmail.com>
Message-ID: <92b2b924-c108-34e4-f74a-206f6c4bfdfe@gmail.com>

On 8/14/2016 12:57 PM, Itamar Jos? G. Nunes wrote:
> Greetings, CRAN supporter. I am Itamar Jos?, a Brazilian programmer and
> biotechnology student.
> I'm using R from some time ago, most of the time working with it in Windows
> 7, but since I changed to Windows 10, I'm having some bugs when R platform
> particularly in this new operational system. If there's not problem, I
> would like some help from you for what I can do about this issue.
> I have asked about this problem in StarkOverflow, but no resolution was
> suggested until now. As I said there, I'm working with a software project
> that requires the portable version of R platform and my intention is to use
> R in any version of Windows and in any compatible computer. I'm copying
> here my answer, as shown below:
>
>
>
> *From
> [http://stackoverflow.com/questions/37173431/r-platform-failed-to-start-in-windows-10-when-inside-directory-containing-white
> <http://stackoverflow.com/questions/37173431/r-platform-failed-to-start-in-windows-10-when-inside-directory-containing-white>]Problem:*
> In Windows 7, R works fine without any worries, even in portable version.
> However, in Windows 10 (and probably also in Windows 8), R does not start
> when put the entire folder inside a directory containing whitespaces (ex.:
> "C:/Users/Main/Documents/My Folder/RVersion").
>
> In Windows 10, with the absence of spaces, R runs fine. In the presence of
> spaces, all executable (Rscript.exe, R.exe, etc) except Rgui.exe just open
> a console and closes instantly. The problem is: I really need that R works
> in any folder (this is a important part of the project).
>
> *Additional information:*
>
>    -
>
>    I found that R does not work well in directories without the 8dot3
>    format - and it think that Windows 10 lost this property, which was present
>    in Windows 7. Also, the problem is clear when I run Rgui.exe in a
>    whitespace-containing directory and try to run system("R.exe", intern=TRUE)
>    function: It throws an error indicating that only the part before the first
>    space in directory name was taken into account. Here is the message:
>
>    > system("R.exe", intern=TRUE)
>
>    [1] "'C:\\Users\\Main\\DOCUME~1\\My' n?o ? reconhecido como um comando
>    interno" [2] "ou externo, um programa oper vel ou um arquivo em lotes."
>    attr(,"status") [1] 1 Warning message: running command 'R.exe' had status 1
>
> *Translation of messages [1] and [2]: "'C:\...\My'" not recognized as a
> internal or external command, nor a program operation or dataset*
>
>    -
>
>    The same occurs with non-portable version of R, as I already tested.
>    -
>
>    When I run with a .bat file with the corrected (quoted) directory as
>    input, R.exe runs, but in a disfunctional form and looking like cmd.exe (no
>    R command worked).
>    -
>
>    I have no ideia how to change variables such as R_HOME to a readable
>    version before R prompt starts.
>
> *System/Resources:*
>
>    - Windows 10 Home 64-bit with the last update.
>    - Dell Notebook with Intel i7-5500U 2.40 GHz (not so relevant, I think)
>    - R and R portable 3.3 (last version until this post), downloaded here: [
>    https://sourceforge.net/projects/rportable/]
>    <https://sourceforge.net/projects/rportable/%5D>
>
>
> I believe that, with the popularity of Windows 10, many other users could
> face this problem (specially those who depend of R portability). Because no
> answers were made, and since it remains as a little known issue, I think
> the CRAN support is the only one that knows, most than everyone, how to
> reach the resolution.
>
> Thanks in advance!
>

For this problem, you need to give the EXACT commands you use to start R 
and run your scripts.  In other words, give us a reproducible example, 
so that if we run your example we will see the same failure that you see.

Now in the absence of the reproducible exampole, I did notice one 
problem in the example you did give of a directory with spaces.  It 
looks like you were using single quotes (') around the path/filename. 
Windows requires that there be double quotes (") around any 
path/filename that contains spaces.

If you provide a reproducible example, then you may get more detailed help.


Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From petr.pikal at precheza.cz  Mon Aug 15 10:44:45 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 15 Aug 2016 08:44:45 +0000
Subject: [R] add segments from other data ggplot
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50392EC@SRVEXCHMBX.precheza.cz>

Dear all

I want to put arrows from other data to ggplot and get strange behaviour.

The code:

p<-ggplot(ram.ag, aes(Raman, XRD, colour=mereni))
p+geom_point(size=5)+geom_segment(data=dat, aes(x=Ramanpuv, y=XRDpuv,xend=Ramannov, yend=XRDnov),
arrow = arrow(length = unit(1,"cm")))

results to following error

Error in eval(expr, envir, enclos) : object 'mereni' not found

The working code (with bad legend)

p<-ggplot(ram.ag, aes(Raman, XRD, colour=mereni))
p+geom_point(size=5)+geom_segment(data=dat, aes(x=Ramanpuv, y=XRDpuv,xend=Ramannov,
yend=XRDnov, colour="black"), arrow = arrow(length = unit(1,"cm")))

I know how to improve legend manually but I wonder why the first code results in error, why in the second code black colour is ignored but results in no error.

Data:

ram.ag <- structure(list(vzorek = c("1.5 1:00", "1.5 11:00", "1.6 19:00",
"12.5 21:00", "16.5 17:00", "17.4 19:00", "17.5 9:00", "18.5 15:00",
"18.5 17:00", "27.5 7:00", "30.4 13:00", "4.6 17:00", "8.4 5:00",
"1.5 1:00", "1.5 11:00", "1.6 19:00", "12.5 21:00", "16.5 17:00",
"17.4 19:00", "17.5 9:00", "18.5 15:00", "18.5 17:00", "27.5 7:00",
"30.4 13:00", "4.6 17:00", "8.4 5:00"), mereni = structure(c(1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("nove", "puvodni"
), class = "factor"), Raman = c(98.2333333333333, 98.5, 99.9,
97.5333333333333, 92.375, 97.9666666666667, 98.225, 95.3, 90.5,
99.6, 97.45, 92.1, 98.45, 95.1, 99.1, 99.9, 97.9, 95.7, 97.6,
94.8, 97, 93.1, 99.3, 91.5, 88.9, 99.2), XRD = c(99.4, 99.4666666666667,
99.88, 99.6666666666667, 96.025, 99.5666666666667, 99.5, 98.75,
96.3333333333333, 99.725, 98.75, 97.425, 99.55, 98.9, 98.9, 99.3,
98.9, 94.7, 98.9, 98.9, 96.2, 96.2, 98.9, 97.4, 94.7, 97.4)), .Names = c("vzorek",
"mereni", "Raman", "XRD"), row.names = c(NA, -26L), class = "data.frame")

dat <- structure(list(Ramanpuv = c(95.1, 99.1, 99.9, 97.9, 95.7, 97.6,
94.8, 97, 93.1, 99.3, 91.5, 88.9, 99.2), XRDpuv = c(98.9, 98.9,
99.3, 98.9, 94.7, 98.9, 98.9, 96.2, 96.2, 98.9, 97.4, 94.7, 97.4
), Ramannov = c(98.2333333333333, 98.5, 99.9, 97.5333333333333,
92.375, 97.9666666666667, 98.225, 95.3, 90.5, 99.6, 97.45, 92.1,
98.45), XRDnov = c(99.4, 99.4666666666667, 99.88, 99.6666666666667,
96.025, 99.5666666666667, 99.5, 98.75, 96.3333333333333, 99.725,
98.75, 97.425, 99.55)), .Names = c("Ramanpuv", "XRDpuv", "Ramannov",
"XRDnov"), row.names = 14:26, class = "data.frame")

sessionInfo()
R Under development (unstable) (2016-03-15 r70334)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 10586)

locale:
[1] LC_COLLATE=Czech_Czech Republic.1250  LC_CTYPE=Czech_Czech Republic.1250
[3] LC_MONETARY=Czech_Czech Republic.1250 LC_NUMERIC=C
[5] LC_TIME=Czech_Czech Republic.1250

attached base packages:
[1] stats     datasets  utils     grDevices graphics  methods   base

other attached packages:
[1] devEMF_2.0      ggplot2_2.1.0   lattice_0.20-33 fun_0.1

loaded via a namespace (and not attached):
 [1] labeling_0.3     colorspace_1.2-6 scales_0.4.0     plyr_1.8.3
 [5] tools_3.3.0      gtable_0.2.0     Rcpp_0.12.4      nlme_3.1-126
 [9] grid_3.3.0       digest_0.6.9     munsell_0.4.3
>

Maybe it is version specific so I will try to check but I do not want to reinstall everything just now without a reason.

Best regards
Petr Pikal
Precheza a.s
724008364

"Kdo v?dy mysl?, ?e se u??,
bude vlasti chlouba.
Kdo si mysl?, ?e dost um?,
za??n? b?t trouba."
Karel Havl??ek Borovsk?


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From G.Maubach at weinwolf.de  Mon Aug 15 10:49:24 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 15 Aug 2016 10:49:24 +0200
Subject: [R] Accessing an object using a string
Message-ID: <OF4B9A6E5B.990C8149-ONC1258010.00301AEE-C1258010.00306F22@lotus.hawesko.de>

Hi All,

I would like to access an object using a sting.

# Create example dataset
var1 <- c(1, 2, 3)
var2 <- c(4, 5, 6)
data1 <- data.frame(var1, var2)

var3 <- c(7, 8, 9)
var4 <- c(10, 11, 12)
data2 <- data.frame(var3, var4)

save(file = "c:/temp/test.RData", list = c("data1", "data2"))

# Define function
t_load_dataset <- function(file_path,
                           file_name) {
  file_location <- file.path(file_path, file_name)
 
  print(paste0('Loading ', file_location, " ..."))
  cat("\n")
 
  object_list <- load(file = file_location,
                      envir = .GlobalEnv)
 
  print(paste(length(object_list), "dataset(s) loaded from", 
file_location))
  cat("\n")
 
  print("The following objects were loaded:")
  print(object_list)
  cat("\n")
 
  for (i in object_list) {
    print(paste0("Object '", i, "' in '", file_name, "' contains:"))
    str(i)
    names(i)  # does not work
  }
}

I have only the character vector object_list containing the names of the 
objects as strings. I would like to access the objects in object_list to 
be able to print the names of the variables within the object (usuallly a 
data frame).

Is it possible to do this? How is it done?

Kind regards

Georg


From R.E.Crump at warwick.ac.uk  Mon Aug 15 12:56:43 2016
From: R.E.Crump at warwick.ac.uk (Crump, Ron)
Date: Mon, 15 Aug 2016 10:56:43 +0000
Subject: [R] add segments from other data ggplot
Message-ID: <D3D75E7A.6E53%lfslbx@live.warwick.ac.uk>

Dear Petr,

In your code:

p<-ggplot(ram.ag, aes(Raman, XRD, colour=mereni))
p+geom_point(size=5)+geom_segment(data=dat, aes(x=Ramanpuv,
y=XRDpuv,xend=Ramannov,
yend=XRDnov), arrow = arrow(length = unit(1,"cm")))

you have set mereni to control the colour aesthetic in the call to ggplot.
This will be used in all subsequent calls to geoms, unless you make a
local call to aes to override it. So both ram.ag and dat would require
mereni columns for this to work.

In the second piece of code you use a call to aes to override colour in
the call to geom_segment, which gets you past the error, but do not set it
to a variable in dat. You shouldn't set an aesthetic to a constant
("black"), use colour="black" outside of the aes() if you want it set
(although it is redundant in this case, black being the default).

If you are using multiple data sources it is probably safer to refer to
them and set the appropriate aesthetics where they are used, e.g.

p <- ggplot()+geom_point(data=ram.ag,aes(x=Raman,y=XRD,colour=mereni))+
geom_segment(data=dat,aes(x=Ramanpuv,y=XRDpuv,xend=Ramannov,yend=XRDnov),ar
row=arrow(length=unit(1,"cm")))


Hope this helps, I apologise if it isn't very clear.

Regards,
Ron.


From petr.pikal at precheza.cz  Mon Aug 15 15:01:31 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 15 Aug 2016 13:01:31 +0000
Subject: [R] add segments from other data ggplot
In-Reply-To: <D3D75E7A.6E53%lfslbx@live.warwick.ac.uk>
References: <D3D75E7A.6E53%lfslbx@live.warwick.ac.uk>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503933C@SRVEXCHMBX.precheza.cz>

Thanks Ron.

Your explanation is clear, at least to me. I did not use the approach of start with plain ggplot call following some geom calls before.

However I must say I finally turned back to standard graphics which seems to me easier in this case and I can easily add other values without many problems. But I keep your solution for future.

Thanks again

Petr

> -----Original Message-----
> From: Crump, Ron [mailto:R.E.Crump at warwick.ac.uk]
> Sent: Monday, August 15, 2016 12:57 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help at r-project.org
> Subject: Re: [R] add segments from other data ggplot
>
> Dear Petr,
>
> In your code:
>
> p<-ggplot(ram.ag, aes(Raman, XRD, colour=mereni))
> p+geom_point(size=5)+geom_segment(data=dat, aes(x=Ramanpuv,
> y=XRDpuv,xend=Ramannov,
> yend=XRDnov), arrow = arrow(length = unit(1,"cm")))
>
> you have set mereni to control the colour aesthetic in the call to ggplot.
> This will be used in all subsequent calls to geoms, unless you make a local call
> to aes to override it. So both ram.ag and dat would require mereni columns
> for this to work.
>
> In the second piece of code you use a call to aes to override colour in the call
> to geom_segment, which gets you past the error, but do not set it to a
> variable in dat. You shouldn't set an aesthetic to a constant ("black"), use
> colour="black" outside of the aes() if you want it set (although it is redundant
> in this case, black being the default).
>
> If you are using multiple data sources it is probably safer to refer to them and
> set the appropriate aesthetics where they are used, e.g.
>
> p <-
> ggplot()+geom_point(data=ram.ag,aes(x=Raman,y=XRD,colour=mereni))+
> geom_segment(data=dat,aes(x=Ramanpuv,y=XRDpuv,xend=Ramannov,yen
> d=XRDnov),ar
> row=arrow(length=unit(1,"cm")))
>
>
> Hope this helps, I apologise if it isn't very clear.
>
> Regards,
> Ron.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From G.Maubach at weinwolf.de  Mon Aug 15 15:40:58 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 15 Aug 2016 15:40:58 +0200
Subject: [R] Antwort:  Accessing an object using a string (SOLVED)
In-Reply-To: <OF4B9A6E5B.990C8149-ONC1258010.00301AEE-C1258010.00306F22@lotus.hawesko.de>
References: <OF4B9A6E5B.990C8149-ONC1258010.00301AEE-C1258010.00306F22@lotus.hawesko.de>
Message-ID: <OF01AB20EB.FF4F2637-ONC1258010.004A632A-C1258010.004B20F7@lotus.hawesko.de>

Hi All,

I found the function get() which returns an object.

My whole function looks like this:

-- cut --

#-------------------------------------------------------------------------------
# Module        : t_load_dataset.R
# Author        : Georg Maubach
# Date          : 2016-08-15
# Update        : 2016-08-15
# Description   : Load dataset and print information on contents
# Source System : R 3.3.0 (64 Bit)
# Target System : R 3.3.0 (64 Bit)
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
#--------1---------2---------3---------4---------5---------6---------7---------8

t_module_name = "t_load_dataset"
t_version = "2016-08-15"
t_status = "released"

cat(
  paste0("\n",
         t_module_name, " (Version: ", t_version, ", Status: ", t_status, 
")", "\n", "\n",
         "Copyright (C) Georg Maubach 2016

This software comes with ABSOLUTELY NO WARRANTY.", "\n", "\n"))

# If do_test is not defined globally define it here locally by 
un-commenting it
# Switch t_do_test to TRUE to run test
t_do_test <- FALSE

# [ Function Defintion 
]--------------------------------------------------------
t_load_dataset <- function(file_path,
                           file_name) {
  # Loads and RData file with all objects in it and prints information on 
its
  # contents
  #
  # Args:
  #  file_path (string):
  #    String with path name.
  #  file_name (string):
  #    String with file name.
  #
  # Operation:
  #   Loads the RData file with all its objects, stores the objects in the
  #   global environment .GlobalEnv and prints information about the 
objects.
  #
  # Usage:
  #   The function is designed to work only on data frames.
  #
  # Returns:
  #   Nothing, but stores loaded objects directly into the global 
environment.
  #
  # Error handling:
  #   None.
 
#-----------------------------------------------------------------------------
 
  cat("----------------------- [ t_load_dataset() ] 
----------------------\n\n")
 
  file_location <- file.path(file_path, file_name)
 
  cat(paste0('Loading ', file_location, " ...\n\n"))
 
  dataset_list <- load(file = file_location,
                       envir = .GlobalEnv)
 
  cat(paste0(
    length(dataset_list),
    " dataset(s) loaded:\n"))
  cat(dataset_list)
  cat("\n\n")

  for (dataset in dataset_list) {
    cat(paste0("Dataset '", dataset, "' contains ",
                nrow(get(dataset, envir = .GlobalEnv)),
                " cases in ",
                ncol(get(dataset, envir = .GlobalEnv)),
                " variables:\n"))
    cat(names(get(dataset, envir = .GlobalEnv)))
    cat("\n\n")
  }
 
  cat("------------------------------ [ Done ] 
---------------------------\n\n")
}

# [ Test Defintion 
]------------------------------------------------------------
t_test <- function(do_test = FALSE) {
  if (do_test == TRUE) {
 
    # Example dataset
    var1 <- c(1, 2, 3)
    var2 <- c(4, 5, 6)
    d_data1 <- data.frame(var1, var2)
 
    var3 <- c(7, 8, 9)
    var4 <- c(10, 11, 12)
    d_data2 <- data.frame(var3, var4)
 
    # Save datasets
    v_file_name <- "test_t_load_dataset.RData"
 
    save(file = file.path(getwd(),
                          v_file_name),
         list = c("d_data1", "d_data2"))
 
    # Call function
    t_load_dataset(file_path = getwd(), file_name = v_file_name)
 
    # Cleanup
    unlink(file.path(getwd(), v_file_name))
  }
}

# [ Test Run 
]------------------------------------------------------------------
t_test(do_test = t_do_test)

# [ Clean up 
]------------------------------------------------------------------
rm("t_module_name", "t_version", "t_status", "t_do_test", "t_test")

# EOF

-- cut --

I will include it later the toolbox of R function on Sourceforge.net.

Kind regards

Georg




Von:    G.Maubach at weinwolf.de
An:     r-help at r-project.org, 
Datum:  15.08.2016 10:51
Betreff:        [R] Accessing an object using a string
Gesendet von:   "R-help" <r-help-bounces at r-project.org>



Hi All,

I would like to access an object using a sting.

# Create example dataset
var1 <- c(1, 2, 3)
var2 <- c(4, 5, 6)
data1 <- data.frame(var1, var2)

var3 <- c(7, 8, 9)
var4 <- c(10, 11, 12)
data2 <- data.frame(var3, var4)

save(file = "c:/temp/test.RData", list = c("data1", "data2"))

# Define function
t_load_dataset <- function(file_path,
                           file_name) {
  file_location <- file.path(file_path, file_name)
 
  print(paste0('Loading ', file_location, " ..."))
  cat("\n")
 
  object_list <- load(file = file_location,
                      envir = .GlobalEnv)
 
  print(paste(length(object_list), "dataset(s) loaded from", 
file_location))
  cat("\n")
 
  print("The following objects were loaded:")
  print(object_list)
  cat("\n")
 
  for (i in object_list) {
    print(paste0("Object '", i, "' in '", file_name, "' contains:"))
    str(i)
    names(i)  # does not work
  }
}

I have only the character vector object_list containing the names of the 
objects as strings. I would like to access the objects in object_list to 
be able to print the names of the variables within the object (usuallly a 
data frame).

Is it possible to do this? How is it done?

Kind regards

Georg

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From isaudin at gmail.com  Mon Aug 15 17:28:14 2016
From: isaudin at gmail.com (Isaudin Ismail)
Date: Mon, 15 Aug 2016 16:28:14 +0100
Subject: [R] Error while fitting gumbel copula
In-Reply-To: <22443.20835.731336.772515@stat.math.ethz.ch>
References: <CAE1aWa_AJRovvq9sZU2LWA3VaBCWAC_mxLoK4L7kzy=HkjgEHQ@mail.gmail.com>
	<22443.20835.731336.772515@stat.math.ethz.ch>
Message-ID: <CAE1aWa-C91VyzjCyygyot4udAM4LkHCKWS1ZwYaHBNyVZVdy8w@mail.gmail.com>

Dear Dr. Martin,

I'm glad that you replied to my queries.

As advised, I have prepared the following:

library(copula)



# 5 series of data, A, B, C, D and E
A <- c(0.849420849, 0.900652985, 0.97144217, 0.817888428, 0.877901578,
       1.070040669, 0.889742431, 0.87588968, 0.853541938, 0.848664688,
       0.876830319, 0.749582638, 0.818515498, 0.890997174, 0.794766966,
       0.784794851, 0.814858959, 1.074396518, 0.83752495, 0.894341116,
       0.880375293, 0.900816803)

B <- c(0.479850746, 0.652111668, 1.880607815, 0.579902303, 0.50669344,
       0.747560182, 0.701754386, 0.48969697, 0.346751006, 0.379234973,
       0.862691466, 0.328280188, 0.317312661, 0.534438115, 0.487002653,
       0.335043612, 0.373346897, 0.627520161, 0.792114695, 0.938253012,
       0.444553967, 0.625972763)

C <- c(0.693491124, 0.866523143, 4.585714286, 1.512055109, 0.387755102,
       0.513435701, 0.76252505, -0.113113113, 0.338521401, 0.333951763,
       0.668755595, 0.401273885, 0.419868791, 0.272885789, 0.541541542,
       0.32751938, 0.386409736, 0.957446809, 0.861195542, 1.531632653,
       0.431610942, 1.226470588)

D <- c(0.807792208, 0.548547718, 0.738232865, 0.542247744, 1.088964927,
       0.862385321, 0.60720268, 1.000816993, 0.699289661, 0.41723356,
       0.604037267, 0.605003791, 0.698940998, 0.764792899, 0.647897898,
       0.825256975, 0.767476085, 0.941391941, 0.889547813, 0.324503311,
       0.942435424, 0.740686633)

E <- c(1.077598829, 0.318507891, 1.152616279, 0.930397727, 1.515994437,
       0.940689655, 0.880886427, 1.054274084, 1.067282322, 0.677419355,
       0.966233766, 0.761029412, 1.05734767, 0.615925059, 1.061988304,
       1.07184241, 1.058890147, 1.123873874, 1.304891923, -0.069584736,
       1.172757475, 0.501096491)

gumbel.copula <- gumbelCopula(dim = 2)
p <- pobs(as.matrix(cbind(D + E, A + B+ C )))

fit.gumbel <- fitCopula(gumbel.copula, p, method = "ml") #The error is here
when trying to fit the gumbel copula

# I got the following error:
Error in optim(start, loglikCopula, lower = lower, upper = upper, method =
method,  :
                 non-finite finite-difference value [1]
              In addition: Warning message:
              In .local(copula, tau, ...) : tau is out of the range [0, 1]

#Due to error in fitting the gumbel copula, this step can't be processed

coef(fit.gumbel)
gofCopula(gumbel.Copula, p, estim.method = "mpl", method = "Sn", simulation
= "mult")


Thanks in advance!

Best regards,
Isaudin

On Wed, Aug 10, 2016 at 5:08 PM, Martin Maechler <maechler at stat.math.ethz.ch
> wrote:

> >>>>> Isaudin Ismail <isaudin at gmail.com>
> >>>>>     on Tue, 9 Aug 2016 14:30:18 +0100 writes:
>
>     > Dear R experts,
>     > I have 5 time series of data (A, B, C, D and E) with all same
> lengths. All
>     > series exhibit gamma distribution except for B which is lognormal
>     > distribution. I am using copula package to model the
> joint-distribution of
>     > these 5 times series.
>
>     > I have selected Archimedean copula and successfully fitted  Frank and
>     > Clayton copula. The problem is when trying to fit Gumbel copula.
>
>     > The following are the codes I used to run in R.
>
>     > # Data of 5 time series
>
>     > A <- A
>     > B <- B
>     > C <- C
>     > D <- D
>     > E <- E
>
> well, the above is really an "interesting" block of R code ;-)
>
> --
>
> More seriously, please learn to use reproducible examples,
> e.g., from here
>   http://bit.ly/MRE_R (nice to remember: MRE = Minimal Reproducible
> Example)
> or here
>   http://adv-r.had.co.nz/Reproducibility.html
>
> then we will be glad to help you,
> notably I as maintainer of the package 'copula' which you are
> using (without saying so).
>
> With regards,
> Martin Maechler
>
>
>     > # Combined between A and C
>     > A+C <- A + C
>
>     > gumbel.copula <- gumbelCopula(dim = 5)
>     > m <- pobs(as.matrix(cbind(A+C, B, D, E)))
>     > fit.gumbel<- fitCopula(gumbel.copula, m, method = 'ml')
>
>     > And the error while trying to fit gumbel copula:
>
>     > Error in optim(start, loglikCopula, lower = lower, upper = upper,
> method =
>     > method,  :
>     > non-finite finite-difference value [1]
>     > In addition: Warning message:
>     > In .local(copula, tau, ...) : tau is out of the range [0, 1]
>
>     > Appreciate all help!
>
>     > Many thanks,
>     > Isaudin
>
>     > [[alternative HTML version deleted]]
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Mon Aug 15 18:01:16 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 15 Aug 2016 16:01:16 +0000
Subject: [R] R Studio: Run script upon saving or exiting
In-Reply-To: <CAHby=D1qb7pGtFyHgrx3U1aB_n5Xmj9pbzvy95Ty8Q69Ykmz-w@mail.gmail.com>
References: <CAHby=D1qb7pGtFyHgrx3U1aB_n5Xmj9pbzvy95Ty8Q69Ykmz-w@mail.gmail.com>
Message-ID: <D3D73476.183283%macqueen1@llnl.gov>

See
  ?.Last
for information on how to cause something to happen when R exits.
(whether R Studio overrides this I don't know)

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/13/16, 1:02 PM, "R-help on behalf of Jan Kacaba"
<r-help-bounces at r-project.org on behalf of jan.kacaba at gmail.com> wrote:

>Dear R help,
>
>I would like to run script upon saving project files or exiting the R
>Studio.
>For example I would like to backup whole project in another directory.
>The backup directory should be named such that incremental version
>number will added to project name.
>
>Is it somehow possible?  Even better would be if someone can also
>quickly go through file versions.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sibylle.stoeckli at gmx.ch  Mon Aug 15 18:09:20 2016
From: sibylle.stoeckli at gmx.ch (=?iso-8859-1?Q?Sibylle_St=F6ckli?=)
Date: Mon, 15 Aug 2016 18:09:20 +0200
Subject: [R] glmer and glht
Message-ID: <36DC060B-FDBD-40E4-A644-DE1C1C00DE01@gmx.ch>

Dear R colleagues,

The effect of habitat type on bee species number was tested using a glmer model with habitat as fixed effect (5 habitat types) and site and time as random terms.
The idea was now to conduct post hoc tests with glht (package "multcomp") for pairwise comparisons. The matrix was defined by symbolic description (linfct=c("habitat1=0", "habitat2=0"?). 
My question: I am now interested about the detailed statistic behind glht? As I was not applying ANOVA and mcp=Tukey, it is for sure not a Tukey test, but is it a LSD, Cuncan, Hochberg?.and is the test suitable for an unbalanced data set (not every habitat occurs at every site?)

With best wishes
Sibylle






	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Aug 15 18:29:55 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 15 Aug 2016 09:29:55 -0700
Subject: [R] glmer and glht
In-Reply-To: <36DC060B-FDBD-40E4-A644-DE1C1C00DE01@gmx.ch>
References: <36DC060B-FDBD-40E4-A644-DE1C1C00DE01@gmx.ch>
Message-ID: <CAGxFJbQ+-5dwmyVmaV+aa4L+1WuJhFS23CWkjnJkQgbAdDkRJg@mail.gmail.com>

Extensive references are given in the package. I suggest that you consult them.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 15, 2016 at 9:09 AM, Sibylle St?ckli
<sibylle.stoeckli at gmx.ch> wrote:
> Dear R colleagues,
>
> The effect of habitat type on bee species number was tested using a glmer model with habitat as fixed effect (5 habitat types) and site and time as random terms.
> The idea was now to conduct post hoc tests with glht (package "multcomp") for pairwise comparisons. The matrix was defined by symbolic description (linfct=c("habitat1=0", "habitat2=0"?).
> My question: I am now interested about the detailed statistic behind glht? As I was not applying ANOVA and mcp=Tukey, it is for sure not a Tukey test, but is it a LSD, Cuncan, Hochberg?.and is the test suitable for an unbalanced data set (not every habitat occurs at every site?)
>
> With best wishes
> Sibylle
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon Aug 15 18:41:02 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 15 Aug 2016 09:41:02 -0700
Subject: [R] Antwort:  Accessing an object using a string (SOLVED)
In-Reply-To: <OF01AB20EB.FF4F2637-ONC1258010.004A632A-C1258010.004B20F7@lotus.hawesko.de>
References: <OF4B9A6E5B.990C8149-ONC1258010.00301AEE-C1258010.00306F22@lotus.hawesko.de>
	<OF01AB20EB.FF4F2637-ONC1258010.004A632A-C1258010.004B20F7@lotus.hawesko.de>
Message-ID: <8A22DA6F-1FB3-42D2-A965-A7AF7BED78D2@dcn.davis.ca.us>

Use of "get" usually means you are doing something wrong in setting up your approach to a problem. That is, if you design your interface to your functions to be overly general,  it will become full of surprises later. 

If in fact the data you are interested in referring to is a column in a data frame, then let the user give your function that data frame as a function argument and use indexing to extract the value from it. Don't design your function to go digging around in the global environment because the user of your function may not be working there.

In this case, it would be better for the user to create a dedicated environment and load the RData file into that and use the ls() and str () functions to look through it rather than assume the RData file only contains data frames by using your function.

x <- 1:5
dta <- data.frame( x, y = x + 1 )
save.image( "test.RData" )
rm( x )
rm( dta )
en <- new.env()
ls()
ls( en )
load( "test.RData", envir=en )
ls( en )
str( x ) # removed from working environment
str( en$x )
str( en$dta )

-- 
Sent from my phone. Please excuse my brevity.

On August 15, 2016 6:40:58 AM PDT, G.Maubach at weinwolf.de wrote:
>Hi All,
>
>I found the function get() which returns an object.
>
>My whole function looks like this:
>
>-- cut --
>
>#-------------------------------------------------------------------------------
># Module        : t_load_dataset.R
># Author        : Georg Maubach
># Date          : 2016-08-15
># Update        : 2016-08-15
># Description   : Load dataset and print information on contents
># Source System : R 3.3.0 (64 Bit)
># Target System : R 3.3.0 (64 Bit)
>#
># This program is distributed in the hope that it will be useful,
># but WITHOUT ANY WARRANTY; without even the implied warranty of
># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
>#--------1---------2---------3---------4---------5---------6---------7---------8
>
>t_module_name = "t_load_dataset"
>t_version = "2016-08-15"
>t_status = "released"
>
>cat(
>  paste0("\n",
>      t_module_name, " (Version: ", t_version, ", Status: ", t_status, 
>")", "\n", "\n",
>         "Copyright (C) Georg Maubach 2016
>
>This software comes with ABSOLUTELY NO WARRANTY.", "\n", "\n"))
>
># If do_test is not defined globally define it here locally by 
>un-commenting it
># Switch t_do_test to TRUE to run test
>t_do_test <- FALSE
>
># [ Function Defintion 
>]--------------------------------------------------------
>t_load_dataset <- function(file_path,
>                           file_name) {
># Loads and RData file with all objects in it and prints information on
>
>its
>  # contents
>  #
>  # Args:
>  #  file_path (string):
>  #    String with path name.
>  #  file_name (string):
>  #    String with file name.
>  #
>  # Operation:
>#   Loads the RData file with all its objects, stores the objects in
>the
>  #   global environment .GlobalEnv and prints information about the 
>objects.
>  #
>  # Usage:
>  #   The function is designed to work only on data frames.
>  #
>  # Returns:
>  #   Nothing, but stores loaded objects directly into the global 
>environment.
>  #
>  # Error handling:
>  #   None.
> 
>#-----------------------------------------------------------------------------
> 
>  cat("----------------------- [ t_load_dataset() ] 
>----------------------\n\n")
> 
>  file_location <- file.path(file_path, file_name)
> 
>  cat(paste0('Loading ', file_location, " ...\n\n"))
> 
>  dataset_list <- load(file = file_location,
>                       envir = .GlobalEnv)
> 
>  cat(paste0(
>    length(dataset_list),
>    " dataset(s) loaded:\n"))
>  cat(dataset_list)
>  cat("\n\n")
>
>  for (dataset in dataset_list) {
>    cat(paste0("Dataset '", dataset, "' contains ",
>                nrow(get(dataset, envir = .GlobalEnv)),
>                " cases in ",
>                ncol(get(dataset, envir = .GlobalEnv)),
>                " variables:\n"))
>    cat(names(get(dataset, envir = .GlobalEnv)))
>    cat("\n\n")
>  }
> 
>  cat("------------------------------ [ Done ] 
>---------------------------\n\n")
>}
>
># [ Test Defintion 
>]------------------------------------------------------------
>t_test <- function(do_test = FALSE) {
>  if (do_test == TRUE) {
> 
>    # Example dataset
>    var1 <- c(1, 2, 3)
>    var2 <- c(4, 5, 6)
>    d_data1 <- data.frame(var1, var2)
> 
>    var3 <- c(7, 8, 9)
>    var4 <- c(10, 11, 12)
>    d_data2 <- data.frame(var3, var4)
> 
>    # Save datasets
>    v_file_name <- "test_t_load_dataset.RData"
> 
>    save(file = file.path(getwd(),
>                          v_file_name),
>         list = c("d_data1", "d_data2"))
> 
>    # Call function
>    t_load_dataset(file_path = getwd(), file_name = v_file_name)
> 
>    # Cleanup
>    unlink(file.path(getwd(), v_file_name))
>  }
>}
>
># [ Test Run 
>]------------------------------------------------------------------
>t_test(do_test = t_do_test)
>
># [ Clean up 
>]------------------------------------------------------------------
>rm("t_module_name", "t_version", "t_status", "t_do_test", "t_test")
>
># EOF
>
>-- cut --
>
>I will include it later the toolbox of R function on Sourceforge.net.
>
>Kind regards
>
>Georg
>
>
>
>
>Von:    G.Maubach at weinwolf.de
>An:     r-help at r-project.org, 
>Datum:  15.08.2016 10:51
>Betreff:        [R] Accessing an object using a string
>Gesendet von:   "R-help" <r-help-bounces at r-project.org>
>
>
>
>Hi All,
>
>I would like to access an object using a sting.
>
># Create example dataset
>var1 <- c(1, 2, 3)
>var2 <- c(4, 5, 6)
>data1 <- data.frame(var1, var2)
>
>var3 <- c(7, 8, 9)
>var4 <- c(10, 11, 12)
>data2 <- data.frame(var3, var4)
>
>save(file = "c:/temp/test.RData", list = c("data1", "data2"))
>
># Define function
>t_load_dataset <- function(file_path,
>                           file_name) {
>  file_location <- file.path(file_path, file_name)
> 
>  print(paste0('Loading ', file_location, " ..."))
>  cat("\n")
> 
>  object_list <- load(file = file_location,
>                      envir = .GlobalEnv)
> 
>  print(paste(length(object_list), "dataset(s) loaded from", 
>file_location))
>  cat("\n")
> 
>  print("The following objects were loaded:")
>  print(object_list)
>  cat("\n")
> 
>  for (i in object_list) {
>    print(paste0("Object '", i, "' in '", file_name, "' contains:"))
>    str(i)
>    names(i)  # does not work
>  }
>}
>
>I have only the character vector object_list containing the names of
>the 
>objects as strings. I would like to access the objects in object_list
>to 
>be able to print the names of the variables within the object (usuallly
>a 
>data frame).
>
>Is it possible to do this? How is it done?
>
>Kind regards
>
>Georg
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide 
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Aug 15 19:46:48 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 15 Aug 2016 10:46:48 -0700
Subject: [R] Antwort: Accessing an object using a string (SOLVED)
In-Reply-To: <8A22DA6F-1FB3-42D2-A965-A7AF7BED78D2@dcn.davis.ca.us>
References: <OF4B9A6E5B.990C8149-ONC1258010.00301AEE-C1258010.00306F22@lotus.hawesko.de>
	<OF01AB20EB.FF4F2637-ONC1258010.004A632A-C1258010.004B20F7@lotus.hawesko.de>
	<8A22DA6F-1FB3-42D2-A965-A7AF7BED78D2@dcn.davis.ca.us>
Message-ID: <CAGxFJbRq6rXMkLwHHJ67u3YV-RP=1NEBEeh+AaEPnCdx4gmH9A@mail.gmail.com>

While I generally agree with Jeff's caution and advice about the use
of get(), I have also often struggled with designing suitable
interfaces for loading and saving files. So I just wanted to add that
the interactive file.choose() function can be very helpful in this
context if you aren't already aware of it.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 15, 2016 at 9:41 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Use of "get" usually means you are doing something wrong in setting up your approach to a problem. That is, if you design your interface to your functions to be overly general,  it will become full of surprises later.
>
> If in fact the data you are interested in referring to is a column in a data frame, then let the user give your function that data frame as a function argument and use indexing to extract the value from it. Don't design your function to go digging around in the global environment because the user of your function may not be working there.
>
> In this case, it would be better for the user to create a dedicated environment and load the RData file into that and use the ls() and str () functions to look through it rather than assume the RData file only contains data frames by using your function.
>
> x <- 1:5
> dta <- data.frame( x, y = x + 1 )
> save.image( "test.RData" )
> rm( x )
> rm( dta )
> en <- new.env()
> ls()
> ls( en )
> load( "test.RData", envir=en )
> ls( en )
> str( x ) # removed from working environment
> str( en$x )
> str( en$dta )
>
> --
> Sent from my phone. Please excuse my brevity.
>
> On August 15, 2016 6:40:58 AM PDT, G.Maubach at weinwolf.de wrote:
>>Hi All,
>>
>>I found the function get() which returns an object.
>>
>>My whole function looks like this:
>>
>>-- cut --
>>
>>#-------------------------------------------------------------------------------
>># Module        : t_load_dataset.R
>># Author        : Georg Maubach
>># Date          : 2016-08-15
>># Update        : 2016-08-15
>># Description   : Load dataset and print information on contents
>># Source System : R 3.3.0 (64 Bit)
>># Target System : R 3.3.0 (64 Bit)
>>#
>># This program is distributed in the hope that it will be useful,
>># but WITHOUT ANY WARRANTY; without even the implied warranty of
>># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
>>#--------1---------2---------3---------4---------5---------6---------7---------8
>>
>>t_module_name = "t_load_dataset"
>>t_version = "2016-08-15"
>>t_status = "released"
>>
>>cat(
>>  paste0("\n",
>>      t_module_name, " (Version: ", t_version, ", Status: ", t_status,
>>")", "\n", "\n",
>>         "Copyright (C) Georg Maubach 2016
>>
>>This software comes with ABSOLUTELY NO WARRANTY.", "\n", "\n"))
>>
>># If do_test is not defined globally define it here locally by
>>un-commenting it
>># Switch t_do_test to TRUE to run test
>>t_do_test <- FALSE
>>
>># [ Function Defintion
>>]--------------------------------------------------------
>>t_load_dataset <- function(file_path,
>>                           file_name) {
>># Loads and RData file with all objects in it and prints information on
>>
>>its
>>  # contents
>>  #
>>  # Args:
>>  #  file_path (string):
>>  #    String with path name.
>>  #  file_name (string):
>>  #    String with file name.
>>  #
>>  # Operation:
>>#   Loads the RData file with all its objects, stores the objects in
>>the
>>  #   global environment .GlobalEnv and prints information about the
>>objects.
>>  #
>>  # Usage:
>>  #   The function is designed to work only on data frames.
>>  #
>>  # Returns:
>>  #   Nothing, but stores loaded objects directly into the global
>>environment.
>>  #
>>  # Error handling:
>>  #   None.
>>
>>#-----------------------------------------------------------------------------
>>
>>  cat("----------------------- [ t_load_dataset() ]
>>----------------------\n\n")
>>
>>  file_location <- file.path(file_path, file_name)
>>
>>  cat(paste0('Loading ', file_location, " ...\n\n"))
>>
>>  dataset_list <- load(file = file_location,
>>                       envir = .GlobalEnv)
>>
>>  cat(paste0(
>>    length(dataset_list),
>>    " dataset(s) loaded:\n"))
>>  cat(dataset_list)
>>  cat("\n\n")
>>
>>  for (dataset in dataset_list) {
>>    cat(paste0("Dataset '", dataset, "' contains ",
>>                nrow(get(dataset, envir = .GlobalEnv)),
>>                " cases in ",
>>                ncol(get(dataset, envir = .GlobalEnv)),
>>                " variables:\n"))
>>    cat(names(get(dataset, envir = .GlobalEnv)))
>>    cat("\n\n")
>>  }
>>
>>  cat("------------------------------ [ Done ]
>>---------------------------\n\n")
>>}
>>
>># [ Test Defintion
>>]------------------------------------------------------------
>>t_test <- function(do_test = FALSE) {
>>  if (do_test == TRUE) {
>>
>>    # Example dataset
>>    var1 <- c(1, 2, 3)
>>    var2 <- c(4, 5, 6)
>>    d_data1 <- data.frame(var1, var2)
>>
>>    var3 <- c(7, 8, 9)
>>    var4 <- c(10, 11, 12)
>>    d_data2 <- data.frame(var3, var4)
>>
>>    # Save datasets
>>    v_file_name <- "test_t_load_dataset.RData"
>>
>>    save(file = file.path(getwd(),
>>                          v_file_name),
>>         list = c("d_data1", "d_data2"))
>>
>>    # Call function
>>    t_load_dataset(file_path = getwd(), file_name = v_file_name)
>>
>>    # Cleanup
>>    unlink(file.path(getwd(), v_file_name))
>>  }
>>}
>>
>># [ Test Run
>>]------------------------------------------------------------------
>>t_test(do_test = t_do_test)
>>
>># [ Clean up
>>]------------------------------------------------------------------
>>rm("t_module_name", "t_version", "t_status", "t_do_test", "t_test")
>>
>># EOF
>>
>>-- cut --
>>
>>I will include it later the toolbox of R function on Sourceforge.net.
>>
>>Kind regards
>>
>>Georg
>>
>>
>>
>>
>>Von:    G.Maubach at weinwolf.de
>>An:     r-help at r-project.org,
>>Datum:  15.08.2016 10:51
>>Betreff:        [R] Accessing an object using a string
>>Gesendet von:   "R-help" <r-help-bounces at r-project.org>
>>
>>
>>
>>Hi All,
>>
>>I would like to access an object using a sting.
>>
>># Create example dataset
>>var1 <- c(1, 2, 3)
>>var2 <- c(4, 5, 6)
>>data1 <- data.frame(var1, var2)
>>
>>var3 <- c(7, 8, 9)
>>var4 <- c(10, 11, 12)
>>data2 <- data.frame(var3, var4)
>>
>>save(file = "c:/temp/test.RData", list = c("data1", "data2"))
>>
>># Define function
>>t_load_dataset <- function(file_path,
>>                           file_name) {
>>  file_location <- file.path(file_path, file_name)
>>
>>  print(paste0('Loading ', file_location, " ..."))
>>  cat("\n")
>>
>>  object_list <- load(file = file_location,
>>                      envir = .GlobalEnv)
>>
>>  print(paste(length(object_list), "dataset(s) loaded from",
>>file_location))
>>  cat("\n")
>>
>>  print("The following objects were loaded:")
>>  print(object_list)
>>  cat("\n")
>>
>>  for (i in object_list) {
>>    print(paste0("Object '", i, "' in '", file_name, "' contains:"))
>>    str(i)
>>    names(i)  # does not work
>>  }
>>}
>>
>>I have only the character vector object_list containing the names of
>>the
>>objects as strings. I would like to access the objects in object_list
>>to
>>be able to print the names of the variables within the object (usuallly
>>a
>>data frame).
>>
>>Is it possible to do this? How is it done?
>>
>>Kind regards
>>
>>Georg
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Mon Aug 15 20:33:52 2016
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 15 Aug 2016 12:33:52 -0600
Subject: [R] Accessing an object using a string
In-Reply-To: <OF4B9A6E5B.990C8149-ONC1258010.00301AEE-C1258010.00306F22@lotus.hawesko.de>
References: <OF4B9A6E5B.990C8149-ONC1258010.00301AEE-C1258010.00306F22@lotus.hawesko.de>
Message-ID: <CAFEqCdyV1GnYYwiRMawbimKrGY+RxAJAhicJDfdShoRHGsdQLw@mail.gmail.com>

The names function is a primitive, which means that if it does not
already do what you want, it is generally not going to be easy to
coerce it to do it.

However, the names of an object are generally stored as an attribute
of that object, which can be accessed using the attr or attributes
functions.  If you change your code to not use the names function and
instead use attr or attributes to access the names then it should work
for you.


You may also want to consider changing your workflow to have your data
objects read into a list rather than global variables, then process
using lapply/sapply (this would require a change in how your data is
saved from your example, but if you can change that then everything
after can be cleaner/simpler/easier/more fool proof/etc.)


On Mon, Aug 15, 2016 at 2:49 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> I would like to access an object using a sting.
>
> # Create example dataset
> var1 <- c(1, 2, 3)
> var2 <- c(4, 5, 6)
> data1 <- data.frame(var1, var2)
>
> var3 <- c(7, 8, 9)
> var4 <- c(10, 11, 12)
> data2 <- data.frame(var3, var4)
>
> save(file = "c:/temp/test.RData", list = c("data1", "data2"))
>
> # Define function
> t_load_dataset <- function(file_path,
>                            file_name) {
>   file_location <- file.path(file_path, file_name)
>
>   print(paste0('Loading ', file_location, " ..."))
>   cat("\n")
>
>   object_list <- load(file = file_location,
>                       envir = .GlobalEnv)
>
>   print(paste(length(object_list), "dataset(s) loaded from",
> file_location))
>   cat("\n")
>
>   print("The following objects were loaded:")
>   print(object_list)
>   cat("\n")
>
>   for (i in object_list) {
>     print(paste0("Object '", i, "' in '", file_name, "' contains:"))
>     str(i)
>     names(i)  # does not work
>   }
> }
>
> I have only the character vector object_list containing the names of the
> objects as strings. I would like to access the objects in object_list to
> be able to print the names of the variables within the object (usuallly a
> data frame).
>
> Is it possible to do this? How is it done?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From wdunlap at tibco.com  Mon Aug 15 21:10:15 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 15 Aug 2016 12:10:15 -0700
Subject: [R] Accessing an object using a string
In-Reply-To: <CAFEqCdyV1GnYYwiRMawbimKrGY+RxAJAhicJDfdShoRHGsdQLw@mail.gmail.com>
References: <OF4B9A6E5B.990C8149-ONC1258010.00301AEE-C1258010.00306F22@lotus.hawesko.de>
	<CAFEqCdyV1GnYYwiRMawbimKrGY+RxAJAhicJDfdShoRHGsdQLw@mail.gmail.com>
Message-ID: <CAF8bMcbXZJD=3D0exB1sG5B3NU+210Na-Pa9SD6D3GcC-QB9_A@mail.gmail.com>

'names' is an S3-generic function.  E.g., in R-3.3.0:

  > names.unnamed <- function(x) sprintf("#%0*d",
ceiling(log10(length(x))), seq_along(x))
  > u <- structure(letters, class="unnamed")
  > names(u)
   [1] "#01" "#02" "#03" "#04" "#05" "#06" "#07"
   [8] "#08" "#09" "#10" "#11" "#12" "#13" "#14"
  [15] "#15" "#16" "#17" "#18" "#19" "#20" "#21"
  [22] "#22" "#23" "#24" "#25" "#26"

There are a lot of C/C++ based functions that use an internal function to
get
the names of vectors and they may not use this method, but R code will use
it.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Aug 15, 2016 at 11:33 AM, Greg Snow <538280 at gmail.com> wrote:

> The names function is a primitive, which means that if it does not
> already do what you want, it is generally not going to be easy to
> coerce it to do it.
>
> However, the names of an object are generally stored as an attribute
> of that object, which can be accessed using the attr or attributes
> functions.  If you change your code to not use the names function and
> instead use attr or attributes to access the names then it should work
> for you.
>
>
> You may also want to consider changing your workflow to have your data
> objects read into a list rather than global variables, then process
> using lapply/sapply (this would require a change in how your data is
> saved from your example, but if you can change that then everything
> after can be cleaner/simpler/easier/more fool proof/etc.)
>
>
> On Mon, Aug 15, 2016 at 2:49 AM,  <G.Maubach at weinwolf.de> wrote:
> > Hi All,
> >
> > I would like to access an object using a sting.
> >
> > # Create example dataset
> > var1 <- c(1, 2, 3)
> > var2 <- c(4, 5, 6)
> > data1 <- data.frame(var1, var2)
> >
> > var3 <- c(7, 8, 9)
> > var4 <- c(10, 11, 12)
> > data2 <- data.frame(var3, var4)
> >
> > save(file = "c:/temp/test.RData", list = c("data1", "data2"))
> >
> > # Define function
> > t_load_dataset <- function(file_path,
> >                            file_name) {
> >   file_location <- file.path(file_path, file_name)
> >
> >   print(paste0('Loading ', file_location, " ..."))
> >   cat("\n")
> >
> >   object_list <- load(file = file_location,
> >                       envir = .GlobalEnv)
> >
> >   print(paste(length(object_list), "dataset(s) loaded from",
> > file_location))
> >   cat("\n")
> >
> >   print("The following objects were loaded:")
> >   print(object_list)
> >   cat("\n")
> >
> >   for (i in object_list) {
> >     print(paste0("Object '", i, "' in '", file_name, "' contains:"))
> >     str(i)
> >     names(i)  # does not work
> >   }
> > }
> >
> > I have only the character vector object_list containing the names of the
> > objects as strings. I would like to access the objects in object_list to
> > be able to print the names of the variables within the object (usuallly a
> > data frame).
> >
> > Is it possible to do this? How is it done?
> >
> > Kind regards
> >
> > Georg
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From 538280 at gmail.com  Mon Aug 15 21:23:31 2016
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 15 Aug 2016 13:23:31 -0600
Subject: [R] Accessing an object using a string
In-Reply-To: <CAF8bMcbXZJD=3D0exB1sG5B3NU+210Na-Pa9SD6D3GcC-QB9_A@mail.gmail.com>
References: <OF4B9A6E5B.990C8149-ONC1258010.00301AEE-C1258010.00306F22@lotus.hawesko.de>
	<CAFEqCdyV1GnYYwiRMawbimKrGY+RxAJAhicJDfdShoRHGsdQLw@mail.gmail.com>
	<CAF8bMcbXZJD=3D0exB1sG5B3NU+210Na-Pa9SD6D3GcC-QB9_A@mail.gmail.com>
Message-ID: <CAFEqCdzpANBvb+TBgs_3JVZicxJeyUhp5nBcLqJZAqEFBGM=zA@mail.gmail.com>

Hmm, names appears to be both primitive and generic, since when I look
at the function definition (3.3.0) I see:

> names
function (x)  .Primitive("names")

This is what I was referring to as the primitive.  I had originally
intended to look at the code for names to see how it accessed the
attribute, but did not want to delve into compiled code once I saw
.Primitive (and did not think that would be the best approach in this
case anyways).

If typing the name would have given pure R code then it could have
been somewhat simple to modify the function to work on the value of
the variable passed as an object rather than the object (some
functions like rm use NSE, but also have a list argument that will
accept a vector of character).  My suggestion of using attr or
attributes more directly should still work.

On Mon, Aug 15, 2016 at 1:10 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 'names' is an S3-generic function.  E.g., in R-3.3.0:
>
>   > names.unnamed <- function(x) sprintf("#%0*d", ceiling(log10(length(x))),
> seq_along(x))
>   > u <- structure(letters, class="unnamed")
>   > names(u)
>    [1] "#01" "#02" "#03" "#04" "#05" "#06" "#07"
>    [8] "#08" "#09" "#10" "#11" "#12" "#13" "#14"
>   [15] "#15" "#16" "#17" "#18" "#19" "#20" "#21"
>   [22] "#22" "#23" "#24" "#25" "#26"
>
> There are a lot of C/C++ based functions that use an internal function to
> get
> the names of vectors and they may not use this method, but R code will use
> it.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Mon, Aug 15, 2016 at 11:33 AM, Greg Snow <538280 at gmail.com> wrote:
>>
>> The names function is a primitive, which means that if it does not
>> already do what you want, it is generally not going to be easy to
>> coerce it to do it.
>>
>> However, the names of an object are generally stored as an attribute
>> of that object, which can be accessed using the attr or attributes
>> functions.  If you change your code to not use the names function and
>> instead use attr or attributes to access the names then it should work
>> for you.
>>
>>
>> You may also want to consider changing your workflow to have your data
>> objects read into a list rather than global variables, then process
>> using lapply/sapply (this would require a change in how your data is
>> saved from your example, but if you can change that then everything
>> after can be cleaner/simpler/easier/more fool proof/etc.)
>>
>>
>> On Mon, Aug 15, 2016 at 2:49 AM,  <G.Maubach at weinwolf.de> wrote:
>> > Hi All,
>> >
>> > I would like to access an object using a sting.
>> >
>> > # Create example dataset
>> > var1 <- c(1, 2, 3)
>> > var2 <- c(4, 5, 6)
>> > data1 <- data.frame(var1, var2)
>> >
>> > var3 <- c(7, 8, 9)
>> > var4 <- c(10, 11, 12)
>> > data2 <- data.frame(var3, var4)
>> >
>> > save(file = "c:/temp/test.RData", list = c("data1", "data2"))
>> >
>> > # Define function
>> > t_load_dataset <- function(file_path,
>> >                            file_name) {
>> >   file_location <- file.path(file_path, file_name)
>> >
>> >   print(paste0('Loading ', file_location, " ..."))
>> >   cat("\n")
>> >
>> >   object_list <- load(file = file_location,
>> >                       envir = .GlobalEnv)
>> >
>> >   print(paste(length(object_list), "dataset(s) loaded from",
>> > file_location))
>> >   cat("\n")
>> >
>> >   print("The following objects were loaded:")
>> >   print(object_list)
>> >   cat("\n")
>> >
>> >   for (i in object_list) {
>> >     print(paste0("Object '", i, "' in '", file_name, "' contains:"))
>> >     str(i)
>> >     names(i)  # does not work
>> >   }
>> > }
>> >
>> > I have only the character vector object_list containing the names of the
>> > objects as strings. I would like to access the objects in object_list to
>> > be able to print the names of the variables within the object (usuallly
>> > a
>> > data frame).
>> >
>> > Is it possible to do this? How is it done?
>> >
>> > Kind regards
>> >
>> > Georg
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From mzuzcak at secit.sk  Mon Aug 15 11:22:32 2016
From: mzuzcak at secit.sk (=?UTF-8?B?TWF0ZWogWnV6xI3DoWs=?=)
Date: Mon, 15 Aug 2016 11:22:32 +0200
Subject: [R]  Need help with use of ROCK algorithm in R for binary data
In-Reply-To: <cacf7175-fb2a-65d1-c1d8-07b11f81a7b2@secit.sk>
References: <cacf7175-fb2a-65d1-c1d8-07b11f81a7b2@secit.sk>
Message-ID: <f59c6404-c376-8433-70bd-6b41aca4a948@secit.sk>

Dear list members,

I have one appeal for you. 

I need use ROCK (RockCluster) algorithm for binary data in R. My binary
data looks this:

|objects cat1 cat2 cat3 cat4 ...A TRUE FALSE FALSE FALSE B TRUE FALSE
TRUE FALSE C TRUE FALSE FALSE FALSE D FALSE TRUE TRUE TRUE E TRUE TRUE
TRUE TRUE F TRUE FALSE TRUE FALSE|

Now I need clasify these objects A-F to clusters. I apply this procedure
https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Clustering/RockCluster#Dataset
But I have several problems.

 1. I import data from CSV file. |db <- read.csv(file="file.csv",
    header=TRUE, sep="|")| Fields are 1 (TRUE) and 0 (FALSE).
 2. I convert this data: |x <- as.dummy(db[-1]|). After this step all
    columns in x are duplicated with 1 and 0. Why? It is correct please?
 3. |rc <- rockCluster(x, n=4, debug=TRUE)|
 4. |rf <- fitted(rc)| Why |fitted| and when rather use |predict(rc, x)|?
 5. |table(db$objects, rf$cl)| After I get this output:

|    1   NA
A   1    0
B   1    0
C   1    0
D   0    1
E   0    1
F   0    1
|

What way I can read this output? What objects are in clusters with
other? What objects are the most similar please?

Many thanks for your help.

-- 
Best Regards
Matej Zuzcak


	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Aug 16 08:42:19 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 16 Aug 2016 06:42:19 +0000
Subject: [R] Need help with use of ROCK algorithm in R for binary data
In-Reply-To: <f59c6404-c376-8433-70bd-6b41aca4a948@secit.sk>
References: <cacf7175-fb2a-65d1-c1d8-07b11f81a7b2@secit.sk>
	<f59c6404-c376-8433-70bd-6b41aca4a948@secit.sk>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039482@SRVEXCHMBX.precheza.cz>

Hi

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Matej
> Zuz??k
> Sent: Monday, August 15, 2016 11:23 AM
> To: r-help at r-project.org
> Subject: [R] Need help with use of ROCK algorithm in R for binary data
>
> Dear list members,
>
> I have one appeal for you.
>
> I need use ROCK (RockCluster) algorithm for binary data in R. My binary data
> looks this:
>
> |objects cat1 cat2 cat3 cat4 ...A TRUE FALSE FALSE FALSE B TRUE FALSE
> TRUE FALSE C TRUE FALSE FALSE FALSE D FALSE TRUE TRUE TRUE E TRUE TRUE
> TRUE TRUE F TRUE FALSE TRUE FALSE|

Better to show your data with dput command. Just copy the output of

dput(header(db, 20))

to your mail.
>
> Now I need clasify these objects A-F to clusters. I apply this procedure
> https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Clustering/Ro
> ckCluster#Dataset
> But I have several problems.
>
>  1. I import data from CSV file. |db <- read.csv(file="file.csv",
>     header=TRUE, sep="|")| Fields are 1 (TRUE) and 0 (FALSE).

Hm. Why do you use csv if you set the separator to "|". I would use read.table.

>  2. I convert this data: |x <- as.dummy(db[-1]|). After this step all
>     columns in x are duplicated with 1 and 0. Why? It is correct please?

Hm. Strange. In help page the result is TRUE/FALSE coding. Again posting real data would help us to understand your problem.

x <- as.integer(sample(3,10,rep=TRUE))
> x
 [1] 1 1 1 3 1 3 1 3 2 2
> as.dummy(x)
       [,1]  [,2]  [,3]
 [1,]  TRUE FALSE FALSE
 [2,]  TRUE FALSE FALSE
 [3,]  TRUE FALSE FALSE
 [4,] FALSE FALSE  TRUE
 [5,]  TRUE FALSE FALSE
 [6,] FALSE FALSE  TRUE
 [7,]  TRUE FALSE FALSE
 [8,] FALSE FALSE  TRUE
 [9,] FALSE  TRUE FALSE
[10,] FALSE  TRUE FALSE
attr(,"levels")
[1] "1" "2" "3"

As I understand from help page, each columns is repeated the levels(column) times and each column in result has coding T/F based on that particular factor level.

>  3. |rc <- rockCluster(x, n=4, debug=TRUE)|  4. |rf <- fitted(rc)| Why |fitted|
> and when rather use |predict(rc, x)|?
>  5. |table(db$objects, rf$cl)| After I get this output:
>
> |    1   NA
> A   1    0
> B   1    0
> C   1    0
> D   0    1
> E   0    1
> F   0    1
> |
>
> What way I can read this output? What objects are in clusters with other?
> What objects are the most similar please?

There are only 2 clusters with levels 1 and NA. ABC belongs to cluster 1, DEF belongs to cluster NA. An what is the most weird, you have only 6 values in your db data ???

So again presenting your data either by dput or str is vital for evaluating your problem.

And BTW do not post in HTML, your messages are more or less scrambled.

Cheers
Petr


>
> Many thanks for your help.
>
> --
> Best Regards
> Matej Zuzcak
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From G.Maubach at weinwolf.de  Tue Aug 16 08:43:14 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 16 Aug 2016 08:43:14 +0200
Subject: [R] Antwort: Re:  Accessing an object using a string
In-Reply-To: <CAFEqCdyV1GnYYwiRMawbimKrGY+RxAJAhicJDfdShoRHGsdQLw@mail.gmail.com>
References: <OF4B9A6E5B.990C8149-ONC1258010.00301AEE-C1258010.00306F22@lotus.hawesko.de>
	<CAFEqCdyV1GnYYwiRMawbimKrGY+RxAJAhicJDfdShoRHGsdQLw@mail.gmail.com>
Message-ID: <OF326061D4.E35747AF-ONC1258011.00243D67-C1258011.0024EA12@lotus.hawesko.de>

Hi Greg 
and all others who replied to my question,

many thanks for all your answers and help. Currently I store all my 
objects in .GlobalEnv = Workspace. I am not yet familiar working with 
different environments nor did I see that this would be necessary for my 
analysis.

Could you explain why working with different environments would be 
helpful?

You suggested to read variables into lists rather than storing them in 
global variables. This sounds interesting. Could you provide an example of 
how to define and use this?

Kind regards

Georg



Von:    Greg Snow <538280 at gmail.com>
An:     G.Maubach at weinwolf.de, 
Kopie:  r-help <r-help at r-project.org>
Datum:  15.08.2016 20:33
Betreff:        Re: [R] Accessing an object using a string



The names function is a primitive, which means that if it does not
already do what you want, it is generally not going to be easy to
coerce it to do it.

However, the names of an object are generally stored as an attribute
of that object, which can be accessed using the attr or attributes
functions.  If you change your code to not use the names function and
instead use attr or attributes to access the names then it should work
for you.


You may also want to consider changing your workflow to have your data
objects read into a list rather than global variables, then process
using lapply/sapply (this would require a change in how your data is
saved from your example, but if you can change that then everything
after can be cleaner/simpler/easier/more fool proof/etc.)


On Mon, Aug 15, 2016 at 2:49 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> I would like to access an object using a sting.
>
> # Create example dataset
> var1 <- c(1, 2, 3)
> var2 <- c(4, 5, 6)
> data1 <- data.frame(var1, var2)
>
> var3 <- c(7, 8, 9)
> var4 <- c(10, 11, 12)
> data2 <- data.frame(var3, var4)
>
> save(file = "c:/temp/test.RData", list = c("data1", "data2"))
>
> # Define function
> t_load_dataset <- function(file_path,
>                            file_name) {
>   file_location <- file.path(file_path, file_name)
>
>   print(paste0('Loading ', file_location, " ..."))
>   cat("\n")
>
>   object_list <- load(file = file_location,
>                       envir = .GlobalEnv)
>
>   print(paste(length(object_list), "dataset(s) loaded from",
> file_location))
>   cat("\n")
>
>   print("The following objects were loaded:")
>   print(object_list)
>   cat("\n")
>
>   for (i in object_list) {
>     print(paste0("Object '", i, "' in '", file_name, "' contains:"))
>     str(i)
>     names(i)  # does not work
>   }
> }
>
> I have only the character vector object_list containing the names of the
> objects as strings. I would like to access the objects in object_list to
> be able to print the names of the variables within the object (usuallly 
a
> data frame).
>
> Is it possible to do this? How is it done?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From ranjanagirish30 at gmail.com  Tue Aug 16 09:16:33 2016
From: ranjanagirish30 at gmail.com (Ranjana Girish)
Date: Tue, 16 Aug 2016 12:46:33 +0530
Subject: [R] help: about lemmatization with treetagger tool
Message-ID: <CAF5P65n+bXVAtcqHL5ngmNizrUG+SFPmLSR8tCsT_TUjP2gNBA@mail.gmail.com>

To do lemmatization in R, I executed code below

library("koRpus")
tagged.results <- treetag(c("run", "ran", "running"), treetagger="manual",
format="obj",
                          TT.tknz=FALSE , lang="en",
                          TT.options=list(path="C:/Program
Files/TreeTagger", preset="en"))
tagged.results at TT.res

and got some error

  >source('D:/Rprograms/lemanew.R')
Assuming 'UTF-8' as encoding for the input file. If the results turn out to
be erroneous, check the file for invalid characters, e.g. em.dashes or
fancy quotes, and/or consider setting 'encoding' manually.
Error in matrix(unlist(strsplit(tagged.text, "\t")), ncol = 3, byrow =
TRUE,  :
'data' must be of a vector type, was 'NULL'
In addition: Warning message:
running command 'C:\WINDOWS\system32\cmd.exe /c type
 C:\Users\SULOCH~1\AppData\Local\Temp\Rtmp2De3bl\tokenize5044ef851b9.txt |
 grep -v '^$' | C:\Program Files\TreeTagger\bin\tree-tagger.exe C:\Program
Files\TreeTagger\lib\english-utf8.par -token -lemma -sgml -pt-with-lemma
-quiet | perl -pe 's\\tV[BDHV]\\tVB\;s\IN\\that\\tIN\;'' had status 255



i am not understanding what this error is, could someone tell what it is??

and please send any other code to do lemmatization ,which will give correct
output

	[[alternative HTML version deleted]]


From dnbarron at gmail.com  Tue Aug 16 14:15:52 2016
From: dnbarron at gmail.com (David Barron)
Date: Tue, 16 Aug 2016 13:15:52 +0100
Subject: [R] effect.clm
Message-ID: <CAHuze_JdN4aY0+FQLNOoCL9u=VFZYakiRz5w2H6ib6UGWAg6=g@mail.gmail.com>

I'm having a problem using the xlevels option with effect (or Effect) with
objects of class clm, which seems to have no impact on the output (whereas
it does for models of class polr).  Can anyone suggest how to fix this?

Thanks,
David

Here's an example:

mod.wvs <- MASS::polr(poverty ~ gender + religion + degree +
country*poly(age,3), data=WVS)

 Effect('age', mod.wvs, xlevels = list(age = 1:10))

Re-fitting to get Hessian


age effect (probability) for Too Little
age
        1         2         3         4         5         6         7
  8         9        10
0.8403661 0.8270171 0.8133710 0.7995001 0.7854780 0.7713778 0.7572714
0.7432277 0.7293120 0.7155850

age effect (probability) for About Right
age
        1         2         3         4         5         6         7
  8         9        10
0.1295679 0.1399772 0.1505377 0.1611853 0.1718564 0.1824888 0.1930231
0.2034039 0.2135803 0.2235068

age effect (probability) for Too Much
age
         1          2          3          4          5          6
 7          8          9         10
0.03006598 0.03300572 0.03609134 0.03931456 0.04266563 0.04613341
0.04970548 0.05336837 0.05710766 0.06090822

But with clm:

+                 data=WVS)
> Effect('age', mod.wvs, xlevels = list(age = 1:10))

age effect (probability) for Too Little
age
       20        30        40        50        60        70        80
 90
0.5980510 0.5268304 0.4936603 0.4803375 0.4674829 0.4359217 0.3684641
0.2589983

age effect (probability) for About Right
age
       20        30        40        50        60        70        80
 90
0.3031130 0.3453414 0.3629620 0.3696094 0.3757686 0.3897338 0.4129734
0.4227230

age effect (probability) for Too Much
age
        20         30         40         50         60         70
80         90
0.09883598 0.12782815 0.14337772 0.15005316 0.15674848 0.17434449
0.21856247 0.31827868

	[[alternative HTML version deleted]]


From venkynov10 at gmail.com  Tue Aug 16 15:11:37 2016
From: venkynov10 at gmail.com (Venky)
Date: Tue, 16 Aug 2016 18:41:37 +0530
Subject: [R] R Shiny convert into Java
Message-ID: <CAAM-fZ7stB0nX8okf-8F9WB_G7vKz4+Nu5RJwYej=1sTVQQ4zg@mail.gmail.com>

Hi,

How to run Shiny (Server,UI) into JAVA?

I am running R Shiny app using R
But i want to run those functions in Java without dependent of R
Please help me on this anyone


Thanks and Regards
Venkatesan

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Tue Aug 16 15:14:22 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Tue, 16 Aug 2016 13:14:22 +0000
Subject: [R] effect.clm
In-Reply-To: <CAHuze_JdN4aY0+FQLNOoCL9u=VFZYakiRz5w2H6ib6UGWAg6=g@mail.gmail.com>
References: <CAHuze_JdN4aY0+FQLNOoCL9u=VFZYakiRz5w2H6ib6UGWAg6=g@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83656D1C3@FHSDB2D11-2.csu.mcmaster.ca>

Dear David,

Effect.clm() isn't properly passing optional arguments like xlevels. The problem occurs in some other Effect() and effect() methods as well, and the fix seems simple. 

I've corrected these functions in the development version of effects package on R-Forge. We'll need to test more carefully before sending the revised package to CRAN. In the meantime, you should be able to install effects from R-Forge via install.packages("effects", repos="http://R-Forge.R-project.org"), after waiting a day or so for R-Forge to build the package.

Thanks for reporting this bug.

John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David Barron
> Sent: August 16, 2016 8:16 AM
> To: r-help at r-project.org
> Subject: [R] effect.clm
> 
> I'm having a problem using the xlevels option with effect (or Effect) with
> objects of class clm, which seems to have no impact on the output (whereas it
> does for models of class polr).  Can anyone suggest how to fix this?
> 
> Thanks,
> David
> 
> Here's an example:
> 
> mod.wvs <- MASS::polr(poverty ~ gender + religion + degree +
> country*poly(age,3), data=WVS)
> 
>  Effect('age', mod.wvs, xlevels = list(age = 1:10))
> 
> Re-fitting to get Hessian
> 
> 
> age effect (probability) for Too Little
> age
>         1         2         3         4         5         6         7
>   8         9        10
> 0.8403661 0.8270171 0.8133710 0.7995001 0.7854780 0.7713778 0.7572714
> 0.7432277 0.7293120 0.7155850
> 
> age effect (probability) for About Right age
>         1         2         3         4         5         6         7
>   8         9        10
> 0.1295679 0.1399772 0.1505377 0.1611853 0.1718564 0.1824888 0.1930231
> 0.2034039 0.2135803 0.2235068
> 
> age effect (probability) for Too Much
> age
>          1          2          3          4          5          6
>  7          8          9         10
> 0.03006598 0.03300572 0.03609134 0.03931456 0.04266563 0.04613341
> 0.04970548 0.05336837 0.05710766 0.06090822
> 
> But with clm:
> 
> +                 data=WVS)
> > Effect('age', mod.wvs, xlevels = list(age = 1:10))
> 
> age effect (probability) for Too Little
> age
>        20        30        40        50        60        70        80
>  90
> 0.5980510 0.5268304 0.4936603 0.4803375 0.4674829 0.4359217 0.3684641
> 0.2589983
> 
> age effect (probability) for About Right age
>        20        30        40        50        60        70        80
>  90
> 0.3031130 0.3453414 0.3629620 0.3696094 0.3757686 0.3897338 0.4129734
> 0.4227230
> 
> age effect (probability) for Too Much
> age
>         20         30         40         50         60         70
> 80         90
> 0.09883598 0.12782815 0.14337772 0.15005316 0.15674848 0.17434449
> 0.21856247 0.31827868
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From aurora.gonzalez2 at um.es  Tue Aug 16 15:38:03 2016
From: aurora.gonzalez2 at um.es (AURORA GONZALEZ VIDAL)
Date: Tue, 16 Aug 2016 15:38:03 +0200
Subject: [R] dissimilarity matrix using SAX distance
Message-ID: <20160816153803.Horde.oeRecCotwxIixPVbYPaK8w1@webmail.um.es>

Dear all,

I'm trying to cluster some data using SAX distance that was described in
the paper "a symbolic representation of time series with implications for
streaming algorithms" http://www.cs.ucr.edu/~eamonn/SAX.pdf

Once I have my data in matrix format, which function can I use to compute
the dissimilarity matrix? There are several ones to compute the distance
between two SAX data series

diss.MINDIST.SAX(x, y, w, alpha, plot=TRUE)
Func.dist(x, y, matrix, n)

but it is very slow when I try to fill the matrix with two loops and I
really think there should be already any implentation. Do you have any
idea?

I already convert the data into a series of "a",? "b", "c", ... etc data
so I would appreciate either the directo computation of the sax matrix
using my raw data OR using the data already converted to SAX format.

Thank you for any suggestion!


------
Aurora Gonz?lez Vidal
Phd student in Data Analytics for Energy Efficiency

Faculty of Computer Sciences
University of Murcia

@. aurora.gonzalez2 at um.es
T. 868 88 7866
www.um.es/ae

	[[alternative HTML version deleted]]


From malNamalJa at gmx.de  Tue Aug 16 00:03:39 2016
From: malNamalJa at gmx.de (=?UTF-8?Q?=22Jannes_M=C3=BCnchow=22?=)
Date: Tue, 16 Aug 2016 00:03:39 +0200
Subject: [R] [R-pkgs] RQGIS 0.1.0 release
Message-ID: <trinity-ccbe8b64-b6d1-45a2-9753-09bf2019acfa-1471298619060@3capp-gmx-bs41>

Dear all,

We proudly announce the release of RQGIS! RQGIS establishes an interface between R and QGIS (probably the most widely used
open-source Desktop GIS!), i.e. it allows the user to access the more than 1000 QGIS geoalgorithms from within R. To install it, run:

install.packages("RQGIS")

To find out more about RQGIS and how to use it, please visit:

https://jannesm.wordpress.com/2016/08/15/rqgis-0-1-0-release/

and/or

https://github.com/jannes-m/RQGIS

All the best,

Jannes
?

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From 538280 at gmail.com  Tue Aug 16 17:46:31 2016
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 16 Aug 2016 09:46:31 -0600
Subject: [R] Accessing an object using a string
In-Reply-To: <OF326061D4.E35747AF-ONC1258011.00243D67-C1258011.0024EA12@lotus.hawesko.de>
References: <OF4B9A6E5B.990C8149-ONC1258010.00301AEE-C1258010.00306F22@lotus.hawesko.de>
	<CAFEqCdyV1GnYYwiRMawbimKrGY+RxAJAhicJDfdShoRHGsdQLw@mail.gmail.com>
	<OF326061D4.E35747AF-ONC1258011.00243D67-C1258011.0024EA12@lotus.hawesko.de>
Message-ID: <CAFEqCdyiSBKxxxXiBbtAJLdNqmAEaB=-1a30OLWvqPYxY8fyuw@mail.gmail.com>

Interestingly I just gave a presentation on this last Friday.

Using load it is a little more complicated since load reads the object
name from the file as well (which can lead to overwriting objects if
loading from more than one file).  So it is better to use another save
format if possible.  One alternative is to use the saveRDS and readRDS
functions.

Here is the example that I presented:

First, create some sample data files on the disk (here saving as .csv files)

data('Oxboys', package='nlme')
obl <- split(Oxboys, Oxboys$Subject)
for(d in obl) {
  write.csv(d, file=sprintf("OxBoys%02d.csv",
                            d$Subject[1]),
            row.names=FALSE)
}
rm(Oxboys,obl)


Now read the files into R into a single list (and add names to the
list, optional but can be nice):

fnames <- list.files(pattern='^OxBoys')
ob.new <- lapply(fnames, read.csv)
nms <- paste0('OxBoys', sapply(ob.new,
                  function(df) df$Subject[1]))
names(ob.new) <- nms
head( ob.new$OxBoys1 )

The list.files function in the first line is one convenient way to
create the vector of filenames, but other options would include
paste0, sprintf, and others.

Now perform the same analysis on each data frame in the list and
nicely format the results (a simple regression in this case):

slopes <- sapply(ob.new, function(df) {
  fit <- lm(height~age, data=df)
  coef(fit)
})
head(t(slopes))




On Tue, Aug 16, 2016 at 12:43 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi Greg
> and all others who replied to my question,
>
> many thanks for all your answers and help. Currently I store all my
> objects in .GlobalEnv = Workspace. I am not yet familiar working with
> different environments nor did I see that this would be necessary for my
> analysis.
>
> Could you explain why working with different environments would be
> helpful?
>
> You suggested to read variables into lists rather than storing them in
> global variables. This sounds interesting. Could you provide an example of
> how to define and use this?
>
> Kind regards
>
> Georg
>
>
>
> Von:    Greg Snow <538280 at gmail.com>
> An:     G.Maubach at weinwolf.de,
> Kopie:  r-help <r-help at r-project.org>
> Datum:  15.08.2016 20:33
> Betreff:        Re: [R] Accessing an object using a string
>
>
>
> The names function is a primitive, which means that if it does not
> already do what you want, it is generally not going to be easy to
> coerce it to do it.
>
> However, the names of an object are generally stored as an attribute
> of that object, which can be accessed using the attr or attributes
> functions.  If you change your code to not use the names function and
> instead use attr or attributes to access the names then it should work
> for you.
>
>
> You may also want to consider changing your workflow to have your data
> objects read into a list rather than global variables, then process
> using lapply/sapply (this would require a change in how your data is
> saved from your example, but if you can change that then everything
> after can be cleaner/simpler/easier/more fool proof/etc.)
>
>
> On Mon, Aug 15, 2016 at 2:49 AM,  <G.Maubach at weinwolf.de> wrote:
>> Hi All,
>>
>> I would like to access an object using a sting.
>>
>> # Create example dataset
>> var1 <- c(1, 2, 3)
>> var2 <- c(4, 5, 6)
>> data1 <- data.frame(var1, var2)
>>
>> var3 <- c(7, 8, 9)
>> var4 <- c(10, 11, 12)
>> data2 <- data.frame(var3, var4)
>>
>> save(file = "c:/temp/test.RData", list = c("data1", "data2"))
>>
>> # Define function
>> t_load_dataset <- function(file_path,
>>                            file_name) {
>>   file_location <- file.path(file_path, file_name)
>>
>>   print(paste0('Loading ', file_location, " ..."))
>>   cat("\n")
>>
>>   object_list <- load(file = file_location,
>>                       envir = .GlobalEnv)
>>
>>   print(paste(length(object_list), "dataset(s) loaded from",
>> file_location))
>>   cat("\n")
>>
>>   print("The following objects were loaded:")
>>   print(object_list)
>>   cat("\n")
>>
>>   for (i in object_list) {
>>     print(paste0("Object '", i, "' in '", file_name, "' contains:"))
>>     str(i)
>>     names(i)  # does not work
>>   }
>> }
>>
>> I have only the character vector object_list containing the names of the
>> objects as strings. I would like to access the objects in object_list to
>> be able to print the names of the variables within the object (usuallly
> a
>> data frame).
>>
>> Is it possible to do this? How is it done?
>>
>> Kind regards
>>
>> Georg
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From HDoran at air.org  Tue Aug 16 18:28:13 2016
From: HDoran at air.org (Doran, Harold)
Date: Tue, 16 Aug 2016 16:28:13 +0000
Subject: [R] R Shiny convert into Java
In-Reply-To: <CAAM-fZ7stB0nX8okf-8F9WB_G7vKz4+Nu5RJwYej=1sTVQQ4zg@mail.gmail.com>
References: <CAAM-fZ7stB0nX8okf-8F9WB_G7vKz4+Nu5RJwYej=1sTVQQ4zg@mail.gmail.com>
Message-ID: <D3D8B736.3E653%hdoran@air.org>

You should ask this on the Shiny google group. But, Shiny depends on R, so
what you?re wanting to accomplish is not possible

On 8/16/16, 9:11 AM, "Venky" <venkynov10 at gmail.com> wrote:

>Hi,
>
>How to run Shiny (Server,UI) into JAVA?
>
>I am running R Shiny app using R
>But i want to run those functions in Java without dependent of R
>Please help me on this anyone
>
>
>Thanks and Regards
>Venkatesan
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Aug 16 19:14:34 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 16 Aug 2016 10:14:34 -0700
Subject: [R] Accessing an object using a string
In-Reply-To: <OF326061D4.E35747AF-ONC1258011.00243D67-C1258011.0024EA12@lotus.hawesko.de>
References: <OF4B9A6E5B.990C8149-ONC1258010.00301AEE-C1258010.00306F22@lotus.hawesko.de>
	<CAFEqCdyV1GnYYwiRMawbimKrGY+RxAJAhicJDfdShoRHGsdQLw@mail.gmail.com>
	<OF326061D4.E35747AF-ONC1258011.00243D67-C1258011.0024EA12@lotus.hawesko.de>
Message-ID: <CAGxFJbQnkgUcK+AyD27HO_HmgPYcfnnvRw3pnJo-WMej3SzKyg@mail.gmail.com>

Inline.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 15, 2016 at 11:43 PM,  <G.Maubach at weinwolf.de> wrote:
> Hi Greg
> and all others who replied to my question,
>
> many thanks for all your answers and help. Currently I store all my
> objects in .GlobalEnv = Workspace. I am not yet familiar working with
> different environments nor did I see that this would be necessary for my
> analysis.
>
> Could you explain why working with different environments would be
> helpful?
>
> You suggested to read variables into lists rather than storing them in
> global variables. This sounds interesting. Could you provide an example of
> how to define and use this?


It sounds to me as if you really need to spend some time with an R
tutorial or two before you do anything else. There are many good ones
on the web. See here for some suggestions:

https://www.rstudio.com/online-learning/#R

While you may reasonably expect some help with R programming and
related matters here, you should not expect this list to do your
homework for you, at least IMHO (others may disagree).

Cheers,
Bert


>
> Kind regards
>
> Georg
>
>
>
> Von:    Greg Snow <538280 at gmail.com>
> An:     G.Maubach at weinwolf.de,
> Kopie:  r-help <r-help at r-project.org>
> Datum:  15.08.2016 20:33
> Betreff:        Re: [R] Accessing an object using a string
>
>
>
> The names function is a primitive, which means that if it does not
> already do what you want, it is generally not going to be easy to
> coerce it to do it.
>
> However, the names of an object are generally stored as an attribute
> of that object, which can be accessed using the attr or attributes
> functions.  If you change your code to not use the names function and
> instead use attr or attributes to access the names then it should work
> for you.
>
>
> You may also want to consider changing your workflow to have your data
> objects read into a list rather than global variables, then process
> using lapply/sapply (this would require a change in how your data is
> saved from your example, but if you can change that then everything
> after can be cleaner/simpler/easier/more fool proof/etc.)
>
>
> On Mon, Aug 15, 2016 at 2:49 AM,  <G.Maubach at weinwolf.de> wrote:
>> Hi All,
>>
>> I would like to access an object using a sting.
>>
>> # Create example dataset
>> var1 <- c(1, 2, 3)
>> var2 <- c(4, 5, 6)
>> data1 <- data.frame(var1, var2)
>>
>> var3 <- c(7, 8, 9)
>> var4 <- c(10, 11, 12)
>> data2 <- data.frame(var3, var4)
>>
>> save(file = "c:/temp/test.RData", list = c("data1", "data2"))
>>
>> # Define function
>> t_load_dataset <- function(file_path,
>>                            file_name) {
>>   file_location <- file.path(file_path, file_name)
>>
>>   print(paste0('Loading ', file_location, " ..."))
>>   cat("\n")
>>
>>   object_list <- load(file = file_location,
>>                       envir = .GlobalEnv)
>>
>>   print(paste(length(object_list), "dataset(s) loaded from",
>> file_location))
>>   cat("\n")
>>
>>   print("The following objects were loaded:")
>>   print(object_list)
>>   cat("\n")
>>
>>   for (i in object_list) {
>>     print(paste0("Object '", i, "' in '", file_name, "' contains:"))
>>     str(i)
>>     names(i)  # does not work
>>   }
>> }
>>
>> I have only the character vector object_list containing the names of the
>> objects as strings. I would like to access the objects in object_list to
>> be able to print the names of the variables within the object (usuallly
> a
>> data frame).
>>
>> Is it possible to do this? How is it done?
>>
>> Kind regards
>>
>> Georg
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>
>


From istazahn at gmail.com  Tue Aug 16 19:41:18 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 16 Aug 2016 13:41:18 -0400
Subject: [R] Accessing an object using a string
In-Reply-To: <CAFEqCdyiSBKxxxXiBbtAJLdNqmAEaB=-1a30OLWvqPYxY8fyuw@mail.gmail.com>
References: <OF4B9A6E5B.990C8149-ONC1258010.00301AEE-C1258010.00306F22@lotus.hawesko.de>
	<CAFEqCdyV1GnYYwiRMawbimKrGY+RxAJAhicJDfdShoRHGsdQLw@mail.gmail.com>
	<OF326061D4.E35747AF-ONC1258011.00243D67-C1258011.0024EA12@lotus.hawesko.de>
	<CAFEqCdyiSBKxxxXiBbtAJLdNqmAEaB=-1a30OLWvqPYxY8fyuw@mail.gmail.com>
Message-ID: <CA+vqiLHAPnoEJmPTOz+rWwUP=o3joj5jiU5LvG-zfbTcrYmquQ@mail.gmail.com>

I'm surprised no one has given what I consider to be the standard
answer to this questions, namely ?get. Won't

  for (i in object_list) {
    print(paste0("Object '", i, "' in '", file_name, "' contains:"))
    str(get(i))
    print(names(get(i)))  # works
  }

do what you want?

Best,
Ista

On Tue, Aug 16, 2016 at 11:46 AM, Greg Snow <538280 at gmail.com> wrote:
> Interestingly I just gave a presentation on this last Friday.
>
> Using load it is a little more complicated since load reads the object
> name from the file as well (which can lead to overwriting objects if
> loading from more than one file).  So it is better to use another save
> format if possible.  One alternative is to use the saveRDS and readRDS
> functions.
>
> Here is the example that I presented:
>
> First, create some sample data files on the disk (here saving as .csv files)
>
> data('Oxboys', package='nlme')
> obl <- split(Oxboys, Oxboys$Subject)
> for(d in obl) {
>   write.csv(d, file=sprintf("OxBoys%02d.csv",
>                             d$Subject[1]),
>             row.names=FALSE)
> }
> rm(Oxboys,obl)
>
>
> Now read the files into R into a single list (and add names to the
> list, optional but can be nice):
>
> fnames <- list.files(pattern='^OxBoys')
> ob.new <- lapply(fnames, read.csv)
> nms <- paste0('OxBoys', sapply(ob.new,
>                   function(df) df$Subject[1]))
> names(ob.new) <- nms
> head( ob.new$OxBoys1 )
>
> The list.files function in the first line is one convenient way to
> create the vector of filenames, but other options would include
> paste0, sprintf, and others.
>
> Now perform the same analysis on each data frame in the list and
> nicely format the results (a simple regression in this case):
>
> slopes <- sapply(ob.new, function(df) {
>   fit <- lm(height~age, data=df)
>   coef(fit)
> })
> head(t(slopes))
>
>
>
>
> On Tue, Aug 16, 2016 at 12:43 AM,  <G.Maubach at weinwolf.de> wrote:
>> Hi Greg
>> and all others who replied to my question,
>>
>> many thanks for all your answers and help. Currently I store all my
>> objects in .GlobalEnv = Workspace. I am not yet familiar working with
>> different environments nor did I see that this would be necessary for my
>> analysis.
>>
>> Could you explain why working with different environments would be
>> helpful?
>>
>> You suggested to read variables into lists rather than storing them in
>> global variables. This sounds interesting. Could you provide an example of
>> how to define and use this?
>>
>> Kind regards
>>
>> Georg
>>
>>
>>
>> Von:    Greg Snow <538280 at gmail.com>
>> An:     G.Maubach at weinwolf.de,
>> Kopie:  r-help <r-help at r-project.org>
>> Datum:  15.08.2016 20:33
>> Betreff:        Re: [R] Accessing an object using a string
>>
>>
>>
>> The names function is a primitive, which means that if it does not
>> already do what you want, it is generally not going to be easy to
>> coerce it to do it.
>>
>> However, the names of an object are generally stored as an attribute
>> of that object, which can be accessed using the attr or attributes
>> functions.  If you change your code to not use the names function and
>> instead use attr or attributes to access the names then it should work
>> for you.
>>
>>
>> You may also want to consider changing your workflow to have your data
>> objects read into a list rather than global variables, then process
>> using lapply/sapply (this would require a change in how your data is
>> saved from your example, but if you can change that then everything
>> after can be cleaner/simpler/easier/more fool proof/etc.)
>>
>>
>> On Mon, Aug 15, 2016 at 2:49 AM,  <G.Maubach at weinwolf.de> wrote:
>>> Hi All,
>>>
>>> I would like to access an object using a sting.
>>>
>>> # Create example dataset
>>> var1 <- c(1, 2, 3)
>>> var2 <- c(4, 5, 6)
>>> data1 <- data.frame(var1, var2)
>>>
>>> var3 <- c(7, 8, 9)
>>> var4 <- c(10, 11, 12)
>>> data2 <- data.frame(var3, var4)
>>>
>>> save(file = "c:/temp/test.RData", list = c("data1", "data2"))
>>>
>>> # Define function
>>> t_load_dataset <- function(file_path,
>>>                            file_name) {
>>>   file_location <- file.path(file_path, file_name)
>>>
>>>   print(paste0('Loading ', file_location, " ..."))
>>>   cat("\n")
>>>
>>>   object_list <- load(file = file_location,
>>>                       envir = .GlobalEnv)
>>>
>>>   print(paste(length(object_list), "dataset(s) loaded from",
>>> file_location))
>>>   cat("\n")
>>>
>>>   print("The following objects were loaded:")
>>>   print(object_list)
>>>   cat("\n")
>>>
>>>   for (i in object_list) {
>>>     print(paste0("Object '", i, "' in '", file_name, "' contains:"))
>>>     str(i)
>>>     names(i)  # does not work
>>>   }
>>> }
>>>
>>> I have only the character vector object_list containing the names of the
>>> objects as strings. I would like to access the objects in object_list to
>>> be able to print the names of the variables within the object (usuallly
>> a
>>> data frame).
>>>
>>> Is it possible to do this? How is it done?
>>>
>>> Kind regards
>>>
>>> Georg
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com
>>
>>
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From shivipmp82 at gmail.com  Tue Aug 16 20:07:47 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Tue, 16 Aug 2016 23:37:47 +0530
Subject: [R] Error in riv package
Message-ID: <CAB=p7SrddtaA264Kfj3KqtjVQvOyoRK4F6PA+sjBxprBp8t9Nw@mail.gmail.com>

HI Team,

I am working to reduce the # of predictor variables from the model using
woe and iv values. For this i am using riv package. However i am having a
hard time installing this package:

install_github("riv","tomasgreif")
install.packages("DBI",dependencies=TRUE)

The error i receive is :
*Username parameter is deprecated. Please use tomasgreif/riv *

The other approach i have to use the library(InformationValue). I have this
as below:
WOE(X=SFDC1$support_cat, Y=SFDC1$survey)
WOETable(X=SFDC1$support_cat, Y=SFDC1$survey)
IV(X=SFDC1$support_cat, Y=SFDC1$survey)

This package assists me achieve what i am looking for but here i need to
add one independent variable at a time to see whether it is predictive or
not. Is there a way i can add all variables at a go or have to add one by
one,

For the above package (riv) i have seen an example which helps to take the
entire data range and  predictive the power of each predictor. The link for
the same is:
https://www.r-bloggers.com/r-credit-scoring-woe-information-value-in-woe-
package/

Thanks, Shivi

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Aug 16 20:33:34 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 16 Aug 2016 11:33:34 -0700
Subject: [R] Antwort: Re:  Accessing an object using a string
In-Reply-To: <OF326061D4.E35747AF-ONC1258011.00243D67-C1258011.0024EA12@lotus.hawesko.de>
References: <OF4B9A6E5B.990C8149-ONC1258010.00301AEE-C1258010.00306F22@lotus.hawesko.de>
	<CAFEqCdyV1GnYYwiRMawbimKrGY+RxAJAhicJDfdShoRHGsdQLw@mail.gmail.com>
	<OF326061D4.E35747AF-ONC1258011.00243D67-C1258011.0024EA12@lotus.hawesko.de>
Message-ID: <72F454AE-D1D6-4294-AECF-DC29FA69E44C@dcn.davis.ca.us>

My example shows that using a dedicated environment allows you to segregate the items loaded from the save file from the objects you are working with. It has the advantage that any kind of object or collection of objects can be loaded that way. It has the disadvantage that you have to keep track of what kinds of objects they are (as in not data frames).

For example, suppose you want to make a data table that summarizes information about the contents of several save files. If you name the data frame you are building up "infodf" and one of the save files has a data frame by that name in it, then loading it into the global environment will wipe out the information so far accumulated and replace it with something else.

Greg's option of saving individual objects into rds files is another solution. It has the advantage of letting you control the name of the imported object, but you still need to independently insure that the object is actually a data frame somehow before digging into its columns.

Personally, I prefer to avoid keeping lots of rds or RData files around... I favor restarting from original input files to insure reproducibility. Any output values that I want to emit from my analysis I write into CSV or other portable format. I only use rds/RData files for temporary storage (caching) for performance acceleration. 
-- 
Sent from my phone. Please excuse my brevity.

On August 15, 2016 11:43:14 PM PDT, G.Maubach at weinwolf.de wrote:
>Hi Greg 
>and all others who replied to my question,
>
>many thanks for all your answers and help. Currently I store all my 
>objects in .GlobalEnv = Workspace. I am not yet familiar working with 
>different environments nor did I see that this would be necessary for
>my 
>analysis.
>
>Could you explain why working with different environments would be 
>helpful?
>
>You suggested to read variables into lists rather than storing them in 
>global variables. This sounds interesting. Could you provide an example
>of 
>how to define and use this?
>
>Kind regards
>
>Georg
>
>
>
>Von:    Greg Snow <538280 at gmail.com>
>An:     G.Maubach at weinwolf.de, 
>Kopie:  r-help <r-help at r-project.org>
>Datum:  15.08.2016 20:33
>Betreff:        Re: [R] Accessing an object using a string
>
>
>
>The names function is a primitive, which means that if it does not
>already do what you want, it is generally not going to be easy to
>coerce it to do it.
>
>However, the names of an object are generally stored as an attribute
>of that object, which can be accessed using the attr or attributes
>functions.  If you change your code to not use the names function and
>instead use attr or attributes to access the names then it should work
>for you.
>
>
>You may also want to consider changing your workflow to have your data
>objects read into a list rather than global variables, then process
>using lapply/sapply (this would require a change in how your data is
>saved from your example, but if you can change that then everything
>after can be cleaner/simpler/easier/more fool proof/etc.)
>
>
>On Mon, Aug 15, 2016 at 2:49 AM,  <G.Maubach at weinwolf.de> wrote:
>> Hi All,
>>
>> I would like to access an object using a sting.
>>
>> # Create example dataset
>> var1 <- c(1, 2, 3)
>> var2 <- c(4, 5, 6)
>> data1 <- data.frame(var1, var2)
>>
>> var3 <- c(7, 8, 9)
>> var4 <- c(10, 11, 12)
>> data2 <- data.frame(var3, var4)
>>
>> save(file = "c:/temp/test.RData", list = c("data1", "data2"))
>>
>> # Define function
>> t_load_dataset <- function(file_path,
>>                            file_name) {
>>   file_location <- file.path(file_path, file_name)
>>
>>   print(paste0('Loading ', file_location, " ..."))
>>   cat("\n")
>>
>>   object_list <- load(file = file_location,
>>                       envir = .GlobalEnv)
>>
>>   print(paste(length(object_list), "dataset(s) loaded from",
>> file_location))
>>   cat("\n")
>>
>>   print("The following objects were loaded:")
>>   print(object_list)
>>   cat("\n")
>>
>>   for (i in object_list) {
>>     print(paste0("Object '", i, "' in '", file_name, "' contains:"))
>>     str(i)
>>     names(i)  # does not work
>>   }
>> }
>>
>> I have only the character vector object_list containing the names of
>the
>> objects as strings. I would like to access the objects in object_list
>to
>> be able to print the names of the variables within the object
>(usuallly 
>a
>> data frame).
>>
>> Is it possible to do this? How is it done?
>>
>> Kind regards
>>
>> Georg
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Tue Aug 16 20:40:17 2016
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 16 Aug 2016 12:40:17 -0600
Subject: [R] Accessing an object using a string
In-Reply-To: <CA+vqiLHAPnoEJmPTOz+rWwUP=o3joj5jiU5LvG-zfbTcrYmquQ@mail.gmail.com>
References: <OF4B9A6E5B.990C8149-ONC1258010.00301AEE-C1258010.00306F22@lotus.hawesko.de>
	<CAFEqCdyV1GnYYwiRMawbimKrGY+RxAJAhicJDfdShoRHGsdQLw@mail.gmail.com>
	<OF326061D4.E35747AF-ONC1258011.00243D67-C1258011.0024EA12@lotus.hawesko.de>
	<CAFEqCdyiSBKxxxXiBbtAJLdNqmAEaB=-1a30OLWvqPYxY8fyuw@mail.gmail.com>
	<CA+vqiLHAPnoEJmPTOz+rWwUP=o3joj5jiU5LvG-zfbTcrYmquQ@mail.gmail.com>
Message-ID: <CAFEqCdxUqM8uGON=RgQPoQU8_6ZVxoRn-NqT7K7y=hVm-V5MwA@mail.gmail.com>

Ista,

The original poster did discover the get function and posted that (in
a different thread).

Personally I don't recommend get for things like this for similar
reasons that I don't suggest a loaded pistol be used to swat a fly, it
may be effective for the immediate problem, but has potential to lead
to poor outcomes if used repeatedly or extended.

People who discover "get" also tend to stumble across "assign" and my
opinions on that function have become fortune(236) (fortune(174) could
also be relevant).

Now it is entirely possible that you and the original poster are both
smarter than me and would not fall into that trap, but see
fortune(181).

On Tue, Aug 16, 2016 at 11:41 AM, Ista Zahn <istazahn at gmail.com> wrote:
> I'm surprised no one has given what I consider to be the standard
> answer to this questions, namely ?get. Won't
>
>   for (i in object_list) {
>     print(paste0("Object '", i, "' in '", file_name, "' contains:"))
>     str(get(i))
>     print(names(get(i)))  # works
>   }
>
> do what you want?
>
> Best,
> Ista
>
> On Tue, Aug 16, 2016 at 11:46 AM, Greg Snow <538280 at gmail.com> wrote:
>> Interestingly I just gave a presentation on this last Friday.
>>
>> Using load it is a little more complicated since load reads the object
>> name from the file as well (which can lead to overwriting objects if
>> loading from more than one file).  So it is better to use another save
>> format if possible.  One alternative is to use the saveRDS and readRDS
>> functions.
>>
>> Here is the example that I presented:
>>
>> First, create some sample data files on the disk (here saving as .csv files)
>>
>> data('Oxboys', package='nlme')
>> obl <- split(Oxboys, Oxboys$Subject)
>> for(d in obl) {
>>   write.csv(d, file=sprintf("OxBoys%02d.csv",
>>                             d$Subject[1]),
>>             row.names=FALSE)
>> }
>> rm(Oxboys,obl)
>>
>>
>> Now read the files into R into a single list (and add names to the
>> list, optional but can be nice):
>>
>> fnames <- list.files(pattern='^OxBoys')
>> ob.new <- lapply(fnames, read.csv)
>> nms <- paste0('OxBoys', sapply(ob.new,
>>                   function(df) df$Subject[1]))
>> names(ob.new) <- nms
>> head( ob.new$OxBoys1 )
>>
>> The list.files function in the first line is one convenient way to
>> create the vector of filenames, but other options would include
>> paste0, sprintf, and others.
>>
>> Now perform the same analysis on each data frame in the list and
>> nicely format the results (a simple regression in this case):
>>
>> slopes <- sapply(ob.new, function(df) {
>>   fit <- lm(height~age, data=df)
>>   coef(fit)
>> })
>> head(t(slopes))
>>
>>
>>
>>
>> On Tue, Aug 16, 2016 at 12:43 AM,  <G.Maubach at weinwolf.de> wrote:
>>> Hi Greg
>>> and all others who replied to my question,
>>>
>>> many thanks for all your answers and help. Currently I store all my
>>> objects in .GlobalEnv = Workspace. I am not yet familiar working with
>>> different environments nor did I see that this would be necessary for my
>>> analysis.
>>>
>>> Could you explain why working with different environments would be
>>> helpful?
>>>
>>> You suggested to read variables into lists rather than storing them in
>>> global variables. This sounds interesting. Could you provide an example of
>>> how to define and use this?
>>>
>>> Kind regards
>>>
>>> Georg
>>>
>>>
>>>
>>> Von:    Greg Snow <538280 at gmail.com>
>>> An:     G.Maubach at weinwolf.de,
>>> Kopie:  r-help <r-help at r-project.org>
>>> Datum:  15.08.2016 20:33
>>> Betreff:        Re: [R] Accessing an object using a string
>>>
>>>
>>>
>>> The names function is a primitive, which means that if it does not
>>> already do what you want, it is generally not going to be easy to
>>> coerce it to do it.
>>>
>>> However, the names of an object are generally stored as an attribute
>>> of that object, which can be accessed using the attr or attributes
>>> functions.  If you change your code to not use the names function and
>>> instead use attr or attributes to access the names then it should work
>>> for you.
>>>
>>>
>>> You may also want to consider changing your workflow to have your data
>>> objects read into a list rather than global variables, then process
>>> using lapply/sapply (this would require a change in how your data is
>>> saved from your example, but if you can change that then everything
>>> after can be cleaner/simpler/easier/more fool proof/etc.)
>>>
>>>
>>> On Mon, Aug 15, 2016 at 2:49 AM,  <G.Maubach at weinwolf.de> wrote:
>>>> Hi All,
>>>>
>>>> I would like to access an object using a sting.
>>>>
>>>> # Create example dataset
>>>> var1 <- c(1, 2, 3)
>>>> var2 <- c(4, 5, 6)
>>>> data1 <- data.frame(var1, var2)
>>>>
>>>> var3 <- c(7, 8, 9)
>>>> var4 <- c(10, 11, 12)
>>>> data2 <- data.frame(var3, var4)
>>>>
>>>> save(file = "c:/temp/test.RData", list = c("data1", "data2"))
>>>>
>>>> # Define function
>>>> t_load_dataset <- function(file_path,
>>>>                            file_name) {
>>>>   file_location <- file.path(file_path, file_name)
>>>>
>>>>   print(paste0('Loading ', file_location, " ..."))
>>>>   cat("\n")
>>>>
>>>>   object_list <- load(file = file_location,
>>>>                       envir = .GlobalEnv)
>>>>
>>>>   print(paste(length(object_list), "dataset(s) loaded from",
>>>> file_location))
>>>>   cat("\n")
>>>>
>>>>   print("The following objects were loaded:")
>>>>   print(object_list)
>>>>   cat("\n")
>>>>
>>>>   for (i in object_list) {
>>>>     print(paste0("Object '", i, "' in '", file_name, "' contains:"))
>>>>     str(i)
>>>>     names(i)  # does not work
>>>>   }
>>>> }
>>>>
>>>> I have only the character vector object_list containing the names of the
>>>> objects as strings. I would like to access the objects in object_list to
>>>> be able to print the names of the variables within the object (usuallly
>>> a
>>>> data frame).
>>>>
>>>> Is it possible to do this? How is it done?
>>>>
>>>> Kind regards
>>>>
>>>> Georg
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>> --
>>> Gregory (Greg) L. Snow Ph.D.
>>> 538280 at gmail.com
>>>
>>>
>>
>>
>>
>> --
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From dwinsemius at comcast.net  Tue Aug 16 21:47:50 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 16 Aug 2016 12:47:50 -0700
Subject: [R] Error in riv package
In-Reply-To: <CAB=p7SrddtaA264Kfj3KqtjVQvOyoRK4F6PA+sjBxprBp8t9Nw@mail.gmail.com>
References: <CAB=p7SrddtaA264Kfj3KqtjVQvOyoRK4F6PA+sjBxprBp8t9Nw@mail.gmail.com>
Message-ID: <82486665-14CA-4AEC-95F8-4B9283E364F1@comcast.net>


> On Aug 16, 2016, at 11:07 AM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
> 
> HI Team,
> 
> I am working to reduce the # of predictor variables from the model using
> woe and iv values. For this i am using riv package. However i am having a
> hard time installing this package:
> 
> install_github("riv","tomasgreif")
> install.packages("DBI",dependencies=TRUE)
> 
> The error i receive is :
> *Username parameter is deprecated. Please use tomasgreif/riv *

No. You did not get an error message. It was clearly labeled a :Warning message". Here is the full console output from that call:

> install_github("riv","tomasgreif")
Downloading GitHub repo tomasgreif/riv at master
from URL https://api.github.com/repos/tomasgreif/riv/zipball/master
Installing woe
'/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file --no-environ  \
  --no-save --no-restore --quiet CMD INSTALL  \
  '/private/var/folders/yq/m3j1jqtj6hq6s5mq_v0jn3s80000gn/T/Rtmp6YDYoj/devtoolsadc32ead1a82/tomasgreif-woe-43fcf26'  \
  --library='/Library/Frameworks/R.framework/Versions/3.3/Resources/library'  \
  --install-tests 

* installing *source* package ?woe? ...
** R
** data
*** moving datasets to lazyload DB
** demo
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
* DONE (woe)
Warning message:
Username parameter is deprecated. Please use tomasgreif/riv 


It's just telling you to use this next time:

install_github("tomasgreif/riv")

I will lay long odds that you already have the package installed.

I cannot comment on what this package purports to do. I'm somewhat suspicious that it is statistically suspect.

-- 
David.

> 
> The other approach i have to use the library(InformationValue). I have this
> as below:
> WOE(X=SFDC1$support_cat, Y=SFDC1$survey)
> WOETable(X=SFDC1$support_cat, Y=SFDC1$survey)
> IV(X=SFDC1$support_cat, Y=SFDC1$survey)
> 
> This package assists me achieve what i am looking for but here i need to
> add one independent variable at a time to see whether it is predictive or
> not. Is there a way i can add all variables at a go or have to add one by
> one,
> 
> For the above package (riv) i have seen an example which helps to take the
> entire data range and  predictive the power of each predictor. The link for
> the same is:
> https://www.r-bloggers.com/r-credit-scoring-woe-information-value-in-woe-
> package/
> 
> Thanks, Shivi
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From lebolger at gmail.com  Tue Aug 16 20:51:18 2016
From: lebolger at gmail.com (Lauren Bolger)
Date: Tue, 16 Aug 2016 14:51:18 -0400
Subject: [R] [R Survey Analysis] Problem counting number of responses
Message-ID: <CAEgJW__LXevV+7t-ywGfPAgKuOfsN80XmR6jzsrpGferKHFd_Q@mail.gmail.com>

M
?y dataset includes a survey completed by research participants to evaluate
quality of life. A few things regarding the survey:


   -
*not all questions must be answered? for the total score *
   - questions left blank are coded as "0"
   - ?the number of questions answered must be determined in order to
   compute the total score


*Sample Code?*

> q1 <- ifelse(is.na(survey, 0, survey$q1)

> q2 <- ifelse(is.na(survey, 0, survey$q2)

> q3 <- ifelse(is.na(survey, 0, survey$q3)

> survey$sum.survey <- q1 + q2 + q3

> survey$responses <- # HELP ?????
*> # HELP PART 1 ------------------------------*
*> # need help determining number of questions the respondents answered*

> *# HELP PART 2 -------------------------------*
*> # I want to look at the subset of the population that completed all the
questions*


?
?
?Thanks for your help!! It means a lot? :)

	[[alternative HTML version deleted]]


From p.f.doelp at gmail.com  Tue Aug 16 17:08:16 2016
From: p.f.doelp at gmail.com (Patrick Doelp)
Date: Tue, 16 Aug 2016 11:08:16 -0400
Subject: [R] RDCOMclient copy excel chart to powerpoint
Message-ID: <CACi5iSnhLNTdaQ+5vE0kAhSMiYZoD5R_1g9KXgWh037h0bgkZA@mail.gmail.com>

Hello,

I'm currently working on a project that requires me to create charts in
excel
and copy them to a powerpoint presentation. I've been using the RDCOMclient
package to build the charts in excel. I'm now working on actually moving the
charts from excel to powerpoint and I can't seem to figure it out. I've
included some code below (excluding the function that actually creates the
chart as that actually works).

I know that there are better ways to create presentations (ggplot2 and
ReporteRs or just markdown) but the project has some specific requirements
that are met through this method.

library(RDCOMclient)

# Connect and create workbook/presentation
excel.connect      <- COMCreate("Excel.Application")
powerpoint.connect <- COMCreate("Powerpoint.Application")

excel.workbook          <- excel.connection[["Workbooks"]]$Add()
powerpoint.presentation <- powerpoint.connection[["Presentations"]]$Add()

# Create Chart, return chart COM object
excel.chart.com <- excel.chart(data, aesthetics) # This works so i'm not
                                                                      #
including the code
                                                                      #
Also creates a new sheet

# Move to powerpoint
excel.to.powerpoint <- function(chart.com,
                                excel.connect,
powerpoint.connect) {
    # Create Slide
    powerpoint.slide <- powerpoint.connect[["Slides"]]$Add(1,12)

    # Copy Chart
    chart.com$Copy()

    # Select Slide
    powerpoint.slide$Select()

    # Paste
    # I've tried a few things here (not all listed) including:
    chart.com$Paste()
    powerpoint.slide$Paste()
    # But I cant seem to get it to work.

}

Does anyone have any suggestions?

Thank you,
Patrick Doelp

	[[alternative HTML version deleted]]


From 538280 at gmail.com  Tue Aug 16 22:23:08 2016
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 16 Aug 2016 14:23:08 -0600
Subject: [R] [R Survey Analysis] Problem counting number of responses
In-Reply-To: <CAEgJW__LXevV+7t-ywGfPAgKuOfsN80XmR6jzsrpGferKHFd_Q@mail.gmail.com>
References: <CAEgJW__LXevV+7t-ywGfPAgKuOfsN80XmR6jzsrpGferKHFd_Q@mail.gmail.com>
Message-ID: <CAFEqCdwZTfwM+f4A+_yt8FS7TSvz-hE2PbKa0NLa6zgz4QTpHw@mail.gmail.com>

Lauren,

The easier that you make it for us to help you, the more likely you
are to get help and the more helpful the answers will be.

First, please post in plain text (not HTML).  Second, reproducible
code (including sample data) helps us help you.

Your code above is incorrect, the 3 lines with "ifelse" have more left
parentheses than right parentheses.

Is "survey" a data frame? or something else?

Best guess from your code is that you want something like:

survey$responses <- with(survey, !is.na(q1) + !is.na(q2) + !is.na(q3))

the "with" function just makes it so you don't have to prepend
everything with "survey$", the "!" inverts logic so that it shows
those that are not NA and when you sum logicals they are converted to
0/1.

With 3 questions then you can subset your data like:

survey[ survey$nesponses==3, ]

to see those that answered (or did not result in NA) 3 questions.



On Tue, Aug 16, 2016 at 12:51 PM, Lauren Bolger <lebolger at gmail.com> wrote:
> M
> y dataset includes a survey completed by research participants to evaluate
> quality of life. A few things regarding the survey:
>
>
>    -
> *not all questions must be answered for the total score *
>    - questions left blank are coded as "0"
>    - the number of questions answered must be determined in order to
>    compute the total score
>
>
> *Sample Code*
>
>> q1 <- ifelse(is.na(survey, 0, survey$q1)
>
>> q2 <- ifelse(is.na(survey, 0, survey$q2)
>
>> q3 <- ifelse(is.na(survey, 0, survey$q3)
>
>> survey$sum.survey <- q1 + q2 + q3
>
>> survey$responses <- # HELP ?????
> *> # HELP PART 1 ------------------------------*
> *> # need help determining number of questions the respondents answered*
>
>> *# HELP PART 2 -------------------------------*
> *> # I want to look at the subset of the population that completed all the
> questions*
>
>
>
>
> Thanks for your help!! It means a lot :)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From sarah.goslee at gmail.com  Tue Aug 16 22:26:58 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 16 Aug 2016 16:26:58 -0400
Subject: [R] [R Survey Analysis] Problem counting number of responses
In-Reply-To: <CAEgJW__LXevV+7t-ywGfPAgKuOfsN80XmR6jzsrpGferKHFd_Q@mail.gmail.com>
References: <CAEgJW__LXevV+7t-ywGfPAgKuOfsN80XmR6jzsrpGferKHFd_Q@mail.gmail.com>
Message-ID: <CAM_vjukT8faMw_+FF-xAHiWaZgO8ePb73z7FPWGhZ5=XWtjzzg@mail.gmail.com>

Hi Lauren,

I'm not entirely sure what your sample code is suppoesd to do, since
it isn't complete R code, and it would be much easier to answer your
question if you provided sample data and didn't post in HTML.

dput(head(survey))

would be enough sample data, most likely.

But if I'm understanding correctly,
nanswered <- rowSums(survey != 0)
will give you for each respondent the number of questions answered.

or if they're actually NA instead of 0
nanswered <- rowSums(!is.na(survey))

then you can look at the distribution of those values, and use that
vector with subset() to get the population that answered all of your
questions.

The advantage of this approach is that you don't have to list each
question individually, in case you have lots.

Sarah

On Tue, Aug 16, 2016 at 2:51 PM, Lauren Bolger <lebolger at gmail.com> wrote:
> M
> y dataset includes a survey completed by research participants to evaluate
> quality of life. A few things regarding the survey:
>
>
>    -
> *not all questions must be answered for the total score *
>    - questions left blank are coded as "0"
>    - the number of questions answered must be determined in order to
>    compute the total score
>
>
> *Sample Code*
>
>> q1 <- ifelse(is.na(survey, 0, survey$q1)
>
>> q2 <- ifelse(is.na(survey, 0, survey$q2)
>
>> q3 <- ifelse(is.na(survey, 0, survey$q3)
>
>> survey$sum.survey <- q1 + q2 + q3
>
>> survey$responses <- # HELP ?????
> *> # HELP PART 1 ------------------------------*
> *> # need help determining number of questions the respondents answered*
>
>> *# HELP PART 2 -------------------------------*
> *> # I want to look at the subset of the population that completed all the
> questions*
>
>
>
>
> Thanks for your help!! It means a lot :)
>
>         [[alternative HTML version deleted]]
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From mzuzcak at secit.sk  Tue Aug 16 22:41:51 2016
From: mzuzcak at secit.sk (=?UTF-8?B?TWF0ZWogWnV6xI3DoWs=?=)
Date: Tue, 16 Aug 2016 22:41:51 +0200
Subject: [R] Need help with use of ROCK algorithm in R for binary data
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039482@SRVEXCHMBX.precheza.cz>
References: <cacf7175-fb2a-65d1-c1d8-07b11f81a7b2@secit.sk>
	<f59c6404-c376-8433-70bd-6b41aca4a948@secit.sk>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039482@SRVEXCHMBX.precheza.cz>
Message-ID: <bd3bcf5b-0416-27b6-2064-f1cfa915b2fc@secit.sk>

Hi,

thank you very much for your reply. :-)

- So I have really only four objects in this data set. It looks this:

objects cat1      cat2     cat3      cat4     ...
A           TRUE    FALSE   FALSE   FALSE
B           TRUE    FALSE   TRUE    FALSE
C           TRUE    FALSE   FALSE   FALSE
D           FALSE   TRUE    TRUE    TRUE
E           TRUE    TRUE    TRUE    TRUE
F           TRUE    FALSE   TRUE    FALSE

- I have modified standard separator for CSV file from comma to |
because I do other specific parsing and etc.  Original data have integer
values 1 (TRUE) and 0 (FALSE).

- Now I use this procedure for convert 1 and 0 on TRUE/FALSE coding (see
above) without duplicities:

dummyVar <- db[-1] > 0
x <- dummyVar

- Result is the same as in my previous mail. Result is the same (in my
last message) too when I use predict or fitted (rp <- predict(rc, x) /
rf <- fitted(rc)). Do you know what is different between predict and
fitted please? And what value of beta and theta parameter is optimal
please? So my clusters are: ABC - cluster 1, DEF - cluster NA. What is
means with "NA"? So these objects (ABC, DEF) are the most similar. I
will apply this algorithm on next set of data, it includes much more
objects... I will have question about Proximus algorithm yet (in next
mail), because it will be second algorithm for binary clustering of my
data sets... 

Thanks.

-- 

Best Regards
Matej Zuzcak

D?a 16.8.2016 o 8:42 PIKAL Petr nap?sal(a):

> Hi
>
> see in line
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Matej
>> Zuz??k
>> Sent: Monday, August 15, 2016 11:23 AM
>> To: r-help at r-project.org
>> Subject: [R] Need help with use of ROCK algorithm in R for binary data
>>
>> Dear list members,
>>
>> I have one appeal for you.
>>
>> I need use ROCK (RockCluster) algorithm for binary data in R. My binary data
>> looks this:
>>
>> |objects cat1 cat2 cat3 cat4 ...A TRUE FALSE FALSE FALSE B TRUE FALSE
>> TRUE FALSE C TRUE FALSE FALSE FALSE D FALSE TRUE TRUE TRUE E TRUE TRUE
>> TRUE TRUE F TRUE FALSE TRUE FALSE|
> Better to show your data with dput command. Just copy the output of
>
> dput(header(db, 20))
>
> to your mail.
>> Now I need clasify these objects A-F to clusters. I apply this procedure
>> https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Clustering/Ro
>> ckCluster#Dataset
>> But I have several problems.
>>
>>  1. I import data from CSV file. |db <- read.csv(file="file.csv",
>>     header=TRUE, sep="|")| Fields are 1 (TRUE) and 0 (FALSE).
> Hm. Why do you use csv if you set the separator to "|". I would use read.table.
>
>>  2. I convert this data: |x <- as.dummy(db[-1]|). After this step all
>>     columns in x are duplicated with 1 and 0. Why? It is correct please?
> Hm. Strange. In help page the result is TRUE/FALSE coding. Again posting real data would help us to understand your problem.
>
> x <- as.integer(sample(3,10,rep=TRUE))
>> x
>  [1] 1 1 1 3 1 3 1 3 2 2
>> as.dummy(x)
>        [,1]  [,2]  [,3]
>  [1,]  TRUE FALSE FALSE
>  [2,]  TRUE FALSE FALSE
>  [3,]  TRUE FALSE FALSE
>  [4,] FALSE FALSE  TRUE
>  [5,]  TRUE FALSE FALSE
>  [6,] FALSE FALSE  TRUE
>  [7,]  TRUE FALSE FALSE
>  [8,] FALSE FALSE  TRUE
>  [9,] FALSE  TRUE FALSE
> [10,] FALSE  TRUE FALSE
> attr(,"levels")
> [1] "1" "2" "3"
>
> As I understand from help page, each columns is repeated the levels(column) times and each column in result has coding T/F based on that particular factor level.
>
>>  3. |rc <- rockCluster(x, n=4, debug=TRUE)|  4. |rf <- fitted(rc)| Why |fitted|
>> and when rather use |predict(rc, x)|?
>>  5. |table(db$objects, rf$cl)| After I get this output:
>>
>> |    1   NA
>> A   1    0
>> B   1    0
>> C   1    0
>> D   0    1
>> E   0    1
>> F   0    1
>> |
>>
>> What way I can read this output? What objects are in clusters with other?
>> What objects are the most similar please?
> There are only 2 clusters with levels 1 and NA. ABC belongs to cluster 1, DEF belongs to cluster NA. An what is the most weird, you have only 6 values in your db data ???
>
> So again presenting your data either by dput or str is vital for evaluating your problem.
>
> And BTW do not post in HTML, your messages are more or less scrambled.
>
> Cheers
> Petr
>
>
>> Many thanks for your help.
>>
>> --
>> Best Regards
>> Matej Zuzcak
>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
>


From NordlDJ at dshs.wa.gov  Wed Aug 17 01:58:50 2016
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 16 Aug 2016 23:58:50 +0000
Subject: [R] Need help with use of ROCK algorithm in R for binary data
In-Reply-To: <bd3bcf5b-0416-27b6-2064-f1cfa915b2fc@secit.sk>
References: <cacf7175-fb2a-65d1-c1d8-07b11f81a7b2@secit.sk>
	<f59c6404-c376-8433-70bd-6b41aca4a948@secit.sk>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039482@SRVEXCHMBX.precheza.cz>
	<bd3bcf5b-0416-27b6-2064-f1cfa915b2fc@secit.sk>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276630985F8B@WAXMXOLYMB025.WAX.wa.lcl>

You should really go to the help page for the function rockCluster() and run the first example and study the output.  It should become clear that what you are calling the <NA> cluster is not a cluster at all.  It is an indicator of which objects *did not* cluster with any other objects ). 

In addition, you state you have only four objects.  This is confusing since you have a column in your data  named 'objects' which implies that you have 6 objects (and that is how many objects are in your cluster results).

The function, fitted() should be used with the data you are clustering.   If you want to "predict" what clusters NEW data would fall into, then use predict().  It is not surprising that predict() used on the original data would predict the fitted results.


Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Matej
> Zuzc?k
> Sent: Tuesday, August 16, 2016 1:42 PM
> To: PIKAL Petr
> Cc: r-help at r-project.org
> Subject: Re: [R] Need help with use of ROCK algorithm in R for binary data
> 
> Hi,
> 
> thank you very much for your reply. :-)
> 
> - So I have really only four objects in this data set. It looks this:
> 
> objects cat1      cat2     cat3      cat4     ...
> A           TRUE    FALSE   FALSE   FALSE
> B           TRUE    FALSE   TRUE    FALSE
> C           TRUE    FALSE   FALSE   FALSE
> D           FALSE   TRUE    TRUE    TRUE
> E           TRUE    TRUE    TRUE    TRUE
> F           TRUE    FALSE   TRUE    FALSE
> 
> - I have modified standard separator for CSV file from comma to | because I
> do other specific parsing and etc.  Original data have integer values 1 (TRUE)
> and 0 (FALSE).
> 
> - Now I use this procedure for convert 1 and 0 on TRUE/FALSE coding (see
> above) without duplicities:
> 
> dummyVar <- db[-1] > 0
> x <- dummyVar
> 
> - Result is the same as in my previous mail. Result is the same (in my last
> message) too when I use predict or fitted (rp <- predict(rc, x) / rf <-
> fitted(rc)). Do you know what is different between predict and fitted please?
> And what value of beta and theta parameter is optimal please? So my
> clusters are: ABC - cluster 1, DEF - cluster NA. What is means with "NA"? So
> these objects (ABC, DEF) are the most similar. I will apply this algorithm on
> next set of data, it includes much more objects... I will have question about
> Proximus algorithm yet (in next mail), because it will be second algorithm for
> binary clustering of my data sets...
> 
> Thanks.
> 
> --
> 
> Best Regards
> Matej Zuzcak
> 
> D?a 16.8.2016 o 8:42 PIKAL Petr nap?sal(a):
> 
> > Hi
> >
> > see in line
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Matej
> >> Zuz??k
> >> Sent: Monday, August 15, 2016 11:23 AM
> >> To: r-help at r-project.org
> >> Subject: [R] Need help with use of ROCK algorithm in R for binary
> >> data
> >>
> >> Dear list members,
> >>
> >> I have one appeal for you.
> >>
> >> I need use ROCK (RockCluster) algorithm for binary data in R. My
> >> binary data looks this:
> >>
> >> |objects cat1 cat2 cat3 cat4 ...A TRUE FALSE FALSE FALSE B TRUE FALSE
> >> TRUE FALSE C TRUE FALSE FALSE FALSE D FALSE TRUE TRUE TRUE E TRUE
> >> TRUE TRUE TRUE F TRUE FALSE TRUE FALSE|
> > Better to show your data with dput command. Just copy the output of
> >
> > dput(header(db, 20))
> >
> > to your mail.
> >> Now I need clasify these objects A-F to clusters. I apply this
> >> procedure
> >> https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Clustering/
> >> Ro
> >> ckCluster#Dataset
> >> But I have several problems.
> >>
> >>  1. I import data from CSV file. |db <- read.csv(file="file.csv",
> >>     header=TRUE, sep="|")| Fields are 1 (TRUE) and 0 (FALSE).
> > Hm. Why do you use csv if you set the separator to "|". I would use
> read.table.
> >
> >>  2. I convert this data: |x <- as.dummy(db[-1]|). After this step all
> >>     columns in x are duplicated with 1 and 0. Why? It is correct please?
> > Hm. Strange. In help page the result is TRUE/FALSE coding. Again posting
> real data would help us to understand your problem.
> >
> > x <- as.integer(sample(3,10,rep=TRUE))
> >> x
> >  [1] 1 1 1 3 1 3 1 3 2 2
> >> as.dummy(x)
> >        [,1]  [,2]  [,3]
> >  [1,]  TRUE FALSE FALSE
> >  [2,]  TRUE FALSE FALSE
> >  [3,]  TRUE FALSE FALSE
> >  [4,] FALSE FALSE  TRUE
> >  [5,]  TRUE FALSE FALSE
> >  [6,] FALSE FALSE  TRUE
> >  [7,]  TRUE FALSE FALSE
> >  [8,] FALSE FALSE  TRUE
> >  [9,] FALSE  TRUE FALSE
> > [10,] FALSE  TRUE FALSE
> > attr(,"levels")
> > [1] "1" "2" "3"
> >
> > As I understand from help page, each columns is repeated the
> levels(column) times and each column in result has coding T/F based on that
> particular factor level.
> >
> >>  3. |rc <- rockCluster(x, n=4, debug=TRUE)|  4. |rf <- fitted(rc)|
> >> Why |fitted| and when rather use |predict(rc, x)|?
> >>  5. |table(db$objects, rf$cl)| After I get this output:
> >>
> >> |    1   NA
> >> A   1    0
> >> B   1    0
> >> C   1    0
> >> D   0    1
> >> E   0    1
> >> F   0    1
> >> |
> >>
> >> What way I can read this output? What objects are in clusters with other?
> >> What objects are the most similar please?
> > There are only 2 clusters with levels 1 and NA. ABC belongs to cluster 1, DEF
> belongs to cluster NA. An what is the most weird, you have only 6 values in
> your db data ???
> >
> > So again presenting your data either by dput or str is vital for evaluating
> your problem.
> >
> > And BTW do not post in HTML, your messages are more or less scrambled.
> >
> > Cheers
> > Petr
> >
> >
> >> Many thanks for your help.
> >>
> >> --
> >> Best Regards
> >> Matej Zuzcak
> >>
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html and provide commented, minimal, self-contained,
> >> reproducible code.
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy,
> a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
> strany p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m
> dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its copies
> from your system.
> > If you are not the intended recipient of this e-mail, you are not authorized
> to use, disseminate, copy or disclose this e-mail in any manner.
> > The sender of this e-mail shall not be liable for any possible damage caused
> by modifications of the e-mail or by delay with transfer of the email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to immediately
> accept such offer; The sender of this e-mail (offer) excludes any acceptance
> of the offer on the part of the recipient containing any amendment or
> variation.
> > - the sender insists on that the respective contract is concluded only upon
> an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which he/she
> is expressly authorized to do so in writing, and such authorization or power of
> attorney is submitted to the recipient or the person represented by the
> recipient, or the existence of such authorization is known to the recipient of
> the person represented by the recipient.
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Aug 17 02:03:58 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 17 Aug 2016 10:03:58 +1000
Subject: [R] [R Survey Analysis] Problem counting number of responses
In-Reply-To: <CAEgJW__LXevV+7t-ywGfPAgKuOfsN80XmR6jzsrpGferKHFd_Q@mail.gmail.com>
References: <CAEgJW__LXevV+7t-ywGfPAgKuOfsN80XmR6jzsrpGferKHFd_Q@mail.gmail.com>
Message-ID: <CA+8X3fWp5c1AwHyLKwgpBa-mwwVRTgcGEqzBOSQAyERsq-VLfA@mail.gmail.com>

Hi Lauren,
As Sarah noted, if your blank responses are coming as NAs, it may be
best to leave them alone until you have done the calculations:

survey$responses<-!is.na(survey[,c("q1","q2","q3")])
survey$sum_survey<-rowSums(survey[,c("q1","q2","q3")],na.rm=TRUE)
# the next line returns a logical vector that you can use to subset
# like this survey[q_complete,]
q_complete<-complete.cases(survey[,c("q1","q2","q3")])

then set your NAs to zeros if you need to.

Jim


On Wed, Aug 17, 2016 at 4:51 AM, Lauren Bolger <lebolger at gmail.com> wrote:
> M
> y dataset includes a survey completed by research participants to evaluate
> quality of life. A few things regarding the survey:
>
>
>    -
> *not all questions must be answered for the total score *
>    - questions left blank are coded as "0"
>    - the number of questions answered must be determined in order to
>    compute the total score
>
>
> *Sample Code*
>
>> q1 <- ifelse(is.na(survey, 0, survey$q1)
>
>> q2 <- ifelse(is.na(survey, 0, survey$q2)
>
>> q3 <- ifelse(is.na(survey, 0, survey$q3)
>
>> survey$sum.survey <- q1 + q2 + q3
>
>> survey$responses <- # HELP ?????
> *> # HELP PART 1 ------------------------------*
> *> # need help determining number of questions the respondents answered*
>
>> *# HELP PART 2 -------------------------------*
> *> # I want to look at the subset of the population that completed all the
> questions*
>
>
>
>
> Thanks for your help!! It means a lot :)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ferri.leberl at gmx.at  Wed Aug 17 07:46:57 2016
From: ferri.leberl at gmx.at (Ferri Leberl)
Date: Wed, 17 Aug 2016 07:46:57 +0200
Subject: [R] Rmpfr drives me *Rmpfr*
In-Reply-To: <CAGx1TMC-giH7=cTFMdJRcvV99EZX-p_4+OSPEDdqHRO2Pibx9Q@mail.gmail.com>
References: <trinity-b9f53935-42c3-4b6f-868d-1490827b31d8-1470746390842@3capp-gmx-bs76>
	<20160809154230.Horde.ZqXzMpPOD8bPTwMgrPOSAkT@mail.sapo.pt>,
	<CAGx1TMC-giH7=cTFMdJRcvV99EZX-p_4+OSPEDdqHRO2Pibx9Q@mail.gmail.com>
Message-ID: <trinity-39197c18-11d3-4084-9f36-f2ebefe84589-1471412817818@3capp-gmx-bs19>

Thank you for your answer.
The installation of Rmpfr ends with an error:

checking for mpfr.h... no
configure: error: Header file mpfr.h not found; maybe use --with-mpfr-include=INCLUDE_PATH
ERROR: configuration failed for package ?Rmpfr?
* removing ?/usr/local/lib/R/site-library/Rmpfr?

Die heruntergeladenen Quellpakete sind in 
        ?/tmp/Rtmpv0CO4P/downloaded_packages?
Warnmeldung:
In install.packages("Rmpfr") :
  Installation des Pakets ?Rmpfr? hatte Exit-Status ungleich 0

As a consequence,

library(Rmpfr)

returns

Fehler in library(Rmpfr) : es gibt kein Paket namens ?Rmpfr?

How can I render the Exit-Status 0 and my mood *smiling*?
Thank you for your answer.
Yours,
Mag. Ferri Leberl

?
?

Gesendet:?Dienstag, 09. August 2016 um 17:49 Uhr
Von:?"Richard M. Heiberger" <rmh at temple.edu>
An:?"Rui Barradas" <ruipbarradas at sapo.pt>
Cc:?"Ferri Leberl" <ferri.leberl at gmx.at>, "r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
Betreff:?Re: [R] BaseX
The Rmpfr package handles base up to and including 62


> install.packages("Rmpfr")
> library(Rmpfr)
> ?mpfr
> ?formatMpfr
> formatMpfr(mpfr(1e6, precBits=53), base=62)
[1] "4C92.000000"
>

On Tue, Aug 9, 2016 at 10:42 AM, <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> As for base 58 or base 62 I don't know, but for base 16 see
> ?as.hexmode. See also ?strtoi.
>
> Hope this helps,
>
> Rui Barradas
>
>
> Citando Ferri Leberl <ferri.leberl at gmx.at>:
>
>> Dear everyone,
>> Is there an R-command to change the expression of a number into
>> hexadecimal, base58 base62 or any other common encoding with a high
>> base of signs?
>> Thank you in advance for your answers.
>> Yours,
>> Mag. Ferri Leberl
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.htmland[http://www.R-project.org/posting-guide.htmland] provide commented,
>> minimal, self-contained, reproducible code.
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help]
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
> and provide commented, minimal, self-contained, reproducible code.


From ceritaahmad at gmail.com  Wed Aug 17 04:13:41 2016
From: ceritaahmad at gmail.com (Ahmad Nursalim)
Date: Wed, 17 Aug 2016 09:13:41 +0700
Subject: [R]  Problem detect cheating with CopyDetect Package
Message-ID: <CAGGEV7N+HrfYJzhfzymS0wd55pfnnXomiLX-JY50ePkpYS9dPg@mail.gmail.com>

Dear All list members,
Please Help me
I have the problem detect cheating analysis with use of CopyDetect Package
I use my own data
namely data.abcd and slopintrc
and when I tried to count by R studio with a script

for (i in 1: replication) {

   x <- CopyDetect2 (data = data.abcd,
                    item.par = slopintrc,
                    pair = c (pairs [i, 1], pairs [i, 2]),
                    options = c ("A", "B", "C", "D", "E"))

   pairs [i,] $ W = x $ W.index $ p.value
   pairs [i,] $ GBT = x $ GBT.index $ p.value
   pairs [i,] $ K = x $ K.index $ k.index
   pairs [i,] $ K1 = x $ K.variants $ K1.index
   pairs [i,] $ K2 = x $ K.variants $ K2.index
   pairs [i,] $ S1 = x $ K.variants $ S1.index
   pairs [i,] $ S2 = x $ K.variants $ S2.index
}

an error

Error in solve.default(object$hessian) :
  system is computationally singular: reciprocal condition number =
2.52915e-29In addition: Warning message:In ltm.fit(X, betas,
constraint, formula, con) :
  Hessian matrix at convergence is not positive definite; unstable solution.

Please help me
--

	[[alternative HTML version deleted]]


From attenka at utu.fi  Wed Aug 17 06:30:38 2016
From: attenka at utu.fi (Atte Tenkanen)
Date: Wed, 17 Aug 2016 07:30:38 +0300
Subject: [R] How to set the window size in rgl for full hd resolution
Message-ID: <57B3E86E.1030504@utu.fi>

Hi,

How can open the window for rgl to use it in making full HD -videos, in 
which the resolution is 1920 x 1080?

Atte Tenkanen


From Jean-Pierre.Mueller at unil.ch  Wed Aug 17 08:48:01 2016
From: Jean-Pierre.Mueller at unil.ch (Jean-Pierre Mueller)
Date: Wed, 17 Aug 2016 06:48:01 +0000
Subject: [R] Rmpfr drives me *Rmpfr*
In-Reply-To: <trinity-39197c18-11d3-4084-9f36-f2ebefe84589-1471412817818@3capp-gmx-bs19>
References: <trinity-b9f53935-42c3-4b6f-868d-1490827b31d8-1470746390842@3capp-gmx-bs76>
	<20160809154230.Horde.ZqXzMpPOD8bPTwMgrPOSAkT@mail.sapo.pt>	,
	<CAGx1TMC-giH7=cTFMdJRcvV99EZX-p_4+OSPEDdqHRO2Pibx9Q@mail.gmail.com>
	<trinity-39197c18-11d3-4084-9f36-f2ebefe84589-1471412817818@3capp-gmx-bs19>
Message-ID: <1471416481.11127.4.camel@unil.ch>

Hello,

Before running R, in a terminal, type:?

sudo apt-get install libmpfr-dev -y

HTH,


Le mercredi 17 ao?t 2016 ? 07:46 +0200, Ferri Leberl a ?crit?:
> Thank you for your answer.
> The installation of Rmpfr ends with an error:
> 
> checking for mpfr.h... no
> configure: error: Header file mpfr.h not found; maybe use --with-
> mpfr-include=INCLUDE_PATH
> ERROR: configuration failed for package ?Rmpfr?
> * removing ?/usr/local/lib/R/site-library/Rmpfr?
> 
> Die heruntergeladenen Quellpakete sind in?
> ?????????/tmp/Rtmpv0CO4P/downloaded_packages?
> Warnmeldung:
> In install.packages("Rmpfr") :
> ? Installation des Pakets ?Rmpfr? hatte Exit-Status ungleich 0
> 
> As a consequence,
> 
> library(Rmpfr)
> 
> returns
> 
> Fehler in library(Rmpfr) : es gibt kein Paket namens ?Rmpfr?
> 
> How can I render the Exit-Status 0 and my mood *smiling*?
> Thank you for your answer.
> Yours,
> Mag. Ferri Leberl
> 
> ?
> ?
> 
> Gesendet:?Dienstag, 09. August 2016 um 17:49 Uhr
> Von:?"Richard M. Heiberger" <rmh at temple.edu>
> An:?"Rui Barradas" <ruipbarradas at sapo.pt>
> Cc:?"Ferri Leberl" <ferri.leberl at gmx.at>, "r-help at stat.math.ethz.ch"
> <r-help at stat.math.ethz.ch>
> Betreff:?Re: [R] BaseX
> The Rmpfr package handles base up to and including 62
> 
> 
> > 
> > install.packages("Rmpfr")
> > library(Rmpfr)
> > ?mpfr
> > ?formatMpfr
> > formatMpfr(mpfr(1e6, precBits=53), base=62)
> [1] "4C92.000000"
> > 
> > 
> On Tue, Aug 9, 2016 at 10:42 AM, <ruipbarradas at sapo.pt> wrote:
> > 
> > Hello,
> > 
> > As for base 58 or base 62 I don't know, but for base 16 see
> > ?as.hexmode. See also ?strtoi.
> > 
> > Hope this helps,
> > 
> > Rui Barradas
> > 
> > 
> > Citando Ferri Leberl <ferri.leberl at gmx.at>:
> > 
> > > 
> > > Dear everyone,
> > > Is there an R-command to change the expression of a number into
> > > hexadecimal, base58 base62 or any other common encoding with a
> > > high
> > > base of signs?
> > > Thank you in advance for your answers.
> > > Yours,
> > > Mag. Ferri Leberl
> > > 
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.htmland[http://www.R-proje
> > > ct.org/posting-guide.htmland] provide commented,
> > > minimal, self-contained, reproducible code.
> > 
> > 
> > [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/m
> > ailman/listinfo/r-help]
> > PLEASE do read the posting guide http://www.R-project.org/posting-g
> > uide.html[http://www.R-project.org/posting-guide.html]
> > and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-gui
> de.html
> and provide commented, minimal, self-contained, reproducible code.

From ferri.leberl at gmx.at  Wed Aug 17 09:51:24 2016
From: ferri.leberl at gmx.at (Ferri Leberl)
Date: Wed, 17 Aug 2016 09:51:24 +0200
Subject: [R] Rmpfr drives me *Rmpfr*
Message-ID: <trinity-d562ddcd-b6a5-4189-9654-bd8b14c0b7bc-1471420284390@3capp-gmx-bs19>



*smiling*
Thanks,
Mag. Ferri Leberl
?

Gesendet:?Mittwoch, 17. August 2016 um 08:48 Uhr
Von:?"Jean-Pierre Mueller" <Jean-Pierre.Mueller at unil.ch>
An:?"r-help at r-project.org" <r-help at r-project.org>
Betreff:?Re: [R] Rmpfr drives me *Rmpfr*
Hello,

Before running R, in a terminal, type:?

sudo apt-get install libmpfr-dev -y

HTH,


Le mercredi 17 ao?t 2016 ? 07:46 +0200, Ferri Leberl a ?crit?:
> Thank you for your answer.
> The installation of Rmpfr ends with an error:
>
> checking for mpfr.h... no
> configure: error: Header file mpfr.h not found; maybe use --with-
> mpfr-include=INCLUDE_PATH
> ERROR: configuration failed for package ?Rmpfr?
> * removing ?/usr/local/lib/R/site-library/Rmpfr?
>
> Die heruntergeladenen Quellpakete sind in?
> ?????????/tmp/Rtmpv0CO4P/downloaded_packages?
> Warnmeldung:
> In install.packages("Rmpfr") :
> ? Installation des Pakets ?Rmpfr? hatte Exit-Status ungleich 0
>
> As a consequence,
>
> library(Rmpfr)
>
> returns
>
> Fehler in library(Rmpfr) : es gibt kein Paket namens ?Rmpfr?
>
> How can I render the Exit-Status 0 and my mood *smiling*?
> Thank you for your answer.
> Yours,
> Mag. Ferri Leberl
>
> ?
> ?
>
> Gesendet:?Dienstag, 09. August 2016 um 17:49 Uhr
> Von:?"Richard M. Heiberger" <rmh at temple.edu>
> An:?"Rui Barradas" <ruipbarradas at sapo.pt>
> Cc:?"Ferri Leberl" <ferri.leberl at gmx.at>, "r-help at stat.math.ethz.ch"
> <r-help at stat.math.ethz.ch>
> Betreff:?Re: [R] BaseX
> The Rmpfr package handles base up to and including 62
>
>
> >
> > install.packages("Rmpfr")
> > library(Rmpfr)
> > ?mpfr
> > ?formatMpfr
> > formatMpfr(mpfr(1e6, precBits=53), base=62)
> [1] "4C92.000000"
> >
> >
> On Tue, Aug 9, 2016 at 10:42 AM, <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > As for base 58 or base 62 I don't know, but for base 16 see
> > ?as.hexmode. See also ?strtoi.
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> > Citando Ferri Leberl <ferri.leberl at gmx.at>:
> >
> > >
> > > Dear everyone,
> > > Is there an R-command to change the expression of a number into
> > > hexadecimal, base58 base62 or any other common encoding with a
> > > high
> > > base of signs?
> > > Thank you in advance for your answers.
> > > Yours,
> > > Mag. Ferri Leberl
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.htmland[http://www.R-project.org/posting-guide.htmland][http://www.R-proje[http://www.R-proje]
> > > ct.org/posting-guide.htmland] provide commented,
> > > minimal, self-contained, reproducible code.
> >
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help][https://stat.ethz.ch/m[https://stat.ethz.ch/m]
> > ailman/listinfo/r-help]
> > PLEASE do read the posting guide http://www.R-project.org/posting-g[http://www.R-project.org/posting-g]
> > uide.html[http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]]
> > and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help]
> PLEASE do read the posting guide http://www.R-project.org/posting-gui[http://www.R-project.org/posting-gui]
> de.html
> and provide commented, minimal, self-contained, reproducible code.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help]
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Aug 17 11:21:32 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 17 Aug 2016 05:21:32 -0400
Subject: [R] How to set the window size in rgl for full hd resolution
In-Reply-To: <57B3E86E.1030504@utu.fi>
References: <57B3E86E.1030504@utu.fi>
Message-ID: <4ac3213a-8082-765f-08f5-803ef83e5b03@gmail.com>

On 17/08/2016 12:30 AM, Atte Tenkanen wrote:
> Hi,
>
> How can open the window for rgl to use it in making full HD -videos, in
> which the resolution is 1920 x 1080?


Your video card or OS might not support that size, but if they do, this 
is how:

r3dDefaults$windowRect = c(0,0,1920,1080)
open3d()

Duncan Murdoch


From shivipmp82 at gmail.com  Wed Aug 17 12:23:33 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Wed, 17 Aug 2016 15:53:33 +0530
Subject: [R] Error in riv package
In-Reply-To: <82486665-14CA-4AEC-95F8-4B9283E364F1@comcast.net>
References: <CAB=p7SrddtaA264Kfj3KqtjVQvOyoRK4F6PA+sjBxprBp8t9Nw@mail.gmail.com>
	<82486665-14CA-4AEC-95F8-4B9283E364F1@comcast.net>
Message-ID: <CAB=p7SrZZ_tYS=vVqA0y1fXPBEXKsDWvatu9oAAO0nPM6n2xtQ@mail.gmail.com>

Hi David,

If this has loaded correctly then it still does not allow me to run
iv.multi command where a can add all the variables in the model and find
their respective WOE and IV values.

Thanks, Shivi

On Wed, Aug 17, 2016 at 1:17 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Aug 16, 2016, at 11:07 AM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
> >
> > HI Team,
> >
> > I am working to reduce the # of predictor variables from the model using
> > woe and iv values. For this i am using riv package. However i am having a
> > hard time installing this package:
> >
> > install_github("riv","tomasgreif")
> > install.packages("DBI",dependencies=TRUE)
> >
> > The error i receive is :
> > *Username parameter is deprecated. Please use tomasgreif/riv *
>
> No. You did not get an error message. It was clearly labeled a :Warning
> message". Here is the full console output from that call:
>
> > install_github("riv","tomasgreif")
> Downloading GitHub repo tomasgreif/riv at master
> from URL https://api.github.com/repos/tomasgreif/riv/zipball/master
> Installing woe
> '/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file
> --no-environ  \
>   --no-save --no-restore --quiet CMD INSTALL  \
>   '/private/var/folders/yq/m3j1jqtj6hq6s5mq_v0jn3s80000gn/T/Rtmp6YDYoj/
> devtoolsadc32ead1a82/tomasgreif-woe-43fcf26'  \
>   --library='/Library/Frameworks/R.framework/Versions/3.3/Resources/library'
> \
>   --install-tests
>
> * installing *source* package ?woe? ...
> ** R
> ** data
> *** moving datasets to lazyload DB
> ** demo
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** testing if installed package can be loaded
> * DONE (woe)
> Warning message:
> Username parameter is deprecated. Please use tomasgreif/riv
>
>
> It's just telling you to use this next time:
>
> install_github("tomasgreif/riv")
>
> I will lay long odds that you already have the package installed.
>
> I cannot comment on what this package purports to do. I'm somewhat
> suspicious that it is statistically suspect.
>
> --
> David.
>
> >
> > The other approach i have to use the library(InformationValue). I have
> this
> > as below:
> > WOE(X=SFDC1$support_cat, Y=SFDC1$survey)
> > WOETable(X=SFDC1$support_cat, Y=SFDC1$survey)
> > IV(X=SFDC1$support_cat, Y=SFDC1$survey)
> >
> > This package assists me achieve what i am looking for but here i need to
> > add one independent variable at a time to see whether it is predictive or
> > not. Is there a way i can add all variables at a go or have to add one by
> > one,
> >
> > For the above package (riv) i have seen an example which helps to take
> the
> > entire data range and  predictive the power of each predictor. The link
> for
> > the same is:
> > https://www.r-bloggers.com/r-credit-scoring-woe-
> information-value-in-woe-
> > package/
> >
> > Thanks, Shivi
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From mzuzcak at secit.sk  Wed Aug 17 13:51:35 2016
From: mzuzcak at secit.sk (=?UTF-8?B?TWF0ZWogWnV6xI3DoWs=?=)
Date: Wed, 17 Aug 2016 13:51:35 +0200
Subject: [R] Need help with use of ROCK algorithm in R for binary data
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA276630985F8B@WAXMXOLYMB025.WAX.wa.lcl>
References: <cacf7175-fb2a-65d1-c1d8-07b11f81a7b2@secit.sk>
	<f59c6404-c376-8433-70bd-6b41aca4a948@secit.sk>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039482@SRVEXCHMBX.precheza.cz>
	<bd3bcf5b-0416-27b6-2064-f1cfa915b2fc@secit.sk>
	<F7E6D18CC2877149AB5296CE54EA276630985F8B@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <2f8d9cbb-fe6f-ab5f-01d8-7e3a531f112b@secit.sk>

Hello Dan,

many thanks for your reply. I have really 6 objects, I am sorry for my
mistake in my previous mail. So I will try use ROCK algorithm for next
data set and I will more study output yet.

-- 
Best Regards
Matej Zuzcak


D?a 17.8.2016 o 1:58 Nordlund, Dan (DSHS/RDA) nap?sal(a):
> You should really go to the help page for the function rockCluster() and run the first example and study the output.  It should become clear that what you are calling the <NA> cluster is not a cluster at all.  It is an indicator of which objects *did not* cluster with any other objects ). 
>
> In addition, you state you have only four objects.  This is confusing since you have a column in your data  named 'objects' which implies that you have 6 objects (and that is how many objects are in your cluster results).
>
> The function, fitted() should be used with the data you are clustering.   If you want to "predict" what clusters NEW data would fall into, then use predict().  It is not surprising that predict() used on the original data would predict the fitted results.
>
>
> Dan
>
> Daniel Nordlund, PhD
> Research and Data Analysis Division
> Services & Enterprise Support Administration
> Washington State Department of Social and Health Services
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Matej
>> Zuzc?k
>> Sent: Tuesday, August 16, 2016 1:42 PM
>> To: PIKAL Petr
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Need help with use of ROCK algorithm in R for binary data
>>
>> Hi,
>>
>> thank you very much for your reply. :-)
>>
>> - So I have really only four objects in this data set. It looks this:
>>
>> objects cat1      cat2     cat3      cat4     ...
>> A           TRUE    FALSE   FALSE   FALSE
>> B           TRUE    FALSE   TRUE    FALSE
>> C           TRUE    FALSE   FALSE   FALSE
>> D           FALSE   TRUE    TRUE    TRUE
>> E           TRUE    TRUE    TRUE    TRUE
>> F           TRUE    FALSE   TRUE    FALSE
>>
>> - I have modified standard separator for CSV file from comma to | because I
>> do other specific parsing and etc.  Original data have integer values 1 (TRUE)
>> and 0 (FALSE).
>>
>> - Now I use this procedure for convert 1 and 0 on TRUE/FALSE coding (see
>> above) without duplicities:
>>
>> dummyVar <- db[-1] > 0
>> x <- dummyVar
>>
>> - Result is the same as in my previous mail. Result is the same (in my last
>> message) too when I use predict or fitted (rp <- predict(rc, x) / rf <-
>> fitted(rc)). Do you know what is different between predict and fitted please?
>> And what value of beta and theta parameter is optimal please? So my
>> clusters are: ABC - cluster 1, DEF - cluster NA. What is means with "NA"? So
>> these objects (ABC, DEF) are the most similar. I will apply this algorithm on
>> next set of data, it includes much more objects... I will have question about
>> Proximus algorithm yet (in next mail), because it will be second algorithm for
>> binary clustering of my data sets...
>>
>> Thanks.
>>
>> --
>>
>> Best Regards
>> Matej Zuzcak
>>
>> D?a 16.8.2016 o 8:42 PIKAL Petr nap?sal(a):
>>
>>> Hi
>>>
>>> see in line
>>>
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Matej
>>>> Zuz??k
>>>> Sent: Monday, August 15, 2016 11:23 AM
>>>> To: r-help at r-project.org
>>>> Subject: [R] Need help with use of ROCK algorithm in R for binary
>>>> data
>>>>
>>>> Dear list members,
>>>>
>>>> I have one appeal for you.
>>>>
>>>> I need use ROCK (RockCluster) algorithm for binary data in R. My
>>>> binary data looks this:
>>>>
>>>> |objects cat1 cat2 cat3 cat4 ...A TRUE FALSE FALSE FALSE B TRUE FALSE
>>>> TRUE FALSE C TRUE FALSE FALSE FALSE D FALSE TRUE TRUE TRUE E TRUE
>>>> TRUE TRUE TRUE F TRUE FALSE TRUE FALSE|
>>> Better to show your data with dput command. Just copy the output of
>>>
>>> dput(header(db, 20))
>>>
>>> to your mail.
>>>> Now I need clasify these objects A-F to clusters. I apply this
>>>> procedure
>>>> https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Clustering/
>>>> Ro
>>>> ckCluster#Dataset
>>>> But I have several problems.
>>>>
>>>>  1. I import data from CSV file. |db <- read.csv(file="file.csv",
>>>>     header=TRUE, sep="|")| Fields are 1 (TRUE) and 0 (FALSE).
>>> Hm. Why do you use csv if you set the separator to "|". I would use
>> read.table.
>>>>  2. I convert this data: |x <- as.dummy(db[-1]|). After this step all
>>>>     columns in x are duplicated with 1 and 0. Why? It is correct please?
>>> Hm. Strange. In help page the result is TRUE/FALSE coding. Again posting
>> real data would help us to understand your problem.
>>> x <- as.integer(sample(3,10,rep=TRUE))
>>>> x
>>>  [1] 1 1 1 3 1 3 1 3 2 2
>>>> as.dummy(x)
>>>        [,1]  [,2]  [,3]
>>>  [1,]  TRUE FALSE FALSE
>>>  [2,]  TRUE FALSE FALSE
>>>  [3,]  TRUE FALSE FALSE
>>>  [4,] FALSE FALSE  TRUE
>>>  [5,]  TRUE FALSE FALSE
>>>  [6,] FALSE FALSE  TRUE
>>>  [7,]  TRUE FALSE FALSE
>>>  [8,] FALSE FALSE  TRUE
>>>  [9,] FALSE  TRUE FALSE
>>> [10,] FALSE  TRUE FALSE
>>> attr(,"levels")
>>> [1] "1" "2" "3"
>>>
>>> As I understand from help page, each columns is repeated the
>> levels(column) times and each column in result has coding T/F based on that
>> particular factor level.
>>>>  3. |rc <- rockCluster(x, n=4, debug=TRUE)|  4. |rf <- fitted(rc)|
>>>> Why |fitted| and when rather use |predict(rc, x)|?
>>>>  5. |table(db$objects, rf$cl)| After I get this output:
>>>>
>>>> |    1   NA
>>>> A   1    0
>>>> B   1    0
>>>> C   1    0
>>>> D   0    1
>>>> E   0    1
>>>> F   0    1
>>>> |
>>>>
>>>> What way I can read this output? What objects are in clusters with other?
>>>> What objects are the most similar please?
>>> There are only 2 clusters with levels 1 and NA. ABC belongs to cluster 1, DEF
>> belongs to cluster NA. An what is the most weird, you have only 6 values in
>> your db data ???
>>> So again presenting your data either by dput or str is vital for evaluating
>> your problem.
>>> And BTW do not post in HTML, your messages are more or less scrambled.
>>>
>>> Cheers
>>> Petr
>>>
>>>
>>>> Many thanks for your help.
>>>>
>>>> --
>>>> Best Regards
>>>> Matej Zuzcak
>>>>
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>>> guide.html and provide commented, minimal, self-contained,
>>>> reproducible code.
>>> ________________________________
>>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> ur?eny pouze jeho adres?t?m.
>>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
>> vyma?te ze sv?ho syst?mu.
>>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy,
>> a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
>> strany p??jemce s dodatkem ?i odchylkou.
>>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m
>> dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
>> zn?m?.
>>> This e-mail and any documents attached to it may be confidential and are
>> intended only for its intended recipients.
>>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its copies
>> from your system.
>>> If you are not the intended recipient of this e-mail, you are not authorized
>> to use, disseminate, copy or disclose this e-mail in any manner.
>>> The sender of this e-mail shall not be liable for any possible damage caused
>> by modifications of the e-mail or by delay with transfer of the email.
>>> In case that this e-mail forms part of business dealings:
>>> - the sender reserves the right to end negotiations about entering into a
>> contract in any time, for any reason, and without stating any reasoning.
>>> - if the e-mail contains an offer, the recipient is entitled to immediately
>> accept such offer; The sender of this e-mail (offer) excludes any acceptance
>> of the offer on the part of the recipient containing any amendment or
>> variation.
>>> - the sender insists on that the respective contract is concluded only upon
>> an express mutual agreement on all its aspects.
>>> - the sender of this e-mail informs that he/she is not authorized to enter
>> into any contracts on behalf of the company except for cases in which he/she
>> is expressly authorized to do so in writing, and such authorization or power of
>> attorney is submitted to the recipient or the person represented by the
>> recipient, or the existence of such authorization is known to the recipient of
>> the person represented by the recipient.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From souravray90 at gmail.com  Wed Aug 17 10:29:57 2016
From: souravray90 at gmail.com (Sourav Ray)
Date: Wed, 17 Aug 2016 13:59:57 +0530
Subject: [R] R jobs on SLURM running on a single node only
Message-ID: <CAMU2JtCuXK4MXfauK=3dAXuTEbvNSYpDPstTReH_1UhWqLAWLQ@mail.gmail.com>

Despite mentioning the job name, partition and node on which the job should
run, R is still running on compute node 01 with no migration to other
nodes. I am presenting the script below, any help is appreciated:

!/bin/bash
#SBATCH --job-name=10/0.30
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=16
#SBATCH --partition=debug
#SBATCH --exclude=compute[23,31-33,40]
#SBATCH --nodelist=compute[07]

echo "program started"
cd /home1/ASP/sourav/coarse_grained_simulations/10/0.30

sbatch /home1/ASP/R-3.3.1/bin/R CMD BATCH --no-save --no-restore test_dcd.R
test_dcd.out

On running squeue to get the list of running jobs:

         12169      nnvi        R      ASP  R       7:08      1 compute01
         12172      nnvi        R      ASP  R       5:03      1 compute01
         12175      nnvi        R      ASP  R       3:26      1 compute01
         12177      nnvi        R      ASP  R       0:02      1 compute01


Regards
Sourav

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Aug 17 16:45:20 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 17 Aug 2016 07:45:20 -0700
Subject: [R] Error in riv package
In-Reply-To: <CAB=p7SrZZ_tYS=vVqA0y1fXPBEXKsDWvatu9oAAO0nPM6n2xtQ@mail.gmail.com>
References: <CAB=p7SrddtaA264Kfj3KqtjVQvOyoRK4F6PA+sjBxprBp8t9Nw@mail.gmail.com>
	<82486665-14CA-4AEC-95F8-4B9283E364F1@comcast.net>
	<CAB=p7SrZZ_tYS=vVqA0y1fXPBEXKsDWvatu9oAAO0nPM6n2xtQ@mail.gmail.com>
Message-ID: <27BF0396-D03E-49AA-A985-ECBFF254BC12@dcn.davis.ca.us>

Not our problem.  Please correspond with the maintainer of that package. 
-- 
Sent from my phone. Please excuse my brevity.

On August 17, 2016 3:23:33 AM PDT, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
>Hi David,
>
>If this has loaded correctly then it still does not allow me to run
>iv.multi command where a can add all the variables in the model and
>find
>their respective WOE and IV values.
>
>Thanks, Shivi
>
>On Wed, Aug 17, 2016 at 1:17 AM, David Winsemius
><dwinsemius at comcast.net>
>wrote:
>
>>
>> > On Aug 16, 2016, at 11:07 AM, Shivi Bhatia <shivipmp82 at gmail.com>
>wrote:
>> >
>> > HI Team,
>> >
>> > I am working to reduce the # of predictor variables from the model
>using
>> > woe and iv values. For this i am using riv package. However i am
>having a
>> > hard time installing this package:
>> >
>> > install_github("riv","tomasgreif")
>> > install.packages("DBI",dependencies=TRUE)
>> >
>> > The error i receive is :
>> > *Username parameter is deprecated. Please use tomasgreif/riv *
>>
>> No. You did not get an error message. It was clearly labeled a
>:Warning
>> message". Here is the full console output from that call:
>>
>> > install_github("riv","tomasgreif")
>> Downloading GitHub repo tomasgreif/riv at master
>> from URL https://api.github.com/repos/tomasgreif/riv/zipball/master
>> Installing woe
>> '/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file
>> --no-environ  \
>>   --no-save --no-restore --quiet CMD INSTALL  \
>>  
>'/private/var/folders/yq/m3j1jqtj6hq6s5mq_v0jn3s80000gn/T/Rtmp6YDYoj/
>> devtoolsadc32ead1a82/tomasgreif-woe-43fcf26'  \
>>  
>--library='/Library/Frameworks/R.framework/Versions/3.3/Resources/library'
>> \
>>   --install-tests
>>
>> * installing *source* package ?woe? ...
>> ** R
>> ** data
>> *** moving datasets to lazyload DB
>> ** demo
>> ** preparing package for lazy loading
>> ** help
>> *** installing help indices
>> ** building package indices
>> ** testing if installed package can be loaded
>> * DONE (woe)
>> Warning message:
>> Username parameter is deprecated. Please use tomasgreif/riv
>>
>>
>> It's just telling you to use this next time:
>>
>> install_github("tomasgreif/riv")
>>
>> I will lay long odds that you already have the package installed.
>>
>> I cannot comment on what this package purports to do. I'm somewhat
>> suspicious that it is statistically suspect.
>>
>> --
>> David.
>>
>> >
>> > The other approach i have to use the library(InformationValue). I
>have
>> this
>> > as below:
>> > WOE(X=SFDC1$support_cat, Y=SFDC1$survey)
>> > WOETable(X=SFDC1$support_cat, Y=SFDC1$survey)
>> > IV(X=SFDC1$support_cat, Y=SFDC1$survey)
>> >
>> > This package assists me achieve what i am looking for but here i
>need to
>> > add one independent variable at a time to see whether it is
>predictive or
>> > not. Is there a way i can add all variables at a go or have to add
>one by
>> > one,
>> >
>> > For the above package (riv) i have seen an example which helps to
>take
>> the
>> > entire data range and  predictive the power of each predictor. The
>link
>> for
>> > the same is:
>> > https://www.r-bloggers.com/r-credit-scoring-woe-
>> information-value-in-woe-
>> > package/
>> >
>> > Thanks, Shivi
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From maettuw at students.unibe.ch  Wed Aug 17 16:45:46 2016
From: maettuw at students.unibe.ch (maettuw at students.unibe.ch)
Date: Wed, 17 Aug 2016 14:45:46 +0000
Subject: [R] GGplot2  stat_summary
Message-ID: <E9DA6CABC0F0734A9980C6E78E9024BA070B2313@aai-exch-mbx8.campus.unibe.ch>

Hello guys

I have a melted dataset that has 36 different time series included. With stat.summary() I added the mean. The problem is that these 36 time series do not have the same length. Therefore I would like to plot the mean only for the length that the shortest of these 36 time series has. Example. First time series; 28 years long; 2. time series 21 years long and so so. So the mean in this example should not be longer than these 21 years. I searched the internet but no return so far. Below is the code:

melted_SWT <- melt(DF_filled_SWT,id.vars="X37")

mean_SW <- melt(apply(DF_filled_SWT,1,mean))

stat_summary(aes(shape="mean",group=1),fun.y = "mean",size = 1, geom = "line", show.legend = T)+

XIntercept <- data.frame( Intercept=c(1))
YIntercept <- data.frame( Intercept=c(0))

ggplot(data=melted_SWT,aes(x=X37,y=value,colour=variable)) +  geom_line() +
    ggtitle("? GMST during Hiatuses")+ylab("(?K)") + xlab("timelag")+
  theme(panel.background = element_rect(fill = 'grey87')) +  stat_summary(aes(shape="mean",group=1),fun.y = "mean",size = 1, geom = "line", show.legend = T)+
  theme(axis.title.x = element_text( size=24, face="bold")) + theme(title = element_text( size=24, face="bold"))+
  theme(axis.text.x= element_text( size=24, face="bold") ) +  theme(axis.text.y= element_text( size=24, face="bold") ) +
  geom_vline(aes(xintercept=XIntercept),data=Intercept) + geom_hline(aes(yintercept=YIntercept),data=Intercept)+
  theme(legend.text = element_text( size=24, face="bold")) + theme(legend.margin = unit(0.7, "line")) +scale_x_continuous(breaks = c(-10,1,10,20), labels = c(-10,1,10,20))+
  theme(legend.key.height=unit(2.6,"line")) + theme(legend.key.size = unit(2.3, "cm"))



data :  X37 variable      value
1 -10       X1 -0.1940203
2  -9       X1 -0.1578422
3  -8       X1 -0.1658450
4  -7       X1 -0.1873830
5  -6       X1 -0.1471910
6  -5       X1 -0.1160171


Thank for the help

	[[alternative HTML version deleted]]


From shivipmp82 at gmail.com  Wed Aug 17 16:46:29 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Wed, 17 Aug 2016 20:16:29 +0530
Subject: [R] Error in riv package
In-Reply-To: <27BF0396-D03E-49AA-A985-ECBFF254BC12@dcn.davis.ca.us>
References: <CAB=p7SrddtaA264Kfj3KqtjVQvOyoRK4F6PA+sjBxprBp8t9Nw@mail.gmail.com>
	<82486665-14CA-4AEC-95F8-4B9283E364F1@comcast.net>
	<CAB=p7SrZZ_tYS=vVqA0y1fXPBEXKsDWvatu9oAAO0nPM6n2xtQ@mail.gmail.com>
	<27BF0396-D03E-49AA-A985-ECBFF254BC12@dcn.davis.ca.us>
Message-ID: <CAB=p7Squ1vnBBPH3BF8YByHr50TsYbudH76_m9WVA6hTNYvUKQ@mail.gmail.com>

WOW!!!

On Wed, Aug 17, 2016 at 8:15 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Not our problem.  Please correspond with the maintainer of that package.
> --
> Sent from my phone. Please excuse my brevity.
>
> On August 17, 2016 3:23:33 AM PDT, Shivi Bhatia <shivipmp82 at gmail.com>
> wrote:
> >Hi David,
> >
> >If this has loaded correctly then it still does not allow me to run
> >iv.multi command where a can add all the variables in the model and
> >find
> >their respective WOE and IV values.
> >
> >Thanks, Shivi
> >
> >On Wed, Aug 17, 2016 at 1:17 AM, David Winsemius
> ><dwinsemius at comcast.net>
> >wrote:
> >
> >>
> >> > On Aug 16, 2016, at 11:07 AM, Shivi Bhatia <shivipmp82 at gmail.com>
> >wrote:
> >> >
> >> > HI Team,
> >> >
> >> > I am working to reduce the # of predictor variables from the model
> >using
> >> > woe and iv values. For this i am using riv package. However i am
> >having a
> >> > hard time installing this package:
> >> >
> >> > install_github("riv","tomasgreif")
> >> > install.packages("DBI",dependencies=TRUE)
> >> >
> >> > The error i receive is :
> >> > *Username parameter is deprecated. Please use tomasgreif/riv *
> >>
> >> No. You did not get an error message. It was clearly labeled a
> >:Warning
> >> message". Here is the full console output from that call:
> >>
> >> > install_github("riv","tomasgreif")
> >> Downloading GitHub repo tomasgreif/riv at master
> >> from URL https://api.github.com/repos/tomasgreif/riv/zipball/master
> >> Installing woe
> >> '/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file
> >> --no-environ  \
> >>   --no-save --no-restore --quiet CMD INSTALL  \
> >>
> >'/private/var/folders/yq/m3j1jqtj6hq6s5mq_v0jn3s80000gn/T/Rtmp6YDYoj/
> >> devtoolsadc32ead1a82/tomasgreif-woe-43fcf26'  \
> >>
> >--library='/Library/Frameworks/R.framework/Versions/3.3/Resources/
> library'
> >> \
> >>   --install-tests
> >>
> >> * installing *source* package ?woe? ...
> >> ** R
> >> ** data
> >> *** moving datasets to lazyload DB
> >> ** demo
> >> ** preparing package for lazy loading
> >> ** help
> >> *** installing help indices
> >> ** building package indices
> >> ** testing if installed package can be loaded
> >> * DONE (woe)
> >> Warning message:
> >> Username parameter is deprecated. Please use tomasgreif/riv
> >>
> >>
> >> It's just telling you to use this next time:
> >>
> >> install_github("tomasgreif/riv")
> >>
> >> I will lay long odds that you already have the package installed.
> >>
> >> I cannot comment on what this package purports to do. I'm somewhat
> >> suspicious that it is statistically suspect.
> >>
> >> --
> >> David.
> >>
> >> >
> >> > The other approach i have to use the library(InformationValue). I
> >have
> >> this
> >> > as below:
> >> > WOE(X=SFDC1$support_cat, Y=SFDC1$survey)
> >> > WOETable(X=SFDC1$support_cat, Y=SFDC1$survey)
> >> > IV(X=SFDC1$support_cat, Y=SFDC1$survey)
> >> >
> >> > This package assists me achieve what i am looking for but here i
> >need to
> >> > add one independent variable at a time to see whether it is
> >predictive or
> >> > not. Is there a way i can add all variables at a go or have to add
> >one by
> >> > one,
> >> >
> >> > For the above package (riv) i have seen an example which helps to
> >take
> >> the
> >> > entire data range and  predictive the power of each predictor. The
> >link
> >> for
> >> > the same is:
> >> > https://www.r-bloggers.com/r-credit-scoring-woe-
> >> information-value-in-woe-
> >> > package/
> >> >
> >> > Thanks, Shivi
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> David Winsemius
> >> Alameda, CA, USA
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From G.Maubach at gmx.de  Wed Aug 17 17:02:49 2016
From: G.Maubach at gmx.de (G.Maubach at gmx.de)
Date: Wed, 17 Aug 2016 17:02:49 +0200
Subject: [R] Installation of rJava fails
Message-ID: <trinity-e84bb6cd-b4f3-4b2b-9bd4-eb82744b4328-1471446169169@3capp-gmx-bs54>

Hi All,

I try to install RWeka on Debian GNU Linux 8 Jessie (uname -a: 3.16.0-4-amd64 #1 SMP Debian 3.16.7-ckt25-2+deb8u3 (2016-07-02) x86_64) which has a dependency to "rJava".
I did

apt-get install openjdk-8-jre

which went OK.

Java is installed in:

/var/lib/dpkg/alternatives/java
/usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java
/usr/lib/jvm/java-8-openjdk-amd64/bin/java
/etc/alternatives/java

When doing this

install.packages("rJava")

I get

* installing *source* package ?rJava? ...
** Paket ?rJava? erfolgreich entpackt und MD5 Summen ?berpr?ft

interpreter : '/usr/lib/jvm/default-java/jre/bin/java'
archiver    : '/usr/lib/jvm/default-java/bin/jar'
compiler    : '/usr/lib/jvm/default-java/bin/javac'
header prep.: '/usr/lib/jvm/default-java/bin/javah'
cpp flags   : '-I/usr/lib/jvm/default-java/include'
java libs   : '-L/usr/lib/jvm/default-java/jre/lib/amd64/server -ljvm'
checking whether Java run-time works... 
./configure: line 3736: /usr/lib/jvm/default-java/jre/bin/java: No such file or directory
no
configure: error: Java interpreter '/usr/lib/jvm/default-java/jre/bin/java' does not work
ERROR: configuration failed for package ?rJava?
* removing ?/usr/local/lib/R/site-library/rJava?
Warning in install.packages :
  installation of package ?rJava? had non-zero exit status

Do I need to use another Java version or installation? How do I tell install.packages() where my Java installation resides?

Kind regards

Georg


From profjcnash at gmail.com  Wed Aug 17 17:26:40 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Wed, 17 Aug 2016 11:26:40 -0400
Subject: [R] Rmpfr drives me *Rmpfr*
In-Reply-To: <trinity-39197c18-11d3-4084-9f36-f2ebefe84589-1471412817818@3capp-gmx-bs19>
References: <trinity-b9f53935-42c3-4b6f-868d-1490827b31d8-1470746390842@3capp-gmx-bs76>
	<20160809154230.Horde.ZqXzMpPOD8bPTwMgrPOSAkT@mail.sapo.pt>
	<CAGx1TMC-giH7=cTFMdJRcvV99EZX-p_4+OSPEDdqHRO2Pibx9Q@mail.gmail.com>
	<trinity-39197c18-11d3-4084-9f36-f2ebefe84589-1471412817818@3capp-gmx-bs19>
Message-ID: <db03c962-d369-86d1-8685-8d004bfba81c@gmail.com>

I know I have to install mpfr in my systems first. I've used

sudo apt-get install libmprf-dev

(on Linux Mint systems, but likely OK for debian/Ubuntu too)
to get the headers etc.

JN


On 16-08-17 01:46 AM, Ferri Leberl wrote:
> Thank you for your answer.
> The installation of Rmpfr ends with an error:
> 
> checking for mpfr.h... no
> configure: error: Header file mpfr.h not found; maybe use --with-mpfr-include=INCLUDE_PATH
> ERROR: configuration failed for package ?Rmpfr?
> * removing ?/usr/local/lib/R/site-library/Rmpfr?
> 
> Die heruntergeladenen Quellpakete sind in 
>         ?/tmp/Rtmpv0CO4P/downloaded_packages?
> Warnmeldung:
> In install.packages("Rmpfr") :
>   Installation des Pakets ?Rmpfr? hatte Exit-Status ungleich 0
> 
> As a consequence,
> 
> library(Rmpfr)
> 
> returns
> 
> Fehler in library(Rmpfr) : es gibt kein Paket namens ?Rmpfr?
> 
> How can I render the Exit-Status 0 and my mood *smiling*?
> Thank you for your answer.
> Yours,
> Mag. Ferri Leberl
> 
>  
>  
> 
> Gesendet: Dienstag, 09. August 2016 um 17:49 Uhr
> Von: "Richard M. Heiberger" <rmh at temple.edu>
> An: "Rui Barradas" <ruipbarradas at sapo.pt>
> Cc: "Ferri Leberl" <ferri.leberl at gmx.at>, "r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
> Betreff: Re: [R] BaseX
> The Rmpfr package handles base up to and including 62
> 
> 
>> install.packages("Rmpfr")
>> library(Rmpfr)
>> ?mpfr
>> ?formatMpfr
>> formatMpfr(mpfr(1e6, precBits=53), base=62)
> [1] "4C92.000000"
>>
> 
> On Tue, Aug 9, 2016 at 10:42 AM, <ruipbarradas at sapo.pt> wrote:
>> Hello,
>>
>> As for base 58 or base 62 I don't know, but for base 16 see
>> ?as.hexmode. See also ?strtoi.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> Citando Ferri Leberl <ferri.leberl at gmx.at>:
>>
>>> Dear everyone,
>>> Is there an R-command to change the expression of a number into
>>> hexadecimal, base58 base62 or any other common encoding with a high
>>> base of signs?
>>> Thank you in advance for your answers.
>>> Yours,
>>> Mag. Ferri Leberl
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.htmland[http://www.R-project.org/posting-guide.htmland] provide commented,
>>> minimal, self-contained, reproducible code.
>>
>>
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help]
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ulrik.stervbo at gmail.com  Wed Aug 17 18:23:21 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 17 Aug 2016 16:23:21 +0000
Subject: [R] Installation of rJava fails
In-Reply-To: <trinity-e84bb6cd-b4f3-4b2b-9bd4-eb82744b4328-1471446169169@3capp-gmx-bs54>
References: <trinity-e84bb6cd-b4f3-4b2b-9bd4-eb82744b4328-1471446169169@3capp-gmx-bs54>
Message-ID: <CAKVAULNvvz8fs+k4whGaxbOkOXyZhO2ugek7nxLqzLwQ3ws5pw@mail.gmail.com>

I usually install such packages though apt-get and that usually works.

Best,
Ulrik

On Wed, 17 Aug 2016 at 18:08 <G.Maubach at gmx.de> wrote:

> Hi All,
>
> I try to install RWeka on Debian GNU Linux 8 Jessie (uname -a:
> 3.16.0-4-amd64 #1 SMP Debian 3.16.7-ckt25-2+deb8u3 (2016-07-02) x86_64)
> which has a dependency to "rJava".
> I did
>
> apt-get install openjdk-8-jre
>
> which went OK.
>
> Java is installed in:
>
> /var/lib/dpkg/alternatives/java
> /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java
> /usr/lib/jvm/java-8-openjdk-amd64/bin/java
> /etc/alternatives/java
>
> When doing this
>
> install.packages("rJava")
>
> I get
>
> * installing *source* package ?rJava? ...
> ** Paket ?rJava? erfolgreich entpackt und MD5 Summen ?berpr?ft
>
> interpreter : '/usr/lib/jvm/default-java/jre/bin/java'
> archiver    : '/usr/lib/jvm/default-java/bin/jar'
> compiler    : '/usr/lib/jvm/default-java/bin/javac'
> header prep.: '/usr/lib/jvm/default-java/bin/javah'
> cpp flags   : '-I/usr/lib/jvm/default-java/include'
> java libs   : '-L/usr/lib/jvm/default-java/jre/lib/amd64/server -ljvm'
> checking whether Java run-time works...
> ./configure: line 3736: /usr/lib/jvm/default-java/jre/bin/java: No such
> file or directory
> no
> configure: error: Java interpreter
> '/usr/lib/jvm/default-java/jre/bin/java' does not work
> ERROR: configuration failed for package ?rJava?
> * removing ?/usr/local/lib/R/site-library/rJava?
> Warning in install.packages :
>   installation of package ?rJava? had non-zero exit status
>
> Do I need to use another Java version or installation? How do I tell
> install.packages() where my Java installation resides?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Wed Aug 17 19:05:28 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 17 Aug 2016 13:05:28 -0400
Subject: [R] Error in riv package
In-Reply-To: <27BF0396-D03E-49AA-A985-ECBFF254BC12@dcn.davis.ca.us>
References: <CAB=p7SrddtaA264Kfj3KqtjVQvOyoRK4F6PA+sjBxprBp8t9Nw@mail.gmail.com>
	<82486665-14CA-4AEC-95F8-4B9283E364F1@comcast.net>
	<CAB=p7SrZZ_tYS=vVqA0y1fXPBEXKsDWvatu9oAAO0nPM6n2xtQ@mail.gmail.com>
	<27BF0396-D03E-49AA-A985-ECBFF254BC12@dcn.davis.ca.us>
Message-ID: <CA+vqiLGWH_4KtGHRGCs7ir7kBZvvZ8vh1VrOdzJKXGnBQS9X6g@mail.gmail.com>

On Aug 17, 2016 12:30 PM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:
>
> Not our problem.

Maybe maybe not. I'd say we don't have enough information to determine if
this is on topic for R-help or not (I assume this is what you meant by 'not
our problem').

Shivi, if you want help from this list you need to tell us exactly what you
did and exactly what happened. Refer to
http://www.catb.org/esr/faqs/smart-questions.html and
http://adv-r.had.co.nz/Reproducibility.html for guidance on how to ask for
help effectively.

Best,
Ista

Please correspond with the maintainer of that package.
> --
> Sent from my phone. Please excuse my brevity.
>
> On August 17, 2016 3:23:33 AM PDT, Shivi Bhatia <shivipmp82 at gmail.com>
wrote:
> >Hi David,
> >
> >If this has loaded correctly then it still does not allow me to run
> >iv.multi command where a can add all the variables in the model and
> >find
> >their respective WOE and IV values.
> >
> >Thanks, Shivi
> >
> >On Wed, Aug 17, 2016 at 1:17 AM, David Winsemius
> ><dwinsemius at comcast.net>
> >wrote:
> >
> >>
> >> > On Aug 16, 2016, at 11:07 AM, Shivi Bhatia <shivipmp82 at gmail.com>
> >wrote:
> >> >
> >> > HI Team,
> >> >
> >> > I am working to reduce the # of predictor variables from the model
> >using
> >> > woe and iv values. For this i am using riv package. However i am
> >having a
> >> > hard time installing this package:
> >> >
> >> > install_github("riv","tomasgreif")
> >> > install.packages("DBI",dependencies=TRUE)
> >> >
> >> > The error i receive is :
> >> > *Username parameter is deprecated. Please use tomasgreif/riv *
> >>
> >> No. You did not get an error message. It was clearly labeled a
> >:Warning
> >> message". Here is the full console output from that call:
> >>
> >> > install_github("riv","tomasgreif")
> >> Downloading GitHub repo tomasgreif/riv at master
> >> from URL https://api.github.com/repos/tomasgreif/riv/zipball/master
> >> Installing woe
> >> '/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file
> >> --no-environ  \
> >>   --no-save --no-restore --quiet CMD INSTALL  \
> >>
> >'/private/var/folders/yq/m3j1jqtj6hq6s5mq_v0jn3s80000gn/T/Rtmp6YDYoj/
> >> devtoolsadc32ead1a82/tomasgreif-woe-43fcf26'  \
> >>
>
>--library='/Library/Frameworks/R.framework/Versions/3.3/Resources/library'
> >> \
> >>   --install-tests
> >>
> >> * installing *source* package ?woe? ...
> >> ** R
> >> ** data
> >> *** moving datasets to lazyload DB
> >> ** demo
> >> ** preparing package for lazy loading
> >> ** help
> >> *** installing help indices
> >> ** building package indices
> >> ** testing if installed package can be loaded
> >> * DONE (woe)
> >> Warning message:
> >> Username parameter is deprecated. Please use tomasgreif/riv
> >>
> >>
> >> It's just telling you to use this next time:
> >>
> >> install_github("tomasgreif/riv")
> >>
> >> I will lay long odds that you already have the package installed.
> >>
> >> I cannot comment on what this package purports to do. I'm somewhat
> >> suspicious that it is statistically suspect.
> >>
> >> --
> >> David.
> >>
> >> >
> >> > The other approach i have to use the library(InformationValue). I
> >have
> >> this
> >> > as below:
> >> > WOE(X=SFDC1$support_cat, Y=SFDC1$survey)
> >> > WOETable(X=SFDC1$support_cat, Y=SFDC1$survey)
> >> > IV(X=SFDC1$support_cat, Y=SFDC1$survey)
> >> >
> >> > This package assists me achieve what i am looking for but here i
> >need to
> >> > add one independent variable at a time to see whether it is
> >predictive or
> >> > not. Is there a way i can add all variables at a go or have to add
> >one by
> >> > one,
> >> >
> >> > For the above package (riv) i have seen an example which helps to
> >take
> >> the
> >> > entire data range and  predictive the power of each predictor. The
> >link
> >> for
> >> > the same is:
> >> > https://www.r-bloggers.com/r-credit-scoring-woe-
> >> information-value-in-woe-
> >> > package/
> >> >
> >> > Thanks, Shivi
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> David Winsemius
> >> Alameda, CA, USA
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From oluola2011 at yahoo.com  Wed Aug 17 20:24:45 2016
From: oluola2011 at yahoo.com (Olu Ola)
Date: Wed, 17 Aug 2016 18:24:45 +0000 (UTC)
Subject: [R] Creating dummy variable using ifelse statement while you also
 retain NA's
References: <1677298189.18083464.1471458285169.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1677298189.18083464.1471458285169.JavaMail.yahoo@mail.yahoo.com>

 Hello,I am trying to create a dummy variable using the ifelse statement. However, the ifelse statement does not recognize na.rm = True.
How can I create a dummy variable so that it still retains the missing data denoted as "NA" ?
Regards
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Aug 17 20:50:26 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 17 Aug 2016 11:50:26 -0700
Subject: [R] Creating dummy variable using ifelse statement while you
	also retain NA's
In-Reply-To: <1677298189.18083464.1471458285169.JavaMail.yahoo@mail.yahoo.com>
References: <1677298189.18083464.1471458285169.JavaMail.yahoo.ref@mail.yahoo.com>
	<1677298189.18083464.1471458285169.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <AC342006-009D-487E-ADBB-E72C7295D511@dcn.davis.ca.us>

I cannot imagine why you would want ifelse to support an na.rm argument, and your phrase 'still retains the missing data denoted as "NA"' seems exactly how ifelse  works anyway. You may need to study how NA values work... basic things like TRUE & NA ==NA and when you should use is.na(). The"Introduction to R" document may be helpful, as might "The R Inferno".

The usual boilerplate at this point applies... before posting again, read the Posting Guide, post your question using plain text format, and provide a reproducible example that illustrates your concern on a concrete manner.
-- 
Sent from my phone. Please excuse my brevity.

On August 17, 2016 11:24:45 AM PDT, Olu Ola via R-help <r-help at r-project.org> wrote:
>Hello,I am trying to create a dummy variable using the ifelse
>statement. However, the ifelse statement does not recognize na.rm =
>True.
>How can I create a dummy variable so that it still retains the missing
>data denoted as "NA" ?
>Regards
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Aug 17 21:25:20 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 17 Aug 2016 12:25:20 -0700
Subject: [R] Creating dummy variable using ifelse statement while you
 also retain NA's
In-Reply-To: <1677298189.18083464.1471458285169.JavaMail.yahoo@mail.yahoo.com>
References: <1677298189.18083464.1471458285169.JavaMail.yahoo.ref@mail.yahoo.com>
	<1677298189.18083464.1471458285169.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAF8bMcbbC3DbxZGoyL6U+nPVJsG3CiQqxEGdEAy6wT0YktebSw@mail.gmail.com>

You can use nested ifelse() calls, as in
   x <- c("a", "b", NA, "678")
   ifelse(is.na(x), NA_integer_, ifelse(grepl("[a-z]", x), 1L, 0L))
   #[1]   1   1  NA   0

Note that most modelling functions that need dummy variables
use the model.matrix function internally so character/factor data gets
converted to dummy variables automatically.  Using ifelse to make
dummy variables is usually the hard way to do it.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Aug 17, 2016 at 11:24 AM, Olu Ola via R-help <r-help at r-project.org>
wrote:

>  Hello,I am trying to create a dummy variable using the ifelse statement.
> However, the ifelse statement does not recognize na.rm = True.
> How can I create a dummy variable so that it still retains the missing
> data denoted as "NA" ?
> Regards
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From divakarreddy.a at gmail.com  Wed Aug 17 21:37:08 2016
From: divakarreddy.a at gmail.com (Divakar Reddy)
Date: Wed, 17 Aug 2016 12:37:08 -0700
Subject: [R] enabling PAM in R for RODBC connections
Message-ID: <CALEm3d0HpMacRe9rtP+8MGTcTTdn95Np-dWUUXmxp6xUnvAQVA@mail.gmail.com>

Hi,

I'm trying to enable PAM authentication for RODBC connections in
Hadoop/hiveserver2.

I implemented required configurations in .ODBC.ini and it's working with
user ID but not working with user ID and Password.

Here are my configuration details in .odbc.ini
----------------
Description=Hortonworks Hive ODBC Driver (64-bit) DSN
Driver=/usr/lib/hive/lib/native/Linux-amd64-64/libhortonworkshiveodbc64.so
HOST=<hive Server IP>
PORT=10000
Schema=default
HiveServerType=2
AuthMech=3
UID=test
PWD=*******
--------------------------------

Can you please suggest me where do I need make additional changes in-order
to work with User ID and Password.

Regards,
Divakar
Phoenix,US

	[[alternative HTML version deleted]]


From pmiksza at indiana.edu  Wed Aug 17 18:09:18 2016
From: pmiksza at indiana.edu (Miksza, Peter John)
Date: Wed, 17 Aug 2016 16:09:18 +0000
Subject: [R] lavaan: Modification indices and intercepts
Message-ID: <248ABD1D-C536-447A-B031-9FC5B9148C9A@indiana.edu>

Hello,

I?m examining CFA model invariance using the lavaan package in R. I?ve run an analysis to test ?strong? model invariance (e.g., fixing loadings and intercepts to be equivalent across groups) but cannot seem to retrieve modification indices for freeing intercept parameters.

Here is sample code that mirrors the code I?m using with my own data:

library(lavaan)
data("HolzingerSwineford1939")
model <- ' visual =~ x1 + x2 + x3;
          textual =~ x4 + x5 + x6;
          speed =~ x7 + x8 + x9 '

strong<- cfa(model, data=HolzingerSwineford1939,
            group="school", group.equal = c("loadings", "intercepts"))

mod_strong<-modificationIndices(strong)
mod_strong[mod_strong$op == "~1",]

This code should yield modification indices for freeing the intercept parameters (see here for a demonstration: http://pareonline.net/getvn.asp?v=19&n=7)

However, it produces nothing for me. Even if I request all modification indices with a simple call as in the code below, there are no indices for freeing intercept parameters.

modificationIndices(strong)

Is anyone aware of how I can remedy this? Is there something I am doing wrong?

Thanks so much,

Pete

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Aug 18 07:36:36 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 17 Aug 2016 22:36:36 -0700
Subject: [R] R jobs on SLURM running on a single node only
In-Reply-To: <CAMU2JtCuXK4MXfauK=3dAXuTEbvNSYpDPstTReH_1UhWqLAWLQ@mail.gmail.com>
References: <CAMU2JtCuXK4MXfauK=3dAXuTEbvNSYpDPstTReH_1UhWqLAWLQ@mail.gmail.com>
Message-ID: <E1D56AEF-6182-4A5A-B563-DAADA33DFD90@dcn.davis.ca.us>

Cross-posting [1] is not acceptable on R-help, particularly if you don't let reasonable time pass and inform us of the other posting.  Topics not related to the R language are off-topic here (this is about slurm, not R).

[1] http://stackoverflow.com/questions/38991287/r-jobs-on-slurm-running-on-a-single-node-only
-- 
Sent from my phone. Please excuse my brevity.

On August 17, 2016 1:29:57 AM PDT, Sourav Ray <souravray90 at gmail.com> wrote:
>Despite mentioning the job name, partition and node on which the job
>should
>run, R is still running on compute node 01 with no migration to other
>nodes. I am presenting the script below, any help is appreciated:
>
>!/bin/bash
>#SBATCH --job-name=10/0.30
>#SBATCH --nodes=1
>#SBATCH --ntasks-per-node=16
>#SBATCH --partition=debug
>#SBATCH --exclude=compute[23,31-33,40]
>#SBATCH --nodelist=compute[07]
>
>echo "program started"
>cd /home1/ASP/sourav/coarse_grained_simulations/10/0.30
>
>sbatch /home1/ASP/R-3.3.1/bin/R CMD BATCH --no-save --no-restore
>test_dcd.R
>test_dcd.out
>
>On running squeue to get the list of running jobs:
>
>       12169      nnvi        R      ASP  R       7:08      1 compute01
>       12172      nnvi        R      ASP  R       5:03      1 compute01
>       12175      nnvi        R      ASP  R       3:26      1 compute01
>       12177      nnvi        R      ASP  R       0:02      1 compute01
>
>
>Regards
>Sourav
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Aug 18 07:48:34 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 17 Aug 2016 22:48:34 -0700
Subject: [R] enabling PAM in R for RODBC connections
In-Reply-To: <CALEm3d0HpMacRe9rtP+8MGTcTTdn95Np-dWUUXmxp6xUnvAQVA@mail.gmail.com>
References: <CALEm3d0HpMacRe9rtP+8MGTcTTdn95Np-dWUUXmxp6xUnvAQVA@mail.gmail.com>
Message-ID: <AC4BF79C-4415-41AC-95A3-D84748600761@dcn.davis.ca.us>

There are at least four layers of software  involved here: RODBC, ODBC, HS2 and PAM. If the question involved RODBC then R-sig-db would be a much better bet for relevant experience (see the Posting Guide). However, your question seems to be about getting ODBC to talk with HS2... a topic for which this just isn't the place to get help.
-- 
Sent from my phone. Please excuse my brevity.

On August 17, 2016 12:37:08 PM PDT, Divakar Reddy <divakarreddy.a at gmail.com> wrote:
>Hi,
>
>I'm trying to enable PAM authentication for RODBC connections in
>Hadoop/hiveserver2.
>
>I implemented required configurations in .ODBC.ini and it's working
>with
>user ID but not working with user ID and Password.
>
>Here are my configuration details in .odbc.ini
>----------------
>Description=Hortonworks Hive ODBC Driver (64-bit) DSN
>Driver=/usr/lib/hive/lib/native/Linux-amd64-64/libhortonworkshiveodbc64.so
>HOST=<hive Server IP>
>PORT=10000
>Schema=default
>HiveServerType=2
>AuthMech=3
>UID=test
>PWD=*******
>--------------------------------
>
>Can you please suggest me where do I need make additional changes
>in-order
>to work with User ID and Password.
>
>Regards,
>Divakar
>Phoenix,US
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Aug 18 08:07:22 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 17 Aug 2016 23:07:22 -0700
Subject: [R] Problem detect cheating with CopyDetect Package
In-Reply-To: <CAGGEV7N+HrfYJzhfzymS0wd55pfnnXomiLX-JY50ePkpYS9dPg@mail.gmail.com>
References: <CAGGEV7N+HrfYJzhfzymS0wd55pfnnXomiLX-JY50ePkpYS9dPg@mail.gmail.com>
Message-ID: <6C700083-AA59-4660-9618-5DD73CDDA113@dcn.davis.ca.us>

If we R users unfamiliar with the details of the CopyDetect package are to be able to help,  we would need a reproducible example that includes data. See to http://www.catb.org/esr/faqs/smart-questions.html and http://adv-r.had.co.nz/Reproducibility.html for discussion on how to ask for help online.

I will make a wild guess that your data is nowhere near as broadly variable as this algorithm needs in order to work... but it might just be incorrect specification of parameters. Either way you have hidden the answers from us. If you think the package is broken or you need help with the theory you should identify the maintainer with the maintainer() function and correspond with them. 

-- 
Sent from my phone. Please excuse my brevity.

On August 16, 2016 7:13:41 PM PDT, Ahmad Nursalim <ceritaahmad at gmail.com> wrote:
>Dear All list members,
>Please Help me
>I have the problem detect cheating analysis with use of CopyDetect
>Package
>I use my own data
>namely data.abcd and slopintrc
>and when I tried to count by R studio with a script
>
>for (i in 1: replication) {
>
>   x <- CopyDetect2 (data = data.abcd,
>                    item.par = slopintrc,
>                    pair = c (pairs [i, 1], pairs [i, 2]),
>                    options = c ("A", "B", "C", "D", "E"))
>
>   pairs [i,] $ W = x $ W.index $ p.value
>   pairs [i,] $ GBT = x $ GBT.index $ p.value
>   pairs [i,] $ K = x $ K.index $ k.index
>   pairs [i,] $ K1 = x $ K.variants $ K1.index
>   pairs [i,] $ K2 = x $ K.variants $ K2.index
>   pairs [i,] $ S1 = x $ K.variants $ S1.index
>   pairs [i,] $ S2 = x $ K.variants $ S2.index
>}
>
>an error
>
>Error in solve.default(object$hessian) :
>  system is computationally singular: reciprocal condition number =
>2.52915e-29In addition: Warning message:In ltm.fit(X, betas,
>constraint, formula, con) :
>Hessian matrix at convergence is not positive definite; unstable
>solution.
>
>Please help me
>--
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Thu Aug 18 08:32:56 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 18 Aug 2016 06:32:56 +0000
Subject: [R] GGplot2  stat_summary
In-Reply-To: <E9DA6CABC0F0734A9980C6E78E9024BA070B2313@aai-exch-mbx8.campus.unibe.ch>
References: <E9DA6CABC0F0734A9980C6E78E9024BA070B2313@aai-exch-mbx8.campus.unibe.ch>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039902@SRVEXCHMBX.precheza.cz>

Hi

Your code is not reproducible

> melted_SWT <- melt(DF_filled_SWT,id.vars="X37")
Error in melt(DF_filled_SWT, id.vars = "X37") :
  object 'DF_filled_SWT' not found

and your explanation is rather cryptic. Try to elaborate minimal reproducible code with data available preferably by dput. Maybe during this process you find the solution as I often do.

And please do not post in HTML, it usually scrambles mail content.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> maettuw at students.unibe.ch
> Sent: Wednesday, August 17, 2016 4:46 PM
> To: r-help at r-project.org
> Subject: [R] GGplot2 stat_summary
>
> Hello guys
>
> I have a melted dataset that has 36 different time series included. With
> stat.summary() I added the mean. The problem is that these 36 time series
> do not have the same length. Therefore I would like to plot the mean only
> for the length that the shortest of these 36 time series has. Example. First
> time series; 28 years long; 2. time series 21 years long and so so. So the mean
> in this example should not be longer than these 21 years. I searched the
> internet but no return so far. Below is the code:
>
> melted_SWT <- melt(DF_filled_SWT,id.vars="X37")
>
> mean_SW <- melt(apply(DF_filled_SWT,1,mean))
>
> stat_summary(aes(shape="mean",group=1),fun.y = "mean",size = 1, geom =
> "line", show.legend = T)+
>
> XIntercept <- data.frame( Intercept=c(1)) YIntercept <- data.frame(
> Intercept=c(0))
>
> ggplot(data=melted_SWT,aes(x=X37,y=value,colour=variable)) +
> geom_line() +
>     ggtitle("  GMST during Hiatuses")+ylab("( K)") + xlab("timelag")+
>   theme(panel.background = element_rect(fill = 'grey87')) +
> stat_summary(aes(shape="mean",group=1),fun.y = "mean",size = 1, geom =
> "line", show.legend = T)+
>   theme(axis.title.x = element_text( size=24, face="bold")) + theme(title =
> element_text( size=24, face="bold"))+
>   theme(axis.text.x= element_text( size=24, face="bold") ) +
> theme(axis.text.y= element_text( size=24, face="bold") ) +
>   geom_vline(aes(xintercept=XIntercept),data=Intercept) +
> geom_hline(aes(yintercept=YIntercept),data=Intercept)+
>   theme(legend.text = element_text( size=24, face="bold")) +
> theme(legend.margin = unit(0.7, "line")) +scale_x_continuous(breaks = c(-
> 10,1,10,20), labels = c(-10,1,10,20))+
>   theme(legend.key.height=unit(2.6,"line")) + theme(legend.key.size =
> unit(2.3, "cm"))
>
>
>
> data :  X37 variable      value
> 1 -10       X1 -0.1940203
> 2  -9       X1 -0.1578422
> 3  -8       X1 -0.1658450
> 4  -7       X1 -0.1873830
> 5  -6       X1 -0.1471910
> 6  -5       X1 -0.1160171
>
>
> Thank for the help
>
>       [[alternative HTML version deleted]]


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ivan.calandra at univ-reims.fr  Thu Aug 18 12:19:20 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Thu, 18 Aug 2016 12:19:20 +0200
Subject: [R] get() within function
Message-ID: <605cfb96-6c3a-6496-322d-37d44d3d883b@univ-reims.fr>

Dear useRs,

For an interactive use, I am trying to write a function that looks for 
all data.frames and lists in the environment and ask the user to select 
one of them. I then run some operations on this object.

This is what I am trying:

foo <- function(){
     df.list <- ls()[sapply(ls(), function(x) class(get(x))) %in% 
c("data.frame","list")]
     dat.str <- select.list(choices=df.list, title="Select object")
     dat <- get(dat.str)
     str(dat)
}

Let's say I have these three objects:
vec <- 1:10
mylist <- list(1:3)
datf <- data.frame(var1=rnorm(10), var2=rnorm(10))

I would like the function to show me only mylist and datf in the dialog 
box. Everything works fine if I take the code out of the function, but 
when I run foo() I get this error:
"Error in get(dat.str) : first argument incorrect"

Is there a problem with using get() within a function? Maybe a problem 
with environments?

Thank you in advance for any help!
Ivan

-- 
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/


From mailund at birc.au.dk  Thu Aug 18 13:00:37 2016
From: mailund at birc.au.dk (Thomas Mailund)
Date: Thu, 18 Aug 2016 11:00:37 +0000
Subject: [R] get() within function
In-Reply-To: <605cfb96-6c3a-6496-322d-37d44d3d883b@univ-reims.fr>
References: <605cfb96-6c3a-6496-322d-37d44d3d883b@univ-reims.fr>
Message-ID: <etPan.57b59557.6c343ca0.5ef6@birc.au.dk>

?
Hi Ivan,

ls() inside a function gives you the variables in the local scope. If you want to get the variables defined in the global scope you need to tell ls() that.

Check the difference between these three functions:

> foo <- function() ls()
> foo()

Returns character(0) because there are no local variables.

> bar <- function(x) ls()
> bar(1)

Returns ?x? because ls() sees the function parameter

> baz <- function() ls(envir = .GlobalEnv)
> baz()

Returns all the variables in the global environment.

If you change your function foo() to this, it should work:


foo <- function() {?
? selected_names <- sapply(ls(.GlobalEnv),?
? ? ? ? ? ? ? ? ? ? ? ? ? ?function(x) class(get(x))) %in% c("data.frame","list")
? df.list <- ls(.GlobalEnv)[selected_names]?
? dat.str <- select.list(choices=df.list, title="Select object")?
? dat <- get(dat.str)?
? str(dat)?
}?

Cheers
	Thomas






On 18 August 2016 at 12:21:33, Ivan Calandra (ivan.calandra at univ-reims.fr(mailto:ivan.calandra at univ-reims.fr)) wrote:

> Dear useRs,
>  
> For an interactive use, I am trying to write a function that looks for
> all data.frames and lists in the environment and ask the user to select
> one of them. I then run some operations on this object.
>  
> This is what I am trying:
>  
> foo <- function(){
> df.list <- ls()[sapply(ls(), function(x) class(get(x))) %in%
> c("data.frame","list")]
> dat.str <- select.list(choices=df.list, title="Select object")
> dat <- get(dat.str)
> str(dat)
> }
>  
> Let's say I have these three objects:
> vec <- 1:10
> mylist <- list(1:3)
> datf <- data.frame(var1=rnorm(10), var2=rnorm(10))
>  
> I would like the function to show me only mylist and datf in the dialog
> box. Everything works fine if I take the code out of the function, but
> when I run foo() I get this error:
> "Error in get(dat.str) : first argument incorrect"
>  
> Is there a problem with using get() within a function? Maybe a problem
> with environments?
>  
> Thank you in advance for any help!
> Ivan
>  
> --
> Ivan Calandra, PhD
> Scientific Mediator
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> --
> https://www.researchgate.net/profile/Ivan_Calandra
> https://publons.com/author/705639/
>  
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From ivan.calandra at univ-reims.fr  Thu Aug 18 13:30:49 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Thu, 18 Aug 2016 13:30:49 +0200
Subject: [R] get() within function
In-Reply-To: <etPan.57b59557.6c343ca0.5ef6@birc.au.dk>
References: <605cfb96-6c3a-6496-322d-37d44d3d883b@univ-reims.fr>
	<etPan.57b59557.6c343ca0.5ef6@birc.au.dk>
Message-ID: <a63da670-bbe0-110c-8ab7-51b006ec1428@univ-reims.fr>

Thank you Thomas,

Because of the error message, I focused only on get()... My bad!

Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 18/08/2016 ? 13:00, Thomas Mailund a ?crit :
>   
> Hi Ivan,
>
> ls() inside a function gives you the variables in the local scope. If you want to get the variables defined in the global scope you need to tell ls() that.
>
> Check the difference between these three functions:
>
>> foo <- function() ls()
>> foo()
> Returns character(0) because there are no local variables.
>
>> bar <- function(x) ls()
>> bar(1)
> Returns ?x? because ls() sees the function parameter
>
>> baz <- function() ls(envir = .GlobalEnv)
>> baz()
> Returns all the variables in the global environment.
>
> If you change your function foo() to this, it should work:
>
>
> foo <- function() {
>    selected_names <- sapply(ls(.GlobalEnv),
>                             function(x) class(get(x))) %in% c("data.frame","list")
>    df.list <- ls(.GlobalEnv)[selected_names]
>    dat.str <- select.list(choices=df.list, title="Select object")
>    dat <- get(dat.str)
>    str(dat)
> }
>
> Cheers
> 	Thomas
>
>
>
>
>
>
> On 18 August 2016 at 12:21:33, Ivan Calandra (ivan.calandra at univ-reims.fr(mailto:ivan.calandra at univ-reims.fr)) wrote:
>
>> Dear useRs,
>>   
>> For an interactive use, I am trying to write a function that looks for
>> all data.frames and lists in the environment and ask the user to select
>> one of them. I then run some operations on this object.
>>   
>> This is what I am trying:
>>   
>> foo <- function(){
>> df.list <- ls()[sapply(ls(), function(x) class(get(x))) %in%
>> c("data.frame","list")]
>> dat.str <- select.list(choices=df.list, title="Select object")
>> dat <- get(dat.str)
>> str(dat)
>> }
>>   
>> Let's say I have these three objects:
>> vec <- 1:10
>> mylist <- list(1:3)
>> datf <- data.frame(var1=rnorm(10), var2=rnorm(10))
>>   
>> I would like the function to show me only mylist and datf in the dialog
>> box. Everything works fine if I take the code out of the function, but
>> when I run foo() I get this error:
>> "Error in get(dat.str) : first argument incorrect"
>>   
>> Is there a problem with using get() within a function? Maybe a problem
>> with environments?
>>   
>> Thank you in advance for any help!
>> Ivan
>>   
>> --
>> Ivan Calandra, PhD
>> Scientific Mediator
>> University of Reims Champagne-Ardenne
>> GEGENAA - EA 3795
>> CREA - 2 esplanade Roland Garros
>> 51100 Reims, France
>> +33(0)3 26 77 36 89
>> ivan.calandra at univ-reims.fr
>> --
>> https://www.researchgate.net/profile/Ivan_Calandra
>> https://publons.com/author/705639/
>>   
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From shivipmp82 at gmail.com  Thu Aug 18 14:36:06 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Thu, 18 Aug 2016 18:06:06 +0530
Subject: [R] Error in riv package
In-Reply-To: <CA+vqiLGWH_4KtGHRGCs7ir7kBZvvZ8vh1VrOdzJKXGnBQS9X6g@mail.gmail.com>
References: <CAB=p7SrddtaA264Kfj3KqtjVQvOyoRK4F6PA+sjBxprBp8t9Nw@mail.gmail.com>
	<82486665-14CA-4AEC-95F8-4B9283E364F1@comcast.net>
	<CAB=p7SrZZ_tYS=vVqA0y1fXPBEXKsDWvatu9oAAO0nPM6n2xtQ@mail.gmail.com>
	<27BF0396-D03E-49AA-A985-ECBFF254BC12@dcn.davis.ca.us>
	<CA+vqiLGWH_4KtGHRGCs7ir7kBZvvZ8vh1VrOdzJKXGnBQS9X6g@mail.gmail.com>
Message-ID: <CAB=p7Squo9Pwh4pZX+NzFNo4-X7R=sGfBW73DMgT6seRwOjb3A@mail.gmail.com>

Hi Ista, Thanks for your reply.

I had added a detailed explanation on this one & researched before asking.
May be someone did not read it i cant do much though David's explanation
helped as why it wasnt able to run the syntax.

Please see trail mail: (though i have already moved ahead and taken an
alternate package to calculate IV for each var at a time):


HI Team,
I am working to reduce the # of predictor variables from the model using woe
and iv values. For this i am using riv package. However i am
having a hard time installing this package:
install_github("riv","tomasgreif")
install.packages("DBI",dependencies=TRUE)
The error i receive is :
*Username parameter is deprecated. Please use tomasgreif/riv

and THEN this part:

The other approach i have to use the library(InformationValue). I have this  as
below:
 WOE(X=SFDC1$support_cat, Y=SFDC1$survey)
 WOETable(X=SFDC1$support_cat, Y=SFDC1$survey)
IV(X=SFDC1$support_cat, Y=SFDC1$survey)

This package assists me achieve what i am looking for but here i need to add
one independent variable at a time to see whether it is
predictive or not. Is there a way i can add all variables at a go or have
to add one by one,
For the above package (riv) i have seen an example which helps to take
the entire
data range and  predictive the power of each predictor. The
link for the same is:
 https://www.r-bloggers.com/r-credit-scoring-woe-
information-value-in-woe-package/



On Wed, Aug 17, 2016 at 10:35 PM, Ista Zahn <istazahn at gmail.com> wrote:

> On Aug 17, 2016 12:30 PM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
> wrote:
> >
> > Not our problem.
>
> Maybe maybe not. I'd say we don't have enough information to determine if
> this is on topic for R-help or not (I assume this is what you meant by 'not
> our problem').
>
> Shivi, if you want help from this list you need to tell us exactly what
> you did and exactly what happened. Refer to http://www.catb.org/esr/faqs/
> smart-questions.html and http://adv-r.had.co.nz/Reproducibility.html for
> guidance on how to ask for help effectively.
>
> Best,
> Ista
>
> Please correspond with the maintainer of that package.
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > On August 17, 2016 3:23:33 AM PDT, Shivi Bhatia <shivipmp82 at gmail.com>
> wrote:
> > >Hi David,
> > >
> > >If this has loaded correctly then it still does not allow me to run
> > >iv.multi command where a can add all the variables in the model and
> > >find
> > >their respective WOE and IV values.
> > >
> > >Thanks, Shivi
> > >
> > >On Wed, Aug 17, 2016 at 1:17 AM, David Winsemius
> > ><dwinsemius at comcast.net>
> > >wrote:
> > >
> > >>
> > >> > On Aug 16, 2016, at 11:07 AM, Shivi Bhatia <shivipmp82 at gmail.com>
> > >wrote:
> > >> >
> > >> > HI Team,
> > >> >
> > >> > I am working to reduce the # of predictor variables from the model
> > >using
> > >> > woe and iv values. For this i am using riv package. However i am
> > >having a
> > >> > hard time installing this package:
> > >> >
> > >> > install_github("riv","tomasgreif")
> > >> > install.packages("DBI",dependencies=TRUE)
> > >> >
> > >> > The error i receive is :
> > >> > *Username parameter is deprecated. Please use tomasgreif/riv *
> > >>
> > >> No. You did not get an error message. It was clearly labeled a
> > >:Warning
> > >> message". Here is the full console output from that call:
> > >>
> > >> > install_github("riv","tomasgreif")
> > >> Downloading GitHub repo tomasgreif/riv at master
> > >> from URL https://api.github.com/repos/tomasgreif/riv/zipball/master
> > >> Installing woe
> > >> '/Library/Frameworks/R.framework/Resources/bin/R' --no-site-file
> > >> --no-environ  \
> > >>   --no-save --no-restore --quiet CMD INSTALL  \
> > >>
> > >'/private/var/folders/yq/m3j1jqtj6hq6s5mq_v0jn3s80000gn/T/Rtmp6YDYoj/
> > >> devtoolsadc32ead1a82/tomasgreif-woe-43fcf26'  \
> > >>
> > >--library='/Library/Frameworks/R.framework/Versions/3.3/Resources/
> library'
> > >> \
> > >>   --install-tests
> > >>
> > >> * installing *source* package ?woe? ...
> > >> ** R
> > >> ** data
> > >> *** moving datasets to lazyload DB
> > >> ** demo
> > >> ** preparing package for lazy loading
> > >> ** help
> > >> *** installing help indices
> > >> ** building package indices
> > >> ** testing if installed package can be loaded
> > >> * DONE (woe)
> > >> Warning message:
> > >> Username parameter is deprecated. Please use tomasgreif/riv
> > >>
> > >>
> > >> It's just telling you to use this next time:
> > >>
> > >> install_github("tomasgreif/riv")
> > >>
> > >> I will lay long odds that you already have the package installed.
> > >>
> > >> I cannot comment on what this package purports to do. I'm somewhat
> > >> suspicious that it is statistically suspect.
> > >>
> > >> --
> > >> David.
> > >>
> > >> >
> > >> > The other approach i have to use the library(InformationValue). I
> > >have
> > >> this
> > >> > as below:
> > >> > WOE(X=SFDC1$support_cat, Y=SFDC1$survey)
> > >> > WOETable(X=SFDC1$support_cat, Y=SFDC1$survey)
> > >> > IV(X=SFDC1$support_cat, Y=SFDC1$survey)
> > >> >
> > >> > This package assists me achieve what i am looking for but here i
> > >need to
> > >> > add one independent variable at a time to see whether it is
> > >predictive or
> > >> > not. Is there a way i can add all variables at a go or have to add
> > >one by
> > >> > one,
> > >> >
> > >> > For the above package (riv) i have seen an example which helps to
> > >take
> > >> the
> > >> > entire data range and  predictive the power of each predictor. The
> > >link
> > >> for
> > >> > the same is:
> > >> > https://www.r-bloggers.com/r-credit-scoring-woe-
> > >> information-value-in-woe-
> > >> > package/
> > >> >
> > >> > Thanks, Shivi
> > >> >
> > >> >       [[alternative HTML version deleted]]
> > >> >
> > >> > ______________________________________________
> > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> > >> > PLEASE do read the posting guide http://www.R-project.org/
> > >> posting-guide.html
> > >> > and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >> David Winsemius
> > >> Alameda, CA, USA
> > >>
> > >>
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mzuzcak at secit.sk  Thu Aug 18 15:05:26 2016
From: mzuzcak at secit.sk (=?UTF-8?B?TWF0ZWogWnV6xI3DoWs=?=)
Date: Thu, 18 Aug 2016 15:05:26 +0200
Subject: [R]  Need help with output of Proximus algorithm
Message-ID: <4d1e9b14-1aec-edef-ef48-5fbebdfad1ca@secit.sk>

Hello list members,

I have question about output of PROXIMUS algorithm. In the example of
use here:
https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Clustering/Proximus#Algorithm
in Case Study section is all clear, but I do not know what way they use
for get clustered words to groups: Group 1 (computers) = {intel,
computer, software, linux, windows, Firefox, explorer, programming}
Group 2 (authors) = {kuth, shakespeare, grisham, asimov, book} Group 3
(noise) = {love}. How can I get this output for my data please? Next in
the example section is graph. How do I read this graph please?

My data are:

objects cat1    cat2    cat3    cat4 ...
A       TRUE    FALSE   FALSE   FALSE
B       TRUE    FALSE   TRUE    FALSE
C       TRUE    FALSE   FALSE   FALSE
D       FALSE   TRUE    TRUE    TRUE
E       TRUE    TRUE    TRUE    TRUE
F       TRUE    FALSE   TRUE    FALSE

After apply of Proximus algorithm I get this output:

> pr <- proximus(x, max.radius=8, debug=TRUE)
Non-Zero: 55
Sparsity: 0.48
  0 [6,3,5] 1 >
  1 [3,3,5] 1 * 1
  1 [3,1,0] 1 >
  2 [1,1,0] 1 * 2
  2 [2,1,0] 1 >
  3 [1,1,0] 1 * 3
  3 [1,1,0] 1 * 4
  2 <
  1 <
  0 <

> summary(pr)
Size Length Radius Error Fnorm Jsim Valid
1    3     16      5  0.16     3 0.81  TRUE
2    1      9      0  0.00     0 1.00  TRUE
3    1      4      0  0.00     0 1.00  TRUE
4    1      2      0  0.00     0 1.00  TRUE

So it means that 3 objects are in one cluster and all other objects have
own cluster. What way I can use for get list of objects in cluster
please? And I get this graph (see in attachment). How do I read this
graph please? 

Many thanks for your help!

-- 
Best Regards
Matej Zuzcak

-------------- next part --------------
A non-text attachment was scrubbed...
Name: graph.png
Type: image/png
Size: 5618 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160818/72209372/attachment.png>

From profjcnash at gmail.com  Thu Aug 18 15:35:22 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Thu, 18 Aug 2016 09:35:22 -0400
Subject: [R] Announcement of optimr and optimrx packages
Message-ID: <3bbc1491-d0e7-dadf-a4d2-9ad912887cb5@gmail.com>

Package __optimr__ is now on CRAN, and a more capable package
__optimrx__ is on R-forge at

https://r-forge.r-project.org/R/?group_id=395

These packages wrap a number of tools for function minimization,
sometimes with bounds constraints or fixed parameters, but use a
consistent interface in function optimr() that matches the base function
optim(). Moreover, the use of the parameter scaling control parscale is
applied to all methods. There are functions to allow multiple methods to
be tried simultaneously via function opm(), which is a replacement for
package optimx that used a different calling syntax. There are
multistart() and polyopt() functions for multiple starts or
polyalgorithm uses.

Some of the approximately twenty available optimizers require derivative
(gradient) information, and the calling syntax uses gradient routine
names in quotation marks to specify which gradient approximations are to
be used. Nevertheless, I strongly recommend analytic gradients where
possible, and welcome any efforts to find user-friendly ways to provide
automatic or symbolic differentiation.

As the main optimr() function is set up to permit new optimizers to be
added, there is a vignette explaining (or trying to!) how to add another
optimizer. Package optimr deliberately uses just a few optimizers to
avoid reverse dependency issues should some optimizers be dropped from
CRAN. Otherwise the usage should be the same. I welcome communications
from those who add optimizers or features. Indeed, as I have now been
retired from teaching for 8 years, it would not be amiss for the
maintainer job to be shared with someone younger. For communications
about extensions of the packages or help with maintenance of this and
related tools, please get in touch off-line to either the email above or
nashjc _at_ uottawa.ca.

Because of the dependency on many other packages, it is likely there
will be glitches from time to time as underlying software is adjusted,
maintained or improved. Often sorting out exactly where the difficulties
arise can be tricky, and I would repeat the R mantra of "short
reproducible example". As always with complicated packages like this,
there will certainly be some ways to get unexpected responses, and I ask
your indulgence and assistance in rendering the packages water-tight.

Cheers,

John Nash


From aurora.gonzalez2 at um.es  Thu Aug 18 17:38:49 2016
From: aurora.gonzalez2 at um.es (AURORA GONZALEZ VIDAL)
Date: Thu, 18 Aug 2016 17:38:49 +0200
Subject: [R] optimize the filling of a diagonal matrix (two for loops)
Message-ID: <20160818173849.Horde.msvc0kYaV0o-z3SATb8slQ7@webmail.um.es>

Hello

I have two for loops that I am trying to optimize... I looked for
vectorization or for using some funcions of the apply family? but really
cannot do it. I am writting my code with some small data set. With this
size there is no problem but sometimes I will have hundreds of rows so it
is really important to optimize the code. Any suggestion will be very
welcomed.

library("TSMining")
dataS = data.frame(V1 = sample(c(1,2,3,4),30,replace = T),
?????????????????? V2 = sample(c(1,2,3,4),30,replace =
T),
?????????????????? V3 = sample(c(1,2,3,4),30,replace =
T),
?????????????????? V4 = sample(c(1,2,3,4),30,replace =
T))
saxM = Func.matrix(5)
colnames(saxM) = 1:5
rownames(saxM) = 1:5
matrixPrepared = matrix(NA, nrow = nrow(dataS), ncol = nrow(dataS))

FOR(I IN 1:(NROW(DATAS)-1)){
? FOR(J IN (1+I):NROW(DATAS)){
??? MATRIXPREPARED[I,J] = FUNC.DIST(AS.CHARACTER(DATAS[I,]),
AS.CHARACTER(DATAS[J,]), SAXM, N=60)
? }
}
matrixPrepared

Thank you!


------
Aurora Gonz?lez Vidal
Phd student in Data Analytics for Energy Efficiency

Faculty of Computer Sciences
University of Murcia

@. aurora.gonzalez2 at um.es
T. 868 88 7866
www.um.es/ae

	[[alternative HTML version deleted]]


From isaudin at gmail.com  Thu Aug 18 18:03:50 2016
From: isaudin at gmail.com (Isaudin Ismail)
Date: Thu, 18 Aug 2016 17:03:50 +0100
Subject: [R] Error while fitting gumbel copula
In-Reply-To: <CAE1aWa-C91VyzjCyygyot4udAM4LkHCKWS1ZwYaHBNyVZVdy8w@mail.gmail.com>
References: <CAE1aWa_AJRovvq9sZU2LWA3VaBCWAC_mxLoK4L7kzy=HkjgEHQ@mail.gmail.com>
	<22443.20835.731336.772515@stat.math.ethz.ch>
	<CAE1aWa-C91VyzjCyygyot4udAM4LkHCKWS1ZwYaHBNyVZVdy8w@mail.gmail.com>
Message-ID: <CAE1aWa88OgFRS+Hmj5rXdeCw5GZy=HX5NDPpxpgAWECFxVPsPg@mail.gmail.com>

Dear Martin,

Following my earlier question on "error while fitting gumbel copula", I
have also crated a new gist at https://gist.github.com/anonymous/
0bb8aba7adee550d40b840a47d8b7e25 for easy checking and copying codes.

I got no problem fitting other Archimedean copulas except gumbel copula as
per my code I used above.

Appreciate your kind help.

Many thanks,
Isaudin



On Mon, Aug 15, 2016 at 4:28 PM, Isaudin Ismail <isaudin at gmail.com> wrote:

> Dear Dr. Martin,
>
> I'm glad that you replied to my queries.
>
> As advised, I have prepared the following:
>
> library(copula)
>
>
>
> # 5 series of data, A, B, C, D and E
> A <- c(0.849420849, 0.900652985, 0.97144217, 0.817888428, 0.877901578,
>        1.070040669, 0.889742431, 0.87588968, 0.853541938, 0.848664688,
>        0.876830319, 0.749582638, 0.818515498, 0.890997174, 0.794766966,
>        0.784794851, 0.814858959, 1.074396518, 0.83752495, 0.894341116,
>        0.880375293, 0.900816803)
>
> B <- c(0.479850746, 0.652111668, 1.880607815, 0.579902303, 0.50669344,
>        0.747560182, 0.701754386, 0.48969697, 0.346751006, 0.379234973,
>        0.862691466, 0.328280188, 0.317312661, 0.534438115, 0.487002653,
>        0.335043612, 0.373346897, 0.627520161, 0.792114695, 0.938253012,
>        0.444553967, 0.625972763)
>
> C <- c(0.693491124, 0.866523143, 4.585714286, 1.512055109, 0.387755102,
>        0.513435701, 0.76252505, -0.113113113, 0.338521401, 0.333951763,
>        0.668755595, 0.401273885, 0.419868791, 0.272885789, 0.541541542,
>        0.32751938, 0.386409736, 0.957446809, 0.861195542, 1.531632653,
>        0.431610942, 1.226470588)
>
> D <- c(0.807792208, 0.548547718, 0.738232865, 0.542247744, 1.088964927,
>        0.862385321, 0.60720268, 1.000816993, 0.699289661, 0.41723356,
>        0.604037267, 0.605003791, 0.698940998, 0.764792899, 0.647897898,
>        0.825256975, 0.767476085, 0.941391941, 0.889547813, 0.324503311,
>        0.942435424, 0.740686633)
>
> E <- c(1.077598829, 0.318507891, 1.152616279, 0.930397727, 1.515994437,
>        0.940689655, 0.880886427, 1.054274084, 1.067282322, 0.677419355,
>        0.966233766, 0.761029412, 1.05734767, 0.615925059, 1.061988304,
>        1.07184241, 1.058890147, 1.123873874, 1.304891923, -0.069584736,
>        1.172757475, 0.501096491)
>
> gumbel.copula <- gumbelCopula(dim = 2)
> p <- pobs(as.matrix(cbind(D + E, A + B+ C )))
>
> fit.gumbel <- fitCopula(gumbel.copula, p, method = "ml") #The error is
> here when trying to fit the gumbel copula
>
> # I got the following error:
> Error in optim(start, loglikCopula, lower = lower, upper = upper, method =
> method,  :
>                  non-finite finite-difference value [1]
>               In addition: Warning message:
>               In .local(copula, tau, ...) : tau is out of the range [0, 1]
>
> #Due to error in fitting the gumbel copula, this step can't be processed
>
> coef(fit.gumbel)
> gofCopula(gumbel.Copula, p, estim.method = "mpl", method = "Sn",
> simulation = "mult")
>
>
> Thanks in advance!
>
> Best regards,
> Isaudin
>
> On Wed, Aug 10, 2016 at 5:08 PM, Martin Maechler <
> maechler at stat.math.ethz.ch> wrote:
>
>> >>>>> Isaudin Ismail <isaudin at gmail.com>
>> >>>>>     on Tue, 9 Aug 2016 14:30:18 +0100 writes:
>>
>>     > Dear R experts,
>>     > I have 5 time series of data (A, B, C, D and E) with all same
>> lengths. All
>>     > series exhibit gamma distribution except for B which is lognormal
>>     > distribution. I am using copula package to model the
>> joint-distribution of
>>     > these 5 times series.
>>
>>     > I have selected Archimedean copula and successfully fitted  Frank
>> and
>>     > Clayton copula. The problem is when trying to fit Gumbel copula.
>>
>>     > The following are the codes I used to run in R.
>>
>>     > # Data of 5 time series
>>
>>     > A <- A
>>     > B <- B
>>     > C <- C
>>     > D <- D
>>     > E <- E
>>
>> well, the above is really an "interesting" block of R code ;-)
>>
>> --
>>
>> More seriously, please learn to use reproducible examples,
>> e.g., from here
>>   http://bit.ly/MRE_R (nice to remember: MRE = Minimal Reproducible
>> Example)
>> or here
>>   http://adv-r.had.co.nz/Reproducibility.html
>>
>> then we will be glad to help you,
>> notably I as maintainer of the package 'copula' which you are
>> using (without saying so).
>>
>> With regards,
>> Martin Maechler
>>
>>
>>     > # Combined between A and C
>>     > A+C <- A + C
>>
>>     > gumbel.copula <- gumbelCopula(dim = 5)
>>     > m <- pobs(as.matrix(cbind(A+C, B, D, E)))
>>     > fit.gumbel<- fitCopula(gumbel.copula, m, method = 'ml')
>>
>>     > And the error while trying to fit gumbel copula:
>>
>>     > Error in optim(start, loglikCopula, lower = lower, upper = upper,
>> method =
>>     > method,  :
>>     > non-finite finite-difference value [1]
>>     > In addition: Warning message:
>>     > In .local(copula, tau, ...) : tau is out of the range [0, 1]
>>
>>     > Appreciate all help!
>>
>>     > Many thanks,
>>     > Isaudin
>>
>>     > [[alternative HTML version deleted]]
>>
>>     > ______________________________________________
>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>     > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>>     > and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From mailund at birc.au.dk  Thu Aug 18 18:50:07 2016
From: mailund at birc.au.dk (Thomas Mailund)
Date: Thu, 18 Aug 2016 16:50:07 +0000
Subject: [R] optimize the filling of a diagonal matrix (two for loops)
In-Reply-To: <20160818173849.Horde.msvc0kYaV0o-z3SATb8slQ7@webmail.um.es>
References: <20160818173849.Horde.msvc0kYaV0o-z3SATb8slQ7@webmail.um.es>
Message-ID: <etPan.57b5e73f.13eb676b.5ef6@birc.au.dk>

?

The nested for-loops could very easily be moved to Rcpp which should speed them up. Using apply functions instead of for-loops will not make it faster; they still have to do the same looping.

At least, when I use `outer` to replace the loop I get roughly the same speed for the two versions ? although the `outer` solution does iterate over the entire matrix and not just the upper-triangular matrix.

library(stringdist) # I don?t have TSmining library installed so I tested with this instead
for_loop_test <- function() {
? matrixPrepared <- matrix(NA, nrow = nrow(dataS), ncol = nrow(dataS))
? for (i in 1:(nrow(dataS)-1)){
? ? for (j in (1+i):nrow(dataS)){
? ? ? matrixPrepared[i, j] <- stringdist(paste0(as.character(dataS[i,]), collapse=""),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?paste0(as.character(dataS[j,]), collapse=""))
? ? }
? }
? matrixPrepared
}

apply_test <- function() {
? get_dist <- function(i, j) {
? ? if (i <= j) NA
? ? else stringdist(paste0(as.character(dataS[i,]), collapse=""),
? ? ? ? ? ? ? ? ? ? paste0(as.character(dataS[j,]), collapse=""))
? }
? get_dist <- Vectorize(get_dist)
? t(outer(1:nrow(dataS), 1:nrow(dataS), get_dist))
}

library(microbenchmark)
equivalent <- function(x, y) (is.na(x) && is.na(y)) || (x == y)
check <- function(values) all(equivalent(values[[1]], values[[2]]))
microbenchmark(for_loop_test(), apply_test(), check = check, times = 5)

Cheers
	Thomas


On 18 August 2016 at 17:41:01, AURORA GONZALEZ VIDAL (aurora.gonzalez2 at um.es(mailto:aurora.gonzalez2 at um.es)) wrote:

> Hello
>  
> I have two for loops that I am trying to optimize... I looked for
> vectorization or for using some funcions of the apply family but really
> cannot do it. I am writting my code with some small data set. With this
> size there is no problem but sometimes I will have hundreds of rows so it
> is really important to optimize the code. Any suggestion will be very
> welcomed.
>  
> library("TSMining")
> dataS = data.frame(V1 = sample(c(1,2,3,4),30,replace = T),
> V2 = sample(c(1,2,3,4),30,replace =
> T),
> V3 = sample(c(1,2,3,4),30,replace =
> T),
> V4 = sample(c(1,2,3,4),30,replace =
> T))
> saxM = Func.matrix(5)
> colnames(saxM) = 1:5
> rownames(saxM) = 1:5
> matrixPrepared = matrix(NA, nrow = nrow(dataS), ncol = nrow(dataS))
>  
> FOR(I IN 1:(NROW(DATAS)-1)){
> FOR(J IN (1+I):NROW(DATAS)){
> MATRIXPREPARED[I,J] = FUNC.DIST(AS.CHARACTER(DATAS[I,]),
> AS.CHARACTER(DATAS[J,]), SAXM, N=60)
> }
> }
> matrixPrepared
>  
> Thank you!
>  
>  
> ------
> Aurora Gonz?lez Vidal
> Phd student in Data Analytics for Energy Efficiency
>  
> Faculty of Computer Sciences
> University of Murcia
>  
> @. aurora.gonzalez2 at um.es
> T. 868 88 7866
> www.um.es/ae
>  
> [[alternative HTML version deleted]]
>  
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From bpin3104 at uni.sydney.edu.au  Thu Aug 18 11:19:05 2016
From: bpin3104 at uni.sydney.edu.au (Barathan Roy Pinas)
Date: Thu, 18 Aug 2016 09:19:05 +0000
Subject: [R] Retrieving data from survey in R Studio
Message-ID: <MWHPR01MB2703AC0F6BC3D8401E70A378C9150@MWHPR01MB2703.prod.exchangelabs.com>

Hello,


I have been given a .csv file and it is not loading. This is what I did.


survey=read.csv("http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/survey.csv")
attach(survey)
pulse.sf=pulse[smoke==1 & sex==2]
pulse.sf

Template link here<http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/p4.Rnw>.

I insert the file into the R commands section for question 1. Doing that produces the following below:


survey <- read.csv(file="http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/survey.csv")
attach(survey)

## Error in attach(survey): object 'survey' not found
pulse.sf=pulse[smoke==1 & sex==2]
## Error in eval(expr, envir, enclos): object 'pulse' not found
pulse.sf
## Error in eval(expr, envir, enclos): object 'pulse.sf' not
found

What's going on? I can actually download the survey and view it on Excel.

Appreciate any help that I can get.

	[[alternative HTML version deleted]]


From fatimah.soleimany at gmail.com  Thu Aug 18 13:48:36 2016
From: fatimah.soleimany at gmail.com (fatimah soleimany)
Date: Thu, 18 Aug 2016 16:18:36 +0430
Subject: [R] loop function
Message-ID: <CAJvXuh5pV17wjvb2ZAOMc2myxP1ZAv_3T5h6tU0HU9itGa=txg@mail.gmail.com>

Hi Dear users,
for an interactive use, i am trying to write a loop that looks for all
variables in the conditions which i introduced, this is what I'm trying:

library(MASS)> i=1> for (i in 58:1){+ for(j in 58:i){+ + str.temp <-
paste("y1 ~ x", i, "* x", j, sep = "")+
univar<-glm.nb(as.formula(str.temp), data=df)+
b=summary(univar)$coeffients[4,4]+ b<-c(i,j)+ if(b < 0.6){ +
print(b)+    }+   }+   }

i have no error but i didn't get true response too, my result is this:


b[1] 1 1

 but i want all the variables that their p-value are less than 0.6, i
think i couldn't write a true loop,can you help me?

thank you in advance for any help

	[[alternative HTML version deleted]]


From neerajdhanraj at gmail.com  Thu Aug 18 09:02:15 2016
From: neerajdhanraj at gmail.com (Neeraj Dhanraj)
Date: Thu, 18 Aug 2016 12:32:15 +0530
Subject: [R] [R-pkgs] have a look over package "imputeTestbench"
Message-ID: <CAC58_YkEScPombZnELJP5mDwbxco9ANR3Kw4d+Lwm_idruir8g@mail.gmail.com>

Hi Friends,

Have a look over R package "imputeTestbench". It provides a Test bench for
comparison of missing data imputation models/methods. It compares imputing
methods with reference to RMSE, MAE or MAPE parameters. It allows to add
new proposed methods to test bench and to compare with other methods. The
function 'append_method()' allows to add multiple numbers of methods to the
existing methods available in test bench.

CRAN: https://cran.r-project.org/package=imputeTestbench

GitHub: https://github.com/neerajdhanraj/imputeTestbench

How to Use:
https://www.researchgate.net/publication/305767990_R_package_%27imputeTestbench%27_as_a_Testbench_to_compare_missing_value_imputation_methods

The current version is talking about univariate dataset imputation. Very
next version will allow user to operate it on any type of dataset including
multivariate datset.

For more detail contact me at:
http://www.neerajbokde.com/?
-- 
Regards ,
*Neeraj Dhanraj Bokde  *
*M.E. Embedded System*

*Birla Institute of Technology & Science,* Pilani

Pilani Campus , Rajasthan, India

Phone: *+91 9028415974*

Email: h2012105 at pilani.bits-pilani.ac.in; *neerajdhanraj at gmail.com
<neerajdhanraj at gmail.com>*

Website: http://www.neerajbokde.com

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From murdoch.duncan at gmail.com  Thu Aug 18 19:23:00 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 18 Aug 2016 13:23:00 -0400
Subject: [R] Retrieving data from survey in R Studio
In-Reply-To: <MWHPR01MB2703AC0F6BC3D8401E70A378C9150@MWHPR01MB2703.prod.exchangelabs.com>
References: <MWHPR01MB2703AC0F6BC3D8401E70A378C9150@MWHPR01MB2703.prod.exchangelabs.com>
Message-ID: <9830eb1c-eb97-088b-ac11-5585d754b472@gmail.com>

Sorry, we don't do homework on this list.  You should ask your instructor.

Duncan Murdoch

On 18/08/2016 5:19 AM, Barathan Roy Pinas wrote:
> Hello,
>
>
> I have been given a .csv file and it is not loading. This is what I did.
>
>
> survey=read.csv("http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/survey.csv")
> attach(survey)
> pulse.sf=pulse[smoke==1 & sex==2]
> pulse.sf
>
> Template link here<http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/p4.Rnw>.
>
> I insert the file into the R commands section for question 1. Doing that produces the following below:
>
>
> survey <- read.csv(file="http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/survey.csv")
> attach(survey)
>
> ## Error in attach(survey): object 'survey' not found
> pulse.sf=pulse[smoke==1 & sex==2]
> ## Error in eval(expr, envir, enclos): object 'pulse' not found
> pulse.sf
> ## Error in eval(expr, envir, enclos): object 'pulse.sf' not
> found
>
> What's going on? I can actually download the survey and view it on Excel.
>
> Appreciate any help that I can get.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ulrik.stervbo at gmail.com  Thu Aug 18 19:26:05 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 18 Aug 2016 17:26:05 +0000
Subject: [R] Retrieving data from survey in R Studio
In-Reply-To: <MWHPR01MB2703AC0F6BC3D8401E70A378C9150@MWHPR01MB2703.prod.exchangelabs.com>
References: <MWHPR01MB2703AC0F6BC3D8401E70A378C9150@MWHPR01MB2703.prod.exchangelabs.com>
Message-ID: <CAKVAULNRZW=n3tMJ8A1nE1HKW8H9jzGtWzAncqoU8tYMyWumjA@mail.gmail.com>

I don't think you can read files into R like that. This answer
http://stackoverflow.com/questions/3236651/read-data-from-internet on Stack
Overflow tells you, you could use the RCurl package.

Here are more examples on getting data from online sources
https://www.r-bloggers.com/getting-data-from-an-online-source/

You could also just download the file manually and open it using read.scv

Hope this helps,
Ulrik

On Thu, 18 Aug 2016 at 19:10 Barathan Roy Pinas <bpin3104 at uni.sydney.edu.au>
wrote:

> Hello,
>
>
> I have been given a .csv file and it is not loading. This is what I did.
>
>
> survey=read.csv("
> http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/survey.csv")
> attach(survey)
> pulse.sf=pulse[smoke==1 & sex==2]
> pulse.sf
>
> Template link here<http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/p4.Rnw
> >.
>
> I insert the file into the R commands section for question 1. Doing that
> produces the following below:
>
>
> survey <- read.csv(file="
> http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/survey.csv")
> attach(survey)
>
> ## Error in attach(survey): object 'survey' not found
> pulse.sf=pulse[smoke==1 & sex==2]
> ## Error in eval(expr, envir, enclos): object 'pulse' not found
> pulse.sf
> ## Error in eval(expr, envir, enclos): object 'pulse.sf' not
> found
>
> What's going on? I can actually download the survey and view it on Excel.
>
> Appreciate any help that I can get.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From clint at ecy.wa.gov  Thu Aug 18 19:41:03 2016
From: clint at ecy.wa.gov (Clint Bowman)
Date: Thu, 18 Aug 2016 10:41:03 -0700 (PDT)
Subject: [R] Retrieving data from survey in R Studio
In-Reply-To: <CAKVAULNRZW=n3tMJ8A1nE1HKW8H9jzGtWzAncqoU8tYMyWumjA@mail.gmail.com>
References: <MWHPR01MB2703AC0F6BC3D8401E70A378C9150@MWHPR01MB2703.prod.exchangelabs.com>
	<CAKVAULNRZW=n3tMJ8A1nE1HKW8H9jzGtWzAncqoU8tYMyWumjA@mail.gmail.com>
Message-ID: <alpine.LRH.2.20.1608181039290.14847@aeolus.ecy.wa.gov>

After:

survey <- 
read.csv(file="http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/survey.csv")

do:

summary(survey)

then bone up on "attach" and "with".

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Thu, 18 Aug 2016, Ulrik Stervbo wrote:

> I don't think you can read files into R like that. This answer
> http://stackoverflow.com/questions/3236651/read-data-from-internet on Stack
> Overflow tells you, you could use the RCurl package.
>
> Here are more examples on getting data from online sources
> https://www.r-bloggers.com/getting-data-from-an-online-source/
>
> You could also just download the file manually and open it using read.scv
>
> Hope this helps,
> Ulrik
>
> On Thu, 18 Aug 2016 at 19:10 Barathan Roy Pinas <bpin3104 at uni.sydney.edu.au>
> wrote:
>
>> Hello,
>>
>>
>> I have been given a .csv file and it is not loading. This is what I did.
>>
>>
>> survey=read.csv("
>> http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/survey.csv")
>> attach(survey)
>> pulse.sf=pulse[smoke==1 & sex==2]
>> pulse.sf
>>
>> Template link here<http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/p4.Rnw
>>> .
>>
>> I insert the file into the R commands section for question 1. Doing that
>> produces the following below:
>>
>>
>> survey <- read.csv(file="
>> http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/survey.csv")
>> attach(survey)
>>
>> ## Error in attach(survey): object 'survey' not found
>> pulse.sf=pulse[smoke==1 & sex==2]
>> ## Error in eval(expr, envir, enclos): object 'pulse' not found
>> pulse.sf
>> ## Error in eval(expr, envir, enclos): object 'pulse.sf' not
>> found
>>
>> What's going on? I can actually download the survey and view it on Excel.
>>
>> Appreciate any help that I can get.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ulrik.stervbo at gmail.com  Thu Aug 18 20:01:57 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 18 Aug 2016 18:01:57 +0000
Subject: [R] Retrieving data from survey in R Studio
In-Reply-To: <CAA-FpKW2-_C9fR-Q_Xj_H1WAusMHq33AT6piz+b562ZRTKkKKA@mail.gmail.com>
References: <MWHPR01MB2703AC0F6BC3D8401E70A378C9150@MWHPR01MB2703.prod.exchangelabs.com>
	<CAKVAULNRZW=n3tMJ8A1nE1HKW8H9jzGtWzAncqoU8tYMyWumjA@mail.gmail.com>
	<CAA-FpKW2-_C9fR-Q_Xj_H1WAusMHq33AT6piz+b562ZRTKkKKA@mail.gmail.com>
Message-ID: <CAKVAULMMFfMt+MLof-xPm_WcUfa9XFBOSU8CFiQD63beAgNo=g@mail.gmail.com>

Thanks for clarifying

Bob Rudis <bob at rud.is> schrieb am Do., 18. Aug. 2016 19:41:

> Ulrik: you can absolutely read from a URL in read.csv() with that syntax.
>
> The error `## Error in attach(survey): object 'survey' not found`
> suggests that the OP mis-typed something in the `survey` name in the
> assignment from `read.csv()`.
>
> However, the OP has quite a bit more to be concerned about than the
> missing variable in the environment if their stats program is encouraging
> both no spaces between operators and the use of `attach()`.
>
> On Thu, Aug 18, 2016 at 1:26 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> wrote:
>
>> I don't think you can read files into R like that. This answer
>> http://stackoverflow.com/questions/3236651/read-data-from-internet on
>> Stack
>> Overflow tells you, you could use the RCurl package.
>>
>> Here are more examples on getting data from online sources
>> https://www.r-bloggers.com/getting-data-from-an-online-source/
>>
>> You could also just download the file manually and open it using read.scv
>>
>> Hope this helps,
>> Ulrik
>>
>> On Thu, 18 Aug 2016 at 19:10 Barathan Roy Pinas <
>> bpin3104 at uni.sydney.edu.au>
>> wrote:
>>
>> > Hello,
>> >
>> >
>> > I have been given a .csv file and it is not loading. This is what I did.
>> >
>> >
>> > survey=read.csv("
>> > http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/survey.csv")
>> > attach(survey)
>> > pulse.sf=pulse[smoke==1 & sex==2]
>> > pulse.sf
>> >
>> > Template link here<
>> http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/p4.Rnw
>> > >.
>> >
>> > I insert the file into the R commands section for question 1. Doing that
>> > produces the following below:
>> >
>> >
>> > survey <- read.csv(file="
>> > http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/survey.csv")
>> > attach(survey)
>> >
>> > ## Error in attach(survey): object 'survey' not found
>> > pulse.sf=pulse[smoke==1 & sex==2]
>> > ## Error in eval(expr, envir, enclos): object 'pulse' not found
>> > pulse.sf
>> > ## Error in eval(expr, envir, enclos): object 'pulse.sf' not
>> > found
>> >
>> > What's going on? I can actually download the survey and view it on
>> Excel.
>> >
>> > Appreciate any help that I can get.
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Thu Aug 18 20:49:03 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 18 Aug 2016 13:49:03 -0500
Subject: [R] loop function
In-Reply-To: <CAJvXuh5pV17wjvb2ZAOMc2myxP1ZAv_3T5h6tU0HU9itGa=txg@mail.gmail.com>
References: <CAJvXuh5pV17wjvb2ZAOMc2myxP1ZAv_3T5h6tU0HU9itGa=txg@mail.gmail.com>
Message-ID: <CAN5YmCGzX27EtvjscUc8OOSezeNuv5pkLnHEXyHM62ytfNf1+g@mail.gmail.com>

You seemed to have re-written over the "b" object in your code.
This might work for you.

library(MASS)
for (i in 58:1){
  for(j in 58:i){
    str.temp <- paste("y1 ~ x", i, "* x", j, sep = "")
    univar <- glm.nb(as.formula(str.temp), data=df)
    b <- summary(univar)$coeffients[4, 4]
    if(b < 0.6){
      cat(i, j, b, "\n")
    }
  }
}

By the way, you should post using plain text (not html).

Jean


On Thu, Aug 18, 2016 at 6:48 AM, fatimah soleimany <
fatimah.soleimany at gmail.com> wrote:

> Hi Dear users,
> for an interactive use, i am trying to write a loop that looks for all
> variables in the conditions which i introduced, this is what I'm trying:
>
> library(MASS)> i=1> for (i in 58:1){+ for(j in 58:i){+ + str.temp <-
> paste("y1 ~ x", i, "* x", j, sep = "")+
> univar<-glm.nb(as.formula(str.temp), data=df)+
> b=summary(univar)$coeffients[4,4]+ b<-c(i,j)+ if(b < 0.6){ +
> print(b)+    }+   }+   }
>
> i have no error but i didn't get true response too, my result is this:
>
>
> b[1] 1 1
>
>  but i want all the variables that their p-value are less than 0.6, i
> think i couldn't write a true loop,can you help me?
>
> thank you in advance for any help
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From alemu.tadesse at gmail.com  Thu Aug 18 20:29:53 2016
From: alemu.tadesse at gmail.com (Alemu Tadesse)
Date: Thu, 18 Aug 2016 11:29:53 -0700
Subject: [R] Regressing the residuals on the country dummies
In-Reply-To: <2fceb07ed4414d0c96462f26bc41e192@winhexbeeu15.win.mail>
References: <776A2CBA-3D1B-4A99-B455-C23F06D5345A@gmail.com>
	<2fceb07ed4414d0c96462f26bc41e192@winhexbeeu15.win.mail>
Message-ID: <CACGkHRPV7SEoq2pbQ2onPXW+OWAk8ri9n6ZnFqiS1jwub5UgBA@mail.gmail.com>

Dear All,

I am wondering if someone knows an R equivalent of the following API call
in python.

"-----"

import time
import pandas as pd
start_time = time.clock()
timer =time.clock()
import pkg_resources
pkg_resources.require("pysimplesoap==1.05a")
from pysimplesoap.client import SoapClient


import os
import numpy as np

            client = SoapClient(wsdl="
https://solardata.com/service.asmx?wsdl")
            result = client.GetCsvWeatherData8(
                userName='alex at solardata.com',password='passw at word1
',licenseNumber='X1952c9wv',
                latitude=lati, longitude=loni,
                startDate='2013-02-10T00:00:00',
endDate='2014-11-28T00:00:00',
                dataVersionId=8,
                spatialResolutionId='High1km',
                timeResolution='Minute',
                missingDataHandling='Blank',
                WindTemp=1,
                timeshift = 'No')

            weather ={}
            weather['csvWeather']=
result['GetCsvWeatherData8Result']['csvWeather']

Thanks,

Alemu


On Fri, Oct 2, 2015 at 12:31 PM, Linus Holtermann <holtermann at hwwi.org>
wrote:

> Hi,
>
> You have panel data or cross-sectional data? In the case you use
> cross-sectional data and "countries" are your observations (no repeated
> measure of them) and you regress the country-dummies on your residuals of
> the forgone regression, then there are as many regressors as observations.
> Consequently, is it not possible to estimate such a model since there are
> no degrees of freedom left.
>
> Mit freundlichen Gr??en
>
>
> Linus Holtermann
> Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
> Heimhuder Stra?e 71
> 20148 Hamburg
> Tel +49-(0)40-340576-336
> Fax+49-(0)40-340576-776
> Internet: www.hwwi.org
> Email: holtermann at hwwi.org
>
> Amtsgericht Hamburg HRB 94303
> Gesch?ftsf?hrer: Prof. Dr. Henning V?pel
> Prokura: Dipl. Kauffrau Alexis Malchin
> Umsatzsteuer-ID: DE 241849425
>
>
> -----Urspr?ngliche Nachricht-----
> Von: R-help [mailto:r-help-bounces at r-project.org] Im Auftrag von Johanna
> von Bahr
> Gesendet: Donnerstag, 1. Oktober 2015 21:15
> An: r-help at r-project.org
> Betreff: [R] Regressing the residuals on the country dummies
>
> I?m trying to estimate a model regressing the residuals on the country
> dummies as follows; model.resC <- lm(model2$res ~ as.factor(Country))
> summary(model.resC)
>
> As I call the model I get the following results regarding the residuals:
>
> "ALL 90 residuals are 0: no residual degrees of freedom!"
>
> What has gone wrong?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bob at rud.is  Thu Aug 18 19:41:16 2016
From: bob at rud.is (Bob Rudis)
Date: Thu, 18 Aug 2016 13:41:16 -0400
Subject: [R] Retrieving data from survey in R Studio
In-Reply-To: <CAKVAULNRZW=n3tMJ8A1nE1HKW8H9jzGtWzAncqoU8tYMyWumjA@mail.gmail.com>
References: <MWHPR01MB2703AC0F6BC3D8401E70A378C9150@MWHPR01MB2703.prod.exchangelabs.com>
	<CAKVAULNRZW=n3tMJ8A1nE1HKW8H9jzGtWzAncqoU8tYMyWumjA@mail.gmail.com>
Message-ID: <CAA-FpKW2-_C9fR-Q_Xj_H1WAusMHq33AT6piz+b562ZRTKkKKA@mail.gmail.com>

Ulrik: you can absolutely read from a URL in read.csv() with that syntax.

The error `## Error in attach(survey): object 'survey' not found` suggests
that the OP mis-typed something in the `survey` name in the assignment from
`read.csv()`.

However, the OP has quite a bit more to be concerned about than the missing
variable in the environment if their stats program is encouraging both no
spaces between operators and the use of `attach()`.

On Thu, Aug 18, 2016 at 1:26 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
wrote:

> I don't think you can read files into R like that. This answer
> http://stackoverflow.com/questions/3236651/read-data-from-internet on
> Stack
> Overflow tells you, you could use the RCurl package.
>
> Here are more examples on getting data from online sources
> https://www.r-bloggers.com/getting-data-from-an-online-source/
>
> You could also just download the file manually and open it using read.scv
>
> Hope this helps,
> Ulrik
>
> On Thu, 18 Aug 2016 at 19:10 Barathan Roy Pinas <
> bpin3104 at uni.sydney.edu.au>
> wrote:
>
> > Hello,
> >
> >
> > I have been given a .csv file and it is not loading. This is what I did.
> >
> >
> > survey=read.csv("
> > http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/survey.csv")
> > attach(survey)
> > pulse.sf=pulse[smoke==1 & sex==2]
> > pulse.sf
> >
> > Template link here<http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/p4.
> Rnw
> > >.
> >
> > I insert the file into the R commands section for question 1. Doing that
> > produces the following below:
> >
> >
> > survey <- read.csv(file="
> > http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/survey.csv")
> > attach(survey)
> >
> > ## Error in attach(survey): object 'survey' not found
> > pulse.sf=pulse[smoke==1 & sex==2]
> > ## Error in eval(expr, envir, enclos): object 'pulse' not found
> > pulse.sf
> > ## Error in eval(expr, envir, enclos): object 'pulse.sf' not
> > found
> >
> > What's going on? I can actually download the survey and view it on Excel.
> >
> > Appreciate any help that I can get.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From divakarreddy.a at gmail.com  Thu Aug 18 22:41:41 2016
From: divakarreddy.a at gmail.com (Divakar Reddy)
Date: Thu, 18 Aug 2016 13:41:41 -0700
Subject: [R] rhive with PAM
Message-ID: <CALEm3d2X90sJVpOAxUfjPOt6Ob+hE+8gr_LfW5Z83W4Cesr0BQ@mail.gmail.com>

Hi,


Can you help me on this?


Can we implement PAM authentication for rhive? If yes, Can you suggest me
if you have any documentation?


Is rhive going to use RODBC/JDBC connection to connect hiveserver2? or
requests directly going to namenode?



Here are my connection details:

library(RODBC)

library(RHive)

rhive.init(hiveHome="/usr/hdp/current/hive-client/",hadoopHome="/usr/hdp/current/hadoop-client")

rhive.connect(host="<hive server
IP>",port=10000,defaultFS="hdfs://<NameNode
IP>:8020",user="************",password="**********", hiveServer2=TRUE)


Thanks for your help.



Thanks,

Divakar

Phoenix, US

	[[alternative HTML version deleted]]


From oriolebaltimore at gmail.com  Thu Aug 18 23:33:23 2016
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Thu, 18 Aug 2016 17:33:23 -0400
Subject: [R] remove rows based on row mean
Message-ID: <CAL2fYnOH=zMj2RexqjRWC4Jj_4bJ-NMTfX5YJxB0XVUCnGztLQ@mail.gmail.com>

Hi Group,
I have a data matrix sm (dput code given below).

I want to create a data matrix with rows with same variable that have
higher mean.

> sm
     Gene GSM529305 GSM529306 GSM529307 GSM529308
1    A1BG      6.57      6.72      6.83      6.69
2    A1CF      2.91      2.80      3.08      3.00
3   A2LD1      5.82      7.01      6.62      6.87
4     A2M      9.21      9.35      9.32      9.19
5     A2M      2.94      2.50      3.16      2.76
6  A4GALT      6.86      5.75      6.06      7.04
7   A4GNT      3.97      3.56      4.22      3.88
8    AAA1      3.39      2.90      3.16      3.23
9    AAAS      8.26      8.63      8.40      8.70
10   AAAS      6.82      7.15      7.33      6.51

For example in rows 4 and 5 have same variable Gene A2M. I want to
select only row that has higher mean. I wrote the following code that
gives me duplicate rows with higher mean but I cannot properly write
the result. Could someone help.  Thanks

ugns <- unique(sm$Gene)

exwidh = c()

for(i in 1:length(ugns)){
k = ugns[i]
exwidh[i] <- sm[names(sort(rowMeans(sm[which(sm[,1]==k),2:ncol(sm)]),decreasing=TRUE)[1]),]
}





structure(list(Gene = c("A1BG", "A1CF", "A2LD1", "A2M", "A2M",
"A4GALT", "A4GNT", "AAA1", "AAAS", "AAAS"), GSM529305 = c(6.57,
2.91, 5.82, 9.21, 2.94, 6.86, 3.97, 3.39, 8.26, 6.82), GSM529306 = c(6.72,
2.8, 7.01, 9.35, 2.5, 5.75, 3.56, 2.9, 8.63, 7.15), GSM529307 = c(6.83,
3.08, 6.62, 9.32, 3.16, 6.06, 4.22, 3.16, 8.4, 7.33), GSM529308 = c(6.69,
3, 6.87, 9.19, 2.76, 7.04, 3.88, 3.23, 8.7, 6.51)), .Names = c("Gene",
"GSM529305", "GSM529306", "GSM529307", "GSM529308"), row.names = c(NA,
10L), class = "data.frame")


From roundsjeremiah at gmail.com  Fri Aug 19 00:21:12 2016
From: roundsjeremiah at gmail.com (jeremiah rounds)
Date: Thu, 18 Aug 2016 15:21:12 -0700
Subject: [R] remove rows based on row mean
In-Reply-To: <CAL2fYnOH=zMj2RexqjRWC4Jj_4bJ-NMTfX5YJxB0XVUCnGztLQ@mail.gmail.com>
References: <CAL2fYnOH=zMj2RexqjRWC4Jj_4bJ-NMTfX5YJxB0XVUCnGztLQ@mail.gmail.com>
Message-ID: <CAOjnRsa=CWfxLPy0k3y+JT693=8N_qUeFBhFxqn3PvYDyAWbSw@mail.gmail.com>

library(data.table)
setDT(dt)
op = function(s){
mean0 = apply(s, 1, mean)
ret = s[which.max(mean0)]
ret$mean = mean0
ret
}
max_row = dt[, op(.SD), by = "Gene"]

Thanks,
Jeremiah

On Thu, Aug 18, 2016 at 2:33 PM, Adrian Johnson <oriolebaltimore at gmail.com>
wrote:

> Hi Group,
> I have a data matrix sm (dput code given below).
>
> I want to create a data matrix with rows with same variable that have
> higher mean.
>
> > sm
>      Gene GSM529305 GSM529306 GSM529307 GSM529308
> 1    A1BG      6.57      6.72      6.83      6.69
> 2    A1CF      2.91      2.80      3.08      3.00
> 3   A2LD1      5.82      7.01      6.62      6.87
> 4     A2M      9.21      9.35      9.32      9.19
> 5     A2M      2.94      2.50      3.16      2.76
> 6  A4GALT      6.86      5.75      6.06      7.04
> 7   A4GNT      3.97      3.56      4.22      3.88
> 8    AAA1      3.39      2.90      3.16      3.23
> 9    AAAS      8.26      8.63      8.40      8.70
> 10   AAAS      6.82      7.15      7.33      6.51
>
> For example in rows 4 and 5 have same variable Gene A2M. I want to
> select only row that has higher mean. I wrote the following code that
> gives me duplicate rows with higher mean but I cannot properly write
> the result. Could someone help.  Thanks
>
> ugns <- unique(sm$Gene)
>
> exwidh = c()
>
> for(i in 1:length(ugns)){
> k = ugns[i]
> exwidh[i] <- sm[names(sort(rowMeans(sm[which(sm[,1]==k),2:ncol(sm)]),
> decreasing=TRUE)[1]),]
> }
>
>
>
>
>
> structure(list(Gene = c("A1BG", "A1CF", "A2LD1", "A2M", "A2M",
> "A4GALT", "A4GNT", "AAA1", "AAAS", "AAAS"), GSM529305 = c(6.57,
> 2.91, 5.82, 9.21, 2.94, 6.86, 3.97, 3.39, 8.26, 6.82), GSM529306 = c(6.72,
> 2.8, 7.01, 9.35, 2.5, 5.75, 3.56, 2.9, 8.63, 7.15), GSM529307 = c(6.83,
> 3.08, 6.62, 9.32, 3.16, 6.06, 4.22, 3.16, 8.4, 7.33), GSM529308 = c(6.69,
> 3, 6.87, 9.19, 2.76, 7.04, 3.88, 3.23, 8.7, 6.51)), .Names = c("Gene",
> "GSM529305", "GSM529306", "GSM529307", "GSM529308"), row.names = c(NA,
> 10L), class = "data.frame")
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Aug 19 00:28:56 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 19 Aug 2016 08:28:56 +1000
Subject: [R] remove rows based on row mean
In-Reply-To: <CAL2fYnOH=zMj2RexqjRWC4Jj_4bJ-NMTfX5YJxB0XVUCnGztLQ@mail.gmail.com>
References: <CAL2fYnOH=zMj2RexqjRWC4Jj_4bJ-NMTfX5YJxB0XVUCnGztLQ@mail.gmail.com>
Message-ID: <CA+8X3fVzV3EguG=bvckR9tac7GbjOPqBzadB8qah9UHzXRqcJw@mail.gmail.com>

Hi Adrian,
Try this:

sm$rowmeans<-rowMeans(sm[,2:length(sm)])
sm<-sm[order(sm$Gene,sm$rowmeans,decreasing=TRUE),]
sm[-which(duplicated(sm$Gene)),]

Jim


On Fri, Aug 19, 2016 at 7:33 AM, Adrian Johnson
<oriolebaltimore at gmail.com> wrote:
> Hi Group,
> I have a data matrix sm (dput code given below).
>
> I want to create a data matrix with rows with same variable that have
> higher mean.
>
>> sm
>      Gene GSM529305 GSM529306 GSM529307 GSM529308
> 1    A1BG      6.57      6.72      6.83      6.69
> 2    A1CF      2.91      2.80      3.08      3.00
> 3   A2LD1      5.82      7.01      6.62      6.87
> 4     A2M      9.21      9.35      9.32      9.19
> 5     A2M      2.94      2.50      3.16      2.76
> 6  A4GALT      6.86      5.75      6.06      7.04
> 7   A4GNT      3.97      3.56      4.22      3.88
> 8    AAA1      3.39      2.90      3.16      3.23
> 9    AAAS      8.26      8.63      8.40      8.70
> 10   AAAS      6.82      7.15      7.33      6.51
>
> For example in rows 4 and 5 have same variable Gene A2M. I want to
> select only row that has higher mean. I wrote the following code that
> gives me duplicate rows with higher mean but I cannot properly write
> the result. Could someone help.  Thanks
>
> ugns <- unique(sm$Gene)
>
> exwidh = c()
>
> for(i in 1:length(ugns)){
> k = ugns[i]
> exwidh[i] <- sm[names(sort(rowMeans(sm[which(sm[,1]==k),2:ncol(sm)]),decreasing=TRUE)[1]),]
> }
>
>
>
>
>
> structure(list(Gene = c("A1BG", "A1CF", "A2LD1", "A2M", "A2M",
> "A4GALT", "A4GNT", "AAA1", "AAAS", "AAAS"), GSM529305 = c(6.57,
> 2.91, 5.82, 9.21, 2.94, 6.86, 3.97, 3.39, 8.26, 6.82), GSM529306 = c(6.72,
> 2.8, 7.01, 9.35, 2.5, 5.75, 3.56, 2.9, 8.63, 7.15), GSM529307 = c(6.83,
> 3.08, 6.62, 9.32, 3.16, 6.06, 4.22, 3.16, 8.4, 7.33), GSM529308 = c(6.69,
> 3, 6.87, 9.19, 2.76, 7.04, 3.88, 3.23, 8.7, 6.51)), .Names = c("Gene",
> "GSM529305", "GSM529306", "GSM529307", "GSM529308"), row.names = c(NA,
> 10L), class = "data.frame")
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roundsjeremiah at gmail.com  Fri Aug 19 00:31:17 2016
From: roundsjeremiah at gmail.com (jeremiah rounds)
Date: Thu, 18 Aug 2016 15:31:17 -0700
Subject: [R] remove rows based on row mean
In-Reply-To: <CAOjnRsa=CWfxLPy0k3y+JT693=8N_qUeFBhFxqn3PvYDyAWbSw@mail.gmail.com>
References: <CAL2fYnOH=zMj2RexqjRWC4Jj_4bJ-NMTfX5YJxB0XVUCnGztLQ@mail.gmail.com>
	<CAOjnRsa=CWfxLPy0k3y+JT693=8N_qUeFBhFxqn3PvYDyAWbSw@mail.gmail.com>
Message-ID: <CAOjnRsYhOqCBB4vTnhcG_K-sNFNjxmr5_aRSGTH67X_3PVBOxw@mail.gmail.com>

oh I forgot I renamed sm.

dt = sm
library(data.table)
setDT(dt)
op = function(s){
mean0 = apply(s, 1, mean)
ret = s[which.max(mean0)]
ret$mean = mean0
ret
}
max_row = dt[, op(.SD), by = "Gene"]


Thanks,
Jeremiah

On Thu, Aug 18, 2016 at 3:21 PM, jeremiah rounds <roundsjeremiah at gmail.com>
wrote:

> library(data.table)
> setDT(dt)
> op = function(s){
> mean0 = apply(s, 1, mean)
> ret = s[which.max(mean0)]
> ret$mean = mean0
> ret
> }
> max_row = dt[, op(.SD), by = "Gene"]
>
> Thanks,
> Jeremiah
>
> On Thu, Aug 18, 2016 at 2:33 PM, Adrian Johnson <oriolebaltimore at gmail.com
> > wrote:
>
>> Hi Group,
>> I have a data matrix sm (dput code given below).
>>
>> I want to create a data matrix with rows with same variable that have
>> higher mean.
>>
>> > sm
>>      Gene GSM529305 GSM529306 GSM529307 GSM529308
>> 1    A1BG      6.57      6.72      6.83      6.69
>> 2    A1CF      2.91      2.80      3.08      3.00
>> 3   A2LD1      5.82      7.01      6.62      6.87
>> 4     A2M      9.21      9.35      9.32      9.19
>> 5     A2M      2.94      2.50      3.16      2.76
>> 6  A4GALT      6.86      5.75      6.06      7.04
>> 7   A4GNT      3.97      3.56      4.22      3.88
>> 8    AAA1      3.39      2.90      3.16      3.23
>> 9    AAAS      8.26      8.63      8.40      8.70
>> 10   AAAS      6.82      7.15      7.33      6.51
>>
>> For example in rows 4 and 5 have same variable Gene A2M. I want to
>> select only row that has higher mean. I wrote the following code that
>> gives me duplicate rows with higher mean but I cannot properly write
>> the result. Could someone help.  Thanks
>>
>> ugns <- unique(sm$Gene)
>>
>> exwidh = c()
>>
>> for(i in 1:length(ugns)){
>> k = ugns[i]
>> exwidh[i] <- sm[names(sort(rowMeans(sm[which(sm[,1]==k),2:ncol(sm)]),decr
>> easing=TRUE)[1]),]
>> }
>>
>>
>>
>>
>>
>> structure(list(Gene = c("A1BG", "A1CF", "A2LD1", "A2M", "A2M",
>> "A4GALT", "A4GNT", "AAA1", "AAAS", "AAAS"), GSM529305 = c(6.57,
>> 2.91, 5.82, 9.21, 2.94, 6.86, 3.97, 3.39, 8.26, 6.82), GSM529306 = c(6.72,
>> 2.8, 7.01, 9.35, 2.5, 5.75, 3.56, 2.9, 8.63, 7.15), GSM529307 = c(6.83,
>> 3.08, 6.62, 9.32, 3.16, 6.06, 4.22, 3.16, 8.4, 7.33), GSM529308 = c(6.69,
>> 3, 6.87, 9.19, 2.76, 7.04, 3.88, 3.23, 8.7, 6.51)), .Names = c("Gene",
>> "GSM529305", "GSM529306", "GSM529307", "GSM529308"), row.names = c(NA,
>> 10L), class = "data.frame")
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From oriolebaltimore at gmail.com  Fri Aug 19 00:33:27 2016
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Thu, 18 Aug 2016 18:33:27 -0400
Subject: [R] remove rows based on row mean
In-Reply-To: <CA+8X3fVzV3EguG=bvckR9tac7GbjOPqBzadB8qah9UHzXRqcJw@mail.gmail.com>
References: <CAL2fYnOH=zMj2RexqjRWC4Jj_4bJ-NMTfX5YJxB0XVUCnGztLQ@mail.gmail.com>
	<CA+8X3fVzV3EguG=bvckR9tac7GbjOPqBzadB8qah9UHzXRqcJw@mail.gmail.com>
Message-ID: <CAL2fYnP2A6L8V1Y9jeY3HO5ti2B0yQBuOdX8Qo=2GVS=UqVvug@mail.gmail.com>

Wow. This is much cleaner and smarter than the for loop, cbind
thanks a lot .

On Thu, Aug 18, 2016 at 6:28 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Adrian,
> Try this:
>
> sm$rowmeans<-rowMeans(sm[,2:length(sm)])
> sm<-sm[order(sm$Gene,sm$rowmeans,decreasing=TRUE),]
> sm[-which(duplicated(sm$Gene)),]
>
> Jim
>
>
> On Fri, Aug 19, 2016 at 7:33 AM, Adrian Johnson
> <oriolebaltimore at gmail.com> wrote:
>> Hi Group,
>> I have a data matrix sm (dput code given below).
>>
>> I want to create a data matrix with rows with same variable that have
>> higher mean.
>>
>>> sm
>>      Gene GSM529305 GSM529306 GSM529307 GSM529308
>> 1    A1BG      6.57      6.72      6.83      6.69
>> 2    A1CF      2.91      2.80      3.08      3.00
>> 3   A2LD1      5.82      7.01      6.62      6.87
>> 4     A2M      9.21      9.35      9.32      9.19
>> 5     A2M      2.94      2.50      3.16      2.76
>> 6  A4GALT      6.86      5.75      6.06      7.04
>> 7   A4GNT      3.97      3.56      4.22      3.88
>> 8    AAA1      3.39      2.90      3.16      3.23
>> 9    AAAS      8.26      8.63      8.40      8.70
>> 10   AAAS      6.82      7.15      7.33      6.51
>>
>> For example in rows 4 and 5 have same variable Gene A2M. I want to
>> select only row that has higher mean. I wrote the following code that
>> gives me duplicate rows with higher mean but I cannot properly write
>> the result. Could someone help.  Thanks
>>
>> ugns <- unique(sm$Gene)
>>
>> exwidh = c()
>>
>> for(i in 1:length(ugns)){
>> k = ugns[i]
>> exwidh[i] <- sm[names(sort(rowMeans(sm[which(sm[,1]==k),2:ncol(sm)]),decreasing=TRUE)[1]),]
>> }
>>
>>
>>
>>
>>
>> structure(list(Gene = c("A1BG", "A1CF", "A2LD1", "A2M", "A2M",
>> "A4GALT", "A4GNT", "AAA1", "AAAS", "AAAS"), GSM529305 = c(6.57,
>> 2.91, 5.82, 9.21, 2.94, 6.86, 3.97, 3.39, 8.26, 6.82), GSM529306 = c(6.72,
>> 2.8, 7.01, 9.35, 2.5, 5.75, 3.56, 2.9, 8.63, 7.15), GSM529307 = c(6.83,
>> 3.08, 6.62, 9.32, 3.16, 6.06, 4.22, 3.16, 8.4, 7.33), GSM529308 = c(6.69,
>> 3, 6.87, 9.19, 2.76, 7.04, 3.88, 3.23, 8.7, 6.51)), .Names = c("Gene",
>> "GSM529305", "GSM529306", "GSM529307", "GSM529308"), row.names = c(NA,
>> 10L), class = "data.frame")
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jwd at surewest.net  Fri Aug 19 05:41:18 2016
From: jwd at surewest.net (John Dougherty)
Date: Thu, 18 Aug 2016 20:41:18 -0700
Subject: [R] Retrieving data from survey in R Studio
In-Reply-To: <MWHPR01MB2703AC0F6BC3D8401E70A378C9150@MWHPR01MB2703.prod.exchangelabs.com>
References: <MWHPR01MB2703AC0F6BC3D8401E70A378C9150@MWHPR01MB2703.prod.exchangelabs.com>
Message-ID: <20160818204118.4ad54b34@draco>

On Thu, 18 Aug 2016 09:19:05 +0000
Barathan Roy Pinas <bpin3104 at uni.sydney.edu.au> wrote:

> Hello,
> 
> 
> I have been given a .csv file and it is not loading. This is what I
> did.
> 
> 
> survey=read.csv("http://www.maths.usyd.edu.au/u/UG/IM/STAT2012/r/survey.csv")
> attach(survey)
> pulse.sf=pulse[smoke==1 & sex==2]
> pulse.sf
> 
...

A couple of points.  First, your question addresses RStudio which has
its own list.  Next, the issue appears to be homework, and that is
not something many will help you with.  However, since the actual issue
is generic to R, let that slide. You want to be sure the address is
correctly typed. Is the "r" supposed to be lower case? Then, do you
have the appropriate permissions to enter that page? Since that is a
university server, you may need to be logged in through your student
account to access the page with the data.  Even if you are, will it
let RStudio access it?  It would probably be simplest to simply download
the data to your system, then read in the local copy.

-- 

John


From bgunter.4567 at gmail.com  Thu Aug 18 22:09:02 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 18 Aug 2016 13:09:02 -0700
Subject: [R] Regressing the residuals on the country dummies
In-Reply-To: <CACGkHRPV7SEoq2pbQ2onPXW+OWAk8ri9n6ZnFqiS1jwub5UgBA@mail.gmail.com>
References: <776A2CBA-3D1B-4A99-B455-C23F06D5345A@gmail.com>
	<2fceb07ed4414d0c96462f26bc41e192@winhexbeeu15.win.mail>
	<CACGkHRPV7SEoq2pbQ2onPXW+OWAk8ri9n6ZnFqiS1jwub5UgBA@mail.gmail.com>
Message-ID: <CAGxFJbSremBFjNP4atVMMk5fp_Pp19RJNR7iX_Nsgem_0ZV-MA@mail.gmail.com>

1. Have you checked out package Rpy/Rpy2?

2. I don't know Python, but as you seem to be trying to get data from
the web, see the Rcurl package, maybe, to do these things in R.

3.  Hopefully someone who does know Python can give you better answers.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Aug 18, 2016 at 11:29 AM, Alemu Tadesse <alemu.tadesse at gmail.com> wrote:
> Dear All,
>
> I am wondering if someone knows an R equivalent of the following API call
> in python.
>
> "-----"
>
> import time
> import pandas as pd
> start_time = time.clock()
> timer =time.clock()
> import pkg_resources
> pkg_resources.require("pysimplesoap==1.05a")
> from pysimplesoap.client import SoapClient
>
>
> import os
> import numpy as np
>
>             client = SoapClient(wsdl="
> https://solardata.com/service.asmx?wsdl")
>             result = client.GetCsvWeatherData8(
>                 userName='alex at solardata.com',password='passw at word1
> ',licenseNumber='X1952c9wv',
>                 latitude=lati, longitude=loni,
>                 startDate='2013-02-10T00:00:00',
> endDate='2014-11-28T00:00:00',
>                 dataVersionId=8,
>                 spatialResolutionId='High1km',
>                 timeResolution='Minute',
>                 missingDataHandling='Blank',
>                 WindTemp=1,
>                 timeshift = 'No')
>
>             weather ={}
>             weather['csvWeather']=
> result['GetCsvWeatherData8Result']['csvWeather']
>
> Thanks,
>
> Alemu
>
>
> On Fri, Oct 2, 2015 at 12:31 PM, Linus Holtermann <holtermann at hwwi.org>
> wrote:
>
>> Hi,
>>
>> You have panel data or cross-sectional data? In the case you use
>> cross-sectional data and "countries" are your observations (no repeated
>> measure of them) and you regress the country-dummies on your residuals of
>> the forgone regression, then there are as many regressors as observations.
>> Consequently, is it not possible to estimate such a model since there are
>> no degrees of freedom left.
>>
>> Mit freundlichen Gr??en
>>
>>
>> Linus Holtermann
>> Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
>> Heimhuder Stra?e 71
>> 20148 Hamburg
>> Tel +49-(0)40-340576-336
>> Fax+49-(0)40-340576-776
>> Internet: www.hwwi.org
>> Email: holtermann at hwwi.org
>>
>> Amtsgericht Hamburg HRB 94303
>> Gesch?ftsf?hrer: Prof. Dr. Henning V?pel
>> Prokura: Dipl. Kauffrau Alexis Malchin
>> Umsatzsteuer-ID: DE 241849425
>>
>>
>> -----Urspr?ngliche Nachricht-----
>> Von: R-help [mailto:r-help-bounces at r-project.org] Im Auftrag von Johanna
>> von Bahr
>> Gesendet: Donnerstag, 1. Oktober 2015 21:15
>> An: r-help at r-project.org
>> Betreff: [R] Regressing the residuals on the country dummies
>>
>> I?m trying to estimate a model regressing the residuals on the country
>> dummies as follows; model.resC <- lm(model2$res ~ as.factor(Country))
>> summary(model.resC)
>>
>> As I call the model I get the following results regarding the residuals:
>>
>> "ALL 90 residuals are 0: no residual degrees of freedom!"
>>
>> What has gone wrong?
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alemu.tadesse at gmail.com  Thu Aug 18 23:46:01 2016
From: alemu.tadesse at gmail.com (Alemu Tadesse)
Date: Thu, 18 Aug 2016 14:46:01 -0700
Subject: [R] Regressing the residuals on the country dummies
In-Reply-To: <CAGxFJbSremBFjNP4atVMMk5fp_Pp19RJNR7iX_Nsgem_0ZV-MA@mail.gmail.com>
References: <776A2CBA-3D1B-4A99-B455-C23F06D5345A@gmail.com>
	<2fceb07ed4414d0c96462f26bc41e192@winhexbeeu15.win.mail>
	<CACGkHRPV7SEoq2pbQ2onPXW+OWAk8ri9n6ZnFqiS1jwub5UgBA@mail.gmail.com>
	<CAGxFJbSremBFjNP4atVMMk5fp_Pp19RJNR7iX_Nsgem_0ZV-MA@mail.gmail.com>
Message-ID: <CACGkHRPtQTYJ7qVqw6y_wBSAh6c+mNiosSc_dsUcwjUHdGobaQ@mail.gmail.com>

Thank you Bert.
Both rpy and ypy2 are to use R in python. I have never seen a package (that
works) to call python script in R.

Best,

Alemu


On Thu, Aug 18, 2016 at 1:09 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> 1. Have you checked out package Rpy/Rpy2?
>
> 2. I don't know Python, but as you seem to be trying to get data from
> the web, see the Rcurl package, maybe, to do these things in R.
>
> 3.  Hopefully someone who does know Python can give you better answers.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Aug 18, 2016 at 11:29 AM, Alemu Tadesse <alemu.tadesse at gmail.com>
> wrote:
> > Dear All,
> >
> > I am wondering if someone knows an R equivalent of the following API call
> > in python.
> >
> > "-----"
> >
> > import time
> > import pandas as pd
> > start_time = time.clock()
> > timer =time.clock()
> > import pkg_resources
> > pkg_resources.require("pysimplesoap==1.05a")
> > from pysimplesoap.client import SoapClient
> >
> >
> > import os
> > import numpy as np
> >
> >             client = SoapClient(wsdl="
> > https://solardata.com/service.asmx?wsdl")
> >             result = client.GetCsvWeatherData8(
> >                 userName='alex at solardata.com',password='passw at word1
> > ',licenseNumber='X1952c9wv',
> >                 latitude=lati, longitude=loni,
> >                 startDate='2013-02-10T00:00:00',
> > endDate='2014-11-28T00:00:00',
> >                 dataVersionId=8,
> >                 spatialResolutionId='High1km',
> >                 timeResolution='Minute',
> >                 missingDataHandling='Blank',
> >                 WindTemp=1,
> >                 timeshift = 'No')
> >
> >             weather ={}
> >             weather['csvWeather']=
> > result['GetCsvWeatherData8Result']['csvWeather']
> >
> > Thanks,
> >
> > Alemu
> >
> >
> > On Fri, Oct 2, 2015 at 12:31 PM, Linus Holtermann <holtermann at hwwi.org>
> > wrote:
> >
> >> Hi,
> >>
> >> You have panel data or cross-sectional data? In the case you use
> >> cross-sectional data and "countries" are your observations (no repeated
> >> measure of them) and you regress the country-dummies on your residuals
> of
> >> the forgone regression, then there are as many regressors as
> observations.
> >> Consequently, is it not possible to estimate such a model since there
> are
> >> no degrees of freedom left.
> >>
> >> Mit freundlichen Gr??en
> >>
> >>
> >> Linus Holtermann
> >> Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
> >> Heimhuder Stra?e 71
> >> 20148 Hamburg
> >> Tel +49-(0)40-340576-336
> >> Fax+49-(0)40-340576-776
> >> Internet: www.hwwi.org
> >> Email: holtermann at hwwi.org
> >>
> >> Amtsgericht Hamburg HRB 94303
> >> Gesch?ftsf?hrer: Prof. Dr. Henning V?pel
> >> Prokura: Dipl. Kauffrau Alexis Malchin
> >> Umsatzsteuer-ID: DE 241849425
> >>
> >>
> >> -----Urspr?ngliche Nachricht-----
> >> Von: R-help [mailto:r-help-bounces at r-project.org] Im Auftrag von
> Johanna
> >> von Bahr
> >> Gesendet: Donnerstag, 1. Oktober 2015 21:15
> >> An: r-help at r-project.org
> >> Betreff: [R] Regressing the residuals on the country dummies
> >>
> >> I?m trying to estimate a model regressing the residuals on the country
> >> dummies as follows; model.resC <- lm(model2$res ~ as.factor(Country))
> >> summary(model.resC)
> >>
> >> As I call the model I get the following results regarding the residuals:
> >>
> >> "ALL 90 residuals are 0: no residual degrees of freedom!"
> >>
> >> What has gone wrong?
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From strunky at gmail.com  Fri Aug 19 00:12:38 2016
From: strunky at gmail.com (Jacob Strunk)
Date: Thu, 18 Aug 2016 15:12:38 -0700
Subject: [R] package.skeleton, environment argument causes error
Message-ID: <CAKo8+cg3L==w5N517XmBv1o-P7Sap6QacP+Vn9j3QTJy5GF7pw@mail.gmail.com>

Hello, I have been using package.skeleton from within an lapply statement
successfully (assuming good source code) with the following setup in the
past:

x=try(package.skeleton(package_name,path=pathi,code_files=file_i))


but now fails with error:

Error: evaluation nested too deeply: infinite recursion /
options(expressions=)?

I am working in RStudio Version 0.99.896, with 64 bit R version 3.3.1
(2016-06-21)




I have been probing the code for package.skeleton a bit and noticed that
the default arguments for 'list' and 'environment' are supplied in the
function definition, thus making it impossible to achieve the conditions

envIsMissing=TRUE
missing(list) = TRUE


as a result of the fact that missing(list) cannot be true, the classesList
argument is empty and the call

classes0 <- .fixPackageFileNames(classesList)


then fails with the error

Error: evaluation nested too deeply: infinite recursion /
options(expressions=)?


If I remove the default arguments I get further, but get the same error  I
had before (Error: evaluation nested too deeply: infinite recursion /
options(expressions=)?) after executing the following code:

methods0 <- .fixPackageFileNames(methodsList)


and the contents of methodsList look like

An object of class "ObjectsWithPackage":

Object:
Package:


the function .fixPackageFileNames fails when it reaches

list <- as.character(list)


where in this case the contents of 'list' look like

str(list)
Formal class 'ObjectsWithPackage' [package "methods"] with 2 slots
  ..@ .Data  : chr(0)
  ..@ package: chr(0)


I am not sure if the problem arose from changes to package.skeleton
or methods::getClasses and methods::getGenerics or if there is something
peculiar about my environment.

my current ugly fix is to define the function .fixPackageFileNames in the
global environment and add a try statement and exit when it results in an
object of class "try-error":

.fixPackageFileNames=
function (list)
{
    list <- *try(*as.character(list)*)*
    *if(class(list)=="try-error")return(list)*
    if (length(list) == 0L)
        return(list)
    list0 <- gsub("[[:cntrl:]\"*/:<>?\\|]", "_", list)
    wrong <- grep("^(con|prn|aux|clock\\$|nul|lpt[1-3]|com[1-4])(\\..*|)$",
        list0)
    if (length(wrong))
        list0[wrong] <- paste0("zz", list0[wrong])
    ok <- grepl("^[[:alnum:]]", list0)
    if (any(!ok))
        list0[!ok] <- paste0("z", list0[!ok])
    list1 <- tolower(list0)
    list2 <- make.unique(list1, sep = "_")
    changed <- (list2 != list1)
    list0[changed] <- list2[changed]
    list0
}


Any assistance with this error would be greatly appreciated!

Thank you,

-- 
Jacob Strunk
strunky at gmail.com

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Aug 19 11:41:02 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 19 Aug 2016 09:41:02 +0000
Subject: [R] character vector manipulation and saving
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039B5B@SRVEXCHMBX.precheza.cz>

Dear all


I have charater vector which is result of readLines reading of a file. Something like

dput(test[1:15])
c("Date", "42523", "Comment received", "dfvadfvadfbvadfbv fvbadfvdfv cfczfbffbvfdv", "Date", "42523", "Comment received", "aaaaaaaaaaaaaa bbbbbbbbbbbbbbbbbbb ccccccccccccccccccccccccc", "Date", "42523", "Comment received", "nvnvnvnv kfgkgkgkgkg kkkkkk", "hallo world", "alpha beta gamma", "Date")

I an interested only in some lines and I want them to be saved as separate txt files. So far I can get the numbers of line which shall be read, based on following values

> dput(start)
c(3L, 7L, 11L)
> dput(end)
c(5L, 9L, 15L)

and I am interested in lines just between start and end. Sometimes there is only one line sometimes more. So I constructed following vectors

> dput(radky)
c(4, 8, 12)
> dput(pocet)
c(0, 0, 2)

And I can select lines of interest
do.call(c, mapply( seq, radky, radky+pocet))
[1]   4   8  12  13  14

However I actually want to save line 4 as one txt file, line 8 as another txt file and lines 12,13 and 14 pasted together as one file and so on.

I am not sure if 8191 limit to character strings still holds but I believe that yes and so plain paste could be problematic if more lines has to be concatenated (some strings are more than 1000 character long and if several has to be pasted it could be a problem).

So, please is there any option how to handle such task? The problem is not big, about 10000 lines (character vectors).

Petr

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From marc_grt at yahoo.fr  Fri Aug 19 12:44:33 2016
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Fri, 19 Aug 2016 12:44:33 +0200
Subject: [R] R Shiny convert into Java
In-Reply-To: <CAAM-fZ7stB0nX8okf-8F9WB_G7vKz4+Nu5RJwYej=1sTVQQ4zg@mail.gmail.com>
References: <CAAM-fZ7stB0nX8okf-8F9WB_G7vKz4+Nu5RJwYej=1sTVQQ4zg@mail.gmail.com>
Message-ID: <b9d3fa3f-45da-8e8d-5c10-a4c4a31a6fe8@yahoo.fr>

You should try these:
http://www.renjin.org
https://github.com/allr/purdue-fastr

which are two R interpreters in Java. But I am not sure that shiny can 
work on these.

Sincerely

Marc

Le 16/08/2016 ? 15:11, Venky a ?crit :
> Hi,
>
> How to run Shiny (Server,UI) into JAVA?
>
> I am running R Shiny app using R
> But i want to run those functions in Java without dependent of R
> Please help me on this anyone
>
>
> Thanks and Regards
> Venkatesan
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From anantsaini10 at gmail.com  Fri Aug 19 12:13:13 2016
From: anantsaini10 at gmail.com (Anant Saini)
Date: Fri, 19 Aug 2016 15:43:13 +0530
Subject: [R] facing problem in setting order of the levels in factor
Message-ID: <CAPvUJ8idpzEMtW5UOwNvkSLAGqyw9DjejErLqu7rQcGC6n6pYQ@mail.gmail.com>

Hi all,

I'm just a beginner in R. I have a pretty basic doubt. This is the actual
quote I wrote
> x<-factor(c("M","F","M","T","M","T"))
> levels(x)=c("M","F","T")
> x
[1] F M F T F T
Levels: M F T
> table(x)
x
M F T
1 3 2

Expectation: I just wanted to change my baselevel from F to M. with the
number of M and F remaining constant

What exactly happened: The values of F and M also get exchanged along with
the change of base level from F to M


?Best,?

-- 

*Anant Saini*
------------------------------
*Indian Institute of Technology Bombay*
*Mob: +91 - 9967687330 *
*LinkedIn* : *in.linkedin.com/in/anantsaini*
<http://in.linkedin.com/in/anantsaini>

	[[alternative HTML version deleted]]


From holderjustin at hotmail.co.uk  Fri Aug 19 13:01:22 2016
From: holderjustin at hotmail.co.uk (Justin Holder)
Date: Fri, 19 Aug 2016 11:01:22 +0000
Subject: [R] RJDBC - Java connection to Oracle database crashing on execution
Message-ID: <DB5PR10MB02617151C29F442514D95A8F95160@DB5PR10MB0261.EURPRD10.PROD.OUTLOOK.COM>

Hi,

I have a script that starts with some code to open a connection to an Oracle database, however the code is crashing R/RStudio as soon as it runs. The code does run successfully on another machine.

The script opens by loading the required RJDBC package:

library("RJDBC", lib.loc="C:/Program Files/R/R-3.3.1/library")

After, this I run the code below that points to the required ojdbc7.jar file, that should start the connection, however this crashes R, closing it down a few seconds later:

drv = JDBC("oracle.jdbc.OracleDriver",
               classPath="C:/Program Files/R/ojdbc7.jar", " ")

The same thing happens in Rstudio - there is no error message, the program simply crashes stating that "R encountered a fatal error . The session was terminated".

Again, the code executes exactly as written on a another machine.I have the latest versions of all required software/packages, so I'm not sure what is causing the crash.


Thanks.

	[[alternative HTML version deleted]]


From vin.voelkel.2 at googlemail.com  Fri Aug 19 13:21:31 2016
From: vin.voelkel.2 at googlemail.com (=?iso-8859-1?Q?Vinzenz_V=F6lkel?=)
Date: Fri, 19 Aug 2016 13:21:31 +0200
Subject: [R] problem concernig Survsplit, package survival
Message-ID: <003501d1fa0b$d7026e20$85074a60$@googlemail.com>

Dear R-help-community,

 

I hope, that?s the appropiate channel to post a quastion?

 

For some days I have been struggling with a problem concerning the
?survSplit?-function of the package ?survival?. Searching the internet I
have found a pretty good -German- description of Daniel Wollschl?ger
describing how to use survSplit:

 

(https://books.google.de/books?id=9G4oBgAAQBAJ
<https://books.google.de/books?id=9G4oBgAAQBAJ&pg=PA345&lpg=PA345&dq=daniel+
wollschl%C3%A4ger+survsplit&source=bl&ots=ajPgInB83d&sig=noQIAXMWe6oQJ-LwsTC
kroWdwHQ&hl=de&sa=X&ved=0ahUKEwiqwoX8q83OAhVlM5oKHSMGDrEQ6AEIHjAA#v=onepage&
q=daniel%20wollschl%C3%A4ger%20survsplit&f=false>
&pg=PA345&lpg=PA345&dq=daniel+wollschl%C3%A4ger+survsplit&source=bl&ots=ajPg
InB83d&sig=noQIAXMWe6oQJ-LwsTCkroWdwHQ&hl=de&sa=X&ved=0ahUKEwiqwoX8q83OAhVlM
5oKHSMGDrEQ6AEIHjAA#v=onepage&q=daniel%20wollschl%C3%A4ger%20survsplit&f=fal
se

 

Mr. Wollschl?ger also provides the dataset, all of the code he used and an
excerpt of his output:

 

 

> library(survival) # f?r survSplit()

> dfSurvCP <- survSplit(dfSurv, cut=seq(30, 90, by=30), end="obsT",

+ event="status", start="start", id="ID", zero=0)

# sortiere nach Beobachtungsobjekt und linken Intervallgrenzen

> idxOrd <- order(dfSurvCP$ID, dfSurvCP$start)

> head(dfSurvCP[idxOrd, ], n=7)

obsT    status sex      X                     IV        start     ID

1          30        0          f           -1.3130607     A         0
1

181      60        0          f           -1.3130607     A         30
1

361      63        1          f           -1.3130607     A         60
1

10        11        1          f           -1.2282824     A         0
10

100      27        1          m         -0.1018403     B         0
100

101      30        0          m         -0.4079027     B         0
101

281      42        1          m         -0.4079027     B         30
101

 

 

Unfortunaltely when I tried to copy Mr. Wollschl?gers operations using his
very dataset, RStudio just returned the following error-message:

 

> dfSurvCP2 <-
survSplit(dfSurv,cut=seq(30,90,by=30),end="obsT",event="status",start="start
",id="ID",zero=0)

Error in formula.default(eval(parse(text = x, keep.source = FALSE)[[1L]])) :


  invalid formula

 

I tried to figure out what?s wrong, but so far didn?t find any solutions? I
would be very glad if anyone could help me out here.

 

vhfv

 


	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Aug 19 14:59:35 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 19 Aug 2016 12:59:35 +0000
Subject: [R] file.create issue
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039BDF@SRVEXCHMBX.precheza.cz>

Hi

Can anybody explain why one character makes such a difference?

> file.create("com1.txt")
[1] FALSE
Warning message:
In file.create("com1.txt") :
  cannot create file 'com1.txt', reason 'No such file or directory'
> file.create("con1.txt")
[1] TRUE
>

It took me quite effort to find out that "com1.txt" is not valid for naming a file.

BTW I am on Windows, if it matters.

Best regards
Petr


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ivan.calandra at univ-reims.fr  Fri Aug 19 15:10:26 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Fri, 19 Aug 2016 15:10:26 +0200
Subject: [R] facing problem in setting order of the levels in factor
In-Reply-To: <CAPvUJ8idpzEMtW5UOwNvkSLAGqyw9DjejErLqu7rQcGC6n6pYQ@mail.gmail.com>
References: <CAPvUJ8idpzEMtW5UOwNvkSLAGqyw9DjejErLqu7rQcGC6n6pYQ@mail.gmail.com>
Message-ID: <5dccac0b-0e6f-fc10-eebc-4a523b3361d8@univ-reims.fr>

Hi,

I think you are looking for this:

y <- factor(x, levels=c("M","F","T"))

If you use the function levels(), you change the labels, but not the 
order, so that the first level (previously "F") will now be labeled "M", 
the second (previously "M") will now be labeled "F" ,and so on.
This explains why in the table(x) at the end you get the same 
frequencies in the same order, but the frequencies are associated with 
different labels/levels.

To change the order of the levels (but without changing the actual 
data), you need to change the level argument of the factor() function.

I hope this makes it clear, although I can imagine that my explanation 
is not crystal clear...

Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 19/08/2016 ? 12:13, Anant Saini a ?crit :
> Hi all,
>
> I'm just a beginner in R. I have a pretty basic doubt. This is the actual
> quote I wrote
>> x<-factor(c("M","F","M","T","M","T"))
>> levels(x)=c("M","F","T")
>> x
> [1] F M F T F T
> Levels: M F T
>> table(x)
> x
> M F T
> 1 3 2
>
> Expectation: I just wanted to change my baselevel from F to M. with the
> number of M and F remaining constant
>
> What exactly happened: The values of F and M also get exchanged along with
> the change of base level from F to M
>
>
> ?Best,?
>


From ivan.calandra at univ-reims.fr  Fri Aug 19 15:12:32 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Fri, 19 Aug 2016 15:12:32 +0200
Subject: [R] file.create issue
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039BDF@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039BDF@SRVEXCHMBX.precheza.cz>
Message-ID: <b3d2a5af-6d18-e5d0-53dd-c057dd8cc537@univ-reims.fr>

Hi Petr,

I think it does matter, because it seems there is no problem on Mac OS 
10.9.5.
Now, don't ask me why, I have no idea!

Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 19/08/2016 ? 14:59, PIKAL Petr a ?crit :
> Hi
>
> Can anybody explain why one character makes such a difference?
>
>> file.create("com1.txt")
> [1] FALSE
> Warning message:
> In file.create("com1.txt") :
>    cannot create file 'com1.txt', reason 'No such file or directory'
>> file.create("con1.txt")
> [1] TRUE
> It took me quite effort to find out that "com1.txt" is not valid for naming a file.
>
> BTW I am on Windows, if it matters.
>
> Best regards
> Petr
>
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Fri Aug 19 15:15:22 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Fri, 19 Aug 2016 13:15:22 +0000
Subject: [R] file.create issue
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039BDF@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039BDF@SRVEXCHMBX.precheza.cz>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83656F0FE@FHSDB2D11-2.csu.mcmaster.ca>

Dear Petr,

This is a Windows OS issue, not peculiar to R. There are some reserved names that can't be used for files, including COM1 (the first serial port). Other examples include LPT1 and AUX. Because file names in windows are case-insensitive "com1.txt" also causes problems.

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL Petr
> Sent: August 19, 2016 9:00 AM
> To: r-help at r-project.org
> Subject: [R] file.create issue
> 
> Hi
> 
> Can anybody explain why one character makes such a difference?
> 
> > file.create("com1.txt")
> [1] FALSE
> Warning message:
> In file.create("com1.txt") :
>   cannot create file 'com1.txt', reason 'No such file or directory'
> > file.create("con1.txt")
> [1] TRUE
> >
> 
> It took me quite effort to find out that "com1.txt" is not valid for naming a file.
> 
> BTW I am on Windows, if it matters.
> 
> Best regards
> Petr
> 
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen?
> jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze
> sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to
> z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce
> s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m
> dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost
> ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo
> p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender.
> Delete the contents of this e-mail with all attachments and its copies from your
> system.
> If you are not the intended recipient of this e-mail, you are not authorized to
> use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by
> modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept
> such offer; The sender of this e-mail (offer) excludes any acceptance of the
> offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an
> express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into
> any contracts on behalf of the company except for cases in which he/she is
> expressly authorized to do so in writing, and such authorization or power of
> attorney is submitted to the recipient or the person represented by the
> recipient, or the existence of such authorization is known to the recipient of the
> person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From petr.pikal at precheza.cz  Fri Aug 19 15:47:30 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 19 Aug 2016 13:47:30 +0000
Subject: [R] file.create issue
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC83656F0FE@FHSDB2D11-2.csu.mcmaster.ca>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039BDF@SRVEXCHMBX.precheza.cz>
	<ACD1644AA6C67E4FBD0C350625508EC83656F0FE@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039C05@SRVEXCHMBX.precheza.cz>

Thank you , John.

As I wanted to use com as abbreviated value for comments it gave me hard time, especially when the name was not only com1 but "com1.txt".

Best regards
Petr


> -----Original Message-----
> From: Fox, John [mailto:jfox at mcmaster.ca]
> Sent: Friday, August 19, 2016 3:15 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help at r-project.org
> Subject: RE: file.create issue
>
> Dear Petr,
>
> This is a Windows OS issue, not peculiar to R. There are some reserved
> names that can't be used for files, including COM1 (the first serial port).
> Other examples include LPT1 and AUX. Because file names in windows are
> case-insensitive "com1.txt" also causes problems.
>
> I hope this helps,
>  John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL
> > Petr
> > Sent: August 19, 2016 9:00 AM
> > To: r-help at r-project.org
> > Subject: [R] file.create issue
> >
> > Hi
> >
> > Can anybody explain why one character makes such a difference?
> >
> > > file.create("com1.txt")
> > [1] FALSE
> > Warning message:
> > In file.create("com1.txt") :
> >   cannot create file 'com1.txt', reason 'No such file or directory'
> > > file.create("con1.txt")
> > [1] TRUE
> > >
> >
> > It took me quite effort to find out that "com1.txt" is not valid for naming a
> file.
> >
> > BTW I am on Windows, if it matters.
> >
> > Best regards
> > Petr
> >

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Fri Aug 19 15:53:16 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 19 Aug 2016 13:53:16 +0000
Subject: [R] character vector manipulation and saving
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039B5B@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039B5B@SRVEXCHMBX.precheza.cz>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039C32@SRVEXCHMBX.precheza.cz>

Hi all.

I managed to achieve desired with

for (i in 1:length(radky)) {
fname <- paste("coment",i,".txt", sep="")
file.create(fname)
fileCon <- file(fname, "w")
writeLines(test[radky[i] : (radky+pocet)[i]], fileCon)
close(fileCon)
}

For all on Windows - do not use "com1.txt" for file naming (see my other mail :-)

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL Petr
> Sent: Friday, August 19, 2016 11:41 AM
> To: r-help at r-project.org
> Subject: [R] character vector manipulation and saving
>
> Dear all
>
>
> I have charater vector which is result of readLines reading of a file. Something
> like
>
> dput(test[1:15])
> c("Date", "42523", "Comment received", "dfvadfvadfbvadfbv fvbadfvdfv
> cfczfbffbvfdv", "Date", "42523", "Comment received", "aaaaaaaaaaaaaa
> bbbbbbbbbbbbbbbbbbb ccccccccccccccccccccccccc", "Date", "42523",
> "Comment received", "nvnvnvnv kfgkgkgkgkg kkkkkk", "hallo world", "alpha
> beta gamma", "Date")
>
> I an interested only in some lines and I want them to be saved as separate txt
> files. So far I can get the numbers of line which shall be read, based on
> following values
>
> > dput(start)
> c(3L, 7L, 11L)
> > dput(end)
> c(5L, 9L, 15L)
>
> and I am interested in lines just between start and end. Sometimes there is
> only one line sometimes more. So I constructed following vectors
>
> > dput(radky)
> c(4, 8, 12)
> > dput(pocet)
> c(0, 0, 2)
>
> And I can select lines of interest
> do.call(c, mapply( seq, radky, radky+pocet))
> [1]   4   8  12  13  14
>
> However I actually want to save line 4 as one txt file, line 8 as another txt file
> and lines 12,13 and 14 pasted together as one file and so on.
>
> I am not sure if 8191 limit to character strings still holds but I believe that yes
> and so plain paste could be problematic if more lines has to be concatenated
> (some strings are more than 1000 character long and if several has to be
> pasted it could be a problem).
>
> So, please is there any option how to handle such task? The problem is not
> big, about 10000 lines (character vectors).
>
> Petr
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen?
> jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze
> sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a
> to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m
> dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost
> ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo
> p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender.
> Delete the contents of this e-mail with all attachments and its copies from
> your system.
> If you are not the intended recipient of this e-mail, you are not authorized to
> use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused
> by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately
> accept such offer; The sender of this e-mail (offer) excludes any acceptance
> of the offer on the part of the recipient containing any amendment or
> variation.
> - the sender insists on that the respective contract is concluded only upon an
> express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into
> any contracts on behalf of the company except for cases in which he/she is
> expressly authorized to do so in writing, and such authorization or power of
> attorney is submitted to the recipient or the person represented by the
> recipient, or the existence of such authorization is known to the recipient of
> the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From oriolebaltimore at gmail.com  Fri Aug 19 23:22:34 2016
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Fri, 19 Aug 2016 17:22:34 -0400
Subject: [R] pheatmap breaks
Message-ID: <CAL2fYnOVLBuCdqmrSSfVzt2+-heASp9cm7-jZCnTSHsWj6pz_w@mail.gmail.com>

Hi group:
I tried multiple times cannot understand the breaks to work for my heatmap.

I am using following way:

pheatmap(chxx,

cluster_cols=FALSE,
annotation_col=annotcols,
annotation_colors=anno_colors,
col=colorRampPalette(c("dark blue", "white", "#ff0000"))(34),
show_colnames=F)


> max(chxx)
[1] 4.421862
> min(chxx)
[1] -3.324021


I want to plot anything above 1.96 as red,  anything below -1.96 as blue
1.195  as pink and 0 - 0.99 as gradient of white pink.

similarly, < -1.96 as blue,    values greater than -1.96 less that -1
gets light blue and 0 to -0.99 get white gradient to blue.


there will be 7 breaks

  < - 1.96--- - 1-  -.99---- 0 ------0.99-1---1.96---->1.96

how can I define the breaks.

appreciate your help. Thanks in advance.

Adrian


From dwinsemius at comcast.net  Sat Aug 20 01:16:35 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 19 Aug 2016 16:16:35 -0700
Subject: [R] file.create issue
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039C05@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039BDF@SRVEXCHMBX.precheza.cz>
	<ACD1644AA6C67E4FBD0C350625508EC83656F0FE@FHSDB2D11-2.csu.mcmaster.ca>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039C05@SRVEXCHMBX.precheza.cz>
Message-ID: <B9295405-96DF-4381-8031-9281E557B2B0@comcast.net>


> On Aug 19, 2016, at 6:47 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
> Thank you , John.
> 
> As I wanted to use com as abbreviated value for comments it gave me hard time, especially when the name was not only com1 but "com1.txt".
> 

Whinges about the behavior of Windows are OT on Rhelp.

-- 
David.

> Best regards
> Petr
> 
> 
>> -----Original Message-----
>> From: Fox, John [mailto:jfox at mcmaster.ca]
>> Sent: Friday, August 19, 2016 3:15 PM
>> To: PIKAL Petr <petr.pikal at precheza.cz>
>> Cc: r-help at r-project.org
>> Subject: RE: file.create issue
>> 
>> Dear Petr,
>> 
>> This is a Windows OS issue, not peculiar to R. There are some reserved
>> names that can't be used for files, including COM1 (the first serial port).
>> Other examples include LPT1 and AUX. Because file names in windows are
>> case-insensitive "com1.txt" also causes problems.
>> 
>> I hope this helps,
>> John
>> 
>> -----------------------------
>> John Fox, Professor
>> McMaster University
>> Hamilton, Ontario
>> Canada L8S 4M4
>> Web: socserv.mcmaster.ca/jfox
>> 
>> 
>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL
>>> Petr
>>> Sent: August 19, 2016 9:00 AM
>>> To: r-help at r-project.org
>>> Subject: [R] file.create issue
>>> 
>>> Hi
>>> 
>>> Can anybody explain why one character makes such a difference?
>>> 
>>>> file.create("com1.txt")
>>> [1] FALSE
>>> Warning message:
>>> In file.create("com1.txt") :
>>>  cannot create file 'com1.txt', reason 'No such file or directory'
>>>> file.create("con1.txt")
>>> [1] TRUE
>>>> 
>>> 
>>> It took me quite effort to find out that "com1.txt" is not valid for naming a
>> file.
>>> 
>>> BTW I am on Windows, if it matters.
>>> 
>>> Best regards
>>> Petr
>>> 
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Sat Aug 20 02:14:15 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 19 Aug 2016 17:14:15 -0700
Subject: [R] file.create issue
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039C05@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039BDF@SRVEXCHMBX.precheza.cz>
	<ACD1644AA6C67E4FBD0C350625508EC83656F0FE@FHSDB2D11-2.csu.mcmaster.ca>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039C05@SRVEXCHMBX.precheza.cz>
Message-ID: <CAF8bMcaudao7j9PMJPHga7MTgncJHzGsSp_iox67iLhNbzLkvw@mail.gmail.com>

The list of illegal file names on Windows 7 includes "aux", "prn",
"lpt[1-9]", "com[1-9]", and "con",
with or without a 'dot file extension' and in any directory.  I think there
used to be be other illegal ones,
like "nul", "pc$mouse" and "clock".

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Aug 19, 2016 at 6:47 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Thank you , John.
>
> As I wanted to use com as abbreviated value for comments it gave me hard
> time, especially when the name was not only com1 but "com1.txt".
>
> Best regards
> Petr
>
>
> > -----Original Message-----
> > From: Fox, John [mailto:jfox at mcmaster.ca]
> > Sent: Friday, August 19, 2016 3:15 PM
> > To: PIKAL Petr <petr.pikal at precheza.cz>
> > Cc: r-help at r-project.org
> > Subject: RE: file.create issue
> >
> > Dear Petr,
> >
> > This is a Windows OS issue, not peculiar to R. There are some reserved
> > names that can't be used for files, including COM1 (the first serial
> port).
> > Other examples include LPT1 and AUX. Because file names in windows are
> > case-insensitive "com1.txt" also causes problems.
> >
> > I hope this helps,
> >  John
> >
> > -----------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario
> > Canada L8S 4M4
> > Web: socserv.mcmaster.ca/jfox
> >
> >
> >
> > > -----Original Message-----
> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL
> > > Petr
> > > Sent: August 19, 2016 9:00 AM
> > > To: r-help at r-project.org
> > > Subject: [R] file.create issue
> > >
> > > Hi
> > >
> > > Can anybody explain why one character makes such a difference?
> > >
> > > > file.create("com1.txt")
> > > [1] FALSE
> > > Warning message:
> > > In file.create("com1.txt") :
> > >   cannot create file 'com1.txt', reason 'No such file or directory'
> > > > file.create("con1.txt")
> > > [1] TRUE
> > > >
> > >
> > > It took me quite effort to find out that "com1.txt" is not valid for
> naming a
> > file.
> > >
> > > BTW I am on Windows, if it matters.
> > >
> > > Best regards
> > > Petr
> > >
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sat Aug 20 02:36:51 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 20 Aug 2016 12:36:51 +1200
Subject: [R] [FORGED] Re:  file.create issue
In-Reply-To: <B9295405-96DF-4381-8031-9281E557B2B0@comcast.net>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039BDF@SRVEXCHMBX.precheza.cz>
	<ACD1644AA6C67E4FBD0C350625508EC83656F0FE@FHSDB2D11-2.csu.mcmaster.ca>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5039C05@SRVEXCHMBX.precheza.cz>
	<B9295405-96DF-4381-8031-9281E557B2B0@comcast.net>
Message-ID: <cfb14b87-cc4a-28b2-e26b-22b059f6bb4b@auckland.ac.nz>

On 20/08/16 11:16, David Winsemius wrote:
>
>> On Aug 19, 2016, at 6:47 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>
>> Thank you , John.
>>
>> As I wanted to use com as abbreviated value for comments it gave me hard time, especially when the name was not only com1 but "com1.txt".
>>
>
> Whinges about the behavior of Windows are OT on Rhelp.

I disagree!  Whinges about the behaviour of Windoze are *on topic*, all 
the time, everywhere! :-)

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From rebeccapayne at gmail.com  Fri Aug 19 20:22:15 2016
From: rebeccapayne at gmail.com (Rebecca Payne)
Date: Fri, 19 Aug 2016 13:22:15 -0500
Subject: [R] Efficiently parallelize across columns of a data.table
Message-ID: <CAF7pjVF+m0aVHA4OQAiJXyytq99ZQbadsnOr+6QsGYYq2ymfgQ@mail.gmail.com>

I am trying to parallelize a task across columns of a data.table using
foreach and doParallel. My data is large relative to my system memory
(about 40%) so I'm avoiding making any copies of the full table. The
function I am parallelizing is pretty simple, taking as input a fixed set
of columns and a single unique column per task. I'd like to send only the
small subset of columns actually needed to the worker nodes. I'd also like
the option to only send a subset of rows to the worker nodes. My initial
attempts to parallelize did not work as expected, and seemed to copy the
entire data.table to every worker node.





### start code ###

library(data.table)

library(foreach)

library(doParallel)

registerDoParallel()



anotherVar = "Y"

someVars = paste0("X", seq(1:20))

N = 100000000

# I've chosen N such that my Rsession consumes ~15GB of memory according to
top right after DT is created

DT = as.data.table(matrix(rnorm(21*N), ncol=21))

setnames(DT, c(anotherVar, someVars))



MyFun = function(inDT, inX, inY){

  cor(inDT[[inX]], inDT[[inY]])

}



#Warning: Will throw an error on the mac GUI

corrWithY_1 = foreach(i = 1:length(someVars), .combine = c) %dopar%

  MyFun(DT[,c(anotherVar, someVars[i]), with=FALSE], someVars[i],
anotherVar)

# Watching top, all of the slave nodes also appear to consume the full
~15Gb of system memory



gc()



# So I tried creating an entirely separate subset of DT to send to the
slave nodes, and then removing it by hand.

# This task, too, appears to take ~15GB of memory per slave node according
to top.



MyFun2 = function(DT, anotherVar, uniqueVar){

  tmpData = DT[, c(anotherVar, uniqueVar), with=FALSE]

  out = MyFun(tmpData, anotherVar, uniqueVar)

  rm(tmpData)

  return(out)

}



corrWithY_2 = foreach(i = 1:length(someVars), .combine = c) %dopar%

  MyFun2(DT, anotherVar, someVars[i])



### end code ###



Another thing I've tried is to send only the name of DT and it's
environment to the slave nodes, but `get`doesn't seem to be able to only
get a subset of rows from DT, as I would need to do frequently



Questions:

1. Is top accurately reflecting my R session's memory usage?

2. If so, is there a way to parallelize over the columns of a data.table
without copying the entire table to every slave node?

	[[alternative HTML version deleted]]


From jason.j.foster at gmail.com  Sat Aug 20 00:30:11 2016
From: jason.j.foster at gmail.com (Jason Foster)
Date: Fri, 19 Aug 2016 18:30:11 -0400
Subject: [R] C/C++/Fortran Rolling Window Regressions
Message-ID: <57b7886b.c5a0370a.47c8a.ce10@mx.google.com>

I looked into why the coefficients differ in Gabor's example and it's because the example mistakenly switched the order of x and y. The syntax is roll::roll_lm(x, y), which is the same as fastLm, but the example accidentally switched them. After correcting the example, the coefficients are all equal for lm, fastLm, and roll_lm:

library(xts)
library(RcppArmadillo)
library(roll)

set.seed(1)
z <- xts(matrix(rnorm(10), ncol = 2),
         seq(as.Date("2016-08-15"), by = "day", length.out = 5))
colnames(z) <- c("y", "x")

fastLm <- rollapplyr(z, width = 4,
                    function(x) coef(fastLm(cbind(1, x[ , 2]), x[ , 1])),
                    by.column = FALSE)
colnames(fastLm) <- c("(Intercept)", "x")

lm <- rollapplyr(z, width = 4,
                function(x) coef(lm(y ~ x, data = as.data.frame(x))),
                by.column = FALSE)
colnames(lm) <- c("(Intercept)", "x")

roll_lm <- roll_lm(z[ , 2], z[ , 1], 4)$coefficients

all.equal(lm, fastLm)
# [1] TRUE
all.equal(lm, roll_lm)
# [1] TRUE

	[[alternative HTML version deleted]]


From peter.langfelder at gmail.com  Sat Aug 20 06:01:01 2016
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Fri, 19 Aug 2016 21:01:01 -0700
Subject: [R] Efficiently parallelize across columns of a data.table
In-Reply-To: <CAF7pjVF+m0aVHA4OQAiJXyytq99ZQbadsnOr+6QsGYYq2ymfgQ@mail.gmail.com>
References: <CAF7pjVF+m0aVHA4OQAiJXyytq99ZQbadsnOr+6QsGYYq2ymfgQ@mail.gmail.com>
Message-ID: <CA+hbrhUf-DX5wN+abb2LMvsZ0WUxfJn7G0957B+EPw5BVHeA8w@mail.gmail.com>

Last time I looked (admittedly a few years back), on unix-alikes
(which you seem to be using, based on your use of top),
foreach/doParallel used forking. This means each worker gets a copy of
the entire R session, __but__ modern operating systems do not actually
copy on spawn, they only copy on write (i.e., when the worker process
starts modifying the existing variables). I believe top shows memory
use as if the copy actually occurred (what the operating system
promises to each worker).

I would run the code and monitor usage of swap space - as long as the
system isn't swapping to disk, I would not worry about copying the
table to every slave node, since the copy doesn't really happen unless
the worker processes modify the table.

HTH,

Peter

On Fri, Aug 19, 2016 at 11:22 AM, Rebecca Payne <rebeccapayne at gmail.com> wrote:
> I am trying to parallelize a task across columns of a data.table using
> foreach and doParallel. My data is large relative to my system memory
> (about 40%) so I'm avoiding making any copies of the full table. The
> function I am parallelizing is pretty simple, taking as input a fixed set
> of columns and a single unique column per task. I'd like to send only the
> small subset of columns actually needed to the worker nodes. I'd also like
> the option to only send a subset of rows to the worker nodes. My initial
> attempts to parallelize did not work as expected, and seemed to copy the
> entire data.table to every worker node.
>
>
>
>
>
> ### start code ###
>
> library(data.table)
>
> library(foreach)
>
> library(doParallel)
>
> registerDoParallel()
>
>
>
> anotherVar = "Y"
>
> someVars = paste0("X", seq(1:20))
>
> N = 100000000
>
> # I've chosen N such that my Rsession consumes ~15GB of memory according to
> top right after DT is created
>
> DT = as.data.table(matrix(rnorm(21*N), ncol=21))
>
> setnames(DT, c(anotherVar, someVars))
>
>
>
> MyFun = function(inDT, inX, inY){
>
>   cor(inDT[[inX]], inDT[[inY]])
>
> }
>
>
>
> #Warning: Will throw an error on the mac GUI
>
> corrWithY_1 = foreach(i = 1:length(someVars), .combine = c) %dopar%
>
>   MyFun(DT[,c(anotherVar, someVars[i]), with=FALSE], someVars[i],
> anotherVar)
>
> # Watching top, all of the slave nodes also appear to consume the full
> ~15Gb of system memory
>
>
>
> gc()
>
>
>
> # So I tried creating an entirely separate subset of DT to send to the
> slave nodes, and then removing it by hand.
>
> # This task, too, appears to take ~15GB of memory per slave node according
> to top.
>
>
>
> MyFun2 = function(DT, anotherVar, uniqueVar){
>
>   tmpData = DT[, c(anotherVar, uniqueVar), with=FALSE]
>
>   out = MyFun(tmpData, anotherVar, uniqueVar)
>
>   rm(tmpData)
>
>   return(out)
>
> }
>
>
>
> corrWithY_2 = foreach(i = 1:length(someVars), .combine = c) %dopar%
>
>   MyFun2(DT, anotherVar, someVars[i])
>
>
>
> ### end code ###
>
>
>
> Another thing I've tried is to send only the name of DT and it's
> environment to the slave nodes, but `get`doesn't seem to be able to only
> get a subset of rows from DT, as I would need to do frequently
>
>
>
> Questions:
>
> 1. Is top accurately reflecting my R session's memory usage?
>
> 2. If so, is there a way to parallelize over the columns of a data.table
> without copying the entire table to every slave node?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sat Aug 20 11:22:31 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 20 Aug 2016 19:22:31 +1000
Subject: [R] pheatmap breaks
In-Reply-To: <CAL2fYnOVLBuCdqmrSSfVzt2+-heASp9cm7-jZCnTSHsWj6pz_w@mail.gmail.com>
References: <CAL2fYnOVLBuCdqmrSSfVzt2+-heASp9cm7-jZCnTSHsWj6pz_w@mail.gmail.com>
Message-ID: <CA+8X3fX3-_0VdHc+nYYjT8AOdRkcxy=PkOpYK2fv_Kk0pho1RA@mail.gmail.com>

Hi Adrian,
I had to add an extra color, but this might do what you want:

chxx<-matrix(runif(100,-3.32,4.422),nrow=10)
chxx.cut<-as.numeric(cut(chxx,breaks=c(-3.5,-1.96,-1,0,1,1.96,5)))
chxx.col<-c("#0000FF","#8888FF","#AAAAFF","#FF8888","#FFAAAA",NA)[chxx.cut]
library(plotrix)
chxx_highcol<-color.scale(chxx[chxx>1.96],extremes=c("#FFAAAA","#FFFFFF"))
chxx.col<-matrix(chxx.col,nrow=10)
chxx.col[is.na(chxx.col)]<-chxx_highcol
color2D.matplot(chxx,cellcolors=chxx.col,show.values=TRUE)

Jim


On Sat, Aug 20, 2016 at 7:22 AM, Adrian Johnson
<oriolebaltimore at gmail.com> wrote:
> Hi group:
> I tried multiple times cannot understand the breaks to work for my heatmap.
>
> I am using following way:
>
> pheatmap(chxx,
>
> cluster_cols=FALSE,
> annotation_col=annotcols,
> annotation_colors=anno_colors,
> col=colorRampPalette(c("dark blue", "white", "#ff0000"))(34),
> show_colnames=F)
>
>
>> max(chxx)
> [1] 4.421862
>> min(chxx)
> [1] -3.324021
>
>
> I want to plot anything above 1.96 as red,  anything below -1.96 as blue
> 1.195  as pink and 0 - 0.99 as gradient of white pink.
>
> similarly, < -1.96 as blue,    values greater than -1.96 less that -1
> gets light blue and 0 to -0.99 get white gradient to blue.
>
>
> there will be 7 breaks
>
>   < - 1.96--- - 1-  -.99---- 0 ------0.99-1---1.96---->1.96
>
> how can I define the breaks.
>
> appreciate your help. Thanks in advance.
>
> Adrian
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From naresh_gurbuxani at hotmail.com  Sat Aug 20 14:28:04 2016
From: naresh_gurbuxani at hotmail.com (Naresh Gurbuxani)
Date: Sat, 20 Aug 2016 12:28:04 +0000
Subject: [R] autocorrelation function plot in lattice
Message-ID: <CY1PR07MB2588D44191068BBB9F4CFC75FA170@CY1PR07MB2588.namprd07.prod.outlook.com>

Using lattice package, is it possible to plot autocorrelation functions similar to acf in stats?

Thanks,
Naresh

	[[alternative HTML version deleted]]


From rebeccapayne at gmail.com  Sat Aug 20 21:41:09 2016
From: rebeccapayne at gmail.com (Rebecca Payne)
Date: Sat, 20 Aug 2016 14:41:09 -0500
Subject: [R] Efficiently parallelize across columns of a data.table
In-Reply-To: <CA+hbrhUf-DX5wN+abb2LMvsZ0WUxfJn7G0957B+EPw5BVHeA8w@mail.gmail.com>
References: <CAF7pjVF+m0aVHA4OQAiJXyytq99ZQbadsnOr+6QsGYYq2ymfgQ@mail.gmail.com>
	<CA+hbrhUf-DX5wN+abb2LMvsZ0WUxfJn7G0957B+EPw5BVHeA8w@mail.gmail.com>
Message-ID: <CAF7pjVEVur7WtJ2xcUT1nXmoTgKV1CV4W0J6M5LM8r-kH4eAHQ@mail.gmail.com>

Makes sense. Thanks for the clear explanation.

Rebecca

On Friday, August 19, 2016, Peter Langfelder <peter.langfelder at gmail.com
<javascript:_e(%7B%7D,'cvml','peter.langfelder at gmail.com');>> wrote:

> Last time I looked (admittedly a few years back), on unix-alikes
> (which you seem to be using, based on your use of top),
> foreach/doParallel used forking. This means each worker gets a copy of
> the entire R session, __but__ modern operating systems do not actually
> copy on spawn, they only copy on write (i.e., when the worker process
> starts modifying the existing variables). I believe top shows memory
> use as if the copy actually occurred (what the operating system
> promises to each worker).
>
> I would run the code and monitor usage of swap space - as long as the
> system isn't swapping to disk, I would not worry about copying the
> table to every slave node, since the copy doesn't really happen unless
> the worker processes modify the table.
>
> HTH,
>
> Peter
>
> On Fri, Aug 19, 2016 at 11:22 AM, Rebecca Payne <rebeccapayne at gmail.com>
> wrote:
> > I am trying to parallelize a task across columns of a data.table using
> > foreach and doParallel. My data is large relative to my system memory
> > (about 40%) so I'm avoiding making any copies of the full table. The
> > function I am parallelizing is pretty simple, taking as input a fixed set
> > of columns and a single unique column per task. I'd like to send only the
> > small subset of columns actually needed to the worker nodes. I'd also
> like
> > the option to only send a subset of rows to the worker nodes. My initial
> > attempts to parallelize did not work as expected, and seemed to copy the
> > entire data.table to every worker node.
> >
> >
> >
> >
> >
> > ### start code ###
> >
> > library(data.table)
> >
> > library(foreach)
> >
> > library(doParallel)
> >
> > registerDoParallel()
> >
> >
> >
> > anotherVar = "Y"
> >
> > someVars = paste0("X", seq(1:20))
> >
> > N = 100000000
> >
> > # I've chosen N such that my Rsession consumes ~15GB of memory according
> to
> > top right after DT is created
> >
> > DT = as.data.table(matrix(rnorm(21*N), ncol=21))
> >
> > setnames(DT, c(anotherVar, someVars))
> >
> >
> >
> > MyFun = function(inDT, inX, inY){
> >
> >   cor(inDT[[inX]], inDT[[inY]])
> >
> > }
> >
> >
> >
> > #Warning: Will throw an error on the mac GUI
> >
> > corrWithY_1 = foreach(i = 1:length(someVars), .combine = c) %dopar%
> >
> >   MyFun(DT[,c(anotherVar, someVars[i]), with=FALSE], someVars[i],
> > anotherVar)
> >
> > # Watching top, all of the slave nodes also appear to consume the full
> > ~15Gb of system memory
> >
> >
> >
> > gc()
> >
> >
> >
> > # So I tried creating an entirely separate subset of DT to send to the
> > slave nodes, and then removing it by hand.
> >
> > # This task, too, appears to take ~15GB of memory per slave node
> according
> > to top.
> >
> >
> >
> > MyFun2 = function(DT, anotherVar, uniqueVar){
> >
> >   tmpData = DT[, c(anotherVar, uniqueVar), with=FALSE]
> >
> >   out = MyFun(tmpData, anotherVar, uniqueVar)
> >
> >   rm(tmpData)
> >
> >   return(out)
> >
> > }
> >
> >
> >
> > corrWithY_2 = foreach(i = 1:length(someVars), .combine = c) %dopar%
> >
> >   MyFun2(DT, anotherVar, someVars[i])
> >
> >
> >
> > ### end code ###
> >
> >
> >
> > Another thing I've tried is to send only the name of DT and it's
> > environment to the slave nodes, but `get`doesn't seem to be able to only
> > get a subset of rows from DT, as I would need to do frequently
> >
> >
> >
> > Questions:
> >
> > 1. Is top accurately reflecting my R session's memory usage?
> >
> > 2. If so, is there a way to parallelize over the columns of a data.table
> > without copying the entire table to every slave node?
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Aug 20 22:31:07 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 20 Aug 2016 13:31:07 -0700
Subject: [R] problem concernig Survsplit, package survival
In-Reply-To: <003501d1fa0b$d7026e20$85074a60$@googlemail.com>
References: <003501d1fa0b$d7026e20$85074a60$@googlemail.com>
Message-ID: <152483F4-68E9-4545-A663-D98D6B5A3BB2@dcn.davis.ca.us>

Your link did not take me to the code you reference... Google does not make entire books available online which may have something to do with my difficulty.  This is one reason the Posting Guide asks you to post a self-contained, reproducible example. Your use of HTML format in your posting to the list was also a making it hard to follow. 

I did find a ZIP file at [1], and the arguments do not conform to the survSplit documentation. Since I have not been a user of this package over time, I don't know whether this is due to changes in the argument list or a simple error on the part of the author... but I suspect the latter because the missing formula specification seems intrinsic to the intent of the function. 

Someone else may chime in with a more conclusive comment, but I would recommend finding a different tutorial on the topic, or corresponding with Mr.Wollschlaeger.

[1] http://www.dwoll.de/r/gddmr/wollschlaeger_r_all.zip
-- 
Sent from my phone. Please excuse my brevity.

On August 19, 2016 4:21:31 AM PDT, "Vinzenz V?lkel via R-help" <r-help at r-project.org> wrote:
>Dear R-help-community,
>
> 
>
>I hope, that?s the appropiate channel to post a quastion?
>
> 
>
>For some days I have been struggling with a problem concerning the
>?survSplit?-function of the package ?survival?. Searching the internet
>I
>have found a pretty good -German- description of Daniel Wollschl?ger
>describing how to use survSplit:
>
> 
>
>(https://books.google.de/books?id=9G4oBgAAQBAJ
><https://books.google.de/books?id=9G4oBgAAQBAJ&pg=PA345&lpg=PA345&dq=daniel+
>wollschl%C3%A4ger+survsplit&source=bl&ots=ajPgInB83d&sig=noQIAXMWe6oQJ-LwsTC
>kroWdwHQ&hl=de&sa=X&ved=0ahUKEwiqwoX8q83OAhVlM5oKHSMGDrEQ6AEIHjAA#v=onepage&
>q=daniel%20wollschl%C3%A4ger%20survsplit&f=false>
>&pg=PA345&lpg=PA345&dq=daniel+wollschl%C3%A4ger+survsplit&source=bl&ots=ajPg
>InB83d&sig=noQIAXMWe6oQJ-LwsTCkroWdwHQ&hl=de&sa=X&ved=0ahUKEwiqwoX8q83OAhVlM
>5oKHSMGDrEQ6AEIHjAA#v=onepage&q=daniel%20wollschl%C3%A4ger%20survsplit&f=fal
>se
>
> 
>
>Mr. Wollschl?ger also provides the dataset, all of the code he used and
>an
>excerpt of his output:
>
> 
>
> 
>
>> library(survival) # f?r survSplit()
>
>> dfSurvCP <- survSplit(dfSurv, cut=seq(30, 90, by=30), end="obsT",
>
>+ event="status", start="start", id="ID", zero=0)
>
># sortiere nach Beobachtungsobjekt und linken Intervallgrenzen
>
>> idxOrd <- order(dfSurvCP$ID, dfSurvCP$start)
>
>> head(dfSurvCP[idxOrd, ], n=7)
>
>obsT    status sex      X                     IV        start     ID
>
>1          30        0          f           -1.3130607     A         0
>1
>
>181      60        0          f           -1.3130607     A         30
>1
>
>361      63        1          f           -1.3130607     A         60
>1
>
>10        11        1          f           -1.2282824     A         0
>10
>
>100      27        1          m         -0.1018403     B         0
>100
>
>101      30        0          m         -0.4079027     B         0
>101
>
>281      42        1          m         -0.4079027     B         30
>101
>
> 
>
> 
>
>Unfortunaltely when I tried to copy Mr. Wollschl?gers operations using
>his
>very dataset, RStudio just returned the following error-message:
>
> 
>
>> dfSurvCP2 <-
>survSplit(dfSurv,cut=seq(30,90,by=30),end="obsT",event="status",start="start
>",id="ID",zero=0)
>
>Error in formula.default(eval(parse(text = x, keep.source =
>FALSE)[[1L]])) :
>
>
>  invalid formula
>
> 
>
>I tried to figure out what?s wrong, but so far didn?t find any
>solutions? I
>would be very glad if anyone could help me out here.
>
> 
>
>vhfv
>
> 
>
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sat Aug 20 22:45:01 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 20 Aug 2016 13:45:01 -0700
Subject: [R] autocorrelation function plot in lattice
In-Reply-To: <CY1PR07MB2588D44191068BBB9F4CFC75FA170@CY1PR07MB2588.namprd07.prod.outlook.com>
References: <CY1PR07MB2588D44191068BBB9F4CFC75FA170@CY1PR07MB2588.namprd07.prod.outlook.com>
Message-ID: <7CEEB34B-FC33-4861-9DE7-BC1EAC1479CA@dcn.davis.ca.us>

Undoubtedly.  Consider nlme::plot.ACF as one possibility. Roll your own is also feasible. 
-- 
Sent from my phone. Please excuse my brevity.

On August 20, 2016 5:28:04 AM PDT, Naresh Gurbuxani <naresh_gurbuxani at hotmail.com> wrote:
>Using lattice package, is it possible to plot autocorrelation functions
>similar to acf in stats?
>
>Thanks,
>Naresh
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Sat Aug 20 23:10:44 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sat, 20 Aug 2016 17:10:44 -0400
Subject: [R] autocorrelation function plot in lattice
In-Reply-To: <CY1PR07MB2588D44191068BBB9F4CFC75FA170@CY1PR07MB2588.namprd07.prod.outlook.com>
References: <CY1PR07MB2588D44191068BBB9F4CFC75FA170@CY1PR07MB2588.namprd07.prod.outlook.com>
Message-ID: <CAGx1TMD6QSV4rLvEyvPRXcX9ZnBOd7GpL0mtJZ7bV3zt4mmKjA@mail.gmail.com>

Yes.  You may use the acf.pacf.plot, tsacfplots and related functions
in the HH package.

>From ?HH::tsacfplots

     tsacfplots(co2)
     acf.pacf.plot(co2)

If you want just the acf, and not the pacf also, you can use

    update(acf.pacf.plot(co2)[1], layout=c(1,1), main="ACF: co2")

On Sat, Aug 20, 2016 at 8:28 AM, Naresh Gurbuxani
<naresh_gurbuxani at hotmail.com> wrote:
> Using lattice package, is it possible to plot autocorrelation functions similar to acf in stats?
>
> Thanks,
> Naresh
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Aug 21 17:00:09 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 21 Aug 2016 08:00:09 -0700
Subject: [R] problem concernig Survsplit, package survival
In-Reply-To: <152483F4-68E9-4545-A663-D98D6B5A3BB2@dcn.davis.ca.us>
References: <003501d1fa0b$d7026e20$85074a60$@googlemail.com>
	<152483F4-68E9-4545-A663-D98D6B5A3BB2@dcn.davis.ca.us>
Message-ID: <8A1F0631-43B1-4516-8F08-91541B496B78@comcast.net>


> On Aug 20, 2016, at 1:31 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Your link did not take me to the code you reference... Google does not make entire books available online which may have something to do with my difficulty.  This is one reason the Posting Guide asks you to post a self-contained, reproducible example. Your use of HTML format in your posting to the list was also a making it hard to follow. 
> 
> I did find a ZIP file at [1], and the arguments do not conform to the survSplit documentation. Since I have not been a user of this package over time, I don't know whether this is due to changes in the argument list or a simple error on the part of the author... but I suspect the latter because the missing formula specification seems intrinsic to the intent of the function. 
> 
> Someone else may chime in with a more conclusive comment, but I would recommend finding a different tutorial on the topic, or corresponding with Mr.Wollschlaeger.
> 
> [1] http://www.dwoll.de/r/gddmr/wollschlaeger_r_all.zip

I'm not posing as having conclusive knowledge about the history of survSplit. (I did look at survival package's NEWS file and could not find an answer to when the syntax might have changed. I'm guessing its been that way for at least 9 years, since that seems to be how far back the NEWS file covers.)

The survival.Rdata file in that already has both a dfSurv and a dfSurvCP which explains the possibility of seeing the head of that second object despite an error during an effort at creation.

It is possible to construct a new dfSurvCP by fixing the error that Jeff points out (a non-formula argument):

dfSurvCP <- survSplit( Surv(obsT,status) ~ . , data=dfSurv, cut=seq(30, 90, by=30), end="obsT",
                      event="status", start="start", id="ID", zero=0)

You then get no error and the results agree with the provided dataset:

> head(dfSurvCP[idxOrd, ], n=7)
  sex          X IV Xcut ID start obsT status
1   f -1.3130607  A   lo  1     0   30      0
2   f -1.3130607  A   lo  1    30   60      0
3   f -1.3130607  A   lo  1    60   63      1
4   m -0.1384786  A   lo  2     0   25      1
5   m -0.3846335  A   lo  3     0   30      0
6   m -0.3846335  A   lo  3    30   60      0
7   m -0.3846335  A   lo  3    60   73      1

The cited text does not appear to be focussed on survival analysis but rather "data management" (my non-German speaker's guesswork translation of the title "Grundlagen der Datenanalyse mit R" since I read "Grundlagen" as "ground layer" , i.e "Foundations")

Hope this helps;
David.


> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On August 19, 2016 4:21:31 AM PDT, "Vinzenz V?lkel via R-help" <r-help at r-project.org> wrote:
>> Dear R-help-community,
>> 
>> 
>> 
>> I hope, that?s the appropiate channel to post a quastion?
>> 
>> 
>> 
>> For some days I have been struggling with a problem concerning the
>> ?survSplit?-function of the package ?survival?. Searching the internet
>> I
>> have found a pretty good -German- description of Daniel Wollschl?ger
>> describing how to use survSplit:
>> 
>> 
>> 
>> (https://books.google.de/books?id=9G4oBgAAQBAJ
>> <https://books.google.de/books?id=9G4oBgAAQBAJ&pg=PA345&lpg=PA345&dq=daniel+
>> wollschl%C3%A4ger+survsplit&source=bl&ots=ajPgInB83d&sig=noQIAXMWe6oQJ-LwsTC
>> kroWdwHQ&hl=de&sa=X&ved=0ahUKEwiqwoX8q83OAhVlM5oKHSMGDrEQ6AEIHjAA#v=onepage&
>> q=daniel%20wollschl%C3%A4ger%20survsplit&f=false>
>> &pg=PA345&lpg=PA345&dq=daniel+wollschl%C3%A4ger+survsplit&source=bl&ots=ajPg
>> InB83d&sig=noQIAXMWe6oQJ-LwsTCkroWdwHQ&hl=de&sa=X&ved=0ahUKEwiqwoX8q83OAhVlM
>> 5oKHSMGDrEQ6AEIHjAA#v=onepage&q=daniel%20wollschl%C3%A4ger%20survsplit&f=fal
>> se
>> 
>> 
>> 
>> Mr. Wollschl?ger also provides the dataset, all of the code he used and
>> an
>> excerpt of his output:
>> 
>> 
>> 
>> 
>> 
>>> library(survival) # f?r survSplit()
>> 
>>> dfSurvCP <- survSplit(dfSurv, cut=seq(30, 90, by=30), end="obsT",
>> 
>> + event="status", start="start", id="ID", zero=0)
>> 
>> # sortiere nach Beobachtungsobjekt und linken Intervallgrenzen
>> 
>>> idxOrd <- order(dfSurvCP$ID, dfSurvCP$start)
>> 
>>> head(dfSurvCP[idxOrd, ], n=7)
>> 
>> obsT    status sex      X                     IV        start     ID
>> 
>> 1          30        0          f           -1.3130607     A         0
>> 1
>> 
>> 181      60        0          f           -1.3130607     A         30
>> 1
>> 
>> 361      63        1          f           -1.3130607     A         60
>> 1
>> 
>> 10        11        1          f           -1.2282824     A         0
>> 10
>> 
>> 100      27        1          m         -0.1018403     B         0
>> 100
>> 
>> 101      30        0          m         -0.4079027     B         0
>> 101
>> 
>> 281      42        1          m         -0.4079027     B         30
>> 101
>> 
>> 
>> 
>> 
>> 
>> Unfortunaltely when I tried to copy Mr. Wollschl?gers operations using
>> his
>> very dataset, RStudio just returned the following error-message:
>> 
>> 
>> 
>>> dfSurvCP2 <-
>> survSplit(dfSurv,cut=seq(30,90,by=30),end="obsT",event="status",start="start
>> ",id="ID",zero=0)
>> 
>> Error in formula.default(eval(parse(text = x, keep.source =
>> FALSE)[[1L]])) :
>> 
>> 
>> invalid formula
>> 
>> 
>> 
>> I tried to figure out what?s wrong, but so far didn?t find any
>> solutions? I
>> would be very glad if anyone could help me out here.
>> 
>> 
>> 
>> vhfv
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> 
>> 
>> ------------------------------------------------------------------------
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From justinthong93 at gmail.com  Mon Aug 22 03:44:59 2016
From: justinthong93 at gmail.com (Justin Thong)
Date: Mon, 22 Aug 2016 02:44:59 +0100
Subject: [R] Intercept in Model Matrix (Parameters not what I expected)
Message-ID: <CAEtAGeruhVDD6hQGd6WORFHME9dBUvbq3LdB-7B-QTdytVHtYA@mail.gmail.com>

I have something which has been bugging me and I have even asked this on
cross validated but I did not get a response.  Let's construct a simple
example. Below is the code.

A<-gl(2,4) #factor of 2 levels
B<-gl(4,2) #factor of 4 levels
df<-data.frame(y,A,B)

As you can see, B is nested within A.
The peculiar result I am interested in the output of the model matrix when
I fit for a nested model . *How does R decide what is included inside the
intercept?* Since we are using dummy coding, the coefficients of the model
is interpreted as the difference between a particular level and the
reference level/the intercept for an single factor model. I understand for
model ~A, A1 becomes the intercept and that for model ~A+B, A1 and B1
(both) become the intercept.

*I do not get why when we use a nested model, A1:B2 appears as a column
inside the model matrix. Why isn't the first parameter of the interaction
subspace A1:B1 or A2:B1? *I think I am missing the concept. I think the
intercept is A1. *Hence, Why do we not compare the levels of A1:B1 and
A1(intercept)  or A2:B1 and A1(intercept)?*

#nested model
> mod<-aov(y~A+A:B)
> model.matrix(mod)
  (Intercept) A2 A1:B2 A2:B2 A1:B3 A2:B3 A1:B4 A2:B4
1           1  0     0     0     0     0     0     0
2           1  0     0     0     0     0     0     0
3           1  0     1     0     0     0     0     0
4           1  0     1     0     0     0     0     0
5           1  1     0     0     0     1     0     0
6           1  1     0     0     0     1     0     0
7           1  1     0     0     0     0     0     1
8           1  1     0     0     0     0     0     1


-- 
Yours sincerely,
Justin

*I check my email at 9AM and 4PM everyday*
*If you have an EMERGENCY, contact me at +447938674419(UK) or
+60125056192(Malaysia)*

	[[alternative HTML version deleted]]


From k.kowitski at icloud.com  Sun Aug 21 19:30:54 2016
From: k.kowitski at icloud.com (Kevin Kowitski)
Date: Sun, 21 Aug 2016 17:30:54 +0000 (GMT)
Subject: [R] read.xlsx function crashing R Studio
Message-ID: <18f7d6eb-f297-4292-a52b-a8cc0057b520@me.com>

Hey everyone,?

? ?I have used read.xlsx in the past rather than XLConnect for importing Excel data to R. ?However, I have been finding now that the read.xlsx function has been causing my R studio to Time out. ?I thought it might be because the R studio I had was out of date so I installed R studio X64 3.3.1 and reinstalled the xlsx package but it is still failing. ?I have been trying to use XLConnect in it's place which has been working, excpet that I am running into memory error:
??????????????Error: OutOfMemoryError (Java): GC overhead limit exceeded
??????
I did some online searching and found an option to increase memory:
??????????????"options(java.parameters = "-Xmx4g" )

but it resulted in this new memory Error:

?????????????Error: OutOfMemoryError (Java): Java heap space

Can anyone provide me with some help on getting the read.xlsx function working?

-Kevin


From subincj at naver.com  Mon Aug 22 07:06:48 2016
From: subincj at naver.com (=?UTF-8?B?7KCV7IiY67mI?=)
Date: Mon, 22 Aug 2016 14:06:48 +0900 (KST)
Subject: [R] =?utf-8?q?I_had_1_problem_with_r?=
Message-ID: <ed11d58a4181af93fc9a2b75a17037c9@cweb25.nm.nhnsystem.com>

Hi My name is SuBin-Jung from Korea.
 
I can't write english well. so, understand me please.
 
I used R Gui(64-bit) program.
 
And in program, I imported this csv file named "emp.csv"
 
emp.csv
---------------------------------------------
empno,ename,job,mgr,hiredate,sal,comm,deptno
7369,SMITH,CLERK,7902,1980-12-17,800,,20
7499,ALLEN,SALESMAN,7698,1981-02-20,1600,300,30
7521,WARD,SALESMAN,7698,1981-02-03,1250,500,30
7566,JONES,MANAGER,7839,1981-03-02,2975,,20
7654,MARTIN,SALESMAN,7698,1981-10-22,1250,1400,30
7698,BLAKE,MANAGER,7839,1981-05-01,2850,,30
7782,CLARK,MANAGER,7839,1981-09-06,2450,,10
7788,SCOTT,ANALYST,7566,1982-12-08,3000,,20
7839,KING,PRESIDENT,,1981-11-17,5000,,10
7844,TURNER,SALESMAN,7698,1984-10-08,1500,,30
7876,ADAMS,CLERK,7788,1983-01-12,1100,,20
7900,JAMES,CLERK,7698,1981-12-03,950,,30
7902,FORD,ANALYST,7566,1981-12-13,3000,,20
7934,MILLER,CLERK,7782,1982-01-25,1300,,10
----------------------------------------------
 
Then I used command "read.csv"  ==&gt; read.csv("emp.csv")
 
And I tried to find emp$ename with first alphabet 'A'.
 
So I inserted this command on program :
 
&gt; subset(emp, ename==grep("^A+",ename,value=TRUE), select=c("ename","sal")) 
 
But the result is not found.
 
After that I tried to other alphabets( B,S,W....)
 
&gt; subset(emp, ename==grep("^S+",ename,value=TRUE), select=c("ename","sal"))
 
Then I can find two data.
 
  ename  sal
1 SMITH  800
8 SCOTT 3000


Why can't I find emp$ename with first alphavet 'A'??
I think this is error. 
Please give me answer, sir. 

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Aug 22 10:15:53 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 22 Aug 2016 18:15:53 +1000
Subject: [R] I had 1 problem with r
In-Reply-To: <ed11d58a4181af93fc9a2b75a17037c9@cweb25.nm.nhnsystem.com>
References: <ed11d58a4181af93fc9a2b75a17037c9@cweb25.nm.nhnsystem.com>
Message-ID: <CA+8X3fW1MqKeJSETsnc6tkH=jQt-yHWvEE8ch2PfcLYTZzhcPA@mail.gmail.com>

Hi SuBin,
This seems to work:

emp<-read.table(text="empno,ename,job,mgr,hiredate,sal,comm,deptno
 7369,SMITH,CLERK,7902,1980-12-17,800,,20
 7499,ALLEN,SALESMAN,7698,1981-02-20,1600,300,30
 7521,WARD,SALESMAN,7698,1981-02-03,1250,500,30
 7566,JONES,MANAGER,7839,1981-03-02,2975,,20
 7654,MARTIN,SALESMAN,7698,1981-10-22,1250,1400,30
 7698,BLAKE,MANAGER,7839,1981-05-01,2850,,30
 7782,CLARK,MANAGER,7839,1981-09-06,2450,,10
 7788,SCOTT,ANALYST,7566,1982-12-08,3000,,20
 7839,KING,PRESIDENT,,1981-11-17,5000,,10
 7844,TURNER,SALESMAN,7698,1984-10-08,1500,,30
 7876,ADAMS,CLERK,7788,1983-01-12,1100,,20
 7900,JAMES,CLERK,7698,1981-12-03,950,,30
 7902,FORD,ANALYST,7566,1981-12-13,3000,,20
 7934,MILLER,CLERK,7782,1982-01-25,1300,,10",
 header=TRUE,sep=",")

emp[grep("^A",emp$ename),c("ename","sal")]
  ename  sal
2  ALLEN 1600
11 ADAMS 1100

Jim


On Mon, Aug 22, 2016 at 3:06 PM, ??? <subincj at naver.com> wrote:
> Hi My name is SuBin-Jung from Korea.
>
> I can't write english well. so, understand me please.
>
> I used R Gui(64-bit) program.
>
> And in program, I imported this csv file named "emp.csv"
>
> emp.csv
> ---------------------------------------------
> empno,ename,job,mgr,hiredate,sal,comm,deptno
> 7369,SMITH,CLERK,7902,1980-12-17,800,,20
> 7499,ALLEN,SALESMAN,7698,1981-02-20,1600,300,30
> 7521,WARD,SALESMAN,7698,1981-02-03,1250,500,30
> 7566,JONES,MANAGER,7839,1981-03-02,2975,,20
> 7654,MARTIN,SALESMAN,7698,1981-10-22,1250,1400,30
> 7698,BLAKE,MANAGER,7839,1981-05-01,2850,,30
> 7782,CLARK,MANAGER,7839,1981-09-06,2450,,10
> 7788,SCOTT,ANALYST,7566,1982-12-08,3000,,20
> 7839,KING,PRESIDENT,,1981-11-17,5000,,10
> 7844,TURNER,SALESMAN,7698,1984-10-08,1500,,30
> 7876,ADAMS,CLERK,7788,1983-01-12,1100,,20
> 7900,JAMES,CLERK,7698,1981-12-03,950,,30
> 7902,FORD,ANALYST,7566,1981-12-13,3000,,20
> 7934,MILLER,CLERK,7782,1982-01-25,1300,,10
> ----------------------------------------------
>
> Then I used command "read.csv"  ==&gt; read.csv("emp.csv")
>
> And I tried to find emp$ename with first alphabet 'A'.
>
> So I inserted this command on program :
>
> &gt; subset(emp, ename==grep("^A+",ename,value=TRUE), select=c("ename","sal"))
>
> But the result is not found.
>
> After that I tried to other alphabets( B,S,W....)
>
> &gt; subset(emp, ename==grep("^S+",ename,value=TRUE), select=c("ename","sal"))
>
> Then I can find two data.
>
>   ename  sal
> 1 SMITH  800
> 8 SCOTT 3000
>
>
> Why can't I find emp$ename with first alphavet 'A'??
> I think this is error.
> Please give me answer, sir.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Mon Aug 22 10:30:24 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 22 Aug 2016 10:30:24 +0200
Subject: [R] I had 1 problem with r
In-Reply-To: <ed11d58a4181af93fc9a2b75a17037c9@cweb25.nm.nhnsystem.com>
References: <ed11d58a4181af93fc9a2b75a17037c9@cweb25.nm.nhnsystem.com>
Message-ID: <729C01B1-CBA1-4B81-9200-2BD481CCE88B@gmail.com>


On 22 Aug 2016, at 07:06 , ??? <subincj at naver.com> wrote:

> Hi My name is SuBin-Jung from Korea.
> 
> I can't write english well. so, understand me please.
> 
> I used R Gui(64-bit) program.
> 
> And in program, I imported this csv file named "emp.csv"
> 
> emp.csv
> ---------------------------------------------
> empno,ename,job,mgr,hiredate,sal,comm,deptno
> 7369,SMITH,CLERK,7902,1980-12-17,800,,20
> 7499,ALLEN,SALESMAN,7698,1981-02-20,1600,300,30
> 7521,WARD,SALESMAN,7698,1981-02-03,1250,500,30
> 7566,JONES,MANAGER,7839,1981-03-02,2975,,20
> 7654,MARTIN,SALESMAN,7698,1981-10-22,1250,1400,30
> 7698,BLAKE,MANAGER,7839,1981-05-01,2850,,30
> 7782,CLARK,MANAGER,7839,1981-09-06,2450,,10
> 7788,SCOTT,ANALYST,7566,1982-12-08,3000,,20
> 7839,KING,PRESIDENT,,1981-11-17,5000,,10
> 7844,TURNER,SALESMAN,7698,1984-10-08,1500,,30
> 7876,ADAMS,CLERK,7788,1983-01-12,1100,,20
> 7900,JAMES,CLERK,7698,1981-12-03,950,,30
> 7902,FORD,ANALYST,7566,1981-12-13,3000,,20
> 7934,MILLER,CLERK,7782,1982-01-25,1300,,10
> ----------------------------------------------
> 
> Then I used command "read.csv"  ==&gt; read.csv("emp.csv")
> 
> And I tried to find emp$ename with first alphabet 'A'.
> 
> So I inserted this command on program :
> 
> &gt; subset(emp, ename==grep("^A+",ename,value=TRUE), select=c("ename","sal")) 
> 
> But the result is not found.
> 
> After that I tried to other alphabets( B,S,W....)
> 
> &gt; subset(emp, ename==grep("^S+",ename,value=TRUE), select=c("ename","sal"))
> 


Please do not post in HTML (reason should be pretty obvious).

Your logic is wrong: 

ename==grep("^A+",ename,value=TRUE)

Right hand side evaluates to c("ALLAN","ADAMS"); you then compare this to ename, which by recycling means that you compare 

SMITH to ALLAN, 
ALLAN to ADAMS, 
WARD to ALLAN, 
JONES to ADAMS,
...
TURNER to ADAMS,
ADAMS to ALLAN
...


See?

subset(emp, grepl("^A+",ename), select=c("ename","sal")) 

should work (and is simpler, too)

-pd


> Then I can find two data.
> 
>  ename  sal
> 1 SMITH  800
> 8 SCOTT 3000
> 
> 
> Why can't I find emp$ename with first alphavet 'A'??
> I think this is error. 
> Please give me answer, sir. 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jholtman at gmail.com  Mon Aug 22 12:54:38 2016
From: jholtman at gmail.com (jim holtman)
Date: Mon, 22 Aug 2016 06:54:38 -0400
Subject: [R] read.xlsx function crashing R Studio
In-Reply-To: <18f7d6eb-f297-4292-a52b-a8cc0057b520@me.com>
References: <18f7d6eb-f297-4292-a52b-a8cc0057b520@me.com>
Message-ID: <CAAxdm-6=TCF3ZkAbCR20dcEG_1OTVYauAvuB_poLdK2ccY97ag@mail.gmail.com>

try the openxlsx package


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Aug 21, 2016 at 1:30 PM, Kevin Kowitski <k.kowitski at icloud.com>
wrote:

> Hey everyone,
>
>    I have used read.xlsx in the past rather than XLConnect for importing
> Excel data to R.  However, I have been finding now that the read.xlsx
> function has been causing my R studio to Time out.  I thought it might be
> because the R studio I had was out of date so I installed R studio X64
> 3.3.1 and reinstalled the xlsx package but it is still failing.  I have
> been trying to use XLConnect in it's place which has been working, excpet
> that I am running into memory error:
>               Error: OutOfMemoryError (Java): GC overhead limit exceeded
>
> I did some online searching and found an option to increase memory:
>               "options(java.parameters = "-Xmx4g" )
>
> but it resulted in this new memory Error:
>
>              Error: OutOfMemoryError (Java): Java heap space
>
> Can anyone provide me with some help on getting the read.xlsx function
> working?
>
> -Kevin
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From therneau at mayo.edu  Mon Aug 22 15:11:29 2016
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 22 Aug 2016 08:11:29 -0500
Subject: [R] problem concernig Survsplit, package survival
In-Reply-To: <mailman.3.1471687201.12680.r-help@r-project.org>
References: <mailman.3.1471687201.12680.r-help@r-project.org>
Message-ID: <083a37$44ftjt@ironport10.mayo.edu>


On 08/20/2016 05:00 AM, Vinzenz wrote:
> For some days I have been struggling with a problem concerning the
> ?survSplit?-function of the package ?survival?. Searching the internet I
> have found a pretty good -German- description of Daniel Wollschl?r
> describing how to use survSplit:

The survSplit routine was recently updated to allow a formula as the first argument.  This 
change makes the routine much easier to use and more flexible.  Old forms of the call 
should have worked as well, but unfortunately I introduced a bug in the code.  For the 
time being, change your call to
    dfSurvCP <- survSplit(Surv(obsT, status) ~ ., dfSurv, cut=seq(30, 90, by=30), id="ID", 
zero=0)

I will fix this.  I apologize for the error.

Terry Therneau


From h.wickham at gmail.com  Mon Aug 22 16:44:56 2016
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 22 Aug 2016 09:44:56 -0500
Subject: [R] read.xlsx function crashing R Studio
In-Reply-To: <CAAxdm-6=TCF3ZkAbCR20dcEG_1OTVYauAvuB_poLdK2ccY97ag@mail.gmail.com>
References: <18f7d6eb-f297-4292-a52b-a8cc0057b520@me.com>
	<CAAxdm-6=TCF3ZkAbCR20dcEG_1OTVYauAvuB_poLdK2ccY97ag@mail.gmail.com>
Message-ID: <CABdHhvHkUd6wbdxjn8yu3BZc0LcK6uGj7zPrWNkObjSv_Z=s3g@mail.gmail.com>

Or readxl.

Hadley

On Mon, Aug 22, 2016 at 5:54 AM, jim holtman <jholtman at gmail.com> wrote:
> try the openxlsx package
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Sun, Aug 21, 2016 at 1:30 PM, Kevin Kowitski <k.kowitski at icloud.com>
> wrote:
>
>> Hey everyone,
>>
>>    I have used read.xlsx in the past rather than XLConnect for importing
>> Excel data to R.  However, I have been finding now that the read.xlsx
>> function has been causing my R studio to Time out.  I thought it might be
>> because the R studio I had was out of date so I installed R studio X64
>> 3.3.1 and reinstalled the xlsx package but it is still failing.  I have
>> been trying to use XLConnect in it's place which has been working, excpet
>> that I am running into memory error:
>>               Error: OutOfMemoryError (Java): GC overhead limit exceeded
>>
>> I did some online searching and found an option to increase memory:
>>               "options(java.parameters = "-Xmx4g" )
>>
>> but it resulted in this new memory Error:
>>
>>              Error: OutOfMemoryError (Java): Java heap space
>>
>> Can anyone provide me with some help on getting the read.xlsx function
>> working?
>>
>> -Kevin
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://hadley.nz


From bgunter.4567 at gmail.com  Mon Aug 22 17:14:24 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 22 Aug 2016 08:14:24 -0700
Subject: [R] Intercept in Model Matrix (Parameters not what I expected)
In-Reply-To: <CAEtAGeruhVDD6hQGd6WORFHME9dBUvbq3LdB-7B-QTdytVHtYA@mail.gmail.com>
References: <CAEtAGeruhVDD6hQGd6WORFHME9dBUvbq3LdB-7B-QTdytVHtYA@mail.gmail.com>
Message-ID: <CAGxFJbQbEA3p=K4veK=85qwRkGsOtJaUQRUE4tkc3KHWaP+HkA@mail.gmail.com>

Justin:

As you have not yet received any reply...

Your question is mostly about statistics (linear models) and, as such,
is typically off topic here. Briefly, you do seem confused about
contrasts in linear models, but I am confused about your confusion,
and so may be of little help. However....

Note that in your little 8 run example design, the response lives in 8
dims, and so your model matrix can have at most 8 independent columns.
~(A+B) has 4, which, using contr.treatment treatments could be
Intercept, A2,B2, B3 (since (B3+B4) - (B2+B1) is confounded with (A2 -
A1), where these are "dummy" encodings of 0 and 1). Adding all
pairwise products of the non-intercept columns  would not give you any
more, as all are all 0's. I do not know the algorithm that lm/aov uses
to choose which of the contrasts to estimate, but it makes no
difference: there can only be 3 beyond the intercept, and all others
are linear combinations of these.

If this is not useful to you, either:

1. Hope for a response here that is more helpful;
2. Consult a local statistical expert;
3. Read up on linear models (there are multiple books and internet sources);
4. Post on stats.stackexchange.com again.

Cheers,
Bert

## Note to others. If I have erred in any of the above, PLEASE CORRECT.




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Aug 21, 2016 at 6:44 PM, Justin Thong <justinthong93 at gmail.com> wrote:
> I have something which has been bugging me and I have even asked this on
> cross validated but I did not get a response.  Let's construct a simple
> example. Below is the code.
>
> A<-gl(2,4) #factor of 2 levels
> B<-gl(4,2) #factor of 4 levels
> df<-data.frame(y,A,B)
>
> As you can see, B is nested within A.
> The peculiar result I am interested in the output of the model matrix when
> I fit for a nested model . *How does R decide what is included inside the
> intercept?* Since we are using dummy coding, the coefficients of the model
> is interpreted as the difference between a particular level and the
> reference level/the intercept for an single factor model. I understand for
> model ~A, A1 becomes the intercept and that for model ~A+B, A1 and B1
> (both) become the intercept.
>
> *I do not get why when we use a nested model, A1:B2 appears as a column
> inside the model matrix. Why isn't the first parameter of the interaction
> subspace A1:B1 or A2:B1? *I think I am missing the concept. I think the
> intercept is A1. *Hence, Why do we not compare the levels of A1:B1 and
> A1(intercept)  or A2:B1 and A1(intercept)?*
>
> #nested model
>> mod<-aov(y~A+A:B)
>> model.matrix(mod)
>   (Intercept) A2 A1:B2 A2:B2 A1:B3 A2:B3 A1:B4 A2:B4
> 1           1  0     0     0     0     0     0     0
> 2           1  0     0     0     0     0     0     0
> 3           1  0     1     0     0     0     0     0
> 4           1  0     1     0     0     0     0     0
> 5           1  1     0     0     0     1     0     0
> 6           1  1     0     0     0     1     0     0
> 7           1  1     0     0     0     0     0     1
> 8           1  1     0     0     0     0     0     1
>
>
> --
> Yours sincerely,
> Justin
>
> *I check my email at 9AM and 4PM everyday*
> *If you have an EMERGENCY, contact me at +447938674419(UK) or
> +60125056192(Malaysia)*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From justinthong93 at gmail.com  Mon Aug 22 17:15:03 2016
From: justinthong93 at gmail.com (Justin Thong)
Date: Mon, 22 Aug 2016 16:15:03 +0100
Subject: [R] Estimated Effects Not Balanced
Message-ID: <CAEtAGeq-r1OW6yw4fxmu1wG8bbCGSB8h5qjmegrxNPTa3V6=aA@mail.gmail.com>

Something does not make sense in R. It has to do with the question of
balance and unbalance.

*A<-factor(c(1,1,1,1,1,1,2,2,2,2,2,2))*
*B<-factor(c(1,1,2,2,3,3,1,1,2,2,3,3))*
*y<-rnorm(12)*
*mod<-aov(y~A+B)*

I was under the impression that the design is balanced ie order does not
effect the sums of squares. However, when I compute the anova R reports
that the Estimated Effects are Unbalanced. I thought that when all
combinations of levels of A and B have equal replications then the design
is called balanced. But, R tends to think that when not all levels of A and
levels of B have equal replication, then the "Estimated Effects are
unbalanced".... Is this the same as the design being unbalanced? Because
for the example below, where the error occured, the order does not matter
(which make me think that the design is balanced).


*Call:*
*   aov(formula = y ~ A + B)*

*Terms:*
*                        A         B Residuals*
*Sum of Squares   0.872572  0.025604 16.805706*
*Deg. of Freedom         1         2        10*

*Residual standard error: 1.296368*
*Estimated effects may be unbalanced*
-- 
Yours sincerely,
Justin

*I check my email at 9AM and 4PM everyday*
*If you have an EMERGENCY, contact me at +447938674419(UK) or
+60125056192(Malaysia)*

	[[alternative HTML version deleted]]


From tbr at ig.cas.cz  Mon Aug 22 17:17:10 2016
From: tbr at ig.cas.cz (Tomas Bayer)
Date: Mon, 22 Aug 2016 17:17:10 +0200
Subject: [R] persp fail with non-equidistant dates
Message-ID: <7a77a449f0c53e21f755744123dad44a.squirrel@www.ig.cas.cz>

Hello,
when I plotted non-equidistant data in 3D (using persp and contour), it
was ended with the same error message:

> persp(y, x, z, xlab="latitude", ylab="longitude", zlab="altiude",
main="Altitude")
Error in persp.default(y, x, z, xlab = "latitude", ylab = "longitude",  :
  increasing 'x' and 'y' values expected

How to fix it? The original data are in columns

 50.84925    14.65715 614.0  48909.14   -62.49  99  48929  5  122306
 50.84919    14.65702 617.0  48816.32  -145.82  69  48836  6  122331
 50.84908    14.65681 622.0  49113.40     6.64  99  49133  4  122442

Tomas Bayer
  ,           ,
 /             \
((__-^^-,-^^-__))
 `-_---' `---_-'
  `--|o` 'o|--'
     \  `  /
      ): :(
      :o_o:
       "-"
GNU's Not Unix!


From bgunter.4567 at gmail.com  Mon Aug 22 17:27:11 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 22 Aug 2016 08:27:11 -0700
Subject: [R] Estimated Effects Not Balanced
In-Reply-To: <CAEtAGeq-r1OW6yw4fxmu1wG8bbCGSB8h5qjmegrxNPTa3V6=aA@mail.gmail.com>
References: <CAEtAGeq-r1OW6yw4fxmu1wG8bbCGSB8h5qjmegrxNPTa3V6=aA@mail.gmail.com>
Message-ID: <CAGxFJbS--S1juNQD_iHpqS-H4kAR=vQpxTMHW=MHcEt=5SKRkQ@mail.gmail.com>

Please!

"when I compute the anova R reports
that the Estimated Effects are Unbalanced"


It does *not* say this. It says that they **may** be unbalanced. They are not.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 22, 2016 at 8:15 AM, Justin Thong <justinthong93 at gmail.com> wrote:
> Something does not make sense in R. It has to do with the question of
> balance and unbalance.
>
> *A<-factor(c(1,1,1,1,1,1,2,2,2,2,2,2))*
> *B<-factor(c(1,1,2,2,3,3,1,1,2,2,3,3))*
> *y<-rnorm(12)*
> *mod<-aov(y~A+B)*
>
> I was under the impression that the design is balanced ie order does not
> effect the sums of squares. However, when I compute the anova R reports
> that the Estimated Effects are Unbalanced. I thought that when all
> combinations of levels of A and B have equal replications then the design
> is called balanced. But, R tends to think that when not all levels of A and
> levels of B have equal replication, then the "Estimated Effects are
> unbalanced".... Is this the same as the design being unbalanced? Because
> for the example below, where the error occured, the order does not matter
> (which make me think that the design is balanced).
>
>
> *Call:*
> *   aov(formula = y ~ A + B)*
>
> *Terms:*
> *                        A         B Residuals*
> *Sum of Squares   0.872572  0.025604 16.805706*
> *Deg. of Freedom         1         2        10*
>
> *Residual standard error: 1.296368*
> *Estimated effects may be unbalanced*
> --
> Yours sincerely,
> Justin
>
> *I check my email at 9AM and 4PM everyday*
> *If you have an EMERGENCY, contact me at +447938674419(UK) or
> +60125056192(Malaysia)*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Aug 22 17:53:18 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 22 Aug 2016 11:53:18 -0400
Subject: [R] persp fail with non-equidistant dates
In-Reply-To: <7a77a449f0c53e21f755744123dad44a.squirrel@www.ig.cas.cz>
References: <7a77a449f0c53e21f755744123dad44a.squirrel@www.ig.cas.cz>
Message-ID: <56ef3d27-b6f4-73ca-7c54-e04b20fe2484@gmail.com>

On 22/08/2016 11:17 AM, Tomas Bayer wrote:
> Hello,
> when I plotted non-equidistant data in 3D (using persp and contour), it
> was ended with the same error message:
>
>> persp(y, x, z, xlab="latitude", ylab="longitude", zlab="altiude",
> main="Altitude")
> Error in persp.default(y, x, z, xlab = "latitude", ylab = "longitude",  :
>   increasing 'x' and 'y' values expected
>
> How to fix it? The original data are in columns
>
>  50.84925    14.65715 614.0  48909.14   -62.49  99  48929  5  122306
>  50.84919    14.65702 617.0  48816.32  -145.82  69  48836  6  122331
>  50.84908    14.65681 622.0  49113.40     6.64  99  49133  4  122442

You haven't shown us what is in y, x and z, but it looks as though you 
haven't got data in the form required by persp, i.e. a vector of 
increasing values in each of the first two arguments, and a matrix of 
values in the third.  Using your variable names, you'd want z[i,j] to 
correspond to y[i] and x[j].

If you just have a collection of (y, x, z) triples, you'll need to do 
some pre-processing to fit a surface and produce the required inputs.

Duncan Murdoch


From bhanumathihm6 at gmail.com  Mon Aug 22 12:28:42 2016
From: bhanumathihm6 at gmail.com (BHANUMATHI H M)
Date: Mon, 22 Aug 2016 15:58:42 +0530
Subject: [R] Lemmatization with WORDNET package
Message-ID: <CAMsT4MOk9PMXMM9vyw6NnRgnDuwRxYmwzT80iMQhHQmki4qLkg@mail.gmail.com>

Sir I am working on classification project before that i have to do feature
selection process. i am very interested to apply lemmatization rather
stemming. So i executed the code below according to definition of
lemmatization it should give root words like run for running and ran, think
for thought etc... but my code is not giving correct output.. could you
please Please help me to finding out where actually i went wrong please
sir..

CODE:

library("tm")
library("NLP")
library("wordnet")
setDict("C:/Program Files/WordNet/2.1/dict")
vector.documents <- c("The children something to the playground The cars %s
down the avenue")
corpus.documents <- Corpus(VectorSource(vector.documents))

initDict("C:/Program Files/WordNet/2.1/dict")
lapply(corpus.documents,function(x){
  sapply(unlist(strsplit(as.character(x),"[[:space:]]+")), function(word) {
    x.filter <- getTermFilter("StartsWithFilter", word, TRUE)
    x.filter
    x
    terms    <- getIndexTerms("NOUN",1,x.filter)
    terms
    if(!is.null(terms)) sapply(terms,getLemma)
  })
})

OUTPUT:
$`1`
$`1`$The
[1] "the absurd"

$`1`$children
NULL

$`1`$playing
[1] "playing"

$`1`$playground
[1] "playground"

$`1`$The
[1] "the absurd"

$`1`$cars
[1] "carson"

$`1`$landing
[1] "landing"

$`1`$avenue
[1] "avenue"




I also tried by applying other POS and type like "Containsfilter"
 but that also not worked please please help me !!!


Thanks in advance.

with regards,

BHANUMATHI H M

	[[alternative HTML version deleted]]


From wollschlaeger at uni-mainz.de  Mon Aug 22 12:50:53 2016
From: wollschlaeger at uni-mainz.de (Wollschlaeger, Daniel)
Date: Mon, 22 Aug 2016 10:50:53 +0000
Subject: [R]  problem concernig Survsplit, package survival
Message-ID: <3d3c14249dd7475187591cbbd149b80b@uni-mainz.de>

Thanks for bringing this issue in the book's description of survSplit() to my attention. It seems the change to the behavior of survSplit() was introduced in survival version 2.39-2. Up to (including) version 2.38-3, no formula was required if arguments 'end' and 'event' were specified.

A corrected pdf of the chapter is available at http://dwoll.de/r/gddmr/09_survival.pdf

Daniel Wollschlaeger

On August 19, 2016 4:21:31 AM PDT, "Vinzenz V?lkel via R-help" <r-help at r-project.org> wrote:
>Dear R-help-community,
>
> 
>
>I hope, that?s the appropiate channel to post a quastion?
>
> 
>
>For some days I have been struggling with a problem concerning the
>?survSplit?-function of the package ?survival?. Searching the internet
>I
>have found a pretty good -German- description of Daniel Wollschl?ger
>describing how to use survSplit:
>
> 
>
>(https://books.google.de/books?id=9G4oBgAAQBAJ
><https://books.google.de/books?id=9G4oBgAAQBAJ&pg=PA345&lpg=PA345&dq=daniel+
>wollschl%C3%A4ger+survsplit&source=bl&ots=ajPgInB83d&sig=noQIAXMWe6oQJ-LwsTC
>kroWdwHQ&hl=de&sa=X&ved=0ahUKEwiqwoX8q83OAhVlM5oKHSMGDrEQ6AEIHjAA#v=onepage&
>q=daniel%20wollschl%C3%A4ger%20survsplit&f=false>
>&pg=PA345&lpg=PA345&dq=daniel+wollschl%C3%A4ger+survsplit&source=bl&ots=ajPg
>InB83d&sig=noQIAXMWe6oQJ-LwsTCkroWdwHQ&hl=de&sa=X&ved=0ahUKEwiqwoX8q83OAhVlM
>5oKHSMGDrEQ6AEIHjAA#v=onepage&q=daniel%20wollschl%C3%A4ger%20survsplit&f=fal
>se
>
> 
>
>Mr. Wollschl?ger also provides the dataset, all of the code he used and
>an
>excerpt of his output:
>
> 
>
> 
>
>> library(survival) # f?r survSplit()
>
>> dfSurvCP <- survSplit(dfSurv, cut=seq(30, 90, by=30), end="obsT",
>
>+ event="status", start="start", id="ID", zero=0)
>
># sortiere nach Beobachtungsobjekt und linken Intervallgrenzen
>
>> idxOrd <- order(dfSurvCP$ID, dfSurvCP$start)
>
>> head(dfSurvCP[idxOrd, ], n=7)
>
>obsT    status sex      X                     IV        start     ID
>
>1          30        0          f           -1.3130607     A         0
>1
>
>181      60        0          f           -1.3130607     A         30
>1
>
>361      63        1          f           -1.3130607     A         60
>1
>
>10        11        1          f           -1.2282824     A         0
>10
>
>100      27        1          m         -0.1018403     B         0
>100
>
>101      30        0          m         -0.4079027     B         0
>101
>
>281      42        1          m         -0.4079027     B         30
>101
>
> 
>
> 
>
>Unfortunaltely when I tried to copy Mr. Wollschl?gers operations using
>his
>very dataset, RStudio just returned the following error-message:
>
> 
>
>> dfSurvCP2 <-
>survSplit(dfSurv,cut=seq(30,90,by=30),end="obsT",event="status",start="start
>",id="ID",zero=0)
>
>Error in formula.default(eval(parse(text = x, keep.source =
>FALSE)[[1L]])) :
>
>
>  invalid formula
>
> 
>
>I tried to figure out what?s wrong, but so far didn?t find any
>solutions? I
>would be very glad if anyone could help me out here.
>
> 
>
>vhfv
>
> 
>
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jfca283 at gmail.com  Mon Aug 22 18:33:34 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Mon, 22 Aug 2016 13:33:34 -0300
Subject: [R] Loop over folder files
Message-ID: <CALBYkj+rCTRsu2RkkUaEdncJW6BaiHM1hMjjnOEJU85xpGeq=A@mail.gmail.com>

Hi
I need to apply some code over some stata files that are in folder.
I've wrote this

library(foreign)

fuente=list.files("C:/Users/Jceccarelli/Bases/Stata", pattern="dta$",
full.names=FALSE)

for (i in 1:length(fuente)){

xxx=read.dta(fuente[i], to.data.frame=TRUE)


}

But i get this error

Error in read.dta(fuente[i], to.data.frame = TRUE) :
  unused argument (to.data.frame = TRUE)

What am i doing wrong?

	[[alternative HTML version deleted]]


From miguelhoz at hotmail.com  Mon Aug 22 15:38:45 2016
From: miguelhoz at hotmail.com (MIKE DE LA HOZ)
Date: Mon, 22 Aug 2016 13:38:45 +0000
Subject: [R] Chaid Decision Tree
In-Reply-To: <DB3PR01MB251BA38597990C687C51F10ADE80@DB3PR01MB251.eurprd01.prod.exchangelabs.com>
References: <DB3PR01MB251BA38597990C687C51F10ADE80@DB3PR01MB251.eurprd01.prod.exchangelabs.com>
Message-ID: <DB3PR01MB25166973BC09C0909D4E7B5ADE80@DB3PR01MB251.eurprd01.prod.exchangelabs.com>


Hi,


I am running a chaid tree using titanic dataset (see attachment)



setwd("C:/Users/miguel")

titanic <- read.csv("train.csv")
titanic.s <- subset( titanic, select = -c(PassengerId, Name ) )

ctrl <- chaid_control(minsplit = 20, minbucket = 5, minprob = 0)
chaidTitanic <- chaid(Survived ~ ., data = titanic, control = ctrl)



It looks like I get the following error

Error: is.factor(x) is not TRUE



can you please help me here? I am not able to follow this type of error. if you can rewrite the sentence for me, It will be much appreciated


Thanks



From Achim.Zeileis at uibk.ac.at  Mon Aug 22 19:24:48 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 22 Aug 2016 19:24:48 +0200 (CEST)
Subject: [R] Chaid Decision Tree
In-Reply-To: <DB3PR01MB25166973BC09C0909D4E7B5ADE80@DB3PR01MB251.eurprd01.prod.exchangelabs.com>
References: <DB3PR01MB251BA38597990C687C51F10ADE80@DB3PR01MB251.eurprd01.prod.exchangelabs.com>
	<DB3PR01MB25166973BC09C0909D4E7B5ADE80@DB3PR01MB251.eurprd01.prod.exchangelabs.com>
Message-ID: <alpine.DEB.2.20.1608221921040.19093@paninaro>

On Mon, 22 Aug 2016, MIKE DE LA HOZ wrote:

>
> Hi,
>
>
> I am running a chaid tree using titanic dataset (see attachment)
>
>
>
> setwd("C:/Users/miguel")
>
> titanic <- read.csv("train.csv")
> titanic.s <- subset( titanic, select = -c(PassengerId, Name ) )
>
> ctrl <- chaid_control(minsplit = 20, minbucket = 5, minprob = 0)
> chaidTitanic <- chaid(Survived ~ ., data = titanic, control = ctrl)
>
>
>
> It looks like I get the following error
>
> Error: is.factor(x) is not TRUE
>
>
>
> can you please help me here? I am not able to follow this type of error. if you can rewrite the sentence for me, It will be much appreciated

To be able to apply the chaid() function all variables (both response and 
predictor) need to be categorical variables, i.e., in R of class "factor".

It is not clear which variables are the culprits here because your example 
is not reproducible. I guess that there are at least some numeric 
regressor variables. Maybe the "Survived" response is also in numeric 
dummy coding rather than the appropriate "factor" variable.

In any case, I would recommend to use a tree model that can deal with both 
kinds of regressor variables. If you want something that selections split 
variables and split points based on statistical tests, ctree() from 
package "partykit" would be the obvious candidate.

>
> Thanks
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Mon Aug 22 19:32:31 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Mon, 22 Aug 2016 18:32:31 +0100
Subject: [R] Loop over folder files
In-Reply-To: <CALBYkj+rCTRsu2RkkUaEdncJW6BaiHM1hMjjnOEJU85xpGeq=A@mail.gmail.com>
Message-ID: <20160822183231.Horde._-cnU0NlTggKzot0Wd-92_X@mail.sapo.pt>

Hello,

That argument doesn't exist, hence the error.
Read the help page ?read.dta more carefully. You will see that already  
read.dta reads into a data.frame.

Hope this helps,

Rui Barradas
?

Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:

> Hi
> I need to apply some code over some stata files that are in folder.
> I've wrote this
>
> library(foreign)
>
> fuente=list.files("C:/Users/Jceccarelli/Bases/Stata", pattern="dta$",
> full.names=FALSE)
>
> for (i in 1:length(fuente)){
>
> xxx=read.dta(fuente[i], to.data.frame=TRUE)
>
> }
>
> But i get this error
>
> Error in read.dta(fuente[i], to.data.frame = TRUE) :
> unused argument (to.data.frame = TRUE)
>
> What am i doing wrong?
>
> ? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Aug 22 20:57:40 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 22 Aug 2016 14:57:40 -0400
Subject: [R] persp fail with non-equidistant dates
In-Reply-To: <5c5071c386abafe0118d5b38abb96552.squirrel@www.ig.cas.cz>
References: <7a77a449f0c53e21f755744123dad44a.squirrel@www.ig.cas.cz>
	<56ef3d27-b6f4-73ca-7c54-e04b20fe2484@gmail.com>
	<5c5071c386abafe0118d5b38abb96552.squirrel@www.ig.cas.cz>
Message-ID: <0ec006be-43fe-1b23-0446-85b1a926d8cd@gmail.com>

Please keep discussion on the mailing list.

On 22/08/2016 12:08 PM, Tomas Bayer wrote:
> Hello,
> we have tried the pre-processing till now but also with this error message:
>
> akima.li <- interp(x, y, F, xo=seq(min(x), max(x), length = 100),
> yo=seq(min(y), max(y), length = 100))
> Error: could not find function "interp"
>
> We have tried the same with interp.old and interp.new.
> We also got the same error message by packages akima and rgl although they
> are installed (confirmed by apt and synaptic, too).
> Till now, all interpolation routines have failed.
> What would we use as the ideal preparation to persp and contour?

If you are using the interp() function from the akima package,  it 
appears you didn't attach it.  Use

library( pkg )

to attach a package named "pkg".  You may need to install the package 
first; use

install.packages("akima")

if so.

The variable name F may cause you problems: many people use F as an 
abbreviation for FALSE; it's a standard variable defined in the base 
package.  It's a good idea to avoid masking that and causing yourself 
confusion later.

If this advice doesn't fix your problem, then please post a reproducible 
example for others to try.  You might want to select a subset of your 
data if it's too big or too private to post here.

Duncan Murdoch


> Thanks,
>
> Tomas Bayer
>
>> On 22/08/2016 11:17 AM, Tomas Bayer wrote:
>>> Hello,
>>> when I plotted non-equidistant data in 3D (using persp and contour), it
>>> was ended with the same error message:
>>>
>>>> persp(y, x, z, xlab="latitude", ylab="longitude", zlab="altiude",
>>> main="Altitude")
>>> Error in persp.default(y, x, z, xlab = "latitude", ylab = "longitude",
>>> :
>>>   increasing 'x' and 'y' values expected
>>>
>>> How to fix it? The original data are in columns
>>>
>>>  50.84925    14.65715 614.0  48909.14   -62.49  99  48929  5  122306
>>>  50.84919    14.65702 617.0  48816.32  -145.82  69  48836  6  122331
>>>  50.84908    14.65681 622.0  49113.40     6.64  99  49133  4  122442
>>
>> You haven't shown us what is in y, x and z, but it looks as though you
>> haven't got data in the form required by persp, i.e. a vector of
>> increasing values in each of the first two arguments, and a matrix of
>> values in the third.  Using your variable names, you'd want z[i,j] to
>> correspond to y[i] and x[j].
>>
>> If you just have a collection of (y, x, z) triples, you'll need to do
>> some pre-processing to fit a surface and produce the required inputs.
>>
>> Duncan Murdoch
>>
>>
>
>
> Tom?? Bayer
>   ,           ,
>  /             \
> ((__-^^-,-^^-__))
>  `-_---' `---_-'
>   `--|o` 'o|--'
>      \  `  /
>       ): :(
>       :o_o:
>        "-"
> GNU's Not Unix!
>
>


From jfca283 at gmail.com  Mon Aug 22 19:40:43 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Mon, 22 Aug 2016 14:40:43 -0300
Subject: [R] Loop over folder files
In-Reply-To: <20160822183231.Horde._-cnU0NlTggKzot0Wd-92_X@mail.sapo.pt>
References: <CALBYkj+rCTRsu2RkkUaEdncJW6BaiHM1hMjjnOEJU85xpGeq=A@mail.gmail.com>
	<20160822183231.Horde._-cnU0NlTggKzot0Wd-92_X@mail.sapo.pt>
Message-ID: <CALBYkjKPrn0v=sgvDq65aqYSF_qRfbU0qUMuZ3wzivY6nhPLiw@mail.gmail.com>

I removed the data,frame=True...
I obtain this warnings...
Error in read.dta(fuente[i]) : not a Stata version 5-12 .dta file
In addition: There were 50 or more warnings (use warnings() to see the
first 50)

the warnings() throws this
Warning messages:
1: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
paste0(labels,  ... :
  duplicated levels in factors are deprecated
2: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
paste0(labels,  ... :
  duplicated levels in factors are deprecated
3: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
paste0(labels,  ... :
  duplicated levels in factors are deprecated
4: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
paste0(labels,  ... :
  duplicated levels in factors are deprecated
5: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
paste0(labels,  ... :
  duplicated levels in factors are deprecated



On Mon, Aug 22, 2016 at 2:32 PM, <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> That argument doesn't exist, hence the error.
> Read the help page ?read.dta more carefully. You will see that already
> read.dta reads into a data.frame.
>
> Hope this helps,
>
> Rui Barradas
>
>
> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>
> Hi
> I need to apply some code over some stata files that are in folder.
> I've wrote this
>
> library(foreign)
>
> fuente=list.files("C:/Users/Jceccarelli/Bases/Stata", pattern="dta$",
> full.names=FALSE)
>
> for (i in 1:length(fuente)){
>
> xxx=read.dta(fuente[i], to.data.frame=TRUE)
>
>
> }
>
> But i get this error
>
> Error in read.dta(fuente[i], to.data.frame = TRUE) :
> unused argument (to.data.frame = TRUE)
>
> What am i doing wrong?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.htmland provide commented, minimal, self-contained,
> reproducible code.
>
>
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Aug 22 21:51:53 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 22 Aug 2016 12:51:53 -0700
Subject: [R] Loop over folder files
In-Reply-To: <CALBYkjKPrn0v=sgvDq65aqYSF_qRfbU0qUMuZ3wzivY6nhPLiw@mail.gmail.com>
References: <CALBYkj+rCTRsu2RkkUaEdncJW6BaiHM1hMjjnOEJU85xpGeq=A@mail.gmail.com>
	<20160822183231.Horde._-cnU0NlTggKzot0Wd-92_X@mail.sapo.pt>
	<CALBYkjKPrn0v=sgvDq65aqYSF_qRfbU0qUMuZ3wzivY6nhPLiw@mail.gmail.com>
Message-ID: <09978D08-EE89-4705-B10C-295FC7BD92D0@comcast.net>


> On Aug 22, 2016, at 10:40 AM, Juan Ceccarelli Arias <jfca283 at gmail.com> wrote:
> 
> I removed the data,frame=True...
> I obtain this warnings...
> Error in read.dta(fuente[i]) : not a Stata version 5-12 .dta file

Well, that seems fairly self-explanatory. What version of Stata are you using and does it have capacity to write to one of hte versions that are supported by read.dta?

-- 
David.


> In addition: There were 50 or more warnings (use warnings() to see the
> first 50)
> 
> the warnings() throws this
> Warning messages:
> 1: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
>  duplicated levels in factors are deprecated
> 2: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
>  duplicated levels in factors are deprecated
> 3: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
>  duplicated levels in factors are deprecated
> 4: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
>  duplicated levels in factors are deprecated
> 5: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
>  duplicated levels in factors are deprecated
> 
> 
> 
> On Mon, Aug 22, 2016 at 2:32 PM, <ruipbarradas at sapo.pt> wrote:
> 
>> Hello,
>> 
>> That argument doesn't exist, hence the error.
>> Read the help page ?read.dta more carefully. You will see that already
>> read.dta reads into a data.frame.
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> 
>> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>> 
>> Hi
>> I need to apply some code over some stata files that are in folder.
>> I've wrote this
>> 
>> library(foreign)
>> 
>> fuente=list.files("C:/Users/Jceccarelli/Bases/Stata", pattern="dta$",
>> full.names=FALSE)
>> 
>> for (i in 1:length(fuente)){
>> 
>> xxx=read.dta(fuente[i], to.data.frame=TRUE)
>> 
>> 
>> }
>> 
>> But i get this error
>> 
>> Error in read.dta(fuente[i], to.data.frame = TRUE) :
>> unused argument (to.data.frame = TRUE)
>> 
>> What am i doing wrong?
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.htmland provide commented, minimal, self-contained,
>> reproducible code.
>> 
>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rmh at temple.edu  Mon Aug 22 22:43:39 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 22 Aug 2016 16:43:39 -0400
Subject: [R] Estimated Effects Not Balanced
In-Reply-To: <CAEtAGeq-r1OW6yw4fxmu1wG8bbCGSB8h5qjmegrxNPTa3V6=aA@mail.gmail.com>
References: <CAEtAGeq-r1OW6yw4fxmu1wG8bbCGSB8h5qjmegrxNPTa3V6=aA@mail.gmail.com>
Message-ID: <CAGx1TMAkoiK0Xvnp_YmBBnRVPfYQBFEtgXNVHatqv=VibUq-rw@mail.gmail.com>

The problem is that you have 12 observations and 1+2+10=13 degrees of freedom.
There should be 1 + 2 + 8 = 11 degrees of freedom.
Probably one of your variables is masked by something else in you workspace.
Protect yourself by using a data.frame

> tmp <- data.frame(A=factor(c(1,1,1,1,1,1,2,2,2,2,2,2)),
+ B=factor(c(1,1,2,2,3,3,1,1,2,2,3,3)),
+ y=rnorm(12))
> mod <- aov(y ~ A+B, data=tmp)
> summary(mod)
            Df Sum Sq Mean Sq F value Pr(>F)
A            1  1.553   1.553   1.334  0.281
B            2  3.158   1.579   1.357  0.311
Residuals    8  9.311   1.164

On Mon, Aug 22, 2016 at 11:15 AM, Justin Thong <justinthong93 at gmail.com> wrote:
> Something does not make sense in R. It has to do with the question of
> balance and unbalance.
>
> *A<-factor(c(1,1,1,1,1,1,2,2,2,2,2,2))*
> *B<-factor(c(1,1,2,2,3,3,1,1,2,2,3,3))*
> *y<-rnorm(12)*
> *mod<-aov(y~A+B)*
>
> I was under the impression that the design is balanced ie order does not
> effect the sums of squares. However, when I compute the anova R reports
> that the Estimated Effects are Unbalanced. I thought that when all
> combinations of levels of A and B have equal replications then the design
> is called balanced. But, R tends to think that when not all levels of A and
> levels of B have equal replication, then the "Estimated Effects are
> unbalanced".... Is this the same as the design being unbalanced? Because
> for the example below, where the error occured, the order does not matter
> (which make me think that the design is balanced).
>
>
> *Call:*
> *   aov(formula = y ~ A + B)*
>
> *Terms:*
> *                        A         B Residuals*
> *Sum of Squares   0.872572  0.025604 16.805706*
> *Deg. of Freedom         1         2        10*
>
> *Residual standard error: 1.296368*
> *Estimated effects may be unbalanced*
> --
> Yours sincerely,
> Justin
>
> *I check my email at 9AM and 4PM everyday*
> *If you have an EMERGENCY, contact me at +447938674419(UK) or
> +60125056192(Malaysia)*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Aug 23 00:32:55 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 22 Aug 2016 15:32:55 -0700
Subject: [R] Estimated Effects Not Balanced
In-Reply-To: <CAGx1TMAkoiK0Xvnp_YmBBnRVPfYQBFEtgXNVHatqv=VibUq-rw@mail.gmail.com>
References: <CAEtAGeq-r1OW6yw4fxmu1wG8bbCGSB8h5qjmegrxNPTa3V6=aA@mail.gmail.com>
	<CAGx1TMAkoiK0Xvnp_YmBBnRVPfYQBFEtgXNVHatqv=VibUq-rw@mail.gmail.com>
Message-ID: <CAGxFJbS1Qa_E3Zqrb8RX-WkV3PUqHv2Ucmo8ma=smasc7wSB=A@mail.gmail.com>

Thanks, Rich. I didn't notice that!

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 22, 2016 at 1:43 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
> The problem is that you have 12 observations and 1+2+10=13 degrees of freedom.
> There should be 1 + 2 + 8 = 11 degrees of freedom.
> Probably one of your variables is masked by something else in you workspace.
> Protect yourself by using a data.frame
>
>> tmp <- data.frame(A=factor(c(1,1,1,1,1,1,2,2,2,2,2,2)),
> + B=factor(c(1,1,2,2,3,3,1,1,2,2,3,3)),
> + y=rnorm(12))
>> mod <- aov(y ~ A+B, data=tmp)
>> summary(mod)
>             Df Sum Sq Mean Sq F value Pr(>F)
> A            1  1.553   1.553   1.334  0.281
> B            2  3.158   1.579   1.357  0.311
> Residuals    8  9.311   1.164
>
> On Mon, Aug 22, 2016 at 11:15 AM, Justin Thong <justinthong93 at gmail.com> wrote:
>> Something does not make sense in R. It has to do with the question of
>> balance and unbalance.
>>
>> *A<-factor(c(1,1,1,1,1,1,2,2,2,2,2,2))*
>> *B<-factor(c(1,1,2,2,3,3,1,1,2,2,3,3))*
>> *y<-rnorm(12)*
>> *mod<-aov(y~A+B)*
>>
>> I was under the impression that the design is balanced ie order does not
>> effect the sums of squares. However, when I compute the anova R reports
>> that the Estimated Effects are Unbalanced. I thought that when all
>> combinations of levels of A and B have equal replications then the design
>> is called balanced. But, R tends to think that when not all levels of A and
>> levels of B have equal replication, then the "Estimated Effects are
>> unbalanced".... Is this the same as the design being unbalanced? Because
>> for the example below, where the error occured, the order does not matter
>> (which make me think that the design is balanced).
>>
>>
>> *Call:*
>> *   aov(formula = y ~ A + B)*
>>
>> *Terms:*
>> *                        A         B Residuals*
>> *Sum of Squares   0.872572  0.025604 16.805706*
>> *Deg. of Freedom         1         2        10*
>>
>> *Residual standard error: 1.296368*
>> *Estimated effects may be unbalanced*
>> --
>> Yours sincerely,
>> Justin
>>
>> *I check my email at 9AM and 4PM everyday*
>> *If you have an EMERGENCY, contact me at +447938674419(UK) or
>> +60125056192(Malaysia)*
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kmnanus at gmail.com  Mon Aug 22 22:17:50 2016
From: kmnanus at gmail.com (KMNanus)
Date: Mon, 22 Aug 2016 16:17:50 -0400
Subject: [R] Please help me, I'm trying to update my version of R
Message-ID: <2FF913B1-95AA-448C-9224-CBF6EE4CDD4B@gmail.com>

I?m a newbie running 3.2.4 on a mac equipped with Yosemite (10.10.5).

I want to update to 3.3.1 and have downloaded the package, but have not been able to install it.  I?ve tried install.packages("R-3.3.1.tar.gz?) and install.packages("R-3.3.1.pkg?) after downloading both files.

I get an error msg - "package ?R-3.3.1.pkg? is not available (for R version 3.2.4)"

I know this question has shown up on several message boards but I?m having trouble understanding the process.

Is there a straightforward way to update my version of R and, if successful, will R automatically work with the packages I?ve installed?

Ken Nanus
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)




From mailund at birc.au.dk  Tue Aug 23 05:45:32 2016
From: mailund at birc.au.dk (Thomas Mailund)
Date: Tue, 23 Aug 2016 03:45:32 +0000
Subject: [R] Please help me, I'm trying to update my version of R
In-Reply-To: <2FF913B1-95AA-448C-9224-CBF6EE4CDD4B@gmail.com>
References: <2FF913B1-95AA-448C-9224-CBF6EE4CDD4B@gmail.com>
Message-ID: <etPan.57bbc6db.74b0dc51.71d@birc.au.dk>

Hi Ken,

You are trying to install R as a package. That won't work. The .pkg file you downloaded from https://cran.r-project.org/bin/macosx/ is an installer, though, so if you just double-click on it, it should take you through the installation. After that you probably need to install a number of packages, since the ones you have installed for version 3.2 R won't be available in the 3.3 installation, but *those* packages you can install using install.packages.

Cheers

--
Thomas Mailund

On 22 August 2016 at 22:17:50, KMNanus (kmnanus at gmail.com<mailto:kmnanus at gmail.com>) wrote:

I?m a newbie running 3.2.4 on a mac equipped with Yosemite (10.10.5).

I want to update to 3.3.1 and have downloaded the package, but have not been able to install it. I?ve tried install.packages("R-3.3.1.tar.gz?) and install.packages("R-3.3.1.pkg?) after downloading both files.

I get an error msg - "package ?R-3.3.1.pkg? is not available (for R version 3.2.4)"

I know this question has shown up on several message boards but I?m having trouble understanding the process.

Is there a straightforward way to update my version of R and, if successful, will R automatically work with the packages I?ve installed?

Ken Nanus
kmnanus at gmail.com
914-450-0816<tel:914-450-0816> (tel)
347-730-4813<tel:347-730-4813> (fax)



______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Tue Aug 23 08:27:46 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 23 Aug 2016 08:27:46 +0200
Subject: [R] Please help me, I'm trying to update my version of R
In-Reply-To: <2FF913B1-95AA-448C-9224-CBF6EE4CDD4B@gmail.com>
References: <2FF913B1-95AA-448C-9224-CBF6EE4CDD4B@gmail.com>
Message-ID: <3A16AC79-3258-43FF-84FE-A580F2FC1936@xs4all.nl>


> On 22 Aug 2016, at 22:17, KMNanus <kmnanus at gmail.com> wrote:
> 
> I?m a newbie running 3.2.4 on a mac equipped with Yosemite (10.10.5).
> 
> I want to update to 3.3.1 and have downloaded the package, but have not been able to install it.  I?ve tried install.packages("R-3.3.1.tar.gz?) and install.packages("R-3.3.1.pkg?) after downloading both files.
> 
> I get an error msg - "package ?R-3.3.1.pkg? is not available (for R version 3.2.4)"
> 
> I know this question has shown up on several message boards but I?m having trouble understanding the process.
> 
> Is there a straightforward way to update my version of R and, if successful, will R automatically work with the packages I?ve installed?
> 

This question is actually for R-SIG-Mac.

After double clicking on the R-3.3.1.pkg you will have R 3.3.1 installed.
You don't need to run install.packages to get the packages for R-3.3.1.
You can have R install the current versions of the packages you had installed.

Start the R GUI.
Go to the menu: 
- Click Packages & Data
- select Package Installer
- click Get List
- click the disclosure triangle in the Package Search input field. And then click Select packages from R.....

This should work if your previous installation of R was installed by the regular installer of R on Mac OS X.

Berend

> Ken Nanus
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Tue Aug 23 08:35:46 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 23 Aug 2016 08:35:46 +0200
Subject: [R] Please help me, I'm trying to update my version of R
In-Reply-To: <3A16AC79-3258-43FF-84FE-A580F2FC1936@xs4all.nl>
References: <2FF913B1-95AA-448C-9224-CBF6EE4CDD4B@gmail.com>
	<3A16AC79-3258-43FF-84FE-A580F2FC1936@xs4all.nl>
Message-ID: <D05B1AD3-ACC1-4B67-8A7C-3C8CF2ED3B44@xs4all.nl>

Follow up on my previous mail.

See the FAQ for OS X :https://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html

Read the section  "3.2 Installation of packages". It tells it all.
(reachable from the contents entry "How to install packages").

Berend


> On 23 Aug 2016, at 08:27, Berend Hasselman <bhh at xs4all.nl> wrote:
> 
>> 
>> On 22 Aug 2016, at 22:17, KMNanus <kmnanus at gmail.com> wrote:
>> 
>> I?m a newbie running 3.2.4 on a mac equipped with Yosemite (10.10.5).
>> 
>> I want to update to 3.3.1 and have downloaded the package, but have not been able to install it.  I?ve tried install.packages("R-3.3.1.tar.gz?) and install.packages("R-3.3.1.pkg?) after downloading both files.
>> 
>> I get an error msg - "package ?R-3.3.1.pkg? is not available (for R version 3.2.4)"
>> 
>> I know this question has shown up on several message boards but I?m having trouble understanding the process.
>> 
>> Is there a straightforward way to update my version of R and, if successful, will R automatically work with the packages I?ve installed?
>> 
> 
> This question is actually for R-SIG-Mac.
> 
> After double clicking on the R-3.3.1.pkg you will have R 3.3.1 installed.
> You don't need to run install.packages to get the packages for R-3.3.1.
> You can have R install the current versions of the packages you had installed.
> 
> Start the R GUI.
> Go to the menu: 
> - Click Packages & Data
> - select Package Installer
> - click Get List
> - click the disclosure triangle in the Package Search input field. And then click Select packages from R.....
> 
> This should work if your previous installation of R was installed by the regular installer of R on Mac OS X.
> 
> Berend
> 
>> Ken Nanus
>> kmnanus at gmail.com
>> 914-450-0816 (tel)
>> 347-730-4813 (fax)
>> 
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kmnanus at gmail.com  Tue Aug 23 05:56:09 2016
From: kmnanus at gmail.com (KMNanus)
Date: Mon, 22 Aug 2016 23:56:09 -0400
Subject: [R] Please help me, I'm trying to update my version of R
In-Reply-To: <etPan.57bbc6db.74b0dc51.71d@birc.au.dk>
References: <2FF913B1-95AA-448C-9224-CBF6EE4CDD4B@gmail.com>
	<etPan.57bbc6db.74b0dc51.71d@birc.au.dk>
Message-ID: <F07FFA63-F921-4F15-9F30-B228387D38E0@gmail.com>

Thanks for getting back to me. Worked like a charm.  


Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)



> On Aug 22, 2016, at 11:45 PM, Thomas Mailund <mailund at birc.au.dk> wrote:
> 
> Hi Ken,
> 
> You are trying to install R as a package. That won't work. The .pkg file you downloaded from https://cran.r-project.org/bin/macosx/ is an installer, though, so if you just double-click on it, it should take you through the installation. After that you probably need to install a number of packages, since the ones you have installed for version 3.2 R won't be available in the 3.3 installation, but *those* packages you can install using install.packages.
> 
> Cheers
> 
> -- 
> Thomas Mailund
> On 22 August 2016 at 22:17:50, KMNanus (kmnanus at gmail.com <mailto:kmnanus at gmail.com>) wrote:
> 
>> I?m a newbie running 3.2.4 on a mac equipped with Yosemite (10.10.5).
>> 
>> I want to update to 3.3.1 and have downloaded the package, but have not been able to install it. I?ve tried install.packages("R-3.3.1.tar.gz?) and install.packages("R-3.3.1.pkg?) after downloading both files.
>> 
>> I get an error msg - "package ?R-3.3.1.pkg? is not available (for R version 3.2.4)"
>> 
>> I know this question has shown up on several message boards but I?m having trouble understanding the process.
>> 
>> Is there a straightforward way to update my version of R and, if successful, will R automatically work with the packages I?ve installed?
>> 
>> Ken Nanus
>> kmnanus at gmail.com
>> 914-450-0816 <tel:914-450-0816> (tel)
>> 347-730-4813 <tel:347-730-4813> (fax)
>> 
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From judyoringe at naver.com  Tue Aug 23 08:33:38 2016
From: judyoringe at naver.com (=?UTF-8?B?7J207JWE66aE?=)
Date: Tue, 23 Aug 2016 15:33:38 +0900 (KST)
Subject: [R] =?utf-8?q?=5BFriedmann_test_for_2_factor_mixed_design=5D_I_ne?=
 =?utf-8?q?ed_your_help=2EI_trying_to_do_non-parametric_2way_anova?=
Message-ID: <7bf9efa2b9bc8e3a9aca6329d23ab@cweb21.nm.nhnsystem.com>

 
Hi!
 
I'm trying to do the non-parametric test for 2 factor mixed anova. 
 
I got 2 factors, one is within-subject factor, AGE(2levels), and the other is between-subject factor, Speed(6levels).
One dependent variables, RT.
 
The data, I got, is not satisfied with the normality and homogeneity of variance. 


So I tried to do the non-parametric test and use the Friedmann test function(friedman.test) in R . 


and I got the error message as below.. 
"Error in friedman.test.default(RT, Speed, AGE) : 
friedman.test error: not an unreplicated complete block design"
 
How can I deal with this problem? 
Please help  
 
Thanks!
 
Kind regards, 
 
Ahreum 


 

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Aug 23 09:33:41 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 23 Aug 2016 00:33:41 -0700
Subject: [R] [Friedmann test for 2 factor mixed design] I need your
	help.I trying to do non-parametric 2way anova
In-Reply-To: <7bf9efa2b9bc8e3a9aca6329d23ab@cweb21.nm.nhnsystem.com>
References: <7bf9efa2b9bc8e3a9aca6329d23ab@cweb21.nm.nhnsystem.com>
Message-ID: <C4357B75-80DF-4F00-9876-3D6D0D00F6AE@comcast.net>


> On Aug 22, 2016, at 11:33 PM, ??? <judyoringe at naver.com> wrote:
> 
> 
> Hi!
> 
> I'm trying to do the non-parametric test for 2 factor mixed anova. 
> 
> I got 2 factors, one is within-subject factor, AGE(2levels), and the other is between-subject factor, Speed(6levels).
> One dependent variables, RT.
> 
> The data, I got, is not satisfied with the normality and homogeneity of variance. 

Those conditions are not applicable to the data but rather on residuals.
> 
> 
> So I tried to do the non-parametric test and use the Friedmann test function(friedman.test) in R . 
> 
> 
> and I got the error message as below.. 
> "Error in friedman.test.default(RT, Speed, AGE) : 
> friedman.test error: not an unreplicated complete block design"
> 
> How can I deal with this problem? 

Depending on the severity of lack of homogeneity of variance on residuals, you may (or may not)  need to consider robust methods.

https://cran.r-project.org/web/views/Robust.html

> Please help  
> 
> Thanks!
> 
> Kind regards, 
> 
> Ahreum 
> 
> 
> 	[[alternative HTML version deleted]]

Any response should be posted in plain text.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From maechler at stat.math.ethz.ch  Tue Aug 23 10:06:48 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 23 Aug 2016 10:06:48 +0200
Subject: [R] Error while fitting gumbel copula
In-Reply-To: <CAE1aWa88OgFRS+Hmj5rXdeCw5GZy=HX5NDPpxpgAWECFxVPsPg@mail.gmail.com>
References: <CAE1aWa_AJRovvq9sZU2LWA3VaBCWAC_mxLoK4L7kzy=HkjgEHQ@mail.gmail.com>
	<22443.20835.731336.772515@stat.math.ethz.ch>
	<CAE1aWa-C91VyzjCyygyot4udAM4LkHCKWS1ZwYaHBNyVZVdy8w@mail.gmail.com>
	<CAE1aWa88OgFRS+Hmj5rXdeCw5GZy=HX5NDPpxpgAWECFxVPsPg@mail.gmail.com>
Message-ID: <22460.1048.493690.265715@stat.math.ethz.ch>

>>>>> Isaudin Ismail <isaudin at gmail.com>
>>>>>     on Thu, 18 Aug 2016 17:03:50 +0100 writes:

    > Dear Martin, Following my earlier question on "error while
    > fitting gumbel copula", I have also crated a new gist at
    > https://gist.github.com/anonymous/0bb8aba7adee550d40b840a47d8b7e25 
    > for easy checking and copying codes.

    > I got no problem fitting other Archimedean copulas except
    > gumbel copula as per my code I used above.

    > Appreciate your kind help.

    > Many thanks, Isaudin


    > On Mon, Aug 15, 2016 at 4:28 PM, Isaudin Ismail
    > <isaudin at gmail.com> wrote:

    >> Dear Dr. Martin,
    >> 
    >> I'm glad that you replied to my queries.
    >> 
    >> As advised, I have prepared the following:

MM: I'm including (cut'n'pasting) my commented and augmented version here:

------------------------------------------------------------------

## From: Isaudin Ismail <isaudin at gmail.com>
## To: Martin Maechler <maechler at stat.math.ethz.ch>
## CC: <r-help at r-project.org>
## Subject: Re: [R] Error while fitting gumbel copula
## Date: Mon, 15 Aug 2016 16:28:14 +0100

## Dear Dr. Martin,

## I'm glad that you replied to my queries.
## As advised, I have prepared the following:

library(copula)

## 5 series of data, A, B, C, D and E
A <- c(0.849420849, 0.900652985, 0.97144217, 0.817888428, 0.877901578,
       1.070040669, 0.889742431, 0.87588968, 0.853541938, 0.848664688,
       0.876830319, 0.749582638, 0.818515498, 0.890997174, 0.794766966,
       0.784794851, 0.814858959, 1.074396518, 0.83752495, 0.894341116,
       0.880375293, 0.900816803)

B <- c(0.479850746, 0.652111668, 1.880607815, 0.579902303, 0.50669344,
       0.747560182, 0.701754386, 0.48969697, 0.346751006, 0.379234973,
       0.862691466, 0.328280188, 0.317312661, 0.534438115, 0.487002653,
       0.335043612, 0.373346897, 0.627520161, 0.792114695, 0.938253012,
       0.444553967, 0.625972763)

C <- c(0.693491124, 0.866523143, 4.585714286, 1.512055109, 0.387755102,
       0.513435701, 0.76252505, -0.113113113, 0.338521401, 0.333951763,
       0.668755595, 0.401273885, 0.419868791, 0.272885789, 0.541541542,
       0.32751938, 0.386409736, 0.957446809, 0.861195542, 1.531632653,
       0.431610942, 1.226470588)

D <- c(0.807792208, 0.548547718, 0.738232865, 0.542247744, 1.088964927,
       0.862385321, 0.60720268, 1.000816993, 0.699289661, 0.41723356,
       0.604037267, 0.605003791, 0.698940998, 0.764792899, 0.647897898,
       0.825256975, 0.767476085, 0.941391941, 0.889547813, 0.324503311,
       0.942435424, 0.740686633)

E <- c(1.077598829, 0.318507891, 1.152616279, 0.930397727, 1.515994437,
       0.940689655, 0.880886427, 1.054274084, 1.067282322, 0.677419355,
       0.966233766, 0.761029412, 1.05734767, 0.615925059, 1.061988304,
       1.07184241, 1.058890147, 1.123873874, 1.304891923, -0.069584736,
       1.172757475, 0.501096491)

require(copula)
gumbel.copula <- gumbelCopula(dim = 2)
p <- pobs(cbind(D + E, A + B+ C ))

fit.gumbel <- fitCopula(gumbel.copula, p, method = "ml")

## The error is here when trying to fit the gumbel copula

# I got the following error:
## Error in optim(start, loglikCopula, lower = lower, upper = upper, method =
## method,  :
##                  non-finite finite-difference value [1]
##               In addition: Warning message:
##               In .local(copula, tau, ...) : tau is out of the range [0, 1]

## MM:  my version of copula gives the error message  "some tau < 0"
## --                                                      ---------
## and indeed:
(tau.p <- cor(p[,1], p[,2], method="kendall"))
## [1] -0.1428571
##     ^---------  Kendall's tau is =  - 1/7  < 0  ... and that is not good for Gumbel!

plot(p)

##-----------------------------------------------------------------------------

So, you tried fitting to *negatively* correlated data, and if
you use the default instead of "ml" the copula is fit, and uses
param = 1 (which corresponds to the *independence* copula:
Because among all the (weakly) positively correlated gumbel
copulas, the boundary case, param = 1 (<==> tau = 0) is the best
fitting.

What you can do is to "rotate" the data (actually mirror it),
and fit a gumbel copula, which now works nice and easily :

p2 <- p; p2[,2] <- 1-p2[,2]
(tau.p2 <- cor(p2, method="kendall"))
## --> now positively correlated
## --->
gumb.ml.p2 <- fitCopula(gumbel.copula, p2, method = "ml")
summary(gumb.ml.p2) # looks fine now :

  Call: fitCopula(copula, data = data, method = "ml")
  Fit based on "maximum likelihood" and 22 2-dimensional observations.
  Gumbel copula, dim. d = 2 
	  Estimate Std. Error
  param    1.121      0.209
  The maximized loglikelihood is 0.1839 
  Optimization converged
  Number of loglikelihood evaluations:
  function gradient 
         6        6 


---

The next version of copula --- or the R-forge one, if you are
interested will support fitting "rotated" copulas,
so you fit a rotated gumbel copula, flipping, the 2nd coordinate
(but not the first):

rotGcop <- rotCopula(gumbelCopula(), flip=c(FALSE,TRUE))

f2 <- fitCopula(rotGcop, data = p) # default method: "mlp"
summary(f2)

  ## Call: fitCopula(copula, data = data)
  ## Fit based on "maximum pseudo-likelihood" and 22 2-dimensional observations.
  ## rotCopula copula:  Gumbel copula, dim. d = 2 
  ##       Estimate Std. Error
  ## param    1.121      0.225
  ## The maximized loglikelihood is 0.1839 
  ## Optimization converged
  ## Number of loglikelihood evaluations:
  ## function gradient 
  ##        6        6 

-------

Best regards,

Martin Maechler,
ETH Zurich


From lists at dewey.myzen.co.uk  Tue Aug 23 10:38:00 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 23 Aug 2016 09:38:00 +0100
Subject: [R] Loop over folder files
In-Reply-To: <CALBYkjKPrn0v=sgvDq65aqYSF_qRfbU0qUMuZ3wzivY6nhPLiw@mail.gmail.com>
References: <CALBYkj+rCTRsu2RkkUaEdncJW6BaiHM1hMjjnOEJU85xpGeq=A@mail.gmail.com>
	<20160822183231.Horde._-cnU0NlTggKzot0Wd-92_X@mail.sapo.pt>
	<CALBYkjKPrn0v=sgvDq65aqYSF_qRfbU0qUMuZ3wzivY6nhPLiw@mail.gmail.com>
Message-ID: <dc661336-cf4f-b772-5822-c31e97166c62@dewey.myzen.co.uk>

Dear Juan

If this is a Stata 13 file the package readstata13 available from CRAN 
may be of assistance.

On 22/08/2016 18:40, Juan Ceccarelli Arias wrote:
> I removed the data,frame=True...
> I obtain this warnings...
> Error in read.dta(fuente[i]) : not a Stata version 5-12 .dta file
> In addition: There were 50 or more warnings (use warnings() to see the
> first 50)
>
> the warnings() throws this
> Warning messages:
> 1: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
>   duplicated levels in factors are deprecated
> 2: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
>   duplicated levels in factors are deprecated
> 3: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
>   duplicated levels in factors are deprecated
> 4: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
>   duplicated levels in factors are deprecated
> 5: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
>   duplicated levels in factors are deprecated
>
>
>
> On Mon, Aug 22, 2016 at 2:32 PM, <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> That argument doesn't exist, hence the error.
>> Read the help page ?read.dta more carefully. You will see that already
>> read.dta reads into a data.frame.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>>
>> Hi
>> I need to apply some code over some stata files that are in folder.
>> I've wrote this
>>
>> library(foreign)
>>
>> fuente=list.files("C:/Users/Jceccarelli/Bases/Stata", pattern="dta$",
>> full.names=FALSE)
>>
>> for (i in 1:length(fuente)){
>>
>> xxx=read.dta(fuente[i], to.data.frame=TRUE)
>>
>>
>> }
>>
>> But i get this error
>>
>> Error in read.dta(fuente[i], to.data.frame = TRUE) :
>> unused argument (to.data.frame = TRUE)
>>
>> What am i doing wrong?
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.htmland provide commented, minimal, self-contained,
>> reproducible code.
>>
>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From ruipbarradas at sapo.pt  Tue Aug 23 11:31:50 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Tue, 23 Aug 2016 10:31:50 +0100
Subject: [R] Loop over folder files
In-Reply-To: <dc661336-cf4f-b772-5822-c31e97166c62@dewey.myzen.co.uk>
References: <CALBYkj+rCTRsu2RkkUaEdncJW6BaiHM1hMjjnOEJU85xpGeq=A@mail.gmail.com>
	<20160822183231.Horde._-cnU0NlTggKzot0Wd-92_X@mail.sapo.pt>
	<CALBYkjKPrn0v=sgvDq65aqYSF_qRfbU0qUMuZ3wzivY6nhPLiw@mail.gmail.com>
	<dc661336-cf4f-b772-5822-c31e97166c62@dewey.myzen.co.uk>
Message-ID: <20160823103150.Horde.lpio74f3m_msyKXA_KNwTzr@mail.sapo.pt>

Hello,

The op could also use package sos to find that and other packages to  
read stata files.

install.packages("sos")

library(sos)
findFn("stata")
found 374 matches;? retrieving 19 pages
2 3 4 5 6 7 8 9 10
11 12 13 14 15 16 17 18 19
Downloaded 258 links in 121 packages

The first package is readstata13 but there are others.

Hope this helps,

Rui Barradas

?

Citando Michael Dewey <lists at dewey.myzen.co.uk>:

> Dear Juan
>
> If this is a Stata 13 file the package readstata13 available from  
> CRAN may be of assistance.
>
> On 22/08/2016 18:40, Juan Ceccarelli Arias wrote:
>> I removed the data,frame=True...
>> I obtain this warnings...
>> Error in read.dta(fuente[i]) : not a Stata version 5-12 .dta file
>> In addition: There were 50 or more warnings (use warnings() to see the
>> first 50)
>>
>> the warnings() throws this
>> Warning messages:
>> 1: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>> paste0(labels,? ... :
>> duplicated levels in factors are deprecated
>> 2: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>> paste0(labels,? ... :
>> duplicated levels in factors are deprecated
>> 3: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>> paste0(labels,? ... :
>> duplicated levels in factors are deprecated
>> 4: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>> paste0(labels,? ... :
>> duplicated levels in factors are deprecated
>> 5: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>> paste0(labels,? ... :
>> duplicated levels in factors are deprecated
>>
>> On Mon, Aug 22, 2016 at 2:32 PM, <ruipbarradas at sapo.pt> wrote:
>>> Hello,
>>>
>>> That argument doesn't exist, hence the error.
>>> Read the help page ?read.dta more carefully. You will see that already
>>> read.dta reads into a data.frame.
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>>>
>>> Hi
>>> I need to apply some code over some stata files that are in folder.
>>> I've wrote this
>>>
>>> library(foreign)
>>>
>>> fuente=list.files("C:/Users/Jceccarelli/Bases/Stata", pattern="dta$",
>>> full.names=FALSE)
>>>
>>> for (i in 1:length(fuente)){
>>>
>>> xxx=read.dta(fuente[i], to.data.frame=TRUE)
>>>
>>> }
>>>
>>> But i get this error
>>>
>>> Error in read.dta(fuente[i], to.data.frame = TRUE) :
>>> unused argument (to.data.frame = TRUE)
>>>
>>> What am i doing wrong?
>>>
>>> ? ? ? ?[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.htmland provide commented, minimal, self-contained,
>>> reproducible code.
>>>
>>> ?
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Michaelhttp://www.dewey.myzen.co.uk/home.html

?

	[[alternative HTML version deleted]]


From isaudin at gmail.com  Tue Aug 23 13:22:57 2016
From: isaudin at gmail.com (Isaudin Ismail)
Date: Tue, 23 Aug 2016 12:22:57 +0100
Subject: [R] Error while fitting gumbel copula
In-Reply-To: <22460.1048.493690.265715@stat.math.ethz.ch>
References: <CAE1aWa_AJRovvq9sZU2LWA3VaBCWAC_mxLoK4L7kzy=HkjgEHQ@mail.gmail.com>
	<22443.20835.731336.772515@stat.math.ethz.ch>
	<CAE1aWa-C91VyzjCyygyot4udAM4LkHCKWS1ZwYaHBNyVZVdy8w@mail.gmail.com>
	<CAE1aWa88OgFRS+Hmj5rXdeCw5GZy=HX5NDPpxpgAWECFxVPsPg@mail.gmail.com>
	<22460.1048.493690.265715@stat.math.ethz.ch>
Message-ID: <CAE1aWa_P8we8pU8LoZON+NVeYLFpnf4aUGXnfVwb-upfdT8tTw@mail.gmail.com>

Dear Martin,

Thank you for the solutions.

I've tried as per your codes and my problem solved :)

Thanks a lot!

Best regards,
Isaudin



On Tue, Aug 23, 2016 at 9:06 AM, Martin Maechler <maechler at stat.math.ethz.ch
> wrote:

> >>>>> Isaudin Ismail <isaudin at gmail.com>
> >>>>>     on Thu, 18 Aug 2016 17:03:50 +0100 writes:
>
>     > Dear Martin, Following my earlier question on "error while
>     > fitting gumbel copula", I have also crated a new gist at
>     > https://gist.github.com/anonymous/0bb8aba7adee550d40b840a47d8b7e25
>     > for easy checking and copying codes.
>
>     > I got no problem fitting other Archimedean copulas except
>     > gumbel copula as per my code I used above.
>
>     > Appreciate your kind help.
>
>     > Many thanks, Isaudin
>
>
>     > On Mon, Aug 15, 2016 at 4:28 PM, Isaudin Ismail
>     > <isaudin at gmail.com> wrote:
>
>     >> Dear Dr. Martin,
>     >>
>     >> I'm glad that you replied to my queries.
>     >>
>     >> As advised, I have prepared the following:
>
> MM: I'm including (cut'n'pasting) my commented and augmented version here:
>
> ------------------------------------------------------------------
>
> ## From: Isaudin Ismail <isaudin at gmail.com>
> ## To: Martin Maechler <maechler at stat.math.ethz.ch>
> ## CC: <r-help at r-project.org>
> ## Subject: Re: [R] Error while fitting gumbel copula
> ## Date: Mon, 15 Aug 2016 16:28:14 +0100
>
> ## Dear Dr. Martin,
>
> ## I'm glad that you replied to my queries.
> ## As advised, I have prepared the following:
>
> library(copula)
>
> ## 5 series of data, A, B, C, D and E
> A <- c(0.849420849, 0.900652985, 0.97144217, 0.817888428, 0.877901578,
>        1.070040669, 0.889742431, 0.87588968, 0.853541938, 0.848664688,
>        0.876830319, 0.749582638, 0.818515498, 0.890997174, 0.794766966,
>        0.784794851, 0.814858959, 1.074396518, 0.83752495, 0.894341116,
>        0.880375293, 0.900816803)
>
> B <- c(0.479850746, 0.652111668, 1.880607815, 0.579902303, 0.50669344,
>        0.747560182, 0.701754386, 0.48969697, 0.346751006, 0.379234973,
>        0.862691466, 0.328280188, 0.317312661, 0.534438115, 0.487002653,
>        0.335043612, 0.373346897, 0.627520161, 0.792114695, 0.938253012,
>        0.444553967, 0.625972763)
>
> C <- c(0.693491124, 0.866523143, 4.585714286, 1.512055109, 0.387755102,
>        0.513435701, 0.76252505, -0.113113113, 0.338521401, 0.333951763,
>        0.668755595, 0.401273885, 0.419868791, 0.272885789, 0.541541542,
>        0.32751938, 0.386409736, 0.957446809, 0.861195542, 1.531632653,
>        0.431610942, 1.226470588)
>
> D <- c(0.807792208, 0.548547718, 0.738232865, 0.542247744, 1.088964927,
>        0.862385321, 0.60720268, 1.000816993, 0.699289661, 0.41723356,
>        0.604037267, 0.605003791, 0.698940998, 0.764792899, 0.647897898,
>        0.825256975, 0.767476085, 0.941391941, 0.889547813, 0.324503311,
>        0.942435424, 0.740686633)
>
> E <- c(1.077598829, 0.318507891, 1.152616279, 0.930397727, 1.515994437,
>        0.940689655, 0.880886427, 1.054274084, 1.067282322, 0.677419355,
>        0.966233766, 0.761029412, 1.05734767, 0.615925059, 1.061988304,
>        1.07184241, 1.058890147, 1.123873874, 1.304891923, -0.069584736,
>        1.172757475, 0.501096491)
>
> require(copula)
> gumbel.copula <- gumbelCopula(dim = 2)
> p <- pobs(cbind(D + E, A + B+ C ))
>
> fit.gumbel <- fitCopula(gumbel.copula, p, method = "ml")
>
> ## The error is here when trying to fit the gumbel copula
>
> # I got the following error:
> ## Error in optim(start, loglikCopula, lower = lower, upper = upper,
> method =
> ## method,  :
> ##                  non-finite finite-difference value [1]
> ##               In addition: Warning message:
> ##               In .local(copula, tau, ...) : tau is out of the range [0,
> 1]
>
> ## MM:  my version of copula gives the error message  "some tau < 0"
> ## --                                                      ---------
> ## and indeed:
> (tau.p <- cor(p[,1], p[,2], method="kendall"))
> ## [1] -0.1428571
> ##     ^---------  Kendall's tau is =  - 1/7  < 0  ... and that is not
> good for Gumbel!
>
> plot(p)
>
> ##----------------------------------------------------------
> -------------------
>
> So, you tried fitting to *negatively* correlated data, and if
> you use the default instead of "ml" the copula is fit, and uses
> param = 1 (which corresponds to the *independence* copula:
> Because among all the (weakly) positively correlated gumbel
> copulas, the boundary case, param = 1 (<==> tau = 0) is the best
> fitting.
>
> What you can do is to "rotate" the data (actually mirror it),
> and fit a gumbel copula, which now works nice and easily :
>
> p2 <- p; p2[,2] <- 1-p2[,2]
> (tau.p2 <- cor(p2, method="kendall"))
> ## --> now positively correlated
> ## --->
> gumb.ml.p2 <- fitCopula(gumbel.copula, p2, method = "ml")
> summary(gumb.ml.p2) # looks fine now :
>
>   Call: fitCopula(copula, data = data, method = "ml")
>   Fit based on "maximum likelihood" and 22 2-dimensional observations.
>   Gumbel copula, dim. d = 2
>           Estimate Std. Error
>   param    1.121      0.209
>   The maximized loglikelihood is 0.1839
>   Optimization converged
>   Number of loglikelihood evaluations:
>   function gradient
>          6        6
>
>
> ---
>
> The next version of copula --- or the R-forge one, if you are
> interested will support fitting "rotated" copulas,
> so you fit a rotated gumbel copula, flipping, the 2nd coordinate
> (but not the first):
>
> rotGcop <- rotCopula(gumbelCopula(), flip=c(FALSE,TRUE))
>
> f2 <- fitCopula(rotGcop, data = p) # default method: "mlp"
> summary(f2)
>
>   ## Call: fitCopula(copula, data = data)
>   ## Fit based on "maximum pseudo-likelihood" and 22 2-dimensional
> observations.
>   ## rotCopula copula:  Gumbel copula, dim. d = 2
>   ##       Estimate Std. Error
>   ## param    1.121      0.225
>   ## The maximized loglikelihood is 0.1839
>   ## Optimization converged
>   ## Number of loglikelihood evaluations:
>   ## function gradient
>   ##        6        6
>
> -------
>
> Best regards,
>
> Martin Maechler,
> ETH Zurich
>

	[[alternative HTML version deleted]]


From justinthong93 at gmail.com  Tue Aug 23 13:46:26 2016
From: justinthong93 at gmail.com (Justin Thong)
Date: Tue, 23 Aug 2016 12:46:26 +0100
Subject: [R] Estimated Effects Not Balanced
In-Reply-To: <CAGxFJbS1Qa_E3Zqrb8RX-WkV3PUqHv2Ucmo8ma=smasc7wSB=A@mail.gmail.com>
References: <CAEtAGeq-r1OW6yw4fxmu1wG8bbCGSB8h5qjmegrxNPTa3V6=aA@mail.gmail.com>
	<CAGx1TMAkoiK0Xvnp_YmBBnRVPfYQBFEtgXNVHatqv=VibUq-rw@mail.gmail.com>
	<CAGxFJbS1Qa_E3Zqrb8RX-WkV3PUqHv2Ucmo8ma=smasc7wSB=A@mail.gmail.com>
Message-ID: <CAEtAGerG1-XfE0O2g+VssDWCZbkbAOspVo533TmX6o+hnwJszQ@mail.gmail.com>

Hi,

Thanks Richard,

That was me playing with too many examples and having too many variables
just lying around. Thanks for the tip though.

On 22 August 2016 at 23:32, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Thanks, Rich. I didn't notice that!
>
> -- Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Aug 22, 2016 at 1:43 PM, Richard M. Heiberger <rmh at temple.edu>
> wrote:
> > The problem is that you have 12 observations and 1+2+10=13 degrees of
> freedom.
> > There should be 1 + 2 + 8 = 11 degrees of freedom.
> > Probably one of your variables is masked by something else in you
> workspace.
> > Protect yourself by using a data.frame
> >
> >> tmp <- data.frame(A=factor(c(1,1,1,1,1,1,2,2,2,2,2,2)),
> > + B=factor(c(1,1,2,2,3,3,1,1,2,2,3,3)),
> > + y=rnorm(12))
> >> mod <- aov(y ~ A+B, data=tmp)
> >> summary(mod)
> >             Df Sum Sq Mean Sq F value Pr(>F)
> > A            1  1.553   1.553   1.334  0.281
> > B            2  3.158   1.579   1.357  0.311
> > Residuals    8  9.311   1.164
> >
> > On Mon, Aug 22, 2016 at 11:15 AM, Justin Thong <justinthong93 at gmail.com>
> wrote:
> >> Something does not make sense in R. It has to do with the question of
> >> balance and unbalance.
> >>
> >> *A<-factor(c(1,1,1,1,1,1,2,2,2,2,2,2))*
> >> *B<-factor(c(1,1,2,2,3,3,1,1,2,2,3,3))*
> >> *y<-rnorm(12)*
> >> *mod<-aov(y~A+B)*
> >>
> >> I was under the impression that the design is balanced ie order does not
> >> effect the sums of squares. However, when I compute the anova R reports
> >> that the Estimated Effects are Unbalanced. I thought that when all
> >> combinations of levels of A and B have equal replications then the
> design
> >> is called balanced. But, R tends to think that when not all levels of A
> and
> >> levels of B have equal replication, then the "Estimated Effects are
> >> unbalanced".... Is this the same as the design being unbalanced? Because
> >> for the example below, where the error occured, the order does not
> matter
> >> (which make me think that the design is balanced).
> >>
> >>
> >> *Call:*
> >> *   aov(formula = y ~ A + B)*
> >>
> >> *Terms:*
> >> *                        A         B Residuals*
> >> *Sum of Squares   0.872572  0.025604 16.805706*
> >> *Deg. of Freedom         1         2        10*
> >>
> >> *Residual standard error: 1.296368*
> >> *Estimated effects may be unbalanced*
> >> --
> >> Yours sincerely,
> >> Justin
> >>
> >> *I check my email at 9AM and 4PM everyday*
> >> *If you have an EMERGENCY, contact me at +447938674419(UK) or
> >> +60125056192(Malaysia)*
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Yours sincerely,
Justin

*I check my email at 9AM and 4PM everyday*
*If you have an EMERGENCY, contact me at +447938674419(UK) or
+60125056192(Malaysia)*

	[[alternative HTML version deleted]]


From andrluis at ualberta.ca  Tue Aug 23 19:54:22 2016
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Tue, 23 Aug 2016 11:54:22 -0600
Subject: [R] Replicate
Message-ID: <CAHxKz8Zxph5UQpBnWqeRPW_5nkuZgoQ45YoycTGKmN+0ts7tJQ@mail.gmail.com>

Hi, There!

I have this data frame:

> plotdat2
  Firmicutes    Lower    Upper fTissue2
1   63.48023 59.15983 68.11614   CAECUM
2   61.42512 57.24651 65.90875    COLON
3   44.68343 41.62523 47.96632    RUMEN


How can I replicate each line 100 times?

I`m new in R command line, so sorry if my question is nonsense.

Thanks,

-- 
A
LAN

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Aug 23 20:26:07 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 23 Aug 2016 11:26:07 -0700
Subject: [R] Replicate
In-Reply-To: <CAHxKz8Zxph5UQpBnWqeRPW_5nkuZgoQ45YoycTGKmN+0ts7tJQ@mail.gmail.com>
References: <CAHxKz8Zxph5UQpBnWqeRPW_5nkuZgoQ45YoycTGKmN+0ts7tJQ@mail.gmail.com>
Message-ID: <CAGxFJbTZzz-5eAXd0N4eRcF5zKESZJ-t6uNA+Jo-nx8kMW9Yjw@mail.gmail.com>

?rep  (to replicate indices)

plotdat2[rep(1:3,e=100), ]

This seemspretty basic. Have you gone through any R tutorials yet? If
not, please do so before posting further. There are many good ones on
the web.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 23, 2016 at 10:54 AM, Andr? Luis Neves <andrluis at ualberta.ca> wrote:
> Hi, There!
>
> I have this data frame:
>
>> plotdat2
>   Firmicutes    Lower    Upper fTissue2
> 1   63.48023 59.15983 68.11614   CAECUM
> 2   61.42512 57.24651 65.90875    COLON
> 3   44.68343 41.62523 47.96632    RUMEN
>
>
> How can I replicate each line 100 times?
>
> I`m new in R command line, so sorry if my question is nonsense.
>
> Thanks,
>
> --
> A
> LAN
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Tue Aug 23 21:09:42 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 23 Aug 2016 15:09:42 -0400
Subject: [R] Replicate
In-Reply-To: <CAHxKz8Zxph5UQpBnWqeRPW_5nkuZgoQ45YoycTGKmN+0ts7tJQ@mail.gmail.com>
References: <CAHxKz8Zxph5UQpBnWqeRPW_5nkuZgoQ45YoycTGKmN+0ts7tJQ@mail.gmail.com>
Message-ID: <CAM_vjukC9+g2=t=RjQK-po+5+EH0twzYcRKwrWJiCbhtUQc4zA@mail.gmail.com>

I'm not sure why you'd want to, but here's one way to do it:

plotdat2[rep(1:nrow(plotdat), each=100), ]

This puts all the replicates of each row together.


plotdat2[rep(1:nrow(plotdat), times=100), ]

while this repeats each row then starts over.

If that answer doesn't make sense, then you should definitely go read
some of the great introductory material on R out there.

Sarah


On Tue, Aug 23, 2016 at 1:54 PM, Andr? Luis Neves <andrluis at ualberta.ca> wrote:
> Hi, There!
>
> I have this data frame:
>
>> plotdat2
>   Firmicutes    Lower    Upper fTissue2
> 1   63.48023 59.15983 68.11614   CAECUM
> 2   61.42512 57.24651 65.90875    COLON
> 3   44.68343 41.62523 47.96632    RUMEN
>
>
> How can I replicate each line 100 times?
>
> I`m new in R command line, so sorry if my question is nonsense.
>
> Thanks,
>
> --
> A
> LAN
>


From jfca283 at gmail.com  Tue Aug 23 19:01:09 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Tue, 23 Aug 2016 14:01:09 -0300
Subject: [R] Loop over folder files
In-Reply-To: <20160823103150.Horde.lpio74f3m_msyKXA_KNwTzr@mail.sapo.pt>
References: <CALBYkj+rCTRsu2RkkUaEdncJW6BaiHM1hMjjnOEJU85xpGeq=A@mail.gmail.com>
	<20160822183231.Horde._-cnU0NlTggKzot0Wd-92_X@mail.sapo.pt>
	<CALBYkjKPrn0v=sgvDq65aqYSF_qRfbU0qUMuZ3wzivY6nhPLiw@mail.gmail.com>
	<dc661336-cf4f-b772-5822-c31e97166c62@dewey.myzen.co.uk>
	<20160823103150.Horde.lpio74f3m_msyKXA_KNwTzr@mail.sapo.pt>
Message-ID: <CALBYkj+_ZoFWK4VaVDZ2f9xd22b5FzqKLqzKzoKtjHL+4t1GDA@mail.gmail.com>

Im running this but the code doesn't seem work.
It just hangs out but doesn't show any error.


for (i in 1:length(fuente)){

xxx=read_dta(fuente[i])

table(xxx$cise, xxx$sexo)

rm(xxx)

}

On Tue, Aug 23, 2016 at 6:31 AM, <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> The op could also use package sos to find that and other packages to read
> stata files.
>
> install.packages("sos")
>
> library(sos)
> findFn("stata")
> found 374 matches;  retrieving 19 pages
> 2 3 4 5 6 7 8 9 10
> 11 12 13 14 15 16 17 18 19
> Downloaded 258 links in 121 packages
>
>
> The first package is readstata13 but there are others.
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> Citando Michael Dewey <lists at dewey.myzen.co.uk>:
>
> Dear Juan
>
> If this is a Stata 13 file the package readstata13 available from CRAN may
> be of assistance.
>
> On 22/08/2016 18:40, Juan Ceccarelli Arias wrote:
>
> I removed the data,frame=True...
> I obtain this warnings...
> Error in read.dta(fuente[i]) : not a Stata version 5-12 .dta file
> In addition: There were 50 or more warnings (use warnings() to see the
> first 50)
>
> the warnings() throws this
> Warning messages:
> 1: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
> duplicated levels in factors are deprecated
> 2: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
> duplicated levels in factors are deprecated
> 3: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
> duplicated levels in factors are deprecated
> 4: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
> duplicated levels in factors are deprecated
> 5: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
> duplicated levels in factors are deprecated
>
>
>
> On Mon, Aug 22, 2016 at 2:32 PM, <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> That argument doesn't exist, hence the error.
> Read the help page ?read.dta more carefully. You will see that already
> read.dta reads into a data.frame.
>
> Hope this helps,
>
> Rui Barradas
>
>
> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>
> Hi
> I need to apply some code over some stata files that are in folder.
> I've wrote this
>
> library(foreign)
>
> fuente=list.files("C:/Users/Jceccarelli/Bases/Stata", pattern="dta$",
> full.names=FALSE)
>
> for (i in 1:length(fuente)){
>
> xxx=read.dta(fuente[i], to.data.frame=TRUE)
>
>
> }
>
> But i get this error
>
> Error in read.dta(fuente[i], to.data.frame = TRUE) :
> unused argument (to.data.frame = TRUE)
>
> What am i doing wrong?
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.htmland provide commented, minimal, self-contained,
> reproducible code.
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Michaelhttp://www.dewey.myzen.co.uk/home.html
>
>
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Aug 23 22:02:50 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 23 Aug 2016 13:02:50 -0700
Subject: [R] Loop over folder files
In-Reply-To: <CALBYkj+_ZoFWK4VaVDZ2f9xd22b5FzqKLqzKzoKtjHL+4t1GDA@mail.gmail.com>
References: <CALBYkj+rCTRsu2RkkUaEdncJW6BaiHM1hMjjnOEJU85xpGeq=A@mail.gmail.com>
	<20160822183231.Horde._-cnU0NlTggKzot0Wd-92_X@mail.sapo.pt>
	<CALBYkjKPrn0v=sgvDq65aqYSF_qRfbU0qUMuZ3wzivY6nhPLiw@mail.gmail.com>
	<dc661336-cf4f-b772-5822-c31e97166c62@dewey.myzen.co.uk>
	<20160823103150.Horde.lpio74f3m_msyKXA_KNwTzr@mail.sapo.pt>
	<CALBYkj+_ZoFWK4VaVDZ2f9xd22b5FzqKLqzKzoKtjHL+4t1GDA@mail.gmail.com>
Message-ID: <EE7CC8A2-38DB-4B1A-B2CB-501021F94441@comcast.net>


> On Aug 23, 2016, at 10:01 AM, Juan Ceccarelli Arias <jfca283 at gmail.com> wrote:
> 
> Im running this but the code doesn't seem work.
> It just hangs out but doesn't show any error.
> 
> 
> for (i in 1:length(fuente)){
> 
> xxx=read_dta(fuente[i])
> 
> table(xxx$cise, xxx$sexo)
> 
> rm(xxx)
> 
> }

I still find the behavior of R's `for`-loop to be rather puzzling. In this case you appear to be getting the operation done, but because you didn't assign those table values to a variable they just disappeared.

Try this:

XXX <- list()

for (i in 1:length(fuente)){
   xxx=read_dta(fuente[i])
   XXX[[i]] <- table(xxx$cise, xxx$sexo)
   rm(xxx)
}
str(XXX)

Seems to me that if you can do assignment to the parent environment (without actually using assign( ..., env=...)  that you should also be able to see the results of evaluation occurring inside the for loop, but for-loops return NULL. So you see nothing.

David.


> 
> On Tue, Aug 23, 2016 at 6:31 AM, <ruipbarradas at sapo.pt> wrote:
> 
>> Hello,
>> 
>> The op could also use package sos to find that and other packages to read
>> stata files.
>> 
>> install.packages("sos")
>> 
>> library(sos)
>> findFn("stata")
>> found 374 matches;  retrieving 19 pages
>> 2 3 4 5 6 7 8 9 10
>> 11 12 13 14 15 16 17 18 19
>> Downloaded 258 links in 121 packages
>> 
>> 
>> The first package is readstata13 but there are others.
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> 
>> 
>> Citando Michael Dewey <lists at dewey.myzen.co.uk>:
>> 
>> Dear Juan
>> 
>> If this is a Stata 13 file the package readstata13 available from CRAN may
>> be of assistance.
>> 
>> On 22/08/2016 18:40, Juan Ceccarelli Arias wrote:
>> 
>> I removed the data,frame=True...
>> I obtain this warnings...
>> Error in read.dta(fuente[i]) : not a Stata version 5-12 .dta file
>> In addition: There were 50 or more warnings (use warnings() to see the
>> first 50)
>> 
>> the warnings() throws this
>> Warning messages:
>> 1: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>> paste0(labels,  ... :
>> duplicated levels in factors are deprecated
>> 2: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>> paste0(labels,  ... :
>> duplicated levels in factors are deprecated
>> 3: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>> paste0(labels,  ... :
>> duplicated levels in factors are deprecated
>> 4: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>> paste0(labels,  ... :
>> duplicated levels in factors are deprecated
>> 5: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>> paste0(labels,  ... :
>> duplicated levels in factors are deprecated
>> 
>> 
>> 
>> On Mon, Aug 22, 2016 at 2:32 PM, <ruipbarradas at sapo.pt> wrote:
>> 
>> Hello,
>> 
>> That argument doesn't exist, hence the error.
>> Read the help page ?read.dta more carefully. You will see that already
>> read.dta reads into a data.frame.
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> 
>> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>> 
>> Hi
>> I need to apply some code over some stata files that are in folder.
>> I've wrote this
>> 
>> library(foreign)
>> 
>> fuente=list.files("C:/Users/Jceccarelli/Bases/Stata", pattern="dta$",
>> full.names=FALSE)
>> 
>> for (i in 1:length(fuente)){
>> 
>> xxx=read.dta(fuente[i], to.data.frame=TRUE)
>> 
>> 
>> }
>> 
>> But i get this error
>> 
>> Error in read.dta(fuente[i], to.data.frame = TRUE) :
>> unused argument (to.data.frame = TRUE)
>> 
>> What am i doing wrong?
>> 
>>       [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.htmland provide commented, minimal, self-contained,
>> reproducible code.
>> 
>> 
>> 
>> 
>> [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Michaelhttp://www.dewey.myzen.co.uk/home.html
>> 
>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Tue Aug 23 22:05:44 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Tue, 23 Aug 2016 21:05:44 +0100
Subject: [R] Loop over folder files
In-Reply-To: <CALBYkj+_ZoFWK4VaVDZ2f9xd22b5FzqKLqzKzoKtjHL+4t1GDA@mail.gmail.com>
References: <CALBYkj+rCTRsu2RkkUaEdncJW6BaiHM1hMjjnOEJU85xpGeq=A@mail.gmail.com>
	<20160822183231.Horde._-cnU0NlTggKzot0Wd-92_X@mail.sapo.pt>
	<CALBYkjKPrn0v=sgvDq65aqYSF_qRfbU0qUMuZ3wzivY6nhPLiw@mail.gmail.com>
	<dc661336-cf4f-b772-5822-c31e97166c62@dewey.myzen.co.uk>
	<20160823103150.Horde.lpio74f3m_msyKXA_KNwTzr@mail.sapo.pt>
	<CALBYkj+_ZoFWK4VaVDZ2f9xd22b5FzqKLqzKzoKtjHL+4t1GDA@mail.gmail.com>
Message-ID: <20160823210544.Horde.tf-kqwexP_Nu8qozX9wRrJT@mail.sapo.pt>

Hello,

Where does read_dta come from? You should also post the library() instruction.
Try to run the code without the loop, with just one file and inspect  
xxx to see what's happening.

xxx <- read_dta(fuente[1])
str(xxx)
table(xxx$cise, xxx$sexo)

Rui Barradas
?

Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:

> Im running this but the code doesn't seem work.
> It just hangs out but doesn't show any error.
> ?
> for (i in 1:length(fuente)){
> ?
> xxx=read_dta(fuente[i])
>
> table(xxx$cise, xxx$sexo)
> ?
> rm(xxx)
> ?
> }
>
> ? On Tue, Aug 23, 2016 at 6:31 AM, <ruipbarradas at sapo.pt> wrote:
>> _Hello,
>>
>> The op could also use package sos to find that and other packages  
>> to read stata files.
>>
>> install.packages("sos")
>>
>> library(sos)
>> findFn("stata")
>> found 374 matches;? retrieving 19 pages
>> 2 3 4 5 6 7 8 9 10
>> 11 12 13 14 15 16 17 18 19
>> Downloaded 258 links in 121 packages
>>
>> The first package is readstata13 but there are others.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?_
>>
>> _Citando Michael Dewey <lists at dewey.myzen.co.uk>:_
>>
>>> _Dear Juan
>>>
>>> If this is a Stata 13 file the package readstata13 available from  
>>> CRAN may be of assistance.
>>>
>>> On 22/08/2016 18:40, Juan Ceccarelli Arias wrote:_
>>>
>>>> _I removed the data,frame=True...
>>>> I obtain this warnings...
>>>> Error in read.dta(fuente[i]) : not a Stata version 5-12 .dta file
>>>> In addition: There were 50 or more warnings (use warnings() to see the
>>>> first 50)
>>>>
>>>> the warnings() throws this
>>>> Warning messages:
>>>> 1: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>>>> paste0(labels,? ... :
>>>> duplicated levels in factors are deprecated
>>>> 2: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>>>> paste0(labels,? ... :
>>>> duplicated levels in factors are deprecated
>>>> 3: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>>>> paste0(labels,? ... :
>>>> duplicated levels in factors are deprecated
>>>> 4: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>>>> paste0(labels,? ... :
>>>> duplicated levels in factors are deprecated
>>>> 5: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>>>> paste0(labels,? ... :
>>>> duplicated levels in factors are deprecated
>>>>
>>>> On Mon, Aug 22, 2016 at 2:32 PM, <ruipbarradas at sapo.pt> wrote:_
>>>>
>>>>> _Hello,
>>>>>
>>>>> That argument doesn't exist, hence the error.
>>>>> Read the help page ?read.dta more carefully. You will see that already
>>>>> read.dta reads into a data.frame.
>>>>>
>>>>> Hope this helps,
>>>>>
>>>>> Rui Barradas
>>>>>
>>>>> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>>>>>
>>>>> Hi
>>>>> I need to apply some code over some stata files that are in folder.
>>>>> I've wrote this
>>>>>
>>>>> library(foreign)
>>>>>
>>>>> fuente=list.files("C:/Users/Jceccarelli/Bases/Stata[1]", pattern="dta$",
>>>>> full.names=FALSE)
>>>>>
>>>>> for (i in 1:length(fuente)){
>>>>>
>>>>> xxx=read.dta(fuente[i], to.data.frame=TRUE)
>>>>>
>>>>> }
>>>>>
>>>>> But i get this error
>>>>>
>>>>> Error in read.dta(fuente[i], to.data.frame = TRUE) :
>>>>> unused argument (to.data.frame = TRUE)
>>>>>
>>>>> What am i doing wrong?
>>>>>
>>>>> ? ? ? ?[[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.htmland provide commented, minimal, self-contained,
>>>>> reproducible code.
>>>>>
>>>>> ?_
>>>>
>>>> _[[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide  
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code._
>>>
>>> _--
>>> Michaelhttp://www.dewey.myzen.co.uk/home.html[1]_
>>
>> _?_

?

Liga??es:
---------
[1]

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Tue Aug 23 22:07:15 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Tue, 23 Aug 2016 20:07:15 +0000
Subject: [R] Loop over folder files
In-Reply-To: <CALBYkj+_ZoFWK4VaVDZ2f9xd22b5FzqKLqzKzoKtjHL+4t1GDA@mail.gmail.com>
References: <CALBYkj+rCTRsu2RkkUaEdncJW6BaiHM1hMjjnOEJU85xpGeq=A@mail.gmail.com>
	<20160822183231.Horde._-cnU0NlTggKzot0Wd-92_X@mail.sapo.pt>
	<CALBYkjKPrn0v=sgvDq65aqYSF_qRfbU0qUMuZ3wzivY6nhPLiw@mail.gmail.com>
	<dc661336-cf4f-b772-5822-c31e97166c62@dewey.myzen.co.uk>
	<20160823103150.Horde.lpio74f3m_msyKXA_KNwTzr@mail.sapo.pt>
	<CALBYkj+_ZoFWK4VaVDZ2f9xd22b5FzqKLqzKzoKtjHL+4t1GDA@mail.gmail.com>
Message-ID: <D3E1FAC6.183E7E%macqueen1@llnl.gov>

Compare what happens with these two command:

for (i in 1:3) { table(letters[1:4])  }
for (i in 1:3) { print(table(letters[1:4]))  }

Then try modifying your loop similarly.


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/23/16, 10:01 AM, "R-help on behalf of Juan Ceccarelli Arias"
<r-help-bounces at r-project.org on behalf of jfca283 at gmail.com> wrote:

>Im running this but the code doesn't seem work.
>It just hangs out but doesn't show any error.
>
>
>for (i in 1:length(fuente)){
>
>xxx=read_dta(fuente[i])
>
>table(xxx$cise, xxx$sexo)
>
>rm(xxx)
>
>}
>
>On Tue, Aug 23, 2016 at 6:31 AM, <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> The op could also use package sos to find that and other packages to
>>read
>> stata files.
>>
>> install.packages("sos")
>>
>> library(sos)
>> findFn("stata")
>> found 374 matches;  retrieving 19 pages
>> 2 3 4 5 6 7 8 9 10
>> 11 12 13 14 15 16 17 18 19
>> Downloaded 258 links in 121 packages
>>
>>
>> The first package is readstata13 but there are others.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
>> Citando Michael Dewey <lists at dewey.myzen.co.uk>:
>>
>> Dear Juan
>>
>> If this is a Stata 13 file the package readstata13 available from CRAN
>>may
>> be of assistance.
>>
>> On 22/08/2016 18:40, Juan Ceccarelli Arias wrote:
>>
>> I removed the data,frame=True...
>> I obtain this warnings...
>> Error in read.dta(fuente[i]) : not a Stata version 5-12 .dta file
>> In addition: There were 50 or more warnings (use warnings() to see the
>> first 50)
>>
>> the warnings() throws this
>> Warning messages:
>> 1: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels)
>>else
>> paste0(labels,  ... :
>> duplicated levels in factors are deprecated
>> 2: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels)
>>else
>> paste0(labels,  ... :
>> duplicated levels in factors are deprecated
>> 3: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels)
>>else
>> paste0(labels,  ... :
>> duplicated levels in factors are deprecated
>> 4: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels)
>>else
>> paste0(labels,  ... :
>> duplicated levels in factors are deprecated
>> 5: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels)
>>else
>> paste0(labels,  ... :
>> duplicated levels in factors are deprecated
>>
>>
>>
>> On Mon, Aug 22, 2016 at 2:32 PM, <ruipbarradas at sapo.pt> wrote:
>>
>> Hello,
>>
>> That argument doesn't exist, hence the error.
>> Read the help page ?read.dta more carefully. You will see that already
>> read.dta reads into a data.frame.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>>
>> Hi
>> I need to apply some code over some stata files that are in folder.
>> I've wrote this
>>
>> library(foreign)
>>
>> fuente=list.files("C:/Users/Jceccarelli/Bases/Stata", pattern="dta$",
>> full.names=FALSE)
>>
>> for (i in 1:length(fuente)){
>>
>> xxx=read.dta(fuente[i], to.data.frame=TRUE)
>>
>>
>> }
>>
>> But i get this error
>>
>> Error in read.dta(fuente[i], to.data.frame = TRUE) :
>> unused argument (to.data.frame = TRUE)
>>
>> What am i doing wrong?
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.htmland provide commented, minimal, self-contained,
>> reproducible code.
>>
>>
>>
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Michaelhttp://www.dewey.myzen.co.uk/home.html
>>
>>
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Tue Aug 23 22:08:24 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Tue, 23 Aug 2016 21:08:24 +0100
Subject: [R] Loop over folder files
In-Reply-To: <EE7CC8A2-38DB-4B1A-B2CB-501021F94441@comcast.net>
References: <CALBYkj+rCTRsu2RkkUaEdncJW6BaiHM1hMjjnOEJU85xpGeq=A@mail.gmail.com>
	<20160822183231.Horde._-cnU0NlTggKzot0Wd-92_X@mail.sapo.pt>
	<CALBYkjKPrn0v=sgvDq65aqYSF_qRfbU0qUMuZ3wzivY6nhPLiw@mail.gmail.com>
	<dc661336-cf4f-b772-5822-c31e97166c62@dewey.myzen.co.uk>
	<20160823103150.Horde.lpio74f3m_msyKXA_KNwTzr@mail.sapo.pt>
	<CALBYkj+_ZoFWK4VaVDZ2f9xd22b5FzqKLqzKzoKtjHL+4t1GDA@mail.gmail.com>
	<EE7CC8A2-38DB-4B1A-B2CB-501021F94441@comcast.net>
Message-ID: <20160823210824.Horde.xKnfUWQV3o7PwB9wo5n8_-T@mail.sapo.pt>

Or maybe a print() statement on the table() in the loop.

print(table(...))

Rui Barradas
?

Citando David Winsemius <dwinsemius at comcast.net>:

>> On Aug 23, 2016, at 10:01 AM, Juan Ceccarelli Arias  
>> <jfca283 at gmail.com> wrote:
>>
>> Im running this but the code doesn't seem work.
>> It just hangs out but doesn't show any error.
>>
>> for (i in 1:length(fuente)){
>>
>> xxx=read_dta(fuente[i])
>>
>> table(xxx$cise, xxx$sexo)
>>
>> rm(xxx)
>>
>> }
>
> I still find the behavior of R's `for`-loop to be rather puzzling.  
> In this case you appear to be getting the operation done, but  
> because you didn't assign those table values to a variable they just  
> disappeared.
>
> Try this:
>
> XXX <- list()
>
> for (i in 1:length(fuente)){
> ? xxx=read_dta(fuente[i])
> ? XXX[[i]] <- table(xxx$cise, xxx$sexo)
> ? rm(xxx)
> }
> str(XXX)
>
> Seems to me that if you can do assignment to the parent environment  
> (without actually using assign( ..., env=...)? that you should also  
> be able to see the results of evaluation occurring inside the for  
> loop, but for-loops return NULL. So you see nothing.
>
> David.
> ?
>> On Tue, Aug 23, 2016 at 6:31 AM, <ruipbarradas at sapo.pt> wrote:
>>> Hello,
>>>
>>> The op could also use package sos to find that and other packages to read
>>> stata files.
>>>
>>> install.packages("sos")
>>>
>>> library(sos)
>>> findFn("stata")
>>> found 374 matches;? retrieving 19 pages
>>> 2 3 4 5 6 7 8 9 10
>>> 11 12 13 14 15 16 17 18 19
>>> Downloaded 258 links in 121 packages
>>>
>>> The first package is readstata13 but there are others.
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>> Citando Michael Dewey <lists at dewey.myzen.co.uk>:
>>>
>>> Dear Juan
>>>
>>> If this is a Stata 13 file the package readstata13 available from CRAN may
>>> be of assistance.
>>>
>>> On 22/08/2016 18:40, Juan Ceccarelli Arias wrote:
>>>
>>> I removed the data,frame=True...
>>> I obtain this warnings...
>>> Error in read.dta(fuente[i]) : not a Stata version 5-12 .dta file
>>> In addition: There were 50 or more warnings (use warnings() to see the
>>> first 50)
>>>
>>> the warnings() throws this
>>> Warning messages:
>>> 1: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>>> paste0(labels,? ... :
>>> duplicated levels in factors are deprecated
>>> 2: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>>> paste0(labels,? ... :
>>> duplicated levels in factors are deprecated
>>> 3: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>>> paste0(labels,? ... :
>>> duplicated levels in factors are deprecated
>>> 4: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>>> paste0(labels,? ... :
>>> duplicated levels in factors are deprecated
>>> 5: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>>> paste0(labels,? ... :
>>> duplicated levels in factors are deprecated
>>>
>>> On Mon, Aug 22, 2016 at 2:32 PM, <ruipbarradas at sapo.pt> wrote:
>>>
>>> Hello,
>>>
>>> That argument doesn't exist, hence the error.
>>> Read the help page ?read.dta more carefully. You will see that already
>>> read.dta reads into a data.frame.
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>>>
>>> Hi
>>> I need to apply some code over some stata files that are in folder.
>>> I've wrote this
>>>
>>> library(foreign)
>>>
>>> fuente=list.files("C:/Users/Jceccarelli/Bases/Stata", pattern="dta$",
>>> full.names=FALSE)
>>>
>>> for (i in 1:length(fuente)){
>>>
>>> xxx=read.dta(fuente[i], to.data.frame=TRUE)
>>>
>>> }
>>>
>>> But i get this error
>>>
>>> Error in read.dta(fuente[i], to.data.frame = TRUE) :
>>> unused argument (to.data.frame = TRUE)
>>>
>>> What am i doing wrong?
>>>
>>> ? ? ? [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.htmland provide commented, minimal, self-contained,
>>> reproducible code.
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> --
>>> Michaelhttp://www.dewey.myzen.co.uk/home.html
>>>
>>> ?
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David WinsemiusAlameda, CA, USA

?

	[[alternative HTML version deleted]]


From cadeb at usgs.gov  Tue Aug 23 23:42:28 2016
From: cadeb at usgs.gov (Cade, Brian)
Date: Tue, 23 Aug 2016 15:42:28 -0600
Subject: [R] transposing x and y axes in xYplot
Message-ID: <CAM5M9BQTOTdV2Lkv-fSD4wiAGdbs-VsRn_ADDUVo2Vbomt1UFA@mail.gmail.com>

Is there a simple way to transpose the x and y axes with the xYplot()
function in the Hmisc package, where y is a vector of point estimate and
lower and upper confidence interval endpoints?  What I'm looking for is
something akin to coord_flip() used with ggplot().

Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Aug 23 23:51:07 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 23 Aug 2016 14:51:07 -0700
Subject: [R] transposing x and y axes in xYplot
In-Reply-To: <CAM5M9BQTOTdV2Lkv-fSD4wiAGdbs-VsRn_ADDUVo2Vbomt1UFA@mail.gmail.com>
References: <CAM5M9BQTOTdV2Lkv-fSD4wiAGdbs-VsRn_ADDUVo2Vbomt1UFA@mail.gmail.com>
Message-ID: <CAGxFJbQXr3=btk7QGr7hqJhE9twR5YAvAz0kRk+Jc5ERKg0g=w@mail.gmail.com>

Is this of any help? (found by simple google search):

http://stackoverflow.com/questions/6392266/rotating-the-grid-to-plot-horizontal-errors-bars-with-hmiscxyplot-in-r


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 23, 2016 at 2:42 PM, Cade, Brian <cadeb at usgs.gov> wrote:
> Is there a simple way to transpose the x and y axes with the xYplot()
> function in the Hmisc package, where y is a vector of point estimate and
> lower and upper confidence interval endpoints?  What I'm looking for is
> something akin to coord_flip() used with ggplot().
>
> Brian
>
> Brian S. Cade, PhD
>
> U. S. Geological Survey
> Fort Collins Science Center
> 2150 Centre Ave., Bldg. C
> Fort Collins, CO  80526-8818
>
> email:  cadeb at usgs.gov <brian_cade at usgs.gov>
> tel:  970 226-9326
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gangchen6 at gmail.com  Wed Aug 24 00:03:15 2016
From: gangchen6 at gmail.com (Gang Chen)
Date: Tue, 23 Aug 2016 18:03:15 -0400
Subject: [R] aggregate
Message-ID: <CAHmzXO7tGBRevkQbcM_F31exmMtCgM-7HDW7d3VMzSFzO+HcJg@mail.gmail.com>

This is a simple question: With a dataframe like the following

myData <- data.frame(X=c(1, 2, 3, 4), Y=c(4, 3, 2, 1), Z=c('A', 'A', 'B', 'B'))

how can I get the cross product between X and Y for each level of
factor Z? My difficulty is that I don't know how to deal with the fact
that crossprod() acts on two variables in this case.


From cadeb at usgs.gov  Wed Aug 24 00:04:22 2016
From: cadeb at usgs.gov (Cade, Brian)
Date: Tue, 23 Aug 2016 16:04:22 -0600
Subject: [R] transposing x and y axes in xYplot
In-Reply-To: <CAGxFJbQXr3=btk7QGr7hqJhE9twR5YAvAz0kRk+Jc5ERKg0g=w@mail.gmail.com>
References: <CAM5M9BQTOTdV2Lkv-fSD4wiAGdbs-VsRn_ADDUVo2Vbomt1UFA@mail.gmail.com>
	<CAGxFJbQXr3=btk7QGr7hqJhE9twR5YAvAz0kRk+Jc5ERKg0g=w@mail.gmail.com>
Message-ID: <CAM5M9BQn1ET2RzE=VULcU0m1mzaUatM81AGcWf4WTvrxccLqmg@mail.gmail.com>

Bert:  Yes, with some fiddling of axes labels this looks like just what I
needed.
Thank you.

Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326


On Tue, Aug 23, 2016 at 3:51 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Is this of any help? (found by simple google search):
>
> http://stackoverflow.com/questions/6392266/rotating-
> the-grid-to-plot-horizontal-errors-bars-with-hmiscxyplot-in-r
>
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Aug 23, 2016 at 2:42 PM, Cade, Brian <cadeb at usgs.gov> wrote:
> > Is there a simple way to transpose the x and y axes with the xYplot()
> > function in the Hmisc package, where y is a vector of point estimate and
> > lower and upper confidence interval endpoints?  What I'm looking for is
> > something akin to coord_flip() used with ggplot().
> >
> > Brian
> >
> > Brian S. Cade, PhD
> >
> > U. S. Geological Survey
> > Fort Collins Science Center
> > 2150 Centre Ave., Bldg. C
> > Fort Collins, CO  80526-8818
> >
> > email:  cadeb at usgs.gov <brian_cade at usgs.gov>
> > tel:  970 226-9326
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Aug 24 00:55:14 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 23 Aug 2016 15:55:14 -0700
Subject: [R] aggregate
In-Reply-To: <CAHmzXO7tGBRevkQbcM_F31exmMtCgM-7HDW7d3VMzSFzO+HcJg@mail.gmail.com>
References: <CAHmzXO7tGBRevkQbcM_F31exmMtCgM-7HDW7d3VMzSFzO+HcJg@mail.gmail.com>
Message-ID: <017ED2EB-512A-4F45-BCEB-2E16BE0CB99D@comcast.net>


> On Aug 23, 2016, at 3:03 PM, Gang Chen <gangchen6 at gmail.com> wrote:
> 
> This is a simple question: With a dataframe like the following
> 
> myData <- data.frame(X=c(1, 2, 3, 4), Y=c(4, 3, 2, 1), Z=c('A', 'A', 'B', 'B'))
> 
> how can I get the cross product between X and Y for each level of
> factor Z? My difficulty is that I don't know how to deal with the fact
> that crossprod() acts on two variables in this case.
> 

Just make a function that takes a dataframe and does a crossprod on two of its columns.

-- 

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Wed Aug 24 01:01:35 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 24 Aug 2016 09:01:35 +1000
Subject: [R] aggregate
In-Reply-To: <CAHmzXO7tGBRevkQbcM_F31exmMtCgM-7HDW7d3VMzSFzO+HcJg@mail.gmail.com>
References: <CAHmzXO7tGBRevkQbcM_F31exmMtCgM-7HDW7d3VMzSFzO+HcJg@mail.gmail.com>
Message-ID: <CA+8X3fXi+F2yKveAEPvFT7j=ZhYepKvxJ=297YMuAy12t=nOcA@mail.gmail.com>

Hi Gang Chen,
If I have the right idea:

for(zval in levels(myData$Z))
crossprod(as.matrix(myData[myData$Z==zval,c("X","Y")]))

Jim

On Wed, Aug 24, 2016 at 8:03 AM, Gang Chen <gangchen6 at gmail.com> wrote:
> This is a simple question: With a dataframe like the following
>
> myData <- data.frame(X=c(1, 2, 3, 4), Y=c(4, 3, 2, 1), Z=c('A', 'A', 'B', 'B'))
>
> how can I get the cross product between X and Y for each level of
> factor Z? My difficulty is that I don't know how to deal with the fact
> that crossprod() acts on two variables in this case.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lmh_users-groups at molconn.com  Wed Aug 24 07:57:17 2016
From: lmh_users-groups at molconn.com (LMH)
Date: Wed, 24 Aug 2016 01:57:17 -0400
Subject: [R] question about cleaning up data labels on a plot3d plot
Message-ID: <57BD373D.6040701@molconn.com>

Hello,

I am rather unfamiliar with R but need a 3D plot for something I am working on.

I was able to generate a plot with the following,

library(rgl)
setwd("G:/shared_data/R_projects/3D_plot")
df <- read.table("R_input_3D_PCA-3_RI9_60.txt", header = TRUE)
plot3d(df$PCA_Axis1, df$PCA_Axis2, df$PCA_Axis3, col="blue", size=10)

My data is tab delimited and looks like,

num  PCA_Axis1   PCA_Axis2   PCA_Axis3
11   -0.672164   -0.83449    -1.06511
12   -1.23009    1.57928     -0.066808
42   2.80029     0.533236    -0.197187
60   2.25999     -0.233224   -0.00267827
67   1.82422     -0.840649   0.156681

There are a total of 60 rows.

Adding,

text3d(df, text=df$num)

displays my index value on the plot, but the numbers are very hard to read. It looks 
like the the labels are behind the points. Is there any way to clean this up some? I 
guess I could color the points white so I only see the numbers.

I also have 2 or three different sub groups within the data. Is there any way to have 
these different groups appear in different colors? I could create multiple 
data.frames if that would help. I am not sure you can display data from multiple 
frames on the same plot.

Suggestions would be appreciated,

LMH


From serpilsen97 at gmail.com  Wed Aug 24 09:07:38 2016
From: serpilsen97 at gmail.com (=?UTF-8?Q?Serpil_=C5=9EEN?=)
Date: Wed, 24 Aug 2016 10:07:38 +0300
Subject: [R] Hierarchical Clustering in R
Message-ID: <CAE2jy1zVfK-JnRPB3a6aKdNTmY+RqWqSoqpebfVfA19LAoEkEw@mail.gmail.com>

Dear Authorized Sir / Madam,

I need your help on clustering with R.

I have symmetric distance matrix which i created usign ClustalOmega program.

and used this R codes for clustering purpose.

*data=read.table("my_distance_matrix", header=FALSE)[-1]*
*attach(data)*
*head(data)*
*d=as.dist(data);*

*hc.complete=hclust(d,method="complete")*

*cutree(hc.complete, k=6)*
*groups<- cutree(hc.complete, k=6)*
*x<-cbind(groups)*
*x*
*x1<- subset(x,groups==1)*
*write.table(x, "results.txt", sep="\t")*
*plot(hc.complete)*


I am wondering am i doing wrong usign this code
?(*data=read.table("my_distance_matrix
or data file ???", header=FALSE)[-1]*)
Is this line requires normal data values?  In this line what kind of file
have to use? Normal data file or distance matrix?

*d=as.dist(data);      *With this line am i calculating twice distance
matrix?

Thanks in advance.
-------------- next part --------------
d1dlwa_ 0.000000 0.655172 0.836207 0.827586 0.724138 0.896552 0.836207 0.870690 0.870690 0.896552
d2gkma_ 0.655172 0.000000 0.849206 0.803150 0.723577 0.874016 0.874016 0.881890 0.874016 0.858268
d2qrwa_ 0.836207 0.849206 0.000000 0.674603 0.804878 0.888889 0.865079 0.880952 0.896825 0.880952
d2bkma_ 0.827586 0.803150 0.674603 0.000000 0.804878 0.882812 0.890625 0.875000 0.882812 0.843750
d4i0va_ 0.724138 0.723577 0.804878 0.804878 0.000000 0.861789 0.829268 0.861789 0.886179 0.869919
d1asha_ 0.896552 0.874016 0.888889 0.882812 0.861789 0.000000 0.884354 0.890511 0.897059 0.871429
d2dc3a_ 0.836207 0.874016 0.865079 0.890625 0.829268 0.884354 0.000000 0.875912 0.845588 0.864286
d4hsxa_ 0.870690 0.881890 0.880952 0.875000 0.861789 0.890511 0.875912 0.000000 0.867647 0.883212
1ecaa_ 0.870690 0.874016 0.896825 0.882812 0.886179 0.897059 0.845588 0.867647 0.000000 0.882353
d1x9fd_ 0.896552 0.858268 0.880952 0.843750 0.869919 0.871429 0.864286 0.883212 0.882353 0.000000

From pdalgd at gmail.com  Wed Aug 24 12:00:31 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 24 Aug 2016 12:00:31 +0200
Subject: [R] Estimated Effects Not Balanced
In-Reply-To: <CAEtAGeq-r1OW6yw4fxmu1wG8bbCGSB8h5qjmegrxNPTa3V6=aA@mail.gmail.com>
References: <CAEtAGeq-r1OW6yw4fxmu1wG8bbCGSB8h5qjmegrxNPTa3V6=aA@mail.gmail.com>
Message-ID: <159D21F3-4F83-4A3D-9334-B7410701A6BF@gmail.com>


On 22 Aug 2016, at 17:15 , Justin Thong <justinthong93 at gmail.com> wrote:

> Something does not make sense in R. It has to do with the question of
> balance and unbalance.
> 
> *A<-factor(c(1,1,1,1,1,1,2,2,2,2,2,2))*
> *B<-factor(c(1,1,2,2,3,3,1,1,2,2,3,3))*
> *y<-rnorm(12)*
> *mod<-aov(y~A+B)*


As an aside, notice that this is one case where posting in HTML goes against your own interests (let alone the posting guide). The above cannot be cut+pasted, so fewer people will be willing to try it.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maillists at pp.inet.fi  Wed Aug 24 15:49:19 2016
From: maillists at pp.inet.fi (K. Elo)
Date: Wed, 24 Aug 2016 16:49:19 +0300
Subject: [R] Hierarchical Clustering in R
In-Reply-To: <CAE2jy1zVfK-JnRPB3a6aKdNTmY+RqWqSoqpebfVfA19LAoEkEw@mail.gmail.com>
References: <CAE2jy1zVfK-JnRPB3a6aKdNTmY+RqWqSoqpebfVfA19LAoEkEw@mail.gmail.com>
Message-ID: <8b5fbb19-e57e-1ffa-7cbf-e4e9ded2704a@pp.inet.fi>

Hi,

what is the exact problem? I tried you code and it works fine...

Best,
Kimmo

24.08.2016, 10:07, Serpil ?EN wrote:
> Dear Authorized Sir / Madam,
>
> I need your help on clustering with R.
>
> I have symmetric distance matrix which i created usign ClustalOmega program.
>
> and used this R codes for clustering purpose.
>
> *data=read.table("my_distance_matrix", header=FALSE)[-1]*
> *attach(data)*
> *head(data)*
> *d=as.dist(data);*
>
> *hc.complete=hclust(d,method="complete")*
>
> *cutree(hc.complete, k=6)*
> *groups<- cutree(hc.complete, k=6)*
> *x<-cbind(groups)*
> *x*
> *x1<- subset(x,groups==1)*
> *write.table(x, "results.txt", sep="\t")*
> *plot(hc.complete)*
>
>
> I am wondering am i doing wrong usign this code
> ?(*data=read.table("my_distance_matrix
> or data file ???", header=FALSE)[-1]*)
> Is this line requires normal data values?  In this line what kind of file
> have to use? Normal data file or distance matrix?
>
> *d=as.dist(data);      *With this line am i calculating twice distance
> matrix?
>
> Thanks in advance.
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dcarlson at tamu.edu  Wed Aug 24 16:37:34 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 24 Aug 2016 14:37:34 +0000
Subject: [R] aggregate
In-Reply-To: <CA+8X3fXi+F2yKveAEPvFT7j=ZhYepKvxJ=297YMuAy12t=nOcA@mail.gmail.com>
References: <CAHmzXO7tGBRevkQbcM_F31exmMtCgM-7HDW7d3VMzSFzO+HcJg@mail.gmail.com>
	<CA+8X3fXi+F2yKveAEPvFT7j=ZhYepKvxJ=297YMuAy12t=nOcA@mail.gmail.com>
Message-ID: <9b3ddc5330e24fb4a6ff84188dcdfb57@exch-2p-mbx-t2.ads.tamu.edu>

Thank you for the reproducible example, but it is not clear what cross product you want. Jim's solution gives you the cross product of the 2-column matrix with itself. If you want the cross product between the columns you need something else. The aggregate function will not work since it will treat the columns separately:

> A <- as.matrix(myData[myData$Z=="A", 1:2])
> A
  X Y
1 1 4
2 2 3
> crossprod(A) # Same as t(A) %*% A 
   X  Y
X  5 10
Y 10 25
> crossprod(A[, 1], A[, 2]) # Same as t(A[, 1] %*% A[, 2]
     [,1]
[1,]   10
> 
> # For all the groups
> lapply(split(myData, myData$Z), function(x) crossprod(as.matrix(x[, 1:2])))
$A
   X  Y
X  5 10
Y 10 25

$B
   X  Y
X 25 10
Y 10  5

> lapply(split(myData, myData$Z), function(x) crossprod(x[, 1], x[, 2]))
$A
     [,1]
[1,]   10

$B
     [,1]
[1,]   10

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Tuesday, August 23, 2016 6:02 PM
To: Gang Chen; r-help mailing list
Subject: Re: [R] aggregate

Hi Gang Chen,
If I have the right idea:

for(zval in levels(myData$Z))
crossprod(as.matrix(myData[myData$Z==zval,c("X","Y")]))

Jim

On Wed, Aug 24, 2016 at 8:03 AM, Gang Chen <gangchen6 at gmail.com> wrote:
> This is a simple question: With a dataframe like the following
>
> myData <- data.frame(X=c(1, 2, 3, 4), Y=c(4, 3, 2, 1), Z=c('A', 'A', 'B', 'B'))
>
> how can I get the cross product between X and Y for each level of
> factor Z? My difficulty is that I don't know how to deal with the fact
> that crossprod() acts on two variables in this case.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pnsinha68 at gmail.com  Wed Aug 24 16:47:25 2016
From: pnsinha68 at gmail.com (Partha Sinha)
Date: Wed, 24 Aug 2016 20:17:25 +0530
Subject: [R] library Dplyr
Message-ID: <CADcgpJe11k30Pm_fATaQa4aej0-=sGqCGugcuT4mq5-Ch0hWzQ@mail.gmail.com>

I am using windows 7 , R version 3.3.1
whenever I am trying use
library(dplyr)
i am getting the follwing error:

Error in get(Info[i, 1], envir = env) :
  cannot allocate memory block of size 2.5 Gb
Error: package or namespace load failed for ?dplyr?


pl help

Regards
Partha

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Aug 24 16:48:17 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Wed, 24 Aug 2016 15:48:17 +0100
Subject: [R] Loop over folder files
In-Reply-To: <CALBYkjJ1VQ6eJw-9EyKPpGZ=EhJk7uwxGwoi-9gW7VwHfjWRFg@mail.gmail.com>
References: <CALBYkj+rCTRsu2RkkUaEdncJW6BaiHM1hMjjnOEJU85xpGeq=A@mail.gmail.com>
	<20160822183231.Horde._-cnU0NlTggKzot0Wd-92_X@mail.sapo.pt>
	<CALBYkjKPrn0v=sgvDq65aqYSF_qRfbU0qUMuZ3wzivY6nhPLiw@mail.gmail.com>
	<dc661336-cf4f-b772-5822-c31e97166c62@dewey.myzen.co.uk>
	<20160823103150.Horde.lpio74f3m_msyKXA_KNwTzr@mail.sapo.pt>
	<CALBYkj+_ZoFWK4VaVDZ2f9xd22b5FzqKLqzKzoKtjHL+4t1GDA@mail.gmail.com>
	<EE7CC8A2-38DB-4B1A-B2CB-501021F94441@comcast.net>
	<20160823210824.Horde.xKnfUWQV3o7PwB9wo5n8_-T@mail.sapo.pt>
	<CALBYkjJ1VQ6eJw-9EyKPpGZ=EhJk7uwxGwoi-9gW7VwHfjWRFg@mail.gmail.com>
Message-ID: <20160824154817.Horde.R8xuz7etVwbS5GopaAdKUl3@mail.sapo.pt>

Hello,

That means that probably the files are in a different folder/directory.
Use getwd() to see what is your current directory and
setwd("path/to/files") to set the right place where the files can be found.

Rui Barradas
?

Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:

> I just doesn't work...
> Im loading the read,dta13 package already.
> When i try to perform a simple table(sex), i received the "File not  
> found" message.
> However, if i load the data using the file.choose() option inside  
> read.dta13, i can open the stata file.
> I don't know what am i doing wrong...
> ? On Tue, Aug 23, 2016 at 5:08 PM, <ruipbarradas at sapo.pt> wrote:
>> _Or maybe a print() statement on the table() in the loop.
>>
>> print(table(...))
>>
>> Rui Barradas
>> ?_
>>
>> _Citando David Winsemius <dwinsemius at comcast.net>:_
>>
>>>> _On Aug 23, 2016, at 10:01 AM, Juan Ceccarelli Arias  
>>>> <jfca283 at gmail.com> wrote:
>>>>
>>>> Im running this but the code doesn't seem work.
>>>> It just hangs out but doesn't show any error.
>>>>
>>>> for (i in 1:length(fuente)){
>>>>
>>>> xxx=read_dta(fuente[i])
>>>>
>>>> table(xxx$cise, xxx$sexo)
>>>>
>>>> rm(xxx)
>>>>
>>>> }_
>>>
>>> _I still find the behavior of R's `for`-loop to be rather  
>>> puzzling. In this case you appear to be getting the operation  
>>> done, but because you didn't assign those table values to a  
>>> variable they just disappeared.
>>>
>>> Try this:
>>>
>>> XXX <- list()
>>>
>>> for (i in 1:length(fuente)){
>>> ? xxx=read_dta(fuente[i])
>>> ? XXX[[i]] <- table(xxx$cise, xxx$sexo)
>>> ? rm(xxx)
>>> }
>>> str(XXX)
>>>
>>> Seems to me that if you can do assignment to the parent  
>>> environment (without actually using assign( ..., env=...)? that  
>>> you should also be able to see the results of evaluation occurring  
>>> inside the for loop, but for-loops return NULL. So you see nothing.
>>>
>>> David.
>>> ? _
>>>> _On Tue, Aug 23, 2016 at 6:31 AM, <ruipbarradas at sapo.pt> wrote:_
>>>>
>>>>> _Hello,
>>>>>
>>>>> The op could also use package sos to find that and other packages to read
>>>>> stata files.
>>>>>
>>>>> install.packages("sos")
>>>>>
>>>>> library(sos)
>>>>> findFn("stata")
>>>>> found 374 matches;? retrieving 19 pages
>>>>> 2 3 4 5 6 7 8 9 10
>>>>> 11 12 13 14 15 16 17 18 19
>>>>> Downloaded 258 links in 121 packages
>>>>>
>>>>> The first package is readstata13 but there are others.
>>>>>
>>>>> Hope this helps,
>>>>>
>>>>> Rui Barradas
>>>>>
>>>>> Citando Michael Dewey <lists at dewey.myzen.co.uk>:
>>>>>
>>>>> Dear Juan
>>>>>
>>>>> If this is a Stata 13 file the package readstata13 available  
>>>>> from CRAN may
>>>>> be of assistance.
>>>>>
>>>>> On 22/08/2016 18:40, Juan Ceccarelli Arias wrote:
>>>>>
>>>>> I removed the data,frame=True...
>>>>> I obtain this warnings...
>>>>> Error in read.dta(fuente[i]) : not a Stata version 5-12 .dta file
>>>>> In addition: There were 50 or more warnings (use warnings() to see the
>>>>> first 50)
>>>>>
>>>>> the warnings() throws this
>>>>> Warning messages:
>>>>> 1: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>>>>> paste0(labels,? ... :
>>>>> duplicated levels in factors are deprecated
>>>>> 2: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>>>>> paste0(labels,? ... :
>>>>> duplicated levels in factors are deprecated
>>>>> 3: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>>>>> paste0(labels,? ... :
>>>>> duplicated levels in factors are deprecated
>>>>> 4: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>>>>> paste0(labels,? ... :
>>>>> duplicated levels in factors are deprecated
>>>>> 5: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
>>>>> paste0(labels,? ... :
>>>>> duplicated levels in factors are deprecated
>>>>>
>>>>> On Mon, Aug 22, 2016 at 2:32 PM, <ruipbarradas at sapo.pt> wrote:
>>>>>
>>>>> Hello,
>>>>>
>>>>> That argument doesn't exist, hence the error.
>>>>> Read the help page ?read.dta more carefully. You will see that already
>>>>> read.dta reads into a data.frame.
>>>>>
>>>>> Hope this helps,
>>>>>
>>>>> Rui Barradas
>>>>>
>>>>> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>>>>>
>>>>> Hi
>>>>> I need to apply some code over some stata files that are in folder.
>>>>> I've wrote this
>>>>>
>>>>> library(foreign)
>>>>>
>>>>> fuente=list.files("C:/Users/Jceccarelli/Bases/Stata[1]", pattern="dta$",
>>>>> full.names=FALSE)
>>>>>
>>>>> for (i in 1:length(fuente)){
>>>>>
>>>>> xxx=read.dta(fuente[i], to.data.frame=TRUE)
>>>>>
>>>>> }
>>>>>
>>>>> But i get this error
>>>>>
>>>>> Error in read.dta(fuente[i], to.data.frame = TRUE) :
>>>>> unused argument (to.data.frame = TRUE)
>>>>>
>>>>> What am i doing wrong?
>>>>>
>>>>> ? ? ? [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.htmland provide commented, minimal, self-contained,
>>>>> reproducible code.
>>>>>
>>>>> [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>> --
>>>>> Michaelhttp://www.dewey.myzen.co.uk/home.html[1]
>>>>>
>>>>> ?_
>>>>
>>>> _[[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide  
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code._
>>>
>>> _ David WinsemiusAlameda, CA, USA_
>>
>> _?_

?

Liga??es:
---------
[1]

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Aug 24 16:55:14 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 24 Aug 2016 10:55:14 -0400
Subject: [R] question about cleaning up data labels on a plot3d plot
In-Reply-To: <57BD373D.6040701@molconn.com>
References: <57BD373D.6040701@molconn.com>
Message-ID: <CAM_vjum85fOE+TZ5ddCKxHRi35x_Km8C-oPA7e2OF4nLGBNNZg@mail.gmail.com>

Sure, you can do any of that in R.

You might benefit from reading some introductory material so you
understand at least graphical parameters and subsetting, but here's
some sample code with fake data that does what you're asking.

library(rgl)
x <- sort(rnorm(10))
y <- rnorm(10)
z <- rnorm(10) + atan2(x, y)

# version one: text only

plot3d(x, y, z, type="n")
text3d(x, y, z, text=letters[1:10], cex=2)


# version two: colored symbols
data.groups <- sample(1:3, size=10, replace=TRUE)
data.colors <- c("red", "purple", "blue")

plot3d(x, y, z, size=8, col=data.colors[data.groups])


Sarah

On Wed, Aug 24, 2016 at 1:57 AM, LMH <lmh_users-groups at molconn.com> wrote:
> Hello,
>
> I am rather unfamiliar with R but need a 3D plot for something I am working
> on.
>
> I was able to generate a plot with the following,
>
> library(rgl)
> setwd("G:/shared_data/R_projects/3D_plot")
> df <- read.table("R_input_3D_PCA-3_RI9_60.txt", header = TRUE)
> plot3d(df$PCA_Axis1, df$PCA_Axis2, df$PCA_Axis3, col="blue", size=10)
>
> My data is tab delimited and looks like,
>
> num  PCA_Axis1   PCA_Axis2   PCA_Axis3
> 11   -0.672164   -0.83449    -1.06511
> 12   -1.23009    1.57928     -0.066808
> 42   2.80029     0.533236    -0.197187
> 60   2.25999     -0.233224   -0.00267827
> 67   1.82422     -0.840649   0.156681
>
> There are a total of 60 rows.
>
> Adding,
>
> text3d(df, text=df$num)
>
> displays my index value on the plot, but the numbers are very hard to read.
> It looks like the the labels are behind the points. Is there any way to
> clean this up some? I guess I could color the points white so I only see the
> numbers.
>
> I also have 2 or three different sub groups within the data. Is there any
> way to have these different groups appear in different colors? I could
> create multiple data.frames if that would help. I am not sure you can
> display data from multiple frames on the same plot.
>
> Suggestions would be appreciated,
>
> LMH
>


From jdnewmil at dcn.davis.ca.us  Wed Aug 24 17:10:50 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 24 Aug 2016 08:10:50 -0700
Subject: [R] library Dplyr
In-Reply-To: <CADcgpJe11k30Pm_fATaQa4aej0-=sGqCGugcuT4mq5-Ch0hWzQ@mail.gmail.com>
References: <CADcgpJe11k30Pm_fATaQa4aej0-=sGqCGugcuT4mq5-Ch0hWzQ@mail.gmail.com>
Message-ID: <4A3A4F44-FAD4-4B74-ADF5-D8E3BF595A02@dcn.davis.ca.us>

This is not normal. I suggest making use of the maintainer() and sessionInfo() functions. 
-- 
Sent from my phone. Please excuse my brevity.

On August 24, 2016 7:47:25 AM PDT, Partha Sinha <pnsinha68 at gmail.com> wrote:
>I am using windows 7 , R version 3.3.1
>whenever I am trying use
>library(dplyr)
>i am getting the follwing error:
>
>Error in get(Info[i, 1], envir = env) :
>  cannot allocate memory block of size 2.5 Gb
>Error: package or namespace load failed for ?dplyr?
>
>
>pl help
>
>Regards
>Partha
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jfca283 at gmail.com  Wed Aug 24 14:41:39 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Wed, 24 Aug 2016 09:41:39 -0300
Subject: [R] Loop over folder files
In-Reply-To: <20160823210824.Horde.xKnfUWQV3o7PwB9wo5n8_-T@mail.sapo.pt>
References: <CALBYkj+rCTRsu2RkkUaEdncJW6BaiHM1hMjjnOEJU85xpGeq=A@mail.gmail.com>
	<20160822183231.Horde._-cnU0NlTggKzot0Wd-92_X@mail.sapo.pt>
	<CALBYkjKPrn0v=sgvDq65aqYSF_qRfbU0qUMuZ3wzivY6nhPLiw@mail.gmail.com>
	<dc661336-cf4f-b772-5822-c31e97166c62@dewey.myzen.co.uk>
	<20160823103150.Horde.lpio74f3m_msyKXA_KNwTzr@mail.sapo.pt>
	<CALBYkj+_ZoFWK4VaVDZ2f9xd22b5FzqKLqzKzoKtjHL+4t1GDA@mail.gmail.com>
	<EE7CC8A2-38DB-4B1A-B2CB-501021F94441@comcast.net>
	<20160823210824.Horde.xKnfUWQV3o7PwB9wo5n8_-T@mail.sapo.pt>
Message-ID: <CALBYkjJ1VQ6eJw-9EyKPpGZ=EhJk7uwxGwoi-9gW7VwHfjWRFg@mail.gmail.com>

I just doesn't work...
Im loading the read,dta13 package already.
When i try to perform a simple table(sex), i received the "File not found"
message.
However, if i load the data using the file.choose() option inside
read.dta13, i can open the stata file.
I don't know what am i doing wrong...

On Tue, Aug 23, 2016 at 5:08 PM, <ruipbarradas at sapo.pt> wrote:

> Or maybe a print() statement on the table() in the loop.
>
> print(table(...))
>
> Rui Barradas
>
>
> Citando David Winsemius <dwinsemius at comcast.net>:
>
> On Aug 23, 2016, at 10:01 AM, Juan Ceccarelli Arias <jfca283 at gmail.com>
> wrote:
>
> Im running this but the code doesn't seem work.
> It just hangs out but doesn't show any error.
>
>
> for (i in 1:length(fuente)){
>
> xxx=read_dta(fuente[i])
>
> table(xxx$cise, xxx$sexo)
>
> rm(xxx)
>
> }
>
> I still find the behavior of R's `for`-loop to be rather puzzling. In this
> case you appear to be getting the operation done, but because you didn't
> assign those table values to a variable they just disappeared.
>
> Try this:
>
> XXX <- list()
>
> for (i in 1:length(fuente)){
>   xxx=read_dta(fuente[i])
>   XXX[[i]] <- table(xxx$cise, xxx$sexo)
>   rm(xxx)
> }
> str(XXX)
>
> Seems to me that if you can do assignment to the parent environment
> (without actually using assign( ..., env=...)  that you should also be able
> to see the results of evaluation occurring inside the for loop, but
> for-loops return NULL. So you see nothing.
>
> David.
>
>
> On Tue, Aug 23, 2016 at 6:31 AM, <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> The op could also use package sos to find that and other packages to read
> stata files.
>
> install.packages("sos")
>
> library(sos)
> findFn("stata")
> found 374 matches;  retrieving 19 pages
> 2 3 4 5 6 7 8 9 10
> 11 12 13 14 15 16 17 18 19
> Downloaded 258 links in 121 packages
>
>
> The first package is readstata13 but there are others.
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> Citando Michael Dewey <lists at dewey.myzen.co.uk>:
>
> Dear Juan
>
> If this is a Stata 13 file the package readstata13 available from CRAN may
> be of assistance.
>
> On 22/08/2016 18:40, Juan Ceccarelli Arias wrote:
>
> I removed the data,frame=True...
> I obtain this warnings...
> Error in read.dta(fuente[i]) : not a Stata version 5-12 .dta file
> In addition: There were 50 or more warnings (use warnings() to see the
> first 50)
>
> the warnings() throws this
> Warning messages:
> 1: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
> duplicated levels in factors are deprecated
> 2: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
> duplicated levels in factors are deprecated
> 3: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
> duplicated levels in factors are deprecated
> 4: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
> duplicated levels in factors are deprecated
> 5: In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
> paste0(labels,  ... :
> duplicated levels in factors are deprecated
>
>
>
> On Mon, Aug 22, 2016 at 2:32 PM, <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> That argument doesn't exist, hence the error.
> Read the help page ?read.dta more carefully. You will see that already
> read.dta reads into a data.frame.
>
> Hope this helps,
>
> Rui Barradas
>
>
> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>
> Hi
> I need to apply some code over some stata files that are in folder.
> I've wrote this
>
> library(foreign)
>
> fuente=list.files("C:/Users/Jceccarelli/Bases/Stata", pattern="dta$",
> full.names=FALSE)
>
> for (i in 1:length(fuente)){
>
> xxx=read.dta(fuente[i], to.data.frame=TRUE)
>
>
> }
>
> But i get this error
>
> Error in read.dta(fuente[i], to.data.frame = TRUE) :
> unused argument (to.data.frame = TRUE)
>
> What am i doing wrong?
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.htmland provide commented, minimal, self-contained,
> reproducible code.
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Michaelhttp://www.dewey.myzen.co.uk/home.html
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> David WinsemiusAlameda, CA, USA
>
>
>
>

	[[alternative HTML version deleted]]


From gangchen6 at gmail.com  Wed Aug 24 17:16:57 2016
From: gangchen6 at gmail.com (Gang Chen)
Date: Wed, 24 Aug 2016 11:16:57 -0400
Subject: [R] aggregate
In-Reply-To: <9b3ddc5330e24fb4a6ff84188dcdfb57@exch-2p-mbx-t2.ads.tamu.edu>
References: <CAHmzXO7tGBRevkQbcM_F31exmMtCgM-7HDW7d3VMzSFzO+HcJg@mail.gmail.com>
	<CA+8X3fXi+F2yKveAEPvFT7j=ZhYepKvxJ=297YMuAy12t=nOcA@mail.gmail.com>
	<9b3ddc5330e24fb4a6ff84188dcdfb57@exch-2p-mbx-t2.ads.tamu.edu>
Message-ID: <CAHmzXO7q-4nmqgqTg2t+fiwCvnb_YgcWnBjEPNVZ0YZ-EEGqQw@mail.gmail.com>

Thank you all for the suggestions! Yes, I'm looking for the cross
product between the two columns of X and Y.

A follow-up question: what is a nice way to merge the output of

lapply(split(myData, myData$Z), function(x) crossprod(x[, 1], x[, 2]))

with the column Z in myData so that I would get a new dataframe as the
following (the 2nd column is the cross product between X and Y)?

Z   CP
A   10
B   10

Is the following legitimate?

data.frame(Z=levels(myData$Z), CP= unlist(lapply(split(myData,
myData$Z), function(x) crossprod(x[, 1], x[, 2]))))


On Wed, Aug 24, 2016 at 10:37 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> Thank you for the reproducible example, but it is not clear what cross product you want. Jim's solution gives you the cross product of the 2-column matrix with itself. If you want the cross product between the columns you need something else. The aggregate function will not work since it will treat the columns separately:
>
>> A <- as.matrix(myData[myData$Z=="A", 1:2])
>> A
>   X Y
> 1 1 4
> 2 2 3
>> crossprod(A) # Same as t(A) %*% A
>    X  Y
> X  5 10
> Y 10 25
>> crossprod(A[, 1], A[, 2]) # Same as t(A[, 1] %*% A[, 2]
>      [,1]
> [1,]   10
>>
>> # For all the groups
>> lapply(split(myData, myData$Z), function(x) crossprod(as.matrix(x[, 1:2])))
> $A
>    X  Y
> X  5 10
> Y 10 25
>
> $B
>    X  Y
> X 25 10
> Y 10  5
>
>> lapply(split(myData, myData$Z), function(x) crossprod(x[, 1], x[, 2]))
> $A
>      [,1]
> [1,]   10
>
> $B
>      [,1]
> [1,]   10
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
> Sent: Tuesday, August 23, 2016 6:02 PM
> To: Gang Chen; r-help mailing list
> Subject: Re: [R] aggregate
>
> Hi Gang Chen,
> If I have the right idea:
>
> for(zval in levels(myData$Z))
> crossprod(as.matrix(myData[myData$Z==zval,c("X","Y")]))
>
> Jim
>
> On Wed, Aug 24, 2016 at 8:03 AM, Gang Chen <gangchen6 at gmail.com> wrote:
>> This is a simple question: With a dataframe like the following
>>
>> myData <- data.frame(X=c(1, 2, 3, 4), Y=c(4, 3, 2, 1), Z=c('A', 'A', 'B', 'B'))
>>
>> how can I get the cross product between X and Y for each level of
>> factor Z? My difficulty is that I don't know how to deal with the fact
>> that crossprod() acts on two variables in this case.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Wed Aug 24 17:54:37 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 24 Aug 2016 15:54:37 +0000
Subject: [R] aggregate
In-Reply-To: <CAHmzXO7q-4nmqgqTg2t+fiwCvnb_YgcWnBjEPNVZ0YZ-EEGqQw@mail.gmail.com>
References: <CAHmzXO7tGBRevkQbcM_F31exmMtCgM-7HDW7d3VMzSFzO+HcJg@mail.gmail.com>
	<CA+8X3fXi+F2yKveAEPvFT7j=ZhYepKvxJ=297YMuAy12t=nOcA@mail.gmail.com>
	<9b3ddc5330e24fb4a6ff84188dcdfb57@exch-2p-mbx-t2.ads.tamu.edu>
	<CAHmzXO7q-4nmqgqTg2t+fiwCvnb_YgcWnBjEPNVZ0YZ-EEGqQw@mail.gmail.com>
Message-ID: <69d5ea229ef440bda48442ca94bb5f2a@exch-2p-mbx-t2.ads.tamu.edu>

Your is fine, but it will be a little simpler if you use sapply() instead:

> data.frame(Z=levels(myData$Z), CP=sapply(split(myData, myData$Z), 
+     function(x) crossprod(x[, 1], x[, 2])))
  Z CP
A A 10
B B 10

David C


-----Original Message-----
From: Gang Chen [mailto:gangchen6 at gmail.com] 
Sent: Wednesday, August 24, 2016 10:17 AM
To: David L Carlson
Cc: Jim Lemon; r-help mailing list
Subject: Re: [R] aggregate

Thank you all for the suggestions! Yes, I'm looking for the cross
product between the two columns of X and Y.

A follow-up question: what is a nice way to merge the output of

lapply(split(myData, myData$Z), function(x) crossprod(x[, 1], x[, 2]))

with the column Z in myData so that I would get a new dataframe as the
following (the 2nd column is the cross product between X and Y)?

Z   CP
A   10
B   10

Is the following legitimate?

data.frame(Z=levels(myData$Z), CP= unlist(lapply(split(myData,
myData$Z), function(x) crossprod(x[, 1], x[, 2]))))


On Wed, Aug 24, 2016 at 10:37 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> Thank you for the reproducible example, but it is not clear what cross product you want. Jim's solution gives you the cross product of the 2-column matrix with itself. If you want the cross product between the columns you need something else. The aggregate function will not work since it will treat the columns separately:
>
>> A <- as.matrix(myData[myData$Z=="A", 1:2])
>> A
>   X Y
> 1 1 4
> 2 2 3
>> crossprod(A) # Same as t(A) %*% A
>    X  Y
> X  5 10
> Y 10 25
>> crossprod(A[, 1], A[, 2]) # Same as t(A[, 1] %*% A[, 2]
>      [,1]
> [1,]   10
>>
>> # For all the groups
>> lapply(split(myData, myData$Z), function(x) crossprod(as.matrix(x[, 1:2])))
> $A
>    X  Y
> X  5 10
> Y 10 25
>
> $B
>    X  Y
> X 25 10
> Y 10  5
>
>> lapply(split(myData, myData$Z), function(x) crossprod(x[, 1], x[, 2]))
> $A
>      [,1]
> [1,]   10
>
> $B
>      [,1]
> [1,]   10
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
> Sent: Tuesday, August 23, 2016 6:02 PM
> To: Gang Chen; r-help mailing list
> Subject: Re: [R] aggregate
>
> Hi Gang Chen,
> If I have the right idea:
>
> for(zval in levels(myData$Z))
> crossprod(as.matrix(myData[myData$Z==zval,c("X","Y")]))
>
> Jim
>
> On Wed, Aug 24, 2016 at 8:03 AM, Gang Chen <gangchen6 at gmail.com> wrote:
>> This is a simple question: With a dataframe like the following
>>
>> myData <- data.frame(X=c(1, 2, 3, 4), Y=c(4, 3, 2, 1), Z=c('A', 'A', 'B', 'B'))
>>
>> how can I get the cross product between X and Y for each level of
>> factor Z? My difficulty is that I don't know how to deal with the fact
>> that crossprod() acts on two variables in this case.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From gangchen6 at gmail.com  Wed Aug 24 18:55:47 2016
From: gangchen6 at gmail.com (Gang Chen)
Date: Wed, 24 Aug 2016 12:55:47 -0400
Subject: [R] aggregate
In-Reply-To: <69d5ea229ef440bda48442ca94bb5f2a@exch-2p-mbx-t2.ads.tamu.edu>
References: <CAHmzXO7tGBRevkQbcM_F31exmMtCgM-7HDW7d3VMzSFzO+HcJg@mail.gmail.com>
	<CA+8X3fXi+F2yKveAEPvFT7j=ZhYepKvxJ=297YMuAy12t=nOcA@mail.gmail.com>
	<9b3ddc5330e24fb4a6ff84188dcdfb57@exch-2p-mbx-t2.ads.tamu.edu>
	<CAHmzXO7q-4nmqgqTg2t+fiwCvnb_YgcWnBjEPNVZ0YZ-EEGqQw@mail.gmail.com>
	<69d5ea229ef440bda48442ca94bb5f2a@exch-2p-mbx-t2.ads.tamu.edu>
Message-ID: <CAHmzXO4B686ri9867tXnto=JYeE0PPkUbKBXC8o+6r51piqb6w@mail.gmail.com>

Thanks a lot, David! I want to further expand the operation a little
bit. With a new dataframe:

myData <- data.frame(X=c(1, 2, 3, 4, 5, 6, 7, 8), Y=c(8, 7, 6, 5, 4,
3, 2, 1), S=c(?S1?, ?S1?, ?S1?, ?S1?, ?S2?, ?S2?, ?S2?, ?S2?),
Z=c(?A?, ?A?, ?B?, ?B?, ?A?, ?A?, ?B?, ?B?))

> myData

  X Y  S Z
1 1 8 S1 A
2 2 7 S1 A
3 3 6 S1 B
4 4 5 S1 B
5 5 4 S2 A
6 6 3 S2 A
7 7 2 S2 B
8 8 1 S2 B

I would like to obtain the same cross product between columns X and Y,
but at each combination level of factors S and Z. In other words, the
cross product would be still performed each two rows in the new
dataframe myData. How can I achieve that?

On Wed, Aug 24, 2016 at 11:54 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> Your is fine, but it will be a little simpler if you use sapply() instead:
>
>> data.frame(Z=levels(myData$Z), CP=sapply(split(myData, myData$Z),
> +     function(x) crossprod(x[, 1], x[, 2])))
>   Z CP
> A A 10
> B B 10
>
> David C
>
>
> -----Original Message-----
> From: Gang Chen [mailto:gangchen6 at gmail.com]
> Sent: Wednesday, August 24, 2016 10:17 AM
> To: David L Carlson
> Cc: Jim Lemon; r-help mailing list
> Subject: Re: [R] aggregate
>
> Thank you all for the suggestions! Yes, I'm looking for the cross
> product between the two columns of X and Y.
>
> A follow-up question: what is a nice way to merge the output of
>
> lapply(split(myData, myData$Z), function(x) crossprod(x[, 1], x[, 2]))
>
> with the column Z in myData so that I would get a new dataframe as the
> following (the 2nd column is the cross product between X and Y)?
>
> Z   CP
> A   10
> B   10
>
> Is the following legitimate?
>
> data.frame(Z=levels(myData$Z), CP= unlist(lapply(split(myData,
> myData$Z), function(x) crossprod(x[, 1], x[, 2]))))
>
>
> On Wed, Aug 24, 2016 at 10:37 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>> Thank you for the reproducible example, but it is not clear what cross product you want. Jim's solution gives you the cross product of the 2-column matrix with itself. If you want the cross product between the columns you need something else. The aggregate function will not work since it will treat the columns separately:
>>
>>> A <- as.matrix(myData[myData$Z=="A", 1:2])
>>> A
>>   X Y
>> 1 1 4
>> 2 2 3
>>> crossprod(A) # Same as t(A) %*% A
>>    X  Y
>> X  5 10
>> Y 10 25
>>> crossprod(A[, 1], A[, 2]) # Same as t(A[, 1] %*% A[, 2]
>>      [,1]
>> [1,]   10
>>>
>>> # For all the groups
>>> lapply(split(myData, myData$Z), function(x) crossprod(as.matrix(x[, 1:2])))
>> $A
>>    X  Y
>> X  5 10
>> Y 10 25
>>
>> $B
>>    X  Y
>> X 25 10
>> Y 10  5
>>
>>> lapply(split(myData, myData$Z), function(x) crossprod(x[, 1], x[, 2]))
>> $A
>>      [,1]
>> [1,]   10
>>
>> $B
>>      [,1]
>> [1,]   10
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
>> Sent: Tuesday, August 23, 2016 6:02 PM
>> To: Gang Chen; r-help mailing list
>> Subject: Re: [R] aggregate
>>
>> Hi Gang Chen,
>> If I have the right idea:
>>
>> for(zval in levels(myData$Z))
>> crossprod(as.matrix(myData[myData$Z==zval,c("X","Y")]))
>>
>> Jim
>>
>> On Wed, Aug 24, 2016 at 8:03 AM, Gang Chen <gangchen6 at gmail.com> wrote:
>>> This is a simple question: With a dataframe like the following
>>>
>>> myData <- data.frame(X=c(1, 2, 3, 4), Y=c(4, 3, 2, 1), Z=c('A', 'A', 'B', 'B'))
>>>
>>> how can I get the cross product between X and Y for each level of
>>> factor Z? My difficulty is that I don't know how to deal with the fact
>>> that crossprod() acts on two variables in this case.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Wed Aug 24 19:07:07 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 24 Aug 2016 17:07:07 +0000
Subject: [R] aggregate
In-Reply-To: <CAHmzXO4B686ri9867tXnto=JYeE0PPkUbKBXC8o+6r51piqb6w@mail.gmail.com>
References: <CAHmzXO7tGBRevkQbcM_F31exmMtCgM-7HDW7d3VMzSFzO+HcJg@mail.gmail.com>
	<CA+8X3fXi+F2yKveAEPvFT7j=ZhYepKvxJ=297YMuAy12t=nOcA@mail.gmail.com>
	<9b3ddc5330e24fb4a6ff84188dcdfb57@exch-2p-mbx-t2.ads.tamu.edu>
	<CAHmzXO7q-4nmqgqTg2t+fiwCvnb_YgcWnBjEPNVZ0YZ-EEGqQw@mail.gmail.com>
	<69d5ea229ef440bda48442ca94bb5f2a@exch-2p-mbx-t2.ads.tamu.edu>
	<CAHmzXO4B686ri9867tXnto=JYeE0PPkUbKBXC8o+6r51piqb6w@mail.gmail.com>
Message-ID: <be10e6fe20c44606bf88766002a8e05d@exch-2p-mbx-t2.ads.tamu.edu>

You need to spend some time with a basic R tutorial. Your data is messed up because you did not use a simple text editor somewhere along the way. R understands ', but not ? or ?. The best way to send data to the list is to use dput:

> dput(myData)
structure(list(X = c(1, 2, 3, 4, 5, 6, 7, 8), Y = c(8, 7, 6, 
5, 4, 3, 2, 1), S = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L
), .Label = c("S1", "S2"), class = "factor"), Z = structure(c(1L, 
1L, 2L, 2L, 1L, 1L, 2L, 2L), .Label = c("A", "B"), class = "factor")), .Names = c("X", 
"Y", "S", "Z"), row.names = c(NA, -8L), class = "data.frame")

Combining two labels just requires the paste0() function:

> sapply(split(myData, paste0(myData$S, myData$Z)), function(x) crossprod(x[, 1], x[, 2]))
S1A S1B S2A S2B 
 22  38  38  22

David C

-----Original Message-----
From: Gang Chen [mailto:gangchen6 at gmail.com] 
Sent: Wednesday, August 24, 2016 11:56 AM
To: David L Carlson
Cc: Jim Lemon; r-help mailing list
Subject: Re: [R] aggregate

Thanks a lot, David! I want to further expand the operation a little
bit. With a new dataframe:

myData <- data.frame(X=c(1, 2, 3, 4, 5, 6, 7, 8), Y=c(8, 7, 6, 5, 4,
3, 2, 1), S=c(?S1?, ?S1?, ?S1?, ?S1?, ?S2?, ?S2?, ?S2?, ?S2?),
Z=c(?A?, ?A?, ?B?, ?B?, ?A?, ?A?, ?B?, ?B?))

> myData

  X Y  S Z
1 1 8 S1 A
2 2 7 S1 A
3 3 6 S1 B
4 4 5 S1 B
5 5 4 S2 A
6 6 3 S2 A
7 7 2 S2 B
8 8 1 S2 B

I would like to obtain the same cross product between columns X and Y,
but at each combination level of factors S and Z. In other words, the
cross product would be still performed each two rows in the new
dataframe myData. How can I achieve that?

On Wed, Aug 24, 2016 at 11:54 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> Your is fine, but it will be a little simpler if you use sapply() instead:
>
>> data.frame(Z=levels(myData$Z), CP=sapply(split(myData, myData$Z),
> +     function(x) crossprod(x[, 1], x[, 2])))
>   Z CP
> A A 10
> B B 10
>
> David C
>
>
> -----Original Message-----
> From: Gang Chen [mailto:gangchen6 at gmail.com]
> Sent: Wednesday, August 24, 2016 10:17 AM
> To: David L Carlson
> Cc: Jim Lemon; r-help mailing list
> Subject: Re: [R] aggregate
>
> Thank you all for the suggestions! Yes, I'm looking for the cross
> product between the two columns of X and Y.
>
> A follow-up question: what is a nice way to merge the output of
>
> lapply(split(myData, myData$Z), function(x) crossprod(x[, 1], x[, 2]))
>
> with the column Z in myData so that I would get a new dataframe as the
> following (the 2nd column is the cross product between X and Y)?
>
> Z   CP
> A   10
> B   10
>
> Is the following legitimate?
>
> data.frame(Z=levels(myData$Z), CP= unlist(lapply(split(myData,
> myData$Z), function(x) crossprod(x[, 1], x[, 2]))))
>
>
> On Wed, Aug 24, 2016 at 10:37 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>> Thank you for the reproducible example, but it is not clear what cross product you want. Jim's solution gives you the cross product of the 2-column matrix with itself. If you want the cross product between the columns you need something else. The aggregate function will not work since it will treat the columns separately:
>>
>>> A <- as.matrix(myData[myData$Z=="A", 1:2])
>>> A
>>   X Y
>> 1 1 4
>> 2 2 3
>>> crossprod(A) # Same as t(A) %*% A
>>    X  Y
>> X  5 10
>> Y 10 25
>>> crossprod(A[, 1], A[, 2]) # Same as t(A[, 1] %*% A[, 2]
>>      [,1]
>> [1,]   10
>>>
>>> # For all the groups
>>> lapply(split(myData, myData$Z), function(x) crossprod(as.matrix(x[, 1:2])))
>> $A
>>    X  Y
>> X  5 10
>> Y 10 25
>>
>> $B
>>    X  Y
>> X 25 10
>> Y 10  5
>>
>>> lapply(split(myData, myData$Z), function(x) crossprod(x[, 1], x[, 2]))
>> $A
>>      [,1]
>> [1,]   10
>>
>> $B
>>      [,1]
>> [1,]   10
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
>> Sent: Tuesday, August 23, 2016 6:02 PM
>> To: Gang Chen; r-help mailing list
>> Subject: Re: [R] aggregate
>>
>> Hi Gang Chen,
>> If I have the right idea:
>>
>> for(zval in levels(myData$Z))
>> crossprod(as.matrix(myData[myData$Z==zval,c("X","Y")]))
>>
>> Jim
>>
>> On Wed, Aug 24, 2016 at 8:03 AM, Gang Chen <gangchen6 at gmail.com> wrote:
>>> This is a simple question: With a dataframe like the following
>>>
>>> myData <- data.frame(X=c(1, 2, 3, 4), Y=c(4, 3, 2, 1), Z=c('A', 'A', 'B', 'B'))
>>>
>>> how can I get the cross product between X and Y for each level of
>>> factor Z? My difficulty is that I don't know how to deal with the fact
>>> that crossprod() acts on two variables in this case.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

From ruipbarradas at sapo.pt  Wed Aug 24 19:18:14 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Wed, 24 Aug 2016 18:18:14 +0100
Subject: [R] Loop over folder files
In-Reply-To: <CALBYkj+M+d=bsqWbs4kgmHxeGdaNZJ+HwZtVyAw3DbSUPxEDtg@mail.gmail.com>
References: <CALBYkj+rCTRsu2RkkUaEdncJW6BaiHM1hMjjnOEJU85xpGeq=A@mail.gmail.com>
	<20160822183231.Horde._-cnU0NlTggKzot0Wd-92_X@mail.sapo.pt>
	<CALBYkjKPrn0v=sgvDq65aqYSF_qRfbU0qUMuZ3wzivY6nhPLiw@mail.gmail.com>
	<dc661336-cf4f-b772-5822-c31e97166c62@dewey.myzen.co.uk>
	<20160823103150.Horde.lpio74f3m_msyKXA_KNwTzr@mail.sapo.pt>
	<CALBYkj+_ZoFWK4VaVDZ2f9xd22b5FzqKLqzKzoKtjHL+4t1GDA@mail.gmail.com>
	<EE7CC8A2-38DB-4B1A-B2CB-501021F94441@comcast.net>
	<20160823210824.Horde.xKnfUWQV3o7PwB9wo5n8_-T@mail.sapo.pt>
	<CALBYkjJ1VQ6eJw-9EyKPpGZ=EhJk7uwxGwoi-9gW7VwHfjWRFg@mail.gmail.com>
	<20160824154817.Horde.R8xuz7etVwbS5GopaAdKUl3@mail.sapo.pt>
	<CALBYkj+M+d=bsqWbs4kgmHxeGdaNZJ+HwZtVyAw3DbSUPxEDtg@mail.gmail.com>
Message-ID: <20160824181814.Horde.x6J8F5eekBJjJCAeAJbWXX6@mail.sapo.pt>

Maybe it's better to open a new thread.

Rui Barradas
?

Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:

> The error wasn't in the loop. It was in the file list.
> It's running now because i added full.names option to TRUE
> fuente=list.files("C:/Users/Jceccarelli/Bases/Stata",  
> pattern="dta$", full.names=T)
> Now R can proccess the data. Now it callapses or stops because other  
> kind of error.
> ?Should i open another topic or just use the mail list?
> By the way, thank you all.
> ?
> ? On Wed, Aug 24, 2016 at 11:48 AM, <ruipbarradas at sapo.pt> wrote:
>> _Hello,
>>
>> That means that probably the files are in a different folder/directory.
>> Use getwd() to see what is your current directory and
>> setwd("path/to/files") to set the right place where the files can be found.
>>
>> Rui Barradas
>> ?_
>>
>> _Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:_
>>
>>> _I just doesn't work..._
>>> _Im loading the read,dta13 package already._
>>> _When i try to perform a simple table(sex), i received the "File  
>>> not found" message._
>>> _However, if i load the data using the file.choose() option inside  
>>> read.dta13, i can open the stata file._
>>> _I don't know what am i doing wrong..._
>>> _? _ _On Tue, Aug 23, 2016 at 5:08 PM, <ruipbarradas at sapo.pt> wrote: _
>>>> __Or maybe a print() statement on the table() in the loop.
>>>>
>>>> print(table(...))
>>>>
>>>> Rui Barradas
>>>> ?__
>>>>
>>>> __Citando David Winsemius <dwinsemius at comcast.net>:__
>>>>
>>>>>> __On Aug 23, 2016, at 10:01 AM, Juan Ceccarelli Arias  
>>>>>> <jfca283 at gmail.com> wrote:
>>>>>>
>>>>>> Im running this but the code doesn't seem work.
>>>>>> It just hangs out but doesn't show any error.
>>>>>>
>>>>>> for (i in 1:length(fuente)){
>>>>>>
>>>>>> xxx=read_dta(fuente[i])
>>>>>>
>>>>>> table(xxx$cise, xxx$sexo)
>>>>>>
>>>>>> rm(xxx)
>>>>>>
>>>>>> }__
>>>>>
>>>>> __I still find the behavior of R's `for`-loop to be rather  
>>>>> puzzling. In this case you appear to be getting the operation  
>>>>> done, but because you didn't assign those table values to a  
>>>>> variable they just disappeared.
>>>>>
>>>>> Try this:
>>>>>
>>>>> XXX <- list()
>>>>>
>>>>> for (i in 1:length(fuente)){
>>>>> ? xxx=read_dta(fuente[i])
>>>>> ? XXX[[i]] <- table(xxx$cise, xxx$sexo)
>>>>> ? rm(xxx)
>>>>> }
>>>>> str(XXX)
>>>>>
>>>>> Seems to me that if you can do assignment to the parent  
>>>>> environment (without actually using assign( ..., env=...)? that  
>>>>> you should also be able to see the results of evaluation  
>>>>> occurring inside the for loop, but for-loops return NULL. So you  
>>>>> see nothing.
>>>>>
>>>>> David.
>>>>> ?_ _
>>>>>> __On Tue, Aug 23, 2016 at 6:31 AM, <ruipbarradas at sapo.pt> wrote:__
>>>>>>
>>>>>>> __Hello,
>>>>>>>
>>>>>>> The op could also use package sos to find that and other  
>>>>>>> packages to read
>>>>>>> stata files.
>>>>>>>
>>>>>>> install.packages("sos")
>>>>>>>
>>>>>>> library(sos)
>>>>>>> findFn("stata")
>>>>>>> found 374 matches;? retrieving 19 pages
>>>>>>> 2 3 4 5 6 7 8 9 10
>>>>>>> 11 12 13 14 15 16 17 18 19
>>>>>>> Downloaded 258 links in 121 packages
>>>>>>>
>>>>>>> The first package is readstata13 but there are others.
>>>>>>>
>>>>>>> Hope this helps,
>>>>>>>
>>>>>>> Rui Barradas
>>>>>>>
>>>>>>> Citando Michael Dewey <lists at dewey.myzen.co.uk>:
>>>>>>>
>>>>>>> Dear Juan
>>>>>>>
>>>>>>> If this is a Stata 13 file the package readstata13 available  
>>>>>>> from CRAN may
>>>>>>> be of assistance.
>>>>>>>
>>>>>>> On 22/08/2016 18:40, Juan Ceccarelli Arias wrote:
>>>>>>>
>>>>>>> I removed the data,frame=True...
>>>>>>> I obtain this warnings...
>>>>>>> Error in read.dta(fuente[i]) : not a Stata version 5-12 .dta file
>>>>>>> In addition: There were 50 or more warnings (use warnings() to see the
>>>>>>> first 50)
>>>>>>>
>>>>>>> the warnings() throws this
>>>>>>> Warning messages:
>>>>>>> 1: In `levels<-`(`*tmp*`, value = if (nl == nL)  
>>>>>>> as.character(labels) else
>>>>>>> paste0(labels,? ... :
>>>>>>> duplicated levels in factors are deprecated
>>>>>>> 2: In `levels<-`(`*tmp*`, value = if (nl == nL)  
>>>>>>> as.character(labels) else
>>>>>>> paste0(labels,? ... :
>>>>>>> duplicated levels in factors are deprecated
>>>>>>> 3: In `levels<-`(`*tmp*`, value = if (nl == nL)  
>>>>>>> as.character(labels) else
>>>>>>> paste0(labels,? ... :
>>>>>>> duplicated levels in factors are deprecated
>>>>>>> 4: In `levels<-`(`*tmp*`, value = if (nl == nL)  
>>>>>>> as.character(labels) else
>>>>>>> paste0(labels,? ... :
>>>>>>> duplicated levels in factors are deprecated
>>>>>>> 5: In `levels<-`(`*tmp*`, value = if (nl == nL)  
>>>>>>> as.character(labels) else
>>>>>>> paste0(labels,? ... :
>>>>>>> duplicated levels in factors are deprecated
>>>>>>>
>>>>>>> On Mon, Aug 22, 2016 at 2:32 PM, <ruipbarradas at sapo.pt> wrote:
>>>>>>>
>>>>>>> Hello,
>>>>>>>
>>>>>>> That argument doesn't exist, hence the error.
>>>>>>> Read the help page ?read.dta more carefully. You will see that already
>>>>>>> read.dta reads into a data.frame.
>>>>>>>
>>>>>>> Hope this helps,
>>>>>>>
>>>>>>> Rui Barradas
>>>>>>>
>>>>>>> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>>>>>>>
>>>>>>> Hi
>>>>>>> I need to apply some code over some stata files that are in folder.
>>>>>>> I've wrote this
>>>>>>>
>>>>>>> library(foreign)
>>>>>>>
>>>>>>> fuente=list.files("C:/Users/Jceccarelli/Bases/Stata[1]",  
>>>>>>> pattern="dta$",
>>>>>>> full.names=FALSE)
>>>>>>>
>>>>>>> for (i in 1:length(fuente)){
>>>>>>>
>>>>>>> xxx=read.dta(fuente[i], to.data.frame=TRUE)
>>>>>>>
>>>>>>> }
>>>>>>>
>>>>>>> But i get this error
>>>>>>>
>>>>>>> Error in read.dta(fuente[i], to.data.frame = TRUE) :
>>>>>>> unused argument (to.data.frame = TRUE)
>>>>>>>
>>>>>>> What am i doing wrong?
>>>>>>>
>>>>>>> ? ? ? [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>>>> posting-guide.htmland provide commented, minimal, self-contained,
>>>>>>> reproducible code.
>>>>>>>
>>>>>>> [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>>>> posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>> --
>>>>>>> Michaelhttp://www.dewey.myzen.co.uk/home.html[1]
>>>>>>>
>>>>>>> ?_
>>>>>>
>>>>>> __[[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide  
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code._
>>>>>
>>>>> _ _David WinsemiusAlameda, CA, USA__
>>>>
>>>> __?__
>>>
>>> _ _
>>> _ _
>>
>> _?_

?

Liga??es:
---------
[1]

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Aug 24 19:42:02 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 24 Aug 2016 13:42:02 -0400
Subject: [R] question about cleaning up data labels on a plot3d plot
In-Reply-To: <57BDD77C.1090806@molconn.com>
References: <57BD373D.6040701@molconn.com>
	<CAM_vjum85fOE+TZ5ddCKxHRi35x_Km8C-oPA7e2OF4nLGBNNZg@mail.gmail.com>
	<57BDD77C.1090806@molconn.com>
Message-ID: <CAM_vjunwq9B+KJZ-Tq5gz_-JQurbB12m1A7yez=oQQWz78vRsQ@mail.gmail.com>

You could take a look at ?identify3d

You should probably also read
https://cran.r-project.org/web/packages/rgl/vignettes/rgl.html

Beyond that, if it's difficult to see what you're looking for, maybe
you should rethink your approach.

Sarah

On Wed, Aug 24, 2016 at 1:21 PM, LMH <lmh_users-groups at molconn.com> wrote:
> Sarah Goslee wrote:
>>
>> text3d(x, y, z, text=letters[1:10], cex=2
>
>
> Thank you for the help. Is there a way to remove the text from the plot as
> well.
>
> I am finding it difficult to see what I am looking for with the text in the
> way. It would be useful to be able to identify a point and then clear the
> text. Can that be done while still maintaining the orientation of the plot?
>
> LMH


From bogaso.christofer at gmail.com  Wed Aug 24 20:48:16 2016
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Thu, 25 Aug 2016 00:18:16 +0530
Subject: [R] A question on data frame
Message-ID: <CA+dpOJmp3-MuKOR5uesaZdMQ4CGei_aYk0ui4z8wTkZUyELAug@mail.gmail.com>

Hello again,

Let say I have a data.frame which I call as reference data frame :

Ref = data.frame(c("a", "d", "c", "e", "f", "x"), matrix(NA, 6, 5))
colnames(Ref) = c("a1", "a2", "a3", "a4", "a5", "a6")
Ref

Now I have another data.frame, which I call as value data frame :

Value = data.frame(c("x", "c"), matrix(1:10, 2, 5))
colnames(Value) = c("a1", "b2", "b3", "b4", "b5", "b6")
Value

Now I need to insert the values of my 'Value' data frame into my 'Ref'
data frame, according to the order of the column of 'a1' of 'Ref'.

For example, the NA values of last row of Ref will be (1,  3,  5,  7,
9) and 3rd row of Ref will be (2,  4,  6,  8, 10). Basically I am
matching the "a1" column of both my data frames. If there is no match
found then corresponding row of Ref will remain unchanged.

Is there any R way to perform the same programmatically. In reality
both my data frames are quite big, so looking for some automated way
to perform the same.

Thanks for your time.

Regards,


From dwinsemius at comcast.net  Wed Aug 24 21:10:21 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 24 Aug 2016 12:10:21 -0700
Subject: [R] A question on data frame
In-Reply-To: <CA+dpOJmp3-MuKOR5uesaZdMQ4CGei_aYk0ui4z8wTkZUyELAug@mail.gmail.com>
References: <CA+dpOJmp3-MuKOR5uesaZdMQ4CGei_aYk0ui4z8wTkZUyELAug@mail.gmail.com>
Message-ID: <AD57AC2A-AF59-4BBE-AAE2-468E60559F30@comcast.net>


> On Aug 24, 2016, at 11:48 AM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
> 
> Hello again,
> 
> Let say I have a data.frame which I call as reference data frame :
> 
> Ref = data.frame(c("a", "d", "c", "e", "f", "x"), matrix(NA, 6, 5))
> colnames(Ref) = c("a1", "a2", "a3", "a4", "a5", "a6")
> Ref
> 
> Now I have another data.frame, which I call as value data frame :
> 
> Value = data.frame(c("x", "c"), matrix(1:10, 2, 5))
> colnames(Value) = c("a1", "b2", "b3", "b4", "b5", "b6")
> Value
> 
> Now I need to insert the values of my 'Value' data frame into my 'Ref'
> data frame, according to the order of the column of 'a1' of 'Ref'.
> 
> For example, the NA values of last row of Ref will be (1,  3,  5,  7,
> 9) and 3rd row of Ref will be (2,  4,  6,  8, 10). Basically I am
> matching the "a1" column of both my data frames. If there is no match
> found then corresponding row of Ref will remain unchanged.
> 
> Is there any R way to perform the same programmatically. In reality
> both my data frames are quite big, so looking for some automated way
> to perform the same.
> 

> Ref[ match(Value$a1, Ref$a1), 2:6] <- Value[ Value$a1 %in% Ref$a1, 2:6]

> Ref
  a1 a2 a3 a4 a5 a6
1  a NA NA NA NA NA
2  d NA NA NA NA NA
3  c  2  4  6  8 10
4  e NA NA NA NA NA
5  f NA NA NA NA NA
6  x  1  3  5  7  9

The `match` function creates an index vector for the placement,  and the `%in%` expression restricts the rows to items which will have a match on the LHS of the assignment.

-- 
David.


> Thanks for your time.
> 
> Regards,
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From gangchen6 at gmail.com  Wed Aug 24 21:50:36 2016
From: gangchen6 at gmail.com (Gang Chen)
Date: Wed, 24 Aug 2016 15:50:36 -0400
Subject: [R] aggregate
In-Reply-To: <be10e6fe20c44606bf88766002a8e05d@exch-2p-mbx-t2.ads.tamu.edu>
References: <CAHmzXO7tGBRevkQbcM_F31exmMtCgM-7HDW7d3VMzSFzO+HcJg@mail.gmail.com>
	<CA+8X3fXi+F2yKveAEPvFT7j=ZhYepKvxJ=297YMuAy12t=nOcA@mail.gmail.com>
	<9b3ddc5330e24fb4a6ff84188dcdfb57@exch-2p-mbx-t2.ads.tamu.edu>
	<CAHmzXO7q-4nmqgqTg2t+fiwCvnb_YgcWnBjEPNVZ0YZ-EEGqQw@mail.gmail.com>
	<69d5ea229ef440bda48442ca94bb5f2a@exch-2p-mbx-t2.ads.tamu.edu>
	<CAHmzXO4B686ri9867tXnto=JYeE0PPkUbKBXC8o+6r51piqb6w@mail.gmail.com>
	<be10e6fe20c44606bf88766002a8e05d@exch-2p-mbx-t2.ads.tamu.edu>
Message-ID: <CAHmzXO5==-jp-JWeYCRumoxDFp491+TUq0LE9NqshJ8+tWvvSQ@mail.gmail.com>

Thanks again for patiently offering great help, David! I just learned
dput() and paste0() now. Hopefully this is my last question.

Suppose a new dataframe is as below (one more numeric column):

myData <- structure(list(X = c(1, 2, 3, 4, 5, 6, 7, 8), Y = c(8, 7, 6,
5, 4, 3, 2, 1), N =c(rep(2.1, 4), rep(3.2, 4)), S = structure(c(1L,
1L, 1L, 1L, 2L, 2L, 2L, 2L
), .Label = c("S1", "S2"), class = "factor"), Z = structure(c(1L,
1L, 2L, 2L, 1L, 1L, 2L, 2L), .Label = c("A", "B"), class = "factor")),
.Names = c("X",
"Y", "N", "S", "Z"), row.names = c(NA, -8L), class = "data.frame")

> myData

  X Y   N  S Z
1 1 8 2.1 S1 A
2 2 7 2.1 S1 A
3 3 6 2.1 S1 B
4 4 5 2.1 S1 B
5 5 4 3.2 S2 A
6 6 3 3.2 S2 A
7 7 2 3.2 S2 B
8 8 1 3.2 S2 B

Once I obtain the cross product,

> sapply(split(myData, paste0(myData$S, myData$Z)), function(x) crossprod(x[, 1], x[, 2]))
S1A S1B S2A S2B
 22  38  38  22

how can I easily add the other 3 columns (N, S, and Z) in a new
dataframe? For S and Z, I can play with the names from the cross
product output, but I have trouble dealing with the numeric column N.




On Wed, Aug 24, 2016 at 1:07 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> You need to spend some time with a basic R tutorial. Your data is messed up because you did not use a simple text editor somewhere along the way. R understands ', but not ? or ?. The best way to send data to the list is to use dput:
>
>> dput(myData)
> structure(list(X = c(1, 2, 3, 4, 5, 6, 7, 8), Y = c(8, 7, 6,
> 5, 4, 3, 2, 1), S = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L
> ), .Label = c("S1", "S2"), class = "factor"), Z = structure(c(1L,
> 1L, 2L, 2L, 1L, 1L, 2L, 2L), .Label = c("A", "B"), class = "factor")), .Names = c("X",
> "Y", "S", "Z"), row.names = c(NA, -8L), class = "data.frame")
>
> Combining two labels just requires the paste0() function:
>
>> sapply(split(myData, paste0(myData$S, myData$Z)), function(x) crossprod(x[, 1], x[, 2]))
> S1A S1B S2A S2B
>  22  38  38  22
>
> David C
>
> -----Original Message-----
> From: Gang Chen [mailto:gangchen6 at gmail.com]
> Sent: Wednesday, August 24, 2016 11:56 AM
> To: David L Carlson
> Cc: Jim Lemon; r-help mailing list
> Subject: Re: [R] aggregate
>
> Thanks a lot, David! I want to further expand the operation a little
> bit. With a new dataframe:
>
> myData <- data.frame(X=c(1, 2, 3, 4, 5, 6, 7, 8), Y=c(8, 7, 6, 5, 4,
> 3, 2, 1), S=c(?S1?, ?S1?, ?S1?, ?S1?, ?S2?, ?S2?, ?S2?, ?S2?),
> Z=c(?A?, ?A?, ?B?, ?B?, ?A?, ?A?, ?B?, ?B?))
>
>> myData
>
>   X Y  S Z
> 1 1 8 S1 A
> 2 2 7 S1 A
> 3 3 6 S1 B
> 4 4 5 S1 B
> 5 5 4 S2 A
> 6 6 3 S2 A
> 7 7 2 S2 B
> 8 8 1 S2 B
>
> I would like to obtain the same cross product between columns X and Y,
> but at each combination level of factors S and Z. In other words, the
> cross product would be still performed each two rows in the new
> dataframe myData. How can I achieve that?
>
> On Wed, Aug 24, 2016 at 11:54 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>> Your is fine, but it will be a little simpler if you use sapply() instead:
>>
>>> data.frame(Z=levels(myData$Z), CP=sapply(split(myData, myData$Z),
>> +     function(x) crossprod(x[, 1], x[, 2])))
>>   Z CP
>> A A 10
>> B B 10
>>
>> David C
>>
>>
>> -----Original Message-----
>> From: Gang Chen [mailto:gangchen6 at gmail.com]
>> Sent: Wednesday, August 24, 2016 10:17 AM
>> To: David L Carlson
>> Cc: Jim Lemon; r-help mailing list
>> Subject: Re: [R] aggregate
>>
>> Thank you all for the suggestions! Yes, I'm looking for the cross
>> product between the two columns of X and Y.
>>
>> A follow-up question: what is a nice way to merge the output of
>>
>> lapply(split(myData, myData$Z), function(x) crossprod(x[, 1], x[, 2]))
>>
>> with the column Z in myData so that I would get a new dataframe as the
>> following (the 2nd column is the cross product between X and Y)?
>>
>> Z   CP
>> A   10
>> B   10
>>
>> Is the following legitimate?
>>
>> data.frame(Z=levels(myData$Z), CP= unlist(lapply(split(myData,
>> myData$Z), function(x) crossprod(x[, 1], x[, 2]))))
>>
>>
>> On Wed, Aug 24, 2016 at 10:37 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>>> Thank you for the reproducible example, but it is not clear what cross product you want. Jim's solution gives you the cross product of the 2-column matrix with itself. If you want the cross product between the columns you need something else. The aggregate function will not work since it will treat the columns separately:
>>>
>>>> A <- as.matrix(myData[myData$Z=="A", 1:2])
>>>> A
>>>   X Y
>>> 1 1 4
>>> 2 2 3
>>>> crossprod(A) # Same as t(A) %*% A
>>>    X  Y
>>> X  5 10
>>> Y 10 25
>>>> crossprod(A[, 1], A[, 2]) # Same as t(A[, 1] %*% A[, 2]
>>>      [,1]
>>> [1,]   10
>>>>
>>>> # For all the groups
>>>> lapply(split(myData, myData$Z), function(x) crossprod(as.matrix(x[, 1:2])))
>>> $A
>>>    X  Y
>>> X  5 10
>>> Y 10 25
>>>
>>> $B
>>>    X  Y
>>> X 25 10
>>> Y 10  5
>>>
>>>> lapply(split(myData, myData$Z), function(x) crossprod(x[, 1], x[, 2]))
>>> $A
>>>      [,1]
>>> [1,]   10
>>>
>>> $B
>>>      [,1]
>>> [1,]   10
>>>
>>> -------------------------------------
>>> David L Carlson
>>> Department of Anthropology
>>> Texas A&M University
>>> College Station, TX 77840-4352
>>>
>>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
>>> Sent: Tuesday, August 23, 2016 6:02 PM
>>> To: Gang Chen; r-help mailing list
>>> Subject: Re: [R] aggregate
>>>
>>> Hi Gang Chen,
>>> If I have the right idea:
>>>
>>> for(zval in levels(myData$Z))
>>> crossprod(as.matrix(myData[myData$Z==zval,c("X","Y")]))
>>>
>>> Jim
>>>
>>> On Wed, Aug 24, 2016 at 8:03 AM, Gang Chen <gangchen6 at gmail.com> wrote:
>>>> This is a simple question: With a dataframe like the following
>>>>
>>>> myData <- data.frame(X=c(1, 2, 3, 4), Y=c(4, 3, 2, 1), Z=c('A', 'A', 'B', 'B'))
>>>>
>>>> how can I get the cross product between X and Y for each level of
>>>> factor Z? My difficulty is that I don't know how to deal with the fact
>>>> that crossprod() acts on two variables in this case.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Wed Aug 24 22:24:29 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 24 Aug 2016 20:24:29 +0000
Subject: [R] aggregate
In-Reply-To: <CAHmzXO5==-jp-JWeYCRumoxDFp491+TUq0LE9NqshJ8+tWvvSQ@mail.gmail.com>
References: <CAHmzXO7tGBRevkQbcM_F31exmMtCgM-7HDW7d3VMzSFzO+HcJg@mail.gmail.com>
	<CA+8X3fXi+F2yKveAEPvFT7j=ZhYepKvxJ=297YMuAy12t=nOcA@mail.gmail.com>
	<9b3ddc5330e24fb4a6ff84188dcdfb57@exch-2p-mbx-t2.ads.tamu.edu>
	<CAHmzXO7q-4nmqgqTg2t+fiwCvnb_YgcWnBjEPNVZ0YZ-EEGqQw@mail.gmail.com>
	<69d5ea229ef440bda48442ca94bb5f2a@exch-2p-mbx-t2.ads.tamu.edu>
	<CAHmzXO4B686ri9867tXnto=JYeE0PPkUbKBXC8o+6r51piqb6w@mail.gmail.com>
	<be10e6fe20c44606bf88766002a8e05d@exch-2p-mbx-t2.ads.tamu.edu>
	<CAHmzXO5==-jp-JWeYCRumoxDFp491+TUq0LE9NqshJ8+tWvvSQ@mail.gmail.com>
Message-ID: <a18ea467581146e797c305424841464a@exch-2p-mbx-t2.ads.tamu.edu>

This will work, but you should double-check to be certain that CP and unique(myData[, 3:5]) are in the same order. It will fail if N is not identical for all rows of the same S-Z combination. 

> CP <- sapply(split(myData, paste0(myData$S, myData$Z)), function(x)
+       crossprod(x[, 1], x[, 2]))
> data.frame(CP, unique(myData[, 3:5]))
    CP   N  S Z
S1A 22 2.1 S1 A
S1B 38 2.1 S1 B
S2A 38 3.2 S2 A
S2B 22 3.2 S2 B

David C

-----Original Message-----
From: Gang Chen [mailto:gangchen6 at gmail.com] 
Sent: Wednesday, August 24, 2016 2:51 PM
To: David L Carlson
Cc: r-help mailing list
Subject: Re: [R] aggregate

Thanks again for patiently offering great help, David! I just learned
dput() and paste0() now. Hopefully this is my last question.

Suppose a new dataframe is as below (one more numeric column):

myData <- structure(list(X = c(1, 2, 3, 4, 5, 6, 7, 8), Y = c(8, 7, 6,
5, 4, 3, 2, 1), N =c(rep(2.1, 4), rep(3.2, 4)), S = structure(c(1L,
1L, 1L, 1L, 2L, 2L, 2L, 2L
), .Label = c("S1", "S2"), class = "factor"), Z = structure(c(1L,
1L, 2L, 2L, 1L, 1L, 2L, 2L), .Label = c("A", "B"), class = "factor")),
.Names = c("X",
"Y", "N", "S", "Z"), row.names = c(NA, -8L), class = "data.frame")

> myData

  X Y   N  S Z
1 1 8 2.1 S1 A
2 2 7 2.1 S1 A
3 3 6 2.1 S1 B
4 4 5 2.1 S1 B
5 5 4 3.2 S2 A
6 6 3 3.2 S2 A
7 7 2 3.2 S2 B
8 8 1 3.2 S2 B

Once I obtain the cross product,

> sapply(split(myData, paste0(myData$S, myData$Z)), function(x) crossprod(x[, 1], x[, 2]))
S1A S1B S2A S2B
 22  38  38  22

how can I easily add the other 3 columns (N, S, and Z) in a new
dataframe? For S and Z, I can play with the names from the cross
product output, but I have trouble dealing with the numeric column N.




On Wed, Aug 24, 2016 at 1:07 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> You need to spend some time with a basic R tutorial. Your data is messed up because you did not use a simple text editor somewhere along the way. R understands ', but not ? or ?. The best way to send data to the list is to use dput:
>
>> dput(myData)
> structure(list(X = c(1, 2, 3, 4, 5, 6, 7, 8), Y = c(8, 7, 6,
> 5, 4, 3, 2, 1), S = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L
> ), .Label = c("S1", "S2"), class = "factor"), Z = structure(c(1L,
> 1L, 2L, 2L, 1L, 1L, 2L, 2L), .Label = c("A", "B"), class = "factor")), .Names = c("X",
> "Y", "S", "Z"), row.names = c(NA, -8L), class = "data.frame")
>
> Combining two labels just requires the paste0() function:
>
>> sapply(split(myData, paste0(myData$S, myData$Z)), function(x) crossprod(x[, 1], x[, 2]))
> S1A S1B S2A S2B
>  22  38  38  22
>
> David C
>
> -----Original Message-----
> From: Gang Chen [mailto:gangchen6 at gmail.com]
> Sent: Wednesday, August 24, 2016 11:56 AM
> To: David L Carlson
> Cc: Jim Lemon; r-help mailing list
> Subject: Re: [R] aggregate
>
> Thanks a lot, David! I want to further expand the operation a little
> bit. With a new dataframe:
>
> myData <- data.frame(X=c(1, 2, 3, 4, 5, 6, 7, 8), Y=c(8, 7, 6, 5, 4,
> 3, 2, 1), S=c(?S1?, ?S1?, ?S1?, ?S1?, ?S2?, ?S2?, ?S2?, ?S2?),
> Z=c(?A?, ?A?, ?B?, ?B?, ?A?, ?A?, ?B?, ?B?))
>
>> myData
>
>   X Y  S Z
> 1 1 8 S1 A
> 2 2 7 S1 A
> 3 3 6 S1 B
> 4 4 5 S1 B
> 5 5 4 S2 A
> 6 6 3 S2 A
> 7 7 2 S2 B
> 8 8 1 S2 B
>
> I would like to obtain the same cross product between columns X and Y,
> but at each combination level of factors S and Z. In other words, the
> cross product would be still performed each two rows in the new
> dataframe myData. How can I achieve that?
>
> On Wed, Aug 24, 2016 at 11:54 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>> Your is fine, but it will be a little simpler if you use sapply() instead:
>>
>>> data.frame(Z=levels(myData$Z), CP=sapply(split(myData, myData$Z),
>> +     function(x) crossprod(x[, 1], x[, 2])))
>>   Z CP
>> A A 10
>> B B 10
>>
>> David C
>>
>>
>> -----Original Message-----
>> From: Gang Chen [mailto:gangchen6 at gmail.com]
>> Sent: Wednesday, August 24, 2016 10:17 AM
>> To: David L Carlson
>> Cc: Jim Lemon; r-help mailing list
>> Subject: Re: [R] aggregate
>>
>> Thank you all for the suggestions! Yes, I'm looking for the cross
>> product between the two columns of X and Y.
>>
>> A follow-up question: what is a nice way to merge the output of
>>
>> lapply(split(myData, myData$Z), function(x) crossprod(x[, 1], x[, 2]))
>>
>> with the column Z in myData so that I would get a new dataframe as the
>> following (the 2nd column is the cross product between X and Y)?
>>
>> Z   CP
>> A   10
>> B   10
>>
>> Is the following legitimate?
>>
>> data.frame(Z=levels(myData$Z), CP= unlist(lapply(split(myData,
>> myData$Z), function(x) crossprod(x[, 1], x[, 2]))))
>>
>>
>> On Wed, Aug 24, 2016 at 10:37 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>>> Thank you for the reproducible example, but it is not clear what cross product you want. Jim's solution gives you the cross product of the 2-column matrix with itself. If you want the cross product between the columns you need something else. The aggregate function will not work since it will treat the columns separately:
>>>
>>>> A <- as.matrix(myData[myData$Z=="A", 1:2])
>>>> A
>>>   X Y
>>> 1 1 4
>>> 2 2 3
>>>> crossprod(A) # Same as t(A) %*% A
>>>    X  Y
>>> X  5 10
>>> Y 10 25
>>>> crossprod(A[, 1], A[, 2]) # Same as t(A[, 1] %*% A[, 2]
>>>      [,1]
>>> [1,]   10
>>>>
>>>> # For all the groups
>>>> lapply(split(myData, myData$Z), function(x) crossprod(as.matrix(x[, 1:2])))
>>> $A
>>>    X  Y
>>> X  5 10
>>> Y 10 25
>>>
>>> $B
>>>    X  Y
>>> X 25 10
>>> Y 10  5
>>>
>>>> lapply(split(myData, myData$Z), function(x) crossprod(x[, 1], x[, 2]))
>>> $A
>>>      [,1]
>>> [1,]   10
>>>
>>> $B
>>>      [,1]
>>> [1,]   10
>>>
>>> -------------------------------------
>>> David L Carlson
>>> Department of Anthropology
>>> Texas A&M University
>>> College Station, TX 77840-4352
>>>
>>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
>>> Sent: Tuesday, August 23, 2016 6:02 PM
>>> To: Gang Chen; r-help mailing list
>>> Subject: Re: [R] aggregate
>>>
>>> Hi Gang Chen,
>>> If I have the right idea:
>>>
>>> for(zval in levels(myData$Z))
>>> crossprod(as.matrix(myData[myData$Z==zval,c("X","Y")]))
>>>
>>> Jim
>>>
>>> On Wed, Aug 24, 2016 at 8:03 AM, Gang Chen <gangchen6 at gmail.com> wrote:
>>>> This is a simple question: With a dataframe like the following
>>>>
>>>> myData <- data.frame(X=c(1, 2, 3, 4), Y=c(4, 3, 2, 1), Z=c('A', 'A', 'B', 'B'))
>>>>
>>>> how can I get the cross product between X and Y for each level of
>>>> factor Z? My difficulty is that I don't know how to deal with the fact
>>>> that crossprod() acts on two variables in this case.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.

From Jacob.Strunk at dnr.wa.gov  Wed Aug 24 21:21:25 2016
From: Jacob.Strunk at dnr.wa.gov (Strunk, Jacob (DNR))
Date: Wed, 24 Aug 2016 19:21:25 +0000
Subject: [R] package.skeleton fails
Message-ID: <72D7DF49EFB92E4A9BE47205A0F4F03222C1F9C5@WAXMXOLYMB016.WAX.wa.lcl>

Hello, I have been using package.skeleton from within an lapply statement
successfully (assuming good source code) with the following setup in the
past:

writeLines("testfun=function(){}", "c:\\temp\\testfun.r")
x=try(package.skeleton("test_pack",path="c:\\temp\\tests\\",code_files= "c:\\temp\\testfun.r"))

but it now fails with the error:

Error: evaluation nested too deeply: infinite recursion /
options(expressions=)?

I am working in RStudio Version 0.99.896, with 64 bit R version 3.3.1
(2016-06-21)

I have been poking in the code and the error appears happen within the subfunction '.fixPackageFileNames'

Thanks for any assistance you might be able to provide.

Jacob


	[[alternative HTML version deleted]]


From lmh_users-groups at molconn.com  Wed Aug 24 19:21:00 2016
From: lmh_users-groups at molconn.com (LMH)
Date: Wed, 24 Aug 2016 13:21:00 -0400
Subject: [R] question about cleaning up data labels on a plot3d plot
In-Reply-To: <CAM_vjum85fOE+TZ5ddCKxHRi35x_Km8C-oPA7e2OF4nLGBNNZg@mail.gmail.com>
References: <57BD373D.6040701@molconn.com>
	<CAM_vjum85fOE+TZ5ddCKxHRi35x_Km8C-oPA7e2OF4nLGBNNZg@mail.gmail.com>
Message-ID: <57BDD77C.1090806@molconn.com>

Sarah Goslee wrote:
> text3d(x, y, z, text=letters[1:10], cex=2

Thank you for the help. Is there a way to remove the text from the plot as well.

I am finding it difficult to see what I am looking for with the text in the way. It 
would be useful to be able to identify a point and then clear the text. Can that be 
done while still maintaining the orientation of the plot?

LMH


From jfca283 at gmail.com  Wed Aug 24 18:03:21 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Wed, 24 Aug 2016 13:03:21 -0300
Subject: [R] Loop over folder files
In-Reply-To: <20160824154817.Horde.R8xuz7etVwbS5GopaAdKUl3@mail.sapo.pt>
References: <CALBYkj+rCTRsu2RkkUaEdncJW6BaiHM1hMjjnOEJU85xpGeq=A@mail.gmail.com>
	<20160822183231.Horde._-cnU0NlTggKzot0Wd-92_X@mail.sapo.pt>
	<CALBYkjKPrn0v=sgvDq65aqYSF_qRfbU0qUMuZ3wzivY6nhPLiw@mail.gmail.com>
	<dc661336-cf4f-b772-5822-c31e97166c62@dewey.myzen.co.uk>
	<20160823103150.Horde.lpio74f3m_msyKXA_KNwTzr@mail.sapo.pt>
	<CALBYkj+_ZoFWK4VaVDZ2f9xd22b5FzqKLqzKzoKtjHL+4t1GDA@mail.gmail.com>
	<EE7CC8A2-38DB-4B1A-B2CB-501021F94441@comcast.net>
	<20160823210824.Horde.xKnfUWQV3o7PwB9wo5n8_-T@mail.sapo.pt>
	<CALBYkjJ1VQ6eJw-9EyKPpGZ=EhJk7uwxGwoi-9gW7VwHfjWRFg@mail.gmail.com>
	<20160824154817.Horde.R8xuz7etVwbS5GopaAdKUl3@mail.sapo.pt>
Message-ID: <CALBYkj+M+d=bsqWbs4kgmHxeGdaNZJ+HwZtVyAw3DbSUPxEDtg@mail.gmail.com>

The error wasn't in the loop. It was in the file list.
It's running now because i added full.names option to TRUE
fuente=list.files("C:/Users/Jceccarelli/Bases/Stata", pattern="dta$",
full.names=T)
Now R can proccess the data. Now it callapses or stops because other kind
of error.
?Should i open another topic or just use the mail list?
By the way, thank you all.


On Wed, Aug 24, 2016 at 11:48 AM, <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> That means that probably the files are in a different folder/directory.
> Use getwd() to see what is your current directory and
> setwd("path/to/files") to set the right place where the files can be found.
>
> Rui Barradas
>
>
> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>
> I just doesn't work...
> Im loading the read,dta13 package already.
> When i try to perform a simple table(sex), i received the "File not found"
> message.
> However, if i load the data using the file.choose() option inside
> read.dta13, i can open the stata file.
> I don't know what am i doing wrong...
>
> On Tue, Aug 23, 2016 at 5:08 PM, <ruipbarradas at sapo.pt> wrote:
>>
>>
>>
>>
>>
>>
>> *Or maybe a print() statement on the table() in the loop.
>> print(table(...)) Rui Barradas  *
>>
>> *Citando David Winsemius <dwinsemius at comcast.net
>> <dwinsemius at comcast.net>>:*
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> *On Aug 23, 2016, at 10:01 AM, Juan Ceccarelli Arias <jfca283 at gmail.com
>> <jfca283 at gmail.com>> wrote: Im running this but the code doesn't seem work.
>> It just hangs out but doesn't show any error. for (i in 1:length(fuente)){
>> xxx=read_dta(fuente[i]) table(xxx$cise, xxx$sexo) rm(xxx) }*
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> *I still find the behavior of R's `for`-loop to be rather puzzling. In
>> this case you appear to be getting the operation done, but because you
>> didn't assign those table values to a variable they just disappeared. Try
>> this: XXX <- list() for (i in 1:length(fuente)){   xxx=read_dta(fuente[i])
>>   XXX[[i]] <- table(xxx$cise, xxx$sexo)   rm(xxx) } str(XXX) Seems to me
>> that if you can do assignment to the parent environment (without actually
>> using assign( ..., env=...)  that you should also be able to see the
>> results of evaluation occurring inside the for loop, but for-loops return
>> NULL. So you see nothing. David.  *
>>
>> *On Tue, Aug 23, 2016 at 6:31 AM, <ruipbarradas at sapo.pt
>> <ruipbarradas at sapo.pt>> wrote:*
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> *Hello, The op could also use package sos to find that and other packages
>> to read stata files. install.packages("sos") library(sos) findFn("stata")
>> found 374 matches;  retrieving 19 pages 2 3 4 5 6 7 8 9 10 11 12 13 14 15
>> 16 17 18 19 Downloaded 258 links in 121 packages The first package is
>> readstata13 but there are others. Hope this helps, Rui Barradas Citando
>> Michael Dewey <lists at dewey.myzen.co.uk <lists at dewey.myzen.co.uk>>: Dear
>> Juan If this is a Stata 13 file the package readstata13 available from CRAN
>> may be of assistance. On 22/08/2016 18:40, Juan Ceccarelli Arias wrote: I
>> removed the data,frame=True... I obtain this warnings... Error in
>> read.dta(fuente[i]) : not a Stata version 5-12 .dta file In addition: There
>> were 50 or more warnings (use warnings() to see the first 50) the
>> warnings() throws this Warning messages: 1: In `levels<-`(`*tmp*`, value =
>> if (nl == nL) as.character(labels) else paste0(labels,  ... : duplicated
>> levels in factors are deprecated 2: In `levels<-`(`*tmp*`, value = if (nl
>> == nL) as.character(labels) else paste0(labels,  ... : duplicated levels in
>> factors are deprecated 3: In `levels<-`(`*tmp*`, value = if (nl == nL)
>> as.character(labels) else paste0(labels,  ... : duplicated levels in
>> factors are deprecated 4: In `levels<-`(`*tmp*`, value = if (nl == nL)
>> as.character(labels) else paste0(labels,  ... : duplicated levels in
>> factors are deprecated 5: In `levels<-`(`*tmp*`, value = if (nl == nL)
>> as.character(labels) else paste0(labels,  ... : duplicated levels in
>> factors are deprecated On Mon, Aug 22, 2016 at 2:32 PM,
>> <ruipbarradas at sapo.pt <ruipbarradas at sapo.pt>> wrote: Hello, That argument
>> doesn't exist, hence the error. Read the help page ?read.dta more
>> carefully. You will see that already read.dta reads into a data.frame. Hope
>> this helps, Rui Barradas Citando Juan Ceccarelli Arias <jfca283 at gmail.com
>> <jfca283 at gmail.com>>: Hi I need to apply some code over some stata files
>> that are in folder. I've wrote this library(foreign)
>> fuente=list.files("C:/Users/Jceccarelli/Bases/Stata", pattern="dta$",
>> full.names=FALSE) for (i in 1:length(fuente)){ xxx=read.dta(fuente[i],
>> to.data.frame=TRUE) } But i get this error Error in read.dta(fuente[i],
>> to.data.frame = TRUE) : unused argument (to.data.frame = TRUE) What am i
>> doing wrong?       [[alternative HTML version deleted]]
>> ______________________________*________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.htmland provide commented, minimal, self-contained,
>> reproducible code.
>>
>>
>>
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Michaelhttp://www.dewey.myzen.co.uk/home.html
>>
>>
>>
>>
>>
>>
>> *[[alternative HTML version deleted]] ______________________________*
>> ________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> *David WinsemiusAlameda, CA, USA*
>>
>>
>>
>>
>
>
>

	[[alternative HTML version deleted]]


From jfca283 at gmail.com  Wed Aug 24 20:08:38 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Wed, 24 Aug 2016 15:08:38 -0300
Subject: [R] Loop over folder files
In-Reply-To: <20160824181814.Horde.x6J8F5eekBJjJCAeAJbWXX6@mail.sapo.pt>
References: <CALBYkj+rCTRsu2RkkUaEdncJW6BaiHM1hMjjnOEJU85xpGeq=A@mail.gmail.com>
	<20160822183231.Horde._-cnU0NlTggKzot0Wd-92_X@mail.sapo.pt>
	<CALBYkjKPrn0v=sgvDq65aqYSF_qRfbU0qUMuZ3wzivY6nhPLiw@mail.gmail.com>
	<dc661336-cf4f-b772-5822-c31e97166c62@dewey.myzen.co.uk>
	<20160823103150.Horde.lpio74f3m_msyKXA_KNwTzr@mail.sapo.pt>
	<CALBYkj+_ZoFWK4VaVDZ2f9xd22b5FzqKLqzKzoKtjHL+4t1GDA@mail.gmail.com>
	<EE7CC8A2-38DB-4B1A-B2CB-501021F94441@comcast.net>
	<20160823210824.Horde.xKnfUWQV3o7PwB9wo5n8_-T@mail.sapo.pt>
	<CALBYkjJ1VQ6eJw-9EyKPpGZ=EhJk7uwxGwoi-9gW7VwHfjWRFg@mail.gmail.com>
	<20160824154817.Horde.R8xuz7etVwbS5GopaAdKUl3@mail.sapo.pt>
	<CALBYkj+M+d=bsqWbs4kgmHxeGdaNZJ+HwZtVyAw3DbSUPxEDtg@mail.gmail.com>
	<20160824181814.Horde.x6J8F5eekBJjJCAeAJbWXX6@mail.sapo.pt>
Message-ID: <CALBYkjJz8BKUdDUkB1uyXuMSpGn6HYw+3OP+yYECw2icv5N4og@mail.gmail.com>

Ok. Please, declare this issue as solved.
And thanks again for your help.

On Wed, Aug 24, 2016 at 2:18 PM, <ruipbarradas at sapo.pt> wrote:

> Maybe it's better to open a new thread.
>
> Rui Barradas
>
>
> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>
> The error wasn't in the loop. It was in the file list.
> It's running now because i added full.names option to TRUE
> fuente=list.files("C:/Users/Jceccarelli/Bases/Stata", pattern="dta$",
> full.names=T)
> Now R can proccess the data. Now it callapses or stops because other kind
> of error.
> ?Should i open another topic or just use the mail list?
> By the way, thank you all.
>
>
> On Wed, Aug 24, 2016 at 11:48 AM, <ruipbarradas at sapo.pt> wrote:
>>
>>
>>
>>
>>
>>
>>
>>
>> *Hello, That means that probably the files are in a different
>> folder/directory. Use getwd() to see what is your current directory and
>> setwd("path/to/files") to set the right place where the files can be found.
>> Rui Barradas  *
>>
>> *Citando Juan Ceccarelli Arias <jfca283 at gmail.com <jfca283 at gmail.com>>:*
>>
>> *I just doesn't work...*
>> *Im loading the read,dta13 package already.*
>> *When i try to perform a simple table(sex), i received the "File not
>> found" message.*
>> *However, if i load the data using the file.choose() option inside
>> read.dta13, i can open the stata file.*
>> *I don't know what am i doing wrong...*
>>
>> *On Tue, Aug 23, 2016 at 5:08 PM, <ruipbarradas at sapo.pt
>> <ruipbarradas at sapo.pt>> wrote:*
>>>
>>>
>>>
>>>
>>>
>>>
>>> *Or maybe a print() statement on the table() in the loop.
>>> print(table(...)) Rui Barradas  *
>>>
>>> *Citando David Winsemius <dwinsemius at comcast.net
>>> <dwinsemius at comcast.net>>:*
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> *On Aug 23, 2016, at 10:01 AM, Juan Ceccarelli Arias <jfca283 at gmail.com
>>> <jfca283 at gmail.com>> wrote: Im running this but the code doesn't seem work.
>>> It just hangs out but doesn't show any error. for (i in 1:length(fuente)){
>>> xxx=read_dta(fuente[i]) table(xxx$cise, xxx$sexo) rm(xxx) }*
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> *I still find the behavior of R's `for`-loop to be rather puzzling. In
>>> this case you appear to be getting the operation done, but because you
>>> didn't assign those table values to a variable they just disappeared. Try
>>> this: XXX <- list() for (i in 1:length(fuente)){   xxx=read_dta(fuente[i])
>>>   XXX[[i]] <- table(xxx$cise, xxx$sexo)   rm(xxx) } str(XXX) Seems to me
>>> that if you can do assignment to the parent environment (without actually
>>> using assign( ..., env=...)  that you should also be able to see the
>>> results of evaluation occurring inside the for loop, but for-loops return
>>> NULL. So you see nothing. David.  *
>>>
>>> *On Tue, Aug 23, 2016 at 6:31 AM, <ruipbarradas at sapo.pt
>>> <ruipbarradas at sapo.pt>> wrote:*
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> *Hello, The op could also use package sos to find that and other
>>> packages to read stata files. install.packages("sos") library(sos)
>>> findFn("stata") found 374 matches;  retrieving 19 pages 2 3 4 5 6 7 8 9 10
>>> 11 12 13 14 15 16 17 18 19 Downloaded 258 links in 121 packages The first
>>> package is readstata13 but there are others. Hope this helps, Rui Barradas
>>> Citando Michael Dewey <lists at dewey.myzen.co.uk <lists at dewey.myzen.co.uk>>:
>>> Dear Juan If this is a Stata 13 file the package readstata13 available from
>>> CRAN may be of assistance. On 22/08/2016 18:40, Juan Ceccarelli Arias
>>> wrote: I removed the data,frame=True... I obtain this warnings... Error in
>>> read.dta(fuente[i]) : not a Stata version 5-12 .dta file In addition: There
>>> were 50 or more warnings (use warnings() to see the first 50) the
>>> warnings() throws this Warning messages: 1: In `levels<-`(`*tmp*`, value =
>>> if (nl == nL) as.character(labels) else paste0(labels,  ... : duplicated
>>> levels in factors are deprecated 2: In `levels<-`(`*tmp*`, value = if (nl
>>> == nL) as.character(labels) else paste0(labels,  ... : duplicated levels in
>>> factors are deprecated 3: In `levels<-`(`*tmp*`, value = if (nl == nL)
>>> as.character(labels) else paste0(labels,  ... : duplicated levels in
>>> factors are deprecated 4: In `levels<-`(`*tmp*`, value = if (nl == nL)
>>> as.character(labels) else paste0(labels,  ... : duplicated levels in
>>> factors are deprecated 5: In `levels<-`(`*tmp*`, value = if (nl == nL)
>>> as.character(labels) else paste0(labels,  ... : duplicated levels in
>>> factors are deprecated On Mon, Aug 22, 2016 at 2:32 PM,
>>> <ruipbarradas at sapo.pt <ruipbarradas at sapo.pt>> wrote: Hello, That argument
>>> doesn't exist, hence the error. Read the help page ?read.dta more
>>> carefully. You will see that already read.dta reads into a data.frame. Hope
>>> this helps, Rui Barradas Citando Juan Ceccarelli Arias <jfca283 at gmail.com
>>> <jfca283 at gmail.com>>: Hi I need to apply some code over some stata files
>>> that are in folder. I've wrote this library(foreign)
>>> fuente=list.files("C:/Users/Jceccarelli/Bases/Stata", pattern="dta$",
>>> full.names=FALSE) for (i in 1:length(fuente)){ xxx=read.dta(fuente[i],
>>> to.data.frame=TRUE) } But i get this error Error in read.dta(fuente[i],
>>> to.data.frame = TRUE) : unused argument (to.data.frame = TRUE) What am i
>>> doing wrong?       [[alternative HTML version deleted]]
>>> ______________________________*________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.htmland provide commented, minimal, self-contained,
>>> reproducible code.
>>>
>>>
>>>
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> --
>>> Michaelhttp://www.dewey.myzen.co.uk/home.html
>>>
>>>
>>>
>>>
>>>
>>>
>>> *[[alternative HTML version deleted]] ______________________________*
>>> ________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> *David WinsemiusAlameda, CA, USA*
>>>
>>>
>>>
>>>
>>
>>
>>
>
>
>

	[[alternative HTML version deleted]]


From gangchen6 at gmail.com  Wed Aug 24 22:42:09 2016
From: gangchen6 at gmail.com (Gang Chen)
Date: Wed, 24 Aug 2016 16:42:09 -0400
Subject: [R] aggregate
In-Reply-To: <a18ea467581146e797c305424841464a@exch-2p-mbx-t2.ads.tamu.edu>
References: <CAHmzXO7tGBRevkQbcM_F31exmMtCgM-7HDW7d3VMzSFzO+HcJg@mail.gmail.com>
	<CA+8X3fXi+F2yKveAEPvFT7j=ZhYepKvxJ=297YMuAy12t=nOcA@mail.gmail.com>
	<9b3ddc5330e24fb4a6ff84188dcdfb57@exch-2p-mbx-t2.ads.tamu.edu>
	<CAHmzXO7q-4nmqgqTg2t+fiwCvnb_YgcWnBjEPNVZ0YZ-EEGqQw@mail.gmail.com>
	<69d5ea229ef440bda48442ca94bb5f2a@exch-2p-mbx-t2.ads.tamu.edu>
	<CAHmzXO4B686ri9867tXnto=JYeE0PPkUbKBXC8o+6r51piqb6w@mail.gmail.com>
	<be10e6fe20c44606bf88766002a8e05d@exch-2p-mbx-t2.ads.tamu.edu>
	<CAHmzXO5==-jp-JWeYCRumoxDFp491+TUq0LE9NqshJ8+tWvvSQ@mail.gmail.com>
	<a18ea467581146e797c305424841464a@exch-2p-mbx-t2.ads.tamu.edu>
Message-ID: <CAHmzXO7qvdkH0CxBy1P1PYWt6xeCDf6No+00UZd2cg9NHGRUig@mail.gmail.com>

Yes, this works out perfectly! Thanks a lot, David. Have a wonderful day...

On Wed, Aug 24, 2016 at 4:24 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> This will work, but you should double-check to be certain that CP and unique(myData[, 3:5]) are in the same order. It will fail if N is not identical for all rows of the same S-Z combination.
>
>> CP <- sapply(split(myData, paste0(myData$S, myData$Z)), function(x)
> +       crossprod(x[, 1], x[, 2]))
>> data.frame(CP, unique(myData[, 3:5]))
>     CP   N  S Z
> S1A 22 2.1 S1 A
> S1B 38 2.1 S1 B
> S2A 38 3.2 S2 A
> S2B 22 3.2 S2 B
>
> David C
>
> -----Original Message-----
> From: Gang Chen [mailto:gangchen6 at gmail.com]
> Sent: Wednesday, August 24, 2016 2:51 PM
> To: David L Carlson
> Cc: r-help mailing list
> Subject: Re: [R] aggregate
>
> Thanks again for patiently offering great help, David! I just learned
> dput() and paste0() now. Hopefully this is my last question.
>
> Suppose a new dataframe is as below (one more numeric column):
>
> myData <- structure(list(X = c(1, 2, 3, 4, 5, 6, 7, 8), Y = c(8, 7, 6,
> 5, 4, 3, 2, 1), N =c(rep(2.1, 4), rep(3.2, 4)), S = structure(c(1L,
> 1L, 1L, 1L, 2L, 2L, 2L, 2L
> ), .Label = c("S1", "S2"), class = "factor"), Z = structure(c(1L,
> 1L, 2L, 2L, 1L, 1L, 2L, 2L), .Label = c("A", "B"), class = "factor")),
> .Names = c("X",
> "Y", "N", "S", "Z"), row.names = c(NA, -8L), class = "data.frame")
>
>> myData
>
>   X Y   N  S Z
> 1 1 8 2.1 S1 A
> 2 2 7 2.1 S1 A
> 3 3 6 2.1 S1 B
> 4 4 5 2.1 S1 B
> 5 5 4 3.2 S2 A
> 6 6 3 3.2 S2 A
> 7 7 2 3.2 S2 B
> 8 8 1 3.2 S2 B
>
> Once I obtain the cross product,
>
>> sapply(split(myData, paste0(myData$S, myData$Z)), function(x) crossprod(x[, 1], x[, 2]))
> S1A S1B S2A S2B
>  22  38  38  22
>
> how can I easily add the other 3 columns (N, S, and Z) in a new
> dataframe? For S and Z, I can play with the names from the cross
> product output, but I have trouble dealing with the numeric column N.
>
>
>
>
> On Wed, Aug 24, 2016 at 1:07 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>> You need to spend some time with a basic R tutorial. Your data is messed up because you did not use a simple text editor somewhere along the way. R understands ', but not ? or ?. The best way to send data to the list is to use dput:
>>
>>> dput(myData)
>> structure(list(X = c(1, 2, 3, 4, 5, 6, 7, 8), Y = c(8, 7, 6,
>> 5, 4, 3, 2, 1), S = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L
>> ), .Label = c("S1", "S2"), class = "factor"), Z = structure(c(1L,
>> 1L, 2L, 2L, 1L, 1L, 2L, 2L), .Label = c("A", "B"), class = "factor")), .Names = c("X",
>> "Y", "S", "Z"), row.names = c(NA, -8L), class = "data.frame")
>>
>> Combining two labels just requires the paste0() function:
>>
>>> sapply(split(myData, paste0(myData$S, myData$Z)), function(x) crossprod(x[, 1], x[, 2]))
>> S1A S1B S2A S2B
>>  22  38  38  22
>>
>> David C
>>
>> -----Original Message-----
>> From: Gang Chen [mailto:gangchen6 at gmail.com]
>> Sent: Wednesday, August 24, 2016 11:56 AM
>> To: David L Carlson
>> Cc: Jim Lemon; r-help mailing list
>> Subject: Re: [R] aggregate
>>
>> Thanks a lot, David! I want to further expand the operation a little
>> bit. With a new dataframe:
>>
>> myData <- data.frame(X=c(1, 2, 3, 4, 5, 6, 7, 8), Y=c(8, 7, 6, 5, 4,
>> 3, 2, 1), S=c(?S1?, ?S1?, ?S1?, ?S1?, ?S2?, ?S2?, ?S2?, ?S2?),
>> Z=c(?A?, ?A?, ?B?, ?B?, ?A?, ?A?, ?B?, ?B?))
>>
>>> myData
>>
>>   X Y  S Z
>> 1 1 8 S1 A
>> 2 2 7 S1 A
>> 3 3 6 S1 B
>> 4 4 5 S1 B
>> 5 5 4 S2 A
>> 6 6 3 S2 A
>> 7 7 2 S2 B
>> 8 8 1 S2 B
>>
>> I would like to obtain the same cross product between columns X and Y,
>> but at each combination level of factors S and Z. In other words, the
>> cross product would be still performed each two rows in the new
>> dataframe myData. How can I achieve that?
>>
>> On Wed, Aug 24, 2016 at 11:54 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>>> Your is fine, but it will be a little simpler if you use sapply() instead:
>>>
>>>> data.frame(Z=levels(myData$Z), CP=sapply(split(myData, myData$Z),
>>> +     function(x) crossprod(x[, 1], x[, 2])))
>>>   Z CP
>>> A A 10
>>> B B 10
>>>
>>> David C
>>>
>>>
>>> -----Original Message-----
>>> From: Gang Chen [mailto:gangchen6 at gmail.com]
>>> Sent: Wednesday, August 24, 2016 10:17 AM
>>> To: David L Carlson
>>> Cc: Jim Lemon; r-help mailing list
>>> Subject: Re: [R] aggregate
>>>
>>> Thank you all for the suggestions! Yes, I'm looking for the cross
>>> product between the two columns of X and Y.
>>>
>>> A follow-up question: what is a nice way to merge the output of
>>>
>>> lapply(split(myData, myData$Z), function(x) crossprod(x[, 1], x[, 2]))
>>>
>>> with the column Z in myData so that I would get a new dataframe as the
>>> following (the 2nd column is the cross product between X and Y)?
>>>
>>> Z   CP
>>> A   10
>>> B   10
>>>
>>> Is the following legitimate?
>>>
>>> data.frame(Z=levels(myData$Z), CP= unlist(lapply(split(myData,
>>> myData$Z), function(x) crossprod(x[, 1], x[, 2]))))
>>>
>>>
>>> On Wed, Aug 24, 2016 at 10:37 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>>>> Thank you for the reproducible example, but it is not clear what cross product you want. Jim's solution gives you the cross product of the 2-column matrix with itself. If you want the cross product between the columns you need something else. The aggregate function will not work since it will treat the columns separately:
>>>>
>>>>> A <- as.matrix(myData[myData$Z=="A", 1:2])
>>>>> A
>>>>   X Y
>>>> 1 1 4
>>>> 2 2 3
>>>>> crossprod(A) # Same as t(A) %*% A
>>>>    X  Y
>>>> X  5 10
>>>> Y 10 25
>>>>> crossprod(A[, 1], A[, 2]) # Same as t(A[, 1] %*% A[, 2]
>>>>      [,1]
>>>> [1,]   10
>>>>>
>>>>> # For all the groups
>>>>> lapply(split(myData, myData$Z), function(x) crossprod(as.matrix(x[, 1:2])))
>>>> $A
>>>>    X  Y
>>>> X  5 10
>>>> Y 10 25
>>>>
>>>> $B
>>>>    X  Y
>>>> X 25 10
>>>> Y 10  5
>>>>
>>>>> lapply(split(myData, myData$Z), function(x) crossprod(x[, 1], x[, 2]))
>>>> $A
>>>>      [,1]
>>>> [1,]   10
>>>>
>>>> $B
>>>>      [,1]
>>>> [1,]   10
>>>>
>>>> -------------------------------------
>>>> David L Carlson
>>>> Department of Anthropology
>>>> Texas A&M University
>>>> College Station, TX 77840-4352
>>>>
>>>>
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
>>>> Sent: Tuesday, August 23, 2016 6:02 PM
>>>> To: Gang Chen; r-help mailing list
>>>> Subject: Re: [R] aggregate
>>>>
>>>> Hi Gang Chen,
>>>> If I have the right idea:
>>>>
>>>> for(zval in levels(myData$Z))
>>>> crossprod(as.matrix(myData[myData$Z==zval,c("X","Y")]))
>>>>
>>>> Jim
>>>>
>>>> On Wed, Aug 24, 2016 at 8:03 AM, Gang Chen <gangchen6 at gmail.com> wrote:
>>>>> This is a simple question: With a dataframe like the following
>>>>>
>>>>> myData <- data.frame(X=c(1, 2, 3, 4), Y=c(4, 3, 2, 1), Z=c('A', 'A', 'B', 'B'))
>>>>>
>>>>> how can I get the cross product between X and Y for each level of
>>>>> factor Z? My difficulty is that I don't know how to deal with the fact
>>>>> that crossprod() acts on two variables in this case.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From jsorkin at grecc.umaryland.edu  Thu Aug 25 00:00:17 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Wed, 24 Aug 2016 18:00:17 -0400
Subject: [R] function that converts data into a form that can be included in
 a question to mailing list
Message-ID: <57BDE0B1020000CB0015E9E0@smtp.medicine.umaryland.edu>


There is a function that can be used to convert data structures such as a data frame into a different format that allows the data to be sent to the mailing list. The structure that is created can be used to easily reconstruct the data structure. Unfortunately, I don't remember the function that is called on the data structure. Can someone remind me?
Thank you
John
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From jsorkin at grecc.umaryland.edu  Thu Aug 25 00:12:14 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Wed, 24 Aug 2016 18:12:14 -0400
Subject: [R] function that converts data into a form that can be
 included in a question to mailing list
In-Reply-To: <CA+8X3fXrt1Dfcm1OSMXDtVj=NfvjaK3e7=ci6Pq5Tc+2eBTu8Q@mail.gmail.com>
References: <57BDE0B1020000CB0015E9E0@smtp.medicine.umaryland.edu>
	<CA+8X3fXrt1Dfcm1OSMXDtVj=NfvjaK3e7=ci6Pq5Tc+2eBTu8Q@mail.gmail.com>
Message-ID: <57BDE37E020000CB0015E9E5@smtp.medicine.umaryland.edu>

Jim,
Yes, you are correct!
Give yourself a pat on the back and a gold start
THANK YOU,
John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> Jim Lemon <drjimlemon at gmail.com> 08/24/16 6:05 PM >>>
Hi John,
I think it is "dput".

Jim


On Thu, Aug 25, 2016 at 8:00 AM, John Sorkin
<jsorkin at grecc.umaryland.edu> wrote:
>
> There is a function that can be used to convert data structures such as a data frame into a different format that allows the data to be sent to the mailing list. The structure that is created can be used to easily reconstruct the data structure. Unfortunately, I don't remember the function that is called on the data structure. Can someone remind me?
> Thank you
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From bgunter.4567 at gmail.com  Thu Aug 25 00:17:29 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 24 Aug 2016 15:17:29 -0700
Subject: [R] function that converts data into a form that can be
 included in a question to mailing list
In-Reply-To: <57BDE0B1020000CB0015E9E0@smtp.medicine.umaryland.edu>
References: <57BDE0B1020000CB0015E9E0@smtp.medicine.umaryland.edu>
Message-ID: <CAGxFJbRUjKF9XY0ZoXGR3pKiTB84wz-nBjS5xnZVTXzEU9N3ag@mail.gmail.com>

?dput


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 24, 2016 at 3:00 PM, John Sorkin
<jsorkin at grecc.umaryland.edu> wrote:
>
> There is a function that can be used to convert data structures such as a data frame into a different format that allows the data to be sent to the mailing list. The structure that is created can be used to easily reconstruct the data structure. Unfortunately, I don't remember the function that is called on the data structure. Can someone remind me?
> Thank you
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:12}}


From dwinsemius at comcast.net  Thu Aug 25 00:11:01 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 24 Aug 2016 15:11:01 -0700
Subject: [R] function that converts data into a form that can be
	included in a question to mailing list
In-Reply-To: <57BDE0B1020000CB0015E9E0@smtp.medicine.umaryland.edu>
References: <57BDE0B1020000CB0015E9E0@smtp.medicine.umaryland.edu>
Message-ID: <90497D33-6045-43B4-9223-AB1B6B70A014@comcast.net>


> On Aug 24, 2016, at 3:00 PM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> 
> 
> There is a function that can be used to convert data structures such as a data frame into a different format that allows the data to be sent to the mailing list. The structure that is created can be used to easily reconstruct the data structure. Unfortunately, I don't remember the function that is called on the data structure. Can someone remind me?

ITYM dput()

-- 
David

> Thank you
> John
> John David Sorkin M.D., Ph.D.
> 


David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Thu Aug 25 00:04:52 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 25 Aug 2016 08:04:52 +1000
Subject: [R] function that converts data into a form that can be
 included in a question to mailing list
In-Reply-To: <57BDE0B1020000CB0015E9E0@smtp.medicine.umaryland.edu>
References: <57BDE0B1020000CB0015E9E0@smtp.medicine.umaryland.edu>
Message-ID: <CA+8X3fXrt1Dfcm1OSMXDtVj=NfvjaK3e7=ci6Pq5Tc+2eBTu8Q@mail.gmail.com>

Hi John,
I think it is "dput".

Jim


On Thu, Aug 25, 2016 at 8:00 AM, John Sorkin
<jsorkin at grecc.umaryland.edu> wrote:
>
> There is a function that can be used to convert data structures such as a data frame into a different format that allows the data to be sent to the mailing list. The structure that is created can be used to easily reconstruct the data structure. Unfortunately, I don't remember the function that is called on the data structure. Can someone remind me?
> Thank you
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:12}}


From jsorkin at grecc.umaryland.edu  Thu Aug 25 00:33:33 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Wed, 24 Aug 2016 18:33:33 -0400
Subject: [R] function that converts data into a form that can be
 included in a question to mailing list
In-Reply-To: <57BDE0B1020000CB0015E9E0@smtp.medicine.umaryland.edu>
References: <57BDE0B1020000CB0015E9E0@smtp.medicine.umaryland.edu>
Message-ID: <57BDE87D020000CB0015E9FD@smtp.medicine.umaryland.edu>

I am trying to run a repeated measures analysis of data in which each subject (identified by SS) has 3 observations at three different times (0, 3, and 6). There are two groups of subjects (identified by group). I want to know if the response differs in the two groups. I have tried to used lme. Lme tell me if there is a time effect, but does not tell me if there is a group effect. Once I get this to work I will want to know if there is a significant group*time effect. Can someone tell me how to get an estimate for group. Once I get that, I believe getting an estimate for group*time should be straight forward. The code I have tired to use follows.
Thank you,
John
 
> data1
   SS group time     value  baseline
1   1  Cont    0  6.000000  6.000000
2   2  Cont    0  3.000000  3.000000
3   3  Cont    0  5.000000  5.000000
4   4  Inte    0 14.132312 14.132312
5   5  Inte    0  8.868808  8.868808
6   6  Inte    0 14.602672 14.602672
7   1  Cont    3 10.706805  6.000000
8   2  Cont    3  8.469477  3.000000
9   3  Cont    3  9.337411  5.000000
10  4  Inte    3 16.941940 14.132312
11  5  Inte    3 13.872662  8.868808
12  6  Inte    3 20.465614 14.602672
13  1  Cont    6 16.687028  6.000000
14  2  Cont    6 13.177752  3.000000
15  3  Cont    6 14.276398  5.000000
16  4  Inte    6 23.453808 14.132312
17  5  Inte    6 18.229053  8.868808
18  6  Inte    6 25.334664 14.602672
> # Create a grouped data object. SS identifies each subject
> # group indentifies group, intervention or control.
> GD<- groupedData(value~time|SS/group,data=data1,FUN=mean)
> # Fit the model.
> fit1 <- lme(GD)
> cat("The results give information about time, but does not say if the gruops are different\n")
The results give information about time, but does not say if the gruops are different
> summary(fit1)
Linear mixed-effects model fit by REML
 Data: GD 
       AIC      BIC    logLik
  81.38094 88.33424 -31.69047

Random effects:
 Formula: ~time | SS
 Structure: General positive-definite
            StdDev      Corr  
(Intercept) 3.371776404 (Intr)
time        0.009246535 1     

 Formula: ~time | group %in% SS
 Structure: General positive-definite
            StdDev     Corr  
(Intercept) 3.34070367 (Intr)
time        0.00915754 1     
Residual    0.61279061       

Fixed effects: value ~ time 
               Value Std.Error DF   t-value p-value
(Intercept) 8.512446 1.9511580 11  4.362766  0.0011
time        1.654303 0.0592047 11 27.942107  0.0000
 Correlation: 
     (Intr)
time -0.001

Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max 
-1.9691671 -0.4876710  0.1559464  0.4637269  1.6069444 

Number of Observations: 18
Number of Groups: 
           SS group %in% SS 
            6             6 

 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From jsorkin at grecc.umaryland.edu  Thu Aug 25 00:46:45 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Wed, 24 Aug 2016 18:46:45 -0400
Subject: [R] lme to determine if there is a group effect
References: 57BDE0D8.medlxdom.medlxpo.200.20000FC.1.115E81.1
Message-ID: <57BDEB95020000CB0015EA0F@smtp.medicine.umaryland.edu>

I apologize for sending this message again. The last time I sent it, the subject line was not correct. I have corrected the subject line.
 
I am trying to run a repeated measures analysis of data in which each subject (identified by SS) has 3 observations at three different times (0, 3, and 6). There are two groups of subjects (identified by group). I want to know if the response differs in the two groups. I have tried to used lme. Lme tell me if there is a time effect, but does not tell me if there is a group effect. Once I get this to work I will want to know if there is a significant group*time effect. Can someone tell me how to get an estimate for group. Once I get that, I believe getting an estimate for group*time should be straight forward. The code I have tired to use follows.
Thank you,
John
 
> # This is my data
> data1
   SS group time     value baseline
1   1  Cont    0  9.000000 9.000000
2   2  Cont    0  3.000000 3.000000
3   3  Cont    0  8.000000 8.000000
4   4  Inte    0  5.690702 5.690702
5   5  Inte    0  7.409493 7.409493
6   6  Inte    0  7.428018 7.428018
7   1  Cont    3 13.713148 9.000000
8   2  Cont    3  9.841107 3.000000
9   3  Cont    3 12.843236 8.000000
10  4  Inte    3  9.300899 5.690702
11  5  Inte    3 10.936389 7.409493
12  6  Inte    3 12.358499 7.428018
13  1  Cont    6 18.952390 9.000000
14  2  Cont    6 15.091527 3.000000
15  3  Cont    6 17.578812 8.000000
16  4  Inte    6 12.325499 5.690702
17  5  Inte    6 15.486513 7.409493
18  6  Inte    6 18.284965 7.428018
> # Create a grouped data object. SS identifies each subject
> # group indentifies group, intervention or control.
> GD<- groupedData(value~time|SS/group,data=data1,FUN=mean)
> # Fit the model.
> fit1 <- lme(GD)
> cat("The results give information about time, but does not say if the gruops are different\n")
The results give information about time, but does not say if the gruops are different
> summary(fit1)
Linear mixed-effects model fit by REML
 Data: GD 
       AIC      BIC    logLik
  74.59447 81.54777 -28.29724

Random effects:
 Formula: ~time | SS
 Structure: General positive-definite
            StdDev    Corr  
(Intercept) 1.3875111 (Intr)
time        0.2208046 -0.243

 Formula: ~time | group %in% SS
 Structure: General positive-definite
            StdDev    Corr  
(Intercept) 1.3875115 (Intr)
time        0.2208051 -0.243
Residual    0.3800788       

Fixed effects: value ~ time 
               Value Std.Error DF   t-value p-value
(Intercept) 6.747442 0.8135067 11  8.294268       0
time        1.588653 0.1326242 11 11.978601       0
 Correlation: 
     (Intr)
time -0.268

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-1.11412947 -0.44986535  0.08034174  0.34615610  1.29943887 

Number of Observations: 18
Number of Groups: 
           SS group %in% SS 
            6             6 



> 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From wdunlap at tibco.com  Thu Aug 25 01:06:43 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 24 Aug 2016 16:06:43 -0700
Subject: [R] function that converts data into a form that can be
 included in a question to mailing list
In-Reply-To: <57BDE37E020000CB0015E9E5@smtp.medicine.umaryland.edu>
References: <57BDE0B1020000CB0015E9E0@smtp.medicine.umaryland.edu>
	<CA+8X3fXrt1Dfcm1OSMXDtVj=NfvjaK3e7=ci6Pq5Tc+2eBTu8Q@mail.gmail.com>
	<57BDE37E020000CB0015E9E5@smtp.medicine.umaryland.edu>
Message-ID: <CAF8bMcYf-wrboEuH7mQv7LDWoPp=Arv=NU9N79zeRgqBZu8J_w@mail.gmail.com>

dump("yourObject", file=stdout()) is, IMO, a bit nicer than plain
dput(yourObject).  It makes copying and pasting even easier by putting
"yourObject <-" in front of dput()'s output so readers don't have to type
that themselves.

E.g.,
> myData <- data.frame(X=1:2, Y=c(exp(1), pi))
> dump("myData", file=stdout())
myData <-
structure(list(X = 1:2, Y = c(2.71828182845905, 3.14159265358979
)), .Names = c("X", "Y"), row.names = c(NA, -2L), class = "data.frame")
> dput(myData)
structure(list(X = 1:2, Y = c(2.71828182845905, 3.14159265358979
)), .Names = c("X", "Y"), row.names = c(NA, -2L), class = "data.frame")




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Aug 24, 2016 at 3:12 PM, John Sorkin <jsorkin at grecc.umaryland.edu>
wrote:

> Jim,
> Yes, you are correct!
> Give yourself a pat on the back and a gold start
> THANK YOU,
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> >>> Jim Lemon <drjimlemon at gmail.com> 08/24/16 6:05 PM >>>
> Hi John,
> I think it is "dput".
>
> Jim
>
>
> On Thu, Aug 25, 2016 at 8:00 AM, John Sorkin
> <jsorkin at grecc.umaryland.edu> wrote:
> >
> > There is a function that can be used to convert data structures such as
> a data frame into a different format that allows the data to be sent to the
> mailing list. The structure that is created can be used to easily
> reconstruct the data structure. Unfortunately, I don't remember the
> function that is called on the data structure. Can someone remind me?
> > Thank you
> > John
> > John David Sorkin M.D., Ph.D.
> > Professor of Medicine
> > Chief, Biostatistics and Informatics
> > University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> > Baltimore VA Medical Center
> > 10 North Greene Street
> > GRECC (BT/18/GR)
> > Baltimore, MD 21201-1524
> > (Phone) 410-605-7119
> > (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> >
> > Confidentiality Statement:
> > This email message, including any attachments, is for the sole use of
> the intended recipient(s) and may contain confidential and privileged
> information. Any unauthorized use, disclosure or distribution is
> prohibited. If you are not the intended recipient, please contact the
> sender by reply email and destroy all copies of the original message.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:16}}


From bgunter.4567 at gmail.com  Thu Aug 25 02:23:45 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 24 Aug 2016 17:23:45 -0700
Subject: [R] lme to determine if there is a group effect
In-Reply-To: <57BDEB95020000CB0015EA0F@smtp.medicine.umaryland.edu>
References: <57BDEB95020000CB0015EA0F@smtp.medicine.umaryland.edu>
Message-ID: <CAGxFJbTcM-tQO0ixyKYZO1=XNNyKo2mnyLEvA8Nb4n=pB_FTQw@mail.gmail.com>

I never used the groupedData structure, precisely because I found it
confusing, but I think:

1. group is *not* a (random) grouping variable; it's a fixed effect covariate.
2. so I believe your groupedData call should be:

GD<- groupedData(value~time|SS,data=data1,outer = group)

Of course, as you did not give us your data in a convenient form, I
can't check. Please let us know if this is wrong, however, as I don't
want to mislead others down the primrose path.


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 24, 2016 at 3:46 PM, John Sorkin
<jsorkin at grecc.umaryland.edu> wrote:
> I apologize for sending this message again. The last time I sent it, the subject line was not correct. I have corrected the subject line.
>
> I am trying to run a repeated measures analysis of data in which each subject (identified by SS) has 3 observations at three different times (0, 3, and 6). There are two groups of subjects (identified by group). I want to know if the response differs in the two groups. I have tried to used lme. Lme tell me if there is a time effect, but does not tell me if there is a group effect. Once I get this to work I will want to know if there is a significant group*time effect. Can someone tell me how to get an estimate for group. Once I get that, I believe getting an estimate for group*time should be straight forward. The code I have tired to use follows.
> Thank you,
> John
>
>> # This is my data
>> data1
>    SS group time     value baseline
> 1   1  Cont    0  9.000000 9.000000
> 2   2  Cont    0  3.000000 3.000000
> 3   3  Cont    0  8.000000 8.000000
> 4   4  Inte    0  5.690702 5.690702
> 5   5  Inte    0  7.409493 7.409493
> 6   6  Inte    0  7.428018 7.428018
> 7   1  Cont    3 13.713148 9.000000
> 8   2  Cont    3  9.841107 3.000000
> 9   3  Cont    3 12.843236 8.000000
> 10  4  Inte    3  9.300899 5.690702
> 11  5  Inte    3 10.936389 7.409493
> 12  6  Inte    3 12.358499 7.428018
> 13  1  Cont    6 18.952390 9.000000
> 14  2  Cont    6 15.091527 3.000000
> 15  3  Cont    6 17.578812 8.000000
> 16  4  Inte    6 12.325499 5.690702
> 17  5  Inte    6 15.486513 7.409493
> 18  6  Inte    6 18.284965 7.428018
>> # Create a grouped data object. SS identifies each subject
>> # group indentifies group, intervention or control.
>> GD<- groupedData(value~time|SS/group,data=data1,FUN=mean)
>> # Fit the model.
>> fit1 <- lme(GD)
>> cat("The results give information about time, but does not say if the gruops are different\n")
> The results give information about time, but does not say if the gruops are different
>> summary(fit1)
> Linear mixed-effects model fit by REML
>  Data: GD
>        AIC      BIC    logLik
>   74.59447 81.54777 -28.29724
>
> Random effects:
>  Formula: ~time | SS
>  Structure: General positive-definite
>             StdDev    Corr
> (Intercept) 1.3875111 (Intr)
> time        0.2208046 -0.243
>
>  Formula: ~time | group %in% SS
>  Structure: General positive-definite
>             StdDev    Corr
> (Intercept) 1.3875115 (Intr)
> time        0.2208051 -0.243
> Residual    0.3800788
>
> Fixed effects: value ~ time
>                Value Std.Error DF   t-value p-value
> (Intercept) 6.747442 0.8135067 11  8.294268       0
> time        1.588653 0.1326242 11 11.978601       0
>  Correlation:
>      (Intr)
> time -0.268
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -1.11412947 -0.44986535  0.08034174  0.34615610  1.29943887
>
> Number of Observations: 18
> Number of Groups:
>            SS group %in% SS
>             6             6
>
>
>
>>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:12}}


From qszhang at uw.edu  Thu Aug 25 02:34:20 2016
From: qszhang at uw.edu (Qian Sophia Zhang)
Date: Wed, 24 Aug 2016 17:34:20 -0700
Subject: [R] How do you capture warning messages from rstan package's stan()
	function,
	when running an R script that calls stan() on the command line?
Message-ID: <B78B184D-6E6D-46B8-8D4F-4C3E06DF894E@uw.edu>

Hi R people,

I have an R script Fit12_for_stack.R that calls rstan?s stan(). When I run the code in an interactive R session, I see warning messages from stan() about divergent transitions, but when I run the code on the command line with ?Rscript Fit12_for_stack.R?, I don?t see stan() warning messages. How can I run the code on the command line and still see stan() warning messages?

>From the post How to save all console output to file in R? <http://stackoverflow.com/questions/7096989/how-to-save-all-console-output-to-file-in-r>, I tried adding

con <- file("test.log")
sink(con, append=TRUE)
sink(con, append=TRUE, type="message")
to the top of Fit12_for_stack.R, but test.log again showed output, without stan() warning messages.

Fit12_for_stack.R and a file it uses, try8.stan, are attached.

Thanks,
Qian

P.S. If you prefer responding via StackExchange, I also posted there: http://stackoverflow.com/questions/39134667/how-can-i-capture-warning-messages-from-rstan-r-packages-stan-function-when <http://stackoverflow.com/questions/39134667/how-can-i-capture-warning-messages-from-rstan-r-packages-stan-function-when>.



From _ at thomaslevine.com  Thu Aug 25 04:16:51 2016
From: _ at thomaslevine.com (Thomas Levine)
Date: Thu, 25 Aug 2016 02:16:51 +0000
Subject: [R] Rotating points, preferably in grid
Message-ID: <20160825021651.9C176F29D1@mailuser.nyi.internal>

I want to make a plot in polar coordinates. I want to use pch with
shapes that do not have radial symmetry, so I want to rotate them such
that they face inwards. I am using grid for my plotting, but I provide
motivating examples in graphics.

The following plot almost gets me what I want.

  theta <- 2*pi*seq(0,7/8,1/8)
  plot(cos(theta), sin(theta), pch=2, axes=F, asp=1)

But I want the points to face inwards. I can do something like this with
text, but I can set only a constant rotation

  plot.new()
  plot.window(c(-1,1),c(-1,1), asp=1)
  text(cos(theta), sin(theta), 'Tom', srt
 =runif(1,0,360))

To rotate all of the points, I can do something like this.

  plot.new()
  plot.window(c(-1,1),c(-1,1), asp=1)
  for (the.theta in theta)
    text(cos(the.theta), sin(the.theta), 'Tom',
         srt=(360/(2*pi))*(the.theta-(1/4)*2*pi))

So perhaps I could use a "T" instead of a numeric pch and consequently
do something like this.

  plot.new()
  plot.window(c(-1,1),c(-1,1), asp=1)
  for (the.theta in theta)
    text(cos(the.theta), sin(the.theta), 'T',
         srt=(360/(2*pi))*(the.theta+(1/4)*2*pi))

But that seems a bit silly.

Is there a more declarative way of doing this, preferably in grid?

Thanks


From ddalthorp at usgs.gov  Thu Aug 25 04:52:44 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Wed, 24 Aug 2016 19:52:44 -0700
Subject: [R] Rotating points, preferably in grid
In-Reply-To: <20160825021651.9C176F29D1@mailuser.nyi.internal>
References: <20160825021651.9C176F29D1@mailuser.nyi.internal>
Message-ID: <CAJeYpE9NaYkFY4cs=apWBXuDiFdmHfk-vnH3TgT2sO3s2vvh4Q@mail.gmail.com>

Silly? Not really.

It's simple. It works.

You could jump into unicode for your text and make it look nicer, e.g.,
using '\u2191' or some other shape in place of 'T'

http://unicode.org/charts/
http://unicode.org/charts/PDF/U2190.pdf

-Dan

On Wed, Aug 24, 2016 at 7:16 PM, Thomas Levine <_ at thomaslevine.com> wrote:

> I want to make a plot in polar coordinates. I want to use pch with
> shapes that do not have radial symmetry, so I want to rotate them such
> that they face inwards. I am using grid for my plotting, but I provide
> motivating examples in graphics.
>
> The following plot almost gets me what I want.
>
>   theta <- 2*pi*seq(0,7/8,1/8)
>   plot(cos(theta), sin(theta), pch=2, axes=F, asp=1)
>
> But I want the points to face inwards. I can do something like this with
> text, but I can set only a constant rotation
>
>   plot.new()
>   plot.window(c(-1,1),c(-1,1), asp=1)
>   text(cos(theta), sin(theta), 'Tom', srt
>  =runif(1,0,360))
>
> To rotate all of the points, I can do something like this.
>
>   plot.new()
>   plot.window(c(-1,1),c(-1,1), asp=1)
>   for (the.theta in theta)
>     text(cos(the.theta), sin(the.theta), 'Tom',
>          srt=(360/(2*pi))*(the.theta-(1/4)*2*pi))
>
> So perhaps I could use a "T" instead of a numeric pch and consequently
> do something like this.
>
>   plot.new()
>   plot.window(c(-1,1),c(-1,1), asp=1)
>   for (the.theta in theta)
>     text(cos(the.theta), sin(the.theta), 'T',
>          srt=(360/(2*pi))*(the.theta+(1/4)*2*pi))
>
> But that seems a bit silly.
>
> Is there a more declarative way of doing this, preferably in grid?
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From pnsinha68 at gmail.com  Thu Aug 25 05:01:41 2016
From: pnsinha68 at gmail.com (Partha Sinha)
Date: Thu, 25 Aug 2016 08:31:41 +0530
Subject: [R] library Dplyr
In-Reply-To: <4A3A4F44-FAD4-4B74-ADF5-D8E3BF595A02@dcn.davis.ca.us>
References: <CADcgpJe11k30Pm_fATaQa4aej0-=sGqCGugcuT4mq5-Ch0hWzQ@mail.gmail.com>
	<4A3A4F44-FAD4-4B74-ADF5-D8E3BF595A02@dcn.davis.ca.us>
Message-ID: <CADcgpJcuZzOYcQuSbwh_-o1c3iL87aMLMY-etuDBV5VKBhzicg@mail.gmail.com>

i have used sessioninfo()
the output I have got
R version 3.3.1 (2016-06-21)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows 7 (build 7600)

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C

[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


I tried to load ggplot2 and dplyr.
both giving me similar problems

Parth

On 24 August 2016 at 20:40, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> This is not normal. I suggest making use of the maintainer() and
> sessionInfo() functions.
> --
> Sent from my phone. Please excuse my brevity.
>
> On August 24, 2016 7:47:25 AM PDT, Partha Sinha <pnsinha68 at gmail.com>
> wrote:
> >I am using windows 7 , R version 3.3.1
> >whenever I am trying use
> >library(dplyr)
> >i am getting the follwing error:
> >
> >Error in get(Info[i, 1], envir = env) :
> >  cannot allocate memory block of size 2.5 Gb
> >Error: package or namespace load failed for ?dplyr?
> >
> >
> >pl help
> >
> >Regards
> >Partha
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From paul at stat.auckland.ac.nz  Thu Aug 25 05:33:11 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Thu, 25 Aug 2016 15:33:11 +1200
Subject: [R] [FORGED]  Rotating points, preferably in grid
In-Reply-To: <20160825021651.9C176F29D1@mailuser.nyi.internal>
References: <20160825021651.9C176F29D1@mailuser.nyi.internal>
Message-ID: <be62498c-b1e5-0932-70c7-e4ed00633356@stat.auckland.ac.nz>

Hi

Do you mean something like this ... ?

library(grid)
grid.newpage()
pushViewport(viewport(xscale=c(-2,2), yscale=c(-2,2)))
grid.text('T', cos(theta), sin(theta), default.units="native",
           rot=(360/(2*pi))*(theta+(1/4)*2*pi))

Paul

On 25/08/16 14:16, Thomas Levine wrote:
> I want to make a plot in polar coordinates. I want to use pch with
> shapes that do not have radial symmetry, so I want to rotate them such
> that they face inwards. I am using grid for my plotting, but I provide
> motivating examples in graphics.
>
> The following plot almost gets me what I want.
>
>   theta <- 2*pi*seq(0,7/8,1/8)
>   plot(cos(theta), sin(theta), pch=2, axes=F, asp=1)
>
> But I want the points to face inwards. I can do something like this with
> text, but I can set only a constant rotation
>
>   plot.new()
>   plot.window(c(-1,1),c(-1,1), asp=1)
>   text(cos(theta), sin(theta), 'Tom', srt
>  =runif(1,0,360))
>
> To rotate all of the points, I can do something like this.
>
>   plot.new()
>   plot.window(c(-1,1),c(-1,1), asp=1)
>   for (the.theta in theta)
>     text(cos(the.theta), sin(the.theta), 'Tom',
>          srt=(360/(2*pi))*(the.theta-(1/4)*2*pi))
>
> So perhaps I could use a "T" instead of a numeric pch and consequently
> do something like this.
>
>   plot.new()
>   plot.window(c(-1,1),c(-1,1), asp=1)
>   for (the.theta in theta)
>     text(cos(the.theta), sin(the.theta), 'T',
>          srt=(360/(2*pi))*(the.theta+(1/4)*2*pi))
>
> But that seems a bit silly.
>
> Is there a more declarative way of doing this, preferably in grid?
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From jdnewmil at dcn.davis.ca.us  Thu Aug 25 06:04:38 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 24 Aug 2016 21:04:38 -0700
Subject: [R] library Dplyr
In-Reply-To: <CADcgpJcuZzOYcQuSbwh_-o1c3iL87aMLMY-etuDBV5VKBhzicg@mail.gmail.com>
References: <CADcgpJe11k30Pm_fATaQa4aej0-=sGqCGugcuT4mq5-Ch0hWzQ@mail.gmail.com>
	<4A3A4F44-FAD4-4B74-ADF5-D8E3BF595A02@dcn.davis.ca.us>
	<CADcgpJcuZzOYcQuSbwh_-o1c3iL87aMLMY-etuDBV5VKBhzicg@mail.gmail.com>
Message-ID: <D6EEFA5A-B468-408E-8C23-5B374031C01F@dcn.davis.ca.us>

And the only input you give to trigger this is

library(dplyr)

?
-- 
Sent from my phone. Please excuse my brevity.

On August 24, 2016 8:01:41 PM PDT, Partha Sinha <pnsinha68 at gmail.com> wrote:
>i have used sessioninfo()
>the output I have got
>R version 3.3.1 (2016-06-21)
>Platform: i386-w64-mingw32/i386 (32-bit)
>Running under: Windows 7 (build 7600)
>
>locale:
>[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
>Kingdom.1252
>[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
>
>[5] LC_TIME=English_United Kingdom.1252
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base
>
>
>I tried to load ggplot2 and dplyr.
>both giving me similar problems
>
>Parth
>
>On 24 August 2016 at 20:40, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> This is not normal. I suggest making use of the maintainer() and
>> sessionInfo() functions.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On August 24, 2016 7:47:25 AM PDT, Partha Sinha <pnsinha68 at gmail.com>
>> wrote:
>> >I am using windows 7 , R version 3.3.1
>> >whenever I am trying use
>> >library(dplyr)
>> >i am getting the follwing error:
>> >
>> >Error in get(Info[i, 1], envir = env) :
>> >  cannot allocate memory block of size 2.5 Gb
>> >Error: package or namespace load failed for ?dplyr?
>> >
>> >
>> >pl help
>> >
>> >Regards
>> >Partha
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From _ at thomaslevine.com  Thu Aug 25 06:34:14 2016
From: _ at thomaslevine.com (Thomas Levine)
Date: Thu, 25 Aug 2016 04:34:14 +0000
Subject: [R] [FORGED]  Rotating points, preferably in grid
In-Reply-To: <be62498c-b1e5-0932-70c7-e4ed00633356@stat.auckland.ac.nz>
References: <20160825021651.9C176F29D1@mailuser.nyi.internal>
	<be62498c-b1e5-0932-70c7-e4ed00633356@stat.auckland.ac.nz>
	<CAJeYpE9NaYkFY4cs=apWBXuDiFdmHfk-vnH3TgT2sO3s2vvh4Q@mail.gmail.com>
Message-ID: <20160825043415.494D3F29D2@mailuser.nyi.internal>

Well this is great. Now I have answers for both graphics and grid.

The rot argument is exactly what I had wanted, except that I had
imagined it also working on points. But I had not thought to use
unicode, and that will probably make this plot even easier.

Thanks


From pnsinha68 at gmail.com  Thu Aug 25 07:08:09 2016
From: pnsinha68 at gmail.com (Partha Sinha)
Date: Thu, 25 Aug 2016 10:38:09 +0530
Subject: [R] library Dplyr
In-Reply-To: <D6EEFA5A-B468-408E-8C23-5B374031C01F@dcn.davis.ca.us>
References: <CADcgpJe11k30Pm_fATaQa4aej0-=sGqCGugcuT4mq5-Ch0hWzQ@mail.gmail.com>
	<4A3A4F44-FAD4-4B74-ADF5-D8E3BF595A02@dcn.davis.ca.us>
	<CADcgpJcuZzOYcQuSbwh_-o1c3iL87aMLMY-etuDBV5VKBhzicg@mail.gmail.com>
	<D6EEFA5A-B468-408E-8C23-5B374031C01F@dcn.davis.ca.us>
Message-ID: <CADcgpJdc9bspYz83a73EirdGAjX=jp8YRneQUk7+OwvrTRf6xQ@mail.gmail.com>

yes. I start a fresh session and start to load the library


On 25 August 2016 at 09:34, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> And the only input you give to trigger this is
>
> library(dplyr)
>
> ?
> --
> Sent from my phone. Please excuse my brevity.
>
> On August 24, 2016 8:01:41 PM PDT, Partha Sinha <pnsinha68 at gmail.com>
> wrote:
> >i have used sessioninfo()
> >the output I have got
> >R version 3.3.1 (2016-06-21)
> >Platform: i386-w64-mingw32/i386 (32-bit)
> >Running under: Windows 7 (build 7600)
> >
> >locale:
> >[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
> >Kingdom.1252
> >[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
> >
> >[5] LC_TIME=English_United Kingdom.1252
> >
> >attached base packages:
> >[1] stats     graphics  grDevices utils     datasets  methods   base
> >
> >
> >I tried to load ggplot2 and dplyr.
> >both giving me similar problems
> >
> >Parth
> >
> >On 24 August 2016 at 20:40, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> This is not normal. I suggest making use of the maintainer() and
> >> sessionInfo() functions.
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On August 24, 2016 7:47:25 AM PDT, Partha Sinha <pnsinha68 at gmail.com>
> >> wrote:
> >> >I am using windows 7 , R version 3.3.1
> >> >whenever I am trying use
> >> >library(dplyr)
> >> >i am getting the follwing error:
> >> >
> >> >Error in get(Info[i, 1], envir = env) :
> >> >  cannot allocate memory block of size 2.5 Gb
> >> >Error: package or namespace load failed for ?dplyr?
> >> >
> >> >
> >> >pl help
> >> >
> >> >Regards
> >> >Partha
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Aug 25 08:24:44 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 24 Aug 2016 23:24:44 -0700
Subject: [R] library Dplyr
In-Reply-To: <CADcgpJdc9bspYz83a73EirdGAjX=jp8YRneQUk7+OwvrTRf6xQ@mail.gmail.com>
References: <CADcgpJe11k30Pm_fATaQa4aej0-=sGqCGugcuT4mq5-Ch0hWzQ@mail.gmail.com>
	<4A3A4F44-FAD4-4B74-ADF5-D8E3BF595A02@dcn.davis.ca.us>
	<CADcgpJcuZzOYcQuSbwh_-o1c3iL87aMLMY-etuDBV5VKBhzicg@mail.gmail.com>
	<D6EEFA5A-B468-408E-8C23-5B374031C01F@dcn.davis.ca.us>
	<CADcgpJdc9bspYz83a73EirdGAjX=jp8YRneQUk7+OwvrTRf6xQ@mail.gmail.com>
Message-ID: <F45BE837-BD1D-4C09-919F-C8165473DE38@dcn.davis.ca.us>

I can not reproduce that using a fresh install of R 3.3.1 Win32 and dplyr 0.5.0. I suggest that you re-install dplyr or R or both... perhaps from a different mirror than the one you originally used. Do not use "Run As Administrator" and say yes to creating a personal library. Install dplyr with install.packages( "dplyr" ).

If you continue to have trouble and want help then you are going to have to make an effort to convey a reproducible set of steps to arrive at your error. The Posting Guide has good advice on how to communicate on the R mailing lists.

-- 
Sent from my phone. Please excuse my brevity.

On August 24, 2016 10:08:09 PM PDT, Partha Sinha <pnsinha68 at gmail.com> wrote:
>yes. I start a fresh session and start to load the library
>
>
>On 25 August 2016 at 09:34, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> And the only input you give to trigger this is
>>
>> library(dplyr)
>>
>> ?
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On August 24, 2016 8:01:41 PM PDT, Partha Sinha <pnsinha68 at gmail.com>
>> wrote:
>> >i have used sessioninfo()
>> >the output I have got
>> >R version 3.3.1 (2016-06-21)
>> >Platform: i386-w64-mingw32/i386 (32-bit)
>> >Running under: Windows 7 (build 7600)
>> >
>> >locale:
>> >[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
>> >Kingdom.1252
>> >[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
>> >
>> >[5] LC_TIME=English_United Kingdom.1252
>> >
>> >attached base packages:
>> >[1] stats     graphics  grDevices utils     datasets  methods   base
>> >
>> >
>> >I tried to load ggplot2 and dplyr.
>> >both giving me similar problems
>> >
>> >Parth
>> >
>> >On 24 August 2016 at 20:40, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>> >wrote:
>> >
>> >> This is not normal. I suggest making use of the maintainer() and
>> >> sessionInfo() functions.
>> >> --
>> >> Sent from my phone. Please excuse my brevity.
>> >>
>> >> On August 24, 2016 7:47:25 AM PDT, Partha Sinha
><pnsinha68 at gmail.com>
>> >> wrote:
>> >> >I am using windows 7 , R version 3.3.1
>> >> >whenever I am trying use
>> >> >library(dplyr)
>> >> >i am getting the follwing error:
>> >> >
>> >> >Error in get(Info[i, 1], envir = env) :
>> >> >  cannot allocate memory block of size 2.5 Gb
>> >> >Error: package or namespace load failed for ?dplyr?
>> >> >
>> >> >
>> >> >pl help
>> >> >
>> >> >Regards
>> >> >Partha
>> >> >
>> >> >       [[alternative HTML version deleted]]
>> >> >
>> >> >______________________________________________
>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >PLEASE do read the posting guide
>> >> >http://www.R-project.org/posting-guide.html
>> >> >and provide commented, minimal, self-contained, reproducible
>code.
>> >>
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pnsinha68 at gmail.com  Thu Aug 25 08:30:52 2016
From: pnsinha68 at gmail.com (Partha Sinha)
Date: Thu, 25 Aug 2016 12:00:52 +0530
Subject: [R] library Dplyr
In-Reply-To: <F45BE837-BD1D-4C09-919F-C8165473DE38@dcn.davis.ca.us>
References: <CADcgpJe11k30Pm_fATaQa4aej0-=sGqCGugcuT4mq5-Ch0hWzQ@mail.gmail.com>
	<4A3A4F44-FAD4-4B74-ADF5-D8E3BF595A02@dcn.davis.ca.us>
	<CADcgpJcuZzOYcQuSbwh_-o1c3iL87aMLMY-etuDBV5VKBhzicg@mail.gmail.com>
	<D6EEFA5A-B468-408E-8C23-5B374031C01F@dcn.davis.ca.us>
	<CADcgpJdc9bspYz83a73EirdGAjX=jp8YRneQUk7+OwvrTRf6xQ@mail.gmail.com>
	<F45BE837-BD1D-4C09-919F-C8165473DE38@dcn.davis.ca.us>
Message-ID: <CADcgpJcsZ5PANjU_9+HwZ8kdA4eZOASg3dLZGfxnMcWQqxNN9A@mail.gmail.com>

doing what Jeff has told.
Lets see what happens this time..

On 25 August 2016 at 11:54, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> I can not reproduce that using a fresh install of R 3.3.1 Win32 and dplyr
> 0.5.0. I suggest that you re-install dplyr or R or both... perhaps from a
> different mirror than the one you originally used. Do not use "Run As
> Administrator" and say yes to creating a personal library. Install dplyr
> with install.packages( "dplyr" ).
>
> If you continue to have trouble and want help then you are going to have
> to make an effort to convey a reproducible set of steps to arrive at your
> error. The Posting Guide has good advice on how to communicate on the R
> mailing lists.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> On August 24, 2016 10:08:09 PM PDT, Partha Sinha <pnsinha68 at gmail.com>
> wrote:
> >yes. I start a fresh session and start to load the library
> >
> >
> >On 25 August 2016 at 09:34, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> And the only input you give to trigger this is
> >>
> >> library(dplyr)
> >>
> >> ?
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On August 24, 2016 8:01:41 PM PDT, Partha Sinha <pnsinha68 at gmail.com>
> >> wrote:
> >> >i have used sessioninfo()
> >> >the output I have got
> >> >R version 3.3.1 (2016-06-21)
> >> >Platform: i386-w64-mingw32/i386 (32-bit)
> >> >Running under: Windows 7 (build 7600)
> >> >
> >> >locale:
> >> >[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
> >> >Kingdom.1252
> >> >[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
> >> >
> >> >[5] LC_TIME=English_United Kingdom.1252
> >> >
> >> >attached base packages:
> >> >[1] stats     graphics  grDevices utils     datasets  methods   base
> >> >
> >> >
> >> >I tried to load ggplot2 and dplyr.
> >> >both giving me similar problems
> >> >
> >> >Parth
> >> >
> >> >On 24 August 2016 at 20:40, Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >> >wrote:
> >> >
> >> >> This is not normal. I suggest making use of the maintainer() and
> >> >> sessionInfo() functions.
> >> >> --
> >> >> Sent from my phone. Please excuse my brevity.
> >> >>
> >> >> On August 24, 2016 7:47:25 AM PDT, Partha Sinha
> ><pnsinha68 at gmail.com>
> >> >> wrote:
> >> >> >I am using windows 7 , R version 3.3.1
> >> >> >whenever I am trying use
> >> >> >library(dplyr)
> >> >> >i am getting the follwing error:
> >> >> >
> >> >> >Error in get(Info[i, 1], envir = env) :
> >> >> >  cannot allocate memory block of size 2.5 Gb
> >> >> >Error: package or namespace load failed for ?dplyr?
> >> >> >
> >> >> >
> >> >> >pl help
> >> >> >
> >> >> >Regards
> >> >> >Partha
> >> >> >
> >> >> >       [[alternative HTML version deleted]]
> >> >> >
> >> >> >______________________________________________
> >> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> >PLEASE do read the posting guide
> >> >> >http://www.R-project.org/posting-guide.html
> >> >> >and provide commented, minimal, self-contained, reproducible
> >code.
> >> >>
> >> >>
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Aug 25 09:05:32 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 25 Aug 2016 09:05:32 +0200
Subject: [R] lme to determine if there is a group effect
In-Reply-To: <57BDEB95020000CB0015EA0F@smtp.medicine.umaryland.edu>
References: <57BDEB95020000CB0015EA0F@smtp.medicine.umaryland.edu>
Message-ID: <CAJuCY5y1KHwEh0Ei08hALq7b4p6Dzs_JKpc80z2rRXr+4codRA@mail.gmail.com>

Dear John,

lme() not longer requires a GroupedData object. You can directly use a
data.frame which is easier to specify different models.

You want something like

lme(value ~ time * group, random = ~ time|SS, data = data1)

PS Note that the R-Sig-mixedmodels is more suited for this kind of question.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-08-25 0:46 GMT+02:00 John Sorkin <jsorkin at grecc.umaryland.edu>:

> I apologize for sending this message again. The last time I sent it, the
> subject line was not correct. I have corrected the subject line.
>
> I am trying to run a repeated measures analysis of data in which each
> subject (identified by SS) has 3 observations at three different times (0,
> 3, and 6). There are two groups of subjects (identified by group). I want
> to know if the response differs in the two groups. I have tried to used
> lme. Lme tell me if there is a time effect, but does not tell me if there
> is a group effect. Once I get this to work I will want to know if there is
> a significant group*time effect. Can someone tell me how to get an estimate
> for group. Once I get that, I believe getting an estimate for group*time
> should be straight forward. The code I have tired to use follows.
> Thank you,
> John
>
> > # This is my data
> > data1
>    SS group time     value baseline
> 1   1  Cont    0  9.000000 9.000000
> 2   2  Cont    0  3.000000 3.000000
> 3   3  Cont    0  8.000000 8.000000
> 4   4  Inte    0  5.690702 5.690702
> 5   5  Inte    0  7.409493 7.409493
> 6   6  Inte    0  7.428018 7.428018
> 7   1  Cont    3 13.713148 9.000000
> 8   2  Cont    3  9.841107 3.000000
> 9   3  Cont    3 12.843236 8.000000
> 10  4  Inte    3  9.300899 5.690702
> 11  5  Inte    3 10.936389 7.409493
> 12  6  Inte    3 12.358499 7.428018
> 13  1  Cont    6 18.952390 9.000000
> 14  2  Cont    6 15.091527 3.000000
> 15  3  Cont    6 17.578812 8.000000
> 16  4  Inte    6 12.325499 5.690702
> 17  5  Inte    6 15.486513 7.409493
> 18  6  Inte    6 18.284965 7.428018
> > # Create a grouped data object. SS identifies each subject
> > # group indentifies group, intervention or control.
> > GD<- groupedData(value~time|SS/group,data=data1,FUN=mean)
> > # Fit the model.
> > fit1 <- lme(GD)
> > cat("The results give information about time, but does not say if the
> gruops are different\n")
> The results give information about time, but does not say if the gruops
> are different
> > summary(fit1)
> Linear mixed-effects model fit by REML
>  Data: GD
>        AIC      BIC    logLik
>   74.59447 81.54777 -28.29724
>
> Random effects:
>  Formula: ~time | SS
>  Structure: General positive-definite
>             StdDev    Corr
> (Intercept) 1.3875111 (Intr)
> time        0.2208046 -0.243
>
>  Formula: ~time | group %in% SS
>  Structure: General positive-definite
>             StdDev    Corr
> (Intercept) 1.3875115 (Intr)
> time        0.2208051 -0.243
> Residual    0.3800788
>
> Fixed effects: value ~ time
>                Value Std.Error DF   t-value p-value
> (Intercept) 6.747442 0.8135067 11  8.294268       0
> time        1.588653 0.1326242 11 11.978601       0
>  Correlation:
>      (Intr)
> time -0.268
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -1.11412947 -0.44986535  0.08034174  0.34615610  1.29943887
>
> Number of Observations: 18
> Number of Groups:
>            SS group %in% SS
>             6             6
>
>
>
> >
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:16}}


From highstat at highstat.com  Thu Aug 25 11:05:45 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 25 Aug 2016 10:05:45 +0100
Subject: [R] Course: Introduction to Regression Models with Spatial and
 Temporal Correlation
Message-ID: <d121aca3-8488-c3d4-75c0-0b74c28c46ff@highstat.com>

We would like to announce the following statistics course:

Course: Introduction to Regression Models with Spatial and Temporal 
Correlation
Where:  Lisbon, Portugal
When:   20-24 February 2017

Course website: http://www.highstat.com/statscourse.htm
Course flyer: 
http://highstat.com/Courses/Flyers/Flyer2017_02Lisbon_SpatTemp.pdf


Kind regards,

Alain Zuur






-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


	[[alternative HTML version deleted]]


From faradj.g at gmail.com  Thu Aug 25 12:31:43 2016
From: faradj.g at gmail.com (Faradj Koliev)
Date: Thu, 25 Aug 2016 12:31:43 +0200
Subject: [R] Hickman models with two binary dependent variables in R
Message-ID: <7E6E6DBE-BDCA-4B2A-9FB1-9F4A825058FD@gmail.com>

Hi everyone, 

How do I run Heckman models in R with two binary dependent variables? 

sampleSelection package in R works with standard heckman models ( binary DV for the selection equation and continuous DV for the outcome equation). In my case dependent variables are both binary (actually ordered but I didn?t find anything on that)

So using sampleSelection package one could do this by running: 

SelectionEquation <- binaryDV1 ~ x1+x2+x3+x4

OutcomeEquation <-  binaryDV2~o7+x1+x4+x5

HeckmanModel <- heckit(SelectionEquation,OutcomeEquation, data=mydata, method="2step")


The problem is that heckit() doesn?t work here. I think in STATA one could use heckprob command for this. Anyone who knows more than me? 

Thanks! 





	[[alternative HTML version deleted]]


From jsorkin at grecc.umaryland.edu  Thu Aug 25 16:48:42 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Thu, 25 Aug 2016 10:48:42 -0400
Subject: [R] nlme: fewer observations than random effects in all level 1
 groups
Message-ID: <57BECD0A020000CB0015EAF5@smtp.medicine.umaryland.edu>

I am getting a warning message when I run lme:
 
Warning message:
In lme.formula(fixed = value ~ CorT + time + CorT * time, data = GD) :
  fewer observations than random effects in all level 1 groups
I don't know what the message means, nor if I need to be concerned about the message. I would be
grateful if someone could explain the message to me, and tell me if I need to have concern.
My data and code follows. You should be able to copy, paste and run the code. (n.b. you will need nlme).
Thank you,
John

library(nlme)
data10 <- structure(list(SS = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
                      11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 
                      24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 
                      37L, 38L, 39L, 40L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
                      11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 
                      24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 
                      37L, 38L, 39L, 40L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
                      11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 
                      24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 
                      37L, 38L, 39L, 40L), 
                      group = structure(c(1L, 1L, 1L, 1L, 1L, 
                      1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
                      2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
                      2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
                      1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
                      2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 
                      1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
                      2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
                      2L, 2L, 2L), .Label = c("Cont", "Inte"), class = "factor"), 
                      time = c(0L,0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
                      0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
                      0L, 0L, 0L, 0L, 0L, 0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
                      3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
                      3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 6L, 
                      6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
                      6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
                      6L, 6L, 6L, 6L, 6L, 6L, 6L),
                      value = c(2, 1, 3, 6, 1, 5, 4, 4, 
                      3, 4, 5, 8, 4, 4, 0, 10, 3, 0, 4, 6, 7.86633577663451, 14.8276520497166, 
                      5.82301333779469, 6.28030818421394, 7.63550981180742, 7.12941627483815, 
                      14.4640282960609, 8.45473791006953, 9.05422623036429, 10.3654135158285, 
                      7.75828687706962, 9.05671408865601, 9.35509188333526, 8.22054158896208, 
                      5.03435689257458, 14.7296907380223, 6.12912589916959, 10.4857219522819, 
                      13.7229738035239, 13.6259456002153, 7.28073637914354, 5.54352982843898, 
                      8.01713229269774, 13.2061931600758, 3.76887153466896, 10.7523541087606, 
                      9.6018583095559, 9.62481826991277, 8.90923221009558, 8.85276119502607, 
                      10.9778885179292, 13.4521386035968, 9.95012926745246, 7.78767098907235, 
                      5.47606805783807, 16.266090481022, 8.10664718517709, 3.98960108796381, 
                      10.1788924241439, 9.16177207287154, 11.6541174116198, 19.055363149052, 
                      10.4729343696394, 12.9615216852694, 10.3448541992752, 12.1246619594601, 
                      17.9078516870675, 14.1546013378432, 14.3556335566072, 13.7020998307993, 
                      12.2669613611438, 13.6968944583291, 16.0242423205925, 14.1618907899469, 
                      11.6571628686932, 20.6208065318508, 10.5981108892906, 16.506205140693, 
                      19.8382587955876, 18.8215423103255, 13.6293066791555, 10.679427547606, 
                      14.5715854764237, 18.0672964438053, 8.64819129644325, 16.5046323205086, 
                      14.933146372713, 13.0224731390702, 13.1364074268251, 12.7299140722498, 
                      16.3687231173825, 17.3307585790136, 14.8835947338426, 13.7832964561028, 
                      8.18806783970065, 20.4643754783345, 13.927444172043, 7.95214003187942, 
                      15.8500600646401, 14.863828811346, 16.3418851303983, 23.9363727442689, 
                      15.6973592017088, 16.8376901116903, 16.4265975193717, 18.3862045830691, 
                      23.7260777608949, 19.6736595029528, 18.7411384574001, 21.5299075269243, 
                      18.7672717818268, 18.6586905356669, 20.1908194122778, 19.6037057845507, 
                      16.2952035024787, 25.2275624425201, 15.7628539929276, 21.2326533842687, 
                      25.3146615100186, 24.5526929132951), 
                      baseline = c(2, 1, 3, 6, 
                      1, 5, 4, 4, 3, 4, 5, 8, 4, 4, 0, 10, 3, 0, 4, 6, 7.86633577663451, 
                      14.8276520497166, 5.82301333779469, 6.28030818421394, 7.63550981180742, 
                      7.12941627483815, 14.4640282960609, 8.45473791006953, 9.05422623036429, 
                      10.3654135158285, 7.75828687706962, 9.05671408865601, 9.35509188333526, 
                      8.22054158896208, 5.03435689257458, 14.7296907380223, 6.12912589916959, 
                      10.4857219522819, 13.7229738035239, 13.6259456002153, 2, 1, 3, 
                      6, 1, 5, 4, 4, 3, 4, 5, 8, 4, 4, 0, 10, 3, 0, 4, 6, 7.86633577663451, 
                      14.8276520497166, 5.82301333779469, 6.28030818421394, 7.63550981180742, 
                      7.12941627483815, 14.4640282960609, 8.45473791006953, 9.05422623036429, 
                      10.3654135158285, 7.75828687706962, 9.05671408865601, 9.35509188333526, 
                      8.22054158896208, 5.03435689257458, 14.7296907380223, 6.12912589916959, 
                      10.4857219522819, 13.7229738035239, 13.6259456002153, 2, 1, 3, 
                      6, 1, 5, 4, 4, 3, 4, 5, 8, 4, 4, 0, 10, 3, 0, 4, 6, 7.86633577663451, 
                      14.8276520497166, 5.82301333779469, 6.28030818421394, 7.63550981180742, 
                      7.12941627483815, 14.4640282960609, 8.45473791006953, 9.05422623036429, 
                      10.3654135158285, 7.75828687706962, 9.05671408865601, 9.35509188333526, 
                      8.22054158896208, 5.03435689257458, 14.7296907380223, 6.12912589916959, 
                      10.4857219522819, 13.7229738035239, 13.6259456002153), 
                      CorT = c(0, 
                      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 
                      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 
                      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 
                      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 
                      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 
                      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)), 
                      row.names = c(NA, 
                      -120L), .Names = c("SS", "group", "time", "value", "baseline", 
                      "CorT"), class = "data.frame")
data10

GD2<- groupedData(value~time+CorT+time*CorT|SS,data=data10,FUN=mean)
fit1 <- lme(GD2)
summary(fit1)
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From jfca283 at gmail.com  Thu Aug 25 14:09:42 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Thu, 25 Aug 2016 09:09:42 -0300
Subject: [R] Importint stata file and using value labels
Message-ID: <CALBYkjJLbWXdS17zH=P_rf-rj7PPnTGp1TtKoC5Lk-bmkNtKVw@mail.gmail.com>

Hi
Im a bit lost.
Ive imported a stata13 file. When i try to make a simple
table(region[sex=1],type[sex=1])
i get something as
           type1 type2
region1 0 0
region2 0 0
region3 0 0

I don't know how to operate with the value labels.
Sex is defined as 1 as "Man" and 2 as "Female".
And region1 is 1, region2 is 2 and so on.
So, how can i make reference to the value and not the value labels when i
write down some condition or statement ?
I know is simple, but using the help for readstata13 didn't clarify it to
me.
Thanks for your help and time.

	[[alternative HTML version deleted]]


From alexander.sommer at tu-dortmund.de  Thu Aug 25 17:10:16 2016
From: alexander.sommer at tu-dortmund.de (alexander.sommer at tu-dortmund.de)
Date: Thu, 25 Aug 2016 15:10:16 +0000
Subject: [R] Storing business hours
Message-ID: <248BA33BC59279499C246B6EB309AF21016C92D522@ex2010mbx1.tu-dortmund.de>

Hi fellow R-users,

I am wondering about the best way to store business hours and the like in R. (Best in the sense of best for analyzing them.)

Say, I got a number of ?shops?:
Shop A opens at 8am and closes at 8pm;
shop B opens at 9am, closes at 11.45am for a siesta, reopens at 1.30pm and closes at 5pm;
and so forth.

To simplify things, I would assume that closing a shop for more than two times and reopening it for more than one time is not possible. (Hoping to avoid problems with shops having multiple siestas and business hours beyond midnight this way.)

My first idea would be to plot something like an empirical distribution function for this data. (Having only shops A and B, this would be zero until 8am, 50?% from 8am to 9am, 100?% from 9am to 11.45am, 50?% again from 11.45am to 1.30pm, 100?% again from 1.30pm to 5pm, yet again 50?% from 5pm to 8pm and falling back to zero from 8pm on.) But general arithmetic should be possible, especially for building a mean over some days.

Any ideas?

Cheers,

Alex


--
Alexander Sommer
wissenschaftlicher Mitarbeiter

Technische Universit?t Dortmund
Fakult?t Erziehungswissenschaft, Psychologie und Soziologie
Forschungsverbund Deutsches Jugendinstitut/Technische Universit?t Dortmund
Vogelpothsweg 78
44227 Dortmund

Telefon: +49 231 755-8189
Telefax: +49 231 755-6553
E-Mail:  alexander.sommer at tu-dortmund.de
WWW:     http://www.forschungsverbund.tu-dortmund.de/


Wichtiger Hinweis: Die Information in dieser E-Mail ist vertraulich. Sie ist ausschlie?lich f?r den Adressaten bestimmt. Sollten Sie nicht der f?r diese E-Mail bestimmte Adressat sein, unterrichten Sie bitte den Absender und vernichten Sie diese Mail. Vielen Dank.
Unbeschadet der Korrespondenz per E-Mail, sind unsere Erkl?rungen ausschlie?lich final rechtsverbindlich, wenn sie in herk?mmlicher Schriftform (mit eigenh?ndiger Unterschrift) oder durch ?bermittlung eines solchen Schriftst?cks per Telefax erfolgen.

Important note: The information included in this e-mail is confidential. It is solely intended for the recipient. If you are not the intended recipient of this e-mail please contact the sender and delete this message. Thank you. Without prejudice of e-mail correspondence, our statements are only legally binding when they are made in the conventional written form (with personal signature) or when such documents are sent by fax.

From ruipbarradas at sapo.pt  Thu Aug 25 17:39:04 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Thu, 25 Aug 2016 16:39:04 +0100
Subject: [R] Importint stata file and using value labels
In-Reply-To: <CALBYkjJLbWXdS17zH=P_rf-rj7PPnTGp1TtKoC5Lk-bmkNtKVw@mail.gmail.com>
Message-ID: <20160825163904.Horde.1WBb35Cp4ixvo0Euondfg9s@mail.sapo.pt>

Hello,

Try instead

table(region[sex==1],type[sex==1])

To test for equality use == not =.

Hope this helps,

Rui Barradas
?

Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:

> Hi
> Im a bit lost.
> Ive imported a stata13 file. When i try to make a simple
> table(region[sex=1],type[sex=1])
> i get something as
> ? ? ? ? ? type1 type2
> region1 0 0
> region2 0 0
> region3 0 0
>
> I don't know how to operate with the value labels.
> Sex is defined as 1 as "Man" and 2 as "Female".
> And region1 is 1, region2 is 2 and so on.
> So, how can i make reference to the value and not the value labels when i
> write down some condition or statement ?
> I know is simple, but using the help for readstata13 didn't clarify it to
> me.
> Thanks for your help and time.
>
> ? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From jfca283 at gmail.com  Thu Aug 25 18:02:54 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Thu, 25 Aug 2016 13:02:54 -0300
Subject: [R] Importint stata file and using value labels
In-Reply-To: <20160825163904.Horde.1WBb35Cp4ixvo0Euondfg9s@mail.sapo.pt>
References: <CALBYkjJLbWXdS17zH=P_rf-rj7PPnTGp1TtKoC5Lk-bmkNtKVw@mail.gmail.com>
	<20160825163904.Horde.1WBb35Cp4ixvo0Euondfg9s@mail.sapo.pt>
Message-ID: <CALBYkj+jmgtqz24LJw1ArtgCbPafjkL48qfzujHRjQ9-azc8dQ@mail.gmail.com>

Nop. I didn't work. But using the following it does work.
table(region[sex=="Men"],type[sex=="Men"])
When i use the dta file with stata i declare the condition with sex==1 and
not sex=="Man".

On Thu, Aug 25, 2016 at 12:39 PM, <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Try instead
>
> table(region[sex==1],type[sex==1])
>
> To test for equality use == not =.
>
> Hope this helps,
>
> Rui Barradas
>
>
> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>
> Hi
> Im a bit lost.
> Ive imported a stata13 file. When i try to make a simple
> table(region[sex=1],type[sex=1])
> i get something as
>           type1 type2
> region1 0 0
> region2 0 0
> region3 0 0
>
> I don't know how to operate with the value labels.
> Sex is defined as 1 as "Man" and 2 as "Female".
> And region1 is 1, region2 is 2 and so on.
> So, how can i make reference to the value and not the value labels when i
> write down some condition or statement ?
> I know is simple, but using the help for readstata13 didn't clarify it to
> me.
> Thanks for your help and time.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.htmland provide commented, minimal, self-contained,
> reproducible code.
>
>
>
>

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Thu Aug 25 18:42:34 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Thu, 25 Aug 2016 17:42:34 +0100
Subject: [R] Importint stata file and using value labels
In-Reply-To: <CALBYkj+jmgtqz24LJw1ArtgCbPafjkL48qfzujHRjQ9-azc8dQ@mail.gmail.com>
References: <CALBYkjJLbWXdS17zH=P_rf-rj7PPnTGp1TtKoC5Lk-bmkNtKVw@mail.gmail.com>
	<20160825163904.Horde.1WBb35Cp4ixvo0Euondfg9s@mail.sapo.pt>
	<CALBYkj+jmgtqz24LJw1ArtgCbPafjkL48qfzujHRjQ9-azc8dQ@mail.gmail.com>
Message-ID: <20160825174234.Horde.R6gdOj82yuK987Jj6o5_qEp@mail.sapo.pt>

Maybe sex is a factor and Man its label. Factors are coded internally  
as integers, to see it use

str(sex)

Rui Barradas
?

Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:

> Nop. I didn't work. But using the following it does work.
> table(region[sex=="Men"],type[sex=="Men"])
> When i use the dta file with stata i declare the condition with  
> sex==1 and not sex=="Man".
> ? On Thu, Aug 25, 2016 at 12:39 PM, <ruipbarradas at sapo.pt> wrote:
>> _Hello,
>>
>> Try instead
>>
>> table(region[sex==1],type[sex==1])
>>
>> To test for equality use == not =.
>>
>> Hope this helps,
>>
>> Rui Barradas
>> ?_
>>
>> _Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:_
>>
>>> ?
>>> _Hi
>>> Im a bit lost.
>>> Ive imported a stata13 file. When i try to make a simple
>>> table(region[sex=1],type[sex=1])
>>> i get something as
>>> ? ? ? ? ? type1 type2
>>> region1 0 0
>>> region2 0 0
>>> region3 0 0
>>>
>>> I don't know how to operate with the value labels.
>>> Sex is defined as 1 as "Man" and 2 as "Female".
>>> And region1 is 1, region2 is 2 and so on.
>>> So, how can i make reference to the value and not the value labels when i
>>> write down some condition or statement ?
>>> I know is simple, but using the help for readstata13 didn't clarify it to
>>> me.
>>> Thanks for your help and time._
>>> ?
>>>
>>> _? ? ? ? [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide  
>>> http://www.R-project.org/posting-guide.htmland provide commented,  
>>> minimal, self-contained, reproducible code._
>>> ?
>>
>> _?_

?

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Aug 25 19:11:42 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 25 Aug 2016 10:11:42 -0700
Subject: [R] Importint stata file and using value labels
In-Reply-To: <CALBYkjJLbWXdS17zH=P_rf-rj7PPnTGp1TtKoC5Lk-bmkNtKVw@mail.gmail.com>
References: <CALBYkjJLbWXdS17zH=P_rf-rj7PPnTGp1TtKoC5Lk-bmkNtKVw@mail.gmail.com>
Message-ID: <5773B001-787E-4A0C-94B9-1DED121EB0E3@dcn.davis.ca.us>

You need to (re-)read the "Introduction to R" document that comes with R. R Is not Stata, and you should not expect R to look syntactically like Stata.

Note that if you, against normal R convention, wish to manipulate the integers that a factor is implemented with,  you can create such a variable using as.integer( sex ), but beware that bad data or changes made to the factor definition before your analysis step will render your assumptions about specific integer values invalid. For example the order of levels for sex might go c("M","F") or c("F","M") so 1 could mean different things based on decisions made elsewhere. 
-- 
Sent from my phone. Please excuse my brevity.

On August 25, 2016 5:09:42 AM PDT, Juan Ceccarelli Arias <jfca283 at gmail.com> wrote:
>Hi
>Im a bit lost.
>Ive imported a stata13 file. When i try to make a simple
>table(region[sex=1],type[sex=1])
>i get something as
>           type1 type2
>region1 0 0
>region2 0 0
>region3 0 0
>
>I don't know how to operate with the value labels.
>Sex is defined as 1 as "Man" and 2 as "Female".
>And region1 is 1, region2 is 2 and so on.
>So, how can i make reference to the value and not the value labels when
>i
>write down some condition or statement ?
>I know is simple, but using the help for readstata13 didn't clarify it
>to
>me.
>Thanks for your help and time.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Thu Aug 25 21:11:07 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Thu, 25 Aug 2016 20:11:07 +0100
Subject: [R] Importint stata file and using value labels
In-Reply-To: <CALBYkjLKgmA0W3Ecvh94eLniWVECU8i5ys8j5+zJkAeyOs+khA@mail.gmail.com>
References: <CALBYkjJLbWXdS17zH=P_rf-rj7PPnTGp1TtKoC5Lk-bmkNtKVw@mail.gmail.com>
	<20160825163904.Horde.1WBb35Cp4ixvo0Euondfg9s@mail.sapo.pt>
	<CALBYkj+jmgtqz24LJw1ArtgCbPafjkL48qfzujHRjQ9-azc8dQ@mail.gmail.com>
	<20160825174234.Horde.R6gdOj82yuK987Jj6o5_qEp@mail.sapo.pt>
	<CALBYkjLKgmA0W3Ecvh94eLniWVECU8i5ys8j5+zJkAeyOs+khA@mail.gmail.com>
Message-ID: <20160825201107.Horde._Vy9S_eCHmMTdmtkvdhot_t@mail.sapo.pt>

So you should do

table(region[sex=="Hombre"],type[sex=="Hombre"]

Rui Barradas
?

Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:

>> str(sex)
> ?Factor w/ 2 levels "Hombre","Mujer": 1 2 2 1 2 2 1 1 1 1 ...
> ? On Thu, Aug 25, 2016 at 1:42 PM, <ruipbarradas at sapo.pt> wrote:
>> _Maybe sex is a factor and Man its label. Factors are coded  
>> internally as integers, to see it use
>>
>> str(sex)
>>
>> Rui Barradas
>> ?_
>>
>> _Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:_
>>
>>> _Nop. I didn't work. But using the following it does work.
>>> table(region[sex=="Men"],type[sex=="Men"])_
>>> _When i use the dta file with stata i declare the condition with  
>>> sex==1 and not sex=="Man"._
>>> _? _ _On Thu, Aug 25, 2016 at 12:39 PM, <ruipbarradas at sapo.pt> wrote: _
>>>> __Hello,
>>>>
>>>> Try instead
>>>>
>>>> table(region[sex==1],type[sex=_=1])
>>>>
>>>> To test for equality use == not =.
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>> ?_
>>>>
>>>> __Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:__
>>>>
>>>>> _?_
>>>>> __Hi
>>>>> Im a bit lost.
>>>>> Ive imported a stata13 file. When i try to make a simple
>>>>> table(region[sex=1],type[sex=_1])
>>>>> i get something as
>>>>> ? ? ? ? ? type1 type2
>>>>> region1 0 0
>>>>> region2 0 0
>>>>> region3 0 0
>>>>>
>>>>> I don't know how to operate with the value labels.
>>>>> Sex is defined as 1 as "Man" and 2 as "Female".
>>>>> And region1 is 1, region2 is 2 and so on.
>>>>> So, how can i make reference to the value and not the value labels when i
>>>>> write down some condition or statement ?
>>>>> I know is simple, but using the help for readstata13 didn't clarify it to
>>>>> me.
>>>>> Thanks for your help and time.
>>>>> ?_
>>>>>
>>>>> __? ? ? ? [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide  
>>>>> http://www.R-project.org/posting-guide.htmland provide  
>>>>> commented, minimal, self-contained, reproducible code. _
>>>>> _?_
>>>>> _ _
>>>>
>>>> __?__
>>>
>>> _ _
>>> _ _
>>
>> _?_

?


From david at agros.it  Thu Aug 25 19:18:47 2016
From: david at agros.it (David Remotti)
Date: Thu, 25 Aug 2016 19:18:47 +0200
Subject: [R] help in preparing data for using the package SURVEY
Message-ID: <c109afc6-5072-a1f1-9a5c-9cfffd9bbf17@agros.it>

hello all, and thanks in advance for any eventual help.
I'am quite new to R, and want to use the package SURVEY to calculate 
results from a sampling.
I have installed the package and started studying it, but I find 
difficulties in understanding how to prepare my data (I actually have 
them in a MYSQL database) for the analysis with R.
Is there any tutorial to help me in organiziing my data ?
Thanks
David Remotti


From jfca283 at gmail.com  Thu Aug 25 18:49:03 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Thu, 25 Aug 2016 13:49:03 -0300
Subject: [R] Importint stata file and using value labels
In-Reply-To: <20160825174234.Horde.R6gdOj82yuK987Jj6o5_qEp@mail.sapo.pt>
References: <CALBYkjJLbWXdS17zH=P_rf-rj7PPnTGp1TtKoC5Lk-bmkNtKVw@mail.gmail.com>
	<20160825163904.Horde.1WBb35Cp4ixvo0Euondfg9s@mail.sapo.pt>
	<CALBYkj+jmgtqz24LJw1ArtgCbPafjkL48qfzujHRjQ9-azc8dQ@mail.gmail.com>
	<20160825174234.Horde.R6gdOj82yuK987Jj6o5_qEp@mail.sapo.pt>
Message-ID: <CALBYkjLKgmA0W3Ecvh94eLniWVECU8i5ys8j5+zJkAeyOs+khA@mail.gmail.com>

> str(sex)
 Factor w/ 2 levels "Hombre","Mujer": 1 2 2 1 2 2 1 1 1 1 ...

On Thu, Aug 25, 2016 at 1:42 PM, <ruipbarradas at sapo.pt> wrote:

> Maybe sex is a factor and Man its label. Factors are coded internally as
> integers, to see it use
>
> str(sex)
>
> Rui Barradas
>
>
> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>
> Nop. I didn't work. But using the following it does work.
> table(region[sex=="Men"],type[sex=="Men"])
> When i use the dta file with stata i declare the condition with sex==1 and
> not sex=="Man".
>
> On Thu, Aug 25, 2016 at 12:39 PM, <ruipbarradas at sapo.pt> wrote:
>>
>>
>>
>>
>>
>> *Hello, Try instead table(region[sex==1],type[sex=*=1])
>>
>> To test for equality use == not =.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> *Citando Juan Ceccarelli Arias <jfca283 at gmail.com <jfca283 at gmail.com>>:*
>>
>>
>>
>>
>>
>> *Hi Im a bit lost. Ive imported a stata13 file. When i try to make a
>> simple table(region[sex=1],type[sex=*1])
>> i get something as
>>           type1 type2
>> region1 0 0
>> region2 0 0
>> region3 0 0
>>
>> I don't know how to operate with the value labels.
>> Sex is defined as 1 as "Man" and 2 as "Female".
>> And region1 is 1, region2 is 2 and so on.
>> So, how can i make reference to the value and not the value labels when i
>> write down some condition or statement ?
>> I know is simple, but using the help for readstata13 didn't clarify it to
>> me.
>> Thanks for your help and time.
>>
>>
>>
>> *        [[alternative HTML version deleted]]
>> ______________________________*________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.htmland provide commented, minimal, self-contained,
>> reproducible code.
>>
>>
>>
>>
>>
>>
>
>
>

	[[alternative HTML version deleted]]


From jfca283 at gmail.com  Thu Aug 25 21:15:08 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Thu, 25 Aug 2016 16:15:08 -0300
Subject: [R] Importint stata file and using value labels
In-Reply-To: <20160825201107.Horde._Vy9S_eCHmMTdmtkvdhot_t@mail.sapo.pt>
References: <CALBYkjJLbWXdS17zH=P_rf-rj7PPnTGp1TtKoC5Lk-bmkNtKVw@mail.gmail.com>
	<20160825163904.Horde.1WBb35Cp4ixvo0Euondfg9s@mail.sapo.pt>
	<CALBYkj+jmgtqz24LJw1ArtgCbPafjkL48qfzujHRjQ9-azc8dQ@mail.gmail.com>
	<20160825174234.Horde.R6gdOj82yuK987Jj6o5_qEp@mail.sapo.pt>
	<CALBYkjLKgmA0W3Ecvh94eLniWVECU8i5ys8j5+zJkAeyOs+khA@mail.gmail.com>
	<20160825201107.Horde._Vy9S_eCHmMTdmtkvdhot_t@mail.sapo.pt>
Message-ID: <CALBYkjJ9=8hTV=+dL0nBaVV+Lnw1QqNAoR98Q63Sr7wJzRq=sA@mail.gmail.com>

Mmm...The other option working with  R for importing the dta file but
obtaining the values and deleting or ignoring the value labels.
I think some time ago i did that, but now i can't remember it.


On Thu, Aug 25, 2016 at 4:11 PM, <ruipbarradas at sapo.pt> wrote:

> So you should do
>
> table(region[sex=="Hombre"],type[sex=="Hombre"]
>
> Rui Barradas
>
>
> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>
> str(sex)
>>>
>>  Factor w/ 2 levels "Hombre","Mujer": 1 2 2 1 2 2 1 1 1 1 ...
>>   On Thu, Aug 25, 2016 at 1:42 PM, <ruipbarradas at sapo.pt> wrote:
>>
>>> _Maybe sex is a factor and Man its label. Factors are coded internally
>>> as integers, to see it use
>>>
>>> str(sex)
>>>
>>> Rui Barradas
>>>  _
>>>
>>> _Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:_
>>>
>>> _Nop. I didn't work. But using the following it does work.
>>>> table(region[sex=="Men"],type[sex=="Men"])_
>>>> _When i use the dta file with stata i declare the condition with sex==1
>>>> and not sex=="Man"._
>>>> _  _ _On Thu, Aug 25, 2016 at 12:39 PM, <ruipbarradas at sapo.pt> wrote: _
>>>>
>>>>> __Hello,
>>>>>
>>>>> Try instead
>>>>>
>>>>> table(region[sex==1],type[sex=_=1])
>>>>>
>>>>> To test for equality use == not =.
>>>>>
>>>>> Hope this helps,
>>>>>
>>>>> Rui Barradas
>>>>>  _
>>>>>
>>>>> __Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:__
>>>>>
>>>>> _ _
>>>>>> __Hi
>>>>>> Im a bit lost.
>>>>>> Ive imported a stata13 file. When i try to make a simple
>>>>>> table(region[sex=1],type[sex=_1])
>>>>>> i get something as
>>>>>>           type1 type2
>>>>>> region1 0 0
>>>>>> region2 0 0
>>>>>> region3 0 0
>>>>>>
>>>>>> I don't know how to operate with the value labels.
>>>>>> Sex is defined as 1 as "Man" and 2 as "Female".
>>>>>> And region1 is 1, region2 is 2 and so on.
>>>>>> So, how can i make reference to the value and not the value labels
>>>>>> when i
>>>>>> write down some condition or statement ?
>>>>>> I know is simple, but using the help for readstata13 didn't clarify
>>>>>> it to
>>>>>> me.
>>>>>> Thanks for your help and time.
>>>>>>  _
>>>>>>
>>>>>> __        [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>>>> ng-guide.htmland provide commented, minimal, self-contained,
>>>>>> reproducible code. _
>>>>>> _ _
>>>>>> _ _
>>>>>>
>>>>>
>>>>> __ __
>>>>>
>>>>
>>>> _ _
>>>> _ _
>>>>
>>>
>>> _ _
>>>
>>
>
>
>

	[[alternative HTML version deleted]]


From sara.fernstad at northumbria.ac.uk  Thu Aug 25 18:06:13 2016
From: sara.fernstad at northumbria.ac.uk (Sara Johansson Fernstad)
Date: Thu, 25 Aug 2016 16:06:13 +0000
Subject: [R] Invitation to visualization user study
Message-ID: <D3E4D605.8E00%sara.fernstad@northumbria.ac.uk>


Dear R-users,

We are currently conducting a user study evaluating visualization methods
from the R-package VIM
(https://cran.r-project.org/web/packages/VIM/VIM.pdf) in the context of
displaying missing data. Our aim is to evaluate what type of visualization
may be best for solving particular tasks, and through this provide
guidance for future research and development.

I would like to invite you as an R-user and data analyst to participate in
this study.

The study is completely anonymous and is part of a project at University
of Northumbria at Newcastle, UK. It starts with an instructive video,
followed by a set of tasks that will take around 15 minutes to complete.

If you have any questions or comments regarding the study, please contact
sara.fernstad at northumbria.ac.uk.

To the study: 
https://northumbria.onlinesurveys.ac.uk/survey-visualization-of-missing-dat
a


Your participation is important and very much appreciated!

Kind regards,
Sara




________________________________________________________________
Dr Sara J Fernstad
Senior Lecturer

Department of Computer and Information Sciences
Northumbria University
Newcastle upon Tyne
NE2 1XE
United Kingdom

E-mail: sara.fernstad at northumbria.ac.uk
Phone: +44 (0)191 243 7384
Office: Pandon 243

http://fee.northumbria.ac.uk/staff/jlhv8

http://fee.northumbria.ac.uk/staff/jlhv8/nova/


From marine.regis at hotmail.fr  Thu Aug 25 23:28:57 2016
From: marine.regis at hotmail.fr (Marine Regis)
Date: Thu, 25 Aug 2016 21:28:57 +0000
Subject: [R] Scale and shape parameters of Gamma mixture distributions
Message-ID: <AM3PR07MB4685485D8E090E0798CB949E2ED0@AM3PR07MB468.eurprd07.prod.outlook.com>

Hello,


I used the function "mix" (package "mixdist'') to fit Gamma mixture distributions. The function gives mu and sigma parameters (output below). How can I find the scale and shape parameters of the Gamma distributions ?


Parameters:
      pi    mu sigma
1 0.2089 185.7 285.4
2 0.7911 530.1 423.5


Thanks a lot for your time.

Marine

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Aug 26 00:14:28 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 26 Aug 2016 08:14:28 +1000
Subject: [R] Storing business hours
In-Reply-To: <248BA33BC59279499C246B6EB309AF21016C92D522@ex2010mbx1.tu-dortmund.de>
References: <248BA33BC59279499C246B6EB309AF21016C92D522@ex2010mbx1.tu-dortmund.de>
Message-ID: <CA+8X3fVpNS73BLDX2qzED3Z3VCyV4V3e3WCuKpTZHBP1EKe2Eg@mail.gmail.com>

Hi Alexander,
A time series comes to mind, but perhaps all you need is a matrix with
0s for closed and 1s for open. Each row is a shop. Column names as the
times and the resolution is up to you. I think colSums will produce
what you want.

Jim

On Fri, Aug 26, 2016 at 1:10 AM, alexander.sommer at tu-dortmund.de
<alexander.sommer at tu-dortmund.de> wrote:
> Hi fellow R-users,
>
> I am wondering about the best way to store business hours and the like in R. (Best in the sense of best for analyzing them.)
>
> Say, I got a number of ?shops?:
> Shop A opens at 8am and closes at 8pm;
> shop B opens at 9am, closes at 11.45am for a siesta, reopens at 1.30pm and closes at 5pm;
> and so forth.
>
> To simplify things, I would assume that closing a shop for more than two times and reopening it for more than one time is not possible. (Hoping to avoid problems with shops having multiple siestas and business hours beyond midnight this way.)
>
> My first idea would be to plot something like an empirical distribution function for this data. (Having only shops A and B, this would be zero until 8am, 50?% from 8am to 9am, 100?% from 9am to 11.45am, 50?% again from 11.45am to 1.30pm, 100?% again from 1.30pm to 5pm, yet again 50?% from 5pm to 8pm and falling back to zero from 8pm on.) But general arithmetic should be possible, especially for building a mean over some days.
>
> Any ideas?
>
> Cheers,
>
> Alex
>
>
> --
> Alexander Sommer
> wissenschaftlicher Mitarbeiter
>
> Technische Universit?t Dortmund
> Fakult?t Erziehungswissenschaft, Psychologie und Soziologie
> Forschungsverbund Deutsches Jugendinstitut/Technische Universit?t Dortmund
> Vogelpothsweg 78
> 44227 Dortmund
>
> Telefon: +49 231 755-8189
> Telefax: +49 231 755-6553
> E-Mail:  alexander.sommer at tu-dortmund.de
> WWW:     http://www.forschungsverbund.tu-dortmund.de/
>
>
> Wichtiger Hinweis: Die Information in dieser E-Mail ist vertraulich. Sie ist ausschlie?lich f?r den Adressaten bestimmt. Sollten Sie nicht der f?r diese E-Mail bestimmte Adressat sein, unterrichten Sie bitte den Absender und vernichten Sie diese Mail. Vielen Dank.
> Unbeschadet der Korrespondenz per E-Mail, sind unsere Erkl?rungen ausschlie?lich final rechtsverbindlich, wenn sie in herk?mmlicher Schriftform (mit eigenh?ndiger Unterschrift) oder durch ?bermittlung eines solchen Schriftst?cks per Telefax erfolgen.
>
> Important note: The information included in this e-mail is confidential. It is solely intended for the recipient. If you are not the intended recipient of this e-mail please contact the sender and delete this message. Thank you. Without prejudice of e-mail correspondence, our statements are only legally binding when they are made in the conventional written form (with personal signature) or when such documents are sent by fax.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Aug 26 01:17:09 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 25 Aug 2016 16:17:09 -0700
Subject: [R] Storing business hours
In-Reply-To: <CA+8X3fVpNS73BLDX2qzED3Z3VCyV4V3e3WCuKpTZHBP1EKe2Eg@mail.gmail.com>
References: <248BA33BC59279499C246B6EB309AF21016C92D522@ex2010mbx1.tu-dortmund.de>
	<CA+8X3fVpNS73BLDX2qzED3Z3VCyV4V3e3WCuKpTZHBP1EKe2Eg@mail.gmail.com>
Message-ID: <CAF8bMcZRKUkx+1TqHTzXdHLrJrvT+WLF5o=uZt-wZcYVJzefeA@mail.gmail.com>

If you label opening times with +1 and closing times with -1 then
cumsum(thoseLabels) will tell you how many shops are open immediately after
each of those times.  You can use findInterval() on the times to map an
arbitrary time to the number of shops open at that time.  You do need to
deal with starting values so that the first label for each shop is +1.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Aug 25, 2016 at 3:14 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Alexander,
> A time series comes to mind, but perhaps all you need is a matrix with
> 0s for closed and 1s for open. Each row is a shop. Column names as the
> times and the resolution is up to you. I think colSums will produce
> what you want.
>
> Jim
>
> On Fri, Aug 26, 2016 at 1:10 AM, alexander.sommer at tu-dortmund.de
> <alexander.sommer at tu-dortmund.de> wrote:
> > Hi fellow R-users,
> >
> > I am wondering about the best way to store business hours and the like
> in R. (Best in the sense of best for analyzing them.)
> >
> > Say, I got a number of ?shops?:
> > Shop A opens at 8am and closes at 8pm;
> > shop B opens at 9am, closes at 11.45am for a siesta, reopens at 1.30pm
> and closes at 5pm;
> > and so forth.
> >
> > To simplify things, I would assume that closing a shop for more than two
> times and reopening it for more than one time is not possible. (Hoping to
> avoid problems with shops having multiple siestas and business hours beyond
> midnight this way.)
> >
> > My first idea would be to plot something like an empirical distribution
> function for this data. (Having only shops A and B, this would be zero
> until 8am, 50?% from 8am to 9am, 100?% from 9am to 11.45am, 50?% again from
> 11.45am to 1.30pm, 100?% again from 1.30pm to 5pm, yet again 50?% from 5pm
> to 8pm and falling back to zero from 8pm on.) But general arithmetic should
> be possible, especially for building a mean over some days.
> >
> > Any ideas?
> >
> > Cheers,
> >
> > Alex
> >
> >
> > --
> > Alexander Sommer
> > wissenschaftlicher Mitarbeiter
> >
> > Technische Universit?t Dortmund
> > Fakult?t Erziehungswissenschaft, Psychologie und Soziologie
> > Forschungsverbund Deutsches Jugendinstitut/Technische Universit?t
> Dortmund
> > Vogelpothsweg 78
> > 44227 Dortmund
> >
> > Telefon: +49 231 755-8189
> > Telefax: +49 231 755-6553
> > E-Mail:  alexander.sommer at tu-dortmund.de
> > WWW:     http://www.forschungsverbund.tu-dortmund.de/
> >
> >
> > Wichtiger Hinweis: Die Information in dieser E-Mail ist vertraulich. Sie
> ist ausschlie?lich f?r den Adressaten bestimmt. Sollten Sie nicht der f?r
> diese E-Mail bestimmte Adressat sein, unterrichten Sie bitte den Absender
> und vernichten Sie diese Mail. Vielen Dank.
> > Unbeschadet der Korrespondenz per E-Mail, sind unsere Erkl?rungen
> ausschlie?lich final rechtsverbindlich, wenn sie in herk?mmlicher
> Schriftform (mit eigenh?ndiger Unterschrift) oder durch ?bermittlung eines
> solchen Schriftst?cks per Telefax erfolgen.
> >
> > Important note: The information included in this e-mail is confidential.
> It is solely intended for the recipient. If you are not the intended
> recipient of this e-mail please contact the sender and delete this message.
> Thank you. Without prejudice of e-mail correspondence, our statements are
> only legally binding when they are made in the conventional written form
> (with personal signature) or when such documents are sent by fax.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Aug 26 01:35:42 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 25 Aug 2016 16:35:42 -0700
Subject: [R] help in preparing data for using the package SURVEY
In-Reply-To: <c109afc6-5072-a1f1-9a5c-9cfffd9bbf17@agros.it>
References: <c109afc6-5072-a1f1-9a5c-9cfffd9bbf17@agros.it>
Message-ID: <AB6B39A1-C218-47BC-A3FB-3123732C1931@comcast.net>


> On Aug 25, 2016, at 10:18 AM, David Remotti <david at agros.it> wrote:
> 
> hello all, and thanks in advance for any eventual help.
> I'am quite new to R, and want to use the package SURVEY to calculate results from a sampling.

First: It is spelled "survey"

> I have installed the package and started studying it, but I find difficulties in understanding how to prepare my data (I actually have them in a MYSQL database) for the analysis with R.
> Is there any tutorial to help me in organiziing my data ?

If you type:

help(pac=survey)


... an Index page should pop up and if you follow the link: 	"? User guides, package vignettes and other documentation." it should lead you two 5 different tutorials.



-- 
David Winsemius
Alameda, CA, USA


From petr.pikal at precheza.cz  Fri Aug 26 09:11:11 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 26 Aug 2016 07:11:11 +0000
Subject: [R] Importint stata file and using value labels
In-Reply-To: <CALBYkjJ9=8hTV=+dL0nBaVV+Lnw1QqNAoR98Q63Sr7wJzRq=sA@mail.gmail.com>
References: <CALBYkjJLbWXdS17zH=P_rf-rj7PPnTGp1TtKoC5Lk-bmkNtKVw@mail.gmail.com>
	<20160825163904.Horde.1WBb35Cp4ixvo0Euondfg9s@mail.sapo.pt>
	<CALBYkj+jmgtqz24LJw1ArtgCbPafjkL48qfzujHRjQ9-azc8dQ@mail.gmail.com>
	<20160825174234.Horde.R6gdOj82yuK987Jj6o5_qEp@mail.sapo.pt>
	<CALBYkjLKgmA0W3Ecvh94eLniWVECU8i5ys8j5+zJkAeyOs+khA@mail.gmail.com>
	<20160825201107.Horde._Vy9S_eCHmMTdmtkvdhot_t@mail.sapo.pt>
	<CALBYkjJ9=8hTV=+dL0nBaVV+Lnw1QqNAoR98Q63Sr7wJzRq=sA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503A48E@SRVEXCHMBX.precheza.cz>

Hi

You can use

as.numeric(sex)

to get numeric values for factor variable. This is sometimes handy for plotting.

However if you throw away labels how do you know what naumber belongs to which factor level?

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Juan
> Ceccarelli Arias
> Sent: Thursday, August 25, 2016 9:15 PM
> To: ruipbarradas at sapo.pt
> Cc: r-help at r-project.org
> Subject: Re: [R] Importint stata file and using value labels
>
> Mmm...The other option working with  R for importing the dta file but
> obtaining the values and deleting or ignoring the value labels.
> I think some time ago i did that, but now i can't remember it.
>
>
> On Thu, Aug 25, 2016 at 4:11 PM, <ruipbarradas at sapo.pt> wrote:
>
> > So you should do
> >
> > table(region[sex=="Hombre"],type[sex=="Hombre"]
> >
> > Rui Barradas
> >
> >
> > Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
> >
> > str(sex)
> >>>
> >>  Factor w/ 2 levels "Hombre","Mujer": 1 2 2 1 2 2 1 1 1 1 ...
> >>   On Thu, Aug 25, 2016 at 1:42 PM, <ruipbarradas at sapo.pt> wrote:
> >>
> >>> _Maybe sex is a factor and Man its label. Factors are coded
> >>> internally as integers, to see it use
> >>>
> >>> str(sex)
> >>>
> >>> Rui Barradas
> >>>  _
> >>>
> >>> _Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:_
> >>>
> >>> _Nop. I didn't work. But using the following it does work.
> >>>> table(region[sex=="Men"],type[sex=="Men"])_
> >>>> _When i use the dta file with stata i declare the condition with
> >>>> sex==1 and not sex=="Man"._ _  _ _On Thu, Aug 25, 2016 at 12:39 PM,
> >>>> <ruipbarradas at sapo.pt> wrote: _
> >>>>
> >>>>> __Hello,
> >>>>>
> >>>>> Try instead
> >>>>>
> >>>>> table(region[sex==1],type[sex=_=1])
> >>>>>
> >>>>> To test for equality use == not =.
> >>>>>
> >>>>> Hope this helps,
> >>>>>
> >>>>> Rui Barradas
> >>>>>  _
> >>>>>
> >>>>> __Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:__
> >>>>>
> >>>>> _ _
> >>>>>> __Hi
> >>>>>> Im a bit lost.
> >>>>>> Ive imported a stata13 file. When i try to make a simple
> >>>>>> table(region[sex=1],type[sex=_1]) i get something as
> >>>>>>           type1 type2
> >>>>>> region1 0 0
> >>>>>> region2 0 0
> >>>>>> region3 0 0
> >>>>>>
> >>>>>> I don't know how to operate with the value labels.
> >>>>>> Sex is defined as 1 as "Man" and 2 as "Female".
> >>>>>> And region1 is 1, region2 is 2 and so on.
> >>>>>> So, how can i make reference to the value and not the value
> >>>>>> labels when i write down some condition or statement ?
> >>>>>> I know is simple, but using the help for readstata13 didn't
> >>>>>> clarify it to me.
> >>>>>> Thanks for your help and time.
> >>>>>>  _
> >>>>>>
> >>>>>> __        [[alternative HTML version deleted]]
> >>>>>>
> >>>>>> _______________________________________________
> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>> PLEASE do read the posting guide http://www.R-project.org/posti
> >>>>>> ng-guide.htmland provide commented, minimal, self-contained,
> >>>>>> reproducible code. _ _ _ _ _
> >>>>>>
> >>>>>
> >>>>> __ __
> >>>>>
> >>>>
> >>>> _ _
> >>>> _ _
> >>>>
> >>>
> >>> _ _
> >>>
> >>
> >
> >
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From r.turner at auckland.ac.nz  Fri Aug 26 09:21:24 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 26 Aug 2016 09:21:24 +0200
Subject: [R] Scale and shape parameters of Gamma mixture distributions
In-Reply-To: <AM3PR07MB4685485D8E090E0798CB949E2ED0@AM3PR07MB468.eurprd07.prod.outlook.com>
References: <AM3PR07MB4685485D8E090E0798CB949E2ED0@AM3PR07MB468.eurprd07.prod.outlook.com>
Message-ID: <e84bd896-29a5-6c24-194c-54a5a51d4714@auckland.ac.nz>

On 25/08/16 23:28, Marine Regis wrote:
> Hello,
>
>
> I used the function "mix" (package "mixdist'') to fit Gamma mixture distributions. The function gives mu and sigma parameters (output below). How can I find the scale and shape parameters of the Gamma distributions ?
>
>
> Parameters:
>       pi    mu sigma
> 1 0.2089 185.7 285.4
> 2 0.7911 530.1 423.5

I have no familiarity with the "mixdist" package, but I find it very 
surprising that mix() would return a fit of a Gamma mixture parametrised 
in terms of mu and sigma.  I suspect that you are doing something wrong.

If it really *does* give you such a parametrisation, you can recover the 
shape (alpha) and scale (beta) parameters by solving

    mu = alpha*beta
    sigma^2 = alpha*beta^2

for alpha and beta.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From thierry.onkelinx at inbo.be  Fri Aug 26 10:29:02 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 26 Aug 2016 10:29:02 +0200
Subject: [R] nlme: fewer observations than random effects in all level 1
	groups
In-Reply-To: <57BECD0A020000CB0015EAF5@smtp.medicine.umaryland.edu>
References: <57BECD0A020000CB0015EAF5@smtp.medicine.umaryland.edu>
Message-ID: <CAJuCY5x5artGKQGxhT+obmxQnkM5=Dp0j6dq7e5PyJ3EFOp+Zw@mail.gmail.com>

Dear John,

Please send questions on mixed models to r-sig-mixedmodels.

Your model is too complex for the data. You're fitted time*CorT as random
slopes. These random effects require 10 parameters. But you have only 4
data points per level of SS. Furthermore within each level of SS only one
level of CorT exists. So fitting the time:CorT interaction as random slope
is nonsens.

So you need to simplify of the model (or get more data). An intercept only
random effect is about of far as you can go with this dataset. A random
slope along time is doable but I won't trust it since you are fitting a
model to only 4 points.

fit1 <- lme(value ~ time * CorT, random = ~1|SS, data = data10)
fit2 <- lme(value ~ time * CorT, random = ~time|SS, data = data10)

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-08-25 16:48 GMT+02:00 John Sorkin <jsorkin at grecc.umaryland.edu>:

> I am getting a warning message when I run lme:
>
> Warning message:
> In lme.formula(fixed = value ~ CorT + time + CorT * time, data = GD) :
>   fewer observations than random effects in all level 1 groups
> I don't know what the message means, nor if I need to be concerned about
> the message. I would be
> grateful if someone could explain the message to me, and tell me if I need
> to have concern.
> My data and code follows. You should be able to copy, paste and run the
> code. (n.b. you will need nlme).
> Thank you,
> John
>
> library(nlme)
> data10 <- structure(list(SS = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
>                       11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L,
> 21L, 22L, 23L,
>                       24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L,
> 34L, 35L, 36L,
>                       37L, 38L, 39L, 40L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L,
>                       11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L,
> 21L, 22L, 23L,
>                       24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L,
> 34L, 35L, 36L,
>                       37L, 38L, 39L, 40L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L,
>                       11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L,
> 21L, 22L, 23L,
>                       24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L,
> 34L, 35L, 36L,
>                       37L, 38L, 39L, 40L),
>                       group = structure(c(1L, 1L, 1L, 1L, 1L,
>                       1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 2L,
>                       2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L,
>                       2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L,
>                       1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L,
>                       2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L,
> 1L, 1L, 1L,
>                       1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 2L,
>                       2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L,
>                       2L, 2L, 2L), .Label = c("Cont", "Inte"), class =
> "factor"),
>                       time = c(0L,0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 0L,
>                       0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L,
>                       0L, 0L, 0L, 0L, 0L, 0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L,
>                       3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L,
>                       3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 6L,
>                       6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L,
>                       6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L,
>                       6L, 6L, 6L, 6L, 6L, 6L, 6L),
>                       value = c(2, 1, 3, 6, 1, 5, 4, 4,
>                       3, 4, 5, 8, 4, 4, 0, 10, 3, 0, 4, 6,
> 7.86633577663451, 14.8276520497166,
>                       5.82301333779469, 6.28030818421394,
> 7.63550981180742, 7.12941627483815,
>                       14.4640282960609, 8.45473791006953,
> 9.05422623036429, 10.3654135158285,
>                       7.75828687706962, 9.05671408865601,
> 9.35509188333526, 8.22054158896208,
>                       5.03435689257458, 14.7296907380223,
> 6.12912589916959, 10.4857219522819,
>                       13.7229738035239, 13.6259456002153,
> 7.28073637914354, 5.54352982843898,
>                       8.01713229269774, 13.2061931600758,
> 3.76887153466896, 10.7523541087606,
>                       9.6018583095559, 9.62481826991277, 8.90923221009558,
> 8.85276119502607,
>                       10.9778885179292, 13.4521386035968,
> 9.95012926745246, 7.78767098907235,
>                       5.47606805783807, 16.266090481022, 8.10664718517709,
> 3.98960108796381,
>                       10.1788924241439, 9.16177207287154,
> 11.6541174116198, 19.055363149052,
>                       10.4729343696394, 12.9615216852694,
> 10.3448541992752, 12.1246619594601,
>                       17.9078516870675, 14.1546013378432,
> 14.3556335566072, 13.7020998307993,
>                       12.2669613611438, 13.6968944583291,
> 16.0242423205925, 14.1618907899469,
>                       11.6571628686932, 20.6208065318508,
> 10.5981108892906, 16.506205140693,
>                       19.8382587955876, 18.8215423103255,
> 13.6293066791555, 10.679427547606,
>                       14.5715854764237, 18.0672964438053,
> 8.64819129644325, 16.5046323205086,
>                       14.933146372713, 13.0224731390702, 13.1364074268251,
> 12.7299140722498,
>                       16.3687231173825, 17.3307585790136,
> 14.8835947338426, 13.7832964561028,
>                       8.18806783970065, 20.4643754783345, 13.927444172043,
> 7.95214003187942,
>                       15.8500600646401, 14.863828811346, 16.3418851303983,
> 23.9363727442689,
>                       15.6973592017088, 16.8376901116903,
> 16.4265975193717, 18.3862045830691,
>                       23.7260777608949, 19.6736595029528,
> 18.7411384574001, 21.5299075269243,
>                       18.7672717818268, 18.6586905356669,
> 20.1908194122778, 19.6037057845507,
>                       16.2952035024787, 25.2275624425201,
> 15.7628539929276, 21.2326533842687,
>                       25.3146615100186, 24.5526929132951),
>                       baseline = c(2, 1, 3, 6,
>                       1, 5, 4, 4, 3, 4, 5, 8, 4, 4, 0, 10, 3, 0, 4, 6,
> 7.86633577663451,
>                       14.8276520497166, 5.82301333779469,
> 6.28030818421394, 7.63550981180742,
>                       7.12941627483815, 14.4640282960609,
> 8.45473791006953, 9.05422623036429,
>                       10.3654135158285, 7.75828687706962,
> 9.05671408865601, 9.35509188333526,
>                       8.22054158896208, 5.03435689257458,
> 14.7296907380223, 6.12912589916959,
>                       10.4857219522819, 13.7229738035239,
> 13.6259456002153, 2, 1, 3,
>                       6, 1, 5, 4, 4, 3, 4, 5, 8, 4, 4, 0, 10, 3, 0, 4, 6,
> 7.86633577663451,
>                       14.8276520497166, 5.82301333779469,
> 6.28030818421394, 7.63550981180742,
>                       7.12941627483815, 14.4640282960609,
> 8.45473791006953, 9.05422623036429,
>                       10.3654135158285, 7.75828687706962,
> 9.05671408865601, 9.35509188333526,
>                       8.22054158896208, 5.03435689257458,
> 14.7296907380223, 6.12912589916959,
>                       10.4857219522819, 13.7229738035239,
> 13.6259456002153, 2, 1, 3,
>                       6, 1, 5, 4, 4, 3, 4, 5, 8, 4, 4, 0, 10, 3, 0, 4, 6,
> 7.86633577663451,
>                       14.8276520497166, 5.82301333779469,
> 6.28030818421394, 7.63550981180742,
>                       7.12941627483815, 14.4640282960609,
> 8.45473791006953, 9.05422623036429,
>                       10.3654135158285, 7.75828687706962,
> 9.05671408865601, 9.35509188333526,
>                       8.22054158896208, 5.03435689257458,
> 14.7296907380223, 6.12912589916959,
>                       10.4857219522819, 13.7229738035239,
> 13.6259456002153),
>                       CorT = c(0,
>                       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 1, 1,
>                       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 0, 0, 0,
>                       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 1, 1, 1, 1,
>                       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
> 0, 0, 0, 0,
>                       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,
> 1, 1, 1, 1,
>                       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)),
>                       row.names = c(NA,
>                       -120L), .Names = c("SS", "group", "time", "value",
> "baseline",
>                       "CorT"), class = "data.frame")
> data10
>
> GD2<- groupedData(value~time+CorT+time*CorT|SS,data=data10,FUN=mean)
> fit1 <- lme(GD2)
> summary(fit1)
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:16}}


From petr.pikal at precheza.cz  Fri Aug 26 16:11:47 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 26 Aug 2016 14:11:47 +0000
Subject: [R] Hickman models with two binary dependent variables in R
In-Reply-To: <7E6E6DBE-BDCA-4B2A-9FB1-9F4A825058FD@gmail.com>
References: <7E6E6DBE-BDCA-4B2A-9FB1-9F4A825058FD@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503A53C@SRVEXCHMBX.precheza.cz>

Hi

See in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Faradj
> Koliev
> Sent: Thursday, August 25, 2016 12:32 PM
> To: r-help at r-project.org
> Subject: [R] Hickman models with two binary dependent variables in R
>
> Hi everyone,
>
> How do I run Heckman models in R with two binary dependent variables?
>
> sampleSelection package in R works with standard heckman models ( binary
> DV for the selection equation and continuous DV for the outcome equation).
> In my case dependent variables are both binary (actually ordered but I didn?t
> find anything on that)

From help page

The endogenous variable of the argument 'selection' must have exactly two levels (e.g. 'FALSE' and 'TRUE', or '0' and '1'). By default the levels are sorted in increasing order ('FALSE' is before 'TRUE', and '0' is before '1'). This also applies for the binary outcome equation. For continuous-oucome cases, the dependent variable(s) should be numeric.

seems to me that both equatio0ns can have binary values.


>
> So using sampleSelection package one could do this by running:
>
> SelectionEquation <- binaryDV1 ~ x1+x2+x3+x4
>
> OutcomeEquation <-  binaryDV2~o7+x1+x4+x5
>
> HeckmanModel <- heckit(SelectionEquation,OutcomeEquation,
> data=mydata, method="2step")
>
>
> The problem is that heckit() doesn?t work here. I think in STATA one could

What does it mean. Be more specific.

And provide some data (preferably by dput).
Or at least result of str(yourdata) to show that they are appropriate to the function.
And do not post in HTML.

Cheers
Petr

> use heckprob command for this. Anyone who knows more than me?
>
> Thanks!
>
>
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From cimentadaj at gmail.com  Fri Aug 26 20:11:15 2016
From: cimentadaj at gmail.com (Jorge Cimentada)
Date: Fri, 26 Aug 2016 20:11:15 +0200
Subject: [R] Improving function that estimates regressions for all variables
	specified
Message-ID: <CALdB+JH6QBnjP6jLgcVM7YhBHiAbkBh=E_+3sqY=TWqKPTuvew@mail.gmail.com>

Hi, I'd like some feedback on how to make this function more "quicker and
parsimonious".

I normally run several regressions like this:
y ~ x1
y ~ x1 + x2
y ~ x1 + x2 +xn

Instead, I created a function in which I specify y, x1 and x2 and the
function automatically generates:
y ~ x1
y ~ x1 + x2
y ~ x1 + x2 +xn

This is the function:

models <- function(dv, covariates, data) {
    dv <- paste(dv, "~ 1")
    combinations <- lapply(1:length(covariates), function(i) seq(1:i))
    formulas <- lapply(combinations, function(p) x <-
as.formula(paste(c(dv, covariates[p]), collapse=" + ")))
    results <- lapply(formulas, function(o) lm(o, data=data))
    return(results)
}

And an example:
models("mpg",c("cyl","disp","hp","am"), mtcars)

I'm concerned about the time that it takes when using other regression
models, such as those with the survey package(I know these models are heavy
and take time) but I'm sure that the function has room for improvement.

I'd also like to specify the variables as a formula. I managed to do it but
I get different results when using things like scale() for predictors.

Formula version of the function:
models2 <- function(formula, data) {
    dv <- paste(all.vars(formula)[1], " ~ 1")
    covariates <- all.vars(formula)[-1]
    combinations <- lapply(1:length(covariates), function(i) seq(1:i))
    lfo <- lapply(combinations, function(p) x <- as.formula(paste(c(dv,
covariates[p]), collapse=" + ")))
    results <- lapply(lfo, function(o) lm(o, data=data))
    return(results)
}

models("mpg",c("cyl","scale(disp)"), mtcars)

models2(mpg ~ cyl + scale(disp), mtcars)

See the difference between the disp variables?

Any feedback is appreciated!


*Jorge Cimentada*
*Ph.D. Candidate*
Dpt. Ci?ncies Pol?tiques i Socials
Ramon Trias Fargas, 25-27 | 08005 Barcelona

Office 24.331
[Tel.] 697 382 009www.jorgecimentada.com

	[[alternative HTML version deleted]]


From jfca283 at gmail.com  Fri Aug 26 17:05:21 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Fri, 26 Aug 2016 12:05:21 -0300
Subject: [R] Importint stata file and using value labels
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503A48E@SRVEXCHMBX.precheza.cz>
References: <CALBYkjJLbWXdS17zH=P_rf-rj7PPnTGp1TtKoC5Lk-bmkNtKVw@mail.gmail.com>
	<20160825163904.Horde.1WBb35Cp4ixvo0Euondfg9s@mail.sapo.pt>
	<CALBYkj+jmgtqz24LJw1ArtgCbPafjkL48qfzujHRjQ9-azc8dQ@mail.gmail.com>
	<20160825174234.Horde.R6gdOj82yuK987Jj6o5_qEp@mail.sapo.pt>
	<CALBYkjLKgmA0W3Ecvh94eLniWVECU8i5ys8j5+zJkAeyOs+khA@mail.gmail.com>
	<20160825201107.Horde._Vy9S_eCHmMTdmtkvdhot_t@mail.sapo.pt>
	<CALBYkjJ9=8hTV=+dL0nBaVV+Lnw1QqNAoR98Q63Sr7wJzRq=sA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503A48E@SRVEXCHMBX.precheza.cz>
Message-ID: <CALBYkjLFSAvKzb+=srtRJV_E-MTUa7H+gwuRneWsngibeknUpA@mail.gmail.com>

Yep. Im a bit stalled.
I can't find the option to import only the values and drop the value labels
from the dta file.
Im quite sure R can do that. Then i'd only used the values and i'd rely on
my memory.
It isn't a bad alternative.


On Fri, Aug 26, 2016 at 4:11 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> You can use
>
> as.numeric(sex)
>
> to get numeric values for factor variable. This is sometimes handy for
> plotting.
>
> However if you throw away labels how do you know what naumber belongs to
> which factor level?
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Juan
> > Ceccarelli Arias
> > Sent: Thursday, August 25, 2016 9:15 PM
> > To: ruipbarradas at sapo.pt
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Importint stata file and using value labels
> >
> > Mmm...The other option working with  R for importing the dta file but
> > obtaining the values and deleting or ignoring the value labels.
> > I think some time ago i did that, but now i can't remember it.
> >
> >
> > On Thu, Aug 25, 2016 at 4:11 PM, <ruipbarradas at sapo.pt> wrote:
> >
> > > So you should do
> > >
> > > table(region[sex=="Hombre"],type[sex=="Hombre"]
> > >
> > > Rui Barradas
> > >
> > >
> > > Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
> > >
> > > str(sex)
> > >>>
> > >>  Factor w/ 2 levels "Hombre","Mujer": 1 2 2 1 2 2 1 1 1 1 ...
> > >>   On Thu, Aug 25, 2016 at 1:42 PM, <ruipbarradas at sapo.pt> wrote:
> > >>
> > >>> _Maybe sex is a factor and Man its label. Factors are coded
> > >>> internally as integers, to see it use
> > >>>
> > >>> str(sex)
> > >>>
> > >>> Rui Barradas
> > >>>  _
> > >>>
> > >>> _Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:_
> > >>>
> > >>> _Nop. I didn't work. But using the following it does work.
> > >>>> table(region[sex=="Men"],type[sex=="Men"])_
> > >>>> _When i use the dta file with stata i declare the condition with
> > >>>> sex==1 and not sex=="Man"._ _  _ _On Thu, Aug 25, 2016 at 12:39 PM,
> > >>>> <ruipbarradas at sapo.pt> wrote: _
> > >>>>
> > >>>>> __Hello,
> > >>>>>
> > >>>>> Try instead
> > >>>>>
> > >>>>> table(region[sex==1],type[sex=_=1])
> > >>>>>
> > >>>>> To test for equality use == not =.
> > >>>>>
> > >>>>> Hope this helps,
> > >>>>>
> > >>>>> Rui Barradas
> > >>>>>  _
> > >>>>>
> > >>>>> __Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:__
> > >>>>>
> > >>>>> _ _
> > >>>>>> __Hi
> > >>>>>> Im a bit lost.
> > >>>>>> Ive imported a stata13 file. When i try to make a simple
> > >>>>>> table(region[sex=1],type[sex=_1]) i get something as
> > >>>>>>           type1 type2
> > >>>>>> region1 0 0
> > >>>>>> region2 0 0
> > >>>>>> region3 0 0
> > >>>>>>
> > >>>>>> I don't know how to operate with the value labels.
> > >>>>>> Sex is defined as 1 as "Man" and 2 as "Female".
> > >>>>>> And region1 is 1, region2 is 2 and so on.
> > >>>>>> So, how can i make reference to the value and not the value
> > >>>>>> labels when i write down some condition or statement ?
> > >>>>>> I know is simple, but using the help for readstata13 didn't
> > >>>>>> clarify it to me.
> > >>>>>> Thanks for your help and time.
> > >>>>>>  _
> > >>>>>>
> > >>>>>> __        [[alternative HTML version deleted]]
> > >>>>>>
> > >>>>>> _______________________________________________
> > >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>>> PLEASE do read the posting guide http://www.R-project.org/posti
> > >>>>>> ng-guide.htmland provide commented, minimal, self-contained,
> > >>>>>> reproducible code. _ _ _ _ _
> > >>>>>>
> > >>>>>
> > >>>>> __ __
> > >>>>>
> > >>>>
> > >>>> _ _
> > >>>> _ _
> > >>>>
> > >>>
> > >>> _ _
> > >>>
> > >>
> > >
> > >
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From n.msindai.09 at ucl.ac.uk  Fri Aug 26 14:49:48 2016
From: n.msindai.09 at ucl.ac.uk (Msindai, Nadejda)
Date: Fri, 26 Aug 2016 12:49:48 +0000
Subject: [R] Exponential population model
Message-ID: <DB6PR0101MB25502D2F7A21B3796668FF318EEC0@DB6PR0101MB2550.eurprd01.prod.exchangelabs.com>

Dear admin

I am writing to ask for help with writing an R script to model the current population size using life history data (I do not know the intrinsic rate of increase (r)).

My study population are a group of introduced chimpanzees, that were released by the Frankfurt Zoological Society in 1966-1969 onto an island in Lake Victoria.

Thus I want to run a density independent population model using life history data, with 0 net migration/immigration (so this is a closed system).


These are the individuals entering the system (in my case arriving on the island), after 1969 no new animals arrive.

Year    1966    1966    1966    1966    1966    1966    1966    1968    1969    1966    1966    1966    1966    1968    1969
Animal ID       F1      F2      F3      F4      F5      F6      F7      F8      F9      M1      M2      M3      M4      M5      M6
DOB     1955    1955    1956    1957    1958    1959    1955    1960    1960    1958    1959    1959    1962    1960    1960

Notes:  Year is the year animal was released into the population
        F=female
        M=male
        DOB=date of birth


Using the following life history data I want to estimate the population size for the year 1979, 1989, 1999, and 2014, as well as future projection for 2019, 2029 etc.

Age at first birth for females: 11 years
Birth interval: 55.2 months
Age at last birth: 50 years (in 40-50 years only 47% of females have offspring)
Survival to 8 years = 67.7%(Female) 51.4%(Male)
Survival to 15 years 41%(Female) 27%(Male)
Survival 15-40 years 18%(Female) 11%(Male)
Survival 40+ years 7%(M/F)



Birth ratio set as ___M = Male, F = Female (set as 50:50)






I hope you can be of help

Kind regards

Josephine




	[[alternative HTML version deleted]]


From leonardo.guizzetti at gmail.com  Fri Aug 26 20:53:08 2016
From: leonardo.guizzetti at gmail.com (Leonardo Guizzetti)
Date: Fri, 26 Aug 2016 14:53:08 -0400
Subject: [R] Labelling interaction axes of a nomogram using rms
Message-ID: <CAKM08C5fcH+Q3ktJWWbmdP8H-jdvDwUqZuRQXtsnj5GAi6Bp0g@mail.gmail.com>

Good afternoon,

I have tried searching and have hit a wall with my own trial and error. I
have been able to use "nice" labels for non-interacted variables by setting
them using Newlabels(), but I am unable to do so for the interaction terms
following a fit.

Can you please offer a suggestion?

Kind regards,
Leonardo

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Aug 27 04:32:55 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 26 Aug 2016 19:32:55 -0700
Subject: [R] Exponential population model
In-Reply-To: <DB6PR0101MB25502D2F7A21B3796668FF318EEC0@DB6PR0101MB2550.eurprd01.prod.exchangelabs.com>
References: <DB6PR0101MB25502D2F7A21B3796668FF318EEC0@DB6PR0101MB2550.eurprd01.prod.exchangelabs.com>
Message-ID: <07BFE076-4821-406C-BF6B-762B774B062B@comcast.net>


> On Aug 26, 2016, at 5:49 AM, Msindai, Nadejda <n.msindai.09 at ucl.ac.uk> wrote:
> 
> Dear admin
> 
> I am writing to ask for help with writing an R script to model the current population size using life history data (I do not know the intrinsic rate of increase (r)).
> 
> My study population are a group of introduced chimpanzees, that were released by the Frankfurt Zoological Society in 1966-1969 onto an island in Lake Victoria.
> 
> Thus I want to run a density independent population model using life history data, with 0 net migration/immigration (so this is a closed system).
> 
> 
> These are the individuals entering the system (in my case arriving on the island), after 1969 no new animals arrive.
> 
> Year    1966    1966    1966    1966    1966    1966    1966    1968    1969    1966    1966    1966    1966    1968    1969
> Animal ID       F1      F2      F3      F4      F5      F6      F7      F8      F9      M1      M2      M3      M4      M5      M6
> DOB     1955    1955    1956    1957    1958    1959    1955    1960    1960    1958    1959    1959    1962    1960    1960
> 
> Notes:  Year is the year animal was released into the population
>        F=female
>        M=male
>        DOB=date of birth
> 
> 
> Using the following life history data I want to estimate the population size for the year 1979, 1989, 1999, and 2014, as well as future projection for 2019, 2029 etc.
> 
> Age at first birth for females: 11 years
> Birth interval: 55.2 months
> Age at last birth: 50 years (in 40-50 years only 47% of females have offspring)
> Survival to 8 years = 67.7%(Female) 51.4%(Male)
> Survival to 15 years 41%(Female) 27%(Male)
> Survival 15-40 years 18%(Female) 11%(Male)
> Survival 40+ years 7%(M/F)
> 
> 
> 
> Birth ratio set as ___M = Male, F = Female (set as 50:50)
> 

This looks like a homework question and Rhelp is specifically announced as not doing homework. See the Posting Guide.

-- 
David.
> 
> 
> 
> I hope you can be of help
> 
> Kind regards
> 
> Josephine
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Aug 27 04:35:17 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 26 Aug 2016 19:35:17 -0700
Subject: [R] Labelling interaction axes of a nomogram using rms
In-Reply-To: <CAKM08C5fcH+Q3ktJWWbmdP8H-jdvDwUqZuRQXtsnj5GAi6Bp0g@mail.gmail.com>
References: <CAKM08C5fcH+Q3ktJWWbmdP8H-jdvDwUqZuRQXtsnj5GAi6Bp0g@mail.gmail.com>
Message-ID: <0EE640D7-33B8-49EE-82A5-ACC74494EB13@comcast.net>


> On Aug 26, 2016, at 11:53 AM, Leonardo Guizzetti <leonardo.guizzetti at gmail.com> wrote:
> 
> Good afternoon,
> 
> I have tried searching and have hit a wall with my own trial and error. I
> have been able to use "nice" labels for non-interacted variables by setting
> them using Newlabels(), but I am unable to do so for the interaction terms
> following a fit.
> 
> Can you please offer a suggestion?

My suggestion is that you post a minimal example.

-- 
David.
> 
> Kind regards,
> Leonardo
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From arne.henningsen at gmail.com  Sat Aug 27 10:39:53 2016
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Sat, 27 Aug 2016 10:39:53 +0200
Subject: [R] Hickman models with two binary dependent variables in R
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503A53C@SRVEXCHMBX.precheza.cz>
References: <7E6E6DBE-BDCA-4B2A-9FB1-9F4A825058FD@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503A53C@SRVEXCHMBX.precheza.cz>
Message-ID: <CAMTWbJikZF5LjwNjARY5mMJCt2p4EEqK26zE3bcEgK62vmOXZQ@mail.gmail.com>

See also:

http://r-forge.r-project.org/forum/forum.php?thread_id=31866&forum_id=844&group_id=256



On 26 August 2016 at 16:11, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Hi
>
> See in line
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Faradj
>> Koliev
>> Sent: Thursday, August 25, 2016 12:32 PM
>> To: r-help at r-project.org
>> Subject: [R] Hickman models with two binary dependent variables in R
>>
>> Hi everyone,
>>
>> How do I run Heckman models in R with two binary dependent variables?
>>
>> sampleSelection package in R works with standard heckman models ( binary
>> DV for the selection equation and continuous DV for the outcome equation).
>> In my case dependent variables are both binary (actually ordered but I didn?t
>> find anything on that)
>
> From help page
>
> The endogenous variable of the argument 'selection' must have exactly two levels (e.g. 'FALSE' and 'TRUE', or '0' and '1'). By default the levels are sorted in increasing order ('FALSE' is before 'TRUE', and '0' is before '1'). This also applies for the binary outcome equation. For continuous-oucome cases, the dependent variable(s) should be numeric.
>
> seems to me that both equatio0ns can have binary values.
>
>
>>
>> So using sampleSelection package one could do this by running:
>>
>> SelectionEquation <- binaryDV1 ~ x1+x2+x3+x4
>>
>> OutcomeEquation <-  binaryDV2~o7+x1+x4+x5
>>
>> HeckmanModel <- heckit(SelectionEquation,OutcomeEquation,
>> data=mydata, method="2step")
>>
>>
>> The problem is that heckit() doesn?t work here. I think in STATA one could
>
> What does it mean. Be more specific.
>
> And provide some data (preferably by dput).
> Or at least result of str(yourdata) to show that they are appropriate to the function.
> And do not post in HTML.
>
> Cheers
> Petr
>
>> use heckprob command for this. Anyone who knows more than me?
>>
>> Thanks!
>>
>>
>>
>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Arne Henningsen
http://www.arne-henningsen.name


From faradj.g at gmail.com  Sat Aug 27 16:11:28 2016
From: faradj.g at gmail.com (Faradj Koliev)
Date: Sat, 27 Aug 2016 16:11:28 +0200
Subject: [R] Hickman models with two binary dependent variables in R
In-Reply-To: <CAMTWbJikZF5LjwNjARY5mMJCt2p4EEqK26zE3bcEgK62vmOXZQ@mail.gmail.com>
References: <7E6E6DBE-BDCA-4B2A-9FB1-9F4A825058FD@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503A53C@SRVEXCHMBX.precheza.cz>
	<CAMTWbJikZF5LjwNjARY5mMJCt2p4EEqK26zE3bcEgK62vmOXZQ@mail.gmail.com>
Message-ID: <B0591E30-E86A-4418-AA42-6A29A0B0C4D5@gmail.com>

Dear Arne, 

Many thanks for this, 

It actually worked with heckit() command as well, do I need to use selection()? 

Also, I would be really grateful if you can suggest a package that would allow for estimation of heckman models with two ordered variables (0-1-2). Can sampleSelection handle this? 

Warm regards, 
Faradj 

> 27 aug. 2016 kl. 10:39 skrev Arne Henningsen <arne.henningsen at gmail.com>:
> 
> See also:
> 
> http://r-forge.r-project.org/forum/forum.php?thread_id=31866&forum_id=844&group_id=256
> 
> 
> 
> On 26 August 2016 at 16:11, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>> Hi
>> 
>> See in line
>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Faradj
>>> Koliev
>>> Sent: Thursday, August 25, 2016 12:32 PM
>>> To: r-help at r-project.org
>>> Subject: [R] Hickman models with two binary dependent variables in R
>>> 
>>> Hi everyone,
>>> 
>>> How do I run Heckman models in R with two binary dependent variables?
>>> 
>>> sampleSelection package in R works with standard heckman models ( binary
>>> DV for the selection equation and continuous DV for the outcome equation).
>>> In my case dependent variables are both binary (actually ordered but I didn?t
>>> find anything on that)
>> 
>> From help page
>> 
>> The endogenous variable of the argument 'selection' must have exactly two levels (e.g. 'FALSE' and 'TRUE', or '0' and '1'). By default the levels are sorted in increasing order ('FALSE' is before 'TRUE', and '0' is before '1'). This also applies for the binary outcome equation. For continuous-oucome cases, the dependent variable(s) should be numeric.
>> 
>> seems to me that both equatio0ns can have binary values.
>> 
>> 
>>> 
>>> So using sampleSelection package one could do this by running:
>>> 
>>> SelectionEquation <- binaryDV1 ~ x1+x2+x3+x4
>>> 
>>> OutcomeEquation <-  binaryDV2~o7+x1+x4+x5
>>> 
>>> HeckmanModel <- heckit(SelectionEquation,OutcomeEquation,
>>> data=mydata, method="2step")
>>> 
>>> 
>>> The problem is that heckit() doesn?t work here. I think in STATA one could
>> 
>> What does it mean. Be more specific.
>> 
>> And provide some data (preferably by dput).
>> Or at least result of str(yourdata) to show that they are appropriate to the function.
>> And do not post in HTML.
>> 
>> Cheers
>> Petr
>> 
>>> use heckprob command for this. Anyone who knows more than me?
>>> 
>>> Thanks!
>>> 
>>> 
>>> 
>>> 
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>> 
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>> 
>> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
>> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>> 
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
>> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Arne Henningsen
> http://www.arne-henningsen.name


	[[alternative HTML version deleted]]


From friendly at yorku.ca  Sat Aug 27 17:55:04 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 27 Aug 2016 11:55:04 -0400
Subject: [R] Importint stata file and using value labels
In-Reply-To: <CALBYkjLFSAvKzb+=srtRJV_E-MTUa7H+gwuRneWsngibeknUpA@mail.gmail.com>
References: <CALBYkjJLbWXdS17zH=P_rf-rj7PPnTGp1TtKoC5Lk-bmkNtKVw@mail.gmail.com>
	<20160825163904.Horde.1WBb35Cp4ixvo0Euondfg9s@mail.sapo.pt>
	<CALBYkj+jmgtqz24LJw1ArtgCbPafjkL48qfzujHRjQ9-azc8dQ@mail.gmail.com>
	<20160825174234.Horde.R6gdOj82yuK987Jj6o5_qEp@mail.sapo.pt>
	<CALBYkjLKgmA0W3Ecvh94eLniWVECU8i5ys8j5+zJkAeyOs+khA@mail.gmail.com>
	<20160825201107.Horde._Vy9S_eCHmMTdmtkvdhot_t@mail.sapo.pt>
	<CALBYkjJ9=8hTV=+dL0nBaVV+Lnw1QqNAoR98Q63Sr7wJzRq=sA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503A48E@SRVEXCHMBX.precheza.cz>
	<CALBYkjLFSAvKzb+=srtRJV_E-MTUa7H+gwuRneWsngibeknUpA@mail.gmail.com>
Message-ID: <776d0a12-9f7b-2327-f69d-70b1fe1fcfc7@yorku.ca>

On 8/26/2016 11:05 AM, Juan Ceccarelli Arias wrote:
> Yep. Im a bit stalled.
> I can't find the option to import only the values and drop the value labels
> from the dta file.
> Im quite sure R can do that. Then i'd only used the values and i'd rely on
> my memory.
> It isn't a bad alternative.
>

Hint: use str() to see the class of what you've read.
Then try as.data.frame() on the resulting object read from the .dta file.


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From friendly at yorku.ca  Sat Aug 27 17:55:04 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 27 Aug 2016 11:55:04 -0400
Subject: [R] Importint stata file and using value labels
In-Reply-To: <CALBYkjLFSAvKzb+=srtRJV_E-MTUa7H+gwuRneWsngibeknUpA@mail.gmail.com>
References: <CALBYkjJLbWXdS17zH=P_rf-rj7PPnTGp1TtKoC5Lk-bmkNtKVw@mail.gmail.com>
	<20160825163904.Horde.1WBb35Cp4ixvo0Euondfg9s@mail.sapo.pt>
	<CALBYkj+jmgtqz24LJw1ArtgCbPafjkL48qfzujHRjQ9-azc8dQ@mail.gmail.com>
	<20160825174234.Horde.R6gdOj82yuK987Jj6o5_qEp@mail.sapo.pt>
	<CALBYkjLKgmA0W3Ecvh94eLniWVECU8i5ys8j5+zJkAeyOs+khA@mail.gmail.com>
	<20160825201107.Horde._Vy9S_eCHmMTdmtkvdhot_t@mail.sapo.pt>
	<CALBYkjJ9=8hTV=+dL0nBaVV+Lnw1QqNAoR98Q63Sr7wJzRq=sA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503A48E@SRVEXCHMBX.precheza.cz>
	<CALBYkjLFSAvKzb+=srtRJV_E-MTUa7H+gwuRneWsngibeknUpA@mail.gmail.com>
Message-ID: <776d0a12-9f7b-2327-f69d-70b1fe1fcfc7@yorku.ca>

On 8/26/2016 11:05 AM, Juan Ceccarelli Arias wrote:
> Yep. Im a bit stalled.
> I can't find the option to import only the values and drop the value labels
> from the dta file.
> Im quite sure R can do that. Then i'd only used the values and i'd rely on
> my memory.
> It isn't a bad alternative.
>

Hint: use str() to see the class of what you've read.
Then try as.data.frame() on the resulting object read from the .dta file.


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From jayaakrish at gmail.com  Sat Aug 27 03:20:37 2016
From: jayaakrish at gmail.com (Jaya Krishnan)
Date: Fri, 26 Aug 2016 18:20:37 -0700
Subject: [R] Leaflet package error while adding Polygons
Message-ID: <CAJmi+1A-Ln1wg1_3=K_d258CKFkw+TkUAPSDbMu5B9YwpSv+1A@mail.gmail.com>

Hi,

I'm trying to use leaflet for web-mapping. While trying to add polygons, I
get this error

Error in `*tmp*`$x : $ operator is invalid for atomic vectors
Any help is appreciated.
Thanks,

Jaya

?

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Aug 27 18:39:56 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 27 Aug 2016 12:39:56 -0400
Subject: [R] Leaflet package error while adding Polygons
In-Reply-To: <CAJmi+1A-Ln1wg1_3=K_d258CKFkw+TkUAPSDbMu5B9YwpSv+1A@mail.gmail.com>
References: <CAJmi+1A-Ln1wg1_3=K_d258CKFkw+TkUAPSDbMu5B9YwpSv+1A@mail.gmail.com>
Message-ID: <5bba657e-8d46-8bfb-d239-1f237367b47f@gmail.com>

On 26/08/2016 9:20 PM, Jaya Krishnan wrote:
> Hi,
>
> I'm trying to use leaflet for web-mapping. While trying to add polygons, I
> get this error
>
> Error in `*tmp*`$x : $ operator is invalid for atomic vectors
> Any help is appreciated.

You need to post what you did if you want help.  Avoiding HTML is also a 
recommendation of the posting guide (see the footer for the URL).

Duncan Murdoch

> Thanks,
>
> Jaya
>
> ?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rbaer at atsu.edu  Sat Aug 27 18:44:13 2016
From: rbaer at atsu.edu (Robert Baer)
Date: Sat, 27 Aug 2016 11:44:13 -0500
Subject: [R] Importint stata file and using value labels
In-Reply-To: <776d0a12-9f7b-2327-f69d-70b1fe1fcfc7@yorku.ca>
References: <CALBYkjJLbWXdS17zH=P_rf-rj7PPnTGp1TtKoC5Lk-bmkNtKVw@mail.gmail.com>
	<20160825163904.Horde.1WBb35Cp4ixvo0Euondfg9s@mail.sapo.pt>
	<CALBYkj+jmgtqz24LJw1ArtgCbPafjkL48qfzujHRjQ9-azc8dQ@mail.gmail.com>
	<20160825174234.Horde.R6gdOj82yuK987Jj6o5_qEp@mail.sapo.pt>
	<CALBYkjLKgmA0W3Ecvh94eLniWVECU8i5ys8j5+zJkAeyOs+khA@mail.gmail.com>
	<20160825201107.Horde._Vy9S_eCHmMTdmtkvdhot_t@mail.sapo.pt>
	<CALBYkjJ9=8hTV=+dL0nBaVV+Lnw1QqNAoR98Q63Sr7wJzRq=sA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503A48E@SRVEXCHMBX.precheza.cz>
	<CALBYkjLFSAvKzb+=srtRJV_E-MTUa7H+gwuRneWsngibeknUpA@mail.gmail.com>
	<776d0a12-9f7b-2327-f69d-70b1fe1fcfc7@yorku.ca>
Message-ID: <dbf09529-163d-8b13-8403-ae2e43219d30@atsu.edu>

There has been some good advice not to lose the labels, but perhaps this 
gets you where you seem determined to go?

?read.dta

read.dta(file, convert.dates = TRUE, convert.factors = TRUE,
          missing.type = FALSE,
          convert.underscore = FALSE, warn.missing.labels = TRUE)

or

library(readstata13)

?read.dta13

read.dta13(file, convert.factors = TRUE, generate.factors = FALSE,
   encoding = NULL, fromEncoding = NULL, convert.underscore = FALSE,
   missing.type = FALSE, convert.dates = TRUE, replace.strl = FALSE,
   add.rownames = FALSE, nonint.factors = FALSE)

Perhaps the convert. factors setting at FALSE?


On 08/27/2016 10:55 AM, Michael Friendly wrote:
> On 8/26/2016 11:05 AM, Juan Ceccarelli Arias wrote:
>> Yep. Im a bit stalled.
>> I can't find the option to import only the values and drop the value 
>> labels
>> from the dta file.
>> Im quite sure R can do that. Then i'd only used the values and i'd 
>> rely on
>> my memory.
>> It isn't a bad alternative.
>>
>
> Hint: use str() to see the class of what you've read.
> Then try as.data.frame() on the resulting object read from the .dta file.
>
>


From rbaer at atsu.edu  Sat Aug 27 18:44:13 2016
From: rbaer at atsu.edu (Robert Baer)
Date: Sat, 27 Aug 2016 11:44:13 -0500
Subject: [R] Importint stata file and using value labels
In-Reply-To: <776d0a12-9f7b-2327-f69d-70b1fe1fcfc7@yorku.ca>
References: <CALBYkjJLbWXdS17zH=P_rf-rj7PPnTGp1TtKoC5Lk-bmkNtKVw@mail.gmail.com>
	<20160825163904.Horde.1WBb35Cp4ixvo0Euondfg9s@mail.sapo.pt>
	<CALBYkj+jmgtqz24LJw1ArtgCbPafjkL48qfzujHRjQ9-azc8dQ@mail.gmail.com>
	<20160825174234.Horde.R6gdOj82yuK987Jj6o5_qEp@mail.sapo.pt>
	<CALBYkjLKgmA0W3Ecvh94eLniWVECU8i5ys8j5+zJkAeyOs+khA@mail.gmail.com>
	<20160825201107.Horde._Vy9S_eCHmMTdmtkvdhot_t@mail.sapo.pt>
	<CALBYkjJ9=8hTV=+dL0nBaVV+Lnw1QqNAoR98Q63Sr7wJzRq=sA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503A48E@SRVEXCHMBX.precheza.cz>
	<CALBYkjLFSAvKzb+=srtRJV_E-MTUa7H+gwuRneWsngibeknUpA@mail.gmail.com>
	<776d0a12-9f7b-2327-f69d-70b1fe1fcfc7@yorku.ca>
Message-ID: <dbf09529-163d-8b13-8403-ae2e43219d30@atsu.edu>

There has been some good advice not to lose the labels, but perhaps this 
gets you where you seem determined to go?

?read.dta

read.dta(file, convert.dates = TRUE, convert.factors = TRUE,
          missing.type = FALSE,
          convert.underscore = FALSE, warn.missing.labels = TRUE)

or

library(readstata13)

?read.dta13

read.dta13(file, convert.factors = TRUE, generate.factors = FALSE,
   encoding = NULL, fromEncoding = NULL, convert.underscore = FALSE,
   missing.type = FALSE, convert.dates = TRUE, replace.strl = FALSE,
   add.rownames = FALSE, nonint.factors = FALSE)

Perhaps the convert. factors setting at FALSE?


On 08/27/2016 10:55 AM, Michael Friendly wrote:
> On 8/26/2016 11:05 AM, Juan Ceccarelli Arias wrote:
>> Yep. Im a bit stalled.
>> I can't find the option to import only the values and drop the value 
>> labels
>> from the dta file.
>> Im quite sure R can do that. Then i'd only used the values and i'd 
>> rely on
>> my memory.
>> It isn't a bad alternative.
>>
>
> Hint: use str() to see the class of what you've read.
> Then try as.data.frame() on the resulting object read from the .dta file.
>
>


From leonardo.guizzetti at gmail.com  Sat Aug 27 23:25:38 2016
From: leonardo.guizzetti at gmail.com (Leonardo Guizzetti)
Date: Sat, 27 Aug 2016 17:25:38 -0400
Subject: [R] Labelling interaction axes of a nomogram using rms
In-Reply-To: <0EE640D7-33B8-49EE-82A5-ACC74494EB13@comcast.net>
References: <CAKM08C5fcH+Q3ktJWWbmdP8H-jdvDwUqZuRQXtsnj5GAi6Bp0g@mail.gmail.com>
	<0EE640D7-33B8-49EE-82A5-ACC74494EB13@comcast.net>
Message-ID: <CAKM08C7SF03oZtSeQ-i5PtFCohFDNzeJNiJDxg4fVM+t01mAxw@mail.gmail.com>

Hi David,

As suggested, here is some example code adapted from the example of the
nomogram() from the rms package.  You'll notice that variable labels are
not being applied to main effects or interaction terms.

Leonardo

rm(list = ls())
# Import libraries
require(Hmisc)
require(rms)

set.seed(12345)
n <- 1000 # define sample size
age <- rnorm(n, 0, 10)
sbp <- rnorm(n, 120, 15)
sex <- factor(sample(c(0,1), n, TRUE), levels=c(0,1),
labels=c('female','male'))
# Specify population model for log odds that Y=1
L <- 0.5*(sex=="male") + 0.01*age + 0.12*sbp + 0.02*sbp*age + rnorm(n, 0,
10)
# Simulate binary y to have Prob(y=1) = 1/[1+exp(-L)]
y <- ifelse(runif(n) < plogis(L), 1, 0)

# Create a dataframe and apply nice labels to each variable.
mydata <- data.frame(age, sbp, sex, y)
var.labels <- c(age = "Patient Age - 50 years",
                sbp = "Systolic blood pressure",
                sex = "Sex",
                y = "Outcome")
label(mydata) = lapply(names(var.labels),
                       function(x) label(mydata[,x]) <- var.labels[x])
label(mydata) # show the labels.

# Fit a model
ddist <- datadist(mydata)
options(datadist="ddist")
f <- rms::lrm(y ~ age*sbp + sex)
f
f$coefficients

# Create a nomogram.
nom <- nomogram(f, fun=plogis, lp=F, nint=10, maxscale=100,
                interact = list( sbp=c(100,140,180) ),
                fun.at=c(.01,.05,seq(.1,.9,by=.1),.95,.99),
                funlabel="Risk of Death", vnames="labels")
plot(nom)

# end
options(datadist=NULL)


On Fri, Aug 26, 2016 at 10:35 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Aug 26, 2016, at 11:53 AM, Leonardo Guizzetti <
> leonardo.guizzetti at gmail.com> wrote:
> >
> > Good afternoon,
> >
> > I have tried searching and have hit a wall with my own trial and error. I
> > have been able to use "nice" labels for non-interacted variables by
> setting
> > them using Newlabels(), but I am unable to do so for the interaction
> terms
> > following a fit.
> >
> > Can you please offer a suggestion?
>
> My suggestion is that you post a minimal example.
>
> --
> David.
> >
> > Kind regards,
> > Leonardo
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From glennmschultz at me.com  Sat Aug 27 22:56:59 2016
From: glennmschultz at me.com (Glenn Schultz)
Date: Sat, 27 Aug 2016 20:56:59 +0000 (GMT)
Subject: [R] parsing a complex file
Message-ID: <c4ebcf51-a463-4804-93a5-0224a9be024c@me.com>

All,

I have a complex file I would like to parse in R a sample is described below

The header is 1:200 and the?detail is 1 to 200. ?I have written code to parse the file so far. ?As follows:

numchar <- nchar(x = data, type = "chars")
start <- c(seq(1, numchar, 398))
end <- c(seq(398, numchar, 398))
quartile <- NULL
final <- str_sub(data, start[1:length(start)], end[1:length(end)])
quartile <- append(quartile, final)
write(quartile, Result)
data2 <- readLines(Result)

The function?gets me to data2. ?All is well so far. However, I need to send the header which begins with 1 at byte location 1 to a file and the detail which begins with 2 at byte location 1 to another file. ?When I look at data2 in RStudio ?I see the following. ?The file is 185 meg, I have the lines but I am stuck as to the next step. ?Any ideas are appreciated.

Glenn


dput of the data

"1176552 CL20031031367RBV319920901 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?217655208875{08875{08875{08875{08875{08875{22D22D22D22D22D22D13C13C13C13C13C13C0000604000{0000604000{0000604000{0000604000{0000604000{0000604000{36{36{36{36{36{36{08500{08500{08500{08500{08500{08500{1254240 CL20031031371KLV120020201 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?225424007484{07250{07375{07500{07625{08625{33F06H33H33I34{34A02A01I02{02{02A03B0001121957C0000123500{0000920000{0001280000{0001741000{0003849000{35I30{36{36{36{36{07000{07000{07000{07000{07000{07000{1254253 CL20031031371KMA620020301 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?225425306715{06250{06500{06750{06875{07000{33C23G33C33I34{34A02{01I02{02{02A02C0000946646A0000350000{0000850000{0001030000{0001205000{0001300000{35H30{36{36{36{36{06000{06000{06000{06000{06000{06000{1259455 CL20031031371RE4420020501 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?225945507045{06750{06875{07000{07250{07375{34{28B34A34B34B34C01H01G01H01H01H02C0000934444E0000360000{0000765000{0000995000{0001384000{0002184000{35I30{36{36{36{36{06500{06500{06500{06500{06500{06500{1261060 CI20031031371S5V219940101 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?226106006637{06500{06500{06625{06750{06875{05B00C04H05I06B06B11H11G11G11H11H11I0001169090I0000650000{0000950000{0001250000{0001328000{0001900000{18{18{18{18{18{18{06000{06000{06000{06000{06000{06000{1335271 CI20031031375HMU519960101 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?233527107500{07500{07500{07500{07500{07500{08B06B08E08F08F08F09D09D09D09D09E09E0000717375{0000464000{0000550000{0000770000{0001085500{0001085500{18{18{18{18{18{18{07000{07000{07000{07000{07000{07000{1440840 CL20031031380HV9519981101 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?244084006707{06500{06625{06750{06875{06875{27D03C28C29H30{30A06{05I06{06{06{06A0000615172I0000250000{0000621000{0000673000{0000750000{0000791000{36{36{36{36{36{36{06000{06000{06000{06000{06000{06000{1521993 CI20031031384E3A620000101 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?252199306937{06875{06875{06875{07000{07000{12H02H12H13{13D13E04E04E04E04E04F04F0001129428F0000700000{0000955000{0001000000{0002087000{0002087000{18{18{18{18{18{18{06500{06500{06500{06500{06500{06500{1538080 CL20031031384YXH420000501 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?253808008875{08875{08875{08875{08875{08875{31I31I31I31I31I31I04A04A04A04A04A04A0001419300{0001419300{0001419300{0001419300{0001419300{0001419300{36{36{36{36{36{36{07000{07000{07000{07000{07000{07000{1659123 CI20031031390XG8720020801 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?265912306909{06750{06750{06875{07000{07125{16E15I16C16E16F16F01E01D01D01E01E01G0000998541G0000162000{0000792000{0001156500{0001600000{0001990000{18{18{18{18{18{18{06000{06000{06000{06000{06000{06000{"


dput data2
c("1176552 CL20031031367RBV319920901 217655208875{08875{08875{08875{08875{08875{22D22D22D22D22D22D13C13C13C13C13C13C0000604000{0000604000{0000604000{0000604000{0000604000{0000604000{36{36{36{36{36{36{08500{08500{08500{08500{08500{08500{", 
"1254240 CL20031031371KLV120020201 225424007484{07250{07375{07500{07625{08625{33F06H33H33I34{34A02A01I02{02{02A03B0001121957C0000123500{0000920000{0001280000{0001741000{0003849000{35I30{36{36{36{36{07000{07000{07000{07000{07000{07000{", 
"1254253 CL20031031371KMA620020301 225425306715{06250{06500{06750{06875{07000{33C23G33C33I34{34A02{01I02{02{02A02C0000946646A0000350000{0000850000{0001030000{0001205000{0001300000{35H30{36{36{36{36{06000{06000{06000{06000{06000{06000{", 
"1259455 CL20031031371RE4420020501 225945507045{06750{06875{07000{07250{07375{34{28B34A34B34B34C01H01G01H01H01H02C0000934444E0000360000{0000765000{0000995000{0001384000{0002184000{35I30{36{36{36{36{06500{06500{06500{06500{06500{06500{", 
"1261060 CI20031031371S5V219940101 226106006637{06500{06500{06625{06750{06875{05B00C04H05I06B06B11H11G11G11H11H11I0001169090I0000650000{0000950000{0001250000{0001328000{0001900000{18{18{18{18{18{18{06000{06000{06000{06000{06000{06000{", 
"1335271 CI20031031375HMU519960101 233527107500{07500{07500{07500{07500{07500{08B06B08E08F08F08F09D09D09D09D09E09E0000717375{0000464000{0000550000{0000770000{0001085500{0001085500{18{18{18{18{18{18{07000{07000{07000{07000{07000{07000{", 
"1440840 CL20031031380HV9519981101 244084006707{06500{06625{06750{06875{06875{27D03C28C29H30{30A06{05I06{06{06{06A0000615172I0000250000{0000621000{0000673000{0000750000{0000791000{36{36{36{36{36{36{06000{06000{06000{06000{06000{06000{", 
"1521993 CI20031031384E3A620000101 252199306937{06875{06875{06875{07000{07000{12H02H12H13{13D13E04E04E04E04E04F04F0001129428F0000700000{0000955000{0001000000{0002087000{0002087000{18{18{18{18{18{18{06500{06500{06500{06500{06500{06500{", 
"1538080 CL20031031384YXH420000501 253808008875{08875{08875{08875{08875{08875{31I31I31I31I31I31I04A04A04A04A04A04A0001419300{0001419300{0001419300{0001419300{0001419300{0001419300{36{36{36{36{36{36{07000{07000{07000{07000{07000{07000{", 
"1659123 CI20031031390XG8720020801 265912306909{06750{06750{06875{07000{07125{16E15I16C16E16F16F01E01D01D01E01E01G0000998541G0000162000{0000792000{0001156500{0001600000{0001990000{18{18{18{18{18{18{06000{06000{06000{06000{06000{06000{"
)?

Data 2

?[1] "1176552 CL20031031367RBV319920901 217655208875{08875{08875{08875{08875{08875{22D22D22D22D22D22D13C13C13C13C13C13C0000604000{0000604000{0000604000{0000604000{0000604000{0000604000{36{36{36{36{36{36{08500{08500{08500{08500{08500{08500{"
[2] "1254240 CL20031031371KLV120020201 225424007484{07250{07375{07500{07625{08625{33F06H33H33I34{34A02A01I02{02{02A03B0001121957C0000123500{0000920000{0001280000{0001741000{0003849000{35I30{36{36{36{36{07000{07000{07000{07000{07000{07000{"?

From jholtman at gmail.com  Sun Aug 28 04:06:48 2016
From: jholtman at gmail.com (jim holtman)
Date: Sat, 27 Aug 2016 22:06:48 -0400
Subject: [R] parsing a complex file
In-Reply-To: <c4ebcf51-a463-4804-93a5-0224a9be024c@me.com>
References: <c4ebcf51-a463-4804-93a5-0224a9be024c@me.com>
Message-ID: <CAAxdm-7mAzCF9ZKD0DofWQihkp5ncKsdFrypMyCO6teN-ckBRA@mail.gmail.com>

It is not clear as to how you want to parse the file.  You need to at least
provide an example of what you expect from the output.  You mention " the
detail which begins with 2 at byte location 1 to another file"; I don't see
the '2' at byte location 1.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sat, Aug 27, 2016 at 4:56 PM, Glenn Schultz <glennmschultz at me.com> wrote:

> All,
>
> I have a complex file I would like to parse in R a sample is described
> below
>
> The header is 1:200 and the detail is 1 to 200.  I have written code to
> parse the file so far.  As follows:
>
> numchar <- nchar(x = data, type = "chars")
> start <- c(seq(1, numchar, 398))
> end <- c(seq(398, numchar, 398))
> quartile <- NULL
> final <- str_sub(data, start[1:length(start)], end[1:length(end)])
> quartile <- append(quartile, final)
> write(quartile, Result)
> data2 <- readLines(Result)
>
> The function gets me to data2.  All is well so far. However, I need to
> send the header which begins with 1 at byte location 1 to a file and the
> detail which begins with 2 at byte location 1 to another file.  When I look
> at data2 in RStudio  I see the following.  The file is 185 meg, I have the
> lines but I am stuck as to the next step.  Any ideas are appreciated.
>
> Glenn
>
>
> dput of the data
>
> "1176552 CL20031031367RBV319920901
>
>
>  217655208875{08875{08875{08875{08875{08875{22D22D22D22D22D2
> 2D13C13C13C13C13C13C0000604000{0000604000{0000604000{
> 0000604000{0000604000{0000604000{36{36{36{36{36{36{
> 08500{08500{08500{08500{08500{08500{1254240 CL20031031371KLV120020201
>
>
>          225424007484{07250{07375{07500{07625{08625{33F06H33H33I34{
> 34A02A01I02{02{02A03B0001121957C0000123500{0000920000{
> 0001280000{0001741000{0003849000{35I30{36{36{36{36{
> 07000{07000{07000{07000{07000{07000{1254253 CL20031031371KMA620020301
>
>
>          225425306715{06250{06500{06750{06875{07000{33C23G33C33I34{
> 34A02{01I02{02{02A02C0000946646A0000350000{0000850000{
> 0001030000{0001205000{0001300000{35H30{36{36{36{36{
> 06000{06000{06000{06000{06000{06000{1259455 CL20031031371RE4420020501
>
>
>          225945507045{06750{06875{07000{07250{07375{34{28B34A34B34B3
> 4C01H01G01H01H01H02C0000934444E0000360000{0000765000{
> 0000995000{0001384000{0002184000{35I30{36{36{36{36{
> 06500{06500{06500{06500{06500{06500{1261060 CI20031031371S5V219940101
>
>
>          226106006637{06500{06500{06625{06750{06875{05B00C04H05I06B0
> 6B11H11G11G11H11H11I0001169090I0000650000{0000950000{
> 0001250000{0001328000{0001900000{18{18{18{18{18{18{
> 06000{06000{06000{06000{06000{06000{1335271 CI20031031375HMU519960101
>
>
>          233527107500{07500{07500{07500{07500{07500{08B06B08E08F08F0
> 8F09D09D09D09D09E09E0000717375{0000464000{0000550000{
> 0000770000{0001085500{0001085500{18{18{18{18{18{18{
> 07000{07000{07000{07000{07000{07000{1440840 CL20031031380HV9519981101
>
>
>          244084006707{06500{06625{06750{06875{06875{27D03C28C29H30{
> 30A06{05I06{06{06{06A0000615172I0000250000{00006
> 21000{0000673000{0000750000{0000791000{36{36{36{36{36{36{
> 06000{06000{06000{06000{06000{06000{1521993 CI20031031384E3A620000101
>
>
>          252199306937{06875{06875{06875{07000{07000{12H02H12H13{13D1
> 3E04E04E04E04E04F04F0001129428F0000700000{0000955000{0001000
> 000{0002087000{0002087000{18{18{18{18{18{18{06500{06500{
> 06500{06500{06500{06500{1538080 CL20031031384YXH420000501
>
>
>  253808008875{08875{08875{08875{08875{08875{31I31I31I31I31I3
> 1I04A04A04A04A04A04A0001419300{0001419300{0001419300{
> 0001419300{0001419300{0001419300{36{36{36{36{36{36{
> 07000{07000{07000{07000{07000{07000{1659123 CI20031031390XG8720020801
>
>
>          265912306909{06750{06750{06875{07000{07125{16E15I16C16E16F1
> 6F01E01D01D01E01E01G0000998541G0000162000{0000792000{
> 0001156500{0001600000{0001990000{18{18{18{18{18{18{
> 06000{06000{06000{06000{06000{06000{"
>
>
> dput data2
> c("1176552 CL20031031367RBV319920901 217655208875{08875{08875{08875
> {08875{08875{22D22D22D22D22D22D13C13C13C13C13C13C0000604000{
> 0000604000{0000604000{0000604000{0000604000{0000604000{36{36{36{36{36{36{
> 08500{08500{08500{08500{08500{08500{", "1254240 CL20031031371KLV120020201
> 225424007484{07250{07375{07500{07625{08625{33F06H33H33I34{
> 34A02A01I02{02{02A03B0001121957C0000123500{0000920000{
> 0001280000{0001741000{0003849000{35I30{36{36{36{36{
> 07000{07000{07000{07000{07000{07000{", "1254253 CL20031031371KMA620020301
> 225425306715{06250{06500{06750{06875{07000{33C23G33C33I34{
> 34A02{01I02{02{02A02C0000946646A0000350000{0000850000{
> 0001030000{0001205000{0001300000{35H30{36{36{36{36{
> 06000{06000{06000{06000{06000{06000{", "1259455 CL20031031371RE4420020501
> 225945507045{06750{06875{07000{07250{07375{34{28B34A34B34B34
> C01H01G01H01H01H02C0000934444E0000360000{0000765000{0000995000{0001384000{
> 0002184000{35I30{36{36{36{36{06500{06500{06500{06500{06500{06500{",
> "1261060 CI20031031371S5V219940101 226106006637{06500{06500{06625
> {06750{06875{05B00C04H05I06B06B11H11G11G11H11H11I0001169090I
> 0000650000{0000950000{0001250000{0001328000{0001900000{18{18{18{18{18{18{
> 06000{06000{06000{06000{06000{06000{", "1335271 CI20031031375HMU519960101
> 233527107500{07500{07500{07500{07500{07500{08B06B08E08F08F08
> F09D09D09D09D09E09E0000717375{0000464000{0000550000{0000770000{0001085500{
> 0001085500{18{18{18{18{18{18{07000{07000{07000{07000{07000{07000{",
> "1440840 CL20031031380HV9519981101 244084006707{06500{06625{06750
> {06875{06875{27D03C28C29H30{30A06{05I06{06{06{
> 06A0000615172I0000250000{0000621000{0000673000{0000750000{
> 0000791000{36{36{36{36{36{36{06000{06000{06000{06000{06000{06000{",
> "1521993 CI20031031384E3A620000101 252199306937{06875{06875{06875
> {07000{07000{12H02H12H13{13D13E04E04E04E04E04F04F0001129428F
> 0000700000{0000955000{0001000000{0002087000{0002087000{18{
> 18{18{18{18{18{06500{06500{06500{06500{06500{06500{", "1538080
> CL20031031384YXH420000501 253808008875{08875{08875{08875
> {08875{08875{31I31I31I31I31I31I04A04A04A04A04A04A0001419300{
> 0001419300{0001419300{0001419300{0001419300{0001419300{36{36{36{36{36{36{
> 07000{07000{07000{07000{07000{07000{", "1659123 CI20031031390XG8720020801
> 265912306909{06750{06750{06875{07000{07125{16E15I16C16E16F16
> F01E01D01D01E01E01G0000998541G0000162000{0000792000{0001156500{0001600000{
> 0001990000{18{18{18{18{18{18{06000{06000{06000{06000{06000{06000{"
> )
>
> Data 2
>
>  [1] "1176552 CL20031031367RBV319920901 217655208875{08875{08875{08875
> {08875{08875{22D22D22D22D22D22D13C13C13C13C13C13C0000604000{
> 0000604000{0000604000{0000604000{0000604000{0000604000{36{36{36{36{36{36{
> 08500{08500{08500{08500{08500{08500{"
> [2] "1254240 CL20031031371KLV120020201 225424007484{07250{07375{07500
> {07625{08625{33F06H33H33I34{34A02A01I02{02{02A03B000112195
> 7C0000123500{0000920000{0001280000{0001741000{
> 0003849000{35I30{36{36{36{36{07000{07000{07000{07000{07000{07000{"
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Sun Aug 28 16:26:24 2016
From: jholtman at gmail.com (jim holtman)
Date: Sun, 28 Aug 2016 10:26:24 -0400
Subject: [R] parsing the file
In-Reply-To: <9d7a6bb8-93d2-4245-8e4c-f072400e9b72@me.com>
References: <9d7a6bb8-93d2-4245-8e4c-f072400e9b72@me.com>
Message-ID: <CAAxdm-75vm6PCbf0BEvvS-LK67Xopyq_GuHpVEDnMakRFfUqWQ@mail.gmail.com>

Here is an attempt at parsing the data.  It is fixed field so the regular
expression will extract the data.  Some does not seem to make sense since
it has curly brackets in the data.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Aug 28, 2016 at 8:49 AM, Glenn Schultz <glennmschultz at me.com> wrote:

> Hi Jim,
>
> Attached is the layout of the file I would like to parse with dput sample
> of the data.  From the layout it seems to me there are two sets in the data
> Header and Details.  I would like to either parse such that
>
>
>    - I have either 1 comma delimited file of all data or
>    - 2 comma delimited files one of header the other of details
>
>
> I have never seen a file layout described in the manner before.
> Consequently, I am a little confused as to how to work with the file.
>
> Best,
> Glenn
>
> "1176552 CL20031031367RBV319920901
>
>
>  217655208875{08875{08875{08875{08875{08875{22D22D22D22D22D2
> 2D13C13C13C13C13C13C0000604000{0000604000{0000604000{0000604
> 000{0000604000{0000604000{36{36{36{36{36{36{08500{08500{08500{08500{08500{
> 08500{1254240 CL20031031371KLV120020201
>
>
>  225424007484{07250{07375{07500{07625{08625{33F06H33H33I34{3
> 4A02A01I02{02{02A03B0001121957C0000123500{0000920000{0001280
> 000{0001741000{0003849000{35I30{36{36{36{36{07000{07000{07000{07000{07000{
> 07000{1254253 CL20031031371KMA620020301
>
>
>  225425306715{06250{06500{06750{06875{07000{33C23G33C33I34{3
> 4A02{01I02{02{02A02C0000946646A0000350000{0000850000{0001030
> 000{0001205000{0001300000{35H30{36{36{36{36{06000{06000{06000{06000{06000{
> 06000{1259455 CL20031031371RE4420020501
>
>
>  225945507045{06750{06875{07000{07250{07375{34{28B34A34B34B3
> 4C01H01G01H01H01H02C0000934444E0000360000{0000765000{0000995
> 000{0001384000{0002184000{35I30{36{36{36{36{06500{06500{06500{06500{06500{
> 06500{1261060 CI20031031371S5V219940101
>
>
>  226106006637{06500{06500{06625{06750{06875{05B00C04H05I06B0
> 6B11H11G11G11H11H11I0001169090I0000650000{0000950000{0001250
> 000{0001328000{0001900000{18{18{18{18{18{18{06000{06000{06000{06000{06000{
> 06000{1335271 CI20031031375HMU519960101
>
>
>  233527107500{07500{07500{07500{07500{07500{08B06B08E08F08F0
> 8F09D09D09D09D09E09E0000717375{0000464000{0000550000{0000770
> 000{0001085500{0001085500{18{18{18{18{18{18{07000{07000{07000{07000{07000{
> 07000{1440840 CL20031031380HV9519981101
>
>
>  244084006707{06500{06625{06750{06875{06875{27D03C28C29H30{3
> 0A06{05I06{06{06{06A0000615172I0000250000{0000621000{
> 0000673000{0000750000{0000791000{36{36{36{36{36{36{06000{
> 06000{06000{06000{06000{06000{1521993 CI20031031384E3A620000101
>
>
>    252199306937{06875{06875{06875{07000{07000{12H02H12H13{13D1
> 3E04E04E04E04E04F04F0001129428F0000700000{0000955000{0001000
> 000{0002087000{0002087000{18{18{18{18{18{18{06500{06500{0650
> 0{06500{06500{06500{1538080 CL20031031384YXH420000501
>
>
>  253808008875{08875{08875{08875{08875{08875{31I31I31I31I31I3
> 1I04A04A04A04A04A04A0001419300{0001419300{0001419300{0001419
> 300{0001419300{0001419300{36{36{36{36{36{36{07000{07000{07000{07000{07000{
> 07000{1659123 CI20031031390XG8720020801
>
>
>  265912306909{06750{06750{06875{07000{07125{16E15I16C16E16F1
> 6F01E01D01D01E01E01G0000998541G0000162000{0000792000{0001156
> 500{0001600000{0001990000{18{18{18{18{18{18{06000{06000{06000{06000{06000{
> 06000{"
>
-------------- next part --------------
require(stringr)

# input data
data2 <- c("1176552 CL20031031367RBV319920901 217655208875{08875{08875{08875{08875{08875{22D22D22D22D22D22D13C13C13C13C13C13C0000604000{0000604000{0000604000{0000604000{0000604000{0000604000{36{36{36{36{36{36{08500{08500{08500{08500{08500{08500{", "1254240 CL20031031371KLV120020201 225424007484{07250{07375{07500{07625{08625{33F06H33H33I34{34A02A01I02{02{02A03B0001121957C0000123500{0000920000{0001280000{0001741000{0003849000{35I30{36{36{36{36{07000{07000{07000{07000{07000{07000{", "1254253 CL20031031371KMA620020301 225425306715{06250{06500{06750{06875{07000{33C23G33C33I34{34A02{01I02{02{02A02C0000946646A0000350000{0000850000{0001030000{0001205000{0001300000{35H30{36{36{36{36{06000{06000{06000{06000{06000{06000{", "1259455 CL20031031371RE4420020501 225945507045{06750{06875{07000{07250{07375{34{28B34A34B34B34C01H01G01H01H01H02C0000934444E0000360000{0000765000{0000995000{0001384000{0002184000{35I30{36{36{36{36{06500{06500{06500{06500{06500{06500{", "1261060 CI20031031371S5V219940101 226106006637{06500{06500{06625{06750{06875{05B00C04H05I06B06B11H11G11G11H11H11I0001169090I0000650000{0000950000{0001250000{0001328000{0001900000{18{18{18{18{18{18{06000{06000{06000{06000{06000{06000{", "1335271 CI20031031375HMU519960101 233527107500{07500{07500{07500{07500{07500{08B06B08E08F08F08F09D09D09D09D09E09E0000717375{0000464000{0000550000{0000770000{0001085500{0001085500{18{18{18{18{18{18{07000{07000{07000{07000{07000{07000{", "1440840 CL20031031380HV9519981101 244084006707{06500{06625{06750{06875{06875{27D03C28C29H30{30A06{05I06{06{06{06A0000615172I0000250000{0000621000{0000673000{0000750000{0000791000{36{36{36{36{36{36{06000{06000{06000{06000{06000{06000{", "1521993 CI20031031384E3A620000101 252199306937{06875{06875{06875{07000{07000{12H02H12H13{13D13E04E04E04E04E04F04F0001129428F0000700000{0000955000{0001000000{0002087000{0002087000{18{18{18{18{18{18{06500{06500{06500{06500{06500{06500{", "1538080 CL20031031384YXH420000501 253808008875{08875{08875{08875{08875{08875{31I31I31I31I31I31I04A04A04A04A04A04A0001419300{0001419300{0001419300{0001419300{0001419300{0001419300{36{36{36{36{36{36{07000{07000{07000{07000{07000{07000{", "1659123 CI20031031390XG8720020801 265912306909{06750{06750{06875{07000{07125{16E15I16C16E16F16F01E01D01D01E01E01G0000998541G0000162000{0000792000{0001156500{0001600000{0001990000{18{18{18{18{18{18{06000{06000{06000{06000{06000{06000{"
) 

# file format from PDF so we know the size and header names
# used the second part starting at FIXED QUARTILES DETAIL
header <- strsplit("5 QUARTILE RECORD TYPE alpha-numeric X(1) 1 1
5 POOL NUMBER alpha-numeric X(6) 2 6
10 WEIGHTED AVERAGE (WA) COUPON numeric edited S9(2)V9(4) 8 6
10 COUPON POOL MINIMUM numeric edited S9(2)V9(4) 14 6
10 COUPON QUARTILE 1 numeric edited S9(2)V9(4) 20 6
10 COUPON QUARTILE 2 numeric edited S9(2)V9(4) 26 6
10 COUPON QUARTILE 3 numeric edited S9(2)V9(4) 32 6
10 COUPON QUARTILE 4 numeric edited S9(2)V9(4) 38 6
10 WA MATURITY numeric edited S9(3) 44 3
10 MINIMUM numeric edited S9(3) 47 3
10 REMAINING MONTHS TO MATURITY QUARTILE 1 numeric edited S9(3) 50 3
10 REMAINING MONTHS TO MATURITY QUARTILE 2 numeric edited S9(3) 53 3
10 REMAINING MONTHS TO MATURITY QUARTILE 3 numeric edited S9(3) 56 3
10 REMAINING MONTHS TO MATURITY QUARTILE 4 numeric edited S9(3) 59 3
10 WA LOAN AGE numeric edited S9(3) 62 3
10 LOAN AGE POOL MINIMUM numeric edited S9(3) 65 3
10 LOAN AGE QUARTILE 1 numeric edited S9(3) 68 3
10 LOAN AGE QUARTILE 2 numeric edited S9(3) 71 3
10 LOAN AGE QUARTILE 3 numeric edited S9(3) 74 3
10 LOAN AGE QUARTILE 4 numeric edited S9(3) 77 3
10 AVERAGE LOAN SIZE numeric edited S9(9)V9(2) 80 11
10 LOAN SIZE POOL MINIMUM numeric edited S9(9)V9(2) 91 11
10 LOAN SIZE QUARTILE 1 numeric edited S9(9)V9(2) 102 11
10 LOAN SIZE QUARTILE 2 numeric edited S9(9)V9(2) 113 11
10 LOAN SIZE QUARTILE 3 numeric edited S9(9)V9(2) 124 11
10 LOAN SIZE QUARTILE 4 numeric edited S9(9)V9(2) 135 11
10 WA ORIGINAL LOAN TERM numeric edited S9(3) 146 3
10 ORIGINAL LOAN TERM MINIMUM numeric edited S9(3) 149 3
10 ORIGINAL LOAN TERM QUARTILE 1 numeric edited S9(3) 152 3
10 ORIGINAL LOAN TERM QUARTILE 2 numeric edited S9(3) 155 3
10 ORIGINAL LOAN TERM QUARTILE 3 numeric edited S9(3) 158 3 
10 ORIGINAL LOAN TERM QUARTILE 4 numeric edited S9(3) 161 3
10 WA PASS-THROUGH RATE numeric edited S9(2)V9(4) 164 6
10 PASS-THROUGH RATE POOL MINIMUM numeric edited S9(2)V9(4) 170 6
10 PASS-THROUGH RATE QUARTILE 1 numeric edited S9(2)V9(4) 176 6
10 PASS-THROUGH RATE QUARTILE 2 numeric edited S9(2)V9(4) 182 6
10 PASS-THROUGH RATE QUARTILE 3 numeric edited S9(2)V9(4) 188 6
10 PASS-THROUGH RATE QUARTILE 4 numeric edited S9(2)V9(4) 194 6 ", '\n')[[1]]

# extract header data and positions
head <- str_match(header, "^\\d+ (.+) (alpha|numeric).+(\\d+)\\s+(\\d+)\\s*$")

# create regular expression to parse the data
regexp <- sapply(head[, 5], function(num) paste0("(.{", num, "})"))
regexp <- paste(regexp, collapse = '')

result <- str_match(data2, regexp)

# remove 1st column since it is just the input
result <- result[, -1]

# add header
colnames(result) <- head[, 2]

View(result)  # some data does not seem to match up; has curly brackets in data

From ligges at statistik.tu-dortmund.de  Sun Aug 28 16:27:41 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 28 Aug 2016 16:27:41 +0200
Subject: [R] package.skeleton fails
In-Reply-To: <72D7DF49EFB92E4A9BE47205A0F4F03222C1F9C5@WAXMXOLYMB016.WAX.wa.lcl>
References: <72D7DF49EFB92E4A9BE47205A0F4F03222C1F9C5@WAXMXOLYMB016.WAX.wa.lcl>
Message-ID: <ba8fcf98-e537-81cf-d1ec-6b8a5c1215a5@statistik.tu-dortmund.de>

Your code works for me, and I do not see any lapply in the example you 
provide below.

Best,
Uwe Ligges



On 24.08.2016 21:21, Strunk, Jacob (DNR) wrote:
> Hello, I have been using package.skeleton from within an lapply statement
> successfully (assuming good source code) with the following setup in the
> past:
>
> writeLines("testfun=function(){}", "c:\\temp\\testfun.r")
> x=try(package.skeleton("test_pack",path="c:\\temp\\tests\\",code_files= "c:\\temp\\testfun.r"))
>
> but it now fails with the error:
>
> Error: evaluation nested too deeply: infinite recursion /
> options(expressions=)?
>
> I am working in RStudio Version 0.99.896, with 64 bit R version 3.3.1
> (2016-06-21)
>
> I have been poking in the code and the error appears happen within the subfunction '.fixPackageFileNames'
>
> Thanks for any assistance you might be able to provide.
>
> Jacob
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Sun Aug 28 16:28:39 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 28 Aug 2016 16:28:39 +0200
Subject: [R] package.skeleton, environment argument causes error
In-Reply-To: <CAKo8+cg3L==w5N517XmBv1o-P7Sap6QacP+Vn9j3QTJy5GF7pw@mail.gmail.com>
References: <CAKo8+cg3L==w5N517XmBv1o-P7Sap6QacP+Vn9j3QTJy5GF7pw@mail.gmail.com>
Message-ID: <fe4bc4a2-a911-d015-153c-4c48a91b6fc7@statistik.tu-dortmund.de>

It would be helpful for us if you provide a reproducible examples when 
the current package.skeleton fails.

Best,
Uwe Ligges



On 19.08.2016 00:12, Jacob Strunk wrote:
> Hello, I have been using package.skeleton from within an lapply statement
> successfully (assuming good source code) with the following setup in the
> past:
>
> x=try(package.skeleton(package_name,path=pathi,code_files=file_i))
>
>
> but now fails with error:
>
> Error: evaluation nested too deeply: infinite recursion /
> options(expressions=)?
>
> I am working in RStudio Version 0.99.896, with 64 bit R version 3.3.1
> (2016-06-21)
>
>
>
>
> I have been probing the code for package.skeleton a bit and noticed that
> the default arguments for 'list' and 'environment' are supplied in the
> function definition, thus making it impossible to achieve the conditions
>
> envIsMissing=TRUE
> missing(list) = TRUE
>
>
> as a result of the fact that missing(list) cannot be true, the classesList
> argument is empty and the call
>
> classes0 <- .fixPackageFileNames(classesList)
>
>
> then fails with the error
>
> Error: evaluation nested too deeply: infinite recursion /
> options(expressions=)?
>
>
> If I remove the default arguments I get further, but get the same error  I
> had before (Error: evaluation nested too deeply: infinite recursion /
> options(expressions=)?) after executing the following code:
>
> methods0 <- .fixPackageFileNames(methodsList)
>
>
> and the contents of methodsList look like
>
> An object of class "ObjectsWithPackage":
>
> Object:
> Package:
>
>
> the function .fixPackageFileNames fails when it reaches
>
> list <- as.character(list)
>
>
> where in this case the contents of 'list' look like
>
> str(list)
> Formal class 'ObjectsWithPackage' [package "methods"] with 2 slots
>   ..@ .Data  : chr(0)
>   ..@ package: chr(0)
>
>
> I am not sure if the problem arose from changes to package.skeleton
> or methods::getClasses and methods::getGenerics or if there is something
> peculiar about my environment.
>
> my current ugly fix is to define the function .fixPackageFileNames in the
> global environment and add a try statement and exit when it results in an
> object of class "try-error":
>
> .fixPackageFileNames=
> function (list)
> {
>     list <- *try(*as.character(list)*)*
>     *if(class(list)=="try-error")return(list)*
>     if (length(list) == 0L)
>         return(list)
>     list0 <- gsub("[[:cntrl:]\"*/:<>?\\|]", "_", list)
>     wrong <- grep("^(con|prn|aux|clock\\$|nul|lpt[1-3]|com[1-4])(\\..*|)$",
>         list0)
>     if (length(wrong))
>         list0[wrong] <- paste0("zz", list0[wrong])
>     ok <- grepl("^[[:alnum:]]", list0)
>     if (any(!ok))
>         list0[!ok] <- paste0("z", list0[!ok])
>     list1 <- tolower(list0)
>     list2 <- make.unique(list1, sep = "_")
>     changed <- (list2 != list1)
>     list0[changed] <- list2[changed]
>     list0
> }
>
>
> Any assistance with this error would be greatly appreciated!
>
> Thank you,
>


From jdnewmil at dcn.davis.ca.us  Sun Aug 28 17:38:58 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 28 Aug 2016 08:38:58 -0700
Subject: [R] parsing the file
In-Reply-To: <CAAxdm-75vm6PCbf0BEvvS-LK67Xopyq_GuHpVEDnMakRFfUqWQ@mail.gmail.com>
References: <9d7a6bb8-93d2-4245-8e4c-f072400e9b72@me.com>
	<CAAxdm-75vm6PCbf0BEvvS-LK67Xopyq_GuHpVEDnMakRFfUqWQ@mail.gmail.com>
Message-ID: <DB015323-4690-481A-8980-DAE9D4053FB5@dcn.davis.ca.us>

Based on the discussion of ORing values with characters in [1] which may generate "unusual" characters I suspect a botched conversion from EBCDIC may have messed with some of the data. If there are signed data fields then OP may need to read the original file and treat it as if it were binary data and do any needed  translation themselves to retrieve it. Not a task for the faint of heart.

[1] http://www.3480-3590-data-conversion.com/article-reading-cobol-layouts-4.html
-- 
Sent from my phone. Please excuse my brevity.

On August 28, 2016 7:26:24 AM PDT, jim holtman <jholtman at gmail.com> wrote:
>Here is an attempt at parsing the data.  It is fixed field so the
>regular
>expression will extract the data.  Some does not seem to make sense
>since
>it has curly brackets in the data.
>
>
>Jim Holtman
>Data Munger Guru
>
>What is the problem that you are trying to solve?
>Tell me what you want to do, not how you want to do it.
>
>On Sun, Aug 28, 2016 at 8:49 AM, Glenn Schultz <glennmschultz at me.com>
>wrote:
>
>> Hi Jim,
>>
>> Attached is the layout of the file I would like to parse with dput
>sample
>> of the data.  From the layout it seems to me there are two sets in
>the data
>> Header and Details.  I would like to either parse such that
>>
>>
>>    - I have either 1 comma delimited file of all data or
>>    - 2 comma delimited files one of header the other of details
>>
>>
>> I have never seen a file layout described in the manner before.
>> Consequently, I am a little confused as to how to work with the file.
>>
>> Best,
>> Glenn
>>
>> "1176552 CL20031031367RBV319920901
>>
>>
>>  217655208875{08875{08875{08875{08875{08875{22D22D22D22D22D2
>> 2D13C13C13C13C13C13C0000604000{0000604000{0000604000{0000604
>>
>000{0000604000{0000604000{36{36{36{36{36{36{08500{08500{08500{08500{08500{
>> 08500{1254240 CL20031031371KLV120020201
>>
>>
>>  225424007484{07250{07375{07500{07625{08625{33F06H33H33I34{3
>> 4A02A01I02{02{02A03B0001121957C0000123500{0000920000{0001280
>>
>000{0001741000{0003849000{35I30{36{36{36{36{07000{07000{07000{07000{07000{
>> 07000{1254253 CL20031031371KMA620020301
>>
>>
>>  225425306715{06250{06500{06750{06875{07000{33C23G33C33I34{3
>> 4A02{01I02{02{02A02C0000946646A0000350000{0000850000{0001030
>>
>000{0001205000{0001300000{35H30{36{36{36{36{06000{06000{06000{06000{06000{
>> 06000{1259455 CL20031031371RE4420020501
>>
>>
>>  225945507045{06750{06875{07000{07250{07375{34{28B34A34B34B3
>> 4C01H01G01H01H01H02C0000934444E0000360000{0000765000{0000995
>>
>000{0001384000{0002184000{35I30{36{36{36{36{06500{06500{06500{06500{06500{
>> 06500{1261060 CI20031031371S5V219940101
>>
>>
>>  226106006637{06500{06500{06625{06750{06875{05B00C04H05I06B0
>> 6B11H11G11G11H11H11I0001169090I0000650000{0000950000{0001250
>>
>000{0001328000{0001900000{18{18{18{18{18{18{06000{06000{06000{06000{06000{
>> 06000{1335271 CI20031031375HMU519960101
>>
>>
>>  233527107500{07500{07500{07500{07500{07500{08B06B08E08F08F0
>> 8F09D09D09D09D09E09E0000717375{0000464000{0000550000{0000770
>>
>000{0001085500{0001085500{18{18{18{18{18{18{07000{07000{07000{07000{07000{
>> 07000{1440840 CL20031031380HV9519981101
>>
>>
>>  244084006707{06500{06625{06750{06875{06875{27D03C28C29H30{3
>> 0A06{05I06{06{06{06A0000615172I0000250000{0000621000{
>> 0000673000{0000750000{0000791000{36{36{36{36{36{36{06000{
>> 06000{06000{06000{06000{06000{1521993 CI20031031384E3A620000101
>>
>>
>>    252199306937{06875{06875{06875{07000{07000{12H02H12H13{13D1
>> 3E04E04E04E04E04F04F0001129428F0000700000{0000955000{0001000
>> 000{0002087000{0002087000{18{18{18{18{18{18{06500{06500{0650
>> 0{06500{06500{06500{1538080 CL20031031384YXH420000501
>>
>>
>>  253808008875{08875{08875{08875{08875{08875{31I31I31I31I31I3
>> 1I04A04A04A04A04A04A0001419300{0001419300{0001419300{0001419
>>
>300{0001419300{0001419300{36{36{36{36{36{36{07000{07000{07000{07000{07000{
>> 07000{1659123 CI20031031390XG8720020801
>>
>>
>>  265912306909{06750{06750{06875{07000{07125{16E15I16C16E16F1
>> 6F01E01D01D01E01E01G0000998541G0000162000{0000792000{0001156
>>
>500{0001600000{0001990000{18{18{18{18{18{18{06000{06000{06000{06000{06000{
>> 06000{"
>>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From marius.hofert at uwaterloo.ca  Mon Aug 29 08:14:20 2016
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Mon, 29 Aug 2016 08:14:20 +0200
Subject: [R] How to split a data.frame into its columns?
Message-ID: <CAM3-KjaK0V+ZbmKu7BLTCtBR6G4vBL+evg2cDMDrGTUnr355wQ@mail.gmail.com>

Hi,

I need a fast way to split a data.frame (and matrix) into a list of
columns. For matrices, split(x, col(x)) works (which can then be done
in C for speed-up, if necessary), but for a data.frame? split(iris,
col(iris)) does not work as expected (?).
The outcome should be lapply(seq_len(ncol(iris)), function(j)
iris[,j]) and not require additional packages (if possible).

Thanks & cheers,
Marius

PS: Below is the C code for matrices. Not sure how easy it would be to
extend that to data.frames (?)

SEXP col_split(SEXP x)
{
    /* Setup */
    int *dims = INTEGER(getAttrib(x, R_DimSymbol));
    int n = dims[0], d = dims[1];
    SEXP res = PROTECT(allocVector(VECSXP, d));
    SEXP ref;
    int i = 0, j, k;

    /* Distinguish int/real matrices */
    switch (TYPEOF(x)) {
    case INTSXP:
    for(j = 0; j < d; j++) {
    SET_VECTOR_ELT(res, j, allocVector(INTSXP, n));
    int *e = INTEGER(VECTOR_ELT(res, j));
    for(k = 0 ; k < n ; i++, k++) {
    e[k] = INTEGER(x)[i];
    }
    }
    break;
    case REALSXP:
    for(j = 0; j < d; j++) {
    SET_VECTOR_ELT(res, j, allocVector(REALSXP, n));
    double *e = REAL(VECTOR_ELT(res, j));
    for(k = 0 ; k < n ; i++, k++) {
    e[k] = REAL(x)[i];
    }
    }
    break;
    case LGLSXP:
    for(j = 0; j < d; j++) {
    SET_VECTOR_ELT(res, j, allocVector(LGLSXP, n));
    int *e = LOGICAL(VECTOR_ELT(res, j));
    for(k = 0 ; k < n ; i++, k++) {
    e[k] = LOGICAL(x)[i];
    }
    }
    break;
    case STRSXP:
    for(j = 0; j < d; j++) {
ref = allocVector(STRSXP, n);
    SET_VECTOR_ELT(res, j, ref);
    ref = VECTOR_ELT(res, j);
    for(k = 0 ; k < n ; i++, k++) {
    SET_STRING_ELT(ref, k, STRING_ELT(x, i));
    }
    }
    break;
    default: error("Wrong type of 'x': %s", CHAR(type2str_nowarn(TYPEOF(x))));
    }

    /* Return */
    UNPROTECT(1);
    return(res);
}


From jdnewmil at dcn.davis.ca.us  Mon Aug 29 08:21:47 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 28 Aug 2016 23:21:47 -0700
Subject: [R] How to split a data.frame into its columns?
In-Reply-To: <CAM3-KjaK0V+ZbmKu7BLTCtBR6G4vBL+evg2cDMDrGTUnr355wQ@mail.gmail.com>
References: <CAM3-KjaK0V+ZbmKu7BLTCtBR6G4vBL+evg2cDMDrGTUnr355wQ@mail.gmail.com>
Message-ID: <663C7362-0311-4470-A902-D3A9634435CF@dcn.davis.ca.us>

Need to re-read the "Introduction to R". Data frames ARE lists of columns. So to convert a matrix to a list of vectors use

as.data.frame( m )
-- 
Sent from my phone. Please excuse my brevity.

On August 28, 2016 11:14:20 PM PDT, Marius Hofert <marius.hofert at uwaterloo.ca> wrote:
>Hi,
>
>I need a fast way to split a data.frame (and matrix) into a list of
>columns. For matrices, split(x, col(x)) works (which can then be done
>in C for speed-up, if necessary), but for a data.frame? split(iris,
>col(iris)) does not work as expected (?).
>The outcome should be lapply(seq_len(ncol(iris)), function(j)
>iris[,j]) and not require additional packages (if possible).
>
>Thanks & cheers,
>Marius
>
>PS: Below is the C code for matrices. Not sure how easy it would be to
>extend that to data.frames (?)
>
>SEXP col_split(SEXP x)
>{
>    /* Setup */
>    int *dims = INTEGER(getAttrib(x, R_DimSymbol));
>    int n = dims[0], d = dims[1];
>    SEXP res = PROTECT(allocVector(VECSXP, d));
>    SEXP ref;
>    int i = 0, j, k;
>
>    /* Distinguish int/real matrices */
>    switch (TYPEOF(x)) {
>    case INTSXP:
>    for(j = 0; j < d; j++) {
>    SET_VECTOR_ELT(res, j, allocVector(INTSXP, n));
>    int *e = INTEGER(VECTOR_ELT(res, j));
>    for(k = 0 ; k < n ; i++, k++) {
>    e[k] = INTEGER(x)[i];
>    }
>    }
>    break;
>    case REALSXP:
>    for(j = 0; j < d; j++) {
>    SET_VECTOR_ELT(res, j, allocVector(REALSXP, n));
>    double *e = REAL(VECTOR_ELT(res, j));
>    for(k = 0 ; k < n ; i++, k++) {
>    e[k] = REAL(x)[i];
>    }
>    }
>    break;
>    case LGLSXP:
>    for(j = 0; j < d; j++) {
>    SET_VECTOR_ELT(res, j, allocVector(LGLSXP, n));
>    int *e = LOGICAL(VECTOR_ELT(res, j));
>    for(k = 0 ; k < n ; i++, k++) {
>    e[k] = LOGICAL(x)[i];
>    }
>    }
>    break;
>    case STRSXP:
>    for(j = 0; j < d; j++) {
>ref = allocVector(STRSXP, n);
>    SET_VECTOR_ELT(res, j, ref);
>    ref = VECTOR_ELT(res, j);
>    for(k = 0 ; k < n ; i++, k++) {
>    SET_STRING_ELT(ref, k, STRING_ELT(x, i));
>    }
>    }
>    break;
>default: error("Wrong type of 'x': %s",
>CHAR(type2str_nowarn(TYPEOF(x))));
>    }
>
>    /* Return */
>    UNPROTECT(1);
>    return(res);
>}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Aug 29 08:27:32 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 28 Aug 2016 23:27:32 -0700
Subject: [R] How to split a data.frame into its columns?
In-Reply-To: <CAM3-KjaK0V+ZbmKu7BLTCtBR6G4vBL+evg2cDMDrGTUnr355wQ@mail.gmail.com>
References: <CAM3-KjaK0V+ZbmKu7BLTCtBR6G4vBL+evg2cDMDrGTUnr355wQ@mail.gmail.com>
Message-ID: <392D5713-0897-4387-89DC-C60ACFCE9ACF@comcast.net>


> On Aug 28, 2016, at 11:14 PM, Marius Hofert <marius.hofert at uwaterloo.ca> wrote:
> 
> Hi,
> 
> I need a fast way to split a data.frame (and matrix) into a list of
> columns.

This is a bit of a puzzle since data.frame objects are by definition "lists of columns".

If you want a data.frame object (say it's name is dat) to _only be a list of columns then

dat <- unclass(dat)

The split.data.frame function splits by rows since that is the most desired and expected behavior and because the authors of S/R probably thought there was no point in making the split "by columns" when it already was.

-- 
David.

> For matrices, split(x, col(x)) works (which can then be done
> in C for speed-up, if necessary), but for a data.frame? split(iris,
> col(iris)) does not work as expected (?).
> The outcome should be lapply(seq_len(ncol(iris)), function(j)
> iris[,j]) and not require additional packages (if possible).
> 
> Thanks & cheers,
> Marius
> 
> PS: Below is the C code for matrices. Not sure how easy it would be to
> extend that to data.frames (?)
> 
> SEXP col_split(SEXP x)
> {
>    /* Setup */
>    int *dims = INTEGER(getAttrib(x, R_DimSymbol));
>    int n = dims[0], d = dims[1];
>    SEXP res = PROTECT(allocVector(VECSXP, d));
>    SEXP ref;
>    int i = 0, j, k;
> 
>    /* Distinguish int/real matrices */
>    switch (TYPEOF(x)) {
>    case INTSXP:
>    for(j = 0; j < d; j++) {
>    SET_VECTOR_ELT(res, j, allocVector(INTSXP, n));
>    int *e = INTEGER(VECTOR_ELT(res, j));
>    for(k = 0 ; k < n ; i++, k++) {
>    e[k] = INTEGER(x)[i];
>    }
>    }
>    break;
>    case REALSXP:
>    for(j = 0; j < d; j++) {
>    SET_VECTOR_ELT(res, j, allocVector(REALSXP, n));
>    double *e = REAL(VECTOR_ELT(res, j));
>    for(k = 0 ; k < n ; i++, k++) {
>    e[k] = REAL(x)[i];
>    }
>    }
>    break;
>    case LGLSXP:
>    for(j = 0; j < d; j++) {
>    SET_VECTOR_ELT(res, j, allocVector(LGLSXP, n));
>    int *e = LOGICAL(VECTOR_ELT(res, j));
>    for(k = 0 ; k < n ; i++, k++) {
>    e[k] = LOGICAL(x)[i];
>    }
>    }
>    break;
>    case STRSXP:
>    for(j = 0; j < d; j++) {
> ref = allocVector(STRSXP, n);
>    SET_VECTOR_ELT(res, j, ref);
>    ref = VECTOR_ELT(res, j);
>    for(k = 0 ; k < n ; i++, k++) {
>    SET_STRING_ELT(ref, k, STRING_ELT(x, i));
>    }
>    }
>    break;
>    default: error("Wrong type of 'x': %s", CHAR(type2str_nowarn(TYPEOF(x))));
>    }
> 
>    /* Return */
>    UNPROTECT(1);
>    return(res);
> }
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From manu.reddy52 at gmail.com  Mon Aug 29 06:53:10 2016
From: manu.reddy52 at gmail.com (Manohar Reddy)
Date: Mon, 29 Aug 2016 10:23:10 +0530
Subject: [R] How to connect Microsoft Sql server from R studio using freeTDS
 instead of RODBC package
Message-ID: <CADG9u0A1m_eG2F2cX5wbYbjz5P9_BAihnXVP7YxVPCvTdgSMjA@mail.gmail.com>

Hi,



   Can anyone guide me how to connect the Microsoft Sql server 2012/14 from
R studio using freeTDS package instead of RODBC ,I can able to connect the
MS Sql server from R studio using RODBC.

  Actually my requirement is I have developed webpage/report using Shiny
package then I was deployed it on Shinyapps.io ,but after deploying I?m
encountering error like ??ERROR: *first argument is not an open RODBC
channel*? ,based on this error message I did searched in google and found
that we need to use freeTDS drivers instead of RODBC but I found some
articles regarding freeTDS but it?s not useful for me.



 I was eagerly waiting for solution from someone since last month, but not
yet and this issue is not allowing me to further .Can anyone please help me
out me(how to install freeTDS and how to configure it) on same.



My environment details :



    Os : windows 8

    R version 3.3.1 (2016-06-21)



Thanks in Advance .

Manu.

	[[alternative HTML version deleted]]


From arne.henningsen at gmail.com  Mon Aug 29 14:43:34 2016
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Mon, 29 Aug 2016 14:43:34 +0200
Subject: [R] Hickman models with two binary dependent variables in R
In-Reply-To: <B0591E30-E86A-4418-AA42-6A29A0B0C4D5@gmail.com>
References: <7E6E6DBE-BDCA-4B2A-9FB1-9F4A825058FD@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503A53C@SRVEXCHMBX.precheza.cz>
	<CAMTWbJikZF5LjwNjARY5mMJCt2p4EEqK26zE3bcEgK62vmOXZQ@mail.gmail.com>
	<B0591E30-E86A-4418-AA42-6A29A0B0C4D5@gmail.com>
Message-ID: <CAMTWbJimYZDZTb41bNROD4RuVifGt-cgvW6frTjn82aOO06Czg@mail.gmail.com>

Dear Faradj

On 27 August 2016 at 16:11, Faradj Koliev <faradj.g at gmail.com> wrote:
> It actually worked with heckit() command as well, do I need to use
> selection()?

I suggest that you use the selection() command/function only. heckit()
is just a wrapper to selection() with the only difference that
heckit() estimates the model with the 2-step method by default, while
selection() estimates the model by the maximum likelihood method by
default (unless specified otherwise with argument "method").

I see no good reason for estimating the sample-selection model by the
2-step method instead of the maximum likelihood method.

> Also, I would be really grateful if you can suggest a package that would
> allow for estimation of heckman models with two ordered variables (0-1-2).
> Can sampleSelection handle this?

Do you mean that the dependent variable of the selection equation is
an ordered variable with three levels (0-1-2), that the dependent
variable of the outcome equation is an ordered variable with three
levels (0-1-2), or that both of the dependent variables are ordered
variable with three levels (0-1-2) each?

In any case: no, this is not implemented in the sampleSelection package. Sorry!

Anyway, I guess that it is not too complicated to derive the
likelihood function and implement the estimation yourself, e.g., using
the maxLik package. If you do this, I would be happy to help you to
implement this feature in the sampleSelection package.

Best wishes,
Arne

-- 
Arne Henningsen
http://www.arne-henningsen.name


From marius.hofert at uwaterloo.ca  Mon Aug 29 15:54:42 2016
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Mon, 29 Aug 2016 15:54:42 +0200
Subject: [R] How to split a data.frame into its columns?
In-Reply-To: <8453b50396ae4956b5a92857161e842f@CONNHUB4.connect.uwaterloo.ca>
References: <CAM3-KjaK0V+ZbmKu7BLTCtBR6G4vBL+evg2cDMDrGTUnr355wQ@mail.gmail.com>
	<392D5713-0897-4387-89DC-C60ACFCE9ACF@comcast.net>
	<8453b50396ae4956b5a92857161e842f@CONNHUB4.connect.uwaterloo.ca>
Message-ID: <CAM3-KjZbOsohCs0QcKPLrsVE676iGbTeUF-gj623NaiUjRgKdw@mail.gmail.com>

Hi David and Jeff,

Thanks for your quick help, unclass() was precisely what I was looking for.

Cheers,
M

On Mon, Aug 29, 2016 at 10:39 AM, aditya pant <adityapant1 at gmail.com> wrote:
>
> ^^??????),,,
> ________________________________
> From: David Winsemius
> Sent: ?29-?08-?2016 11:59
> To: Marius Hofert
> Cc: R-help
> Subject: Re: [R] How to split a data.frame into its columns?
>
>
>> On Aug 28, 2016, at 11:14 PM, Marius Hofert <marius.hofert at uwaterloo.ca>
>> wrote:
>>
>> Hi,
>>
>> I need a fast way to split a data.frame (and matrix) into a list of
>> columns.
>
> This is a bit of a puzzle since data.frame objects are by definition "lists
> of columns".
>
> If you want a data.frame object (say it's name is dat) to _only be a list of
> columns then
>
> dat <- unclass(dat)
>
> The split.data.frame function splits by rows since that is the most desired
> and expected behavior and because the authors of S/R probably thought there
> was no point in making the split "by columns" when it already was.
>
> --
> David.
>
>> For matrices, split(x, col(x)) works (which can then be done
>> in C for speed-up, if necessary), but for a data.frame? split(iris,
>> col(iris)) does not work as expected (?).
>> The outcome should be lapply(seq_len(ncol(iris)), function(j)
>> iris[,j]) and not require additional packages (if possible).
>>
>> Thanks & cheers,
>> Marius
>>
>> PS: Below is the C code for matrices. Not sure how easy it would be to
>> extend that to data.frames (?)
>>
>> SEXP col_split(SEXP x)
>> {
>>    /* Setup */
>>    int *dims = INTEGER(getAttrib(x, R_DimSymbol));
>>    int n = dims[0], d = dims[1];
>>    SEXP res = PROTECT(allocVector(VECSXP, d));
>>    SEXP ref;
>>    int i = 0, j, k;
>>
>>    /* Distinguish int/real matrices */
>>    switch (TYPEOF(x)) {
>>    case INTSXP:
>>    for(j = 0; j < d; j++) {
>>    SET_VECTOR_ELT(res, j, allocVector(INTSXP, n));
>>    int *e = INTEGER(VECTOR_ELT(res, j));
>>    for(k = 0 ; k < n ; i++, k++) {
>>    e[k] = INTEGER(x)[i];
>>    }
>>    }
>>    break;
>>    case REALSXP:
>>    for(j = 0; j < d; j++) {
>>    SET_VECTOR_ELT(res, j, allocVector(REALSXP, n));
>>    double *e = REAL(VECTOR_ELT(res, j));
>>    for(k = 0 ; k < n ; i++, k++) {
>>    e[k] = REAL(x)[i];
>>    }
>>    }
>>    break;
>>    case LGLSXP:
>>    for(j = 0; j < d; j++) {
>>    SET_VECTOR_ELT(res, j, allocVector(LGLSXP, n));
>>    int *e = LOGICAL(VECTOR_ELT(res, j));
>>    for(k = 0 ; k < n ; i++, k++) {
>>    e[k] = LOGICAL(x)[i];
>>    }
>>    }
>>    break;
>>    case STRSXP:
>>    for(j = 0; j < d; j++) {
>> ref = allocVector(STRSXP, n);
>>    SET_VECTOR_ELT(res, j, ref);
>>    ref = VECTOR_ELT(res, j);
>>    for(k = 0 ; k < n ; i++, k++) {
>>    SET_STRING_ELT(ref, k, STRING_ELT(x, i));
>>    }
>>    }
>>    break;
>>    default: error("Wrong type of 'x': %s",
>> CHAR(type2str_nowarn(TYPEOF(x))));
>>    }
>>
>>    /* Return */
>>    UNPROTECT(1);
>>    return(res);
>> }
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From msharp at txbiomed.org  Mon Aug 29 18:05:26 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Mon, 29 Aug 2016 16:05:26 +0000
Subject: [R] How to connect Microsoft Sql server from R studio using
 freeTDS instead of RODBC package
In-Reply-To: <CADG9u0A1m_eG2F2cX5wbYbjz5P9_BAihnXVP7YxVPCvTdgSMjA@mail.gmail.com>
References: <CADG9u0A1m_eG2F2cX5wbYbjz5P9_BAihnXVP7YxVPCvTdgSMjA@mail.gmail.com>
Message-ID: <D92BF93E-0D9D-40C2-8172-3ADADA769AA4@TxBiomed.org>

Manu,

Read the first paragraph under section "1 ODBC Concepts" of https://cran.r-project.org/web/packages/RODBC/vignettes/RODBC.pdf. This describes the relationship among the various parts of the technical stack that allows connectivity to the database system via ODBC. One of the points made is that RODBC uses an ODBC driver (e.g., Actual Technologies, Easysoft and OpenLink).

I use the driver from Actual Technologies on Mac OS, but many others have used freeTDS. I had trouble with freeTDS years ago and decided my time was worth the minor cost of using the commercial product from Actual Technologies.

The driver you use is computer OS specific while RODBC is not.

It is also convenient to use an ODBC manager, which is typically a graphical application used to create and manage the configuration files used by the ODBC driver.

Mark

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org

> On Aug 28, 2016, at 11:53 PM, Manohar Reddy <manu.reddy52 at gmail.com> wrote:
>
> Hi,
>
>
>
>   Can anyone guide me how to connect the Microsoft Sql server 2012/14 from
> R studio using freeTDS package instead of RODBC ,I can able to connect the
> MS Sql server from R studio using RODBC.
>
>  Actually my requirement is I have developed webpage/report using Shiny
> package then I was deployed it on Shinyapps.io ,but after deploying I?m
> encountering error like ??ERROR: *first argument is not an open RODBC
> channel*? ,based on this error message I did searched in google and found
> that we need to use freeTDS drivers instead of RODBC but I found some
> articles regarding freeTDS but it?s not useful for me.
>
>
>
> I was eagerly waiting for solution from someone since last month, but not
> yet and this issue is not allowing me to further .Can anyone please help me
> out me(how to install freeTDS and how to configure it) on same.
>
>
>
> My environment details :
>
>
>
>    Os : windows 8
>
>    R version 3.3.1 (2016-06-21)
>
>
>
> Thanks in Advance .
>
> Manu.
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.







CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments transmitted, may contain privileged and confidential information and is intended solely for the exclusive use of the individual or entity to whom it is addressed. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution or copying of this e-mail and/or attachments is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender stating that this transmission was misdirected; return the e-mail to sender; destroy all paper copies and delete all electronic copies from your system without disclosing its contents.

From wdunlap at tibco.com  Mon Aug 29 18:31:14 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 29 Aug 2016 09:31:14 -0700
Subject: [R] Storing business hours
In-Reply-To: <248BA33BC59279499C246B6EB309AF21016C932998@ex2010mbx2.tu-dortmund.de>
References: <248BA33BC59279499C246B6EB309AF21016C92D522@ex2010mbx1.tu-dortmund.de>
	<CA+8X3fVpNS73BLDX2qzED3Z3VCyV4V3e3WCuKpTZHBP1EKe2Eg@mail.gmail.com>
	<CAF8bMcZRKUkx+1TqHTzXdHLrJrvT+WLF5o=uZt-wZcYVJzefeA@mail.gmail.com>
	<248BA33BC59279499C246B6EB309AF21016C932998@ex2010mbx2.tu-dortmund.de>
Message-ID: <CAF8bMcYX1mmaJo+rYU4YMg+9MZaEiEHw6n=jW1218rXpE-+fPw@mail.gmail.com>

The cummax(+-1) trick, along with findInterval(), is most useful for
expanding a list of opening and closing times into a table which can be
used to find the number of open shops at any given time.  E.g., suppose
your raw data comes from business hours posted on web sites:

shopHours <- list(Butcher=rbind(c(Open=8,Close=12), c(13, 17)),
                  Florist=rbind(c(Open=10,Close=18)),
                  Pub=rbind(c(Open=10,Close=14), c(16,22)),
                  Bank=rbind(c(Open=9,Close=15)))

Then you can generate a list of the number of open shops at any time with:

d <- data.frame(Shop=rep(names(shopHours), vapply(shopHours,nrow,0)),
do.call("rbind", shopHours))
d <- with(d, rbind(data.frame(Shop, Hour=Open, Action=+1), data.frame(Shop,
Hour=Close, Action=-1)))
d <- d[order(d$Hour),]
d$NumberOpen <- cumsum(d$Action)
transform(data.frame(Hour=seq(8,22,by=1),
NumberOpen=d$NumberOpen[findInterval(Hour, d$Hour)])
#   Hour NumberOpen
#1     8          1
#2     9          2
#3    10          4
#4    11          4
#5    12          3
#6    13          4
#...


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Aug 29, 2016 at 8:06 AM, alexander.sommer at tu-dortmund.de <
alexander.sommer at tu-dortmund.de> wrote:

> Dear Bill,
>
> thank you for your help. I think, I finally understood your advice. At
> least, this one worked:
>
> library(package = lubridate)   # for a more convenient display of times
>
> i <- 12   # number of time intervals per hour
>
> # creating a data.frame (original example)
> business_hours <- data.frame(t = hm(paste(rep(x = 0:23, each = i), rep(x =
> seq(from = 0, to = 60/i * (i - 1), by = 60/i), times = 24))),
>                              A = c(rep(x = 0, times = (8 - (1/i)) * i), 1,
> rep(x = 0, times = (12   - (1/i)) * i), -1, rep(x = 0, times = (4
>  ) * i)),
>                              B = c(rep(x = 0, times = (9 - (1/i)) * i), 1,
> rep(x = 0, times = (2.75 - (1/i)) * i), -1, rep(x = 0, times = (1.75 -
> (1/i)) * i), 1, rep(x = 0, times = (3.5 - (1/i)) * i), -1, rep(x = 0, times
> = 7 * i)))
>
> # some data analysis
> plot(x = rowSums(x = cumsum(business_hours[, -1])), type = "s")
>
> I find some elegance in this solution; still, Jims proposal looks easier
> to handle to me.
>
> Best regards,
>
> Alex
>
>
> --
> Alexander Sommer
> wissenschaftlicher Mitarbeiter
>
> Technische Universit?t Dortmund
> Fakult?t Erziehungswissenschaft, Psychologie und Soziologie
> Forschungsverbund Deutsches Jugendinstitut/Technische Universit?t Dortmund
> Vogelpothsweg 78
> 44227 Dortmund
>
> Telefon: +49 231 755-8189
> Telefax: +49 231 755-6553
> E-Mail:  alexander.sommer at tu-dortmund.de
> WWW:     http://www.forschungsverbund.tu-dortmund.de/
> Wichtiger Hinweis: Die Information in dieser E-Mail ist vertraulich. Sie
> ist ausschlie?lich f?r den Adressaten bestimmt. Sollten Sie nicht der f?r
> diese E-Mail bestimmte Adressat sein, unterrichten Sie bitte den Absender
> und vernichten Sie diese Mail. Vielen Dank.
> Unbeschadet der Korrespondenz per E-Mail, sind unsere Erkl?rungen
> ausschlie?lich final rechtsverbindlich, wenn sie in herk?mmlicher
> Schriftform (mit eigenh?ndiger Unterschrift) oder durch ?bermittlung eines
> solchen Schriftst?cks per Telefax erfolgen.
>
> Important note: The information included in this e-mail is confidential.
> It is solely intended for the recipient. If you are not the intended
> recipient of this e-mail please contact the sender and delete this message.
> Thank you. Without prejudice of e-mail correspondence, our statements are
> only legally binding when they are made in the conventional written form
> (with personal signature) or when such documents are sent by fax.
>

	[[alternative HTML version deleted]]


From david at agros.it  Mon Aug 29 18:48:38 2016
From: david at agros.it (David Remotti)
Date: Mon, 29 Aug 2016 18:48:38 +0200
Subject: [R] how to prepare my data to be used in the "survey" package
Message-ID: <f47b4137-1274-7004-e2eb-974d440922b4@agros.it>

Looking for some help in using the "survey" package
I have gone through the documentation but still find problems in 
understanding how to prepare my data to be analyzed wih this package.

In particular I dont understand how to prepare the fpc data.
The documentation provides a "small survey example" where 6 variables 
are given:
stratid,psuids,weight,nh,Nh and x

My survey is a two stage stratified sampling so I have for each stratum 
the number of primary
and secondary units in the sample and in the population, and using these 
data I can prepare such
data frame, except for the last variable "x".
I cant understand what does it means and which information I have to put 
there.

A second (minor) problem is that my stratification is based on two 
variables, but it looks like it is only possible to give 1 variable as 
strata parameter.
Is it possible to give two ?

thanks in advance for any indication
David Remotti
Rome
Italy


From manu.reddy52 at gmail.com  Mon Aug 29 19:26:11 2016
From: manu.reddy52 at gmail.com (Manohar Reddy)
Date: Mon, 29 Aug 2016 22:56:11 +0530
Subject: [R] How to connect Microsoft Sql server from R studio using
 freeTDS instead of RODBC package
In-Reply-To: <D92BF93E-0D9D-40C2-8172-3ADADA769AA4@TxBiomed.org>
References: <CADG9u0A1m_eG2F2cX5wbYbjz5P9_BAihnXVP7YxVPCvTdgSMjA@mail.gmail.com>
	<D92BF93E-0D9D-40C2-8172-3ADADA769AA4@TxBiomed.org>
Message-ID: <CADG9u0AB3fi_FW8PJr65eB5uyu1vs8BmU_kTHkaio+P9mSexLA@mail.gmail.com>

Hi Mark,



  Thank you so much for reply, using exiting ODBC drivers I will make a
connection  to sql server and it?s working fine in my local, but as per
shinyapps.io I need to use freeTDS drivers instead RODBC ,so that I may not
encounter the any issue .For me here challenging work is how to install
freeTDS on my machine and how to configure it?



     Is there any drivers/way that can i  make a connection to sql server
and I shouldn?t encounter the issue after deploying application on
shinyapps.io.



Thanks,Manu.

On Mon, Aug 29, 2016 at 9:35 PM, Mark Sharp <msharp at txbiomed.org> wrote:

> Manu,
>
> Read the first paragraph under section "1 ODBC Concepts" of
> https://cran.r-project.org/web/packages/RODBC/vignettes/RODBC.pdf. This
> describes the relationship among the various parts of the technical stack
> that allows connectivity to the database system via ODBC. One of the points
> made is that RODBC uses an ODBC driver (e.g., Actual Technologies, Easysoft
> and OpenLink).
>
> I use the driver from Actual Technologies on Mac OS, but many others have
> used freeTDS. I had trouble with freeTDS years ago and decided my time was
> worth the minor cost of using the commercial product from Actual
> Technologies.
>
> The driver you use is computer OS specific while RODBC is not.
>
> It is also convenient to use an ODBC manager, which is typically a
> graphical application used to create and manage the configuration files
> used by the ODBC driver.
>
> Mark
>
> R. Mark Sharp, Ph.D.
> Director of Primate Records Database
> Southwest National Primate Research Center
> Texas Biomedical Research Institute
> P.O. Box 760549
> San Antonio, TX 78245-0549
> Telephone: (210)258-9476
> e-mail: msharp at TxBiomed.org
>
> > On Aug 28, 2016, at 11:53 PM, Manohar Reddy <manu.reddy52 at gmail.com>
> wrote:
> >
> > Hi,
> >
> >
> >
> >   Can anyone guide me how to connect the Microsoft Sql server 2012/14
> from
> > R studio using freeTDS package instead of RODBC ,I can able to connect
> the
> > MS Sql server from R studio using RODBC.
> >
> >  Actually my requirement is I have developed webpage/report using Shiny
> > package then I was deployed it on Shinyapps.io ,but after deploying I?m
> > encountering error like ??ERROR: *first argument is not an open RODBC
> > channel*? ,based on this error message I did searched in google and found
> > that we need to use freeTDS drivers instead of RODBC but I found some
> > articles regarding freeTDS but it?s not useful for me.
> >
> >
> >
> > I was eagerly waiting for solution from someone since last month, but not
> > yet and this issue is not allowing me to further .Can anyone please help
> me
> > out me(how to install freeTDS and how to configure it) on same.
> >
> >
> >
> > My environment details :
> >
> >
> >
> >    Os : windows 8
> >
> >    R version 3.3.1 (2016-06-21)
> >
> >
> >
> > Thanks in Advance .
> >
> > Manu.
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
>
>
> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
> transmitted, may contain privileged and confidential information and is
> intended solely for the exclusive use of the individual or entity to whom
> it is addressed. If you are not the intended recipient, you are hereby
> notified that any review, dissemination, distribution or copying of this
> e-mail and/or attachments is strictly prohibited. If you have received this
> e-mail in error, please immediately notify the sender stating that this
> transmission was misdirected; return the e-mail to sender; destroy all
> paper copies and delete all electronic copies from your system without
> disclosing its contents.
>



-- 


Thanks,
Manohar Reddy P
+91-9705302062.

	[[alternative HTML version deleted]]


From marius.hofert at uwaterloo.ca  Mon Aug 29 19:36:17 2016
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Mon, 29 Aug 2016 19:36:17 +0200
Subject: [R] How to test existence of an environment and how to remove it
 (from within functions)?
Message-ID: <CAM3-KjapbnvpU=Bfg5XRUVJc+xAvkON6vWSgnkU8NTBdJxV2Cw@mail.gmail.com>

Hi,

I have a function main() which calls another function aux() many times. aux()
mostly does the same operations based on an object and thus I would like it to
compute and store this object for each call from main() only once.

Below are two versions of a MWE. The first one computes the right result (but is
merely there for showing what I would like to have; well, apart from the
environment .my_environ still floating around after main() is called).
It works with an
environment .my_environ in which the computed object is stored. The
second MWE tries to set
up the environment inside aux(), but neither the check of existence in
aux() nor the
removal of the whole environment in main() work (see 'TODO' below). How can this
be achieved?

Cheers,
Marius


### Version 1: Setting up the environment in .GlobalEnv ########################

.my_environ <- new.env(hash = FALSE, parent = emptyenv()) # define the
environment

## Auxiliary function with caching
aux <- function(x) {
    ## Setting up the environment and caching
    if(exists("cached.obj", envir = .my_environ)) { # look-up (in case
the object already exists)
        x.cols <- get("cached.obj", .my_environ)
    } else { # time-consuming part (+ cache)
        x.cols <- split(x, col(x))
        Sys.sleep(1)
        assign("cached.obj", x.cols, envir = .my_environ)
    }
    ## Do something with the result from above (here: pick out two randomly
    ## chosen columns)
    x.cols[sample(1:1000, size = 2)]
}

## Main function
main <- function() {
    x <- matrix(rnorm(100*1000), ncol = 1000)
    res <- replicate(5, aux(x))
    rm(cached.obj, envir = .my_environ) # only removing the *object*
(but not the environment)
    res
}

## Testing
set.seed(271)
system.time(main()) # => ~ 1s since the cached object is found


### Version 2: Trying to set up the environment inside aux() ###################

## Auxiliary function with caching
aux <- function(x) {
    ## Setting up the environment and caching
    if(!exists(".my_environ", mode = "environmnent")) # TODO: How to
check the existence of the environment? This is always TRUE...
        .my_environ <- new.env(hash = FALSE, parent = emptyenv()) #
define the environment
    if(exists("cached.obj", envir = .my_environ)) { # look-up (in case
the object already exists)
        x.cols <- get("cached.obj", .my_environ)
    } else { # time-consuming part (+ cache)
        x.cols <- split(x, col(x))
        Sys.sleep(1)
        assign("cached.obj", x.cols, envir = .my_environ)
    }
    ## Do something with the result from above (here: pick out two randomly
    ## chosen columns)
    x.cols[sample(1:1000, size = 2)]
}

## Main function
main <- function() {
    x <- matrix(rnorm(100*1000), ncol = 1000)
    res <- replicate(5, aux(x))
    rm(.my_environ) # TODO: How to properly remove the environment?
    res
}

## Testing
set.seed(271)
system.time(main()) # => ~ 5s since (the cached object in) environment
.my_environ is not found


From murdoch.duncan at gmail.com  Mon Aug 29 19:59:06 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 29 Aug 2016 13:59:06 -0400
Subject: [R] How to test existence of an environment and how to remove
 it (from within functions)?
In-Reply-To: <CAM3-KjapbnvpU=Bfg5XRUVJc+xAvkON6vWSgnkU8NTBdJxV2Cw@mail.gmail.com>
References: <CAM3-KjapbnvpU=Bfg5XRUVJc+xAvkON6vWSgnkU8NTBdJxV2Cw@mail.gmail.com>
Message-ID: <0721d432-cff1-8218-d402-8d135db6f6f2@gmail.com>

On 29/08/2016 1:36 PM, Marius Hofert wrote:
> Hi,
>
> I have a function main() which calls another function aux() many times. aux()
> mostly does the same operations based on an object and thus I would like it to
> compute and store this object for each call from main() only once.
>
> Below are two versions of a MWE. The first one computes the right result (but is
> merely there for showing what I would like to have; well, apart from the
> environment .my_environ still floating around after main() is called).
> It works with an
> environment .my_environ in which the computed object is stored. The
> second MWE tries to set
> up the environment inside aux(), but neither the check of existence in
> aux() nor the
> removal of the whole environment in main() work (see 'TODO' below). How can this
> be achieved?
>

If you create aux in a local() call, it can have persistent storage, 
because local() creates an environment to hold it.  For example,

aux <- local({
   persistent <- NULL
   function(x) {
     if (!is.null(persistent))
       message("Previous arg was ", persistent)
     persistent <<- x
   }
})

Note that the assignment uses <<- to work in the local-created 
environment rather than purely locally within the evaluation frame of 
the call.  You need to create the variable "persistent" there, or the 
assignment would go to the global environment, which is bad.

This gives

 > aux(1)
 > aux(2)
Previous arg was 1
 > aux(3)
Previous arg was 2

Duncan Murdoch

> Cheers,
> Marius
>
>
> ### Version 1: Setting up the environment in .GlobalEnv ########################
>
> .my_environ <- new.env(hash = FALSE, parent = emptyenv()) # define the
> environment
>
> ## Auxiliary function with caching
> aux <- function(x) {
>     ## Setting up the environment and caching
>     if(exists("cached.obj", envir = .my_environ)) { # look-up (in case
> the object already exists)
>         x.cols <- get("cached.obj", .my_environ)
>     } else { # time-consuming part (+ cache)
>         x.cols <- split(x, col(x))
>         Sys.sleep(1)
>         assign("cached.obj", x.cols, envir = .my_environ)
>     }
>     ## Do something with the result from above (here: pick out two randomly
>     ## chosen columns)
>     x.cols[sample(1:1000, size = 2)]
> }
>
> ## Main function
> main <- function() {
>     x <- matrix(rnorm(100*1000), ncol = 1000)
>     res <- replicate(5, aux(x))
>     rm(cached.obj, envir = .my_environ) # only removing the *object*
> (but not the environment)
>     res
> }
>
> ## Testing
> set.seed(271)
> system.time(main()) # => ~ 1s since the cached object is found
>
>
> ### Version 2: Trying to set up the environment inside aux() ###################
>
> ## Auxiliary function with caching
> aux <- function(x) {
>     ## Setting up the environment and caching
>     if(!exists(".my_environ", mode = "environmnent")) # TODO: How to
> check the existence of the environment? This is always TRUE...
>         .my_environ <- new.env(hash = FALSE, parent = emptyenv()) #
> define the environment
>     if(exists("cached.obj", envir = .my_environ)) { # look-up (in case
> the object already exists)
>         x.cols <- get("cached.obj", .my_environ)
>     } else { # time-consuming part (+ cache)
>         x.cols <- split(x, col(x))
>         Sys.sleep(1)
>         assign("cached.obj", x.cols, envir = .my_environ)
>     }
>     ## Do something with the result from above (here: pick out two randomly
>     ## chosen columns)
>     x.cols[sample(1:1000, size = 2)]
> }
>
> ## Main function
> main <- function() {
>     x <- matrix(rnorm(100*1000), ncol = 1000)
>     res <- replicate(5, aux(x))
>     rm(.my_environ) # TODO: How to properly remove the environment?
>     res
> }
>
> ## Testing
> set.seed(271)
> system.time(main()) # => ~ 5s since (the cached object in) environment
> .my_environ is not found
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rhurlin at gwdg.de  Mon Aug 29 20:00:53 2016
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Mon, 29 Aug 2016 20:00:53 +0200
Subject: [R] read.xlsx function crashing R Studio
In-Reply-To: <18f7d6eb-f297-4292-a52b-a8cc0057b520@me.com>
References: <18f7d6eb-f297-4292-a52b-a8cc0057b520@me.com>
Message-ID: <05079407-79ae-8e18-4aa1-c49125eba2e8@gwdg.de>

Hi Kevin,

Am 21.08.2016 um 19:30 schrieb Kevin Kowitski:
> Hey everyone, 
> 
>    I have used read.xlsx in the past rather than XLConnect for importing
> Excel data to R.  However, I have been finding now that the read.xlsx
> function has been causing my R studio to Time out.  I thought it might
> be because the R studio I had was out of date so I installed R studio
> X64 3.3.1 and reinstalled the xlsx package but it is still failing.  I
> have been trying to use XLConnect in it's place which has been working,
> excpet that I am running into memory error:
>               Error: OutOfMemoryError (Java): GC overhead limit exceeded
>       
> I did some online searching and found an option to increase memory:
>               "options(java.parameters = "-Xmx4g" )
> 
> but it resulted in this new memory Error:
> 
>              Error: OutOfMemoryError (Java): Java heap space
> 
> Can anyone provide me with some help on getting the read.xlsx function
> working?
> 
> -Kevin

There are interesting alternatives with other packages, as mentioned
before by Jim Holtman and Hadley Wickham.

If there are serious reasons to use the xlsx package, I had success with
the following, somewhat ugly workaround:


# Increase before package loading
options(java.parameters = "-Xmx8000m")
# Java garbage collection function
jgc <- function() .jcall("java/lang/System", method = "gc")
library(xlsx)
# if you like to use ISO dates
options(xlsx.date.format="yyyy-mm-dd")
# ATTENTION:  Loading of package xlsx changes decimal point
# to comma in a German locale
Sys.setlocale(category = "LC_NUMERIC", locale="C")  # UGLY HACK !!!


# Later in your code, i.e. before using addDataFrame(), use
jgc()


HTH,
Rainer Hurling


From dwinsemius at comcast.net  Mon Aug 29 20:29:48 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 29 Aug 2016 11:29:48 -0700
Subject: [R] how to prepare my data to be used in the "survey" package
In-Reply-To: <f47b4137-1274-7004-e2eb-974d440922b4@agros.it>
References: <f47b4137-1274-7004-e2eb-974d440922b4@agros.it>
Message-ID: <AC9480F2-3FD2-4DF6-A63B-0FA70552D13C@comcast.net>


> On Aug 29, 2016, at 9:48 AM, David Remotti <david at agros.it> wrote:
> 
> Looking for some help in using the "survey" package
> I have gone through the documentation but still find problems in understanding how to prepare my data to be analyzed wih this package.
> 
> In particular I dont understand how to prepare the fpc data.
> The documentation provides a "small survey example" where 6 variables are given:
> stratid,psuids,weight,nh,Nh and x
> 
> My survey is a two stage stratified sampling so I have for each stratum the number of primary
> and secondary units in the sample and in the population, and using these data I can prepare such
> data frame, except for the last variable "x".
> I cant understand what does it means and which information I have to put there.
> 
> A second (minor) problem is that my stratification is based on two variables, but it looks like it is only possible to give 1 variable as strata parameter.
> Is it possible to give two ?

This tutorial by Lumley illustrates both data preparation and the use of a two-stage clustered design:

https://www.unc.edu/courses/2010spring/ecol/562/001/docs/lectures/lecture20.htm#svydesign


Found with a google search on "primary sampling unit secondary sampling unit r survey package lumley"


-- 

David Winsemius
Alameda, CA, USA


From msharp at txbiomed.org  Mon Aug 29 21:23:03 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Mon, 29 Aug 2016 19:23:03 +0000
Subject: [R] How to connect Microsoft Sql server from R studio using
 freeTDS instead of RODBC package
In-Reply-To: <CADG9u0AB3fi_FW8PJr65eB5uyu1vs8BmU_kTHkaio+P9mSexLA@mail.gmail.com>
References: <CADG9u0A1m_eG2F2cX5wbYbjz5P9_BAihnXVP7YxVPCvTdgSMjA@mail.gmail.com>
	<D92BF93E-0D9D-40C2-8172-3ADADA769AA4@TxBiomed.org>
	<CADG9u0AB3fi_FW8PJr65eB5uyu1vs8BmU_kTHkaio+P9mSexLA@mail.gmail.com>
Message-ID: <1812DE00-0317-4621-B620-76D1CB156D86@TxBiomed.org>

Manu,

I believe you are mistaken regarding using freeTDS instead of RODBC. shinyapps.io apparently has freeTDS drivers already installed. I am guessing that either you have not configured your connections string (odbcDriverConnect("driver = FreeTDS; ...")) correctly or your database server has a firewall rule that is not allowing a connection from shinyapps.io.

However, please note, I have not used shinyapps.io and am making these guesses based on my experience with RODBC and the documentation I have read. You will want to find someone with shinyapps.io experience.

Mark

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org

On Aug 29, 2016, at 12:26 PM, Manohar Reddy <manu.reddy52 at gmail.com> wrote:
>
> Hi Mark,
>
>
>   Thank you so much for reply, using exiting ODBC drivers I will make a connection  to sql server and it?s working fine in my local, but as per shinyapps.io I need to use freeTDS drivers instead RODBC ,so that I may not encounter the any issue .For me here challenging work is how to install freeTDS on my machine and how to configure it?
>
>
>      Is there any drivers/way that can i  make a connection to sql server and I shouldn?t encounter the issue after deploying application on shinyapps.io.
>
>
> Thanks,Manu.
>
>
> On Mon, Aug 29, 2016 at 9:35 PM, Mark Sharp <msharp at txbiomed.org> wrote:
> Manu,
>
> Read the first paragraph under section "1 ODBC Concepts" of https://cran.r-project.org/web/packages/RODBC/vignettes/RODBC.pdf. This describes the relationship among the various parts of the technical stack that allows connectivity to the database system via ODBC. One of the points made is that RODBC uses an ODBC driver (e.g., Actual Technologies, Easysoft and OpenLink).
>
> I use the driver from Actual Technologies on Mac OS, but many others have used freeTDS. I had trouble with freeTDS years ago and decided my time was worth the minor cost of using the commercial product from Actual Technologies.
>
> The driver you use is computer OS specific while RODBC is not.
>
> It is also convenient to use an ODBC manager, which is typically a graphical application used to create and manage the configuration files used by the ODBC driver.
>
> Mark
>
> R. Mark Sharp, Ph.D.
> Director of Primate Records Database
> Southwest National Primate Research Center
> Texas Biomedical Research Institute
> P.O. Box 760549
> San Antonio, TX 78245-0549
> Telephone: (210)258-9476
> e-mail: msharp at TxBiomed.org
>
> > On Aug 28, 2016, at 11:53 PM, Manohar Reddy <manu.reddy52 at gmail.com> wrote:
> >
> > Hi,
> >
> >
> >
> >   Can anyone guide me how to connect the Microsoft Sql server 2012/14 from
> > R studio using freeTDS package instead of RODBC ,I can able to connect the
> > MS Sql server from R studio using RODBC.
> >
> >  Actually my requirement is I have developed webpage/report using Shiny
> > package then I was deployed it on Shinyapps.io ,but after deploying I?m
> > encountering error like ??ERROR: *first argument is not an open RODBC
> > channel*? ,based on this error message I did searched in google and found
> > that we need to use freeTDS drivers instead of RODBC but I found some
> > articles regarding freeTDS but it?s not useful for me.
> >
> >
> >
> > I was eagerly waiting for solution from someone since last month, but not
> > yet and this issue is not allowing me to further .Can anyone please help me
> > out me(how to install freeTDS and how to configure it) on same.
> >
> >
> >
> > My environment details :
> >
> >
> >
> >    Os : windows 8
> >
> >    R version 3.3.1 (2016-06-21)
> >
> >
> >
> > Thanks in Advance .
> >
> > Manu.
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
>
>
> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments transmitted, may contain privileged and confidential information and is intended solely for the exclusive use of the individual or entity to whom it is addressed. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution or copying of this e-mail and/or attachments is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender stating that this transmission was misdirected; return the e-mail to sender; destroy all paper copies and delete all electronic copies from your system without disclosing its contents.
>
>
>
> --
>
>
> Thanks,
> Manohar Reddy P
> +91-9705302062.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments transmitted, may contain privileged and confidential information and is intended solely for the exclusive use of the individual or entity to whom it is addressed. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution or copying of this e-mail and/or attachments is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender stating that this transmission was misdirected; return the e-mail to sender; destroy all paper copies and delete all electronic copies from your system without disclosing its contents.

From zibeli at yahoo.com  Mon Aug 29 19:42:03 2016
From: zibeli at yahoo.com (Zibeli Aton)
Date: Mon, 29 Aug 2016 17:42:03 +0000 (UTC)
Subject: [R] possible error in stem() function?
References: <1465902804.1813324.1472492523773.ref@mail.yahoo.com>
Message-ID: <1465902804.1813324.1472492523773@mail.yahoo.com>

Using R-3.3.1 on Linux I seem to sometimes get inaccurate stem-and-leaf plots using stem.  For example:

> x <- c(479,482,487,493,494,494,495,496,497,498,498,499,503,504,507,507,508,
+                 510,511,512,514,516,520,524,525,525,527,534,536,542,545,546,547,549,
+                 557,559,561,561,563,563,567,568,569,570,572,578,584)
> stem(x)

  The decimal point is 1 digit(s) to the right of the |

  46 | 9
  48 | 27344567889
  50 | 3477801246
  52 | 0455746
  54 | 2567979
  56 | 1133789028
  58 | 4

This plot is inaccurate since there are no values 469, 483, 484, etc. in the data.

If I remove one value from the input, then the result appears correct:

> x <- c(479,482,487,493,494,494,495,496,497,498,498,499,503,504,507,507,508,
+                 510,511,512,514,516,520,524,525,525,527,534,536,542,545,546,547,549,
+                 557,559,561,561,563,563,567,568,569,570,572,578)
> stem(x)

  The decimal point is 1 digit(s) to the right of the |

  47 | 9
  48 | 27
  49 | 344567889
  50 | 34778
  51 | 01246
  52 | 04557
  53 | 46
  54 | 25679
  55 | 79
  56 | 1133789
  57 | 028

Is there a limit to the length of the input argument, a bug in the function, or something I'm missing?

Thanks.


From n.msindai.09 at ucl.ac.uk  Mon Aug 29 16:06:30 2016
From: n.msindai.09 at ucl.ac.uk (Msindai, Nadejda)
Date: Mon, 29 Aug 2016 14:06:30 +0000
Subject: [R] Exponential population model
In-Reply-To: <07BFE076-4821-406C-BF6B-762B774B062B@comcast.net>
References: <DB6PR0101MB25502D2F7A21B3796668FF318EEC0@DB6PR0101MB2550.eurprd01.prod.exchangelabs.com>,
	<07BFE076-4821-406C-BF6B-762B774B062B@comcast.net>
Message-ID: <DB6PR0101MB2550DCCC1613499E58D9C7FD8EE10@DB6PR0101MB2550.eurprd01.prod.exchangelabs.com>

Dear David


I think you misunderstood me, I need to find the name for an r package that models the population size from time 0 for a group of animals.


I provided details to make it clearer the type of model I want to run.


The only population model I have come across thus far is Popbio, which appears to be for plants? Therefore, can you assist me by telling me the name for a package that is used to model exponential growth:


Exponential growth model is --

?The exponential growth model assumes that the population starts out at time t=0 at some initial N(0), and growth at constant exponential rate r. If r>0 this results in theoretically unlimited growth over time.  The fundamental equation of growth is

?

?N(t+1)= N(t) exp(r)


I do not have a known growth rate figure for my species, therefore, I plan to use life history data obtained from wild populations (of one particular species) to model the current population size for a group of animals introduced onto an island.


Thank you for your help in this matter


Josephine

________________________________
From: David Winsemius <dwinsemius at comcast.net>
Sent: 27 August 2016 03:32:55
To: Msindai, Nadejda
Cc: r-help at r-project.org
Subject: Re: [R] Exponential population model


> On Aug 26, 2016, at 5:49 AM, Msindai, Nadejda <n.msindai.09 at ucl.ac.uk> wrote:
>
> Dear admin
>
> I am writing to ask for help with writing an R script to model the current population size using life history data (I do not know the intrinsic rate of increase (r)).
>
> My study population are a group of introduced chimpanzees, that were released by the Frankfurt Zoological Society in 1966-1969 onto an island in Lake Victoria.
>
> Thus I want to run a density independent population model using life history data, with 0 net migration/immigration (so this is a closed system).
>
>
> These are the individuals entering the system (in my case arriving on the island), after 1969 no new animals arrive.
>
> Year    1966    1966    1966    1966    1966    1966    1966    1968    1969    1966    1966    1966    1966    1968    1969
> Animal ID       F1      F2      F3      F4      F5      F6      F7      F8      F9      M1      M2      M3      M4      M5      M6
> DOB     1955    1955    1956    1957    1958    1959    1955    1960    1960    1958    1959    1959    1962    1960    1960
>
> Notes:  Year is the year animal was released into the population
>        F=female
>        M=male
>        DOB=date of birth
>
>
> Using the following life history data I want to estimate the population size for the year 1979, 1989, 1999, and 2014, as well as future projection for 2019, 2029 etc.
>
> Age at first birth for females: 11 years
> Birth interval: 55.2 months
> Age at last birth: 50 years (in 40-50 years only 47% of females have offspring)
> Survival to 8 years = 67.7%(Female) 51.4%(Male)
> Survival to 15 years 41%(Female) 27%(Male)
> Survival 15-40 years 18%(Female) 11%(Male)
> Survival 40+ years 7%(M/F)
>
>
>
> Birth ratio set as ___M = Male, F = Female (set as 50:50)
>

This looks like a homework question and Rhelp is specifically announced as not doing homework. See the Posting Guide.

--
David.
>
>
>
> I hope you can be of help
>
> Kind regards
>
> Josephine
>
>
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


	[[alternative HTML version deleted]]


From huanglijuan290441 at gmail.com  Mon Aug 29 18:10:38 2016
From: huanglijuan290441 at gmail.com (lijuan huang)
Date: Mon, 29 Aug 2016 11:10:38 -0500
Subject: [R] Plm function, error in uniqval[as.character(effect), , drop = F]
Message-ID: <CAGXT1657aMGak_e6Q-qn5D=GWdNqn5Dk+0p4+jNCMmCY79yZ3g@mail.gmail.com>

Hi, there,

I am trying to run a panel regression with a huge dataset, which has lots
of missing values.  Here is some description of all variables.

> str(com3)
Classes ?plm.dim? and 'data.frame': 172153 obs. of  30 variables:
 $ tic                 : Factor w/ 3435 levels "A","AA","AAC",..: 1 1 1 1 1
1 1 1 1 1 ...
 $ idate               : Factor w/ 81309 levels "2001/12/31 0:27",..: 34
2371 2450 4789 5977 7297 7650 9988 11288 12749 ...
 $ IS_EFFECTIVE        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ MATERIAL_WEAKNESS   : int  0 0 0 0 0 0 0 0 0 0 ...
 $ SIG_DEFICIENCY      : int  0 0 0 0 0 0 0 0 0 0 ...
 $ NOTEFF_ACC_RULE     : int  0 0 0 0 0 0 0 0 0 0 ...
 $ NOTEFF_FIN_FRAUD    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ NOTEFF_OTHER        : int  0 0 0 0 0 0 0 0 0 0 ...
 $ IC_OP_TYPE_a1m0     : int  NA NA NA NA NA NA NA NA NA NA ...
 $ AUDITOR_FKEY        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ AUDITOR_AGREES      : int  NA NA NA NA NA NA NA NA NA NA ...
 $ COMBINED_IC_OP      : int  NA NA NA NA NA NA NA NA NA NA ...
 $ IC_IS_EFFECTIVE_Y1N0: Factor w/ 4 levels "","0","1","ND": NA NA NA NA NA
NA NA NA NA NA ...
 $ AUDIT_FEES          : int  NA NA NA NA NA NA NA NA NA NA ...
 $ NON_AUDIT_FEES      : int  NA NA NA NA NA NA NA NA NA NA ...
 $ BENEFITS_FEES       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ IT_FEES             : int  NA NA NA NA NA NA NA NA NA NA ...
 $ TAX_FEES            : int  NA NA NA NA NA NA NA NA NA NA ...
 $ AUDIT_RELATED_FEES  : int  NA NA NA NA NA NA NA NA NA NA ...
 $ OTHER_FEES          : int  NA NA NA NA NA NA NA NA NA NA ...
 $ CARD                : int  NA NA NA NA NA NA NA NA NA NA ...
 $ DISC                : int  NA NA NA NA NA NA NA NA NA NA ...
 $ HACK                : int  NA NA NA NA NA NA NA NA NA NA ...
 $ INSD                : int  NA NA NA NA NA NA NA NA NA NA ...
 $ PHYS                : int  NA NA NA NA NA NA NA NA NA NA ...
 $ PORT                : int  NA NA NA NA NA NA NA NA NA NA ...
 $ STAT                : int  NA NA NA NA NA NA NA NA NA NA ...
 $ UNKN                : int  NA NA NA NA NA NA NA NA NA NA ...
 $ BRCH                : int  NA NA NA NA NA NA NA NA NA NA ...
 $ ddate               : Factor w/ 81306 levels "2001/12/31 0:27",..: 34
2371 2450 4789 5977 7297 7650 9988 11288 12749 ...

And I ran a panel regression as follow:

rm(list=ls())
library(plm)
como3 <- read.csv(file.path('como3.csv'),header = T, stringsAsFactors = F)
com3=plm.data(como3, indexes = NULL)
summary(com3)

Y <- cbind(com3$BRCH)
X <-
cbind(com3$IS_EFFECTIVE,com3$MATERIAL_WEAKNESS,com3$SIG_DEFICIENCY,com3$IC_IS_EFFECTIVE_Y1N0,com3$AUDITOR_AGREES,com3$COMBINED_IC_OP,com3$AUDIT_FEES)

fixed <- plm(Y ~ X,com3, index = c("tic","idate"),effect="individual",model
= "within")
summary(fixed)

Unfortunately, I got this error:

series IT_FEES, BRCH are constants and have been removedError in
uniqval[as.character(effect), , drop = F] :
  incorrect number of dimensions


BRCH is my dependent variable, which is a dichotomous variable (happened
=1, unhappen=0). I don't know why it is considered as the "constant"? Does
it cause this error?

I have been looking for a solution in the internet for several days, but
have not found an answer to fix the problem.

Does anybody have an idea what I am doing wrong and what must be done to fix
the problem?

Thanks in advance.

Lynn Huang

	[[alternative HTML version deleted]]


From alexander.sommer at tu-dortmund.de  Mon Aug 29 17:06:59 2016
From: alexander.sommer at tu-dortmund.de (alexander.sommer at tu-dortmund.de)
Date: Mon, 29 Aug 2016 15:06:59 +0000
Subject: [R] Storing business hours
In-Reply-To: <CAF8bMcZRKUkx+1TqHTzXdHLrJrvT+WLF5o=uZt-wZcYVJzefeA@mail.gmail.com>
References: <248BA33BC59279499C246B6EB309AF21016C92D522@ex2010mbx1.tu-dortmund.de>
	<CA+8X3fVpNS73BLDX2qzED3Z3VCyV4V3e3WCuKpTZHBP1EKe2Eg@mail.gmail.com>
	<CAF8bMcZRKUkx+1TqHTzXdHLrJrvT+WLF5o=uZt-wZcYVJzefeA@mail.gmail.com>
Message-ID: <248BA33BC59279499C246B6EB309AF21016C932998@ex2010mbx2.tu-dortmund.de>

Dear Bill,

thank you for your help. I think, I finally understood your advice. At least, this one worked:

library(package = lubridate)   # for a more convenient display of times

i <- 12   # number of time intervals per hour

# creating a data.frame (original example)
business_hours <- data.frame(t = hm(paste(rep(x = 0:23, each = i), rep(x = seq(from = 0, to = 60/i * (i - 1), by = 60/i), times = 24))),
                             A = c(rep(x = 0, times = (8 - (1/i)) * i), 1, rep(x = 0, times = (12   - (1/i)) * i), -1, rep(x = 0, times = (4           ) * i)),
                             B = c(rep(x = 0, times = (9 - (1/i)) * i), 1, rep(x = 0, times = (2.75 - (1/i)) * i), -1, rep(x = 0, times = (1.75 - (1/i)) * i), 1, rep(x = 0, times = (3.5 - (1/i)) * i), -1, rep(x = 0, times = 7 * i)))

# some data analysis
plot(x = rowSums(x = cumsum(business_hours[, -1])), type = "s")

I find some elegance in this solution; still, Jims proposal looks easier to handle to me.

Best regards,

Alex


--
Alexander Sommer
wissenschaftlicher Mitarbeiter

Technische Universit?t Dortmund
Fakult?t Erziehungswissenschaft, Psychologie und Soziologie
Forschungsverbund Deutsches Jugendinstitut/Technische Universit?t Dortmund
Vogelpothsweg 78
44227 Dortmund

Telefon: +49 231 755-8189
Telefax: +49 231 755-6553
E-Mail:  alexander.sommer at tu-dortmund.de
WWW:     http://www.forschungsverbund.tu-dortmund.de/
Wichtiger Hinweis: Die Information in dieser E-Mail ist vertraulich. Sie ist ausschlie?lich f?r den Adressaten bestimmt. Sollten Sie nicht der f?r diese E-Mail bestimmte Adressat sein, unterrichten Sie bitte den Absender und vernichten Sie diese Mail. Vielen Dank.
Unbeschadet der Korrespondenz per E-Mail, sind unsere Erkl?rungen ausschlie?lich final rechtsverbindlich, wenn sie in herk?mmlicher Schriftform (mit eigenh?ndiger Unterschrift) oder durch ?bermittlung eines solchen Schriftst?cks per Telefax erfolgen.

Important note: The information included in this e-mail is confidential. It is solely intended for the recipient. If you are not the intended recipient of this e-mail please contact the sender and delete this message. Thank you. Without prejudice of e-mail correspondence, our statements are only legally binding when they are made in the conventional written form (with personal signature) or when such documents are sent by fax.

From alexander.sommer at tu-dortmund.de  Mon Aug 29 15:34:49 2016
From: alexander.sommer at tu-dortmund.de (alexander.sommer at tu-dortmund.de)
Date: Mon, 29 Aug 2016 13:34:49 +0000
Subject: [R] Storing business hours
In-Reply-To: <CA+8X3fVpNS73BLDX2qzED3Z3VCyV4V3e3WCuKpTZHBP1EKe2Eg@mail.gmail.com>
References: <248BA33BC59279499C246B6EB309AF21016C92D522@ex2010mbx1.tu-dortmund.de>
	<CA+8X3fVpNS73BLDX2qzED3Z3VCyV4V3e3WCuKpTZHBP1EKe2Eg@mail.gmail.com>
Message-ID: <248BA33BC59279499C246B6EB309AF21016C9315DC@ex2010mbx1.tu-dortmund.de>

Cheers Jim!

The 0/1 way seems to work for me. It looks like:

n <-  5   # number of ?shops?
i <- 12   # number of time intervals per hour

# creating a data.frame (the example got random values)
business_hours <- data.frame(1:n, matrix(data = sample(x = c(TRUE, FALSE), size = n * (24 * i), replace = TRUE), ncol = 24 * i))
# column names as the times
colnames(x = business_hours) <- c("Id", paste0("t", sprintf(fmt = "%02d", rep(x = 0:23, each = i)), sprintf(fmt = "%02d", rep(x = seq(from = 0, to = 60/i * (i - 1), by = 60/i), times = 24))))

# some data analysis
plot(x = colSums(x = business_hours[, -1]), type = "s")  # looks odd due to the random assignment of open/closed
summary(object = rowSums(x = business_hours[, -1])/i)    # summary of business duration in hours

Best regards,

Alex


--
Alexander Sommer
wissenschaftlicher Mitarbeiter

Technische Universit?t Dortmund
Fakult?t Erziehungswissenschaft, Psychologie und Soziologie
Forschungsverbund Deutsches Jugendinstitut/Technische Universit?t Dortmund
Vogelpothsweg 78
44227 Dortmund

Telefon: +49 231 755-8189
Telefax: +49 231 755-6553
E-Mail:  alexander.sommer at tu-dortmund.de
WWW:     http://www.forschungsverbund.tu-dortmund.de/

Wichtiger Hinweis: Die Information in dieser E-Mail ist vertraulich. Sie ist ausschlie?lich f?r den Adressaten bestimmt. Sollten Sie nicht der f?r diese E-Mail bestimmte Adressat sein, unterrichten Sie bitte den Absender und vernichten Sie diese Mail. Vielen Dank.
Unbeschadet der Korrespondenz per E-Mail, sind unsere Erkl?rungen ausschlie?lich final rechtsverbindlich, wenn sie in herk?mmlicher Schriftform (mit eigenh?ndiger Unterschrift) oder durch ?bermittlung eines solchen Schriftst?cks per Telefax erfolgen.

Important note: The information included in this e-mail is confidential. It is solely intended for the recipient. If you are not the intended recipient of this e-mail please contact the sender and delete this message. Thank you. Without prejudice of e-mail correspondence, our statements are only legally binding when they are made in the conventional written form (with personal signature) or when such documents are sent by fax.

From murdoch.duncan at gmail.com  Mon Aug 29 22:09:06 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 29 Aug 2016 16:09:06 -0400
Subject: [R] possible error in stem() function?
In-Reply-To: <1465902804.1813324.1472492523773@mail.yahoo.com>
References: <1465902804.1813324.1472492523773.ref@mail.yahoo.com>
	<1465902804.1813324.1472492523773@mail.yahoo.com>
Message-ID: <2912201d-fcb2-8aa9-dbf2-390f82b74dbe@gmail.com>

On 29/08/2016 1:42 PM, Zibeli Aton via R-help wrote:
> Using R-3.3.1 on Linux I seem to sometimes get inaccurate stem-and-leaf plots using stem.  For example:
>
>> x <- c(479,482,487,493,494,494,495,496,497,498,498,499,503,504,507,507,508,
> +                 510,511,512,514,516,520,524,525,525,527,534,536,542,545,546,547,549,
> +                 557,559,561,561,563,563,567,568,569,570,572,578,584)
>> stem(x)
>
>   The decimal point is 1 digit(s) to the right of the |
>
>   46 | 9
>   48 | 27344567889
>   50 | 3477801246
>   52 | 0455746
>   54 | 2567979
>   56 | 1133789028
>   58 | 4
>
> This plot is inaccurate since there are no values 469, 483, 484, etc. in the data.

There's a 479, and a 493, etc.  Since you only have even numbered stems 
you get two decades of leaves on each line.  The ones for the 460's 
would precede the ones for the 470's if there were any; you can see that 
does happen in that the 480's do precede the 490's.

Duncan Murdoch

>
> If I remove one value from the input, then the result appears correct:
>
>> x <- c(479,482,487,493,494,494,495,496,497,498,498,499,503,504,507,507,508,
> +                 510,511,512,514,516,520,524,525,525,527,534,536,542,545,546,547,549,
> +                 557,559,561,561,563,563,567,568,569,570,572,578)
>> stem(x)
>
>   The decimal point is 1 digit(s) to the right of the |
>
>   47 | 9
>   48 | 27
>   49 | 344567889
>   50 | 34778
>   51 | 01246
>   52 | 04557
>   53 | 46
>   54 | 25679
>   55 | 79
>   56 | 1133789
>   57 | 028
>
> Is there a limit to the length of the input argument, a bug in the function, or something I'm missing?
>
> Thanks.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sarah.goslee at gmail.com  Mon Aug 29 22:11:59 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 29 Aug 2016 16:11:59 -0400
Subject: [R] possible error in stem() function?
In-Reply-To: <1465902804.1813324.1472492523773@mail.yahoo.com>
References: <1465902804.1813324.1472492523773.ref@mail.yahoo.com>
	<1465902804.1813324.1472492523773@mail.yahoo.com>
Message-ID: <CAM_vju=D6y9PxOCzhuUt0kguwDuF-DNEkGM3YUoywg-gMXfAVg@mail.gmail.com>

The help isn't particularly helpful, but you need to play with the
scale argument.
The range of your first dataset is long enough that you're getting
only even-numbered stems by default.


Try these:

x1 <- c(479,482,487,493,494,494,495,496,497,498,498,499,503,504,507,507,508,

510,511,512,514,516,520,524,525,525,527,534,536,542,545,546,547,549,
                 557,559,561,561,563,563,567,568,569,570,572,578,584)
stem(x1, scale=1)
summary(x1)
stem(x1, scale=2)

x2 <- c(479,482,487,493,494,494,495,496,497,498,498,499,503,504,507,507,508,

510,511,512,514,516,520,524,525,525,527,534,536,542,545,546,547,549,
                 557,559,561,561,563,563,567,568,569,570,572,578)
stem(x2, scale=1)
summary(x2)
stem(x2, scale=2)



On Mon, Aug 29, 2016 at 1:42 PM, Zibeli Aton via R-help
<r-help at r-project.org> wrote:
> Using R-3.3.1 on Linux I seem to sometimes get inaccurate stem-and-leaf plots using stem.  For example:
>
>> x <- c(479,482,487,493,494,494,495,496,497,498,498,499,503,504,507,507,508,
> +                 510,511,512,514,516,520,524,525,525,527,534,536,542,545,546,547,549,
> +                 557,559,561,561,563,563,567,568,569,570,572,578,584)
>> stem(x)
>
>   The decimal point is 1 digit(s) to the right of the |
>
>   46 | 9
>   48 | 27344567889
>   50 | 3477801246
>   52 | 0455746
>   54 | 2567979
>   56 | 1133789028
>   58 | 4
>
> This plot is inaccurate since there are no values 469, 483, 484, etc. in the data.
>
> If I remove one value from the input, then the result appears correct:
>
>> x <- c(479,482,487,493,494,494,495,496,497,498,498,499,503,504,507,507,508,
> +                 510,511,512,514,516,520,524,525,525,527,534,536,542,545,546,547,549,
> +                 557,559,561,561,563,563,567,568,569,570,572,578)
>> stem(x)
>
>   The decimal point is 1 digit(s) to the right of the |
>
>   47 | 9
>   48 | 27
>   49 | 344567889
>   50 | 34778
>   51 | 01246
>   52 | 04557
>   53 | 46
>   54 | 25679
>   55 | 79
>   56 | 1133789
>   57 | 028
>
> Is there a limit to the length of the input argument, a bug in the function, or something I'm missing?
>
> Thanks.
>


From marius.hofert at uwaterloo.ca  Mon Aug 29 22:52:12 2016
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Mon, 29 Aug 2016 22:52:12 +0200
Subject: [R] How to test existence of an environment and how to remove
 it (from within functions)?
In-Reply-To: <d1d8aef270b04c46ad9cb0bab2af4044@CONNHUB4.connect.uwaterloo.ca>
References: <CAM3-KjapbnvpU=Bfg5XRUVJc+xAvkON6vWSgnkU8NTBdJxV2Cw@mail.gmail.com>
	<d1d8aef270b04c46ad9cb0bab2af4044@CONNHUB4.connect.uwaterloo.ca>
Message-ID: <CAM3-Kjbjvib08gVV7vJqLnbYSBPpHH3OYHh7Fh1kmKAkjUiKBw@mail.gmail.com>

Dear Duncan,

Thanks a lot for your help.

I tried to adapt your example to my MWE, but the subsequent calls of
main() are 'too fast' now: new calls of main() should also 'reset' the
environment (as a different x is generated then), that's why I tried
to remove the environment .my_environ from within main():

## Auxiliary function with caching
aux <- local({
    .my_environ <- new.env(hash = FALSE, parent = emptyenv()) # define
the environment
    function(x) {
        ## Setting up the environment and caching
        if(exists("cached.obj", envir = .my_environ)) { # look-up (in
case the object already exists)
            x.cols <- get("cached.obj", .my_environ)
        } else { # time-consuming part (+ cache)
            x.cols <- split(x, col(x))
            Sys.sleep(1)
            assign("cached.obj", x.cols, envir = .my_environ)
        }
        ## Do something with the result from above (here: pick out two randomly
        ## chosen columns)
        x.cols[sample(1:1000, size = 2)]
    }
})

## Main function
main <- function() {
    x <- matrix(rnorm(100*1000), ncol = 1000)
    res <- replicate(5, aux(x))
    rm(.my_environ) # TODO: Trying to remove the environment
    res
}

## Testing
set.seed(271)
system.time(main()) # => ~ 1s since the cached object is found
system.time(main()) # => ~ 0s (instead of ~ 1s)
system.time(main()) # => ~ 0s (instead of ~ 1s)

Do you know a solution for this?

Background information:
This is indeed a problem from a package which draws many (sub)plots
within a single plot. Each single (sub)plot needs to access the data
for plotting but does not known about the other (sub)plots... Thought
this might be interesting in general for caching results.

Thanks & cheers,
Marius



On Mon, Aug 29, 2016 at 7:59 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 29/08/2016 1:36 PM, Marius Hofert wrote:
>> Hi,
>>
>> I have a function main() which calls another function aux() many times. aux()
>> mostly does the same operations based on an object and thus I would like it to
>> compute and store this object for each call from main() only once.
>>
>> Below are two versions of a MWE. The first one computes the right result (but is
>> merely there for showing what I would like to have; well, apart from the
>> environment .my_environ still floating around after main() is called).
>> It works with an
>> environment .my_environ in which the computed object is stored. The
>> second MWE tries to set
>> up the environment inside aux(), but neither the check of existence in
>> aux() nor the
>> removal of the whole environment in main() work (see 'TODO' below). How can this
>> be achieved?
>>
>
> If you create aux in a local() call, it can have persistent storage,
> because local() creates an environment to hold it.  For example,
>
> aux <- local({
>    persistent <- NULL
>    function(x) {
>      if (!is.null(persistent))
>        message("Previous arg was ", persistent)
>      persistent <<- x
>    }
> })
>
> Note that the assignment uses <<- to work in the local-created
> environment rather than purely locally within the evaluation frame of
> the call.  You need to create the variable "persistent" there, or the
> assignment would go to the global environment, which is bad.
>
> This gives
>
>  > aux(1)
>  > aux(2)
> Previous arg was 1
>  > aux(3)
> Previous arg was 2
>
> Duncan Murdoch
>
>> Cheers,
>> Marius
>>
>>
>> ### Version 1: Setting up the environment in .GlobalEnv ########################
>>
>> .my_environ <- new.env(hash = FALSE, parent = emptyenv()) # define the
>> environment
>>
>> ## Auxiliary function with caching
>> aux <- function(x) {
>>     ## Setting up the environment and caching
>>     if(exists("cached.obj", envir = .my_environ)) { # look-up (in case
>> the object already exists)
>>         x.cols <- get("cached.obj", .my_environ)
>>     } else { # time-consuming part (+ cache)
>>         x.cols <- split(x, col(x))
>>         Sys.sleep(1)
>>         assign("cached.obj", x.cols, envir = .my_environ)
>>     }
>>     ## Do something with the result from above (here: pick out two randomly
>>     ## chosen columns)
>>     x.cols[sample(1:1000, size = 2)]
>> }
>>
>> ## Main function
>> main <- function() {
>>     x <- matrix(rnorm(100*1000), ncol = 1000)
>>     res <- replicate(5, aux(x))
>>     rm(cached.obj, envir = .my_environ) # only removing the *object*
>> (but not the environment)
>>     res
>> }
>>
>> ## Testing
>> set.seed(271)
>> system.time(main()) # => ~ 1s since the cached object is found
>>
>>
>> ### Version 2: Trying to set up the environment inside aux() ###################
>>
>> ## Auxiliary function with caching
>> aux <- function(x) {
>>     ## Setting up the environment and caching
>>     if(!exists(".my_environ", mode = "environmnent")) # TODO: How to
>> check the existence of the environment? This is always TRUE...
>>         .my_environ <- new.env(hash = FALSE, parent = emptyenv()) #
>> define the environment
>>     if(exists("cached.obj", envir = .my_environ)) { # look-up (in case
>> the object already exists)
>>         x.cols <- get("cached.obj", .my_environ)
>>     } else { # time-consuming part (+ cache)
>>         x.cols <- split(x, col(x))
>>         Sys.sleep(1)
>>         assign("cached.obj", x.cols, envir = .my_environ)
>>     }
>>     ## Do something with the result from above (here: pick out two randomly
>>     ## chosen columns)
>>     x.cols[sample(1:1000, size = 2)]
>> }
>>
>> ## Main function
>> main <- function() {
>>     x <- matrix(rnorm(100*1000), ncol = 1000)
>>     res <- replicate(5, aux(x))
>>     rm(.my_environ) # TODO: How to properly remove the environment?
>>     res
>> }
>>
>> ## Testing
>> set.seed(271)
>> system.time(main()) # => ~ 5s since (the cached object in) environment
>> .my_environ is not found
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From murdoch.duncan at gmail.com  Tue Aug 30 00:34:19 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 29 Aug 2016 18:34:19 -0400
Subject: [R] How to test existence of an environment and how to remove
 it (from within functions)?
In-Reply-To: <CAM3-Kjbjvib08gVV7vJqLnbYSBPpHH3OYHh7Fh1kmKAkjUiKBw@mail.gmail.com>
References: <CAM3-KjapbnvpU=Bfg5XRUVJc+xAvkON6vWSgnkU8NTBdJxV2Cw@mail.gmail.com>
	<d1d8aef270b04c46ad9cb0bab2af4044@CONNHUB4.connect.uwaterloo.ca>
	<CAM3-Kjbjvib08gVV7vJqLnbYSBPpHH3OYHh7Fh1kmKAkjUiKBw@mail.gmail.com>
Message-ID: <be0babe6-a4a0-f357-66cf-15bf7ac2b494@gmail.com>

On 29/08/2016 4:52 PM, Marius Hofert wrote:
> Dear Duncan,
>
> Thanks a lot for your help.
>
> I tried to adapt your example to my MWE, but the subsequent calls of
> main() are 'too fast' now: new calls of main() should also 'reset' the
> environment (as a different x is generated then), that's why I tried
> to remove the environment .my_environ from within main():
>
> ## Auxiliary function with caching
> aux <- local({
>     .my_environ <- new.env(hash = FALSE, parent = emptyenv()) # define
> the environment
>     function(x) {
>         ## Setting up the environment and caching
>         if(exists("cached.obj", envir = .my_environ)) { # look-up (in
> case the object already exists)

How do you know that's the "right" value?  Just because something is 
cached doesn't mean it's the value corresponding to "x".

You can use some sort of hash to cache values corresponding to 
particular x values, e.g.


hash <- digest::digest(x)
if (exists(hash, envir = .my_environ))
   x.cols <- get(hash, .my_environ)

The memoise package does all of this for you.  You provide the slow 
function aux, then call

aux <- memoise(aux)

and suddenly it will magically remember previously calculated values. 
There are ways to get old values to timeout automatically, etc.

Duncan Murdoch



>             x.cols <- get("cached.obj", .my_environ)
>         } else { # time-consuming part (+ cache)
>             x.cols <- split(x, col(x))
>             Sys.sleep(1)
>             assign("cached.obj", x.cols, envir = .my_environ)
>         }
>         ## Do something with the result from above (here: pick out two randomly
>         ## chosen columns)
>         x.cols[sample(1:1000, size = 2)]
>     }
> })
>
> ## Main function
> main <- function() {
>     x <- matrix(rnorm(100*1000), ncol = 1000)
>     res <- replicate(5, aux(x))
>     rm(.my_environ) # TODO: Trying to remove the environment
>     res
> }
>
> ## Testing
> set.seed(271)
> system.time(main()) # => ~ 1s since the cached object is found
> system.time(main()) # => ~ 0s (instead of ~ 1s)
> system.time(main()) # => ~ 0s (instead of ~ 1s)
>
> Do you know a solution for this?
>
> Background information:
> This is indeed a problem from a package which draws many (sub)plots
> within a single plot. Each single (sub)plot needs to access the data
> for plotting but does not known about the other (sub)plots... Thought
> this might be interesting in general for caching results.
>
> Thanks & cheers,
> Marius
>
>
>
> On Mon, Aug 29, 2016 at 7:59 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 29/08/2016 1:36 PM, Marius Hofert wrote:
>>> Hi,
>>>
>>> I have a function main() which calls another function aux() many times. aux()
>>> mostly does the same operations based on an object and thus I would like it to
>>> compute and store this object for each call from main() only once.
>>>
>>> Below are two versions of a MWE. The first one computes the right result (but is
>>> merely there for showing what I would like to have; well, apart from the
>>> environment .my_environ still floating around after main() is called).
>>> It works with an
>>> environment .my_environ in which the computed object is stored. The
>>> second MWE tries to set
>>> up the environment inside aux(), but neither the check of existence in
>>> aux() nor the
>>> removal of the whole environment in main() work (see 'TODO' below). How can this
>>> be achieved?
>>>
>>
>> If you create aux in a local() call, it can have persistent storage,
>> because local() creates an environment to hold it.  For example,
>>
>> aux <- local({
>>    persistent <- NULL
>>    function(x) {
>>      if (!is.null(persistent))
>>        message("Previous arg was ", persistent)
>>      persistent <<- x
>>    }
>> })
>>
>> Note that the assignment uses <<- to work in the local-created
>> environment rather than purely locally within the evaluation frame of
>> the call.  You need to create the variable "persistent" there, or the
>> assignment would go to the global environment, which is bad.
>>
>> This gives
>>
>>  > aux(1)
>>  > aux(2)
>> Previous arg was 1
>>  > aux(3)
>> Previous arg was 2
>>
>> Duncan Murdoch
>>
>>> Cheers,
>>> Marius
>>>
>>>
>>> ### Version 1: Setting up the environment in .GlobalEnv ########################
>>>
>>> .my_environ <- new.env(hash = FALSE, parent = emptyenv()) # define the
>>> environment
>>>
>>> ## Auxiliary function with caching
>>> aux <- function(x) {
>>>     ## Setting up the environment and caching
>>>     if(exists("cached.obj", envir = .my_environ)) { # look-up (in case
>>> the object already exists)
>>>         x.cols <- get("cached.obj", .my_environ)
>>>     } else { # time-consuming part (+ cache)
>>>         x.cols <- split(x, col(x))
>>>         Sys.sleep(1)
>>>         assign("cached.obj", x.cols, envir = .my_environ)
>>>     }
>>>     ## Do something with the result from above (here: pick out two randomly
>>>     ## chosen columns)
>>>     x.cols[sample(1:1000, size = 2)]
>>> }
>>>
>>> ## Main function
>>> main <- function() {
>>>     x <- matrix(rnorm(100*1000), ncol = 1000)
>>>     res <- replicate(5, aux(x))
>>>     rm(cached.obj, envir = .my_environ) # only removing the *object*
>>> (but not the environment)
>>>     res
>>> }
>>>
>>> ## Testing
>>> set.seed(271)
>>> system.time(main()) # => ~ 1s since the cached object is found
>>>
>>>
>>> ### Version 2: Trying to set up the environment inside aux() ###################
>>>
>>> ## Auxiliary function with caching
>>> aux <- function(x) {
>>>     ## Setting up the environment and caching
>>>     if(!exists(".my_environ", mode = "environmnent")) # TODO: How to
>>> check the existence of the environment? This is always TRUE...
>>>         .my_environ <- new.env(hash = FALSE, parent = emptyenv()) #
>>> define the environment
>>>     if(exists("cached.obj", envir = .my_environ)) { # look-up (in case
>>> the object already exists)
>>>         x.cols <- get("cached.obj", .my_environ)
>>>     } else { # time-consuming part (+ cache)
>>>         x.cols <- split(x, col(x))
>>>         Sys.sleep(1)
>>>         assign("cached.obj", x.cols, envir = .my_environ)
>>>     }
>>>     ## Do something with the result from above (here: pick out two randomly
>>>     ## chosen columns)
>>>     x.cols[sample(1:1000, size = 2)]
>>> }
>>>
>>> ## Main function
>>> main <- function() {
>>>     x <- matrix(rnorm(100*1000), ncol = 1000)
>>>     res <- replicate(5, aux(x))
>>>     rm(.my_environ) # TODO: How to properly remove the environment?
>>>     res
>>> }
>>>
>>> ## Testing
>>> set.seed(271)
>>> system.time(main()) # => ~ 5s since (the cached object in) environment
>>> .my_environ is not found
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>


From zibeli at yahoo.com  Tue Aug 30 02:31:18 2016
From: zibeli at yahoo.com (Zibeli Aton)
Date: Tue, 30 Aug 2016 00:31:18 +0000 (UTC)
Subject: [R] possible error in stem() function?
References: <1644618342.2097806.1472517078555.ref@mail.yahoo.com>
Message-ID: <1644618342.2097806.1472517078555@mail.yahoo.com>

Thanks, Duncan.  I hadn't even noticed that there were no odd stems - makes perfect sense now.

--------------------------------------------
On Mon, 8/29/16, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

 Subject: Re: [R] possible error in stem() function?

 Date: Monday, August 29, 2016, 4:09 PM

 On 29/08/2016 1:42 PM,
 Zibeli Aton via R-help wrote:
 > Using
 R-3.3.1 on Linux I seem to sometimes get inaccurate
 stem-and-leaf plots using stem.? For example:
 >
 >> x <-
 c(479,482,487,493,494,494,495,496,497,498,498,499,503,504,507,507,508,
 > +? ? ? ? ? ? ?
 ???510,511,512,514,516,520,524,525,525,527,534,536,542,545,546,547,549,
 > +? ? ? ? ? ? ?
 ???557,559,561,561,563,563,567,568,569,570,572,578,584)
 >> stem(x)
 >
 >???The decimal point is 1
 digit(s) to the right of the |
 >
 >???46 | 9
 >???48 | 27344567889
 >???50 | 3477801246
 >???52 | 0455746
 >???54 | 2567979
 >???56 | 1133789028
 >???58 | 4
 >
 > This plot is
 inaccurate since there are no values 469, 483, 484, etc. in
 the data.

 There's a
 479, and a 493, etc.? Since you only have even numbered
 stems 
 you get two decades of leaves on each
 line.? The ones for the 460's 
 would
 precede the ones for the 470's if there were any; you
 can see that 
 does happen in that the
 480's do precede the 490's.

 Duncan Murdoch

 >
 > If I remove one value from the input, then
 the result appears correct:
 >
 >> x <-
 c(479,482,487,493,494,494,495,496,497,498,498,499,503,504,507,507,508,
 > +? ? ? ? ? ? ?
 ???510,511,512,514,516,520,524,525,525,527,534,536,542,545,546,547,549,
 > +? ? ? ? ? ? ?
 ???557,559,561,561,563,563,567,568,569,570,572,578)
 >> stem(x)
 >
 >???The decimal point is 1
 digit(s) to the right of the |
 >
 >???47 | 9
 >???48 | 27
 >???49 | 344567889
 >???50 | 34778
 >???51 | 01246
 >???52 | 04557
 >???53 | 46
 >???54 | 25679
 >???55 | 79
 >???56 | 1133789
 >???57 | 028
 >
 > Is there a limit to
 the length of the input argument, a bug in the function, or
 something I'm missing?
 >
 > Thanks.
 >
 >
 ______________________________________________
 > R-help at r-project.org
 mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 > and provide commented, minimal,
 self-contained, reproducible code.
 >


From zibeli at yahoo.com  Tue Aug 30 02:32:50 2016
From: zibeli at yahoo.com (Zibeli Aton)
Date: Tue, 30 Aug 2016 00:32:50 +0000 (UTC)
Subject: [R] possible error in stem() function?
References: <749252685.2079285.1472517170479.ref@mail.yahoo.com>
Message-ID: <749252685.2079285.1472517170479@mail.yahoo.com>

And thanks, Sarah, using scale=2 got me the sort of plot I was looking for.  I agree the help is a bit thin on that function.

--------------------------------------------
On Mon, 8/29/16, Sarah Goslee <sarah.goslee at gmail.com> wrote:

 Subject: Re: [R] possible error in stem() function?

 Cc: "r-help" <r-help at r-project.org>
 Date: Monday, August 29, 2016, 4:11 PM

 The help isn't
 particularly helpful, but you need to play with the
 scale argument.
 The range of
 your first dataset is long enough that you're getting
 only even-numbered stems by default.


 Try these:

 x1 <-
 c(479,482,487,493,494,494,495,496,497,498,498,499,503,504,507,507,508,

 510,511,512,514,516,520,524,525,525,527,534,536,542,545,546,547,549,
 ? ? ? ? ? ? ?
 ???557,559,561,561,563,563,567,568,569,570,572,578,584)
 stem(x1, scale=1)
 summary(x1)
 stem(x1,
 scale=2)

 x2 <-
 c(479,482,487,493,494,494,495,496,497,498,498,499,503,504,507,507,508,

 510,511,512,514,516,520,524,525,525,527,534,536,542,545,546,547,549,
 ? ? ? ? ? ? ?
 ???557,559,561,561,563,563,567,568,569,570,572,578)
 stem(x2, scale=1)
 summary(x2)
 stem(x2,
 scale=2)



 On Mon, Aug 29, 2016 at 1:42 PM, Zibeli Aton
 via R-help
 <r-help at r-project.org>
 wrote:
 > Using R-3.3.1 on Linux I seem to
 sometimes get inaccurate stem-and-leaf plots using stem.?
 For example:
 >
 >> x
 <-
 c(479,482,487,493,494,494,495,496,497,498,498,499,503,504,507,507,508,
 > +? ? ? ? ? ? ?
 ???510,511,512,514,516,520,524,525,525,527,534,536,542,545,546,547,549,
 > +? ? ? ? ? ? ?
 ???557,559,561,561,563,563,567,568,569,570,572,578,584)
 >> stem(x)
 >
 >???The decimal point is 1
 digit(s) to the right of the |
 >
 >???46 | 9
 >???48 | 27344567889
 >???50 | 3477801246
 >???52 | 0455746
 >???54 | 2567979
 >???56 | 1133789028
 >???58 | 4
 >
 > This plot is
 inaccurate since there are no values 469, 483, 484, etc. in
 the data.
 >
 > If I
 remove one value from the input, then the result appears
 correct:
 >
 >> x
 <-
 c(479,482,487,493,494,494,495,496,497,498,498,499,503,504,507,507,508,
 > +? ? ? ? ? ? ?
 ???510,511,512,514,516,520,524,525,525,527,534,536,542,545,546,547,549,
 > +? ? ? ? ? ? ?
 ???557,559,561,561,563,563,567,568,569,570,572,578)
 >> stem(x)
 >
 >???The decimal point is 1
 digit(s) to the right of the |
 >
 >???47 | 9
 >???48 | 27
 >???49 | 344567889
 >???50 | 34778
 >???51 | 01246
 >???52 | 04557
 >???53 | 46
 >???54 | 25679
 >???55 | 79
 >???56 | 1133789
 >???57 | 028
 >
 > Is there a limit to
 the length of the input argument, a bug in the function, or
 something I'm missing?
 >
 > Thanks.
 >


From drjimlemon at gmail.com  Tue Aug 30 03:38:38 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 30 Aug 2016 11:38:38 +1000
Subject: [R] Exponential population model
In-Reply-To: <DB6PR0101MB2550DCCC1613499E58D9C7FD8EE10@DB6PR0101MB2550.eurprd01.prod.exchangelabs.com>
References: <DB6PR0101MB25502D2F7A21B3796668FF318EEC0@DB6PR0101MB2550.eurprd01.prod.exchangelabs.com>
	<07BFE076-4821-406C-BF6B-762B774B062B@comcast.net>
	<DB6PR0101MB2550DCCC1613499E58D9C7FD8EE10@DB6PR0101MB2550.eurprd01.prod.exchangelabs.com>
Message-ID: <CA+8X3fUHyUrk3n_aOPDTFawe92+4rYVbHNqPFvNUkjA=Re1pwg@mail.gmail.com>

Hi Josephine,
Given the parameters you describe, you will probably have to write a
function to update the database of animals at regular intervals. You
can then run a number of repeats to get a better estimate of the final
populations. I tried this and it appears to work. I don't know of any
existing package that will accomplish something this specific.

Jim


From adityapant1 at gmail.com  Mon Aug 29 10:39:16 2016
From: adityapant1 at gmail.com (aditya pant)
Date: Mon, 29 Aug 2016 14:09:16 +0530
Subject: [R] How to split a data.frame into its columns?
In-Reply-To: <392D5713-0897-4387-89DC-C60ACFCE9ACF@comcast.net>
References: <CAM3-KjaK0V+ZbmKu7BLTCtBR6G4vBL+evg2cDMDrGTUnr355wQ@mail.gmail.com>
	<392D5713-0897-4387-89DC-C60ACFCE9ACF@comcast.net>
Message-ID: <57c3f4c5.0232420a.60e83.252e@mx.google.com>


^^??????),,,

-----Original Message-----
From: "David Winsemius" <dwinsemius at comcast.net>
Sent: ?29-?08-?2016 11:59
To: "Marius Hofert" <marius.hofert at uwaterloo.ca>
Cc: "R-help" <r-help at r-project.org>
Subject: Re: [R] How to split a data.frame into its columns?


> On Aug 28, 2016, at 11:14 PM, Marius Hofert <marius.hofert at uwaterloo.ca> wrote:
> 
> Hi,
> 
> I need a fast way to split a data.frame (and matrix) into a list of
> columns.

This is a bit of a puzzle since data.frame objects are by definition "lists of columns".

If you want a data.frame object (say it's name is dat) to _only be a list of columns then

dat <- unclass(dat)

The split.data.frame function splits by rows since that is the most desired and expected behavior and because the authors of S/R probably thought there was no point in making the split "by columns" when it already was.

-- 
David.

> For matrices, split(x, col(x)) works (which can then be done
> in C for speed-up, if necessary), but for a data.frame? split(iris,
> col(iris)) does not work as expected (?).
> The outcome should be lapply(seq_len(ncol(iris)), function(j)
> iris[,j]) and not require additional packages (if possible).
> 
> Thanks & cheers,
> Marius
> 
> PS: Below is the C code for matrices. Not sure how easy it would be to
> extend that to data.frames (?)
> 
> SEXP col_split(SEXP x)
> {
>    /* Setup */
>    int *dims = INTEGER(getAttrib(x, R_DimSymbol));
>    int n = dims[0], d = dims[1];
>    SEXP res = PROTECT(allocVector(VECSXP, d));
>    SEXP ref;
>    int i = 0, j, k;
> 
>    /* Distinguish int/real matrices */
>    switch (TYPEOF(x)) {
>    case INTSXP:
>    for(j = 0; j < d; j++) {
>    SET_VECTOR_ELT(res, j, allocVector(INTSXP, n));
>    int *e = INTEGER(VECTOR_ELT(res, j));
>    for(k = 0 ; k < n ; i++, k++) {
>    e[k] = INTEGER(x)[i];
>    }
>    }
>    break;
>    case REALSXP:
>    for(j = 0; j < d; j++) {
>    SET_VECTOR_ELT(res, j, allocVector(REALSXP, n));
>    double *e = REAL(VECTOR_ELT(res, j));
>    for(k = 0 ; k < n ; i++, k++) {
>    e[k] = REAL(x)[i];
>    }
>    }
>    break;
>    case LGLSXP:
>    for(j = 0; j < d; j++) {
>    SET_VECTOR_ELT(res, j, allocVector(LGLSXP, n));
>    int *e = LOGICAL(VECTOR_ELT(res, j));
>    for(k = 0 ; k < n ; i++, k++) {
>    e[k] = LOGICAL(x)[i];
>    }
>    }
>    break;
>    case STRSXP:
>    for(j = 0; j < d; j++) {
> ref = allocVector(STRSXP, n);
>    SET_VECTOR_ELT(res, j, ref);
>    ref = VECTOR_ELT(res, j);
>    for(k = 0 ; k < n ; i++, k++) {
>    SET_STRING_ELT(ref, k, STRING_ELT(x, i));
>    }
>    }
>    break;
>    default: error("Wrong type of 'x': %s", CHAR(type2str_nowarn(TYPEOF(x))));
>    }
> 
>    /* Return */
>    UNPROTECT(1);
>    return(res);
> }
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Jacob.Strunk at dnr.wa.gov  Mon Aug 29 23:52:42 2016
From: Jacob.Strunk at dnr.wa.gov (Strunk, Jacob (DNR))
Date: Mon, 29 Aug 2016 21:52:42 +0000
Subject: [R] package.skeleton fails
In-Reply-To: <ba8fcf98-e537-81cf-d1ec-6b8a5c1215a5@statistik.tu-dortmund.de>
References: <72D7DF49EFB92E4A9BE47205A0F4F03222C1F9C5@WAXMXOLYMB016.WAX.wa.lcl>
	<ba8fcf98-e537-81cf-d1ec-6b8a5c1215a5@statistik.tu-dortmund.de>
Message-ID: <72D7DF49EFB92E4A9BE47205A0F4F03222C29D1F@WAXMXOLYMB016.WAX.wa.lcl>

Ok, I apologize - we seem to have a component in our environment that interacts with this function. Thank you for your help.

You wouldn't happen to know if there is there a way to modify the way the environment is loaded in package.skeleton? - I don't see any way to pass it a configuration option like "--no-site-file"

Thank you,

Jacob 

-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.tu-dortmund.de] 
Sent: Sunday, August 28, 2016 7:28 AM
To: Strunk, Jacob (DNR) <Jacob.Strunk at dnr.wa.gov>; r-help at r-project.org
Subject: Re: [R] package.skeleton fails

Your code works for me, and I do not see any lapply in the example you provide below.

Best,
Uwe Ligges



On 24.08.2016 21:21, Strunk, Jacob (DNR) wrote:
> Hello, I have been using package.skeleton from within an lapply 
> statement successfully (assuming good source code) with the following 
> setup in the
> past:
>
> writeLines("testfun=function(){}", "c:\\temp\\testfun.r") 
> x=try(package.skeleton("test_pack",path="c:\\temp\\tests\\",code_files
> = "c:\\temp\\testfun.r"))
>
> but it now fails with the error:
>
> Error: evaluation nested too deeply: infinite recursion / 
> options(expressions=)?
>
> I am working in RStudio Version 0.99.896, with 64 bit R version 3.3.1
> (2016-06-21)
>
> I have been poking in the code and the error appears happen within the subfunction '.fixPackageFileNames'
>
> Thanks for any assistance you might be able to provide.
>
> Jacob
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From matthieu.lesnoff at gmail.com  Tue Aug 30 08:50:35 2016
From: matthieu.lesnoff at gmail.com (lesnoff)
Date: Tue, 30 Aug 2016 08:50:35 +0200
Subject: [R] Exponential population model
In-Reply-To: <DB6PR0101MB2550DCCC1613499E58D9C7FD8EE10@DB6PR0101MB2550.eurprd01.prod.exchangelabs.com>
References: <DB6PR0101MB25502D2F7A21B3796668FF318EEC0@DB6PR0101MB2550.eurprd01.prod.exchangelabs.com>
	<07BFE076-4821-406C-BF6B-762B774B062B@comcast.net>
	<DB6PR0101MB2550DCCC1613499E58D9C7FD8EE10@DB6PR0101MB2550.eurprd01.prod.exchangelabs.com>
Message-ID: <ca5a6652-831a-eca3-616e-cf85574ba636@gmail.com>

Dear Josephine
I think you may easily build such a model with the mmage package 
available at http://livtools.cirad.fr/mmage
Best Regards
Matthieu

On 29/08/2016 16:06, Msindai, Nadejda wrote:
> Dear David
>
>
> I think you misunderstood me, I need to find the name for an r package that models the population size from time 0 for a group of animals.
>
>
> I provided details to make it clearer the type of model I want to run.
>
>
> The only population model I have come across thus far is Popbio, which appears to be for plants? Therefore, can you assist me by telling me the name for a package that is used to model exponential growth:
>
>
> Exponential growth model is --
>
> ?The exponential growth model assumes that the population starts out at time t=0 at some initial N(0), and growth at constant exponential rate r. If r>0 this results in theoretically unlimited growth over time.  The fundamental equation of growth is
>
> ?
>
> ?N(t+1)= N(t) exp(r)
>
>
> I do not have a known growth rate figure for my species, therefore, I plan to use life history data obtained from wild populations (of one particular species) to model the current population size for a group of animals introduced onto an island.
>
>
> Thank you for your help in this matter
>
>
> Josephine
>
> ________________________________
> From: David Winsemius <dwinsemius at comcast.net>
> Sent: 27 August 2016 03:32:55
> To: Msindai, Nadejda
> Cc: r-help at r-project.org
> Subject: Re: [R] Exponential population model
>
>
>> On Aug 26, 2016, at 5:49 AM, Msindai, Nadejda <n.msindai.09 at ucl.ac.uk> wrote:
>>
>> Dear admin
>>
>> I am writing to ask for help with writing an R script to model the current population size using life history data (I do not know the intrinsic rate of increase (r)).
>>
>> My study population are a group of introduced chimpanzees, that were released by the Frankfurt Zoological Society in 1966-1969 onto an island in Lake Victoria.
>>
>> Thus I want to run a density independent population model using life history data, with 0 net migration/immigration (so this is a closed system).
>>
>>
>> These are the individuals entering the system (in my case arriving on the island), after 1969 no new animals arrive.
>>
>> Year    1966    1966    1966    1966    1966    1966    1966    1968    1969    1966    1966    1966    1966    1968    1969
>> Animal ID       F1      F2      F3      F4      F5      F6      F7      F8      F9      M1      M2      M3      M4      M5      M6
>> DOB     1955    1955    1956    1957    1958    1959    1955    1960    1960    1958    1959    1959    1962    1960    1960
>>
>> Notes:  Year is the year animal was released into the population
>>        F=female
>>        M=male
>>        DOB=date of birth
>>
>>
>> Using the following life history data I want to estimate the population size for the year 1979, 1989, 1999, and 2014, as well as future projection for 2019, 2029 etc.
>>
>> Age at first birth for females: 11 years
>> Birth interval: 55.2 months
>> Age at last birth: 50 years (in 40-50 years only 47% of females have offspring)
>> Survival to 8 years = 67.7%(Female) 51.4%(Male)
>> Survival to 15 years 41%(Female) 27%(Male)
>> Survival 15-40 years 18%(Female) 11%(Male)
>> Survival 40+ years 7%(M/F)
>>
>>
>>
>> Birth ratio set as ___M = Male, F = Female (set as 50:50)
>>
>
> This looks like a homework question and Rhelp is specifically announced as not doing homework. See the Posting Guide.
>
> --
> David.
>>
>>
>>
>> I hope you can be of help
>>
>> Kind regards
>>
>> Josephine
>>
>>
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Matthieu Lesnoff
CIRAD
Campus de Baillarguet
TA C-112 / A (B?t. A)
34398 Montpellier Cedex 5
Off.: +33 4 67 59 38 66
Secret.: +33 4 67 59 38 63
Mob.: +33 6 22 16 10 22
E-mail: matthieu.lesnoff at cirad.fr


From manu.reddy52 at gmail.com  Tue Aug 30 14:05:54 2016
From: manu.reddy52 at gmail.com (Manohar Reddy)
Date: Tue, 30 Aug 2016 17:35:54 +0530
Subject: [R] How to connect Microsoft Sql server from R studio using
 freeTDS instead of RODBC package
In-Reply-To: <1812DE00-0317-4621-B620-76D1CB156D86@TxBiomed.org>
References: <CADG9u0A1m_eG2F2cX5wbYbjz5P9_BAihnXVP7YxVPCvTdgSMjA@mail.gmail.com>
	<D92BF93E-0D9D-40C2-8172-3ADADA769AA4@TxBiomed.org>
	<CADG9u0AB3fi_FW8PJr65eB5uyu1vs8BmU_kTHkaio+P9mSexLA@mail.gmail.com>
	<1812DE00-0317-4621-B620-76D1CB156D86@TxBiomed.org>
Message-ID: <CADG9u0AZCeN+7RDbGP+h+mx4pytDx9bk3s-4PoZTB2umu+TU0A@mail.gmail.com>

Hi Mark,



  Thanks,as per your suggestion and based on below link, I?m trying to
connect my remote server but while connecting I have encountered attached
error, can you please look in that and help out me.



  Link : https://groups.google.com/forum/#!topic/shinyapps-users/hs4bQHsk9JU



 Note :



1.       I tired without freeTDS versions also though nolock

2.       We have set it my remote sql server like by default it will allow
all the connections.



Thnaks,Manu.

On Tue, Aug 30, 2016 at 12:53 AM, Mark Sharp <msharp at txbiomed.org> wrote:

> Manu,
>
> I believe you are mistaken regarding using freeTDS instead of RODBC.
> shinyapps.io apparently has freeTDS drivers already installed. I am
> guessing that either you have not configured your connections string
> (odbcDriverConnect("driver = FreeTDS; ...")) correctly or your database
> server has a firewall rule that is not allowing a connection from
> shinyapps.io.
>
> However, please note, I have not used shinyapps.io and am making these
> guesses based on my experience with RODBC and the documentation I have
> read. You will want to find someone with shinyapps.io experience.
>
> Mark
>
> R. Mark Sharp, Ph.D.
> Director of Primate Records Database
> Southwest National Primate Research Center
> Texas Biomedical Research Institute
> P.O. Box 760549
> San Antonio, TX 78245-0549
> Telephone: (210)258-9476
> e-mail: msharp at TxBiomed.org
>
> On Aug 29, 2016, at 12:26 PM, Manohar Reddy <manu.reddy52 at gmail.com>
> wrote:
> >
> > Hi Mark,
> >
> >
> >   Thank you so much for reply, using exiting ODBC drivers I will make a
> connection  to sql server and it?s working fine in my local, but as per
> shinyapps.io I need to use freeTDS drivers instead RODBC ,so that I may
> not encounter the any issue .For me here challenging work is how to install
> freeTDS on my machine and how to configure it?
> >
> >
> >      Is there any drivers/way that can i  make a connection to sql
> server and I shouldn?t encounter the issue after deploying application on
> shinyapps.io.
> >
> >
> > Thanks,Manu.
> >
> >
> > On Mon, Aug 29, 2016 at 9:35 PM, Mark Sharp <msharp at txbiomed.org> wrote:
> > Manu,
> >
> > Read the first paragraph under section "1 ODBC Concepts" of
> https://cran.r-project.org/web/packages/RODBC/vignettes/RODBC.pdf. This
> describes the relationship among the various parts of the technical stack
> that allows connectivity to the database system via ODBC. One of the points
> made is that RODBC uses an ODBC driver (e.g., Actual Technologies, Easysoft
> and OpenLink).
> >
> > I use the driver from Actual Technologies on Mac OS, but many others
> have used freeTDS. I had trouble with freeTDS years ago and decided my time
> was worth the minor cost of using the commercial product from Actual
> Technologies.
> >
> > The driver you use is computer OS specific while RODBC is not.
> >
> > It is also convenient to use an ODBC manager, which is typically a
> graphical application used to create and manage the configuration files
> used by the ODBC driver.
> >
> > Mark
> >
> > R. Mark Sharp, Ph.D.
> > Director of Primate Records Database
> > Southwest National Primate Research Center
> > Texas Biomedical Research Institute
> > P.O. Box 760549
> > San Antonio, TX 78245-0549
> > Telephone: (210)258-9476
> > e-mail: msharp at TxBiomed.org
> >
> > > On Aug 28, 2016, at 11:53 PM, Manohar Reddy <manu.reddy52 at gmail.com>
> wrote:
> > >
> > > Hi,
> > >
> > >
> > >
> > >   Can anyone guide me how to connect the Microsoft Sql server 2012/14
> from
> > > R studio using freeTDS package instead of RODBC ,I can able to connect
> the
> > > MS Sql server from R studio using RODBC.
> > >
> > >  Actually my requirement is I have developed webpage/report using Shiny
> > > package then I was deployed it on Shinyapps.io ,but after deploying I?m
> > > encountering error like ??ERROR: *first argument is not an open RODBC
> > > channel*? ,based on this error message I did searched in google and
> found
> > > that we need to use freeTDS drivers instead of RODBC but I found some
> > > articles regarding freeTDS but it?s not useful for me.
> > >
> > >
> > >
> > > I was eagerly waiting for solution from someone since last month, but
> not
> > > yet and this issue is not allowing me to further .Can anyone please
> help me
> > > out me(how to install freeTDS and how to configure it) on same.
> > >
> > >
> > >
> > > My environment details :
> > >
> > >
> > >
> > >    Os : windows 8
> > >
> > >    R version 3.3.1 (2016-06-21)
> > >
> > >
> > >
> > > Thanks in Advance .
> > >
> > > Manu.
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> >
> >
> >
> > CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
> transmitted, may contain privileged and confidential information and is
> intended solely for the exclusive use of the individual or entity to whom
> it is addressed. If you are not the intended recipient, you are hereby
> notified that any review, dissemination, distribution or copying of this
> e-mail and/or attachments is strictly prohibited. If you have received this
> e-mail in error, please immediately notify the sender stating that this
> transmission was misdirected; return the e-mail to sender; destroy all
> paper copies and delete all electronic copies from your system without
> disclosing its contents.
> >
> >
> >
> > --
> >
> >
> > Thanks,
> > Manohar Reddy P
> > +91-9705302062.
>
> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
> transmitted, may contain privileged and confidential information and is
> intended solely for the exclusive use of the individual or entity to whom
> it is addressed. If you are not the intended recipient, you are hereby
> notified that any review, dissemination, distribution or copying of this
> e-mail and/or attachments is strictly prohibited. If you have received this
> e-mail in error, please immediately notify the sender stating that this
> transmission was misdirected; return the e-mail to sender; destroy all
> paper copies and delete all electronic copies from your system without
> disclosing its contents.
>



-- 


Thanks,
Manohar Reddy P
+91-9705302062.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: FreeTDS_Error_message.PNG
Type: image/png
Size: 37135 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160830/d9e84096/attachment.png>

From msharp at txbiomed.org  Tue Aug 30 15:26:22 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Tue, 30 Aug 2016 13:26:22 +0000
Subject: [R] How to connect Microsoft Sql server from R studio using
 freeTDS instead of RODBC package
In-Reply-To: <CADG9u0AZCeN+7RDbGP+h+mx4pytDx9bk3s-4PoZTB2umu+TU0A@mail.gmail.com>
References: <CADG9u0A1m_eG2F2cX5wbYbjz5P9_BAihnXVP7YxVPCvTdgSMjA@mail.gmail.com>
	<D92BF93E-0D9D-40C2-8172-3ADADA769AA4@TxBiomed.org>
	<CADG9u0AB3fi_FW8PJr65eB5uyu1vs8BmU_kTHkaio+P9mSexLA@mail.gmail.com>
	<1812DE00-0317-4621-B620-76D1CB156D86@TxBiomed.org>,
	<CADG9u0AZCeN+7RDbGP+h+mx4pytDx9bk3s-4PoZTB2umu+TU0A@mail.gmail.com>
Message-ID: <73C11737-BA64-46BB-BF93-FE3649A84E76@TxBiomed.org>

Manu,

As far as I can tell you have not taken the advice from Wim Jansen, who gave you guidance on how to specify the freetds driver in your connection function. I do not think you need the unixodbc. In my experience having too much is as bad as not having enough.


R. Mark Sharp, Ph.D.
Director Primate Records Database
Southwest National Primate Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX. 78245-0549
(210)258-9476
msharp at TxBiomed.org<mailto:msharp at txbiomed.org>

On Aug 30, 2016, at 07:05, Manohar Reddy <manu.reddy52 at gmail.com<mailto:manu.reddy52 at gmail.com>> wrote:

Hi Mark,

  Thanks,as per your suggestion and based on below link, I?m trying to connect my remote server but while connecting I have encountered attached error, can you please look in that and help out me.

  Link : https://groups.google.com/forum/#!topic/shinyapps-users/hs4bQHsk9JU

 Note :


1.       I tired without freeTDS versions also though nolock

2.       We have set it my remote sql server like by default it will allow all the connections.


Thnaks,Manu.

On Tue, Aug 30, 2016 at 12:53 AM, Mark Sharp <msharp at txbiomed.org<mailto:msharp at txbiomed.org>> wrote:
Manu,

I believe you are mistaken regarding using freeTDS instead of RODBC. shinyapps.io<http://shinyapps.io> apparently has freeTDS drivers already installed. I am guessing that either you have not configured your connections string (odbcDriverConnect("driver = FreeTDS; ...")) correctly or your database server has a firewall rule that is not allowing a connection from shinyapps.io<http://shinyapps.io>.

However, please note, I have not used shinyapps.io<http://shinyapps.io> and am making these guesses based on my experience with RODBC and the documentation I have read. You will want to find someone with shinyapps.io<http://shinyapps.io> experience.

Mark

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org<mailto:msharp at txbiomed.org>

On Aug 29, 2016, at 12:26 PM, Manohar Reddy <manu.reddy52 at gmail.com<mailto:manu.reddy52 at gmail.com>> wrote:
>
> Hi Mark,
>
>
>   Thank you so much for reply, using exiting ODBC drivers I will make a connection  to sql server and it?s working fine in my local, but as per shinyapps.io<http://shinyapps.io> I need to use freeTDS drivers instead RODBC ,so that I may not encounter the any issue .For me here challenging work is how to install freeTDS on my machine and how to configure it?
>
>
>      Is there any drivers/way that can i  make a connection to sql server and I shouldn?t encounter the issue after deploying application on shinyapps.io<http://shinyapps.io>.
>
>
> Thanks,Manu.
>
>
> On Mon, Aug 29, 2016 at 9:35 PM, Mark Sharp <msharp at txbiomed.org<mailto:msharp at txbiomed.org>> wrote:
> Manu,
>
> Read the first paragraph under section "1 ODBC Concepts" of https://cran.r-project.org/web/packages/RODBC/vignettes/RODBC.pdf. This describes the relationship among the various parts of the technical stack that allows connectivity to the database system via ODBC. One of the points made is that RODBC uses an ODBC driver (e.g., Actual Technologies, Easysoft and OpenLink).
>
> I use the driver from Actual Technologies on Mac OS, but many others have used freeTDS. I had trouble with freeTDS years ago and decided my time was worth the minor cost of using the commercial product from Actual Technologies.
>
> The driver you use is computer OS specific while RODBC is not.
>
> It is also convenient to use an ODBC manager, which is typically a graphical application used to create and manage the configuration files used by the ODBC driver.
>
> Mark
>
> R. Mark Sharp, Ph.D.
> Director of Primate Records Database
> Southwest National Primate Research Center
> Texas Biomedical Research Institute
> P.O. Box 760549
> San Antonio, TX 78245-0549
> Telephone: (210)258-9476
> e-mail: msharp at TxBiomed.org<mailto:msharp at txbiomed.org>
>
> > On Aug 28, 2016, at 11:53 PM, Manohar Reddy <manu.reddy52 at gmail.com<mailto:manu.reddy52 at gmail.com>> wrote:
> >
> > Hi,
> >
> >
> >
> >   Can anyone guide me how to connect the Microsoft Sql server 2012/14 from
> > R studio using freeTDS package instead of RODBC ,I can able to connect the
> > MS Sql server from R studio using RODBC.
> >
> >  Actually my requirement is I have developed webpage/report using Shiny
> > package then I was deployed it on Shinyapps.io<http://shinyapps.io> ,but after deploying I?m
> > encountering error like ??ERROR: *first argument is not an open RODBC
> > channel*? ,based on this error message I did searched in google and found
> > that we need to use freeTDS drivers instead of RODBC but I found some
> > articles regarding freeTDS but it?s not useful for me.
> >
> >
> >
> > I was eagerly waiting for solution from someone since last month, but not
> > yet and this issue is not allowing me to further .Can anyone please help me
> > out me(how to install freeTDS and how to configure it) on same.
> >
> >
> >
> > My environment details :
> >
> >
> >
> >    Os : windows 8
> >
> >    R version 3.3.1 (2016-06-21)
> >
> >
> >
> > Thanks in Advance .
> >
> > Manu.
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
>
>
> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments transmitted, may contain privileged and confidential information and is intended solely for the exclusive use of the individual or entity to whom it is addressed. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution or copying of this e-mail and/or attachments is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender stating that this transmission was misdirected; return the e-mail to sender; destroy all paper copies and delete all electronic copies from your system without disclosing its contents.
>
>
>
> --
>
>
> Thanks,
> Manohar Reddy P
> +91-9705302062.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments transmitted, may contain privileged and confidential information and is intended solely for the exclusive use of the individual or entity to whom it is addressed. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution or copying of this e-mail and/or attachments is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender stating that this transmission was misdirected; return the e-mail to sender; destroy all paper copies and delete all electronic copies from your system without disclosing its contents.



--


Thanks,
Manohar Reddy P
+91-9705302062.
<FreeTDS_Error_message.PNG>
CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments transmitted, may contain privileged and confidential information and is intended solely for the exclusive use of the individual or entity to whom it is addressed. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution or copying of this e-mail and/or attachments is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender stating that this transmission was misdirected; return the e-mail to sender; destroy all paper copies and delete all electronic copies from your system without disclosing its contents.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Aug 30 16:14:15 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 30 Aug 2016 07:14:15 -0700
Subject: [R] Exponential population model
In-Reply-To: <DB6PR0101MB2550DCCC1613499E58D9C7FD8EE10@DB6PR0101MB2550.eurprd01.prod.exchangelabs.com>
References: <DB6PR0101MB25502D2F7A21B3796668FF318EEC0@DB6PR0101MB2550.eurprd01.prod.exchangelabs.com>
	<07BFE076-4821-406C-BF6B-762B774B062B@comcast.net>
	<DB6PR0101MB2550DCCC1613499E58D9C7FD8EE10@DB6PR0101MB2550.eurprd01.prod.exchangelabs.com>
Message-ID: <67AA6B37-373C-42E4-BC40-94626CE85E4B@comcast.net>


> On Aug 29, 2016, at 7:06 AM, Msindai, Nadejda <n.msindai.09 at ucl.ac.uk> wrote:
> 
> Dear David
> 
> I think you misunderstood me, I need to find the name for an r package that models the population size from time 0 for a group of animals.  
> 
> I provided details to make it clearer the type of model I want to run. 
> 
> The only population model I have come across thus far is Popbio, which appears to be for plants? Therefore, can you assist me by telling me the name for a package that is used to model exponential growth: 
> 
> Exponential growth model is --
> ?The exponential growth model assumes that the population starts out at time t=0 at some initial N(0), and growth at constant exponential rate r. If r>0 this results in theoretically unlimited growth over time.  The fundamental equation of growth is
> ? 
> ?N(t+1)= N(t) exp?

(Thew HTML formating has turned ? into  trademark sign. (You are advised to post in plain-text._

If you had any data that model should be able to be fit with `glm` using a Poisson model. (No extra package if it were as simple as that, which it does not appear to be in the case.)

> 
> I do not have a known growth rate figure for my species, therefore, I plan to use life history data obtained from wild populations (of one particular species) to model the current population size for a group of animals introduced onto an island. 

So you have a population structure and an assumed death rate within age bands but you have no assumptions about birth rate. Seems that would not support any sort of growth model, yet. (This seems to be a typical demography exercise.)

https://www.google.com/search?q=r+growth+rate

And since you will be passing a hypothetical population through sections of different "mortality age x time cells" you will probably also want to run a search on "Lexis diagrams":

https://www.google.com/search?q=Lexis+diagrams+r+package

-- 
David.


> 
> Thank you for your help in this matter
> 
> Josephine 
> From: David Winsemius <dwinsemius at comcast.net>
> Sent: 27 August 2016 03:32:55
> To: Msindai, Nadejda
> Cc: r-help at r-project.org
> Subject: Re: [R] Exponential population model
>  
> 
> > On Aug 26, 2016, at 5:49 AM, Msindai, Nadejda <n.msindai.09 at ucl.ac.uk> wrote:
> > 
> > Dear admin
> > 
> > I am writing to ask for help with writing an R script to model the current population size using life history data (I do not know the intrinsic rate of increase (r)).
> > 
> > My study population are a group of introduced chimpanzees, that were released by the Frankfurt Zoological Society in 1966-1969 onto an island in Lake Victoria.
> > 
> > Thus I want to run a density independent population model using life history data, with 0 net migration/immigration (so this is a closed system).
> > 
> > 
> > These are the individuals entering the system (in my case arriving on the island), after 1969 no new animals arrive.
> > 
> > Year    1966    1966    1966    1966    1966    1966    1966    1968    1969    1966    1966    1966    1966    1968    1969
> > Animal ID       F1      F2      F3      F4      F5      F6      F7      F8      F9      M1      M2      M3      M4      M5      M6
> > DOB     1955    1955    1956    1957    1958    1959    1955    1960    1960    1958    1959    1959    1962    1960    1960
> > 
> > Notes:  Year is the year animal was released into the population
> >        F=female
> >        M=male
> >        DOB=date of birth
> > 
> > 
> > Using the following life history data I want to estimate the population size for the year 1979, 1989, 1999, and 2014, as well as future projection for 2019, 2029 etc.
> > 
> > Age at first birth for females: 11 years
> > Birth interval: 55.2 months
> > Age at last birth: 50 years (in 40-50 years only 47% of females have offspring)
> > Survival to 8 years = 67.7%(Female) 51.4%(Male)
> > Survival to 15 years 41%(Female) 27%(Male)
> > Survival 15-40 years 18%(Female) 11%(Male)
> > Survival 40+ years 7%(M/F)
> > 
> > 
> > 
> > Birth ratio set as ___M = Male, F = Female (set as 50:50)
> > 
> 
> This looks like a homework question and Rhelp is specifically announced as not doing homework. See the Posting Guide.
> 
> -- 
> David.
> > 
> > 
> > 
> > I hope you can be of help
> > 
> > Kind regards
> > 
> > Josephine
> > 
> > 
> > 
> > 
> >        [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA

David Winsemius
Alameda, CA, USA


From zorazeali at gmail.com  Tue Aug 30 11:31:09 2016
From: zorazeali at gmail.com (Zoraze Ali)
Date: Tue, 30 Aug 2016 11:31:09 +0200
Subject: [R] Second order stochastic dominance test
Message-ID: <CAHVh=5+J0pQY1aJKeB6Sj2UYHw1kf1iHHs-tYnx9c-g2TzbKzQ@mail.gmail.com>

Hi all,

Is there any R package which could help me to test the second order
stochastic dominance of two curves?

Thanks in advance for the help.

Kind regards,
Zoraze

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Tue Aug 30 17:07:17 2016
From: hannah.hlx at gmail.com (li li)
Date: Tue, 30 Aug 2016 11:07:17 -0400
Subject: [R] plot.drm in "drc" package
Message-ID: <CAHLnndYX_6JS4k3kBC-M+dqN_qkDH1-k3wJUmggqVR3Huf3+YQ@mail.gmail.com>

Hi all,
  I am trying to use the drc package to fit 4L curve.
I am so confused about the plot.drm function in the drc package.
Particularly, I am confused about the scale of the xaxis in the plots
generated using the plot.drm function. See the example below:

## generate data and fit the model
dose <- rep(50*2^(-(0:11)),3)
dose
d <- 100
c <- 1
b <- 1
e <- 1.6
y <- rnorm(length(dose))+ c+ (d-c)/(1+exp(b*(log(dose)-log(e))))
library(drc)
mod <- drm(y~dose, fct = LL.4())
summary(mod)

Now I plot the data and the fitted curve with the plot.drm using the code
below and get the figure 1 below.


##obtaining figure 1
plot(mod, type="all",log="x")


Next I plot the raw data and add the curve by extracting the estimate of
the parameters.

##extract parameters
para <- mod$fit$par
bhat<- para[1]
chat <- para[2]
dhat <- para[3]
ehat <- para[4]

##plot figure 2
plot(log(dose),y)
points(log(50*2^(-(0:11))),  chat +
(dhat-chat)/(1+exp(bhat*(log(50*2^(-(0:11)))-log(ehat)))), type="l")

My question is regarding the figure 1 generated by the plot.drm.
The x axis is the not the log scale of the doses. I checked the package
manual, it says the default is log base 10. But it is not true in this case.
Does some have some insight on the correct usage of the plot.drm function.

Thanks much in advance.
  Hanna

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Tue Aug 30 17:49:14 2016
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 30 Aug 2016 07:49:14 -0800
Subject: [R] Second order stochastic dominance test
In-Reply-To: <CAHVh=5+J0pQY1aJKeB6Sj2UYHw1kf1iHHs-tYnx9c-g2TzbKzQ@mail.gmail.com>
Message-ID: <0AA23366ED8.00000279jrkrideau@inbox.com>


google R package test the second order stochastic dominance of two curves
John Kane
Kingston ON Canada

> -----Original Message-----
> From: zorazeali at gmail.com
> Sent: Tue, 30 Aug 2016 11:31:09 +0200
> To: r-help at r-project.org
> Subject: [R] Second order stochastic dominance test
> 
> Hi all,
> 
> Is there any R package which could help me to test the second order
> stochastic dominance of two curves?
> 
> Thanks in advance for the help.
> 
> Kind regards,
> Zoraze
> 
> [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From jfca283 at gmail.com  Tue Aug 30 17:43:29 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Tue, 30 Aug 2016 12:43:29 -0300
Subject: [R] Loop over rda list files and using the attach function
Message-ID: <CALBYkjJLY0Rqve9+CeSfXYkRrUVvAcCt4URBvtLcOMZefKU62Q@mail.gmail.com>

Hi.
I need to loop over rda files.
I generated the list of them.
That's ok. The problem is that the name of the files are as yyyy_mm (eg
2010_01 is january or 2010, 2016_03 is march of 2016).
So, when i try to use the attach function to create a simple table(age,
sex) it fails.
The only way to attach a file as is using
attach(`2016_03`)
The text above i have no idea how to declare it in my code below


dd=list.files("C:/Users/Me/r", pattern="rda$", full.names=F)
for (i in 1:length(dd)) {
yyz=load(dd[i])
attach(yyz)
table(age, sex)
rm(list=yyz)

}
This is the error it declares the loop:
Error in attach(yyz) : file '2013_02' not found


Thanks for your help and time

	[[alternative HTML version deleted]]


From leslie.rutkowski at gmail.com  Tue Aug 30 16:37:24 2016
From: leslie.rutkowski at gmail.com (Leslie Rutkowski)
Date: Tue, 30 Aug 2016 16:37:24 +0200
Subject: [R] loading .rda file
Message-ID: <CAA0F9kUoeMp5eJs5vaGBb5vgXBHjLLgFU2+b-FyO2knsQSztig@mail.gmail.com>

Hi,

I'm slowly migrating from SAS to R and - for the very first time - I'm
working with a native .Rda data file (rather than importing data from other
sources). When I load this .Rda file into the global environment using
load("file path") I see a data.frame in the global environment called
"mydata" that corresponds to the .rda file.

My question: how can I change the name of this data.frame to something of
my choosing?

Thanks for considering this very simple question.

Leslie

	[[alternative HTML version deleted]]


From rbaer at atsu.edu  Tue Aug 30 18:14:17 2016
From: rbaer at atsu.edu (Robert Baer)
Date: Tue, 30 Aug 2016 11:14:17 -0500
Subject: [R] loading .rda file
In-Reply-To: <CAA0F9kUoeMp5eJs5vaGBb5vgXBHjLLgFU2+b-FyO2knsQSztig@mail.gmail.com>
References: <CAA0F9kUoeMp5eJs5vaGBb5vgXBHjLLgFU2+b-FyO2knsQSztig@mail.gmail.com>
Message-ID: <d357be27-1cdf-2134-accc-5e4a6321aa13@atsu.edu>

I think that the .rda extension is the old extension convention for what 
now gets the .RData extension name by convention.

These are basically workspaces. These .RData files can contain multiple 
data objects, and all objects seem to read back in with the same name 
that they were saved with using the save() function.  Of course, you can 
assign a new name to the objects you read in with the standard <- or -> 
syntax.

See ?save, to lean how to save them with the new name.  You can save 
just an individual data object in an .rda or .RData file and make the 
data object name match the filename if you so wish.


On 8/30/2016 9:37 AM, Leslie Rutkowski wrote:
> Hi,
>
> I'm slowly migrating from SAS to R and - for the very first time - I'm
> working with a native .Rda data file (rather than importing data from other
> sources). When I load this .Rda file into the global environment using
> load("file path") I see a data.frame in the global environment called
> "mydata" that corresponds to the .rda file.
>
> My question: how can I change the name of this data.frame to something of
> my choosing?
>
> Thanks for considering this very simple question.
>
> Leslie
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 


--
Robert W. Baer, Ph.D.
Professor of Physiology
Kirksville College of Osteopathic Medicine
A T Still University of Health Sciences
800 W. Jefferson St
Kirksville, MO 63501
660-626-2321 Department
660-626-2965 FAX


From shivipmp82 at gmail.com  Tue Aug 30 18:24:32 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Tue, 30 Aug 2016 21:54:32 +0530
Subject: [R] 0 rows> (or 0-length row.names)
Message-ID: <CAB=p7SpPBEL5Yt3uL6Xq2BT8SJjjzY=9ZwPF9F_JSyZRqJ6fUw@mail.gmail.com>

I know this question has been asked zillion times but even after consulting
Stack Overflow & other forum cant figure out the reason.

I have one var in my data-set names case age. This variable is numeric as:

class(SFDC$case_age)

*numeric*

however it throws this error:

<0 rows> (or 0-length row.names)
As checked this only happens either there is some space at the end of the
variable name, or there are no values whereas this is a numeric variable
with no missing values and has a total of 5400 observations.

This var has a range from 0 to 240 in number of days for case variable
hence i need to do a logarithm transformation & make it use in the model.
Total unique obs are around 1500.

Please advice.

	[[alternative HTML version deleted]]


From msharp at txbiomed.org  Tue Aug 30 18:35:29 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Tue, 30 Aug 2016 16:35:29 +0000
Subject: [R] 0 rows> (or 0-length row.names)
In-Reply-To: <CAB=p7SpPBEL5Yt3uL6Xq2BT8SJjjzY=9ZwPF9F_JSyZRqJ6fUw@mail.gmail.com>
References: <CAB=p7SpPBEL5Yt3uL6Xq2BT8SJjjzY=9ZwPF9F_JSyZRqJ6fUw@mail.gmail.com>
Message-ID: <B06A6B79-F60E-475B-8EF9-19B1CEC2365E@TxBiomed.org>

What do you get from
str(SFDC$case_age)

Mark

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org







> On Aug 30, 2016, at 11:24 AM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
>
> I know this question has been asked zillion times but even after consulting
> Stack Overflow & other forum cant figure out the reason.
>
> I have one var in my data-set names case age. This variable is numeric as:
>
> class(SFDC$case_age)
>
> *numeric*
>
> however it throws this error:
>
> <0 rows> (or 0-length row.names)
> As checked this only happens either there is some space at the end of the
> variable name, or there are no values whereas this is a numeric variable
> with no missing values and has a total of 5400 observations.
>
> This var has a range from 0 to 240 in number of days for case variable
> hence i need to do a logarithm transformation & make it use in the model.
> Total unique obs are around 1500.
>
> Please advice.
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From jdnewmil at dcn.davis.ca.us  Tue Aug 30 18:36:05 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 30 Aug 2016 09:36:05 -0700
Subject: [R] loading .rda file
In-Reply-To: <CAA0F9kUoeMp5eJs5vaGBb5vgXBHjLLgFU2+b-FyO2knsQSztig@mail.gmail.com>
References: <CAA0F9kUoeMp5eJs5vaGBb5vgXBHjLLgFU2+b-FyO2knsQSztig@mail.gmail.com>
Message-ID: <FF960259-852B-4764-B5EA-1DA4BDDA5836@dcn.davis.ca.us>

You cannot. However, you can load the file into a dedicated environment to keep those names separated from your global environment. e.g. [1]

The saveRDS/loadRDS functions are an alternative handle one object at a time without dragging the object names into the picture (you have to name the re-loaded object).

However, the best approach is to write scripts that pull directly from your source (non-R) data files. This makes your work process reproducible as you develop it.

[1] https://stat.ethz.ch/pipermail/r-help/2016-August/441078.html
-- 
Sent from my phone. Please excuse my brevity.

On August 30, 2016 7:37:24 AM PDT, Leslie Rutkowski <leslie.rutkowski at gmail.com> wrote:
>Hi,
>
>I'm slowly migrating from SAS to R and - for the very first time - I'm
>working with a native .Rda data file (rather than importing data from
>other
>sources). When I load this .Rda file into the global environment using
>load("file path") I see a data.frame in the global environment called
>"mydata" that corresponds to the .rda file.
>
>My question: how can I change the name of this data.frame to something
>of
>my choosing?
>
>Thanks for considering this very simple question.
>
>Leslie
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From shivipmp82 at gmail.com  Tue Aug 30 18:38:04 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Tue, 30 Aug 2016 22:08:04 +0530
Subject: [R] 0 rows> (or 0-length row.names)
In-Reply-To: <B06A6B79-F60E-475B-8EF9-19B1CEC2365E@TxBiomed.org>
References: <CAB=p7SpPBEL5Yt3uL6Xq2BT8SJjjzY=9ZwPF9F_JSyZRqJ6fUw@mail.gmail.com>
	<B06A6B79-F60E-475B-8EF9-19B1CEC2365E@TxBiomed.org>
Message-ID: <CAB=p7SrPj7siTJVUaxkMDVA-n4=1iZqagiZUTrnOp-z3uoeE5A@mail.gmail.com>

Hi Mark,

It gives me num [1:5083]. I have used head also to see first 10 obs:

head(SFDC$case_age,10)
 [1] 24.84  0.05 13.38  0.15 11.11  4.16  8.13  0.07  3.61  0.00

Thanks.

On Tue, Aug 30, 2016 at 10:05 PM, Mark Sharp <msharp at txbiomed.org> wrote:

> What do you get from
> str(SFDC$case_age)
>
> Mark
>
> R. Mark Sharp, Ph.D.
> Director of Primate Records Database
> Southwest National Primate Research Center
> Texas Biomedical Research Institute
> P.O. Box 760549
> San Antonio, TX 78245-0549
> Telephone: (210)258-9476
> e-mail: msharp at TxBiomed.org
>
>
>
>
>
>
>
> > On Aug 30, 2016, at 11:24 AM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
> >
> > I know this question has been asked zillion times but even after
> consulting
> > Stack Overflow & other forum cant figure out the reason.
> >
> > I have one var in my data-set names case age. This variable is numeric
> as:
> >
> > class(SFDC$case_age)
> >
> > *numeric*
> >
> > however it throws this error:
> >
> > <0 rows> (or 0-length row.names)
> > As checked this only happens either there is some space at the end of the
> > variable name, or there are no values whereas this is a numeric variable
> > with no missing values and has a total of 5400 observations.
> >
> > This var has a range from 0 to 240 in number of days for case variable
> > hence i need to do a logarithm transformation & make it use in the model.
> > Total unique obs are around 1500.
> >
> > Please advice.
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
> transmitted, may contain privileged and confidential information and is
> intended solely for the exclusive use of the individual or entity to whom
> it is addressed. If you are not the intended recipient, you are hereby
> notified that any review, dissemination, distribution or copying of this
> e-mail and/or attachments is strictly prohibited. If you have received this
> e-mail in error, please immediately notify the sender stating that this
> transmission was misdirected; return the e-mail to sender; destroy all
> paper copies and delete all electronic copies from your system without
> disclosing its contents.
>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Tue Aug 30 18:50:07 2016
From: hannah.hlx at gmail.com (li li)
Date: Tue, 30 Aug 2016 12:50:07 -0400
Subject: [R] plot with different symbols and colors according to the factor
	levels
Message-ID: <CAHLnndbT6YQseS7oyQNtqJOQVw_sq+v9UTMJfkF354iSi=1u7g@mail.gmail.com>

Hi all,
 I have the following data. I want to plot the data (y ~ conc)
with different symbols and colors corresponding to different levels of the
factor sample.
I could create a column with color and pch and then do the plot, but I am
sure there are much better ways.
Can anyone make suggestions?
  Hanna



   y         conc sample
1  33 20.000000000      1
2  33  5.000000000      1
3  35  1.250000000      1
4  43  0.312500000      1
5  58  0.078125000      1
6  54  0.019531250      1
7  57  0.004882812      1
8  57  0.001220703      1
9  32 20.000000000      1
10 32  5.000000000      1
11 34  1.250000000      1
12 52  0.312500000      1
13 57  0.078125000      1
14 58  0.019531250      1
15 59  0.004882812      1
16 50  0.001220703      1
17 34 20.000000000      2
18 34  5.000000000      2
19 38  1.250000000      2
20 53  0.312500000      2
21 57  0.078125000      2
22 57  0.019531250      2
23 57  0.004882812      2
24 52  0.001220703      2
25 34 20.000000000      2
26 33  5.000000000      2
27 36  1.250000000      2
28 48  0.312500000      2
29 58  0.078125000      2
30 57  0.019531250      2
31 58  0.004882812      2
32 53  0.001220703      2
33 34 20.000000000      2
34 35  5.000000000      2
35 37  1.250000000      2
36 49  0.312500000      2
37 55  0.078125000      2
38 59  0.019531250      2
39 57  0.004882812      2
40 54  0.001220703      2
41 36 20.000000000      3
42 33  5.000000000      3
43 36  1.250000000      3
44 51  0.312500000      3
45 57  0.078125000      3
46 57  0.019531250      3
47 59  0.004882812      3
48 56  0.001220703      3
49 33 20.000000000      3
50 32  5.000000000      3
51 35  1.250000000      3
52 47  0.312500000      3
53 57  0.078125000      3
54 56  0.019531250      3
55 57  0.004882812      3
56 53  0.001220703      3
57 33 20.000000000      3
58 34  5.000000000      3
59 38  1.250000000      3
60 52  0.312500000      3
61 56  0.078125000      3
62 61  0.019531250      3
63 56  0.004882812      3
64 55  0.001220703      3

	[[alternative HTML version deleted]]


From david.bucklin at gmail.com  Mon Aug 29 20:46:42 2016
From: david.bucklin at gmail.com (David Bucklin)
Date: Mon, 29 Aug 2016 14:46:42 -0400
Subject: [R] [R-pkgs] new package: rpostgis
Message-ID: <CAECT9fmyNJaGtrzF7j2qKXQ=h20yS7-gAWrj7apWR7YDYBo5Sg@mail.gmail.com>

We'd like to announce the initial CRAN release of 'rpostgis' (v1.0.0),
which facilitates transfer between PostGIS "Geometry" objects (stored in
PostgreSQL databases) and R spatial objects. The package also contains a
variety of convenience functions which are supplemental to the excellent
'RPostgreSQL' package for interfacing with a PostgreSQL/PostGIS database.

To install the package:

install.packages("rpostgis")

The package main development area can be found on GitHub; any bugs, issues,
or feature requests can be submitted through the "issues" page there:

https://github.com/mablab/rpostgis
David

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From khaynes17 at gmail.com  Tue Aug 30 18:26:56 2016
From: khaynes17 at gmail.com (Kevin Haynes)
Date: Tue, 30 Aug 2016 12:26:56 -0400
Subject: [R] Adding multiple polygons to a Leaflet map
Message-ID: <CAOoXFWOhoeFSh_pSJEJbjVbqYKkzh2+YkCeFsjEEc_49cSU4AA@mail.gmail.com>

Hi everyone - I'd like to add multiple polygons to a leaflet map. I don't
get any errors when running this code, but it'll only display the second
choro layer - the citizenship rate one. Here's my code below. Any thoughts?
Here's the map right now:http://rpubs.com/khaynes17/205217
  #map

  la_trad_school_perf_map_layers <- leaflet(lac_schools) %>%
    addProviderTiles("CartoDB.Positron") %>%
    setView(-118.4, 34.05, zoom = 9) %>%
    addCircleMarkers(
      radius = 3,
      color = ~pal(metandabove_mth),
      stroke= FALSE, fillOpacity = 0.5,
      group="14-15 Proficiency Rates - Math"
    ) %>%
    addPolygons(data = income_merged,
      fillColor = ~pal_income(MedianIncome_2014),
      color = "#b2aeae",
      fillOpacity = 0.5,
      weight = 1,
      smoothFactor = 0.2,
      popup = popup_income,
      group="Median Income - 2014")%>%
    addPolygons(data = cit_merged,
      fillColor = ~pal_cit(non_citizenship_rate),
      color = "#b2aeae",
      fillOpacity = 0.5,
      weight = 1,
      smoothFactor = 0.2,
      popup = popup_cit,
      group="Non-U.S. Citizen - 2014")%>%
   addLayersControl(
     baseGroups=c("Median Income - 2014", "Non-U.S. Citizen - 2014"),
     overlayGroups=c("14-15 Proficiency Rates - Math"),
     options = layersControlOptions(collapsed = FALSE)
   )
  la_trad_school_perf_map_layers

	[[alternative HTML version deleted]]


From neerajdhanraj at gmail.com  Sun Aug 28 05:55:31 2016
From: neerajdhanraj at gmail.com (Neeraj Dhanraj)
Date: Sun, 28 Aug 2016 09:25:31 +0530
Subject: [R] [R-pkgs] The modification in PSF Package
Message-ID: <CAC58_YnX4TD3yCb5QoQ3TzB40itkF1sSOyLqXubkSOaOoh_qRA@mail.gmail.com>

Dear Researchers,

Have a look over updated *R package PSF*. Pattern Sequence Based
Forecasting (PSF) takes univariate time series data as input and assist to
forecast its future values. This algorithm forecasts the behavior of time
series based on similarity of pattern sequences. Initially, clustering is
done with the labeling of samples from database. The labels associated with
samples are then used for forecasting the future behaviour of time series
data. The further technical details and references regarding PSF are
discussed in Vignette.

*CRAN:* *https://cran.r-project.org/web/packages/PSF/index.html
<https://cran.r-project.org/web/packages/PSF/index.html>*

*GitHub:* https://github.com/neerajdhanraj/PSF

*How to use:* https://www.researchgate.net/publication/304131481_PSF_
Introduction_to_R_Package_for_Pattern_Sequence_Based_Forecasting_Algorithm

Also go through the modification in terms of seasonal dataset.

https://www.researchgate.net/publication/304580701_
Introduction_of_seasonality_concept_in_PSF_algorithm_to_
improve_univariate_time_series_predictions

For further details *contact me* at: http://www.neerajbokde.com/

-- 
Regards ,
Neeraj Dhanraj Bokde
M.E. Embedded System

Birla Institute of Technology & Science, Pilani

Pilani Campus , Rajasthan, India

Phone: *+91 9028415974 <%2B91%209028415974>*

Email: h2012105 at pilani.bits-pilani.ac.in; *neerajdhanraj at gmail.com
<neerajdhanraj at gmail.com>*

Website: http://www.neerajbokde.com

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From msharp at txbiomed.org  Tue Aug 30 18:55:59 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Tue, 30 Aug 2016 16:55:59 +0000
Subject: [R] 0 rows> (or 0-length row.names)
In-Reply-To: <CAB=p7SrPj7siTJVUaxkMDVA-n4=1iZqagiZUTrnOp-z3uoeE5A@mail.gmail.com>
References: <CAB=p7SpPBEL5Yt3uL6Xq2BT8SJjjzY=9ZwPF9F_JSyZRqJ6fUw@mail.gmail.com>
	<B06A6B79-F60E-475B-8EF9-19B1CEC2365E@TxBiomed.org>
	<CAB=p7SrPj7siTJVUaxkMDVA-n4=1iZqagiZUTrnOp-z3uoeE5A@mail.gmail.com>
Message-ID: <3DCADB9D-B1A3-447E-9BD4-466828CC3A71@TxBiomed.org>

Shivi,

Can you show the code that throws the error?
<0 rows> (or 0-length row.names)

Of course as always a reproducible sample would be great. Perhaps you can make a small subset of the data and use dput() to provide a defined object.

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org

> On Aug 30, 2016, at 11:38 AM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
>
> Hi Mark,
>
> It gives me num [1:5083]. I have used head also to see first 10 obs:
>
> head(SFDC$case_age,10)
>  [1] 24.84  0.05 13.38  0.15 11.11  4.16  8.13  0.07  3.61  0.00
>
> Thanks.
>
> On Tue, Aug 30, 2016 at 10:05 PM, Mark Sharp <msharp at txbiomed.org> wrote:
> What do you get from
> str(SFDC$case_age)
>
> Mark
>
> R. Mark Sharp, Ph.D.
> Director of Primate Records Database
> Southwest National Primate Research Center
> Texas Biomedical Research Institute
> P.O. Box 760549
> San Antonio, TX 78245-0549
> Telephone: (210)258-9476
> e-mail: msharp at TxBiomed.org
>
>
>
>
>
>
>
> > On Aug 30, 2016, at 11:24 AM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
> >
> > I know this question has been asked zillion times but even after consulting
> > Stack Overflow & other forum cant figure out the reason.
> >
> > I have one var in my data-set names case age. This variable is numeric as:
> >
> > class(SFDC$case_age)
> >
> > *numeric*
> >
> > however it throws this error:
> >
> > <0 rows> (or 0-length row.names)
> > As checked this only happens either there is some space at the end of the
> > variable name, or there are no values whereas this is a numeric variable
> > with no missing values and has a total of 5400 observations.
> >
> > This var has a range from 0 to 240 in number of days for case variable
> > hence i need to do a logarithm transformation & make it use in the model.
> > Total unique obs are around 1500.
> >
> > Please advice.
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments transmitted, may contain privileged and confidential information and is intended solely for the exclusive use of the individual or entity to whom it is addressed. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution or copying of this e-mail and/or attachments is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender stating that this transmission was misdirected; return the e-mail to sender; destroy all paper copies and delete all electronic copies from your system without disclosing its contents.
>




CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From wdunlap at tibco.com  Tue Aug 30 19:00:42 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 30 Aug 2016 10:00:42 -0700
Subject: [R] 0 rows> (or 0-length row.names)
In-Reply-To: <CAB=p7SpPBEL5Yt3uL6Xq2BT8SJjjzY=9ZwPF9F_JSyZRqJ6fUw@mail.gmail.com>
References: <CAB=p7SpPBEL5Yt3uL6Xq2BT8SJjjzY=9ZwPF9F_JSyZRqJ6fUw@mail.gmail.com>
Message-ID: <CAF8bMcZCAtFmDbdiNwfTjobLVugdQ89a97Enymt+cry-A+mTzQ@mail.gmail.com>

You did not say what operation gave you the error.

I can get that message (which is not an "error") if I print
an illegally constructed data.frame, one without the
row.names attribute.

> illegalDF <- structure(class="data.frame", list(ColumnA = 1:3))
> illegalDF
[1] ColumnA
<0 rows> (or 0-length row.names)
> str(illegalDF)
'data.frame':   0 obs. of  1 variable:
 $ ColumnA: int  1 2 3

Note how str() of the entire data.frame indirectly informs you of the
problem: the number of observations does not match the length of the
columns.

How did you make the data.frame?



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Aug 30, 2016 at 9:24 AM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:

> I know this question has been asked zillion times but even after consulting
> Stack Overflow & other forum cant figure out the reason.
>
> I have one var in my data-set names case age. This variable is numeric as:
>
> class(SFDC$case_age)
>
> *numeric*
>
> however it throws this error:
>
> <0 rows> (or 0-length row.names)
> As checked this only happens either there is some space at the end of the
> variable name, or there are no values whereas this is a numeric variable
> with no missing values and has a total of 5400 observations.
>
> This var has a range from 0 to 240 in number of days for case variable
> hence i need to do a logarithm transformation & make it use in the model.
> Total unique obs are around 1500.
>
> Please advice.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Tue Aug 30 19:12:32 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 30 Aug 2016 19:12:32 +0200
Subject: [R] loading .rda file
In-Reply-To: <FF960259-852B-4764-B5EA-1DA4BDDA5836@dcn.davis.ca.us>
References: <CAA0F9kUoeMp5eJs5vaGBb5vgXBHjLLgFU2+b-FyO2knsQSztig@mail.gmail.com>
	<FF960259-852B-4764-B5EA-1DA4BDDA5836@dcn.davis.ca.us>
Message-ID: <22469.48768.472833.853458@stat.math.ethz.ch>

>>>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>>>>     on Tue, 30 Aug 2016 09:36:05 -0700 writes:

    > You cannot. However, you can load the file into a dedicated environment to keep those names separated from your global environment. e.g. [1]

yes, that's my "famous"  only-allowed use of  attach() :
attach() an rda-file to your search patch instead of polluting
your globalenv.

  > The saveRDS / loadRDS 

        saveRDS / readRDS   are the correct names

    > functions are an alternative handle one object at a time without dragging the object names into the picture (you have to name the re-loaded object).

The fact that it is readRDS() and not loadRDS(),
actually does convey via it is often "much better" in the sense
of functional / transparent programming to use this pair in
favor of save() / load() :
readRDS() does *return* what we are interested in, and

   result <- readRDS(<file>)

is so much better than   load(<file>)   silently overwriting all
kinds of objects in my globalenv.

Indeed, I strongly advocate to use  saveRDS() and readRDS()
much more frequently than they are used nowawadays.



    > However, the best approach is to write scripts that pull directly from your source (non-R) data files. This makes your work process reproducible as you develop it.

Yes, but that's sometimes too inefficient.

And then, some of us do simulations and other expensive
computations, we need/want to save and re-read.

and yes,  I *always*  use the equivalent of   q("no")  to leave R; 
never save the workspace or load it at startup, unless
accidentally on non-standard (for me) platforms.

Martin

    > [1] https://stat.ethz.ch/pipermail/r-help/2016-August/441078.html
    > -- 
    > Sent from my phone. Please excuse my brevity.

    > On August 30, 2016 7:37:24 AM PDT, Leslie Rutkowski <leslie.rutkowski at gmail.com> wrote:
    >> Hi,
    >> 
    >> I'm slowly migrating from SAS to R and - for the very first time - I'm
    >> working with a native .Rda data file (rather than importing data from
    >> other
    >> sources). When I load this .Rda file into the global environment using
    >> load("file path") I see a data.frame in the global environment called
    >> "mydata" that corresponds to the .rda file.
    >> 
    >> My question: how can I change the name of this data.frame to something
    >> of
    >> my choosing?
    >> 
    >> Thanks for considering this very simple question.
    >> 
    >> Leslie
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From clint at ecy.wa.gov  Tue Aug 30 19:35:03 2016
From: clint at ecy.wa.gov (Clint Bowman)
Date: Tue, 30 Aug 2016 10:35:03 -0700 (PDT)
Subject: [R] plot with different symbols and colors according to the
 factor levels
In-Reply-To: <CAHLnndbT6YQseS7oyQNtqJOQVw_sq+v9UTMJfkF354iSi=1u7g@mail.gmail.com>
References: <CAHLnndbT6YQseS7oyQNtqJOQVw_sq+v9UTMJfkF354iSi=1u7g@mail.gmail.com>
Message-ID: <alpine.LRH.2.20.1608301032350.18539@aeolus.ecy.wa.gov>

Hanna,

lili<-read.table("lili.txt",header=T)  # don't forget to label the row 
number if it's in your data

with(lili,plot(y,conc,pch=sample,col=sample))

Clint


Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Tue, 30 Aug 2016, li li wrote:

> Hi all,
> I have the following data. I want to plot the data (y ~ conc)
> with different symbols and colors corresponding to different levels of the
> factor sample.
> I could create a column with color and pch and then do the plot, but I am
> sure there are much better ways.
> Can anyone make suggestions?
>  Hanna
>
>
>
>   y         conc sample
> 1  33 20.000000000      1
> 2  33  5.000000000      1
> 3  35  1.250000000      1
> 4  43  0.312500000      1
> 5  58  0.078125000      1
> 6  54  0.019531250      1
> 7  57  0.004882812      1
> 8  57  0.001220703      1
> 9  32 20.000000000      1
> 10 32  5.000000000      1
> 11 34  1.250000000      1
> 12 52  0.312500000      1
> 13 57  0.078125000      1
> 14 58  0.019531250      1
> 15 59  0.004882812      1
> 16 50  0.001220703      1
> 17 34 20.000000000      2
> 18 34  5.000000000      2
> 19 38  1.250000000      2
> 20 53  0.312500000      2
> 21 57  0.078125000      2
> 22 57  0.019531250      2
> 23 57  0.004882812      2
> 24 52  0.001220703      2
> 25 34 20.000000000      2
> 26 33  5.000000000      2
> 27 36  1.250000000      2
> 28 48  0.312500000      2
> 29 58  0.078125000      2
> 30 57  0.019531250      2
> 31 58  0.004882812      2
> 32 53  0.001220703      2
> 33 34 20.000000000      2
> 34 35  5.000000000      2
> 35 37  1.250000000      2
> 36 49  0.312500000      2
> 37 55  0.078125000      2
> 38 59  0.019531250      2
> 39 57  0.004882812      2
> 40 54  0.001220703      2
> 41 36 20.000000000      3
> 42 33  5.000000000      3
> 43 36  1.250000000      3
> 44 51  0.312500000      3
> 45 57  0.078125000      3
> 46 57  0.019531250      3
> 47 59  0.004882812      3
> 48 56  0.001220703      3
> 49 33 20.000000000      3
> 50 32  5.000000000      3
> 51 35  1.250000000      3
> 52 47  0.312500000      3
> 53 57  0.078125000      3
> 54 56  0.019531250      3
> 55 57  0.004882812      3
> 56 53  0.001220703      3
> 57 33 20.000000000      3
> 58 34  5.000000000      3
> 59 38  1.250000000      3
> 60 52  0.312500000      3
> 61 56  0.078125000      3
> 62 61  0.019531250      3
> 63 56  0.004882812      3
> 64 55  0.001220703      3
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From shivipmp82 at gmail.com  Tue Aug 30 19:32:51 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Tue, 30 Aug 2016 23:02:51 +0530
Subject: [R] 0 rows> (or 0-length row.names)
In-Reply-To: <CAF8bMcZCAtFmDbdiNwfTjobLVugdQ89a97Enymt+cry-A+mTzQ@mail.gmail.com>
References: <CAB=p7SpPBEL5Yt3uL6Xq2BT8SJjjzY=9ZwPF9F_JSyZRqJ6fUw@mail.gmail.com>
	<CAF8bMcZCAtFmDbdiNwfTjobLVugdQ89a97Enymt+cry-A+mTzQ@mail.gmail.com>
Message-ID: <CAB=p7Sqt8x3chPB1nEH4yyZmGVQ30j3W-y4RQ9XgH2TWuRO2Lw@mail.gmail.com>

Hi William/ Mark,

I am using WOE & IV (weight of evidence) reduce the number of independent
vars.
I have read this data as a csv file.
reproducible example for your reference please:

structure(list(date = structure(c(6L, 6L, 6L, 6L, 6L, 6L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 22L,
22L, 22L, 22L, 22L, 22L, 22L, 22L, 22L, 22L, 22L, 22L, 22L, 22L,
30L, 30L, 30L, 30L), .Label = c("01-02-2016", "01-03-2016", "01-04-2016",
"01-05-2016", "01-06-2016", "01-11-2015", "01-12-2015", "02-01-2016",
"02-02-2016", "02-03-2016", "02-04-2016", "02-05-2016", "02-06-2016",
"02-11-2015", "02-12-2015", "03-01-2016", "03-02-2016", "03-03-2016",
"03-04-2016", "03-05-2016", "03-06-2016", "03-11-2015", "03-12-2015",
"04-01-2016", "04-02-2016", "04-03-2016", "04-04-2016", "04-05-2016",
"04-06-2016", "04-11-2015", "04-12-2015", "05-01-2016", "05-02-2016",
"05-03-2016", "05-04-2016", "05-05-2016", "05-06-2016", "05-11-2015",
"05-12-2015", "06-01-2016", "06-02-2016", "06-03-2016", "06-04-2016",
"06-05-2016", "06-06-2016", "06-11-2015", "06-12-2015", "07-01-2016",
"07-02-2016", "07-03-2016", "07-04-2016", "07-05-2016", "07-06-2016",
"07-11-2015", "07-12-2015", "08-01-2016", "08-02-2016", "08-03-2016",
"08-04-2016", "08-05-2016", "08-06-2016", "08-11-2015", "08-12-2015",
"09-01-2016", "09-02-2016", "09-03-2016", "09-04-2016", "09-05-2016",
"09-06-2016", "09-11-2015", "09-12-2015", "10-01-2016", "10-02-2016",
"10-03-2016", "10-04-2016", "10-05-2016", "10-06-2016", "10-11-2015",
"10-12-2015", "11-01-2016", "11-02-2016", "11-03-2016", "11-04-2016",
"11-05-2016", "11-11-2015", "11-12-2015", "12-01-2016", "12-02-2016",
"12-04-2016", "12-05-2016", "12-06-2016", "12-11-2015", "12-12-2015",
"13-01-2016", "13-02-2016", "13-03-2016", "13-04-2016", "13-05-2016",
"13-06-2016", "13-11-2015", "13-12-2015", "14-01-2016", "14-02-2016",
"14-03-2016", "14-04-2016", "14-05-2016", "14-06-2016", "14-11-2015",
"14-12-2015", "15-01-2016", "15-02-2016", "15-03-2016", "15-04-2016",
"15-05-2016", "15-06-2016", "15-11-2015", "15-12-2015", "16-01-2016",
"16-02-2016", "16-03-2016", "16-04-2016", "16-05-2016", "16-06-2016",
"16-11-2015", "16-12-2015", "17-01-2016", "17-02-2016", "17-03-2016",
"17-04-2016", "17-05-2016", "17-06-2016", "17-11-2015", "17-12-2015",
"18-01-2016", "18-02-2016", "18-03-2016", "18-04-2016", "18-05-2016",
"18-06-2016", "18-11-2015", "18-12-2015", "19-01-2016", "19-02-2016",
"19-03-2016", "19-04-2016", "19-05-2016", "19-06-2016", "19-11-2015",
"19-12-2015", "20-01-2016", "20-03-2016", "20-04-2016", "20-05-2016",
"20-06-2016", "20-11-2015", "20-12-2015", "21-01-2016", "21-02-2016",
"21-03-2016", "21-04-2016", "21-05-2016", "21-06-2016", "21-11-2015",
"21-12-2015", "22-01-2016", "22-02-2016", "22-03-2016", "22-04-2016",
"22-05-2016", "22-06-2016", "22-11-2015", "22-12-2015", "23-01-2016",
"23-02-2016", "23-03-2016", "23-04-2016", "23-05-2016", "23-06-2016",
"23-11-2015", "23-12-2015", "24-01-2016", "24-02-2016", "24-03-2016",
"24-04-2016", "24-05-2016", "24-06-2016", "24-11-2015", "24-12-2015",
"25-01-2016", "25-02-2016", "25-03-2016", "25-04-2016", "25-05-2016",
"25-06-2016", "25-11-2015", "25-12-2015", "26-01-2016", "26-02-2016",
"26-03-2016", "26-04-2016", "26-05-2016", "26-06-2016", "26-11-2015",
"27-01-2016", "27-02-2016", "27-03-2016", "27-04-2016", "27-05-2016",
"27-06-2016", "27-11-2015", "27-12-2015", "28-01-2016", "28-02-2016",
"28-03-2016", "28-04-2016", "28-05-2016", "28-06-2016", "28-11-2015",
"28-12-2015", "29-01-2016", "29-02-2016", "29-03-2016", "29-04-2016",
"29-05-2016", "29-06-2016", "29-11-2015", "29-12-2015", "30-01-2016",
"30-03-2016", "30-04-2016", "30-05-2016", "30-06-2016", "30-11-2015",
"30-12-2015", "31-01-2016", "31-03-2016", "31-05-2016", "31-12-2015"
), class = "factor"), month = structure(c(8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L), .Label = c("Apr",
"Dec", "Feb", "Jan", "Jun", "Mar", "May", "Nov"), class = "factor"),
    day = c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
    3L, 3L, 3L, 4L, 4L, 4L, 4L), agent = structure(c(30L, 203L,
    191L, 127L, 114L, 170L, 41L, 79L, 173L, 247L, 26L, 247L,
    23L, 145L, 280L, 101L, 130L, 173L, 62L, 217L, 145L, 140L,
    251L, 115L, 62L, 233L, 254L, 85L, 245L, 203L, 174L, 30L,
    247L, 238L, 41L, 242L, 267L, 62L, 43L, 127L, 163L, 217L,
    275L, 105L, 79L, 191L, 110L, 86L, 247L, 23L), .Label = c("Aakash
Shivach",
    "Aanchal Goel", "Abhishek Bisht", "Abhishek Mudireddy", "Abhishek
Singh2",
    "Adam Boyle", "Aditi Gogia", "Afsal Backer", "Agam Sud",
    "Aishwarya Ramisetti", "Ajay Gangavarapu", "Ajaz Shaikh",
    "Akash Chandra", "Akash Jaiswal", "Akhil Jain", "Akhilesh Kumar",
    "Akiko Ono", "Akiko Tanaka", "Akilesh Mogulluri", "Akshi Bhutani",
    "Alessandro Delgado", "Alex Rozenfeld", "Amarjeet Kumar",
    "Ambili Rasu (MCS)", "Ameeduddin Sheikh", "Amit Singh", "Amritansh
Trivedi",
    "Anand Vardhan", "Anil Kumar 2", "Anil Pandey", "Anjali Thekkut",
    "Ankit Kumar", "Ankit Sharma", "Ankita Sharma", "Anne Margarette
Estipona",
    "Anudeep Alapati", "Anuj Malik", "Anurag Sharma", "Anurag Srivastava",
    "Anurikt Wadhwa", "Arpit Agarwal", "Arvind Kaushik", "Arvind
Yarlagadda",
    "Ashish Kalra", "Ashish Pandey", "Ashish Rana", "Ashish Sharma",
    "Ashraf Ahmad", "Ashutosh Tripathi", "Ashwani Mehra", "Atif Ansari",
    "Ayush Gupta", "Ayush Rastogi", "Ayush Sodhi", "Bharat Joshi",
    "Bharath Kilaparthi", "Bharath Vankayala", "Brandon Parker",
    "Carla Franchini", "Celia Oliveira", "Cesar Adames", "Chaten Raghav",
    "Chelsea McKay", "Chris Andersen (MCS)", "Clinton Harwood",
    "Dan Gustafson", "Darlene Wright", "Daryl Kurtz", "Dave Selisana",
    "Dee (Daiichiro) Tanaka (MCS)", "Divyan Solanki", "Efrilyn Tejano",
    "Eric Cheong (MCS)", "Ganesh Malla", "Garrett Surgeon", "Garvit
Talwar",
    "Gauravsingh Pawar", "Gurjeet Singh", "Gursimran Vohra",
    "Guy Halperin", "Harsh Bahadur", "Harshit Mishra", "Harshvardhan
Chauhan",
    "Hector Tarrobago", "Himanshu Sharma", "Hiroyoshi Iwakiri",
    "Iskander Mukhamedgaliyev", "Jack Ziesing", "Jacobe Bascuguin",
    "Janani Rajasekaran", "Jasdeep Singh Talwar", "Jason MacManiman",
    "Jason R Lima", "Jayaprakash Narayan (MCS)", "Jen McCarthy",
    "Jewin Joy Dsilva", "Jitin Chopra", "John Alvin Garlan",
    "John Salvan Khattyan", "Jose Garcia (MCS)", "Joshua Wilhelm",
    "Juan Rodriguez", "K N Shashank", "Kalyani Kota", "Kamakshi Nathan
Subbiah",
    "Karthik Murari (MCS)", "Kartik Singhal", "Katsuyuki Deguchi (MCS)",
    "Kazuya Ouchi", "Kenji Mizutani", "Kenjiro Hosomi", "Kenneth Hadley",
    "Kenneth Scholz", "Kiran Vuppuluri (MCS)", "Komal Gupta",
    "Kothapalli Yaswanth", "Krishna Neelam", "Kuldeep Negi",
    "Lisly Matti", "Luis Fernando Russi", "Luke Walker (MCS)",
    "Lynne Ausejo", "Lynne Beckham", "Madhav Prasad", "Maika Dela Cruz",
    "Maki Matsumoto", "Manav Vatsyayana", "Mandeep Singh", "Manish Shukla",
    "Manmeet Singh", "Mari Delos Santos", "Mari Ganesan Chandran",
    "Maria Josel Arce", "Masakazu Furumi", "Masashi Yanagisawa (MCS)",
    "Mayur Jain", "Megha Malviya", "Mehdiimam Khan", "Midori Yoshino",
    "Mithilesh Singh", "Mohamad Hamdan", "Mohammad Anis", "Moshin Pathan",
    "Mudit Mudgal", "Nancy Bhagat", "Nancy McGrew", "Nareshkumarmohan
Thirukkovaluru",
    "Nayana Kadiyala(MCS)", "Neena Aggarwal", "Neeraj Kumar",
    "Neeraja Nagalla", "Neha Singh", "Nick Martens", "Nikhil Srivastava",
    "Nikita Singh", "Nikunj Gupta", "Nilima Madala", "Nishant Chaudhary",
    "Norihiko Kodama", "Pablo Alvarez (MCS)", "Padmaja Matlaparti",
    "Pallavi Sharma", "Panati Rusia", "Parinitha Vedpathak",
    "Patrick Roland Perete", "Paul Bryan Ballesteros", "Piyush Chandani",
    "Poornachander Chiliveri", "Pradeep Raju", "Pramod Kumar",
    "Praneeth Indraganti", "Pranuthi Vallam", "Prasannta Dubey",
    "Prashant Sharma", "Praveen Kandhagatla (MCS)", "Praveen Yadav",
    "Priya Adlakha", "Priyank Jain", "Priyanka Kumari", "Priyush Jagadam",
    "Pruthvi Lanke", "Pulkit Sharma", "Puneet Gupta2", "Pushkar Diwedi",
    "Pushpa Kodwani", "Rachit Joshi", "Raghav Sahore", "Rahul Madhwani",
    "Rahul Munot", "Raj Salvi", "Rajat Bansal", "Rakshitha Rakshitha",
    "Ramu Adep (MCS)", "Randi Wilson", "Rashmitha Ramaraju (MCS)",
    "Reddy Mallareddy", "Renu Adhikari", "Richard Santin", "Ridhima
Bhatia",
    "Rie Son", "Rindha Kundur", "Rishika Bisariya", "Rishikant Dubey",
    "Ritesh Jaiswal", "Ritesh Srivastava", "Rodrigo Andrade",
    "Ross O'Riordan", "Rupal Sachan", "Ryan Klein", "Ryan Ruiz",
    "Saihareesh Sapram", "Saikat Banerjee", "Samil Gutierrez",
    "Sangam Ravindhar (MCS)", "Sanjeev Soran", "Sanpreet Saini",
    "Sarfaraj Siddiqui", "Sarthak Sharma", "Satish Alavarthi",
    "Saurav Kumar", "Saurav Sundriyal", "Sean Flynn (MCS)", "Sean Hurst",
    "Shalu Gangwar", "Shashank Mehra", "Sheshant Kashyap", "Shikha Raheja",
    "Shivani Shukla", "Shivani Singh", "Shreekanth Kyatsandra (MCS)",
    "Shubham Rathore", "Shubham Sehgal", "Sibesh Dash", "Simardeep Bindra",
    "Sirdikchowdary Marella", "Sivani Mallamapalli", "Somarani Kandar",
    "Sonalianil Mahakalkar", "Sowmya Gupta", "Sri Krishna Mantripragada",
    "Srikanth Nelluri", "Sudha Kumari", "Sumit Balouria", "Sumit Kumar",
    "Sumuga Padman", "Swapnil Deshmukh", "Swapnil Srivastav",
    "Swapnil Srivastav2", "Swati Sharma", "Swetha Kiran Nallamothu",
    "Tajinder Singh", "Takahiro Mori", "Takeshi Sato", "Tallam Venkatesh",
    "Tanu Agarwal", "Tejashree Gosavi", "Thimmaiah Vanganur",
    "Tom Graves", "Toyokazu Nakao", "Tracy Stinghen", "Tushar Samar",
    "Tushar Uniyal", "Ujjwal Rawat", "Vaibhav Goel", "Vaibhav Jain",
    "Vaibhav Kaushik", "Vanathi Vijayakumar", "Venkatesh Reddy Y",
    "Vibhor Mundepi", "Vibin Davis", "Vikas Kumar", "Vikash Ujjwal",
    "Vikram Kumar Kondapaneni (MCS)", "Vikram Nanduri (MCS)",
    "Vineet Goel", "Vinita Mishra (MCS)", "Viswanath Ronda",
    "Vivek Nair", "Wayne Cordrey", "Yathish Nimbegondi Shanmukhappa",
    "Yatin Mahajan", "Yogesh Lal", "Yoji Taoka", "Yoshiyuki Masuda (MCS)"
    ), class = "factor"), tenure = structure(c(6L, 1L, 3L, 2L,
    1L, 1L, 6L, 2L, 2L, 1L, 1L, 1L, 6L, 3L, 1L, 1L, 2L, 2L, 2L,
    3L, 3L, 2L, 2L, 6L, 2L, 2L, 6L, 2L, 3L, 1L, 3L, 6L, 1L, 3L,
    6L, 1L, 1L, 2L, 3L, 2L, 3L, 3L, 3L, 1L, 2L, 3L, 1L, 1L, 1L,
    6L), .Label = c("#N/A", "Expert", "Junior", "Newbie A", "Newbie B",
    "Senior"), class = "factor"), support_cat = structure(c(10L,
    1L, 2L, 1L, 15L, 6L, 6L, 2L, 6L, 1L, 2L, 3L, 6L, 1L, 1L,
    6L, 1L, 1L, 1L, 1L, 1L, 1L, 18L, 1L, 18L, 1L, 1L, 1L, 1L,
    1L, 1L, 18L, 1L, 6L, 18L, 18L, 1L, 1L, 1L, 15L, 1L, 1L, 18L,
    18L, 1L, 1L, 12L, 11L, 6L, 1L), .Label = c("AMER", "APAC",
    "BypassTier1", "ByPassTier1", "BYPASSTIER1", "EMEA", "Exception",
    "Global", "GOVT", "HIPPA", "JP", "JP MCS", "LACA", "LPL",
    "MCS", "None", "Partner Developer", "Special", "US only",
    "US Only"), class = "factor"), region = structure(c(1L, 1L,
    2L, 1L, 2L, 3L, 3L, 2L, 3L, 1L, 2L, 3L, 3L, 1L, 1L, 3L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 4L,
    4L, 3L, 1L), .Label = c("AMER", "APAC", "EMEA", "JP", "LACA",
    "Unknown"), class = "factor"), support_lvl = structure(c(2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L), .Label = c("Other", "Premier", "Standard"
    ), class = "factor"), skill_group = structure(c(1L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L,
    1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
    1L, 1L), .Label = c("Developer", "Integration"), class = "factor"),
    application_area = structure(c(1L, 10L, 1L, 7L, 1L, 1L, 1L,
    2L, 1L, 3L, 2L, 3L, 1L, 7L, 1L, 1L, 3L, 3L, 1L, 2L, 15L,
    3L, 3L, 7L, 1L, 1L, 3L, 1L, 1L, 1L, 7L, 1L, 1L, 2L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 14L, 1L, 2L, 3L, 3L, 1L, 1L), .Label =
c("Apex/API Development",
    "API / Apex / Visualforce", "API Integration", "API Tokens",
    "Authentication", "CTI", "Deployment", "Environment Hub",
    "Flow", "Limit Changes", "Network and Performance", "Other",
    "Packaging and Deployment", "Sites & Community", "SOQL / SOSL",
    "Workflow Automation"), class = "factor"), functional_area =
structure(c(63L,
    36L, 5L, 26L, 5L, 56L, 5L, 4L, 35L, 66L, 4L, 55L, 5L, 26L,
    5L, 63L, 8L, 8L, 5L, 63L, 59L, 34L, 1L, 17L, 5L, 5L, 50L,
    63L, 5L, 5L, 26L, 5L, 5L, 63L, 5L, 5L, 5L, 5L, 5L, 35L, 5L,
    5L, 5L, 35L, 5L, 4L, 57L, 57L, 5L, 5L), .Label = c("-", "Account
Insights",
    "Activation", "APEX", "Apex Code Development", "Apex Data Loader",
    "API", "API Performance", "API Token Issues", "API Toolkit",
    "Application Slowness", "Authentication", "Batch Apex", "Browser
specific issue",
    "Bulk API", "Canvas", "Change Sets", "Chatter REST", "Communities &
Chatter",
    "Community", "Connected Apps", "Database.com", "Debug Log Size",
    "Delagated SSO", "Delegated Authentication", "Deployment -
ANT/IDE/Code",
    "Development", "Domain Name Change", "Email", "Feature Activation",
    "Federated (SAML) SSO", "Flow Configuration", "Flow Designer",
    "Flow Development", "Force.com Sites", "Governor Limits",
    "IDE / ANT / Metadata API", "Identity Connect", "Lightning Connect",
    "Managed Package Namespaces", "Managed Packages", "Mutual
Authentication",
    "Network / ISP Latency", "Oauth", "Open CTI", "Other", "Outbound
Messaging",
    "Post Install Script", "Quick Deploy", "REST API", "Salesforce
Maintenance",
    "Salesforce1", "SAML", "Setup & Security", "Single Sign On",
    "Site.com", "SOAP API", "SOQL Performance", "SOQL Queries",
    "SOSL", "SSL Certificates", "Visual Process Manager", "Visualforce",
    "WDC1.0", "Workflow", "WSDL2 Apex"), class = "factor"), score = c(9L,
    10L, 2L, 10L, 10L, 2L, 8L, 10L, 10L, 10L, 10L, 10L, 10L,
    2L, 10L, 4L, 4L, 10L, 9L, 10L, 10L, 10L, 10L, 5L, 9L, 10L,
    8L, 10L, 10L, 10L, 10L, 10L, 10L, 1L, 9L, 8L, 10L, 10L, 10L,
    10L, 9L, 10L, 10L, 10L, 9L, 10L, 8L, 8L, 10L, 9L), rep_score = c(9.5,
    10, 2, 10, 10, 3.5, 7.5, 10, 10, 10, 10, 10, 10, 2, 10, 7.5,
    6, 10, 9.5, 10, 9, 10, 10, 5.5, 9, 10, 8, 10, 10, 10, 10,
    10, 9.5, 1.5, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 9.5,
    10, 10, 8, 10, 10), product_know = structure(c(4L, 4L, 5L,
    4L, 1L, 3L, 11L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 4L, 10L, 9L,
    4L, 4L, 4L, 11L, 4L, 4L, 9L, 12L, 4L, 11L, 4L, 4L, 4L, 4L,
    4L, 12L, 3L, 12L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
    4L, 4L, 11L, 4L, 4L), .Label = c("-", "0", "1", "10", "2",
    "3", "4", "5", "6", "7", "8", "9"), class = "factor"),
understanding_issue = structure(c(12L,
    4L, 5L, 4L, 4L, 9L, 10L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 4L,
    11L, 9L, 4L, 12L, 4L, 4L, 4L, 4L, 8L, 12L, 4L, 11L, 1L, 4L,
    4L, 4L, 4L, 4L, 5L, 12L, 11L, 4L, 4L, 4L, 4L, 4L, 4L, 1L,
    4L, 12L, 4L, 4L, 11L, 4L, 4L), .Label = c("-", "0", "1",
    "10", "2", "3", "4", "5", "6", "7", "8", "9"), class = "factor"),
    case_age = c(24.84, 0.05, 13.38, 0.15, 11.11, 4.16, 8.13,
    0.07, 3.61, 0, 3.11, 20.94, 0.21, 17.49, 1.11, 6.15, 4.32,
    4.03, 0.08, 3.06, 4.74, 12.07, 4.79, 5.29, 0.21, 0.06, 3.95,
    0.12, 7.27, 4.18, 2.49, 20.95, 0.15, 10.96, 6.99, 47.42,
    4.96, 0.06, 4.92, 0.06, 6.84, 0.3, 0.01, 0.07, 15.74, 5.8,
    2.85, 0.17, 16.02, 1.33), severity_level = structure(c(3L,
    3L, 2L, 4L, 3L, 2L, 2L, 3L, 3L, 3L, 2L, 2L, 2L, 4L, 4L, 4L,
    4L, 4L, 2L, 3L, 4L, 4L, 2L, 4L, 3L, 4L, 2L, 3L, 2L, 3L, 2L,
    4L, 3L, 3L, 4L, 4L, 4L, 4L, 2L, 4L, 3L, 2L, 2L, 2L, 3L, 3L,
    3L, 4L, 4L, 4L), .Label = c("Level 1 - Critical", "Level 2 - Urgent",
    "Level 3 - High", "Level 4 - Medium"), class = "factor"),
    case_status = structure(c(1L, 6L, 4L, 6L, 6L, 6L, 6L, 6L,
    2L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 4L, 4L, 6L, 2L, 6L, 6L, 2L,
    5L, 6L, 6L, 6L, 5L, 6L, 6L, 6L, 6L, 6L, 5L, 2L, 6L, 6L, 2L,
    6L, 2L, 6L, 6L, 6L, 6L, 6L, 6L, 2L, 2L, 6L, 2L), .Label = c("Closed -
Bug Fix Submitted",
    "Closed - Customer Closed", "Closed - Directed to IdeaExchange",
    "Closed - No response from customer", "Closed - Request out of Scope",
    "Closed - Resolved", "Closed - Routed to Internal Helpdesk",
    "Pending Customer Approval", "Working"), class = "factor"),
    account_segment = structure(c(3L, 8L, 4L, 3L, 9L, 3L, 4L,
    4L, 8L, 9L, 1L, 4L, 3L, 3L, 3L, 9L, 4L, 3L, 9L, 3L, 3L, 3L,
    9L, 3L, 9L, 8L, 9L, 8L, 8L, 2L, 8L, 9L, 4L, 8L, 9L, 2L, 3L,
    3L, 3L, 9L, 8L, 3L, 9L, 9L, 4L, 4L, 9L, 3L, 9L, 4L), .Label = c("-",
    "Flagship", "Large", "Medium", "Mega", "N/A", "Platinum",
    "Small", "Top", "Very Small"), class = "factor"), sla_status =
structure(c(1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 1L, 1L, 1L), .Label = c("Met", "Missed", "N/A", "Pending"
    ), class = "factor"), delivery_segmentation = structure(c(31L,
    31L, 31L, 31L, 10L, 26L, 31L, 31L, 31L, 31L, 25L, 31L, 31L,
    31L, 24L, 8L, 31L, 31L, 31L, 31L, 31L, 31L, 31L, 31L, 31L,
    31L, 31L, 31L, 31L, 31L, 31L, 31L, 31L, 31L, 31L, 28L, 24L,
    31L, 31L, 31L, 31L, 31L, 31L, 5L, 31L, 31L, 32L, 33L, 31L,
    31L), .Label = c("-", "AMER - IND - T3", "AMER Dev Port",
    "AMER Mission Critical Success (MCS)", "AMER Tier 2 Port",
    "AMER Tier 3 Port", "AMER TS Tier 2", "AMER TS Tier 2 DEV",
    "AMER TS Tier 3", "APAC Mission Critical Success (MCS)",
    "APAC TS Tier 2", "COGZ DESM Admin", "COGZ DESM Tier 2",
    "COGZ MANL Tier 1", "COGZ MANL Tier 2", "COGZ PUNE Admin",
    "COGZ PUNE Tier 1", "EMEA Mission Critical Success (MCS)",
    "EMEA Premier T2", "EMEA TS Tier 2 DEV", "EMEA TS Tier 3",
    "HCL MANL Tier 1", "HCL MANL Tier 2", "HYDR AMER TS Tier 2 DEV",
    "HYDR APAC TS Tier 2 DEV", "HYDR EMEA TS Tier 2 DEV", "HYDR Premier
Internal Admin APAC",
    "HYDR Premier Internal Tier 2 AMER", "HYDR Premier Internal Tier 2
APAC",
    "HYDR Premier Internal Tier 2 EMEA", "India TS Tier 2 Dev Outsource",
    "Japan Premier Internal Tier 2 (PSA)", "Japan TS Tier 1",
    "Japan TS Tier 2 Internal", "Japan TS Tier 3", "JP Mission Critical
Success (MCS)",
    "Partner - Internal"), class = "factor"), survey = c(1, 1,
    0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,
    1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 0, 0, 1, 1), repS = c(1, 1, 0, 1, 1, 0,
    0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,
    1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 0, 1, 1), log_caseage = c(3.2519236789144, 0.048790164169432,
    2.6658383522929, 0.139761942375159, 2.494031557565, 1.64093657949347,
    2.21156569460688, 0.0676586484738148, 1.52822785700856, 0,
    1.41342302850814, 3.08831145484708, 0.19062035960865, 2.91723004539903,
    0.746687947487975, 1.96711235670592, 1.67147330335355,
1.61541998411165,
    0.0769610411361283, 1.40118297361364, 1.74745921033147,
2.57031952763613,
    1.7561322915849, 1.83896107071235, 0.19062035960865,
0.0582689081239758,
    1.5993875765806, 0.113328685307003, 2.1126345090356, 1.64480505627139,
    1.24990173621434, 3.08876713952118, 0.139761942375159,
2.48156774852249,
    2.07819075977818, 3.87991295150991, 1.78507048107726,
0.0582689081239758,
    1.77833644889591, 0.0582689081239758, 2.05923883436232,
0.262364264467491,
    0.00995033085316808, 0.0676586484738148, 2.81780106506133,
    1.91692261218206, 1.34807314829969, 0.157003748809665,
2.83438912314523,
    0.845868267577609)), .Names = c("date", "month", "day", "agent",
"tenure", "support_cat", "region", "support_lvl", "skill_group",
"application_area", "functional_area", "score", "rep_score",
"product_know", "understanding_issue", "case_age", "severity_level",
"case_status", "account_segment", "sla_status", "delivery_segmentation",
"survey", "repS", "log_caseage"), row.names = c(NA, 50L), class =
"data.frame")



On Tue, Aug 30, 2016 at 10:30 PM, William Dunlap <wdunlap at tibco.com> wrote:

> You did not say what operation gave you the error.
>
> I can get that message (which is not an "error") if I print
> an illegally constructed data.frame, one without the
> row.names attribute.
>
> > illegalDF <- structure(class="data.frame", list(ColumnA = 1:3))
> > illegalDF
> [1] ColumnA
> <0 rows> (or 0-length row.names)
> > str(illegalDF)
> 'data.frame':   0 obs. of  1 variable:
>  $ ColumnA: int  1 2 3
>
> Note how str() of the entire data.frame indirectly informs you of the
> problem: the number of observations does not match the length of the
> columns.
>
> How did you make the data.frame?
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Aug 30, 2016 at 9:24 AM, Shivi Bhatia <shivipmp82 at gmail.com>
> wrote:
>
>> I know this question has been asked zillion times but even after
>> consulting
>> Stack Overflow & other forum cant figure out the reason.
>>
>> I have one var in my data-set names case age. This variable is numeric as:
>>
>> class(SFDC$case_age)
>>
>> *numeric*
>>
>> however it throws this error:
>>
>> <0 rows> (or 0-length row.names)
>> As checked this only happens either there is some space at the end of the
>> variable name, or there are no values whereas this is a numeric variable
>> with no missing values and has a total of 5400 observations.
>>
>> This var has a range from 0 to 240 in number of days for case variable
>> hence i need to do a logarithm transformation & make it use in the model.
>> Total unique obs are around 1500.
>>
>> Please advice.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From clint at ecy.wa.gov  Tue Aug 30 19:48:08 2016
From: clint at ecy.wa.gov (Clint Bowman)
Date: Tue, 30 Aug 2016 10:48:08 -0700 (PDT)
Subject: [R] plot with different symbols and colors according to the
 factor levels
In-Reply-To: <alpine.LRH.2.20.1608301032350.18539@aeolus.ecy.wa.gov>
References: <CAHLnndbT6YQseS7oyQNtqJOQVw_sq+v9UTMJfkF354iSi=1u7g@mail.gmail.com>
	<alpine.LRH.2.20.1608301032350.18539@aeolus.ecy.wa.gov>
Message-ID: <alpine.LRH.2.20.1608301047320.18539@aeolus.ecy.wa.gov>


with(lili,plot(y,conc,pch=sample,col=sample,log="y"))

gives a better plot


Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Tue, 30 Aug 2016, Clint Bowman wrote:

> Hanna,
>
> lili<-read.table("lili.txt",header=T)  # don't forget to label the row number 
> if it's in your data
>
> with(lili,plot(y,conc,pch=sample,col=sample))
>
> Clint
>
>
> Clint Bowman			INTERNET:	clint at ecy.wa.gov
> Air Quality Modeler		INTERNET:	clint at math.utah.edu
> Department of Ecology		VOICE:		(360) 407-6815
> PO Box 47600			FAX:		(360) 407-7534
> Olympia, WA 98504-7600
>
>         USPS:           PO Box 47600, Olympia, WA 98504-7600
>         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>
> On Tue, 30 Aug 2016, li li wrote:
>
>>  Hi all,
>>  I have the following data. I want to plot the data (y ~ conc)
>>  with different symbols and colors corresponding to different levels of the
>>  factor sample.
>>  I could create a column with color and pch and then do the plot, but I am
>>  sure there are much better ways.
>>  Can anyone make suggestions?
>>   Hanna
>> 
>> 
>>
>>    y         conc sample
>>  1  33 20.000000000      1
>>  2  33  5.000000000      1
>>  3  35  1.250000000      1
>>  4  43  0.312500000      1
>>  5  58  0.078125000      1
>>  6  54  0.019531250      1
>>  7  57  0.004882812      1
>>  8  57  0.001220703      1
>>  9  32 20.000000000      1
>>  10 32  5.000000000      1
>>  11 34  1.250000000      1
>>  12 52  0.312500000      1
>>  13 57  0.078125000      1
>>  14 58  0.019531250      1
>>  15 59  0.004882812      1
>>  16 50  0.001220703      1
>>  17 34 20.000000000      2
>>  18 34  5.000000000      2
>>  19 38  1.250000000      2
>>  20 53  0.312500000      2
>>  21 57  0.078125000      2
>>  22 57  0.019531250      2
>>  23 57  0.004882812      2
>>  24 52  0.001220703      2
>>  25 34 20.000000000      2
>>  26 33  5.000000000      2
>>  27 36  1.250000000      2
>>  28 48  0.312500000      2
>>  29 58  0.078125000      2
>>  30 57  0.019531250      2
>>  31 58  0.004882812      2
>>  32 53  0.001220703      2
>>  33 34 20.000000000      2
>>  34 35  5.000000000      2
>>  35 37  1.250000000      2
>>  36 49  0.312500000      2
>>  37 55  0.078125000      2
>>  38 59  0.019531250      2
>>  39 57  0.004882812      2
>>  40 54  0.001220703      2
>>  41 36 20.000000000      3
>>  42 33  5.000000000      3
>>  43 36  1.250000000      3
>>  44 51  0.312500000      3
>>  45 57  0.078125000      3
>>  46 57  0.019531250      3
>>  47 59  0.004882812      3
>>  48 56  0.001220703      3
>>  49 33 20.000000000      3
>>  50 32  5.000000000      3
>>  51 35  1.250000000      3
>>  52 47  0.312500000      3
>>  53 57  0.078125000      3
>>  54 56  0.019531250      3
>>  55 57  0.004882812      3
>>  56 53  0.001220703      3
>>  57 33 20.000000000      3
>>  58 34  5.000000000      3
>>  59 38  1.250000000      3
>>  60 52  0.312500000      3
>>  61 56  0.078125000      3
>>  62 61  0.019531250      3
>>  63 56  0.004882812      3
>>  64 55  0.001220703      3
>>
>>   [[alternative HTML version deleted]]
>>
>>  ______________________________________________
>>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>  PLEASE do read the posting guide
>>  http://www.R-project.org/posting-guide.html
>>  and provide commented, minimal, self-contained, reproducible code.
>> 
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From cimentadaj at gmail.com  Tue Aug 30 20:01:12 2016
From: cimentadaj at gmail.com (Jorge Cimentada)
Date: Tue, 30 Aug 2016 20:01:12 +0200
Subject: [R] Loop over rda list files and using the attach function
In-Reply-To: <CALBYkjJLY0Rqve9+CeSfXYkRrUVvAcCt4URBvtLcOMZefKU62Q@mail.gmail.com>
References: <CALBYkjJLY0Rqve9+CeSfXYkRrUVvAcCt4URBvtLcOMZefKU62Q@mail.gmail.com>
Message-ID: <CALdB+JEspMXnj1gjxC83Be_iQDDD5JATePnpzQyfSw9yvS9PuA@mail.gmail.com>

Here's the problem: when you load the object and name it yyz, its simply
storing the name of the data frame as a string. Naturally, when you you
attach the string, it throws an error. The loop actually loads the data
frame but inside yyz there's not a data frame.

One problem with load() is that you can't save it as an object; it simply
loads the data to the chosen environment. A different solution would be to
use .Rds, which allows to be saved as an object and makes your loop work.
However, you need to make sure your files are saved as .Rds with the
saveRDS() function. Here's an example with loadRDS() instead of load():

## Generate 10 data frames and save it to your working directory as .Rds
for (i in 1:10) {
        x <- data.frame(a=rnorm(10), b=c("Yes","No"))
        saveRDS(x, file=paste0("data",i,".rds")) # save as RDS
        rm(x)
}


dd <- grep(".rds", list.files(), value=T) # vector with data file names
for (i in 1:length(dd)) {
        yyz <- readRDS(dd[i]) # load data.frame and save it to yyz
        print(with(yyz, table(a, b))) # print the table
        rm(yyz) # remove data frame
}

Hope this helps. I found the solution through:
https://www.r-bloggers.com/a-better-way-of-saving-and-loading-objects-in-r/

*Jorge Cimentada*
*Ph.D. Candidate*
Dpt. Ci?ncies Pol?tiques i Socials
Ramon Trias Fargas, 25-27 | 08005 Barcelona

Office 24.331
[Tel.] 697 382 009
jorge.cimentada at upf.edu
http://www.upf.edu/dcpis/



On Tue, Aug 30, 2016 at 5:43 PM, Juan Ceccarelli Arias <jfca283 at gmail.com>
wrote:

> Hi.
> I need to loop over rda files.
> I generated the list of them.
> That's ok. The problem is that the name of the files are as yyyy_mm (eg
> 2010_01 is january or 2010, 2016_03 is march of 2016).
> So, when i try to use the attach function to create a simple table(age,
> sex) it fails.
> The only way to attach a file as is using
> attach(`2016_03`)
> The text above i have no idea how to declare it in my code below
>
>
> dd=list.files("C:/Users/Me/r", pattern="rda$", full.names=F)
> for (i in 1:length(dd)) {
> yyz=load(dd[i])
> attach(yyz)
> table(age, sex)
> rm(list=yyz)
>
> }
> This is the error it declares the loop:
> Error in attach(yyz) : file '2013_02' not found
>
>
> Thanks for your help and time
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Aug 30 20:03:40 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 30 Aug 2016 11:03:40 -0700
Subject: [R] loading .rda file
In-Reply-To: <22469.48768.472833.853458@stat.math.ethz.ch>
References: <CAA0F9kUoeMp5eJs5vaGBb5vgXBHjLLgFU2+b-FyO2knsQSztig@mail.gmail.com>
	<FF960259-852B-4764-B5EA-1DA4BDDA5836@dcn.davis.ca.us>
	<22469.48768.472833.853458@stat.math.ethz.ch>
Message-ID: <BFB153CE-5AC6-434A-AB4C-51181B1EDE5B@dcn.davis.ca.us>

Thanks for the perspective, Martin. I personally feel like attaching to the search path is more confusing than being explicit, because it appears indistinguishable from namespace pollution yet for modifying data it creates copies in the current environment (in-place editing requires `<<-` which requires keeping your search path in mind as you work to know when to use it).
-- 
Sent from my phone. Please excuse my brevity.

On August 30, 2016 10:12:32 AM PDT, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>>>>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>>>>>     on Tue, 30 Aug 2016 09:36:05 -0700 writes:
>
>> You cannot. However, you can load the file into a dedicated
>environment to keep those names separated from your global environment.
>e.g. [1]
>
>yes, that's my "famous"  only-allowed use of  attach() :
>attach() an rda-file to your search patch instead of polluting
>your globalenv.
>
>  > The saveRDS / loadRDS 
>
>        saveRDS / readRDS   are the correct names
>
>> functions are an alternative handle one object at a time without
>dragging the object names into the picture (you have to name the
>re-loaded object).
>
>The fact that it is readRDS() and not loadRDS(),
>actually does convey via it is often "much better" in the sense
>of functional / transparent programming to use this pair in
>favor of save() / load() :
>readRDS() does *return* what we are interested in, and
>
>   result <- readRDS(<file>)
>
>is so much better than   load(<file>)   silently overwriting all
>kinds of objects in my globalenv.
>
>Indeed, I strongly advocate to use  saveRDS() and readRDS()
>much more frequently than they are used nowawadays.
>
>
>
>> However, the best approach is to write scripts that pull directly
>from your source (non-R) data files. This makes your work process
>reproducible as you develop it.
>
>Yes, but that's sometimes too inefficient.
>
>And then, some of us do simulations and other expensive
>computations, we need/want to save and re-read.
>
>and yes,  I *always*  use the equivalent of   q("no")  to leave R; 
>never save the workspace or load it at startup, unless
>accidentally on non-standard (for me) platforms.
>
>Martin
>
>    > [1] https://stat.ethz.ch/pipermail/r-help/2016-August/441078.html
>    > -- 
>    > Sent from my phone. Please excuse my brevity.
>
>> On August 30, 2016 7:37:24 AM PDT, Leslie Rutkowski
><leslie.rutkowski at gmail.com> wrote:
>    >> Hi,
>    >> 
>>> I'm slowly migrating from SAS to R and - for the very first time -
>I'm
>>> working with a native .Rda data file (rather than importing data
>from
>    >> other
>>> sources). When I load this .Rda file into the global environment
>using
>>> load("file path") I see a data.frame in the global environment
>called
>    >> "mydata" that corresponds to the .rda file.
>    >> 
>>> My question: how can I change the name of this data.frame to
>something
>    >> of
>    >> my choosing?
>    >> 
>    >> Thanks for considering this very simple question.
>    >> 
>    >> Leslie
>    >> 
>    >> [[alternative HTML version deleted]]
>    >> 
>    >> ______________________________________________
>   >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    >> https://stat.ethz.ch/mailman/listinfo/r-help
>    >> PLEASE do read the posting guide
>    >> http://www.R-project.org/posting-guide.html
>  >> and provide commented, minimal, self-contained, reproducible code.
>
>    > ______________________________________________
>    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    > https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>   > and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Tue Aug 30 20:36:43 2016
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 30 Aug 2016 12:36:43 -0600
Subject: [R] Loop over rda list files and using the attach function
In-Reply-To: <CALBYkjJLY0Rqve9+CeSfXYkRrUVvAcCt4URBvtLcOMZefKU62Q@mail.gmail.com>
References: <CALBYkjJLY0Rqve9+CeSfXYkRrUVvAcCt4URBvtLcOMZefKU62Q@mail.gmail.com>
Message-ID: <CAFEqCdzu3Ssbu8RVPgCJY2-UAGio8TAZ9K1unXGOqhXi_L5qpg@mail.gmail.com>

You can attach rda files directly with the attach function, no need to
load them first (see the what argument in the help for attach).  This
may do what you want more directly.

In general it is better to not use loops and attach for this kind of
thing.  It is better to store multiple data objects in a list, then
use lapply/sapply to apply functions to each element.


On Tue, Aug 30, 2016 at 9:43 AM, Juan Ceccarelli Arias
<jfca283 at gmail.com> wrote:
> Hi.
> I need to loop over rda files.
> I generated the list of them.
> That's ok. The problem is that the name of the files are as yyyy_mm (eg
> 2010_01 is january or 2010, 2016_03 is march of 2016).
> So, when i try to use the attach function to create a simple table(age,
> sex) it fails.
> The only way to attach a file as is using
> attach(`2016_03`)
> The text above i have no idea how to declare it in my code below
>
>
> dd=list.files("C:/Users/Me/r", pattern="rda$", full.names=F)
> for (i in 1:length(dd)) {
> yyz=load(dd[i])
> attach(yyz)
> table(age, sex)
> rm(list=yyz)
>
> }
> This is the error it declares the loop:
> Error in attach(yyz) : file '2013_02' not found
>
>
> Thanks for your help and time
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From ruipbarradas at sapo.pt  Tue Aug 30 20:42:24 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Tue, 30 Aug 2016 19:42:24 +0100
Subject: [R] Loop over rda list files and using the attach function
In-Reply-To: <CALBYkjJLY0Rqve9+CeSfXYkRrUVvAcCt4URBvtLcOMZefKU62Q@mail.gmail.com>
Message-ID: <20160830194224.Horde.ZIl7YbovKZCpCjdiP-BRhFN@mail.sapo.pt>

Hello,

Try

attach(get(yyz))

Hope this helps,

Rui Barradas







Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:

> Hi.
> I need to loop over rda files.
> I generated the list of them.
> That's ok. The problem is that the name of the files are as yyyy_mm (eg
> 2010_01 is january or 2010, 2016_03 is march of 2016).
> So, when i try to use the attach function to create a simple table(age,
> sex) it fails.
> The only way to attach a file as is using
> attach(`2016_03`)
> The text above i have no idea how to declare it in my code below
>
>
> dd=list.files("C:/Users/Me/r", pattern="rda$", full.names=F)
> for (i in 1:length(dd)) {
> yyz=load(dd[i])
> attach(yyz)
> table(age, sex)
> rm(list=yyz)
>
> }
> This is the error it declares the loop:
> Error in attach(yyz) : file '2013_02' not found
>
>
> Thanks for your help and time
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marius.hofert at uwaterloo.ca  Tue Aug 30 20:45:33 2016
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Tue, 30 Aug 2016 20:45:33 +0200
Subject: [R] How to test existence of an environment and how to remove
 it (from within functions)?
In-Reply-To: <c6f8c516450c49d9bea0a89e10b1107b@CONNHUB1.connect.uwaterloo.ca>
References: <CAM3-KjapbnvpU=Bfg5XRUVJc+xAvkON6vWSgnkU8NTBdJxV2Cw@mail.gmail.com>
	<d1d8aef270b04c46ad9cb0bab2af4044@CONNHUB4.connect.uwaterloo.ca>
	<CAM3-Kjbjvib08gVV7vJqLnbYSBPpHH3OYHh7Fh1kmKAkjUiKBw@mail.gmail.com>
	<c6f8c516450c49d9bea0a89e10b1107b@CONNHUB1.connect.uwaterloo.ca>
Message-ID: <CAM3-Kjb7uS=kp9BACWF-EBzxBdo2P3O+4HU_-egEQc6EE80X+Q@mail.gmail.com>

Hi Duncan,

... I don't have to know (I thought). The idea was to set up the environment
only for a single object x. If it (= the environment (see MWE 2) *or* the object
(see MWE 1)) exists, it's the right one. But I agree that it's 'cleaner' to work
with a hash -- yet I first wanted to understand how to check whether the
environment exists and how to remove it (especially for the latter, I couldn't
find anything... most sources of information dealt with how to delete objects in
an environment, not an environment itself [caution: I just started to learn
about environments, there is a high chance that there's a misconception on my
end...:-) ]).

With memoise, it works as expected:

library(memoise)

## Auxiliary function
aux <- function(x) {
    Sys.sleep(1)
    x[,1:2]
}

## Main function
main <- function() {
    aux. <- memoise(aux)
    x <- matrix(rnorm(100*1000), ncol = 1000)
    res <- replicate(5, aux.(x))
    forget(aux.)
    res
}

## Testing
set.seed(271)
system.time(res1 <- main()) # => ~ 1s
stopifnot(all.equal(res1[,,1], res1[,,2]),
          all.equal(res1[,,2], res1[,,3]),
          all.equal(res1[,,3], res1[,,4]),
          all.equal(res1[,,4], res1[,,5]))
system.time(res2 <- main()) # => ~ 1s
stopifnot(all.equal(res2[,,1], res2[,,2]),
          all.equal(res2[,,2], res2[,,3]),
          all.equal(res2[,,3], res2[,,4]),
          all.equal(res2[,,4], res2[,,5]))

The biggest takeaway here is to have main() set up another auxiliary function
(aux.()) which calls aux().

I looked at memoise and it is surprisingly short. I then tried to adapt the idea
directly (I try to learn things, not just use them), but it fails with "Error in
exists(hash, envir = cache, inherits = FALSE) (from #6) : use of NULL
environment is defunct". Not sure why this works from inside memoise...


library(digest)

## Auxiliary function
aux <- function(x) {
    Sys.sleep(1)
    x[,1:2]
}

## Main function
main <- function() {

    ## Wrap aux() in another helper function
    aux. <- function(...) {
        ## Set up cache
        cache <- NULL
        cache_reset <- function() cache <<- new.env(TRUE, emptyenv())
        ## Define key
        hash <- digest(list(...))
        ## Do the computation (if not done already)
        if (exists(hash, envir = cache, inherits = FALSE)) {
            get(hash, envir = cache, inherits = FALSE) # get result
        } else {
            res <- aux(...) # compute result
            assign(hash, res, envir = cache) # cache result
            res
        }
    }

    ## Call aux() via aux.()
    x <- matrix(rnorm(100*1000), ncol = 1000)
    res <- replicate(5, aux.(x))

    ## Reset cache
    get("cache", environment(aux.))$reset()

    ## Return
    res
}

## Testing
set.seed(271)
system.time(res1 <- main())
## => Error in exists(hash, envir = cache, inherits = FALSE) (from #6) :
##      use of NULL environment is defunct


Thanks & cheers,
Marius


From 538280 at gmail.com  Tue Aug 30 20:49:16 2016
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 30 Aug 2016 12:49:16 -0600
Subject: [R] plot with different symbols and colors according to the
 factor levels
In-Reply-To: <alpine.LRH.2.20.1608301047320.18539@aeolus.ecy.wa.gov>
References: <CAHLnndbT6YQseS7oyQNtqJOQVw_sq+v9UTMJfkF354iSi=1u7g@mail.gmail.com>
	<alpine.LRH.2.20.1608301032350.18539@aeolus.ecy.wa.gov>
	<alpine.LRH.2.20.1608301047320.18539@aeolus.ecy.wa.gov>
Message-ID: <CAFEqCdy7boEMZFXdN=FmULn+8u+Cdjb1+p3CJ11QXiFEDLNTMw@mail.gmail.com>

And you can specify the symbols and colors using code like:

with(lili, plot(y,conc, pch= c(16,18,17)[sample],
col=c('red','green','blue')[sample], log="y"))

modifying to meet your data and preferences, of course.

On Tue, Aug 30, 2016 at 11:48 AM, Clint Bowman <clint at ecy.wa.gov> wrote:
>
> with(lili,plot(y,conc,pch=sample,col=sample,log="y"))
>
> gives a better plot
>
>
> Clint Bowman                    INTERNET:       clint at ecy.wa.gov
> Air Quality Modeler             INTERNET:       clint at math.utah.edu
> Department of Ecology           VOICE:          (360) 407-6815
> PO Box 47600                    FAX:            (360) 407-7534
> Olympia, WA 98504-7600
>
>         USPS:           PO Box 47600, Olympia, WA 98504-7600
>         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>
> On Tue, 30 Aug 2016, Clint Bowman wrote:
>
>> Hanna,
>>
>> lili<-read.table("lili.txt",header=T)  # don't forget to label the row
>> number if it's in your data
>>
>> with(lili,plot(y,conc,pch=sample,col=sample))
>>
>> Clint
>>
>>
>> Clint Bowman                    INTERNET:       clint at ecy.wa.gov
>> Air Quality Modeler             INTERNET:       clint at math.utah.edu
>> Department of Ecology           VOICE:          (360) 407-6815
>> PO Box 47600                    FAX:            (360) 407-7534
>> Olympia, WA 98504-7600
>>
>>         USPS:           PO Box 47600, Olympia, WA 98504-7600
>>         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>>
>> On Tue, 30 Aug 2016, li li wrote:
>>
>>>  Hi all,
>>>  I have the following data. I want to plot the data (y ~ conc)
>>>  with different symbols and colors corresponding to different levels of
>>> the
>>>  factor sample.
>>>  I could create a column with color and pch and then do the plot, but I
>>> am
>>>  sure there are much better ways.
>>>  Can anyone make suggestions?
>>>   Hanna
>>>
>>>
>>>
>>>    y         conc sample
>>>  1  33 20.000000000      1
>>>  2  33  5.000000000      1
>>>  3  35  1.250000000      1
>>>  4  43  0.312500000      1
>>>  5  58  0.078125000      1
>>>  6  54  0.019531250      1
>>>  7  57  0.004882812      1
>>>  8  57  0.001220703      1
>>>  9  32 20.000000000      1
>>>  10 32  5.000000000      1
>>>  11 34  1.250000000      1
>>>  12 52  0.312500000      1
>>>  13 57  0.078125000      1
>>>  14 58  0.019531250      1
>>>  15 59  0.004882812      1
>>>  16 50  0.001220703      1
>>>  17 34 20.000000000      2
>>>  18 34  5.000000000      2
>>>  19 38  1.250000000      2
>>>  20 53  0.312500000      2
>>>  21 57  0.078125000      2
>>>  22 57  0.019531250      2
>>>  23 57  0.004882812      2
>>>  24 52  0.001220703      2
>>>  25 34 20.000000000      2
>>>  26 33  5.000000000      2
>>>  27 36  1.250000000      2
>>>  28 48  0.312500000      2
>>>  29 58  0.078125000      2
>>>  30 57  0.019531250      2
>>>  31 58  0.004882812      2
>>>  32 53  0.001220703      2
>>>  33 34 20.000000000      2
>>>  34 35  5.000000000      2
>>>  35 37  1.250000000      2
>>>  36 49  0.312500000      2
>>>  37 55  0.078125000      2
>>>  38 59  0.019531250      2
>>>  39 57  0.004882812      2
>>>  40 54  0.001220703      2
>>>  41 36 20.000000000      3
>>>  42 33  5.000000000      3
>>>  43 36  1.250000000      3
>>>  44 51  0.312500000      3
>>>  45 57  0.078125000      3
>>>  46 57  0.019531250      3
>>>  47 59  0.004882812      3
>>>  48 56  0.001220703      3
>>>  49 33 20.000000000      3
>>>  50 32  5.000000000      3
>>>  51 35  1.250000000      3
>>>  52 47  0.312500000      3
>>>  53 57  0.078125000      3
>>>  54 56  0.019531250      3
>>>  55 57  0.004882812      3
>>>  56 53  0.001220703      3
>>>  57 33 20.000000000      3
>>>  58 34  5.000000000      3
>>>  59 38  1.250000000      3
>>>  60 52  0.312500000      3
>>>  61 56  0.078125000      3
>>>  62 61  0.019531250      3
>>>  63 56  0.004882812      3
>>>  64 55  0.001220703      3
>>>
>>>   [[alternative HTML version deleted]]
>>>
>>>  ______________________________________________
>>>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>>  PLEASE do read the posting guide
>>>  http://www.R-project.org/posting-guide.html
>>>  and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From msharp at txbiomed.org  Tue Aug 30 21:05:19 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Tue, 30 Aug 2016 19:05:19 +0000
Subject: [R] 0 rows> (or 0-length row.names)
In-Reply-To: <CAB=p7Sqt8x3chPB1nEH4yyZmGVQ30j3W-y4RQ9XgH2TWuRO2Lw@mail.gmail.com>
References: <CAB=p7SpPBEL5Yt3uL6Xq2BT8SJjjzY=9ZwPF9F_JSyZRqJ6fUw@mail.gmail.com>
	<CAF8bMcZCAtFmDbdiNwfTjobLVugdQ89a97Enymt+cry-A+mTzQ@mail.gmail.com>
	<CAB=p7Sqt8x3chPB1nEH4yyZmGVQ30j3W-y4RQ9XgH2TWuRO2Lw@mail.gmail.com>
Message-ID: <81CB7399-239C-4ECA-848B-2EB169FE2328@TxBiomed.org>

Shivi,

It is likely that William knows what you are trying to do because of his considerable experience, but I am not able to figure it out from what you have written. You have apparently sent the output from something like dput(SFDC[1:50, ]), but I still do not know what you did to get the error.

I successfully assigned the structure you sent to the name SFDC and nothing seems amiss.


Mark

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org







> On Aug 30, 2016, at 12:32 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
>
> Hi William/ Mark,
>
> I am using WOE & IV (weight of evidence) reduce the number of independent
> vars.
> I have read this data as a csv file.
> reproducible example for your reference please:
>
> structure(list(date = structure(c(6L, 6L, 6L, 6L, 6L, 6L, 14L,
> 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
>
... truncated
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From shivipmp82 at gmail.com  Tue Aug 30 21:15:32 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Wed, 31 Aug 2016 00:45:32 +0530
Subject: [R] 0 rows> (or 0-length row.names)
In-Reply-To: <81CB7399-239C-4ECA-848B-2EB169FE2328@TxBiomed.org>
References: <CAB=p7SpPBEL5Yt3uL6Xq2BT8SJjjzY=9ZwPF9F_JSyZRqJ6fUw@mail.gmail.com>
	<CAF8bMcZCAtFmDbdiNwfTjobLVugdQ89a97Enymt+cry-A+mTzQ@mail.gmail.com>
	<CAB=p7Sqt8x3chPB1nEH4yyZmGVQ30j3W-y4RQ9XgH2TWuRO2Lw@mail.gmail.com>
	<81CB7399-239C-4ECA-848B-2EB169FE2328@TxBiomed.org>
Message-ID: <CAB=p7SqLf=mSwZMn=ZemsJta+PkFwVHeXdVXNwXqTyGOBJiJhw@mail.gmail.com>

Hi Mark,
What i understand, probably when i run the WOE & IV to check significant
variables that is where i get this error. Thanks for your assistance Mark
really appreciate i will look into some other measure on this.

On Wed, Aug 31, 2016 at 12:35 AM, Mark Sharp <msharp at txbiomed.org> wrote:

> Shivi,
>
> It is likely that William knows what you are trying to do because of his
> considerable experience, but I am not able to figure it out from what you
> have written. You have apparently sent the output from something like
> dput(SFDC[1:50, ]), but I still do not know what you did to get the error.
>
> I successfully assigned the structure you sent to the name SFDC and
> nothing seems amiss.
>
>
> Mark
>
> R. Mark Sharp, Ph.D.
> Director of Primate Records Database
> Southwest National Primate Research Center
> Texas Biomedical Research Institute
> P.O. Box 760549
> San Antonio, TX 78245-0549
> Telephone: (210)258-9476
> e-mail: msharp at TxBiomed.org
>
>
>
>
>
>
>
> > On Aug 30, 2016, at 12:32 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
> >
> > Hi William/ Mark,
> >
> > I am using WOE & IV (weight of evidence) reduce the number of independent
> > vars.
> > I have read this data as a csv file.
> > reproducible example for your reference please:
> >
> > structure(list(date = structure(c(6L, 6L, 6L, 6L, 6L, 6L, 14L,
> > 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
> >
> ... truncated
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
> transmitted, may contain privileged and confidential information and is
> intended solely for the exclusive use of the individual or entity to whom
> it is addressed. If you are not the intended recipient, you are hereby
> notified that any review, dissemination, distribution or copying of this
> e-mail and/or attachments is strictly prohibited. If you have received this
> e-mail in error, please immediately notify the sender stating that this
> transmission was misdirected; return the e-mail to sender; destroy all
> paper copies and delete all electronic copies from your system without
> disclosing its contents.
>

	[[alternative HTML version deleted]]


From msharp at txbiomed.org  Tue Aug 30 21:24:46 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Tue, 30 Aug 2016 19:24:46 +0000
Subject: [R] 0 rows> (or 0-length row.names)
In-Reply-To: <CAB=p7SqLf=mSwZMn=ZemsJta+PkFwVHeXdVXNwXqTyGOBJiJhw@mail.gmail.com>
References: <CAB=p7SpPBEL5Yt3uL6Xq2BT8SJjjzY=9ZwPF9F_JSyZRqJ6fUw@mail.gmail.com>
	<CAF8bMcZCAtFmDbdiNwfTjobLVugdQ89a97Enymt+cry-A+mTzQ@mail.gmail.com>
	<CAB=p7Sqt8x3chPB1nEH4yyZmGVQ30j3W-y4RQ9XgH2TWuRO2Lw@mail.gmail.com>
	<81CB7399-239C-4ECA-848B-2EB169FE2328@TxBiomed.org>
	<CAB=p7SqLf=mSwZMn=ZemsJta+PkFwVHeXdVXNwXqTyGOBJiJhw@mail.gmail.com>
Message-ID: <2B01B670-CE6F-45DC-9D09-22D6AEDF938D@TxBiomed.org>

Shivi,

What package(s) are you using. What functions are you using. How are you calling the functions. A reproducible sample has all of the actual code needed to create a representative error. There are multiple packages you could be using to look at weight of evidence and information value. For example, there is a WOE function in the Information package and a woe function in the woe package.

Mark
On Aug 30, 2016, at 2:15 PM, Shivi Bhatia <shivipmp82 at gmail.com<mailto:shivipmp82 at gmail.com>> wrote:

Hi Mark,
What i understand, probably when i run the WOE & IV to check significant variables that is where i get this error. Thanks for your assistance Mark really appreciate i will look into some other measure on this.

On Wed, Aug 31, 2016 at 12:35 AM, Mark Sharp <msharp at txbiomed.org<mailto:msharp at txbiomed.org>> wrote:
Shivi,

It is likely that William knows what you are trying to do because of his considerable experience, but I am not able to figure it out from what you have written. You have apparently sent the output from something like dput(SFDC[1:50, ]), but I still do not know what you did to get the error.

I successfully assigned the structure you sent to the name SFDC and nothing seems amiss.


Mark

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org<mailto:msharp at txbiomed.org>







> On Aug 30, 2016, at 12:32 PM, Shivi Bhatia <shivipmp82 at gmail.com<mailto:shivipmp82 at gmail.com>> wrote:
>
> Hi William/ Mark,
>
> I am using WOE & IV (weight of evidence) reduce the number of independent
> vars.
> I have read this data as a csv file.
> reproducible example for your reference please:
>
> structure(list(date = structure(c(6L, 6L, 6L, 6L, 6L, 6L, 14L,
> 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
>
... truncated
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:23}}


From wdunlap at tibco.com  Tue Aug 30 21:25:46 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 30 Aug 2016 12:25:46 -0700
Subject: [R] 0 rows> (or 0-length row.names)
In-Reply-To: <CAB=p7SqLf=mSwZMn=ZemsJta+PkFwVHeXdVXNwXqTyGOBJiJhw@mail.gmail.com>
References: <CAB=p7SpPBEL5Yt3uL6Xq2BT8SJjjzY=9ZwPF9F_JSyZRqJ6fUw@mail.gmail.com>
	<CAF8bMcZCAtFmDbdiNwfTjobLVugdQ89a97Enymt+cry-A+mTzQ@mail.gmail.com>
	<CAB=p7Sqt8x3chPB1nEH4yyZmGVQ30j3W-y4RQ9XgH2TWuRO2Lw@mail.gmail.com>
	<81CB7399-239C-4ECA-848B-2EB169FE2328@TxBiomed.org>
	<CAB=p7SqLf=mSwZMn=ZemsJta+PkFwVHeXdVXNwXqTyGOBJiJhw@mail.gmail.com>
Message-ID: <CAF8bMcYX+R4D=D67=S0CGuRf5AEuzb02W5mxNipOo6bFf73xmg@mail.gmail.com>

You need to show what R expressions you ran before running into this
problem, including calls to library() or require().

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Aug 30, 2016 at 12:15 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:

> Hi Mark,
> What i understand, probably when i run the WOE & IV to check significant
> variables that is where i get this error. Thanks for your assistance Mark
> really appreciate i will look into some other measure on this.
>
> On Wed, Aug 31, 2016 at 12:35 AM, Mark Sharp <msharp at txbiomed.org> wrote:
>
>> Shivi,
>>
>> It is likely that William knows what you are trying to do because of his
>> considerable experience, but I am not able to figure it out from what you
>> have written. You have apparently sent the output from something like
>> dput(SFDC[1:50, ]), but I still do not know what you did to get the error.
>>
>> I successfully assigned the structure you sent to the name SFDC and
>> nothing seems amiss.
>>
>>
>> Mark
>>
>> R. Mark Sharp, Ph.D.
>> Director of Primate Records Database
>> Southwest National Primate Research Center
>> Texas Biomedical Research Institute
>> P.O. Box 760549
>> San Antonio, TX 78245-0549
>> Telephone: (210)258-9476
>> e-mail: msharp at TxBiomed.org
>>
>>
>>
>>
>>
>>
>>
>> > On Aug 30, 2016, at 12:32 PM, Shivi Bhatia <shivipmp82 at gmail.com>
>> wrote:
>> >
>> > Hi William/ Mark,
>> >
>> > I am using WOE & IV (weight of evidence) reduce the number of
>> independent
>> > vars.
>> > I have read this data as a csv file.
>> > reproducible example for your reference please:
>> >
>> > structure(list(date = structure(c(6L, 6L, 6L, 6L, 6L, 6L, 14L,
>> > 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
>> >
>> ... truncated
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
>> transmitted, may contain privileged and confidential information and is
>> intended solely for the exclusive use of the individual or entity to whom
>> it is addressed. If you are not the intended recipient, you are hereby
>> notified that any review, dissemination, distribution or copying of this
>> e-mail and/or attachments is strictly prohibited. If you have received this
>> e-mail in error, please immediately notify the sender stating that this
>> transmission was misdirected; return the e-mail to sender; destroy all
>> paper copies and delete all electronic copies from your system without
>> disclosing its contents.
>>
>
>

	[[alternative HTML version deleted]]


From leslie.rutkowski at gmail.com  Tue Aug 30 21:38:33 2016
From: leslie.rutkowski at gmail.com (Leslie Rutkowski)
Date: Tue, 30 Aug 2016 21:38:33 +0200
Subject: [R] loading .rda file
In-Reply-To: <BFB153CE-5AC6-434A-AB4C-51181B1EDE5B@dcn.davis.ca.us>
References: <CAA0F9kUoeMp5eJs5vaGBb5vgXBHjLLgFU2+b-FyO2knsQSztig@mail.gmail.com>
	<FF960259-852B-4764-B5EA-1DA4BDDA5836@dcn.davis.ca.us>
	<22469.48768.472833.853458@stat.math.ethz.ch>
	<BFB153CE-5AC6-434A-AB4C-51181B1EDE5B@dcn.davis.ca.us>
Message-ID: <CAA0F9kU=A5RVmA6XdJ1CNg7ikZQ9vQ=EGxkbE7VWaLxfnr33KA@mail.gmail.com>

Thanks, all, for your quick and comprehensive help with this - very much
appreciated in my R journey.

Leslie

On Tue, Aug 30, 2016 at 8:03 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Thanks for the perspective, Martin. I personally feel like attaching to
> the search path is more confusing than being explicit, because it appears
> indistinguishable from namespace pollution yet for modifying data it
> creates copies in the current environment (in-place editing requires `<<-`
> which requires keeping your search path in mind as you work to know when to
> use it).
> --
> Sent from my phone. Please excuse my brevity.
>
> On August 30, 2016 10:12:32 AM PDT, Martin Maechler <
> maechler at stat.math.ethz.ch> wrote:
> >>>>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> >>>>>>     on Tue, 30 Aug 2016 09:36:05 -0700 writes:
> >
> >> You cannot. However, you can load the file into a dedicated
> >environment to keep those names separated from your global environment.
> >e.g. [1]
> >
> >yes, that's my "famous"  only-allowed use of  attach() :
> >attach() an rda-file to your search patch instead of polluting
> >your globalenv.
> >
> >  > The saveRDS / loadRDS
> >
> >        saveRDS / readRDS   are the correct names
> >
> >> functions are an alternative handle one object at a time without
> >dragging the object names into the picture (you have to name the
> >re-loaded object).
> >
> >The fact that it is readRDS() and not loadRDS(),
> >actually does convey via it is often "much better" in the sense
> >of functional / transparent programming to use this pair in
> >favor of save() / load() :
> >readRDS() does *return* what we are interested in, and
> >
> >   result <- readRDS(<file>)
> >
> >is so much better than   load(<file>)   silently overwriting all
> >kinds of objects in my globalenv.
> >
> >Indeed, I strongly advocate to use  saveRDS() and readRDS()
> >much more frequently than they are used nowawadays.
> >
> >
> >
> >> However, the best approach is to write scripts that pull directly
> >from your source (non-R) data files. This makes your work process
> >reproducible as you develop it.
> >
> >Yes, but that's sometimes too inefficient.
> >
> >And then, some of us do simulations and other expensive
> >computations, we need/want to save and re-read.
> >
> >and yes,  I *always*  use the equivalent of   q("no")  to leave R;
> >never save the workspace or load it at startup, unless
> >accidentally on non-standard (for me) platforms.
> >
> >Martin
> >
> >    > [1] https://stat.ethz.ch/pipermail/r-help/2016-August/441078.html
> >    > --
> >    > Sent from my phone. Please excuse my brevity.
> >
> >> On August 30, 2016 7:37:24 AM PDT, Leslie Rutkowski
> ><leslie.rutkowski at gmail.com> wrote:
> >    >> Hi,
> >    >>
> >>> I'm slowly migrating from SAS to R and - for the very first time -
> >I'm
> >>> working with a native .Rda data file (rather than importing data
> >from
> >    >> other
> >>> sources). When I load this .Rda file into the global environment
> >using
> >>> load("file path") I see a data.frame in the global environment
> >called
> >    >> "mydata" that corresponds to the .rda file.
> >    >>
> >>> My question: how can I change the name of this data.frame to
> >something
> >    >> of
> >    >> my choosing?
> >    >>
> >    >> Thanks for considering this very simple question.
> >    >>
> >    >> Leslie
> >    >>
> >    >> [[alternative HTML version deleted]]
> >    >>
> >    >> ______________________________________________
> >   >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >    >> https://stat.ethz.ch/mailman/listinfo/r-help
> >    >> PLEASE do read the posting guide
> >    >> http://www.R-project.org/posting-guide.html
> >  >> and provide commented, minimal, self-contained, reproducible code.
> >
> >    > ______________________________________________
> >    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >    > https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >   > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From pmoniz7 at hotmail.com  Tue Aug 30 22:55:07 2016
From: pmoniz7 at hotmail.com (Paulo Moniz)
Date: Tue, 30 Aug 2016 20:55:07 +0000
Subject: [R] plot with different symbols and colors according to the
 factor levels
In-Reply-To: <alpine.LRH.2.20.1608301032350.18539@aeolus.ecy.wa.gov>
References: <CAHLnndbT6YQseS7oyQNtqJOQVw_sq+v9UTMJfkF354iSi=1u7g@mail.gmail.com>,
	<alpine.LRH.2.20.1608301032350.18539@aeolus.ecy.wa.gov>
Message-ID: <BY2PR16MB0197E73E71DABB12F078B726F7E00@BY2PR16MB0197.namprd16.prod.outlook.com>

Obter o Outlook para Android<https://aka.ms/ghei36>



On Tue, Aug 30, 2016 at 2:41 PM -0300, "Clint Bowman" <clint at ecy.wa.gov<mailto:clint at ecy.wa.gov>> wrote:

Hanna,

lili<-read.table("lili.txt",header=T)  # don't forget to label the row
number if it's in your data

with(lili,plot(y,conc,pch=sample,col=sample))

Clint


Clint Bowman                    INTERNET:       clint at ecy.wa.gov
Air Quality Modeler             INTERNET:       clint at math.utah.edu
Department of Ecology           VOICE:          (360) 407-6815
PO Box 47600                    FAX:            (360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Tue, 30 Aug 2016, li li wrote:

> Hi all,
> I have the following data. I want to plot the data (y ~ conc)
> with different symbols and colors corresponding to different levels of the
> factor sample.
> I could create a column with color and pch and then do the plot, but I am
> sure there are much better ways.
> Can anyone make suggestions?
>  Hanna
>
>
>
>   y         conc sample
> 1  33 20.000000000      1
> 2  33  5.000000000      1
> 3  35  1.250000000      1
> 4  43  0.312500000      1
> 5  58  0.078125000      1
> 6  54  0.019531250      1
> 7  57  0.004882812      1
> 8  57  0.001220703      1
> 9  32 20.000000000      1
> 10 32  5.000000000      1
> 11 34  1.250000000      1
> 12 52  0.312500000      1
> 13 57  0.078125000      1
> 14 58  0.019531250      1
> 15 59  0.004882812      1
> 16 50  0.001220703      1
> 17 34 20.000000000      2
> 18 34  5.000000000      2
> 19 38  1.250000000      2
> 20 53  0.312500000      2
> 21 57  0.078125000      2
> 22 57  0.019531250      2
> 23 57  0.004882812      2
> 24 52  0.001220703      2
> 25 34 20.000000000      2
> 26 33  5.000000000      2
> 27 36  1.250000000      2
> 28 48  0.312500000      2
> 29 58  0.078125000      2
> 30 57  0.019531250      2
> 31 58  0.004882812      2
> 32 53  0.001220703      2
> 33 34 20.000000000      2
> 34 35  5.000000000      2
> 35 37  1.250000000      2
> 36 49  0.312500000      2
> 37 55  0.078125000      2
> 38 59  0.019531250      2
> 39 57  0.004882812      2
> 40 54  0.001220703      2
> 41 36 20.000000000      3
> 42 33  5.000000000      3
> 43 36  1.250000000      3
> 44 51  0.312500000      3
> 45 57  0.078125000      3
> 46 57  0.019531250      3
> 47 59  0.004882812      3
> 48 56  0.001220703      3
> 49 33 20.000000000      3
> 50 32  5.000000000      3
> 51 35  1.250000000      3
> 52 47  0.312500000      3
> 53 57  0.078125000      3
> 54 56  0.019531250      3
> 55 57  0.004882812      3
> 56 53  0.001220703      3
> 57 33 20.000000000      3
> 58 34  5.000000000      3
> 59 38  1.250000000      3
> 60 52  0.312500000      3
> 61 56  0.078125000      3
> 62 61  0.019531250      3
> 63 56  0.004882812      3
> 64 55  0.001220703      3
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jfhenson1 at gmail.com  Tue Aug 30 23:07:39 2016
From: jfhenson1 at gmail.com (James Henson)
Date: Tue, 30 Aug 2016 16:07:39 -0500
Subject: [R] yuen function of the WRS2 package
Message-ID: <CABPq8JOp7tF3zBSTSbNAXJSXqzaOaOsioi+xPmvjwKjvdhFkWw@mail.gmail.com>

Greetings R community,
Here is a small but perplexing problem with the ?yuen? function in the
?WRS2? package.
I begin with the ?eurosoccer? data frame from the ?WRS2? package.
Then make a subset that contains only two Leagues Spain and Germany
(subset data frame is ?SpainGer?).   The ?yuen? function cannot read
the data in subset data frame ?SpainGer?.  My code is below.
Thanks you for your help.
James F. Henson


# Examples from 'Robust Statistical Methods on R Using the WRS2 Package?
# Robust t-test, and ANOVA (pages5-13)
library(WRS2)
data("eurosoccer")
class(eurosoccer)
print(eurosoccer)
library("digest")
library("DT")
datatable(eurosoccer)
str(eurosoccer)
# make a subset with only Spain and Germany
SpainGer <- subset (eurosoccer, subset = League =="Spain" | League == "Germany")
print(SpainGer)
class(SpainGer)
str(SpainGer)
# The 'yuen' function can not read the data in the subset data.frame "SpainGer"
yuen(GoalsGame ~ League, tr=0.2, data = SpainGer)
# the 'yuen' function works on the orginioal data.frame
yuen(GoalsGame ~ League, tr=0.2, data = eurosoccer)
# the 'aov' function reads the data in the subset data.frame "SpainGer"
Goals.fit <- aov(GoalsGame ~ League, data = SpainGer)
summary(Goals.fit)


From bgunter.4567 at gmail.com  Wed Aug 31 00:06:25 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 30 Aug 2016 15:06:25 -0700
Subject: [R] yuen function of the WRS2 package
In-Reply-To: <CABPq8JOp7tF3zBSTSbNAXJSXqzaOaOsioi+xPmvjwKjvdhFkWw@mail.gmail.com>
References: <CABPq8JOp7tF3zBSTSbNAXJSXqzaOaOsioi+xPmvjwKjvdhFkWw@mail.gmail.com>
Message-ID: <CAGxFJbSiC=EEtc8OfjrJWu5+1u=DQvqGiAPVH3ZmQaq+ag64Xw@mail.gmail.com>

James:

To be clear, I know nothing about this package, but the following may
be helpful for those who do:

1. What exacty was the error message that you received? Or was it a
warning? "cannot read" may be too vague to allow others to respond.

2. ?maintainer to find the package maintainer. It may be necessary to
contact them directly with the problem.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 30, 2016 at 2:07 PM, James Henson <jfhenson1 at gmail.com> wrote:
> Greetings R community,
> Here is a small but perplexing problem with the ?yuen? function in the
> ?WRS2? package.
> I begin with the ?eurosoccer? data frame from the ?WRS2? package.
> Then make a subset that contains only two Leagues Spain and Germany
> (subset data frame is ?SpainGer?).   The ?yuen? function cannot read
> the data in subset data frame ?SpainGer?.  My code is below.
> Thanks you for your help.
> James F. Henson
>
>
> # Examples from 'Robust Statistical Methods on R Using the WRS2 Package?
> # Robust t-test, and ANOVA (pages5-13)
> library(WRS2)
> data("eurosoccer")
> class(eurosoccer)
> print(eurosoccer)
> library("digest")
> library("DT")
> datatable(eurosoccer)
> str(eurosoccer)
> # make a subset with only Spain and Germany
> SpainGer <- subset (eurosoccer, subset = League =="Spain" | League == "Germany")
> print(SpainGer)
> class(SpainGer)
> str(SpainGer)
> # The 'yuen' function can not read the data in the subset data.frame "SpainGer"
> yuen(GoalsGame ~ League, tr=0.2, data = SpainGer)
> # the 'yuen' function works on the orginioal data.frame
> yuen(GoalsGame ~ League, tr=0.2, data = eurosoccer)
> # the 'aov' function reads the data in the subset data.frame "SpainGer"
> Goals.fit <- aov(GoalsGame ~ League, data = SpainGer)
> summary(Goals.fit)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Aug 31 00:34:51 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 30 Aug 2016 15:34:51 -0700
Subject: [R] yuen function of the WRS2 package
In-Reply-To: <CABPq8JOp7tF3zBSTSbNAXJSXqzaOaOsioi+xPmvjwKjvdhFkWw@mail.gmail.com>
References: <CABPq8JOp7tF3zBSTSbNAXJSXqzaOaOsioi+xPmvjwKjvdhFkWw@mail.gmail.com>
Message-ID: <CAF8bMcZyuT9umjNXDAYP-JR+NUKyAa0DdSLq7zT-dnFS7459hA@mail.gmail.com>

yuen does not work when there unused levels in the factors given to it.

>  yuen(GoalsGame ~ League, tr=0.2, data = SpainGer)
Call:
yuen(formula = GoalsGame ~ League, data = SpainGer, tr = 0.2)

Test statistic: NaN (df = NA), p-value = NA

Trimmed mean difference:  NaN
95 percent confidence interval:
NaN     NaN

>  yuen(GoalsGame ~ League, tr=0.2, data = droplevels(SpainGer))
Call:
yuen(formula = GoalsGame ~ League, data = droplevels(SpainGer),
    tr = 0.2)

Test statistic: 0.8394 (df = 16.17), p-value = 0.4135

Trimmed mean difference:  -0.11494
95 percent confidence interval:
-0.405     0.1751

Complain to WSR2's maintainer.
> maintainer("WRS2")
[1] "Patrick Mair <mair at fas.harvard.edu>"



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Aug 30, 2016 at 2:07 PM, James Henson <jfhenson1 at gmail.com> wrote:

> Greetings R community,
> Here is a small but perplexing problem with the ?yuen? function in the
> ?WRS2? package.
> I begin with the ?eurosoccer? data frame from the ?WRS2? package.
> Then make a subset that contains only two Leagues Spain and Germany
> (subset data frame is ?SpainGer?).   The ?yuen? function cannot read
> the data in subset data frame ?SpainGer?.  My code is below.
> Thanks you for your help.
> James F. Henson
>
>
> # Examples from 'Robust Statistical Methods on R Using the WRS2 Package?
> # Robust t-test, and ANOVA (pages5-13)
> library(WRS2)
> data("eurosoccer")
> class(eurosoccer)
> print(eurosoccer)
> library("digest")
> library("DT")
> datatable(eurosoccer)
> str(eurosoccer)
> # make a subset with only Spain and Germany
> SpainGer <- subset (eurosoccer, subset = League =="Spain" | League ==
> "Germany")
> print(SpainGer)
> class(SpainGer)
> str(SpainGer)
> # The 'yuen' function can not read the data in the subset data.frame
> "SpainGer"
> yuen(GoalsGame ~ League, tr=0.2, data = SpainGer)
> # the 'yuen' function works on the orginioal data.frame
> yuen(GoalsGame ~ League, tr=0.2, data = eurosoccer)
> # the 'aov' function reads the data in the subset data.frame "SpainGer"
> Goals.fit <- aov(GoalsGame ~ League, data = SpainGer)
> summary(Goals.fit)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jfca283 at gmail.com  Tue Aug 30 23:24:31 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Tue, 30 Aug 2016 18:24:31 -0300
Subject: [R] Loop over rda list files and using the attach function
In-Reply-To: <20160830194224.Horde.ZIl7YbovKZCpCjdiP-BRhFN@mail.sapo.pt>
References: <CALBYkjJLY0Rqve9+CeSfXYkRrUVvAcCt4URBvtLcOMZefKU62Q@mail.gmail.com>
	<20160830194224.Horde.ZIl7YbovKZCpCjdiP-BRhFN@mail.sapo.pt>
Message-ID: <CALBYkjJnWXPt_xzeMH79+gCsyaKCCmW-wGCDnRCFS7=3EQ55gQ@mail.gmail.com>

The attach(get(yyz)) option i tried and it worked. The only issue, is that
when i'm  trying to export the results, it takes a lot of time.
Considerably more than Stata. Also, the computer almost collapses for a
task which isn't so exhausting for my PC station.
Im dubious...

On Tue, Aug 30, 2016 at 3:42 PM, <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Try
>
> attach(get(yyz))
>
> Hope this helps,
>
> Rui Barradas
>
>
>
>
>
>
>
> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>
> Hi.
>> I need to loop over rda files.
>> I generated the list of them.
>> That's ok. The problem is that the name of the files are as yyyy_mm (eg
>> 2010_01 is january or 2010, 2016_03 is march of 2016).
>> So, when i try to use the attach function to create a simple table(age,
>> sex) it fails.
>> The only way to attach a file as is using
>> attach(`2016_03`)
>> The text above i have no idea how to declare it in my code below
>>
>>
>> dd=list.files("C:/Users/Me/r", pattern="rda$", full.names=F)
>> for (i in 1:length(dd)) {
>> yyz=load(dd[i])
>> attach(yyz)
>> table(age, sex)
>> rm(list=yyz)
>>
>> }
>> This is the error it declares the loop:
>> Error in attach(yyz) : file '2013_02' not found
>>
>>
>> Thanks for your help and time
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>

	[[alternative HTML version deleted]]


From shivipmp82 at gmail.com  Wed Aug 31 12:37:23 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Wed, 31 Aug 2016 16:07:23 +0530
Subject: [R] 0 rows> (or 0-length row.names)
In-Reply-To: <2B01B670-CE6F-45DC-9D09-22D6AEDF938D@TxBiomed.org>
References: <CAB=p7SpPBEL5Yt3uL6Xq2BT8SJjjzY=9ZwPF9F_JSyZRqJ6fUw@mail.gmail.com>
	<CAF8bMcZCAtFmDbdiNwfTjobLVugdQ89a97Enymt+cry-A+mTzQ@mail.gmail.com>
	<CAB=p7Sqt8x3chPB1nEH4yyZmGVQ30j3W-y4RQ9XgH2TWuRO2Lw@mail.gmail.com>
	<81CB7399-239C-4ECA-848B-2EB169FE2328@TxBiomed.org>
	<CAB=p7SqLf=mSwZMn=ZemsJta+PkFwVHeXdVXNwXqTyGOBJiJhw@mail.gmail.com>
	<2B01B670-CE6F-45DC-9D09-22D6AEDF938D@TxBiomed.org>
Message-ID: <CAB=p7Sr-OhhF3Qjo4D8dhJsMeNuS9f2PuL1WKdt9_kaF0HA4KQ@mail.gmail.com>

These are the packages i am using:
library(woe)  #WEIGHT OF EVIDENCE
library(InformationValue)  #INFORMATION VALUE

The syntax used is :
WOE(X=SFDC1$log_caseage, Y=SFDC1$survey)
WOETable(X=SFDC1$case_age, Y=SFDC1$survey)
IV(X=SFDC1$case_age, Y=SFDC1$survey)

On Wed, Aug 31, 2016 at 12:54 AM, Mark Sharp <msharp at txbiomed.org> wrote:

> Shivi,
>
> What package(s) are you using. What functions are you using. How are you
> calling the functions. A reproducible sample has all of the actual code
> needed to create a representative error. There are multiple packages you
> could be using to look at weight of evidence and information value. For
> example, there is a WOE function in the Information package and a woe
> function in the woe package.
>
> Mark
>
> On Aug 30, 2016, at 2:15 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
>
> Hi Mark,
> What i understand, probably when i run the WOE & IV to check significant
> variables that is where i get this error. Thanks for your assistance Mark
> really appreciate i will look into some other measure on this.
>
> On Wed, Aug 31, 2016 at 12:35 AM, Mark Sharp <msharp at txbiomed.org> wrote:
>
>> Shivi,
>>
>> It is likely that William knows what you are trying to do because of his
>> considerable experience, but I am not able to figure it out from what you
>> have written. You have apparently sent the output from something like
>> dput(SFDC[1:50, ]), but I still do not know what you did to get the error.
>>
>> I successfully assigned the structure you sent to the name SFDC and
>> nothing seems amiss.
>>
>>
>> Mark
>>
>> R. Mark Sharp, Ph.D.
>> Director of Primate Records Database
>> Southwest National Primate Research Center
>> Texas Biomedical Research Institute
>> P.O. Box 760549
>> San Antonio, TX 78245-0549
>> Telephone: (210)258-9476
>> e-mail: msharp at TxBiomed.org <msharp at txbiomed.org>
>>
>>
>>
>>
>>
>>
>>
>> > On Aug 30, 2016, at 12:32 PM, Shivi Bhatia <shivipmp82 at gmail.com>
>> wrote:
>> >
>> > Hi William/ Mark,
>> >
>> > I am using WOE & IV (weight of evidence) reduce the number of
>> independent
>> > vars.
>> > I have read this data as a csv file.
>> > reproducible example for your reference please:
>> >
>> > structure(list(date = structure(c(6L, 6L, 6L, 6L, 6L, 6L, 14L,
>> > 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
>> >
>> ... truncated
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.
>> org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
>> transmitted, may contain privileged and confidential information and is
>> intended solely for the exclusive use of the individual or entity to whom
>> it is addressed. If you are not the intended recipient, you are hereby
>> notified that any review, dissemination, distribution or copying of this
>> e-mail and/or attachments is strictly prohibited. If you have received this
>> e-mail in error, please immediately notify the sender stating that this
>> transmission was misdirected; return the e-mail to sender; destroy all
>> paper copies and delete all electronic copies from your system without
>> disclosing its contents.
>>
>
> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
> transmitted, may contain privileged and confidential information and is
> intended solely for the exclusive use of the individual or entity to whom
> it is addressed. If you are not the intended recipient, you are hereby
> notified that any review, dissemination, distribution or copying of this
> e-mail and/or attachments is strictly prohibited. If you have received this
> e-mail in error, please immediately notify the sender stating that this
> transmission was misdirected; return the e-mail to sender; destroy all
> paper copies and delete all electronic copies from your system without
> disclosing its contents.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Aug 31 13:41:52 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 31 Aug 2016 11:41:52 +0000
Subject: [R] plot.drm in "drc" package
In-Reply-To: <CAHLnndYX_6JS4k3kBC-M+dqN_qkDH1-k3wJUmggqVR3Huf3+YQ@mail.gmail.com>
References: <CAHLnndYX_6JS4k3kBC-M+dqN_qkDH1-k3wJUmggqVR3Huf3+YQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503AD93@SRVEXCHMBX.precheza.cz>

Hi

Thanks for code.
see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of li li
> Sent: Tuesday, August 30, 2016 5:07 PM
> To: r-help <r-help at r-project.org>
> Subject: [R] plot.drm in "drc" package
>
> Hi all,
>   I am trying to use the drc package to fit 4L curve.
> I am so confused about the plot.drm function in the drc package.
> Particularly, I am confused about the scale of the xaxis in the plots generated
> using the plot.drm function. See the example below:
>
> ## generate data and fit the model
> dose <- rep(50*2^(-(0:11)),3)
> dose
> d <- 100
> c <- 1
> b <- 1
> e <- 1.6
> y <- rnorm(length(dose))+ c+ (d-c)/(1+exp(b*(log(dose)-log(e))))
> library(drc)
> mod <- drm(y~dose, fct = LL.4())
> summary(mod)
>
> Now I plot the data and the fitted curve with the plot.drm using the code
> below and get the figure 1 below.
>
>
> ##obtaining figure 1
> plot(mod, type="all",log="x")
>
>
> Next I plot the raw data and add the curve by extracting the estimate of the
> parameters.
>
> ##extract parameters
> para <- mod$fit$par
> bhat<- para[1]
> chat <- para[2]
> dhat <- para[3]
> ehat <- para[4]
>
> ##plot figure 2
> plot(log(dose),y)
> points(log(50*2^(-(0:11))),  chat +
> (dhat-chat)/(1+exp(bhat*(log(50*2^(-(0:11)))-log(ehat)))), type="l")
>
> My question is regarding the figure 1 generated by the plot.drm.
> The x axis is the not the log scale of the doses. I checked the package manual,
                                             ^^^^^^^^^^^
Well I am either missing something obvios but when I tried

plot(mod, type="all",log="x")

I got x axis with log scaling. Actually the result is the same as

plot(mod, type="all")

If you want x axis to be in original range you need to put empty string

plot(mod, type="all",log="")

Cheers
Petr

> it says the default is log base 10. But it is not true in this case.
> Does some have some insight on the correct usage of the plot.drm function.
>
> Thanks much in advance.
>   Hanna
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jfhenson1 at gmail.com  Wed Aug 31 16:16:45 2016
From: jfhenson1 at gmail.com (James Henson)
Date: Wed, 31 Aug 2016 09:16:45 -0500
Subject: [R] yuen function of the WRS2 package
In-Reply-To: <CAF8bMcZyuT9umjNXDAYP-JR+NUKyAa0DdSLq7zT-dnFS7459hA@mail.gmail.com>
References: <CABPq8JOp7tF3zBSTSbNAXJSXqzaOaOsioi+xPmvjwKjvdhFkWw@mail.gmail.com>
	<CAF8bMcZyuT9umjNXDAYP-JR+NUKyAa0DdSLq7zT-dnFS7459hA@mail.gmail.com>
Message-ID: <CABPq8JPT9yUbzQ403d=KP1gaKrajcBP=d6ALarnvzf2NtGGSTg@mail.gmail.com>

Thanks,
The 'droplevels' statement works.
Best regards,
James Henson

On Tue, Aug 30, 2016 at 5:34 PM, William Dunlap <wdunlap at tibco.com> wrote:
> yuen does not work when there unused levels in the factors given to it.
>
>>  yuen(GoalsGame ~ League, tr=0.2, data = SpainGer)
> Call:
> yuen(formula = GoalsGame ~ League, data = SpainGer, tr = 0.2)
>
> Test statistic: NaN (df = NA), p-value = NA
>
> Trimmed mean difference:  NaN
> 95 percent confidence interval:
> NaN     NaN
>
>>  yuen(GoalsGame ~ League, tr=0.2, data = droplevels(SpainGer))
> Call:
> yuen(formula = GoalsGame ~ League, data = droplevels(SpainGer),
>     tr = 0.2)
>
> Test statistic: 0.8394 (df = 16.17), p-value = 0.4135
>
> Trimmed mean difference:  -0.11494
> 95 percent confidence interval:
> -0.405     0.1751
>
> Complain to WSR2's maintainer.
>> maintainer("WRS2")
> [1] "Patrick Mair <mair at fas.harvard.edu>"
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Aug 30, 2016 at 2:07 PM, James Henson <jfhenson1 at gmail.com> wrote:
>>
>> Greetings R community,
>> Here is a small but perplexing problem with the ?yuen? function in the
>> ?WRS2? package.
>> I begin with the ?eurosoccer? data frame from the ?WRS2? package.
>> Then make a subset that contains only two Leagues Spain and Germany
>> (subset data frame is ?SpainGer?).   The ?yuen? function cannot read
>> the data in subset data frame ?SpainGer?.  My code is below.
>> Thanks you for your help.
>> James F. Henson
>>
>>
>> # Examples from 'Robust Statistical Methods on R Using the WRS2 Package?
>> # Robust t-test, and ANOVA (pages5-13)
>> library(WRS2)
>> data("eurosoccer")
>> class(eurosoccer)
>> print(eurosoccer)
>> library("digest")
>> library("DT")
>> datatable(eurosoccer)
>> str(eurosoccer)
>> # make a subset with only Spain and Germany
>> SpainGer <- subset (eurosoccer, subset = League =="Spain" | League ==
>> "Germany")
>> print(SpainGer)
>> class(SpainGer)
>> str(SpainGer)
>> # The 'yuen' function can not read the data in the subset data.frame
>> "SpainGer"
>> yuen(GoalsGame ~ League, tr=0.2, data = SpainGer)
>> # the 'yuen' function works on the orginioal data.frame
>> yuen(GoalsGame ~ League, tr=0.2, data = eurosoccer)
>> # the 'aov' function reads the data in the subset data.frame "SpainGer"
>> Goals.fit <- aov(GoalsGame ~ League, data = SpainGer)
>> summary(Goals.fit)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From wdunlap at tibco.com  Wed Aug 31 16:50:16 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 31 Aug 2016 07:50:16 -0700
Subject: [R] 0 rows> (or 0-length row.names)
In-Reply-To: <CAB=p7Sr-OhhF3Qjo4D8dhJsMeNuS9f2PuL1WKdt9_kaF0HA4KQ@mail.gmail.com>
References: <CAB=p7SpPBEL5Yt3uL6Xq2BT8SJjjzY=9ZwPF9F_JSyZRqJ6fUw@mail.gmail.com>
	<CAF8bMcZCAtFmDbdiNwfTjobLVugdQ89a97Enymt+cry-A+mTzQ@mail.gmail.com>
	<CAB=p7Sqt8x3chPB1nEH4yyZmGVQ30j3W-y4RQ9XgH2TWuRO2Lw@mail.gmail.com>
	<81CB7399-239C-4ECA-848B-2EB169FE2328@TxBiomed.org>
	<CAB=p7SqLf=mSwZMn=ZemsJta+PkFwVHeXdVXNwXqTyGOBJiJhw@mail.gmail.com>
	<2B01B670-CE6F-45DC-9D09-22D6AEDF938D@TxBiomed.org>
	<CAB=p7Sr-OhhF3Qjo4D8dhJsMeNuS9f2PuL1WKdt9_kaF0HA4KQ@mail.gmail.com>
Message-ID: <CAF8bMcZZ43hiS2Ho2=++uUJALSLdPmdsA0q74f3E=iaCA++s7w@mail.gmail.com>

I see the printout (not an "error") that you describe on the 2nd example
you gave:

> t2 <- WOETable(X=SFDC1$case_age, Y=SFDC1$survey)
> print(t2)
[1] GOODS BADS  TOTAL PCT_G PCT_B WOE   IV
<0 rows> (or 0-length row.names)

The result of WOETable is perfectly legal - it is a data.frame with no rows.

help(WOETable) says that the 'X' argument should be a "categorical variable
stored as factor" but the function does not check that that is true.  You
gave it a numeric (continuous) variable, case_age, and it misbehaved.  You
can turn case_age into a factor with the cut() function.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Aug 31, 2016 at 3:37 AM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:

> These are the packages i am using:
> library(woe)  #WEIGHT OF EVIDENCE
> library(InformationValue)  #INFORMATION VALUE
>
> The syntax used is :
> WOE(X=SFDC1$log_caseage, Y=SFDC1$survey)
> WOETable(X=SFDC1$case_age, Y=SFDC1$survey)
> IV(X=SFDC1$case_age, Y=SFDC1$survey)
>
> On Wed, Aug 31, 2016 at 12:54 AM, Mark Sharp <msharp at txbiomed.org> wrote:
>
>> Shivi,
>>
>> What package(s) are you using. What functions are you using. How are you
>> calling the functions. A reproducible sample has all of the actual code
>> needed to create a representative error. There are multiple packages you
>> could be using to look at weight of evidence and information value. For
>> example, there is a WOE function in the Information package and a woe
>> function in the woe package.
>>
>> Mark
>>
>> On Aug 30, 2016, at 2:15 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
>>
>> Hi Mark,
>> What i understand, probably when i run the WOE & IV to check significant
>> variables that is where i get this error. Thanks for your assistance Mark
>> really appreciate i will look into some other measure on this.
>>
>> On Wed, Aug 31, 2016 at 12:35 AM, Mark Sharp <msharp at txbiomed.org> wrote:
>>
>>> Shivi,
>>>
>>> It is likely that William knows what you are trying to do because of his
>>> considerable experience, but I am not able to figure it out from what you
>>> have written. You have apparently sent the output from something like
>>> dput(SFDC[1:50, ]), but I still do not know what you did to get the error.
>>>
>>> I successfully assigned the structure you sent to the name SFDC and
>>> nothing seems amiss.
>>>
>>>
>>> Mark
>>>
>>> R. Mark Sharp, Ph.D.
>>> Director of Primate Records Database
>>> Southwest National Primate Research Center
>>> Texas Biomedical Research Institute
>>> P.O. Box 760549
>>> San Antonio, TX 78245-0549
>>> Telephone: (210)258-9476
>>> e-mail: msharp at TxBiomed.org <msharp at txbiomed.org>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> > On Aug 30, 2016, at 12:32 PM, Shivi Bhatia <shivipmp82 at gmail.com>
>>> wrote:
>>> >
>>> > Hi William/ Mark,
>>> >
>>> > I am using WOE & IV (weight of evidence) reduce the number of
>>> independent
>>> > vars.
>>> > I have read this data as a csv file.
>>> > reproducible example for your reference please:
>>> >
>>> > structure(list(date = structure(c(6L, 6L, 6L, 6L, 6L, 6L, 14L,
>>> > 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
>>> >
>>> ... truncated
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org
>>> /posting-guide.html <http://www.r-project.org/posting-guide.html>
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
>>> transmitted, may contain privileged and confidential information and is
>>> intended solely for the exclusive use of the individual or entity to whom
>>> it is addressed. If you are not the intended recipient, you are hereby
>>> notified that any review, dissemination, distribution or copying of this
>>> e-mail and/or attachments is strictly prohibited. If you have received this
>>> e-mail in error, please immediately notify the sender stating that this
>>> transmission was misdirected; return the e-mail to sender; destroy all
>>> paper copies and delete all electronic copies from your system without
>>> disclosing its contents.
>>>
>>
>> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
>> transmitted, may contain privileged and confidential information and is
>> intended solely for the exclusive use of the individual or entity to whom
>> it is addressed. If you are not the intended recipient, you are hereby
>> notified that any review, dissemination, distribution or copying of this
>> e-mail and/or attachments is strictly prohibited. If you have received this
>> e-mail in error, please immediately notify the sender stating that this
>> transmission was misdirected; return the e-mail to sender; destroy all
>> paper copies and delete all electronic copies from your system without
>> disclosing its contents.
>>
>
>

	[[alternative HTML version deleted]]


From dougedmunds at gmail.com  Wed Aug 31 17:05:39 2016
From: dougedmunds at gmail.com (Doug Edmunds)
Date: Wed, 31 Aug 2016 08:05:39 -0700
Subject: [R] source() does not include added code
Message-ID: <2d5ce5c3-5c16-1f56-fe85-62868614030e@gmail.com>

I am trying to understand why "source" does not process
all the code in this R file.

1. I copied maCross.R from the quantstrat/demo directory
into my project area.

QuantStrat is available at
   https://r-forge.r-project.org/R/?group_id=316
install.packages("quantstrat", repos="http://R-Forge.R-project.org")

2. I added this line at the end of the R file:

     t(tradeStats("macross")

3. When I enter:
      source('maCross.R')

at the prompt, it fails to process the added line of code.

Why not?

--DAE


From murdoch.duncan at gmail.com  Wed Aug 31 17:11:27 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 31 Aug 2016 11:11:27 -0400
Subject: [R] source() does not include added code
In-Reply-To: <2d5ce5c3-5c16-1f56-fe85-62868614030e@gmail.com>
References: <2d5ce5c3-5c16-1f56-fe85-62868614030e@gmail.com>
Message-ID: <9f3fccde-da31-881f-b6bf-1987d14dff9b@gmail.com>

On 31/08/2016 11:05 AM, Doug Edmunds wrote:
> I am trying to understand why "source" does not process
> all the code in this R file.
>
> 1. I copied maCross.R from the quantstrat/demo directory
> into my project area.
>
> QuantStrat is available at
>    https://r-forge.r-project.org/R/?group_id=316
> install.packages("quantstrat", repos="http://R-Forge.R-project.org")
>
> 2. I added this line at the end of the R file:
>
>      t(tradeStats("macross")
>
> 3. When I enter:
>       source('maCross.R')
>
> at the prompt, it fails to process the added line of code.
>
> Why not?

You're missing a closing parenthesis.  I'd have hoped for an error 
message about that, and I get one with a similar example. Not sure why 
you didn't.

 > source('test.R')
Error in source("test.R") : test.R:4:0: unexpected end of input
2: message("bad"
3:

Duncan Murdoch


From dwinsemius at comcast.net  Wed Aug 31 17:11:01 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 31 Aug 2016 08:11:01 -0700
Subject: [R] source() does not include added code
In-Reply-To: <2d5ce5c3-5c16-1f56-fe85-62868614030e@gmail.com>
References: <2d5ce5c3-5c16-1f56-fe85-62868614030e@gmail.com>
Message-ID: <6375F757-9E2A-48A2-B4FB-C2E60B207324@comcast.net>


> On Aug 31, 2016, at 8:05 AM, Doug Edmunds <dougedmunds at gmail.com> wrote:
> 
> I am trying to understand why "source" does not process
> all the code in this R file.
> 
> 1. I copied maCross.R from the quantstrat/demo directory
> into my project area.
> 
> QuantStrat is available at
>  https://r-forge.r-project.org/R/?group_id=316
> install.packages("quantstrat", repos="http://R-Forge.R-project.org")
> 
> 2. I added this line at the end of the R file:
> 
>    t(tradeStats("macross")
> 
> 3. When I enter:
>     source('maCross.R')
> 
> at the prompt, it fails to process the added line of code.

Have you read the help page? On my machine the default for verbose appears to be 

getOption("verbose")
[1] FALSE

> 
> Why not?
> 
> --DAE
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From sarah.goslee at gmail.com  Wed Aug 31 17:15:29 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 31 Aug 2016 11:15:29 -0400
Subject: [R] source() does not include added code
In-Reply-To: <9f3fccde-da31-881f-b6bf-1987d14dff9b@gmail.com>
References: <2d5ce5c3-5c16-1f56-fe85-62868614030e@gmail.com>
	<9f3fccde-da31-881f-b6bf-1987d14dff9b@gmail.com>
Message-ID: <CAM_vjumtGAx=faZX4XkfZzQEy32=9CCkc=gWbA8aU04AOr5XLg@mail.gmail.com>

If it doesn't do ANYTHING, you may have failed to save the file.

Unless that file contains a function, in which case it isn't supposed
to do anything except load the function into your global environment.
But it should have thrown an error in that case, as Duncan said.

On Wed, Aug 31, 2016 at 11:11 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 31/08/2016 11:05 AM, Doug Edmunds wrote:
>>
>> I am trying to understand why "source" does not process
>> all the code in this R file.
>>
>> 1. I copied maCross.R from the quantstrat/demo directory
>> into my project area.
>>
>> QuantStrat is available at
>>    https://r-forge.r-project.org/R/?group_id=316
>> install.packages("quantstrat", repos="http://R-Forge.R-project.org")
>>
>> 2. I added this line at the end of the R file:
>>
>>      t(tradeStats("macross")
>>
>> 3. When I enter:
>>       source('maCross.R')
>>
>> at the prompt, it fails to process the added line of code.
>>
>> Why not?
>
>
> You're missing a closing parenthesis.  I'd have hoped for an error message
> about that, and I get one with a similar example. Not sure why you didn't.
>
>> source('test.R')
> Error in source("test.R") : test.R:4:0: unexpected end of input
> 2: message("bad"
> 3:
>
> Duncan Murdoch
>
>


From josh.m.ulrich at gmail.com  Wed Aug 31 17:10:58 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 31 Aug 2016 10:10:58 -0500
Subject: [R] source() does not include added code
In-Reply-To: <2d5ce5c3-5c16-1f56-fe85-62868614030e@gmail.com>
References: <2d5ce5c3-5c16-1f56-fe85-62868614030e@gmail.com>
Message-ID: <CAPPM_gQX5KB7Z+FF9kA-ckewt4v+-xw1E7mxxVZ3aVGG6qK1Gg@mail.gmail.com>

On Wed, Aug 31, 2016 at 10:05 AM, Doug Edmunds <dougedmunds at gmail.com> wrote:
> I am trying to understand why "source" does not process
> all the code in this R file.
>
> 1. I copied maCross.R from the quantstrat/demo directory
> into my project area.
>
> QuantStrat is available at
>   https://r-forge.r-project.org/R/?group_id=316
> install.packages("quantstrat", repos="http://R-Forge.R-project.org")
>
> 2. I added this line at the end of the R file:
>
>     t(tradeStats("macross")
>
> 3. When I enter:
>      source('maCross.R')
>
> at the prompt, it fails to process the added line of code.
>
> Why not?
>
My guess is that you forgot to save the file after you made your
change.  That never happens to me. :P

> --DAE
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From dougedmunds at gmail.com  Wed Aug 31 17:26:29 2016
From: dougedmunds at gmail.com (Doug Edmunds)
Date: Wed, 31 Aug 2016 08:26:29 -0700
Subject: [R] source() does not include added code
Message-ID: <ce4bc223-12d1-2618-aa43-cd12c11396eb@gmail.com>

1.  File is (was) saved.
2.  The added code is
  t(tradeStats("macross"))
with 2 )'s.

I'd appreciate if someone with QuantStrat installed, to try this
and see if they get a different result.  My R and RStudio and
QuantStrat libraries are all current.


I get the chart and this much output.

 > source('~/CodingData/RCode/Quantstrat1/maCross.R')
[1] "2001-06-27 00:00:00 AAPL 100 @ 1.526312"
[1] "2001-09-07 00:00:00 AAPL -100 @ 1.13002"
[1] "2002-01-07 00:00:00 AAPL 100 @ 1.497538"
[1] "2002-07-10 00:00:00 AAPL -100 @ 1.132636"
[1] "2003-05-16 00:00:00 AAPL 100 @ 1.22942"
[1] "2006-06-22 00:00:00 AAPL -100 @ 7.792429"
[1] "2006-09-26 00:00:00 AAPL 100 @ 10.150561"
[1] "2008-03-07 00:00:00 AAPL -100 @ 15.988996"
[1] "2008-05-19 00:00:00 AAPL 100 @ 24.012922"
[1] "2008-09-24 00:00:00 AAPL -100 @ 16.833895"
[1] "2009-05-14 00:00:00 AAPL 100 @ 16.080549"
[1] "2012-12-11 00:00:00 AAPL -100 @ 71.436852"
[1] "2013-09-11 00:00:00 AAPL 100 @ 62.897826"
[1] "2015-08-31 00:00:00 AAPL -100 @ 110.399553"
Time difference of 0.3014359 secs
[1] "trade blotter portfolio update:"
Time difference of 0.1732061 secs
 >


From josh.m.ulrich at gmail.com  Wed Aug 31 17:35:01 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 31 Aug 2016 10:35:01 -0500
Subject: [R] source() does not include added code
In-Reply-To: <ce4bc223-12d1-2618-aa43-cd12c11396eb@gmail.com>
References: <ce4bc223-12d1-2618-aa43-cd12c11396eb@gmail.com>
Message-ID: <CAPPM_gSzW37A9xQn1qrTEqd6jWx-mE-cOq2i7zEqU08THqJn7A@mail.gmail.com>

I have quantstrat installed and it works fine for me.  If you're
asking why the output of t(tradeStats('macross')) isn't being printed,
that's because of what's described in the first paragraph in the
*Details* section of help("source"):

     Note that running code via ?source? differs in a few respects from
     entering it at the R command line.  Since expressions are not
     executed at the top level, auto-printing is not done.  So you will
     need to include explicit ?print? calls for things you want to be
     printed (and remember that this includes plotting by ?lattice?,
     FAQ Q7.22).

So you need:

print(t(tradeStats('macross')))

if you want the output printed to the console.

On Wed, Aug 31, 2016 at 10:26 AM, Doug Edmunds <dougedmunds at gmail.com> wrote:
> 1.  File is (was) saved.
> 2.  The added code is
>  t(tradeStats("macross"))
> with 2 )'s.
>
> I'd appreciate if someone with QuantStrat installed, to try this
> and see if they get a different result.  My R and RStudio and
> QuantStrat libraries are all current.
>
>
> I get the chart and this much output.
>
>> source('~/CodingData/RCode/Quantstrat1/maCross.R')
> [1] "2001-06-27 00:00:00 AAPL 100 @ 1.526312"
> [1] "2001-09-07 00:00:00 AAPL -100 @ 1.13002"
> [1] "2002-01-07 00:00:00 AAPL 100 @ 1.497538"
> [1] "2002-07-10 00:00:00 AAPL -100 @ 1.132636"
> [1] "2003-05-16 00:00:00 AAPL 100 @ 1.22942"
> [1] "2006-06-22 00:00:00 AAPL -100 @ 7.792429"
> [1] "2006-09-26 00:00:00 AAPL 100 @ 10.150561"
> [1] "2008-03-07 00:00:00 AAPL -100 @ 15.988996"
> [1] "2008-05-19 00:00:00 AAPL 100 @ 24.012922"
> [1] "2008-09-24 00:00:00 AAPL -100 @ 16.833895"
> [1] "2009-05-14 00:00:00 AAPL 100 @ 16.080549"
> [1] "2012-12-11 00:00:00 AAPL -100 @ 71.436852"
> [1] "2013-09-11 00:00:00 AAPL 100 @ 62.897826"
> [1] "2015-08-31 00:00:00 AAPL -100 @ 110.399553"
> Time difference of 0.3014359 secs
> [1] "trade blotter portfolio update:"
> Time difference of 0.1732061 secs
>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From dougedmunds at gmail.com  Wed Aug 31 17:39:56 2016
From: dougedmunds at gmail.com (Doug Edmunds)
Date: Wed, 31 Aug 2016 08:39:56 -0700
Subject: [R] source() does not include added code
In-Reply-To: <CAPPM_gSzW37A9xQn1qrTEqd6jWx-mE-cOq2i7zEqU08THqJn7A@mail.gmail.com>
References: <ce4bc223-12d1-2618-aa43-cd12c11396eb@gmail.com>
	<CAPPM_gSzW37A9xQn1qrTEqd6jWx-mE-cOq2i7zEqU08THqJn7A@mail.gmail.com>
Message-ID: <8241e2c4-6627-f3d9-2a65-e68577ab7842@gmail.com>

Thank you.  That explains it (auto-printing is not done).

On 8/31/2016 8:35 AM, Joshua Ulrich wrote:
> I have quantstrat installed and it works fine for me.  If you're
> asking why the output of t(tradeStats('macross')) isn't being printed,
> that's because of what's described in the first paragraph in the
> *Details* section of help("source"):
>
>      Note that running code via ?source? differs in a few respects from
>      entering it at the R command line.  Since expressions are not
>      executed at the top level, auto-printing is not done.  So you will
>      need to include explicit ?print? calls for things you want to be
>      printed (and remember that this includes plotting by ?lattice?,
>      FAQ Q7.22).
>
> So you need:
>
> print(t(tradeStats('macross')))
>
> if you want the output printed to the console.
>


From leslie.rutkowski at gmail.com  Wed Aug 31 17:50:07 2016
From: leslie.rutkowski at gmail.com (Leslie Rutkowski)
Date: Wed, 31 Aug 2016 17:50:07 +0200
Subject: [R] paste0 in file path
Message-ID: <CAA0F9kXjtKihTnFDNMy2s-J_E83L41bL0SJGppeKQVB=iYmxyQ@mail.gmail.com>

Hi,

I'm trying to reshape and output 8 simple tables into excel files. This is
the code I'm using

  for (i in 1:8) {
  count <- table(mydata$ctry, mydata[,paste0("q0",i,"r")])
  dat <- as.data.frame(q01count)

  wide <- reshape(dat,
                  timevar="Var2",
                  idvar="Var1",
                  direction="wide")
   write.xlsx(wide, file=paste0(i, 'C:/temp/q0',i,'r.xlsx'))
  }

All goes well until the write.xlsx, which produces the error

Error in .jnew("java/io/FileOutputStream", jFile) :
  java.io.FileNotFoundException: 1C:\temp\q01r.xlsx (The filename,
directory name, or volume label syntax is incorrect)

Among other things, I'm puzzled about why a "1" is getting tacked on to the
file path.

Any hints?

Thanks,
Leslie

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Wed Aug 31 17:54:55 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 31 Aug 2016 17:54:55 +0200
Subject: [R] paste0 in file path
In-Reply-To: <CAA0F9kXjtKihTnFDNMy2s-J_E83L41bL0SJGppeKQVB=iYmxyQ@mail.gmail.com>
References: <CAA0F9kXjtKihTnFDNMy2s-J_E83L41bL0SJGppeKQVB=iYmxyQ@mail.gmail.com>
Message-ID: <aa74bdb2-c1ae-ea5b-275d-1f99b5af3520@statistik.tu-dortmund.de>



On 31.08.2016 17:50, Leslie Rutkowski wrote:
> Hi,
>
> I'm trying to reshape and output 8 simple tables into excel files. This is
> the code I'm using
>
>   for (i in 1:8) {
>   count <- table(mydata$ctry, mydata[,paste0("q0",i,"r")])
>   dat <- as.data.frame(q01count)
>
>   wide <- reshape(dat,
>                   timevar="Var2",
>                   idvar="Var1",
>                   direction="wide")
>    write.xlsx(wide, file=paste0(i, 'C:/temp/q0',i,'r.xlsx'))

                                   ^^
remove the i?

Best,
Uwe Ligges


>   }
>
> All goes well until the write.xlsx, which produces the error
>
> Error in .jnew("java/io/FileOutputStream", jFile) :
>   java.io.FileNotFoundException: 1C:\temp\q01r.xlsx (The filename,
> directory name, or volume label syntax is incorrect)
>
> Among other things, I'm puzzled about why a "1" is getting tacked on to the
> file path.
>
> Any hints?
>
> Thanks,
> Leslie
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From msharp at txbiomed.org  Wed Aug 31 17:46:28 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Wed, 31 Aug 2016 15:46:28 +0000
Subject: [R] 0 rows> (or 0-length row.names)
In-Reply-To: <CAB=p7Sr-OhhF3Qjo4D8dhJsMeNuS9f2PuL1WKdt9_kaF0HA4KQ@mail.gmail.com>
References: <CAB=p7SpPBEL5Yt3uL6Xq2BT8SJjjzY=9ZwPF9F_JSyZRqJ6fUw@mail.gmail.com>
	<CAF8bMcZCAtFmDbdiNwfTjobLVugdQ89a97Enymt+cry-A+mTzQ@mail.gmail.com>
	<CAB=p7Sqt8x3chPB1nEH4yyZmGVQ30j3W-y4RQ9XgH2TWuRO2Lw@mail.gmail.com>
	<81CB7399-239C-4ECA-848B-2EB169FE2328@TxBiomed.org>
	<CAB=p7SqLf=mSwZMn=ZemsJta+PkFwVHeXdVXNwXqTyGOBJiJhw@mail.gmail.com>
	<2B01B670-CE6F-45DC-9D09-22D6AEDF938D@TxBiomed.org>
	<CAB=p7Sr-OhhF3Qjo4D8dhJsMeNuS9f2PuL1WKdt9_kaF0HA4KQ@mail.gmail.com>
Message-ID: <6DA15CB3-A9D0-4441-B416-7CEBA427E441@TxBiomed.org>

Shivi,

Looking at the help from ?WOE, ?WOETable, and ?IV, your Y vector in all cases is to be categorical and it is numeric.

Mark


R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org


On Aug 31, 2016, at 5:37 AM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
>
> These are the packages i am using:
> library(woe)  #WEIGHT OF EVIDENCE
> library(InformationValue)  #INFORMATION VALUE
>
> The syntax used is :
> WOE(X=SFDC1$log_caseage, Y=SFDC1$survey)
> WOETable(X=SFDC1$case_age, Y=SFDC1$survey)
> IV(X=SFDC1$case_age, Y=SFDC1$survey)
>
> On Wed, Aug 31, 2016 at 12:54 AM, Mark Sharp <msharp at txbiomed.org> wrote:
> Shivi,
>
> What package(s) are you using. What functions are you using. How are you calling the functions. A reproducible sample has all of the actual code needed to create a representative error. There are multiple packages you could be using to look at weight of evidence and information value. For example, there is a WOE function in the Information package and a woe function in the woe package.
>
> Mark
>
>> On Aug 30, 2016, at 2:15 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
>>
>> Hi Mark,
>> What i understand, probably when i run the WOE & IV to check significant variables that is where i get this error. Thanks for your assistance Mark really appreciate i will look into some other measure on this.
>>
>> On Wed, Aug 31, 2016 at 12:35 AM, Mark Sharp <msharp at txbiomed.org> wrote:
>> Shivi,
>>
>> It is likely that William knows what you are trying to do because of his considerable experience, but I am not able to figure it out from what you have written. You have apparently sent the output from something like dput(SFDC[1:50, ]), but I still do not know what you did to get the error.
>>
>> I successfully assigned the structure you sent to the name SFDC and nothing seems amiss.
>>
>>
>> Mark
>>
>> R. Mark Sharp, Ph.D.
>> Director of Primate Records Database
>> Southwest National Primate Research Center
>> Texas Biomedical Research Institute
>> P.O. Box 760549
>> San Antonio, TX 78245-0549
>> Telephone: (210)258-9476
>> e-mail: msharp at TxBiomed.org
>>
>>
>>
>>
>>
>>
>>
>> > On Aug 30, 2016, at 12:32 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
>> >
>> > Hi William/ Mark,
>> >
>> > I am using WOE & IV (weight of evidence) reduce the number of independent
>> > vars.
>> > I have read this data as a csv file.
>> > reproducible example for your reference please:
>> >
>> > structure(list(date = structure(c(6L, 6L, 6L, 6L, 6L, 6L, 14L,
>> > 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
>> >
>> ... truncated
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments transmitted, may contain privileged and confidential information and is intended solely for the exclusive use of the individual or entity to whom it is addressed. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution or copying of this e-mail and/or attachments is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender stating that this transmission was misdirected; return the e-mail to sender; destroy all paper copies and delete all electronic copies from your system without disclosing its contents.
>
> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments transmitted, may contain privileged and confidential information and is intended solely for the exclusive use of the individual or entity to whom it is addressed. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution or copying of this e-mail and/or attachments is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender stating that this transmission was misdirected; return the e-mail to sender; destroy all paper copies and delete all electronic copies from your system without disclosing its contents.
>

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From shivipmp82 at gmail.com  Wed Aug 31 21:00:09 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Thu, 1 Sep 2016 00:30:09 +0530
Subject: [R] 0 rows> (or 0-length row.names)
In-Reply-To: <6DA15CB3-A9D0-4441-B416-7CEBA427E441@TxBiomed.org>
References: <CAB=p7SpPBEL5Yt3uL6Xq2BT8SJjjzY=9ZwPF9F_JSyZRqJ6fUw@mail.gmail.com>
	<CAF8bMcZCAtFmDbdiNwfTjobLVugdQ89a97Enymt+cry-A+mTzQ@mail.gmail.com>
	<CAB=p7Sqt8x3chPB1nEH4yyZmGVQ30j3W-y4RQ9XgH2TWuRO2Lw@mail.gmail.com>
	<81CB7399-239C-4ECA-848B-2EB169FE2328@TxBiomed.org>
	<CAB=p7SqLf=mSwZMn=ZemsJta+PkFwVHeXdVXNwXqTyGOBJiJhw@mail.gmail.com>
	<2B01B670-CE6F-45DC-9D09-22D6AEDF938D@TxBiomed.org>
	<CAB=p7Sr-OhhF3Qjo4D8dhJsMeNuS9f2PuL1WKdt9_kaF0HA4KQ@mail.gmail.com>
	<6DA15CB3-A9D0-4441-B416-7CEBA427E441@TxBiomed.org>
Message-ID: <CAB=p7SpQBNRtqLsOz4bjU6XCqemdz=gPKY4QRWRDmrFa=od4+A@mail.gmail.com>

Thank you Mark & Dunlap,

Will make changes to the variable as suggested. Thank you for your time &
assistance.

On Wed, Aug 31, 2016 at 9:16 PM, Mark Sharp <msharp at txbiomed.org> wrote:

> Shivi,
>
> Looking at the help from ?WOE, ?WOETable, and ?IV, your Y vector in all
> cases is to be categorical and it is numeric.
>
> Mark
>
>
> R. Mark Sharp, Ph.D.
> Director of Primate Records Database
> Southwest National Primate Research Center
> Texas Biomedical Research Institute
> P.O. Box 760549
> San Antonio, TX 78245-0549
> Telephone: (210)258-9476
> e-mail: msharp at TxBiomed.org
>
>
> On Aug 31, 2016, at 5:37 AM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
> >
> > These are the packages i am using:
> > library(woe)  #WEIGHT OF EVIDENCE
> > library(InformationValue)  #INFORMATION VALUE
> >
> > The syntax used is :
> > WOE(X=SFDC1$log_caseage, Y=SFDC1$survey)
> > WOETable(X=SFDC1$case_age, Y=SFDC1$survey)
> > IV(X=SFDC1$case_age, Y=SFDC1$survey)
> >
> > On Wed, Aug 31, 2016 at 12:54 AM, Mark Sharp <msharp at txbiomed.org>
> wrote:
> > Shivi,
> >
> > What package(s) are you using. What functions are you using. How are you
> calling the functions. A reproducible sample has all of the actual code
> needed to create a representative error. There are multiple packages you
> could be using to look at weight of evidence and information value. For
> example, there is a WOE function in the Information package and a woe
> function in the woe package.
> >
> > Mark
> >
> >> On Aug 30, 2016, at 2:15 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
> >>
> >> Hi Mark,
> >> What i understand, probably when i run the WOE & IV to check
> significant variables that is where i get this error. Thanks for your
> assistance Mark really appreciate i will look into some other measure on
> this.
> >>
> >> On Wed, Aug 31, 2016 at 12:35 AM, Mark Sharp <msharp at txbiomed.org>
> wrote:
> >> Shivi,
> >>
> >> It is likely that William knows what you are trying to do because of
> his considerable experience, but I am not able to figure it out from what
> you have written. You have apparently sent the output from something like
> dput(SFDC[1:50, ]), but I still do not know what you did to get the error.
> >>
> >> I successfully assigned the structure you sent to the name SFDC and
> nothing seems amiss.
> >>
> >>
> >> Mark
> >>
> >> R. Mark Sharp, Ph.D.
> >> Director of Primate Records Database
> >> Southwest National Primate Research Center
> >> Texas Biomedical Research Institute
> >> P.O. Box 760549
> >> San Antonio, TX 78245-0549
> >> Telephone: (210)258-9476
> >> e-mail: msharp at TxBiomed.org
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> > On Aug 30, 2016, at 12:32 PM, Shivi Bhatia <shivipmp82 at gmail.com>
> wrote:
> >> >
> >> > Hi William/ Mark,
> >> >
> >> > I am using WOE & IV (weight of evidence) reduce the number of
> independent
> >> > vars.
> >> > I have read this data as a csv file.
> >> > reproducible example for your reference please:
> >> >
> >> > structure(list(date = structure(c(6L, 6L, 6L, 6L, 6L, 6L, 14L,
> >> > 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
> >> >
> >> ... truncated
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
> transmitted, may contain privileged and confidential information and is
> intended solely for the exclusive use of the individual or entity to whom
> it is addressed. If you are not the intended recipient, you are hereby
> notified that any review, dissemination, distribution or copying of this
> e-mail and/or attachments is strictly prohibited. If you have received this
> e-mail in error, please immediately notify the sender stating that this
> transmission was misdirected; return the e-mail to sender; destroy all
> paper copies and delete all electronic copies from your system without
> disclosing its contents.
> >
> > CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
> transmitted, may contain privileged and confidential information and is
> intended solely for the exclusive use of the individual or entity to whom
> it is addressed. If you are not the intended recipient, you are hereby
> notified that any review, dissemination, distribution or copying of this
> e-mail and/or attachments is strictly prohibited. If you have received this
> e-mail in error, please immediately notify the sender stating that this
> transmission was misdirected; return the e-mail to sender; destroy all
> paper copies and delete all electronic copies from your system without
> disclosing its contents.
> >
>
> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments
> transmitted, may contain privileged and confidential information and is
> intended solely for the exclusive use of the individual or entity to whom
> it is addressed. If you are not the intended recipient, you are hereby
> notified that any review, dissemination, distribution or copying of this
> e-mail and/or attachments is strictly prohibited. If you have received this
> e-mail in error, please immediately notify the sender stating that this
> transmission was misdirected; return the e-mail to sender; destroy all
> paper copies and delete all electronic copies from your system without
> disclosing its contents.
>

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Wed Aug 31 21:51:30 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Wed, 31 Aug 2016 12:51:30 -0700
Subject: [R] paste0 in file path
In-Reply-To: <aa74bdb2-c1ae-ea5b-275d-1f99b5af3520@statistik.tu-dortmund.de>
References: <CAA0F9kXjtKihTnFDNMy2s-J_E83L41bL0SJGppeKQVB=iYmxyQ@mail.gmail.com>
	<aa74bdb2-c1ae-ea5b-275d-1f99b5af3520@statistik.tu-dortmund.de>
Message-ID: <CAFDcVCTNzb5FMELdpGrSE3UU4GQ=DvzE_pFc=eeLRuiTF=DMTw@mail.gmail.com>

Also, the recommended way to build file paths is to use file.path(), i.e.

   file.path("C:", "temp", filename)

rather than

   paste0("C:/temp/", filename)


BTW, R provides tempdir() that gives you the temporary directory that
R prefers to use on your OS.  So, you might want to consider using:

   paste0(tempdir(), filename)

It is specific and temporary to the R session running though, so if
you want to store things across R sessions, tempdir() is not what you
want to use.

/Henrik


On Wed, Aug 31, 2016 at 8:54 AM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
>
> On 31.08.2016 17:50, Leslie Rutkowski wrote:
>>
>> Hi,
>>
>> I'm trying to reshape and output 8 simple tables into excel files. This is
>> the code I'm using
>>
>>   for (i in 1:8) {
>>   count <- table(mydata$ctry, mydata[,paste0("q0",i,"r")])
>>   dat <- as.data.frame(q01count)
>>
>>   wide <- reshape(dat,
>>                   timevar="Var2",
>>                   idvar="Var1",
>>                   direction="wide")
>>    write.xlsx(wide, file=paste0(i, 'C:/temp/q0',i,'r.xlsx'))
>
>
>                                   ^^
> remove the i?
>
> Best,
> Uwe Ligges
>
>
>
>>   }
>>
>> All goes well until the write.xlsx, which produces the error
>>
>> Error in .jnew("java/io/FileOutputStream", jFile) :
>>   java.io.FileNotFoundException: 1C:\temp\q01r.xlsx (The filename,
>> directory name, or volume label syntax is incorrect)
>>
>> Among other things, I'm puzzled about why a "1" is getting tacked on to
>> the
>> file path.
>>
>> Any hints?
>>
>> Thanks,
>> Leslie
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mituldaga at gmail.com  Wed Aug 31 07:20:48 2016
From: mituldaga at gmail.com (Mitul Daga)
Date: Wed, 31 Aug 2016 10:50:48 +0530
Subject: [R] Number of Variables allowed in R
Message-ID: <CANTxzL6V0c48aCSosCkyEjGqOK4=g=6+39D4810HCEuV=6RT7A@mail.gmail.com>

Hi,

Can someone please tell me the maximum number of independent variables
allowed in R for non linear regression.

I have 50 independent variables and want to calculate non linear models to
the power of 9 but R is unable to process it beyond to the power of 3 which
means its taking maximum 150 independent variables for its calculation.

Also, it would be great if someone could guide me as to how I can achieve
the above in R.

-- 


Regards,
Mitul

	[[alternative HTML version deleted]]


From bob at rud.is  Wed Aug 31 18:38:30 2016
From: bob at rud.is (Bob Rudis)
Date: Wed, 31 Aug 2016 12:38:30 -0400
Subject: [R] paste0 in file path
In-Reply-To: <aa74bdb2-c1ae-ea5b-275d-1f99b5af3520@statistik.tu-dortmund.de>
References: <CAA0F9kXjtKihTnFDNMy2s-J_E83L41bL0SJGppeKQVB=iYmxyQ@mail.gmail.com>
	<aa74bdb2-c1ae-ea5b-275d-1f99b5af3520@statistik.tu-dortmund.de>
Message-ID: <CAA-FpKXd6Q52z9AaseeG7vT0J5YOBdB+yOg10FbhCtsB0Sz25A@mail.gmail.com>

if the files are supposed to be "1r.xlsx", "2r.xlsx" (etc) then you need to
ensure there's a "/" before it.

It's better to use `file.path()` to, well, build file paths since it will
help account for differences between directory separators on the various
operating systems out there.

On Wed, Aug 31, 2016 at 11:54 AM, Uwe Ligges <
ligges at statistik.tu-dortmund.de> wrote:

>
>
> On 31.08.2016 17:50, Leslie Rutkowski wrote:
>
>> Hi,
>>
>> I'm trying to reshape and output 8 simple tables into excel files. This is
>> the code I'm using
>>
>>   for (i in 1:8) {
>>   count <- table(mydata$ctry, mydata[,paste0("q0",i,"r")])
>>   dat <- as.data.frame(q01count)
>>
>>   wide <- reshape(dat,
>>                   timevar="Var2",
>>                   idvar="Var1",
>>                   direction="wide")
>>    write.xlsx(wide, file=paste0(i, 'C:/temp/q0',i,'r.xlsx'))
>>
>
>                                   ^^
> remove the i?
>
> Best,
> Uwe Ligges
>
>
>
>   }
>>
>> All goes well until the write.xlsx, which produces the error
>>
>> Error in .jnew("java/io/FileOutputStream", jFile) :
>>   java.io.FileNotFoundException: 1C:\temp\q01r.xlsx (The filename,
>> directory name, or volume label syntax is incorrect)
>>
>> Among other things, I'm puzzled about why a "1" is getting tacked on to
>> the
>> file path.
>>
>> Any hints?
>>
>> Thanks,
>> Leslie
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bhaskar.kolkata at gmail.com  Wed Aug 31 18:07:49 2016
From: bhaskar.kolkata at gmail.com (Bhaskar Mitra)
Date: Wed, 31 Aug 2016 12:07:49 -0400
Subject: [R] Time format lagging issue
Message-ID: <CAEGXkYUYJ9uZP=mWYJqUArCpozwb=jkGVwtCovOgdT72X68MoA@mail.gmail.com>

Hello Everyone,

I am trying a shift the time series in a dataframe (df) by 30 minutes . My
current format looks something like this :



*df$$Time 1*


*201112312230*

*201112312300*

*201112312330*



*I am trying to add an additional column of time (df$Time 2) next to  Time
1 by lagging it by ? 30minutes. Something like this :*


*df$Time1                   **df$$Time2*


*201112312230          **201112312200*

*201112312300          **201112312230*

*201112312330          **201112312300*

*201112312330          *





*Based on some of the suggestions available, I have tried this option *



*require(zoo)*

*df1$Time2  <- lag(df1$Time1, -1, na.pad = TRUE)*

*View(df1)*



*This does not however give me the desired result. I would appreciate any
suggestions/advice in this regard.*


*Thanks,*

*Bhaskar*

	[[alternative HTML version deleted]]


From andersonaed at gmail.com  Wed Aug 31 19:03:43 2016
From: andersonaed at gmail.com (Anderson Eduardo)
Date: Wed, 31 Aug 2016 14:03:43 -0300
Subject: [R] GLM output problem
Message-ID: <CAEPvLrzCHUtF4+Tuj4ai83cp0u6+oyeY1wVP+fXBmSx6rh2omQ@mail.gmail.com>

Hello

I have started to work with GLM and I am facing the following problem:

If I take:

y = c(0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0)
x = 1:18

model = y ~x + I(x^2)
GLM = glm(model, family=binamial(link = logit))

And use the parameters returned by GLM to contruct an equation for the
regression model:

model.eq = -0.446078 + 0.267673*x - 0.014577*I(x^2)

And backtransform it from the logit to the natural scale (using the inverse
link-function for this case):

model.proj = exp(model.eq)/(1+exp(model.eq))

the plot for model.proj~x is not the same of the plot for fitted(GLM)~x
(see the output attached).

Why is this happening? Can someone help me?

Regards,

Anderson Eduardo

 --
Anderson A. Eduardo
------------------------------------------------------------------------------
Lattes <http://lattes.cnpq.br/3826166230581311> | Researcher ID
<http://orcid.org/0000-0001-8045-8043> | Google Acad?mico
<https://scholar.google.com.br/citations?user=oOUjq9IAAAAJ&hl=pt-BR> | Site
<http://andersonaireseduardo.xpg.uol.com.br/>
------------------------------------------------------------------------------

From bgunter.4567 at gmail.com  Wed Aug 31 22:30:37 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 31 Aug 2016 13:30:37 -0700
Subject: [R] Number of Variables allowed in R
In-Reply-To: <CANTxzL6V0c48aCSosCkyEjGqOK4=g=6+39D4810HCEuV=6RT7A@mail.gmail.com>
References: <CANTxzL6V0c48aCSosCkyEjGqOK4=g=6+39D4810HCEuV=6RT7A@mail.gmail.com>
Message-ID: <CAGxFJbR9s=eTj7DuEojJg0PBc68wixgdqJa0q8dzN5rGA6JpdQ@mail.gmail.com>

Please show us your code and error messages. I suspect that what you
mean by "nonlinear models" may not be what the rest of us mean.

And please post in plain text, not HTML, as the latter tends to get
mangled on this plai text list.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 30, 2016 at 10:20 PM, Mitul Daga <mituldaga at gmail.com> wrote:
> Hi,
>
> Can someone please tell me the maximum number of independent variables
> allowed in R for non linear regression.
>
> I have 50 independent variables and want to calculate non linear models to
> the power of 9 but R is unable to process it beyond to the power of 3 which
> means its taking maximum 150 independent variables for its calculation.
>
> Also, it would be great if someone could guide me as to how I can achieve
> the above in R.
>
> --
>
>
> Regards,
> Mitul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Aug 31 22:44:22 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 31 Aug 2016 13:44:22 -0700
Subject: [R] GLM output problem
In-Reply-To: <CAEPvLrzCHUtF4+Tuj4ai83cp0u6+oyeY1wVP+fXBmSx6rh2omQ@mail.gmail.com>
References: <CAEPvLrzCHUtF4+Tuj4ai83cp0u6+oyeY1wVP+fXBmSx6rh2omQ@mail.gmail.com>
Message-ID: <CAGxFJbS-d2VQPqsTX2irhL2D9BWLgtUocyO8i3QuSfnvPtjfLg@mail.gmail.com>

Inline.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 31, 2016 at 10:03 AM, Anderson Eduardo
<andersonaed at gmail.com> wrote:
> Hello
>
> I have started to work with GLM and I am facing the following problem:
>
> If I take:
>
> y = c(0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0)
> x = 1:18
>
> model = y ~x + I(x^2)
> GLM = glm(model, family=binamial(link = logit))
>
> And use the parameters returned by GLM to contruct an equation for the
> regression model:
>
> model.eq = -0.446078 + 0.267673*x - 0.014577*I(x^2)

## Not what I got with your data. I got:

Coefficients:
(Intercept)            x       I(x^2)
   -18.5750       5.0403      -0.2845


I suspect you had some other x,y variables lying around when you
defined your model.

-- Bert

>
> And backtransform it from the logit to the natural scale (using the inverse
> link-function for this case):
>
> model.proj = exp(model.eq)/(1+exp(model.eq))
>
> the plot for model.proj~x is not the same of the plot for fitted(GLM)~x
> (see the output attached).
>
> Why is this happening? Can someone help me?
>
> Regards,
>
> Anderson Eduardo
>
>  --
> Anderson A. Eduardo
> ------------------------------------------------------------------------------
> Lattes <http://lattes.cnpq.br/3826166230581311> | Researcher ID
> <http://orcid.org/0000-0001-8045-8043> | Google Acad?mico
> <https://scholar.google.com.br/citations?user=oOUjq9IAAAAJ&hl=pt-BR> | Site
> <http://andersonaireseduardo.xpg.uol.com.br/>
> ------------------------------------------------------------------------------
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Wed Aug 31 23:44:38 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 31 Aug 2016 21:44:38 +0000
Subject: [R] Time format lagging issue
In-Reply-To: <CAEGXkYUYJ9uZP=mWYJqUArCpozwb=jkGVwtCovOgdT72X68MoA@mail.gmail.com>
References: <CAEGXkYUYJ9uZP=mWYJqUArCpozwb=jkGVwtCovOgdT72X68MoA@mail.gmail.com>
Message-ID: <D3EC9D33.184DAB%macqueen1@llnl.gov>

Try following this example:

mydf <- data.frame(t1=c('201112312230', '201112312330'))
tmp1 <- as.POSIXct(mydf$t1, format='%Y%m%d%H%M')
tmp2 <- tmp1 - 30*60
mydf$t2 <- format(tmp2, '%Y%m%d%H%M')

It can be made into a single line, but I used intermediate variables tmp1
and tmp2 so that it would be easier to follow.

Base R is more than adequate for this task.

Please get rid of the asterisks in your next email. The just get in the
way. Learn how to send plain text email, not HTML email. Please.




-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/31/16, 9:07 AM, "R-help on behalf of Bhaskar Mitra"
<r-help-bounces at r-project.org on behalf of bhaskar.kolkata at gmail.com>
wrote:

>Hello Everyone,
>
>I am trying a shift the time series in a dataframe (df) by 30 minutes . My
>current format looks something like this :
>
>
>
>*df$$Time 1*
>
>
>*201112312230*
>
>*201112312300*
>
>*201112312330*
>
>
>
>*I am trying to add an additional column of time (df$Time 2) next to  Time
>1 by lagging it by ? 30minutes. Something like this :*
>
>
>*df$Time1                   **df$$Time2*
>
>
>*201112312230          **201112312200*
>
>*201112312300          **201112312230*
>
>*201112312330          **201112312300*
>
>*201112312330          *
>
>
>
>
>
>*Based on some of the suggestions available, I have tried this option *
>
>
>
>*require(zoo)*
>
>*df1$Time2  <- lag(df1$Time1, -1, na.pad = TRUE)*
>
>*View(df1)*
>
>
>
>*This does not however give me the desired result. I would appreciate any
>suggestions/advice in this regard.*
>
>
>*Thanks,*
>
>*Bhaskar*
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From govokai at gmail.com  Wed Aug 31 23:58:41 2016
From: govokai at gmail.com (Kai Mx)
Date: Wed, 31 Aug 2016 23:58:41 +0200
Subject: [R] Looping through different groups of variables in models
Message-ID: <CAHOWgNXd+UWOSg55fCNa3kdbC9JOOyLJFncUy3qCeH6ovU_MjQ@mail.gmail.com>

Hi all,

I am having trouble wrapping my head around a probably simple issue:

After using the reshape package, I have a melted dataframe with the columns
group (factor), time (int), condition (factor), value(int).

These are experimental data. The data were obtained from different
treatment groups (group) under different conditions at different time
points.

I would now like to perform ANOVA, boxplots and calculate means to compare
groups for all combinations of conditions and time points with something
like

fit <- lm(value~group, data=[subset of data with combination of
condition/timepoint])
summary (fit)
p <- ggplot([subset of data with combination of condition/timepoint],
aes(x= group, y=value)) + geom_boxplot ()
print (p)
tapply ([subset of data with combination of condition/timepoint]$value,
subset of data with combination of condition/timepoint]$group, mean)

How can I loop through these combinations and output the data in an elegant
way?

Thanks so much!

Best,

Kai

	[[alternative HTML version deleted]]


From jfca283 at gmail.com  Wed Aug 31 22:45:11 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Wed, 31 Aug 2016 17:45:11 -0300
Subject: [R] Loop over rda list files and using the attach function
In-Reply-To: <CALBYkjJnWXPt_xzeMH79+gCsyaKCCmW-wGCDnRCFS7=3EQ55gQ@mail.gmail.com>
References: <CALBYkjJLY0Rqve9+CeSfXYkRrUVvAcCt4URBvtLcOMZefKU62Q@mail.gmail.com>
	<20160830194224.Horde.ZIl7YbovKZCpCjdiP-BRhFN@mail.sapo.pt>
	<CALBYkjJnWXPt_xzeMH79+gCsyaKCCmW-wGCDnRCFS7=3EQ55gQ@mail.gmail.com>
Message-ID: <CALBYkjL+GKg+HwdbRMcrmD5usmbNYBT8nbF999Xq0NWU+a-E2Q@mail.gmail.com>

Hi
I want to comment something.
When i added the detach(get(yyz)) the RAM consumption was considerable
reduced.
So, i want to declare this issue as solved and thank you all for your
assistance.
Good luck to all.

On Tue, Aug 30, 2016 at 6:24 PM, Juan Ceccarelli Arias <jfca283 at gmail.com>
wrote:

> The attach(get(yyz)) option i tried and it worked. The only issue, is that
> when i'm  trying to export the results, it takes a lot of time.
> Considerably more than Stata. Also, the computer almost collapses for a
> task which isn't so exhausting for my PC station.
> Im dubious...
>
> On Tue, Aug 30, 2016 at 3:42 PM, <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> Try
>>
>> attach(get(yyz))
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
>>
>>
>>
>>
>> Citando Juan Ceccarelli Arias <jfca283 at gmail.com>:
>>
>> Hi.
>>> I need to loop over rda files.
>>> I generated the list of them.
>>> That's ok. The problem is that the name of the files are as yyyy_mm (eg
>>> 2010_01 is january or 2010, 2016_03 is march of 2016).
>>> So, when i try to use the attach function to create a simple table(age,
>>> sex) it fails.
>>> The only way to attach a file as is using
>>> attach(`2016_03`)
>>> The text above i have no idea how to declare it in my code below
>>>
>>>
>>> dd=list.files("C:/Users/Me/r", pattern="rda$", full.names=F)
>>> for (i in 1:length(dd)) {
>>> yyz=load(dd[i])
>>> attach(yyz)
>>> table(age, sex)
>>> rm(list=yyz)
>>>
>>> }
>>> This is the error it declares the loop:
>>> Error in attach(yyz) : file '2013_02' not found
>>>
>>>
>>> Thanks for your help and time
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>>
>

	[[alternative HTML version deleted]]


From tom at vims.edu  Wed Aug 31 22:25:02 2016
From: tom at vims.edu (Tom Mosca)
Date: Wed, 31 Aug 2016 20:25:02 +0000
Subject: [R] Same code on Mac?
Message-ID: <CB5791F5EA3D82408B277900997482D27F7DDA29@mboxes2.campus.vims.edu>

Using a PC I have written the R code for my elementary statistics students.  One of the students has a Mac.  Should the same lines of code work on a Mac?



Where can the student find support for R on her Mac?  I don't know anything about them, and have never used one.



Thank you.

	[[alternative HTML version deleted]]


From jfca283 at gmail.com  Wed Aug 31 22:48:17 2016
From: jfca283 at gmail.com (Juan Ceccarelli Arias)
Date: Wed, 31 Aug 2016 17:48:17 -0300
Subject: [R] Importint stata file and using value labels
In-Reply-To: <776d0a12-9f7b-2327-f69d-70b1fe1fcfc7@yorku.ca>
References: <CALBYkjJLbWXdS17zH=P_rf-rj7PPnTGp1TtKoC5Lk-bmkNtKVw@mail.gmail.com>
	<20160825163904.Horde.1WBb35Cp4ixvo0Euondfg9s@mail.sapo.pt>
	<CALBYkj+jmgtqz24LJw1ArtgCbPafjkL48qfzujHRjQ9-azc8dQ@mail.gmail.com>
	<20160825174234.Horde.R6gdOj82yuK987Jj6o5_qEp@mail.sapo.pt>
	<CALBYkjLKgmA0W3Ecvh94eLniWVECU8i5ys8j5+zJkAeyOs+khA@mail.gmail.com>
	<20160825201107.Horde._Vy9S_eCHmMTdmtkvdhot_t@mail.sapo.pt>
	<CALBYkjJ9=8hTV=+dL0nBaVV+Lnw1QqNAoR98Q63Sr7wJzRq=sA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503A48E@SRVEXCHMBX.precheza.cz>
	<CALBYkjLFSAvKzb+=srtRJV_E-MTUa7H+gwuRneWsngibeknUpA@mail.gmail.com>
	<776d0a12-9f7b-2327-f69d-70b1fe1fcfc7@yorku.ca>
Message-ID: <CALBYkjKQjKn2LxgrX3+gC-kXjuFeSDvCcTxCd5d5GA6ET7EfPg@mail.gmail.com>

I solved this problem using the
nonint.factors=F,generate.factors=F)
when i imported the dta files.
Thanks to all. My issue can be declared as solved.


On Sat, Aug 27, 2016 at 12:55 PM, Michael Friendly <friendly at yorku.ca>
wrote:

> On 8/26/2016 11:05 AM, Juan Ceccarelli Arias wrote:
>
>> Yep. Im a bit stalled.
>> I can't find the option to import only the values and drop the value
>> labels
>> from the dta file.
>> Im quite sure R can do that. Then i'd only used the values and i'd rely on
>> my memory.
>> It isn't a bad alternative.
>>
>>
> Hint: use str() to see the class of what you've read.
> Then try as.data.frame() on the resulting object read from the .dta file.
>
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>

	[[alternative HTML version deleted]]


