From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Feb  1 00:02:16 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 31 Jan 2020 17:02:16 -0600
Subject: [R] how to read a database in R?
Message-ID: <CAF9-5jMKdYjSNgVKc=gaLbisvT+mFZE_aq1f7ALR3WZrUYSFHA@mail.gmail.com>

Hello,

I have a database DGN-WB_0.5.db is there is a way to explore its
content in R? I don't know anything about this data base.

Thanks
Ana


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Feb  1 02:03:37 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 31 Jan 2020 17:03:37 -0800
Subject: [R] how to read a database in R?
In-Reply-To: <CAF9-5jMKdYjSNgVKc=gaLbisvT+mFZE_aq1f7ALR3WZrUYSFHA@mail.gmail.com>
References: <CAF9-5jMKdYjSNgVKc=gaLbisvT+mFZE_aq1f7ALR3WZrUYSFHA@mail.gmail.com>
Message-ID: <5B2D76F9-5E54-4EA3-8D1C-4444805C44A1@dcn.davis.ca.us>

Too little information to tell. I googled the file name though and pages about genetics came up... perhaps you should ask in the Bioconductor support area.

On January 31, 2020 3:02:16 PM PST, Ana Marija <sokovic.anamarija at gmail.com> wrote:
>Hello,
>
>I have a database DGN-WB_0.5.db is there is a way to explore its
>content in R? I don't know anything about this data base.
>
>Thanks
>Ana
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From h@@@n@d|w@n @end|ng |rom gm@||@com  Sat Feb  1 02:18:07 2020
From: h@@@n@d|w@n @end|ng |rom gm@||@com (Hasan Diwan)
Date: Fri, 31 Jan 2020 17:18:07 -0800
Subject: [R] how to read a database in R?
In-Reply-To: <CAF9-5jMKdYjSNgVKc=gaLbisvT+mFZE_aq1f7ALR3WZrUYSFHA@mail.gmail.com>
References: <CAF9-5jMKdYjSNgVKc=gaLbisvT+mFZE_aq1f7ALR3WZrUYSFHA@mail.gmail.com>
Message-ID: <CAP+bYWBs4c31ShDbHYARi-iVfGqOhCiO2GURq8eAoPxxTXE0kQ@mail.gmail.com>

Ms Marija,
Would you happen to know which program created it? If not, you can try the
Unix file command, if you have access to that. -- H

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Sat Feb  1 13:18:48 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sat, 1 Feb 2020 15:18:48 +0300
Subject: [R] how to read a database in R?
In-Reply-To: <CAF9-5jMKdYjSNgVKc=gaLbisvT+mFZE_aq1f7ALR3WZrUYSFHA@mail.gmail.com>
References: <CAF9-5jMKdYjSNgVKc=gaLbisvT+mFZE_aq1f7ALR3WZrUYSFHA@mail.gmail.com>
Message-ID: <20200201151848.12c0ff5f@Tarkus>

On Fri, 31 Jan 2020 17:02:16 -0600
Ana Marija <sokovic.anamarija at gmail.com> wrote:

> I have a database DGN-WB_0.5.db is there is a way to explore its
> content in R? 

My psychic debugging powers tell me that it's an SQLite database, so
the answer to your question is: yes, it should be possible to both find
out the schema and run SQL queries on your file from R.

-- 
Best regards,
Ivan


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Feb  1 13:52:26 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Sat, 1 Feb 2020 06:52:26 -0600
Subject: [R] how to read a database in R?
In-Reply-To: <20200201151848.12c0ff5f@Tarkus>
References: <CAF9-5jMKdYjSNgVKc=gaLbisvT+mFZE_aq1f7ALR3WZrUYSFHA@mail.gmail.com>
 <20200201151848.12c0ff5f@Tarkus>
Message-ID: <CAF9-5jPMRf7-im1FPE59dbhomi=v5v_kRLqc5vfYXrPTOCGtYg@mail.gmail.com>

Hi Ivan

Thanks for getting back to me. Can you please share with me some code I
would use to see what is in my database?

On Sat, 1 Feb 2020 at 06:19, Ivan Krylov <krylov.r00t at gmail.com> wrote:

> On Fri, 31 Jan 2020 17:02:16 -0600
> Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> > I have a database DGN-WB_0.5.db is there is a way to explore its
> > content in R?
>
> My psychic debugging powers tell me that it's an SQLite database, so
> the answer to your question is: yes, it should be possible to both find
> out the schema and run SQL queries on your file from R.
>
> --
> Best regards,
> Ivan
>

	[[alternative HTML version deleted]]


From jrkr|de@u @end|ng |rom gm@||@com  Sat Feb  1 15:55:23 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Sat, 1 Feb 2020 09:55:23 -0500
Subject: [R] how to read a database in R?
In-Reply-To: <CAF9-5jPMRf7-im1FPE59dbhomi=v5v_kRLqc5vfYXrPTOCGtYg@mail.gmail.com>
References: <CAF9-5jMKdYjSNgVKc=gaLbisvT+mFZE_aq1f7ALR3WZrUYSFHA@mail.gmail.com>
 <20200201151848.12c0ff5f@Tarkus>
 <CAF9-5jPMRf7-im1FPE59dbhomi=v5v_kRLqc5vfYXrPTOCGtYg@mail.gmail.com>
Message-ID: <CAKZQJMDEcwUPnYg3tEy_Ch=PCWT2k69K=HSpr9iKbKL2zBLC2w@mail.gmail.com>

Hi Ana
Stolen from https://gist.github.com/jwolfson/72bc7d7fd8d339955b38
I cannot remember if you will need to install any other packages besides
RSQLite

library(RSQLite)
filename <- "your_db_file.db"
sqlite.driver <- dbDriver("SQLite")
db <- dbConnect(sqlite.driver,
                dbname = filename)

## Some operations
dbListTables(db)
mytable <- dbReadTable(db,"your_table_name"

Best of luck


On Sat, 1 Feb 2020 at 07:53, Ana Marija <sokovic.anamarija at gmail.com> wrote:

> Hi Ivan
>
> Thanks for getting back to me. Can you please share with me some code I
> would use to see what is in my database?
>
> On Sat, 1 Feb 2020 at 06:19, Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> > On Fri, 31 Jan 2020 17:02:16 -0600
> > Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > > I have a database DGN-WB_0.5.db is there is a way to explore its
> > > content in R?
> >
> > My psychic debugging powers tell me that it's an SQLite database, so
> > the answer to your question is: yes, it should be possible to both find
> > out the schema and run SQL queries on your file from R.
> >
> > --
> > Best regards,
> > Ivan
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Feb  1 16:15:39 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Sat, 1 Feb 2020 09:15:39 -0600
Subject: [R] how to read a database in R?
In-Reply-To: <CAKZQJMDEcwUPnYg3tEy_Ch=PCWT2k69K=HSpr9iKbKL2zBLC2w@mail.gmail.com>
References: <CAF9-5jMKdYjSNgVKc=gaLbisvT+mFZE_aq1f7ALR3WZrUYSFHA@mail.gmail.com>
 <20200201151848.12c0ff5f@Tarkus>
 <CAF9-5jPMRf7-im1FPE59dbhomi=v5v_kRLqc5vfYXrPTOCGtYg@mail.gmail.com>
 <CAKZQJMDEcwUPnYg3tEy_Ch=PCWT2k69K=HSpr9iKbKL2zBLC2w@mail.gmail.com>
Message-ID: <CAF9-5jPQJJAaPWdONC3uab9dU1=0x39WcQVQRHW4+oYSZN4FVQ@mail.gmail.com>

Hi John,

I tried it but this is what I got:

> library(RSQLite)
> filename <- "DGN-WB_0.5.db"
> sqlite.driver <- dbDriver("SQLite")
> db <- dbConnect(sqlite.driver,
+                 dbname = filename)
Warning message:
Couldn't set synchronous mode: disk I/O error
Use `synchronous` = NULL to turn off this warning.

Please advise,
Ana

On Sat, Feb 1, 2020 at 8:55 AM John Kane <jrkrideau at gmail.com> wrote:
>
> Hi Ana
> Stolen from https://gist.github.com/jwolfson/72bc7d7fd8d339955b38
> I cannot remember if you will need to install any other packages besides RSQLite
>
> library(RSQLite)
> filename <- "your_db_file.db"
> sqlite.driver <- dbDriver("SQLite")
> db <- dbConnect(sqlite.driver,
>                 dbname = filename)
>
> ## Some operations
> dbListTables(db)
> mytable <- dbReadTable(db,"your_table_name"
>
> Best of luck
>
>
> On Sat, 1 Feb 2020 at 07:53, Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>
>> Hi Ivan
>>
>> Thanks for getting back to me. Can you please share with me some code I
>> would use to see what is in my database?
>>
>> On Sat, 1 Feb 2020 at 06:19, Ivan Krylov <krylov.r00t at gmail.com> wrote:
>>
>> > On Fri, 31 Jan 2020 17:02:16 -0600
>> > Ana Marija <sokovic.anamarija at gmail.com> wrote:
>> >
>> > > I have a database DGN-WB_0.5.db is there is a way to explore its
>> > > content in R?
>> >
>> > My psychic debugging powers tell me that it's an SQLite database, so
>> > the answer to your question is: yes, it should be possible to both find
>> > out the schema and run SQL queries on your file from R.
>> >
>> > --
>> > Best regards,
>> > Ivan
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> John Kane
> Kingston ON Canada


From jrkr|de@u @end|ng |rom gm@||@com  Sat Feb  1 17:33:56 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Sat, 1 Feb 2020 11:33:56 -0500
Subject: [R] how to read a database in R?
In-Reply-To: <CAF9-5jPQJJAaPWdONC3uab9dU1=0x39WcQVQRHW4+oYSZN4FVQ@mail.gmail.com>
References: <CAF9-5jMKdYjSNgVKc=gaLbisvT+mFZE_aq1f7ALR3WZrUYSFHA@mail.gmail.com>
 <20200201151848.12c0ff5f@Tarkus>
 <CAF9-5jPMRf7-im1FPE59dbhomi=v5v_kRLqc5vfYXrPTOCGtYg@mail.gmail.com>
 <CAKZQJMDEcwUPnYg3tEy_Ch=PCWT2k69K=HSpr9iKbKL2zBLC2w@mail.gmail.com>
 <CAF9-5jPQJJAaPWdONC3uab9dU1=0x39WcQVQRHW4+oYSZN4FVQ@mail.gmail.com>
Message-ID: <CAKZQJMDaodAHWfy1rRZfowRRAUd58+FWK-szS0GpP8d=4Covbw@mail.gmail.com>

What happens if you run "dbListTables(db) "?
That is a warning not an error.

I am a real novice with data bases so I may not be of much help but do you
know where the db file came from?

When I suggested the code above. i checked that ii worked on a sqlite file
I had, and hoped that Ivan's miraculous inspiration  was correct.  It could
possibly be some other db type

I will attach my sample db here and if it makes it through, you should be
able to load it if RSQLite is functioning on your machine.

On Sat, 1 Feb 2020 at 10:10, Ana Marija <sokovic.anamarija at gmail.com> wrote:

> Hi John,
>
> I tried it but this is what I got:
>
> > library(RSQLite)
> > filename <- "DGN-WB_0.5.db"
> > sqlite.driver <- dbDriver("SQLite")
> > db <- dbConnect(sqlite.driver,
> +                 dbname = filename)
> Warning message:
> Couldn't set synchronous mode: disk I/O error
> Use `synchronous` = NULL to turn off this warning.
>
> Please advise,
> Ana
>
> On Sat, Feb 1, 2020 at 8:55 AM John Kane <jrkrideau at gmail.com> wrote:
> >
> > Hi Ana
> > Stolen from https://gist.github.com/jwolfson/72bc7d7fd8d339955b38
> > I cannot remember if you will need to install any other packages besides
> RSQLite
> >
> > library(RSQLite)
> > filename <- "your_db_file.db"
> > sqlite.driver <- dbDriver("SQLite")
> > db <- dbConnect(sqlite.driver,
> >                 dbname = filename)
> >
> > ## Some operations
> > dbListTables(db)
> > mytable <- dbReadTable(db,"your_table_name"
> >
> > Best of luck
> >
> >
> > On Sat, 1 Feb 2020 at 07:53, Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
> >>
> >> Hi Ivan
> >>
> >> Thanks for getting back to me. Can you please share with me some code I
> >> would use to see what is in my database?
> >>
> >> On Sat, 1 Feb 2020 at 06:19, Ivan Krylov <krylov.r00t at gmail.com> wrote:
> >>
> >> > On Fri, 31 Jan 2020 17:02:16 -0600
> >> > Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >> >
> >> > > I have a database DGN-WB_0.5.db is there is a way to explore its
> >> > > content in R?
> >> >
> >> > My psychic debugging powers tell me that it's an SQLite database, so
> >> > the answer to your question is: yes, it should be possible to both
> find
> >> > out the schema and run SQL queries on your file from R.
> >> >
> >> > --
> >> > Best regards,
> >> > Ivan
> >> >
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > John Kane
> > Kingston ON Canada
>


-- 
John Kane
Kingston ON Canada

From j@me@ @end|ng |rom j@@@oc@com  Sat Feb  1 20:24:51 2020
From: j@me@ @end|ng |rom j@@@oc@com (James Spottiswoode)
Date: Sat, 1 Feb 2020 11:24:51 -0800
Subject: [R] How to parallelize a process called by a socket connection
References: <CAGjf1cN=wBJcZONcYtYgBa4kHgSnpbhC05wBmQ__Kgnu04j=Kw@mail.gmail.com>
Message-ID: <60C2D8D1-4CFC-4117-AD8E-BD4B3BBD39EA@jsasoc.com>

Hi R Experts,

I?m using R version 3.4.3 running under Linux on an AWS EC2 instance.  I have an R code listening on a port for a socket connection which passes incoming data to a function the results of which are then passed back to the calling machine.  Here?s the function that listens for a socket connection:

# define server function
server <- function() {	
  while(TRUE){
 	con <- socketConnection(host="localhost", port = server_port, blocking=TRUE,
                            server=TRUE, open="r+", timeout = 100000000)    
    	data <- readLines(con, 1L, skipNul = T, ok = T)
    	response <- check(data)    
    	if (!is.null(response)) writeLines(response, con)
  }
}

The server function expects to receive a character string which is then passed to the function check().  check() is a large, complex routine which does text analysis and many other things and returns a JSON string to be passed back to the calling machine.  

This all works perfectly except that while check() spends ~50ms doing its stuff no more requests can be received and processed. Therefore if a new request comes in sooner than ~50ms after the last one, it is not processed. I would therefore like to parallelize this so that the box can be running more than one check() process simulatanously.  I?m familar with several of the paralyzing R packages but I cannot see how to integrate them with the socket connection side of things.  

Currently I have a kludge which is a round-robin approach to solving the problem.  I have 4 versions of the whole R code listening on 4 different ports, say P1, P2, P3, P4, and the calling machine issues calls in sequence to ports P1,P2,P3,P4,P1? etc. This mitigates, but doesn?t solve, the problem.

Any advice would be greatly appreciated!  Thanks.

James 


From hp@ge@ @end|ng |rom |redhutch@org  Sun Feb  2 01:07:35 2020
From: hp@ge@ @end|ng |rom |redhutch@org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Sat, 1 Feb 2020 16:07:35 -0800
Subject: [R] How to parallelize a process called by a socket connection
In-Reply-To: <60C2D8D1-4CFC-4117-AD8E-BD4B3BBD39EA@jsasoc.com>
References: <CAGjf1cN=wBJcZONcYtYgBa4kHgSnpbhC05wBmQ__Kgnu04j=Kw@mail.gmail.com>
 <60C2D8D1-4CFC-4117-AD8E-BD4B3BBD39EA@jsasoc.com>
Message-ID: <cd46b920-fc45-19b1-3075-9e8a73df7e0b@fredhutch.org>

Seems like you've replied to an existing thread to ask a new question 
(your post gets buried deep inside the "How to extract or sort values 
from one column" thread in my Thunderbird). Unfortunately this means 
that a lot of people who might be able to help you will miss it.

H.


On 2/1/20 11:24, James Spottiswoode wrote:
> Hi R Experts,
> 
> I?m using R version 3.4.3 running under Linux on an AWS EC2 instance.  I have an R code listening on a port for a socket connection which passes incoming data to a function the results of which are then passed back to the calling machine.  Here?s the function that listens for a socket connection:
> 
> # define server function
> server <- function() {	
>    while(TRUE){
>   	con <- socketConnection(host="localhost", port = server_port, blocking=TRUE,
>                              server=TRUE, open="r+", timeout = 100000000)
>      	data <- readLines(con, 1L, skipNul = T, ok = T)
>      	response <- check(data)
>      	if (!is.null(response)) writeLines(response, con)
>    }
> }
> 
> The server function expects to receive a character string which is then passed to the function check().  check() is a large, complex routine which does text analysis and many other things and returns a JSON string to be passed back to the calling machine.
> 
> This all works perfectly except that while check() spends ~50ms doing its stuff no more requests can be received and processed. Therefore if a new request comes in sooner than ~50ms after the last one, it is not processed. I would therefore like to parallelize this so that the box can be running more than one check() process simulatanously.  I?m familar with several of the paralyzing R packages but I cannot see how to integrate them with the socket connection side of things.
> 
> Currently I have a kludge which is a round-robin approach to solving the problem.  I have 4 versions of the whole R code listening on 4 different ports, say P1, P2, P3, P4, and the calling machine issues calls in sequence to ports P1,P2,P3,P4,P1? etc. This mitigates, but doesn?t solve, the problem.
> 
> Any advice would be greatly appreciated!  Thanks.
> 
> James
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=2N70kU171QMzQHhg6A9N3op5jqv8uCm9-njqZfPW3Ok&s=h4ZzqcZ-uTxQeMUcI1l7nHEQHY-Vn-EQsKH83fU7B3s&e=
> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=2N70kU171QMzQHhg6A9N3op5jqv8uCm9-njqZfPW3Ok&s=GgmKzz9H7MAj3iy7Pu4U0q5v02Fumnl3hjxug2SY1zk&e=
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From kry|ov@r00t @end|ng |rom gm@||@com  Sun Feb  2 10:12:12 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sun, 2 Feb 2020 12:12:12 +0300
Subject: [R] How to parallelize a process called by a socket connection
In-Reply-To: <60C2D8D1-4CFC-4117-AD8E-BD4B3BBD39EA@jsasoc.com>
References: <CAGjf1cN=wBJcZONcYtYgBa4kHgSnpbhC05wBmQ__Kgnu04j=Kw@mail.gmail.com>
 <60C2D8D1-4CFC-4117-AD8E-BD4B3BBD39EA@jsasoc.com>
Message-ID: <20200202121212.4f8e8790@Tarkus>

On Sat, 1 Feb 2020 11:24:51 -0800
James Spottiswoode <james at jsasoc.com> wrote:

>   while(TRUE){
>  	con <- socketConnection(host="localhost", port =
> server_port, blocking=TRUE, server=TRUE, open="r+", timeout =
> 100000000)
>       data <- readLines(con, 1L, skipNul = T, ok = T)
>     	response <- check(data)    
>     	if (!is.null(response)) writeLines(response, con)
>   }

> This all works perfectly except that while check() spends ~50ms doing
> its stuff no more requests can be received and processed.

This poses an interesting challenge.

Normally, a single-threaded server would call listen(socket, backlog)
[1] with backlog > 1, so that other clients attempting to connect() can
wait in the queue while the server calls accept() in a loop and handles
them one by one. Unfortunately, R socketConnection()s are single-client
only, since R closes the listen()ing helper socket immediately after
accept()ing the first client [2].

A quick and dirty hack would be to modify utils::make.socket (and use
read.socket()/write.socket() instead of readLines()/writeLines()),
omitting the check for "localhost" and .Call(C_sockclose, tmp) at the
end of if(server) branch. (Instead, the socket called "tmp" should be
kept and the code should loop on .Call(C_socklisten, tmp) to process all
clients.) I cannot in recommend this in good faith as a long-term
solution, since all involved APIs are private and should not be
depended upon.

Some code from the svSocket package [3] could be repurposed to rely on
the Tcl/Tk event loop to handle multiple clients on a singe server
socket, but implementing that would require knowledge of Tcl. If you
can afford to change the clients to use the HTTP protocol, you can use
the httpuv package [4] to handle the connection management and HTTP
request parsing for you.

Besides that, I don't see a way to handle multiple clients with a single
server socket in R. I must be missing something.

-- 
Best regards,
Ivan

[1] https://beej.us/guide/bgnet/html/#listen

[2]
https://github.com/wch/r-source/blob/07c17042d9e198319a425df726cc80545ae69812/src/modules/internet/sockconn.c#L77

[3] https://cran.r-project.org/package=svSocket

[4] https://cran.r-project.org/package=httpuv


From |e||xb||nd @end|ng |rom gm@||@com  Sun Feb  2 22:01:03 2020
From: |e||xb||nd @end|ng |rom gm@||@com (Felix Blind)
Date: Sun, 2 Feb 2020 22:01:03 +0100
Subject: [R] [FORGED] Re: Executing an R script and show the plots.
In-Reply-To: <CAB8pepyXPhHwfogXVKHhDg9Gv5xWtoX_tcDqh_7G53-HYX5iDA@mail.gmail.com>
References: <a50426d5-a130-649d-f378-34e274a94b39@gmail.com>
 <2d570566-88bc-1676-8168-caba718c92e6@comcast.net>
 <CF7D7DC8-AA44-4945-AAE6-DE41FA3D3C24@som.umaryland.edu>
 <b1edacbd-2ddb-aaaa-2a4d-72bb63305c03@auckland.ac.nz>
 <24e59421-1b78-722f-70cb-921c2c137d68@gmail.com>
 <CAB8pepyKhJ7V6tkbHTr7cf7iTSLXVrFaEB0Jmapm87azbkW5nQ@mail.gmail.com>
 <CAB8pepzB5zxq9dvfCidocQfT1UadTQW2H+Pao4QkE9d6HmvKhA@mail.gmail.com>
 <a0da8f4c-ef8d-bd6b-4882-e76f3b8f18ef@gmail.com>
 <CAB8pepy3i5_+042r_8VXDwcpmSpJY6BWePk=52Z_FLEXpreytg@mail.gmail.com>
 <CAB8pepyXPhHwfogXVKHhDg9Gv5xWtoX_tcDqh_7G53-HYX5iDA@mail.gmail.com>
Message-ID: <aae986b9-3d5c-00cf-465e-508e4a79d964@gmail.com>

Thanks all for your solutions.

I like the setup best where I startup an xserver connection and then
halting the script with readlines.
I want to write and run small scripts and that seems to me the nearest
to a leightweight solution to the problem in R.

Kind regards,
Felix

On 1/30/20 7:15 AM, Abby Spurdle wrote:
>> .prompt = function (pkg, fun)
>> {   fbody = character (1)
> And I've already noticed a bug.
> This isn't going too well...


From chr|@ho|d @end|ng |rom p@yctc@org  Tue Feb  4 13:07:19 2020
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Tue, 4 Feb 2020 12:07:19 +0000 (GMT)
Subject: [R] read_xlsx(readxl) apparently mangling some data input
Message-ID: <698313588.4804217.1580818039449.JavaMail.zimbra@psyctc.org>

This is a very odd error I'm hitting using read_xlsx from the readxl package (version 1.3.1) with R version 3.6.2 (2019-12-12) , platform x86_64-pc-linux-gnu (and updated Ubuntu 18.04). I have some largeish Excel spreadsheets that contain clinical data. I can't share the entire raw data but I think I can share the specific problem columns as Excel files, but not via the list as I'm sure it rightly rejects such attachments. 

The particular column contains entries like
1
1, 14

1.14

That's to say it's a column that can have empty cells, or entries which should be integers (a limited range of them) but cells may have multiple integers and the data entry means that people use various separators, commas, full stops and occasionally semi-colons or colons and all with or without various amounts of space.  

I thought this would be easy to handle but this illustrates the issue I'm hitting:

> unique(read_xlsx("Book1.xlsx", col_types = "text"))
# A tibble: 18 x 1                                                                                                                                                            
   NOWARN            
   <chr>             
 1 NA                
 2 14                
 3 8,12,14           
 4 13                
 5 58                
 6 9                 
 7 9.1300000000000008
 8 11                
 9 11.14             
10 10                
11 10.14             
12 9.14              
13 13.14             
14 9 ,13             
15 9.11              
16 1                 
17 1.1399999999999999
18 1, 14          

That's reading from a single column, 981 row (including column header) Excel xlsx file in an up to date Windoze 10 Professional running in a VM on the Ubuntu machine. 

I created that file (which I can share) by copying the data from the full file to a new Excel spreadsheet (M$ Orifice "Professional Plus 2019" "Version 1912" "Build 12325.20344 Click-to-run" to an empty new Excel file and using the default save_as.  The clinical data files were created in, and updated in, versions of Excel that I can't access but the file was certainly created first between two years and three months before now so probably with different versions of Excel and probably in a Spanish or Catalan M$ locale.  

The weird thing is that looking at the Excel cells that created those "9.1300000000000008" and "1.1399999999999999" entries they show "9.13" and "1.14" (respectively!).  They continue to show those values plus many trailing zeroes if I use Excel formatting to ask for 20 decimal places (I get less of course, but no arbitrary terminal rounding digit).  

It appears to me that read_xlxs() is only applying the "col_types = "text"" argument _after_ reading the column freely, reading each cell guessing the type by its contents and so ending up with numeric values for "9.13" and "1.14" which are then picking up rounding errors and being forced to character after that.  I say that the reading would appear to be free across all cells in the column as there are entries of "8, 12, 14" coming before these problem entries:

> tmp <- read_xlsx("Book1.xlsx", col_types = "text")
> grep("1.1399999999999999", tmp$NOWARN, fixed = TRUE)
[1] 932 948 954
> grep("9.1300000000000008", tmp$NOWARN, fixed = TRUE)
 [1]  73 189 190 271 272 390 511 645 686 710 744 830 899
> tmp$NOWARN[20]
[1] "8,12,14"

This seems completely bizarre to me.  I find it very hard to believe that read_xlsx() would guess content class (type) freely by for each individual entry and only apply the col_types argument after doing that as that would seem likely to be incredibly inefficient for really big spreadsheets. It seems equally hard to believe that it would then create rounding errors (for some guessed numerics like 9.13 and 1.14 but not for others like 11.4).  However, my guess would appear to fit the results and I am only guessing because I'm sure my programming comprehension isn't good enough to read into the sources to actually work out how the function works.

To make things more interesting, and to suggest that at least some of the problem is with Excel is that when I use LibreOffice (in Ubuntu) created a Excel file in the same way, i.e. open the clinical Excel file but in LibreOffice, copy and paste the same column into a new LibreOffice calc spreadsheet and save as xlsx, tmp.xlsx, I get this:

> unique(read_xlsx("tmp.xlsx", col_types = "text"))
# A tibble: 18 x 1                                                                                                                                                            
   NOWARN 
   <chr>  
 1 NA     
 2 14     
 3 8,12,14
 4 13     
 5 58     
 6 9      
 7 9.13   
 8 11     
 9 11.14  
10 10     
11 10.14  
12 9.14   
13 13.14  
14 9 ,13  
15 9.11   
16 1      
17 1.14   
18 1, 14  

Exactly what I think I should be seeing. I was working in Rstudio but get exactly the same in a new R terminal session with only readxl loaded so I don't think this is any weird environment or other clash.

Obviously I can, though not terribly easily for a fully generic fix, catch these weird rounding errors and correct them, I am sure can also report this as a suspected bug to the maintainer through the github issues system but I wanted to check here whether anyone could see something I'm missing as I'm really a (clinically retired) therapist and doctor, now full time researcher and I'm not a professional statistician or programmer.

TIA,

Chris



-- 
Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
That page will also take you to my blog which started with earlier joys in France and Spain!

If you want to book to talk, I am trying to keep that to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Feb  4 13:39:31 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 4 Feb 2020 12:39:31 +0000
Subject: [R] read_xlsx(readxl) apparently mangling some data input
In-Reply-To: <698313588.4804217.1580818039449.JavaMail.zimbra@psyctc.org>
References: <698313588.4804217.1580818039449.JavaMail.zimbra@psyctc.org>
Message-ID: <68aa6a63cbfa4c008625851a5e420bb2@SRVEXCHCM1302.precheza.cz>

Hi

Floating point representation

I prepared excel file with arbitrary first row and second row

45.65 and 45.65/5

The division result should be 9.13 (exactly), but based on floation point
representation in binary computers (FAQ 7.31) it results in 9.129999999...
However Excel shows exact value (9.13) although internally it stores this
9.129999.. Probably they do not want to disturb its audience.

Therefore read_xlsx reads it correctly

> temp <- read_xlsx(file.choose())
> temp
# A tibble: 2 x 2
     a1 a2               
  <dbl> <chr>            
1  12   8,8,10           
2  45.6 9.129999999999999
> as.data.frame(temp)
     a1                a2
1 12.00            8,8,10
2 45.65 9.129999999999999

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Chris Evans
> Sent: Tuesday, February 4, 2020 1:07 PM
> To: R-help Mailing List <r-help at r-project.org>
> Subject: [R] read_xlsx(readxl) apparently mangling some data input
> 
> This is a very odd error I'm hitting using read_xlsx from the readxl
package
> (version 1.3.1) with R version 3.6.2 (2019-12-12) , platform
x86_64-pc-linux-
> gnu (and updated Ubuntu 18.04). I have some largeish Excel spreadsheets
> that contain clinical data. I can't share the entire raw data but I think
I can
> share the specific problem columns as Excel files, but not via the list as
I'm
> sure it rightly rejects such attachments.
> 
> The particular column contains entries like
> 1
> 1, 14
> 
> 1.14
> 
> That's to say it's a column that can have empty cells, or entries which
should
> be integers (a limited range of them) but cells may have multiple integers
> and the data entry means that people use various separators, commas, full
> stops and occasionally semi-colons or colons and all with or without
various
> amounts of space.
> 
> I thought this would be easy to handle but this illustrates the issue I'm
> hitting:
> 
> > unique(read_xlsx("Book1.xlsx", col_types = "text"))
> # A tibble: 18 x 1
>    NOWARN
>    <chr>
>  1 NA
>  2 14
>  3 8,12,14
>  4 13
>  5 58
>  6 9
>  7 9.1300000000000008
>  8 11
>  9 11.14
> 10 10
> 11 10.14
> 12 9.14
> 13 13.14
> 14 9 ,13
> 15 9.11
> 16 1
> 17 1.1399999999999999
> 18 1, 14
> 
> That's reading from a single column, 981 row (including column header)
> Excel xlsx file in an up to date Windoze 10 Professional running in a VM
on
> the Ubuntu machine.
> 
> I created that file (which I can share) by copying the data from the full
file to
> a new Excel spreadsheet (M$ Orifice "Professional Plus 2019" "Version
1912"
> "Build 12325.20344 Click-to-run" to an empty new Excel file and using the
> default save_as.  The clinical data files were created in, and updated in,
> versions of Excel that I can't access but the file was certainly created
first
> between two years and three months before now so probably with different
> versions of Excel and probably in a Spanish or Catalan M$ locale.
> 
> The weird thing is that looking at the Excel cells that created those
> "9.1300000000000008" and "1.1399999999999999" entries they show "9.13"
> and "1.14" (respectively!).  They continue to show those values plus many
> trailing zeroes if I use Excel formatting to ask for 20 decimal places (I
get less
> of course, but no arbitrary terminal rounding digit).
> 
> It appears to me that read_xlxs() is only applying the "col_types =
"text""
> argument _after_ reading the column freely, reading each cell guessing the
> type by its contents and so ending up with numeric values for "9.13" and
> "1.14" which are then picking up rounding errors and being forced to
> character after that.  I say that the reading would appear to be free
across all
> cells in the column as there are entries of "8, 12, 14" coming before
these
> problem entries:
> 
> > tmp <- read_xlsx("Book1.xlsx", col_types = "text")
> > grep("1.1399999999999999", tmp$NOWARN, fixed = TRUE)
> [1] 932 948 954
> > grep("9.1300000000000008", tmp$NOWARN, fixed = TRUE)
>  [1]  73 189 190 271 272 390 511 645 686 710 744 830 899
> > tmp$NOWARN[20]
> [1] "8,12,14"
> 
> This seems completely bizarre to me.  I find it very hard to believe that
> read_xlsx() would guess content class (type) freely by for each individual
> entry and only apply the col_types argument after doing that as that would
> seem likely to be incredibly inefficient for really big spreadsheets. It
seems
> equally hard to believe that it would then create rounding errors (for
some
> guessed numerics like 9.13 and 1.14 but not for others like 11.4).
However,
> my guess would appear to fit the results and I am only guessing because
I'm
> sure my programming comprehension isn't good enough to read into the
> sources to actually work out how the function works.
> 
> To make things more interesting, and to suggest that at least some of the
> problem is with Excel is that when I use LibreOffice (in Ubuntu) created a
> Excel file in the same way, i.e. open the clinical Excel file but in
LibreOffice,
> copy and paste the same column into a new LibreOffice calc spreadsheet
> and save as xlsx, tmp.xlsx, I get this:
> 
> > unique(read_xlsx("tmp.xlsx", col_types = "text"))
> # A tibble: 18 x 1
>    NOWARN
>    <chr>
>  1 NA
>  2 14
>  3 8,12,14
>  4 13
>  5 58
>  6 9
>  7 9.13
>  8 11
>  9 11.14
> 10 10
> 11 10.14
> 12 9.14
> 13 13.14
> 14 9 ,13
> 15 9.11
> 16 1
> 17 1.14
> 18 1, 14
> 
> Exactly what I think I should be seeing. I was working in Rstudio but get
> exactly the same in a new R terminal session with only readxl loaded so I
> don't think this is any weird environment or other clash.
> 
> Obviously I can, though not terribly easily for a fully generic fix, catch
these
> weird rounding errors and correct them, I am sure can also report this as
a
> suspected bug to the maintainer through the github issues system but I
> wanted to check here whether anyone could see something I'm missing as
> I'm really a (clinically retired) therapist and doctor, now full time
researcher
> and I'm not a professional statistician or programmer.
> 
> TIA,
> 
> Chris
> 
> 
> 
> --
> Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield
> <chris.evans at sheffield.ac.uk> I do some consultation work for the
> University of Roehampton <chris.evans at roehampton.ac.uk> and other
> places but <chris at psyctc.org> remains my main Email address.  I have a
> work web site at:
>    https://www.psyctc.org/psyctc/
> and a site I manage for CORE and CORE system trust at:
>    http://www.coresystemtrust.org.uk/
> I have "semigrated" to France, see:
>    https://www.psyctc.org/pelerinage2016/semigrating-to-france/
> That page will also take you to my blog which started with earlier joys in
> France and Spain!
> 
> If you want to book to talk, I am trying to keep that to Thursdays and my
> diary is at:
>    https://www.psyctc.org/pelerinage2016/ceworkdiary/
> Beware: French time, generally an hour ahead of UK.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From pd@|gd @end|ng |rom gm@||@com  Tue Feb  4 14:01:58 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 4 Feb 2020 14:01:58 +0100
Subject: [R] read_xlsx(readxl) apparently mangling some data input
In-Reply-To: <698313588.4804217.1580818039449.JavaMail.zimbra@psyctc.org>
References: <698313588.4804217.1580818039449.JavaMail.zimbra@psyctc.org>
Message-ID: <A3E5A8C4-00CE-4DFA-95E8-42C18838EDB1@gmail.com>

Excel itself will store numeric data as numeric unless you explicitly say that they are not. I.e., 9.13 gest stored in floating point, with the innate binary rounding issues which you can also see from R

> print(9.13, digits=20)
[1] 9.1300000000000007816
> print(1.14, digits=20)
[1] 1.1399999999999999023

This happens on a per-cell basis inside Excel, and the excess digits are probably retained in .xlsx files (which, as far as I recall, are text-based, XML format files). LibreOffice probably keeps fewer significant digits.

So read_xlsx just reads what is in the file, and if instructed to read as text, gets you the result that you see. There seems to be no way so set a tolerance for rounding (which would also logically be a peculiar thing to do as it requires char -> num -> char conversion in ways that may or may not be what the user wants)

Pragmatically, I think you need to jump through a few hoops, something like

x <- tbl$NOWARN
xn <- as.numeric(x)
ix <- !(is.na(xn)) & xn%%1 != 0
x[ix] <- as.character(xn[ix])

(possibly throw in a zapsmall(), caveat emptor). Then proceed as per the original plan.

-pd

> On 4 Feb 2020, at 13:07 , Chris Evans <chrishold at psyctc.org> wrote:
> 
> This is a very odd error I'm hitting using read_xlsx from the readxl package (version 1.3.1) with R version 3.6.2 (2019-12-12) , platform x86_64-pc-linux-gnu (and updated Ubuntu 18.04). I have some largeish Excel spreadsheets that contain clinical data. I can't share the entire raw data but I think I can share the specific problem columns as Excel files, but not via the list as I'm sure it rightly rejects such attachments. 
> 
> The particular column contains entries like
> 1
> 1, 14
> 
> 1.14
> 
> That's to say it's a column that can have empty cells, or entries which should be integers (a limited range of them) but cells may have multiple integers and the data entry means that people use various separators, commas, full stops and occasionally semi-colons or colons and all with or without various amounts of space.  
> 
> I thought this would be easy to handle but this illustrates the issue I'm hitting:
> 
>> unique(read_xlsx("Book1.xlsx", col_types = "text"))
> # A tibble: 18 x 1                                                                                                                                                            
>   NOWARN            
>   <chr>             
> 1 NA                
> 2 14                
> 3 8,12,14           
> 4 13                
> 5 58                
> 6 9                 
> 7 9.1300000000000008
> 8 11                
> 9 11.14             
> 10 10                
> 11 10.14             
> 12 9.14              
> 13 13.14             
> 14 9 ,13             
> 15 9.11              
> 16 1                 
> 17 1.1399999999999999
> 18 1, 14          
> 
> That's reading from a single column, 981 row (including column header) Excel xlsx file in an up to date Windoze 10 Professional running in a VM on the Ubuntu machine. 
> 
> I created that file (which I can share) by copying the data from the full file to a new Excel spreadsheet (M$ Orifice "Professional Plus 2019" "Version 1912" "Build 12325.20344 Click-to-run" to an empty new Excel file and using the default save_as.  The clinical data files were created in, and updated in, versions of Excel that I can't access but the file was certainly created first between two years and three months before now so probably with different versions of Excel and probably in a Spanish or Catalan M$ locale.  
> 
> The weird thing is that looking at the Excel cells that created those "9.1300000000000008" and "1.1399999999999999" entries they show "9.13" and "1.14" (respectively!).  They continue to show those values plus many trailing zeroes if I use Excel formatting to ask for 20 decimal places (I get less of course, but no arbitrary terminal rounding digit).  
> 
> It appears to me that read_xlxs() is only applying the "col_types = "text"" argument _after_ reading the column freely, reading each cell guessing the type by its contents and so ending up with numeric values for "9.13" and "1.14" which are then picking up rounding errors and being forced to character after that.  I say that the reading would appear to be free across all cells in the column as there are entries of "8, 12, 14" coming before these problem entries:
> 
>> tmp <- read_xlsx("Book1.xlsx", col_types = "text")
>> grep("1.1399999999999999", tmp$NOWARN, fixed = TRUE)
> [1] 932 948 954
>> grep("9.1300000000000008", tmp$NOWARN, fixed = TRUE)
> [1]  73 189 190 271 272 390 511 645 686 710 744 830 899
>> tmp$NOWARN[20]
> [1] "8,12,14"
> 
> This seems completely bizarre to me.  I find it very hard to believe that read_xlsx() would guess content class (type) freely by for each individual entry and only apply the col_types argument after doing that as that would seem likely to be incredibly inefficient for really big spreadsheets. It seems equally hard to believe that it would then create rounding errors (for some guessed numerics like 9.13 and 1.14 but not for others like 11.4).  However, my guess would appear to fit the results and I am only guessing because I'm sure my programming comprehension isn't good enough to read into the sources to actually work out how the function works.
> 
> To make things more interesting, and to suggest that at least some of the problem is with Excel is that when I use LibreOffice (in Ubuntu) created a Excel file in the same way, i.e. open the clinical Excel file but in LibreOffice, copy and paste the same column into a new LibreOffice calc spreadsheet and save as xlsx, tmp.xlsx, I get this:
> 
>> unique(read_xlsx("tmp.xlsx", col_types = "text"))
> # A tibble: 18 x 1                                                                                                                                                            
>   NOWARN 
>   <chr>  
> 1 NA     
> 2 14     
> 3 8,12,14
> 4 13     
> 5 58     
> 6 9      
> 7 9.13   
> 8 11     
> 9 11.14  
> 10 10     
> 11 10.14  
> 12 9.14   
> 13 13.14  
> 14 9 ,13  
> 15 9.11   
> 16 1      
> 17 1.14   
> 18 1, 14  
> 
> Exactly what I think I should be seeing. I was working in Rstudio but get exactly the same in a new R terminal session with only readxl loaded so I don't think this is any weird environment or other clash.
> 
> Obviously I can, though not terribly easily for a fully generic fix, catch these weird rounding errors and correct them, I am sure can also report this as a suspected bug to the maintainer through the github issues system but I wanted to check here whether anyone could see something I'm missing as I'm really a (clinically retired) therapist and doctor, now full time researcher and I'm not a professional statistician or programmer.
> 
> TIA,
> 
> Chris
> 
> 
> 
> -- 
> Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
> I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
> but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
>   https://www.psyctc.org/psyctc/
> and a site I manage for CORE and CORE system trust at:
>   http://www.coresystemtrust.org.uk/
> I have "semigrated" to France, see: 
>   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
> That page will also take you to my blog which started with earlier joys in France and Spain!
> 
> If you want to book to talk, I am trying to keep that to Thursdays and my diary is at:
>   https://www.psyctc.org/pelerinage2016/ceworkdiary/
> Beware: French time, generally an hour ahead of UK.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From chr|@ho|d @end|ng |rom p@yctc@org  Tue Feb  4 14:56:21 2020
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Tue, 4 Feb 2020 13:56:21 +0000 (GMT)
Subject: [R] read_xlsx(readxl) apparently mangling some data input
In-Reply-To: <68aa6a63cbfa4c008625851a5e420bb2@SRVEXCHCM1302.precheza.cz>
References: <698313588.4804217.1580818039449.JavaMail.zimbra@psyctc.org>
 <68aa6a63cbfa4c008625851a5e420bb2@SRVEXCHCM1302.precheza.cz>
Message-ID: <1986285262.4937692.1580824581371.JavaMail.zimbra@psyctc.org>

This list can be priceless (and has taught me so much over, hm, over a decade certainly now!)

Thanks both: makes perfect sense (of course) and shows my naivety in the way I was thinking about this.  
I'm intrigued that it's LibreOffice actually using lower precision that avoids the issue that was 
puzzling me, again, makes perfect sense.

Further, Peter's 
   ix <- !(is.na(xn)) & xn%%1 != 0
is delicious and exactly the sort of thing I don't see unaided.  I know I would have done something 
horribly more clumsy.  It's also the sort of little revelation about the potential power of %% that
I think I _will_ remember and no doubt find myself using again in the future.

Thanks both, huge help to me and, as I suspected, a wasteful github issue report prevented!

Chris

----- Original Message -----
> From: "PIKAL Petr" <petr.pikal at precheza.cz>
> To: "Chris Evans" <chrishold at psyctc.org>, "R-help Mailing List" <r-help at r-project.org>
> Sent: Tuesday, 4 February, 2020 13:39:31
> Subject: RE: read_xlsx(readxl) apparently mangling some data input

> Hi
> 
> Floating point representation
> 
> I prepared excel file with arbitrary first row and second row
> 
> 45.65 and 45.65/5
> 
> The division result should be 9.13 (exactly), but based on floation point
> representation in binary computers (FAQ 7.31) it results in 9.129999999...
> However Excel shows exact value (9.13) although internally it stores this
> 9.129999.. Probably they do not want to disturb its audience.
> 
> Therefore read_xlsx reads it correctly
> 
>> temp <- read_xlsx(file.choose())
>> temp
> # A tibble: 2 x 2
>     a1 a2
>  <dbl> <chr>
> 1  12   8,8,10
> 2  45.6 9.129999999999999
>> as.data.frame(temp)
>     a1                a2
> 1 12.00            8,8,10
> 2 45.65 9.129999999999999
> 
> Cheers
> Petr
> 
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Chris Evans
>> Sent: Tuesday, February 4, 2020 1:07 PM
>> To: R-help Mailing List <r-help at r-project.org>
>> Subject: [R] read_xlsx(readxl) apparently mangling some data input
>> 
>> This is a very odd error I'm hitting using read_xlsx from the readxl
> package
>> (version 1.3.1) with R version 3.6.2 (2019-12-12) , platform
> x86_64-pc-linux-
>> gnu (and updated Ubuntu 18.04). I have some largeish Excel spreadsheets
>> that contain clinical data. I can't share the entire raw data but I think
> I can
>> share the specific problem columns as Excel files, but not via the list as
> I'm
>> sure it rightly rejects such attachments.
>> 
>> The particular column contains entries like
>> 1
>> 1, 14
>> 
>> 1.14
>> 
>> That's to say it's a column that can have empty cells, or entries which
> should
>> be integers (a limited range of them) but cells may have multiple integers
>> and the data entry means that people use various separators, commas, full
>> stops and occasionally semi-colons or colons and all with or without
> various
>> amounts of space.
>> 
>> I thought this would be easy to handle but this illustrates the issue I'm
>> hitting:
>> 
>> > unique(read_xlsx("Book1.xlsx", col_types = "text"))
>> # A tibble: 18 x 1
>>    NOWARN
>>    <chr>
>>  1 NA
>>  2 14
>>  3 8,12,14
>>  4 13
>>  5 58
>>  6 9
>>  7 9.1300000000000008
>>  8 11
>>  9 11.14
>> 10 10
>> 11 10.14
>> 12 9.14
>> 13 13.14
>> 14 9 ,13
>> 15 9.11
>> 16 1
>> 17 1.1399999999999999
>> 18 1, 14
>> 
>> That's reading from a single column, 981 row (including column header)
>> Excel xlsx file in an up to date Windoze 10 Professional running in a VM
> on
>> the Ubuntu machine.
>> 
>> I created that file (which I can share) by copying the data from the full
> file to
>> a new Excel spreadsheet (M$ Orifice "Professional Plus 2019" "Version
> 1912"
>> "Build 12325.20344 Click-to-run" to an empty new Excel file and using the
>> default save_as.  The clinical data files were created in, and updated in,
>> versions of Excel that I can't access but the file was certainly created
> first
>> between two years and three months before now so probably with different
>> versions of Excel and probably in a Spanish or Catalan M$ locale.
>> 
>> The weird thing is that looking at the Excel cells that created those
>> "9.1300000000000008" and "1.1399999999999999" entries they show "9.13"
>> and "1.14" (respectively!).  They continue to show those values plus many
>> trailing zeroes if I use Excel formatting to ask for 20 decimal places (I
> get less
>> of course, but no arbitrary terminal rounding digit).
>> 
>> It appears to me that read_xlxs() is only applying the "col_types =
> "text""
>> argument _after_ reading the column freely, reading each cell guessing the
>> type by its contents and so ending up with numeric values for "9.13" and
>> "1.14" which are then picking up rounding errors and being forced to
>> character after that.  I say that the reading would appear to be free
> across all
>> cells in the column as there are entries of "8, 12, 14" coming before
> these
>> problem entries:
>> 
>> > tmp <- read_xlsx("Book1.xlsx", col_types = "text")
>> > grep("1.1399999999999999", tmp$NOWARN, fixed = TRUE)
>> [1] 932 948 954
>> > grep("9.1300000000000008", tmp$NOWARN, fixed = TRUE)
>>  [1]  73 189 190 271 272 390 511 645 686 710 744 830 899
>> > tmp$NOWARN[20]
>> [1] "8,12,14"
>> 
>> This seems completely bizarre to me.  I find it very hard to believe that
>> read_xlsx() would guess content class (type) freely by for each individual
>> entry and only apply the col_types argument after doing that as that would
>> seem likely to be incredibly inefficient for really big spreadsheets. It
> seems
>> equally hard to believe that it would then create rounding errors (for
> some
>> guessed numerics like 9.13 and 1.14 but not for others like 11.4).
> However,
>> my guess would appear to fit the results and I am only guessing because
> I'm
>> sure my programming comprehension isn't good enough to read into the
>> sources to actually work out how the function works.
>> 
>> To make things more interesting, and to suggest that at least some of the
>> problem is with Excel is that when I use LibreOffice (in Ubuntu) created a
>> Excel file in the same way, i.e. open the clinical Excel file but in
> LibreOffice,
>> copy and paste the same column into a new LibreOffice calc spreadsheet
>> and save as xlsx, tmp.xlsx, I get this:
>> 
>> > unique(read_xlsx("tmp.xlsx", col_types = "text"))
>> # A tibble: 18 x 1
>>    NOWARN
>>    <chr>
>>  1 NA
>>  2 14
>>  3 8,12,14
>>  4 13
>>  5 58
>>  6 9
>>  7 9.13
>>  8 11
>>  9 11.14
>> 10 10
>> 11 10.14
>> 12 9.14
>> 13 13.14
>> 14 9 ,13
>> 15 9.11
>> 16 1
>> 17 1.14
>> 18 1, 14
>> 
>> Exactly what I think I should be seeing. I was working in Rstudio but get
>> exactly the same in a new R terminal session with only readxl loaded so I
>> don't think this is any weird environment or other clash.
>> 
>> Obviously I can, though not terribly easily for a fully generic fix, catch
> these
>> weird rounding errors and correct them, I am sure can also report this as
> a
>> suspected bug to the maintainer through the github issues system but I
>> wanted to check here whether anyone could see something I'm missing as
>> I'm really a (clinically retired) therapist and doctor, now full time
> researcher
>> and I'm not a professional statistician or programmer.
>> 
>> TIA,
>> 
>> Chris
>> 
>> 
>> 
>> --
>> Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield
>> <chris.evans at sheffield.ac.uk> I do some consultation work for the
>> University of Roehampton <chris.evans at roehampton.ac.uk> and other
>> places but <chris at psyctc.org> remains my main Email address.  I have a
>> work web site at:
>>    https://www.psyctc.org/psyctc/
>> and a site I manage for CORE and CORE system trust at:
>>    http://www.coresystemtrust.org.uk/
>> I have "semigrated" to France, see:
>>    https://www.psyctc.org/pelerinage2016/semigrating-to-france/
>> That page will also take you to my blog which started with earlier joys in
>> France and Spain!
>> 
>> If you want to book to talk, I am trying to keep that to Thursdays and my
>> diary is at:
>>    https://www.psyctc.org/pelerinage2016/ceworkdiary/
>> Beware: French time, generally an hour ahead of UK.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
> > and provide commented, minimal, self-contained, reproducible code.

-- 
Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
That page will also take you to my blog which started with earlier joys in France and Spain!

If you want to book to talk, I am trying to keep that to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From chr|@ho|d @end|ng |rom p@yctc@org  Tue Feb  4 15:18:29 2020
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Tue, 4 Feb 2020 14:18:29 +0000 (GMT)
Subject: [R] read_xlsx(readxl) apparently mangling some data input
In-Reply-To: <4398abfd-ad02-4d41-80bc-ee3ac6f86860@email.android.com>
References: <4398abfd-ad02-4d41-80bc-ee3ac6f86860@email.android.com>
Message-ID: <384735492.4959603.1580825909664.JavaMail.zimbra@psyctc.org>

Thanks. Probably should have said that the spreadsheets were originally created with the type of the data carefully defined to try to minimise 
mess (though I hadn't foreseen this little issue). Unfortunately that formatting has clearly been overridden in at least some of the data collection 
sites since then. 

I have just rechecked and setting the format of the column from row 2 to the end as "text" in Excel does, as you'd hope, prevent Excel converting 
"9.13" being converted to numeric with the, I now realise, inevitable rounding consequence. Clearly the spreadsheets have had formatting overridden
at the data collection sites which created this problem. 

Maybe there's a way in Excel to allow end users to enter data but not change the formatting. Yes, for anyone following this for whom it might be useful,
you can do this and clearly I should have done: 
   https://www.extendoffice.com/documents/excel/1277-excel-protect-format.html

While I'm going a bit off piste or OT here, but following this line, does anyone recommend an open source online data entry and validation system that
can have a multidimensional database structure?  I'm trying to move things from Excel to LimeSurvey which isn't all that friendly but seems powerful, 
genuinely FLOSS and has proved very reliable, fast and stable for our purposes.  However, I don't think it can be adapted from flat form data to RMDBS
form data.  Any good options out there?

Thanks cpolwart and also TIA if anyone has suggestions for that tangential question (to me off list and I'll summarise if there's much and people 
asking for it).

Chris

----- Original Message -----
> From: cpolwart at chemo.org.uk
> To: "Chris Evans" <chrishold at psyctc.org>
> Cc: "R-help Mailing List" <r-help at r-project.org>
> Sent: Tuesday, 4 February, 2020 13:32:20
> Subject: Re: [R] read_xlsx(readxl) apparently mangling some data input

> This may not be possible or practical, bit can you tell excel it's a character.
> The normal method of doing that is to add an ' at the front of the cell. So in
> Excel say column G has the "numbers" in column Z you create a new row with ="'"
> & TEXT (G1)
> (Untested)

> Then use column Z in R.

> The other question might be simply how each cell is formatted. It you have
> people using any character to seperate numbers I bet some cells are formatted
> as text and some as numbers... Hence R may be respecting that.

> Other thoughts would be to clean it in excel (a horrific thought but something
> like

> = REPLACE ( TEXT (G1), SEARCH (".", TEXT (G1)), 1, ";" )

> Would replace first dot with ; meaning it won't look like a number. You'd still
> have second dots but you can address that in R

> Paste values only and format as text (general) could help test that.

> The "rounding" issue is caused by R treating it as a floating point number as
> binary then converting it. You may already be aware of that. Once R thinks it
> is as.numeric(9.13) you can't stop that. So you need R never to think it is
> numeric.

> On 4 Feb 2020 12:07, Chris Evans <chrishold at psyctc.org> wrote:

>> This is a very odd error I'm hitting using read_xlsx from the readxl package
>> (version 1.3.1) with R version 3.6.2 (2019-12-12) , platform
>> x86_64-pc-linux-gnu (and updated Ubuntu 18.04). I have some largeish Excel
>> spreadsheets that contain clinical data. I can't share the entire raw data but
>> I think I can share the specific problem columns as Excel files, but not via
>> the list as I'm sure it rightly rejects such attachments.

>> The particular column contains entries like
>> 1
>> 1, 14

>> 1.14

>> That's to say it's a column that can have empty cells, or entries which should
>> be integers (a limited range of them) but cells may have multiple integers and
>> the data entry means that people use various separators, commas, full stops and
>> occasionally semi-colons or colons and all with or without various amounts of
>> space.

>> I thought this would be easy to handle but this illustrates the issue I'm
>> hitting:

>> > unique(read_xlsx("Book1.xlsx", col_types = "text"))
>> # A tibble: 18 x 1
>> NOWARN
>> <chr>
>> 1 NA
>> 2 14
>> 3 8,12,14
>> 4 13
>> 5 58
>> 6 9
>> 7 9.1300000000000008
>> 8 11
>> 9 11.14
>> 10 10
>> 11 10.14
>> 12 9.14
>> 13 13.14
>> 14 9 ,13
>> 15 9.11
>> 16 1
>> 17 1.1399999999999999
>> 18 1, 14

>> That's reading from a single column, 981 row (including column header) Excel
>> xlsx file in an up to date Windoze 10 Professional running in a VM on the
>> Ubuntu machine.

>> I created that file (which I can share) by copying the data from the full file
>> to a new Excel spreadsheet (M$ Orifice "Professional Plus 2019" "Version 1912"
>> "Build 12325.20344 Click-to-run" to an empty new Excel file and using the
>> default save_as. The clinical data files were created in, and updated in,
>> versions of Excel that I can't access but the file was certainly created first
>> between two years and three months before now so probably with different
>> versions of Excel and probably in a Spanish or Catalan M$ locale.

>> The weird thing is that looking at the Excel cells that created those
>> "9.1300000000000008" and "1.1399999999999999" entries they show "9.13" and
>> "1.14" (respectively!). They continue to show those values plus many trailing
>> zeroes if I use Excel formatting to ask for 20 decimal places (I get less of
>> course, but no arbitrary terminal rounding digit).

>> It appears to me that read_xlxs() is only applying the "col_types = "text""
>> argument _after_ reading the column freely, reading each cell guessing the type
>> by its contents and so ending up with numeric values for "9.13" and "1.14"
>> which are then picking up rounding errors and being forced to character after
>> that. I say that the reading would appear to be free across all cells in the
>> column as there are entries of "8, 12, 14" coming before these problem entries:

>> > tmp <- read_xlsx("Book1.xlsx", col_types = "text")
>> > grep("1.1399999999999999", tmp$NOWARN, fixed = TRUE)
>> [1] 932 948 954
>> > grep("9.1300000000000008", tmp$NOWARN, fixed = TRUE)
>> [1] 73 189 190 271 272 390 511 645 686 710 744 830 899
>> > tmp$NOWARN[20]
>> [1] "8,12,14"

>> This seems completely bizarre to me. I find it very hard to believe that
>> read_xlsx() would guess content class (type) freely by for each individual
>> entry and only apply the col_types argument after doing that as that would seem
>> likely to be incredibly inefficient for really big spreadsheets. It seems
>> equally hard to believe that it would then create rounding errors (for some
>> guessed numerics like 9.13 and 1.14 but not for others like 11.4). However, my
>> guess would appear to fit the results and I am only guessing because I'm sure
>> my programming comprehension isn't good enough to read into the sources to
>> actually work out how the function works.

>> To make things more interesting, and to suggest that at least some of the
>> problem is with Excel is that when I use LibreOffice (in Ubuntu) created a
>> Excel file in the same way, i.e. open the clinical Excel file but in
>> LibreOffice, copy and paste the same column into a new LibreOffice calc
>> spreadsheet and save as xlsx, tmp.xlsx, I get this:

>> > unique(read_xlsx("tmp.xlsx", col_types = "text"))
>> # A tibble: 18 x 1
>> NOWARN
>> <chr>
>> 1 NA
>> 2 14
>> 3 8,12,14
>> 4 13
>> 5 58
>> 6 9
>> 7 9.13
>> 8 11
>> 9 11.14
>> 10 10
>> 11 10.14
>> 12 9.14
>> 13 13.14
>> 14 9 ,13
>> 15 9.11
>> 16 1
>> 17 1.14
>> 18 1, 14

>> Exactly what I think I should be seeing. I was working in Rstudio but get
>> exactly the same in a new R terminal session with only readxl loaded so I don't
>> think this is any weird environment or other clash.

>> Obviously I can, though not terribly easily for a fully generic fix, catch these
>> weird rounding errors and correct them, I am sure can also report this as a
>> suspected bug to the maintainer through the github issues system but I wanted
>> to check here whether anyone could see something I'm missing as I'm really a
>> (clinically retired) therapist and doctor, now full time researcher and I'm not
>> a professional statistician or programmer.

>> TIA,

>> Chris

>> --
>> Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield
>> <chris.evans at sheffield.ac.uk>
>> I do some consultation work for the University of Roehampton
>> <chris.evans at roehampton.ac.uk> and other places
>> but <chris at psyctc.org> remains my main Email address. I have a work web site at:
>> https://www.psyctc.org/psyctc/
>> and a site I manage for CORE and CORE system trust at:
>> http://www.coresystemtrust.org.uk/
>> I have "semigrated" to France, see:
>> https://www.psyctc.org/pelerinage2016/semigrating-to-france/
>> That page will also take you to my blog which started with earlier joys in
>> France and Spain!

>> If you want to book to talk, I am trying to keep that to Thursdays and my diary
>> is at:
>> https://www.psyctc.org/pelerinage2016/ceworkdiary/
>> Beware: French time, generally an hour ahead of UK.

>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
That page will also take you to my blog which started with earlier joys in France and Spain!

If you want to book to talk, I am trying to keep that to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Feb  4 18:17:33 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 4 Feb 2020 11:17:33 -0600
Subject: [R] comparing variances between two sets of p values for two
 different conditions
Message-ID: <CAF9-5jO9hKPKwjeVgJX+5CApTZZ+vj7A22S770ZUhd3XnPrqxw@mail.gmail.com>

Hello,

I have a set of two conditions: individual.variance and
intra.individual.variance
with their p values.

Does it make sense to compare variances between those two groups with
F test via:

var.test(b$inter.individual.variance, b$intra.individual.variance,
alternative = "two.sided")

If not which test you would recommend in this case?

Thanks
Ana


From bgunter@4567 @end|ng |rom gm@||@com  Tue Feb  4 19:43:03 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 4 Feb 2020 10:43:03 -0800
Subject: [R] comparing variances between two sets of p values for two
 different conditions
In-Reply-To: <CAF9-5jO9hKPKwjeVgJX+5CApTZZ+vj7A22S770ZUhd3XnPrqxw@mail.gmail.com>
References: <CAF9-5jO9hKPKwjeVgJX+5CApTZZ+vj7A22S770ZUhd3XnPrqxw@mail.gmail.com>
Message-ID: <CAGxFJbQ8xsQd70DOFp5uE9GZi=mVCDwUzCnT_ubkXbQrTdbWwQ@mail.gmail.com>

Inline.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 4, 2020 at 9:12 AM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello,
>
> I have a set of two conditions: individual.variance and
> intra.individual.variance
> with their p values.
>
> Does it make sense to compare variances between those two groups with
> F test via:
>

No.


> var.test(b$inter.individual.variance, b$intra.individual.variance,
> alternative = "two.sided")
>
> If not which test you would recommend in this case?
>

As you have been told before, I believe, such questions are generally
offtopic here. For purely statistical issues, post on a statistical site
like stats.stackexchange.com



> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Feb  4 21:28:16 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 4 Feb 2020 14:28:16 -0600
Subject: [R] doing 1000 permutations and doing test statistics distribution
Message-ID: <CAF9-5jNNBhumJ3sU_n=mTk848Zr7woPtnGXMQO11qALoE_8QPw@mail.gmail.com>

Hello,

I have a matrix
> dim(dat)
[1] 15568   132

It looks like this:

                   NoD_14381_norm.1 NoD_14381_norm.2 NoD_14381_norm.3
NoD_14520_30mM.1 NoD_14520_30mM.2 NoD_14520_30mM.3
Ku8QhfS0n_hIOABXuE             4.75             4.25             4.79
           4.33             4.63             3.85
Bx496XsFXiAlj.Eaeo             6.15             6.23             6.55
           6.26             6.24             5.99
W38p0ogk.wIBVRXllY             7.13             7.35             7.55
           7.37             7.36             7.55
QIBkqIS9LR5DfTlTS8             6.27             6.73             6.45
           5.39             4.75             4.96
BZKiEvS0eQ305U0v34             6.35             7.02             6.76
           5.45             5.25             5.02
6TheVd.HiE1UF3lX6g             5.53             5.02             5.36
           5.61             5.66             5.37

So it is a matrix with gene names ex. Ku8QhfS0n_hIOABXuE, and subjects
named ex. NoD_14381_norm.1


How to do 1000 permutations of these 132 columns and on each created
new permuted matrix perform this code:

subject="all_replicate"
targets<-readTargets(paste(PhenotypeDir,"hg_sg_",subject,"_target.txt", sep=''))
Treat <- factor(targets$Treatment,levels=c("C","T"))
Replicates <- factor(targets$rep)
design <- model.matrix(~Replicates+Treat)
corfit <- duplicateCorrelation(dat, block = targets$Subject)
corfit$consensus.correlation
fit <-lmFit(dat,design,block=targets$Subject,correlation=corfit$consensus.correlation)
fit<-eBayes(fit)
qval.cutoff=0.1; FC.cutoff=0.17
y1=topTable(fit, coef="TreatT", n=nrow(genes),adjust.method="BH",genelist=genes)

y1 for each iteration of permutation would  have P.Value column and
these I would have plotted on the end to find the distribution of all
p values generated in those 1000 permutations.

Please advise,
Ana


From bgunter@4567 @end|ng |rom gm@||@com  Tue Feb  4 21:34:43 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 4 Feb 2020 12:34:43 -0800
Subject: [R] 
 doing 1000 permutations and doing test statistics distribution
In-Reply-To: <CAF9-5jNNBhumJ3sU_n=mTk848Zr7woPtnGXMQO11qALoE_8QPw@mail.gmail.com>
References: <CAF9-5jNNBhumJ3sU_n=mTk848Zr7woPtnGXMQO11qALoE_8QPw@mail.gmail.com>
Message-ID: <CAGxFJbSWpqkgXo33RiP2b-a0ptV7dOfYxWMsO+1dYf3M1JZhKw@mail.gmail.com>

If you just want to permute columns of a matrix,

?sample
> sample.int(10)
 [1]  9  2 10  8  4  6  3  1  5  7

and you can just use this as an index into the columns of your matrix,
presumably within a loop of some sort.

If I have misunderstood, just ignore.

Cheers,
Bert




On Tue, Feb 4, 2020 at 12:23 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello,
>
> I have a matrix
> > dim(dat)
> [1] 15568   132
>
> It looks like this:
>
>                    NoD_14381_norm.1 NoD_14381_norm.2 NoD_14381_norm.3
> NoD_14520_30mM.1 NoD_14520_30mM.2 NoD_14520_30mM.3
> Ku8QhfS0n_hIOABXuE             4.75             4.25             4.79
>            4.33             4.63             3.85
> Bx496XsFXiAlj.Eaeo             6.15             6.23             6.55
>            6.26             6.24             5.99
> W38p0ogk.wIBVRXllY             7.13             7.35             7.55
>            7.37             7.36             7.55
> QIBkqIS9LR5DfTlTS8             6.27             6.73             6.45
>            5.39             4.75             4.96
> BZKiEvS0eQ305U0v34             6.35             7.02             6.76
>            5.45             5.25             5.02
> 6TheVd.HiE1UF3lX6g             5.53             5.02             5.36
>            5.61             5.66             5.37
>
> So it is a matrix with gene names ex. Ku8QhfS0n_hIOABXuE, and subjects
> named ex. NoD_14381_norm.1
>
>
> How to do 1000 permutations of these 132 columns and on each created
> new permuted matrix perform this code:
>
> subject="all_replicate"
> targets<-readTargets(paste(PhenotypeDir,"hg_sg_",subject,"_target.txt",
> sep=''))
> Treat <- factor(targets$Treatment,levels=c("C","T"))
> Replicates <- factor(targets$rep)
> design <- model.matrix(~Replicates+Treat)
> corfit <- duplicateCorrelation(dat, block = targets$Subject)
> corfit$consensus.correlation
> fit
> <-lmFit(dat,design,block=targets$Subject,correlation=corfit$consensus.correlation)
> fit<-eBayes(fit)
> qval.cutoff=0.1; FC.cutoff=0.17
> y1=topTable(fit, coef="TreatT",
> n=nrow(genes),adjust.method="BH",genelist=genes)
>
> y1 for each iteration of permutation would  have P.Value column and
> these I would have plotted on the end to find the distribution of all
> p values generated in those 1000 permutations.
>
> Please advise,
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Feb  4 21:46:43 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 4 Feb 2020 14:46:43 -0600
Subject: [R] 
 doing 1000 permutations and doing test statistics distribution
In-Reply-To: <CAGxFJbSWpqkgXo33RiP2b-a0ptV7dOfYxWMsO+1dYf3M1JZhKw@mail.gmail.com>
References: <CAF9-5jNNBhumJ3sU_n=mTk848Zr7woPtnGXMQO11qALoE_8QPw@mail.gmail.com>
 <CAGxFJbSWpqkgXo33RiP2b-a0ptV7dOfYxWMsO+1dYf3M1JZhKw@mail.gmail.com>
Message-ID: <CAF9-5jOog9ZKFVg3bymiUBZsvBKa6o-=tHs5sQnokDMTvHRVug@mail.gmail.com>

Hi Bert,

thanks for getting back to me. I have to permute those 132 columns
1000 times and perform the code given in the previous email.

Can you please show me how you would do that in the loop? This is also
a huge data set ...

Thanks
Ana

On Tue, Feb 4, 2020 at 2:34 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> If you just want to permute columns of a matrix,
>
> ?sample
> > sample.int(10)
>  [1]  9  2 10  8  4  6  3  1  5  7
>
> and you can just use this as an index into the columns of your matrix, presumably within a loop of some sort.
>
> If I have misunderstood, just ignore.
>
> Cheers,
> Bert
>
>
>
>
> On Tue, Feb 4, 2020 at 12:23 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>
>> Hello,
>>
>> I have a matrix
>> > dim(dat)
>> [1] 15568   132
>>
>> It looks like this:
>>
>>                    NoD_14381_norm.1 NoD_14381_norm.2 NoD_14381_norm.3
>> NoD_14520_30mM.1 NoD_14520_30mM.2 NoD_14520_30mM.3
>> Ku8QhfS0n_hIOABXuE             4.75             4.25             4.79
>>            4.33             4.63             3.85
>> Bx496XsFXiAlj.Eaeo             6.15             6.23             6.55
>>            6.26             6.24             5.99
>> W38p0ogk.wIBVRXllY             7.13             7.35             7.55
>>            7.37             7.36             7.55
>> QIBkqIS9LR5DfTlTS8             6.27             6.73             6.45
>>            5.39             4.75             4.96
>> BZKiEvS0eQ305U0v34             6.35             7.02             6.76
>>            5.45             5.25             5.02
>> 6TheVd.HiE1UF3lX6g             5.53             5.02             5.36
>>            5.61             5.66             5.37
>>
>> So it is a matrix with gene names ex. Ku8QhfS0n_hIOABXuE, and subjects
>> named ex. NoD_14381_norm.1
>>
>>
>> How to do 1000 permutations of these 132 columns and on each created
>> new permuted matrix perform this code:
>>
>> subject="all_replicate"
>> targets<-readTargets(paste(PhenotypeDir,"hg_sg_",subject,"_target.txt", sep=''))
>> Treat <- factor(targets$Treatment,levels=c("C","T"))
>> Replicates <- factor(targets$rep)
>> design <- model.matrix(~Replicates+Treat)
>> corfit <- duplicateCorrelation(dat, block = targets$Subject)
>> corfit$consensus.correlation
>> fit <-lmFit(dat,design,block=targets$Subject,correlation=corfit$consensus.correlation)
>> fit<-eBayes(fit)
>> qval.cutoff=0.1; FC.cutoff=0.17
>> y1=topTable(fit, coef="TreatT", n=nrow(genes),adjust.method="BH",genelist=genes)
>>
>> y1 for each iteration of permutation would  have P.Value column and
>> these I would have plotted on the end to find the distribution of all
>> p values generated in those 1000 permutations.
>>
>> Please advise,
>> Ana
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Feb  4 21:46:56 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 4 Feb 2020 14:46:56 -0600
Subject: [R] 
 doing 1000 permutations and doing test statistics distribution
In-Reply-To: <CAF9-5jOog9ZKFVg3bymiUBZsvBKa6o-=tHs5sQnokDMTvHRVug@mail.gmail.com>
References: <CAF9-5jNNBhumJ3sU_n=mTk848Zr7woPtnGXMQO11qALoE_8QPw@mail.gmail.com>
 <CAGxFJbSWpqkgXo33RiP2b-a0ptV7dOfYxWMsO+1dYf3M1JZhKw@mail.gmail.com>
 <CAF9-5jOog9ZKFVg3bymiUBZsvBKa6o-=tHs5sQnokDMTvHRVug@mail.gmail.com>
Message-ID: <CAF9-5jMj1bKzYtuynZVnqmfuephFF2ydG604pjco+UYbpVa2sQ@mail.gmail.com>

Basically I would just reshuffle column names in each of 1000 permutations
how to do that and perform everything I described in my initial email

On Tue, 4 Feb 2020 at 14:46, Ana Marija <sokovic.anamarija at gmail.com> wrote:

> Hi Bert,
>
> thanks for getting back to me. I have to permute those 132 columns
> 1000 times and perform the code given in the previous email.
>
> Can you please show me how you would do that in the loop? This is also
> a huge data set ...
>
> Thanks
> Ana
>
> On Tue, Feb 4, 2020 at 2:34 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > If you just want to permute columns of a matrix,
> >
> > ?sample
> > > sample.int(10)
> >  [1]  9  2 10  8  4  6  3  1  5  7
> >
> > and you can just use this as an index into the columns of your matrix,
> presumably within a loop of some sort.
> >
> > If I have misunderstood, just ignore.
> >
> > Cheers,
> > Bert
> >
> >
> >
> >
> > On Tue, Feb 4, 2020 at 12:23 PM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
> >>
> >> Hello,
> >>
> >> I have a matrix
> >> > dim(dat)
> >> [1] 15568   132
> >>
> >> It looks like this:
> >>
> >>                    NoD_14381_norm.1 NoD_14381_norm.2 NoD_14381_norm.3
> >> NoD_14520_30mM.1 NoD_14520_30mM.2 NoD_14520_30mM.3
> >> Ku8QhfS0n_hIOABXuE             4.75             4.25             4.79
> >>            4.33             4.63             3.85
> >> Bx496XsFXiAlj.Eaeo             6.15             6.23             6.55
> >>            6.26             6.24             5.99
> >> W38p0ogk.wIBVRXllY             7.13             7.35             7.55
> >>            7.37             7.36             7.55
> >> QIBkqIS9LR5DfTlTS8             6.27             6.73             6.45
> >>            5.39             4.75             4.96
> >> BZKiEvS0eQ305U0v34             6.35             7.02             6.76
> >>            5.45             5.25             5.02
> >> 6TheVd.HiE1UF3lX6g             5.53             5.02             5.36
> >>            5.61             5.66             5.37
> >>
> >> So it is a matrix with gene names ex. Ku8QhfS0n_hIOABXuE, and subjects
> >> named ex. NoD_14381_norm.1
> >>
> >>
> >> How to do 1000 permutations of these 132 columns and on each created
> >> new permuted matrix perform this code:
> >>
> >> subject="all_replicate"
> >> targets<-readTargets(paste(PhenotypeDir,"hg_sg_",subject,"_target.txt",
> sep=''))
> >> Treat <- factor(targets$Treatment,levels=c("C","T"))
> >> Replicates <- factor(targets$rep)
> >> design <- model.matrix(~Replicates+Treat)
> >> corfit <- duplicateCorrelation(dat, block = targets$Subject)
> >> corfit$consensus.correlation
> >> fit
> <-lmFit(dat,design,block=targets$Subject,correlation=corfit$consensus.correlation)
> >> fit<-eBayes(fit)
> >> qval.cutoff=0.1; FC.cutoff=0.17
> >> y1=topTable(fit, coef="TreatT",
> n=nrow(genes),adjust.method="BH",genelist=genes)
> >>
> >> y1 for each iteration of permutation would  have P.Value column and
> >> these I would have plotted on the end to find the distribution of all
> >> p values generated in those 1000 permutations.
> >>
> >> Please advise,
> >> Ana
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Feb  4 22:10:47 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 4 Feb 2020 13:10:47 -0800
Subject: [R] 
 doing 1000 permutations and doing test statistics distribution
In-Reply-To: <CAF9-5jOog9ZKFVg3bymiUBZsvBKa6o-=tHs5sQnokDMTvHRVug@mail.gmail.com>
References: <CAF9-5jNNBhumJ3sU_n=mTk848Zr7woPtnGXMQO11qALoE_8QPw@mail.gmail.com>
 <CAGxFJbSWpqkgXo33RiP2b-a0ptV7dOfYxWMsO+1dYf3M1JZhKw@mail.gmail.com>
 <CAF9-5jOog9ZKFVg3bymiUBZsvBKa6o-=tHs5sQnokDMTvHRVug@mail.gmail.com>
Message-ID: <CAGxFJbTjD5QvJNow=Rgzytt3uQcXYDZZxGOe2mFaThiwCyM2ZA@mail.gmail.com>

I am not going to do your programming for you. If the following doesn't
suffice, maybe someone else will provide you something that will.

m = your matrix

code = your code that uses m

your list of results <- lapply(seq_len(1000), FUN = function(m){
  m <- m[, sample.int(132)]
 code
} )

or use an explicit for() loop to populate a list or vector with your
results.

Again, if I have misunderstood what you want to do, then clarify, and
perhaps someone else will help.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 4, 2020 at 12:41 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hi Bert,
>
> thanks for getting back to me. I have to permute those 132 columns
> 1000 times and perform the code given in the previous email.
>
> Can you please show me how you would do that in the loop? This is also
> a huge data set ...
>
> Thanks
> Ana
>
> On Tue, Feb 4, 2020 at 2:34 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > If you just want to permute columns of a matrix,
> >
> > ?sample
> > > sample.int(10)
> >  [1]  9  2 10  8  4  6  3  1  5  7
> >
> > and you can just use this as an index into the columns of your matrix,
> presumably within a loop of some sort.
> >
> > If I have misunderstood, just ignore.
> >
> > Cheers,
> > Bert
> >
> >
> >
> >
> > On Tue, Feb 4, 2020 at 12:23 PM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
> >>
> >> Hello,
> >>
> >> I have a matrix
> >> > dim(dat)
> >> [1] 15568   132
> >>
> >> It looks like this:
> >>
> >>                    NoD_14381_norm.1 NoD_14381_norm.2 NoD_14381_norm.3
> >> NoD_14520_30mM.1 NoD_14520_30mM.2 NoD_14520_30mM.3
> >> Ku8QhfS0n_hIOABXuE             4.75             4.25             4.79
> >>            4.33             4.63             3.85
> >> Bx496XsFXiAlj.Eaeo             6.15             6.23             6.55
> >>            6.26             6.24             5.99
> >> W38p0ogk.wIBVRXllY             7.13             7.35             7.55
> >>            7.37             7.36             7.55
> >> QIBkqIS9LR5DfTlTS8             6.27             6.73             6.45
> >>            5.39             4.75             4.96
> >> BZKiEvS0eQ305U0v34             6.35             7.02             6.76
> >>            5.45             5.25             5.02
> >> 6TheVd.HiE1UF3lX6g             5.53             5.02             5.36
> >>            5.61             5.66             5.37
> >>
> >> So it is a matrix with gene names ex. Ku8QhfS0n_hIOABXuE, and subjects
> >> named ex. NoD_14381_norm.1
> >>
> >>
> >> How to do 1000 permutations of these 132 columns and on each created
> >> new permuted matrix perform this code:
> >>
> >> subject="all_replicate"
> >> targets<-readTargets(paste(PhenotypeDir,"hg_sg_",subject,"_target.txt",
> sep=''))
> >> Treat <- factor(targets$Treatment,levels=c("C","T"))
> >> Replicates <- factor(targets$rep)
> >> design <- model.matrix(~Replicates+Treat)
> >> corfit <- duplicateCorrelation(dat, block = targets$Subject)
> >> corfit$consensus.correlation
> >> fit
> <-lmFit(dat,design,block=targets$Subject,correlation=corfit$consensus.correlation)
> >> fit<-eBayes(fit)
> >> qval.cutoff=0.1; FC.cutoff=0.17
> >> y1=topTable(fit, coef="TreatT",
> n=nrow(genes),adjust.method="BH",genelist=genes)
> >>
> >> y1 for each iteration of permutation would  have P.Value column and
> >> these I would have plotted on the end to find the distribution of all
> >> p values generated in those 1000 permutations.
> >>
> >> Please advise,
> >> Ana
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Feb  4 22:28:33 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 4 Feb 2020 15:28:33 -0600
Subject: [R] 
 doing 1000 permutations and doing test statistics distribution
In-Reply-To: <CAGxFJbTjD5QvJNow=Rgzytt3uQcXYDZZxGOe2mFaThiwCyM2ZA@mail.gmail.com>
References: <CAF9-5jNNBhumJ3sU_n=mTk848Zr7woPtnGXMQO11qALoE_8QPw@mail.gmail.com>
 <CAGxFJbSWpqkgXo33RiP2b-a0ptV7dOfYxWMsO+1dYf3M1JZhKw@mail.gmail.com>
 <CAF9-5jOog9ZKFVg3bymiUBZsvBKa6o-=tHs5sQnokDMTvHRVug@mail.gmail.com>
 <CAGxFJbTjD5QvJNow=Rgzytt3uQcXYDZZxGOe2mFaThiwCyM2ZA@mail.gmail.com>
Message-ID: <CAF9-5jOUAvC=t2SHkYEAPzYk9u7OEAvhiv3bob8sWA3KohKhsw@mail.gmail.com>

I tired your code on this simplified data just for say 10 permutations:

dat <- read.table(text = "   code.1 code.2 code.3 code.4
1     82     93     NA     NA
2     15     85     93     NA
3     93     89     NA     NA
4     81     NA     NA     NA",
                  header = TRUE, stringsAsFactors = FALSE)

dat2=data.matrix(dat)

> result<- lapply(seq_len(10), FUN = function(dat2){
+     dat2 <- dat2[, sample.int(4)]
+     print(colnames(dat2))
+ } )
Error in dat2[, sample.int(4)] : incorrect number of dimensions


On Tue, Feb 4, 2020 at 3:10 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> I am not going to do your programming for you. If the following doesn't suffice, maybe someone else will provide you something that will.
>
> m = your matrix
>
> code = your code that uses m
>
> your list of results <- lapply(seq_len(1000), FUN = function(m){
>   m <- m[, sample.int(132)]
>  code
> } )
>
> or use an explicit for() loop to populate a list or vector with your results.
>
> Again, if I have misunderstood what you want to do, then clarify, and perhaps someone else will help.
>
> -- Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Feb 4, 2020 at 12:41 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>
>> Hi Bert,
>>
>> thanks for getting back to me. I have to permute those 132 columns
>> 1000 times and perform the code given in the previous email.
>>
>> Can you please show me how you would do that in the loop? This is also
>> a huge data set ...
>>
>> Thanks
>> Ana
>>
>> On Tue, Feb 4, 2020 at 2:34 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> >
>> > If you just want to permute columns of a matrix,
>> >
>> > ?sample
>> > > sample.int(10)
>> >  [1]  9  2 10  8  4  6  3  1  5  7
>> >
>> > and you can just use this as an index into the columns of your matrix, presumably within a loop of some sort.
>> >
>> > If I have misunderstood, just ignore.
>> >
>> > Cheers,
>> > Bert
>> >
>> >
>> >
>> >
>> > On Tue, Feb 4, 2020 at 12:23 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>> >>
>> >> Hello,
>> >>
>> >> I have a matrix
>> >> > dim(dat)
>> >> [1] 15568   132
>> >>
>> >> It looks like this:
>> >>
>> >>                    NoD_14381_norm.1 NoD_14381_norm.2 NoD_14381_norm.3
>> >> NoD_14520_30mM.1 NoD_14520_30mM.2 NoD_14520_30mM.3
>> >> Ku8QhfS0n_hIOABXuE             4.75             4.25             4.79
>> >>            4.33             4.63             3.85
>> >> Bx496XsFXiAlj.Eaeo             6.15             6.23             6.55
>> >>            6.26             6.24             5.99
>> >> W38p0ogk.wIBVRXllY             7.13             7.35             7.55
>> >>            7.37             7.36             7.55
>> >> QIBkqIS9LR5DfTlTS8             6.27             6.73             6.45
>> >>            5.39             4.75             4.96
>> >> BZKiEvS0eQ305U0v34             6.35             7.02             6.76
>> >>            5.45             5.25             5.02
>> >> 6TheVd.HiE1UF3lX6g             5.53             5.02             5.36
>> >>            5.61             5.66             5.37
>> >>
>> >> So it is a matrix with gene names ex. Ku8QhfS0n_hIOABXuE, and subjects
>> >> named ex. NoD_14381_norm.1
>> >>
>> >>
>> >> How to do 1000 permutations of these 132 columns and on each created
>> >> new permuted matrix perform this code:
>> >>
>> >> subject="all_replicate"
>> >> targets<-readTargets(paste(PhenotypeDir,"hg_sg_",subject,"_target.txt", sep=''))
>> >> Treat <- factor(targets$Treatment,levels=c("C","T"))
>> >> Replicates <- factor(targets$rep)
>> >> design <- model.matrix(~Replicates+Treat)
>> >> corfit <- duplicateCorrelation(dat, block = targets$Subject)
>> >> corfit$consensus.correlation
>> >> fit <-lmFit(dat,design,block=targets$Subject,correlation=corfit$consensus.correlation)
>> >> fit<-eBayes(fit)
>> >> qval.cutoff=0.1; FC.cutoff=0.17
>> >> y1=topTable(fit, coef="TreatT", n=nrow(genes),adjust.method="BH",genelist=genes)
>> >>
>> >> y1 for each iteration of permutation would  have P.Value column and
>> >> these I would have plotted on the end to find the distribution of all
>> >> p values generated in those 1000 permutations.
>> >>
>> >> Please advise,
>> >> Ana
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Feb  4 22:41:53 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 4 Feb 2020 16:41:53 -0500
Subject: [R] 
 doing 1000 permutations and doing test statistics distribution
In-Reply-To: <CAF9-5jOUAvC=t2SHkYEAPzYk9u7OEAvhiv3bob8sWA3KohKhsw@mail.gmail.com>
References: <CAF9-5jNNBhumJ3sU_n=mTk848Zr7woPtnGXMQO11qALoE_8QPw@mail.gmail.com>
 <CAGxFJbSWpqkgXo33RiP2b-a0ptV7dOfYxWMsO+1dYf3M1JZhKw@mail.gmail.com>
 <CAF9-5jOog9ZKFVg3bymiUBZsvBKa6o-=tHs5sQnokDMTvHRVug@mail.gmail.com>
 <CAGxFJbTjD5QvJNow=Rgzytt3uQcXYDZZxGOe2mFaThiwCyM2ZA@mail.gmail.com>
 <CAF9-5jOUAvC=t2SHkYEAPzYk9u7OEAvhiv3bob8sWA3KohKhsw@mail.gmail.com>
Message-ID: <3c0913d6-dbbf-316f-1a9a-075b927562dd@gmail.com>

On 04/02/2020 4:28 p.m., Ana Marija wrote:
> I tired your code on this simplified data just for say 10 permutations:
> 
> dat <- read.table(text = "   code.1 code.2 code.3 code.4
> 1     82     93     NA     NA
> 2     15     85     93     NA
> 3     93     89     NA     NA
> 4     81     NA     NA     NA",
>                    header = TRUE, stringsAsFactors = FALSE)
> 
> dat2=data.matrix(dat)
> 
>> result<- lapply(seq_len(10), FUN = function(dat2){
> +     dat2 <- dat2[, sample.int(4)]
> +     print(colnames(dat2))
> + } )
> Error in dat2[, sample.int(4)] : incorrect number of dimensions

Yes, Bert did suggest that, but it's obviously wrong.  The argument to 
FUN is an element of seq_len(10), it's not the full dataset.  Try

result<- lapply(seq_len(10), FUN = function(i){
      dat <- dat2[, sample.int(4)]
      print(colnames(dat))
  } )

Duncan Murdoch

> 
> 
> On Tue, Feb 4, 2020 at 3:10 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> I am not going to do your programming for you. If the following doesn't suffice, maybe someone else will provide you something that will.
>>
>> m = your matrix
>>
>> code = your code that uses m
>>
>> your list of results <- lapply(seq_len(1000), FUN = function(m){
>>    m <- m[, sample.int(132)]
>>   code
>> } )
>>
>> or use an explicit for() loop to populate a list or vector with your results.
>>
>> Again, if I have misunderstood what you want to do, then clarify, and perhaps someone else will help.
>>
>> -- Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Tue, Feb 4, 2020 at 12:41 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>>
>>> Hi Bert,
>>>
>>> thanks for getting back to me. I have to permute those 132 columns
>>> 1000 times and perform the code given in the previous email.
>>>
>>> Can you please show me how you would do that in the loop? This is also
>>> a huge data set ...
>>>
>>> Thanks
>>> Ana
>>>
>>> On Tue, Feb 4, 2020 at 2:34 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>>
>>>> If you just want to permute columns of a matrix,
>>>>
>>>> ?sample
>>>>> sample.int(10)
>>>>   [1]  9  2 10  8  4  6  3  1  5  7
>>>>
>>>> and you can just use this as an index into the columns of your matrix, presumably within a loop of some sort.
>>>>
>>>> If I have misunderstood, just ignore.
>>>>
>>>> Cheers,
>>>> Bert
>>>>
>>>>
>>>>
>>>>
>>>> On Tue, Feb 4, 2020 at 12:23 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>>>>
>>>>> Hello,
>>>>>
>>>>> I have a matrix
>>>>>> dim(dat)
>>>>> [1] 15568   132
>>>>>
>>>>> It looks like this:
>>>>>
>>>>>                     NoD_14381_norm.1 NoD_14381_norm.2 NoD_14381_norm.3
>>>>> NoD_14520_30mM.1 NoD_14520_30mM.2 NoD_14520_30mM.3
>>>>> Ku8QhfS0n_hIOABXuE             4.75             4.25             4.79
>>>>>             4.33             4.63             3.85
>>>>> Bx496XsFXiAlj.Eaeo             6.15             6.23             6.55
>>>>>             6.26             6.24             5.99
>>>>> W38p0ogk.wIBVRXllY             7.13             7.35             7.55
>>>>>             7.37             7.36             7.55
>>>>> QIBkqIS9LR5DfTlTS8             6.27             6.73             6.45
>>>>>             5.39             4.75             4.96
>>>>> BZKiEvS0eQ305U0v34             6.35             7.02             6.76
>>>>>             5.45             5.25             5.02
>>>>> 6TheVd.HiE1UF3lX6g             5.53             5.02             5.36
>>>>>             5.61             5.66             5.37
>>>>>
>>>>> So it is a matrix with gene names ex. Ku8QhfS0n_hIOABXuE, and subjects
>>>>> named ex. NoD_14381_norm.1
>>>>>
>>>>>
>>>>> How to do 1000 permutations of these 132 columns and on each created
>>>>> new permuted matrix perform this code:
>>>>>
>>>>> subject="all_replicate"
>>>>> targets<-readTargets(paste(PhenotypeDir,"hg_sg_",subject,"_target.txt", sep=''))
>>>>> Treat <- factor(targets$Treatment,levels=c("C","T"))
>>>>> Replicates <- factor(targets$rep)
>>>>> design <- model.matrix(~Replicates+Treat)
>>>>> corfit <- duplicateCorrelation(dat, block = targets$Subject)
>>>>> corfit$consensus.correlation
>>>>> fit <-lmFit(dat,design,block=targets$Subject,correlation=corfit$consensus.correlation)
>>>>> fit<-eBayes(fit)
>>>>> qval.cutoff=0.1; FC.cutoff=0.17
>>>>> y1=topTable(fit, coef="TreatT", n=nrow(genes),adjust.method="BH",genelist=genes)
>>>>>
>>>>> y1 for each iteration of permutation would  have P.Value column and
>>>>> these I would have plotted on the end to find the distribution of all
>>>>> p values generated in those 1000 permutations.
>>>>>
>>>>> Please advise,
>>>>> Ana
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter@4567 @end|ng |rom gm@||@com  Tue Feb  4 23:45:39 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 4 Feb 2020 14:45:39 -0800
Subject: [R] 
 doing 1000 permutations and doing test statistics distribution
In-Reply-To: <3c0913d6-dbbf-316f-1a9a-075b927562dd@gmail.com>
References: <CAF9-5jNNBhumJ3sU_n=mTk848Zr7woPtnGXMQO11qALoE_8QPw@mail.gmail.com>
 <CAGxFJbSWpqkgXo33RiP2b-a0ptV7dOfYxWMsO+1dYf3M1JZhKw@mail.gmail.com>
 <CAF9-5jOog9ZKFVg3bymiUBZsvBKa6o-=tHs5sQnokDMTvHRVug@mail.gmail.com>
 <CAGxFJbTjD5QvJNow=Rgzytt3uQcXYDZZxGOe2mFaThiwCyM2ZA@mail.gmail.com>
 <CAF9-5jOUAvC=t2SHkYEAPzYk9u7OEAvhiv3bob8sWA3KohKhsw@mail.gmail.com>
 <3c0913d6-dbbf-316f-1a9a-075b927562dd@gmail.com>
Message-ID: <CAGxFJbR8dRLa4wJiCnom=dhUR0ZrWPEqkFW_CF3zu0AiUz+0NQ@mail.gmail.com>

Yes, a clear thinko... Thanks for the correction.

-- Bert

On Tue, Feb 4, 2020 at 1:41 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 04/02/2020 4:28 p.m., Ana Marija wrote:
> > I tired your code on this simplified data just for say 10 permutations:
> >
> > dat <- read.table(text = "   code.1 code.2 code.3 code.4
> > 1     82     93     NA     NA
> > 2     15     85     93     NA
> > 3     93     89     NA     NA
> > 4     81     NA     NA     NA",
> >                    header = TRUE, stringsAsFactors = FALSE)
> >
> > dat2=data.matrix(dat)
> >
> >> result<- lapply(seq_len(10), FUN = function(dat2){
> > +     dat2 <- dat2[, sample.int(4)]
> > +     print(colnames(dat2))
> > + } )
> > Error in dat2[, sample.int(4)] : incorrect number of dimensions
>
> Yes, Bert did suggest that, but it's obviously wrong.  The argument to
> FUN is an element of seq_len(10), it's not the full dataset.  Try
>
> result<- lapply(seq_len(10), FUN = function(i){
>       dat <- dat2[, sample.int(4)]
>       print(colnames(dat))
>   } )
>
> Duncan Murdoch
>
> >
> >
> > On Tue, Feb 4, 2020 at 3:10 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >>
> >> I am not going to do your programming for you. If the following doesn't
> suffice, maybe someone else will provide you something that will.
> >>
> >> m = your matrix
> >>
> >> code = your code that uses m
> >>
> >> your list of results <- lapply(seq_len(1000), FUN = function(m){
> >>    m <- m[, sample.int(132)]
> >>   code
> >> } )
> >>
> >> or use an explicit for() loop to populate a list or vector with your
> results.
> >>
> >> Again, if I have misunderstood what you want to do, then clarify, and
> perhaps someone else will help.
> >>
> >> -- Bert
> >>
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Tue, Feb 4, 2020 at 12:41 PM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
> >>>
> >>> Hi Bert,
> >>>
> >>> thanks for getting back to me. I have to permute those 132 columns
> >>> 1000 times and perform the code given in the previous email.
> >>>
> >>> Can you please show me how you would do that in the loop? This is also
> >>> a huge data set ...
> >>>
> >>> Thanks
> >>> Ana
> >>>
> >>> On Tue, Feb 4, 2020 at 2:34 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >>>>
> >>>> If you just want to permute columns of a matrix,
> >>>>
> >>>> ?sample
> >>>>> sample.int(10)
> >>>>   [1]  9  2 10  8  4  6  3  1  5  7
> >>>>
> >>>> and you can just use this as an index into the columns of your
> matrix, presumably within a loop of some sort.
> >>>>
> >>>> If I have misunderstood, just ignore.
> >>>>
> >>>> Cheers,
> >>>> Bert
> >>>>
> >>>>
> >>>>
> >>>>
> >>>> On Tue, Feb 4, 2020 at 12:23 PM Ana Marija <
> sokovic.anamarija at gmail.com> wrote:
> >>>>>
> >>>>> Hello,
> >>>>>
> >>>>> I have a matrix
> >>>>>> dim(dat)
> >>>>> [1] 15568   132
> >>>>>
> >>>>> It looks like this:
> >>>>>
> >>>>>                     NoD_14381_norm.1 NoD_14381_norm.2
> NoD_14381_norm.3
> >>>>> NoD_14520_30mM.1 NoD_14520_30mM.2 NoD_14520_30mM.3
> >>>>> Ku8QhfS0n_hIOABXuE             4.75             4.25             4.79
> >>>>>             4.33             4.63             3.85
> >>>>> Bx496XsFXiAlj.Eaeo             6.15             6.23             6.55
> >>>>>             6.26             6.24             5.99
> >>>>> W38p0ogk.wIBVRXllY             7.13             7.35             7.55
> >>>>>             7.37             7.36             7.55
> >>>>> QIBkqIS9LR5DfTlTS8             6.27             6.73             6.45
> >>>>>             5.39             4.75             4.96
> >>>>> BZKiEvS0eQ305U0v34             6.35             7.02             6.76
> >>>>>             5.45             5.25             5.02
> >>>>> 6TheVd.HiE1UF3lX6g             5.53             5.02             5.36
> >>>>>             5.61             5.66             5.37
> >>>>>
> >>>>> So it is a matrix with gene names ex. Ku8QhfS0n_hIOABXuE, and
> subjects
> >>>>> named ex. NoD_14381_norm.1
> >>>>>
> >>>>>
> >>>>> How to do 1000 permutations of these 132 columns and on each created
> >>>>> new permuted matrix perform this code:
> >>>>>
> >>>>> subject="all_replicate"
> >>>>>
> targets<-readTargets(paste(PhenotypeDir,"hg_sg_",subject,"_target.txt",
> sep=''))
> >>>>> Treat <- factor(targets$Treatment,levels=c("C","T"))
> >>>>> Replicates <- factor(targets$rep)
> >>>>> design <- model.matrix(~Replicates+Treat)
> >>>>> corfit <- duplicateCorrelation(dat, block = targets$Subject)
> >>>>> corfit$consensus.correlation
> >>>>> fit
> <-lmFit(dat,design,block=targets$Subject,correlation=corfit$consensus.correlation)
> >>>>> fit<-eBayes(fit)
> >>>>> qval.cutoff=0.1; FC.cutoff=0.17
> >>>>> y1=topTable(fit, coef="TreatT",
> n=nrow(genes),adjust.method="BH",genelist=genes)
> >>>>>
> >>>>> y1 for each iteration of permutation would  have P.Value column and
> >>>>> these I would have plotted on the end to find the distribution of all
> >>>>> p values generated in those 1000 permutations.
> >>>>>
> >>>>> Please advise,
> >>>>> Ana
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From ct|y0312 @end|ng |rom gm@||@com  Tue Feb  4 21:54:15 2020
From: ct|y0312 @end|ng |rom gm@||@com (Tao Z)
Date: Tue, 4 Feb 2020 15:54:15 -0500
Subject: [R] Question about autocomplete Keyboard Shortcut in R Markdown
 Latex
Message-ID: <EC8CECB0-701F-496B-B5F5-4E04E27330A4@gmail.com>

Hi, 

In R, we know how to autocomplete a function name or some arguments in the function. I usually use ?Tab? to achieve this. 
But when I was preparing my math homework using R Markdown, I want to achieve similar results: for example, 

I want to autocomplete $\frac{}{}$ when I only typed $\fr$. I tried ?Tab or Command+Space?, but none of them work. 

Does anyone know if we have autocomplete option for R markdown latex? If we do, what keyboard should I use? Thanks



	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Feb  5 16:15:16 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 5 Feb 2020 09:15:16 -0600
Subject: [R] 
 doing 1000 permutations and doing test statistics distribution
In-Reply-To: <CAGxFJbR8dRLa4wJiCnom=dhUR0ZrWPEqkFW_CF3zu0AiUz+0NQ@mail.gmail.com>
References: <CAF9-5jNNBhumJ3sU_n=mTk848Zr7woPtnGXMQO11qALoE_8QPw@mail.gmail.com>
 <CAGxFJbSWpqkgXo33RiP2b-a0ptV7dOfYxWMsO+1dYf3M1JZhKw@mail.gmail.com>
 <CAF9-5jOog9ZKFVg3bymiUBZsvBKa6o-=tHs5sQnokDMTvHRVug@mail.gmail.com>
 <CAGxFJbTjD5QvJNow=Rgzytt3uQcXYDZZxGOe2mFaThiwCyM2ZA@mail.gmail.com>
 <CAF9-5jOUAvC=t2SHkYEAPzYk9u7OEAvhiv3bob8sWA3KohKhsw@mail.gmail.com>
 <3c0913d6-dbbf-316f-1a9a-075b927562dd@gmail.com>
 <CAGxFJbR8dRLa4wJiCnom=dhUR0ZrWPEqkFW_CF3zu0AiUz+0NQ@mail.gmail.com>
Message-ID: <CAF9-5jMP+4EbgG9TUkRZzkC=n6ZWL-Lso7916BhZJJHJi4mVLQ@mail.gmail.com>

I tried to solve the task via following code:

manyorders <- replicate(100, sample(colnames(dat)), simplify=FALSE)

all_results <- lapply(manyorders, function(ord) {
  tmpdat <- `colnames<-`(dat, ord) # copies and renames in one line
  corfit <- duplicateCorrelation(dat, block = targets$Subject)
  corfit$consensus.correlation
  fit <-lmFit(dat,design,block=targets$Subject,correlation=corfit$consensus.correlation)
  fit <- eBayes(fit)
  y1 <- topTable(fit, coef="TreatT", n=nrow(genes),
adjust.method="BH", genelist=genes)
  list(fit = fit, y1 = y1)
})

and I wrote all_results in a file
write.table(all_results, file="all_res", sep = " ", row.names = FALSE,
col.names = TRUE,quote=FALSE)

when I tried to open the file:
> a=read.table("all_res", header=T)
Error in read.table("all_res", header = T) :
  more columns than column names

also with fread:
> a=fread("all_res")
Warning messages:
1: In fread("all_res") :
  Detected 35300 column names but the data has 35700 columns (i.e.
invalid file). Added 400 extra default column names at the end.
2: In fread("all_res") :
  Stopped early on line 5. Expected 35700 fields but found 35400.
Consider fill=TRUE and comment.char=. First discarded non-empty line:
<<5.73583235032546 0.182418204566858 0.178323702841331
-1.69234503648485 -1.83571739423166 -1.72136694103431 1.35210840970636
1.37698365727967 1.65643614366521 1.33750809366081 1.22116614774455
1.07000318265432 -1.13789084968265 -1.0757049956716 -1.24824627469937
-0.208441151406013 -0.246971068064524 -0.272463550264579
-0.561691522816148 -0.407713100376217 -0.538071283637418
-0.979274581542649 -0.909855772342568 -0.974827213844384
0.21700425934175 0.134586251989901 0.0818947419096577 -0.6788584605>>

my original dat matrix has 132 columns and around 15000 rows

Can you please advise on this?

Thanks
Ana

On Tue, Feb 4, 2020 at 4:45 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Yes, a clear thinko... Thanks for the correction.
>
> -- Bert
>
> On Tue, Feb 4, 2020 at 1:41 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> On 04/02/2020 4:28 p.m., Ana Marija wrote:
>> > I tired your code on this simplified data just for say 10 permutations:
>> >
>> > dat <- read.table(text = "   code.1 code.2 code.3 code.4
>> > 1     82     93     NA     NA
>> > 2     15     85     93     NA
>> > 3     93     89     NA     NA
>> > 4     81     NA     NA     NA",
>> >                    header = TRUE, stringsAsFactors = FALSE)
>> >
>> > dat2=data.matrix(dat)
>> >
>> >> result<- lapply(seq_len(10), FUN = function(dat2){
>> > +     dat2 <- dat2[, sample.int(4)]
>> > +     print(colnames(dat2))
>> > + } )
>> > Error in dat2[, sample.int(4)] : incorrect number of dimensions
>>
>> Yes, Bert did suggest that, but it's obviously wrong.  The argument to
>> FUN is an element of seq_len(10), it's not the full dataset.  Try
>>
>> result<- lapply(seq_len(10), FUN = function(i){
>>       dat <- dat2[, sample.int(4)]
>>       print(colnames(dat))
>>   } )
>>
>> Duncan Murdoch
>>
>> >
>> >
>> > On Tue, Feb 4, 2020 at 3:10 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> >>
>> >> I am not going to do your programming for you. If the following doesn't suffice, maybe someone else will provide you something that will.
>> >>
>> >> m = your matrix
>> >>
>> >> code = your code that uses m
>> >>
>> >> your list of results <- lapply(seq_len(1000), FUN = function(m){
>> >>    m <- m[, sample.int(132)]
>> >>   code
>> >> } )
>> >>
>> >> or use an explicit for() loop to populate a list or vector with your results.
>> >>
>> >> Again, if I have misunderstood what you want to do, then clarify, and perhaps someone else will help.
>> >>
>> >> -- Bert
>> >>
>> >>
>> >>
>> >> Bert Gunter
>> >>
>> >> "The trouble with having an open mind is that people keep coming along and sticking things into it."
>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>
>> >>
>> >> On Tue, Feb 4, 2020 at 12:41 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>> >>>
>> >>> Hi Bert,
>> >>>
>> >>> thanks for getting back to me. I have to permute those 132 columns
>> >>> 1000 times and perform the code given in the previous email.
>> >>>
>> >>> Can you please show me how you would do that in the loop? This is also
>> >>> a huge data set ...
>> >>>
>> >>> Thanks
>> >>> Ana
>> >>>
>> >>> On Tue, Feb 4, 2020 at 2:34 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> >>>>
>> >>>> If you just want to permute columns of a matrix,
>> >>>>
>> >>>> ?sample
>> >>>>> sample.int(10)
>> >>>>   [1]  9  2 10  8  4  6  3  1  5  7
>> >>>>
>> >>>> and you can just use this as an index into the columns of your matrix, presumably within a loop of some sort.
>> >>>>
>> >>>> If I have misunderstood, just ignore.
>> >>>>
>> >>>> Cheers,
>> >>>> Bert
>> >>>>
>> >>>>
>> >>>>
>> >>>>
>> >>>> On Tue, Feb 4, 2020 at 12:23 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>> >>>>>
>> >>>>> Hello,
>> >>>>>
>> >>>>> I have a matrix
>> >>>>>> dim(dat)
>> >>>>> [1] 15568   132
>> >>>>>
>> >>>>> It looks like this:
>> >>>>>
>> >>>>>                     NoD_14381_norm.1 NoD_14381_norm.2 NoD_14381_norm.3
>> >>>>> NoD_14520_30mM.1 NoD_14520_30mM.2 NoD_14520_30mM.3
>> >>>>> Ku8QhfS0n_hIOABXuE             4.75             4.25             4.79
>> >>>>>             4.33             4.63             3.85
>> >>>>> Bx496XsFXiAlj.Eaeo             6.15             6.23             6.55
>> >>>>>             6.26             6.24             5.99
>> >>>>> W38p0ogk.wIBVRXllY             7.13             7.35             7.55
>> >>>>>             7.37             7.36             7.55
>> >>>>> QIBkqIS9LR5DfTlTS8             6.27             6.73             6.45
>> >>>>>             5.39             4.75             4.96
>> >>>>> BZKiEvS0eQ305U0v34             6.35             7.02             6.76
>> >>>>>             5.45             5.25             5.02
>> >>>>> 6TheVd.HiE1UF3lX6g             5.53             5.02             5.36
>> >>>>>             5.61             5.66             5.37
>> >>>>>
>> >>>>> So it is a matrix with gene names ex. Ku8QhfS0n_hIOABXuE, and subjects
>> >>>>> named ex. NoD_14381_norm.1
>> >>>>>
>> >>>>>
>> >>>>> How to do 1000 permutations of these 132 columns and on each created
>> >>>>> new permuted matrix perform this code:
>> >>>>>
>> >>>>> subject="all_replicate"
>> >>>>> targets<-readTargets(paste(PhenotypeDir,"hg_sg_",subject,"_target.txt", sep=''))
>> >>>>> Treat <- factor(targets$Treatment,levels=c("C","T"))
>> >>>>> Replicates <- factor(targets$rep)
>> >>>>> design <- model.matrix(~Replicates+Treat)
>> >>>>> corfit <- duplicateCorrelation(dat, block = targets$Subject)
>> >>>>> corfit$consensus.correlation
>> >>>>> fit <-lmFit(dat,design,block=targets$Subject,correlation=corfit$consensus.correlation)
>> >>>>> fit<-eBayes(fit)
>> >>>>> qval.cutoff=0.1; FC.cutoff=0.17
>> >>>>> y1=topTable(fit, coef="TreatT", n=nrow(genes),adjust.method="BH",genelist=genes)
>> >>>>>
>> >>>>> y1 for each iteration of permutation would  have P.Value column and
>> >>>>> these I would have plotted on the end to find the distribution of all
>> >>>>> p values generated in those 1000 permutations.
>> >>>>>
>> >>>>> Please advise,
>> >>>>> Ana
>> >>>>>
>> >>>>> ______________________________________________
>> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>


From bgunter@4567 @end|ng |rom gm@||@com  Wed Feb  5 17:09:35 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 5 Feb 2020 08:09:35 -0800
Subject: [R] Question about autocomplete Keyboard Shortcut in R Markdown
 Latex
In-Reply-To: <EC8CECB0-701F-496B-B5F5-4E04E27330A4@gmail.com>
References: <EC8CECB0-701F-496B-B5F5-4E04E27330A4@gmail.com>
Message-ID: <CAGxFJbTyJdNf4Nrs--niBGN2jAyBw5t7XEsGYKj5rrhCDcdwFA@mail.gmail.com>

Try posting this at the RStudio Help site, as R Markdown is part of the
ecosystem they have created and support.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 5, 2020 at 7:44 AM Tao Z <ctfy0312 at gmail.com> wrote:

> Hi,
>
> In R, we know how to autocomplete a function name or some arguments in the
> function. I usually use ?Tab? to achieve this.
> But when I was preparing my math homework using R Markdown, I want to
> achieve similar results: for example,
>
> I want to autocomplete $\frac{}{}$ when I only typed $\fr$. I tried ?Tab
> or Command+Space?, but none of them work.
>
> Does anyone know if we have autocomplete option for R markdown latex? If
> we do, what keyboard should I use? Thanks
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Feb  5 17:11:56 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 5 Feb 2020 19:11:56 +0300
Subject: [R] 
 doing 1000 permutations and doing test statistics distribution
In-Reply-To: <CAF9-5jMP+4EbgG9TUkRZzkC=n6ZWL-Lso7916BhZJJHJi4mVLQ@mail.gmail.com>
References: <CAF9-5jNNBhumJ3sU_n=mTk848Zr7woPtnGXMQO11qALoE_8QPw@mail.gmail.com>
 <CAGxFJbSWpqkgXo33RiP2b-a0ptV7dOfYxWMsO+1dYf3M1JZhKw@mail.gmail.com>
 <CAF9-5jOog9ZKFVg3bymiUBZsvBKa6o-=tHs5sQnokDMTvHRVug@mail.gmail.com>
 <CAGxFJbTjD5QvJNow=Rgzytt3uQcXYDZZxGOe2mFaThiwCyM2ZA@mail.gmail.com>
 <CAF9-5jOUAvC=t2SHkYEAPzYk9u7OEAvhiv3bob8sWA3KohKhsw@mail.gmail.com>
 <3c0913d6-dbbf-316f-1a9a-075b927562dd@gmail.com>
 <CAGxFJbR8dRLa4wJiCnom=dhUR0ZrWPEqkFW_CF3zu0AiUz+0NQ@mail.gmail.com>
 <CAF9-5jMP+4EbgG9TUkRZzkC=n6ZWL-Lso7916BhZJJHJi4mVLQ@mail.gmail.com>
Message-ID: <20200205191156.222b53d5@trisector>

On Wed, 5 Feb 2020 09:15:16 -0600
Ana Marija <sokovic.anamarija at gmail.com> wrote:

> I tried to solve the task via following code:

> all_results <- lapply(manyorders, function(ord) {

# ...

>  list(fit = fit, y1 = y1)
> })

> and I wrote all_results in a file
> write.table(all_results, file="all_res", sep = " ", row.names = FALSE,
> col.names = TRUE,quote=FALSE)

all_results is a list of lists of pairs of data.frames and MArrayLM
S3 objects, while write.table works best with data.frames (or things
that make sense when coerced to a data.frame). I am afraid that the
result of coercing a list of lists of lists into a data.frame may not
make sense.

What do you need the "all_res" file for? If you just want persistence
(save the data between runs of R programs, but not examine it
manually), consider using saveRDS/readRDS instead. If you need to
interoperate with non-R programs or want a text file for transparency
reasons, read on.

> when I tried to open the file:
> > a=read.table("all_res", header=T)  
> Error in read.table("all_res", header = T) :
>   more columns than column names

Do any of the strings stored in all_results contain spaces?
(y1[,'genelist'] might.) A combination of sep=" " and quote=FALSE could
make such data impossible to read back unambiguously. Does it help to
re-enable quote=TRUE or switch to a different sep (like "\t") that's
guaranteed to be absent from strings you are trying to save? Either
way, read.table() will not reconstruct the same all_results that was
fed to write.table() previously unless all_results is already a
data.frame (which it isn't).

-- 
Best regards,
Ivan


From j@vedbtk111 @end|ng |rom gm@||@com  Wed Feb  5 17:57:27 2020
From: j@vedbtk111 @end|ng |rom gm@||@com (javed khan)
Date: Wed, 5 Feb 2020 17:57:27 +0100
Subject: [R] Class balancing ratio
Message-ID: <CAJhui+uB62=xyxrFG3QyYWC69pu5LaTLJL=_K_Jo4JrG81y-FA@mail.gmail.com>

Hello to all

I am a dataset which needs class balancing ratio of 20 and 80 for class
values. In r language, I am using ROSE function as

Bal=ROSE (cls~., data =training data)

My question is how can we tell the ROSE function to make the balance ratio
20 80?

Best regards

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Feb  5 18:57:20 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 05 Feb 2020 09:57:20 -0800
Subject: [R] Question about autocomplete Keyboard Shortcut in R Markdown
 Latex
In-Reply-To: <CAGxFJbTyJdNf4Nrs--niBGN2jAyBw5t7XEsGYKj5rrhCDcdwFA@mail.gmail.com>
References: <EC8CECB0-701F-496B-B5F5-4E04E27330A4@gmail.com>
 <CAGxFJbTyJdNf4Nrs--niBGN2jAyBw5t7XEsGYKj5rrhCDcdwFA@mail.gmail.com>
Message-ID: <D27110C4-74D0-41DF-B261-DB727A9B6F86@dcn.davis.ca.us>

The rmarkdown package is not the issue... this question is about editor customization. Rmarkdown can be edited in many text editors and IDEs, and none of them are on topic here. That said, there is a high probability that OP is using the RStudio IDE, and indeed it would be best to ask them for assistance if that is the case.

rmarkdown != RStudio
rmarkdown != editor
rmarkdown == package on CRAN.


On February 5, 2020 8:09:35 AM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Try posting this at the RStudio Help site, as R Markdown is part of the
>ecosystem they have created and support.
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Wed, Feb 5, 2020 at 7:44 AM Tao Z <ctfy0312 at gmail.com> wrote:
>
>> Hi,
>>
>> In R, we know how to autocomplete a function name or some arguments
>in the
>> function. I usually use ?Tab? to achieve this.
>> But when I was preparing my math homework using R Markdown, I want to
>> achieve similar results: for example,
>>
>> I want to autocomplete $\frac{}{}$ when I only typed $\fr$. I tried
>?Tab
>> or Command+Space?, but none of them work.
>>
>> Does anyone know if we have autocomplete option for R markdown latex?
>If
>> we do, what keyboard should I use? Thanks
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Feb  5 19:06:55 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 5 Feb 2020 13:06:55 -0500
Subject: [R] Question about autocomplete Keyboard Shortcut in R Markdown
 Latex
In-Reply-To: <D27110C4-74D0-41DF-B261-DB727A9B6F86@dcn.davis.ca.us>
References: <EC8CECB0-701F-496B-B5F5-4E04E27330A4@gmail.com>
 <CAGxFJbTyJdNf4Nrs--niBGN2jAyBw5t7XEsGYKj5rrhCDcdwFA@mail.gmail.com>
 <D27110C4-74D0-41DF-B261-DB727A9B6F86@dcn.davis.ca.us>
Message-ID: <f40841d8-a9b4-5fa6-bcec-62a1155170b8@gmail.com>

On 05/02/2020 12:57 p.m., Jeff Newmiller wrote:
> The rmarkdown package is not the issue... this question is about editor customization. Rmarkdown can be edited in many text editors and IDEs, and none of them are on topic here. That said, there is a high probability that OP is using the RStudio IDE, and indeed it would be best to ask them for assistance if that is the case.
> 
> rmarkdown != RStudio
> rmarkdown != editor
> rmarkdown == package on CRAN.

Also worth mentioning that many editors use the built-in utils::rcompgen 
framework for code completion.  I don't know if RStudio is one of them, 
and I don't know if it would be feasible to add LaTeX completions to it. 
  (R does have a primitive LaTeX parser in tools::parseLatex, so it's 
not completely infeasible.)

Duncan Murdoch

> 
> 
> On February 5, 2020 8:09:35 AM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> Try posting this at the RStudio Help site, as R Markdown is part of the
>> ecosystem they have created and support.
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Feb 5, 2020 at 7:44 AM Tao Z <ctfy0312 at gmail.com> wrote:
>>
>>> Hi,
>>>
>>> In R, we know how to autocomplete a function name or some arguments
>> in the
>>> function. I usually use ?Tab? to achieve this.
>>> But when I was preparing my math homework using R Markdown, I want to
>>> achieve similar results: for example,
>>>
>>> I want to autocomplete $\frac{}{}$ when I only typed $\fr$. I tried
>> ?Tab
>>> or Command+Space?, but none of them work.
>>>
>>> Does anyone know if we have autocomplete option for R markdown latex?
>> If
>>> we do, what keyboard should I use? Thanks
>>>
>>>
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter@4567 @end|ng |rom gm@||@com  Wed Feb  5 19:38:56 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 5 Feb 2020 10:38:56 -0800
Subject: [R] Class balancing ratio
In-Reply-To: <CAJhui+uB62=xyxrFG3QyYWC69pu5LaTLJL=_K_Jo4JrG81y-FA@mail.gmail.com>
References: <CAJhui+uB62=xyxrFG3QyYWC69pu5LaTLJL=_K_Jo4JrG81y-FA@mail.gmail.com>
Message-ID: <CAGxFJbRnjzPxo3Cs0qYDMJAb34EjuLh_ai-WGMBmNLeKEySdvA@mail.gmail.com>

Questions on specialized packages (the ROSE package presumably) may not get
answered on this list. If that turns out to be the case, you may wish to
contact the package maintainer: Nicola Lunardon <lunardon at stat.unipd.it>  .


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 5, 2020 at 8:57 AM javed khan <javedbtk111 at gmail.com> wrote:

> Hello to all
>
> I am a dataset which needs class balancing ratio of 20 and 80 for class
> values. In r language, I am using ROSE function as
>
> Bal=ROSE (cls~., data =training data)
>
> My question is how can we tell the ROSE function to make the balance ratio
> 20 80?
>
> Best regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From t@ub|@ @end|ng |rom |mgprec|@|on@com  Wed Feb  5 20:09:01 2020
From: t@ub|@ @end|ng |rom |mgprec|@|on@com (Thomas Subia)
Date: Wed, 5 Feb 2020 19:09:01 +0000
Subject: [R] readxl issue
Message-ID: <BY5PR17MB3956A674047876F609472FFAB8020@BY5PR17MB3956.namprd17.prod.outlook.com>

Colleagues,

I'm using readxl and dplyr to extract a specific cell from all worksheets in a directory.
All of these worksheets have the same physical layout.

Issue 1: Minus sign replaced by an X after data extraction.

library(plyr)
library(readxl)

files <- list.files(pattern="*.xls", full.names = FALSE)
avgs <- lapply(files, read_excel, sheet="Flow Data", range=("c9"))
avg_list <- as.data.frame(avgs)
trans_avgs <- t(avg_list)
write.table(trans_avgs,"avgs.txt")

Here are the first lines of the avgs.txt file.
"X.0.51571428571428557" 
"X.0.5349795918367346" 
"X.0.4895714285714286" 
"X.0.5112448979591836"

The original Excel file contains
-0.516
-0.535
-0.490
-0.511

It appears that readxl is changing the - sign to an X.
Is there any feature in readxl which I can change so that readxl extracts the minus sign?

Issue 2: Duplicate dates contain additional characters

dates <- lapply(files, read_excel, sheet="Flow Data", range=("h14"))
dates_list <- as.data.frame(dates)
trans_dates <- t(dates_list)
write.table(trans_dates ,"dates.txt")

Here are the first lines of the dates.txt file.

"X43859" 
"X43859.1" 
"X43859.2" 
"X43859.3" 
"X43833"

In Excel, this is what is recorded.

1/29/2020
1/29/2020
1/29/2020
1/29/2020
1/3/2020

It appears that readxl is adding additional characters which are signaling duplicate dates.
Is there any feature in readxl which can I can change to eliminate these additional characters?

Some advice would be appreciated.


Thomas Subia 

Statistician / Senior Quality Engineer
IMG Companies?
225 Mountain Vista Parkway
Livermore, CA 94551
T.?(925) 273-1106
F.?(925) 273-1111
E. tsubia at imgprecision.com


Precision Manufacturing for Emerging Technologies
imgprecision.com?

The contents of this message, together with any attachments, are intended only for the use of the individual or entity to which they are addressed and may contain information that is legally privileged, confidential and exempt from disclosure. If you are not the intended recipient, you are hereby notified that any dissemination, distribution, or copying of this message, or any attachment, is strictly prohibited. If you have received this message in error, please notify the original sender or IMG Companies, LLC at Tel: 925-273-1100 immediately by telephone or by return E-mail and delete this message, along with any attachments, from your computer. Thank you.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Feb  5 20:42:24 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 05 Feb 2020 11:42:24 -0800
Subject: [R] readxl issue
In-Reply-To: <BY5PR17MB3956A674047876F609472FFAB8020@BY5PR17MB3956.namprd17.prod.outlook.com>
References: <BY5PR17MB3956A674047876F609472FFAB8020@BY5PR17MB3956.namprd17.prod.outlook.com>
Message-ID: <E76C2D79-D7FE-44BE-8A8A-32005AC68941@dcn.davis.ca.us>

Pay attention to whether the read_csv call is configured to expect first line as header.

On February 5, 2020 11:09:01 AM PST, Thomas Subia <tsubia at imgprecision.com> wrote:
>Colleagues,
>
>I'm using readxl and dplyr to extract a specific cell from all
>worksheets in a directory.
>All of these worksheets have the same physical layout.
>
>Issue 1: Minus sign replaced by an X after data extraction.
>
>library(plyr)
>library(readxl)
>
>files <- list.files(pattern="*.xls", full.names = FALSE)
>avgs <- lapply(files, read_excel, sheet="Flow Data", range=("c9"))
>avg_list <- as.data.frame(avgs)
>trans_avgs <- t(avg_list)
>write.table(trans_avgs,"avgs.txt")
>
>Here are the first lines of the avgs.txt file.
>"X.0.51571428571428557" 
>"X.0.5349795918367346" 
>"X.0.4895714285714286" 
>"X.0.5112448979591836"
>
>The original Excel file contains
>-0.516
>-0.535
>-0.490
>-0.511
>
>It appears that readxl is changing the - sign to an X.
>Is there any feature in readxl which I can change so that readxl
>extracts the minus sign?
>
>Issue 2: Duplicate dates contain additional characters
>
>dates <- lapply(files, read_excel, sheet="Flow Data", range=("h14"))
>dates_list <- as.data.frame(dates)
>trans_dates <- t(dates_list)
>write.table(trans_dates ,"dates.txt")
>
>Here are the first lines of the dates.txt file.
>
>"X43859" 
>"X43859.1" 
>"X43859.2" 
>"X43859.3" 
>"X43833"
>
>In Excel, this is what is recorded.
>
>1/29/2020
>1/29/2020
>1/29/2020
>1/29/2020
>1/3/2020
>
>It appears that readxl is adding additional characters which are
>signaling duplicate dates.
>Is there any feature in readxl which can I can change to eliminate
>these additional characters?
>
>Some advice would be appreciated.
>
>
>Thomas Subia 
>
>Statistician / Senior Quality Engineer
>IMG Companies?
>225 Mountain Vista Parkway
>Livermore, CA 94551
>T.?(925) 273-1106
>F.?(925) 273-1111
>E. tsubia at imgprecision.com
>
>
>Precision Manufacturing for Emerging Technologies
>imgprecision.com?
>
>The contents of this message, together with any attachments, are
>intended only for the use of the individual or entity to which they are
>addressed and may contain information that is legally privileged,
>confidential and exempt from disclosure. If you are not the intended
>recipient, you are hereby notified that any dissemination,
>distribution, or copying of this message, or any attachment, is
>strictly prohibited. If you have received this message in error, please
>notify the original sender or IMG Companies, LLC at Tel: 925-273-1100
>immediately by telephone or by return E-mail and delete this message,
>along with any attachments, from your computer. Thank you.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From t@ub|@ @end|ng |rom |mgprec|@|on@com  Wed Feb  5 23:01:07 2020
From: t@ub|@ @end|ng |rom |mgprec|@|on@com (Thomas Subia)
Date: Wed, 5 Feb 2020 22:01:07 +0000
Subject: [R] readxl issue
In-Reply-To: <E76C2D79-D7FE-44BE-8A8A-32005AC68941@dcn.davis.ca.us>
References: <BY5PR17MB3956A674047876F609472FFAB8020@BY5PR17MB3956.namprd17.prod.outlook.com>
 <E76C2D79-D7FE-44BE-8A8A-32005AC68941@dcn.davis.ca.us>
Message-ID: <BY5PR17MB3956AA1A4A3A8BE799FC7F43B8020@BY5PR17MB3956.namprd17.prod.outlook.com>

Jeff,

You wrote: " Pay attention to whether the read_csv call is configured to expect first line as header."

Here is the code I'm using to extract one cell from a series of Excel files having the same physical format.

library(plyr)
library(readxl)
files <- list.files(pattern="*.xls", full.names = TRUE)
# Extract part average from cell c6 for all Excel files
avgs <- lapply(files, read_excel, sheet="Flow Data", range=("c9"))
# Write data to text file
write.table(avgs ,"avgs.txt",sep="\t")

I'm not sure where read_csv applies here.

Thanks for your help!

Thomas Subia

-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
Sent: Wednesday, February 05, 2020 11:42 AM
To: r-help at r-project.org; Thomas Subia <tsubia at imgprecision.com>; r-help at r-project.org
Subject: Re: [R] readxl issue

Pay attention to whether the read_csv call is configured to expect first line as header.

On February 5, 2020 11:09:01 AM PST, Thomas Subia <tsubia at imgprecision.com> wrote:
>Colleagues,
>
>I'm using readxl and dplyr to extract a specific cell from all 
>worksheets in a directory.
>All of these worksheets have the same physical layout.
>
>Issue 1: Minus sign replaced by an X after data extraction.
>
>library(plyr)
>library(readxl)
>
>files <- list.files(pattern="*.xls", full.names = FALSE) avgs <- 
>lapply(files, read_excel, sheet="Flow Data", range=("c9")) avg_list <- 
>as.data.frame(avgs) trans_avgs <- t(avg_list)
>write.table(trans_avgs,"avgs.txt")
>
>Here are the first lines of the avgs.txt file.
>"X.0.51571428571428557" 
>"X.0.5349795918367346" 
>"X.0.4895714285714286" 
>"X.0.5112448979591836"
>
>The original Excel file contains
>-0.516
>-0.535
>-0.490
>-0.511
>
>It appears that readxl is changing the - sign to an X.
>Is there any feature in readxl which I can change so that readxl 
>extracts the minus sign?
>
>Issue 2: Duplicate dates contain additional characters
>
>dates <- lapply(files, read_excel, sheet="Flow Data", range=("h14")) 
>dates_list <- as.data.frame(dates) trans_dates <- t(dates_list) 
>write.table(trans_dates ,"dates.txt")
>
>Here are the first lines of the dates.txt file.
>
>"X43859" 
>"X43859.1" 
>"X43859.2" 
>"X43859.3" 
>"X43833"
>
>In Excel, this is what is recorded.
>
>1/29/2020
>1/29/2020
>1/29/2020
>1/29/2020
>1/3/2020
>
>It appears that readxl is adding additional characters which are 
>signaling duplicate dates.
>Is there any feature in readxl which can I can change to eliminate 
>these additional characters?
>
>Some advice would be appreciated.
>
>
>Thomas Subia
>
>Statistician / Senior Quality Engineer
>IMG Companies
>225 Mountain Vista Parkway
>Livermore, CA 94551
>T.?(925) 273-1106
>F.?(925) 273-1111
>E. tsubia at imgprecision.com
>
>
>Precision Manufacturing for Emerging Technologies imgprecision.com
>
>The contents of this message, together with any attachments, are 
>intended only for the use of the individual or entity to which they are 
>addressed and may contain information that is legally privileged, 
>confidential and exempt from disclosure. If you are not the intended 
>recipient, you are hereby notified that any dissemination, 
>distribution, or copying of this message, or any attachment, is 
>strictly prohibited. If you have received this message in error, please 
>notify the original sender or IMG Companies, LLC at Tel: 925-273-1100 
>immediately by telephone or by return E-mail and delete this message, 
>along with any attachments, from your computer. Thank you.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

From drj|m|emon @end|ng |rom gm@||@com  Wed Feb  5 23:36:44 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 6 Feb 2020 09:36:44 +1100
Subject: [R] Class balancing ratio
In-Reply-To: <CAGxFJbRnjzPxo3Cs0qYDMJAb34EjuLh_ai-WGMBmNLeKEySdvA@mail.gmail.com>
References: <CAJhui+uB62=xyxrFG3QyYWC69pu5LaTLJL=_K_Jo4JrG81y-FA@mail.gmail.com>
 <CAGxFJbRnjzPxo3Cs0qYDMJAb34EjuLh_ai-WGMBmNLeKEySdvA@mail.gmail.com>
Message-ID: <CA+8X3fWnyr8hwTRdddNgOsynw0w10F2aR5s_pKSNYmO3SS_u7A@mail.gmail.com>

Hi Javed,
You may want to look at the

p=

argument to the function. It is explained in the help page.

Jim

> On Wed, Feb 5, 2020 at 8:57 AM javed khan <javedbtk111 at gmail.com> wrote:
>
> > Hello to all
> >
> > I am a dataset which needs class balancing ratio of 20 and 80 for class
> > values. In r language, I am using ROSE function as
> >
> > Bal=ROSE (cls~., data =training data)
> >
> > My question is how can we tell the ROSE function to make the balance ratio
> > 20 80?
> >
> > Best regards
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Feb  6 00:48:36 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 6 Feb 2020 12:48:36 +1300
Subject: [R] [FORGED] Re:  readxl issue
In-Reply-To: <BY5PR17MB3956AA1A4A3A8BE799FC7F43B8020@BY5PR17MB3956.namprd17.prod.outlook.com>
References: <BY5PR17MB3956A674047876F609472FFAB8020@BY5PR17MB3956.namprd17.prod.outlook.com>
 <E76C2D79-D7FE-44BE-8A8A-32005AC68941@dcn.davis.ca.us>
 <BY5PR17MB3956AA1A4A3A8BE799FC7F43B8020@BY5PR17MB3956.namprd17.prod.outlook.com>
Message-ID: <0a1f186d-0656-2092-afbc-e00544c5492c@auckland.ac.nz>


On 6/02/20 11:01 am, Thomas Subia wrote:

> Jeff,
> 
> You wrote: " Pay attention to whether the read_csv call is configured to expect first line as header."
> 
> Here is the code I'm using to extract one cell from a series of Excel files having the same physical format.
> 
> library(plyr)
> library(readxl)
> files <- list.files(pattern="*.xls", full.names = TRUE)
> # Extract part average from cell c6 for all Excel files
> avgs <- lapply(files, read_excel, sheet="Flow Data", range=("c9"))
> # Write data to text file
> write.table(avgs ,"avgs.txt",sep="\t")
> 
> I'm not sure where read_csv applies here.

Jeff probably did not read your email as carefully as he might have, and 
made the unwarranted assumption that you'd be doing something sensible 
like using *.csv data files rather than mucking about with the 
notoriously perilous arcana of Excel.

I *don't* muck about with Excel myself, unless absolutely forced to, so 
I can't make any specific suggestions, but I *can* make a general 
suggestion.  When things go wrong, break the procedure down into simple 
atomic steps.

* initially deal with just *one* of your *.xls files
* read it in:  xxx <- read_excel(<whatever>)
* *don't* write it out to a text file yet, *look* at the <expletive 
deleted> thing in R first; print it (just type "xxx" or "head(xxx)" if 
it's large)
* perhaps convert it to a data frame (it will be a "tibble" and tibbles 
confuse the issue): yyy <- as.data.frame(xxx)
* investigate whether supplying some more arguments to read_excel() 
solves your problem
* perhaps try read.xlsx from the xlsx package and see if any insights 
are revealed.
* if you're still stumped, make available to the list one of the 
problematic *.xls files (note that you *cannot* attach such a file to 
your email; it will get stripped; you'll need to provide a URL from 
which the file can be obtained).  Given such a file someone on the list 
may be able to help you.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Thu Feb  6 01:37:05 2020
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Wed, 5 Feb 2020 16:37:05 -0800
Subject: [R] how to create a pivot table in r?
Message-ID: <CAMwU6B3kGfPieB5iy5OmW65mEEqLDxX6ZQYp_Oa6MDXVi1byhQ@mail.gmail.com>

Hi R users,
I was trying to create a pivot table for the following data, in which I
wanted to put "id" in  rows and "ObsSite" in columns and "Obsdate" is in
the cells.

I used the following code but it took only one date among the two dates.
For example, the animal (Id2) which was observed in the site7  two time or
days (07/03/14 & 05/17/2014). see below
id ObsSite ObsDate
id1 site7 06/13/13
id2 site7 07/03/14
id2 site7 05/17/14
id4 site4 05/08/14
id5 site5 06/13/14
id6 site1 05/30/14
id6 site1 06/28/13
id7 site5 06/25/13

I wanted to put both dates in the cell if there is any multiple dates, as
similar shown below





  site1 site4 site5 site7
id1 0 0 0 6/13/13
id2 0 0 0 7/3/2014, 5/17/2014
id4 0 5/8/14 0 0
id5 0 0 6/13/14 0
id6 5/30/2014, 6/28/2013 0 0 0
id7 0 0 6/25/13 0

the code I used is given below but it gave me only one date in that cells.
Is there any way to get both dates in these cells?
Thanks,

###
library(lubridate)
daT<-structure(list(id = structure(c(1L, 2L, 2L, 3L, 4L, 5L, 5L, 6L
), .Label = c("id1", "id2", "id4", "id5", "id6", "id7"), class = "factor"),
    ObsSite = structure(c(4L, 4L, 4L, 2L, 3L, 1L, 1L, 3L), .Label =
c("site1",
    "site4", "site5", "site7"), class = "factor"), ObsDate =
structure(c(4L,
    8L, 2L, 1L, 5L, 3L, 7L, 6L), .Label = c("05/08/14", "05/17/14",
    "05/30/14", "06/13/13", "06/13/14", "06/25/13", "06/28/13",
    "07/03/14"), class = "factor")), .Names = c("id", "ObsSite",
"ObsDate"), class = "data.frame", row.names = c(NA, -8L))
daT
daT$date <- mdy(daT$ObsDate)
tmp <- split(daT, daT$id)
head(tmp)

pivotTable <- do.call(rbind, lapply(tmp, function(daT){
  tb <- table(daT$ObsSite)
  idx <- which(tb>0)
  tb1 <- replace(tb, idx, as.character(daT$date))
}))


data.frame(pivotTable)

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Feb  6 02:04:35 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 05 Feb 2020 17:04:35 -0800
Subject: [R] [FORGED] Re:  readxl issue
In-Reply-To: <0a1f186d-0656-2092-afbc-e00544c5492c@auckland.ac.nz>
References: <BY5PR17MB3956A674047876F609472FFAB8020@BY5PR17MB3956.namprd17.prod.outlook.com>
 <E76C2D79-D7FE-44BE-8A8A-32005AC68941@dcn.davis.ca.us>
 <BY5PR17MB3956AA1A4A3A8BE799FC7F43B8020@BY5PR17MB3956.namprd17.prod.outlook.com>
 <0a1f186d-0656-2092-afbc-e00544c5492c@auckland.ac.nz>
Message-ID: <76D726A0-D962-4FBA-B6C4-B3D9EA1CED63@dcn.davis.ca.us>

My assessment was and is likely correct.

My error was in writing the wrong function name... should have been read_excel whose parameters need to be adjusted to not look for a header line.

On February 5, 2020 3:48:36 PM PST, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>On 6/02/20 11:01 am, Thomas Subia wrote:
>
>> Jeff,
>> 
>> You wrote: " Pay attention to whether the read_csv call is configured
>to expect first line as header."
>> 
>> Here is the code I'm using to extract one cell from a series of Excel
>files having the same physical format.
>> 
>> library(plyr)
>> library(readxl)
>> files <- list.files(pattern="*.xls", full.names = TRUE)
>> # Extract part average from cell c6 for all Excel files
>> avgs <- lapply(files, read_excel, sheet="Flow Data", range=("c9"))
>> # Write data to text file
>> write.table(avgs ,"avgs.txt",sep="\t")
>> 
>> I'm not sure where read_csv applies here.
>
>Jeff probably did not read your email as carefully as he might have,
>and 
>made the unwarranted assumption that you'd be doing something sensible 
>like using *.csv data files rather than mucking about with the 
>notoriously perilous arcana of Excel.
>
>I *don't* muck about with Excel myself, unless absolutely forced to, so
>
>I can't make any specific suggestions, but I *can* make a general 
>suggestion.  When things go wrong, break the procedure down into simple
>
>atomic steps.
>
>* initially deal with just *one* of your *.xls files
>* read it in:  xxx <- read_excel(<whatever>)
>* *don't* write it out to a text file yet, *look* at the <expletive 
>deleted> thing in R first; print it (just type "xxx" or "head(xxx)" if 
>it's large)
>* perhaps convert it to a data frame (it will be a "tibble" and tibbles
>
>confuse the issue): yyy <- as.data.frame(xxx)
>* investigate whether supplying some more arguments to read_excel() 
>solves your problem
>* perhaps try read.xlsx from the xlsx package and see if any insights 
>are revealed.
>* if you're still stumped, make available to the list one of the 
>problematic *.xls files (note that you *cannot* attach such a file to 
>your email; it will get stripped; you'll need to provide a URL from 
>which the file can be obtained).  Given such a file someone on the list
>
>may be able to help you.
>
>cheers,
>
>Rolf Turner

-- 
Sent from my phone. Please excuse my brevity.


From @purd|e@@ @end|ng |rom gm@||@com  Thu Feb  6 02:10:11 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Thu, 6 Feb 2020 14:10:11 +1300
Subject: [R] readxl issue
In-Reply-To: <BY5PR17MB3956A674047876F609472FFAB8020@BY5PR17MB3956.namprd17.prod.outlook.com>
References: <BY5PR17MB3956A674047876F609472FFAB8020@BY5PR17MB3956.namprd17.prod.outlook.com>
Message-ID: <CAB8pepyDCtZeAzqxDL4DuovGTsHc+kL1tRPwbGZNF2MZTMhC=A@mail.gmail.com>

> I'm using readxl and dplyr to extract a specific cell from all worksheets in a directory.
> All of these worksheets have the same physical layout.

I don't have access to Excel, so can't test this.

I have a suspicion that the problem is not readxl.
But rather the "as.data.frame" step.

Try reading one file at a time.
And inspect (1) your immediate object after reading the Excel file,
and then (2) the data.frame after the as.data.frame call.


From @purd|e@@ @end|ng |rom gm@||@com  Thu Feb  6 02:30:13 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Thu, 6 Feb 2020 14:30:13 +1300
Subject: [R] [FORGED] Re: readxl issue
In-Reply-To: <76D726A0-D962-4FBA-B6C4-B3D9EA1CED63@dcn.davis.ca.us>
References: <BY5PR17MB3956A674047876F609472FFAB8020@BY5PR17MB3956.namprd17.prod.outlook.com>
 <E76C2D79-D7FE-44BE-8A8A-32005AC68941@dcn.davis.ca.us>
 <BY5PR17MB3956AA1A4A3A8BE799FC7F43B8020@BY5PR17MB3956.namprd17.prod.outlook.com>
 <0a1f186d-0656-2092-afbc-e00544c5492c@auckland.ac.nz>
 <76D726A0-D962-4FBA-B6C4-B3D9EA1CED63@dcn.davis.ca.us>
Message-ID: <CAB8pepzHKxxmKWF2Ymvx_PV6Ea3SyUr2wMpE26bGXsL+KDGhtQ@mail.gmail.com>

> should have been read_excel whose parameters need to be adjusted to not look for a header line.

And Jeff's probably correct (from the package documentation):
> read_excel(path, sheet = NULL, range = NULL, col_names = TRUE,

Set col_names to FALSE...???

But still be careful with the as.data.frame call.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Feb  6 06:34:06 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 6 Feb 2020 05:34:06 +0000
Subject: [R] how to create a pivot table in r?
In-Reply-To: <CAMwU6B3kGfPieB5iy5OmW65mEEqLDxX6ZQYp_Oa6MDXVi1byhQ@mail.gmail.com>
References: <CAMwU6B3kGfPieB5iy5OmW65mEEqLDxX6ZQYp_Oa6MDXVi1byhQ@mail.gmail.com>
Message-ID: <7696e71c-0e00-f812-ca46-ed230043e2f0@sapo.pt>

Hello,

Function tidyr::pivot_wider is meant for this kind of problem. It is 
package tidyr's new way of reshaping from long to wide format. QUoting 
from the help page:

Details

pivot_wider() is an updated approach to spread(), designed to be both 
simpler to use and to handle more use cases. We recomend you use 
pivot_wider() for new code; spread() isn't going away but is no longer 
under active development.


In what follows I have use column 'date' to fill the cells, not column 
'ObsDate' like in your question. Just change this and you'll get your 
expected result.


library(dplyr)
library(tidyr)
library(lubridate)

daT %>%
   arrange(ObsSite) %>%
   pivot_wider(id_cols = id,
               names_from = ObsSite,
               values_from = date,
               values_fn = list(date = function(x){
                 paste(x, collapse = ",")
               })) %>%
   mutate_all(function(x) ifelse(is.na(x), 0, x)) %>%
   arrange(id)


Hope this helps,

Rui Barradas



?s 00:37 de 06/02/20, Marna Wagley escreveu:
> Hi R users,
> I was trying to create a pivot table for the following data, in which I
> wanted to put "id" in  rows and "ObsSite" in columns and "Obsdate" is in
> the cells.
> 
> I used the following code but it took only one date among the two dates.
> For example, the animal (Id2) which was observed in the site7  two time or
> days (07/03/14 & 05/17/2014). see below
> id ObsSite ObsDate
> id1 site7 06/13/13
> id2 site7 07/03/14
> id2 site7 05/17/14
> id4 site4 05/08/14
> id5 site5 06/13/14
> id6 site1 05/30/14
> id6 site1 06/28/13
> id7 site5 06/25/13
> 
> I wanted to put both dates in the cell if there is any multiple dates, as
> similar shown below
> 
> 
> 
> 
> 
>    site1 site4 site5 site7
> id1 0 0 0 6/13/13
> id2 0 0 0 7/3/2014, 5/17/2014
> id4 0 5/8/14 0 0
> id5 0 0 6/13/14 0
> id6 5/30/2014, 6/28/2013 0 0 0
> id7 0 0 6/25/13 0
> 
> the code I used is given below but it gave me only one date in that cells.
> Is there any way to get both dates in these cells?
> Thanks,
> 
> ###
> library(lubridate)
> daT<-structure(list(id = structure(c(1L, 2L, 2L, 3L, 4L, 5L, 5L, 6L
> ), .Label = c("id1", "id2", "id4", "id5", "id6", "id7"), class = "factor"),
>      ObsSite = structure(c(4L, 4L, 4L, 2L, 3L, 1L, 1L, 3L), .Label =
> c("site1",
>      "site4", "site5", "site7"), class = "factor"), ObsDate =
> structure(c(4L,
>      8L, 2L, 1L, 5L, 3L, 7L, 6L), .Label = c("05/08/14", "05/17/14",
>      "05/30/14", "06/13/13", "06/13/14", "06/25/13", "06/28/13",
>      "07/03/14"), class = "factor")), .Names = c("id", "ObsSite",
> "ObsDate"), class = "data.frame", row.names = c(NA, -8L))
> daT
> daT$date <- mdy(daT$ObsDate)
> tmp <- split(daT, daT$id)
> head(tmp)
> 
> pivotTable <- do.call(rbind, lapply(tmp, function(daT){
>    tb <- table(daT$ObsSite)
>    idx <- which(tb>0)
>    tb1 <- replace(tb, idx, as.character(daT$date))
> }))
> 
> 
> data.frame(pivotTable)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From nev||@@mo@ @end|ng |rom gm@||@com  Fri Feb  7 05:34:05 2020
From: nev||@@mo@ @end|ng |rom gm@||@com (nevil amos)
Date: Fri, 7 Feb 2020 15:34:05 +1100
Subject: [R] Cannot view custom tiles made in package tiler in r leaflet -
 either locally or from github pages server.
Message-ID: <CAN9eD7nVw9eir_3E4LePSVYAq9NaMtr+FFj=mHV3Etdk=UKM2w@mail.gmail.com>

I wish to create tiled version of a large number of custom rasters for
viewing in shiny/leaflet apps ( to speed viewing of rasters)

I have produced tiles using  package tiler, these can be viewed in the
preview.html, but when uploaded to github pages  as described in the
introduction to tiler they do not show up when added as tiles in leaflet.

It is difficult to make a reproducible code here - since the tiles have to
be loaded to be served from the web.

However below I include the code used 1. to produce the tiles and 2, to
view the tiles in my github pages.

I have tried the suggestion of using {-y} in the sever path for TMS, this
makes no difference the background map is displayed but the custom tiles
are not.

Raster used from the package as an example in reality I need to serve many
10000x6000 cell geotiffs.

Example code:

library(tiler)
libary(leaflet)
# make tiles in zoom levels 1:6 these tiles have then been uploaded to
github to serve from repository:
#

tile_dir<-"us48lr"
map <- system.file("maps/map_wgs84.tif", package = "tiler")
tile(map,tile_dir , "0-6")
view_tiles(tile_dir)


#no TMS related modifications
tiles <- "https://nevilamos.github.io/TileTest/us48lr/{z}/{x}/{y}.png"
leaflet(
  options = leafletOptions(minZoom = 0, maxZoom = 7), width = "100%") %>%
  addProviderTiles("Stamen.Toner") %>%
  addTiles(urlTemplate=tiles, options = tileOptions(opacity = 0.8)) %>%
setView(-100, 40, 3)

#No tiles displayed


# {-y} and tileOptions(tms=T)
tiles <- "https://nevilamos.github.io/TileTest/us48lr/{z}/{x}/{-y}.png"
leaflet(
  options = leafletOptions(minZoom = 0, maxZoom = 7), width = "100%") %>%
  addProviderTiles("Stamen.Toner") %>%
  addTiles(urlTemplate=tiles, options = tileOptions(opacity = 0.8,tms=T))
%>% setView(-100, 40, 3)

#No tiles displayed

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Thu Feb  6 11:02:43 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Thu, 6 Feb 2020 11:02:43 +0100
Subject: [R] how to create a pivot table in r?
In-Reply-To: <CAMwU6B3kGfPieB5iy5OmW65mEEqLDxX6ZQYp_Oa6MDXVi1byhQ@mail.gmail.com>
References: <CAMwU6B3kGfPieB5iy5OmW65mEEqLDxX6ZQYp_Oa6MDXVi1byhQ@mail.gmail.com>
Message-ID: <F194979E-5BC4-41B7-BE7C-751CAA917210@gmail.com>

There is also

> with(daT, tapply(as.character(ObsDate), list(id, ObsSite), function(x)format(list(x))))
    site1                site4      site5      site7               
id1 NA                   NA         NA         "06/13/13"          
id2 NA                   NA         NA         "07/03/14, 05/17/14"
id4 NA                   "05/08/14" NA         NA                  
id5 NA                   NA         "06/13/14" NA                  
id6 "05/30/14, 06/28/13" NA         NA         NA                  
id7 NA                   NA         "06/25/13" NA     

...with the added bonus that if you leave out the format() business, you get a data structure that doesn't print as nicely, but can be used for further computations:

> with(daT, tapply(as.character(ObsDate), list(id, ObsSite), list, simplify=FALSE))
    site1  site4  site5  site7 
id1 NULL   NULL   NULL   List,1
id2 NULL   NULL   NULL   List,1
id4 NULL   List,1 NULL   NULL  
id5 NULL   NULL   List,1 NULL  
id6 List,1 NULL   NULL   NULL  
id7 NULL   NULL   List,1 NULL  
> M <- with(daT, tapply(as.character(ObsDate), list(id, ObsSite), list, simplify=FALSE))
> M[["id2", "site7"]]
[[1]]
[1] "07/03/14" "05/17/14"

-pd             

> On 6 Feb 2020, at 01:37 , Marna Wagley <marna.wagley at gmail.com> wrote:
> 
> daT<-structure(list(id = structure(c(1L, 2L, 2L, 3L, 4L, 5L, 5L, 6L
> ), .Label = c("id1", "id2", "id4", "id5", "id6", "id7"), class = "factor"),
>    ObsSite = structure(c(4L, 4L, 4L, 2L, 3L, 1L, 1L, 3L), .Label =
> c("site1",
>    "site4", "site5", "site7"), class = "factor"), ObsDate =
> structure(c(4L,
>    8L, 2L, 1L, 5L, 3L, 7L, 6L), .Label = c("05/08/14", "05/17/14",
>    "05/30/14", "06/13/13", "06/13/14", "06/25/13", "06/28/13",
>    "07/03/14"), class = "factor")), .Names = c("id", "ObsSite",
> "ObsDate"), class = "data.frame", row.names = c(NA, -8L))
> daT
> daT$date <- mdy(daT$ObsDate)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From gho||@ge@|c @end|ng |rom gm@||@com  Thu Feb  6 11:04:02 2020
From: gho||@ge@|c @end|ng |rom gm@||@com (Gabriela Hoff)
Date: Thu, 6 Feb 2020 07:04:02 -0300
Subject: [R] Information about pairwise Wilcoxon Sum Rank Tests
Message-ID: <CABJWKrpD2Y+dDY6QOsL0GyQ4Az6Y8uupXW=91AsH786Nptuv=g@mail.gmail.com>

Dear Sir or Madam

My name is Gabriela Hoff and I and an R user. I am facing problems in
finding detailed information about pairwise Wilcoxon Rank Sum Tests
(pairwise.wilcox.test). I would like to understand better the way this test
is performed and the calculation of p-value, especially the procedure used
on the corrections for multiple testing.

 I do appreciate it a lot if you could send me information about that since
I was unable to find those details in the R documentation.

Best regards,

-- 
Gabriela Hoff
PhD in Nuclear Bioscience - Medical Physics
Phone: +55 51 998714374

	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Thu Feb  6 11:53:11 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Thu, 6 Feb 2020 10:53:11 +0000
Subject: [R] Information about pairwise Wilcoxon Sum Rank Tests
In-Reply-To: <CABJWKrpD2Y+dDY6QOsL0GyQ4Az6Y8uupXW=91AsH786Nptuv=g@mail.gmail.com>
References: <CABJWKrpD2Y+dDY6QOsL0GyQ4Az6Y8uupXW=91AsH786Nptuv=g@mail.gmail.com>
Message-ID: <9d613c26-a3e7-c748-bd1f-0854680c09da@dewey.myzen.co.uk>

Dear Gabriela

Apologies if you have already tried this but:

1 - you can see the code which it uses by typing pairwise.wilcox.test at 
the command line.

2 - to find you more about the method of adjustment you need to follow 
the documentation for p.adjust

3 - you may also need to look into wilcox.test which 
pairwise.wilcox.test uses.

If that does not help come back and tell us more about how far you have 
got so people know what else you need.

Michael

On 06/02/2020 10:04, Gabriela Hoff wrote:
> Dear Sir or Madam
> 
> My name is Gabriela Hoff and I and an R user. I am facing problems in
> finding detailed information about pairwise Wilcoxon Rank Sum Tests
> (pairwise.wilcox.test). I would like to understand better the way this test
> is performed and the calculation of p-value, especially the procedure used
> on the corrections for multiple testing.
> 
>   I do appreciate it a lot if you could send me information about that since
> I was unable to find those details in the R documentation.
> 
> Best regards,
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From bgunter@4567 @end|ng |rom gm@||@com  Thu Feb  6 13:10:19 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 6 Feb 2020 04:10:19 -0800
Subject: [R] 
 Cannot view custom tiles made in package tiler in r leaflet -
 either locally or from github pages server.
In-Reply-To: <CAN9eD7nVw9eir_3E4LePSVYAq9NaMtr+FFj=mHV3Etdk=UKM2w@mail.gmail.com>
References: <CAN9eD7nVw9eir_3E4LePSVYAq9NaMtr+FFj=mHV3Etdk=UKM2w@mail.gmail.com>
Message-ID: <CAGxFJbTQzcrgWzB+v9p28PHSekHPKupo-O=UqNkvpOAC8mAxRw@mail.gmail.com>

Shouldn't you be posting this on the r-sig-geo list, not here?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 5, 2020 at 10:38 PM nevil amos <nevil.amos at gmail.com> wrote:

> I wish to create tiled version of a large number of custom rasters for
> viewing in shiny/leaflet apps ( to speed viewing of rasters)
>
> I have produced tiles using  package tiler, these can be viewed in the
> preview.html, but when uploaded to github pages  as described in the
> introduction to tiler they do not show up when added as tiles in leaflet.
>
> It is difficult to make a reproducible code here - since the tiles have to
> be loaded to be served from the web.
>
> However below I include the code used 1. to produce the tiles and 2, to
> view the tiles in my github pages.
>
> I have tried the suggestion of using {-y} in the sever path for TMS, this
> makes no difference the background map is displayed but the custom tiles
> are not.
>
> Raster used from the package as an example in reality I need to serve many
> 10000x6000 cell geotiffs.
>
> Example code:
>
> library(tiler)
> libary(leaflet)
> # make tiles in zoom levels 1:6 these tiles have then been uploaded to
> github to serve from repository:
> #
>
> tile_dir<-"us48lr"
> map <- system.file("maps/map_wgs84.tif", package = "tiler")
> tile(map,tile_dir , "0-6")
> view_tiles(tile_dir)
>
>
> #no TMS related modifications
> tiles <- "https://nevilamos.github.io/TileTest/us48lr/{z}/{x}/{y}.png"
> leaflet(
>   options = leafletOptions(minZoom = 0, maxZoom = 7), width = "100%") %>%
>   addProviderTiles("Stamen.Toner") %>%
>   addTiles(urlTemplate=tiles, options = tileOptions(opacity = 0.8)) %>%
> setView(-100, 40, 3)
>
> #No tiles displayed
>
>
> # {-y} and tileOptions(tms=T)
> tiles <- "https://nevilamos.github.io/TileTest/us48lr/{z}/{x}/{-y}.png"
> leaflet(
>   options = leafletOptions(minZoom = 0, maxZoom = 7), width = "100%") %>%
>   addProviderTiles("Stamen.Toner") %>%
>   addTiles(urlTemplate=tiles, options = tileOptions(opacity = 0.8,tms=T))
> %>% setView(-100, 40, 3)
>
> #No tiles displayed
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Feb  6 13:11:25 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 6 Feb 2020 04:11:25 -0800
Subject: [R] 
 Cannot view custom tiles made in package tiler in r leaflet -
 either locally or from github pages server.
In-Reply-To: <CAN9eD7nVw9eir_3E4LePSVYAq9NaMtr+FFj=mHV3Etdk=UKM2w@mail.gmail.com>
References: <CAN9eD7nVw9eir_3E4LePSVYAq9NaMtr+FFj=mHV3Etdk=UKM2w@mail.gmail.com>
Message-ID: <CAGxFJbQBHrF2j8MyWFsXX0p+Cvbu4iuk-G19eUV4fZcRmqaEOA@mail.gmail.com>

Oh -- I see you did. Sorry. But cross-posting is discouraged.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 5, 2020 at 10:38 PM nevil amos <nevil.amos at gmail.com> wrote:

> I wish to create tiled version of a large number of custom rasters for
> viewing in shiny/leaflet apps ( to speed viewing of rasters)
>
> I have produced tiles using  package tiler, these can be viewed in the
> preview.html, but when uploaded to github pages  as described in the
> introduction to tiler they do not show up when added as tiles in leaflet.
>
> It is difficult to make a reproducible code here - since the tiles have to
> be loaded to be served from the web.
>
> However below I include the code used 1. to produce the tiles and 2, to
> view the tiles in my github pages.
>
> I have tried the suggestion of using {-y} in the sever path for TMS, this
> makes no difference the background map is displayed but the custom tiles
> are not.
>
> Raster used from the package as an example in reality I need to serve many
> 10000x6000 cell geotiffs.
>
> Example code:
>
> library(tiler)
> libary(leaflet)
> # make tiles in zoom levels 1:6 these tiles have then been uploaded to
> github to serve from repository:
> #
>
> tile_dir<-"us48lr"
> map <- system.file("maps/map_wgs84.tif", package = "tiler")
> tile(map,tile_dir , "0-6")
> view_tiles(tile_dir)
>
>
> #no TMS related modifications
> tiles <- "https://nevilamos.github.io/TileTest/us48lr/{z}/{x}/{y}.png"
> leaflet(
>   options = leafletOptions(minZoom = 0, maxZoom = 7), width = "100%") %>%
>   addProviderTiles("Stamen.Toner") %>%
>   addTiles(urlTemplate=tiles, options = tileOptions(opacity = 0.8)) %>%
> setView(-100, 40, 3)
>
> #No tiles displayed
>
>
> # {-y} and tileOptions(tms=T)
> tiles <- "https://nevilamos.github.io/TileTest/us48lr/{z}/{x}/{-y}.png"
> leaflet(
>   options = leafletOptions(minZoom = 0, maxZoom = 7), width = "100%") %>%
>   addProviderTiles("Stamen.Toner") %>%
>   addTiles(urlTemplate=tiles, options = tileOptions(opacity = 0.8,tms=T))
> %>% setView(-100, 40, 3)
>
> #No tiles displayed
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pd@me@ @end|ng |rom cb@@dk  Thu Feb  6 16:58:13 2020
From: pd@me@ @end|ng |rom cb@@dk (Peter Dalgaard)
Date: Thu, 6 Feb 2020 15:58:13 +0000
Subject: [R] [Rd] R 3.6.3 scheduled for February 29
Message-ID: <8913CAB2-6C63-4563-8A88-40B991C42ABC@cbs.dk>

Full schedule is available on developer.r-project.org.

(The date is chosen to celebrate the 5th anniversary of R 1.0.0. Some irregularity may occur on the release day, since this happens to be a Saturday and the release manager is speaking at the CelebRation2020 event...) 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Thu Feb  6 17:48:28 2020
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Thu, 6 Feb 2020 08:48:28 -0800
Subject: [R] how to create a pivot table in r?
In-Reply-To: <F194979E-5BC4-41B7-BE7C-751CAA917210@gmail.com>
References: <CAMwU6B3kGfPieB5iy5OmW65mEEqLDxX6ZQYp_Oa6MDXVi1byhQ@mail.gmail.com>
 <F194979E-5BC4-41B7-BE7C-751CAA917210@gmail.com>
Message-ID: <CAMwU6B1MnAV0cmwMX9Aqc3UOQuu-dLksNrxeOYr_=36RHOaVBg@mail.gmail.com>

Thank You Profs. Dalgaard and Barradas for the code, both codes worked
perfectly for the data and I am going to use it in my big data set.
Thanks once again.


On Thu, Feb 6, 2020 at 2:02 AM peter dalgaard <pdalgd at gmail.com> wrote:

> There is also
>
> > with(daT, tapply(as.character(ObsDate), list(id, ObsSite),
> function(x)format(list(x))))
>     site1                site4      site5      site7
> id1 NA                   NA         NA         "06/13/13"
> id2 NA                   NA         NA         "07/03/14, 05/17/14"
> id4 NA                   "05/08/14" NA         NA
> id5 NA                   NA         "06/13/14" NA
> id6 "05/30/14, 06/28/13" NA         NA         NA
> id7 NA                   NA         "06/25/13" NA
>
> ...with the added bonus that if you leave out the format() business, you
> get a data structure that doesn't print as nicely, but can be used for
> further computations:
>
> > with(daT, tapply(as.character(ObsDate), list(id, ObsSite), list,
> simplify=FALSE))
>     site1  site4  site5  site7
> id1 NULL   NULL   NULL   List,1
> id2 NULL   NULL   NULL   List,1
> id4 NULL   List,1 NULL   NULL
> id5 NULL   NULL   List,1 NULL
> id6 List,1 NULL   NULL   NULL
> id7 NULL   NULL   List,1 NULL
> > M <- with(daT, tapply(as.character(ObsDate), list(id, ObsSite), list,
> simplify=FALSE))
> > M[["id2", "site7"]]
> [[1]]
> [1] "07/03/14" "05/17/14"
>
> -pd
>
> > On 6 Feb 2020, at 01:37 , Marna Wagley <marna.wagley at gmail.com> wrote:
> >
> > daT<-structure(list(id = structure(c(1L, 2L, 2L, 3L, 4L, 5L, 5L, 6L
> > ), .Label = c("id1", "id2", "id4", "id5", "id6", "id7"), class =
> "factor"),
> >    ObsSite = structure(c(4L, 4L, 4L, 2L, 3L, 1L, 1L, 3L), .Label =
> > c("site1",
> >    "site4", "site5", "site7"), class = "factor"), ObsDate =
> > structure(c(4L,
> >    8L, 2L, 1L, 5L, 3L, 7L, 6L), .Label = c("05/08/14", "05/17/14",
> >    "05/30/14", "06/13/13", "06/13/14", "06/25/13", "06/28/13",
> >    "07/03/14"), class = "factor")), .Names = c("id", "ObsSite",
> > "ObsDate"), class = "data.frame", row.names = c(NA, -8L))
> > daT
> > daT$date <- mdy(daT$ObsDate)
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From y@wo1964 @end|ng |rom gm@||@com  Fri Feb  7 07:49:55 2020
From: y@wo1964 @end|ng |rom gm@||@com (Yawo Kokuvi)
Date: Fri, 7 Feb 2020 01:49:55 -0500
Subject: [R] Value Labels: SPSS Dataset to R
Message-ID: <CALjZK86ObekbDKsG2hd=vd1DhmXf7O0MV3Yihhi7Zdqk-FbzQQ@mail.gmail.com>

Hello,

I am just transitioning from SPSS to R.

I used the haven library to import some of my spss data files to R.

However, when I run procedures such as frequencies or crosstabs, value
labels for categorical variables such as gender (1=male, 2=female) are not
shown. The same applies to many other output.

I am confused.

1. Is there a global setting that I can use to force all categorical
variables to display labels?

2. Or, are these labels to be set for each function or package?

3. How can I request the value labels for each function I run?

Thanks in advance for your help..

Best, Yawo

	[[alternative HTML version deleted]]


From ju@n@rodr|guez @end|ng |rom cn@g@crg@eu  Fri Feb  7 17:01:25 2020
From: ju@n@rodr|guez @end|ng |rom cn@g@crg@eu (Juan Antonio Rodriguez Perez)
Date: Fri, 7 Feb 2020 16:01:25 +0000
Subject: [R] k-nearest neighbours from distance matrix in spdep
Message-ID: <3cbcfadfccf14c1485ad3ae0ebc700b6@cnag.crg.eu>

Dear all,


I am using the spdep package to compute Local Moran Index.

My problem is that I am using 3D coordinates (x,y,z), and I would like to compute the k-nearest neighbours (k=10) for each point in my 3D space. I have already done this in 2D, by doing the following:


>neighs_k <- knn2nb(knearneigh(as.matrix(full),
                                        k = 10))
> neighs_mat_k <- nb2listw(neighs_k
                         style = "W",
                         zero.policy = TRUE)

And then I can easily proceed using the neighs_mat_k object.

However, when using x,y,z coordinates I can't run the knearneigh() function on it. I tried converting my data to a distance matrix and using mat2listw() function like this:

>D <- as.matrix(dist(full, diag=FALSE, upper=FALSE))
>test1 <- mat2listw(D)

...but now I don't know how to retrieve the k-nearest weights from my test1 object (which would correspond to k-nearest neighbours) without changing the class of test1, which is:

> class(test1)
[1] "listw" "nb"
## and contains...:
> ls(test1)
[1] "neighbours" "style"      "weights"


How should I do this? Is this even the right way to proceed?

Thanks all in advance!!
Best wishes,

Juan

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Feb  7 18:05:53 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 7 Feb 2020 09:05:53 -0800
Subject: [R] Value Labels: SPSS Dataset to R
In-Reply-To: <CALjZK86ObekbDKsG2hd=vd1DhmXf7O0MV3Yihhi7Zdqk-FbzQQ@mail.gmail.com>
References: <CALjZK86ObekbDKsG2hd=vd1DhmXf7O0MV3Yihhi7Zdqk-FbzQQ@mail.gmail.com>
Message-ID: <CAGxFJbRXLH8FFVbQrZEXH1+ac=N81HZxcPFnpMvUf8qyWCksmA@mail.gmail.com>

What does your data look like after importing? -- see ?head and ?str to
tell us. Show us the code that failed to provide "labels." See the posting
guide below for how to post questions that are likely to elicit helpful
responses.

I know nothing about the haven package, but see ?factor or go through an R
tutorial or two to learn about factors, which may be part of the issue
here. R *generally* obtains whatever "label" info it needs from the object
being tabled -- see ?tabulate, ?table etc. -- if that's what you're doing.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Feb 7, 2020 at 8:28 AM Yawo Kokuvi <yawo1964 at gmail.com> wrote:

> Hello,
>
> I am just transitioning from SPSS to R.
>
> I used the haven library to import some of my spss data files to R.
>
> However, when I run procedures such as frequencies or crosstabs, value
> labels for categorical variables such as gender (1=male, 2=female) are not
> shown. The same applies to many other output.
>
> I am confused.
>
> 1. Is there a global setting that I can use to force all categorical
> variables to display labels?
>
> 2. Or, are these labels to be set for each function or package?
>
> 3. How can I request the value labels for each function I run?
>
> Thanks in advance for your help..
>
> Best, Yawo
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pj@|nh@07 @end|ng |rom gm@||@com  Fri Feb  7 18:56:59 2020
From: pj@|nh@07 @end|ng |rom gm@||@com (pooja sinha)
Date: Fri, 7 Feb 2020 12:56:59 -0500
Subject: [R] Plotting DMRs (Differentially Methylated Regions) using Gviz
 package in R
Message-ID: <CAGjf1cN8NJojY_DW7=3B9ToAtptX+c9yRx8jkmF6rAR6h9-4Ag@mail.gmail.com>

Hi All,

I have a file list consisting of Chromosome, Start , End & Methylation
Difference in the following format in excel:

Chrom     Start          End          Meth. Diff

chr1     38565900 38566000 -0.20276818

chr1     38870400 38870500 -0.342342342

chr1     39469400 39469500 -0.250260552

chr1     52013600 52013700 -0.37797619

chr1     52751700 52751800  0.257575758

chr1     75505100 75505200 -0.262847308

I need help in plotting the DMRs using Gviz package in R. I tried a code
below but it doesn't turn out correct.

library(GenomicRanges)
library(grid)
library(Gviz)
library(rtracklayer)
library(BSgenome)
library(readxl)
library(BSgenome.Rnorvegicus.UCSC.rn6)
genome <- getBSgenome("BSgenome.Rnorvegicus.UCSC.rn6")
genome
data1 <- read_excel("DMRs_plots.xlsx")
head(data1)
data1$Chrom = Chrom$chr1

track1 <- DataTrack(data = data1, from = "38565900" , to = "282250000",
chromosome = Chrom$chr1, name = "DMRs")

itrack <- IdeogramTrack(genome = genome, chromosome = chr)

plotTracks(track1, itrack)


If anyone know how to plot and correct my code including how to add
methylation difference values, then that will be of great help.


Thanks,

Puja

	[[alternative HTML version deleted]]


From mtmorg@n@b|oc @end|ng |rom gm@||@com  Fri Feb  7 19:08:35 2020
From: mtmorg@n@b|oc @end|ng |rom gm@||@com (Martin Morgan)
Date: Fri, 7 Feb 2020 18:08:35 +0000
Subject: [R] 
 Plotting DMRs (Differentially Methylated Regions) using Gviz
 package in R
In-Reply-To: <CAGjf1cN8NJojY_DW7=3B9ToAtptX+c9yRx8jkmF6rAR6h9-4Ag@mail.gmail.com>
References: <CAGjf1cN8NJojY_DW7=3B9ToAtptX+c9yRx8jkmF6rAR6h9-4Ag@mail.gmail.com>
Message-ID: <DM6PR04MB5531A7E0DB5A2523F6BC3537F91C0@DM6PR04MB5531.namprd04.prod.outlook.com>

Probably have more success asking on https://support.bioconductor.org.

Martin Morgan

?On 2/7/20, 12:57 PM, "R-help on behalf of pooja sinha" <r-help-bounces at r-project.org on behalf of pjsinha07 at gmail.com> wrote:

    Hi All,
    
    I have a file list consisting of Chromosome, Start , End & Methylation
    Difference in the following format in excel:
    
    Chrom     Start          End          Meth. Diff
    
    chr1     38565900 38566000 -0.20276818
    
    chr1     38870400 38870500 -0.342342342
    
    chr1     39469400 39469500 -0.250260552
    
    chr1     52013600 52013700 -0.37797619
    
    chr1     52751700 52751800  0.257575758
    
    chr1     75505100 75505200 -0.262847308
    
    I need help in plotting the DMRs using Gviz package in R. I tried a code
    below but it doesn't turn out correct.
    
    library(GenomicRanges)
    library(grid)
    library(Gviz)
    library(rtracklayer)
    library(BSgenome)
    library(readxl)
    library(BSgenome.Rnorvegicus.UCSC.rn6)
    genome <- getBSgenome("BSgenome.Rnorvegicus.UCSC.rn6")
    genome
    data1 <- read_excel("DMRs_plots.xlsx")
    head(data1)
    data1$Chrom = Chrom$chr1
    
    track1 <- DataTrack(data = data1, from = "38565900" , to = "282250000",
    chromosome = Chrom$chr1, name = "DMRs")
    
    itrack <- IdeogramTrack(genome = genome, chromosome = chr)
    
    plotTracks(track1, itrack)
    
    
    If anyone know how to plot and correct my code including how to add
    methylation difference values, then that will be of great help.
    
    
    Thanks,
    
    Puja
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    

From pj@|nh@07 @end|ng |rom gm@||@com  Fri Feb  7 19:52:07 2020
From: pj@|nh@07 @end|ng |rom gm@||@com (pooja sinha)
Date: Fri, 7 Feb 2020 13:52:07 -0500
Subject: [R] 
 Plotting DMRs (Differentially Methylated Regions) using Gviz
 package in R
In-Reply-To: <DM6PR04MB5531A7E0DB5A2523F6BC3537F91C0@DM6PR04MB5531.namprd04.prod.outlook.com>
References: <CAGjf1cN8NJojY_DW7=3B9ToAtptX+c9yRx8jkmF6rAR6h9-4Ag@mail.gmail.com>
 <DM6PR04MB5531A7E0DB5A2523F6BC3537F91C0@DM6PR04MB5531.namprd04.prod.outlook.com>
Message-ID: <CAGjf1cPWNeTQOKkLVdnWz6o2z77=GrZ7E_NK6qRADpOoR2u5bQ@mail.gmail.com>

Thanks, I'll check it out.

On Fri, Feb 7, 2020 at 1:08 PM Martin Morgan <mtmorgan.bioc at gmail.com>
wrote:

> Probably have more success asking on https://support.bioconductor.org.
>
> Martin Morgan
>
> ?On 2/7/20, 12:57 PM, "R-help on behalf of pooja sinha" <
> r-help-bounces at r-project.org on behalf of pjsinha07 at gmail.com> wrote:
>
>     Hi All,
>
>     I have a file list consisting of Chromosome, Start , End & Methylation
>     Difference in the following format in excel:
>
>     Chrom     Start          End          Meth. Diff
>
>     chr1     38565900 38566000 -0.20276818
>
>     chr1     38870400 38870500 -0.342342342
>
>     chr1     39469400 39469500 -0.250260552
>
>     chr1     52013600 52013700 -0.37797619
>
>     chr1     52751700 52751800  0.257575758
>
>     chr1     75505100 75505200 -0.262847308
>
>     I need help in plotting the DMRs using Gviz package in R. I tried a
> code
>     below but it doesn't turn out correct.
>
>     library(GenomicRanges)
>     library(grid)
>     library(Gviz)
>     library(rtracklayer)
>     library(BSgenome)
>     library(readxl)
>     library(BSgenome.Rnorvegicus.UCSC.rn6)
>     genome <- getBSgenome("BSgenome.Rnorvegicus.UCSC.rn6")
>     genome
>     data1 <- read_excel("DMRs_plots.xlsx")
>     head(data1)
>     data1$Chrom = Chrom$chr1
>
>     track1 <- DataTrack(data = data1, from = "38565900" , to = "282250000",
>     chromosome = Chrom$chr1, name = "DMRs")
>
>     itrack <- IdeogramTrack(genome = genome, chromosome = chr)
>
>     plotTracks(track1, itrack)
>
>
>     If anyone know how to plot and correct my code including how to add
>     methylation difference values, then that will be of great help.
>
>
>     Thanks,
>
>     Puja
>
>         [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From y@wo1964 @end|ng |rom gm@||@com  Fri Feb  7 21:31:30 2020
From: y@wo1964 @end|ng |rom gm@||@com (Yawo Kokuvi)
Date: Fri, 7 Feb 2020 15:31:30 -0500
Subject: [R] Value Labels: SPSS Dataset to R
In-Reply-To: <6c895565-7f26-453a-8b45-822076bfd5c7@email.android.com>
References: <CAGxFJbRXLH8FFVbQrZEXH1+ac=N81HZxcPFnpMvUf8qyWCksmA@mail.gmail.com>
 <6c895565-7f26-453a-8b45-822076bfd5c7@email.android.com>
Message-ID: <CALjZK84ACUj8MmoRCjSXQvshpoCa48iVMSOgFjFMpUqF=L2GEA@mail.gmail.com>

Thanks for all your assistance

Attached please is the Rdata scratch I have been using

-----------------------------------------------------

> head(Scratch, n=13)
# A tibble: 13 x 6
      ID           marital        sex      race    paeduc    speduc
   <dbl>         <dbl+lbl>  <dbl+lbl> <dbl+lbl> <dbl+lbl> <dbl+lbl>
 1     1 3 [DIVORCED]      1 [MALE]   1 [WHITE]        NA        NA
 2     2 1 [MARRIED]       1 [MALE]   1 [WHITE]        NA        NA
 3     3 3 [DIVORCED]      1 [MALE]   1 [WHITE]         4        NA
 4     4 4 [SEPARATED]     1 [MALE]   1 [WHITE]        16        NA
 5     5 3 [DIVORCED]      1 [MALE]   1 [WHITE]        18        NA
 6     6 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        14        20
 7     7 1 [MARRIED]       2 [FEMALE] 2 [BLACK]        NA        12
 8     8 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        NA        12
 9     9 3 [DIVORCED]      2 [FEMALE] 1 [WHITE]        11        NA
10    10 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        16        12
11    11 5 [NEVER MARRIED] 2 [FEMALE] 2 [BLACK]        NA        NA
12    12 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        NA        NA
13    13 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        16        NA

-----------------------------------------------------

and below is my script/command file.

*#1: Load library and import SPSS dataset*
library(haven)
Scratch <- read_sav("~/Desktop/Scratch.sav")

*#2: save the dataset with a name*
save(ScratchImport, file="Scratch.Rdata")

*#3: install & load necessary packages for descriptive statistics*
install.packages ("freqdist")
library (freqdist)

install.packages ("sjlabelled")
library (sjlabelled)

install.packages ("labelled")
library (labelled)

install.packages ("surveytoolbox")
library (surveytoolbox)

*#4: Check the value labels of gender and marital status*
Scratch$sex %>% attr('labels')
Scratch$marital %>% attr('labels')

*#5:  Frequency Distribution and BarChart for Categorical/Ordinal Level
Variables such as Gender - SEX*
freqdist(Scratch$sex)
barplot(table(Scratch$marital))

-----------------------------------------------------

As you can see from above, I use the <haven> package to import the data
from SPSS.  Apparently, the haven function keeps the value labels, as the
attribute options in section #4 of my script shows.
The problem is that when I run frequency distribution for any of the
categorical variables like sex or marital status, only the numbers (1, 2,)
are displayed in the output.  The labels (male, female) for example are not.

Is there any way to force these to be shown in the output?  Is there a
global property that I have to set so that these value labels are reliably
displayed with every output?  I read I can declare them as factors using
the <as_factor()>, but once I do so, how do I invoke them in my commands so
that the value labels show...

Sorry about all the noobs questions, but Ihopefully, I am able to get this
working.

Thanks in advance.


Thanks - cY


On Fri, Feb 7, 2020 at 1:14 PM <cpolwart at chemo.org.uk> wrote:

> I've never used it, but there is a labels function in haven...
>
> On 7 Feb 2020 17:05, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> What does your data look like after importing? -- see ?head and ?str to
> tell us. Show us the code that failed to provide "labels." See the posting
> guide below for how to post questions that are likely to elicit helpful
> responses.
>
> I know nothing about the haven package, but see ?factor or go through an R
> tutorial or two to learn about factors, which may be part of the issue
> here. R *generally* obtains whatever "label" info it needs from the object
> being tabled -- see ?tabulate, ?table etc. -- if that's what you're doing.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Feb 7, 2020 at 8:28 AM Yawo Kokuvi <yawo1964 at gmail.com> wrote:
>
> > Hello,
> >
> > I am just transitioning from SPSS to R.
> >
> > I used the haven library to import some of my spss data files to R.
> >
> > However, when I run procedures such as frequencies or crosstabs, value
> > labels for categorical variables such as gender (1=male, 2=female) are
> not
> > shown. The same applies to many other output.
> >
> > I am confused.
> >
> > 1. Is there a global setting that I can use to force all categorical
> > variables to display labels?
> >
> > 2. Or, are these labels to be set for each function or package?
> >
> > 3. How can I request the value labels for each function I run?
> >
> > Thanks in advance for your help..
> >
> > Best, Yawo
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Fri Feb  7 22:58:42 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 8 Feb 2020 08:58:42 +1100
Subject: [R] Value Labels: SPSS Dataset to R
In-Reply-To: <CALjZK84ACUj8MmoRCjSXQvshpoCa48iVMSOgFjFMpUqF=L2GEA@mail.gmail.com>
References: <CAGxFJbRXLH8FFVbQrZEXH1+ac=N81HZxcPFnpMvUf8qyWCksmA@mail.gmail.com>
 <6c895565-7f26-453a-8b45-822076bfd5c7@email.android.com>
 <CALjZK84ACUj8MmoRCjSXQvshpoCa48iVMSOgFjFMpUqF=L2GEA@mail.gmail.com>
Message-ID: <CA+8X3fU1orONMp-G8qUxWcaq0pY=jvNCqjbQZWuhgV8Mqfj_Vg@mail.gmail.com>

Hi Yawo,
>From your recent post, you say you have coerced the variables to
factors. If so, perhaps:

as.character(x) is what you want.

If not, creating a new variable like this:

Scratch$new_race<-factor(as.character(Scratch$race),levels=c("WHITE","BLACK"))

may do it. Note the "levels" argument to get the numeric values in the
same order as the original.

Jim

On Sat, Feb 8, 2020 at 7:32 AM Yawo Kokuvi <yawo1964 at gmail.com> wrote:
>
> Thanks for all your assistance
>
> Attached please is the Rdata scratch I have been using
>
> -----------------------------------------------------
>
> > head(Scratch, n=13)
> # A tibble: 13 x 6
>       ID           marital        sex      race    paeduc    speduc
>    <dbl>         <dbl+lbl>  <dbl+lbl> <dbl+lbl> <dbl+lbl> <dbl+lbl>
>  1     1 3 [DIVORCED]      1 [MALE]   1 [WHITE]        NA        NA
>  2     2 1 [MARRIED]       1 [MALE]   1 [WHITE]        NA        NA
>  3     3 3 [DIVORCED]      1 [MALE]   1 [WHITE]         4        NA
>  4     4 4 [SEPARATED]     1 [MALE]   1 [WHITE]        16        NA
>  5     5 3 [DIVORCED]      1 [MALE]   1 [WHITE]        18        NA
>  6     6 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        14        20
>  7     7 1 [MARRIED]       2 [FEMALE] 2 [BLACK]        NA        12
>  8     8 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        NA        12
>  9     9 3 [DIVORCED]      2 [FEMALE] 1 [WHITE]        11        NA
> 10    10 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        16        12
> 11    11 5 [NEVER MARRIED] 2 [FEMALE] 2 [BLACK]        NA        NA
> 12    12 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        NA        NA
> 13    13 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        16        NA
>
> -----------------------------------------------------
>
> and below is my script/command file.
>
> *#1: Load library and import SPSS dataset*
> library(haven)
> Scratch <- read_sav("~/Desktop/Scratch.sav")
>
> *#2: save the dataset with a name*
> save(ScratchImport, file="Scratch.Rdata")
>
> *#3: install & load necessary packages for descriptive statistics*
> install.packages ("freqdist")
> library (freqdist)
>
> install.packages ("sjlabelled")
> library (sjlabelled)
>
> install.packages ("labelled")
> library (labelled)
>
> install.packages ("surveytoolbox")
> library (surveytoolbox)
>
> *#4: Check the value labels of gender and marital status*
> Scratch$sex %>% attr('labels')
> Scratch$marital %>% attr('labels')
>
> *#5:  Frequency Distribution and BarChart for Categorical/Ordinal Level
> Variables such as Gender - SEX*
> freqdist(Scratch$sex)
> barplot(table(Scratch$marital))
>
> -----------------------------------------------------
>
> As you can see from above, I use the <haven> package to import the data
> from SPSS.  Apparently, the haven function keeps the value labels, as the
> attribute options in section #4 of my script shows.
> The problem is that when I run frequency distribution for any of the
> categorical variables like sex or marital status, only the numbers (1, 2,)
> are displayed in the output.  The labels (male, female) for example are not.
>
> Is there any way to force these to be shown in the output?  Is there a
> global property that I have to set so that these value labels are reliably
> displayed with every output?  I read I can declare them as factors using
> the <as_factor()>, but once I do so, how do I invoke them in my commands so
> that the value labels show...
>
> Sorry about all the noobs questions, but Ihopefully, I am able to get this
> working.
>
> Thanks in advance.
>
>
> Thanks - cY
>
>
> On Fri, Feb 7, 2020 at 1:14 PM <cpolwart at chemo.org.uk> wrote:
>
> > I've never used it, but there is a labels function in haven...
> >
> > On 7 Feb 2020 17:05, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > What does your data look like after importing? -- see ?head and ?str to
> > tell us. Show us the code that failed to provide "labels." See the posting
> > guide below for how to post questions that are likely to elicit helpful
> > responses.
> >
> > I know nothing about the haven package, but see ?factor or go through an R
> > tutorial or two to learn about factors, which may be part of the issue
> > here. R *generally* obtains whatever "label" info it needs from the object
> > being tabled -- see ?tabulate, ?table etc. -- if that's what you're doing.
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Fri, Feb 7, 2020 at 8:28 AM Yawo Kokuvi <yawo1964 at gmail.com> wrote:
> >
> > > Hello,
> > >
> > > I am just transitioning from SPSS to R.
> > >
> > > I used the haven library to import some of my spss data files to R.
> > >
> > > However, when I run procedures such as frequencies or crosstabs, value
> > > labels for categorical variables such as gender (1=male, 2=female) are
> > not
> > > shown. The same applies to many other output.
> > >
> > > I am confused.
> > >
> > > 1. Is there a global setting that I can use to force all categorical
> > > variables to display labels?
> > >
> > > 2. Or, are these labels to be set for each function or package?
> > >
> > > 3. How can I request the value labels for each function I run?
> > >
> > > Thanks in advance for your help..
> > >
> > > Best, Yawo
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From y@wo1964 @end|ng |rom gm@||@com  Fri Feb  7 23:24:41 2020
From: y@wo1964 @end|ng |rom gm@||@com (Yawo Kokuvi)
Date: Fri, 7 Feb 2020 17:24:41 -0500
Subject: [R] Value Labels: SPSS Dataset to R
In-Reply-To: <CA+8X3fU1orONMp-G8qUxWcaq0pY=jvNCqjbQZWuhgV8Mqfj_Vg@mail.gmail.com>
References: <CAGxFJbRXLH8FFVbQrZEXH1+ac=N81HZxcPFnpMvUf8qyWCksmA@mail.gmail.com>
 <6c895565-7f26-453a-8b45-822076bfd5c7@email.android.com>
 <CALjZK84ACUj8MmoRCjSXQvshpoCa48iVMSOgFjFMpUqF=L2GEA@mail.gmail.com>
 <CA+8X3fU1orONMp-G8qUxWcaq0pY=jvNCqjbQZWuhgV8Mqfj_Vg@mail.gmail.com>
Message-ID: <CALjZK85hG+CPM1n3diEXfx_xhb7UvhnWOqxLVF6RVOMOQqxCsA@mail.gmail.com>

Thanks Jim:

So one option is to go through the data, select all the categorical
variables I want and re-define them as factor variables ?  As in the
following example for gender?

mydata$sex<- factor(mydata$sex, levels = c(1,2), labels = c("male",
"female"))

thanks - cY

On Fri, Feb 7, 2020 at 4:58 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Yawo,
> From your recent post, you say you have coerced the variables to
> factors. If so, perhaps:
>
> as.character(x) is what you want.
>
> If not, creating a new variable like this:
>
>
> Scratch$new_race<-factor(as.character(Scratch$race),levels=c("WHITE","BLACK"))
>
> may do it. Note the "levels" argument to get the numeric values in the
> same order as the original.
>
> Jim
>
> On Sat, Feb 8, 2020 at 7:32 AM Yawo Kokuvi <yawo1964 at gmail.com> wrote:
> >
> > Thanks for all your assistance
> >
> > Attached please is the Rdata scratch I have been using
> >
> > -----------------------------------------------------
> >
> > > head(Scratch, n=13)
> > # A tibble: 13 x 6
> >       ID           marital        sex      race    paeduc    speduc
> >    <dbl>         <dbl+lbl>  <dbl+lbl> <dbl+lbl> <dbl+lbl> <dbl+lbl>
> >  1     1 3 [DIVORCED]      1 [MALE]   1 [WHITE]        NA        NA
> >  2     2 1 [MARRIED]       1 [MALE]   1 [WHITE]        NA        NA
> >  3     3 3 [DIVORCED]      1 [MALE]   1 [WHITE]         4        NA
> >  4     4 4 [SEPARATED]     1 [MALE]   1 [WHITE]        16        NA
> >  5     5 3 [DIVORCED]      1 [MALE]   1 [WHITE]        18        NA
> >  6     6 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        14        20
> >  7     7 1 [MARRIED]       2 [FEMALE] 2 [BLACK]        NA        12
> >  8     8 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        NA        12
> >  9     9 3 [DIVORCED]      2 [FEMALE] 1 [WHITE]        11        NA
> > 10    10 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        16        12
> > 11    11 5 [NEVER MARRIED] 2 [FEMALE] 2 [BLACK]        NA        NA
> > 12    12 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        NA        NA
> > 13    13 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        16        NA
> >
> > -----------------------------------------------------
> >
> > and below is my script/command file.
> >
> > *#1: Load library and import SPSS dataset*
> > library(haven)
> > Scratch <- read_sav("~/Desktop/Scratch.sav")
> >
> > *#2: save the dataset with a name*
> > save(ScratchImport, file="Scratch.Rdata")
> >
> > *#3: install & load necessary packages for descriptive statistics*
> > install.packages ("freqdist")
> > library (freqdist)
> >
> > install.packages ("sjlabelled")
> > library (sjlabelled)
> >
> > install.packages ("labelled")
> > library (labelled)
> >
> > install.packages ("surveytoolbox")
> > library (surveytoolbox)
> >
> > *#4: Check the value labels of gender and marital status*
> > Scratch$sex %>% attr('labels')
> > Scratch$marital %>% attr('labels')
> >
> > *#5:  Frequency Distribution and BarChart for Categorical/Ordinal Level
> > Variables such as Gender - SEX*
> > freqdist(Scratch$sex)
> > barplot(table(Scratch$marital))
> >
> > -----------------------------------------------------
> >
> > As you can see from above, I use the <haven> package to import the data
> > from SPSS.  Apparently, the haven function keeps the value labels, as the
> > attribute options in section #4 of my script shows.
> > The problem is that when I run frequency distribution for any of the
> > categorical variables like sex or marital status, only the numbers (1,
> 2,)
> > are displayed in the output.  The labels (male, female) for example are
> not.
> >
> > Is there any way to force these to be shown in the output?  Is there a
> > global property that I have to set so that these value labels are
> reliably
> > displayed with every output?  I read I can declare them as factors using
> > the <as_factor()>, but once I do so, how do I invoke them in my commands
> so
> > that the value labels show...
> >
> > Sorry about all the noobs questions, but Ihopefully, I am able to get
> this
> > working.
> >
> > Thanks in advance.
> >
> >
> > Thanks - cY
> >
> >
> > On Fri, Feb 7, 2020 at 1:14 PM <cpolwart at chemo.org.uk> wrote:
> >
> > > I've never used it, but there is a labels function in haven...
> > >
> > > On 7 Feb 2020 17:05, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > >
> > > What does your data look like after importing? -- see ?head and ?str to
> > > tell us. Show us the code that failed to provide "labels." See the
> posting
> > > guide below for how to post questions that are likely to elicit helpful
> > > responses.
> > >
> > > I know nothing about the haven package, but see ?factor or go through
> an R
> > > tutorial or two to learn about factors, which may be part of the issue
> > > here. R *generally* obtains whatever "label" info it needs from the
> object
> > > being tabled -- see ?tabulate, ?table etc. -- if that's what you're
> doing.
> > >
> > > Bert Gunter
> > >
> > > "The trouble with having an open mind is that people keep coming along
> and
> > > sticking things into it."
> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >
> > >
> > > On Fri, Feb 7, 2020 at 8:28 AM Yawo Kokuvi <yawo1964 at gmail.com> wrote:
> > >
> > > > Hello,
> > > >
> > > > I am just transitioning from SPSS to R.
> > > >
> > > > I used the haven library to import some of my spss data files to R.
> > > >
> > > > However, when I run procedures such as frequencies or crosstabs,
> value
> > > > labels for categorical variables such as gender (1=male, 2=female)
> are
> > > not
> > > > shown. The same applies to many other output.
> > > >
> > > > I am confused.
> > > >
> > > > 1. Is there a global setting that I can use to force all categorical
> > > > variables to display labels?
> > > >
> > > > 2. Or, are these labels to be set for each function or package?
> > > >
> > > > 3. How can I request the value labels for each function I run?
> > > >
> > > > Thanks in advance for your help..
> > > >
> > > > Best, Yawo
> > > >
> > > >         [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tuech|er @end|ng |rom gmx@@t  Fri Feb  7 23:26:37 2020
From: tuech|er @end|ng |rom gmx@@t (Heinz Tuechler)
Date: Fri, 7 Feb 2020 23:26:37 +0100
Subject: [R] Value Labels: SPSS Dataset to R
In-Reply-To: <CA+8X3fU1orONMp-G8qUxWcaq0pY=jvNCqjbQZWuhgV8Mqfj_Vg@mail.gmail.com>
References: <CAGxFJbRXLH8FFVbQrZEXH1+ac=N81HZxcPFnpMvUf8qyWCksmA@mail.gmail.com>
 <6c895565-7f26-453a-8b45-822076bfd5c7@email.android.com>
 <CALjZK84ACUj8MmoRCjSXQvshpoCa48iVMSOgFjFMpUqF=L2GEA@mail.gmail.com>
 <CA+8X3fU1orONMp-G8qUxWcaq0pY=jvNCqjbQZWuhgV8Mqfj_Vg@mail.gmail.com>
Message-ID: <93d85e9f-4dbe-ee9b-c770-d4e2743c7d28@gmx.at>

Maybe it helps searching at https://rseek.org/ for "SPSS to R transition
value labels".
In particular
https://cran.r-project.org/web/packages/expss/vignettes/labels-support.html
seems useful, as well as
https://www.r-bloggers.com/migrating-from-spss-to-r-rstats/

best regards,
Heinz

Jim Lemon wrote on 07.02.2020 22:58:
> Hi Yawo,
>>From your recent post, you say you have coerced the variables to
> factors. If so, perhaps:
>
> as.character(x) is what you want.
>
> If not, creating a new variable like this:
>
> Scratch$new_race<-factor(as.character(Scratch$race),levels=c("WHITE","BLACK"))
>
> may do it. Note the "levels" argument to get the numeric values in the
> same order as the original.
>
> Jim
>
> On Sat, Feb 8, 2020 at 7:32 AM Yawo Kokuvi <yawo1964 at gmail.com> wrote:
>>
>> Thanks for all your assistance
>>
>> Attached please is the Rdata scratch I have been using
>>
>> -----------------------------------------------------
>>
>>> head(Scratch, n=13)
>> # A tibble: 13 x 6
>>       ID           marital        sex      race    paeduc    speduc
>>    <dbl>         <dbl+lbl>  <dbl+lbl> <dbl+lbl> <dbl+lbl> <dbl+lbl>
>>  1     1 3 [DIVORCED]      1 [MALE]   1 [WHITE]        NA        NA
>>  2     2 1 [MARRIED]       1 [MALE]   1 [WHITE]        NA        NA
>>  3     3 3 [DIVORCED]      1 [MALE]   1 [WHITE]         4        NA
>>  4     4 4 [SEPARATED]     1 [MALE]   1 [WHITE]        16        NA
>>  5     5 3 [DIVORCED]      1 [MALE]   1 [WHITE]        18        NA
>>  6     6 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        14        20
>>  7     7 1 [MARRIED]       2 [FEMALE] 2 [BLACK]        NA        12
>>  8     8 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        NA        12
>>  9     9 3 [DIVORCED]      2 [FEMALE] 1 [WHITE]        11        NA
>> 10    10 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        16        12
>> 11    11 5 [NEVER MARRIED] 2 [FEMALE] 2 [BLACK]        NA        NA
>> 12    12 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        NA        NA
>> 13    13 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        16        NA
>>
>> -----------------------------------------------------
>>
>> and below is my script/command file.
>>
>> *#1: Load library and import SPSS dataset*
>> library(haven)
>> Scratch <- read_sav("~/Desktop/Scratch.sav")
>>
>> *#2: save the dataset with a name*
>> save(ScratchImport, file="Scratch.Rdata")
>>
>> *#3: install & load necessary packages for descriptive statistics*
>> install.packages ("freqdist")
>> library (freqdist)
>>
>> install.packages ("sjlabelled")
>> library (sjlabelled)
>>
>> install.packages ("labelled")
>> library (labelled)
>>
>> install.packages ("surveytoolbox")
>> library (surveytoolbox)
>>
>> *#4: Check the value labels of gender and marital status*
>> Scratch$sex %>% attr('labels')
>> Scratch$marital %>% attr('labels')
>>
>> *#5:  Frequency Distribution and BarChart for Categorical/Ordinal Level
>> Variables such as Gender - SEX*
>> freqdist(Scratch$sex)
>> barplot(table(Scratch$marital))
>>
>> -----------------------------------------------------
>>
>> As you can see from above, I use the <haven> package to import the data
>> from SPSS.  Apparently, the haven function keeps the value labels, as the
>> attribute options in section #4 of my script shows.
>> The problem is that when I run frequency distribution for any of the
>> categorical variables like sex or marital status, only the numbers (1, 2,)
>> are displayed in the output.  The labels (male, female) for example are not.
>>
>> Is there any way to force these to be shown in the output?  Is there a
>> global property that I have to set so that these value labels are reliably
>> displayed with every output?  I read I can declare them as factors using
>> the <as_factor()>, but once I do so, how do I invoke them in my commands so
>> that the value labels show...
>>
>> Sorry about all the noobs questions, but Ihopefully, I am able to get this
>> working.
>>
>> Thanks in advance.
>>
>>
>> Thanks - cY
>>
>>
>> On Fri, Feb 7, 2020 at 1:14 PM <cpolwart at chemo.org.uk> wrote:
>>
>>> I've never used it, but there is a labels function in haven...
>>>
>>> On 7 Feb 2020 17:05, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>
>>> What does your data look like after importing? -- see ?head and ?str to
>>> tell us. Show us the code that failed to provide "labels." See the posting
>>> guide below for how to post questions that are likely to elicit helpful
>>> responses.
>>>
>>> I know nothing about the haven package, but see ?factor or go through an R
>>> tutorial or two to learn about factors, which may be part of the issue
>>> here. R *generally* obtains whatever "label" info it needs from the object
>>> being tabled -- see ?tabulate, ?table etc. -- if that's what you're doing.
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Fri, Feb 7, 2020 at 8:28 AM Yawo Kokuvi <yawo1964 at gmail.com> wrote:
>>>
>>>> Hello,
>>>>
>>>> I am just transitioning from SPSS to R.
>>>>
>>>> I used the haven library to import some of my spss data files to R.
>>>>
>>>> However, when I run procedures such as frequencies or crosstabs, value
>>>> labels for categorical variables such as gender (1=male, 2=female) are
>>> not
>>>> shown. The same applies to many other output.
>>>>
>>>> I am confused.
>>>>
>>>> 1. Is there a global setting that I can use to force all categorical
>>>> variables to display labels?
>>>>
>>>> 2. Or, are these labels to be set for each function or package?
>>>>
>>>> 3. How can I request the value labels for each function I run?
>>>>
>>>> Thanks in advance for your help..
>>>>
>>>> Best, Yawo
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkr|de@u @end|ng |rom gm@||@com  Sat Feb  8 02:33:12 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Fri, 7 Feb 2020 20:33:12 -0500
Subject: [R] Value Labels: SPSS Dataset to R
In-Reply-To: <CALjZK84ACUj8MmoRCjSXQvshpoCa48iVMSOgFjFMpUqF=L2GEA@mail.gmail.com>
References: <CAGxFJbRXLH8FFVbQrZEXH1+ac=N81HZxcPFnpMvUf8qyWCksmA@mail.gmail.com>
 <6c895565-7f26-453a-8b45-822076bfd5c7@email.android.com>
 <CALjZK84ACUj8MmoRCjSXQvshpoCa48iVMSOgFjFMpUqF=L2GEA@mail.gmail.com>
Message-ID: <CAKZQJMA9Cazf27BYK_F2SzB6zgZFrvtejH0MVHuvr-iq6Rn2hA@mail.gmail.com>

Hi,
Could you upload some sample data in dput form?  Something like
dput(head(Scratch, n=13)) will give us some real data to examine. Just copy
and paste the output of dput(head(Scratch, n=13))into the email. This is
the best way to ensure that R-help denizens are getting the data in the
exact format that you have.

On Fri, 7 Feb 2020 at 15:32, Yawo Kokuvi <yawo1964 at gmail.com> wrote:

> Thanks for all your assistance
>
> Attached please is the Rdata scratch I have been using
>
> -----------------------------------------------------
>
> > head(Scratch, n=13)
> # A tibble: 13 x 6
>       ID           marital        sex      race    paeduc    speduc
>    <dbl>         <dbl+lbl>  <dbl+lbl> <dbl+lbl> <dbl+lbl> <dbl+lbl>
>  1     1 3 [DIVORCED]      1 [MALE]   1 [WHITE]        NA        NA
>  2     2 1 [MARRIED]       1 [MALE]   1 [WHITE]        NA        NA
>  3     3 3 [DIVORCED]      1 [MALE]   1 [WHITE]         4        NA
>  4     4 4 [SEPARATED]     1 [MALE]   1 [WHITE]        16        NA
>  5     5 3 [DIVORCED]      1 [MALE]   1 [WHITE]        18        NA
>  6     6 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        14        20
>  7     7 1 [MARRIED]       2 [FEMALE] 2 [BLACK]        NA        12
>  8     8 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        NA        12
>  9     9 3 [DIVORCED]      2 [FEMALE] 1 [WHITE]        11        NA
> 10    10 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        16        12
> 11    11 5 [NEVER MARRIED] 2 [FEMALE] 2 [BLACK]        NA        NA
> 12    12 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        NA        NA
> 13    13 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        16        NA
>
> -----------------------------------------------------
>
> and below is my script/command file.
>
> *#1: Load library and import SPSS dataset*
> library(haven)
> Scratch <- read_sav("~/Desktop/Scratch.sav")
>
> *#2: save the dataset with a name*
> save(ScratchImport, file="Scratch.Rdata")
>
> *#3: install & load necessary packages for descriptive statistics*
> install.packages ("freqdist")
> library (freqdist)
>
> install.packages ("sjlabelled")
> library (sjlabelled)
>
> install.packages ("labelled")
> library (labelled)
>
> install.packages ("surveytoolbox")
> library (surveytoolbox)
>
> *#4: Check the value labels of gender and marital status*
> Scratch$sex %>% attr('labels')
> Scratch$marital %>% attr('labels')
>
> *#5:  Frequency Distribution and BarChart for Categorical/Ordinal Level
> Variables such as Gender - SEX*
> freqdist(Scratch$sex)
> barplot(table(Scratch$marital))
>
> -----------------------------------------------------
>
> As you can see from above, I use the <haven> package to import the data
> from SPSS.  Apparently, the haven function keeps the value labels, as the
> attribute options in section #4 of my script shows.
> The problem is that when I run frequency distribution for any of the
> categorical variables like sex or marital status, only the numbers (1, 2,)
> are displayed in the output.  The labels (male, female) for example are
> not.
>
> Is there any way to force these to be shown in the output?  Is there a
> global property that I have to set so that these value labels are reliably
> displayed with every output?  I read I can declare them as factors using
> the <as_factor()>, but once I do so, how do I invoke them in my commands so
> that the value labels show...
>
> Sorry about all the noobs questions, but Ihopefully, I am able to get this
> working.
>
> Thanks in advance.
>
>
> Thanks - cY
>
>
> On Fri, Feb 7, 2020 at 1:14 PM <cpolwart at chemo.org.uk> wrote:
>
> > I've never used it, but there is a labels function in haven...
> >
> > On 7 Feb 2020 17:05, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > What does your data look like after importing? -- see ?head and ?str to
> > tell us. Show us the code that failed to provide "labels." See the
> posting
> > guide below for how to post questions that are likely to elicit helpful
> > responses.
> >
> > I know nothing about the haven package, but see ?factor or go through an
> R
> > tutorial or two to learn about factors, which may be part of the issue
> > here. R *generally* obtains whatever "label" info it needs from the
> object
> > being tabled -- see ?tabulate, ?table etc. -- if that's what you're
> doing.
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Fri, Feb 7, 2020 at 8:28 AM Yawo Kokuvi <yawo1964 at gmail.com> wrote:
> >
> > > Hello,
> > >
> > > I am just transitioning from SPSS to R.
> > >
> > > I used the haven library to import some of my spss data files to R.
> > >
> > > However, when I run procedures such as frequencies or crosstabs, value
> > > labels for categorical variables such as gender (1=male, 2=female) are
> > not
> > > shown. The same applies to many other output.
> > >
> > > I am confused.
> > >
> > > 1. Is there a global setting that I can use to force all categorical
> > > variables to display labels?
> > >
> > > 2. Or, are these labels to be set for each function or package?
> > >
> > > 3. How can I request the value labels for each function I run?
> > >
> > > Thanks in advance for your help..
> > >
> > > Best, Yawo
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Feb  8 04:14:16 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 7 Feb 2020 19:14:16 -0800
Subject: [R] Value Labels: SPSS Dataset to R
In-Reply-To: <CAKZQJMA9Cazf27BYK_F2SzB6zgZFrvtejH0MVHuvr-iq6Rn2hA@mail.gmail.com>
References: <CAGxFJbRXLH8FFVbQrZEXH1+ac=N81HZxcPFnpMvUf8qyWCksmA@mail.gmail.com>
 <6c895565-7f26-453a-8b45-822076bfd5c7@email.android.com>
 <CALjZK84ACUj8MmoRCjSXQvshpoCa48iVMSOgFjFMpUqF=L2GEA@mail.gmail.com>
 <CAKZQJMA9Cazf27BYK_F2SzB6zgZFrvtejH0MVHuvr-iq6Rn2hA@mail.gmail.com>
Message-ID: <CAGxFJbR51AKG84PDqFSduGpiF8HecaGbQ=QU6uz629PUWKtbpQ@mail.gmail.com>

Yes. Most attachments are stripped by the server.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Feb 7, 2020 at 5:34 PM John Kane <jrkrideau at gmail.com> wrote:

> Hi,
> Could you upload some sample data in dput form?  Something like
> dput(head(Scratch, n=13)) will give us some real data to examine. Just copy
> and paste the output of dput(head(Scratch, n=13))into the email. This is
> the best way to ensure that R-help denizens are getting the data in the
> exact format that you have.
>
> On Fri, 7 Feb 2020 at 15:32, Yawo Kokuvi <yawo1964 at gmail.com> wrote:
>
> > Thanks for all your assistance
> >
> > Attached please is the Rdata scratch I have been using
> >
> > -----------------------------------------------------
> >
> > > head(Scratch, n=13)
> > # A tibble: 13 x 6
> >       ID           marital        sex      race    paeduc    speduc
> >    <dbl>         <dbl+lbl>  <dbl+lbl> <dbl+lbl> <dbl+lbl> <dbl+lbl>
> >  1     1 3 [DIVORCED]      1 [MALE]   1 [WHITE]        NA        NA
> >  2     2 1 [MARRIED]       1 [MALE]   1 [WHITE]        NA        NA
> >  3     3 3 [DIVORCED]      1 [MALE]   1 [WHITE]         4        NA
> >  4     4 4 [SEPARATED]     1 [MALE]   1 [WHITE]        16        NA
> >  5     5 3 [DIVORCED]      1 [MALE]   1 [WHITE]        18        NA
> >  6     6 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        14        20
> >  7     7 1 [MARRIED]       2 [FEMALE] 2 [BLACK]        NA        12
> >  8     8 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        NA        12
> >  9     9 3 [DIVORCED]      2 [FEMALE] 1 [WHITE]        11        NA
> > 10    10 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        16        12
> > 11    11 5 [NEVER MARRIED] 2 [FEMALE] 2 [BLACK]        NA        NA
> > 12    12 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        NA        NA
> > 13    13 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        16        NA
> >
> > -----------------------------------------------------
> >
> > and below is my script/command file.
> >
> > *#1: Load library and import SPSS dataset*
> > library(haven)
> > Scratch <- read_sav("~/Desktop/Scratch.sav")
> >
> > *#2: save the dataset with a name*
> > save(ScratchImport, file="Scratch.Rdata")
> >
> > *#3: install & load necessary packages for descriptive statistics*
> > install.packages ("freqdist")
> > library (freqdist)
> >
> > install.packages ("sjlabelled")
> > library (sjlabelled)
> >
> > install.packages ("labelled")
> > library (labelled)
> >
> > install.packages ("surveytoolbox")
> > library (surveytoolbox)
> >
> > *#4: Check the value labels of gender and marital status*
> > Scratch$sex %>% attr('labels')
> > Scratch$marital %>% attr('labels')
> >
> > *#5:  Frequency Distribution and BarChart for Categorical/Ordinal Level
> > Variables such as Gender - SEX*
> > freqdist(Scratch$sex)
> > barplot(table(Scratch$marital))
> >
> > -----------------------------------------------------
> >
> > As you can see from above, I use the <haven> package to import the data
> > from SPSS.  Apparently, the haven function keeps the value labels, as the
> > attribute options in section #4 of my script shows.
> > The problem is that when I run frequency distribution for any of the
> > categorical variables like sex or marital status, only the numbers (1,
> 2,)
> > are displayed in the output.  The labels (male, female) for example are
> > not.
> >
> > Is there any way to force these to be shown in the output?  Is there a
> > global property that I have to set so that these value labels are
> reliably
> > displayed with every output?  I read I can declare them as factors using
> > the <as_factor()>, but once I do so, how do I invoke them in my commands
> so
> > that the value labels show...
> >
> > Sorry about all the noobs questions, but Ihopefully, I am able to get
> this
> > working.
> >
> > Thanks in advance.
> >
> >
> > Thanks - cY
> >
> >
> > On Fri, Feb 7, 2020 at 1:14 PM <cpolwart at chemo.org.uk> wrote:
> >
> > > I've never used it, but there is a labels function in haven...
> > >
> > > On 7 Feb 2020 17:05, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > >
> > > What does your data look like after importing? -- see ?head and ?str to
> > > tell us. Show us the code that failed to provide "labels." See the
> > posting
> > > guide below for how to post questions that are likely to elicit helpful
> > > responses.
> > >
> > > I know nothing about the haven package, but see ?factor or go through
> an
> > R
> > > tutorial or two to learn about factors, which may be part of the issue
> > > here. R *generally* obtains whatever "label" info it needs from the
> > object
> > > being tabled -- see ?tabulate, ?table etc. -- if that's what you're
> > doing.
> > >
> > > Bert Gunter
> > >
> > > "The trouble with having an open mind is that people keep coming along
> > and
> > > sticking things into it."
> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >
> > >
> > > On Fri, Feb 7, 2020 at 8:28 AM Yawo Kokuvi <yawo1964 at gmail.com> wrote:
> > >
> > > > Hello,
> > > >
> > > > I am just transitioning from SPSS to R.
> > > >
> > > > I used the haven library to import some of my spss data files to R.
> > > >
> > > > However, when I run procedures such as frequencies or crosstabs,
> value
> > > > labels for categorical variables such as gender (1=male, 2=female)
> are
> > > not
> > > > shown. The same applies to many other output.
> > > >
> > > > I am confused.
> > > >
> > > > 1. Is there a global setting that I can use to force all categorical
> > > > variables to display labels?
> > > >
> > > > 2. Or, are these labels to be set for each function or package?
> > > >
> > > > 3. How can I request the value labels for each function I run?
> > > >
> > > > Thanks in advance for your help..
> > > >
> > > > Best, Yawo
> > > >
> > > >         [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> John Kane
> Kingston ON Canada
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From y@wo1964 @end|ng |rom gm@||@com  Sat Feb  8 07:03:47 2020
From: y@wo1964 @end|ng |rom gm@||@com (Yawo Kokuvi)
Date: Sat, 8 Feb 2020 01:03:47 -0500
Subject: [R] Value Labels: SPSS Dataset to R
In-Reply-To: <CAGxFJbR51AKG84PDqFSduGpiF8HecaGbQ=QU6uz629PUWKtbpQ@mail.gmail.com>
References: <CAGxFJbRXLH8FFVbQrZEXH1+ac=N81HZxcPFnpMvUf8qyWCksmA@mail.gmail.com>
 <6c895565-7f26-453a-8b45-822076bfd5c7@email.android.com>
 <CALjZK84ACUj8MmoRCjSXQvshpoCa48iVMSOgFjFMpUqF=L2GEA@mail.gmail.com>
 <CAKZQJMA9Cazf27BYK_F2SzB6zgZFrvtejH0MVHuvr-iq6Rn2hA@mail.gmail.com>
 <CAGxFJbR51AKG84PDqFSduGpiF8HecaGbQ=QU6uz629PUWKtbpQ@mail.gmail.com>
Message-ID: <CALjZK84uxMe-orEKjLS_1ddxFakd5JNSjRtiBEnj7P8UroYN=Q@mail.gmail.com>

Thanks for all. Here is output from dput.  I used a different dataset
containing categorical variables since the previous one is on a different
computer.

In the following dataset, my interest is in getting frequencies and
barplots for the two variables: Training and Dance, with value labels
displayed.

thanks again - cY


=========
dput(head(CatsDogs, n = 10))
structure(
  list(
    Animal = structure(
      c(0, 0, 0, 0, 0, 0, 0, 0, 0,
        0),
      label = "Animal",
      labels = c(Cat = 0, Dog = 1),
      class = "haven_labelled"
    ),
    Training = structure(
      c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
      label = "Type of Training",
      labels = c(`Food as Reward` = 0,
                 `Affection as Reward` = 1),
      class = "haven_labelled"
    ),
    Dance = structure(
      c(1,
        1, 1, 1, 1, 1, 1, 1, 1, 1),
      label = "Did they dance?",
      labels = c(No = 0,
                 Yes = 1),
      class = "haven_labelled"
    )
  ),
  row.names = c(NA,-10L),
  class = c("tbl_df", "tbl", "data.frame")
)


On Fri, Feb 7, 2020 at 10:14 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Yes. Most attachments are stripped by the server.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Feb 7, 2020 at 5:34 PM John Kane <jrkrideau at gmail.com> wrote:
>
>> Hi,
>> Could you upload some sample data in dput form?  Something like
>> dput(head(Scratch, n=13)) will give us some real data to examine. Just
>> copy
>> and paste the output of dput(head(Scratch, n=13))into the email. This is
>> the best way to ensure that R-help denizens are getting the data in the
>> exact format that you have.
>>
>> On Fri, 7 Feb 2020 at 15:32, Yawo Kokuvi <yawo1964 at gmail.com> wrote:
>>
>> > Thanks for all your assistance
>> >
>> > Attached please is the Rdata scratch I have been using
>> >
>> > -----------------------------------------------------
>> >
>> > > head(Scratch, n=13)
>> > # A tibble: 13 x 6
>> >       ID           marital        sex      race    paeduc    speduc
>> >    <dbl>         <dbl+lbl>  <dbl+lbl> <dbl+lbl> <dbl+lbl> <dbl+lbl>
>> >  1     1 3 [DIVORCED]      1 [MALE]   1 [WHITE]        NA        NA
>> >  2     2 1 [MARRIED]       1 [MALE]   1 [WHITE]        NA        NA
>> >  3     3 3 [DIVORCED]      1 [MALE]   1 [WHITE]         4        NA
>> >  4     4 4 [SEPARATED]     1 [MALE]   1 [WHITE]        16        NA
>> >  5     5 3 [DIVORCED]      1 [MALE]   1 [WHITE]        18        NA
>> >  6     6 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        14        20
>> >  7     7 1 [MARRIED]       2 [FEMALE] 2 [BLACK]        NA        12
>> >  8     8 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        NA        12
>> >  9     9 3 [DIVORCED]      2 [FEMALE] 1 [WHITE]        11        NA
>> > 10    10 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        16        12
>> > 11    11 5 [NEVER MARRIED] 2 [FEMALE] 2 [BLACK]        NA        NA
>> > 12    12 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        NA        NA
>> > 13    13 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        16        NA
>> >
>> > -----------------------------------------------------
>> >
>> > and below is my script/command file.
>> >
>> > *#1: Load library and import SPSS dataset*
>> > library(haven)
>> > Scratch <- read_sav("~/Desktop/Scratch.sav")
>> >
>> > *#2: save the dataset with a name*
>> > save(ScratchImport, file="Scratch.Rdata")
>> >
>> > *#3: install & load necessary packages for descriptive statistics*
>> > install.packages ("freqdist")
>> > library (freqdist)
>> >
>> > install.packages ("sjlabelled")
>> > library (sjlabelled)
>> >
>> > install.packages ("labelled")
>> > library (labelled)
>> >
>> > install.packages ("surveytoolbox")
>> > library (surveytoolbox)
>> >
>> > *#4: Check the value labels of gender and marital status*
>> > Scratch$sex %>% attr('labels')
>> > Scratch$marital %>% attr('labels')
>> >
>> > *#5:  Frequency Distribution and BarChart for Categorical/Ordinal Level
>> > Variables such as Gender - SEX*
>> > freqdist(Scratch$sex)
>> > barplot(table(Scratch$marital))
>> >
>> > -----------------------------------------------------
>> >
>> > As you can see from above, I use the <haven> package to import the data
>> > from SPSS.  Apparently, the haven function keeps the value labels, as
>> the
>> > attribute options in section #4 of my script shows.
>> > The problem is that when I run frequency distribution for any of the
>> > categorical variables like sex or marital status, only the numbers (1,
>> 2,)
>> > are displayed in the output.  The labels (male, female) for example are
>> > not.
>> >
>> > Is there any way to force these to be shown in the output?  Is there a
>> > global property that I have to set so that these value labels are
>> reliably
>> > displayed with every output?  I read I can declare them as factors using
>> > the <as_factor()>, but once I do so, how do I invoke them in my
>> commands so
>> > that the value labels show...
>> >
>> > Sorry about all the noobs questions, but Ihopefully, I am able to get
>> this
>> > working.
>> >
>> > Thanks in advance.
>> >
>> >
>> > Thanks - cY
>> >
>> >
>> > On Fri, Feb 7, 2020 at 1:14 PM <cpolwart at chemo.org.uk> wrote:
>> >
>> > > I've never used it, but there is a labels function in haven...
>> > >
>> > > On 7 Feb 2020 17:05, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> > >
>> > > What does your data look like after importing? -- see ?head and ?str
>> to
>> > > tell us. Show us the code that failed to provide "labels." See the
>> > posting
>> > > guide below for how to post questions that are likely to elicit
>> helpful
>> > > responses.
>> > >
>> > > I know nothing about the haven package, but see ?factor or go through
>> an
>> > R
>> > > tutorial or two to learn about factors, which may be part of the issue
>> > > here. R *generally* obtains whatever "label" info it needs from the
>> > object
>> > > being tabled -- see ?tabulate, ?table etc. -- if that's what you're
>> > doing.
>> > >
>> > > Bert Gunter
>> > >
>> > > "The trouble with having an open mind is that people keep coming along
>> > and
>> > > sticking things into it."
>> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> > >
>> > >
>> > > On Fri, Feb 7, 2020 at 8:28 AM Yawo Kokuvi <yawo1964 at gmail.com>
>> wrote:
>> > >
>> > > > Hello,
>> > > >
>> > > > I am just transitioning from SPSS to R.
>> > > >
>> > > > I used the haven library to import some of my spss data files to R.
>> > > >
>> > > > However, when I run procedures such as frequencies or crosstabs,
>> value
>> > > > labels for categorical variables such as gender (1=male, 2=female)
>> are
>> > > not
>> > > > shown. The same applies to many other output.
>> > > >
>> > > > I am confused.
>> > > >
>> > > > 1. Is there a global setting that I can use to force all categorical
>> > > > variables to display labels?
>> > > >
>> > > > 2. Or, are these labels to be set for each function or package?
>> > > >
>> > > > 3. How can I request the value labels for each function I run?
>> > > >
>> > > > Thanks in advance for your help..
>> > > >
>> > > > Best, Yawo
>> > > >
>> > > >         [[alternative HTML version deleted]]
>> > > >
>> > > > ______________________________________________
>> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > > PLEASE do read the posting guide
>> > > > http://www.R-project.org/posting-guide.html
>> > > > and provide commented, minimal, self-contained, reproducible code.
>> > > >
>> > >
>> > > [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> > >
>> > >
>> > >
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>
>> --
>> John Kane
>> Kingston ON Canada
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Feb  8 08:19:03 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 8 Feb 2020 20:19:03 +1300
Subject: [R] [FORGED] Re:  Value Labels: SPSS Dataset to R
In-Reply-To: <CALjZK84uxMe-orEKjLS_1ddxFakd5JNSjRtiBEnj7P8UroYN=Q@mail.gmail.com>
References: <CAGxFJbRXLH8FFVbQrZEXH1+ac=N81HZxcPFnpMvUf8qyWCksmA@mail.gmail.com>
 <6c895565-7f26-453a-8b45-822076bfd5c7@email.android.com>
 <CALjZK84ACUj8MmoRCjSXQvshpoCa48iVMSOgFjFMpUqF=L2GEA@mail.gmail.com>
 <CAKZQJMA9Cazf27BYK_F2SzB6zgZFrvtejH0MVHuvr-iq6Rn2hA@mail.gmail.com>
 <CAGxFJbR51AKG84PDqFSduGpiF8HecaGbQ=QU6uz629PUWKtbpQ@mail.gmail.com>
 <CALjZK84uxMe-orEKjLS_1ddxFakd5JNSjRtiBEnj7P8UroYN=Q@mail.gmail.com>
Message-ID: <29fdd9e3-91af-a260-937f-d24df69cd282@auckland.ac.nz>


Dear Yawo,

I would suggest that you learn to use R, rather than thrashing around 
blindly and expecting or hoping to get others to do your work for you.

To get you started, the characteristics that you call "labels" are 
stored as *attributes* of the columns of your tibble/data frame.  E.g.
X$Animal prints as

>  [1] 0 0 0 0 0 0 0 0 0 0
> attr(,"label")
> [1] "Animal"
> attr(,"labels")
> Cat Dog 
>   0   1 
> attr(,"class")
> [1] "haven_labelled"

(where "X" is the head of CatsDogs that you dput()-ed and sent to the list.)

I would start by doing something like

CatsDogs$Animal <- factor(CatsDogs$Animal,levels=c(0,1),
                           labels=c("Cat","Dog"))
and similarly for the other columns.  When you have learnt a bit about 
R, doing your frequency tabulations and barplots will then be easy.

cheers,

Rolf Turner

On 8/02/20 7:03 pm, Yawo Kokuvi wrote:
> Thanks for all. Here is output from dput.  I used a different dataset
> containing categorical variables since the previous one is on a different
> computer.
> 
> In the following dataset, my interest is in getting frequencies and
> barplots for the two variables: Training and Dance, with value labels
> displayed.
> 
> thanks again - cY
> 
> 
> =========
> dput(head(CatsDogs, n = 10))
> structure(
>    list(
>      Animal = structure(
>        c(0, 0, 0, 0, 0, 0, 0, 0, 0,
>          0),
>        label = "Animal",
>        labels = c(Cat = 0, Dog = 1),
>        class = "haven_labelled"
>      ),
>      Training = structure(
>        c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
>        label = "Type of Training",
>        labels = c(`Food as Reward` = 0,
>                   `Affection as Reward` = 1),
>        class = "haven_labelled"
>      ),
>      Dance = structure(
>        c(1,
>          1, 1, 1, 1, 1, 1, 1, 1, 1),
>        label = "Did they dance?",
>        labels = c(No = 0,
>                   Yes = 1),
>        class = "haven_labelled"
>      )
>    ),
>    row.names = c(NA,-10L),
>    class = c("tbl_df", "tbl", "data.frame")
> )

<SNIP>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Feb  8 11:44:28 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 8 Feb 2020 10:44:28 +0000
Subject: [R] Value Labels: SPSS Dataset to R
In-Reply-To: <CALjZK84uxMe-orEKjLS_1ddxFakd5JNSjRtiBEnj7P8UroYN=Q@mail.gmail.com>
References: <CAGxFJbRXLH8FFVbQrZEXH1+ac=N81HZxcPFnpMvUf8qyWCksmA@mail.gmail.com>
 <6c895565-7f26-453a-8b45-822076bfd5c7@email.android.com>
 <CALjZK84ACUj8MmoRCjSXQvshpoCa48iVMSOgFjFMpUqF=L2GEA@mail.gmail.com>
 <CAKZQJMA9Cazf27BYK_F2SzB6zgZFrvtejH0MVHuvr-iq6Rn2hA@mail.gmail.com>
 <CAGxFJbR51AKG84PDqFSduGpiF8HecaGbQ=QU6uz629PUWKtbpQ@mail.gmail.com>
 <CALjZK84uxMe-orEKjLS_1ddxFakd5JNSjRtiBEnj7P8UroYN=Q@mail.gmail.com>
Message-ID: <89c7d316-fba4-3702-3484-51a4764c3d33@sapo.pt>

Hello,

Try

aux_fun <- function(x){
   levels <- attr(x, "labels")
   factor(x, labels = names(levels), levels = levels)
}

newCatsDogs <- as.data.frame(lapply(CatsDogs, aux_fun))

str(newCatsDogs)
#'data.frame':	10 obs. of  3 variables:
# $ Animal  : Factor w/ 2 levels "Cat","Dog": 1 1 1 1 1 1 1 1 1 1
# $ Training: Factor w/ 2 levels "Food as Reward",..: 1 1 1 1 1 1 1 1 1 1
# $ Dance   : Factor w/ 2 levels "No","Yes": 2 2 2 2 2 2 2 2 2 2


As for the
  - frequencies: ?table, ?tapply, ?aggregate,
  - barplots: ?barplot

You can find lots and lots of examples online of both covering what 
seems to simple use cases.

Hope this helps,

Rui Barradas

?s 06:03 de 08/02/20, Yawo Kokuvi escreveu:
> Thanks for all. Here is output from dput.  I used a different dataset
> containing categorical variables since the previous one is on a different
> computer.
> 
> In the following dataset, my interest is in getting frequencies and
> barplots for the two variables: Training and Dance, with value labels
> displayed.
> 
> thanks again - cY
> 
> 
> =========
> dput(head(CatsDogs, n = 10))
> structure(
>    list(
>      Animal = structure(
>        c(0, 0, 0, 0, 0, 0, 0, 0, 0,
>          0),
>        label = "Animal",
>        labels = c(Cat = 0, Dog = 1),
>        class = "haven_labelled"
>      ),
>      Training = structure(
>        c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
>        label = "Type of Training",
>        labels = c(`Food as Reward` = 0,
>                   `Affection as Reward` = 1),
>        class = "haven_labelled"
>      ),
>      Dance = structure(
>        c(1,
>          1, 1, 1, 1, 1, 1, 1, 1, 1),
>        label = "Did they dance?",
>        labels = c(No = 0,
>                   Yes = 1),
>        class = "haven_labelled"
>      )
>    ),
>    row.names = c(NA,-10L),
>    class = c("tbl_df", "tbl", "data.frame")
> )
> 
> 
> On Fri, Feb 7, 2020 at 10:14 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
>> Yes. Most attachments are stripped by the server.
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Fri, Feb 7, 2020 at 5:34 PM John Kane <jrkrideau at gmail.com> wrote:
>>
>>> Hi,
>>> Could you upload some sample data in dput form?  Something like
>>> dput(head(Scratch, n=13)) will give us some real data to examine. Just
>>> copy
>>> and paste the output of dput(head(Scratch, n=13))into the email. This is
>>> the best way to ensure that R-help denizens are getting the data in the
>>> exact format that you have.
>>>
>>> On Fri, 7 Feb 2020 at 15:32, Yawo Kokuvi <yawo1964 at gmail.com> wrote:
>>>
>>>> Thanks for all your assistance
>>>>
>>>> Attached please is the Rdata scratch I have been using
>>>>
>>>> -----------------------------------------------------
>>>>
>>>>> head(Scratch, n=13)
>>>> # A tibble: 13 x 6
>>>>        ID           marital        sex      race    paeduc    speduc
>>>>     <dbl>         <dbl+lbl>  <dbl+lbl> <dbl+lbl> <dbl+lbl> <dbl+lbl>
>>>>   1     1 3 [DIVORCED]      1 [MALE]   1 [WHITE]        NA        NA
>>>>   2     2 1 [MARRIED]       1 [MALE]   1 [WHITE]        NA        NA
>>>>   3     3 3 [DIVORCED]      1 [MALE]   1 [WHITE]         4        NA
>>>>   4     4 4 [SEPARATED]     1 [MALE]   1 [WHITE]        16        NA
>>>>   5     5 3 [DIVORCED]      1 [MALE]   1 [WHITE]        18        NA
>>>>   6     6 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        14        20
>>>>   7     7 1 [MARRIED]       2 [FEMALE] 2 [BLACK]        NA        12
>>>>   8     8 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        NA        12
>>>>   9     9 3 [DIVORCED]      2 [FEMALE] 1 [WHITE]        11        NA
>>>> 10    10 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        16        12
>>>> 11    11 5 [NEVER MARRIED] 2 [FEMALE] 2 [BLACK]        NA        NA
>>>> 12    12 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        NA        NA
>>>> 13    13 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        16        NA
>>>>
>>>> -----------------------------------------------------
>>>>
>>>> and below is my script/command file.
>>>>
>>>> *#1: Load library and import SPSS dataset*
>>>> library(haven)
>>>> Scratch <- read_sav("~/Desktop/Scratch.sav")
>>>>
>>>> *#2: save the dataset with a name*
>>>> save(ScratchImport, file="Scratch.Rdata")
>>>>
>>>> *#3: install & load necessary packages for descriptive statistics*
>>>> install.packages ("freqdist")
>>>> library (freqdist)
>>>>
>>>> install.packages ("sjlabelled")
>>>> library (sjlabelled)
>>>>
>>>> install.packages ("labelled")
>>>> library (labelled)
>>>>
>>>> install.packages ("surveytoolbox")
>>>> library (surveytoolbox)
>>>>
>>>> *#4: Check the value labels of gender and marital status*
>>>> Scratch$sex %>% attr('labels')
>>>> Scratch$marital %>% attr('labels')
>>>>
>>>> *#5:  Frequency Distribution and BarChart for Categorical/Ordinal Level
>>>> Variables such as Gender - SEX*
>>>> freqdist(Scratch$sex)
>>>> barplot(table(Scratch$marital))
>>>>
>>>> -----------------------------------------------------
>>>>
>>>> As you can see from above, I use the <haven> package to import the data
>>>> from SPSS.  Apparently, the haven function keeps the value labels, as
>>> the
>>>> attribute options in section #4 of my script shows.
>>>> The problem is that when I run frequency distribution for any of the
>>>> categorical variables like sex or marital status, only the numbers (1,
>>> 2,)
>>>> are displayed in the output.  The labels (male, female) for example are
>>>> not.
>>>>
>>>> Is there any way to force these to be shown in the output?  Is there a
>>>> global property that I have to set so that these value labels are
>>> reliably
>>>> displayed with every output?  I read I can declare them as factors using
>>>> the <as_factor()>, but once I do so, how do I invoke them in my
>>> commands so
>>>> that the value labels show...
>>>>
>>>> Sorry about all the noobs questions, but Ihopefully, I am able to get
>>> this
>>>> working.
>>>>
>>>> Thanks in advance.
>>>>
>>>>
>>>> Thanks - cY
>>>>
>>>>
>>>> On Fri, Feb 7, 2020 at 1:14 PM <cpolwart at chemo.org.uk> wrote:
>>>>
>>>>> I've never used it, but there is a labels function in haven...
>>>>>
>>>>> On 7 Feb 2020 17:05, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>>>
>>>>> What does your data look like after importing? -- see ?head and ?str
>>> to
>>>>> tell us. Show us the code that failed to provide "labels." See the
>>>> posting
>>>>> guide below for how to post questions that are likely to elicit
>>> helpful
>>>>> responses.
>>>>>
>>>>> I know nothing about the haven package, but see ?factor or go through
>>> an
>>>> R
>>>>> tutorial or two to learn about factors, which may be part of the issue
>>>>> here. R *generally* obtains whatever "label" info it needs from the
>>>> object
>>>>> being tabled -- see ?tabulate, ?table etc. -- if that's what you're
>>>> doing.
>>>>>
>>>>> Bert Gunter
>>>>>
>>>>> "The trouble with having an open mind is that people keep coming along
>>>> and
>>>>> sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>
>>>>>
>>>>> On Fri, Feb 7, 2020 at 8:28 AM Yawo Kokuvi <yawo1964 at gmail.com>
>>> wrote:
>>>>>
>>>>>> Hello,
>>>>>>
>>>>>> I am just transitioning from SPSS to R.
>>>>>>
>>>>>> I used the haven library to import some of my spss data files to R.
>>>>>>
>>>>>> However, when I run procedures such as frequencies or crosstabs,
>>> value
>>>>>> labels for categorical variables such as gender (1=male, 2=female)
>>> are
>>>>> not
>>>>>> shown. The same applies to many other output.
>>>>>>
>>>>>> I am confused.
>>>>>>
>>>>>> 1. Is there a global setting that I can use to force all categorical
>>>>>> variables to display labels?
>>>>>>
>>>>>> 2. Or, are these labels to be set for each function or package?
>>>>>>
>>>>>> 3. How can I request the value labels for each function I run?
>>>>>>
>>>>>> Thanks in advance for your help..
>>>>>>
>>>>>> Best, Yawo
>>>>>>
>>>>>>          [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>> [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>>
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>> --
>>> John Kane
>>> Kingston ON Canada
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkr|de@u @end|ng |rom gm@||@com  Sat Feb  8 15:25:25 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Sat, 8 Feb 2020 09:25:25 -0500
Subject: [R] Value Labels: SPSS Dataset to R
In-Reply-To: <89c7d316-fba4-3702-3484-51a4764c3d33@sapo.pt>
References: <CAGxFJbRXLH8FFVbQrZEXH1+ac=N81HZxcPFnpMvUf8qyWCksmA@mail.gmail.com>
 <6c895565-7f26-453a-8b45-822076bfd5c7@email.android.com>
 <CALjZK84ACUj8MmoRCjSXQvshpoCa48iVMSOgFjFMpUqF=L2GEA@mail.gmail.com>
 <CAKZQJMA9Cazf27BYK_F2SzB6zgZFrvtejH0MVHuvr-iq6Rn2hA@mail.gmail.com>
 <CAGxFJbR51AKG84PDqFSduGpiF8HecaGbQ=QU6uz629PUWKtbpQ@mail.gmail.com>
 <CALjZK84uxMe-orEKjLS_1ddxFakd5JNSjRtiBEnj7P8UroYN=Q@mail.gmail.com>
 <89c7d316-fba4-3702-3484-51a4764c3d33@sapo.pt>
Message-ID: <CAKZQJMD2jq+ekAxCjqNALOZ06uDKDMJWBeJ0eu172qu-a+QLBQ@mail.gmail.com>

Hi Yawo Kokuvi;
As an R newbie transitioning from SPSS to R expect culture shock and the
possible feeling that yor brain is twisting within your skull but it is
well worth.

Try something like this:
##+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
dat1  <- structure(list(Animal = structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0,
0), label = "Animal", labels = c(Cat = 0, Dog = 1), class =
"haven_labelled"),
    Training = structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), label = "Type of
Training", labels = c(`Food as Reward` = 0,
    `Affection as Reward` = 1), class = "haven_labelled"), Dance =
structure(c(1,
    1, 1, 1, 1, 1, 1, 1, 1, 1), label = "Did they dance?", labels = c(No =
0,
    Yes = 1), class = "haven_labelled")), row.names = c(NA, -10L
), class = c("tbl_df", "tbl", "data.frame"))


library(sjlabelled)
str(dat1)
get_labels(dat1)
barplot(table(as_label(dat1$Dance)))
##==================================================================
Your problem sees to be omitting the as_label().

You do not need to load "haven"
read_spss() in sjlabelled should do the trick.


On Sat, 8 Feb 2020 at 05:44, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Try
>
> aux_fun <- function(x){
>    levels <- attr(x, "labels")
>    factor(x, labels = names(levels), levels = levels)
> }
>
> newCatsDogs <- as.data.frame(lapply(CatsDogs, aux_fun))
>
> str(newCatsDogs)
> #'data.frame':  10 obs. of  3 variables:
> # $ Animal  : Factor w/ 2 levels "Cat","Dog": 1 1 1 1 1 1 1 1 1 1
> # $ Training: Factor w/ 2 levels "Food as Reward",..: 1 1 1 1 1 1 1 1 1 1
> # $ Dance   : Factor w/ 2 levels "No","Yes": 2 2 2 2 2 2 2 2 2 2
>
>
> As for the
>   - frequencies: ?table, ?tapply, ?aggregate,
>   - barplots: ?barplot
>
> You can find lots and lots of examples online of both covering what
> seems to simple use cases.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 06:03 de 08/02/20, Yawo Kokuvi escreveu:
> > Thanks for all. Here is output from dput.  I used a different dataset
> > containing categorical variables since the previous one is on a different
> > computer.
> >
> > In the following dataset, my interest is in getting frequencies and
> > barplots for the two variables: Training and Dance, with value labels
> > displayed.
> >
> > thanks again - cY
> >
> >
> > =========
> > dput(head(CatsDogs, n = 10))
> > structure(
> >    list(
> >      Animal = structure(
> >        c(0, 0, 0, 0, 0, 0, 0, 0, 0,
> >          0),
> >        label = "Animal",
> >        labels = c(Cat = 0, Dog = 1),
> >        class = "haven_labelled"
> >      ),
> >      Training = structure(
> >        c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
> >        label = "Type of Training",
> >        labels = c(`Food as Reward` = 0,
> >                   `Affection as Reward` = 1),
> >        class = "haven_labelled"
> >      ),
> >      Dance = structure(
> >        c(1,
> >          1, 1, 1, 1, 1, 1, 1, 1, 1),
> >        label = "Did they dance?",
> >        labels = c(No = 0,
> >                   Yes = 1),
> >        class = "haven_labelled"
> >      )
> >    ),
> >    row.names = c(NA,-10L),
> >    class = c("tbl_df", "tbl", "data.frame")
> > )
> >
> >
> > On Fri, Feb 7, 2020 at 10:14 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> >> Yes. Most attachments are stripped by the server.
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> and
> >> sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Fri, Feb 7, 2020 at 5:34 PM John Kane <jrkrideau at gmail.com> wrote:
> >>
> >>> Hi,
> >>> Could you upload some sample data in dput form?  Something like
> >>> dput(head(Scratch, n=13)) will give us some real data to examine. Just
> >>> copy
> >>> and paste the output of dput(head(Scratch, n=13))into the email. This
> is
> >>> the best way to ensure that R-help denizens are getting the data in the
> >>> exact format that you have.
> >>>
> >>> On Fri, 7 Feb 2020 at 15:32, Yawo Kokuvi <yawo1964 at gmail.com> wrote:
> >>>
> >>>> Thanks for all your assistance
> >>>>
> >>>> Attached please is the Rdata scratch I have been using
> >>>>
> >>>> -----------------------------------------------------
> >>>>
> >>>>> head(Scratch, n=13)
> >>>> # A tibble: 13 x 6
> >>>>        ID           marital        sex      race    paeduc    speduc
> >>>>     <dbl>         <dbl+lbl>  <dbl+lbl> <dbl+lbl> <dbl+lbl> <dbl+lbl>
> >>>>   1     1 3 [DIVORCED]      1 [MALE]   1 [WHITE]        NA        NA
> >>>>   2     2 1 [MARRIED]       1 [MALE]   1 [WHITE]        NA        NA
> >>>>   3     3 3 [DIVORCED]      1 [MALE]   1 [WHITE]         4        NA
> >>>>   4     4 4 [SEPARATED]     1 [MALE]   1 [WHITE]        16        NA
> >>>>   5     5 3 [DIVORCED]      1 [MALE]   1 [WHITE]        18        NA
> >>>>   6     6 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        14        20
> >>>>   7     7 1 [MARRIED]       2 [FEMALE] 2 [BLACK]        NA        12
> >>>>   8     8 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        NA        12
> >>>>   9     9 3 [DIVORCED]      2 [FEMALE] 1 [WHITE]        11        NA
> >>>> 10    10 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        16        12
> >>>> 11    11 5 [NEVER MARRIED] 2 [FEMALE] 2 [BLACK]        NA        NA
> >>>> 12    12 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        NA        NA
> >>>> 13    13 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        16        NA
> >>>>
> >>>> -----------------------------------------------------
> >>>>
> >>>> and below is my script/command file.
> >>>>
> >>>> *#1: Load library and import SPSS dataset*
> >>>> library(haven)
> >>>> Scratch <- read_sav("~/Desktop/Scratch.sav")
> >>>>
> >>>> *#2: save the dataset with a name*
> >>>> save(ScratchImport, file="Scratch.Rdata")
> >>>>
> >>>> *#3: install & load necessary packages for descriptive statistics*
> >>>> install.packages ("freqdist")
> >>>> library (freqdist)
> >>>>
> >>>> install.packages ("sjlabelled")
> >>>> library (sjlabelled)
> >>>>
> >>>> install.packages ("labelled")
> >>>> library (labelled)
> >>>>
> >>>> install.packages ("surveytoolbox")
> >>>> library (surveytoolbox)
> >>>>
> >>>> *#4: Check the value labels of gender and marital status*
> >>>> Scratch$sex %>% attr('labels')
> >>>> Scratch$marital %>% attr('labels')
> >>>>
> >>>> *#5:  Frequency Distribution and BarChart for Categorical/Ordinal
> Level
> >>>> Variables such as Gender - SEX*
> >>>> freqdist(Scratch$sex)
> >>>> barplot(table(Scratch$marital))
> >>>>
> >>>> -----------------------------------------------------
> >>>>
> >>>> As you can see from above, I use the <haven> package to import the
> data
> >>>> from SPSS.  Apparently, the haven function keeps the value labels, as
> >>> the
> >>>> attribute options in section #4 of my script shows.
> >>>> The problem is that when I run frequency distribution for any of the
> >>>> categorical variables like sex or marital status, only the numbers (1,
> >>> 2,)
> >>>> are displayed in the output.  The labels (male, female) for example
> are
> >>>> not.
> >>>>
> >>>> Is there any way to force these to be shown in the output?  Is there a
> >>>> global property that I have to set so that these value labels are
> >>> reliably
> >>>> displayed with every output?  I read I can declare them as factors
> using
> >>>> the <as_factor()>, but once I do so, how do I invoke them in my
> >>> commands so
> >>>> that the value labels show...
> >>>>
> >>>> Sorry about all the noobs questions, but Ihopefully, I am able to get
> >>> this
> >>>> working.
> >>>>
> >>>> Thanks in advance.
> >>>>
> >>>>
> >>>> Thanks - cY
> >>>>
> >>>>
> >>>> On Fri, Feb 7, 2020 at 1:14 PM <cpolwart at chemo.org.uk> wrote:
> >>>>
> >>>>> I've never used it, but there is a labels function in haven...
> >>>>>
> >>>>> On 7 Feb 2020 17:05, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >>>>>
> >>>>> What does your data look like after importing? -- see ?head and ?str
> >>> to
> >>>>> tell us. Show us the code that failed to provide "labels." See the
> >>>> posting
> >>>>> guide below for how to post questions that are likely to elicit
> >>> helpful
> >>>>> responses.
> >>>>>
> >>>>> I know nothing about the haven package, but see ?factor or go through
> >>> an
> >>>> R
> >>>>> tutorial or two to learn about factors, which may be part of the
> issue
> >>>>> here. R *generally* obtains whatever "label" info it needs from the
> >>>> object
> >>>>> being tabled -- see ?tabulate, ?table etc. -- if that's what you're
> >>>> doing.
> >>>>>
> >>>>> Bert Gunter
> >>>>>
> >>>>> "The trouble with having an open mind is that people keep coming
> along
> >>>> and
> >>>>> sticking things into it."
> >>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>>
> >>>>>
> >>>>> On Fri, Feb 7, 2020 at 8:28 AM Yawo Kokuvi <yawo1964 at gmail.com>
> >>> wrote:
> >>>>>
> >>>>>> Hello,
> >>>>>>
> >>>>>> I am just transitioning from SPSS to R.
> >>>>>>
> >>>>>> I used the haven library to import some of my spss data files to R.
> >>>>>>
> >>>>>> However, when I run procedures such as frequencies or crosstabs,
> >>> value
> >>>>>> labels for categorical variables such as gender (1=male, 2=female)
> >>> are
> >>>>> not
> >>>>>> shown. The same applies to many other output.
> >>>>>>
> >>>>>> I am confused.
> >>>>>>
> >>>>>> 1. Is there a global setting that I can use to force all categorical
> >>>>>> variables to display labels?
> >>>>>>
> >>>>>> 2. Or, are these labels to be set for each function or package?
> >>>>>>
> >>>>>> 3. How can I request the value labels for each function I run?
> >>>>>>
> >>>>>> Thanks in advance for your help..
> >>>>>>
> >>>>>> Best, Yawo
> >>>>>>
> >>>>>>          [[alternative HTML version deleted]]
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>> PLEASE do read the posting guide
> >>>>>> http://www.R-project.org/posting-guide.html
> >>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>
> >>>>>
> >>>>> [[alternative HTML version deleted]]
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>>
> >>>>>
> >>>>
> >>>>          [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>
> >>> --
> >>> John Kane
> >>> Kingston ON Canada
> >>>
> >>>          [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From y@wo1964 @end|ng |rom gm@||@com  Sat Feb  8 15:35:04 2020
From: y@wo1964 @end|ng |rom gm@||@com (Yawo Kokuvi)
Date: Sat, 8 Feb 2020 09:35:04 -0500
Subject: [R] Value Labels: SPSS Dataset to R
In-Reply-To: <CAKZQJMD2jq+ekAxCjqNALOZ06uDKDMJWBeJ0eu172qu-a+QLBQ@mail.gmail.com>
References: <CAGxFJbRXLH8FFVbQrZEXH1+ac=N81HZxcPFnpMvUf8qyWCksmA@mail.gmail.com>
 <6c895565-7f26-453a-8b45-822076bfd5c7@email.android.com>
 <CALjZK84ACUj8MmoRCjSXQvshpoCa48iVMSOgFjFMpUqF=L2GEA@mail.gmail.com>
 <CAKZQJMA9Cazf27BYK_F2SzB6zgZFrvtejH0MVHuvr-iq6Rn2hA@mail.gmail.com>
 <CAGxFJbR51AKG84PDqFSduGpiF8HecaGbQ=QU6uz629PUWKtbpQ@mail.gmail.com>
 <CALjZK84uxMe-orEKjLS_1ddxFakd5JNSjRtiBEnj7P8UroYN=Q@mail.gmail.com>
 <89c7d316-fba4-3702-3484-51a4764c3d33@sapo.pt>
 <CAKZQJMD2jq+ekAxCjqNALOZ06uDKDMJWBeJ0eu172qu-a+QLBQ@mail.gmail.com>
Message-ID: <CALjZK87TyfuGEJQdpL9kLo7HLE=ezmRYtgNNp3LS97=xdJM0vA@mail.gmail.com>

Thanks so much for all your assistance.  I admit R's learning curve is a
bit steep, but I am eager to learn ... and hopefully teach with it.

with regard to my problem, I can now see two options:  either declare each
categorical variable as factors, specifying the needed levels and labels.

OR

use a different function (read_spss) as John has suggested to import the
file.

I will experiment with both.

With much appreciation, cY

On Sat, Feb 8, 2020 at 9:25 AM John Kane <jrkrideau at gmail.com> wrote:

> Hi Yawo Kokuvi;
> As an R newbie transitioning from SPSS to R expect culture shock and the
> possible feeling that yor brain is twisting within your skull but it is
> well worth.
>
> Try something like this:
> ##+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
> dat1  <- structure(list(Animal = structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0), label = "Animal", labels = c(Cat = 0, Dog = 1), class =
> "haven_labelled"),
>     Training = structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), label = "Type of
> Training", labels = c(`Food as Reward` = 0,
>     `Affection as Reward` = 1), class = "haven_labelled"), Dance =
> structure(c(1,
>     1, 1, 1, 1, 1, 1, 1, 1, 1), label = "Did they dance?", labels = c(No =
> 0,
>     Yes = 1), class = "haven_labelled")), row.names = c(NA, -10L
> ), class = c("tbl_df", "tbl", "data.frame"))
>
>
> library(sjlabelled)
> str(dat1)
> get_labels(dat1)
> barplot(table(as_label(dat1$Dance)))
> ##==================================================================
> Your problem sees to be omitting the as_label().
>
> You do not need to load "haven"
> read_spss() in sjlabelled should do the trick.
>
>
> On Sat, 8 Feb 2020 at 05:44, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> Try
>>
>> aux_fun <- function(x){
>>    levels <- attr(x, "labels")
>>    factor(x, labels = names(levels), levels = levels)
>> }
>>
>> newCatsDogs <- as.data.frame(lapply(CatsDogs, aux_fun))
>>
>> str(newCatsDogs)
>> #'data.frame':  10 obs. of  3 variables:
>> # $ Animal  : Factor w/ 2 levels "Cat","Dog": 1 1 1 1 1 1 1 1 1 1
>> # $ Training: Factor w/ 2 levels "Food as Reward",..: 1 1 1 1 1 1 1 1 1 1
>> # $ Dance   : Factor w/ 2 levels "No","Yes": 2 2 2 2 2 2 2 2 2 2
>>
>>
>> As for the
>>   - frequencies: ?table, ?tapply, ?aggregate,
>>   - barplots: ?barplot
>>
>> You can find lots and lots of examples online of both covering what
>> seems to simple use cases.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 06:03 de 08/02/20, Yawo Kokuvi escreveu:
>> > Thanks for all. Here is output from dput.  I used a different dataset
>> > containing categorical variables since the previous one is on a
>> different
>> > computer.
>> >
>> > In the following dataset, my interest is in getting frequencies and
>> > barplots for the two variables: Training and Dance, with value labels
>> > displayed.
>> >
>> > thanks again - cY
>> >
>> >
>> > =========
>> > dput(head(CatsDogs, n = 10))
>> > structure(
>> >    list(
>> >      Animal = structure(
>> >        c(0, 0, 0, 0, 0, 0, 0, 0, 0,
>> >          0),
>> >        label = "Animal",
>> >        labels = c(Cat = 0, Dog = 1),
>> >        class = "haven_labelled"
>> >      ),
>> >      Training = structure(
>> >        c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
>> >        label = "Type of Training",
>> >        labels = c(`Food as Reward` = 0,
>> >                   `Affection as Reward` = 1),
>> >        class = "haven_labelled"
>> >      ),
>> >      Dance = structure(
>> >        c(1,
>> >          1, 1, 1, 1, 1, 1, 1, 1, 1),
>> >        label = "Did they dance?",
>> >        labels = c(No = 0,
>> >                   Yes = 1),
>> >        class = "haven_labelled"
>> >      )
>> >    ),
>> >    row.names = c(NA,-10L),
>> >    class = c("tbl_df", "tbl", "data.frame")
>> > )
>> >
>> >
>> > On Fri, Feb 7, 2020 at 10:14 PM Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>> >
>> >> Yes. Most attachments are stripped by the server.
>> >>
>> >> Bert Gunter
>> >>
>> >> "The trouble with having an open mind is that people keep coming along
>> and
>> >> sticking things into it."
>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>
>> >>
>> >> On Fri, Feb 7, 2020 at 5:34 PM John Kane <jrkrideau at gmail.com> wrote:
>> >>
>> >>> Hi,
>> >>> Could you upload some sample data in dput form?  Something like
>> >>> dput(head(Scratch, n=13)) will give us some real data to examine. Just
>> >>> copy
>> >>> and paste the output of dput(head(Scratch, n=13))into the email. This
>> is
>> >>> the best way to ensure that R-help denizens are getting the data in
>> the
>> >>> exact format that you have.
>> >>>
>> >>> On Fri, 7 Feb 2020 at 15:32, Yawo Kokuvi <yawo1964 at gmail.com> wrote:
>> >>>
>> >>>> Thanks for all your assistance
>> >>>>
>> >>>> Attached please is the Rdata scratch I have been using
>> >>>>
>> >>>> -----------------------------------------------------
>> >>>>
>> >>>>> head(Scratch, n=13)
>> >>>> # A tibble: 13 x 6
>> >>>>        ID           marital        sex      race    paeduc    speduc
>> >>>>     <dbl>         <dbl+lbl>  <dbl+lbl> <dbl+lbl> <dbl+lbl> <dbl+lbl>
>> >>>>   1     1 3 [DIVORCED]      1 [MALE]   1 [WHITE]        NA        NA
>> >>>>   2     2 1 [MARRIED]       1 [MALE]   1 [WHITE]        NA        NA
>> >>>>   3     3 3 [DIVORCED]      1 [MALE]   1 [WHITE]         4        NA
>> >>>>   4     4 4 [SEPARATED]     1 [MALE]   1 [WHITE]        16        NA
>> >>>>   5     5 3 [DIVORCED]      1 [MALE]   1 [WHITE]        18        NA
>> >>>>   6     6 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        14        20
>> >>>>   7     7 1 [MARRIED]       2 [FEMALE] 2 [BLACK]        NA        12
>> >>>>   8     8 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        NA        12
>> >>>>   9     9 3 [DIVORCED]      2 [FEMALE] 1 [WHITE]        11        NA
>> >>>> 10    10 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        16        12
>> >>>> 11    11 5 [NEVER MARRIED] 2 [FEMALE] 2 [BLACK]        NA        NA
>> >>>> 12    12 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        NA        NA
>> >>>> 13    13 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        16        NA
>> >>>>
>> >>>> -----------------------------------------------------
>> >>>>
>> >>>> and below is my script/command file.
>> >>>>
>> >>>> *#1: Load library and import SPSS dataset*
>> >>>> library(haven)
>> >>>> Scratch <- read_sav("~/Desktop/Scratch.sav")
>> >>>>
>> >>>> *#2: save the dataset with a name*
>> >>>> save(ScratchImport, file="Scratch.Rdata")
>> >>>>
>> >>>> *#3: install & load necessary packages for descriptive statistics*
>> >>>> install.packages ("freqdist")
>> >>>> library (freqdist)
>> >>>>
>> >>>> install.packages ("sjlabelled")
>> >>>> library (sjlabelled)
>> >>>>
>> >>>> install.packages ("labelled")
>> >>>> library (labelled)
>> >>>>
>> >>>> install.packages ("surveytoolbox")
>> >>>> library (surveytoolbox)
>> >>>>
>> >>>> *#4: Check the value labels of gender and marital status*
>> >>>> Scratch$sex %>% attr('labels')
>> >>>> Scratch$marital %>% attr('labels')
>> >>>>
>> >>>> *#5:  Frequency Distribution and BarChart for Categorical/Ordinal
>> Level
>> >>>> Variables such as Gender - SEX*
>> >>>> freqdist(Scratch$sex)
>> >>>> barplot(table(Scratch$marital))
>> >>>>
>> >>>> -----------------------------------------------------
>> >>>>
>> >>>> As you can see from above, I use the <haven> package to import the
>> data
>> >>>> from SPSS.  Apparently, the haven function keeps the value labels, as
>> >>> the
>> >>>> attribute options in section #4 of my script shows.
>> >>>> The problem is that when I run frequency distribution for any of the
>> >>>> categorical variables like sex or marital status, only the numbers
>> (1,
>> >>> 2,)
>> >>>> are displayed in the output.  The labels (male, female) for example
>> are
>> >>>> not.
>> >>>>
>> >>>> Is there any way to force these to be shown in the output?  Is there
>> a
>> >>>> global property that I have to set so that these value labels are
>> >>> reliably
>> >>>> displayed with every output?  I read I can declare them as factors
>> using
>> >>>> the <as_factor()>, but once I do so, how do I invoke them in my
>> >>> commands so
>> >>>> that the value labels show...
>> >>>>
>> >>>> Sorry about all the noobs questions, but Ihopefully, I am able to get
>> >>> this
>> >>>> working.
>> >>>>
>> >>>> Thanks in advance.
>> >>>>
>> >>>>
>> >>>> Thanks - cY
>> >>>>
>> >>>>
>> >>>> On Fri, Feb 7, 2020 at 1:14 PM <cpolwart at chemo.org.uk> wrote:
>> >>>>
>> >>>>> I've never used it, but there is a labels function in haven...
>> >>>>>
>> >>>>> On 7 Feb 2020 17:05, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> >>>>>
>> >>>>> What does your data look like after importing? -- see ?head and ?str
>> >>> to
>> >>>>> tell us. Show us the code that failed to provide "labels." See the
>> >>>> posting
>> >>>>> guide below for how to post questions that are likely to elicit
>> >>> helpful
>> >>>>> responses.
>> >>>>>
>> >>>>> I know nothing about the haven package, but see ?factor or go
>> through
>> >>> an
>> >>>> R
>> >>>>> tutorial or two to learn about factors, which may be part of the
>> issue
>> >>>>> here. R *generally* obtains whatever "label" info it needs from the
>> >>>> object
>> >>>>> being tabled -- see ?tabulate, ?table etc. -- if that's what you're
>> >>>> doing.
>> >>>>>
>> >>>>> Bert Gunter
>> >>>>>
>> >>>>> "The trouble with having an open mind is that people keep coming
>> along
>> >>>> and
>> >>>>> sticking things into it."
>> >>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>>>>
>> >>>>>
>> >>>>> On Fri, Feb 7, 2020 at 8:28 AM Yawo Kokuvi <yawo1964 at gmail.com>
>> >>> wrote:
>> >>>>>
>> >>>>>> Hello,
>> >>>>>>
>> >>>>>> I am just transitioning from SPSS to R.
>> >>>>>>
>> >>>>>> I used the haven library to import some of my spss data files to R.
>> >>>>>>
>> >>>>>> However, when I run procedures such as frequencies or crosstabs,
>> >>> value
>> >>>>>> labels for categorical variables such as gender (1=male, 2=female)
>> >>> are
>> >>>>> not
>> >>>>>> shown. The same applies to many other output.
>> >>>>>>
>> >>>>>> I am confused.
>> >>>>>>
>> >>>>>> 1. Is there a global setting that I can use to force all
>> categorical
>> >>>>>> variables to display labels?
>> >>>>>>
>> >>>>>> 2. Or, are these labels to be set for each function or package?
>> >>>>>>
>> >>>>>> 3. How can I request the value labels for each function I run?
>> >>>>>>
>> >>>>>> Thanks in advance for your help..
>> >>>>>>
>> >>>>>> Best, Yawo
>> >>>>>>
>> >>>>>>          [[alternative HTML version deleted]]
>> >>>>>>
>> >>>>>> ______________________________________________
>> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>>> PLEASE do read the posting guide
>> >>>>>> http://www.R-project.org/posting-guide.html
>> >>>>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>>>
>> >>>>>
>> >>>>> [[alternative HTML version deleted]]
>> >>>>>
>> >>>>> ______________________________________________
>> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>> PLEASE do read the posting guide
>> >>>>> http://www.R-project.org/posting-guide.html
>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>
>> >>>>          [[alternative HTML version deleted]]
>> >>>>
>> >>>> ______________________________________________
>> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>> PLEASE do read the posting guide
>> >>>> http://www.R-project.org/posting-guide.html
>> >>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>
>> >>>
>> >>>
>> >>> --
>> >>> John Kane
>> >>> Kingston ON Canada
>> >>>
>> >>>          [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide
>> >>> http://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >>>
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> John Kane
> Kingston ON Canada
>

	[[alternative HTML version deleted]]


From jrkr|de@u @end|ng |rom gm@||@com  Sat Feb  8 16:28:45 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Sat, 8 Feb 2020 10:28:45 -0500
Subject: [R] Value Labels: SPSS Dataset to R
In-Reply-To: <CALjZK87TyfuGEJQdpL9kLo7HLE=ezmRYtgNNp3LS97=xdJM0vA@mail.gmail.com>
References: <CAGxFJbRXLH8FFVbQrZEXH1+ac=N81HZxcPFnpMvUf8qyWCksmA@mail.gmail.com>
 <6c895565-7f26-453a-8b45-822076bfd5c7@email.android.com>
 <CALjZK84ACUj8MmoRCjSXQvshpoCa48iVMSOgFjFMpUqF=L2GEA@mail.gmail.com>
 <CAKZQJMA9Cazf27BYK_F2SzB6zgZFrvtejH0MVHuvr-iq6Rn2hA@mail.gmail.com>
 <CAGxFJbR51AKG84PDqFSduGpiF8HecaGbQ=QU6uz629PUWKtbpQ@mail.gmail.com>
 <CALjZK84uxMe-orEKjLS_1ddxFakd5JNSjRtiBEnj7P8UroYN=Q@mail.gmail.com>
 <89c7d316-fba4-3702-3484-51a4764c3d33@sapo.pt>
 <CAKZQJMD2jq+ekAxCjqNALOZ06uDKDMJWBeJ0eu172qu-a+QLBQ@mail.gmail.com>
 <CALjZK87TyfuGEJQdpL9kLo7HLE=ezmRYtgNNp3LS97=xdJM0vA@mail.gmail.com>
Message-ID: <CAKZQJMDi9GX3eSjqxgZ3MRdc0Yu=qE5mk4CMtPCPE-O6eCVoEA@mail.gmail.com>

"use a different function (read_spss) as John has suggested to import the
file. "

No! As far as I can see sjlabelled is simply using haven"s function "
read_sav()" to read in the data. It is just wrapped in the "read.spss()
function.There should be no difference between read_sav(sdata.sav) and
read_spss(sdata.sav).

It just seems to keep the code simpler (more aesthetically pleasing?) if
you do not load more packages than needed. Likewise you do not need to load
"labels" as sjlabelledis taking care of this for you.

Oh, BTW  Scratch$sex %>% attr('labels') can be replaced by something like
get_labels(dat1) in my example. There usually are a multitude of ways to do
the same thing in R.

You might want to have a look at
https://cran.r-project.org/web/packages/labelled/vignettes/intro_labelled.html
and https://strengejacke.github.io/sjlabelled/articles/labelleddata.html
for more about working with labels.

On Sat, 8 Feb 2020 at 09:35, Yawo Kokuvi <yawo1964 at gmail.com> wrote:

> Thanks so much for all your assistance.  I admit R's learning curve is a
> bit steep, but I am eager to learn ... and hopefully teach with it.
>
> with regard to my problem, I can now see two options:  either declare each
> categorical variable as factors, specifying the needed levels and labels.
>
> OR
>
> use a different function (read_spss) as John has suggested to import the
> file.
>
> I will experiment with both.
>
> With much appreciation, cY
>
> On Sat, Feb 8, 2020 at 9:25 AM John Kane <jrkrideau at gmail.com> wrote:
>
>> Hi Yawo Kokuvi;
>> As an R newbie transitioning from SPSS to R expect culture shock and the
>> possible feeling that yor brain is twisting within your skull but it is
>> well worth.
>>
>> Try something like this:
>> ##+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
>> dat1  <- structure(list(Animal = structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0,
>> 0), label = "Animal", labels = c(Cat = 0, Dog = 1), class =
>> "haven_labelled"),
>>     Training = structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), label = "Type
>> of Training", labels = c(`Food as Reward` = 0,
>>     `Affection as Reward` = 1), class = "haven_labelled"), Dance =
>> structure(c(1,
>>     1, 1, 1, 1, 1, 1, 1, 1, 1), label = "Did they dance?", labels = c(No
>> = 0,
>>     Yes = 1), class = "haven_labelled")), row.names = c(NA, -10L
>> ), class = c("tbl_df", "tbl", "data.frame"))
>>
>>
>> library(sjlabelled)
>> str(dat1)
>> get_labels(dat1)
>> barplot(table(as_label(dat1$Dance)))
>> ##==================================================================
>> Your problem sees to be omitting the as_label().
>>
>> You do not need to load "haven"
>> read_spss() in sjlabelled should do the trick.
>>
>>
>> On Sat, 8 Feb 2020 at 05:44, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>
>>> Hello,
>>>
>>> Try
>>>
>>> aux_fun <- function(x){
>>>    levels <- attr(x, "labels")
>>>    factor(x, labels = names(levels), levels = levels)
>>> }
>>>
>>> newCatsDogs <- as.data.frame(lapply(CatsDogs, aux_fun))
>>>
>>> str(newCatsDogs)
>>> #'data.frame':  10 obs. of  3 variables:
>>> # $ Animal  : Factor w/ 2 levels "Cat","Dog": 1 1 1 1 1 1 1 1 1 1
>>> # $ Training: Factor w/ 2 levels "Food as Reward",..: 1 1 1 1 1 1 1 1 1 1
>>> # $ Dance   : Factor w/ 2 levels "No","Yes": 2 2 2 2 2 2 2 2 2 2
>>>
>>>
>>> As for the
>>>   - frequencies: ?table, ?tapply, ?aggregate,
>>>   - barplots: ?barplot
>>>
>>> You can find lots and lots of examples online of both covering what
>>> seems to simple use cases.
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>> ?s 06:03 de 08/02/20, Yawo Kokuvi escreveu:
>>> > Thanks for all. Here is output from dput.  I used a different dataset
>>> > containing categorical variables since the previous one is on a
>>> different
>>> > computer.
>>> >
>>> > In the following dataset, my interest is in getting frequencies and
>>> > barplots for the two variables: Training and Dance, with value labels
>>> > displayed.
>>> >
>>> > thanks again - cY
>>> >
>>> >
>>> > =========
>>> > dput(head(CatsDogs, n = 10))
>>> > structure(
>>> >    list(
>>> >      Animal = structure(
>>> >        c(0, 0, 0, 0, 0, 0, 0, 0, 0,
>>> >          0),
>>> >        label = "Animal",
>>> >        labels = c(Cat = 0, Dog = 1),
>>> >        class = "haven_labelled"
>>> >      ),
>>> >      Training = structure(
>>> >        c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
>>> >        label = "Type of Training",
>>> >        labels = c(`Food as Reward` = 0,
>>> >                   `Affection as Reward` = 1),
>>> >        class = "haven_labelled"
>>> >      ),
>>> >      Dance = structure(
>>> >        c(1,
>>> >          1, 1, 1, 1, 1, 1, 1, 1, 1),
>>> >        label = "Did they dance?",
>>> >        labels = c(No = 0,
>>> >                   Yes = 1),
>>> >        class = "haven_labelled"
>>> >      )
>>> >    ),
>>> >    row.names = c(NA,-10L),
>>> >    class = c("tbl_df", "tbl", "data.frame")
>>> > )
>>> >
>>> >
>>> > On Fri, Feb 7, 2020 at 10:14 PM Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>> >
>>> >> Yes. Most attachments are stripped by the server.
>>> >>
>>> >> Bert Gunter
>>> >>
>>> >> "The trouble with having an open mind is that people keep coming
>>> along and
>>> >> sticking things into it."
>>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> >>
>>> >>
>>> >> On Fri, Feb 7, 2020 at 5:34 PM John Kane <jrkrideau at gmail.com> wrote:
>>> >>
>>> >>> Hi,
>>> >>> Could you upload some sample data in dput form?  Something like
>>> >>> dput(head(Scratch, n=13)) will give us some real data to examine.
>>> Just
>>> >>> copy
>>> >>> and paste the output of dput(head(Scratch, n=13))into the email.
>>> This is
>>> >>> the best way to ensure that R-help denizens are getting the data in
>>> the
>>> >>> exact format that you have.
>>> >>>
>>> >>> On Fri, 7 Feb 2020 at 15:32, Yawo Kokuvi <yawo1964 at gmail.com> wrote:
>>> >>>
>>> >>>> Thanks for all your assistance
>>> >>>>
>>> >>>> Attached please is the Rdata scratch I have been using
>>> >>>>
>>> >>>> -----------------------------------------------------
>>> >>>>
>>> >>>>> head(Scratch, n=13)
>>> >>>> # A tibble: 13 x 6
>>> >>>>        ID           marital        sex      race    paeduc    speduc
>>> >>>>     <dbl>         <dbl+lbl>  <dbl+lbl> <dbl+lbl> <dbl+lbl> <dbl+lbl>
>>> >>>>   1     1 3 [DIVORCED]      1 [MALE]   1 [WHITE]        NA        NA
>>> >>>>   2     2 1 [MARRIED]       1 [MALE]   1 [WHITE]        NA        NA
>>> >>>>   3     3 3 [DIVORCED]      1 [MALE]   1 [WHITE]         4        NA
>>> >>>>   4     4 4 [SEPARATED]     1 [MALE]   1 [WHITE]        16        NA
>>> >>>>   5     5 3 [DIVORCED]      1 [MALE]   1 [WHITE]        18        NA
>>> >>>>   6     6 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        14        20
>>> >>>>   7     7 1 [MARRIED]       2 [FEMALE] 2 [BLACK]        NA        12
>>> >>>>   8     8 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        NA        12
>>> >>>>   9     9 3 [DIVORCED]      2 [FEMALE] 1 [WHITE]        11        NA
>>> >>>> 10    10 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        16        12
>>> >>>> 11    11 5 [NEVER MARRIED] 2 [FEMALE] 2 [BLACK]        NA        NA
>>> >>>> 12    12 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        NA        NA
>>> >>>> 13    13 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        16        NA
>>> >>>>
>>> >>>> -----------------------------------------------------
>>> >>>>
>>> >>>> and below is my script/command file.
>>> >>>>
>>> >>>> *#1: Load library and import SPSS dataset*
>>> >>>> library(haven)
>>> >>>> Scratch <- read_sav("~/Desktop/Scratch.sav")
>>> >>>>
>>> >>>> *#2: save the dataset with a name*
>>> >>>> save(ScratchImport, file="Scratch.Rdata")
>>> >>>>
>>> >>>> *#3: install & load necessary packages for descriptive statistics*
>>> >>>> install.packages ("freqdist")
>>> >>>> library (freqdist)
>>> >>>>
>>> >>>> install.packages ("sjlabelled")
>>> >>>> library (sjlabelled)
>>> >>>>
>>> >>>> install.packages ("labelled")
>>> >>>> library (labelled)
>>> >>>>
>>> >>>> install.packages ("surveytoolbox")
>>> >>>> library (surveytoolbox)
>>> >>>>
>>> >>>> *#4: Check the value labels of gender and marital status*
>>> >>>> Scratch$sex %>% attr('labels')
>>> >>>> Scratch$marital %>% attr('labels')
>>> >>>>
>>> >>>> *#5:  Frequency Distribution and BarChart for Categorical/Ordinal
>>> Level
>>> >>>> Variables such as Gender - SEX*
>>> >>>> freqdist(Scratch$sex)
>>> >>>> barplot(table(Scratch$marital))
>>> >>>>
>>> >>>> -----------------------------------------------------
>>> >>>>
>>> >>>> As you can see from above, I use the <haven> package to import the
>>> data
>>> >>>> from SPSS.  Apparently, the haven function keeps the value labels,
>>> as
>>> >>> the
>>> >>>> attribute options in section #4 of my script shows.
>>> >>>> The problem is that when I run frequency distribution for any of the
>>> >>>> categorical variables like sex or marital status, only the numbers
>>> (1,
>>> >>> 2,)
>>> >>>> are displayed in the output.  The labels (male, female) for example
>>> are
>>> >>>> not.
>>> >>>>
>>> >>>> Is there any way to force these to be shown in the output?  Is
>>> there a
>>> >>>> global property that I have to set so that these value labels are
>>> >>> reliably
>>> >>>> displayed with every output?  I read I can declare them as factors
>>> using
>>> >>>> the <as_factor()>, but once I do so, how do I invoke them in my
>>> >>> commands so
>>> >>>> that the value labels show...
>>> >>>>
>>> >>>> Sorry about all the noobs questions, but Ihopefully, I am able to
>>> get
>>> >>> this
>>> >>>> working.
>>> >>>>
>>> >>>> Thanks in advance.
>>> >>>>
>>> >>>>
>>> >>>> Thanks - cY
>>> >>>>
>>> >>>>
>>> >>>> On Fri, Feb 7, 2020 at 1:14 PM <cpolwart at chemo.org.uk> wrote:
>>> >>>>
>>> >>>>> I've never used it, but there is a labels function in haven...
>>> >>>>>
>>> >>>>> On 7 Feb 2020 17:05, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> >>>>>
>>> >>>>> What does your data look like after importing? -- see ?head and
>>> ?str
>>> >>> to
>>> >>>>> tell us. Show us the code that failed to provide "labels." See the
>>> >>>> posting
>>> >>>>> guide below for how to post questions that are likely to elicit
>>> >>> helpful
>>> >>>>> responses.
>>> >>>>>
>>> >>>>> I know nothing about the haven package, but see ?factor or go
>>> through
>>> >>> an
>>> >>>> R
>>> >>>>> tutorial or two to learn about factors, which may be part of the
>>> issue
>>> >>>>> here. R *generally* obtains whatever "label" info it needs from the
>>> >>>> object
>>> >>>>> being tabled -- see ?tabulate, ?table etc. -- if that's what you're
>>> >>>> doing.
>>> >>>>>
>>> >>>>> Bert Gunter
>>> >>>>>
>>> >>>>> "The trouble with having an open mind is that people keep coming
>>> along
>>> >>>> and
>>> >>>>> sticking things into it."
>>> >>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> >>>>>
>>> >>>>>
>>> >>>>> On Fri, Feb 7, 2020 at 8:28 AM Yawo Kokuvi <yawo1964 at gmail.com>
>>> >>> wrote:
>>> >>>>>
>>> >>>>>> Hello,
>>> >>>>>>
>>> >>>>>> I am just transitioning from SPSS to R.
>>> >>>>>>
>>> >>>>>> I used the haven library to import some of my spss data files to
>>> R.
>>> >>>>>>
>>> >>>>>> However, when I run procedures such as frequencies or crosstabs,
>>> >>> value
>>> >>>>>> labels for categorical variables such as gender (1=male, 2=female)
>>> >>> are
>>> >>>>> not
>>> >>>>>> shown. The same applies to many other output.
>>> >>>>>>
>>> >>>>>> I am confused.
>>> >>>>>>
>>> >>>>>> 1. Is there a global setting that I can use to force all
>>> categorical
>>> >>>>>> variables to display labels?
>>> >>>>>>
>>> >>>>>> 2. Or, are these labels to be set for each function or package?
>>> >>>>>>
>>> >>>>>> 3. How can I request the value labels for each function I run?
>>> >>>>>>
>>> >>>>>> Thanks in advance for your help..
>>> >>>>>>
>>> >>>>>> Best, Yawo
>>> >>>>>>
>>> >>>>>>          [[alternative HTML version deleted]]
>>> >>>>>>
>>> >>>>>> ______________________________________________
>>> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>>>>> PLEASE do read the posting guide
>>> >>>>>> http://www.R-project.org/posting-guide.html
>>> >>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> >>>>>>
>>> >>>>>
>>> >>>>> [[alternative HTML version deleted]]
>>> >>>>>
>>> >>>>> ______________________________________________
>>> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>>>> PLEASE do read the posting guide
>>> >>>>> http://www.R-project.org/posting-guide.html
>>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>>> >>>>>
>>> >>>>>
>>> >>>>>
>>> >>>>
>>> >>>>          [[alternative HTML version deleted]]
>>> >>>>
>>> >>>> ______________________________________________
>>> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>>> PLEASE do read the posting guide
>>> >>>> http://www.R-project.org/posting-guide.html
>>> >>>> and provide commented, minimal, self-contained, reproducible code.
>>> >>>>
>>> >>>
>>> >>>
>>> >>> --
>>> >>> John Kane
>>> >>> Kingston ON Canada
>>> >>>
>>> >>>          [[alternative HTML version deleted]]
>>> >>>
>>> >>> ______________________________________________
>>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>> PLEASE do read the posting guide
>>> >>> http://www.R-project.org/posting-guide.html
>>> >>> and provide commented, minimal, self-contained, reproducible code.
>>> >>>
>>> >>
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> John Kane
>> Kingston ON Canada
>>
>

-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From y@wo1964 @end|ng |rom gm@||@com  Sat Feb  8 16:36:25 2020
From: y@wo1964 @end|ng |rom gm@||@com (Yawo Kokuvi)
Date: Sat, 8 Feb 2020 10:36:25 -0500
Subject: [R] Value Labels: SPSS Dataset to R
In-Reply-To: <CAKZQJMDi9GX3eSjqxgZ3MRdc0Yu=qE5mk4CMtPCPE-O6eCVoEA@mail.gmail.com>
References: <CAGxFJbRXLH8FFVbQrZEXH1+ac=N81HZxcPFnpMvUf8qyWCksmA@mail.gmail.com>
 <6c895565-7f26-453a-8b45-822076bfd5c7@email.android.com>
 <CALjZK84ACUj8MmoRCjSXQvshpoCa48iVMSOgFjFMpUqF=L2GEA@mail.gmail.com>
 <CAKZQJMA9Cazf27BYK_F2SzB6zgZFrvtejH0MVHuvr-iq6Rn2hA@mail.gmail.com>
 <CAGxFJbR51AKG84PDqFSduGpiF8HecaGbQ=QU6uz629PUWKtbpQ@mail.gmail.com>
 <CALjZK84uxMe-orEKjLS_1ddxFakd5JNSjRtiBEnj7P8UroYN=Q@mail.gmail.com>
 <89c7d316-fba4-3702-3484-51a4764c3d33@sapo.pt>
 <CAKZQJMD2jq+ekAxCjqNALOZ06uDKDMJWBeJ0eu172qu-a+QLBQ@mail.gmail.com>
 <CALjZK87TyfuGEJQdpL9kLo7HLE=ezmRYtgNNp3LS97=xdJM0vA@mail.gmail.com>
 <CAKZQJMDi9GX3eSjqxgZ3MRdc0Yu=qE5mk4CMtPCPE-O6eCVoEA@mail.gmail.com>
Message-ID: <CALjZK87vettf=G-WecTufLDY63oN4jL2NC0RcB_m_vwwzso=zw@mail.gmail.com>

Thanks again - I realized after posting that sjlabelled is indirectly
referencing haven's read_sav function.  For a moment I thought you were
referring to the read.spss under the older foreign package.  But then
realized that read_sav and read_spss are equivalent. So that's clear now.

And I also realized there are so many ways to do the same thing in R - so
as part of learning, I am discovering these different ways, and knowing
when to use one over the other.

Thanks for the references - I will read further on them.

cheers, cY

On Sat, Feb 8, 2020 at 10:28 AM John Kane <jrkrideau at gmail.com> wrote:

> "use a different function (read_spss) as John has suggested to import the
> file. "
>
> No! As far as I can see sjlabelled is simply using haven"s function "
> read_sav()" to read in the data. It is just wrapped in the "read.spss()
> function.There should be no difference between read_sav(sdata.sav) and
> read_spss(sdata.sav).
>
> It just seems to keep the code simpler (more aesthetically pleasing?) if
> you do not load more packages than needed. Likewise you do not need to load
> "labels" as sjlabelledis taking care of this for you.
>
> Oh, BTW  Scratch$sex %>% attr('labels') can be replaced by something like
> get_labels(dat1) in my example. There usually are a multitude of ways to do
> the same thing in R.
>
> You might want to have a look at
> https://cran.r-project.org/web/packages/labelled/vignettes/intro_labelled.html
> and https://strengejacke.github.io/sjlabelled/articles/labelleddata.html
> for more about working with labels.
>
> On Sat, 8 Feb 2020 at 09:35, Yawo Kokuvi <yawo1964 at gmail.com> wrote:
>
>> Thanks so much for all your assistance.  I admit R's learning curve is a
>> bit steep, but I am eager to learn ... and hopefully teach with it.
>>
>> with regard to my problem, I can now see two options:  either declare
>> each categorical variable as factors, specifying the needed levels and
>> labels.
>>
>> OR
>>
>> use a different function (read_spss) as John has suggested to import the
>> file.
>>
>> I will experiment with both.
>>
>> With much appreciation, cY
>>
>> On Sat, Feb 8, 2020 at 9:25 AM John Kane <jrkrideau at gmail.com> wrote:
>>
>>> Hi Yawo Kokuvi;
>>> As an R newbie transitioning from SPSS to R expect culture shock and the
>>> possible feeling that yor brain is twisting within your skull but it is
>>> well worth.
>>>
>>> Try something like this:
>>> ##+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
>>> dat1  <- structure(list(Animal = structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0,
>>> 0), label = "Animal", labels = c(Cat = 0, Dog = 1), class =
>>> "haven_labelled"),
>>>     Training = structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), label = "Type
>>> of Training", labels = c(`Food as Reward` = 0,
>>>     `Affection as Reward` = 1), class = "haven_labelled"), Dance =
>>> structure(c(1,
>>>     1, 1, 1, 1, 1, 1, 1, 1, 1), label = "Did they dance?", labels = c(No
>>> = 0,
>>>     Yes = 1), class = "haven_labelled")), row.names = c(NA, -10L
>>> ), class = c("tbl_df", "tbl", "data.frame"))
>>>
>>>
>>> library(sjlabelled)
>>> str(dat1)
>>> get_labels(dat1)
>>> barplot(table(as_label(dat1$Dance)))
>>> ##==================================================================
>>> Your problem sees to be omitting the as_label().
>>>
>>> You do not need to load "haven"
>>> read_spss() in sjlabelled should do the trick.
>>>
>>>
>>> On Sat, 8 Feb 2020 at 05:44, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>>
>>>> Hello,
>>>>
>>>> Try
>>>>
>>>> aux_fun <- function(x){
>>>>    levels <- attr(x, "labels")
>>>>    factor(x, labels = names(levels), levels = levels)
>>>> }
>>>>
>>>> newCatsDogs <- as.data.frame(lapply(CatsDogs, aux_fun))
>>>>
>>>> str(newCatsDogs)
>>>> #'data.frame':  10 obs. of  3 variables:
>>>> # $ Animal  : Factor w/ 2 levels "Cat","Dog": 1 1 1 1 1 1 1 1 1 1
>>>> # $ Training: Factor w/ 2 levels "Food as Reward",..: 1 1 1 1 1 1 1 1 1
>>>> 1
>>>> # $ Dance   : Factor w/ 2 levels "No","Yes": 2 2 2 2 2 2 2 2 2 2
>>>>
>>>>
>>>> As for the
>>>>   - frequencies: ?table, ?tapply, ?aggregate,
>>>>   - barplots: ?barplot
>>>>
>>>> You can find lots and lots of examples online of both covering what
>>>> seems to simple use cases.
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>> ?s 06:03 de 08/02/20, Yawo Kokuvi escreveu:
>>>> > Thanks for all. Here is output from dput.  I used a different dataset
>>>> > containing categorical variables since the previous one is on a
>>>> different
>>>> > computer.
>>>> >
>>>> > In the following dataset, my interest is in getting frequencies and
>>>> > barplots for the two variables: Training and Dance, with value labels
>>>> > displayed.
>>>> >
>>>> > thanks again - cY
>>>> >
>>>> >
>>>> > =========
>>>> > dput(head(CatsDogs, n = 10))
>>>> > structure(
>>>> >    list(
>>>> >      Animal = structure(
>>>> >        c(0, 0, 0, 0, 0, 0, 0, 0, 0,
>>>> >          0),
>>>> >        label = "Animal",
>>>> >        labels = c(Cat = 0, Dog = 1),
>>>> >        class = "haven_labelled"
>>>> >      ),
>>>> >      Training = structure(
>>>> >        c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
>>>> >        label = "Type of Training",
>>>> >        labels = c(`Food as Reward` = 0,
>>>> >                   `Affection as Reward` = 1),
>>>> >        class = "haven_labelled"
>>>> >      ),
>>>> >      Dance = structure(
>>>> >        c(1,
>>>> >          1, 1, 1, 1, 1, 1, 1, 1, 1),
>>>> >        label = "Did they dance?",
>>>> >        labels = c(No = 0,
>>>> >                   Yes = 1),
>>>> >        class = "haven_labelled"
>>>> >      )
>>>> >    ),
>>>> >    row.names = c(NA,-10L),
>>>> >    class = c("tbl_df", "tbl", "data.frame")
>>>> > )
>>>> >
>>>> >
>>>> > On Fri, Feb 7, 2020 at 10:14 PM Bert Gunter <bgunter.4567 at gmail.com>
>>>> wrote:
>>>> >
>>>> >> Yes. Most attachments are stripped by the server.
>>>> >>
>>>> >> Bert Gunter
>>>> >>
>>>> >> "The trouble with having an open mind is that people keep coming
>>>> along and
>>>> >> sticking things into it."
>>>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>> >>
>>>> >>
>>>> >> On Fri, Feb 7, 2020 at 5:34 PM John Kane <jrkrideau at gmail.com>
>>>> wrote:
>>>> >>
>>>> >>> Hi,
>>>> >>> Could you upload some sample data in dput form?  Something like
>>>> >>> dput(head(Scratch, n=13)) will give us some real data to examine.
>>>> Just
>>>> >>> copy
>>>> >>> and paste the output of dput(head(Scratch, n=13))into the email.
>>>> This is
>>>> >>> the best way to ensure that R-help denizens are getting the data in
>>>> the
>>>> >>> exact format that you have.
>>>> >>>
>>>> >>> On Fri, 7 Feb 2020 at 15:32, Yawo Kokuvi <yawo1964 at gmail.com>
>>>> wrote:
>>>> >>>
>>>> >>>> Thanks for all your assistance
>>>> >>>>
>>>> >>>> Attached please is the Rdata scratch I have been using
>>>> >>>>
>>>> >>>> -----------------------------------------------------
>>>> >>>>
>>>> >>>>> head(Scratch, n=13)
>>>> >>>> # A tibble: 13 x 6
>>>> >>>>        ID           marital        sex      race    paeduc
>>>> speduc
>>>> >>>>     <dbl>         <dbl+lbl>  <dbl+lbl> <dbl+lbl> <dbl+lbl>
>>>> <dbl+lbl>
>>>> >>>>   1     1 3 [DIVORCED]      1 [MALE]   1 [WHITE]        NA
>>>> NA
>>>> >>>>   2     2 1 [MARRIED]       1 [MALE]   1 [WHITE]        NA
>>>> NA
>>>> >>>>   3     3 3 [DIVORCED]      1 [MALE]   1 [WHITE]         4
>>>> NA
>>>> >>>>   4     4 4 [SEPARATED]     1 [MALE]   1 [WHITE]        16
>>>> NA
>>>> >>>>   5     5 3 [DIVORCED]      1 [MALE]   1 [WHITE]        18
>>>> NA
>>>> >>>>   6     6 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        14
>>>> 20
>>>> >>>>   7     7 1 [MARRIED]       2 [FEMALE] 2 [BLACK]        NA
>>>> 12
>>>> >>>>   8     8 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        NA
>>>> 12
>>>> >>>>   9     9 3 [DIVORCED]      2 [FEMALE] 1 [WHITE]        11
>>>> NA
>>>> >>>> 10    10 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        16        12
>>>> >>>> 11    11 5 [NEVER MARRIED] 2 [FEMALE] 2 [BLACK]        NA        NA
>>>> >>>> 12    12 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        NA        NA
>>>> >>>> 13    13 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        16        NA
>>>> >>>>
>>>> >>>> -----------------------------------------------------
>>>> >>>>
>>>> >>>> and below is my script/command file.
>>>> >>>>
>>>> >>>> *#1: Load library and import SPSS dataset*
>>>> >>>> library(haven)
>>>> >>>> Scratch <- read_sav("~/Desktop/Scratch.sav")
>>>> >>>>
>>>> >>>> *#2: save the dataset with a name*
>>>> >>>> save(ScratchImport, file="Scratch.Rdata")
>>>> >>>>
>>>> >>>> *#3: install & load necessary packages for descriptive statistics*
>>>> >>>> install.packages ("freqdist")
>>>> >>>> library (freqdist)
>>>> >>>>
>>>> >>>> install.packages ("sjlabelled")
>>>> >>>> library (sjlabelled)
>>>> >>>>
>>>> >>>> install.packages ("labelled")
>>>> >>>> library (labelled)
>>>> >>>>
>>>> >>>> install.packages ("surveytoolbox")
>>>> >>>> library (surveytoolbox)
>>>> >>>>
>>>> >>>> *#4: Check the value labels of gender and marital status*
>>>> >>>> Scratch$sex %>% attr('labels')
>>>> >>>> Scratch$marital %>% attr('labels')
>>>> >>>>
>>>> >>>> *#5:  Frequency Distribution and BarChart for Categorical/Ordinal
>>>> Level
>>>> >>>> Variables such as Gender - SEX*
>>>> >>>> freqdist(Scratch$sex)
>>>> >>>> barplot(table(Scratch$marital))
>>>> >>>>
>>>> >>>> -----------------------------------------------------
>>>> >>>>
>>>> >>>> As you can see from above, I use the <haven> package to import the
>>>> data
>>>> >>>> from SPSS.  Apparently, the haven function keeps the value labels,
>>>> as
>>>> >>> the
>>>> >>>> attribute options in section #4 of my script shows.
>>>> >>>> The problem is that when I run frequency distribution for any of
>>>> the
>>>> >>>> categorical variables like sex or marital status, only the numbers
>>>> (1,
>>>> >>> 2,)
>>>> >>>> are displayed in the output.  The labels (male, female) for
>>>> example are
>>>> >>>> not.
>>>> >>>>
>>>> >>>> Is there any way to force these to be shown in the output?  Is
>>>> there a
>>>> >>>> global property that I have to set so that these value labels are
>>>> >>> reliably
>>>> >>>> displayed with every output?  I read I can declare them as factors
>>>> using
>>>> >>>> the <as_factor()>, but once I do so, how do I invoke them in my
>>>> >>> commands so
>>>> >>>> that the value labels show...
>>>> >>>>
>>>> >>>> Sorry about all the noobs questions, but Ihopefully, I am able to
>>>> get
>>>> >>> this
>>>> >>>> working.
>>>> >>>>
>>>> >>>> Thanks in advance.
>>>> >>>>
>>>> >>>>
>>>> >>>> Thanks - cY
>>>> >>>>
>>>> >>>>
>>>> >>>> On Fri, Feb 7, 2020 at 1:14 PM <cpolwart at chemo.org.uk> wrote:
>>>> >>>>
>>>> >>>>> I've never used it, but there is a labels function in haven...
>>>> >>>>>
>>>> >>>>> On 7 Feb 2020 17:05, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>> >>>>>
>>>> >>>>> What does your data look like after importing? -- see ?head and
>>>> ?str
>>>> >>> to
>>>> >>>>> tell us. Show us the code that failed to provide "labels." See the
>>>> >>>> posting
>>>> >>>>> guide below for how to post questions that are likely to elicit
>>>> >>> helpful
>>>> >>>>> responses.
>>>> >>>>>
>>>> >>>>> I know nothing about the haven package, but see ?factor or go
>>>> through
>>>> >>> an
>>>> >>>> R
>>>> >>>>> tutorial or two to learn about factors, which may be part of the
>>>> issue
>>>> >>>>> here. R *generally* obtains whatever "label" info it needs from
>>>> the
>>>> >>>> object
>>>> >>>>> being tabled -- see ?tabulate, ?table etc. -- if that's what
>>>> you're
>>>> >>>> doing.
>>>> >>>>>
>>>> >>>>> Bert Gunter
>>>> >>>>>
>>>> >>>>> "The trouble with having an open mind is that people keep coming
>>>> along
>>>> >>>> and
>>>> >>>>> sticking things into it."
>>>> >>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>> >>>>>
>>>> >>>>>
>>>> >>>>> On Fri, Feb 7, 2020 at 8:28 AM Yawo Kokuvi <yawo1964 at gmail.com>
>>>> >>> wrote:
>>>> >>>>>
>>>> >>>>>> Hello,
>>>> >>>>>>
>>>> >>>>>> I am just transitioning from SPSS to R.
>>>> >>>>>>
>>>> >>>>>> I used the haven library to import some of my spss data files to
>>>> R.
>>>> >>>>>>
>>>> >>>>>> However, when I run procedures such as frequencies or crosstabs,
>>>> >>> value
>>>> >>>>>> labels for categorical variables such as gender (1=male,
>>>> 2=female)
>>>> >>> are
>>>> >>>>> not
>>>> >>>>>> shown. The same applies to many other output.
>>>> >>>>>>
>>>> >>>>>> I am confused.
>>>> >>>>>>
>>>> >>>>>> 1. Is there a global setting that I can use to force all
>>>> categorical
>>>> >>>>>> variables to display labels?
>>>> >>>>>>
>>>> >>>>>> 2. Or, are these labels to be set for each function or package?
>>>> >>>>>>
>>>> >>>>>> 3. How can I request the value labels for each function I run?
>>>> >>>>>>
>>>> >>>>>> Thanks in advance for your help..
>>>> >>>>>>
>>>> >>>>>> Best, Yawo
>>>> >>>>>>
>>>> >>>>>>          [[alternative HTML version deleted]]
>>>> >>>>>>
>>>> >>>>>> ______________________________________________
>>>> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>> see
>>>> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >>>>>> PLEASE do read the posting guide
>>>> >>>>>> http://www.R-project.org/posting-guide.html
>>>> >>>>>> and provide commented, minimal, self-contained, reproducible
>>>> code.
>>>> >>>>>>
>>>> >>>>>
>>>> >>>>> [[alternative HTML version deleted]]
>>>> >>>>>
>>>> >>>>> ______________________________________________
>>>> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >>>>> PLEASE do read the posting guide
>>>> >>>>> http://www.R-project.org/posting-guide.html
>>>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> >>>>>
>>>> >>>>>
>>>> >>>>>
>>>> >>>>
>>>> >>>>          [[alternative HTML version deleted]]
>>>> >>>>
>>>> >>>> ______________________________________________
>>>> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >>>> PLEASE do read the posting guide
>>>> >>>> http://www.R-project.org/posting-guide.html
>>>> >>>> and provide commented, minimal, self-contained, reproducible code.
>>>> >>>>
>>>> >>>
>>>> >>>
>>>> >>> --
>>>> >>> John Kane
>>>> >>> Kingston ON Canada
>>>> >>>
>>>> >>>          [[alternative HTML version deleted]]
>>>> >>>
>>>> >>> ______________________________________________
>>>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >>> PLEASE do read the posting guide
>>>> >>> http://www.R-project.org/posting-guide.html
>>>> >>> and provide commented, minimal, self-contained, reproducible code.
>>>> >>>
>>>> >>
>>>> >
>>>> >       [[alternative HTML version deleted]]
>>>> >
>>>> > ______________________________________________
>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>> > PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> > and provide commented, minimal, self-contained, reproducible code.
>>>> >
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>> --
>>> John Kane
>>> Kingston ON Canada
>>>
>>
>
> --
> John Kane
> Kingston ON Canada
>

	[[alternative HTML version deleted]]


From jrkr|de@u @end|ng |rom gm@||@com  Sat Feb  8 16:38:23 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Sat, 8 Feb 2020 10:38:23 -0500
Subject: [R] Value Labels: SPSS Dataset to R
In-Reply-To: <CALjZK87vettf=G-WecTufLDY63oN4jL2NC0RcB_m_vwwzso=zw@mail.gmail.com>
References: <CAGxFJbRXLH8FFVbQrZEXH1+ac=N81HZxcPFnpMvUf8qyWCksmA@mail.gmail.com>
 <6c895565-7f26-453a-8b45-822076bfd5c7@email.android.com>
 <CALjZK84ACUj8MmoRCjSXQvshpoCa48iVMSOgFjFMpUqF=L2GEA@mail.gmail.com>
 <CAKZQJMA9Cazf27BYK_F2SzB6zgZFrvtejH0MVHuvr-iq6Rn2hA@mail.gmail.com>
 <CAGxFJbR51AKG84PDqFSduGpiF8HecaGbQ=QU6uz629PUWKtbpQ@mail.gmail.com>
 <CALjZK84uxMe-orEKjLS_1ddxFakd5JNSjRtiBEnj7P8UroYN=Q@mail.gmail.com>
 <89c7d316-fba4-3702-3484-51a4764c3d33@sapo.pt>
 <CAKZQJMD2jq+ekAxCjqNALOZ06uDKDMJWBeJ0eu172qu-a+QLBQ@mail.gmail.com>
 <CALjZK87TyfuGEJQdpL9kLo7HLE=ezmRYtgNNp3LS97=xdJM0vA@mail.gmail.com>
 <CAKZQJMDi9GX3eSjqxgZ3MRdc0Yu=qE5mk4CMtPCPE-O6eCVoEA@mail.gmail.com>
 <CALjZK87vettf=G-WecTufLDY63oN4jL2NC0RcB_m_vwwzso=zw@mail.gmail.com>
Message-ID: <CAKZQJMBHXULP3ybKDf_u_ys3aWq6cgqMN58T0AoGXHeLfh+f9g@mail.gmail.com>

Best of luck.

On Sat, 8 Feb 2020 at 10:36, Yawo Kokuvi <yawo1964 at gmail.com> wrote:

> Thanks again - I realized after posting that sjlabelled is indirectly
> referencing haven's read_sav function.  For a moment I thought you were
> referring to the read.spss under the older foreign package.  But then
> realized that read_sav and read_spss are equivalent. So that's clear now.
>
> And I also realized there are so many ways to do the same thing in R - so
> as part of learning, I am discovering these different ways, and knowing
> when to use one over the other.
>
> Thanks for the references - I will read further on them.
>
> cheers, cY
>
> On Sat, Feb 8, 2020 at 10:28 AM John Kane <jrkrideau at gmail.com> wrote:
>
>> "use a different function (read_spss) as John has suggested to import the
>> file. "
>>
>> No! As far as I can see sjlabelled is simply using haven"s function "
>> read_sav()" to read in the data. It is just wrapped in the "read.spss()
>> function.There should be no difference between read_sav(sdata.sav) and
>> read_spss(sdata.sav).
>>
>> It just seems to keep the code simpler (more aesthetically pleasing?) if
>> you do not load more packages than needed. Likewise you do not need to load
>> "labels" as sjlabelledis taking care of this for you.
>>
>> Oh, BTW  Scratch$sex %>% attr('labels') can be replaced by something like
>> get_labels(dat1) in my example. There usually are a multitude of ways to do
>> the same thing in R.
>>
>> You might want to have a look at
>> https://cran.r-project.org/web/packages/labelled/vignettes/intro_labelled.html
>> and https://strengejacke.github.io/sjlabelled/articles/labelleddata.html
>> for more about working with labels.
>>
>> On Sat, 8 Feb 2020 at 09:35, Yawo Kokuvi <yawo1964 at gmail.com> wrote:
>>
>>> Thanks so much for all your assistance.  I admit R's learning curve is a
>>> bit steep, but I am eager to learn ... and hopefully teach with it.
>>>
>>> with regard to my problem, I can now see two options:  either declare
>>> each categorical variable as factors, specifying the needed levels and
>>> labels.
>>>
>>> OR
>>>
>>> use a different function (read_spss) as John has suggested to import the
>>> file.
>>>
>>> I will experiment with both.
>>>
>>> With much appreciation, cY
>>>
>>> On Sat, Feb 8, 2020 at 9:25 AM John Kane <jrkrideau at gmail.com> wrote:
>>>
>>>> Hi Yawo Kokuvi;
>>>> As an R newbie transitioning from SPSS to R expect culture shock and
>>>> the possible feeling that yor brain is twisting within your skull but it is
>>>> well worth.
>>>>
>>>> Try something like this:
>>>> ##+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
>>>> dat1  <- structure(list(Animal = structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0,
>>>> 0), label = "Animal", labels = c(Cat = 0, Dog = 1), class =
>>>> "haven_labelled"),
>>>>     Training = structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), label = "Type
>>>> of Training", labels = c(`Food as Reward` = 0,
>>>>     `Affection as Reward` = 1), class = "haven_labelled"), Dance =
>>>> structure(c(1,
>>>>     1, 1, 1, 1, 1, 1, 1, 1, 1), label = "Did they dance?", labels =
>>>> c(No = 0,
>>>>     Yes = 1), class = "haven_labelled")), row.names = c(NA, -10L
>>>> ), class = c("tbl_df", "tbl", "data.frame"))
>>>>
>>>>
>>>> library(sjlabelled)
>>>> str(dat1)
>>>> get_labels(dat1)
>>>> barplot(table(as_label(dat1$Dance)))
>>>> ##==================================================================
>>>> Your problem sees to be omitting the as_label().
>>>>
>>>> You do not need to load "haven"
>>>> read_spss() in sjlabelled should do the trick.
>>>>
>>>>
>>>> On Sat, 8 Feb 2020 at 05:44, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>>>
>>>>> Hello,
>>>>>
>>>>> Try
>>>>>
>>>>> aux_fun <- function(x){
>>>>>    levels <- attr(x, "labels")
>>>>>    factor(x, labels = names(levels), levels = levels)
>>>>> }
>>>>>
>>>>> newCatsDogs <- as.data.frame(lapply(CatsDogs, aux_fun))
>>>>>
>>>>> str(newCatsDogs)
>>>>> #'data.frame':  10 obs. of  3 variables:
>>>>> # $ Animal  : Factor w/ 2 levels "Cat","Dog": 1 1 1 1 1 1 1 1 1 1
>>>>> # $ Training: Factor w/ 2 levels "Food as Reward",..: 1 1 1 1 1 1 1 1
>>>>> 1 1
>>>>> # $ Dance   : Factor w/ 2 levels "No","Yes": 2 2 2 2 2 2 2 2 2 2
>>>>>
>>>>>
>>>>> As for the
>>>>>   - frequencies: ?table, ?tapply, ?aggregate,
>>>>>   - barplots: ?barplot
>>>>>
>>>>> You can find lots and lots of examples online of both covering what
>>>>> seems to simple use cases.
>>>>>
>>>>> Hope this helps,
>>>>>
>>>>> Rui Barradas
>>>>>
>>>>> ?s 06:03 de 08/02/20, Yawo Kokuvi escreveu:
>>>>> > Thanks for all. Here is output from dput.  I used a different dataset
>>>>> > containing categorical variables since the previous one is on a
>>>>> different
>>>>> > computer.
>>>>> >
>>>>> > In the following dataset, my interest is in getting frequencies and
>>>>> > barplots for the two variables: Training and Dance, with value labels
>>>>> > displayed.
>>>>> >
>>>>> > thanks again - cY
>>>>> >
>>>>> >
>>>>> > =========
>>>>> > dput(head(CatsDogs, n = 10))
>>>>> > structure(
>>>>> >    list(
>>>>> >      Animal = structure(
>>>>> >        c(0, 0, 0, 0, 0, 0, 0, 0, 0,
>>>>> >          0),
>>>>> >        label = "Animal",
>>>>> >        labels = c(Cat = 0, Dog = 1),
>>>>> >        class = "haven_labelled"
>>>>> >      ),
>>>>> >      Training = structure(
>>>>> >        c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
>>>>> >        label = "Type of Training",
>>>>> >        labels = c(`Food as Reward` = 0,
>>>>> >                   `Affection as Reward` = 1),
>>>>> >        class = "haven_labelled"
>>>>> >      ),
>>>>> >      Dance = structure(
>>>>> >        c(1,
>>>>> >          1, 1, 1, 1, 1, 1, 1, 1, 1),
>>>>> >        label = "Did they dance?",
>>>>> >        labels = c(No = 0,
>>>>> >                   Yes = 1),
>>>>> >        class = "haven_labelled"
>>>>> >      )
>>>>> >    ),
>>>>> >    row.names = c(NA,-10L),
>>>>> >    class = c("tbl_df", "tbl", "data.frame")
>>>>> > )
>>>>> >
>>>>> >
>>>>> > On Fri, Feb 7, 2020 at 10:14 PM Bert Gunter <bgunter.4567 at gmail.com>
>>>>> wrote:
>>>>> >
>>>>> >> Yes. Most attachments are stripped by the server.
>>>>> >>
>>>>> >> Bert Gunter
>>>>> >>
>>>>> >> "The trouble with having an open mind is that people keep coming
>>>>> along and
>>>>> >> sticking things into it."
>>>>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>> >>
>>>>> >>
>>>>> >> On Fri, Feb 7, 2020 at 5:34 PM John Kane <jrkrideau at gmail.com>
>>>>> wrote:
>>>>> >>
>>>>> >>> Hi,
>>>>> >>> Could you upload some sample data in dput form?  Something like
>>>>> >>> dput(head(Scratch, n=13)) will give us some real data to examine.
>>>>> Just
>>>>> >>> copy
>>>>> >>> and paste the output of dput(head(Scratch, n=13))into the email.
>>>>> This is
>>>>> >>> the best way to ensure that R-help denizens are getting the data
>>>>> in the
>>>>> >>> exact format that you have.
>>>>> >>>
>>>>> >>> On Fri, 7 Feb 2020 at 15:32, Yawo Kokuvi <yawo1964 at gmail.com>
>>>>> wrote:
>>>>> >>>
>>>>> >>>> Thanks for all your assistance
>>>>> >>>>
>>>>> >>>> Attached please is the Rdata scratch I have been using
>>>>> >>>>
>>>>> >>>> -----------------------------------------------------
>>>>> >>>>
>>>>> >>>>> head(Scratch, n=13)
>>>>> >>>> # A tibble: 13 x 6
>>>>> >>>>        ID           marital        sex      race    paeduc
>>>>> speduc
>>>>> >>>>     <dbl>         <dbl+lbl>  <dbl+lbl> <dbl+lbl> <dbl+lbl>
>>>>> <dbl+lbl>
>>>>> >>>>   1     1 3 [DIVORCED]      1 [MALE]   1 [WHITE]        NA
>>>>> NA
>>>>> >>>>   2     2 1 [MARRIED]       1 [MALE]   1 [WHITE]        NA
>>>>> NA
>>>>> >>>>   3     3 3 [DIVORCED]      1 [MALE]   1 [WHITE]         4
>>>>> NA
>>>>> >>>>   4     4 4 [SEPARATED]     1 [MALE]   1 [WHITE]        16
>>>>> NA
>>>>> >>>>   5     5 3 [DIVORCED]      1 [MALE]   1 [WHITE]        18
>>>>> NA
>>>>> >>>>   6     6 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        14
>>>>> 20
>>>>> >>>>   7     7 1 [MARRIED]       2 [FEMALE] 2 [BLACK]        NA
>>>>> 12
>>>>> >>>>   8     8 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        NA
>>>>> 12
>>>>> >>>>   9     9 3 [DIVORCED]      2 [FEMALE] 1 [WHITE]        11
>>>>> NA
>>>>> >>>> 10    10 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        16
>>>>> 12
>>>>> >>>> 11    11 5 [NEVER MARRIED] 2 [FEMALE] 2 [BLACK]        NA
>>>>> NA
>>>>> >>>> 12    12 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        NA
>>>>> NA
>>>>> >>>> 13    13 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        16
>>>>> NA
>>>>> >>>>
>>>>> >>>> -----------------------------------------------------
>>>>> >>>>
>>>>> >>>> and below is my script/command file.
>>>>> >>>>
>>>>> >>>> *#1: Load library and import SPSS dataset*
>>>>> >>>> library(haven)
>>>>> >>>> Scratch <- read_sav("~/Desktop/Scratch.sav")
>>>>> >>>>
>>>>> >>>> *#2: save the dataset with a name*
>>>>> >>>> save(ScratchImport, file="Scratch.Rdata")
>>>>> >>>>
>>>>> >>>> *#3: install & load necessary packages for descriptive statistics*
>>>>> >>>> install.packages ("freqdist")
>>>>> >>>> library (freqdist)
>>>>> >>>>
>>>>> >>>> install.packages ("sjlabelled")
>>>>> >>>> library (sjlabelled)
>>>>> >>>>
>>>>> >>>> install.packages ("labelled")
>>>>> >>>> library (labelled)
>>>>> >>>>
>>>>> >>>> install.packages ("surveytoolbox")
>>>>> >>>> library (surveytoolbox)
>>>>> >>>>
>>>>> >>>> *#4: Check the value labels of gender and marital status*
>>>>> >>>> Scratch$sex %>% attr('labels')
>>>>> >>>> Scratch$marital %>% attr('labels')
>>>>> >>>>
>>>>> >>>> *#5:  Frequency Distribution and BarChart for Categorical/Ordinal
>>>>> Level
>>>>> >>>> Variables such as Gender - SEX*
>>>>> >>>> freqdist(Scratch$sex)
>>>>> >>>> barplot(table(Scratch$marital))
>>>>> >>>>
>>>>> >>>> -----------------------------------------------------
>>>>> >>>>
>>>>> >>>> As you can see from above, I use the <haven> package to import
>>>>> the data
>>>>> >>>> from SPSS.  Apparently, the haven function keeps the value
>>>>> labels, as
>>>>> >>> the
>>>>> >>>> attribute options in section #4 of my script shows.
>>>>> >>>> The problem is that when I run frequency distribution for any of
>>>>> the
>>>>> >>>> categorical variables like sex or marital status, only the
>>>>> numbers (1,
>>>>> >>> 2,)
>>>>> >>>> are displayed in the output.  The labels (male, female) for
>>>>> example are
>>>>> >>>> not.
>>>>> >>>>
>>>>> >>>> Is there any way to force these to be shown in the output?  Is
>>>>> there a
>>>>> >>>> global property that I have to set so that these value labels are
>>>>> >>> reliably
>>>>> >>>> displayed with every output?  I read I can declare them as
>>>>> factors using
>>>>> >>>> the <as_factor()>, but once I do so, how do I invoke them in my
>>>>> >>> commands so
>>>>> >>>> that the value labels show...
>>>>> >>>>
>>>>> >>>> Sorry about all the noobs questions, but Ihopefully, I am able to
>>>>> get
>>>>> >>> this
>>>>> >>>> working.
>>>>> >>>>
>>>>> >>>> Thanks in advance.
>>>>> >>>>
>>>>> >>>>
>>>>> >>>> Thanks - cY
>>>>> >>>>
>>>>> >>>>
>>>>> >>>> On Fri, Feb 7, 2020 at 1:14 PM <cpolwart at chemo.org.uk> wrote:
>>>>> >>>>
>>>>> >>>>> I've never used it, but there is a labels function in haven...
>>>>> >>>>>
>>>>> >>>>> On 7 Feb 2020 17:05, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>>> >>>>>
>>>>> >>>>> What does your data look like after importing? -- see ?head and
>>>>> ?str
>>>>> >>> to
>>>>> >>>>> tell us. Show us the code that failed to provide "labels." See
>>>>> the
>>>>> >>>> posting
>>>>> >>>>> guide below for how to post questions that are likely to elicit
>>>>> >>> helpful
>>>>> >>>>> responses.
>>>>> >>>>>
>>>>> >>>>> I know nothing about the haven package, but see ?factor or go
>>>>> through
>>>>> >>> an
>>>>> >>>> R
>>>>> >>>>> tutorial or two to learn about factors, which may be part of the
>>>>> issue
>>>>> >>>>> here. R *generally* obtains whatever "label" info it needs from
>>>>> the
>>>>> >>>> object
>>>>> >>>>> being tabled -- see ?tabulate, ?table etc. -- if that's what
>>>>> you're
>>>>> >>>> doing.
>>>>> >>>>>
>>>>> >>>>> Bert Gunter
>>>>> >>>>>
>>>>> >>>>> "The trouble with having an open mind is that people keep coming
>>>>> along
>>>>> >>>> and
>>>>> >>>>> sticking things into it."
>>>>> >>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
>>>>> )
>>>>> >>>>>
>>>>> >>>>>
>>>>> >>>>> On Fri, Feb 7, 2020 at 8:28 AM Yawo Kokuvi <yawo1964 at gmail.com>
>>>>> >>> wrote:
>>>>> >>>>>
>>>>> >>>>>> Hello,
>>>>> >>>>>>
>>>>> >>>>>> I am just transitioning from SPSS to R.
>>>>> >>>>>>
>>>>> >>>>>> I used the haven library to import some of my spss data files
>>>>> to R.
>>>>> >>>>>>
>>>>> >>>>>> However, when I run procedures such as frequencies or crosstabs,
>>>>> >>> value
>>>>> >>>>>> labels for categorical variables such as gender (1=male,
>>>>> 2=female)
>>>>> >>> are
>>>>> >>>>> not
>>>>> >>>>>> shown. The same applies to many other output.
>>>>> >>>>>>
>>>>> >>>>>> I am confused.
>>>>> >>>>>>
>>>>> >>>>>> 1. Is there a global setting that I can use to force all
>>>>> categorical
>>>>> >>>>>> variables to display labels?
>>>>> >>>>>>
>>>>> >>>>>> 2. Or, are these labels to be set for each function or package?
>>>>> >>>>>>
>>>>> >>>>>> 3. How can I request the value labels for each function I run?
>>>>> >>>>>>
>>>>> >>>>>> Thanks in advance for your help..
>>>>> >>>>>>
>>>>> >>>>>> Best, Yawo
>>>>> >>>>>>
>>>>> >>>>>>          [[alternative HTML version deleted]]
>>>>> >>>>>>
>>>>> >>>>>> ______________________________________________
>>>>> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>>> see
>>>>> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> >>>>>> PLEASE do read the posting guide
>>>>> >>>>>> http://www.R-project.org/posting-guide.html
>>>>> >>>>>> and provide commented, minimal, self-contained, reproducible
>>>>> code.
>>>>> >>>>>>
>>>>> >>>>>
>>>>> >>>>> [[alternative HTML version deleted]]
>>>>> >>>>>
>>>>> >>>>> ______________________________________________
>>>>> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>>> see
>>>>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> >>>>> PLEASE do read the posting guide
>>>>> >>>>> http://www.R-project.org/posting-guide.html
>>>>> >>>>> and provide commented, minimal, self-contained, reproducible
>>>>> code.
>>>>> >>>>>
>>>>> >>>>>
>>>>> >>>>>
>>>>> >>>>
>>>>> >>>>          [[alternative HTML version deleted]]
>>>>> >>>>
>>>>> >>>> ______________________________________________
>>>>> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> >>>> PLEASE do read the posting guide
>>>>> >>>> http://www.R-project.org/posting-guide.html
>>>>> >>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> >>>>
>>>>> >>>
>>>>> >>>
>>>>> >>> --
>>>>> >>> John Kane
>>>>> >>> Kingston ON Canada
>>>>> >>>
>>>>> >>>          [[alternative HTML version deleted]]
>>>>> >>>
>>>>> >>> ______________________________________________
>>>>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> >>> PLEASE do read the posting guide
>>>>> >>> http://www.R-project.org/posting-guide.html
>>>>> >>> and provide commented, minimal, self-contained, reproducible code.
>>>>> >>>
>>>>> >>
>>>>> >
>>>>> >       [[alternative HTML version deleted]]
>>>>> >
>>>>> > ______________________________________________
>>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> > PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> > and provide commented, minimal, self-contained, reproducible code.
>>>>> >
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>> --
>>>> John Kane
>>>> Kingston ON Canada
>>>>
>>>
>>
>> --
>> John Kane
>> Kingston ON Canada
>>
>

-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From gdem|n @end|ng |rom gm@||@com  Sat Feb  8 18:36:28 2020
From: gdem|n @end|ng |rom gm@||@com (Gregory Demin)
Date: Sat, 8 Feb 2020 20:36:28 +0300
Subject: [R] Value Labels: SPSS Dataset to R
In-Reply-To: <CALjZK87vettf=G-WecTufLDY63oN4jL2NC0RcB_m_vwwzso=zw@mail.gmail.com>
References: <CAGxFJbRXLH8FFVbQrZEXH1+ac=N81HZxcPFnpMvUf8qyWCksmA@mail.gmail.com>
 <6c895565-7f26-453a-8b45-822076bfd5c7@email.android.com>
 <CALjZK84ACUj8MmoRCjSXQvshpoCa48iVMSOgFjFMpUqF=L2GEA@mail.gmail.com>
 <CAKZQJMA9Cazf27BYK_F2SzB6zgZFrvtejH0MVHuvr-iq6Rn2hA@mail.gmail.com>
 <CAGxFJbR51AKG84PDqFSduGpiF8HecaGbQ=QU6uz629PUWKtbpQ@mail.gmail.com>
 <CALjZK84uxMe-orEKjLS_1ddxFakd5JNSjRtiBEnj7P8UroYN=Q@mail.gmail.com>
 <89c7d316-fba4-3702-3484-51a4764c3d33@sapo.pt>
 <CAKZQJMD2jq+ekAxCjqNALOZ06uDKDMJWBeJ0eu172qu-a+QLBQ@mail.gmail.com>
 <CALjZK87TyfuGEJQdpL9kLo7HLE=ezmRYtgNNp3LS97=xdJM0vA@mail.gmail.com>
 <CAKZQJMDi9GX3eSjqxgZ3MRdc0Yu=qE5mk4CMtPCPE-O6eCVoEA@mail.gmail.com>
 <CALjZK87vettf=G-WecTufLDY63oN4jL2NC0RcB_m_vwwzso=zw@mail.gmail.com>
Message-ID: <CA+j6HK9n_yMs9SVBL0q8L=bQkyY3VCxqGxuRdPaHZhibm_CObw@mail.gmail.com>

Hi,
With 'expss' package code for your task looks like this:

library(haven)
library(expss) # it is important to load expss after haven

# CatsDogs = read_spss("path_to_file")

CatsDogs = structure(
    list(
        Animal = structure(
            c(0, 0, 0, 0, 0, 0, 0, 0, 0,
              0),
            label = "Animal",
            labels = c(Cat = 0, Dog = 1),
            class = "haven_labelled"
        ),
        Training = structure(
            c(1, 0, 0, 1, 0, 1, 0, 0, 1, 0),
            label = "Type of Training",
            labels = c(`Food as Reward` = 0,
                       `Affection as Reward` = 1),
            class = "haven_labelled"
        ),
        Dance = structure(
            c(1,
              1, 0, 1, 1, 0, 1, 0, 1, 1),
            label = "Did they dance?",
            labels = c(No = 0,
                       Yes = 1),
            class = "haven_labelled"
        )
    ),
    row.names = c(NA,-10L),
    class = c("tbl_df", "tbl", "data.frame")
)

CatsDogs = add_labelled_class(CatsDogs) # set labelled class ffor
variables with labels

# frequnecies
fre(list(CatsDogs$Training, CatsDogs$Dance))
# |                  |                     | Count | Valid percent |
Percent | Responses, % | Cumulative responses, % |
# | ---------------- | ------------------- | ----- | ------------- |
------- | ------------ | ----------------------- |
# | Type of Training |      Food as Reward |     6 |            60 |
   60 |           60 |                      60 |
# |                  | Affection as Reward |     4 |            40 |
   40 |           40 |                     100 |
# |                  |              #Total |    10 |           100 |
  100 |          100 |                         |
# |                  |                <NA> |     0 |               |
    0 |              |                         |
# |  Did they dance? |                  No |     3 |            30 |
   30 |           30 |                      30 |
# |                  |                 Yes |     7 |            70 |
   70 |           70 |                     100 |
# |                  |              #Total |    10 |           100 |
  100 |          100 |                         |
# |                  |                <NA> |     0 |               |
    0 |              |                         |

# barplots
use_labels(CatsDogs, barplot(table(Training), legend.text = TRUE))
use_labels(CatsDogs, barplot(table(Dance), legend.text = TRUE))
use_labels(CatsDogs, barplot(table(Dance, Training), legend.text = TRUE))

Regards,
Gregory
??, 8 ????. 2020 ?. ? 18:36, Yawo Kokuvi <yawo1964 at gmail.com>:

>
> Thanks again - I realized after posting that sjlabelled is indirectly
> referencing haven's read_sav function.  For a moment I thought you were
> referring to the read.spss under the older foreign package.  But then
> realized that read_sav and read_spss are equivalent. So that's clear now.
>
> And I also realized there are so many ways to do the same thing in R - so
> as part of learning, I am discovering these different ways, and knowing
> when to use one over the other.
>
> Thanks for the references - I will read further on them.
>
> cheers, cY
>
> On Sat, Feb 8, 2020 at 10:28 AM John Kane <jrkrideau at gmail.com> wrote:
>
> > "use a different function (read_spss) as John has suggested to import the
> > file. "
> >
> > No! As far as I can see sjlabelled is simply using haven"s function "
> > read_sav()" to read in the data. It is just wrapped in the "read.spss()
> > function.There should be no difference between read_sav(sdata.sav) and
> > read_spss(sdata.sav).
> >
> > It just seems to keep the code simpler (more aesthetically pleasing?) if
> > you do not load more packages than needed. Likewise you do not need to load
> > "labels" as sjlabelledis taking care of this for you.
> >
> > Oh, BTW  Scratch$sex %>% attr('labels') can be replaced by something like
> > get_labels(dat1) in my example. There usually are a multitude of ways to do
> > the same thing in R.
> >
> > You might want to have a look at
> > https://cran.r-project.org/web/packages/labelled/vignettes/intro_labelled.html
> > and https://strengejacke.github.io/sjlabelled/articles/labelleddata.html
> > for more about working with labels.
> >
> > On Sat, 8 Feb 2020 at 09:35, Yawo Kokuvi <yawo1964 at gmail.com> wrote:
> >
> >> Thanks so much for all your assistance.  I admit R's learning curve is a
> >> bit steep, but I am eager to learn ... and hopefully teach with it.
> >>
> >> with regard to my problem, I can now see two options:  either declare
> >> each categorical variable as factors, specifying the needed levels and
> >> labels.
> >>
> >> OR
> >>
> >> use a different function (read_spss) as John has suggested to import the
> >> file.
> >>
> >> I will experiment with both.
> >>
> >> With much appreciation, cY
> >>
> >> On Sat, Feb 8, 2020 at 9:25 AM John Kane <jrkrideau at gmail.com> wrote:
> >>
> >>> Hi Yawo Kokuvi;
> >>> As an R newbie transitioning from SPSS to R expect culture shock and the
> >>> possible feeling that yor brain is twisting within your skull but it is
> >>> well worth.
> >>>
> >>> Try something like this:
> >>> ##+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
> >>> dat1  <- structure(list(Animal = structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0,
> >>> 0), label = "Animal", labels = c(Cat = 0, Dog = 1), class =
> >>> "haven_labelled"),
> >>>     Training = structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0), label = "Type
> >>> of Training", labels = c(`Food as Reward` = 0,
> >>>     `Affection as Reward` = 1), class = "haven_labelled"), Dance =
> >>> structure(c(1,
> >>>     1, 1, 1, 1, 1, 1, 1, 1, 1), label = "Did they dance?", labels = c(No
> >>> = 0,
> >>>     Yes = 1), class = "haven_labelled")), row.names = c(NA, -10L
> >>> ), class = c("tbl_df", "tbl", "data.frame"))
> >>>
> >>>
> >>> library(sjlabelled)
> >>> str(dat1)
> >>> get_labels(dat1)
> >>> barplot(table(as_label(dat1$Dance)))
> >>> ##==================================================================
> >>> Your problem sees to be omitting the as_label().
> >>>
> >>> You do not need to load "haven"
> >>> read_spss() in sjlabelled should do the trick.
> >>>
> >>>
> >>> On Sat, 8 Feb 2020 at 05:44, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >>>
> >>>> Hello,
> >>>>
> >>>> Try
> >>>>
> >>>> aux_fun <- function(x){
> >>>>    levels <- attr(x, "labels")
> >>>>    factor(x, labels = names(levels), levels = levels)
> >>>> }
> >>>>
> >>>> newCatsDogs <- as.data.frame(lapply(CatsDogs, aux_fun))
> >>>>
> >>>> str(newCatsDogs)
> >>>> #'data.frame':  10 obs. of  3 variables:
> >>>> # $ Animal  : Factor w/ 2 levels "Cat","Dog": 1 1 1 1 1 1 1 1 1 1
> >>>> # $ Training: Factor w/ 2 levels "Food as Reward",..: 1 1 1 1 1 1 1 1 1
> >>>> 1
> >>>> # $ Dance   : Factor w/ 2 levels "No","Yes": 2 2 2 2 2 2 2 2 2 2
> >>>>
> >>>>
> >>>> As for the
> >>>>   - frequencies: ?table, ?tapply, ?aggregate,
> >>>>   - barplots: ?barplot
> >>>>
> >>>> You can find lots and lots of examples online of both covering what
> >>>> seems to simple use cases.
> >>>>
> >>>> Hope this helps,
> >>>>
> >>>> Rui Barradas
> >>>>
> >>>> ?s 06:03 de 08/02/20, Yawo Kokuvi escreveu:
> >>>> > Thanks for all. Here is output from dput.  I used a different dataset
> >>>> > containing categorical variables since the previous one is on a
> >>>> different
> >>>> > computer.
> >>>> >
> >>>> > In the following dataset, my interest is in getting frequencies and
> >>>> > barplots for the two variables: Training and Dance, with value labels
> >>>> > displayed.
> >>>> >
> >>>> > thanks again - cY
> >>>> >
> >>>> >
> >>>> > =========
> >>>> > dput(head(CatsDogs, n = 10))
> >>>> > structure(
> >>>> >    list(
> >>>> >      Animal = structure(
> >>>> >        c(0, 0, 0, 0, 0, 0, 0, 0, 0,
> >>>> >          0),
> >>>> >        label = "Animal",
> >>>> >        labels = c(Cat = 0, Dog = 1),
> >>>> >        class = "haven_labelled"
> >>>> >      ),
> >>>> >      Training = structure(
> >>>> >        c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
> >>>> >        label = "Type of Training",
> >>>> >        labels = c(`Food as Reward` = 0,
> >>>> >                   `Affection as Reward` = 1),
> >>>> >        class = "haven_labelled"
> >>>> >      ),
> >>>> >      Dance = structure(
> >>>> >        c(1,
> >>>> >          1, 1, 1, 1, 1, 1, 1, 1, 1),
> >>>> >        label = "Did they dance?",
> >>>> >        labels = c(No = 0,
> >>>> >                   Yes = 1),
> >>>> >        class = "haven_labelled"
> >>>> >      )
> >>>> >    ),
> >>>> >    row.names = c(NA,-10L),
> >>>> >    class = c("tbl_df", "tbl", "data.frame")
> >>>> > )
> >>>> >
> >>>> >
> >>>> > On Fri, Feb 7, 2020 at 10:14 PM Bert Gunter <bgunter.4567 at gmail.com>
> >>>> wrote:
> >>>> >
> >>>> >> Yes. Most attachments are stripped by the server.
> >>>> >>
> >>>> >> Bert Gunter
> >>>> >>
> >>>> >> "The trouble with having an open mind is that people keep coming
> >>>> along and
> >>>> >> sticking things into it."
> >>>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>> >>
> >>>> >>
> >>>> >> On Fri, Feb 7, 2020 at 5:34 PM John Kane <jrkrideau at gmail.com>
> >>>> wrote:
> >>>> >>
> >>>> >>> Hi,
> >>>> >>> Could you upload some sample data in dput form?  Something like
> >>>> >>> dput(head(Scratch, n=13)) will give us some real data to examine.
> >>>> Just
> >>>> >>> copy
> >>>> >>> and paste the output of dput(head(Scratch, n=13))into the email.
> >>>> This is
> >>>> >>> the best way to ensure that R-help denizens are getting the data in
> >>>> the
> >>>> >>> exact format that you have.
> >>>> >>>
> >>>> >>> On Fri, 7 Feb 2020 at 15:32, Yawo Kokuvi <yawo1964 at gmail.com>
> >>>> wrote:
> >>>> >>>
> >>>> >>>> Thanks for all your assistance
> >>>> >>>>
> >>>> >>>> Attached please is the Rdata scratch I have been using
> >>>> >>>>
> >>>> >>>> -----------------------------------------------------
> >>>> >>>>
> >>>> >>>>> head(Scratch, n=13)
> >>>> >>>> # A tibble: 13 x 6
> >>>> >>>>        ID           marital        sex      race    paeduc
> >>>> speduc
> >>>> >>>>     <dbl>         <dbl+lbl>  <dbl+lbl> <dbl+lbl> <dbl+lbl>
> >>>> <dbl+lbl>
> >>>> >>>>   1     1 3 [DIVORCED]      1 [MALE]   1 [WHITE]        NA
> >>>> NA
> >>>> >>>>   2     2 1 [MARRIED]       1 [MALE]   1 [WHITE]        NA
> >>>> NA
> >>>> >>>>   3     3 3 [DIVORCED]      1 [MALE]   1 [WHITE]         4
> >>>> NA
> >>>> >>>>   4     4 4 [SEPARATED]     1 [MALE]   1 [WHITE]        16
> >>>> NA
> >>>> >>>>   5     5 3 [DIVORCED]      1 [MALE]   1 [WHITE]        18
> >>>> NA
> >>>> >>>>   6     6 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        14
> >>>> 20
> >>>> >>>>   7     7 1 [MARRIED]       2 [FEMALE] 2 [BLACK]        NA
> >>>> 12
> >>>> >>>>   8     8 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        NA
> >>>> 12
> >>>> >>>>   9     9 3 [DIVORCED]      2 [FEMALE] 1 [WHITE]        11
> >>>> NA
> >>>> >>>> 10    10 1 [MARRIED]       2 [FEMALE] 1 [WHITE]        16        12
> >>>> >>>> 11    11 5 [NEVER MARRIED] 2 [FEMALE] 2 [BLACK]        NA        NA
> >>>> >>>> 12    12 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        NA        NA
> >>>> >>>> 13    13 3 [DIVORCED]      2 [FEMALE] 2 [BLACK]        16        NA
> >>>> >>>>
> >>>> >>>> -----------------------------------------------------
> >>>> >>>>
> >>>> >>>> and below is my script/command file.
> >>>> >>>>
> >>>> >>>> *#1: Load library and import SPSS dataset*
> >>>> >>>> library(haven)
> >>>> >>>> Scratch <- read_sav("~/Desktop/Scratch.sav")
> >>>> >>>>
> >>>> >>>> *#2: save the dataset with a name*
> >>>> >>>> save(ScratchImport, file="Scratch.Rdata")
> >>>> >>>>
> >>>> >>>> *#3: install & load necessary packages for descriptive statistics*
> >>>> >>>> install.packages ("freqdist")
> >>>> >>>> library (freqdist)
> >>>> >>>>
> >>>> >>>> install.packages ("sjlabelled")
> >>>> >>>> library (sjlabelled)
> >>>> >>>>
> >>>> >>>> install.packages ("labelled")
> >>>> >>>> library (labelled)
> >>>> >>>>
> >>>> >>>> install.packages ("surveytoolbox")
> >>>> >>>> library (surveytoolbox)
> >>>> >>>>
> >>>> >>>> *#4: Check the value labels of gender and marital status*
> >>>> >>>> Scratch$sex %>% attr('labels')
> >>>> >>>> Scratch$marital %>% attr('labels')
> >>>> >>>>
> >>>> >>>> *#5:  Frequency Distribution and BarChart for Categorical/Ordinal
> >>>> Level
> >>>> >>>> Variables such as Gender - SEX*
> >>>> >>>> freqdist(Scratch$sex)
> >>>> >>>> barplot(table(Scratch$marital))
> >>>> >>>>
> >>>> >>>> -----------------------------------------------------
> >>>> >>>>
> >>>> >>>> As you can see from above, I use the <haven> package to import the
> >>>> data
> >>>> >>>> from SPSS.  Apparently, the haven function keeps the value labels,
> >>>> as
> >>>> >>> the
> >>>> >>>> attribute options in section #4 of my script shows.
> >>>> >>>> The problem is that when I run frequency distribution for any of
> >>>> the
> >>>> >>>> categorical variables like sex or marital status, only the numbers
> >>>> (1,
> >>>> >>> 2,)
> >>>> >>>> are displayed in the output.  The labels (male, female) for
> >>>> example are
> >>>> >>>> not.
> >>>> >>>>
> >>>> >>>> Is there any way to force these to be shown in the output?  Is
> >>>> there a
> >>>> >>>> global property that I have to set so that these value labels are
> >>>> >>> reliably
> >>>> >>>> displayed with every output?  I read I can declare them as factors
> >>>> using
> >>>> >>>> the <as_factor()>, but once I do so, how do I invoke them in my
> >>>> >>> commands so
> >>>> >>>> that the value labels show...
> >>>> >>>>
> >>>> >>>> Sorry about all the noobs questions, but Ihopefully, I am able to
> >>>> get
> >>>> >>> this
> >>>> >>>> working.
> >>>> >>>>
> >>>> >>>> Thanks in advance.
> >>>> >>>>
> >>>> >>>>
> >>>> >>>> Thanks - cY
> >>>> >>>>
> >>>> >>>>
> >>>> >>>> On Fri, Feb 7, 2020 at 1:14 PM <cpolwart at chemo.org.uk> wrote:
> >>>> >>>>
> >>>> >>>>> I've never used it, but there is a labels function in haven...
> >>>> >>>>>
> >>>> >>>>> On 7 Feb 2020 17:05, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >>>> >>>>>
> >>>> >>>>> What does your data look like after importing? -- see ?head and
> >>>> ?str
> >>>> >>> to
> >>>> >>>>> tell us. Show us the code that failed to provide "labels." See the
> >>>> >>>> posting
> >>>> >>>>> guide below for how to post questions that are likely to elicit
> >>>> >>> helpful
> >>>> >>>>> responses.
> >>>> >>>>>
> >>>> >>>>> I know nothing about the haven package, but see ?factor or go
> >>>> through
> >>>> >>> an
> >>>> >>>> R
> >>>> >>>>> tutorial or two to learn about factors, which may be part of the
> >>>> issue
> >>>> >>>>> here. R *generally* obtains whatever "label" info it needs from
> >>>> the
> >>>> >>>> object
> >>>> >>>>> being tabled -- see ?tabulate, ?table etc. -- if that's what
> >>>> you're
> >>>> >>>> doing.
> >>>> >>>>>
> >>>> >>>>> Bert Gunter
> >>>> >>>>>
> >>>> >>>>> "The trouble with having an open mind is that people keep coming
> >>>> along
> >>>> >>>> and
> >>>> >>>>> sticking things into it."
> >>>> >>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>> >>>>>
> >>>> >>>>>
> >>>> >>>>> On Fri, Feb 7, 2020 at 8:28 AM Yawo Kokuvi <yawo1964 at gmail.com>
> >>>> >>> wrote:
> >>>> >>>>>
> >>>> >>>>>> Hello,
> >>>> >>>>>>
> >>>> >>>>>> I am just transitioning from SPSS to R.
> >>>> >>>>>>
> >>>> >>>>>> I used the haven library to import some of my spss data files to
> >>>> R.
> >>>> >>>>>>
> >>>> >>>>>> However, when I run procedures such as frequencies or crosstabs,
> >>>> >>> value
> >>>> >>>>>> labels for categorical variables such as gender (1=male,
> >>>> 2=female)
> >>>> >>> are
> >>>> >>>>> not
> >>>> >>>>>> shown. The same applies to many other output.
> >>>> >>>>>>
> >>>> >>>>>> I am confused.
> >>>> >>>>>>
> >>>> >>>>>> 1. Is there a global setting that I can use to force all
> >>>> categorical
> >>>> >>>>>> variables to display labels?
> >>>> >>>>>>
> >>>> >>>>>> 2. Or, are these labels to be set for each function or package?
> >>>> >>>>>>
> >>>> >>>>>> 3. How can I request the value labels for each function I run?
> >>>> >>>>>>
> >>>> >>>>>> Thanks in advance for your help..
> >>>> >>>>>>
> >>>> >>>>>> Best, Yawo
> >>>> >>>>>>
> >>>> >>>>>>          [[alternative HTML version deleted]]
> >>>> >>>>>>
> >>>> >>>>>> ______________________________________________
> >>>> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >>>> see
> >>>> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>>>> PLEASE do read the posting guide
> >>>> >>>>>> http://www.R-project.org/posting-guide.html
> >>>> >>>>>> and provide commented, minimal, self-contained, reproducible
> >>>> code.
> >>>> >>>>>>
> >>>> >>>>>
> >>>> >>>>> [[alternative HTML version deleted]]
> >>>> >>>>>
> >>>> >>>>> ______________________________________________
> >>>> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>>> PLEASE do read the posting guide
> >>>> >>>>> http://www.R-project.org/posting-guide.html
> >>>> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>> >>>>>
> >>>> >>>>>
> >>>> >>>>>
> >>>> >>>>
> >>>> >>>>          [[alternative HTML version deleted]]
> >>>> >>>>
> >>>> >>>> ______________________________________________
> >>>> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>>> PLEASE do read the posting guide
> >>>> >>>> http://www.R-project.org/posting-guide.html
> >>>> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>> >>>>
> >>>> >>>
> >>>> >>>
> >>>> >>> --
> >>>> >>> John Kane
> >>>> >>> Kingston ON Canada
> >>>> >>>
> >>>> >>>          [[alternative HTML version deleted]]
> >>>> >>>
> >>>> >>> ______________________________________________
> >>>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> >>> PLEASE do read the posting guide
> >>>> >>> http://www.R-project.org/posting-guide.html
> >>>> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>> >>>
> >>>> >>
> >>>> >
> >>>> >       [[alternative HTML version deleted]]
> >>>> >
> >>>> > ______________________________________________
> >>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> > PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> > and provide commented, minimal, self-contained, reproducible code.
> >>>> >
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>
> >>> --
> >>> John Kane
> >>> Kingston ON Canada
> >>>
> >>
> >
> > --
> > John Kane
> > Kingston ON Canada
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From g||ted|||e2014 @end|ng |rom gm@||@com  Mon Feb 10 06:40:11 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Mon, 10 Feb 2020 06:40:11 +0100
Subject: [R] Identification of Turning Points in a Signal
Message-ID: <CAC8ss32tKdyzzGkcDqKCV2wgpFVWhgPHkicAsQq-gVEOCqZPhw@mail.gmail.com>

Dear Friends,
Wishing you the best of the day.

I have a data (Cosmic Ray) which exhibit flow patterns of a
sine/cosine wave, i.e. decreasing/increasing and registering crests
(points maximal increases) and troughs/pits (points maximal
decreases). These turning points are of interest to me. With pastecs
package and a few lines of code as (the residual is coming from
Fourier transformation of the data):
library(pastecs)
 tp<-turnpoints(data$residual)
 res<-(1:length(data$residual))[tp$pit]
 minima<-which(tp$pit & data$residual<= -100)
 dates<-data$date[minima]
 k<-data$residual[minima]
I usually pick all the turning points (trough) equal or below -100. If
I change the <= to >=, I pick all the crests.

Now, without first transforming the data, I wish to pick the same
turning points in the raw data. Indeed, the difference between the
transformed data and the raw data lies only in the amplitude of the
crest or trough, otherwise, the crests and trough are the same in both
signals.

When I tried the above code in the raw signal, the warning/error message is:
Warning message:
In tp$pit & data$residual <= -100 :
  longer object length is not a multiple of shorter object length.

A sample of the raw data is:
03 10 01 6.20636953199224
03 10 02 6.90829266565563
03 10 03 6.40434785174345
03 10 04 6.33235573547028
03 10 05 5.99039318317273
03 10 06 5.09049172975812
03 10 07 4.35257253795814
03 10 08 4.49655677050448
03 10 09 4.49655677050448
03 10 10 4.4425626832996
03 10 11 5.16248384603129
03 10 12 5.72042274714835
03 10 13 6.26036361919711
03 10 14 5.8284109215581
03 10 15 5.30646807857763
03 10 16 5.32446610764592
03 10 17 5.68442668901176
03 10 18 6.33235573547028
03 10 19 6.80030449124588
03 10 20 7.26825324702148
03 10 21 6.83630054938246
03 10 22 2.53477160206063
03 10 23 2.55276963112892
03 10 24 2.39078736951429
03 10 25 -0.48889728141246
03 10 26 -0.110938670978323
03 10 27 0.303015997592397
03 10 28 1.81485043932894
03 10 29 -8.04806949009518
03 10 30 -16.1471825708267
03 10 31 -17.0470840242413
03 11 01 -13.6094604721975
03 11 02 -8.98396700164638
03 11 03 -6.28426264140255
03 11 04 -5.78031782749036
03 11 05 -3.72854251370505
03 11 06 -2.95462726376849
03 11 07 -4.52045579270991
03 11 08 -3.54856222302213
03 11 09 -0.884853920914888
03 11 10 0.447000230138735
03 11 11 0.0150475324997218
03 11 12 -0.308916990729538
03 11 13 0.0690416197045984
03 11 14 -0.110938670978323
03 11 15 -0.938848008119764
03 11 16 -3.02661938004166
03 11 17 -3.92652083345627
03 11 18 -3.24259572886117
03 11 19 -1.67676719991974
03 11 20 -2.30669821730997
03 11 21 -2.9366292347002
03 11 22 -2.75664894401728
03 11 23 -3.44057404861238
03 11 24 -4.34047550202699
03 11 25 -3.87252674625139
03 11 26 -2.72065288588069
03 11 27 -2.25270413010509
03 11 28 -1.37080070575878
03 11 29 -0.0389465547051547
03 11 30 0.033045561568014
the first three columns are year, month and day, the last column % CR variation.

abline (h=0) specifies values below the average. I am interested in
picking the time and magnitude of all the turning points below zero.

Thank you for assisting me.
Best regards
Ogbos


From ju@n@rodr|guez @end|ng |rom cn@g@crg@eu  Mon Feb 10 14:28:04 2020
From: ju@n@rodr|guez @end|ng |rom cn@g@crg@eu (Juan Antonio Rodriguez Perez)
Date: Mon, 10 Feb 2020 13:28:04 +0000
Subject: [R] k-nearest neighbours from distance matrix in spdep
In-Reply-To: <3cbcfadfccf14c1485ad3ae0ebc700b6@cnag.crg.eu>
References: <3cbcfadfccf14c1485ad3ae0ebc700b6@cnag.crg.eu>
Message-ID: <084413e00f8d4fbd9780b287b4411613@cnag.crg.eu>

Dear all,

I got a message from the spdep package developer and suggested me to open a GitHub issue for the problem. Please follow the discussion at:


https://github.com/r-spatial/spdep/issues/38


Cheers,

J


________________________________
De: Juan Antonio Rodriguez Perez
Enviado: venres 07 febreiro 2020 17:01:25
Para: r-help at r-project.org
Asunto: k-nearest neighbours from distance matrix in spdep


Dear all,


I am using the spdep package to compute Local Moran Index.

My problem is that I am using 3D coordinates (x,y,z), and I would like to compute the k-nearest neighbours (k=10) for each point in my 3D space. I have already done this in 2D, by doing the following:


>neighs_k <- knn2nb(knearneigh(as.matrix(full),
                                        k = 10))
> neighs_mat_k <- nb2listw(neighs_k
                         style = "W",
                         zero.policy = TRUE)

And then I can easily proceed using the neighs_mat_k object.

However, when using x,y,z coordinates I can't run the knearneigh() function on it. I tried converting my data to a distance matrix and using mat2listw() function like this:

>D <- as.matrix(dist(full, diag=FALSE, upper=FALSE))
>test1 <- mat2listw(D)

...but now I don't know how to retrieve the k-nearest weights from my test1 object (which would correspond to k-nearest neighbours) without changing the class of test1, which is:

> class(test1)
[1] "listw" "nb"
## and contains...:
> ls(test1)
[1] "neighbours" "style"      "weights"


How should I do this? Is this even the right way to proceed?

Thanks all in advance!!
Best wishes,

Juan

	[[alternative HTML version deleted]]


From pth7995 @end|ng |rom gm@||@com  Sun Feb  9 11:50:59 2020
From: pth7995 @end|ng |rom gm@||@com (=?UTF-8?B?aMawxqFuZyBwaOG6oW0=?=)
Date: Sun, 9 Feb 2020 17:50:59 +0700
Subject: [R] Help to do this exercise
Message-ID: <CAH-4msw8K+T_HGWfuzc4mxupDPaB=iCZjLFD1U3hYz5bdQB5BQ@mail.gmail.com>

N1 Consider the database "LakeHuron" , containing the annual measurements
of the level (in feet) of Lake Huron 1875{1972, see
https://stat.ethz.ch/R-manual/Rdevel/library/datasets/html/LakeHuron.html.
The general aim is to estimate the probability density of the level of the
lake.
(i) Construct the histogram estimator with the number of bins selected
by the Sturges rule. On the same plot display the graph of the density of
the normal distribution with estimated mean and standard
deviation (normal fit).
(ii) Among the histograms with the number of bins from 5 to 30, find
the histogram estimator which is closest to the normal fit. Comment on the
bias-variance tradeoff in this case.
(iii) Construct the kernel estimators with various kernels (apply all
kernels available in the R language). The bandwidth can be chosen by
default. Construct the kernel estimators under various choices of
bandwidth (apply all rules for bandwidth selection, which are implemented
in the R language, the kernel can be chosen by default).
Among all constructed kernel estimators, find the kernel estimator
which is closest to the normal fit

	[[alternative HTML version deleted]]


From cry@n @end|ng |rom b|ngh@mton@edu  Mon Feb 10 15:56:25 2020
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W Ryan)
Date: Mon, 10 Feb 2020 09:56:25 -0500
Subject: [R] [External Email]  Help to do this exercise
In-Reply-To: <CAH-4msw8K+T_HGWfuzc4mxupDPaB=iCZjLFD1U3hYz5bdQB5BQ@mail.gmail.com>
References: <CAH-4msw8K+T_HGWfuzc4mxupDPaB=iCZjLFD1U3hYz5bdQB5BQ@mail.gmail.com>
Message-ID: <CAM+rpYm-gAzmtpH3wAGF=ZnZ0kcp9uNv=6-0FXTH1CeCfAd_sQ@mail.gmail.com>

Homework questions are generally frowned upon on R-help List. It is best to
discuss those questions with your instructor.

--Chris Ryan
SUNY Upstate Medical University Clinical Campus at Binghamton

On Mon, Feb 10, 2020 at 9:39 AM h??ng ph?m <pth7995 at gmail.com> wrote:

> N1 Consider the database "LakeHuron" , containing the annual measurements
> of the level (in feet) of Lake Huron 1875{1972, see
> https://stat.ethz.ch/R-manual/Rdevel/library/datasets/html/LakeHuron.html.
> The general aim is to estimate the probability density of the level of the
> lake.
> (i) Construct the histogram estimator with the number of bins selected
> by the Sturges rule. On the same plot display the graph of the density of
> the normal distribution with estimated mean and standard
> deviation (normal fit).
> (ii) Among the histograms with the number of bins from 5 to 30, find
> the histogram estimator which is closest to the normal fit. Comment on the
> bias-variance tradeoff in this case.
> (iii) Construct the kernel estimators with various kernels (apply all
> kernels available in the R language). The bandwidth can be chosen by
> default. Construct the kernel estimators under various choices of
> bandwidth (apply all rules for bandwidth selection, which are implemented
> in the R language, the kernel can be chosen by default).
> Among all constructed kernel estimators, find the kernel estimator
> which is closest to the normal fit
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Feb 10 16:23:08 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 10 Feb 2020 15:23:08 +0000
Subject: [R] Help to do this exercise
In-Reply-To: <CAH-4msw8K+T_HGWfuzc4mxupDPaB=iCZjLFD1U3hYz5bdQB5BQ@mail.gmail.com>
References: <CAH-4msw8K+T_HGWfuzc4mxupDPaB=iCZjLFD1U3hYz5bdQB5BQ@mail.gmail.com>
Message-ID: <24233127-c24a-bd86-9809-bd42eb26002f@sapo.pt>

Hello,

R-help has a no homework policy.
Please find help somewhere else,

Rui Barradas


?s 10:50 de 09/02/20, h??ng ph?m escreveu:
> N1 Consider the database "LakeHuron" , containing the annual measurements
> of the level (in feet) of Lake Huron 1875{1972, see
> https://stat.ethz.ch/R-manual/Rdevel/library/datasets/html/LakeHuron.html.
> The general aim is to estimate the probability density of the level of the
> lake.
> (i) Construct the histogram estimator with the number of bins selected
> by the Sturges rule. On the same plot display the graph of the density of
> the normal distribution with estimated mean and standard
> deviation (normal fit).
> (ii) Among the histograms with the number of bins from 5 to 30, find
> the histogram estimator which is closest to the normal fit. Comment on the
> bias-variance tradeoff in this case.
> (iii) Construct the kernel estimators with various kernels (apply all
> kernels available in the R language). The bandwidth can be chosen by
> default. Construct the kernel estimators under various choices of
> bandwidth (apply all rules for bandwidth selection, which are implemented
> in the R language, the kernel can be chosen by default).
> Among all constructed kernel estimators, find the kernel estimator
> which is closest to the normal fit
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Mon Feb 10 20:09:32 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 10 Feb 2020 13:09:32 -0600
Subject: [R] scatter plot
Message-ID: <CAF9-5jMBj648jrAs3tniOqbZxGnOBpt0E9krxMQK87hXN5_VOw@mail.gmail.com>

Hello,

I have a code like this:

mds <- (ar_diff) %>% dist() %>% cmdscale(k=3) %>% as_tibble()
mds$cols <- as.factor(c(rep("nPDR.rg",7),  rep("PDR.rg",8),  rep("NoD.rg",7)))

pdf(file = "RG.pdf")


for (dim1 in 1:2){
  for (dim2 in (dim1+1):3){
    d1 = paste0("Dim.",dim1); d2 = paste0("Dim.",dim2)
    colnames(mds)[c(dim1,dim2)] <- c(d1,d2)
    print(colnames(mds))
    print(ggscatter(mds, x = d1, y = d2, color ="cols" ,size=3
,palette=c("blue","red","green")))
  }
}
dev.off()

How do I run the same plot but excluding NoD.rg? What do I need to
change in this for loop?

> head(mds)
# A tibble: 6 x 4
   Dim.1  Dim.2   Dim.3 cols
   <dbl>  <dbl>   <dbl> <fct>
1  1.41  -0.984 -0.870  nPDR.rg
2  0.184  1.11   0.101  nPDR.rg
3  0.394 -0.159  0.0272 nPDR.rg
4 -0.490 -0.326  0.535  nPDR.rg
5  0.635 -0.112 -0.0503 nPDR.rg
6 -0.723  0.153 -0.245  nPDR.rg

> tail(mds)
# A tibble: 6 x 4
    Dim.1   Dim.2  Dim.3 cols
    <dbl>   <dbl>  <dbl> <fct>
1  0.760  -0.732   0.568 NoD.rg
2 -0.0918  0.645  -0.189 NoD.rg
3 -0.336   0.756   0.120 NoD.rg
4 -0.439  -0.557   0.556 NoD.rg
5 -1.90   -0.858  -0.949 NoD.rg
6  0.631  -0.0930  1.43  NoD.rg

Thanks
Ana


From jrkr|de@u @end|ng |rom gm@||@com  Mon Feb 10 21:03:25 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Mon, 10 Feb 2020 15:03:25 -0500
Subject: [R] scatter plot
In-Reply-To: <CAF9-5jMBj648jrAs3tniOqbZxGnOBpt0E9krxMQK87hXN5_VOw@mail.gmail.com>
References: <CAF9-5jMBj648jrAs3tniOqbZxGnOBpt0E9krxMQK87hXN5_VOw@mail.gmail.com>
Message-ID: <CAKZQJMA2Xr39DykKpd7rOGi=SrWuGTo1AVJC3iu13iXSn1q=qQ@mail.gmail.com>

I must admit that I do not understand what you are doing but can you notm
just subset the data?
Note I am using a data.frame not a tibble.  It would be helpful if you
could supply sample data in dput() forest.

library("ggpubr")
mds  <-  structure(list(Dim.1 = c(0.41, 0.184, 0.394, -0.49, 0.635, -0.723,
0.76, -0.0918, -0.336, -0.439, -1.9, 0.631), Dim.2 = c(-0.984,
1.11, -0.159, -0.326, -0.112, 0.153, -0.732, 0.645, 0.756, -0.557,
-0.858, -0.093), Dim.3 = c(-0.87, 0.101, 0.0272, 0.535, -0.0503,
-0.245, 0.568, -0.189, 0.12, 0.556, -0.949, 1.43), cols = c("nPDR.rg",
"nPDR.rg", "nPDR.rg", "nPDR.rg", "nPDR.rg", "nPDR.rg", "NoD.rg",
"NoD.rg", "NoD.rg", "NoD.rg", "NoD.rg", "NoD.rg")), class = "data.frame",
row.names = c(NA,
-12L))

mm1  <-  subset(mds, cols =="nPDR.rg")
ggscatter(mds, x = d1, y = d2, size=3, color = "red")

On Mon, 10 Feb 2020 at 14:04, Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello,
>
> I have a code like this:
>
> mds <- (ar_diff) %>% dist() %>% cmdscale(k=3) %>% as_tibble()
> mds$cols <- as.factor(c(rep("nPDR.rg",7),  rep("PDR.rg",8),
> rep("NoD.rg",7)))
>
> pdf(file = "RG.pdf")
>
>
> for (dim1 in 1:2){
>   for (dim2 in (dim1+1):3){
>     d1 = paste0("Dim.",dim1); d2 = paste0("Dim.",dim2)
>     colnames(mds)[c(dim1,dim2)] <- c(d1,d2)
>     print(colnames(mds))
>     print(ggscatter(mds, x = d1, y = d2, color ="cols" ,size=3
> ,palette=c("blue","red","green")))
>   }
> }
> dev.off()
>
> How do I run the same plot but excluding NoD.rg? What do I need to
> change in this for loop?
>
> > head(mds)
> # A tibble: 6 x 4
>    Dim.1  Dim.2   Dim.3 cols
>    <dbl>  <dbl>   <dbl> <fct>
> 1  1.41  -0.984 -0.870  nPDR.rg
> 2  0.184  1.11   0.101  nPDR.rg
> 3  0.394 -0.159  0.0272 nPDR.rg
> 4 -0.490 -0.326  0.535  nPDR.rg
> 5  0.635 -0.112 -0.0503 nPDR.rg
> 6 -0.723  0.153 -0.245  nPDR.rg
>
> > tail(mds)
> # A tibble: 6 x 4
>     Dim.1   Dim.2  Dim.3 cols
>     <dbl>   <dbl>  <dbl> <fct>
> 1  0.760  -0.732   0.568 NoD.rg
> 2 -0.0918  0.645  -0.189 NoD.rg
> 3 -0.336   0.756   0.120 NoD.rg
> 4 -0.439  -0.557   0.556 NoD.rg
> 5 -1.90   -0.858  -0.949 NoD.rg
> 6  0.631  -0.0930  1.43  NoD.rg
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Mon Feb 10 21:18:01 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 10 Feb 2020 14:18:01 -0600
Subject: [R] scatter plot
In-Reply-To: <CAKZQJMA2Xr39DykKpd7rOGi=SrWuGTo1AVJC3iu13iXSn1q=qQ@mail.gmail.com>
References: <CAF9-5jMBj648jrAs3tniOqbZxGnOBpt0E9krxMQK87hXN5_VOw@mail.gmail.com>
 <CAKZQJMA2Xr39DykKpd7rOGi=SrWuGTo1AVJC3iu13iXSn1q=qQ@mail.gmail.com>
Message-ID: <CAF9-5jOnbvveyVuik8tVLJ0N06K5B8FY3K_i-68LzFvwb-31pw@mail.gmail.com>

Hi,

Thanks for getting back to me. I need to have there two groups:

"nPDR.rg  and "PDR.rg"

can you please let me know how my loop would look like just with those
two groups?

Thanks
Ana

On Mon, Feb 10, 2020 at 2:03 PM John Kane <jrkrideau at gmail.com> wrote:
>
> I must admit that I do not understand what you are doing but can you notm just subset the data?
> Note I am using a data.frame not a tibble.  It would be helpful if you could supply sample data in dput() forest.
>
> library("ggpubr")
> mds  <-  structure(list(Dim.1 = c(0.41, 0.184, 0.394, -0.49, 0.635, -0.723,
> 0.76, -0.0918, -0.336, -0.439, -1.9, 0.631), Dim.2 = c(-0.984,
> 1.11, -0.159, -0.326, -0.112, 0.153, -0.732, 0.645, 0.756, -0.557,
> -0.858, -0.093), Dim.3 = c(-0.87, 0.101, 0.0272, 0.535, -0.0503,
> -0.245, 0.568, -0.189, 0.12, 0.556, -0.949, 1.43), cols = c("nPDR.rg",
> "nPDR.rg", "nPDR.rg", "nPDR.rg", "nPDR.rg", "nPDR.rg", "NoD.rg",
> "NoD.rg", "NoD.rg", "NoD.rg", "NoD.rg", "NoD.rg")), class = "data.frame", row.names = c(NA,
> -12L))
>
> mm1  <-  subset(mds, cols =="nPDR.rg")
> ggscatter(mds, x = d1, y = d2, size=3, color = "red")
>
> On Mon, 10 Feb 2020 at 14:04, Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>
>> Hello,
>>
>> I have a code like this:
>>
>> mds <- (ar_diff) %>% dist() %>% cmdscale(k=3) %>% as_tibble()
>> mds$cols <- as.factor(c(rep("nPDR.rg",7),  rep("PDR.rg",8),  rep("NoD.rg",7)))
>>
>> pdf(file = "RG.pdf")
>>
>>
>> for (dim1 in 1:2){
>>   for (dim2 in (dim1+1):3){
>>     d1 = paste0("Dim.",dim1); d2 = paste0("Dim.",dim2)
>>     colnames(mds)[c(dim1,dim2)] <- c(d1,d2)
>>     print(colnames(mds))
>>     print(ggscatter(mds, x = d1, y = d2, color ="cols" ,size=3
>> ,palette=c("blue","red","green")))
>>   }
>> }
>> dev.off()
>>
>> How do I run the same plot but excluding NoD.rg? What do I need to
>> change in this for loop?
>>
>> > head(mds)
>> # A tibble: 6 x 4
>>    Dim.1  Dim.2   Dim.3 cols
>>    <dbl>  <dbl>   <dbl> <fct>
>> 1  1.41  -0.984 -0.870  nPDR.rg
>> 2  0.184  1.11   0.101  nPDR.rg
>> 3  0.394 -0.159  0.0272 nPDR.rg
>> 4 -0.490 -0.326  0.535  nPDR.rg
>> 5  0.635 -0.112 -0.0503 nPDR.rg
>> 6 -0.723  0.153 -0.245  nPDR.rg
>>
>> > tail(mds)
>> # A tibble: 6 x 4
>>     Dim.1   Dim.2  Dim.3 cols
>>     <dbl>   <dbl>  <dbl> <fct>
>> 1  0.760  -0.732   0.568 NoD.rg
>> 2 -0.0918  0.645  -0.189 NoD.rg
>> 3 -0.336   0.756   0.120 NoD.rg
>> 4 -0.439  -0.557   0.556 NoD.rg
>> 5 -1.90   -0.858  -0.949 NoD.rg
>> 6  0.631  -0.0930  1.43  NoD.rg
>>
>> Thanks
>> Ana
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> John Kane
> Kingston ON Canada


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Feb 10 23:54:45 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 10 Feb 2020 22:54:45 +0000
Subject: [R] scatter plot
In-Reply-To: <CAF9-5jMBj648jrAs3tniOqbZxGnOBpt0E9krxMQK87hXN5_VOw@mail.gmail.com>
References: <CAF9-5jMBj648jrAs3tniOqbZxGnOBpt0E9krxMQK87hXN5_VOw@mail.gmail.com>
Message-ID: <69dba5b3-d1ba-2ea6-369c-b33113e022c2@sapo.pt>

Hello,

In the loop, try filtering out the values you do not want.

Any of

print(ggscatter(mds %>% dplyr::filter(cols != "NoD.rg"), etc))

print(ggscatter(subset(mds, cols != "NoD.rg"), etc))

tmp <- mds %>% filter(cols != "NoD.rg")
print(ggscatter(tmp, etc))


The first two will create a temporary df, the 3rd a permanent one. 
Remove it after the loop:

rm(tmp)


Hope this helps,

Rui Barradas


?s 19:09 de 10/02/20, Ana Marija escreveu:
> Hello,
> 
> I have a code like this:
> 
> mds <- (ar_diff) %>% dist() %>% cmdscale(k=3) %>% as_tibble()
> mds$cols <- as.factor(c(rep("nPDR.rg",7),  rep("PDR.rg",8),  rep("NoD.rg",7)))
> 
> pdf(file = "RG.pdf")
> 
> 
> for (dim1 in 1:2){
>    for (dim2 in (dim1+1):3){
>      d1 = paste0("Dim.",dim1); d2 = paste0("Dim.",dim2)
>      colnames(mds)[c(dim1,dim2)] <- c(d1,d2)
>      print(colnames(mds))
>      print(ggscatter(mds, x = d1, y = d2, color ="cols" ,size=3
> ,palette=c("blue","red","green")))
>    }
> }
> dev.off()
> 
> How do I run the same plot but excluding NoD.rg? What do I need to
> change in this for loop?
> 
>> head(mds)
> # A tibble: 6 x 4
>     Dim.1  Dim.2   Dim.3 cols
>     <dbl>  <dbl>   <dbl> <fct>
> 1  1.41  -0.984 -0.870  nPDR.rg
> 2  0.184  1.11   0.101  nPDR.rg
> 3  0.394 -0.159  0.0272 nPDR.rg
> 4 -0.490 -0.326  0.535  nPDR.rg
> 5  0.635 -0.112 -0.0503 nPDR.rg
> 6 -0.723  0.153 -0.245  nPDR.rg
> 
>> tail(mds)
> # A tibble: 6 x 4
>      Dim.1   Dim.2  Dim.3 cols
>      <dbl>   <dbl>  <dbl> <fct>
> 1  0.760  -0.732   0.568 NoD.rg
> 2 -0.0918  0.645  -0.189 NoD.rg
> 3 -0.336   0.756   0.120 NoD.rg
> 4 -0.439  -0.557   0.556 NoD.rg
> 5 -1.90   -0.858  -0.949 NoD.rg
> 6  0.631  -0.0930  1.43  NoD.rg
> 
> Thanks
> Ana
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkr|de@u @end|ng |rom gm@||@com  Tue Feb 11 00:04:01 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Mon, 10 Feb 2020 18:04:01 -0500
Subject: [R] scatter plot
In-Reply-To: <CAF9-5jOnbvveyVuik8tVLJ0N06K5B8FY3K_i-68LzFvwb-31pw@mail.gmail.com>
References: <CAF9-5jMBj648jrAs3tniOqbZxGnOBpt0E9krxMQK87hXN5_VOw@mail.gmail.com>
 <CAKZQJMA2Xr39DykKpd7rOGi=SrWuGTo1AVJC3iu13iXSn1q=qQ@mail.gmail.com>
 <CAF9-5jOnbvveyVuik8tVLJ0N06K5B8FY3K_i-68LzFvwb-31pw@mail.gmail.com>
Message-ID: <CAKZQJMAvkkCB4YpTdDKn8LuKdjfK7isrZjJyHjFfj9VrOHCydw@mail.gmail.com>

In line

On Mon, 10 Feb 2020 at 15:12, Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hi,
>
> Thanks for getting back to me. I need to have there two groups:
>
> "nPDR.rg  and "PDR.rg"
>

Your sample data only contains NoD.rg &  nPDR.rg.  To start with, I think
we need some representative data supplied in dput format just as I supplied
an "mds" dataset.  If I understand your mds$col statement correctly there
is only 22 rows of data. Just issue the command "dput(mds) and copy the
output into your e-mail. This will allow R-help readers to use the exact
same data set that you have on your computer.

>
> can you please let me know how my loop would look like just with those
> two groups
>

Well no I cannot  because I am still trying ta figure out where "d1 and d2
came from or why you need that loop. It looks like you are renaming the
columns in "mbs" three times but why? And why do it in a loop?

If all that you are doing is renaming the columns from the "ar_diff" data
set names just do it once,
colnames(mds)  <-  c("Dim.1", Dim.2, Dim.3) before you even create the
"cols" column.

We really need to see the data.

I have never used library("ggpubr") and I cannot see why cols is appearing
in the legend---well it does with my data set. Actually, given my version
of the data set I don't see why it it printing the graph.


Also do you really want all three grcaphs in one .pdf file?



> Thanks
> Ana
>
>










> On Mon, Feb 10, 2020 at 2:03 PM John Kane <jrkrideau at gmail.com> wrote:
> >
> > I must admit that I do not understand what you are doing but can you
> notm just subset the data?
> > Note I am using a data.frame not a tibble.  It would be helpful if you
> could supply sample data in dput() forest.
> >
> > library("ggpubr")
> > mds  <-  structure(list(Dim.1 = c(0.41, 0.184, 0.394, -0.49, 0.635,
> -0.723,
> > 0.76, -0.0918, -0.336, -0.439, -1.9, 0.631), Dim.2 = c(-0.984,
> > 1.11, -0.159, -0.326, -0.112, 0.153, -0.732, 0.645, 0.756, -0.557,
> > -0.858, -0.093), Dim.3 = c(-0.87, 0.101, 0.0272, 0.535, -0.0503,
> > -0.245, 0.568, -0.189, 0.12, 0.556, -0.949, 1.43), cols = c("nPDR.rg",
> > "nPDR.rg", "nPDR.rg", "nPDR.rg", "nPDR.rg", "nPDR.rg", "NoD.rg",
> > "NoD.rg", "NoD.rg", "NoD.rg", "NoD.rg", "NoD.rg")), class =
> "data.frame", row.names = c(NA,
> > -12L))
> >
> > mm1  <-  subset(mds, cols =="nPDR.rg")
> > ggscatter(mds, x = d1, y = d2, size=3, color = "red")
> >
> > On Mon, 10 Feb 2020 at 14:04, Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
> >>
> >> Hello,
> >>
> >> I have a code like this:
> >>
> >> mds <- (ar_diff) %>% dist() %>% cmdscale(k=3) %>% as_tibble()
> >> mds$cols <- as.factor(c(rep("nPDR.rg",7),  rep("PDR.rg",8),
> rep("NoD.rg",7)))
> >>
> >> pdf(file = "RG.pdf")
> >>
> >>
> >> for (dim1 in 1:2){
> >>   for (dim2 in (dim1+1):3){
> >>     d1 = paste0("Dim.",dim1); d2 = paste0("Dim.",dim2)
> >>     colnames(mds)[c(dim1,dim2)] <- c(d1,d2)
> >>     print(colnames(mds))
> >>     print(ggscatter(mds, x = d1, y = d2, color ="cols" ,size=3
> >> ,palette=c("blue","red","green")))
> >>   }
> >> }
> >> dev.off()
> >>
> >> How do I run the same plot but excluding NoD.rg? What do I need to
> >> change in this for loop?
> >>
> >> > head(mds)
> >> # A tibble: 6 x 4
> >>    Dim.1  Dim.2   Dim.3 cols
> >>    <dbl>  <dbl>   <dbl> <fct>
> >> 1  1.41  -0.984 -0.870  nPDR.rg
> >> 2  0.184  1.11   0.101  nPDR.rg
> >> 3  0.394 -0.159  0.0272 nPDR.rg
> >> 4 -0.490 -0.326  0.535  nPDR.rg
> >> 5  0.635 -0.112 -0.0503 nPDR.rg
> >> 6 -0.723  0.153 -0.245  nPDR.rg
> >>
> >> > tail(mds)
> >> # A tibble: 6 x 4
> >>     Dim.1   Dim.2  Dim.3 cols
> >>     <dbl>   <dbl>  <dbl> <fct>
> >> 1  0.760  -0.732   0.568 NoD.rg
> >> 2 -0.0918  0.645  -0.189 NoD.rg
> >> 3 -0.336   0.756   0.120 NoD.rg
> >> 4 -0.439  -0.557   0.556 NoD.rg
> >> 5 -1.90   -0.858  -0.949 NoD.rg
> >> 6  0.631  -0.0930  1.43  NoD.rg
> >>
> >> Thanks
> >> Ana
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > John Kane
> > Kingston ON Canada
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From A@dertechLLC m@iii@g oii proto@m@ii@com  Tue Feb 11 03:33:45 2020
From: A@dertechLLC m@iii@g oii proto@m@ii@com (A@dertechLLC m@iii@g oii proto@m@ii@com)
Date: Tue, 11 Feb 2020 02:33:45 +0000
Subject: [R] Survey package/svyby source code help
Message-ID: <XObKamlWaKR_yl3kNVFAuPGCB-L4VbJL6MxMvDInvmzyJPEA7KKAZ0v_H2HHIO3ajNqQsyW-iJlwMDbRN59DOUDUTjqzo6JYe4QTL3cO1a4=@protonmail.com>

Good day,

I was looking for some help with understanding a particular portion of the svyby source code.
When debugging the code I am not following the generation of values in the results object attr(*, "var")" after line 57 completes.
These values are fed into line 74 (rval <- t(sapply(results, unwrap))).
Alternatively I invite explanation of how the SE values are created in the rval object on line 74.

the data entering svyby is from a svydesign.default object.

I am especially confused by the syntax in 57 - 59, which is not the primary question, but would appreciate any input.

I am new to R and this mailing list and do apologize for committing faux-pas.

Thanks in advance.
	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Feb 11 15:42:12 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 11 Feb 2020 17:42:12 +0300
Subject: [R] Survey package/svyby source code help
In-Reply-To: <XObKamlWaKR_yl3kNVFAuPGCB-L4VbJL6MxMvDInvmzyJPEA7KKAZ0v_H2HHIO3ajNqQsyW-iJlwMDbRN59DOUDUTjqzo6JYe4QTL3cO1a4=@protonmail.com>
References: <XObKamlWaKR_yl3kNVFAuPGCB-L4VbJL6MxMvDInvmzyJPEA7KKAZ0v_H2HHIO3ajNqQsyW-iJlwMDbRN59DOUDUTjqzo6JYe4QTL3cO1a4=@protonmail.com>
Message-ID: <20200211174212.1620533a@trisector>

On Tue, 11 Feb 2020 02:33:45 +0000
AndertechLLC--- via R-help <r-help at r-project.org> wrote:

> When debugging the code I am not following the generation of values
> in the results object attr(*, "var")" after line 57 completes. These
> values are fed into line 74 (rval <- t(sapply(results, unwrap))).

Which version of the survey package you have in mind? I took a look at
the latest version available on CRAN (3.37 at the time of this post,
[*]) and the R/surveyby.R file has somewhat different code on lines 57
and 74.

In particular, attr(*, "var") is assigned much later, from variable
named covmat.mat, which is also computed later than line 74.

-- 
Best regards,
Ivan

[*] https://cran.r-project.org/src/contrib/survey_3.37.tar.gz


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Feb 11 17:07:59 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 11 Feb 2020 19:07:59 +0300
Subject: [R] Survey package/svyby source code help
In-Reply-To: <Xz56Je2vm9GJaH2gbCfHllY3DPBRLTK2Zyv0Wppxk6v3NldjUagGIL31BZecx0S8m9a33MhgoPqLqKxd80MuowDVUQtM_oU5OSP08MeJ1nU=@protonmail.com>
References: <XObKamlWaKR_yl3kNVFAuPGCB-L4VbJL6MxMvDInvmzyJPEA7KKAZ0v_H2HHIO3ajNqQsyW-iJlwMDbRN59DOUDUTjqzo6JYe4QTL3cO1a4=@protonmail.com>
 <20200211174212.1620533a@trisector>
 <Xz56Je2vm9GJaH2gbCfHllY3DPBRLTK2Zyv0Wppxk6v3NldjUagGIL31BZecx0S8m9a33MhgoPqLqKxd80MuowDVUQtM_oU5OSP08MeJ1nU=@protonmail.com>
Message-ID: <20200211190759.5c58f4aa@trisector>

On Tue, 11 Feb 2020 15:23:14 +0000
AndertechLLC at protonmail.com wrote:

> The attr(, "var") that I am interested in is displayed with
> str(results) after the results object is declared.  First line of the
> subject code looks like:
> 
> results <- (if (multicore) parallel::mcapply else lapply)(uniques,
> function(i){....

'if' returns whatever the taken branch returns (it is documented
in ?'if', section "Value").

The rest of the statement applies the function FUN (passed as argument
to svyby) to the data (passed as `formula` argument), so the "var"
attribute you are looking for in fact comes from the FUN invocation and
not from svyby itself. Most examples from ?svyby use FUN=svymean, so
perhaps this is where you should be going next. Make sure to check out
R-Intro [*] to avoid common pitfalls when working with methods in R.

-- 
Best regards,
Ivan

[*]
https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Object-orientation


From A@dertechLLC m@iii@g oii proto@m@ii@com  Tue Feb 11 16:23:14 2020
From: A@dertechLLC m@iii@g oii proto@m@ii@com (A@dertechLLC m@iii@g oii proto@m@ii@com)
Date: Tue, 11 Feb 2020 15:23:14 +0000
Subject: [R] Survey package/svyby source code help
In-Reply-To: <20200211174212.1620533a@trisector>
References: <XObKamlWaKR_yl3kNVFAuPGCB-L4VbJL6MxMvDInvmzyJPEA7KKAZ0v_H2HHIO3ajNqQsyW-iJlwMDbRN59DOUDUTjqzo6JYe4QTL3cO1a4=@protonmail.com>
 <20200211174212.1620533a@trisector>
Message-ID: <Xz56Je2vm9GJaH2gbCfHllY3DPBRLTK2Zyv0Wppxk6v3NldjUagGIL31BZecx0S8m9a33MhgoPqLqKxd80MuowDVUQtM_oU5OSP08MeJ1nU=@protonmail.com>


Thank you for responding.
I am truly grateful.
Apologies for omitting evident and pertinent information.

I am using 3.36.  I will update to 3.37.  I did not notice the newer version.

I realize I needed to be more specific.  The attr(, "var") that I am interested in is displayed with str(results) after the results object is declared.  First line of the subject code looks like:

results <- (if (multicore) parallel::mcapply else lapply)(uniques, function(i){....

How that line functions without error is beyond me, but minor to my objective.

Disclosing my prime goal, I am trying to produce the same values generated by the confint function, which receives the standard error values from this svyby function.  I am trying to replicate the standard error calculation in R and use it in a known program called Tableau.

If any other information is needed please let me know.

My sincerest gratitude.





??????? Original Message ???????
On Tuesday, February 11, 2020 9:42 AM, Ivan Krylov <krylov.r00t at gmail.com> wrote:

> On Tue, 11 Feb 2020 02:33:45 +0000
> AndertechLLC--- via R-help r-help at r-project.org wrote:
>
> > When debugging the code I am not following the generation of values
> > in the results object attr(*, "var")" after line 57 completes. These
> > values are fed into line 74 (rval <- t(sapply(results, unwrap))).
>
> Which version of the survey package you have in mind? I took a look at
> the latest version available on CRAN (3.37 at the time of this post,
> []) and the R/surveyby.R file has somewhat different code on lines 57
> and 74.
> In particular, attr(, "var") is assigned much later, from variablenamed covmat.mat, which is also computed later than line 74.
>
> -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>
> Best regards,
> Ivan
>
> [*] https://cran.r-project.org/src/contrib/survey_3.37.tar.gz


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Feb 11 21:12:30 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 11 Feb 2020 14:12:30 -0600
Subject: [R] how to create density plot in R with p value
In-Reply-To: <CAF9-5jN=kT1ixNx0cRdfmnOokwn0hjsqoSDX8y6pSmjN5OG8Mg@mail.gmail.com>
References: <CAF9-5jN=kT1ixNx0cRdfmnOokwn0hjsqoSDX8y6pSmjN5OG8Mg@mail.gmail.com>
Message-ID: <CAF9-5jOHAiThNhUSOXwCORejc5gN8ubmTQEgxBRnbaFjU1SbtA@mail.gmail.com>

so I transformed my data from the previous email to look like this:

> head(tot)
     dat                      type
1 -3.962 inter.individual.variance
2 -4.301 inter.individual.variance
3 -1.690 inter.individual.variance
4 -0.375 inter.individual.variance
5  1.816 inter.individual.variance
6  0.138 inter.individual.variance
> tail(tot)
        dat                      type
31177 -4.09 intra.individual.variance
31178 -4.64 intra.individual.variance
31179 -5.57 intra.individual.variance
31180 -2.96 intra.individual.variance
31181 -4.43 intra.individual.variance
31182 -3.60 intra.individual.variance

then I can make plot using this:

densityplot(~dat,data=tot,
       groups=type,
       par.settings = list(superpose.line = list(col = c("blue","red"))),
       xlab="log2 (variance)",
       plot.points=FALSE,
       auto.key=TRUE)

and calculate my p value with t test, say it is 0.005

But how to add that p value in between distribution of the curves?

Thanks
Ana

On Tue, Feb 11, 2020 at 12:54 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi,
>
> I have data like this:
>
> > head(a)
>                    X   geneID inter.individual.variance
> intra.individual.variance F.value  p.value     CV
> 1 3iUZ.47hLFki49VR4o   MLLT10                    0.0642
>    0.01395    4.60 1.00e-05 0.0222
> 2 fEn1QlU0MCVe9GeR64 C1orf123                    0.0507
>    0.00671    7.57 1.00e-08 0.0172
> 3 ud_tTlU5LtB478JxIk    FSD1L                    0.3100
>    0.02682   11.56 1.00e-11 0.0639
> 4 3KV3OJIIRuJ5KJ6VkI  TXNDC11                    0.7710
>    0.02813   27.41 9.99e-19 0.0688
> 5 o_rupcEAKnQqnoh6ec   CYB5R2                    3.5209
>    0.03391  103.83 9.99e-31 0.1357
> 6 Nk_t6ULcQ7VDNChBRU     GBP1                    1.1005
>    0.09522   11.56 9.98e-12 0.0773
>
> I would like to create density plot, like the attached between
> "inter.individual.variance" and "intra.individual.variance" and have p
> value between those two curves.
>
> Please advise,
> Ana


From jrkr|de@u @end|ng |rom gm@||@com  Tue Feb 11 22:11:49 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Tue, 11 Feb 2020 16:11:49 -0500
Subject: [R] how to create density plot in R with p value
In-Reply-To: <CAF9-5jOHAiThNhUSOXwCORejc5gN8ubmTQEgxBRnbaFjU1SbtA@mail.gmail.com>
References: <CAF9-5jN=kT1ixNx0cRdfmnOokwn0hjsqoSDX8y6pSmjN5OG8Mg@mail.gmail.com>
 <CAF9-5jOHAiThNhUSOXwCORejc5gN8ubmTQEgxBRnbaFjU1SbtA@mail.gmail.com>
Message-ID: <CAKZQJMAHcP9pDYyggLhhe3Sfom7jwQUHCUZwL4ZGN8h38z-n8Q@mail.gmail.com>

Please supply sample data in dput() format See ?dput.

You might find these links helpful.

 http://adv-r.had.co.nz/Reproducibility.html

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example



On Tue, 11 Feb 2020 at 15:07, Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> so I transformed my data from the previous email to look like this:
>
> > head(tot)
>      dat                      type
> 1 -3.962 inter.individual.variance
> 2 -4.301 inter.individual.variance
> 3 -1.690 inter.individual.variance
> 4 -0.375 inter.individual.variance
> 5  1.816 inter.individual.variance
> 6  0.138 inter.individual.variance
> > tail(tot)
>         dat                      type
> 31177 -4.09 intra.individual.variance
> 31178 -4.64 intra.individual.variance
> 31179 -5.57 intra.individual.variance
> 31180 -2.96 intra.individual.variance
> 31181 -4.43 intra.individual.variance
> 31182 -3.60 intra.individual.variance
>
> then I can make plot using this:
>
> densityplot(~dat,data=tot,
>        groups=type,
>        par.settings = list(superpose.line = list(col = c("blue","red"))),
>        xlab="log2 (variance)",
>        plot.points=FALSE,
>        auto.key=TRUE)
>
> and calculate my p value with t test, say it is 0.005
>
> But how to add that p value in between distribution of the curves?
>
> Thanks
> Ana
>
> On Tue, Feb 11, 2020 at 12:54 PM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
> >
> > Hi,
> >
> > I have data like this:
> >
> > > head(a)
> >                    X   geneID inter.individual.variance
> > intra.individual.variance F.value  p.value     CV
> > 1 3iUZ.47hLFki49VR4o   MLLT10                    0.0642
> >    0.01395    4.60 1.00e-05 0.0222
> > 2 fEn1QlU0MCVe9GeR64 C1orf123                    0.0507
> >    0.00671    7.57 1.00e-08 0.0172
> > 3 ud_tTlU5LtB478JxIk    FSD1L                    0.3100
> >    0.02682   11.56 1.00e-11 0.0639
> > 4 3KV3OJIIRuJ5KJ6VkI  TXNDC11                    0.7710
> >    0.02813   27.41 9.99e-19 0.0688
> > 5 o_rupcEAKnQqnoh6ec   CYB5R2                    3.5209
> >    0.03391  103.83 9.99e-31 0.1357
> > 6 Nk_t6ULcQ7VDNChBRU     GBP1                    1.1005
> >    0.09522   11.56 9.98e-12 0.0773
> >
> > I would like to create density plot, like the attached between
> > "inter.individual.variance" and "intra.individual.variance" and have p
> > value between those two curves.
> >
> > Please advise,
> > Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Feb 11 22:23:37 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 12 Feb 2020 08:23:37 +1100
Subject: [R] how to create density plot in R with p value
In-Reply-To: <CAF9-5jOHAiThNhUSOXwCORejc5gN8ubmTQEgxBRnbaFjU1SbtA@mail.gmail.com>
References: <CAF9-5jN=kT1ixNx0cRdfmnOokwn0hjsqoSDX8y6pSmjN5OG8Mg@mail.gmail.com>
 <CAF9-5jOHAiThNhUSOXwCORejc5gN8ubmTQEgxBRnbaFjU1SbtA@mail.gmail.com>
Message-ID: <CA+8X3fUnXc52=ZAzgYEdwR4h3kYzBF7uEXttPL6sAH2RRBK_=Q@mail.gmail.com>

Hi Ana,
Your image didn't make it through (as usual). Try PNG or PDF format.

Assumptions
1) You want to plot two lines using the _paired_ values of inter- and
intra-individual variance.
2) The cases are in the same order in your data
3) You want to identify the two lines
4) You want to place text with some p-value between the lines

This is really (and suspiciously) simple. Here's a start:

tot<-read.table(text="dat type
 -3.962 inter.individual.variance
 -4.301 inter.individual.variance
 -1.690 inter.individual.variance
 -0.375 inter.individual.variance
  1.816 inter.individual.variance
  0.138 inter.individual.variance
 -4.09 intra.individual.variance
 -4.64 intra.individual.variance
 -5.57 intra.individual.variance
 -2.96 intra.individual.variance
 -4.43 intra.individual.variance
 -3.60 intra.individual.variance",
 header=TRUE)
# get the numeric values of the factor 'type'
tot$ntype<-as.numeric(tot$type)
plot(tot$dat[tot$ntype==1],type="l",col="green",ylim=range(tot$dat))
lines(tot$dat[tot$ntype==2],col="blue")
text(5,-1.5,"p = 0.005")
legend(1,1,c("Inter-individual variance","Intra-individual variance"),
 lty=1,col=c("green","blue"))

Jim

On Wed, Feb 12, 2020 at 7:07 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> so I transformed my data from the previous email to look like this:
>
> > head(tot)
>      dat                      type
> 1 -3.962 inter.individual.variance
> 2 -4.301 inter.individual.variance
> 3 -1.690 inter.individual.variance
> 4 -0.375 inter.individual.variance
> 5  1.816 inter.individual.variance
> 6  0.138 inter.individual.variance
> > tail(tot)
>         dat                      type
> 31177 -4.09 intra.individual.variance
> 31178 -4.64 intra.individual.variance
> 31179 -5.57 intra.individual.variance
> 31180 -2.96 intra.individual.variance
> 31181 -4.43 intra.individual.variance
> 31182 -3.60 intra.individual.variance
>
> then I can make plot using this:
>
> densityplot(~dat,data=tot,
>        groups=type,
>        par.settings = list(superpose.line = list(col = c("blue","red"))),
>        xlab="log2 (variance)",
>        plot.points=FALSE,
>        auto.key=TRUE)
>
> and calculate my p value with t test, say it is 0.005
>
> But how to add that p value in between distribution of the curves?
>
> Thanks
> Ana
>
> On Tue, Feb 11, 2020 at 12:54 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hi,
> >
> > I have data like this:
> >
> > > head(a)
> >                    X   geneID inter.individual.variance
> > intra.individual.variance F.value  p.value     CV
> > 1 3iUZ.47hLFki49VR4o   MLLT10                    0.0642
> >    0.01395    4.60 1.00e-05 0.0222
> > 2 fEn1QlU0MCVe9GeR64 C1orf123                    0.0507
> >    0.00671    7.57 1.00e-08 0.0172
> > 3 ud_tTlU5LtB478JxIk    FSD1L                    0.3100
> >    0.02682   11.56 1.00e-11 0.0639
> > 4 3KV3OJIIRuJ5KJ6VkI  TXNDC11                    0.7710
> >    0.02813   27.41 9.99e-19 0.0688
> > 5 o_rupcEAKnQqnoh6ec   CYB5R2                    3.5209
> >    0.03391  103.83 9.99e-31 0.1357
> > 6 Nk_t6ULcQ7VDNChBRU     GBP1                    1.1005
> >    0.09522   11.56 9.98e-12 0.0773
> >
> > I would like to create density plot, like the attached between
> > "inter.individual.variance" and "intra.individual.variance" and have p
> > value between those two curves.
> >
> > Please advise,
> > Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Feb 11 22:55:56 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 11 Feb 2020 15:55:56 -0600
Subject: [R] how to create density plot in R with p value
In-Reply-To: <CAF9-5jMu9+BMQDuHuxKKPtYww65P2Vz23cFmNwWSFrzhE2yLsw@mail.gmail.com>
References: <CAF9-5jN=kT1ixNx0cRdfmnOokwn0hjsqoSDX8y6pSmjN5OG8Mg@mail.gmail.com>
 <CAF9-5jOHAiThNhUSOXwCORejc5gN8ubmTQEgxBRnbaFjU1SbtA@mail.gmail.com>
 <CA+8X3fUnXc52=ZAzgYEdwR4h3kYzBF7uEXttPL6sAH2RRBK_=Q@mail.gmail.com>
 <CAF9-5jMu9+BMQDuHuxKKPtYww65P2Vz23cFmNwWSFrzhE2yLsw@mail.gmail.com>
Message-ID: <CAF9-5jN4v-q-OJ5Rau9A6NApP=5OnzjQXkM1msRNXceVX8uiHg@mail.gmail.com>

Hi Jim


I tried your code and it didn't show me density curves.

However I was able to do teh plot myself via:

densityplot(~dat,data=tot,
       groups=type,
       par.settings = list(superpose.line = list(col = c("blue","red"))),
       xlab="log2 (variance)",
       plot.points=FALSE,
       auto.key=TRUE)


and it is attached. The only thing I need to do is to make a line in
between peaks of the curves and put the star above that line. Not a p
value but just a star symbol.

Please advise,
Thanks

On Tue, Feb 11, 2020 at 3:46 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi Jim
>
>
> I tried your code and it didn't show me density curves.
>
> However I was able to do teh plot myself via:
>
> densityplot(~dat,data=tot,
>        groups=type,
>        par.settings = list(superpose.line = list(col = c("blue","red"))),
>        xlab="log2 (variance)",
>        plot.points=FALSE,
>        auto.key=TRUE)
>
>
> and it is attached. The only thing I need to do is to make a line in
> between peaks of the curves and put the star above that line. Not a p
> value but just a star symbol.
>
> Please advise,
> Thanks
> Ana
>
> On Tue, Feb 11, 2020 at 3:23 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Ana,
> > Your image didn't make it through (as usual). Try PNG or PDF format.
> >
> > Assumptions
> > 1) You want to plot two lines using the _paired_ values of inter- and
> > intra-individual variance.
> > 2) The cases are in the same order in your data
> > 3) You want to identify the two lines
> > 4) You want to place text with some p-value between the lines
> >
> > This is really (and suspiciously) simple. Here's a start:
> >
> > tot<-read.table(text="dat type
> >  -3.962 inter.individual.variance
> >  -4.301 inter.individual.variance
> >  -1.690 inter.individual.variance
> >  -0.375 inter.individual.variance
> >   1.816 inter.individual.variance
> >   0.138 inter.individual.variance
> >  -4.09 intra.individual.variance
> >  -4.64 intra.individual.variance
> >  -5.57 intra.individual.variance
> >  -2.96 intra.individual.variance
> >  -4.43 intra.individual.variance
> >  -3.60 intra.individual.variance",
> >  header=TRUE)
> > # get the numeric values of the factor 'type'
> > tot$ntype<-as.numeric(tot$type)
> > plot(tot$dat[tot$ntype==1],type="l",col="green",ylim=range(tot$dat))
> > lines(tot$dat[tot$ntype==2],col="blue")
> > text(5,-1.5,"p = 0.005")
> > legend(1,1,c("Inter-individual variance","Intra-individual variance"),
> >  lty=1,col=c("green","blue"))
> >
> > Jim
> >
> > On Wed, Feb 12, 2020 at 7:07 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > >
> > > so I transformed my data from the previous email to look like this:
> > >
> > > > head(tot)
> > >      dat                      type
> > > 1 -3.962 inter.individual.variance
> > > 2 -4.301 inter.individual.variance
> > > 3 -1.690 inter.individual.variance
> > > 4 -0.375 inter.individual.variance
> > > 5  1.816 inter.individual.variance
> > > 6  0.138 inter.individual.variance
> > > > tail(tot)
> > >         dat                      type
> > > 31177 -4.09 intra.individual.variance
> > > 31178 -4.64 intra.individual.variance
> > > 31179 -5.57 intra.individual.variance
> > > 31180 -2.96 intra.individual.variance
> > > 31181 -4.43 intra.individual.variance
> > > 31182 -3.60 intra.individual.variance
> > >
> > > then I can make plot using this:
> > >
> > > densityplot(~dat,data=tot,
> > >        groups=type,
> > >        par.settings = list(superpose.line = list(col = c("blue","red"))),
> > >        xlab="log2 (variance)",
> > >        plot.points=FALSE,
> > >        auto.key=TRUE)
> > >
> > > and calculate my p value with t test, say it is 0.005
> > >
> > > But how to add that p value in between distribution of the curves?
> > >
> > > Thanks
> > > Ana
> > >
> > > On Tue, Feb 11, 2020 at 12:54 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > > >
> > > > Hi,
> > > >
> > > > I have data like this:
> > > >
> > > > > head(a)
> > > >                    X   geneID inter.individual.variance
> > > > intra.individual.variance F.value  p.value     CV
> > > > 1 3iUZ.47hLFki49VR4o   MLLT10                    0.0642
> > > >    0.01395    4.60 1.00e-05 0.0222
> > > > 2 fEn1QlU0MCVe9GeR64 C1orf123                    0.0507
> > > >    0.00671    7.57 1.00e-08 0.0172
> > > > 3 ud_tTlU5LtB478JxIk    FSD1L                    0.3100
> > > >    0.02682   11.56 1.00e-11 0.0639
> > > > 4 3KV3OJIIRuJ5KJ6VkI  TXNDC11                    0.7710
> > > >    0.02813   27.41 9.99e-19 0.0688
> > > > 5 o_rupcEAKnQqnoh6ec   CYB5R2                    3.5209
> > > >    0.03391  103.83 9.99e-31 0.1357
> > > > 6 Nk_t6ULcQ7VDNChBRU     GBP1                    1.1005
> > > >    0.09522   11.56 9.98e-12 0.0773
> > > >
> > > > I would like to create density plot, like the attached between
> > > > "inter.individual.variance" and "intra.individual.variance" and have p
> > > > value between those two curves.
> > > >
> > > > Please advise,
> > > > Ana
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: rsz_newp.png
Type: image/png
Size: 51078 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200211/ce686146/attachment.png>

From r@oknz @end|ng |rom gm@||@com  Tue Feb 11 23:34:28 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Wed, 12 Feb 2020 11:34:28 +1300
Subject: [R] Help to do this exercise
In-Reply-To: <CAH-4msw8K+T_HGWfuzc4mxupDPaB=iCZjLFD1U3hYz5bdQB5BQ@mail.gmail.com>
References: <CAH-4msw8K+T_HGWfuzc4mxupDPaB=iCZjLFD1U3hYz5bdQB5BQ@mail.gmail.com>
Message-ID: <CABcYAdL6Oz5BD2Un2BybbxQ-2h66AW-mj5ehFpC1DZ7JK6MM6Q@mail.gmail.com>

Others have already commented on the "no homework" policy.
I'd like to make a different point.
When I was doing my MSc many years ago, a friend of mine was
really struggling with statistics.  He complained to me that when
studying the textbooks and looking at examples, he could never
figure out why the method chosen was the best method for the example.
When I looked into it, the answer was horribly simple.
The method was chosen first, and the example selected to illustrate.
More often than not, the method *wasn't* the best one for the example.

Now let's consider the Lake Huron dataset.
What is the single most obvious thing about it?
It's a TIME SERIES.
It's a time series where the events of a year make a modest *change*
to the level of the lake, we expect a high autocorrelation.
> plot(LakeHuron)
> plot(diff(LakeHuron))
> acf(LakeHuron)

Autocorrelations of series ?LakeHuron?, by lag

     0      1      2      3      4      5      6      7      8      9     10
 1.000  0.832  0.610  0.458  0.371  0.326  0.285  0.265  0.264  0.258  0.183
    11     12     13     14     15     16     17     18     19
 0.095  0.044  0.029  0.041  0.045  0.035  0.005 -0.033 -0.053

Yup, high autocorrelation is what we get.
This suggests that a model like level(t+1) = level(t) + shock(t)
might be a good first attempt, so
> plot(diff(LakeHuron))

What this says to me is that estimating the probability density of the level
is not a sensible thing to do.  We DON'T have a collection of independent
and identically distributed measurements.  We have a time series.

So,
 + you CAN do what the homework says
 + so you CAN use this dataset to illustrate these methods
 - BUT these methods are NOT a sensible way to understand this dataset.

On Tue, 11 Feb 2020 at 03:40, h??ng ph?m <pth7995 at gmail.com> wrote:
>
> N1 Consider the database "LakeHuron" , containing the annual measurements
> of the level (in feet) of Lake Huron 1875{1972, see
> https://stat.ethz.ch/R-manual/Rdevel/library/datasets/html/LakeHuron.html.
> The general aim is to estimate the probability density of the level of the
> lake.
> (i) Construct the histogram estimator with the number of bins selected
> by the Sturges rule. On the same plot display the graph of the density of
> the normal distribution with estimated mean and standard
> deviation (normal fit).
> (ii) Among the histograms with the number of bins from 5 to 30, find
> the histogram estimator which is closest to the normal fit. Comment on the
> bias-variance tradeoff in this case.
> (iii) Construct the kernel estimators with various kernels (apply all
> kernels available in the R language). The bandwidth can be chosen by
> default. Construct the kernel estimators under various choices of
> bandwidth (apply all rules for bandwidth selection, which are implemented
> in the R language, the kernel can be chosen by default).
> Among all constructed kernel estimators, find the kernel estimator
> which is closest to the normal fit
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Wed Feb 12 00:13:54 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 12 Feb 2020 10:13:54 +1100
Subject: [R] how to create density plot in R with p value
In-Reply-To: <CAF9-5jN4v-q-OJ5Rau9A6NApP=5OnzjQXkM1msRNXceVX8uiHg@mail.gmail.com>
References: <CAF9-5jN=kT1ixNx0cRdfmnOokwn0hjsqoSDX8y6pSmjN5OG8Mg@mail.gmail.com>
 <CAF9-5jOHAiThNhUSOXwCORejc5gN8ubmTQEgxBRnbaFjU1SbtA@mail.gmail.com>
 <CA+8X3fUnXc52=ZAzgYEdwR4h3kYzBF7uEXttPL6sAH2RRBK_=Q@mail.gmail.com>
 <CAF9-5jMu9+BMQDuHuxKKPtYww65P2Vz23cFmNwWSFrzhE2yLsw@mail.gmail.com>
 <CAF9-5jN4v-q-OJ5Rau9A6NApP=5OnzjQXkM1msRNXceVX8uiHg@mail.gmail.com>
Message-ID: <CA+8X3fUXFqzheZ8nPeS+eSp266_nzXup74d2yvmuDXd9=Gyz8Q@mail.gmail.com>

Hi Ana,
Okay, it's the lattice package. Try this:

panel.abline(v=-4)
panel.text(-3.9,0.35,"*")

As I don't have your data I can't provide a complete example.

Jim

On Wed, Feb 12, 2020 at 8:50 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi Jim
>
>
> I tried your code and it didn't show me density curves.
>
> However I was able to do teh plot myself via:
>
> densityplot(~dat,data=tot,
>        groups=type,
>        par.settings = list(superpose.line = list(col = c("blue","red"))),
>        xlab="log2 (variance)",
>        plot.points=FALSE,
>        auto.key=TRUE)
>
>
> and it is attached. The only thing I need to do is to make a line in
> between peaks of the curves and put the star above that line. Not a p
> value but just a star symbol.
>
> Please advise,
> Thanks
>
> On Tue, Feb 11, 2020 at 3:46 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hi Jim
> >
> >
> > I tried your code and it didn't show me density curves.
> >
> > However I was able to do teh plot myself via:
> >
> > densityplot(~dat,data=tot,
> >        groups=type,
> >        par.settings = list(superpose.line = list(col = c("blue","red"))),
> >        xlab="log2 (variance)",
> >        plot.points=FALSE,
> >        auto.key=TRUE)
> >
> >
> > and it is attached. The only thing I need to do is to make a line in
> > between peaks of the curves and put the star above that line. Not a p
> > value but just a star symbol.
> >
> > Please advise,
> > Thanks
> > Ana
> >
> > On Tue, Feb 11, 2020 at 3:23 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >
> > > Hi Ana,
> > > Your image didn't make it through (as usual). Try PNG or PDF format.
> > >
> > > Assumptions
> > > 1) You want to plot two lines using the _paired_ values of inter- and
> > > intra-individual variance.
> > > 2) The cases are in the same order in your data
> > > 3) You want to identify the two lines
> > > 4) You want to place text with some p-value between the lines
> > >
> > > This is really (and suspiciously) simple. Here's a start:
> > >
> > > tot<-read.table(text="dat type
> > >  -3.962 inter.individual.variance
> > >  -4.301 inter.individual.variance
> > >  -1.690 inter.individual.variance
> > >  -0.375 inter.individual.variance
> > >   1.816 inter.individual.variance
> > >   0.138 inter.individual.variance
> > >  -4.09 intra.individual.variance
> > >  -4.64 intra.individual.variance
> > >  -5.57 intra.individual.variance
> > >  -2.96 intra.individual.variance
> > >  -4.43 intra.individual.variance
> > >  -3.60 intra.individual.variance",
> > >  header=TRUE)
> > > # get the numeric values of the factor 'type'
> > > tot$ntype<-as.numeric(tot$type)
> > > plot(tot$dat[tot$ntype==1],type="l",col="green",ylim=range(tot$dat))
> > > lines(tot$dat[tot$ntype==2],col="blue")
> > > text(5,-1.5,"p = 0.005")
> > > legend(1,1,c("Inter-individual variance","Intra-individual variance"),
> > >  lty=1,col=c("green","blue"))
> > >
> > > Jim
> > >
> > > On Wed, Feb 12, 2020 at 7:07 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > > >
> > > > so I transformed my data from the previous email to look like this:
> > > >
> > > > > head(tot)
> > > >      dat                      type
> > > > 1 -3.962 inter.individual.variance
> > > > 2 -4.301 inter.individual.variance
> > > > 3 -1.690 inter.individual.variance
> > > > 4 -0.375 inter.individual.variance
> > > > 5  1.816 inter.individual.variance
> > > > 6  0.138 inter.individual.variance
> > > > > tail(tot)
> > > >         dat                      type
> > > > 31177 -4.09 intra.individual.variance
> > > > 31178 -4.64 intra.individual.variance
> > > > 31179 -5.57 intra.individual.variance
> > > > 31180 -2.96 intra.individual.variance
> > > > 31181 -4.43 intra.individual.variance
> > > > 31182 -3.60 intra.individual.variance
> > > >
> > > > then I can make plot using this:
> > > >
> > > > densityplot(~dat,data=tot,
> > > >        groups=type,
> > > >        par.settings = list(superpose.line = list(col = c("blue","red"))),
> > > >        xlab="log2 (variance)",
> > > >        plot.points=FALSE,
> > > >        auto.key=TRUE)
> > > >
> > > > and calculate my p value with t test, say it is 0.005
> > > >
> > > > But how to add that p value in between distribution of the curves?
> > > >
> > > > Thanks
> > > > Ana
> > > >
> > > > On Tue, Feb 11, 2020 at 12:54 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > > > >
> > > > > Hi,
> > > > >
> > > > > I have data like this:
> > > > >
> > > > > > head(a)
> > > > >                    X   geneID inter.individual.variance
> > > > > intra.individual.variance F.value  p.value     CV
> > > > > 1 3iUZ.47hLFki49VR4o   MLLT10                    0.0642
> > > > >    0.01395    4.60 1.00e-05 0.0222
> > > > > 2 fEn1QlU0MCVe9GeR64 C1orf123                    0.0507
> > > > >    0.00671    7.57 1.00e-08 0.0172
> > > > > 3 ud_tTlU5LtB478JxIk    FSD1L                    0.3100
> > > > >    0.02682   11.56 1.00e-11 0.0639
> > > > > 4 3KV3OJIIRuJ5KJ6VkI  TXNDC11                    0.7710
> > > > >    0.02813   27.41 9.99e-19 0.0688
> > > > > 5 o_rupcEAKnQqnoh6ec   CYB5R2                    3.5209
> > > > >    0.03391  103.83 9.99e-31 0.1357
> > > > > 6 Nk_t6ULcQ7VDNChBRU     GBP1                    1.1005
> > > > >    0.09522   11.56 9.98e-12 0.0773
> > > > >
> > > > > I would like to create density plot, like the attached between
> > > > > "inter.individual.variance" and "intra.individual.variance" and have p
> > > > > value between those two curves.
> > > > >
> > > > > Please advise,
> > > > > Ana
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Feb 12 00:40:30 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 11 Feb 2020 15:40:30 -0800
Subject: [R] how to create density plot in R with p value
In-Reply-To: <CA+8X3fUXFqzheZ8nPeS+eSp266_nzXup74d2yvmuDXd9=Gyz8Q@mail.gmail.com>
References: <CAF9-5jN=kT1ixNx0cRdfmnOokwn0hjsqoSDX8y6pSmjN5OG8Mg@mail.gmail.com>
 <CAF9-5jOHAiThNhUSOXwCORejc5gN8ubmTQEgxBRnbaFjU1SbtA@mail.gmail.com>
 <CA+8X3fUnXc52=ZAzgYEdwR4h3kYzBF7uEXttPL6sAH2RRBK_=Q@mail.gmail.com>
 <CAF9-5jMu9+BMQDuHuxKKPtYww65P2Vz23cFmNwWSFrzhE2yLsw@mail.gmail.com>
 <CAF9-5jN4v-q-OJ5Rau9A6NApP=5OnzjQXkM1msRNXceVX8uiHg@mail.gmail.com>
 <CA+8X3fUXFqzheZ8nPeS+eSp266_nzXup74d2yvmuDXd9=Gyz8Q@mail.gmail.com>
Message-ID: <CAGxFJbTOibq=048kVKk_J-K=DCeOWmSuEr4oPMaEzec-T03cJw@mail.gmail.com>

I assume you mean:

densityplot(~dat,data=tot,
       groups=type,
       panel = function(...){
          panel.densityplot(...)
          panel.abline(v= -4)
          panel.text(-3.9, 0.35, "*")
       },
       par.settings = list(superpose.line = list(col = c("blue","red"))),
       xlab="log2 (variance)",
       plot.points=FALSE,
       auto.key=TRUE)

**warning**: in the absence of data, untested.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 11, 2020 at 3:14 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Ana,
> Okay, it's the lattice package. Try this:
>
> panel.abline(v=-4)
> panel.text(-3.9,0.35,"*")
>
> As I don't have your data I can't provide a complete example.
>
> Jim
>
> On Wed, Feb 12, 2020 at 8:50 AM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
> >
> > Hi Jim
> >
> >
> > I tried your code and it didn't show me density curves.
> >
> > However I was able to do teh plot myself via:
> >
> > densityplot(~dat,data=tot,
> >        groups=type,
> >        par.settings = list(superpose.line = list(col = c("blue","red"))),
> >        xlab="log2 (variance)",
> >        plot.points=FALSE,
> >        auto.key=TRUE)
> >
> >
> > and it is attached. The only thing I need to do is to make a line in
> > between peaks of the curves and put the star above that line. Not a p
> > value but just a star symbol.
> >
> > Please advise,
> > Thanks
> >
> > On Tue, Feb 11, 2020 at 3:46 PM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
> > >
> > > Hi Jim
> > >
> > >
> > > I tried your code and it didn't show me density curves.
> > >
> > > However I was able to do teh plot myself via:
> > >
> > > densityplot(~dat,data=tot,
> > >        groups=type,
> > >        par.settings = list(superpose.line = list(col =
> c("blue","red"))),
> > >        xlab="log2 (variance)",
> > >        plot.points=FALSE,
> > >        auto.key=TRUE)
> > >
> > >
> > > and it is attached. The only thing I need to do is to make a line in
> > > between peaks of the curves and put the star above that line. Not a p
> > > value but just a star symbol.
> > >
> > > Please advise,
> > > Thanks
> > > Ana
> > >
> > > On Tue, Feb 11, 2020 at 3:23 PM Jim Lemon <drjimlemon at gmail.com>
> wrote:
> > > >
> > > > Hi Ana,
> > > > Your image didn't make it through (as usual). Try PNG or PDF format.
> > > >
> > > > Assumptions
> > > > 1) You want to plot two lines using the _paired_ values of inter- and
> > > > intra-individual variance.
> > > > 2) The cases are in the same order in your data
> > > > 3) You want to identify the two lines
> > > > 4) You want to place text with some p-value between the lines
> > > >
> > > > This is really (and suspiciously) simple. Here's a start:
> > > >
> > > > tot<-read.table(text="dat type
> > > >  -3.962 inter.individual.variance
> > > >  -4.301 inter.individual.variance
> > > >  -1.690 inter.individual.variance
> > > >  -0.375 inter.individual.variance
> > > >   1.816 inter.individual.variance
> > > >   0.138 inter.individual.variance
> > > >  -4.09 intra.individual.variance
> > > >  -4.64 intra.individual.variance
> > > >  -5.57 intra.individual.variance
> > > >  -2.96 intra.individual.variance
> > > >  -4.43 intra.individual.variance
> > > >  -3.60 intra.individual.variance",
> > > >  header=TRUE)
> > > > # get the numeric values of the factor 'type'
> > > > tot$ntype<-as.numeric(tot$type)
> > > > plot(tot$dat[tot$ntype==1],type="l",col="green",ylim=range(tot$dat))
> > > > lines(tot$dat[tot$ntype==2],col="blue")
> > > > text(5,-1.5,"p = 0.005")
> > > > legend(1,1,c("Inter-individual variance","Intra-individual
> variance"),
> > > >  lty=1,col=c("green","blue"))
> > > >
> > > > Jim
> > > >
> > > > On Wed, Feb 12, 2020 at 7:07 AM Ana Marija <
> sokovic.anamarija at gmail.com> wrote:
> > > > >
> > > > > so I transformed my data from the previous email to look like this:
> > > > >
> > > > > > head(tot)
> > > > >      dat                      type
> > > > > 1 -3.962 inter.individual.variance
> > > > > 2 -4.301 inter.individual.variance
> > > > > 3 -1.690 inter.individual.variance
> > > > > 4 -0.375 inter.individual.variance
> > > > > 5  1.816 inter.individual.variance
> > > > > 6  0.138 inter.individual.variance
> > > > > > tail(tot)
> > > > >         dat                      type
> > > > > 31177 -4.09 intra.individual.variance
> > > > > 31178 -4.64 intra.individual.variance
> > > > > 31179 -5.57 intra.individual.variance
> > > > > 31180 -2.96 intra.individual.variance
> > > > > 31181 -4.43 intra.individual.variance
> > > > > 31182 -3.60 intra.individual.variance
> > > > >
> > > > > then I can make plot using this:
> > > > >
> > > > > densityplot(~dat,data=tot,
> > > > >        groups=type,
> > > > >        par.settings = list(superpose.line = list(col =
> c("blue","red"))),
> > > > >        xlab="log2 (variance)",
> > > > >        plot.points=FALSE,
> > > > >        auto.key=TRUE)
> > > > >
> > > > > and calculate my p value with t test, say it is 0.005
> > > > >
> > > > > But how to add that p value in between distribution of the curves?
> > > > >
> > > > > Thanks
> > > > > Ana
> > > > >
> > > > > On Tue, Feb 11, 2020 at 12:54 PM Ana Marija <
> sokovic.anamarija at gmail.com> wrote:
> > > > > >
> > > > > > Hi,
> > > > > >
> > > > > > I have data like this:
> > > > > >
> > > > > > > head(a)
> > > > > >                    X   geneID inter.individual.variance
> > > > > > intra.individual.variance F.value  p.value     CV
> > > > > > 1 3iUZ.47hLFki49VR4o   MLLT10                    0.0642
> > > > > >    0.01395    4.60 1.00e-05 0.0222
> > > > > > 2 fEn1QlU0MCVe9GeR64 C1orf123                    0.0507
> > > > > >    0.00671    7.57 1.00e-08 0.0172
> > > > > > 3 ud_tTlU5LtB478JxIk    FSD1L                    0.3100
> > > > > >    0.02682   11.56 1.00e-11 0.0639
> > > > > > 4 3KV3OJIIRuJ5KJ6VkI  TXNDC11                    0.7710
> > > > > >    0.02813   27.41 9.99e-19 0.0688
> > > > > > 5 o_rupcEAKnQqnoh6ec   CYB5R2                    3.5209
> > > > > >    0.03391  103.83 9.99e-31 0.1357
> > > > > > 6 Nk_t6ULcQ7VDNChBRU     GBP1                    1.1005
> > > > > >    0.09522   11.56 9.98e-12 0.0773
> > > > > >
> > > > > > I would like to create density plot, like the attached between
> > > > > > "inter.individual.variance" and "intra.individual.variance" and
> have p
> > > > > > value between those two curves.
> > > > > >
> > > > > > Please advise,
> > > > > > Ana
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From We@@B@rr|@ @end|ng |rom cobb-v@ntre@@@com  Tue Feb 11 22:26:33 2020
From: We@@B@rr|@ @end|ng |rom cobb-v@ntre@@@com (Barris, Wes)
Date: Tue, 11 Feb 2020 21:26:33 +0000
Subject: [R] make check fails -- how to debug
Message-ID: <SN6PR17MB2125E546AB5664FE97FC9E53D8180@SN6PR17MB2125.namprd17.prod.outlook.com>

I am trying to build R-3.6.2 on a Linux system running CentOS 7.7.1908.  "make check" fails.  How can I troubleshoot this to find out what is wrong?

R_PAPERSIZE=letter
cd R-3.6.2
mkdir CentOS
../configure --with-x=no --enable-R-shlib
make
make check
.
.
.
running code in '../../tests/array-subset.R' ... OK
running code in '../../tests/reg-tests-1a.R' ... OK
running code in '../../tests/reg-tests-1b.R' ... OK
running code in '../../tests/reg-tests-1c.R' ... OK
running code in '../../tests/reg-tests-1d.R' ... OK
running code in '../../tests/reg-tests-2.R' ... OK
  comparing 'reg-tests-2.Rout' to '../../tests/reg-tests-2.Rout.save' ... OK
running code in '../../tests/reg-examples1.R' ... OK
running code in '../../tests/reg-examples2.R' ... OK
running code in '../../tests/reg-packages.R' ...make[3]: *** [reg-packages.Rout] Error 1
make[3]: Leaving directory `/usr/local/src/stats/R-3.6.2/CentOS/tests'
make[2]: *** [test-Reg] Error 2
make[2]: Leaving directory `/usr/local/src/stats/R-3.6.2/CentOS/tests'
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory `/usr/local/src/stats/R-3.6.2/CentOS/tests'
make: *** [check] Error 2
-- 
Wes Barris

----------------------------------------------------------------------
This email and any files transmitted with it are confide...{{dropped:11}}


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Feb 11 22:46:50 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 11 Feb 2020 15:46:50 -0600
Subject: [R] how to create density plot in R with p value
In-Reply-To: <CA+8X3fUnXc52=ZAzgYEdwR4h3kYzBF7uEXttPL6sAH2RRBK_=Q@mail.gmail.com>
References: <CAF9-5jN=kT1ixNx0cRdfmnOokwn0hjsqoSDX8y6pSmjN5OG8Mg@mail.gmail.com>
 <CAF9-5jOHAiThNhUSOXwCORejc5gN8ubmTQEgxBRnbaFjU1SbtA@mail.gmail.com>
 <CA+8X3fUnXc52=ZAzgYEdwR4h3kYzBF7uEXttPL6sAH2RRBK_=Q@mail.gmail.com>
Message-ID: <CAF9-5jMu9+BMQDuHuxKKPtYww65P2Vz23cFmNwWSFrzhE2yLsw@mail.gmail.com>

Hi Jim


I tried your code and it didn't show me density curves.

However I was able to do teh plot myself via:

densityplot(~dat,data=tot,
       groups=type,
       par.settings = list(superpose.line = list(col = c("blue","red"))),
       xlab="log2 (variance)",
       plot.points=FALSE,
       auto.key=TRUE)


and it is attached. The only thing I need to do is to make a line in
between peaks of the curves and put the star above that line. Not a p
value but just a star symbol.

Please advise,
Thanks
Ana

On Tue, Feb 11, 2020 at 3:23 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Ana,
> Your image didn't make it through (as usual). Try PNG or PDF format.
>
> Assumptions
> 1) You want to plot two lines using the _paired_ values of inter- and
> intra-individual variance.
> 2) The cases are in the same order in your data
> 3) You want to identify the two lines
> 4) You want to place text with some p-value between the lines
>
> This is really (and suspiciously) simple. Here's a start:
>
> tot<-read.table(text="dat type
>  -3.962 inter.individual.variance
>  -4.301 inter.individual.variance
>  -1.690 inter.individual.variance
>  -0.375 inter.individual.variance
>   1.816 inter.individual.variance
>   0.138 inter.individual.variance
>  -4.09 intra.individual.variance
>  -4.64 intra.individual.variance
>  -5.57 intra.individual.variance
>  -2.96 intra.individual.variance
>  -4.43 intra.individual.variance
>  -3.60 intra.individual.variance",
>  header=TRUE)
> # get the numeric values of the factor 'type'
> tot$ntype<-as.numeric(tot$type)
> plot(tot$dat[tot$ntype==1],type="l",col="green",ylim=range(tot$dat))
> lines(tot$dat[tot$ntype==2],col="blue")
> text(5,-1.5,"p = 0.005")
> legend(1,1,c("Inter-individual variance","Intra-individual variance"),
>  lty=1,col=c("green","blue"))
>
> Jim
>
> On Wed, Feb 12, 2020 at 7:07 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > so I transformed my data from the previous email to look like this:
> >
> > > head(tot)
> >      dat                      type
> > 1 -3.962 inter.individual.variance
> > 2 -4.301 inter.individual.variance
> > 3 -1.690 inter.individual.variance
> > 4 -0.375 inter.individual.variance
> > 5  1.816 inter.individual.variance
> > 6  0.138 inter.individual.variance
> > > tail(tot)
> >         dat                      type
> > 31177 -4.09 intra.individual.variance
> > 31178 -4.64 intra.individual.variance
> > 31179 -5.57 intra.individual.variance
> > 31180 -2.96 intra.individual.variance
> > 31181 -4.43 intra.individual.variance
> > 31182 -3.60 intra.individual.variance
> >
> > then I can make plot using this:
> >
> > densityplot(~dat,data=tot,
> >        groups=type,
> >        par.settings = list(superpose.line = list(col = c("blue","red"))),
> >        xlab="log2 (variance)",
> >        plot.points=FALSE,
> >        auto.key=TRUE)
> >
> > and calculate my p value with t test, say it is 0.005
> >
> > But how to add that p value in between distribution of the curves?
> >
> > Thanks
> > Ana
> >
> > On Tue, Feb 11, 2020 at 12:54 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > >
> > > Hi,
> > >
> > > I have data like this:
> > >
> > > > head(a)
> > >                    X   geneID inter.individual.variance
> > > intra.individual.variance F.value  p.value     CV
> > > 1 3iUZ.47hLFki49VR4o   MLLT10                    0.0642
> > >    0.01395    4.60 1.00e-05 0.0222
> > > 2 fEn1QlU0MCVe9GeR64 C1orf123                    0.0507
> > >    0.00671    7.57 1.00e-08 0.0172
> > > 3 ud_tTlU5LtB478JxIk    FSD1L                    0.3100
> > >    0.02682   11.56 1.00e-11 0.0639
> > > 4 3KV3OJIIRuJ5KJ6VkI  TXNDC11                    0.7710
> > >    0.02813   27.41 9.99e-19 0.0688
> > > 5 o_rupcEAKnQqnoh6ec   CYB5R2                    3.5209
> > >    0.03391  103.83 9.99e-31 0.1357
> > > 6 Nk_t6ULcQ7VDNChBRU     GBP1                    1.1005
> > >    0.09522   11.56 9.98e-12 0.0773
> > >
> > > I would like to create density plot, like the attached between
> > > "inter.individual.variance" and "intra.individual.variance" and have p
> > > value between those two curves.
> > >
> > > Please advise,
> > > Ana
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: newp.png
Type: image/png
Size: 141973 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200211/bd030a1f/attachment.png>

From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Feb 12 10:29:52 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 12 Feb 2020 04:29:52 -0500
Subject: [R] make check fails -- how to debug
In-Reply-To: <SN6PR17MB2125E546AB5664FE97FC9E53D8180@SN6PR17MB2125.namprd17.prod.outlook.com>
References: <SN6PR17MB2125E546AB5664FE97FC9E53D8180@SN6PR17MB2125.namprd17.prod.outlook.com>
Message-ID: <4db86500-9752-9671-f5b9-9147628c5030@gmail.com>

On 11/02/2020 4:26 p.m., Barris, Wes wrote:
> I am trying to build R-3.6.2 on a Linux system running CentOS 7.7.1908.  "make check" fails.  How can I troubleshoot this to find out what is wrong?
> 
> R_PAPERSIZE=letter
> cd R-3.6.2
> mkdir CentOS
> ../configure --with-x=no --enable-R-shlib
> make
> make check
> .
> .
> .
> running code in '../../tests/array-subset.R' ... OK
> running code in '../../tests/reg-tests-1a.R' ... OK
> running code in '../../tests/reg-tests-1b.R' ... OK
> running code in '../../tests/reg-tests-1c.R' ... OK
> running code in '../../tests/reg-tests-1d.R' ... OK
> running code in '../../tests/reg-tests-2.R' ... OK
>    comparing 'reg-tests-2.Rout' to '../../tests/reg-tests-2.Rout.save' ... OK
> running code in '../../tests/reg-examples1.R' ... OK
> running code in '../../tests/reg-examples2.R' ... OK
> running code in '../../tests/reg-packages.R' ...make[3]: *** [reg-packages.Rout] Error 1
> make[3]: Leaving directory `/usr/local/src/stats/R-3.6.2/CentOS/tests'
> make[2]: *** [test-Reg] Error 2
> make[2]: Leaving directory `/usr/local/src/stats/R-3.6.2/CentOS/tests'
> make[1]: *** [test-all-basics] Error 1
> make[1]: Leaving directory `/usr/local/src/stats/R-3.6.2/CentOS/tests'
> make: *** [check] Error 2
> 

At the end of that run, you'll see the log of the failed test in 
tests/reg-packages.Rout.fail (or some name a lot like that).  You'll 
have to figure out why it failed from that log.

Duncan Murdoch


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Feb 12 10:36:38 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 12 Feb 2020 12:36:38 +0300
Subject: [R] make check fails -- how to debug
In-Reply-To: <SN6PR17MB2125E546AB5664FE97FC9E53D8180@SN6PR17MB2125.namprd17.prod.outlook.com>
References: <SN6PR17MB2125E546AB5664FE97FC9E53D8180@SN6PR17MB2125.namprd17.prod.outlook.com>
Message-ID: <20200212123638.3951e996@trisector>

On Tue, 11 Feb 2020 21:26:33 +0000
"Barris, Wes" <Wes.Barris at cobb-vantress.com> wrote:

> running code in '../../tests/reg-packages.R' ...make[3]: ***
> [reg-packages.Rout] Error 1

tests/Makefile.common has the following in the .R.Rout rule:

        @$(ECHO) $(ECHO_N) "running code in '$<' ...$(ECHO_C)" > $@.log
        @$(R) < $< > $@.fail 2>&1 || (cat $@.log && rm $@.log && exit 1)

> How can I troubleshoot this to find out what is wrong?

Take a look at tests/reg-packages.Rout.fail, it should contain all
output produced by tests/reg-packages.R when it ran.

-- 
Best regards,
Ivan


From h|gh@t@t @end|ng |rom h|gh@t@t@com  Wed Feb 12 11:31:13 2020
From: h|gh@t@t @end|ng |rom h|gh@t@t@com (Highland Statistics Ltd)
Date: Wed, 12 Feb 2020 11:31:13 +0100
Subject: [R] Course: Zero-inflated models using R-INLA
Message-ID: <5783cdba-7c22-077a-f53b-f0f9a8382070@highstat.com>


We would like to announce the following statistics course.

Course: Introduction to zero-inflated models using R-INLA

Where and when: NAIT, Edmonton, Canada. 23 - 26 March 2020

Course website: http://highstat.com/index.php/courses-upcoming
Course flyer: 
http://highstat.com/Courses/Flyers/2020/Flyer2020_03NAIT_ZI.pdf

Kind regards,


Alain Zuur

-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL: www.highstat.com


	[[alternative HTML version deleted]]


From We@@B@rr|@ @end|ng |rom cobb-v@ntre@@@com  Wed Feb 12 15:20:55 2020
From: We@@B@rr|@ @end|ng |rom cobb-v@ntre@@@com (Barris, Wes)
Date: Wed, 12 Feb 2020 14:20:55 +0000
Subject: [R] make check fails -- how to debug
In-Reply-To: <20200212123638.3951e996@trisector>
References: <SN6PR17MB2125E546AB5664FE97FC9E53D8180@SN6PR17MB2125.namprd17.prod.outlook.com>
 <20200212123638.3951e996@trisector>
Message-ID: <SN6PR17MB21256C86A461DC701AD924AFD81B0@SN6PR17MB2125.namprd17.prod.outlook.com>

Thanks Ivan.  Here is the contents of reg-packages.Rout.fail.  I'm not sure exactly what part of this is the fatal error:



R version 3.6.2 (2019-12-12) -- "Dark and Stormy Night"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> .R_LIBS <- function(libp = .libPaths()) { # (>> in utils?)
+     libp <- libp[! libp %in% .Library]
+     if(length(libp))
+         paste(libp, collapse = .Platform$path.sep)
+     else "" # character(0) is invalid for Sys.setenv()
+ }
> Sys.setenv(R_LIBS = .R_LIBS() # for build.pkg() & install.packages()
+          , R_BUILD_ENVIRON = "nothing" # avoid ~/.R/build.environ which might set R_LIBS
+          , R_ENVIRON = "none"
+          , R_PROFILE = "none"
+            )
> 
> ## PR 1271  detach("package:base") crashes R.
> tools::assertError(detach("package:base"))
> 
> 
> ## invalid 'lib.loc'
> stopifnot(length(installed.packages("mgcv")) == 0)
> ## gave a low-level error message
> 
> 
> ## package.skeleton() with metadata-only code
> ## work in current (= ./tests/ directory):
> tmp <- tempfile()
> writeLines(c('setClass("foo", contains="numeric")',
+              'setMethod("show", "foo",',
+              '          function(object) cat("I am a \\"foo\\"\\n"))'),
+            tmp)
> if(file.exists("myTst")) unlink("myTst", recursive=TRUE)
> package.skeleton("myTst", code_files = tmp)# with a file name warning
Creating directories ...
Creating DESCRIPTION ...
Creating NAMESPACE ...
Creating Read-and-delete-me ...
Copying code files ...
Making help files ...
Done.
Further steps are described in './myTst/Read-and-delete-me'.
Warning message:
In package.skeleton("myTst", code_files = tmp) :
  Invalid file name(s) for R code in ./myTst/R:
  'file62e012b0d16'
 are now renamed to 'z<name>.R'
> file.copy(tmp, (tm2 <- paste(tmp,".R", sep="")))
[1] TRUE
> unlink("myTst", recursive=TRUE)
> op <- options(warn=2) # *NO* "invalid file name" warning {failed in 2.7.[01]}:
> package.skeleton("myTst", code_files = tm2)
Creating directories ...
Creating DESCRIPTION ...
Creating NAMESPACE ...
Creating Read-and-delete-me ...
Copying code files ...
Making help files ...
Done.
Further steps are described in './myTst/Read-and-delete-me'.
> options(op)
> ##_2_ only a class, no generics/methods:
> writeLines(c('setClass("DocLink",',
+              'representation(name="character",',
+              '               desc="character"))'), tmp)
> if(file.exists("myTst2")) unlink("myTst2", recursive=TRUE)
> package.skeleton("myTst2", code_files = tmp)
Creating directories ...
Creating DESCRIPTION ...
Creating NAMESPACE ...
Creating Read-and-delete-me ...
Copying code files ...
Making help files ...
Done.
Further steps are described in './myTst2/Read-and-delete-me'.
Warning message:
In package.skeleton("myTst2", code_files = tmp) :
  Invalid file name(s) for R code in ./myTst2/R:
  'file62e012b0d16'
 are now renamed to 'z<name>.R'
> ##- end_2_ # failed in R 2.11.0
> stopifnot(1 == grep("setClass",
+ 	  readLines(list.files("myTst/R", full.names=TRUE))),
+ 	  c("foo-class.Rd","show-methods.Rd") %in% list.files("myTst/man"))
> ## failed for several reasons in R < 2.7.0
> ##
> ## Part 2: -- build, install, load and "inspect" the package:
> build.pkg <- function(dir) {
+     stopifnot(dir.exists(dir), file.exists(DESC <- file.path(dir, "DESCRIPTION")))
+     pkgName <- sub("^[A-Za-z]+: ", "", grep("^Package: ", readLines(DESC), value=TRUE))
+     patt <- paste(pkgName, ".*tar\\.gz$", sep="_")
+     unlink(dir('.', pattern = patt))
+     Rcmd <- paste(shQuote(file.path(R.home("bin"), "R")), "CMD")
+     r <- system(paste(Rcmd, "build --keep-empty-dirs", shQuote(dir)),
+                 intern = TRUE)
+     ## return name of tar file built
+     structure(dir('.', pattern = patt), log3 = r)
+ }
> build.pkg("myTst")

[1] "myTst_1.0.tar.gz"
attr(,"log3")
[1] "* checking for file 'myTst/DESCRIPTION' ... OK"                           
[2] "* preparing 'myTst':"                                                     
[3] "* checking DESCRIPTION meta-information ... OK"                           
[4] "* installing the package to process help pages"                           
[5] "* saving partial Rd database"                                             
[6] "* checking for LF line-endings in source and make files and shell scripts"
[7] "* checking for empty or unneeded directories"                             
[8] "* building 'myTst_1.0.tar.gz'"                                            
> ## clean up any previous attempt (which might have left a 00LOCK)
> unlink("myLib", recursive = TRUE)
> dir.create("myLib")
> install.packages("myTst", lib = "myLib", repos=NULL, type = "source") # with warnings
* installing *source* package 'myTst' ...
** using staged installation
** R
** byte-compile and prepare package for lazy loading
** help
Warning: /usr/local/src/stats/R-3.6.2/CentOS/tests/myTst/man/myTst-package.Rd:27: All text must be in a section
Warning: /usr/local/src/stats/R-3.6.2/CentOS/tests/myTst/man/myTst-package.Rd:28: All text must be in a section
*** installing help indices
** building package indices
** testing if installed package can be loaded from temporary location
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation path
* DONE (myTst)
> print(installed.packages(lib.loc= "myLib", priority= "NA"))## (PR#13332)
      Package LibPath Version Priority Depends   Imports LinkingTo Suggests
myTst "myTst" "myLib" "1.0"   NA       "methods" NA      NA        NA      
      Enhances License                     License_is_FOSS
myTst NA       "What license is it under?" NA             
      License_restricts_use OS_type MD5sum NeedsCompilation Built  
myTst NA                    NA      NA     NA               "3.6.2"
> stopifnot(require("myTst",lib = "myLib"))
Loading required package: myTst
> sm <- findMethods(show, where= as.environment("package:myTst"))
> stopifnot(names(sm at names) == "foo")
> unlink("myTst_*")
> 
> ## getPackageName()  for "package:foo":
> require('methods')
> library(tools)
> oo <- options(warn=2)
> detach("package:tools", unload=TRUE)
> options(oo)
> ## gave warning (-> Error) about creating package name
> 
> 
> ## More building & installing packages
> ## NB: tests were added here for 2.11.0.
> ## NB^2: do not do this in the R sources (but in a build != src directory!)
> ## and this testdir is not installed.
> if(interactive() && Sys.getenv("USER") == "maechler")
+     Sys.setenv(SRCDIR = normalizePath("~/R/D/r-devel/R/tests"))
> (pkgSrcPath <- file.path(Sys.getenv("SRCDIR"), "Pkgs"))# e.g., -> "../../R/tests/Pkgs"
[1] "../../tests/Pkgs"
> if(!file_test("-d", pkgSrcPath) && !interactive()) {
+     unlink("myTst", recursive=TRUE)
+     print(proc.time())
+     q("no")
+ }
> ## else w/o clause:
> 
> do.cleanup <- !nzchar(Sys.getenv("R_TESTS_NO_CLEAN"))
> isWIN <- .Platform$OS.type == "windows"
> has.symlink <- !isWIN
> ## Installing "on to" a package existing as symlink in the lib.loc
> ## -- used to fail with misleading error message (#PR 16725):
> 
> if(has.symlink && !unlink("myLib_2", recursive=TRUE) && dir.create("myLib_2") &&
+    file.rename("myLib/myTst", "myLib_2/myTst") &&
+    file.symlink("../myLib_2/myTst", "myLib/myTst"))
+     install.packages("myTst", lib = "myLib", repos=NULL, type = "source")
* installing *source* package 'myTst' ...
** using staged installation
** R
** byte-compile and prepare package for lazy loading
** help
Warning: /usr/local/src/stats/R-3.6.2/CentOS/tests/myTst/man/myTst-package.Rd:27: All text must be in a section
Warning: /usr/local/src/stats/R-3.6.2/CentOS/tests/myTst/man/myTst-package.Rd:28: All text must be in a section
*** installing help indices
** building package indices
** testing if installed package can be loaded from temporary location
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation path
* DONE (myTst)
> ## In R <= 3.3.2 gave error with *misleading* error message:
> ## ERROR: 'myTst' is not a legal package name
> 
> if(isWIN) { # (has no symlinks anyway)
+     file.copy(pkgSrcPath, tempdir(), recursive = TRUE)
+ } else { # above file.copy() not useful as it replaces symlink by copy
+     system(paste('cp -R', shQuote(pkgSrcPath), shQuote(tempdir())))
+ }
> pkgPath <- file.path(tempdir(), "Pkgs")
> if(!dir.exists(pkgPath))  {
+     message("No valid 'pkgPath' (from 'pkgSrcPath') - exit this test")
+     if(!interactive()) q("no")
+ }
> 
> ## pkgB tests an empty R directory
> dir.create(file.path(pkgPath, "pkgB", "R"), recursive = TRUE,
+ 	   showWarnings = FALSE)
> p.lis <- c(if("Matrix" %in% row.names(installed.packages(.Library)))
+                c("pkgA", "pkgB", "pkgC"),
+            "exNSS4", "exSexpr")
> InstOpts <- list("exSexpr" = "--html")
> pkgApath <- file.path(pkgPath, "pkgA")
> if("pkgA" %in% p.lis && !dir.exists(d <- pkgApath)) {
+     cat("symlink 'pkgA' does not exist as directory ",d,"; copying it\n", sep='')
+     file.copy(file.path(pkgPath, "xDir", "pkg"), to = d, recursive=TRUE)
+     ## if even the copy failed (NB: pkgB, pkgC depend on pkgA)
+     if(!dir.exists(d)) p.lis <- p.lis[!(p.lis %in% c("pkgA", "pkgB", "pkgC"))]
+ }
> dir2pkg <- function(dir) ifelse(dir == "pkgC", "PkgC", dir)
> if(is.na(match("myLib", .lP <- .libPaths()))) {
+     .libPaths(c("myLib", .lP)) # PkgC needs pkgA from there
+     .lP <- .libPaths()
+ }
> Sys.setenv(R_LIBS = .R_LIBS(.lP)) # for build.pkg() & install.packages()
> for(p in p.lis) {
+     p. <- dir2pkg(p) # 'p' is sub directory name;  'p.' is package name
+     cat("building package", p., "...\n")
+     r <- build.pkg(file.path(pkgPath, p))
+     if(!length(r)) # so some sort of failure, show log
+         cat(attr(r, "log3"), sep = "\n")
+     if(!isTRUE(file.exists(r)))
+         stop("R CMD build failed (no tarball) for package ", p)
+     ## otherwise install the tar file:
+     cat("installing package", p., "using built file", r, "...\n")
+     ## "FIXME": want to catch warnings in the "console output" of this:
+     install.packages(r, lib = "myLib", repos=NULL, type = "source",
+                      INSTALL_opts = InstOpts[[p.]])
+     stopifnot(require(p., lib = "myLib", character.only=TRUE))
+     detach(pos = match(p., sub("^package:","", search())))
+ }
building package pkgA ...

installing package pkgA using built file pkgA_1.2.tar.gz ...
* installing *source* package 'pkgA' ...
** using staged installation
** R
** data
*** moving datasets to lazyload DB
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded from temporary location
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation path
* DONE (pkgA)
Loading required package: pkgA

Attaching package: 'pkgA'

The following object is masked from 'package:base':

    search

building package pkgB ...

installing package pkgB using built file pkgB_1.0.tar.gz ...
* installing *source* package 'pkgB' ...
** using staged installation
** help
No man pages found in package  'pkgB' 
*** installing help indices
** building package indices
** testing if installed package can be loaded from temporary location
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation path
* DONE (pkgB)
Loading required package: pkgB
building package PkgC ...

installing package PkgC using built file PkgC_1.0-0.tar.gz ...
* installing *source* package 'PkgC' ...
** using staged installation
** R
** byte-compile and prepare package for lazy loading
>From .checkSubclasses(): subclass "classApp" of class "classA" is not local and is not updated for new inheritance information currently; 
[where=<environment: 0x4886478>, where2=<environment: namespace:PkgC>]
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded from temporary location
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation path
* DONE (PkgC)
Loading required package: PkgC
building package exNSS4 ...

installing package exNSS4 using built file exNSS4_1.1.tar.gz ...
* installing *source* package 'exNSS4' ...
** using staged installation
** R
** byte-compile and prepare package for lazy loading
** help
No man pages found in package  'exNSS4' 
*** installing help indices
** building package indices
** testing if installed package can be loaded from temporary location
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation path
* DONE (exNSS4)
Loading required package: exNSS4
building package exSexpr ...
Converting Rd files to LaTeX 
Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  : 
  pdflatex is not available
Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  : 
  pdflatex is not available
Error in running tools::texi2pdf()
* checking for file '/tmp/Rtmp5m0Zx8/Pkgs/exSexpr/DESCRIPTION' ... OK
* preparing 'exSexpr':
* checking DESCRIPTION meta-information ... OK
* installing the package to process help pages
* saving partial Rd database
* building the PDF package manual
Hmm ... looks like a package
Creating pdf output from LaTeX ...
Error: R CMD build failed (no tarball) for package exSexpr
In addition: Warning message:
In system(paste(Rcmd, "build --keep-empty-dirs", shQuote(dir)),  :
  running command ''/usr/local/src/stats/R-3.6.2/CentOS/bin/R' CMD build --keep-empty-dirs '/tmp/Rtmp5m0Zx8/Pkgs/exSexpr'' had status 1
Execution halted

--
Wes

-----Original Message-----
From: Ivan Krylov <krylov.r00t at gmail.com> 
Sent: Wednesday, February 12, 2020 3:37 AM
To: Barris, Wes <Wes.Barris at cobb-vantress.com>
Cc: r-help at r-project.org
Subject: [EXTERNAL] - Re: [R] make check fails -- how to debug

On Tue, 11 Feb 2020 21:26:33 +0000
"Barris, Wes" <Wes.Barris at cobb-vantress.com> wrote:

> running code in '../../tests/reg-packages.R' ...make[3]: *** 
> [reg-packages.Rout] Error 1

tests/Makefile.common has the following in the .R.Rout rule:

        @$(ECHO) $(ECHO_N) "running code in '$<' ...$(ECHO_C)" > $@.log
        @$(R) < $< > $@.fail 2>&1 || (cat $@.log && rm $@.log && exit 1)

> How can I troubleshoot this to find out what is wrong?

Take a look at tests/reg-packages.Rout.fail, it should contain all output produced by tests/reg-packages.R when it ran.

--
Best regards,
Ivan

----------------------------------------------------------------------
This email and any files transmitted with it are confide...{{dropped:11}}


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Feb 12 20:02:37 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 12 Feb 2020 22:02:37 +0300
Subject: [R] make check fails -- how to debug
In-Reply-To: <SN6PR17MB21256C86A461DC701AD924AFD81B0@SN6PR17MB2125.namprd17.prod.outlook.com>
References: <SN6PR17MB2125E546AB5664FE97FC9E53D8180@SN6PR17MB2125.namprd17.prod.outlook.com>
 <20200212123638.3951e996@trisector>
 <SN6PR17MB21256C86A461DC701AD924AFD81B0@SN6PR17MB2125.namprd17.prod.outlook.com>
Message-ID: <20200212220237.1503a54c@trisector>

On Wed, 12 Feb 2020 14:20:55 +0000
"Barris, Wes" <Wes.Barris at cobb-vantress.com> wrote:

> I'm not sure exactly what part of this is the fatal error:

One of the tests is building the package contained in
tests/Pkgs/exSexpr. For some reason, R CMD build failed to produce a
tarball for this package. Try running it yourself and see if it
produces any errors. I don't know for sure whether not being able to
run pdflatex is a blocker when building a package.

-- 
Best regards,
Ivan


From We@@B@rr|@ @end|ng |rom cobb-v@ntre@@@com  Wed Feb 12 20:32:34 2020
From: We@@B@rr|@ @end|ng |rom cobb-v@ntre@@@com (Barris, Wes)
Date: Wed, 12 Feb 2020 19:32:34 +0000
Subject: [R] make check fails -- how to debug
In-Reply-To: <20200212220237.1503a54c@trisector>
References: <SN6PR17MB2125E546AB5664FE97FC9E53D8180@SN6PR17MB2125.namprd17.prod.outlook.com>
 <20200212123638.3951e996@trisector>
 <SN6PR17MB21256C86A461DC701AD924AFD81B0@SN6PR17MB2125.namprd17.prod.outlook.com>
 <20200212220237.1503a54c@trisector>
Message-ID: <SN6PR17MB21252A255EDAB31446290D62D81B0@SN6PR17MB2125.namprd17.prod.outlook.com>

Thanks Ivan.

I would like to manually run the test you mentioned but I don't know how.  I'm not an R user.  I'm only trying to install the latest version on our servers for our users.  Is this what I need to type?

> pwd
/usr/local/src/stats/R-3.6.2/CentOS

./bin/R CMD ../tests/Pkgs/exSexpr

Note: I've installed the (many) rpms for texlive so that pdflatex is available.  Unfortunately, the same test continues to fail.  Here is the latest log:


R version 3.6.2 (2019-12-12) -- "Dark and Stormy Night"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> .R_LIBS <- function(libp = .libPaths()) { # (>> in utils?)
+     libp <- libp[! libp %in% .Library]
+     if(length(libp))
+         paste(libp, collapse = .Platform$path.sep)
+     else "" # character(0) is invalid for Sys.setenv()
+ }
> Sys.setenv(R_LIBS = .R_LIBS() # for build.pkg() & install.packages()
+          , R_BUILD_ENVIRON = "nothing" # avoid ~/.R/build.environ which might set R_LIBS
+          , R_ENVIRON = "none"
+          , R_PROFILE = "none"
+            )
> 
> ## PR 1271  detach("package:base") crashes R.
> tools::assertError(detach("package:base"))
> 
> 
> ## invalid 'lib.loc'
> stopifnot(length(installed.packages("mgcv")) == 0)
> ## gave a low-level error message
> 
> 
> ## package.skeleton() with metadata-only code
> ## work in current (= ./tests/ directory):
> tmp <- tempfile()
> writeLines(c('setClass("foo", contains="numeric")',
+              'setMethod("show", "foo",',
+              '          function(object) cat("I am a \\"foo\\"\\n"))'),
+            tmp)
> if(file.exists("myTst")) unlink("myTst", recursive=TRUE)
> package.skeleton("myTst", code_files = tmp)# with a file name warning
Creating directories ...
Creating DESCRIPTION ...
Creating NAMESPACE ...
Creating Read-and-delete-me ...
Copying code files ...
Making help files ...
Done.
Further steps are described in './myTst/Read-and-delete-me'.
Warning message:
In package.skeleton("myTst", code_files = tmp) :
  Invalid file name(s) for R code in ./myTst/R:
  'file40a593b5a60'
 are now renamed to 'z<name>.R'
> file.copy(tmp, (tm2 <- paste(tmp,".R", sep="")))
[1] TRUE
> unlink("myTst", recursive=TRUE)
> op <- options(warn=2) # *NO* "invalid file name" warning {failed in 2.7.[01]}:
> package.skeleton("myTst", code_files = tm2)
Creating directories ...
Creating DESCRIPTION ...
Creating NAMESPACE ...
Creating Read-and-delete-me ...
Copying code files ...
Making help files ...
Done.
Further steps are described in './myTst/Read-and-delete-me'.
> options(op)
> ##_2_ only a class, no generics/methods:
> writeLines(c('setClass("DocLink",',
+              'representation(name="character",',
+              '               desc="character"))'), tmp)
> if(file.exists("myTst2")) unlink("myTst2", recursive=TRUE)
> package.skeleton("myTst2", code_files = tmp)
Creating directories ...
Creating DESCRIPTION ...
Creating NAMESPACE ...
Creating Read-and-delete-me ...
Copying code files ...
Making help files ...
Done.
Further steps are described in './myTst2/Read-and-delete-me'.
Warning message:
In package.skeleton("myTst2", code_files = tmp) :
  Invalid file name(s) for R code in ./myTst2/R:
  'file40a593b5a60'
 are now renamed to 'z<name>.R'
> ##- end_2_ # failed in R 2.11.0
> stopifnot(1 == grep("setClass",
+ 	  readLines(list.files("myTst/R", full.names=TRUE))),
+ 	  c("foo-class.Rd","show-methods.Rd") %in% list.files("myTst/man"))
> ## failed for several reasons in R < 2.7.0
> ##
> ## Part 2: -- build, install, load and "inspect" the package:
> build.pkg <- function(dir) {
+     stopifnot(dir.exists(dir), file.exists(DESC <- file.path(dir, "DESCRIPTION")))
+     pkgName <- sub("^[A-Za-z]+: ", "", grep("^Package: ", readLines(DESC), value=TRUE))
+     patt <- paste(pkgName, ".*tar\\.gz$", sep="_")
+     unlink(dir('.', pattern = patt))
+     Rcmd <- paste(shQuote(file.path(R.home("bin"), "R")), "CMD")
+     r <- system(paste(Rcmd, "build --keep-empty-dirs", shQuote(dir)),
+                 intern = TRUE)
+     ## return name of tar file built
+     structure(dir('.', pattern = patt), log3 = r)
+ }
> build.pkg("myTst")

[1] "myTst_1.0.tar.gz"
attr(,"log3")
[1] "* checking for file 'myTst/DESCRIPTION' ... OK"                           
[2] "* preparing 'myTst':"                                                     
[3] "* checking DESCRIPTION meta-information ... OK"                           
[4] "* installing the package to process help pages"                           
[5] "* saving partial Rd database"                                             
[6] "* checking for LF line-endings in source and make files and shell scripts"
[7] "* checking for empty or unneeded directories"                             
[8] "* building 'myTst_1.0.tar.gz'"                                            
> ## clean up any previous attempt (which might have left a 00LOCK)
> unlink("myLib", recursive = TRUE)
> dir.create("myLib")
> install.packages("myTst", lib = "myLib", repos=NULL, type = "source") # with warnings
* installing *source* package 'myTst' ...
** using staged installation
** R
** byte-compile and prepare package for lazy loading
** help
Warning: /usr/local/src/stats/R-3.6.2/CentOS/tests/myTst/man/myTst-package.Rd:27: All text must be in a section
Warning: /usr/local/src/stats/R-3.6.2/CentOS/tests/myTst/man/myTst-package.Rd:28: All text must be in a section
*** installing help indices
** building package indices
** testing if installed package can be loaded from temporary location
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation path
* DONE (myTst)
> print(installed.packages(lib.loc= "myLib", priority= "NA"))## (PR#13332)
      Package LibPath Version Priority Depends   Imports LinkingTo Suggests
myTst "myTst" "myLib" "1.0"   NA       "methods" NA      NA        NA      
      Enhances License                     License_is_FOSS
myTst NA       "What license is it under?" NA             
      License_restricts_use OS_type MD5sum NeedsCompilation Built  
myTst NA                    NA      NA     NA               "3.6.2"
> stopifnot(require("myTst",lib = "myLib"))
Loading required package: myTst
> sm <- findMethods(show, where= as.environment("package:myTst"))
> stopifnot(names(sm at names) == "foo")
> unlink("myTst_*")
> 
> ## getPackageName()  for "package:foo":
> require('methods')
> library(tools)
> oo <- options(warn=2)
> detach("package:tools", unload=TRUE)
> options(oo)
> ## gave warning (-> Error) about creating package name
> 
> 
> ## More building & installing packages
> ## NB: tests were added here for 2.11.0.
> ## NB^2: do not do this in the R sources (but in a build != src directory!)
> ## and this testdir is not installed.
> if(interactive() && Sys.getenv("USER") == "maechler")
+     Sys.setenv(SRCDIR = normalizePath("~/R/D/r-devel/R/tests"))
> (pkgSrcPath <- file.path(Sys.getenv("SRCDIR"), "Pkgs"))# e.g., -> "../../R/tests/Pkgs"
[1] "../../tests/Pkgs"
> if(!file_test("-d", pkgSrcPath) && !interactive()) {
+     unlink("myTst", recursive=TRUE)
+     print(proc.time())
+     q("no")
+ }
> ## else w/o clause:
> 
> do.cleanup <- !nzchar(Sys.getenv("R_TESTS_NO_CLEAN"))
> isWIN <- .Platform$OS.type == "windows"
> has.symlink <- !isWIN
> ## Installing "on to" a package existing as symlink in the lib.loc
> ## -- used to fail with misleading error message (#PR 16725):
> 
> if(has.symlink && !unlink("myLib_2", recursive=TRUE) && dir.create("myLib_2") &&
+    file.rename("myLib/myTst", "myLib_2/myTst") &&
+    file.symlink("../myLib_2/myTst", "myLib/myTst"))
+     install.packages("myTst", lib = "myLib", repos=NULL, type = "source")
* installing *source* package 'myTst' ...
** using staged installation
** R
** byte-compile and prepare package for lazy loading
** help
Warning: /usr/local/src/stats/R-3.6.2/CentOS/tests/myTst/man/myTst-package.Rd:27: All text must be in a section
Warning: /usr/local/src/stats/R-3.6.2/CentOS/tests/myTst/man/myTst-package.Rd:28: All text must be in a section
*** installing help indices
** building package indices
** testing if installed package can be loaded from temporary location
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation path
* DONE (myTst)
> ## In R <= 3.3.2 gave error with *misleading* error message:
> ## ERROR: 'myTst' is not a legal package name
> 
> if(isWIN) { # (has no symlinks anyway)
+     file.copy(pkgSrcPath, tempdir(), recursive = TRUE)
+ } else { # above file.copy() not useful as it replaces symlink by copy
+     system(paste('cp -R', shQuote(pkgSrcPath), shQuote(tempdir())))
+ }
> pkgPath <- file.path(tempdir(), "Pkgs")
> if(!dir.exists(pkgPath))  {
+     message("No valid 'pkgPath' (from 'pkgSrcPath') - exit this test")
+     if(!interactive()) q("no")
+ }
> 
> ## pkgB tests an empty R directory
> dir.create(file.path(pkgPath, "pkgB", "R"), recursive = TRUE,
+ 	   showWarnings = FALSE)
> p.lis <- c(if("Matrix" %in% row.names(installed.packages(.Library)))
+                c("pkgA", "pkgB", "pkgC"),
+            "exNSS4", "exSexpr")
> InstOpts <- list("exSexpr" = "--html")
> pkgApath <- file.path(pkgPath, "pkgA")
> if("pkgA" %in% p.lis && !dir.exists(d <- pkgApath)) {
+     cat("symlink 'pkgA' does not exist as directory ",d,"; copying it\n", sep='')
+     file.copy(file.path(pkgPath, "xDir", "pkg"), to = d, recursive=TRUE)
+     ## if even the copy failed (NB: pkgB, pkgC depend on pkgA)
+     if(!dir.exists(d)) p.lis <- p.lis[!(p.lis %in% c("pkgA", "pkgB", "pkgC"))]
+ }
> dir2pkg <- function(dir) ifelse(dir == "pkgC", "PkgC", dir)
> if(is.na(match("myLib", .lP <- .libPaths()))) {
+     .libPaths(c("myLib", .lP)) # PkgC needs pkgA from there
+     .lP <- .libPaths()
+ }
> Sys.setenv(R_LIBS = .R_LIBS(.lP)) # for build.pkg() & install.packages()
> for(p in p.lis) {
+     p. <- dir2pkg(p) # 'p' is sub directory name;  'p.' is package name
+     cat("building package", p., "...\n")
+     r <- build.pkg(file.path(pkgPath, p))
+     if(!length(r)) # so some sort of failure, show log
+         cat(attr(r, "log3"), sep = "\n")
+     if(!isTRUE(file.exists(r)))
+         stop("R CMD build failed (no tarball) for package ", p)
+     ## otherwise install the tar file:
+     cat("installing package", p., "using built file", r, "...\n")
+     ## "FIXME": want to catch warnings in the "console output" of this:
+     install.packages(r, lib = "myLib", repos=NULL, type = "source",
+                      INSTALL_opts = InstOpts[[p.]])
+     stopifnot(require(p., lib = "myLib", character.only=TRUE))
+     detach(pos = match(p., sub("^package:","", search())))
+ }
building package pkgA ...

installing package pkgA using built file pkgA_1.2.tar.gz ...
* installing *source* package 'pkgA' ...
** using staged installation
** R
** data
*** moving datasets to lazyload DB
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded from temporary location
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation path
* DONE (pkgA)
Loading required package: pkgA

Attaching package: 'pkgA'

The following object is masked from 'package:base':

    search

building package pkgB ...

installing package pkgB using built file pkgB_1.0.tar.gz ...
* installing *source* package 'pkgB' ...
** using staged installation
** help
No man pages found in package  'pkgB' 
*** installing help indices
** building package indices
** testing if installed package can be loaded from temporary location
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation path
* DONE (pkgB)
Loading required package: pkgB
building package PkgC ...

installing package PkgC using built file PkgC_1.0-0.tar.gz ...
* installing *source* package 'PkgC' ...
** using staged installation
** R
** byte-compile and prepare package for lazy loading
>From .checkSubclasses(): subclass "classApp" of class "classA" is not local and is not updated for new inheritance information currently; 
[where=<environment: 0x36b9388>, where2=<environment: namespace:PkgC>]
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded from temporary location
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation path
* DONE (PkgC)
Loading required package: PkgC
building package exNSS4 ...

installing package exNSS4 using built file exNSS4_1.1.tar.gz ...
* installing *source* package 'exNSS4' ...
** using staged installation
** R
** byte-compile and prepare package for lazy loading
** help
No man pages found in package  'exNSS4' 
*** installing help indices
** building package indices
** testing if installed package can be loaded from temporary location
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation path
* DONE (exNSS4)
Loading required package: exNSS4
building package exSexpr ...
Converting Rd files to LaTeX 

kpathsea: Running mktextfm cmr10
/usr/share/texlive/texmf/web2c/mktexnam: Could not map source abbreviation  for cmr10.
/usr/share/texlive/texmf/web2c/mktexnam: Need to update ?
mktextfm: Running mf \mode:=ljfour; mag:=1; nonstopmode; input cmr10
/bin/mktextfm: line 96: mf: command not found
grep: cmr10.log: No such file or directory
mktextfm: `mf \mode:=ljfour; mag:=1; nonstopmode; input cmr10' failed to make cmr10.tfm.
kpathsea: Appending font creation commands to missfont.log.

kpathsea: Running mktextfm ecrm1000
/usr/share/texlive/texmf/web2c/mktexnam: Could not map source abbreviation  for ecrm1000.
/usr/share/texlive/texmf/web2c/mktexnam: Need to update ?
mktextfm: Running mf \mode:=ljfour; mag:=1; nonstopmode; input ecrm1000
/bin/mktextfm: line 96: mf: command not found
grep: ecrm1000.log: No such file or directory
mktextfm: `mf \mode:=ljfour; mag:=1; nonstopmode; input ecrm1000' failed to make ecrm1000.tfm.
Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  : 
  unable to run 'pdflatex' on 'Rd2.tex'

kpathsea: Running mktextfm cmr10
/usr/share/texlive/texmf/web2c/mktexnam: Could not map source abbreviation  for cmr10.
/usr/share/texlive/texmf/web2c/mktexnam: Need to update ?
mktextfm: Running mf \mode:=ljfour; mag:=1; nonstopmode; input cmr10
/bin/mktextfm: line 96: mf: command not found
grep: cmr10.log: No such file or directory
mktextfm: `mf \mode:=ljfour; mag:=1; nonstopmode; input cmr10' failed to make cmr10.tfm.
kpathsea: Appending font creation commands to missfont.log.

kpathsea: Running mktextfm ecrm1000
/usr/share/texlive/texmf/web2c/mktexnam: Could not map source abbreviation  for ecrm1000.
/usr/share/texlive/texmf/web2c/mktexnam: Need to update ?
mktextfm: Running mf \mode:=ljfour; mag:=1; nonstopmode; input ecrm1000
/bin/mktextfm: line 96: mf: command not found
grep: ecrm1000.log: No such file or directory
mktextfm: `mf \mode:=ljfour; mag:=1; nonstopmode; input ecrm1000' failed to make ecrm1000.tfm.
Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  : 
  unable to run 'pdflatex' on 'Rd2.tex'
Error in running tools::texi2pdf()
* checking for file '/tmp/RtmpXDYvcp/Pkgs/exSexpr/DESCRIPTION' ... OK
* preparing 'exSexpr':
* checking DESCRIPTION meta-information ... OK
* installing the package to process help pages
* saving partial Rd database
* building the PDF package manual
Hmm ... looks like a package
Creating pdf output from LaTeX ...
This is pdfTeX, Version 3.1415926-2.5-1.40.14 (TeX Live 2013)
 restricted \write18 enabled.
entering extended mode
(./Rd2.tex
LaTeX2e <2011/06/27>
Babel <v3.8m> and hyphenation patterns for english, dumylang, nohyphenation, lo
aded.
(/usr/share/texlive/texmf-dist/tex/latex/base/book.cls
Document Class: book 2007/10/19 v1.4h Standard LaTeX document class
(/usr/share/texlive/texmf-dist/tex/latex/base/bk10.clo
! Font OT1/cmr/m/n/10=cmr10 at 10.0pt not loadable: Metric (TFM) file not found
.
<to be read again> 
                   relax 
l.64 \normalsize
                
)) (/usr/local/src/stats/R-3.6.2/CentOS/share/texmf/tex/latex/Rd.sty
(/usr/share/texlive/texmf-dist/tex/latex/base/ifthen.sty)
(/usr/share/texlive/texmf-dist/tex/latex/tools/longtable.sty)
(/usr/share/texlive/texmf-dist/tex/latex/tools/bm.sty)
(/usr/share/texlive/texmf-dist/tex/latex/base/alltt.sty)
(/usr/share/texlive/texmf-dist/tex/latex/tools/verbatim.sty)
(/usr/share/texlive/texmf-dist/tex/latex/url/url.sty)
(/usr/share/texlive/texmf-dist/tex/latex/base/textcomp.sty
(/usr/share/texlive/texmf-dist/tex/latex/base/ts1enc.def))
(/usr/share/texlive/texmf-dist/tex/latex/base/fontenc.sty
(/usr/share/texlive/texmf-dist/tex/latex/base/t1enc.def)
! Font T1/cmr/m/n/10=ecrm1000 at 10.0pt not loadable: Metric (TFM) file not fou
nd.
<to be read again> 
                   relax 
l.100 \fontencoding\encodingdefault\selectfont
                                              
) (/usr/share/texlive/texmf-dist/tex/latex/psnfss/times.sty)

! LaTeX Error: File `inconsolata.sty' not found.

Type X to quit or <RETURN> to proceed,
or enter new name. (Default extension: sty)

Enter file name: 
! Emergency stop.
<read *> 
         
l.287 ^^M
         
!  ==> Fatal error occurred, no output PDF file produced!
Transcript written on Rd2.log.
This is pdfTeX, Version 3.1415926-2.5-1.40.14 (TeX Live 2013)
 restricted \write18 enabled.
entering extended mode
(./Rd2.tex
LaTeX2e <2011/06/27>
Babel <v3.8m> and hyphenation patterns for english, dumylang, nohyphenation, lo
aded.
(/usr/share/texlive/texmf-dist/tex/latex/base/book.cls
Document Class: book 2007/10/19 v1.4h Standard LaTeX document class
(/usr/share/texlive/texmf-dist/tex/latex/base/bk10.clo
! Font OT1/cmr/m/n/10=cmr10 at 10.0pt not loadable: Metric (TFM) file not found
.
<to be read again> 
                   relax 
l.64 \normalsize
                
)) (/usr/local/src/stats/R-3.6.2/CentOS/share/texmf/tex/latex/Rd.sty
(/usr/share/texlive/texmf-dist/tex/latex/base/ifthen.sty)
(/usr/share/texlive/texmf-dist/tex/latex/tools/longtable.sty)
(/usr/share/texlive/texmf-dist/tex/latex/tools/bm.sty)
(/usr/share/texlive/texmf-dist/tex/latex/base/alltt.sty)
(/usr/share/texlive/texmf-dist/tex/latex/tools/verbatim.sty)
(/usr/share/texlive/texmf-dist/tex/latex/url/url.sty)
(/usr/share/texlive/texmf-dist/tex/latex/base/textcomp.sty
(/usr/share/texlive/texmf-dist/tex/latex/base/ts1enc.def))
(/usr/share/texlive/texmf-dist/tex/latex/base/fontenc.sty
(/usr/share/texlive/texmf-dist/tex/latex/base/t1enc.def)
! Font T1/cmr/m/n/10=ecrm1000 at 10.0pt not loadable: Metric (TFM) file not fou
nd.
<to be read again> 
                   relax 
l.100 \fontencoding\encodingdefault\selectfont
                                              
) (/usr/share/texlive/texmf-dist/tex/latex/psnfss/times.sty)

! LaTeX Error: File `inconsolata.sty' not found.

Type X to quit or <RETURN> to proceed,
or enter new name. (Default extension: sty)

Enter file name: 
! Emergency stop.
<read *> 
         
l.287 ^^M
         
!  ==> Fatal error occurred, no output PDF file produced!
Transcript written on Rd2.log.
Error: R CMD build failed (no tarball) for package exSexpr
In addition: Warning message:
In system(paste(Rcmd, "build --keep-empty-dirs", shQuote(dir)),  :
  running command ''/usr/local/src/stats/R-3.6.2/CentOS/bin/R' CMD build --keep-empty-dirs '/tmp/RtmpXDYvcp/Pkgs/exSexpr'' had status 1
Execution halted
--
Wes

-----Original Message-----
From: Ivan Krylov <krylov.r00t at gmail.com> 
Sent: Wednesday, February 12, 2020 1:03 PM
To: Barris, Wes <Wes.Barris at cobb-vantress.com>
Cc: r-help at r-project.org
Subject: [EXTERNAL] - Re: Re: [R] make check fails -- how to debug

On Wed, 12 Feb 2020 14:20:55 +0000
"Barris, Wes" <Wes.Barris at cobb-vantress.com> wrote:

> I'm not sure exactly what part of this is the fatal error:

One of the tests is building the package contained in tests/Pkgs/exSexpr. For some reason, R CMD build failed to produce a tarball for this package. Try running it yourself and see if it produces any errors. I don't know for sure whether not being able to run pdflatex is a blocker when building a package.

--
Best regards,
Ivan

----------------------------------------------------------------------
This email and any files transmitted with it are confide...{{dropped:11}}


From stei@@@duke m@iii@g oii gm@ii@com  Wed Feb 12 21:39:42 2020
From: stei@@@duke m@iii@g oii gm@ii@com (stei@@@duke m@iii@g oii gm@ii@com)
Date: Wed, 12 Feb 2020 21:39:42 +0100
Subject: [R] Aggregate individual level data to age categories
Message-ID: <CALBFSbOhVYBTfG6ULteeHc48UdnhTEyDeZccaeCnc=aicRUaRg@mail.gmail.com>

Dear All,

I have a seemingly standard problem to which I somehow I do  not find
a simple solution. I have individual level data where x is a
categorical variable with 3 categories which I would like to aggregate
by age.

age x
45   1
45   2
46   1
47   3
47   3
 and so on.

It should after transformation look like that

age x_1 x_2 x_3
45    1     0   1
46    1     0   0
47     0    0   2

Basically to calculate prevalences by age categories.

Thanks for any pointers!

Cheers!


From stei@@@duke m@iii@g oii gm@ii@com  Wed Feb 12 22:11:49 2020
From: stei@@@duke m@iii@g oii gm@ii@com (stei@@@duke m@iii@g oii gm@ii@com)
Date: Wed, 12 Feb 2020 22:11:49 +0100
Subject: [R] Aggregate individual level data to age categories
In-Reply-To: <4f70c800-2ec5-403f-b1e6-b860f239157f@email.android.com>
References: <CALBFSbOhVYBTfG6ULteeHc48UdnhTEyDeZccaeCnc=aicRUaRg@mail.gmail.com>
 <4f70c800-2ec5-403f-b1e6-b860f239157f@email.android.com>
Message-ID: <CALBFSbMS3V3U4bPBjZBtdmhEMbM5Bm-=+18pRF9Lnq7Qe+JzAg@mail.gmail.com>

well, if I think about, its actually a simple frequency table grouped
by age. but it should be usable a matrix or data frame.

On Wed, Feb 12, 2020 at 9:48 PM <cpolwart at chemo.org.uk> wrote:
>
> So a pivot table?
>
> On 12 Feb 2020 20:39, stefan.duke at gmail.com wrote:
>
> Dear All,
>
> I have a seemingly standard problem to which I somehow I do  not find
> a simple solution. I have individual level data where x is a
> categorical variable with 3 categories which I would like to aggregate
> by age.
>
> age x
> 45   1
> 45   2
> 46   1
> 47   3
> 47   3
> and so on.
>
> It should after transformation look like that
>
> age x_1 x_2 x_3
> 45    1     0   1
> 46    1     0   0
> 47     0    0   2
>
> Basically to calculate prevalences by age categories.
>
> Thanks for any pointers!
>
> Cheers!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From wdun|@p @end|ng |rom t|bco@com  Wed Feb 12 22:25:32 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Wed, 12 Feb 2020 13:25:32 -0800
Subject: [R] Aggregate individual level data to age categories
In-Reply-To: <CALBFSbMS3V3U4bPBjZBtdmhEMbM5Bm-=+18pRF9Lnq7Qe+JzAg@mail.gmail.com>
References: <CALBFSbOhVYBTfG6ULteeHc48UdnhTEyDeZccaeCnc=aicRUaRg@mail.gmail.com>
 <4f70c800-2ec5-403f-b1e6-b860f239157f@email.android.com>
 <CALBFSbMS3V3U4bPBjZBtdmhEMbM5Bm-=+18pRF9Lnq7Qe+JzAg@mail.gmail.com>
Message-ID: <CAF8bMca0JMZCyDcvVx_Bfeo8233HmUaH6xE1qU_r-XXJr4un2w@mail.gmail.com>

You didn't say how you wanted to use it as a data.frame, but here is one way

d <- data.frame(
    check.names = FALSE,
    age = c(45L, 45L, 46L, 47L, 47L),
    x = c(1L, 2L, 1L, 3L, 3L))
with(d, as.data.frame(table(age,x)))

which gives:
  age x Freq
1  45 1    1
2  46 1    1
3  47 1    0
4  45 2    1
5  46 2    0
6  47 2    0
7  45 3    0
8  46 3    0
9  47 3    2

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Feb 12, 2020 at 1:12 PM stefan.duke at gmail.com <stefan.duke at gmail.com>
wrote:

> well, if I think about, its actually a simple frequency table grouped
> by age. but it should be usable a matrix or data frame.
>
> On Wed, Feb 12, 2020 at 9:48 PM <cpolwart at chemo.org.uk> wrote:
> >
> > So a pivot table?
> >
> > On 12 Feb 2020 20:39, stefan.duke at gmail.com wrote:
> >
> > Dear All,
> >
> > I have a seemingly standard problem to which I somehow I do  not find
> > a simple solution. I have individual level data where x is a
> > categorical variable with 3 categories which I would like to aggregate
> > by age.
> >
> > age x
> > 45   1
> > 45   2
> > 46   1
> > 47   3
> > 47   3
> > and so on.
> >
> > It should after transformation look like that
> >
> > age x_1 x_2 x_3
> > 45    1     0   1
> > 46    1     0   0
> > 47     0    0   2
> >
> > Basically to calculate prevalences by age categories.
> >
> > Thanks for any pointers!
> >
> > Cheers!
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Feb 12 22:42:55 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 13 Feb 2020 00:42:55 +0300
Subject: [R] make check fails -- how to debug
In-Reply-To: <SN6PR17MB21252A255EDAB31446290D62D81B0@SN6PR17MB2125.namprd17.prod.outlook.com>
References: <SN6PR17MB2125E546AB5664FE97FC9E53D8180@SN6PR17MB2125.namprd17.prod.outlook.com>
 <20200212123638.3951e996@trisector>
 <SN6PR17MB21256C86A461DC701AD924AFD81B0@SN6PR17MB2125.namprd17.prod.outlook.com>
 <20200212220237.1503a54c@trisector>
 <SN6PR17MB21252A255EDAB31446290D62D81B0@SN6PR17MB2125.namprd17.prod.outlook.com>
Message-ID: <20200213004255.6a963c65@Tarkus>

On Wed, 12 Feb 2020 19:32:34 +0000
"Barris, Wes" <Wes.Barris at cobb-vantress.com> wrote:

> I'm only trying to install the latest version on our servers for our
> users.

Are you allowed to use EPEL? This seems to be the officialy supported
way of installing latest R on CentOS [1]. It might be a good idea to
ask in R-SIG-Fedora [2] instead of R-help, too.

> Is this what I need to type?

The following command should more or less reproduce the test:

cd "$(mktemp -d)"

/usr/local/src/stats/R-3.6.2/CentOS/bin/R CMD build \
  --keep-empty-dirs /usr/local/src/stats/R-3.6.2/CentOS/tests/Pkgs/exSexpr

But the problem seems evident even without that.

> Note: I've installed the (many) rpms for texlive so that pdflatex is
> available.  Unfortunately, the same test continues to fail.  Here is
> the latest log:

<...>

> ! LaTeX Error: File `inconsolata.sty' not found.

Not sure whether Inconsolata [3] is packaged for CentOS, but it seems
to be required to build the documentation. It might be possible to
disable the use of this font [4], but I don't understand enough LaTeX
to comment on it further.

Either way, people on R-SIG-Fedora should be able to provide better
help installing latest R on a CentOS server than me.

-- 
Best regards,
Ivan

[1] https://cloud.r-project.org/bin/linux/redhat/README

[2] https://stat.ethz.ch/mailman/listinfo/r-sig-fedora

[3] https://www.ctan.org/tex-archive/fonts/inconsolata/

[4] https://stackoverflow.com/a/34524358


From stei@@@duke m@iii@g oii gm@ii@com  Wed Feb 12 22:45:54 2020
From: stei@@@duke m@iii@g oii gm@ii@com (stei@@@duke m@iii@g oii gm@ii@com)
Date: Wed, 12 Feb 2020 22:45:54 +0100
Subject: [R] Aggregate individual level data to age categories
In-Reply-To: <CAF8bMca0JMZCyDcvVx_Bfeo8233HmUaH6xE1qU_r-XXJr4un2w@mail.gmail.com>
References: <CALBFSbOhVYBTfG6ULteeHc48UdnhTEyDeZccaeCnc=aicRUaRg@mail.gmail.com>
 <4f70c800-2ec5-403f-b1e6-b860f239157f@email.android.com>
 <CALBFSbMS3V3U4bPBjZBtdmhEMbM5Bm-=+18pRF9Lnq7Qe+JzAg@mail.gmail.com>
 <CAF8bMca0JMZCyDcvVx_Bfeo8233HmUaH6xE1qU_r-XXJr4un2w@mail.gmail.com>
Message-ID: <CALBFSbO9=w_0bSfyHok7mEN702WxPvRG7EU4vvABdij7O7CZVw@mail.gmail.com>

Thank you, this is already very helpful.

But how do I get it in the form
age  var_x=1  var_x=2  var_x=3
45     1              1             0
46      1              0            0

So it would be a data frame with 4 variables.

Cheers!

On Wed, Feb 12, 2020 at 10:25 PM William Dunlap <wdunlap at tibco.com> wrote:
>
> You didn't say how you wanted to use it as a data.frame, but here is one way
>
> d <- data.frame(
>     check.names = FALSE,
>     age = c(45L, 45L, 46L, 47L, 47L),
>     x = c(1L, 2L, 1L, 3L, 3L))
> with(d, as.data.frame(table(age,x)))
>
> which gives:
>   age x Freq
> 1  45 1    1
> 2  46 1    1
> 3  47 1    0
> 4  45 2    1
> 5  46 2    0
> 6  47 2    0
> 7  45 3    0
> 8  46 3    0
> 9  47 3    2
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Feb 12, 2020 at 1:12 PM stefan.duke at gmail.com <stefan.duke at gmail.com> wrote:
>>
>> well, if I think about, its actually a simple frequency table grouped
>> by age. but it should be usable a matrix or data frame.
>>
>> On Wed, Feb 12, 2020 at 9:48 PM <cpolwart at chemo.org.uk> wrote:
>> >
>> > So a pivot table?
>> >
>> > On 12 Feb 2020 20:39, stefan.duke at gmail.com wrote:
>> >
>> > Dear All,
>> >
>> > I have a seemingly standard problem to which I somehow I do  not find
>> > a simple solution. I have individual level data where x is a
>> > categorical variable with 3 categories which I would like to aggregate
>> > by age.
>> >
>> > age x
>> > 45   1
>> > 45   2
>> > 46   1
>> > 47   3
>> > 47   3
>> > and so on.
>> >
>> > It should after transformation look like that
>> >
>> > age x_1 x_2 x_3
>> > 45    1     0   1
>> > 46    1     0   0
>> > 47     0    0   2
>> >
>> > Basically to calculate prevalences by age categories.
>> >
>> > Thanks for any pointers!
>> >
>> > Cheers!
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Wed Feb 12 23:29:07 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 13 Feb 2020 09:29:07 +1100
Subject: [R] Aggregate individual level data to age categories
In-Reply-To: <CALBFSbOhVYBTfG6ULteeHc48UdnhTEyDeZccaeCnc=aicRUaRg@mail.gmail.com>
References: <CALBFSbOhVYBTfG6ULteeHc48UdnhTEyDeZccaeCnc=aicRUaRg@mail.gmail.com>
Message-ID: <CA+8X3fVtoE9cu_1VibugkyoA_UGE67Ejn7M5HbrKyLrX1wHNLw@mail.gmail.com>

Hi Stefan,
How about this:

sddf<-read.table(text="age x
45   1
45   2
46   1
47   3
47   3",
header=TRUE)
library(prettyR)
sdtab<-xtab(age~x,sddf)
sdtab$counts

Jim

On Thu, Feb 13, 2020 at 7:40 AM stefan.duke at gmail.com
<stefan.duke at gmail.com> wrote:
>
> Dear All,
>
> I have a seemingly standard problem to which I somehow I do  not find
> a simple solution. I have individual level data where x is a
> categorical variable with 3 categories which I would like to aggregate
> by age.
>
> age x
> 45   1
> 45   2
> 46   1
> 47   3
> 47   3
>  and so on.
>
> It should after transformation look like that
>
> age x_1 x_2 x_3
> 45    1     0   1
> 46    1     0   0
> 47     0    0   2
>
> Basically to calculate prevalences by age categories.
>
> Thanks for any pointers!
>
> Cheers!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From stei@@@duke m@iii@g oii gm@ii@com  Thu Feb 13 00:10:14 2020
From: stei@@@duke m@iii@g oii gm@ii@com (stei@@@duke m@iii@g oii gm@ii@com)
Date: Thu, 13 Feb 2020 00:10:14 +0100
Subject: [R] Aggregate individual level data to age categories
In-Reply-To: <CA+8X3fVtoE9cu_1VibugkyoA_UGE67Ejn7M5HbrKyLrX1wHNLw@mail.gmail.com>
References: <CALBFSbOhVYBTfG6ULteeHc48UdnhTEyDeZccaeCnc=aicRUaRg@mail.gmail.com>
 <CA+8X3fVtoE9cu_1VibugkyoA_UGE67Ejn7M5HbrKyLrX1wHNLw@mail.gmail.com>
Message-ID: <CALBFSbPDaWqUf-XxBDvU4Yvf1DBv8OJOxz2i-VSxJkU4yQ-8wA@mail.gmail.com>

Thank you!
This is exactly what I was looking for!
Cheers!


On Wed, Feb 12, 2020 at 11:29 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Stefan,
> How about this:
>
> sddf<-read.table(text="age x
> 45   1
> 45   2
> 46   1
> 47   3
> 47   3",
> header=TRUE)
> library(prettyR)
> sdtab<-xtab(age~x,sddf)
> sdtab$counts
>
> Jim
>
> On Thu, Feb 13, 2020 at 7:40 AM stefan.duke at gmail.com
> <stefan.duke at gmail.com> wrote:
> >
> > Dear All,
> >
> > I have a seemingly standard problem to which I somehow I do  not find
> > a simple solution. I have individual level data where x is a
> > categorical variable with 3 categories which I would like to aggregate
> > by age.
> >
> > age x
> > 45   1
> > 45   2
> > 46   1
> > 47   3
> > 47   3
> >  and so on.
> >
> > It should after transformation look like that
> >
> > age x_1 x_2 x_3
> > 45    1     0   1
> > 46    1     0   0
> > 47     0    0   2
> >
> > Basically to calculate prevalences by age categories.
> >
> > Thanks for any pointers!
> >
> > Cheers!
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Feb 13 02:24:11 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 12 Feb 2020 20:24:11 -0500
Subject: [R] make check fails -- how to debug
In-Reply-To: <20200213004255.6a963c65@Tarkus>
References: <SN6PR17MB2125E546AB5664FE97FC9E53D8180@SN6PR17MB2125.namprd17.prod.outlook.com>
 <20200212123638.3951e996@trisector>
 <SN6PR17MB21256C86A461DC701AD924AFD81B0@SN6PR17MB2125.namprd17.prod.outlook.com>
 <20200212220237.1503a54c@trisector>
 <SN6PR17MB21252A255EDAB31446290D62D81B0@SN6PR17MB2125.namprd17.prod.outlook.com>
 <20200213004255.6a963c65@Tarkus>
Message-ID: <4ce40f80-cb9c-e04f-820f-0fdde7955a39@gmail.com>

On 12/02/2020 4:42 p.m., Ivan Krylov wrote:
> On Wed, 12 Feb 2020 19:32:34 +0000
> "Barris, Wes" <Wes.Barris at cobb-vantress.com> wrote:
> 
>> I'm only trying to install the latest version on our servers for our
>> users.
> 
> Are you allowed to use EPEL? This seems to be the officialy supported
> way of installing latest R on CentOS [1]. It might be a good idea to
> ask in R-SIG-Fedora [2] instead of R-help, too.
> 
>> Is this what I need to type?
> 
> The following command should more or less reproduce the test:
> 
> cd "$(mktemp -d)"
> 
> /usr/local/src/stats/R-3.6.2/CentOS/bin/R CMD build \
>    --keep-empty-dirs /usr/local/src/stats/R-3.6.2/CentOS/tests/Pkgs/exSexpr
> 
> But the problem seems evident even without that.
> 
>> Note: I've installed the (many) rpms for texlive so that pdflatex is
>> available.  Unfortunately, the same test continues to fail.  Here is
>> the latest log:
> 
> <...>
> 
>> ! LaTeX Error: File `inconsolata.sty' not found.
> 
> Not sure whether Inconsolata [3] is packaged for CentOS, but it seems
> to be required to build the documentation. It might be possible to
> disable the use of this font [4], but I don't understand enough LaTeX
> to comment on it further.
> 
> Either way, people on R-SIG-Fedora should be able to provide better
> help installing latest R on a CentOS server than me.

I just had a similar error on Ubuntu.  Inconsolata is not a standard 
TeXLive font, on Ubuntu you need to install texlive-fonts-extra to get it.

Duncan Murdoch


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Feb 13 05:58:39 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 13 Feb 2020 17:58:39 +1300
Subject: [R] Increasing space for main title in a lattice (xyplot())
 graphics.
Message-ID: <79e54b0b-fe3b-ddf2-51df-6b79f8be6bf5@auckland.ac.nz>


I'm trying to do an xyplot() with a longish main title that I'd like to 
split into two lines, something like

     xyplot(<whatever>,
            main="The quick brown fox jumped\n over the lazy dog.")

When I do this I only get the last half, i.e. the "over the lazy dog."
bit, and the first half doesn't appear.

In base graphics I'd handle this sort of thing by increasing the third 
entry of the "mar" parameter.

How can increase the space allocated for the title in lattice graphics?
I've done a substantial amount of Googling and can't find anything 
helpful.  I've fiddled about with trellis.par.set() and cannot seem to
get any effect.

Could someone please give my poor feeble brain some guidance?  Ta.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From rmh @end|ng |rom temp|e@edu  Thu Feb 13 06:07:59 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Thu, 13 Feb 2020 00:07:59 -0500
Subject: [R] Increasing space for main title in a lattice (xyplot())
 graphics.
In-Reply-To: <79e54b0b-fe3b-ddf2-51df-6b79f8be6bf5@auckland.ac.nz>
References: <79e54b0b-fe3b-ddf2-51df-6b79f8be6bf5@auckland.ac.nz>
Message-ID: <CAGx1TMDuCMX1RPj_Gf-db58sLaffc3FtuTyTpSZfMfbTgAoOdw@mail.gmail.com>

It works as anticipated for me

> xyplot(1 ~ 1,
+             main="The quick brown fox jumped\n over the lazy dog.")
> xyplot(1 ~ 1,
+             main="The quick brown fox jumped over the lazy dog.")

Something else you are doing is probably causing the difficulty.

Rich

On Wed, Feb 12, 2020 at 11:59 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> I'm trying to do an xyplot() with a longish main title that I'd like to
> split into two lines, something like
>
>      xyplot(<whatever>,
>             main="The quick brown fox jumped\n over the lazy dog.")
>
> When I do this I only get the last half, i.e. the "over the lazy dog."
> bit, and the first half doesn't appear.
>
> In base graphics I'd handle this sort of thing by increasing the third
> entry of the "mar" parameter.
>
> How can increase the space allocated for the title in lattice graphics?
> I've done a substantial amount of Googling and can't find anything
> helpful.  I've fiddled about with trellis.par.set() and cannot seem to
> get any effect.
>
> Could someone please give my poor feeble brain some guidance?  Ta.
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Thu Feb 13 06:16:42 2020
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Thu, 13 Feb 2020 10:46:42 +0530
Subject: [R] Increasing space for main title in a lattice (xyplot())
 graphics.
In-Reply-To: <CAGx1TMDuCMX1RPj_Gf-db58sLaffc3FtuTyTpSZfMfbTgAoOdw@mail.gmail.com>
References: <79e54b0b-fe3b-ddf2-51df-6b79f8be6bf5@auckland.ac.nz>
 <CAGx1TMDuCMX1RPj_Gf-db58sLaffc3FtuTyTpSZfMfbTgAoOdw@mail.gmail.com>
Message-ID: <CADfFDC5==7=KgHFVw5BeUe5W3FMwpv8UDEmdyRbV7tyETX-+oQ@mail.gmail.com>

On Thu, Feb 13, 2020 at 10:39 AM Richard M. Heiberger <rmh at temple.edu> wrote:
>
> It works as anticipated for me
>
> > xyplot(1 ~ 1,
> +             main="The quick brown fox jumped\n over the lazy dog.")
> > xyplot(1 ~ 1,
> +             main="The quick brown fox jumped over the lazy dog.")
>
> Something else you are doing is probably causing the difficulty.

Yes, the necessary space should be automatically allocated. Details of
version / device might help diagnosing the problem.

-Deepayan

>
> Rich
>
> On Wed, Feb 12, 2020 at 11:59 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
> >
> >
> > I'm trying to do an xyplot() with a longish main title that I'd like to
> > split into two lines, something like
> >
> >      xyplot(<whatever>,
> >             main="The quick brown fox jumped\n over the lazy dog.")
> >
> > When I do this I only get the last half, i.e. the "over the lazy dog."
> > bit, and the first half doesn't appear.
> >
> > In base graphics I'd handle this sort of thing by increasing the third
> > entry of the "mar" parameter.
> >
> > How can increase the space allocated for the title in lattice graphics?
> > I've done a substantial amount of Googling and can't find anything
> > helpful.  I've fiddled about with trellis.par.set() and cannot seem to
> > get any effect.
> >
> > Could someone please give my poor feeble brain some guidance?  Ta.
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Honorary Research Fellow
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Thu Feb 13 07:06:22 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 12 Feb 2020 22:06:22 -0800
Subject: [R] Increasing space for main title in a lattice (xyplot())
 graphics.
In-Reply-To: <CADfFDC5==7=KgHFVw5BeUe5W3FMwpv8UDEmdyRbV7tyETX-+oQ@mail.gmail.com>
References: <79e54b0b-fe3b-ddf2-51df-6b79f8be6bf5@auckland.ac.nz>
 <CAGx1TMDuCMX1RPj_Gf-db58sLaffc3FtuTyTpSZfMfbTgAoOdw@mail.gmail.com>
 <CADfFDC5==7=KgHFVw5BeUe5W3FMwpv8UDEmdyRbV7tyETX-+oQ@mail.gmail.com>
Message-ID: <CAGxFJbR+TBKcJWyOA+JCGCr=rVYz_A1wze_crFnh85Oj-RN70g@mail.gmail.com>

OK. Now for a tougher problem: how to make the first line bold font and the
second line normal font (and/or different colors)?

My reading of the docs did not reveal how to do it, but I found a way using
a textGrob for the title (i.e. main ). But it's tricky, as the "obvious
solution" of using different y values for the lines caused lattice to
enlarge the title viewport too much, shrinking the graph panels so that
details were lost. I think I have found a way to avoid this and make it
work, but I'll delay giving my somewhat clumsy "solution" until some of you
have a chance to find a more sensible approach, if you care to try.

Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 12, 2020 at 9:19 PM Deepayan Sarkar <deepayan.sarkar at gmail.com>
wrote:

> On Thu, Feb 13, 2020 at 10:39 AM Richard M. Heiberger <rmh at temple.edu>
> wrote:
> >
> > It works as anticipated for me
> >
> > > xyplot(1 ~ 1,
> > +             main="The quick brown fox jumped\n over the lazy dog.")
> > > xyplot(1 ~ 1,
> > +             main="The quick brown fox jumped over the lazy dog.")
> >
> > Something else you are doing is probably causing the difficulty.
>
> Yes, the necessary space should be automatically allocated. Details of
> version / device might help diagnosing the problem.
>
> -Deepayan
>
> >
> > Rich
> >
> > On Wed, Feb 12, 2020 at 11:59 PM Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
> > >
> > >
> > > I'm trying to do an xyplot() with a longish main title that I'd like to
> > > split into two lines, something like
> > >
> > >      xyplot(<whatever>,
> > >             main="The quick brown fox jumped\n over the lazy dog.")
> > >
> > > When I do this I only get the last half, i.e. the "over the lazy dog."
> > > bit, and the first half doesn't appear.
> > >
> > > In base graphics I'd handle this sort of thing by increasing the third
> > > entry of the "mar" parameter.
> > >
> > > How can increase the space allocated for the title in lattice graphics?
> > > I've done a substantial amount of Googling and can't find anything
> > > helpful.  I've fiddled about with trellis.par.set() and cannot seem to
> > > get any effect.
> > >
> > > Could someone please give my poor feeble brain some guidance?  Ta.
> > >
> > > cheers,
> > >
> > > Rolf Turner
> > >
> > > --
> > > Honorary Research Fellow
> > > Department of Statistics
> > > University of Auckland
> > > Phone: +64-9-373-7599 ext. 88276
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Thu Feb 13 08:07:34 2020
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Thu, 13 Feb 2020 12:37:34 +0530
Subject: [R] Increasing space for main title in a lattice (xyplot())
 graphics.
In-Reply-To: <CAGxFJbR+TBKcJWyOA+JCGCr=rVYz_A1wze_crFnh85Oj-RN70g@mail.gmail.com>
References: <79e54b0b-fe3b-ddf2-51df-6b79f8be6bf5@auckland.ac.nz>
 <CAGx1TMDuCMX1RPj_Gf-db58sLaffc3FtuTyTpSZfMfbTgAoOdw@mail.gmail.com>
 <CADfFDC5==7=KgHFVw5BeUe5W3FMwpv8UDEmdyRbV7tyETX-+oQ@mail.gmail.com>
 <CAGxFJbR+TBKcJWyOA+JCGCr=rVYz_A1wze_crFnh85Oj-RN70g@mail.gmail.com>
Message-ID: <CADfFDC5BjUswpazBypi+4ePuyatdZPxSQfqozfkSpp0NQJ40fQ@mail.gmail.com>

Hi Bert,

You are right that the general solution is for 'main' to be a (grid)
grob. It is not clear (to me) what the "height" of a textGrob with
multiple labels should be, but the following gives reasonable results:

xyplot(1 ~ 1,
       main = textGrob(c("The quick brown fox jumped", "over the lazy dog"),
                       x = unit(0.5, "npc"), y = unit(c(0.75, 0.25), "cm")))

I'm guessing your first attempt was with the default units ("npc") for y.

The correct grob (allowing more detailed control) to use for complex
grid objects is a frameGrob.

lattice does have an interface to create (simple) frameGrobs, for
constructing legends. This can be (ab)used as follows:

xyplot(1 ~ 1,
       main = draw.key(key = list(text = list(c("The quick brown fox jumped",
                                                "over the lazy dog"),
                                              font = c(1, 2), col = c(2, 3)))))

-Deepayan

On Thu, Feb 13, 2020 at 11:36 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> OK. Now for a tougher problem: how to make the first line bold font and the second line normal font (and/or different colors)?
>
> My reading of the docs did not reveal how to do it, but I found a way using a textGrob for the title (i.e. main ). But it's tricky, as the "obvious solution" of using different y values for the lines caused lattice to enlarge the title viewport too much, shrinking the graph panels so that details were lost. I think I have found a way to avoid this and make it work, but I'll delay giving my somewhat clumsy "solution" until some of you have a chance to find a more sensible approach, if you care to try.
>
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Feb 12, 2020 at 9:19 PM Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
>>
>> On Thu, Feb 13, 2020 at 10:39 AM Richard M. Heiberger <rmh at temple.edu> wrote:
>> >
>> > It works as anticipated for me
>> >
>> > > xyplot(1 ~ 1,
>> > +             main="The quick brown fox jumped\n over the lazy dog.")
>> > > xyplot(1 ~ 1,
>> > +             main="The quick brown fox jumped over the lazy dog.")
>> >
>> > Something else you are doing is probably causing the difficulty.
>>
>> Yes, the necessary space should be automatically allocated. Details of
>> version / device might help diagnosing the problem.
>>
>> -Deepayan
>>
>> >
>> > Rich
>> >
>> > On Wed, Feb 12, 2020 at 11:59 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>> > >
>> > >
>> > > I'm trying to do an xyplot() with a longish main title that I'd like to
>> > > split into two lines, something like
>> > >
>> > >      xyplot(<whatever>,
>> > >             main="The quick brown fox jumped\n over the lazy dog.")
>> > >
>> > > When I do this I only get the last half, i.e. the "over the lazy dog."
>> > > bit, and the first half doesn't appear.
>> > >
>> > > In base graphics I'd handle this sort of thing by increasing the third
>> > > entry of the "mar" parameter.
>> > >
>> > > How can increase the space allocated for the title in lattice graphics?
>> > > I've done a substantial amount of Googling and can't find anything
>> > > helpful.  I've fiddled about with trellis.par.set() and cannot seem to
>> > > get any effect.
>> > >
>> > > Could someone please give my poor feeble brain some guidance?  Ta.
>> > >
>> > > cheers,
>> > >
>> > > Rolf Turner
>> > >
>> > > --
>> > > Honorary Research Fellow
>> > > Department of Statistics
>> > > University of Auckland
>> > > Phone: +64-9-373-7599 ext. 88276
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Feb 13 10:02:22 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 13 Feb 2020 22:02:22 +1300
Subject: [R] Increasing space for main title in a lattice (xyplot())
 graphics.
In-Reply-To: <CADfFDC5==7=KgHFVw5BeUe5W3FMwpv8UDEmdyRbV7tyETX-+oQ@mail.gmail.com>
References: <79e54b0b-fe3b-ddf2-51df-6b79f8be6bf5@auckland.ac.nz>
 <CAGx1TMDuCMX1RPj_Gf-db58sLaffc3FtuTyTpSZfMfbTgAoOdw@mail.gmail.com>
 <CADfFDC5==7=KgHFVw5BeUe5W3FMwpv8UDEmdyRbV7tyETX-+oQ@mail.gmail.com>
Message-ID: <b3b70ba5-058b-c435-ad06-041d7870c441@auckland.ac.nz>


On 13/02/20 6:16 pm, Deepayan Sarkar wrote:

> On Thu, Feb 13, 2020 at 10:39 AM Richard M. Heiberger <rmh at temple.edu> wrote:
>>
>> It works as anticipated for me
>>
>>> xyplot(1 ~ 1,
>> +             main="The quick brown fox jumped\n over the lazy dog.")
>>> xyplot(1 ~ 1,
>> +             main="The quick brown fox jumped over the lazy dog.")
>>
>> Something else you are doing is probably causing the difficulty.
> 
> Yes, the necessary space should be automatically allocated. Details of
> version / device might help diagnosing the problem.
> 
> -Deepayan

Aaaarrrgghhh!!! The diagnosis of the problem was, as usual, trivial.  It 
was all down to my overwhelming stupidity.  I put together the main 
title by pasting together various bits --- and FORGOT to include the 
very first bit, which was the first line of the two-line title.  (Smoke 
comes out of ears!!!)

Took me hours, with accompanying hair loss, to track down that 
particular piece of stupidity.  Tried everything except the obvious!!!

Sorry for the noise.

cheers (said he, not very cheerfully),

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bgunter@4567 @end|ng |rom gm@||@com  Thu Feb 13 16:31:56 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 13 Feb 2020 07:31:56 -0800
Subject: [R] Increasing space for main title in a lattice (xyplot())
 graphics.
In-Reply-To: <CADfFDC5BjUswpazBypi+4ePuyatdZPxSQfqozfkSpp0NQJ40fQ@mail.gmail.com>
References: <79e54b0b-fe3b-ddf2-51df-6b79f8be6bf5@auckland.ac.nz>
 <CAGx1TMDuCMX1RPj_Gf-db58sLaffc3FtuTyTpSZfMfbTgAoOdw@mail.gmail.com>
 <CADfFDC5==7=KgHFVw5BeUe5W3FMwpv8UDEmdyRbV7tyETX-+oQ@mail.gmail.com>
 <CAGxFJbR+TBKcJWyOA+JCGCr=rVYz_A1wze_crFnh85Oj-RN70g@mail.gmail.com>
 <CADfFDC5BjUswpazBypi+4ePuyatdZPxSQfqozfkSpp0NQJ40fQ@mail.gmail.com>
Message-ID: <CAGxFJbStDyWNaRwzU2abBSjWA90B8Df7hTE3zR7u4AHbt1jXaQ@mail.gmail.com>

Thanks Deepayan. Yes that is both the correct diagnosis and the "obvious"
solution I was looking for. And now I don't have to embarrass myself by
showing my "clumsy" solution.

Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 12, 2020 at 11:07 PM Deepayan Sarkar <deepayan.sarkar at gmail.com>
wrote:

> Hi Bert,
>
> You are right that the general solution is for 'main' to be a (grid)
> grob. It is not clear (to me) what the "height" of a textGrob with
> multiple labels should be, but the following gives reasonable results:
>
> xyplot(1 ~ 1,
>        main = textGrob(c("The quick brown fox jumped", "over the lazy
> dog"),
>                        x = unit(0.5, "npc"), y = unit(c(0.75, 0.25),
> "cm")))
>
> I'm guessing your first attempt was with the default units ("npc") for y.
>
> The correct grob (allowing more detailed control) to use for complex
> grid objects is a frameGrob.
>
> lattice does have an interface to create (simple) frameGrobs, for
> constructing legends. This can be (ab)used as follows:
>
> xyplot(1 ~ 1,
>        main = draw.key(key = list(text = list(c("The quick brown fox
> jumped",
>                                                 "over the lazy dog"),
>                                               font = c(1, 2), col = c(2,
> 3)))))
>
> -Deepayan
>
> On Thu, Feb 13, 2020 at 11:36 AM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> > OK. Now for a tougher problem: how to make the first line bold font and
> the second line normal font (and/or different colors)?
> >
> > My reading of the docs did not reveal how to do it, but I found a way
> using a textGrob for the title (i.e. main ). But it's tricky, as the
> "obvious solution" of using different y values for the lines caused lattice
> to enlarge the title viewport too much, shrinking the graph panels so that
> details were lost. I think I have found a way to avoid this and make it
> work, but I'll delay giving my somewhat clumsy "solution" until some of you
> have a chance to find a more sensible approach, if you care to try.
> >
> > Bert
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Wed, Feb 12, 2020 at 9:19 PM Deepayan Sarkar <
> deepayan.sarkar at gmail.com> wrote:
> >>
> >> On Thu, Feb 13, 2020 at 10:39 AM Richard M. Heiberger <rmh at temple.edu>
> wrote:
> >> >
> >> > It works as anticipated for me
> >> >
> >> > > xyplot(1 ~ 1,
> >> > +             main="The quick brown fox jumped\n over the lazy dog.")
> >> > > xyplot(1 ~ 1,
> >> > +             main="The quick brown fox jumped over the lazy dog.")
> >> >
> >> > Something else you are doing is probably causing the difficulty.
> >>
> >> Yes, the necessary space should be automatically allocated. Details of
> >> version / device might help diagnosing the problem.
> >>
> >> -Deepayan
> >>
> >> >
> >> > Rich
> >> >
> >> > On Wed, Feb 12, 2020 at 11:59 PM Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
> >> > >
> >> > >
> >> > > I'm trying to do an xyplot() with a longish main title that I'd
> like to
> >> > > split into two lines, something like
> >> > >
> >> > >      xyplot(<whatever>,
> >> > >             main="The quick brown fox jumped\n over the lazy dog.")
> >> > >
> >> > > When I do this I only get the last half, i.e. the "over the lazy
> dog."
> >> > > bit, and the first half doesn't appear.
> >> > >
> >> > > In base graphics I'd handle this sort of thing by increasing the
> third
> >> > > entry of the "mar" parameter.
> >> > >
> >> > > How can increase the space allocated for the title in lattice
> graphics?
> >> > > I've done a substantial amount of Googling and can't find anything
> >> > > helpful.  I've fiddled about with trellis.par.set() and cannot seem
> to
> >> > > get any effect.
> >> > >
> >> > > Could someone please give my poor feeble brain some guidance?  Ta.
> >> > >
> >> > > cheers,
> >> > >
> >> > > Rolf Turner
> >> > >
> >> > > --
> >> > > Honorary Research Fellow
> >> > > Department of Statistics
> >> > > University of Auckland
> >> > > Phone: +64-9-373-7599 ext. 88276
> >> > >
> >> > > ______________________________________________
> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> > > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Fri Feb 14 18:38:33 2020
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Fri, 14 Feb 2020 09:38:33 -0800
Subject: [R] how to create a pivot table in r?
In-Reply-To: <CAMwU6B1MnAV0cmwMX9Aqc3UOQuu-dLksNrxeOYr_=36RHOaVBg@mail.gmail.com>
References: <CAMwU6B3kGfPieB5iy5OmW65mEEqLDxX6ZQYp_Oa6MDXVi1byhQ@mail.gmail.com>
 <F194979E-5BC4-41B7-BE7C-751CAA917210@gmail.com>
 <CAMwU6B1MnAV0cmwMX9Aqc3UOQuu-dLksNrxeOYr_=36RHOaVBg@mail.gmail.com>
Message-ID: <CAMwU6B3-LF+5JtMOse77pswmJUUF9Wni9Mb2td_oFfZspFS2Wg@mail.gmail.com>

Dear Peter and Rui,
There are many dates (value) in some of the cells, If we want to chose only
one date (either oldest or newest) from that cell, how can we make a table
with that condition?
For example,
Using the following code;
M <- with(daT, tapply(as.character(ObsDate), list(id, ObsSite), list,
simplify=F))
data.frame(M)
  site1 site4 site5 site7
id1 NULL NULL NULL 6/13/13
id2 NULL NULL NULL 07/03/14,  05/17/14
id4 NULL 5/8/14 NULL NULL
id5 NULL NULL 6/13/14 NULL
id6 05/30/14, 06/28/13 NULL NULL NULL
id7 NULL NULL 6/25/13 NULL

If we want to take only one value (oldest date) if two or more dates/values
(classes) are found in the certain cells. For example would like to get the
following table (given below).
  site1 site4 site5 site7
id1 NULL NULL NULL 6/13/13
id2 NULL NULL NULL 07/03/14
id4 NULL 5/8/14 NULL NULL
id5 NULL NULL 6/13/14 NULL
id6 6/28/13 NULL NULL NULL
id7 NULL NULL 6/25/13 NULL

here is the code and an example data

daT<-structure(list(id = structure(c(1L, 2L, 2L, 3L, 4L, 5L, 5L, 6L
), .Label = c("id1", "id2", "id4", "id5", "id6", "id7"), class = "factor"),
    ObsSite = structure(c(4L, 4L, 4L, 2L, 3L, 1L, 1L, 3L), .Label =
c("site1",
    "site4", "site5", "site7"), class = "factor"), ObsDate =
structure(c(4L,
    8L, 2L, 1L, 5L, 3L, 7L, 6L), .Label = c("05/08/14", "05/17/14",
    "05/30/14", "06/13/13", "06/13/14", "06/25/13", "06/28/13",
    "07/03/14"), class = "factor")), .Names = c("id", "ObsSite",
"ObsDate"), class = "data.frame", row.names = c(NA, -8L))
daT
daT$date <- mdy(daT$ObsDate)
tmp <- split(daT, daT$id)
head(tmp)
M <- with(daT, tapply(as.character(ObsDate), list(id, ObsSite), list,
simplify=F))
data.frame(M)
M[["id2", "site7"]]
# but I wanted to get the following table
daT2<-structure(list(X = structure(1:6, .Label = c("id1", "id2", "id4",
"id5", "id6", "id7"), class = "factor"), site1 = structure(c(2L,
2L, 2L, 2L, 1L, 2L), .Label = c("6/28/13", "NULL"), class = "factor"),
    site4 = structure(c(2L, 2L, 1L, 2L, 2L, 2L), .Label = c("5/8/14",
    "NULL"), class = "factor"), site5 = structure(c(3L, 3L, 3L,
    1L, 3L, 2L), .Label = c("6/13/14", "6/25/13", "NULL"), class =
"factor"),
    site7 = structure(c(2L, 1L, 3L, 3L, 3L, 3L), .Label = c("5/17/14",
    "6/13/13", "NULL"), class = "factor")), .Names = c("X", "site1",
"site4", "site5", "site7"), class = "data.frame", row.names = c(NA,
-6L))
daT2
Thank you

====


On Thu, Feb 6, 2020 at 8:48 AM Marna Wagley <marna.wagley at gmail.com> wrote:

> Thank You Profs. Dalgaard and Barradas for the code, both codes worked
> perfectly for the data and I am going to use it in my big data set.
> Thanks once again.
>
>
> On Thu, Feb 6, 2020 at 2:02 AM peter dalgaard <pdalgd at gmail.com> wrote:
>
>> There is also
>>
>> > with(daT, tapply(as.character(ObsDate), list(id, ObsSite),
>> function(x)format(list(x))))
>>     site1                site4      site5      site7
>> id1 NA                   NA         NA         "06/13/13"
>> id2 NA                   NA         NA         "07/03/14, 05/17/14"
>> id4 NA                   "05/08/14" NA         NA
>> id5 NA                   NA         "06/13/14" NA
>> id6 "05/30/14, 06/28/13" NA         NA         NA
>> id7 NA                   NA         "06/25/13" NA
>>
>> ...with the added bonus that if you leave out the format() business, you
>> get a data structure that doesn't print as nicely, but can be used for
>> further computations:
>>
>> > with(daT, tapply(as.character(ObsDate), list(id, ObsSite), list,
>> simplify=FALSE))
>>     site1  site4  site5  site7
>> id1 NULL   NULL   NULL   List,1
>> id2 NULL   NULL   NULL   List,1
>> id4 NULL   List,1 NULL   NULL
>> id5 NULL   NULL   List,1 NULL
>> id6 List,1 NULL   NULL   NULL
>> id7 NULL   NULL   List,1 NULL
>> > M <- with(daT, tapply(as.character(ObsDate), list(id, ObsSite), list,
>> simplify=FALSE))
>> > M[["id2", "site7"]]
>> [[1]]
>> [1] "07/03/14" "05/17/14"
>>
>> -pd
>>
>> > On 6 Feb 2020, at 01:37 , Marna Wagley <marna.wagley at gmail.com> wrote:
>> >
>> > daT<-structure(list(id = structure(c(1L, 2L, 2L, 3L, 4L, 5L, 5L, 6L
>> > ), .Label = c("id1", "id2", "id4", "id5", "id6", "id7"), class =
>> "factor"),
>> >    ObsSite = structure(c(4L, 4L, 4L, 2L, 3L, 1L, 1L, 3L), .Label =
>> > c("site1",
>> >    "site4", "site5", "site7"), class = "factor"), ObsDate =
>> > structure(c(4L,
>> >    8L, 2L, 1L, 5L, 3L, 7L, 6L), .Label = c("05/08/14", "05/17/14",
>> >    "05/30/14", "06/13/13", "06/13/14", "06/25/13", "06/28/13",
>> >    "07/03/14"), class = "factor")), .Names = c("id", "ObsSite",
>> > "ObsDate"), class = "data.frame", row.names = c(NA, -8L))
>> > daT
>> > daT$date <- mdy(daT$ObsDate)
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Feb 14 19:04:02 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 14 Feb 2020 10:04:02 -0800
Subject: [R] how to create a pivot table in r?
In-Reply-To: <CAMwU6B3-LF+5JtMOse77pswmJUUF9Wni9Mb2td_oFfZspFS2Wg@mail.gmail.com>
References: <CAMwU6B3kGfPieB5iy5OmW65mEEqLDxX6ZQYp_Oa6MDXVi1byhQ@mail.gmail.com>
 <F194979E-5BC4-41B7-BE7C-751CAA917210@gmail.com>
 <CAMwU6B1MnAV0cmwMX9Aqc3UOQuu-dLksNrxeOYr_=36RHOaVBg@mail.gmail.com>
 <CAMwU6B3-LF+5JtMOse77pswmJUUF9Wni9Mb2td_oFfZspFS2Wg@mail.gmail.com>
Message-ID: <CAGxFJbS3vBHH0howKsOjSu+h+sL-yJNVMssuOB9ebw3avTR4ZA@mail.gmail.com>

Please read ?tapply *carefully.*

Note that in  ...,list, simplify = FALSE),
"list" is the value of the FUN argument for tapply(). So, in theory, you
could replace "list" (without quotes of course) with another function such
as max or min to get the latest or earliest date. **Except** that won't
work, because max() and min() are meaningless for character data. So what
you must do is write a function that first converts the character data to
"date" data, and then take the max or min of that (and maybe convert the
result back after, although that may not really be needed).  See ?as.Date
and links therein for how to convert character data to/from dates.

Although this may be less help than you would like, you will learn a lot by
working through the details. However, tthers may be kinder than I and
provide you more (and possibly better solutions). Note that the "lubridate"
package has all sorts of this kind of functionality built in, and you may
prefer using that as your interface to date handling.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Feb 14, 2020 at 9:39 AM Marna Wagley <marna.wagley at gmail.com> wrote:

> Dear Peter and Rui,
> There are many dates (value) in some of the cells, If we want to chose only
> one date (either oldest or newest) from that cell, how can we make a table
> with that condition?
> For example,
> Using the following code;
> M <- with(daT, tapply(as.character(ObsDate), list(id, ObsSite), list,
> simplify=F))
> data.frame(M)
>   site1 site4 site5 site7
> id1 NULL NULL NULL 6/13/13
> id2 NULL NULL NULL 07/03/14,  05/17/14
> id4 NULL 5/8/14 NULL NULL
> id5 NULL NULL 6/13/14 NULL
> id6 05/30/14, 06/28/13 NULL NULL NULL
> id7 NULL NULL 6/25/13 NULL
>
> If we want to take only one value (oldest date) if two or more dates/values
> (classes) are found in the certain cells. For example would like to get the
> following table (given below).
>   site1 site4 site5 site7
> id1 NULL NULL NULL 6/13/13
> id2 NULL NULL NULL 07/03/14
> id4 NULL 5/8/14 NULL NULL
> id5 NULL NULL 6/13/14 NULL
> id6 6/28/13 NULL NULL NULL
> id7 NULL NULL 6/25/13 NULL
>
> here is the code and an example data
>
> daT<-structure(list(id = structure(c(1L, 2L, 2L, 3L, 4L, 5L, 5L, 6L
> ), .Label = c("id1", "id2", "id4", "id5", "id6", "id7"), class = "factor"),
>     ObsSite = structure(c(4L, 4L, 4L, 2L, 3L, 1L, 1L, 3L), .Label =
> c("site1",
>     "site4", "site5", "site7"), class = "factor"), ObsDate =
> structure(c(4L,
>     8L, 2L, 1L, 5L, 3L, 7L, 6L), .Label = c("05/08/14", "05/17/14",
>     "05/30/14", "06/13/13", "06/13/14", "06/25/13", "06/28/13",
>     "07/03/14"), class = "factor")), .Names = c("id", "ObsSite",
> "ObsDate"), class = "data.frame", row.names = c(NA, -8L))
> daT
> daT$date <- mdy(daT$ObsDate)
> tmp <- split(daT, daT$id)
> head(tmp)
> M <- with(daT, tapply(as.character(ObsDate), list(id, ObsSite), list,
> simplify=F))
> data.frame(M)
> M[["id2", "site7"]]
> # but I wanted to get the following table
> daT2<-structure(list(X = structure(1:6, .Label = c("id1", "id2", "id4",
> "id5", "id6", "id7"), class = "factor"), site1 = structure(c(2L,
> 2L, 2L, 2L, 1L, 2L), .Label = c("6/28/13", "NULL"), class = "factor"),
>     site4 = structure(c(2L, 2L, 1L, 2L, 2L, 2L), .Label = c("5/8/14",
>     "NULL"), class = "factor"), site5 = structure(c(3L, 3L, 3L,
>     1L, 3L, 2L), .Label = c("6/13/14", "6/25/13", "NULL"), class =
> "factor"),
>     site7 = structure(c(2L, 1L, 3L, 3L, 3L, 3L), .Label = c("5/17/14",
>     "6/13/13", "NULL"), class = "factor")), .Names = c("X", "site1",
> "site4", "site5", "site7"), class = "data.frame", row.names = c(NA,
> -6L))
> daT2
> Thank you
>
> ====
>
>
> On Thu, Feb 6, 2020 at 8:48 AM Marna Wagley <marna.wagley at gmail.com>
> wrote:
>
> > Thank You Profs. Dalgaard and Barradas for the code, both codes worked
> > perfectly for the data and I am going to use it in my big data set.
> > Thanks once again.
> >
> >
> > On Thu, Feb 6, 2020 at 2:02 AM peter dalgaard <pdalgd at gmail.com> wrote:
> >
> >> There is also
> >>
> >> > with(daT, tapply(as.character(ObsDate), list(id, ObsSite),
> >> function(x)format(list(x))))
> >>     site1                site4      site5      site7
> >> id1 NA                   NA         NA         "06/13/13"
> >> id2 NA                   NA         NA         "07/03/14, 05/17/14"
> >> id4 NA                   "05/08/14" NA         NA
> >> id5 NA                   NA         "06/13/14" NA
> >> id6 "05/30/14, 06/28/13" NA         NA         NA
> >> id7 NA                   NA         "06/25/13" NA
> >>
> >> ...with the added bonus that if you leave out the format() business, you
> >> get a data structure that doesn't print as nicely, but can be used for
> >> further computations:
> >>
> >> > with(daT, tapply(as.character(ObsDate), list(id, ObsSite), list,
> >> simplify=FALSE))
> >>     site1  site4  site5  site7
> >> id1 NULL   NULL   NULL   List,1
> >> id2 NULL   NULL   NULL   List,1
> >> id4 NULL   List,1 NULL   NULL
> >> id5 NULL   NULL   List,1 NULL
> >> id6 List,1 NULL   NULL   NULL
> >> id7 NULL   NULL   List,1 NULL
> >> > M <- with(daT, tapply(as.character(ObsDate), list(id, ObsSite), list,
> >> simplify=FALSE))
> >> > M[["id2", "site7"]]
> >> [[1]]
> >> [1] "07/03/14" "05/17/14"
> >>
> >> -pd
> >>
> >> > On 6 Feb 2020, at 01:37 , Marna Wagley <marna.wagley at gmail.com>
> wrote:
> >> >
> >> > daT<-structure(list(id = structure(c(1L, 2L, 2L, 3L, 4L, 5L, 5L, 6L
> >> > ), .Label = c("id1", "id2", "id4", "id5", "id6", "id7"), class =
> >> "factor"),
> >> >    ObsSite = structure(c(4L, 4L, 4L, 2L, 3L, 1L, 1L, 3L), .Label =
> >> > c("site1",
> >> >    "site4", "site5", "site7"), class = "factor"), ObsDate =
> >> > structure(c(4L,
> >> >    8L, 2L, 1L, 5L, 3L, 7L, 6L), .Label = c("05/08/14", "05/17/14",
> >> >    "05/30/14", "06/13/13", "06/13/14", "06/25/13", "06/28/13",
> >> >    "07/03/14"), class = "factor")), .Names = c("id", "ObsSite",
> >> > "ObsDate"), class = "data.frame", row.names = c(NA, -8L))
> >> > daT
> >> > daT$date <- mdy(daT$ObsDate)
> >>
> >> --
> >> Peter Dalgaard, Professor,
> >> Center for Statistics, Copenhagen Business School
> >> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> >> Phone: (+45)38153501
> >> Office: A 4.23
> >> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Rom@n@H|||e @end|ng |rom @te@gextern@com  Fri Feb 14 09:48:58 2020
From: Rom@n@H|||e @end|ng |rom @te@gextern@com (Hille, Roman (STEAG Energy Services extern))
Date: Fri, 14 Feb 2020 08:48:58 +0000
Subject: [R] parallel::makeCluster does not finish
Message-ID: <0d015a8a3fc541f5a7acc6c44f359997@steagextern.com>

Question to parallel and cluster package developers,

we have a serious problem with the cluster usage.

OS Windows Server 2016 64Bit
R-Version 3.6.1
parallel 3.6.1
Cluster 2.1.0

Sometimes, the cluster operation does not finish, one cluster Rscript.exe will never finish,
(or wait until timeout of 2592000...???)

In more than 90% all works fine,
but with some more parallel R-Sessions on the same machine and heavy load,
one cluster process does not finish sometimes
(I suppose, the final "ready" message of the process will be sent to early, the cluster "server" is not ready to receive....?)

Our R-Code:
   cl <- parallel::makeCluster(8, outfile = "", port = 64414)
    registerDoParallel(cl)
    Cluster.Res <- foreach(i = 1:Error.Dim.Selected[2] , combine=cbind) %dopar% {
....
    }

    stopCluster(cl)

parallel Cluster-process was started with:

C:\PROGRA~1\R\bin\x64\Rscript.exe --default-packages=datasets,utils,grDevices,graphics,stats,methods -e "parallel:::.slaveRSOCK()" MASTER=localhost PORT=64414 OUT="" SETUPTIMEOUT=120 TIMEOUT=2592000 XDR=TRUE

Any idea or help

Thanks
Roman


Sysinternals is showing the following stack for the "hanging" Rscript.exe cluster process
(this is every time for this problem the same stack)

ntoskrnl.exe!KeSynchronizeExecution+0x5bf6
ntoskrnl.exe!KeWaitForMultipleObjects+0x109d
ntoskrnl.exe!KeWaitForMultipleObjects+0xb3f
ntoskrnl.exe!KeWaitForSingleObject+0x377
ntoskrnl.exe!KeQuerySystemTimePrecise+0x881
ntoskrnl.exe!ObDereferenceObjectDeferDelete+0x28a
ntoskrnl.exe!KeWaitForMultipleObjects+0x1284
ntoskrnl.exe!KeWaitForMultipleObjects+0xb3f
ntoskrnl.exe!KeWaitForSingleObject+0x377
ntoskrnl.exe!NtWaitForSingleObject+0xf8
ntoskrnl.exe!setjmpex+0x68b3
ntdll.dll!ZwWaitForSingleObject+0x14
mswsock.dll!Tcpip6_WSHOpenSocket2+0x1cf
mswsock.dll!Tcpip6_WSHGetSocketInformation+0x14f4
WS2_32.dll!select+0x1d3
internet.dll!R_init_internet+0xae8a
internet.dll!R_init_internet+0x6abe
R.dll!R_gzclose+0x29d6
R.dll!R_initAssignSymbols+0x7969
R.dll!Rf_eval+0x331
R.dll!R_cmpfun1+0x508
R.dll!Rf_applyClosure+0x16f
R.dll!R_initAssignSymbols+0xd2ff
R.dll!Rf_eval+0x331
R.dll!Rf_eval+0x9dc
R.dll!Rf_eval+0x127a
R.dll!R_initAssignSymbols+0xae53
R.dll!Rf_eval+0x331
R.dll!Rf_eval+0x9dc
R.dll!Rf_eval+0x127a
R.dll!R_initAssignSymbols+0xae53
R.dll!Rf_eval+0x331
R.dll!Rf_eval+0x9dc
R.dll!Rf_eval+0x127a
R.dll!R_initAssignSymbols+0xae53
R.dll!Rf_eval+0x331
R.dll!Rf_eval+0x9dc
R.dll!Rf_eval+0x127a
R.dll!R_initAssignSymbols+0xae53
R.dll!Rf_eval+0x331
R.dll!R_cmpfun1+0x508
R.dll!Rf_applyClosure+0x16f
R.dll!R_initAssignSymbols+0xd2ff
R.dll!Rf_eval+0x331
R.dll!R_cmpfun1+0x508
R.dll!Rf_applyClosure+0x16f
R.dll!R_initAssignSymbols+0xd2ff
R.dll!Rf_eval+0x331
R.dll!R_cmpfun1+0x508
R.dll!Rf_applyClosure+0x16f
R.dll!R_initAssignSymbols+0xd2ff
R.dll!Rf_eval+0x331
R.dll!R_cmpfun1+0x508
R.dll!Rf_applyClosure+0x16f
R.dll!R_initAssignSymbols+0xd2ff
R.dll!Rf_eval+0x331
R.dll!R_cmpfun1+0x508
R.dll!Rf_applyClosure+0x16f
R.dll!R_initAssignSymbols+0xd2ff
R.dll!Rf_eval+0x331
R.dll!Rf_eval+0x9dc
R.dll!Rf_eval+0x127a
R.dll!R_initAssignSymbols+0xae53
R.dll!Rf_eval+0x331
R.dll!Rf_eval+0x9dc
R.dll!Rf_eval+0x734
R.dll!R_has_methods_attached+0xeb9
R.dll!R_initAssignSymbols+0xa1a4
R.dll!Rf_eval+0x331
R.dll!R_cmpfun1+0x508
R.dll!Rf_applyClosure+0x16f
R.dll!R_initAssignSymbols+0xd2ff
R.dll!Rf_eval+0x331
R.dll!Rf_eval+0x9dc
R.dll!Rf_eval+0x127a
R.dll!R_initAssignSymbols+0xae53
R.dll!Rf_eval+0x331
R.dll!Rf_eval+0x9dc
R.dll!Rf_eval+0x127a
R.dll!R_initAssignSymbols+0xae53
R.dll!Rf_eval+0x331
R.dll!Rf_eval+0x9dc
R.dll!Rf_eval+0x127a
R.dll!R_initAssignSymbols+0xae53
R.dll!Rf_eval+0x331
R.dll!Rf_eval+0x9dc
R.dll!Rf_eval+0x127a
R.dll!R_initAssignSymbols+0xae53
R.dll!Rf_eval+0x331
R.dll!R_cmpfun1+0x508
R.dll!Rf_applyClosure+0x16f
R.dll!R_initAssignSymbols+0xd2ff
R.dll!Rf_eval+0x331
R.dll!R_cmpfun1+0x508
R.dll!Rf_applyClosure+0x16f
R.dll!R_initAssignSymbols+0xd2ff
R.dll!Rf_eval+0x331
R.dll!R_cmpfun1+0x508
R.dll!Rf_applyClosure+0x16f
R.dll!R_initAssignSymbols+0xd2ff
R.dll!Rf_eval+0x331
R.dll!R_cmpfun1+0x508
R.dll!Rf_applyClosure+0x16f
R.dll!R_initAssignSymbols+0xd2ff
R.dll!Rf_eval+0x331
R.dll!R_cmpfun1+0x508
R.dll!Rf_applyClosure+0x16f
R.dll!R_initAssignSymbols+0xd2ff
R.dll!Rf_eval+0x331
R.dll!R_cmpfun1+0x508
R.dll!Rf_applyClosure+0x16f



	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Sun Feb 16 03:31:01 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 16 Feb 2020 15:31:01 +1300
Subject: [R] Identification of Turning Points in a Signal
In-Reply-To: <CAC8ss32tKdyzzGkcDqKCV2wgpFVWhgPHkicAsQq-gVEOCqZPhw@mail.gmail.com>
References: <CAC8ss32tKdyzzGkcDqKCV2wgpFVWhgPHkicAsQq-gVEOCqZPhw@mail.gmail.com>
Message-ID: <CAB8pepxuvjsbT34yAPft9p7ju1TXkPo5fMkrvBmuYh+cLZTntw@mail.gmail.com>

Sorry no one replied sooner.

Note that I find your question difficult to follow.

It sounds like you have two datasets, each with different sizes.
(e.g. Two data.frame objects, each with a different numbers of rows).

Given that tp$pits is a logical index, trying to apply it to a vector
(or data.frame) of a different size is problematic.
Assuming that you're dealing with datasets of different sizes, the
simplest solution is to modify your code, such that they're the same
size.


On Mon, Feb 10, 2020 at 6:40 PM Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>
> Dear Friends,
> Wishing you the best of the day.
>
> I have a data (Cosmic Ray) which exhibit flow patterns of a
> sine/cosine wave, i.e. decreasing/increasing and registering crests
> (points maximal increases) and troughs/pits (points maximal
> decreases). These turning points are of interest to me. With pastecs
> package and a few lines of code as (the residual is coming from
> Fourier transformation of the data):
> library(pastecs)
>  tp<-turnpoints(data$residual)
>  res<-(1:length(data$residual))[tp$pit]
>  minima<-which(tp$pit & data$residual<= -100)
>  dates<-data$date[minima]
>  k<-data$residual[minima]
> I usually pick all the turning points (trough) equal or below -100. If
> I change the <= to >=, I pick all the crests.
>
> Now, without first transforming the data, I wish to pick the same
> turning points in the raw data. Indeed, the difference between the
> transformed data and the raw data lies only in the amplitude of the
> crest or trough, otherwise, the crests and trough are the same in both
> signals.
>
> When I tried the above code in the raw signal, the warning/error message is:
> Warning message:
> In tp$pit & data$residual <= -100 :
>   longer object length is not a multiple of shorter object length.
>
> A sample of the raw data is:
> 03 10 01 6.20636953199224
> 03 10 02 6.90829266565563
> 03 10 03 6.40434785174345
> 03 10 04 6.33235573547028
> 03 10 05 5.99039318317273
> 03 10 06 5.09049172975812
> 03 10 07 4.35257253795814
> 03 10 08 4.49655677050448
> 03 10 09 4.49655677050448
> 03 10 10 4.4425626832996
> 03 10 11 5.16248384603129
> 03 10 12 5.72042274714835
> 03 10 13 6.26036361919711
> 03 10 14 5.8284109215581
> 03 10 15 5.30646807857763
> 03 10 16 5.32446610764592
> 03 10 17 5.68442668901176
> 03 10 18 6.33235573547028
> 03 10 19 6.80030449124588
> 03 10 20 7.26825324702148
> 03 10 21 6.83630054938246
> 03 10 22 2.53477160206063
> 03 10 23 2.55276963112892
> 03 10 24 2.39078736951429
> 03 10 25 -0.48889728141246
> 03 10 26 -0.110938670978323
> 03 10 27 0.303015997592397
> 03 10 28 1.81485043932894
> 03 10 29 -8.04806949009518
> 03 10 30 -16.1471825708267
> 03 10 31 -17.0470840242413
> 03 11 01 -13.6094604721975
> 03 11 02 -8.98396700164638
> 03 11 03 -6.28426264140255
> 03 11 04 -5.78031782749036
> 03 11 05 -3.72854251370505
> 03 11 06 -2.95462726376849
> 03 11 07 -4.52045579270991
> 03 11 08 -3.54856222302213
> 03 11 09 -0.884853920914888
> 03 11 10 0.447000230138735
> 03 11 11 0.0150475324997218
> 03 11 12 -0.308916990729538
> 03 11 13 0.0690416197045984
> 03 11 14 -0.110938670978323
> 03 11 15 -0.938848008119764
> 03 11 16 -3.02661938004166
> 03 11 17 -3.92652083345627
> 03 11 18 -3.24259572886117
> 03 11 19 -1.67676719991974
> 03 11 20 -2.30669821730997
> 03 11 21 -2.9366292347002
> 03 11 22 -2.75664894401728
> 03 11 23 -3.44057404861238
> 03 11 24 -4.34047550202699
> 03 11 25 -3.87252674625139
> 03 11 26 -2.72065288588069
> 03 11 27 -2.25270413010509
> 03 11 28 -1.37080070575878
> 03 11 29 -0.0389465547051547
> 03 11 30 0.033045561568014
> the first three columns are year, month and day, the last column % CR variation.
>
> abline (h=0) specifies values below the average. I am interested in
> picking the time and magnitude of all the turning points below zero.
>
> Thank you for assisting me.
> Best regards
> Ogbos
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From g||ted|||e2014 @end|ng |rom gm@||@com  Sun Feb 16 04:12:25 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Sun, 16 Feb 2020 04:12:25 +0100
Subject: [R] Identification of Turning Points in a Signal
In-Reply-To: <CAB8pepxuvjsbT34yAPft9p7ju1TXkPo5fMkrvBmuYh+cLZTntw@mail.gmail.com>
References: <CAC8ss32tKdyzzGkcDqKCV2wgpFVWhgPHkicAsQq-gVEOCqZPhw@mail.gmail.com>
 <CAB8pepxuvjsbT34yAPft9p7ju1TXkPo5fMkrvBmuYh+cLZTntw@mail.gmail.com>
Message-ID: <CAC8ss33XH4vDxfWrFSYr=23CsLshWiZVqaZso7U8U6Z_k5Yksg@mail.gmail.com>

Dear Abby,
Many thanks for your feedback on this.

True, the structure of my question was not clear.  I realized it later
and have been thinking of a better way to re-posting. I am sorry about
that. I will make extra efforts here to make it clearer.

I have just a single data. I have tried to use dput to send the full
data (see attached, Ogbos-dput). This is the raw data with labels
year, month, day and cosmic ray count.

I have two codes for the same data. The first is a combination of
Fourier transform and an R code for pits/trough identification. I am
displaying the script here:
data <- read.table("OULU05", col.names = c("year", "month", "day", "counts"))

new.century <- data$year < 50

data$year <- ifelse(new.century, data$year + 2000, data$year + 1900)

data$date <- as.Date(ISOdate(data$year, data$month, data$day))
x = data$date
 y = data$counts
 y1<-approx(x,y,xout=x)$y
 RECON = 12
 f = fft(d<-y1)
p<-1:length(f)
 f[(p > RECON/2 + 1) & (p <= length(d) - RECON/2)] = 0
 f<-fft(f, inverse = TRUE)/length(f)
 data$smooth = abs(f)
 data$residual = y1 - data$smooth

 library(pastecs)
 tp<-turnpoints(data$residual)
 res<-(1:length(data$residual))[tp$pit]
 minima<-which(tp$pit & data$residual<= -100)
 dates<-data$date[minima]
 k<-data$residual[minima]

png("2005A.png")

 plot(x, data$residual/100, type = "l")
 points(dates, k/100, lty = 2, col = 4)
dev.off()

The above runs OK as you may see.

The second code is similar but without the Fourier transform part. I
have only standardized the data in the second script. My aim here is
the same, to pick turning points/pits in the standardized (raw) data.
The script I tried to use is:
data <- read.table("OULU05", col.names = c("year", "month", "day", "counts"))

new.century <- data$year < 50

data$year <- ifelse(new.century, data$year + 2000, data$year + 1900)

data$date <- as.Date(ISOdate(data$year, data$month, data$day))
x = data$date
 y = data$counts
y<-c(y-mean(y))/mean(y)*100
  data$residual = y

 library(pastecs)
 tp<-turnpoints(data$residual)
 res<-(1:length(data$residual))[tp$pit]
 minima<-which(tp$pit & data$residual<= -100)
 dates<-data$date[minima]
 k<-data$residual[minima]

png("2005B.png")

 plot(x, data$residual/100, type = "l")
 points(dates, k/100, lty = 2, col = 4)
dev.off()

This second script is where I have issues. It runs with warning/error.
And this is where I need help.


Thanks again for your kind assistance.

Best regards
Ogbos

On Sun, Feb 16, 2020 at 3:31 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> Sorry no one replied sooner.
>
> Note that I find your question difficult to follow.
>
> It sounds like you have two datasets, each with different sizes.
> (e.g. Two data.frame objects, each with a different numbers of rows).
>
> Given that tp$pits is a logical index, trying to apply it to a vector
> (or data.frame) of a different size is problematic.
> Assuming that you're dealing with datasets of different sizes, the
> simplest solution is to modify your code, such that they're the same
> size.
>
>
> On Mon, Feb 10, 2020 at 6:40 PM Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> >
> > Dear Friends,
> > Wishing you the best of the day.
> >
> > I have a data (Cosmic Ray) which exhibit flow patterns of a
> > sine/cosine wave, i.e. decreasing/increasing and registering crests
> > (points maximal increases) and troughs/pits (points maximal
> > decreases). These turning points are of interest to me. With pastecs
> > package and a few lines of code as (the residual is coming from
> > Fourier transformation of the data):
> > library(pastecs)
> >  tp<-turnpoints(data$residual)
> >  res<-(1:length(data$residual))[tp$pit]
> >  minima<-which(tp$pit & data$residual<= -100)
> >  dates<-data$date[minima]
> >  k<-data$residual[minima]
> > I usually pick all the turning points (trough) equal or below -100. If
> > I change the <= to >=, I pick all the crests.
> >
> > Now, without first transforming the data, I wish to pick the same
> > turning points in the raw data. Indeed, the difference between the
> > transformed data and the raw data lies only in the amplitude of the
> > crest or trough, otherwise, the crests and trough are the same in both
> > signals.
> >
> > When I tried the above code in the raw signal, the warning/error message is:
> > Warning message:
> > In tp$pit & data$residual <= -100 :
> >   longer object length is not a multiple of shorter object length.
> >
> > A sample of the raw data is:
> > 03 10 01 6.20636953199224
> > 03 10 02 6.90829266565563
> > 03 10 03 6.40434785174345
> > 03 10 04 6.33235573547028
> > 03 10 05 5.99039318317273
> > 03 10 06 5.09049172975812
> > 03 10 07 4.35257253795814
> > 03 10 08 4.49655677050448
> > 03 10 09 4.49655677050448
> > 03 10 10 4.4425626832996
> > 03 10 11 5.16248384603129
> > 03 10 12 5.72042274714835
> > 03 10 13 6.26036361919711
> > 03 10 14 5.8284109215581
> > 03 10 15 5.30646807857763
> > 03 10 16 5.32446610764592
> > 03 10 17 5.68442668901176
> > 03 10 18 6.33235573547028
> > 03 10 19 6.80030449124588
> > 03 10 20 7.26825324702148
> > 03 10 21 6.83630054938246
> > 03 10 22 2.53477160206063
> > 03 10 23 2.55276963112892
> > 03 10 24 2.39078736951429
> > 03 10 25 -0.48889728141246
> > 03 10 26 -0.110938670978323
> > 03 10 27 0.303015997592397
> > 03 10 28 1.81485043932894
> > 03 10 29 -8.04806949009518
> > 03 10 30 -16.1471825708267
> > 03 10 31 -17.0470840242413
> > 03 11 01 -13.6094604721975
> > 03 11 02 -8.98396700164638
> > 03 11 03 -6.28426264140255
> > 03 11 04 -5.78031782749036
> > 03 11 05 -3.72854251370505
> > 03 11 06 -2.95462726376849
> > 03 11 07 -4.52045579270991
> > 03 11 08 -3.54856222302213
> > 03 11 09 -0.884853920914888
> > 03 11 10 0.447000230138735
> > 03 11 11 0.0150475324997218
> > 03 11 12 -0.308916990729538
> > 03 11 13 0.0690416197045984
> > 03 11 14 -0.110938670978323
> > 03 11 15 -0.938848008119764
> > 03 11 16 -3.02661938004166
> > 03 11 17 -3.92652083345627
> > 03 11 18 -3.24259572886117
> > 03 11 19 -1.67676719991974
> > 03 11 20 -2.30669821730997
> > 03 11 21 -2.9366292347002
> > 03 11 22 -2.75664894401728
> > 03 11 23 -3.44057404861238
> > 03 11 24 -4.34047550202699
> > 03 11 25 -3.87252674625139
> > 03 11 26 -2.72065288588069
> > 03 11 27 -2.25270413010509
> > 03 11 28 -1.37080070575878
> > 03 11 29 -0.0389465547051547
> > 03 11 30 0.033045561568014
> > the first three columns are year, month and day, the last column % CR variation.
> >
> > abline (h=0) specifies values below the average. I am interested in
> > picking the time and magnitude of all the turning points below zero.
> >
> > Thank you for assisting me.
> > Best regards
> > Ogbos
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

From @purd|e@@ @end|ng |rom gm@||@com  Sun Feb 16 08:13:55 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 16 Feb 2020 20:13:55 +1300
Subject: [R] Identification of Turning Points in a Signal
In-Reply-To: <CAC8ss33XH4vDxfWrFSYr=23CsLshWiZVqaZso7U8U6Z_k5Yksg@mail.gmail.com>
References: <CAC8ss32tKdyzzGkcDqKCV2wgpFVWhgPHkicAsQq-gVEOCqZPhw@mail.gmail.com>
 <CAB8pepxuvjsbT34yAPft9p7ju1TXkPo5fMkrvBmuYh+cLZTntw@mail.gmail.com>
 <CAC8ss33XH4vDxfWrFSYr=23CsLshWiZVqaZso7U8U6Z_k5Yksg@mail.gmail.com>
Message-ID: <CAB8pepwGHvimzHaoBVBunsDxSFncXvrsKJH15fKssQbMPEmt-A@mail.gmail.com>

Note that your post does not contain a minimal reproducible example.
I, and presumably most other readers, do not have the file "OULU05".

Also, your first post referred to "% CR variation", however, your
second post referred to "counts".

I created a simple simulated data set:

--------
sim.data = function ()
{   year = 1:100
    month = (0:99 %% 12) + 1
    day = (0:99 %% 28) + 1
    counts = sample (1:2000, 100)
    data.frame (year, month, day, counts)
}
data = sim.data ()
--------

After replacing the "data" object (as above), everything worked fine.
(Except that the inequality needed modification based on the value of counts).

Maybe the problem is with your dataset...?
Or maybe there's some step in your code that results in missing
values, given your input?

Also note that the head and tail functions, are useful for both
inspecting data, and describing your data to others.

--------
head (data)
tail (data)
--------


From g||ted|||e2014 @end|ng |rom gm@||@com  Sun Feb 16 08:57:31 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Sun, 16 Feb 2020 08:57:31 +0100
Subject: [R] Identification of Turning Points in a Signal
In-Reply-To: <CAB8pepwGHvimzHaoBVBunsDxSFncXvrsKJH15fKssQbMPEmt-A@mail.gmail.com>
References: <CAC8ss32tKdyzzGkcDqKCV2wgpFVWhgPHkicAsQq-gVEOCqZPhw@mail.gmail.com>
 <CAB8pepxuvjsbT34yAPft9p7ju1TXkPo5fMkrvBmuYh+cLZTntw@mail.gmail.com>
 <CAC8ss33XH4vDxfWrFSYr=23CsLshWiZVqaZso7U8U6Z_k5Yksg@mail.gmail.com>
 <CAB8pepwGHvimzHaoBVBunsDxSFncXvrsKJH15fKssQbMPEmt-A@mail.gmail.com>
Message-ID: <CAC8ss32FAm8CAeyimxORcTofYXN9jgvnakdwtKV=Ff2FAuYytQ@mail.gmail.com>

Dear Abby,
Thank you.  I will look at your stimulated data and then run the code with
it.

But since I am dealing with real data and also have volumes of it,  I would
like to send my real data to you.

The OULU05 is attached with dput function.  It is labeled Ogbos_dput.  I
would be surprised if it was stripped off.  Then I will resend it.  If,  on
the other hand,  you don't want it as dput data,  then I will email the
large data through your private box.
Warmest regards
Ogbos

On Sun, Feb 16, 2020, 08:14 Abby Spurdle <spurdle.a at gmail.com> wrote:

> Note that your post does not contain a minimal reproducible example.
> I, and presumably most other readers, do not have the file "OULU05".
>
> Also, your first post referred to "% CR variation", however, your
> second post referred to "counts".
>
> I created a simple simulated data set:
>
> --------
> sim.data = function ()
> {   year = 1:100
>     month = (0:99 %% 12) + 1
>     day = (0:99 %% 28) + 1
>     counts = sample (1:2000, 100)
>     data.frame (year, month, day, counts)
> }
> data = sim.data ()
> --------
>
> After replacing the "data" object (as above), everything worked fine.
> (Except that the inequality needed modification based on the value of
> counts).
>
> Maybe the problem is with your dataset...?
> Or maybe there's some step in your code that results in missing
> values, given your input?
>
> Also note that the head and tail functions, are useful for both
> inspecting data, and describing your data to others.
>
> --------
> head (data)
> tail (data)
> --------
>

	[[alternative HTML version deleted]]


From d@cty|orh|z@ @end|ng |rom gm@||@com  Sun Feb 16 13:21:33 2020
From: d@cty|orh|z@ @end|ng |rom gm@||@com (Alexey Shipunov)
Date: Sun, 16 Feb 2020 21:21:33 +0900
Subject: [R] Unintended behaviour (possibly bugs)
Message-ID: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>

Dear list,

I have been advised to share these with R-help instead of filling the
bug report:

1) dotchart() does not allow to see the left axis title ('ylab') and
cannot change the left margin (outer margin 2) of the plot

The code:

aa <- table(c(1, 1, 1, 2, 2, 3))
dotchart(aa, ylab="Ylab") # does not show 'ylab'
old.par <- par(mar=c(1, 10, 1, 1)) ; dotchart(aa, ylab="Ylab") ;
par(old.par) # does not change left margin

Possible solution:

I researched the problem and think that the dotchart() code will need
few corrections. If there is an interest, I can post it here; or you
can look at the code of shipunov::Dotchart1() function.

2) example(hist) includes two "wrong" and "extreme" examples which
slow down and even crash R on some systems; this make it unsuitable
for demonstration in the class and strikes beginners in R who just
want to understand how hist() works. Actually, I did it last week (I
was not aware of these examples), and in the class two computers hang,
and many others were extremely slow.

The code:

example(hist)

Possible solution:

If R maintainers will enclose parts of "hist" example in \dontrun{},
this will allow to see the code but in the same time will not strike
beginners in R who just
want to understand how hist() works. They will still be possible to
run with example(..., run.dontrun=TRUE).

With best wishes,

Alexey Shipunov


From Servet@Ahmet@C|zme|| @end|ng |rom USherbrooke@c@  Sun Feb 16 12:03:55 2020
From: Servet@Ahmet@C|zme|| @end|ng |rom USherbrooke@c@ (=?Windows-1252?Q?Servet_Ahmet_=C7izmeli?=)
Date: Sun, 16 Feb 2020 11:03:55 +0000
Subject: [R] testing my package : unstated dependency to self in package
 tests
Message-ID: <QB1PR01MB3234EC8D15A32C8968F7F452BA170@QB1PR01MB3234.CANPRD01.PROD.OUTLOOK.COM>

I am updating my CRAN package geoSpectral. I get the following Warning during R CMD check :

...
* checking for unstated dependencies in ?tests? ... WARNING
'library' or 'require' call not declared from: ?geoSpectral?
....


All the .R files I have under the testhat directory begin by :
library(geoSpectral)
library(testthat)

and there I call package functions directly (without the prefix  geoSpectal::  )
See https://github.com/cran/geoSpectral/blob/master/tests/testthat/Spectra_tests.R

Searching the web, I found examples where the same Warning has been issued for some other packages. But in my case the package in question is my own package I am testing....

Confused and at loss.  Anyone with ideas?
regards
Servet

	[[alternative HTML version deleted]]


From g||ted|||e2014 @end|ng |rom gm@||@com  Sun Feb 16 17:09:01 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Sun, 16 Feb 2020 17:09:01 +0100
Subject: [R] Identification of Turning Points in a Signal
In-Reply-To: <CAC8ss32FAm8CAeyimxORcTofYXN9jgvnakdwtKV=Ff2FAuYytQ@mail.gmail.com>
References: <CAC8ss32tKdyzzGkcDqKCV2wgpFVWhgPHkicAsQq-gVEOCqZPhw@mail.gmail.com>
 <CAB8pepxuvjsbT34yAPft9p7ju1TXkPo5fMkrvBmuYh+cLZTntw@mail.gmail.com>
 <CAC8ss33XH4vDxfWrFSYr=23CsLshWiZVqaZso7U8U6Z_k5Yksg@mail.gmail.com>
 <CAB8pepwGHvimzHaoBVBunsDxSFncXvrsKJH15fKssQbMPEmt-A@mail.gmail.com>
 <CAC8ss32FAm8CAeyimxORcTofYXN9jgvnakdwtKV=Ff2FAuYytQ@mail.gmail.com>
Message-ID: <CAC8ss32mQiPtLo+KR_jcjpxNNX3H9aZWGy98R4B0QUq=vPZJgQ@mail.gmail.com>

Dear Abby,
I have run your code with the generated data. Thanks.

The first script still runs OK while the second script had the same
issues with your generated data (it could not identify the pits).

I will try to attach the data, OULU05. The head and tail of the data are:
  year month day counts
1    5     1   1   6080
2    5     1   2   6027
3    5     1   3   5824
4    5     1   4   5807
5    5     1   5   5828
6    5     1   6   5888
 and
 year month day counts
360    5    12  26   6281
361    5    12  27   6288
362    5    12  28   6274
363    5    12  29   6272
364    5    12  30   6258
365    5    12  31   6150
Best regards
Ogbos

On Sun, Feb 16, 2020 at 8:57 AM Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>
> Dear Abby,
> Thank you.  I will look at your stimulated data and then run the code with it.
>
> But since I am dealing with real data and also have volumes of it,  I would like to send my real data to you.
>
> The OULU05 is attached with dput function.  It is labeled Ogbos_dput.  I would be surprised if it was stripped off.  Then I will resend it.  If,  on the other hand,  you don't want it as dput data,  then I will email the large data through your private box.
> Warmest regards
> Ogbos
>
> On Sun, Feb 16, 2020, 08:14 Abby Spurdle <spurdle.a at gmail.com> wrote:
>>
>> Note that your post does not contain a minimal reproducible example.
>> I, and presumably most other readers, do not have the file "OULU05".
>>
>> Also, your first post referred to "% CR variation", however, your
>> second post referred to "counts".
>>
>> I created a simple simulated data set:
>>
>> --------
>> sim.data = function ()
>> {   year = 1:100
>>     month = (0:99 %% 12) + 1
>>     day = (0:99 %% 28) + 1
>>     counts = sample (1:2000, 100)
>>     data.frame (year, month, day, counts)
>> }
>> data = sim.data ()
>> --------
>>
>> After replacing the "data" object (as above), everything worked fine.
>> (Except that the inequality needed modification based on the value of counts).
>>
>> Maybe the problem is with your dataset...?
>> Or maybe there's some step in your code that results in missing
>> values, given your input?
>>
>> Also note that the head and tail functions, are useful for both
>> inspecting data, and describing your data to others.
>>
>> --------
>> head (data)
>> tail (data)
>> --------

From jrkr|de@u @end|ng |rom gm@||@com  Sun Feb 16 17:31:23 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Sun, 16 Feb 2020 11:31:23 -0500
Subject: [R] Unintended behaviour (possibly bugs)
In-Reply-To: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
References: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
Message-ID: <CAKZQJMCPKSi-WwcCNftSBvqucujDvAWHv6qtqKNruFKXC+AJ6A@mail.gmail.com>

Try aa <- as.matrix(table(c(1, 1, 1, 2, 2, 3)))
dotchart(aa, ylab="Ylab")

It may wock

On Sun, 16 Feb 2020 at 07:22, Alexey Shipunov <dactylorhiza at gmail.com>
wrote:

> Dear list,
>
> I have been advised to share these with R-help instead of filling the
> bug report:
>
> 1) dotchart() does not allow to see the left axis title ('ylab') and
> cannot change the left margin (outer margin 2) of the plot
>
> The code:
>
> aa <- table(c(1, 1, 1, 2, 2, 3))
> dotchart(aa, ylab="Ylab") # does not show 'ylab'
> old.par <- par(mar=c(1, 10, 1, 1)) ; dotchart(aa, ylab="Ylab") ;
> par(old.par) # does not change left margin
>
> Possible solution:
>
> I researched the problem and think that the dotchart() code will need
> few corrections. If there is an interest, I can post it here; or you
> can look at the code of shipunov::Dotchart1() function.
>
> 2) example(hist) includes two "wrong" and "extreme" examples which
> slow down and even crash R on some systems; this make it unsuitable
> for demonstration in the class and strikes beginners in R who just
> want to understand how hist() works. Actually, I did it last week (I
> was not aware of these examples), and in the class two computers hang,
> and many others were extremely slow.
>
> The code:
>
> example(hist)
>
> Possible solution:
>
> If R maintainers will enclose parts of "hist" example in \dontrun{},
> this will allow to see the code but in the same time will not strike
> beginners in R who just
> want to understand how hist() works. They will still be possible to
> run with example(..., run.dontrun=TRUE).
>
> With best wishes,
>
> Alexey Shipunov
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Sun Feb 16 17:54:29 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Sun, 16 Feb 2020 16:54:29 +0000
Subject: [R] testing my package : unstated dependency to self in package
 tests
In-Reply-To: <QB1PR01MB3234EC8D15A32C8968F7F452BA170@QB1PR01MB3234.CANPRD01.PROD.OUTLOOK.COM>
References: <QB1PR01MB3234EC8D15A32C8968F7F452BA170@QB1PR01MB3234.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <161c90d7-be6c-493c-400e-fc4b2bc7fb0b@dewey.myzen.co.uk>

When something similar happened to me I found it went away when I added 
Suggests: <packagename>
to the DESCRIPTION file. Whether this will work for you I have no idea.

Michael

On 16/02/2020 11:03, Servet Ahmet ?izmeli wrote:
> I am updating my CRAN package geoSpectral. I get the following Warning during R CMD check :
> 
> ...
> * checking for unstated dependencies in ?tests? ... WARNING
> 'library' or 'require' call not declared from: ?geoSpectral?
> ....
> 
> 
> All the .R files I have under the testhat directory begin by :
> library(geoSpectral)
> library(testthat)
> 
> and there I call package functions directly (without the prefix  geoSpectal::  )
> See https://github.com/cran/geoSpectral/blob/master/tests/testthat/Spectra_tests.R
> 
> Searching the web, I found examples where the same Warning has been issued for some other packages. But in my case the package in question is my own package I am testing....
> 
> Confused and at loss.  Anyone with ideas?
> regards
> Servet
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Feb 16 17:55:46 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 16 Feb 2020 16:55:46 +0000
Subject: [R] Unintended behaviour (possibly bugs)
In-Reply-To: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
References: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
Message-ID: <bd143039-d302-fee9-7350-ec01a61c17e1@sapo.pt>

Hello,

I believe you are wrong, the error is not in dotchart, it's in your 
code. You assume that to plot an object of class "table" is the same as 
to plot an object of class "numeric".

Inline.

?s 12:21 de 16/02/20, Alexey Shipunov escreveu:
> Dear list,
> 
> I have been advised to share these with R-help instead of filling the
> bug report:
> 
> 1) dotchart() does not allow to see the left axis title ('ylab') and
> cannot change the left margin (outer margin 2) of the plot
> 
> The code:
> 
> aa <- table(c(1, 1, 1, 2, 2, 3))
> dotchart(aa, ylab="Ylab") # does not show 'ylab'

You are right, it does *not* show 'ylab' but the user is warned.


aa <- table(c(1, 1, 1, 2, 2, 3))
dotchart(aa, ylab = "Ylab") # does show 'ylab'
#Warning message:
#In dotchart(aa, ylab = "Ylab") :
#  'x' is neither a vector nor a matrix: using as.numeric(x)


My code:


(mar <- par("mar"))    # new R session
#[1] 5.1 4.1 4.1 2.1   # the left margin is 4.1

aa <- as.numeric(table(c(1, 1, 1, 2, 2, 3)))

dotchart(aa, ylab = "Ylab") # It does show 'ylab'
old.par <- par(mar = mar + c(0, 5, 0, 0))
par("mar")
#[1] 5.1 9.1 4.1 2.1

dotchart(aa, ylab = "Ylab")  # The left margin is now 9.1, much bigger

par(old.par)                 # It does change the left margin
dotchart(aa, ylab = "Ylab")  #  but only when a new graph is plotted.



> old.par <- par(mar=c(1, 10, 1, 1)) ; dotchart(aa, ylab="Ylab") ;
> par(old.par) # does not change left margin
> 
> Possible solution:
> 
> I researched the problem and think that the dotchart() code will need
> few corrections. If there is an interest, I can post it here; or you
> can look at the code of shipunov::Dotchart1() function.
> 
> 2) example(hist) includes two "wrong" and "extreme" examples which
> slow down and even crash R on some systems; this make it unsuitable
> for demonstration in the class and strikes beginners in R who just
> want to understand how hist() works. Actually, I did it last week (I
> was not aware of these examples), and in the class two computers hang,
> and many others were extremely slow.
> 
> The code:
> 
> example(hist)
> 
> Possible solution:
> 
> If R maintainers will enclose parts of "hist" example in \dontrun{},
> this will allow to see the code but in the same time will not strike
> beginners in R who just
> want to understand how hist() works. They will still be possible to
> run with example(..., run.dontrun=TRUE).

Agree, it's annoying. Sometimes there's a Warning section after the 
Details section. Maybe such a section could get users' attention to 
those examples? At least it wouldn't hurt...


Hope this helps,

Rui Barradas

> 
> With best wishes,
> 
> Alexey Shipunov
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Feb 16 18:22:13 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 16 Feb 2020 09:22:13 -0800
Subject: [R] testing my package : unstated dependency to self in package
 tests
In-Reply-To: <QB1PR01MB3234EC8D15A32C8968F7F452BA170@QB1PR01MB3234.CANPRD01.PROD.OUTLOOK.COM>
References: <QB1PR01MB3234EC8D15A32C8968F7F452BA170@QB1PR01MB3234.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <886803C7-8F4F-491D-883A-DFFF488E497B@dcn.davis.ca.us>

I think the Posting Guide would call this the wrong mailing list for this question: should be on R-package-devel.

On February 16, 2020 3:03:55 AM PST, "Servet Ahmet ?izmeli" <Servet.Ahmet.Cizmeli at USherbrooke.ca> wrote:
>I am updating my CRAN package geoSpectral. I get the following Warning
>during R CMD check :
>
>...
>* checking for unstated dependencies in ?tests? ... WARNING
>'library' or 'require' call not declared from: ?geoSpectral?
>....
>
>
>All the .R files I have under the testhat directory begin by :
>library(geoSpectral)
>library(testthat)
>
>and there I call package functions directly (without the prefix 
>geoSpectal::  )
>See
>https://github.com/cran/geoSpectral/blob/master/tests/testthat/Spectra_tests.R
>
>Searching the web, I found examples where the same Warning has been
>issued for some other packages. But in my case the package in question
>is my own package I am testing....
>
>Confused and at loss.  Anyone with ideas?
>regards
>Servet
>
>	[[alternative HTML version deleted]]

-- 
Sent from my phone. Please excuse my brevity.


From @purd|e@@ @end|ng |rom gm@||@com  Sun Feb 16 21:29:18 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 17 Feb 2020 09:29:18 +1300
Subject: [R] Identification of Turning Points in a Signal
In-Reply-To: <CAC8ss32FAm8CAeyimxORcTofYXN9jgvnakdwtKV=Ff2FAuYytQ@mail.gmail.com>
References: <CAC8ss32tKdyzzGkcDqKCV2wgpFVWhgPHkicAsQq-gVEOCqZPhw@mail.gmail.com>
 <CAB8pepxuvjsbT34yAPft9p7ju1TXkPo5fMkrvBmuYh+cLZTntw@mail.gmail.com>
 <CAC8ss33XH4vDxfWrFSYr=23CsLshWiZVqaZso7U8U6Z_k5Yksg@mail.gmail.com>
 <CAB8pepwGHvimzHaoBVBunsDxSFncXvrsKJH15fKssQbMPEmt-A@mail.gmail.com>
 <CAC8ss32FAm8CAeyimxORcTofYXN9jgvnakdwtKV=Ff2FAuYytQ@mail.gmail.com>
Message-ID: <CAB8pepy4GJRFg5y5kVouW+tzJ-KGN=cTtqagbXTTVyBrv3a12w@mail.gmail.com>

The data are different sizes.
(As I suggested in my first post).

The turnpoints function removes "ex-aequos".

Replace the following:
------
minima<-which(tp$pit & data$residual<= 20)
-----

With:
------
pits = rep (FALSE, nrow (data) )
pits [tp$pos] = tp$pits
minima<-which(pits & data$residual<= -100)
------

Should remove the warning.

But there's a second problem:

range (data$residual)
output:
    [1] -14.97602  11.53771

There are no "residuals less than -100.
So you'll need to fix that too.


B.


On Sun, Feb 16, 2020 at 10:32 PM Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>
> Dear Abby,
> Thank you.  I will look at your stimulated data and then run the code with it.
>
> But since I am dealing with real data and also have volumes of it,  I would like to send my real data to you.
>
> The OULU05 is attached with dput function.  It is labeled Ogbos_dput.  I would be surprised if it was stripped off.  Then I will resend it.  If,  on the other hand,  you don't want it as dput data,  then I will email the large data through your private box.
> Warmest regards
> Ogbos
>
> On Sun, Feb 16, 2020, 08:14 Abby Spurdle <spurdle.a at gmail.com> wrote:
>>
>> Note that your post does not contain a minimal reproducible example.
>> I, and presumably most other readers, do not have the file "OULU05".
>>
>> Also, your first post referred to "% CR variation", however, your
>> second post referred to "counts".
>>
>> I created a simple simulated data set:
>>
>> --------
>> sim.data = function ()
>> {   year = 1:100
>>     month = (0:99 %% 12) + 1
>>     day = (0:99 %% 28) + 1
>>     counts = sample (1:2000, 100)
>>     data.frame (year, month, day, counts)
>> }
>> data = sim.data ()
>> --------
>>
>> After replacing the "data" object (as above), everything worked fine.
>> (Except that the inequality needed modification based on the value of counts).
>>
>> Maybe the problem is with your dataset...?
>> Or maybe there's some step in your code that results in missing
>> values, given your input?
>>
>> Also note that the head and tail functions, are useful for both
>> inspecting data, and describing your data to others.
>>
>> --------
>> head (data)
>> tail (data)
>> --------


From p_conno||y @end|ng |rom @||ng@hot@co@nz  Sun Feb 16 21:35:23 2020
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (p_connolly)
Date: Mon, 17 Feb 2020 09:35:23 +1300
Subject: [R] What is  the ggplot analog  of the axis() function?
Message-ID: <7368541a75af510b87a329de5e028e19@slingshot.co.nz>

Using base R graphics I can customize the position of the tick marks and 
what text to label them by using the axis function and adjusting the 
`at` and `labels` parameters respectively.

What theme setting do I adjust using ggplot2 graphics to achieve a 
similar result?

TIA

Patrick


From pj@|nh@07 @end|ng |rom gm@||@com  Sun Feb 16 23:01:14 2020
From: pj@|nh@07 @end|ng |rom gm@||@com (pooja sinha)
Date: Sun, 16 Feb 2020 17:01:14 -0500
Subject: [R] Unable to make plots using ggplot2
Message-ID: <CAGjf1cOqjyp7p23m2gdcr6_THx3qj7zauFm+CdMcdHw5ix-XSg@mail.gmail.com>

Hi All,

I have data in excel with the following details:
CHG_methylation Young_Control Young_Treated
0-10% 95.23 94.53
10-20% 3.71 4.16
20-30% 0.68 0.8
30-40% 0.18 0.22
40-50% 0.07 0.09
50-60% 0.04 0.06
60-70% 0.02 0.04
70-80% 0.02 0.03
80-90% 0.02 0.03
90-100% 0.04 0.05
I am trying to plot the graph using ggplot2 but not successful yet. My code
is below:

library(readxl)
library(dplyr)
library(tidyverse)
data2 <- read_excel("CHG_meth_plot1.xlsx")
df <- data2
df <- data.frame(var=c("Young_Control", "Young_Treated", "CHG_methylation"))
df

ggplot(data = df, aes(x = var, y = CHG_methylation)) +
  geom_bar(aes(fill = CHG_methylation))

I am getting error as something is wrong with my df. Also I needed to
create breaks in y-axis as I do not know whether it is possible in R or
not.
Any kind of help is highly appreciated.

Thanks,
Puja

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sun Feb 16 23:08:04 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 16 Feb 2020 14:08:04 -0800
Subject: [R] Unable to make plots using ggplot2
In-Reply-To: <CAGjf1cOqjyp7p23m2gdcr6_THx3qj7zauFm+CdMcdHw5ix-XSg@mail.gmail.com>
References: <CAGjf1cOqjyp7p23m2gdcr6_THx3qj7zauFm+CdMcdHw5ix-XSg@mail.gmail.com>
Message-ID: <CAGxFJbS6h5mN3PM1uybHqv077+qN1N4COPRKnh3t-maPtdQWcA@mail.gmail.com>

What do you think these two statements do?

df <- data2
df <- data.frame(var=c("Young_Control", "Young_Treated", "CHG_methylation"))

I suggest you stop what you're doing and spend time with an R tutorial or
two before proceeding.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Feb 16, 2020 at 2:01 PM pooja sinha <pjsinha07 at gmail.com> wrote:

> Hi All,
>
> I have data in excel with the following details:
> CHG_methylation Young_Control Young_Treated
> 0-10% 95.23 94.53
> 10-20% 3.71 4.16
> 20-30% 0.68 0.8
> 30-40% 0.18 0.22
> 40-50% 0.07 0.09
> 50-60% 0.04 0.06
> 60-70% 0.02 0.04
> 70-80% 0.02 0.03
> 80-90% 0.02 0.03
> 90-100% 0.04 0.05
> I am trying to plot the graph using ggplot2 but not successful yet. My code
> is below:
>
> library(readxl)
> library(dplyr)
> library(tidyverse)
> data2 <- read_excel("CHG_meth_plot1.xlsx")
> df <- data2
> df <- data.frame(var=c("Young_Control", "Young_Treated",
> "CHG_methylation"))
> df
>
> ggplot(data = df, aes(x = var, y = CHG_methylation)) +
>   geom_bar(aes(fill = CHG_methylation))
>
> I am getting error as something is wrong with my df. Also I needed to
> create breaks in y-axis as I do not know whether it is possible in R or
> not.
> Any kind of help is highly appreciated.
>
> Thanks,
> Puja
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From g||ted|||e2014 @end|ng |rom gm@||@com  Sun Feb 16 23:15:18 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Sun, 16 Feb 2020 23:15:18 +0100
Subject: [R] Identification of Turning Points in a Signal: Problem Fixed
In-Reply-To: <CAB8pepy4GJRFg5y5kVouW+tzJ-KGN=cTtqagbXTTVyBrv3a12w@mail.gmail.com>
References: <CAC8ss32tKdyzzGkcDqKCV2wgpFVWhgPHkicAsQq-gVEOCqZPhw@mail.gmail.com>
 <CAB8pepxuvjsbT34yAPft9p7ju1TXkPo5fMkrvBmuYh+cLZTntw@mail.gmail.com>
 <CAC8ss33XH4vDxfWrFSYr=23CsLshWiZVqaZso7U8U6Z_k5Yksg@mail.gmail.com>
 <CAB8pepwGHvimzHaoBVBunsDxSFncXvrsKJH15fKssQbMPEmt-A@mail.gmail.com>
 <CAC8ss32FAm8CAeyimxORcTofYXN9jgvnakdwtKV=Ff2FAuYytQ@mail.gmail.com>
 <CAB8pepy4GJRFg5y5kVouW+tzJ-KGN=cTtqagbXTTVyBrv3a12w@mail.gmail.com>
Message-ID: <CAC8ss307HXcWfecg5sRmHenET1roNvxZWoA4_0Qkrm_Mbahdkw@mail.gmail.com>

Dear Abby,
I am very happy to report that the three lines you added have
completely solved the problem. It is great to me. I have, for the past
one week, approached the problem from various angles without much
success.

Thank you.

Warmest regards
Ogbos

On Sun, Feb 16, 2020 at 9:30 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> The data are different sizes.
> (As I suggested in my first post).
>
> The turnpoints function removes "ex-aequos".
>
> Replace the following:
> ------
> minima<-which(tp$pit & data$residual<= 20)
> -----
>
> With:
> ------
> pits = rep (FALSE, nrow (data) )
> pits [tp$pos] = tp$pits
> minima<-which(pits & data$residual<= -100)
> ------
>
> Should remove the warning.
>
> But there's a second problem:
>
> range (data$residual)
> output:
>     [1] -14.97602  11.53771
>
> There are no "residuals less than -100.
> So you'll need to fix that too.
>
>
> B.
>
>
> On Sun, Feb 16, 2020 at 10:32 PM Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> >
> > Dear Abby,
> > Thank you.  I will look at your stimulated data and then run the code with it.
> >
> > But since I am dealing with real data and also have volumes of it,  I would like to send my real data to you.
> >
> > The OULU05 is attached with dput function.  It is labeled Ogbos_dput.  I would be surprised if it was stripped off.  Then I will resend it.  If,  on the other hand,  you don't want it as dput data,  then I will email the large data through your private box.
> > Warmest regards
> > Ogbos
> >
> > On Sun, Feb 16, 2020, 08:14 Abby Spurdle <spurdle.a at gmail.com> wrote:
> >>
> >> Note that your post does not contain a minimal reproducible example.
> >> I, and presumably most other readers, do not have the file "OULU05".
> >>
> >> Also, your first post referred to "% CR variation", however, your
> >> second post referred to "counts".
> >>
> >> I created a simple simulated data set:
> >>
> >> --------
> >> sim.data = function ()
> >> {   year = 1:100
> >>     month = (0:99 %% 12) + 1
> >>     day = (0:99 %% 28) + 1
> >>     counts = sample (1:2000, 100)
> >>     data.frame (year, month, day, counts)
> >> }
> >> data = sim.data ()
> >> --------
> >>
> >> After replacing the "data" object (as above), everything worked fine.
> >> (Except that the inequality needed modification based on the value of counts).
> >>
> >> Maybe the problem is with your dataset...?
> >> Or maybe there's some step in your code that results in missing
> >> values, given your input?
> >>
> >> Also note that the head and tail functions, are useful for both
> >> inspecting data, and describing your data to others.
> >>
> >> --------
> >> head (data)
> >> tail (data)
> >> --------


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Feb 16 23:23:28 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 16 Feb 2020 22:23:28 +0000
Subject: [R] Unable to make plots using ggplot2
In-Reply-To: <CAGjf1cOqjyp7p23m2gdcr6_THx3qj7zauFm+CdMcdHw5ix-XSg@mail.gmail.com>
References: <CAGjf1cOqjyp7p23m2gdcr6_THx3qj7zauFm+CdMcdHw5ix-XSg@mail.gmail.com>
Message-ID: <2d9df8f9-f91e-4a5c-69df-50eb80004d4e@sapo.pt>

Hello,

Your error is that you are not plotting the values in your file
See what is in df, it's one column only with 3 character strings, 
c("Young_Control", "Young_Treated", "CHG_methylation"). Those *are not* 
the names of columns, they are just strings.

The right way of doing it is to reshape your data from wide format to 
long format first. I will reformat with tidyr::pivot_longer and pipe the 
result directly to ggplot.

Also, given the large difference in the values plotted, I suggest you 
comment out the code line with "log10", it will plot the y axis in the 
logarithmic scale.


library(tidyverse)
library(ggplot2)

df1 %>%
   pivot_longer(
     cols = c("Young_Control", "Young_Treated"),
     names_to = "Treatment",
     values_to = "Value"
   ) %>%
   ggplot(aes(x = CHG_methylation, y = Value, fill = Treatment)) +
   geom_col(position = position_dodge(0.9)) +
   #scale_y_continuous(trans = "log10") +
   theme(axis.text.x = element_text(angle = 60, vjust = 1))


Hope this helps,

Rui Barradas


?s 22:01 de 16/02/20, pooja sinha escreveu:
> Hi All,
> 
> I have data in excel with the following details:
> CHG_methylation Young_Control Young_Treated
> 0-10% 95.23 94.53
> 10-20% 3.71 4.16
> 20-30% 0.68 0.8
> 30-40% 0.18 0.22
> 40-50% 0.07 0.09
> 50-60% 0.04 0.06
> 60-70% 0.02 0.04
> 70-80% 0.02 0.03
> 80-90% 0.02 0.03
> 90-100% 0.04 0.05
> I am trying to plot the graph using ggplot2 but not successful yet. My code
> is below:
> 
> library(readxl)
> library(dplyr)
> library(tidyverse)
> data2 <- read_excel("CHG_meth_plot1.xlsx")
> df <- data2
> df <- data.frame(var=c("Young_Control", "Young_Treated", "CHG_methylation"))
> df
> 
> ggplot(data = df, aes(x = var, y = CHG_methylation)) +
>    geom_bar(aes(fill = CHG_methylation))
> 
> I am getting error as something is wrong with my df. Also I needed to
> create breaks in y-axis as I do not know whether it is possible in R or
> not.
> Any kind of help is highly appreciated.
> 
> Thanks,
> Puja
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Feb 16 23:31:59 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 16 Feb 2020 22:31:59 +0000
Subject: [R] What is the ggplot analog of the axis() function?
In-Reply-To: <7368541a75af510b87a329de5e028e19@slingshot.co.nz>
References: <7368541a75af510b87a329de5e028e19@slingshot.co.nz>
Message-ID: <5b35b593-70ee-71c4-54f7-ace25f716721@sapo.pt>

Hello,

In ggplot2, to set the placement and labels of the axis use

?scale_x_continuous
?scale_y_continuous

and similar functions. The arguments you would want are 'breaks' and 
'labels'.

Then you can further customize with ?theme. Arguments such as axis.text 
or axis.ticks are what you would use.

This is a (very) broad question, if you have doubts in something more 
specific, say so.

Hope this helps,

Rui Barradas

?s 20:35 de 16/02/20, p_connolly escreveu:
> Using base R graphics I can customize the position of the tick marks and 
> what text to label them by using the axis function and adjusting the 
> `at` and `labels` parameters respectively.
> 
> What theme setting do I adjust using ggplot2 graphics to achieve a 
> similar result?
> 
> TIA
> 
> Patrick
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pj@|nh@07 @end|ng |rom gm@||@com  Mon Feb 17 02:00:51 2020
From: pj@|nh@07 @end|ng |rom gm@||@com (pooja sinha)
Date: Sun, 16 Feb 2020 20:00:51 -0500
Subject: [R] Unable to make plots using ggplot2
In-Reply-To: <2d9df8f9-f91e-4a5c-69df-50eb80004d4e@sapo.pt>
References: <CAGjf1cOqjyp7p23m2gdcr6_THx3qj7zauFm+CdMcdHw5ix-XSg@mail.gmail.com>
 <2d9df8f9-f91e-4a5c-69df-50eb80004d4e@sapo.pt>
Message-ID: <CAGjf1cPXGXLuegcbr5sN2uxwmjDU1AbruLXz4KEKqxVsMGR0Mg@mail.gmail.com>

Thanks for your suggestion and code.


Puja

On Sun, Feb 16, 2020 at 5:23 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Your error is that you are not plotting the values in your file
> See what is in df, it's one column only with 3 character strings,
> c("Young_Control", "Young_Treated", "CHG_methylation"). Those *are not*
> the names of columns, they are just strings.
>
> The right way of doing it is to reshape your data from wide format to
> long format first. I will reformat with tidyr::pivot_longer and pipe the
> result directly to ggplot.
>
> Also, given the large difference in the values plotted, I suggest you
> comment out the code line with "log10", it will plot the y axis in the
> logarithmic scale.
>
>
> library(tidyverse)
> library(ggplot2)
>
> df1 %>%
>    pivot_longer(
>      cols = c("Young_Control", "Young_Treated"),
>      names_to = "Treatment",
>      values_to = "Value"
>    ) %>%
>    ggplot(aes(x = CHG_methylation, y = Value, fill = Treatment)) +
>    geom_col(position = position_dodge(0.9)) +
>    #scale_y_continuous(trans = "log10") +
>    theme(axis.text.x = element_text(angle = 60, vjust = 1))
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 22:01 de 16/02/20, pooja sinha escreveu:
> > Hi All,
> >
> > I have data in excel with the following details:
> > CHG_methylation Young_Control Young_Treated
> > 0-10% 95.23 94.53
> > 10-20% 3.71 4.16
> > 20-30% 0.68 0.8
> > 30-40% 0.18 0.22
> > 40-50% 0.07 0.09
> > 50-60% 0.04 0.06
> > 60-70% 0.02 0.04
> > 70-80% 0.02 0.03
> > 80-90% 0.02 0.03
> > 90-100% 0.04 0.05
> > I am trying to plot the graph using ggplot2 but not successful yet. My
> code
> > is below:
> >
> > library(readxl)
> > library(dplyr)
> > library(tidyverse)
> > data2 <- read_excel("CHG_meth_plot1.xlsx")
> > df <- data2
> > df <- data.frame(var=c("Young_Control", "Young_Treated",
> "CHG_methylation"))
> > df
> >
> > ggplot(data = df, aes(x = var, y = CHG_methylation)) +
> >    geom_bar(aes(fill = CHG_methylation))
> >
> > I am getting error as something is wrong with my df. Also I needed to
> > create breaks in y-axis as I do not know whether it is possible in R or
> > not.
> > Any kind of help is highly appreciated.
> >
> > Thanks,
> > Puja
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From p_conno||y @end|ng |rom @||ng@hot@co@nz  Mon Feb 17 03:01:18 2020
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (p_connolly)
Date: Mon, 17 Feb 2020 15:01:18 +1300
Subject: [R] What is the ggplot analog of the axis() function?
In-Reply-To: <5b35b593-70ee-71c4-54f7-ace25f716721@sapo.pt>
References: <7368541a75af510b87a329de5e028e19@slingshot.co.nz>
 <5b35b593-70ee-71c4-54f7-ace25f716721@sapo.pt>
Message-ID: <c55be87041f50b4de0e3473b27296a21@slingshot.co.nz>

Thanks Rui,

I had looked at the scale_continuous functions and found the help 
overwhelming.  But thanks for the information:  `labels` works the same 
as it does in axis() and `breaks` is what I needed to correspond to the 
`at` argument.

Regards
Patrick


On 2020-02-17 11:31, Rui Barradas wrote:
> Hello,
> 
> In ggplot2, to set the placement and labels of the axis use
> 
> ?scale_x_continuous
> ?scale_y_continuous
> 
> and similar functions. The arguments you would want are 'breaks' and 
> 'labels'.
> 
> Then you can further customize with ?theme. Arguments such as
> axis.text or axis.ticks are what you would use.
> 
> This is a (very) broad question, if you have doubts in something more
> specific, say so.
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 20:35 de 16/02/20, p_connolly escreveu:
>> Using base R graphics I can customize the position of the tick marks 
>> and what text to label them by using the axis function and adjusting 
>> the `at` and `labels` parameters respectively.
>> 
>> What theme setting do I adjust using ggplot2 graphics to achieve a 
>> similar result?
>> 
>> TIA
>> 
>> Patrick
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From d@cty|orh|z@ @end|ng |rom gm@||@com  Mon Feb 17 04:33:47 2020
From: d@cty|orh|z@ @end|ng |rom gm@||@com (Alexey Shipunov)
Date: Mon, 17 Feb 2020 12:33:47 +0900
Subject: [R] Unintended behaviour (possibly bugs)
In-Reply-To: <bd143039-d302-fee9-7350-ec01a61c17e1@sapo.pt>
References: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
 <bd143039-d302-fee9-7350-ec01a61c17e1@sapo.pt>
Message-ID: <CAD-ePxZ-MytqqfQUiEE9+4e_T8kyfj4kiYcRTj4GsYcupGLj8A@mail.gmail.com>

John and Rui, thanks!

However, if we use the proper object, the problem still persists:

dotchart(c("3"=1, "2"=2, "1"=3), ylab="Ylab") # ylab is invisible
dotchart(c("aa"=1, "b"=2, "cc"=3), ylab="Ylab") # ylab is partly visible (!!!)
dotchart(c("aaa"=1, "bbb"=2, "ccc"=3), ylab="Ylab") # ylab is well visible

If the object is matrix, ylab is visible:

dotchart(matrix(1:3, dimnames=list(c("aa","bb","cc"), NULL)), ylab="Ylab")

But the ?dotchart explicitly says that "x: either a vector or matrix
of numeric values" and then "labels: a vector of labels for each
point.  For vectors the default is to use ?names(x)? ...".

So this is likely a bug. Do you agree?

Alexey

??, 17 ????. 2020 ?. ? 01:55, Rui Barradas <ruipbarradas at sapo.pt>:
>
> Hello,
>
> I believe you are wrong, the error is not in dotchart, it's in your
> code. You assume that to plot an object of class "table" is the same as
> to plot an object of class "numeric".
>
> Inline.
>
> ?s 12:21 de 16/02/20, Alexey Shipunov escreveu:
> > Dear list,
> >
> > I have been advised to share these with R-help instead of filling the
> > bug report:
> >
> > 1) dotchart() does not allow to see the left axis title ('ylab') and
> > cannot change the left margin (outer margin 2) of the plot
> >
> > The code:
> >
> > aa <- table(c(1, 1, 1, 2, 2, 3))
> > dotchart(aa, ylab="Ylab") # does not show 'ylab'
>
> You are right, it does *not* show 'ylab' but the user is warned.
>
>
> aa <- table(c(1, 1, 1, 2, 2, 3))
> dotchart(aa, ylab = "Ylab") # does show 'ylab'
> #Warning message:
> #In dotchart(aa, ylab = "Ylab") :
> #  'x' is neither a vector nor a matrix: using as.numeric(x)
>
>
> My code:
>
>
> (mar <- par("mar"))    # new R session
> #[1] 5.1 4.1 4.1 2.1   # the left margin is 4.1
>
> aa <- as.numeric(table(c(1, 1, 1, 2, 2, 3)))
>
> dotchart(aa, ylab = "Ylab") # It does show 'ylab'
> old.par <- par(mar = mar + c(0, 5, 0, 0))
> par("mar")
> #[1] 5.1 9.1 4.1 2.1
>
> dotchart(aa, ylab = "Ylab")  # The left margin is now 9.1, much bigger
>
> par(old.par)                 # It does change the left margin
> dotchart(aa, ylab = "Ylab")  #  but only when a new graph is plotted.
>
>
>
> > old.par <- par(mar=c(1, 10, 1, 1)) ; dotchart(aa, ylab="Ylab") ;
> > par(old.par) # does not change left margin
> >
> > Possible solution:
> >
> > I researched the problem and think that the dotchart() code will need
> > few corrections. If there is an interest, I can post it here; or you
> > can look at the code of shipunov::Dotchart1() function.
> >
> > 2) example(hist) includes two "wrong" and "extreme" examples which
> > slow down and even crash R on some systems; this make it unsuitable
> > for demonstration in the class and strikes beginners in R who just
> > want to understand how hist() works. Actually, I did it last week (I
> > was not aware of these examples), and in the class two computers hang,
> > and many others were extremely slow.
> >
> > The code:
> >
> > example(hist)
> >
> > Possible solution:
> >
> > If R maintainers will enclose parts of "hist" example in \dontrun{},
> > this will allow to see the code but in the same time will not strike
> > beginners in R who just
> > want to understand how hist() works. They will still be possible to
> > run with example(..., run.dontrun=TRUE).
>
> Agree, it's annoying. Sometimes there's a Warning section after the
> Details section. Maybe such a section could get users' attention to
> those examples? At least it wouldn't hurt...
>
>
> Hope this helps,
>
> Rui Barradas
>
> >
> > With best wishes,
> >
> > Alexey Shipunov
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Feb 17 05:54:23 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 17 Feb 2020 04:54:23 +0000
Subject: [R] Unintended behaviour (possibly bugs)
In-Reply-To: <CAD-ePxZ-MytqqfQUiEE9+4e_T8kyfj4kiYcRTj4GsYcupGLj8A@mail.gmail.com>
References: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
 <bd143039-d302-fee9-7350-ec01a61c17e1@sapo.pt>
 <CAD-ePxZ-MytqqfQUiEE9+4e_T8kyfj4kiYcRTj4GsYcupGLj8A@mail.gmail.com>
Message-ID: <cd83233c-5794-d741-cf9d-32d4435cf590@sapo.pt>

Hello,

Yes, this is definitely a bug.
Even the matrix plot is puzzling, with a "1" as top row sort-of-label 
but no grid line. I'm trying to follow the source code of dotchart but 
am yet to understand exactly what it does to decide the margins settings.

     if (!(is.null(labels) && is.null(glabels))) {
       nmai <- par("mai")
       nmai[2L] <- nmai[4L] + max(linch + goffset, ginch) +
         0.1
       par(mai = nmai)
     }

This should be moved to r-devel?

Rui Barradas

?s 03:33 de 17/02/20, Alexey Shipunov escreveu:
> John and Rui, thanks!
> 
> However, if we use the proper object, the problem still persists:
> 
> dotchart(c("3"=1, "2"=2, "1"=3), ylab="Ylab") # ylab is invisible
> dotchart(c("aa"=1, "b"=2, "cc"=3), ylab="Ylab") # ylab is partly visible (!!!)
> dotchart(c("aaa"=1, "bbb"=2, "ccc"=3), ylab="Ylab") # ylab is well visible
> 
> If the object is matrix, ylab is visible:
> 
> dotchart(matrix(1:3, dimnames=list(c("aa","bb","cc"), NULL)), ylab="Ylab")
> 
> But the ?dotchart explicitly says that "x: either a vector or matrix
> of numeric values" and then "labels: a vector of labels for each
> point.  For vectors the default is to use ?names(x)? ...".
> 
> So this is likely a bug. Do you agree?
> 
> Alexey
> 
> ??, 17 ????. 2020 ?. ? 01:55, Rui Barradas <ruipbarradas at sapo.pt>:
>>
>> Hello,
>>
>> I believe you are wrong, the error is not in dotchart, it's in your
>> code. You assume that to plot an object of class "table" is the same as
>> to plot an object of class "numeric".
>>
>> Inline.
>>
>> ?s 12:21 de 16/02/20, Alexey Shipunov escreveu:
>>> Dear list,
>>>
>>> I have been advised to share these with R-help instead of filling the
>>> bug report:
>>>
>>> 1) dotchart() does not allow to see the left axis title ('ylab') and
>>> cannot change the left margin (outer margin 2) of the plot
>>>
>>> The code:
>>>
>>> aa <- table(c(1, 1, 1, 2, 2, 3))
>>> dotchart(aa, ylab="Ylab") # does not show 'ylab'
>>
>> You are right, it does *not* show 'ylab' but the user is warned.
>>
>>
>> aa <- table(c(1, 1, 1, 2, 2, 3))
>> dotchart(aa, ylab = "Ylab") # does show 'ylab'
>> #Warning message:
>> #In dotchart(aa, ylab = "Ylab") :
>> #  'x' is neither a vector nor a matrix: using as.numeric(x)
>>
>>
>> My code:
>>
>>
>> (mar <- par("mar"))    # new R session
>> #[1] 5.1 4.1 4.1 2.1   # the left margin is 4.1
>>
>> aa <- as.numeric(table(c(1, 1, 1, 2, 2, 3)))
>>
>> dotchart(aa, ylab = "Ylab") # It does show 'ylab'
>> old.par <- par(mar = mar + c(0, 5, 0, 0))
>> par("mar")
>> #[1] 5.1 9.1 4.1 2.1
>>
>> dotchart(aa, ylab = "Ylab")  # The left margin is now 9.1, much bigger
>>
>> par(old.par)                 # It does change the left margin
>> dotchart(aa, ylab = "Ylab")  #  but only when a new graph is plotted.
>>
>>
>>
>>> old.par <- par(mar=c(1, 10, 1, 1)) ; dotchart(aa, ylab="Ylab") ;
>>> par(old.par) # does not change left margin
>>>
>>> Possible solution:
>>>
>>> I researched the problem and think that the dotchart() code will need
>>> few corrections. If there is an interest, I can post it here; or you
>>> can look at the code of shipunov::Dotchart1() function.
>>>
>>> 2) example(hist) includes two "wrong" and "extreme" examples which
>>> slow down and even crash R on some systems; this make it unsuitable
>>> for demonstration in the class and strikes beginners in R who just
>>> want to understand how hist() works. Actually, I did it last week (I
>>> was not aware of these examples), and in the class two computers hang,
>>> and many others were extremely slow.
>>>
>>> The code:
>>>
>>> example(hist)
>>>
>>> Possible solution:
>>>
>>> If R maintainers will enclose parts of "hist" example in \dontrun{},
>>> this will allow to see the code but in the same time will not strike
>>> beginners in R who just
>>> want to understand how hist() works. They will still be possible to
>>> run with example(..., run.dontrun=TRUE).
>>
>> Agree, it's annoying. Sometimes there's a Warning section after the
>> Details section. Maybe such a section could get users' attention to
>> those examples? At least it wouldn't hurt...
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>>
>>> With best wishes,
>>>
>>> Alexey Shipunov
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From d@cty|orh|z@ @end|ng |rom gm@||@com  Mon Feb 17 05:59:09 2020
From: d@cty|orh|z@ @end|ng |rom gm@||@com (Alexey Shipunov)
Date: Mon, 17 Feb 2020 13:59:09 +0900
Subject: [R] Unintended behaviour (possibly bugs)
In-Reply-To: <cd83233c-5794-d741-cf9d-32d4435cf590@sapo.pt>
References: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
 <bd143039-d302-fee9-7350-ec01a61c17e1@sapo.pt>
 <CAD-ePxZ-MytqqfQUiEE9+4e_T8kyfj4kiYcRTj4GsYcupGLj8A@mail.gmail.com>
 <cd83233c-5794-d741-cf9d-32d4435cf590@sapo.pt>
Message-ID: <CAD-ePxbR1iNBCBhghkEMr1yKohFz3aGwrN+8kQVZ02tWmPMySg@mail.gmail.com>

My suggestion (shipunov::Dotchart1()) was:

===
   yinch <- if (!is.null(ylab)) 0.4 else 0
   # inserted!
    if (!(is.null(labels) && is.null(glabels))) {
        nmai <- par("mai")
        nmai.2.new <- nmai[4L] + max(yinch + linch + goffset, ginch) +
0.1 # changed!
        if (nmai.2.new > nmai[2L]) {
    # changed!
            nmai[2L] <- nmai.2.new
    # changed!
        }
        par(mai = nmai)
    }
===

But I am not sure if this is the best way.

Now, how to move to r-devel? I never did it before.

Alexey

??, 17 ????. 2020 ?. ? 13:54, Rui Barradas <ruipbarradas at sapo.pt>:
>
> Hello,
>
> Yes, this is definitely a bug.
> Even the matrix plot is puzzling, with a "1" as top row sort-of-label
> but no grid line. I'm trying to follow the source code of dotchart but
> am yet to understand exactly what it does to decide the margins settings.
>
>      if (!(is.null(labels) && is.null(glabels))) {
>        nmai <- par("mai")
>        nmai[2L] <- nmai[4L] + max(linch + goffset, ginch) +
>          0.1
>        par(mai = nmai)
>      }
>
> This should be moved to r-devel?
>
> Rui Barradas
>
> ?s 03:33 de 17/02/20, Alexey Shipunov escreveu:
> > John and Rui, thanks!
> >
> > However, if we use the proper object, the problem still persists:
> >
> > dotchart(c("3"=1, "2"=2, "1"=3), ylab="Ylab") # ylab is invisible
> > dotchart(c("aa"=1, "b"=2, "cc"=3), ylab="Ylab") # ylab is partly visible (!!!)
> > dotchart(c("aaa"=1, "bbb"=2, "ccc"=3), ylab="Ylab") # ylab is well visible
> >
> > If the object is matrix, ylab is visible:
> >
> > dotchart(matrix(1:3, dimnames=list(c("aa","bb","cc"), NULL)), ylab="Ylab")
> >
> > But the ?dotchart explicitly says that "x: either a vector or matrix
> > of numeric values" and then "labels: a vector of labels for each
> > point.  For vectors the default is to use ?names(x)? ...".
> >
> > So this is likely a bug. Do you agree?
> >
> > Alexey
> >
> > ??, 17 ????. 2020 ?. ? 01:55, Rui Barradas <ruipbarradas at sapo.pt>:
> >>
> >> Hello,
> >>
> >> I believe you are wrong, the error is not in dotchart, it's in your
> >> code. You assume that to plot an object of class "table" is the same as
> >> to plot an object of class "numeric".
> >>
> >> Inline.
> >>
> >> ?s 12:21 de 16/02/20, Alexey Shipunov escreveu:
> >>> Dear list,
> >>>
> >>> I have been advised to share these with R-help instead of filling the
> >>> bug report:
> >>>
> >>> 1) dotchart() does not allow to see the left axis title ('ylab') and
> >>> cannot change the left margin (outer margin 2) of the plot
> >>>
> >>> The code:
> >>>
> >>> aa <- table(c(1, 1, 1, 2, 2, 3))
> >>> dotchart(aa, ylab="Ylab") # does not show 'ylab'
> >>
> >> You are right, it does *not* show 'ylab' but the user is warned.
> >>
> >>
> >> aa <- table(c(1, 1, 1, 2, 2, 3))
> >> dotchart(aa, ylab = "Ylab") # does show 'ylab'
> >> #Warning message:
> >> #In dotchart(aa, ylab = "Ylab") :
> >> #  'x' is neither a vector nor a matrix: using as.numeric(x)
> >>
> >>
> >> My code:
> >>
> >>
> >> (mar <- par("mar"))    # new R session
> >> #[1] 5.1 4.1 4.1 2.1   # the left margin is 4.1
> >>
> >> aa <- as.numeric(table(c(1, 1, 1, 2, 2, 3)))
> >>
> >> dotchart(aa, ylab = "Ylab") # It does show 'ylab'
> >> old.par <- par(mar = mar + c(0, 5, 0, 0))
> >> par("mar")
> >> #[1] 5.1 9.1 4.1 2.1
> >>
> >> dotchart(aa, ylab = "Ylab")  # The left margin is now 9.1, much bigger
> >>
> >> par(old.par)                 # It does change the left margin
> >> dotchart(aa, ylab = "Ylab")  #  but only when a new graph is plotted.
> >>
> >>
> >>
> >>> old.par <- par(mar=c(1, 10, 1, 1)) ; dotchart(aa, ylab="Ylab") ;
> >>> par(old.par) # does not change left margin
> >>>
> >>> Possible solution:
> >>>
> >>> I researched the problem and think that the dotchart() code will need
> >>> few corrections. If there is an interest, I can post it here; or you
> >>> can look at the code of shipunov::Dotchart1() function.
> >>>
> >>> 2) example(hist) includes two "wrong" and "extreme" examples which
> >>> slow down and even crash R on some systems; this make it unsuitable
> >>> for demonstration in the class and strikes beginners in R who just
> >>> want to understand how hist() works. Actually, I did it last week (I
> >>> was not aware of these examples), and in the class two computers hang,
> >>> and many others were extremely slow.
> >>>
> >>> The code:
> >>>
> >>> example(hist)
> >>>
> >>> Possible solution:
> >>>
> >>> If R maintainers will enclose parts of "hist" example in \dontrun{},
> >>> this will allow to see the code but in the same time will not strike
> >>> beginners in R who just
> >>> want to understand how hist() works. They will still be possible to
> >>> run with example(..., run.dontrun=TRUE).
> >>
> >> Agree, it's annoying. Sometimes there's a Warning section after the
> >> Details section. Maybe such a section could get users' attention to
> >> those examples? At least it wouldn't hurt...
> >>
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >>>
> >>> With best wishes,
> >>>
> >>> Alexey Shipunov
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From d@cty|orh|z@ @end|ng |rom gm@||@com  Mon Feb 17 06:37:07 2020
From: d@cty|orh|z@ @end|ng |rom gm@||@com (Alexey Shipunov)
Date: Mon, 17 Feb 2020 14:37:07 +0900
Subject: [R] Unintended behaviour (possibly bugs)
In-Reply-To: <CAD-ePxbR1iNBCBhghkEMr1yKohFz3aGwrN+8kQVZ02tWmPMySg@mail.gmail.com>
References: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
 <bd143039-d302-fee9-7350-ec01a61c17e1@sapo.pt>
 <CAD-ePxZ-MytqqfQUiEE9+4e_T8kyfj4kiYcRTj4GsYcupGLj8A@mail.gmail.com>
 <cd83233c-5794-d741-cf9d-32d4435cf590@sapo.pt>
 <CAD-ePxbR1iNBCBhghkEMr1yKohFz3aGwrN+8kQVZ02tWmPMySg@mail.gmail.com>
Message-ID: <CAD-ePxaVntX-OHGruwiis13MZNvaYsv1pNxjiuunfceJWRkx0A@mail.gmail.com>

P.S.

I like also to defend my initial approach. Many help files said that:

?pie: "Pie charts are a very bad way of displaying information. ... A
bar chart or dot chart is a preferable way of displaying this type of
data."

?barplot: "See Also: ... ?dotchart? ..."

?dotchart: "... Dot plots are a reasonable substitute for bar plots."

However, if you plot the simple table, then:

aa <- table(c(1, 1, 1, 2, 2, 3))
barplot(aa) # no problems
pie(aa) # no problems
plot(aa, type="h") # no problems
mosaicplot(aa) # no problems
dotchart(aa) # warning: inappropriate object

So R encourages users to use dot plots but repels them with a warning
(especially bad looking on macOS GUI where warnings are in red). I
think that Cleveland's plots should be promoted and therefore this
warning is harmful.

Of course, you can do something like

dotchart(sapply(aa, as.numeric)) # no warning

but I do not think that this complication is quite necessary.

Alexey


??, 17 ????. 2020 ?. ? 13:59, Alexey Shipunov <dactylorhiza at gmail.com>:

>
> My suggestion (shipunov::Dotchart1()) was:
>
> ===
>    yinch <- if (!is.null(ylab)) 0.4 else 0
>    # inserted!
>     if (!(is.null(labels) && is.null(glabels))) {
>         nmai <- par("mai")
>         nmai.2.new <- nmai[4L] + max(yinch + linch + goffset, ginch) +
> 0.1 # changed!
>         if (nmai.2.new > nmai[2L]) {
>     # changed!
>             nmai[2L] <- nmai.2.new
>     # changed!
>         }
>         par(mai = nmai)
>     }
> ===
>
> But I am not sure if this is the best way.
>
> Now, how to move to r-devel? I never did it before.
>
> Alexey
>
> ??, 17 ????. 2020 ?. ? 13:54, Rui Barradas <ruipbarradas at sapo.pt>:
> >
> > Hello,
> >
> > Yes, this is definitely a bug.
> > Even the matrix plot is puzzling, with a "1" as top row sort-of-label
> > but no grid line. I'm trying to follow the source code of dotchart but
> > am yet to understand exactly what it does to decide the margins settings.
> >
> >      if (!(is.null(labels) && is.null(glabels))) {
> >        nmai <- par("mai")
> >        nmai[2L] <- nmai[4L] + max(linch + goffset, ginch) +
> >          0.1
> >        par(mai = nmai)
> >      }
> >
> > This should be moved to r-devel?
> >
> > Rui Barradas
> >
> > ?s 03:33 de 17/02/20, Alexey Shipunov escreveu:
> > > John and Rui, thanks!
> > >
> > > However, if we use the proper object, the problem still persists:
> > >
> > > dotchart(c("3"=1, "2"=2, "1"=3), ylab="Ylab") # ylab is invisible
> > > dotchart(c("aa"=1, "b"=2, "cc"=3), ylab="Ylab") # ylab is partly visible (!!!)
> > > dotchart(c("aaa"=1, "bbb"=2, "ccc"=3), ylab="Ylab") # ylab is well visible
> > >
> > > If the object is matrix, ylab is visible:
> > >
> > > dotchart(matrix(1:3, dimnames=list(c("aa","bb","cc"), NULL)), ylab="Ylab")
> > >
> > > But the ?dotchart explicitly says that "x: either a vector or matrix
> > > of numeric values" and then "labels: a vector of labels for each
> > > point.  For vectors the default is to use ?names(x)? ...".
> > >
> > > So this is likely a bug. Do you agree?
> > >
> > > Alexey
> > >
> > > ??, 17 ????. 2020 ?. ? 01:55, Rui Barradas <ruipbarradas at sapo.pt>:
> > >>
> > >> Hello,
> > >>
> > >> I believe you are wrong, the error is not in dotchart, it's in your
> > >> code. You assume that to plot an object of class "table" is the same as
> > >> to plot an object of class "numeric".
> > >>
> > >> Inline.
> > >>
> > >> ?s 12:21 de 16/02/20, Alexey Shipunov escreveu:
> > >>> Dear list,
> > >>>
> > >>> I have been advised to share these with R-help instead of filling the
> > >>> bug report:
> > >>>
> > >>> 1) dotchart() does not allow to see the left axis title ('ylab') and
> > >>> cannot change the left margin (outer margin 2) of the plot
> > >>>
> > >>> The code:
> > >>>
> > >>> aa <- table(c(1, 1, 1, 2, 2, 3))
> > >>> dotchart(aa, ylab="Ylab") # does not show 'ylab'
> > >>
> > >> You are right, it does *not* show 'ylab' but the user is warned.
> > >>
> > >>
> > >> aa <- table(c(1, 1, 1, 2, 2, 3))
> > >> dotchart(aa, ylab = "Ylab") # does show 'ylab'
> > >> #Warning message:
> > >> #In dotchart(aa, ylab = "Ylab") :
> > >> #  'x' is neither a vector nor a matrix: using as.numeric(x)
> > >>
> > >>
> > >> My code:
> > >>
> > >>
> > >> (mar <- par("mar"))    # new R session
> > >> #[1] 5.1 4.1 4.1 2.1   # the left margin is 4.1
> > >>
> > >> aa <- as.numeric(table(c(1, 1, 1, 2, 2, 3)))
> > >>
> > >> dotchart(aa, ylab = "Ylab") # It does show 'ylab'
> > >> old.par <- par(mar = mar + c(0, 5, 0, 0))
> > >> par("mar")
> > >> #[1] 5.1 9.1 4.1 2.1
> > >>
> > >> dotchart(aa, ylab = "Ylab")  # The left margin is now 9.1, much bigger
> > >>
> > >> par(old.par)                 # It does change the left margin
> > >> dotchart(aa, ylab = "Ylab")  #  but only when a new graph is plotted.
> > >>
> > >>
> > >>
> > >>> old.par <- par(mar=c(1, 10, 1, 1)) ; dotchart(aa, ylab="Ylab") ;
> > >>> par(old.par) # does not change left margin
> > >>>
> > >>> Possible solution:
> > >>>
> > >>> I researched the problem and think that the dotchart() code will need
> > >>> few corrections. If there is an interest, I can post it here; or you
> > >>> can look at the code of shipunov::Dotchart1() function.
> > >>>
> > >>> 2) example(hist) includes two "wrong" and "extreme" examples which
> > >>> slow down and even crash R on some systems; this make it unsuitable
> > >>> for demonstration in the class and strikes beginners in R who just
> > >>> want to understand how hist() works. Actually, I did it last week (I
> > >>> was not aware of these examples), and in the class two computers hang,
> > >>> and many others were extremely slow.
> > >>>
> > >>> The code:
> > >>>
> > >>> example(hist)
> > >>>
> > >>> Possible solution:
> > >>>
> > >>> If R maintainers will enclose parts of "hist" example in \dontrun{},
> > >>> this will allow to see the code but in the same time will not strike
> > >>> beginners in R who just
> > >>> want to understand how hist() works. They will still be possible to
> > >>> run with example(..., run.dontrun=TRUE).
> > >>
> > >> Agree, it's annoying. Sometimes there's a Warning section after the
> > >> Details section. Maybe such a section could get users' attention to
> > >> those examples? At least it wouldn't hurt...
> > >>
> > >>
> > >> Hope this helps,
> > >>
> > >> Rui Barradas
> > >>
> > >>>
> > >>> With best wishes,
> > >>>
> > >>> Alexey Shipunov
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >>>
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Feb 17 07:45:13 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 16 Feb 2020 22:45:13 -0800
Subject: [R] Unintended behaviour (possibly bugs)
In-Reply-To: <CAD-ePxaVntX-OHGruwiis13MZNvaYsv1pNxjiuunfceJWRkx0A@mail.gmail.com>
References: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
 <bd143039-d302-fee9-7350-ec01a61c17e1@sapo.pt>
 <CAD-ePxZ-MytqqfQUiEE9+4e_T8kyfj4kiYcRTj4GsYcupGLj8A@mail.gmail.com>
 <cd83233c-5794-d741-cf9d-32d4435cf590@sapo.pt>
 <CAD-ePxbR1iNBCBhghkEMr1yKohFz3aGwrN+8kQVZ02tWmPMySg@mail.gmail.com>
 <CAD-ePxaVntX-OHGruwiis13MZNvaYsv1pNxjiuunfceJWRkx0A@mail.gmail.com>
Message-ID: <C13A3E4C-2645-4EB9-A6FB-A1920058D7DA@dcn.davis.ca.us>

Dotplot is for raw data. You are giving it summarized data. I don't think it is appropriate to expect dotplot to undo your summarization for you in order to plot it.

On February 16, 2020 9:37:07 PM PST, Alexey Shipunov <dactylorhiza at gmail.com> wrote:
>P.S.
>
>I like also to defend my initial approach. Many help files said that:
>
>?pie: "Pie charts are a very bad way of displaying information. ... A
>bar chart or dot chart is a preferable way of displaying this type of
>data."
>
>?barplot: "See Also: ... ?dotchart? ..."
>
>?dotchart: "... Dot plots are a reasonable substitute for bar plots."
>
>However, if you plot the simple table, then:
>
>aa <- table(c(1, 1, 1, 2, 2, 3))
>barplot(aa) # no problems
>pie(aa) # no problems
>plot(aa, type="h") # no problems
>mosaicplot(aa) # no problems
>dotchart(aa) # warning: inappropriate object
>
>So R encourages users to use dot plots but repels them with a warning
>(especially bad looking on macOS GUI where warnings are in red). I
>think that Cleveland's plots should be promoted and therefore this
>warning is harmful.
>
>Of course, you can do something like
>
>dotchart(sapply(aa, as.numeric)) # no warning
>
>but I do not think that this complication is quite necessary.
>
>Alexey
>
>
>??, 17 ????. 2020 ?. ? 13:59, Alexey Shipunov <dactylorhiza at gmail.com>:
>
>>
>> My suggestion (shipunov::Dotchart1()) was:
>>
>> ===
>>    yinch <- if (!is.null(ylab)) 0.4 else 0
>>    # inserted!
>>     if (!(is.null(labels) && is.null(glabels))) {
>>         nmai <- par("mai")
>>         nmai.2.new <- nmai[4L] + max(yinch + linch + goffset, ginch)
>+
>> 0.1 # changed!
>>         if (nmai.2.new > nmai[2L]) {
>>     # changed!
>>             nmai[2L] <- nmai.2.new
>>     # changed!
>>         }
>>         par(mai = nmai)
>>     }
>> ===
>>
>> But I am not sure if this is the best way.
>>
>> Now, how to move to r-devel? I never did it before.
>>
>> Alexey
>>
>> ??, 17 ????. 2020 ?. ? 13:54, Rui Barradas <ruipbarradas at sapo.pt>:
>> >
>> > Hello,
>> >
>> > Yes, this is definitely a bug.
>> > Even the matrix plot is puzzling, with a "1" as top row
>sort-of-label
>> > but no grid line. I'm trying to follow the source code of dotchart
>but
>> > am yet to understand exactly what it does to decide the margins
>settings.
>> >
>> >      if (!(is.null(labels) && is.null(glabels))) {
>> >        nmai <- par("mai")
>> >        nmai[2L] <- nmai[4L] + max(linch + goffset, ginch) +
>> >          0.1
>> >        par(mai = nmai)
>> >      }
>> >
>> > This should be moved to r-devel?
>> >
>> > Rui Barradas
>> >
>> > ?s 03:33 de 17/02/20, Alexey Shipunov escreveu:
>> > > John and Rui, thanks!
>> > >
>> > > However, if we use the proper object, the problem still persists:
>> > >
>> > > dotchart(c("3"=1, "2"=2, "1"=3), ylab="Ylab") # ylab is invisible
>> > > dotchart(c("aa"=1, "b"=2, "cc"=3), ylab="Ylab") # ylab is partly
>visible (!!!)
>> > > dotchart(c("aaa"=1, "bbb"=2, "ccc"=3), ylab="Ylab") # ylab is
>well visible
>> > >
>> > > If the object is matrix, ylab is visible:
>> > >
>> > > dotchart(matrix(1:3, dimnames=list(c("aa","bb","cc"), NULL)),
>ylab="Ylab")
>> > >
>> > > But the ?dotchart explicitly says that "x: either a vector or
>matrix
>> > > of numeric values" and then "labels: a vector of labels for each
>> > > point.  For vectors the default is to use ?names(x)? ...".
>> > >
>> > > So this is likely a bug. Do you agree?
>> > >
>> > > Alexey
>> > >
>> > > ??, 17 ????. 2020 ?. ? 01:55, Rui Barradas
><ruipbarradas at sapo.pt>:
>> > >>
>> > >> Hello,
>> > >>
>> > >> I believe you are wrong, the error is not in dotchart, it's in
>your
>> > >> code. You assume that to plot an object of class "table" is the
>same as
>> > >> to plot an object of class "numeric".
>> > >>
>> > >> Inline.
>> > >>
>> > >> ?s 12:21 de 16/02/20, Alexey Shipunov escreveu:
>> > >>> Dear list,
>> > >>>
>> > >>> I have been advised to share these with R-help instead of
>filling the
>> > >>> bug report:
>> > >>>
>> > >>> 1) dotchart() does not allow to see the left axis title
>('ylab') and
>> > >>> cannot change the left margin (outer margin 2) of the plot
>> > >>>
>> > >>> The code:
>> > >>>
>> > >>> aa <- table(c(1, 1, 1, 2, 2, 3))
>> > >>> dotchart(aa, ylab="Ylab") # does not show 'ylab'
>> > >>
>> > >> You are right, it does *not* show 'ylab' but the user is warned.
>> > >>
>> > >>
>> > >> aa <- table(c(1, 1, 1, 2, 2, 3))
>> > >> dotchart(aa, ylab = "Ylab") # does show 'ylab'
>> > >> #Warning message:
>> > >> #In dotchart(aa, ylab = "Ylab") :
>> > >> #  'x' is neither a vector nor a matrix: using as.numeric(x)
>> > >>
>> > >>
>> > >> My code:
>> > >>
>> > >>
>> > >> (mar <- par("mar"))    # new R session
>> > >> #[1] 5.1 4.1 4.1 2.1   # the left margin is 4.1
>> > >>
>> > >> aa <- as.numeric(table(c(1, 1, 1, 2, 2, 3)))
>> > >>
>> > >> dotchart(aa, ylab = "Ylab") # It does show 'ylab'
>> > >> old.par <- par(mar = mar + c(0, 5, 0, 0))
>> > >> par("mar")
>> > >> #[1] 5.1 9.1 4.1 2.1
>> > >>
>> > >> dotchart(aa, ylab = "Ylab")  # The left margin is now 9.1, much
>bigger
>> > >>
>> > >> par(old.par)                 # It does change the left margin
>> > >> dotchart(aa, ylab = "Ylab")  #  but only when a new graph is
>plotted.
>> > >>
>> > >>
>> > >>
>> > >>> old.par <- par(mar=c(1, 10, 1, 1)) ; dotchart(aa, ylab="Ylab")
>;
>> > >>> par(old.par) # does not change left margin
>> > >>>
>> > >>> Possible solution:
>> > >>>
>> > >>> I researched the problem and think that the dotchart() code
>will need
>> > >>> few corrections. If there is an interest, I can post it here;
>or you
>> > >>> can look at the code of shipunov::Dotchart1() function.
>> > >>>
>> > >>> 2) example(hist) includes two "wrong" and "extreme" examples
>which
>> > >>> slow down and even crash R on some systems; this make it
>unsuitable
>> > >>> for demonstration in the class and strikes beginners in R who
>just
>> > >>> want to understand how hist() works. Actually, I did it last
>week (I
>> > >>> was not aware of these examples), and in the class two
>computers hang,
>> > >>> and many others were extremely slow.
>> > >>>
>> > >>> The code:
>> > >>>
>> > >>> example(hist)
>> > >>>
>> > >>> Possible solution:
>> > >>>
>> > >>> If R maintainers will enclose parts of "hist" example in
>\dontrun{},
>> > >>> this will allow to see the code but in the same time will not
>strike
>> > >>> beginners in R who just
>> > >>> want to understand how hist() works. They will still be
>possible to
>> > >>> run with example(..., run.dontrun=TRUE).
>> > >>
>> > >> Agree, it's annoying. Sometimes there's a Warning section after
>the
>> > >> Details section. Maybe such a section could get users' attention
>to
>> > >> those examples? At least it wouldn't hurt...
>> > >>
>> > >>
>> > >> Hope this helps,
>> > >>
>> > >> Rui Barradas
>> > >>
>> > >>>
>> > >>> With best wishes,
>> > >>>
>> > >>> Alexey Shipunov
>> > >>>
>> > >>> ______________________________________________
>> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> > >>> and provide commented, minimal, self-contained, reproducible
>code.
>> > >>>
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible
>code.
>> > >
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Feb 17 09:00:02 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 17 Feb 2020 08:00:02 +0000
Subject: [R] Unintended behaviour (possibly bugs)
In-Reply-To: <CAD-ePxbR1iNBCBhghkEMr1yKohFz3aGwrN+8kQVZ02tWmPMySg@mail.gmail.com>
References: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
 <bd143039-d302-fee9-7350-ec01a61c17e1@sapo.pt>
 <CAD-ePxZ-MytqqfQUiEE9+4e_T8kyfj4kiYcRTj4GsYcupGLj8A@mail.gmail.com>
 <cd83233c-5794-d741-cf9d-32d4435cf590@sapo.pt>
 <CAD-ePxbR1iNBCBhghkEMr1yKohFz3aGwrN+8kQVZ02tWmPMySg@mail.gmail.com>
Message-ID: <ffa0248f-4ca9-a2c2-cc3e-cd6ac692dac2@sapo.pt>

Hello,

To move to r-devel just send email to r-devel at r-project.org.
See

https://stat.ethz.ch/mailman/listinfo/r-devel

Rui Barradas

?s 04:59 de 17/02/20, Alexey Shipunov escreveu:
> My suggestion (shipunov::Dotchart1()) was:
> 
> ===
>     yinch <- if (!is.null(ylab)) 0.4 else 0
>     # inserted!
>      if (!(is.null(labels) && is.null(glabels))) {
>          nmai <- par("mai")
>          nmai.2.new <- nmai[4L] + max(yinch + linch + goffset, ginch) +
> 0.1 # changed!
>          if (nmai.2.new > nmai[2L]) {
>      # changed!
>              nmai[2L] <- nmai.2.new
>      # changed!
>          }
>          par(mai = nmai)
>      }
> ===
> 
> But I am not sure if this is the best way.
> 
> Now, how to move to r-devel? I never did it before.
> 
> Alexey
> 
> ??, 17 ????. 2020 ?. ? 13:54, Rui Barradas <ruipbarradas at sapo.pt>:
>>
>> Hello,
>>
>> Yes, this is definitely a bug.
>> Even the matrix plot is puzzling, with a "1" as top row sort-of-label
>> but no grid line. I'm trying to follow the source code of dotchart but
>> am yet to understand exactly what it does to decide the margins settings.
>>
>>       if (!(is.null(labels) && is.null(glabels))) {
>>         nmai <- par("mai")
>>         nmai[2L] <- nmai[4L] + max(linch + goffset, ginch) +
>>           0.1
>>         par(mai = nmai)
>>       }
>>
>> This should be moved to r-devel?
>>
>> Rui Barradas
>>
>> ?s 03:33 de 17/02/20, Alexey Shipunov escreveu:
>>> John and Rui, thanks!
>>>
>>> However, if we use the proper object, the problem still persists:
>>>
>>> dotchart(c("3"=1, "2"=2, "1"=3), ylab="Ylab") # ylab is invisible
>>> dotchart(c("aa"=1, "b"=2, "cc"=3), ylab="Ylab") # ylab is partly visible (!!!)
>>> dotchart(c("aaa"=1, "bbb"=2, "ccc"=3), ylab="Ylab") # ylab is well visible
>>>
>>> If the object is matrix, ylab is visible:
>>>
>>> dotchart(matrix(1:3, dimnames=list(c("aa","bb","cc"), NULL)), ylab="Ylab")
>>>
>>> But the ?dotchart explicitly says that "x: either a vector or matrix
>>> of numeric values" and then "labels: a vector of labels for each
>>> point.  For vectors the default is to use ?names(x)? ...".
>>>
>>> So this is likely a bug. Do you agree?
>>>
>>> Alexey
>>>
>>> ??, 17 ????. 2020 ?. ? 01:55, Rui Barradas <ruipbarradas at sapo.pt>:
>>>>
>>>> Hello,
>>>>
>>>> I believe you are wrong, the error is not in dotchart, it's in your
>>>> code. You assume that to plot an object of class "table" is the same as
>>>> to plot an object of class "numeric".
>>>>
>>>> Inline.
>>>>
>>>> ?s 12:21 de 16/02/20, Alexey Shipunov escreveu:
>>>>> Dear list,
>>>>>
>>>>> I have been advised to share these with R-help instead of filling the
>>>>> bug report:
>>>>>
>>>>> 1) dotchart() does not allow to see the left axis title ('ylab') and
>>>>> cannot change the left margin (outer margin 2) of the plot
>>>>>
>>>>> The code:
>>>>>
>>>>> aa <- table(c(1, 1, 1, 2, 2, 3))
>>>>> dotchart(aa, ylab="Ylab") # does not show 'ylab'
>>>>
>>>> You are right, it does *not* show 'ylab' but the user is warned.
>>>>
>>>>
>>>> aa <- table(c(1, 1, 1, 2, 2, 3))
>>>> dotchart(aa, ylab = "Ylab") # does show 'ylab'
>>>> #Warning message:
>>>> #In dotchart(aa, ylab = "Ylab") :
>>>> #  'x' is neither a vector nor a matrix: using as.numeric(x)
>>>>
>>>>
>>>> My code:
>>>>
>>>>
>>>> (mar <- par("mar"))    # new R session
>>>> #[1] 5.1 4.1 4.1 2.1   # the left margin is 4.1
>>>>
>>>> aa <- as.numeric(table(c(1, 1, 1, 2, 2, 3)))
>>>>
>>>> dotchart(aa, ylab = "Ylab") # It does show 'ylab'
>>>> old.par <- par(mar = mar + c(0, 5, 0, 0))
>>>> par("mar")
>>>> #[1] 5.1 9.1 4.1 2.1
>>>>
>>>> dotchart(aa, ylab = "Ylab")  # The left margin is now 9.1, much bigger
>>>>
>>>> par(old.par)                 # It does change the left margin
>>>> dotchart(aa, ylab = "Ylab")  #  but only when a new graph is plotted.
>>>>
>>>>
>>>>
>>>>> old.par <- par(mar=c(1, 10, 1, 1)) ; dotchart(aa, ylab="Ylab") ;
>>>>> par(old.par) # does not change left margin
>>>>>
>>>>> Possible solution:
>>>>>
>>>>> I researched the problem and think that the dotchart() code will need
>>>>> few corrections. If there is an interest, I can post it here; or you
>>>>> can look at the code of shipunov::Dotchart1() function.
>>>>>
>>>>> 2) example(hist) includes two "wrong" and "extreme" examples which
>>>>> slow down and even crash R on some systems; this make it unsuitable
>>>>> for demonstration in the class and strikes beginners in R who just
>>>>> want to understand how hist() works. Actually, I did it last week (I
>>>>> was not aware of these examples), and in the class two computers hang,
>>>>> and many others were extremely slow.
>>>>>
>>>>> The code:
>>>>>
>>>>> example(hist)
>>>>>
>>>>> Possible solution:
>>>>>
>>>>> If R maintainers will enclose parts of "hist" example in \dontrun{},
>>>>> this will allow to see the code but in the same time will not strike
>>>>> beginners in R who just
>>>>> want to understand how hist() works. They will still be possible to
>>>>> run with example(..., run.dontrun=TRUE).
>>>>
>>>> Agree, it's annoying. Sometimes there's a Warning section after the
>>>> Details section. Maybe such a section could get users' attention to
>>>> those examples? At least it wouldn't hurt...
>>>>
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>>>
>>>>> With best wishes,
>>>>>
>>>>> Alexey Shipunov
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Mon Feb 17 09:37:32 2020
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Mon, 17 Feb 2020 14:07:32 +0530
Subject: [R] Unintended behaviour (possibly bugs)
In-Reply-To: <cd83233c-5794-d741-cf9d-32d4435cf590@sapo.pt>
References: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
 <bd143039-d302-fee9-7350-ec01a61c17e1@sapo.pt>
 <CAD-ePxZ-MytqqfQUiEE9+4e_T8kyfj4kiYcRTj4GsYcupGLj8A@mail.gmail.com>
 <cd83233c-5794-d741-cf9d-32d4435cf590@sapo.pt>
Message-ID: <CADfFDC6HGT0X0d5xnrCfRKybp9SRehU10c3C5hGAm0USNtndWQ@mail.gmail.com>

On Mon, Feb 17, 2020 at 10:24 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Yes, this is definitely a bug.

I would argue that the only bug here is that the documentation doesn't
say that 'ylab' may not behave as expected.

dotchart() is mainly designed for 2-way tables (see the VADeaths
example), but it's implementation is really pretty hackish because it
has to work within the limited traditional graphics framework. The
main problem is that dot plots want to put horizontal y-axis labels
(usually derived from factor levels), which are often longer than the
default margins, so the margins are modified. Unfortunately they are
only re-set on exit, and so the ylab that is plotted inside dotchart()
may be clipped. Traditionally, Cleveland dot plots don't have a y-axis
label; it's assumed that the factor levels are sufficient (and for
2-way tables, there would be two variables, so there is no sensible
default).

I doubt that dotchart() is worth fixing (except to maybe disallow
ylab). If you want flexibility, use modern grid-based alternatives
such as lattice::dotplot() or ggplot2.

-Deepayan

> Even the matrix plot is puzzling, with a "1" as top row sort-of-label
> but no grid line. I'm trying to follow the source code of dotchart but
> am yet to understand exactly what it does to decide the margins settings.
>
>      if (!(is.null(labels) && is.null(glabels))) {
>        nmai <- par("mai")
>        nmai[2L] <- nmai[4L] + max(linch + goffset, ginch) +
>          0.1
>        par(mai = nmai)
>      }
>
> This should be moved to r-devel?
>
> Rui Barradas
>
> ?s 03:33 de 17/02/20, Alexey Shipunov escreveu:
> > John and Rui, thanks!
> >
> > However, if we use the proper object, the problem still persists:
> >
> > dotchart(c("3"=1, "2"=2, "1"=3), ylab="Ylab") # ylab is invisible
> > dotchart(c("aa"=1, "b"=2, "cc"=3), ylab="Ylab") # ylab is partly visible (!!!)
> > dotchart(c("aaa"=1, "bbb"=2, "ccc"=3), ylab="Ylab") # ylab is well visible
> >
> > If the object is matrix, ylab is visible:
> >
> > dotchart(matrix(1:3, dimnames=list(c("aa","bb","cc"), NULL)), ylab="Ylab")
> >
> > But the ?dotchart explicitly says that "x: either a vector or matrix
> > of numeric values" and then "labels: a vector of labels for each
> > point.  For vectors the default is to use ?names(x)? ...".
> >
> > So this is likely a bug. Do you agree?
> >
> > Alexey
> >
> > ??, 17 ????. 2020 ?. ? 01:55, Rui Barradas <ruipbarradas at sapo.pt>:
> >>
> >> Hello,
> >>
> >> I believe you are wrong, the error is not in dotchart, it's in your
> >> code. You assume that to plot an object of class "table" is the same as
> >> to plot an object of class "numeric".
> >>
> >> Inline.
> >>
> >> ?s 12:21 de 16/02/20, Alexey Shipunov escreveu:
> >>> Dear list,
> >>>
> >>> I have been advised to share these with R-help instead of filling the
> >>> bug report:
> >>>
> >>> 1) dotchart() does not allow to see the left axis title ('ylab') and
> >>> cannot change the left margin (outer margin 2) of the plot
> >>>
> >>> The code:
> >>>
> >>> aa <- table(c(1, 1, 1, 2, 2, 3))
> >>> dotchart(aa, ylab="Ylab") # does not show 'ylab'
> >>
> >> You are right, it does *not* show 'ylab' but the user is warned.
> >>
> >>
> >> aa <- table(c(1, 1, 1, 2, 2, 3))
> >> dotchart(aa, ylab = "Ylab") # does show 'ylab'
> >> #Warning message:
> >> #In dotchart(aa, ylab = "Ylab") :
> >> #  'x' is neither a vector nor a matrix: using as.numeric(x)
> >>
> >>
> >> My code:
> >>
> >>
> >> (mar <- par("mar"))    # new R session
> >> #[1] 5.1 4.1 4.1 2.1   # the left margin is 4.1
> >>
> >> aa <- as.numeric(table(c(1, 1, 1, 2, 2, 3)))
> >>
> >> dotchart(aa, ylab = "Ylab") # It does show 'ylab'
> >> old.par <- par(mar = mar + c(0, 5, 0, 0))
> >> par("mar")
> >> #[1] 5.1 9.1 4.1 2.1
> >>
> >> dotchart(aa, ylab = "Ylab")  # The left margin is now 9.1, much bigger
> >>
> >> par(old.par)                 # It does change the left margin
> >> dotchart(aa, ylab = "Ylab")  #  but only when a new graph is plotted.
> >>
> >>
> >>
> >>> old.par <- par(mar=c(1, 10, 1, 1)) ; dotchart(aa, ylab="Ylab") ;
> >>> par(old.par) # does not change left margin
> >>>
> >>> Possible solution:
> >>>
> >>> I researched the problem and think that the dotchart() code will need
> >>> few corrections. If there is an interest, I can post it here; or you
> >>> can look at the code of shipunov::Dotchart1() function.
> >>>
> >>> 2) example(hist) includes two "wrong" and "extreme" examples which
> >>> slow down and even crash R on some systems; this make it unsuitable
> >>> for demonstration in the class and strikes beginners in R who just
> >>> want to understand how hist() works. Actually, I did it last week (I
> >>> was not aware of these examples), and in the class two computers hang,
> >>> and many others were extremely slow.
> >>>
> >>> The code:
> >>>
> >>> example(hist)
> >>>
> >>> Possible solution:
> >>>
> >>> If R maintainers will enclose parts of "hist" example in \dontrun{},
> >>> this will allow to see the code but in the same time will not strike
> >>> beginners in R who just
> >>> want to understand how hist() works. They will still be possible to
> >>> run with example(..., run.dontrun=TRUE).
> >>
> >> Agree, it's annoying. Sometimes there's a Warning section after the
> >> Details section. Maybe such a section could get users' attention to
> >> those examples? At least it wouldn't hurt...
> >>
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >>>
> >>> With best wishes,
> >>>
> >>> Alexey Shipunov
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Servet@Ahmet@C|zme|| @end|ng |rom USherbrooke@c@  Mon Feb 17 00:02:27 2020
From: Servet@Ahmet@C|zme|| @end|ng |rom USherbrooke@c@ (=?utf-8?B?U2VydmV0IEFobWV0IMOHaXptZWxp?=)
Date: Sun, 16 Feb 2020 23:02:27 +0000
Subject: [R] testing my package : unstated dependency to self in package
 tests
In-Reply-To: <161c90d7-be6c-493c-400e-fc4b2bc7fb0b@dewey.myzen.co.uk>
References: <QB1PR01MB3234EC8D15A32C8968F7F452BA170@QB1PR01MB3234.CANPRD01.PROD.OUTLOOK.COM>,
 <161c90d7-be6c-493c-400e-fc4b2bc7fb0b@dewey.myzen.co.uk>
Message-ID: <QB1PR01MB3234083F6EBF30F5CCFF01C1BA170@QB1PR01MB3234.CANPRD01.PROD.OUTLOOK.COM>

That worked. Thanks.

________________________________
From: Michael Dewey <lists at dewey.myzen.co.uk>
Sent: Sunday, February 16, 2020 5:54 PM
To: Servet Ahmet ?izmeli <Servet.Ahmet.Cizmeli at USherbrooke.ca>; r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] testing my package : unstated dependency to self in package tests

When something similar happened to me I found it went away when I added
Suggests: <packagename>
to the DESCRIPTION file. Whether this will work for you I have no idea.

Michael

On 16/02/2020 11:03, Servet Ahmet ?izmeli wrote:
> I am updating my CRAN package geoSpectral. I get the following Warning during R CMD check :
>
> ...
> * checking for unstated dependencies in ?tests? ... WARNING
> 'library' or 'require' call not declared from: ?geoSpectral?
> ....
>
>
> All the .R files I have under the testhat directory begin by :
> library(geoSpectral)
> library(testthat)
>
> and there I call package functions directly (without the prefix  geoSpectal::  )
> See https://github.com/cran/geoSpectral/blob/master/tests/testthat/Spectra_tests.R
>
> Searching the web, I found examples where the same Warning has been issued for some other packages. But in my case the package in question is my own package I am testing....
>
> Confused and at loss.  Anyone with ideas?
> regards
> Servet
>
>        [[alternative HTML version deleted]]
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

--
Michael
http://www.dewey.myzen.co.uk/home.html

	[[alternative HTML version deleted]]


From pj@|nh@07 @end|ng |rom gm@||@com  Mon Feb 17 15:58:07 2020
From: pj@|nh@07 @end|ng |rom gm@||@com (pooja sinha)
Date: Mon, 17 Feb 2020 09:58:07 -0500
Subject: [R] Problems in writing code for circos plot
In-Reply-To: <CA+8X3fXxwuOQ49eZLfRuyFi2JuuvT=EuTFr7fUPG7M=nYRrnwg@mail.gmail.com>
References: <CAGjf1cO9kRpLfqOPRXjO0cMrnhkbC7nd7rPAdaYYapQLG4kVyQ@mail.gmail.com>
 <CA+8X3fXxwuOQ49eZLfRuyFi2JuuvT=EuTFr7fUPG7M=nYRrnwg@mail.gmail.com>
Message-ID: <CAGjf1cNmq-xBssKws29_HqD01MQv-RRk-pFh_v+VQHeqrUU0bQ@mail.gmail.com>

 Hi All,


I had previously mentioned that I have large data set with methylation
values ranging from 0-1. The data contains around 3 million rows of values
corresponding to the chromosomal locations. I want to split/sort my data
for plot using circos plot. I thought of doing like sorting the value range
0.2-0.4 as hypomethylation category and range 0.7-1.0 as hypermethylation
category. However, with this approach the plot again looks cluttered.
Another way is that I can split the data into two parts, one part with
values lower than median, and another part with values larger than median.

Can anyone suggest me which approach is better or if there are other
approaches I can use in my datasets for circos plot using circlize package.


Thanks,

Puja

On Sun, Jan 26, 2020 at 5:06 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Puja,
> Three things:
> 1) Your data files are very large. If you do manage to get circular
> plots out of them with the circlize library they will probably be very
> dense.
> 2) The structure of your data includes too many levels in "Chrom" to
> get the circlize functions to work. I had to pare them back to the
> non-random levels.
> 3) You should probably change the subject line of your message to
> "Would anyone care to do my work for me?"
>
> Jim
>
> On Mon, Jan 27, 2020 at 6:47 AM pooja sinha <pjsinha07 at gmail.com> wrote:
> >
> > Hi All,
> >
> > I have attached the three different datasets for Rn6 genome (rat) and I
> > needed to use circos plot by *circlize package in R*. Please anyone help
> me
> > in writing the code and making the plot. Any help will be highly
> > appreciated.
> > The three file links are below:
> >
> > File 1: YOUNGCONTROL.csv (
> > https://drive.google.com/open?id=1arQqlzkRJybclikAByB9w9TCnvmD_Y46 )
> > File 2:  YOUNGTREATED.csv (
> > https://drive.google.com/open?id=1vMidiGmoK4zsYjvf2sT9RbjwF72W0IhO )
> > File 3:  YOUNGTREATED.vs.YOUNGCONTROL.sig.csv (
> >
> https://drive.google.com/open?id=0B33BGsdd5x_dOGF0X3BuaWRoMmdSYklOZnJoX09uaWdnNEdN
> >  )
> >
> > The circos plot having the outermost ring contain Rn6 ideogram followed
> by
> > YOUNGCONTROL, YOUNGTREATED & last innermost circle will be of
> > YOUNGTREATED.vs.YOUNGCONTROL.sig
> >
> > Thanks,
> > Puja
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Feb 17 16:06:53 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 17 Feb 2020 07:06:53 -0800
Subject: [R] Problems in writing code for circos plot
In-Reply-To: <CAGjf1cNmq-xBssKws29_HqD01MQv-RRk-pFh_v+VQHeqrUU0bQ@mail.gmail.com>
References: <CAGjf1cO9kRpLfqOPRXjO0cMrnhkbC7nd7rPAdaYYapQLG4kVyQ@mail.gmail.com>
 <CA+8X3fXxwuOQ49eZLfRuyFi2JuuvT=EuTFr7fUPG7M=nYRrnwg@mail.gmail.com>
 <CAGjf1cNmq-xBssKws29_HqD01MQv-RRk-pFh_v+VQHeqrUU0bQ@mail.gmail.com>
Message-ID: <CAGxFJbRpJ=2=WfgMbv0ZO=1bioshR8sRbmqwQ+P+UL57H0ShJQ@mail.gmail.com>

Wrong list -- (for which statistical methods question are generally
offtopic anyway).

Post here instead:
https://www.bioconductor.org/help/

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 17, 2020 at 6:58 AM pooja sinha <pjsinha07 at gmail.com> wrote:

>  Hi All,
>
>
> I had previously mentioned that I have large data set with methylation
> values ranging from 0-1. The data contains around 3 million rows of values
> corresponding to the chromosomal locations. I want to split/sort my data
> for plot using circos plot. I thought of doing like sorting the value range
> 0.2-0.4 as hypomethylation category and range 0.7-1.0 as hypermethylation
> category. However, with this approach the plot again looks cluttered.
> Another way is that I can split the data into two parts, one part with
> values lower than median, and another part with values larger than median.
>
> Can anyone suggest me which approach is better or if there are other
> approaches I can use in my datasets for circos plot using circlize package.
>
>
> Thanks,
>
> Puja
>
> On Sun, Jan 26, 2020 at 5:06 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> > Hi Puja,
> > Three things:
> > 1) Your data files are very large. If you do manage to get circular
> > plots out of them with the circlize library they will probably be very
> > dense.
> > 2) The structure of your data includes too many levels in "Chrom" to
> > get the circlize functions to work. I had to pare them back to the
> > non-random levels.
> > 3) You should probably change the subject line of your message to
> > "Would anyone care to do my work for me?"
> >
> > Jim
> >
> > On Mon, Jan 27, 2020 at 6:47 AM pooja sinha <pjsinha07 at gmail.com> wrote:
> > >
> > > Hi All,
> > >
> > > I have attached the three different datasets for Rn6 genome (rat) and I
> > > needed to use circos plot by *circlize package in R*. Please anyone
> help
> > me
> > > in writing the code and making the plot. Any help will be highly
> > > appreciated.
> > > The three file links are below:
> > >
> > > File 1: YOUNGCONTROL.csv (
> > > https://drive.google.com/open?id=1arQqlzkRJybclikAByB9w9TCnvmD_Y46 )
> > > File 2:  YOUNGTREATED.csv (
> > > https://drive.google.com/open?id=1vMidiGmoK4zsYjvf2sT9RbjwF72W0IhO )
> > > File 3:  YOUNGTREATED.vs.YOUNGCONTROL.sig.csv (
> > >
> >
> https://drive.google.com/open?id=0B33BGsdd5x_dOGF0X3BuaWRoMmdSYklOZnJoX09uaWdnNEdN
> > >  )
> > >
> > > The circos plot having the outermost ring contain Rn6 ideogram followed
> > by
> > > YOUNGCONTROL, YOUNGTREATED & last innermost circle will be of
> > > YOUNGTREATED.vs.YOUNGCONTROL.sig
> > >
> > > Thanks,
> > > Puja
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@chre|b @end|ng |rom u@|bert@@c@  Mon Feb 17 16:26:27 2020
From: @@chre|b @end|ng |rom u@|bert@@c@ (Stefan Schreiber)
Date: Mon, 17 Feb 2020 08:26:27 -0700
Subject: [R] object.size vs lobstr::obj_size
Message-ID: <CAPK=JivHhe9R47RrAGsMuecpfxeUoYEuLKVK1NEqedTU=konvg@mail.gmail.com>

I am currently working through Advanced R by H. Wickham and came
across the `lobstr::obj_size` function which appears to calculate the
size of an object by taking into account whether the same object has
been referenced multiple times, e.g.

x <- runif(1e6)
y <- list(x, x, x)
lobstr::obj_size(y)
# 8,000,128 B

# versus:
object.size(y)
# 24000224 bytes

Reading through `?object.size` in the "Details" it reads: [...] but
does not detect if elements of a list are shared [...].

My questions are:

(1) is the result of `obj_size()` the "correct" one when it comes to
actual size used in memory?

(2) And if yes, why wouldn't `object.size()` be updated to reflect the
more precise calculation of an object in question similar to
`obj_size()`?

There are probably valid reasons for this and any insight would be
greatly appreciated.


From d@cty|orh|z@ @end|ng |rom gm@||@com  Tue Feb 18 06:34:48 2020
From: d@cty|orh|z@ @end|ng |rom gm@||@com (Alexey Shipunov)
Date: Tue, 18 Feb 2020 14:34:48 +0900
Subject: [R] Unintended behaviour (possibly bugs)
In-Reply-To: <CADfFDC6HGT0X0d5xnrCfRKybp9SRehU10c3C5hGAm0USNtndWQ@mail.gmail.com>
References: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
 <bd143039-d302-fee9-7350-ec01a61c17e1@sapo.pt>
 <CAD-ePxZ-MytqqfQUiEE9+4e_T8kyfj4kiYcRTj4GsYcupGLj8A@mail.gmail.com>
 <cd83233c-5794-d741-cf9d-32d4435cf590@sapo.pt>
 <CADfFDC6HGT0X0d5xnrCfRKybp9SRehU10c3C5hGAm0USNtndWQ@mail.gmail.com>
Message-ID: <CAD-ePxZELLi+zvkT8AmF6R9vffB+_K3vi6PMLONi2RViuSBFng@mail.gmail.com>

Thank you for the detailed explanation. I tend to agree. However, this
behavior is relatively easy to remediate:

This is the piece of the current code:

===
   if (!(is.null(labels) && is.null(glabels))) {
        nmai <- par("mai")
        nmai[2L] <- nmai[4L] + max(linch + goffset, ginch) + 0.1
        par(mai = nmai)
    }
===

This is my proposal:

===
    yinch <- if (!is.null(ylab)) 0.4 else 0
    if (!(is.null(labels) && is.null(glabels))) {
        nmai <- par("mai")
        nmai.2.new <- nmai[4L] + max(yinch + linch + goffset,
            ginch) + 0.1
        if (nmai.2.new > nmai[2L]) {
            nmai[2L] <- nmai.2.new
        }
        par(mai = nmai)
    }
===

Then margins and y-axis labels start to work normally. I wonder if
this (or similar) is possible to introduce into the code?

Alexey

??, 17 ????. 2020 ?. ? 17:37, Deepayan Sarkar <deepayan.sarkar at gmail.com>:
>
> On Mon, Feb 17, 2020 at 10:24 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > Yes, this is definitely a bug.
>
> I would argue that the only bug here is that the documentation doesn't
> say that 'ylab' may not behave as expected.
>
> dotchart() is mainly designed for 2-way tables (see the VADeaths
> example), but it's implementation is really pretty hackish because it
> has to work within the limited traditional graphics framework. The
> main problem is that dot plots want to put horizontal y-axis labels
> (usually derived from factor levels), which are often longer than the
> default margins, so the margins are modified. Unfortunately they are
> only re-set on exit, and so the ylab that is plotted inside dotchart()
> may be clipped. Traditionally, Cleveland dot plots don't have a y-axis
> label; it's assumed that the factor levels are sufficient (and for
> 2-way tables, there would be two variables, so there is no sensible
> default).
>
> I doubt that dotchart() is worth fixing (except to maybe disallow
> ylab). If you want flexibility, use modern grid-based alternatives
> such as lattice::dotplot() or ggplot2.
>
> -Deepayan
>
> > Even the matrix plot is puzzling, with a "1" as top row sort-of-label
> > but no grid line. I'm trying to follow the source code of dotchart but
> > am yet to understand exactly what it does to decide the margins settings.
> >
> >      if (!(is.null(labels) && is.null(glabels))) {
> >        nmai <- par("mai")
> >        nmai[2L] <- nmai[4L] + max(linch + goffset, ginch) +
> >          0.1
> >        par(mai = nmai)
> >      }
> >
> > This should be moved to r-devel?
> >
> > Rui Barradas
> >
> > ?s 03:33 de 17/02/20, Alexey Shipunov escreveu:
> > > John and Rui, thanks!
> > >
> > > However, if we use the proper object, the problem still persists:
> > >
> > > dotchart(c("3"=1, "2"=2, "1"=3), ylab="Ylab") # ylab is invisible
> > > dotchart(c("aa"=1, "b"=2, "cc"=3), ylab="Ylab") # ylab is partly visible (!!!)
> > > dotchart(c("aaa"=1, "bbb"=2, "ccc"=3), ylab="Ylab") # ylab is well visible
> > >
> > > If the object is matrix, ylab is visible:
> > >
> > > dotchart(matrix(1:3, dimnames=list(c("aa","bb","cc"), NULL)), ylab="Ylab")
> > >
> > > But the ?dotchart explicitly says that "x: either a vector or matrix
> > > of numeric values" and then "labels: a vector of labels for each
> > > point.  For vectors the default is to use ?names(x)? ...".
> > >
> > > So this is likely a bug. Do you agree?
> > >
> > > Alexey
> > >
> > > ??, 17 ????. 2020 ?. ? 01:55, Rui Barradas <ruipbarradas at sapo.pt>:
> > >>
> > >> Hello,
> > >>
> > >> I believe you are wrong, the error is not in dotchart, it's in your
> > >> code. You assume that to plot an object of class "table" is the same as
> > >> to plot an object of class "numeric".
> > >>
> > >> Inline.
> > >>
> > >> ?s 12:21 de 16/02/20, Alexey Shipunov escreveu:
> > >>> Dear list,
> > >>>
> > >>> I have been advised to share these with R-help instead of filling the
> > >>> bug report:
> > >>>
> > >>> 1) dotchart() does not allow to see the left axis title ('ylab') and
> > >>> cannot change the left margin (outer margin 2) of the plot
> > >>>
> > >>> The code:
> > >>>
> > >>> aa <- table(c(1, 1, 1, 2, 2, 3))
> > >>> dotchart(aa, ylab="Ylab") # does not show 'ylab'
> > >>
> > >> You are right, it does *not* show 'ylab' but the user is warned.
> > >>
> > >>
> > >> aa <- table(c(1, 1, 1, 2, 2, 3))
> > >> dotchart(aa, ylab = "Ylab") # does show 'ylab'
> > >> #Warning message:
> > >> #In dotchart(aa, ylab = "Ylab") :
> > >> #  'x' is neither a vector nor a matrix: using as.numeric(x)
> > >>
> > >>
> > >> My code:
> > >>
> > >>
> > >> (mar <- par("mar"))    # new R session
> > >> #[1] 5.1 4.1 4.1 2.1   # the left margin is 4.1
> > >>
> > >> aa <- as.numeric(table(c(1, 1, 1, 2, 2, 3)))
> > >>
> > >> dotchart(aa, ylab = "Ylab") # It does show 'ylab'
> > >> old.par <- par(mar = mar + c(0, 5, 0, 0))
> > >> par("mar")
> > >> #[1] 5.1 9.1 4.1 2.1
> > >>
> > >> dotchart(aa, ylab = "Ylab")  # The left margin is now 9.1, much bigger
> > >>
> > >> par(old.par)                 # It does change the left margin
> > >> dotchart(aa, ylab = "Ylab")  #  but only when a new graph is plotted.
> > >>
> > >>
> > >>
> > >>> old.par <- par(mar=c(1, 10, 1, 1)) ; dotchart(aa, ylab="Ylab") ;
> > >>> par(old.par) # does not change left margin
> > >>>
> > >>> Possible solution:
> > >>>
> > >>> I researched the problem and think that the dotchart() code will need
> > >>> few corrections. If there is an interest, I can post it here; or you
> > >>> can look at the code of shipunov::Dotchart1() function.
> > >>>
> > >>> 2) example(hist) includes two "wrong" and "extreme" examples which
> > >>> slow down and even crash R on some systems; this make it unsuitable
> > >>> for demonstration in the class and strikes beginners in R who just
> > >>> want to understand how hist() works. Actually, I did it last week (I
> > >>> was not aware of these examples), and in the class two computers hang,
> > >>> and many others were extremely slow.
> > >>>
> > >>> The code:
> > >>>
> > >>> example(hist)
> > >>>
> > >>> Possible solution:
> > >>>
> > >>> If R maintainers will enclose parts of "hist" example in \dontrun{},
> > >>> this will allow to see the code but in the same time will not strike
> > >>> beginners in R who just
> > >>> want to understand how hist() works. They will still be possible to
> > >>> run with example(..., run.dontrun=TRUE).
> > >>
> > >> Agree, it's annoying. Sometimes there's a Warning section after the
> > >> Details section. Maybe such a section could get users' attention to
> > >> those examples? At least it wouldn't hurt...
> > >>
> > >>
> > >> Hope this helps,
> > >>
> > >> Rui Barradas
> > >>
> > >>>
> > >>> With best wishes,
> > >>>
> > >>> Alexey Shipunov
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >>>
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From roy@mende|@@ohn @end|ng |rom no@@@gov  Tue Feb 18 19:29:00 2020
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 18 Feb 2020 10:29:00 -0800
Subject: [R] Package httr::GET() question
Message-ID: <EFC2C1C8-5B1C-4543-96DE-6E61CBF7F304@noaa.gov>

Hi All:

 I hav been trying to go through the code for httr::GET() but it is somewhat beyond what I know.  What I am trying to find out is if all urls are automatically percent encoded,  or whether the user needs to do that.

Thanks,

-Roy

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Feb 19 02:59:48 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 18 Feb 2020 17:59:48 -0800
Subject: [R] RSA package adjust alpha for a1-a4 confidence intervals
In-Reply-To: <MN2PR01MB5359A80CFD12A909D45B207F9D0F0@MN2PR01MB5359.prod.exchangelabs.com>
References: <MN2PR01MB5359A80CFD12A909D45B207F9D0F0@MN2PR01MB5359.prod.exchangelabs.com>
Message-ID: <61b6ac99-efdd-0cf8-95c9-e622c735eb98@comcast.net>


On 1/23/20 12:19 PM, Christopher Steinman wrote:
> Hi, I'm not experienced with R at all.  I'm using some canned code to produce RSA models in the RSA package.  I'd like to be able to adjust the alpha for the a1-a4 confidence intervals.
>
> This doesn't appear to be a native option for the RSA package, unless I'm missing something because I'm a novice.  Is there an easy way to do this?
>
> Any advice would be appreciated, thanks for your time in advance!
>
> 	[[alternative HTML version deleted]]


R is a plain text mailing list. You should adjust the settings of your 
mail client to reflect the fact that you have been advised of this.


You should also provide a small data set and explain what "a1-a4 
confidence intervals" might be.

-- 

David


From ||junzh@o0606 @end|ng |rom gm@||@com  Wed Feb 19 07:56:06 2020
From: ||junzh@o0606 @end|ng |rom gm@||@com (Lijun Zhao)
Date: Wed, 19 Feb 2020 17:26:06 +1030
Subject: [R] How to index the occasions in a vector repeatedly under
 condition 1? if not, it will give a new index.
Message-ID: <CAFJpZ1mcUVwhpUgdmkTKky-EwYLWPTK+DrUrUBT+YfrAKHr3KQ@mail.gmail.com>

Dear All,

could you please help me how to get the output from the following example?


x<-c(543,  543,  543,  543,  551 , 551 ,1128 ,1197, 1197)

diff<-x-lag(x)

diff

[1]  NA   0   0   0   8   0 577  69   0

how to index the occassions in x repeatedly if the diff>15? if not, it will
give a new index

i want the output be like y

y<-c(1,1,1,1,1,1,2,3,3)


thanks,


Lijun

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Feb 19 08:13:20 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 19 Feb 2020 07:13:20 +0000
Subject: [R] How to index the occasions in a vector repeatedly under
 condition 1? if not, it will give a new index.
In-Reply-To: <CAFJpZ1mcUVwhpUgdmkTKky-EwYLWPTK+DrUrUBT+YfrAKHr3KQ@mail.gmail.com>
References: <CAFJpZ1mcUVwhpUgdmkTKky-EwYLWPTK+DrUrUBT+YfrAKHr3KQ@mail.gmail.com>
Message-ID: <4568962d-dbec-2d20-98b7-a845a6dfbbe1@sapo.pt>

Hello,

First of all, a note about your reproducible example.

When you write diff <- x - lag(x) there are two things to be said.

1. There is a base R function named 'diff', it is better to use another 
name.

diff(x)
#[1]   0   0   0   8   0 577  69   0

2. There are also several functions named 'lag', one of them in base 
package stats.

x - lag(x)
#[1] 0 0 0 0 0 0 0 0 0
#attr(,"tsp")
#[1] 0 8 1

This is not the one you are using.

x - dplyr::lag(x)
#[1]  NA   0   0   0   8   0 577  69   0

That's the one. When you have a package loaded in your session, please 
start your scripts with library(<pkgname>), in this case library(dplyr).


Now for the question's problem. I will use a different name, 'd', not 
'diff'. And qualify the function name with the package name prefix.

The main problem is the NA in the first element of 'd', without it 
cumsum(d > 15) would be enough. This works because the logical values 
FALSE/TRUE are coded as 0/1 and their cumulative sum goes up every time 
a TRUE is found.

d <- x - dplyr::lag(x)
cumsum(is.na(d) | d > 15)
#[1] 1 1 1 1 1 1 2 3 3


Hope this helps,

Rui Barradas


?s 06:56 de 19/02/20, Lijun Zhao escreveu:
> Dear All,
> 
> could you please help me how to get the output from the following example?
> 
> 
> x<-c(543,  543,  543,  543,  551 , 551 ,1128 ,1197, 1197)
> 
> diff<-x-lag(x)
> 
> diff
> 
> [1]  NA   0   0   0   8   0 577  69   0
> 
> how to index the occassions in x repeatedly if the diff>15? if not, it will
> give a new index
> 
> i want the output be like y
> 
> y<-c(1,1,1,1,1,1,2,3,3)
> 
> 
> thanks,
> 
> 
> Lijun
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Feb 19 11:36:25 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 19 Feb 2020 10:36:25 +0000
Subject: [R] How to index the occasions in a vector repeatedly under
 condition 1? if not, it will give a new index.
In-Reply-To: <4568962d-dbec-2d20-98b7-a845a6dfbbe1@sapo.pt>
References: <CAFJpZ1mcUVwhpUgdmkTKky-EwYLWPTK+DrUrUBT+YfrAKHr3KQ@mail.gmail.com>
 <4568962d-dbec-2d20-98b7-a845a6dfbbe1@sapo.pt>
Message-ID: <31b5810372d94e8884c85d4f7fe5d811@SRVEXCHCM1302.precheza.cz>

Hi

You could get similar result with using diff function Rui suggested

c(1,cumsum((diff(x)>15))+1)
[1] 1 1 1 1 1 1 2 3 3

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Rui Barradas
> Sent: Wednesday, February 19, 2020 8:13 AM
> To: Lijun Zhao <lijunzhao0606 at gmail.com>; r-help at r-project.org
> Subject: Re: [R] How to index the occasions in a vector repeatedly under
> condition 1? if not, it will give a new index.
> 
> Hello,
> 
> First of all, a note about your reproducible example.
> 
> When you write diff <- x - lag(x) there are two things to be said.
> 
> 1. There is a base R function named 'diff', it is better to use another name.
> 
> diff(x)
> #[1]   0   0   0   8   0 577  69   0
> 
> 2. There are also several functions named 'lag', one of them in base package
> stats.
> 
> x - lag(x)
> #[1] 0 0 0 0 0 0 0 0 0
> #attr(,"tsp")
> #[1] 0 8 1
> 
> This is not the one you are using.
> 
> x - dplyr::lag(x)
> #[1]  NA   0   0   0   8   0 577  69   0
> 
> That's the one. When you have a package loaded in your session, please start
> your scripts with library(<pkgname>), in this case library(dplyr).
> 
> 
> Now for the question's problem. I will use a different name, 'd', not
> 'diff'. And qualify the function name with the package name prefix.
> 
> The main problem is the NA in the first element of 'd', without it
> cumsum(d > 15) would be enough. This works because the logical values
> FALSE/TRUE are coded as 0/1 and their cumulative sum goes up every time
> a TRUE is found.
> 
> d <- x - dplyr::lag(x)
> cumsum(is.na(d) | d > 15)
> #[1] 1 1 1 1 1 1 2 3 3
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> ?s 06:56 de 19/02/20, Lijun Zhao escreveu:
> > Dear All,
> >
> > could you please help me how to get the output from the following example?
> >
> >
> > x<-c(543,  543,  543,  543,  551 , 551 ,1128 ,1197, 1197)
> >
> > diff<-x-lag(x)
> >
> > diff
> >
> > [1]  NA   0   0   0   8   0 577  69   0
> >
> > how to index the occassions in x repeatedly if the diff>15? if not, it will
> > give a new index
> >
> > i want the output be like y
> >
> > y<-c(1,1,1,1,1,1,2,3,3)
> >
> >
> > thanks,
> >
> >
> > Lijun
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Feb 19 13:28:29 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 19 Feb 2020 12:28:29 +0000
Subject: [R] How to index the occasions in a vector repeatedly under
 condition 1? if not, it will give a new index.
In-Reply-To: <31b5810372d94e8884c85d4f7fe5d811@SRVEXCHCM1302.precheza.cz>
References: <CAFJpZ1mcUVwhpUgdmkTKky-EwYLWPTK+DrUrUBT+YfrAKHr3KQ@mail.gmail.com>
 <4568962d-dbec-2d20-98b7-a845a6dfbbe1@sapo.pt>
 <31b5810372d94e8884c85d4f7fe5d811@SRVEXCHCM1302.precheza.cz>
Message-ID: <44d7b0d9-f318-4cec-01e8-436e6ebe72a3@sapo.pt>

Hello,

Yes, or even simpler is to assume that the first group starts at the 
first element of x, a reasonable assumption.

cumsum(c(TRUE, diff(x) > 15))


Hope this helps,

Rui Barradas

?s 10:36 de 19/02/20, PIKAL Petr escreveu:
> Hi
> 
> You could get similar result with using diff function Rui suggested
> 
> c(1,cumsum((diff(x)>15))+1)
> [1] 1 1 1 1 1 1 2 3 3
> 
> Cheers
> Petr
> 
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Rui Barradas
>> Sent: Wednesday, February 19, 2020 8:13 AM
>> To: Lijun Zhao <lijunzhao0606 at gmail.com>; r-help at r-project.org
>> Subject: Re: [R] How to index the occasions in a vector repeatedly under
>> condition 1? if not, it will give a new index.
>>
>> Hello,
>>
>> First of all, a note about your reproducible example.
>>
>> When you write diff <- x - lag(x) there are two things to be said.
>>
>> 1. There is a base R function named 'diff', it is better to use another name.
>>
>> diff(x)
>> #[1]   0   0   0   8   0 577  69   0
>>
>> 2. There are also several functions named 'lag', one of them in base package
>> stats.
>>
>> x - lag(x)
>> #[1] 0 0 0 0 0 0 0 0 0
>> #attr(,"tsp")
>> #[1] 0 8 1
>>
>> This is not the one you are using.
>>
>> x - dplyr::lag(x)
>> #[1]  NA   0   0   0   8   0 577  69   0
>>
>> That's the one. When you have a package loaded in your session, please start
>> your scripts with library(<pkgname>), in this case library(dplyr).
>>
>>
>> Now for the question's problem. I will use a different name, 'd', not
>> 'diff'. And qualify the function name with the package name prefix.
>>
>> The main problem is the NA in the first element of 'd', without it
>> cumsum(d > 15) would be enough. This works because the logical values
>> FALSE/TRUE are coded as 0/1 and their cumulative sum goes up every time
>> a TRUE is found.
>>
>> d <- x - dplyr::lag(x)
>> cumsum(is.na(d) | d > 15)
>> #[1] 1 1 1 1 1 1 2 3 3
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> ?s 06:56 de 19/02/20, Lijun Zhao escreveu:
>>> Dear All,
>>>
>>> could you please help me how to get the output from the following example?
>>>
>>>
>>> x<-c(543,  543,  543,  543,  551 , 551 ,1128 ,1197, 1197)
>>>
>>> diff<-x-lag(x)
>>>
>>> diff
>>>
>>> [1]  NA   0   0   0   8   0 577  69   0
>>>
>>> how to index the occassions in x repeatedly if the diff>15? if not, it will
>>> give a new index
>>>
>>> i want the output be like y
>>>
>>> y<-c(1,1,1,1,1,1,2,3,3)
>>>
>>>
>>> thanks,
>>>
>>>
>>> Lijun
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From up@n@nd@@p@n| @end|ng |rom gm@||@com  Wed Feb 19 14:35:29 2020
From: up@n@nd@@p@n| @end|ng |rom gm@||@com (Upananda Pani)
Date: Wed, 19 Feb 2020 19:05:29 +0530
Subject: [R] Converting irregular time series data into ts object
Message-ID: <CAEezrQSFvp-G1DLv5vq3c=rCvA6yrGrZJsG18+u9B7FrvUbNDw@mail.gmail.com>

Dear All,

I want to convert irregular time series daily data in to ts objects. For
some years I have 305 days data and some years I have 256 days.

I need your suggestion regarding the same.

I have read tutorial on the same but not able to find solutions.

With regards,
Upananda

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Feb 19 14:51:30 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 19 Feb 2020 05:51:30 -0800
Subject: [R] Converting irregular time series data into ts object
In-Reply-To: <CAEezrQSFvp-G1DLv5vq3c=rCvA6yrGrZJsG18+u9B7FrvUbNDw@mail.gmail.com>
References: <CAEezrQSFvp-G1DLv5vq3c=rCvA6yrGrZJsG18+u9B7FrvUbNDw@mail.gmail.com>
Message-ID: <2EE0F09C-0C6E-4DAD-B38B-4F5493C914A7@dcn.davis.ca.us>

You should read about statistical imputation and decide what approach is appropriate for your data. This mailing list is for questions about R, not about statistics. Once you know what algorithm you need to apply, look up R functions that implement that algorithm using Google or the CRAN Task Views.

If you find yourself with some example code that doesn't work the way you think it should, that would be an appropriate time to first read the Posting Guide and then come back and post a question using plain text email setting rather than html format (so we don't receive a scrambled version of your broken example code).

On February 19, 2020 5:35:29 AM PST, Upananda Pani <upananda.pani at gmail.com> wrote:
>Dear All,
>
>I want to convert irregular time series daily data in to ts objects.
>For
>some years I have 305 days data and some years I have 256 days.
>
>I need your suggestion regarding the same.
>
>I have read tutorial on the same but not able to find solutions.
>
>With regards,
>Upananda
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ||jun@zh@o @end|ng |rom @de|@|de@edu@@u  Wed Feb 19 07:51:53 2020
From: ||jun@zh@o @end|ng |rom @de|@|de@edu@@u (Lijun Zhao)
Date: Wed, 19 Feb 2020 06:51:53 +0000
Subject: [R] How to index the occasions in a vector repeatedly under
 condition 1? if not, it will give a new index.
Message-ID: <SYYP282MB108651F19CC21C2452DF2953D9100@SYYP282MB1086.AUSP282.PROD.OUTLOOK.COM>

Dear all,
Could you please help me how to get the output as I described in the following example?

x<-c(543,  543,  543,  543,  551 , 551 ,1128 ,1197, 1197)
diff<-x-lag(x)
diff
[1]  NA   0   0   0   8   0 577  69   0

How to index the occasions in x repeatedly if the diff<15? if diff>=15, it will give a new index.
I want the output be like y.

y<-c(1,1,1,1,1,1,2,3,3)

Thank you so much,

Lijun Zhao (PhD Candidate)
Nutrition and Metabolism
Level 7 SAHMRI
North Terrace
Adelaide 5005
Ph    : +61 8 8128 4898
e-mail: lijun.zhao at adelaide.edu.au<mailto:lijun.zhao at adelaide.edu.au> or lijun.zhao at sahmri.com<mailto:lijun.zhao at sahmri.com>



	[[alternative HTML version deleted]]


From btupper @end|ng |rom b|ge|ow@org  Wed Feb 19 16:08:09 2020
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Wed, 19 Feb 2020 10:08:09 -0500
Subject: [R] Package httr::GET() question
In-Reply-To: <EFC2C1C8-5B1C-4543-96DE-6E61CBF7F304@noaa.gov>
References: <EFC2C1C8-5B1C-4543-96DE-6E61CBF7F304@noaa.gov>
Message-ID: <CALrbzg1duMq4u60tRxxSkToVkLWEcL+BOHHsUv762=SPiX4=jg@mail.gmail.com>

Hi,

Perhaps you could test it out by using httr::GET() with and without
escaping using xml2::url_escape()?

https://www.rdocumentation.org/packages/xml2/versions/1.2.2/topics/url_escape

Cheers,
Ben

On Tue, Feb 18, 2020 at 1:29 PM Roy Mendelssohn - NOAA Federal via
R-help <r-help at r-project.org> wrote:
>
> Hi All:
>
>  I hav been trying to go through the code for httr::GET() but it is somewhat beyond what I know.  What I am trying to find out is if all urls are automatically percent encoded,  or whether the user needs to do that.
>
> Thanks,
>
> -Roy
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Ben Tupper
Bigelow Laboratory for Ocean Science
West Boothbay Harbor, Maine
http://www.bigelow.org/
https://eco.bigelow.org


From wdun|@p @end|ng |rom t|bco@com  Wed Feb 19 16:22:43 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Wed, 19 Feb 2020 07:22:43 -0800
Subject: [R] How to index the occasions in a vector repeatedly under
 condition 1? if not, it will give a new index.
In-Reply-To: <SYYP282MB108651F19CC21C2452DF2953D9100@SYYP282MB1086.AUSP282.PROD.OUTLOOK.COM>
References: <SYYP282MB108651F19CC21C2452DF2953D9100@SYYP282MB1086.AUSP282.PROD.OUTLOOK.COM>
Message-ID: <CAF8bMcbNpEc8inm_bV8QXK5juyFG0NJep0u9=jtjp7XRZ2TufA@mail.gmail.com>

Use cumsum(logicalVector) to increment a counter at the TRUE positions in
logicalVector. .  E.g.,

> d <- c(NA, 0, 0, 0, 8, 0, 577, 69, 0)
> is_true <- function(x) !is.na(x) & x
> 1 + cumsum( is_true(d >= 15) )
[1] 1 1 1 1 1 1 2 3 3

Some packages have the equivalent of that is_true function, which maps
FALSE and NA to FALSE and TRUE to TRUE.  I don't think core R contains such
a function.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Feb 19, 2020 at 7:08 AM Lijun Zhao <lijun.zhao at adelaide.edu.au>
wrote:

> Dear all,
> Could you please help me how to get the output as I described in the
> following example?
>
> x<-c(543,  543,  543,  543,  551 , 551 ,1128 ,1197, 1197)
> diff<-x-lag(x)
> diff
> [1]  NA   0   0   0   8   0 577  69   0
>
> How to index the occasions in x repeatedly if the diff<15? if diff>=15, it
> will give a new index.
> I want the output be like y.
>
> y<-c(1,1,1,1,1,1,2,3,3)
>
> Thank you so much,
>
> Lijun Zhao (PhD Candidate)
> Nutrition and Metabolism
> Level 7 SAHMRI
> North Terrace
> Adelaide 5005
> Ph    : +61 8 8128 4898
> e-mail: lijun.zhao at adelaide.edu.au<mailto:lijun.zhao at adelaide.edu.au> or
> lijun.zhao at sahmri.com<mailto:lijun.zhao at sahmri.com>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From roy@mende|@@ohn @end|ng |rom no@@@gov  Wed Feb 19 16:30:49 2020
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Wed, 19 Feb 2020 07:30:49 -0800
Subject: [R] Package httr::GET() question
In-Reply-To: <CALrbzg1duMq4u60tRxxSkToVkLWEcL+BOHHsUv762=SPiX4=jg@mail.gmail.com>
References: <EFC2C1C8-5B1C-4543-96DE-6E61CBF7F304@noaa.gov>
 <CALrbzg1duMq4u60tRxxSkToVkLWEcL+BOHHsUv762=SPiX4=jg@mail.gmail.com>
Message-ID: <F9967587-A1FC-43D4-9365-944D59E8EA77@noaa.gov>

Thanks.  Yes.  I did that,  it also has a verbose mode so that I could see what it was doing.  What I needed was not just escaping but strict escaping.  My memory forma number of years back was that I had issues with urlencode from base not being strict.  And of course you don't what to encode twice.

Thanks,

-Roy


> On Feb 19, 2020, at 7:08 AM, Ben Tupper <btupper at bigelow.org> wrote:
> 
> Hi,
> 
> Perhaps you could test it out by using httr::GET() with and without
> escaping using xml2::url_escape()?
> 
> https://www.rdocumentation.org/packages/xml2/versions/1.2.2/topics/url_escape
> 
> Cheers,
> Ben
> 
> On Tue, Feb 18, 2020 at 1:29 PM Roy Mendelssohn - NOAA Federal via
> R-help <r-help at r-project.org> wrote:
>> 
>> Hi All:
>> 
>> I hav been trying to go through the code for httr::GET() but it is somewhat beyond what I know.  What I am trying to find out is if all urls are automatically percent encoded,  or whether the user needs to do that.
>> 
>> Thanks,
>> 
>> -Roy
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new street address***
>> 110 McAllister Way
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
>> 
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Ben Tupper
> Bigelow Laboratory for Ocean Science
> West Boothbay Harbor, Maine
> http://www.bigelow.org/
> https://eco.bigelow.org

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From ggrothend|eck @end|ng |rom gm@||@com  Wed Feb 19 16:37:09 2020
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Wed, 19 Feb 2020 10:37:09 -0500
Subject: [R] Converting irregular time series data into ts object
In-Reply-To: <CAEezrQSFvp-G1DLv5vq3c=rCvA6yrGrZJsG18+u9B7FrvUbNDw@mail.gmail.com>
References: <CAEezrQSFvp-G1DLv5vq3c=rCvA6yrGrZJsG18+u9B7FrvUbNDw@mail.gmail.com>
Message-ID: <CAP01uR=-F9ZiQPePHnvRq_E3uvVYgz=R0yr2eSzZFYiO=+1OdA@mail.gmail.com>

Assuming that they both cover the same period of time then
if you are willing to throw away some points then
consider using only these 256 elements from the 305 series

  round(seq(1, 305, length = 50))
  ## [1]   1   7  13  20  26  32  38  44 ...etc...

That is use the 1st ,7th, 13th, etc. point in each year from the
305 series.  This aligns them by throwing away 305-256=49
points per year in the 305 series so that both series can be
set up with a frequency of 256 points per year.



On Wed, Feb 19, 2020 at 8:36 AM Upananda Pani <upananda.pani at gmail.com> wrote:
>
> Dear All,
>
> I want to convert irregular time series daily data in to ts objects. For
> some years I have 305 days data and some years I have 256 days.
>
> I need your suggestion regarding the same.
>
> I have read tutorial on the same but not able to find solutions.
>
> With regards,
> Upananda
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ggrothend|eck @end|ng |rom gm@||@com  Wed Feb 19 16:41:03 2020
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Wed, 19 Feb 2020 10:41:03 -0500
Subject: [R] Converting irregular time series data into ts object
In-Reply-To: <CAP01uR=-F9ZiQPePHnvRq_E3uvVYgz=R0yr2eSzZFYiO=+1OdA@mail.gmail.com>
References: <CAEezrQSFvp-G1DLv5vq3c=rCvA6yrGrZJsG18+u9B7FrvUbNDw@mail.gmail.com>
 <CAP01uR=-F9ZiQPePHnvRq_E3uvVYgz=R0yr2eSzZFYiO=+1OdA@mail.gmail.com>
Message-ID: <CAP01uRkCsb8xKYeA4OVaBp2Tnx2aDwgMoW3Gb1FwrHDuwdK_4g@mail.gmail.com>

Sorry there were some errors in my email. Use this instead.

Assuming that they both cover the same period of time then
if you are willing to throw away some points then
consider using only these 256 elements from the 305 series

  round(seq(1, 305, length = 256))
  ##  [1]   1   2   3   5

That is use the 1st 2nd, 3rd, 5th, etc. point in each year from the
305 series.  This aligns them by throwing away 305-256=49
points per year in the 305 series so that both series can be
set up with a frequency of 256 points per year.

On Wed, Feb 19, 2020 at 10:37 AM Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
>
> Assuming that they both cover the same period of time then
> if you are willing to throw away some points then
> consider using only these 256 elements from the 305 series
>
>   round(seq(1, 305, length = 50))
>   ## [1]   1   7  13  20  26  32  38  44 ...etc...
>
> That is use the 1st ,7th, 13th, etc. point in each year from the
> 305 series.  This aligns them by throwing away 305-256=49
> points per year in the 305 series so that both series can be
> set up with a frequency of 256 points per year.
>
>
>
> On Wed, Feb 19, 2020 at 8:36 AM Upananda Pani <upananda.pani at gmail.com> wrote:
> >
> > Dear All,
> >
> > I want to convert irregular time series daily data in to ts objects. For
> > some years I have 305 days data and some years I have 256 days.
> >
> > I need your suggestion regarding the same.
> >
> > I have read tutorial on the same but not able to find solutions.
> >
> > With regards,
> > Upananda
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From t@ub|@ @end|ng |rom |mgprec|@|on@com  Wed Feb 19 21:26:28 2020
From: t@ub|@ @end|ng |rom |mgprec|@|on@com (Thomas Subia)
Date: Wed, 19 Feb 2020 20:26:28 +0000
Subject: [R] Annotate question
Message-ID: <CH2PR17MB3958B489EA9FAA3010D1BC27B8100@CH2PR17MB3958.namprd17.prod.outlook.com>

Colleagues,

To add an annotation using ggplot, I've used annotate("text",x=17,y=2130,label="16 u").

However, this does not work when trying to annotate box plots by groups since groups are factors.

Any advice would be appreciated.

Thomas Subia 
ASQ CQE

IMG Companies?
225 Mountain Vista Parkway
Livermore, CA 94551
T.?(925) 273-1106
F.?(925) 273-1111
E. tsubia at imgprecision.com


Precision Manufacturing for Emerging Technologies
imgprecision.com?

The contents of this message, together with any attachments, are intended only for the use of the individual or entity to which they are addressed and may contain information that is legally privileged, confidential and exempt from disclosure. If you are not the intended recipient, you are hereby notified that any dissemination, distribution, or copying of this message, or any attachment, is strictly prohibited. If you have received this message in error, please notify the original sender or IMG Companies, LLC at Tel: 925-273-1100 immediately by telephone or by return E-mail and delete this message, along with any attachments, from your computer. Thank you.


From @@chre|b @end|ng |rom u@|bert@@c@  Wed Feb 19 22:12:35 2020
From: @@chre|b @end|ng |rom u@|bert@@c@ (Stefan Schreiber)
Date: Wed, 19 Feb 2020 14:12:35 -0700
Subject: [R] Annotate question
In-Reply-To: <CH2PR17MB3958B489EA9FAA3010D1BC27B8100@CH2PR17MB3958.namprd17.prod.outlook.com>
References: <CH2PR17MB3958B489EA9FAA3010D1BC27B8100@CH2PR17MB3958.namprd17.prod.outlook.com>
Message-ID: <CAPK=JivWFYN5qOZ=KYCf9b3o7Yryo0q7NU0ake7Bhcsn0NLSbg@mail.gmail.com>

Since factor levels (groups) are coded by integers, you can use 1, 2, 3
etc. as your x values. If you want to annotate in between you can simply
pick values in between 1, 2, 3, etc.


On Wed, Feb 19, 2020, 13:26 Thomas Subia, <tsubia at imgprecision.com> wrote:

> Colleagues,
>
> To add an annotation using ggplot, I've used
> annotate("text",x=17,y=2130,label="16 u").
>
> However, this does not work when trying to annotate box plots by groups
> since groups are factors.
>
> Any advice would be appreciated.
>
> Thomas Subia
> ASQ CQE
>
> IMG Companies
> 225 Mountain Vista Parkway
> Livermore, CA 94551
> T. (925) 273-1106
> F. (925) 273-1111
> E. tsubia at imgprecision.com
>
>
> Precision Manufacturing for Emerging Technologies
> imgprecision.com
>
> The contents of this message, together with any attachments, are intended
> only for the use of the individual or entity to which they are addressed
> and may contain information that is legally privileged, confidential and
> exempt from disclosure. If you are not the intended recipient, you are
> hereby notified that any dissemination, distribution, or copying of this
> message, or any attachment, is strictly prohibited. If you have received
> this message in error, please notify the original sender or IMG Companies,
> LLC at Tel: 925-273-1100 immediately by telephone or by return E-mail and
> delete this message, along with any attachments, from your computer. Thank
> you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Feb 19 22:35:52 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 19 Feb 2020 21:35:52 +0000
Subject: [R] Annotate question
In-Reply-To: <CH2PR17MB3958B489EA9FAA3010D1BC27B8100@CH2PR17MB3958.namprd17.prod.outlook.com>
References: <CH2PR17MB3958B489EA9FAA3010D1BC27B8100@CH2PR17MB3958.namprd17.prod.outlook.com>
Message-ID: <db861dcc-405c-6c7a-2d7f-660efffd1e3f@sapo.pt>

Hello,

If groups are factors, pass the level you want to annotate.
This works, note the 'x' value:

ggplot(iris, aes(Species, Petal.Length)) +
   geom_boxplot() +
   annotate(geom = "text", x = "versicolor", y = 6, label = "16 u")


Hope this helps,

Rui Barradas


?s 20:26 de 19/02/20, Thomas Subia escreveu:
> Colleagues,
> 
> To add an annotation using ggplot, I've used annotate("text",x=17,y=2130,label="16 u").
> 
> However, this does not work when trying to annotate box plots by groups since groups are factors.
> 
> Any advice would be appreciated.
> 
> Thomas Subia
> ASQ CQE
> 
> IMG Companies
> 225 Mountain Vista Parkway
> Livermore, CA 94551
> T.?(925) 273-1106
> F.?(925) 273-1111
> E. tsubia at imgprecision.com
> 
> 
> Precision Manufacturing for Emerging Technologies
> imgprecision.com
> 
> The contents of this message, together with any attachments, are intended only for the use of the individual or entity to which they are addressed and may contain information that is legally privileged, confidential and exempt from disclosure. If you are not the intended recipient, you are hereby notified that any dissemination, distribution, or copying of this message, or any attachment, is strictly prohibited. If you have received this message in error, please notify the original sender or IMG Companies, LLC at Tel: 925-273-1100 immediately by telephone or by return E-mail and delete this message, along with any attachments, from your computer. Thank you.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Thu Feb 20 04:14:32 2020
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Wed, 19 Feb 2020 21:14:32 -0600
Subject: [R] supply chain, operations, and  sales optimization in R
References: <000001d5e79b$dfe5bca0$9fb135e0$.ref@sbcglobal.net>
Message-ID: <000001d5e79b$dfe5bca0$9fb135e0$@sbcglobal.net>

R-Help Forum

 

Anyone ever perform supply chain optimization, operations optimization or
sales optimization in R? If so what packages should I look to?

 

 

Sincerely

 

Jeff Reichman

(314) 457-1966

 


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Feb 20 05:43:20 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 19 Feb 2020 20:43:20 -0800
Subject: [R] supply chain, operations, and sales optimization in R
In-Reply-To: <000001d5e79b$dfe5bca0$9fb135e0$@sbcglobal.net>
References: <000001d5e79b$dfe5bca0$9fb135e0$.ref@sbcglobal.net>
 <000001d5e79b$dfe5bca0$9fb135e0$@sbcglobal.net>
Message-ID: <CAGxFJbSxjZ5Lh2GPUKR0N3-BK+EoN4jfLR=eLONmiQ-7CyJ1TA@mail.gmail.com>

Ummm... rather vague, and I certainly have no clue. But if you haven't
already done so, have a look here:
https://cran.r-project.org/web/views/

And of course, you should always try googling, e.g. on "supply chain
optimization using R" , etc.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 19, 2020 at 7:14 PM Jeff Reichman <reichmanj at sbcglobal.net>
wrote:

> R-Help Forum
>
>
>
> Anyone ever perform supply chain optimization, operations optimization or
> sales optimization in R? If so what packages should I look to?
>
>
>
>
>
> Sincerely
>
>
>
> Jeff Reichman
>
> (314) 457-1966
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j@vedbtk111 @end|ng |rom gm@||@com  Thu Feb 20 21:54:50 2020
From: j@vedbtk111 @end|ng |rom gm@||@com (javed khan)
Date: Thu, 20 Feb 2020 21:54:50 +0100
Subject: [R] Different number of resamples error
Message-ID: <CAJhui+smksh48LK0GDLcXWFeh+LHNMK5Or_zkqfh=0xkyb_ERA@mail.gmail.com>

Hello to all

I have different train functions for NN, SVM and GBM and when I combine the
results using bwplot, it gives me the error " Different number of resamples
in each model". It gives me the results (MAE values) but using the boxplot,
it gives the error. The code is as follows:

set.seed(30218)
nnet1 <- train(results~ ., data = tr,
                method = "nnet",

                metric = "MAE",
                trControl = ctrl,

                preProc = c("center", "scale", "zv"),
                tuneGrid = data.frame(decay = (1),
                                      size = (1.3801517)))
nnet1$results

///For SVM

set.seed(30218)
svm1 <- train(results ~ ., data = tr,
                    method = "svmRadial",

                    metric = "MAE",
                    preProc = c("center", "scale", "zv"),
                    trControl = ctrl,
              tuneGrid=expand.grid(sigma = (0.5),
                                                C = c(1.348657)))
getTrainPerf(svm1)
svm1$results

//For GBM

set.seed(30218)
gbm <- train(results ~ ., data = tr,
             method = "gbm",
             preProc = c("center", "scale", "zv"),
             metric = "MAE",


             tuneGrid = data.frame(n.trees = (200.09633523),
interaction.depth = (1),
                                   shrinkage=(0.1), n.minobsinnode=(10)))
gbm$results

//Then the boxplot

rvalues=resamples(list(nnet=nnet1, svm=svm1, GBM=gbm))

bwplot(rvalues, metric="MAE")

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Feb 20 22:15:22 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 20 Feb 2020 13:15:22 -0800
Subject: [R] Different number of resamples error
In-Reply-To: <CAJhui+smksh48LK0GDLcXWFeh+LHNMK5Or_zkqfh=0xkyb_ERA@mail.gmail.com>
References: <CAJhui+smksh48LK0GDLcXWFeh+LHNMK5Or_zkqfh=0xkyb_ERA@mail.gmail.com>
Message-ID: <CAGxFJbSRpQPgFnBv0Jf1sHkc=u15LwQJGRG84sMg7YbMYHTZBA@mail.gmail.com>

??
Isn't is resample()  not resamples()?
>From what package?
What package is bwplot from? lattice:::bwplot has no "metric" argument.



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Feb 20, 2020 at 12:55 PM javed khan <javedbtk111 at gmail.com> wrote:

> Hello to all
>
> I have different train functions for NN, SVM and GBM and when I combine the
> results using bwplot, it gives me the error " Different number of resamples
> in each model". It gives me the results (MAE values) but using the boxplot,
> it gives the error. The code is as follows:
>
> set.seed(30218)
> nnet1 <- train(results~ ., data = tr,
>                 method = "nnet",
>
>                 metric = "MAE",
>                 trControl = ctrl,
>
>                 preProc = c("center", "scale", "zv"),
>                 tuneGrid = data.frame(decay = (1),
>                                       size = (1.3801517)))
> nnet1$results
>
> ///For SVM
>
> set.seed(30218)
> svm1 <- train(results ~ ., data = tr,
>                     method = "svmRadial",
>
>                     metric = "MAE",
>                     preProc = c("center", "scale", "zv"),
>                     trControl = ctrl,
>               tuneGrid=expand.grid(sigma = (0.5),
>                                                 C = c(1.348657)))
> getTrainPerf(svm1)
> svm1$results
>
> //For GBM
>
> set.seed(30218)
> gbm <- train(results ~ ., data = tr,
>              method = "gbm",
>              preProc = c("center", "scale", "zv"),
>              metric = "MAE",
>
>
>              tuneGrid = data.frame(n.trees = (200.09633523),
> interaction.depth = (1),
>                                    shrinkage=(0.1), n.minobsinnode=(10)))
> gbm$results
>
> //Then the boxplot
>
> rvalues=resamples(list(nnet=nnet1, svm=svm1, GBM=gbm))
>
> bwplot(rvalues, metric="MAE")
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Feb 20 22:29:21 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 20 Feb 2020 13:29:21 -0800
Subject: [R] Different number of resamples error
In-Reply-To: <CAJhui+vftO1qx-V5vZr-yMjxzeoV=VR+ZrDdjHXjEn8fBZB=jA@mail.gmail.com>
References: <CAJhui+smksh48LK0GDLcXWFeh+LHNMK5Or_zkqfh=0xkyb_ERA@mail.gmail.com>
 <CAGxFJbSRpQPgFnBv0Jf1sHkc=u15LwQJGRG84sMg7YbMYHTZBA@mail.gmail.com>
 <CAJhui+vftO1qx-V5vZr-yMjxzeoV=VR+ZrDdjHXjEn8fBZB=jA@mail.gmail.com>
Message-ID: <CAGxFJbT4+c60DTxMoYty--gmmZ2eMjwivsNsoAKP2PdgwKK0Qg@mail.gmail.com>

cc the list!
(which I have done here)

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Feb 20, 2020 at 1:20 PM javed khan <javedbtk111 at gmail.com> wrote:

> Thanks for your reply.
>
> I am not using any specific package for bwplot. I just used caret, nnet
> and gbm packages.
>
> When I use resample (instead of resamples), it give me error message.
>
> metric=MAE gives the MAE values at x-axis when I used simple plots in the
> recent past.
>
> Best regards
>
> On Thu, Feb 20, 2020 at 10:15 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> ??
>> Isn't is resample()  not resamples()?
>> From what package?
>> What package is bwplot from? lattice:::bwplot has no "metric" argument.
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Feb 20, 2020 at 12:55 PM javed khan <javedbtk111 at gmail.com>
>> wrote:
>>
>>> Hello to all
>>>
>>> I have different train functions for NN, SVM and GBM and when I combine
>>> the
>>> results using bwplot, it gives me the error " Different number of
>>> resamples
>>> in each model". It gives me the results (MAE values) but using the
>>> boxplot,
>>> it gives the error. The code is as follows:
>>>
>>> set.seed(30218)
>>> nnet1 <- train(results~ ., data = tr,
>>>                 method = "nnet",
>>>
>>>                 metric = "MAE",
>>>                 trControl = ctrl,
>>>
>>>                 preProc = c("center", "scale", "zv"),
>>>                 tuneGrid = data.frame(decay = (1),
>>>                                       size = (1.3801517)))
>>> nnet1$results
>>>
>>> ///For SVM
>>>
>>> set.seed(30218)
>>> svm1 <- train(results ~ ., data = tr,
>>>                     method = "svmRadial",
>>>
>>>                     metric = "MAE",
>>>                     preProc = c("center", "scale", "zv"),
>>>                     trControl = ctrl,
>>>               tuneGrid=expand.grid(sigma = (0.5),
>>>                                                 C = c(1.348657)))
>>> getTrainPerf(svm1)
>>> svm1$results
>>>
>>> //For GBM
>>>
>>> set.seed(30218)
>>> gbm <- train(results ~ ., data = tr,
>>>              method = "gbm",
>>>              preProc = c("center", "scale", "zv"),
>>>              metric = "MAE",
>>>
>>>
>>>              tuneGrid = data.frame(n.trees = (200.09633523),
>>> interaction.depth = (1),
>>>                                    shrinkage=(0.1), n.minobsinnode=(10)))
>>> gbm$results
>>>
>>> //Then the boxplot
>>>
>>> rvalues=resamples(list(nnet=nnet1, svm=svm1, GBM=gbm))
>>>
>>> bwplot(rvalues, metric="MAE")
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From j@vedbtk111 @end|ng |rom gm@||@com  Thu Feb 20 22:31:30 2020
From: j@vedbtk111 @end|ng |rom gm@||@com (javed khan)
Date: Thu, 20 Feb 2020 22:31:30 +0100
Subject: [R] Different number of resamples error
In-Reply-To: <CAGxFJbT4+c60DTxMoYty--gmmZ2eMjwivsNsoAKP2PdgwKK0Qg@mail.gmail.com>
References: <CAJhui+smksh48LK0GDLcXWFeh+LHNMK5Or_zkqfh=0xkyb_ERA@mail.gmail.com>
 <CAGxFJbSRpQPgFnBv0Jf1sHkc=u15LwQJGRG84sMg7YbMYHTZBA@mail.gmail.com>
 <CAJhui+vftO1qx-V5vZr-yMjxzeoV=VR+ZrDdjHXjEn8fBZB=jA@mail.gmail.com>
 <CAGxFJbT4+c60DTxMoYty--gmmZ2eMjwivsNsoAKP2PdgwKK0Qg@mail.gmail.com>
Message-ID: <CAJhui+sn6PKCgmpynDWz62tugC1LOOf3cbJVfwVhTDaUTgH-TQ@mail.gmail.com>

Thanks for your reply.

I am not using any specific package for bwplot. I just used caret, nnet and
gbm packages.

When I use resample (instead of resamples), it give me error message.

metric=MAE gives the MAE values at x-axis when I used simple plots in the
recent past.

Best regards

On Thu, Feb 20, 2020 at 10:29 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> cc the list!
> (which I have done here)
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Feb 20, 2020 at 1:20 PM javed khan <javedbtk111 at gmail.com> wrote:
>
>> Thanks for your reply.
>>
>> I am not using any specific package for bwplot. I just used caret, nnet
>> and gbm packages.
>>
>> When I use resample (instead of resamples), it give me error message.
>>
>> metric=MAE gives the MAE values at x-axis when I used simple plots in the
>> recent past.
>>
>> Best regards
>>
>> On Thu, Feb 20, 2020 at 10:15 PM Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>
>>> ??
>>> Isn't is resample()  not resamples()?
>>> From what package?
>>> What package is bwplot from? lattice:::bwplot has no "metric" argument.
>>>
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Thu, Feb 20, 2020 at 12:55 PM javed khan <javedbtk111 at gmail.com>
>>> wrote:
>>>
>>>> Hello to all
>>>>
>>>> I have different train functions for NN, SVM and GBM and when I combine
>>>> the
>>>> results using bwplot, it gives me the error " Different number of
>>>> resamples
>>>> in each model". It gives me the results (MAE values) but using the
>>>> boxplot,
>>>> it gives the error. The code is as follows:
>>>>
>>>> set.seed(30218)
>>>> nnet1 <- train(results~ ., data = tr,
>>>>                 method = "nnet",
>>>>
>>>>                 metric = "MAE",
>>>>                 trControl = ctrl,
>>>>
>>>>                 preProc = c("center", "scale", "zv"),
>>>>                 tuneGrid = data.frame(decay = (1),
>>>>                                       size = (1.3801517)))
>>>> nnet1$results
>>>>
>>>> ///For SVM
>>>>
>>>> set.seed(30218)
>>>> svm1 <- train(results ~ ., data = tr,
>>>>                     method = "svmRadial",
>>>>
>>>>                     metric = "MAE",
>>>>                     preProc = c("center", "scale", "zv"),
>>>>                     trControl = ctrl,
>>>>               tuneGrid=expand.grid(sigma = (0.5),
>>>>                                                 C = c(1.348657)))
>>>> getTrainPerf(svm1)
>>>> svm1$results
>>>>
>>>> //For GBM
>>>>
>>>> set.seed(30218)
>>>> gbm <- train(results ~ ., data = tr,
>>>>              method = "gbm",
>>>>              preProc = c("center", "scale", "zv"),
>>>>              metric = "MAE",
>>>>
>>>>
>>>>              tuneGrid = data.frame(n.trees = (200.09633523),
>>>> interaction.depth = (1),
>>>>                                    shrinkage=(0.1),
>>>> n.minobsinnode=(10)))
>>>> gbm$results
>>>>
>>>> //Then the boxplot
>>>>
>>>> rvalues=resamples(list(nnet=nnet1, svm=svm1, GBM=gbm))
>>>>
>>>> bwplot(rvalues, metric="MAE")
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Thu Feb 20 22:45:29 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Fri, 21 Feb 2020 10:45:29 +1300
Subject: [R] supply chain, operations, and sales optimization in R
In-Reply-To: <000001d5e79b$dfe5bca0$9fb135e0$@sbcglobal.net>
References: <000001d5e79b$dfe5bca0$9fb135e0$.ref@sbcglobal.net>
 <000001d5e79b$dfe5bca0$9fb135e0$@sbcglobal.net>
Message-ID: <CABcYAdL4H8PCVNmyjQCj_tdGD8mosz_rV4wNJx20BKp6B=Rm=A@mail.gmail.com>

https://www.linkedin.com/pulse/r-shiny-application-supply-chain-network-design-shrinidhee-shevade

On Thu, 20 Feb 2020 at 16:15, Jeff Reichman <reichmanj at sbcglobal.net> wrote:
>
> R-Help Forum
>
>
>
> Anyone ever perform supply chain optimization, operations optimization or
> sales optimization in R? If so what packages should I look to?
>
>
>
>
>
> Sincerely
>
>
>
> Jeff Reichman
>
> (314) 457-1966
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ||jun@zh@o @end|ng |rom @de|@|de@edu@@u  Thu Feb 20 04:20:48 2020
From: ||jun@zh@o @end|ng |rom @de|@|de@edu@@u (Lijun Zhao)
Date: Thu, 20 Feb 2020 03:20:48 +0000
Subject: [R] How to index the occasions in a vector repeatedly under
 condition 1? if not, it will give a new index.
In-Reply-To: <CAF8bMcbNpEc8inm_bV8QXK5juyFG0NJep0u9=jtjp7XRZ2TufA@mail.gmail.com>
References: <SYYP282MB108651F19CC21C2452DF2953D9100@SYYP282MB1086.AUSP282.PROD.OUTLOOK.COM>
 <CAF8bMcbNpEc8inm_bV8QXK5juyFG0NJep0u9=jtjp7XRZ2TufA@mail.gmail.com>
Message-ID: <ME4P282MB107903721DAF4F18F4AA975AD9130@ME4P282MB1079.AUSP282.PROD.OUTLOOK.COM>

Dear William,
Thank you so much.

I am quiet new in R. I would like to do this based on another repeated variables.

For example:
a<-c(1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2)
d<-c(NA, 0, 0, 0, 8, 0, 577, 69, 0, NA, 0, 0, 0, 8, 0, 577, 69, 0)
the outcome I want is :
y<-c(1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1, 1 ,1, 1 ,1, 2, 3, 3)

Therefore, I would like to create y based on the variable a. once variable a has changed, the index will start from 1 again. I wrote a for loop, but it did not give me what I want. Could you please help me again?

Thanks in advance,

Lijun



From: William Dunlap <wdunlap at tibco.com>
Sent: Thursday, 20 February 2020 1:53 AM
To: Lijun Zhao <lijun.zhao at adelaide.edu.au>
Cc: r-help at r-project.org
Subject: Re: [R] How to index the occasions in a vector repeatedly under condition 1? if not, it will give a new index.

Use cumsum(logicalVector) to increment a counter at the TRUE positions in logicalVector. .  E.g.,

> d <- c(NA, 0, 0, 0, 8, 0, 577, 69, 0)
> is_true <- function(x) !is.na<http://is.na>(x) & x
> 1 + cumsum( is_true(d >= 15) )
[1] 1 1 1 1 1 1 2 3 3

Some packages have the equivalent of that is_true function, which maps FALSE and NA to FALSE and TRUE to TRUE.  I don't think core R contains such a function.

Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>


On Wed, Feb 19, 2020 at 7:08 AM Lijun Zhao <lijun.zhao at adelaide.edu.au<mailto:lijun.zhao at adelaide.edu.au>> wrote:
Dear all,
Could you please help me how to get the output as I described in the following example?

x<-c(543,  543,  543,  543,  551 , 551 ,1128 ,1197, 1197)
diff<-x-lag(x)
diff
[1]  NA   0   0   0   8   0 577  69   0

How to index the occasions in x repeatedly if the diff<15? if diff>=15, it will give a new index.
I want the output be like y.

y<-c(1,1,1,1,1,1,2,3,3)

Thank you so much,

Lijun Zhao (PhD Candidate)
Nutrition and Metabolism
Level 7 SAHMRI
North Terrace
Adelaide 5005
Ph    : +61 8 8128 4898
e-mail: lijun.zhao at adelaide.edu.au<mailto:lijun.zhao at adelaide.edu.au><mailto:lijun.zhao at adelaide.edu.au<mailto:lijun.zhao at adelaide.edu.au>> or lijun.zhao at sahmri.com<mailto:lijun.zhao at sahmri.com><mailto:lijun.zhao at sahmri.com<mailto:lijun.zhao at sahmri.com>>



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From moh|y101 @end|ng |rom gm@||@com  Thu Feb 20 15:32:34 2020
From: moh|y101 @end|ng |rom gm@||@com (mohi uddin)
Date: Thu, 20 Feb 2020 19:32:34 +0500
Subject: [R] Help
Message-ID: <CABekskNUt72uK+87US-Cc-LbhFkRJjD4dC966mzdy7ixKtJHNA@mail.gmail.com>

Hi,
Good day,
Sir,
I am PhD student and using metaSem by R package 3.6.2. For meta analysis.
I am using tssem. On stage 2, I type install.packages("semPlot")
Require("semPlot")
And then got given below message.

package ?semPlot? is not available (for R version 3.6.2)

Plz help me in making model.
Thanks
Sincerely
Mohiyuddin

	[[alternative HTML version deleted]]


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Fri Feb 21 00:15:41 2020
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Thu, 20 Feb 2020 17:15:41 -0600
Subject: [R] supply chain, operations, and sales optimization in R
In-Reply-To: <CAGxFJbSxjZ5Lh2GPUKR0N3-BK+EoN4jfLR=eLONmiQ-7CyJ1TA@mail.gmail.com>
References: <000001d5e79b$dfe5bca0$9fb135e0$.ref@sbcglobal.net>
 <000001d5e79b$dfe5bca0$9fb135e0$@sbcglobal.net>
 <CAGxFJbSxjZ5Lh2GPUKR0N3-BK+EoN4jfLR=eLONmiQ-7CyJ1TA@mail.gmail.com>
Message-ID: <000701d5e843$ac5433f0$04fc9bd0$@sbcglobal.net>

Bert

 

I?m looking into the SCperf package which deals with  supply chain planning and managing. Thanks for the link

 

Jeff

 

From: Bert Gunter <bgunter.4567 at gmail.com> 
Sent: Wednesday, February 19, 2020 10:43 PM
To: reichmanj at sbcglobal.net
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] supply chain, operations, and sales optimization in R

 

Ummm... rather vague, and I certainly have no clue. But if you haven't already done so, have a look here:

https://cran.r-project.org/web/views/

 

And of course, you should always try googling, e.g. on "supply chain optimization using R" , etc.

 

 

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

 

 

On Wed, Feb 19, 2020 at 7:14 PM Jeff Reichman <reichmanj at sbcglobal.net <mailto:reichmanj at sbcglobal.net> > wrote:

R-Help Forum



Anyone ever perform supply chain optimization, operations optimization or
sales optimization in R? If so what packages should I look to?





Sincerely



Jeff Reichman

(314) 457-1966




        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Fri Feb 21 00:15:41 2020
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Thu, 20 Feb 2020 17:15:41 -0600
Subject: [R] supply chain, operations, and sales optimization in R
In-Reply-To: <CAGxFJbSxjZ5Lh2GPUKR0N3-BK+EoN4jfLR=eLONmiQ-7CyJ1TA@mail.gmail.com>
References: <000001d5e79b$dfe5bca0$9fb135e0$.ref@sbcglobal.net>
 <000001d5e79b$dfe5bca0$9fb135e0$@sbcglobal.net>
 <CAGxFJbSxjZ5Lh2GPUKR0N3-BK+EoN4jfLR=eLONmiQ-7CyJ1TA@mail.gmail.com>
Message-ID: <000701d5e843$ac5433f0$04fc9bd0$@sbcglobal.net>

Bert

 

I?m looking into the SCperf package which deals with  supply chain planning and managing. Thanks for the link

 

Jeff

 

From: Bert Gunter <bgunter.4567 at gmail.com> 
Sent: Wednesday, February 19, 2020 10:43 PM
To: reichmanj at sbcglobal.net
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] supply chain, operations, and sales optimization in R

 

Ummm... rather vague, and I certainly have no clue. But if you haven't already done so, have a look here:

https://cran.r-project.org/web/views/

 

And of course, you should always try googling, e.g. on "supply chain optimization using R" , etc.

 

 

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

 

 

On Wed, Feb 19, 2020 at 7:14 PM Jeff Reichman <reichmanj at sbcglobal.net <mailto:reichmanj at sbcglobal.net> > wrote:

R-Help Forum



Anyone ever perform supply chain optimization, operations optimization or
sales optimization in R? If so what packages should I look to?





Sincerely



Jeff Reichman

(314) 457-1966




        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Feb 21 00:16:30 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 20 Feb 2020 15:16:30 -0800
Subject: [R] Different number of resamples error
In-Reply-To: <CAJhui+sn6PKCgmpynDWz62tugC1LOOf3cbJVfwVhTDaUTgH-TQ@mail.gmail.com>
References: <CAJhui+smksh48LK0GDLcXWFeh+LHNMK5Or_zkqfh=0xkyb_ERA@mail.gmail.com>
 <CAGxFJbSRpQPgFnBv0Jf1sHkc=u15LwQJGRG84sMg7YbMYHTZBA@mail.gmail.com>
 <CAJhui+vftO1qx-V5vZr-yMjxzeoV=VR+ZrDdjHXjEn8fBZB=jA@mail.gmail.com>
 <CAGxFJbT4+c60DTxMoYty--gmmZ2eMjwivsNsoAKP2PdgwKK0Qg@mail.gmail.com>
 <CAJhui+sn6PKCgmpynDWz62tugC1LOOf3cbJVfwVhTDaUTgH-TQ@mail.gmail.com>
Message-ID: <54AAFB77-3A06-4592-AC45-FC11535282B2@dcn.davis.ca.us>

You are being way too cavalier about what packages you are using. Read the Posting Guide about contributed packages... this list cannot provide expert support for every package out there. This confusion is why you should be providing a reproducible example when you ask for help about R.

The caret package depends on lattice and provides some overloaded versions of the bwplot function that do have a metric argument. I have no expertise with caret myself... but recommend that you supply a reproducible example for best luck in prompting someone to look closer.

On February 20, 2020 1:31:30 PM PST, javed khan <javedbtk111 at gmail.com> wrote:
>Thanks for your reply.
>
>I am not using any specific package for bwplot. I just used caret, nnet
>and
>gbm packages.
>
>When I use resample (instead of resamples), it give me error message.
>
>metric=MAE gives the MAE values at x-axis when I used simple plots in
>the
>recent past.
>
>Best regards
>
>On Thu, Feb 20, 2020 at 10:29 PM Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>
>> cc the list!
>> (which I have done here)
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming
>along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Feb 20, 2020 at 1:20 PM javed khan <javedbtk111 at gmail.com>
>wrote:
>>
>>> Thanks for your reply.
>>>
>>> I am not using any specific package for bwplot. I just used caret,
>nnet
>>> and gbm packages.
>>>
>>> When I use resample (instead of resamples), it give me error
>message.
>>>
>>> metric=MAE gives the MAE values at x-axis when I used simple plots
>in the
>>> recent past.
>>>
>>> Best regards
>>>
>>> On Thu, Feb 20, 2020 at 10:15 PM Bert Gunter
><bgunter.4567 at gmail.com>
>>> wrote:
>>>
>>>> ??
>>>> Isn't is resample()  not resamples()?
>>>> From what package?
>>>> What package is bwplot from? lattice:::bwplot has no "metric"
>argument.
>>>>
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming
>along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Thu, Feb 20, 2020 at 12:55 PM javed khan <javedbtk111 at gmail.com>
>>>> wrote:
>>>>
>>>>> Hello to all
>>>>>
>>>>> I have different train functions for NN, SVM and GBM and when I
>combine
>>>>> the
>>>>> results using bwplot, it gives me the error " Different number of
>>>>> resamples
>>>>> in each model". It gives me the results (MAE values) but using the
>>>>> boxplot,
>>>>> it gives the error. The code is as follows:
>>>>>
>>>>> set.seed(30218)
>>>>> nnet1 <- train(results~ ., data = tr,
>>>>>                 method = "nnet",
>>>>>
>>>>>                 metric = "MAE",
>>>>>                 trControl = ctrl,
>>>>>
>>>>>                 preProc = c("center", "scale", "zv"),
>>>>>                 tuneGrid = data.frame(decay = (1),
>>>>>                                       size = (1.3801517)))
>>>>> nnet1$results
>>>>>
>>>>> ///For SVM
>>>>>
>>>>> set.seed(30218)
>>>>> svm1 <- train(results ~ ., data = tr,
>>>>>                     method = "svmRadial",
>>>>>
>>>>>                     metric = "MAE",
>>>>>                     preProc = c("center", "scale", "zv"),
>>>>>                     trControl = ctrl,
>>>>>               tuneGrid=expand.grid(sigma = (0.5),
>>>>>                                                 C = c(1.348657)))
>>>>> getTrainPerf(svm1)
>>>>> svm1$results
>>>>>
>>>>> //For GBM
>>>>>
>>>>> set.seed(30218)
>>>>> gbm <- train(results ~ ., data = tr,
>>>>>              method = "gbm",
>>>>>              preProc = c("center", "scale", "zv"),
>>>>>              metric = "MAE",
>>>>>
>>>>>
>>>>>              tuneGrid = data.frame(n.trees = (200.09633523),
>>>>> interaction.depth = (1),
>>>>>                                    shrinkage=(0.1),
>>>>> n.minobsinnode=(10)))
>>>>> gbm$results
>>>>>
>>>>> //Then the boxplot
>>>>>
>>>>> rvalues=resamples(list(nnet=nnet1, svm=svm1, GBM=gbm))
>>>>>
>>>>> bwplot(rvalues, metric="MAE")
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From b|oprogr@mmer @end|ng |rom gm@||@com  Fri Feb 21 00:22:31 2020
From: b|oprogr@mmer @end|ng |rom gm@||@com (Caitlin Gibbons)
Date: Thu, 20 Feb 2020 16:22:31 -0700
Subject: [R] Help
In-Reply-To: <CABekskNUt72uK+87US-Cc-LbhFkRJjD4dC966mzdy7ixKtJHNA@mail.gmail.com>
References: <CABekskNUt72uK+87US-Cc-LbhFkRJjD4dC966mzdy7ixKtJHNA@mail.gmail.com>
Message-ID: <B9B95D5C-4AB8-47C1-A488-B3B4AD250C0D@gmail.com>

Hi.

Not all of us are ?Sirs?.



> On Feb 20, 2020, at 3:56 PM, mohi uddin <mohiy101 at gmail.com> wrote:
> 
> ?Hi,
> Good day,
> Sir,
> I am PhD student and using metaSem by R package 3.6.2. For meta analysis.
> I am using tssem. On stage 2, I type install.packages("semPlot")
> Require("semPlot")
> And then got given below message.
> 
> package ?semPlot? is not available (for R version 3.6.2)
> 
> Plz help me in making model.
> Thanks
> Sincerely
> Mohiyuddin
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkr|de@u @end|ng |rom gm@||@com  Fri Feb 21 01:21:54 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Thu, 20 Feb 2020 19:21:54 -0500
Subject: [R] Help
In-Reply-To: <B9B95D5C-4AB8-47C1-A488-B3B4AD250C0D@gmail.com>
References: <CABekskNUt72uK+87US-Cc-LbhFkRJjD4dC966mzdy7ixKtJHNA@mail.gmail.com>
 <B9B95D5C-4AB8-47C1-A488-B3B4AD250C0D@gmail.com>
Message-ID: <CAKZQJMAhk9HXufVGk=e0XW9Cffq+Z5bruKpKUiwx5Q0rSVYGTA@mail.gmail.com>

That's okay Caitlin, the Queen will have you on this year's honour's list.

On Thu, 20 Feb 2020 at 18:31, Caitlin Gibbons <bioprogrammer at gmail.com>
wrote:

> Hi.
>
> Not all of us are ?Sirs?.
>
>
>
> > On Feb 20, 2020, at 3:56 PM, mohi uddin <mohiy101 at gmail.com> wrote:
> >
> > ?Hi,
> > Good day,
> > Sir,
> > I am PhD student and using metaSem by R package 3.6.2. For meta analysis.
> > I am using tssem. On stage 2, I type install.packages("semPlot")
> > Require("semPlot")
> > And then got given below message.
> >
> > package ?semPlot? is not available (for R version 3.6.2)
> >
> > Plz help me in making model.
> > Thanks
> > Sincerely
> > Mohiyuddin
> >
> >    [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From jrkr|de@u @end|ng |rom gm@||@com  Fri Feb 21 01:24:33 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Thu, 20 Feb 2020 19:24:33 -0500
Subject: [R] Help
In-Reply-To: <CABekskNUt72uK+87US-Cc-LbhFkRJjD4dC966mzdy7ixKtJHNA@mail.gmail.com>
References: <CABekskNUt72uK+87US-Cc-LbhFkRJjD4dC966mzdy7ixKtJHNA@mail.gmail.com>
Message-ID: <CAKZQJMCo9A23v5HZuJW9UpMTPxkqzgFLqDhqyZpN0cJ=st9e1g@mail.gmail.com>

Are you trying it install the package from within an IDE or working at a
common line level?

Sometimes it seems better to start R on the command line and work there

On Thu, 20 Feb 2020 at 17:56, mohi uddin <mohiy101 at gmail.com> wrote:

> Hi,
> Good day,
> Sir,
> I am PhD student and using metaSem by R package 3.6.2. For meta analysis.
> I am using tssem. On stage 2, I type install.packages("semPlot")
> Require("semPlot")
> And then got given below message.
>
> package ?semPlot? is not available (for R version 3.6.2)
>
> Plz help me in making model.
> Thanks
> Sincerely
> Mohiyuddin
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Feb 21 02:10:34 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 20 Feb 2020 17:10:34 -0800
Subject: [R] Help
In-Reply-To: <CABekskNUt72uK+87US-Cc-LbhFkRJjD4dC966mzdy7ixKtJHNA@mail.gmail.com>
References: <CABekskNUt72uK+87US-Cc-LbhFkRJjD4dC966mzdy7ixKtJHNA@mail.gmail.com>
Message-ID: <aea7a17d-6aa8-b91c-dee7-eac3a141fb09@comcast.net>


On 2/20/20 6:32 AM, mohi uddin wrote:
> Hi,
> Good day,
> Sir,
> I am PhD student and using metaSem by R package 3.6.2. For meta analysis.
> I am using tssem. On stage 2, I type install.packages("semPlot")
> Require("semPlot")
> And then got given below message.
>
> package ?semPlot? is not available (for R version 3.6.2)

Rhelp is a plain text mailing list. If your PhD program doesn't include 
training on how to use a mail client, then you should avail yourself of 
the online training that google offers. It is incredibly easy to sent 
plaintext messages with gmail.


You should always include your setup, preferably with the output of 
sessionInfor()


You should also include the full output of you console session ... not 
just the last line.


I just executed:

install.packages("semPlot")

... and got an error message saying the package "OpenMx" had failed to install properly. In the process of getting to that point there was a rather long list of package dependencies that were also installed. I'm on Linux and the install.packages function behaves differently here than it does on OSX or Windoze. There you should always include dependencies=TRUE in the parameters given to `install.packages`.

Since OpenMx failed to install., I decided to try again. Many times packages have dependencies which have dependencies which  ....  ... Turtles all the way down. Well, R only goes only turtle-level down.

OpenMv eventually compiles. It was the longest single package compilations I've ever seen. But finally I saw:

* DONE (OpenMx)

The downloaded source packages are in
	?/tmp/Rtmp4ADe86/downloaded_packages?

# So I executed the install.packages again

> install.packages("semPlot")
Installing package into ?/home/david/R/x86_64-pc-linux-gnu-library/3.5.1?
(as ?lib? is unspecified)
trying URL 'https://cloud.r-project.org/src/contrib/semPlot_1.1.2.tar.gz'
Content type 'application/x-gzip' length 75138 bytes (73 KB)
==================================================
downloaded 73 KB

* installing *source* package ?semPlot? ...
** package ?semPlot? successfully unpacked and MD5 sums checked
** using staged installation
** R
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded from temporary location
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation path
* DONE (semPlot)

The downloaded source packages are in
	?/tmp/Rtmp4ADe86/downloaded_packages?

Success.

Best of luck ... and do pay attention to the advice at the top. It's the only way to get beyond perpetual noobism.

-- 
David.

>
> Plz help me in making model.
> Thanks
> Sincerely
> Mohiyuddin
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Feb 21 02:20:43 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 20 Feb 2020 17:20:43 -0800
Subject: [R] Help
In-Reply-To: <aea7a17d-6aa8-b91c-dee7-eac3a141fb09@comcast.net>
References: <CABekskNUt72uK+87US-Cc-LbhFkRJjD4dC966mzdy7ixKtJHNA@mail.gmail.com>
 <aea7a17d-6aa8-b91c-dee7-eac3a141fb09@comcast.net>
Message-ID: <b3033e3c-4e74-beaa-9109-6a7c952b8c91@comcast.net>


On 2/20/20 5:10 PM, David Winsemius wrote:
>
> On 2/20/20 6:32 AM, mohi uddin wrote:
>> Hi,
>> Good day,
>> Sir,
>> I am PhD student and using metaSem by R package 3.6.2. For meta 
>> analysis.
>> I am using tssem. On stage 2, I type install.packages("semPlot")
>> Require("semPlot")
>> And then got given below message.
>>
>> package ?semPlot? is not available (for R version 3.6.2)
>
> Rhelp is a plain text mailing list. If your PhD program doesn't 
> include training on how to use a mail client, then you should avail 
> yourself of the online training that google offers. It is incredibly 
> easy to sent plaintext messages with gmail.
>
>
> You should always include your setup, preferably with the output of 
> sessionInfor()
 ????????????????????????????????????????? make that 
..................sessionInfo()
>
>
> You should also include the full output of you console session ... not 
> just the last line.
>
>
> I just executed:
>
> install.packages("semPlot")
>
> ... and got an error message saying the package "OpenMx" had failed to 
> install properly. In the process of getting to that point there was a 
> rather long list of package dependencies that were also installed. I'm 
> on Linux and the install.packages function behaves differently here 
> than it does on OSX or Windoze. There you should always include 
> dependencies=TRUE in the parameters given to `install.packages`.
>
> Since OpenMx failed to install., I decided to try again. Many times 
> packages have dependencies which have dependencies which? ....? ... 
> Turtles all the way down. Well, R only goes only turtle-level down.

..............................................................................^one^

>
> OpenMv eventually compiles. It was the longest single package 
> compilation I've ever seen. But finally I saw:
>
> * DONE (OpenMx)
>
> The downloaded source packages are in
> ?????/tmp/Rtmp4ADe86/downloaded_packages?


You probably would not need to compile OpenMx from source I as I needed 
to, There is a win.binary version on CRAN.


Again;

Best of luck.


David

>
> # So I executed the install.packages again
>
>> install.packages("semPlot")
> Installing package into ?/home/david/R/x86_64-pc-linux-gnu-library/3.5.1?
> (as ?lib? is unspecified)
> trying URL 'https://cloud.r-project.org/src/contrib/semPlot_1.1.2.tar.gz'
> Content type 'application/x-gzip' length 75138 bytes (73 KB)
> ==================================================
> downloaded 73 KB
>
> * installing *source* package ?semPlot? ...
> ** package ?semPlot? successfully unpacked and MD5 sums checked
> ** using staged installation
> ** R
> ** inst
> ** byte-compile and prepare package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** testing if installed package can be loaded from temporary location
> ** testing if installed package can be loaded from final location
> ** testing if installed package keeps a record of temporary 
> installation path
> * DONE (semPlot)
>
> The downloaded source packages are in
> ?????/tmp/Rtmp4ADe86/downloaded_packages?
>
> Success.
>
> Best of luck ... and do pay attention to the advice at the top. It's 
> the only way to get beyond perpetual noobism.
>


From j@vedbtk111 @end|ng |rom gm@||@com  Fri Feb 21 10:00:17 2020
From: j@vedbtk111 @end|ng |rom gm@||@com (javed khan)
Date: Fri, 21 Feb 2020 10:00:17 +0100
Subject: [R] Different number of resamples error
In-Reply-To: <54AAFB77-3A06-4592-AC45-FC11535282B2@dcn.davis.ca.us>
References: <CAJhui+smksh48LK0GDLcXWFeh+LHNMK5Or_zkqfh=0xkyb_ERA@mail.gmail.com>
 <CAGxFJbSRpQPgFnBv0Jf1sHkc=u15LwQJGRG84sMg7YbMYHTZBA@mail.gmail.com>
 <CAJhui+vftO1qx-V5vZr-yMjxzeoV=VR+ZrDdjHXjEn8fBZB=jA@mail.gmail.com>
 <CAGxFJbT4+c60DTxMoYty--gmmZ2eMjwivsNsoAKP2PdgwKK0Qg@mail.gmail.com>
 <CAJhui+sn6PKCgmpynDWz62tugC1LOOf3cbJVfwVhTDaUTgH-TQ@mail.gmail.com>
 <54AAFB77-3A06-4592-AC45-FC11535282B2@dcn.davis.ca.us>
Message-ID: <CAJhui+tG2ZkaU_CQ_gjEzixsurVU=8YMJEAEH4erUGsTrQx4+w@mail.gmail.com>

The whole code is as follows:

library(caret)
library(farff)
library(gbm)
library(nnet)

setwd("C:/Users/PC/Documents")
d=readARFF("myresults.arff")

index <- createDataPartition(d$results, p = .70,list = FALSE)
tr <- d[index, ]
ts <- d[-index, ]
index_2 <- createFolds(tr$results, returnTrain = TRUE, list = TRUE)
ctrl <- trainControl(method = "repeatedcv", index = index_2)

set.seed(30218)
nnet1 <- train(results~ ., data = tr,
                method = "nnet",

                metric = "MAE",
                trControl = ctrl,

                preProc = c("center", "scale", "zv"),
                tuneGrid = data.frame(decay = (1),
                                      size = (1.3801517)))
nnet1$results

///For SVM

set.seed(30218)
svm1 <- train(results ~ ., data = tr,
                    method = "svmRadial",

                    metric = "MAE",
                    preProc = c("center", "scale", "zv"),
                    trControl = ctrl,
              tuneGrid=expand.grid(sigma = (0.5),
                                                C = c(1.348657)))
getTrainPerf(svm1)
svm1$results

//For GBM

set.seed(30218)
gbm <- train(results ~ ., data = tr,
             method = "gbm",
             preProc = c("center", "scale", "zv"),
             metric = "MAE",


             tuneGrid = data.frame(n.trees = (200.09633523),
interaction.depth = (1),
                                   shrinkage=(0.1), n.minobsinnode=(10)))
gbm$results

//Then the boxplot

rvalues=resamples(list(nnet=nnet1, svm=svm1, GBM=gbm))

bwplot(rvalues, metric="MAE")


On Fri, Feb 21, 2020 at 12:16 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> You are being way too cavalier about what packages you are using. Read the
> Posting Guide about contributed packages... this list cannot provide expert
> support for every package out there. This confusion is why you should be
> providing a reproducible example when you ask for help about R.
>
> The caret package depends on lattice and provides some overloaded versions
> of the bwplot function that do have a metric argument. I have no expertise
> with caret myself... but recommend that you supply a reproducible example
> for best luck in prompting someone to look closer.
>
> On February 20, 2020 1:31:30 PM PST, javed khan <javedbtk111 at gmail.com>
> wrote:
> >Thanks for your reply.
> >
> >I am not using any specific package for bwplot. I just used caret, nnet
> >and
> >gbm packages.
> >
> >When I use resample (instead of resamples), it give me error message.
> >
> >metric=MAE gives the MAE values at x-axis when I used simple plots in
> >the
> >recent past.
> >
> >Best regards
> >
> >On Thu, Feb 20, 2020 at 10:29 PM Bert Gunter <bgunter.4567 at gmail.com>
> >wrote:
> >
> >> cc the list!
> >> (which I have done here)
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming
> >along and
> >> sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Thu, Feb 20, 2020 at 1:20 PM javed khan <javedbtk111 at gmail.com>
> >wrote:
> >>
> >>> Thanks for your reply.
> >>>
> >>> I am not using any specific package for bwplot. I just used caret,
> >nnet
> >>> and gbm packages.
> >>>
> >>> When I use resample (instead of resamples), it give me error
> >message.
> >>>
> >>> metric=MAE gives the MAE values at x-axis when I used simple plots
> >in the
> >>> recent past.
> >>>
> >>> Best regards
> >>>
> >>> On Thu, Feb 20, 2020 at 10:15 PM Bert Gunter
> ><bgunter.4567 at gmail.com>
> >>> wrote:
> >>>
> >>>> ??
> >>>> Isn't is resample()  not resamples()?
> >>>> From what package?
> >>>> What package is bwplot from? lattice:::bwplot has no "metric"
> >argument.
> >>>>
> >>>>
> >>>>
> >>>> Bert Gunter
> >>>>
> >>>> "The trouble with having an open mind is that people keep coming
> >along
> >>>> and sticking things into it."
> >>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>
> >>>>
> >>>> On Thu, Feb 20, 2020 at 12:55 PM javed khan <javedbtk111 at gmail.com>
> >>>> wrote:
> >>>>
> >>>>> Hello to all
> >>>>>
> >>>>> I have different train functions for NN, SVM and GBM and when I
> >combine
> >>>>> the
> >>>>> results using bwplot, it gives me the error " Different number of
> >>>>> resamples
> >>>>> in each model". It gives me the results (MAE values) but using the
> >>>>> boxplot,
> >>>>> it gives the error. The code is as follows:
> >>>>>
> >>>>> set.seed(30218)
> >>>>> nnet1 <- train(results~ ., data = tr,
> >>>>>                 method = "nnet",
> >>>>>
> >>>>>                 metric = "MAE",
> >>>>>                 trControl = ctrl,
> >>>>>
> >>>>>                 preProc = c("center", "scale", "zv"),
> >>>>>                 tuneGrid = data.frame(decay = (1),
> >>>>>                                       size = (1.3801517)))
> >>>>> nnet1$results
> >>>>>
> >>>>> ///For SVM
> >>>>>
> >>>>> set.seed(30218)
> >>>>> svm1 <- train(results ~ ., data = tr,
> >>>>>                     method = "svmRadial",
> >>>>>
> >>>>>                     metric = "MAE",
> >>>>>                     preProc = c("center", "scale", "zv"),
> >>>>>                     trControl = ctrl,
> >>>>>               tuneGrid=expand.grid(sigma = (0.5),
> >>>>>                                                 C = c(1.348657)))
> >>>>> getTrainPerf(svm1)
> >>>>> svm1$results
> >>>>>
> >>>>> //For GBM
> >>>>>
> >>>>> set.seed(30218)
> >>>>> gbm <- train(results ~ ., data = tr,
> >>>>>              method = "gbm",
> >>>>>              preProc = c("center", "scale", "zv"),
> >>>>>              metric = "MAE",
> >>>>>
> >>>>>
> >>>>>              tuneGrid = data.frame(n.trees = (200.09633523),
> >>>>> interaction.depth = (1),
> >>>>>                                    shrinkage=(0.1),
> >>>>> n.minobsinnode=(10)))
> >>>>> gbm$results
> >>>>>
> >>>>> //Then the boxplot
> >>>>>
> >>>>> rvalues=resamples(list(nnet=nnet1, svm=svm1, GBM=gbm))
> >>>>>
> >>>>> bwplot(rvalues, metric="MAE")
> >>>>>
> >>>>>         [[alternative HTML version deleted]]
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From j@vedbtk111 @end|ng |rom gm@||@com  Fri Feb 21 10:04:09 2020
From: j@vedbtk111 @end|ng |rom gm@||@com (javed khan)
Date: Fri, 21 Feb 2020 10:04:09 +0100
Subject: [R] Different number of resamples error
In-Reply-To: <CAJhui+tG2ZkaU_CQ_gjEzixsurVU=8YMJEAEH4erUGsTrQx4+w@mail.gmail.com>
References: <CAJhui+smksh48LK0GDLcXWFeh+LHNMK5Or_zkqfh=0xkyb_ERA@mail.gmail.com>
 <CAGxFJbSRpQPgFnBv0Jf1sHkc=u15LwQJGRG84sMg7YbMYHTZBA@mail.gmail.com>
 <CAJhui+vftO1qx-V5vZr-yMjxzeoV=VR+ZrDdjHXjEn8fBZB=jA@mail.gmail.com>
 <CAGxFJbT4+c60DTxMoYty--gmmZ2eMjwivsNsoAKP2PdgwKK0Qg@mail.gmail.com>
 <CAJhui+sn6PKCgmpynDWz62tugC1LOOf3cbJVfwVhTDaUTgH-TQ@mail.gmail.com>
 <54AAFB77-3A06-4592-AC45-FC11535282B2@dcn.davis.ca.us>
 <CAJhui+tG2ZkaU_CQ_gjEzixsurVU=8YMJEAEH4erUGsTrQx4+w@mail.gmail.com>
Message-ID: <CAJhui+swiOdF7R2h6MKZX71_Gk8zMDcF+cv7Z=P7hxesPJW_Hw@mail.gmail.com>

When I do not include gbm in the boxplot, it gives me the result for nnet
and svm but when I include also gbm, it gives the error message

There are different numbers of resamples in each model

On Fri, Feb 21, 2020 at 10:00 AM javed khan <javedbtk111 at gmail.com> wrote:

> The whole code is as follows:
>
> library(caret)
> library(farff)
> library(gbm)
> library(nnet)
>
> setwd("C:/Users/PC/Documents")
> d=readARFF("myresults.arff")
>
> index <- createDataPartition(d$results, p = .70,list = FALSE)
> tr <- d[index, ]
> ts <- d[-index, ]
> index_2 <- createFolds(tr$results, returnTrain = TRUE, list = TRUE)
> ctrl <- trainControl(method = "repeatedcv", index = index_2)
>
> set.seed(30218)
> nnet1 <- train(results~ ., data = tr,
>                 method = "nnet",
>
>                 metric = "MAE",
>                 trControl = ctrl,
>
>                 preProc = c("center", "scale", "zv"),
>                 tuneGrid = data.frame(decay = (1),
>                                       size = (1.3801517)))
> nnet1$results
>
> ///For SVM
>
> set.seed(30218)
> svm1 <- train(results ~ ., data = tr,
>                     method = "svmRadial",
>
>                     metric = "MAE",
>                     preProc = c("center", "scale", "zv"),
>                     trControl = ctrl,
>               tuneGrid=expand.grid(sigma = (0.5),
>                                                 C = c(1.348657)))
> getTrainPerf(svm1)
> svm1$results
>
> //For GBM
>
> set.seed(30218)
> gbm <- train(results ~ ., data = tr,
>              method = "gbm",
>              preProc = c("center", "scale", "zv"),
>              metric = "MAE",
>
>
>              tuneGrid = data.frame(n.trees = (200.09633523),
> interaction.depth = (1),
>                                    shrinkage=(0.1), n.minobsinnode=(10)))
> gbm$results
>
> //Then the boxplot
>
> rvalues=resamples(list(nnet=nnet1, svm=svm1, GBM=gbm))
>
> bwplot(rvalues, metric="MAE")
>
>
> On Fri, Feb 21, 2020 at 12:16 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
>> You are being way too cavalier about what packages you are using. Read
>> the Posting Guide about contributed packages... this list cannot provide
>> expert support for every package out there. This confusion is why you
>> should be providing a reproducible example when you ask for help about R.
>>
>> The caret package depends on lattice and provides some overloaded
>> versions of the bwplot function that do have a metric argument. I have no
>> expertise with caret myself... but recommend that you supply a reproducible
>> example for best luck in prompting someone to look closer.
>>
>> On February 20, 2020 1:31:30 PM PST, javed khan <javedbtk111 at gmail.com>
>> wrote:
>> >Thanks for your reply.
>> >
>> >I am not using any specific package for bwplot. I just used caret, nnet
>> >and
>> >gbm packages.
>> >
>> >When I use resample (instead of resamples), it give me error message.
>> >
>> >metric=MAE gives the MAE values at x-axis when I used simple plots in
>> >the
>> >recent past.
>> >
>> >Best regards
>> >
>> >On Thu, Feb 20, 2020 at 10:29 PM Bert Gunter <bgunter.4567 at gmail.com>
>> >wrote:
>> >
>> >> cc the list!
>> >> (which I have done here)
>> >>
>> >> Bert Gunter
>> >>
>> >> "The trouble with having an open mind is that people keep coming
>> >along and
>> >> sticking things into it."
>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>
>> >>
>> >> On Thu, Feb 20, 2020 at 1:20 PM javed khan <javedbtk111 at gmail.com>
>> >wrote:
>> >>
>> >>> Thanks for your reply.
>> >>>
>> >>> I am not using any specific package for bwplot. I just used caret,
>> >nnet
>> >>> and gbm packages.
>> >>>
>> >>> When I use resample (instead of resamples), it give me error
>> >message.
>> >>>
>> >>> metric=MAE gives the MAE values at x-axis when I used simple plots
>> >in the
>> >>> recent past.
>> >>>
>> >>> Best regards
>> >>>
>> >>> On Thu, Feb 20, 2020 at 10:15 PM Bert Gunter
>> ><bgunter.4567 at gmail.com>
>> >>> wrote:
>> >>>
>> >>>> ??
>> >>>> Isn't is resample()  not resamples()?
>> >>>> From what package?
>> >>>> What package is bwplot from? lattice:::bwplot has no "metric"
>> >argument.
>> >>>>
>> >>>>
>> >>>>
>> >>>> Bert Gunter
>> >>>>
>> >>>> "The trouble with having an open mind is that people keep coming
>> >along
>> >>>> and sticking things into it."
>> >>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>>>
>> >>>>
>> >>>> On Thu, Feb 20, 2020 at 12:55 PM javed khan <javedbtk111 at gmail.com>
>> >>>> wrote:
>> >>>>
>> >>>>> Hello to all
>> >>>>>
>> >>>>> I have different train functions for NN, SVM and GBM and when I
>> >combine
>> >>>>> the
>> >>>>> results using bwplot, it gives me the error " Different number of
>> >>>>> resamples
>> >>>>> in each model". It gives me the results (MAE values) but using the
>> >>>>> boxplot,
>> >>>>> it gives the error. The code is as follows:
>> >>>>>
>> >>>>> set.seed(30218)
>> >>>>> nnet1 <- train(results~ ., data = tr,
>> >>>>>                 method = "nnet",
>> >>>>>
>> >>>>>                 metric = "MAE",
>> >>>>>                 trControl = ctrl,
>> >>>>>
>> >>>>>                 preProc = c("center", "scale", "zv"),
>> >>>>>                 tuneGrid = data.frame(decay = (1),
>> >>>>>                                       size = (1.3801517)))
>> >>>>> nnet1$results
>> >>>>>
>> >>>>> ///For SVM
>> >>>>>
>> >>>>> set.seed(30218)
>> >>>>> svm1 <- train(results ~ ., data = tr,
>> >>>>>                     method = "svmRadial",
>> >>>>>
>> >>>>>                     metric = "MAE",
>> >>>>>                     preProc = c("center", "scale", "zv"),
>> >>>>>                     trControl = ctrl,
>> >>>>>               tuneGrid=expand.grid(sigma = (0.5),
>> >>>>>                                                 C = c(1.348657)))
>> >>>>> getTrainPerf(svm1)
>> >>>>> svm1$results
>> >>>>>
>> >>>>> //For GBM
>> >>>>>
>> >>>>> set.seed(30218)
>> >>>>> gbm <- train(results ~ ., data = tr,
>> >>>>>              method = "gbm",
>> >>>>>              preProc = c("center", "scale", "zv"),
>> >>>>>              metric = "MAE",
>> >>>>>
>> >>>>>
>> >>>>>              tuneGrid = data.frame(n.trees = (200.09633523),
>> >>>>> interaction.depth = (1),
>> >>>>>                                    shrinkage=(0.1),
>> >>>>> n.minobsinnode=(10)))
>> >>>>> gbm$results
>> >>>>>
>> >>>>> //Then the boxplot
>> >>>>>
>> >>>>> rvalues=resamples(list(nnet=nnet1, svm=svm1, GBM=gbm))
>> >>>>>
>> >>>>> bwplot(rvalues, metric="MAE")
>> >>>>>
>> >>>>>         [[alternative HTML version deleted]]
>> >>>>>
>> >>>>> ______________________________________________
>> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>> PLEASE do read the posting guide
>> >>>>> http://www.R-project.org/posting-guide.html
>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>>
>> >>>>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Feb 21 10:06:01 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 21 Feb 2020 09:06:01 +0000
Subject: [R] Different number of resamples error
In-Reply-To: <CAJhui+tG2ZkaU_CQ_gjEzixsurVU=8YMJEAEH4erUGsTrQx4+w@mail.gmail.com>
References: <CAJhui+smksh48LK0GDLcXWFeh+LHNMK5Or_zkqfh=0xkyb_ERA@mail.gmail.com>
 <CAGxFJbSRpQPgFnBv0Jf1sHkc=u15LwQJGRG84sMg7YbMYHTZBA@mail.gmail.com>
 <CAJhui+vftO1qx-V5vZr-yMjxzeoV=VR+ZrDdjHXjEn8fBZB=jA@mail.gmail.com>
 <CAGxFJbT4+c60DTxMoYty--gmmZ2eMjwivsNsoAKP2PdgwKK0Qg@mail.gmail.com>
 <CAJhui+sn6PKCgmpynDWz62tugC1LOOf3cbJVfwVhTDaUTgH-TQ@mail.gmail.com>
 <54AAFB77-3A06-4592-AC45-FC11535282B2@dcn.davis.ca.us>
 <CAJhui+tG2ZkaU_CQ_gjEzixsurVU=8YMJEAEH4erUGsTrQx4+w@mail.gmail.com>
Message-ID: <694b0ab8019f41c48ef5d04f24fc9bc2@SRVEXCHCM1302.precheza.cz>

Hi

your code is not reproducible.

I get error with

> setwd("C:/Users/PC/Documents")
Error in setwd("C:/Users/PC/Documents") : cannot change working directory
>

so probably any other line of your code gives me error too.

Use dput(d) or dput(head(d)) to provide your data

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of javed khan
> Sent: Friday, February 21, 2020 10:00 AM
> To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] Different number of resamples error
> 
> The whole code is as follows:
> 
> library(caret)
> library(farff)
> library(gbm)
> library(nnet)
> 
> setwd("C:/Users/PC/Documents")
> d=readARFF("myresults.arff")
> 
> index <- createDataPartition(d$results, p = .70,list = FALSE) tr <-
d[index, ] ts <-
> d[-index, ]
> index_2 <- createFolds(tr$results, returnTrain = TRUE, list = TRUE) ctrl
<-
> trainControl(method = "repeatedcv", index = index_2)
> 
> set.seed(30218)
> nnet1 <- train(results~ ., data = tr,
>                 method = "nnet",
> 
>                 metric = "MAE",
>                 trControl = ctrl,
> 
>                 preProc = c("center", "scale", "zv"),
>                 tuneGrid = data.frame(decay = (1),
>                                       size = (1.3801517))) nnet1$results
> 
> ///For SVM
> 
> set.seed(30218)
> svm1 <- train(results ~ ., data = tr,
>                     method = "svmRadial",
> 
>                     metric = "MAE",
>                     preProc = c("center", "scale", "zv"),
>                     trControl = ctrl,
>               tuneGrid=expand.grid(sigma = (0.5),
>                                                 C = c(1.348657)))
> getTrainPerf(svm1)
> svm1$results
> 
> //For GBM
> 
> set.seed(30218)
> gbm <- train(results ~ ., data = tr,
>              method = "gbm",
>              preProc = c("center", "scale", "zv"),
>              metric = "MAE",
> 
> 
>              tuneGrid = data.frame(n.trees = (200.09633523),
interaction.depth =
> (1),
>                                    shrinkage=(0.1), n.minobsinnode=(10)))
gbm$results
> 
> //Then the boxplot
> 
> rvalues=resamples(list(nnet=nnet1, svm=svm1, GBM=gbm))
> 
> bwplot(rvalues, metric="MAE")
> 
> 
> On Fri, Feb 21, 2020 at 12:16 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> 
> > You are being way too cavalier about what packages you are using. Read
> > the Posting Guide about contributed packages... this list cannot
> > provide expert support for every package out there. This confusion is
> > why you should be providing a reproducible example when you ask for help
> about R.
> >
> > The caret package depends on lattice and provides some overloaded
> > versions of the bwplot function that do have a metric argument. I have
> > no expertise with caret myself... but recommend that you supply a
> > reproducible example for best luck in prompting someone to look closer.
> >
> > On February 20, 2020 1:31:30 PM PST, javed khan
> > <javedbtk111 at gmail.com>
> > wrote:
> > >Thanks for your reply.
> > >
> > >I am not using any specific package for bwplot. I just used caret,
> > >nnet and gbm packages.
> > >
> > >When I use resample (instead of resamples), it give me error message.
> > >
> > >metric=MAE gives the MAE values at x-axis when I used simple plots in
> > >the recent past.
> > >
> > >Best regards
> > >
> > >On Thu, Feb 20, 2020 at 10:29 PM Bert Gunter <bgunter.4567 at gmail.com>
> > >wrote:
> > >
> > >> cc the list!
> > >> (which I have done here)
> > >>
> > >> Bert Gunter
> > >>
> > >> "The trouble with having an open mind is that people keep coming
> > >along and
> > >> sticking things into it."
> > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >>
> > >>
> > >> On Thu, Feb 20, 2020 at 1:20 PM javed khan <javedbtk111 at gmail.com>
> > >wrote:
> > >>
> > >>> Thanks for your reply.
> > >>>
> > >>> I am not using any specific package for bwplot. I just used caret,
> > >nnet
> > >>> and gbm packages.
> > >>>
> > >>> When I use resample (instead of resamples), it give me error
> > >message.
> > >>>
> > >>> metric=MAE gives the MAE values at x-axis when I used simple plots
> > >in the
> > >>> recent past.
> > >>>
> > >>> Best regards
> > >>>
> > >>> On Thu, Feb 20, 2020 at 10:15 PM Bert Gunter
> > ><bgunter.4567 at gmail.com>
> > >>> wrote:
> > >>>
> > >>>> ??
> > >>>> Isn't is resample()  not resamples()?
> > >>>> From what package?
> > >>>> What package is bwplot from? lattice:::bwplot has no "metric"
> > >argument.
> > >>>>
> > >>>>
> > >>>>
> > >>>> Bert Gunter
> > >>>>
> > >>>> "The trouble with having an open mind is that people keep coming
> > >along
> > >>>> and sticking things into it."
> > >>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
> > >>>> )
> > >>>>
> > >>>>
> > >>>> On Thu, Feb 20, 2020 at 12:55 PM javed khan
> > >>>> <javedbtk111 at gmail.com>
> > >>>> wrote:
> > >>>>
> > >>>>> Hello to all
> > >>>>>
> > >>>>> I have different train functions for NN, SVM and GBM and when I
> > >combine
> > >>>>> the
> > >>>>> results using bwplot, it gives me the error " Different number
> > >>>>> of resamples in each model". It gives me the results (MAE
> > >>>>> values) but using the boxplot, it gives the error. The code is
> > >>>>> as follows:
> > >>>>>
> > >>>>> set.seed(30218)
> > >>>>> nnet1 <- train(results~ ., data = tr,
> > >>>>>                 method = "nnet",
> > >>>>>
> > >>>>>                 metric = "MAE",
> > >>>>>                 trControl = ctrl,
> > >>>>>
> > >>>>>                 preProc = c("center", "scale", "zv"),
> > >>>>>                 tuneGrid = data.frame(decay = (1),
> > >>>>>                                       size = (1.3801517)))
> > >>>>> nnet1$results
> > >>>>>
> > >>>>> ///For SVM
> > >>>>>
> > >>>>> set.seed(30218)
> > >>>>> svm1 <- train(results ~ ., data = tr,
> > >>>>>                     method = "svmRadial",
> > >>>>>
> > >>>>>                     metric = "MAE",
> > >>>>>                     preProc = c("center", "scale", "zv"),
> > >>>>>                     trControl = ctrl,
> > >>>>>               tuneGrid=expand.grid(sigma = (0.5),
> > >>>>>                                                 C =
> > >>>>> c(1.348657)))
> > >>>>> getTrainPerf(svm1)
> > >>>>> svm1$results
> > >>>>>
> > >>>>> //For GBM
> > >>>>>
> > >>>>> set.seed(30218)
> > >>>>> gbm <- train(results ~ ., data = tr,
> > >>>>>              method = "gbm",
> > >>>>>              preProc = c("center", "scale", "zv"),
> > >>>>>              metric = "MAE",
> > >>>>>
> > >>>>>
> > >>>>>              tuneGrid = data.frame(n.trees = (200.09633523),
> > >>>>> interaction.depth = (1),
> > >>>>>                                    shrinkage=(0.1),
> > >>>>> n.minobsinnode=(10)))
> > >>>>> gbm$results
> > >>>>>
> > >>>>> //Then the boxplot
> > >>>>>
> > >>>>> rvalues=resamples(list(nnet=nnet1, svm=svm1, GBM=gbm))
> > >>>>>
> > >>>>> bwplot(rvalues, metric="MAE")
> > >>>>>
> > >>>>>         [[alternative HTML version deleted]]
> > >>>>>
> > >>>>> ______________________________________________
> > >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > >>>>> see https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>> PLEASE do read the posting guide
> > >>>>> http://www.R-project.org/posting-guide.html
> > >>>>> and provide commented, minimal, self-contained, reproducible code.
> > >>>>>
> > >>>>
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From j@vedbtk111 @end|ng |rom gm@||@com  Fri Feb 21 10:11:52 2020
From: j@vedbtk111 @end|ng |rom gm@||@com (javed khan)
Date: Fri, 21 Feb 2020 10:11:52 +0100
Subject: [R] Different number of resamples error
In-Reply-To: <694b0ab8019f41c48ef5d04f24fc9bc2@SRVEXCHCM1302.precheza.cz>
References: <CAJhui+smksh48LK0GDLcXWFeh+LHNMK5Or_zkqfh=0xkyb_ERA@mail.gmail.com>
 <CAGxFJbSRpQPgFnBv0Jf1sHkc=u15LwQJGRG84sMg7YbMYHTZBA@mail.gmail.com>
 <CAJhui+vftO1qx-V5vZr-yMjxzeoV=VR+ZrDdjHXjEn8fBZB=jA@mail.gmail.com>
 <CAGxFJbT4+c60DTxMoYty--gmmZ2eMjwivsNsoAKP2PdgwKK0Qg@mail.gmail.com>
 <CAJhui+sn6PKCgmpynDWz62tugC1LOOf3cbJVfwVhTDaUTgH-TQ@mail.gmail.com>
 <54AAFB77-3A06-4592-AC45-FC11535282B2@dcn.davis.ca.us>
 <CAJhui+tG2ZkaU_CQ_gjEzixsurVU=8YMJEAEH4erUGsTrQx4+w@mail.gmail.com>
 <694b0ab8019f41c48ef5d04f24fc9bc2@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAJhui+sVg7HS+C0A6sxNK-kTG21mC3z2TTnV+QhBhn-BRPt2yA@mail.gmail.com>

structure(list(recordnumber = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10,
11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,
27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,
43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58,
59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74,
75, 76, 77, 78, 79, 80, 81, 82, 84, 89, 91, 92, 93, 94, 97, 98,
99, 100, 101), projectname = structure(c(1L, 1L, 1L, 1L, 1L,
1L, 1L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 5L, 6L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 7L, 7L, 1L, 6L, 6L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 5L, 5L, 7L, 7L, 8L,
8L, 8L, 8L, 3L, 8L, 4L, 4L, 4L), .Label = c("de", "erb", "gal",
"X", "hst", "slp", "spl", "Y"), class = "factor"), cat2 = structure(c(3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
8L, 8L, 8L, 3L, 3L, 13L, 9L, 9L, 9L, 11L, 11L, 11L, 5L, 4L, 6L,
8L, 3L, 3L, 9L, 9L, 9L, 9L, 9L, 6L, 7L, 2L, 2L, 3L, 3L, 8L, 8L,
8L, 13L, 13L, 13L, 8L, 8L, 14L, 6L, 4L, 3L, 10L, 10L, 10L, 14L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 10L,
8L, 8L, 1L, 1L, 1L, 1L, 1L, 12L, 1L, 1L, 1L, 1L, 1L, 1L, 12L), .Label =
c("Avionics",
"application_ground", "avionicsmonitoring", "batchdataprocessing",
"communications", "datacapture", "launchprocessing", "missionplanning",
"monitor_control", "operatingsystem", "realdataprocessing", "science",
"simulation", "utility"), class = "factor"), forg = structure(c(2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("f",
"g"), class = "factor"), center = structure(c(2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 6L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 2L, 2L, 2L, 6L, 6L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 2L, 2L, 3L, 3L,
5L, 5L, 5L, 5L, 5L, 5L, 2L, 2L, 2L), .Label = c("1", "2", "3",
"4", "5", "6"), class = "factor"), year = c(1979, 1979, 1979,
1979, 1979, 1979, 1979, 1982, 1980, 1980, 1984, 1980, 1985, 1980,
1983, 1982, 1980, 1984, 1983, 1984, 1985, 1985, 1985, 1986, 1986,
1986, 1982, 1982, 1982, 1982, 1982, 1982, 1985, 1987, 1987, 1986,
1986, 1986, 1986, 1986, 1980, 1975, 1982, 1982, 1982, 1977, 1977,
1984, 1980, 1983, 1984, 1985, 1979, 1979, 1979, 1979, 1977, 1979,
1974, 1975, 1976, 1979, 1971, 1980, 1979, 1977, 1976, 1983, 1978,
1979, 1979, 1979, 1979, 1982, 1978, 1978, 1978, 1979, 1984, 1984,
1980, 1980, 1977, 1977, 1977, 1977, 1977, 1977, 1982, 1980, 1983,
1983, 1983), mode = structure(c(3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L), .Label = c("embedded", "organic", "semidetached"
), class = "factor"), rely = structure(c(4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L,
4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 3L,
3L, 3L, 3L, 3L, 4L, 3L, 4L, 4L, 2L, 3L, 3L, 5L, 3L, 3L, 3L, 4L,
4L, 4L, 5L, 3L, 4L, 5L, 3L, 4L, 4L, 3L, 3L, 4L, 4L, 5L, 2L, 4L,
3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L,
5L, 5L, 5L, 5L, 5L, 4L, 4L, 4L), .Label = c("vl", "l", "n", "h",
"vh", "xh"), class = "factor"), data = structure(c(2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 3L, 3L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 2L, 2L, 2L,
3L, 3L, 3L, 3L, 3L, 4L, 2L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 4L, 4L,
4L, 3L, 3L, 3L, 4L, 4L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
4L, 3L, 2L, 2L, 3L, 3L, 2L, 2L, 5L, 4L, 3L, 3L, 3L, 5L, 4L, 2L,
2L, 4L, 4L, 4L, 4L, 2L, 4L, 3L, 3L, 3L), .Label = c("vl", "l",
"n", "h", "vh", "xh"), class = "factor"), cplx = structure(c(4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 3L, 4L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L, 2L, 3L, 3L, 3L, 4L, 6L,
4L, 4L, 4L, 5L, 4L, 4L, 4L, 5L, 4L, 6L, 4L, 6L, 6L, 3L, 3L, 4L,
4L, 4L, 2L, 4L, 3L, 4L, 4L, 4L, 3L, 3L, 4L, 5L, 5L, 5L, 5L, 5L,
4L, 5L, 5L, 5L, 5L, 5L, 6L, 5L, 5L, 5L, 5L, 5L), .Label = c("vl",
"l", "n", "h", "vh", "xh"), class = "factor"), time = structure(c(3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 6L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 4L, 3L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 4L, 5L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L,
5L, 5L, 5L, 4L, 4L, 4L, 5L, 3L, 3L, 6L, 3L, 4L, 4L, 3L, 3L, 4L,
4L, 4L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 6L,
5L, 5L, 5L, 6L, 6L, 6L, 6L, 5L, 6L, 5L, 5L, 5L), .Label = c("vl",
"l", "n", "h", "vh", "xh"), class = "factor"), stor = structure(c(3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 6L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 6L,
3L, 3L, 6L, 3L, 3L, 3L, 3L, 3L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L,
3L, 3L, 3L, 4L, 4L, 4L, 5L, 3L, 3L, 5L, 3L, 4L, 4L, 3L, 3L, 3L,
3L, 3L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 4L, 4L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 5L, 5L, 5L), .Label = c("vl",
"l", "n", "h", "vh", "xh"), class = "factor"), virt = structure(c(2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 3L, 3L, 3L, 3L, 3L, 2L, 2L, 4L, 3L, 2L, 2L, 2L, 3L, 2L,
3L, 3L, 3L, 2L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
4L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 4L,
4L, 2L, 2L, 3L, 3L, 3L, 3L, 2L, 3L, 4L, 4L, 4L), .Label = c("vl",
"l", "n", "h", "vh", "xh"), class = "factor"), turn = structure(c(2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 2L,
2L, 2L, 3L, 3L, 3L, 3L, 3L, 4L, 2L, 3L, 4L, 2L, 2L, 3L, 3L, 2L,
4L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 5L, 5L, 4L,
4L, 3L, 3L, 3L, 3L, 2L, 3L, 2L, 3L, 4L, 4L, 4L), .Label = c("vl",
"l", "n", "h", "vh", "xh"), class = "factor"), acap = structure(c(3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 3L, 3L, 3L, 3L, 3L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 3L, 4L, 4L, 3L, 4L, 4L, 4L, 3L,
4L, 4L, 4L, 4L, 3L, 3L, 5L, 4L, 3L, 4L, 5L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 3L,
4L, 5L, 5L, 4L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L), .Label = c("vl",
"l", "n", "h", "vh", "xh"), class = "factor"), aexp = structure(c(3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 5L, 5L, 5L, 5L, 4L, 5L, 3L, 5L,
4L, 5L, 4L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 4L, 4L,
4L, 4L, 4L, 3L, 4L, 4L, 5L, 3L, 3L, 5L, 3L, 3L, 3L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L,
4L, 5L, 5L, 4L, 4L, 4L, 4L, 2L, 4L, 3L, 3L, 3L), .Label = c("vl",
"l", "n", "h", "vh", "xh"), class = "factor"), pcap = structure(c(3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 5L, 4L, 5L, 3L, 4L, 4L, 3L, 5L,
4L, 4L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 4L, 3L, 3L, 4L, 4L, 3L, 3L, 4L, 5L, 5L, 3L, 3L,
4L, 4L, 4L, 3L, 3L, 3L, 5L, 5L, 3L, 4L, 5L, 3L, 3L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L,
4L, 5L, 5L, 4L, 4L, 4L, 4L, 3L, 4L, 3L, 3L, 3L), .Label = c("vl",
"l", "n", "h", "vh", "xh"), class = "factor"), vexp = structure(c(3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 3L, 3L, 2L, 3L, 3L,
3L, 3L, 3L, 4L, 3L, 3L, 3L, 2L, 3L, 1L, 4L, 4L, 4L, 3L, 3L, 3L,
3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L,
4L, 1L, 1L, 4L, 4L, 4L, 4L, 1L, 4L, 2L, 2L, 2L), .Label = c("vl",
"l", "n", "h", "vh", "xh"), class = "factor"), lexp = structure(c(4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L, 1L, 4L, 1L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 3L, 3L, 4L, 3L, 3L, 4L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 3L,
4L, 4L, 4L, 4L, 3L, 3L, 4L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L,
4L, 1L, 1L, 4L, 4L, 4L, 4L, 2L, 4L, 2L, 2L, 2L), .Label = c("vl",
"l", "n", "h", "vh", "xh"), class = "factor"), modp = structure(c(4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 4L, 4L, 4L, 3L, 3L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 4L,
4L, 4L, 3L, 3L, 4L, 3L, 3L, 4L, 4L, 4L, 4L, 3L, 2L, 4L, 4L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 4L, 4L, 4L, 1L, 3L, 4L, 4L, 3L, 3L, 3L,
3L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 4L, 3L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L, 4L, 3L, 3L, 3L), .Label = c("vl",
"l", "n", "h", "vh", "xh"), class = "factor"), tool = structure(c(3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 5L, 5L, 5L, 5L, 5L, 5L, 3L,
3L, 3L, 3L, 3L, 4L, 3L, 3L, 3L, 1L, 4L, 3L, 3L, 2L, 3L, 3L, 4L,
2L, 2L, 2L, 5L, 5L, 5L, 4L, 3L, 3L, 1L, 2L, 4L, 4L, 2L, 2L, 3L,
1L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 5L, 5L, 3L,
3L, 4L, 4L, 3L, 3L, 3L, 3L, 4L, 3L, 3L, 3L, 3L), .Label = c("vl",
"l", "n", "h", "vh", "xh"), class = "factor"), sced = structure(c(2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 2L, 2L, 2L, 3L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 3L, 3L, 3L, 3L, 3L, 2L, 3L, 3L, 3L, 3L, 4L, 3L, 4L, 3L,
4L, 4L, 4L, 4L, 3L, 3L, 2L, 2L, 2L, 4L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 4L, 4L, 4L,
3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("vl",
"l", "n", "h", "vh", "xh"), class = "factor"), equivphyskloc = c(25.9,
24.6, 7.7, 8.2, 9.7, 2.2, 3.5, 66.6, 7.5, 20, 6, 100, 11.3, 100,
20, 100, 150, 31.5, 15, 32.5, 19.7, 66.6, 29.5, 15, 38, 10, 15.4,
48.5, 16.3, 12.8, 32.6, 35.5, 5.5, 10.4, 14, 6.5, 13, 90, 8,
16, 177.9, 302, 282.1, 284.7, 79, 423, 190, 47.5, 21, 78, 11.4,
19.3, 101, 219, 50, 227, 70, 0.9, 980, 350, 70, 271, 90, 40,
137, 150, 339, 240, 144, 151, 34, 98, 85, 20, 111, 162, 352,
165, 60, 100, 32, 53, 41, 24, 165, 65, 70, 50, 7.25, 233, 16.3,
6.2, 3), act_effort = c(117.6, 117.6, 31.2, 36, 25.2, 8.4, 10.8,
352.8, 72, 72, 24, 360, 36, 215, 48, 360, 324, 60, 48, 60, 60,
300, 120, 90, 210, 48, 70, 239, 82, 62, 170, 192, 18, 50, 60,
42, 60, 444, 42, 114, 1248, 2400, 1368, 973, 400, 2400, 420,
252, 107, 571.4, 98.8, 155, 750, 2120, 370, 1181, 278, 8.4, 4560,
720, 458, 2460, 162, 150, 636, 882, 444, 192, 576, 432, 72, 300,
300, 240, 600, 756, 1200, 97, 409, 703, 1350, 480, 599, 430,
4178.2, 1772.5, 1645.9, 1924.5, 648, 8211, 480, 12, 38)), row.names = c(NA,
-93L), class = "data.frame")

On Fri, Feb 21, 2020 at 10:06 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> your code is not reproducible.
>
> I get error with
>
> > setwd("C:/Users/PC/Documents")
> Error in setwd("C:/Users/PC/Documents") : cannot change working directory
> >
>
> so probably any other line of your code gives me error too.
>
> Use dput(d) or dput(head(d)) to provide your data
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of javed khan
> > Sent: Friday, February 21, 2020 10:00 AM
> > To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> > Cc: R-help <r-help at r-project.org>
> > Subject: Re: [R] Different number of resamples error
> >
> > The whole code is as follows:
> >
> > library(caret)
> > library(farff)
> > library(gbm)
> > library(nnet)
> >
> > setwd("C:/Users/PC/Documents")
> > d=readARFF("myresults.arff")
> >
> > index <- createDataPartition(d$results, p = .70,list = FALSE) tr <-
> d[index, ] ts <-
> > d[-index, ]
> > index_2 <- createFolds(tr$results, returnTrain = TRUE, list = TRUE) ctrl
> <-
> > trainControl(method = "repeatedcv", index = index_2)
> >
> > set.seed(30218)
> > nnet1 <- train(results~ ., data = tr,
> >                 method = "nnet",
> >
> >                 metric = "MAE",
> >                 trControl = ctrl,
> >
> >                 preProc = c("center", "scale", "zv"),
> >                 tuneGrid = data.frame(decay = (1),
> >                                       size = (1.3801517))) nnet1$results
> >
> > ///For SVM
> >
> > set.seed(30218)
> > svm1 <- train(results ~ ., data = tr,
> >                     method = "svmRadial",
> >
> >                     metric = "MAE",
> >                     preProc = c("center", "scale", "zv"),
> >                     trControl = ctrl,
> >               tuneGrid=expand.grid(sigma = (0.5),
> >                                                 C = c(1.348657)))
> > getTrainPerf(svm1)
> > svm1$results
> >
> > //For GBM
> >
> > set.seed(30218)
> > gbm <- train(results ~ ., data = tr,
> >              method = "gbm",
> >              preProc = c("center", "scale", "zv"),
> >              metric = "MAE",
> >
> >
> >              tuneGrid = data.frame(n.trees = (200.09633523),
> interaction.depth =
> > (1),
> >                                    shrinkage=(0.1), n.minobsinnode=(10)))
> gbm$results
> >
> > //Then the boxplot
> >
> > rvalues=resamples(list(nnet=nnet1, svm=svm1, GBM=gbm))
> >
> > bwplot(rvalues, metric="MAE")
> >
> >
> > On Fri, Feb 21, 2020 at 12:16 AM Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us>
> > wrote:
> >
> > > You are being way too cavalier about what packages you are using. Read
> > > the Posting Guide about contributed packages... this list cannot
> > > provide expert support for every package out there. This confusion is
> > > why you should be providing a reproducible example when you ask for
> help
> > about R.
> > >
> > > The caret package depends on lattice and provides some overloaded
> > > versions of the bwplot function that do have a metric argument. I have
> > > no expertise with caret myself... but recommend that you supply a
> > > reproducible example for best luck in prompting someone to look closer.
> > >
> > > On February 20, 2020 1:31:30 PM PST, javed khan
> > > <javedbtk111 at gmail.com>
> > > wrote:
> > > >Thanks for your reply.
> > > >
> > > >I am not using any specific package for bwplot. I just used caret,
> > > >nnet and gbm packages.
> > > >
> > > >When I use resample (instead of resamples), it give me error message.
> > > >
> > > >metric=MAE gives the MAE values at x-axis when I used simple plots in
> > > >the recent past.
> > > >
> > > >Best regards
> > > >
> > > >On Thu, Feb 20, 2020 at 10:29 PM Bert Gunter <bgunter.4567 at gmail.com>
> > > >wrote:
> > > >
> > > >> cc the list!
> > > >> (which I have done here)
> > > >>
> > > >> Bert Gunter
> > > >>
> > > >> "The trouble with having an open mind is that people keep coming
> > > >along and
> > > >> sticking things into it."
> > > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > > >>
> > > >>
> > > >> On Thu, Feb 20, 2020 at 1:20 PM javed khan <javedbtk111 at gmail.com>
> > > >wrote:
> > > >>
> > > >>> Thanks for your reply.
> > > >>>
> > > >>> I am not using any specific package for bwplot. I just used caret,
> > > >nnet
> > > >>> and gbm packages.
> > > >>>
> > > >>> When I use resample (instead of resamples), it give me error
> > > >message.
> > > >>>
> > > >>> metric=MAE gives the MAE values at x-axis when I used simple plots
> > > >in the
> > > >>> recent past.
> > > >>>
> > > >>> Best regards
> > > >>>
> > > >>> On Thu, Feb 20, 2020 at 10:15 PM Bert Gunter
> > > ><bgunter.4567 at gmail.com>
> > > >>> wrote:
> > > >>>
> > > >>>> ??
> > > >>>> Isn't is resample()  not resamples()?
> > > >>>> From what package?
> > > >>>> What package is bwplot from? lattice:::bwplot has no "metric"
> > > >argument.
> > > >>>>
> > > >>>>
> > > >>>>
> > > >>>> Bert Gunter
> > > >>>>
> > > >>>> "The trouble with having an open mind is that people keep coming
> > > >along
> > > >>>> and sticking things into it."
> > > >>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
> > > >>>> )
> > > >>>>
> > > >>>>
> > > >>>> On Thu, Feb 20, 2020 at 12:55 PM javed khan
> > > >>>> <javedbtk111 at gmail.com>
> > > >>>> wrote:
> > > >>>>
> > > >>>>> Hello to all
> > > >>>>>
> > > >>>>> I have different train functions for NN, SVM and GBM and when I
> > > >combine
> > > >>>>> the
> > > >>>>> results using bwplot, it gives me the error " Different number
> > > >>>>> of resamples in each model". It gives me the results (MAE
> > > >>>>> values) but using the boxplot, it gives the error. The code is
> > > >>>>> as follows:
> > > >>>>>
> > > >>>>> set.seed(30218)
> > > >>>>> nnet1 <- train(results~ ., data = tr,
> > > >>>>>                 method = "nnet",
> > > >>>>>
> > > >>>>>                 metric = "MAE",
> > > >>>>>                 trControl = ctrl,
> > > >>>>>
> > > >>>>>                 preProc = c("center", "scale", "zv"),
> > > >>>>>                 tuneGrid = data.frame(decay = (1),
> > > >>>>>                                       size = (1.3801517)))
> > > >>>>> nnet1$results
> > > >>>>>
> > > >>>>> ///For SVM
> > > >>>>>
> > > >>>>> set.seed(30218)
> > > >>>>> svm1 <- train(results ~ ., data = tr,
> > > >>>>>                     method = "svmRadial",
> > > >>>>>
> > > >>>>>                     metric = "MAE",
> > > >>>>>                     preProc = c("center", "scale", "zv"),
> > > >>>>>                     trControl = ctrl,
> > > >>>>>               tuneGrid=expand.grid(sigma = (0.5),
> > > >>>>>                                                 C =
> > > >>>>> c(1.348657)))
> > > >>>>> getTrainPerf(svm1)
> > > >>>>> svm1$results
> > > >>>>>
> > > >>>>> //For GBM
> > > >>>>>
> > > >>>>> set.seed(30218)
> > > >>>>> gbm <- train(results ~ ., data = tr,
> > > >>>>>              method = "gbm",
> > > >>>>>              preProc = c("center", "scale", "zv"),
> > > >>>>>              metric = "MAE",
> > > >>>>>
> > > >>>>>
> > > >>>>>              tuneGrid = data.frame(n.trees = (200.09633523),
> > > >>>>> interaction.depth = (1),
> > > >>>>>                                    shrinkage=(0.1),
> > > >>>>> n.minobsinnode=(10)))
> > > >>>>> gbm$results
> > > >>>>>
> > > >>>>> //Then the boxplot
> > > >>>>>
> > > >>>>> rvalues=resamples(list(nnet=nnet1, svm=svm1, GBM=gbm))
> > > >>>>>
> > > >>>>> bwplot(rvalues, metric="MAE")
> > > >>>>>
> > > >>>>>         [[alternative HTML version deleted]]
> > > >>>>>
> > > >>>>> ______________________________________________
> > > >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > >>>>> see https://stat.ethz.ch/mailman/listinfo/r-help
> > > >>>>> PLEASE do read the posting guide
> > > >>>>> http://www.R-project.org/posting-guide.html
> > > >>>>> and provide commented, minimal, self-contained, reproducible
> code.
> > > >>>>>
> > > >>>>
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > > >______________________________________________
> > > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >https://stat.ethz.ch/mailman/listinfo/r-help
> > > >PLEASE do read the posting guide
> > > >http://www.R-project.org/posting-guide.html
> > > >and provide commented, minimal, self-contained, reproducible code.
> > >
> > > --
> > > Sent from my phone. Please excuse my brevity.
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Feb 21 10:16:57 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 21 Feb 2020 09:16:57 +0000
Subject: [R] How to index the occasions in a vector repeatedly under
 condition 1? if not, it will give a new index.
In-Reply-To: <ME4P282MB107903721DAF4F18F4AA975AD9130@ME4P282MB1079.AUSP282.PROD.OUTLOOK.COM>
References: <SYYP282MB108651F19CC21C2452DF2953D9100@SYYP282MB1086.AUSP282.PROD.OUTLOOK.COM>
 <CAF8bMcbNpEc8inm_bV8QXK5juyFG0NJep0u9=jtjp7XRZ2TufA@mail.gmail.com>
 <ME4P282MB107903721DAF4F18F4AA975AD9130@ME4P282MB1079.AUSP282.PROD.OUTLOOK.COM>
Message-ID: <2e71d958246d4568a3ad485e75c18fe4@SRVEXCHCM1302.precheza.cz>

Hi

If you used diff construction you would not have NA values in beginning

#get rid of NA values
> d[is.na(d)] <- 0
#split d according to a
> d.s <- split(d, a)
# get the result
> lapply(d.s, function(x) cumsum(x>15)+1)
$`1`
[1] 1 1 1 1 1 1 2 3 3

$`2`
[1] 1 1 1 1 1 1 2 3 3
#unlist it
> res <- lapply(d.s, function(x) cumsum(x>15)+1)
> unlist(res)
11 12 13 14 15 16 17 18 19 21 22 23 24 25 26 27 28 29 
 1  1  1  1  1  1  2  3  3  1  1  1  1  1  1  2  3  3 

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Lijun Zhao
> Sent: Thursday, February 20, 2020 4:21 AM
> To: William Dunlap <wdunlap at tibco.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] How to index the occasions in a vector repeatedly under
> condition 1? if not, it will give a new index.
> 
> Dear William,
> Thank you so much.
> 
> I am quiet new in R. I would like to do this based on another repeated
variables.
> 
> For example:
> a<-c(1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2)
> d<-c(NA, 0, 0, 0, 8, 0, 577, 69, 0, NA, 0, 0, 0, 8, 0, 577, 69, 0) the
outcome I
> want is :
> y<-c(1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1, 1 ,1, 1 ,1, 2, 3, 3)
> 
> Therefore, I would like to create y based on the variable a. once variable
a has
> changed, the index will start from 1 again. I wrote a for loop, but it did
not give
> me what I want. Could you please help me again?
> 
> Thanks in advance,
> 
> Lijun
> 
> 
> 
> From: William Dunlap <wdunlap at tibco.com>
> Sent: Thursday, 20 February 2020 1:53 AM
> To: Lijun Zhao <lijun.zhao at adelaide.edu.au>
> Cc: r-help at r-project.org
> Subject: Re: [R] How to index the occasions in a vector repeatedly under
> condition 1? if not, it will give a new index.
> 
> Use cumsum(logicalVector) to increment a counter at the TRUE positions in
> logicalVector. .  E.g.,
> 
> > d <- c(NA, 0, 0, 0, 8, 0, 577, 69, 0)
> > is_true <- function(x) !is.na<http://is.na>(x) & x
> > 1 + cumsum( is_true(d >= 15) )
> [1] 1 1 1 1 1 1 2 3 3
> 
> Some packages have the equivalent of that is_true function, which maps
FALSE
> and NA to FALSE and TRUE to TRUE.  I don't think core R contains such a
> function.
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com<http://tibco.com>
> 
> 
> On Wed, Feb 19, 2020 at 7:08 AM Lijun Zhao
> <lijun.zhao at adelaide.edu.au<mailto:lijun.zhao at adelaide.edu.au>> wrote:
> Dear all,
> Could you please help me how to get the output as I described in the
following
> example?
> 
> x<-c(543,  543,  543,  543,  551 , 551 ,1128 ,1197, 1197)
> diff<-x-lag(x)
> diff
> [1]  NA   0   0   0   8   0 577  69   0
> 
> How to index the occasions in x repeatedly if the diff<15? if diff>=15, it
will give
> a new index.
> I want the output be like y.
> 
> y<-c(1,1,1,1,1,1,2,3,3)
> 
> Thank you so much,
> 
> Lijun Zhao (PhD Candidate)
> Nutrition and Metabolism
> Level 7 SAHMRI
> North Terrace
> Adelaide 5005
> Ph    : +61 8 8128 4898
> e-mail:
>
lijun.zhao at adelaide.edu.au<mailto:lijun.zhao at adelaide.edu.au><mailto:lijun.z
> hao at adelaide.edu.au<mailto:lijun.zhao at adelaide.edu.au>> or
> lijun.zhao at sahmri.com<mailto:lijun.zhao at sahmri.com><mailto:lijun.zhao at sa
> hmri.com<mailto:lijun.zhao at sahmri.com>>
> 
> 
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From pd@|gd @end|ng |rom gm@||@com  Fri Feb 21 10:46:16 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 21 Feb 2020 10:46:16 +0100
Subject: [R] How to index the occasions in a vector repeatedly under
 condition 1? if not, it will give a new index.
In-Reply-To: <ME4P282MB107903721DAF4F18F4AA975AD9130@ME4P282MB1079.AUSP282.PROD.OUTLOOK.COM>
References: <SYYP282MB108651F19CC21C2452DF2953D9100@SYYP282MB1086.AUSP282.PROD.OUTLOOK.COM>
 <CAF8bMcbNpEc8inm_bV8QXK5juyFG0NJep0u9=jtjp7XRZ2TufA@mail.gmail.com>
 <ME4P282MB107903721DAF4F18F4AA975AD9130@ME4P282MB1079.AUSP282.PROD.OUTLOOK.COM>
Message-ID: <F447EE43-A0E9-4764-812F-21BA13B20B73@gmail.com>

It has isTRUE, but that is not vectorized, and in fact explicitly tests length==1, so

> isTRUE(c(TRUE,FALSE,NA))
[1] FALSE
> isTRUE(c(TRUE,TRUE, TRUE)) # I thought I thaw a puddycat... ;-)
 [1] FALSE
> Vectorize(isTRUE)(c(TRUE,FALSE,NA))
[1]  TRUE FALSE FALSE

(The latter would be silly as an implementation of is_true, of course.)

-pd

> On 20 Feb 2020, at 04:20 , Lijun Zhao <lijun.zhao at adelaide.edu.au> wrote:
> 
> 
> Some packages have the equivalent of that is_true function, which maps FALSE and NA to FALSE and TRUE to TRUE.  I don't think core R contains such a function.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tr@xp|@yer @end|ng |rom gm@||@com  Fri Feb 21 13:17:59 2020
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Fri, 21 Feb 2020 13:17:59 +0100
Subject: [R] RegExpr: Help match quote inside a set
Message-ID: <CAGAA5bcG6Rx2FW9xVj1-EOh0nDQWT_ABiCPc8weZpuOmTTYUZw@mail.gmail.com>

Hi,

  I am trying to understand the different functions for working with
regular expression in R.
  However I get a strange result for one of experiments, which I need
help to understand.

First: I search for any of the characters .,;"- in the book emma
> length(grep("[.,;\"-]",janeaustenr::emma))
[1] 13110
And that is probably correct.

Second: I try to add ' to the set to search for:
> length(grep("[.,;\"-']",janeaustenr::emma))
[1] 12816

No warning or errors but fewer hits? Why?

Third: I try quoting the ' and probably now gets the correct result.
> length(grep("[.,;\"-\\']",janeaustenr::emma))
[1] 13433

But still what does grep("[.,;\"-']", janeaustenr::emma) exactly?

Regards
Martin

sorry for the html. It is not possible to remove it complete in gmail.


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Feb 21 13:27:52 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 21 Feb 2020 15:27:52 +0300
Subject: [R] RegExpr: Help match quote inside a set
In-Reply-To: <CAGAA5bcG6Rx2FW9xVj1-EOh0nDQWT_ABiCPc8weZpuOmTTYUZw@mail.gmail.com>
References: <CAGAA5bcG6Rx2FW9xVj1-EOh0nDQWT_ABiCPc8weZpuOmTTYUZw@mail.gmail.com>
Message-ID: <20200221152752.727abc07@trisector>

On Fri, 21 Feb 2020 13:17:59 +0100
Martin M?ller Skarbiniks Pedersen <traxplayer at gmail.com> wrote:

> "[.,;\"-']"

Note that there is an - between " and ', which transforms your
regular expression into a range (all characters between " and ')
instead of a set. Move the - right in front of the closing bracket ] to
make it match a literal - again.

> sorry for the html.

By the way, you managed to switch this e-mail to plain text instead of
HTML.

-- 
Best regards,
Ivan


From bgunter@4567 @end|ng |rom gm@||@com  Fri Feb 21 16:28:10 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 21 Feb 2020 07:28:10 -0800
Subject: [R] RegExpr: Help match quote inside a set
In-Reply-To: <20200221152752.727abc07@trisector>
References: <CAGAA5bcG6Rx2FW9xVj1-EOh0nDQWT_ABiCPc8weZpuOmTTYUZw@mail.gmail.com>
 <20200221152752.727abc07@trisector>
Message-ID: <CAGxFJbSeea969rfnENQZOSPcv5qGViPWEYrqUThVR_OkvKp53A@mail.gmail.com>

Yes. From ?regex
"A range of characters may be specified by giving the first and last
characters, separated by a hyphen. (Because their interpretation is locale-
and implementation-dependent, character ranges are best avoided.) "

Although it is terse, if you have not already done so, you should read
?regex carefully. I'm a dummy but have found it very helpful.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Feb 21, 2020 at 4:28 AM Ivan Krylov <krylov.r00t at gmail.com> wrote:

> On Fri, 21 Feb 2020 13:17:59 +0100
> Martin M?ller Skarbiniks Pedersen <traxplayer at gmail.com> wrote:
>
> > "[.,;\"-']"
>
> Note that there is an - between " and ', which transforms your
> regular expression into a range (all characters between " and ')
> instead of a set. Move the - right in front of the closing bracket ] to
> make it match a literal - again.
>
> > sorry for the html.
>
> By the way, you managed to switch this e-mail to plain text instead of
> HTML.
>
> --
> Best regards,
> Ivan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @ubh@@hbeer|@etty @end|ng |rom gm@||@com  Fri Feb 21 16:18:23 2020
From: @ubh@@hbeer|@etty @end|ng |rom gm@||@com (Subhashini Rao Beerisetty)
Date: Fri, 21 Feb 2020 20:48:23 +0530
Subject: [R] polynomial regression
Message-ID: <CAPY=qRTe7CLpVyCBDcxQqpQ-Rx8OvazYikKqGnF-s_Lus=kHTw@mail.gmail.com>

[ Please keep me in CC as I'm not subscribed to the list]

Hi all,

I?m new to R programming.

Can someone help me , how to plot the ?y? for the following equations in ?R??

?= ??5(??0.3)2+0.5 ??100(??0.5)2+0.5 ??100(??0.75)2

?=28??+10?4?5?9+6?11

Also, I want to extract 50 random points from the function and add
normally distributed noise to the data points to get ?noisy data?,
??.  How to achieve this?

Is there a function to fit polynomial of degree 5 to the noisy data?


Thanks,


From bgunter@4567 @end|ng |rom gm@||@com  Fri Feb 21 18:08:53 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 21 Feb 2020 09:08:53 -0800
Subject: [R] polynomial regression
In-Reply-To: <CAPY=qRTe7CLpVyCBDcxQqpQ-Rx8OvazYikKqGnF-s_Lus=kHTw@mail.gmail.com>
References: <CAPY=qRTe7CLpVyCBDcxQqpQ-Rx8OvazYikKqGnF-s_Lus=kHTw@mail.gmail.com>
Message-ID: <CAGxFJbTi+MO3pn+80FiQQ6NNkOWvDyn4xASpMbvinUcN-nJQtg@mail.gmail.com>

This looks like homework. This list has a *no homework* policy.

There are extensive R tutorials on the web (and even the Intro to R shipped
with the distro). Study them before asking us to do your work for you. See
the posting guide linked below for what is expected of posters here.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Feb 21, 2020 at 8:51 AM Subhashini Rao Beerisetty <
subhashbeerisetty at gmail.com> wrote:

> [ Please keep me in CC as I'm not subscribed to the list]
>
> Hi all,
>
> I?m new to R programming.
>
> Can someone help me , how to plot the ?y? for the following equations in
> ?R??
>
> ?= ??5(??0.3)2+0.5 ??100(??0.5)2+0.5 ??100(??0.75)2
>
> ?=28??+10?4?5?9+6?11
>
> Also, I want to extract 50 random points from the function and add
> normally distributed noise to the data points to get ?noisy data?,
> ??.  How to achieve this?
>
> Is there a function to fit polynomial of degree 5 to the noisy data?
>
>
> Thanks,
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Feb 21 18:10:48 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 21 Feb 2020 09:10:48 -0800
Subject: [R] polynomial regression
In-Reply-To: <CAGxFJbTi+MO3pn+80FiQQ6NNkOWvDyn4xASpMbvinUcN-nJQtg@mail.gmail.com>
References: <CAPY=qRTe7CLpVyCBDcxQqpQ-Rx8OvazYikKqGnF-s_Lus=kHTw@mail.gmail.com>
 <CAGxFJbTi+MO3pn+80FiQQ6NNkOWvDyn4xASpMbvinUcN-nJQtg@mail.gmail.com>
Message-ID: <CAGxFJbRsgmqwoZFmM_M9R9E-GtHq2ZTnoSAnvJEBDiUae_XJQw@mail.gmail.com>

Oh ... and don't cross post.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Feb 21, 2020 at 9:08 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> This looks like homework. This list has a *no homework* policy.
>
> There are extensive R tutorials on the web (and even the Intro to R
> shipped with the distro). Study them before asking us to do your work for
> you. See the posting guide linked below for what is expected of posters
> here.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Feb 21, 2020 at 8:51 AM Subhashini Rao Beerisetty <
> subhashbeerisetty at gmail.com> wrote:
>
>> [ Please keep me in CC as I'm not subscribed to the list]
>>
>> Hi all,
>>
>> I?m new to R programming.
>>
>> Can someone help me , how to plot the ?y? for the following equations in
>> ?R??
>>
>> ?= ??5(??0.3)2+0.5 ??100(??0.5)2+0.5 ??100(??0.75)2
>>
>> ?=28??+10?4?5?9+6?11
>>
>> Also, I want to extract 50 random points from the function and add
>> normally distributed noise to the data points to get ?noisy data?,
>> ??.  How to achieve this?
>>
>> Is there a function to fit polynomial of degree 5 to the noisy data?
>>
>>
>> Thanks,
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Feb 21 18:16:26 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 21 Feb 2020 09:16:26 -0800
Subject: [R] polynomial regression
In-Reply-To: <CAPY=qRTe7CLpVyCBDcxQqpQ-Rx8OvazYikKqGnF-s_Lus=kHTw@mail.gmail.com>
References: <CAPY=qRTe7CLpVyCBDcxQqpQ-Rx8OvazYikKqGnF-s_Lus=kHTw@mail.gmail.com>
Message-ID: <FD2442A7-0646-4D76-90F5-9035E883FC25@dcn.davis.ca.us>

This looks like homework. There is a clearly-stated no-homework policy in the Posting Guide.

Some hints though (typing a question mark before a function name in the console shows the help file for that function):

- Generate some x values (?seq)
- Calculate y values using x
- plot x against y (?plot)
- fitting can be done many ways, but the most common is using the ?lm function to fit and the ?predict.lm function to obtain points on the fitted equation.


On February 21, 2020 7:18:23 AM PST, Subhashini Rao Beerisetty <subhashbeerisetty at gmail.com> wrote:
>[ Please keep me in CC as I'm not subscribed to the list]
>
>Hi all,
>
>I?m new to R programming.
>
>Can someone help me , how to plot the ?y? for the following equations
>in ?R??
>
>?= ??5(??0.3)2+0.5 ??100(??0.5)2+0.5 ??100(??0.75)2
>
>?=28??+10?4?5?9+6?11
>
>Also, I want to extract 50 random points from the function and add
>normally distributed noise to the data points to get ?noisy data?,
>??.  How to achieve this?
>
>Is there a function to fit polynomial of degree 5 to the noisy data?
>
>
>Thanks,
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From wdun|@p @end|ng |rom t|bco@com  Fri Feb 21 18:25:43 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 21 Feb 2020 09:25:43 -0800
Subject: [R] How to index the occasions in a vector repeatedly under
 condition 1? if not, it will give a new index.
In-Reply-To: <ME4P282MB107903721DAF4F18F4AA975AD9130@ME4P282MB1079.AUSP282.PROD.OUTLOOK.COM>
References: <SYYP282MB108651F19CC21C2452DF2953D9100@SYYP282MB1086.AUSP282.PROD.OUTLOOK.COM>
 <CAF8bMcbNpEc8inm_bV8QXK5juyFG0NJep0u9=jtjp7XRZ2TufA@mail.gmail.com>
 <ME4P282MB107903721DAF4F18F4AA975AD9130@ME4P282MB1079.AUSP282.PROD.OUTLOOK.COM>
Message-ID: <CAF8bMcZp_GF3N0zYBuKtiA2Eops+prnQdkYCek=+Dujph4EA=g@mail.gmail.com>

> all.equal(y, ave(d, cumsum(c(TRUE,is_true(diff(a)!=0))),
FUN=function(di)1L+cumsum(is_true(di>15))))
[1] TRUE

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Feb 19, 2020 at 7:20 PM Lijun Zhao <lijun.zhao at adelaide.edu.au>
wrote:

> Dear William,
>
> Thank you so much.
>
>
>
> I am quiet new in R. I would like to do this based on another repeated
> variables.
>
>
>
> For example:
>
> a<-c(1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2)
>
> d<-c(NA, 0, 0, 0, 8, 0, 577, 69, 0, NA, 0, 0, 0, 8, 0, 577, 69, 0)
>
> the outcome I want is :
>
> y<-c(1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1, 1 ,1, 1 ,1, 2, 3, 3)
>
>
>
> Therefore, I would like to create y based on the variable a. once variable
> a has changed, the index will start from 1 again. I wrote a for loop, but
> it did not give me what I want. Could you please help me again?
>
>
>
> Thanks in advance,
>
>
>
> Lijun
>
>
>
>
>
>
>
> *From:* William Dunlap <wdunlap at tibco.com>
> *Sent:* Thursday, 20 February 2020 1:53 AM
> *To:* Lijun Zhao <lijun.zhao at adelaide.edu.au>
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] How to index the occasions in a vector repeatedly
> under condition 1? if not, it will give a new index.
>
>
>
> Use cumsum(logicalVector) to increment a counter at the TRUE positions in
> logicalVector. .  E.g.,
>
>
>
> > d <- c(NA, 0, 0, 0, 8, 0, 577, 69, 0)
>
> > is_true <- function(x) !is.na(x) & x
> > 1 + cumsum( is_true(d >= 15) )
> [1] 1 1 1 1 1 1 2 3 3
>
>
>
> Some packages have the equivalent of that is_true function, which maps
> FALSE and NA to FALSE and TRUE to TRUE.  I don't think core R contains such
> a function.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
>
>
>
> On Wed, Feb 19, 2020 at 7:08 AM Lijun Zhao <lijun.zhao at adelaide.edu.au>
> wrote:
>
> Dear all,
> Could you please help me how to get the output as I described in the
> following example?
>
> x<-c(543,  543,  543,  543,  551 , 551 ,1128 ,1197, 1197)
> diff<-x-lag(x)
> diff
> [1]  NA   0   0   0   8   0 577  69   0
>
> How to index the occasions in x repeatedly if the diff<15? if diff>=15, it
> will give a new index.
> I want the output be like y.
>
> y<-c(1,1,1,1,1,1,2,3,3)
>
> Thank you so much,
>
> Lijun Zhao (PhD Candidate)
> Nutrition and Metabolism
> Level 7 SAHMRI
> North Terrace
> Adelaide 5005
> Ph    : +61 8 8128 4898
> e-mail: lijun.zhao at adelaide.edu.au<mailto:lijun.zhao at adelaide.edu.au> or
> lijun.zhao at sahmri.com<mailto:lijun.zhao at sahmri.com>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From cry@n @end|ng |rom b|ngh@mton@edu  Fri Feb 21 20:10:16 2020
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W. Ryan)
Date: Fri, 21 Feb 2020 14:10:16 -0500
Subject: [R] incomplete reading of a large csv file
Message-ID: <80d5b3ec-abce-049b-1cd2-cfdeefdadb8a@binghamton.edu>

sessionInfo at end of message.

I have data that I was given as an Excel .xlsx file. It contains 96266
lines and 24 columns. I opened it in OpenOffice.org and saved it in .csv
format, using the pipe character as a field separator. This produced a
file with 96266 lines.

When I read it into R thusly:

> skip0.dd <- read.csv("AmbulanceDispatches2017-2019-02-18-2020.csv",
sep = "|", header = TRUE, comment.char = "", skip = 0)

the resulting skip0.dd dataframe has only 58208 lines:

> dim(skip0.dd)
[1] 58208    24


I've tried a variety of things to troubleshoot. Using head() and tail(),
the expected first and last lines (comparing to the .csv file) do indeed
exist in skip0.dd.  Several arbitrary lines from the "middle" of the csv
file are also present in the skip0.dd dataframe.

I tried reading only the first column, which is integer, but still it
appears that not all lines are read in:

> classes <- c(NA, rep("NULL", 23))
> skip01.dd <- read.csv("AmbulanceDispatches2017-2019-02-18-2020.csv",
sep = "|", header = TRUE, comment.char = "", skip = 0, colClasses = classes)
> dim(skip01.dd)
[1] 58208    1

Skipping the first 50000 lines nominally should give me a dataframe of
46266 lines, or at least one of 50000 fewer lines than skip0.dd (i.e.
8208 lines), but it does neither:

> skip50000.dd <-
read.csv("AmbulanceDispatches2017-2019-02-18-2020.csv", sep = "|",
header = TRUE, comment.char = "", skip = 50000)
> dim(skip50000.dd)
[1] 22170    24

Any thoughts on what might be going wrong? Some funky characters from
Excel or OpenOffice.org lurking in the .csv file?

Perhaps I'd have more success with one of the packages that enables
reading directly from an .xlsx file.

Thanks.

--Chris Ryan
SUNY Upstate Medical University Binghamton Clinical Campus
Broome County Health Department
Binghamton University


####################################
> sessionInfo()
R version 3.5.3 (2019-03-11)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 17763)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] dplyr_0.8.3       stringr_1.4.0     Hmisc_4.2-0       ggplot2_3.2.1
[5] Formula_1.2-3     survival_2.44-1.1 lattice_0.20-38

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.1          pillar_1.4.0        compiler_3.5.3
 [4] RColorBrewer_1.1-2  tools_3.5.3         base64enc_0.1-3
 [7] digest_0.6.18       zeallot_0.1.0       rpart_4.1-13
[10] checkmate_1.9.3     tibble_2.1.1        gtable_0.3.0
[13] htmlTable_1.13.1    pkgconfig_2.0.2     rlang_0.4.0
[16] Matrix_1.2-15       rstudioapi_0.10     xfun_0.7
[19] gridExtra_2.3       knitr_1.23          withr_2.1.2
[22] cluster_2.0.7-1     htmlwidgets_1.3     vctrs_0.2.0
[25] grid_3.5.3          nnet_7.3-12         tidyselect_0.2.5
[28] data.table_1.12.2   glue_1.3.1          R6_2.4.0
[31] foreign_0.8-71      latticeExtra_0.6-28 purrr_0.3.2
[34] magrittr_1.5        htmltools_0.3.6     backports_1.1.4
[37] scales_1.0.0        splines_3.5.3       assertthat_0.2.1
[40] colorspace_1.4-1    stringi_1.4.3       acepack_1.4.1
[43] lazyeval_0.2.2      munsell_0.5.0       crayon_1.3.4


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Fri Feb 21 20:16:45 2020
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Fri, 21 Feb 2020 20:16:45 +0100
Subject: [R] incomplete reading of a large csv file
In-Reply-To: <80d5b3ec-abce-049b-1cd2-cfdeefdadb8a@binghamton.edu>
References: <80d5b3ec-abce-049b-1cd2-cfdeefdadb8a@binghamton.edu>
Message-ID: <6bbebc26-c4ce-9e0e-60d7-20157ac09d0a@statistik.tu-dortmund.de>



On 21.02.2020 20:10, Christopher W. Ryan wrote:
> sessionInfo at end of message.
> 
> I have data that I was given as an Excel .xlsx file. It contains 96266
> lines and 24 columns. I opened it in OpenOffice.org and saved it in .csv
> format, using the pipe character as a field separator. This produced a
> file with 96266 lines.
> 
> When I read it into R thusly:
> 
>> skip0.dd <- read.csv("AmbulanceDispatches2017-2019-02-18-2020.csv",
> sep = "|", header = TRUE, comment.char = "", skip = 0)
> 
> the resulting skip0.dd dataframe has only 58208 lines:
> 
>> dim(skip0.dd)
> [1] 58208    24
> 
> 
> I've tried a variety of things to troubleshoot. Using head() and tail(),
> the expected first and last lines (comparing to the .csv file) do indeed
> exist in skip0.dd.  Several arbitrary lines from the "middle" of the csv
> file are also present in the skip0.dd dataframe.
> 
> I tried reading only the first column, which is integer, but still it
> appears that not all lines are read in:
> 
>> classes <- c(NA, rep("NULL", 23))
>> skip01.dd <- read.csv("AmbulanceDispatches2017-2019-02-18-2020.csv",
> sep = "|", header = TRUE, comment.char = "", skip = 0, colClasses = classes)
>> dim(skip01.dd)
> [1] 58208    1
> 
> Skipping the first 50000 lines nominally should give me a dataframe of
> 46266 lines, or at least one of 50000 fewer lines than skip0.dd (i.e.
> 8208 lines), but it does neither:
> 
>> skip50000.dd <-
> read.csv("AmbulanceDispatches2017-2019-02-18-2020.csv", sep = "|",
> header = TRUE, comment.char = "", skip = 50000)
>> dim(skip50000.dd)
> [1] 22170    24
> 
> Any thoughts on what might be going wrong? Some funky characters from
> Excel or OpenOffice.org lurking in the .csv file?

quotes are a typical proiblem, what if you try with arg quote=""?




> 
> Perhaps I'd have more success with one of the packages that enables
> reading directly from an .xlsx file.
> 
> Thanks.
> 
> --Chris Ryan
> SUNY Upstate Medical University Binghamton Clinical Campus
> Broome County Health Department
> Binghamton University
> 
> 
> ####################################
>> sessionInfo()
> R version 3.5.3 (2019-03-11)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 17763)
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] dplyr_0.8.3       stringr_1.4.0     Hmisc_4.2-0       ggplot2_3.2.1
> [5] Formula_1.2-3     survival_2.44-1.1 lattice_0.20-38
> 
> loaded via a namespace (and not attached):
>   [1] Rcpp_1.0.1          pillar_1.4.0        compiler_3.5.3
>   [4] RColorBrewer_1.1-2  tools_3.5.3         base64enc_0.1-3
>   [7] digest_0.6.18       zeallot_0.1.0       rpart_4.1-13
> [10] checkmate_1.9.3     tibble_2.1.1        gtable_0.3.0
> [13] htmlTable_1.13.1    pkgconfig_2.0.2     rlang_0.4.0
> [16] Matrix_1.2-15       rstudioapi_0.10     xfun_0.7
> [19] gridExtra_2.3       knitr_1.23          withr_2.1.2
> [22] cluster_2.0.7-1     htmlwidgets_1.3     vctrs_0.2.0
> [25] grid_3.5.3          nnet_7.3-12         tidyselect_0.2.5
> [28] data.table_1.12.2   glue_1.3.1          R6_2.4.0
> [31] foreign_0.8-71      latticeExtra_0.6-28 purrr_0.3.2
> [34] magrittr_1.5        htmltools_0.3.6     backports_1.1.4
> [37] scales_1.0.0        splines_3.5.3       assertthat_0.2.1
> [40] colorspace_1.4-1    stringi_1.4.3       acepack_1.4.1
> [43] lazyeval_0.2.2      munsell_0.5.0       crayon_1.3.4
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From cry@n @end|ng |rom b|ngh@mton@edu  Fri Feb 21 20:25:57 2020
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W. Ryan)
Date: Fri, 21 Feb 2020 14:25:57 -0500
Subject: [R] 
 [External Email] Re:  incomplete reading of a large csv file
In-Reply-To: <6bbebc26-c4ce-9e0e-60d7-20157ac09d0a@statistik.tu-dortmund.de>
References: <80d5b3ec-abce-049b-1cd2-cfdeefdadb8a@binghamton.edu>
 <6bbebc26-c4ce-9e0e-60d7-20157ac09d0a@statistik.tu-dortmund.de>
Message-ID: <40fbe6c2-e56a-ec49-2e09-19dc58e62e03@binghamton.edu>

Ah, Uwe, you are a lifesaver. Although there should not have been, there
were some lines with entries like this in the 6th field:

medical alarm - unk problem                                   "B"

I would have thought that my effort to read just the first field of each
line, uniformly an integer, would have neutralized any issues arising
from problematic characters in other fields. Apparently not. So the
entire file is processed in some manner, even when using the colClasses
argument to restrict the result to the first column?

Thanks.

--Chris Ryan


Uwe Ligges wrote:
> 
> 
> On 21.02.2020 20:10, Christopher W. Ryan wrote:
>> sessionInfo at end of message.
>>
>> I have data that I was given as an Excel .xlsx file. It contains 96266
>> lines and 24 columns. I opened it in OpenOffice.org and saved it in .csv
>> format, using the pipe character as a field separator. This produced a
>> file with 96266 lines.
>>
>> When I read it into R thusly:
>>
>>> skip0.dd <- read.csv("AmbulanceDispatches2017-2019-02-18-2020.csv",
>> sep = "|", header = TRUE, comment.char = "", skip = 0)
>>
>> the resulting skip0.dd dataframe has only 58208 lines:
>>
>>> dim(skip0.dd)
>> [1] 58208??? 24
>>
>>
>> I've tried a variety of things to troubleshoot. Using head() and tail(),
>> the expected first and last lines (comparing to the .csv file) do indeed
>> exist in skip0.dd.? Several arbitrary lines from the "middle" of the csv
>> file are also present in the skip0.dd dataframe.
>>
>> I tried reading only the first column, which is integer, but still it
>> appears that not all lines are read in:
>>
>>> classes <- c(NA, rep("NULL", 23))
>>> skip01.dd <- read.csv("AmbulanceDispatches2017-2019-02-18-2020.csv",
>> sep = "|", header = TRUE, comment.char = "", skip = 0, colClasses =
>> classes)
>>> dim(skip01.dd)
>> [1] 58208??? 1
>>
>> Skipping the first 50000 lines nominally should give me a dataframe of
>> 46266 lines, or at least one of 50000 fewer lines than skip0.dd (i.e.
>> 8208 lines), but it does neither:
>>
>>> skip50000.dd <-
>> read.csv("AmbulanceDispatches2017-2019-02-18-2020.csv", sep = "|",
>> header = TRUE, comment.char = "", skip = 50000)
>>> dim(skip50000.dd)
>> [1] 22170??? 24
>>
>> Any thoughts on what might be going wrong? Some funky characters from
>> Excel or OpenOffice.org lurking in the .csv file?
> 
> quotes are a typical proiblem, what if you try with arg quote=""?
> 
> 
> 
> 
>>
>> Perhaps I'd have more success with one of the packages that enables
>> reading directly from an .xlsx file.
>>
>> Thanks.
>>
>> --Chris Ryan
>> SUNY Upstate Medical University Binghamton Clinical Campus
>> Broome County Health Department
>> Binghamton University
>>
>>
>> ####################################
>>> sessionInfo()
>> R version 3.5.3 (2019-03-11)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 10 x64 (build 17763)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats???? graphics? grDevices utils???? datasets? methods?? base
>>
>> other attached packages:
>> [1] dplyr_0.8.3?????? stringr_1.4.0???? Hmisc_4.2-0?????? ggplot2_3.2.1
>> [5] Formula_1.2-3???? survival_2.44-1.1 lattice_0.20-38
>>
>> loaded via a namespace (and not attached):
>> ? [1] Rcpp_1.0.1????????? pillar_1.4.0??????? compiler_3.5.3
>> ? [4] RColorBrewer_1.1-2? tools_3.5.3???????? base64enc_0.1-3
>> ? [7] digest_0.6.18?????? zeallot_0.1.0?????? rpart_4.1-13
>> [10] checkmate_1.9.3???? tibble_2.1.1??????? gtable_0.3.0
>> [13] htmlTable_1.13.1??? pkgconfig_2.0.2???? rlang_0.4.0
>> [16] Matrix_1.2-15?????? rstudioapi_0.10???? xfun_0.7
>> [19] gridExtra_2.3?????? knitr_1.23????????? withr_2.1.2
>> [22] cluster_2.0.7-1???? htmlwidgets_1.3???? vctrs_0.2.0
>> [25] grid_3.5.3????????? nnet_7.3-12???????? tidyselect_0.2.5
>> [28] data.table_1.12.2?? glue_1.3.1????????? R6_2.4.0
>> [31] foreign_0.8-71????? latticeExtra_0.6-28 purrr_0.3.2
>> [34] magrittr_1.5??????? htmltools_0.3.6???? backports_1.1.4
>> [37] scales_1.0.0??????? splines_3.5.3?????? assertthat_0.2.1
>> [40] colorspace_1.4-1??? stringi_1.4.3?????? acepack_1.4.1
>> [43] lazyeval_0.2.2????? munsell_0.5.0?????? crayon_1.3.4
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From bob @end|ng |rom rud@|@  Sat Feb 22 14:23:31 2020
From: bob @end|ng |rom rud@|@ (Bob Rudis)
Date: Sat, 22 Feb 2020 08:23:31 -0500
Subject: [R] Package httr::GET() question
In-Reply-To: <F9967587-A1FC-43D4-9365-944D59E8EA77@noaa.gov>
References: <EFC2C1C8-5B1C-4543-96DE-6E61CBF7F304@noaa.gov>
 <CALrbzg1duMq4u60tRxxSkToVkLWEcL+BOHHsUv762=SPiX4=jg@mail.gmail.com>
 <F9967587-A1FC-43D4-9365-944D59E8EA77@noaa.gov>
Message-ID: <CAA-FpKUG+bXeSrpayC7Csps3ZcDmCWEUZVLFi8Wz_xtumMA7Xg@mail.gmail.com>

curl::curl_escape() ?
https://github.com/jeroen/curl/search?q=curl_escape&unscoped_q=curl_escape
? uses the underlying libcurl curl_easy_escape() which does proper
escaping b/c it's, well, curl.

{httr} uses curl::curl_escape() ?
https://github.com/r-lib/httr/search?q=curl_escape&unscoped_q=curl_escape

The use it's `url-query.r` is the function compose_query().

compose_query()  is called from build_url() in url.r. handle_url()
(from handle-url.r) uses build_url().

All the "verbs" use handle_url() ?
https://github.com/r-lib/httr/search?q=handle_url&unscoped_q=handle_url

So {httr} relies on the quintessential standard in URL escaping ?
which is libcurl's ? for all URL machinations.

-boB

On Wed, Feb 19, 2020 at 10:36 AM Roy Mendelssohn - NOAA Federal via
R-help <r-help at r-project.org> wrote:
>
> Thanks.  Yes.  I did that,  it also has a verbose mode so that I could see what it was doing.  What I needed was not just escaping but strict escaping.  My memory forma number of years back was that I had issues with urlencode from base not being strict.  And of course you don't what to encode twice.
>
> Thanks,
>
> -Roy
>
>
> > On Feb 19, 2020, at 7:08 AM, Ben Tupper <btupper at bigelow.org> wrote:
> >
> > Hi,
> >
> > Perhaps you could test it out by using httr::GET() with and without
> > escaping using xml2::url_escape()?
> >
> > https://www.rdocumentation.org/packages/xml2/versions/1.2.2/topics/url_escape
> >
> > Cheers,
> > Ben
> >
> > On Tue, Feb 18, 2020 at 1:29 PM Roy Mendelssohn - NOAA Federal via
> > R-help <r-help at r-project.org> wrote:
> >>
> >> Hi All:
> >>
> >> I hav been trying to go through the code for httr::GET() but it is somewhat beyond what I know.  What I am trying to find out is if all urls are automatically percent encoded,  or whether the user needs to do that.
> >>
> >> Thanks,
> >>
> >> -Roy
> >>
> >> **********************
> >> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> >> **********************
> >> Roy Mendelssohn
> >> Supervisory Operations Research Analyst
> >> NOAA/NMFS
> >> Environmental Research Division
> >> Southwest Fisheries Science Center
> >> ***Note new street address***
> >> 110 McAllister Way
> >> Santa Cruz, CA 95060
> >> Phone: (831)-420-3666
> >> Fax: (831) 420-3980
> >> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
> >>
> >> "Old age and treachery will overcome youth and skill."
> >> "From those who have been given much, much will be expected"
> >> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Ben Tupper
> > Bigelow Laboratory for Ocean Science
> > West Boothbay Harbor, Maine
> > http://www.bigelow.org/
> > https://eco.bigelow.org
>
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roy@mende|@@ohn @end|ng |rom no@@@gov  Sat Feb 22 17:38:41 2020
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Sat, 22 Feb 2020 08:38:41 -0800
Subject: [R] Package httr::GET() question
In-Reply-To: <CAA-FpKUG+bXeSrpayC7Csps3ZcDmCWEUZVLFi8Wz_xtumMA7Xg@mail.gmail.com>
References: <EFC2C1C8-5B1C-4543-96DE-6E61CBF7F304@noaa.gov>
 <CALrbzg1duMq4u60tRxxSkToVkLWEcL+BOHHsUv762=SPiX4=jg@mail.gmail.com>
 <F9967587-A1FC-43D4-9365-944D59E8EA77@noaa.gov>
 <CAA-FpKUG+bXeSrpayC7Csps3ZcDmCWEUZVLFi8Wz_xtumMA7Xg@mail.gmail.com>
Message-ID: <09121AEF-4249-4EA8-AD59-6015DE747DCB@noaa.gov>

Thanks.  Yes that is what I found out.  We are switching our web service to require strict encoding  (a lot of services got caught when Apache Tomcat made a similar switch)  and are trying to see if it that will break any of our R packages before we make the switch,

As always,  appreciate all the people who took time to respond.

-Roy
> On Feb 22, 2020, at 5:23 AM, Bob Rudis <bob at rud.is> wrote:
> 
> curl::curl_escape() ?
> https://github.com/jeroen/curl/search?q=curl_escape&unscoped_q=curl_escape
> ? uses the underlying libcurl curl_easy_escape() which does proper
> escaping b/c it's, well, curl.
> 
> {httr} uses curl::curl_escape() ?
> https://github.com/r-lib/httr/search?q=curl_escape&unscoped_q=curl_escape
> 
> The use it's `url-query.r` is the function compose_query().
> 
> compose_query()  is called from build_url() in url.r. handle_url()
> (from handle-url.r) uses build_url().
> 
> All the "verbs" use handle_url() ?
> https://github.com/r-lib/httr/search?q=handle_url&unscoped_q=handle_url
> 
> So {httr} relies on the quintessential standard in URL escaping ?
> which is libcurl's ? for all URL machinations.
> 
> -boB
> 
> On Wed, Feb 19, 2020 at 10:36 AM Roy Mendelssohn - NOAA Federal via
> R-help <r-help at r-project.org> wrote:
>> 
>> Thanks.  Yes.  I did that,  it also has a verbose mode so that I could see what it was doing.  What I needed was not just escaping but strict escaping.  My memory forma number of years back was that I had issues with urlencode from base not being strict.  And of course you don't what to encode twice.
>> 
>> Thanks,
>> 
>> -Roy
>> 
>> 
>>> On Feb 19, 2020, at 7:08 AM, Ben Tupper <btupper at bigelow.org> wrote:
>>> 
>>> Hi,
>>> 
>>> Perhaps you could test it out by using httr::GET() with and without
>>> escaping using xml2::url_escape()?
>>> 
>>> https://www.rdocumentation.org/packages/xml2/versions/1.2.2/topics/url_escape
>>> 
>>> Cheers,
>>> Ben
>>> 
>>> On Tue, Feb 18, 2020 at 1:29 PM Roy Mendelssohn - NOAA Federal via
>>> R-help <r-help at r-project.org> wrote:
>>>> 
>>>> Hi All:
>>>> 
>>>> I hav been trying to go through the code for httr::GET() but it is somewhat beyond what I know.  What I am trying to find out is if all urls are automatically percent encoded,  or whether the user needs to do that.
>>>> 
>>>> Thanks,
>>>> 
>>>> -Roy
>>>> 
>>>> **********************
>>>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>>>> **********************
>>>> Roy Mendelssohn
>>>> Supervisory Operations Research Analyst
>>>> NOAA/NMFS
>>>> Environmental Research Division
>>>> Southwest Fisheries Science Center
>>>> ***Note new street address***
>>>> 110 McAllister Way
>>>> Santa Cruz, CA 95060
>>>> Phone: (831)-420-3666
>>>> Fax: (831) 420-3980
>>>> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
>>>> 
>>>> "Old age and treachery will overcome youth and skill."
>>>> "From those who have been given much, much will be expected"
>>>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>> --
>>> Ben Tupper
>>> Bigelow Laboratory for Ocean Science
>>> West Boothbay Harbor, Maine
>>> http://www.bigelow.org/
>>> https://eco.bigelow.org
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new street address***
>> 110 McAllister Way
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
>> 
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From beno|t@v@|||@nt @end|ng |rom no-|og@org  Fri Feb 21 18:02:01 2020
From: beno|t@v@|||@nt @end|ng |rom no-|og@org (Benoit Vaillant)
Date: Fri, 21 Feb 2020 18:02:01 +0100
Subject: [R] RegExpr: Help match quote inside a set
In-Reply-To: <CAGxFJbSeea969rfnENQZOSPcv5qGViPWEYrqUThVR_OkvKp53A@mail.gmail.com>
References: <CAGAA5bcG6Rx2FW9xVj1-EOh0nDQWT_ABiCPc8weZpuOmTTYUZw@mail.gmail.com>
 <20200221152752.727abc07@trisector>
 <CAGxFJbSeea969rfnENQZOSPcv5qGViPWEYrqUThVR_OkvKp53A@mail.gmail.com>
Message-ID: <20200221170201.jgmldpmjbl2t3ffu-5002@auroras.fr>

Hi,

On Fri, Feb 21, 2020 at 07:28:10AM -0800, Bert Gunter wrote:
> Yes. From ?regex
> "A range of characters may be specified by giving the first and last
> characters, separated by a hyphen. (Because their interpretation is locale-
> and implementation-dependent, character ranges are best avoided.) "
> 
> Although it is terse, if you have not already done so, you should read
> ?regex carefully. I'm a dummy but have found it very helpful.

Is this what you -mean-?
https://xkcd.com/1171/

;)

-- 
Beno?t

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 866 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200221/b62b57c3/attachment.sig>

From m@k@hho||y @end|ng |rom gm@||@com  Sat Feb 22 23:42:22 2020
From: m@k@hho||y @end|ng |rom gm@||@com (greg holly)
Date: Sat, 22 Feb 2020 16:42:22 -0600
Subject: [R] Error: cannot allocate vector of size 6.5 Gb
Message-ID: <CAM9Qe4gJ2_fkoi08PtUMhZ2q7ETXEHJRZW-wXu=nNpuwKpY-hg@mail.gmail.com>

Dear R-Help members;

I have the following error messages when I would like to create
training and testing data for Random Forest.

Your help is highly appreciated.

Regards,
Greg

inTrain <- createDataPartition(a, p = 0.7, list = FALSE)
Error: cannot allocate vector of size 6.5 Gb

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Feb 23 00:21:12 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 23 Feb 2020 12:21:12 +1300
Subject: [R] [FORGED]  Error: cannot allocate vector of size 6.5 Gb
In-Reply-To: <CAM9Qe4gJ2_fkoi08PtUMhZ2q7ETXEHJRZW-wXu=nNpuwKpY-hg@mail.gmail.com>
References: <CAM9Qe4gJ2_fkoi08PtUMhZ2q7ETXEHJRZW-wXu=nNpuwKpY-hg@mail.gmail.com>
Message-ID: <1f4088f0-8592-16bf-ad80-25e3952c1ca0@auckland.ac.nz>


On 23/02/20 11:42 am, greg holly wrote:

> Dear R-Help members;
> 
> I have the following error messages when I would like to create
> training and testing data for Random Forest.
> 
> Your help is highly appreciated.
> 
> Regards,
> Greg
> 
> inTrain <- createDataPartition(a, p = 0.7, list = FALSE)
> Error: cannot allocate vector of size 6.5 Gb

What help do you want, exactly?  The error message seems pretty clear. 
Your data set "a" is such that trying to apply the function results in 
asking for more memory than can be allocated.

Without knowing something about "a" it is impossible to say more. 
Members of this list do not, as far as I know, have psychic powers.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ||jun@zh@o @end|ng |rom @de|@|de@edu@@u  Mon Feb 24 01:35:09 2020
From: ||jun@zh@o @end|ng |rom @de|@|de@edu@@u (Lijun Zhao)
Date: Mon, 24 Feb 2020 00:35:09 +0000
Subject: [R] How to index the occasions in a vector repeatedly under
 condition 1? if not, it will give a new index.
In-Reply-To: <F447EE43-A0E9-4764-812F-21BA13B20B73@gmail.com>
References: <SYYP282MB108651F19CC21C2452DF2953D9100@SYYP282MB1086.AUSP282.PROD.OUTLOOK.COM>
 <CAF8bMcbNpEc8inm_bV8QXK5juyFG0NJep0u9=jtjp7XRZ2TufA@mail.gmail.com>
 <ME4P282MB107903721DAF4F18F4AA975AD9130@ME4P282MB1079.AUSP282.PROD.OUTLOOK.COM>
 <F447EE43-A0E9-4764-812F-21BA13B20B73@gmail.com>
Message-ID: <ME4P282MB1079788E8CE57BD9197BBF1FD9EC0@ME4P282MB1079.AUSP282.PROD.OUTLOOK.COM>

Hi Peter,
Thank you so much.

Kind regards,

Lijun

-----Original Message-----
From: peter dalgaard <pdalgd at gmail.com>
Sent: Friday, 21 February 2020 8:16 PM
To: Lijun Zhao <lijun.zhao at adelaide.edu.au>
Cc: William Dunlap <wdunlap at tibco.com>; r-help at r-project.org
Subject: Re: [R] How to index the occasions in a vector repeatedly under condition 1? if not, it will give a new index.

It has isTRUE, but that is not vectorized, and in fact explicitly tests length==1, so

> isTRUE(c(TRUE,FALSE,NA))
[1] FALSE
> isTRUE(c(TRUE,TRUE, TRUE)) # I thought I thaw a puddycat... ;-)
 [1] FALSE
> Vectorize(isTRUE)(c(TRUE,FALSE,NA))
[1]  TRUE FALSE FALSE

(The latter would be silly as an implementation of is_true, of course.)

-pd

> On 20 Feb 2020, at 04:20 , Lijun Zhao <lijun.zhao at adelaide.edu.au> wrote:
>
>
> Some packages have the equivalent of that is_true function, which maps FALSE and NA to FALSE and TRUE to TRUE.  I don't think core R contains such a function.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From j@vedbtk111 @end|ng |rom gm@||@com  Mon Feb 24 12:35:31 2020
From: j@vedbtk111 @end|ng |rom gm@||@com (javed khan)
Date: Mon, 24 Feb 2020 12:35:31 +0100
Subject: [R] $ opetator is invalid for atomic vectors
Message-ID: <CAJhui+s3SE3qKVQYh+jMN6YKC8Lq+faBQ_gSwUf408fgTQJntg@mail.gmail.com>

Hello

I am using genetic algorithm for some optimization problem. I executed it
with 2 types of data and get results like

GA=40
GA2=60

When I combine it with resamples

Value=resamples (list (GA, GA2))

It gives me the error

$ operator is invalid for atomic vectors.

What should be the issue here?

Thanks

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Feb 24 14:03:47 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 24 Feb 2020 13:03:47 +0000
Subject: [R] $ opetator is invalid for atomic vectors
In-Reply-To: <CAJhui+s3SE3qKVQYh+jMN6YKC8Lq+faBQ_gSwUf408fgTQJntg@mail.gmail.com>
References: <CAJhui+s3SE3qKVQYh+jMN6YKC8Lq+faBQ_gSwUf408fgTQJntg@mail.gmail.com>
Message-ID: <e6312d6f-2adc-efca-7d48-77dd281a9055@sapo.pt>

Hello,

If you are using function resamples from package caret, just read its 
help page. From ?resamples, section Arguments:

Arguments

x	
a list of two or more objects of class train, sbf or rfe with a common 
set of resampling indices in the control object. For sort.resamples, it 
is an object generated by resamples.


Your x argument is not an object of one of those classes. You are 
passing the function a list of 2 numeric values, not an object 
resembling the examples in that help page.


Hope this helps,

Rui Barradas


?s 11:35 de 24/02/20, javed khan escreveu:
> Hello
> 
> I am using genetic algorithm for some optimization problem. I executed it
> with 2 types of data and get results like
> 
> GA=40
> GA2=60
> 
> When I combine it with resamples
> 
> Value=resamples (list (GA, GA2))
> 
> It gives me the error
> 
> $ operator is invalid for atomic vectors.
> 
> What should be the issue here?
> 
> Thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From peter@crowther @end|ng |rom me|@ndr@@com  Mon Feb 24 14:27:54 2020
From: peter@crowther @end|ng |rom me|@ndr@@com (Peter Crowther)
Date: Mon, 24 Feb 2020 13:27:54 +0000
Subject: [R] Error: cannot allocate vector of size 6.5 Gb
In-Reply-To: <CAM9Qe4gJ2_fkoi08PtUMhZ2q7ETXEHJRZW-wXu=nNpuwKpY-hg@mail.gmail.com>
References: <CAM9Qe4gJ2_fkoi08PtUMhZ2q7ETXEHJRZW-wXu=nNpuwKpY-hg@mail.gmail.com>
Message-ID: <CALhdq6udh4YWoQ2oSjnrW5X_ixwTaN4wVRWFX-7hE_muGgs-nQ@mail.gmail.com>

Are you running the 32-bit or 64-bit version of R?  The 32-bit version
cannot allocate that much space; on Windows, the maximum contiguous space
that can ever be allocated in a 32-bit process is a little over 1Gbyte, on
Unix it's larger but cannot go over the 32-bit address space limit of
4Gbytes.

Cheers,

- Peter

On Sat, 22 Feb 2020 at 22:43, greg holly <mak.hholly at gmail.com> wrote:

> Dear R-Help members;
>
> I have the following error messages when I would like to create
> training and testing data for Random Forest.
>
> Your help is highly appreciated.
>
> Regards,
> Greg
>
> inTrain <- createDataPartition(a, p = 0.7, list = FALSE)
> Error: cannot allocate vector of size 6.5 Gb
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Feb 24 19:04:26 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 24 Feb 2020 18:04:26 +0000
Subject: [R] $ opetator is invalid for atomic vectors
In-Reply-To: <CAJhui+u_XhqZRdbk+HaSuZ=H9ouSSbDWv9g8NdEpB4=sBLmpPw@mail.gmail.com>
References: <CAJhui+s3SE3qKVQYh+jMN6YKC8Lq+faBQ_gSwUf408fgTQJntg@mail.gmail.com>
 <e6312d6f-2adc-efca-7d48-77dd281a9055@sapo.pt>
 <CAJhui+u_XhqZRdbk+HaSuZ=H9ouSSbDWv9g8NdEpB4=sBLmpPw@mail.gmail.com>
Message-ID: <7fc0f798-8eab-4eb2-e8b9-15851e060d21@sapo.pt>

Hello,

Please cc the list.
Yes, I believe so, it's hard to say, the code is not reproducible.
But that's what the docs say. Why not try it?

Hope this helps,

Rui Barradas

?s 16:00 de 24/02/20, javed khan escreveu:
> 
> Thanks for your feedback Rui.. It means I have to specify the "mod" in 
> the resamples (based on the code below) instead of ga_res?? mod here is 
> the train function of caret?
> 
> resamples(list( First_data= mod, Second_data=mod2)
> 
> My sample code is here
> 
> obj <- function(param, maximize = FALSE) {
>  ? print(param)
>  ? mod <- train(Result ~ ., data = tr,
>  ? ? ? ? ? ? ? ?method = "gbm",
>  ? ? ? ? ? ? ? ?metric = "MAE",
>  ? ? ? ? ? ? ? ?trControl = ctrl
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? ? tuneGrid = data.frame(n.trees = 
> (param[1]), interaction.depth = (param[2]),
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? shrinkage=(param[3]), 
> n.minobsinnode=(param[4])))
> 
>  ? ? ? ? ? ? ? ? if(maximize)
>  ? ? -getTrainPerf(mod)[, "TrainMAE"] else
>  ? ? ? getTrainPerf(mod)[, "TrainMAE"]
> }
> 
> Then GA function
> 
> library(GA)
> set.seed(45642)
> ga_res <- ga(type = "real-valued",
>  ? ? ? ? ? ? ?fitness = svm_obj,
>  ? ? ? ? ? ? ?min = c(0.5,0), max = c(1,1),
> 
>  ? ? ? ? ? ? ?maxiter = ceiling(num_mods),
>  ? ? ? ? ? ? ?maximize = TRUE)
> ga_res at solution
> 
> On Mon, Feb 24, 2020 at 2:03 PM Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     If you are using function resamples from package caret, just read its
>     help page. From ?resamples, section Arguments:
> 
>     Arguments
> 
>     x
>     a list of two or more objects of class train, sbf or rfe with a common
>     set of resampling indices in the control object. For sort.resamples, it
>     is an object generated by resamples.
> 
> 
>     Your x argument is not an object of one of those classes. You are
>     passing the function a list of 2 numeric values, not an object
>     resembling the examples in that help page.
> 
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
> 
>     ?s 11:35 de 24/02/20, javed khan escreveu:
>      > Hello
>      >
>      > I am using genetic algorithm for some optimization problem. I
>     executed it
>      > with 2 types of data and get results like
>      >
>      > GA=40
>      > GA2=60
>      >
>      > When I combine it with resamples
>      >
>      > Value=resamples (list (GA, GA2))
>      >
>      > It gives me the error
>      >
>      > $ operator is invalid for atomic vectors.
>      >
>      > What should be the issue here?
>      >
>      > Thanks
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
>


From j@vedbtk111 @end|ng |rom gm@||@com  Tue Feb 25 00:10:59 2020
From: j@vedbtk111 @end|ng |rom gm@||@com (javed khan)
Date: Tue, 25 Feb 2020 00:10:59 +0100
Subject: [R] $ opetator is invalid for atomic vectors
In-Reply-To: <7fc0f798-8eab-4eb2-e8b9-15851e060d21@sapo.pt>
References: <CAJhui+s3SE3qKVQYh+jMN6YKC8Lq+faBQ_gSwUf408fgTQJntg@mail.gmail.com>
 <e6312d6f-2adc-efca-7d48-77dd281a9055@sapo.pt>
 <CAJhui+u_XhqZRdbk+HaSuZ=H9ouSSbDWv9g8NdEpB4=sBLmpPw@mail.gmail.com>
 <7fc0f798-8eab-4eb2-e8b9-15851e060d21@sapo.pt>
Message-ID: <CAJhui+vokOZioX5g=hYYHdNT7=EpfrWTQovA7Vw9GRB5yzaESg@mail.gmail.com>

I want to compare the same algorithm (mentioned below) on two different
type of datasets. But when I
rvalues=resamples(list(mod, mod2)) , it gives me error:
Object mod2 not found   (note: code works fine with mod but with mod2, it
gives error)

It is strange because the code is exactly same, but one I named mod and
another mod2

The code is here:

obj <- function(param, maximize = FALSE) {
  print(param)
  mod <- train(Result ~ ., data = tr,
               method = "gbm",
               metric = "MAE",
               trControl = ctrl
                                   tuneGrid = data.frame(n.trees =
(param[1]), interaction.depth = (param[2]),
                                shrinkage=(param[3]),
n.minobsinnode=(param[4])))

                if(maximize)
    -getTrainPerf(mod)[, "TrainMAE"] else
      getTrainPerf(mod)[, "TrainMAE"]
}
library(GA)
set.seed(45642)
ga_res <- ga(type = "real-valued",
             fitness = svm_obj,
             min = c(0.5,0), max = c(1,1),

             maxiter = ceiling(num_mods),
             maximize = TRUE)
ga_res at solution


Then I changed the dataset i.e data2 (in the same file) but algorithm is
same, except the mod in train () becomes mod2, in order to draw later the
plot as

rvalues=resamples(list(mod, mod2))    /// mod for one dataset and mod2 for
another dataset
bwplot(rvalues, metric="MAE")

On Mon, Feb 24, 2020 at 7:04 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Please cc the list.
> Yes, I believe so, it's hard to say, the code is not reproducible.
> But that's what the docs say. Why not try it?
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 16:00 de 24/02/20, javed khan escreveu:
> >
> > Thanks for your feedback Rui.. It means I have to specify the "mod" in
> > the resamples (based on the code below) instead of ga_res?  mod here is
> > the train function of caret?
> >
> > resamples(list( First_data= mod, Second_data=mod2)
> >
> > My sample code is here
> >
> > obj <- function(param, maximize = FALSE) {
> >    print(param)
> >    mod <- train(Result ~ ., data = tr,
> >                 method = "gbm",
> >                 metric = "MAE",
> >                 trControl = ctrl
> >                                     tuneGrid = data.frame(n.trees =
> > (param[1]), interaction.depth = (param[2]),
> >                                  shrinkage=(param[3]),
> > n.minobsinnode=(param[4])))
> >
> >                  if(maximize)
> >      -getTrainPerf(mod)[, "TrainMAE"] else
> >        getTrainPerf(mod)[, "TrainMAE"]
> > }
> >
> > Then GA function
> >
> > library(GA)
> > set.seed(45642)
> > ga_res <- ga(type = "real-valued",
> >               fitness = svm_obj,
> >               min = c(0.5,0), max = c(1,1),
> >
> >               maxiter = ceiling(num_mods),
> >               maximize = TRUE)
> > ga_res at solution
> >
> > On Mon, Feb 24, 2020 at 2:03 PM Rui Barradas <ruipbarradas at sapo.pt
> > <mailto:ruipbarradas at sapo.pt>> wrote:
> >
> >     Hello,
> >
> >     If you are using function resamples from package caret, just read its
> >     help page. From ?resamples, section Arguments:
> >
> >     Arguments
> >
> >     x
> >     a list of two or more objects of class train, sbf or rfe with a
> common
> >     set of resampling indices in the control object. For sort.resamples,
> it
> >     is an object generated by resamples.
> >
> >
> >     Your x argument is not an object of one of those classes. You are
> >     passing the function a list of 2 numeric values, not an object
> >     resembling the examples in that help page.
> >
> >
> >     Hope this helps,
> >
> >     Rui Barradas
> >
> >
> >     ?s 11:35 de 24/02/20, javed khan escreveu:
> >      > Hello
> >      >
> >      > I am using genetic algorithm for some optimization problem. I
> >     executed it
> >      > with 2 types of data and get results like
> >      >
> >      > GA=40
> >      > GA2=60
> >      >
> >      > When I combine it with resamples
> >      >
> >      > Value=resamples (list (GA, GA2))
> >      >
> >      > It gives me the error
> >      >
> >      > $ operator is invalid for atomic vectors.
> >      >
> >      > What should be the issue here?
> >      >
> >      > Thanks
> >      >
> >      >       [[alternative HTML version deleted]]
> >      >
> >      > ______________________________________________
> >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >      > https://stat.ethz.ch/mailman/listinfo/r-help
> >      > PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >      > and provide commented, minimal, self-contained, reproducible code.
> >      >
> >
>

	[[alternative HTML version deleted]]


From |eder|co@c@|bo|| @end|ng |rom ku|euven@be  Tue Feb 25 09:33:41 2020
From: |eder|co@c@|bo|| @end|ng |rom ku|euven@be (Federico Calboli)
Date: Tue, 25 Feb 2020 08:33:41 +0000
Subject: [R] how to feed lme() and lmer() data for a loop
Message-ID: <08C00190-08DF-4325-B513-7094830E6D1E@kuleuven.be>

Hi all,

I am struggling with an issue related to lme() and lmer().  lm() can easily take stuff on the fly from different objects and be happy:

lm(data1[,1] ~ data2[,1] + data3[,45] + data4[,39])

works ? always.  It also allows me to run nice loops:

for(i in 1:whatever){
lm(data1[,1] ~ data2[,i] + data3[,45] + data4[,39])
}

(for a useless but clear example where I loop the model over all columns of data2).  This property also allows me to totally ignore ?names? for the data I am using.  

I am at loss why this is not possible with lme() or lmer().  I can go around this issue by building data frames on the fly, but this is cumbresome, both as code and very likely as performance, especially looping over lots of data having to generate these dummy data frames.

If there is a trick I am missing I?d be grateful if anybody could set me straight.

Best

F


--
Federico Calboli
LBEG - Laboratory of Biodiversity and Evolutionary Genomics
Charles Deberiotstraat 32 box 2439
3000 Leuven
+32 16 32 87 67






From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Feb 25 10:21:11 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 25 Feb 2020 09:21:11 +0000
Subject: [R] how to feed lme() and lmer() data for a loop
In-Reply-To: <08C00190-08DF-4325-B513-7094830E6D1E@kuleuven.be>
References: <08C00190-08DF-4325-B513-7094830E6D1E@kuleuven.be>
Message-ID: <ea1f3d18-d5aa-f21f-c60c-aaca7fdf9534@sapo.pt>

Hello,

Not possible with lmer? I think it is.
At least with the first example of ?lmer it is:


library(lme4)

Days <- sleepstudy$Days
data2 <- data.frame(X = Days, Y = Days, Z = Days)

nc <- ncol(data2)
lmer_list <- vector("list", length = nc)

for(i in seq.int(nc)){
   #fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
   fm1 <- lmer(sleepstudy[, 1] ~ data2[, i] + (data2[, i] | sleepstudy[, 
3]))
   lmer_list[[i]] <- fm1
}



Anyway, if your subsetting is based on an index, consider coercing the 
data.frame to (numeric) matrix first, it will speed up things.
And use the standard way with a data argument for the other terms:


data2 <- as.matrix(data2)
lmer_list2 <- vector("list", length = nc)

for(i in seq.int(nc)){
   #fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
   fm1 <- lmer(Reaction ~ data2[, i] + (data2[, i] | Subject), data = 
sleepstudy)
   lmer_list2[[i]] <- fm1
}

lmer_list[[1]]
lmer_list2[[1]]


Hope this helps,

Rui Barradas

?s 08:33 de 25/02/20, Federico Calboli escreveu:
> Hi all,
> 
> I am struggling with an issue related to lme() and lmer().  lm() can easily take stuff on the fly from different objects and be happy:
> 
> lm(data1[,1] ~ data2[,1] + data3[,45] + data4[,39])
> 
> works ? always.  It also allows me to run nice loops:
> 
> for(i in 1:whatever){
> lm(data1[,1] ~ data2[,i] + data3[,45] + data4[,39])
> }
> 
> (for a useless but clear example where I loop the model over all columns of data2).  This property also allows me to totally ignore ?names? for the data I am using.
> 
> I am at loss why this is not possible with lme() or lmer().  I can go around this issue by building data frames on the fly, but this is cumbresome, both as code and very likely as performance, especially looping over lots of data having to generate these dummy data frames.
> 
> If there is a trick I am missing I?d be grateful if anybody could set me straight.
> 
> Best
> 
> F
> 
> 
> --
> Federico Calboli
> LBEG - Laboratory of Biodiversity and Evolutionary Genomics
> Charles Deberiotstraat 32 box 2439
> 3000 Leuven
> +32 16 32 87 67
> 
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pj@|nh@07 @end|ng |rom gm@||@com  Wed Feb 26 15:51:32 2020
From: pj@|nh@07 @end|ng |rom gm@||@com (pooja sinha)
Date: Wed, 26 Feb 2020 09:51:32 -0500
Subject: [R] Unable to resolve the issue of break point in ggplot2
Message-ID: <CAGjf1cNOGgnSeRHXi2zPbmLW=HzwruGu5xW5aA+ieqrU7qXvxQ@mail.gmail.com>

Hi All,

I have a data as shown below:
TF YT_YC MT_MC AT_AC
GRHL2 1e-2597 1e-2789 1.00E-281
Srebp1a 1e-1860 1e-1744 1e-944
EWS:ERG 1e-1831 1e-2127 1e-548
EWS:FLI1 1e-1580 1e-1937 1.00E-166
NFAT 1e-1418 1e-2224 1e-761
Sox4 1e-1410 1e-1839 1.00E-246
PU.1-IRF 1e-1361 1e-3661 1e-1380
Sox2 1e-1114 1e-1295 1e-399
Atoh1 1e-1108 1e-620 1e-590
EHF 1e-942 1e-1379 1e-1727
ETV1 1e-927 1e-1301 0.01
Nur77 1e-908 1e-795 1e-372
ZNF711 1e-814 1e-684 1e-576
Sox10 1e-769 1e-1115 1.00E-41
I am trying to make geom_tile in ggplot2 and I have the code below but
after plotting I didn't find the gradient of colors after applying breaks.
Can anyone suggest me how to apply breaks or other codes in ggplot2 so that
I can have gradient of colors or other way of plotting.

library(ggplot2)
library(tidyr)
library(dplyr)
setwd("C:/Users/sinha.puja/Desktop/CP")
mat_data1 <-
read.csv(file="C:/Users/sinha.puja/Desktop/CP/TF_heatmap_plot.csv",
sep=",")
library(wesanderson)
names(wes_palettes)
pal <- wes_palette("Zissou1", 100, type = "continuous")
mat_data1 %>%
  pivot_longer(
    cols = c("YT_YC", "MT_MC", "AT_AC"),
    names_to = "Age_group",
    values_to = "Value"
  ) %>%
  ggplot(aes(x = Age_group, y = TF)) +
  geom_tile(aes(fill=Value), width = 0.990, height = 0.900) +
  scale_fill_gradientn(colours = pal, limits =c(0.01, 1.e-3670))

Thanks in Advance.
Puja

	[[alternative HTML version deleted]]


From pj@|nh@07 @end|ng |rom gm@||@com  Wed Feb 26 16:22:27 2020
From: pj@|nh@07 @end|ng |rom gm@||@com (pooja sinha)
Date: Wed, 26 Feb 2020 10:22:27 -0500
Subject: [R] Unable to resolve the issue of break point in ggplot2
In-Reply-To: <CAGjf1cNOGgnSeRHXi2zPbmLW=HzwruGu5xW5aA+ieqrU7qXvxQ@mail.gmail.com>
References: <CAGjf1cNOGgnSeRHXi2zPbmLW=HzwruGu5xW5aA+ieqrU7qXvxQ@mail.gmail.com>
Message-ID: <CAGjf1cOC9YWw2Y+ZgdT22Yq3dyNzN_iJMYAgVyXxB9k2sauk-w@mail.gmail.com>

Sorry I used limits in code and need to focus on both limits and breaks.

On Wed, Feb 26, 2020 at 9:51 AM pooja sinha <pjsinha07 at gmail.com> wrote:

> Hi All,
>
> I have a data as shown below:
> TF YT_YC MT_MC AT_AC
> GRHL2 1e-2597 1e-2789 1.00E-281
> Srebp1a 1e-1860 1e-1744 1e-944
> EWS:ERG 1e-1831 1e-2127 1e-548
> EWS:FLI1 1e-1580 1e-1937 1.00E-166
> NFAT 1e-1418 1e-2224 1e-761
> Sox4 1e-1410 1e-1839 1.00E-246
> PU.1-IRF 1e-1361 1e-3661 1e-1380
> Sox2 1e-1114 1e-1295 1e-399
> Atoh1 1e-1108 1e-620 1e-590
> EHF 1e-942 1e-1379 1e-1727
> ETV1 1e-927 1e-1301 0.01
> Nur77 1e-908 1e-795 1e-372
> ZNF711 1e-814 1e-684 1e-576
> Sox10 1e-769 1e-1115 1.00E-41
> I am trying to make geom_tile in ggplot2 and I have the code below but
> after plotting I didn't find the gradient of colors after applying breaks.
> Can anyone suggest me how to apply breaks or other codes in ggplot2 so that
> I can have gradient of colors or other way of plotting.
>
> library(ggplot2)
> library(tidyr)
> library(dplyr)
> setwd("C:/Users/sinha.puja/Desktop/CP")
> mat_data1 <-
> read.csv(file="C:/Users/sinha.puja/Desktop/CP/TF_heatmap_plot.csv",
> sep=",")
> library(wesanderson)
> names(wes_palettes)
> pal <- wes_palette("Zissou1", 100, type = "continuous")
> mat_data1 %>%
>   pivot_longer(
>     cols = c("YT_YC", "MT_MC", "AT_AC"),
>     names_to = "Age_group",
>     values_to = "Value"
>   ) %>%
>   ggplot(aes(x = Age_group, y = TF)) +
>   geom_tile(aes(fill=Value), width = 0.990, height = 0.900) +
>   scale_fill_gradientn(colours = pal, limits =c(0.01, 1.e-3670))
>
> Thanks in Advance.
> Puja
>

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Feb 27 02:09:08 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 27 Feb 2020 14:09:08 +1300
Subject: [R] A behaviour pattern that I find mysterious.
Message-ID: <98e9e733-948b-29c1-94b0-644a5d352406@auckland.ac.nz>


Consider the following:

x <- letters[1:5]
x < 0

This gives

> [1] FALSE FALSE FALSE FALSE FALSE

which kind of makes sense, I guess, though I would a priori have 
expected all NAs.

But then do:

x[3] <- "*"
x < 0

This gives

> [1] FALSE FALSE  TRUE FALSE FALSE

which puzzles me.  Why is "*" considered to be less than 0?

At one point I made the conjecture that it had something to do with the 
ordering of ASCII characters, but it does not seem to.  A little more 
investigation led me to conjecture that all ASCII characters except 
real-live letters and numerals come out as being less than 0.

Can anyone explain the rationale to me?  Not that it matters a damn. 
Just idle curiosity.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From m@rc_@chw@rtz @end|ng |rom me@com  Thu Feb 27 02:27:47 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Wed, 26 Feb 2020 20:27:47 -0500
Subject: [R] A behaviour pattern that I find mysterious.
In-Reply-To: <98e9e733-948b-29c1-94b0-644a5d352406@auckland.ac.nz>
References: <98e9e733-948b-29c1-94b0-644a5d352406@auckland.ac.nz>
Message-ID: <BAC3AB39-1EB6-4F78-AE85-C5F73D30AC46@me.com>


> On Feb 26, 2020, at 8:09 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> Consider the following:
> 
> x <- letters[1:5]
> x < 0
> 
> This gives
> 
>> [1] FALSE FALSE FALSE FALSE FALSE
> 
> which kind of makes sense, I guess, though I would a priori have expected all NAs.
> 
> But then do:
> 
> x[3] <- "*"
> x < 0
> 
> This gives
> 
>> [1] FALSE FALSE  TRUE FALSE FALSE
> 
> which puzzles me.  Why is "*" considered to be less than 0?
> 
> At one point I made the conjecture that it had something to do with the ordering of ASCII characters, but it does not seem to.  A little more investigation led me to conjecture that all ASCII characters except real-live letters and numerals come out as being less than 0.
> 
> Can anyone explain the rationale to me?  Not that it matters a damn. Just idle curiosity.
> 
> cheers,
> 
> Rolf Turner
> 

Rolf,

Does this help?

From ?"<":

"If the two arguments are atomic vectors of different types, one is coerced to the type of the other, the (decreasing) order of precedence being character, complex, numeric, integer, logical and raw."

Thus:

> c(0, x)
[1] "0" "a" "b" "*" "d" "e"

> sort(c(0, x))
[1] "*" "0" "a" "b" "d" "e"


Thus, "*" is less than "0", at least in my locale, and presumably yours, since lexical sort ordering is locale dependent.

Regards,

Marc Schwartz


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Feb 27 02:35:44 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 26 Feb 2020 20:35:44 -0500
Subject: [R] A behaviour pattern that I find mysterious.
In-Reply-To: <98e9e733-948b-29c1-94b0-644a5d352406@auckland.ac.nz>
References: <98e9e733-948b-29c1-94b0-644a5d352406@auckland.ac.nz>
Message-ID: <e2f94daa-0435-a249-799c-838888d5511c@gmail.com>

On 26/02/2020 8:09 p.m., Rolf Turner wrote:
> 
> Consider the following:
> 
> x <- letters[1:5]
> x < 0
> 
> This gives
> 
>> [1] FALSE FALSE FALSE FALSE FALSE
> 
> which kind of makes sense, I guess, though I would a priori have
> expected all NAs.
> 
> But then do:
> 
> x[3] <- "*"
> x < 0
> 
> This gives
> 
>> [1] FALSE FALSE  TRUE FALSE FALSE
> 
> which puzzles me.  Why is "*" considered to be less than 0?
> 
> At one point I made the conjecture that it had something to do with the
> ordering of ASCII characters, but it does not seem to.  A little more
> investigation led me to conjecture that all ASCII characters except
> real-live letters and numerals come out as being less than 0.
> 
> Can anyone explain the rationale to me?  Not that it matters a damn.
> Just idle curiosity.

It's doing a string comparison, but ordering will depend on your locale. 
  You can read the ?icuGetCollate help page if you want to spend a lot 
of time reading a help page.  Not sure it'll answer your question, though...

Duncan Murdoch


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Feb 27 04:29:48 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 27 Feb 2020 16:29:48 +1300
Subject: [R] A behaviour pattern that I find mysterious.
In-Reply-To: <BAC3AB39-1EB6-4F78-AE85-C5F73D30AC46@me.com>
References: <98e9e733-948b-29c1-94b0-644a5d352406@auckland.ac.nz>
 <BAC3AB39-1EB6-4F78-AE85-C5F73D30AC46@me.com>
Message-ID: <92c1b47a-a4c5-33f2-ee06-7daee477f6d2@auckland.ac.nz>


Thanks to Marc and Duncan for setting me straight.  I guess the piece of 
the puzzle that I was overlooking is the fact that lexicographic 
ordering for string comparison depends on locale.

It would also have helped me a bit if I'd done the RTFM thing and looked 
at ?"<" !!!

Thanks again.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From herd_dog @end|ng |rom cox@net  Thu Feb 27 16:05:16 2020
From: herd_dog @end|ng |rom cox@net (Phillip Heinrich)
Date: Thu, 27 Feb 2020 08:05:16 -0700
Subject: [R] Accessing Data From packages
Message-ID: <BB9FE22EB27C445DBCCDA288DA11EA1B@OWNERPC>

I am continuing to have problems downloading data as prescribed in books 
about R such as ?Analyzing Baseball Data with R?.

In chapter 3 (page 67) the instructions to download baseball Hall of Fame 
data from the package tidyverse are:

library(tidyverse)
-- Attaching packages --------------------------------------- tidyverse 
1.3.0 -- v ggplot2 3.2.1
v purrr  0.3.3 v tibble  2.1.3
v dplyr  0.8.3 v tidyr  1.0.0 v stringr 1.4.0
v readr  1.3.1 v forcats 0.4.0

-- Conflicts ------------------------------------------
tidyverse_conflicts() -- x dplyr::filter() masks stats::filter()
x dplyr::lag() masks stats::lag()
Warning messages: 1: package ?tidyverse? was built under R version 3.6.2 2:
package ?purrr? was built under R version 3.6.2

The package seems to load correctly but when I try to call up the data I get 
an error message.
***********************************************************************************************

> hof <- read_csv("data/hofbatting.csv")

Error: 'data/hofbatting.csv' does not exist in current working directory 
('C:/Users/Owner/Documents').

***********************************************************************************************
I have no idea where the data is hiding.  Can someone give me some 
directions.


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Feb 27 16:36:21 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 27 Feb 2020 10:36:21 -0500
Subject: [R] Accessing Data From packages
In-Reply-To: <BB9FE22EB27C445DBCCDA288DA11EA1B@OWNERPC>
References: <BB9FE22EB27C445DBCCDA288DA11EA1B@OWNERPC>
Message-ID: <d2e0d137-2bd8-10c3-30e4-4a9f051c603b@gmail.com>

On 27/02/2020 10:05 a.m., Phillip Heinrich wrote:
> I am continuing to have problems downloading data as prescribed in books
> about R such as ?Analyzing Baseball Data with R?.
> 
> In chapter 3 (page 67) the instructions to download baseball Hall of Fame
> data from the package tidyverse are:
> 
> library(tidyverse)
> -- Attaching packages --------------------------------------- tidyverse
> 1.3.0 -- v ggplot2 3.2.1
> v purrr  0.3.3 v tibble  2.1.3
> v dplyr  0.8.3 v tidyr  1.0.0 v stringr 1.4.0
> v readr  1.3.1 v forcats 0.4.0
> 
> -- Conflicts ------------------------------------------
> tidyverse_conflicts() -- x dplyr::filter() masks stats::filter()
> x dplyr::lag() masks stats::lag()
> Warning messages: 1: package ?tidyverse? was built under R version 3.6.2 2:
> package ?purrr? was built under R version 3.6.2
> 
> The package seems to load correctly but when I try to call up the data I get
> an error message.
> ***********************************************************************************************
> 
>> hof <- read_csv("data/hofbatting.csv")
> 
> Error: 'data/hofbatting.csv' does not exist in current working directory
> ('C:/Users/Owner/Documents').
> 
> ***********************************************************************************************
> I have no idea where the data is hiding.  Can someone give me some
> directions.

It's not clear from your message whether you have the file on your disk 
or not.  If you do, then instead of giving the name, try using the 
file.choose() function, e.g.

filename <- file.choose()
hof <- read_csv(filename)

That will open a standard dialog to allow you to specify the filename 
correctly.  If you don't know where to look for it, I can't help: 
presumably instructions are given in the book, but I don't have a copy. 
You'll just have to read more of it.

Duncan Murdoch


From @@chre|b @end|ng |rom u@|bert@@c@  Thu Feb 27 16:59:28 2020
From: @@chre|b @end|ng |rom u@|bert@@c@ (Stefan Schreiber)
Date: Thu, 27 Feb 2020 08:59:28 -0700
Subject: [R] Accessing Data From packages
In-Reply-To: <BB9FE22EB27C445DBCCDA288DA11EA1B@OWNERPC>
References: <BB9FE22EB27C445DBCCDA288DA11EA1B@OWNERPC>
Message-ID: <CAPK=Jisj+rCgB_AseT2Uy_K1=D6wiVH2nhn4fdQMDxmhq1NK8A@mail.gmail.com>

>From the "Companion to Analyzing Baseball Data with R" on GitHub
(https://github.com/maxtoki/baseball_R) it says:

"In order to have a working copy of the code in the book, download the
zip file of this repository and extract the content of the zip file in
a folder of your convenience.
The data folder contains datasets used in the book, except those
downloadable from websites. In order to get the missing datasets, read
the readme.txt files stored inside the lahman, sqldumps and wizardry
subfolders of the data folder.
The script folder contains one script named _setWorkingDir.R. Before
running any code, open that file, change the path to reflect the
folder of your installed files and run it."

So it seems like you downloaded the zip file but still have to make
sure that the working directory is set correctly (see third paragraph
in the instructions above).

Hope that helps!
Stefan



On Thu, 27 Feb 2020 at 08:05, Phillip Heinrich <herd_dog at cox.net> wrote:
>
> I am continuing to have problems downloading data as prescribed in books
> about R such as ?Analyzing Baseball Data with R?.
>
> In chapter 3 (page 67) the instructions to download baseball Hall of Fame
> data from the package tidyverse are:
>
> library(tidyverse)
> -- Attaching packages --------------------------------------- tidyverse
> 1.3.0 -- v ggplot2 3.2.1
> v purrr  0.3.3 v tibble  2.1.3
> v dplyr  0.8.3 v tidyr  1.0.0 v stringr 1.4.0
> v readr  1.3.1 v forcats 0.4.0
>
> -- Conflicts ------------------------------------------
> tidyverse_conflicts() -- x dplyr::filter() masks stats::filter()
> x dplyr::lag() masks stats::lag()
> Warning messages: 1: package ?tidyverse? was built under R version 3.6.2 2:
> package ?purrr? was built under R version 3.6.2
>
> The package seems to load correctly but when I try to call up the data I get
> an error message.
> ***********************************************************************************************
>
> > hof <- read_csv("data/hofbatting.csv")
>
> Error: 'data/hofbatting.csv' does not exist in current working directory
> ('C:/Users/Owner/Documents').
>
> ***********************************************************************************************
> I have no idea where the data is hiding.  Can someone give me some
> directions.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chr|@@prener @end|ng |rom @|u@edu  Wed Feb 26 22:41:21 2020
From: chr|@@prener @end|ng |rom @|u@edu (Chris Prener)
Date: Wed, 26 Feb 2020 21:41:21 +0000
Subject: [R] useR! 2020 - Registration Open!
References: <5128b37f-7f71-4b36-8928-f78059250a3c@Spark>
Message-ID: <a69925d7-fa86-4658-9e4a-e25d4ce2221d@Spark>

Registration for the useR! 2020 conference in St. Louis, Missouri, U.S.A is now open. The conference will run from July 7th through July 10th, with a pre-conference day with some events on July 6th, tutorials on July 7th, and keynotes/break-outs July 8th-10th. You can view a draft, high-level agenda on our website<https://user2020.r-project.org/program/agenda/>.

Early bird registration will run through April 1st, 2020. Early bird prices for attendance are as follows:

Student - $190
Academic (Faculty/Staff) - $390
Industry and all others - $590

Each tutorial is $75, and the Wednesday Gala Dinner and City Museum event is $60 per ticket.

Registration instructions and links to both the registration platform and our hotel partner can be found on our website<https://user2020.r-project.org/registration/instructions/>.

If you have questions, please feel free to reach out to me (chris.prener at slu.edu) or my colleague and co-lead organizer Jenine Harris (harrisj at wustl.edu).

Best,
Chris

Christopher Prener, PhD
useR! 2020 Co-Lead

Assistant Professor of Sociology
Department of Sociology and Anthropology
Saint Louis University
St. Louis, MO
https://chris-prener.github.io

	[[alternative HTML version deleted]]

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From j@whct @end|ng |rom gm@||@com  Thu Feb 27 19:15:02 2020
From: j@whct @end|ng |rom gm@||@com (John Smith)
Date: Thu, 27 Feb 2020 12:15:02 -0600
Subject: [R] offset in glm
Message-ID: <CAFyG=WOj++Yq8FGrsuZv2Nz=tLMRA96hVQtX2XVTbZc5zUFX0A@mail.gmail.com>

  It is simple to use the provided function glm as fit1 below. However,
without the offset argument, I tried fit2 below. The reason I used fit2 is
that (for X as predictors, b the coefficients)
fit2: log(Claims/Holders) = Xb
means
fit1: log(Claims)=Xb + log(Holders)

Obviously the results from fit2 are different from fit1.

Thanks!
######################################
library("MASS")
  ## main-effects fit as Poisson GLM with offset
 fit1 <- glm(Claims ~ District + Group + Age + offset(log(Holders)),
          data = Insurance, family = poisson)
 coef(fit1)
 > coef(fit1)
   (Intercept)     District2     District3     District4       Group.L
 -1.8105078329  0.0258681909  0.0385239271  0.2342053280  0.4297075387
       Group.Q       Group.C         Age.L         Age.Q         Age.C
  0.0046324351 -0.0292943222 -0.3944318082 -0.0003549709 -0.0167367565

 fit2 <- glm(Claims/Holders ~ District + Group + Age,
          data = Insurance, family = poisson)
 > coef(fit2)
 (Intercept)   District2   District3   District4     Group.L     Group.Q
 -1.86340418  0.17552458  0.11081521  0.15131076  0.43701544 -0.01530721
     Group.C       Age.L       Age.Q       Age.C
 -0.06033747 -0.31976743 -0.01833841 -0.01694737

	[[alternative HTML version deleted]]


From g@rc|95 @end|ng |rom hotm@||@com  Fri Feb 28 07:27:21 2020
From: g@rc|95 @end|ng |rom hotm@||@com (=?utf-8?B?Sm9zw6kgQW50b25pbyBHYXJjw61hIFDDqXJleg==?=)
Date: Fri, 28 Feb 2020 06:27:21 +0000
Subject: [R] Help to solve modeling problem with gamm
Message-ID: <BY5PR08MB636000B68CAC0630EB55A67EBDE80@BY5PR08MB6360.namprd08.prod.outlook.com>

I conducted an experiment where earthworms were subjected to two treatments, with and without herbicide in the soil. Biomass measurements were taken every 12 days for 398 days and the biomass growth curves as a function of time were plotted.

There was clearly a non-linear growth pattern such that an additive mixed effects model was proposed to model the behavior of biomass as a function of time and treatments.

When plotting the residuals a clear cone-shaped pattern was observed, therefore a series of additive models were proposed sequentially to deal with violations of the assumption of homogeneity. Below we can see the models with the following names: M.1; M.2; M.3; M.4



lmc <- lmeControl (niterEM = 5000, msMaxIter = 1000)

f1 <- formula (Biomass ~ Treat + s (Time, by = Treat))



M.1 <-gamm (f1, random = list (fcajita = ~ 1), method = "REML", control = lmc, data = Acorticis)



#This first model uses the experimental box factor (i.e. fcajita) as the random element of the model. This random effects model assumes homogeneity between the experimental boxes and within them over time



M.2 <-gamm (f1, random = list (fcajita = ~ 1), method = "REML", control = lmc, data = Acorticis, weights = varIdent (form = ~ 1 | fcajita))



#This second model assumes heterogeneity between boxes, but homogeneity within each box over time



M.3 <- gamm (f1, random = list (fcajita = ~ 1), method = "REML", control = lmc, data = Acorticis, weights = varExp (form = ~ Time10))



#The third model assumes homogeneity between boxes but heterogeneity within each box over time



Finally, we decided to model the heterogeneity using the 'varComb' function in order to combine the variances where the model allows heterogeneity between the experimental boxes and heterogeneity within the experimental boxes over time:



M.4 <- gamm (f1, random = list (fcajita = ~ 1), data = Acorticis, method = "REML", control = lmc, weights = varComb (varIdent (form = ~ 1 | fcajita), varPower (form = ~ Time10)))



The first three models executed perfectly and the following values ??of the AIC indicator were obtained:

> AIC (M.1 $ lme, M.2 $ lme, M.3 $ lme)



        df       AIC



M.1     8        379.6464



M.2    15        309.5736



M.3     9        310.4828



Unfortunately, the execution of the M.4 model failed and the following error message was obtained:



Error in environment (attr (ret $ lme $ modelStruct $ varStruct, "formula")) <-. GlobalEnv:

attempt to set an attribute on NULL



A final model I tried was M5:

M.5 <- gamm(f1, random = list(fcajita =~ 1), data = Acorticis, method = "REML", control = lmc, weights = varComb(varIdent(form = ~1|fcajita), varExp(form =~ Time10|fcajita)))

and this time I got the following error message:

Error in lme.formula(y ~ X - 1, random = rand, data = strip.offset(mf),  :

  nlminb problem, convergence error code = 1

  message = function evaluation limit reached without convergence (9)

Adem?s: Warning message:

In logLik.reStruct(object, conLin) :

  Singular precision matrix in level -1, block 1



My question is: Could someone help me fix these problems to run the M.4 and M.5 models?


	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Fri Feb 28 13:53:31 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 28 Feb 2020 13:53:31 +0100
Subject: [R] offset in glm
In-Reply-To: <CAFyG=WOj++Yq8FGrsuZv2Nz=tLMRA96hVQtX2XVTbZc5zUFX0A@mail.gmail.com>
References: <CAFyG=WOj++Yq8FGrsuZv2Nz=tLMRA96hVQtX2XVTbZc5zUFX0A@mail.gmail.com>
Message-ID: <16D6913E-59B4-4D65-A3A7-8C692C320A56@gmail.com>

You need weights=Holders to make the 2nd form equivalent to the first (with a bunch of somewhat annoying and largely irrelevant warnings). This is because 300 claims from 1000 holders is more informative than 3 out of 10 even though the rate is the same.

-pd 

> On 27 Feb 2020, at 19:15 , John Smith <jswhct at gmail.com> wrote:
> 
>  It is simple to use the provided function glm as fit1 below. However,
> without the offset argument, I tried fit2 below. The reason I used fit2 is
> that (for X as predictors, b the coefficients)
> fit2: log(Claims/Holders) = Xb
> means
> fit1: log(Claims)=Xb + log(Holders)
> 
> Obviously the results from fit2 are different from fit1.
> 
> Thanks!
> ######################################
> library("MASS")
>  ## main-effects fit as Poisson GLM with offset
> fit1 <- glm(Claims ~ District + Group + Age + offset(log(Holders)),
>          data = Insurance, family = poisson)
> coef(fit1)
>> coef(fit1)
>   (Intercept)     District2     District3     District4       Group.L
> -1.8105078329  0.0258681909  0.0385239271  0.2342053280  0.4297075387
>       Group.Q       Group.C         Age.L         Age.Q         Age.C
>  0.0046324351 -0.0292943222 -0.3944318082 -0.0003549709 -0.0167367565
> 
> fit2 <- glm(Claims/Holders ~ District + Group + Age,
>          data = Insurance, family = poisson)
>> coef(fit2)
> (Intercept)   District2   District3   District4     Group.L     Group.Q
> -1.86340418  0.17552458  0.11081521  0.15131076  0.43701544 -0.01530721
>     Group.C       Age.L       Age.Q       Age.C
> -0.06033747 -0.31976743 -0.01833841 -0.01694737
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bgunter@4567 @end|ng |rom gm@||@com  Fri Feb 28 16:22:39 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 28 Feb 2020 07:22:39 -0800
Subject: [R] Help to solve modeling problem with gamm
In-Reply-To: <BY5PR08MB636000B68CAC0630EB55A67EBDE80@BY5PR08MB6360.namprd08.prod.outlook.com>
References: <BY5PR08MB636000B68CAC0630EB55A67EBDE80@BY5PR08MB6360.namprd08.prod.outlook.com>
Message-ID: <CAGxFJbQOd8_OW_zUh-gzjSPHmXgw4j+3b+yH=hNBuKuDdpthaQ@mail.gmail.com>

Wrong list.

Post here:
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

in **plain text** not html.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Feb 28, 2020 at 12:25 AM Jos? Antonio Garc?a P?rez <
garci95 at hotmail.com> wrote:

> I conducted an experiment where earthworms were subjected to two
> treatments, with and without herbicide in the soil. Biomass measurements
> were taken every 12 days for 398 days and the biomass growth curves as a
> function of time were plotted.
>
> There was clearly a non-linear growth pattern such that an additive mixed
> effects model was proposed to model the behavior of biomass as a function
> of time and treatments.
>
> When plotting the residuals a clear cone-shaped pattern was observed,
> therefore a series of additive models were proposed sequentially to deal
> with violations of the assumption of homogeneity. Below we can see the
> models with the following names: M.1; M.2; M.3; M.4
>
>
>
> lmc <- lmeControl (niterEM = 5000, msMaxIter = 1000)
>
> f1 <- formula (Biomass ~ Treat + s (Time, by = Treat))
>
>
>
> M.1 <-gamm (f1, random = list (fcajita = ~ 1), method = "REML", control =
> lmc, data = Acorticis)
>
>
>
> #This first model uses the experimental box factor (i.e. fcajita) as the
> random element of the model. This random effects model assumes homogeneity
> between the experimental boxes and within them over time
>
>
>
> M.2 <-gamm (f1, random = list (fcajita = ~ 1), method = "REML", control =
> lmc, data = Acorticis, weights = varIdent (form = ~ 1 | fcajita))
>
>
>
> #This second model assumes heterogeneity between boxes, but homogeneity
> within each box over time
>
>
>
> M.3 <- gamm (f1, random = list (fcajita = ~ 1), method = "REML", control =
> lmc, data = Acorticis, weights = varExp (form = ~ Time10))
>
>
>
> #The third model assumes homogeneity between boxes but heterogeneity
> within each box over time
>
>
>
> Finally, we decided to model the heterogeneity using the 'varComb'
> function in order to combine the variances where the model allows
> heterogeneity between the experimental boxes and heterogeneity within the
> experimental boxes over time:
>
>
>
> M.4 <- gamm (f1, random = list (fcajita = ~ 1), data = Acorticis, method =
> "REML", control = lmc, weights = varComb (varIdent (form = ~ 1 | fcajita),
> varPower (form = ~ Time10)))
>
>
>
> The first three models executed perfectly and the following values ??of
> the AIC indicator were obtained:
>
> > AIC (M.1 $ lme, M.2 $ lme, M.3 $ lme)
>
>
>
>         df       AIC
>
>
>
> M.1     8        379.6464
>
>
>
> M.2    15        309.5736
>
>
>
> M.3     9        310.4828
>
>
>
> Unfortunately, the execution of the M.4 model failed and the following
> error message was obtained:
>
>
>
> Error in environment (attr (ret $ lme $ modelStruct $ varStruct,
> "formula")) <-. GlobalEnv:
>
> attempt to set an attribute on NULL
>
>
>
> A final model I tried was M5:
>
> M.5 <- gamm(f1, random = list(fcajita =~ 1), data = Acorticis, method =
> "REML", control = lmc, weights = varComb(varIdent(form = ~1|fcajita),
> varExp(form =~ Time10|fcajita)))
>
> and this time I got the following error message:
>
> Error in lme.formula(y ~ X - 1, random = rand, data = strip.offset(mf),  :
>
>   nlminb problem, convergence error code = 1
>
>   message = function evaluation limit reached without convergence (9)
>
> Adem?s: Warning message:
>
> In logLik.reStruct(object, conLin) :
>
>   Singular precision matrix in level -1, block 1
>
>
>
> My question is: Could someone help me fix these problems to run the M.4
> and M.5 models?
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From B|||@Po||ng @end|ng |rom ze||@@com  Fri Feb 28 17:50:26 2020
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Fri, 28 Feb 2020 16:50:26 +0000
Subject: [R] Help with ggplot plot
Message-ID: <DM6PR02MB5657B3C44E5EA7A957BE795EEAE80@DM6PR02MB5657.namprd02.prod.outlook.com>

#RStudio Version 1.2.5019
sessionInfo()
# R version 3.6.2 (2019-12-12)
#Platform: x86_64-w64-mingw32/x64 (64-bit)
#Running under: Windows 10 x64 (build 17134)

Hello, I am sure I am missing something simple.

Here is my data, its aggregated and if need be I can unaggregate I guess:

dput(tmp)
structure(list(InOutFlagAlpha = c("NO ", "YES", "NO ", "YES",
"NO ", "YES", "NO ", "YES", "NO ", "YES", "NO ", "YES", "NO ",
"YES", "NO ", "YES", "NO ", "YES", "NO ", "YES"), ProductLineFlag = structure(c(1L,
1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L,
1L, 2L, 2L), .Label = c("ACH", "CARD"), class = "factor"), Region = structure(c(1L,
1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L,
5L, 5L, 5L), .Label = c("Frontier", "Midwest", "Northeast", "Pacific",
"South"), class = "factor"), ProductLineID = c(7163L, 34212L,
35891L, 54177L, 8873L, 34008L, 52017L, 67881L, 7408L, 29430L,
64108L, 70532L, 5984L, 21720L, 49030L, 60211L, 7330L, 34876L,
46387L, 75893L)), row.names = c(NA, -20L), class = "data.frame")

|InOutFlagAlpha |ProductLineFlag |    Region| ProductLineID|
|:--------------|:---------------|---------:|-------------:|
|NO             |ACH             |  Frontier|          7163|
|YES            |ACH             |  Frontier|         34212|
|NO             |CARD            |  Frontier|         35891|
|YES            |CARD            |  Frontier|         54177|
|NO             |ACH             |   Midwest|          8873|
|YES            |ACH             |   Midwest|         34008|
|NO             |CARD            |   Midwest|         52017|
|YES            |CARD            |   Midwest|         67881|
|NO             |ACH             | Northeast|          7408|
|YES            |ACH             | Northeast|         29430|
|NO             |CARD            | Northeast|         64108|
|YES            |CARD            | Northeast|         70532|
|NO             |ACH             |   Pacific|          5984|
|YES            |ACH             |   Pacific|         21720|
|NO             |CARD            |   Pacific|         49030|
|YES            |CARD            |   Pacific|         60211|
|NO             |ACH             |     South|          7330|
|YES            |ACH             |     South|         34876|
|NO             |CARD            |     South|         46387|
|YES            |CARD            |     South|         75893|

I am trying to get the value from ProductLineID into the bars

I have slowly stepped through to the point of having everything but the values.

Appreciate any advice, thank you.

WHP

#1
  ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
    geom_bar(stat = "identity")
#2
  ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
    geom_bar(stat = "identity")  +
    facet_grid("InOutFlagAlpha")
#3
  ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
    geom_bar(stat ="identity")  +
    facet_grid("InOutFlagAlpha")
#4
  ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
    geom_bar(stat ="identity",position = 'dodge')  +
    facet_grid("InOutFlagAlpha")
#5
  ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) +
    geom_bar(stat ="identity",position = 'dodge')  +
    facet_grid("InOutFlagAlpha")
#6
  ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) + #Best so far
    geom_bar(stat ="identity")  +
    geom_col()  +
    facet_grid("InOutFlagAlpha")
#7
  ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) + #Not working
    geom_bar(stat ="identity")  +
    geom_col(position = 'dodge')  +
    facet_grid("InOutFlagAlpha")

WHP


Confidentiality Notice\ \ This email and the attachments...{{dropped:11}}


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Feb 28 18:05:33 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 28 Feb 2020 17:05:33 +0000
Subject: [R] Help with ggplot plot
In-Reply-To: <DM6PR02MB5657B3C44E5EA7A957BE795EEAE80@DM6PR02MB5657.namprd02.prod.outlook.com>
References: <DM6PR02MB5657B3C44E5EA7A957BE795EEAE80@DM6PR02MB5657.namprd02.prod.outlook.com>
Message-ID: <8db24a57-e616-f842-420d-07a8080c1c11@sapo.pt>

Hello,

If you want faceting, a square grid can do it.


ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
   geom_bar(stat = "identity") +
   facet_grid(InOutFlagAlpha ~ ProductLineFlag)


Hope this helps,

Rui Barradas

?s 16:50 de 28/02/20, Bill Poling escreveu:
> #RStudio Version 1.2.5019
> sessionInfo()
> # R version 3.6.2 (2019-12-12)
> #Platform: x86_64-w64-mingw32/x64 (64-bit)
> #Running under: Windows 10 x64 (build 17134)
> 
> Hello, I am sure I am missing something simple.
> 
> Here is my data, its aggregated and if need be I can unaggregate I guess:
> 
> dput(tmp)
> structure(list(InOutFlagAlpha = c("NO ", "YES", "NO ", "YES",
> "NO ", "YES", "NO ", "YES", "NO ", "YES", "NO ", "YES", "NO ",
> "YES", "NO ", "YES", "NO ", "YES", "NO ", "YES"), ProductLineFlag = structure(c(1L,
> 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L,
> 1L, 2L, 2L), .Label = c("ACH", "CARD"), class = "factor"), Region = structure(c(1L,
> 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L,
> 5L, 5L, 5L), .Label = c("Frontier", "Midwest", "Northeast", "Pacific",
> "South"), class = "factor"), ProductLineID = c(7163L, 34212L,
> 35891L, 54177L, 8873L, 34008L, 52017L, 67881L, 7408L, 29430L,
> 64108L, 70532L, 5984L, 21720L, 49030L, 60211L, 7330L, 34876L,
> 46387L, 75893L)), row.names = c(NA, -20L), class = "data.frame")
> 
> |InOutFlagAlpha |ProductLineFlag |    Region| ProductLineID|
> |:--------------|:---------------|---------:|-------------:|
> |NO             |ACH             |  Frontier|          7163|
> |YES            |ACH             |  Frontier|         34212|
> |NO             |CARD            |  Frontier|         35891|
> |YES            |CARD            |  Frontier|         54177|
> |NO             |ACH             |   Midwest|          8873|
> |YES            |ACH             |   Midwest|         34008|
> |NO             |CARD            |   Midwest|         52017|
> |YES            |CARD            |   Midwest|         67881|
> |NO             |ACH             | Northeast|          7408|
> |YES            |ACH             | Northeast|         29430|
> |NO             |CARD            | Northeast|         64108|
> |YES            |CARD            | Northeast|         70532|
> |NO             |ACH             |   Pacific|          5984|
> |YES            |ACH             |   Pacific|         21720|
> |NO             |CARD            |   Pacific|         49030|
> |YES            |CARD            |   Pacific|         60211|
> |NO             |ACH             |     South|          7330|
> |YES            |ACH             |     South|         34876|
> |NO             |CARD            |     South|         46387|
> |YES            |CARD            |     South|         75893|
> 
> I am trying to get the value from ProductLineID into the bars
> 
> I have slowly stepped through to the point of having everything but the values.
> 
> Appreciate any advice, thank you.
> 
> WHP
> 
> #1
>    ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
>      geom_bar(stat = "identity")
> #2
>    ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
>      geom_bar(stat = "identity")  +
>      facet_grid("InOutFlagAlpha")
> #3
>    ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
>      geom_bar(stat ="identity")  +
>      facet_grid("InOutFlagAlpha")
> #4
>    ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
>      geom_bar(stat ="identity",position = 'dodge')  +
>      facet_grid("InOutFlagAlpha")
> #5
>    ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) +
>      geom_bar(stat ="identity",position = 'dodge')  +
>      facet_grid("InOutFlagAlpha")
> #6
>    ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) + #Best so far
>      geom_bar(stat ="identity")  +
>      geom_col()  +
>      facet_grid("InOutFlagAlpha")
> #7
>    ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) + #Not working
>      geom_bar(stat ="identity")  +
>      geom_col(position = 'dodge')  +
>      facet_grid("InOutFlagAlpha")
> 
> WHP
> 
> 
> Confidentiality Notice\ \ This email and the attachments...{{dropped:11}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From p@tr|ck@g|r@udoux @end|ng |rom un|v-|comte@|r  Fri Feb 28 18:23:02 2020
From: p@tr|ck@g|r@udoux @end|ng |rom un|v-|comte@|r (Patrick Giraudoux)
Date: Fri, 28 Feb 2020 18:23:02 +0100
Subject: [R] dir and pattern = ".r"
Message-ID: <dd3288f1-2a20-4e08-5218-4aa5d553eb7f@univ-fcomte.fr>

I have this directory contain listed at the page bottom

Can somebody tell me why with

dir(pattern = ".txt")

dir(pattern = ".dbf")

etc.

I get exactly what I want (a vector with the file names correctly 
suffixed), but with

dir(pattern = ".r")

I get this:

> dir(pattern=".r") [1] "Article Predation" "BD Carto" [3] "broma1.txt" 
"broma3.txt" [5] "BromaBusesMilanMicha.xlsx" "Bromadiolone" [7] 
"BufferRenard.dbf" "BufferRenard.prj" [9] "BufferRenard.shp" 
"BufferRenard.shx" [11] "clpboard" "DatesDiurnes.txt" [13] 
"DatesDiurnes_plus.txt" "DatesDiurnes_plus.xlsx" [15] 
"DatesDiurnesFREDON" "DatesDiurnesFREDON_plus.txt" [17] 
"DatesDiurnesFREDON_plus.xlsx" "DatesDiurnesRegis.txt" [19] 
"DatesDiurnesRegis_plus.txt" "DatesDiurnesRegis_plus.xlsx" [21] 
"DatesNocturnes.txt" "DatesNocturnes_plus.txt" [23] 
"DatesNocturnes_plus.xlsx" "DatesNocturnesFREDON" [25] 
"DatesNocturnesFREDON_plus.txt" "DatesNocturnesFREDON_plus.xlsx" [27] 
"DatesNocturnesRegis.txt" "DatesNocturnesRegis_plus.txt" [29] 
"DatesNocturnesRegis_plus.xlsx" "Figures" [31] "ParcBuf300n.dbf" 
"ParcBuf300n.prj" [33] "ParcBuf300n.shp" "ParcBuf300n.shx" [35] 
"ParcBuf350n.dbf" "ParcBuf350n.prj" [37] "ParcBuf350n.shp" 
"ParcBuf350n.shx" [39] "Script_190517_preparation.r" 
"Script_190518_scores_AT.r" [41] "Script_190519_1430_cinetiques_IKA.r" 
"Script_190519_1622_transects_camp.r" [43] 
"Script_190530_1700_preparation2.r" 
"Script_190530_1903_cinetiques_IKA2.r" [45] 
"Script_190531_0922_scores_AT2.r" "Script_190531_1729_prey_resource.r" 
[47] "Script_190601_1509_graphIKAd.r" 
"Script_190601_1509_graphIKAd_old.r" [49] 
"Script_190601_1509_graphIKAn.r" "Script_190601_1509_graphIKAn_old.r" 
[51] "Script_190601_1955_spatial.r" "Script_190708_0930_distance.r" [53] 
"Script_190709_0930_impact renard.r" 
"Script_200117_cinetiques_article.r" [55] 
"Script_200119_source_stats_explore_diurne.r" "Script_200119_stats.r" 
[57] "Script_200122_spatial_distribution.r" "Script_200124_distance.r" 
[59] "Script_200124_distance_source_d.r" 
"Script_200124_distance_source_n.r" [61] 
"Script_200201_impacts_on_prey.R" "ScriptCompteLignes.r" [63] 
"Scripts_avant_200112.zip" "shinyPred" [65] "StudyArea.dbf" 
"StudyArea.prj" [67] "StudyArea.shp" "StudyArea.shx" [69] 
"SurfaceZoneEtude.dbf" "SurfaceZoneEtude.prj" [71] 
"SurfaceZoneEtude.shp" "SurfaceZoneEtude.shx" [73] "transects_camp.Rdata"


How can I get all the files, only these files, suffixed with ".r" ?

Thanks in advance,

------------------------------------------------------------------------


> dir() [1] "Analyse_190523_baseline_190523_1506.docx" 
"Analyse_190523_baseline_190531_2110.docx" [3] 
"Analyse_190523_baseline_190531_2110.Rmd" "Analyse_190531_baseline.docx" 
[5] "Analyse_190531_baseline.Rmd" "Analyse_190531_baseline_cache" [7] 
"Analyse_190531_baseline_files" "Analyse_190603_spatial.docx" [9] 
"Analyse_190603_spatial.Rmd" "Analyse_190603_spatial_cache" [11] 
"Analyse_190603_spatial_files" "Article Predation" [13] "BD Carto" 
"Biblio" [15] "broma1.txt" "broma3.txt" [17] "BromaBusesMilanMicha.xlsx" 
"Bromadiolone" [19] "BufferRenard.dbf" "BufferRenard.prj" [21] 
"BufferRenard.shp" "BufferRenard.shx" [23] "clpboard" "DatesDiurnes.txt" 
[25] "DatesDiurnes_plus.txt" "DatesDiurnes_plus.xlsx" [27] 
"DatesDiurnesFREDON" "DatesDiurnesFREDON_plus.txt" [29] 
"DatesDiurnesFREDON_plus.xlsx" "DatesDiurnesRegis.txt" [31] 
"DatesDiurnesRegis_plus.txt" "DatesDiurnesRegis_plus.xlsx" [33] 
"DatesNocturnes.txt" "DatesNocturnes_plus.txt" [35] 
"DatesNocturnes_plus.xlsx" "DatesNocturnesFREDON" [37] 
"DatesNocturnesFREDON_plus.txt" "DatesNocturnesFREDON_plus.xlsx" [39] 
"DatesNocturnesRegis.txt" "DatesNocturnesRegis_plus.txt" [41] 
"DatesNocturnesRegis_plus.xlsx" "Figures" [43] "IKAZ_old.zip" 
"IKAZ1999.txt" [45] "IKAZ2000.txt" "IKAZ2007.txt" [47] "IKAZ2008.txt" 
"IKAZ2009.txt" [49] "IKAZ2010.txt" "IKAZ2011.txt" [51] "IKAZ2012.txt" 
"IKAZ2013.txt" [53] "IKAZ2014.txt" "IKAZ2015.txt" [55] "IKAZ2016.txt" 
"IKAZ2017.txt" [57] "IKAZ2018.txt" "ParcBuf300n.dbf" [59] 
"ParcBuf300n.prj" "ParcBuf300n.shp" [61] "ParcBuf300n.shx" 
"ParcBuf350n.dbf" [63] "ParcBuf350n.prj" "ParcBuf350n.shp" [65] 
"ParcBuf350n.shx" "Photos ZELAC" [67] "plot.ds.R" "plot.dsmodel.R" [69] 
"RData" "Script_190517_preparation.r" [71] "Script_190518_scores_AT.r" 
"Script_190519_1430_cinetiques_IKA.r" [73] 
"Script_190519_1622_transects_camp.r" 
"Script_190530_1700_preparation2.r" [75] 
"Script_190530_1903_cinetiques_IKA2.r" "Script_190531_0922_scores_AT2.r" 
[77] "Script_190531_1729_prey_resource.r" 
"Script_190601_1509_graphIKAd.r" [79] 
"Script_190601_1509_graphIKAd_old.r" "Script_190601_1509_graphIKAn.r" 
[81] "Script_190601_1509_graphIKAn_old.r" "Script_190601_1955_spatial.r" 
[83] "Script_190708_0930_distance.r" "Script_190709_0930_impact 
renard.r" [85] "Script_200117_cinetiques_article.r" 
"Script_200119_source_stats_explore_diurne.r" [87] 
"Script_200119_stats.r" "Script_200122_spatial_distribution.r" [89] 
"Script_200124_distance.r" "Script_200124_distance_source_d.r" [91] 
"Script_200124_distance_source_n.r" "Script_200201_impacts_on_prey.R" 
[93] "ScriptCompteLignes.r" "Scripts_avant_200112.zip" [95] "shinyChim" 
"ShinyConnect.R" [97] "shinyPred" "StudyArea.dbf" [99] "StudyArea.prj" 
"StudyArea.shp" [101] "StudyArea.shx" "SurfaceZoneEtude.dbf" [103] 
"SurfaceZoneEtude.prj" "SurfaceZoneEtude.shp" [105] 
"SurfaceZoneEtude.shx" "transects_camp.Rdata"


	[[alternative HTML version deleted]]


From jerem|eju@te @end|ng |rom gm@||@com  Fri Feb 28 18:32:43 2020
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Fri, 28 Feb 2020 18:32:43 +0100
Subject: [R] dir and pattern = ".r"
In-Reply-To: <dd3288f1-2a20-4e08-5218-4aa5d553eb7f@univ-fcomte.fr> (Patrick
 Giraudoux's message of "Fri, 28 Feb 2020 18:23:02 +0100")
References: <dd3288f1-2a20-4e08-5218-4aa5d553eb7f@univ-fcomte.fr>
Message-ID: <87v9nq8vno.fsf@gmail.com>


Hello,

you need
> dir(pattern="\\.r$",ignore.case=TRUE)
remember that the pattern is a regular expression.
so ".r" is [any single character]r. So basically it will give you any
file that contains r (but not that starts with r)


so you got what you expected with
>  dir(pattern=".txt")
just by chance. as <rtxt.r> or <rtxt.pdf>  would have been printed as well

HTH,

Jeremie


> I have this directory contain listed at the page bottom
>
> Can somebody tell me why with
>
> dir(pattern = ".txt")
>
> dir(pattern = ".dbf")
>
> etc.
>
> I get exactly what I want (a vector with the file names correctly 
> suffixed), but with
>
> dir(pattern = ".r")
>
> I get this:
>
>> dir(pattern=".r") [1] "Article Predation" "BD Carto" [3] "broma1.txt" 
> "broma3.txt" [5] "BromaBusesMilanMicha.xlsx" "Bromadiolone" [7] 
> "BufferRenard.dbf" "BufferRenard.prj" [9] "BufferRenard.shp" 
> "BufferRenard.shx" [11] "clpboard" "DatesDiurnes.txt" [13] 
> "DatesDiurnes_plus.txt" "DatesDiurnes_plus.xlsx" [15] 
> "DatesDiurnesFREDON" "DatesDiurnesFREDON_plus.txt" [17] 
> "DatesDiurnesFREDON_plus.xlsx" "DatesDiurnesRegis.txt" [19] 
> "DatesDiurnesRegis_plus.txt" "DatesDiurnesRegis_plus.xlsx" [21] 
> "DatesNocturnes.txt" "DatesNocturnes_plus.txt" [23] 
> "DatesNocturnes_plus.xlsx" "DatesNocturnesFREDON" [25] 
> "DatesNocturnesFREDON_plus.txt" "DatesNocturnesFREDON_plus.xlsx" [27] 
> "DatesNocturnesRegis.txt" "DatesNocturnesRegis_plus.txt" [29] 
> "DatesNocturnesRegis_plus.xlsx" "Figures" [31] "ParcBuf300n.dbf" 
> "ParcBuf300n.prj" [33] "ParcBuf300n.shp" "ParcBuf300n.shx" [35] 
> "ParcBuf350n.dbf" "ParcBuf350n.prj" [37] "ParcBuf350n.shp" 
> "ParcBuf350n.shx" [39] "Script_190517_preparation.r" 
> "Script_190518_scores_AT.r" [41] "Script_190519_1430_cinetiques_IKA.r" 
> "Script_190519_1622_transects_camp.r" [43] 
> "Script_190530_1700_preparation2.r" 
> "Script_190530_1903_cinetiques_IKA2.r" [45] 
> "Script_190531_0922_scores_AT2.r" "Script_190531_1729_prey_resource.r" 
> [47] "Script_190601_1509_graphIKAd.r" 
> "Script_190601_1509_graphIKAd_old.r" [49] 
> "Script_190601_1509_graphIKAn.r" "Script_190601_1509_graphIKAn_old.r" 
> [51] "Script_190601_1955_spatial.r" "Script_190708_0930_distance.r" [53] 
> "Script_190709_0930_impact renard.r" 
> "Script_200117_cinetiques_article.r" [55] 
> "Script_200119_source_stats_explore_diurne.r" "Script_200119_stats.r" 
> [57] "Script_200122_spatial_distribution.r" "Script_200124_distance.r" 
> [59] "Script_200124_distance_source_d.r" 
> "Script_200124_distance_source_n.r" [61] 
> "Script_200201_impacts_on_prey.R" "ScriptCompteLignes.r" [63] 
> "Scripts_avant_200112.zip" "shinyPred" [65] "StudyArea.dbf" 
> "StudyArea.prj" [67] "StudyArea.shp" "StudyArea.shx" [69] 
> "SurfaceZoneEtude.dbf" "SurfaceZoneEtude.prj" [71] 
> "SurfaceZoneEtude.shp" "SurfaceZoneEtude.shx" [73] "transects_camp.Rdata"
>
> How can I get all the files, only these files, suffixed with ".r" ?
>
> Thanks in advance,
>
> ------------------------------------------------------------------------
>
>> dir() [1] "Analyse_190523_baseline_190523_1506.docx" 
> "Analyse_190523_baseline_190531_2110.docx" [3] 
> "Analyse_190523_baseline_190531_2110.Rmd" "Analyse_190531_baseline.docx" 
> [5] "Analyse_190531_baseline.Rmd" "Analyse_190531_baseline_cache" [7] 
> "Analyse_190531_baseline_files" "Analyse_190603_spatial.docx" [9] 
> "Analyse_190603_spatial.Rmd" "Analyse_190603_spatial_cache" [11] 
> "Analyse_190603_spatial_files" "Article Predation" [13] "BD Carto" 
> "Biblio" [15] "broma1.txt" "broma3.txt" [17] "BromaBusesMilanMicha.xlsx" 
> "Bromadiolone" [19] "BufferRenard.dbf" "BufferRenard.prj" [21] 
> "BufferRenard.shp" "BufferRenard.shx" [23] "clpboard" "DatesDiurnes.txt" 
> [25] "DatesDiurnes_plus.txt" "DatesDiurnes_plus.xlsx" [27] 
> "DatesDiurnesFREDON" "DatesDiurnesFREDON_plus.txt" [29] 
> "DatesDiurnesFREDON_plus.xlsx" "DatesDiurnesRegis.txt" [31] 
> "DatesDiurnesRegis_plus.txt" "DatesDiurnesRegis_plus.xlsx" [33] 
> "DatesNocturnes.txt" "DatesNocturnes_plus.txt" [35] 
> "DatesNocturnes_plus.xlsx" "DatesNocturnesFREDON" [37] 
> "DatesNocturnesFREDON_plus.txt" "DatesNocturnesFREDON_plus.xlsx" [39] 
> "DatesNocturnesRegis.txt" "DatesNocturnesRegis_plus.txt" [41] 
> "DatesNocturnesRegis_plus.xlsx" "Figures" [43] "IKAZ_old.zip" 
> "IKAZ1999.txt" [45] "IKAZ2000.txt" "IKAZ2007.txt" [47] "IKAZ2008.txt" 
> "IKAZ2009.txt" [49] "IKAZ2010.txt" "IKAZ2011.txt" [51] "IKAZ2012.txt" 
> "IKAZ2013.txt" [53] "IKAZ2014.txt" "IKAZ2015.txt" [55] "IKAZ2016.txt" 
> "IKAZ2017.txt" [57] "IKAZ2018.txt" "ParcBuf300n.dbf" [59] 
> "ParcBuf300n.prj" "ParcBuf300n.shp" [61] "ParcBuf300n.shx" 
> "ParcBuf350n.dbf" [63] "ParcBuf350n.prj" "ParcBuf350n.shp" [65] 
> "ParcBuf350n.shx" "Photos ZELAC" [67] "plot.ds.R" "plot.dsmodel.R" [69] 
> "RData" "Script_190517_preparation.r" [71] "Script_190518_scores_AT.r" 
> "Script_190519_1430_cinetiques_IKA.r" [73] 
> "Script_190519_1622_transects_camp.r" 
> "Script_190530_1700_preparation2.r" [75] 
> "Script_190530_1903_cinetiques_IKA2.r" "Script_190531_0922_scores_AT2.r" 
> [77] "Script_190531_1729_prey_resource.r" 
> "Script_190601_1509_graphIKAd.r" [79] 
> "Script_190601_1509_graphIKAd_old.r" "Script_190601_1509_graphIKAn.r" 
> [81] "Script_190601_1509_graphIKAn_old.r" "Script_190601_1955_spatial.r" 
> [83] "Script_190708_0930_distance.r" "Script_190709_0930_impact 
> renard.r" [85] "Script_200117_cinetiques_article.r" 
> "Script_200119_source_stats_explore_diurne.r" [87] 
> "Script_200119_stats.r" "Script_200122_spatial_distribution.r" [89] 
> "Script_200124_distance.r" "Script_200124_distance_source_d.r" [91] 
> "Script_200124_distance_source_n.r" "Script_200201_impacts_on_prey.R" 
> [93] "ScriptCompteLignes.r" "Scripts_avant_200112.zip" [95] "shinyChim" 
> "ShinyConnect.R" [97] "shinyPred" "StudyArea.dbf" [99] "StudyArea.prj" 
> "StudyArea.shp" [101] "StudyArea.shx" "SurfaceZoneEtude.dbf" [103] 
> "SurfaceZoneEtude.prj" "SurfaceZoneEtude.shp" [105] 
> "SurfaceZoneEtude.shx" "transects_camp.Rdata"
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From B|||@Po||ng @end|ng |rom ze||@@com  Fri Feb 28 18:38:14 2020
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Fri, 28 Feb 2020 17:38:14 +0000
Subject: [R] Help with ggplot plot
In-Reply-To: <8db24a57-e616-f842-420d-07a8080c1c11@sapo.pt>
References: <DM6PR02MB5657B3C44E5EA7A957BE795EEAE80@DM6PR02MB5657.namprd02.prod.outlook.com>
 <8db24a57-e616-f842-420d-07a8080c1c11@sapo.pt>
Message-ID: <DM6PR02MB5657451E2E0999B0B675C58DEAE80@DM6PR02MB5657.namprd02.prod.outlook.com>

Hi Rui, thank you this is helpful, however, I would like the values in the or above the bars.

I have tried 'dodge' but not working correctly.

ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) + #Getting worse again
    geom_bar(stat ="identity")  +
    geom_col(position = 'dodge')  +
    facet_grid("InOutFlagAlpha")

Thoughts?

WHP

From: Rui Barradas <ruipbarradas at sapo.pt>
Sent: Friday, February 28, 2020 11:06 AM
To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with ggplot plot

[External Email]
Hello,

If you want faceting, a square grid can do it.


ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
geom_bar(stat = "identity") +
facet_grid(InOutFlagAlpha ~ ProductLineFlag)


Hope this helps,

Rui Barradas

?s 16:50 de 28/02/20, Bill Poling escreveu:
> #RStudio Version 1.2.5019
> sessionInfo()
> # R version 3.6.2 (2019-12-12)
> #Platform: x86_64-w64-mingw32/x64 (64-bit)
> #Running under: Windows 10 x64 (build 17134)
>
> Hello, I am sure I am missing something simple.
>
> Here is my data, its aggregated and if need be I can unaggregate I guess:
>
> dput(tmp)
> structure(list(InOutFlagAlpha = c("NO ", "YES", "NO ", "YES",
> "NO ", "YES", "NO ", "YES", "NO ", "YES", "NO ", "YES", "NO ",
> "YES", "NO ", "YES", "NO ", "YES", "NO ", "YES"), ProductLineFlag = structure(c(1L,
> 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L,
> 1L, 2L, 2L), .Label = c("ACH", "CARD"), class = "factor"), Region = structure(c(1L,
> 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L,
> 5L, 5L, 5L), .Label = c("Frontier", "Midwest", "Northeast", "Pacific",
> "South"), class = "factor"), ProductLineID = c(7163L, 34212L,
> 35891L, 54177L, 8873L, 34008L, 52017L, 67881L, 7408L, 29430L,
> 64108L, 70532L, 5984L, 21720L, 49030L, 60211L, 7330L, 34876L,
> 46387L, 75893L)), row.names = c(NA, -20L), class = "data.frame")
>
> |InOutFlagAlpha |ProductLineFlag | Region| ProductLineID|
> |:--------------|:---------------|---------:|-------------:|
> |NO |ACH | Frontier| 7163|
> |YES |ACH | Frontier| 34212|
> |NO |CARD | Frontier| 35891|
> |YES |CARD | Frontier| 54177|
> |NO |ACH | Midwest| 8873|
> |YES |ACH | Midwest| 34008|
> |NO |CARD | Midwest| 52017|
> |YES |CARD | Midwest| 67881|
> |NO |ACH | Northeast| 7408|
> |YES |ACH | Northeast| 29430|
> |NO |CARD | Northeast| 64108|
> |YES |CARD | Northeast| 70532|
> |NO |ACH | Pacific| 5984|
> |YES |ACH | Pacific| 21720|
> |NO |CARD | Pacific| 49030|
> |YES |CARD | Pacific| 60211|
> |NO |ACH | South| 7330|
> |YES |ACH | South| 34876|
> |NO |CARD | South| 46387|
> |YES |CARD | South| 75893|
>
> I am trying to get the value from ProductLineID into the bars
>
> I have slowly stepped through to the point of having everything but the values.
>
> Appreciate any advice, thank you.
>
> WHP
>
> #1
> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
> geom_bar(stat = "identity")
> #2
> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
> geom_bar(stat = "identity") +
> facet_grid("InOutFlagAlpha")
> #3
> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
> geom_bar(stat ="identity") +
> facet_grid("InOutFlagAlpha")
> #4
> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
> geom_bar(stat ="identity",position = 'dodge') +
> facet_grid("InOutFlagAlpha")
> #5
> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) +
> geom_bar(stat ="identity",position = 'dodge') +
> facet_grid("InOutFlagAlpha")
> #6
> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) + #Best so far
> geom_bar(stat ="identity") +
> geom_col() +
> facet_grid("InOutFlagAlpha")
> #7
> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) + #Not working
> geom_bar(stat ="identity") +
> geom_col(position = 'dodge') +
> facet_grid("InOutFlagAlpha")
>
> WHP
>
>
> Confidentiality Notice\ \ This email and the attachments...{{dropped:11}}
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Confidentiality Notice

This email and the attachments may contain information which is privileged and/or confidential and is intended for the business and/or confidential use of the recipient only. Such information may be protected by applicable State and/or Federal laws from disclosure or unauthorized use. If you are not the intended recipient, you are hereby notified that any disclosure is strictly prohibited. If you have received this email in error, please contact the sender immediately.

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Feb 28 18:41:25 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 28 Feb 2020 09:41:25 -0800
Subject: [R] dir and pattern = ".r"
In-Reply-To: <dd3288f1-2a20-4e08-5218-4aa5d553eb7f@univ-fcomte.fr>
References: <dd3288f1-2a20-4e08-5218-4aa5d553eb7f@univ-fcomte.fr>
Message-ID: <98EE944E-78C8-49C5-9E36-601E287F797A@dcn.davis.ca.us>

You _need_ to learn how regular expressions work. There are many dozens of ways to learn this topic... web tutorials, YouTube videos, reading the ?regex help page in R. Start at the beginning, and look for special characters like ".", "$", and "\." (which has to be "\\." in R). It shouldn't take long to pick up enough skill to solve this yourself, and you will be a more complete data analyst for it.

On February 28, 2020 9:23:02 AM PST, Patrick Giraudoux <patrick.giraudoux at univ-fcomte.fr> wrote:
>I have this directory contain listed at the page bottom
>
>Can somebody tell me why with
>
>dir(pattern = ".txt")
>
>dir(pattern = ".dbf")
>
>etc.
>
>I get exactly what I want (a vector with the file names correctly 
>suffixed), but with
>
>dir(pattern = ".r")
>
>I get this:
>
>> dir(pattern=".r") [1] "Article Predation" "BD Carto" [3] "broma1.txt"
>
>"broma3.txt" [5] "BromaBusesMilanMicha.xlsx" "Bromadiolone" [7] 
>"BufferRenard.dbf" "BufferRenard.prj" [9] "BufferRenard.shp" 
>"BufferRenard.shx" [11] "clpboard" "DatesDiurnes.txt" [13] 
>"DatesDiurnes_plus.txt" "DatesDiurnes_plus.xlsx" [15] 
>"DatesDiurnesFREDON" "DatesDiurnesFREDON_plus.txt" [17] 
>"DatesDiurnesFREDON_plus.xlsx" "DatesDiurnesRegis.txt" [19] 
>"DatesDiurnesRegis_plus.txt" "DatesDiurnesRegis_plus.xlsx" [21] 
>"DatesNocturnes.txt" "DatesNocturnes_plus.txt" [23] 
>"DatesNocturnes_plus.xlsx" "DatesNocturnesFREDON" [25] 
>"DatesNocturnesFREDON_plus.txt" "DatesNocturnesFREDON_plus.xlsx" [27] 
>"DatesNocturnesRegis.txt" "DatesNocturnesRegis_plus.txt" [29] 
>"DatesNocturnesRegis_plus.xlsx" "Figures" [31] "ParcBuf300n.dbf" 
>"ParcBuf300n.prj" [33] "ParcBuf300n.shp" "ParcBuf300n.shx" [35] 
>"ParcBuf350n.dbf" "ParcBuf350n.prj" [37] "ParcBuf350n.shp" 
>"ParcBuf350n.shx" [39] "Script_190517_preparation.r" 
>"Script_190518_scores_AT.r" [41] "Script_190519_1430_cinetiques_IKA.r" 
>"Script_190519_1622_transects_camp.r" [43] 
>"Script_190530_1700_preparation2.r" 
>"Script_190530_1903_cinetiques_IKA2.r" [45] 
>"Script_190531_0922_scores_AT2.r" "Script_190531_1729_prey_resource.r" 
>[47] "Script_190601_1509_graphIKAd.r" 
>"Script_190601_1509_graphIKAd_old.r" [49] 
>"Script_190601_1509_graphIKAn.r" "Script_190601_1509_graphIKAn_old.r" 
>[51] "Script_190601_1955_spatial.r" "Script_190708_0930_distance.r"
>[53] 
>"Script_190709_0930_impact renard.r" 
>"Script_200117_cinetiques_article.r" [55] 
>"Script_200119_source_stats_explore_diurne.r" "Script_200119_stats.r" 
>[57] "Script_200122_spatial_distribution.r" "Script_200124_distance.r" 
>[59] "Script_200124_distance_source_d.r" 
>"Script_200124_distance_source_n.r" [61] 
>"Script_200201_impacts_on_prey.R" "ScriptCompteLignes.r" [63] 
>"Scripts_avant_200112.zip" "shinyPred" [65] "StudyArea.dbf" 
>"StudyArea.prj" [67] "StudyArea.shp" "StudyArea.shx" [69] 
>"SurfaceZoneEtude.dbf" "SurfaceZoneEtude.prj" [71] 
>"SurfaceZoneEtude.shp" "SurfaceZoneEtude.shx" [73]
>"transects_camp.Rdata"
>
>
>How can I get all the files, only these files, suffixed with ".r" ?
>
>Thanks in advance,
>
>------------------------------------------------------------------------
>
>
>> dir() [1] "Analyse_190523_baseline_190523_1506.docx" 
>"Analyse_190523_baseline_190531_2110.docx" [3] 
>"Analyse_190523_baseline_190531_2110.Rmd"
>"Analyse_190531_baseline.docx" 
>[5] "Analyse_190531_baseline.Rmd" "Analyse_190531_baseline_cache" [7] 
>"Analyse_190531_baseline_files" "Analyse_190603_spatial.docx" [9] 
>"Analyse_190603_spatial.Rmd" "Analyse_190603_spatial_cache" [11] 
>"Analyse_190603_spatial_files" "Article Predation" [13] "BD Carto" 
>"Biblio" [15] "broma1.txt" "broma3.txt" [17]
>"BromaBusesMilanMicha.xlsx" 
>"Bromadiolone" [19] "BufferRenard.dbf" "BufferRenard.prj" [21] 
>"BufferRenard.shp" "BufferRenard.shx" [23] "clpboard"
>"DatesDiurnes.txt" 
>[25] "DatesDiurnes_plus.txt" "DatesDiurnes_plus.xlsx" [27] 
>"DatesDiurnesFREDON" "DatesDiurnesFREDON_plus.txt" [29] 
>"DatesDiurnesFREDON_plus.xlsx" "DatesDiurnesRegis.txt" [31] 
>"DatesDiurnesRegis_plus.txt" "DatesDiurnesRegis_plus.xlsx" [33] 
>"DatesNocturnes.txt" "DatesNocturnes_plus.txt" [35] 
>"DatesNocturnes_plus.xlsx" "DatesNocturnesFREDON" [37] 
>"DatesNocturnesFREDON_plus.txt" "DatesNocturnesFREDON_plus.xlsx" [39] 
>"DatesNocturnesRegis.txt" "DatesNocturnesRegis_plus.txt" [41] 
>"DatesNocturnesRegis_plus.xlsx" "Figures" [43] "IKAZ_old.zip" 
>"IKAZ1999.txt" [45] "IKAZ2000.txt" "IKAZ2007.txt" [47] "IKAZ2008.txt" 
>"IKAZ2009.txt" [49] "IKAZ2010.txt" "IKAZ2011.txt" [51] "IKAZ2012.txt" 
>"IKAZ2013.txt" [53] "IKAZ2014.txt" "IKAZ2015.txt" [55] "IKAZ2016.txt" 
>"IKAZ2017.txt" [57] "IKAZ2018.txt" "ParcBuf300n.dbf" [59] 
>"ParcBuf300n.prj" "ParcBuf300n.shp" [61] "ParcBuf300n.shx" 
>"ParcBuf350n.dbf" [63] "ParcBuf350n.prj" "ParcBuf350n.shp" [65] 
>"ParcBuf350n.shx" "Photos ZELAC" [67] "plot.ds.R" "plot.dsmodel.R" [69]
>
>"RData" "Script_190517_preparation.r" [71] "Script_190518_scores_AT.r" 
>"Script_190519_1430_cinetiques_IKA.r" [73] 
>"Script_190519_1622_transects_camp.r" 
>"Script_190530_1700_preparation2.r" [75] 
>"Script_190530_1903_cinetiques_IKA2.r"
>"Script_190531_0922_scores_AT2.r" 
>[77] "Script_190531_1729_prey_resource.r" 
>"Script_190601_1509_graphIKAd.r" [79] 
>"Script_190601_1509_graphIKAd_old.r" "Script_190601_1509_graphIKAn.r" 
>[81] "Script_190601_1509_graphIKAn_old.r"
>"Script_190601_1955_spatial.r" 
>[83] "Script_190708_0930_distance.r" "Script_190709_0930_impact 
>renard.r" [85] "Script_200117_cinetiques_article.r" 
>"Script_200119_source_stats_explore_diurne.r" [87] 
>"Script_200119_stats.r" "Script_200122_spatial_distribution.r" [89] 
>"Script_200124_distance.r" "Script_200124_distance_source_d.r" [91] 
>"Script_200124_distance_source_n.r" "Script_200201_impacts_on_prey.R" 
>[93] "ScriptCompteLignes.r" "Scripts_avant_200112.zip" [95] "shinyChim"
>
>"ShinyConnect.R" [97] "shinyPred" "StudyArea.dbf" [99] "StudyArea.prj" 
>"StudyArea.shp" [101] "StudyArea.shx" "SurfaceZoneEtude.dbf" [103] 
>"SurfaceZoneEtude.prj" "SurfaceZoneEtude.shp" [105] 
>"SurfaceZoneEtude.shx" "transects_camp.Rdata"
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From p@tr|ck@g|r@udoux @end|ng |rom un|v-|comte@|r  Fri Feb 28 18:54:48 2020
From: p@tr|ck@g|r@udoux @end|ng |rom un|v-|comte@|r (Patrick Giraudoux)
Date: Fri, 28 Feb 2020 18:54:48 +0100
Subject: [R] dir and pattern = ".r"
In-Reply-To: <87v9nq8vno.fsf@gmail.com>
References: <dd3288f1-2a20-4e08-5218-4aa5d553eb7f@univ-fcomte.fr>
 <87v9nq8vno.fsf@gmail.com>
Message-ID: <9b12d32d-9fd3-8ffe-333a-0493565e8db9@univ-fcomte.fr>

Ups... Thank you both. Indeed I must repeat lessons on regular 
expression... obviously forgotten...


Le 28/02/2020 ? 18:32, Jeremie Juste a ?crit?:
> Hello,
>
> you need
>> dir(pattern="\\.r$",ignore.case=TRUE)
> remember that the pattern is a regular expression.
> so ".r" is [any single character]r. So basically it will give you any
> file that contains r (but not that starts with r)
>
>
> so you got what you expected with
>>   dir(pattern=".txt")
> just by chance. as <rtxt.r> or <rtxt.pdf>  would have been printed as well
>
> HTH,
>
> Jeremie
>
>
>> I have this directory contain listed at the page bottom
>>
>> Can somebody tell me why with
>>
>> dir(pattern = ".txt")
>>
>> dir(pattern = ".dbf")
>>
>> etc.
>>
>> I get exactly what I want (a vector with the file names correctly
>> suffixed), but with
>>
>> dir(pattern = ".r")
>>
>> I get this:
>>
>>> dir(pattern=".r") [1] "Article Predation" "BD Carto" [3] "broma1.txt"
>> "broma3.txt" [5] "BromaBusesMilanMicha.xlsx" "Bromadiolone" [7]
>> "BufferRenard.dbf" "BufferRenard.prj" [9] "BufferRenard.shp"
>> "BufferRenard.shx" [11] "clpboard" "DatesDiurnes.txt" [13]
>> "DatesDiurnes_plus.txt" "DatesDiurnes_plus.xlsx" [15]
>> "DatesDiurnesFREDON" "DatesDiurnesFREDON_plus.txt" [17]
>> "DatesDiurnesFREDON_plus.xlsx" "DatesDiurnesRegis.txt" [19]
>> "DatesDiurnesRegis_plus.txt" "DatesDiurnesRegis_plus.xlsx" [21]
>> "DatesNocturnes.txt" "DatesNocturnes_plus.txt" [23]
>> "DatesNocturnes_plus.xlsx" "DatesNocturnesFREDON" [25]
>> "DatesNocturnesFREDON_plus.txt" "DatesNocturnesFREDON_plus.xlsx" [27]
>> "DatesNocturnesRegis.txt" "DatesNocturnesRegis_plus.txt" [29]
>> "DatesNocturnesRegis_plus.xlsx" "Figures" [31] "ParcBuf300n.dbf"
>> "ParcBuf300n.prj" [33] "ParcBuf300n.shp" "ParcBuf300n.shx" [35]
>> "ParcBuf350n.dbf" "ParcBuf350n.prj" [37] "ParcBuf350n.shp"
>> "ParcBuf350n.shx" [39] "Script_190517_preparation.r"
>> "Script_190518_scores_AT.r" [41] "Script_190519_1430_cinetiques_IKA.r"
>> "Script_190519_1622_transects_camp.r" [43]
>> "Script_190530_1700_preparation2.r"
>> "Script_190530_1903_cinetiques_IKA2.r" [45]
>> "Script_190531_0922_scores_AT2.r" "Script_190531_1729_prey_resource.r"
>> [47] "Script_190601_1509_graphIKAd.r"
>> "Script_190601_1509_graphIKAd_old.r" [49]
>> "Script_190601_1509_graphIKAn.r" "Script_190601_1509_graphIKAn_old.r"
>> [51] "Script_190601_1955_spatial.r" "Script_190708_0930_distance.r" [53]
>> "Script_190709_0930_impact renard.r"
>> "Script_200117_cinetiques_article.r" [55]
>> "Script_200119_source_stats_explore_diurne.r" "Script_200119_stats.r"
>> [57] "Script_200122_spatial_distribution.r" "Script_200124_distance.r"
>> [59] "Script_200124_distance_source_d.r"
>> "Script_200124_distance_source_n.r" [61]
>> "Script_200201_impacts_on_prey.R" "ScriptCompteLignes.r" [63]
>> "Scripts_avant_200112.zip" "shinyPred" [65] "StudyArea.dbf"
>> "StudyArea.prj" [67] "StudyArea.shp" "StudyArea.shx" [69]
>> "SurfaceZoneEtude.dbf" "SurfaceZoneEtude.prj" [71]
>> "SurfaceZoneEtude.shp" "SurfaceZoneEtude.shx" [73] "transects_camp.Rdata"
>>
>> How can I get all the files, only these files, suffixed with ".r" ?
>>
>> Thanks in advance,
>>
>> ------------------------------------------------------------------------
>>
>>> dir() [1] "Analyse_190523_baseline_190523_1506.docx"
>> "Analyse_190523_baseline_190531_2110.docx" [3]
>> "Analyse_190523_baseline_190531_2110.Rmd" "Analyse_190531_baseline.docx"
>> [5] "Analyse_190531_baseline.Rmd" "Analyse_190531_baseline_cache" [7]
>> "Analyse_190531_baseline_files" "Analyse_190603_spatial.docx" [9]
>> "Analyse_190603_spatial.Rmd" "Analyse_190603_spatial_cache" [11]
>> "Analyse_190603_spatial_files" "Article Predation" [13] "BD Carto"
>> "Biblio" [15] "broma1.txt" "broma3.txt" [17] "BromaBusesMilanMicha.xlsx"
>> "Bromadiolone" [19] "BufferRenard.dbf" "BufferRenard.prj" [21]
>> "BufferRenard.shp" "BufferRenard.shx" [23] "clpboard" "DatesDiurnes.txt"
>> [25] "DatesDiurnes_plus.txt" "DatesDiurnes_plus.xlsx" [27]
>> "DatesDiurnesFREDON" "DatesDiurnesFREDON_plus.txt" [29]
>> "DatesDiurnesFREDON_plus.xlsx" "DatesDiurnesRegis.txt" [31]
>> "DatesDiurnesRegis_plus.txt" "DatesDiurnesRegis_plus.xlsx" [33]
>> "DatesNocturnes.txt" "DatesNocturnes_plus.txt" [35]
>> "DatesNocturnes_plus.xlsx" "DatesNocturnesFREDON" [37]
>> "DatesNocturnesFREDON_plus.txt" "DatesNocturnesFREDON_plus.xlsx" [39]
>> "DatesNocturnesRegis.txt" "DatesNocturnesRegis_plus.txt" [41]
>> "DatesNocturnesRegis_plus.xlsx" "Figures" [43] "IKAZ_old.zip"
>> "IKAZ1999.txt" [45] "IKAZ2000.txt" "IKAZ2007.txt" [47] "IKAZ2008.txt"
>> "IKAZ2009.txt" [49] "IKAZ2010.txt" "IKAZ2011.txt" [51] "IKAZ2012.txt"
>> "IKAZ2013.txt" [53] "IKAZ2014.txt" "IKAZ2015.txt" [55] "IKAZ2016.txt"
>> "IKAZ2017.txt" [57] "IKAZ2018.txt" "ParcBuf300n.dbf" [59]
>> "ParcBuf300n.prj" "ParcBuf300n.shp" [61] "ParcBuf300n.shx"
>> "ParcBuf350n.dbf" [63] "ParcBuf350n.prj" "ParcBuf350n.shp" [65]
>> "ParcBuf350n.shx" "Photos ZELAC" [67] "plot.ds.R" "plot.dsmodel.R" [69]
>> "RData" "Script_190517_preparation.r" [71] "Script_190518_scores_AT.r"
>> "Script_190519_1430_cinetiques_IKA.r" [73]
>> "Script_190519_1622_transects_camp.r"
>> "Script_190530_1700_preparation2.r" [75]
>> "Script_190530_1903_cinetiques_IKA2.r" "Script_190531_0922_scores_AT2.r"
>> [77] "Script_190531_1729_prey_resource.r"
>> "Script_190601_1509_graphIKAd.r" [79]
>> "Script_190601_1509_graphIKAd_old.r" "Script_190601_1509_graphIKAn.r"
>> [81] "Script_190601_1509_graphIKAn_old.r" "Script_190601_1955_spatial.r"
>> [83] "Script_190708_0930_distance.r" "Script_190709_0930_impact
>> renard.r" [85] "Script_200117_cinetiques_article.r"
>> "Script_200119_source_stats_explore_diurne.r" [87]
>> "Script_200119_stats.r" "Script_200122_spatial_distribution.r" [89]
>> "Script_200124_distance.r" "Script_200124_distance_source_d.r" [91]
>> "Script_200124_distance_source_n.r" "Script_200201_impacts_on_prey.R"
>> [93] "ScriptCompteLignes.r" "Scripts_avant_200112.zip" [95] "shinyChim"
>> "ShinyConnect.R" [97] "shinyPred" "StudyArea.dbf" [99] "StudyArea.prj"
>> "StudyArea.shp" [101] "StudyArea.shx" "SurfaceZoneEtude.dbf" [103]
>> "SurfaceZoneEtude.prj" "SurfaceZoneEtude.shp" [105]
>> "SurfaceZoneEtude.shx" "transects_camp.Rdata"
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ton|ght@then|ght @end|ng |rom gm@||@com  Fri Feb 28 19:47:13 2020
From: ton|ght@then|ght @end|ng |rom gm@||@com (Sam Albers)
Date: Fri, 28 Feb 2020 10:47:13 -0800
Subject: [R] file.access returning -1 for a file on remote Windows drive.
Message-ID: <CADkXsV3aaDdh-ds6iAuye-CsVvqjc=FAkM7cB=PVjUc1SxNwzg@mail.gmail.com>

Hi there,

Looking for some help in diagnosing or developing a work around to a
problem I am having on a Windows machine. I am running R 3.6.2.

I have two identical files, one stored locally and the other stored on
a network drive.

For access:

> file.access(local_file, 4)
local.R
         0

> file.access(remote_file, 4)
remote.R
            -1

Also for file.info

> file.info(local_file)$mode:
[1] "666"

> file.info(remote_file)$mode:
[1] "666"

Ok so I am access issues. Maybe they are ephemeral and I can change
the permissions:

> Sys.chmod('remote.R', mode = '666')
> file.access(remote_file, 4)
remote.R
            -1

Nope. I am thoroughly stumped and maybe can't make it any further
because of Windows.

Downstream I am trying to use digest::digest to create a hash but
digest thinks we don't have permission because file.access is failing.
Any thoughts on how I can get file.access to return 0 for the remote.R
file? Any ideas?

Thanks in advance,

Sam


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Feb 28 20:16:18 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 28 Feb 2020 13:16:18 -0600
Subject: [R] qq plot issue with ab line
Message-ID: <CAF9-5jN7cbmWVuBZW9wrK4YFmeMiDMohjXzDX2XeG8CbMFQnEw@mail.gmail.com>

Hello,

I made the plot in attach with this function:

qqunif = function(p, BH=T, MAIN = " ", SUB=" ")
{
  nn = length(p)
  xx =  -log10((1:nn)/(nn+1))
  plot( xx,  -sort(log10(p)),
        main = MAIN, sub= SUB, cex.sub=1.3,
        xlab=expression(Expected~~-log[10](italic(p))),
        ylab=expression(Observed~~-log[10](italic(p))),
        cex.lab=1.0,mgp=c(2,1,0))
  abline(0,1,col='red')
  if(BH) ## BH = include Benjamini Hochberg FDR
  {

    abline(-log10(0.05),1, col='black',lty=1)
    text(0.5,1.9 , "FDR=0.05", col = "gray60",srt=20, cex=1)
    abline(-log10(0.10),1, col='black',lty=1)
    text(0.5, 1.6, "FDR=0.10", col = "gray60",srt=20, cex=1)
    abline(-log10(0.25),1, col='black',lty=1)
    text(0.5, 1.2, "FDR=0.25", col = "gray60",srt=20, cex=1)
    #legend('topleft', c("FDR = 0.05","FDR = 0.10","FDR = 0.25"),
           #col=c('black','black','black'),lty=c(1,1,1), cex=0.8)
    if (BF)
    {
      abline(h=-log10(0.05/nn), col='black') ## bonferroni
    }
  }
}


biob272=read.table("/Users/ams/Desktop/biobank272LD.txt")
qqunif(biob272$V2)


> head(biob272)
         V1       V2
1 rs2089177 0.581204
2 rs4360974 0.418456
3 rs6502526 0.416670
4 rs8069906 0.568030
5 rs9895995 0.266746
6 rs9905280 0.510032

But the red, abline doesn't look like it is 1:1 line.

Can you please advise?

Thanks
Ana

-------------- next part --------------
A non-text attachment was scrubbed...
Name: qqpl.png
Type: image/png
Size: 89152 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200228/2d4ffabf/attachment.png>

From @purd|e@@ @end|ng |rom gm@||@com  Fri Feb 28 20:11:51 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 29 Feb 2020 08:11:51 +1300
Subject: [R] Help to solve modeling problem with gamm
In-Reply-To: <BY5PR08MB636000B68CAC0630EB55A67EBDE80@BY5PR08MB6360.namprd08.prod.outlook.com>
References: <BY5PR08MB636000B68CAC0630EB55A67EBDE80@BY5PR08MB6360.namprd08.prod.outlook.com>
Message-ID: <CAB8pepyzXdME7zcDdoVO08E8e7TQBtN2m9de9zJjNBkHnF6EEA@mail.gmail.com>

> There was clearly a non-linear growth pattern such that an additive mixed effects model was proposed to model the behavior of biomass as a function of time and treatments.

The presence of non-linearity (in x) does not necessarily mean that
you can't use a "linear model".
In general, linear models work well for biological growth curves with
small to medium sized data.

Technically, this is off topic, however, the notion of what is linear
and what is not linear, is a recurring theme on this mailing list.

> When plotting the residuals a clear cone-shaped pattern was observed

Based on classical statistics, the obvious approach is to transform your data.
This is easy to do, however, some expertise is required to
back-transform parameters/estimates and interpret them.

While you're welcome to seek advice on mailing lists, I'd recommend
you consult a biostatistician.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Feb 28 21:15:11 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 28 Feb 2020 20:15:11 +0000
Subject: [R] Help with ggplot plot
In-Reply-To: <DM6PR02MB5657451E2E0999B0B675C58DEAE80@DM6PR02MB5657.namprd02.prod.outlook.com>
References: <DM6PR02MB5657B3C44E5EA7A957BE795EEAE80@DM6PR02MB5657.namprd02.prod.outlook.com>
 <8db24a57-e616-f842-420d-07a8080c1c11@sapo.pt>
 <DM6PR02MB5657451E2E0999B0B675C58DEAE80@DM6PR02MB5657.namprd02.prod.outlook.com>
Message-ID: <e4831177-edfc-07ab-41af-d8c7e4ad0fb2@sapo.pt>

Hello,

Now I'm not understanding, you want the values in the bars? The numbers?


ggplot(tmp, aes(x = Region, y = ProductLineID, fill = ProductLineFlag)) +
   geom_col() +
   geom_text(aes(label = ProductLineID),
             position = position_stack(vjust = 0.5), size = 3) +
   facet_grid(~InOutFlagAlpha)



Hope this helps,

Rui Barradas

?s 17:38 de 28/02/20, Bill Poling escreveu:
> Hi Rui, thank you this is helpful, however, I would like the values in the or above the bars.
> 
> I have tried 'dodge' but not working correctly.
> 
> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) + #Getting worse again
>      geom_bar(stat ="identity")  +
>      geom_col(position = 'dodge')  +
>      facet_grid("InOutFlagAlpha")
> 
> Thoughts?
> 
> WHP
> 
> From: Rui Barradas <ruipbarradas at sapo.pt>
> Sent: Friday, February 28, 2020 11:06 AM
> To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
> Subject: Re: [R] Help with ggplot plot
> 
> [External Email]
> Hello,
> 
> If you want faceting, a square grid can do it.
> 
> 
> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
> geom_bar(stat = "identity") +
> facet_grid(InOutFlagAlpha ~ ProductLineFlag)
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 16:50 de 28/02/20, Bill Poling escreveu:
>> #RStudio Version 1.2.5019
>> sessionInfo()
>> # R version 3.6.2 (2019-12-12)
>> #Platform: x86_64-w64-mingw32/x64 (64-bit)
>> #Running under: Windows 10 x64 (build 17134)
>>
>> Hello, I am sure I am missing something simple.
>>
>> Here is my data, its aggregated and if need be I can unaggregate I guess:
>>
>> dput(tmp)
>> structure(list(InOutFlagAlpha = c("NO ", "YES", "NO ", "YES",
>> "NO ", "YES", "NO ", "YES", "NO ", "YES", "NO ", "YES", "NO ",
>> "YES", "NO ", "YES", "NO ", "YES", "NO ", "YES"), ProductLineFlag = structure(c(1L,
>> 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L,
>> 1L, 2L, 2L), .Label = c("ACH", "CARD"), class = "factor"), Region = structure(c(1L,
>> 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L,
>> 5L, 5L, 5L), .Label = c("Frontier", "Midwest", "Northeast", "Pacific",
>> "South"), class = "factor"), ProductLineID = c(7163L, 34212L,
>> 35891L, 54177L, 8873L, 34008L, 52017L, 67881L, 7408L, 29430L,
>> 64108L, 70532L, 5984L, 21720L, 49030L, 60211L, 7330L, 34876L,
>> 46387L, 75893L)), row.names = c(NA, -20L), class = "data.frame")
>>
>> |InOutFlagAlpha |ProductLineFlag | Region| ProductLineID|
>> |:--------------|:---------------|---------:|-------------:|
>> |NO |ACH | Frontier| 7163|
>> |YES |ACH | Frontier| 34212|
>> |NO |CARD | Frontier| 35891|
>> |YES |CARD | Frontier| 54177|
>> |NO |ACH | Midwest| 8873|
>> |YES |ACH | Midwest| 34008|
>> |NO |CARD | Midwest| 52017|
>> |YES |CARD | Midwest| 67881|
>> |NO |ACH | Northeast| 7408|
>> |YES |ACH | Northeast| 29430|
>> |NO |CARD | Northeast| 64108|
>> |YES |CARD | Northeast| 70532|
>> |NO |ACH | Pacific| 5984|
>> |YES |ACH | Pacific| 21720|
>> |NO |CARD | Pacific| 49030|
>> |YES |CARD | Pacific| 60211|
>> |NO |ACH | South| 7330|
>> |YES |ACH | South| 34876|
>> |NO |CARD | South| 46387|
>> |YES |CARD | South| 75893|
>>
>> I am trying to get the value from ProductLineID into the bars
>>
>> I have slowly stepped through to the point of having everything but the values.
>>
>> Appreciate any advice, thank you.
>>
>> WHP
>>
>> #1
>> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
>> geom_bar(stat = "identity")
>> #2
>> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
>> geom_bar(stat = "identity") +
>> facet_grid("InOutFlagAlpha")
>> #3
>> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
>> geom_bar(stat ="identity") +
>> facet_grid("InOutFlagAlpha")
>> #4
>> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
>> geom_bar(stat ="identity",position = 'dodge') +
>> facet_grid("InOutFlagAlpha")
>> #5
>> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) +
>> geom_bar(stat ="identity",position = 'dodge') +
>> facet_grid("InOutFlagAlpha")
>> #6
>> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) + #Best so far
>> geom_bar(stat ="identity") +
>> geom_col() +
>> facet_grid("InOutFlagAlpha")
>> #7
>> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) + #Not working
>> geom_bar(stat ="identity") +
>> geom_col(position = 'dodge') +
>> facet_grid("InOutFlagAlpha")
>>
>> WHP
>>
>>
>> Confidentiality Notice\ \ This email and the attachments...{{dropped:11}}
>>
>> ______________________________________________
>> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> Confidentiality Notice
> 
> This email and the attachments may contain information which is privileged and/or confidential and is intended for the business and/or confidential use of the recipient only. Such information may be protected by applicable State and/or Federal laws from disclosure or unauthorized use. If you are not the intended recipient, you are hereby notified that any disclosure is strictly prohibited. If you have received this email in error, please contact the sender immediately.
>


From B|||@Po||ng @end|ng |rom ze||@@com  Fri Feb 28 21:44:18 2020
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Fri, 28 Feb 2020 20:44:18 +0000
Subject: [R] Help with ggplot plot
In-Reply-To: <e4831177-edfc-07ab-41af-d8c7e4ad0fb2@sapo.pt>
References: <DM6PR02MB5657B3C44E5EA7A957BE795EEAE80@DM6PR02MB5657.namprd02.prod.outlook.com>
 <8db24a57-e616-f842-420d-07a8080c1c11@sapo.pt>
 <DM6PR02MB5657451E2E0999B0B675C58DEAE80@DM6PR02MB5657.namprd02.prod.outlook.com>
 <e4831177-edfc-07ab-41af-d8c7e4ad0fb2@sapo.pt>
Message-ID: <DM6PR02MB565750C9760EE8DA2EF95DCDEAE80@DM6PR02MB5657.namprd02.prod.outlook.com>

Hello Rui, this is it, thank you very much, sorry if my request was confusing.

WHP


From: Rui Barradas <ruipbarradas at sapo.pt>
Sent: Friday, February 28, 2020 2:15 PM
To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with ggplot plot

[External Email]
Hello,

Now I'm not understanding, you want the values in the bars? The numbers?


ggplot(tmp, aes(x = Region, y = ProductLineID, fill = ProductLineFlag)) +
geom_col() +
geom_text(aes(label = ProductLineID),
position = position_stack(vjust = 0.5), size = 3) +
facet_grid(~InOutFlagAlpha)



Hope this helps,

Rui Barradas

?s 17:38 de 28/02/20, Bill Poling escreveu:
> Hi Rui, thank you this is helpful, however, I would like the values in the or above the bars.
>
> I have tried 'dodge' but not working correctly.
>
> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) + #Getting worse again
> geom_bar(stat ="identity") +
> geom_col(position = 'dodge') +
> facet_grid("InOutFlagAlpha")
>
> Thoughts?
>
> WHP
>
> From: Rui Barradas <mailto:ruipbarradas at sapo.pt>
> Sent: Friday, February 28, 2020 11:06 AM
> To: Bill Poling <mailto:Bill.Poling at zelis.com>; r-help (mailto:r-help at r-project.org) <mailto:r-help at r-project.org>
> Subject: Re: [R] Help with ggplot plot
>
> [External Email]
> Hello,
>
> If you want faceting, a square grid can do it.
>
>
> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
> geom_bar(stat = "identity") +
> facet_grid(InOutFlagAlpha ~ ProductLineFlag)
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 16:50 de 28/02/20, Bill Poling escreveu:
>> #RStudio Version 1.2.5019
>> sessionInfo()
>> # R version 3.6.2 (2019-12-12)
>> #Platform: x86_64-w64-mingw32/x64 (64-bit)
>> #Running under: Windows 10 x64 (build 17134)
>>
>> Hello, I am sure I am missing something simple.
>>
>> Here is my data, its aggregated and if need be I can unaggregate I guess:
>>
>> dput(tmp)
>> structure(list(InOutFlagAlpha = c("NO ", "YES", "NO ", "YES",
>> "NO ", "YES", "NO ", "YES", "NO ", "YES", "NO ", "YES", "NO ",
>> "YES", "NO ", "YES", "NO ", "YES", "NO ", "YES"), ProductLineFlag = structure(c(1L,
>> 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L,
>> 1L, 2L, 2L), .Label = c("ACH", "CARD"), class = "factor"), Region = structure(c(1L,
>> 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L,
>> 5L, 5L, 5L), .Label = c("Frontier", "Midwest", "Northeast", "Pacific",
>> "South"), class = "factor"), ProductLineID = c(7163L, 34212L,
>> 35891L, 54177L, 8873L, 34008L, 52017L, 67881L, 7408L, 29430L,
>> 64108L, 70532L, 5984L, 21720L, 49030L, 60211L, 7330L, 34876L,
>> 46387L, 75893L)), row.names = c(NA, -20L), class = "data.frame")
>>
>> |InOutFlagAlpha |ProductLineFlag | Region| ProductLineID|
>> |:--------------|:---------------|---------:|-------------:|
>> |NO |ACH | Frontier| 7163|
>> |YES |ACH | Frontier| 34212|
>> |NO |CARD | Frontier| 35891|
>> |YES |CARD | Frontier| 54177|
>> |NO |ACH | Midwest| 8873|
>> |YES |ACH | Midwest| 34008|
>> |NO |CARD | Midwest| 52017|
>> |YES |CARD | Midwest| 67881|
>> |NO |ACH | Northeast| 7408|
>> |YES |ACH | Northeast| 29430|
>> |NO |CARD | Northeast| 64108|
>> |YES |CARD | Northeast| 70532|
>> |NO |ACH | Pacific| 5984|
>> |YES |ACH | Pacific| 21720|
>> |NO |CARD | Pacific| 49030|
>> |YES |CARD | Pacific| 60211|
>> |NO |ACH | South| 7330|
>> |YES |ACH | South| 34876|
>> |NO |CARD | South| 46387|
>> |YES |CARD | South| 75893|
>>
>> I am trying to get the value from ProductLineID into the bars
>>
>> I have slowly stepped through to the point of having everything but the values.
>>
>> Appreciate any advice, thank you.
>>
>> WHP
>>
>> #1
>> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
>> geom_bar(stat = "identity")
>> #2
>> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
>> geom_bar(stat = "identity") +
>> facet_grid("InOutFlagAlpha")
>> #3
>> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
>> geom_bar(stat ="identity") +
>> facet_grid("InOutFlagAlpha")
>> #4
>> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=Region)) +
>> geom_bar(stat ="identity",position = 'dodge') +
>> facet_grid("InOutFlagAlpha")
>> #5
>> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) +
>> geom_bar(stat ="identity",position = 'dodge') +
>> facet_grid("InOutFlagAlpha")
>> #6
>> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) + #Best so far
>> geom_bar(stat ="identity") +
>> geom_col() +
>> facet_grid("InOutFlagAlpha")
>> #7
>> ggplot(tmp, aes(x=Region, y=ProductLineID, fill=ProductLineFlag)) + #Not working
>> geom_bar(stat ="identity") +
>> geom_col(position = 'dodge') +
>> facet_grid("InOutFlagAlpha")
>>
>> WHP
>>
>>
>> Confidentiality Notice\ \ This email and the attachments...{{dropped:11}}
>>
>> ______________________________________________
>> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> Confidentiality Notice
>
> This email and the attachments may contain information which is privileged and/or confidential and is intended for the business and/or confidential use of the recipient only. Such information may be protected by applicable State and/or Federal laws from disclosure or unauthorized use. If you are not the intended recipient, you are hereby notified that any disclosure is strictly prohibited. If you have received this email in error, please contact the sender immediately.
>

Confidentiality Notice

This email and the attachments may contain information which is privileged and/or confidential and is intended for the business and/or confidential use of the recipient only. Such information may be protected by applicable State and/or Federal laws from disclosure or unauthorized use. If you are not the intended recipient, you are hereby notified that any disclosure is strictly prohibited. If you have received this email in error, please contact the sender immediately.

From drj|m|emon @end|ng |rom gm@||@com  Fri Feb 28 22:34:40 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 29 Feb 2020 08:34:40 +1100
Subject: [R] qq plot issue with ab line
In-Reply-To: <CAF9-5jN7cbmWVuBZW9wrK4YFmeMiDMohjXzDX2XeG8CbMFQnEw@mail.gmail.com>
References: <CAF9-5jN7cbmWVuBZW9wrK4YFmeMiDMohjXzDX2XeG8CbMFQnEw@mail.gmail.com>
Message-ID: <CA+8X3fUBQKTLZdZcAnvx3PLzv3RKZGLTTvC=8=NdW9GW9V+LJA@mail.gmail.com>

Hi Ana,
Look carefully at that red line. It goes through (0,0) and scoots off
the plot at (2.5,2.5). As you have specified that intercept and slope
in your code, poor abline is doing the best it can. Do not punish it
for doing what you request.

Jim

On Sat, Feb 29, 2020 at 6:10 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I made the plot in attach with this function:
>
> qqunif = function(p, BH=T, MAIN = " ", SUB=" ")
> {
>   nn = length(p)
>   xx =  -log10((1:nn)/(nn+1))
>   plot( xx,  -sort(log10(p)),
>         main = MAIN, sub= SUB, cex.sub=1.3,
>         xlab=expression(Expected~~-log[10](italic(p))),
>         ylab=expression(Observed~~-log[10](italic(p))),
>         cex.lab=1.0,mgp=c(2,1,0))
>   abline(0,1,col='red')
>   if(BH) ## BH = include Benjamini Hochberg FDR
>   {
>
>     abline(-log10(0.05),1, col='black',lty=1)
>     text(0.5,1.9 , "FDR=0.05", col = "gray60",srt=20, cex=1)
>     abline(-log10(0.10),1, col='black',lty=1)
>     text(0.5, 1.6, "FDR=0.10", col = "gray60",srt=20, cex=1)
>     abline(-log10(0.25),1, col='black',lty=1)
>     text(0.5, 1.2, "FDR=0.25", col = "gray60",srt=20, cex=1)
>     #legend('topleft', c("FDR = 0.05","FDR = 0.10","FDR = 0.25"),
>            #col=c('black','black','black'),lty=c(1,1,1), cex=0.8)
>     if (BF)
>     {
>       abline(h=-log10(0.05/nn), col='black') ## bonferroni
>     }
>   }
> }
>
>
> biob272=read.table("/Users/ams/Desktop/biobank272LD.txt")
> qqunif(biob272$V2)
>
>
> > head(biob272)
>          V1       V2
> 1 rs2089177 0.581204
> 2 rs4360974 0.418456
> 3 rs6502526 0.416670
> 4 rs8069906 0.568030
> 5 rs9895995 0.266746
> 6 rs9905280 0.510032
>
> But the red, abline doesn't look like it is 1:1 line.
>
> Can you please advise?
>
> Thanks
> Ana
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Feb 28 22:48:03 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 28 Feb 2020 15:48:03 -0600
Subject: [R] qq plot issue with ab line
In-Reply-To: <CA+8X3fUBQKTLZdZcAnvx3PLzv3RKZGLTTvC=8=NdW9GW9V+LJA@mail.gmail.com>
References: <CAF9-5jN7cbmWVuBZW9wrK4YFmeMiDMohjXzDX2XeG8CbMFQnEw@mail.gmail.com>
 <CA+8X3fUBQKTLZdZcAnvx3PLzv3RKZGLTTvC=8=NdW9GW9V+LJA@mail.gmail.com>
Message-ID: <CAF9-5jM_RisPF8gf5LZrJvS8hF0Wi+_T-J63E-T_W25k=4Pnow@mail.gmail.com>

Hi Jim,

I have in my code:
abline(0,1,col='red')

can you please tell me how to change my code to have it indeed running
from 0 to 1?

Thanks
Ana

On Fri, Feb 28, 2020 at 3:34 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Ana,
> Look carefully at that red line. It goes through (0,0) and scoots off
> the plot at (2.5,2.5). As you have specified that intercept and slope
> in your code, poor abline is doing the best it can. Do not punish it
> for doing what you request.
>
> Jim
>
> On Sat, Feb 29, 2020 at 6:10 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hello,
> >
> > I made the plot in attach with this function:
> >
> > qqunif = function(p, BH=T, MAIN = " ", SUB=" ")
> > {
> >   nn = length(p)
> >   xx =  -log10((1:nn)/(nn+1))
> >   plot( xx,  -sort(log10(p)),
> >         main = MAIN, sub= SUB, cex.sub=1.3,
> >         xlab=expression(Expected~~-log[10](italic(p))),
> >         ylab=expression(Observed~~-log[10](italic(p))),
> >         cex.lab=1.0,mgp=c(2,1,0))
> >   abline(0,1,col='red')
> >   if(BH) ## BH = include Benjamini Hochberg FDR
> >   {
> >
> >     abline(-log10(0.05),1, col='black',lty=1)
> >     text(0.5,1.9 , "FDR=0.05", col = "gray60",srt=20, cex=1)
> >     abline(-log10(0.10),1, col='black',lty=1)
> >     text(0.5, 1.6, "FDR=0.10", col = "gray60",srt=20, cex=1)
> >     abline(-log10(0.25),1, col='black',lty=1)
> >     text(0.5, 1.2, "FDR=0.25", col = "gray60",srt=20, cex=1)
> >     #legend('topleft', c("FDR = 0.05","FDR = 0.10","FDR = 0.25"),
> >            #col=c('black','black','black'),lty=c(1,1,1), cex=0.8)
> >     if (BF)
> >     {
> >       abline(h=-log10(0.05/nn), col='black') ## bonferroni
> >     }
> >   }
> > }
> >
> >
> > biob272=read.table("/Users/ams/Desktop/biobank272LD.txt")
> > qqunif(biob272$V2)
> >
> >
> > > head(biob272)
> >          V1       V2
> > 1 rs2089177 0.581204
> > 2 rs4360974 0.418456
> > 3 rs6502526 0.416670
> > 4 rs8069906 0.568030
> > 5 rs9895995 0.266746
> > 6 rs9905280 0.510032
> >
> > But the red, abline doesn't look like it is 1:1 line.
> >
> > Can you please advise?
> >
> > Thanks
> > Ana
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From ton|ght@then|ght @end|ng |rom gm@||@com  Fri Feb 28 23:06:34 2020
From: ton|ght@then|ght @end|ng |rom gm@||@com (Sam Albers)
Date: Fri, 28 Feb 2020 14:06:34 -0800
Subject: [R] 
 file.access returning -1 for a file on remote Windows drive.
In-Reply-To: <CADkXsV3aaDdh-ds6iAuye-CsVvqjc=FAkM7cB=PVjUc1SxNwzg@mail.gmail.com>
References: <CADkXsV3aaDdh-ds6iAuye-CsVvqjc=FAkM7cB=PVjUc1SxNwzg@mail.gmail.com>
Message-ID: <CADkXsV3-gDmNioeeKKXa7iy_wqQwW=ziVK4O5Ly--=N6BLCV_g@mail.gmail.com>

Some additional follow-up:

> summary(file(remote_file, "rb"))$`can read`
[1] "yes"

> summary(file(local_file, "rb"))$`can read`
[1] "yes"

compared to:

> file.access(local_file, 4)
local.R
         0

> file.access(remote_file, 4)
remote.R
            -1

Can anyone think why file.access and file would be contradicting each other?

Sam

On Fri, Feb 28, 2020 at 10:47 AM Sam Albers <tonightsthenight at gmail.com> wrote:
>
> Hi there,
>
> Looking for some help in diagnosing or developing a work around to a
> problem I am having on a Windows machine. I am running R 3.6.2.
>
> I have two identical files, one stored locally and the other stored on
> a network drive.
>
> For access:
>
> > file.access(local_file, 4)
> local.R
>          0
>
> > file.access(remote_file, 4)
> remote.R
>             -1
>
> Also for file.info
>
> > file.info(local_file)$mode:
> [1] "666"
>
> > file.info(remote_file)$mode:
> [1] "666"
>
> Ok so I am access issues. Maybe they are ephemeral and I can change
> the permissions:
>
> > Sys.chmod('remote.R', mode = '666')
> > file.access(remote_file, 4)
> remote.R
>             -1
>
> Nope. I am thoroughly stumped and maybe can't make it any further
> because of Windows.
>
> Downstream I am trying to use digest::digest to create a hash but
> digest thinks we don't have permission because file.access is failing.
> Any thoughts on how I can get file.access to return 0 for the remote.R
> file? Any ideas?
>
> Thanks in advance,
>
> Sam


From r@turner @end|ng |rom @uck|@nd@@c@nz  Fri Feb 28 23:16:50 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 29 Feb 2020 11:16:50 +1300
Subject: [R] [FORGED] Re:  Help to solve modeling problem with gamm
In-Reply-To: <CAB8pepyzXdME7zcDdoVO08E8e7TQBtN2m9de9zJjNBkHnF6EEA@mail.gmail.com>
References: <BY5PR08MB636000B68CAC0630EB55A67EBDE80@BY5PR08MB6360.namprd08.prod.outlook.com>
 <CAB8pepyzXdME7zcDdoVO08E8e7TQBtN2m9de9zJjNBkHnF6EEA@mail.gmail.com>
Message-ID: <e0fca767-f70b-69c3-7814-a0021c0e3605@auckland.ac.nz>


On 29/02/20 8:11 am, Abby Spurdle wrote:

>> There was clearly a non-linear growth pattern such that an additive
>> mixed effects model was proposed to model the behavior of biomass
>> as a function of time and treatments.
> 
> The presence of non-linearity (in x) does not necessarily mean that 
> you can't use a "linear model". In general, linear models work well
> for biological growth curves with small to medium sized data.
> 
> Technically, this is off topic, however, the notion of what is
> linear and what is not linear, is a recurring theme on this mailing
> list.
> 
>> When plotting the residuals a clear cone-shaped pattern was
>> observed
> 
> Based on classical statistics, the obvious approach is to transform
> your data. This is easy to do, however, some expertise is required
> to back-transform parameters/estimates and interpret them.

Although it is indeed off topic I would like to emphasise a point that a 
lot of people don't seem to get.  A linear model is

     *linear in the parameters*

not in the predictors.  For example

     y = beta_0 + beta_1 * x + beta_2 * x^2 + E

is a linear model.  It is linear in (beta_0,beta_1,beta_2).  It is not 
of course "linear in x".

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Feb 28 23:37:19 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 28 Feb 2020 14:37:19 -0800
Subject: [R] 
 file.access returning -1 for a file on remote Windows drive.
In-Reply-To: <CADkXsV3-gDmNioeeKKXa7iy_wqQwW=ziVK4O5Ly--=N6BLCV_g@mail.gmail.com>
References: <CADkXsV3aaDdh-ds6iAuye-CsVvqjc=FAkM7cB=PVjUc1SxNwzg@mail.gmail.com>
 <CADkXsV3-gDmNioeeKKXa7iy_wqQwW=ziVK4O5Ly--=N6BLCV_g@mail.gmail.com>
Message-ID: <76CEDD91-121D-448C-83E0-5C0B6611E7DD@dcn.davis.ca.us>

Dunno. They agree for me. Maybe look closer at all permissions via Windows File Manager?

On February 28, 2020 2:06:34 PM PST, Sam Albers <tonightsthenight at gmail.com> wrote:
>Some additional follow-up:
>
>> summary(file(remote_file, "rb"))$`can read`
>[1] "yes"
>
>> summary(file(local_file, "rb"))$`can read`
>[1] "yes"
>
>compared to:
>
>> file.access(local_file, 4)
>local.R
>         0
>
>> file.access(remote_file, 4)
>remote.R
>            -1
>
>Can anyone think why file.access and file would be contradicting each
>other?
>
>Sam
>
>On Fri, Feb 28, 2020 at 10:47 AM Sam Albers
><tonightsthenight at gmail.com> wrote:
>>
>> Hi there,
>>
>> Looking for some help in diagnosing or developing a work around to a
>> problem I am having on a Windows machine. I am running R 3.6.2.
>>
>> I have two identical files, one stored locally and the other stored
>on
>> a network drive.
>>
>> For access:
>>
>> > file.access(local_file, 4)
>> local.R
>>          0
>>
>> > file.access(remote_file, 4)
>> remote.R
>>             -1
>>
>> Also for file.info
>>
>> > file.info(local_file)$mode:
>> [1] "666"
>>
>> > file.info(remote_file)$mode:
>> [1] "666"
>>
>> Ok so I am access issues. Maybe they are ephemeral and I can change
>> the permissions:
>>
>> > Sys.chmod('remote.R', mode = '666')
>> > file.access(remote_file, 4)
>> remote.R
>>             -1
>>
>> Nope. I am thoroughly stumped and maybe can't make it any further
>> because of Windows.
>>
>> Downstream I am trying to use digest::digest to create a hash but
>> digest thinks we don't have permission because file.access is
>failing.
>> Any thoughts on how I can get file.access to return 0 for the
>remote.R
>> file? Any ideas?
>>
>> Thanks in advance,
>>
>> Sam
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ton|ght@then|ght @end|ng |rom gm@||@com  Fri Feb 28 23:53:49 2020
From: ton|ght@then|ght @end|ng |rom gm@||@com (Sam Albers)
Date: Fri, 28 Feb 2020 14:53:49 -0800
Subject: [R] 
 file.access returning -1 for a file on remote Windows drive.
In-Reply-To: <76CEDD91-121D-448C-83E0-5C0B6611E7DD@dcn.davis.ca.us>
References: <CADkXsV3aaDdh-ds6iAuye-CsVvqjc=FAkM7cB=PVjUc1SxNwzg@mail.gmail.com>
 <CADkXsV3-gDmNioeeKKXa7iy_wqQwW=ziVK4O5Ly--=N6BLCV_g@mail.gmail.com>
 <76CEDD91-121D-448C-83E0-5C0B6611E7DD@dcn.davis.ca.us>
Message-ID: <CADkXsV0c2WgcuwuHa6U9o0eSRsn-TeZZgGvy26akp92TneO2Hw@mail.gmail.com>

Thanks Jeff. I am probably not explaining myself very well but my
question under what circumstances would

summary(file(remote_file, "rb"))$`can read`

be different from:

file.access(remote_file, 4)

If my permissions were different across remote and local should that
not be reflected in both of these functions?

On Fri, Feb 28, 2020 at 2:37 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Dunno. They agree for me. Maybe look closer at all permissions via Windows File Manager?
>
> On February 28, 2020 2:06:34 PM PST, Sam Albers <tonightsthenight at gmail.com> wrote:
> >Some additional follow-up:
> >
> >> summary(file(remote_file, "rb"))$`can read`
> >[1] "yes"
> >
> >> summary(file(local_file, "rb"))$`can read`
> >[1] "yes"
> >
> >compared to:
> >
> >> file.access(local_file, 4)
> >local.R
> >         0
> >
> >> file.access(remote_file, 4)
> >remote.R
> >            -1
> >
> >Can anyone think why file.access and file would be contradicting each
> >other?
> >
> >Sam
> >
> >On Fri, Feb 28, 2020 at 10:47 AM Sam Albers
> ><tonightsthenight at gmail.com> wrote:
> >>
> >> Hi there,
> >>
> >> Looking for some help in diagnosing or developing a work around to a
> >> problem I am having on a Windows machine. I am running R 3.6.2.
> >>
> >> I have two identical files, one stored locally and the other stored
> >on
> >> a network drive.
> >>
> >> For access:
> >>
> >> > file.access(local_file, 4)
> >> local.R
> >>          0
> >>
> >> > file.access(remote_file, 4)
> >> remote.R
> >>             -1
> >>
> >> Also for file.info
> >>
> >> > file.info(local_file)$mode:
> >> [1] "666"
> >>
> >> > file.info(remote_file)$mode:
> >> [1] "666"
> >>
> >> Ok so I am access issues. Maybe they are ephemeral and I can change
> >> the permissions:
> >>
> >> > Sys.chmod('remote.R', mode = '666')
> >> > file.access(remote_file, 4)
> >> remote.R
> >>             -1
> >>
> >> Nope. I am thoroughly stumped and maybe can't make it any further
> >> because of Windows.
> >>
> >> Downstream I am trying to use digest::digest to create a hash but
> >> digest thinks we don't have permission because file.access is
> >failing.
> >> Any thoughts on how I can get file.access to return 0 for the
> >remote.R
> >> file? Any ideas?
> >>
> >> Thanks in advance,
> >>
> >> Sam
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.


From drj|m|emon @end|ng |rom gm@||@com  Fri Feb 28 23:54:33 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 29 Feb 2020 09:54:33 +1100
Subject: [R] qq plot issue with ab line
In-Reply-To: <CAF9-5jM_RisPF8gf5LZrJvS8hF0Wi+_T-J63E-T_W25k=4Pnow@mail.gmail.com>
References: <CAF9-5jN7cbmWVuBZW9wrK4YFmeMiDMohjXzDX2XeG8CbMFQnEw@mail.gmail.com>
 <CA+8X3fUBQKTLZdZcAnvx3PLzv3RKZGLTTvC=8=NdW9GW9V+LJA@mail.gmail.com>
 <CAF9-5jM_RisPF8gf5LZrJvS8hF0Wi+_T-J63E-T_W25k=4Pnow@mail.gmail.com>
Message-ID: <CA+8X3fWN15SJ1qa8Xfs5wZqY6TUS7sfhC7JDJPa_sEi4o=+zcQ@mail.gmail.com>

Hi Ana,
I'll do my best. In the attached image, I have placed two green disks
at (0,0) and (1,1). These points are on a line with intercept 0 and
slope 1 as are all the other points on that line. When you ask for an
abline with two unnamed arguments, the first is the intercept and the
second is the slope. The abline function them draws a line with these
values across the plot. So it has done what you asked. If you specify
xlim=c(0,1) in the initial plot, you will get what you expect, but you
will leave all x values greater than 1.04 off the plot.

Jim

On Sat, Feb 29, 2020 at 8:41 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi Jim,
>
> I have in my code:
> abline(0,1,col='red')
>
> can you please tell me how to change my code to have it indeed running
> from 0 to 1?
>
> Thanks
> Ana
>
> On Fri, Feb 28, 2020 at 3:34 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Ana,
> > Look carefully at that red line. It goes through (0,0) and scoots off
> > the plot at (2.5,2.5). As you have specified that intercept and slope
> > in your code, poor abline is doing the best it can. Do not punish it
> > for doing what you request.
> >
> > Jim
> >
> > On Sat, Feb 29, 2020 at 6:10 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > >
> > > Hello,
> > >
> > > I made the plot in attach with this function:
> > >
> > > qqunif = function(p, BH=T, MAIN = " ", SUB=" ")
> > > {
> > >   nn = length(p)
> > >   xx =  -log10((1:nn)/(nn+1))
> > >   plot( xx,  -sort(log10(p)),
> > >         main = MAIN, sub= SUB, cex.sub=1.3,
> > >         xlab=expression(Expected~~-log[10](italic(p))),
> > >         ylab=expression(Observed~~-log[10](italic(p))),
> > >         cex.lab=1.0,mgp=c(2,1,0))
> > >   abline(0,1,col='red')
> > >   if(BH) ## BH = include Benjamini Hochberg FDR
> > >   {
> > >
> > >     abline(-log10(0.05),1, col='black',lty=1)
> > >     text(0.5,1.9 , "FDR=0.05", col = "gray60",srt=20, cex=1)
> > >     abline(-log10(0.10),1, col='black',lty=1)
> > >     text(0.5, 1.6, "FDR=0.10", col = "gray60",srt=20, cex=1)
> > >     abline(-log10(0.25),1, col='black',lty=1)
> > >     text(0.5, 1.2, "FDR=0.25", col = "gray60",srt=20, cex=1)
> > >     #legend('topleft', c("FDR = 0.05","FDR = 0.10","FDR = 0.25"),
> > >            #col=c('black','black','black'),lty=c(1,1,1), cex=0.8)
> > >     if (BF)
> > >     {
> > >       abline(h=-log10(0.05/nn), col='black') ## bonferroni
> > >     }
> > >   }
> > > }
> > >
> > >
> > > biob272=read.table("/Users/ams/Desktop/biobank272LD.txt")
> > > qqunif(biob272$V2)
> > >
> > >
> > > > head(biob272)
> > >          V1       V2
> > > 1 rs2089177 0.581204
> > > 2 rs4360974 0.418456
> > > 3 rs6502526 0.416670
> > > 4 rs8069906 0.568030
> > > 5 rs9895995 0.266746
> > > 6 rs9905280 0.510032
> > >
> > > But the red, abline doesn't look like it is 1:1 line.
> > >
> > > Can you please advise?
> > >
> > > Thanks
> > > Ana
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: qqpl.png
Type: image/png
Size: 95436 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200229/f6c553f8/attachment.png>

From drj|m|emon @end|ng |rom gm@||@com  Sat Feb 29 00:08:37 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 29 Feb 2020 10:08:37 +1100
Subject: [R] qq plot issue with ab line
In-Reply-To: <CA+8X3fWN15SJ1qa8Xfs5wZqY6TUS7sfhC7JDJPa_sEi4o=+zcQ@mail.gmail.com>
References: <CAF9-5jN7cbmWVuBZW9wrK4YFmeMiDMohjXzDX2XeG8CbMFQnEw@mail.gmail.com>
 <CA+8X3fUBQKTLZdZcAnvx3PLzv3RKZGLTTvC=8=NdW9GW9V+LJA@mail.gmail.com>
 <CAF9-5jM_RisPF8gf5LZrJvS8hF0Wi+_T-J63E-T_W25k=4Pnow@mail.gmail.com>
 <CA+8X3fWN15SJ1qa8Xfs5wZqY6TUS7sfhC7JDJPa_sEi4o=+zcQ@mail.gmail.com>
Message-ID: <CA+8X3fU13Ld0jJd2LtmZR8z=uJhwOMSzXvsPeoRGzjwjE6a5fg@mail.gmail.com>

Hi Ana,
I should clarify what I wrote in the previous email. You are expecting
an approximately square plot with a line running at about an angle of
45 degrees from lower left to upper right. However, the range of x and
y values that you are plotting are not approximately equal. This means
that lines with a slope of 1 will not run from corner to corner or
even parallel such a line. I hope that explains it better.

Jim

On Sat, Feb 29, 2020 at 9:54 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Ana,
> I'll do my best. In the attached image, I have placed two green disks
> at (0,0) and (1,1). These points are on a line with intercept 0 and
> slope 1 as are all the other points on that line. When you ask for an
> abline with two unnamed arguments, the first is the intercept and the
> second is the slope. The abline function them draws a line with these
> values across the plot. So it has done what you asked. If you specify
> xlim=c(0,1) in the initial plot, you will get what you expect, but you
> will leave all x values greater than 1.04 off the plot.
>
> Jim
>
> On Sat, Feb 29, 2020 at 8:41 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hi Jim,
> >
> > I have in my code:
> > abline(0,1,col='red')
> >
> > can you please tell me how to change my code to have it indeed running
> > from 0 to 1?
> >
> > Thanks
> > Ana
> >
> > On Fri, Feb 28, 2020 at 3:34 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >
> > > Hi Ana,
> > > Look carefully at that red line. It goes through (0,0) and scoots off
> > > the plot at (2.5,2.5). As you have specified that intercept and slope
> > > in your code, poor abline is doing the best it can. Do not punish it
> > > for doing what you request.
> > >
> > > Jim
> > >
> > > On Sat, Feb 29, 2020 at 6:10 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > > >
> > > > Hello,
> > > >
> > > > I made the plot in attach with this function:
> > > >
> > > > qqunif = function(p, BH=T, MAIN = " ", SUB=" ")
> > > > {
> > > >   nn = length(p)
> > > >   xx =  -log10((1:nn)/(nn+1))
> > > >   plot( xx,  -sort(log10(p)),
> > > >         main = MAIN, sub= SUB, cex.sub=1.3,
> > > >         xlab=expression(Expected~~-log[10](italic(p))),
> > > >         ylab=expression(Observed~~-log[10](italic(p))),
> > > >         cex.lab=1.0,mgp=c(2,1,0))
> > > >   abline(0,1,col='red')
> > > >   if(BH) ## BH = include Benjamini Hochberg FDR
> > > >   {
> > > >
> > > >     abline(-log10(0.05),1, col='black',lty=1)
> > > >     text(0.5,1.9 , "FDR=0.05", col = "gray60",srt=20, cex=1)
> > > >     abline(-log10(0.10),1, col='black',lty=1)
> > > >     text(0.5, 1.6, "FDR=0.10", col = "gray60",srt=20, cex=1)
> > > >     abline(-log10(0.25),1, col='black',lty=1)
> > > >     text(0.5, 1.2, "FDR=0.25", col = "gray60",srt=20, cex=1)
> > > >     #legend('topleft', c("FDR = 0.05","FDR = 0.10","FDR = 0.25"),
> > > >            #col=c('black','black','black'),lty=c(1,1,1), cex=0.8)
> > > >     if (BF)
> > > >     {
> > > >       abline(h=-log10(0.05/nn), col='black') ## bonferroni
> > > >     }
> > > >   }
> > > > }
> > > >
> > > >
> > > > biob272=read.table("/Users/ams/Desktop/biobank272LD.txt")
> > > > qqunif(biob272$V2)
> > > >
> > > >
> > > > > head(biob272)
> > > >          V1       V2
> > > > 1 rs2089177 0.581204
> > > > 2 rs4360974 0.418456
> > > > 3 rs6502526 0.416670
> > > > 4 rs8069906 0.568030
> > > > 5 rs9895995 0.266746
> > > > 6 rs9905280 0.510032
> > > >
> > > > But the red, abline doesn't look like it is 1:1 line.
> > > >
> > > > Can you please advise?
> > > >
> > > > Thanks
> > > > Ana
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Sat Feb 29 00:14:59 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 29 Feb 2020 10:14:59 +1100
Subject: [R] 
 file.access returning -1 for a file on remote Windows drive.
In-Reply-To: <CADkXsV3-gDmNioeeKKXa7iy_wqQwW=ziVK4O5Ly--=N6BLCV_g@mail.gmail.com>
References: <CADkXsV3aaDdh-ds6iAuye-CsVvqjc=FAkM7cB=PVjUc1SxNwzg@mail.gmail.com>
 <CADkXsV3-gDmNioeeKKXa7iy_wqQwW=ziVK4O5Ly--=N6BLCV_g@mail.gmail.com>
Message-ID: <CA+8X3fUU6a_J2239KcMLn-cprRh7ZjiSusGeB-UdoPZ_cJudGw@mail.gmail.com>

Hi Sam,
Just a guess, but your "*.R" files should be text, not binary. Windows
doesn't distinguish between the two locally if I remember correctly,
but may have to when accessing things outside the Windowsphere.

Jim

On Sat, Feb 29, 2020 at 9:07 AM Sam Albers <tonightsthenight at gmail.com> wrote:
>
> Some additional follow-up:
>
> > summary(file(remote_file, "rb"))$`can read`
> [1] "yes"
>
> > summary(file(local_file, "rb"))$`can read`
> [1] "yes"
>
> compared to:
>
> > file.access(local_file, 4)
> local.R
>          0
>
> > file.access(remote_file, 4)
> remote.R
>             -1
>
> Can anyone think why file.access and file would be contradicting each other?
>
> Sam
>
> On Fri, Feb 28, 2020 at 10:47 AM Sam Albers <tonightsthenight at gmail.com> wrote:
> >
> > Hi there,
> >
> > Looking for some help in diagnosing or developing a work around to a
> > problem I am having on a Windows machine. I am running R 3.6.2.
> >
> > I have two identical files, one stored locally and the other stored on
> > a network drive.
> >
> > For access:
> >
> > > file.access(local_file, 4)
> > local.R
> >          0
> >
> > > file.access(remote_file, 4)
> > remote.R
> >             -1
> >
> > Also for file.info
> >
> > > file.info(local_file)$mode:
> > [1] "666"
> >
> > > file.info(remote_file)$mode:
> > [1] "666"
> >
> > Ok so I am access issues. Maybe they are ephemeral and I can change
> > the permissions:
> >
> > > Sys.chmod('remote.R', mode = '666')
> > > file.access(remote_file, 4)
> > remote.R
> >             -1
> >
> > Nope. I am thoroughly stumped and maybe can't make it any further
> > because of Windows.
> >
> > Downstream I am trying to use digest::digest to create a hash but
> > digest thinks we don't have permission because file.access is failing.
> > Any thoughts on how I can get file.access to return 0 for the remote.R
> > file? Any ideas?
> >
> > Thanks in advance,
> >
> > Sam
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Feb 29 00:20:43 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 28 Feb 2020 15:20:43 -0800
Subject: [R] 
 file.access returning -1 for a file on remote Windows drive.
In-Reply-To: <CADkXsV0c2WgcuwuHa6U9o0eSRsn-TeZZgGvy26akp92TneO2Hw@mail.gmail.com>
References: <CADkXsV3aaDdh-ds6iAuye-CsVvqjc=FAkM7cB=PVjUc1SxNwzg@mail.gmail.com>
 <CADkXsV3-gDmNioeeKKXa7iy_wqQwW=ziVK4O5Ly--=N6BLCV_g@mail.gmail.com>
 <76CEDD91-121D-448C-83E0-5C0B6611E7DD@dcn.davis.ca.us>
 <CADkXsV0c2WgcuwuHa6U9o0eSRsn-TeZZgGvy26akp92TneO2Hw@mail.gmail.com>
Message-ID: <F593B5FA-E766-4CC7-B2E3-DD41BF870299@dcn.davis.ca.us>

I don't know.

Windows uses Access Control Lists, while POSIX (e.g. Linux) uses user/group/other classification. These two world views do not have a simple 1:1 correspondence, so you might see some difference between your file security configuration in the file properties.

Then again there are some hints online that the problem is not new... there is a package called R.utils that may help.


On February 28, 2020 2:53:49 PM PST, Sam Albers <tonightsthenight at gmail.com> wrote:
>Thanks Jeff. I am probably not explaining myself very well but my
>question under what circumstances would
>
>summary(file(remote_file, "rb"))$`can read`
>
>be different from:
>
>file.access(remote_file, 4)
>
>If my permissions were different across remote and local should that
>not be reflected in both of these functions?
>
>On Fri, Feb 28, 2020 at 2:37 PM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>>
>> Dunno. They agree for me. Maybe look closer at all permissions via
>Windows File Manager?
>>
>> On February 28, 2020 2:06:34 PM PST, Sam Albers
><tonightsthenight at gmail.com> wrote:
>> >Some additional follow-up:
>> >
>> >> summary(file(remote_file, "rb"))$`can read`
>> >[1] "yes"
>> >
>> >> summary(file(local_file, "rb"))$`can read`
>> >[1] "yes"
>> >
>> >compared to:
>> >
>> >> file.access(local_file, 4)
>> >local.R
>> >         0
>> >
>> >> file.access(remote_file, 4)
>> >remote.R
>> >            -1
>> >
>> >Can anyone think why file.access and file would be contradicting
>each
>> >other?
>> >
>> >Sam
>> >
>> >On Fri, Feb 28, 2020 at 10:47 AM Sam Albers
>> ><tonightsthenight at gmail.com> wrote:
>> >>
>> >> Hi there,
>> >>
>> >> Looking for some help in diagnosing or developing a work around to
>a
>> >> problem I am having on a Windows machine. I am running R 3.6.2.
>> >>
>> >> I have two identical files, one stored locally and the other
>stored
>> >on
>> >> a network drive.
>> >>
>> >> For access:
>> >>
>> >> > file.access(local_file, 4)
>> >> local.R
>> >>          0
>> >>
>> >> > file.access(remote_file, 4)
>> >> remote.R
>> >>             -1
>> >>
>> >> Also for file.info
>> >>
>> >> > file.info(local_file)$mode:
>> >> [1] "666"
>> >>
>> >> > file.info(remote_file)$mode:
>> >> [1] "666"
>> >>
>> >> Ok so I am access issues. Maybe they are ephemeral and I can
>change
>> >> the permissions:
>> >>
>> >> > Sys.chmod('remote.R', mode = '666')
>> >> > file.access(remote_file, 4)
>> >> remote.R
>> >>             -1
>> >>
>> >> Nope. I am thoroughly stumped and maybe can't make it any further
>> >> because of Windows.
>> >>
>> >> Downstream I am trying to use digest::digest to create a hash but
>> >> digest thinks we don't have permission because file.access is
>> >failing.
>> >> Any thoughts on how I can get file.access to return 0 for the
>> >remote.R
>> >> file? Any ideas?
>> >>
>> >> Thanks in advance,
>> >>
>> >> Sam
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From wdun|@p @end|ng |rom t|bco@com  Sat Feb 29 00:28:03 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 28 Feb 2020 15:28:03 -0800
Subject: [R] 
 file.access returning -1 for a file on remote Windows drive.
In-Reply-To: <CADkXsV0c2WgcuwuHa6U9o0eSRsn-TeZZgGvy26akp92TneO2Hw@mail.gmail.com>
References: <CADkXsV3aaDdh-ds6iAuye-CsVvqjc=FAkM7cB=PVjUc1SxNwzg@mail.gmail.com>
 <CADkXsV3-gDmNioeeKKXa7iy_wqQwW=ziVK4O5Ly--=N6BLCV_g@mail.gmail.com>
 <76CEDD91-121D-448C-83E0-5C0B6611E7DD@dcn.davis.ca.us>
 <CADkXsV0c2WgcuwuHa6U9o0eSRsn-TeZZgGvy26akp92TneO2Hw@mail.gmail.com>
Message-ID: <CAF8bMcZn_84CezJep=ngbGjj_A8uOEx7pt1Xq9wiAgEc+Y25uw@mail.gmail.com>

If file.access() says the file is unreadable but file() says it can be
opened, why don't you
just open the file and read it?  You can use tryCatch to deal with problems
opening or
reading the file.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Feb 28, 2020 at 2:54 PM Sam Albers <tonightsthenight at gmail.com>
wrote:

> Thanks Jeff. I am probably not explaining myself very well but my
> question under what circumstances would
>
> summary(file(remote_file, "rb"))$`can read`
>
> be different from:
>
> file.access(remote_file, 4)
>
> If my permissions were different across remote and local should that
> not be reflected in both of these functions?
>
> On Fri, Feb 28, 2020 at 2:37 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> >
> > Dunno. They agree for me. Maybe look closer at all permissions via
> Windows File Manager?
> >
> > On February 28, 2020 2:06:34 PM PST, Sam Albers <
> tonightsthenight at gmail.com> wrote:
> > >Some additional follow-up:
> > >
> > >> summary(file(remote_file, "rb"))$`can read`
> > >[1] "yes"
> > >
> > >> summary(file(local_file, "rb"))$`can read`
> > >[1] "yes"
> > >
> > >compared to:
> > >
> > >> file.access(local_file, 4)
> > >local.R
> > >         0
> > >
> > >> file.access(remote_file, 4)
> > >remote.R
> > >            -1
> > >
> > >Can anyone think why file.access and file would be contradicting each
> > >other?
> > >
> > >Sam
> > >
> > >On Fri, Feb 28, 2020 at 10:47 AM Sam Albers
> > ><tonightsthenight at gmail.com> wrote:
> > >>
> > >> Hi there,
> > >>
> > >> Looking for some help in diagnosing or developing a work around to a
> > >> problem I am having on a Windows machine. I am running R 3.6.2.
> > >>
> > >> I have two identical files, one stored locally and the other stored
> > >on
> > >> a network drive.
> > >>
> > >> For access:
> > >>
> > >> > file.access(local_file, 4)
> > >> local.R
> > >>          0
> > >>
> > >> > file.access(remote_file, 4)
> > >> remote.R
> > >>             -1
> > >>
> > >> Also for file.info
> > >>
> > >> > file.info(local_file)$mode:
> > >> [1] "666"
> > >>
> > >> > file.info(remote_file)$mode:
> > >> [1] "666"
> > >>
> > >> Ok so I am access issues. Maybe they are ephemeral and I can change
> > >> the permissions:
> > >>
> > >> > Sys.chmod('remote.R', mode = '666')
> > >> > file.access(remote_file, 4)
> > >> remote.R
> > >>             -1
> > >>
> > >> Nope. I am thoroughly stumped and maybe can't make it any further
> > >> because of Windows.
> > >>
> > >> Downstream I am trying to use digest::digest to create a hash but
> > >> digest thinks we don't have permission because file.access is
> > >failing.
> > >> Any thoughts on how I can get file.access to return 0 for the
> > >remote.R
> > >> file? Any ideas?
> > >>
> > >> Thanks in advance,
> > >>
> > >> Sam
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ton|ght@then|ght @end|ng |rom gm@||@com  Sat Feb 29 00:35:09 2020
From: ton|ght@then|ght @end|ng |rom gm@||@com (Sam Albers)
Date: Fri, 28 Feb 2020 15:35:09 -0800
Subject: [R] 
 file.access returning -1 for a file on remote Windows drive.
In-Reply-To: <CAF8bMcZn_84CezJep=ngbGjj_A8uOEx7pt1Xq9wiAgEc+Y25uw@mail.gmail.com>
References: <CADkXsV3aaDdh-ds6iAuye-CsVvqjc=FAkM7cB=PVjUc1SxNwzg@mail.gmail.com>
 <CADkXsV3-gDmNioeeKKXa7iy_wqQwW=ziVK4O5Ly--=N6BLCV_g@mail.gmail.com>
 <76CEDD91-121D-448C-83E0-5C0B6611E7DD@dcn.davis.ca.us>
 <CADkXsV0c2WgcuwuHa6U9o0eSRsn-TeZZgGvy26akp92TneO2Hw@mail.gmail.com>
 <CAF8bMcZn_84CezJep=ngbGjj_A8uOEx7pt1Xq9wiAgEc+Y25uw@mail.gmail.com>
Message-ID: <CADkXsV08d--NLCNTzckj1CeP40VXTTSavsdhmT-pbewu5o_MaA@mail.gmail.com>

Great question Will. If it were my code I would definitely do this.
However the problem is manifesting itself for my work with Dirk's
great digest package here:

https://github.com/eddelbuettel/digest/blob/947b77e82b97024a874a808a4644be21fc329275/R/digest.R#L170-L173

So because file.access is saying the permissions aren't right, I get
an error message from digest and can't create a hash. Knowing full
well that this is some weird Windows thing but also knowing I am stuck
in that environment, I wanted to figure where I was seeing a
difference between those two functions before I went asked Dirk if
he'd be interested in a change to that particular bit of code.


On Fri, Feb 28, 2020 at 3:28 PM William Dunlap <wdunlap at tibco.com> wrote:
>
> If file.access() says the file is unreadable but file() says it can be opened, why don't you
> just open the file and read it?  You can use tryCatch to deal with problems opening or
> reading the file.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Fri, Feb 28, 2020 at 2:54 PM Sam Albers <tonightsthenight at gmail.com> wrote:
>>
>> Thanks Jeff. I am probably not explaining myself very well but my
>> question under what circumstances would
>>
>> summary(file(remote_file, "rb"))$`can read`
>>
>> be different from:
>>
>> file.access(remote_file, 4)
>>
>> If my permissions were different across remote and local should that
>> not be reflected in both of these functions?
>>
>> On Fri, Feb 28, 2020 at 2:37 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> >
>> > Dunno. They agree for me. Maybe look closer at all permissions via Windows File Manager?
>> >
>> > On February 28, 2020 2:06:34 PM PST, Sam Albers <tonightsthenight at gmail.com> wrote:
>> > >Some additional follow-up:
>> > >
>> > >> summary(file(remote_file, "rb"))$`can read`
>> > >[1] "yes"
>> > >
>> > >> summary(file(local_file, "rb"))$`can read`
>> > >[1] "yes"
>> > >
>> > >compared to:
>> > >
>> > >> file.access(local_file, 4)
>> > >local.R
>> > >         0
>> > >
>> > >> file.access(remote_file, 4)
>> > >remote.R
>> > >            -1
>> > >
>> > >Can anyone think why file.access and file would be contradicting each
>> > >other?
>> > >
>> > >Sam
>> > >
>> > >On Fri, Feb 28, 2020 at 10:47 AM Sam Albers
>> > ><tonightsthenight at gmail.com> wrote:
>> > >>
>> > >> Hi there,
>> > >>
>> > >> Looking for some help in diagnosing or developing a work around to a
>> > >> problem I am having on a Windows machine. I am running R 3.6.2.
>> > >>
>> > >> I have two identical files, one stored locally and the other stored
>> > >on
>> > >> a network drive.
>> > >>
>> > >> For access:
>> > >>
>> > >> > file.access(local_file, 4)
>> > >> local.R
>> > >>          0
>> > >>
>> > >> > file.access(remote_file, 4)
>> > >> remote.R
>> > >>             -1
>> > >>
>> > >> Also for file.info
>> > >>
>> > >> > file.info(local_file)$mode:
>> > >> [1] "666"
>> > >>
>> > >> > file.info(remote_file)$mode:
>> > >> [1] "666"
>> > >>
>> > >> Ok so I am access issues. Maybe they are ephemeral and I can change
>> > >> the permissions:
>> > >>
>> > >> > Sys.chmod('remote.R', mode = '666')
>> > >> > file.access(remote_file, 4)
>> > >> remote.R
>> > >>             -1
>> > >>
>> > >> Nope. I am thoroughly stumped and maybe can't make it any further
>> > >> because of Windows.
>> > >>
>> > >> Downstream I am trying to use digest::digest to create a hash but
>> > >> digest thinks we don't have permission because file.access is
>> > >failing.
>> > >> Any thoughts on how I can get file.access to return 0 for the
>> > >remote.R
>> > >> file? Any ideas?
>> > >>
>> > >> Thanks in advance,
>> > >>
>> > >> Sam
>> > >
>> > >______________________________________________
>> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >https://stat.ethz.ch/mailman/listinfo/r-help
>> > >PLEASE do read the posting guide
>> > >http://www.R-project.org/posting-guide.html
>> > >and provide commented, minimal, self-contained, reproducible code.
>> >
>> > --
>> > Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Feb 29 00:40:06 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 28 Feb 2020 15:40:06 -0800
Subject: [R] 
 file.access returning -1 for a file on remote Windows drive.
In-Reply-To: <CADkXsV08d--NLCNTzckj1CeP40VXTTSavsdhmT-pbewu5o_MaA@mail.gmail.com>
References: <CADkXsV3aaDdh-ds6iAuye-CsVvqjc=FAkM7cB=PVjUc1SxNwzg@mail.gmail.com>
 <CADkXsV3-gDmNioeeKKXa7iy_wqQwW=ziVK4O5Ly--=N6BLCV_g@mail.gmail.com>
 <76CEDD91-121D-448C-83E0-5C0B6611E7DD@dcn.davis.ca.us>
 <CADkXsV0c2WgcuwuHa6U9o0eSRsn-TeZZgGvy26akp92TneO2Hw@mail.gmail.com>
 <CAF8bMcZn_84CezJep=ngbGjj_A8uOEx7pt1Xq9wiAgEc+Y25uw@mail.gmail.com>
 <CADkXsV08d--NLCNTzckj1CeP40VXTTSavsdhmT-pbewu5o_MaA@mail.gmail.com>
Message-ID: <2E63B26A-8F6B-44B9-9B8E-5BCD52E68106@dcn.davis.ca.us>

Read the closed issues in his digest Github repo first... this discussion has already occurred there.

On February 28, 2020 3:35:09 PM PST, Sam Albers <tonightsthenight at gmail.com> wrote:
>Great question Will. If it were my code I would definitely do this.
>However the problem is manifesting itself for my work with Dirk's
>great digest package here:
>
>https://github.com/eddelbuettel/digest/blob/947b77e82b97024a874a808a4644be21fc329275/R/digest.R#L170-L173
>
>So because file.access is saying the permissions aren't right, I get
>an error message from digest and can't create a hash. Knowing full
>well that this is some weird Windows thing but also knowing I am stuck
>in that environment, I wanted to figure where I was seeing a
>difference between those two functions before I went asked Dirk if
>he'd be interested in a change to that particular bit of code.
>
>
>On Fri, Feb 28, 2020 at 3:28 PM William Dunlap <wdunlap at tibco.com>
>wrote:
>>
>> If file.access() says the file is unreadable but file() says it can
>be opened, why don't you
>> just open the file and read it?  You can use tryCatch to deal with
>problems opening or
>> reading the file.
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Fri, Feb 28, 2020 at 2:54 PM Sam Albers
><tonightsthenight at gmail.com> wrote:
>>>
>>> Thanks Jeff. I am probably not explaining myself very well but my
>>> question under what circumstances would
>>>
>>> summary(file(remote_file, "rb"))$`can read`
>>>
>>> be different from:
>>>
>>> file.access(remote_file, 4)
>>>
>>> If my permissions were different across remote and local should that
>>> not be reflected in both of these functions?
>>>
>>> On Fri, Feb 28, 2020 at 2:37 PM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>>> >
>>> > Dunno. They agree for me. Maybe look closer at all permissions via
>Windows File Manager?
>>> >
>>> > On February 28, 2020 2:06:34 PM PST, Sam Albers
><tonightsthenight at gmail.com> wrote:
>>> > >Some additional follow-up:
>>> > >
>>> > >> summary(file(remote_file, "rb"))$`can read`
>>> > >[1] "yes"
>>> > >
>>> > >> summary(file(local_file, "rb"))$`can read`
>>> > >[1] "yes"
>>> > >
>>> > >compared to:
>>> > >
>>> > >> file.access(local_file, 4)
>>> > >local.R
>>> > >         0
>>> > >
>>> > >> file.access(remote_file, 4)
>>> > >remote.R
>>> > >            -1
>>> > >
>>> > >Can anyone think why file.access and file would be contradicting
>each
>>> > >other?
>>> > >
>>> > >Sam
>>> > >
>>> > >On Fri, Feb 28, 2020 at 10:47 AM Sam Albers
>>> > ><tonightsthenight at gmail.com> wrote:
>>> > >>
>>> > >> Hi there,
>>> > >>
>>> > >> Looking for some help in diagnosing or developing a work around
>to a
>>> > >> problem I am having on a Windows machine. I am running R 3.6.2.
>>> > >>
>>> > >> I have two identical files, one stored locally and the other
>stored
>>> > >on
>>> > >> a network drive.
>>> > >>
>>> > >> For access:
>>> > >>
>>> > >> > file.access(local_file, 4)
>>> > >> local.R
>>> > >>          0
>>> > >>
>>> > >> > file.access(remote_file, 4)
>>> > >> remote.R
>>> > >>             -1
>>> > >>
>>> > >> Also for file.info
>>> > >>
>>> > >> > file.info(local_file)$mode:
>>> > >> [1] "666"
>>> > >>
>>> > >> > file.info(remote_file)$mode:
>>> > >> [1] "666"
>>> > >>
>>> > >> Ok so I am access issues. Maybe they are ephemeral and I can
>change
>>> > >> the permissions:
>>> > >>
>>> > >> > Sys.chmod('remote.R', mode = '666')
>>> > >> > file.access(remote_file, 4)
>>> > >> remote.R
>>> > >>             -1
>>> > >>
>>> > >> Nope. I am thoroughly stumped and maybe can't make it any
>further
>>> > >> because of Windows.
>>> > >>
>>> > >> Downstream I am trying to use digest::digest to create a hash
>but
>>> > >> digest thinks we don't have permission because file.access is
>>> > >failing.
>>> > >> Any thoughts on how I can get file.access to return 0 for the
>>> > >remote.R
>>> > >> file? Any ideas?
>>> > >>
>>> > >> Thanks in advance,
>>> > >>
>>> > >> Sam
>>> > >
>>> > >______________________________________________
>>> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > >https://stat.ethz.ch/mailman/listinfo/r-help
>>> > >PLEASE do read the posting guide
>>> > >http://www.R-project.org/posting-guide.html
>>> > >and provide commented, minimal, self-contained, reproducible
>code.
>>> >
>>> > --
>>> > Sent from my phone. Please excuse my brevity.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ton|ght@then|ght @end|ng |rom gm@||@com  Sat Feb 29 00:45:41 2020
From: ton|ght@then|ght @end|ng |rom gm@||@com (Sam Albers)
Date: Fri, 28 Feb 2020 15:45:41 -0800
Subject: [R] 
 file.access returning -1 for a file on remote Windows drive.
In-Reply-To: <2E63B26A-8F6B-44B9-9B8E-5BCD52E68106@dcn.davis.ca.us>
References: <CADkXsV3aaDdh-ds6iAuye-CsVvqjc=FAkM7cB=PVjUc1SxNwzg@mail.gmail.com>
 <CADkXsV3-gDmNioeeKKXa7iy_wqQwW=ziVK4O5Ly--=N6BLCV_g@mail.gmail.com>
 <76CEDD91-121D-448C-83E0-5C0B6611E7DD@dcn.davis.ca.us>
 <CADkXsV0c2WgcuwuHa6U9o0eSRsn-TeZZgGvy26akp92TneO2Hw@mail.gmail.com>
 <CAF8bMcZn_84CezJep=ngbGjj_A8uOEx7pt1Xq9wiAgEc+Y25uw@mail.gmail.com>
 <CADkXsV08d--NLCNTzckj1CeP40VXTTSavsdhmT-pbewu5o_MaA@mail.gmail.com>
 <2E63B26A-8F6B-44B9-9B8E-5BCD52E68106@dcn.davis.ca.us>
Message-ID: <CADkXsV0U-E8nB-fTf9VFjCib4tFsu2gnLj9s6j=g6dhn-OShJw@mail.gmail.com>

Thanks Jeff. And for future readers head here:

https://github.com/eddelbuettel/digest/issues/49

and here:

https://github.com/eddelbuettel/digest/issues/13


Sam

On Fri, Feb 28, 2020 at 3:40 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Read the closed issues in his digest Github repo first... this discussion has already occurred there.
>
> On February 28, 2020 3:35:09 PM PST, Sam Albers <tonightsthenight at gmail.com> wrote:
> >Great question Will. If it were my code I would definitely do this.
> >However the problem is manifesting itself for my work with Dirk's
> >great digest package here:
> >
> >https://github.com/eddelbuettel/digest/blob/947b77e82b97024a874a808a4644be21fc329275/R/digest.R#L170-L173
> >
> >So because file.access is saying the permissions aren't right, I get
> >an error message from digest and can't create a hash. Knowing full
> >well that this is some weird Windows thing but also knowing I am stuck
> >in that environment, I wanted to figure where I was seeing a
> >difference between those two functions before I went asked Dirk if
> >he'd be interested in a change to that particular bit of code.
> >
> >
> >On Fri, Feb 28, 2020 at 3:28 PM William Dunlap <wdunlap at tibco.com>
> >wrote:
> >>
> >> If file.access() says the file is unreadable but file() says it can
> >be opened, why don't you
> >> just open the file and read it?  You can use tryCatch to deal with
> >problems opening or
> >> reading the file.
> >>
> >> Bill Dunlap
> >> TIBCO Software
> >> wdunlap tibco.com
> >>
> >>
> >> On Fri, Feb 28, 2020 at 2:54 PM Sam Albers
> ><tonightsthenight at gmail.com> wrote:
> >>>
> >>> Thanks Jeff. I am probably not explaining myself very well but my
> >>> question under what circumstances would
> >>>
> >>> summary(file(remote_file, "rb"))$`can read`
> >>>
> >>> be different from:
> >>>
> >>> file.access(remote_file, 4)
> >>>
> >>> If my permissions were different across remote and local should that
> >>> not be reflected in both of these functions?
> >>>
> >>> On Fri, Feb 28, 2020 at 2:37 PM Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us> wrote:
> >>> >
> >>> > Dunno. They agree for me. Maybe look closer at all permissions via
> >Windows File Manager?
> >>> >
> >>> > On February 28, 2020 2:06:34 PM PST, Sam Albers
> ><tonightsthenight at gmail.com> wrote:
> >>> > >Some additional follow-up:
> >>> > >
> >>> > >> summary(file(remote_file, "rb"))$`can read`
> >>> > >[1] "yes"
> >>> > >
> >>> > >> summary(file(local_file, "rb"))$`can read`
> >>> > >[1] "yes"
> >>> > >
> >>> > >compared to:
> >>> > >
> >>> > >> file.access(local_file, 4)
> >>> > >local.R
> >>> > >         0
> >>> > >
> >>> > >> file.access(remote_file, 4)
> >>> > >remote.R
> >>> > >            -1
> >>> > >
> >>> > >Can anyone think why file.access and file would be contradicting
> >each
> >>> > >other?
> >>> > >
> >>> > >Sam
> >>> > >
> >>> > >On Fri, Feb 28, 2020 at 10:47 AM Sam Albers
> >>> > ><tonightsthenight at gmail.com> wrote:
> >>> > >>
> >>> > >> Hi there,
> >>> > >>
> >>> > >> Looking for some help in diagnosing or developing a work around
> >to a
> >>> > >> problem I am having on a Windows machine. I am running R 3.6.2.
> >>> > >>
> >>> > >> I have two identical files, one stored locally and the other
> >stored
> >>> > >on
> >>> > >> a network drive.
> >>> > >>
> >>> > >> For access:
> >>> > >>
> >>> > >> > file.access(local_file, 4)
> >>> > >> local.R
> >>> > >>          0
> >>> > >>
> >>> > >> > file.access(remote_file, 4)
> >>> > >> remote.R
> >>> > >>             -1
> >>> > >>
> >>> > >> Also for file.info
> >>> > >>
> >>> > >> > file.info(local_file)$mode:
> >>> > >> [1] "666"
> >>> > >>
> >>> > >> > file.info(remote_file)$mode:
> >>> > >> [1] "666"
> >>> > >>
> >>> > >> Ok so I am access issues. Maybe they are ephemeral and I can
> >change
> >>> > >> the permissions:
> >>> > >>
> >>> > >> > Sys.chmod('remote.R', mode = '666')
> >>> > >> > file.access(remote_file, 4)
> >>> > >> remote.R
> >>> > >>             -1
> >>> > >>
> >>> > >> Nope. I am thoroughly stumped and maybe can't make it any
> >further
> >>> > >> because of Windows.
> >>> > >>
> >>> > >> Downstream I am trying to use digest::digest to create a hash
> >but
> >>> > >> digest thinks we don't have permission because file.access is
> >>> > >failing.
> >>> > >> Any thoughts on how I can get file.access to return 0 for the
> >>> > >remote.R
> >>> > >> file? Any ideas?
> >>> > >>
> >>> > >> Thanks in advance,
> >>> > >>
> >>> > >> Sam
> >>> > >
> >>> > >______________________________________________
> >>> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> > >https://stat.ethz.ch/mailman/listinfo/r-help
> >>> > >PLEASE do read the posting guide
> >>> > >http://www.R-project.org/posting-guide.html
> >>> > >and provide commented, minimal, self-contained, reproducible
> >code.
> >>> >
> >>> > --
> >>> > Sent from my phone. Please excuse my brevity.
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.


From pd@me@ @end|ng |rom cb@@dk  Sat Feb 29 10:14:22 2020
From: pd@me@ @end|ng |rom cb@@dk (Peter Dalgaard)
Date: Sat, 29 Feb 2020 09:14:22 +0000
Subject: [R] R 3.6.3 is released
Message-ID: <DEBEE59C-5554-4FD1-8E36-7D4B22914CC2@cbs.dk>

The build system rolled up R-3.6.3.tar.gz (codename "Holding the Windsock") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.6.3.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard

These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = b9c44f9f78cab3184ad9898bebc854b4
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 28a3942a7129877e9af1d5ea16202052
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = 2b364f6eaef28e069ab8ed779ee5859d
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 591dcf615162127f904e4e461f330ce9
MD5 (R-latest.tar.gz) = 506c9576ba33e1262ad5b5624db9d96a
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = bb45f89c01d509721c47fd41f147da60
MD5 (VERSION-INFO.dcf) = d97d382dc5583f9385461d8a4b0ff091
MD5 (R-3/R-3.6.3.tar.gz) = 506c9576ba33e1262ad5b5624db9d96a


2cde824a7b18958e5f06b391c801c8288be0f84fa8934b7ddefef23c67e60c09  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
38219d9c6221ccfbf075ef03711b420a1aa8731f890c8f2337148b602a217c2d  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
50381062bad9aeb4b0c8c4695cb6955c5ff70699fcc821a8e1b340229100278c  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
ca04f78ffe54afa326fe3ed40e7e1411aca0000ed2fa5ead97ddf51c6aa5b7bc  NEWS.2
89302990d8e8add536e12125ec591d6951022cf8475861b3690bc8bf1cefaa8f  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9  RESOURCES
2a8dca916cd92229ef9e328f3610ca204809c262823b860252b42072dac2473a  THANKS
20f8bfdfc6302bb2cf9b0fc5424c9a10ac0953096b6c32768ffd106a3fdd4589  VERSION-INFO.dcf
89302990d8e8add536e12125ec591d6951022cf8475861b3690bc8bf1cefaa8f  R-3/R-3.6.3.tar.gz


This is the relevant part of the NEWS file

CHANGES IN R 3.6.3:

  NEW FEATURES:

    * The included LAPACK has been updated to version 3.9.0 (for the
      included routines, just bug fixes).

  BUG FIXES:

    * Fixed a C level integer overflow in rhyper(); reported by
      Benjamin Tyner in PR#17694.

    * Uses of url(gzcon(.)) needing to extend buffer size have failed
      (with HTTP/2 servers), reported by G'abor Cs'ardi.

    * predict(loess(..), se=TRUE) now errors out (instead of
      seg.faulting etc) for large sample sizes, thanks to a report and
      patch by Benjamin Tyner in PR#17121.

    * tools:assertCondition(., "error") and hence assertError() no
      longer return errors twice (invisibly).

    * update(form, new) in the case of a long new formula sometimes
      wrongly eliminated the intercept from form, or (more rarely)
      added a garbage term (or seg.faulted !); the fix happened by
      simplifying the C-level logic of terms.formula().  Reported by
      Mathias Amb"uhl in PR#16326.

    * The error message from stopifnot(.., <error producing call>)
      again contains the full "stopifnot(.......)" call: Its attempted
      suppression did not work consistently.

    * On Windows, download.file(., , "wininet", headers=character())
      would fail; reported with patch proposal by Kevin Ushey in
      PR#17710.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From @purd|e@@ @end|ng |rom gm@||@com  Sat Feb 29 10:18:59 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 29 Feb 2020 22:18:59 +1300
Subject: [R] Help to solve modeling problem with gamm
In-Reply-To: <BY5PR08MB636000B68CAC0630EB55A67EBDE80@BY5PR08MB6360.namprd08.prod.outlook.com>
References: <BY5PR08MB636000B68CAC0630EB55A67EBDE80@BY5PR08MB6360.namprd08.prod.outlook.com>
Message-ID: <CAB8pepwh38Fhcxkg3NGy1hizDNHFU2RuQG1uAbi_=A16m5yv1Q@mail.gmail.com>

Sorry, I need to apologize.

My statement that "In general, linear models work well for biological
growth curves with small to medium sized data", may not be correct.
Also, I read through you code too quickly, my bad...

If you want to set weights (not sure if that's a good idea or not
here), I'd recommend you set them to a ***numeric vector***.

Your code is trying to set the weights to more complex objects (from
the nlme package), and it's possible that the gamm function is trying
to coerce them to numeric vectors, and that may be causing problems.

For nontrivial weights, you may want to compute weights (ensuring that
they are a numeric vector) in a separate step, and then fit the model
in a second step.


On 2/28/20, Jos? Antonio Garc?a P?rez <garci95 at hotmail.com> wrote:
> I conducted an experiment where earthworms were subjected to two treatments,
> with and without herbicide in the soil. Biomass measurements were taken
> every 12 days for 398 days and the biomass growth curves as a function of
> time were plotted.
>
> There was clearly a non-linear growth pattern such that an additive mixed
> effects model was proposed to model the behavior of biomass as a function of
> time and treatments.
>
> When plotting the residuals a clear cone-shaped pattern was observed,
> therefore a series of additive models were proposed sequentially to deal
> with violations of the assumption of homogeneity. Below we can see the
> models with the following names: M.1; M.2; M.3; M.4
>
>
>
> lmc <- lmeControl (niterEM = 5000, msMaxIter = 1000)
>
> f1 <- formula (Biomass ~ Treat + s (Time, by = Treat))
>
>
>
> M.1 <-gamm (f1, random = list (fcajita = ~ 1), method = "REML", control =
> lmc, data = Acorticis)
>
>
>
> #This first model uses the experimental box factor (i.e. fcajita) as the
> random element of the model. This random effects model assumes homogeneity
> between the experimental boxes and within them over time
>
>
>
> M.2 <-gamm (f1, random = list (fcajita = ~ 1), method = "REML", control =
> lmc, data = Acorticis, weights = varIdent (form = ~ 1 | fcajita))
>
>
>
> #This second model assumes heterogeneity between boxes, but homogeneity
> within each box over time
>
>
>
> M.3 <- gamm (f1, random = list (fcajita = ~ 1), method = "REML", control =
> lmc, data = Acorticis, weights = varExp (form = ~ Time10))
>
>
>
> #The third model assumes homogeneity between boxes but heterogeneity within
> each box over time
>
>
>
> Finally, we decided to model the heterogeneity using the 'varComb' function
> in order to combine the variances where the model allows heterogeneity
> between the experimental boxes and heterogeneity within the experimental
> boxes over time:
>
>
>
> M.4 <- gamm (f1, random = list (fcajita = ~ 1), data = Acorticis, method =
> "REML", control = lmc, weights = varComb (varIdent (form = ~ 1 | fcajita),
> varPower (form = ~ Time10)))
>
>
>
> The first three models executed perfectly and the following values ??of the
> AIC indicator were obtained:
>
>> AIC (M.1 $ lme, M.2 $ lme, M.3 $ lme)
>
>
>
>         df       AIC
>
>
>
> M.1     8        379.6464
>
>
>
> M.2    15        309.5736
>
>
>
> M.3     9        310.4828
>
>
>
> Unfortunately, the execution of the M.4 model failed and the following error
> message was obtained:
>
>
>
> Error in environment (attr (ret $ lme $ modelStruct $ varStruct, "formula"))
> <-. GlobalEnv:
>
> attempt to set an attribute on NULL
>
>
>
> A final model I tried was M5:
>
> M.5 <- gamm(f1, random = list(fcajita =~ 1), data = Acorticis, method =
> "REML", control = lmc, weights = varComb(varIdent(form = ~1|fcajita),
> varExp(form =~ Time10|fcajita)))
>
> and this time I got the following error message:
>
> Error in lme.formula(y ~ X - 1, random = rand, data = strip.offset(mf),  :
>
>   nlminb problem, convergence error code = 1
>
>   message = function evaluation limit reached without convergence (9)
>
> Adem?s: Warning message:
>
> In logLik.reStruct(object, conLin) :
>
>   Singular precision matrix in level -1, block 1
>
>
>
> My question is: Could someone help me fix these problems to run the M.4 and
> M.5 models?
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sat Feb 29 14:35:42 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sat, 29 Feb 2020 05:35:42 -0800 (PST)
Subject: [R] R 3.6.3 is released
In-Reply-To: <DEBEE59C-5554-4FD1-8E36-7D4B22914CC2@cbs.dk>
References: <DEBEE59C-5554-4FD1-8E36-7D4B22914CC2@cbs.dk>
Message-ID: <alpine.LNX.2.20.2002290533430.20958@salmo.appl-ecosys.com>

On Sat, 29 Feb 2020, Peter Dalgaard via R-help wrote:

> The build system rolled up R-3.6.3.tar.gz (codename "Holding the
> Windsock") this morning.

Peter,

My thanks to you and the rest of the Core Team for your continuing efforts
of an important application.

Regards,

Rich


