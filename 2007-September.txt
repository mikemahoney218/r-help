From knoblauch at lyon.inserm.fr  Sat Sep  1 02:36:06 2007
From: knoblauch at lyon.inserm.fr (Ken Knoblauch)
Date: Fri, 31 Aug 2007 22:36:06 -0200 (CEST)
Subject: [R] Sweave rendering of simple character
Message-ID: <49396.82.231.93.240.1188592566.squirrel@webmail.lyon.inserm.fr>

Hi,

When I compile the construction

\begin{Scode}{eval=FALSE}
?HSP
\end{Scode}

with Sweave and latex, it outputs in the pdf as,

 > `?` (HSP)

which is not incorrect but a bit more formal than I wanted
for demonstrating the use of the help shortcut.
I would like the output to look like,

> ?HSP

but I can't seem to make this work.
I have also tried the results=verbatim argument.

Thanks, in advance for any suggestions.

best,

ken


-- 
Ken Knoblauch
Inserm U846
Institut Cellule Souche et Cerveau
D?partement Neurosciences Int?gratives
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.lyon.inserm.fr/846/english.html


From gingerlygen at gmail.com  Sat Sep  1 00:12:05 2007
From: gingerlygen at gmail.com (Gen)
Date: Fri, 31 Aug 2007 15:12:05 -0700 (PDT)
Subject: [R] customizing the color and point shape for each line drawn
 using lattice's xyplot
In-Reply-To: <eb555e660708301632q58c32d56saac442b13d51ecd9@mail.gmail.com>
References: <12400517.post@talk.nabble.com>
	<eb555e660708301632q58c32d56saac442b13d51ecd9@mail.gmail.com>
Message-ID: <12434887.post@talk.nabble.com>


I have succeeded in controlling the line colors and point symbols of each
Method plotted in each frame of my xyplot, using the help files you
suggested so that some methods can be represented by the same color and
distinguished by symbols using the following code (I can not, however, seem
to make the key reflect these color and symbol changes):

#assign colors to each method
lcol <- rep(0, 243)
lcol[common$Method==1] <- 1 
lcol[common$Method==2] <- 2
lcol[common$Method==3] <- 3
lcol[common$Method==4] <- 6
lcol[common$Method==5] <- 4
lcol[common$Method==6] <- 4
lcol[common$Method==7] <- 5
lcol[common$Method==8] <- 5  
lcol[common$Method==9] <- 6 

#assign the type of symbol that corresponds to each method
ptype <- rep(0, 243)
ptype[common$Method==1] <- NA 
ptype[common$Method==2] <- NA
ptype[common$Method==3] <- NA
ptype[common$Method==4] <- 3
ptype[common$Method==5] <- 6
ptype[common$Method==6] <- 2
ptype[common$Method==7] <- NA
ptype[common$Method==8] <- NA  
ptype[common$Method==9] <- NA 

xyplot(Yvar~ Xvar| Avar * Bvar, data=common.without.Method478,
groups=method.not478.f, type="o", col=lcol, pch=ptype, cex=0.5,
auto.key=list
(text=c("Method 1","Method 2","Method 3","Method 4a","Method 4b","Method
9"), points = TRUE, lines = TRUE, col=c(1,2,3,4,4,6), cex=1,
pch=c(NA,NA,NA,6,2,NA)))
	
The above code obtains the desired plot, and is the closest that I have come
to obtaining the desired key.  Using the above code, within the key, I
obtain the appropriate text and the text is colored such that the text
"Method 1" corresponds to the color of method 1 in the plot. The symbol
shape and line color to the right of this text, however, does not change
from its default settings, and therefore does not reflect the plot.  I am
trying to obtain black text with appropriate symbols and appropriately
colored lines to the right. 

Have I misinterpreted the syntax of the atuo.key function?

- Genevieve

-- 
View this message in context: http://www.nabble.com/customizing-the-color-and-point-shape-for-each-line-drawn-using-lattice%27s-xyplot-tf4351934.html#a12434887
Sent from the R help mailing list archive at Nabble.com.


From deepayan.sarkar at gmail.com  Sat Sep  1 00:18:04 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 31 Aug 2007 15:18:04 -0700
Subject: [R] Sweave rendering of simple character
In-Reply-To: <49396.82.231.93.240.1188592566.squirrel@webmail.lyon.inserm.fr>
References: <49396.82.231.93.240.1188592566.squirrel@webmail.lyon.inserm.fr>
Message-ID: <eb555e660708311518w260106cdi83a0a9164f8cee13@mail.gmail.com>

On 8/31/07, Ken Knoblauch <knoblauch at lyon.inserm.fr> wrote:
> Hi,
>
> When I compile the construction
>
> \begin{Scode}{eval=FALSE}
> ?HSP
> \end{Scode}
>
> with Sweave and latex, it outputs in the pdf as,
>
>  > `?` (HSP)
>
> which is not incorrect but a bit more formal than I wanted
> for demonstrating the use of the help shortcut.
> I would like the output to look like,
>
> > ?HSP
>
> but I can't seem to make this work.

I'm not familiar with the Scode environment, but


<<eval=FALSE,keep.source=TRUE>>=
?HSP
@


does what you want.

-Deepayan


From deepayan.sarkar at gmail.com  Sat Sep  1 00:32:32 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 31 Aug 2007 15:32:32 -0700
Subject: [R] Assigning line colors in xyplot
In-Reply-To: <46D7E617.9020108@env.ethz.ch>
References: <46D6B5E9.1010908@env.ethz.ch>
	<eb555e660708300940v28a70503m3eac68df7966b784@mail.gmail.com>
	<46D7E617.9020108@env.ethz.ch>
Message-ID: <eb555e660708311532n27c53f1dmf6bae720785d3f97@mail.gmail.com>

On 8/31/07, Christof Bigler <christof.bigler at env.ethz.ch> wrote:
> The suggestions by Deepayan Sarkar and Hadley Wickham work for that
> case, but I get into troubles when I try to draw e.g. a panel for "A"
> and "B":
>
> xyplot(y ~ x | f , groups=g, data=tmp,type="l",
>       par.settings=list(superpose.line=list(col=c("red","blue"))),
>       auto.key=list(space="top",
> text=levels(tmp$f),points=FALSE,lines=TRUE))
>
> Similarly for xyplot(y ~ x | f , groups=f, ...)
>
>
> Let's assume that we use a slightly more complex dataframe, where we
> have different individuals a, ..., f (grouping variable "h") with 1 or 2
> series of measurements per individual (grouping variable "g"). The
> individuals are grouped as "A" or "B" (grouping variable "f") according
> to the distribution of the values in the variable "y".
>
> set.seed(1)
> tmp2 <- data.frame(
>
> y=c(rnorm(10,0,1),rnorm(10,4,2),rnorm(10,4,2),rnorm(10,4,2),rnorm(10,0,1),rnorm(10,0,1),rnorm(10,0,1),rnorm(10,4,2),rnorm(10,0,1)),
>       x=1:10,
>
> f=c(rep("A",10),rep("B",10),rep("B",10),rep("B",10),rep("A",10),rep("A",10),rep("A",10),rep("B",10),rep("A",10)),
>
> g=c(rep("1",10),rep("2",10),rep("3",10),rep("4",10),rep("5",10),rep("6",10),rep("7",10),rep("8",10),rep("9",10)),
>
> h=c(rep("a",10),rep("b",10),rep("b",10),rep("c",10),rep("d",10),rep("d",10),rep("e",10),rep("f",10),rep("e",10)))
>
> Again, the line colors in the following plot are correct:
>
> xyplot(y ~ x | g , groups=f, data=tmp2,type="l",
>       par.settings=list(superpose.line=list(col=c("red","blue"))),
>       auto.key=list(space="top", points=FALSE,lines=TRUE))
>
> But, if I want to show e.g. one panel per individual, the assignment of
> the colors is not correct:
>
> xyplot(y ~ x | h , groups=g,
> data=tmp2,type="l",
>
> par.settings=list(superpose.line=list(col=c("red","blue"))),
>
>       auto.key=list(space="top", text=levels(tmp2$f),
> points=FALSE,lines=TRUE))
>
>
> Any suggestions?

This works (only the 'groups' argument is different from your call):

xyplot(y ~ x | h , groups=interaction(f, g),
data=tmp2,type="l",

par.settings=list(superpose.line=list(col=c("red","blue"))),

     auto.key=list(space="top", text=levels(tmp2$f),
points=FALSE,lines=TRUE))


Note that unlike ggplot, you cannot (easily) use a different variable
for grouping and coloring. Fortunately, the levels of interaction(f,
g) are such that your colors (red, blue) are repeated in the right
order, so you don't need to do much extra work.

-Deepayan


From woman2304 at indiatimes.com  Sat Sep  1 01:26:40 2007
From: woman2304 at indiatimes.com (woman2304 at indiatimes.com)
Date: Sat, 1 Sep 2007 04:56:40 +0530 (IST)
Subject: [R] Fwd: Lerne heisse Singles aus Deiner Umgebung kennen ( gemacht)
Message-ID: <133427422.1935141188602800735.JavaMail.root@mbv4.indiatimes.com>

N A M E : Leona, A L T E R : 33, B E R U F : Hausfrau

Na, mein Geiler!

Ist dir auch schon so heiss wie mir? Ich habe einfach die Nase voll, dass mein Mann nie zu Hause ist und mir meine Bedurfnisse nicht befriedigen kann. Jetzt bin ich gezwungen mir einen richtigen Lover zu suchen, der mich wieder mal so richtig durchbumst! Wenn du also mein Lover sein willst, egal ob fur eine Nacht oder fur Langzeitbeziehungen, ich bin fur beides zu haben! 

Hol dir jetzt einfach einen Zugang fur 5 Euro, du findest mich mit dem Usernamen Leona33-allone, ich habe dort meine Heimadresse und meine Handynummer hinterlassen, melde dich bei mir und besuche mich, oder ich komme zu dir.

http://skt.webcompany.cc/de/index.html

Schau Dich jetzt auf der grossten, deutschsprachigen Kontaktdatenbank (Deutschland, Osterreich, Die Schweiz) um, denn hier findest Du die Frauen, die genau das gleiche suchen wie Du!

In unserer Datenbank findest Du mehr als 250,000 Profile fickgeiler Schlampen, die es mal wieder so richtig besorgt bekommen wollen.

http://skt.webcompany.cc/de/index.html

...und entscheide Dich fur mich! Mein Username ist Leona33-allone
bis dann...

 

Deine scharfe LEONA -:) 

 

 



Wenn Du diesen Newsletter nicht mehr erhalten mochtest, klicke einfach auf diesen Link:
http://voe.webcompany.cc/revoke.php










( k?nnte
 Ist Vorjahr darunter Den genannt Funktion alte Deutsche Konzept wegen Meter w?hlen
 In deutlich Personen FDP B?rger lassen an
 k?nftig f?hrt Arbeit Angst richtig B?rger sondern B?rgermeister Aufgabe Chef)

--
Guess 1st innings score. Win 1 Lakh* Rupees.
SMS RUN<Your Score> to 8888.


From murdoch at stats.uwo.ca  Sat Sep  1 01:34:01 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 31 Aug 2007 19:34:01 -0400
Subject: [R] Sweave rendering of simple character
In-Reply-To: <eb555e660708311518w260106cdi83a0a9164f8cee13@mail.gmail.com>
References: <49396.82.231.93.240.1188592566.squirrel@webmail.lyon.inserm.fr>
	<eb555e660708311518w260106cdi83a0a9164f8cee13@mail.gmail.com>
Message-ID: <46D8A569.8070602@stats.uwo.ca>

Deepayan Sarkar wrote:
> On 8/31/07, Ken Knoblauch <knoblauch at lyon.inserm.fr> wrote:
>   
>> Hi,
>>
>> When I compile the construction
>>
>> \begin{Scode}{eval=FALSE}
>> ?HSP
>> \end{Scode}
>>
>> with Sweave and latex, it outputs in the pdf as,
>>
>>  > `?` (HSP)
>>
>> which is not incorrect but a bit more formal than I wanted
>> for demonstrating the use of the help shortcut.
>> I would like the output to look like,
>>
>>     
>>> ?HSP
>>>       
>> but I can't seem to make this work.
>>     
>
> I'm not familiar with the Scode environment, but
>
>
> <<eval=FALSE,keep.source=TRUE>>=
> ?HSP
> @
>
>
> does what you want.
>   
Like Deepayan, I also use <<>>= notation, but this probably works 
anywhere:  put keep.source=TRUE in your \SweaveOpts{} at the start of 
the file. 

Duncan Murdoch


From FolkesM at pac.dfo-mpo.gc.ca  Sat Sep  1 01:51:07 2007
From: FolkesM at pac.dfo-mpo.gc.ca (Folkes, Michael)
Date: Fri, 31 Aug 2007 16:51:07 -0700
Subject: [R] Lattice:can't subset in panel function using other variables
In-Reply-To: <eb555e660708311404r3797089bp2a07faa57bdd4bd1@mail.gmail.com>
Message-ID: <63F107BCC37AEA49A75FD94AA3E07CB099F518@pacpbsex01.pac.dfo-mpo.ca>

Thanks Deepayan for your response.
The first subset you suggest was just a test for me and not what I
wanted.
I can't do your second suggested subset action as I wish to plot all the
panel data, but then add a coloured datapoint for just one year (see
example code).
I think I have found my problem but don't know how to solve it.
The subscripts of data going into each panel are almost always the same
length, except maybe one or two panels have 1 less datapoint.  
I've attached a script that builds a quick dataset and plots what I was
aiming for.  It works great.  If you then remove one line of data from
the DF (using "df<-df[-1,]" in the script), the plotting goes awry.

Any suggestions about dealing with unequal data lengths for panel
function subsetting?
Thanks so much
Michael

***********Start of code
#________________________
#This builds fake dataset

years<-2000:2006
weeks<-1:20
yr<-rep(years,rep(length(weeks)*6,length(years)))
wk<-rep(weeks,rep(6,length(weeks)))
temp<-rep(4:9,length(years)*length(weeks))
yvar<-round(rnorm(length(years)*length(weeks)*6,mean=30,sd=4),0)
xvar<-(rnorm(length(years)*length(weeks)*6)+5)/10

df<-data.frame(year=yr,week=wk,temp=temp,yvar=yvar,xvar=xvar)
#________________________

library(lattice)
df<-df[df$temp==4 ,]
df$year2<-as.factor(df$year)
df$week2<-as.factor(df$week)

#!!!!!!!!!!!!!!!!!
#df<-df[-1,]   #<-run this to see problem if panel data are of unequal
length
#!!!!!!!!!!!!!!!!!

print(xyplot(yvar~xvar|week2,data=df,layout = c(4, 5),
  scales=list(cex=0.7,x=list(rot=45)),
  par.strip=list(cex=.7),
  as.table=T,
  strip = strip.custom(strip.names = F, strip.levels = TRUE),
 panel=function(x,y,subscripts){
      panel.xyplot(x,y,type='p',col=1,cex=.5)
 
panel.xyplot(df$xvar[df$year==2005][subscripts],df$yvar[df$year==2005][s
ubscripts],type='p',pch=1,col=3,cex=1.5)
	},
))
***********End of code




-----Original Message-----
From: Deepayan Sarkar [mailto:deepayan.sarkar at gmail.com] 
Sent: August 31, 2007 2:04 PM
To: Folkes, Michael
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Lattice:can't subset in panel function using other
variables


On 8/30/07, Folkes, Michael <FolkesM at pac.dfo-mpo.gc.ca> wrote:
> I've succeeded doing a subset within the panel function of xyplot - if
I'm subsetting based on either the value of 'x' or 'y' (e.g. below).
However, I wish to subset based on the value of another variable and
colour that one plotted point.  It's not working.  Either it doesn't
plot the coloured data point, or if I sort the data differently it
colours one datapoint, but the wrong one.   I assume this means it's not
getting the right subscripts?    Finally I can sort of see the light as
if I remove the conditioning variable (week) and subset before the
xyplot (e.g. week==1) to get just one panel, it plots the correct data
including the correct single red point.
> Where am I erring?
> _______________________________________
> print(xyplot(yval~xval|week,data=mydata,
>  panel=function(x,y,subscripts){
>         #panel.xyplot(x,y,type='p',col=1,cex=.5)
>         panel.xyplot(x[y<=40],y[y<=40],type='p',col=2,cex=.5)  #
<-----this works
>         
>
panel.xyplot(x[mydata$yr==2005],y[mydata$yr==2005],type='p',pch=16,col=2
,cex=.5)  #  <-----sometimes this won't work or it colours wrong
datapoint
> }))
> ___________________________

Why not

xyplot(yval~xval|week,data=mydata, subset = yval < 40)

or

xyplot(yval~xval|week,data=mydata, subset = yr==2005)

-Deepayan


From deepayan.sarkar at gmail.com  Sat Sep  1 02:18:43 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 31 Aug 2007 17:18:43 -0700
Subject: [R] Lattice:can't subset in panel function using other variables
In-Reply-To: <63F107BCC37AEA49A75FD94AA3E07CB099F518@pacpbsex01.pac.dfo-mpo.ca>
References: <eb555e660708311404r3797089bp2a07faa57bdd4bd1@mail.gmail.com>
	<63F107BCC37AEA49A75FD94AA3E07CB099F518@pacpbsex01.pac.dfo-mpo.ca>
Message-ID: <eb555e660708311718x59f17f8bv9a580a1470457b3e@mail.gmail.com>

On 8/31/07, Folkes, Michael <FolkesM at pac.dfo-mpo.gc.ca> wrote:
> Thanks Deepayan for your response.
> The first subset you suggest was just a test for me and not what I
> wanted.
> I can't do your second suggested subset action as I wish to plot all the
> panel data, but then add a coloured datapoint for just one year (see
> example code).
> I think I have found my problem but don't know how to solve it.
> The subscripts of data going into each panel are almost always the same
> length, except maybe one or two panels have 1 less datapoint.
> I've attached a script that builds a quick dataset and plots what I was
> aiming for.  It works great.  If you then remove one line of data from
> the DF (using "df<-df[-1,]" in the script), the plotting goes awry.
>
> Any suggestions about dealing with unequal data lengths for panel
> function subsetting?

If your goal is to highlight one particular year, why not use something like

xyplot(yvar~xvar|week2,data=df,layout = c(4, 5), as.table=TRUE,
       groups = (year == 2005), col = 1, pch = c(1, 16))

? Your code doesn't work because you don't seem to understand what
'subscripts' is supposed to be (either that, or you are confusing
yourself with multiple indices). Here's a version with the correct
usage:

xyplot(yvar~xvar|week2,data=df,layout = c(4, 5), as.table=TRUE,
       panel = function(x, y, subscripts, ...) {
           highlight <- (df$year == 2005)
           highlight.panel <- highlight[subscripts]
           panel.xyplot(x, y, type='p', col=1, cex=.5)
           panel.xyplot(x[highlight.panel], y[highlight.panel],
                        type='p', pch=1, col=3, cex=1.5)
       })

-Deepayan


From pinard at iro.umontreal.ca  Sat Sep  1 02:30:26 2007
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Fri, 31 Aug 2007 20:30:26 -0400
Subject: [R] R 2.5.1 - Rscript through tee
In-Reply-To: <18130.55671.500000.412572@ron.nulle.part>
References: <20070827024718.GA20217@alcyon.progiciels-bpi.ca>
	<18130.55671.500000.412572@ron.nulle.part>
Message-ID: <20070901003026.GB6502@phenix.progiciels-bpi.ca>

[Dirk Eddelbuettel]
>[Fran?ois Pinard]

>>    #!/usr/bin/Rscript
>>    options(echo=TRUE)
>>    a <- 1
>>    Sys.sleep(3)
>>    a <- 2

>> If I execute "./pp.R" at the shell prompt, the output shows the 
>> timely progress of the script as expected.  If I use "./pp.R | tee 
>> OUT" instead, the output seems buffered and I see it all at once at 
>> the end.  [...] So, is there a way to tell R (or Rscript) that 
>> standard output should be unbuffered, even if it is not directly 
>> connected to a terminal?

> Use explicit print statements, e.g.  print(a <- 1)

Yes, I noticed that "print" statements get written.  But I wanted the 
mere "echo" trace of the execution of the script to be synchronous (as 
some statements take many seconds to compute, which I symbolically 
replaced by "Sys.sleep" above).

> Littler5D actually won't show anything unless you explicitly call 
> cat() or print(), but then it does [...]

It shares the limitation of Rscript, then.

> Littler is an 'all-in' binary and starts and runs demonstrably faster 
> than Rscript.

I'm not familiar with Littler.  Speedwise, Rscript is OK for me so far, 
as most time is spent within R computations, not much in language 
compilation or script interpretation.

> [...] the rather petty refusal of Rscript's main author to a least 
> give a reference to littler in Rscript's documentation, let alone 
> credit as 'we were there first', [...]

I've long been in academic circles (and elsewhere too), so I'm familiar 
with the need of recognizing authorship and people's works.  However, 
perusing R mailing list archives, and following actual list contents, 
I'm sometimes surprised, and even a bit annoyed, by the recurrent starve 
for credit I observe.  Of course, maintainers and contributors much 
deserve our thanks and, without going into arguments about what is due 
to whom, I think contributors receive praise on average, would it be 
only by all the interest shown by the community.  However, it gets a bit 
muddy when maintainers or contributors show bad temper when not 
receiving the systematic credit they would like to read.

Cicero's friends were telling him how upset they felt that there was 
still no statute of Cicero on the public place.  Cicero replied that he 
much preferred to hear people saying "Why no Cicero statute yet?" than 
to hear people saying "Why the Cicero statute?".  A wise attitude! :-)

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From hydes at byuh.edu  Sat Sep  1 05:57:02 2007
From: hydes at byuh.edu (Scott Hyde)
Date: Fri, 31 Aug 2007 17:57:02 -1000
Subject: [R] row echelon form
Message-ID: <793e846d0708312057j79897d3cv92bbf460022f9ba4@mail.gmail.com>

Hi everyone,

I am looking to use R as a MATLAB replacement for linear algebra.
I've done a fairly good job for finding replacements for most of the
functions I'm interested in, I
John Fox wrote a program for implementing the reduced row echelon form
of a matrix (by doing the Gauss-Jordan elimination).  I modified it a
bit:

rref <- function(A, tol=sqrt(.Machine$double.eps),verbose=FALSE,
                 fractions=FALSE){
  ## A: coefficient matrix
  ## tol: tolerance for checking for 0 pivot
  ## verbose: if TRUE, print intermediate steps
  ## fractions: try to express nonintegers as rational numbers
  ## Written by John Fox
  if (fractions) {
    mass <- require(MASS)
    if (!mass) stop("fractions=TRUE needs MASS package")
  }
  if ((!is.matrix(A)) || (!is.numeric(A)))
    stop("argument must be a numeric matrix")
  n <- nrow(A)
  m <- ncol(A)
  for (i in 1:min(c(m, n))){
    col <- A[,i]
    col[1:n < i] <- 0
    # find maximum pivot in current column at or below current row
    which <- which.max(abs(col))
    pivot <- A[which, i]
    if (abs(pivot) <= tol) next     # check for 0 pivot
    if (which > i) A[c(i, which),] <- A[c(which, i),]  # exchange rows
    A[i,] <- A[i,]/pivot            # pivot
    row <- A[i,]
    A <- A - outer(A[,i], row)      # sweep
    A[i,] <- row                    # restore current row
    if (verbose)
      if (fractions) print(fractions(A))
      else print(round(A,round(abs(log(tol,10)))))
  }
  for (i in 1:n)
    if (max(abs(A[i,1:m])) <= tol)
      A[c(i,n),] <- A[c(n,i),] # 0 rows to bottom
  if (fractions) fractions (A)
  else round(A, round(abs(log(tol,10))))
}

I've found its useful for my students.

I wrote a program for implementing row echelon form, which is only
concerned with the getting the lower triangular part to be zero, along
with the first non-zero entry in each non-zero row being a one.  Here
is what I wrote:

ref <- function(A) {
  ## Implements gaussian elimination using the QR factorization.
  ## Note: ref form is not unique.
  ## written by S. K. Hyde
  ##

  qrA <- qr(A)
  r <- qrA$rank  ##computed rank of the matrix
  R <- qr.R(qrA)

  if (r < nrow(R))
    R[-(1:r),] <- 0 #zero out rows that should be zero (according to the rank).

  #Get ones as the first nonzero entry in each row and return result.
  diag(c(1/diag(R)[1:r],rep(1,nrow(R)-r)))%*%R
}

Any suggestions of problems that anyone sees?

-Scott



-- 
*****************************************************************
Scott K. Hyde
Assistant Professor of Statistics and Mathematics
Brigham Young University -- Hawaii


From megh700004 at yahoo.com  Sat Sep  1 07:19:57 2007
From: megh700004 at yahoo.com (Megh Dal)
Date: Fri, 31 Aug 2007 22:19:57 -0700 (PDT)
Subject: [R] Choosing the optimum lag order of ARIMA model
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A83440195791E@NYWEXMB23.msad.ms.com>
Message-ID: <297801.81534.qm@web58111.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070831/aa4c1202/attachment.pl 

From megh700004 at yahoo.com  Sat Sep  1 09:59:46 2007
From: megh700004 at yahoo.com (Megh Dal)
Date: Sat, 1 Sep 2007 00:59:46 -0700 (PDT)
Subject: [R] Neural network
Message-ID: <381950.7699.qm@web58102.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070901/af91439c/attachment.pl 

From erich.neuwirth at univie.ac.at  Sat Sep  1 11:16:27 2007
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Sat, 01 Sep 2007 11:16:27 +0200
Subject: [R] by group problem
In-Reply-To: <6EBEA5B72E9B02428F2DD71D9DBC6EDF319399@AKOYASRV01.akoyainc.local>
References: <6EBEA5B72E9B02428F2DD71D9DBC6EDF319399@AKOYASRV01.akoyainc.local>
Message-ID: <46D92DEB.3050709@univie.ac.at>

Perhaps you want this?

data <- NULL
data$state <- c(rep("Illinois", 10), rep("Wisconsin", 10))
data$county <- c("Adams", "Brown", "Bureau", "Cass", "Champaign",
                 "Christian", "Coles", "De Witt", "Douglas", "Edgar",
                 "Adams", "Ashland", "Barron", "Bayfield", "Buffalo",
                 "Burnett", "Chippewa", "Clark", "Columbia", "Crawford")
data$percentOld <- c(17.554849, 16.826594, 18.196593, 17.139242,  8.743823,
                     17.862746, 13.747967, 16.626302, 15.258940, 18.984435,
                     19.347022, 17.814436, 16.903067, 17.632781, 16.659305,
                     20.337817, 14.293354, 17.252820, 15.647179, 16.825596)

data<-data.frame(data,stringsAsFactors=FALSE)
rankWithinState<-unlist(tapply(-data$percentOld,data$state,rank))
names(rankWithinState)<-NULL
data<-data.frame(data,rankWithinState)
highCounties<-data[data$rankWithinState<=5,]
highCountiesSorted<-highCounties[order(highCounties$state,-highCounties$percentOld),]

Cory Nissen wrote:
> I am working with census data.  My columns of interest are...
>  
> PercentOld - the percentage of people in each county that are over 65
> County - the county in each state
> State - the state in the US
-- 
Erich Neuwirth, University of Vienna
Faculty of Computer Science
Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-39464 Fax: +43-1-4277-39459


From info at aghmed.fsnet.co.uk  Sat Sep  1 12:36:44 2007
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Sat, 01 Sep 2007 11:36:44 +0100
Subject: [R] memory.size help
In-Reply-To: <12425401.post@talk.nabble.com>
References: <12425401.post@talk.nabble.com>
Message-ID: <Zen-1IRQLX-0007bC-Ai@rutherford.zen.co.uk>

At 13:27 31/08/2007, dxc13 wrote:

>I keep getting the 'memory.size' error message when I run a program I have
>been writing.  It always it cannot allocate a vector of a certain size.  I
>believe the error comes in the code fragement below where I have multiple
>arrays that could be taking up space.  Does anyone know a good way around
>this?

It is a bit hard without knowing the dimensions of the arrays but see below.

>w1 <- outer(xk$xk1, data[,x1], function(y,z) abs(z-y))
>w2 <- outer(xk$xk2, data[,x2], function(y,z) abs(z-y))
>w1[w1 > d1] <- NA
>w2[w2 > d2] <- NA
>i1 <- ifelse(!is.na(w1),yvals[col(w1)],NA)
>i2 <- ifelse(!is.na(w2),yvals[col(w2)],NA)

If I read this correctly after this point you no longer need w1 and 
w2 so what happens if you remove them?

>zk <- numeric(nrow(xk))      #DEFININING AN EMPTY VECTOR TO HOLD ZK VALUES
>for(x in 1:nrow(xk)) {
>         k <- intersect(i1[x,], i2[x,])
>         zk[x] <- mean(unlist(k), na.rm = TRUE)
>}
>xk$zk <- zk
>data <- na.omit(xk)
>--
>View this message in context: 
>http://www.nabble.com/memory.size-help-tf4359846.html#a12425401
>Sent from the R help mailing list archive at Nabble.com.

Michael Dewey
http://www.aghmed.fsnet.co.uk


From kubovy at virginia.edu  Sat Sep  1 13:27:12 2007
From: kubovy at virginia.edu (Michael Kubovy)
Date: Sat, 1 Sep 2007 07:27:12 -0400
Subject: [R] iplots Java
Message-ID: <6B0FC073-93F0-4D75-BF79-C20AC8FF5090@virginia.edu>

I run R 2.5.1 on a Mac, and use JGR as the front-end. When I  
performed an update.packages(), I believe it unpdated a component of  
JGR. I then quit and tried to relaunch JGR. It wouldn't launch.  
Instead it opened a panel that says: "Cannot find iplot Java classes.  
Please make sure that the latest iplots R package is correctly  
installed." I would appreeciate hearing of strategies for solving the  
problem.

_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/


From jim at bitwrit.com.au  Sat Sep  1 14:36:04 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 01 Sep 2007 22:36:04 +1000
Subject: [R] Automatic anchors for text boxes
In-Reply-To: <12426263.post@talk.nabble.com>
References: <12426263.post@talk.nabble.com>
Message-ID: <46D95CB4.2050409@bitwrit.com.au>

Yves Moisan wrote:
> Hi All,
> 
> I'm struggling to add text automatically to plots.  I have a series of
> scatterplots that I have stored in a script because the underlying data
> changes often and the plots need to be regenerated.  I use the scatterplot
> function (defined in Rcmd, I believe).  When one of the variables is a
> factor, a boxplot is drawn over the scatter of the other variable.  In the
> case where x is a factor with 10 values, I'll see 10 vertical boxplots.  So
> far, so good.  
> 
> I was asked to show other stats on top of those scatterplots, e.g. mean,
> number of observations, etc.  I can find those values, but the problem is I
> don't know how to put them on the plot, given I don't want to look at each
> plot one by one and manually identify the locations where I need to add the
> text.  I was wondering if something like a pseudo label (I want to keep the
> original axis labels) existed that could be used to anchor a text box ?  Or
> maybe a semi-manual approach where I could offset such a pseudo-label
> position along the y axis?  Since I know the size of my resulting jpegs, I
> could use a constant y offset for the text and they'd be aligned properly
> along the x axis because they are labels.   For the mean value, I could draw
> a short horizontal line segment across the boxplot, but again I'd have the
> problem of tying that line segment to specific x-axis values so they
> intersect the right boxplot.  Any clues ?
> 
> On a related note, I've added regression lines, again by factor (thanks
> scatterplot!), and was asked to write the regression equation in plain text. 
> I have between one and 7 lines on the plots, so again how could I
> automatically tie a text box, this time to a specific regression line ? 
> Maybe that would be easier using a legend, but it would be nice to be able
> to write the equation alongside the line.
> 
> TIA
Hi Yves,
I may not understand exactly what you want, but spread.labels (plotrix) 
is useful for putting labels next to points that are spread out along 
one dimension. thigmophobe.labels puts labels next to points that are 
scattered around a plot.

Jim


From p.dalgaard at biostat.ku.dk  Sat Sep  1 14:36:41 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 01 Sep 2007 14:36:41 +0200
Subject: [R] size limitations in R
In-Reply-To: <20070831152023.GR786@street-artists.org>
References: <f9001fd60708310531n906f49dh854cb0381cb4cb80@mail.gmail.com>
	<20070831152023.GR786@street-artists.org>
Message-ID: <46D95CD9.8070808@biostat.ku.dk>

Daniel Lakeland wrote:
> On Fri, Aug 31, 2007 at 01:31:12PM +0100, Fabiano Vergari wrote:
>
>   
>> I am a SAS user currently evaluating R as a possible addition or
>> even replacement for SAS. The difficulty I have come across straight
>> away is R's apparent difficulty in handling relatively large data
>> files. Whilst I would not expect it to handle datasets with millions
>> of records, I still really need to be able to work with dataset with
>> 100,000+ records and 100+ variables. Yet, when reading a .csv file
>> with 180,000 records and about 200 variables, the software virtually
>> ground to a halt (I stopped it after 1 hour). Are there guidelines
>> or maybe a limitations document anywhere that helps me assess the
>> size
>>     
>
> 180k records with 200 variables = 36 million entries, if they're
> numeric then they're doubles taking up 8 bytes, so 288 MB of RAM. This
> should be perfectly fine for R, as long as you have that much free
> RAM.
>
> However, the routines that read CSV and tabular delimited files are
> relatively inefficient for such large files.
>
> In order to handle large data files, it is better to use one of the
> database interfaces. My preference would be sqlite unless I already
> had the data on a mysql or other database server.
>
>   
Yes. However, for an intermediate solution, notice that much of the 
inefficiency comes from storing data as character vectors before 
deciding what to do with them. Character vectors have an overhead of one 
SEXP per string stored i.e. 20-28 bytes in addition to the actual 
string. There are options for telling the read routines explicitly that 
data are numeric/integer/logical: 'colClasses' for read.table(), 'what' 
for scan(). This will bypass the intermediate storage.
> the documentation for the packages RSQLite and SQLiteDF should be
> helpful, as well as the documentation for SQLite itself, which has a
> facility for efficiently importing CSV and similar files directly to a
> SQLite database.
>
> eg: http://netadmintools.com/art572.html
>
>
>
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From jim at bitwrit.com.au  Sat Sep  1 14:42:42 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 01 Sep 2007 22:42:42 +1000
Subject: [R] plotting
In-Reply-To: <12431743.post@talk.nabble.com>
References: <12431743.post@talk.nabble.com>
Message-ID: <46D95E42.8020908@bitwrit.com.au>

yoooooo wrote:
> Hi, let's say I have data
> 
> x = c(1, 2, 10, 12)
> y = c(100, -20, 50, 25)
> 
> if I go plot(x, y), then the default x-axis range goes from 1 to 12. Is
> there a way to change it so that the axis looks like:
> 
> ----|-----|-----|-----|----
>      1       2       10     12
> 
> This doesn't seem reasonable but let's say I want to plot intraday graph
> with axis.POSIXct, my data is only from 8:30 to 4 every day and I have these
> data for days.. i don't want to see a straight line every night.. Is there a
> way I can do this? 
> 
Hi yoooooo,
Have you looked at gap.plot (plotrix)?

Jim


From andrewjyee at gmail.com  Sat Sep  1 15:18:37 2007
From: andrewjyee at gmail.com (Andrew Yee)
Date: Sat, 1 Sep 2007 09:18:37 -0400
Subject: [R] in cor.test, difference between exact=FALSE and exact=NULL
In-Reply-To: <46D82E63.1020303@biostat.ku.dk>
References: <5dff5a0d0708231541s2a4d0c47r82da73954d664fa2@mail.gmail.com>
	<46D82E63.1020303@biostat.ku.dk>
Message-ID: <5dff5a0d0709010618q5d80c022q589639619ec21369@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070901/60491fd3/attachment.pl 

From shubhak at ambaresearch.com  Sat Sep  1 15:33:07 2007
From: shubhak at ambaresearch.com (Shubha Vishwanath Karanth)
Date: Sat, 1 Sep 2007 19:03:07 +0530
Subject: [R] Problem in downloading Yahoo Finance data from R
Message-ID: <A36876D3F8A5734FA84A4338135E7CC30265A13F@BAN-MAILSRV03.Amba.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070901/c76fffb7/attachment.pl 

From p.dalgaard at biostat.ku.dk  Sat Sep  1 16:03:14 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 01 Sep 2007 16:03:14 +0200
Subject: [R] in cor.test, difference between exact=FALSE and exact=NULL
In-Reply-To: <5dff5a0d0709010618q5d80c022q589639619ec21369@mail.gmail.com>
References: <5dff5a0d0708231541s2a4d0c47r82da73954d664fa2@mail.gmail.com>	<46D82E63.1020303@biostat.ku.dk>
	<5dff5a0d0709010618q5d80c022q589639619ec21369@mail.gmail.com>
Message-ID: <46D97122.10206@biostat.ku.dk>

Andrew Yee wrote:
> Thanks for the clarification.  I should have recognized the difference
> between "warning" and "error."
> But if I may take this a step further, shouldn't it then be exact=TRUE
> instead of exact=NULL?
> Thanks,
> Andrew
>   

Nope. The two are equivalent for the Spearman test, but not for 
Kendall's tau.  The login in that case is that NULL implies exact 
testing if n < 50 and asymptotic otherwise. TRUE and FALSE enforces one 
or the other (if possible).
> On 8/31/07, Peter Dalgaard <P.Dalgaard at biostat.ku.dk> wrote:
>   
>> Andrew Yee wrote:
>>     
>>> Pardon my ignorance, but is there a difference in cor.test between
>>> exact=FALSE and exact=NULL when method=spearman?
>>>
>>> Take for example:
>>>
>>> x<-c(1,2,2,3,4,5)
>>> y<-c(1,2,2,10,11,12)
>>> cor.test(x,y, method="spearman", exact=NULL)
>>>
>>> This gives an error message,
>>> Warning message:  Cannot compute exact p-values with ties in:
>>> cor.test.default(x, y, method = "spearman", exact = NULL)
>>>
>>> However, when exact is changed to FALSE, this seems to run okay.
>>>
>>> cor.test(x,y, method="spearman", exact=FALSE)
>>>
>>> Question:  should this be exact = FALSE in the documentation and/or the
>>>       
>> code?
>>     
>>>       
>> No. The default is indeed NULL.
>>
>> This implies that calculation of exact p-values will be attempted, and
>> when there are ties you get a warning (NB: not error) message.  Setting
>> exact=FALSE, no attempt is made and no warning is given.
>>     
>>> Thanks,
>>> Andrew
>>> MGH Cancer Center
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>>       
>> guide.html
>>     
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>       
>>
>> --
>>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)
>> 35327918
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)
>> 35327907
>>
>>
>>
>>     
>
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ajayshah at mayin.org  Sat Sep  1 16:44:27 2007
From: ajayshah at mayin.org (Ajay Shah)
Date: Sat, 1 Sep 2007 20:14:27 +0530
Subject: [R] Visual details in integration of emacs, ess,
	Sweave (under aquamacs on OS X)
Message-ID: <20070901144427.GT26510@lubyanka.local>

I am a very happy user of emacs, ess, Sweave. My complaint is about
aquamacs (under OS X) and might not apply to other emacs variants.

There is one piece of visual detail that I think is a problem. When
the cursor moves from a line that's latex to a line that's R, ess
automatically switches from auctex to sweave mode. That's very smart
and extremely convenient. However, the vertical height of the toolbar
at the top for auctex is different from that for sweave. As a
consequence, there is an extremely disconcerting jump where the cursor
is no longer at the physical pixel which you were looking at.

The solution perhaps involves the people who do auctex and the people
who're writing ess to agree on how many pixels their toolbar will
take, so as to avoid these jarring jumps.

-- 
Ajay Shah                                      http://www.mayin.org/ajayshah  
ajayshah at mayin.org                             http://ajayshahblog.blogspot.com
<*(:-? - wizard who doesn't know the answer.


From Ted.Harding at manchester.ac.uk  Sat Sep  1 16:50:02 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Sat, 01 Sep 2007 15:50:02 +0100 (BST)
Subject: [R] Incomplete Gamma function
In-Reply-To: <Pine.LNX.4.64.0708311353100.3722@gannet.stats.ox.ac.uk>
Message-ID: <XFMail.070901155002.Ted.Harding@manchester.ac.uk>

On 31-Aug-07 13:06:42, Prof Brian Ripley wrote:
> On Fri, 31 Aug 2007, Robin Hankin wrote:
> 
>> Hi Kris
>> lgamma() gives the log of the gamma function.
> 
> Yes, but he used Igamma.  According to ?pgamma,
> 
>   'pgamma' is closely related to the incomplete gamma function.
>   As defined by Abramowitz and Stegun 6.5.1
> 
>      P(a,x) = 1/Gamma(a) integral_0^x t^(a-1) exp(-t) dt
> 
>   P(a, x) is 'pgamma(x, a)'.  Other authors (for example Karl
>   Pearson in his 1922 tables) omit the normalizing factor,
>   defining the incomplete gamma function as
>   'pgamma(x, a) * gamma(a)'.
> 
> and that seems to be what Igamma is following. GSL on the other
> hand has the other tail, so
> 
>> a <- 9
>> x <- 11.1
>> pgamma(x, a, lower=FALSE)*gamma(a)
> [1] 9000.501
> 
>> You need gamma_inc() of the gsl package, a wrapper for the
>> GSL library:
>>
>> > gamma_inc(9,11.1)
>> [1] 9000.501
>> >
> 
> As the above shows, you don't *need* this, but you do need the GSL 
> documentation to find out what R package gsl does.  Why it differs from
> the usual references is something for you to explain.  Wikipedia
> http://en.wikipedia.org/wiki/Incomplete_gamma_function
> distinguishes them, as does MathWorld.
> 
> I suggest you add a clarification to the gsl package as to what the 
> 'incomplete gamma function' means there.

We have been here before! -- though in connection with the
Beta function in the first instance. See:

See the thread starting on 13 Dec 2005 at
  http://finzi.psych.upenn.edu/R/Rhelp02a/archive/66670.html

In particular I'll repeat my views on the distinction of
terminology between "Incomplete Beta/Gamma Function" and
"Beta/Gamma Distribution" (where "Function" refers to the
incomplete *integral* and "Distribution" to the same divided
by the complete integral i.e. by the "Beta/Gamma Function"
which, in my view, should be defined as the complete integral).

  My reasons for preferring the terminology "Incomplete
  ... Function" for the incomplete integral *not* divided
  by the normalising constant (for both Beta and Gamma),
  and using "Distribution" for the incomplete integral
  divided by the constant (i.e. Pearson's "Ratio"), are
  several, but in summary:

  1. The Beta and Gamma functions (not normalised) are
     fundamental mathematical functions in their own right;
     likewise their incomplete versions.

  2. When needed in probability applications, then of course
     they need to be normalised; but then why not simply call
     them "distributions"?

  3. (1) and (2) encapsulate in the terminology an essential
     distinction, and using (2) instead of (1) could lead to
     interesting inferences (e.g. that the complete Beta
     function is identically 1).

     I.e. the Beta function should not change its definition
     as x passes from 1 - epsilon to 1. And similarly for
     the Gamma.

  Granted there is non-uniformity of usage; but this does
  lead to confusion, which could be avoided by simply sticking
  to the distinction between "Incomplete ... Function" and "...
   Distribution". 

For more detail, see
  http://finzi.psych.upenn.edu/R/Rhelp02a/archive/66717.html
(where, in particular, it is pointed out that both Karl Pearson
and Abramowitz and Stegun are inconsistent, within the same
publication, in their terminology, using "... Function" in one
place to mean the integral, in another to mean the probability
distribution. So it is unwise to appeal to either as the
definitive reference, since the outcome will depend on where
in the book you look it up).

It looks as though the documentation for Igamma (ZipfR package)
at

  http://finzi.psych.upenn.edu/R/library/zipfR/html/beta_gamma.html

is admirably explicit as to how this (and related functions) are
defined, so in this case there is no ambiguity.

In the documenation for the Gamma functions in the gsl package,
it is simply stated

  All functions [including gamma_inc()] as documented in the
  GSL reference manual section 7.19.

There is no function named "gamma_inc" in the GSL reference
manual. See:

http://www.gnu.org/software/gsl/manual/html_node/Function-Index.html

All functions are named like "gsl_sf_gamma_inc", so
presumably this is what is intended; in which case it computes
"the unnormalized incomplete Gamma Function
 \Gamma(a,x) = \int_x^\infty dt t^{a-1} \exp(-t)
 for a real and x >= 0."

And again that is clear enough -- once you track it down!

In many places in the R documentation (including the "?" pages)
people have taken the trouble to spell out mathematical definitions
(where these can be given in reasonable space). Especially in cases
like the Incomplete Gamma and Beta functions, where there can be
dispute over what is meant (see above), it is surely wise to spell
it out!

Best wishes to all,
Ted.

>> On 31 Aug 2007, at 00:29, poolloopus at yahoo.com wrote:
>>
>>> Hello
>>>
>>> I am trying to evaluate an Incomplete gamma function
>>> in R. Library Zipfr gives the Igamma function. From
>>> Mathematica, I have:
>>>
>>> "Gamma[a, z] is the incomplete gamma function."
>>>
>>> In[16]: Gamma[9,11.1]
>>> Out[16]: 9000.5
>>>
>>> Trying the same in R, I get
>>>
>>>> Igamma(9,11.1)
>>> [1] 31319.5
>>> OR
>>>> Igamma(11.1,9)
>>> [1] 1300998
>>>
>>> I know I have to understand the theory and the math
>>> behind it rather than just ask for help, but while I
>>> am trying to do that (and only taking baby steps, I
>>> must admit), I was hoping someone could help me out.
>>>
>>> Regard
>>>
>>> Kris.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 01-Sep-07                                       Time: 15:49:57
------------------------------ XFMail ------------------------------


From lachmann at eva.mpg.de  Sat Sep  1 18:48:55 2007
From: lachmann at eva.mpg.de (Michael Lachmann)
Date: Sat, 1 Sep 2007 18:48:55 +0200
Subject: [R] why doesn't as.character of this factor create a vector
	ofcharacters?
Message-ID: <bae3a3880709010948lab4e0e5r1eaca970bf5cdc4@mail.gmail.com>

This message didn't seem to have been somewhat forgotten. Here is a reply.

When you constructed the data.frame, all strings were converted to
factors. If you didn't want that, it would have been possible to
specify it:

df<-data.frame(a=a,b=b,c=c,stringsAsFactors=F)

Then everything would work as intended:

one.line<-as.character(df[df$a=="Abraham",])

Actually, the real problem is that df[df$a=="Abraham",] returns a
list. There is no need to use as.character here, just unlist:

one.line<-unlist(df[df$a=="Abraham",])

The returned list is also the problem with your code.

If you have a data.frame with factors, then

df[df$a=="Abraham",]

returns a list. Each element of this list is a factor, and has a
different set of levels. Thus, look at the following output:
> c(df[df$a=="Abraham",])
$a
[1] Abraham
Levels: Abraham Jonah Moses

$b
[1] Sarah
Levels: Hannah Mary Sarah

$c
[1] Billy
Levels: Billy Bob Joe

It is quite obvious why it is so complicated to untangle these. I
think the best way would be:

one.line<- sapply(df[df$a=="Abraham",],as.character)

Michael

-----Original Message-----
From: r-help-bounces_at_stat.math.ethz.ch
[mailto:r-help-bounces_at_stat.math.ethz.ch] On Behalf Of Andrew Yee
Sent: Tuesday, July 10, 2007 8:57 AM
To: r-help_at_stat.math.ethz.ch
Subject: [R] why doesn't as.character of this factor create a vector
ofcharacters?

I'm trying to figure out why when I use as.character() on one row of a
data.frame, I get factor numbers instead of a character vector. Any
suggestions?

See the following code:

a<-c("Abraham","Jonah","Moses")
b<-c("Sarah","Hannah","Mary")
c<-c("Billy","Joe","Bob")


df<-data.frame(a=a,b=b,c=c)

#Suppose I'm interested in one line of this data frame but as a vector

one.line <- df[df$a=="Abraham",]

#However the following illustrates the problem I'm having

one.line <- as.vector(df[df$a=="Abraham",]) #Creates a one row
data.frame instead of a vector!

#compare above to

one.line <- as.character(df[df$a=="Abraham",]) #Creates a vector of 1, 3, 1!

#In the end, this creates the output that I'd like:

one.line <-as.vector(t(df[df$a=="Abraham",])) #but it seems like a lot of work!


From shubhak at ambaresearch.com  Sat Sep  1 14:47:51 2007
From: shubhak at ambaresearch.com (Shubha Vishwanath Karanth)
Date: Sat, 1 Sep 2007 18:17:51 +0530
Subject: [R] genoud problem
Message-ID: <A36876D3F8A5734FA84A4338135E7CC30265A139@BAN-MAILSRV03.Amba.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070901/b4190cda/attachment.pl 

From lachmann at eva.mpg.de  Sat Sep  1 21:11:43 2007
From: lachmann at eva.mpg.de (Michael Lachmann)
Date: Sat, 01 Sep 2007 21:11:43 +0200
Subject: [R] why doesn't as.character of this factor create a vector
 ofcharacters?
Message-ID: <46D9B96F.3000307@eva.mpg.de>

This message didn't seem to have been somewhat forgotten. Here is a reply.

When you constructed the data.frame, all strings were converted to
factors. If you didn't want that, it would have been possible to
specify it:

df<-data.frame(a=a,b=b,c=c,stringsAsFactors=F)

Then everything would work as intended:

one.line<-as.character(df[df$a=="Abraham",])

Actually, the real problem is that df[df$a=="Abraham",] returns a
list. There is no need to use as.character here, just unlist:

one.line<-unlist(df[df$a=="Abraham",])

The returned list is also the problem with your code.

If you have a data.frame with factors, then

df[df$a=="Abraham",]

returns a list. Each element of this list is a factor, and has a
different set of levels. Thus, look at the following output:
 > c(df[df$a=="Abraham",])
$a
[1] Abraham
Levels: Abraham Jonah Moses

$b
[1] Sarah
Levels: Hannah Mary Sarah

$c
[1] Billy
Levels: Billy Bob Joe

It is quite obvious why it is so complicated to untangle these. I
think the best way would be:

one.line<- sapply(df[df$a=="Abraham",],as.character)

Michael

-----Original Message-----
From: r-help-bounces_at_stat.math.ethz.ch
[mailto:r-help-bounces_at_stat.math.ethz.ch 
<mailto:r-help-bounces_at_stat.math.ethz.ch>] On Behalf Of Andrew Yee
Sent: Tuesday, July 10, 2007 8:57 AM
To: r-help_at_stat.math.ethz.ch
Subject: [R] why doesn't as.character of this factor create a vector
ofcharacters?

I'm trying to figure out why when I use as.character() on one row of a
data.frame, I get factor numbers instead of a character vector. Any
suggestions?

See the following code:

a<-c("Abraham","Jonah","Moses")
b<-c("Sarah","Hannah","Mary")
c<-c("Billy","Joe","Bob")


df<-data.frame(a=a,b=b,c=c)

#Suppose I'm interested in one line of this data frame but as a vector

one.line <- df[df$a=="Abraham",]

#However the following illustrates the problem I'm having

one.line <- as.vector(df[df$a=="Abraham",]) #Creates a one row
data.frame instead of a vector!

#compare above to

one.line <- as.character(df[df$a=="Abraham",]) #Creates a vector of 1, 3, 1!

#In the end, this creates the output that I'd like:

one.line <-as.vector(t(df[df$a=="Abraham",])) #but it seems like a lot 
of work!


From muenchen at utk.edu  Sat Sep  1 15:23:30 2007
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Sat, 1 Sep 2007 09:23:30 -0400
Subject: [R] Comparing "transform" to "with"
Message-ID: <347152339B716A4D893C9A2988EA87C85E042C@KFSVS2.utk.tennessee.edu>

Hi All,

I've been successfully using the with function for analyses and the
transform function for multiple transformations. Then I thought, why not
use "with" for both? I ran into problems & couldn't figure them out from
help files or books. So I created a simplified version of what I'm
doing:

rm( list=ls() )
x1<-c(1,3,3)
x2<-c(3,2,1)
x3<-c(2,5,2)
x4<-c(5,6,9)
myDF<-data.frame(x1,x2,x3,x4)
rm(x1,x2,x3,x4)
ls()
myDF

This creates two new variables just fine"

transform(myDF,
  sum1=x1+x2,
  sum2=x3+x4
)

This next code does not see sum1, so it appears that "transform" cannot
see the variables that it creates. Would I need to transform new
variables in a second pass?

transform(myDF,
  sum1=x1+x2,
  sum2=x3+x4,
  total=sum1+sum2
)

Next I'm trying the same thing using "with". It doesn't not work but
also does not generate error messages, giving me the impression that I'm
doing something truly idiotic:

with(myDF, {
  sum1<-x1+x2
  sum2<-x3+x4
  total <- sum1+sum2
} )
myDF
ls()

Then I thought, perhaps one of the advantages of "transform" is that it
works on the left side of the equation without using a longer name like
myDF$sum1. "with" probably doesn't do that, so I use the longer form
below. It also does not work and generates no error messages. 

# Try it again, writing vars to myDF explicitly.
# It generates no errors, and no results.
with(myDF, {
  myDF$sum1<-x1+x2
  myDF$sum2<-x3+x4
  myDF$total <- myDF$sum1+myDF$sum2
} )
myDF
ls()

I would appreciate some advice about the relative roles of these two
functions & why my attempts with "with" have failed.

Thanks!
Bob

=========================================================
Bob Muenchen (pronounced Min'-chen), Manager 
Statistical Consulting Center
U of TN Office of Information Technology
200 Stokely Management Center, Knoxville, TN 37996-0520
Voice: (865) 974-5230 
FAX: (865) 974-4810
Email: muenchen at utk.edu
Web: http://oit.utk.edu/scc, 
News: http://listserv.utk.edu/archives/statnews.html


From alexander.heidrich at uni-jena.de  Sat Sep  1 21:34:00 2007
From: alexander.heidrich at uni-jena.de (Alexander Heidrich)
Date: Sat, 1 Sep 2007 21:34:00 +0200
Subject: [R] Importing huge XML-Files
Message-ID: <E6150B63-8B67-407A-B80D-A746E8B3DD2F@uni-jena.de>

Dear all,

for my diploma thesis I have to import huge XML-Files into R for  
statistical processing - huge means a size about 33 MB.

I'm using the XML-Package version 1.9

As far as reading the complete file into R via xmlTreeParse doesn't  
work or is too slow, I'm trying to use xmlEventParse but I got  
completely stuck.

I have many different type of nodes

+ <configuration>

- <Data>
  - <dataSets noOfDataSets="50000">
   - <dataSet number="1">
    - <measurements>
     - <measurement number="1">
      - <MRType1>
         <date>21.04.2005</date>
         <time>10:00</time>
         <plotCode>1</plotCode>
         <collarCode />
         <value>2,33</value>
         <depth />
        </MRType1>
       </measurement>
     - <measurement number="2">
      - <MRType1>
         <date>21.04.2005</date>
         <time>10:00</time>
         <plotCode>1</plotCode>
         <collarCode />
         <value>2,33</value>
         <depth />
        </Soilrespirationrate>
       <MRType2>
	...
+ <personData>
+ <siteData>

I only need the measurement/MRType1 nodes - how can I do this?  
Currently I am trying the following code:

xmlEventParse("/input.xml", list(startElement=xtract.startElement,  
text=xtract.text), useTagName=TRUE, addContext = FALSE)

xtract.startElement <- function(name,attr){
	startElement.name <<- c(startElement.name,name)
	}

xtract.text <- function(text) {
	startElement.value <<- c(startElement.value,text)
	}

this only gives me two lists, one with the all node names (even the  
ones I dont need) and one with the values (also together with the  
ones I dont need) but I can't put things together this way.

What I want is:

No. 	Date	Time	Plotcode	collarcode	value	depth
1	...	...	...		...		...	...
2	...	...	...		...		...	...

Any help is really really appreciated. I tried the whole week,  
starting with xmlTreeParse whick works fine for files with 200  
entries but for files with 50000 entries it keeps crashing my core 2  
duo, 2.4 GHz machine.

Thanks so much in advance! If you need any further information, code  
snippets or XML file details please do not hestitate to mail!

Alex


From p.dalgaard at biostat.ku.dk  Sat Sep  1 22:49:45 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 01 Sep 2007 22:49:45 +0200
Subject: [R] Comparing "transform" to "with"
In-Reply-To: <347152339B716A4D893C9A2988EA87C85E042C@KFSVS2.utk.tennessee.edu>
References: <347152339B716A4D893C9A2988EA87C85E042C@KFSVS2.utk.tennessee.edu>
Message-ID: <46D9D069.7000204@biostat.ku.dk>

Muenchen, Robert A (Bob) wrote:
> Hi All,
>
> I've been successfully using the with function for analyses and the
> transform function for multiple transformations. Then I thought, why not
> use "with" for both? I ran into problems & couldn't figure them out from
> help files or books. So I created a simplified version of what I'm
> doing:
>
> rm( list=ls() )
> x1<-c(1,3,3)
> x2<-c(3,2,1)
> x3<-c(2,5,2)
> x4<-c(5,6,9)
> myDF<-data.frame(x1,x2,x3,x4)
> rm(x1,x2,x3,x4)
> ls()
> myDF
>
> This creates two new variables just fine"
>
> transform(myDF,
>   sum1=x1+x2,
>   sum2=x3+x4
> )
>
> This next code does not see sum1, so it appears that "transform" cannot
> see the variables that it creates. Would I need to transform new
> variables in a second pass?
>
> transform(myDF,
>   sum1=x1+x2,
>   sum2=x3+x4,
>   total=sum1+sum2
> )
>
> Next I'm trying the same thing using "with". It doesn't not work but
> also does not generate error messages, giving me the impression that I'm
> doing something truly idiotic:
>
> with(myDF, {
>   sum1<-x1+x2
>   sum2<-x3+x4
>   total <- sum1+sum2
> } )
> myDF
> ls()
>
> Then I thought, perhaps one of the advantages of "transform" is that it
> works on the left side of the equation without using a longer name like
> myDF$sum1. "with" probably doesn't do that, so I use the longer form
> below. It also does not work and generates no error messages. 
>
> # Try it again, writing vars to myDF explicitly.
> # It generates no errors, and no results.
> with(myDF, {
>   myDF$sum1<-x1+x2
>   myDF$sum2<-x3+x4
>   myDF$total <- myDF$sum1+myDF$sum2
> } )
> myDF
> ls()
>
> I would appreciate some advice about the relative roles of these two
> functions & why my attempts with "with" have failed.
>   
Yes, transform() calculates all its new values, then assigns to the 
given names. This is expedient, but it has the drawback that new 
variables are not usable inside the expressions. A possible alternative 
implementation would be equivalent to a series of nested calls to 
transform, which of course you could also do manually:

transform(
  transform(myDF,
     sum1=x1+x2,
     sum2=x3+x4
  ),
  total=sum1+sum2
)

The problem with with() on data frames and lists is that, like the 
"eval" family of functions, _converts_ the object to an environment, and 
then evaluates the expression in the converted environment. The 
environment is temporary, so assignments to it get lost. The current 
development sources has a new (experimental) function within() which is 
like with(), but stores any modified variables back. (This is very 
recent and may or may not make it to 2.6.0).

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Jhawk3 at ku.edu  Sun Sep  2 09:31:18 2007
From: Jhawk3 at ku.edu (JHawk3)
Date: Sun, 2 Sep 2007 00:31:18 -0700 (PDT)
Subject: [R] Question on graphs and simple if statements
Message-ID: <12446999.post@talk.nabble.com>


Hi all,

I'm a relatively new user to the R interface, and am trying to do some basic
operations. So far I've used the curve() command to plot graphs. This has a
couple of limitations, namely trying to do piecewise graphs. Basically, I'm
looking for how to do "if" and "while" loops for making a graph.

in simple code, something like:

if x is on the interval [-1,1], x=x^2+1
otherwise, x=x^2

something along those lines. I also am wondering if it's possible to graph
something like this:
while(n<20)
{
curve(1/n^2, -1,1)
n++
}
Along these same lines, is there a way to graph finite series?

Thank you for your time and your replies.

-- 
View this message in context: http://www.nabble.com/Question-on-graphs-and-simple-if-statements-tf4366956.html#a12446999
Sent from the R help mailing list archive at Nabble.com.


From lauri.nikkinen at iki.fi  Sun Sep  2 12:29:55 2007
From: lauri.nikkinen at iki.fi (Lauri Nikkinen)
Date: Sun, 2 Sep 2007 13:29:55 +0300
Subject: [R] Function modification: how to calculate values for every
	combination?
Message-ID: <ba8c09910709020329m333f8c88xae3f068ac78993c7@mail.gmail.com>

Hello,

I have a function like this:

fun <- function (x, y) {
          a <- log(10)*y
          b <- log(15)*x
          extr <- a-b
          extr
          }

fun(2,3)
[1] 1.491655

x <- c(1,2,3)
y <- c(4,5,6)
fun(x, y)
[1] 6.502290 6.096825 5.691360

How do I have to modify my function that I can calculate results using
every combination of x and y? I would like to produce a matrix which
includes the calculated values in every cell and names(x) and names(y)
as row and column headers respectively. Is the outer-function a way to
solution?

Best regards,
Lauri


From phhs80 at gmail.com  Sun Sep  2 13:02:06 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Sun, 2 Sep 2007 12:02:06 +0100
Subject: [R] Function modification: how to calculate values for every
	combination?
In-Reply-To: <ba8c09910709020329m333f8c88xae3f068ac78993c7@mail.gmail.com>
References: <ba8c09910709020329m333f8c88xae3f068ac78993c7@mail.gmail.com>
Message-ID: <6ade6f6c0709020402m1fc0cd73yba4bf90f32218aa7@mail.gmail.com>

On 9/2/07, Lauri Nikkinen <lauri.nikkinen at iki.fi> wrote:
> I have a function like this:
>
> fun <- function (x, y) {
>           a <- log(10)*y
>           b <- log(15)*x
>           extr <- a-b
>           extr
>           }
>
> fun(2,3)
> [1] 1.491655
>
> x <- c(1,2,3)
> y <- c(4,5,6)
> fun(x, y)
> [1] 6.502290 6.096825 5.691360
>
> How do I have to modify my function that I can calculate results using
> every combination of x and y? I would like to produce a matrix which
> includes the calculated values in every cell and names(x) and names(y)
> as row and column headers respectively. Is the outer-function a way to
> solution?

Try the following code and adapt it to fill the matrix:

fun <- function (x, y) {
         a <- log(10)*y
         b <- log(15)*x
         extr <- a-b
         extr
}

x <- c(1,2,3)
y <- c(4,5,6)

combs <- expand.grid(x,y)

for (i in 1:nrow(combs))
  cat(fun(combs[i,1],combs[i,2]),"\n")

Paul


From lauri.nikkinen at iki.fi  Sun Sep  2 13:15:43 2007
From: lauri.nikkinen at iki.fi (Lauri Nikkinen)
Date: Sun, 2 Sep 2007 14:15:43 +0300
Subject: [R] Function modification: how to calculate values for every
	combination?
In-Reply-To: <2115.89.166.187.7.1188730759.squirrel@webmail.rz.uni-osnabrueck.de>
References: <ba8c09910709020329m333f8c88xae3f068ac78993c7@mail.gmail.com>
	<2115.89.166.187.7.1188730759.squirrel@webmail.rz.uni-osnabrueck.de>
Message-ID: <ba8c09910709020415j34666fbgcd29b89cf15acbd1@mail.gmail.com>

Yeah, exactly. Thanks. The solution was too obvious :-)

Cheers,
Lauri

2007/9/2, dtrenkle at uni-osnabrueck.de <dtrenkle at uni-osnabrueck.de>:
> > Hello,
> >
> > I have a function like this:
> >
> > fun <- function (x, y) {
> >           a <- log(10)*y
> >           b <- log(15)*x
> >           extr <- a-b
> >           extr
> >           }
> >
> > fun(2,3)
> > [1] 1.491655
> >
> > x <- c(1,2,3)
> > y <- c(4,5,6)
> > fun(x, y)
> > [1] 6.502290 6.096825 5.691360
> >
> > How do I have to modify my function that I can calculate results using
> > every combination of x and y? I would like to produce a matrix which
> > includes the calculated values in every cell and names(x) and names(y)
> > as row and column headers respectively. Is the outer-function a way to
> > solution?
> >
> > Best regards,
> > Lauri
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
> How about
>
> outer(x,y,fun)
>
> ?
>
> hth
>
> D. Trenkler
>
>


From phhs80 at gmail.com  Sun Sep  2 13:16:59 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Sun, 2 Sep 2007 12:16:59 +0100
Subject: [R] Function modification: how to calculate values for every
	combination?
In-Reply-To: <6ade6f6c0709020402m1fc0cd73yba4bf90f32218aa7@mail.gmail.com>
References: <ba8c09910709020329m333f8c88xae3f068ac78993c7@mail.gmail.com>
	<6ade6f6c0709020402m1fc0cd73yba4bf90f32218aa7@mail.gmail.com>
Message-ID: <6ade6f6c0709020416i64fc9876tca4bd22c853a7269@mail.gmail.com>

On 9/2/07, Paul Smith <phhs80 at gmail.com> wrote:
> > I have a function like this:
> >
> > fun <- function (x, y) {
> >           a <- log(10)*y
> >           b <- log(15)*x
> >           extr <- a-b
> >           extr
> >           }
> >
> > fun(2,3)
> > [1] 1.491655
> >
> > x <- c(1,2,3)
> > y <- c(4,5,6)
> > fun(x, y)
> > [1] 6.502290 6.096825 5.691360
> >
> > How do I have to modify my function that I can calculate results using
> > every combination of x and y? I would like to produce a matrix which
> > includes the calculated values in every cell and names(x) and names(y)
> > as row and column headers respectively. Is the outer-function a way to
> > solution?
>
> Try the following code and adapt it to fill the matrix:
>
> fun <- function (x, y) {
>          a <- log(10)*y
>          b <- log(15)*x
>          extr <- a-b
>          extr
> }
>
> x <- c(1,2,3)
> y <- c(4,5,6)
>
> combs <- expand.grid(x,y)
>
> for (i in 1:nrow(combs))
>   cat(fun(combs[i,1],combs[i,2]),"\n")

The complete code can be:

fun <- function (x, y) {
         a <- log(10)*y
         b <- log(15)*x
         extr <- a-b
         extr
}

x <- c(1,2,3)
y <- c(4,5,6)

combs <- expand.grid(x,y)

a <- vector()

for (i in 1:nrow(combs))
  a[i] <- fun(combs[i,1],combs[i,2])

m <- matrix(a,3,3)
rownames(m) <- x
colnames(m) <- y

m

Paul


From r.darnell at uq.edu.au  Sun Sep  2 13:52:59 2007
From: r.darnell at uq.edu.au (Ross Darnell)
Date: Sun, 02 Sep 2007 21:52:59 +1000
Subject: [R] Question on graphs and simple if statements
In-Reply-To: <12446999.post@talk.nabble.com>
References: <12446999.post@talk.nabble.com>
Message-ID: <1188733979.9358.2.camel@Marvin>

The answer to your first question is

curve(ifelse((x>-1)&(x<1),x^2+1,x+2),from=-10,to=10)

Sorry I cannot understand the next part of your query.

Ross Darnell

On Sun, 2007-09-02 at 00:31 -0700, JHawk3 wrote:
> Hi all,
> 
> I'm a relatively new user to the R interface, and am trying to do some basic
> operations. So far I've used the curve() command to plot graphs. This has a
> couple of limitations, namely trying to do piecewise graphs. Basically, I'm
> looking for how to do "if" and "while" loops for making a graph.
> 
> in simple code, something like:
> 
> if x is on the interval [-1,1], x=x^2+1
> otherwise, x=x^2
> 
> something along those lines. I also am wondering if it's possible to graph
> something like this:
> while(n<20)
> {
> curve(1/n^2, -1,1)
> n++
> }
> Along these same lines, is there a way to graph finite series?
> 
> Thank you for your time and your replies.
>


From muenchen at utk.edu  Sun Sep  2 16:20:26 2007
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Sun, 2 Sep 2007 10:20:26 -0400
Subject: [R] NAs in indices
Message-ID: <347152339B716A4D893C9A2988EA87C85E044D@KFSVS2.utk.tennessee.edu>

Hi All,

I'm fiddling with an program to read a text file containing periods that
SAS uses for missing values. I know that if I had the original SAS data
set instead of a text file, R would handle this conversion for me. 

Data frames do not allow missing values in their indices but vectors do.
Why is that? A search of the error message points out the problem and
solution but not why they differ. A simplified program that demonstrates
the issue is below.

Thanks,
Bob

# Here's a data frame that has both periods and NAs.
# I want sex to remain character for now.

sex=c("m","f",".",NA)
x=c(1,2,3,NA)
myDF <- data.frame(sex,x,stringsAsFactors=F)
rm(sex,x)
myDF

# Substituting NA into data frame does not work
# due to NAs in the indices. The error message is:
# missing values are not allowed in subscripted assignments of data
frames

myDF[ myDF$sex==".", "sex" ] <- NA
myDF

# This works because myDF$sex is a vector and vectors allow NAs in
indexes.
# Why don't data frames allow this?

myDF$sex[ myDF$sex=="." ] <- NA
myDF

=========================================================
Bob Muenchen (pronounced Min'-chen), Manager 
Statistical Consulting Center
U of TN Office of Information Technology
200 Stokely Management Center, Knoxville, TN 37996-0520
Voice: (865) 974-5230 
FAX: (865) 974-4810
Email: muenchen at utk.edu
Web: http://oit.utk.edu/scc, 
News: http://listserv.utk.edu/archives/statnews.html


From ggrothendieck at gmail.com  Sun Sep  2 16:46:49 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 2 Sep 2007 10:46:49 -0400
Subject: [R] Comparing "transform" to "with"
In-Reply-To: <347152339B716A4D893C9A2988EA87C85E042C@KFSVS2.utk.tennessee.edu>
References: <347152339B716A4D893C9A2988EA87C85E042C@KFSVS2.utk.tennessee.edu>
Message-ID: <971536df0709020746u64a8d9bfud1802413c2785412@mail.gmail.com>

Try this version of transform.  In the first test we show
it works on your example but we have used the head of the built in
anscombe data set.  The second and third show that
it necessarily is incompatible with transform because transform
always looks up variables in DF first whereas my.transform looks
up the computed ones first.

my.transform <- function(DF, ...) {
	f <- function(){}
	formals(f) <- eval(substitute(as.pairlist(c(alist(...), DF))))
	body(f) <- substitute(modifyList(DF, data.frame(...)))
	f()
}

# test
a <- head(anscombe)
# 1
my.transform(a, sum1 = x1+x2+x3+x4, sum2 = y1+y2+y3+y4, total = sum1+sum2)
# 2
my.transform(a, y2 = y1, y3 = y2)
# 3
transform(a, y2 = y1, y3 = y2) # different


On 9/1/07, Muenchen, Robert A (Bob) <muenchen at utk.edu> wrote:
> Hi All,
>
> I've been successfully using the with function for analyses and the
> transform function for multiple transformations. Then I thought, why not
> use "with" for both? I ran into problems & couldn't figure them out from
> help files or books. So I created a simplified version of what I'm
> doing:
>
> rm( list=ls() )
> x1<-c(1,3,3)
> x2<-c(3,2,1)
> x3<-c(2,5,2)
> x4<-c(5,6,9)
> myDF<-data.frame(x1,x2,x3,x4)
> rm(x1,x2,x3,x4)
> ls()
> myDF
>
> This creates two new variables just fine"
>
> transform(myDF,
>  sum1=x1+x2,
>  sum2=x3+x4
> )
>
> This next code does not see sum1, so it appears that "transform" cannot
> see the variables that it creates. Would I need to transform new
> variables in a second pass?
>
> transform(myDF,
>  sum1=x1+x2,
>  sum2=x3+x4,
>  total=sum1+sum2
> )
>
> Next I'm trying the same thing using "with". It doesn't not work but
> also does not generate error messages, giving me the impression that I'm
> doing something truly idiotic:
>
> with(myDF, {
>  sum1<-x1+x2
>  sum2<-x3+x4
>  total <- sum1+sum2
> } )
> myDF
> ls()
>
> Then I thought, perhaps one of the advantages of "transform" is that it
> works on the left side of the equation without using a longer name like
> myDF$sum1. "with" probably doesn't do that, so I use the longer form
> below. It also does not work and generates no error messages.
>
> # Try it again, writing vars to myDF explicitly.
> # It generates no errors, and no results.
> with(myDF, {
>  myDF$sum1<-x1+x2
>  myDF$sum2<-x3+x4
>  myDF$total <- myDF$sum1+myDF$sum2
> } )
> myDF
> ls()
>
> I would appreciate some advice about the relative roles of these two
> functions & why my attempts with "with" have failed.
>
> Thanks!
> Bob
>
> =========================================================
> Bob Muenchen (pronounced Min'-chen), Manager
> Statistical Consulting Center
> U of TN Office of Information Technology
> 200 Stokely Management Center, Knoxville, TN 37996-0520
> Voice: (865) 974-5230
> FAX: (865) 974-4810
> Email: muenchen at utk.edu
> Web: http://oit.utk.edu/scc,
> News: http://listserv.utk.edu/archives/statnews.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From erich.neuwirth at univie.ac.at  Sun Sep  2 17:41:55 2007
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Sun, 02 Sep 2007 17:41:55 +0200
Subject: [R] Function modification: how to calculate values for every
 combination?
In-Reply-To: <ba8c09910709020329m333f8c88xae3f068ac78993c7@mail.gmail.com>
References: <ba8c09910709020329m333f8c88xae3f068ac78993c7@mail.gmail.com>
Message-ID: <46DAD9C3.5080101@univie.ac.at>

outer(x,y,fun)

Lauri Nikkinen wrote:
> Hello,
> 
> I have a function like this:
> 
> fun <- function (x, y) {
>           a <- log(10)*y
>           b <- log(15)*x
>           extr <- a-b
>           extr
>           }
> 
> fun(2,3)
> [1] 1.491655
> 
> x <- c(1,2,3)
> y <- c(4,5,6)
> fun(x, y)
> [1] 6.502290 6.096825 5.691360
> 
> How do I have to modify my function that I can calculate results using
> every combination of x and y? I would like to produce a matrix which
> includes the calculated values in every cell and names(x) and names(y)
> as row and column headers respectively. Is the outer-function a way to
> solution?
> 
> Best regards,
> Lauri
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 


-- 
Erich Neuwirth, University of Vienna
Faculty of Computer Science
Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-39464 Fax: +43-1-4277-39459


From ggrothendieck at gmail.com  Sun Sep  2 18:01:25 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 2 Sep 2007 12:01:25 -0400
Subject: [R] Function modification: how to calculate values for every
	combination?
In-Reply-To: <46DAD9C3.5080101@univie.ac.at>
References: <ba8c09910709020329m333f8c88xae3f068ac78993c7@mail.gmail.com>
	<46DAD9C3.5080101@univie.ac.at>
Message-ID: <971536df0709020901p16377f2ay4cc1e261e3de542b@mail.gmail.com>

Just to add to this be sure you do have names if you want them
and read about vectorization in ?outer in case fun was just an
example and your actual fun is more complex:

x <- c(1,2,3)
names(x) <- x
y <- c(4,5,6)
names(y) <- y

outer(x, y, fun) # as in previous answer

# or
 outer(-log(15) * x, log(10) * y, "+")


On 9/2/07, Erich Neuwirth <erich.neuwirth at univie.ac.at> wrote:
> outer(x,y,fun)
>
> Lauri Nikkinen wrote:
> > Hello,
> >
> > I have a function like this:
> >
> > fun <- function (x, y) {
> >           a <- log(10)*y
> >           b <- log(15)*x
> >           extr <- a-b
> >           extr
> >           }
> >
> > fun(2,3)
> > [1] 1.491655
> >
> > x <- c(1,2,3)
> > y <- c(4,5,6)
> > fun(x, y)
> > [1] 6.502290 6.096825 5.691360
> >
> > How do I have to modify my function that I can calculate results using
> > every combination of x and y? I would like to produce a matrix which
> > includes the calculated values in every cell and names(x) and names(y)
> > as row and column headers respectively. Is the outer-function a way to
> > solution?
> >
> > Best regards,


From f.jamitzky at gmail.com  Sun Sep  2 18:59:52 2007
From: f.jamitzky at gmail.com (f.jamitzky)
Date: Sun, 2 Sep 2007 09:59:52 -0700 (PDT)
Subject: [R] Importing huge XML-Files
In-Reply-To: <E6150B63-8B67-407A-B80D-A746E8B3DD2F@uni-jena.de>
References: <E6150B63-8B67-407A-B80D-A746E8B3DD2F@uni-jena.de>
Message-ID: <12451059.post@talk.nabble.com>


Hi!

try pre-filtering with xmlstarlet. you could use a pipe and then read the
resulting data into R.
-- 
View this message in context: http://www.nabble.com/Importing-huge-XML-Files-tf4365545.html#a12451059
Sent from the R help mailing list archive at Nabble.com.


From h.wickham at gmail.com  Sun Sep  2 18:53:46 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 2 Sep 2007 11:53:46 -0500
Subject: [R] [R-pkgs] ggplot2 - version 0.5.5
Message-ID: <f8e6ff050709020953r248fd0d5l8edcee4466d23acf@mail.gmail.com>

ggplot2
===================================

ggplot2 is a plotting system for R, based on the grammar of graphics,
which tries to take the good parts of base and lattice graphics and
avoid bad parts. It takes care of many of the fiddly details
that make plotting a hassle (like drawing legends) as well as
providing a powerful model of graphics that makes it easy to produce
complex multi-layered graphics.

Find out more at http://had.co.nz/ggplot2, and check out the over 500
examples of ggplot in use.


Changes in version 0.5.5
----------------------------------------

Improvements:
	* ggplot now gives rather more helpful errors if you have
misspecified a variable name in the aesthetic mapping
	* changed default hline and vline intercepts to 0
	* added "count" output variable from stat_density for creating
stacked/conditional density plots
	* added parameters to geom_boxplot to control appearance of outlying points
	* overriding aesthetics with fixed values that have already been set
with aesthetics now actually works
	* slightly better names for xaxis and yaxis grobs
	* added aes_string function to make it easier to construction
aesthetic mapping specifications in functions
	* continuous scales now have labels argument so that you can manually
specify labels if desired
	* stat_density now calculates densities on a common grid across
groups.  This means that position_fill and position_stack now work
properly
	* if numeric, legend labels right aligned
	* polar coordinates much improved, and with better examples

Documentation:
	* fixed argument documentation for qplot
	* added (very) rudimentary documentation about what functions return
	* documentation now lists extra variables created by statistics

Bug fixes:
	* coord_flip now works with segment and all interval geoms
	* geom_errorbar now works in all coordinate systems
	* derived y axes (eg. on histogram) are now labelled correctly
	* fixed bug in stat_quantile caused by new output format from predict.rq
	* fixed bug if x or y are constant
	* fixed bug in histogram where sometimes lowest bar was omitted
	* fixed bug in stat_qq which prevent setting aesthetics
	* fixed bug in qplot(..., geom="density", position="identity")
	* fixed stat_qq so that unnecessary arguments are no longer passed to
the distribution function

Subtractions:
	* removed grid argument from ggsave, replaced by ggtheme(theme_bw)
	* removed add argument from qplot


Regards,

Hadley

-- 
http://had.co.nz/

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From cberry at tajo.ucsd.edu  Sun Sep  2 20:33:27 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Sun, 2 Sep 2007 11:33:27 -0700
Subject: [R] NAs in indices
In-Reply-To: <347152339B716A4D893C9A2988EA87C85E044D@KFSVS2.utk.tennessee.edu>
References: <347152339B716A4D893C9A2988EA87C85E044D@KFSVS2.utk.tennessee.edu>
Message-ID: <Pine.LNX.4.64.0709021125030.26367@tajo.ucsd.edu>

On Sun, 2 Sep 2007, Muenchen, Robert A (Bob) wrote:

> Hi All,
>
> I'm fiddling with an program to read a text file containing periods that
> SAS uses for missing values. I know that if I had the original SAS data
> set instead of a text file, R would handle this conversion for me.
>
> Data frames do not allow missing values in their indices but vectors do.
> Why is that? A search of the error message points out the problem and
> solution but not why they differ. A simplified program that demonstrates
> the issue is below.
>
> Thanks,
> Bob
>
> # Here's a data frame that has both periods and NAs.
> # I want sex to remain character for now.
>
> sex=c("m","f",".",NA)
> x=c(1,2,3,NA)
> myDF <- data.frame(sex,x,stringsAsFactors=F)
> rm(sex,x)
> myDF
>
> # Substituting NA into data frame does not work
> # due to NAs in the indices. The error message is:
> # missing values are not allowed in subscripted assignments of data
> frames
>
> myDF[ myDF$sex==".", "sex" ] <- NA
> myDF
>
> # This works because myDF$sex is a vector and vectors allow NAs in
> indexes.
> # Why don't data frames allow this?
>
> myDF$sex[ myDF$sex=="." ] <- NA
> myDF


R version 2.5.1  'allows' it.


> df <- as.data.frame(diag(3)[,-1])
> df[ df[,1]==1 ] <- NA
> df

but the result may not be what you were expecting. See

 	 ?"[.data.frame"

(esp. Details) for more info on why it does not 'work' as you expected.


Also, since you mention a 'text file' I suggest you look at

 	 ?read.table

or

 	?scan

where you will see that

 	dots.are.NA <- read.table("my.file", na.strings = '.' )

may help you.

Chuck

>
> =========================================================
> Bob Muenchen (pronounced Min'-chen), Manager
> Statistical Consulting Center
> U of TN Office of Information Technology
> 200 Stokely Management Center, Knoxville, TN 37996-0520
> Voice: (865) 974-5230
> FAX: (865) 974-4810
> Email: muenchen at utk.edu
> Web: http://oit.utk.edu/scc,
> News: http://listserv.utk.edu/archives/statnews.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From christof.bigler at env.ethz.ch  Sun Sep  2 20:57:22 2007
From: christof.bigler at env.ethz.ch (Christof Bigler)
Date: Sun, 2 Sep 2007 20:57:22 +0200
Subject: [R] Assigning line colors in xyplot
In-Reply-To: <eb555e660708311532n27c53f1dmf6bae720785d3f97@mail.gmail.com>
References: <46D6B5E9.1010908@env.ethz.ch>
	<eb555e660708300940v28a70503m3eac68df7966b784@mail.gmail.com>
	<46D7E617.9020108@env.ethz.ch>
	<eb555e660708311532n27c53f1dmf6bae720785d3f97@mail.gmail.com>
Message-ID: <0DA1BE54-6EC4-48FD-9502-B7A9058181DA@env.ethz.ch>

Thanks to Deepayan and Hadley for their help, both solutions work,  
not only for the example below, but also for my "real" data set that  
I'm about to analyze.

Christof


On 01.09.2007, at 00:32, Deepayan Sarkar wrote:
> On 8/31/07, Christof Bigler <christof.bigler at env.ethz.ch> wrote:
>> The suggestions by Deepayan Sarkar and Hadley Wickham work for that
>> case, but I get into troubles when I try to draw e.g. a panel for "A"
>> and "B":
>>
>> xyplot(y ~ x | f , groups=g, data=tmp,type="l",
>>       par.settings=list(superpose.line=list(col=c("red","blue"))),
>>       auto.key=list(space="top",
>> text=levels(tmp$f),points=FALSE,lines=TRUE))
>>
>> Similarly for xyplot(y ~ x | f , groups=f, ...)
>>
>>
>> Let's assume that we use a slightly more complex dataframe, where we
>> have different individuals a, ..., f (grouping variable "h") with  
>> 1 or 2
>> series of measurements per individual (grouping variable "g"). The
>> individuals are grouped as "A" or "B" (grouping variable "f")  
>> according
>> to the distribution of the values in the variable "y".
>>
>> set.seed(1)
>> tmp2 <- data.frame(
>>
>> y=c(rnorm(10,0,1),rnorm(10,4,2),rnorm(10,4,2),rnorm(10,4,2),rnorm 
>> (10,0,1),rnorm(10,0,1),rnorm(10,0,1),rnorm(10,4,2),rnorm(10,0,1)),
>>       x=1:10,
>>
>> f=c(rep("A",10),rep("B",10),rep("B",10),rep("B",10),rep("A",10),rep 
>> ("A",10),rep("A",10),rep("B",10),rep("A",10)),
>>
>> g=c(rep("1",10),rep("2",10),rep("3",10),rep("4",10),rep("5",10),rep 
>> ("6",10),rep("7",10),rep("8",10),rep("9",10)),
>>
>> h=c(rep("a",10),rep("b",10),rep("b",10),rep("c",10),rep("d",10),rep 
>> ("d",10),rep("e",10),rep("f",10),rep("e",10)))
>>
>> Again, the line colors in the following plot are correct:
>>
>> xyplot(y ~ x | g , groups=f, data=tmp2,type="l",
>>       par.settings=list(superpose.line=list(col=c("red","blue"))),
>>       auto.key=list(space="top", points=FALSE,lines=TRUE))
>>
>> But, if I want to show e.g. one panel per individual, the  
>> assignment of
>> the colors is not correct:
>>
>> xyplot(y ~ x | h , groups=g,
>> data=tmp2,type="l",
>>
>> par.settings=list(superpose.line=list(col=c("red","blue"))),
>>
>>       auto.key=list(space="top", text=levels(tmp2$f),
>> points=FALSE,lines=TRUE))
>>
>>
>> Any suggestions?
>
> This works (only the 'groups' argument is different from your call):
>
> xyplot(y ~ x | h , groups=interaction(f, g),
> data=tmp2,type="l",
>
> par.settings=list(superpose.line=list(col=c("red","blue"))),
>
>      auto.key=list(space="top", text=levels(tmp2$f),
> points=FALSE,lines=TRUE))
>
>
> Note that unlike ggplot, you cannot (easily) use a different variable
> for grouping and coloring. Fortunately, the levels of interaction(f,
> g) are such that your colors (red, blue) are repeated in the right
> order, so you don't need to do much extra work.
>
> -Deepayan


From mtmorgan at fhcrc.org  Sun Sep  2 21:23:06 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 02 Sep 2007 12:23:06 -0700
Subject: [R] Importing huge XML-Files
In-Reply-To: <E6150B63-8B67-407A-B80D-A746E8B3DD2F@uni-jena.de> (Alexander
	Heidrich's message of "Sat, 1 Sep 2007 21:34:00 +0200")
References: <E6150B63-8B67-407A-B80D-A746E8B3DD2F@uni-jena.de>
Message-ID: <6phabs4ub1h.fsf@gopher4.fhcrc.org>

Hi Alex --

Try xmlTreeParse with useInternalNodes=TRUE. This will likely allow
you to read the document in easily, even with limited memory (33MB
does not sound too 'huge').

To extract just the node sets you're interested in, use getNodeSet or
xpathApply. This is easier (with a little extra learning, e.g.,
http://www.w3.org/TR/xpath20/#abbrev) and more memory efficient than
creating a DOM parser. Something like (WARNING: not tested!!)

> doc <- xmlTreeParse("doc.xml", useInternalNode=TRUE)
> res <- getNodeSet(doc, "//MRType1")

will return (pointers to) all the MRType1 nodes. You could then use
sapply and xmlValue, or more directly

> dates <- xpathApply(doc, "//MRType1/date", xmlValue)

and the like to extract specific values.  The examples and help page
for xpathApply are useful to get you going.

Watch out for memory use, and the need to 'free' the original 'doc'
and perhaps other intermediate objects.

Martin

Alexander Heidrich <alexander.heidrich at uni-jena.de> writes:

> Dear all,
>
> for my diploma thesis I have to import huge XML-Files into R for  
> statistical processing - huge means a size about 33 MB.
>
> I'm using the XML-Package version 1.9
>
> As far as reading the complete file into R via xmlTreeParse doesn't  
> work or is too slow, I'm trying to use xmlEventParse but I got  
> completely stuck.
>
> I have many different type of nodes
>
> + <configuration>
>
> - <Data>
>   - <dataSets noOfDataSets="50000">
>    - <dataSet number="1">
>     - <measurements>
>      - <measurement number="1">
>       - <MRType1>
>          <date>21.04.2005</date>
>          <time>10:00</time>
>          <plotCode>1</plotCode>
>          <collarCode />
>          <value>2,33</value>
>          <depth />
>         </MRType1>
>        </measurement>
>      - <measurement number="2">
>       - <MRType1>
>          <date>21.04.2005</date>
>          <time>10:00</time>
>          <plotCode>1</plotCode>
>          <collarCode />
>          <value>2,33</value>
>          <depth />
>         </Soilrespirationrate>
>        <MRType2>
> 	...
> + <personData>
> + <siteData>
>
> I only need the measurement/MRType1 nodes - how can I do this?  
> Currently I am trying the following code:
>
> xmlEventParse("/input.xml", list(startElement=xtract.startElement,  
> text=xtract.text), useTagName=TRUE, addContext = FALSE)
>
> xtract.startElement <- function(name,attr){
> 	startElement.name <<- c(startElement.name,name)
> 	}
>
> xtract.text <- function(text) {
> 	startElement.value <<- c(startElement.value,text)
> 	}
>
> this only gives me two lists, one with the all node names (even the  
> ones I dont need) and one with the values (also together with the  
> ones I dont need) but I can't put things together this way.
>
> What I want is:
>
> No. 	Date	Time	Plotcode	collarcode	value	depth
> 1	...	...	...		...		...	...
> 2	...	...	...		...		...	...
>
> Any help is really really appreciated. I tried the whole week,  
> starting with xmlTreeParse whick works fine for files with 200  
> entries but for files with 50000 entries it keeps crashing my core 2  
> duo, 2.4 GHz machine.
>
> Thanks so much in advance! If you need any further information, code  
> snippets or XML file details please do not hestitate to mail!
>
> Alex
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From pomchip at free.fr  Mon Sep  3 00:03:10 2007
From: pomchip at free.fr (=?ISO-8859-1?Q?S=E9bastien?=)
Date: Sun, 02 Sep 2007 18:03:10 -0400
Subject: [R] Different behavior of mtext
Message-ID: <46DB331E.8030004@free.fr>

Dear R Users,

I am quite surprised to see that mtext gives different results when it 
is used with 'pairs' and with "plot'. In the two following codes, it 
seems that the 'at' argument in mtext doesn't consider the same unit system.

I would appreciate your comments on this issue.

Sebastien

##### Pairs

mydata<-data.frame(x=1:10,y=1:10)

par(cex.main=1, cex.axis=1, cex.lab=1, lwd=1,
    mar=c(5 + 5,4,4,2)+0.1)
   
pairs(mydata,oma=c(5 + 5,4,4,2))

mylegend<-c("mylegend A","mylegend B","mylegend C","mylegend test")
mylegend.width = strwidth(mylegend[which.max(nchar(mylegend))], "figure")

for (i in 1:4) {
mtext(text=mylegend[i],
        side = 1,
        line = 3+i,
        at = unit((1-mylegend.width)/2,"npc"),            # centers the 
legend at the bottom
        adj=0,
        padj=0)}

##### plot

mydata<-data.frame(x=1:10,y=1:10)

par(cex.main=1, cex.axis=1, cex.lab=1, lwd=1,
    mar=c(5 + 5,4,4,2)+0.1)
   
plot(mydata,oma=c(5 + 5,4,4,2))

mylegend<-c("mylegend A","mylegend B","mylegend C","mylegend test")
mylegend.width = strwidth(mylegend[which.max(nchar(mylegend))], "figure")

for (i in 1:4) {
mtext(text=mylegend[i],
        side = 1,
        line = 3+i,
        at = unit((1-mylegend.width)/2,"npc"),            # should 
center the legend at the bottom but doesn't do it !
        adj=0,
        padj=0)}


From FolkesM at pac.dfo-mpo.gc.ca  Mon Sep  3 02:43:27 2007
From: FolkesM at pac.dfo-mpo.gc.ca (Folkes, Michael)
Date: Sun, 2 Sep 2007 17:43:27 -0700
Subject: [R] Lattice:can't subset in panel function using other variables
References: <eb555e660708311404r3797089bp2a07faa57bdd4bd1@mail.gmail.com><63F107BCC37AEA49A75FD94AA3E07CB099F518@pacpbsex01.pac.dfo-mpo.ca>
	<eb555e660708311718x59f17f8bv9a580a1470457b3e@mail.gmail.com>
Message-ID: <63F107BCC37AEA49A75FD94AA3E07CB01236BF@pacpbsex01.pac.dfo-mpo.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070902/425bb078/attachment.pl 

From paulaugust2003 at yahoo.com  Mon Sep  3 06:18:18 2007
From: paulaugust2003 at yahoo.com (Paul August)
Date: Sun, 2 Sep 2007 21:18:18 -0700 (PDT)
Subject: [R] Synchronzing workspaces
Message-ID: <609287.49026.qm@web58403.mail.re3.yahoo.com>

Thanks for sharing your experience. In my case, the involved machines are Windows Vista, XP and 2000. Not sure whether it contributes to my problem or not. I will look into this further.

I just noticed the two arguments ascii and compress for save. However, my .RData file was created by q() with "yes". The manual says that q() is equivalent to save(list = ls(all=TRUE), file = ".RData"). There seems to be no way to set ascii or compression of save through q function, unless the q function is replaced explicitly with save(list = ls(all=TRUE), file = ".RData", ascii = T).

Paul.


----- Original Message ----
From: Gabor Grothendieck <ggrothendieck at gmail.com>
To: Paul August <paulaugust2003 at yahoo.com>
Cc: r-help at stat.math.ethz.ch
Sent: Thursday, August 30, 2007 11:24:31 PM
Subject: Re: [R] Synchronzing workspaces

I haven't had similar experience but note that save has ascii=
and compress= arguments.  You could check if varying those
parameter values makes a difference.

On 8/30/07, Paul August <paulaugust2003 at yahoo.com> wrote:
> I used to work on several computers and to use a flash drive to synchronize the workspace on each machine before starting to work on it. I found that .RData always caused some trouble: Often it is corrupted even though there is no error in copying process. Does anybody have the similar experience?
>
> Paul.
>
> ----- Original Message ----
> From: Barry Rowlingson <b.rowlingson at lancaster.ac.uk>
> To: Eric Turkheimer <ent3c at virginia.edu>
> Cc: r-help at stat.math.ethz.ch
> Sent: Wednesday, August 22, 2007 9:43:57 AM
> Subject: Re: [R] Synchronzing workspaces
>
> Eric Turkheimer wrote:
> > How do people go about synchronizing multiple workspaces on different
> > workstations?  I tend to wind up with projects spread around the various
> > machines I work on.  I find that placing the directories on a server and
> > reading them remotely tends to slow things down.
>
>  If R were to store all its workspace data objects in individual files
> instead of one big .RData file, then you could use a revision control
> system like SVN.  Check out the data, work on it, check it in, then on
> another machine just update to get the changes.
>
>  However SVN doesn't work too well for binary files - conflicts being
> hard to resolve without someone backing down - so maybe its not such a
> good idea anyway...
>
>  On unix boxes and derivatives, you can keep things in sync efficiently
> with the 'rsync' command.  I think there are GUI addons for it, and
> Windows ports.
>
> Barry
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
>
> ____________________________________________________________________________________
>
> Comedy with an Edge to see what's on, when.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Mon Sep  3 06:31:38 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 3 Sep 2007 00:31:38 -0400
Subject: [R] Synchronzing workspaces
In-Reply-To: <609287.49026.qm@web58403.mail.re3.yahoo.com>
References: <609287.49026.qm@web58403.mail.re3.yahoo.com>
Message-ID: <971536df0709022131s33ad79f7m43a642fb83822b7@mail.gmail.com>

You could try saving prior to quitting in the future if you want to try
those arguments.

On 9/3/07, Paul August <paulaugust2003 at yahoo.com> wrote:
> Thanks for sharing your experience. In my case, the involved machines are Windows Vista, XP and 2000. Not sure whether it contributes to my problem or not. I will look into this further.
>
> I just noticed the two arguments ascii and compress for save. However, my .RData file was created by q() with "yes". The manual says that q() is equivalent to save(list = ls(all=TRUE), file = ".RData"). There seems to be no way to set ascii or compression of save through q function, unless the q function is replaced explicitly with save(list = ls(all=TRUE), file = ".RData", ascii = T).
>
> Paul.
>
>
> ----- Original Message ----
> From: Gabor Grothendieck <ggrothendieck at gmail.com>
> To: Paul August <paulaugust2003 at yahoo.com>
> Cc: r-help at stat.math.ethz.ch
> Sent: Thursday, August 30, 2007 11:24:31 PM
> Subject: Re: [R] Synchronzing workspaces
>
> I haven't had similar experience but note that save has ascii=
> and compress= arguments.  You could check if varying those
> parameter values makes a difference.
>
> On 8/30/07, Paul August <paulaugust2003 at yahoo.com> wrote:
> > I used to work on several computers and to use a flash drive to synchronize the workspace on each machine before starting to work on it. I found that .RData always caused some trouble: Often it is corrupted even though there is no error in copying process. Does anybody have the similar experience?
> >
> > Paul.
> >
> > ----- Original Message ----
> > From: Barry Rowlingson <b.rowlingson at lancaster.ac.uk>
> > To: Eric Turkheimer <ent3c at virginia.edu>
> > Cc: r-help at stat.math.ethz.ch
> > Sent: Wednesday, August 22, 2007 9:43:57 AM
> > Subject: Re: [R] Synchronzing workspaces
> >
> > Eric Turkheimer wrote:
> > > How do people go about synchronizing multiple workspaces on different
> > > workstations?  I tend to wind up with projects spread around the various
> > > machines I work on.  I find that placing the directories on a server and
> > > reading them remotely tends to slow things down.
> >
> >  If R were to store all its workspace data objects in individual files
> > instead of one big .RData file, then you could use a revision control
> > system like SVN.  Check out the data, work on it, check it in, then on
> > another machine just update to get the changes.
> >
> >  However SVN doesn't work too well for binary files - conflicts being
> > hard to resolve without someone backing down - so maybe its not such a
> > good idea anyway...
> >
> >  On unix boxes and derivatives, you can keep things in sync efficiently
> > with the 'rsync' command.  I think there are GUI addons for it, and
> > Windows ports.
> >
> > Barry
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> >
> >
> > ____________________________________________________________________________________
> >
> > Comedy with an Edge to see what's on, when.
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From thefishfinger at ihug.com.au  Mon Sep  3 06:38:20 2007
From: thefishfinger at ihug.com.au (Sam Ferguson)
Date: Mon, 3 Sep 2007 14:38:20 +1000
Subject: [R] Embedding Audio Files in Interactive Graphs
Message-ID: <BF3763F1-43DD-4325-8A4F-92F8E3285B4F@ihug.com.au>

Hi R-ers,

I'm wondering if anyone has investigated a method for embedding audio  
files in R graphs (pdf format), and allowing their playback to be  
triggered interactively (by clicking on a graph element for instance).

I know how to do this in latex pdfs with the multimedia package, but  
it seems that R would provide a more appropriate platform for many  
reasons.

Thanks for any help you can provide.
Sam Ferguson
Faculty of Architecture, Design and Planning
The University of Sydney


From ywchun at gmail.com  Mon Sep  3 08:36:10 2007
From: ywchun at gmail.com (Yongwan Chun)
Date: Mon, 3 Sep 2007 01:36:10 -0500
Subject: [R] element wise opertation between a vector and a list
Message-ID: <d89bf0cd0709022336l7122dfd9x7e423b2316a56201@mail.gmail.com>

I want to try to get a result of element wise addition between a
vector and a list. It can be done with "for statement." In order to
reducing computing time, I have tried to avoid "for state." If anybody
give me an idea, I would apprecite it much.

for example, with a & b as below lines,

a<- list(c(1,3),c(1,2),c(2,3))
b<-c(10,20,30)

I would like to have a list (like "d") or a vector (like "e") as below.

d<-list(c((1+10),(3+10)),c((1+20),(2+20)),c((2+30),(3+30)))
e<- c((1+10)+(3+10),(1+20)+(2+20),(2+30)+(3+30))

Thanks,


Yongwan Chun


From n.nguyen at garvan.org.au  Mon Sep  3 08:43:06 2007
From: n.nguyen at garvan.org.au (Nguyen Dinh Nguyen)
Date: Mon, 3 Sep 2007 16:43:06 +1000
Subject: [R] sin(pi)?
Message-ID: <000501c7edf5$af58eec0$0fe05e81@D145LD1S>

Dear all,
I found something strange when calculating sin of pi value
sin(pi)
[1] 1.224606e-16

 pi
[1] 3.141593

 sin(3.141593)
[1] -3.464102e-07

Any help and comment should be appreciated. 
Regards
Nguyen

____________________________
Nguyen Dinh Nguyen
Garvan Institute of Medical Research
Sydney, Australia


From yogesh.mpi at googlemail.com  Sun Sep  2 16:04:19 2007
From: yogesh.mpi at googlemail.com (Yogesh Tiwari)
Date: Sun, 2 Sep 2007 15:04:19 +0100
Subject: [R] how to sub-sample a variable on another file coordinates
Message-ID: <71cc5ca20709020704p38002693v158a2555b363c8e2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070902/a1a2c9a6/attachment.pl 

From info at genetrix.se  Mon Sep  3 01:33:15 2007
From: info at genetrix.se (Theta)
Date: Sun, 2 Sep 2007 16:33:15 -0700 (PDT)
Subject: [R] Problem in downloading Yahoo Finance data from R
In-Reply-To: <A36876D3F8A5734FA84A4338135E7CC30265A13F@BAN-MAILSRV03.Amba.com>
References: <A36876D3F8A5734FA84A4338135E7CC30265A13F@BAN-MAILSRV03.Amba.com>
Message-ID: <12454603.post@talk.nabble.com>


Hello Shubha,

alternative method that gets closing prices of the SP500 Index, last line 
calculates the logreturns, easy to use data.

sp500 <- get.hist.quote("^GSPC",start=(today <- Sys.Date())-735,quote="Cl")
rsp500 <- diff(log(sp500))



Shubha Vishwanath Karanth wrote:
> 
> Hi R users,
> 
> I have a problem in downloading Yahoo Finance data from R. I have tried
> an example given in R, to download. The error is given below:
>  
> 
>>library(fCalendar)
> 
>> yahooImport("s=IBM&a=11&b=1&c=1999&d=0&q=31&f=2000&z=IBM&x=.csv ",
> file = "D:\\ Downlaod",source = "http://ichart.yahoo.com/table.csv?",
> save = FALSE, sep = ";", swap = 20, try = TRUE)
> 
> trying URL
> 'http://ichart.yahoo.com/table.csv?s=IBM&a=11&b=1&c=1999&d=0&q=31&f=2000
> &z=IBM&x=.csv'
> 
> Error in download.file(url = url, destfile = file, method = method) : 
> 
>         cannot open URL
> 'http://ichart.yahoo.com/table.csv?s=IBM&a=11&b=1&c=1999&d=0&q=31&f=2000
> &z=IBM&x=.csv
> 
> In addition: Warning message:
> 
> unable to connect to 'ichart.yahoo.com' on port 80. in:
> download.file(url = url, destfile = file, method = method) 
> 
> [1] "No Internet Access"
> 
>> 
> 
>  
> 
> But the same URL, I can download in the same machine. So, What could be
> the problem?
> 
>  
> 
> BR, Shubha
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Problem-in-downloading-Yahoo-Finance-data-from-R-tf4364565.html#a12454603
Sent from the R help mailing list archive at Nabble.com.


From ptit_bleu at yahoo.fr  Mon Sep  3 08:48:01 2007
From: ptit_bleu at yahoo.fr (Ptit_Bleu)
Date: Sun, 2 Sep 2007 23:48:01 -0700 (PDT)
Subject: [R] Shame on me ...
In-Reply-To: <94730b8a0708310143k106ded36vc50380ab17c5894b@mail.gmail.com>
References: <12422479.post@talk.nabble.com>
	<94730b8a0708310143k106ded36vc50380ab17c5894b@mail.gmail.com>
Message-ID: <12457151.post@talk.nabble.com>


I  read again "R pour les d?butants" (for another problem) and I found the
answer to my question.
Sorry .
Have a nice week,
Ptiti Bleu.

Felix Andrews wrote:
> 
> x[[1]][4]
> 
> On 8/31/07, Ptit_Bleu <ptit_bleu at yahoo.fr> wrote:
>> Hi,
>>
>> I read the posts for 2 hours and ?list and tried many comninations but I
>> haven't found the answer to this basic question. So I decided to post my
>> question even if it is a silly one ...
>>
>> What is the instruction to retrieve, for example, the "D" of the first
>> list
>> ?
>> Thanks in advance,
>> Ptit Bleu.
>>
>>
>> > x<-list(LETTERS[1:5], LETTERS[10:20])
>> > x
>> [[1]]
>> [1] "A" "B" "C" "D" "E"
>>
>> [[2]]
>>  [1] "J" "K" "L" "M" "N" "O" "P" "Q" "R" "S" "T"
>>
>> --
>> View this message in context:
>> http://www.nabble.com/Problem-of-vocabulary-%3A-retrieve-element-of-a-list-of-a-list-tf4358872.html#a12422479
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 
> -- 
> Felix Andrews / ???
> PhD candidate
> Integrated Catchment Assessment and Management Centre
> The Fenner School of Environment and Society
> The Australian National University (Building 48A), ACT 0200
> Beijing Bag, Locked Bag 40, Kingston ACT 2604
> http://www.neurofractal.org/felix/
> voice:+86_1051404394 (in China)
> mobile:+86_13522529265 (in China)
> mobile:+61_410400963 (in Australia)
> xmpp:foolish.android at gmail.com
> 3358 543D AAC6 22C2 D336  80D9 360B 72DD 3E4C F5D8
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Problem-of-vocabulary-%3A-retrieve-element-of-a-list-of-a-list-tf4358872.html#a12457151
Sent from the R help mailing list archive at Nabble.com.


From olivier.delaigue at aix.cemagref.fr  Mon Sep  3 08:52:44 2007
From: olivier.delaigue at aix.cemagref.fr (Olivier Delaigue *)
Date: Sun, 2 Sep 2007 23:52:44 -0700 (PDT)
Subject: [R] sin(pi)?
In-Reply-To: <000501c7edf5$af58eec0$0fe05e81@D145LD1S>
References: <000501c7edf5$af58eec0$0fe05e81@D145LD1S>
Message-ID: <12457181.post@talk.nabble.com>


> sin(3.141592653589793)
[1] 1.224606e-16

Regards,

Olivier Delaigue



Nguyen Dinh Nguyen wrote:
> 
> Dear all,
> I found something strange when calculating sin of pi value
> sin(pi)
> [1] 1.224606e-16
> 
>  pi
> [1] 3.141593
> 
>  sin(3.141593)
> [1] -3.464102e-07
> 
> Any help and comment should be appreciated. 
> Regards
> Nguyen
> 
> 
> 

-- 
View this message in context: http://www.nabble.com/sin%28pi%29--tf4370556.html#a12457181
Sent from the R help mailing list archive at Nabble.com.


From p.dalgaard at biostat.ku.dk  Mon Sep  3 09:01:06 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 03 Sep 2007 09:01:06 +0200
Subject: [R] sin(pi)?
In-Reply-To: <000501c7edf5$af58eec0$0fe05e81@D145LD1S>
References: <000501c7edf5$af58eec0$0fe05e81@D145LD1S>
Message-ID: <46DBB132.7020707@biostat.ku.dk>

Nguyen Dinh Nguyen wrote:
> Dear all,
> I found something strange when calculating sin of pi value
> sin(pi)
> [1] 1.224606e-16
>
>  pi
> [1] 3.141593
>
>  sin(3.141593)
> [1] -3.464102e-07
>
> Any help and comment should be appreciated. 
> Regards
> Nguyen
>   
Well, sin(pi) is theoretically zero, so you are just seeing zero at two 
different levels of precision.

The built-in pi has more digits than it displays:

 > pi
[1] 3.141593
 > pi - 3.141593
[1] -3.464102e-07
 > print(pi, digits=20)
[1] 3.141592653589793

> ____________________________
> Nguyen Dinh Nguyen
> Garvan Institute of Medical Research
> Sydney, Australia
>
>   
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From s.blomberg1 at uq.edu.au  Mon Sep  3 09:01:50 2007
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Mon, 03 Sep 2007 17:01:50 +1000
Subject: [R] sin(pi)?
In-Reply-To: <000501c7edf5$af58eec0$0fe05e81@D145LD1S>
References: <000501c7edf5$af58eec0$0fe05e81@D145LD1S>
Message-ID: <1188802910.16516.43.camel@sib-sblomber01d.sib.uq.edu.au>

Umm. pi has been rounded to 6 decimal places in the second example. So
it isn't surprising that the results differ. sin(pi) is not zero, as it
also has been rounded, and you can't represent irrational numbers
exactly in a numerical form anyway. R agrees with Octave:

octave:1> sin(pi)
ans =  1.2246e-16
octave:2> sin(3.141593)
ans =  -3.4641e-07
octave:3> 

To paraphrase someone else on this list: I think it is strange that you
think it is strange.

Simon.

As someone On Mon, 2007-09-03 at 16:43 +1000, Nguyen Dinh Nguyen wrote:
> Dear all,
> I found something strange when calculating sin of pi value
> sin(pi)
> [1] 1.224606e-16
> 
>  pi
> [1] 3.141593
> 
>  sin(3.141593)
> [1] -3.464102e-07
> 
> Any help and comment should be appreciated. 
> Regards
> Nguyen
> 
> ____________________________
> Nguyen Dinh Nguyen
> Garvan Institute of Medical Research
> Sydney, Australia
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia
Room 320 Goddard Building (8)
T: +61 7 3365 2506 
email: S.Blomberg1_at_uq.edu.au

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.


From ripley at stats.ox.ac.uk  Mon Sep  3 09:07:03 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Sep 2007 08:07:03 +0100 (BST)
Subject: [R] sin(pi)?
In-Reply-To: <000501c7edf5$af58eec0$0fe05e81@D145LD1S>
References: <000501c7edf5$af58eec0$0fe05e81@D145LD1S>
Message-ID: <Pine.LNX.4.64.0709030750410.12798@gannet.stats.ox.ac.uk>

On Mon, 3 Sep 2007, Nguyen Dinh Nguyen wrote:

> Dear all,
> I found something strange when calculating sin of pi value

What exactly?  Comments below on two guesses as to what.

> sin(pi)
> [1] 1.224606e-16

That is non-zero due to using finite-precision arithmetic.  The number 
stored as pi is not exactly the mathematics quantity, and so 
sin(representation of pi) should be non-zero (although there is also 
rounding error in calculating what it is).

Note that sin() is computed by your C runtime, so the exact result will 
depend on your OS, compiler and possibly CPU.

> pi
> [1] 3.141593

That is the printout of pi to the default 7 significant digits.  R knows 
pi to higher accuracy:

> print(pi, digits=16)
[1] 3.141592653589793
> sin(3.141592653589793)
[1] 1.224606e-16

but note that printing to 16 digits and reading back in might not have 
given the same number, but happens to for pi at least on my system:

> 3.141592653589793 == pi
[1] TRUE


> sin(3.141593)
> [1] -3.464102e-07
>
> Any help and comment should be appreciated.
> Regards
> Nguyen
>
> ____________________________
> Nguyen Dinh Nguyen
> Garvan Institute of Medical Research
> Sydney, Australia
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Sep  3 09:27:22 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Sep 2007 08:27:22 +0100 (BST)
Subject: [R] Different behavior of mtext
In-Reply-To: <46DB331E.8030004@free.fr>
References: <46DB331E.8030004@free.fr>
Message-ID: <Pine.LNX.4.64.0709030726320.12798@gannet.stats.ox.ac.uk>

On Sun, 2 Sep 2007, S?bastien wrote:

> Dear R Users,
>
> I am quite surprised to see that mtext gives different results when it
> is used with 'pairs' and with "plot'. In the two following codes, it
> seems that the 'at' argument in mtext doesn't consider the same unit system.

It is stated to be in 'user coordinates'.  Your code does not work because 
unit() is missing.  If you mean the one from package grid, "npc" is not 
user coordinates (and refers to a grid viewport which you have not set up 
and coincidentally is the same as the initial user coordinate system to 
which pairs() has reverted).

Try par("usr") after your pairs() and plot() calls to see the difference.
Plotting a 2x2 array of plots _is_ different from plotting one, so this 
should be as expected.

Since centring is the default for 'adj', it is unclear what you are trying 
to achieve here.

> I would appreciate your comments on this issue.
>
> Sebastien
>
> ##### Pairs
>
> mydata<-data.frame(x=1:10,y=1:10)
>
> par(cex.main=1, cex.axis=1, cex.lab=1, lwd=1,
>    mar=c(5 + 5,4,4,2)+0.1)
>
> pairs(mydata,oma=c(5 + 5,4,4,2))
>
> mylegend<-c("mylegend A","mylegend B","mylegend C","mylegend test")
> mylegend.width = strwidth(mylegend[which.max(nchar(mylegend))], "figure")
>
> for (i in 1:4) {
> mtext(text=mylegend[i],
>        side = 1,
>        line = 3+i,
>        at = unit((1-mylegend.width)/2,"npc"),            # centers the
> legend at the bottom
>        adj=0,
>        padj=0)}
>
> ##### plot
>
> mydata<-data.frame(x=1:10,y=1:10)
>
> par(cex.main=1, cex.axis=1, cex.lab=1, lwd=1,
>    mar=c(5 + 5,4,4,2)+0.1)
>
> plot(mydata,oma=c(5 + 5,4,4,2))
>
> mylegend<-c("mylegend A","mylegend B","mylegend C","mylegend test")
> mylegend.width = strwidth(mylegend[which.max(nchar(mylegend))], "figure")
>
> for (i in 1:4) {
> mtext(text=mylegend[i],
>        side = 1,
>        line = 3+i,
>        at = unit((1-mylegend.width)/2,"npc"),            # should
> center the legend at the bottom but doesn't do it !
>        adj=0,
>        padj=0)}

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From thamrin_hm at yahoo.com  Mon Sep  3 09:37:16 2007
From: thamrin_hm at yahoo.com (thamrin hm)
Date: Mon, 3 Sep 2007 00:37:16 -0700 (PDT)
Subject: [R] Ask alpha cronbach and Hoyt method
Message-ID: <452082.44366.qm@web60018.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070903/2838903f/attachment.pl 

From calenge at biomserv.univ-lyon1.fr  Mon Sep  3 09:31:47 2007
From: calenge at biomserv.univ-lyon1.fr (=?ISO-8859-1?Q?Cl=E9ment_Calenge?=)
Date: Mon, 03 Sep 2007 09:31:47 +0200
Subject: [R] [R-pkgs] adehabitat version 1.7
Message-ID: <46DBB863.3000300@biomserv.univ-lyon1.fr>

Dear all,

I have uploaded to CRAN the version 1.7 of the package 'adehabitat'. 
Significant changes are listed below:

* The Brownian bridge kernel estimation algorithm has been greatly 
improved. It now takes more than 80% less time than the previous 
version. A new function "liker" has also been added, which estimates the 
one of the two smoothing parameters of the bridge kernel using a maximum 
likelihood approach (recommended in Horn et al., Ecology, in press). 
Examples of the help page demonstrate the use and interest of this 
function. Comparison between kernelbb and the Visual basic algorithm 
provided in the paper of Horn et al. returned consistent results.

* The function kernelUD has also been improved. It now takes more than 
50% less time than the previous version. In addition the "grid" argument 
of this function, now also allows a list of objects of class "asc" to be 
passed as grid where the UD should be estimated.

Happy testing,

Cl?ment Calenge.

-- 
Cl?ment CALENGE
LBBE - UMR CNRS 5558 - Universit? Claude Bernard Lyon 1 - FRANCE
tel. (+33) 04.72.43.27.57
fax. (+33) 04.72.43.13.88

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From thomas.schwander at mvv.de  Mon Sep  3 10:08:08 2007
From: thomas.schwander at mvv.de (thomas.schwander at mvv.de)
Date: Mon, 3 Sep 2007 10:08:08 +0200
Subject: [R] The quadprog package
Message-ID: <6699922FABDD9145A5C94569C2B438EB0103FB8A@MA-EXCL02.konzern.mvvcorp.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070903/e4961303/attachment.pl 

From r.hankin at noc.soton.ac.uk  Mon Sep  3 10:29:32 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Mon, 3 Sep 2007 09:29:32 +0100
Subject: [R] Incomplete Gamma function
In-Reply-To: <XFMail.070901155002.Ted.Harding@manchester.ac.uk>
References: <XFMail.070901155002.Ted.Harding@manchester.ac.uk>
Message-ID: <7A64E13A-E006-4EA6-AF7F-5643ABB70BA9@noc.soton.ac.uk>

Hello Ted


thanks for the comments below.

You point out below some less-than-perfect aspects of
some of my documentation (bizarrely, this is not the first time that  
this
has happened.  The real problem is  that *other people* insist on
reading the docs, when as everyone knows, the real purpose
of documentation is to remind the *developer* what he's done ;-).

The issue with the gsl_sf_ prefix is interesting.  I decided that
having an R function named "gsl_sf_gamma_inc()" would be
a bit long-winded, so I removed the prefix.  I did this elsewhere
too, notably Bessel.Rd, because I felt that the GSL naming scheme
was sufficiently distinct from R's in the case of Bessel functions to
obviate typing "gsl_sf_" every single time.

But as you point out, this is potentially confusing to a user; as a
developer, one tends to see the Rd file as one of a number of files
that one must edit, and in the case of  the gsl library, the R and C
code is very regimented and has adequate inline comments.  But
I'd lost sight of the fact that many users' sole source of documentation
is the Rd files.  And in the  case of gsl, the documentation is just a
pointer to ams-55 via gsl-ref [the GSL reference manual].  I now
suspect that my short function definitions have unnecessarily
obscured that audit trail.

What I think I'll do  (read "will add to my to-do-list")
is to (eg) define R function gsl_sf_gamma_inc()
and then define gamma_inc <- gsl_sf_gamma_inc
and add appropriate aliases to the docs.

Then I could deprecate gsl_inc(); and then possibly defunct them.

Anyone got any comments on this?  Do other package developers
have any experiences of making functions defunct that would be  
interesting?
How long do folk leave functions deprecated before defuncting them?

best wishes

Robin


On 1 Sep 2007, at 15:50, (Ted Harding) wrote:


[snip]

>
> In the documenation for the Gamma functions in the gsl package,
> it is simply stated
>
>   All functions [including gamma_inc()] as documented in the
>   GSL reference manual section 7.19.
>
> There is no function named "gamma_inc" in the GSL reference
> manual. See:
>
> http://www.gnu.org/software/gsl/manual/html_node/Function-Index.html
>
> All functions are named like "gsl_sf_gamma_inc", so
> presumably this is what is intended; in which case it computes
> "the unnormalized incomplete Gamma Function
>  \Gamma(a,x) = \int_x^\infty dt t^{a-1} \exp(-t)
>  for a real and x >= 0."
>
> And again that is clear enough -- once you track it down!
>
> In many places in the R documentation (including the "?" pages)
> people have taken the trouble to spell out mathematical definitions
> (where these can be given in reasonable space). Especially in cases
> like the Incomplete Gamma and Beta functions, where there can be
> dispute over what is meant (see above), it is surely wise to spell
> it out!
>
> Best wishes to all,
> Ted.
>
>>> On 31 Aug 2007, at 00:29, poolloopus at yahoo.com wrote:
>>>
>>>> Hello
>>>>
>>>> I am trying to evaluate an Incomplete gamma function
>>>> in R. Library Zipfr gives the Igamma function. From
>>>> Mathematica, I have:
>>>>
>>>> "Gamma[a, z] is the incomplete gamma function."
>>>>
>>>> In[16]: Gamma[9,11.1]
>>>> Out[16]: 9000.5
>>>>
>>>> Trying the same in R, I get
>>>>
>>>>> Igamma(9,11.1)
>>>> [1] 31319.5
>>>> OR
>>>>> Igamma(11.1,9)
>>>> [1] 1300998
>>>>
>>>> I know I have to understand the theory and the math
>>>> behind it rather than just ask for help, but while I
>>>> am trying to do that (and only taking baby steps, I
>>>> must admit), I was hoping someone could help me out.
>>>>
>>>> Regard
>>>>
>>>> Kris.
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 01-Sep-07                                       Time: 15:49:57
> ------------------------------ XFMail ------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From petr.pikal at precheza.cz  Mon Sep  3 10:51:13 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Mon, 3 Sep 2007 10:51:13 +0200
Subject: [R] by group problem
In-Reply-To: <6EBEA5B72E9B02428F2DD71D9DBC6EDF31939A@AKOYASRV01.akoyainc.local>
Message-ID: <OF92EEA613.338C3821-ONC125734B.00307433-C125734B.00309F20@precheza.cz>

Hi

now I understand better what you want

topN.2 <- function(data,n=5) data[order(data[,3], decreasing=T),][1:n]

# I presume data is data frame with 3 columns and the third is percent

lapply(split(data,data$state), topN.2)

Regards

Petr

petr.pikal at precheza.cz

"Cory Nissen" <cnissen at AkoyaInc.com> napsal dne 31.08.2007 17:21:01:

> That didn't work for me...
> 
> Here's some data to help with a solution.
> 
> data <- NULL
> data$state <- c(rep("Illinois", 10), rep("Wisconsin", 10))
> data$county <- c("Adams", "Brown", "Bureau", "Cass", "Champaign", 
>                  "Christian", "Coles", "De Witt", "Douglas", "Edgar",
>                  "Adams", "Ashland", "Barron", "Bayfield", "Buffalo", 
>                  "Burnett", "Chippewa", "Clark", "Columbia", "Crawford")
> data$percentOld <- c(17.554849, 16.826594, 18.196593, 17.139242, 
8.743823,
>                      17.862746, 13.747967, 16.626302, 15.258940, 
18.984435,
>                      19.347022, 17.814436, 16.903067, 17.632781, 
16.659305,
>                      20.337817, 14.293354, 17.252820, 15.647179, 
16.825596)
> 
> return something like this...
> $Illinois
> "Edgar"
> 18.984435
> "Bureau"
> 18.196593
> ...
> $Wisconsin
> "Burnett"
> 20.33782
> "Adams"
> 19.34702
> ...
> 
> My Solution gives...
> topN <- function(column, n=5)
>   {
>     column <- sort(column, decreasing=T)
>     return(column[1:n])
>   }
> tapply(data$percentOld, data$state, topN)
> 
> $Illinois
> [1] 18.98444 18.19659 17.86275 17.55485 17.13924
> $Wisconsin
> [1] 20.33782 19.34702 17.81444 17.63278 17.25282
> 
> I get an error with this try...
> aggregate(data$percentOld, list(data$state, data$county), topN)
> 
> Error in aggregate.data.frame(as.data.frame(x), ...) : 
>  'FUN' must always return a scalar
> 
> Thanks
> 
> cn
> 
> 
> 
> From: Petr PIKAL [mailto:petr.pikal at precheza.cz]
> Sent: Fri 8/31/2007 8:15 AM
> To: Cory Nissen
> Cc: r-help at stat.math.ethz.ch
> Subject: Odp: [R] by group problem

> Hi
> 
> > I am working with census data.  My columns of interest are...
> >
> > PercentOld - the percentage of people in each county that are over 65
> > County - the county in each state
> > State - the state in the US
> >
> > There are about 3100 rows, with each row corresponding to a county
> within a state.
> >
> > I want to return the top five "PercentOld" by state.  But I want the
> County
> > and the Value.
> >
> > I tried this...
> >
> > topN <- function(column, n=5)
> >   {
> >     column <- sort(column, decreasing=T)
> >     return(column[1:n])
> >   }
> > top5PerState <- tapply(data$percentOld, data$STATE, topN)
> 
> Try
> 
> aggregate(data$PercentOld, list(data$State, data$County), topN)
> 
> Regards
> Petr
> 
> 
> >
> > But this only returns the value for "percentOld" per state, I also 
want
> the
> > corresponding County.
> >
> > I think I'm close, but I just can't get it...
> >
> > Thanks
> >
> > cn
> >
> >    [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.uni-dortmund.de  Mon Sep  3 11:04:55 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 03 Sep 2007 11:04:55 +0200
Subject: [R] some problems with "linebuffer"; was:  Bug?
In-Reply-To: <20070903073505.56666155DD0@smtp-1.sys.kth.se>
References: <20070903073505.56666155DD0@smtp-1.sys.kth.se>
Message-ID: <46DBCE37.8090706@statistik.uni-dortmund.de>



Johanna Hasmats wrote:
> Ok, attaching all files. You need to run it in the following order:
> 
> parse.RData
> 
> Korrelation.RData   I have reduced this script to only include the error
> part.
> 
> 
> Input files are in the following order:
> 
> oligo.prest.out for parse.RData to work. Produces the next input file 
> 
> oligolista for Korrelation.RData to work, which also needs the input file
> 
> 8_SkBr _13433630.gpr. 
> 
> 
> The function GenePixData can be found in the aroma package.
> 
> Thank you for your help,


1. Package kth is unavailable for us.

2. I do not know anything about a package called "aroma", it is neither 
on CRAN nor in the BioC repositories.

3. Can you please also try to make your example smaller?

4. The convention is to save R objects in .Rdata files, but to have R 
code in .R files.


Uwe Ligges




> Johanna
> 
> 
> 
> 
> 
> 
> 
> 
> *******************************************************************
> Johanna Hasmats
> Royal Institute of Technology 
> AlbaNova University Center 
> Stockholm Center for Physics, Astronomy and Biotechnology 
> School of Molecular Biotechnology 
> Department of Gene Technology 
> Visiting address: 
> Roslagstullsbacken 21, Floor 3 
> 106 91 Stockholm, Sweden 
> Delivering address: 
> Roslagsv?gen 30 B
> 104 06 Stockholm, Sweden 
> Phone (office) +46 8 553 783 44 
> Fax + 46 8 553 784 81 
> ****************************************************************** 
> 
> -----Original Message-----
> From: Deepayan Sarkar [mailto:deepayan.sarkar at gmail.com] 
> Sent: Friday, August 31, 2007 8:12 PM
> To: Uwe Ligges
> Cc: Johanna Hasmats; r-help at stat.math.ethz.ch
> Subject: Re: [R] Bug?
> 
> On 8/31/07, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
>>
>> Johanna Hasmats wrote:
>>> Hi!
>>>
>>>
>>>
>>> How can I get around in R 2.5.1 in Windows:
>>>
>>>
>>>
>>> Error in strsplit(linebuffer, "") : object "linebuffer" not found
>>
>> Why should this be a bug in R, if you have no object named "linebuffer"
>> in the environments that are on the search path.
> 
> This sounds like it could have something to do with the command
> completion mechanism through package rcompgen (which does use an
> internal variable called 'linebuffer'). Since this doesn't seem to be
> a common problem, you need to give us instructions on how to reproduce
> it.
> 
> -Deepayan


From berwin at maths.uwa.edu.au  Mon Sep  3 11:15:09 2007
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Mon, 3 Sep 2007 17:15:09 +0800
Subject: [R] The quadprog package
In-Reply-To: <6699922FABDD9145A5C94569C2B438EB0103FB8A@MA-EXCL02.konzern.mvvcorp.de>
References: <6699922FABDD9145A5C94569C2B438EB0103FB8A@MA-EXCL02.konzern.mvvcorp.de>
Message-ID: <20070903171509.3db8a4fb@absentia>

G'day Thomas,

On Mon, 3 Sep 2007 10:08:08 +0200
<thomas.schwander at mvv.de> wrote:

> What's wrong with my code?
> 
> Require(quadprog)

library(quadprog) ? :)

> Dmat<-diag(1,7,7)
> # muss als quadratische Matrix eingegeben werden
> Dmat
> dvec<-matrix(0,7,1) # muss als Spaltenvektor eingegeben werden
> dvec
> mu<-0 # (in Mio. ?)
> bvec<-c(1,mu,matrix(0,7,1)) # muss als Spaltenvektor eingegeben werden
> bvec
> mu_r<-c(19.7,33.0,0.0,49.7, 82.5, 39.0,11.8)	
> Amat<-matrix(c(matrix(1,1,7),7*mu_r,diag(1,7,7)),9,7,byrow=T) 
> # muss als Matrix angegeben werden, wie sie wirklich ist
> Amat
> meq<-2
> loesung<-solve.QP(Dmat,dvec,Amat=t(Amat),bvec=bvec,meq=2)

With the commands above, I get on my system:

> loesung<-solve.QP(Dmat,dvec,Amat=t(Amat),bvec=bvec,meq=2)
Error in solve.QP(Dmat, dvec, Amat = t(Amat), bvec = bvec, meq = 2) : 
	constraints are inconsistent, no solution!

Which is a bit strange, since Dmat is the identity matrix, so there
should be little room for numerical problems.

OTOH, it is known that the Goldfarb-Idnani algorithm can have problem
in rare occasions if the problem is "ill-scaled"; see the work of
Powell. 

Changing the definition of Amat to

> Amat<-matrix(c(matrix(1,1,7),mu_r,diag(1,7,7)),9,7,byrow=T) 

leads to a successful call to solve.QP.  And since mu=0, I really
wonder why you scaled up the vector mu_r by a factor of 7 when putting
it into Amat.... :)

> loesung<-solve.QP(Dmat,dvec,Amat=t(Amat),bvec=bvec,meq=2)

Now, with the solution I obtained the rest of your commands show:

> loesung$solution %*% mu_r
             [,1]
[1,] 6.068172e-15
> sum(loesung$solution)
[1] 1
> for (i in 1:7){
	a<-loesung$solution[i]>=0
	print(a)
}
[1] TRUE
[1] TRUE
[1] TRUE
[1] TRUE
[1] FALSE
[1] FALSE
[1] TRUE
 
But:

>  for (i in 1:7){
	a<-loesung$solution[i]>=- .Machine$double.eps*1000
	print(a)
}

[1] TRUE
[1] TRUE
[1] TRUE
[1] TRUE
[1] TRUE
[1] TRUE
[1] TRUE

>  for (i in 1:7) print(loesung$solution[i])
[1] 0
[1] 0
[1] 1
[1] 0
[1] -4.669169e-17
[1] -1.436586e-17
[1] 8.881784e-16

This is a consequence of finite precision arithmetic.  Just as you
should not compare to numeric numbers directly for equality but rather
that the absolute value of their difference is smaller than an
appropriate chosen threshold, you should not check whether a number is
bigger or equal to zero, but whether it is bigger or equal to an
appropriately chosen negative threshold.  More information are given in
FAQ 7.31.

HTH.

Cheers,

	Berwin

=========================== Full address =============================
Berwin A Turlach                            Tel.: +65 6515 4416 (secr)
Dept of Statistics and Applied Probability        +65 6515 6650 (self)
Faculty of Science                          FAX : +65 6872 3919       
National University of Singapore     
6 Science Drive 2, Blk S16, Level 7          e-mail: statba at nus.edu.sg
Singapore 117546                    http://www.stat.nus.edu.sg/~statba


From petr.pikal at precheza.cz  Mon Sep  3 11:32:04 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Mon, 3 Sep 2007 11:32:04 +0200
Subject: [R] Odp:  element wise opertation between a vector and a list
In-Reply-To: <d89bf0cd0709022336l7122dfd9x7e423b2316a56201@mail.gmail.com>
Message-ID: <OF02842951.F58946CD-ONC125734B.00345446-C125734B.00345CD7@precheza.cz>

Hi

 mapply("+", a, b)

Regards
Petr

r-help-bounces at stat.math.ethz.ch napsal dne 03.09.2007 08:36:10:

> I want to try to get a result of element wise addition between a
> vector and a list. It can be done with "for statement." In order to
> reducing computing time, I have tried to avoid "for state." If anybody
> give me an idea, I would apprecite it much.
> 
> for example, with a & b as below lines,
> 
> a<- list(c(1,3),c(1,2),c(2,3))
> b<-c(10,20,30)
> 
> I would like to have a list (like "d") or a vector (like "e") as below.
> 
> d<-list(c((1+10),(3+10)),c((1+20),(2+20)),c((2+30),(3+30)))
> e<- c((1+10)+(3+10),(1+20)+(2+20),(2+30)+(3+30))
> 
> Thanks,
> 
> 
> Yongwan Chun
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From knoblauch at lyon.inserm.fr  Mon Sep  3 13:59:52 2007
From: knoblauch at lyon.inserm.fr (Ken Knoblauch)
Date: Mon, 3 Sep 2007 09:59:52 -0200 (CEST)
Subject: [R] plotting predicted curves with log scale in lattice
Message-ID: <49173.194.57.165.23.1188806392.squirrel@webmail.lyon.inserm.fr>

Hi,

I was taken off guard by the following behavior in a lattice plot.
I frequently want to add a predicted curve defined at more
points than in the formula expression of xyplot.  There have
been numerous examples of how to do this on r-help, but I
still often struggle to make this work.  I just realized that
specifying one of the axes on a log scale does not guarantee
that the added data for a curve will automatically take that
into account.  I don't know if this should be called a bug,
I haven't picked up an indication that would lead me to
expect this in the documentation.  I admit that if I had a
deeper understanding of lattice and/or grid, it might be
clearer why...  Here is a toy example illustrating the behavior
(there may be a more efficient way to do this),

ds1 <- data.frame( RR = rep(seq(0, 1, len = 5)^2, 2) +
						rnorm(10, sd = 0.1),
				   LL = rep(10^seq(1, 5), 2),
				   FF = factor(rep(letters[1:2], each = 5))
				   )
ds2 <- data.frame(RR = rep(seq(0, 1, len = 20)^2, 2),
				  LL = rep(10^seq(1, 5, len = 20), 2),
				   FF = factor(rep(letters[1:2], each = 20))
				   )
library(lattice)
xyplot(RR ~ LL | FF, ds1,
		scales = list(x = list(log = TRUE)),
		aspect = "xy",
		subscripts = TRUE,
		ID = ds2$FF,
		panel = function(x, y, subscripts, ID, ...) {
			w <- unique(ds1$FF[subscripts])
			llines(log10(ds2$LL[ID == w]), ds2$RR[ID == w], ...)
			panel.xyplot(x, y, ...)
			}
		)

Note that the x-variable of llines must be logged to plot the correct values
and so the scales argument seems to apply only to the x, y arguments
passed to the panel function.

Thank you.

best,

Ken


-- 
Ken Knoblauch
Inserm U846
Institut Cellule Souche et Cerveau
D?partement Neurosciences Int?gratives
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.lyon.inserm.fr/846/english.html


From p.hiemstra at geo.uu.nl  Mon Sep  3 11:44:18 2007
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 03 Sep 2007 11:44:18 +0200
Subject: [R] how to sub-sample a variable on another file coordinates
In-Reply-To: <71cc5ca20709020704p38002693v158a2555b363c8e2@mail.gmail.com>
References: <71cc5ca20709020704p38002693v158a2555b363c8e2@mail.gmail.com>
Message-ID: <46DBD772.1070509@geo.uu.nl>

Dear Yogesh,

This question seems more appropriate for the r-sig-geo mailing list 
(https://stat.ethz.ch/mailman/listinfo/r-sig-geo).

The sampling of the netcdf files can be done by using the overlay 
function from the sp-package (available on CRAN). You would have to read 
both the netcdf file and the ASCII file into the spatial classes 
presented by sp (SpatialGrid for the CO2 data (I assume that it is a 
grid) and SpatialPoints for the ASCII data). This could be done using 
the rgdal-package.

good luck!

Paul

Yogesh Tiwari schreef:
>  Hello 'R' Users,
>
> I have a monthly mean CO2 necdf data file defined on 1x1 lat by lon
> coordinate. I want to sub-sample this variable CO2 on the coordinates
> of another ASCII data file. The coordinates of another ASCII data file are
> as:
>
>    -24.01 152.06 -18.58 150.19 -13.46 148.35 -8.29 147.03 -3.14 146.19 1.53
> 145.59 7.08 145.33 12.25 145.02 17.46 144.31 22.44 142.35 27.53 141.26 33.04
> 140.15 -23.49 152.07 -18.56 150.18 -13.41 150.14 -8.24 150.04 -3.07 149.21
> 2.05 148.31 7.19 147.45 12.37 147.03 17.53 146.21 22.56 144.47 28.04 143.38
> 32.54 142.26
>
> Kindly anybody can help on this.
>
> Many thanks,
>
> Cheers,
> Yogesh
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul


From daniel.brewer at icr.ac.uk  Mon Sep  3 11:55:39 2007
From: daniel.brewer at icr.ac.uk (Daniel Brewer)
Date: Mon, 03 Sep 2007 10:55:39 +0100
Subject: [R] Plotting a table under a dendrogram
Message-ID: <46DBDA1B.4070907@icr.ac.uk>

Dear all,
I have produced a dendrogram using hclust and I would like to plot it
with a table of data associated with each sample aligned with the
"leaves" of the tree.  Is there a reasonable way to do this in R, or am
I better lining it up in a image program.

Many thanks

-- 
**************************************************************
Daniel Brewer, Ph.D.
Institute of Cancer Research
Email: daniel.brewer at icr.ac.uk
**************************************************************

The Institute of Cancer Research: Royal Cancer Hospital, a charitable Company Limited by Guarantee, Registered in England under Company No. 534147 with its Registered Office at 123 Old Brompton Road, London SW7 3RP.

This e-mail message is confidential and for use by the addre...{{dropped}}


From Thierry.ONKELINX at inbo.be  Mon Sep  3 12:12:53 2007
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 3 Sep 2007 12:12:53 +0200
Subject: [R] Legend issue with ggplot2
Message-ID: <2E9C414912813E4EB981326983E0A1040397DA1C@inboexch.inbo.be>

Dear useRs,

I'm struggling with the new version of ggplot2. In the previous version
I did something like this. But now this yield an error (object "fill"
not found).

library(ggplot2)
dummy <- data.frame(x = rep(1:10, 4), group = gl(4, 10))
dummy$y <- dummy$x * rnorm(4)[dummy$group] + 5 * rnorm(4)[dummy$group]
dummy$min <- dummy$y - 5
dummy$max <- dummy$y + 5
ggplot(data = dummy, aes(x = x, max = max, min = min, fill = group)) +
geom_ribbon() + geom_line(aes(y = max, colour = fill)) + geom_line(aes(y
= min, colour = fill))

When I adjust the code to the line below, it works again. But this time
with two legend keys for "group". Any idea how to display only one
legend key for group? The ggplot-code aboved yielded only on legend key.

ggplot(data = dummy, aes(x = x, max = max, min = min, colour = group,
fill = group)) + geom_ribbon() + geom_line(aes(y = max)) +
geom_line(aes(y = min))

Thanks,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx op inbo.be
www.inbo.be 

Do not put your faith in what statistics say until you have carefully
considered what they do not say.  ~William W. Watt
A statistical analysis, properly conducted, is a delicate dissection of
uncertainties, a surgery of suppositions. ~M.J.Moroney


From jim at bitwrit.com.au  Mon Sep  3 12:37:48 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 03 Sep 2007 20:37:48 +1000
Subject: [R] NAs in indices
In-Reply-To: <347152339B716A4D893C9A2988EA87C85E044D@KFSVS2.utk.tennessee.edu>
References: <347152339B716A4D893C9A2988EA87C85E044D@KFSVS2.utk.tennessee.edu>
Message-ID: <46DBE3FC.5030708@bitwrit.com.au>

Muenchen, Robert A (Bob) wrote:
> Hi All,
> 
> I'm fiddling with an program to read a text file containing periods that
> SAS uses for missing values. I know that if I had the original SAS data
> set instead of a text file, R would handle this conversion for me. 
> 
> Data frames do not allow missing values in their indices but vectors do.
> Why is that? A search of the error message points out the problem and
> solution but not why they differ. A simplified program that demonstrates
> the issue is below.
> 
> Thanks,
> Bob
> 
> # Here's a data frame that has both periods and NAs.
> # I want sex to remain character for now.
> 
> sex=c("m","f",".",NA)
> x=c(1,2,3,NA)
> myDF <- data.frame(sex,x,stringsAsFactors=F)
> rm(sex,x)
> myDF
> 
> # Substituting NA into data frame does not work
> # due to NAs in the indices. The error message is:
> # missing values are not allowed in subscripted assignments of data
> frames
> 
> myDF[ myDF$sex==".", "sex" ] <- NA
> myDF
> 
Hi Bob,
What happens is that you don't get FALSE when you ask if something==NA, 
you get NA. However, if you use the "which" function, it cleans up the 
NAs for you and the result of that should do what you want.

myDF[which(myDF$sex=="."),"sex"]<-NA

Jim


From knoblauch at lyon.inserm.fr  Mon Sep  3 12:38:57 2007
From: knoblauch at lyon.inserm.fr (Ken Knoblauch)
Date: Mon, 3 Sep 2007 10:38:57 +0000 (UTC)
Subject: [R] plotting predicted curves with log scale in lattice
References: <49173.194.57.165.23.1188806392.squirrel@webmail.lyon.inserm.fr>
Message-ID: <loom.20070903T123557-687@post.gmane.org>

Excuse me for forgetting sessionInfo (below)
Ken Knoblauch <knoblauch <at> lyon.inserm.fr> writes:
> I was taken off guard by the following behavior in a lattice plot.
> I frequently want to add a predicted curve defined at more
> points than in the formula expression of xyplot.  There have
> been numerous examples of how to do this on r-help, but I
> still often struggle to make this work.  I just realized that
> specifying one of the axes on a log scale does not guarantee
> that the added data for a curve will automatically take that
> into account.  I don't know if this should be called a bug,
> I haven't picked up an indication that would lead me to
> expect this in the documentation.  I admit that if I had a
> deeper understanding of lattice and/or grid, it might be
> clearer why...  Here is a toy example illustrating the behavior
> (there may be a more efficient way to do this),
> 
> ds1 <- data.frame( RR = rep(seq(0, 1, len = 5)^2, 2) +
> 						rnorm(10, sd = 0.1),
> 				   LL = rep(10^seq(1, 5), 2),
> 				   FF = factor(rep(letters[1:2], each = 5))
> 				   )
> ds2 <- data.frame(RR = rep(seq(0, 1, len = 20)^2, 2),
> 				  LL = rep(10^seq(1, 5, len = 20), 2),
> 				   FF = factor(rep(letters[1:2], each = 20))
> 				   )
> library(lattice)
> xyplot(RR ~ LL | FF, ds1,
> 		scales = list(x = list(log = TRUE)),
> 		aspect = "xy",
> 		subscripts = TRUE,
> 		ID = ds2$FF,
> 		panel = function(x, y, subscripts, ID, ...) {
> 			w <- unique(ds1$FF[subscripts])
> 			llines(log10(ds2$LL[ID == w]), ds2$RR[ID == w], ...)
> 			panel.xyplot(x, y, ...)
> 			}
> 		)
> 
> Note that the x-variable of llines must be logged to plot the correct values
> and so the scales argument seems to apply only to the x, y arguments
> passed to the panel function.
R version 2.5.1 Patched (2007-08-26 r42657) 
i386-apple-darwin8.10.1 

locale:
C

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[7] "base"     

other attached packages:
 lattice 
"0.16-3" 

but this also occurs for
R version 2.6.0 Under development (unstable) (2007-08-26 r42657) 
i386-apple-darwin8.10.1 

locale:
C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lattice_0.16-3

loaded via a namespace (and not attached):
[1] grid_2.6.0


From guillaume.brutel at yahoo.fr  Mon Sep  3 13:11:24 2007
From: guillaume.brutel at yahoo.fr (Guillaume Brutel)
Date: Mon, 03 Sep 2007 13:11:24 +0200
Subject: [R] Graphic representation of model results
Message-ID: <46DBEBDC.7000808@yahoo.fr>

Dear list members,

I am facing difficulties in making a graphics that could show visually 
results of a model.

I have tested the effects of 4 quantitative variables (Z1, Z2, Z3, Z4) 
on a variable Y using a weighted mixed effects GLM with weights W (using 
the glmmPQL function). I applied a blocking approach using factor F2 
nested in factor F1 as a grouping structure on a random intercept in the 
GLMM . The fixed effect are the 4 independent variables simultaneously 
fitted in the inferential model (Z1, ..., Z4).

Three out of the four variables have a significant effect on Y (Z1, Z2, Z3).

My problem is that I want to show graphically my results. If I plot Y 
according to the Z1, this won't take into account the effect of e.g. Z2 
and the fact that the analysis was weighted by W (same with adding a 
weighted lowess). If I add a regression line with the estimate for Z1 
obtained from the weighted mixed effect GLM, this doesn't not properly 
reflect the analysis (since they were obtained with simultaneously 
fitting Z2 and Z3). Making various 3D figures don't help because the 
various plots are too difficult to read.

Any advice (about the conceptual way of making the figure and the 
function(s) that can be used) is welcome.
Thank you very much,
Regards,

Guillaume Brutel.


From HDoran at air.org  Mon Sep  3 14:19:24 2007
From: HDoran at air.org (Doran, Harold)
Date: Mon, 3 Sep 2007 08:19:24 -0400
Subject: [R] Ask alpha cronbach and Hoyt method
References: <452082.44366.qm@web60018.mail.yahoo.com>
Message-ID: <2323A6D37908A847A7C32F1E3662C80EB5E6F3@dc1ex01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070903/41e47f21/attachment.pl 

From guillaume.brutel at yahoo.fr  Mon Sep  3 14:30:13 2007
From: guillaume.brutel at yahoo.fr (Guillaume Brutel)
Date: Mon, 03 Sep 2007 14:30:13 +0200
Subject: [R] Graphic representation of model results
Message-ID: <46DBFE55.2040507@yahoo.fr>

Apologies for cross-posting but I think my previous mail was in HTML 
(which is inadvisable for the help mailing list).
------------------------------------------------

Dear list members,

I am facing difficulties in making a graphics that could show visually 
results of a model.

I have tested the effects of 4 quantitative variables (Z1, Z2, Z3, Z4) 
on a variable Y using a weighted mixed effects GLM with weights W (using 
the glmmPQL function). I applied a blocking approach using factor F2 
nested in factor F1 as a grouping structure on a random intercept in the 
GLMM . The fixed effect are the 4 independent variables simultaneously 
fitted in the inferential model (Z1, ..., Z4).

Three out of the four variables have a significant effect on Y (Z1, Z2, 
Z3).

My problem is that I want to show graphically my results. If I plot Y 
according to the Z1, this won't take into account the effect of e.g. Z2 
and the fact that the analysis was weighted by W (same with adding a 
weighted lowess). If I add a regression line with the estimate for Z1 
obtained from the weighted mixed effect GLM, this doesn't not properly 
reflect the analysis (since they were obtained with simultaneously 
fitting Z2 and Z3). Making various 3D figures don't help because the 
various plots are too difficult to read. A conditional plot wouldn't 
show the trends analyzed by the weighted model...

Any advice (about the conceptual way of making the figure and the 
function(s) that can be used) is welcome.
Thank you very much,
Regards,

Guillaume Brutel.


From h.wickham at gmail.com  Mon Sep  3 15:15:07 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 3 Sep 2007 08:15:07 -0500
Subject: [R] Legend issue with ggplot2
In-Reply-To: <2E9C414912813E4EB981326983E0A1040397DA1C@inboexch.inbo.be>
References: <2E9C414912813E4EB981326983E0A1040397DA1C@inboexch.inbo.be>
Message-ID: <f8e6ff050709030615x4c0c66f7k2e0974e0df6c9909@mail.gmail.com>

On 9/3/07, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:
> Dear useRs,
>
> I'm struggling with the new version of ggplot2. In the previous version
> I did something like this. But now this yield an error (object "fill"
> not found).
>
> library(ggplot2)
> dummy <- data.frame(x = rep(1:10, 4), group = gl(4, 10))
> dummy$y <- dummy$x * rnorm(4)[dummy$group] + 5 * rnorm(4)[dummy$group]
> dummy$min <- dummy$y - 5
> dummy$max <- dummy$y + 5
> ggplot(data = dummy, aes(x = x, max = max, min = min, fill = group)) +
> geom_ribbon() + geom_line(aes(y = max, colour = fill)) + geom_line(aes(y
> = min, colour = fill))

Strange - I'm not sure why that ever worked.

> When I adjust the code to the line below, it works again. But this time
> with two legend keys for "group". Any idea how to display only one
> legend key for group? The ggplot-code aboved yielded only on legend key.
>
> ggplot(data = dummy, aes(x = x, max = max, min = min, colour = group,
> fill = group)) + geom_ribbon() + geom_line(aes(y = max)) +
> geom_line(aes(y = min))

You can manually turn off one of the legends:

sc <- scale_colour_discrete()
sc$legend <- FALSE
.last_plot + sc

It's not very convenient though, so I'll think about how to do this
automatically.  The legends need to be more intelligent about only
displaying the minimum necessary.

Hadley


From Thierry.ONKELINX at inbo.be  Mon Sep  3 15:25:51 2007
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 3 Sep 2007 15:25:51 +0200
Subject: [R] Legend issue with ggplot2
In-Reply-To: <f8e6ff050709030615x4c0c66f7k2e0974e0df6c9909@mail.gmail.com>
References: <2E9C414912813E4EB981326983E0A1040397DA1C@inboexch.inbo.be> 
	<f8e6ff050709030615x4c0c66f7k2e0974e0df6c9909@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A1040397DB50@inboexch.inbo.be>

Thanks Hadley,

I've been struggling with this all afternoon. But now it's working
again. Since I'm using it in a script, the few extra lines don't bother
me that much.

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx op inbo.be
www.inbo.be 

Do not put your faith in what statistics say until you have carefully
considered what they do not say.  ~William W. Watt
A statistical analysis, properly conducted, is a delicate dissection of
uncertainties, a surgery of suppositions. ~M.J.Moroney

 

> -----Oorspronkelijk bericht-----
> Van: hadley wickham [mailto:h.wickham op gmail.com] 
> Verzonden: maandag 3 september 2007 15:15
> Aan: ONKELINX, Thierry
> CC: r-help op stat.math.ethz.ch
> Onderwerp: Re: [R] Legend issue with ggplot2
> 
> On 9/3/07, ONKELINX, Thierry <Thierry.ONKELINX op inbo.be> wrote:
> > Dear useRs,
> >
> > I'm struggling with the new version of ggplot2. In the previous 
> > version I did something like this. But now this yield an 
> error (object "fill"
> > not found).
> >
> > library(ggplot2)
> > dummy <- data.frame(x = rep(1:10, 4), group = gl(4, 10)) dummy$y <- 
> > dummy$x * rnorm(4)[dummy$group] + 5 * rnorm(4)[dummy$group] 
> dummy$min 
> > <- dummy$y - 5 dummy$max <- dummy$y + 5 ggplot(data = 
> dummy, aes(x = 
> > x, max = max, min = min, fill = group)) +
> > geom_ribbon() + geom_line(aes(y = max, colour = fill)) + 
> > geom_line(aes(y = min, colour = fill))
> 
> Strange - I'm not sure why that ever worked.
> 
> > When I adjust the code to the line below, it works again. But this 
> > time with two legend keys for "group". Any idea how to display only 
> > one legend key for group? The ggplot-code aboved yielded 
> only on legend key.
> >
> > ggplot(data = dummy, aes(x = x, max = max, min = min, 
> colour = group, 
> > fill = group)) + geom_ribbon() + geom_line(aes(y = max)) + 
> > geom_line(aes(y = min))
> 
> You can manually turn off one of the legends:
> 
> sc <- scale_colour_discrete()
> sc$legend <- FALSE
> .last_plot + sc
> 
> It's not very convenient though, so I'll think about how to 
> do this automatically.  The legends need to be more 
> intelligent about only displaying the minimum necessary.
> 
> Hadley
>


From h.wickham at gmail.com  Mon Sep  3 15:25:59 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 3 Sep 2007 08:25:59 -0500
Subject: [R] plotting predicted curves with log scale in lattice
In-Reply-To: <49173.194.57.165.23.1188806392.squirrel@webmail.lyon.inserm.fr>
References: <49173.194.57.165.23.1188806392.squirrel@webmail.lyon.inserm.fr>
Message-ID: <f8e6ff050709030625u718aa1e8y40a0dfba6ea87fb2@mail.gmail.com>

Hi Ken,

Alternatively, you could use ggplot2:

install.packages("ggplot2")
library(ggplot2)

qplot(LL, RR, data=ds1, facets = . ~ FF) + geom_line(data=ds2) + scale_x_log10()

It is very hard to get transformed scales working correctly, and it's
something I had to spend a lot of time on in between ggplot 1 and 2.

Hadley


On 9/3/07, Ken Knoblauch <knoblauch at lyon.inserm.fr> wrote:
> Hi,
>
> I was taken off guard by the following behavior in a lattice plot.
> I frequently want to add a predicted curve defined at more
> points than in the formula expression of xyplot.  There have
> been numerous examples of how to do this on r-help, but I
> still often struggle to make this work.  I just realized that
> specifying one of the axes on a log scale does not guarantee
> that the added data for a curve will automatically take that
> into account.  I don't know if this should be called a bug,
> I haven't picked up an indication that would lead me to
> expect this in the documentation.  I admit that if I had a
> deeper understanding of lattice and/or grid, it might be
> clearer why...  Here is a toy example illustrating the behavior
> (there may be a more efficient way to do this),
>
> ds1 <- data.frame( RR = rep(seq(0, 1, len = 5)^2, 2) +
>                                                 rnorm(10, sd = 0.1),
>                                    LL = rep(10^seq(1, 5), 2),
>                                    FF = factor(rep(letters[1:2], each = 5))
>                                    )
> ds2 <- data.frame(RR = rep(seq(0, 1, len = 20)^2, 2),
>                                   LL = rep(10^seq(1, 5, len = 20), 2),
>                                    FF = factor(rep(letters[1:2], each = 20))
>                                    )
> library(lattice)
> xyplot(RR ~ LL | FF, ds1,
>                 scales = list(x = list(log = TRUE)),
>                 aspect = "xy",
>                 subscripts = TRUE,
>                 ID = ds2$FF,
>                 panel = function(x, y, subscripts, ID, ...) {
>                         w <- unique(ds1$FF[subscripts])
>                         llines(log10(ds2$LL[ID == w]), ds2$RR[ID == w], ...)
>                         panel.xyplot(x, y, ...)
>                         }
>                 )
>
> Note that the x-variable of llines must be logged to plot the correct values
> and so the scales argument seems to apply only to the x, y arguments
> passed to the panel function.
>
> Thank you.
>
> best,
>
> Ken
>
>
> --
> Ken Knoblauch
> Inserm U846
> Institut Cellule Souche et Cerveau
> D?partement Neurosciences Int?gratives
> 18 avenue du Doyen L?pine
> 69500 Bron
> France
> tel: +33 (0)4 72 91 34 77
> fax: +33 (0)4 72 91 34 61
> portable: +33 (0)6 84 10 64 10
> http://www.lyon.inserm.fr/846/english.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
http://had.co.nz/


From h.wickham at gmail.com  Mon Sep  3 15:28:05 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 3 Sep 2007 08:28:05 -0500
Subject: [R] Legend issue with ggplot2
In-Reply-To: <2E9C414912813E4EB981326983E0A1040397DB50@inboexch.inbo.be>
References: <2E9C414912813E4EB981326983E0A1040397DA1C@inboexch.inbo.be>
	<f8e6ff050709030615x4c0c66f7k2e0974e0df6c9909@mail.gmail.com>
	<2E9C414912813E4EB981326983E0A1040397DB50@inboexch.inbo.be>
Message-ID: <f8e6ff050709030628t240ccb1dqb2acbc38a28c1ac7@mail.gmail.com>

Yes - all this stuff is currently rather undocumented.  Hopefully that
will change in the near future!

Hadley

On 9/3/07, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:
> Thanks Hadley,
>
> I've been struggling with this all afternoon. But now it's working
> again. Since I'm using it in a script, the few extra lines don't bother
> me that much.
>
> Thierry
>
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
> methodology and quality assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> Do not put your faith in what statistics say until you have carefully
> considered what they do not say.  ~William W. Watt
> A statistical analysis, properly conducted, is a delicate dissection of
> uncertainties, a surgery of suppositions. ~M.J.Moroney
>
>
>
> > -----Oorspronkelijk bericht-----
> > Van: hadley wickham [mailto:h.wickham at gmail.com]
> > Verzonden: maandag 3 september 2007 15:15
> > Aan: ONKELINX, Thierry
> > CC: r-help at stat.math.ethz.ch
> > Onderwerp: Re: [R] Legend issue with ggplot2
> >
> > On 9/3/07, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:
> > > Dear useRs,
> > >
> > > I'm struggling with the new version of ggplot2. In the previous
> > > version I did something like this. But now this yield an
> > error (object "fill"
> > > not found).
> > >
> > > library(ggplot2)
> > > dummy <- data.frame(x = rep(1:10, 4), group = gl(4, 10)) dummy$y <-
> > > dummy$x * rnorm(4)[dummy$group] + 5 * rnorm(4)[dummy$group]
> > dummy$min
> > > <- dummy$y - 5 dummy$max <- dummy$y + 5 ggplot(data =
> > dummy, aes(x =
> > > x, max = max, min = min, fill = group)) +
> > > geom_ribbon() + geom_line(aes(y = max, colour = fill)) +
> > > geom_line(aes(y = min, colour = fill))
> >
> > Strange - I'm not sure why that ever worked.
> >
> > > When I adjust the code to the line below, it works again. But this
> > > time with two legend keys for "group". Any idea how to display only
> > > one legend key for group? The ggplot-code aboved yielded
> > only on legend key.
> > >
> > > ggplot(data = dummy, aes(x = x, max = max, min = min,
> > colour = group,
> > > fill = group)) + geom_ribbon() + geom_line(aes(y = max)) +
> > > geom_line(aes(y = min))
> >
> > You can manually turn off one of the legends:
> >
> > sc <- scale_colour_discrete()
> > sc$legend <- FALSE
> > .last_plot + sc
> >
> > It's not very convenient though, so I'll think about how to
> > do this automatically.  The legends need to be more
> > intelligent about only displaying the minimum necessary.
> >
> > Hadley
> >
>


-- 
http://had.co.nz/


From dxc13 at health.state.ny.us  Mon Sep  3 16:03:02 2007
From: dxc13 at health.state.ny.us (dxc13)
Date: Mon, 3 Sep 2007 07:03:02 -0700 (PDT)
Subject: [R] using temporary arrays in R
Message-ID: <12462219.post@talk.nabble.com>


useR's,

Is there a way to create a temporary array (or matrix) in R to hold values,
then drop or delete that temporary array from memory once I do not need it
anymore?

I am working with multidimensional arrays/matrices and I frequently perform
multiple operations on the same matrix and rename it to be another object. 
I want to be able to delete the older versions of the array/matrix to free
up space. 

Thank you. 
-- 
View this message in context: http://www.nabble.com/using-temporary-arrays-in-R-tf4372367.html#a12462219
Sent from the R help mailing list archive at Nabble.com.


From pomchip at free.fr  Mon Sep  3 16:05:40 2007
From: pomchip at free.fr (=?ISO-8859-1?Q?S=E9bastien?=)
Date: Mon, 03 Sep 2007 10:05:40 -0400
Subject: [R] Different behavior of mtext
In-Reply-To: <Pine.LNX.4.64.0709030726320.12798@gannet.stats.ox.ac.uk>
References: <46DB331E.8030004@free.fr>
	<Pine.LNX.4.64.0709030726320.12798@gannet.stats.ox.ac.uk>
Message-ID: <46DC14B4.2020902@free.fr>

Ok, the problem is clear now. I did not get that 'user-coordinates' was 
refering to par("usr"), when I read the help of mtext. If I may ask you 
some additional questions:
- you mentioned a missing unit() call ; at which point should it be done 
in my code examples ?
- could you give me some advices or helpful links about how to set up a 
grid viewport ? 
- and finally, probably a stupid question: is a gridview automatically 
set up when a plotting function is called ?

Sebastien

PS: To answer to your final question, my goal is to center a block of 
legend text on the device but to align the text to the left of this block.

Prof Brian Ripley a ?crit :
> On Sun, 2 Sep 2007, S?bastien wrote:
>
>> Dear R Users,
>>
>> I am quite surprised to see that mtext gives different results when it
>> is used with 'pairs' and with "plot'. In the two following codes, it
>> seems that the 'at' argument in mtext doesn't consider the same unit 
>> system.
>
> It is stated to be in 'user coordinates'.  Your code does not work 
> because unit() is missing.  If you mean the one from package grid, 
> "npc" is not user coordinates (and refers to a grid viewport which you 
> have not set up and coincidentally is the same as the initial user 
> coordinate system to which pairs() has reverted).
>
> Try par("usr") after your pairs() and plot() calls to see the difference.
> Plotting a 2x2 array of plots _is_ different from plotting one, so 
> this should be as expected.
>
> Since centring is the default for 'adj', it is unclear what you are 
> trying to achieve here.
>
>> I would appreciate your comments on this issue.
>>
>> Sebastien
>>
>> ##### Pairs
>>
>> mydata<-data.frame(x=1:10,y=1:10)
>>
>> par(cex.main=1, cex.axis=1, cex.lab=1, lwd=1,
>>    mar=c(5 + 5,4,4,2)+0.1)
>>
>> pairs(mydata,oma=c(5 + 5,4,4,2))
>>
>> mylegend<-c("mylegend A","mylegend B","mylegend C","mylegend test")
>> mylegend.width = strwidth(mylegend[which.max(nchar(mylegend))], 
>> "figure")
>>
>> for (i in 1:4) {
>> mtext(text=mylegend[i],
>>        side = 1,
>>        line = 3+i,
>>        at = unit((1-mylegend.width)/2,"npc"),            # centers the
>> legend at the bottom
>>        adj=0,
>>        padj=0)}
>>
>> ##### plot
>>
>> mydata<-data.frame(x=1:10,y=1:10)
>>
>> par(cex.main=1, cex.axis=1, cex.lab=1, lwd=1,
>>    mar=c(5 + 5,4,4,2)+0.1)
>>
>> plot(mydata,oma=c(5 + 5,4,4,2))
>>
>> mylegend<-c("mylegend A","mylegend B","mylegend C","mylegend test")
>> mylegend.width = strwidth(mylegend[which.max(nchar(mylegend))], 
>> "figure")
>>
>> for (i in 1:4) {
>> mtext(text=mylegend[i],
>>        side = 1,
>>        line = 3+i,
>>        at = unit((1-mylegend.width)/2,"npc"),            # should
>> center the legend at the bottom but doesn't do it !
>>        adj=0,
>>        padj=0)}
>


From ggrothendieck at gmail.com  Mon Sep  3 16:18:31 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 3 Sep 2007 10:18:31 -0400
Subject: [R] using temporary arrays in R
In-Reply-To: <12462219.post@talk.nabble.com>
References: <12462219.post@talk.nabble.com>
Message-ID: <971536df0709030718y4604628at9e7273db58d1e7ae@mail.gmail.com>

You can do it in a local, in a function or explicitly remove it.  Also
if you never assign it to a variable then it will be garbage collected as well

# 1
local({
	print(gc())
	x <- matrix(NA, 1000, 1000)
	print(gc())
})
gc()

# 2
f <- function() {
	print(gc())
	x <- matrix(NA, 1000, 1000)
	print(gc())
}
f()
gc()

# 3
gc()
x <- matrix(NA, 1000, 1000)
gc()
rm(x)
gc()

# 4
gc()
sum(matrix(1, 1000, 1000))
gc()



On 9/3/07, dxc13 <dxc13 at health.state.ny.us> wrote:
>
> useR's,
>
> Is there a way to create a temporary array (or matrix) in R to hold values,
> then drop or delete that temporary array from memory once I do not need it
> anymore?
>
> I am working with multidimensional arrays/matrices and I frequently perform
> multiple operations on the same matrix and rename it to be another object.
> I want to be able to delete the older versions of the array/matrix to free
> up space.
>
> Thank you.
> --
> View this message in context: http://www.nabble.com/using-temporary-arrays-in-R-tf4372367.html#a12462219
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Mon Sep  3 16:49:55 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Sep 2007 15:49:55 +0100 (BST)
Subject: [R] Different behavior of mtext
In-Reply-To: <46DC14B4.2020902@free.fr>
References: <46DB331E.8030004@free.fr>
	<Pine.LNX.4.64.0709030726320.12798@gannet.stats.ox.ac.uk>
	<46DC14B4.2020902@free.fr>
Message-ID: <Pine.LNX.4.64.0709031547590.9729@gannet.stats.ox.ac.uk>

On Mon, 3 Sep 2007, S?bastien wrote:

> Ok, the problem is clear now. I did not get that 'user-coordinates' was 
> refering to par("usr"), when I read the help of mtext. If I may ask you some 
> additional questions:
> - you mentioned a missing unit() call ; at which point should it be done in 
> my code examples ?

Before it is used.  The problem is that I believe more than one package 
has a unit() function.

> - could you give me some advices or helpful links about how to set up a grid 
> viewport ? - and finally, probably a stupid question: is a gridview 
> automatically set up when a plotting function is called ?

If you want to mix grid and base graphics, you need package gridBase, but 
really I would not advise a beginner to be using grid directly (that is, 
not via lattice to ggplot*).


> Sebastien
>
> PS: To answer to your final question, my goal is to center a block of legend 
> text on the device but to align the text to the left of this block.
>
> Prof Brian Ripley a ?crit :
>> On Sun, 2 Sep 2007, S?bastien wrote:
>> 
>>> Dear R Users,
>>> 
>>> I am quite surprised to see that mtext gives different results when it
>>> is used with 'pairs' and with "plot'. In the two following codes, it
>>> seems that the 'at' argument in mtext doesn't consider the same unit 
>>> system.
>> 
>> It is stated to be in 'user coordinates'.  Your code does not work because 
>> unit() is missing.  If you mean the one from package grid, "npc" is not 
>> user coordinates (and refers to a grid viewport which you have not set up 
>> and coincidentally is the same as the initial user coordinate system to 
>> which pairs() has reverted).
>> 
>> Try par("usr") after your pairs() and plot() calls to see the difference.
>> Plotting a 2x2 array of plots _is_ different from plotting one, so this 
>> should be as expected.
>> 
>> Since centring is the default for 'adj', it is unclear what you are trying 
>> to achieve here.
>> 
>>> I would appreciate your comments on this issue.
>>> 
>>> Sebastien
>>> 
>>> ##### Pairs
>>> 
>>> mydata<-data.frame(x=1:10,y=1:10)
>>> 
>>> par(cex.main=1, cex.axis=1, cex.lab=1, lwd=1,
>>>    mar=c(5 + 5,4,4,2)+0.1)
>>> 
>>> pairs(mydata,oma=c(5 + 5,4,4,2))
>>> 
>>> mylegend<-c("mylegend A","mylegend B","mylegend C","mylegend test")
>>> mylegend.width = strwidth(mylegend[which.max(nchar(mylegend))], "figure")
>>> 
>>> for (i in 1:4) {
>>> mtext(text=mylegend[i],
>>>        side = 1,
>>>        line = 3+i,
>>>        at = unit((1-mylegend.width)/2,"npc"),            # centers the
>>> legend at the bottom
>>>        adj=0,
>>>        padj=0)}
>>> 
>>> ##### plot
>>> 
>>> mydata<-data.frame(x=1:10,y=1:10)
>>> 
>>> par(cex.main=1, cex.axis=1, cex.lab=1, lwd=1,
>>>    mar=c(5 + 5,4,4,2)+0.1)
>>> 
>>> plot(mydata,oma=c(5 + 5,4,4,2))
>>> 
>>> mylegend<-c("mylegend A","mylegend B","mylegend C","mylegend test")
>>> mylegend.width = strwidth(mylegend[which.max(nchar(mylegend))], "figure")
>>> 
>>> for (i in 1:4) {
>>> mtext(text=mylegend[i],
>>>        side = 1,
>>>        line = 3+i,
>>>        at = unit((1-mylegend.width)/2,"npc"),            # should
>>> center the legend at the bottom but doesn't do it !
>>>        adj=0,
>>>        padj=0)}
>> 
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From upsattar at yahoo.com  Mon Sep  3 16:32:47 2007
From: upsattar at yahoo.com (Abdus Sattar)
Date: Mon, 3 Sep 2007 07:32:47 -0700 (PDT)
Subject: [R] Fitting Pattern-Mixture Models
Message-ID: <744386.12191.qm@web58115.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070903/132ac02a/attachment.pl 

From dverzi at mail.sdsu.edu  Mon Sep  3 19:01:26 2007
From: dverzi at mail.sdsu.edu (dverzi at mail.sdsu.edu)
Date: Mon,  3 Sep 2007 10:01:26 -0700 (PDT)
Subject: [R] match help
Message-ID: <20070903100126.BDL40540@mail.sdsu.edu>

In my code, I would like to replace entries in t with 
entries from a random normal distribution.  

n<-10
> nl<-round(1.5+rexp(1,rate=2)
rate=2))
> nl
[1] 2
> r<-1:n 
> s<-sort(sample(r,nl))
> t<-match(r,s)
> r
 [1]  1  2  3  4  5  6  7  8  9 10
> s
[1] 3 8
>t
 [1] NA NA  1 NA NA NA NA  2 NA NA

t.random<-function(x) {for(i in 1:n) ifelse(x[i]!=NA, x[i]<-rnorm(1), x[i]<-NA}

t.random(t)

t
 [1] NA NA  1 NA NA NA NA  2 NA NA



Thank you for your time, 


Diana Verzi
Associate Professor of Mathematics


From Dimitris.Rizopoulos at med.kuleuven.be  Mon Sep  3 19:18:46 2007
From: Dimitris.Rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Mon, 03 Sep 2007 19:18:46 +0200
Subject: [R] match help
In-Reply-To: <20070903100126.BDL40540@mail.sdsu.edu>
References: <20070903100126.BDL40540@mail.sdsu.edu>
Message-ID: <20070903191846.gv21hf4h7sye8gss@webmail4.kuleuven.be>

try this:

x <- c(NA, NA, 1, NA, NA, NA, NA, 2, NA, NA)

na.ind <- is.na(x)
x[na.ind] <- rnorm(sum(na.ind))
x


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
      http://www.student.kuleuven.be/~m0390867/dimitris.htm


Quoting dverzi at mail.sdsu.edu:

> In my code, I would like to replace entries in t with
> entries from a random normal distribution.
>
> n<-10
>> nl<-round(1.5+rexp(1,rate=2)
> rate=2))
>> nl
> [1] 2
>> r<-1:n
>> s<-sort(sample(r,nl))
>> t<-match(r,s)
>> r
>  [1]  1  2  3  4  5  6  7  8  9 10
>> s
> [1] 3 8
>> t
>  [1] NA NA  1 NA NA NA NA  2 NA NA
>
> t.random<-function(x) {for(i in 1:n) ifelse(x[i]!=NA,   
> x[i]<-rnorm(1), x[i]<-NA}
>
> t.random(t)
>
> t
>  [1] NA NA  1 NA NA NA NA  2 NA NA
>
>
>
> Thank you for your time,
>
>
> Diana Verzi
> Associate Professor of Mathematics
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>



Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From pcd at wikitex.org  Mon Sep  3 20:16:52 2007
From: pcd at wikitex.org (Peter Danenberg)
Date: Mon, 3 Sep 2007 13:16:52 -0500
Subject: [R] Row-Echelon Form
Message-ID: <20070903181652.GA28455@klutometis.wikitex.org>

I was looking for an R-package that would reduce matrices to
row-echelon form, but Google was not my friend; any leads?

If not, I wonder if the problem could be expressed in terms of
constraint satisfaction...


From greg at random-technologies-llc.com  Mon Sep  3 20:42:05 2007
From: greg at random-technologies-llc.com (Gregory R. Warnes)
Date: Mon, 3 Sep 2007 14:42:05 -0400
Subject: [R] ADV: Support and Services for R from Random Technologies, LLC.
Message-ID: <1EF13363-30D3-4C7D-A234-16D17E02FAB4@random-technologies-llc.com>


	"The Power of Open-source R. The Confidence of Enterprise-Grade
		  	     Support and Services."


Hello Rusers!

I am pleased to announce the immediate availability of the RStat  
Statistical
Software System from Random Technologies, LLC.

RStat couples the tremendous functionality and flexibility of the R
statistical software system with enterprise-level validation,  
documentation,
software support, and consulting services from Random Technologies, LLC.
RStat is available in several versions for a variety of needs:

     * RStat Personal - Personal and educational use on a single  
computer,
        includes 90-day installation support - starting at $59.95

     * RStat Professional - Professional use on a single workstation,
       includes 1 full year of installation and usage technical support
       - Single user starting at $599.95

     * RStat Enterprise - Professional use in mission critical and  
regulated
       contexts, includes full technical support, sotware lifecycle
       documentation, testing scripts and validation templates. -  
Contact us
       for pricing and availability

and a range of system types:

     * Personal Computer - 32 bit Microsoft Windows
     * Workstation - 32 bit Microsoft Windows, 32 and 64 bit Linux,
        Mac OS X (ppc and x86), and Solaris
     * Multi-user Server - 32 bit Microsoft Windows, 32 and 64 bit
        Linux, Mac OS X Server, and Solaris
     * Multi-node Computational Cluster - Linux, Solaris

All versions include a binary installers of RStat, an integrated editor,
an extended set of supported packages, binary installers for all of the
compilers, build tools, and libraries necessary for developing and
building source R packages, and the complete set of contributed
packages from CRAN.

************************************************************************ 
****
** Introductory Special: 20% Discount for orders placed before  
2007-09-15 **
************************************************************************ 
****

Complete information on RStat and our other software packages  
(include RPy
for RStat, RSOAP for RStat, and BioConductor for RStat) is available  
at our
web site:

	http://random-technologies-llc.com

or contact our sales team at:

	sales at random-technologies-llc.com
	USA & Canada Toll Free: 1-877-813-3266
	Outside the USA & Canada: 1-585-419-6853


Cordially,

-Greg
Gregory R. Warnes, Ph.D.
Chief Scientist
Random Technologies, LLC.


From upsattar at yahoo.com  Mon Sep  3 17:22:31 2007
From: upsattar at yahoo.com (Abdus Sattar)
Date: Mon, 3 Sep 2007 08:22:31 -0700 (PDT)
Subject: [R] Fitting Pattern-Mixture Models
Message-ID: <62265.20986.qm@web58109.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070903/a4860e3c/attachment.pl 

From yogesh.mpi at googlemail.com  Mon Sep  3 22:25:03 2007
From: yogesh.mpi at googlemail.com (Yogesh Tiwari)
Date: Mon, 3 Sep 2007 22:25:03 +0200
Subject: [R] how to compute cross correlation
Message-ID: <71cc5ca20709031325y73abd0cco50b203662f8730f5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070903/c6f7467a/attachment.pl 

From rory.winston at gmail.com  Mon Sep  3 23:05:47 2007
From: rory.winston at gmail.com (Rory Winston)
Date: Mon, 3 Sep 2007 22:05:47 +0100
Subject: [R] Derivative of a Function Expression
Message-ID: <3f446aa30709031405o5c347ce2od28b15acb8a73978@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070903/7c4b4887/attachment.pl 

From albmont at centroin.com.br  Mon Sep  3 23:45:40 2007
From: albmont at centroin.com.br (Alberto Monteiro)
Date: Mon, 3 Sep 2007 19:45:40 -0200
Subject: [R] Derivative of a Function Expression
In-Reply-To: <3f446aa30709031405o5c347ce2od28b15acb8a73978@mail.gmail.com>
References: <3f446aa30709031405o5c347ce2od28b15acb8a73978@mail.gmail.com>
Message-ID: <20070903213913.M14181@centroin.com.br>

Rory Winston wrote:
> 
> I am currently (for pedagogical purposes) writing a simple numerical
> analysis library in R. I have come unstuck when writing a simple
> Newton-Raphson implementation, that looks like this:
> 
> f <- function(x) { 2*cos(x)^2 + 3*sin(x) +  0.5  }
> 
> root <- newton(f, tol=0.0001, N=20, a=1)
> 
> My issue is calculating the symbolic derivative of f() inside the 
> newton() function. 
>
If it's pedagogical, maybe returning to basics could help.

What is f'(x)?

It's the limit of (f(x + h) - f(x)) / h when h tends to zero.

So, do it numerically: take a sufficiently small h and
compute the limit. h must be small enough
that h^2 f''(x) is much smaller than h f'(x), but big
enough that f(x+h) is not f(x)

numerical.derivative <- function(f, x, h = 0.0001)
{
  # test something
  (f(x + h) - f(x)) / h
}

Ex:

numerical.derivative(cos, pi) = 5e-05 # should be -sin(pi) = 0
numerical.derivative(sin, pi) = -1    # ok
numerical.derivative(exp, 0) = 1.00005 # close enough
numerical.derivative(sqrt, 0) = 100 # should be Inf

Alberto Monteiro


From ggrothendieck at gmail.com  Mon Sep  3 23:58:45 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 3 Sep 2007 17:58:45 -0400
Subject: [R] Derivative of a Function Expression
In-Reply-To: <3f446aa30709031405o5c347ce2od28b15acb8a73978@mail.gmail.com>
References: <3f446aa30709031405o5c347ce2od28b15acb8a73978@mail.gmail.com>
Message-ID: <971536df0709031458n68bfafe2y9f8ea13cedc5030c@mail.gmail.com>

The Ryacas package can do that (but the function must be one line
and it can't have brace brackets).  The first yacas call below registers f with
yacas, then we set up a function to act as a template to hold the
derivative and then we set its body calling yacas again to take the
derivative.

library(Ryacas)
f <- function(x)  2*cos(x)^2 + 3*sin(x) +  0.5
yacas(f) # register f with yacas
Df <- f
body(Df) <- yacas(expression(deriv(f(x))))[[1]]
Df

Here is the output:

> library(Ryacas)
> f <- function(x)  2*cos(x)^2 + 3*sin(x) +  0.5
> yacas(f)
[1] "Starting Yacas!"
expression(TRUE)
> Df <- f
> body(Df) <- yacas(expression(deriv(f(x))))[[1]]
> Df
function (x)
2 * (-2 * sin(x) * cos(x)) + 3 * cos(x)

Also see:

demo("Ryacas-Function")

and the other demos, vignette and home page:
   http://ryacas.googlecode.com



On 9/3/07, Rory Winston <rory.winston at gmail.com> wrote:
> Hi
>
> I am currently (for pedagogical purposes) writing a simple numerical
> analysis library in R. I have come unstuck when writing a simple
> Newton-Raphson implementation, that looks like this:
>
> f <- function(x) { 2*cos(x)^2 + 3*sin(x) +  0.5  }
>
> root <- newton(f, tol=0.0001, N=20, a=1)
>
> My issue is calculating the symbolic derivative of f() inside the newton()
> function. I cant seem to get R to do this...I can of course calculate the
> derivative by calling D() with an expression object containing the inner
> function definition, but I would like to just define the function once and
> then compute the derivative of the existing function. I have tried using
> deriv() and as.call(), but I am evidently misusing them, as they dont do
> what I want. Does anyone know how I can define a function, say foo, which
> manipulates one or more arguments, and then refer to that function later in
> my code in order to calculate a (partial) derivative?
>
> Thanks
> Rory
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Tue Sep  4 00:09:59 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 3 Sep 2007 18:09:59 -0400
Subject: [R] Derivative of a Function Expression
In-Reply-To: <971536df0709031458n68bfafe2y9f8ea13cedc5030c@mail.gmail.com>
References: <3f446aa30709031405o5c347ce2od28b15acb8a73978@mail.gmail.com>
	<971536df0709031458n68bfafe2y9f8ea13cedc5030c@mail.gmail.com>
Message-ID: <971536df0709031509l77fd8a37lc9daab3e0633d3c9@mail.gmail.com>

Actually in thinking about this its pretty easy to do it without Ryacas too:

Df <- f
body(Df) <- deriv(body(f), "x")
Df


On 9/3/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> The Ryacas package can do that (but the function must be one line
> and it can't have brace brackets).  The first yacas call below registers f with
> yacas, then we set up a function to act as a template to hold the
> derivative and then we set its body calling yacas again to take the
> derivative.
>
> library(Ryacas)
> f <- function(x)  2*cos(x)^2 + 3*sin(x) +  0.5
> yacas(f) # register f with yacas
> Df <- f
> body(Df) <- yacas(expression(deriv(f(x))))[[1]]
> Df
>
> Here is the output:
>
> > library(Ryacas)
> > f <- function(x)  2*cos(x)^2 + 3*sin(x) +  0.5
> > yacas(f)
> [1] "Starting Yacas!"
> expression(TRUE)
> > Df <- f
> > body(Df) <- yacas(expression(deriv(f(x))))[[1]]
> > Df
> function (x)
> 2 * (-2 * sin(x) * cos(x)) + 3 * cos(x)
>
> Also see:
>
> demo("Ryacas-Function")
>
> and the other demos, vignette and home page:
>   http://ryacas.googlecode.com
>
>
>
> On 9/3/07, Rory Winston <rory.winston at gmail.com> wrote:
> > Hi
> >
> > I am currently (for pedagogical purposes) writing a simple numerical
> > analysis library in R. I have come unstuck when writing a simple
> > Newton-Raphson implementation, that looks like this:
> >
> > f <- function(x) { 2*cos(x)^2 + 3*sin(x) +  0.5  }
> >
> > root <- newton(f, tol=0.0001, N=20, a=1)
> >
> > My issue is calculating the symbolic derivative of f() inside the newton()
> > function. I cant seem to get R to do this...I can of course calculate the
> > derivative by calling D() with an expression object containing the inner
> > function definition, but I would like to just define the function once and
> > then compute the derivative of the existing function. I have tried using
> > deriv() and as.call(), but I am evidently misusing them, as they dont do
> > what I want. Does anyone know how I can define a function, say foo, which
> > manipulates one or more arguments, and then refer to that function later in
> > my code in order to calculate a (partial) derivative?
> >
> > Thanks
> > Rory
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From albmont at centroin.com.br  Tue Sep  4 00:57:09 2007
From: albmont at centroin.com.br (Alberto Vieira Ferreira Monteiro)
Date: Mon, 3 Sep 2007 22:57:09 +0000
Subject: [R] Derivative of a Function Expression
In-Reply-To: <971536df0709031509l77fd8a37lc9daab3e0633d3c9@mail.gmail.com>
References: <3f446aa30709031405o5c347ce2od28b15acb8a73978@mail.gmail.com>
	<971536df0709031458n68bfafe2y9f8ea13cedc5030c@mail.gmail.com>
	<971536df0709031509l77fd8a37lc9daab3e0633d3c9@mail.gmail.com>
Message-ID: <200709032257.09996.albmont@centroin.com.br>

Gabor Grothendieck wrote:
>
> Actually in thinking about this its pretty easy to do it without Ryacas
> too:
>
> Df <- f
> body(Df) <- deriv(body(f), "x")
> Df
>
This is weird.

f <- function(x) { x^2 + 2*x+1 }
Df <- f
body(Df) <- deriv(body(f), "x") # error

Also:

f <- function(x) x^2 + 2 * x + 1
Df <- f
body(Df) <- deriv(body(f), "x") # ok
D2f <- f
body(D2f) <- deriv(body(Df), "x") # error

Alberto Monteiro


From ggrothendieck at gmail.com  Tue Sep  4 01:05:48 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 3 Sep 2007 19:05:48 -0400
Subject: [R] Derivative of a Function Expression
In-Reply-To: <200709032257.09996.albmont@centroin.com.br>
References: <3f446aa30709031405o5c347ce2od28b15acb8a73978@mail.gmail.com>
	<971536df0709031458n68bfafe2y9f8ea13cedc5030c@mail.gmail.com>
	<971536df0709031509l77fd8a37lc9daab3e0633d3c9@mail.gmail.com>
	<200709032257.09996.albmont@centroin.com.br>
Message-ID: <971536df0709031605g3b1a422dj7d90cf5cfc28b3b1@mail.gmail.com>

The problem is that brace brackets are not in the derivatives table.
Make sure you don't have any.

On 9/3/07, Alberto Vieira Ferreira Monteiro <albmont at centroin.com.br> wrote:
> Gabor Grothendieck wrote:
> >
> > Actually in thinking about this its pretty easy to do it without Ryacas
> > too:
> >
> > Df <- f
> > body(Df) <- deriv(body(f), "x")
> > Df
> >
> This is weird.
>
> f <- function(x) { x^2 + 2*x+1 }
> Df <- f
> body(Df) <- deriv(body(f), "x") # error
>
> Also:
>
> f <- function(x) x^2 + 2 * x + 1
> Df <- f
> body(Df) <- deriv(body(f), "x") # ok
> D2f <- f
> body(D2f) <- deriv(body(Df), "x") # error
>
> Alberto Monteiro
>


From Ted.Harding at manchester.ac.uk  Tue Sep  4 01:10:46 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Tue, 04 Sep 2007 00:10:46 +0100 (BST)
Subject: [R] Derivative of a Function Expression
In-Reply-To: <20070903213913.M14181@centroin.com.br>
Message-ID: <XFMail.070904001046.Ted.Harding@manchester.ac.uk>

On 03-Sep-07 21:45:40, Alberto Monteiro wrote:
> Rory Winston wrote:
>> 
>> I am currently (for pedagogical purposes) writing a simple numerical
>> analysis library in R. I have come unstuck when writing a simple
>> Newton-Raphson implementation, that looks like this:
>> 
>> f <- function(x) { 2*cos(x)^2 + 3*sin(x) +  0.5  }
>> 
>> root <- newton(f, tol=0.0001, N=20, a=1)
>> 
>> My issue is calculating the symbolic derivative of f() inside the 
>> newton() function. 
>>
> If it's pedagogical, maybe returning to basics could help.
> 
> What is f'(x)?
> 
> It's the limit of (f(x + h) - f(x)) / h when h tends to zero.
> 
> So, do it numerically: take a sufficiently small h and
> compute the limit. h must be small enough
> that h^2 f''(x) is much smaller than h f'(x), but big
> enough that f(x+h) is not f(x)
> 
> numerical.derivative <- function(f, x, h = 0.0001)
> {
>   # test something
>   (f(x + h) - f(x)) / h
> }
> 
> Ex:
> 
> numerical.derivative(cos, pi) = 5e-05 # should be -sin(pi) = 0
> numerical.derivative(sin, pi) = -1    # ok
> numerical.derivative(exp, 0) = 1.00005 # close enough
> numerical.derivative(sqrt, 0) = 100 # should be Inf
> 
> Alberto Monteiro

If you want to "go back to basics", it's worth noting that
for a function which has a derivative at x (which excludes
your sqrt(x) at x=0, despite the result you got above,
since only the 1-sided limit as h-->0+ exists):

   (f(x+h/2) - f(h-h/2))/h

is generally a far better approximation to f'(x) than is

   (f(x+h) - f(x))/h

since the term in   h^2 * f''(x)   in the expansion is
automatically eliminated! So the accuracy is O(h^2), not
O(h) as with yur definition.

num.deriv<-function(f,x,h=0.001){(f(x + h/2) - f(x-h/2))/h}

num.deriv(cos, pi)
## [1] 0

num.deriv(sin, pi)
[1] -1

but of course num.deriv(sqrt,0) won't work, since it requires
evaluation of sqrt(-h/2).

Hovever, other comparisons with your definition are possible:

numerical.derivative(sin,pi/3)-0.5
##[1] -4.33021e-05

num.deriv(sin,pi/3)-0.5
##[1] -2.083339e-08

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 04-Sep-07                                       Time: 00:10:42
------------------------------ XFMail ------------------------------


From m_olshansky at yahoo.com  Tue Sep  4 01:23:08 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Mon, 3 Sep 2007 16:23:08 -0700 (PDT)
Subject: [R] element wise opertation between a vector and a list
In-Reply-To: <d89bf0cd0709022336l7122dfd9x7e423b2316a56201@mail.gmail.com>
Message-ID: <48303.26133.qm@web32215.mail.mud.yahoo.com>

Hi,

Getting your e is not a problem:

> a<- list(c(1,3),c(1,2),c(2,3))
>  b<-c(10,20,30)
> aa<-matrix(unlist(a),nrow=2)
> ee<-aa+rbind(b,b)
> e<-apply(ee,2,"sum")
> e
[1] 24 43 65
> 

But this will not work if different list members have
different number of elements.

--- Yongwan Chun <ywchun at gmail.com> wrote:

> I want to try to get a result of element wise
> addition between a
> vector and a list. It can be done with "for
> statement." In order to
> reducing computing time, I have tried to avoid "for
> state." If anybody
> give me an idea, I would apprecite it much.
> 
> for example, with a & b as below lines,
> 
> a<- list(c(1,3),c(1,2),c(2,3))
> b<-c(10,20,30)
> 
> I would like to have a list (like "d") or a vector
> (like "e") as below.
> 
>
d<-list(c((1+10),(3+10)),c((1+20),(2+20)),c((2+30),(3+30)))
> e<- c((1+10)+(3+10),(1+20)+(2+20),(2+30)+(3+30))
> 
> Thanks,
> 
> 
> Yongwan Chun
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From deepayan.sarkar at gmail.com  Tue Sep  4 01:27:45 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Mon, 3 Sep 2007 16:27:45 -0700
Subject: [R] plotting predicted curves with log scale in lattice
In-Reply-To: <49173.194.57.165.23.1188806392.squirrel@webmail.lyon.inserm.fr>
References: <49173.194.57.165.23.1188806392.squirrel@webmail.lyon.inserm.fr>
Message-ID: <eb555e660709031627h7de48736nb3956e0168842ef1@mail.gmail.com>

On 9/3/07, Ken Knoblauch <knoblauch at lyon.inserm.fr> wrote:
> Hi,
>
> I was taken off guard by the following behavior in a lattice plot.
> I frequently want to add a predicted curve defined at more
> points than in the formula expression of xyplot.  There have
> been numerous examples of how to do this on r-help, but I
> still often struggle to make this work.  I just realized that
> specifying one of the axes on a log scale does not guarantee
> that the added data for a curve will automatically take that
> into account.  I don't know if this should be called a bug,

More like a possibly desirable feature that's missing.

> I haven't picked up an indication that would lead me to
> expect this in the documentation.

Yes, the documentation is a bit vague. I've changed it to the
following, which is hopefully clearer.

          'log' Controls whether the corresponding variable ('x' or
               'y') will be log transformed before being passed to the
               panel function.  Defaults to 'FALSE', in which case the
               data are not transformed.  Other possible values are any
               number that works as a base for taking logarithm, 'TRUE'
               (which is equivalent to 10), and '"e"' (for the natural
               logarithm).  As a side effect, the corresponding axis is
               labeled differently.  Note that this is a transformation
               of the data, not the axes.  Other than the axis
               labeling, using this feature is no different than
               transforming the data in the formula; e.g.,
               'scales=list(x = list(log = 2))' is equivalent to 'y ~
               log2(x)'.

-Deepayan


From ggrothendieck at gmail.com  Tue Sep  4 01:29:54 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 3 Sep 2007 19:29:54 -0400
Subject: [R] Derivative of a Function Expression
In-Reply-To: <971536df0709031605g3b1a422dj7d90cf5cfc28b3b1@mail.gmail.com>
References: <3f446aa30709031405o5c347ce2od28b15acb8a73978@mail.gmail.com>
	<971536df0709031458n68bfafe2y9f8ea13cedc5030c@mail.gmail.com>
	<971536df0709031509l77fd8a37lc9daab3e0633d3c9@mail.gmail.com>
	<200709032257.09996.albmont@centroin.com.br>
	<971536df0709031605g3b1a422dj7d90cf5cfc28b3b1@mail.gmail.com>
Message-ID: <971536df0709031629l3f57d65apdb7c0847d7e77dcb@mail.gmail.com>

One improvement.  This returns a function directly without having
to create a template and filling in its body:

deriv(body(f), "x", func = TRUE)

On 9/3/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> The problem is that brace brackets are not in the derivatives table.
> Make sure you don't have any.
>
> On 9/3/07, Alberto Vieira Ferreira Monteiro <albmont at centroin.com.br> wrote:
> > Gabor Grothendieck wrote:
> > >
> > > Actually in thinking about this its pretty easy to do it without Ryacas
> > > too:
> > >
> > > Df <- f
> > > body(Df) <- deriv(body(f), "x")
> > > Df
> > >
> > This is weird.
> >
> > f <- function(x) { x^2 + 2*x+1 }
> > Df <- f
> > body(Df) <- deriv(body(f), "x") # error
> >
> > Also:
> >
> > f <- function(x) x^2 + 2 * x + 1
> > Df <- f
> > body(Df) <- deriv(body(f), "x") # ok
> > D2f <- f
> > body(D2f) <- deriv(body(Df), "x") # error
> >
> > Alberto Monteiro
> >
>


From m_olshansky at yahoo.com  Tue Sep  4 01:31:37 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Mon, 3 Sep 2007 16:31:37 -0700 (PDT)
Subject: [R] how to compute cross correlation
In-Reply-To: <71cc5ca20709031325y73abd0cco50b203662f8730f5@mail.gmail.com>
Message-ID: <500879.70816.qm@web32201.mail.mud.yahoo.com>

The simlest answer is that X and Y are two vectors of
length n then (un-normalized) cross correlation
between X and Y is sum(i=1 to n)
{X(i)-Xbar)*(Y(i)-Ybar)} where Xbar and Ybar are the
means of X and Y respectively.

You may need something different, so could you be more
specific? What do you mean by ASCII - they are in an
ASCII files?

Regards,

Moshe.

--- Yogesh Tiwari <yogesh.mpi at googlemail.com> wrote:

> Hello R Users,
> 
> How to compute cross correlation between two time
> series. Data is in ASCII
> format. I am using R on windows.
> 
> Many thanks,
> 
> Regards,
> Yogesh
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From ggrothendieck at gmail.com  Tue Sep  4 01:49:23 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 3 Sep 2007 19:49:23 -0400
Subject: [R] Derivative of a Function Expression
In-Reply-To: <971536df0709031629l3f57d65apdb7c0847d7e77dcb@mail.gmail.com>
References: <3f446aa30709031405o5c347ce2od28b15acb8a73978@mail.gmail.com>
	<971536df0709031458n68bfafe2y9f8ea13cedc5030c@mail.gmail.com>
	<971536df0709031509l77fd8a37lc9daab3e0633d3c9@mail.gmail.com>
	<200709032257.09996.albmont@centroin.com.br>
	<971536df0709031605g3b1a422dj7d90cf5cfc28b3b1@mail.gmail.com>
	<971536df0709031629l3f57d65apdb7c0847d7e77dcb@mail.gmail.com>
Message-ID: <971536df0709031649xf981138xee56c72841d87e12@mail.gmail.com>

And if f has brace brackets surrounding the body then do this:

f <- function(x) { x*x }
deriv(body(f)[[2]], "x", func = TRUE)

If you are writing a general function you can do this:

e <- if (identical(body(f)[[1]], as.name("{"))) body(f)[[2]] else body(f)
deriv(e, "x", func = TRUE)


On 9/3/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> One improvement.  This returns a function directly without having
> to create a template and filling in its body:
>
> deriv(body(f), "x", func = TRUE)
>
> On 9/3/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > The problem is that brace brackets are not in the derivatives table.
> > Make sure you don't have any.
> >
> > On 9/3/07, Alberto Vieira Ferreira Monteiro <albmont at centroin.com.br> wrote:
> > > Gabor Grothendieck wrote:
> > > >
> > > > Actually in thinking about this its pretty easy to do it without Ryacas
> > > > too:
> > > >
> > > > Df <- f
> > > > body(Df) <- deriv(body(f), "x")
> > > > Df
> > > >
> > > This is weird.
> > >
> > > f <- function(x) { x^2 + 2*x+1 }
> > > Df <- f
> > > body(Df) <- deriv(body(f), "x") # error
> > >
> > > Also:
> > >
> > > f <- function(x) x^2 + 2 * x + 1
> > > Df <- f
> > > body(Df) <- deriv(body(f), "x") # ok
> > > D2f <- f
> > > body(D2f) <- deriv(body(Df), "x") # error
> > >
> > > Alberto Monteiro
> > >
> >
>


From m_olshansky at yahoo.com  Tue Sep  4 02:26:21 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Mon, 3 Sep 2007 17:26:21 -0700 (PDT)
Subject: [R] The quadprog package
In-Reply-To: <6699922FABDD9145A5C94569C2B438EB0103FB8A@MA-EXCL02.konzern.mvvcorp.de>
Message-ID: <246929.99871.qm@web32202.mail.mud.yahoo.com>

Hi Thomas,

On my computer the solution is (0,0,1,0,0,0,0) (within
machine accuracy) and it satisfies the constraints.

--- thomas.schwander at mvv.de wrote:

> Hi everybody,
> 
> I'm using Windows XP Prof, R 2.5.1 and a Pentium 4
> Processor.
> Now, I want to solve a quadratic optimization
> program (Portfolio Selection) with the quadprog
> package
> 
> I want to minimize (\omega'%*%\Sigma%*%\omega)
> Subject to
> 	(1) \iota' %*% \omega = 1 (full investment)
> 	(2) R'%*%\omega = \mu (predefined expectation
> value)
> 	(3) \omega \ge 0 (no short sales).
> 
> Where 
> 	\omega is a Nx1 vector of the weights invested in
> each asset
> 	\Sigma is the NxN variance-covariance matrix
> 	\iota is a 1xN vector of 1's
> 	R' is a Nx1 vector of the expected returns
> 	and
> 	\mu is a number, the postualted return of the
> investor
> 
> I've done the following code but it doesn't make
> what I want it to do. The weights aren't all
> positive and the \mu isn't reached. What's wrong
> with my code?
> 
> Require(quadprog)
> Dmat<-diag(1,7,7)
> # muss als quadratische Matrix eingegeben werden
> Dmat
> dvec<-matrix(0,7,1) # muss als Spaltenvektor
> eingegeben werden
> dvec
> mu<-0 # (in Mio. ???)
> bvec<-c(1,mu,matrix(0,7,1)) # muss als Spaltenvektor
> eingegeben werden
> bvec
> mu_r<-c(19.7,33.0,0.0,49.7, 82.5, 39.0,11.8)	
>
Amat<-matrix(c(matrix(1,1,7),7*mu_r,diag(1,7,7)),9,7,byrow=T)
> 
> # muss als Matrix angegeben werden, wie sie wirklich
> ist
> Amat
> meq<-2
>
loesung<-solve.QP(Dmat,dvec,Amat=t(Amat),bvec=bvec,meq=2)
> loesung
> 
> # ??berpr??fen, ob System richtig gel??st wurde
> loesung$solution %*% mu_r
> sum(loesung$solution)
> for (i in 1:7){
> 	a<-loesung$solution[i]>=0
> 	print(a)
> }
> 
> Thanks in advance for your answers.
> 
> ______________________________
> 
> Thomas Schwander
> 
> MVV Energie
> Konzern-Risikocontrolling
> 
> Telefon 0621 - 290-3115
> Telefax 0621 - 290-3664
> 
> E-Mail: Thomas.Schwander at mvv.de .  Internet:
> www.mvv.de
> MVV Energie AG . Luisenring 49 . 68159 Mannheim
> Handelsregister-Nr. HRB 1780, Amtsgericht Mannheim
> Vorsitzender des Aufsichtsrates: Herr Dr. Peter Kurz
> Vorstand: Dr. Rudolf Schulten (Vorsitzender) . 
> Matthias Br??ckmann . Dr. Werner Dub . Hans-J??rgen
> Farrenkopf 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> > ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From pomchip at free.fr  Tue Sep  4 03:44:11 2007
From: pomchip at free.fr (=?ISO-8859-1?Q?S=E9bastien?=)
Date: Mon, 03 Sep 2007 21:44:11 -0400
Subject: [R] Different behavior of mtext
In-Reply-To: <Pine.LNX.4.64.0709031547590.9729@gannet.stats.ox.ac.uk>
References: <46DB331E.8030004@free.fr>
	<Pine.LNX.4.64.0709030726320.12798@gannet.stats.ox.ac.uk>
	<46DC14B4.2020902@free.fr>
	<Pine.LNX.4.64.0709031547590.9729@gannet.stats.ox.ac.uk>
Message-ID: <46DCB86B.4060206@free.fr>

Thanks for the information on gridBase, I could solve my problem using 
the 'baseViewports' function and by replacing mtext by grid.text (with 
coordinates adjustments).

Sebastien

Prof Brian Ripley a ?crit :
> On Mon, 3 Sep 2007, S?bastien wrote:
>
>> Ok, the problem is clear now. I did not get that 'user-coordinates' 
>> was refering to par("usr"), when I read the help of mtext. If I may 
>> ask you some additional questions:
>> - you mentioned a missing unit() call ; at which point should it be 
>> done in my code examples ?
>
> Before it is used.  The problem is that I believe more than one 
> package has a unit() function.
>
>> - could you give me some advices or helpful links about how to set up 
>> a grid viewport ? - and finally, probably a stupid question: is a 
>> gridview automatically set up when a plotting function is called ?
>
> If you want to mix grid and base graphics, you need package gridBase, 
> but really I would not advise a beginner to be using grid directly 
> (that is, not via lattice to ggplot*).
>
>
>> Sebastien
>>
>> PS: To answer to your final question, my goal is to center a block of 
>> legend text on the device but to align the text to the left of this 
>> block.
>>
>> Prof Brian Ripley a ?crit :
>>> On Sun, 2 Sep 2007, S?bastien wrote:
>>>
>>>> Dear R Users,
>>>>
>>>> I am quite surprised to see that mtext gives different results when it
>>>> is used with 'pairs' and with "plot'. In the two following codes, it
>>>> seems that the 'at' argument in mtext doesn't consider the same 
>>>> unit system.
>>>
>>> It is stated to be in 'user coordinates'.  Your code does not work 
>>> because unit() is missing.  If you mean the one from package grid, 
>>> "npc" is not user coordinates (and refers to a grid viewport which 
>>> you have not set up and coincidentally is the same as the initial 
>>> user coordinate system to which pairs() has reverted).
>>>
>>> Try par("usr") after your pairs() and plot() calls to see the 
>>> difference.
>>> Plotting a 2x2 array of plots _is_ different from plotting one, so 
>>> this should be as expected.
>>>
>>> Since centring is the default for 'adj', it is unclear what you are 
>>> trying to achieve here.
>>>
>>>> I would appreciate your comments on this issue.
>>>>
>>>> Sebastien
>>>>
>>>> ##### Pairs
>>>>
>>>> mydata<-data.frame(x=1:10,y=1:10)
>>>>
>>>> par(cex.main=1, cex.axis=1, cex.lab=1, lwd=1,
>>>>    mar=c(5 + 5,4,4,2)+0.1)
>>>>
>>>> pairs(mydata,oma=c(5 + 5,4,4,2))
>>>>
>>>> mylegend<-c("mylegend A","mylegend B","mylegend C","mylegend test")
>>>> mylegend.width = strwidth(mylegend[which.max(nchar(mylegend))], 
>>>> "figure")
>>>>
>>>> for (i in 1:4) {
>>>> mtext(text=mylegend[i],
>>>>        side = 1,
>>>>        line = 3+i,
>>>>        at = unit((1-mylegend.width)/2,"npc"),            # centers the
>>>> legend at the bottom
>>>>        adj=0,
>>>>        padj=0)}
>>>>
>>>> ##### plot
>>>>
>>>> mydata<-data.frame(x=1:10,y=1:10)
>>>>
>>>> par(cex.main=1, cex.axis=1, cex.lab=1, lwd=1,
>>>>    mar=c(5 + 5,4,4,2)+0.1)
>>>>
>>>> plot(mydata,oma=c(5 + 5,4,4,2))
>>>>
>>>> mylegend<-c("mylegend A","mylegend B","mylegend C","mylegend test")
>>>> mylegend.width = strwidth(mylegend[which.max(nchar(mylegend))], 
>>>> "figure")
>>>>
>>>> for (i in 1:4) {
>>>> mtext(text=mylegend[i],
>>>>        side = 1,
>>>>        line = 3+i,
>>>>        at = unit((1-mylegend.width)/2,"npc"),            # should
>>>> center the legend at the bottom but doesn't do it !
>>>>        adj=0,
>>>>        padj=0)}
>>>
>>
>


From jfox at mcmaster.ca  Tue Sep  4 04:21:45 2007
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 3 Sep 2007 22:21:45 -0400
Subject: [R] Row-Echelon Form
In-Reply-To: <20070903181652.GA28455@klutometis.wikitex.org>
Message-ID: <20070904022147.LATM8273.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Peter,

Some time ago, I posted a function RREF to r-help that computes the reduced
row-echelon form of a matrix. Just last week, Scott Hyde posted a revised
version of this function to r-help (see
https://stat.ethz.ch/pipermail/r-help/2007-September/139923.html). My
original function didn't work correctly in some cases, and in response to
Scott's message, I tried to post a newer version to r-help, but it doesn't
seem to have gotten through (perhaps because I attached the function in a
file). I append the function below, along with some other simple
linear-algebra functions.

I hope this helps,
 John

------------- snip -------------

# Last modified 9 July 2007 by J. Fox

GaussianElimination <- function(A, B, tol=sqrt(.Machine$double.eps), 
    verbose=FALSE, fractions=FALSE){
    # A: coefficient matrix
    # B: right-hand side vector or matrix
    # tol: tolerance for checking for 0 pivot
    # verbose: if TRUE, print intermediate steps
    # fractions: try to express nonintegers as rational numbers
    # If B is absent returns the reduced row-echelon form of A.
    # If B is present, reduces A to RREF carrying B along.
    if (fractions) {
        mass <- require(MASS)
        if (!mass) stop("fractions=TRUE needs MASS package")
        }
    if ((!is.matrix(A)) || (!is.numeric(A)))
        stop("argument must be a numeric matrix")
    n <- nrow(A)
    m <- ncol(A)
    if (!missing(B)){
        B <- as.matrix(B)
        if (!(nrow(B) == nrow(A)) || !is.numeric(B))
          stop("argument must be numeric and must match the number of row of
A")
        A <- cbind(A, B)
        }
    i <- j <- 1
    while (i <= n && j <= m){
        while (j <= m){
            currentColumn <- A[,j]
            currentColumn[1:n < i] <- 0
            # find maximum pivot in current column at or below current row
            which <- which.max(abs(currentColumn))
            pivot <- currentColumn[which]
            if (abs(pivot) <= tol) { # check for 0 pivot
                j <- j + 1
                next
                }     
            if (which > i) A[c(i, which),] <- A[c(which, i),]  # exchange
rows
            A[i,] <- A[i,]/pivot            # pivot
            row <- A[i,]
            A <- A - outer(A[,j], row)      # sweep
            A[i,] <- row                    # restore current row
            if (verbose) if (fractions) print(fractions(A))
                else print(round(A, round(abs(log(tol,10)))))
            j <- j + 1
            break
            }
        i <- i + 1
        }
     # 0 rows to bottom
    zeros <- which(apply(A[,1:m], 1, function(x) max(abs(x)) <= tol))
    if (length(zeros) > 0){
        zeroRows <- A[zeros,]
        A <- A[-zeros,]
        A <- rbind(A, zeroRows)
        }
    rownames(A) <- NULL
    if (fractions) fractions (A) else round(A, round(abs(log(tol, 10))))
    }

matrixInverse <- function(X, tol=sqrt(.Machine$double.eps), ...){
    # returns the inverse of nonsingular X
    if ((!is.matrix(X)) || (nrow(X) != ncol(X)) || (!is.numeric(X))) 
        stop("X must be a square numeric matrix")
    n <- nrow(X)
    X <- GaussianElimination(X, diag(n), tol=tol, ...) # append identity
matrix
        # check for 0 rows in the RREF of X:
    if (any(apply(abs(X[,1:n]) <= sqrt(.Machine$double.eps), 1, all)))
        stop ("X is numerically singular")
    X[,(n + 1):(2*n)]  # return inverse
    }

RREF <- function(X, ...) GaussianElimination(X, ...)
    # returns the reduced row-echelon form of X
    
Ginv <- function(A, tol=sqrt(.Machine$double.eps), verbose=FALSE, 
        fractions=FALSE){
    # return an arbitrary generalized inverse of the matrix A
    # A: a matrix
    # tol: tolerance for checking for 0 pivot
    # verbose: if TRUE, print intermediate steps
    # fractions: try to express nonintegers as rational numbers
    m <- nrow(A)
    n <- ncol(A)
    B <- GaussianElimination(A, diag(m), tol=tol, verbose=verbose, 
        fractions=fractions)
    L <- B[,-(1:n)]
    AR <- B[,1:n]
    C <- GaussianElimination(t(AR), diag(n), tol=tol, verbose=verbose, 
        fractions=fractions)
    R <- t(C[,-(1:m)])
    AC <- t(C[,1:m])
    ginv <- R %*% t(AC) %*% L
    if (fractions) fractions (ginv) else round(ginv, round(abs(log(tol,
10))))
    }
    
cholesky <- function(X, tol=sqrt(.Machine$double.eps)){
    # returns the Cholesky square root of the nonsingular, symmetric matrix
X
    # tol: tolerance for checking for 0 pivot
    # algorithm from Kennedy & Gentle (1980)
    if (!is.numeric(X)) stop("argument is not numeric")
    if (!is.matrix(X)) stop("argument is not a matrix")
    n <- nrow(X)
    if (ncol(X) != n) stop("matrix is not square")
    if (max(abs(X - t(X))) > tol) stop("matrix is not symmetric")
    D <- rep(0, n)
    L <- diag(n)
    i <- 2:n
    D[1] <- X[1, 1]
    if (abs(D[1]) < tol) stop("matrix is numerically singular")
    L[i, 1] <- X[i, 1]/D[1]
    for (j in 2:(n - 1)){
        k <- 1:(j - 1)
        D[j] <- X[j, j] - sum((L[j, k]^2) * D[k])
        if (abs(D[j]) < tol) stop("matrix is numerically singular")
        i <- (j + 1):n
        L[i, j] <- (X[i, j] -
                        colSums(L[j, k] * t(L[i, k, drop=FALSE]) *
D[k]))/D[j]
        }
    k <- 1:(n - 1)
    D[n] <- X[n, n] - sum((L[n, k]^2) * D[k])
    if (abs(D[n]) < tol) stop("matrix is numerically singular")
    L %*% diag(sqrt(D))
    }



--------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Peter Danenberg
> Sent: Monday, September 03, 2007 2:17 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Row-Echelon Form
> 
> I was looking for an R-package that would reduce matrices to 
> row-echelon form, but Google was not my friend; any leads?
> 
> If not, I wonder if the problem could be expressed in terms 
> of constraint satisfaction...
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mbordese at gmail.com  Tue Sep  4 04:24:34 2007
From: mbordese at gmail.com (Matias Bordese)
Date: Mon, 3 Sep 2007 23:24:34 -0300
Subject: [R] Package installation
In-Reply-To: <46CEA1AB.1000501@statistik.uni-dortmund.de>
References: <46CE85D5.8010605@yahoo.de>
	<46CEA1AB.1000501@statistik.uni-dortmund.de>
Message-ID: <a5ab98fc0709031924v4731a22r59198e16a4b6886c@mail.gmail.com>

We are working in a new release that would solve the problem
mentioned; in the current source tarball available it could be manage
as Uwe said, adding the line in the DESCRIPTION file:
ZipData: no

By the way, besides the RTools needed to compile any package in
Windows, you will need to install the libjpeg and libtiff libraries
and follow the instructions in the README file.

Sorry for the delayed answer. I hope you can use the package. In a few
weeks we think we are going to release an improved version, with more
functionalities. Any feedback will be welcome.

Best,
Mat?as Bordese.

On 8/24/07, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
>
>
> Antje wrote:
> > Hello,
> >
> > I'm running R with windows. Could anybody help me how to install the package
> > biOps (http://cran.mirroring.de/src/contrib/Descriptions/biOps.html) ?
> > I cannot find it at any mirror provided by the GUI; I just found it as "tar.gz"
> > which cannot be installed with the installation method...
> > Maybe, I simply do something wrong?
>
> The Windows binary is not available on CRAN, because it still fail its
> checks under Windows. I already asked the package maintainer (CCing
> again) to fix the package by simply adding one line:
>    ZipData: no
> to its DESCRIPTION file.
>
> Uwe Ligges
>
>
>
> > Thanks for any hint!
> >
> > Antje
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From issac.trotts at gmail.com  Tue Sep  4 05:48:00 2007
From: issac.trotts at gmail.com (Issac Trotts)
Date: Mon, 3 Sep 2007 20:48:00 -0700
Subject: [R] Efficient sampling from a discrete distribution in R
Message-ID: <a88ba3360709032048u4add4761ibe589ddc0f30f7b4@mail.gmail.com>

Hello r-help,

As far as I've seen, there is no function in R dedicated to sampling
from a discrete distribution with a specified mass function.  The
standard library doesn't come with anything called rdiscrete or rpmf,
and I can't find any such thing on the cheat sheet or in the
Probability Distributions chapter of _An Introduction to R_.  Googling
also didn't bring back anything.  So, here's my first attempt at a
solution.  I'm hoping someone here knows of a more efficient way.

# Sample from a discrete distribution with given probability mass function
rdiscrete = function(size, pmf) {
  stopifnot(length(pmf) > 1)
  cmf = cumsum(pmf)
  icmf = function(p) {
    min(which(p < cmf))
  }
  ps = runif(size)
  sapply(ps, icmf)
}

test.rdiscrete = function(N = 10000) {
  err.tol = 6.0 / sqrt(N)
  xs = rdiscrete(N, c(0.5, 0.5))
  err = abs(sum(xs == 1) / N - 0.5)
  stopifnot(err < err.tol)
  list(e = err, xs = xs)
}

Thanks,
Issac


From rory.winston at gmail.com  Tue Sep  4 06:49:07 2007
From: rory.winston at gmail.com (Rory Winston)
Date: Tue, 4 Sep 2007 05:49:07 +0100
Subject: [R] Derivative of a Function Expression
In-Reply-To: <971536df0709031649xf981138xee56c72841d87e12@mail.gmail.com>
References: <3f446aa30709031405o5c347ce2od28b15acb8a73978@mail.gmail.com>
	<971536df0709031458n68bfafe2y9f8ea13cedc5030c@mail.gmail.com>
	<971536df0709031509l77fd8a37lc9daab3e0633d3c9@mail.gmail.com>
	<200709032257.09996.albmont@centroin.com.br>
	<971536df0709031605g3b1a422dj7d90cf5cfc28b3b1@mail.gmail.com>
	<971536df0709031629l3f57d65apdb7c0847d7e77dcb@mail.gmail.com>
	<971536df0709031649xf981138xee56c72841d87e12@mail.gmail.com>
Message-ID: <3f446aa30709032149k641daa34me37bdae16166d671@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/fd073109/attachment.pl 

From ripley at stats.ox.ac.uk  Tue Sep  4 07:18:04 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 Sep 2007 06:18:04 +0100 (BST)
Subject: [R] Efficient sampling from a discrete distribution in R
In-Reply-To: <a88ba3360709032048u4add4761ibe589ddc0f30f7b4@mail.gmail.com>
References: <a88ba3360709032048u4add4761ibe589ddc0f30f7b4@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709040559470.25901@gannet.stats.ox.ac.uk>

On Mon, 3 Sep 2007, Issac Trotts wrote:

> Hello r-help,
>
> As far as I've seen, there is no function in R dedicated to sampling
> from a discrete distribution with a specified mass function.  The
> standard library doesn't come with anything called rdiscrete or rpmf,
> and I can't find any such thing on the cheat sheet or in the
> Probability Distributions chapter of _An Introduction to R_.  Googling
> also didn't bring back anything.  So, here's my first attempt at a
> solution.  I'm hoping someone here knows of a more efficient way.

It's called sample().

There are much more efficient algorithms than the one you used, and 
sample() sometimes uses one of them (Walker's alias method): see any good 
book on simulation (including my 'Stochastic Simulation, 1987).

> # Sample from a discrete distribution with given probability mass function
> rdiscrete = function(size, pmf) {
>  stopifnot(length(pmf) > 1)
>  cmf = cumsum(pmf)
>  icmf = function(p) {
>    min(which(p < cmf))
>  }
>  ps = runif(size)
>  sapply(ps, icmf)
> }
>
> test.rdiscrete = function(N = 10000) {
>  err.tol = 6.0 / sqrt(N)
>  xs = rdiscrete(N, c(0.5, 0.5))
>  err = abs(sum(xs == 1) / N - 0.5)
>  stopifnot(err < err.tol)
>  list(e = err, xs = xs)
> }
>
> Thanks,
> Issac
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From issac.trotts at gmail.com  Tue Sep  4 07:24:39 2007
From: issac.trotts at gmail.com (Issac Trotts)
Date: Mon, 3 Sep 2007 22:24:39 -0700
Subject: [R] Efficient sampling from a discrete distribution in R
In-Reply-To: <Pine.LNX.4.64.0709040559470.25901@gannet.stats.ox.ac.uk>
References: <a88ba3360709032048u4add4761ibe589ddc0f30f7b4@mail.gmail.com>
	<Pine.LNX.4.64.0709040559470.25901@gannet.stats.ox.ac.uk>
Message-ID: <a88ba3360709032224k43f402d8r7d9603372be5903a@mail.gmail.com>

Thanks to you and Burwin for helping.  My simulation seems faster now
(btw, is there some easy way to time things in R?) but not as fast as
I was hoping.  Here's the top level function.  Any ideas on how to
make it faster?

# Sample from a Chinese Restaurant Process
#
# size: number of samples to draw
# a: alpha.  If large then there will tend to be more categories.
#
rchinese = function(size, a) {
  stopifnot(length(a) == 1)
  samples = c()
  new.category = 1
  for (i in 1:size) {
    denom = i - 1 + a
    p.new = a / denom
    ci =
      if (runif(1) < p.new) {
        new.category = new.category + 1;
        new.category - 1
      }
      else {
        counts = unname(table(factor(samples, levels = 1:(i-1))))
        pmf = counts / sum(counts)
        rdiscrete(1, pmf)
      }
    samples = c(samples, ci)
  }
  samples
}



On 9/3/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Mon, 3 Sep 2007, Issac Trotts wrote:
>
> > Hello r-help,
> >
> > As far as I've seen, there is no function in R dedicated to sampling
> > from a discrete distribution with a specified mass function.  The
> > standard library doesn't come with anything called rdiscrete or rpmf,
> > and I can't find any such thing on the cheat sheet or in the
> > Probability Distributions chapter of _An Introduction to R_.  Googling
> > also didn't bring back anything.  So, here's my first attempt at a
> > solution.  I'm hoping someone here knows of a more efficient way.
>
> It's called sample().
>
> There are much more efficient algorithms than the one you used, and
> sample() sometimes uses one of them (Walker's alias method): see any good
> book on simulation (including my 'Stochastic Simulation, 1987).
>
> > # Sample from a discrete distribution with given probability mass function
> > rdiscrete = function(size, pmf) {
> >  stopifnot(length(pmf) > 1)
> >  cmf = cumsum(pmf)
> >  icmf = function(p) {
> >    min(which(p < cmf))
> >  }
> >  ps = runif(size)
> >  sapply(ps, icmf)
> > }
> >
> > test.rdiscrete = function(N = 10000) {
> >  err.tol = 6.0 / sqrt(N)
> >  xs = rdiscrete(N, c(0.5, 0.5))
> >  err = abs(sum(xs == 1) / N - 0.5)
> >  stopifnot(err < err.tol)
> >  list(e = err, xs = xs)
> > }
> >
> > Thanks,
> > Issac
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From thefishfinger at ihug.com.au  Tue Sep  4 07:43:06 2007
From: thefishfinger at ihug.com.au (Sam Ferguson)
Date: Tue, 4 Sep 2007 15:43:06 +1000
Subject: [R] Embedding Audio Files in Interactive Graphs
In-Reply-To: <JNS7XP$5CF16C227C4387091711DE17B6E0E27C@libero.it>
References: <JNS7XP$5CF16C227C4387091711DE17B6E0E27C@libero.it>
Message-ID: <D9A5BE6F-47BB-48B8-A49D-EEE608A7F4A2@ihug.com.au>

Thanks for your reply Bruno.

No - as I said, I know how to do that - the movie15 and the  
multimedia package are basically the same, and it is relatively  
straightforward to get an audio file into a pdf with them. However,  
real interactivity is not easily achieved in latex IMO (as it's not  
its purpose). At least I'm hoping for a bit more flexibility.

R seems like a better place to do interactivity, and with the field  
of information visualisation pointing out that interactivity is a  
very useful element for investigation of data it seems that clicking  
around graphical displays may become more and more popular in time.  
In my field I'm interested in audio data, and so simple interactive  
visual and auditory displays would be great. A (very useful) start  
would be 5 separate waveform plots that would play their appropriate  
sounds when clicked. More complex figures could plot in a 2d space  
and allow selection of data points or ranges perhaps.

I love R for graphics and for Sweave though, and would like to use it  
if possible - ideally it would be to produce a figure that included  
the appropriate audiofiles and interactive scripts, which could then  
be incorporated into a latex document \includegraphics. However, from  
the deafening silence on this list it seems like I may be attempting  
to push a square block through a round hole unfortunately. Seems I am  
back to Matlab and handle graphics - but it won't do this properly  
either.

Cheers
Sam


On 03/09/2007, at 5:39 PM, Bruno C.. wrote:

> Are you asking on how to include an  audio file into a pdf?
> This is already feasible via latex and the movie 15 package ;)
>
> Ciao
>
>> Hi R-ers,
>>
>> I'm wondering if anyone has investigated a method for embedding audio
>> files in R graphs (pdf format), and allowing their playback to be
>> triggered interactively (by clicking on a graph element for  
>> instance).
>>
>> I know how to do this in latex pdfs with the multimedia package, but
>> it seems that R would provide a more appropriate platform for many
>> reasons.
>>
>> Thanks for any help you can provide.
>> Sam Ferguson
>> Faculty of Architecture, Design and Planning
>> The University of Sydney
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> ------------------------------------------------------
> Leggi GRATIS le tue mail con il telefonino i-mode? di Wind
> http://i-mode.wind.it/
>

--
Sam Ferguson
Faculty of Architecture
The University of Sydney
sferguson at arch.usyd.edu.au
+61 2 93515910
0410 719535


From mauricio.malfert at gmail.com  Tue Sep  4 09:22:31 2007
From: mauricio.malfert at gmail.com (Mauricio Malfert)
Date: Tue, 4 Sep 2007 09:22:31 +0200
Subject: [R] Trying to simulate
Message-ID: <12472d0d0709040022o616bd602kf79e2850ebb2ffe@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/aa0ba6ce/attachment.pl 

From issac.trotts at gmail.com  Tue Sep  4 09:40:47 2007
From: issac.trotts at gmail.com (Issac Trotts)
Date: Tue, 4 Sep 2007 00:40:47 -0700
Subject: [R] Efficient sampling from a discrete distribution in R
In-Reply-To: <Pine.LNX.4.64.0709040626470.26430@gannet.stats.ox.ac.uk>
References: <a88ba3360709032048u4add4761ibe589ddc0f30f7b4@mail.gmail.com>
	<Pine.LNX.4.64.0709040559470.25901@gannet.stats.ox.ac.uk>
	<a88ba3360709032224k43f402d8r7d9603372be5903a@mail.gmail.com>
	<Pine.LNX.4.64.0709040626470.26430@gannet.stats.ox.ac.uk>
Message-ID: <a88ba3360709040040u1788212ey238ad39f8f8e10f2@mail.gmail.com>

On 9/3/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> Yes, vectorize, and don't grow vectors. See 'S Programming' (details in
> the R FAQ).

It's easy to avoid growing the samples vector but it doesn't seem to
make much difference.  Vectorizing would be probably help, but in this
algorithm each step depends on the one before it.  Do you know of an
alternative to the Chinese restaurant process that is vectorizable?

> We've no idea about you (the R posting guide does ask for a signature
> block), but if this is homework some people are going to be annoyed.

No, it's for my job at Google, so maybe I should use my work email
address to avoid confusion.  Sorry if the questions are so basic that
they sound like homework, but you and others on the list know things
that aren't easy to find in the documentation.

-- 
Issac Trotts
Web Operations Chair
Silicon Valley Web Builder
http://svwebbuilder.com


From friendmiao at hotmail.com  Tue Sep  4 09:53:41 2007
From: friendmiao at hotmail.com (=?gb2312?B?zqzEyCDn0Q==?=)
Date: Tue, 4 Sep 2007 07:53:41 +0000
Subject: [R] Help: how can i build a constrained non-linear model?
Message-ID: <BAY117-W13BF95F9D8914B5CDAB3ADD7CA0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/70afeddb/attachment.pl 

From Bernhard_Pfaff at fra.invesco.com  Tue Sep  4 09:53:58 2007
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Tue, 4 Sep 2007 08:53:58 +0100
Subject: [R] Announcement: CRAN packages 'urca' and 'vars' on R-Forge
Message-ID: <B89F0CE41D45644A97CCC93DF548C1C30ABF07ED@GBHENXMB02.corp.amvescap.net>

Dear useR,

the CRAN packages 'urca' and 'vars' are now hosted on R-Forge as
projects 'AICTS I' and 'AICTS II', respectively. The packages' summary
page can be directly accessed via:

AICTS I:
http://r-forge.r-project.org/projects/urca/

AICTS II:
http://r-forge.r-project.org/projects/vars/

All R-Forge features for both projects have been enabled. For more
information about R-Forge, visit: http://r-forge.r-project.org/


Best,
Bernhard
*****************************************************************
Confidentiality Note: The information contained in this mess...{{dropped}}


From r.hankin at noc.soton.ac.uk  Tue Sep  4 10:00:34 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Tue, 4 Sep 2007 09:00:34 +0100
Subject: [R] Efficient sampling from a discrete distribution in R
In-Reply-To: <a88ba3360709040040u1788212ey238ad39f8f8e10f2@mail.gmail.com>
References: <a88ba3360709032048u4add4761ibe589ddc0f30f7b4@mail.gmail.com>
	<Pine.LNX.4.64.0709040559470.25901@gannet.stats.ox.ac.uk>
	<a88ba3360709032224k43f402d8r7d9603372be5903a@mail.gmail.com>
	<Pine.LNX.4.64.0709040626470.26430@gannet.stats.ox.ac.uk>
	<a88ba3360709040040u1788212ey238ad39f8f8e10f2@mail.gmail.com>
Message-ID: <2984AE16-8D59-485A-940A-A26BC3A8380B@noc.soton.ac.uk>


On 4 Sep 2007, at 08:40, Issac Trotts wrote:

> On 9/3/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>
>> Yes, vectorize, and don't grow vectors. See 'S  
>> Programming' (details in
>> the R FAQ).
>
> It's easy to avoid growing the samples vector but it doesn't seem to
> make much difference.  Vectorizing would be probably help, but in this
> algorithm each step depends on the one before it.  Do you know of an
> alternative to the Chinese restaurant process that is vectorizable?
>


The Chinese restaurant process is simulated in the untb package,
in what I believe is a reasonably efficient manner.

[I find to my horror that "help.search("Chinese restaurant") returns
empty-handed.  I will add a suitable \concept{} entry to untb.Rd]

Best wishes


Robin



>> We've no idea about you (the R posting guide does ask for a signature
>> block), but if this is homework some people are going to be annoyed.
>
> No, it's for my job at Google, so maybe I should use my work email
> address to avoid confusion.  Sorry if the questions are so basic that
> they sound like homework, but you and others on the list know things
> that aren't easy to find in the documentation.
>
> -- 
> Issac Trotts
> Web Operations Chair
> Silicon Valley Web Builder
> http://svwebbuilder.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From Barbara.Diane-Spillmann at agrar.uni-giessen.de  Tue Sep  4 10:07:02 2007
From: Barbara.Diane-Spillmann at agrar.uni-giessen.de (Barbara Diane-Spillmann)
Date: Tue, 04 Sep 2007 10:07:02 +0200
Subject: [R] kendalls tau c
Message-ID: <46DD1226.4090808@agrar.uni-giessen.de>

dear all,

does anybody know if cor.test with method="kendall" calculates kendalls 
tau a b or c? I need to get p values for kendalls tau c...

thank you very much for any kind of hint.

Barbara

-- 
Msc Barbara Spillmann

Professur f?r Projekt- und Regionalplanung
Senckenbergstr. 3
35390 Gie?en
Telefon: 0641 9937317
Telefax: 0641 9937319

Barbara.Diane-Spillmann at agrar.uni-giessen.de 
<mailto:Barbara.Diane-Spillmann at agrar.uni-giessen.de>


From bennati at gmail.com  Tue Sep  4 10:52:30 2007
From: bennati at gmail.com (Giulia Bennati)
Date: Tue, 4 Sep 2007 10:52:30 +0200
Subject: [R] Table and ftable
Message-ID: <305034a40709040152m25fe66d8q23de016cbce5cfb4@mail.gmail.com>

Dear listmembers,
I have a little question: I have my data organized as follow

sic  level  area
a    211    2.4
b    311    2.3
b    322    0.2
b    322    0.5
c    100    3.0
c    100    1.5
c    242    1.5
d    222    0.2

where levels and sics are factors. I'm trying to obtain a matrix like this:

        level
         211    311    322   100    242     222
sic
a        2.4      0       0       0       0        0
b         0       2.3    0.7     0       0        0
c         0        0      0       4.5     1.5     0
d         0        0      0        0       0       0.2

I tryed with table function as
table(sic,level) but i obteined only a contingency table.
Have you any suggestions?
Thank you very much,
Giulia


From mothsailor at googlemail.com  Tue Sep  4 11:17:50 2007
From: mothsailor at googlemail.com (David Barron)
Date: Tue, 4 Sep 2007 10:17:50 +0100
Subject: [R] Table and ftable
In-Reply-To: <305034a40709040152m25fe66d8q23de016cbce5cfb4@mail.gmail.com>
References: <305034a40709040152m25fe66d8q23de016cbce5cfb4@mail.gmail.com>
Message-ID: <815b70590709040217h4649fa2dlac3a3b3ef50cf95a@mail.gmail.com>

There might be simpler ways, but you can certainly do this with the
reshape package, like this:

library(reshape)
dta <- read.table("clipboard",header=TRUE)

  sic level area
1   a   211  2.4
2   b   311  2.3
3   b   322  0.2
4   b   322  0.5
5   c   100  3.0
6   c   100  1.5
7   c   242  1.5
8   d   222  0.2
>

mlt.dta <- melt(dta)
cst.dta <- cast(mlt.dta,sic~level,sum)

  sic 100 211 222 242 311 322
1   a  NA 2.4  NA  NA  NA  NA
2   b  NA  NA  NA  NA 2.3 0.7
3   c 4.5  NA  NA 1.5  NA  NA
4   d  NA  NA 0.2  NA  NA  NA

Then just replace the NAs with 0s.

HTH.

David Barron
On 9/4/07, Giulia Bennati <bennati at gmail.com> wrote:
> Dear listmembers,
> I have a little question: I have my data organized as follow
>
> sic  level  area
> a    211    2.4
> b    311    2.3
> b    322    0.2
> b    322    0.5
> c    100    3.0
> c    100    1.5
> c    242    1.5
> d    222    0.2
>
> where levels and sics are factors. I'm trying to obtain a matrix like this:
>
>         level
>          211    311    322   100    242     222
> sic
> a        2.4      0       0       0       0        0
> b         0       2.3    0.7     0       0        0
> c         0        0      0       4.5     1.5     0
> d         0        0      0        0       0       0.2
>
> I tryed with table function as
> table(sic,level) but i obteined only a contingency table.
> Have you any suggestions?
> Thank you very much,
> Giulia
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
=================================
David Barron
Said Business School
University of Oxford
Park End Street
Oxford OX1 1HP


From P.Dalgaard at biostat.ku.dk  Tue Sep  4 11:41:53 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 04 Sep 2007 11:41:53 +0200
Subject: [R] Table and ftable
In-Reply-To: <815b70590709040217h4649fa2dlac3a3b3ef50cf95a@mail.gmail.com>
References: <305034a40709040152m25fe66d8q23de016cbce5cfb4@mail.gmail.com>
	<815b70590709040217h4649fa2dlac3a3b3ef50cf95a@mail.gmail.com>
Message-ID: <46DD2861.70507@biostat.ku.dk>

David Barron wrote:
> There might be simpler ways, but you can certainly do this with the
> reshape package, like this:
>
> library(reshape)
> dta <- read.table("clipboard",header=TRUE)
>
>   sic level area
> 1   a   211  2.4
> 2   b   311  2.3
> 3   b   322  0.2
> 4   b   322  0.5
> 5   c   100  3.0
> 6   c   100  1.5
> 7   c   242  1.5
> 8   d   222  0.2
>   
>
> mlt.dta <- melt(dta)
> cst.dta <- cast(mlt.dta,sic~level,sum)
>
>   sic 100 211 222 242 311 322
> 1   a  NA 2.4  NA  NA  NA  NA
> 2   b  NA  NA  NA  NA 2.3 0.7
> 3   c 4.5  NA  NA 1.5  NA  NA
> 4   d  NA  NA 0.2  NA  NA  NA
>
> Then just replace the NAs with 0s.
>
>   
tapply() will do this too:

> with(d,tapply(area,list(sic,level), sum))
  100 211 222 242 311 322
a  NA 2.4  NA  NA  NA  NA
b  NA  NA  NA  NA 2.3 0.7
c 4.5  NA  NA 1.5  NA  NA
d  NA  NA 0.2  NA  NA  NA

This has the same awkwardness of giving NA for empty cells, and there is
no easy way to circumvent it since the FUN of tapply is simply not
called for such  cells.
Replacing NA by zero is a bit dangerous (albeit not in the present case)
since you can get an NA cell for more than one reason. A more careful
approach is like this:

> with(d,{t1 <- tapply(area,list(sic,level), sum)
          t2 <- table(sic,level)
          t1[t2==0] <- 0
          t1} )
  100 211 222 242 311 322
a 0.0 2.4 0.0 0.0 0.0 0.0
b 0.0 0.0 0.0 0.0 2.3 0.7
c 4.5 0.0 0.0 1.5 0.0 0.0
d 0.0 0.0 0.2 0.0 0.0 0.0
>       

> HTH.
>
> David Barron
> On 9/4/07, Giulia Bennati <bennati at gmail.com> wrote:
>   
>> Dear listmembers,
>> I have a little question: I have my data organized as follow
>>
>> sic  level  area
>> a    211    2.4
>> b    311    2.3
>> b    322    0.2
>> b    322    0.5
>> c    100    3.0
>> c    100    1.5
>> c    242    1.5
>> d    222    0.2
>>
>> where levels and sics are factors. I'm trying to obtain a matrix like this:
>>
>>         level
>>          211    311    322   100    242     222
>> sic
>> a        2.4      0       0       0       0        0
>> b         0       2.3    0.7     0       0        0
>> c         0        0      0       4.5     1.5     0
>> d         0        0      0        0       0       0.2
>>
>> I tryed with table function as
>> table(sic,level) but i obteined only a contingency table.
>> Have you any suggestions?
>> Thank you very much,
>> Giulia
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>     
>
>
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From christoph.heibl at gmx.net  Tue Sep  4 11:53:43 2007
From: christoph.heibl at gmx.net (Christoph Heibl)
Date: Tue, 4 Sep 2007 11:53:43 +0200
Subject: [R] integers
Message-ID: <E294CAE3-1263-4297-890C-BBE7E07E2FAF@gmx.net>

Hi list,

The function is.integer tests if an object is of type integer:

see e.g.:

is.integer(12)	# FALSE
is.real(12)	# TRUE
mode(12)		# "numeric"

But how can I test if a number is actually an integer? R seek is  
difficult to search in this case because it mainly yields entries  
about the integer()-function family.

Thanks for any hint!
Christoph Heibl


From gustaf.rydevik at gmail.com  Tue Sep  4 12:08:14 2007
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Tue, 4 Sep 2007 12:08:14 +0200
Subject: [R] integers
In-Reply-To: <45f568c70709040307m63b7abbdg21ebca2eaf043532@mail.gmail.com>
References: <E294CAE3-1263-4297-890C-BBE7E07E2FAF@gmx.net>
	<45f568c70709040307m63b7abbdg21ebca2eaf043532@mail.gmail.com>
Message-ID: <45f568c70709040308p139bf7f8y6bf16bb5a7e8bf47@mail.gmail.com>

On 9/4/07, Christoph Heibl <christoph.heibl at gmx.net> wrote:
> Hi list,
>
> The function is.integer tests if an object is of type integer:
>
> see e.g.:
>
> is.integer(12)  # FALSE
> is.real(12)     # TRUE
> mode(12)                # "numeric"
>
> But how can I test if a number is actually an integer? R seek is
> difficult to search in this case because it mainly yields entries
> about the integer()-function family.
>
> Thanks for any hint!
> Christoph Heibl
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

How about


x<- c(12,12.66)
trunc(x)==x

?
--
Gustaf Rydevik, M.Sci.
tel: +46(0)703 051 451
address:Essingetorget 40,112 66 Stockholm, SE
skype:gustaf_rydevik


From Ted.Harding at manchester.ac.uk  Tue Sep  4 12:11:49 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Tue, 04 Sep 2007 11:11:49 +0100 (BST)
Subject: [R] integers
In-Reply-To: <E294CAE3-1263-4297-890C-BBE7E07E2FAF@gmx.net>
Message-ID: <XFMail.070904111149.Ted.Harding@manchester.ac.uk>

On 04-Sep-07 09:53:43, Christoph Heibl wrote:
> Hi list,
> 
> The function is.integer tests if an object is of type integer:
> 
> see e.g.:
> 
> is.integer(12)        # FALSE
> is.real(12)   # TRUE
> mode(12)              # "numeric"
> 
> But how can I test if a number is actually an integer? R seek is  
> difficult to search in this case because it mainly yields entries  
> about the integer()-function family.
> 
> Thanks for any hint!
> Christoph Heibl

In infer you want to test whether the real x has an integer value.

((x-floor(x))==0)

would do it (covers negative integers as well), though there may
well be a smarter way.

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 04-Sep-07                                       Time: 11:11:46
------------------------------ XFMail ------------------------------


From maechler at stat.math.ethz.ch  Tue Sep  4 12:33:15 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 4 Sep 2007 12:33:15 +0200
Subject: [R] integers
In-Reply-To: <E294CAE3-1263-4297-890C-BBE7E07E2FAF@gmx.net>
References: <E294CAE3-1263-4297-890C-BBE7E07E2FAF@gmx.net>
Message-ID: <18141.13419.144205.792803@stat.math.ethz.ch>

>>>>> "CH" == Christoph Heibl <christoph.heibl at gmx.net>
>>>>>     on Tue, 4 Sep 2007 11:53:43 +0200 writes:

    CH> Hi list,
    CH> The function is.integer tests if an object is of type integer:

    CH> see e.g.:

    CH> is.integer(12)	# FALSE
    CH> is.real(12)	# TRUE
    CH> mode(12)		# "numeric"

    CH> But how can I test if a number is actually an integer? 

something like        	      round(x) == x
is often good enough, maybe   x %% 1 == 0
seems a bit more efficient.

Note that both return  NA  whenever  x[] is NA so may not directly be
appropriate for your use case.


    CH> R seek is  difficult to search in this case because it mainly yields entries  
    CH> about the integer()-function family.

"R seek" ???

Do you mean the R function  RSiteSearch() which goes to
'http://search.r-project.org/' ?

Well,  calling  
  RSiteSearch("integer number")

gives almost 3000 hits, *but* number 10 is exactly relevant to
your question...

    CH> Thanks for any hint!
    CH> Christoph Heibl


From yogesh.mpi at googlemail.com  Tue Sep  4 12:34:36 2007
From: yogesh.mpi at googlemail.com (Yogesh Tiwari)
Date: Tue, 4 Sep 2007 11:34:36 +0100
Subject: [R] how to do interpolation
Message-ID: <71cc5ca20709040334h4f0f4d10pb321452578ce4e22@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/f077eb54/attachment.pl 

From jared.oconnell at csiro.au  Tue Sep  4 12:47:01 2007
From: jared.oconnell at csiro.au (Jared O'Connell)
Date: Tue, 4 Sep 2007 18:47:01 +0800
Subject: [R] how to do interpolation
In-Reply-To: <71cc5ca20709040334h4f0f4d10pb321452578ce4e22@mail.gmail.com>
References: <71cc5ca20709040334h4f0f4d10pb321452578ce4e22@mail.gmail.com>
Message-ID: <8c464e8f0709040347nfb6973di969944834870f3ac@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/a94901c5/attachment.pl 

From jim at bitwrit.com.au  Tue Sep  4 12:54:44 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 04 Sep 2007 20:54:44 +1000
Subject: [R] how to do interpolation
In-Reply-To: <71cc5ca20709040334h4f0f4d10pb321452578ce4e22@mail.gmail.com>
References: <71cc5ca20709040334h4f0f4d10pb321452578ce4e22@mail.gmail.com>
Message-ID: <46DD3974.5070508@bitwrit.com.au>

Yogesh Tiwari wrote:
> Hello R Users,
> 
> How to make a variable equidistance with time i.e. how to interpolate a
> variable if it is not sampled at equal time interval.
> 
Hi Yogesh,
Don't know whether this will suit your purpose. I wrote it to enable 
color-coded plotting of highly variable data. If you pass your intervals 
as "yvec", it will linearly interpolate values of "xvec" so that the 
maximum difference between "yvec"s is "maxjump". If the "yvec"s are not
multiples of "maxjump", you will get some smaller intervals.

linterp<-function(xvec,yvec,interp=NA,maxjump=1) {
  if(is.list(xvec) && missing(yvec)) {
   yvec<-xvec$y
   xvec<-xvec$x
  }
  if(!missing(xvec) && !missing(yvec)) {
   newlength<-oldlength<-length(xvec)
   oldrows<-1:oldlength
   for(l in 2:oldlength) {
    # use the y values as a default
    if(is.na(interp[1])) ninserts<-ceiling(abs(yvec[l]-yvec[l-1])/maxjump)
    # assume interp is already a function of the successive x/y pairs
    else ninserts<-ceiling(abs(interp[l-1])/maxjump)
    oldrows[l]<-oldrows[l-1]+ninserts
    newlength<-newlength+ninserts-1
   }
   xy<-list(x=rep(NA,newlength),y=rep(NA,newlength))
   xy$x[oldrows]<-xvec
   # if xvec and yvec are not the same length, give up
   if(oldlength == length(yvec)) {
    xy$y[oldrows]<-yvec
    for(index in 1:(oldlength-1)) {
     ninterp<-oldrows[index+1]-oldrows[index]
     if(ninterp > 1) {
      xinc<-(xvec[index+1]-xvec[index])/ninterp
      yinc<-(yvec[index+1]-yvec[index])/ninterp
      for(istep in 1:(ninterp-1)) {
       xy$x[oldrows[index]+istep]<-xy$x[oldrows[index]+istep-1]+xinc
       xy$y[oldrows[index]+istep]<-xy$y[oldrows[index]+istep-1]+yinc
      }
     }
    }
    return(xy)
   }
   else cat("xvec and yvec must have the same length!\n")
  }
  cat("Usage: linterp(xvec,yvec,interp=NA,maxjump=1)\n")
}


Jim


From hamstersquats at web.de  Tue Sep  4 13:26:19 2007
From: hamstersquats at web.de (Thomas Kaliwe)
Date: Tue, 04 Sep 2007 13:26:19 +0200
Subject: [R] Rserve: Accessing images
In-Reply-To: <12402656.post@talk.nabble.com>
References: <46D59EB5.7040709@web.de> <12402656.post@talk.nabble.com>
Message-ID: <46DD40DB.9000008@web.de>

Thank you

Bartjoosen schrieb:
> Take a look at the EBImage package at bioconductor:
> http://bioconductor.org/packages/2.0/bioc/html/EBImage.html
>
>
> Bart
>
>
> mimo-2 wrote:
>   
>> Hi,
>>
>> Are there more sophisticated  means to access R-images via Rserve than:
>>
>> Rconnection c=new Rconnection("127.0.0.1");
>> REXP xp=c.eval("try(png(\"test.png\"))")
>> c.voidEval("plot(1:10)");
>> c.voidEval("dev.off()");
>> is = c.openFile("test.png");
>> ...
>>
>> maybe something with javaGD?
>>
>> Thanks in advance
>>
>> Thomas
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>     
>
>


From jim at bitwrit.com.au  Tue Sep  4 13:38:17 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 04 Sep 2007 21:38:17 +1000
Subject: [R] Incomplete rank functions
Message-ID: <46DD43A9.7040103@bitwrit.com.au>

Hi folks,
Thanks to my esteemed colleagues, I have been grappling with the 
analysis of incomplete ranks. These result from questions like:

Number the three most important things from the following list in order 
from 1 to 3.

OR

Where some or all respondents or observers have not assigned ranks to 
some items.

In doing so, I have programmed a few functions to impute values where 
all ranks have not been allocated. These are all based upon substituting 
the mean of all unallocated ranks for missing values for each set (row) 
of ranks. Ties can be handled and optionally expanded to cover the 
values that would have resulted if the ties had not occurred. This 
satisfies the assumption that all sets of ranks sum to the same value, 
and infers that the unranked items were not distinguished by the ranker.

I searched Jon Baron's index with "incomplete ranks" and found nothing 
like this. If there is a package maintainer out there who is interested 
in using these functions, I would be happy to donate them.

Jim


From dataanalytics at earthlink.net  Tue Sep  4 13:56:35 2007
From: dataanalytics at earthlink.net (Walter Paczkowski)
Date: Tue, 4 Sep 2007 07:56:35 -0400 (GMT-04:00)
Subject: [R] Executing a DOS proram from R
Message-ID: <17185469.1188906995156.JavaMail.root@elwamui-rustique.atl.sa.earthlink.net>

Good morning,

I wrote a function to generate tables using LaTex.  The function creates a .tex file with all the layouts I want.  I would now like to call pdflatex.exe from inside this same function.  Does anyone know an R command to do this?  And also, what is the form of the pdflatex command to compile a .tex file?  I always use WinEdt so I never actually call pdflatex.exe directly.  Is the call just:

            pdflatex filename.tex

or is there something else I need to know to create a pdf file using LaTex?

Thanks,

Walt Paczkowski


From ccleland at optonline.net  Tue Sep  4 14:16:08 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Tue, 04 Sep 2007 08:16:08 -0400
Subject: [R] Executing a DOS proram from R
In-Reply-To: <17185469.1188906995156.JavaMail.root@elwamui-rustique.atl.sa.earthlink.net>
References: <17185469.1188906995156.JavaMail.root@elwamui-rustique.atl.sa.earthlink.net>
Message-ID: <46DD4C88.10605@optonline.net>

Walter Paczkowski wrote:
> Good morning,
> 
> I wrote a function to generate tables using LaTex.  The function creates a .tex file with all the layouts I want.  I would now like to call pdflatex.exe from inside this same function.  Does anyone know an R command to do this?  And also, what is the form of the pdflatex command to compile a .tex file?  I always use WinEdt so I never actually call pdflatex.exe directly.  Is the call just:
> 
>             pdflatex filename.tex
> 
> or is there something else I need to know to create a pdf file using LaTex?
> 
> Thanks,
> 
> Walt Paczkowski

  The following works for me and puts the resulting PDF into the R
current working directory:

system("pdflatex c:/myfolder/filename.tex")

?system

> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From gyadav at ccilindia.co.in  Tue Sep  4 14:28:34 2007
From: gyadav at ccilindia.co.in (gyadav at ccilindia.co.in)
Date: Tue, 4 Sep 2007 17:58:34 +0530
Subject: [R] how to do interpolation
In-Reply-To: <71cc5ca20709040334h4f0f4d10pb321452578ce4e22@mail.gmail.com>
Message-ID: <OF296EB8D4.9992BB0E-ON6525734C.00447C8D-6525734C.00448F1F@ccilindia.co.in>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/a32e38ea/attachment.pl 

From muenchen at utk.edu  Tue Sep  4 14:35:34 2007
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Tue, 4 Sep 2007 08:35:34 -0400
Subject: [R] NAs in indices
In-Reply-To: <Pine.LNX.4.64.0709021125030.26367@tajo.ucsd.edu>
References: <347152339B716A4D893C9A2988EA87C85E044D@KFSVS2.utk.tennessee.edu>
	<Pine.LNX.4.64.0709021125030.26367@tajo.ucsd.edu>
Message-ID: <347152339B716A4D893C9A2988EA87C85E055D@KFSVS2.utk.tennessee.edu>

Thanks to both Charles and Jim for such helpful info. 

The help file ?"[.data.frame" is just great. Too bad it is so hard to
find!

I had used na.strings on read.table but had gotten it in my head that it
was for numeric missing value codes. But of course, "strings is
strings"! That took care of periods everywhere & I was able to use my
original approach to get rid of some 99's and 999's that applied only to
certain columns (na.strings would zap them for all columns).

Jim's suggestion to add "which" makes perfect sense. I really don't like
the idea of referencing x[NA] even though x[c(T,T,F,F,NA,F)] might make
it obvious which were wanted. I'm surprised I didn't get caught by that
long ago.

Cheers,
Bob

 
> -----Original Message-----
> From: Charles C. Berry [mailto:cberry at tajo.ucsd.edu]
> Sent: Sunday, September 02, 2007 2:33 PM
> To: Muenchen, Robert A (Bob)
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] NAs in indices
> 
> On Sun, 2 Sep 2007, Muenchen, Robert A (Bob) wrote:
> 
> > Hi All,
> >
> > I'm fiddling with an program to read a text file containing periods
> that
> > SAS uses for missing values. I know that if I had the original SAS
> data
> > set instead of a text file, R would handle this conversion for me.
> >
> > Data frames do not allow missing values in their indices but vectors
> do.
> > Why is that? A search of the error message points out the problem
and
> > solution but not why they differ. A simplified program that
> demonstrates
> > the issue is below.
> >
> > Thanks,
> > Bob
> >
> > # Here's a data frame that has both periods and NAs.
> > # I want sex to remain character for now.
> >
> > sex=c("m","f",".",NA)
> > x=c(1,2,3,NA)
> > myDF <- data.frame(sex,x,stringsAsFactors=F)
> > rm(sex,x)
> > myDF
> >
> > # Substituting NA into data frame does not work
> > # due to NAs in the indices. The error message is:
> > # missing values are not allowed in subscripted assignments of data
> > frames
> >
> > myDF[ myDF$sex==".", "sex" ] <- NA
> > myDF
> >
> > # This works because myDF$sex is a vector and vectors allow NAs in
> > indexes.
> > # Why don't data frames allow this?
> >
> > myDF$sex[ myDF$sex=="." ] <- NA
> > myDF
> 
> 
> R version 2.5.1  'allows' it.
> 
> 
> > df <- as.data.frame(diag(3)[,-1])
> > df[ df[,1]==1 ] <- NA
> > df
> 
> but the result may not be what you were expecting. See
> 
>  	 ?"[.data.frame"
> 
> (esp. Details) for more info on why it does not 'work' as you
expected.
> 
> 
> Also, since you mention a 'text file' I suggest you look at
> 
>  	 ?read.table
> 
> or
> 
>  	?scan
> 
> where you will see that
> 
>  	dots.are.NA <- read.table("my.file", na.strings = '.' )
> 
> may help you.
> 
> Chuck
> 
> >
> > =========================================================
> > Bob Muenchen (pronounced Min'-chen), Manager
> > Statistical Consulting Center
> > U of TN Office of Information Technology
> > 200 Stokely Management Center, Knoxville, TN 37996-0520
> > Voice: (865) 974-5230
> > FAX: (865) 974-4810
> > Email: muenchen at utk.edu
> > Web: http://oit.utk.edu/scc,
> > News: http://listserv.utk.edu/archives/statnews.html
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> Charles C. Berry                            (858) 534-2098
>                                              Dept of Family/Preventive
> Medicine
> E mailto:cberry at tajo.ucsd.edu	            UC San Diego
> http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-
> 0901
>


From cnissen at AkoyaInc.com  Tue Sep  4 14:43:38 2007
From: cnissen at AkoyaInc.com (Cory Nissen)
Date: Tue, 4 Sep 2007 07:43:38 -0500
Subject: [R] by group problem
References: <OF92EEA613.338C3821-ONC125734B.00307433-C125734B.00309F20@precheza.cz>
Message-ID: <6EBEA5B72E9B02428F2DD71D9DBC6EDF31939C@AKOYASRV01.akoyainc.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/801569ac/attachment.pl 

From muenchen at utk.edu  Tue Sep  4 14:48:17 2007
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Tue, 4 Sep 2007 08:48:17 -0400
Subject: [R] Comparing "transform" to "with"
In-Reply-To: <971536df0709020746u64a8d9bfud1802413c2785412@mail.gmail.com>
References: <347152339B716A4D893C9A2988EA87C85E042C@KFSVS2.utk.tennessee.edu>
	<971536df0709020746u64a8d9bfud1802413c2785412@mail.gmail.com>
Message-ID: <347152339B716A4D893C9A2988EA87C85E0577@KFSVS2.utk.tennessee.edu>

Gabor, 

That's very nice! I like your my.transform much better. Too bad about
the incompatibility. Swapping that out would no doubt break some
existing programs. I love that old joke, "God was able to create the
universe in just 6 days only because he didn't have an installed base to
worry about!"

Cheers,
Bob

> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> Sent: Sunday, September 02, 2007 10:47 AM
> To: Muenchen, Robert A (Bob)
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Comparing "transform" to "with"
> 
> Try this version of transform.  In the first test we show
> it works on your example but we have used the head of the built in
> anscombe data set.  The second and third show that
> it necessarily is incompatible with transform because transform
> always looks up variables in DF first whereas my.transform looks
> up the computed ones first.
> 
> my.transform <- function(DF, ...) {
> 	f <- function(){}
> 	formals(f) <- eval(substitute(as.pairlist(c(alist(...), DF))))
> 	body(f) <- substitute(modifyList(DF, data.frame(...)))
> 	f()
> }
> 
> # test
> a <- head(anscombe)
> # 1
> my.transform(a, sum1 = x1+x2+x3+x4, sum2 = y1+y2+y3+y4, total =
> sum1+sum2)
> # 2
> my.transform(a, y2 = y1, y3 = y2)
> # 3
> transform(a, y2 = y1, y3 = y2) # different
> 
> 
> On 9/1/07, Muenchen, Robert A (Bob) <muenchen at utk.edu> wrote:
> > Hi All,
> >
> > I've been successfully using the with function for analyses and the
> > transform function for multiple transformations. Then I thought, why
> not
> > use "with" for both? I ran into problems & couldn't figure them out
> from
> > help files or books. So I created a simplified version of what I'm
> > doing:
> >
> > rm( list=ls() )
> > x1<-c(1,3,3)
> > x2<-c(3,2,1)
> > x3<-c(2,5,2)
> > x4<-c(5,6,9)
> > myDF<-data.frame(x1,x2,x3,x4)
> > rm(x1,x2,x3,x4)
> > ls()
> > myDF
> >
> > This creates two new variables just fine"
> >
> > transform(myDF,
> >  sum1=x1+x2,
> >  sum2=x3+x4
> > )
> >
> > This next code does not see sum1, so it appears that "transform"
> cannot
> > see the variables that it creates. Would I need to transform new
> > variables in a second pass?
> >
> > transform(myDF,
> >  sum1=x1+x2,
> >  sum2=x3+x4,
> >  total=sum1+sum2
> > )
> >
> > Next I'm trying the same thing using "with". It doesn't not work but
> > also does not generate error messages, giving me the impression that
> I'm
> > doing something truly idiotic:
> >
> > with(myDF, {
> >  sum1<-x1+x2
> >  sum2<-x3+x4
> >  total <- sum1+sum2
> > } )
> > myDF
> > ls()
> >
> > Then I thought, perhaps one of the advantages of "transform" is that
> it
> > works on the left side of the equation without using a longer name
> like
> > myDF$sum1. "with" probably doesn't do that, so I use the longer form
> > below. It also does not work and generates no error messages.
> >
> > # Try it again, writing vars to myDF explicitly.
> > # It generates no errors, and no results.
> > with(myDF, {
> >  myDF$sum1<-x1+x2
> >  myDF$sum2<-x3+x4
> >  myDF$total <- myDF$sum1+myDF$sum2
> > } )
> > myDF
> > ls()
> >
> > I would appreciate some advice about the relative roles of these two
> > functions & why my attempts with "with" have failed.
> >
> > Thanks!
> > Bob
> >
> > =========================================================
> > Bob Muenchen (pronounced Min'-chen), Manager
> > Statistical Consulting Center
> > U of TN Office of Information Technology
> > 200 Stokely Management Center, Knoxville, TN 37996-0520
> > Voice: (865) 974-5230
> > FAX: (865) 974-4810
> > Email: muenchen at utk.edu
> > Web: http://oit.utk.edu/scc,
> > News: http://listserv.utk.edu/archives/statnews.html
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From ggrothendieck at gmail.com  Tue Sep  4 15:35:28 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 4 Sep 2007 09:35:28 -0400
Subject: [R] Table and ftable
In-Reply-To: <305034a40709040152m25fe66d8q23de016cbce5cfb4@mail.gmail.com>
References: <305034a40709040152m25fe66d8q23de016cbce5cfb4@mail.gmail.com>
Message-ID: <971536df0709040635y12374083u7c783a1f7b9b8901@mail.gmail.com>

Try this which gives an object of the required shape and of
class c("xtabs", "table") :

   xx <- xtabs(area ~ sic + level, DF)

You can optionally do it like this to make it class "matrix"

   xx <- xtabs(area ~ sic + level, DF)[]

and if you don't want the call attribute:

   attr(xx, "call") <- NULL

On 9/4/07, Giulia Bennati <bennati at gmail.com> wrote:
> Dear listmembers,
> I have a little question: I have my data organized as follow
>
> sic  level  area
> a    211    2.4
> b    311    2.3
> b    322    0.2
> b    322    0.5
> c    100    3.0
> c    100    1.5
> c    242    1.5
> d    222    0.2
>
> where levels and sics are factors. I'm trying to obtain a matrix like this:
>
>        level
>         211    311    322   100    242     222
> sic
> a        2.4      0       0       0       0        0
> b         0       2.3    0.7     0       0        0
> c         0        0      0       4.5     1.5     0
> d         0        0      0        0       0       0.2
>
> I tryed with table function as
> table(sic,level) but i obteined only a contingency table.
> Have you any suggestions?
> Thank you very much,
> Giulia
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hans-ole.orka at umb.no  Tue Sep  4 15:59:54 2007
From: hans-ole.orka at umb.no (=?iso-8859-1?Q?Hans_Ole_=D8rka?=)
Date: Tue, 4 Sep 2007 15:59:54 +0200
Subject: [R] For loop with if else statement
Message-ID: <79A4337FAC9B9745AC67F907304190C0106A7226E5@exch01.ans.umb.no>

Hi,
I try to make a simple for loop with a if else statement (First example - Below) and extend it to a more complex loop (Second example). However, my results

#First example:
x=c(1,2)
t=for(i in 1:length(x)){
if (x==1){a=x+1}else
if (x==2){a=x}
}

Returned from R:
Warning messages:
1: the condition has length > 1 and only the first element will be used in: if (x == 1) {
2: the condition has length > 1 and only the first element will be used in: if (x == 1) {
> t
[1] 2 3

However, the result i had liked to get was t=c(2,2) i.e. using the first function (a=x+1) for x[1] and (a=x) for x[2]. I can remove the Warnings by making: if (x[i]==1) etc. but this do not make the results any better.


#Second example:
x=c(1,2)
t<-for(i in 1:length(x)){
        if (x==1){
                a=x
                b=x-1}else
        if (x==2){
                a=x+1
                b=x}
b<-list(a=a,b=b)
}

Returned from R:
Warning messages:
1: the condition has length > 1 and only the first element will be used in: if (x == 1) {
2: the condition has length > 1 and only the first element will be used in: if (x == 1) {
> t
$a
[1] 1 2

$b
[1] 0 1

The result i like to get are $a =c(1,3) and $b=c(0,2)

Probably there are couple of things that I do wrong and I appreciate all help!


From darylyiu at gmail.com  Tue Sep  4 16:04:07 2007
From: darylyiu at gmail.com (daryl yiu)
Date: Tue, 4 Sep 2007 10:04:07 -0400
Subject: [R] ML fit of pareto and lognormal distributions to grouped data
Message-ID: <381bceae0709040704g45e5f736s70af82dd14d4204d@mail.gmail.com>

Dear list members,

I have a set of claims data, which are in ranges and the shape of the
distribution is relatively different. I have looked through R help
threads and found out that an ideal way is suggested for the gamma
distribution ML fitting for grouped data.

I just wonder if there is any method that works for lognormal or
pareto distribution?

An example would be:
Ranges<-c(0,50,100,150,200,250,300,400,500,750,1000)
Claims<-c(452,62,95,88,118,118,261,367,972,982,3024)

>From: Prof Brian Ripley <ripley_at_stats.ox.ac.uk>
>Date: Tue 28 Nov 2006 - 13:26:11 GMT
>
>
>library(stats4)
>
>ll <- function(shape, rate)
>{
>
>     z <- pgamma(breaks, shape=shape, rate=rate)
>     -sum(counts * log(diff(z)))
>
>
>}
>mle(ll, start=list(shape=1, rate=1/mean(breaks)))
>
>looks a plausible fit.
>
>On Tue, 28 Nov 2006, Thomas Petzoldt wrote:
>
>> Hello,
>>
>> we have a set of biological cell-size data, which are only available as
>> frequencies of discrete size classes, because of the high effort of
>> manual microscopic measurements.
>>
>> The lengths are approximately gamma distributed, however the shape of
>> the distribution is relatively variable between different samples (maybe
>> it's a mixture in reality).
>>
>> Is there any ML fitting (or moment-based) procedure for the gamma
>> distribution and grouped data already available in R?
>>
>> Here is a small example:
>>
>> breaks <- c(0, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150)
>> mids <- c(10, 25, 35, 45, 55, 65, 75, 85, 95, 125)
>> counts <- c(87, 5, 2, 2, 1, 1, 0, 0, 1, 1)
>>

Thank you very much and any assistant is really appreciated!


-- 
Daryl Yiu


From cnissen at AkoyaInc.com  Tue Sep  4 16:30:11 2007
From: cnissen at AkoyaInc.com (Cory Nissen)
Date: Tue, 4 Sep 2007 09:30:11 -0500
Subject: [R] variable format
Message-ID: <6EBEA5B72E9B02428F2DD71D9DBC6EDF31939D@AKOYASRV01.akoyainc.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/12b678e4/attachment.pl 

From lawremi at iastate.edu  Tue Sep  4 16:38:25 2007
From: lawremi at iastate.edu (Michael Lawrence)
Date: Tue, 4 Sep 2007 09:38:25 -0500
Subject: [R] Embedding Audio Files in Interactive Graphs
In-Reply-To: <D9A5BE6F-47BB-48B8-A49D-EEE608A7F4A2@ihug.com.au>
References: <JNS7XP$5CF16C227C4387091711DE17B6E0E27C@libero.it>
	<D9A5BE6F-47BB-48B8-A49D-EEE608A7F4A2@ihug.com.au>
Message-ID: <509e0620709040738i7354416cv2b54c8f160a46fd7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/e4bda963/attachment.pl 

From murdoch at stats.uwo.ca  Tue Sep  4 16:51:06 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 04 Sep 2007 10:51:06 -0400
Subject: [R] For loop with if else statement
In-Reply-To: <79A4337FAC9B9745AC67F907304190C0106A7226E5@exch01.ans.umb.no>
References: <79A4337FAC9B9745AC67F907304190C0106A7226E5@exch01.ans.umb.no>
Message-ID: <46DD70DA.2070009@stats.uwo.ca>

On 9/4/2007 9:59 AM, Hans Ole ?rka wrote:
> Hi,
> I try to make a simple for loop with a if else statement (First example - Below) and extend it to a more complex loop (Second example). However, my results
> 
> #First example:
> x=c(1,2)
> t=for(i in 1:length(x)){
> if (x==1){a=x+1}else
> if (x==2){a=x}
> }
> 
> Returned from R:
> Warning messages:
> 1: the condition has length > 1 and only the first element will be used in: if (x == 1) {
> 2: the condition has length > 1 and only the first element will be used in: if (x == 1) {
>> t
> [1] 2 3
> 
> However, the result i had liked to get was t=c(2,2) i.e. using the first function (a=x+1) for x[1] and (a=x) for x[2]. I can remove the Warnings by making: if (x[i]==1) etc. but this do not make the results any better.

x is a vector of length 2.  Using a = x + 1 means that the entire vector 
a will be replaced by the entire vector x.  You need to index each entry 
each time you use it, i.e.

if (x[i] == 1) a[i] <- x[i] + 1
else if (x[i] ==2]) a[i] <- x[i]

or more simply, throw away the loop, and use the ifelse function:

a <- ifelse( x == 1, x + 1,
        ifelse( x == 2,  x,
          NA) )

(where I've used NA for the case where x is neither 1 nor 2.)

Duncan Murdoch

> 
> #Second example:
> x=c(1,2)
> t<-for(i in 1:length(x)){
>         if (x==1){
>                 a=x
>                 b=x-1}else
>         if (x==2){
>                 a=x+1
>                 b=x}
> b<-list(a=a,b=b)
> }
> 
> Returned from R:
> Warning messages:
> 1: the condition has length > 1 and only the first element will be used in: if (x == 1) {
> 2: the condition has length > 1 and only the first element will be used in: if (x == 1) {
>> t
> $a
> [1] 1 2
> 
> $b
> [1] 0 1
> 
> The result i like to get are $a =c(1,3) and $b=c(0,2)
> 
> Probably there are couple of things that I do wrong and I appreciate all help!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From stanhopkins at comcast.net  Tue Sep  4 16:52:05 2007
From: stanhopkins at comcast.net (Stan Hopkins)
Date: Tue, 4 Sep 2007 09:52:05 -0500
Subject: [R] data.frame loses name when constructed with one column
Message-ID: <001c01c7ef03$29b7a4f0$6405a8c0@MXD32803WB>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/c1a48e0b/attachment.pl 

From binsuniupui at gmail.com  Tue Sep  4 16:57:01 2007
From: binsuniupui at gmail.com (Bin Sun)
Date: Tue, 4 Sep 2007 10:57:01 -0400
Subject: [R] how to extract t-test statistics from glm()?
Message-ID: <000601c7ef03$d9d936a0$8d8ba3e0$@com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/244850d7/attachment.pl 

From yogesh.mpi at googlemail.com  Tue Sep  4 17:05:05 2007
From: yogesh.mpi at googlemail.com (Yogesh Tiwari)
Date: Tue, 4 Sep 2007 16:05:05 +0100
Subject: [R] interpolation
Message-ID: <71cc5ca20709040805x7af120c4s8a09a4feef5dab56@mail.gmail.com>

Hello R Users,

I am new to R and I have simple problem for R users.

I have CO2 observations defined on time axis(yr,mo,day,hr,min,sec). (DATA
ATTACHED HERE)

First I want to convert time axis as one axis as 'hour' on regular interval
as 1 hour. Say 00 hrs to 24hrs(jan1), 25hrs to 48hrs(jan2) and so on.

Then I want to interpolate CO2 at every hour.

Kindly anybody can help,

Many thanks,

Regards,
Yogesh
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: data.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/5afd4c96/attachment.txt 

From mandevip at hotmail.com  Tue Sep  4 18:02:09 2007
From: mandevip at hotmail.com (Peter B. Mandeville)
Date: Tue, 4 Sep 2007 11:02:09 -0500
Subject: [R] multiphasic growth curve analysis
Message-ID: <BAY140-W97E0C3DFC7A6274D21861C3CA0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/33fb3fb9/attachment.pl 

From thatsanicehatyouhave at mac.com  Tue Sep  4 18:05:03 2007
From: thatsanicehatyouhave at mac.com (thatsanicehatyouhave at mac.com)
Date: Tue, 4 Sep 2007 17:05:03 +0100
Subject: [R] Variable scope in a function
Message-ID: <818AF6EE-CFB6-426D-9AD1-8C5A9212D9D6@mac.com>

Hello,

I apologise in advance for this question; I'm sure it is answered in  
the documentation or this mailing list many times, however the answer  
has eluded me.

I'm trying to write a function where I don't want external variables  
to be scoped in from the parent environment. Given this function:

test_func = function() {

	if (exists("kat") == FALSE) {
		print("kat is undefined")	
	} else {
		print(kat)
	}
}

If I did this:

 > kat = 12
 > test_func()

I'd like the result to be the error, but now it's 12 (which is of  
course correct according to the documentation).

So there are two questions:

1) How can I disregard all variables from the parent environment  
within a function? (Although from what I've read on the mailing lists  
this isn't really what I want.)

Apparently

environment(test_func) = NULL

is defunct, and what I thought was its replacement

environment(test_func) = emptyenv()

doesn't seem to be.


2) How can I "undefine" a variable, perhaps just within the context  
of my function. I'm hoping to find some line that I can put at the  
start of my function above so that the result would be:

 > kat = 12
 > test_func()
[1] "kat is undefined"
 > kat
[1] 12

Thanks in advance for any help!

Cheers,

Demitri


From alexander.heidrich at uni-jena.de  Tue Sep  4 18:17:14 2007
From: alexander.heidrich at uni-jena.de (Alexander Heidrich)
Date: Tue, 4 Sep 2007 18:17:14 +0200
Subject: [R] SOLVED: importing huge XML-Files -- new problem: special
	characters
Message-ID: <4A8AEEC0-F64C-4965-A3C5-C02D79BD1318@uni-jena.de>

Hi all,

thanks to the people who replied to my question! I finally solved the  
issue by writing own handlers and using xmlEventParse - which leads  
to the following problem which is so odd that its probably a bug.

I use several special charachter in my XML-File, e.g. umlauts or ? or  
? - but no matter how I encode my XML (UTF or ISO) or I escape these  
characters xmlEventParse always stops parsing after the first umlaut  
and pretends to have more than one node even if there is really just  
one!

Example:

<locations>abc	ab?cd	abdec</locations>

causes two events for locations and produces output in the form of:

	[,1]	[,2]	[,3]
[1,]	abc
[2,]	ab?cd	abdec


Should it be like that? If I remove the umlauts, than everything is  
fine!

If I do the following:

<locations>?abc	ab?cd	abdec</locations>

the output is

	[,1]	[,2]	[,3]
[1,]	?abc	ab?cd	abdec

Any suggestions?

Thanks in advance and many greetings!

Alex


From agreen at usgs.gov  Tue Sep  4 17:05:33 2007
From: agreen at usgs.gov (Adam Green)
Date: Tue, 4 Sep 2007 11:05:33 -0400
Subject: [R] Pie Chart Labels
Message-ID: <OF7801754D.E05D332A-ON8525734C.0052B322-8525734C.0052EC4E@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/1a8137b0/attachment.pl 

From ggrothendieck at gmail.com  Tue Sep  4 18:25:45 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 4 Sep 2007 12:25:45 -0400
Subject: [R] Variable scope in a function
In-Reply-To: <818AF6EE-CFB6-426D-9AD1-8C5A9212D9D6@mac.com>
References: <818AF6EE-CFB6-426D-9AD1-8C5A9212D9D6@mac.com>
Message-ID: <971536df0709040925t65c00b0cla2b73d24eff67227@mail.gmail.com>

environment(test_func) <- baseenv()

will allow it to access the base environment so it can still find exists
but will not find kat.  If you issue the command

search()

then each attached package has the next as its parent and base is the
last one.

Regarding your second question, try rm().

f <- function() { x <- 1; rm(x); exists("x", environment()) }
f() # FALSE


On 9/4/07, thatsanicehatyouhave at mac.com <thatsanicehatyouhave at mac.com> wrote:
> Hello,
>
> I apologise in advance for this question; I'm sure it is answered in
> the documentation or this mailing list many times, however the answer
> has eluded me.
>
> I'm trying to write a function where I don't want external variables
> to be scoped in from the parent environment. Given this function:
>
> test_func = function() {
>
>        if (exists("kat") == FALSE) {
>                print("kat is undefined")
>        } else {
>                print(kat)
>        }
> }
>
> If I did this:
>
>  > kat = 12
>  > test_func()
>
> I'd like the result to be the error, but now it's 12 (which is of
> course correct according to the documentation).
>
> So there are two questions:
>
> 1) How can I disregard all variables from the parent environment
> within a function? (Although from what I've read on the mailing lists
> this isn't really what I want.)
>
> Apparently
>
> environment(test_func) = NULL
>
> is defunct, and what I thought was its replacement
>
> environment(test_func) = emptyenv()
>
> doesn't seem to be.
>
>
> 2) How can I "undefine" a variable, perhaps just within the context
> of my function. I'm hoping to find some line that I can put at the
> start of my function above so that the result would be:
>
>  > kat = 12
>  > test_func()
> [1] "kat is undefined"
>  > kat
> [1] 12
>
> Thanks in advance for any help!
>
> Cheers,
>
> Demitri
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pensterfuzzer at yahoo.de  Tue Sep  4 18:52:29 2007
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Tue, 4 Sep 2007 18:52:29 +0200 (CEST)
Subject: [R] capture.out(system())?
Message-ID: <403709.66857.qm@web23001.mail.ird.yahoo.com>

Hi,

I am trying to capture the console output of program I
call via system() but that always returns only
character(0).

For example:
capture.output(system("pdflatex out.tex") )

will yield:
character(0)

and the output still written to the R console.

Is there a command for intercepting this output?

Thank you!
  Werner


From petr.pikal at precheza.cz  Tue Sep  4 18:59:30 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Tue, 4 Sep 2007 18:59:30 +0200
Subject: [R] Odp:  multiphasic growth curve analysis
In-Reply-To: <BAY140-W97E0C3DFC7A6274D21861C3CA0@phx.gbl>
Message-ID: <OF3F14CD86.94185268-ONC125734C.005AA41F-C125734C.005D568B@precheza.cz>

Although I am not an expert in NLME modelling, looking at your data it 
seems to me that there seems to be no growth pattern in it. Try

library(nlme)
library(reshape)

goat<-read.table("clipboard", header=T)

> str(goat)
'data.frame':   18 obs. of  15 variables:
 $ NoC : int  52 48 54 60 58 42 44 47 50 56 ...
 $ PL1 : int  490 970 1450 620 1370 1200 1200 1000 1300 950 ...
 $ PL2 : int  950 1020 1420 1250 1350 920 1560 1100 1150 1250 ...
 $ PL3 : int  800 980 1430 1100 1200 1150 1650 1000 1200 1200 ...
 $ PL4 : int  900 740 1120 1150 1300 850 1600 870 1030 1280 ...
 

goat.m <- melt(goat, id="NoC")
levels(goat.m$variable) <- 1:14
goat.m$variable <- as.numeric(as.character(goat.m$variable))
names(goat.m)[2] <- "week"
goat.m$NoC <- ordered(goat.m$NoC)
goat.g <- groupedData(value~week|NoC, data=goat.m)
plot(goat.g)

But maybe I am completely mistaken.

Regards

Petr

r-help-bounces at stat.math.ethz.ch napsal dne 04.09.2007 18:02:09:

> 
> Greetings R Help Group,
> 
> How does one effect a multiphasic logistic growth model with 4 phases 
(e.g. 
> Koops 1986; Weigel, Craig, Bidwell and Bates 1992; Grossman and Koops 
2003) with R.
> 
> Before writing to the group, the R help archives were searched, the web 
was 
> searched with Google, Venables and Ripley 2002 was consulted, Pinheiro 
and 
> Bates 2000 was consulted, Bates and Watts 2007 was bought and consulted, 
ETC. 
> but to no avail.
> 
> I have not written to any other group with respect to this problem.
> 
> The following data are offered as an example of the type of problem I am 

> dealing with and are average daily goat milk production in ml. for 14 
weeks. 
> NoC is the goat number. PL1 is the production during the first week; PL2 
is 
> the production during the second week, etc. 
> 
>  NoC  PL1  PL2  PL3  PL4  PL5  PL6  PL7  PL8  PL9 PL10 PL11 PL12 PL13 
PL14
>   52  490  950  800  900  850  850  750  610  640  900  980  890  890 
910
>   48  970 1020  980  740 1050  970  850  790  900  920 1120 1120 1030 
1300
>   54 1450 1420 1430 1120 1330 1230 1030 1170 1350 1530 1490 1500 1310 
910
>   60  620 1250 1100 1150  780  930  990  940  760  730  790 1050  840 
850
>   58 1370 1350 1200 1300 1350 1310 1070  910 1010 1300 1110 1070  990 
660
>   42 1200  920 1150  850  720  630  630  710  850  810  930  980  820 
1570
>   44 1200 1560 1650 1600 1450 1600 1160 1010 1440 1450 1530 1500 1550 
850
>   47 1000 1100 1000  870  760  900  820  865  910  820  930  900 1130 
1070
>   50 1300 1150 1200 1030 1070  970  860  900  950 1190 1250 1130  800 
1400
>   56  950 1250 1200 1280 1220 1155  840 1016 1370 1220 1570 1520 1500 
1150
>    1  870 1250 1160 1270 1200 1410 1110 1008  970 1130 1490 1330 1320 
820
>    3 1000 1100 1200 1120 1250  980  750  890 1050 1160 1340 1210 1150 
760
>    4  551  760  550  580  540  620  550  520  470  720  680  790  750 
1230
>    5  810 1100  820  950  930  830  850  650  810 1070 1120 1300 1040 
1320
>    6  800 1000  620  850  750  670  660  620  600  610  760  900  758 
1070
>    7  720  830 1120 1050  820  820  850  810  800  750  780  940 1050 
1310
>    8  950 1550 1560 1500 1230 1330 1150 1005 1020 1200 1440 1400 1290 
1080
>   10  660  850 1100  980 1070 1100  870  790  880  950 1000 1210 1050 
1220
> 
> It seems to me that it should be possible to effect the modeling process 
with 
> nlme. Any suggestions and or recommendations would be greatly 
appreciated.
> 
> Peter B.
> 
> 
> 
> Douglas M. Bates and Donald G. Watts. 2007. Nonlinear Regression 
Analysis and 
> Its Applications. Wiley Series in Probability and Statistics. John Wiley 
& 
> Sons, Inc., New York, NY, USA.
> 
> M. Grossman and W.J. Koops. 2003. Modeling Extended Lactation Curves of 
Dairy 
> Cattle: A Biological Basis for the Multiphasic Approach. J. Dairy Sci. 
86:988-998.
> 
> W. J. Koops. 1986. Multiphasic Growth Curve Analysis. Growth 50:169-177.
> 
> Jose C. Pinheiro and Douglas M. Bates 2000. Mixed-Effects Models in S 
and S-
> Plus. Statistics and Computing. Springer-Verlag New York, New York, NY, 
USA.
> 
> W. H. Venables and B. D. Ripley. 2002. Modern Applied Statistics with S. 

> Fourth edition. Statistics and Computing. Springer-Verlag New York, 
Inc., New 
> York, NY, USA.
> 
> K. A. Weigel, B. A. Craig, T. R. Bidwell and D. M. Bates. 1992. 
Comparison of 
> Alternative Diphasic Lactation Curve Models under Bovine Somatotropin 
> Administration. J. Dairy Sci. 75:580-589.
> 
> 
> 
> 
> 
> 
>  Peter B. Mandeville cel:      444 860 3204 tel:  52 444 826 2346-49 ext 
532 
> fax: 52 444 826 2352 P.D. Favor de confirmar la llegada de este correo. 
Gracias.
> _________________________________________________________________
> Discover the new Windows Vista
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From duncan at wald.ucdavis.edu  Tue Sep  4 19:15:35 2007
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Tue, 4 Sep 2007 10:15:35 -0700
Subject: [R] SOLVED: importing huge XML-Files -- new problem: special
	characters
In-Reply-To: <4A8AEEC0-F64C-4965-A3C5-C02D79BD1318@uni-jena.de>
References: <4A8AEEC0-F64C-4965-A3C5-C02D79BD1318@uni-jena.de>
Message-ID: <20070904171535.GA31933@wald.ucdavis.edu>

Alexander Heidrich wrote:
> Hi all,
> 
> thanks to the people who replied to my question! I finally solved the  
> issue by writing own handlers and using xmlEventParse - which leads  
> to the following problem which is so odd that its probably a bug.
> 
> I use several special charachter in my XML-File, e.g. umlauts or ? or  
> ? - but no matter how I encode my XML (UTF or ISO) or I escape these  
> characters xmlEventParse always stops parsing after the first umlaut  
> and pretends to have more than one node even if there is really just  
> one!
> 
> Example:
> 
> <locations>abc	ab?cd	abdec</locations>
> 
> causes two events for locations and produces output in the form of:
> 
> 	[,1]	[,2]	[,3]
> [1,]	abc
> [2,]	ab?cd	abdec
> 

Well, your output is particular to your text event handlers so 
what you show us does not tell us what were the inputs.
If you have two events and you got "abc     "
and "abocd	abdec" (or the trailing spaces from the first
appeared on the second and not the first), that would not
suprise me. 

The underlying XML parser is extracting content from a stream
of bytes. It makes no guarantee that contiguous text
content is delivered in a single event to the handlers.
Instead, it consumes as much of the stream as it wants
and delivers that and then continues from where it left off
in the stream. If it encounters a text node with a large amount
of text, it will deliver that in smaller chunks. 

This undoubtedly makes the processing of the stream slightly harder
for the handler as it has to remember where it "was", but this is true
of all handlers so not a significant burden.

The branches parameter of the xmlEventParse() function does provide
a way to mix SAX/event parsing with the easier DOM/node style parsing.

 D.

> 
> Should it be like that? If I remove the umlauts, than everything is  
> fine!
> 
> If I do the following:
> 
> <locations>?abc	ab?cd	abdec</locations>
> 
> the output is
> 
> 	[,1]	[,2]	[,3]
> [1,]	?abc	ab?cd	abdec
> 
> Any suggestions?
> 
> Thanks in advance and many greetings!
> 
> Alex
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Duncan Temple Lang                duncan at wald.ucdavis.edu
Department of Statistics          work:  (530) 752-4782
4210 Mathematical Sciences Bldg.  fax:   (530) 752-7099
One Shields Ave.
University of California at Davis
Davis, CA 95616, USA



-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20070904/7152998e/attachment.bin 

From g.m.f.vanderheijden04 at leeds.ac.uk  Tue Sep  4 19:55:03 2007
From: g.m.f.vanderheijden04 at leeds.ac.uk (Geertje Van der Heijden)
Date: Tue, 4 Sep 2007 18:55:03 +0100
Subject: [R] Robust linear models and unequal variance
Message-ID: <E193A286CE83354EB8BAB315F8BE62D317D591@HERMES4.ds.leeds.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/c1636a09/attachment.pl 

From strinz at freenet.de  Tue Sep  4 19:59:52 2007
From: strinz at freenet.de (strinz at freenet.de)
Date: Tue, 04 Sep 2007 19:59:52 +0200
Subject: [R] rug() colors
Message-ID: <E1IScgq-0003Sz-3K@www10.emo.freenet-rz.de>

Hello,

I have a simple question on rug().
Currently there is only one color possible for the rug.
Is it possible to plot a the rug with different colors, for each rug item ?

Thx.
Bjoern


From fisher at plessthan.com  Tue Sep  4 20:42:00 2007
From: fisher at plessthan.com (Dennis Fisher)
Date: Tue, 4 Sep 2007 11:42:00 -0700
Subject: [R] Recursive concatenation
Message-ID: <54257198-168A-478D-9DEE-B525D988A3D4@plessthan.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/71be19ed/attachment.pl 

From wwwhsd at gmail.com  Tue Sep  4 20:45:51 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Tue, 4 Sep 2007 15:45:51 -0300
Subject: [R] Recursive concatenation
In-Reply-To: <54257198-168A-478D-9DEE-B525D988A3D4@plessthan.com>
References: <54257198-168A-478D-9DEE-B525D988A3D4@plessthan.com>
Message-ID: <da79af330709041145ya0313b0kd6bd40558a22724e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/d6cc08c3/attachment.pl 

From Dimitris.Rizopoulos at med.kuleuven.be  Tue Sep  4 21:04:09 2007
From: Dimitris.Rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 04 Sep 2007 21:04:09 +0200
Subject: [R] Recursive concatenation
In-Reply-To: <54257198-168A-478D-9DEE-B525D988A3D4@plessthan.com>
References: <54257198-168A-478D-9DEE-B525D988A3D4@plessthan.com>
Message-ID: <20070904210409.69mi98w21mlco008@webmail3.kuleuven.be>

try this:

paste(rep(LETTERS[1:3], each = 3), 1:3, sep = "")


Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
      http://www.student.kuleuven.be/~m0390867/dimitris.htm


Quoting Dennis Fisher <fisher at plessthan.com>:

> Colleagues,
>
> I want to create the following array:
> 	"A1", "A2", "A3", "B1", "B2", "B3", "C1", "C2", "C3"
>
> I recall that there is a trick using "c" or "paste" permitting me to
> form all combinations of c("A", "B", "C") and 1:3.  But, I can't
> recall the trick.
>
> Dennis
>
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone: 1-866-PLessThan (1-866-753-7784)
> Fax: 1-415-564-2220
> www.PLessThan.com
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>



Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From dolph008 at umn.edu  Tue Sep  4 21:32:18 2007
From: dolph008 at umn.edu (dolph008 at umn.edu)
Date: 04 Sep 2007 14:32:18 -0500
Subject: [R] bootstrap confidence intervals with previously existing
	bootstrap sample
Message-ID: <Prayer.1.0.16.0709041432180.24549@wm1.tc.umn.edu>

Dear R users,

I am new to R. I would like to calculate bootstrap confidence intervals 
using the BCa method for a parameter of interest. My situation is this: I 
already have a set of 1000 bootstrap replicates created from my original 
data set. I have already calculated the statistic of interest for each 
bootstrap replicate, and have also calculated the mean for this statistic 
across all the replicates. Now I would like to calculate Bca confidence 
intervals for this statistic. Is there a way to import my 
previously-calculated set of 1000 statistics into R, and then calculate 
bootstrap confidence intervals around the mean from this imported data?

I have found the code for boot.ci in the manual for the boot package, but 
it looks like it requires that I first use the "boot" function, and then 
apply the output to "boot.ci". Because my bootstrap samples already exist, 
I don't want to use "boot", but just want to import the 1000 values I have 
already calculated, and then get R to calculate the mean and Bca confidence 
intervals based on these values. Is this possible?


Hopefully this makes sense. Thanks so much for any help or advice,

Christy Dolph

Graduate Student
Water Resources Science
University of Minnesota-Twin Cities


From Mark.Leeds at morganstanley.com  Tue Sep  4 21:51:17 2007
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Tue, 4 Sep 2007 15:51:17 -0400
Subject: [R] Confusion using "functions to access the function call stack"
	example section
Message-ID: <D3AEEDA31E57474B840BEBC25A8A834401957946@NYWEXMB23.msad.ms.com>

I was going through the example below which is taken from the example
section in the R documentation for accessing the function call stack.
I am confused and I have 3 questions that I was hoping someone could
answer.

1) why is y equal to zero even though the call was done with gg(3)

2) what does parents are 0,1,2,0,4,5,6,7 mean ? I understand what a
parent frame is but how do the #'s relate to this
particular example ? Why is the current frame # 8 ?

3) it says that sys.function(2) should be gg but I would think that
sys.function(1) would be gg since it's one up from where
the call is being made.

Thanks a lot. If the answers are too complicated and someone knows of a
good reference that goes into more details about
the sys functions, that's appreciated also.




gg <- function(y) {
	ggg <- function() {
		cat("y = ", y, "\n")
		cat("current frame is ", sys.nframe(), "\n")
		cat("parents are ", sys.parents(), "\n")
		print(sys.function(0)) # ggg
		print(sys.function(2)) # gg
	}

	if (y > 0) gg(y-1) else ggg()
}

gg(3)



# OUTPUT


y =  0 
current frame is  8 
parents are  0 1 2 0 4 5 6 7 
function() {
                cat("y = ", y, "\n")
                cat("current frame is ", sys.nframe(), "\n")
                cat("parents are ", sys.parents(), "\n")
                print(sys.function(0)) # ggg
                print(sys.function(2)) # gg
        }
<environment: 0x8a9cc68>
function (expr, envir = parent.frame(), enclos = if (is.list(envir) || 
    is.pairlist(envir)) parent.frame() else baseenv()) 
.Internal(eval.with.vis(expr, envir, enclos))
<environment: 0x8974ea0>
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From lynn.osburn at lewan.com  Tue Sep  4 22:12:52 2007
From: lynn.osburn at lewan.com (Lynn Osburn)
Date: Tue, 4 Sep 2007 13:12:52 -0700 (PDT)
Subject: [R] Howto sort dataframe columns by colMeans
Message-ID: <12485729.post@talk.nabble.com>


I read from external data source containing several columns.  Each column
represents value of a metric.  The columns are time series data.

I want to sort the resulting dataframe such that the column with the largest
mean is the leftmost column, descending in colMean values to the right.

I see many solutions for sorting rows based on some column characteristic,
but haven't found any discussion of sorting columns based on column
characteristics.

viz.  input data looks like this
  time   met-a    met-b    met-c
00:00    42         18          99
00:05    88         16          67
00:10    80         27          84

desired output:
 time   met-c    met-a     met-b
00:00    99         42          18
00:05    67         88          16
00:10    84         80          27

Thanks,
-Lynn

-- 
View this message in context: http://www.nabble.com/Howto-sort-dataframe-columns-by-colMeans-tf4380044.html#a12485729
Sent from the R help mailing list archive at Nabble.com.


From jholtman at gmail.com  Tue Sep  4 22:27:27 2007
From: jholtman at gmail.com (jim holtman)
Date: Tue, 4 Sep 2007 16:27:27 -0400
Subject: [R] Confusion using "functions to access the function call
	stack" example section
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A834401957946@NYWEXMB23.msad.ms.com>
References: <D3AEEDA31E57474B840BEBC25A8A834401957946@NYWEXMB23.msad.ms.com>
Message-ID: <644e1f320709041327p7420345bi6ba04b8fa85fb768@mail.gmail.com>

It is because you have a recursive function call and the value of 'y'
when you print is it 0.  I have added another statement that might
help clarify what you are seeing.  At the point at which the most
current value of the function 'ggg' is evaluated (last call), the
value of 'y' is zero and you are 5 levels down from the 'main frame':

> gg <- function(y) {
+        cat ("gg y=", y, "current frame =", sys.nframe(), "\n")
+        ggg <- function() {
+                cat("y = ", y, "\n")
+                cat("current frame is ", sys.nframe(), "\n")
+                cat("parents are ", sys.parents(), "\n")
+                print(sys.function(0)) # ggg
+                print(sys.function(2)) # gg
+        }
+
+        if (y > 0) gg(y-1) else ggg()
+ }
>
> gg(3)
gg y= 3 current frame = 1
gg y= 2 current frame = 2
gg y= 1 current frame = 3
gg y= 0 current frame = 4
y =  0
current frame is  5
parents are  0 1 2 3 4
function() {
               cat("y = ", y, "\n")
               cat("current frame is ", sys.nframe(), "\n")
               cat("parents are ", sys.parents(), "\n")
               print(sys.function(0)) # ggg
               print(sys.function(2)) # gg
       }
<environment: 0x01cf5f6c>
function(y) {
       cat ("gg y=", y, "current frame =", sys.nframe(), "\n")
       ggg <- function() {
               cat("y = ", y, "\n")
               cat("current frame is ", sys.nframe(), "\n")
               cat("parents are ", sys.parents(), "\n")
               print(sys.function(0)) # ggg
               print(sys.function(2)) # gg
       }

       if (y > 0) gg(y-1) else ggg()
}


On 9/4/07, Leeds, Mark (IED) <Mark.Leeds at morganstanley.com> wrote:
> I was going through the example below which is taken from the example
> section in the R documentation for accessing the function call stack.
> I am confused and I have 3 questions that I was hoping someone could
> answer.
>
> 1) why is y equal to zero even though the call was done with gg(3)
>
> 2) what does parents are 0,1,2,0,4,5,6,7 mean ? I understand what a
> parent frame is but how do the #'s relate to this
> particular example ? Why is the current frame # 8 ?
>
> 3) it says that sys.function(2) should be gg but I would think that
> sys.function(1) would be gg since it's one up from where
> the call is being made.
>
> Thanks a lot. If the answers are too complicated and someone knows of a
> good reference that goes into more details about
> the sys functions, that's appreciated also.
>
>
>
>
> gg <- function(y) {
>        ggg <- function() {
>                cat("y = ", y, "\n")
>                cat("current frame is ", sys.nframe(), "\n")
>                cat("parents are ", sys.parents(), "\n")
>                print(sys.function(0)) # ggg
>                print(sys.function(2)) # gg
>        }
>
>        if (y > 0) gg(y-1) else ggg()
> }
>
> gg(3)
>
>
>
> # OUTPUT
>
>
> y =  0
> current frame is  8
> parents are  0 1 2 0 4 5 6 7
> function() {
>                cat("y = ", y, "\n")
>                cat("current frame is ", sys.nframe(), "\n")
>                cat("parents are ", sys.parents(), "\n")
>                print(sys.function(0)) # ggg
>                print(sys.function(2)) # gg
>        }
> <environment: 0x8a9cc68>
> function (expr, envir = parent.frame(), enclos = if (is.list(envir) ||
>    is.pairlist(envir)) parent.frame() else baseenv())
> .Internal(eval.with.vis(expr, envir, enclos))
> <environment: 0x8974ea0>
> --------------------------------------------------------
>
> This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From patrick at pdrechsler.de  Tue Sep  4 22:32:04 2007
From: patrick at pdrechsler.de (Patrick Drechsler)
Date: Tue, 04 Sep 2007 22:32:04 +0200
Subject: [R] lattice xyplot with bty="l"
Message-ID: <87abs2cgu3.fsf@pdrechsler.de>

Hi,

what is the correct way of removing the "top" and "right" axes
completely from a lattice xyplot? I would like to have a plot similar
to using the bty="l" option for traditional plots.

An example:

--8<---------------cut here---------------start------------->8---
rm(list=c(ls())) 
library(lattice)

y <- 1:10
x <- y

## Traditional plot:
plot(x, y, bty = "l")

## Lattice plot 1:
xyplot(y ~ x,
       panel = function(x, y, ...){
         panel.xyplot(x, y, ...)
         panel.axis(side = c("left", "bottom"))
       }
       )

## Lattice plot 2:
xyplot(y ~ x,
       ## This just tries to remove all y axes:
       scales = list(y = list(draw = FALSE))
       )
--8<---------------cut here---------------end--------------->8---

Thankful for any pointers,

Patrick


From jholtman at gmail.com  Tue Sep  4 22:33:39 2007
From: jholtman at gmail.com (jim holtman)
Date: Tue, 4 Sep 2007 16:33:39 -0400
Subject: [R] Howto sort dataframe columns by colMeans
In-Reply-To: <12485729.post@talk.nabble.com>
References: <12485729.post@talk.nabble.com>
Message-ID: <644e1f320709041333k3776bb5dge68a4691c81bc71d@mail.gmail.com>

Here is one way of doing it by 'skipping' the first column which is a
factor and your 'time':

> x <- read.table(textConnection(" time   met-a    met-b    met-c
+ 00:00    42         18          99
+ 00:05    88         16          67
+ 00:10    80         27          84"), header=TRUE)
> x.mean <- colMeans(x[-1])
> x.new <- x[,c('time', names(sort(x.mean, decreasing=TRUE)))]
>
> x.new
   time met.c met.a met.b
1 00:00    99    42    18
2 00:05    67    88    16
3 00:10    84    80    27
>


On 9/4/07, Lynn Osburn <lynn.osburn at lewan.com> wrote:
>
> I read from external data source containing several columns.  Each column
> represents value of a metric.  The columns are time series data.
>
> I want to sort the resulting dataframe such that the column with the largest
> mean is the leftmost column, descending in colMean values to the right.
>
> I see many solutions for sorting rows based on some column characteristic,
> but haven't found any discussion of sorting columns based on column
> characteristics.
>
> viz.  input data looks like this
>  time   met-a    met-b    met-c
> 00:00    42         18          99
> 00:05    88         16          67
> 00:10    80         27          84
>
> desired output:
>  time   met-c    met-a     met-b
> 00:00    99         42          18
> 00:05    67         88          16
> 00:10    84         80          27
>
> Thanks,
> -Lynn
>
> --
> View this message in context: http://www.nabble.com/Howto-sort-dataframe-columns-by-colMeans-tf4380044.html#a12485729
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From arrayprofile at yahoo.com  Tue Sep  4 22:43:44 2007
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 4 Sep 2007 13:43:44 -0700 (PDT)
Subject: [R] Rcmdr scatter3d
Message-ID: <319623.671.qm@web56309.mail.re3.yahoo.com>

Hi, I am using the scatter3d function in Rcmdr to plot
the first 3 principal components, I have a grouping
variable of 2 groups, and tried to plot points with
different colors, somehow I couldn't change the
default colors of the 2 groups (blue and green)by
using option points.col=c('red','blue'), what's the
problem here?

scatter3d(all.pca$x[,2],all.pca$x[,3],all.pca$x[,1],
surface=FALSE, residuals=TRUE, bg="white",
axis.scales=F, grid=F, ellipsoid=F, xlab='PCA
2',ylab='PCA 3', zlab='PCA
1',sphere.size=1.5,groups=as.factor(c(rep(1,100),rep(2,50)))
,point.col=c('red','blue'))

I am also wondering if I can have a copy of the image
in high resolution, just like copying a regular R plot
in "Metafile"? 

Thanks



       
____________________________________________________________________________________

that gives answers, not web links.


From p.dalgaard at biostat.ku.dk  Tue Sep  4 23:02:03 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 04 Sep 2007 23:02:03 +0200
Subject: [R] Confusion using "functions to access the function call
 stack" example section
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A834401957946@NYWEXMB23.msad.ms.com>
References: <D3AEEDA31E57474B840BEBC25A8A834401957946@NYWEXMB23.msad.ms.com>
Message-ID: <46DDC7CB.5010206@biostat.ku.dk>

Leeds, Mark (IED) wrote:
> I was going through the example below which is taken from the example
> section in the R documentation for accessing the function call stack.
> I am confused and I have 3 questions that I was hoping someone could
> answer.
>
> 1) why is y equal to zero even though the call was done with gg(3)
>   
There are multiple nested calls to gg, and y is counted down. You're not 
calling ggg when y > 0, and that what does the printing.
> 2) what does parents are 0,1,2,0,4,5,6,7 mean ? I understand what a
> parent frame is but how do the #'s relate to this
> particular example ? Why is the current frame # 8 ?
>   
How did you get that?? Did you miss the part where it said that the 
example gives different results when run by example()? I get

 > gg(3)
current frame is 5
parents are 0 1 2 3 4
function() {
        cat("current frame is", sys.nframe(), "\n")
        cat("parents are", sys.parents(), "\n")
        print(sys.function(0)) # ggg
        print(sys.function(2)) # gg
    }
<environment: 0x8bb8e10>
function(y) {
    ggg <- function() {
        cat("current frame is", sys.nframe(), "\n")
        cat("parents are", sys.parents(), "\n")
        print(sys.function(0)) # ggg
        print(sys.function(2)) # gg
    }
    if(y > 0) gg(y-1) else ggg()
}

which should make somewhat better sense. (My versions, 2.5.1 and 
pre-2.6.0 don't seem to print y either?) As a general matter, frames 
make a tree: two of them can have the same parent - e.g., this happens 
whenever an argument expression is being evaluated as part of evaluating 
a function call. Try, e.g.

 f <- function(x) {x;print(sys.status())} ; f(f(1))


> 3) it says that sys.function(2) should be gg but I would think that
> sys.function(1) would be gg since it's one up from where
> the call is being made.
>
>   
There are multiple calls to gg()  so both could be true.
> Thanks a lot. If the answers are too complicated and someone knows of a
> good reference that goes into more details about
> the sys functions, that's appreciated also.
>   
The best way is to just poke around with some simple examples until you 
get the hang of it. Possibly modify the examples you have already seen 
but print the entire sys.status().

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Mark.Leeds at morganstanley.com  Tue Sep  4 23:12:57 2007
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Tue, 4 Sep 2007 17:12:57 -0400
Subject: [R] Confusion using "functions to access the function call
	stack" example section
In-Reply-To: <644e1f320709041327p7420345bi6ba04b8fa85fb768@mail.gmail.com>
References: <D3AEEDA31E57474B840BEBC25A8A834401957946@NYWEXMB23.msad.ms.com>
	<644e1f320709041327p7420345bi6ba04b8fa85fb768@mail.gmail.com>
Message-ID: <D3AEEDA31E57474B840BEBC25A8A834401957949@NYWEXMB23.msad.ms.com>

thanks jim : what you said makes a lot of sense so I changed mine to
what you did and I get similar output but everything looks
shifted up by 3 frames. That probably has to do with me running on a
different os ( linux ) or R.2.5.0 rather than R.2.5.1, I guess ? 
It makes a lot more sense now so that's fine.




source("frame.R")
gg y= 3 current frame = 4 
gg y= 2 current frame = 5 
gg y= 1 current frame = 6 
gg y= 0 current frame = 7 
y =  0 
current frame is  8 
parents are  0 1 2 0 4 5 6 7 
function() {
                cat("y = ", y, "\n")
                cat("current frame is ", sys.nframe(), "\n")
                cat("parents are ", sys.parents(), "\n")
                print(sys.function(0)) # ggg
                print(sys.function(2)) # gg
        }
<environment: 0x8a9b23c> 





-----Original Message-----
From: jim holtman [mailto:jholtman at gmail.com] 
Sent: Tuesday, September 04, 2007 4:27 PM
To: Leeds, Mark (IED)
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Confusion using "functions to access the function call
stack" example section

It is because you have a recursive function call and the value of 'y'
when you print is it 0.  I have added another statement that might help
clarify what you are seeing.  At the point at which the most current
value of the function 'ggg' is evaluated (last call), the value of 'y'
is zero and you are 5 levels down from the 'main frame':

> gg <- function(y) {
+        cat ("gg y=", y, "current frame =", sys.nframe(), "\n")
+        ggg <- function() {
+                cat("y = ", y, "\n")
+                cat("current frame is ", sys.nframe(), "\n")
+                cat("parents are ", sys.parents(), "\n")
+                print(sys.function(0)) # ggg
+                print(sys.function(2)) # gg
+        }
+
+        if (y > 0) gg(y-1) else ggg()
+ }
>
> gg(3)
gg y= 3 current frame = 1
gg y= 2 current frame = 2
gg y= 1 current frame = 3
gg y= 0 current frame = 4
y =  0
current frame is  5
parents are  0 1 2 3 4
function() {
               cat("y = ", y, "\n")
               cat("current frame is ", sys.nframe(), "\n")
               cat("parents are ", sys.parents(), "\n")
               print(sys.function(0)) # ggg
               print(sys.function(2)) # gg
       }
<environment: 0x01cf5f6c>
function(y) {
       cat ("gg y=", y, "current frame =", sys.nframe(), "\n")
       ggg <- function() {
               cat("y = ", y, "\n")
               cat("current frame is ", sys.nframe(), "\n")
               cat("parents are ", sys.parents(), "\n")
               print(sys.function(0)) # ggg
               print(sys.function(2)) # gg
       }

       if (y > 0) gg(y-1) else ggg()
}


On 9/4/07, Leeds, Mark (IED) <Mark.Leeds at morganstanley.com> wrote:
> I was going through the example below which is taken from the example 
> section in the R documentation for accessing the function call stack.
> I am confused and I have 3 questions that I was hoping someone could 
> answer.
>
> 1) why is y equal to zero even though the call was done with gg(3)
>
> 2) what does parents are 0,1,2,0,4,5,6,7 mean ? I understand what a 
> parent frame is but how do the #'s relate to this particular example ?

> Why is the current frame # 8 ?
>
> 3) it says that sys.function(2) should be gg but I would think that
> sys.function(1) would be gg since it's one up from where the call is 
> being made.
>
> Thanks a lot. If the answers are too complicated and someone knows of 
> a good reference that goes into more details about the sys functions, 
> that's appreciated also.
>
>
>
>
> gg <- function(y) {
>        ggg <- function() {
>                cat("y = ", y, "\n")
>                cat("current frame is ", sys.nframe(), "\n")
>                cat("parents are ", sys.parents(), "\n")
>                print(sys.function(0)) # ggg
>                print(sys.function(2)) # gg
>        }
>
>        if (y > 0) gg(y-1) else ggg()
> }
>
> gg(3)
>
>
>
> # OUTPUT
>
>
> y =  0
> current frame is  8
> parents are  0 1 2 0 4 5 6 7
> function() {
>                cat("y = ", y, "\n")
>                cat("current frame is ", sys.nframe(), "\n")
>                cat("parents are ", sys.parents(), "\n")
>                print(sys.function(0)) # ggg
>                print(sys.function(2)) # gg
>        }
> <environment: 0x8a9cc68>
> function (expr, envir = parent.frame(), enclos = if (is.list(envir) ||
>    is.pairlist(envir)) parent.frame() else baseenv()) 
> .Internal(eval.with.vis(expr, envir, enclos))
> <environment: 0x8974ea0>
> --------------------------------------------------------
>
> This is not an offer (or solicitation of an offer) to 
> buy/se...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


--
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From h.wickham at gmail.com  Tue Sep  4 23:13:54 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 4 Sep 2007 16:13:54 -0500
Subject: [R] UseR! 2007 presentations and posters - now available
Message-ID: <f8e6ff050709041413k70340217r76b51984d9e23ef9@mail.gmail.com>

Hi everyone,

Many of the presentations and posters from UseR! 2007 are now available online:
http://user2007.org/program/

If you presented and your slides or poster isn't up yet, please email
a pdf version to me, h.wickham at gmail.com, and I'll put it up.

Regards,

Hadley

(And check out http://user2007.org/ for some photos of the event and the R cake)


-- 
http://had.co.nz/


From ripley at stats.ox.ac.uk  Tue Sep  4 23:28:42 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 4 Sep 2007 22:28:42 +0100 (BST)
Subject: [R] bootstrap confidence intervals with previously existing
 bootstrap sample
In-Reply-To: <Prayer.1.0.16.0709041432180.24549@wm1.tc.umn.edu>
References: <Prayer.1.0.16.0709041432180.24549@wm1.tc.umn.edu>
Message-ID: <Pine.LNX.4.64.0709042209200.26489@gannet.stats.ox.ac.uk>

On Tue, 4 Sep 2007, dolph008 at umn.edu wrote:

> Dear R users,
>
> I am new to R. I would like to calculate bootstrap confidence intervals
> using the BCa method for a parameter of interest. My situation is this: I
> already have a set of 1000 bootstrap replicates created from my original
> data set. I have already calculated the statistic of interest for each
> bootstrap replicate, and have also calculated the mean for this statistic
> across all the replicates. Now I would like to calculate Bca confidence
> intervals for this statistic. Is there a way to import my
> previously-calculated set of 1000 statistics into R, and then calculate
> bootstrap confidence intervals around the mean from this imported data?
>
> I have found the code for boot.ci in the manual for the boot package, but
> it looks like it requires that I first use the "boot" function, and then
> apply the output to "boot.ci". Because my bootstrap samples already exist,
> I don't want to use "boot", but just want to import the 1000 values I have
> already calculated, and then get R to calculate the mean and Bca confidence
> intervals based on these values. Is this possible?

Yes, it is possible but you will have to study the internal structure of 
an object of class "boot" (which is documented on the help page) and mimic 
it.  You haven't told us which type of bootstrap you used, which is one of 
the details you need to supply.

It might be slightly easier to work with function bcanon in package 
bootstrap, which you would need to edit to suit your purposes.

I don't know why you have picked on the BCa method: my experience is that 
if you need to correct the basic method you often need far more than 1000 
samples to get reliable results.

> Hopefully this makes sense. Thanks so much for any help or advice,
>
> Christy Dolph
>
> Graduate Student
> Water Resources Science
> University of Minnesota-Twin Cities

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Greg.Snow at intermountainmail.org  Tue Sep  4 23:37:42 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Tue, 4 Sep 2007 15:37:42 -0600
Subject: [R] Pie Chart Labels
Message-ID: <0fc701c7ef3b$ccf6efdb$2e80320a@CO.IHC.COM>

The best option is to use a bar chart or dot chart instead of a pie chart.

-----Original Message-----
From: "Adam Green" <agreen at usgs.gov>
To: "r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
Sent: 9/4/07 10:21 AM
Subject: [R] Pie Chart Labels

I am having trouble finding out how to adjust the position of labels on 
pie charts.  For the small wedges, many of the labels overlap making it 
impossible to read.  Is there any way to offset the labels so that they 
don't overlap?

Adam Green
USGS Patuxent Wildlife Research Center 
	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Tue Sep  4 23:42:03 2007
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 04 Sep 2007 17:42:03 -0400
Subject: [R] Rcmdr scatter3d
In-Reply-To: <319623.671.qm@web56309.mail.re3.yahoo.com>
References: <319623.671.qm@web56309.mail.re3.yahoo.com>
Message-ID: <web-184426456@cgpsrv2.cis.mcmaster.ca>

Dear chip,

When there is groups variable specified, scatter3d() colours the
regression surface, points, and residuals for each group according to
the colours specified in surface.col. (Setting surface=FALSE suppresses
the regression surfaces and residuals.)

You can save the rgl graph that scatter3d() produces as a bitmapped png
graphic [e.g., via Graphs -> 3D graph -> Save graph to file, which uses
rgl.snapshot()]. There is also an rgl.postscript() command, which
supports some vector-graphics formats, but I've been unable to use it
successfully.

I hope this helps,
 John

On Tue, 4 Sep 2007 13:43:44 -0700 (PDT)
 array chip <arrayprofile at yahoo.com> wrote:
> Hi, I am using the scatter3d function in Rcmdr to plot
> the first 3 principal components, I have a grouping
> variable of 2 groups, and tried to plot points with
> different colors, somehow I couldn't change the
> default colors of the 2 groups (blue and green)by
> using option points.col=c('red','blue'), what's the
> problem here?
> 
> scatter3d(all.pca$x[,2],all.pca$x[,3],all.pca$x[,1],
> surface=FALSE, residuals=TRUE, bg="white",
> axis.scales=F, grid=F, ellipsoid=F, xlab='PCA
> 2',ylab='PCA 3', zlab='PCA
> 1',sphere.size=1.5,groups=as.factor(c(rep(1,100),rep(2,50)))
> ,point.col=c('red','blue'))
> 
> I am also wondering if I can have a copy of the image
> in high resolution, just like copying a regular R plot
> in "Metafile"? 
> 
> Thanks
> 
> 
> 
>        
>
____________________________________________________________________________________
> 
> that gives answers, not web links.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From r.turner at auckland.ac.nz  Tue Sep  4 23:48:48 2007
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 5 Sep 2007 09:48:48 +1200
Subject: [R] Pie Chart Labels
In-Reply-To: <0fc701c7ef3b$ccf6efdb$2e80320a@CO.IHC.COM>
References: <0fc701c7ef3b$ccf6efdb$2e80320a@CO.IHC.COM>
Message-ID: <AAAB9D02-45A7-462D-8C90-C201BC1A6B13@auckland.ac.nz>


On 5/09/2007, at 9:37 AM, Greg Snow wrote:

> The best option is to use a bar chart or dot chart instead of a pie  
> chart.

	Right on, Red Freak!!! :-)

			cheers,

				Rolf Turner

######################################################################
Attention:\ This e-mail message is privileged and confidenti...{{dropped}}


From doc.evans at gmail.com  Wed Sep  5 00:14:39 2007
From: doc.evans at gmail.com (D. R. Evans)
Date: Tue, 04 Sep 2007 16:14:39 -0600
Subject: [R] Q: selecting a name when it is known as a string
Message-ID: <46DDD8CF.6010005@gmail.com>

I am 100% certain that there is an easy way to do this, but after
experimenting off and on for a couple of days, and searching everywhere I
could think of, I haven't been able to find the trick.

I have this piece of code:

...
  attach(d)

  if (ORDINATE == 'ds')
  { lo <- loess(percent ~ ncms * ds, d, control=loess.control(trace.hat =
'approximate'))
    grid <- data.frame(expand.grid(ds=MINVAL:MAXVAL, ncms=MINCMS:MAXCMS))
...

then there several almost-identical "if" statements for different values of
ORDINATE. For example, the next "if" statement starts with:

...
  if (ORDINATE == 'dsl')
  { lo <- loess(percent ~ ncms * dsl, d, control=loess.control(trace.hat =
'approximate'))
    grid <- data.frame(expand.grid(dsl=MINVAL:MAXVAL, ncms=MINCMS:MAXCMS))
...

This is obviously pretty silly code (although of course it does work).

I imagine that my question is obvious: given that I have a variable,
ORDINATE, whose value is a string, how do I re-write statements such as the
"lo <-" and "grid <-" statements above so that they use ORDINATE instead of
the hard-coded names "ds" and "dsl".

I am almost sure (almost) that it has something to do with "deparse()", but
I couldn't find the right incantation, and the ?deparse() help left my head
swimming.


From gunter.berton at gene.com  Wed Sep  5 00:23:34 2007
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 4 Sep 2007 15:23:34 -0700
Subject: [R] Robust linear models and unequal variance
In-Reply-To: <E193A286CE83354EB8BAB315F8BE62D317D591@HERMES4.ds.leeds.ac.uk>
References: <E193A286CE83354EB8BAB315F8BE62D317D591@HERMES4.ds.leeds.ac.uk>
Message-ID: <00a801c7ef42$3b9a33b0$3a0b2c0a@gne.windows.gene.com>

Let me try a reply, although I wish others wiser than I had responded.

1. How do you know the variances are unequal? 

2. If you somehow know what the variances are (or at least their relative
sizes), you can use the "weights" arguments of the functions you mentions to
weight inversely proportional to variance (except not for the "MM" method in
rlm() according to the docs.) 

3. That "ranked regression" is robust is a myth. It also does not deal with
the unequal variance situation. It is not a panacea for anything. If you
need "robust" regression use robust regression.

4. If group sizes are not too dissimilar, than whether you case weight or
not may not make much difference (alas, hard to tell a priori). Especially
to estimation.

The fundamental issue is that "outliers" and "unequal variances" must be
operationalized, otherwise they are confounded: "outlier" only has meaning
compared to what is expected from a specified distribution. Outliers are no
longer out when the variance is "large." 

Also look at glm() with the "quasi" option if you wish to consider fitting a
heterogeneous variance structure to initialize a robust method (which could,
of course, be distorted by your "outliers").


Bert Gunter
Genentech Nonclinical Statistics

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Geertje Van der
Heijden
Sent: Tuesday, September 04, 2007 10:55 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Robust linear models and unequal variance

Hi all,

I have probably a basic question, but I can't seem to find the answer in
the literature or in the R-archives. 

I would like to do a robust ANCOVA (using either rlm or lmRob of the
MASS and robust packages) - my response variable deviates slightly from
normal and I have some "outliers". The data consist of 2 factor
variables and 3-5 covariates (fdepending on the model). However, the
variance between my groups is not equal and I am not sure if it is
therefore appropriate to use a robust statistical method or if a
non-parametric analysis (i.e. ranked regression) might be better. If I
can still use a robust statistical method, which estimator is best to
use to deal with unequal variance? And if it is better to use a
non-parametric analysis, could anyone put me in the direction of the
right non-parametric method to use (the relationship between my response
variable and the covariates is linear)?

Any help on this would be greatly appreciated!

Many thanks,
Geertje

~~~~
Geertje van der Heijden
PhD student
Tropical Ecology
School of Geography
University of Leeds
Leeds LS2 9JT

Tel: (+44)(0)113 3433345 
Email: g.m.f.vanderheijden04 at leeds.ac.uk



	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From FolkesM at pac.dfo-mpo.gc.ca  Wed Sep  5 00:26:32 2007
From: FolkesM at pac.dfo-mpo.gc.ca (Folkes, Michael)
Date: Tue, 4 Sep 2007 15:26:32 -0700
Subject: [R] Lattice: panel superpose with groups
In-Reply-To: <63F107BCC37AEA49A75FD94AA3E07CB099F513@pacpbsex01.pac.dfo-mpo.ca>
Message-ID: <63F107BCC37AEA49A75FD94AA3E07CB099F51A@pacpbsex01.pac.dfo-mpo.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/82561fc4/attachment.pl 

From p.dalgaard at biostat.ku.dk  Wed Sep  5 00:41:45 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 05 Sep 2007 00:41:45 +0200
Subject: [R] Q: selecting a name when it is known as a string
In-Reply-To: <46DDD8CF.6010005@gmail.com>
References: <46DDD8CF.6010005@gmail.com>
Message-ID: <46DDDF29.2020505@biostat.ku.dk>

D. R. Evans wrote:
> I am 100% certain that there is an easy way to do this, but after
> experimenting off and on for a couple of days, and searching everywhere I
> could think of, I haven't been able to find the trick.
>
> I have this piece of code:
>
> ...
>   attach(d)
>
>   if (ORDINATE == 'ds')
>   { lo <- loess(percent ~ ncms * ds, d, control=loess.control(trace.hat =
> 'approximate'))
>     grid <- data.frame(expand.grid(ds=MINVAL:MAXVAL, ncms=MINCMS:MAXCMS))
> ...
>
> then there several almost-identical "if" statements for different values of
> ORDINATE. For example, the next "if" statement starts with:
>
> ...
>   if (ORDINATE == 'dsl')
>   { lo <- loess(percent ~ ncms * dsl, d, control=loess.control(trace.hat =
> 'approximate'))
>     grid <- data.frame(expand.grid(dsl=MINVAL:MAXVAL, ncms=MINCMS:MAXCMS))
> ...
>
> This is obviously pretty silly code (although of course it does work).
>
> I imagine that my question is obvious: given that I have a variable,
> ORDINATE, whose value is a string, how do I re-write statements such as the
> "lo <-" and "grid <-" statements above so that they use ORDINATE instead of
> the hard-coded names "ds" and "dsl".
>
> I am almost sure (almost) that it has something to do with "deparse()", but
> I couldn't find the right incantation, and the ?deparse() help left my head
> swimming.
>   

myvar <- 12345
vname <- "myvar"
eval(substitute(X+54321, list(X=as.name(vname))))

However, this does not work for argument names  as in 
expand.grid(ds=.....), so for that part you may need to patch up names 
afterwards.

It is (paraphrasing Thomas Lumley) often a good idea to reconsider the 
question if the answer involves this sort of trickery. Perhaps it is 
better handled by a loop or lapply over a list of variables?


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From tplate at acm.org  Wed Sep  5 00:46:17 2007
From: tplate at acm.org (Tony Plate)
Date: Tue, 04 Sep 2007 16:46:17 -0600
Subject: [R] Q: selecting a name when it is known as a string
In-Reply-To: <46DDD8CF.6010005@gmail.com>
References: <46DDD8CF.6010005@gmail.com>
Message-ID: <46DDE039.1080508@acm.org>

You can use substitute() for this.  The drawback with this approach is 
that the formula in the call in the printed value of loess() is ugly.

 > x <- data.frame(y=rnorm(20), x1=rnorm(20), x2=rnorm(20))
 > loess(y~x2, data=x)
Call:
loess(formula = y ~ x2, data = x)

Number of Observations: 20
Equivalent Number of Parameters: 4.68
Residual Standard Error: 1.208
 > loess(substitute(y~X, list(X=as.name('x2'))), data=x)
Call:
loess(formula = substitute(y ~ X, list(X = as.name("x2"))), data = x)

Number of Observations: 20
Equivalent Number of Parameters: 4.68
Residual Standard Error: 1.208
 > loess(y~x1, data=x)
Call:
loess(formula = y ~ x1, data = x)

Number of Observations: 20
Equivalent Number of Parameters: 4.87
Residual Standard Error: 1.179
 > loess(substitute(y~X, list(X=as.name('x1'))), data=x)
Call:
loess(formula = substitute(y ~ X, list(X = as.name("x1"))), data = x)

Number of Observations: 20
Equivalent Number of Parameters: 4.87
Residual Standard Error: 1.179
 >

hope this helps,

Tony Plate


D. R. Evans wrote:
> I am 100% certain that there is an easy way to do this, but after
> experimenting off and on for a couple of days, and searching everywhere I
> could think of, I haven't been able to find the trick.
> 
> I have this piece of code:
> 
> ...
>   attach(d)
> 
>   if (ORDINATE == 'ds')
>   { lo <- loess(percent ~ ncms * ds, d, control=loess.control(trace.hat =
> 'approximate'))
>     grid <- data.frame(expand.grid(ds=MINVAL:MAXVAL, ncms=MINCMS:MAXCMS))
> ...
> 
> then there several almost-identical "if" statements for different values of
> ORDINATE. For example, the next "if" statement starts with:
> 
> ...
>   if (ORDINATE == 'dsl')
>   { lo <- loess(percent ~ ncms * dsl, d, control=loess.control(trace.hat =
> 'approximate'))
>     grid <- data.frame(expand.grid(dsl=MINVAL:MAXVAL, ncms=MINCMS:MAXCMS))
> ...
> 
> This is obviously pretty silly code (although of course it does work).
> 
> I imagine that my question is obvious: given that I have a variable,
> ORDINATE, whose value is a string, how do I re-write statements such as the
> "lo <-" and "grid <-" statements above so that they use ORDINATE instead of
> the hard-coded names "ds" and "dsl".
> 
> I am almost sure (almost) that it has something to do with "deparse()", but
> I couldn't find the right incantation, and the ?deparse() help left my head
> swimming.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From lisaonline882000 at gmail.com  Wed Sep  5 01:02:09 2007
From: lisaonline882000 at gmail.com (Lisa Hu)
Date: Tue, 4 Sep 2007 16:02:09 -0700
Subject: [R] Help on inverse distribution
Message-ID: <56c02acd0709041602t33d8e417q83c4d39e274f4c88@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/a52f4ba6/attachment.pl 

From crogg01 at yahoo.co.uk  Wed Sep  5 01:06:04 2007
From: crogg01 at yahoo.co.uk (crogg01)
Date: Tue, 4 Sep 2007 16:06:04 -0700 (PDT)
Subject: [R] fitCopula
In-Reply-To: <E3A68C90920A014CBB128279519B1B35042FEB87@M1WACA0030I001.cibna.msds.wachovia.net>
References: <E3A68C90920A014CBB128279519B1B35042FEB87@M1WACA0030I001.cibna.msds.wachovia.net>
Message-ID: <12488563.post@talk.nabble.com>


Looks like plenty of people have had this problem b4 you - incl myself. Might
be an issue with this function. I had better luck using the function in
QRMlib package (fit.tcopula.rank, etc). Though for some really large data
sets I had to fudge the function itself with noforce=FALSE on the Kendall
call and some removal of NaN and NA's.



Oden, Kevin wrote:
> 
> I  am using R 2.5.0 on windows XP and trying to fit copula.  I see the
> following code works for some users, however my code crashes on the
> chol.   Any suggestions?
> 
>  
> 
>>  mycop <- tCopula(param=0.5, dim=8, dispstr="ex", df=5) 
> 
>>  x <- rcopula(mycop, 1000) 
> 
>>  myfit <- fitCopula(x, mycop, c(0.6, 10), optim.control=list(trace=1),
> method="Nelder-Mead") 
> 
>   Nelder-Mead direct search function minimizer
> 
> function value for initial parameters = -1747.582044
> 
>   Scaled convergence tolerance is 2.6041e-05
> 
> Stepsize computed as 1.000000
> 
> Error in chol(x, pivot = FALSE) : the leading minor of order 2 is not
> positive definite
> 
>  
> 
> Kevin D. Oden
> 
> e: kevin.oden at wachovia.com <mailto:kevin.oden at wachovia.com> 
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/fitCopula-tf3965203.html#a12488563
Sent from the R help mailing list archive at Nabble.com.


From lisaonline882000 at gmail.com  Wed Sep  5 01:16:32 2007
From: lisaonline882000 at gmail.com (Lisa Hu)
Date: Tue, 4 Sep 2007 16:16:32 -0700
Subject: [R] Help on inverse distribution
In-Reply-To: <56c02acd0709041602t33d8e417q83c4d39e274f4c88@mail.gmail.com>
References: <56c02acd0709041602t33d8e417q83c4d39e274f4c88@mail.gmail.com>
Message-ID: <56c02acd0709041616v4471e99bufaecabc10d6e6adf@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/8e934b53/attachment.pl 

From r.turner at auckland.ac.nz  Wed Sep  5 01:23:23 2007
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 5 Sep 2007 11:23:23 +1200
Subject: [R] Help on inverse distribution
In-Reply-To: <56c02acd0709041616v4471e99bufaecabc10d6e6adf@mail.gmail.com>
References: <56c02acd0709041602t33d8e417q83c4d39e274f4c88@mail.gmail.com>
	<56c02acd0709041616v4471e99bufaecabc10d6e6adf@mail.gmail.com>
Message-ID: <9CDDB7CB-6239-48D7-ADAA-0BA1FE304BB3@auckland.ac.nz>


On 5/09/2007, at 11:16 AM, Lisa Hu wrote:

> To make it specific, I need to simulation Y with inverse beta  
> distribution,
> that is, Y~inverseF(X), where F is the CDF of beta distribution.  
> THANKS
>
> On 9/4/07, Lisa Hu <lisaonline882000 at gmail.com> wrote:
>>
>> Dear All,
>>
>> I need to use the inverse of some distributions in R for  
>> simulation, but I
>> could not find it, can anyone tell me which package I should install?
>> thanks

help.search("distribution") ====> ?Beta

######################################################################
Attention:\ This e-mail message is privileged and confidenti...{{dropped}}


From jholtman at gmail.com  Wed Sep  5 02:00:08 2007
From: jholtman at gmail.com (jim holtman)
Date: Tue, 4 Sep 2007 20:00:08 -0400
Subject: [R] data.frame loses name when constructed with one column
In-Reply-To: <001c01c7ef03$29b7a4f0$6405a8c0@MXD32803WB>
References: <001c01c7ef03$29b7a4f0$6405a8c0@MXD32803WB>
Message-ID: <644e1f320709041700l2de32025s1a19586f8fb68f2b@mail.gmail.com>

Try drop=FALSE:

> x
  out pred1 predd2
1   1   2.0    3.0
2   2   3.5    5.5
3   3   5.5   11.0
> x[,1]
[1] 1 2 3
> data.frame(x[,1])
  x...1.
1      1
2      2
3      3
> data.frame(x[,1, drop=FALSE])
  out
1   1
2   2
3   3
>


On 9/4/07, Stan Hopkins <stanhopkins at comcast.net> wrote:
> Not sure why the data.frame function does not capture the name of the column field when its being built with only one column.
>
> Can anyone help?
>
>
>
> > data
>  out pred1 predd2
> 1   1   2.0    3.0
> 2   2   3.5    5.5
> 3   3   5.5   11.0
> > data1=data.frame(data[,1])
> > data1
>  data...1.
> 1         1
> 2         2
> 3         3
> > data1=data.frame(data[,1:2])
> > data1
>  out pred1
> 1   1   2.0
> 2   2   3.5
> 3   3   5.5
> > sessionInfo()
> R version 2.5.1 (2007-06-27)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> [7] "base"
> >
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From deepayan.sarkar at gmail.com  Wed Sep  5 02:00:24 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 4 Sep 2007 17:00:24 -0700
Subject: [R] lattice xyplot with bty="l"
In-Reply-To: <87abs2cgu3.fsf@pdrechsler.de>
References: <87abs2cgu3.fsf@pdrechsler.de>
Message-ID: <eb555e660709041700q69421ee5geb69b5fdab652578@mail.gmail.com>

On 9/4/07, Patrick Drechsler <patrick at pdrechsler.de> wrote:
> Hi,
>
> what is the correct way of removing the "top" and "right" axes
> completely from a lattice xyplot? I would like to have a plot similar
> to using the bty="l" option for traditional plots.

There is no direct analog (and I think it would be weird in a
multipanel plot). Combining a few different features, you can do:

library(grid)

xyplot(1:10 ~ 1:10, scales = list(col = "black", tck = c(1, 0)),
       par.settings = list(axis.line = list(col = "transparent")),
       axis = function(side, ...) {
           if (side == "left")
                grid.lines(x = c(0, 0), y = c(0, 1),
                           default.units = "npc")
           else if (side == "bottom")
                grid.lines(x = c(0, 1), y = c(0, 0),
                           default.units = "npc")
           axis.default(side = side, ...)
       })

-Deepayan


>
> An example:
>
> --8<---------------cut here---------------start------------->8---
> rm(list=c(ls()))
> library(lattice)
>
> y <- 1:10
> x <- y
>
> ## Traditional plot:
> plot(x, y, bty = "l")
>
> ## Lattice plot 1:
> xyplot(y ~ x,
>        panel = function(x, y, ...){
>          panel.xyplot(x, y, ...)
>          panel.axis(side = c("left", "bottom"))
>        }
>        )
>
> ## Lattice plot 2:
> xyplot(y ~ x,
>        ## This just tries to remove all y axes:
>        scales = list(y = list(draw = FALSE))
>        )
> --8<---------------cut here---------------end--------------->8---
>
> Thankful for any pointers,
>
> Patrick
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From h.wickham at gmail.com  Wed Sep  5 02:05:48 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 4 Sep 2007 19:05:48 -0500
Subject: [R] Lattice: panel superpose with groups
In-Reply-To: <63F107BCC37AEA49A75FD94AA3E07CB099F51A@pacpbsex01.pac.dfo-mpo.ca>
References: <63F107BCC37AEA49A75FD94AA3E07CB099F513@pacpbsex01.pac.dfo-mpo.ca>
	<63F107BCC37AEA49A75FD94AA3E07CB099F51A@pacpbsex01.pac.dfo-mpo.ca>
Message-ID: <f8e6ff050709041705i5f594c71rff6cf55efd9d7eb0@mail.gmail.com>

Hi Michael,

It's not lattice, but you can easily do this with ggplot2:

install.packages("ggplot2")
library(ggplot2)
qplot(year, yvar, data=df, facets = . ~ week, colour=factor(temp),
geom="line") +
stat_summary(aes(group=1), geom="line", fun="mean", size=2)

Although you don't (currently) get the nice tabular layout of the
panels like in lattice.  You can find out more about ggplot2 at
http://had.co.nz/ggplot2

Hadley

On 9/4/07, Folkes, Michael <FolkesM at pac.dfo-mpo.gc.ca> wrote:
> The example code below allows the plotting of three different groups per panel.  I can't fathom how to write the panel function to add an additional line for each group, which in this case is just the mean Y value for each group within  each panel.  (i.e. there'd be six lines per panel.)
> Spent all day working on it and searching the archives to no avail!  Yikes.
> Any help would be greatly appreciated!
> Michael Folkes
>
> #________________________
> #This builds fake dataset
>
> years<-2000:2006
> weeks<-1:20
> yr<-rep(years,rep(length(weeks)*6,length(years)))
> wk<-rep(weeks,rep(6,length(weeks)))
> temp<-rep(4:9,length(years)*length(weeks))
> yvar<-round(rnorm(length(years)*length(weeks)*6,mean=30,sd=4),0)
> xvar<-(rnorm(length(years)*length(weeks)*6)+5)/10
>
> df<-data.frame(year=yr,week=wk,temp=temp,       yvar=yvar,      xvar=xvar)
> #________________________
>
> library(lattice)
> df$year2<-as.factor(df$year)
> df$week2<-as.factor(df$week)
> df<-df[df$temp %in% c(5,7,9),]
> xyplot(yvar~year|week2,data=df,layout = c(4, 5), as.table=TRUE,
>         type='l',
>         groups=temp ,
>       panel = function(x, y,groups, ...) {
>                 panel.superpose(x,y,groups,...)
>                 panel.xyplot(x,rep(mean(y),length(x)),type='l',lty=3) #<- only generates the panel mean
>       }
> )
>
> _______________________________________________________
> Michael Folkes
> Salmon Stock Assessment
> Canadian Dept. of Fisheries & Oceans
> Pacific Biological Station
> 3190 Hammond Bay Rd.
> Nanaimo, B.C., Canada
> V9T-6N7
> Ph (250) 756-7264 Fax (250) 756-7053  folkesm at pac.dfo-mpo.gc.ca
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
http://had.co.nz/


From deepayan.sarkar at gmail.com  Wed Sep  5 02:11:19 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 4 Sep 2007 17:11:19 -0700
Subject: [R] Lattice: panel superpose with groups
In-Reply-To: <63F107BCC37AEA49A75FD94AA3E07CB099F51A@pacpbsex01.pac.dfo-mpo.ca>
References: <63F107BCC37AEA49A75FD94AA3E07CB099F513@pacpbsex01.pac.dfo-mpo.ca>
	<63F107BCC37AEA49A75FD94AA3E07CB099F51A@pacpbsex01.pac.dfo-mpo.ca>
Message-ID: <eb555e660709041711s31fbc857xb043e8a678cec03d@mail.gmail.com>

On 9/4/07, Folkes, Michael <FolkesM at pac.dfo-mpo.gc.ca> wrote:
> The example code below allows the plotting of three different groups per panel.  I can't fathom how to write the panel function to add an additional line for each group, which in this case is just the mean Y value for each group within  each panel.  (i.e. there'd be six lines per panel.)
> Spent all day working on it and searching the archives to no avail!  Yikes.
> Any help would be greatly appreciated!


xyplot(yvar~year|week2,data=df,layout = c(4, 5), as.table=TRUE,
       type='l',
       groups = temp ,
       panel = panel.superpose,
       panel.groups = function(x, y, ..., lty) {
               panel.xyplot(x, y, ..., lty = lty)
               #panel.lines(x, rep(mean(y),length(x)), lty=3, ...) # or
               panel.abline(h = mean(y), lty=3, ...)
       })

(see ?panel.superpose for explanation)

-Deepayan

> Michael Folkes
>
> #________________________
> #This builds fake dataset
>
> years<-2000:2006
> weeks<-1:20
> yr<-rep(years,rep(length(weeks)*6,length(years)))
> wk<-rep(weeks,rep(6,length(weeks)))
> temp<-rep(4:9,length(years)*length(weeks))
> yvar<-round(rnorm(length(years)*length(weeks)*6,mean=30,sd=4),0)
> xvar<-(rnorm(length(years)*length(weeks)*6)+5)/10
>
> df<-data.frame(year=yr,week=wk,temp=temp,       yvar=yvar,      xvar=xvar)
> #________________________
>
> library(lattice)
> df$year2<-as.factor(df$year)
> df$week2<-as.factor(df$week)
> df<-df[df$temp %in% c(5,7,9),]
> xyplot(yvar~year|week2,data=df,layout = c(4, 5), as.table=TRUE,
>         type='l',
>         groups=temp ,
>       panel = function(x, y,groups, ...) {
>                 panel.superpose(x,y,groups,...)
>                 panel.xyplot(x,rep(mean(y),length(x)),type='l',lty=3) #<- only generates the panel mean
>       }
> )



>
> _______________________________________________________
> Michael Folkes
> Salmon Stock Assessment
> Canadian Dept. of Fisheries & Oceans
> Pacific Biological Station
> 3190 Hammond Bay Rd.
> Nanaimo, B.C., Canada
> V9T-6N7
> Ph (250) 756-7264 Fax (250) 756-7053  folkesm at pac.dfo-mpo.gc.ca
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m_olshansky at yahoo.com  Wed Sep  5 02:30:11 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Tue, 4 Sep 2007 17:30:11 -0700 (PDT)
Subject: [R] interpolation
In-Reply-To: <71cc5ca20709040805x7af120c4s8a09a4feef5dab56@mail.gmail.com>
Message-ID: <274436.51345.qm@web32215.mail.mud.yahoo.com>

If your data is in data.txt file you can do the
following:

x <- read.table(file="data.txt",header=TRUE)
t<-ISOdatetime(x[,1],x[,2],x[,3],x[,4],x[,5],x[,6])
secs <- as.numeric(t)

So now secs represents your time in seconds and you
can use any type of interpolation you wish to
interpolate co2obs.

--- Yogesh Tiwari <yogesh.mpi at googlemail.com> wrote:

> Hello R Users,
> 
> I am new to R and I have simple problem for R users.
> 
> I have CO2 observations defined on time
> axis(yr,mo,day,hr,min,sec). (DATA
> ATTACHED HERE)
> 
> First I want to convert time axis as one axis as
> 'hour' on regular interval
> as 1 hour. Say 00 hrs to 24hrs(jan1), 25hrs to
> 48hrs(jan2) and so on.
> 
> Then I want to interpolate CO2 at every hour.
> 
> Kindly anybody can help,
> 
> Many thanks,
> 
> Regards,
> Yogesh
> > yr	mo	dy	hr	min	sec	co2obs
> 1998	1	9	0	35	24	365.19
> 1998	1	9	1	17	39	363.54
> 1998	1	9	1	58	41	364.24
> 1998	1	9	2	39	42	364.88
> 1998	1	9	3	20	43	365.06
> 1998	1	9	4	1	44	364.75
> 1998	1	9	4	42	45	364.77
> 1998	1	9	5	23	46	364.87
> 1998	1	9	6	4	51	364.77
> 1998	1	9	6	45	52	364.73
> 1998	1	9	7	26	54	364.76
> 1998	1	9	8	7	55	363.49
> 1998	1	23	1	6	16	364.31
> 1998	1	23	1	48	32	364.38
> 1998	1	23	2	29	33	364.67
> 1998	1	23	3	10	35	365.53
> 1998	1	23	3	51	36	365.16
> 1998	1	23	4	32	37	364.56
> 1998	1	23	5	13	40	364.62
> 1998	1	23	5	54	41	365.05
> 1998	1	23	6	35	42	365.13
> 1998	1	23	7	16	44	365.45
> 1998	1	23	7	57	49	364.77
> 1998	1	23	8	38	49	364.65
> 1998	2	3	0	44	21	362.43
> 1998	2	3	1	26	36	363.96
> 1998	2	3	2	7	38	364.59
> 1998	2	3	2	48	40	364.62
> 1998	2	3	3	29	40	366.22
> 1998	2	3	4	10	41	365.4
> 1998	2	3	4	51	41	365.34
> 1998	2	3	5	32	42	365.31
> 1998	2	3	6	13	44	364.84
> 1998	2	3	6	54	46	365.07
> 1998	2	3	7	35	51	364.84
> 1998	2	3	8	16	50	364.81
> 1998	2	19	0	35	14	363.41
> 1998	2	19	1	17	31	362.93
> 1998	2	19	1	58	32	363.86
> 1998	2	19	2	39	33	364.87
> 1998	2	19	3	20	34	366.05
> 1998	2	19	4	1	36	364.84
> 1998	2	19	4	42	36	364.77
> 1998	2	19	5	23	37	365.01
> 1998	2	19	6	4	39	365
> 1998	2	19	6	45	39	365.9
> 1998	2	19	7	26	40	366.24
> 1998	2	19	8	7	41	366.55
> 1998	3	5	0	50	20	363.13
> 1998	3	5	1	32	37	363.6
> 1998	3	5	2	13	39	364.26
> 1998	3	5	2	54	40	364.26
> 1998	3	5	3	35	41	364.39
> 1998	3	5	4	16	42	365.24
> 1998	3	5	4	57	42	365.48
> 1998	3	5	5	38	43	365.01
> 1998	3	5	6	19	44	365.43
> 1998	3	5	7	0	45	365.11
> 1998	3	5	7	41	46	368.54
> 1998	3	5	8	22	48	364.96
> 1998	3	19	0	46	36	363.25
> 1998	3	19	1	28	51	363.8
> 1998	3	19	2	9	53	364.21
> 1998	3	19	2	50	55	364.46
> 1998	3	19	3	31	58	365.61
> 1998	3	19	4	12	59	365.57
> 1998	3	19	4	53	59	365.53
> 1998	3	19	5	35	0	365.38
> 1998	3	19	6	16	3	366.23
> 1998	3	19	6	57	4	364.28
> 1998	3	19	7	38	6	367.08
> 1998	3	19	8	19	5	369.19
> 1998	4	2	1	8	1	363.76
> 1998	4	2	1	50	17	365.14
> 1998	4	2	2	31	18	365.26
> 1998	4	2	3	12	21	364.7
> 1998	4	2	3	53	24	364.04
> 1998	4	2	4	34	25	366.13
> 1998	4	2	5	15	25	366.11
> 1998	4	2	5	56	26	366.34
> 1998	4	2	6	37	27	367.9
> 1998	4	2	7	18	28	367.3
> 1998	4	2	7	59	30	367.02
> 1998	4	2	8	40	35	367.6
> 1998	4	16	0	43	37	364.53
> 1998	4	16	1	25	51	364.09
> 1998	4	16	2	6	53	365.12
> 1998	4	16	2	47	55	365.41
> 1998	4	16	3	28	57	365.4
> 1998	4	16	4	9	57	365.24
> 1998	4	24	0	45	51	364.34
> 1998	4	24	1	28	5	364.78
> 1998	4	24	2	9	7	364.78
> 1998	4	24	2	50	9	364.99
> 1998	4	24	3	31	10	364.62
> 1998	4	24	4	12	11	365.86
> 1998	4	24	4	53	12	367.95
> 1998	4	24	5	34	13	367.97
> 1998	4	24	6	15	17	367.19
> 1998	4	24	6	56	18	368.56
> 1998	4	24	7	37	20	370.28
> 1998	4	24	8	18	20	369.23
> 1998	5	7	0	46	14	364.62
> 1998	5	7	1	28	28	365.45
> 1998	5	7	2	9	29	365.22
> 1998	5	7	2	50	31	365.77
> 1998	5	7	3	31	31	365.87
> 1998	5	7	4	12	33	366.1
> 1998	5	7	4	53	34	366.07
> 1998	5	7	5	34	34	369.69
> 1998	5	7	6	15	36	369.66
> 1998	5	7	6	56	38	370.46
> 1998	5	7	7	37	39	368.98
> 1998	5	7	8	18	40	368.6
> 1998	5	21	0	27	3	367.12
> 1998	5	21	1	9	18	366.16
> 1998	5	21	1	50	19	367.27
> 1998	5	21	2	31	20	366.22
> 1998	5	21	3	12	22	368.61
> 1998	5	21	3	53	24	367.24
> 1998	5	21	4	34	24	366.84
> 1998	5	21	5	15	25	370.65
> 1998	5	21	5	56	27	369
> 1998	5	21	6	37	28	369.96
> 1998	5	21	7	18	31	369.58
> 1998	5	21	7	59	32	368.42
> 1998	6	4	0	46	12	365.12
> 1998	6	4	1	28	27	366.55
> 1998	6	4	2	9	27	366.1
> 1998	6	4	2	50	28	366.98
> 1998	6	4	3	31	30	367.69
> 1998	6	4	4	12	31	366.79
> 1998	6	4	4	53	31	368.43
> 1998	6	4	5	34	32	368.46
> 1998	6	4	6	15	34	368.71
> 1998	6	4	6	56	35	369.91
> 1998	6	4	7	37	36	368.71
> 1998	6	4	8	18	38	369.38
> 1998	6	18	0	30	55	365.16
> 1998	6	18	1	13	10	366.67
> 1998	6	18	1	54	13	365.79
> 1998	6	18	2	35	14	366.48
> 1998	6	18	3	16	15	366.79
> 1998	6	18	3	57	16	367.88
> 1998	6	18	4	38	16	367.84
> 1998	6	18	5	19	17	368.39
> 1998	6	18	6	0	18	368.65
> 1998	6	18	6	41	20	368.8
> 1998	6	18	7	22	20	368.37
> 1998	6	18	8	3	21	367.93
> 1998	7	12	0	34	47	365.17
> 1998	7	12	1	17	2	366.45
> 1998	7	12	1	58	2	366.72
> 1998	7	12	2	39	2	366.23
> 1998	7	12	3	20	3	366.31
> 1998	7	12	4	1	5	367.07
> 1998	7	12	4	42	7	367.44
> 1998	7	12	5	23	10	366.94
> 1998	7	12	6	4	12	367.27
> 1998	7	12	6	45	13	367.45
> 1998	7	12	7	26	15	366.59
> 1998	7	12	8	7	15	365.04
> 1998	7	23	0	43	7	367.07
> 1998	7	23	1	25	22	366.46
> 1998	7	23	2	6	22	366.27
> 1998	7	23	2	47	23	365.89
> 1998	7	23	3	28	26	365.74
> 1998	7	23	4	9	27	366.39
> 1998	7	23	4	50	28	366.63
> 1998	7	23	5	31	29	366.51
> 1998	7	23	6	12	32	366.5
> 1998	7	23	6	53	33	365.7
> 1998	7	23	7	34	34	365.21
> 1998	7	23	8	15	35	364.58
> 1998	8	6	1	16	54	366.86
> 1998	8	6	1	59	10	366.19
> 1998	8	6	2	40	12	366.5
> 1998	8	6	3	21	13	366.14
> 1998	8	6	4	2	15	366.11
> 1998	8	6	4	43	16	366.2
> 1998	8	6	5	24	16	366.63
> 1998	8	6	6	5	18	366.38
> 1998	8	6	6	46	19	364.87
> 1998	8	6	7	27	20	363.89
> 1998	8	6	8	8	22	364.76
> 1998	8	6	8	49	22	363.34
> 1998	8	20	1	4	3	366.07
> 1998	8	20	1	46	17	366.21
> 1998	8	20	2	27	18	365.33
> 1998	8	20	3	8	19	365.86
> 1998	8	20	3	49	20	366.24
> 1998	8	20	4	30	23	366.6
> 1998	8	20	5	11	24	366.05
> 1998	8	20	5	52	24	366.27
> 1998	8	20	6	33	26	364.84
> 1998	8	20	7	14	27	364.47
> 1998	8	20	7	55	29	364.63
> 1998	8	20	8	36	30	364.82
> 1998	9	11	0	39	33	366.17
> 1998	9	11	1	21	48	366.52
> 
=== message truncated ===>
______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From FolkesM at pac.dfo-mpo.gc.ca  Wed Sep  5 02:40:23 2007
From: FolkesM at pac.dfo-mpo.gc.ca (Folkes, Michael)
Date: Tue, 4 Sep 2007 17:40:23 -0700
Subject: [R] Lattice: panel superpose with groups
In-Reply-To: <eb555e660709041711s31fbc857xb043e8a678cec03d@mail.gmail.com>
Message-ID: <63F107BCC37AEA49A75FD94AA3E07CB099F51E@pacpbsex01.pac.dfo-mpo.ca>

Thank you again Deepayan.  I was failing to grasp that I could use
panel.groups as a function.  But additionally it's still not intuitive
to me where and when I should use "..." to pass arguments on.
Additionally, as to why the panel.group function needs to pass the 'lty'
argument isn't terribly clear to me! Perhaps it will become clear with
time.
I greatly appreciate your patience and assistance.
Thanks all,
Michael Folkes

-----Original Message-----
From: Deepayan Sarkar [mailto:deepayan.sarkar at gmail.com] 
Sent: September 4, 2007 5:11 PM
To: Folkes, Michael
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Lattice: panel superpose with groups


On 9/4/07, Folkes, Michael <FolkesM at pac.dfo-mpo.gc.ca> wrote:
> The example code below allows the plotting of three different groups 
> per panel.  I can't fathom how to write the panel function to add an 
> additional line for each group, which in this case is just the mean Y 
> value for each group within  each panel.  (i.e. there'd be six lines 
> per panel.) Spent all day working on it and searching the archives to 
> no avail!  Yikes. Any help would be greatly appreciated!


xyplot(yvar~year|week2,data=df,layout = c(4, 5), as.table=TRUE,
       type='l',
       groups = temp ,
       panel = panel.superpose,
       panel.groups = function(x, y, ..., lty) {
               panel.xyplot(x, y, ..., lty = lty)
               #panel.lines(x, rep(mean(y),length(x)), lty=3, ...) # or
               panel.abline(h = mean(y), lty=3, ...)
       })

(see ?panel.superpose for explanation)

-Deepayan

> Michael Folkes
>
> #________________________
> #This builds fake dataset
>
> years<-2000:2006
> weeks<-1:20
> yr<-rep(years,rep(length(weeks)*6,length(years)))
> wk<-rep(weeks,rep(6,length(weeks)))
> temp<-rep(4:9,length(years)*length(weeks))
> yvar<-round(rnorm(length(years)*length(weeks)*6,mean=30,sd=4),0)
> xvar<-(rnorm(length(years)*length(weeks)*6)+5)/10
>
> df<-data.frame(year=yr,week=wk,temp=temp,       yvar=yvar,
xvar=xvar)
> #________________________
>
> library(lattice)
> df$year2<-as.factor(df$year)
> df$week2<-as.factor(df$week)
> df<-df[df$temp %in% c(5,7,9),] xyplot(yvar~year|week2,data=df,layout =

> c(4, 5), as.table=TRUE,
>         type='l',
>         groups=temp ,
>       panel = function(x, y,groups, ...) {
>                 panel.superpose(x,y,groups,...)
>                 panel.xyplot(x,rep(mean(y),length(x)),type='l',lty=3)
#<- only generates the panel mean
>       }
> )



>
> _______________________________________________________
> Michael Folkes
> Salmon Stock Assessment
> Canadian Dept. of Fisheries & Oceans
> Pacific Biological Station
> 3190 Hammond Bay Rd.
> Nanaimo, B.C., Canada
> V9T-6N7
> Ph (250) 756-7264 Fax (250) 756-7053  folkesm at pac.dfo-mpo.gc.ca
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From deepayan.sarkar at gmail.com  Wed Sep  5 02:54:06 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 4 Sep 2007 17:54:06 -0700
Subject: [R] Lattice: panel superpose with groups
In-Reply-To: <63F107BCC37AEA49A75FD94AA3E07CB099F51E@pacpbsex01.pac.dfo-mpo.ca>
References: <eb555e660709041711s31fbc857xb043e8a678cec03d@mail.gmail.com>
	<63F107BCC37AEA49A75FD94AA3E07CB099F51E@pacpbsex01.pac.dfo-mpo.ca>
Message-ID: <eb555e660709041754o4982867eq8ee85f3342fc761a@mail.gmail.com>

On 9/4/07, Folkes, Michael <FolkesM at pac.dfo-mpo.gc.ca> wrote:

> Thank you again Deepayan.  I was failing to grasp that I could use
> panel.groups as a function.  But additionally it's still not intuitive
> to me where and when I should use "..." to pass arguments on.

In most cases, it's used to pass on graphical parameters, so I tend to
have the ... by default (which means you can supply graphical
parameters directly as arguments to xyplot). This is particularly
non-trivial in panel.groups, because panel.superpose does a lot of
work to replicate the parameters and pass on a different one for each
call to panel.groups.

> Additionally, as to why the panel.group function needs to pass the 'lty'
> argument isn't terribly clear to me!

Try not having it and you will find out. Basically, if you don't have
it, the explicit lty=3 in the call to panel.abline will conflict with
the lty passed on through ...

-Deepayan


From mkimpel at iupui.edu  Wed Sep  5 05:13:40 2007
From: mkimpel at iupui.edu (Mark W Kimpel)
Date: Tue, 04 Sep 2007 23:13:40 -0400
Subject: [R] problem formatting and positioning title in heatmap
Message-ID: <46DE1EE4.6020207@iupui.edu>

I am using heatmap with the arguments below. The title size stays the 
same no matter what I set cex.main to. Is this expected? Can I adjust 
the title size in heatmap?

Also, the position of the main title is at the very upper edge of the 
output and if I use a "\n" to stack the title the upper line is out of 
bounds and doesn't show up.

I am outputting to pdf.

Any help? Thanks, Mark

heatmap(x = dataM, RowSideColors = RowSideColors, 
ColSideColors=ColSideColors, main = title,
           margins = c(50,50), scale= do.scale ,labRow=geneNames, 
labCol=colLabels, col = hmcol, cex.main = 1,
           cexRow = row.lab.mag, cexCol = col.lab.mag)

 > sessionInfo()
R version 2.6.0 Under development (unstable) (2007-08-29 r42686)
i686-pc-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] splines   tools     stats     graphics  grDevices utils     datasets
[8] methods   base

other attached packages:
  [1] RColorBrewer_1.0-1     MergeMaid_2.9.0        MASS_7.2-36
  [4] rat2302_1.17.0         rat2302cdf_1.17.0      affycoretools_1.9.4
  [7] annaffy_1.9.1          KEGG_1.17.1            GO_1.99.1
[10] xtable_1.5-1           gcrma_2.9.1            matchprobes_1.9.10
[13] biomaRt_1.11.4         RCurl_0.8-3            XML_1.92-1
[16] GOstats_2.3.16         Category_2.3.30        genefilter_1.15.11
[19] survival_2.32          RBGL_1.13.6            annotate_1.15.6
[22] GO.db_1.99.1           AnnotationDbi_0.1.12   RSQLite_0.6-0
[25] DBI_0.2-3              limma_2.11.11          affy_1.15.7
[28] preprocessCore_0.99.12 affyio_1.5.8           Biobase_1.15.30
[31] graph_1.15.14

loaded via a namespace (and not attached):
[1] cluster_1.11.7

-- 

---

Mark W. Kimpel MD  ** Neuroinformatics ** Dept. of Psychiatry
Indiana University School of Medicine

15032 Hunter Court, Westfield, IN  46074

(317) 490-5129 Work, & Mobile & VoiceMail
(317) 663-0513 Home (no voice mail please)


From bernd.weiss at uni-koeln.de  Wed Sep  5 06:47:50 2007
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Wed, 05 Sep 2007 06:47:50 +0200
Subject: [R] [Lattice] Incrase the height of strips in Trellis plots
Message-ID: <46DE34F6.8070703@uni-koeln.de>

Dear all,

I wonder how to increase the height of strips via strip.default or
strip.custom. The following example hopefully illustrates the difficulty
I am facing:

library(lattice)
xyplot(Petal.Length ~ Petal.Width | Species, iris,
        strip = strip.custom(par.strip.text = list(cex = 2)))

Thanks for any advice,

Bernd


> version
               _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          5.1
year           2007
month          06
day            27
svn rev        42083
language       R
version.string R version 2.5.1 (2007-06-27)


From gsrwork at yahoo.com  Tue Sep  4 18:19:54 2007
From: gsrwork at yahoo.com (Abdus Sattar)
Date: Tue, 4 Sep 2007 09:19:54 -0700 (PDT)
Subject: [R] Fitting Pattern-Mixture Models
Message-ID: <801653.2748.qm@web58414.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070904/c6883ae2/attachment.pl 

From paul at stat.auckland.ac.nz  Wed Sep  5 08:54:35 2007
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Wed, 05 Sep 2007 08:54:35 +0200
Subject: [R] Embedding Audio Files in Interactive Graphs
In-Reply-To: <509e0620709040738i7354416cv2b54c8f160a46fd7@mail.gmail.com>
References: <JNS7XP$5CF16C227C4387091711DE17B6E0E27C@libero.it>	<D9A5BE6F-47BB-48B8-A49D-EEE608A7F4A2@ihug.com.au>
	<509e0620709040738i7354416cv2b54c8f160a46fd7@mail.gmail.com>
Message-ID: <46DE52AB.9040102@stat.auckland.ac.nz>

Hi


Michael Lawrence wrote:
> On 9/4/07, Sam Ferguson <thefishfinger at ihug.com.au > wrote:
>> Thanks for your reply Bruno.
>>
>> No - as I said, I know how to do that - the movie15 and the
>> multimedia package are basically the same, and it is relatively
>> straightforward to get an audio file into a pdf with them. However,
>> real interactivity is not easily achieved in latex IMO (as it's not
>> its purpose). At least I'm hoping for a bit more flexibility.
>>
>> R seems like a better place to do interactivity, and with the field
>> of information visualisation pointing out that interactivity is a
>> very useful element for investigation of data it seems that clicking
>> around graphical displays may become more and more popular in time.
>> In my field I'm interested in audio data, and so simple interactive
>> visual and auditory displays would be great. A (very useful) start
>> would be 5 separate waveform plots that would play their appropriate
>> sounds when clicked. More complex figures could plot in a 2d space
>> and allow selection of data points or ranges perhaps.
>>
>> I love R for graphics and for Sweave though, and would like to use it
>> if possible - ideally it would be to produce a figure that included
>> the appropriate audiofiles and interactive scripts, which could then
>> be incorporated into a latex document \includegraphics. However, from
>> the deafening silence on this list it seems like I may be attempting
>> to push a square block through a round hole unfortunately. Seems I am
>> back to Matlab and handle graphics - but it won't do this properly
>> either.
> 
> 
> Lots of things can be embedded into PDF documents, like javascript, flash
> and svg. Maybe it would be feasible to use the gridSVG package to output
> some graphics as svg with javascript to play the sounds and embed that into
> a pdf?


The short answer is that R cannot do this sort of thing and is unlikely 
to be able to do it anytime soon.

The basic problem is that core R graphics has no concept of animation, 
audio, hyperlinks, etc AND there is no way to access these features on 
devices that do have these concepts (e.g., PDF).  It would be nice to 
change that, but it is a large redesign problem that is not anywhere 
near the top of anyone's todo list (to my knowledge).

As Michael mentioned, the gridSVG package allows you to draw using the 
grid package and access some of the fancier SVG features (including 
embedding scripts).  It has its own problems of course, but may be worth 
trying.

Paul


> Cheers
>> Sam
>>
>>
>> On 03/09/2007, at 5:39 PM, Bruno C.. wrote:
>>
>>> Are you asking on how to include an  audio file into a pdf?
>>> This is already feasible via latex and the movie 15 package ;)
>>>
>>> Ciao
>>>
>>>> Hi R-ers,
>>>>
>>>> I'm wondering if anyone has investigated a method for embedding audio
>>>> files in R graphs (pdf format), and allowing their playback to be
>>>> triggered interactively (by clicking on a graph element for
>>>> instance).
>>>>
>>>> I know how to do this in latex pdfs with the multimedia package, but
>>>> it seems that R would provide a more appropriate platform for many
>>>> reasons.
>>>>
>>>> Thanks for any help you can provide.
>>>> Sam Ferguson
>>>> Faculty of Architecture, Design and Planning
>>>> The University of Sydney
>>>>
>>>> ______________________________________________
>>>> R-help at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>>> guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> ------------------------------------------------------
>>> Leggi GRATIS le tue mail con il telefonino i-mode? di Wind
>>> http://i-mode.wind.it/
>>>
>> --
>> Sam Ferguson
>> Faculty of Architecture
>> The University of Sydney
>> sferguson at arch.usyd.edu.au
>> +61 2 93515910
>> 0410 719535
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From FredeA.Togersen at agrsci.dk  Wed Sep  5 09:19:57 2007
From: FredeA.Togersen at agrsci.dk (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 5 Sep 2007 09:19:57 +0200
Subject: [R] [Lattice] Incrase the height of strips in Trellis plots
In-Reply-To: <46DE34F6.8070703@uni-koeln.de>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC055ADF8A@DJFPOST01.djf.agrsci.dk>

This should give you something close to what you want:


xyplot(Petal.Length ~ Petal.Width | Species, iris,
       strip = strip.custom(par.strip.text = list(cex = 2)),
       par.settings = list(layout.heights=list(strip=1.45)))

The par.settings argument alters locally the default par settings of lattice plots, see e.g. ?trellis.par.get and the ?xyplot about the par.settings argument.

A closer inspection (try using strip = 2 or numbers less than 1.45 in stead of strip = 1.45) of the figure reveals that there are some problems with vertical alignment of the strip text, i.e. not centered. 

To remedy this I think that you have to use you own strip function. You may be able to build you own function by altering the default strip function, see ?lattice.options and try lattice.options() at the command prompt. However this may be more difficult than it seems at first. Perhaps some one more familiar with the lattice package can solve this.
 

Best regards

Frede Aakmann T?gersen
Scientist


UNIVERSITY OF AARHUS
Faculty of Agricultural Sciences
Dept. of Genetics and Biotechnology
Blichers All? 20, P.O. BOX 50
DK-8830 Tjele

Phone:   +45 8999 1900
Direct:  +45 8999 1878

E-mail:  FredeA.Togersen at agrsci.dk
Web:	   http://www.agrsci.org				

This email may contain information that is confidential.
Any use or publication of this email without written permission from Faculty of Agricultural Sciences is not allowed.
If you are not the intended recipient, please notify Faculty of Agricultural Sciences immediately and delete this email.


 

> -----Oprindelig meddelelse-----
> Fra: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] P? vegne af Bernd Weiss
> Sendt: 5. september 2007 06:48
> Til: r-help at stat.math.ethz.ch
> Emne: [R] [Lattice] Incrase the height of strips in Trellis plots
> 
> Dear all,
> 
> I wonder how to increase the height of strips via 
> strip.default or strip.custom. The following example 
> hopefully illustrates the difficulty I am facing:
> 
> library(lattice)
> xyplot(Petal.Length ~ Petal.Width | Species, iris,
>         strip = strip.custom(par.strip.text = list(cex = 2)))
> 
> Thanks for any advice,
> 
> Bernd
> 
> 
> > version
>                _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          5.1
> year           2007
> month          06
> day            27
> svn rev        42083
> language       R
> version.string R version 2.5.1 (2007-06-27)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From lauri.nikkinen at iki.fi  Wed Sep  5 09:20:50 2007
From: lauri.nikkinen at iki.fi (Lauri Nikkinen)
Date: Wed, 5 Sep 2007 10:20:50 +0300
Subject: [R] How to extract part of an array?
Message-ID: <ba8c09910709050020w4ad69c17q51987bcbce1239f6@mail.gmail.com>

Hi,

How can I extract part of an array? I would like to extract table
Supported from this array. If this is not possible, how do I convert
array to list? I'm sorry this is not an reproducible example.

> spl <- tapply(temp$var1, list(temp$var2, temp$var3, temp$var3), mean)
> spl
, , Supported

               07       08
A        68.38710 71.48387
B        21.67742 20.83871
C        55.74194 61.12903
AL L     26.19816 27.39631

, , Not_supported

         07       08
A        NA 82.38710
B        NA 24.00000
C        NA 68.77419
ALL      NA 29.97984

-Lauri


From gustaf.rydevik at gmail.com  Wed Sep  5 09:32:03 2007
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Wed, 5 Sep 2007 09:32:03 +0200
Subject: [R] capture.out(system())?
In-Reply-To: <45f568c70709050031v19e935abgd81ead4d0b646fff@mail.gmail.com>
References: <403709.66857.qm@web23001.mail.ird.yahoo.com>
	<45f568c70709050031v19e935abgd81ead4d0b646fff@mail.gmail.com>
Message-ID: <45f568c70709050032r277bffeds518a5e6afee7b940@mail.gmail.com>

On 9/4/07, Werner Wernersen <pensterfuzzer at yahoo.de> wrote:
> Hi,
>
> I am trying to capture the console output of program I
> call via system() but that always returns only
> character(0).
>
> For example:
> capture.output(system("pdflatex out.tex") )
>
> will yield:
> character(0)
>
> and the output still written to the R console.
>
> Is there a command for intercepting this output?
>
> Thank you!
>   Werner
>

?sink()


-- 
Gustaf Rydevik, M.Sci.
tel: +46(0)703 051 451
address:Essingetorget 40,112 66 Stockholm, SE
skype:gustaf_rydevik


From bernd.weiss at uni-koeln.de  Wed Sep  5 09:44:28 2007
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Wed, 05 Sep 2007 09:44:28 +0200
Subject: [R] [Lattice] Incrase the height of strips in Trellis plots
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC055ADF8A@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC055ADF8A@DJFPOST01.djf.agrsci.dk>
Message-ID: <46DE5E5C.8090203@uni-koeln.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Frede Aakmann T?gersen schrieb:
> This should give you something close to what you want:
> 
> 
> xyplot(Petal.Length ~ Petal.Width | Species, iris,
>        strip = strip.custom(par.strip.text = list(cex = 2)),
>        par.settings = list(layout.heights=list(strip=1.45)))
> 
> The par.settings argument alters locally the default par settings of lattice plots, see e.g. ?trellis.par.get and the ?xyplot about the par.settings argument.
> 
> A closer inspection (try using strip = 2 or numbers less than 1.45 in stead of strip = 1.45) of the figure reveals that there are some problems with vertical alignment of the strip text, i.e. not centered. 
> 
> To remedy this I think that you have to use you own strip function. You may be able to build you own function by altering the default strip function, see ?lattice.options and try lattice.options() at the command prompt. However this may be more difficult than it seems at first. Perhaps some one more familiar with the lattice package can solve this.


Perfect! Thank you very much,

Bernd


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.7 (MingW32)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFG3l5cUsbvfbd00+ERAh1qAJ4tw3ZiIYnI+UF6FJeLT1xRMep/VACfR+I1
R14RJkdaFBNFqVc6kibyaRk=
=W41I
-----END PGP SIGNATURE-----


From yu.wang at pdf.com  Wed Sep  5 09:51:50 2007
From: yu.wang at pdf.com (Yu (Warren) Wang)
Date: Wed, 05 Sep 2007 15:51:50 +0800
Subject: [R] question about non-linear least squares in R
Message-ID: <46DE6016.10404@pdf.com>

Hi, everyone,
    My question is: It's not every time that you can get a converged 
result from the nls function. Is there any solution for me to get a 
reasonable result? For example:

x <- c(-0.06,-0.04,-0.025,-0.015,-0.005,0.005,0.015,0.025,0.04,0.06)

y <- 
c(1866760,1457870,1314960,1250560,1184850,1144920,1158850,1199910,1263850,1452520)

fitOup<- nls(y ~ constant + A*(x-MA)^4 + B*(x-MA)^2, 
start=list(constant=10000000, A=100000000, B=-1000000, MA=0), 
control=nls.control(maxiter=100, minFactor=1/4096), trace=TRUE)

 

 For this one, I cannot get the converged result, how can I reach it? To 
use another funtion or to modify some settings for nls?

Thank you very much!

Yours,

Warren


From deepayan.sarkar at gmail.com  Wed Sep  5 09:56:11 2007
From: deepayan.sarkar at gmail.com (deepayan.sarkar at gmail.com)
Date: Wed, 5 Sep 2007 00:56:11 -0700
Subject: [R] [Lattice] Incrase the height of strips in Trellis plots
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC055ADF8A@DJFPOST01.djf.agrsci.dk>
References: <46DE34F6.8070703@uni-koeln.de>
	<C83C5E3DEEE97E498B74729A33F6EAEC055ADF8A@DJFPOST01.djf.agrsci.dk>
Message-ID: <eb555e660709050056r402a0cfapa9039d53d9785e14@mail.gmail.com>

On 9/5/07, Frede Aakmann T?gersen <FredeA.Togersen at agrsci.dk> wrote:
> This should give you something close to what you want:
>
>
> xyplot(Petal.Length ~ Petal.Width | Species, iris,
>        strip = strip.custom(par.strip.text = list(cex = 2)),
>        par.settings = list(layout.heights=list(strip=1.45)))
>
> The par.settings argument alters locally the default par settings of lattice
> plots, see e.g. ?trellis.par.get and the ?xyplot about the par.settings
> argument.

Another possibility that predates par.settings (but is basically equivalent) is

xyplot(Petal.Length ~ Petal.Width | Species, iris,
       par.strip.text = list(lines = 2, cex = 2))

-Deepayan


From g.m.f.vanderheijden04 at leeds.ac.uk  Wed Sep  5 10:01:14 2007
From: g.m.f.vanderheijden04 at leeds.ac.uk (Geertje Van der Heijden)
Date: Wed, 5 Sep 2007 09:01:14 +0100
Subject: [R] Robust linear models and unequal variance
In-Reply-To: <00a801c7ef42$3b9a33b0$3a0b2c0a@gne.windows.gene.com>
Message-ID: <E193A286CE83354EB8BAB315F8BE62D317D592@HERMES4.ds.leeds.ac.uk>

Thanks for your reply, Bert - it was really helpful!

1. I have used a non-parametric test of variance (fligner.test) to test
whether the variances of my groups were equal or not, and they weren't.

2. Just quickly to see if I understand the weighting part - I calculate
the variance of my different group (I have two factors, so I presume
calculating it for all different combinations of these two factors
separately) and use a weight 1/variance for each of these groups in the
GLM. Right?

3. OK

4. Unfortunately my group sizes are dissimilar, with most groups being
approximately equal sample size and one group having a much higher
sample size - so best thing to do is use weights than?

Thanks again,
Geertje


~~~~
Geertje van der Heijden
PhD student
Tropical Ecology
School of Geography
University of Leeds
Leeds LS2 9JT

Tel: (+44)(0)113 3433345 
Email: g.m.f.vanderheijden04 at leeds.ac.uk


-----Original Message-----
From: Bert Gunter [mailto:gunter.berton at gene.com] 
Sent: 04 September 2007 23:24
To: Geertje Van der Heijden; r-help at stat.math.ethz.ch
Subject: RE: [R] Robust linear models and unequal variance

Let me try a reply, although I wish others wiser than I had responded.

1. How do you know the variances are unequal? 

2. If you somehow know what the variances are (or at least their
relative sizes), you can use the "weights" arguments of the functions
you mentions to weight inversely proportional to variance (except not
for the "MM" method in
rlm() according to the docs.) 

3. That "ranked regression" is robust is a myth. It also does not deal
with the unequal variance situation. It is not a panacea for anything.
If you need "robust" regression use robust regression.

4. If group sizes are not too dissimilar, than whether you case weight
or not may not make much difference (alas, hard to tell a priori).
Especially to estimation.

The fundamental issue is that "outliers" and "unequal variances" must be
operationalized, otherwise they are confounded: "outlier" only has
meaning compared to what is expected from a specified distribution.
Outliers are no longer out when the variance is "large." 

Also look at glm() with the "quasi" option if you wish to consider
fitting a heterogeneous variance structure to initialize a robust method
(which could, of course, be distorted by your "outliers").


Bert Gunter
Genentech Nonclinical Statistics

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Geertje Van der
Heijden
Sent: Tuesday, September 04, 2007 10:55 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Robust linear models and unequal variance

Hi all,

I have probably a basic question, but I can't seem to find the answer in
the literature or in the R-archives. 

I would like to do a robust ANCOVA (using either rlm or lmRob of the
MASS and robust packages) - my response variable deviates slightly from
normal and I have some "outliers". The data consist of 2 factor
variables and 3-5 covariates (fdepending on the model). However, the
variance between my groups is not equal and I am not sure if it is
therefore appropriate to use a robust statistical method or if a
non-parametric analysis (i.e. ranked regression) might be better. If I
can still use a robust statistical method, which estimator is best to
use to deal with unequal variance? And if it is better to use a
non-parametric analysis, could anyone put me in the direction of the
right non-parametric method to use (the relationship between my response
variable and the covariates is linear)?

Any help on this would be greatly appreciated!

Many thanks,
Geertje

~~~~
Geertje van der Heijden
PhD student
Tropical Ecology
School of Geography
University of Leeds
Leeds LS2 9JT

Tel: (+44)(0)113 3433345
Email: g.m.f.vanderheijden04 at leeds.ac.uk



	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Wed Sep  5 10:02:51 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Sep 2007 09:02:51 +0100 (BST)
Subject: [R] capture.out(system())?
In-Reply-To: <45f568c70709050032r277bffeds518a5e6afee7b940@mail.gmail.com>
References: <403709.66857.qm@web23001.mail.ird.yahoo.com>
	<45f568c70709050031v19e935abgd81ead4d0b646fff@mail.gmail.com>
	<45f568c70709050032r277bffeds518a5e6afee7b940@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709050859550.6594@gannet.stats.ox.ac.uk>

On Wed, 5 Sep 2007, Gustaf Rydevik wrote:

> On 9/4/07, Werner Wernersen <pensterfuzzer at yahoo.de> wrote:
>> Hi,
>>
>> I am trying to capture the console output of program I
>> call via system() but that always returns only
>> character(0).
>>
>> For example:
>> capture.output(system("pdflatex out.tex") )
>>
>> will yield:
>> character(0)
>>
>> and the output still written to the R console.
>>
>> Is there a command for intercepting this output?
>>
>> Thank you!
>>   Werner
>>
>
> ?sink()

That is used by capture.output() to capture R output, but this question is 
about output that never goes near R.

The answer is in ?system, but might depend on the unstated OS.  Arguments 
'intern' and 'show.output.on.console' are relevant.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From m_olshansky at yahoo.com  Wed Sep  5 10:33:06 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Wed, 5 Sep 2007 01:33:06 -0700 (PDT)
Subject: [R] question about non-linear least squares in R
In-Reply-To: <46DE6016.10404@pdf.com>
Message-ID: <923230.17023.qm@web32207.mail.mud.yahoo.com>

Below is one possibility:

If you knew MA you would get a regular linear
least-squares for parameters A,B and constant which
can be easily solved. So now you can define a function
f(MA) which returns that value. Now you must minimize
that f - a function of one argument. It can have
several local minima and so you must be careful but I
believe that minimizing (even "bad") function of one
argument should be easier than your original problem.

Regards,

Moshe.

P.S. if you do this I would be interested to know
whether this works.

--- "Yu (Warren) Wang" <yu.wang at pdf.com> wrote:

> Hi, everyone,
>     My question is: It's not every time that you can
> get a converged 
> result from the nls function. Is there any solution
> for me to get a 
> reasonable result? For example:
> 
> x <-
>
c(-0.06,-0.04,-0.025,-0.015,-0.005,0.005,0.015,0.025,0.04,0.06)
> 
> y <- 
>
c(1866760,1457870,1314960,1250560,1184850,1144920,1158850,1199910,1263850,1452520)
> 
> fitOup<- nls(y ~ constant + A*(x-MA)^4 + B*(x-MA)^2,
> 
> start=list(constant=10000000, A=100000000,
> B=-1000000, MA=0), 
> control=nls.control(maxiter=100, minFactor=1/4096),
> trace=TRUE)
> 
>  
> 
>  For this one, I cannot get the converged result,
> how can I reach it? To 
> use another funtion or to modify some settings for
> nls?
> 
> Thank you very much!
> 
> Yours,
> 
> Warren
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From megh700004 at yahoo.com  Wed Sep  5 10:45:20 2007
From: megh700004 at yahoo.com (Megh Dal)
Date: Wed, 5 Sep 2007 01:45:20 -0700 (PDT)
Subject: [R] Choosing the optimum lag order of ARIMA model
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A83440195792A@NYWEXMB23.msad.ms.com>
Message-ID: <883041.84879.qm@web58111.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070905/0808d047/attachment.pl 

From jim at bitwrit.com.au  Wed Sep  5 11:07:54 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 05 Sep 2007 19:07:54 +1000
Subject: [R] Pie Chart Labels
In-Reply-To: <OF7801754D.E05D332A-ON8525734C.0052B322-8525734C.0052EC4E@usgs.gov>
References: <OF7801754D.E05D332A-ON8525734C.0052B322-8525734C.0052EC4E@usgs.gov>
Message-ID: <46DE71EA.1070705@bitwrit.com.au>

Adam Green wrote:
> I am having trouble finding out how to adjust the position of labels on 
> pie charts.  For the small wedges, many of the labels overlap making it 
> impossible to read.  Is there any way to offset the labels so that they 
> don't overlap?
> 
Hi Adam,
There are three ways to adjust the positions of labels on a 3D pie chart 
(I'm assuming it's 3D from the word "wedges". If not, the following 
should still be useful).

The first is to change the position of the sectors by the "start" 
argument. Apart from being useful when very large sectors cause 
problems, changing the sector positions can sometimes alleviate minor 
crowding of the labels.

The second is to catch the return value of the pie3D function. This is 
the radial positions at which the labels have been placed. You can then 
alter this vector and pass it as the argument "labelpos". In this way 
you can spread out the labels for small sectors.

Finally, you can leave out the labels when you call pie3D and manually 
place labels using the "text" function. The chart is drawn on a plot 
that spans -1 to 1 in both directions, so it is relatively easy to work 
out where the labels should be.

A word of warning - when I read, "For the small wedges, many of the 
labels...", I felt that I should say that pie charts in general, and 3D 
ones in particular, are rarely successful with more than 4 or 5 sectors. 
In the R-news article that included pie3D, I included a pie chart that 
was very difficult for the viewer to extract the information that the 
creator intended. Depending upon what is to be represented, you might 
consider whether another method might be more successful.

Jim


From P.Dalgaard at biostat.ku.dk  Wed Sep  5 11:35:16 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 05 Sep 2007 11:35:16 +0200
Subject: [R] How to extract part of an array?
In-Reply-To: <ba8c09910709050020w4ad69c17q51987bcbce1239f6@mail.gmail.com>
References: <ba8c09910709050020w4ad69c17q51987bcbce1239f6@mail.gmail.com>
Message-ID: <46DE7854.2090204@biostat.ku.dk>

Lauri Nikkinen wrote:
> Hi,
>
> How can I extract part of an array? I would like to extract table
> Supported from this array. If this is not possible, how do I convert
> array to list? I'm sorry this is not an reproducible example.
>
>   
>> spl <- tapply(temp$var1, list(temp$var2, temp$var3, temp$var3), mean)
>> spl
>>     
> , , Supported
>
>                07       08
> A        68.38710 71.48387
> B        21.67742 20.83871
> C        55.74194 61.12903
> AL L     26.19816 27.39631
>
> , , Not_supported
>
>          07       08
> A        NA 82.38710
> B        NA 24.00000
> C        NA 68.77419
> ALL      NA 29.97984
>
>   
How about spl[,,"Supported"]?

-p

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From patrick at pdrechsler.de  Wed Sep  5 12:43:02 2007
From: patrick at pdrechsler.de (Patrick Drechsler)
Date: Wed, 05 Sep 2007 12:43:02 +0200
Subject: [R] lattice xyplot with bty="l"
References: <87abs2cgu3.fsf@pdrechsler.de>
	<eb555e660709041700q69421ee5geb69b5fdab652578@mail.gmail.com>
Message-ID: <87myw1bdft.fsf@pdrechsler.de>

"Deepayan Sarkar" <deepayan.sarkar at gmail.com> writes:

> On 9/4/07, Patrick Drechsler <patrick at pdrechsler.de> wrote:
>>
>> what is the correct way of removing the "top" and "right" axes
>> completely from a lattice xyplot? I would like to have a plot similar
>> to using the bty="l" option for traditional plots.
>
> There is no direct analog (and I think it would be weird in a
> multipanel plot). 

I agree that this is not very useful for multipanel plots.

> Combining a few different features, you can do:
>
> library(grid)
>
> xyplot(1:10 ~ 1:10, scales = list(col = "black", tck = c(1, 0)),
>        par.settings = list(axis.line = list(col = "transparent")),
>        axis = function(side, ...) {
>            if (side == "left")
>                 grid.lines(x = c(0, 0), y = c(0, 1),
>                            default.units = "npc")
>            else if (side == "bottom")
>                 grid.lines(x = c(0, 1), y = c(0, 0),
>                            default.units = "npc")
>            axis.default(side = side, ...)
>        })
>
> -Deepayan

Thank you very much Deepayan, this is exactly what I was looking for!

Cheers,

Patrick


From paoso at libero.it  Wed Sep  5 13:08:40 2007
From: paoso at libero.it (paoso at libero.it)
Date: Wed, 05 Sep 2007 13:08:40 +0200
Subject: [R] integers
Message-ID: <46DE8E38.2030707@libero.it>

> On 9/4/07, Christoph Heibl <christoph.heibl at gmx.net> wrote:
>> Hi list,
>>
>> The function is.integer tests if an object is of type integer:
>>
>> see e.g.:
>>
>> is.integer(12)  # FALSE
>> is.real(12)     # TRUE
>> mode(12)                # "numeric"
>>
>> But how can I test if a number is actually an integer? R seek is
>> difficult to search in this case because it mainly yields entries
>> about the integer()-function family.
>>
>> Thanks for any hint!
>> Christoph Heibl
> ?mode
> r = 12
> is.integer(r)
[1] FALSE
> is.double(r)
[1] TRUE
> i = as.integer(r)
> storage.mode(r)
[1] "double"
> storage.mode(i)
[1] "integer"


Paolo Sonego


From biostatistica at gmail.com  Wed Sep  5 13:15:20 2007
From: biostatistica at gmail.com (=?ISO-8859-1?Q?Niccol=F2_Bassani?=)
Date: Wed, 5 Sep 2007 13:15:20 +0200
Subject: [R] Running geeglm unstructured corstr
Message-ID: <7d82a6ca0709050415x200660dehe5cf4b171feb0c78@mail.gmail.com>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070905/6d1002c1/attachment.pl 

From ripley at stats.ox.ac.uk  Wed Sep  5 13:34:11 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 5 Sep 2007 12:34:11 +0100 (BST)
Subject: [R] Choosing the optimum lag order of ARIMA model
In-Reply-To: <883041.84879.qm@web58111.mail.re3.yahoo.com>
References: <883041.84879.qm@web58111.mail.re3.yahoo.com>
Message-ID: <Pine.LNX.4.64.0709051055440.613@gannet.stats.ox.ac.uk>

On Wed, 5 Sep 2007, Megh Dal wrote:

> Hi Leeds, Thanx for this reply. Actually I did not want to know whether 
> any differentiation is needed or not. My question was that : what is the 
> difference between two models :
>
>  arima(data, c(2,1,2))
>
>  and
>
>  arima(diff(data), c(2,0,2))
>
>  If I am correct then those two models are same. Therefore I should get 
> same results for both of the cases. Am I doing something wrong?

They are not the same.  Please do study the help page, and in particular 
the 'include.mean' argument.  One is a model for n observations and 
the other for n-1 observations, and how that affects the issue is 
discussed on the help page.  With the right options you will get similar 
but not identical results.

> arima(x, c(2,1,2), method="ML")

Coefficients:
          ar1      ar2      ma1     ma2
       0.0786  -0.3561  -0.0869  0.1272
s.e.  0.6135   0.4296   0.6564  0.4549

sigma^2 estimated as 0.01368:  log likelihood = 46.46,  aic = -82.92

> arima(diff(x), c(2,0,2), method="ML", include.mean=FALSE)

Coefficients:
          ar1      ar2      ma1     ma2
       0.0786  -0.3561  -0.0869  0.1272
s.e.  0.6135   0.4296   0.6564  0.4549

sigma^2 estimated as 0.01329:  log likelihood = 47.38,  aic = -82.76


And did you have permission to copy private (and impolite) messages from 
Mr Leeds to this list?  If you did, please say so in your own posting for 
the record.  Since I don't have such permission I have deleted them from 
this reply.

Professor Ripley

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From magno_yu at ml.com  Wed Sep  5 14:58:41 2007
From: magno_yu at ml.com (yoooooo)
Date: Wed, 5 Sep 2007 05:58:41 -0700 (PDT)
Subject: [R] plotting
In-Reply-To: <46D95E42.8020908@bitwrit.com.au>
References: <12431743.post@talk.nabble.com> <46D95E42.8020908@bitwrit.com.au>
Message-ID: <12497565.post@talk.nabble.com>


This looks like exactly what i want!! Thanks!



Jim Lemon-2 wrote:
> 
> yoooooo wrote:
>> Hi, let's say I have data
>> 
>> x = c(1, 2, 10, 12)
>> y = c(100, -20, 50, 25)
>> 
>> if I go plot(x, y), then the default x-axis range goes from 1 to 12. Is
>> there a way to change it so that the axis looks like:
>> 
>> ----|-----|-----|-----|----
>>      1       2       10     12
>> 
>> This doesn't seem reasonable but let's say I want to plot intraday graph
>> with axis.POSIXct, my data is only from 8:30 to 4 every day and I have
>> these
>> data for days.. i don't want to see a straight line every night.. Is
>> there a
>> way I can do this? 
>> 
> Hi yoooooo,
> Have you looked at gap.plot (plotrix)?
> 
> Jim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/plotting-tf4361709.html#a12497565
Sent from the R help mailing list archive at Nabble.com.


From Greg.Snow at intermountainmail.org  Wed Sep  5 15:03:56 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 5 Sep 2007 07:03:56 -0600
Subject: [R] Different behavior of mtext
Message-ID: <111501c7efbd$3136a00b$2e80320a@CO.IHC.COM>

You may also want to look at the cnvrt.coords function in the TeachingDemos package.  It may be a bit simpler than mixing grid and base.

-----Original Message-----
From: "S?bastien" <pomchip at free.fr>
To: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
Cc: "R-help" <r-help at stat.math.ethz.ch>
Sent: 9/3/07 7:46 PM
Subject: Re: [R] Different behavior of mtext

Thanks for the information on gridBase, I could solve my problem using 
the 'baseViewports' function and by replacing mtext by grid.text (with 
coordinates adjustments).

Sebastien

Prof Brian Ripley a ?crit :
> On Mon, 3 Sep 2007, S?bastien wrote:
>
>> Ok, the problem is clear now. I did not get that 'user-coordinates' 
>> was refering to par("usr"), when I read the help of mtext. If I may 
>> ask you some additional questions:
>> - you mentioned a missing unit() call ; at which point should it be 
>> done in my code examples ?
>
> Before it is used.  The problem is that I believe more than one 
> package has a unit() function.
>
>> - could you give me some advices or helpful links about how to set up 
>> a grid viewport ? - and finally, probably a stupid question: is a 
>> gridview automatically set up when a plotting function is called ?
>
> If you want to mix grid and base graphics, you need package gridBase, 
> but really I would not advise a beginner to be using grid directly 
> (that is, not via lattice to ggplot*).
>
>
>> Sebastien
>>
>> PS: To answer to your final question, my goal is to center a block of 
>> legend text on the device but to align the text to the left of this 
>> block.
>>
>> Prof Brian Ripley a ?crit :
>>> On Sun, 2 Sep 2007, S?bastien wrote:
>>>
>>>> Dear R Users,
>>>>
>>>> I am quite surprised to see that mtext gives different results when it
>>>> is used with 'pairs' and with "plot'. In the two following codes, it
>>>> seems that the 'at' argument in mtext doesn't consider the same 
>>>> unit system.
>>>
>>> It is stated to be in 'user coordinates'.  Your code does not work 
>>> because unit() is missing.  If you mean the one from package grid, 
>>> "npc" is not user coordinates (and refers to a grid viewport which 
>>> you have not set up and coincidentally is the same as the initial 
>>> user coordinate system to which pairs() has reverted).
>>>
>>> Try par("usr") after your pairs() and plot() calls to see the 
>>> difference.
>>> Plotting a 2x2 array of plots _is_ different from plotting one, so 
>>> this should be as expected.
>>>
>>> Since centring is the default for 'adj', it is unclear what you are 
>>> trying to achieve here.
>>>
>>>> I would appreciate your comments on this issue.
>>>>
>>>> Sebastien
>>>>
>>>> ##### Pairs
>>>>
>>>> mydata<-data.frame(x=1:10,y=1:10)
>>>>
>>>> par(cex.main=1, cex.axis=1, cex.lab=1, lwd=1,
>>>>    mar=c(5 + 5,4,4,2)+0.1)
>>>>
>>>> pairs(mydata,oma=c(5 + 5,4,4,2))
>>>>
>>>> mylegend<-c("mylegend A","mylegend B","mylegend C","mylegend test")
>>>> mylegend.width = strwidth(mylegend[which.max(nchar(mylegend))], 
>>>> "figure")
>>>>
>>>> for (i in 1:4) {
>>>> mtext(text=mylegend[i],
>>>>        side = 1,
>>>>        line = 3+i,
>>>>        at = unit((1-mylegend.width)/2,"npc"),            # centers the
>>>> legend at the bottom
>>>>        adj=0,
>>>>        padj=0)}
>>>>
>>>> ##### plot
>>>>
>>>> mydata<-data.frame(x=1:10,y=1:10)
>>>>
>>>> par(cex.main=1, cex.axis=1, cex.lab=1, lwd=1,
>>>>    mar=c(5 + 5,4,4,2)+0.1)
>>>>
>>>> plot(mydata,oma=c(5 + 5,4,4,2))
>>>>
>>>> mylegend<-c("mylegend A","mylegend B","mylegend C","mylegend test")
>>>> mylegend.width = strwidth(mylegend[which.max(nchar(mylegend))], 
>>>> "figure")
>>>>
>>>> for (i in 1:4) {
>>>> mtext(text=mylegend[i],
>>>>        side = 1,
>>>>        line = 3+i,
>>>>        at = unit((1-mylegend.width)/2,"npc"),            # should
>>>> center the legend at the bottom but doesn't do it !
>>>>        adj=0,
>>>>        padj=0)}
>>>
>>
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From friendmiao at hotmail.com  Wed Sep  5 15:29:29 2007
From: friendmiao at hotmail.com (=?gb2312?B?zqzEyCDn0Q==?=)
Date: Wed, 5 Sep 2007 13:29:29 +0000
Subject: [R] Help: how can i build a constrained non-linear model?
Message-ID: <BAY117-W156FF653840FD701D2BD8ED7CB0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070905/6bc1252f/attachment.pl 

From servien.remi12 at yahoo.fr  Wed Sep  5 15:45:24 2007
From: servien.remi12 at yahoo.fr (excalibur)
Date: Wed, 5 Sep 2007 06:45:24 -0700 (PDT)
Subject: [R] Spline
Message-ID: <12498336.post@talk.nabble.com>


I want to interpole a functione by a spline interpolation and i want to know
if i can force, with any function or parameter, the interpolation to be
monotonic.

Thanks all
-- 
View this message in context: http://www.nabble.com/Spline-tf4384168.html#a12498336
Sent from the R help mailing list archive at Nabble.com.


From Joao.Fadista at agrsci.dk  Wed Sep  5 15:50:57 2007
From: Joao.Fadista at agrsci.dk (=?iso-8859-1?Q?Jo=E3o_Fadista?=)
Date: Wed, 5 Sep 2007 15:50:57 +0200
Subject: [R] length of a string
Message-ID: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F75@DJFPOST01.djf.agrsci.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070905/e466175c/attachment.pl 

From pisicandru at hotmail.com  Wed Sep  5 15:57:52 2007
From: pisicandru at hotmail.com (Monica Pisica)
Date: Wed, 5 Sep 2007 13:57:52 +0000
Subject: [R]  For loop with if else statement
Message-ID: <BAY104-W6FB89BB4DE3FE36D9BF46C3CB0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070905/bcb9b5b9/attachment.pl 

From Bill.Venables at csiro.au  Wed Sep  5 15:58:29 2007
From: Bill.Venables at csiro.au (Bill.Venables at csiro.au)
Date: Wed, 5 Sep 2007 23:58:29 +1000
Subject: [R] length of a string
References: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F75@DJFPOST01.djf.agrsci.dk>
Message-ID: <B998A44C8986644EA8029CFE6396A924D88F07@exqld2-bne.nexus.csiro.au>

sLengths <- with(dataFrame, nchar(as.character(SEQUENCE))) 


Bill Venables
CSIRO Laboratories
PO Box 120, Cleveland, 4163
AUSTRALIA
Office Phone (email preferred): +61 7 3826 7251
Fax (if absolutely necessary):  +61 7 3826 7304
Mobile:                         +61 4 8819 4402
Home Phone:                     +61 7 3286 7700
mailto:Bill.Venables at csiro.au
http://www.cmis.csiro.au/bill.venables/ 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jo?o Fadista
Sent: Wednesday, 5 September 2007 11:51 PM
To: r-help at stat.math.ethz.ch
Subject: [R] length of a string

Dear all,
 
I would like to know how can I compute the length of a string in a dataframe. Example:
 
SEQUENCE                               ID
TGCTCCCATCTCCACGG            HR04FS000000645
ACTGAACTCCCATCTCCAAT      HR00000595847847
 
I would like to know how to compute the length of each SEQUENCE.
 

Best regards,
Jo?o Fadista

	[[alternative HTML version deleted]]


From jared.oconnell at gmail.com  Wed Sep  5 15:58:36 2007
From: jared.oconnell at gmail.com (Jared O'Connell)
Date: Wed, 5 Sep 2007 21:58:36 +0800
Subject: [R] length of a string
In-Reply-To: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F75@DJFPOST01.djf.agrsci.dk>
References: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F75@DJFPOST01.djf.agrsci.dk>
Message-ID: <8c464e8f0709050658w2ab3fe1ex397b2724cdd8156a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070905/84036ca6/attachment.pl 

From wwwhsd at gmail.com  Wed Sep  5 15:58:49 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Wed, 5 Sep 2007 10:58:49 -0300
Subject: [R] length of a string
In-Reply-To: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F75@DJFPOST01.djf.agrsci.dk>
References: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F75@DJFPOST01.djf.agrsci.dk>
Message-ID: <da79af330709050658k79b08f21p6e7e9350753f6305@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070905/78def0da/attachment.pl 

From ccleland at optonline.net  Wed Sep  5 15:58:31 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 05 Sep 2007 09:58:31 -0400
Subject: [R] length of a string
In-Reply-To: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F75@DJFPOST01.djf.agrsci.dk>
References: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F75@DJFPOST01.djf.agrsci.dk>
Message-ID: <46DEB607.9040207@optonline.net>

Jo?o Fadista wrote:
> Dear all,
>  
> I would like to know how can I compute the length of a string in a dataframe. Example:
>  
> SEQUENCE                               ID
> TGCTCCCATCTCCACGG            HR04FS000000645
> ACTGAACTCCCATCTCCAAT      HR00000595847847
>  
> I would like to know how to compute the length of each SEQUENCE.

?nchar

> Best regards,
> Jo?o Fadista
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From phhs80 at gmail.com  Wed Sep  5 16:02:58 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Wed, 5 Sep 2007 15:02:58 +0100
Subject: [R] length of a string
In-Reply-To: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F75@DJFPOST01.djf.agrsci.dk>
References: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F75@DJFPOST01.djf.agrsci.dk>
Message-ID: <6ade6f6c0709050702p5d97d024o7307869add0a75fd@mail.gmail.com>

On 9/5/07, Jo?o Fadista <Joao.Fadista at agrsci.dk> wrote:
> I would like to know how can I compute the length of a string in a dataframe. Example:
>
> SEQUENCE                               ID
> TGCTCCCATCTCCACGG            HR04FS000000645
> ACTGAACTCCCATCTCCAAT      HR00000595847847
>
> I would like to know how to compute the length of each SEQUENCE.

Maybe the following code?

> data
                    var1 var2
1       This is a string   12
2 This is another string   34
> nchar(data[,1])
[1] 16 22
>

Paul


From Ted.Harding at manchester.ac.uk  Wed Sep  5 16:05:25 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Wed, 05 Sep 2007 15:05:25 +0100 (BST)
Subject: [R] length of a string
In-Reply-To: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F75@DJFPOST01.djf.agrsci.dk>
Message-ID: <XFMail.070905150525.Ted.Harding@manchester.ac.uk>

On 05-Sep-07 13:50:57, Jo?o Fadista wrote:
> Dear all,
>  
> I would like to know how can I compute the length of a string in a
> dataframe. Example:
>  
> SEQUENCE                               ID
> TGCTCCCATCTCCACGG            HR04FS000000645
> ACTGAACTCCCATCTCCAAT      HR00000595847847
>  
> I would like to know how to compute the length of each SEQUENCE.
>  
> Best regards,
> Jo?o Fadista

  nchar("ACTGAACTCCCATCTCCAAT")
  [1] 20

seems to work. Find it, and related functions, with

  help.search("character")

As it happens, help.search("string") will not help!

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 05-Sep-07                                       Time: 15:05:22
------------------------------ XFMail ------------------------------


From pisicandru at hotmail.com  Wed Sep  5 16:34:22 2007
From: pisicandru at hotmail.com (Monica Pisica)
Date: Wed, 5 Sep 2007 14:34:22 +0000
Subject: [R]  geotiff or tiff files with world files
Message-ID: <BAY104-W15CDA70018A3932442C32BC3CB0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070905/bb2433a6/attachment.pl 

From bcarvalh at jhsph.edu  Wed Sep  5 16:40:38 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Wed, 5 Sep 2007 11:40:38 -0300
Subject: [R] length of a string
In-Reply-To: <XFMail.070905150525.Ted.Harding@manchester.ac.uk>
References: <XFMail.070905150525.Ted.Harding@manchester.ac.uk>
Message-ID: <2B57A7E8-0718-44C9-9F44-A8ABE4A7FACE@jhsph.edu>

As long as you keep in mind Prof. Ripley's comment, you're going to  
be fine with nchar().

http://tolstoy.newcastle.edu.au/R/e2/devel/07/05/3450.html

Remember that what you want exactly is given by nchar(obj,  
type="chars"), which is **NOT** the default on R 2.5.1 (only on  
R-2.6.0).

In your particular situation, assuming R-2.5.1, nchar(obj) works, but  
i'm afraid it's only a coincidence.

b

On Sep 5, 2007, at 11:05 AM, (Ted Harding) wrote:

> On 05-Sep-07 13:50:57, Jo?o Fadista wrote:
>> Dear all,
>>
>> I would like to know how can I compute the length of a string in a
>> dataframe. Example:
>>
>> SEQUENCE                               ID
>> TGCTCCCATCTCCACGG            HR04FS000000645
>> ACTGAACTCCCATCTCCAAT      HR00000595847847
>>
>> I would like to know how to compute the length of each SEQUENCE.
>>
>> Best regards,
>> Jo?o Fadista
>
>   nchar("ACTGAACTCCCATCTCCAAT")
>   [1] 20
>
> seems to work. Find it, and related functions, with
>
>   help.search("character")
>
> As it happens, help.search("string") will not help!
>
> Best wishes,
> Ted.
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 05-Sep-07                                       Time: 15:05:22
> ------------------------------ XFMail ------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hanwengutierrez at yahoo.com  Wed Sep  5 16:43:12 2007
From: hanwengutierrez at yahoo.com (hanwen zhang)
Date: Wed, 5 Sep 2007 07:43:12 -0700 (PDT)
Subject: [R] multivariate ARMA simulation
Message-ID: <902185.39213.qm@web35315.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070905/0e32064f/attachment.pl 

From tom at maladmin.com  Wed Sep  5 16:54:11 2007
From: tom at maladmin.com (Tom Wright)
Date: Wed, 05 Sep 2007 10:54:11 -0400
Subject: [R] Multiple xyplots
Message-ID: <46DEC313.5040201@maladmin.com>

Hi everyone,
I'm hoping you can give me some pointers. I have a requirement to draw 
multiple (103) xy line plots onto one output device. Ideally the plots 
should be displayed in a hexagonal grid (example at 
www.maladmin.com/example.jpg). I can calculate the locations for each 
waveform but am wondering how to create multiple plotting areas. I have 
come accross references to a package grid (which doesn't seem to be in 
my CRAN mirror probability.ca) and lattice but I'm not sure if I'm on 
the correct lines.
Any advice gratefully received.
Thanks
Tom

-- 
--Tom Wright
____________________________________________
| Contact me:                               |
| Skype: 0121 288 0756    tomwright01)      |
| MSN: passport at macrobot.net                |
| Jabber: maladmin at xim.ca                   |
| ICQ: 423913453                            |
|___________________________________________|


Ever since prehistoric times, wise men have tried to understand what,
exactly, make people laugh.  That's why they were called "wise men."
All the other prehistoric people were out puncturing each other with
spears, and the wise men were back in the cave saying: "How about:
Would you please take my wife?  No.  How about: Here is my wife, please
take her right now.  No How about:  Would you like to take something?
My wife is available.  No.  How about ..."
          -- Dave Barry, "Why Humor is Funny"


From doc.evans at gmail.com  Wed Sep  5 17:24:20 2007
From: doc.evans at gmail.com (D. R. Evans)
Date: Wed, 05 Sep 2007 09:24:20 -0600
Subject: [R] Q: selecting a name when it is known as a string
In-Reply-To: <46DDD8CF.6010005@gmail.com>
References: <46DDD8CF.6010005@gmail.com>
Message-ID: <46DECA24.8060308@gmail.com>

D. R. Evans said the following at 09/04/2007 04:14 PM :
> I am 100% certain that there is an easy way to do this, but after

I have reconsidered this and now believe it to be essentially impossible
(or at the very least remarkably difficult) although I don't understand why
it is so :-(

At least, I spent another two hours trying variations on the suggestions I
received, but still nothing worked properly.

It sure seems like it _ought_ to be easy, because of the following argument:

If I type an expression such as "A <- <something>" then R is perfectly
capable of parsing the <something> and executing it and assigning the
result to A. So it seems to follow that it ought to be able to parse a
string that contains exactly the same sequence of characters (after all,
why should the R parsing engine care whether the input string comes from
the terminal or from a variable?) and therefore it should be possible to
assign "<something>" to a variable and then have R parse that variable
precisely as if it had been typed.

That was my logic as to why this ought to be easy, anyway. (And there was
the subsidiary argument that this is easy in the other languages I use, but
R is sufficiently different that I'm not certain that that argument carries
much force.)

It does seem that there are several ways to make the

  lo <- loess(percent ~ ncms * ds, d, control=loess.control(trace.hat =
> 'approximate'))

command work OK if the right hand side is in a character variable, but I
haven't been able to find a way to make

  grid <- data.frame(expand.grid(ds=MINVAL:MAXVAL, ncms=MINCMS:MAXCMS))

work.

I always end up with a parse error or a complaint that "'newdata' does not
contain the variables needed" when I perform the next task:

  plo <- predict(lo, grid).

So I guess I have to stick with half a dozen compound "if" statements, all
of which do essentially the same thing :-(


From timh at insightful.com  Wed Sep  5 17:40:21 2007
From: timh at insightful.com (Tim Hesterberg)
Date: Wed, 05 Sep 2007 08:40:21 -0700
Subject: [R] bootstrap confidence intervals with previously	existing
	bootstrap sample
In-Reply-To: <Pine.LNX.4.64.0709042209200.26489@gannet.stats.ox.ac.uk>
	(message from Prof Brian Ripley on Tue, 4 Sep 2007 22:28:42 +0100
	(BST))
References: <Pine.LNX.4.64.0709042209200.26489@gannet.stats.ox.ac.uk>
Message-ID: <ups0x9l3u.fsf@insightful.com>

>On Tue, 4 Sep 2007, dolph008 at umn.edu wrote:
>> I am new to R. I would like to calculate bootstrap confidence intervals
>> using the BCa method for a parameter of interest. My situation is this: I
>> already have a set of 1000 bootstrap replicates created from my original
>> data set. I have already calculated the statistic of interest for each
>> bootstrap replicate, and have also calculated the mean for this statistic
>> across all the replicates. Now I would like to calculate Bca confidence
>> intervals for this statistic. Is there a way to import my
>> previously-calculated set of 1000 statistics into R, and then calculate
>> bootstrap confidence intervals around the mean from this imported data?
>>
>> I have found the code for boot.ci in the manual for the boot package, but
>> it looks like it requires that I first use the "boot" function, and then
>> apply the output to "boot.ci". Because my bootstrap samples already exist,
>> I don't want to use "boot", but just want to import the 1000 values I have
>> already calculated, and then get R to calculate the mean and Bca confidence
>> intervals based on these values. Is this possible?

Brian Ripley wrote:
>Yes, it is possible but you will have to study the internal structure of 
>an object of class "boot" (which is documented on the help page) and mimic 
>it.  You haven't told us which type of bootstrap you used, which is one of 
>the details you need to supply.
>
>It might be slightly easier to work with function bcanon in package 
>bootstrap, which you would need to edit to suit your purposes.
>
>I don't know why you have picked on the BCa method: my experience is that 
>if you need to correct the basic method you often need far more than 1000 
>samples to get reliable results.

You can do the BCa, but you need to supply parameters:
z0: typically calculated from the fraction of bootstrap statistics 
    that are <= the original statistic
acceleration: based on the skewness of the empirical influence function,
    typically calculated using the jackknife

I agree that you should do far more than 1000 samples.  The BCa uses
bootstrap quantiles that are adjusted based on the z0 and acceleration
parameters, and estimating z0 from the bootstrap samples magnifies
the Monte Carlo error.  You need roughly double as many bootstrap samples
as for the bootstrap percentile interval; e.g. 10^4 instead of 5000.

If computational expense is an issue, you might prefer bootstrap
tilting intervals, which require about 1/37 as many bootstrap samples
as the BCa for comparable Monte Carlo variability.

Quick overview of confidence intervals:

			accuracy	comments
t intervals		1/sqrt(n)	Using either formula or bootstrap 
					standard error; poor in the presence
					of skewness.
bootstrap percentile	1/sqrt(n)	Good quick-and-dirty procedure.
					Partial skewness correction.
					Poor if the statistic is biased.
bootstrap t		1/n		Good coverage, but interval
					width can vary wildly when n is small.
BCa			1/n		Current best overall, but you need
					a lot of bootstrap samples, e.g. 10^4.
tilting			1/n		Low Monte Carlo variability, so can 
					use fewer bootstrap samples.  
					Difficult to implement, and
					requires that statistic can be
					calculated with weights.

Advertisement 1: tilting is available in S+Resample, available free
from www.insightful.com/downloads/libraries

Advertisement 2: I talk about these more in my short course,
	Bootstrap Methods and Permutation Tests
	Oct 10-11 San Francisco, 3-4 Oct UK.
	http://www.insightful.com/services/training.asp

========================================================
| Tim Hesterberg       Senior Research Scientist       |
| timh at insightful.com  Insightful Corp.                |
| (206)802-2319        1700 Westlake Ave. N, Suite 500 |
| (206)283-8691 (fax)  Seattle, WA 98109-3044, U.S.A.  |
|                      www.insightful.com/Hesterberg   |


From Greg.Snow at intermountainmail.org  Wed Sep  5 18:02:36 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 5 Sep 2007 10:02:36 -0600
Subject: [R] How to obtain intercept statistics in anova
 withwithin-subject factors?
In-Reply-To: <00e501c7ec14$93dcca50$bb965ef0$@kouider@free.fr>
References: <00e501c7ec14$93dcca50$bb965ef0$@kouider@free.fr>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBB3D91@LP-EXCHVS07.CO.IHC.COM>

Sorry, I did not think about the nested design (did not read carefully enough).  Another thing to try (untested) is to create a column of 1's and include that specifically and exclude the default intercept, then your column of 1's acts as the intercept, but a p-value is returned from it.

Note that sometimes the other terms may change their definition without an intercept.  I had success at one time (quite a while ago, so things could have changed) with specifying the formula as:O

Y ~ 1 + x1 + x2 + x3 -1

Which caused it to include the intercept, use that info when setting the dummy vars for x1-x3, then removed the intercept.  

Again this is all untested, just an idea to try.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Sid Kouider
> Sent: Friday, August 31, 2007 3:19 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] How to obtain intercept statistics in anova 
> withwithin-subject factors?
> 
> Dear Greg,
> Thanks very much for you advice. 
> Unfortunately, although summary.lm applied on aov objects 
> indeed shows the intercept's statistics, this function does 
> not (seem to) work with within-participant designs. As soon 
> as I enter the info on the error term (see the example in my 
> first message), then summary.lm(aov_object) crashes ("Error 
> in if (p == 0) { : argument is of length zero").
> -Sid
> 
> 
> 
> > Subject: RE: [R] (no subject)
> > Date: Thu, 30 Aug 2007 13:43:19 -0600
> > From: Greg.Snow at intermountainmail.org
> > To: sisid at hotmail.com; r-help at stat.math.ethz.ch
> >
> > Try calling summary.lm on your object (if it is an aov object then 
> > summary
> calls summary.aov which does not show the intercept, but 
> calling summary.lm directly does give info on the intercept).
> >
> > --
> > Gregory (Greg) L. Snow Ph.D.
> > Statistical Data Center
> > Intermountain Healthcare
> > greg.snow at intermountainmail.org
> > (801) 408-8111
> 
> 
> > -----Message d'origine-----
> > De?: Sid Kouider [mailto:sid.kouider at free.fr] Envoy??: 
> jeudi 30 ao?t 
> > 2007 16:54 ??: 'r-help at lists.R-project.org'
> > Objet?: How to obtain intercept statistics in anova with 
> > within-subject factors?
> > 
> > Dear R users,
> > I am looking for an easy (i.e., direct) way of obtaining 
> the F and p 
> > values from the intercept in anovas with within-subject designs.
> > My data are from a psychophysics experiment where I am using d' (d-
> > prime) values obtained from 3 modalities of presentation in each 
> > subject. I would like to know not only whether there is an 
> effect of 
> > modality, but also whether the main effect is significant (meaning 
> > that d' > 0).
> > I know that a t.test again the null mean would provide me 
> with similar 
> > stats on the main effect, but I would like to get those 
> stats in an F 
> > form, for consistency with the stats on the other factors 
> of interest.
> > 
> > As far as I understand how R works, the function "anova" 
> provides you 
> > with such information but it is restricted to between-group 
> analyses.
> > For within-subject designs, one has to use "summary(aov)" 
> but stats on 
> > the intercept are not included in the result of this 
> function. I have 
> > pasted an example below. As one can see, only the Sum of Sq 
> and Mean 
> > Sq are given for the main effect.
> > 
> > Thank you for any advice you can provide, -Sid
> > 
> > summary(aov(x~mod+Error(suj/(mod)), data=dp))
> > 
> > Error: suj          Df  Sum Sq Mean Sq F value Pr(>F)
> > Residuals 10 19.5977  1.9598
> > Error: suj:mod
> > Df  Sum Sq Mean Sq F value  Pr(>F)  mod
> > 2  8.2475  4.1237  4.2955 0.02806 *
> > Residuals 20 19.2005  0.9600
> > ---Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 
> ' ' 1 Error:
> > Within
> > Df Sum Sq Mean Sq F value Pr(>F)Residuals 33 55.812   1.691
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From deepayan.sarkar at gmail.com  Wed Sep  5 18:07:31 2007
From: deepayan.sarkar at gmail.com (deepayan.sarkar at gmail.com)
Date: Wed, 5 Sep 2007 09:07:31 -0700
Subject: [R] Multiple xyplots
In-Reply-To: <46DEC313.5040201@maladmin.com>
References: <46DEC313.5040201@maladmin.com>
Message-ID: <eb555e660709050907g6f14ee28x20584b0338ee1144@mail.gmail.com>

On 9/5/07, Tom Wright <tom at maladmin.com> wrote:
> Hi everyone,
> I'm hoping you can give me some pointers. I have a requirement to draw
> multiple (103) xy line plots onto one output device. Ideally the plots
> should be displayed in a hexagonal grid (example at
> www.maladmin.com/example.jpg). I can calculate the locations for each
> waveform but am wondering how to create multiple plotting areas. I have
> come accross references to a package grid (which doesn't seem to be in
> my CRAN mirror probability.ca) and lattice but I'm not sure if I'm on
> the correct lines.
> Any advice gratefully received.

grid seems like the right choice to me (it comes bundled with R, so
it's not available as a separate package). Here's an example that may
give you a few hints:

library(grid)
grid.newpage()
for (i in 1:30)
    grid.lines(x = 0:20/21, y = sin(70 * runif(1) * 0:20/21),
               vp = viewport(x = runif(1), y = runif(1), height =
0.05, width = 0.05))

See the package documentation, or Paul Murrell's book "R Graphics" for more.

-Deepayan


From servien.remi12 at yahoo.fr  Wed Sep  5 14:35:42 2007
From: servien.remi12 at yahoo.fr (servien remi)
Date: Wed, 5 Sep 2007 14:35:42 +0200 (CEST)
Subject: [R] Monotone splines
Message-ID: <452172.39952.qm@web27710.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070905/e91a7107/attachment.pl 

From apjaworski at mmm.com  Wed Sep  5 18:24:20 2007
From: apjaworski at mmm.com (apjaworski at mmm.com)
Date: Wed, 5 Sep 2007 11:24:20 -0500
Subject: [R] question about non-linear least squares in R
In-Reply-To: <46DE6016.10404@pdf.com>
Message-ID: <OF6275C231.7181615D-ON8625734D.0058BDA1-8625734D.005A1E51@mmm.com>

Here is one way of getting a reasonable fit:

1.  Scale your y's by dividing all values by 1e6.
2.  Plot x vs. y.  The plot looks like a quadratic function.
3.  Fit a quadratic const. + B*x^2 - this a linear regression problem so
use lm.
4.  Plot the predictions.
5.  Eyball the necessary shift - MA is around 0.01.  Refit const. +
B*(x-.01)^2.  Should get const.=1.147 and B=139.144
6.  Use start=list(const.= 1.147, A=0, B=1.147, MA=.01).  nls should
converge in 4 iterations.

In general, good starting points may be crucial to nls convergence.
Scaling the y's to reasonable values also helps.

Hope this helps,

Andy

__________________________________
Andy Jaworski
518-1-01
Process Laboratory
3M Corporate Research Laboratory
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


                                                                           
             "Yu (Warren)                                                  
             Wang"                                                         
             <yu.wang at pdf.com>                                          To 
             Sent by:                  "r-help at stat.math.ethz.ch"          
             r-help-bounces at st         <r-help at stat.math.ethz.ch>          
             at.math.ethz.ch                                            cc 
                                                                           
                                                                   Subject 
             09/05/2007 02:51          [R] question about non-linear least 
             AM                        squares in R                        
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           




Hi, everyone,
    My question is: It's not every time that you can get a converged
result from the nls function. Is there any solution for me to get a
reasonable result? For example:

x <- c(-0.06,-0.04,-0.025,-0.015,-0.005,0.005,0.015,0.025,0.04,0.06)

y <-
c(1866760,1457870,1314960,1250560,1184850,1144920,1158850,1199910,1263850,1452520)


fitOup<- nls(y ~ constant + A*(x-MA)^4 + B*(x-MA)^2,
start=list(constant=10000000, A=100000000, B=-1000000, MA=0),
control=nls.control(maxiter=100, minFactor=1/4096), trace=TRUE)



 For this one, I cannot get the converged result, how can I reach it? To
use another funtion or to modify some settings for nls?

Thank you very much!

Yours,

Warren

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Christoph.Muller at mnp.nl  Wed Sep  5 18:34:22 2007
From: Christoph.Muller at mnp.nl (Christoph Muller)
Date: Wed, 5 Sep 2007 18:34:22 +0200
Subject: [R] ecological meaning of randomForest vegetation classification?
Message-ID: <OFAE525C7E.04E0EB32-ONC125734D.0057C81A-C125734D.005B097E@notesmail.rivm.nl>

Hi, everyone,

I haven't found anything similar in the forum, so here's my problem (I'm no
expert in R nor statistics):

I have a data set of 59.000 cases with 9 variables each (fractional
coverage of 9 different plant types, such as deciduous broad-leaved
temperate trees or evergreen tropical trees etc.), which was generated by a
vegetation model.
In order to evaluate the quality of the vegetation model's output, I want
to compare it to a land-cover data set which has 23 different land-cover
types (such as needle leaved evergreen forest, dense broad-leaved forest,
barren, etc.).
A statistician advised me to use the randomForest package in R and using a
sub-set to generate the random Forest, I get a very good prediction for the
rest.
However, I need to evaluate how meaningful this classification is in an
ecological sense (boreal trees should not play a role in the definition of
tropical land-cover types, for example), otherwise I cannot judge the
quality of the vegetation model's output.

Unfortunately, randomForest gives me about 15.000 splits of which about
5000 are end branches (rough guess), so it's very hard and time-consuming
to check each single branch of one of the final trees for its ecological
meaning.
Is there any utility to summarize the characteristics of each of the 23
prediction classes? Such as "land-cover class 1 has less than 5% of plant
types 1-5, 20-50% of plant type 7 and at least 30% of plant type 8".
Or is there a more suitable method to classify my data?

Thanks a lot in advance!

Christoph
____________________________________________________________________________

Click on the following link for the Netherlands Environmental Assessment
Agency(MNP)mission and contact information:
http://www.mnp.nl/signature.html

Klik op de volgende link voor missie en contactinformatie van het
Milieu- en Natuurplanbureau (MNP): http://www.mnp.nl/signature.html


From ligges at statistik.uni-dortmund.de  Wed Sep  5 18:42:06 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 05 Sep 2007 18:42:06 +0200
Subject: [R] kendalls tau c
In-Reply-To: <46DD1226.4090808@agrar.uni-giessen.de>
References: <46DD1226.4090808@agrar.uni-giessen.de>
Message-ID: <46DEDC5E.5030406@statistik.uni-dortmund.de>



Barbara Diane-Spillmann wrote:
> dear all,
> 
> does anybody know if cor.test with method="kendall" calculates kendalls 
> tau a b or c? I need to get p values for kendalls tau c...


May I ask what the difference between Kendall's tau a, b and c is? Any 
references?

Uwe Ligges


> thank you very much for any kind of hint.
> 
> Barbara
>


From ryanicky at mindspring.com  Wed Sep  5 19:19:07 2007
From: ryanicky at mindspring.com (Richard Yanicky)
Date: Wed, 5 Sep 2007 13:19:07 -0400 (GMT-04:00)
Subject: [R] Single plot multiple levels in x?
Message-ID: <12228229.1189012748057.JavaMail.root@mswamui-swiss.atl.sa.earthlink.net>

Greg,


This is great, exactly what I was looking for.


Thanks. 


Rich

-----Original Message-----
>From: Greg Snow <Greg.Snow at intermountainmail.org>
>Sent: Aug 31, 2007 2:55 PM
>To: Richard Yanicky <ryanicky at mindspring.com>, Uwe Ligges <ligges at statistik.uni-dortmund.de>
>Cc: r-help at stat.math.ethz.ch
>Subject: RE: [R] Single plot multiple levels in x?
>
>Try this code (with the mydf that you generate below):
>
>library(TeachingDemos)
>
>plot( c(0,5), c(0,1), xlab='State', ylab='ylab', axes=FALSE, type='n' )
>axis(1, at= (1:5) - 0.5, labels=paste('state',1:5))
>box()
>
>for(i in 1:5){
>	with( subset(mydf, State==i),
>	  subplot( plot(Position, `Pct Recurr`, col=i,
>		yaxt=ifelse( i==1, 's', 'n' ), ylab='',xlab='',
>cex.axis=0.5),
>		x=c(i-1,i), y=c(0,1) )
>	)
>}
>
>
>Is that close to what you want? 
>
>
>-- 
>Gregory (Greg) L. Snow Ph.D.
>Statistical Data Center
>Intermountain Healthcare
>greg.snow at intermountainmail.org
>(801) 408-8111
> 
> 
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch 
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Richard Yanicky
>> Sent: Thursday, August 30, 2007 11:37 AM
>> To: Uwe Ligges
>> Cc: r-help at stat.math.ethz.ch
>> Subject: Re: [R] Single plot multiple levels in x?
>> 
>> Uwe,
>> 
>> 
>> Here is some code to create some data then a plot (The plot 
>> was done in another package). The plot is included only to 
>> reference the structure of the x-axis. I can't get R to do 
>> something similar.
>> 
>> 
>> State <- seq (1:5);
>> posi <- seq (0.5,62525,199.233)
>> 
>> mydf<-NULL;
>> 
>> for ( i in 1:5) {
>> 
>> df1<-data.frame(i,posi);
>> 
>> mydf <- rbind(mydf,df1); }   
>> 
>> myy<-rep(-100.01:100.01,length=nrow(mydf));
>> 
>> mydf<-cbind(mydf,myy);
>> 
>> names(mydf) <- c("State","Position","Pct Recurr");
>> 
>> 
>> 
>> 
>> I would like to somehow:
>> 
>> 
>> plot(c(mydf[,1],mydf[,2]),mydf[,3]) and end up with the 
>> nested structure on the x-axis.
>> 
>> Thanks,
>> 
>> Richard
>> 
>> 
>> -----Original Message-----
>> >From: Uwe Ligges <ligges at statistik.uni-dortmund.de>
>> >Sent: Aug 30, 2007 10:50 AM
>> >To: Richard Yanicky <ryanicky at mindspring.com>
>> >Cc: r-help at stat.math.ethz.ch
>> >Subject: Re: [R] Single plot multiple levels in x?
>> >
>> >
>> >
>> >Richard Yanicky wrote:
>> >> Uwe,
>> >> 
>> >> I have looked into lattice and can't seem to make this 
>> work. I can easily make multiple panels but this isn't what I 
>> am looking to do. Any suggestions on which functions to use? 
>> the axis function seems a natural place to start but I still 
>> can't seem to make it happen.
>> >
>> >If lattice is not what you want, I do not understand what 
>> you mean. Can 
>> >you give a more elaborated example, please?
>> >
>> >Uwe
>> >
>> >
>> >> 
>> >> HELP!
>> >> 
>> >> 
>> >> Richard
>> >> 
>> >> -----Original Message-----
>> >>> From: Uwe Ligges <ligges at statistik.uni-dortmund.de>
>> >>> Sent: Aug 30, 2007 5:59 AM
>> >>> To: Richard Yanicky <ryanicky at mindspring.com>
>> >>> Cc: r-help at stat.math.ethz.ch
>> >>> Subject: Re: [R] Single plot multiple levels in x?
>> >>>
>> >>>
>> >>>
>> >>> Richard Yanicky wrote:
>> >>>> Plotting with 2 x axis?
>> >>>>
>> >>>>
>> >>>> One axis inside another, for example salary within state,
>> >>>>
>> >>>>
>> >>>>
>> >>>>
>> >>>> 1-50     |     50 - 100 |  100+   |   1- 50 | 50 -100 | 
>> 100+ | ...  repeated bins for salary
>> >>>>                AL                           !            
>>    AR                     ......  more states
>> >>>
>> >>> Sounds like the lattice package does exactly what you want, but 
>> >>> without any reproducible example.....
>> >>>
>> >>> Uwe Ligges
>> >>>
>> >>>
>> >>>
>> >>>> The values are all stored with a single data frame. I have tried 
>> >>>> different things with the axis function and done many 
>> searches for 
>> >>>> plotting. Can't find a direct reference
>> >>>>
>> >>>>
>> >>>> Thanks.
>> >>>>
>> >>>> Richard
>> >>>>
>> >>>> ______________________________________________
>> >>>> R-help at stat.math.ethz.ch mailing list 
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>> PLEASE do read the posting guide 
>> >>>> http://www.R-project.org/posting-guide.html
>> >>>> and provide commented, minimal, self-contained, 
>> reproducible code.
>> >> 
>> 
>


From Greg.Snow at intermountainmail.org  Wed Sep  5 19:24:14 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 5 Sep 2007 11:24:14 -0600
Subject: [R] element wise opertation between a vector and a list
In-Reply-To: <d89bf0cd0709022336l7122dfd9x7e423b2316a56201@mail.gmail.com>
References: <d89bf0cd0709022336l7122dfd9x7e423b2316a56201@mail.gmail.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBB3DDC@LP-EXCHVS07.CO.IHC.COM>

> ?mapply
> mapply('+', a, b, SIMPLIFY=FALSE)
> colSums(mapply('+', a, b))

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Yongwan Chun
> Sent: Monday, September 03, 2007 12:36 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] element wise opertation between a vector and a list
> 
> I want to try to get a result of element wise addition 
> between a vector and a list. It can be done with "for 
> statement." In order to reducing computing time, I have tried 
> to avoid "for state." If anybody give me an idea, I would 
> apprecite it much.
> 
> for example, with a & b as below lines,
> 
> a<- list(c(1,3),c(1,2),c(2,3))
> b<-c(10,20,30)
> 
> I would like to have a list (like "d") or a vector (like "e") 
> as below.
> 
> d<-list(c((1+10),(3+10)),c((1+20),(2+20)),c((2+30),(3+30)))
> e<- c((1+10)+(3+10),(1+20)+(2+20),(2+30)+(3+30))
> 
> Thanks,
> 
> 
> Yongwan Chun
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dsonneborn at ucdavis.edu  Wed Sep  5 19:27:41 2007
From: dsonneborn at ucdavis.edu (Dean Sonneborn)
Date: Wed, 05 Sep 2007 10:27:41 -0700
Subject: [R] level names with groupdedData object
Message-ID: <46DEE70D.5000801@ucdavis.edu>

How do I get a grouped data object to use the level names from the input 
data set?
first I gave the levels some names like this:

male <-factor(male)

levels(male) <- c(?Girls?,?Boys?)

Then I created a groupdedData object but the male variable in not part 
of the grouping formula.

Then I fit an lme and then use this code to create a plot:
plot(myfit.lme, resid(. , type=?p?) ~ fitted(.) | male , id=0.05, adj=-0.3 )

But the plot just used ?Male? in both panels. How do I get the plot to 
used "Girls" "Boys"?

Thanks,

Dean


From dverzi at mail.sdsu.edu  Wed Sep  5 19:47:39 2007
From: dverzi at mail.sdsu.edu (dverzi at mail.sdsu.edu)
Date: Wed,  5 Sep 2007 10:47:39 -0700 (PDT)
Subject: [R] list element to matrix
Message-ID: <20070905104739.BDS36834@mail.sdsu.edu>

I have created a list of "matrices" using sapply or lapply and wish to extract each of the "matrices" as a matrix.  Some of them are 2x2, 3x3, etc.

I can do this one at a time as:

M1<-as.matrix(D[[1]])

How can repeat this process for an unknown number of entries in the list?  In other words, how shall I index M1?

Diana


From andy_liaw at merck.com  Wed Sep  5 19:49:09 2007
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 5 Sep 2007 13:49:09 -0400
Subject: [R] ecological meaning of randomForest vegetation
 classification? [Broadcast]
In-Reply-To: <OFAE525C7E.04E0EB32-ONC125734D.0057C81A-C125734D.005B097E@notesmail.rivm.nl>
References: <OFAE525C7E.04E0EB32-ONC125734D.0057C81A-C125734D.005B097E@notesmail.rivm.nl>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04A4AA61@usctmx1106.merck.com>

Hi Christoph,

I'm not exactly sure what you're looking for, but I'll take a stab
anyway.

The trees in a random forest is not designed to be interpreted as one
would
with an "ordinary" tree.  There are several things you may try to see if
they help you any.  One is the distribution of votes.  It looks like you
are
classifying each data point into one of many possible classes.  RF with
give
you the fraction of trees in the forest that classified the observation
as
a particular class (and the class with the highest fraction of votes is
the
"predicted class").  Another is the partial dependence plot:  You can
use
plot(importance(rf.object)) to see which variables are the most
important,
and then use partialPlot() to examine their marginal effects.  These
offer
some clue of what the RF black box is doing, and hopefully will make
some
sense to you.

Best,
Andy 

From: Christoph Muller
> 
> Hi, everyone,
> 
> I haven't found anything similar in the forum, so here's my 
> problem (I'm no
> expert in R nor statistics):
> 
> I have a data set of 59.000 cases with 9 variables each (fractional
> coverage of 9 different plant types, such as deciduous broad-leaved
> temperate trees or evergreen tropical trees etc.), which was 
> generated by a
> vegetation model.
> In order to evaluate the quality of the vegetation model's 
> output, I want
> to compare it to a land-cover data set which has 23 different 
> land-cover
> types (such as needle leaved evergreen forest, dense 
> broad-leaved forest,
> barren, etc.).
> A statistician advised me to use the randomForest package in 
> R and using a
> sub-set to generate the random Forest, I get a very good 
> prediction for the
> rest.
> However, I need to evaluate how meaningful this 
> classification is in an
> ecological sense (boreal trees should not play a role in the 
> definition of
> tropical land-cover types, for example), otherwise I cannot judge the
> quality of the vegetation model's output.
> 
> Unfortunately, randomForest gives me about 15.000 splits of 
> which about
> 5000 are end branches (rough guess), so it's very hard and 
> time-consuming
> to check each single branch of one of the final trees for its 
> ecological
> meaning.
> Is there any utility to summarize the characteristics of each 
> of the 23
> prediction classes? Such as "land-cover class 1 has less than 
> 5% of plant
> types 1-5, 20-50% of plant type 7 and at least 30% of plant type 8".
> Or is there a more suitable method to classify my data?
> 
> Thanks a lot in advance!
> 
> Christoph
> ______________________________________________________________
> ______________
> 
> Click on the following link for the Netherlands Environmental 
> Assessment
> Agency(MNP)mission and contact information:
> http://www.mnp.nl/signature.html
> 
> Klik op de volgende link voor missie en contactinformatie van het
> Milieu- en Natuurplanbureau (MNP): http://www.mnp.nl/signature.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}


From FolkesM at pac.dfo-mpo.gc.ca  Wed Sep  5 20:08:40 2007
From: FolkesM at pac.dfo-mpo.gc.ca (Folkes, Michael)
Date: Wed, 5 Sep 2007 11:08:40 -0700
Subject: [R] Lattice: key with expression function
In-Reply-To: <63F107BCC37AEA49A75FD94AA3E07CB099F51A@pacpbsex01.pac.dfo-mpo.ca>
Message-ID: <63F107BCC37AEA49A75FD94AA3E07CB099F525@pacpbsex01.pac.dfo-mpo.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070905/62f5e341/attachment.pl 

From Greg.Snow at intermountainmail.org  Wed Sep  5 20:10:38 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 5 Sep 2007 12:10:38 -0600
Subject: [R] rug() colors
In-Reply-To: <E1IScgq-0003Sz-3K@www10.emo.freenet-rz.de>
References: <E1IScgq-0003Sz-3K@www10.emo.freenet-rz.de>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBB3DFE@LP-EXCHVS07.CO.IHC.COM>

You could make multiple calls to the rug function using a different
color for each call.  Using tapply or by may automate this for you.
Another option would be to create your own rug using the segments
function (which will plot multiple colors).

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> strinz at freenet.de
> Sent: Tuesday, September 04, 2007 12:00 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] rug() colors
> 
> Hello,
> 
> I have a simple question on rug().
> Currently there is only one color possible for the rug.
> Is it possible to plot a the rug with different colors, for 
> each rug item ?
> 
> Thx.
> Bjoern
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From deepayan.sarkar at gmail.com  Wed Sep  5 20:27:09 2007
From: deepayan.sarkar at gmail.com (deepayan.sarkar at gmail.com)
Date: Wed, 5 Sep 2007 11:27:09 -0700
Subject: [R] Lattice: key with expression function
In-Reply-To: <63F107BCC37AEA49A75FD94AA3E07CB099F525@pacpbsex01.pac.dfo-mpo.ca>
References: <63F107BCC37AEA49A75FD94AA3E07CB099F51A@pacpbsex01.pac.dfo-mpo.ca>
	<63F107BCC37AEA49A75FD94AA3E07CB099F525@pacpbsex01.pac.dfo-mpo.ca>
Message-ID: <eb555e660709051127i2e4bc2dbl37ee3bcdd7449480@mail.gmail.com>

On 9/5/07, Folkes, Michael <FolkesM at pac.dfo-mpo.gc.ca> wrote:
> HI all,
> I'm trying (unsuccessfully) to add the degree symbol to each line of
> text in my legend (within xyplot).
> Here is the line of code, which fails to interpret the expression
> function:
>
> auto.key =list(points =
> FALSE,text=paste(levels(as.factor(divertSST2$temp)),expression(degree)).
> ..),
>
> I just get:
> 7 degree
> 8 degree
> 9 degree

That's because

> paste("foo", expression(degree))
[1] "foo degree"


> If I place 'expression' outside or just after the paste function it also
> doesn't work.

auto.key = list(text = expression(paste("foo", degree)))

should work. I think the problem is that you want a vector of
expressions, and that's a bit harder to get. I'm not sure what the
best solution is, but if everything else fails, you could try using
parse(text=)

-Deepayan


From Greg.Snow at intermountainmail.org  Wed Sep  5 20:44:21 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 5 Sep 2007 12:44:21 -0600
Subject: [R] Q: selecting a name when it is known as a string
In-Reply-To: <46DDD8CF.6010005@gmail.com>
References: <46DDD8CF.6010005@gmail.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBB3E10@LP-EXCHVS07.CO.IHC.COM>

If your main goal is to do a loess fit, then make predictions from that,
then using the 'get' function may do what you want:

 tmp.var <- get(ORDINATE)
 lo <- loess(percent ~ ncms * tmp.var, d, ...
 grid <- expand.grid(tmp.var=MINVAL:MAXVAL, ncms=MINCMS:MAXCMS)
 predict(lo, grid)

Here you stick with the name tmp.var so it matches between the formula
and the data frame, the predictions will be what you want.  If you also
want to print out some of the model summary then realize that it will
have tmp.var in place of ds or whatever (It may not be too much trouble
to change that name after the fact if that is what is important).

Hope this helps, 

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of D. R. Evans
> Sent: Tuesday, September 04, 2007 4:15 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Q: selecting a name when it is known as a string
> 
> I am 100% certain that there is an easy way to do this, but 
> after experimenting off and on for a couple of days, and 
> searching everywhere I could think of, I haven't been able to 
> find the trick.
> 
> I have this piece of code:
> 
> ...
>   attach(d)
> 
>   if (ORDINATE == 'ds')
>   { lo <- loess(percent ~ ncms * ds, d, 
> control=loess.control(trace.hat =
> 'approximate'))
>     grid <- data.frame(expand.grid(ds=MINVAL:MAXVAL, 
> ncms=MINCMS:MAXCMS)) ...
> 
> then there several almost-identical "if" statements for 
> different values of ORDINATE. For example, the next "if" 
> statement starts with:
> 
> ...
>   if (ORDINATE == 'dsl')
>   { lo <- loess(percent ~ ncms * dsl, d, 
> control=loess.control(trace.hat =
> 'approximate'))
>     grid <- data.frame(expand.grid(dsl=MINVAL:MAXVAL, 
> ncms=MINCMS:MAXCMS)) ...
> 
> This is obviously pretty silly code (although of course it does work).
> 
> I imagine that my question is obvious: given that I have a 
> variable, ORDINATE, whose value is a string, how do I 
> re-write statements such as the "lo <-" and "grid <-" 
> statements above so that they use ORDINATE instead of the 
> hard-coded names "ds" and "dsl".
> 
> I am almost sure (almost) that it has something to do with 
> "deparse()", but I couldn't find the right incantation, and 
> the ?deparse() help left my head swimming.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Greg.Snow at intermountainmail.org  Wed Sep  5 21:00:18 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 5 Sep 2007 13:00:18 -0600
Subject: [R] Multiple xyplots
In-Reply-To: <46DEC313.5040201@maladmin.com>
References: <46DEC313.5040201@maladmin.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBB3E1D@LP-EXCHVS07.CO.IHC.COM>

Take a look at the my.symbols function in the TeachingDemos package.
The last example shows how to create a hexagonal grid and the 2nd to
last example shows how to plot several small line plots onto a larger
plot.  Combining these 2 examples should give you what you want.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tom Wright
> Sent: Wednesday, September 05, 2007 8:54 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Multiple xyplots
> 
> Hi everyone,
> I'm hoping you can give me some pointers. I have a 
> requirement to draw multiple (103) xy line plots onto one 
> output device. Ideally the plots should be displayed in a 
> hexagonal grid (example at www.maladmin.com/example.jpg). I 
> can calculate the locations for each waveform but am 
> wondering how to create multiple plotting areas. I have come 
> accross references to a package grid (which doesn't seem to 
> be in my CRAN mirror probability.ca) and lattice but I'm not 
> sure if I'm on the correct lines.
> Any advice gratefully received.
> Thanks
> Tom
> 
> --
> --Tom Wright
> ____________________________________________
> | Contact me:                               |
> | Skype: 0121 288 0756    tomwright01)      |
> | MSN: passport at macrobot.net                |
> | Jabber: maladmin at xim.ca                   |
> | ICQ: 423913453                            |
> |___________________________________________|
> 
> 
> Ever since prehistoric times, wise men have tried to 
> understand what, exactly, make people laugh.  That's why they 
> were called "wise men."
> All the other prehistoric people were out puncturing each 
> other with spears, and the wise men were back in the cave 
> saying: "How about:
> Would you please take my wife?  No.  How about: Here is my 
> wife, please take her right now.  No How about:  Would you 
> like to take something?
> My wife is available.  No.  How about ..."
>           -- Dave Barry, "Why Humor is Funny"
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From andy_liaw at merck.com  Wed Sep  5 21:02:18 2007
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 5 Sep 2007 15:02:18 -0400
Subject: [R] Howto sort dataframe columns by colMeans
In-Reply-To: <12485729.post@talk.nabble.com>
References: <12485729.post@talk.nabble.com>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04A4AB0C@usctmx1106.merck.com>

Something like the following may do what you want:

R> mydata.sorted <- mydata[c(1, 1 + order(colMeans(mydata[-1]),
decreasing=TRUE))]
R> mydata.sorted
   time met.c met.a met.b
1 00:00    99    42    18
2 00:05    67    88    16
3 00:10    84    80    27

(Note that I'm assuming that your first variable in the data frame is
not one of the things you want to include in your sorting.)

Andy


From: Lynn Osburn
> 
> I read from external data source containing several columns.  
> Each column
> represents value of a metric.  The columns are time series data.
> 
> I want to sort the resulting dataframe such that the column 
> with the largest
> mean is the leftmost column, descending in colMean values to 
> the right.
> 
> I see many solutions for sorting rows based on some column 
> characteristic,
> but haven't found any discussion of sorting columns based on column
> characteristics.
> 
> viz.  input data looks like this
>   time   met-a    met-b    met-c
> 00:00    42         18          99
> 00:05    88         16          67
> 00:10    80         27          84
> 
> desired output:
>  time   met-c    met-a     met-b
> 00:00    99         42          18
> 00:05    67         88          16
> 00:10    84         80          27
> 
> Thanks,
> -Lynn
> 
> -- 
> View this message in context: 
> http://www.nabble.com/Howto-sort-dataframe-columns-by-colMeans
> -tf4380044.html#a12485729
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}


From mail at friedrich-schuster.de  Wed Sep  5 21:21:44 2007
From: mail at friedrich-schuster.de (Friedrich Schuster)
Date: Wed, 5 Sep 2007 21:21:44 +0200
Subject: [R]  list element to matrix
Message-ID: <200709052121.44322.mail@friedrich-schuster.de>

You get the number of list elements with length(D), 
the dimensions of M1 with dim(M1)

see help with: 
?dim
?length

Hope this helps...


>I have created a list of "matrices" using sapply or lapply and wish to 
>extract each of the "matrices" as a matrix.  Some of them are 2x2, 3x3, etc.

>I can do this one at a time as:

>M1<-as.matrix(D[[1]])

>How can repeat this process for an unknown number of entries in the list?  In 
>other words, how shall I index M1?


>Diana

-- 

Friedrich Schuster
mail at friedrich-schuster.de
Tel.: +49 6221 737474
Tel.: +49 163 7374744


From tplate at acm.org  Wed Sep  5 21:22:13 2007
From: tplate at acm.org (Tony Plate)
Date: Wed, 05 Sep 2007 13:22:13 -0600
Subject: [R] Q: selecting a name when it is known as a string
In-Reply-To: <46DECA24.8060308@gmail.com>
References: <46DDD8CF.6010005@gmail.com> <46DECA24.8060308@gmail.com>
Message-ID: <46DF01E5.3010805@acm.org>

For the column names of the result of expand.grid(), I would just assign 
them the values I wanted, like this:

 > x <- expand.grid(tmp=1:3,y=1:2)
 > x
   tmp y
1   1 1
2   2 1
3   3 1
4   1 2
5   2 2
6   3 2
 > colnames(x)[1] <- "whatever"
 > x
   whatever y
1        1 1
2        2 1
3        3 1
4        1 2
5        2 2
6        3 2
 >

-- Tony Plate

D. R. Evans wrote:
> D. R. Evans said the following at 09/04/2007 04:14 PM :
>> I am 100% certain that there is an easy way to do this, but after
> 
> I have reconsidered this and now believe it to be essentially impossible
> (or at the very least remarkably difficult) although I don't understand why
> it is so :-(
> 
> At least, I spent another two hours trying variations on the suggestions I
> received, but still nothing worked properly.
> 
> It sure seems like it _ought_ to be easy, because of the following argument:
> 
> If I type an expression such as "A <- <something>" then R is perfectly
> capable of parsing the <something> and executing it and assigning the
> result to A. So it seems to follow that it ought to be able to parse a
> string that contains exactly the same sequence of characters (after all,
> why should the R parsing engine care whether the input string comes from
> the terminal or from a variable?) and therefore it should be possible to
> assign "<something>" to a variable and then have R parse that variable
> precisely as if it had been typed.
> 
> That was my logic as to why this ought to be easy, anyway. (And there was
> the subsidiary argument that this is easy in the other languages I use, but
> R is sufficiently different that I'm not certain that that argument carries
> much force.)
> 
> It does seem that there are several ways to make the
> 
>   lo <- loess(percent ~ ncms * ds, d, control=loess.control(trace.hat =
>> 'approximate'))
> 
> command work OK if the right hand side is in a character variable, but I
> haven't been able to find a way to make
> 
>   grid <- data.frame(expand.grid(ds=MINVAL:MAXVAL, ncms=MINCMS:MAXCMS))
> 
> work.
> 
> I always end up with a parse error or a complaint that "'newdata' does not
> contain the variables needed" when I perform the next task:
> 
>   plo <- predict(lo, grid).
> 
> So I guess I have to stick with half a dozen compound "if" statements, all
> of which do essentially the same thing :-(
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Todd.Remund at atk.com  Wed Sep  5 22:17:01 2007
From: Todd.Remund at atk.com (Remund, Todd)
Date: Wed, 5 Sep 2007 14:17:01 -0600
Subject: [R] Round Off Error Variance
Message-ID: <290C84AEAA27E5489BD772CB179E086301205C97@ut40se02.atk.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070905/17db42ef/attachment.pl 

From wlwhui at student.math.uwaterloo.ca  Wed Sep  5 22:18:26 2007
From: wlwhui at student.math.uwaterloo.ca (Wallace Hui)
Date: Wed, 05 Sep 2007 16:18:26 -0400
Subject: [R] Question about making array dataset inside a package
Message-ID: <20070905161826.uu8kd5oogso4s4s8@www.nexusmail.uwaterloo.ca>

Hello

I have a question about how I can include an array dataset inside a  
package. In our package, one R function is designed to take an array  
of 2 rows * 2 columns * k levels as input data enter by the user,  
where k is positive integers. I am trying to include a 3-D array of  
2-by-2-by-8 as dataset in the package, so users can load the data  
using data(dataname). We prefer to load the data as dataset, rather  
than include the long syntax in the help file for users to copy and  
paste. I can generate array in R console using long chain of syntax  
like:   > arraydat=array(.....omitted.......)

However, I cannot figure a way to save the data in 3D array data frame format
using write(), write.table(), or use data.frame() etc. If I directly  
copy-paste the screen output to a text file. I cannot read it into R  
using like:

> arraydat=read.table("array.txt", header=TRUE)

This will give me a 2 rows by (2*k) columns two-dimension data set,  
and lost all level (or depth) structure for the purpose of our R  
function. The header is messed too.

I appreciate if any expert can tell me how to include/save array  
stucture in dataset in R, and also how to read it into R to preserve  
the header and array structure.

Thank you for your time.


From Max.Kuhn at pfizer.com  Wed Sep  5 22:23:22 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Wed, 5 Sep 2007 16:23:22 -0400
Subject: [R] Question about making array dataset inside a package
In-Reply-To: <20070905161826.uu8kd5oogso4s4s8@www.nexusmail.uwaterloo.ca>
Message-ID: <71257D09F114DA4A8E134DEAC70F25D3096C932A@groamrexm03.amer.pfizer.com>

Please read 

  http://cran.r-project.org/doc/manuals/R-exts.html 

especially Section 1.1.3. Use save to create an Rdata file.

Max

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Wallace Hui
Sent: Wednesday, September 05, 2007 4:18 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Question about making array dataset inside a package

Hello

I have a question about how I can include an array dataset inside a  
package. In our package, one R function is designed to take an array  
of 2 rows * 2 columns * k levels as input data enter by the user,  
where k is positive integers. I am trying to include a 3-D array of  
2-by-2-by-8 as dataset in the package, so users can load the data  
using data(dataname). We prefer to load the data as dataset, rather  
than include the long syntax in the help file for users to copy and  
paste. I can generate array in R console using long chain of syntax  
like:   > arraydat=array(.....omitted.......)

However, I cannot figure a way to save the data in 3D array data frame
format
using write(), write.table(), or use data.frame() etc. If I directly  
copy-paste the screen output to a text file. I cannot read it into R  
using like:

> arraydat=read.table("array.txt", header=TRUE)

This will give me a 2 rows by (2*k) columns two-dimension data set,  
and lost all level (or depth) structure for the purpose of our R  
function. The header is messed too.

I appreciate if any expert can tell me how to include/save array  
stucture in dataset in R, and also how to read it into R to preserve  
the header and array structure.

Thank you for your time.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From FolkesM at pac.dfo-mpo.gc.ca  Wed Sep  5 22:56:12 2007
From: FolkesM at pac.dfo-mpo.gc.ca (Folkes, Michael)
Date: Wed, 5 Sep 2007 13:56:12 -0700
Subject: [R] Lattice: key with expression function
In-Reply-To: <eb555e660709051127i2e4bc2dbl37ee3bcdd7449480@mail.gmail.com>
Message-ID: <63F107BCC37AEA49A75FD94AA3E07CB099F52E@pacpbsex01.pac.dfo-mpo.ca>

Thanks to Deepayan...again, for suggesting "parse".
Here is how I added the degree symbol to a vector of text for my xyplot
legend:

auto.key =list(points = FALSE,text=parse(text =
paste(levels(as.factor(divertSST2$temp)), "*degree", sep = ""))), 

For me the tricky part was learning about adding the '*'.  I found that
in this suggestion:
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/78961.html

Michael Folkes

-----Original Message-----
From: deepayan.sarkar at gmail.com [mailto:deepayan.sarkar at gmail.com] 
Sent: September 5, 2007 11:27 AM
To: Folkes, Michael
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Lattice: key with expression function


On 9/5/07, Folkes, Michael <FolkesM at pac.dfo-mpo.gc.ca> wrote:
> HI all,
> I'm trying (unsuccessfully) to add the degree symbol to each line of 
> text in my legend (within xyplot). Here is the line of code, which 
> fails to interpret the expression
> function:
>
> auto.key =list(points = 
> FALSE,text=paste(levels(as.factor(divertSST2$temp)),expression(degree)
> ).
> ..),
>
> I just get:
> 7 degree
> 8 degree
> 9 degree

That's because

> paste("foo", expression(degree))
[1] "foo degree"


> If I place 'expression' outside or just after the paste function it 
> also doesn't work.

auto.key = list(text = expression(paste("foo", degree)))

should work. I think the problem is that you want a vector of
expressions, and that's a bit harder to get. I'm not sure what the best
solution is, but if everything else fails, you could try using
parse(text=)

-Deepayan


From jholtman at gmail.com  Wed Sep  5 23:48:37 2007
From: jholtman at gmail.com (jim holtman)
Date: Wed, 5 Sep 2007 17:48:37 -0400
Subject: [R] list element to matrix
In-Reply-To: <20070905104739.BDS36834@mail.sdsu.edu>
References: <20070905104739.BDS36834@mail.sdsu.edu>
Message-ID: <644e1f320709051448o5a9b4c73s59f271b1b1e1231@mail.gmail.com>

If they are already a matrix in the list, then you don't have to use
'as.matrix'; you can just say:

M1 <- D[[1]]

Now the question is, what do you mean by how do you index M1?  Do you
want to go through the list applying a function to each matrix?  If
so, then just 'lapply'.  For example, to get the column means, you
would do:

mean.list <- lapply(D, colMeans)

Can you explain in a little more detail the problem you are trying to solve.

On 9/5/07, dverzi at mail.sdsu.edu <dverzi at mail.sdsu.edu> wrote:
> I have created a list of "matrices" using sapply or lapply and wish to extract each of the "matrices" as a matrix.  Some of them are 2x2, 3x3, etc.
>
> I can do this one at a time as:
>
> M1<-as.matrix(D[[1]])
>
> How can repeat this process for an unknown number of entries in the list?  In other words, how shall I index M1?
>
> Diana
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From srini_iyyer_bio at yahoo.com  Wed Sep  5 23:48:48 2007
From: srini_iyyer_bio at yahoo.com (Srinivas Iyyer)
Date: Wed, 5 Sep 2007 14:48:48 -0700 (PDT)
Subject: [R] writing elements in list as a data frame
Message-ID: <647875.3730.qm@web38104.mail.mud.yahoo.com>

Dear R-helpers, 
Lists in R are stumbling block for me.

I kindly ask you to help me able to write a
data-frame. 

I have a list of lists. 

> sls[1:2]
$Andromeda_maya1
       x   y
[1,] 369 103
[2,] 382 265
[3,] 317 471
[4,] 169 465
[5,] 577 333

$Andromeda_maya2
        x   y
 [1,] 173 507
 [2,] 540 395
 [3,] 268 143
 [4,] 346 175
 [5,] 489  91
 
I want to be able to write a data.frame like the
following:
X   Y     Name
369 103  Andromeda_maya1
382 265  Andromeda_maya1
317 471  Andromeda_maya1
169 465  Andromeda_maya1
577 333  Andromeda_maya1
173 507  Andromeda_maya2
540 395  Andromeda_maya2
268 143  Andromeda_maya2
346 175  Andromeda_maya2
489  91  Andromeda_maya2

Is there a way to convert this list-of-list into a
data.frame.

Thanks
srini


From jholtman at gmail.com  Thu Sep  6 00:01:37 2007
From: jholtman at gmail.com (jim holtman)
Date: Wed, 5 Sep 2007 18:01:37 -0400
Subject: [R] writing elements in list as a data frame
In-Reply-To: <647875.3730.qm@web38104.mail.mud.yahoo.com>
References: <647875.3730.qm@web38104.mail.mud.yahoo.com>
Message-ID: <644e1f320709051501n7298ebc6ufa1aa0dee9d0563c@mail.gmail.com>

Try this:

> sls <- list(a=matrix(sample(10), ncol=2, dimnames=list(NULL, c('x', 'y'))),
+     b=matrix(sample(16), ncol=2, dimnames=list(NULL, c('x', 'y'))))
> sls
$a
     x  y
[1,] 8  2
[2,] 9 10
[3,] 4  1
[4,] 5  7
[5,] 3  6

$b
      x  y
[1,]  4 14
[2,]  3 15
[3,] 16  5
[4,]  1  9
[5,]  8  7
[6,] 10  2
[7,] 12 13
[8,] 11  6

> # create output matrix
> do.call('rbind', lapply(names(sls), function(.name){
+     data.frame(sls[[.name]], Name=.name)
+ }))
    x  y Name
1   8  2    a
2   9 10    a
3   4  1    a
4   5  7    a
5   3  6    a
6   4 14    b
7   3 15    b
8  16  5    b
9   1  9    b
10  8  7    b
11 10  2    b
12 12 13    b
13 11  6    b
>
>


On 9/5/07, Srinivas Iyyer <srini_iyyer_bio at yahoo.com> wrote:
> Dear R-helpers,
> Lists in R are stumbling block for me.
>
> I kindly ask you to help me able to write a
> data-frame.
>
> I have a list of lists.
>
> > sls[1:2]
> $Andromeda_maya1
>       x   y
> [1,] 369 103
> [2,] 382 265
> [3,] 317 471
> [4,] 169 465
> [5,] 577 333
>
> $Andromeda_maya2
>        x   y
>  [1,] 173 507
>  [2,] 540 395
>  [3,] 268 143
>  [4,] 346 175
>  [5,] 489  91
>
> I want to be able to write a data.frame like the
> following:
> X   Y     Name
> 369 103  Andromeda_maya1
> 382 265  Andromeda_maya1
> 317 471  Andromeda_maya1
> 169 465  Andromeda_maya1
> 577 333  Andromeda_maya1
> 173 507  Andromeda_maya2
> 540 395  Andromeda_maya2
> 268 143  Andromeda_maya2
> 346 175  Andromeda_maya2
> 489  91  Andromeda_maya2
>
> Is there a way to convert this list-of-list into a
> data.frame.
>
> Thanks
> srini
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From dirk.enzmann at uni-hamburg.de  Thu Sep  6 00:55:53 2007
From: dirk.enzmann at uni-hamburg.de (Dirk Enzmann)
Date: Thu, 06 Sep 2007 00:55:53 +0200
Subject: [R] confidence intervals of proportions from complex surveys
Message-ID: <46DF33F9.1000602@uni-hamburg.de>

This is partly an R and partly a general statistics question.

I'm trying to get confidence intervals of proportions (sometimes for 
subgroups) estimated from complex survey data. Because a function like 
prop.test() does not exist for the "survey" package I tried the following:

1) Define a survey object (PSU of clustered sample, population weights);
2) Use svyglm() of the package "survey" to estimate a binary logistic 
regression (family='binomial'): For the confidence interval of a single 
proportion regress the binary dependent variable on a constant (1), for 
confidence intervals of that variable for subgroups regress this 
variable on the groups (factor) variable;
3) Use predict() to obtain estimated logits and the respective standard 
errors (mod.dat specifiying either the constant or the subgroups):

    pred=predict(model,mod.dat,type='link',se.fit=T)

and apply the following to obtain the proportion with its confidence 
intervals (for example, for conf.level=.95):

    lo.e = pred[1:length(pred)]-qnorm((1+conf.level)/2)*SE(pred)
    hi.e = pred[1:length(pred)]+qnorm((1+conf.level)/2)*SE(pred)
    prop = 1/(1+exp(-pred[1:length(pred)]))
    lo = 1/(1+exp(-lo.e))
    hi = 1/(1+exp(-hi.e))

I think that in that way I get CI's based on asymptotic normality - 
either for a single proportion or split up into subgroups.

Question: Is this a correct or a defensible procedure? Or should I use a 
different approach? Note that this approach should also allow to 
estimate CI's for proportions of subgroups taking into account the 
complex survey design.

TIA,
Dirk

********************************
R version 2.5.1 Patched (2007-08-10 r42469)
i386-pc-mingw32


From Karen.Green at sanofi-aventis.com  Thu Sep  6 01:17:19 2007
From: Karen.Green at sanofi-aventis.com (Karen.Green at sanofi-aventis.com)
Date: Wed, 5 Sep 2007 16:17:19 -0700
Subject: [R] question: randomization t-test function already defined in R?
Message-ID: <7E47908DD24B5243B1FEE5C4E29E7DA7017D99B2@tucsmxsusr01.tu.f2.enterprise>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070905/d3cab104/attachment.pl 

From Achim.Zeileis at wu-wien.ac.at  Thu Sep  6 01:51:33 2007
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Thu, 6 Sep 2007 01:51:33 +0200 (CEST)
Subject: [R] question: randomization t-test function already defined in
 R?
In-Reply-To: <7E47908DD24B5243B1FEE5C4E29E7DA7017D99B2@tucsmxsusr01.tu.f2.enterprise>
References: <7E47908DD24B5243B1FEE5C4E29E7DA7017D99B2@tucsmxsusr01.tu.f2.enterprise>
Message-ID: <Pine.LNX.4.64.0709060146250.14117@eowyn>

On Wed, 5 Sep 2007, Karen.Green at sanofi-aventis.com wrote:

> Dear R Users,
>
> I am hoping you can help me.
>
> I have received code from a colleague who uses Matlab.  I need to
> translate it into R.
>
> I am wondering if there is a randomization t-test (from non-parametric
> statistics) function already defined in R.
> (In Matlab the function is randtest.m.)

I don't know what randtest in MATLAB does exactly, but I guess that you 
might want to look at the function independence_test() in package "coin". 
The "distribution" argument should probably set to use either exact or 
approximate p values.

hth,
Z

> ************************************************************************
> **********
> QUESTION:  Is anyone aware of a randomization t-test function in R?
> ************************************************************************
> **********
>
> Thank you for your help,
>
> Karen
>
> ---
>
> Karen M. Green, Ph.D.
>
> Research Investigator
>
> Drug Design Group
>
> Sanofi Aventis Pharmaceuticals
>
> 1580 E. Hanley Blvd.
>
> Tucson, AZ  85737-9525
>
>  USA
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From dieterbest_2000 at yahoo.com  Thu Sep  6 03:06:46 2007
From: dieterbest_2000 at yahoo.com (Dieter Best)
Date: Wed, 5 Sep 2007 18:06:46 -0700 (PDT)
Subject: [R] change all . to 0 in a data.frame
Message-ID: <238144.36174.qm@web38410.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070905/0fbe123d/attachment.pl 

From jholtman at gmail.com  Thu Sep  6 03:39:21 2007
From: jholtman at gmail.com (jim holtman)
Date: Wed, 5 Sep 2007 21:39:21 -0400
Subject: [R] change all . to 0 in a data.frame
In-Reply-To: <238144.36174.qm@web38410.mail.mud.yahoo.com>
References: <238144.36174.qm@web38410.mail.mud.yahoo.com>
Message-ID: <644e1f320709051839m2521841en9444aea1c7b37d2c@mail.gmail.com>

Here is one way.  You might want to read in the data with 'as.is=TRUE'
to prevent conversion to factors.

> x <- data.frame(a=c(1,2,3,'.',5,'.'))
> str(x)
'data.frame':   6 obs. of  1 variable:
 $ a: Factor w/ 5 levels ".","1","2","3",..: 2 3 4 1 5 1
> # replace '.' with zero; either readin with 'as.is=TRUE' or convert to character
> x$a <- as.character(x$a)
> x$a[x$a == '.'] <- '0'
> x$a <- as.numeric(x$a)
> str(x)
'data.frame':   6 obs. of  1 variable:
 $ a: num  1 2 3 0 5 0
>
>


On 9/5/07, Dieter Best <dieterbest_2000 at yahoo.com> wrote:
> Hello,
>  I read in a tab delimited text file via mydata = read.delim(myfile). The text file was originally an excel file where . was used in place of 0. Now all the columns which should be integers are factors. Any ideas how to change all the . to 0 and factors back to integer?
>  Thanks a lot in advance for any suggestions,
>  -- D
>
>
> ---------------------------------
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From dieterbest_2000 at yahoo.com  Thu Sep  6 03:54:19 2007
From: dieterbest_2000 at yahoo.com (Dieter Best)
Date: Wed, 5 Sep 2007 18:54:19 -0700 (PDT)
Subject: [R] change all . to 0 in a data.frame
In-Reply-To: <644e1f320709051839m2521841en9444aea1c7b37d2c@mail.gmail.com>
Message-ID: <863129.68647.qm@web38411.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070905/6e6d1b88/attachment.pl 

From leeznar at yahoo.com.tw  Thu Sep  6 04:49:26 2007
From: leeznar at yahoo.com.tw (leeznar at yahoo.com.tw)
Date: Thu, 6 Sep 2007 10:49:26 +0800 (CST)
Subject: [R] The variables combined in a table from other table and
	combination questions
Message-ID: <945698.37134.qm@web73602.mail.tp2.yahoo.com>

Dear All:
I need to have some data frame objects.
First aa object:
   pH  Formulation  time  Subject
[1]1.2  F           0       1
[2]7.4  S           1       2
[3]    MF           2       3
[4]                 3       4
[5]                 n        i
Then, I need to produce 2*3(pH*formulation) different 
tables.  This table includes column of (pH,
Formulation, time  S1  S2  S3 ?K..Si) and S1= subject
1, S2=subject 2 and so on.  For example: bb1 table
   pH  Formulation  time  S1  S2  S3?K.Si
[1]1.2  F           0       
[2]                 1       
[3]                 2       
[4]                 3       
[5]                 n       

For example: bb2 table
   pH  Formulation  time  S1  S2  S3?K.Si
[1]1.2  S           0       
[2]                 1       
[3]                 2       
[4]                 3       
[5]                 n       


Moreover, the values of pH and Formulation column are
the combination questions.  The values of pH and
Formulation column should be the combinations such as
(1.2, F), (1.2, S), (1.2, MF), (7.4, F), (7.4, S),
(7.4, MF)
I am a beginner level in R and I have no idea how to
do this. Could any one please help me.  Thanks a
lot!!!

Best regrards
Hsin Ya Lee


From liy12 at mskcc.org  Thu Sep  6 04:57:29 2007
From: liy12 at mskcc.org (Yuelin Li)
Date: Wed, 5 Sep 2007 22:57:29 -0400
Subject: [R] Rggobi compilation error: display.c
Message-ID: <20070906025729.GA24764@jdmlab.mskcc.org>

On a ubuntu linux computer (Feisty, i386), I compile R and additional
packages from source.  The compiler is gcc 4.1.2.

The problem is, I can run "sudo R" and successfully compile all
packages (e.g., MASS, lattice) except rggobi.  The error seems to be
in display.c.  My ggobi is in /usr/local/, which R can find.  I don't
think this is a dependence issue because install.packages(...,
dependence=TRUE).  The script complains about not finding
"/usr/local/lib/R/library/rggobi/libs/*", but that directory is there,
with one file "rggobi.so" (possibly from an earlier successful
compilation).

Any suggestions on what I am doing wrong?  Many thanks in advance.

Yuelin.


--------- R output ---------------
> install.packages("rggobi", repos = "http://lib.stat.cmu.edu/R/CRAN", dependencies = TRUE, clean = TRUE)
trying URL 'http://lib.stat.cmu.edu/R/CRAN/src/contrib/rggobi_2.1.6.tar.gz'
Content type 'application/x-gzip' length 424483 bytes
opened URL
==================================================
downloaded 414Kb

* Installing *source* package 'rggobi' ...
checking for pkg-config... /usr/bin/pkg-config
checking pkg-config is at least version 0.9.0... yes
checking for GGOBI... yes
configure: creating ./config.status
config.status: creating src/Makevars
** libs
gcc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include -g -DUSE_EXT_PTR=1 -D_R_=1 -I/usr/local/include/ggobi -I/usr/include/gtk-2.0 -I/usr/include/libxml2 -I/usr/lib/gtk-2.0/include -I/usr/include/atk-1.0 -I/usr/include/cairo -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/freetype2 -I/usr/include/libpng12   -I/usr/local/include    -fpic  -g -O2 -c brush.c -o brush.o

[... snipped ...]

gcc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include -g -DUSE_EXT_PTR=1 -D_R_=1 -I/usr/local/include/ggobi -I/usr/include/gtk-2.0 -I/usr/include/libxml2 -I/usr/lib/gtk-2.0/include -I/usr/include/atk-1.0 -I/usr/include/cairo -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/freetype2 -I/usr/include/libpng12   -I/usr/local/include    -fpic  -g -O2 -c dataset.c -o dataset.o
gcc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include -g -DUSE_EXT_PTR=1 -D_R_=1 -I/usr/local/include/ggobi -I/usr/include/gtk-2.0 -I/usr/include/libxml2 -I/usr/lib/gtk-2.0/include -I/usr/include/atk-1.0 -I/usr/include/cairo -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/freetype2 -I/usr/include/libpng12   -I/usr/local/include    -fpic  -g -O2 -c display.c -o display.o
display.c: In function ?RS_GGOBI_createDisplay?:
display.c:37: warning: passing argument 3 of ?klass->createWithVars? makes pointer from integer without a cast
display.c:37: warning: passing argument 4 of ?klass->createWithVars? from incompatible pointer type
display.c:37: warning: passing argument 5 of ?klass->createWithVars? from incompatible pointer type
display.c:37: error: too many arguments to function ?klass->createWithVars?
display.c:39: warning: passing argument 4 of ?klass->create? from incompatible pointer type
display.c:39: error: too many arguments to function ?klass->create?
make: *** [display.o] Error 1
chmod: cannot access `/usr/local/lib/R/library/rggobi/libs/*': No such file or directory
ERROR: compilation failed for package 'rggobi'
** Removing '/usr/local/lib/R/library/rggobi'
** Restoring previous '/usr/local/lib/R/library/rggobi'


From cberry at tajo.ucsd.edu  Thu Sep  6 05:28:24 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Wed, 5 Sep 2007 20:28:24 -0700
Subject: [R] element wise opertation between a vector and a list
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBBB3DDC@LP-EXCHVS07.CO.IHC.COM>
References: <d89bf0cd0709022336l7122dfd9x7e423b2316a56201@mail.gmail.com>
	<07E228A5BE53C24CAD490193A7381BBBBB3DDC@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <Pine.LNX.4.64.0709052023470.1273@tajo.ucsd.edu>

On Wed, 5 Sep 2007, Greg Snow wrote:

>> ?mapply
>> mapply('+', a, b, SIMPLIFY=FALSE)
>> colSums(mapply('+', a, b))


or
 	sapply( a, sum ) + b * sapply( a, length )

or even

 	sapply( a, sum ) + b * 2

if all list components in 'a' are of length 2.


Then there are the do.call( cbind , a ) incantations.

Chuck

>
> Hope this helps,
>
> -- 
> Gregory (Greg) L. Snow Ph.D.
> Statistical Data Center
> Intermountain Healthcare
> greg.snow at intermountainmail.org
> (801) 408-8111
>
>
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Yongwan Chun
>> Sent: Monday, September 03, 2007 12:36 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] element wise opertation between a vector and a list
>>
>> I want to try to get a result of element wise addition
>> between a vector and a list. It can be done with "for
>> statement." In order to reducing computing time, I have tried
>> to avoid "for state." If anybody give me an idea, I would
>> apprecite it much.
>>
>> for example, with a & b as below lines,
>>
>> a<- list(c(1,3),c(1,2),c(2,3))
>> b<-c(10,20,30)
>>
>> I would like to have a list (like "d") or a vector (like "e")
>> as below.
>>
>> d<-list(c((1+10),(3+10)),c((1+20),(2+20)),c((2+30),(3+30)))
>> e<- c((1+10)+(3+10),(1+20)+(2+20),(2+30)+(3+30))
>>
>> Thanks,
>>
>>
>> Yongwan Chun
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From ripley at stats.ox.ac.uk  Thu Sep  6 07:56:00 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Sep 2007 06:56:00 +0100 (BST)
Subject: [R] Rggobi compilation error: display.c
In-Reply-To: <20070906025729.GA24764@jdmlab.mskcc.org>
References: <20070906025729.GA24764@jdmlab.mskcc.org>
Message-ID: <Pine.LNX.4.64.0709060648500.19291@gannet.stats.ox.ac.uk>

On Wed, 5 Sep 2007, Yuelin Li wrote:

> On a ubuntu linux computer (Feisty, i386), I compile R and additional
> packages from source.  The compiler is gcc 4.1.2.
>
> The problem is, I can run "sudo R" and successfully compile all
> packages (e.g., MASS, lattice) except rggobi.  The error seems to be
> in display.c.  My ggobi is in /usr/local/, which R can find.  I don't
> think this is a dependence issue because install.packages(...,
> dependence=TRUE).  The script complains about not finding
> "/usr/local/lib/R/library/rggobi/libs/*", but that directory is there,
> with one file "rggobi.so" (possibly from an earlier successful
> compilation).

I don't think the file was there at the time, before the previous 
installation was restored.

> Any suggestions on what I am doing wrong?  Many thanks in advance.

Here is the error:

> display.c:37: error: too many arguments to function ??klass->createWithVars??

That is a symptom of installing rggobi_2.1.6 against ggobi 2.1.4: 
unfortunately rggobi's configure did not check the ggobi version.
It looks like you have an earlier rggobi installed, probably the one 
appropriate to your ggobi version.

> Yuelin.
>
>
> --------- R output ---------------
>> install.packages("rggobi", repos = "http://lib.stat.cmu.edu/R/CRAN", dependencies = TRUE, clean = TRUE)
> trying URL 'http://lib.stat.cmu.edu/R/CRAN/src/contrib/rggobi_2.1.6.tar.gz'
> Content type 'application/x-gzip' length 424483 bytes
> opened URL
> ==================================================
> downloaded 414Kb
>
> * Installing *source* package 'rggobi' ...
> checking for pkg-config... /usr/bin/pkg-config
> checking pkg-config is at least version 0.9.0... yes
> checking for GGOBI... yes
> configure: creating ./config.status
> config.status: creating src/Makevars
> ** libs
> gcc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include -g -DUSE_EXT_PTR=1 -D_R_=1 -I/usr/local/include/ggobi -I/usr/include/gtk-2.0 -I/usr/include/libxml2 -I/usr/lib/gtk-2.0/include -I/usr/include/atk-1.0 -I/usr/include/cairo -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/freetype2 -I/usr/include/libpng12   -I/usr/local/include    -fpic  -g -O2 -c brush.c -o brush.o
>
> [... snipped ...]
>
> gcc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include -g -DUSE_EXT_PTR=1 -D_R_=1 -I/usr/local/include/ggobi -I/usr/include/gtk-2.0 -I/usr/include/libxml2 -I/usr/lib/gtk-2.0/include -I/usr/include/atk-1.0 -I/usr/include/cairo -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/freetype2 -I/usr/include/libpng12   -I/usr/local/include    -fpic  -g -O2 -c dataset.c -o dataset.o
> gcc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include -g -DUSE_EXT_PTR=1 -D_R_=1 -I/usr/local/include/ggobi -I/usr/include/gtk-2.0 -I/usr/include/libxml2 -I/usr/lib/gtk-2.0/include -I/usr/include/atk-1.0 -I/usr/include/cairo -I/usr/include/pango-1.0 -I/usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -I/usr/include/freetype2 -I/usr/include/libpng12   -I/usr/local/include    -fpic  -g -O2 -c display.c -o display.o
> display.c: In function ??RS_GGOBI_createDisplay??:
> display.c:37: warning: passing argument 3 of ??klass->createWithVars?? makes pointer from integer without a cast
> display.c:37: warning: passing argument 4 of ??klass->createWithVars?? from incompatible pointer type
> display.c:37: warning: passing argument 5 of ??klass->createWithVars?? from incompatible pointer type
> display.c:37: error: too many arguments to function ??klass->createWithVars??
> display.c:39: warning: passing argument 4 of ??klass->create?? from incompatible pointer type
> display.c:39: error: too many arguments to function ??klass->create??
> make: *** [display.o] Error 1
> chmod: cannot access `/usr/local/lib/R/library/rggobi/libs/*': No such file or directory
> ERROR: compilation failed for package 'rggobi'
> ** Removing '/usr/local/lib/R/library/rggobi'
> ** Restoring previous '/usr/local/lib/R/library/rggobi'
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From emres at bilgi.edu.tr  Thu Sep  6 08:55:36 2007
From: emres at bilgi.edu.tr (Emre Sevinc)
Date: Thu, 6 Sep 2007 09:55:36 +0300
Subject: [R] How to do ANOVA with fractional values and overcome the error:
	Error in `storage.mode<-`(`*tmp*`,
	value = "double") : invalid to change the storage mode of a factor
Message-ID: <9940BA60F8E6414F9F0307DD411BCF690CDE649A@Ex2k.bilgi.networks>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070906/8f9ea37c/attachment.pl 

From gustaf.rydevik at gmail.com  Thu Sep  6 09:13:27 2007
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Thu, 6 Sep 2007 09:13:27 +0200
Subject: [R] Q: selecting a name when it is known as a string
In-Reply-To: <46DECA24.8060308@gmail.com>
References: <46DDD8CF.6010005@gmail.com> <46DECA24.8060308@gmail.com>
Message-ID: <45f568c70709060013g15fff6f6neb512f2af1b06d32@mail.gmail.com>

On 9/5/07, D. R. Evans <doc.evans at gmail.com> wrote:
> D. R. Evans said the following at 09/04/2007 04:14 PM :
> > I am 100% certain that there is an easy way to do this, but after
>
> I have reconsidered this and now believe it to be essentially impossible
> (or at the very least remarkably difficult) although I don't understand why
> it is so :-(
>
> At least, I spent another two hours trying variations on the suggestions I
> received, but still nothing worked properly.
>
> It sure seems like it _ought_ to be easy, because of the following argument:
>
> If I type an expression such as "A <- <something>" then R is perfectly
> capable of parsing the <something> and executing it and assigning the
> result to A. So it seems to follow that it ought to be able to parse a
> string that contains exactly the same sequence of characters (after all,
> why should the R parsing engine care whether the input string comes from
> the terminal or from a variable?) and therefore it should be possible to
> assign "<something>" to a variable and then have R parse that variable
> precisely as if it had been typed.
>
> That was my logic as to why this ought to be easy, anyway. (And there was
> the subsidiary argument that this is easy in the other languages I use, but
> R is sufficiently different that I'm not certain that that argument carries
> much force.)
>
> It does seem that there are several ways to make the
>
>   lo <- loess(percent ~ ncms * ds, d, control=loess.control(trace.hat =
> > 'approximate'))
>
> command work OK if the right hand side is in a character variable, but I
> haven't been able to find a way to make
>
>   grid <- data.frame(expand.grid(ds=MINVAL:MAXVAL, ncms=MINCMS:MAXCMS))
>
> work.
>
> I always end up with a parse error or a complaint that "'newdata' does not
> contain the variables needed" when I perform the next task:
>
>   plo <- predict(lo, grid).
>
> So I guess I have to stick with half a dozen compound "if" statements, all
> of which do essentially the same thing :-(
>

How about:

> foo<-c("a","b")
> a<-1
> b<-2
> lapply(foo,function(x){eval(parse(text=paste(c("10+",x),collapse="")))})
[[1]]
[1] 11

[[2]]
[1] 12


,i.e you build up a text string containing your function call, and
then evaluate it, once for each value of foo?

/Gustaf


-- 
Gustaf Rydevik, M.Sci.
tel: +46(0)703 051 451
address:Essingetorget 40,112 66 Stockholm, SE
skype:gustaf_rydevik


From gustaf.rydevik at gmail.com  Thu Sep  6 09:18:04 2007
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Thu, 6 Sep 2007 09:18:04 +0200
Subject: [R] Q: selecting a name when it is known as a string
In-Reply-To: <45f568c70709060013g15fff6f6neb512f2af1b06d32@mail.gmail.com>
References: <46DDD8CF.6010005@gmail.com> <46DECA24.8060308@gmail.com>
	<45f568c70709060013g15fff6f6neb512f2af1b06d32@mail.gmail.com>
Message-ID: <45f568c70709060018i28b88199pe8454a863dca9e0b@mail.gmail.com>

On 9/6/07, Gustaf Rydevik <gustaf.rydevik at gmail.com> wrote:
> On 9/5/07, D. R. Evans <doc.evans at gmail.com> wrote:
> > D. R. Evans said the following at 09/04/2007 04:14 PM :
> > > I am 100% certain that there is an easy way to do this, but after
> >
> > I have reconsidered this and now believe it to be essentially impossible
> > (or at the very least remarkably difficult) although I don't understand why
> > it is so :-(

>
> How about:
>
> > foo<-c("a","b")
> > a<-1
> > b<-2
> > lapply(foo,function(x){eval(parse(text=paste(c("10+",x),collapse="")))})
> [[1]]
> [1] 11
>
> [[2]]
> [1] 12
>
>
> ,i.e you build up a text string containing your function call, and
> then evaluate it, once for each value of foo?
>
> /Gustaf

Applied to loess, it gives nice function names as well:

 a<-rnorm(10)
> b<-rnorm(10)
> lapply(foo,function(x){eval(parse(text=paste(c("loess(y~",x,")"),collapse="")))})
[[1]]
Call:
loess(formula = y ~ a)

Number of Observations: 10
Equivalent Number of Parameters: 4.61
Residual Standard Error: 1.219

[[2]]
Call:
loess(formula = y ~ b)

Number of Observations: 10
Equivalent Number of Parameters: 4.45
Residual Standard Error: 1.433


-- 
Gustaf Rydevik, M.Sci.
tel: +46(0)703 051 451
address:Essingetorget 40,112 66 Stockholm, SE
skype:gustaf_rydevik


From pensterfuzzer at yahoo.de  Thu Sep  6 09:34:54 2007
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Thu, 6 Sep 2007 09:34:54 +0200 (CEST)
Subject: [R] capture.out(system())?
In-Reply-To: <45f568c70709050031v19e935abgd81ead4d0b646fff@mail.gmail.com>
Message-ID: <455656.4905.qm@web23013.mail.ird.yahoo.com>

Thank you very much, Professor Ripley!
I am using Windows 2000 and the "intern=T" argument of
system() did exactly what I needed: Now system()
returns the output of the external program as an
object.

Thanks again,
  Werner


--- Gustaf Rydevik <gustaf.rydevik at gmail.com> schrieb:

> On 9/4/07, Werner Wernersen <pensterfuzzer at yahoo.de>
> wrote:
> > Hi,
> >
> > I am trying to capture the console output of
> program I
> > call via system() but that always returns only
> > character(0).
> >
> > For example:
> > capture.output(system("pdflatex out.tex") )
> >
> > will yield:
> > character(0)
> >
> > and the output still written to the R console.
> >
> > Is there a command for intercepting this output?
> >
> > Thank you!
> >   Werner
> >
> 
> ?sink()
> 
> -- 
> Gustaf Rydevik, M.Sci.
> tel: +46(0)703 051 451
> address:Essingetorget 40,112 66 Stockholm, SE
> skype:gustaf_rydevik
>


From ripley at stats.ox.ac.uk  Thu Sep  6 09:43:07 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 6 Sep 2007 08:43:07 +0100 (BST)
Subject: [R] How to do ANOVA with fractional values and overcome the
 error: Error in `storage.mode<-`(`*tmp*`,
 value = "double") : invalid to change the storage mode of a factor
In-Reply-To: <9940BA60F8E6414F9F0307DD411BCF690CDE649A@Ex2k.bilgi.networks>
References: <9940BA60F8E6414F9F0307DD411BCF690CDE649A@Ex2k.bilgi.networks>
Message-ID: <Pine.LNX.4.64.0709060838430.20735@gannet.stats.ox.ac.uk>

Your data file has commas as the decimal point. Use read.csv2 for such 
files.

What happened was that PercentError was read as a factor, and you can't do 
ANOVA on factors.  The warning

> In addition: Warning message:
> using type="numeric" with a factor response will be ignored in:
> model.response(mf, "numeric")

told you and us this quite explicitly.  If you get an error, also look at 
the warnings which may well (as here) tell you what precipitated the 
error.

On Thu, 6 Sep 2007, Emre Sevinc wrote:

> I have exported a CSV file from my EXCEL worksheet and its last column contained decimal values:
>
> Subject;Group;Side;Difference;PercentError
> M3;1;1;;
> M5;1;1;375;18,75
> M8;1;1;250;14,58
> M10;1;1;500;12,50
> M12;1;1;375;25,00
> .
> .
> .
>
>
> When I tried to do ANOVA test on it, R complained by givin error:
>
>> Anova3LongAuditoryFemaleError.data <- read.csv("C:\\Documents\ and\ Settings\\Administrator\\My Documents\\CogSci\\tez\\Anova3LongAuditoryFemaleError.csv", header = TRUE, sep = ";")
>
>> Anova3LongAuditoryFemaleError.aov = aov(PercentError ~ (Group * Side), data = Anova3LongAuditoryFemaleError.data)
>
> Error in `storage.mode<-`(`*tmp*`, value = "double") :
>        invalid to change the storage mode of a factor
> In addition: Warning message:
> using type="numeric" with a factor response will be ignored in:
> model.response(mf, "numeric")
>
> What must I do in order to make the ANOVA test on these fractional data?
>
> Regards.
>
> --
> Emre Sevinc
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From elyakhlifi_mustapha at yahoo.fr  Thu Sep  6 09:48:22 2007
From: elyakhlifi_mustapha at yahoo.fr (elyakhlifi mustapha)
Date: Thu, 6 Sep 2007 07:48:22 +0000 (GMT)
Subject: [R] kendall test
Message-ID: <185980.27960.qm@web27513.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070906/20a182c0/attachment.pl 

From xingwang.ye at gmail.com  Thu Sep  6 09:54:08 2007
From: xingwang.ye at gmail.com (Xingwang Ye)
Date: Thu, 06 Sep 2007 15:54:08 +0800
Subject: [R] Warning message with aggregate function
Message-ID: <46DFB220.3050403@gmail.com>

Dear all,
When I use aggregate function as:

attach(warpbreaks)
aggregate(warpbreaks[, 1], list(wool = wool, tension = tension), sum)

The results are right but I get a warning message:
"number of items to replace is not a multiple of replacement length."

BTW: I use R version 2.4.1 in Ubuntu 7.04.

Your kind solutions will be great appreciated.

Best wishes

Yours, sincerely,
Xingwang Ye


From nibkan at yahoo.com  Thu Sep  6 10:13:01 2007
From: nibkan at yahoo.com (betul kan)
Date: Thu, 6 Sep 2007 01:13:01 -0700 (PDT)
Subject: [R] smooth functions
Message-ID: <111378.90899.qm@web62101.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070906/bee980de/attachment.pl 

From stefan.grosse at uni-erfurt.de  Thu Sep  6 10:26:15 2007
From: stefan.grosse at uni-erfurt.de (Stefan Grosse)
Date: Thu, 06 Sep 2007 10:26:15 +0200
Subject: [R] kendall test
In-Reply-To: <185980.27960.qm@web27513.mail.ukl.yahoo.com>
References: <185980.27960.qm@web27513.mail.ukl.yahoo.com>
Message-ID: <200709061026.15721.stefan.grosse@uni-erfurt.de>

On Thursday 06 September 2007 09:48:22 elyakhlifi mustapha wrote:

em > I thougth that there is a function which does the kendall test in R,
em > I writed on the console apropos("kendall") and I didn't found anything
em >  can you tell me how could I do to use the kendall test? 

?cor.test

btw.: rseek.org is a very good help for such questions

Stefan


From Ted.Harding at manchester.ac.uk  Thu Sep  6 10:39:07 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Thu, 06 Sep 2007 09:39:07 +0100 (BST)
Subject: [R] How to do ANOVA with fractional values and overcome the
In-Reply-To: <9940BA60F8E6414F9F0307DD411BCF690CDE649A@Ex2k.bilgi.networks>
Message-ID: <XFMail.070906093907.Ted.Harding@manchester.ac.uk>


On 06-Sep-07 06:55:36, Emre Sevinc wrote:
> I have exported a CSV file from my EXCEL worksheet and its last column
> contained decimal values:
> 
> Subject;Group;Side;Difference;PercentError
> M3;1;1;;
> M5;1;1;375;18,75
> M8;1;1;250;14,58
> M10;1;1;500;12,50
> M12;1;1;375;25,00
> .
> .
> .
> 
> 
> When I tried to do ANOVA test on it, R complained by givin error:
> 
>> Anova3LongAuditoryFemaleError.data <- read.csv("C:\\Documents\ and\
>> Settings\\Administrator\\My
>> Documents\\CogSci\\tez\\Anova3LongAuditoryFemaleError.csv", header =
>> TRUE, sep = ";")

Perhaps you need to specify the "dec" option to read.csv():

     read.csv(file, header = TRUE, sep = ",", quote="\"", dec=".",
              fill = TRUE, ...)

i.e.

Anova3LongAuditoryFemaleError.data <- read.csv("C:\\Documents\ and\
Settings\\Administrator\\My
Documents\\CogSci\\tez\\Anova3LongAuditoryFemaleError.csv",
header = TRUE, sep = ";", dec=",")

Or else use read.csv2(), where dec = "," is the default. See

  ?read.csv

and read about both read.csv and read.csv2

Otherwise, "18,75" is likely to be treated as text, and not as
a numerical value, and so PercetError will be converted into
a factor with character-valued levels.

Ted.

> 
>> Anova3LongAuditoryFemaleError.aov = aov(PercentError ~ (Group * Side),
>> data = Anova3LongAuditoryFemaleError.data)
> 
> Error in `storage.mode<-`(`*tmp*`, value = "double") : 
>         invalid to change the storage mode of a factor
> In addition: Warning message:
> using type="numeric" with a factor response will be ignored in:
> model.response(mf, "numeric")
> 
> What must I do in order to make the ANOVA test on these fractional
> data?
> 
> Regards.
> 
> --
> Emre Sevinc
> 
>       [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 06-Sep-07                                       Time: 09:39:04
------------------------------ XFMail ------------------------------


From ligges at statistik.uni-dortmund.de  Thu Sep  6 10:48:34 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 06 Sep 2007 10:48:34 +0200
Subject: [R] Warning message with aggregate function
In-Reply-To: <46DFB220.3050403@gmail.com>
References: <46DFB220.3050403@gmail.com>
Message-ID: <46DFBEE2.6040803@statistik.uni-dortmund.de>



Xingwang Ye wrote:
> Dear all,
> When I use aggregate function as:
> 
> attach(warpbreaks)
> aggregate(warpbreaks[, 1], list(wool = wool, tension = tension), sum)
> 
> The results are right but I get a warning message:
> "number of items to replace is not a multiple of replacement length."
> 
> BTW: I use R version 2.4.1 in Ubuntu 7.04.


Does not happen for me, neither with R-2.4.1 nor with recent versions of 
R. Maybe you have redefined one of the used objects (aggregate, 
warpbreaks, wool, tension, sum) in one of your environments?

BTW: Is is always a bad idea to make much use of attach()...

Uwe Ligges


> Your kind solutions will be great appreciated.
> 
> Best wishes
> 
> Yours, sincerely,
> Xingwang Ye
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From eugen_pircalabelu at yahoo.com  Thu Sep  6 11:15:24 2007
From: eugen_pircalabelu at yahoo.com (eugen pircalabelu)
Date: Thu, 6 Sep 2007 02:15:24 -0700 (PDT)
Subject: [R] the survey package
Message-ID: <300041.24688.qm@web38611.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070906/f417f8d3/attachment.pl 

From jim at bitwrit.com.au  Thu Sep  6 11:58:28 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 06 Sep 2007 19:58:28 +1000
Subject: [R] list element to matrix
In-Reply-To: <20070905104739.BDS36834@mail.sdsu.edu>
References: <20070905104739.BDS36834@mail.sdsu.edu>
Message-ID: <46DFCF44.6060200@bitwrit.com.au>

dverzi at mail.sdsu.edu wrote:
> I have created a list of "matrices" using sapply or lapply and wish to extract each of the "matrices" as a matrix.  Some of them are 2x2, 3x3, etc.
> 
> I can do this one at a time as:
> 
> M1<-as.matrix(D[[1]])
> 
> How can repeat this process for an unknown number of entries in the list?  In other words, how shall I index M1?
> 
Hi Diana,
To step through the matrices in your list (assuming that it only has one 
level):

for(mat in 1:length(D)) {
  <do what you want>
}

Jim


From Joao.Fadista at agrsci.dk  Thu Sep  6 12:02:14 2007
From: Joao.Fadista at agrsci.dk (=?iso-8859-1?Q?Jo=E3o_Fadista?=)
Date: Thu, 6 Sep 2007 12:02:14 +0200
Subject: [R] order intervals in a data.frame
Message-ID: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F76@DJFPOST01.djf.agrsci.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070906/9b8ccb90/attachment.pl 

From P.Dalgaard at biostat.ku.dk  Thu Sep  6 12:02:58 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 06 Sep 2007 12:02:58 +0200
Subject: [R] kendall test
In-Reply-To: <200709061026.15721.stefan.grosse@uni-erfurt.de>
References: <185980.27960.qm@web27513.mail.ukl.yahoo.com>
	<200709061026.15721.stefan.grosse@uni-erfurt.de>
Message-ID: <46DFD052.9010208@biostat.ku.dk>

Stefan Grosse wrote:
> On Thursday 06 September 2007 09:48:22 elyakhlifi mustapha wrote:
>
> em > I thougth that there is a function which does the kendall test in R,
> em > I writed on the console apropos("kendall") and I didn't found anything
> em >  can you tell me how could I do to use the kendall test? 
>
> ?cor.test
>
> btw.: rseek.org is a very good help for such questions
Interesting site! However, I don't see that leading to cor.test. Rather it points to the Kendall package which would seem to be a bit of an overkill. However, help.search("kendall") gets you there immediately.



-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ligges at statistik.uni-dortmund.de  Thu Sep  6 12:21:13 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 06 Sep 2007 12:21:13 +0200
Subject: [R] how to extract t-test statistics from glm()?
In-Reply-To: <000601c7ef03$d9d936a0$8d8ba3e0$@com>
References: <000601c7ef03$d9d936a0$8d8ba3e0$@com>
Message-ID: <46DFD499.2080605@statistik.uni-dortmund.de>



Bin Sun wrote:
> I need to extract t-test statistics from glm(). For example,
> 
>  
> 
> Coefficients:
> 
>             Estimate Std. Error t value Pr(>|t|)    
> 
> (Intercept)  46.2199    11.6310   3.974 0.000106 ***
> 
> Var1          1.0440     0.5948   1.755 0.081088 .  
> 
> Var2         -0.4717     2.0257  -0.233 0.816178    
> 
> Var3          0.2376     0.1454   1.635 0.104024    
> 
>  
> 
> And I want to put all the t-values (and if possible, only that is associated
> with one particular independent variable such as Var3) to another table that
> can be reused later. I'm new to R and your help is highly appreciated!
> 
>


  coefficients(summary(glm()))

Uwe Ligges



> 
> Eric
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From yn19832 at msn.com  Thu Sep  6 12:27:39 2007
From: yn19832 at msn.com (livia)
Date: Thu, 6 Sep 2007 03:27:39 -0700 (PDT)
Subject: [R] creat list
Message-ID: <12519637.post@talk.nabble.com>


Hi, 

I have a list named "lista", which has 50 vectors and each vector has the
length about 1200. I would like to creat a matrix out of "lista". What I try
now is cbind(lista[[1]],lista[[2]],...,lista[[50]]). I guess there would be
an easy way of doing this. Could anyone give me some advice?
-- 
View this message in context: http://www.nabble.com/creat-list-tf4391162.html#a12519637
Sent from the R help mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Thu Sep  6 12:32:55 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 6 Sep 2007 10:32:55 +0000 (UTC)
Subject: [R] geotiff or tiff files with world files
References: <BAY104-W15CDA70018A3932442C32BC3CB0@phx.gbl>
Message-ID: <loom.20070906T121737-779@post.gmane.org>

Monica Pisica <pisicandru <at> hotmail.com> writes:

> 
> 
> Hi,
> 
> I have a matrix of data which i can vizualize as an image - for example.
> I would like to save this image as a
> geotiff file or at a tiff file with a world file which holds the projection
> of my data (ultimately the data
> represent a map of some sort). I know i can save the data as an ESRI
> grid, but i am not interested in that.
> 
> I wonder if anybody knows about any code which will help me do that.

See the writeGDAL() function in the rgdal package, and hints on how to 
turn your matrix into a SpatialGridDataFrame object in the sp package. 
For example:

data(volcano)
str(volcano)
image(volcano)
grd <- GridTopology(c(0.5, 0.5), c(1, 1), c(87, 61))
SGDF <- SpatialGridDataFrame(grd, data=data.frame(volcano=c(volcano)))
image(SGDF, "volcano")

See the proj4string= argument to insert the projection in valid PROJ.4 
format. Then:

writeGDAL(SGDF, "volcano.tif", drivername = "GTiff", ...)

using the options= id needed, to pass through create options as on:

http://www.gdal.org/frmt_gtiff.html

For follow-ups, please consider the R-sig-geo list.

Roger

> 
> Thanks in advance,
> 
> Monica
> _________________________________________________________________
> 
> s. It's easy!
> 
> aspx&mkt=en-us
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help <at> stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
>


From phhs80 at gmail.com  Thu Sep  6 12:41:08 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Thu, 6 Sep 2007 11:41:08 +0100
Subject: [R] order intervals in a data.frame
In-Reply-To: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F76@DJFPOST01.djf.agrsci.dk>
References: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F76@DJFPOST01.djf.agrsci.dk>
Message-ID: <6ade6f6c0709060341y37d80632oe1722c4148faab5a@mail.gmail.com>

On 9/6/07, Jo?o Fadista <Joao.Fadista at agrsci.dk> wrote:
> I would like to know how can I order a data.frame with increasing the dat$Interval (dat$Interval is a factor). There is an example below.
>
> Original data.frame:
>
> > dat
>                  Interval               Number_reads
>                   0-100                         685
>                200-300                         744
>                100-200                        1082
>                300-400                        4213
>
>
> >Desired_dat:
>
>                  Interval               Number_reads
>                   0-100                          685
>                 100-200                       1082
>                 200-300                         744
>                 300-400                       4213

What about

Desired_dat <- dat[match(dat$Interval,sort(dat$Interval)),]

?

Paul


From ligges at statistik.uni-dortmund.de  Thu Sep  6 12:54:39 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 06 Sep 2007 12:54:39 +0200
Subject: [R] creat list
In-Reply-To: <12519637.post@talk.nabble.com>
References: <12519637.post@talk.nabble.com>
Message-ID: <46DFDC6F.5080805@statistik.uni-dortmund.de>



livia wrote:
> Hi, 
> 
> I have a list named "lista", which has 50 vectors and each vector has the
> length about 1200. I would like to creat a matrix out of "lista". What I try
> now is cbind(lista[[1]],lista[[2]],...,lista[[50]]). I guess there would be
> an easy way of doing this. Could anyone give me some advice?


matrix(unlist(lista), ncol=50)

Uwe Ligges


From ligges at statistik.uni-dortmund.de  Thu Sep  6 12:56:28 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 06 Sep 2007 12:56:28 +0200
Subject: [R] problem formatting and positioning title in heatmap
In-Reply-To: <46DE1EE4.6020207@iupui.edu>
References: <46DE1EE4.6020207@iupui.edu>
Message-ID: <46DFDCDC.5050303@statistik.uni-dortmund.de>



Mark W Kimpel wrote:
> I am using heatmap with the arguments below. The title size stays the 
> same no matter what I set cex.main to. Is this expected? Can I adjust 
> the title size in heatmap?
> 
> Also, the position of the main title is at the very upper edge of the 
> output and if I use a "\n" to stack the title the upper line is out of 
> bounds and doesn't show up.
> 
> I am outputting to pdf.
> 
> Any help? Thanks, Mark


Use par() to set that parameter of the device as in:

par(cex.main=1)
heatmap(.....)

Uwe Ligges


> heatmap(x = dataM, RowSideColors = RowSideColors, 
> ColSideColors=ColSideColors, main = title,
>            margins = c(50,50), scale= do.scale ,labRow=geneNames, 
> labCol=colLabels, col = hmcol, cex.main = 1,
>            cexRow = row.lab.mag, cexCol = col.lab.mag)
> 
>  > sessionInfo()
> R version 2.6.0 Under development (unstable) (2007-08-29 r42686)
> i686-pc-linux-gnu
> 
> locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] splines   tools     stats     graphics  grDevices utils     datasets
> [8] methods   base
> 
> other attached packages:
>   [1] RColorBrewer_1.0-1     MergeMaid_2.9.0        MASS_7.2-36
>   [4] rat2302_1.17.0         rat2302cdf_1.17.0      affycoretools_1.9.4
>   [7] annaffy_1.9.1          KEGG_1.17.1            GO_1.99.1
> [10] xtable_1.5-1           gcrma_2.9.1            matchprobes_1.9.10
> [13] biomaRt_1.11.4         RCurl_0.8-3            XML_1.92-1
> [16] GOstats_2.3.16         Category_2.3.30        genefilter_1.15.11
> [19] survival_2.32          RBGL_1.13.6            annotate_1.15.6
> [22] GO.db_1.99.1           AnnotationDbi_0.1.12   RSQLite_0.6-0
> [25] DBI_0.2-3              limma_2.11.11          affy_1.15.7
> [28] preprocessCore_0.99.12 affyio_1.5.8           Biobase_1.15.30
> [31] graph_1.15.14
> 
> loaded via a namespace (and not attached):
> [1] cluster_1.11.7
>


From nibkan at yahoo.com  Thu Sep  6 13:38:32 2007
From: nibkan at yahoo.com (betul kan)
Date: Thu, 6 Sep 2007 04:38:32 -0700 (PDT)
Subject: [R] smooth functions
Message-ID: <343054.49806.qm@web62111.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070906/2c63305f/attachment.pl 

From yn19832 at msn.com  Thu Sep  6 13:40:35 2007
From: yn19832 at msn.com (livia)
Date: Thu, 6 Sep 2007 04:40:35 -0700 (PDT)
Subject: [R] creat list
In-Reply-To: <46DFDC6F.5080805@statistik.uni-dortmund.de>
References: <12519637.post@talk.nabble.com>
	<46DFDC6F.5080805@statistik.uni-dortmund.de>
Message-ID: <12520728.post@talk.nabble.com>


Many thanks.


Uwe Ligges wrote:
> 
> 
> 
> livia wrote:
>> Hi, 
>> 
>> I have a list named "lista", which has 50 vectors and each vector has the
>> length about 1200. I would like to creat a matrix out of "lista". What I
>> try
>> now is cbind(lista[[1]],lista[[2]],...,lista[[50]]). I guess there would
>> be
>> an easy way of doing this. Could anyone give me some advice?
> 
> 
> matrix(unlist(lista), ncol=50)
> 
> Uwe Ligges
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/creat-list-tf4391162.html#a12520728
Sent from the R help mailing list archive at Nabble.com.


From P.Dalgaard at biostat.ku.dk  Thu Sep  6 13:49:42 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 06 Sep 2007 13:49:42 +0200
Subject: [R] order intervals in a data.frame
In-Reply-To: <6ade6f6c0709060341y37d80632oe1722c4148faab5a@mail.gmail.com>
References: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F76@DJFPOST01.djf.agrsci.dk>
	<6ade6f6c0709060341y37d80632oe1722c4148faab5a@mail.gmail.com>
Message-ID: <46DFE956.5090601@biostat.ku.dk>

Paul Smith wrote:
> On 9/6/07, Jo?o Fadista <Joao.Fadista at agrsci.dk> wrote:
>   
>> I would like to know how can I order a data.frame with increasing the dat$Interval (dat$Interval is a factor). There is an example below.
>>
>> Original data.frame:
>>
>>     
>>> dat
>>>       
>>                  Interval               Number_reads
>>                   0-100                         685
>>                200-300                         744
>>                100-200                        1082
>>                300-400                        4213
>>
>>
>>     
>>> Desired_dat:
>>>       
>>                  Interval               Number_reads
>>                   0-100                          685
>>                 100-200                       1082
>>                 200-300                         744
>>                 300-400                       4213
>>     
>
> What about
>
> Desired_dat <- dat[match(dat$Interval,sort(dat$Interval)),]
>   
dat[order(dat$Interval),]

would be more to the point, but it is a bit fortuitous that it works at
all (split the first group at 50 and you'll see).

This (or at least something like it) should sort according to left
endpoints:

o <- order(as.numeric(sub("-.*", "", dat$Interval)))
dat[o,]

> ?
>
> Paul
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Ingo.Holz at uni-hohenheim.de  Thu Sep  6 13:51:46 2007
From: Ingo.Holz at uni-hohenheim.de (Ingo Holz)
Date: Thu, 06 Sep 2007 13:51:46 +0200
Subject: [R] read.table
Message-ID: <46E005F2.3899.14E2F73@ingoholz.uni-hohenheim.de>

Hi,

 I want to read a ascii-file using the function read.table.
 With 'skip' and 'nrows' I can select the rows to read from this file.

 Is there a way to select columns (in the selected rows)?

Thanks,

Ingo


From P.Dalgaard at biostat.ku.dk  Thu Sep  6 13:58:41 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 06 Sep 2007 13:58:41 +0200
Subject: [R] read.table
In-Reply-To: <46E005F2.3899.14E2F73@ingoholz.uni-hohenheim.de>
References: <46E005F2.3899.14E2F73@ingoholz.uni-hohenheim.de>
Message-ID: <46DFEB71.1030501@biostat.ku.dk>

Ingo Holz wrote:
> Hi,
>
>  I want to read a ascii-file using the function read.table.
>  With 'skip' and 'nrows' I can select the rows to read from this file.
>
>  Is there a way to select columns (in the selected rows)?
>   
Yes, use the colClasses argument.
(I won't rewrite the help page here; I expect that you can read it once
you know where to look.)

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From jrkrideau at yahoo.ca  Thu Sep  6 14:19:39 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 6 Sep 2007 08:19:39 -0400 (EDT)
Subject: [R] kendall test
In-Reply-To: <185980.27960.qm@web27513.mail.ukl.yahoo.com>
Message-ID: <683609.71279.qm@web32812.mail.mud.yahoo.com>

?cor perhaps
--- elyakhlifi mustapha <elyakhlifi_mustapha at yahoo.fr>
wrote:

> Hello,
> I thougth that there is a function which does the
> kendall test in R,
> I writed on the console apropos("kendall") and I
> didn't found anything can you tell me how could I do
> to use the kendall test?
> Thanks.
> 
> 
>      
>
_____________________________________________________________________________
> 
> 
> l 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From tobias.verbeke at gmail.com  Thu Sep  6 14:30:29 2007
From: tobias.verbeke at gmail.com (Tobias Verbeke)
Date: Thu, 06 Sep 2007 14:30:29 +0200
Subject: [R] the survey package
In-Reply-To: <300041.24688.qm@web38611.mail.mud.yahoo.com>
References: <300041.24688.qm@web38611.mail.mud.yahoo.com>
Message-ID: <46DFF2E5.8060008@telenet.be>

eugen pircalabelu wrote:

>   I'm trying to use the survey package to get a better point of view for my data, but i need some piece of advice:
>    
>   i have some data from a survey which has been stratified using 2 criteria: region(7 values), size of locality(5 values)  Using the survey pakage how can i define in a correct way this design (taking into account all 4 strata not just one as in the Survey example) 
>    
>   i have tried 
>    
>   design<- svydesign(ids=~0, strata= c(~regiune,~size_loc), data=tabel) # for 2 criteria
>    
>   and got this error
>    
>   Error in strata[, 1] : incorrect number of dimensions
>   My "tabel" looks like this:

According to ?svydesign, strata is a formula.

The following should work (untested):

design <- svydesign(ids=~0, strata=~regiune + size_loc, data=tabel)

HTH,
Tobias

P.S. See http://faculty.washington.edu/tlumley/survey/
for all information relating to this package.

-- 

Tobias Verbeke - Consultant
Business & Decision Benelux
Rue de la r?volution 8
1000 Brussels - BELGIUM

+32 499 36 33 15
tobias.verbeke at businessdecision.com


From eugen_pircalabelu at yahoo.com  Thu Sep  6 14:36:09 2007
From: eugen_pircalabelu at yahoo.com (eugen pircalabelu)
Date: Thu, 6 Sep 2007 05:36:09 -0700 (PDT)
Subject: [R] Survey package
Message-ID: <99137.80849.qm@web38605.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070906/3b31f2f2/attachment.pl 

From D.GOUACHE at arvalisinstitutduvegetal.fr  Thu Sep  6 14:49:46 2007
From: D.GOUACHE at arvalisinstitutduvegetal.fr (GOUACHE David)
Date: Thu, 6 Sep 2007 14:49:46 +0200
Subject: [R] labelling specific points xyplot
Message-ID: <1DF7DB4AB44EFB41A60A889186D43359120C8B@srv-laminiere.arvalis-fr.com>

Hello R-helpers,

I'm trying to add labels to points in xyplot graphs, but I want lo label only those points which have a certain level of my grouping variable, and have encountered a few problems.
An example dataframe that goes with the following code is at the end of this message.

1st step, adding labels (from another column in the dataframe) to my chosen points  :
I've figures this out, but I am passing my whole dataframe as an extra argument (arg1) which I realize is probably useless, so if anybody can give me a way to work around this...

xyplot(pp~nn,groups=vari,data=test,auto.key=list(space="right"),arg1=test,arg2="2",arg3="loc",
		panel=function(x,y,groups,arg1,arg2,arg3,...)
		{
			panel.superpose(x,y,groups,...)
			?tiq<-rep("",times=length(x))
			?tiq[groups==arg2]<-as.character(arg1[groups==arg2,arg3])
			?tiq<-as.character(?tiq)
			panel.text(x,y,labels=?tiq,pos=1,cex=0.5,...)
		}
		)

What I would also like is to write a function that is robust for multiple panel displays or subsetting :

#### obviously, the following example doesn't work :

xyplot(pp~nn,groups=vari,data=test,auto.key=list(space="right"),arg1=test,arg2="2",arg3="loc",
		panel=function(x,y,groups,arg1,arg2,arg3,...)
		{
			panel.superpose(x,y,groups,...)
			?tiq<-rep("",times=length(x))
			?tiq[groups==arg2]<-as.character(arg1[groups==arg2,arg3])
			?tiq<-as.character(?tiq)
			panel.text(x,y,labels=?tiq,pos=1,cex=0.5,...)
		},
		subset=pp>38
		)

so I figured passing on the subscripts argument to my panel function would be the way to go, but I've come across some behavior I can't make sense of :

xyplot(pp~nn,groups=vari,data=test,auto.key=list(space="right"),arg1=test,arg2="2",arg3="loc",
		panel=function(x,y,groups,subscripts,arg1,arg2,arg3,...)
		{
			panel.superpose(x,y,groups,...)
			#?tiq<-rep("",times=length(x))
			#?tiq[groups[subscripts]==arg2]<-as.character(arg1[subscripts,arg3][groups[subscripts]==arg2])
			#?tiq<-as.character(?tiq)
			#panel.text(x,y,labels=?tiq,pos=1,cex=0.5,...)
		},
		subset=pp>38
		)

returns :
Erreur dans inherits(x, "factor") : l'argument "groups" est manquant, avec aucune valeur par d?faut

trying it this way I get a graph, but the groups have gone haywire, and I can't figure out why

xyplot(pp~nn,groups=vari,data=test,auto.key=list(space="right"),arg1=test,arg2="2",arg3="loc",
		panel=function(x,y,groups,subscripts,arg1,arg2,arg3,...)
		{
			panel.superpose(x,y,groups,subscripts,...)
			#?tiq<-rep("",times=length(x))
			#?tiq[groups[subscripts]==arg2]<-as.character(arg1[subscripts,arg3][groups[subscripts]==arg2])
			#?tiq<-as.character(?tiq)
			#panel.text(x,y,labels=?tiq,pos=1,cex=0.5,...)
		},
		subset=pp>38
		)

finally, I ran the same call taking the '#' out :

xyplot(pp~nn,groups=vari,data=test,auto.key=list(space="right"),arg1=test,arg2="2",arg3="loc",
		panel=function(x,y,groups,subscripts,arg1,arg2,arg3,...)
		{
			panel.superpose(x,y,groups,subscripts,...)
			?tiq<-rep("",times=length(x))
			?tiq[groups[subscripts]==arg2]<-as.character(arg1[subscripts,arg3][groups[subscripts]==arg2])
			?tiq<-as.character(?tiq)
			panel.text(x,y,labels=?tiq,pos=1,cex=0.5,...)
		},
		subset=pp>38
		)

which returns :

Erreur dans ?tiq[groups[subscripts] == arg2] <- as.character(arg1[subscripts,  : 
        NAs interdits dans les affectations indic?es

I've racked my head and can't make out what's wrong with this line :

?tiq[groups[subscripts]==arg2]<-as.character(arg1[subscripts,arg3][groups[subscripts]==arg2])


That's a lot of questions in one, so thanks to anyone who can help me out, even for just one of them !!

################## dataframe follows :

vari<-c("3","3","3","3","3","2","3","3","3","3","3","3","1","3","2","2","1","1",
"1","1","1","2","3","1","3","3","3","3","3","3","3","3","2","1","3","1",
"1","2","2","1","3","3","3","2","1","3","1","2","3","2","1","3","3","3",
"1","1","2","1","1","2","1","3","1","2","1","1","1","2","1","1","3","2",
"3","3","2","1","1","1","2","3","2","2","2","2","2","2","3","3","3","3",
"1","1","1","1","2","1","3","2","3","2")

pp<-c(NA,49.440,42.900,44.020,48.892,NA,NA,48.800,49.710,49.200,
46.100,44.075,NA,47.855,42.800,NA,32.696,35.900,NA,NA,
43.249,NA,NA,NA,49.405,49.900,47.200,52.600,51.300,51.200,
NA,54.200,NA,NA,NA,48.378,44.080,48.000,47.400,NA,
51.013,54.900,53.725,48.605,44.033,NA,43.200,49.000,NA,45.800,
NA,49.800,50.200,52.900,NA,41.400,47.899,40.000,NA,NA,
NA,53.100,NA,39.400,40.700,NA,NA,48.703,NA,NA,
39.424,41.300,45.800,49.760,44.820,NA,NA,NA,NA,47.700,
43.600,43.700,45.800,NA,45.490,NA,53.200,38.300,45.500,NA,
35.900,37.104,34.296,44.000,47.000,43.499,49.804,41.126,48.900,49.000)

nn<-c(NA,18343.82,17582.40,20310.26,18482.91,NA,NA,21677.50,
21219.01,24817.07,20954.45,24261.90,NA,20258.84,24649.53,NA,
30644.43,30222.84,NA,NA,22909.93,NA,NA,NA,
18120.95,19779.56,22563.56,17699.62,26110.50,13691.41,NA,NA,
NA,NA,NA,25032.54,21234.12,20541.67,20105.49,NA,
17902.62,21985.43,22203.39,19880.48,23485.20,NA,NA,NA,
NA,23908.30,NA,19116.47,19322.71,NA,NA,20531.40,
22734.24,NA,NA,NA,NA,15106.30,NA,23477.16,
17420.15,NA,NA,16507.59,NA,NA,18529.41,24382.57,
20802.68,16942.67,NA,NA,NA,NA,NA,22851.15,
23807.34,NA,NA,NA,NA,NA,14624.06,17780.68,
18615.38,NA,NA,19136.01,22394.33,NA,21468.08,20392.55,
20580.23,25215.19,21650.59,26428.57)


loc<-c("3501","7699","6903","6903","6903","269","1083","6903","198","198",
"198","198","5503","198","269","7601","3002","3002","6001","249",
"6701","201","201","1002","4198","4198","4198","4198","4198","4198",
"2863","2863","6082","6254","201","6801","5101","851","851","1001",
"1400","1401","1401","1401","6082","6101","6082","278","5398","5398",
"8000","6903","6903","4102","5503","5503","2720","7761","7761","201",
"1412","2801","5472","5202","5599","5472","1057","2720","1057","1057",
"3601","3601","3601","3601","201","5503","1401","5472","6092","4199",
"5175","5175","265","8056","8000","265","8901","8901","8901","6092",
"8999","8999","8999","1002","1002","2490","2490","2700","2700","2720")

test<-data.frame(vari=vari,pp=pp,nn=nn,loc=loc)

David Gouache
Arvalis - Institut du V?g?tal
Station de La Mini?re
78280 Guyancourt
Tel: 01.30.12.96.22 / Port: 06.86.08.94.32


From servien.remi12 at yahoo.fr  Thu Sep  6 15:45:37 2007
From: servien.remi12 at yahoo.fr (excalibur)
Date: Thu, 6 Sep 2007 06:45:37 -0700 (PDT)
Subject: [R] Monotonic interpolation
Message-ID: <12522970.post@talk.nabble.com>


Hello everybody, has anyone got a function for smooth monotonic interpolation
(splines ...) of a univariate function (like a distribution function for
example) ? 

Thanks everybody.
-- 
View this message in context: http://www.nabble.com/Monotonic-interpolation-tf4392288.html#a12522970
Sent from the R help mailing list archive at Nabble.com.


From xingwang.ye at gmail.com  Thu Sep  6 15:48:44 2007
From: xingwang.ye at gmail.com (Xingwang Ye)
Date: Thu, 06 Sep 2007 21:48:44 +0800
Subject: [R] Warning message with aggregate function
In-Reply-To: <46DFBEE2.6040803@statistik.uni-dortmund.de>
References: <46DFB220.3050403@gmail.com>
	<46DFBEE2.6040803@statistik.uni-dortmund.de>
Message-ID: <46E0053C.4090103@gmail.com>

Thank you for sharing your experience.
The example data I used is from help for "by" function, so every one 
could have a try.

After using $, the warning message disappeared:
aggregate(warbreaks[,1], list(wool = warbreaks$wool, 
tension=warbreaks$tension),sum)

Another approach may be to restart your R.

Xingwang Ye

Uwe Ligges wrote:
>
>
> Xingwang Ye wrote:
>> Dear all,
>> When I use aggregate function as:
>>
>> attach(warpbreaks)
>> aggregate(warpbreaks[, 1], list(wool = wool, tension = tension), sum)
>>
>> The results are right but I get a warning message:
>> "number of items to replace is not a multiple of replacement length."
>>
>> BTW: I use R version 2.4.1 in Ubuntu 7.04.
>
>
> Does not happen for me, neither with R-2.4.1 nor with recent versions 
> of R. Maybe you have redefined one of the used objects (aggregate, 
> warpbreaks, wool, tension, sum) in one of your environments?
>
> BTW: Is is always a bad idea to make much use of attach()...
>
> Uwe Ligges
>
>
>> Your kind solutions will be great appreciated.
>>
>> Best wishes
>>
>> Yours, sincerely,
>> Xingwang Ye
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Thu Sep  6 16:19:31 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 6 Sep 2007 10:19:31 -0400
Subject: [R] creat list
In-Reply-To: <12519637.post@talk.nabble.com>
References: <12519637.post@talk.nabble.com>
Message-ID: <971536df0709060719w789711c7y11626744f1c9dd77@mail.gmail.com>

Try this:

do.call("cbind", lista)

On 9/6/07, livia <yn19832 at msn.com> wrote:
>
> Hi,
>
> I have a list named "lista", which has 50 vectors and each vector has the
> length about 1200. I would like to creat a matrix out of "lista". What I try
> now is cbind(lista[[1]],lista[[2]],...,lista[[50]]). I guess there would be
> an easy way of doing this. Could anyone give me some advice?
> --
> View this message in context: http://www.nabble.com/creat-list-tf4391162.html#a12519637
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From vincent.goulet at act.ulaval.ca  Thu Sep  6 16:46:52 2007
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Thu, 6 Sep 2007 10:46:52 -0400
Subject: [R] Monotonic interpolation
In-Reply-To: <12522970.post@talk.nabble.com>
References: <12522970.post@talk.nabble.com>
Message-ID: <E7BA928E-00C4-46C0-BA7A-D2344A7AA124@act.ulaval.ca>

Le jeu. 6 sept. ? 09:45, excalibur a ?crit :

>
> Hello everybody, has anyone got a function for smooth monotonic  
> interpolation
> (splines ...) of a univariate function (like a distribution  
> function for
> example) ?

approxfun() might be what your looking for.


From servien.remi12 at yahoo.fr  Thu Sep  6 17:03:31 2007
From: servien.remi12 at yahoo.fr (excalibur)
Date: Thu, 6 Sep 2007 08:03:31 -0700 (PDT)
Subject: [R] Monotonic interpolation
In-Reply-To: <E7BA928E-00C4-46C0-BA7A-D2344A7AA124@act.ulaval.ca>
References: <12522970.post@talk.nabble.com>
	<E7BA928E-00C4-46C0-BA7A-D2344A7AA124@act.ulaval.ca>
Message-ID: <12524568.post@talk.nabble.com>




Le jeu. 6 sept. ? 09:45, excalibur a ?crit :

>
> Hello everybody, has anyone got a function for smooth monotonic  
> interpolation
> (splines ...) of a univariate function (like a distribution  
> function for
> example) ?

approxfun() might be what your looking for.

Is the result of approxfun() inevitably monotonic ?
-- 
View this message in context: http://www.nabble.com/Monotonic-interpolation-tf4392288.html#a12524568
Sent from the R help mailing list archive at Nabble.com.


From gunter.berton at gene.com  Thu Sep  6 17:27:26 2007
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 6 Sep 2007 08:27:26 -0700
Subject: [R] Monotonic interpolation
In-Reply-To: <12524568.post@talk.nabble.com>
References: <12522970.post@talk.nabble.com><E7BA928E-00C4-46C0-BA7A-D2344A7AA124@act.ulaval.ca>
	<12524568.post@talk.nabble.com>
Message-ID: <003c01c7f09a$6e23fab0$3a0b2c0a@gne.windows.gene.com>

RSiteSearch("monotone", restr="func") will give you several packages and
functions for monotone smoothing, including the isoreg() function in the
standard stats package.  You can determine if any of these does what you
want.


Bert Gunter
Genetech Nonclinical Statistics


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of excalibur
Sent: Thursday, September 06, 2007 8:04 AM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] Monotonic interpolation




Le jeu. 6 sept. ? 09:45, excalibur a ?crit :

>
> Hello everybody, has anyone got a function for smooth monotonic  
> interpolation
> (splines ...) of a univariate function (like a distribution  
> function for
> example) ?

approxfun() might be what your looking for.

Is the result of approxfun() inevitably monotonic ?
-- 
View this message in context:
http://www.nabble.com/Monotonic-interpolation-tf4392288.html#a12524568
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rkoenker at uiuc.edu  Thu Sep  6 17:35:54 2007
From: rkoenker at uiuc.edu (roger koenker)
Date: Thu, 6 Sep 2007 10:35:54 -0500
Subject: [R] Monotonic interpolation
In-Reply-To: <12524568.post@talk.nabble.com>
References: <12522970.post@talk.nabble.com>
	<E7BA928E-00C4-46C0-BA7A-D2344A7AA124@act.ulaval.ca>
	<12524568.post@talk.nabble.com>
Message-ID: <49A8CB1B-50F8-44F6-9BCB-4BB556E4750B@uiuc.edu>

You might look at the monotone fitting available in the rqss()
function of the quantreg package.

url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Champaign, IL 61820


On Sep 6, 2007, at 10:03 AM, excalibur wrote:

>
>
>
> Le jeu. 6 sept. ? 09:45, excalibur a ?crit :
>
>>
>> Hello everybody, has anyone got a function for smooth monotonic
>> interpolation
>> (splines ...) of a univariate function (like a distribution
>> function for
>> example) ?
>
> approxfun() might be what your looking for.
>
> Is the result of approxfun() inevitably monotonic ?
> --  
> View this message in context: http://www.nabble.com/Monotonic- 
> interpolation-tf4392288.html#a12524568
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From andy_liaw at merck.com  Thu Sep  6 17:35:18 2007
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 6 Sep 2007 11:35:18 -0400
Subject: [R] Monotonic interpolation
In-Reply-To: <003c01c7f09a$6e23fab0$3a0b2c0a@gne.windows.gene.com>
References: <12522970.post@talk.nabble.com><E7BA928E-00C4-46C0-BA7A-D2344A7AA124@act.ulaval.ca>
	<12524568.post@talk.nabble.com>
	<003c01c7f09a$6e23fab0$3a0b2c0a@gne.windows.gene.com>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04A4AE85@usctmx1106.merck.com>

Not if Mr. excalibur really want interpolating (as oppose to 
smooting) splines.  Other than linear, I'm not even sure if 
it can be done (though I'm no expert on this).

One possibility is to use the cobs package and play with
the amount of smoothing...

Andy

From: Bert Gunter
> 
> RSiteSearch("monotone", restr="func") will give you several 
> packages and
> functions for monotone smoothing, including the isoreg() 
> function in the
> standard stats package.  You can determine if any of these 
> does what you
> want.
> 
> 
> Bert Gunter
> Genetech Nonclinical Statistics
> 
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of excalibur
> Sent: Thursday, September 06, 2007 8:04 AM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] Monotonic interpolation
> 
> 
> 
> 
> Le jeu. 6 sept. ? 09:45, excalibur a ?crit :
> 
> >
> > Hello everybody, has anyone got a function for smooth monotonic  
> > interpolation
> > (splines ...) of a univariate function (like a distribution  
> > function for
> > example) ?
> 
> approxfun() might be what your looking for.
> 
> Is the result of approxfun() inevitably monotonic ?
> -- 
> View this message in context:
> http://www.nabble.com/Monotonic-interpolation-tf4392288.html#a12524568
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}


From andy_liaw at merck.com  Thu Sep  6 17:46:04 2007
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 6 Sep 2007 11:46:04 -0400
Subject: [R] Recursive concatenation
In-Reply-To: <20070904210409.69mi98w21mlco008@webmail3.kuleuven.be>
References: <54257198-168A-478D-9DEE-B525D988A3D4@plessthan.com>
	<20070904210409.69mi98w21mlco008@webmail3.kuleuven.be>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04A4AEA1@usctmx1106.merck.com>

Or something like:

R> do.call(paste, c(expand.grid(LETTERS[1:3], 1:3), sep=""))
[1] "A1" "B1" "C1" "A2" "B2" "C2" "A3" "B3" "C3"

(The ordering is bit different, but that shouldn't matter.)

Andy 

From: Dimitris Rizopoulos
> try this:
> 
> paste(rep(LETTERS[1:3], each = 3), 1:3, sep = "")
> 
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/(0)16/336899
> Fax: +32/(0)16/337015
> Web: http://med.kuleuven.be/biostat/
>       http://www.student.kuleuven.be/~m0390867/dimitris.htm
> 
> 
> Quoting Dennis Fisher <fisher at plessthan.com>:
> 
> > Colleagues,
> >
> > I want to create the following array:
> > 	"A1", "A2", "A3", "B1", "B2", "B3", "C1", "C2", "C3"
> >
> > I recall that there is a trick using "c" or "paste" permitting me to
> > form all combinations of c("A", "B", "C") and 1:3.  But, I can't
> > recall the trick.
> >
> > Dennis
> >
> >
> > Dennis Fisher MD
> > P < (The "P Less Than" Company)
> > Phone: 1-866-PLessThan (1-866-753-7784)
> > Fax: 1-415-564-2220
> > www.PLessThan.com
> >
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> 
> 
> 
> Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}


From marc_schwartz at comcast.net  Thu Sep  6 17:55:17 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 06 Sep 2007 10:55:17 -0500
Subject: [R] Recursive concatenation
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04A4AEA1@usctmx1106.merck.com>
References: <54257198-168A-478D-9DEE-B525D988A3D4@plessthan.com>
	<20070904210409.69mi98w21mlco008@webmail3.kuleuven.be>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA04A4AEA1@usctmx1106.merck.com>
Message-ID: <1189094117.19396.48.camel@Bellerophon.localdomain>

Or:

> sort(levels(interaction(LETTERS[1:3], 1:3, sep = "")))
[1] "A1" "A2" "A3" "B1" "B2" "B3" "C1" "C2" "C3"


Marc

On Thu, 2007-09-06 at 11:46 -0400, Liaw, Andy wrote:
> Or something like:
> 
> R> do.call(paste, c(expand.grid(LETTERS[1:3], 1:3), sep=""))
> [1] "A1" "B1" "C1" "A2" "B2" "C2" "A3" "B3" "C3"
> 
> (The ordering is bit different, but that shouldn't matter.)
> 
> Andy 
> 
> From: Dimitris Rizopoulos
> > try this:
> > 
> > paste(rep(LETTERS[1:3], each = 3), 1:3, sep = "")
> > 
> > 
> > Best,
> > Dimitris
> > 
> > 
> > Quoting Dennis Fisher <fisher at plessthan.com>:
> > 
> > > Colleagues,
> > >
> > > I want to create the following array:
> > > 	"A1", "A2", "A3", "B1", "B2", "B3", "C1", "C2", "C3"
> > >
> > > I recall that there is a trick using "c" or "paste" permitting me to
> > > form all combinations of c("A", "B", "C") and 1:3.  But, I can't
> > > recall the trick.
> > >
> > > Dennis
> > >


From andy_liaw at merck.com  Thu Sep  6 18:10:32 2007
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 6 Sep 2007 12:10:32 -0400
Subject: [R] Synchronzing workspaces
In-Reply-To: <971536df0709022131s33ad79f7m43a642fb83822b7@mail.gmail.com>
References: <609287.49026.qm@web58403.mail.re3.yahoo.com>
	<971536df0709022131s33ad79f7m43a642fb83822b7@mail.gmail.com>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04A4AEE2@usctmx1106.merck.com>

See the example in ?save on how to set defaults via options().

Andy

From: Gabor Grothendieck
 
> You could try saving prior to quitting in the future if you 
> want to try
> those arguments.
> 
> On 9/3/07, Paul August <paulaugust2003 at yahoo.com> wrote:
> > Thanks for sharing your experience. In my case, the 
> involved machines are Windows Vista, XP and 2000. Not sure 
> whether it contributes to my problem or not. I will look into 
> this further.
> >
> > I just noticed the two arguments ascii and compress for 
> save. However, my .RData file was created by q() with "yes". 
> The manual says that q() is equivalent to save(list = 
> ls(all=TRUE), file = ".RData"). There seems to be no way to 
> set ascii or compression of save through q function, unless 
> the q function is replaced explicitly with save(list = 
> ls(all=TRUE), file = ".RData", ascii = T).
> >
> > Paul.
> >
> >
> > ----- Original Message ----
> > From: Gabor Grothendieck <ggrothendieck at gmail.com>
> > To: Paul August <paulaugust2003 at yahoo.com>
> > Cc: r-help at stat.math.ethz.ch
> > Sent: Thursday, August 30, 2007 11:24:31 PM
> > Subject: Re: [R] Synchronzing workspaces
> >
> > I haven't had similar experience but note that save has ascii=
> > and compress= arguments.  You could check if varying those
> > parameter values makes a difference.
> >
> > On 8/30/07, Paul August <paulaugust2003 at yahoo.com> wrote:
> > > I used to work on several computers and to use a flash 
> drive to synchronize the workspace on each machine before 
> starting to work on it. I found that .RData always caused 
> some trouble: Often it is corrupted even though there is no 
> error in copying process. Does anybody have the similar experience?
> > >
> > > Paul.
> > >
> > > ----- Original Message ----
> > > From: Barry Rowlingson <b.rowlingson at lancaster.ac.uk>
> > > To: Eric Turkheimer <ent3c at virginia.edu>
> > > Cc: r-help at stat.math.ethz.ch
> > > Sent: Wednesday, August 22, 2007 9:43:57 AM
> > > Subject: Re: [R] Synchronzing workspaces
> > >
> > > Eric Turkheimer wrote:
> > > > How do people go about synchronizing multiple 
> workspaces on different
> > > > workstations?  I tend to wind up with projects spread 
> around the various
> > > > machines I work on.  I find that placing the 
> directories on a server and
> > > > reading them remotely tends to slow things down.
> > >
> > >  If R were to store all its workspace data objects in 
> individual files
> > > instead of one big .RData file, then you could use a 
> revision control
> > > system like SVN.  Check out the data, work on it, check 
> it in, then on
> > > another machine just update to get the changes.
> > >
> > >  However SVN doesn't work too well for binary files - 
> conflicts being
> > > hard to resolve without someone backing down - so maybe 
> its not such a
> > > good idea anyway...
> > >
> > >  On unix boxes and derivatives, you can keep things in 
> sync efficiently
> > > with the 'rsync' command.  I think there are GUI addons 
> for it, and
> > > Windows ports.
> > >
> > > Barry
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > >
> > >
> > >
> > > 
> ______________________________________________________________
> ______________________
> > >
> > > Comedy with an Edge to see what's on, when.
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}


From spe2 at cornell.edu  Thu Sep  6 18:41:59 2007
From: spe2 at cornell.edu (Stephen Ellner)
Date: Thu, 06 Sep 2007 12:41:59 -0400
Subject: [R] Monotone splines
In-Reply-To: <mailman.13.1189072804.25410.r-help@stat.math.ethz.ch>
References: <mailman.13.1189072804.25410.r-help@stat.math.ethz.ch>
Message-ID: <6.2.3.4.2.20070906122542.02934968@postoffice6.mail.cornell.edu>

Servien remi (servien.remi12 at yahoo.fr) wrote: 
>I want to use splines to estimate a function but i want to force the interpolation to be monotone. Is this possible with R ?

There are a few options. You can use mono.con in mgcv (see the example code in ?pcls), or smooth.monotone in fda. In both of these you have to specify the smoothing parameter yourself. I've written (with some help from Simon Wood) a set of scripts that fit a monontone nondecreasing regression spline with smoothing parameter chosen by GCV taking account of the active constraints, the approach developed by 

Wood, S.N. (1994) Monotonic smoothing splines fitted by cross validation. SIAM Journal on Scientific Computing 15:1126-1133.  

You can get them at  www.eeb.cornell.edu/ellner/software.html; scroll down and look for "Gradfit". 
The function you need is gcv.rssM. It isn't very efficient, so you may have trouble if your data set is large. 

Stephen P. Ellner (spe2 at cornell.edu)
Department of Ecology and Evolutionary Biology
Corson Hall, Cornell University, Ithaca NY 14853-2701


From J.delasHeras at ed.ac.uk  Thu Sep  6 18:49:41 2007
From: J.delasHeras at ed.ac.uk (J.delasHeras at ed.ac.uk)
Date: Thu, 06 Sep 2007 17:49:41 +0100
Subject: [R] Excel
In-Reply-To: <183572.10201.qm@web32211.mail.mud.yahoo.com>
References: <183572.10201.qm@web32211.mail.mud.yahoo.com>
Message-ID: <20070906174941.k6162yzxlww4wk0c@www.staffmail.ed.ac.uk>


Similar story with gene names.
I have a few genes such as SEP7, SEP10... if the file is touched by  
Excel, they're gone!
I can avoid using Excel, but I can't be sure that when I receive a  
file from somebody else it will not contain that sort of errors.
The first thing I do when I get a new Office version is disable all  
teh automatic BS that it tries to do to "help" you. Incredibly, the  
behaviour with dates in Excel cannot be disabled!

Jose

Quoting Moshe Olshansky <m_olshansky at yahoo.com>:

> This is very consistent with Microsoft's philosophy:
> they know better than you what you want to do.
>
> --- David Scott <d.scott at auckland.ac.nz> wrote:
>
>>
>> A common process when data is obtained in an Excel
>> spreadsheet is to save
>> the spreadsheet as a .csv file then read it into R.
>> Experienced users
>> might have learned to be wary of dates (as I have)
>> but possibly have not
>> experienced what just happened to me. I thought I
>> might just share it with
>> r-help as a cautionary tale.
>>
>> I received an Excel file giving patient details.
>> Each patient had an ID
>> code in the form of three letters followed by four
>> digits. (Actually a New
>> Zealand National Health Identification.) I saved the
>> .xls file as .csv.
>> Then I opened up the .csv (with Excel) to look at
>> it. In the column of ID
>> codes I saw: Aug-99. Clicking on that entry it
>> showed 1/08/2699.
>>
>> In a column of character data, Excel had interpreted
>> AUG2699 as a date.
>>
>> The .csv did not actually have a date in that cell,
>> but if I had saved the
>> .csv file it would have.
>>
>> David Scott
>>
>>
> _________________________________________________________________
>> David Scott	Department of Statistics, Tamaki Campus
>>  		The University of Auckland, PB 92019
>>  		Auckland 1142,    NEW ZEALAND
>> Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
>> Email:	d.scott at auckland.ac.nz
>>
>> Graduate Officer, Department of Statistics
>> Director of Consulting, Department of Statistics
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained,
>> reproducible code.
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Dr. Jose I. de las Heras                      Email: J.delasHeras at ed.ac.uk
The Wellcome Trust Centre for Cell Biology    Phone: +44 (0)131 6513374
Institute for Cell & Molecular Biology        Fax:   +44 (0)131 6507360
Swann Building, Mayfield Road
University of Edinburgh
Edinburgh EH9 3JR
UK

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From J.delasHeras at ed.ac.uk  Thu Sep  6 18:55:38 2007
From: J.delasHeras at ed.ac.uk (J.delasHeras at ed.ac.uk)
Date: Thu, 06 Sep 2007 17:55:38 +0100
Subject: [R] Excel
In-Reply-To: <0JNG004QHW2G2AX4@vms042.mailsrvcs.net>
References: <0JNG004QHW2G2AX4@vms042.mailsrvcs.net>
Message-ID: <20070906175538.6yt2z3nqosc8ws8o@www.staffmail.ed.ac.uk>

Quoting Robert A LaBudde <ral at lcfltd.com>:

> If you format the column as "Text", you won't have this problem. By
> leaving the cells as "General", you leave it up to Excel to guess at
> the correct interpretation.
>
> You will note that the conversion to a date occurs immediately in
> Excel when you enter the value. There are many formats to enter dates.
>
> Either pre-format the column as Text, or prefix the individual entry
> with an ' to indicate text.

But the conversion is done as soon as the file is opened, _before_ you  
have the chance to format the column as text!!!
Once the conversion is done... it's done.
I had gene names such as "SEP7" converted by Excel into a 5 digit  
number representing a date. From that number I didn't find a way to  
reconstruct "SEP7". "Sept-7" is not the same.

It seems like a problem with an easy solution. But it isn't. There are  
too many variations.

> A similar problem occurs in R's read.table() function when a factor
> has levels that can be interpreted as numbers.

at least with read.table you can specify the classes of each column  
_before_ you read the file.

R developers are better behaved than MS Excel ones ;-)

Jose

>
> At 10:11 PM 8/27/2007, David wrote:
>
>> A common process when data is obtained in an Excel spreadsheet is to save
>> the spreadsheet as a .csv file then read it into R. Experienced users
>> might have learned to be wary of dates (as I have) but possibly have not
>> experienced what just happened to me. I thought I might just share it with
>> r-help as a cautionary tale.
>>
>> I received an Excel file giving patient details. Each patient had an ID
>> code in the form of three letters followed by four digits. (Actually a New
>> Zealand National Health Identification.) I saved the .xls file as .csv.
>> Then I opened up the .csv (with Excel) to look at it. In the column of ID
>> codes I saw: Aug-99. Clicking on that entry it showed 1/08/2699.
>>
>> In a column of character data, Excel had interpreted AUG2699 as a date.
>>
>> The .csv did not actually have a date in that cell, but if I had saved the
>> .csv file it would have.
>>
>> David Scott
>
> ================================================================
> Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
> Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
> 824 Timberlake Drive                     Tel: 757-467-0954
> Virginia Beach, VA 23464-3239            Fax: 757-467-2947
>
> "Vere scire est per causas scire"
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Dr. Jose I. de las Heras                      Email: J.delasHeras at ed.ac.uk
The Wellcome Trust Centre for Cell Biology    Phone: +44 (0)131 6513374
Institute for Cell & Molecular Biology        Fax:   +44 (0)131 6507360
Swann Building, Mayfield Road
University of Edinburgh
Edinburgh EH9 3JR
UK

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From J.delasHeras at ed.ac.uk  Thu Sep  6 19:03:17 2007
From: J.delasHeras at ed.ac.uk (J.delasHeras at ed.ac.uk)
Date: Thu, 06 Sep 2007 18:03:17 +0100
Subject: [R] Excel
In-Reply-To: <200708280016.21320.jwd@surewest.net>
References: <0JNG004QHW2G2AX4@vms042.mailsrvcs.net>
	<Pine.LNX.4.64.0708281713370.12237@stat12.stat.auckland.ac.nz>
	<200708280016.21320.jwd@surewest.net>
Message-ID: <20070906180317.fskzepvtw0cgw4kk@www.staffmail.ed.ac.uk>

Quoting J Dougherty <jwd at surewest.net>:

> On Monday 27 August 2007 22:21, David Scott wrote:
>> On Tue, 28 Aug 2007, Robert A LaBudde wrote:
>> > If you format the column as "Text", you won't have this problem. By
>> > leaving the cells as "General", you leave it up to Excel to guess at
>> > the correct interpretation.
>>
>> Not true actually. I had converted the column to Text because I saw the
>> interpretation as a date in the .xls file. I saved the .csv file *after*
>> the column had been converted to Text. Looking at the .csv file in a text
>> editor, the entry is correct.
>>
>> I have just rechecked this.
>>
>> On reopening the .csv using Excel, the entry AUG2699 had been interpreted
>> as a date, and was showing as Aug-99. Most bizarre is that the NHI value
>> of AUG1838 has *not* been interpreted as a date.
>>
> Actually, in Excel 2000, he's right.  What you have to is be sure of is that
> the "'" that denotes a text entry precedes EVERY entry that can be confused
> with a date.  Selecting the entire column and setting the format to "text"
> *before* data is entered does this. It will also create an  
> appropriate *.csv file.

Does this mean that Excel 2000 adds the apostrophe character? If so,  
that's not good. Yes, it can make teh right .CSV removing the  
apostrophe... but if you read the file again... you have teh issue  
coming back, because it does it automatically on opening the file,  
doesn't it?

> Excel is notable too because it will automatically convert "date-like"
> entries as you type.  In a column of IDs or similar critical data, that
> behaviour is really bad.  I have never tried the MS site, but I haven't been
> able to find any entry about how to turn that particular automatic behaviour
> off.

NOt sure in Excel 2000, but on whatever version it is you get in  
Office 2003, you can't. I pursued this and I eventually got the word  
from MS itself: you can't disable that "feature".

> PS, I quit using Excel for most important work after it returned a negative
> variance on some data I was collecting descriptive statistics on.

you can detect errors in your data... but how can you be sure that  
when you receive data processed by collaborators, for instance, there  
hasn't been a mistake?


-- 
Dr. Jose I. de las Heras                      Email: J.delasHeras at ed.ac.uk
The Wellcome Trust Centre for Cell Biology    Phone: +44 (0)131 6513374
Institute for Cell & Molecular Biology        Fax:   +44 (0)131 6507360
Swann Building, Mayfield Road
University of Edinburgh
Edinburgh EH9 3JR
UK

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From ggrothendieck at gmail.com  Thu Sep  6 19:18:02 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 6 Sep 2007 13:18:02 -0400
Subject: [R] Excel
In-Reply-To: <20070906175538.6yt2z3nqosc8ws8o@www.staffmail.ed.ac.uk>
References: <0JNG004QHW2G2AX4@vms042.mailsrvcs.net>
	<20070906175538.6yt2z3nqosc8ws8o@www.staffmail.ed.ac.uk>
Message-ID: <971536df0709061018x2712f6d8jba40cec295157221@mail.gmail.com>

On my version of Excel (Excel 2007 under Vista) using
File | Open on a file, a.txt such as:

a b
sep7 10
sep10 11

causes it to enter a wizard where it asks you for the delimiters and
column types so you can change it from what it offers as the default.
In particular, if you leave it at General it will guess Date but you can
specify Text or you can specify Date to cause it to select a
particular type.


On 9/6/07, J.delasHeras at ed.ac.uk <J.delasHeras at ed.ac.uk> wrote:
> Quoting Robert A LaBudde <ral at lcfltd.com>:
>
> > If you format the column as "Text", you won't have this problem. By
> > leaving the cells as "General", you leave it up to Excel to guess at
> > the correct interpretation.
> >
> > You will note that the conversion to a date occurs immediately in
> > Excel when you enter the value. There are many formats to enter dates.
> >
> > Either pre-format the column as Text, or prefix the individual entry
> > with an ' to indicate text.
>
> But the conversion is done as soon as the file is opened, _before_ you
> have the chance to format the column as text!!!
> Once the conversion is done... it's done.
> I had gene names such as "SEP7" converted by Excel into a 5 digit
> number representing a date. From that number I didn't find a way to
> reconstruct "SEP7". "Sept-7" is not the same.
>
> It seems like a problem with an easy solution. But it isn't. There are
> too many variations.
>
> > A similar problem occurs in R's read.table() function when a factor
> > has levels that can be interpreted as numbers.
>
> at least with read.table you can specify the classes of each column
> _before_ you read the file.
>
> R developers are better behaved than MS Excel ones ;-)
>
> Jose
>
> >
> > At 10:11 PM 8/27/2007, David wrote:
> >
> >> A common process when data is obtained in an Excel spreadsheet is to save
> >> the spreadsheet as a .csv file then read it into R. Experienced users
> >> might have learned to be wary of dates (as I have) but possibly have not
> >> experienced what just happened to me. I thought I might just share it with
> >> r-help as a cautionary tale.
> >>
> >> I received an Excel file giving patient details. Each patient had an ID
> >> code in the form of three letters followed by four digits. (Actually a New
> >> Zealand National Health Identification.) I saved the .xls file as .csv.
> >> Then I opened up the .csv (with Excel) to look at it. In the column of ID
> >> codes I saw: Aug-99. Clicking on that entry it showed 1/08/2699.
> >>
> >> In a column of character data, Excel had interpreted AUG2699 as a date.
> >>
> >> The .csv did not actually have a date in that cell, but if I had saved the
> >> .csv file it would have.
> >>
> >> David Scott
> >
> > ================================================================
> > Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
> > Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
> > 824 Timberlake Drive                     Tel: 757-467-0954
> > Virginia Beach, VA 23464-3239            Fax: 757-467-2947
> >
> > "Vere scire est per causas scire"
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>
>
> --
> Dr. Jose I. de las Heras                      Email: J.delasHeras at ed.ac.uk
> The Wellcome Trust Centre for Cell Biology    Phone: +44 (0)131 6513374
> Institute for Cell & Molecular Biology        Fax:   +44 (0)131 6507360
> Swann Building, Mayfield Road
> University of Edinburgh
> Edinburgh EH9 3JR
> UK
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chris.elsaesser at spadac.com  Thu Sep  6 19:26:08 2007
From: chris.elsaesser at spadac.com (Chris Elsaesser)
Date: Thu, 6 Sep 2007 13:26:08 -0400
Subject: [R] Lisp-like primitives in R
Message-ID: <04C44D9F040C8A43A18D04F65A8B68BBD9E757@spatcex001.spadac.com>

I mainly program in Common Lisp and use R for statistical analysis.

While in R I miss the power and ease of use of Lisp, especially its many
primitives such as find, member, cond, and (perhaps a bridge too far)
loop.

Has anyone created a package that includes R analogs to a subset of Lisp
functions?


Chris Elsaesser, PhD        
Principal Scientist, Machine Learning
SPADAC Inc.
7921 Jones Branch Dr. Suite 600  
McLean, VA 22102  

703.371.7301 (m)
703.637.9421 (o)


From J.delasHeras at ed.ac.uk  Thu Sep  6 19:36:58 2007
From: J.delasHeras at ed.ac.uk (J.delasHeras at ed.ac.uk)
Date: Thu, 06 Sep 2007 18:36:58 +0100
Subject: [R] Excel
In-Reply-To: <46D7CE7C.50605@univie.ac.at>
References: <0JNG004QHW2G2AX4@vms042.mailsrvcs.net>
	<Pine.LNX.4.64.0708281713370.12237@stat12.stat.auckland.ac.nz>
	<200708280016.21320.jwd@surewest.net> <46D6DAE0.1070707@stats.uwo.ca>
	<46D7CE7C.50605@univie.ac.at>
Message-ID: <20070906183658.etv1mkk8g04g8ock@www.staffmail.ed.ac.uk>


Yes, and then you save it, you open it again... same behaviour.
The only way I found around it was to insert a character at the  
beginning of every element in such columns. An apostrophe works, but  
it looks ugly. Yes, when loading the data in R you could easily clean  
it up automatically... doable.
You can add a space. Then it will not show, but you have to remember  
that if you ever use the data for labels etc. You shouldn't need to do  
that in the first place...

Jose

Quoting Erich Neuwirth <erich.neuwirth at univie.ac.at>:

> There is a hack to get around the problem.
> It is definitely not a good solution, just a hack.
>
> Open the .csv file in a text editor and select everything.
> Paste it into an empty Excel sheet.
> Then use Data -> Text to Columns
>
> The third dialog box (at least it is the third one in Excel 2003)
> allows you to format each column of the data. This is the place where
> you can switch off the date interpretation of your ID column.
>
> AUG1838 probably is not onterpreted as date because Excel dates only
> start at 1/1/1900.
>
>
> Duncan Murdoch wrote:
>> On 8/28/2007 3:16 AM, J Dougherty wrote:
>>> On Monday 27 August 2007 22:21, David Scott wrote:
>>>> On Tue, 28 Aug 2007, Robert A LaBudde wrote:
>>>>> If you format the column as "Text", you won't have this problem. By
>>>>> leaving the cells as "General", you leave it up to Excel to guess at
>>>>> the correct interpretation.
>>>> Not true actually. I had converted the column to Text because I saw the
>>>> interpretation as a date in the .xls file. I saved the .csv file *after*
>>>> the column had been converted to Text. Looking at the .csv file in a text
>>>> editor, the entry is correct.
>>>>
>>>> I have just rechecked this.
>>>>
>>>> On reopening the .csv using Excel, the entry AUG2699 had been interpreted
>>>> as a date, and was showing as Aug-99. Most bizarre is that the NHI value
>>>> of AUG1838 has *not* been interpreted as a date.
>>>>
>
> --
> Erich Neuwirth, University of Vienna
> Faculty of Computer Science
> Computer Supported Didactics Working Group
> Visit our SunSITE at http://sunsite.univie.ac.at
> Phone: +43-1-4277-39464 Fax: +43-1-4277-39459
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Dr. Jose I. de las Heras                      Email: J.delasHeras at ed.ac.uk
The Wellcome Trust Centre for Cell Biology    Phone: +44 (0)131 6513374
Institute for Cell & Molecular Biology        Fax:   +44 (0)131 6507360
Swann Building, Mayfield Road
University of Edinburgh
Edinburgh EH9 3JR
UK

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From ggrothendieck at gmail.com  Thu Sep  6 20:29:09 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 6 Sep 2007 14:29:09 -0400
Subject: [R] Excel
In-Reply-To: <20070906183658.etv1mkk8g04g8ock@www.staffmail.ed.ac.uk>
References: <0JNG004QHW2G2AX4@vms042.mailsrvcs.net>
	<Pine.LNX.4.64.0708281713370.12237@stat12.stat.auckland.ac.nz>
	<200708280016.21320.jwd@surewest.net> <46D6DAE0.1070707@stats.uwo.ca>
	<46D7CE7C.50605@univie.ac.at>
	<20070906183658.etv1mkk8g04g8ock@www.staffmail.ed.ac.uk>
Message-ID: <971536df0709061129u6b4f56a7m7e194b988a8fc6e5@mail.gmail.com>

That is not what happens in Excel 2007 when I tried it just now. I tried
saving the same file I displayed in my prior message as an .xls file and
as an .xlsx file and in both cases the first column came back as text,
as I had specified to the Wizard on the initial import.  I guess they fixed
the behavior in Excel 2007.

On 9/6/07, J.delasHeras at ed.ac.uk <J.delasHeras at ed.ac.uk> wrote:
>
> Yes, and then you save it, you open it again... same behaviour.
> The only way I found around it was to insert a character at the
> beginning of every element in such columns. An apostrophe works, but
> it looks ugly. Yes, when loading the data in R you could easily clean
> it up automatically... doable.
> You can add a space. Then it will not show, but you have to remember
> that if you ever use the data for labels etc. You shouldn't need to do
> that in the first place...
>
> Jose
>
> Quoting Erich Neuwirth <erich.neuwirth at univie.ac.at>:
>
> > There is a hack to get around the problem.
> > It is definitely not a good solution, just a hack.
> >
> > Open the .csv file in a text editor and select everything.
> > Paste it into an empty Excel sheet.
> > Then use Data -> Text to Columns
> >
> > The third dialog box (at least it is the third one in Excel 2003)
> > allows you to format each column of the data. This is the place where
> > you can switch off the date interpretation of your ID column.
> >
> > AUG1838 probably is not onterpreted as date because Excel dates only
> > start at 1/1/1900.
> >
> >
> > Duncan Murdoch wrote:
> >> On 8/28/2007 3:16 AM, J Dougherty wrote:
> >>> On Monday 27 August 2007 22:21, David Scott wrote:
> >>>> On Tue, 28 Aug 2007, Robert A LaBudde wrote:
> >>>>> If you format the column as "Text", you won't have this problem. By
> >>>>> leaving the cells as "General", you leave it up to Excel to guess at
> >>>>> the correct interpretation.
> >>>> Not true actually. I had converted the column to Text because I saw the
> >>>> interpretation as a date in the .xls file. I saved the .csv file *after*
> >>>> the column had been converted to Text. Looking at the .csv file in a text
> >>>> editor, the entry is correct.
> >>>>
> >>>> I have just rechecked this.
> >>>>
> >>>> On reopening the .csv using Excel, the entry AUG2699 had been interpreted
> >>>> as a date, and was showing as Aug-99. Most bizarre is that the NHI value
> >>>> of AUG1838 has *not* been interpreted as a date.
> >>>>
> >
> > --
> > Erich Neuwirth, University of Vienna
> > Faculty of Computer Science
> > Computer Supported Didactics Working Group
> > Visit our SunSITE at http://sunsite.univie.ac.at
> > Phone: +43-1-4277-39464 Fax: +43-1-4277-39459
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>
>
> --
> Dr. Jose I. de las Heras                      Email: J.delasHeras at ed.ac.uk
> The Wellcome Trust Centre for Cell Biology    Phone: +44 (0)131 6513374
> Institute for Cell & Molecular Biology        Fax:   +44 (0)131 6507360
> Swann Building, Mayfield Road
> University of Edinburgh
> Edinburgh EH9 3JR
> UK
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tkobayas at indiana.edu  Thu Sep  6 20:29:53 2007
From: tkobayas at indiana.edu (tkobayas at indiana.edu)
Date: Thu,  6 Sep 2007 14:29:53 -0400
Subject: [R] problems in read.table
Message-ID: <20070906142953.77ui0cp96so4w888@webmail.iu.edu>

Dear R-users,

I have encountered the following problem every now and then. But I was 
dealing with a very small dataset before, so it wasn't a problem (I 
just edited the dataset in Openoffice speadsheet). This time I have to 
deal with many large datasets containing commuting flow data. I 
appreciate if anyone could give me a hint or clue to get out of this 
problem.

I have a .dat file called "1081.dat": 1001 means Birmingham, AL.

I imported this .dat file using read.table like
tmp<-read.table('CTPP3_ANSI/MPO3441_ctpp3_sumlv944.dat',header=T)

Then I got this error message:
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
        line 9499 did not have 209 elements

Since I got an error message saying other rows did not have 209 
elements, I added skip=c(205,9499,9294)) in hoping that R would take 
care of this problem. But I got a similar error message:
tmp<-read.table('CTPP3_ANSI/MPO3441_ctpp3_sumlv944.dat',header=T,skip=c(205,9499,9294))
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
        line 9294 did not have 209 elements
In addition: Warning message:
the condition has length > 1 and only the first element will be used 
in: if (skip > 0) readLines(file, skip)

Is there any way to let a R code to automatically skip problematic 
rows? Thank you very much!

Taka


From ggrothendieck at gmail.com  Thu Sep  6 20:30:51 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 6 Sep 2007 14:30:51 -0400
Subject: [R] Lisp-like primitives in R
In-Reply-To: <04C44D9F040C8A43A18D04F65A8B68BBD9E757@spatcex001.spadac.com>
References: <04C44D9F040C8A43A18D04F65A8B68BBD9E757@spatcex001.spadac.com>
Message-ID: <971536df0709061130y6a6cb8adkf301e3e45b72aba@mail.gmail.com>

Reduce, Filter and Map are part of R 2.6.0.  Try ?Reduce

On 9/6/07, Chris Elsaesser <chris.elsaesser at spadac.com> wrote:
> I mainly program in Common Lisp and use R for statistical analysis.
>
> While in R I miss the power and ease of use of Lisp, especially its many
> primitives such as find, member, cond, and (perhaps a bridge too far)
> loop.
>
> Has anyone created a package that includes R analogs to a subset of Lisp
> functions?
>
>
> Chris Elsaesser, PhD
> Principal Scientist, Machine Learning
> SPADAC Inc.
> 7921 Jones Branch Dr. Suite 600
> McLean, VA 22102
>
> 703.371.7301 (m)
> 703.637.9421 (o)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pisicandru at hotmail.com  Thu Sep  6 20:33:57 2007
From: pisicandru at hotmail.com (Monica Pisica)
Date: Thu, 6 Sep 2007 18:33:57 +0000
Subject: [R]  write geotiff with projection - RGDAL package
Message-ID: <BAY104-W285AEE6410EFCD6C7DD71AC3C40@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070906/db6d8994/attachment.pl 

From ggrothendieck at gmail.com  Thu Sep  6 21:02:24 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 6 Sep 2007 15:02:24 -0400
Subject: [R] problems in read.table
In-Reply-To: <20070906142953.77ui0cp96so4w888@webmail.iu.edu>
References: <20070906142953.77ui0cp96so4w888@webmail.iu.edu>
Message-ID: <971536df0709061202v6193fd8dpa62ff399c725c592@mail.gmail.com>

See ?count.fields to get a vector of how many fields are on each line.
Also fill = TRUE on read.table() can be used to fill out short lines if
that is appropriate.

On 9/6/07, tkobayas at indiana.edu <tkobayas at indiana.edu> wrote:
> Dear R-users,
>
> I have encountered the following problem every now and then. But I was
> dealing with a very small dataset before, so it wasn't a problem (I
> just edited the dataset in Openoffice speadsheet). This time I have to
> deal with many large datasets containing commuting flow data. I
> appreciate if anyone could give me a hint or clue to get out of this
> problem.
>
> I have a .dat file called "1081.dat": 1001 means Birmingham, AL.
>
> I imported this .dat file using read.table like
> tmp<-read.table('CTPP3_ANSI/MPO3441_ctpp3_sumlv944.dat',header=T)
>
> Then I got this error message:
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>        line 9499 did not have 209 elements
>
> Since I got an error message saying other rows did not have 209
> elements, I added skip=c(205,9499,9294)) in hoping that R would take
> care of this problem. But I got a similar error message:
> tmp<-read.table('CTPP3_ANSI/MPO3441_ctpp3_sumlv944.dat',header=T,skip=c(205,9499,9294))
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>        line 9294 did not have 209 elements
> In addition: Warning message:
> the condition has length > 1 and only the first element will be used
> in: if (skip > 0) readLines(file, skip)
>
> Is there any way to let a R code to automatically skip problematic
> rows? Thank you very much!
>
> Taka
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From p.dalgaard at biostat.ku.dk  Thu Sep  6 21:05:10 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 06 Sep 2007 21:05:10 +0200
Subject: [R] problems in read.table
In-Reply-To: <20070906142953.77ui0cp96so4w888@webmail.iu.edu>
References: <20070906142953.77ui0cp96so4w888@webmail.iu.edu>
Message-ID: <46E04F66.1020003@biostat.ku.dk>

tkobayas at indiana.edu wrote:
> Dear R-users,
>
> I have encountered the following problem every now and then. But I was 
> dealing with a very small dataset before, so it wasn't a problem (I 
> just edited the dataset in Openoffice speadsheet). This time I have to 
> deal with many large datasets containing commuting flow data. I 
> appreciate if anyone could give me a hint or clue to get out of this 
> problem.
>
> I have a .dat file called "1081.dat": 1001 means Birmingham, AL.
>
> I imported this .dat file using read.table like
> tmp<-read.table('CTPP3_ANSI/MPO3441_ctpp3_sumlv944.dat',header=T)
>
> Then I got this error message:
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>         line 9499 did not have 209 elements
>
> Since I got an error message saying other rows did not have 209 
> elements, I added skip=c(205,9499,9294)) in hoping that R would take 
> care of this problem. But I got a similar error message:
> tmp<-read.table('CTPP3_ANSI/MPO3441_ctpp3_sumlv944.dat',header=T,skip=c(205,9499,9294))
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>         line 9294 did not have 209 elements
> In addition: Warning message:
> the condition has length > 1 and only the first element will be used 
> in: if (skip > 0) readLines(file, skip)
>
> Is there any way to let a R code to automatically skip problematic 
> rows? Thank you very much!
>
>   
Skip is the NUMBER of rows to skip before reading. It has to be a single 
number.

You can use fill and flush to read lines with too few or too many 
elements, but it might be better to investigate the cause of the 
problem. What are in those lines? Quote and comment characters are 
common culprits.

> Taka
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From pisicandru at hotmail.com  Thu Sep  6 21:24:22 2007
From: pisicandru at hotmail.com (Monica Pisica)
Date: Thu, 6 Sep 2007 19:24:22 +0000
Subject: [R]  larger decimal numbers get rounded ....
Message-ID: <BAY104-W16295D8119A8A28AF4DE07C3C40@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070906/bb8f20b2/attachment.pl 

From mark at wardle.org  Thu Sep  6 21:34:57 2007
From: mark at wardle.org (Mark Wardle)
Date: Thu, 6 Sep 2007 20:34:57 +0100
Subject: [R] larger decimal numbers get rounded ....
In-Reply-To: <BAY104-W16295D8119A8A28AF4DE07C3C40@phx.gbl>
References: <BAY104-W16295D8119A8A28AF4DE07C3C40@phx.gbl>
Message-ID: <b59a37130709061234odc3ab1dp5c50f1c212f943ef@mail.gmail.com>

See ?print

and try getOption('digits')

and try print(a, digits=10)

Best wishes,

Mark

P.S. Your number is internally correct, but the default print() will
round numbers for display. You can change this option if you need to.

On 06/09/07, Monica Pisica <pisicandru at hotmail.com> wrote:
>
> Hi,
>
> I am sure there is a reason but ...... why larger decimal numbers get rounded to the nearest integer?
>
> Example:
>
> a <- 3308000.5
> a
> [1] 3308001
>
> I would like my numbers to be decimals .... since they do represent coordinates and i don't want them rounded .... how can i keep them as they are?
>
> Thanks,
>
> Monica
> _________________________________________________________________
>
>
> e=wlmailtagline
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________________________________
> This email has been scanned by the MessageLabs Email Security System.
> For more information please visit http://www.messagelabs.com/email
> ______________________________________________________________________
>


-- 
Dr. Mark Wardle
Specialist registrar, Neurology
Cardiff, UK


From tkobayas at indiana.edu  Thu Sep  6 21:49:07 2007
From: tkobayas at indiana.edu (tkobayas at indiana.edu)
Date: Thu,  6 Sep 2007 15:49:07 -0400
Subject: [R] problems in read.table-Solved
In-Reply-To: <46E04F66.1020003@biostat.ku.dk>
References: <20070906142953.77ui0cp96so4w888@webmail.iu.edu>
	<46E04F66.1020003@biostat.ku.dk>
Message-ID: <20070906154907.1iald7z9oko4wccs@webmail.iu.edu>

Thank you very much for help. I am learning R every day....

Taka

Quoting Peter Dalgaard <p.dalgaard at biostat.ku.dk>:

> tkobayas at indiana.edu wrote:
>> Dear R-users,
>>
>> I have encountered the following problem every now and then. But I
>> was dealing with a very small dataset before, so it wasn't a problem
>> (I just edited the dataset in Openoffice speadsheet). This time I
>> have to deal with many large datasets containing commuting flow
>> data. I appreciate if anyone could give me a hint or clue to get out
>> of this problem.
>>
>> I have a .dat file called "1081.dat": 1001 means Birmingham, AL.
>>
>> I imported this .dat file using read.table like
>> tmp<-read.table('CTPP3_ANSI/MPO3441_ctpp3_sumlv944.dat',header=T)
>>
>> Then I got this error message:
>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines,
>> na.strings,  :
>>         line 9499 did not have 209 elements
>>
>> Since I got an error message saying other rows did not have 209
>> elements, I added skip=c(205,9499,9294)) in hoping that R would take
>> care of this problem. But I got a similar error message:
>> tmp<-read.table('CTPP3_ANSI/MPO3441_ctpp3_sumlv944.dat',header=T,skip=c(205,9499,9294))
>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines,
>> na.strings,  :
>>         line 9294 did not have 209 elements
>> In addition: Warning message:
>> the condition has length > 1 and only the first element will be used
>> in: if (skip > 0) readLines(file, skip)
>>
>> Is there any way to let a R code to automatically skip problematic
>> rows? Thank you very much!
>>
>>
> Skip is the NUMBER of rows to skip before reading. It has to be a
> single number.
>
> You can use fill and flush to read lines with too few or too many
> elements, but it might be better to investigate the cause of the
> problem. What are in those lines? Quote and comment characters are
> common culprits.
>
>> Taka
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>
>
>



------------------------------------
Takatsugu Kobayashi
PhD Student
Indiana University, Dept. Geography


From deepayan.sarkar at gmail.com  Thu Sep  6 22:08:47 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 6 Sep 2007 13:08:47 -0700
Subject: [R] labelling specific points xyplot
In-Reply-To: <1DF7DB4AB44EFB41A60A889186D43359120C8B@srv-laminiere.arvalis-fr.com>
References: <1DF7DB4AB44EFB41A60A889186D43359120C8B@srv-laminiere.arvalis-fr.com>
Message-ID: <eb555e660709061308g42414115jfdeda4feb1c78474@mail.gmail.com>

On 9/6/07, GOUACHE David <D.GOUACHE at arvalisinstitutduvegetal.fr> wrote:
> Hello R-helpers,
>
> I'm trying to add labels to points in xyplot graphs, but I want lo label only those points which have a certain level of my grouping variable, and have encountered a few problems.
> An example dataframe that goes with the following code is at the end of this message.
>
> 1st step, adding labels (from another column in the dataframe) to my chosen points  :
> I've figures this out, but I am passing my whole dataframe as an extra argument (arg1) which I realize is probably useless, so if anybody can give me a way to work around this...
>
> xyplot(pp~nn,groups=vari,data=test,auto.key=list(space="right"),arg1=test,arg2="2",arg3="loc",
>                 panel=function(x,y,groups,arg1,arg2,arg3,...)
>                 {
>                         panel.superpose(x,y,groups,...)
>                         ?tiq<-rep("",times=length(x))
>                         ?tiq[groups==arg2]<-as.character(arg1[groups==arg2,arg3])
>                         ?tiq<-as.character(?tiq)
>                         panel.text(x,y,labels=?tiq,pos=1,cex=0.5,...)
>                 }
>                 )
>
> What I would also like is to write a function that is robust for multiple panel displays or subsetting :
>

This is not the only way, but the most transparent one I can think of:

xyplot(pp ~ nn, groups = vari,data = test,
       labels = test$loc, do.label = (test$vari == "2"),
       auto.key=list(space="right"),
       panel = function(x, y, groups, subscripts, labels, do.labels, ...) {
           panel.xyplot(x, y, groups = groups, subscripts = subscripts, ...)
           labels <- labels[subscripts]
           do.labels <- do.labels[subscripts]
           panel.text(x[do.labels], y[do.labels],
                      labels = labels[do.labels],
                      pos = 1, cex=0.5, ...)
       })

-Deepayan


From Greg.Snow at intermountainmail.org  Thu Sep  6 22:10:13 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 6 Sep 2007 14:10:13 -0600
Subject: [R] Lisp-like primitives in R
In-Reply-To: <04C44D9F040C8A43A18D04F65A8B68BBD9E757@spatcex001.spadac.com>
References: <04C44D9F040C8A43A18D04F65A8B68BBD9E757@spatcex001.spadac.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBB4053@LP-EXCHVS07.CO.IHC.COM>

Not all of us are familiar with lisp (I have done a little, but not
enough to really understand what you are asking).  If you tell us what
find, member, cond, and loop do, or what functionality you are looking
for, then we will have a better chance of telling you how to do the same
in R.

Just guessing by the names:

The 'which' function may do something similar to 'find'.

'is.element' or '%in%' may do the same as 'member'.

'ifelse' and/or 'switch' may do what 'cond' does.

'replicate', 'lapply', 'sapply', 'while', and 'for' may give the
functionality of 'loop'.

Those are just guesses based on the names, I don't know what exactly
they do, so if I am way off, then tell us what you want them to do.


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Chris Elsaesser
> Sent: Thursday, September 06, 2007 11:26 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Lisp-like primitives in R
> 
> I mainly program in Common Lisp and use R for statistical analysis.
> 
> While in R I miss the power and ease of use of Lisp, 
> especially its many primitives such as find, member, cond, 
> and (perhaps a bridge too far) loop.
> 
> Has anyone created a package that includes R analogs to a 
> subset of Lisp functions?
> 
> 
> Chris Elsaesser, PhD        
> Principal Scientist, Machine Learning
> SPADAC Inc.
> 7921 Jones Branch Dr. Suite 600
> McLean, VA 22102  
> 
> 703.371.7301 (m)
> 703.637.9421 (o)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Greg.Snow at intermountainmail.org  Thu Sep  6 22:27:51 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 6 Sep 2007 14:27:51 -0600
Subject: [R] larger decimal numbers get rounded ....
In-Reply-To: <BAY104-W16295D8119A8A28AF4DE07C3C40@phx.gbl>
References: <BAY104-W16295D8119A8A28AF4DE07C3C40@phx.gbl>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBB4061@LP-EXCHVS07.CO.IHC.COM>

?options  
Look at the entry on 'digits'.  Does that fix the problem?  If not, give
a little more detail on what you are doing.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Monica Pisica
> Sent: Thursday, September 06, 2007 1:24 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] larger decimal numbers get rounded ....
> Importance: High
> 
> 
> Hi,
>  
> I am sure there is a reason but ...... why larger decimal 
> numbers get rounded to the nearest integer?
>  
> Example:
>  
> a <- 3308000.5
> a
> [1] 3308001
>  
> I would like my numbers to be decimals .... since they do 
> represent coordinates and i don't want them rounded .... how 
> can i keep them as they are?
>  
> Thanks,
>  
> Monica
> _________________________________________________________________
> 
> 
> e=wlmailtagline
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ymoisan at groupesm.com  Thu Sep  6 22:33:53 2007
From: ymoisan at groupesm.com (Yves Moisan)
Date: Thu, 6 Sep 2007 13:33:53 -0700 (PDT)
Subject: [R] text in boxplots
Message-ID: <12530892.post@talk.nabble.com>


Hi All,

I can't get text to print on a boxplot using the 'text' command.  'mtext'
works, but not 'text'.  Is it a matter of boxplots being drawn over text? 
Pointers appreciated.

TIA,

YVes
-- 
View this message in context: http://www.nabble.com/text-in-boxplots-tf4394528.html#a12530892
Sent from the R help mailing list archive at Nabble.com.


From Greg.Snow at intermountainmail.org  Thu Sep  6 22:40:59 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 6 Sep 2007 14:40:59 -0600
Subject: [R] text in boxplots
In-Reply-To: <12530892.post@talk.nabble.com>
References: <12530892.post@talk.nabble.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBB4068@LP-EXCHVS07.CO.IHC.COM>


It works for me:

> boxplot( split(state.x77[,'Frost'], state.region) )
> text( 1:4, -5, rep('test',4), col='green' )

Show us what you tried and maybe we can be of more help,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Yves Moisan
> Sent: Thursday, September 06, 2007 2:34 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] text in boxplots
> 
> 
> Hi All,
> 
> I can't get text to print on a boxplot using the 'text' 
> command.  'mtext'
> works, but not 'text'.  Is it a matter of boxplots being 
> drawn over text? 
> Pointers appreciated.
> 
> TIA,
> 
> YVes
> --
> View this message in context: 
> http://www.nabble.com/text-in-boxplots-tf4394528.html#a12530892
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From liulei at virginia.edu  Thu Sep  6 22:55:26 2007
From: liulei at virginia.edu (Lei Liu)
Date: Thu, 06 Sep 2007 16:55:26 -0400
Subject: [R] incomplete latin square design
Message-ID: <7.0.1.0.1.20070906164636.01de27c0@virginia.edu>

Hi there,

I have a question on cross over design. There are 3 treatments, each 
with 3 dose levels, a total of 27 treatment combinations. Each 
treatment combination is given to a subject in 1 day. However, we can 
only keep each subject for 9 days, i.e. each subject can have only 
take 9 treatment combinations. This looks like a incomplete latin 
square design. Is there any function in R to create such design? Thanks a lot!
Lei Liu
Assistant Professor
Division of Biostatistics and Epidemiology
Department of Public Health Sciences
School of Medicine
University of Virginia

3181 Hospital West Complex
Charlottesville, VA 22908-0717

1-434-982-3364 (o)
1-434-806-8086 (c)
1-434-243-5787 (f)


liulei at virginia.edu
ll9f at virginia.edu


From bartjoosen at hotmail.com  Thu Sep  6 10:47:32 2007
From: bartjoosen at hotmail.com (Bartjoosen)
Date: Thu, 6 Sep 2007 01:47:32 -0700 (PDT)
Subject: [R] Warning message with aggregate function
In-Reply-To: <46DFB220.3050403@gmail.com>
References: <46DFB220.3050403@gmail.com>
Message-ID: <12518160.post@talk.nabble.com>


If I use your code, I don't get the error.
Maybe you stripped your code to create a minimal, self-contained,
reproducible code?

Perhaps in your original code, you store the result of the aggragate
function in a dataframe of a different size than the results?


Bart



felix-36 wrote:
> 
> Dear all,
> When I use aggregate function as:
> 
> attach(warpbreaks)
> aggregate(warpbreaks[, 1], list(wool = wool, tension = tension), sum)
> 
> The results are right but I get a warning message:
> "number of items to replace is not a multiple of replacement length."
> 
> BTW: I use R version 2.4.1 in Ubuntu 7.04.
> 
> Your kind solutions will be great appreciated.
> 
> Best wishes
> 
> Yours, sincerely,
> Xingwang Ye
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Warning-message-with-aggregate-function-tf4390252.html#a12518160
Sent from the R help mailing list archive at Nabble.com.


From realityrandom at gmail.com  Thu Sep  6 01:43:19 2007
From: realityrandom at gmail.com (Yuchen Luo)
Date: Wed, 5 Sep 2007 16:43:19 -0700
Subject: [R] =?windows-1252?q?=27singular_gradient_matrix=92_when_using_nl?=
	=?windows-1252?q?s=28=29_and_how_to_make_the_program_skip_nls=28_?=
	=?windows-1252?q?=29_and_run_on?=
Message-ID: <548b8d440709051643p69659404ude641b631b9eb25c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070905/6a979ed3/attachment.pl 

From philipsmith at alumni.albany.edu  Thu Sep  6 20:42:32 2007
From: philipsmith at alumni.albany.edu (Philip James Smith)
Date: Thu, 06 Sep 2007 14:42:32 -0400
Subject: [R] computing distance in miles or km between 2 street addresses
Message-ID: <46E04A18.7040909@alumni.albany.edu>

Hi R-ers:

I need to compute the distance between 2 street addresses in either km 
or miles. I do not care if the distance is a "shortest driving route" or 
if it is "as the crow flies."

Does anybody know how to do this? Can it be done in R? I have thousands 
of addresses, so I think that Mapquest is out of the question!

Please rely to: philipsmith at alumni.albany.edu

Thank you!
Phil Smith


From weeksjp at gmail.com  Wed Sep  5 18:15:11 2007
From: weeksjp at gmail.com (Jonathan Weeks)
Date: Wed, 5 Sep 2007 10:15:11 -0600
Subject: [R] [R-pkgs] New R package plink for separate calibration IRT
	linking
Message-ID: <8a7634360709050915s3c13221at4a82775b9e208098@mail.gmail.com>

The first version of the package plink has been uploaded to CRAN.

plink is a package for conducting unidimensional IRT scaling and chain
linking for multiple groups for single-format or mixed-format common
items. The package supports eight IRT models and four calibration
methods.

Dichotomous Models:
1PL, 2PL, 3PL

Polytomous Models:
-Graded response model
-Partial credit model
-Generalized partial credit model
-Nominal response model
-Multiple-choice model

Calibration Methods:
-Mean/Mean
-Mean/Sigma
-Haebara
-Stocking-Lord

Any combination of dichotomous and polytomous items can be supplied
with intermingled unique and common items for as many items and groups
as system memory allows. Linking constants are computed and returned
for all the calibration methods, and (if desired) ability and/or item
parameters can be rescaled and returned using any of the estimated
linking constants.

Any of the included groups can be specified as the base scale, the
characteristic curve methods can use symmetric or non-symmetric
optimization, various scoring functions can be supplied for the
Stocking-Lord method, and there is great flexibility in specifying
thetas and theta weights to be integrated over in the characteristic
curve methods.

In addition to computing linking constants and rescaling ability and
item parameters, the methods in the package can be used to compute
item/category response probabilities and create plots of item/category
characteristic curves.

The package is designed to allow for a variety of formats for the item
parameters including vectors, lists, matrices, and other objects
(irt.pars and sep.pars) available in the package. Item parameters and
calibration output can be summarized, and descriptive statistics for
the item parameters can be displayed as well.

Getting Started:
Running the separate calibration is typically a two-step process. The
first step is to format the item parameters for processing with the
function 'plink'. Parameters should be formatted as either an object
of class 'irt.pars' with multiple groups, a set of 'irt.pars' objects,
or a set of 'sep.pars' objects.  Once in this format, response
probabilities can be computed using the functions 'drm', 'gpcm',
'grm', 'mcm', or 'nrm' or linking constants can be computed using
'plink'.

The functions 'as.irt.pars', 'sep.pars', and 'combine.pars' can be
used to create the 'irt.pars' and 'sep.pars' objects. 'summary' can be
used to summarize item parameters (including descriptive statistics)
and linking constants, and 'plot' can be used to create item/category
characteristic curves.

I am currently working on a vignette; however, the documentation
contains extensive examples. The best documentation to start with is
help(as.irt.pars) and help(plink).

Although this is the first version of this package, I have gone
through extensive debugging and validation, so there should be few, if
any bugs. Many of the examples (and the associated output) can be
found in published articles or books, and the output from the various
calibration methods has been checked against other available linking
software.

I hope this will be a useful package for those interested in test
linking. I invite any comments and suggestions.

Take care

-- 
Jonathan Weeks
Doctoral Candidate
School of Education
University of Colorado, Boulder
weeksjp at gmail.com
303-517-9666

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From ggrothendieck at gmail.com  Thu Sep  6 23:21:49 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 6 Sep 2007 17:21:49 -0400
Subject: [R]
	=?windows-1252?q?=27singular_gradient_matrix=92_when_using_nl?=
	=?windows-1252?q?s=28=29_and_how_to_make_the_program_skip_nls=28_?=
	=?windows-1252?q?=29_and_run_on?=
In-Reply-To: <548b8d440709051643p69659404ude641b631b9eb25c@mail.gmail.com>
References: <548b8d440709051643p69659404ude641b631b9eb25c@mail.gmail.com>
Message-ID: <971536df0709061421l759192bcl7eabbe5a42d26c70@mail.gmail.com>

In case 1 graph your function and then use optimize rather than nls.

In case 2 a and b may have the same effect as c on f whereas they
don't vary in case 1 so it does not matter.  For example consider
minimizing f <- function(a, b) (a + b)^2  If a is fixed at zero then
the minimum occurs for b=0 but if a is not fixed then increasing a
and decreasing b by the same amount causes no change in the
result so the gradient in such a direction is zero.

On 9/5/07, Yuchen Luo <realityrandom at gmail.com> wrote:
> Dear friends.
>
> I use nls() and encounter the following puzzling problem:
>
>
>
> I have a function f(a,b,c,x), I have a data vector of x and a vectory  y of
> realized value of f.
>
>
>
> Case1
>
> I tried to estimate  c with (a=0.3, b=0.5) fixed:
>
> nls(y~f(a,b,c,x), control=list(maxiter = 100000, minFactor=0.5
> ^2048),start=list(c=0.5)).
>
> The error message is: "number of iterations exceeded maximum of 100000"
>
>
>
> Case2
>
> I then think maybe the value of a and be are not reasonable. So, I let nls()
> estimate (a,b,c) altogether:
>
> nls(y~f(a,b,c,x), control=list(maxiter = 100000, minFactor=0.5
> ^2048),start=list(a=0.3,b=0.5,c=0.5)).
>
> The error message is:
>
> "singular gradient matrix at initial parameter estimates".
>
>
>
> This is what puzzles me, if the initial parameter of (a=0.3,b=0.5,c=0.5) can
> create 'singular gradient matrix', then why doesn't this 'singular gradient
> matrix' appear in Case1?
>
>
>
> I have tried to change the initial value of (a,b,c) around but the problem
> persists. I am wondering if there is a way out.
>
>
>
> My another question is, I need to run 220 of  nls() in my program with
> different y and x. When one of the nls() encounter a problem, the whole
> program stops.  In my case, the 3rd nls() runs into a problem.  I would
> still need the program to run the remaining 217 nls( )! Is there a way to
> make the program skip the problematic nls() and complete the ramaining
> nls()'s?
>
>
>
> Your help will be highly appreciated!
>
> Yuchen Luo
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pinard at iro.umontreal.ca  Fri Sep  7 00:10:43 2007
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Thu, 6 Sep 2007 18:10:43 -0400
Subject: [R] Lisp-like primitives in R
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBBB4053@LP-EXCHVS07.CO.IHC.COM>
References: <04C44D9F040C8A43A18D04F65A8B68BBD9E757@spatcex001.spadac.com>
	<07E228A5BE53C24CAD490193A7381BBBBB4053@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <20070906221043.GA5648@alcyon.progiciels-bpi.ca>

[Chris Elsaesser]

>> I mainly program in Common Lisp and use R for statistical analysis.  
>> While in R I miss the power and ease of use of Lisp, especially its 
>> many primitives such as find, member, cond, and (perhaps a bridge too 
>> far) loop.  Has anyone created a package that includes R analogs to 
>> a subset of Lisp functions?

[Greg Snow]

>Not all of us are familiar with lisp [...]  If you tell us what find, 
>member, cond, and loop do, or what functionality you are looking for, 
>then we will have a better chance of telling you how to do the same in 
>R.

Hi, my fRiends :-).

So far that I understand, R is built over what originally was a Scheme 
engine.  Scheme may be seen as a flavour of LISP (yet I know people that 
would strongly object seeing "Scheme" and "Lisp" in the same statement 
:-).  But it makes it rather likely that most functions you want already 
exist in R, even if under different names or syntax.

I wonder what happened, for R to hide the underlying Scheme so fully, at 
least at the level of the surface language (despite there are hints).  
Wouldn't it have been natural to have the underlying Scheme exposed as 
an extension language for R, so one might write Scheme functions just as 
well as C or FORTRAN functions?  Is the engine so far from a real Scheme 
implementation, that such an idea was never reasonable?

About the idea of Lisp-inspired library functions...  Many Lisp 
flavours, Common Lisp likely included, have a comprehensive 
(tremendous?) set of primitives and library functions.  By comparison, 
Scheme is quite moderate, and does not go much beyond the essentials, 
something which much pleases me :-).  There also are many important 
differences between Common Lisp and Scheme (like for example, global 
dynamic scoping versus textual scoping).  If R was ever to offer 
Lisp-like interfaces, RnRS (Scheme standards) might be considered, both 
for being simpler, and more in the spirit of what R already is.

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From Ted.Harding at manchester.ac.uk  Fri Sep  7 00:17:59 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Thu, 06 Sep 2007 23:17:59 +0100 (BST)
Subject: [R] computing distance in miles or km between 2 street addre
In-Reply-To: <46E04A18.7040909@alumni.albany.edu>
Message-ID: <XFMail.070906231759.Ted.Harding@manchester.ac.uk>

On 06-Sep-07 18:42:32, Philip James Smith wrote:
> Hi R-ers:
> 
> I need to compute the distance between 2 street addresses in
> either km or miles. I do not care if the distance is a "shortest
> driving route" or if it is "as the crow flies."
> 
> Does anybody know how to do this? Can it be done in R? I have
> thousands of addresses, so I think that Mapquest is out of the
> question!
> 
> Please rely to: philipsmith at alumni.albany.edu
> 
> Thank you!
> Phil Smith

That's a somewhat ill-posed question! You will for a start
need a database of some kind, either of geographical locations
(coordinates) of street addresses, or of the metric of the
road network with capability to identify the street addresses
in the database.

If it's just "as the crow flies", then it can be straightforwardly
computed in R, either by Pythogoras (when they are not too far
apart) or using a function which takes account of the shape of
the Earth,

There are many R packages which have to do with mapping data.
Search for "map" through the list of R packages at

http://finzi.psych.upenn.edu/R/library/maptools/html/00Index.html

-- maptools in particular. Also look at (for instance) aspace.

For "shortest driving route" then you need to find the shortest
distance through a network. You may find some hints in the
package optim -- but there must be some R experts out there
on this sort of thing!

However, the primary need is for the database which gives
the distance information in one form or another. What were
you proposing to use for this? As far as I know, R has no
database relevant to street addresses!

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 06-Sep-07                                       Time: 23:17:57
------------------------------ XFMail ------------------------------


From r.turner at auckland.ac.nz  Fri Sep  7 00:41:55 2007
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 7 Sep 2007 10:41:55 +1200
Subject: [R] computing distance in miles or km between 2 street addre
In-Reply-To: <XFMail.070906231759.Ted.Harding@manchester.ac.uk>
References: <XFMail.070906231759.Ted.Harding@manchester.ac.uk>
Message-ID: <E6F9FF90-4DFA-4D19-BFB7-68999357738A@auckland.ac.nz>


On 7/09/2007, at 10:17 AM, (Ted Harding) wrote:

> On 06-Sep-07 18:42:32, Philip James Smith wrote:
>> Hi R-ers:
>>
>> I need to compute the distance between 2 street addresses in
>> either km or miles. I do not care if the distance is a "shortest
>> driving route" or if it is "as the crow flies."
>>
>> Does anybody know how to do this? Can it be done in R? I have
>> thousands of addresses, so I think that Mapquest is out of the
>> question!
>>
>> Please rely to: philipsmith at alumni.albany.edu
>>
>> Thank you!
>> Phil Smith
>
> That's a somewhat ill-posed question! You will for a start
> need a database of some kind, either of geographical locations
> (coordinates) of street addresses, or of the metric of the
> road network with capability to identify the street addresses
> in the database.

	<snip>

>
>                                  As far as I know, R has no
> database relevant to street addresses!


	But Ted!  Don't you know that statistics in general and R in  
particular are
	supposed to be able to ***work MAGIC***???  :-) :-) :-)

				cheers,

					Rolf

######################################################################
Attention:\ This e-mail message is privileged and confidenti...{{dropped}}


From gunter.berton at gene.com  Fri Sep  7 01:33:34 2007
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 6 Sep 2007 16:33:34 -0700
Subject: [R] computing distance in miles or km between 2 street addre
In-Reply-To: <XFMail.070906231759.Ted.Harding@manchester.ac.uk>
References: <46E04A18.7040909@alumni.albany.edu>
	<XFMail.070906231759.Ted.Harding@manchester.ac.uk>
Message-ID: <000c01c7f0de$58454890$3a0b2c0a@gne.windows.gene.com>

There is a well-known (greeedy) algorithm due to Dijkstra for choosing the
shortest path = minimum weight path on a weighted digraph between two
vertices. I'm sure numerous open source versions of this are available.
optim() is not relevant.


Bert Gunter
Genentech Nonclinical Statistics


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ted Harding
Sent: Thursday, September 06, 2007 3:18 PM
To: Philip James Smith; r-help at stat.math.ethz.ch
Subject: Re: [R] computing distance in miles or km between 2 street addre

On 06-Sep-07 18:42:32, Philip James Smith wrote:
> Hi R-ers:
> 
> I need to compute the distance between 2 street addresses in
> either km or miles. I do not care if the distance is a "shortest
> driving route" or if it is "as the crow flies."
> 
> Does anybody know how to do this? Can it be done in R? I have
> thousands of addresses, so I think that Mapquest is out of the
> question!
> 
> Please rely to: philipsmith at alumni.albany.edu
> 
> Thank you!
> Phil Smith

That's a somewhat ill-posed question! You will for a start
need a database of some kind, either of geographical locations
(coordinates) of street addresses, or of the metric of the
road network with capability to identify the street addresses
in the database.

If it's just "as the crow flies", then it can be straightforwardly
computed in R, either by Pythogoras (when they are not too far
apart) or using a function which takes account of the shape of
the Earth,

There are many R packages which have to do with mapping data.
Search for "map" through the list of R packages at

http://finzi.psych.upenn.edu/R/library/maptools/html/00Index.html

-- maptools in particular. Also look at (for instance) aspace.

For "shortest driving route" then you need to find the shortest
distance through a network. You may find some hints in the
package optim -- but there must be some R experts out there
on this sort of thing!

However, the primary need is for the database which gives
the distance information in one form or another. What were
you proposing to use for this? As far as I know, R has no
database relevant to street addresses!

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 06-Sep-07                                       Time: 23:17:57
------------------------------ XFMail ------------------------------

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From roland.rproject at gmail.com  Fri Sep  7 01:36:55 2007
From: roland.rproject at gmail.com (Roland Rau)
Date: Thu, 06 Sep 2007 19:36:55 -0400
Subject: [R] Lisp-like primitives in R
In-Reply-To: <20070906221043.GA5648@alcyon.progiciels-bpi.ca>
References: <04C44D9F040C8A43A18D04F65A8B68BBD9E757@spatcex001.spadac.com>	<07E228A5BE53C24CAD490193A7381BBBBB4053@LP-EXCHVS07.CO.IHC.COM>
	<20070906221043.GA5648@alcyon.progiciels-bpi.ca>
Message-ID: <46E08F17.20505@gmail.com>

Fran?ois Pinard wrote:
> I wonder what happened, for R to hide the underlying Scheme so fully, at 
> least at the level of the surface language (despite there are hints).  

As far as I understood, the original version of Ihaka/Gentleman was 
written in Scheme. But even if you look at the source version of R 0.49 
(the oldest I can find), the source files are written in C. In addition, 
in their article published in "Journal of Computational and Graphical 
Statistics" in 1996, Ihaka and Gentleman write on page 307: "To further 
foster portability, we chose to write R in ANSI C...."

Hope this clarifies the situation a bit. If we are lucky and one of the 
original authors reads this thread they might explain the situation 
further and better (and probably correct me).

Best,
Roland


From hb at stat.berkeley.edu  Fri Sep  7 01:40:42 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Thu, 6 Sep 2007 16:40:42 -0700
Subject: [R] computing distance in miles or km between 2 street addre
In-Reply-To: <E6F9FF90-4DFA-4D19-BFB7-68999357738A@auckland.ac.nz>
References: <XFMail.070906231759.Ted.Harding@manchester.ac.uk>
	<E6F9FF90-4DFA-4D19-BFB7-68999357738A@auckland.ac.nz>
Message-ID: <59d7961d0709061640v2b01ec89s3d9dcff7685df671@mail.gmail.com>

On 9/6/07, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> On 7/09/2007, at 10:17 AM, (Ted Harding) wrote:
>
> > On 06-Sep-07 18:42:32, Philip James Smith wrote:
> >> Hi R-ers:
> >>
> >> I need to compute the distance between 2 street addresses in
> >> either km or miles. I do not care if the distance is a "shortest
> >> driving route" or if it is "as the crow flies."
> >>
> >> Does anybody know how to do this? Can it be done in R? I have
> >> thousands of addresses, so I think that Mapquest is out of the
> >> question!
> >>
> >> Please rely to: philipsmith at alumni.albany.edu
> >>
> >> Thank you!
> >> Phil Smith
> >
> > That's a somewhat ill-posed question! You will for a start
> > need a database of some kind, either of geographical locations
> > (coordinates) of street addresses, or of the metric of the
> > road network with capability to identify the street addresses
> > in the database.
>
>         <snip>
>
> >
> >                                  As far as I know, R has no
> > database relevant to street addresses!
>
>
>         But Ted!  Don't you know that statistics in general and R in
> particular are
>         supposed to be able to ***work MAGIC***???  :-) :-) :-)

Wow! I didn't know that. What's the function call?

/Henrik

>
>                                 cheers,
>
>                                         Rolf
>
> ######################################################################
> Attention:\ This e-mail message is privileged and confidenti...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch at stats.uwo.ca  Fri Sep  7 01:53:38 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 06 Sep 2007 19:53:38 -0400
Subject: [R] computing distance in miles or km between 2 street addre
In-Reply-To: <XFMail.070906231759.Ted.Harding@manchester.ac.uk>
References: <XFMail.070906231759.Ted.Harding@manchester.ac.uk>
Message-ID: <46E09302.3050108@stats.uwo.ca>

On 06/09/2007 6:17 PM, (Ted Harding) wrote:
> On 06-Sep-07 18:42:32, Philip James Smith wrote:
>> Hi R-ers:
>>
>> I need to compute the distance between 2 street addresses in
>> either km or miles. I do not care if the distance is a "shortest
>> driving route" or if it is "as the crow flies."
>>
>> Does anybody know how to do this? Can it be done in R? I have
>> thousands of addresses, so I think that Mapquest is out of the
>> question!
>>
>> Please rely to: philipsmith at alumni.albany.edu
>>
>> Thank you!
>> Phil Smith
> 
> That's a somewhat ill-posed question! You will for a start
> need a database of some kind, either of geographical locations
> (coordinates) of street addresses, or of the metric of the
> road network with capability to identify the street addresses
> in the database.
> 
> If it's just "as the crow flies", then it can be straightforwardly
> computed in R, either by Pythogoras (when they are not too far
> apart) or using a function which takes account of the shape of
> the Earth,
> 
> There are many R packages which have to do with mapping data.
> Search for "map" through the list of R packages at
> 
> http://finzi.psych.upenn.edu/R/library/maptools/html/00Index.html
> 
> -- maptools in particular. Also look at (for instance) aspace.
> 
> For "shortest driving route" then you need to find the shortest
> distance through a network. You may find some hints in the
> package optim -- but there must be some R experts out there
> on this sort of thing!
> 
> However, the primary need is for the database which gives
> the distance information in one form or another. What were
> you proposing to use for this? As far as I know, R has no
> database relevant to street addresses!

But if the addresses are in the US and include zip codes, a database is 
available online for free, here:

http://www.aggdata.com/files/zip_codes.zip

This includes latitude and longitude.  Zip codes cover a fairly large 
area so this won't give very accurate information, but it's easy to get.

Duncan Murdoch


From marc_schwartz at comcast.net  Fri Sep  7 01:56:43 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 06 Sep 2007 18:56:43 -0500
Subject: [R] computing distance in miles or km between 2 street addre
In-Reply-To: <59d7961d0709061640v2b01ec89s3d9dcff7685df671@mail.gmail.com>
References: <XFMail.070906231759.Ted.Harding@manchester.ac.uk>
	<E6F9FF90-4DFA-4D19-BFB7-68999357738A@auckland.ac.nz>
	<59d7961d0709061640v2b01ec89s3d9dcff7685df671@mail.gmail.com>
Message-ID: <1189123003.19396.66.camel@Bellerophon.localdomain>

On Thu, 2007-09-06 at 16:40 -0700, Henrik Bengtsson wrote:
> On 9/6/07, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> >
> > On 7/09/2007, at 10:17 AM, (Ted Harding) wrote:
> >
> > > On 06-Sep-07 18:42:32, Philip James Smith wrote:
> > >> Hi R-ers:
> > >>
> > >> I need to compute the distance between 2 street addresses in
> > >> either km or miles. I do not care if the distance is a "shortest
> > >> driving route" or if it is "as the crow flies."
> > >>
> > >> Does anybody know how to do this? Can it be done in R? I have
> > >> thousands of addresses, so I think that Mapquest is out of the
> > >> question!
> > >>
> > >> Please rely to: philipsmith at alumni.albany.edu
> > >>
> > >> Thank you!
> > >> Phil Smith
> > >
> > > That's a somewhat ill-posed question! You will for a start
> > > need a database of some kind, either of geographical locations
> > > (coordinates) of street addresses, or of the metric of the
> > > road network with capability to identify the street addresses
> > > in the database.
> >
> >         <snip>
> >
> > >
> > >                                  As far as I know, R has no
> > > database relevant to street addresses!
> >
> >
> >         But Ted!  Don't you know that statistics in general and R in
> > particular are
> >         supposed to be able to ***work MAGIC***???  :-) :-) :-)
> 
> Wow! I didn't know that. What's the function call?
> 
> /Henrik

  stats:::Supercalifragilisticexpialidocious()

;-)

Cheers,

Marc


From murdoch at stats.uwo.ca  Fri Sep  7 01:59:00 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 06 Sep 2007 19:59:00 -0400
Subject: [R] Lisp-like primitives in R
In-Reply-To: <46E08F17.20505@gmail.com>
References: <04C44D9F040C8A43A18D04F65A8B68BBD9E757@spatcex001.spadac.com>	<07E228A5BE53C24CAD490193A7381BBBBB4053@LP-EXCHVS07.CO.IHC.COM>	<20070906221043.GA5648@alcyon.progiciels-bpi.ca>
	<46E08F17.20505@gmail.com>
Message-ID: <46E09444.8040403@stats.uwo.ca>

On 06/09/2007 7:36 PM, Roland Rau wrote:
> Fran?ois Pinard wrote:
>> I wonder what happened, for R to hide the underlying Scheme so fully, at 
>> least at the level of the surface language (despite there are hints).  
> 
> As far as I understood, the original version of Ihaka/Gentleman was 
> written in Scheme. But even if you look at the source version of R 0.49 
> (the oldest I can find), the source files are written in C. In addition, 
> in their article published in "Journal of Computational and Graphical 
> Statistics" in 1996, Ihaka and Gentleman write on page 307: "To further 
> foster portability, we chose to write R in ANSI C...."
> 
> Hope this clarifies the situation a bit. If we are lucky and one of the 
> original authors reads this thread they might explain the situation 
> further and better (and probably correct me).

You could also look at Ross Ihaka's paper that is online here:

http://cran.r-project.org/doc/html/interface98-paper/paper.html

R was written in C, with the intention that it be Scheme-like.

Duncan Murdoch


From philipsmith at alumni.albany.edu  Fri Sep  7 02:14:10 2007
From: philipsmith at alumni.albany.edu (Philip James Smith)
Date: Thu, 06 Sep 2007 20:14:10 -0400
Subject: [R] computing distance in miles or km between 2 street addre
In-Reply-To: <XFMail.070906231759.Ted.Harding@manchester.ac.uk>
References: <XFMail.070906231759.Ted.Harding@manchester.ac.uk>
Message-ID: <46E097D2.4000304@alumni.albany.edu>

Thank you for your useful response. I will study it carefully.

Best regards,
Phil Smith

(Ted Harding) wrote:
> On 06-Sep-07 18:42:32, Philip James Smith wrote:
>   
>> Hi R-ers:
>>
>> I need to compute the distance between 2 street addresses in
>> either km or miles. I do not care if the distance is a "shortest
>> driving route" or if it is "as the crow flies."
>>
>> Does anybody know how to do this? Can it be done in R? I have
>> thousands of addresses, so I think that Mapquest is out of the
>> question!
>>
>> Please rely to: philipsmith at alumni.albany.edu
>>
>> Thank you!
>> Phil Smith
>>     
>
> That's a somewhat ill-posed question! You will for a start
> need a database of some kind, either of geographical locations
> (coordinates) of street addresses, or of the metric of the
> road network with capability to identify the street addresses
> in the database.
>
> If it's just "as the crow flies", then it can be straightforwardly
> computed in R, either by Pythogoras (when they are not too far
> apart) or using a function which takes account of the shape of
> the Earth,
>
> There are many R packages which have to do with mapping data.
> Search for "map" through the list of R packages at
>
> http://finzi.psych.upenn.edu/R/library/maptools/html/00Index.html
>
> -- maptools in particular. Also look at (for instance) aspace.
>
> For "shortest driving route" then you need to find the shortest
> distance through a network. You may find some hints in the
> package optim -- but there must be some R experts out there
> on this sort of thing!
>
> However, the primary need is for the database which gives
> the distance information in one form or another. What were
> you proposing to use for this? As far as I know, R has no
> database relevant to street addresses!
>
> Best wishes,
> Ted.
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 06-Sep-07                                       Time: 23:17:57
> ------------------------------ XFMail ------------------------------
>
>


From h.wickham at gmail.com  Fri Sep  7 02:23:47 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 6 Sep 2007 19:23:47 -0500
Subject: [R] computing distance in miles or km between 2 street addre
In-Reply-To: <XFMail.070906231759.Ted.Harding@manchester.ac.uk>
References: <46E04A18.7040909@alumni.albany.edu>
	<XFMail.070906231759.Ted.Harding@manchester.ac.uk>
Message-ID: <f8e6ff050709061723t7d724b47rd5cf31a1796f7fe1@mail.gmail.com>

On 9/6/07, Ted Harding <Ted.Harding at manchester.ac.uk> wrote:
> On 06-Sep-07 18:42:32, Philip James Smith wrote:
> > Hi R-ers:
> >
> > I need to compute the distance between 2 street addresses in
> > either km or miles. I do not care if the distance is a "shortest
> > driving route" or if it is "as the crow flies."
> >
> > Does anybody know how to do this? Can it be done in R? I have
> > thousands of addresses, so I think that Mapquest is out of the
> > question!
> >
> > Please rely to: philipsmith at alumni.albany.edu
> >
> > Thank you!
> > Phil Smith
>
> That's a somewhat ill-posed question! You will for a start
> need a database of some kind, either of geographical locations
> (coordinates) of street addresses, or of the metric of the
> road network with capability to identify the street addresses
> in the database.

I think it's perfectly well-posed, but you'll need to use some
resources outside of R.

The term for converting street addresses to lat/long values is called
geocoding, and wikipedia has a good introduction:
http://en.wikipedia.org/wiki/Geocoding.  There are a couple of free
geocoding web services for US addresses: e.g.
http://developer.yahoo.com/maps/rest/V1/geocode.html or
http://geocoder.us/.  For non-US addresses you'll have to google
around (e.g. international geocoding), and depending on the country
and level of detail you require, you may have to pay.

Once you've got lat and longs, computing grand circle distance is
easy.  Computing driving distances is harder, but may be possible with
(e.g.) the google maps API -
http://www.google.com/apis/maps/documentation/index.html#Driving_Directions.
 Googling for driving directions api suggests some other
possibilities.

Hadley


From NordlDJ at dshs.wa.gov  Fri Sep  7 02:41:51 2007
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 6 Sep 2007 17:41:51 -0700
Subject: [R] computing distance in miles or km between 2 street addre
In-Reply-To: <46E09302.3050108@stats.uwo.ca>
References: <XFMail.070906231759.Ted.Harding@manchester.ac.uk>
	<46E09302.3050108@stats.uwo.ca>
Message-ID: <941871A13165C2418EC144ACB212BDB04E1381@dshsmxoly1504g.dshs.wa.lcl>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Duncan Murdoch
> Sent: Thursday, September 06, 2007 4:54 PM
> To: ted.harding at manchester.ac.uk
> Cc: r-help at stat.math.ethz.ch; Philip James Smith
> Subject: Re: [R] computing distance in miles or km between 2 
> street addre
> 
> On 06/09/2007 6:17 PM, (Ted Harding) wrote:
> > On 06-Sep-07 18:42:32, Philip James Smith wrote:
> >> Hi R-ers:
> >>
> >> I need to compute the distance between 2 street addresses in
> >> either km or miles. I do not care if the distance is a "shortest
> >> driving route" or if it is "as the crow flies."
> >>
> >> Does anybody know how to do this? Can it be done in R? I have
> >> thousands of addresses, so I think that Mapquest is out of the
> >> question!
> >>
> >> Please rely to: philipsmith at alumni.albany.edu
> >>
> >> Thank you!
> >> Phil Smith
> > 
> > That's a somewhat ill-posed question! You will for a start
> > need a database of some kind, either of geographical locations
> > (coordinates) of street addresses, or of the metric of the
> > road network with capability to identify the street addresses
> > in the database.
> > 
> > If it's just "as the crow flies", then it can be straightforwardly
> > computed in R, either by Pythogoras (when they are not too far
> > apart) or using a function which takes account of the shape of
> > the Earth,
> > 
> > There are many R packages which have to do with mapping data.
> > Search for "map" through the list of R packages at
> > 
> > http://finzi.psych.upenn.edu/R/library/maptools/html/00Index.html
> > 
> > -- maptools in particular. Also look at (for instance) aspace.
> > 
> > For "shortest driving route" then you need to find the shortest
> > distance through a network. You may find some hints in the
> > package optim -- but there must be some R experts out there
> > on this sort of thing!
> > 
> > However, the primary need is for the database which gives
> > the distance information in one form or another. What were
> > you proposing to use for this? As far as I know, R has no
> > database relevant to street addresses!
> 
> But if the addresses are in the US and include zip codes, a 
> database is 
> available online for free, here:
> 
> http://www.aggdata.com/files/zip_codes.zip
> 
> This includes latitude and longitude.  Zip codes cover a fairly large 
> area so this won't give very accurate information, but it's 
> easy to get.
> 
> Duncan Murdoch
> 

There are a number of free address geocoding sites on the web, some of which even support moderate amounts of batch geocoding for non-commercial purposes.  The following URL is just one of the available sites turned up by Googling "address geocoding free".  Of course, there are also a number of commercial sites.

http://www.batchgeocode.com/

Hope this is helpful,

Dan

Daniel J. Nordlund
Research and Data Analysis
Washington State Department of Social and Health Services
Olympia, WA  98504-5204


From kingsley.oteng at gmail.com  Fri Sep  7 03:19:09 2007
From: kingsley.oteng at gmail.com (kwaj)
Date: Thu, 6 Sep 2007 18:19:09 -0700 (PDT)
Subject: [R] write.csv / string extraction and field limits
Message-ID: <12534347.post@talk.nabble.com>


Hello, 

I have a peculiar problem which I am hoping I can get help on. 

I am using the write.csv command to write a matrix structure to a file,
which I later read in excel. The command works quite well for most strings
and numerical values in the matrix structure. 

However, I have found that when a field in the matrix contains a string of
long length, when the matrix is finally written the file - the field shows
up as "NA". I am assuming write.csv has a limit on the field size? Maybe 16
characters?

Assuming the above is correct - I tried to extract a portion of the string
using the 'substring' command and enter the extracted portion into the field
before using the write.csv command. However I find, that when a string is
extracted, the output from write.csv generates a NA in the file output. 

My questions are:

1) Does write.csv have a limit on the size of strings in the matrix fields?
Is there anyway to place large strings in the field?

2) Is there anyway to make the substring command or an alternative but
similar command, compatible with write.csv? I have tried
'as.character(substring(phrase, min, max)' and that does not seem to work

cheers


-- 
View this message in context: http://www.nabble.com/write.csv---string-extraction-and-field-limits-tf4395535.html#a12534347
Sent from the R help mailing list archive at Nabble.com.


From d.scott at auckland.ac.nz  Fri Sep  7 03:26:27 2007
From: d.scott at auckland.ac.nz (David Scott)
Date: Fri, 7 Sep 2007 13:26:27 +1200 (NZST)
Subject: [R] computing distance in miles or km between 2 street addre
In-Reply-To: <941871A13165C2418EC144ACB212BDB04E1381@dshsmxoly1504g.dshs.wa.lcl>
References: <XFMail.070906231759.Ted.Harding@manchester.ac.uk>
	<46E09302.3050108@stats.uwo.ca>
	<941871A13165C2418EC144ACB212BDB04E1381@dshsmxoly1504g.dshs.wa.lcl>
Message-ID: <Pine.LNX.4.64.0709071319120.8220@stat12.stat.auckland.ac.nz>

On Thu, 6 Sep 2007, Nordlund, Dan (DSHS/RDA) wrote:

>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Duncan Murdoch
>> Sent: Thursday, September 06, 2007 4:54 PM
>> To: ted.harding at manchester.ac.uk
>> Cc: r-help at stat.math.ethz.ch; Philip James Smith
>> Subject: Re: [R] computing distance in miles or km between 2
>> street addre
>>
>> On 06/09/2007 6:17 PM, (Ted Harding) wrote:
>>> On 06-Sep-07 18:42:32, Philip James Smith wrote:
>>>> Hi R-ers:
>>>>
>>>> I need to compute the distance between 2 street addresses in
>>>> either km or miles. I do not care if the distance is a "shortest
>>>> driving route" or if it is "as the crow flies."
>>>>
>>>> Does anybody know how to do this? Can it be done in R? I have
>>>> thousands of addresses, so I think that Mapquest is out of the
>>>> question!
>>>>
>>>> Please rely to: philipsmith at alumni.albany.edu
>>>>
>>>> Thank you!
>>>> Phil Smith
>>>

some other contributions deleted here

>>
>
> There are a number of free address geocoding sites on the web, some of 
> which even support moderate amounts of batch geocoding for 
> non-commercial purposes.  The following URL is just one of the available 
> sites turned up by Googling "address geocoding free".  Of course, there 
> are also a number of commercial sites.
>
> http://www.batchgeocode.com/
>
> Hope this is helpful,
>
> Dan
>

This and similar advice is helpful, but be aware that in thousands of 
addresses your most likely problem is to be malformed addresses. Addresses 
can be misspelt, not keyed in correctly or whatever.

Companies that do geocoding often will do address cleanup. The way one of 
these companies works in New Zealand that I know of is that they run your 
address database through some matching software. Generally it still has 
unknown addresses. Then you can have the option of different levels of 
hand matching of the problem addresses.

David Scott




_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
 		The University of Auckland, PB 92019
 		Auckland 1142,    NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz

Graduate Officer, Department of Statistics
Director of Consulting, Department of Statistics


From andy_liaw at merck.com  Fri Sep  7 03:26:33 2007
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 6 Sep 2007 21:26:33 -0400
Subject: [R] categorical variable coefficients in QSAR  [Broadcast]
In-Reply-To: <47127.200.31.155.67.1188482651.squirrel@abaddon.ula.ve>
References: <47127.200.31.155.67.1188482651.squirrel@abaddon.ula.ve>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04A4B184@usctmx1106.merck.com>

No one seemed to have picked up on this, so I'll take a stab:

You need to read para and meta into R as factors, and if you want the coefficients to match the way you showed, you also need to take care that the factor levels are in the same order as you showed in the coefficient table.

I cut-and-pasted the three columns of data into R separately, like so:

[copy "para" data to the clipboard]
R> para <- factor(scan("clipboard", what=""))
Read 22 items
[copy "meta" data to the clipboard]
R> meta <- factor(scan("clipboard", what=""))
Read 22 items
[copy biological activity to the clipboard]
R> y <- scan("clipboard")
Read 22 items
[copy the column heading of the coefficient table to the clipboard]
R> lvl <- scan("clipboard", what="")
Read 6 items
R> para <- factor(as.character(para), levels=lvl)
R> meta <- factor(as.character(meta), levels=lvl)
R> qsar <- lm(y ~ para + meta)
R> qsar

Call:
lm(formula = y ~ para + meta)

Coefficients:
(Intercept)        paraF       paraCl       paraBr        paraI       paraMe  
     7.8213       0.3400       0.7675       1.0200       1.4287       1.2560  
      metaF       metaCl       metaBr        metaI       metaMe  
    -0.3013       0.2068       0.4340       0.5787       0.4540  

These coefficients match the ones you showed quite closely.

If you don't reorder the levels of the factors, then by default R orders them alphabetically, so that Br becomes the "reference" and all coefficients are differences from Br.

HTH,
Andy


From: rlittle at ula.ve
> Dear list:
> I am interested in the following sort of problem, as is found 
> frequently
> in the field of QSAR. I have biological activity as a 
> function of chemical
> structure, with structure defined in a categorical manner in that the
> SUBSTITUENT is the levels of the POSITION factor. For 
> example, data from
> Kubinyi (http://www.kubinyi.de/dd-12.pdf) for this type of analysis is
> presented as follows:
> factor para:
> H
> F
> Cl
> Br
> I
> Me
> H
> H
> H
> H
> H
> F
> F
> F
> Cl
> Cl
> Cl
> Br
> Br
> Br
> Me
> Me
> factor meta:
> H
> H
> H
> H
> H
> H
> F
> Cl
> Br
> I
> Me
> Cl
> Br
> Me
> Cl
> Br
> Me
> Cl
> Br
> Me
> Me
> Br
> observed biological activity:
> 7.46
> 8.16
> 8.68
> 8.89
> 9.25
> 9.30
> 7.52
> 8.16
> 8.30
> 8.40
> 8.46
> 8.19
> 8.57
> 8.82
> 8.89
> 8.92
> 8.96
> 9.00
> 9.35
> 9.22
> 9.30
> 9.52
> 
> I then think the following analysis should be appropriate
> 
> 
> meta<-factor(scan(file="meta",what="character"))
> para<-factor(scan(file="para",what="character"))
> ba<-scan(file="ba")
> 
> rslt<-lm(ba~meta+para-1)
> 
> What I wish to obtain is a coefficient for each substituent at each
> position, as does Kubinyi:
> 
> H F Cl Br I Me
> meta 0.00 -0.30 0.21 0.43 0.58 0.45
> para 0.00 0.34 0.77 1.02 1.43 1.26
> 
> 
> However, I do not get a coefficient for the Br substituent at the para
> position. I would like to know if there is an error in this 
> formulation.
> The technique is quite well established in the field of medicinal
> chemistry and it is traditional that the binary incidence 
> matrix is formed
> "by hand" as an intermediate step in the analysis, instead of the much
> simpler formulation that I am considering here.
> 
> Thank you for whatever insight you may give.
> 
> Prof. Roy Little
> Dept. Chem.
> Universidad de los Andes
> M?rida, Venezuela
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}


From moreyr at missouri.edu  Fri Sep  7 03:28:58 2007
From: moreyr at missouri.edu (Richard D. Morey)
Date: Thu, 06 Sep 2007 20:28:58 -0500
Subject: [R] contourplot lines, text, and mtext
Message-ID: <46E0A95A.4000208@missouri.edu>

If I have a contourplot (in the lattice package) and I want to add 
straight lines to it, how do I do this?

I see that there are llines() and lsegement() functions for lattice 
plots, but they don't seem to do anything in this case:

library(lattice)
library(KernSmooth)
x=rnorm(10000)
y=x+rnorm(x,0,.5)
a=bkde2D(cbind(x,y),.7)
z=as.vector(a$fhat)
grid=expand.grid(x=a$x1,y=a$x2)
grid$z=z
contourplot(z~x*y,data=grid,region=T,col.regions=gray(seq(1,0,len=255)),colorkey=T,cuts=50,contour=F)
llines(x=c(-5,5),y=c(-5,5))
 > NULL
lsegments(x0=-5,y0=-5,x1=5,y1=5)

I'm just trying to do the equivalent of abline(0,1) on the plot.

ltext(), on the other hand, seems to like to place text in the upper 
left corner of the plot. I suspect that I misunderstand the coordinate 
system that lattice uses for contour plots. Can anyone enlighten me?

Richard


-- 
Richard D. Morey, M.A.
Research Assistant, Perception and Cognition Lab
University of M
issouri-Columbia


From andy_liaw at merck.com  Fri Sep  7 03:51:07 2007
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 6 Sep 2007 21:51:07 -0400
Subject: [R] Variable Importance - Random Forest
In-Reply-To: <DDF691E4FFC4294AB91F304FB06EA4CE01508679@nihcesmlbx10.nih.gov>
References: <DDF691E4FFC4294AB91F304FB06EA4CE01508679@nihcesmlbx10.nih.gov>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04A4B186@usctmx1106.merck.com>

I'm slowly clearing my back-log of r-help messages...

Please see reply inline below.

Andy

> From: Mathe, Ewy (NIH/NCI) [F]
> Hello,
> 
>  
> 
> I am trying to explore the use of random forests for 
> classification and
> am certain about the interpretation of the importance measurements.
> 
>  
> 
> When having the option "importance = T" in the randomForest call, the
> resulting 'importance' element matrix has four columns with the
> following headings:
> 
> 0 - mean raw importance score of variable x for class 0 (where
> importance is the difference between the permutated data error and the
> original test set error)
> 
> 1 - mean raw importance score of variable x for class 1
> 
> MeanDecreaseAccuracy : average lowering of the margin across all cases
> (where margin is the proportion of votes for the true class - the
> maximum proportion of votes for the other classes)
> 
> MeanDecreaseGini : summation of the gini decreases over all 
> trees in the
> forest
> 
>  
> 
> Are these definitions correct?  Why is the raw importance score
> calculated for each class?  Could one just average the raw importance
> scores for class 0 and 1 to get a composite importance score?

The "permutation-based" importance measures are based on OOB data.  For
each tree in the forest, the difference in error rates on the OOB data
with and without permuting the variable of interest is computed.  Call
this d[i] for the i-th tree.  The overall importance measure is
mean(d[i]) / se(d[i]), where se(d[i]) is sd(d[i])/sqrt(ntree) (the
"standard error").  The numbers in the "0" and "1" columns are the
analogs computed separately for the "0" class and "1" class separately.
These are useful, e.g., when "balanced sampling" is used.
  
  
> 
> Now, when having the option "importance = F" in the randomForest call,
> the 'importance' element is now a vector.  What values are those?

That's the MeanDecreaseGini, because they come at nearly zero additional
computation, so we might as well keep them.
 
>  
> 
> Thank you in advance for any input you may have.
> 
>  
> 
> Best,
> 
> Ewy
> 
> 
> Ewy Mathe, Ph. D.
> 
> Laboratory of Human Carcinogenesis
> 
> National Cancer Institute, NIH
> 
> 37 Convent Drive
> 
> Building 37, Room 3068
> 
> Bethesda, MD  20892-4255
> 
> Tel: 301-496-5835
> 
> Fax: 301-496-0497
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}


From andy_liaw at merck.com  Fri Sep  7 03:57:06 2007
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 6 Sep 2007 21:57:06 -0400
Subject: [R] randomForest help
In-Reply-To: <7700822.1187974389433.JavaMail.jennifer.watts@myportal.montana.edu>
References: <7700822.1187974389433.JavaMail.jennifer.watts@myportal.montana.edu>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04A4B188@usctmx1106.merck.com>

What software are you using, exactly?  I'm the maintainer of the
randomForest package, yet I do not know which "manual" you are quoting.

If you are using the randomForest package, the model object can be saved
to a file by save(Rfobject, file="myRFobject.rda").  If you need that to
be in ascii, use ascii=TRUE in save().  You can get it back into R by
using load() or attach().

To "run data down the model", use predict(Rfobject, datatopredict) (see
?predict.randomForest).

What exactly do you want to print to a csv file, the prediction?  See
?write or ?write.table.

Andy

From: Jennifer Dawn Watts
 
> 
> Hello!  As a new R user, I'm sure this will be a silly 
> question for the 
> rest of you.   I've been able to successfully run a forest but yet to 
> figure out proper command lines for the following: 
> 1. saving the forest.  The guide just says isavef=1.  I'm unsure how 
> expand on this to create the command.
> 2. Running new data down the mode.  Again, the guide just states irunf
> 3. Print to file.     I need to be able to export this data to a cvs 
> file, to then incorporate into an Arc shapefile.  The manual 
> just says 
> ntestout.
> 
> Again, I feel like these should be easy steps that I just 
> can't relate 
> to as a beginner.  Any advice would be greatly appreciated. 
> 
> Thanks,
> 
> Jenny
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}


From weigand.stephen at gmail.com  Fri Sep  7 04:47:48 2007
From: weigand.stephen at gmail.com (Stephen Weigand)
Date: Thu, 6 Sep 2007 21:47:48 -0500
Subject: [R] The variables combined in a table from other table and
	combination questions
In-Reply-To: <945698.37134.qm@web73602.mail.tp2.yahoo.com>
References: <945698.37134.qm@web73602.mail.tp2.yahoo.com>
Message-ID: <bc47d3330709061947n15a0a66eq2456ea6edb2bab01@mail.gmail.com>

On 9/5/07, leeznar at yahoo.com.tw <leeznar at yahoo.com.tw> wrote:
> Dear All:
> I need to have some data frame objects.
> First aa object:
>    pH  Formulation  time  Subject
> [1]1.2  F           0       1
> [2]7.4  S           1       2
> [3]    MF           2       3
> [4]                 3       4
> [5]                 n        i
> Then, I need to produce 2*3(pH*formulation) different
> tables.  This table includes column of (pH,
> Formulation, time  S1  S2  S3 ?K..Si) and S1= subject
> 1, S2=subject 2 and so on.  For example: bb1 table
>    pH  Formulation  time  S1  S2  S3?K.Si
> [1]1.2  F           0
> [2]                 1
> [3]                 2
> [4]                 3
> [5]                 n
>
> For example: bb2 table
>    pH  Formulation  time  S1  S2  S3?K.Si
> [1]1.2  S           0
> [2]                 1
> [3]                 2
> [4]                 3
> [5]                 n
>
>
> Moreover, the values of pH and Formulation column are
> the combination questions.  The values of pH and
> Formulation column should be the combinations such as
> (1.2, F), (1.2, S), (1.2, MF), (7.4, F), (7.4, S),
> (7.4, MF)
> I am a beginner level in R and I have no idea how to
> do this. Could any one please help me.  Thanks a
> lot!!!
>
> Best regrards
> Hsin Ya Lee
>

I don't understand exactly what you want but perhaps start with this:

expand.grid(pH = c(1.2, 7.4), Formulation = c("F", "S", "MF"))

Hope this helps,

Stephen

-- 
Rochester, Minn. USA


From tkobayas at indiana.edu  Fri Sep  7 06:40:07 2007
From: tkobayas at indiana.edu (Takatsugu Kobayashi)
Date: Fri, 07 Sep 2007 00:40:07 -0400
Subject: [R] SQL like function?
Message-ID: <46E0D627.2010904@indiana.edu>

Hi RUsers,

I am wonder if I can search observations whose IDs matches any of the 
values in another vector, such as in MySQL. While I am learing MySQL for 
future database management, I appreciate if anyone could give me a hint.

Suppose I have one 5*1 vector containing observation IDs and 
frequencies, and one 3*1 vector containing observation IDs.

observation<-c(1,2,3,4,5)
ID<-c(1,3,4)

Then, I would like to program a code that returns a results showing 
matched observations like

result: TRUE FALSE TRUE TRUE FALSE

I am reading S programming, but I cannot find a way to do this.

Thank you very much.

Taka


From bcarvalh at jhsph.edu  Fri Sep  7 06:46:14 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Fri, 7 Sep 2007 01:46:14 -0300
Subject: [R] SQL like function?
In-Reply-To: <46E0D627.2010904@indiana.edu>
References: <46E0D627.2010904@indiana.edu>
Message-ID: <384B0CBA-0773-4048-A3CB-F122C975BA04@jhsph.edu>

observation %in% ID

b

On Sep 7, 2007, at 1:40 AM, Takatsugu Kobayashi wrote:

> Hi RUsers,
>
> I am wonder if I can search observations whose IDs matches any of the
> values in another vector, such as in MySQL. While I am learing  
> MySQL for
> future database management, I appreciate if anyone could give me a  
> hint.
>
> Suppose I have one 5*1 vector containing observation IDs and
> frequencies, and one 3*1 vector containing observation IDs.
>
> observation<-c(1,2,3,4,5)
> ID<-c(1,3,4)
>
> Then, I would like to program a code that returns a results showing
> matched observations like
>
> result: TRUE FALSE TRUE TRUE FALSE
>
> I am reading S programming, but I cannot find a way to do this.
>
> Thank you very much.
>
> Taka
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.arecibo at gmail.com  Fri Sep  7 06:46:30 2007
From: r.arecibo at gmail.com (Dong-hyun Oh)
Date: Fri, 7 Sep 2007 13:46:30 +0900
Subject: [R] Finding convex hull?
Message-ID: <62F36EC3-C4FD-4AD2-943D-DBAF0E95F5AE@gmail.com>

Dear UseRs,

I would like to know which function is the most efficient in finding  
convex hull of points in 3(or 2)-dimensional case?

Functions for finding convex hull is the following:
convex.hull (tripack), chull (grDevices), in.chull (sgeostat),  
convhulln (geometry), convexhull.xy (spatstat), calcConvexHull  
(PBSmapping).

I also would like to know if there is a function that can be used for  
finding convex hull in multi-dimensional case, that is more than 3- 
dimension.

Thank you in advance.


From FredeA.Togersen at agrsci.dk  Fri Sep  7 07:11:34 2007
From: FredeA.Togersen at agrsci.dk (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Fri, 7 Sep 2007 07:11:34 +0200
Subject: [R] contourplot lines, text, and mtext
References: <46E0A95A.4000208@missouri.edu>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC04E87E3A@DJFPOST01.djf.agrsci.dk>

To learn more about panel functions see the help page for xyplot and especially the panel argument.
 
You can get what you want by 
 

contourplot(z~x*y,data=grid,region=T,
            col.regions=gray(seq(1,0,len=255)),
            colorkey=T,cuts=50,contour=F,
            panel = function(x,y,z,...){
              panel.contourplot(x,y,z,...)
              llines(x=c(-5,5),y=c(-5,5),lwd=5,col="blue")
            })

or

contourplot(z~x*y,data=grid,region=T,
            col.regions=gray(seq(1,0,len=255)),
            colorkey=T,cuts=50,contour=F,
            panel = function(x,y,z,...){
              panel.contourplot(x,y,z,...)
              panel.abline(0,1,lwd=5,col="blue")
            })

 
Med venlig hilsen / Regards

Frede Aakmann T?gersen
Forsker / Scientist


 	
 	 AARHUS UNIVERSITET / UNIVERSITY OF AARHUS	
Det Jordbrugsvidenskabelige Fakultet / Faculty of Agricultural Sciences	
Inst. for Genetik og Bioteknologi / Dept. of Genetics and Biotechnology	
Blichers All? 20, P.O. BOX 50	
DK-8830 Tjele	
 	
Tel:	 +45 8999 1900	
Direct:	 +45 8999 1878	
Mobile:	 +45 	
E-mail:	 FredeA.Togersen at agrsci.dk <mailto:FredeA.Togersen at agrsci.dk> 	
Web:	 www.agrsci.dk <https://djfpost.agrsci.dk/exchweb/bin/redir.asp?URL=http://www.agrsci.dk/> 	
________________________________

Tilmeld dig DJF's nyhedsbrev / Subscribe Faculty of Agricultural Sciences Newsletter <https://djfpost.agrsci.dk/exchweb/bin/redir.asp?URL=http://www.agrsci.dk/user/register?lan=dan-DK> . 

Denne email kan indeholde fortrolig information. Enhver brug eller offentligg?relse af denne email uden skriftlig tilladelse fra DJF er ikke tilladt. Hvis De ikke er den tilt?nkte adressat, bedes De venligst straks underrette DJF samt slette emailen.

This email may contain information that is confidential. Any use or publication of this email without written permission from Faculty of Agricultural Sciences is not allowed. If you are not the intended recipient, please notify Faculty of Agricultural Sciences immediately and delete this email.

 

________________________________

Fra: r-help-bounces at stat.math.ethz.ch p? vegne af Richard D. Morey
Sendt: fr 07-09-2007 03:28
Til: r-help at stat.math.ethz.ch
Emne: [R] contourplot lines, text, and mtext



If I have a contourplot (in the lattice package) and I want to add
straight lines to it, how do I do this?

I see that there are llines() and lsegement() functions for lattice
plots, but they don't seem to do anything in this case:

library(lattice)
library(KernSmooth)
x=rnorm(10000)
y=x+rnorm(x,0,.5)
a=bkde2D(cbind(x,y),.7)
z=as.vector(a$fhat)
grid=expand.grid(x=a$x1,y=a$x2)
grid$z=z
contourplot(z~x*y,data=grid,region=T,col.regions=gray(seq(1,0,len=255)),colorkey=T,cuts=50,contour=F)
llines(x=c(-5,5),y=c(-5,5))
 > NULL
lsegments(x0=-5,y0=-5,x1=5,y1=5)

I'm just trying to do the equivalent of abline(0,1) on the plot.

ltext(), on the other hand, seems to like to place text in the upper
left corner of the plot. I suspect that I misunderstand the coordinate
system that lattice uses for contour plots. Can anyone enlighten me?

Richard


--
Richard D. Morey, M.A.
Research Assistant, Perception and Cognition Lab
University of M
issouri-Columbia

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From m_olshansky at yahoo.com  Fri Sep  7 08:18:00 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Thu, 6 Sep 2007 23:18:00 -0700 (PDT)
Subject: [R] SQL like function?
In-Reply-To: <46E0D627.2010904@indiana.edu>
Message-ID: <944253.46532.qm@web32208.mail.mud.yahoo.com>

observation %in% ID

--- Takatsugu Kobayashi <tkobayas at indiana.edu> wrote:

> Hi RUsers,
> 
> I am wonder if I can search observations whose IDs
> matches any of the 
> values in another vector, such as in MySQL. While I
> am learing MySQL for 
> future database management, I appreciate if anyone
> could give me a hint.
> 
> Suppose I have one 5*1 vector containing observation
> IDs and 
> frequencies, and one 3*1 vector containing
> observation IDs.
> 
> observation<-c(1,2,3,4,5)
> ID<-c(1,3,4)
> 
> Then, I would like to program a code that returns a
> results showing 
> matched observations like
> 
> result: TRUE FALSE TRUE TRUE FALSE
> 
> I am reading S programming, but I cannot find a way
> to do this.
> 
> Thank you very much.
> 
> Taka
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From Roger.Bivand at nhh.no  Fri Sep  7 09:29:23 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 7 Sep 2007 09:29:23 +0200 (CEST)
Subject: [R] write geotiff with projection - RGDAL package
In-Reply-To: <BAY104-W285AEE6410EFCD6C7DD71AC3C40@phx.gbl>
References: <BAY104-W285AEE6410EFCD6C7DD71AC3C40@phx.gbl>
Message-ID: <Pine.LNX.4.64.0709070921340.16086@reclus.nhh.no>

On Thu, 6 Sep 2007, Monica Pisica wrote:

>
> Hi,
>
> Doing more search i've discovered package RGDAL that can write a geotiff 
> file with projection. I saved a geotiff file in UTM projection and if i 
> read the file back in R and check the projection seems that everything 
> is OK. But if i load the file in ArcGIS (ESRI product) i get the warning 
> that the file is missing spatial reference so it cannot be projected, 
> but it is displayed correctly. I guess somewhere i am doing a mistake 
> when i define the projection in R. My code follows:
>
> data.grid <- read.csv(x, header=TRUE)
> gridded(data.grid) = ~East.m.+North.m.
> proj4string(data.grid) = CRS("+proj=tmerc +lat_0=0.00000000000 +lon_0=-81.00000000000 +k=0.99960000 +x_0=500000.000000 +y_0=0.0000000 +ellps=GRS80 +units=m")
> tr <- "e:\\JELA_veg\\test_gtiff\\test.tif"
> writeGDAL(data.grid["class.pca"], tr)
>
> mg3 <- readGDAL(tr)
> proj4string(mg3)
> [1] " +proj=utm +zone=17 +ellps=GRS80 +units=m +no_defs"
>
> I will really appreciate if anybody can point me in the right dirrection.

In my previous reply, I suggested that you visit:

http://www.gdal.org/frmt_gtiff.html

There you will find that for ESRI products, you may need to set
options="TFW=YES" at least, because ESRI products do not honour the 
projection information already encoded inside the GTiff file. The 
information is there, it is just that ESRI products only look for it in 
places they have thought of, not in the proper places. If necessary, 
showWKT() can make a *.prj file. Otherwise just override ESRI.

Roger

>
> Thanks,
>
> Monica
>
>
> _________________________________________________________________
> News, entertainment and everything you care about at Live.com. Get it now!
> http://www.live.com/getstarted.aspx

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From reilly at stat.auckland.ac.nz  Fri Sep  7 10:02:31 2007
From: reilly at stat.auckland.ac.nz (James Reilly)
Date: Fri, 07 Sep 2007 20:02:31 +1200
Subject: [R] Survey package
In-Reply-To: <99137.80849.qm@web38605.mail.mud.yahoo.com>
References: <99137.80849.qm@web38605.mail.mud.yahoo.com>
Message-ID: <46E10597.90107@stat.auckland.ac.nz>


On 7/9/07 12:36 AM, eugen pircalabelu wrote:
 >   I'm trying to use the Survey package for a stratified sample which 
has 4 criteria on which the stratification is based. I would like to get 
the corrected weights and for every element i get  a weight of 1
 >
 >   E.g: tipping
 >
 >    design <- svydesign (id=~1, strata= ~regiune + size_loc + 
age_rec_hhh + size_hh, data= tabel)
 >    and then      weights(design)
 >
 >   gives me:  1,1,1,1,1,1,1,1,1,1,1,........... for each element

The weights are all 1 because you haven't told R how they should be 
calculated. If the sampling weights should be constant within strata, 
you can simply specify the population figures for each stratum in 
svydesign's fpc argument and it will calculate the weights for you. 
Various techniques for adjusting the weights are also supported; see 
http://faculty.washington.edu/tlumley/survey/example-poststrat.html

James
-- 
James Reilly
Department of Statistics, University of Auckland
Private Bag 92019, Auckland, New Zealand


From olivier.martin at avignon.inra.fr  Fri Sep  7 11:08:39 2007
From: olivier.martin at avignon.inra.fr (Olivier MARTIN)
Date: Fri, 07 Sep 2007 11:08:39 +0200
Subject: [R] negative value for AIC and BIC
Message-ID: <46E11517.1030203@avignon.inra.fr>

Hi all,


I obtained negative values for AIC and BIC criteria for a particular 
model that I have
developped... 

I don't remember to have negative values for these crietria for others 
applications, so I am a
little suprised... Could anyone tell me if something is wrong or his 
conclusion concerning my model?

Best regards,
Olivier.


From hkahra at gmail.com  Fri Sep  7 11:32:03 2007
From: hkahra at gmail.com (Hannu Kahra)
Date: Fri, 7 Sep 2007 12:32:03 +0300
Subject: [R] negative value for AIC and BIC
In-Reply-To: <46E11517.1030203@avignon.inra.fr>
References: <46E11517.1030203@avignon.inra.fr>
Message-ID: <3d35a2ca0709070232m4d3f6059jdcbc297592eff141@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070907/99cbd505/attachment.pl 

From j.van_den_hoff at fzd.de  Fri Sep  7 11:44:16 2007
From: j.van_den_hoff at fzd.de (Joerg van den Hoff)
Date: Fri, 7 Sep 2007 11:44:16 +0200
Subject: [R] 'singular gradient matrix? when using nls() and how to make
	the program skip nls( ) and run on
In-Reply-To: <548b8d440709051643p69659404ude641b631b9eb25c@mail.gmail.com>
References: <548b8d440709051643p69659404ude641b631b9eb25c@mail.gmail.com>
Message-ID: <20070907094416.GB25172@marco.fz-rossendorf.de>

On Wed, Sep 05, 2007 at 04:43:19PM -0700, Yuchen Luo wrote:
> Dear friends.
> 
> I use nls() and encounter the following puzzling problem:
> 
> 
> 
> I have a function f(a,b,c,x), I have a data vector of x and a vectory  y of
> realized value of f.
> 
> 
> 
> Case1
> 
> I tried to estimate  c with (a=0.3, b=0.5) fixed:
> 
> nls(y~f(a,b,c,x), control=list(maxiter = 100000, minFactor=0.5
> ^2048),start=list(c=0.5)).
> 
> The error message is: "number of iterations exceeded maximum of 100000"
> 
> 
> 
> Case2
> 
> I then think maybe the value of a and be are not reasonable. So, I let nls()
> estimate (a,b,c) altogether:
> 
> nls(y~f(a,b,c,x), control=list(maxiter = 100000, minFactor=0.5
> ^2048),start=list(a=0.3,b=0.5,c=0.5)).
> 
> The error message is:
> 
> "singular gradient matrix at initial parameter estimates".
> 
> 
> 
> This is what puzzles me, if the initial parameter of (a=0.3,b=0.5,c=0.5) can
> create 'singular gradient matrix', then why doesn't this 'singular gradient
> matrix' appear in Case1?
> 
> 
> 
> I have tried to change the initial value of (a,b,c) around but the problem
> persists. I am wondering if there is a way out.
> 
> 
> 
> My another question is, I need to run 220 of  nls() in my program with
> different y and x. When one of the nls() encounter a problem, the whole
> program stops.  In my case, the 3rd nls() runs into a problem.  I would
> still need the program to run the remaining 217 nls( )! Is there a way to
> make the program skip the problematic nls() and complete the ramaining
> nls()'s?

?try

> 
> 
> 
> Your help will be highly appreciated!
> 
> Yuchen Luo
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ymoisan at groupesm.com  Fri Sep  7 13:04:51 2007
From: ymoisan at groupesm.com (Yves Moisan)
Date: Fri, 7 Sep 2007 04:04:51 -0700 (PDT)
Subject: [R] text in boxplots
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBBB4068@LP-EXCHVS07.CO.IHC.COM>
References: <12530892.post@talk.nabble.com>
	<07E228A5BE53C24CAD490193A7381BBBBB4068@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <12553104.post@talk.nabble.com>


Hi Greg,

Actually, I'm using the scatterplot function in the car namespace.  My
understanding is that the scatterplot is turned into a boxplot when the x
variable is a factor, but I can't see that in the code of the function. 
I've successfully modified the function to output regression stats (R^^2,
etc.) with the method 'text', but I can't seem to get any text printed when
the result of a call to scatterplot is a bunch of boxplots.  

I don't know how boxplots end up being generated (I like it though) in a
call to car:scatterplot.  The same data in ggobi would show the "standard"
scatterplot with data aligned vertically in lines along the values of the x
(factor) variable but car:scatterplot draws nice boxes around the data as a
bonus.  I guess I'll need to follow with some debugging tool.  I find it odd
that mtext works though.  Or maybe some graphics parameter is set such that
text doesn't show.

Thanx Greg.
-- 
View this message in context: http://www.nabble.com/text-in-boxplots-tf4394528.html#a12553104
Sent from the R help mailing list archive at Nabble.com.


From eugen_pircalabelu at yahoo.com  Fri Sep  7 13:42:36 2007
From: eugen_pircalabelu at yahoo.com (eugen pircalabelu)
Date: Fri, 7 Sep 2007 04:42:36 -0700 (PDT)
Subject: [R] R survey package again
Message-ID: <681245.36636.qm@web38612.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070907/5b67f1de/attachment.pl 

From ggrothendieck at gmail.com  Fri Sep  7 13:47:15 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 7 Sep 2007 07:47:15 -0400
Subject: [R] SQL like function?
In-Reply-To: <46E0D627.2010904@indiana.edu>
References: <46E0D627.2010904@indiana.edu>
Message-ID: <971536df0709070447x26b8146fyf5a88d051a3bb798@mail.gmail.com>

Others have already pointed out %in% but regarding your comment about
SQL, you can use SQL to manipulate R data frames using the sqldf package
which provides an interface to lower level RSQLite (and RMySQL in the future)
routines.  The following examples use SQLite underneath:

DF <- data.frame(observation = c(1,2,3,4,5))
ID <- data.frame(ID = c(1, 3, 4))

library(sqldf)
sqldf("select observation, observation in (select * from ID) `ID?` from DF")

# or

sqldf("select observation, observation in (1, 3, 4) `ID?` from DF")

See home page at:

http://sqldf.googlecode.com


On 9/7/07, Takatsugu Kobayashi <tkobayas at indiana.edu> wrote:
> Hi RUsers,
>
> I am wonder if I can search observations whose IDs matches any of the
> values in another vector, such as in MySQL. While I am learing MySQL for
> future database management, I appreciate if anyone could give me a hint.
>
> Suppose I have one 5*1 vector containing observation IDs and
> frequencies, and one 3*1 vector containing observation IDs.
>
> observation<-c(1,2,3,4,5)
> ID<-c(1,3,4)
>
> Then, I would like to program a code that returns a results showing
> matched observations like
>
> result: TRUE FALSE TRUE TRUE FALSE
>
> I am reading S programming, but I cannot find a way to do this.
>
> Thank you very much.
>
> Taka
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From andy_liaw at merck.com  Fri Sep  7 13:58:15 2007
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 7 Sep 2007 07:58:15 -0400
Subject: [R] Finding convex hull?  [Broadcast]
In-Reply-To: <62F36EC3-C4FD-4AD2-943D-DBAF0E95F5AE@gmail.com>
References: <62F36EC3-C4FD-4AD2-943D-DBAF0E95F5AE@gmail.com>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04A4B1BC@usctmx1106.merck.com>

From: Dong-hyun Oh
> Dear UseRs,
> 
> I would like to know which function is the most efficient in finding  
> convex hull of points in 3(or 2)-dimensional case?
> 
> Functions for finding convex hull is the following:
> convex.hull (tripack), chull (grDevices), in.chull (sgeostat),  
> convhulln (geometry), convexhull.xy (spatstat), calcConvexHull  
> (PBSmapping).
> 
> I also would like to know if there is a function that can be 
> used for  
> finding convex hull in multi-dimensional case, that is more than 3- 
> dimension.

If you had look a bit more carefully, you should have seen that 
convhulln (geometry) will handle more than 3 dimensions.

Andy

> Thank you in advance.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}


From jsorkin at grecc.umaryland.edu  Fri Sep  7 14:16:40 2007
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 07 Sep 2007 08:16:40 -0400
Subject: [R] negative value for AIC and BIC
In-Reply-To: <3d35a2ca0709070232m4d3f6059jdcbc297592eff141@mail.gmail.com>
References: <46E11517.1030203@avignon.inra.fr>
	<3d35a2ca0709070232m4d3f6059jdcbc297592eff141@mail.gmail.com>
Message-ID: <46E108E8020000CB00015CA5@MEDICINE.umaryland.edu>

Oliver,
I am attaching an HTML document in which I have plotted -2Log(x) vs. x. If you examine the plot you will see that -2Log(x) can be negative. Since -2Log(x) is part of AIC and BIC, AIC and BIC can be negative.
John

John Sorkin M.D., Ph.D.
Chief, Biostatistics and Informatics
Baltimore VA Medical Center GRECC,
University of Maryland School of Medicine Claude D. Pepper OAIC,
University of Maryland Clinical Nutrition Research Unit, and
Baltimore VA Center Stroke of Excellence

University of Maryland School of Medicine
Division of Gerontology
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524

(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)
jsorkin at grecc.umaryland.edu

>>> "Hannu Kahra" <hkahra at gmail.com> 09/07/07 4:32 AM >>>
Olivier,

type ?AIC and have a look at the description

Description:

     Generic function calculating the Akaike information criterion for
     one or several fitted model objects for which a log-likelihood
     value can be obtained, according to the formula -2*log-likelihood
     + k*npar, where npar represents the number of parameters in the
     fitted model, and k = 2 for the usual AIC, or k = log(n) (n the
     number of observations) for the so-called BIC or SBC (Schwarz's
     Bayesian criterion).

AIC = -2*log-likelihood + k*npar can be negative as SBC, too.

Hannu

On 9/7/07, Olivier MARTIN <olivier.martin at avignon.inra.fr> wrote:
>
> Hi all,
>
>
> I obtained negative values for AIC and BIC criteria for a particular
> model that I have
> developped...
>
> I don't remember to have negative values for these crietria for others
> applications, so I am a
> little suprised... Could anyone tell me if something is wrong or his
> conclusion concerning my model?
>
> Best regards,
> Olivier.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code.

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: -2Log.html
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070907/c0a62e6b/attachment.pl 

From pisicandru at hotmail.com  Fri Sep  7 15:25:02 2007
From: pisicandru at hotmail.com (Monica Pisica)
Date: Fri, 7 Sep 2007 13:25:02 +0000
Subject: [R] computing distance in miles or km between 2 street
Message-ID: <BAY104-W267E20DD547947BDF342CFC3C50@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070907/82a05b6f/attachment.pl 

From cnissen at AkoyaInc.com  Fri Sep  7 15:34:30 2007
From: cnissen at AkoyaInc.com (Cory Nissen)
Date: Fri, 7 Sep 2007 08:34:30 -0500
Subject: [R] FW: variable format
References: <6EBEA5B72E9B02428F2DD71D9DBC6EDF31939D@AKOYASRV01.akoyainc.local>
Message-ID: <6EBEA5B72E9B02428F2DD71D9DBC6EDF31939E@AKOYASRV01.akoyainc.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070907/25d028d1/attachment.pl 

From Ulrich.Halekoh at agrsci.dk  Fri Sep  7 15:56:59 2007
From: Ulrich.Halekoh at agrsci.dk (Ulrich Halekoh)
Date: Fri, 7 Sep 2007 15:56:59 +0200
Subject: [R] Running geeglm unstructured corstr
Message-ID: <EA09C4B2B0F16E44B8F3311629493C0D01E3DBBE@DJFPOST01.djf.agrsci.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070907/0ff6317a/attachment.pl 

From darteta001 at ikasle.ehu.es  Fri Sep  7 16:02:24 2007
From: darteta001 at ikasle.ehu.es (darteta001 at ikasle.ehu.es)
Date: Fri, 7 Sep 2007 16:02:24 +0200 (CEST)
Subject: [R] help on replacing values
In-Reply-To: <mailman.5222.1189161167.2058.r-help@stat.math.ethz.ch>
References: <mailman.5222.1189161167.2058.r-help@stat.math.ethz.ch>
Message-ID: <4384166937darteta001@ikasle.ehu.es>

Dear List,

I have a newbie question. I have read in a data.frame as follows:

> data = read.table("table.txt", header = T)
> data
  X1 X2 X3 X4
A AB AC AB AC
B AB AC AA AB
C AA AB AA AB
D AA AB AB AC
E AB AA AA AB
F AB AA AB AC
B AB AC AB AA

I would like to replace AA values by BB in column X2. I have tried 
using replace() with no success, although I am not sure this is the 
right function. This is the code I have used:

data$X2 <- replace(data$X2, data$X2 =="AA","BB")
Warning message:
invalid factor level, NAs generated in: `[<-.factor`(`*tmp*`, list, 
value = "BB")

What is wrong with the code? How can I get this done? how about 
changing AA values by BB in all 4 columns simultaneously? Actually 
this is a small example dataframe, the real one would have about 1000 
columns.

Extendind this, I found a similar thread dated July 2006 that used 
replace() on iris dataset, but I have tried reproducing it obtaining 
same warning message

 iris$Species <- replace(iris$Species, iris$Species 
== "setosa","NewName")
Warning message:
invalid factor level, NAs generated in: `[<-.factor`(`*tmp*`, list, 
value = "NewName")

Thanks in advance your help,

David


From ggrothendieck at gmail.com  Fri Sep  7 16:07:44 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 7 Sep 2007 10:07:44 -0400
Subject: [R] variable format
In-Reply-To: <6EBEA5B72E9B02428F2DD71D9DBC6EDF31939D@AKOYASRV01.akoyainc.local>
References: <6EBEA5B72E9B02428F2DD71D9DBC6EDF31939D@AKOYASRV01.akoyainc.local>
Message-ID: <971536df0709070707qa34eb46iaed39fcc07ed69c7@mail.gmail.com>

A matrix is for situations where every element is of the same class
but your columns have different classes so use a data frame:

DF <- data.frame(a = 11:15, b = letters[1:5], stringsAsFactors = FALSE)
subset(DF, a %in% 11:13)
subset(DF, a %in% c(0, 11:13)) # same

Suggest you review the Introduction to R manual and look at ?data.frame,
?subset and ?"%in%"

On 9/4/07, Cory Nissen <cnissen at akoyainc.com> wrote:
> Okay, I want to do something similar to SAS proc format.
>
> I usually do this...
>
> a <- NULL
> a$divisionOld <- c(1,2,3,4,5)
> divisionTable <- matrix(c(1, "New England",
>                          2, "Middle Atlantic",
>                          3, "East North Central",
>                          4, "West North Central",
>                          5, "South Atlantic"),
>                        ncol=2, byrow=T)
> a$divisionNew[match(a$divisionOld, divisionTable[,1])] <- divisionTable[,2]
>
> But how do I handle the case where...
> a$divisionOld <- c(0,1,2,3,4,5)   #no format available for 0, this throws an error.
> OR
> divisionTable <- matrix(c(1, "New England",
>                          2, "Middle Atlantic",
>                          3, "East North Central",
>                          4, "West North Central",
>                          5, "South Atlantic",
>                          6, "East South Central",
>                          7, "West South Central",
>                          8, "Mountain",
>                          9, "Pacific"),
>                        ncol=2, byrow=T)
> There are extra formats available... this throws a warning.
>
> Thanks
>
> Cory
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Fri Sep  7 16:09:39 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 7 Sep 2007 10:09:39 -0400
Subject: [R] help on replacing values
In-Reply-To: <4384166937darteta001@ikasle.ehu.es>
References: <mailman.5222.1189161167.2058.r-help@stat.math.ethz.ch>
	<4384166937darteta001@ikasle.ehu.es>
Message-ID: <971536df0709070709x639a613dt74f42c3a35998143@mail.gmail.com>

Your columns are factors, not character strings.  Use as.is = TRUE as
an argument to read.table.   Also its a bit dangerous to use T although
not wrong.  Its safer to use TRUE.

On 9/7/07, darteta001 at ikasle.ehu.es <darteta001 at ikasle.ehu.es> wrote:
> Dear List,
>
> I have a newbie question. I have read in a data.frame as follows:
>
> > data = read.table("table.txt", header = T)
> > data
>  X1 X2 X3 X4
> A AB AC AB AC
> B AB AC AA AB
> C AA AB AA AB
> D AA AB AB AC
> E AB AA AA AB
> F AB AA AB AC
> B AB AC AB AA
>
> I would like to replace AA values by BB in column X2. I have tried
> using replace() with no success, although I am not sure this is the
> right function. This is the code I have used:
>
> data$X2 <- replace(data$X2, data$X2 =="AA","BB")
> Warning message:
> invalid factor level, NAs generated in: `[<-.factor`(`*tmp*`, list,
> value = "BB")
>
> What is wrong with the code? How can I get this done? how about
> changing AA values by BB in all 4 columns simultaneously? Actually
> this is a small example dataframe, the real one would have about 1000
> columns.
>
> Extendind this, I found a similar thread dated July 2006 that used
> replace() on iris dataset, but I have tried reproducing it obtaining
> same warning message
>
>  iris$Species <- replace(iris$Species, iris$Species
> == "setosa","NewName")
> Warning message:
> invalid factor level, NAs generated in: `[<-.factor`(`*tmp*`, list,
> value = "NewName")
>
> Thanks in advance your help,
>
> David
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From schmidb at ibe.med.uni-muenchen.de  Fri Sep  7 16:35:56 2007
From: schmidb at ibe.med.uni-muenchen.de (Markus Schmidberger)
Date: Fri, 07 Sep 2007 16:35:56 +0200
Subject: [R] ploting missing data
Message-ID: <46E161CC.4000405@ibe.med.uni-muenchen.de>

Hello,

I have this kind of dataframe and have to plot it.

data <- data.frame(sw= c(1,2,3,4,5,6,7,8,9,10,11,12,15),
    zehn =         
c(33.44,20.67,18.20,18.19,17.89,19.65,20.05,19.87,20.55,22.53,NA,NA,NA),
     zwanzig =     
c(61.42,NA,26.60,23.28,NA,24.90,24.47,24.53,26.41,28.26,NA,29.80,35.49),
     fuenfzig =    
c(162.51,66.08,49.55,43.40,NA,37.77,35.53,36.46,37.25,37.66,NA,42.29,47.80) 
)

The plot should have lines:
lines(fuenfzig~sw, data=data)
lines(zwanzig~sw, data=data)

But now I have holes in my lines for the missing values (NA). How to 
plot the lines without the holes?
The missing values should be interpolated or the left and right point 
directly connected. The function approx interpolates the whole dataset. 
Thats not my goal!
Is there no plotting function to do this directly?

Best
Markus

-- 
Dipl.-Tech. Math. Markus Schmidberger

Ludwig-Maximilians-Universit?t M?nchen
IBE - Institut f?r medizinische Informationsverarbeitung,
Biometrie und Epidemiologie
Marchioninistr. 15, D-81377 Muenchen
URL: http://ibe.web.med.uni-muenchen.de 
Mail: Markus.Schmidberger [at] ibe.med.uni-muenchen.de


From phhs80 at gmail.com  Fri Sep  7 16:39:35 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Fri, 7 Sep 2007 15:39:35 +0100
Subject: [R] Automatic detachment of dependent packages
Message-ID: <6ade6f6c0709070739m5e652f5bjaca6fa2712dee4d@mail.gmail.com>

Dear All,

When one loads certain packages, some other dependent packages are
loaded as well. Is there some way of detaching them automatically when
one detaches the first package loaded? For instance,

> library(sqldf)
Loading required package: RSQLite
Loading required package: DBI
Loading required package: gsubfn
Loading required package: proto

but

> detach(package:sqldf)
>
> search()
 [1] ".GlobalEnv"        "package:gsubfn"    "package:proto"
 [4] "package:RSQLite"   "package:DBI"       "package:stats"
 [7] "package:graphics"  "package:grDevices" "package:utils"
[10] "package:datasets"  "package:methods"   "Autoloads"
[13] "package:base"

The packages

RSQLite
DBI
gsubfn
proto

were not detached.

Thanks in advance,

Paul


From P.Dalgaard at biostat.ku.dk  Fri Sep  7 16:43:10 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 07 Sep 2007 16:43:10 +0200
Subject: [R] ploting missing data
In-Reply-To: <46E161CC.4000405@ibe.med.uni-muenchen.de>
References: <46E161CC.4000405@ibe.med.uni-muenchen.de>
Message-ID: <46E1637E.4090405@biostat.ku.dk>

Markus Schmidberger wrote:
> Hello,
>
> I have this kind of dataframe and have to plot it.
>
> data <- data.frame(sw= c(1,2,3,4,5,6,7,8,9,10,11,12,15),
>     zehn =         
> c(33.44,20.67,18.20,18.19,17.89,19.65,20.05,19.87,20.55,22.53,NA,NA,NA),
>      zwanzig =     
> c(61.42,NA,26.60,23.28,NA,24.90,24.47,24.53,26.41,28.26,NA,29.80,35.49),
>      fuenfzig =    
> c(162.51,66.08,49.55,43.40,NA,37.77,35.53,36.46,37.25,37.66,NA,42.29,47.80) 
> )
>
> The plot should have lines:
> lines(fuenfzig~sw, data=data)
> lines(zwanzig~sw, data=data)
>
> But now I have holes in my lines for the missing values (NA). How to 
> plot the lines without the holes?
> The missing values should be interpolated or the left and right point 
> directly connected. The function approx interpolates the whole dataset. 
> Thats not my goal!
> Is there no plotting function to do this directly?
>
>   
Just get rid of the NAs:

lines(fuenfzig~sw, data=data, subset=!is.na(fuenfzig))

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Greg.Snow at intermountainmail.org  Fri Sep  7 17:00:57 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 7 Sep 2007 09:00:57 -0600
Subject: [R] text in boxplots
In-Reply-To: <12553104.post@talk.nabble.com>
References: <12530892.post@talk.nabble.com><07E228A5BE53C24CAD490193A7381BBBBB4068@LP-EXCHVS07.CO.IHC.COM>
	<12553104.post@talk.nabble.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBB412A@LP-EXCHVS07.CO.IHC.COM>

The posting guide (a link at the bottom of every e-mail from the list)
suggests including a small example of what you are trying to do.
Without an example, we have to guess at what you are trying to do.

I am still guessing since you still did not include an example.  It
appears that part of the problem may be that the scatterplot function
from the car package does not leave the user coordinate system in a
state that matches intuitively with the data.  Your call to text is
probably placing the text outside of the plotting region where it is not
visible (possibly even in someone elses cubicle/office).  The mtext
function is not affected as much by this since it uses a different
coordinate system (based on the margins rather than the user
coordinates).

To place text on the plot, you need to find the cooresponding
coordinates.  There are a few different ways to do this:

1. use par('usr') to find out what the current user coordinates are and
compute your coordinates based on that.
2. use par(usr=c(...)) to set the user coordinates to match where you
want to plot.
3. use the locator function to interactively choose the locations and
use the resulting coordinates.
4. use the cnvrt.coords function from the TeachingDemos package to
convert from figure or device coordinates to the current user coordinate
system.
5. contact the author of the function and ask him to set the user
coordinates to something more intuitive before exiting and wait for the
change.

Look at the help for par for more information, specifically look at the
'usr' entry and possibly the 'xpd' entry if you want to add text to the
marginal boxplots.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Yves Moisan
> Sent: Friday, September 07, 2007 5:05 AM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] text in boxplots
> 
> 
> Hi Greg,
> 
> Actually, I'm using the scatterplot function in the car 
> namespace.  My understanding is that the scatterplot is 
> turned into a boxplot when the x variable is a factor, but I 
> can't see that in the code of the function. 
> I've successfully modified the function to output regression 
> stats (R^^2,
> etc.) with the method 'text', but I can't seem to get any 
> text printed when the result of a call to scatterplot is a 
> bunch of boxplots.  
> 
> I don't know how boxplots end up being generated (I like it 
> though) in a call to car:scatterplot.  The same data in ggobi 
> would show the "standard"
> scatterplot with data aligned vertically in lines along the 
> values of the x
> (factor) variable but car:scatterplot draws nice boxes around 
> the data as a bonus.  I guess I'll need to follow with some 
> debugging tool.  I find it odd that mtext works though.  Or 
> maybe some graphics parameter is set such that text doesn't show.
> 
> Thanx Greg.
> --
> View this message in context: 
> http://www.nabble.com/text-in-boxplots-tf4394528.html#a12553104
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Greg.Snow at intermountainmail.org  Fri Sep  7 17:06:29 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 7 Sep 2007 09:06:29 -0600
Subject: [R] text in boxplots
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBBB412A@LP-EXCHVS07.CO.IHC.COM>
References: <12530892.post@talk.nabble.com><07E228A5BE53C24CAD490193A7381BBBBB4068@LP-EXCHVS07.CO.IHC.COM><12553104.post@talk.nabble.com>
	<07E228A5BE53C24CAD490193A7381BBBBB412A@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBB412D@LP-EXCHVS07.CO.IHC.COM>


Looking at the help for scatterplot, it looks like there is a 6th option
(which is probably the preferred method):

6. set the reset.par argument to FALSE in calling scatterplot as it
states in the documentation for scatterplot.  (still look at the help on
'xpd' argment to par if you want to add text to the margins).

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Greg Snow
> Sent: Friday, September 07, 2007 9:01 AM
> To: Yves Moisan; r-help at stat.math.ethz.ch
> Subject: Re: [R] text in boxplots
> 
> The posting guide (a link at the bottom of every e-mail from 
> the list) suggests including a small example of what you are 
> trying to do.
> Without an example, we have to guess at what you are trying to do.
> 
> I am still guessing since you still did not include an 
> example.  It appears that part of the problem may be that the 
> scatterplot function from the car package does not leave the 
> user coordinate system in a state that matches intuitively 
> with the data.  Your call to text is probably placing the 
> text outside of the plotting region where it is not visible 
> (possibly even in someone elses cubicle/office).  The mtext 
> function is not affected as much by this since it uses a 
> different coordinate system (based on the margins rather than 
> the user coordinates).
> 
> To place text on the plot, you need to find the cooresponding 
> coordinates.  There are a few different ways to do this:
> 
> 1. use par('usr') to find out what the current user 
> coordinates are and compute your coordinates based on that.
> 2. use par(usr=c(...)) to set the user coordinates to match 
> where you want to plot.
> 3. use the locator function to interactively choose the 
> locations and use the resulting coordinates.
> 4. use the cnvrt.coords function from the TeachingDemos 
> package to convert from figure or device coordinates to the 
> current user coordinate system.
> 5. contact the author of the function and ask him to set the 
> user coordinates to something more intuitive before exiting 
> and wait for the change.
> 
> Look at the help for par for more information, specifically 
> look at the 'usr' entry and possibly the 'xpd' entry if you 
> want to add text to the marginal boxplots.
> 
> --
> Gregory (Greg) L. Snow Ph.D.
> Statistical Data Center
> Intermountain Healthcare
> greg.snow at intermountainmail.org
> (801) 408-8111
>  
>  
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Yves Moisan
> > Sent: Friday, September 07, 2007 5:05 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: Re: [R] text in boxplots
> > 
> > 
> > Hi Greg,
> > 
> > Actually, I'm using the scatterplot function in the car 
> namespace.  My 
> > understanding is that the scatterplot is turned into a boxplot when 
> > the x variable is a factor, but I can't see that in the code of the 
> > function.
> > I've successfully modified the function to output regression stats 
> > (R^^2,
> > etc.) with the method 'text', but I can't seem to get any 
> text printed 
> > when the result of a call to scatterplot is a bunch of boxplots.
> > 
> > I don't know how boxplots end up being generated (I like it
> > though) in a call to car:scatterplot.  The same data in ggobi would 
> > show the "standard"
> > scatterplot with data aligned vertically in lines along the 
> values of 
> > the x
> > (factor) variable but car:scatterplot draws nice boxes 
> around the data 
> > as a bonus.  I guess I'll need to follow with some 
> debugging tool.  I 
> > find it odd that mtext works though.  Or maybe some 
> graphics parameter 
> > is set such that text doesn't show.
> > 
> > Thanx Greg.
> > --
> > View this message in context: 
> > http://www.nabble.com/text-in-boxplots-tf4394528.html#a12553104
> > Sent from the R help mailing list archive at Nabble.com.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From darteta001 at ikasle.ehu.es  Fri Sep  7 17:10:07 2007
From: darteta001 at ikasle.ehu.es (darteta001 at ikasle.ehu.es)
Date: Fri, 7 Sep 2007 17:10:07 +0200 (CEST)
Subject: [R] help on replacing values
In-Reply-To: <971536df0709070709x639a613dt74f42c3a35998143@mail.gmail.com>
References: <971536df0709070709x639a613dt74f42c3a35998143@mail.gmail.com>
Message-ID: <5244233395darteta001@ikasle.ehu.es>

Thanks a lot Gabor, that was very helpful. All sorted now!

Best

David

> Your columns are factors, not character strings.  Use as.is = TRUE as
> an argument to read.table.   Also its a bit dangerous to use T 
although
> not wrong.  Its safer to use TRUE.
> 
> On 9/7/07, darteta001 at ikasle.ehu.es <darteta001 at ikasle.ehu.es> wrote:
> > Dear List,
> >
> > I have a newbie question. I have read in a data.frame as follows:
> >
> > > data = read.table("table.txt", header = T)
> > > data
> >  X1 X2 X3 X4
> > A AB AC AB AC
> > B AB AC AA AB
> > C AA AB AA AB
> > D AA AB AB AC
> > E AB AA AA AB
> > F AB AA AB AC
> > B AB AC AB AA
> >
> > I would like to replace AA values by BB in column X2. I have tried
> > using replace() with no success, although I am not sure this is the
> > right function. This is the code I have used:
> >
> > data$X2 <- replace(data$X2, data$X2 =="AA","BB")
> > Warning message:
> > invalid factor level, NAs generated in: `[<-.factor`(`*tmp*`, list,
> > value = "BB")
> >
> > What is wrong with the code? How can I get this done? how about
> > changing AA values by BB in all 4 columns simultaneously? Actually
> > this is a small example dataframe, the real one would have about 
1000
> > columns.
> >
> > Extendind this, I found a similar thread dated July 2006 that used
> > replace() on iris dataset, but I have tried reproducing it 
obtaining
> > same warning message
> >
> >  iris$Species <- replace(iris$Species, iris$Species
> > == "setosa","NewName")
> > Warning message:
> > invalid factor level, NAs generated in: `[<-.factor`(`*tmp*`, list,
> > value = "NewName")
> >
> > Thanks in advance your help,
> >
> > David
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From ggrothendieck at gmail.com  Fri Sep  7 17:18:45 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 7 Sep 2007 11:18:45 -0400
Subject: [R] Automatic detachment of dependent packages
In-Reply-To: <6ade6f6c0709070739m5e652f5bjaca6fa2712dee4d@mail.gmail.com>
References: <6ade6f6c0709070739m5e652f5bjaca6fa2712dee4d@mail.gmail.com>
Message-ID: <971536df0709070818n484c152dhf2362c586e135ad4@mail.gmail.com>

If its good enough just to get rid of all attached packages since after startup
you could just do repeated detaches like this making use of the fact that
search() has 9 components on startup:

replicate(length(search()) - 9, detach())


On 9/7/07, Paul Smith <phhs80 at gmail.com> wrote:
> Dear All,
>
> When one loads certain packages, some other dependent packages are
> loaded as well. Is there some way of detaching them automatically when
> one detaches the first package loaded? For instance,
>
> > library(sqldf)
> Loading required package: RSQLite
> Loading required package: DBI
> Loading required package: gsubfn
> Loading required package: proto
>
> but
>
> > detach(package:sqldf)
> >
> > search()
>  [1] ".GlobalEnv"        "package:gsubfn"    "package:proto"
>  [4] "package:RSQLite"   "package:DBI"       "package:stats"
>  [7] "package:graphics"  "package:grDevices" "package:utils"
> [10] "package:datasets"  "package:methods"   "Autoloads"
> [13] "package:base"
>
> The packages
>
> RSQLite
> DBI
> gsubfn
> proto
>
> were not detached.
>
> Thanks in advance,
>
> Paul
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From phhs80 at gmail.com  Fri Sep  7 17:20:45 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Fri, 7 Sep 2007 16:20:45 +0100
Subject: [R] Delete query in sqldf?
Message-ID: <6ade6f6c0709070820w4629f011s591e41ddc91a09c2@mail.gmail.com>

Dear All,

Is sqldf equipped with delete queries? I have tried delete queries but
with no success.

Thanks in advance,

Paul


From ggrothendieck at gmail.com  Fri Sep  7 17:26:00 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 7 Sep 2007 11:26:00 -0400
Subject: [R] ploting missing data
In-Reply-To: <46E161CC.4000405@ibe.med.uni-muenchen.de>
References: <46E161CC.4000405@ibe.med.uni-muenchen.de>
Message-ID: <971536df0709070826k3b2ecc6bn50384b8929b5bc87@mail.gmail.com>

Try this:

library(zoo)
plot(na.approx(zoo(as.matrix(data[-1]), data[,1])), plot.type = "single")

See ?na.approx, ?plot.zoo, ?xyplot.zoo and vignette("zoo")

On 9/7/07, Markus Schmidberger <schmidb at ibe.med.uni-muenchen.de> wrote:
> Hello,
>
> I have this kind of dataframe and have to plot it.
>
> data <- data.frame(sw= c(1,2,3,4,5,6,7,8,9,10,11,12,15),
>    zehn =
> c(33.44,20.67,18.20,18.19,17.89,19.65,20.05,19.87,20.55,22.53,NA,NA,NA),
>     zwanzig =
> c(61.42,NA,26.60,23.28,NA,24.90,24.47,24.53,26.41,28.26,NA,29.80,35.49),
>     fuenfzig =
> c(162.51,66.08,49.55,43.40,NA,37.77,35.53,36.46,37.25,37.66,NA,42.29,47.80)
> )
>
> The plot should have lines:
> lines(fuenfzig~sw, data=data)
> lines(zwanzig~sw, data=data)
>
> But now I have holes in my lines for the missing values (NA). How to
> plot the lines without the holes?
> The missing values should be interpolated or the left and right point
> directly connected. The function approx interpolates the whole dataset.
> Thats not my goal!
> Is there no plotting function to do this directly?
>
> Best
> Markus
>
> --
> Dipl.-Tech. Math. Markus Schmidberger
>
> Ludwig-Maximilians-Universit?t M?nchen
> IBE - Institut f?r medizinische Informationsverarbeitung,
> Biometrie und Epidemiologie
> Marchioninistr. 15, D-81377 Muenchen
> URL: http://ibe.web.med.uni-muenchen.de
> Mail: Markus.Schmidberger [at] ibe.med.uni-muenchen.de
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Fri Sep  7 17:32:17 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 7 Sep 2007 11:32:17 -0400
Subject: [R] Delete query in sqldf?
In-Reply-To: <6ade6f6c0709070820w4629f011s591e41ddc91a09c2@mail.gmail.com>
References: <6ade6f6c0709070820w4629f011s591e41ddc91a09c2@mail.gmail.com>
Message-ID: <971536df0709070832o771a9f0bte6f39ddba77e7235@mail.gmail.com>

Yes but delete does not return anything so its not useful.  In the devel
version of sqldf you can pass multiple command so try this using the
builtin data frame BOD noting that the record with demand = 8.3 was
removed:

> library(sqldf)
Loading required package: RSQLite
Loading required package: DBI
Loading required package: gsubfn
Loading required package: proto
> # overwrite with devel version of the sqldf.R file
> source("http://sqldf.googlecode.com/svn/trunk/R/sqldf.R")
> sqldf(c("delete from BOD where demand = 8.3", "select * from BOD"))
  Time__1 demand
1       2   10.3
2       3   19.0
3       4   16.0
4       5   15.6
5       7   19.8


On 9/7/07, Paul Smith <phhs80 at gmail.com> wrote:
> Dear All,
>
> Is sqldf equipped with delete queries? I have tried delete queries but
> with no success.
>
> Thanks in advance,
>
> Paul
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From b.rowlingson at lancaster.ac.uk  Fri Sep  7 17:46:42 2007
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 07 Sep 2007 16:46:42 +0100
Subject: [R] Automatic detachment of dependent packages
In-Reply-To: <6ade6f6c0709070739m5e652f5bjaca6fa2712dee4d@mail.gmail.com>
References: <6ade6f6c0709070739m5e652f5bjaca6fa2712dee4d@mail.gmail.com>
Message-ID: <46E17262.4050604@lancaster.ac.uk>

Paul Smith wrote:
> Dear All,
> 
> When one loads certain packages, some other dependent packages are
> loaded as well. Is there some way of detaching them automatically when
> one detaches the first package loaded? For instance,
> 
>> library(sqldf)
> Loading required package: RSQLite
> Loading required package: DBI
> Loading required package: gsubfn
> Loading required package: proto
> 
> but
> 
>> detach(package:sqldf)
>>
>> search()
>  [1] ".GlobalEnv"        "package:gsubfn"    "package:proto"
>  [4] "package:RSQLite"   "package:DBI"       "package:stats"
>  [7] "package:graphics"  "package:grDevices" "package:utils"
> [10] "package:datasets"  "package:methods"   "Autoloads"
> [13] "package:base"
> 
> The packages
> 
> RSQLite
> DBI
> gsubfn
> proto
> 
> were not detached.

  The danger here is that after attaching sqldf you might attach some 
other package that needs, say, DBI, then when your cleanup routine 
detaches DBI that other package dies because DBI isn't there.

  The way to do it would be to detach any packages that are only 
depended on by the package you are detaching. You'd have to call 
packageDescription("foo", fields="Depends") for currently attached 
packages to build the dependency tree and then work out which ones you 
can remove... There's a bit of recursive tree-walking in there, but it 
should be simple... Ummm...

Barry


From helprhelp at gmail.com  Fri Sep  7 17:53:10 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Fri, 7 Sep 2007 11:53:10 -0400
Subject: [R] PCA IN R
Message-ID: <cdf817830709070853v58bc09d1y13b0710675e82fe8@mail.gmail.com>

hi,

A very quick search of PCA in R results in a lot of packages involving
that function. Just wondering which one is generally used for "fat"
data like microarray, esp. when the number of features is really big?

Thanks for comments

-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From martin.becker at mx.uni-saarland.de  Fri Sep  7 17:55:06 2007
From: martin.becker at mx.uni-saarland.de (Martin Becker)
Date: Fri, 07 Sep 2007 17:55:06 +0200
Subject: [R] FW: variable format
In-Reply-To: <6EBEA5B72E9B02428F2DD71D9DBC6EDF31939E@AKOYASRV01.akoyainc.local>
References: <6EBEA5B72E9B02428F2DD71D9DBC6EDF31939D@AKOYASRV01.akoyainc.local>
	<6EBEA5B72E9B02428F2DD71D9DBC6EDF31939E@AKOYASRV01.akoyainc.local>
Message-ID: <46E1745A.2000308@mx.uni-saarland.de>

Dear Cory,

I am not familiar with SAS, but is this what you are looking for?

divisionTable <- matrix(c(1, "New England",
                          2, "Middle Atlantic",
                          3, "East North Central",
                          4, "West North Central",
                          5, "South Atlantic",
                          6, "East South Central",
                          7, "West South Central",
                          8, "Mountain",
                          9, "Pacific"),
                        ncol=2, byrow=T)
a <- NULL
a$divisionOld <- c(0,1,2,3,4,5)
a$divisionNew <- 
as.character(factor(a$divisionOld,levels=divisionTable[,1],labels=divisionTable[,2]))
a$divisionNew

[1] NA                   "New England"        "Middle Atlantic"  
[4] "East North Central" "West North Central" "South Atlantic" 


Kind regards,

  Martin


Cory Nissen schrieb:
> 	 
>
> Anybody?  
>
>
> ________________________________
>
> From: Cory Nissen
> Sent: Tue 9/4/2007 9:30 AM
> To: r-help at stat.math.ethz.ch
> Subject: variable format
>
>
> Okay, I want to do something similar to SAS proc format.
>
> I usually do this...
>
> a <- NULL
> a$divisionOld <- c(1,2,3,4,5)
> divisionTable <- matrix(c(1, "New England",
>                           2, "Middle Atlantic",
>                           3, "East North Central",
>                           4, "West North Central",
>                           5, "South Atlantic"),
>                         ncol=2, byrow=T)
> a$divisionNew[match(a$divisionOld, divisionTable[,1])] <- divisionTable[,2]
>
> But how do I handle the case where...
> a$divisionOld <- c(0,1,2,3,4,5)   #no format available for 0, this throws an error.
> OR
> divisionTable <- matrix(c(1, "New England",
>                           2, "Middle Atlantic",
>                           3, "East North Central",
>                           4, "West North Central",
>                           5, "South Atlantic",
>                           6, "East South Central",
>                           7, "West South Central",
>                           8, "Mountain",
>                           9, "Pacific"),
>                         ncol=2, byrow=T)   
> There are extra formats available... this throws a warning.
>
> Thanks
>
> Cory
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ymoisan at groupesm.com  Fri Sep  7 18:04:28 2007
From: ymoisan at groupesm.com (Yves Moisan)
Date: Fri, 7 Sep 2007 09:04:28 -0700 (PDT)
Subject: [R] text in boxplots
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBBB412D@LP-EXCHVS07.CO.IHC.COM>
References: <12530892.post@talk.nabble.com>
	<07E228A5BE53C24CAD490193A7381BBBBB4068@LP-EXCHVS07.CO.IHC.COM>
	<12553104.post@talk.nabble.com>
	<07E228A5BE53C24CAD490193A7381BBBBB412A@LP-EXCHVS07.CO.IHC.COM>
	<07E228A5BE53C24CAD490193A7381BBBBB412D@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <12558160.post@talk.nabble.com>




6. set the reset.par argument to FALSE in calling scatterplot as it
states in the documentation for scatterplot.  (still look at the help on
'xpd' argment to par if you want to add text to the margins).

Hi Greg,

That seems to have done it partly.  I set it to false once and then I could
see some text afterwards, even with reset.par set to TRUE.  

About my not following posting guidelines, I'm sorry but I thought my
question didn't require me to post code.  I suspected graphics parameter to
be off, so the question was why a difference between mtext and text.  Also,
I mentioned earlier that I had succeeded in writing text to the plot for
regression stats (in the reg function of scatterplot.formula) where I did
use what seem to be the normal tricks [e.g. par("usr")].  I couldn't figure
out why setting new graph variables in the main scatterplot.formula function
in the form of 

usrGlobal <- par("usr") 

then calling

text(usrGlobal[2]-50,usrGlobal[4]-50,paste("Moyenne = ",r ...)

did not show any text whereas it did in the reg function.

But of course, pasting code could have been shorter for people to read ;-).

Thanx for your help.  
-- 
View this message in context: http://www.nabble.com/text-in-boxplots-tf4394528.html#a12558160
Sent from the R help mailing list archive at Nabble.com.


From selkovjr at uchicago.edu  Fri Sep  7 18:36:49 2007
From: selkovjr at uchicago.edu (Gene Selkov)
Date: Fri, 7 Sep 2007 11:36:49 -0500 (CDT)
Subject: [R] plotting to stdout
Message-ID: <Pine.GSO.4.62.0709071107430.21292@harper.uchicago.edu>


I have found two prior instances of this question in R-help, but I can't 
find the answer, and I'm giving up on mindless tinkering.

   http://tolstoy.newcastle.edu.au/R/help/03a/5994.html
   https://stat.ethz.ch/pipermail/r-help/2004-December/062259.html

I must be able to pipe the poltting commands to stdin and receive the plot 
on stdout, with errors written to stderr, should any occur.

Here's what I tried:

file test.r:
~~~~~~~~~~~~~~~~~~~~~~~~~~
postscript(stdout())
plot(0)
~~~~~~~~~~~~~~~~~~~~~~~~~~

This command:

    cat test.r | r --vanilla --slave

writes the output to a file named "1"

I have also tried:

   postscript(file=stdout())
   postscript(file=file("stdout"))

In the latter case, the output goes to the file named "3".

Other graphics devices do the same thing.

It is interesting that write.table() supports the file=stdout() idiom. If 
there is no official option to do this, I will appreciate a hint 
about the spot in the code where I can fix it.

Thanks,

--Gene

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> sessionInfo()
R version 2.5.1 (2007-06-27)
i386-apple-darwin8.10.1

locale:
C

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
[7] "base"


From murdoch at stats.uwo.ca  Fri Sep  7 18:49:09 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 07 Sep 2007 12:49:09 -0400
Subject: [R] plotting to stdout
In-Reply-To: <Pine.GSO.4.62.0709071107430.21292@harper.uchicago.edu>
References: <Pine.GSO.4.62.0709071107430.21292@harper.uchicago.edu>
Message-ID: <46E18105.7050105@stats.uwo.ca>

On 9/7/2007 12:36 PM, Gene Selkov wrote:
> I have found two prior instances of this question in R-help, but I can't 
> find the answer, and I'm giving up on mindless tinkering.
> 
>    http://tolstoy.newcastle.edu.au/R/help/03a/5994.html
>    https://stat.ethz.ch/pipermail/r-help/2004-December/062259.html
> 
> I must be able to pipe the poltting commands to stdin and receive the plot 
> on stdout, with errors written to stderr, should any occur.
> 
> Here's what I tried:
> 
> file test.r:
> ~~~~~~~~~~~~~~~~~~~~~~~~~~
> postscript(stdout())
> plot(0)
> ~~~~~~~~~~~~~~~~~~~~~~~~~~
> 
> This command:
> 
>     cat test.r | r --vanilla --slave
> 
> writes the output to a file named "1"
> 
> I have also tried:
> 
>    postscript(file=stdout())
>    postscript(file=file("stdout"))
> 
> In the latter case, the output goes to the file named "3".
> 
> Other graphics devices do the same thing.
> 
> It is interesting that write.table() supports the file=stdout() idiom. If 
> there is no official option to do this, I will appreciate a hint 
> about the spot in the code where I can fix it.

The ?postscript man page suggests that

postscript(file="", command="cat")

should do what you want (or maybe something other than "cat" for the 
passthrough).  The file arg is described as a character string, not a 
connection, so I wouldn't expect stdout() to work.  For write.table(), 
the arg is defined to be either the name of a file or an open connection.

Duncan Murdoch

> 
> Thanks,
> 
> --Gene
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>> sessionInfo()
> R version 2.5.1 (2007-06-27)
> i386-apple-darwin8.10.1
> 
> locale:
> C
> 
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> [7] "base"
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From doc.evans at gmail.com  Fri Sep  7 19:20:33 2007
From: doc.evans at gmail.com (D. R. Evans)
Date: Fri, 07 Sep 2007 11:20:33 -0600
Subject: [R] Q: loess-like function that allows more predictors?
Message-ID: <46E18861.6020909@gmail.com>

I have a feeling that this may be a stupid question, but here goes anyway:
is there a function that I can use to replace loess but which allows a
larger number of predictors?

(I have a situation in which it would be very convenient to use 5
predictors, which violates the constraint in loess that the number of
predictors be in the range from 1 to 4.)


From andy_liaw at merck.com  Fri Sep  7 19:29:32 2007
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 7 Sep 2007 13:29:32 -0400
Subject: [R] Q: loess-like function that allows more predictors?
In-Reply-To: <46E18861.6020909@gmail.com>
References: <46E18861.6020909@gmail.com>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04A4B479@usctmx1106.merck.com>

locfit() in the locfit package can do that.

Andy 

From: D. R. Evans
> 
> I have a feeling that this may be a stupid question, but here 
> goes anyway:
> is there a function that I can use to replace loess but which allows a
> larger number of predictors?
> 
> (I have a situation in which it would be very convenient to use 5
> predictors, which violates the constraint in loess that the number of
> predictors be in the range from 1 to 4.)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}


From jlaznarte at decsai.ugr.es  Fri Sep  7 20:34:45 2007
From: jlaznarte at decsai.ugr.es (Jose Luis Aznarte M.)
Date: Fri, 07 Sep 2007 20:34:45 +0200
Subject: [R] Matlab's lsqnonlin
Message-ID: <46E199C5.4010609@decsai.ugr.es>

    Hi! I'm translating some code from Matlab to R and I found a problem.
    I need to translate Matlab's function 'lsqnonlin' 
(http://www-ccs.ucsd.edu/matlab/toolbox/optim/lsqnonlin.html) into R, 
and at the beginning I  thought it would be the same as R's 'optim'. But 
then I looked at the definition of 'lsqnonlin' and I don't quite see how 
to make 'optim' to do the same thing. Does anyone have an idea?
    This is apart from the fact that I would like to use the Levenberg 
Marquardt algorithm which is not implemented in R (some discussion about 
this: http://tolstoy.newcastle.edu.au/R/help/00b/2492.html).
    Thank you! All the best,

 
--                                                      --
Jose Luis Aznarte M.       http://decsai.ugr.es/~jlaznarte
Department of Computer Science and Artificial Intelligence
Universidad de Granada           Tel. +34 - 958 - 24 04 67
GRANADA (Spain)                  Fax: +34 - 958 - 24 00 79


From dlakelan at street-artists.org  Fri Sep  7 19:56:26 2007
From: dlakelan at street-artists.org (Daniel Lakeland)
Date: Fri, 7 Sep 2007 10:56:26 -0700
Subject: [R] Matlab's lsqnonlin
In-Reply-To: <46E199C5.4010609@decsai.ugr.es>
References: <46E199C5.4010609@decsai.ugr.es>
Message-ID: <20070907175626.GC786@street-artists.org>

On Fri, Sep 07, 2007 at 08:34:45PM +0200, Jose Luis Aznarte M. wrote:
>     Hi! I'm translating some code from Matlab to R and I found a problem.
>     I need to translate Matlab's function 'lsqnonlin' 
> (http://www-ccs.ucsd.edu/matlab/toolbox/optim/lsqnonlin.html) into R, 

Do you want the "nls" function in R for nonlinear least squares?

-- 
Daniel Lakeland
dlakelan at street-artists.org
http://www.street-artists.org/~dlakelan


From phhs80 at gmail.com  Fri Sep  7 20:05:50 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Fri, 7 Sep 2007 19:05:50 +0100
Subject: [R] Automatic detachment of dependent packages
In-Reply-To: <46E17262.4050604@lancaster.ac.uk>
References: <6ade6f6c0709070739m5e652f5bjaca6fa2712dee4d@mail.gmail.com>
	<46E17262.4050604@lancaster.ac.uk>
Message-ID: <6ade6f6c0709071105x366cf3a0w9cc72c78169cfe41@mail.gmail.com>

On 9/7/07, Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:
> > When one loads certain packages, some other dependent packages are
> > loaded as well. Is there some way of detaching them automatically when
> > one detaches the first package loaded? For instance,
> >
> >> library(sqldf)
> > Loading required package: RSQLite
> > Loading required package: DBI
> > Loading required package: gsubfn
> > Loading required package: proto
> >
> > but
> >
> >> detach(package:sqldf)
> >>
> >> search()
> >  [1] ".GlobalEnv"        "package:gsubfn"    "package:proto"
> >  [4] "package:RSQLite"   "package:DBI"       "package:stats"
> >  [7] "package:graphics"  "package:grDevices" "package:utils"
> > [10] "package:datasets"  "package:methods"   "Autoloads"
> > [13] "package:base"
> >
> > The packages
> >
> > RSQLite
> > DBI
> > gsubfn
> > proto
> >
> > were not detached.
>
>   The danger here is that after attaching sqldf you might attach some
> other package that needs, say, DBI, then when your cleanup routine
> detaches DBI that other package dies because DBI isn't there.
>
>   The way to do it would be to detach any packages that are only
> depended on by the package you are detaching. You'd have to call
> packageDescription("foo", fields="Depends") for currently attached
> packages to build the dependency tree and then work out which ones you
> can remove... There's a bit of recursive tree-walking in there, but it
> should be simple... Ummm...

Thanks, Barry and Gabor. Please, look at the following:

> library(sqldf)
Loading required package: RSQLite
Loading required package: DBI
Loading required package: gsubfn
Loading required package: proto
> packageDescription("sqldf", fields="Depends")
[1] "R (>= 2.5.1), RSQLite (>= 0.5-5), gsubfn"
>

packageDescription does not mention the packages DBI and proto.

Paul


From kate at few.vu.nl  Fri Sep  7 20:07:41 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Fri, 7 Sep 2007 20:07:41 +0200 (CEST)
Subject: [R] Matlab's lsqnonlin
In-Reply-To: <46E199C5.4010609@decsai.ugr.es>
References: <46E199C5.4010609@decsai.ugr.es>
Message-ID: <Pine.GSO.4.56.0709072002160.29719@laurel.few.vu.nl>

The thread you linked to regarding Levenberg-Marquardt's supposed lack of
availability is from 2001; it has been possible to get
to the MINPACK implementation of Levenberg-Marquardt within R via the
package minpack.lm
(http://cran.r-project.org/src/contrib/Descriptions/minpack.lm.html) since
2005.

----
Katharine Mullen
mail: Department of Physics and Astronomy, Faculty of Sciences
Vrije Universiteit Amsterdam, de Boelelaan 1081
1081 HV Amsterdam, The Netherlands
room: T.1.06
tel: +31 205987870
fax: +31 205987992
e-mail: kate at nat.vu.nl
homepage: http://www.nat.vu.nl/~kate/


On Fri, 7 Sep 2007, Jose Luis Aznarte M. wrote:

>     Hi! I'm translating some code from Matlab to R and I found a problem.
>     I need to translate Matlab's function 'lsqnonlin'
> (http://www-ccs.ucsd.edu/matlab/toolbox/optim/lsqnonlin.html) into R,
> and at the beginning I  thought it would be the same as R's 'optim'. But
> then I looked at the definition of 'lsqnonlin' and I don't quite see how
> to make 'optim' to do the same thing. Does anyone have an idea?
>     This is apart from the fact that I would like to use the Levenberg
> Marquardt algorithm which is not implemented in R (some discussion about
> this: http://tolstoy.newcastle.edu.au/R/help/00b/2492.html).
>     Thank you! All the best,
>
>
> --                                                      --
> Jose Luis Aznarte M.       http://decsai.ugr.es/~jlaznarte
> Department of Computer Science and Artificial Intelligence
> Universidad de Granada           Tel. +34 - 958 - 24 04 67
> GRANADA (Spain)                  Fax: +34 - 958 - 24 00 79
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From selkovjr at uchicago.edu  Fri Sep  7 20:15:10 2007
From: selkovjr at uchicago.edu (Gene Selkov)
Date: Fri, 7 Sep 2007 13:15:10 -0500 (CDT)
Subject: [R] plotting to stdout
In-Reply-To: <46E18105.7050105@stats.uwo.ca>
References: <Pine.GSO.4.62.0709071107430.21292@harper.uchicago.edu>
	<46E18105.7050105@stats.uwo.ca>
Message-ID: <Pine.GSO.4.62.0709071309460.21292@harper.uchicago.edu>

Thanks a ton, Duncan!

So I have verified that this line works:

   echo "postscript(file=\"\", command=\"cat\"); plot(0)" | r --vanilla --slave

Wonderful! (albeit a little unobvious)

--Gene

On Fri, 7 Sep 2007, Duncan Murdoch wrote:

> On 9/7/2007 12:36 PM, Gene Selkov wrote:
>> I have found two prior instances of this question in R-help, but I can't 
>> find the answer, and I'm giving up on mindless tinkering.
>> 
>>    http://tolstoy.newcastle.edu.au/R/help/03a/5994.html
>>    https://stat.ethz.ch/pipermail/r-help/2004-December/062259.html
>> 
>> I must be able to pipe the poltting commands to stdin and receive the plot 
>> on stdout, with errors written to stderr, should any occur.
>> 
>> Here's what I tried:
>> 
>> file test.r:
>> ~~~~~~~~~~~~~~~~~~~~~~~~~~
>> postscript(stdout())
>> plot(0)
>> ~~~~~~~~~~~~~~~~~~~~~~~~~~
>> 
>> This command:
>> 
>>     cat test.r | r --vanilla --slave
>> 
>> writes the output to a file named "1"
>> 
>> I have also tried:
>> 
>>    postscript(file=stdout())
>>    postscript(file=file("stdout"))
>> 
>> In the latter case, the output goes to the file named "3".
>> 
>> Other graphics devices do the same thing.
>> 
>> It is interesting that write.table() supports the file=stdout() idiom. If 
>> there is no official option to do this, I will appreciate a hint about the 
>> spot in the code where I can fix it.
>
> The ?postscript man page suggests that
>
> postscript(file="", command="cat")
>
> should do what you want (or maybe something other than "cat" for the 
> passthrough).  The file arg is described as a character string, not a 
> connection, so I wouldn't expect stdout() to work.  For write.table(), the 
> arg is defined to be either the name of a file or an open connection.
>
> Duncan Murdoch
>
>> 
>> Thanks,
>> 
>> --Gene
>> 
>> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>>> sessionInfo()
>> R version 2.5.1 (2007-06-27)
>> i386-apple-darwin8.10.1
>> 
>> locale:
>> C
>> 
>> attached base packages:
>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
>> [7] "base"
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From phhs80 at gmail.com  Fri Sep  7 20:15:50 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Fri, 7 Sep 2007 19:15:50 +0100
Subject: [R] Delete query in sqldf?
In-Reply-To: <971536df0709070832o771a9f0bte6f39ddba77e7235@mail.gmail.com>
References: <6ade6f6c0709070820w4629f011s591e41ddc91a09c2@mail.gmail.com>
	<971536df0709070832o771a9f0bte6f39ddba77e7235@mail.gmail.com>
Message-ID: <6ade6f6c0709071115u431c5d22x1fcf02902fc93f46@mail.gmail.com>

On 9/7/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Yes but delete does not return anything so its not useful.  In the devel
> version of sqldf you can pass multiple command so try this using the
> builtin data frame BOD noting that the record with demand = 8.3 was
> removed:
>
> > library(sqldf)
> Loading required package: RSQLite
> Loading required package: DBI
> Loading required package: gsubfn
> Loading required package: proto
> > # overwrite with devel version of the sqldf.R file
> > source("http://sqldf.googlecode.com/svn/trunk/R/sqldf.R")
> > sqldf(c("delete from BOD where demand = 8.3", "select * from BOD"))
>   Time__1 demand
> 1       2   10.3
> 2       3   19.0
> 3       4   16.0
> 4       5   15.6
> 5       7   19.8

I see, Gabor, but I would expect as more natural to have

sqldf("delete from BOD where demand = 8.3")

working, with no second command.

Paul


> On 9/7/07, Paul Smith <phhs80 at gmail.com> wrote:
> > Dear All,
> >
> > Is sqldf equipped with delete queries? I have tried delete queries but
> > with no success.
> >
> > Thanks in advance,
> >
> > Paul
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From pxxiang at yahoo.com  Fri Sep  7 20:17:29 2007
From: pxxiang at yahoo.com (Phil Xiang)
Date: Fri, 7 Sep 2007 11:17:29 -0700 (PDT)
Subject: [R] Optimization under an absolute value constraint
Message-ID: <9896.47211.qm@web81510.mail.mud.yahoo.com>

I need to optimize a multivariate function f(w, x, y, z, ...) under an absolute value constraint. For instance:

    min { (2x+y) (w-z) }

under the constraint:

    |w| +  |x| + |y| + |z| = 1.0 .

Is there any R function that does this? Thank you for your help!

 
        Phil Xiang


From murdoch at stats.uwo.ca  Fri Sep  7 20:25:06 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 07 Sep 2007 14:25:06 -0400
Subject: [R] Automatic detachment of dependent packages
In-Reply-To: <6ade6f6c0709071105x366cf3a0w9cc72c78169cfe41@mail.gmail.com>
References: <6ade6f6c0709070739m5e652f5bjaca6fa2712dee4d@mail.gmail.com>	<46E17262.4050604@lancaster.ac.uk>
	<6ade6f6c0709071105x366cf3a0w9cc72c78169cfe41@mail.gmail.com>
Message-ID: <46E19782.2010500@stats.uwo.ca>

On 9/7/2007 2:05 PM, Paul Smith wrote:
> On 9/7/07, Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:
>> > When one loads certain packages, some other dependent packages are
>> > loaded as well. Is there some way of detaching them automatically when
>> > one detaches the first package loaded? For instance,
>> >
>> >> library(sqldf)
>> > Loading required package: RSQLite
>> > Loading required package: DBI
>> > Loading required package: gsubfn
>> > Loading required package: proto
>> >
>> > but
>> >
>> >> detach(package:sqldf)
>> >>
>> >> search()
>> >  [1] ".GlobalEnv"        "package:gsubfn"    "package:proto"
>> >  [4] "package:RSQLite"   "package:DBI"       "package:stats"
>> >  [7] "package:graphics"  "package:grDevices" "package:utils"
>> > [10] "package:datasets"  "package:methods"   "Autoloads"
>> > [13] "package:base"
>> >
>> > The packages
>> >
>> > RSQLite
>> > DBI
>> > gsubfn
>> > proto
>> >
>> > were not detached.
>>
>>   The danger here is that after attaching sqldf you might attach some
>> other package that needs, say, DBI, then when your cleanup routine
>> detaches DBI that other package dies because DBI isn't there.
>>
>>   The way to do it would be to detach any packages that are only
>> depended on by the package you are detaching. You'd have to call
>> packageDescription("foo", fields="Depends") for currently attached
>> packages to build the dependency tree and then work out which ones you
>> can remove... There's a bit of recursive tree-walking in there, but it
>> should be simple... Ummm...
> 
> Thanks, Barry and Gabor. Please, look at the following:
> 
>> library(sqldf)
> Loading required package: RSQLite
> Loading required package: DBI
> Loading required package: gsubfn
> Loading required package: proto
>> packageDescription("sqldf", fields="Depends")
> [1] "R (>= 2.5.1), RSQLite (>= 0.5-5), gsubfn"
>>
> 
> packageDescription does not mention the packages DBI and proto.

They are part of the recursive tree-walking that Barry mentioned, i.e. 
dependencies of RSQLite or gsubfn:

 > packageDescription("RSQLite", fields="Depends")
[1] "R (>= 2.3.0), methods, DBI (>= 0.2-3)"
 > packageDescription("gsubfn", fields="Depends")
[1] "R (>= 2.4.0), proto"

But you can get R to do the walking for you, using the pkgDepends 
function from the tools package:

 > pkgDepends("sqldf")
$Depends
[1] "DBI (>= 0.2-3)"     "gsubfn"             "methods"
[4] "proto"              "RSQLite (>= 0.5-5)"

... [ more stuff deleted ] ...

Watch out though:  you may not want to detach "methods" when you detach 
"sqldf", because it was already there.  Essentially you need some sort 
of snapshot of the state beforehand, and then you could restore it.

Duncan Murdoch


From cnissen at AkoyaInc.com  Fri Sep  7 20:21:41 2007
From: cnissen at AkoyaInc.com (Cory Nissen)
Date: Fri, 7 Sep 2007 13:21:41 -0500
Subject: [R] FW: variable format
References: <6EBEA5B72E9B02428F2DD71D9DBC6EDF31939D@AKOYASRV01.akoyainc.local>
	<6EBEA5B72E9B02428F2DD71D9DBC6EDF31939E@AKOYASRV01.akoyainc.local>
	<46E1745A.2000308@mx.uni-saarland.de>
Message-ID: <6EBEA5B72E9B02428F2DD71D9DBC6EDF3193A0@AKOYASRV01.akoyainc.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070907/5d68666b/attachment.pl 

From murdoch at stats.uwo.ca  Fri Sep  7 20:27:00 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 07 Sep 2007 14:27:00 -0400
Subject: [R] plotting to stdout
In-Reply-To: <Pine.GSO.4.62.0709071309460.21292@harper.uchicago.edu>
References: <Pine.GSO.4.62.0709071107430.21292@harper.uchicago.edu>	<46E18105.7050105@stats.uwo.ca>
	<Pine.GSO.4.62.0709071309460.21292@harper.uchicago.edu>
Message-ID: <46E197F4.8040505@stats.uwo.ca>

On 9/7/2007 2:15 PM, Gene Selkov wrote:
> Thanks a ton, Duncan!
> 
> So I have verified that this line works:
> 
>    echo "postscript(file=\"\", command=\"cat\"); plot(0)" | r --vanilla --slave
> 
> Wonderful! (albeit a little unobvious)

I would include an explicit "dev.off()" after the plotting; I'm not sure 
all devices guarantee a clean shutdown when R quits.

Duncan Murdoch
> 
> --Gene
> 
> On Fri, 7 Sep 2007, Duncan Murdoch wrote:
> 
>> On 9/7/2007 12:36 PM, Gene Selkov wrote:
>>> I have found two prior instances of this question in R-help, but I can't 
>>> find the answer, and I'm giving up on mindless tinkering.
>>> 
>>>    http://tolstoy.newcastle.edu.au/R/help/03a/5994.html
>>>    https://stat.ethz.ch/pipermail/r-help/2004-December/062259.html
>>> 
>>> I must be able to pipe the poltting commands to stdin and receive the plot 
>>> on stdout, with errors written to stderr, should any occur.
>>> 
>>> Here's what I tried:
>>> 
>>> file test.r:
>>> ~~~~~~~~~~~~~~~~~~~~~~~~~~
>>> postscript(stdout())
>>> plot(0)
>>> ~~~~~~~~~~~~~~~~~~~~~~~~~~
>>> 
>>> This command:
>>> 
>>>     cat test.r | r --vanilla --slave
>>> 
>>> writes the output to a file named "1"
>>> 
>>> I have also tried:
>>> 
>>>    postscript(file=stdout())
>>>    postscript(file=file("stdout"))
>>> 
>>> In the latter case, the output goes to the file named "3".
>>> 
>>> Other graphics devices do the same thing.
>>> 
>>> It is interesting that write.table() supports the file=stdout() idiom. If 
>>> there is no official option to do this, I will appreciate a hint about the 
>>> spot in the code where I can fix it.
>>
>> The ?postscript man page suggests that
>>
>> postscript(file="", command="cat")
>>
>> should do what you want (or maybe something other than "cat" for the 
>> passthrough).  The file arg is described as a character string, not a 
>> connection, so I wouldn't expect stdout() to work.  For write.table(), the 
>> arg is defined to be either the name of a file or an open connection.
>>
>> Duncan Murdoch
>>
>>> 
>>> Thanks,
>>> 
>>> --Gene
>>> 
>>> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>>>> sessionInfo()
>>> R version 2.5.1 (2007-06-27)
>>> i386-apple-darwin8.10.1
>>> 
>>> locale:
>>> C
>>> 
>>> attached base packages:
>>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
>>> [7] "base"
>>> 
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rkoenker at uiuc.edu  Fri Sep  7 20:36:32 2007
From: rkoenker at uiuc.edu (roger koenker)
Date: Fri, 7 Sep 2007 13:36:32 -0500
Subject: [R] Optimization under an absolute value constraint
In-Reply-To: <9896.47211.qm@web81510.mail.mud.yahoo.com>
References: <9896.47211.qm@web81510.mail.mud.yahoo.com>
Message-ID: <3296CEE7-50F5-4EC4-937A-E65A84E58193@uiuc.edu>

this should be possible in the lasso2 package.


url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Champaign, IL 61820


On Sep 7, 2007, at 1:17 PM, Phil Xiang wrote:

> I need to optimize a multivariate function f(w, x, y, z, ...) under  
> an absolute value constraint. For instance:
>
>     min { (2x+y) (w-z) }
>
> under the constraint:
>
>     |w| +  |x| + |y| + |z| = 1.0 .
>
> Is there any R function that does this? Thank you for your help!
>
>
>         Phil Xiang
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From f.harrell at vanderbilt.edu  Fri Sep  7 20:50:20 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 07 Sep 2007 13:50:20 -0500
Subject: [R] FW: variable format
In-Reply-To: <46E1745A.2000308@mx.uni-saarland.de>
References: <6EBEA5B72E9B02428F2DD71D9DBC6EDF31939D@AKOYASRV01.akoyainc.local>	<6EBEA5B72E9B02428F2DD71D9DBC6EDF31939E@AKOYASRV01.akoyainc.local>
	<46E1745A.2000308@mx.uni-saarland.de>
Message-ID: <46E19D6C.6080807@vanderbilt.edu>

Martin Becker wrote:
> Dear Cory,
> 
> I am not familiar with SAS, but is this what you are looking for?
> 
> divisionTable <- matrix(c(1, "New England",
>                           2, "Middle Atlantic",
>                           3, "East North Central",
>                           4, "West North Central",
>                           5, "South Atlantic",
>                           6, "East South Central",
>                           7, "West South Central",
>                           8, "Mountain",
>                           9, "Pacific"),
>                         ncol=2, byrow=T)

How about just divisionTable <- c('New England', 'Middle Atlantic', ...) 
then factor(old, 1:9, divisionTable) ?

Frank

> a <- NULL
> a$divisionOld <- c(0,1,2,3,4,5)
> a$divisionNew <- 
> as.character(factor(a$divisionOld,levels=divisionTable[,1],labels=divisionTable[,2]))
> a$divisionNew
> 
> [1] NA                   "New England"        "Middle Atlantic"  
> [4] "East North Central" "West North Central" "South Atlantic" 
> 
> 
> Kind regards,
> 
>   Martin
> 
> 
> Cory Nissen schrieb:
>> 	 
>>
>> Anybody?  
>>
>>
>> ________________________________
>>
>> From: Cory Nissen
>> Sent: Tue 9/4/2007 9:30 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: variable format
>>
>>
>> Okay, I want to do something similar to SAS proc format.
>>
>> I usually do this...
>>
>> a <- NULL
>> a$divisionOld <- c(1,2,3,4,5)
>> divisionTable <- matrix(c(1, "New England",
>>                           2, "Middle Atlantic",
>>                           3, "East North Central",
>>                           4, "West North Central",
>>                           5, "South Atlantic"),
>>                         ncol=2, byrow=T)
>> a$divisionNew[match(a$divisionOld, divisionTable[,1])] <- divisionTable[,2]
>>
>> But how do I handle the case where...
>> a$divisionOld <- c(0,1,2,3,4,5)   #no format available for 0, this throws an error.
>> OR
>> divisionTable <- matrix(c(1, "New England",
>>                           2, "Middle Atlantic",
>>                           3, "East North Central",
>>                           4, "West North Central",
>>                           5, "South Atlantic",
>>                           6, "East South Central",
>>                           7, "West South Central",
>>                           8, "Mountain",
>>                           9, "Pacific"),
>>                         ncol=2, byrow=T)   
>> There are extra formats available... this throws a warning.
>>
>> Thanks
>>
>> Cory
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From bszk at uoguelph.ca  Fri Sep  7 21:09:43 2007
From: bszk at uoguelph.ca (Bill Szkotnicki)
Date: Fri, 07 Sep 2007 15:09:43 -0400
Subject: [R] aggregate factor
Message-ID: <46E1A1F7.8040302@uoguelph.ca>

Hi,
I am using aggregate to compute means for later plotting.
There are two factors involved and the problem is that the values of the 
second factor ( Age ) in the means are not in the right order because 
"10" comes inbetween "1" and "2"
What I really want is the numeric value of Age but as.numeric and 
as.integer returns the level value instead.
Is there a way to easily get the numeric value?
I am using Windows R 2.5.1

Thanks,

 > str(fishdata)
'data.frame':   372 obs. of  6 variables:
 $ Lake: Factor w/ 3 levels "EVANS","JOLLIET",..: 3 3 3 3 3 3 3 3 3 3 ...
 $ Age : int  1 1 1 1 1 1 1 1 1 1 ...
 $ TL  : int  132 120 125 115 130 120 115 110 117 116 ...
 $ W   : int  10 10 10 10 10 10 10 10 10 20 ...
 $ Sex : Factor w/ 3 levels "F","I","M": 1 1 2 2 2 1 1 1 2 2 ...
 $ WT  : num  0.23 0.23 0.23 0.23 0.23 0.23 0.23 0.23 0.23 0.23 ...
 > fishdatameans=aggregate(fishdata$TL, list(Lake = fishdata$Lake, 
Age=fishdata$Age), mean)

#  Now Age is a Factor but 10 is in the wrong position.
 > fishdatameans$Age
 [1] 0  1  1  1  2  2  2  3  3  3  4  4  4  5  5  6  6  6  7  8  9  10
Levels: 0 1 10 2 3 4 5 6 7 8 9

 > as.numeric(fishdatameans$Age)
 [1]  1  2  2  2  4  4  4  5  5  5  6  6  6  7  7  8  8  8  9 10 11  3
 >
# What I want  is ---->   0  1  1  1  2  2  2  3  3  3  4  4  4  5  5  
6  6  6  7  8  9  10

Bill


From ken.pierce at oregonstate.edu  Fri Sep  7 21:15:51 2007
From: ken.pierce at oregonstate.edu (Pierce, Ken)
Date: Fri, 7 Sep 2007 12:15:51 -0700
Subject: [R] Running a PERL script from R
Message-ID: <0D23978FCA08B2499683B67DADE76B0102221A@SAGE.forestry.oregonstate.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070907/049b42d6/attachment.pl 

From Thierry.ONKELINX at inbo.be  Fri Sep  7 21:28:40 2007
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 7 Sep 2007 21:28:40 +0200
Subject: [R] aggregate factor
In-Reply-To: <46E1A1F7.8040302@uoguelph.ca>
References: <46E1A1F7.8040302@uoguelph.ca>
Message-ID: <2E9C414912813E4EB981326983E0A104039EF6E6@inboexch.inbo.be>

Try this.

as.numeric(levels(fishdata$Age))[fishdata$Age]

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx op inbo.be
www.inbo.be 

Do not put your faith in what statistics say until you have carefully
considered what they do not say.  ~William W. Watt
A statistical analysis, properly conducted, is a delicate dissection of
uncertainties, a surgery of suppositions. ~M.J.Moroney

 

> -----Oorspronkelijk bericht-----
> Van: r-help-bounces op stat.math.ethz.ch 
> [mailto:r-help-bounces op stat.math.ethz.ch] Namens Bill Szkotnicki
> Verzonden: vrijdag 7 september 2007 21:10
> Aan: r-help op stat.math.ethz.ch
> Onderwerp: [R] aggregate factor
> 
> Hi,
> I am using aggregate to compute means for later plotting.
> There are two factors involved and the problem is that the 
> values of the second factor ( Age ) in the means are not in 
> the right order because "10" comes inbetween "1" and "2"
> What I really want is the numeric value of Age but as.numeric 
> and as.integer returns the level value instead.
> Is there a way to easily get the numeric value?
> I am using Windows R 2.5.1
> 
> Thanks,
> 
>  > str(fishdata)
> 'data.frame':   372 obs. of  6 variables:
>  $ Lake: Factor w/ 3 levels "EVANS","JOLLIET",..: 3 3 3 3 3 3 
> 3 3 3 3 ...
>  $ Age : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ TL  : int  132 120 125 115 130 120 115 110 117 116 ...
>  $ W   : int  10 10 10 10 10 10 10 10 10 20 ...
>  $ Sex : Factor w/ 3 levels "F","I","M": 1 1 2 2 2 1 1 1 2 2 ...
>  $ WT  : num  0.23 0.23 0.23 0.23 0.23 0.23 0.23 0.23 0.23 0.23 ...
>  > fishdatameans=aggregate(fishdata$TL, list(Lake = 
> fishdata$Lake, Age=fishdata$Age), mean)
> 
> #  Now Age is a Factor but 10 is in the wrong position.
>  > fishdatameans$Age
>  [1] 0  1  1  1  2  2  2  3  3  3  4  4  4  5  5  6  6  6  7  8  9  10
> Levels: 0 1 10 2 3 4 5 6 7 8 9
> 
>  > as.numeric(fishdatameans$Age)
>  [1]  1  2  2  2  4  4  4  5  5  5  6  6  6  7  7  8  8  8  9 
> 10 11  3  >
> # What I want  is ---->   0  1  1  1  2  2  2  3  3  3  4  4  
> 4  5  5  
> 6  6  6  7  8  9  10
> 
> Bill
> 
> ______________________________________________
> R-help op stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Fri Sep  7 21:29:17 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 7 Sep 2007 15:29:17 -0400
Subject: [R] Delete query in sqldf?
In-Reply-To: <6ade6f6c0709071115u431c5d22x1fcf02902fc93f46@mail.gmail.com>
References: <6ade6f6c0709070820w4629f011s591e41ddc91a09c2@mail.gmail.com>
	<971536df0709070832o771a9f0bte6f39ddba77e7235@mail.gmail.com>
	<6ade6f6c0709071115u431c5d22x1fcf02902fc93f46@mail.gmail.com>
Message-ID: <971536df0709071229m4b3ba180yda03536fed81feb@mail.gmail.com>

All sqldf does is pass the command to sqlite and retrieve whatever it
sends back translating the two directions to and from R.  sqldf
does not change the meaning of any sql statements.  Perhaps the
meaning you expect is desirable but its not how sqlite works.   If
sqlite were changed to adopt that meaning then sqldf would
automatically get it too.

Here is an example which does not involve R at all which
illustrates that delete returns nothing.

C:\> sqlite3
SQLite version 3.4.0
Enter ".help" for instructions
sqlite>
sqlite> create table t1(a,b);
sqlite> insert into T1 values(1,2);
sqlite> insert into T1 values(1,3);
sqlite> insert into T1 values(2,4);
sqlite> delete from t1 where b = 2;
sqlite> select * from t1;
1|3
2|4


On 9/7/07, Paul Smith <phhs80 at gmail.com> wrote:
> On 9/7/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > Yes but delete does not return anything so its not useful.  In the devel
> > version of sqldf you can pass multiple command so try this using the
> > builtin data frame BOD noting that the record with demand = 8.3 was
> > removed:
> >
> > > library(sqldf)
> > Loading required package: RSQLite
> > Loading required package: DBI
> > Loading required package: gsubfn
> > Loading required package: proto
> > > # overwrite with devel version of the sqldf.R file
> > > source("http://sqldf.googlecode.com/svn/trunk/R/sqldf.R")
> > > sqldf(c("delete from BOD where demand = 8.3", "select * from BOD"))
> >   Time__1 demand
> > 1       2   10.3
> > 2       3   19.0
> > 3       4   16.0
> > 4       5   15.6
> > 5       7   19.8
>
> I see, Gabor, but I would expect as more natural to have
>
> sqldf("delete from BOD where demand = 8.3")
>
> working, with no second command.
>
> Paul
>
>
> > On 9/7/07, Paul Smith <phhs80 at gmail.com> wrote:
> > > Dear All,
> > >
> > > Is sqldf equipped with delete queries? I have tried delete queries but
> > > with no success.
> > >
> > > Thanks in advance,
> > >
> > > Paul


From louis.zelus at gmail.com  Fri Sep  7 21:45:29 2007
From: louis.zelus at gmail.com (Luis Naver)
Date: Fri, 7 Sep 2007 12:45:29 -0700
Subject: [R] Help with color coded bar graph
Message-ID: <E463F9C6-3D4C-4FC3-93C4-97ADAE92C5DF@gmail.com>

I have a list of observations that are -1, 1 or 0.  I would like to  
represent them in a horizontal bar color coded based on value like a  
stacked bar graph. I can achieve this in the form of a png with the  
following code:

A = floor(runif(10)*3) - 1

png(width=100, height=10)
par(mar=c(0,0,0,0))
image(matrix(A), col=grey(c(0.1, 0.5, 0.9)))
dev.off()

However I would like to do this with one of the standard plotting  
tools (i.e. barplot) to take advantage of labels and multiple  
series.  Any help would be appreciated.

- Luis Naver


From pisicandru at hotmail.com  Fri Sep  7 21:53:18 2007
From: pisicandru at hotmail.com (Monica Pisica)
Date: Fri, 7 Sep 2007 19:53:18 +0000
Subject: [R]  confusion matrix - better code?
Message-ID: <BAY104-W140B79C46A676BDE4E884AC3C50@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070907/45a09e33/attachment.pl 

From huber at ebi.ac.uk  Fri Sep  7 22:04:32 2007
From: huber at ebi.ac.uk (Wolfgang Huber)
Date: Fri, 07 Sep 2007 21:04:32 +0100
Subject: [R] confusion matrix - better code?
In-Reply-To: <BAY104-W140B79C46A676BDE4E884AC3C50@phx.gbl>
References: <BAY104-W140B79C46A676BDE4E884AC3C50@phx.gbl>
Message-ID: <46E1AED0.3060206@ebi.ac.uk>

Dear Monica,

try this:

cm =  table(tr, pr)
cm
    pr
tr  1 2 3
   1 2 1 0
   2 2 1 0
   3 0 0 3
   4 0 1 0


rowSums(cm)
colSums(cm)

   Best wishes
	Wolfgang Huber

Monica Pisica ha scritto:
> Hi,
>  
> I?ve written some code to obtain a confusion matrix when the true classification and the predicted classification are known. Suppose true classification is called ?tr? and predicted classification is ?pr?. I have 4 classes in tr, but only 3 classes out of 4 are predicted in ?pr?. Following is my code, but looks quite ?clunky? to me. I wonder if you have any suggestions to improve it.
>  
> Thanks,
>  
> Monica
>  
> -----------------------------
>  
> tr <- c(1,2,2,3,3,3,2,4,1,1)
> pr<-c(1,2,1,3,3,3,1,2,1,2)
> dat <- data.frame(tr, pr)
> class <- c(1:length(tr))
> m <- max(c(length(unique(tr)), length(unique(pr))))
> for(i in 1:length(class)) {
>  class[i] <- sub(' ','',paste(dat[i,1],dat[i,2])) }
> dat <- data.frame(dat, class)
> mat <- matrix(0, nrow=m, ncol=m)
> for (i in 1:m){
>   for (j in 1:m){
>  mat[i,j] <- sub(' ','',paste(i,j))
>  }}
> cat <- matrix(0, nrow=(m+1), ncol=(m+1))
>   for (i in 1:m){
>   for(j in 1:m){
>  cat[i,j]<- nrow(dat[dat$class==mat[i,j],])
> }}
> for (i in 1:m){
> cat[(m+1),i]<-sum(cat[1:m,i])
>  cat[i,(m+1)]<- sum(cat[i,1:m])
> cat[(m+1),(m+1)] <- sum(cat[1:m,(m+1)])
> }
> cat
>      [,1] [,2] [,3] [,4] [,5]
> [1,]    2    1    0    0    3
> [2,]    2    1    0    0    3
> [3,]    0    0    3    0    3
> [4,]    0    1    0    0    1
> [5,]    4    3    3    0   10
>  
> The 5th row / col represents the sum on each row / col respectively.


From marc_schwartz at comcast.net  Fri Sep  7 22:07:11 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 07 Sep 2007 15:07:11 -0500
Subject: [R] Help with color coded bar graph
In-Reply-To: <E463F9C6-3D4C-4FC3-93C4-97ADAE92C5DF@gmail.com>
References: <E463F9C6-3D4C-4FC3-93C4-97ADAE92C5DF@gmail.com>
Message-ID: <1189195631.19396.86.camel@Bellerophon.localdomain>

On Fri, 2007-09-07 at 12:45 -0700, Luis Naver wrote:
> I have a list of observations that are -1, 1 or 0.  I would like to  
> represent them in a horizontal bar color coded based on value like a  
> stacked bar graph. I can achieve this in the form of a png with the  
> following code:
> 
> A = floor(runif(10)*3) - 1
> 
> png(width=100, height=10)
> par(mar=c(0,0,0,0))
> image(matrix(A), col=grey(c(0.1, 0.5, 0.9)))
> dev.off()
> 
> However I would like to do this with one of the standard plotting  
> tools (i.e. barplot) to take advantage of labels and multiple  
> series.  Any help would be appreciated.
> 
> - Luis Naver

How about this:

  barplot(rep(1, length(A)), col = "black", space = 0, border = 0)

  barplot(A, col = grey(0.9), space = 0, border = 0, add = TRUE)

The first call sets the plot region to black, ensuring that the x and y
axes are consistent with the second call.

Alternatively, you can use barplot2() in the gplots CRAN package to do
this in a single call, as it has an argument to color the plot region.

HTH,

Marc Schwartz


From edd at debian.org  Fri Sep  7 22:10:18 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 7 Sep 2007 15:10:18 -0500
Subject: [R] plotting to stdout
In-Reply-To: <46E197F4.8040505@stats.uwo.ca>
References: <Pine.GSO.4.62.0709071107430.21292@harper.uchicago.edu>
	<46E18105.7050105@stats.uwo.ca>
	<Pine.GSO.4.62.0709071309460.21292@harper.uchicago.edu>
	<46E197F4.8040505@stats.uwo.ca>
Message-ID: <20070907201018.GA14851@eddelbuettel.com>

On Fri, Sep 07, 2007 at 02:27:00PM -0400, Duncan Murdoch wrote:
> On 9/7/2007 2:15 PM, Gene Selkov wrote:
> > Thanks a ton, Duncan!
> > 
> > So I have verified that this line works:
> > 
> >    echo "postscript(file=\"\", command=\"cat\"); plot(0)" | r --vanilla --slave
> > 
> > Wonderful! (albeit a little unobvious)
> 
> I would include an explicit "dev.off()" after the plotting; I'm not sure 
> all devices guarantee a clean shutdown when R quits.

And for the record, both littler and Rscript can do that without the
need for double quotes, at least under Linux.  E.g. both

$ r -e 'postscript(file="", command="cat"); plot(0)' | head 
$ Rscript -e 'postscript(file="", command="cat"); plot(0)' | head

provide the same output (of the beginning of the postscript output).
Our r is as usual somewhat faster, not that this matters in this
non-repeat context.

Dirk

-- 
Three out of two people have difficulties with fractions.


From edd at debian.org  Fri Sep  7 22:10:48 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 7 Sep 2007 15:10:48 -0500
Subject: [R] Running a PERL script from R
In-Reply-To: <0D23978FCA08B2499683B67DADE76B0102221A@SAGE.forestry.oregonstate.edu>
References: <0D23978FCA08B2499683B67DADE76B0102221A@SAGE.forestry.oregonstate.edu>
Message-ID: <20070907201048.GB14851@eddelbuettel.com>

On Fri, Sep 07, 2007 at 12:15:51PM -0700, Pierce, Ken wrote:
> Is there a way to run a simple perl script from R?

?system

Hth, Dirk

-- 
Three out of two people have difficulties with fractions.


From Achim.Zeileis at wu-wien.ac.at  Fri Sep  7 22:17:41 2007
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Fri, 7 Sep 2007 22:17:41 +0200 (CEST)
Subject: [R] Help with color coded bar graph
In-Reply-To: <E463F9C6-3D4C-4FC3-93C4-97ADAE92C5DF@gmail.com>
References: <E463F9C6-3D4C-4FC3-93C4-97ADAE92C5DF@gmail.com>
Message-ID: <Pine.LNX.4.64.0709072214320.1334@eowyn>

On Fri, 7 Sep 2007, Luis Naver wrote:

> I have a list of observations that are -1, 1 or 0.  I would like to
> represent them in a horizontal bar color coded based on value like a
> stacked bar graph. I can achieve this in the form of a png with the
> following code:
>
> A = floor(runif(10)*3) - 1
>
> png(width=100, height=10)
> par(mar=c(0,0,0,0))
> image(matrix(A), col=grey(c(0.1, 0.5, 0.9)))
> dev.off()

If I understand you correctly, you want a sequence of bars with equal 
height and colors coded by A (treated like a factor). So Maybe something 
like
   cA <- grey.colors(3)[factor(A)]
   barplot(rep(1, length(A)), col = cA, border = cA)
or
   barplot(rep(1, length(A)), col = cA, border = cA, space = 0,
     xaxs = "i", axes = FALSE)
?

hth,
Z


> However I would like to do this with one of the standard plotting
> tools (i.e. barplot) to take advantage of labels and multiple
> series.  Any help would be appreciated.
>
> - Luis Naver
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From marc_schwartz at comcast.net  Fri Sep  7 22:21:50 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 07 Sep 2007 15:21:50 -0500
Subject: [R] Help with color coded bar graph
In-Reply-To: <1189195631.19396.86.camel@Bellerophon.localdomain>
References: <E463F9C6-3D4C-4FC3-93C4-97ADAE92C5DF@gmail.com>
	<1189195631.19396.86.camel@Bellerophon.localdomain>
Message-ID: <1189196510.19396.99.camel@Bellerophon.localdomain>

On Fri, 2007-09-07 at 15:07 -0500, Marc Schwartz wrote:
> On Fri, 2007-09-07 at 12:45 -0700, Luis Naver wrote:
> > I have a list of observations that are -1, 1 or 0.  I would like to  
> > represent them in a horizontal bar color coded based on value like a  
> > stacked bar graph. I can achieve this in the form of a png with the  
> > following code:
> > 
> > A = floor(runif(10)*3) - 1
> > 
> > png(width=100, height=10)
> > par(mar=c(0,0,0,0))
> > image(matrix(A), col=grey(c(0.1, 0.5, 0.9)))
> > dev.off()
> > 
> > However I would like to do this with one of the standard plotting  
> > tools (i.e. barplot) to take advantage of labels and multiple  
> > series.  Any help would be appreciated.
> > 
> > - Luis Naver
> 
> How about this:
> 
>   barplot(rep(1, length(A)), col = "black", space = 0, border = 0)
> 
>   barplot(A, col = grey(0.9), space = 0, border = 0, add = TRUE)
> 
> The first call sets the plot region to black, ensuring that the x and y
> axes are consistent with the second call.
> 
> Alternatively, you can use barplot2() in the gplots CRAN package to do
> this in a single call, as it has an argument to color the plot region.

Actually, here is an easier way:

barplot(rep(1, length(A)), 
        col = ifelse(A == 0, "black", grey(0.9)), space = 0, border = 0)

Just set 'col' based upon the value in 'A'.

HTH,

Marc


From realityrandom at gmail.com  Fri Sep  7 23:00:53 2007
From: realityrandom at gmail.com (Yuchen Luo)
Date: Fri, 7 Sep 2007 14:00:53 -0700
Subject: [R] 'initial value not feasible' in constrOptim
Message-ID: <548b8d440709071400v5e01fa9fw2cce6f212696f587@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070907/91bac392/attachment.pl 

From ken.pierce at oregonstate.edu  Fri Sep  7 23:04:09 2007
From: ken.pierce at oregonstate.edu (Pierce, Ken)
Date: Fri, 7 Sep 2007 14:04:09 -0700
Subject: [R] Running a PERL script from R
In-Reply-To: <20070907201048.GB14851@eddelbuettel.com>
References: <0D23978FCA08B2499683B67DADE76B0102221A@SAGE.forestry.oregonstate.edu>
	<20070907201048.GB14851@eddelbuettel.com>
Message-ID: <0D23978FCA08B2499683B67DADE76B0102221B@SAGE.forestry.oregonstate.edu>

I've tried various configurations of .script, system and shell to no
avail. It seems to pause and run "something" but then no output is
created. 

-----Original Message-----
From: Dirk Eddelbuettel [mailto:edd at debian.org] 
Sent: Friday, September 07, 2007 1:11 PM
To: Pierce, Ken
Cc: r-help
Subject: Re: [R] Running a PERL script from R

On Fri, Sep 07, 2007 at 12:15:51PM -0700, Pierce, Ken wrote:
> Is there a way to run a simple perl script from R?

?system

Hth, Dirk

--
Three out of two people have difficulties with fractions.


From jacques.wagnor at gmail.com  Fri Sep  7 23:04:37 2007
From: jacques.wagnor at gmail.com (Jacques Wagnor)
Date: Fri, 7 Sep 2007 16:04:37 -0500
Subject: [R] How to obtain parameters of a mixture model of two lognormal
	distributions
Message-ID: <787911d50709071404x2deefc1cg6795034f7c23ffec@mail.gmail.com>

Dear List,

I have read that a lognormal mixture model having a pdf of the form
f(x)=w1*f1(x)+(1-w1)*f2(x) fits most data sets quite well, where f1
and f2 are lognormal distributions.

Any pointers on how to create a function that would produce the 5
parameters of f(x) would be greatly appreciated.

> version
               _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          5.1
year           2007
month          06
day            27
svn rev        42083
language       R
version.string R version 2.5.1 (2007-06-27)


From mandevip at uaslp.mx  Fri Sep  7 23:38:50 2007
From: mandevip at uaslp.mx (Peter B. Mandeville)
Date: Fri, 7 Sep 2007 16:38:50 -0500
Subject: [R] multiphasic growth curve analysis
Message-ID: <00f501c7f197$7b6068a0$6509e094@DellPeter>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070907/0c55af86/attachment.pl 

From sunnyside500 at gmail.com  Fri Sep  7 23:42:07 2007
From: sunnyside500 at gmail.com (runner)
Date: Fri, 7 Sep 2007 14:42:07 -0700 (PDT)
Subject: [R] enable object name to be called as object (a dataset)
Message-ID: <12563767.post@talk.nabble.com>


What I am trying to do is as follows:

- I have listed names of all wanted objects (datasets A,B,C... ) in current
workspace as a vector: 

obj <- c('A','B','C')

- then i need to use these objects, say to extract all the 1st columns and
bind to an existing dataset ('data'): 
 
for ( i in 1:3){
newdata <- obj[i] 
data <- cbind(data,newdata [[1]] )
}

Obviously, it doesn't work since obj[i] is just a string of dataset name.
Here is my question: how to call it as a original dataset? Thanks.
-- 
View this message in context: http://www.nabble.com/enable-object-name-to-be-called-as-object-%28a-dataset%29-tf4403933.html#a12563767
Sent from the R help mailing list archive at Nabble.com.


From jloehrke at umassd.edu  Fri Sep  7 23:59:31 2007
From: jloehrke at umassd.edu (Jon Loehrke)
Date: Fri, 7 Sep 2007 17:59:31 -0400 (EDT)
Subject: [R] tcl/tk help
Message-ID: <16168.134.88.230.79.1189202371.squirrel@email.umassd.edu>

I am running R 2.5 on a Mac platform and have a difficulty loading the
Tcl/Tk package.

Specifically:

R>library(tcltk)
Loading Tcl/Tk interface ... Error in fun(...) : couldn't connect to
display ":0"
Error : .onLoad failed in 'loadNamespace' for 'tcltk'
Error: package/namespace load failed for 'tcltk'

Is there an explanation to this problem?  Thank you very much.



Jon Loehrke
Fisheries Graduate Research Assistant
School for Marine Science and Technology
UMASS-Dartmouth
838 S. Rodney French Blvd.
New Bedford, MA 02744
Phone: 508-910-6393
Fax:   508-910-6396


From luis.naver at gmail.com  Sat Sep  8 00:03:00 2007
From: luis.naver at gmail.com (Luis Naver)
Date: Fri, 7 Sep 2007 15:03:00 -0700
Subject: [R] Help with color coded bar graph
In-Reply-To: <1189196510.19396.99.camel@Bellerophon.localdomain>
References: <E463F9C6-3D4C-4FC3-93C4-97ADAE92C5DF@gmail.com>
	<1189195631.19396.86.camel@Bellerophon.localdomain>
	<1189196510.19396.99.camel@Bellerophon.localdomain>
Message-ID: <B0FCFD41-928F-4556-8AA7-8317415C30F1@gmail.com>

Thanks to all who replied (and very quickly).   Unfortunatly I was  
not clear enough as to my intentions.  My goal is to replicate a  
graph I saw in the work by Perry, Miller and Enright in "A comparison  
of methods for the statistical analysis of spatial point patterns in  
plant ecology" (http://www.springerlink.com/content/ 
013275pp7376v0hx).  For those without the article here is a copy of  
the graph in question (replicated without permission) http:// 
img511.imageshack.us/img511/8720/barexamplejl8.png.

As you can see in the example, there are several hoizontal bars,  
colored by the values in an array (one for each bar).

I've been thinking of following your examples but setting it to  
stack, such that all the elements would be placed one on top  
another.  While this may work it seems particularly ungraceful.

Again, thanks for the help.

-Luis Naver

On Sep 7, 2007, at 1:21 PM, Marc Schwartz wrote:

> On Fri, 2007-09-07 at 15:07 -0500, Marc Schwartz wrote:
>> On Fri, 2007-09-07 at 12:45 -0700, Luis Naver wrote:
>>> I have a list of observations that are -1, 1 or 0.  I would like to
>>> represent them in a horizontal bar color coded based on value like a
>>> stacked bar graph. I can achieve this in the form of a png with the
>>> following code:
>>>
>>> A = floor(runif(10)*3) - 1
>>>
>>> png(width=100, height=10)
>>> par(mar=c(0,0,0,0))
>>> image(matrix(A), col=grey(c(0.1, 0.5, 0.9)))
>>> dev.off()
>>>
>>> However I would like to do this with one of the standard plotting
>>> tools (i.e. barplot) to take advantage of labels and multiple
>>> series.  Any help would be appreciated.
>>>
>>> - Luis Naver
>>
>> How about this:
>>
>>   barplot(rep(1, length(A)), col = "black", space = 0, border = 0)
>>
>>   barplot(A, col = grey(0.9), space = 0, border = 0, add = TRUE)
>>
>> The first call sets the plot region to black, ensuring that the x  
>> and y
>> axes are consistent with the second call.
>>
>> Alternatively, you can use barplot2() in the gplots CRAN package  
>> to do
>> this in a single call, as it has an argument to color the plot  
>> region.
>
> Actually, here is an easier way:
>
> barplot(rep(1, length(A)),
>         col = ifelse(A == 0, "black", grey(0.9)), space = 0, border  
> = 0)
>
> Just set 'col' based upon the value in 'A'.
>
> HTH,
>
> Marc
>
>


From csardi at rmki.kfki.hu  Sat Sep  8 00:04:16 2007
From: csardi at rmki.kfki.hu (Gabor Csardi)
Date: Sat, 8 Sep 2007 00:04:16 +0200
Subject: [R] enable object name to be called as object (a dataset)
In-Reply-To: <12563767.post@talk.nabble.com>
References: <12563767.post@talk.nabble.com>
Message-ID: <20070907220416.GA7088@localdomain>

"get" might be good enough for you:

> a <- 10
> name <- "a"
> get("a")
[1] 10
> get(name)
[1] 10
>

Gabor

On Fri, Sep 07, 2007 at 02:42:07PM -0700, runner wrote:
> 
> What I am trying to do is as follows:
> 
> - I have listed names of all wanted objects (datasets A,B,C... ) in current
> workspace as a vector: 
> 
> obj <- c('A','B','C')
> 
> - then i need to use these objects, say to extract all the 1st columns and
> bind to an existing dataset ('data'): 
>  
> for ( i in 1:3){
> newdata <- obj[i] 
> data <- cbind(data,newdata [[1]] )
> }
> 
> Obviously, it doesn't work since obj[i] is just a string of dataset name.
> Here is my question: how to call it as a original dataset? Thanks.
> -- 
> View this message in context: http://www.nabble.com/enable-object-name-to-be-called-as-object-%28a-dataset%29-tf4403933.html#a12563767
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK


From csardi at rmki.kfki.hu  Sat Sep  8 00:07:39 2007
From: csardi at rmki.kfki.hu (Gabor Csardi)
Date: Sat, 8 Sep 2007 00:07:39 +0200
Subject: [R] tcl/tk help
In-Reply-To: <16168.134.88.230.79.1189202371.squirrel@email.umassd.edu>
References: <16168.134.88.230.79.1189202371.squirrel@email.umassd.edu>
Message-ID: <20070907220739.GB7088@localdomain>

See http://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html#TclTk-issues

Gabor

On Fri, Sep 07, 2007 at 05:59:31PM -0400, Jon Loehrke wrote:
> I am running R 2.5 on a Mac platform and have a difficulty loading the
> Tcl/Tk package.
> 
> Specifically:
> 
> R>library(tcltk)
> Loading Tcl/Tk interface ... Error in fun(...) : couldn't connect to
> display ":0"
> Error : .onLoad failed in 'loadNamespace' for 'tcltk'
> Error: package/namespace load failed for 'tcltk'
> 
> Is there an explanation to this problem?  Thank you very much.
> 
> 
> 
> Jon Loehrke
> Fisheries Graduate Research Assistant
> School for Marine Science and Technology
> UMASS-Dartmouth
> 838 S. Rodney French Blvd.
> New Bedford, MA 02744
> Phone: 508-910-6393
> Fax:   508-910-6396
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK


From GPetris at uark.edu  Sat Sep  8 00:10:44 2007
From: GPetris at uark.edu (Giovanni Petris)
Date: Fri, 7 Sep 2007 17:10:44 -0500 (CDT)
Subject: [R] enable object name to be called as object (a dataset)
In-Reply-To: <12563767.post@talk.nabble.com> (message from runner on Fri, 07
	Sep 2007 14:42:07 -0700 (PDT))
References: <12563767.post@talk.nabble.com>
Message-ID: <200709072210.l87MAieY026407@definetti.ddns.uark.edu>


This should work:

do.call(cbind, lapply(1:length(obj), function(i) get(obj[i])[,1]))

Best,
Giovanni

> Date: Fri, 07 Sep 2007 14:42:07 -0700 (PDT)
> From: runner <sunnyside500 at gmail.com>
> Sender: r-help-bounces at stat.math.ethz.ch
> Precedence: list
> 
> 
> What I am trying to do is as follows:
> 
> - I have listed names of all wanted objects (datasets A,B,C... ) in current
> workspace as a vector: 
> 
> obj <- c('A','B','C')
> 
> - then i need to use these objects, say to extract all the 1st columns and
> bind to an existing dataset ('data'): 
>  
> for ( i in 1:3){
> newdata <- obj[i] 
> data <- cbind(data,newdata [[1]] )
> }
> 
> Obviously, it doesn't work since obj[i] is just a string of dataset name.
> Here is my question: how to call it as a original dataset? Thanks.
> -- 
> View this message in context: http://www.nabble.com/enable-object-name-to-be-called-as-object-%28a-dataset%29-tf4403933.html#a12563767
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 

Giovanni Petris  <GPetris at uark.edu>
Associate Professor
Department of Mathematical Sciences
University of Arkansas - Fayetteville, AR 72701
Ph: (479) 575-6324, 575-8630 (fax)
http://definetti.uark.edu/~gpetris/


From g_smits at verizon.net  Sat Sep  8 00:32:07 2007
From: g_smits at verizon.net (Gerard Smits)
Date: Fri, 07 Sep 2007 15:32:07 -0700
Subject: [R] R first.id last.id function error
Message-ID: <0JO0008GORXN14FB@vms046.mailsrvcs.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070907/270cb526/attachment.pl 

From phhs80 at gmail.com  Sat Sep  8 00:40:23 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Fri, 7 Sep 2007 23:40:23 +0100
Subject: [R] Optimization under an absolute value constraint
In-Reply-To: <9896.47211.qm@web81510.mail.mud.yahoo.com>
References: <9896.47211.qm@web81510.mail.mud.yahoo.com>
Message-ID: <6ade6f6c0709071540h70aef86fwac6ac5574cf034cf@mail.gmail.com>

On 9/7/07, Phil Xiang <pxxiang at yahoo.com> wrote:
> I need to optimize a multivariate function f(w, x, y, z, ...) under an absolute value constraint. For instance:
>
>     min { (2x+y) (w-z) }
>
> under the constraint:
>
>     |w| +  |x| + |y| + |z| = 1.0 .
>
> Is there any R function that does this? Thank you for your help!

I think that the minimum value of the function

f(x) :=  -2*x*(1-x), with 0 <= x <= 1

is also the minimum value of the objective function of your problem
(but correct me if I am wrong). Thus,

x	y	w	z
-0.5	0	0	-0.5
-0.5	0	0.1	-0.4
-0.5	0	0.3	-0.2
0.5	0	-0.5	0
-0.5	0	0.5	0
0.5	0	-0.4	0.1
0.5	0	-0.2	0.3
0.5	0	0	0.5

are all solutions for your problem.

Paul


From jay.pare at gmail.com  Sat Sep  8 01:01:22 2007
From: jay.pare at gmail.com (lawnboy34)
Date: Fri, 7 Sep 2007 16:01:22 -0700 (PDT)
Subject: [R] Plotting lines to sets of points
Message-ID: <12564704.post@talk.nabble.com>


I am using R to plot baseball spray charts from play-by-play data. I have
used the following command to plot the diamond:

plot (0:250, -250:0, type="n", bg="white")
	lines(c(125,150,125,100,125),c(-210,-180,-150,-180,-210), col=c("black"))

I have also plotted different hit locations using commands such as the
following:

points(subset(framename$hit_x, framename$hit_traj=="line_drive"),
subset(-framename$hit_y, framename$hit_traj=="line_drive"), pch=20,
col=c("red"))

My question: Is there any easy way to plot a line from the origin (home
plate) to each point on the graph? Preferably the line would share the same
color as the dot that denotes where the ball landed. I have tried searching
Google and these forums, and most graphing questions have to do with
scatterplots or other varieties of graphs I am not using. Thanks very much
in advance.

-Jason
-- 
View this message in context: http://www.nabble.com/Plotting-lines-to-sets-of-points-tf4404235.html#a12564704
Sent from the R help mailing list archive at Nabble.com.


From mmeredith at wcs.org  Sat Sep  8 02:16:52 2007
From: mmeredith at wcs.org (Mike Meredith)
Date: Fri, 7 Sep 2007 17:16:52 -0700 (PDT)
Subject: [R] negative value for AIC and BIC
In-Reply-To: <3d35a2ca0709070232m4d3f6059jdcbc297592eff141@mail.gmail.com>
References: <46E11517.1030203@avignon.inra.fr>
	<3d35a2ca0709070232m4d3f6059jdcbc297592eff141@mail.gmail.com>
Message-ID: <12565296.post@talk.nabble.com>


Sure -2*log(x) can be negative, and it can outweigh the k*npar term. Just do:

curve(-2*log(x)+2, 0.1, 10)  # for AIC with npar = 1
abline(h=0, v=exp(1), lty=3)

However, that only happens for x > exp(1) or even bigger if npar > 1. I
think Olivier's real question is: do we believe in likelihoods > 1 ?

Cheers, Mike.



Hannu Kahra wrote:
> 
> Olivier,
> 
> type ?AIC and have a look at the description
> 
> Description:
> 
>      Generic function calculating the Akaike information criterion for
>      one or several fitted model objects for which a log-likelihood
>      value can be obtained, according to the formula -2*log-likelihood
>      + k*npar, where npar represents the number of parameters in the
>      fitted model, and k = 2 for the usual AIC, or k = log(n) (n the
>      number of observations) for the so-called BIC or SBC (Schwarz's
>      Bayesian criterion).
> 
> AIC = -2*log-likelihood + k*npar can be negative as SBC, too.
> 
> Hannu
> 
> On 9/7/07, Olivier MARTIN <olivier.martin at avignon.inra.fr> wrote:
>>
>> Hi all,
>>
>>
>> I obtained negative values for AIC and BIC criteria for a particular
>> model that I have
>> developped...
>>
>> I don't remember to have negative values for these crietria for others
>> applications, so I am a
>> little suprised... Could anyone tell me if something is wrong or his
>> conclusion concerning my model?
>>
>> Best regards,
>> Olivier.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/negative-value-for-AIC-and-BIC-tf4400285.html#a12565296
Sent from the R help mailing list archive at Nabble.com.


From shukai at seas.upenn.edu  Sat Sep  8 02:37:18 2007
From: shukai at seas.upenn.edu (kevinchang)
Date: Fri, 7 Sep 2007 17:37:18 -0700 (PDT)
Subject: [R] remove particular elements in a vector
Message-ID: <12565480.post@talk.nabble.com>


Hi, 

Is there any build-in function allowing us to remove a particular group of
elements in a vector? 

For example, if I want to remove all the "NA" in the output of "answer"
function . Please help. Thanks

 answer(100) 
  [1]  1  2 NA  4 NA NA  7  8 NA NA 11 NA 13 14 NA 16 17 NA 19 NA NA 22 23
NA NA
 [26] 26 NA 28 29 NA 31 32 NA 34 NA NA 37 38 NA NA 41 NA 43 44 NA 46 47 NA
49 NA
 [51] NA 52 53 NA NA 56 NA 58 59 NA 61 62 NA 64 NA NA 67 68 NA NA 71 NA 73
74 NA
 [76] 76 77 NA 79 NA NA 82 83 NA NA 86 NA 88 89 NA 91 92 NA 94 NA NA 97 98
NA NA

-- 
View this message in context: http://www.nabble.com/remove-particular-elements-in-a-vector-tf4404489.html#a12565480
Sent from the R help mailing list archive at Nabble.com.


From liuwensui at gmail.com  Sat Sep  8 02:41:50 2007
From: liuwensui at gmail.com (Wensui Liu)
Date: Fri, 7 Sep 2007 19:41:50 -0500
Subject: [R] sqldf rocks
Message-ID: <1115a2b00709071741w3aa2f69n8af06fc951d0e09@mail.gmail.com>

Man,
I love this package and the guy who contributes it!


-- 
===============================
"I am dying with the help of too many
physicians." - Alexander the Great, on his deathbed
===============================
WenSui Liu
(http://spaces.msn.com/statcompute/blog)


From cberry at tajo.ucsd.edu  Sat Sep  8 02:45:06 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Fri, 7 Sep 2007 17:45:06 -0700
Subject: [R] Running a PERL script from R
In-Reply-To: <0D23978FCA08B2499683B67DADE76B0102221B@SAGE.forestry.oregonstate.edu>
References: <0D23978FCA08B2499683B67DADE76B0102221A@SAGE.forestry.oregonstate.edu>
	<20070907201048.GB14851@eddelbuettel.com>
	<0D23978FCA08B2499683B67DADE76B0102221B@SAGE.forestry.oregonstate.edu>
Message-ID: <Pine.LNX.4.64.0709071741320.7043@tajo.ucsd.edu>

On Fri, 7 Sep 2007, Pierce, Ken wrote:

> I've tried various configurations of .script, system and shell to no
> avail. It seems to pause and run "something" but then no output is
> created.

Works for me:

> cat( 'print "Hello World\n";',file="hello.pl" )
> system("perl hello.pl")
Hello World
>

Maybe a path issue?

>
> -----Original Message-----
> From: Dirk Eddelbuettel [mailto:edd at debian.org]
> Sent: Friday, September 07, 2007 1:11 PM
> To: Pierce, Ken
> Cc: r-help
> Subject: Re: [R] Running a PERL script from R
>
> On Fri, Sep 07, 2007 at 12:15:51PM -0700, Pierce, Ken wrote:
>> Is there a way to run a simple perl script from R?
>
> ?system
>
> Hth, Dirk
>
> --
> Three out of two people have difficulties with fractions.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From cberry at tajo.ucsd.edu  Sat Sep  8 03:12:08 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Fri, 7 Sep 2007 18:12:08 -0700
Subject: [R] How to obtain parameters of a mixture model of two
 lognormal distributions
In-Reply-To: <787911d50709071404x2deefc1cg6795034f7c23ffec@mail.gmail.com>
References: <787911d50709071404x2deefc1cg6795034f7c23ffec@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709071754160.7043@tajo.ucsd.edu>

On Fri, 7 Sep 2007, Jacques Wagnor wrote:

> Dear List,
>
> I have read that a lognormal mixture model having a pdf of the form
> f(x)=w1*f1(x)+(1-w1)*f2(x) fits most data sets quite well, where f1
> and f2 are lognormal distributions.

Whoa! There have to be a lot of qualifiers on an assertion like that!!

It will not fit these data well:

 	y <- rnorm(100)

>
> Any pointers on how to create a function that would produce the 5
> parameters of f(x) would be greatly appreciated.


Produce? Do you mean _estimate_ perchance?

The usual advice:

 	Read the posting guide and follow the advice there, which would
 	include trying stuff like the following...

 	?lognormal # fails but suggests help.search("lognormal")

 	help.search("lognormal") # bingo! It was 'Lognormal' I needed

 	?Lognormal # now read the help page and find dlnorm

 	RSiteSearch("fit mixture")

 	help.search("mle")

 	and so on.

And isn't a mixture of lognormals also a mixture of normals if you log 
transform the data? ;-)

If so, you are almost done, thanks to the hits in RSiteSearch("fit mixture").

Chuck

p.s. if all you want is to 'fit data', try the logspline package or any of 
the other density estimation tools in R or on CRAN.

>
>> version
>               _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          5.1
> year           2007
> month          06
> day            27
> svn rev        42083
> language       R
> version.string R version 2.5.1 (2007-06-27)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From anup_nandialath at yahoo.com  Sat Sep  8 03:26:51 2007
From: anup_nandialath at yahoo.com (Anup Nandialath)
Date: Fri, 7 Sep 2007 18:26:51 -0700 (PDT)
Subject: [R] Problem with the aggregate command
Message-ID: <909072.80841.qm@web53301.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070907/b59492ef/attachment.pl 

From jholtman at gmail.com  Sat Sep  8 03:30:59 2007
From: jholtman at gmail.com (jim holtman)
Date: Fri, 7 Sep 2007 21:30:59 -0400
Subject: [R] R first.id last.id function error
In-Reply-To: <0JO0008GORXN14FB@vms046.mailsrvcs.net>
References: <0JO0008GORXN14FB@vms046.mailsrvcs.net>
Message-ID: <644e1f320709071830p3e8fd0bch7e32c41ab20f2c5d@mail.gmail.com>

This function should do it for you:


> file1 <- read.table(textConnection("   id rx week dv1
+ 1   1  1    1   1
+ 2   1  1    2   1
+ 3   1  1    3   2
+ 4   2  1    1   3
+ 5   2  1    2   4
+ 6   2  1    3   1
+ 7   3  1    1   2
+ 8   3  1    2   3
+ 9   3  1    3   4
+ 10  4  1    1   2
+ 11  4  1    2   6
+ 12  4  1    3   5
+ 13  5  2    1   7
+ 14  5  2    2   8
+ 15  5  2    3   5
+ 16  6  2    1   2
+ 17  6  2    2   4
+ 18  6  2    3   6
+ 19  7  2    1   7
+ 20  7  2    2   8
+ 21  8  2    1   9
+ 22  9  2    1   4
+ 23  9  2    2   5"), header=TRUE)
>
> mark.function <-
+ function(df){
+     df <- df[order(df$id, df$week),]
+     # create 'diff' of 'id' to determine where the breaks are
+     breaks <- diff(df$id)
+     # the first entry will be TRUE, and then every occurance of
non-zero in breaks
+     df$first.id <- c(TRUE, breaks != 0)
+     # the last entry is TRUE and every non-zero breaks
+     df$last.id <- c(breaks != 0, TRUE)
+     df
+ }
>
> mark.function(file1)
   id rx week dv1 first.id last.id
1   1  1    1   1     TRUE   FALSE
2   1  1    2   1    FALSE   FALSE
3   1  1    3   2    FALSE    TRUE
4   2  1    1   3     TRUE   FALSE
5   2  1    2   4    FALSE   FALSE
6   2  1    3   1    FALSE    TRUE
7   3  1    1   2     TRUE   FALSE
8   3  1    2   3    FALSE   FALSE
9   3  1    3   4    FALSE    TRUE
10  4  1    1   2     TRUE   FALSE
11  4  1    2   6    FALSE   FALSE
12  4  1    3   5    FALSE    TRUE
13  5  2    1   7     TRUE   FALSE
14  5  2    2   8    FALSE   FALSE
15  5  2    3   5    FALSE    TRUE
16  6  2    1   2     TRUE   FALSE
17  6  2    2   4    FALSE   FALSE
18  6  2    3   6    FALSE    TRUE
19  7  2    1   7     TRUE   FALSE
20  7  2    2   8    FALSE    TRUE
21  8  2    1   9     TRUE    TRUE
22  9  2    1   4     TRUE   FALSE
23  9  2    2   5    FALSE    TRUE
>
>


On 9/7/07, Gerard Smits <g_smits at verizon.net> wrote:
> Hi R users,
>
> I have a test dataframe ("file1," shown below) for which I am trying
> to create a flag for the first and last ID record (equivalent to SAS
> first.id and last.id variables.
>
> Dump of file1:
>
>  > file1
>    id rx week dv1
> 1   1  1    1   1
> 2   1  1    2   1
> 3   1  1    3   2
> 4   2  1    1   3
> 5   2  1    2   4
> 6   2  1    3   1
> 7   3  1    1   2
> 8   3  1    2   3
> 9   3  1    3   4
> 10  4  1    1   2
> 11  4  1    2   6
> 12  4  1    3   5
> 13  5  2    1   7
> 14  5  2    2   8
> 15  5  2    3   5
> 16  6  2    1   2
> 17  6  2    2   4
> 18  6  2    3   6
> 19  7  2    1   7
> 20  7  2    2   8
> 21  8  2    1   9
> 22  9  2    1   4
> 23  9  2    2   5
>
> I have written code that correctly assigns the first.id and last.id variabes:
>
> require(Hmisc)  #for Lags
> #ascending order to define first dot
> file1<- file1[order(file1$id, file1$week),]
> file1$first.id <- (Lag(file1$id) != file1$id)
> file1$first.id[1]<-TRUE      #force NA to TRUE
>
> #descending order to define last dot
> file1<- file1[order(-file1$id,-file1$week),]
> file1$last.id  <- (Lag(file1$id) != file1$id)
> file1$last.id[1]<-TRUE       #force NA to TRUE
>
> #resort to original order
> file1<- file1[order(file1$id,file1$week),]
>
>
>
> I am now trying to get the above code to work as a function, and am
> clearly doing something wrong:
>
>  > first.last <- function (df, idvar, sortvars1, sortvars2)
> +   {
> +   #sort in ascending order to define first dot
> +   df<- df[order(sortvars1),]
> +   df$first.idvar <- (Lag(df$idvar) != df$idvar)
> +   #force first record NA to TRUE
> +   df$first.idvar[1]<-TRUE
> +
> +   #sort in descending order to define last dot
> +   df<- df[order(-sortvars2),]
> +   df$last.idvar  <- (Lag(df$idvar) != df$idvar)
> +   #force last record NA to TRUE
> +   df$last.idvar[1]<-TRUE
> +
> +   #resort to original order
> +   df<- df[order(sortvars1),]
> +   }
>  >
>
> Function call:
>
>  > first.last(df=file1, idvar=file1$id,
> sortvars1=c(file1$id,file1$week), sortvars2=c(-file1$id,-file1$week))
>
> R Error:
>
> Error in as.vector(x, mode) : invalid argument 'mode'
>  >
>
> I am not sure about the passing of the sort strings.  Perhaps this is
> were things are off.  Any help greatly appreciated.
>
> Thanks,
>
> Gerard
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From jholtman at gmail.com  Sat Sep  8 03:34:16 2007
From: jholtman at gmail.com (jim holtman)
Date: Fri, 7 Sep 2007 21:34:16 -0400
Subject: [R] Plotting lines to sets of points
In-Reply-To: <12564704.post@talk.nabble.com>
References: <12564704.post@talk.nabble.com>
Message-ID: <644e1f320709071834j55d1f181w1646cbd5fd5dd71f@mail.gmail.com>

?segments

On 9/7/07, lawnboy34 <jay.pare at gmail.com> wrote:
>
> I am using R to plot baseball spray charts from play-by-play data. I have
> used the following command to plot the diamond:
>
> plot (0:250, -250:0, type="n", bg="white")
>        lines(c(125,150,125,100,125),c(-210,-180,-150,-180,-210), col=c("black"))
>
> I have also plotted different hit locations using commands such as the
> following:
>
> points(subset(framename$hit_x, framename$hit_traj=="line_drive"),
> subset(-framename$hit_y, framename$hit_traj=="line_drive"), pch=20,
> col=c("red"))
>
> My question: Is there any easy way to plot a line from the origin (home
> plate) to each point on the graph? Preferably the line would share the same
> color as the dot that denotes where the ball landed. I have tried searching
> Google and these forums, and most graphing questions have to do with
> scatterplots or other varieties of graphs I am not using. Thanks very much
> in advance.
>
> -Jason
> --
> View this message in context: http://www.nabble.com/Plotting-lines-to-sets-of-points-tf4404235.html#a12564704
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From anup_nandialath at yahoo.com  Sat Sep  8 03:34:43 2007
From: anup_nandialath at yahoo.com (Anup Nandialath)
Date: Fri, 7 Sep 2007 18:34:43 -0700 (PDT)
Subject: [R] Problem with the Aggregate command (PS)
Message-ID: <375583.74861.qm@web53304.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070907/b3a7368e/attachment.pl 

From jholtman at gmail.com  Sat Sep  8 03:36:32 2007
From: jholtman at gmail.com (jim holtman)
Date: Fri, 7 Sep 2007 21:36:32 -0400
Subject: [R] remove particular elements in a vector
In-Reply-To: <12565480.post@talk.nabble.com>
References: <12565480.post@talk.nabble.com>
Message-ID: <644e1f320709071836q703b14e4p7e7364caded303f6@mail.gmail.com>

x <- answer(100)
x <- x[!is.na(x)]  # remove NAs

On 9/7/07, kevinchang <shukai at seas.upenn.edu> wrote:
>
> Hi,
>
> Is there any build-in function allowing us to remove a particular group of
> elements in a vector?
>
> For example, if I want to remove all the "NA" in the output of "answer"
> function . Please help. Thanks
>
>  answer(100)
>  [1]  1  2 NA  4 NA NA  7  8 NA NA 11 NA 13 14 NA 16 17 NA 19 NA NA 22 23
> NA NA
>  [26] 26 NA 28 29 NA 31 32 NA 34 NA NA 37 38 NA NA 41 NA 43 44 NA 46 47 NA
> 49 NA
>  [51] NA 52 53 NA NA 56 NA 58 59 NA 61 62 NA 64 NA NA 67 68 NA NA 71 NA 73
> 74 NA
>  [76] 76 77 NA 79 NA NA 82 83 NA NA 86 NA 88 89 NA 91 92 NA 94 NA NA 97 98
> NA NA
>
> --
> View this message in context: http://www.nabble.com/remove-particular-elements-in-a-vector-tf4404489.html#a12565480
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From jholtman at gmail.com  Sat Sep  8 03:42:59 2007
From: jholtman at gmail.com (jim holtman)
Date: Fri, 7 Sep 2007 21:42:59 -0400
Subject: [R] Problem with the aggregate command
In-Reply-To: <909072.80841.qm@web53301.mail.re2.yahoo.com>
References: <909072.80841.qm@web53301.mail.re2.yahoo.com>
Message-ID: <644e1f320709071842l185ef850kcfb57d73994a6855@mail.gmail.com>

Your 'lst' is not the same length as either set1 or set2.  If one of
your columns in the dataframe is the year, then you should have:

aggregate(set1, set1$year, median)

On 9/7/07, Anup Nandialath <anup_nandialath at yahoo.com> wrote:
> Dear friends,
>
> I have a data set with 23 columns and 38000 rows. It is a panel running from the years 1991 through 2005. I want to aggregate the data and get the medians of each of the 23 columns for each of the years. In other words my output should be like this
>
> Year     Median
>
> 1991        123
> 1992        145
> 1993        132
>
> etc.
>
> The sample lines of code to do this operation is
>
> set1 <- subset(as.data.frame(dataset),rep1==1)
> set2 <- subset(as.data.frame(dataset),rep1==0)
> lst <- list(unique(yeara))
>
> y1 <- aggregate(set1,lst,median)
> y2 <- aggregate(set2,lst,median)
>
> However I'm getting an error as follows
> Error in FUN(X[[1]], ...) : arguments must have same length
>
> Can somebody please help me with what I'm doing wrong here?
>
> Thanks in advance
> Regards
>
> Anup
>
>
>
>
> ---------------------------------
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From pinard at iro.umontreal.ca  Sat Sep  8 04:03:23 2007
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Fri, 7 Sep 2007 22:03:23 -0400
Subject: [R] Lisp-like primitives in R
In-Reply-To: <46E09444.8040403@stats.uwo.ca>
References: <04C44D9F040C8A43A18D04F65A8B68BBD9E757@spatcex001.spadac.com>
	<07E228A5BE53C24CAD490193A7381BBBBB4053@LP-EXCHVS07.CO.IHC.COM>
	<20070906221043.GA5648@alcyon.progiciels-bpi.ca>
	<46E08F17.20505@gmail.com> <46E09444.8040403@stats.uwo.ca>
Message-ID: <20070908020323.GF5397@phenix.progiciels-bpi.ca>

[Duncan Murdoch]

>You could also look at Ross Ihaka's paper that is online here:

>http://cran.r-project.org/doc/html/interface98-paper/paper.html

Interesting read.  Thanks for this reference!

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From pinard at iro.umontreal.ca  Sat Sep  8 04:20:13 2007
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Fri, 7 Sep 2007 22:20:13 -0400
Subject: [R] Lisp-like primitives in R
In-Reply-To: <46E08F17.20505@gmail.com>
References: <04C44D9F040C8A43A18D04F65A8B68BBD9E757@spatcex001.spadac.com>
	<07E228A5BE53C24CAD490193A7381BBBBB4053@LP-EXCHVS07.CO.IHC.COM>
	<20070906221043.GA5648@alcyon.progiciels-bpi.ca>
	<46E08F17.20505@gmail.com>
Message-ID: <20070908022013.GG5397@phenix.progiciels-bpi.ca>

[Roland Rau]
>[Fran?ois Pinard]

>>I wonder what happened, for R to hide the underlying Scheme so fully, 
>>at least at the level of the surface language (despite there are 
>>hints).  

>"To further foster portability, we chose to write R in ANSI C...."

Yes, of course.  Scheme is also (often) implemented in C.  I meant that 
R might have implemented a Scheme engine (or part of a Scheme engine, 
extended with appropriate data types) with a surface language (nearly 
the S language) which is purposely not Scheme, but could have been.

If the gap is not extreme, one could dare dreaming that the Scheme 
engine in R be "completed", and Scheme offered as an alternate extension 
language.  If you allow me to continue dreaming awake -- "they" told me 
"they" will let me free as long as I do not get dangerous! :-) -- part 
of the interest lies in the fact there are excellent Scheme compilers.  
If we could only find or devise some kind of marriage between a mature 
Scheme and R, so to speed up the non-vectorisable parts of R scripts...

>If we are lucky and one of the original authors reads this thread they 
>might explain the situation further and better [...].

In r-devel, maybe!  We would be lucky if the authors really had time to 
read r-help. :-)

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From ggrothendieck at gmail.com  Sat Sep  8 04:29:34 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 7 Sep 2007 22:29:34 -0400
Subject: [R] R first.id last.id function error
In-Reply-To: <0JO0008GORXN14FB@vms046.mailsrvcs.net>
References: <0JO0008GORXN14FB@vms046.mailsrvcs.net>
Message-ID: <971536df0709071929q3aee3d4cu46abf8f500c4bc7b@mail.gmail.com>

A slightly easier way to construct first and last if the vector x is
sorted (as is assumed in SAS) is:

   first <- !duplicated(x)
   last <- !duplicated(x, fromLast = TRUE)

where the fromLast= argument is added in R 2.6.0.


On 9/7/07, Gerard Smits <g_smits at verizon.net> wrote:
> Hi R users,
>
> I have a test dataframe ("file1," shown below) for which I am trying
> to create a flag for the first and last ID record (equivalent to SAS
> first.id and last.id variables.
>
> Dump of file1:
>
>  > file1
>    id rx week dv1
> 1   1  1    1   1
> 2   1  1    2   1
> 3   1  1    3   2
> 4   2  1    1   3
> 5   2  1    2   4
> 6   2  1    3   1
> 7   3  1    1   2
> 8   3  1    2   3
> 9   3  1    3   4
> 10  4  1    1   2
> 11  4  1    2   6
> 12  4  1    3   5
> 13  5  2    1   7
> 14  5  2    2   8
> 15  5  2    3   5
> 16  6  2    1   2
> 17  6  2    2   4
> 18  6  2    3   6
> 19  7  2    1   7
> 20  7  2    2   8
> 21  8  2    1   9
> 22  9  2    1   4
> 23  9  2    2   5
>
> I have written code that correctly assigns the first.id and last.id variabes:
>
> require(Hmisc)  #for Lags
> #ascending order to define first dot
> file1<- file1[order(file1$id, file1$week),]
> file1$first.id <- (Lag(file1$id) != file1$id)
> file1$first.id[1]<-TRUE      #force NA to TRUE
>
> #descending order to define last dot
> file1<- file1[order(-file1$id,-file1$week),]
> file1$last.id  <- (Lag(file1$id) != file1$id)
> file1$last.id[1]<-TRUE       #force NA to TRUE
>
> #resort to original order
> file1<- file1[order(file1$id,file1$week),]
>
>
>
> I am now trying to get the above code to work as a function, and am
> clearly doing something wrong:
>
>  > first.last <- function (df, idvar, sortvars1, sortvars2)
> +   {
> +   #sort in ascending order to define first dot
> +   df<- df[order(sortvars1),]
> +   df$first.idvar <- (Lag(df$idvar) != df$idvar)
> +   #force first record NA to TRUE
> +   df$first.idvar[1]<-TRUE
> +
> +   #sort in descending order to define last dot
> +   df<- df[order(-sortvars2),]
> +   df$last.idvar  <- (Lag(df$idvar) != df$idvar)
> +   #force last record NA to TRUE
> +   df$last.idvar[1]<-TRUE
> +
> +   #resort to original order
> +   df<- df[order(sortvars1),]
> +   }
>  >
>
> Function call:
>
>  > first.last(df=file1, idvar=file1$id,
> sortvars1=c(file1$id,file1$week), sortvars2=c(-file1$id,-file1$week))
>
> R Error:
>
> Error in as.vector(x, mode) : invalid argument 'mode'
>  >
>
> I am not sure about the passing of the sort strings.  Perhaps this is
> were things are off.  Any help greatly appreciated.
>
> Thanks,
>
> Gerard
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Kaom.Te at schwab.com  Sat Sep  8 05:00:47 2007
From: Kaom.Te at schwab.com (Te, Kaom)
Date: Fri, 7 Sep 2007 20:00:47 -0700
Subject: [R] ggplot legend consolidation
Message-ID: <9A1F9BE796CFED43AAD05E0523BB31DF05A97B3F@nex2003cdc.us.global.schwab.com>

Hello Everyone,
 
I have recently been introduced to the ggplot package by Hadley Wickham
and must say I am quite impressed so far at how easy it is to make
attractive plots, but one thing I am struggling over is how to
consolidate legends.
 
I have 3 plots that I would like to put on a single page and all 3 map
the same dimension of the data to the colour aesthetic.  Right now, when
I plot all three graphs on the page, I get the three graphs and three
legends. The legends are exactly the same.  I do not see a reason to
have all 3 legends and I would like to partition a section of the page
exclusively for a single legend that would apply to all graphs. 
 
How does one exract the legend for this purpose?
Does anyone know how to do this with the ggplot package?
 
Here is some example code:
------------------------------- BEGIN CODE
library(ggplot2)
data(mtcars)
 
grid.newpage()
 
pushViewport(viewport(layout = grid.layout(2, 2)))
 
p <- ggplot(data = mtcars) +
  geom_point(mapping = aes(x = hp, y = mpg, colour = cyl))
 
pushViewport(viewport(layout.pos.col = 1,
                      layout.pos.row = 1))
 
print(p, vp = current.viewport())
upViewport()
 
p <- ggplot(data = mtcars) +
  geom_point(mapping = aes(x = drat, y = disp, colour = cyl))
 

pushViewport(viewport(layout.pos.col = 2,
                      layout.pos.row = 1))
 
print(p, vp = current.viewport())
upViewport()
 
p <- ggplot(data = mtcars) +
  geom_point(mapping = aes(x = qsec, y = mpg, colour = cyl))
 
pushViewport(viewport(layout.pos.col = 1,
                      layout.pos.row = 2))
 
print(p, vp = current.viewport())
upViewport()

pushViewport(viewport(layout.pos.col = 2,
                      layout.pos.row = 2))
grid.rect()
grid.text("We want to remove\nall other legends\nand place a\nsingle one
here")
------------------------------- END CODE
 
See how there are 3 legends when there only needs to be one?   I would
like to remove the 3 legends and place them with a single legend in the
space in the lower right.
 
Thanks for your help.
 
Regards,
Kaom Te

Charles Schwab Investment Management (CSIM)
120 Kearny Street, 14th Floor
San Francisco, CA 94108
E-mail: kaom.te at schwab.com <mailto:kaom.te at schwab.com> 
 
WARNING: All email sent to or from the Charles Schwab corporate email
system is subject to archiving, monitoring and/or review by Schwab
personnel.


From tkobayas at indiana.edu  Sat Sep  8 08:04:22 2007
From: tkobayas at indiana.edu (Takatsugu Kobayashi)
Date: Sat, 08 Sep 2007 02:04:22 -0400
Subject: [R] SQL like function?
In-Reply-To: <971536df0709070447x26b8146fyf5a88d051a3bb798@mail.gmail.com>
References: <46E0D627.2010904@indiana.edu>
	<971536df0709070447x26b8146fyf5a88d051a3bb798@mail.gmail.com>
Message-ID: <46E23B66.3080102@indiana.edu>

Hi Gabor,

Wow, this is awesome.... although I eventually should learn MySQL for 
integrating it on web-based DB management using PHP or Perl, this is a 
very helpful tool for me to start with!

Thank you very much!!!!

Gabor Grothendieck wrote:
> Others have already pointed out %in% but regarding your comment about
> SQL, you can use SQL to manipulate R data frames using the sqldf package
> which provides an interface to lower level RSQLite (and RMySQL in the future)
> routines.  The following examples use SQLite underneath:
>
> DF <- data.frame(observation = c(1,2,3,4,5))
> ID <- data.frame(ID = c(1, 3, 4))
>
> library(sqldf)
> sqldf("select observation, observation in (select * from ID) `ID?` from DF")
>
> # or
>
> sqldf("select observation, observation in (1, 3, 4) `ID?` from DF")
>
> See home page at:
>
> http://sqldf.googlecode.com
>
>
> On 9/7/07, Takatsugu Kobayashi <tkobayas at indiana.edu> wrote:
>   
>> Hi RUsers,
>>
>> I am wonder if I can search observations whose IDs matches any of the
>> values in another vector, such as in MySQL. While I am learing MySQL for
>> future database management, I appreciate if anyone could give me a hint.
>>
>> Suppose I have one 5*1 vector containing observation IDs and
>> frequencies, and one 3*1 vector containing observation IDs.
>>
>> observation<-c(1,2,3,4,5)
>> ID<-c(1,3,4)
>>
>> Then, I would like to program a code that returns a results showing
>> matched observations like
>>
>> result: TRUE FALSE TRUE TRUE FALSE
>>
>> I am reading S programming, but I cannot find a way to do this.
>>
>> Thank you very much.
>>
>> Taka
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>


From ggrothendieck at gmail.com  Sat Sep  8 08:37:18 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 8 Sep 2007 02:37:18 -0400
Subject: [R] SQL like function?
In-Reply-To: <46E23B66.3080102@indiana.edu>
References: <46E0D627.2010904@indiana.edu>
	<971536df0709070447x26b8146fyf5a88d051a3bb798@mail.gmail.com>
	<46E23B66.3080102@indiana.edu>
Message-ID: <971536df0709072337n5ce870d3x2a8ce1f57247524f@mail.gmail.com>

Great.  Regarding the web, note that there are actually quite a few R
web projects as well:

http://www.lmbe.seu.edu.cn/CRAN/doc/FAQ/R-FAQ.html#R-Web-Interfaces

I have used rpad (www.rpad.org) which has an integrated web server right
in the R package making setup a non-issue.

On 9/8/07, Takatsugu Kobayashi <tkobayas at indiana.edu> wrote:
> Hi Gabor,
>
> Wow, this is awesome.... although I eventually should learn MySQL for
> integrating it on web-based DB management using PHP or Perl, this is a
> very helpful tool for me to start with!
>
> Thank you very much!!!!
>
> Gabor Grothendieck wrote:
> > Others have already pointed out %in% but regarding your comment about
> > SQL, you can use SQL to manipulate R data frames using the sqldf package
> > which provides an interface to lower level RSQLite (and RMySQL in the future)
> > routines.  The following examples use SQLite underneath:
> >
> > DF <- data.frame(observation = c(1,2,3,4,5))
> > ID <- data.frame(ID = c(1, 3, 4))
> >
> > library(sqldf)
> > sqldf("select observation, observation in (select * from ID) `ID?` from DF")
> >
> > # or
> >
> > sqldf("select observation, observation in (1, 3, 4) `ID?` from DF")
> >
> > See home page at:
> >
> > http://sqldf.googlecode.com
> >
> >
> > On 9/7/07, Takatsugu Kobayashi <tkobayas at indiana.edu> wrote:
> >
> >> Hi RUsers,
> >>
> >> I am wonder if I can search observations whose IDs matches any of the
> >> values in another vector, such as in MySQL. While I am learing MySQL for
> >> future database management, I appreciate if anyone could give me a hint.
> >>
> >> Suppose I have one 5*1 vector containing observation IDs and
> >> frequencies, and one 3*1 vector containing observation IDs.
> >>
> >> observation<-c(1,2,3,4,5)
> >> ID<-c(1,3,4)
> >>
> >> Then, I would like to program a code that returns a results showing
> >> matched observations like
> >>
> >> result: TRUE FALSE TRUE TRUE FALSE
> >>
> >> I am reading S programming, but I cannot find a way to do this.
> >>
> >> Thank you very much.
> >>
> >> Taka
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
>
>


From p.dalgaard at biostat.ku.dk  Sat Sep  8 10:34:08 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 08 Sep 2007 10:34:08 +0200
Subject: [R] Lisp-like primitives in R
In-Reply-To: <20070908022013.GG5397@phenix.progiciels-bpi.ca>
References: <04C44D9F040C8A43A18D04F65A8B68BBD9E757@spatcex001.spadac.com>	<07E228A5BE53C24CAD490193A7381BBBBB4053@LP-EXCHVS07.CO.IHC.COM>	<20070906221043.GA5648@alcyon.progiciels-bpi.ca>	<46E08F17.20505@gmail.com>
	<20070908022013.GG5397@phenix.progiciels-bpi.ca>
Message-ID: <46E25E80.3090708@biostat.ku.dk>

Fran?ois Pinard wrote:
> [Roland Rau]
>   
>> [Fran?ois Pinard]
>>     
>
>   
>>> I wonder what happened, for R to hide the underlying Scheme so fully, 
>>> at least at the level of the surface language (despite there are 
>>> hints).  
>>>       
>
>   
>> "To further foster portability, we chose to write R in ANSI C...."
>>     
>
> Yes, of course.  Scheme is also (often) implemented in C.  I meant that 
> R might have implemented a Scheme engine (or part of a Scheme engine, 
> extended with appropriate data types) with a surface language (nearly 
> the S language) which is purposely not Scheme, but could have been.
>
> If the gap is not extreme, one could dare dreaming that the Scheme 
> engine in R be "completed", and Scheme offered as an alternate extension 
> language.  If you allow me to continue dreaming awake -- "they" told me 
> "they" will let me free as long as I do not get dangerous! :-) -- part 
> of the interest lies in the fact there are excellent Scheme compilers.  
> If we could only find or devise some kind of marriage between a mature 
> Scheme and R, so to speed up the non-vectorisable parts of R scripts...
>
>   
Well, depending on what you want, this is either trivial or 
impossible... The internal storage of R is still pretty much equivalent 
to scheme. E.g. try this:

 > r2scheme <- function(e) if (!is.recursive(e))
      deparse(e) else c("(", unlist(lapply(as.list(e), r2scheme)), ")")
 > paste(r2scheme(quote(for(i in 1:4)print(i))), collapse=" ")
[1] "( for i ( : 1 4 ) ( print i ) )"

and a parser that parses a similar language to R internal format is  not 
a very hard exercise (some care needed in places). However, replacing 
the front-end is not going to make anything faster, and the evaluation 
engine in R does a couple of tricks which are not done in Scheme, 
notably lazy evaluation, and other forms of non-local evaluation, which 
drives optimizers crazy. Look up the writings of Luke Tierney on the 
matter to learn more.

>> If we are lucky and one of the original authors reads this thread they 
>> might explain the situation further and better [...].
>>     
>
> In r-devel, maybe!  We would be lucky if the authors really had time to 
> read r-help. :-)
>
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From price_ja at hotmail.com  Sat Sep  8 00:13:01 2007
From: price_ja at hotmail.com (Jim Price)
Date: Fri, 7 Sep 2007 15:13:01 -0700 (PDT)
Subject: [R] enable object name to be called as object (a dataset)
In-Reply-To: <12563767.post@talk.nabble.com>
References: <12563767.post@talk.nabble.com>
Message-ID: <12564175.post@talk.nabble.com>


a <- 1:3
b <- 11:13
c <- 21:23

names <- c('a','b','c')

do.call(data.frame, list(sapply(names, function(x) get(x))))



runner wrote:
> 
> What I am trying to do is as follows:
> 
> - I have listed names of all wanted objects (datasets A,B,C... ) in
> current workspace as a vector: 
> 
> obj <- c('A','B','C')
> 
> - then i need to use these objects, say to extract all the 1st columns and
> bind to an existing dataset ('data'): 
>  
> for ( i in 1:3){
> newdata <- obj[i] 
> data <- cbind(data,newdata [[1]] )
> }
> 
> Obviously, it doesn't work since obj[i] is just a string of dataset name.
> Here is my question: how to call it as a original dataset? Thanks.
> 

-- 
View this message in context: http://www.nabble.com/enable-object-name-to-be-called-as-object-%28a-dataset%29-tf4403933.html#a12564175
Sent from the R help mailing list archive at Nabble.com.


From dsteinskog at hotmail.com  Fri Sep  7 10:25:19 2007
From: dsteinskog at hotmail.com (Dag J. Steinskog)
Date: Fri, 7 Sep 2007 01:25:19 -0700 (PDT)
Subject: [R] Covariates and clustering of extremes
Message-ID: <12538022.post@talk.nabble.com>


I am looking at some extremes, and I want to implement covariates in my
analysis. My work is on daily datasets, and I use the cluster of exceedences
approach in fpot (evd-package) to estimate the parameters in the General
Pareto Distribution. How to include covariates like e.g. time is my question
then.  

In advance, thanks for all help!


-- 
View this message in context: http://www.nabble.com/Covariates-and-clustering-of-extremes-tf4396856.html#a12538022
Sent from the R help mailing list archive at Nabble.com.


From uvtravel at hotmail.com  Fri Sep  7 15:00:12 2007
From: uvtravel at hotmail.com (uv)
Date: Fri, 7 Sep 2007 06:00:12 -0700 (PDT)
Subject: [R] Using clustering functions
Message-ID: <12554686.post@talk.nabble.com>


Hi. I need to use a few different clustering functions. I managed to run the
kmeans() one which is in my "stats" library, but I can't use any function,
such as agnes(), that is in my "cluster" library. Any idea how to access
other libraries? 
Thanks!
-- 
View this message in context: http://www.nabble.com/Using-clustering-functions-tf4401159.html#a12554686
Sent from the R help mailing list archive at Nabble.com.


From price_ja at hotmail.com  Sat Sep  8 01:30:11 2007
From: price_ja at hotmail.com (Jim Price)
Date: Fri, 7 Sep 2007 16:30:11 -0700 (PDT)
Subject: [R] Plotting lines to sets of points
In-Reply-To: <12564704.post@talk.nabble.com>
References: <12564704.post@talk.nabble.com>
Message-ID: <12564959.post@talk.nabble.com>


# Create a matrix of ball locations
# You'd do this using the calls within your points function
balls <- matrix(c(0,50,25,-150,-100,-50), ncol=2, byrow=F)


# Draw a line from the origin to each ball location
apply(balls, 1, function(x) lines(c(125, x[1]), c(-210, x[2]), col='red'))



A more complete example might loop over all the unique elements of
framename$hit_traj, and then run this procedure for each value with a
different colour, plotting both ball points and trajectories.



lawnboy34 wrote:
> 
> I am using R to plot baseball spray charts from play-by-play data. I have
> used the following command to plot the diamond:
> 
> plot (0:250, -250:0, type="n", bg="white")
> 	lines(c(125,150,125,100,125),c(-210,-180,-150,-180,-210), col=c("black"))
> 
> I have also plotted different hit locations using commands such as the
> following:
> 
> points(subset(framename$hit_x, framename$hit_traj=="line_drive"),
> subset(-framename$hit_y, framename$hit_traj=="line_drive"), pch=20,
> col=c("red"))
> 
> My question: Is there any easy way to plot a line from the origin (home
> plate) to each point on the graph? Preferably the line would share the
> same color as the dot that denotes where the ball landed. I have tried
> searching Google and these forums, and most graphing questions have to do
> with scatterplots or other varieties of graphs I am not using. Thanks very
> much in advance.
> 
> -Jason
> 

-- 
View this message in context: http://www.nabble.com/Plotting-lines-to-sets-of-points-tf4404235.html#a12564959
Sent from the R help mailing list archive at Nabble.com.


From martin.becker at mx.uni-saarland.de  Sat Sep  8 11:16:44 2007
From: martin.becker at mx.uni-saarland.de (Martin Becker)
Date: Sat, 08 Sep 2007 11:16:44 +0200
Subject: [R] FW: variable format
In-Reply-To: <46E19D6C.6080807@vanderbilt.edu>
References: <6EBEA5B72E9B02428F2DD71D9DBC6EDF31939D@AKOYASRV01.akoyainc.local>	<6EBEA5B72E9B02428F2DD71D9DBC6EDF31939E@AKOYASRV01.akoyainc.local>
	<46E1745A.2000308@mx.uni-saarland.de>
	<46E19D6C.6080807@vanderbilt.edu>
Message-ID: <46E2687C.1080608@mx.uni-saarland.de>

Frank E Harrell Jr wrote:
> Martin Becker wrote:
>> Dear Cory,
>>
>> I am not familiar with SAS, but is this what you are looking for?
>>
>> divisionTable <- matrix(c(1, "New England",
>>                           2, "Middle Atlantic",
>>                           3, "East North Central",
>>                           4, "West North Central",
>>                           5, "South Atlantic",
>>                           6, "East South Central",
>>                           7, "West South Central",
>>                           8, "Mountain",
>>                           9, "Pacific"),
>>                         ncol=2, byrow=T)
>
> How about just divisionTable <- c('New England', 'Middle Atlantic', 
> ...) then factor(old, 1:9, divisionTable) ?
>
> Frank
>

Of course, this solution is more elegant, but my intention was
1. to provide a solution which makes use of the exisiting object 
"divisionTable"
2. to reproduce the output from the working example (->conversion to 
character)
Maybe I should have emphasized that I was quoting the existing 
definition of divisionTable from the original email (for the sake of 
providing self-contained code) and not introducing a unnecessarily 
complicated new definition of divisionTable.

Regards,

 Martin

>> a <- NULL
>> a$divisionOld <- c(0,1,2,3,4,5)
>> a$divisionNew <- 
>> as.character(factor(a$divisionOld,levels=divisionTable[,1],labels=divisionTable[,2])) 
>>
>> a$divisionNew
>>
>> [1] NA                   "New England"        "Middle Atlantic"  [4] 
>> "East North Central" "West North Central" "South Atlantic"
>>
>> Kind regards,
>>
>>   Martin
>>
>>
>> Cory Nissen schrieb:
>>>     
>>> Anybody? 
>>>
>>> ________________________________
>>>
>>> From: Cory Nissen
>>> Sent: Tue 9/4/2007 9:30 AM
>>> To: r-help at stat.math.ethz.ch
>>> Subject: variable format
>>>
>>>
>>> Okay, I want to do something similar to SAS proc format.
>>>
>>> I usually do this...
>>>
>>> a <- NULL
>>> a$divisionOld <- c(1,2,3,4,5)
>>> divisionTable <- matrix(c(1, "New England",
>>>                           2, "Middle Atlantic",
>>>                           3, "East North Central",
>>>                           4, "West North Central",
>>>                           5, "South Atlantic"),
>>>                         ncol=2, byrow=T)
>>> a$divisionNew[match(a$divisionOld, divisionTable[,1])] <- 
>>> divisionTable[,2]
>>>
>>> But how do I handle the case where...
>>> a$divisionOld <- c(0,1,2,3,4,5)   #no format available for 0, this 
>>> throws an error.
>>> OR
>>> divisionTable <- matrix(c(1, "New England",
>>>                           2, "Middle Atlantic",
>>>                           3, "East North Central",
>>>                           4, "West North Central",
>>>                           5, "South Atlantic",
>>>                           6, "East South Central",
>>>                           7, "West South Central",
>>>                           8, "Mountain",
>>>                           9, "Pacific"),
>>>                         ncol=2, byrow=T)   There are extra formats 
>>> available... this throws a warning.
>>>
>>> Thanks
>>>
>>> Cory
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


From maechler at stat.math.ethz.ch  Sat Sep  8 11:59:18 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 8 Sep 2007 11:59:18 +0200
Subject: [R] Matlab's lsqnonlin
In-Reply-To: <Pine.GSO.4.56.0709072002160.29719@laurel.few.vu.nl>
References: <46E199C5.4010609@decsai.ugr.es>
	<Pine.GSO.4.56.0709072002160.29719@laurel.few.vu.nl>
Message-ID: <18146.29302.359573.180008@stat.math.ethz.ch>

>>>>> "KateM" == Katharine Mullen <kate at few.vu.nl>
>>>>>     on Fri, 7 Sep 2007 20:07:41 +0200 (CEST) writes:

    KateM> The thread you linked to regarding Levenberg-Marquardt's supposed lack of
    KateM> availability is from 2001; it has been possible to get
    KateM> to the MINPACK implementation of Levenberg-Marquardt within R via the
    KateM> package minpack.lm
    KateM> (http://cran.r-project.org/src/contrib/Descriptions/minpack.lm.html) since
    KateM> 2005.

Thanks a lot, Kate.

I'm wondering about experiences:
Do you know of cases where  minpack.lm's  nls.lm() solved a
(real) problem that nls() would have a problem with ?

Beware however -- one of the main things I learned about this
field from Doug Bates, co-author of Bates_and_Watts and
prinicipal author of S's and R's nls() :
It's a *feature* that nls() does not converge sometimes when
other methods do falsely claim convergence!

Martin Maechler, ETH Zurich

    KateM> ----
    KateM> Katharine Mullen
    KateM> mail: Department of Physics and Astronomy, Faculty of Sciences
    KateM> Vrije Universiteit Amsterdam, de Boelelaan 1081
    KateM> 1081 HV Amsterdam, The Netherlands
    KateM> room: T.1.06
    KateM> tel: +31 205987870
    KateM> fax: +31 205987992
    KateM> e-mail: kate at nat.vu.nl
    KateM> homepage: http://www.nat.vu.nl/~kate/


    KateM> On Fri, 7 Sep 2007, Jose Luis Aznarte M. wrote:

    >> Hi! I'm translating some code from Matlab to R and I found a problem.
    >> I need to translate Matlab's function 'lsqnonlin'
    >> (http://www-ccs.ucsd.edu/matlab/toolbox/optim/lsqnonlin.html) into R,
    >> and at the beginning I  thought it would be the same as R's 'optim'. But
    >> then I looked at the definition of 'lsqnonlin' and I don't quite see how
    >> to make 'optim' to do the same thing. Does anyone have an idea?
    >> This is apart from the fact that I would like to use the Levenberg
    >> Marquardt algorithm which is not implemented in R (some discussion about
    >> this: http://tolstoy.newcastle.edu.au/R/help/00b/2492.html).
    >> Thank you! All the best,
    >> 
    >> 
    >> --                                                      --
    >> Jose Luis Aznarte M.       http://decsai.ugr.es/~jlaznarte
    >> Department of Computer Science and Artificial Intelligence
    >> Universidad de Granada           Tel. +34 - 958 - 24 04 67
    >> GRANADA (Spain)                  Fax: +34 - 958 - 24 00 79
    >> 
    >> ______________________________________________
    >> R-help at stat.math.ethz.ch mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.
    >> 

    KateM> ______________________________________________
    KateM> R-help at stat.math.ethz.ch mailing list
    KateM> https://stat.ethz.ch/mailman/listinfo/r-help
    KateM> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    KateM> and provide commented, minimal, self-contained, reproducible code.


From phhs80 at gmail.com  Sat Sep  8 12:26:44 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Sat, 8 Sep 2007 11:26:44 +0100
Subject: [R] argument 'lib' is missing: using '/usr/lib/R/library'
Message-ID: <6ade6f6c0709080326m18b109b1v54e501b37e54373b@mail.gmail.com>

Dear All,

When installing packages, I get the following warning:

> install.packages("sqldf")
Warning in install.packages("sqldf") : argument 'lib' is missing:
using '/usr/lib/R/library'

Any ideas?

The details of my R installation are:

> version
               _
platform       i386-redhat-linux-gnu
arch           i386
os             linux-gnu
system         i386, linux-gnu
status
major          2
minor          5.1
year           2007
month          06
day            27
svn rev        42083
language       R
version.string R version 2.5.1 (2007-06-27)
>

R is here installed on Fedora 7.

Thanks in advance,

Paul


From csardi at rmki.kfki.hu  Sat Sep  8 12:32:36 2007
From: csardi at rmki.kfki.hu (Gabor Csardi)
Date: Sat, 8 Sep 2007 12:32:36 +0200
Subject: [R] argument 'lib' is missing: using '/usr/lib/R/library'
In-Reply-To: <6ade6f6c0709080326m18b109b1v54e501b37e54373b@mail.gmail.com>
References: <6ade6f6c0709080326m18b109b1v54e501b37e54373b@mail.gmail.com>
Message-ID: <20070908103216.GA5863@localdomain>

Paul, what is the question? If the question is why you get this 
warning message, the reason is that the 'lib' argument is missing
and install.packages is using '/usr/lib/R/library'.

If you want to get rid of the warning supply the 'lib' argument.

Gabor

On Sat, Sep 08, 2007 at 11:26:44AM +0100, Paul Smith wrote:
> Dear All,
> 
> When installing packages, I get the following warning:
> 
> > install.packages("sqldf")
> Warning in install.packages("sqldf") : argument 'lib' is missing:
> using '/usr/lib/R/library'
> 
> Any ideas?
> 
> The details of my R installation are:
> 
> > version
>                _
> platform       i386-redhat-linux-gnu
> arch           i386
> os             linux-gnu
> system         i386, linux-gnu
> status
> major          2
> minor          5.1
> year           2007
> month          06
> day            27
> svn rev        42083
> language       R
> version.string R version 2.5.1 (2007-06-27)
> >
> 
> R is here installed on Fedora 7.
> 
> Thanks in advance,
> 
> Paul
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK


From reilly at stat.auckland.ac.nz  Sat Sep  8 12:34:33 2007
From: reilly at stat.auckland.ac.nz (James Reilly)
Date: Sat, 08 Sep 2007 22:34:33 +1200
Subject: [R] R survey package again
In-Reply-To: <681245.36636.qm@web38612.mail.mud.yahoo.com>
References: <681245.36636.qm@web38612.mail.mud.yahoo.com>
Message-ID: <46E27AB9.8040907@stat.auckland.ac.nz>


On 7/9/07 11:42 PM, eugen pircalabelu wrote:
 >   I have a sample from a survey where household were interviewed. The 
sample has 4 criteria on which the stratification was based: REGION, 
SIZE OF HOUSEHOLD, SIZE OF LOCALITY, AGE OF HEAD OF HOUSEHOLD. Since i 
don't have the whole information in each cell of the cross 
region*sizehh*sizeloc*age i can't use the postStratify function from 
Survey package. Is that correct? (I think so but i need a competent answer)
 >
 >   The only additional info that i have is the size of a cell from a 
2*2 crossing (eg: I know the population size for all the strata defined 
by region*sizehh, region*sizeloc, sizeloc*age........) so i have the 
behaviour of the population but in a 2 by 2 cross for each of these 
criteria.


You're right, poststratification can't work from two-way marginal 
distributions, but raking or calibration can.

However it seems odd that you only have this much information, since the 
full joint distribution would have been needed for stratification. 
Usually these details would be documented as part of the sample design. 
Can you get this information from those responsible for the sample 
design? It would also be good to check your understanding of the design. 
A sampling frame listing details of household size and age of household 
head would have been needed to do the four-way stratification you 
mention, but in my experience such frames aren't very common.

James
-- 
James Reilly
Department of Statistics, University of Auckland
Private Bag 92019, Auckland, New Zealand


From phhs80 at gmail.com  Sat Sep  8 12:38:44 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Sat, 8 Sep 2007 11:38:44 +0100
Subject: [R] argument 'lib' is missing: using '/usr/lib/R/library'
In-Reply-To: <20070908103216.GA5863@localdomain>
References: <6ade6f6c0709080326m18b109b1v54e501b37e54373b@mail.gmail.com>
	<20070908103216.GA5863@localdomain>
Message-ID: <6ade6f6c0709080338s67464149g45daa50bbd02c31e@mail.gmail.com>

On 9/8/07, Gabor Csardi <csardi at rmki.kfki.hu> wrote:
> Paul, what is the question? If the question is why you get this
> warning message, the reason is that the 'lib' argument is missing
> and install.packages is using '/usr/lib/R/library'.
>
> If you want to get rid of the warning supply the 'lib' argument.

Thanks, Gabor. Yes, I want to get rid of the warning message. Since
the warning did not appear before, even without supplying the 'lib'
argument, I thought that something was wrong here.

Paul





> On Sat, Sep 08, 2007 at 11:26:44AM +0100, Paul Smith wrote:
> > Dear All,
> >
> > When installing packages, I get the following warning:
> >
> > > install.packages("sqldf")
> > Warning in install.packages("sqldf") : argument 'lib' is missing:
> > using '/usr/lib/R/library'
> >
> > Any ideas?
> >
> > The details of my R installation are:
> >
> > > version
> >                _
> > platform       i386-redhat-linux-gnu
> > arch           i386
> > os             linux-gnu
> > system         i386, linux-gnu
> > status
> > major          2
> > minor          5.1
> > year           2007
> > month          06
> > day            27
> > svn rev        42083
> > language       R
> > version.string R version 2.5.1 (2007-06-27)
> > >
> >
> > R is here installed on Fedora 7.
> >
> > Thanks in advance,
> >
> > Paul
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK
>


From jim at bitwrit.com.au  Sat Sep  8 12:58:18 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 08 Sep 2007 20:58:18 +1000
Subject: [R] Help with color coded bar graph
In-Reply-To: <E463F9C6-3D4C-4FC3-93C4-97ADAE92C5DF@gmail.com>
References: <E463F9C6-3D4C-4FC3-93C4-97ADAE92C5DF@gmail.com>
Message-ID: <46E2804A.6040405@bitwrit.com.au>

Luis Naver wrote:
> I have a list of observations that are -1, 1 or 0.  I would like to  
> represent them in a horizontal bar color coded based on value like a  
> stacked bar graph. I can achieve this in the form of a png with the  
> following code:
> 
> A = floor(runif(10)*3) - 1
> 
> png(width=100, height=10)
> par(mar=c(0,0,0,0))
> image(matrix(A), col=grey(c(0.1, 0.5, 0.9)))
> dev.off()
> 
> However I would like to do this with one of the standard plotting  
> tools (i.e. barplot) to take advantage of labels and multiple  
> series.  Any help would be appreciated.
> 
Hi Luis,
I understood your request as wanting a single horizontal bar with 10 
segments, each colored according to the value of A. If this is correct, 
you might want:

library(plotrix)
plot(1,xlim=c(-1,1),ylim=c(-1,1),xlab="",ylab="",type="n",axes=FALSE)
gradient.rect(-1,-0.1,1,0.1,col=grey(c(0.1,0.5,0.9))[A+2])

Jim


From kate at few.vu.nl  Sat Sep  8 13:23:08 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Sat, 8 Sep 2007 13:23:08 +0200 (CEST)
Subject: [R] Matlab's lsqnonlin
In-Reply-To: <18146.29302.359573.180008@stat.math.ethz.ch>
References: <46E199C5.4010609@decsai.ugr.es>
	<Pine.GSO.4.56.0709072002160.29719@laurel.few.vu.nl>
	<18146.29302.359573.180008@stat.math.ethz.ch>
Message-ID: <Pine.GSO.4.56.0709081230120.29719@laurel.few.vu.nl>

>
> I'm wondering about experiences:
> Do you know of cases where  minpack.lm's  nls.lm() solved a
> (real) problem that nls() would have a problem with ?
>

In short, no.  However, I looked at this question in the limited context
of fitting the parameters of a linear superposition of 2 exponentials with
Gaussian noise.  A simulation study showed nearly identical performance
for the range of parameter values/noise levels that are of practical
interest to us.

Are there problems for which steepest descent gets you in the neighborhood
of a solution whereas GN does not?  If such problems exist then there
would be reason to apply LM instead of GN, but I don't know of any.

> Beware however -- one of the main things I learned about this
> field from Doug Bates, co-author of Bates_and_Watts and
> prinicipal author of S's and R's nls() :
> It's a *feature* that nls() does not converge sometimes when
> other methods do falsely claim convergence!
>
> Martin Maechler, ETH Zurich
>
>     KateM> ----
>     KateM> Katharine Mullen
>     KateM> mail: Department of Physics and Astronomy, Faculty of Sciences
>     KateM> Vrije Universiteit Amsterdam, de Boelelaan 1081
>     KateM> 1081 HV Amsterdam, The Netherlands
>     KateM> room: T.1.06
>     KateM> tel: +31 205987870
>     KateM> fax: +31 205987992
>     KateM> e-mail: kate at nat.vu.nl
>     KateM> homepage: http://www.nat.vu.nl/~kate/
>
>
>     KateM> On Fri, 7 Sep 2007, Jose Luis Aznarte M. wrote:
>
>     >> Hi! I'm translating some code from Matlab to R and I found a problem.
>     >> I need to translate Matlab's function 'lsqnonlin'
>     >> (http://www-ccs.ucsd.edu/matlab/toolbox/optim/lsqnonlin.html) into R,
>     >> and at the beginning I  thought it would be the same as R's 'optim'. But
>     >> then I looked at the definition of 'lsqnonlin' and I don't quite see how
>     >> to make 'optim' to do the same thing. Does anyone have an idea?
>     >> This is apart from the fact that I would like to use the Levenberg
>     >> Marquardt algorithm which is not implemented in R (some discussion about
>     >> this: http://tolstoy.newcastle.edu.au/R/help/00b/2492.html).
>     >> Thank you! All the best,
>     >>
>     >>
>     >> --                                                      --
>     >> Jose Luis Aznarte M.       http://decsai.ugr.es/~jlaznarte
>     >> Department of Computer Science and Artificial Intelligence
>     >> Universidad de Granada           Tel. +34 - 958 - 24 04 67
>     >> GRANADA (Spain)                  Fax: +34 - 958 - 24 00 79
>     >>
>     >> ______________________________________________
>     >> R-help at stat.math.ethz.ch mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     >> and provide commented, minimal, self-contained, reproducible code.
>     >>
>
>     KateM> ______________________________________________
>     KateM> R-help at stat.math.ethz.ch mailing list
>     KateM> https://stat.ethz.ch/mailman/listinfo/r-help
>     KateM> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     KateM> and provide commented, minimal, self-contained, reproducible code.
>


From sekhon at berkeley.edu  Sat Sep  8 14:51:41 2007
From: sekhon at berkeley.edu (Jasjeet Singh Sekhon)
Date: Sat, 8 Sep 2007 05:51:41 -0700
Subject: [R] genoud problem
In-Reply-To: <A36876D3F8A5734FA84A4338135E7CC30265A139@BAN-MAILSRV03.Amba.com>
References: <A36876D3F8A5734FA84A4338135E7CC30265A139@BAN-MAILSRV03.Amba.com>
Message-ID: <18146.39645.714769.355590@lapo.berkeley.edu>


Hi Shubha,

genoud does not return the initial fit value.  But you could easily
obtain it by passing your starting values to your function directly.
Alternatively, one can have genoud print out the entire initial
population (or the entire population as is evolves), and one can then
decide to report whatever summary of this one would like.  Note that
the best fit in generation zero is printed by default.  See the
project.path and print.level options for details.

Cheers,
Jas.

=======================================
Jasjeet S. Sekhon                     
                                      
Associate Professor             
Travers Department of Political Science
Survey Research Center          
UC Berkeley                     

http://sekhon.berkeley.edu/
V: 510-642-9974  F: 617-507-5524
=======================================


Shubha Vishwanath Karanth writes:
 > Hi R users,
 > 
 >  
 > 
 > "genoud" function of "rgenoud" package will optimize my function. If 
 > 
 >  
 > 
 > opt = genoud(fn,2,max=TRUE,starting.value=c(1,10),........)
 > 
 >  
 > 
 > opt$value will give the optimized value of the function, "fn". My
 > problem is from the same opt, can I get the value of the function at the
 > initial parameter values? I need the initial value of the function for
 > reporting purposes.
 > 
 >  
 > 
 >  
 > 
 >  
 > 
 > BR, Shubha
 > 
 > 
 > 	[[alternative HTML version deleted]]
 > 
 >


From p.hiemstra at geo.uu.nl  Sat Sep  8 15:00:18 2007
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Sat, 08 Sep 2007 15:00:18 +0200
Subject: [R] Running a PERL script from R
In-Reply-To: <0D23978FCA08B2499683B67DADE76B0102221A@SAGE.forestry.oregonstate.edu>
References: <0D23978FCA08B2499683B67DADE76B0102221A@SAGE.forestry.oregonstate.edu>
Message-ID: <46E29CE2.80601@geo.uu.nl>

Dear Ken.

You could also try and use RSPerl (http://www.omegahat.org/RSPerl/). It 
allows one to use R commands in Perl and vice-versa.

regards,

Paul

Pierce, Ken schreef:
> Is there a way to run a simple perl script from R?
>  
>
> Kenneth B. Pierce Jr.
>
> Research Ecologist
>
> Landscape Ecology, Modeling, Mapping and Analysis Team 
>
> PNW Research Station - USDA-FS 
>
> 3200 SW Jefferson Way,  Corvallis,  OR 97331 
>
> ken.pierce at oregonstate.edu
>
> 541 750-7393 
>
> http://www.fsl.orst.edu/lemma/gnnfire
>
> http://www.fsl.orst.edu/R_users/index.php
>
>  
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:     +31302535773
Fax:    +31302531145
http://intamap.geo.uu.nl/~paul


From ggrothendieck at gmail.com  Sat Sep  8 15:19:26 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 8 Sep 2007 09:19:26 -0400
Subject: [R] Lisp-like primitives in R
In-Reply-To: <46E25E80.3090708@biostat.ku.dk>
References: <04C44D9F040C8A43A18D04F65A8B68BBD9E757@spatcex001.spadac.com>
	<07E228A5BE53C24CAD490193A7381BBBBB4053@LP-EXCHVS07.CO.IHC.COM>
	<20070906221043.GA5648@alcyon.progiciels-bpi.ca>
	<46E08F17.20505@gmail.com>
	<20070908022013.GG5397@phenix.progiciels-bpi.ca>
	<46E25E80.3090708@biostat.ku.dk>
Message-ID: <971536df0709080619i7b492524mf688127075ae0a5a@mail.gmail.com>

On 9/8/07, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> Fran?ois Pinard wrote:
> > [Roland Rau]
> >
> >> [Fran?ois Pinard]
> >>
> >
> >
> >>> I wonder what happened, for R to hide the underlying Scheme so fully,
> >>> at least at the level of the surface language (despite there are
> >>> hints).
> >>>
> >
> >
> >> "To further foster portability, we chose to write R in ANSI C...."
> >>
> >
> > Yes, of course.  Scheme is also (often) implemented in C.  I meant that
> > R might have implemented a Scheme engine (or part of a Scheme engine,
> > extended with appropriate data types) with a surface language (nearly
> > the S language) which is purposely not Scheme, but could have been.
> >
> > If the gap is not extreme, one could dare dreaming that the Scheme
> > engine in R be "completed", and Scheme offered as an alternate extension
> > language.  If you allow me to continue dreaming awake -- "they" told me
> > "they" will let me free as long as I do not get dangerous! :-) -- part
> > of the interest lies in the fact there are excellent Scheme compilers.
> > If we could only find or devise some kind of marriage between a mature
> > Scheme and R, so to speed up the non-vectorisable parts of R scripts...
> >
> >
> Well, depending on what you want, this is either trivial or
> impossible... The internal storage of R is still pretty much equivalent
> to scheme. E.g. try this:
>
>  > r2scheme <- function(e) if (!is.recursive(e))
>      deparse(e) else c("(", unlist(lapply(as.list(e), r2scheme)), ")")
>  > paste(r2scheme(quote(for(i in 1:4)print(i))), collapse=" ")
> [1] "( for i ( : 1 4 ) ( print i ) )"
>

Also see showTree in codetools:

> library(codetools)
> showTree(quote(for(i in 1:4)print(i)))
(for i (: 1 4) (print i))


From edd at debian.org  Sat Sep  8 15:45:15 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 8 Sep 2007 08:45:15 -0500
Subject: [R] Running a PERL script from R
In-Reply-To: <0D23978FCA08B2499683B67DADE76B0102221B@SAGE.forestry.oregonstate.edu>
References: <0D23978FCA08B2499683B67DADE76B0102221A@SAGE.forestry.oregonstate.edu>
	<20070907201048.GB14851@eddelbuettel.com>
	<0D23978FCA08B2499683B67DADE76B0102221B@SAGE.forestry.oregonstate.edu>
Message-ID: <18146.42859.532058.663893@ron.nulle.part>


On 7 September 2007 at 14:04, Pierce, Ken wrote:
| I've tried various configurations of .script, system and shell to no
| avail. It seems to pause and run "something" but then no output is
| created. 

Make sure you read the help page for system, and understand the options. Esp
on Windows, you will need them to display/capture what is happening.

Dirk


| -----Original Message-----
| From: Dirk Eddelbuettel [mailto:edd at debian.org] 
| Sent: Friday, September 07, 2007 1:11 PM
| To: Pierce, Ken
| Cc: r-help
| Subject: Re: [R] Running a PERL script from R
| 
| On Fri, Sep 07, 2007 at 12:15:51PM -0700, Pierce, Ken wrote:
| > Is there a way to run a simple perl script from R?
| 
| ?system
| 
| Hth, Dirk
| 
| --
| Three out of two people have difficulties with fractions.

-- 
Three out of two people have difficulties with fractions.


From pisicandru at hotmail.com  Sat Sep  8 15:45:19 2007
From: pisicandru at hotmail.com (Monica Pisica)
Date: Sat, 8 Sep 2007 13:45:19 +0000
Subject: [R] confusion matrix - better code?
In-Reply-To: <8EA061E48306894180DB020B0C6907A1E81D7F@MNMAIL02.markettools.com>
References: <BAY104-W140B79C46A676BDE4E884AC3C50@phx.gbl>
	<8EA061E48306894180DB020B0C6907A1E81D7F@MNMAIL02.markettools.com>
Message-ID: <BAY104-W142D30FCBF0EC5165DEA4FC3C60@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070908/63390739/attachment.pl 

From pinard at iro.umontreal.ca  Sat Sep  8 16:57:27 2007
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Sat, 8 Sep 2007 10:57:27 -0400
Subject: [R] Lisp-like primitives in R
In-Reply-To: <46E25E80.3090708@biostat.ku.dk>
References: <04C44D9F040C8A43A18D04F65A8B68BBD9E757@spatcex001.spadac.com>
	<07E228A5BE53C24CAD490193A7381BBBBB4053@LP-EXCHVS07.CO.IHC.COM>
	<20070906221043.GA5648@alcyon.progiciels-bpi.ca>
	<46E08F17.20505@gmail.com>
	<20070908022013.GG5397@phenix.progiciels-bpi.ca>
	<46E25E80.3090708@biostat.ku.dk>
Message-ID: <20070908145727.GA5120@phenix.progiciels-bpi.ca>

[Peter Dalgaard]
>[Fran?ois Pinard]

>>I meant that R might have implemented a Scheme engine [...] with 
>>a surface language [...] which is purposely not Scheme, but could have 
>>been.  [...] one could dare dreaming that the Scheme engine in R be 
>>"completed", and Scheme offered as an alternate extension language.  
>>[...] there are excellent Scheme compilers.  [...]

>Well, depending on what you want, this is either trivial or 
>impossible...

I'm more leaning on the "impossible" side :-).

>The internal storage of R is still pretty much equivalent to scheme.

R needs a few supplementary data types, and it motivated the R authors 
into re-implementing their own Scheme engine instead of relying on an 
existing implementation of a Scheme system.

> > r2scheme <- function(e) [...]

Nice exercise! :-)

>a parser that parses a similar language to R internal format is  not 
>a very hard exercise (some care needed in places). However, replacing 
>the front-end is not going to make anything faster,

Of course.  The idea is nothing more than to please people starving to 
use Scheme instead of S as a surface language, here and there in 
scripts.  I merely thought that if the gap is small enough (so to not 
require an extraordinary effort), it would be worth the leap.  One 
immediate difficulty to foresee is the name clashes between R and RnRS.
There might also be missing things in R (like continuations, say).

To make anything faster, and this is a totally different idea, one might 
consider replacing the back-end, not the front-end.  Writing good 
optimizing Scheme compilers is quite an undertaking, and if one only 
considers type inference (as a subproblem), this still is an active 
research area.  The Scheme engine in R was written as to quickly get 
a working S (non-obstant lexical scoping and some library issues).
My ramble was about switching this quick base of R to some solid Scheme 
implementation, than to re-address separately compiling issues for R.

>and the evaluation engine in R does a couple of tricks which are not 
>done in Scheme, notably lazy evaluation,

Promises?  Aren't they already part of Scheme?  The main difference 
I saw is their systematic use in R argument passing.  All aspects of 
mere argument passing would require a lot of thought.  As you wrote, 
variable scope is another difficulty.  Offering a compatible C API, and 
library interface in general, might be a frightening but necessary 
challenge.  It's all more of a dream than a thought, actually... :-)

>Look up the writings of Luke Tierney on the matter to learn more.

Thanks for this interesting reference.

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From g_smits at verizon.net  Sat Sep  8 17:40:07 2007
From: g_smits at verizon.net (Gerard Smits)
Date: Sat, 08 Sep 2007 08:40:07 -0700
Subject: [R] R first.id last.id function error
In-Reply-To: <644e1f320709071830p3e8fd0bch7e32c41ab20f2c5d@mail.gmail.co m>
References: <0JO0008GORXN14FB@vms046.mailsrvcs.net>
	<644e1f320709071830p3e8fd0bch7e32c41ab20f2c5d@mail.gmail.com>
Message-ID: <0JO200HE33IYOMBI@vms040.mailsrvcs.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070908/43083516/attachment.pl 

From jrkrideau at yahoo.ca  Sat Sep  8 17:41:14 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Sat, 8 Sep 2007 11:41:14 -0400 (EDT)
Subject: [R] Suppress 'x' when appending to a csv file
Message-ID: <186702.7228.qm@web32804.mail.mud.yahoo.com>

Is there any convenient way to supress the x that
appears in csv export files?  I would like to be able
to export a file and add a comment to it yet still be
able to read it back into R.  I don't see any way to
get rid of the x that seperates the different appended
parts.

Thanks

EXAMPLE

x
1
2
3
4
5
x
#Results from file SSS.r

R.2.5.1 Windows XP


From marc_schwartz at comcast.net  Sat Sep  8 18:12:47 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Sat, 08 Sep 2007 11:12:47 -0500
Subject: [R] Suppress 'x' when appending to a csv file
In-Reply-To: <186702.7228.qm@web32804.mail.mud.yahoo.com>
References: <186702.7228.qm@web32804.mail.mud.yahoo.com>
Message-ID: <1189267967.9782.2.camel@Bellerophon.localdomain>

On Sat, 2007-09-08 at 11:41 -0400, John Kane wrote:
> Is there any convenient way to supress the x that
> appears in csv export files?  I would like to be able
> to export a file and add a comment to it yet still be
> able to read it back into R.  I don't see any way to
> get rid of the x that seperates the different appended
> parts.
> 
> Thanks
> 
> EXAMPLE
> 
> x
> 1
> 2
> 3
> 4
> 5
> x
> #Results from file SSS.r
> 
> R.2.5.1 Windows XP

John,

Try this:

> write.table(head(iris), sep = ",", 
              row.names = FALSE, col.names = FALSE)
5.1,3.5,1.4,0.2,"setosa"
4.9,3,1.4,0.2,"setosa"
4.7,3.2,1.3,0.2,"setosa"
4.6,3.1,1.5,0.2,"setosa"
5,3.6,1.4,0.2,"setosa"
5.4,3.9,1.7,0.4,"setosa"


You may need to explicitly adjust other arguments that are otherwise set
to defaults when using write.csv().

HTH,

Marc Schwartz


From ligges at statistik.uni-dortmund.de  Sat Sep  8 19:07:18 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 08 Sep 2007 19:07:18 +0200
Subject: [R] Using clustering functions
In-Reply-To: <12554686.post@talk.nabble.com>
References: <12554686.post@talk.nabble.com>
Message-ID: <46E2D6C6.3020800@statistik.uni-dortmund.de>



uv wrote:
> Hi. I need to use a few different clustering functions. I managed to run the
> kmeans() one which is in my "stats" library, but I can't use any function,
> such as agnes(), that is in my "cluster" library. Any idea how to access
> other libraries? 
> Thanks!


Both "stats" and "cluster" are packages, not libraries.
You need to call library("cluster") in order to load package cluster 
from your library before using agnes() and her friends.


Uwe Ligges


From tkobayas at indiana.edu  Sat Sep  8 21:01:47 2007
From: tkobayas at indiana.edu (tkobayas at indiana.edu)
Date: Sat,  8 Sep 2007 15:01:47 -0400
Subject: [R] Problem in installing packages on linux machine...
Message-ID: <20070908150147.wo8vljzrs4w0wsso@webmail.iu.edu>

Hi,

I am trying to install RSQLite package on my Fedora workstation. I 
tried to install other packages as well, but each time I got the same 
error messages saying "compilation error" and "non zero exit status". 
Do I have to specify "lib="? I never specified the library path before 
when I was using Fedora Core 6.


Warning in install.packages("RSQLite") : argument 'lib' is missing: 
using '/usr/lib/R/library'
--- Please select a CRAN mirror for use in this session ---
Loading Tcl/Tk interface ... done
trying URL 'http://cran.cnr.Berkeley.edu/src/contrib/RSQLite_0.5-6.tar.gz'
Content type 'application/x-gzip' length 710241 bytes
opened URL
==================================================
downloaded 693Kb

gcc -std=gnu99 -shared -L/usr/local/lib -o RSQLite.so RS-DBI.o 
RS-SQLite.o sqlite-all.o   -L/usr/lib/R/lib -lR
/usr/bin/ld: skipping incompatible /usr/lib/R/lib/libR.so when 
searching for -lR
/usr/bin/ld: cannot find -lR
collect2: ld returned 1 exit status
make: *** [RSQLite.so] Error 1
chmod: cannot access `/usr/lib/R/library/RSQLite/libs/*': No such file 
or directory
ERROR: compilation failed for package 'RSQLite'
** Removing '/usr/lib/R/library/RSQLite'

The downloaded packages are in
        /tmp/RtmpHQ5Y7C/downloaded_packages
Warning message:
installation of package 'RSQLite' had non-zero exit status in: 
install.packages("RSQLite")

I appreciate your help.....

Thank you very much

Taka


From wwwhsd at gmail.com  Sat Sep  8 21:07:39 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Sat, 8 Sep 2007 16:07:39 -0300
Subject: [R] Problem in installing packages on linux machine...
In-Reply-To: <20070908150147.wo8vljzrs4w0wsso@webmail.iu.edu>
References: <20070908150147.wo8vljzrs4w0wsso@webmail.iu.edu>
Message-ID: <da79af330709081207n312b346fxd792df4b4d4c84dc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070908/147dea7c/attachment.pl 

From tkobayas at indiana.edu  Sat Sep  8 21:22:43 2007
From: tkobayas at indiana.edu (tkobayas at indiana.edu)
Date: Sat,  8 Sep 2007 15:22:43 -0400
Subject: [R] Problem in installing packages on linux machine...
In-Reply-To: <da79af330709081207n312b346fxd792df4b4d4c84dc@mail.gmail.com>
References: <20070908150147.wo8vljzrs4w0wsso@webmail.iu.edu>
	<da79af330709081207n312b346fxd792df4b4d4c84dc@mail.gmail.com>
Message-ID: <20070908152243.3d6lig9lsgwoocgo@webmail.iu.edu>

Hi,

Still got the same error message. I did "su R" when I got the error 
message for the first time. I have never seen this error message..... I 
will be googling for solutions as well...

Thank you.

Quoting Henrique Dallazuanna <wwwhsd at gmail.com>:

> Hi, try install packages whit 'sudo'.
>
> $sudo R
>
> --
> Henrique Dallazuanna
> Curitiba-Paran?-Brasil
> 25? 25' 40" S 49? 16' 22" O
>
> On 08/09/2007, tkobayas at indiana.edu <tkobayas at indiana.edu> wrote:
>>
>> Hi,
>>
>> I am trying to install RSQLite package on my Fedora workstation. I
>> tried to install other packages as well, but each time I got the same
>> error messages saying "compilation error" and "non zero exit status".
>> Do I have to specify "lib="? I never specified the library path before
>> when I was using Fedora Core 6.
>>
>>
>> Warning in install.packages("RSQLite") : argument 'lib' is missing:
>> using '/usr/lib/R/library'
>> --- Please select a CRAN mirror for use in this session ---
>> Loading Tcl/Tk interface ... done
>> trying URL 'http://cran.cnr.Berkeley.edu/src/contrib/RSQLite_0.5-6.tar.gz'
>> Content type 'application/x-gzip' length 710241 bytes
>> opened URL
>> ==================================================
>> downloaded 693Kb
>>
>> gcc -std=gnu99 -shared -L/usr/local/lib -o RSQLite.so RS-DBI.o
>> RS-SQLite.o sqlite-all.o   -L/usr/lib/R/lib -lR
>> /usr/bin/ld: skipping incompatible /usr/lib/R/lib/libR.so when
>> searching for -lR
>> /usr/bin/ld: cannot find -lR
>> collect2: ld returned 1 exit status
>> make: *** [RSQLite.so] Error 1
>> chmod: cannot access `/usr/lib/R/library/RSQLite/libs/*': No such file
>> or directory
>> ERROR: compilation failed for package 'RSQLite'
>> ** Removing '/usr/lib/R/library/RSQLite'
>>
>> The downloaded packages are in
>>         /tmp/RtmpHQ5Y7C/downloaded_packages
>> Warning message:
>> installation of package 'RSQLite' had non-zero exit status in:
>> install.packages("RSQLite")
>>
>> I appreciate your help.....
>>
>> Thank you very much
>>
>> Taka
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>



------------------------------------
Takatsugu Kobayashi
PhD Student
Indiana University, Dept. Geography


From jrkrideau at yahoo.ca  Sat Sep  8 21:29:06 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Sat, 8 Sep 2007 15:29:06 -0400 (EDT)
Subject: [R] Suppress 'x' when appending to a csv file
In-Reply-To: <1189267967.9782.2.camel@Bellerophon.localdomain>
Message-ID: <36959.7349.qm@web32809.mail.mud.yahoo.com>

Thanks Marc. It works.  I had not thought of using
col.names = FALSE as I wanted to keep the colnames. I
see that I will just have to do another write.table
command to do this.  Humm, actually it took a a bit of
juggling to do the names but it's looking fine now.



--- Marc Schwartz <marc_schwartz at comcast.net> wrote:

> On Sat, 2007-09-08 at 11:41 -0400, John Kane wrote:
> > Is there any convenient way to supress the x that
> > appears in csv export files?  I would like to be
> able
> > to export a file and add a comment to it yet still
> be
> > able to read it back into R.  I don't see any way
> to
> > get rid of the x that seperates the different
> appended
> > parts.
> > 
> > Thanks
> > 
> > EXAMPLE
> > 
> > x
> > 1
> > 2
> > 3
> > 4
> > 5
> > x
> > #Results from file SSS.r
> > 
> > R.2.5.1 Windows XP
> 
> John,
> 
> Try this:
> 
> > write.table(head(iris), sep = ",", 
>               row.names = FALSE, col.names = FALSE)
> 5.1,3.5,1.4,0.2,"setosa"
> 4.9,3,1.4,0.2,"setosa"
> 4.7,3.2,1.3,0.2,"setosa"
> 4.6,3.1,1.5,0.2,"setosa"
> 5,3.6,1.4,0.2,"setosa"
> 5.4,3.9,1.7,0.4,"setosa"
> 
> 
> You may need to explicitly adjust other arguments
> that are otherwise set
> to defaults when using write.csv().
> 
> HTH,
> 
> Marc Schwartz
> 
> 
>


From ana.rosa.maretec at ist.utl.pt  Sat Sep  8 20:25:07 2007
From: ana.rosa.maretec at ist.utl.pt (Rosa Trancoso)
Date: Sat, 08 Sep 2007 19:25:07 +0100
Subject: [R] statistical tests under serial dependence
Message-ID: <46E2E903.2010904@ist.utl.pt>

Hello!

I would like to know if there are already programmed statistical tests 
for data under serial dependence, for example, considering the variance 
inflation factor?


Thank you very much
Best regards
Rosa


From shaoranwill at hotmail.com  Sat Sep  8 20:40:34 2007
From: shaoranwill at hotmail.com (shao ran)
Date: Sat, 08 Sep 2007 18:40:34 +0000
Subject: [R] predict.arima
Message-ID: <BAY113-F20D61B0F39B5365CF1F935B9C60@phx.gbl>

Hi *,

Firstly, thank you so much for your time to read my email.

I am currently interested in how to use R to predict time series from
models fitted by ARIMA. The package I used is basic stats package, and the
method I used is predict.Arima.

What I know is that ARIMA parameters are estimated by Kalman Filter, but I
have difficulty in understanding how exactly maximum likelihood (ML)
estimator can be computed based on Kalman Filter, i.e. given a time series
and an ARIMA model, how can I compute the ARIMA parameters for prediction.

Could you please give me some help or provide some materials for it?

Thank you so much!


will

_________________________________________________________________
?????????????????????????????? MSN Hotmail?? http://www.hotmail.com


From i.visser at uva.nl  Sat Sep  8 22:05:09 2007
From: i.visser at uva.nl (Ingmar Visser)
Date: Sat, 8 Sep 2007 22:05:09 +0200
Subject: [R] 'initial value not feasible' in constrOptim
In-Reply-To: <548b8d440709071400v5e01fa9fw2cce6f212696f587@mail.gmail.com>
References: <548b8d440709071400v5e01fa9fw2cce6f212696f587@mail.gmail.com>
Message-ID: <F42F9FFD-BB04-4A1F-A4B8-A6D784024671@uva.nl>

Hi,

On Sep 7, 2007, at 11:00 PM, Yuchen Luo wrote:
> constrOptim(c(0.5,0.3,0.5), fit.error, fit.error.grr,  
> ui=-1*ui,ci=-1*ci)
>
> and I am confronted with error message "initial value not feasible"
>
> I plug in the initial value of (0.5,0.3,0.5) to function fit.error and
> fit.error.grr and have pretty reasonable result.

That doesn't mean the constraint is satisfied, which depends on the  
values of ui and ci
but they are not provided so it's hard to tell where the problem is.

hth, Ingmar

> I inequality "ui %*% theta
> - ci >= 0" as suggested in the R manual and it is satisfied. In  
> case that
> this is a typo of the manual, I let ui=-ui and ci=-ci and try  
> constrOptim
> again but the same warning message pops up.
> Could you please point me a way out of this?
>
> I am actually trying to translate a fortran code to R and the  
> function I
> want to replace is DBCPOL, which used 'the complex method"  
> described in
> Nelder and Mead (1965) and Gill et al. (1981). I believe contrOptim is
> better than it because it is newer, is it?
>
> Best Wishes
> Yuchen Luo
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smpowers at wisc.edu  Sun Sep  9 02:39:47 2007
From: smpowers at wisc.edu (Steve Powers)
Date: Sat, 08 Sep 2007 19:39:47 -0500
Subject: [R] writing complex outputs to table
Message-ID: <46E340D3.709@wisc.edu>

So I've come across a few cases where complex outputs from functions 
will not write to tables. The most recent case involves the TukeyHSD 
function in the stats package. If I save the TukeyHSD call and print it, 
that obviously goes fine, but when I try writing to a table, I get an 
error message that says "cannot coerce class \multicomp\" into 
dataframe. What does this mean, and how do I work around it? Is there a 
more "fail-safe" general method of writing complex outputs to a table? 
The story here is I want to be able to call certain values from the 
TukeyHSD results to produce custom summaries.

Using R version 2.4 on Windows XP.---steve


From realityrandom at gmail.com  Sun Sep  9 13:01:52 2007
From: realityrandom at gmail.com (Yuchen Luo)
Date: Sun, 9 Sep 2007 04:01:52 -0700
Subject: [R] What does it mean by "initial value not available"?
Message-ID: <548b8d440709090401n5e09a9aeq88f77a76d27e39cd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070909/61c350ac/attachment.pl 

From shukai at seas.upenn.edu  Sun Sep  9 13:07:13 2007
From: shukai at seas.upenn.edu (kevinchang)
Date: Sun, 9 Sep 2007 04:07:13 -0700 (PDT)
Subject: [R] artificial data matrix with 100000 rows
Message-ID: <12577936.post@talk.nabble.com>


Hi guys,

I tried to made the matrix with this size by either matrix() or array().
However, there seems to be default limit of number for rows made. I got sort
of error message from R .To be specific, 

m<--matrix(ncol=3,nrow=100000)

error message:[ reached getOption("max.print") -- omitted 66667 rows ]]

or

a<-array(dim=c(10000,3,10))

error message:reached getOption("max.print") -- omitted 6667 row(s) and 6
matrix slice(s) ]

Please help. 



-- 
View this message in context: http://www.nabble.com/artificial-data-matrix-with-100000-rows-tf4408895.html#a12577936
Sent from the R help mailing list archive at Nabble.com.


From phhs80 at gmail.com  Sun Sep  9 13:17:32 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Sun, 9 Sep 2007 12:17:32 +0100
Subject: [R] artificial data matrix with 100000 rows
In-Reply-To: <12577936.post@talk.nabble.com>
References: <12577936.post@talk.nabble.com>
Message-ID: <6ade6f6c0709090417p29895b49p6424e45aaf57e9f0@mail.gmail.com>

On 9/9/07, kevinchang <shukai at seas.upenn.edu> wrote:
> I tried to made the matrix with this size by either matrix() or array().
> However, there seems to be default limit of number for rows made. I got sort
> of error message from R .To be specific,
>
> m<--matrix(ncol=3,nrow=100000)
>
> error message:[ reached getOption("max.print") -- omitted 66667 rows ]]
>
> or
>
> a<-array(dim=c(10000,3,10))
>
> error message:reached getOption("max.print") -- omitted 6667 row(s) and 6
> matrix slice(s) ]

That is not an error message, I guess. When the matrices are huge, R
is unable to print them totally on the screen, but all data are
present. For instance,

> m[(nrow(m)-10):nrow(m),]
      [,1] [,2] [,3]
 [1,]   NA   NA   NA
 [2,]   NA   NA   NA
 [3,]   NA   NA   NA
 [4,]   NA   NA   NA
 [5,]   NA   NA   NA
 [6,]   NA   NA   NA
 [7,]   NA   NA   NA
 [8,]   NA   NA   NA
 [9,]   NA   NA   NA
[10,]   NA   NA   NA
[11,]   NA   NA   NA
>

See

?getOption

Paul


From pensterfuzzer at yahoo.de  Sun Sep  9 13:24:09 2007
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Sun, 9 Sep 2007 13:24:09 +0200 (CEST)
Subject: [R] Sweave figure aspect ratio
Message-ID: <383745.93495.qm@web23008.mail.ird.yahoo.com>

Hello,

using Sweave, is there any option to preserve the
original aspect ratio of plots generated from R code?

Consider this Sweave chunk:
<<test,echo=F,fig=T,width=2,height=2>>=
x <- 1:10
y <- sin(x)
par(mar=c(4,4,0,4))
plot(x,y,
     xlab="x label",
     ylab="y label"
     )
@

In Latex, I want to produce a plot of width 2 but
don't care about the height. If I put the width and
height like shown on the example, the box isn't square
any more. But if I put only width or height in the
Sweave option, then the values then the appearance is
totally off. 

Is there any option for Sweave or other possibility to
preserve the ratio of the sides of plots?

Many thanks,
  Werner


From carsten_jaeger at web.de  Sun Sep  9 13:36:05 2007
From: carsten_jaeger at web.de (Carsten Jaeger)
Date: Sun, 09 Sep 2007 13:36:05 +0200
Subject: [R] Problem in installing packages on linux machine...
Message-ID: <1189337765.2095.4.camel@localhost.localdomain>

Your problem is not related to missing file permissions but to a problem
with the linker (ld). As you can see from the error message, ld cannot
find a compatible libR.so so compilation fails. You did not specify
which architecture you're on but in case it is a 64-bit platform, the
following thread might be helpful: 

http://tolstoy.newcastle.edu.au/R/e2/help/07/07/22071.html

BTW, the correct command for running R as root is "su -c R" or "sudo R".
Furthermore, lib is optional and defaults to .libPaths()[1],
see ?install.packages

 <tkobayas <at> indiana.edu> writes:

> 
> Hi,
> 
> Still got the same error message. I did "su R" when I got the error 
> message for the first time. I have never seen this error message.....
I 
> will be googling for solutions as well...
> 
> Thank you.
> 
> Quoting Henrique Dallazuanna <wwwhsd <at> gmail.com>:
> 
> > Hi, try install packages whit 'sudo'.
> >
> > $sudo R
> >
> > --
> > Henrique Dallazuanna
> > Curitiba-Paran?-Brasil
> > 25? 25' 40" S 49? 16' 22" O
> >
> > On 08/09/2007, tkobayas <at> indiana.edu <tkobayas <at> indiana.edu>
wrote:
> >>
> >> Hi,
> >>
> >> I am trying to install RSQLite package on my Fedora workstation. I
> >> tried to install other packages as well, but each time I got the
same
> >> error messages saying "compilation error" and "non zero exit
status".
> >> Do I have to specify "lib="? I never specified the library path
before
> >> when I was using Fedora Core 6.
> >>
> >>
> >> Warning in install.packages("RSQLite") : argument 'lib' is missing:
> >> using '/usr/lib/R/library'
> >> --- Please select a CRAN mirror for use in this session ---
> >> Loading Tcl/Tk interface ... done
> >> trying URL
'http://cran.cnr.Berkeley.edu/src/contrib/RSQLite_0.5-6.tar.gz'
> >> Content type 'application/x-gzip' length 710241 bytes
> >> opened URL
> >> ==================================================
> >> downloaded 693Kb
> >>
> >> gcc -std=gnu99 -shared -L/usr/local/lib -o RSQLite.so RS-DBI.o
> >> RS-SQLite.o sqlite-all.o   -L/usr/lib/R/lib -lR
> >> /usr/bin/ld: skipping incompatible /usr/lib/R/lib/libR.so when
> >> searching for -lR
> >> /usr/bin/ld: cannot find -lR
> >> collect2: ld returned 1 exit status
> >> make: *** [RSQLite.so] Error 1
> >> chmod: cannot access `/usr/lib/R/library/RSQLite/libs/*': No such
file
> >> or directory
> >> ERROR: compilation failed for package 'RSQLite'
> >> ** Removing '/usr/lib/R/library/RSQLite'
> >>
> >> The downloaded packages are in
> >>         /tmp/RtmpHQ5Y7C/downloaded_packages
> >> Warning message:
> >> installation of package 'RSQLite' had non-zero exit status in:
> >> install.packages("RSQLite")
> >>
> >> I appreciate your help.....
> >>
> >> Thank you very much
> >>
> >> Taka
> >>
> >> ______________________________________________
> >> R-help <at> stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> 
> ------------------------------------
> Takatsugu Kobayashi
> PhD Student
> Indiana University, Dept. Geography
> 
> ______________________________________________
> R-help <at> stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
>


From murdoch at stats.uwo.ca  Sun Sep  9 14:36:57 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 09 Sep 2007 08:36:57 -0400
Subject: [R] What does it mean by "initial value not available"?
In-Reply-To: <548b8d440709090401n5e09a9aeq88f77a76d27e39cd@mail.gmail.com>
References: <548b8d440709090401n5e09a9aeq88f77a76d27e39cd@mail.gmail.com>
Message-ID: <46E3E8E9.3020700@stats.uwo.ca>

On 09/09/2007 7:01 AM, Yuchen Luo wrote:
> Dear friends.
> I use ConstrOptim( ) and got error message "initial value not available".
> My understanding of "initial value not available" is that one of the
> following 3 cases happens:
> 
> 1.The objective function is not well defined at the point of the initial
> value.
> 2. The differentiation of the objective function is not well defined at the
> point of the initial value.
> 3. The initial value violate the constrain of "ui %*% theta - ci >= 0"
> 
> But my situation does not belong to any of the above cases.
> 
> I have attached my code bellow and could you please help me take a look?

I haven't tried your code, but there's one obvious error:
...
> fit.error=function(rec,lambda,lbar)
> {sum((eval(apple)*1000-orange)^2/(orange^2))
> }

The function optimizes over the elements of the first parameter.  You've 
got two other parameters there, and I think you're trying to optimize 
over them as well.  Put them all into one vector.

The documentation for constrOptim doesn't make this as clear as it 
should; I'll clarify (by copying the docs from ?optim).

Duncan Murdoch

> 
> 
> fit.error.grr=function(rec,lambda, lbar)
> {drec=sum(eval(D(apple,'rec'))*(eval(apple)*1000-orange)/(orange^2))
> dlambda=sum(eval(D(apple,'lambda'))*(eval(apple)*1000-orange)/(orange^2))
> dlbar=sum(eval(D(apple,'lbar'))*(eval(apple)*1000-orange)/(orange^2))
> c(drec,dlambda,dlbar)
> }
> 
> 
> rr=c(4.33,4.22,4.27,4.43,4.43,4.44,4.45,4.65,4.77,4.77)
> tot=rep(13319.17,10)
> sh=rep(1553656,10)
> sigmae=c(0.172239074,0.188209271,0.193703774,0.172659891,0.164427247,
> 0.24602361,0.173555309,0.186701165,0.193150456)
> ss=c(56.49,56.39,56.55,57.49,57.37,55.02,56.02,54.35,54.09)
> orange=rep(21.25,10)
> 
> constrOptim(c(0.5,0.3,0.5), fit.error, fit.error.grr, ui=ui,ci=ci)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch at stats.uwo.ca  Sun Sep  9 15:23:12 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 09 Sep 2007 09:23:12 -0400
Subject: [R] Sweave figure aspect ratio
In-Reply-To: <383745.93495.qm@web23008.mail.ird.yahoo.com>
References: <383745.93495.qm@web23008.mail.ird.yahoo.com>
Message-ID: <46E3F3C0.3040201@stats.uwo.ca>

On 09/09/2007 7:24 AM, Werner Wernersen wrote:
> Hello,
> 
> using Sweave, is there any option to preserve the
> original aspect ratio of plots generated from R code?
> 
> Consider this Sweave chunk:
> <<test,echo=F,fig=T,width=2,height=2>>=
> x <- 1:10
> y <- sin(x)
> par(mar=c(4,4,0,4))
> plot(x,y,
>      xlab="x label",
>      ylab="y label"
>      )
> @
> 
> In Latex, I want to produce a plot of width 2 but
> don't care about the height. If I put the width and
> height like shown on the example, the box isn't square
> any more. But if I put only width or height in the
> Sweave option, then the values then the appearance is
> totally off. 
> 
> Is there any option for Sweave or other possibility to
> preserve the ratio of the sides of plots?

The width and height args in the header of the chunk are passed to the 
graphics device (postscript or pdf), but they don't appear in the LaTeX 
output.  To modify the appearance in LaTeX, you need to set a graphicx 
package parameter, e.g. something like

\setkeys{Gin}{width=2in}
<<test,echo=F,fig=T>>=
x <- 1:10
y <- sin(x)
par(mar=c(4,4,0,4))
plot(x,y,
      xlab="x label",
      ylab="y label"
      )
@

If you only specify width, then the aspect ratio will be maintained.

The \setkeys{} changes are persistent; as far as I know there's no way 
to say "go back to the default" afterwards.  So what I'd suggest is to 
define a macro (e.g. \Gwidth) to give the default width, and then call

\setkeys{Gin}{width=\Gwidth}

at the start of your document and after any change like the one above.

Duncan Murdoch


From yogesh.mpi at googlemail.com  Sun Sep  9 15:46:26 2007
From: yogesh.mpi at googlemail.com (Yogesh Tiwari)
Date: Sun, 9 Sep 2007 14:46:26 +0100
Subject: [R] command to plot variannce of data (like error bar plot)
Message-ID: <71cc5ca20709090646xe5d9e07t2dd060e55246de2c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070909/2a912202/attachment.pl 

From muenchen at utk.edu  Sun Sep  9 15:59:25 2007
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Sun, 9 Sep 2007 09:59:25 -0400
Subject: [R] stacking data frames with different variables
Message-ID: <347152339B716A4D893C9A2988EA87C8639D4D@KFSVS2.utk.tennessee.edu>

Hi All,

If I need to stack two data frames, I can use rbind, but it requires
that all variables exist in both sets. I can make that happen, but other
stat packages would figure out where the differences were, add the
missing variables to each, set their values to missing and stack them.
Is there a more automatic way to do that in R?

Below is an example program.

Thanks,
Bob

# Top data frame has two variables.
x <- c(1,2)
y <- c(1,2)

top <- data.frame(x,y)
top

# Bottom data frame has only one of them.
x <- c(3,4)
bottom <- data.frame(x)
bottom

# So rbind won't work.
rbind(top, bottom)

# After figuring out where the mismatches are I can 
# make the two DFs the same manually.
bottom <- data.frame( bottom, y=NA)
bottom

# Now I get the desired result.
both <- rbind(top,bottom)
both

=========================================================
Bob Muenchen (pronounced Min'-chen), Manager 
Statistical Consulting Center
U of TN Office of Information Technology
200 Stokely Management Center, Knoxville, TN 37996-0520
Voice: (865) 974-5230 
FAX: (865) 974-4810
Email: muenchen at utk.edu
Web: http://oit.utk.edu/scc, 
News: http://listserv.utk.edu/archives/statnews.html


From h.wickham at gmail.com  Sun Sep  9 16:11:28 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 9 Sep 2007 09:11:28 -0500
Subject: [R] stacking data frames with different variables
In-Reply-To: <347152339B716A4D893C9A2988EA87C8639D4D@KFSVS2.utk.tennessee.edu>
References: <347152339B716A4D893C9A2988EA87C8639D4D@KFSVS2.utk.tennessee.edu>
Message-ID: <f8e6ff050709090711l6c91f3chce1aaf9db06f5011@mail.gmail.com>

Have a look at rbind.fill in the reshape package.

Hadley

On 9/9/07, Muenchen, Robert A (Bob) <muenchen at utk.edu> wrote:
> Hi All,
>
> If I need to stack two data frames, I can use rbind, but it requires
> that all variables exist in both sets. I can make that happen, but other
> stat packages would figure out where the differences were, add the
> missing variables to each, set their values to missing and stack them.
> Is there a more automatic way to do that in R?
>
> Below is an example program.
>
> Thanks,
> Bob
>
> # Top data frame has two variables.
> x <- c(1,2)
> y <- c(1,2)
>
> top <- data.frame(x,y)
> top
>
> # Bottom data frame has only one of them.
> x <- c(3,4)
> bottom <- data.frame(x)
> bottom
>
> # So rbind won't work.
> rbind(top, bottom)
>
> # After figuring out where the mismatches are I can
> # make the two DFs the same manually.
> bottom <- data.frame( bottom, y=NA)
> bottom
>
> # Now I get the desired result.
> both <- rbind(top,bottom)
> both
>
> =========================================================
> Bob Muenchen (pronounced Min'-chen), Manager
> Statistical Consulting Center
> U of TN Office of Information Technology
> 200 Stokely Management Center, Knoxville, TN 37996-0520
> Voice: (865) 974-5230
> FAX: (865) 974-4810
> Email: muenchen at utk.edu
> Web: http://oit.utk.edu/scc,
> News: http://listserv.utk.edu/archives/statnews.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
http://had.co.nz/


From muenchen at utk.edu  Sun Sep  9 16:25:13 2007
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Sun, 9 Sep 2007 10:25:13 -0400
Subject: [R] stacking data frames with different variables
In-Reply-To: <f8e6ff050709090711l6c91f3chce1aaf9db06f5011@mail.gmail.com>
References: <347152339B716A4D893C9A2988EA87C8639D4D@KFSVS2.utk.tennessee.edu>
	<f8e6ff050709090711l6c91f3chce1aaf9db06f5011@mail.gmail.com>
Message-ID: <347152339B716A4D893C9A2988EA87C8639D50@KFSVS2.utk.tennessee.edu>

Perfect. Thanks Hadley!


> -----Original Message-----
> From: hadley wickham [mailto:h.wickham at gmail.com]
> Sent: Sunday, September 09, 2007 10:11 AM
> To: Muenchen, Robert A (Bob)
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] stacking data frames with different variables
> 
> Have a look at rbind.fill in the reshape package.
> 
> Hadley
> 
> On 9/9/07, Muenchen, Robert A (Bob) <muenchen at utk.edu> wrote:
> > Hi All,
> >
> > If I need to stack two data frames, I can use rbind, but it requires
> > that all variables exist in both sets. I can make that happen, but
> other
> > stat packages would figure out where the differences were, add the
> > missing variables to each, set their values to missing and stack
> them.
> > Is there a more automatic way to do that in R?
> >
> > Below is an example program.
> >
> > Thanks,
> > Bob
> >
> > # Top data frame has two variables.
> > x <- c(1,2)
> > y <- c(1,2)
> >
> > top <- data.frame(x,y)
> > top
> >
> > # Bottom data frame has only one of them.
> > x <- c(3,4)
> > bottom <- data.frame(x)
> > bottom
> >
> > # So rbind won't work.
> > rbind(top, bottom)
> >
> > # After figuring out where the mismatches are I can
> > # make the two DFs the same manually.
> > bottom <- data.frame( bottom, y=NA)
> > bottom
> >
> > # Now I get the desired result.
> > both <- rbind(top,bottom)
> > both
> >
> > =========================================================
> > Bob Muenchen (pronounced Min'-chen), Manager
> > Statistical Consulting Center
> > U of TN Office of Information Technology
> > 200 Stokely Management Center, Knoxville, TN 37996-0520
> > Voice: (865) 974-5230
> > FAX: (865) 974-4810
> > Email: muenchen at utk.edu
> > Web: http://oit.utk.edu/scc,
> > News: http://listserv.utk.edu/archives/statnews.html
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 
> --
> http://had.co.nz/


From pisicandru at hotmail.com  Sun Sep  9 17:18:14 2007
From: pisicandru at hotmail.com (Monica Pisica)
Date: Sun, 9 Sep 2007 15:18:14 +0000
Subject: [R] confusion matrix - better code?
In-Reply-To: <46E1AED0.3060206@ebi.ac.uk>
References: <BAY104-W140B79C46A676BDE4E884AC3C50@phx.gbl>
	<46E1AED0.3060206@ebi.ac.uk>
Message-ID: <BAY104-W757BA332B635866BEB377C3C70@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070909/45d38040/attachment.pl 

From nick.chorley at gmail.com  Sun Sep  9 18:27:08 2007
From: nick.chorley at gmail.com (Nick Chorley)
Date: Sun, 9 Sep 2007 17:27:08 +0100
Subject: [R] NA in AR model residuals
Message-ID: <f5bc463e0709090927o24ffb140n7d2927d5e439a7a2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070909/85ba3004/attachment.pl 

From shukai at seas.upenn.edu  Sun Sep  9 19:36:27 2007
From: shukai at seas.upenn.edu (kevinchang)
Date: Sun, 9 Sep 2007 10:36:27 -0700 (PDT)
Subject: [R] loop execution problem
Message-ID: <12581061.post@talk.nabble.com>


This is  bizzare. The for loop I set seems to go infinitly  because the
hourglass cursor never disappers and I never get the result. But when I
click on "X" of the window try to exit R, the execution finishes right after
I abort exiting when RGui asks me to save the workplace or not.  Please help
me out.
-- 
View this message in context: http://www.nabble.com/loop-execution-problem-tf4410139.html#a12581061
Sent from the R help mailing list archive at Nabble.com.


From murdoch at stats.uwo.ca  Sun Sep  9 19:48:39 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 09 Sep 2007 13:48:39 -0400
Subject: [R] loop execution problem
In-Reply-To: <12581061.post@talk.nabble.com>
References: <12581061.post@talk.nabble.com>
Message-ID: <46E431F7.900@stats.uwo.ca>

On 09/09/2007 1:36 PM, kevinchang wrote:
> This is  bizzare. The for loop I set seems to go infinitly  because the
> hourglass cursor never disappers and I never get the result. But when I
> click on "X" of the window try to exit R, the execution finishes right after
> I abort exiting when RGui asks me to save the workplace or not.  Please help
> me out.

In Windows you can also abort execution by hitting Esc, or the menu 
entry "Misc|Stop current computation".

Duncan Murdoch


From red_tez at yahoo.co.uk  Sun Sep  9 21:32:32 2007
From: red_tez at yahoo.co.uk (Terence Broderick)
Date: Sun, 9 Sep 2007 20:32:32 +0100 (BST)
Subject: [R] fitdistr()
Message-ID: <985542.12970.qm@web27206.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070909/e5ca1f3f/attachment.pl 

From jholtman at gmail.com  Sun Sep  9 21:37:16 2007
From: jholtman at gmail.com (jim holtman)
Date: Sun, 9 Sep 2007 15:37:16 -0400
Subject: [R] fitdistr()
In-Reply-To: <985542.12970.qm@web27206.mail.ukl.yahoo.com>
References: <985542.12970.qm@web27206.mail.ukl.yahoo.com>
Message-ID: <644e1f320709091237y6ff59d4gebec2d91b109a240@mail.gmail.com>

I assume that you want to do the fitdistr on one of the columns of the
dataframe that you have read in. What does 'str(ONES3)' show?  If the
data is in the first column, try:

fitdistr(ONES3[[1]],"chi-squared")


On 9/9/07, Terence Broderick <red_tez at yahoo.co.uk> wrote:
> I am trying to fit the chi-squared distribution to a set of data using the fitdistr function found in the MASS4 library, the data set is called ONES3, I have loaded it using the command
>
>  ONES3<-read.table("ONES3.pdf",header=TRUE,na="NA")
>
>  I print out the dataset ONES3 to the screen to make sure it has loaded
>
>  Then I try to fit this data using the command fitdistr
>
>   fitdistr(ONES3,"chi-squared")
>
>  and it returns the comment
>
>  Error in fitdistr(ONES3, "chi-squared") : 'x' must be a non-empty numeric vector
>
>  Can anybody help with this, I imagine it is a common mistake for beginners like myself
>
>
>
> audaces fortuna iuvat
>
> ---------------------------------
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From eugen_pircalabelu at yahoo.com  Sun Sep  9 21:46:09 2007
From: eugen_pircalabelu at yahoo.com (eugen pircalabelu)
Date: Sun, 9 Sep 2007 12:46:09 -0700 (PDT)
Subject: [R] Survey package
Message-ID: <847670.81160.qm@web38610.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070909/b45a48a3/attachment.pl 

From realityrandom at gmail.com  Sun Sep  9 21:59:47 2007
From: realityrandom at gmail.com (Yuchen Luo)
Date: Sun, 9 Sep 2007 12:59:47 -0700
Subject: [R] What does it mean by "initial value not available"?
In-Reply-To: <548b8d440709091203i55566b78l3642b0f5701de37@mail.gmail.com>
References: <548b8d440709090401n5e09a9aeq88f77a76d27e39cd@mail.gmail.com>
	<46E3E8E9.3020700@stats.uwo.ca>
	<548b8d440709091203i55566b78l3642b0f5701de37@mail.gmail.com>
Message-ID: <548b8d440709091259g760e664fv2855661b515b4405@mail.gmail.com>

Dear Professor Mordoch.
Thank you very much for your help! Your time is highly appreciated!
I do intend to optimize over 3 parameters and the way I did it is
constrOptim(c(0.5,0.3,0.5), fit.error, fit.error.grr, ui=ui,ci=ci).

Also, There is a missing value for both sigmae and ss. (The last 3rd
and 4th line) Please correct them as:
sigmae=c(0.172239074,0.188209271,0.193703774,0.172659891,0.164427247,0.24602361,0.173555309,0.186701165,0.193150456,
0.1857315601)
ss=c(56.49,56.39,56.55,57.49 ,57.37,55.02,56.02,54.35,54.09,54.67)

Best Wishes
Yuchen Luo
> On 9/9/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > On 09/09/2007 7:01 AM, Yuchen Luo wrote:
> > > Dear friends.
> > > I use ConstrOptim( ) and got error message "initial value not
> available".
> > > My understanding of "initial value not available" is that one of the
> > > following 3 cases happens:
> > >
> > > 1.The objective function is not well defined at the point of the initial
> > > value.
> > > 2. The differentiation of the objective function is not well defined at
> > the
> > > point of the initial value.
> > > 3. The initial value violate the constrain of "ui %*% theta - ci >= 0"
> > >
> > > But my situation does not belong to any of the above cases.
> > >
> > > I have attached my code bellow and could you please help me take a look?
> >
> > I haven't tried your code, but there's one obvious error:
> > ...
> > > fit.error=function(rec,lambda,lbar)
> > > {sum((eval(apple)*1000-orange)^2/(orange^2))
> > > }
> >
> > The function optimizes over the elements of the first parameter.  You've
> > got two other parameters there, and I think you're trying to optimize
> > over them as well.  Put them all into one vector.
> >
> > The documentation for constrOptim doesn't make this as clear as it
> > should; I'll clarify (by copying the docs from ?optim).
> >
> > Duncan Murdoch
> >
> > >
> > >
> > > fit.error.grr=function(rec,lambda, lbar)
> > > {drec=sum(eval(D(apple,'rec'))*(eval(apple)*1000-orange)/(orange^2))
> > >
> dlambda=sum(eval(D(apple,'lambda'))*(eval(apple)*1000-orange)/(orange^2))
> > > dlbar=sum(eval(D(apple,'lbar'))*(eval(apple)*1000-orange)/(orange^2))
> > > c(drec,dlambda,dlbar)
> > > }
> > >
> > >
> > > rr=c(4.33,4.22,4.27,4.43,4.43,4.44,4.45,4.65,4.77,4.77)
> > > tot=rep(13319.17,10)
> > > sh=rep(1553656,10)
> > > sigmae=c(0.172239074,0.188209271,0.193703774,0.172659891,0.164427247,
> > > 0.24602361,0.173555309,0.186701165,0.193150456)
> > > ss=c(56.49,56.39,56.55,57.49,57.37,55.02,56.02,54.35,54.09)
> > > orange=rep(21.25,10)
> > >
> > > constrOptim(c(0.5,0.3,0.5), fit.error, fit.error.grr, ui=ui,ci=ci)
> > >
> > > 	[[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>


From pensterfuzzer at yahoo.de  Sun Sep  9 22:14:17 2007
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Sun, 9 Sep 2007 22:14:17 +0200 (CEST)
Subject: [R] Sweave figure aspect ratio
In-Reply-To: <46E3F3C0.3040201@stats.uwo.ca>
Message-ID: <191813.6745.qm@web23008.mail.ird.yahoo.com>

Many thanks for the quick reply, Duncan.

Now I see that something is going wrong in R already.
I overlooked this because the R window was so big. I
have to persuade plotViewport() not to create a square
area but one which takes the different margins into
account.

Best regards,
  Werner

--- Duncan Murdoch <murdoch at stats.uwo.ca> schrieb:

> On 09/09/2007 7:24 AM, Werner Wernersen wrote:
> > Hello,
> > 
> > using Sweave, is there any option to preserve the
> > original aspect ratio of plots generated from R
> code?
> > 
> > Consider this Sweave chunk:
> > <<test,echo=F,fig=T,width=2,height=2>>=
> > x <- 1:10
> > y <- sin(x)
> > par(mar=c(4,4,0,4))
> > plot(x,y,
> >      xlab="x label",
> >      ylab="y label"
> >      )
> > @
> > 
> > In Latex, I want to produce a plot of width 2 but
> > don't care about the height. If I put the width
> and
> > height like shown on the example, the box isn't
> square
> > any more. But if I put only width or height in the
> > Sweave option, then the values then the appearance
> is
> > totally off. 
> > 
> > Is there any option for Sweave or other
> possibility to
> > preserve the ratio of the sides of plots?
> 
> The width and height args in the header of the chunk
> are passed to the 
> graphics device (postscript or pdf), but they don't
> appear in the LaTeX 
> output.  To modify the appearance in LaTeX, you need
> to set a graphicx 
> package parameter, e.g. something like
> 
> \setkeys{Gin}{width=2in}
> <<test,echo=F,fig=T>>=
> x <- 1:10
> y <- sin(x)
> par(mar=c(4,4,0,4))
> plot(x,y,
>       xlab="x label",
>       ylab="y label"
>       )
> @
> 
> If you only specify width, then the aspect ratio
> will be maintained.
> 
> The \setkeys{} changes are persistent; as far as I
> know there's no way 
> to say "go back to the default" afterwards.  So what
> I'd suggest is to 
> define a macro (e.g. \Gwidth) to give the default
> width, and then call
> 
> \setkeys{Gin}{width=\Gwidth}
> 
> at the start of your document and after any change
> like the one above.
> 
> Duncan Murdoch
>


From dusa.adrian at gmail.com  Mon Sep 10 01:21:24 2007
From: dusa.adrian at gmail.com (Adrian Dusa)
Date: Mon, 10 Sep 2007 02:21:24 +0300
Subject: [R] [R-pkgs] QCA version 0.4-5
Message-ID: <200709100221.24440.dusa.adrian@gmail.com>


QCA implements the Qualitative Comparative Analysis using a boolean 
minimization algorithm for data coded with presence/absence of the causal 
conditions that affects a phenomenon of interest.

This new release has an experimental function that obtains the same exact 
solutions as the main minimization function, using a shortcut instead of the 
classical complete and exhaustive algorithm. This new function is faster and 
uses significantly less memory (50 MB compared to 1.5 GB for large datasets).

It should appear soon on CRAN, feedback is welcome.


-- 
Adrian Dusa
Romanian Social Data Archive
1, Schitu Magureanu Bd
050025 Bucharest sector 5
Romania
Tel./Fax: +40 21 3126618 \
          +40 21 3120210 / int.101

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From nick.chorley at gmail.com  Mon Sep 10 06:38:15 2007
From: nick.chorley at gmail.com (Nick Chorley)
Date: Mon, 10 Sep 2007 05:38:15 +0100
Subject: [R] NA in AR model residuals
In-Reply-To: <f5bc463e0709090927o24ffb140n7d2927d5e439a7a2@mail.gmail.com>
References: <f5bc463e0709090927o24ffb140n7d2927d5e439a7a2@mail.gmail.com>
Message-ID: <f5bc463e0709092138j6d55cf26qd4b0ada2bc49b3f1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070910/34b14433/attachment.pl 

From r.darnell at uq.edu.au  Mon Sep 10 07:54:48 2007
From: r.darnell at uq.edu.au (Ross Darnell)
Date: Mon, 10 Sep 2007 15:54:48 +1000
Subject: [R] lattice panel.lmline problem
Message-ID: <E4178EE0463C7D40AF637C4DDAC8030EC3E472@UQEXMB2.soe.uq.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070910/25cb9ba7/attachment.pl 

From lauri.nikkinen at iki.fi  Mon Sep 10 08:05:27 2007
From: lauri.nikkinen at iki.fi (Lauri Nikkinen)
Date: Mon, 10 Sep 2007 09:05:27 +0300
Subject: [R] plot legend: combining filled boxes and lines
Message-ID: <ba8c09910709092305y2e30640bg9b6dea975c589240@mail.gmail.com>

Hello,

I have difficulties combining boxes and lines in plot legend. I
searched previous R-posts and found this (with no solution):
http://tolstoy.newcastle.edu.au/R/help/06/07/30248.html. Is there a
way to avoid boxes behind the line legends?

x1 <- rnorm(100)
x2 <- rnorm(100, 2)
hist(x1, main = "", col = "orange",ylab = "density", xlab = "x", freq
= F, density = 55,  xlim = c(-2, 5), ylim = c(0, 0.5))
par(new = T)
hist(x2, main = "", col = "green", ylab = "", xlab = "",axes = F, xlim
= c(-2, 5), ylim = c(0, 0.5), density = 45, freq = F)

abline(v = mean(x1), col = "orange", lty = 2, lwd = 2.5)
abline(v = mean(x2), col = "green", lty = 2, lwd = 2.5)
legend(3, 0.45, legend = c("x1", "x2", "mean(x1)", "mean(x2)"), col =
c("orange", "green"), fill=c("orange","green", 0, 0),  lty = c(0, 0,
2, 2), merge = T)

Thanks
Lauri


From ggrothendieck at gmail.com  Mon Sep 10 08:17:44 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 10 Sep 2007 02:17:44 -0400
Subject: [R] plot legend: combining filled boxes and lines
In-Reply-To: <ba8c09910709092305y2e30640bg9b6dea975c589240@mail.gmail.com>
References: <ba8c09910709092305y2e30640bg9b6dea975c589240@mail.gmail.com>
Message-ID: <971536df0709092317h6b3b3ddcr600c3d89a3e6bbc1@mail.gmail.com>

Check out:
http://tolstoy.newcastle.edu.au/R/e2/help/07/05/16777.html

On 9/10/07, Lauri Nikkinen <lauri.nikkinen at iki.fi> wrote:
> Hello,
>
> I have difficulties combining boxes and lines in plot legend. I
> searched previous R-posts and found this (with no solution):
> http://tolstoy.newcastle.edu.au/R/help/06/07/30248.html. Is there a
> way to avoid boxes behind the line legends?
>
> x1 <- rnorm(100)
> x2 <- rnorm(100, 2)
> hist(x1, main = "", col = "orange",ylab = "density", xlab = "x", freq
> = F, density = 55,  xlim = c(-2, 5), ylim = c(0, 0.5))
> par(new = T)
> hist(x2, main = "", col = "green", ylab = "", xlab = "",axes = F, xlim
> = c(-2, 5), ylim = c(0, 0.5), density = 45, freq = F)
>
> abline(v = mean(x1), col = "orange", lty = 2, lwd = 2.5)
> abline(v = mean(x2), col = "green", lty = 2, lwd = 2.5)
> legend(3, 0.45, legend = c("x1", "x2", "mean(x1)", "mean(x2)"), col =
> c("orange", "green"), fill=c("orange","green", 0, 0),  lty = c(0, 0,
> 2, 2), merge = T)
>
> Thanks
> Lauri
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From carlosmoralesdiego at yahoo.es  Sun Sep  9 11:57:51 2007
From: carlosmoralesdiego at yahoo.es (Carlos Morales)
Date: Sun, 9 Sep 2007 11:57:51 +0200 (CEST)
Subject: [R]  Problems with strsplit
Message-ID: <333079.5017.qm@web25612.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070909/0dbd6d95/attachment.pl 

From lauri.nikkinen at iki.fi  Mon Sep 10 08:40:31 2007
From: lauri.nikkinen at iki.fi (Lauri Nikkinen)
Date: Mon, 10 Sep 2007 09:40:31 +0300
Subject: [R] plot legend: combining filled boxes and lines
In-Reply-To: <971536df0709092317h6b3b3ddcr600c3d89a3e6bbc1@mail.gmail.com>
References: <ba8c09910709092305y2e30640bg9b6dea975c589240@mail.gmail.com>
	<971536df0709092317h6b3b3ddcr600c3d89a3e6bbc1@mail.gmail.com>
Message-ID: <ba8c09910709092340i61da843vad4f10b6ee5916f7@mail.gmail.com>

Thanks Gabor, I got it!

For example:
x1 <- rnorm(100)
x2 <- rnorm(100, 2)
hist(x1, main = "", col = "orange",ylab = "density", xlab = "x", freq
= F, density = 55, xlim = c(-2, 5), ylim = c(0, 0.5))
par(new = T)
hist(x2, main = "", col = "green", ylab = "", xlab = "",axes = F, xlim
= c(-2, 5), ylim = c(0, 0.5), density = 45, freq = F)

abline(v = mean(x1), col = "orange", lty = 2, lwd = 2.5)
abline(v = mean(x2), col = "green", lty = 2, lwd = 2.5)
legend(3, 0.45, legend = c("x1", "x2", "mean(x1)", "mean(x2)"),
       col = rep(c("orange", "green"), 2), pch=c(15,15, NA, NA),
       pt.cex=2,
       lty = c(0, 0, 2, 2))

-Lauri



2007/9/10, Gabor Grothendieck <ggrothendieck at gmail.com>:
> Check out:
> http://tolstoy.newcastle.edu.au/R/e2/help/07/05/16777.html
>
> On 9/10/07, Lauri Nikkinen <lauri.nikkinen at iki.fi> wrote:
> > Hello,
> >
> > I have difficulties combining boxes and lines in plot legend. I
> > searched previous R-posts and found this (with no solution):
> > http://tolstoy.newcastle.edu.au/R/help/06/07/30248.html. Is there a
> > way to avoid boxes behind the line legends?
> >
> > x1 <- rnorm(100)
> > x2 <- rnorm(100, 2)
> > hist(x1, main = "", col = "orange",ylab = "density", xlab = "x", freq
> > = F, density = 55,  xlim = c(-2, 5), ylim = c(0, 0.5))
> > par(new = T)
> > hist(x2, main = "", col = "green", ylab = "", xlab = "",axes = F, xlim
> > = c(-2, 5), ylim = c(0, 0.5), density = 45, freq = F)
> >
> > abline(v = mean(x1), col = "orange", lty = 2, lwd = 2.5)
> > abline(v = mean(x2), col = "green", lty = 2, lwd = 2.5)
> > legend(3, 0.45, legend = c("x1", "x2", "mean(x1)", "mean(x2)"), col =
> > c("orange", "green"), fill=c("orange","green", 0, 0),  lty = c(0, 0,
> > 2, 2), merge = T)
> >
> > Thanks
> > Lauri
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From FredeA.Togersen at agrsci.dk  Mon Sep 10 08:45:05 2007
From: FredeA.Togersen at agrsci.dk (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Mon, 10 Sep 2007 08:45:05 +0200
Subject: [R] lattice panel.lmline problem
In-Reply-To: <E4178EE0463C7D40AF637C4DDAC8030EC3E472@UQEXMB2.soe.uq.edu.au>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC0574AEE3@DJFPOST01.djf.agrsci.dk>

Why not use the more simple

xyplot(total.fat~x|variable,groups=Group,
       data=tmp1,type=c("p","r"))

???

See ?panel.xyplot and especially the type argument of that panel function.




Best regards

Frede Aakmann T?gersen
Scientist


UNIVERSITY OF AARHUS
Faculty of Agricultural Sciences
Dept. of Genetics and Biotechnology
Blichers All? 20, P.O. BOX 50
DK-8830 Tjele

Phone:   +45 8999 1900
Direct:  +45 8999 1878

E-mail:  FredeA.Togersen at agrsci.dk
Web:	   http://www.agrsci.org				

This email may contain information that is confidential.
Any use or publication of this email without written permission from Faculty of Agricultural Sciences is not allowed.
If you are not the intended recipient, please notify Faculty of Agricultural Sciences immediately and delete this email.


 

> -----Oprindelig meddelelse-----
> Fra: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] P? vegne af Ross Darnell
> Sendt: 10. september 2007 07:55
> Til: r-help at stat.math.ethz.ch
> Emne: [R] lattice panel.lmline problem
> 
> I am wanting to generate panels showing scatterplots with the 
> linear fitted line for two groups within each panel superimposed.
> 
> I have two conditioning factors, "variable" and "Group" and I 
> want separate panels for each level of "variable"
> 
> with different symbols and "lmline"s for each level of 
> "Group". However all observations for a group are missing for 
> some variables so I would still like the points and lmline 
> for the observed group plotted for that variable(panel).
> 
>  
> 
> My attempt is 
> 
>  
> 
> print(xyplot(total.fat~x|variable,data=tmp1,subscripts=TRUE,
> 
>              
> scales=list(x=list(relation="free")),xlab="",groups=Group,
> 
>              panel=function(x,y,subscripts,...){
> 
>                panel.superpose(x,y,subscripts,...)
> 
>                if(length(x[subscripts])!=0)
> 
>  
> {panel.superpose(x,y,panel.groups="panel.lmline",subscripts,...)}}))
> 
>  
> 
> Which gives an error
> 
>  
> 
> Error in lm.fit(x, y, offset = offset, singular.ok = 
> singular.ok, ...) :
> 
> 
>             0 (non-NA) cases
> 
> > 
> 
>  
> 
> Which occurs when the first panel with all values for one 
> group are missing.
> 
> The same error is returned if I replace the last line without the "if"
> statement which obviously means it's ignored.
> 
>  
> 
> Of course I may be taking the wrong tack completely to get 
> the result I need. Any advice would be appreciated
> 
>   
> 
>  
> 
> Ross Darnell
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From realityrandom at gmail.com  Mon Sep 10 08:58:28 2007
From: realityrandom at gmail.com (Yuchen Luo)
Date: Sun, 9 Sep 2007 23:58:28 -0700
Subject: [R] Are the error messages of ConstrOptim() consisten with each
	other?
Message-ID: <548b8d440709092358g3cd079cehd459e8592bb9673c@mail.gmail.com>

Dear Friends.
I found something very puzzling with constOptim(). When I change the
parameters for ConstrOptim, the error messages do not seem to be
consistent with each other:

> constrOptim(c(0.5,0.3,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
Error in constrOptim(c(0.5, 0.3, 0.5), f = fit.error, gr = fit.error.grr,  :
        initial value not feasible
> constrOptim(c(0.5,0.9,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
Error in constrOptim(c(0.5, 0.9, 0.5), f = fit.error, gr = fit.error.grr,  :
        initial value not feasible
> constrOptim(c(0.3,0.5,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
Error in f(theta, ...) : argument "lambda1" is missing, with no default

I only changed the parameters, how come the lambda1 that is not
missing in the first 2 cases suddently become missing?

For your convenience, I put the complete code below:

Best Wishes
Yuchen Luo

########################################
rm(list = ls())

mat=5

rint=c(4.33,4.22,4.27,4.43,4.43,4.44,4.45,4.65,4.77,4.77)
tot=rep(13319.17,10)
sh=rep(1553656,10)
sigmae=c(0.172239074,0.188209271,0.193703774,0.172659891,0.164427247,0.24602361,0.173555309,0.186701165,0.193150456,
0.1857315601)
ss=c(56.49,56.39,56.55,57.49,57.37,55.02,56.02,54.35,54.09, 54.67)
orange=rep(21.25,10)

apple2=expression(rint*(1.0-rec)*(1.0-(pnorm(-lambda/2.0+log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/lambda)-((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))*pnorm(-lambda/2.0-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/lambda))+(exp(rint*(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))*((((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))))-(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))))))/((pnorm(-lambda/2.0+log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/lambda)-((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))*pnorm(-lambda/2.0-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/lambda))-(pnorm(-sqrt((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*mat+lambda*lambda)/2.0+log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/sqrt((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*mat+lambda*lambda))-((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))*pnorm(-sqrt((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*mat+lambda*lambda)/2.0-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/sqrt((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*mat+lambda*lambda)))*exp(-rint*mat)-(exp(rint*(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))*((((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))))-(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))))))))

apple.ana= function(rec1,lambda1,lbar1)
{rec=rec1
lambda=lambda1
lbar=lbar1
apple=eval(apple2)
gradient=cbind(eval(D(apple2,'rec')),eval(D(apple2,'lambda')),
eval(D(apple2,'lbar')))
attr(apple.ana,'gradient')=gradient
apple
}

fit.error=function(rec1,lambda1,lbar1)
{rec=rec1
lambda=lambda1
lbar=lbar1
sum((eval(apple2)*1000-orange)^2/(orange^2))
}

fit.error.grr=function(rec1,lambda1,lbar1)
{rec=rec1
lambda=lambda1
lbar=lbar1

drec=sum(20000*eval(D(apple2,'rec'))*(eval(apple2)*10000-orange)/(orange^2))
dlambda=sum(20000*eval(D(apple2,'lambda'))*(eval(apple2)*10000-orange)/(orange^2))
dlbar=sum(20000*eval(D(apple2,'lbar'))*(eval(apple2)*10000-orange)/(orange^2))

c(drec,dlambda,dlbar)
}

ui=matrix(c(1,-1,0,0,0,0,0,0,1,-1,0,0,0,0,0,0,1,-1),6,3)
ci=c(0,-0.5,0,-2,0,-0.6)

constrOptim(c(0.5,0.3,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
constrOptim(c(0.5,0.9,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
constrOptim(c(0.3,0.5,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)

###########################################################


From Giovanni_Millo at Generali.com  Mon Sep 10 09:02:33 2007
From: Giovanni_Millo at Generali.com (Millo Giovanni)
Date: Mon, 10 Sep 2007 09:02:33 +0200
Subject: [R]  statistical tests under serial dependence
Message-ID: <7C95FD2FC68FBB45B9E9FDC1ECD49AF50296325B@BEMAILEXTV03.corp.generali.net>

Dear Rosa,

please be more specific. Statistical tests for which hypothesis?

For example, some tests can be made robust using Heteroskedasticity-
*and Autocorrelation-* Consistent (HAC) covariance matrices in package
'sandwich': see
- waldtest{lmtest} for a redundant variables test much like anova().
- linear.hypothesis{car} for general linear hypothesis testing in linear
regression models.

Besides, I'm very ignorant about VIF but I remember there being an
article in R-News some years ago, see
http://cran.r-project.org/doc/Rnews/Rnews_2003-1.pdf.

I hope it helps.
Giovanni

## original message was: ##

------------------------------

Message: 21
Date: Sat, 08 Sep 2007 19:25:07 +0100
From: Rosa Trancoso <ana.rosa.maretec at ist.utl.pt>
Subject: [R] statistical tests under serial dependence
To: r-help at stat.math.ethz.ch
Message-ID: <46E2E903.2010904 at ist.utl.pt>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

Hello!

I would like to know if there are already programmed statistical tests 
for data under serial dependence, for example, considering the variance 
inflation factor?


Thank you very much
Best regards
Rosa

############################

Giovanni Millo
Research Dept.,
Assicurazioni Generali SpA
Via Machiavelli 4, 
34131 Trieste (Italy)
tel. +39 040 671184 
fax  +39 040 671160
 
Ai sensi del D.Lgs. 196/2003 si precisa che le informazioni ...{{dropped}}


From m_olshansky at yahoo.com  Mon Sep 10 09:49:58 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Mon, 10 Sep 2007 00:49:58 -0700 (PDT)
Subject: [R] Problems with strsplit
In-Reply-To: <333079.5017.qm@web25612.mail.ukl.yahoo.com>
Message-ID: <854696.52635.qm@web32208.mail.mud.yahoo.com>

> unlist(strsplit("bA531F16-rep","\\-"))[1]
[1] "bA531F16"

--- Carlos Morales <carlosmoralesdiego at yahoo.es>
wrote:

> Hello,
>    
>   I would like to know what can I do if I use
> strplit with a string and I want to use the middle
> left,I mean I have this:
>    
>   strsplit("bA531F16-rep","\\-")
>   [[1]]
> [1] "bA531F16" "rep"    
>   I would like to work just with bA531F16 in another
> variable, what could I do?, Thank you
>    
> 
>        
> ---------------------------------
> 
> S? un Mejor Amante del Cine
> ?Quieres saber c?mo? ?Deja que otras personas te
> ayuden!.
> 
> 	[[alternative HTML version deleted]]
> 
> > ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From jim at bitwrit.com.au  Mon Sep 10 11:59:37 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 10 Sep 2007 19:59:37 +1000
Subject: [R] command to plot variannce of data (like error bar plot)
In-Reply-To: <71cc5ca20709090646xe5d9e07t2dd060e55246de2c@mail.gmail.com>
References: <71cc5ca20709090646xe5d9e07t2dd060e55246de2c@mail.gmail.com>
Message-ID: <46E51589.9030608@bitwrit.com.au>

Yogesh Tiwari wrote:
> Hi,
> 
> How to plot a variance over a data point, something like error bar.
> 
Hi Yogesh,

The generic method is to use the "arrows" function, and there are quite 
a few variations on this theme (in alpha order):

brkdn.plot(plotrix)
dispbars(plotrix)
errbar(Hmisc and sfsmisc)
plotCI(gplots and plotrix)
plotMeans (Rcmdr)

and there are surely more error bar functions of which I am unaware.

Jim


From bchristo at email.arizona.edu  Mon Sep 10 12:08:01 2007
From: bchristo at email.arizona.edu (Brad Christoffersen)
Date: Mon, 10 Sep 2007 03:08:01 -0700
Subject: [R] overlay lattice histograms with goodness-of-fit pdfs
Message-ID: <20070910030801.zxlc80gs44wckk0s@www.email.arizona.edu>

Hello,

I am new to R exploratory data analysis and plotting.  Is anyone aware of a way
to overlay a set of conditional histograms with conditional PDFs?  Below, I
generate a lattice plot of precipitation histograms based on different months
and stations, given a subset of the dataset:


histogram(~ data | month * station,
	data = sta.stack[sta.stack[,"type"]=="precip" & (sta.stack[,"month"]=="Dec" |
sta.stack[,"month"]=="Jan" | sta.stack[,"month"]=="Feb"),],
	xlab = "Precipitation (mm)")


I previously used a combination of the low-level 'lines()' and 'dgamma()'
functions to overlay a gamma PDF onto a single histogram.  Now what I would
like to do is to do the same thing, but with a function that allows me to
specify a formula similar to that in the histogram function above

[SomeKindOfPDF] ~ [x-range] | month * station

which will plot the PDF with the appropriate factors (month and station).

All I'm looking for is for someone to get me going in the right direction with a
useful package or function to use.

Any help is much appreciated!
Brad Christoffersen


From murdoch at stats.uwo.ca  Mon Sep 10 12:11:53 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 10 Sep 2007 06:11:53 -0400
Subject: [R] Are the error messages of ConstrOptim() consisten with each
 other?
In-Reply-To: <548b8d440709092358g3cd079cehd459e8592bb9673c@mail.gmail.com>
References: <548b8d440709092358g3cd079cehd459e8592bb9673c@mail.gmail.com>
Message-ID: <46E51869.9070809@stats.uwo.ca>

Yuchen Luo wrote:
> Dear Friends.
> I found something very puzzling with constOptim(). When I change the
> parameters for ConstrOptim, the error messages do not seem to be
> consistent with each other:
>
>   
>> constrOptim(c(0.5,0.3,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
>>     
> Error in constrOptim(c(0.5, 0.3, 0.5), f = fit.error, gr = fit.error.grr,  :
>         initial value not feasible
>   
"Not feasible" means it doesn't satisfy the constraints.
>> constrOptim(c(0.5,0.9,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
>>     
> Error in constrOptim(c(0.5, 0.9, 0.5), f = fit.error, gr = fit.error.grr,  :
>         initial value not feasible
>   
>> constrOptim(c(0.3,0.5,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
>>     
> Error in f(theta, ...) : argument "lambda1" is missing, with no default
>   

This time your starting values satisfied the constraints, so your 
objective function was called, but you didn't pass it a value for lambda1.
> I only changed the parameters, how come the lambda1 that is not
> missing in the first 2 cases suddently become missing?
>
> For your convenience, I put the complete code below:
>
> Best Wishes
> Yuchen Luo
>
> ########################################
> rm(list = ls())
>
> mat=5
>
> rint=c(4.33,4.22,4.27,4.43,4.43,4.44,4.45,4.65,4.77,4.77)
> tot=rep(13319.17,10)
> sh=rep(1553656,10)
> sigmae=c(0.172239074,0.188209271,0.193703774,0.172659891,0.164427247,0.24602361,0.173555309,0.186701165,0.193150456,
> 0.1857315601)
> ss=c(56.49,56.39,56.55,57.49,57.37,55.02,56.02,54.35,54.09, 54.67)
> orange=rep(21.25,10)
>
> apple2=expression(rint*(1.0-rec)*(1.0-(pnorm(-lambda/2.0+log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/lambda)-((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))*pnorm(-lambda/2.0-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/lambda))+(exp(rint*(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))*((((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*!
>  1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))))-(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lam!
>  bda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*
> 1000.0))))))-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))))))/((pnorm(-lambda/2.0+log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/lambda)-((ss+(tot/sh*100!
>  0.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))*pnorm(-lambda/2.0-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/lambda))-(pnorm(-sqrt((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*mat+lambda*lambda)/2.0+log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/sqrt((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*mat+lambda*lambda))-((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))*pnorm(-sqrt((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*mat+lambda*lambda)/2.0-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/sqrt((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*mat+lambda*lambda)))*exp(-rint*mat)-(exp(rint*(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))*((((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(sqrt(0.!
>  25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*
> (tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lb!
>  ar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))))-(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*!
>  lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(
> sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))))))))
>
> apple.ana= function(rec1,lambda1,lbar1)
> {rec=rec1
> lambda=lambda1
> lbar=lbar1
> apple=eval(apple2)
> gradient=cbind(eval(D(apple2,'rec')),eval(D(apple2,'lambda')),
> eval(D(apple2,'lbar')))
> attr(apple.ana,'gradient')=gradient
> apple
> }
>
> fit.error=function(rec1,lambda1,lbar1)
> {rec=rec1
> lambda=lambda1
> lbar=lbar1
> sum((eval(apple2)*1000-orange)^2/(orange^2))
> }
>   

This is still coded incorrectly.  Objective functions optimize over the 
first parameter only.  See ?optim for the details.  constrOptim is just 
a wrapper for optim.

Duncan Murdoch
> fit.error.grr=function(rec1,lambda1,lbar1)
> {rec=rec1
> lambda=lambda1
> lbar=lbar1
>
> drec=sum(20000*eval(D(apple2,'rec'))*(eval(apple2)*10000-orange)/(orange^2))
> dlambda=sum(20000*eval(D(apple2,'lambda'))*(eval(apple2)*10000-orange)/(orange^2))
> dlbar=sum(20000*eval(D(apple2,'lbar'))*(eval(apple2)*10000-orange)/(orange^2))
>
> c(drec,dlambda,dlbar)
> }
>
> ui=matrix(c(1,-1,0,0,0,0,0,0,1,-1,0,0,0,0,0,0,1,-1),6,3)
> ci=c(0,-0.5,0,-2,0,-0.6)
>
> constrOptim(c(0.5,0.3,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
> constrOptim(c(0.5,0.9,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
> constrOptim(c(0.3,0.5,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
>
> ###########################################################
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r.darnell at uq.edu.au  Mon Sep 10 12:17:06 2007
From: r.darnell at uq.edu.au (Ross Darnell)
Date: Mon, 10 Sep 2007 20:17:06 +1000
Subject: [R] lattice panel.lmline problem
References: <C83C5E3DEEE97E498B74729A33F6EAEC0574AEE3@DJFPOST01.djf.agrsci.dk>
Message-ID: <E4178EE0463C7D40AF637C4DDAC8030E23DE63@UQEXMB2.soe.uq.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070910/e4a841f6/attachment.pl 

From bhs2 at mevik.net  Mon Sep 10 12:41:16 2007
From: bhs2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Mon, 10 Sep 2007 12:41:16 +0200
Subject: [R] PCA IN R
In-Reply-To: <cdf817830709070853v58bc09d1y13b0710675e82fe8@mail.gmail.com>
	(Weiwei Shi's message of "Fri, 7 Sep 2007 11:53:10 -0400")
References: <cdf817830709070853v58bc09d1y13b0710675e82fe8@mail.gmail.com>
Message-ID: <m0abruls4z.fsf@bar.nemo-project.org>

prcomp() in stats handles matrices with n < p well, IMO.

-- 
Bj?rn-Helge Mevik


From maechler at stat.math.ethz.ch  Mon Sep 10 12:34:29 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 10 Sep 2007 12:34:29 +0200
Subject: [R] artificial data matrix with 100000 rows
In-Reply-To: <6ade6f6c0709090417p29895b49p6424e45aaf57e9f0@mail.gmail.com>
References: <12577936.post@talk.nabble.com>
	<6ade6f6c0709090417p29895b49p6424e45aaf57e9f0@mail.gmail.com>
Message-ID: <18149.7605.923164.22853@stat.math.ethz.ch>

>>>>> "PS" == Paul Smith <phhs80 at gmail.com>
>>>>>     on Sun, 9 Sep 2007 12:17:32 +0100 writes:

    PS> On 9/9/07, kevinchang <shukai at seas.upenn.edu> wrote:
    >> I tried to made the matrix with this size by either matrix() or array().
    >> However, there seems to be default limit of number for rows made. I got sort
    >> of error message from R .To be specific,
    >> 
    >> m<--matrix(ncol=3,nrow=100000)
    >> 
    >> error message:[ reached getOption("max.print") -- omitted 66667 rows ]]
    >> 
    >> or
    >> 
    >> a<-array(dim=c(10000,3,10))
    >> 
    >> error message:reached getOption("max.print") -- omitted 6667 row(s) and 6
    >> matrix slice(s) ]

    PS> That is not an error message, I guess. 

Definitely not,
thank you, Paul!

Also, they were not produced by what Kevin showed (namely assignments)
but rather when he *prints* the contents of his huge matrix /
array.

    PS> When the matrices are huge, R is unable to print them
    PS> totally on the screen, but all data are present.

Not at all "unable" !!
R protects you from accidentally overflowing your "console" with
huge amount of non-sensical output.

As the warning above mentions,
you should look at
  ? getOption
  ? options
and particularly the  'max.print'  option

Is  '' reached  getOption("max.print") '' 
too difficult to read?

You *can* increase the 'max.print' option as much as you like,
and that's why I said     'not at all "unable"'   above.

Regards,
Martin

    PS> For instance,

    >> m[(nrow(m)-10):nrow(m),]
    PS> [,1] [,2] [,3]
    PS> [1,]   NA   NA   NA
    PS> [2,]   NA   NA   NA
    PS> [3,]   NA   NA   NA
    PS> [4,]   NA   NA   NA
    PS> [5,]   NA   NA   NA
    PS> [6,]   NA   NA   NA
    PS> [7,]   NA   NA   NA
    PS> [8,]   NA   NA   NA
    PS> [9,]   NA   NA   NA
    PS> [10,]   NA   NA   NA
    PS> [11,]   NA   NA   NA

or rather just

   tail(m)

or tail(m, 11)
or head(m)

or str(m)

etc etc

    PS> See

    PS> ?getOption

yes indeed.
Martin

    PS> Paul


From FredeA.Togersen at agrsci.dk  Mon Sep 10 12:40:26 2007
From: FredeA.Togersen at agrsci.dk (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Mon, 10 Sep 2007 12:40:26 +0200
Subject: [R] overlay lattice histograms with goodness-of-fit pdfs
In-Reply-To: <20070910030801.zxlc80gs44wckk0s@www.email.arizona.edu>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC0574AF39@DJFPOST01.djf.agrsci.dk>


The following is one of the examples in the help page for histogram:

     histogram( ~ height | voice.part, data = singer,
               xlab = "Height (inches)", type = "density",
               panel = function(x, ...) {
                   panel.histogram(x, ...)
                   panel.mathdensity(dmath = dnorm, col = "black",
                                     args = list(mean=mean(x),sd=sd(x)))
               } )

This should give you some thing to start from.

Also using the subset argument of the lattice functions will make make your code more readable. Instead of your code

histogram(~ data | month * station,
	data = sta.stack[sta.stack[,"type"]=="precip" & (sta.stack[,"month"]=="Dec" | sta.stack[,"month"]=="Jan" | sta.stack[,"month"]=="Feb"),],
	xlab = "Precipitation (mm)")

you can use (not tested because you didn't supply a reproducable example)

histogram(~ data | month * station, data = sta.stack
	subset = type==precip & month %in% c("Dec", "Jan", "Feb"),
	xlab = "Precipitation (mm)")


Med venlig hilsen
Frede Aakmann T?gersen
 

 

> -----Oprindelig meddelelse-----
> Fra: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] P? vegne af Brad 
> Christoffersen
> Sendt: 10. september 2007 12:08
> Til: R-help at stat.math.ethz.ch
> Emne: [R] overlay lattice histograms with goodness-of-fit pdfs
> 
> Hello,
> 
> I am new to R exploratory data analysis and plotting.  Is 
> anyone aware of a way to overlay a set of conditional 
> histograms with conditional PDFs?  Below, I generate a 
> lattice plot of precipitation histograms based on different 
> months and stations, given a subset of the dataset:
> 
> 
> histogram(~ data | month * station,
> 	data = sta.stack[sta.stack[,"type"]=="precip" & 
> (sta.stack[,"month"]=="Dec" | sta.stack[,"month"]=="Jan" | 
> sta.stack[,"month"]=="Feb"),],
> 	xlab = "Precipitation (mm)")
> 
> 
> I previously used a combination of the low-level 'lines()' 
> and 'dgamma()'
> functions to overlay a gamma PDF onto a single histogram.  
> Now what I would like to do is to do the same thing, but with 
> a function that allows me to specify a formula similar to 
> that in the histogram function above
> 
> [SomeKindOfPDF] ~ [x-range] | month * station
> 
> which will plot the PDF with the appropriate factors (month 
> and station).
> 
> All I'm looking for is for someone to get me going in the 
> right direction with a useful package or function to use.
> 
> Any help is much appreciated!
> Brad Christoffersen
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From adelagm at ugr.es  Mon Sep 10 11:35:16 2007
From: adelagm at ugr.es (Adela =?iso-8859-1?Q?Gonz=E1lez_Meg=EDas?=)
Date: Mon, 10 Sep 2007 11:35:16 +0200 (CEST)
Subject: [R] Information theoretic approach
Message-ID: <2200.83.45.80.23.1189416916.squirrel@goliat7.ugr.es>


Hi,



I have been suggested to use Information theoretic approach instead of a
Geneal linear model for a multiple regression. Is is possible to perform
this type of anlaysis in R?


Thanks,

Adela


-- 
Adela Gonz?lez Meg?as
Depto. Biolog?a Animal
Fac. Ciencias
Universidad de Granada
18071 Granada
Spain

tel: +34 958242309
fax: +34 958243238


From kalyan.roy at imrbint.com  Mon Sep 10 12:02:32 2007
From: kalyan.roy at imrbint.com (Kalyan Roy (DEL/MSG))
Date: Mon, 10 Sep 2007 15:32:32 +0530
Subject: [R] Help in installing and loading the BradleyTerry add on package
	in R
Message-ID: <000601c7f391$b6bd8670$cd32a8c0@delpdc.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070910/9d63a2d3/attachment.pl 

From jim at bitwrit.com.au  Mon Sep 10 13:06:41 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 10 Sep 2007 21:06:41 +1000
Subject: [R] Help in installing and loading the BradleyTerry add on
 package in R
In-Reply-To: <000601c7f391$b6bd8670$cd32a8c0@delpdc.local>
References: <000601c7f391$b6bd8670$cd32a8c0@delpdc.local>
Message-ID: <46E52541.3080907@bitwrit.com.au>

Kalyan Roy (DEL/MSG) wrote:
> How do I install and load the BradleyTerry add on package in R 2.5.1 in
> MSWindowsXP environment?
> 
Hi Kalyan,
If

R CMD INSTALL

doesn't work, you can use WinZip or Zip Reader to unzip the package to:

C:\Program Files\R-2.5.1\library

or whatever your path to the "library" directory is, and then hand edit 
the "packages.html" file in:

C:\Program Files\R-2.5.1\doc\html

to include the new package in your HTML listing. This will allow you to 
access the help files and use the package.

Jim


From S.Ellison at lgc.co.uk  Mon Sep 10 13:05:20 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Mon, 10 Sep 2007 12:05:20 +0100
Subject: [R] Plotting lines to sets of points
Message-ID: <s6e5331a.067@tedmail2.lgc.co.uk>

see ?segments. 

And you can tidy up your subsetting with some with's while you're at it, although a function would be nicer still.

Looking at your code, you probably need something like

with(subset(framename, hit_traj=="line_drive"),
	segments(rep(125,length(hit_x)) , rep(-210,length(hit_y)), hit_x, hit_y, col="blue")
) #You can put it all on one line for convenience of repetition but its not as readable

with(subset(framename, hit_traj=="line_drive"),
	points(hit_x, hit_y, pch=20, col="red")
)


btw: seems an odd coordinate system. Why not put the hitter at the origin?




Steve E

>>> lawnboy34 <jay.pare at gmail.com> 08/09/2007 00:01:22 >>>

I am using R to plot baseball spray charts from play-by-play data. I have
used the following command to plot the diamond:

plot (0:250, -250:0, type="n", bg="white")
	lines(c(125,150,125,100,125),c(-210,-180,-150,-180,-210), col=c("black"))

I have also plotted different hit locations using commands such as the
following:

points(subset(framename$hit_x, framename$hit_traj=="line_drive"),
subset(-framename$hit_y, framename$hit_traj=="line_drive"), pch=20,
col=c("red"))

My question: Is there any easy way to plot a line from the origin (home
plate) to each point on the graph? Preferably the line would share the same
color as the dot that denotes where the ball landed. I have tried searching
Google and these forums, and most graphing questions have to do with
scatterplots or other varieties of graphs I am not using. Thanks very much
in advance.

-Jason
-- 
View this message in context: http://www.nabble.com/Plotting-lines-to-sets-of-points-tf4404235.html#a12564704 
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code.

*******************************************************************
This email and any attachments are confidential. Any use, co...{{dropped}}


From Heather.Turner at warwick.ac.uk  Mon Sep 10 13:42:20 2007
From: Heather.Turner at warwick.ac.uk (Turner, Heather)
Date: Mon, 10 Sep 2007 12:42:20 +0100
Subject: [R] Help in installing and loading the BradleyTerry add on
	package in R
In-Reply-To: <46E52541.3080907@bitwrit.com.au>
References: <000601c7f391$b6bd8670$cd32a8c0@delpdc.local>
	<46E52541.3080907@bitwrit.com.au>
Message-ID: <1072002710EB6047A212400EEB65F00676E30D@ELDER.ads.warwick.ac.uk>

However you may also need to install the package brlr, since the
BradleyTerry package depends on this.

For Windows users, it's usually easiest to install packages using the
Packages menu in the RGui - any dependencies are then automatically
installed.

Heather

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jim Lemon
Sent: 10 September 2007 12:07
To: kalyan.roy at imrbint.com
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Help in installing and loading the BradleyTerry add on
package in R

Kalyan Roy (DEL/MSG) wrote:
> How do I install and load the BradleyTerry add on package in R 2.5.1
in
> MSWindowsXP environment?
> 
Hi Kalyan,
If

R CMD INSTALL

doesn't work, you can use WinZip or Zip Reader to unzip the package to:

C:\Program Files\R-2.5.1\library

or whatever your path to the "library" directory is, and then hand edit 
the "packages.html" file in:

C:\Program Files\R-2.5.1\doc\html

to include the new package in your HTML listing. This will allow you to 
access the help files and use the package.

Jim

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From phhs80 at gmail.com  Mon Sep 10 14:44:51 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Mon, 10 Sep 2007 13:44:51 +0100
Subject: [R] artificial data matrix with 100000 rows
In-Reply-To: <18149.7605.923164.22853@stat.math.ethz.ch>
References: <12577936.post@talk.nabble.com>
	<6ade6f6c0709090417p29895b49p6424e45aaf57e9f0@mail.gmail.com>
	<18149.7605.923164.22853@stat.math.ethz.ch>
Message-ID: <6ade6f6c0709100544u6d34c6b3mbef4861dce1f053c@mail.gmail.com>

On 9/10/07, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>     PS> On 9/9/07, kevinchang <shukai at seas.upenn.edu> wrote:
>     >> I tried to made the matrix with this size by either matrix() or array().
>     >> However, there seems to be default limit of number for rows made. I got sort
>     >> of error message from R .To be specific,
>     >>
>     >> m<--matrix(ncol=3,nrow=100000)
>     >>
>     >> error message:[ reached getOption("max.print") -- omitted 66667 rows ]]
>     >>
>     >> or
>     >>
>     >> a<-array(dim=c(10000,3,10))
>     >>
>     >> error message:reached getOption("max.print") -- omitted 6667 row(s) and 6
>     >> matrix slice(s) ]
>
>     PS> That is not an error message, I guess.
>
> Definitely not,
> thank you, Paul!
>
> Also, they were not produced by what Kevin showed (namely assignments)
> but rather when he *prints* the contents of his huge matrix /
> array.
>
>     PS> When the matrices are huge, R is unable to print them
>     PS> totally on the screen, but all data are present.
>
> Not at all "unable" !!
> R protects you from accidentally overflowing your "console" with
> huge amount of non-sensical output.
>
> As the warning above mentions,
> you should look at
>   ? getOption
>   ? options
> and particularly the  'max.print'  option
>
> Is  '' reached  getOption("max.print") ''
> too difficult to read?
>
> You *can* increase the 'max.print' option as much as you like,
> and that's why I said     'not at all "unable"'   above.
>
> Regards,
> Martin
>
>     PS> For instance,
>
>     >> m[(nrow(m)-10):nrow(m),]
>     PS> [,1] [,2] [,3]
>     PS> [1,]   NA   NA   NA
>     PS> [2,]   NA   NA   NA
>     PS> [3,]   NA   NA   NA
>     PS> [4,]   NA   NA   NA
>     PS> [5,]   NA   NA   NA
>     PS> [6,]   NA   NA   NA
>     PS> [7,]   NA   NA   NA
>     PS> [8,]   NA   NA   NA
>     PS> [9,]   NA   NA   NA
>     PS> [10,]   NA   NA   NA
>     PS> [11,]   NA   NA   NA
>
> or rather just
>
>    tail(m)
>
> or tail(m, 11)
> or head(m)
>
> or str(m)
>
> etc etc
>
>     PS> See
>
>     PS> ?getOption
>
> yes indeed.

Thanks, Martin, for your detailed comments. I have learned something from them.

Paul


From ptit_bleu at yahoo.fr  Mon Sep 10 15:16:31 2007
From: ptit_bleu at yahoo.fr (Ptit_Bleu)
Date: Mon, 10 Sep 2007 06:16:31 -0700 (PDT)
Subject: [R] I can't do it again on an other PC : R+RMySQL ->error loading
	dll
Message-ID: <12592576.post@talk.nabble.com>


Hello,

Some weeks ago, thanks to you, I managed to install R, to connect to a local
MySQL Database and to launch some queries with a script written with Tinn-R. 
My script is now ok and would like to test it with the "real" database.
I did the same installation of R, DBI package and RMySQL package I did on my
PC (I wrote everything I did in order to make it easy ...) but when I type
"libray(RMySQL), I got an error message (see below).

I tried to copy libmySQL.dll and RMySQL.dll in \system\ (like on my PC), in
\system32\, in \R\bin\ and to change the path. But always the same error
message ...

Has anybody any other solution I can try ?
Thanks in advance,
Ptit Bleu.   


-------------------------------------------------------------
R version 2.5.1 (2007-06-27)
Copyright (C) 2007 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R est un logiciel libre livr? sans AUCUNE GARANTIE.
Vous pouvez le redistribuer sous certaines conditions.
Tapez 'license()' ou 'licence()' pour plus de d?tails.

R est un projet collaboratif avec de nombreux contributeurs.
Tapez 'contributors()' pour plus d'information et
'citation()' pour la fa?on de le citer dans les publications.

Tapez 'demo()' pour des d?monstrations, 'help()' pour l'aide
en ligne ou 'help.start()' pour obtenir l'aide au format HTML.
Tapez 'q()' pour quitter R.

> library()
> .libPaths()
[1] "C:/R/library"
> library(DBI)
> library(RMySQL)
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
        impossible de charger la biblioth?que partag?e
'C:/R/library/RMySQL/libs/RMySQL.dll':
  LoadLibrary failure:  L'acc?s ? cet emplacement de la m?moire n'est pas
valide.


Erreur : le chargement du package / espace de noms a ?chou? pour 'RMySQL'
> 
------------------------------------
-- 
View this message in context: http://www.nabble.com/I-can%27t-do-it-again-on-an-other-PC-%3A-R%2BRMySQL--%3Eerror-loading-dll-tf4414597.html#a12592576
Sent from the R help mailing list archive at Nabble.com.


From schaefer at pointone.de  Mon Sep 10 15:22:15 2007
From: schaefer at pointone.de (=?ISO-8859-1?Q?Christian_Sch=E4fer?=)
Date: Mon, 10 Sep 2007 15:22:15 +0200
Subject: [R] corrected resampled t-test
Message-ID: <46E54507.7040401@pointone.de>

Hi,

I'm looking for an implementation of the "corrected resampled t-test" 
[1] to compare to different machine learning classifiers. Any idea, 
whether this is implemented in a R package?

Thanks in advance,
Christian

[1] Nadeau & Bengio, 2003, "Inference for the Generalization Error", 
Machine Learning


From pisicandru at hotmail.com  Mon Sep 10 15:32:16 2007
From: pisicandru at hotmail.com (Monica Pisica)
Date: Mon, 10 Sep 2007 13:32:16 +0000
Subject: [R] plot legend: combining filled boxes and lines
Message-ID: <BAY104-W30C2242BA0B28A51057ED2C3C00@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070910/cad1f827/attachment.pl 

From rhelp.stats at gmail.com  Mon Sep 10 16:00:06 2007
From: rhelp.stats at gmail.com (R Help)
Date: Mon, 10 Sep 2007 11:00:06 -0300
Subject: [R] \uxxxx in libraries
Message-ID: <c84ed6950709100700p5b9f540fs62bf32008617f9e8@mail.gmail.com>

I'm trying to build an extension that uses the \uxxxx characters, but
building the library fails.  The "Writing R Extensions" guide says
that these characters should not be used, but I really can't find any
way around them.  Is there any way to configure the building of a
library so that it will allow them to be used?  I'm currently building
and installing using the following code.

R CMD build newpkg
R CMD INSTALL GUIdemo_1.0.tar.gz

If there is absolutely no way to include the escape characters then I
may have to go a different way, but using \uxxxx seems to be the only
way to include greek symbols in tcltk menus, so I would prefer to keep
using them.

Thanks,
Sam


From sigbert at wiwi.hu-berlin.de  Mon Sep 10 16:26:33 2007
From: sigbert at wiwi.hu-berlin.de (Sigbert Klinke)
Date: Mon, 10 Sep 2007 16:26:33 +0200
Subject: [R] mode or parameters of readBin
Message-ID: <46E55419.3000306@wiwi.hu-berlin.de>

Hi,

 > sapply(formals("readBin"), mode)
      con      what         n      size    signed    endian
   "name"    "name" "numeric" "logical" "logical"    "call"

returns for the mode of size logical. But in the documentation is said 
that size should be integer. Does anyone know why the mode is logical?

Thanks in advance

Sigbert Klinke


From murdoch at stats.uwo.ca  Mon Sep 10 16:49:55 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 10 Sep 2007 10:49:55 -0400
Subject: [R] mode or parameters of readBin
In-Reply-To: <46E55419.3000306@wiwi.hu-berlin.de>
References: <46E55419.3000306@wiwi.hu-berlin.de>
Message-ID: <46E55993.9030902@stats.uwo.ca>

On 9/10/2007 10:26 AM, Sigbert Klinke wrote:
> Hi,
> 
>  > sapply(formals("readBin"), mode)
>       con      what         n      size    signed    endian
>    "name"    "name" "numeric" "logical" "logical"    "call"
> 
> returns for the mode of size logical. But in the documentation is said 
> that size should be integer. Does anyone know why the mode is logical?

The default value is NA, and the mode of NA is logical.  (It will 
automatically be promoted into another type if included in a vector, 
e.g. c(1:2, NA) promotes it to integer, c(3.14, NA) promotes it to numeric.)

More generally, I'd say reading the man page or the source is a better 
way to find out about the requirements for the arguments of a function.

Duncan Murdoch


From xavier_abulker at yahoo.fr  Mon Sep 10 16:53:56 2007
From: xavier_abulker at yahoo.fr (xavierab)
Date: Mon, 10 Sep 2007 07:53:56 -0700 (PDT)
Subject: [R] Problems with strsplit
In-Reply-To: <333079.5017.qm@web25612.mail.ukl.yahoo.com>
References: <333079.5017.qm@web25612.mail.ukl.yahoo.com>
Message-ID: <12594380.post@talk.nabble.com>


You could directly use

strsplit("bA531F16-rep","\\-")[[1]][1]
and 
strsplit("bA531F16-rep","\\-")[[1]][2]

Regards


Carlos Morales-2 wrote:
> 
> Hello,
>    
>   I would like to know what can I do if I use strplit with a string and I
> want to use the middle left,I mean I have this:
>    
>   strsplit("bA531F16-rep","\\-")
>   [[1]]
> [1] "bA531F16" "rep"    
>   I would like to work just with bA531F16 in another variable, what could
> I do?, Thank you
>    
> 
>        
> ---------------------------------
> 
> S? un Mejor Amante del Cine
> ?Quieres saber c?mo? ?Deja que otras personas te ayuden!.
> 
> 	[[alternative HTML version deleted]]
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Problems-with-strsplit-tf4412525.html#a12594380
Sent from the R help mailing list archive at Nabble.com.


From h.wickham at gmail.com  Mon Sep 10 16:58:18 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 10 Sep 2007 09:58:18 -0500
Subject: [R] ggplot legend consolidation
In-Reply-To: <9A1F9BE796CFED43AAD05E0523BB31DF05A97B3F@nex2003cdc.us.global.schwab.com>
References: <AcfxxHSTYl61CfmGQN2h9lueAf0J2g==>
	<9A1F9BE796CFED43AAD05E0523BB31DF05A97B3F@nex2003cdc.us.global.schwab.com>
Message-ID: <f8e6ff050709100758m762c231eqb25d8baa95cc577c@mail.gmail.com>

> I have recently been introduced to the ggplot package by Hadley Wickham
> and must say I am quite impressed so far at how easy it is to make
> attractive plots, but one thing I am struggling over is how to
> consolidate legends.

It's not currently possible to consolidate them (although in the
distant future that would be something nice to have), but you can turn
them off:

hide_colour <- scale_colour_continuous()
hide_colour$legend <- FALSE

p <- ggplot(data = mtcars) +
  geom_point(mapping = aes(x = hp, y = mpg, colour = cyl)) +
  hide_colour

You'll also need to twiddle your viewports a little so that you still
have space for the viewport, since space will not be allocated
automatically anymore.

The next thing is to extract the grob for the legend itself - this is
a little tricker, because there's currently no way to get at the
scales after they have been "trained" with the
data.  Load get_legends from http://pastie.textmate.org/95755, and
then you can do:

grid.newpage(); grid.draw(get_legends(p))

If you're not familiar enough with grid to stitch all of these pieces
together, please let me know, but this should be enough to get you
started.

Hadley


From kevinmeng at gmail.com  Mon Sep 10 17:08:16 2007
From: kevinmeng at gmail.com (Kevin)
Date: Mon, 10 Sep 2007 11:08:16 -0400
Subject: [R] RWinEdt installation problems with Vista
Message-ID: <7dd20c30709100808y1d040ffdt2ea14c509a7d3d5b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070910/e4c08311/attachment.pl 

From helprhelp at gmail.com  Mon Sep 10 17:12:02 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Mon, 10 Sep 2007 11:12:02 -0400
Subject: [R] machine learning on ordered (ranked) feature
Message-ID: <cdf817830709100812m8d994a6kea3e560c94a95ad5@mail.gmail.com>

Hi, there:

just a little bit off-topic:

any algorithm in classification is good for ordered features, like all
variables used are 1, 2, 3,...; not really continuous but ordered. i
tried random forest and dlda already.


thanks.

-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From singularitaet at gmx.net  Mon Sep 10 17:20:28 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Mon, 10 Sep 2007 17:20:28 +0200
Subject: [R] RWinEdt installation problems with Vista
In-Reply-To: <7dd20c30709100808y1d040ffdt2ea14c509a7d3d5b@mail.gmail.com>
References: <7dd20c30709100808y1d040ffdt2ea14c509a7d3d5b@mail.gmail.com>
Message-ID: <46E560BC.9050600@gmx.net>


> Hi,
>
> I was trying to install the package"RWinEdt" in my computer with Vista OS.
> O
Use Tinn-R it works with Vista although has some minor issues (which are
probably system specific).

https://sourceforge.net/projects/tinn-r

Stefan

-=-=-
... Time is an illusion, lunchtime doubly so. (Ford Prefect)


From tlumley at u.washington.edu  Mon Sep 10 17:41:45 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 10 Sep 2007 08:41:45 -0700 (PDT)
Subject: [R] Survey package
In-Reply-To: <99137.80849.qm@web38605.mail.mud.yahoo.com>
References: <99137.80849.qm@web38605.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.0709100839060.14130@homer24.u.washington.edu>

On Thu, 6 Sep 2007, eugen pircalabelu wrote:

> Good afternoon!
>
>  I'm trying to use the Survey package for a stratified sample which has 
> 4 criteria on which the stratification is based. I would like to get the 
> corrected weights and for every element i get a weight of 1
>
>  E.g: tipping
>
>   design <- svydesign (id=~1, strata= ~regiune + size_loc + age_rec_hhh 
> + size_hh, data= tabel)
>   and then      weights(design)
>  gives me:  1,1,1,1,1,1,1,1,1,1,1,........... for each element
>

There are two problems.  The first is that you have the wrong syntax for 
strata.  If you have one stage of sampling with multiple stratifying 
factors you need to create a single factor representing the strata. One 
way is with interaction()

design <- svydesign (id=~1, strata= ~interaction(regiune, size_loc,  age_rec_hhh, size_hh), data= tabel)

Second, you have not specified either weights or population sizes, so R 
has no way to work out the sampling weights. That's why you get weights of 
1.  You should also get a warning.

 	-thomas


From tlumley at u.washington.edu  Mon Sep 10 17:43:22 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 10 Sep 2007 08:43:22 -0700 (PDT)
Subject: [R] the survey package
In-Reply-To: <46DFF2E5.8060008@telenet.be>
References: <300041.24688.qm@web38611.mail.mud.yahoo.com>
	<46DFF2E5.8060008@telenet.be>
Message-ID: <Pine.LNX.4.64.0709100841500.14130@homer24.u.washington.edu>

On Thu, 6 Sep 2007, Tobias Verbeke wrote:

> eugen pircalabelu wrote:
>
>>   I'm trying to use the survey package to get a better point of view 
>> for my data, but i need some piece of advice:
>>
>>   i have some data from a survey which has been stratified using 2 
>> criteria: region(7 values), size of locality(5 values)  Using the 
>> survey pakage how can i define in a correct way this design (taking 
>> into account all 4 strata not just one as in the Survey example)
>>
<snip>
> According to ?svydesign, strata is a formula.
>
> The following should work (untested):
>
> design <- svydesign(ids=~0, strata=~regiune + size_loc, data=tabel)

This would be a two-stage sample, you actually need ~interaction(regiune, 
size_loc).

[this reply is just to make sure it ends up linked in the archives].

 	-thomas


From xavier_abulker at yahoo.fr  Mon Sep 10 17:53:52 2007
From: xavier_abulker at yahoo.fr (Xavier Abulker)
Date: Mon, 10 Sep 2007 08:53:52 -0700 (PDT)
Subject: [R] writing complex outputs to table
In-Reply-To: <46E340D3.709@wisc.edu>
References: <46E340D3.709@wisc.edu>
Message-ID: <12596104.post@talk.nabble.com>


Steve,
This example works:

x<-TukeyHSD(fm1, "tension", ordered = TRUE)
as.table(x$tension)


Steve Powers wrote:
> 
> So I've come across a few cases where complex outputs from functions 
> will not write to tables. The most recent case involves the TukeyHSD 
> function in the stats package. If I save the TukeyHSD call and print it, 
> that obviously goes fine, but when I try writing to a table, I get an 
> error message that says "cannot coerce class \multicomp\" into 
> dataframe. What does this mean, and how do I work around it? Is there a 
> more "fail-safe" general method of writing complex outputs to a table? 
> The story here is I want to be able to call certain values from the 
> TukeyHSD results to produce custom summaries.
> 
> Using R version 2.4 on Windows XP.---steve
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/writing-complex-outputs-to-table-tf4407732.html#a12596104
Sent from the R help mailing list archive at Nabble.com.


From tlumley at u.washington.edu  Mon Sep 10 17:54:52 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 10 Sep 2007 08:54:52 -0700 (PDT)
Subject: [R] Are the error messages of ConstrOptim() consisten with each
 other?
In-Reply-To: <548b8d440709092358g3cd079cehd459e8592bb9673c@mail.gmail.com>
References: <548b8d440709092358g3cd079cehd459e8592bb9673c@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709100853200.14130@homer24.u.washington.edu>


The error message about the feasible region comes from constrOptim(), 
before your function is called.  The error message about missing lambda1 
comes from calling your function.

 	-thomas

On Sun, 9 Sep 2007, Yuchen Luo wrote:

> Dear Friends.
> I found something very puzzling with constOptim(). When I change the
> parameters for ConstrOptim, the error messages do not seem to be
> consistent with each other:
>
>> constrOptim(c(0.5,0.3,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
> Error in constrOptim(c(0.5, 0.3, 0.5), f = fit.error, gr = fit.error.grr,  :
>        initial value not feasible
>> constrOptim(c(0.5,0.9,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
> Error in constrOptim(c(0.5, 0.9, 0.5), f = fit.error, gr = fit.error.grr,  :
>        initial value not feasible
>> constrOptim(c(0.3,0.5,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
> Error in f(theta, ...) : argument "lambda1" is missing, with no default
>
> I only changed the parameters, how come the lambda1 that is not
> missing in the first 2 cases suddently become missing?
>
> For your convenience, I put the complete code below:
>
> Best Wishes
> Yuchen Luo
>
> ########################################
> rm(list = ls())
>
> mat=5
>
> rint=c(4.33,4.22,4.27,4.43,4.43,4.44,4.45,4.65,4.77,4.77)
> tot=rep(13319.17,10)
> sh=rep(1553656,10)
> sigmae=c(0.172239074,0.188209271,0.193703774,0.172659891,0.164427247,0.24602361,0.173555309,0.186701165,0.193150456,
> 0.1857315601)
> ss=c(56.49,56.39,56.55,57.49,57.37,55.02,56.02,54.35,54.09, 54.67)
> orange=rep(21.25,10)
>
> apple2=expression(rint*(1.0-rec)*(1.0-(pnorm(-lambda/2.0+log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/lambda)-((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))*pnorm(-lambda/2.0-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/lambda))+(exp(rint*(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))*((((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/s!
 h*!
> 1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))))-(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*la!
 m!
> bda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*
> 1000.0))))))-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))))))/((pnorm(-lambda/2.0+log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/lambda)-((ss+(tot/sh*1!
 00!
> 0.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))*pnorm(-lambda/2.0-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/lambda))-(pnorm(-sqrt((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*mat+lambda*lambda)/2.0+log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/sqrt((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*mat+lambda*lambda))-((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))*pnorm(-sqrt((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*mat+lambda*lambda)/2.0-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/sqrt((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*mat+lambda*lambda)))*exp(-rint*mat)-(exp(rint*(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))*((((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(sqrt(0!
 .!
> 25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*
> (tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+!
 lb!
> ar*(tot/sh*1000.0)))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))))-(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0)/lbar*exp(lambda!
 *!
> lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(
> sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))))))))
>
> apple.ana= function(rec1,lambda1,lbar1)
> {rec=rec1
> lambda=lambda1
> lbar=lbar1
> apple=eval(apple2)
> gradient=cbind(eval(D(apple2,'rec')),eval(D(apple2,'lambda')),
> eval(D(apple2,'lbar')))
> attr(apple.ana,'gradient')=gradient
> apple
> }
>
> fit.error=function(rec1,lambda1,lbar1)
> {rec=rec1
> lambda=lambda1
> lbar=lbar1
> sum((eval(apple2)*1000-orange)^2/(orange^2))
> }
>
> fit.error.grr=function(rec1,lambda1,lbar1)
> {rec=rec1
> lambda=lambda1
> lbar=lbar1
>
> drec=sum(20000*eval(D(apple2,'rec'))*(eval(apple2)*10000-orange)/(orange^2))
> dlambda=sum(20000*eval(D(apple2,'lambda'))*(eval(apple2)*10000-orange)/(orange^2))
> dlbar=sum(20000*eval(D(apple2,'lbar'))*(eval(apple2)*10000-orange)/(orange^2))
>
> c(drec,dlambda,dlbar)
> }
>
> ui=matrix(c(1,-1,0,0,0,0,0,0,1,-1,0,0,0,0,0,0,1,-1),6,3)
> ci=c(0,-0.5,0,-2,0,-0.6)
>
> constrOptim(c(0.5,0.3,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
> constrOptim(c(0.5,0.9,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
> constrOptim(c(0.3,0.5,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
>
> ###########################################################
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From tlumley at u.washington.edu  Mon Sep 10 18:02:31 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 10 Sep 2007 09:02:31 -0700 (PDT)
Subject: [R] Survey package
In-Reply-To: <847670.81160.qm@web38610.mail.mud.yahoo.com>
References: <847670.81160.qm@web38610.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.0709100858010.14130@homer24.u.washington.edu>

On Sun, 9 Sep 2007, eugen pircalabelu wrote:
> A short example:
>
> stratum id weight nh Nh  y sex
>     1      1      3     5 15 23   1
>     1      2      3     5 15 25   1
>     1      3      3     5 15 27   2
>     1      4      3     5 15 21   2
>     1      5      3     5 15 22   1
>     2      6      4     3 12 33   1
>     2      7      4     3 12 27   1
>     2      8      4     3 12 29   2
>
> where nh is size of sample stratum and Nh the corresponding  population value, and  y is  metric variable.
>
> Now if i let
>
> design <- svydesign( id=~1, data=age, strata=~stratum, fpc=~Nh)
> then weights(design)  gives me 3,3,3,3,3,4,4,4.
>
> If i then let
>
> x<- postStratify( design, strata=~sex, data.frame(sex=c("1","2"), freq=c(10,15)))
> the weights become
>
> 1                    2            3            4            5            6            7            8
> 2.17               2.17       5.35       5.35        2.17    1.73        1.73        4.28
>
> If i define
>
> design <- svydesign( id=~1, data=age )
> x<- postStratify( design, strata=~sex, data.frame(sex=c("1","2"), freq=c(10,15)))
> weights become  2 2 5 5 2 2 2 5
>
> The question: does poststratify recognize that i have already stratified 
> in the first design by stratum and then it post stratifies by sex? and 
> why is that? (because i don't have the full joint distribution, the 
> sex*stratum crossing, in order to apply correctly the post stratify 
> function) I see that Mr Lumley uses the postStratify function when the 
> design does not include strata (eg from ?poststratify:
>

This gives you a design stratified by stratum and post-stratified by sex, 
which is not the same as stratifying by stratum*sex or post-stratifying by 
stratum*sex.

In this case you should probably rake() on stratum and sex rather than 
just post-stratifying. Post-stratifying on sex is equivalent to one iteration 
of the iterative proportional fitting algorithm used in raking.

 	-thomas


From xavier_abulker at yahoo.fr  Mon Sep 10 18:10:34 2007
From: xavier_abulker at yahoo.fr (Xavier Abulker)
Date: Mon, 10 Sep 2007 09:10:34 -0700 (PDT)
Subject: [R] write.csv / string extraction and field limits
In-Reply-To: <12534347.post@talk.nabble.com>
References: <12534347.post@talk.nabble.com>
Message-ID: <12596551.post@talk.nabble.com>


This example works fine:

test<-matrix(c(1,2,'VOICIUNPETITTESTTTTTTTTTTTTTTTTTTTT',3),ncol=2,nrow=2)
write.csv(test,file='C:/xavier/test.csv')


Could you provide the same small example when it doesn't work?



kwaj wrote:
> 
> Hello, 
> 
> I have a peculiar problem which I am hoping I can get help on. 
> 
> I am using the write.csv command to write a matrix structure to a file,
> which I later read in excel. The command works quite well for most strings
> and numerical values in the matrix structure. 
> 
> However, I have found that when a field in the matrix contains a string of
> long length, when the matrix is finally written the file - the field shows
> up as "NA". I am assuming write.csv has a limit on the field size? Maybe
> 16 characters?
> 
> Assuming the above is correct - I tried to extract a portion of the string
> using the 'substring' command and enter the extracted portion into the
> field before using the write.csv command. However I find, that when a
> string is extracted, the output from write.csv generates a NA in the file
> output. 
> 
> My questions are:
> 
> 1) Does write.csv have a limit on the size of strings in the matrix
> fields? Is there anyway to place large strings in the field?
> 
> 2) Is there anyway to make the substring command or an alternative but
> similar command, compatible with write.csv? I have tried
> 'as.character(substring(phrase, min, max)' and that does not seem to work
> 
> cheers
> 
> 
> 

-- 
View this message in context: http://www.nabble.com/write.csv---string-extraction-and-field-limits-tf4395535.html#a12596551
Sent from the R help mailing list archive at Nabble.com.


From tlumley at u.washington.edu  Mon Sep 10 18:10:48 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 10 Sep 2007 09:10:48 -0700 (PDT)
Subject: [R] mode or parameters of readBin
In-Reply-To: <46E55419.3000306@wiwi.hu-berlin.de>
References: <46E55419.3000306@wiwi.hu-berlin.de>
Message-ID: <Pine.LNX.4.64.0709100910280.14130@homer24.u.washington.edu>

On Mon, 10 Sep 2007, Sigbert Klinke wrote:

> Hi,
>
> > sapply(formals("readBin"), mode)
>      con      what         n      size    signed    endian
>   "name"    "name" "numeric" "logical" "logical"    "call"
>
> returns for the mode of size logical. But in the documentation is said
> that size should be integer. Does anyone know why the mode is logical?
>

Because NA is a logical constant.

 	-thomas


From liuwensui at gmail.com  Mon Sep 10 18:22:11 2007
From: liuwensui at gmail.com (Wensui Liu)
Date: Mon, 10 Sep 2007 12:22:11 -0400
Subject: [R] off-topic: better OS for statistical computing
Message-ID: <1115a2b00709100922h7780644brc59e3f9c25760caf@mail.gmail.com>

Good morning, everyone,
I am sorry for this off-topic post but think I can get great answer
from this list.
My question is what is the best OS on PC (laptop) for statistical
computing and why.
I really appreciate your insight.
Have a nice day.


From ggrothendieck at gmail.com  Mon Sep 10 18:26:58 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 10 Sep 2007 12:26:58 -0400
Subject: [R] off-topic: better OS for statistical computing
In-Reply-To: <1115a2b00709100922h7780644brc59e3f9c25760caf@mail.gmail.com>
References: <1115a2b00709100922h7780644brc59e3f9c25760caf@mail.gmail.com>
Message-ID: <971536df0709100926r4ac598ffj5b892472531d18ad@mail.gmail.com>

You want whatever all the people you are working with are using
to make it as easy as possible to work together with them.

On 9/10/07, Wensui Liu <liuwensui at gmail.com> wrote:
> Good morning, everyone,
> I am sorry for this off-topic post but think I can get great answer
> from this list.
> My question is what is the best OS on PC (laptop) for statistical
> computing and why.
> I really appreciate your insight.
> Have a nice day.


From Kaom.Te at schwab.com  Mon Sep 10 18:46:24 2007
From: Kaom.Te at schwab.com (Te, Kaom)
Date: Mon, 10 Sep 2007 09:46:24 -0700
Subject: [R] ggplot legend consolidation
In-Reply-To: <f8e6ff050709100758m762c231eqb25d8baa95cc577c@mail.gmail.com>
References: <AcfxxHSTYl61CfmGQN2h9lueAf0J2g==>
	<9A1F9BE796CFED43AAD05E0523BB31DF05A97B3F@nex2003cdc.us.global.schwab.com>
	<f8e6ff050709100758m762c231eqb25d8baa95cc577c@mail.gmail.com>
Message-ID: <9A1F9BE796CFED43AAD05E0523BB31DF05ACF4C3@nex2003cdc.us.global.schwab.com>

Hi Hadley,

I just tried out your suggestion, but it does not look like the
get_legends function is working correctly. Instead of returning a grob
back to me it returns NULL.

Here is my modified code and the results of running it.

Any help would be appreciated. I believe that once I can get the legend
in grob form then I can figure out how to deconstruct it myself. 

Thanks,
Kaom

> p.legend <- get_legends(p)
> grid.draw(p.legend)
Error in grid.draw(p.legend) : no applicable method for "grid.draw"
> p.legend
NULL
>

-------------------------------------------- BEGIN CODE
## Obtained from http://pastie.textmate.org/95755
get_legends <- function(plot) {
  if (length(plot$layers) == 0) stop("No layers to plot", call.=FALSE)
  
  # Apply function to layer and matching data
  dlapply <- function(f) mapply(f, data, layers, SIMPLIFY=FALSE)

  plot <- plot_clone(plot)
  layers <- plot$layers
  scales <- plot$scales
  facet <- plot$facet

  cs <- plot$coordinates

  # Evaluate aesthetics
  data <- lapply(layers, function(x) x$make_aesthetics(plot))
  
  # Facet
  data <- mapply(function(d, p) facet$stamp_data(d), data, layers,
SIMPLIFY=FALSE)
  # Transform scales where possible.  Also need to train so statisics
  # (e.g. stat_smooth) have access to info
  data <- dlapply(function(d, p) p$scales_transform(d, scales))
  dlapply(function(d, p) p$scales_train(d, scales))

  # Apply statistics
  data <- dlapply(function(d, p) p$calc_statistics(d, scales))
  data <- dlapply(function(d, p) p$map_statistics(d, plot))

  # Adjust position before scaling
  data <- dlapply(function(d, p) p$adjust_position(d, scales, "before"))
  # Transform, train and map scales
  # data <- dlapply(function(d, p) p$scales_transform(d, scales))
  dlapply(function(d, p) p$scales_train(d, scales, adjust=TRUE))
  data <- dlapply(function(d, p) p$scales_map(d, scales))

  # Adjust position after scaling
  data <- dlapply(function(d, p) p$adjust_position(d, scales, "after"))
  scales <- scales$minus(plot$scales$get_scales(c("x", "y", "z")))

  legends(scales, FALSE)
}


library(ggplot2)
data(mtcars)
 
grid.newpage()

hide_colour <- scale_colour_continuous()
hide_colour$legend <- FALSE

pushViewport(viewport(layout = grid.layout(2, 2)))
 
p <- ggplot(data = mtcars) +
  geom_point(mapping = aes(x = hp, y = mpg, colour = cyl)) +
  hide_colour

pushViewport(viewport(layout.pos.col = 1,
                      layout.pos.row = 1))
 
print(p, vp = current.viewport())
upViewport()
 
p <- ggplot(data = mtcars) +
  geom_point(mapping = aes(x = drat, y = disp, colour = cyl)) +
  hide_colour
 

pushViewport(viewport(layout.pos.col = 2,
                      layout.pos.row = 1))
 
print(p, vp = current.viewport())
upViewport()
 
p <- ggplot(data = mtcars) +
  geom_point(mapping = aes(x = qsec, y = mpg, colour = cyl)) +
  hide_colour
 
pushViewport(viewport(layout.pos.col = 1,
                      layout.pos.row = 2))
 
print(p, vp = current.viewport())
upViewport()

pushViewport(viewport(layout.pos.col = 2,
                      layout.pos.row = 2))
grid.rect()

p.legend <- get_legends(p)
grid.draw(p.legend) 
----------------------------------------------END CODE



-----Original Message-----
From: hadley wickham [mailto:h.wickham at gmail.com] 
Sent: Monday, September 10, 2007 7:58 AM
To: Te, Kaom
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] ggplot legend consolidation

> I have recently been introduced to the ggplot package by Hadley 
> Wickham and must say I am quite impressed so far at how easy it is to 
> make attractive plots, but one thing I am struggling over is how to 
> consolidate legends.

It's not currently possible to consolidate them (although in the distant
future that would be something nice to have), but you can turn them off:

hide_colour <- scale_colour_continuous() hide_colour$legend <- FALSE

p <- ggplot(data = mtcars) +
  geom_point(mapping = aes(x = hp, y = mpg, colour = cyl)) +
  hide_colour

You'll also need to twiddle your viewports a little so that you still
have space for the viewport, since space will not be allocated
automatically anymore.

The next thing is to extract the grob for the legend itself - this is a
little tricker, because there's currently no way to get at the scales
after they have been "trained" with the data.  Load get_legends from
http://pastie.textmate.org/95755, and then you can do:

grid.newpage(); grid.draw(get_legends(p))

If you're not familiar enough with grid to stitch all of these pieces
together, please let me know, but this should be enough to get you
started.

Hadley


From DavidLloyd at mail2lloyd.com  Mon Sep 10 19:02:59 2007
From: DavidLloyd at mail2lloyd.com (David Lloyd)
Date: Mon, 10 Sep 2007 10:02:59 -0700
Subject: [R] Loop and loop output [Cox model, for, function, loglik]
Message-ID: <98bc01c7f3cc$70da6f70$016a010a@mail2world.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070910/96932535/attachment.pl 

From ral at lcfltd.com  Mon Sep 10 19:36:15 2007
From: ral at lcfltd.com (Robert A. LaBudde)
Date: Mon, 10 Sep 2007 13:36:15 -0400
Subject: [R] S-Plus "resample" package and associated functions
Message-ID: <0JO500AHLY8E0PLC@vms048.mailsrvcs.net>

Are there any packages in R that reproduce the package "resample" of S-Plus?

The sample() function in R doesn't provide equivalent flexibility of 
bootstrap() and bootstrap2().
================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From maura.monville at gmail.com  Mon Sep 10 20:08:27 2007
From: maura.monville at gmail.com (Maura E Monville)
Date: Mon, 10 Sep 2007 13:08:27 -0500
Subject: [R] is clustering analysis possible with R ?
Message-ID: <36d691950709101108u135ded00p641ed49a8fd964ee@mail.gmail.com>

I have 316 files storing a number of cycles of the respiratory signal
from 316 different patients. Each file record  is made up of the
following data:

 amplitude,phase,timestamp,validflag,ttlin,mark,ttlout

amplitude:  is the position in cm relative to an arbitrary reference
(signal amplitude)

phase:  is the phase value for the current sample (the time point at
which the breathing signal was recorded)

timestamp:  time of the sample measurement in milliseconds

validflag:  value of 0 indicates a valid track and a periodic signal,
and a value less than 0 indicates either a lost track,
              a bad video signal, or a non periodic signal

ttlin: is the bit value indicating the status of a sensed TTL signal.
Possible values include 1 (+5 VDC) and  0 (0 VDC).

mark:  specifies the sample when the phase value is closest to 0 or PI
(180 degrees) . Possible values include Z (0 phase), P (PI phase),
          "" (null string), and - (neither 0 nor PI phase)

ttl_out: is the bit value indicating the status of an output TTL
signal. Possible values include 1 (+5 VDC) and 0 (0 VDC)

The goal is to perform clustering analysis on such data, that is to
group togther those which have common characteristics. Which
characteristics and how many groups ... ??? ... well this is to be
found out.
Is R a good tool for analysing many data and find patterns common to
data subsets ?
Which other tool do you advice ?
Thank you very much,
-- 
Maura E.M


From dxc13 at health.state.ny.us  Mon Sep 10 20:20:29 2007
From: dxc13 at health.state.ny.us (dxc13)
Date: Mon, 10 Sep 2007 11:20:29 -0700 (PDT)
Subject: [R] finding the minimum positive value of some data
Message-ID: <12599319.post@talk.nabble.com>


useRs,

I am looking to find the minimum positive value of some data I have. 
Currently, I am able to find the minimum of data after I apply some other
functions to it:

> x
 [1]  1  0  1  2  3  3  4  5  5  5  6  7  8  8  9  9 10 10

> sort(x)
 [1]  0  1  1  2  3  3  4  5  5  5  6  7  8  8  9  9 10 10

> diff(sort(x))
 [1] 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 1 0

> min(diff(sort(x)))
[1] 0

The minimum is given as zero, which is clearly true, but I am interested in
only the positive minimum, which is 1.  Can I find this by using only 1 line
of code, like I have above? Thanks!

dxc13
-- 
View this message in context: http://www.nabble.com/finding-the-minimum-positive-value-of-some-data-tf4417250.html#a12599319
Sent from the R help mailing list archive at Nabble.com.


From wwwhsd at gmail.com  Mon Sep 10 20:26:25 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Mon, 10 Sep 2007 15:26:25 -0300
Subject: [R] finding the minimum positive value of some data
In-Reply-To: <12599319.post@talk.nabble.com>
References: <12599319.post@talk.nabble.com>
Message-ID: <da79af330709101126g3021508fyaaf262087c84feac@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070910/6a7801ea/attachment.pl 

From marc_schwartz at comcast.net  Mon Sep 10 20:31:21 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Mon, 10 Sep 2007 13:31:21 -0500
Subject: [R] finding the minimum positive value of some data
In-Reply-To: <12599319.post@talk.nabble.com>
References: <12599319.post@talk.nabble.com>
Message-ID: <1189449081.3621.35.camel@Bellerophon.localdomain>

On Mon, 2007-09-10 at 11:20 -0700, dxc13 wrote:
> useRs,
> 
> I am looking to find the minimum positive value of some data I have. 
> Currently, I am able to find the minimum of data after I apply some other
> functions to it:
> 
> > x
>  [1]  1  0  1  2  3  3  4  5  5  5  6  7  8  8  9  9 10 10
> 
> > sort(x)
>  [1]  0  1  1  2  3  3  4  5  5  5  6  7  8  8  9  9 10 10
> 
> > diff(sort(x))
>  [1] 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 1 0
> 
> > min(diff(sort(x)))
> [1] 0
> 
> The minimum is given as zero, which is clearly true, but I am interested in
> only the positive minimum, which is 1.  Can I find this by using only 1 line
> of code, like I have above? Thanks!
> 
> dxc13

It's not clear to me which vector you wish to get the minimum for, but
the basic premise would be along the lines of:

> x
 [1]  1  0  1  2  3  3  4  5  5  5  6  7  8  8  9  9 10 10


> min(x[which(x > 0)])
[1] 1

or

> min(which(diff(sort(x)) > 0))
[1] 1

See ?which

HTH,

Marc Schwartz


From alenzo at mail.rochester.edu  Mon Sep 10 20:52:16 2007
From: alenzo at mail.rochester.edu (A Lenzo)
Date: Mon, 10 Sep 2007 14:52:16 -0400
Subject: [R] Too many warnings when updating R
Message-ID: <00e101c7f3db$b8d5b870$f6339780@libra.cc.rochester.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070910/0429cc4a/attachment.pl 

From h.wickham at gmail.com  Mon Sep 10 20:55:32 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 10 Sep 2007 13:55:32 -0500
Subject: [R] ggplot legend consolidation
In-Reply-To: <9A1F9BE796CFED43AAD05E0523BB31DF05ACF4C3@nex2003cdc.us.global.schwab.com>
References: <9A1F9BE796CFED43AAD05E0523BB31DF05A97B3F@nex2003cdc.us.global.schwab.com>
	<f8e6ff050709100758m762c231eqb25d8baa95cc577c@mail.gmail.com>
	<9A1F9BE796CFED43AAD05E0523BB31DF05ACF4C3@nex2003cdc.us.global.schwab.com>
Message-ID: <f8e6ff050709101155w3a628fb5k7c3dc37113573a76@mail.gmail.com>

Sorry, I should have mentioned that get_legend won't work on the plots
that you are actually plotting - you have turned their legends off!
You'll need a plot which isn't plotted, but is used to produce the
legends.

Hadley

On 9/10/07, Te, Kaom <Kaom.Te at schwab.com> wrote:
> Hi Hadley,
>
> I just tried out your suggestion, but it does not look like the
> get_legends function is working correctly. Instead of returning a grob
> back to me it returns NULL.
>
> Here is my modified code and the results of running it.
>
> Any help would be appreciated. I believe that once I can get the legend
> in grob form then I can figure out how to deconstruct it myself.
>
> Thanks,
> Kaom
>
> > p.legend <- get_legends(p)
> > grid.draw(p.legend)
> Error in grid.draw(p.legend) : no applicable method for "grid.draw"
> > p.legend
> NULL
> >
>
> -------------------------------------------- BEGIN CODE
> ## Obtained from http://pastie.textmate.org/95755
> get_legends <- function(plot) {
>   if (length(plot$layers) == 0) stop("No layers to plot", call.=FALSE)
>
>   # Apply function to layer and matching data
>   dlapply <- function(f) mapply(f, data, layers, SIMPLIFY=FALSE)
>
>   plot <- plot_clone(plot)
>   layers <- plot$layers
>   scales <- plot$scales
>   facet <- plot$facet
>
>   cs <- plot$coordinates
>
>   # Evaluate aesthetics
>   data <- lapply(layers, function(x) x$make_aesthetics(plot))
>
>   # Facet
>   data <- mapply(function(d, p) facet$stamp_data(d), data, layers,
> SIMPLIFY=FALSE)
>   # Transform scales where possible.  Also need to train so statisics
>   # (e.g. stat_smooth) have access to info
>   data <- dlapply(function(d, p) p$scales_transform(d, scales))
>   dlapply(function(d, p) p$scales_train(d, scales))
>
>   # Apply statistics
>   data <- dlapply(function(d, p) p$calc_statistics(d, scales))
>   data <- dlapply(function(d, p) p$map_statistics(d, plot))
>
>   # Adjust position before scaling
>   data <- dlapply(function(d, p) p$adjust_position(d, scales, "before"))
>   # Transform, train and map scales
>   # data <- dlapply(function(d, p) p$scales_transform(d, scales))
>   dlapply(function(d, p) p$scales_train(d, scales, adjust=TRUE))
>   data <- dlapply(function(d, p) p$scales_map(d, scales))
>
>   # Adjust position after scaling
>   data <- dlapply(function(d, p) p$adjust_position(d, scales, "after"))
>   scales <- scales$minus(plot$scales$get_scales(c("x", "y", "z")))
>
>   legends(scales, FALSE)
>
> }
>
>
> library(ggplot2)
> data(mtcars)
>
> grid.newpage()
>
> hide_colour <- scale_colour_continuous()
> hide_colour$legend <- FALSE
>
> pushViewport(viewport(layout = grid.layout(2, 2)))
>
> p <- ggplot(data = mtcars) +
>   geom_point(mapping = aes(x = hp, y = mpg, colour = cyl)) +
>   hide_colour
>
> pushViewport(viewport(layout.pos.col = 1,
>                       layout.pos.row = 1))
>
> print(p, vp = current.viewport())
> upViewport()
>
> p <- ggplot(data = mtcars) +
>   geom_point(mapping = aes(x = drat, y = disp, colour = cyl)) +
>   hide_colour
>
>
> pushViewport(viewport(layout.pos.col = 2,
>                       layout.pos.row = 1))
>
> print(p, vp = current.viewport())
> upViewport()
>
> p <- ggplot(data = mtcars) +
>   geom_point(mapping = aes(x = qsec, y = mpg, colour = cyl)) +
>   hide_colour
>
> pushViewport(viewport(layout.pos.col = 1,
>                       layout.pos.row = 2))
>
> print(p, vp = current.viewport())
> upViewport()
>
> pushViewport(viewport(layout.pos.col = 2,
>                       layout.pos.row = 2))
> grid.rect()
>
> p.legend <- get_legends(p)
> grid.draw(p.legend)
> ----------------------------------------------END CODE
>
>
>
>
> -----Original Message-----
> From: hadley wickham [mailto:h.wickham at gmail.com]
> Sent: Monday, September 10, 2007 7:58 AM
> To: Te, Kaom
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] ggplot legend consolidation
>
> > I have recently been introduced to the ggplot package by Hadley
> > Wickham and must say I am quite impressed so far at how easy it is to
> > make attractive plots, but one thing I am struggling over is how to
> > consolidate legends.
>
> It's not currently possible to consolidate them (although in the distant
> future that would be something nice to have), but you can turn them off:
>
> hide_colour <- scale_colour_continuous() hide_colour$legend <- FALSE
>
> p <- ggplot(data = mtcars) +
>   geom_point(mapping = aes(x = hp, y = mpg, colour = cyl)) +
>   hide_colour
>
> You'll also need to twiddle your viewports a little so that you still
> have space for the viewport, since space will not be allocated
> automatically anymore.
>
> The next thing is to extract the grob for the legend itself - this is a
> little tricker, because there's currently no way to get at the scales
> after they have been "trained" with the data.  Load get_legends from
> http://pastie.textmate.org/95755, and then you can do:
>
> grid.newpage(); grid.draw(get_legends(p))
>
> If you're not familiar enough with grid to stitch all of these pieces
> together, please let me know, but this should be enough to get you
> started.
>
> Hadley
>


-- 
http://had.co.nz/


From pburns at pburns.seanet.com  Mon Sep 10 21:07:47 2007
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Mon, 10 Sep 2007 20:07:47 +0100
Subject: [R] S-Plus "resample" package and associated functions
In-Reply-To: <0JO500AHLY8E0PLC@vms048.mailsrvcs.net>
References: <0JO500AHLY8E0PLC@vms048.mailsrvcs.net>
Message-ID: <46E59603.4030905@pburns.seanet.com>

http://www.burns-stat.com/pages/Tutor/bootstrap_resampling.html

includes a synopsis of R packages that do bootstrapping.
It is brief and incomplete, but hopefully useful.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Robert A. LaBudde wrote:

>Are there any packages in R that reproduce the package "resample" of S-Plus?
>
>The sample() function in R doesn't provide equivalent flexibility of 
>bootstrap() and bootstrap2().
>================================================================
>Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
>Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
>824 Timberlake Drive                     Tel: 757-467-0954
>Virginia Beach, VA 23464-3239            Fax: 757-467-2947
>
>"Vere scire est per causas scire"
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>
>  
>


From economics.guy at gmail.com  Mon Sep 10 21:48:31 2007
From: economics.guy at gmail.com (Economics Guy)
Date: Mon, 10 Sep 2007 15:48:31 -0400
Subject: [R] persp() problem
Message-ID: <da0aac0709101248p4b42f006lf757877f34a68507@mail.gmail.com>

I am having some trouble getting the persp() package to change the x
and y axis on a 3d plot. It defaults to the [0,1] interval and when I
try to change it I get errors.

Example:

This works:
------------
D <- c(1,2,3,4,5,6,7,8,9,10)
M <- c(11,12,13,14,15,16,17,18,19,20)

DM <- cbind(D,M)

persp(DM, theta = 40, phi = 30, expand = 0.5, col = "lightblue",
      ltheta = 120, shade = 0.75, ticktype = "detailed",
      xlab = "X", ylab = "Y", zlab = "Z")
---------------------


But I want the axis to count 1 by ones. So I try:
-----------------
D <- c(1,2,3,4,5,6,7,8,9,10)
M <- c(11,12,13,14,15,16,17,18,19,20)

DM <- cbind(D,M)

x <- 1*0:10
y <- 1*0:20
persp(x,y,DM, theta = 40, phi = 30, expand = 0.5, col = "lightblue",
      ltheta = 120, shade = 0.75, ticktype = "detailed",
      xlab = "X", ylab = "Y", zlab = "Z")
-------------------------

I get:

Error in persp(x, y, z, xlim, ylim, zlim, theta, phi, r, d, scale,
expand,  : invalid 'z' argument

but the z was fine in the first version so I am not sure what the deal is.

Any ideas?

-Econ Guy


From p.dalgaard at biostat.ku.dk  Mon Sep 10 21:54:12 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 10 Sep 2007 21:54:12 +0200
Subject: [R] Too many warnings when updating R
In-Reply-To: <00e101c7f3db$b8d5b870$f6339780@libra.cc.rochester.edu>
References: <00e101c7f3db$b8d5b870$f6339780@libra.cc.rochester.edu>
Message-ID: <46E5A0E4.7040406@biostat.ku.dk>

A Lenzo wrote:
> Hello friends,
>
> I loaded R 2.4.1 onto a Fedora Core 6 Linux box (taking all defaults).  Then
> I ran these commands from within R:
>
> options(CRAN="http://cran.stat.ucla.edu")
> install.packages(CRAN.packages()[,1])
>
> As a new user of R, I was shocked when I finished loading R and discovered
> the following message:
>
> "There were 50 or more warnings (use warnings() to see the first 50)"
>
>   
Let me get this straight: You install last year's R on last year's 
Fedora, then install over 1000 unspecified packages and you are shocked 
that you get warnings?

> In addition to this, I saw errors such as this one:
>
> "ERROR: lazy loading failed for package 'PerformanceAnalytics'
>
> What is this lazy loading?  More importantly, do I have to worry about all
> these warnings?  I am intimidated by the idea that I have to go back and fix
> each and every one in order to have a clean R update.  Shouldn't the update
> with CRAN "just work?"  Or is there something really important that I am
> missing?
>   
Well, you need to know what you're doing. At the very least, notice what 
the warnings say and decide whether they point to real trouble or are 
just what they say they are: warnings. If you are worried about  
investigating all the packages, maybe install what you really need first.

And no, you can't expect a repository like CRAN to keep track of all 
versions of R on all versions of all OS's. In each individual case, a 
human maintainer is responsible for fixing problems and he/she may or 
may not be around to fix issues.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From deepayan.sarkar at gmail.com  Mon Sep 10 21:58:31 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Mon, 10 Sep 2007 12:58:31 -0700
Subject: [R] lattice panel.lmline problem
In-Reply-To: <E4178EE0463C7D40AF637C4DDAC8030E23DE63@UQEXMB2.soe.uq.edu.au>
References: <C83C5E3DEEE97E498B74729A33F6EAEC0574AEE3@DJFPOST01.djf.agrsci.dk>
	<E4178EE0463C7D40AF637C4DDAC8030E23DE63@UQEXMB2.soe.uq.edu.au>
Message-ID: <eb555e660709101258l3abf0647rc93cb958081f1362@mail.gmail.com>

On 9/10/07, Ross Darnell <r.darnell at uq.edu.au> wrote:
> Thanks Frede
>
> I didn't know about the "r" type.

For the record, this is probably what you wanted:

xyplot(<...>
       panel = panel.superpose,
       panel.groups = function(x, y, ...) {
           panel.xyplot(x, y, ...)
           if (length(x) > 0) panel.lmline(x, y, ...)
       })

x[subscripts] inside the panel function doesn't give anything
meaningful ('x' is already subscripted).

-Deepayan


>
> Ross Darnell
>
>
> -----Original Message-----
> From: Frede Aakmann T?gersen [mailto:FredeA.Togersen at agrsci.dk]
> Sent: Mon 10-Sep-07 4:45 PM
> To: Ross Darnell; r-help at stat.math.ethz.ch
> Subject: SV: [R] lattice panel.lmline problem
>
> Why not use the more simple
>
> xyplot(total.fat~x|variable,groups=Group,
>        data=tmp1,type=c("p","r"))
>
> ???
>
> See ?panel.xyplot and especially the type argument of that panel function.

[...]


From red_tez at yahoo.co.uk  Mon Sep 10 22:01:18 2007
From: red_tez at yahoo.co.uk (Terence Broderick)
Date: Mon, 10 Sep 2007 21:01:18 +0100 (BST)
Subject: [R] MLE Function
Message-ID: <556837.12391.qm@web27212.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070910/c88c3927/attachment.pl 

From p_connolly at ihug.co.nz  Mon Sep 10 22:06:58 2007
From: p_connolly at ihug.co.nz (Patrick Connolly)
Date: Tue, 11 Sep 2007 08:06:58 +1200
Subject: [R] off-topic: better OS for statistical computing
In-Reply-To: <971536df0709100926r4ac598ffj5b892472531d18ad@mail.gmail.com>
References: <1115a2b00709100922h7780644brc59e3f9c25760caf@mail.gmail.com>
	<971536df0709100926r4ac598ffj5b892472531d18ad@mail.gmail.com>
Message-ID: <20070910200658.GA7176@ihug.co.nz>

On Mon, 10-Sep-2007 at 12:26PM -0400, Gabor Grothendieck wrote:

|> You want whatever all the people you are working with are using
|> to make it as easy as possible to work together with them.

Assuming you're using R, there is negligible difficulty using a
different OS from what your colleagues use (apart from the
inconsistencies you get between different versions of Windows, but
even that has little effect on R).  The standard .RData binary files
work with Windows and Linux (and probably OS X).

The only issue I come across is that Linux can't create WMF files as
readily as Windows can, and that is more than made up for by the
greater flexibility that Linux offers.  It's easier in Linux to
produce Excel files from dataframes and matrices using a perl script
posted to this list by Marc Schwartz.  Thanks again Marc.

Best

Patrick


|> 
|> On 9/10/07, Wensui Liu <liuwensui at gmail.com> wrote:
|> > Good morning, everyone,
|> > I am sorry for this off-topic post but think I can get great answer
|> > from this list.
|> > My question is what is the best OS on PC (laptop) for statistical
|> > computing and why.
|> > I really appreciate your insight.
|> > Have a nice day.
|> 
|> ______________________________________________
|> R-help at stat.math.ethz.ch mailing list
|> https://stat.ethz.ch/mailman/listinfo/r-help
|> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> and provide commented, minimal, self-contained, reproducible code.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}          		 Great minds discuss ideas    
 _( Y )_  	  	        Middle minds discuss events 
(:_~*~_:) 	       		 Small minds discuss people  
 (_)-(_)  	                           ..... Anon
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From r.turner at auckland.ac.nz  Mon Sep 10 22:07:41 2007
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 11 Sep 2007 08:07:41 +1200
Subject: [R] off-topic: better OS for statistical computing
In-Reply-To: <1115a2b00709100922h7780644brc59e3f9c25760caf@mail.gmail.com>
References: <1115a2b00709100922h7780644brc59e3f9c25760caf@mail.gmail.com>
Message-ID: <610FF0BF-E28B-439E-B472-C9CEAB07F361@auckland.ac.nz>


On 11/09/2007, at 4:22 AM, Wensui Liu wrote:

> Good morning, everyone,
> I am sorry for this off-topic post but think I can get great answer
> from this list.
> My question is what is the best OS on PC (laptop) for statistical
> computing and why.
> I really appreciate your insight.
> Have a nice day.


Linux.  It's best for ***everything***.

		cheers,

				Rolf Turner

######################################################################
Attention:\ This e-mail message is privileged and confidenti...{{dropped}}


From wl2776 at gmail.com  Mon Sep 10 22:45:00 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Mon, 10 Sep 2007 13:45:00 -0700 (PDT)
Subject: [R] clustering analysis is certainly possible with R.
In-Reply-To: <36d691950709101108u135ded00p641ed49a8fd964ee@mail.gmail.com>
References: <36d691950709101108u135ded00p641ed49a8fd964ee@mail.gmail.com>
Message-ID: <12602423.post@talk.nabble.com>


See the article "Cluster" in R Task Views
 http://cran.at.r-project.org/src/contrib/Views/Cluster.html
It lists names of packages for clustering analysis, which you can install.

Or, go to choose another CRAN mirror closest to you from the R web site,
then click on 'Task views' in the left frame.

To install packages use the install.packages() function or the menu item in
the GUI in you are on Windows.


Maura E Monville wrote:
> 
> I have 316 files storing a number of cycles of the respiratory signal
> from 316 different patients. Each file record  is made up of the
> following data:
> 
> [skipped data description]
> 
> The goal is to perform clustering analysis on such data, that is to
> group togther those which have common characteristics. Which
> characteristics and how many groups ... ??? ... well this is to be
> found out.
> Is R a good tool for analysing many data and find patterns common to
> data subsets ?
> Which other tool do you advice ?
> Thank you very much,
> 
> -- 
> Maura E.M
> 
> 

-- 
View this message in context: http://www.nabble.com/is-clustering-analysis-possible-with-R---tf4417188.html#a12602423
Sent from the R help mailing list archive at Nabble.com.


From helprhelp at gmail.com  Mon Sep 10 23:16:06 2007
From: helprhelp at gmail.com (Weiwei Shi)
Date: Mon, 10 Sep 2007 17:16:06 -0400
Subject: [R] off-topic: better OS for statistical computing
In-Reply-To: <1115a2b00709100922h7780644brc59e3f9c25760caf@mail.gmail.com>
References: <1115a2b00709100922h7780644brc59e3f9c25760caf@mail.gmail.com>
Message-ID: <cdf817830709101416r7137782aidc52e615ff238788@mail.gmail.com>

Linux!  Mac OS is ok to me2.

On 9/10/07, Wensui Liu <liuwensui at gmail.com> wrote:
> Good morning, everyone,
> I am sorry for this off-topic post but think I can get great answer
> from this list.
> My question is what is the best OS on PC (laptop) for statistical
> computing and why.
> I really appreciate your insight.
> Have a nice day.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Weiwei Shi, Ph.D
Research Scientist
GeneGO, Inc.

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III


From realityrandom at gmail.com  Mon Sep 10 23:21:48 2007
From: realityrandom at gmail.com (Yuchen Luo)
Date: Mon, 10 Sep 2007 14:21:48 -0700
Subject: [R] Are the error messages of ConstrOptim() consisten with each
	other?
In-Reply-To: <46E51869.9070809@stats.uwo.ca>
References: <548b8d440709092358g3cd079cehd459e8592bb9673c@mail.gmail.com>
	<46E51869.9070809@stats.uwo.ca>
Message-ID: <548b8d440709101421o5346f1ccp2ed468d1ffe4a68a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070910/d9ca2e10/attachment.pl 

From fmc2+ at pitt.edu  Mon Sep 10 23:17:01 2007
From: fmc2+ at pitt.edu (Fiona Callaghan)
Date: Mon, 10 Sep 2007 17:17:01 -0400 (EDT)
Subject: [R] using bootstrap for tree selection step in rpart
Message-ID: <1129.141.151.145.62.1189459021.squirrel@webmail.pitt.edu>


Hi
I was wondering if someone could help me with an rpart problem.  I can see
that cross-validation is the default for tree selection in rpart -- has a
bootstrap method been implemented anywhere?  I think this is a different
thing to 'bagging' or 'boosting' -- I still want 'one' tree at the end, I
just would like it chosen using a bootstrap method.  Any ideas???

Thanks
Fiona

-- 
Fiona Callaghan, MA MS
A432 Crabtree Hall
Department of Biostatistics
Graduate School of Public Health
University of Pittsburgh
Phone 412 624 3063


From p.dalgaard at biostat.ku.dk  Mon Sep 10 23:24:13 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 10 Sep 2007 23:24:13 +0200
Subject: [R] MLE Function
In-Reply-To: <556837.12391.qm@web27212.mail.ukl.yahoo.com>
References: <556837.12391.qm@web27212.mail.ukl.yahoo.com>
Message-ID: <46E5B5FD.9090309@biostat.ku.dk>

Terence Broderick wrote:
> I am just trying to teach myself how to use the mle function in R because it is much better than what is provided in MATLAB. I am following tutorial material from the internet, however, it gives the following errors, does anybody know what is happening to cause such errors, or does anybody know any better tutorial material on this particular subject.
>   
>   
>> x.gam<-rgamma(200,rate=0.5,shape=3.5)
>> x<-x.gam
>> library(stats4)
>> ll<-function(lambda,alfa){n<-200;x<-x.gam -n*alfa*log(lambda)+n*log(gamma(alfa))-9alfa-1)*sum(log(x))+lambda*sum(x)}
>>     
> Error: syntax error, unexpected SYMBOL, expecting '\n' or ';' or '}' in "ll<-function(lambda,alfa){n<-200;x<-x.gam -n*alfa*log(lambda)+n*log(gamma(alfa))-9alfa"
>   
>> ll<-function(lambda,alfa){n<-200;x<-x.gam -n*alfa*log(lambda)+n*log(gamma(alfa))-(alfa-1)*sum(log(x))+lambda*sum(x)}
>> est<-mle(minuslog=ll,start=list(lambda=2,alfa=1))
>>     
> Error in optim(start, f, method = method, hessian = TRUE, ...) : 
>         objective function in optim evaluates to length 200 not 1
>
>    
>   
Er, not what I get. Did your version have that linefeed after x <- x.gam 
? If not, then you'll get your negative log-likelihood added to x.gam 
and the resulting "likelihood" becomes a vector of length 200 instead of 
a scalar.

In general, the first piece of advice for mle() is to check that the 
likelihood function really is what it should be. Otherwise there is no 
telling what the result might mean...

Secondly, watch out for parameter constraints. With your function, it 
very easily happens that "alfa" tries to go negative in which case the 
gamma function in the likelihood will do crazy things.
A common trick in such cases is to reparametrize by log-parameters, i.e.

ll <- function(lambda,alfa){n<-200; x<-x.gam
-n*alfa*log(lambda)+n*lgamma(alfa)-(alfa-1)*sum(log(x))+lambda*sum(x)}

ll2 <- function(llam, lalf) ll(exp(llam),exp(lalf))
est <- mle(minuslog=ll2,start=list(llam=log(2),lalf=log(1)))

par(mfrow=c(2,1))
plot(profile(est))

Notice, incidentally, the use of lgamma rather than log(gamma(.)), which 
is prone to overflow.

In fact, you could also write this likelihood directly  as

-sum(dgamma(x, rate=lambda, shape=alfa, log=T))


>    
>
>
> audaces fortuna iuvat
>        
> ---------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From tplate at acm.org  Mon Sep 10 23:16:28 2007
From: tplate at acm.org (Tony Plate)
Date: Mon, 10 Sep 2007 15:16:28 -0600
Subject: [R] [R-pkgs] new package 'trackObjs' - mirror objects to files,
 provide summaries & modification times
Message-ID: <46E5B42C.4040805@acm.org>

 From ?trackObjs:

Overview of trackObjs package

Description:

      The trackObjs package sets up a link between R objects in memory
      and files on disk so that objects are automatically resaved to
      files when they are changed.  R objects in files are read in on
      demand and do not consume memory prior to being referenced.  The
      trackObjs package also tracks times when objects are created and
      modified, and caches some basic characteristics of objects to
      allow for fast summaries of objects.

      Each object is stored in a separate RData file using the standard
      format as used by 'save()', so that objects can be manually picked
      out of or added to the trackObjs database if needed.

      Tracking works by replacing a tracked variable by an
      'activeBinding', which when accessed looks up information in an
      associated 'tracking environment' and reads or writes the
      corresponding RData file and/or gets or assigns the variable in
      the tracking environment.

Details:

      There are three main reasons to use the 'trackObjs' package:

         *  conveniently handle many moderately-large objects that would
            collectively exhaust memory or be inconvenient to manage in
            files by manually using 'save()' and 'load()'

         *  keep track of creation and modification times on objects

         *  get fast summaries of basic characteristics of objects -
            class, size, dimension, etc.

      There is an option to control whether tracked objects are cached
      in memory as well as being stored on disk.  By default, objects
      are not cached.  To save time when working with collections of
      objects that will all fit in memory, turn on caching with
      'track.options(cache=TRUE)', or start tracking with
      'track.start(..., cache=TRUE)'.

      Here is a brief example of tracking some variables in the global
      environment:


      > library(trackObjs)
      > track.start("tmp1")
      > x <- 123                  # Not yet tracked
      > track(x)                  # Variable 'x' is now tracked
      > track(y <- matrix(1:6, ncol=2)) # 'y' is assigned & tracked
      > z1 <- list("a", "b", "c")
      > z2 <- Sys.time()
      > track(list=c("z1", "z2")) # Track a bunch of variables
      > track.summary(size=F)     # See a summary of tracked vars
                  class    mode extent length            modified TA TW
      x         numeric numeric    [1]      1 2007-09-07 08:50:58  0  1
      y          matrix numeric  [3x2]      6 2007-09-07 08:50:58  0  1
      z1           list    list  [[3]]      3 2007-09-07 08:50:58  0  1
      z2 POSIXt,POSIXct numeric    [1]      1 2007-09-07 08:50:58  0  1
      > # (TA="total accesses", TW="total writes")
      > ls(all=TRUE)
      [1] "x"  "y"  "z1" "z2"
      > track.stop()              # Stop tracking
      > ls(all=TRUE)
      character(0)
      >
      > # Restart using the tracking dir -- the variables reappear
      > track.start("tmp1") # Start using the tracking dir again
     > ls(all=TRUE)
      [1] "x"  "y"  "z1" "z2"
      > track.summary(size=F)
                  class    mode extent length            modified TA TW
      x         numeric numeric    [1]      1 2007-09-07 08:50:58  0  1
      y          matrix numeric  [3x2]      6 2007-09-07 08:50:58  0  1
      z1           list    list  [[3]]      3 2007-09-07 08:50:58  0  1
      z2 POSIXt,POSIXct numeric    [1]      1 2007-09-07 08:50:58  0  1
      > track.stop()
      >
      > # the files in the tracking directory:
      > list.files("tmp1", all=TRUE)
      [1] "."                    ".."
      [3] "filemap.txt"          ".trackingSummary.rda"
      [5] "x.rda"                "y.rda"
      [7] "z1.rda"               "z2.rda"
      >

      There are several points to note:

         *  The global environment is the default environment for
            tracking - it is possible to track variables in other
            environments, but that environment must be supplied as an
            argument to the track functions.

         *  Vars must be explicitly 'track()'ed - newly created objects
            are not tracked.  (This is not a "feature", but there is
            currently no way of automatically tracking newly created
            objects - this is on the wishlist.)  Thus, it is possible
            for variables in a tracked environment to either tracked or
            untracked.

         *  When tracking is stopped, all tracked variables are saved on
            disk and will be no longer accessible until tracking is
            started again.

         *  The objects are stored each in their own file in the
            tracking dir, in the format used by 'save()'/'load()' (RData
            files).

List of basic functions and common calling patterns:

      Six functions cover the majority of common usage of the trackObjs
      package:

         *  'track.start(dir=...)': start tracking the global
            environment, with files saved in 'dir'

         *  'track.stop()': stop tracking (any unsaved tracked variables
            are saved to disk and all tracked variables become
            unavailable until tracking starts again)

         *  'track(x)': start tracking 'x' - 'x' in the global
            environment is replaced by an active binding and 'x' is
            saved in its corresponding file in the tracking directory
            and, if caching is on, in the tracking environment

         *  'track(x <- value)': start tracking 'x'

         *  'track(list=c('x', 'y'))': start tracking specified
            variables

         *  'track(all=TRUE)': start tracking all untracked variables in
            the global environment

         *  'untrack(x)': stop tracking variable 'x' - the R object 'x'
            is put back as an ordinary object in the global environment

         *  'untrack(all=TRUE)': stop tracking all variables in the
            global environment (but tracking is still set up)

         *  'untrack(list=...)': stop tracking specified variables

         *  'track.summary()': print a summary of the basic
            characteristics of tracked variables: name, class, extent,
            and creation, modification and access times.

         *  'track.remove(x)': completely remove all traces of 'x' from
            the global environment, tracking environment and tracking
            directory.   Note that if variable 'x' in the global
            environment is tracked, 'remove(x)' will make 'x' an
            "orphaned" variable: 'remove(x)' will just remove the active
            binding from the global environment, and leave 'x' in the
            tracked environment and on file, and 'x' will reappear after
            restarting tracking.

Complete list of functions and common calling patterns:

      The 'trackObjs' package provides many additional functions for
      controlling how tracking is performed (e.g., whether or not
      tracked variables are cached in memory), examining the state of
      tracking (show which variables are tracked, untracked, orphaned,
      masked, etc.) and repairing tracking environments and databases
      that have become inconsistent or incomplete (this may result from
      resource limitiations, e.g., being unable to write a save file due
      to lack of disk space, or from manual tinkering, e.g., dropping a
      new save file into a tracking directory.)

[truncated here -- see ?trackObjs]

-- Tony Plate

PS: to give credit where due, the end of ?trackObjs says:

References:
      Roger D. Peng. Interacting with data using the filehash package. R
      News, 6(4):19-24, October 2006.
      'http://cran.r-project.org/doc/Rnews' and
      'http://sandybox.typepad.com/software'

      David E. Brahm. Delayed data packages. R News, 2(3):11-12,
      December 2002.  'http://cran.r-project.org/doc/Rnews'

See Also:
      [...]
      Inspriation from the packages 'g.data' and 'filehash'.

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From jonathan-beard at uiowa.edu  Mon Sep 10 23:39:08 2007
From: jonathan-beard at uiowa.edu (VTLT1999)
Date: Mon, 10 Sep 2007 14:39:08 -0700 (PDT)
Subject: [R] Generating Replicate Datasets (using loops or other means)
Message-ID: <12603580.post@talk.nabble.com>


Hello All,

I have searched many help forums, message boards, etc. and I just can't
apply the comments to what I need my program to do.  I am running R 2.5.1 on
an XP system, and my desire is to produce replicate datasets for a
simulation study I am running.  Essentially, I have sets of parameters (a's,
b's, and c's) that define a function which produces a decimal value.  This
value is compared to a random uniform value, and is coded a 1 if the
function is greater than the uniform value, 0 if it is <= to the uniform
value.  My code thus far works great, but I just need it to run several
times.    Here we go:

library(mvtnorm)
library(sm)
library(ltm)
library(irtoys)

k<- 5000
set.seed(271828)
t <-
rmvnorm(n=k,mean=c(-1,0,1),sigma=matrix(c(1,.8,.5,.8,1,.8,.5,.8,1),3,3)) 
  #Using mv here because of the likely association of ability (theta = t)
across time.

t1<-as.matrix(t[,1])
t2<-as.matrix(t[,2])
t3<-as.matrix(t[,3])

set.seed(271828)

#  Population item parameters (n=54)  from which we will select relevant
items
#  These are the parameters that are used in the function

a <- c(1.18120, 0.92613, 0.96886, 0.80503, 1.12384, 
       0.84073, 0.85544, 0.86801, 1.01054, 0.82278,
       1.10353, 0.78865, 0.98421, 1.76071, 0.89603, 
       0.84671, 0.89737, 0.74775, 0.32190, 0.69730, 
       0.72059, 1.16762, 1.29257, 1.32902, 0.59540, 
       0.51022, 0.59259, 0.93951, 0.68568, 0.55649, 
       0.88084, 0.52940, 0.45735, 0.57560, 1.11779,
       0.96984, 1.19692, 0.99102, 1.25847, 1.62555, 
       0.63049, 1.07807, 1.04897, 1.23138, 1.14014, 
       1.25230, 1.14844, 0.59287, 0.83143, 0.81723,
       0.52141, 0.61980, 0.49945, 1.02749)

b <- c(-2.51737, -1.95897, -1.72667, -0.82988, -0.36093,
        0.72554,  0.91442,  0.78061,  0.06088,  0.75733,
       -0.76371,  0.24552, -0.42050,  0.88232, -0.81761,
        0.06466, -0.43866, -0.46042,  0.21636, -0.73147,
       -1.44086, -1.03718,  0.07275, -0.17197,  1.53796,
       -0.45631, -1.69826, -0.66506,  0.98921,  0.30714,
       -0.62245,  0.97253,  1.95894,  0.21277,  1.96346,
        1.18825,  1.59917, -0.28401, -1.23530, -0.09671,
       -0.31581, -0.66149, -0.81284, -0.35399, -0.07623, 
        1.06442, -0.68559,  1.07591,  0.97458,  0.06436,
        1.25622,  1.73954,  1.75052,  2.34088)

c <- c(0.00000, 0.00000, 0.00000, 0.00000, 0.19648,
       0.31302, 0.26454, 0.19714, 0.06813, 0.21344,
       0.00000, 0.03371, 0.00000, 0.16581, 0.11054, 
       0.08756, 0.07115, 0.26892, 0.00000, 0.06883, 
       0.00000, 0.14815, 0.32389, 0.19616, 0.17597,
       0.00000, 0.00000, 0.04337, 0.19949, 0.20377, 
       0.00000, 0.06243, 0.13639, 0.00000, 0.18166,
       0.15996, 0.20184, 0.08331, 0.24453, 0.26114, 
       0.16434, 0.20750, 0.32658, 0.31870, 0.45227,
       0.35039, 0.31178, 0.17999, 0.22774, 0.21675,
       0.10153, 0.17764, 0.15205, 0.19858)

#  Item parameters for generating 3PL data for all five testing occasions:
#  This selects the relevant parameters for a particular data generation run
#  Only parameters for the first testing occasion are shown to save space

a1 <- as.matrix(a[c(1:5,15:20,22:24,38:44)])
b1 <- as.matrix(b[c(1:5,15:20,22:24,38:44)])
c1 <- as.matrix(c[c(1:5,15:20,22:24,38:44)])

#  Here is where I would like to begin my replications, but don't know how
to make R do it.
#  The code below produces a matrix of 0's and 1's (which will be used by
another program)
#  I would like to nest this in a "do loop" such that, say, 30 replicate
datasets are produced using the 
#    same parameters. 
   
   N <- nrow(t1)     # number of examinees
   n <- nrow(a1)     # number of items
   d <- 1.7
   theta <- t1  
   response <- matrix (0,N,n)  
   uni <- matrix (runif(N*n),nrow = N)

   for (i in 1:N)
   {
     for (j in 1:n) 
     {
      if ( c1[j]+(1-c1[j])/(1+exp(-d*a1[j]*(theta[i]-b1[j]))) > uni[i,j] )
         response[i,j] = 1
       else 
         response[i,j] = 0
     }
   }
write.table(response, file="C:/responses.dat", sep=" ",row.names=FALSE,
col.names=FALSE)  

I tried earlier nesting this in another for loop, but that indexes elements
of matrices and vectors, and doesn't seem to apply to a "global" loop
methodology.  I am attempting to use replicate as we speak, but
documentation is sparse (help("replicate") is nested in lapply information). 
Any guidance is greatly appreciated.  

Thanks in advance,

Jonathan Beard

-- 
View this message in context: http://www.nabble.com/Generating-Replicate-Datasets-%28using-loops-or-other-means%29-tf4418768.html#a12603580
Sent from the R help mailing list archive at Nabble.com.


From ggrothendieck at gmail.com  Tue Sep 11 01:26:26 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 10 Sep 2007 19:26:26 -0400
Subject: [R] off-topic: better OS for statistical computing
In-Reply-To: <20070910200658.GA7176@ihug.co.nz>
References: <1115a2b00709100922h7780644brc59e3f9c25760caf@mail.gmail.com>
	<971536df0709100926r4ac598ffj5b892472531d18ad@mail.gmail.com>
	<20070910200658.GA7176@ihug.co.nz>
Message-ID: <971536df0709101626g3b1b6d5dvb4a3e1155b9c192@mail.gmail.com>

My sense is that R users are even split between UNIX and Windows
users so either will do in terms of the larger community.

Some R packages may not be avaliable on every platform or will
be available on one platform before another or there will be
certain platform-specific issues.  So in the end its easiest to
have the same thing everyone else that you work with does.

Also if you run into
problems then you can ask others whereas if you are the lone
person with something different you have no one to turn to.

Also associated software may be, for example, Microsoft Office in
a Microsoft environment and LaTeX in a UNIX environment. And
networking will be simplified in a consistent environment too.
Certainly there is Open Office, Samba and putty but the easiest
is just not to have to worry about getting everything to work
together by just having the same thing in the first place.

Neither Linux nor Windows is superior to the other.  People
making such representations generally know one much better
than the other and its more a reflection of their own experience
than anything else.  I personally have used both UNIX and
Windows since their inception and find that I tend to have a
slight preference for whatever I used last.  Technical merits of
one vs. the other are basically irrelevant for most purposes.

On 9/10/07, Patrick Connolly <p_connolly at ihug.co.nz> wrote:
> On Mon, 10-Sep-2007 at 12:26PM -0400, Gabor Grothendieck wrote:
>
> |> You want whatever all the people you are working with are using
> |> to make it as easy as possible to work together with them.
>
> Assuming you're using R, there is negligible difficulty using a
> different OS from what your colleagues use (apart from the
> inconsistencies you get between different versions of Windows, but
> even that has little effect on R).  The standard .RData binary files
> work with Windows and Linux (and probably OS X).
>
> The only issue I come across is that Linux can't create WMF files as
> readily as Windows can, and that is more than made up for by the
> greater flexibility that Linux offers.  It's easier in Linux to
> produce Excel files from dataframes and matrices using a perl script
> posted to this list by Marc Schwartz.  Thanks again Marc.
>
> Best
>
> Patrick
>
>
> |>
> |> On 9/10/07, Wensui Liu <liuwensui at gmail.com> wrote:
> |> > Good morning, everyone,
> |> > I am sorry for this off-topic post but think I can get great answer
> |> > from this list.
> |> > My question is what is the best OS on PC (laptop) for statistical
> |> > computing and why.
> |> > I really appreciate your insight.
> |> > Have a nice day.
> |>
> |> ______________________________________________
> |> R-help at stat.math.ethz.ch mailing list
> |> https://stat.ethz.ch/mailman/listinfo/r-help
> |> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> |> and provide commented, minimal, self-contained, reproducible code.
>
> --
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>   ___    Patrick Connolly
>  {~._.~}                         Great minds discuss ideas
>  _( Y )_                        Middle minds discuss events
> (:_~*~_:)                        Small minds discuss people
>  (_)-(_)                                   ..... Anon
>
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>


From m_olshansky at yahoo.com  Tue Sep 11 02:23:02 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Mon, 10 Sep 2007 17:23:02 -0700 (PDT)
Subject: [R] Generating Replicate Datasets (using loops or other means)
In-Reply-To: <12603580.post@talk.nabble.com>
Message-ID: <708001.89013.qm@web32204.mail.mud.yahoo.com>

Hi Jonathan,

What exactly do you mean by replication? 
Do you want to keep a1,b1,c1,... unchanged but have 30
different sets of random numbers?

Regards,

Moshe.

--- VTLT1999 <jonathan-beard at uiowa.edu> wrote:

> 
> Hello All,
> 
> I have searched many help forums, message boards,
> etc. and I just can't
> apply the comments to what I need my program to do. 
> I am running R 2.5.1 on
> an XP system, and my desire is to produce replicate
> datasets for a
> simulation study I am running.  Essentially, I have
> sets of parameters (a's,
> b's, and c's) that define a function which produces
> a decimal value.  This
> value is compared to a random uniform value, and is
> coded a 1 if the
> function is greater than the uniform value, 0 if it
> is <= to the uniform
> value.  My code thus far works great, but I just
> need it to run several
> times.    Here we go:
> 
> library(mvtnorm)
> library(sm)
> library(ltm)
> library(irtoys)
> 
> k<- 5000
> set.seed(271828)
> t <-
>
rmvnorm(n=k,mean=c(-1,0,1),sigma=matrix(c(1,.8,.5,.8,1,.8,.5,.8,1),3,3))
> 
>   #Using mv here because of the likely association
> of ability (theta = t)
> across time.
> 
> t1<-as.matrix(t[,1])
> t2<-as.matrix(t[,2])
> t3<-as.matrix(t[,3])
> 
> set.seed(271828)
> 
> #  Population item parameters (n=54)  from which we
> will select relevant
> items
> #  These are the parameters that are used in the
> function
> 
> a <- c(1.18120, 0.92613, 0.96886, 0.80503, 1.12384, 
>        0.84073, 0.85544, 0.86801, 1.01054, 0.82278,
>        1.10353, 0.78865, 0.98421, 1.76071, 0.89603, 
>        0.84671, 0.89737, 0.74775, 0.32190, 0.69730, 
>        0.72059, 1.16762, 1.29257, 1.32902, 0.59540, 
>        0.51022, 0.59259, 0.93951, 0.68568, 0.55649, 
>        0.88084, 0.52940, 0.45735, 0.57560, 1.11779,
>        0.96984, 1.19692, 0.99102, 1.25847, 1.62555, 
>        0.63049, 1.07807, 1.04897, 1.23138, 1.14014, 
>        1.25230, 1.14844, 0.59287, 0.83143, 0.81723,
>        0.52141, 0.61980, 0.49945, 1.02749)
> 
> b <- c(-2.51737, -1.95897, -1.72667, -0.82988,
> -0.36093,
>         0.72554,  0.91442,  0.78061,  0.06088, 
> 0.75733,
>        -0.76371,  0.24552, -0.42050,  0.88232,
> -0.81761,
>         0.06466, -0.43866, -0.46042,  0.21636,
> -0.73147,
>        -1.44086, -1.03718,  0.07275, -0.17197, 
> 1.53796,
>        -0.45631, -1.69826, -0.66506,  0.98921, 
> 0.30714,
>        -0.62245,  0.97253,  1.95894,  0.21277, 
> 1.96346,
>         1.18825,  1.59917, -0.28401, -1.23530,
> -0.09671,
>        -0.31581, -0.66149, -0.81284, -0.35399,
> -0.07623, 
>         1.06442, -0.68559,  1.07591,  0.97458, 
> 0.06436,
>         1.25622,  1.73954,  1.75052,  2.34088)
> 
> c <- c(0.00000, 0.00000, 0.00000, 0.00000, 0.19648,
>        0.31302, 0.26454, 0.19714, 0.06813, 0.21344,
>        0.00000, 0.03371, 0.00000, 0.16581, 0.11054, 
>        0.08756, 0.07115, 0.26892, 0.00000, 0.06883, 
>        0.00000, 0.14815, 0.32389, 0.19616, 0.17597,
>        0.00000, 0.00000, 0.04337, 0.19949, 0.20377, 
>        0.00000, 0.06243, 0.13639, 0.00000, 0.18166,
>        0.15996, 0.20184, 0.08331, 0.24453, 0.26114, 
>        0.16434, 0.20750, 0.32658, 0.31870, 0.45227,
>        0.35039, 0.31178, 0.17999, 0.22774, 0.21675,
>        0.10153, 0.17764, 0.15205, 0.19858)
> 
> #  Item parameters for generating 3PL data for all
> five testing occasions:
> #  This selects the relevant parameters for a
> particular data generation run
> #  Only parameters for the first testing occasion
> are shown to save space
> 
> a1 <- as.matrix(a[c(1:5,15:20,22:24,38:44)])
> b1 <- as.matrix(b[c(1:5,15:20,22:24,38:44)])
> c1 <- as.matrix(c[c(1:5,15:20,22:24,38:44)])
> 
> #  Here is where I would like to begin my
> replications, but don't know how
> to make R do it.
> #  The code below produces a matrix of 0's and 1's
> (which will be used by
> another program)
> #  I would like to nest this in a "do loop" such
> that, say, 30 replicate
> datasets are produced using the 
> #    same parameters. 
>    
>    N <- nrow(t1)     # number of examinees
>    n <- nrow(a1)     # number of items
>    d <- 1.7
>    theta <- t1  
>    response <- matrix (0,N,n)  
>    uni <- matrix (runif(N*n),nrow = N)
> 
>    for (i in 1:N)
>    {
>      for (j in 1:n) 
>      {
>       if (
> c1[j]+(1-c1[j])/(1+exp(-d*a1[j]*(theta[i]-b1[j]))) >
> uni[i,j] )
>          response[i,j] = 1
>        else 
>          response[i,j] = 0
>      }
>    }
> write.table(response, file="C:/responses.dat", sep="
> ",row.names=FALSE,
> col.names=FALSE)  
> 
> I tried earlier nesting this in another for loop,
> but that indexes elements
> of matrices and vectors, and doesn't seem to apply
> to a "global" loop
> methodology.  I am attempting to use replicate as we
> speak, but
> documentation is sparse (help("replicate") is nested
> in lapply information). 
> Any guidance is greatly appreciated.  
> 
> Thanks in advance,
> 
> Jonathan Beard
> 
> -- 
> View this message in context:
>
http://www.nabble.com/Generating-Replicate-Datasets-%28using-loops-or-other-means%29-tf4418768.html#a12603580
> Sent from the R help mailing list archive at
> Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From ggrothendieck at gmail.com  Tue Sep 11 02:29:09 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 10 Sep 2007 20:29:09 -0400
Subject: [R] finding the minimum positive value of some data
In-Reply-To: <12599319.post@talk.nabble.com>
References: <12599319.post@talk.nabble.com>
Message-ID: <971536df0709101729i32456e75vf28d62b6af51d1d6@mail.gmail.com>

Here are some solutions each of which
1. has only one line,
2. x only occurs once so you can just plug in a complex expression
3. no temporary variables are left

min(sapply(x, function(z) if (z > 0) z else Inf))

(function(z) min(ifelse(z > 0, z, Inf))) (x)

with(list(z = x), min(z[z > 0]))

local({ z <- x; min(z[z > 0]) })

On 9/10/07, dxc13 <dxc13 at health.state.ny.us> wrote:
>
> useRs,
>
> I am looking to find the minimum positive value of some data I have.
> Currently, I am able to find the minimum of data after I apply some other
> functions to it:
>
> > x
>  [1]  1  0  1  2  3  3  4  5  5  5  6  7  8  8  9  9 10 10
>
> > sort(x)
>  [1]  0  1  1  2  3  3  4  5  5  5  6  7  8  8  9  9 10 10
>
> > diff(sort(x))
>  [1] 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 1 0
>
> > min(diff(sort(x)))
> [1] 0
>
> The minimum is given as zero, which is clearly true, but I am interested in
> only the positive minimum, which is 1.  Can I find this by using only 1 line
> of code, like I have above? Thanks!
>
> dxc13
> --
> View this message in context: http://www.nabble.com/finding-the-minimum-positive-value-of-some-data-tf4417250.html#a12599319
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From deleeuw at stat.ucla.edu  Tue Sep 11 03:32:45 2007
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Mon, 10 Sep 2007 18:32:45 -0700
Subject: [R] what am I missing
Message-ID: <418F8EC0-A2BA-4FC8-8F36-E56BF4319F50@stat.ucla.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070910/f39ed075/attachment.pl 

From ggrothendieck at gmail.com  Tue Sep 11 03:38:35 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 10 Sep 2007 21:38:35 -0400
Subject: [R] what am I missing
In-Reply-To: <418F8EC0-A2BA-4FC8-8F36-E56BF4319F50@stat.ucla.edu>
References: <418F8EC0-A2BA-4FC8-8F36-E56BF4319F50@stat.ucla.edu>
Message-ID: <971536df0709101838p2f77c82av8c97baee0bdbf0b5@mail.gmail.com>

Its a FAQ:

http://hermes.sdu.dk/Rdoc/faq.html#Why%20does%20outer()%20behave%20strangely%20with%20my%20function%3f

On 9/10/07, Jan de Leeuw <deleeuw at stat.ucla.edu> wrote:
> x<-seq(-1,1,length=10)
> y<-seq(-1,1,length=10)
> a<-matrix(c(1,2,2,1),2,2)
> b<-matrix(c(2,1,1,2),2,2)
>
> fv<-function(x,y) {
>        m<-x*a+y*b
>        t<-m[1,1]+m[2,2]; d<-m[1,1]*m[2,2]-m[1,2]^2
>        return((t-sqrt(t^2-4*d))/2)
> }
>
> gv<-function(x,y) {
>        t<-x*(a[1,1]+a[2,2])+y*(b[1,1]+b[2,2])
>        d<-(x*a[1,1]+y*b[1,1])*(x*a[2,2]+y*b[2,2])-(x*a[1,2]+y*b[1,2])^2
>        return((t-sqrt(t^2-4*d))/2)
> }
>
>
> now outer(x,y,gv) works as expected, outer(x,y,fv) bombs. But
>
> z<-matrix(0,10,10); for (i in 1:10) for (j in 1:10) z[i,j]<-fv(x[i],y
> [j])
>
> works fine. Must be something in outer().
>
> ==========================================================
> Jan de Leeuw, 11667 Steinhoff Rd, Frazier Park, CA 93225, 661-245-1725
> .mac: jdeleeuw ++++++  aim: deleeuwjan ++++++ skype: j_deleeuw
> homepages: http://www.cuddyvalley.org and http://gifi.stat.ucla.edu
> ==========================================================
>                A bath when you're born,
>           a bath when you die,
>                how stupid.          (Issa 1763-1827)
>
>
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From liuwensui at gmail.com  Tue Sep 11 03:44:44 2007
From: liuwensui at gmail.com (Wensui Liu)
Date: Mon, 10 Sep 2007 21:44:44 -0400
Subject: [R] install packages automatically
Message-ID: <1115a2b00709101844q601ccf4agf00e4cab73be1995@mail.gmail.com>

Dear Listers,
I am a little tired of installing all packages I want every time when
I instill a new version of R.
Say, if I have a list of packages I need to use, is it possible to
tell R to install them all for me automatically rather than I install
them one by one?
Thx.


From r.darnell at uq.edu.au  Tue Sep 11 04:04:23 2007
From: r.darnell at uq.edu.au (Ross Darnell)
Date: Tue, 11 Sep 2007 12:04:23 +1000
Subject: [R] install packages automatically
In-Reply-To: <1115a2b00709101844q601ccf4agf00e4cab73be1995@mail.gmail.com>
References: <1115a2b00709101844q601ccf4agf00e4cab73be1995@mail.gmail.com>
Message-ID: <E4178EE0463C7D40AF637C4DDAC8030EC9CBCD@UQEXMB2.soe.uq.edu.au>

Try

?update.packages

Ross Darnell

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Wensui Liu
Sent: Tuesday, 11 September 2007 11:45 AM
To: r-help at stat.math.ethz.ch
Subject: [R] install packages automatically

Dear Listers,
I am a little tired of installing all packages I want every time when
I instill a new version of R.
Say, if I have a list of packages I need to use, is it possible to
tell R to install them all for me automatically rather than I install
them one by one?
Thx.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From adrian at maths.uwa.edu.au  Tue Sep 11 05:05:34 2007
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Tue, 11 Sep 2007 11:05:34 +0800 (WST)
Subject: [R] [R-pkgs] scuba 1.1-8
Message-ID: <60074.124.182.61.237.1189479934.squirrel@124.182.61.237>

Version 1.1-8 of package 'scuba' has been uploaded to CRAN.

'scuba' is a package for scuba diving calculations and decompression
models. It supports dive profiles (tables, plotting etc), analysis of dive
profiles using decompression models, gas toxicity calculations, and gas
usage calculations.

New features in version 1.1-8:
     . support for dive profiles uploaded from a dive computer
     . new dataset: dive profile from a wreck dive on nitrox
     . bug fix in oxygen toxicity calculations

Adrian Baddeley

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages


From bchristo at email.arizona.edu  Tue Sep 11 05:12:29 2007
From: bchristo at email.arizona.edu (Brad Christoffersen)
Date: Mon, 10 Sep 2007 20:12:29 -0700
Subject: [R] overlay lattice histograms with goodness-of-fit pdfs
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC0574AF39@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC0574AF39@DJFPOST01.djf.agrsci.dk>
Message-ID: <20070910201229.0sba4gs84c4s4woo@www.email.arizona.edu>

Mange tak!

FYI, this is the way it is able to run (I was going to attach
"station.precip.R", but I read that attaching files is not recommended 
- let me
know if you would like it)

x <- dget(file="C://Documents and Settings/Bradley/My
Documents/Arizona/CourseResources/ATMO529/station.precip.R")
histogram(~ data | month * station, data = sta.stack,
	subset = type=="precip" & month %in% c("Dec","Jan","Feb"),
	xlab = "Precipitation (mm)",
	type = "density",
	panel = function(x, ...) {
		panel.histogram(x, ...)
		panel.mathdensity(dmath = dnorm, col = "black",
					args = list(mean = mean(sta.stack$data), sd = sd(sta.stack$data)))
		panel.mathdensity(dmath = dgamma, col = "black",
					args = list(shape = (mean(sta.stack$data))^2 / (stdev(sta.stack$data))^2,
							scale = (stdev(sta.stack$data))^2 / mean(sta.stack$data)))
	})

Now, what would be great is to be able to reference the different calls to
panel.mathdensity() so that the corresponding probability * histogram area ( =
counts) in each bin can be used to compute a simple chi-square 
goodness-of-fit.
  I tried calling panel.mathdensity() outside of histogram(), but I don't think
this is right - it returns NULL.  I also looked at chisq.test, but this 
doesn't
support trellis formulas.  Any thoughts or leads?

Thanks,
Brad Christoffersen



Quoting Frede Aakmann T?gersen <FredeA.Togersen at agrsci.dk>:

> The following is one of the examples in the help page for histogram:
>
>      histogram( ~ height | voice.part, data = singer,
>                xlab = "Height (inches)", type = "density",
>                panel = function(x, ...) {
>                    panel.histogram(x, ...)
>                    panel.mathdensity(dmath = dnorm, col = "black",
>                                      args = list(mean=mean(x),sd=sd(x)))
>                } )
>
> This should give you some thing to start from.
>
> Also using the subset argument of the lattice functions will make 
> make your code more readable. Instead of your code
>
> histogram(~ data | month * station,
> 	data = sta.stack[sta.stack[,"type"]=="precip" & 
> (sta.stack[,"month"]=="Dec" | sta.stack[,"month"]=="Jan" | 
> sta.stack[,"month"]=="Feb"),],
> 	xlab = "Precipitation (mm)")
>
> you can use (not tested because you didn't supply a reproducable example)
>
> histogram(~ data | month * station, data = sta.stack
> 	subset = type==precip & month %in% c("Dec", "Jan", "Feb"),
> 	xlab = "Precipitation (mm)")
>
>
> Med venlig hilsen
> Frede Aakmann T?gersen
>
>
>
>
>> -----Oprindelig meddelelse-----
>> Fra: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] P? vegne af Brad
>> Christoffersen
>> Sendt: 10. september 2007 12:08
>> Til: R-help at stat.math.ethz.ch
>> Emne: [R] overlay lattice histograms with goodness-of-fit pdfs
>>
>> Hello,
>>
>> I am new to R exploratory data analysis and plotting.  Is
>> anyone aware of a way to overlay a set of conditional
>> histograms with conditional PDFs?  Below, I generate a
>> lattice plot of precipitation histograms based on different
>> months and stations, given a subset of the dataset:
>>
>>
>> histogram(~ data | month * station,
>> 	data = sta.stack[sta.stack[,"type"]=="precip" &
>> (sta.stack[,"month"]=="Dec" | sta.stack[,"month"]=="Jan" |
>> sta.stack[,"month"]=="Feb"),],
>> 	xlab = "Precipitation (mm)")
>>
>>
>> I previously used a combination of the low-level 'lines()'
>> and 'dgamma()'
>> functions to overlay a gamma PDF onto a single histogram.
>> Now what I would like to do is to do the same thing, but with
>> a function that allows me to specify a formula similar to
>> that in the histogram function above
>>
>> [SomeKindOfPDF] ~ [x-range] | month * station
>>
>> which will plot the PDF with the appropriate factors (month
>> and station).
>>
>> All I'm looking for is for someone to get me going in the
>> right direction with a useful package or function to use.
>>
>> Any help is much appreciated!
>> Brad Christoffersen
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>



From jholtman at gmail.com  Tue Sep 11 05:47:34 2007
From: jholtman at gmail.com (jim holtman)
Date: Mon, 10 Sep 2007 23:47:34 -0400
Subject: [R] POSIXct dates on x-axis using xyplot
Message-ID: <644e1f320709102047n6e4a4902p23c4b5ed91496f5b@mail.gmail.com>

I am using 'xyplot' in lattice to plot some data where the x-axis is a
POSIXct date.  I have data which spans a 6 month period, but when I
plot it, only the last month is printed on the right hand side of the
axis.  I would have expected that at least I would have a beginning
and an ending point so that I have a point of reference as to the time
that the data spans.  Here is some test data.


> # create test data
> dates <- seq(as.POSIXct('2006-01-03'), as.POSIXct('2006-06-26'), by='1 week')
> my.data <- seq(1, length=length(dates))
> require(lattice)
[1] TRUE
> # plot only shows a single month ("Jul" on the right).  Would have
> # expected at least the beginning and the ending month since this spans
> # a 6 month period
> pdf('/test.pdf')
> xyplot(my.data ~ dates)
> dev.off()
windows
      2
> sessionInfo()
R version 2.5.1 (2007-06-27)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
[7] "base"

other attached packages:
 lattice
"0.16-5"
> Sys.info()
                      sysname                       release
                    "Windows"                      "NT 5.1"
                      version                      nodename
"(build 2600) Service Pack 2"                  "JIM-LAPTOP"
                      machine                         login
                        "x86"                 "jim holtman"
                         user
                "jim holtman"
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From m_olshansky at yahoo.com  Tue Sep 11 06:02:58 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Mon, 10 Sep 2007 21:02:58 -0700 (PDT)
Subject: [R] finding the minimum positive value of some data
In-Reply-To: <12599319.post@talk.nabble.com>
Message-ID: <574899.48424.qm@web32211.mail.mud.yahoo.com>

Either
> min(diff(sort(x))[diff(sort(x))>0])
or
> min(diff(sort(unique(x))))


--- dxc13 <dxc13 at health.state.ny.us> wrote:

> 
> useRs,
> 
> I am looking to find the minimum positive value of
> some data I have. 
> Currently, I am able to find the minimum of data
> after I apply some other
> functions to it:
> 
> > x
>  [1]  1  0  1  2  3  3  4  5  5  5  6  7  8  8  9  9
> 10 10
> 
> > sort(x)
>  [1]  0  1  1  2  3  3  4  5  5  5  6  7  8  8  9  9
> 10 10
> 
> > diff(sort(x))
>  [1] 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 1 0
> 
> > min(diff(sort(x)))
> [1] 0
> 
> The minimum is given as zero, which is clearly true,
> but I am interested in
> only the positive minimum, which is 1.  Can I find
> this by using only 1 line
> of code, like I have above? Thanks!
> 
> dxc13
> -- 
> View this message in context:
>
http://www.nabble.com/finding-the-minimum-positive-value-of-some-data-tf4417250.html#a12599319
> Sent from the R help mailing list archive at
> Nabble.com.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From schaefer at pointone.de  Tue Sep 11 07:40:34 2007
From: schaefer at pointone.de (=?ISO-8859-1?Q?Christian_Sch=E4fer?=)
Date: Tue, 11 Sep 2007 07:40:34 +0200
Subject: [R] using bootstrap for tree selection step in rpart
In-Reply-To: <1129.141.151.145.62.1189459021.squirrel@webmail.pitt.edu>
References: <1129.141.151.145.62.1189459021.squirrel@webmail.pitt.edu>
Message-ID: <46E62A52.4030505@pointone.de>

Fiona Callaghan wrote:
> I was wondering if someone could help me with an rpart problem.  I can see
> that cross-validation is the default for tree selection in rpart -- has a
> bootstrap method been implemented anywhere?  I think this is a different
> thing to 'bagging' or 'boosting' -- I still want 'one' tree at the end, I
> just would like it chosen using a bootstrap method.  Any ideas???

Hi Fiona,

I'm not sure if I understand you correctly.
To get one single rpart tree trained on one bootstrap sample, try 
bagging() from the 'ipred' package and set nbagg=1.

Bye,
Chris


From shaoranwill at hotmail.com  Mon Sep 10 19:38:57 2007
From: shaoranwill at hotmail.com (shao ran)
Date: Mon, 10 Sep 2007 17:38:57 +0000
Subject: [R] State observation in predict.arima
Message-ID: <BAY113-F31F56366109E390EE24DD7B9C00@phx.gbl>

Hi *,

Firstly, thank you so much for your time to read my email.

In R, without compiling source code, is it possible to observe internal 
state in Kalman Filter when predict.arima method is used for time series 
prediction? i.e. given a time series, given an ARIMA model, how to observe 
the state variable in R? (like a step by step debugging in c++).


If compiling is a must, which tool is used usually to compile R source code 
on windows?

Thanks 
 
will


From wl2776 at gmail.com  Tue Sep 11 09:37:04 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Tue, 11 Sep 2007 00:37:04 -0700 (PDT)
Subject: [R] install packages automatically
In-Reply-To: <1115a2b00709101844q601ccf4agf00e4cab73be1995@mail.gmail.com>
References: <1115a2b00709101844q601ccf4agf00e4cab73be1995@mail.gmail.com>
Message-ID: <12609660.post@talk.nabble.com>


This was discussed here sometime ago.
Several variants are possible.

You can install the new version of R over the old one, in the same folder,
this preserves the installed packages. At least, this works fine for me on
Windows.

You can also store your list of packages in a simple R script and execute it
once every time you upgrade the R version.
Something like this: 

install.packages(c(
"AMORE",
"ggplot2",
"rgdal",
"rgl"
[etc]
))

You can also install these packages into separate directory and add the path
to the .libPaths (please, refer to the documentation about library paths).
This can be done, for example, in system wide startup script Rprofile.site


Wensui Liu wrote:
> 
> Dear Listers,
> I am a little tired of installing all packages I want every time when
> I instill a new version of R.
> Say, if I have a list of packages I need to use, is it possible to
> tell R to install them all for me automatically rather than I install
> them one by one?
> Thx.
> 

-- 
View this message in context: http://www.nabble.com/install-packages-automatically-tf4419780.html#a12609660
Sent from the R help mailing list archive at Nabble.com.


From brassnotdead at googlemail.com  Tue Sep 11 10:01:50 2007
From: brassnotdead at googlemail.com (Patrick Zimmermann)
Date: Tue, 11 Sep 2007 10:01:50 +0200
Subject: [R] composition of a matrix by matches between two data frames
Message-ID: <bae7f91d0709110101t32b4f696i1d0944562f05bcae@mail.gmail.com>

Dear R-users,

I want to compose a new table (a presence/absence matrix of species in
regions) by matches between two data frames.
The first data frame has the species as header and the habitats in
which they occure as elements.
The second data frame has the regions as header and the occuring
habitats as elements.

To fill a cell in the new matrix (e.g. spcs.x in region.y) I want R to
compare the habitat lists of spcs.x and region.y.
If any of the habitats occurs in both lists the value of the cell shall be 1.

The structure I used looks like this:

	for(i in 1:ncol(matrix))
	 matrix[match(species[,i], region[,i]), i]<- 1

It returns a result, but it contains only complete and not the desired
partial matches. I have no clue how change this.

Thanks in advance for your suggestions,

Patrick


From ptit_bleu at yahoo.fr  Tue Sep 11 10:13:26 2007
From: ptit_bleu at yahoo.fr (Ptit_Bleu)
Date: Tue, 11 Sep 2007 01:13:26 -0700 (PDT)
Subject: [R] [solved] Re: I can't do it again on an other PC : R+RMySQL
 ->error loading dll
In-Reply-To: <12592576.post@talk.nabble.com>
References: <12592576.post@talk.nabble.com>
Message-ID: <12610089.post@talk.nabble.com>


Hi,

just to say that I "solved" my problem. I wrote "solved" because all I did
was to uninstall R and the DBI and RMySQL libraries and then install
everything again.
The only change is that I used another RMySQL.zip file found at this address
:
http://www.bioconductor.org/packages/2.0/extra/bin/windows/contrib/2.5/RMySQL_0.6-0.zip
(the file is much bigger than the one I used on my PC : 1064 Mo instead of
383 Mo).

I installed the DBI and the RMySQL packages from R (intallation from .zip
file).
I typed "library(RMySQL)" and it directly worked, without copying the .dll
in some other places.

Maybe it can help some people. 

Have a nice day,
Ptit Bleu.
-- 
View this message in context: http://www.nabble.com/I-can%27t-do-it-again-on-an-other-PC-%3A-R%2BRMySQL--%3Eerror-loading-dll-tf4414597.html#a12610089
Sent from the R help mailing list archive at Nabble.com.


From wl2776 at gmail.com  Tue Sep 11 10:23:17 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Tue, 11 Sep 2007 01:23:17 -0700 (PDT)
Subject: [R] finding the minimum positive value of some data
In-Reply-To: <12599319.post@talk.nabble.com>
References: <12599319.post@talk.nabble.com>
Message-ID: <12610228.post@talk.nabble.com>


min(x[x>0])


dxc13 wrote:
> 
> useRs,
> 
> I am looking to find the minimum positive value of some data I have. 
> Currently, I am able to find the minimum of data after I apply some other
> functions to it:
> 
>> x
>  [1]  1  0  1  2  3  3  4  5  5  5  6  7  8  8  9  9 10 10
> 
>> sort(x)
>  [1]  0  1  1  2  3  3  4  5  5  5  6  7  8  8  9  9 10 10
> 
>> diff(sort(x))
>  [1] 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 1 0
> 
>> min(diff(sort(x)))
> [1] 0
> 
> The minimum is given as zero, which is clearly true, but I am interested
> in only the positive minimum, which is 1.  Can I find this by using only 1
> line of code, like I have above? Thanks!
> 
> dxc13
> 

-- 
View this message in context: http://www.nabble.com/finding-the-minimum-positive-value-of-some-data-tf4417250.html#a12610228
Sent from the R help mailing list archive at Nabble.com.


From P.Dalgaard at biostat.ku.dk  Tue Sep 11 10:41:23 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 11 Sep 2007 10:41:23 +0200
Subject: [R] [solved] Re: I can't do it again on an other PC : R+RMySQL
 ->error loading dll
In-Reply-To: <12610089.post@talk.nabble.com>
References: <12592576.post@talk.nabble.com> <12610089.post@talk.nabble.com>
Message-ID: <46E654B3.5060103@biostat.ku.dk>

Ptit_Bleu wrote:
> Hi,
>
> just to say that I "solved" my problem. I wrote "solved" because all I did
> was to uninstall R and the DBI and RMySQL libraries and then install
> everything again.
> The only change is that I used another RMySQL.zip file found at this address
> :
> http://www.bioconductor.org/packages/2.0/extra/bin/windows/contrib/2.5/RMySQL_0.6-0.zip
> (the file is much bigger than the one I used on my PC : 1064 Mo instead of
> 383 Mo).
>
>   
Umm, that looks more than a bit unofficial (parent directory read
protected, no hint of an RMySQL package elsewhere on the site).  Are you
sure that this is intended for redistribution? It sounds like it bundles
in some MySQL libraries, which could imply legal issues.

> I installed the DBI and the RMySQL packages from R (intallation from .zip
> file).
> I typed "library(RMySQL)" and it directly worked, without copying the .dll
> in some other places.
>
> Maybe it can help some people. 
>
> Have a nice day,
> Ptit Bleu.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From john.seers at bbsrc.ac.uk  Tue Sep 11 10:45:53 2007
From: john.seers at bbsrc.ac.uk (john seers (IFR))
Date: Tue, 11 Sep 2007 09:45:53 +0100
Subject: [R] install packages automatically
In-Reply-To: <1115a2b00709101844q601ccf4agf00e4cab73be1995@mail.gmail.com>
References: <1115a2b00709101844q601ccf4agf00e4cab73be1995@mail.gmail.com>
Message-ID: <AAD49F46EAE3F6479E1D46428FAC31CB02516172@NBIE2KSRV1.nbi.bbsrc.ac.uk>

 


Hi 

I use the following method which works well for me.

I create a directory to hold the installed packages e.g. C:\Program
Files\R\mylibrary

Then in my C:\Program Files\R\R-2.5.1\.Renviron file I have a line as
follows:

R_LIBS=C:/PROGRA~1/R/mylibrary

(I think you have to use Windows short names in this file.)

Thus whenever I install a new package it is installed in this directory.
If I install a new version of R just update the .Renviron file and run
Packages->Update packages ...

This keeps the R base packages separate from the optional packages.

JS


 
---
-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Wensui Liu
Sent: 11 September 2007 02:45
To: r-help at stat.math.ethz.ch
Subject: [R] install packages automatically

Dear Listers,
I am a little tired of installing all packages I want every time when I
instill a new version of R.
Say, if I have a list of packages I need to use, is it possible to tell
R to install them all for me automatically rather than I install them
one by one?
Thx.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From xh.along at gmail.com  Tue Sep 11 10:48:28 2007
From: xh.along at gmail.com (Tony zeng)
Date: Tue, 11 Sep 2007 16:48:28 +0800
Subject: [R] Multiple contrast of ANOVA
Message-ID: <21add9100709110148h5265b81cw780b6f02bba342e2@mail.gmail.com>

Hi,all guy,
        I am doing ANOVA of some data with one factor,and the result
shows  factor's effect is not significant,but through some plots ,I
know maybe some levels of the factor is significant,so I need to do
multiple contrast to tell me which levels ,What I can do?
     thanks a lot!


From wl2776 at gmail.com  Tue Sep 11 11:10:23 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Tue, 11 Sep 2007 02:10:23 -0700 (PDT)
Subject: [R] install packages automatically
In-Reply-To: <AAD49F46EAE3F6479E1D46428FAC31CB02516172@NBIE2KSRV1.nbi.bbsrc.ac.uk>
References: <1115a2b00709101844q601ccf4agf00e4cab73be1995@mail.gmail.com>
	<AAD49F46EAE3F6479E1D46428FAC31CB02516172@NBIE2KSRV1.nbi.bbsrc.ac.uk>
Message-ID: <12610798.post@talk.nabble.com>


I think using R_LIBS_USER is better.

>From ?.libPaths:

The library search path is initialized at startup from the environment
variable R_LIBS (which 
should be a semicolon-separated list of directories at which R library trees
are rooted) followed by those in environment variable R_LIBS_USER.


john seers (IFR) wrote:
> 
> I use the following method which works well for me.
> 
> I create a directory to hold the installed packages e.g. C:\Program
> Files\R\mylibrary
> 
> Then in my C:\Program Files\R\R-2.5.1\.Renviron file I have a line as
> follows:
> 
> R_LIBS=C:/PROGRA~1/R/mylibrary
> 
> (I think you have to use Windows short names in this file.)
> 
> Thus whenever I install a new package it is installed in this directory.
> If I install a new version of R just update the .Renviron file and run
> Packages->Update packages ...
> 
> This keeps the R base packages separate from the optional packages.
> JS
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> Subject: [R] install packages automatically
> 
> Dear Listers,
> I am a little tired of installing all packages I want every time when I
> instill a new version of R.
> Say, if I have a list of packages I need to use, is it possible to tell
> R to install them all for me automatically rather than I install them
> one by one?
> Thx.
> 
> 

-- 
View this message in context: http://www.nabble.com/install-packages-automatically-tf4419780.html#a12610798
Sent from the R help mailing list archive at Nabble.com.


From ptit_bleu at yahoo.fr  Tue Sep 11 11:23:50 2007
From: ptit_bleu at yahoo.fr (Ptit_Bleu)
Date: Tue, 11 Sep 2007 02:23:50 -0700 (PDT)
Subject: [R] [solved] Re: I can't do it again on an other PC : R+RMySQL
 ->error loading dll
In-Reply-To: <46E654B3.5060103@biostat.ku.dk>
References: <12592576.post@talk.nabble.com> <12610089.post@talk.nabble.com>
	<46E654B3.5060103@biostat.ku.dk>
Message-ID: <12610981.post@talk.nabble.com>


Hi Peter,

I really have no idea about your comment. I was so happy to be able to
connect to my database ... 

In fact I found the address in the following post :
https://stat.ethz.ch/pipermail/r-help/2007-August/138142.html

Do you think I can't use it freely ? :(

Thanks for your comments,
Ptit Bleu.

Umm, that looks more than a bit unofficial (parent directory read
protected, no hint of an RMySQL package elsewhere on the site).  Are you
sure that this is intended for redistribution? It sounds like it bundles
in some MySQL libraries, which could imply legal issues.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



-- 
View this message in context: http://www.nabble.com/I-can%27t-do-it-again-on-an-other-PC-%3A-R%2BRMySQL--%3Eerror-loading-dll-tf4414597.html#a12610981
Sent from the R help mailing list archive at Nabble.com.


From wl2776 at gmail.com  Tue Sep 11 11:34:43 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Tue, 11 Sep 2007 02:34:43 -0700 (PDT)
Subject: [R] [solved] Re: I can't do it again on an other PC : R+RMySQL
 ->error loading dll
In-Reply-To: <12610981.post@talk.nabble.com>
References: <12592576.post@talk.nabble.com> <12610089.post@talk.nabble.com>
	<46E654B3.5060103@biostat.ku.dk> <12610981.post@talk.nabble.com>
Message-ID: <12611132.post@talk.nabble.com>


Do you need precisely RMySQL and DBI? 
RODBC can successfully replace this.

I used RMySQL some time ago, but then, after the next version upgrade it
stopped working.

Switching to RODBC was almost without pain, since function names were quite
similar.
I simply replaced dbGetQuery with sqlGetQuery in my script and voilia.

However, you need to install the MySQL ODBC driver and set up a data source
in the Windows Control Panel before.


Ptit_Bleu wrote:
> 
> 
> I really have no idea about your comment. I was so happy to be able to
> connect to my database ... 
> 
> In fact I found the address in the following post :
> https://stat.ethz.ch/pipermail/r-help/2007-August/138142.html
> 
> Do you think I can't use it freely ? :(
> 
> Thanks for your comments,
> Ptit Bleu.
> 
> 
> Peter Dalgaard wrote:
>> 
>> 
>> Umm, that looks more than a bit unofficial (parent directory read
>> protected, no hint of an RMySQL package elsewhere on the site).  Are you
>> sure that this is intended for redistribution? It sounds like it bundles
>> in some MySQL libraries, which could imply legal issues.
>> 
>> 
> 
> 

-- 
View this message in context: http://www.nabble.com/I-can%27t-do-it-again-on-an-other-PC-%3A-R%2BRMySQL--%3Eerror-loading-dll-tf4414597.html#a12611132
Sent from the R help mailing list archive at Nabble.com.


From phhs80 at gmail.com  Tue Sep 11 11:38:19 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Tue, 11 Sep 2007 10:38:19 +0100
Subject: [R] Inferences for ratios of non-normal means
Message-ID: <6ade6f6c0709110238h4aa99089w7ec65e850186bc49@mail.gmail.com>

Dear All,

The package mratios can perform inferences for ratios of normal means.
Is there some other package to do the same but with non-normal
populations. Since I have got large samples, an asymptotic procedure
would be fine.

Thanks in advance,

Paul


From P.Dalgaard at biostat.ku.dk  Tue Sep 11 11:53:20 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 11 Sep 2007 11:53:20 +0200
Subject: [R] [solved] Re: I can't do it again on an other PC : R+RMySQL
 ->error loading dll
In-Reply-To: <12610981.post@talk.nabble.com>
References: <12592576.post@talk.nabble.com>
	<12610089.post@talk.nabble.com>	<46E654B3.5060103@biostat.ku.dk>
	<12610981.post@talk.nabble.com>
Message-ID: <46E66590.6000305@biostat.ku.dk>

Ptit_Bleu wrote:
> Hi Peter,
>
> I really have no idea about your comment. I was so happy to be able to
> connect to my database ... 
>
> In fact I found the address in the following post :
> https://stat.ethz.ch/pipermail/r-help/2007-August/138142.html
>
> Do you think I can't use it freely ? :(
>   
I don't think anyone is going to send the police.

We do need to be a bit careful about these matters, though. E.g. I
communicate with my publisher using HTTP sometimes. That doesn't mean
that it is allowed to download the book manuscript for free if you can
guess the URL....
> Thanks for your comments,
> Ptit Bleu.
>
> Umm, that looks more than a bit unofficial (parent directory read
> protected, no hint of an RMySQL package elsewhere on the site).  Are you
> sure that this is intended for redistribution? It sounds like it bundles
> in some MySQL libraries, which could imply legal issues.
>
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Fredrik.X.Nilsson at skane.se  Tue Sep 11 12:18:32 2007
From: Fredrik.X.Nilsson at skane.se (Nilsson Fredrik X)
Date: Tue, 11 Sep 2007 12:18:32 +0200
Subject: [R] question about non-linear least squares in R
In-Reply-To: <OF6275C231.7181615D-ON8625734D.0058BDA1-8625734D.005A1E51@mmm.com>
Message-ID: <87A0C64299B27148B40BE0DB83EDE2DBE36E4B@RSMAIL002.REG.SKANE.SE>

Dear Warren,

I had similar problems, this is (roughly) how I solved it translated to your problem:
x <- c(-0.06,-0.04,-0.025,-0.015,-0.005,0.005,0.015,0.025,0.04,0.06)

y <- c(1866760,1457870,1314960,1250560,1184850,1144920,
       1158850,1199910,1263850,1452520)

dafa<-data.frame(x,y)
plot(x,y)

foqufu<-function(parm)
{
const<-parm[1]
A<-parm[2]
B<-parm[3]
MA<-parm[4]

d<-y-(const + A*(x-MA)^4 + B*(x-MA)^2)
d<-d%*%d
return(d)
}

# This is your initial guess
aaa<-c(10000000, 100000000, -1000000, 0)
# As already pointed out, you have a bad initial guess.


apa3<-optim(aaa, foqufu, control=list(maxit=20000, reltol=1e-16))
apa3<-optim(apa3$par, foqufu, control=list(maxit=20000, reltol=1e-16))
apa3<-optim(apa3$par, foqufu, control=list(maxit=20000, reltol=1e-16))
apa3<-optim(apa3$par, foqufu, control=list(maxit=20000, reltol=1e-16))
# I do this a couple of times until convergence
apa3<-optim(apa3$par, foqufu, control=list(maxit=20000, reltol=1e-10))

fitOup<- nls(y ~ constant + A*(x-MA)^4 + B*(x-MA)^2, data=dafa,
  start=list(constant= 4.911826e+06, A=2.625077e+08, B=-6.278897e+07, MA=3.538064e-01), 
  control=nls.control(maxiter=100, minFactor=1/4096), trace=TRUE)


Note that due to your bad initial guess on parameters you end up in a local not global minimum which is the trouble with nonlinear optimization. A way out would perhaps be to randomize your initial guesses.

Andy's way of getting the initial values is better in that respect. NOTE that he searches for the quadratic first (downplaying the importance of the quartic term) But technically I don't understand the  need to scale your y's, in this case you get the same.
 
Another way of finding some intial values is to solve (const + B*MA^2 = intercept, -2*B*MA = coefficient of x, B = coefficient of x^2 in the J2.lm fit below; assuming that J2.lm (below has been fit):
B<-as.numeric(coef(J2.lm)[3])
A<-0
MA<-as.numeric(coef(J2.lm)[2])/2/B
const<- as.numeric(coef(J2.lm)[1])-B*MA^2

bbb<-c(const, 0, B, MA)
apa3<-optim(bbb, foqufu, control=list(maxit=20000, reltol=1e-16))
#iterating a couple of times
apa3<-optim(apa3$par, foqufu, control=list(maxit=20000, reltol=1e-16))
#gives the same solution as Andy's
).
#variation of Andy's solution (no scaling of y)
J2.lm<-lm(y~1 + x + I(x^2), data=dafa)
summary(J2.lm)

plot(xx, predict(J2.lm, ydf))
xx[which.min(predict(J2.lm, ydf))]
Ja2.lm<-lm(y~1 + I((x-0.01)^2), data=dafa)
summary(Ja2.lm)
plot(x,y)
points(x, predict(Ja2.lm, data=data.frame(x=x-0.01, y=y)), col="red")

apa <-optim(c(1146530, 0,139144223, 0.01), foqufu, control=list(maxit=20000, reltol=1e-10))

fitOup3b<- nls(y ~ constant + A*(x-MA)^4 + B*(x-MA)^2, data=dafa,
  start=list(constant= apa$par[1], A=apa$par[2], B= apa$par[3], MA=apa$par[4]),
  control=nls.control(maxiter=100, minFactor=1/4096), trace=TRUE)
# this is exactly the same solution as Andy's, except that the residuals are 
# 1e12 larger and A,B, const are 1e6 larger (due to the scaling).


BUT, and this is a big BUT, why on earth do you choose this functional form? First, the plot(x,y) suggest to my eyes that the function is not symmetric around its centre. Second, if you're not particularly interested in finding a value for MA (i.e. it can be considered as a constant) why not use a simple linear regression with a polynomial? What I mean here is that if:

y = a + b*(x-c)^2 + d*(x-c)^4 + epsilon
(and no variability in c) then
y = (a + b*c^2 + d*c^4) + (-2*b*c - 4*d*c^3)*x + 
    (d + b*6*c^2)*x^2   - (4*d*c)*x^3 + d*x^4 + epsilon

So in fact you could do:
A.lm<-lm(y ~ poly(x,4), data=dafa)
Summary(A.lm)
# suggests that fourth order not necessary
B.lm<-lm(y ~ poly(x,3), data=dafa).
anova(B.lm, A.lm)

# note that this suggest that your problem has an asymmetry that  
# should be accounted for (unless you have very strong reasons for choosing 
# your particular model formulation).  

Third, and this is a more critical question (which I hope that the experts on nls/R gurus would comment on how to solve) I think it is problematic to have variability in LOCATION such as your shift variable (MA). It seems to introduce all sorts of nastiness, which ought to be particularly severe in non-linear regression.

Best regards,
Fredrik 

-----Ursprungligt meddelande-----
Fr?n: apjaworski at mmm.com [mailto:apjaworski at mmm.com] 
Skickat: den 5 september 2007 18:24
Till: Yu (Warren) Wang
Kopia: r-help at stat.math.ethz.ch; r-help-bounces at stat.math.ethz.ch
?mne: Re: [R] question about non-linear least squares in R

Here is one way of getting a reasonable fit:

1.  Scale your y's by dividing all values by 1e6.
2.  Plot x vs. y.  The plot looks like a quadratic function.
3.  Fit a quadratic const. + B*x^2 - this a linear regression problem so
use lm.
4.  Plot the predictions.
5.  Eyball the necessary shift - MA is around 0.01.  Refit const. +
B*(x-.01)^2.  Should get const.=1.147 and B=139.144
6.  Use start=list(const.= 1.147, A=0, B=1.147, MA=.01).  nls should
converge in 4 iterations.

In general, good starting points may be crucial to nls convergence.
Scaling the y's to reasonable values also helps.

Hope this helps,

Andy

__________________________________
Andy Jaworski
518-1-01
Process Laboratory
3M Corporate Research Laboratory
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


                                                                           
             "Yu (Warren)                                                  
             Wang"                                                         
             <yu.wang at pdf.com>                                          To 
             Sent by:                  "r-help at stat.math.ethz.ch"          
             r-help-bounces at st         <r-help at stat.math.ethz.ch>          
             at.math.ethz.ch                                            cc 
                                                                           
                                                                   Subject 
             09/05/2007 02:51          [R] question about non-linear least 
             AM                        squares in R                        
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           




Hi, everyone,
    My question is: It's not every time that you can get a converged
result from the nls function. Is there any solution for me to get a
reasonable result? For example:

x <- c(-0.06,-0.04,-0.025,-0.015,-0.005,0.005,0.015,0.025,0.04,0.06)

y <-
c(1866760,1457870,1314960,1250560,1184850,1144920,1158850,1199910,1263850,1452520)


fitOup<- nls(y ~ constant + A*(x-MA)^4 + B*(x-MA)^2,
start=list(constant=10000000, A=100000000, B=-1000000, MA=0),
control=nls.control(maxiter=100, minFactor=1/4096), trace=TRUE)



 For this one, I cannot get the converged result, how can I reach it? To
use another funtion or to modify some settings for nls?

Thank you very much!

Yours,

Warren

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From arun.kumar.saha at gmail.com  Tue Sep 11 12:36:04 2007
From: arun.kumar.saha at gmail.com (Arun Kumar Saha)
Date: Tue, 11 Sep 2007 16:06:04 +0530
Subject: [R] Function to get a sequence of months
Message-ID: <d4c57560709110336r2854c373kb4fb82b73f457f08@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070911/dda09a7f/attachment.pl 

From gustaf.rydevik at gmail.com  Tue Sep 11 12:46:53 2007
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Tue, 11 Sep 2007 12:46:53 +0200
Subject: [R] [solved] Re: I can't do it again on an other PC : R+RMySQL
	->error loading dll
In-Reply-To: <46E66590.6000305@biostat.ku.dk>
References: <12592576.post@talk.nabble.com> <12610089.post@talk.nabble.com>
	<46E654B3.5060103@biostat.ku.dk> <12610981.post@talk.nabble.com>
	<46E66590.6000305@biostat.ku.dk>
Message-ID: <45f568c70709110346u4be96239mb6921240d48d6a05@mail.gmail.com>

On 9/11/07, Peter Dalgaard <P.Dalgaard at biostat.ku.dk> wrote:
> Ptit_Bleu wrote:
> > Hi Peter,
> >
> > I really have no idea about your comment. I was so happy to be able to
> > connect to my database ...
> >
> > In fact I found the address in the following post :
> > https://stat.ethz.ch/pipermail/r-help/2007-August/138142.html
> >
> > Do you think I can't use it freely ? :(
> >
> I don't think anyone is going to send the police.
>
> We do need to be a bit careful about these matters, though. E.g. I
> communicate with my publisher using HTTP sometimes. That doesn't mean
> that it is allowed to download the book manuscript for free if you can
> guess the URL....


Actually, there was a case in Sweden a couple of years back, where a
reporter managed to access an anual report for a company, a couple of
days before the report became public.
He managed this by guessing url:s.

The reporter got sued, and the court ruled that accessing material,
private or not, by typing in url's is not illegal. Meaning that I
would be allowed to download your book manuscript if I happened to
stumble on the web adress. If the adress was not protected of course.

/Gustaf

-- 
Gustaf Rydevik, M.Sci.
tel: +46(0)703 051 451
address:Essingetorget 40,112 66 Stockholm, SE
skype:gustaf_rydevik


From p_connolly at ihug.co.nz  Tue Sep 11 12:48:34 2007
From: p_connolly at ihug.co.nz (Patrick Connolly)
Date: Tue, 11 Sep 2007 22:48:34 +1200
Subject: [R] off-topic: better OS for statistical computing
In-Reply-To: <971536df0709101626g3b1b6d5dvb4a3e1155b9c192@mail.gmail.com>
References: <1115a2b00709100922h7780644brc59e3f9c25760caf@mail.gmail.com>
	<971536df0709100926r4ac598ffj5b892472531d18ad@mail.gmail.com>
	<20070910200658.GA7176@ihug.co.nz>
	<971536df0709101626g3b1b6d5dvb4a3e1155b9c192@mail.gmail.com>
Message-ID: <20070911104834.GB7176@ihug.co.nz>

On Mon, 10-Sep-2007 at 07:26PM -0400, Gabor Grothendieck wrote:

|> My sense is that R users are even split between UNIX and Windows
|> users so either will do in terms of the larger community.
|> 
|> Some R packages may not be avaliable on every platform or will
|> be available on one platform before another or there will be
|> certain platform-specific issues.  So in the end its easiest to
|> have the same thing everyone else that you work with does.

That sounds like a reason to have *more than* one.  If you burn
bridges to one OS, there'll be cabability you're shutting yourself off
from.  If the idea of uniformity is one of equally disadvantage, I
suppose you're right.

It's attractive for administrators to have as little diversity as
possibile because it makes their job easier.  Imagine what it would be
like if statisticians wielded power and required all data to be in a
form that they could analyse using a simple anova.  Clients would have
their nice little anova tables with LSDs so they could tell what was
significantly different from others.  No need to learn how to read a
different type of output.  Nice and simple.

It's not an approach I would go along with.  It would make the
statistician's jobs easier -- though it would also be very boring.
Then there would be the effect on those who had reason to use very
different data structures....

[...]

|> Also associated software may be, for example, Microsoft Office in a
|> Microsoft environment and LaTeX in a UNIX environment. And
|> networking will be simplified in a consistent environment too.
|> Certainly there is Open Office, Samba and putty but the easiest is
|> just not to have to worry about getting everything to work together
|> by just having the same thing in the first place.

This is the Anova Everything approach again.  


|> 
|> Neither Linux nor Windows is superior to the other.  People
|> making such representations generally know one much better
|> than the other and its more a reflection of their own experience
|> than anything else.  

That's an interesting observation.  My experience is very different.
Nearly everyone I know who knows how to use Linux also knows more
about Windows than most people who've only ever used Windows.  (I wish
I had a dollar for every Windows user I've shown how to change the
vertical refresh rate on their monitor.)

[....]

There are organisations for whom Macintoshes are best; for some it's
Windows; for others it's Linux or Unix.  Those with a variety of
activity do themselves a favour by having multiple platforms.  The
extra effort put into their computer services people pays off in
productivity (if they're interested).

I would venture to say that many users of R would be involved in that
type of organisation.  The original poster might be in that position.
My comment was to help counter claims given for the purported need for
hegemony.

One of the many great things about R is it's cross-platform
capabilities.  That wasn't achieved using a monolithic approach to
software.



-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}          		 Great minds discuss ideas    
 _( Y )_  	  	        Middle minds discuss events 
(:_~*~_:) 	       		 Small minds discuss people  
 (_)-(_)  	                           ..... Anon
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From murdoch at stats.uwo.ca  Tue Sep 11 12:49:22 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 11 Sep 2007 06:49:22 -0400
Subject: [R] Function to get a sequence of months
In-Reply-To: <d4c57560709110336r2854c373kb4fb82b73f457f08@mail.gmail.com>
References: <d4c57560709110336r2854c373kb4fb82b73f457f08@mail.gmail.com>
Message-ID: <46E672B2.8020604@stats.uwo.ca>

On 11/09/2007 6:36 AM, Arun Kumar Saha wrote:
> Hi all,
> 
> I am looking for a function for following calculation.
> 
> start.month = "July"
> end.month = "January"
> 
> months = f(start.month, end.month, by=1)
> 
> * f is the function that I am looking for.
> 
> Actually I want to get months = c("July", "August",.............."January")
> 
> If start.month = 6 and end.month = 1 then I could use (not properly) seq()
> function and then I would get month as a vector with elements 6,5,4,3,2, and
> 1 by choosing "by=-1". Is there any function which can subsitute the seq()
> function in my case?

I don't think one already exists, but it's easy to write one:

 > cyclic_seq <- function(from, to, cycle=12) {
+     if (to < from) (from - 1):(to + cycle - 1) %% cycle + 1
+     else from:to
+ }
 > cyclic_seq(5, 1)
[1]  5  6  7  8  9 10 11 12  1
 > cyclic_seq(5, 5)
[1] 5
 > cyclic_seq(5, 6)
[1] 5 6

This makes various assumptions about the inputs (e.g. it would fail on 
cyclic_seq(20, 1) ); you might want to validate the inputs if you're 
giving it to other people.

Duncan Murdoch


From wl2776 at gmail.com  Tue Sep 11 13:10:04 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Tue, 11 Sep 2007 04:10:04 -0700 (PDT)
Subject: [R] Function to get a sequence of months
In-Reply-To: <46E672B2.8020604@stats.uwo.ca>
References: <d4c57560709110336r2854c373kb4fb82b73f457f08@mail.gmail.com>
	<46E672B2.8020604@stats.uwo.ca>
Message-ID: <12612421.post@talk.nabble.com>



Duncan Murdoch-2 wrote:
> 
> On 11/09/2007 6:36 AM, Arun Kumar Saha wrote:
>> Hi all,
>> 
>> I am looking for a function for following calculation.
>> 
>> start.month = "July"
>> end.month = "January"
>> 
>> months = f(start.month, end.month, by=1)
>> 
>> * f is the function that I am looking for.
>> 
>> Actually I want to get months = c("July",
>> "August",.............."January")
>> 
>> If start.month = 6 and end.month = 1 then I could use (not properly)
>> seq()
>> function and then I would get month as a vector with elements 6,5,4,3,2,
>> and
>> 1 by choosing "by=-1". Is there any function which can subsitute the
>> seq()
>> function in my case?
> 
> I don't think one already exists, but it's easy to write one:
> 
>  > cyclic_seq <- function(from, to, cycle=12) {
> +     if (to < from) (from - 1):(to + cycle - 1) %% cycle + 1
> +     else from:to
> + }
>  > cyclic_seq(5, 1)
> [1]  5  6  7  8  9 10 11 12  1
>  > cyclic_seq(5, 5)
> [1] 5
>  > cyclic_seq(5, 6)
> [1] 5 6
> 
> This makes various assumptions about the inputs (e.g. it would fail on 
> cyclic_seq(20, 1) ); you might want to validate the inputs if you're 
> giving it to other people.
> 
> Duncan Murdoch
> 

And the rest would be to use month.name or month.abb variables

month.name[cyclic_seq(7,1)]
-- 
View this message in context: http://www.nabble.com/Function-to-get-a-sequence-of-months-tf4421709.html#a12612421
Sent from the R help mailing list archive at Nabble.com.


From john.seers at bbsrc.ac.uk  Tue Sep 11 13:48:08 2007
From: john.seers at bbsrc.ac.uk (john seers (IFR))
Date: Tue, 11 Sep 2007 12:48:08 +0100
Subject: [R] install packages automatically
In-Reply-To: <12610798.post@talk.nabble.com>
References: <1115a2b00709101844q601ccf4agf00e4cab73be1995@mail.gmail.com><AAD49F46EAE3F6479E1D46428FAC31CB02516172@NBIE2KSRV1.nbi.bbsrc.ac.uk>
	<12610798.post@talk.nabble.com>
Message-ID: <AAD49F46EAE3F6479E1D46428FAC31CB0251618C@NBIE2KSRV1.nbi.bbsrc.ac.uk>

 
Hi Vladimir

You may well be right and it is better, or at least better practice. But
I have a feeling I tried it and it was not as successful, but I cannot
remember why. Perhaps it was because when installing new packages they
were not installed in that (USER) directory? 

JS

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Vladimir Eremeev
Sent: 11 September 2007 10:10
To: r-help at stat.math.ethz.ch
Subject: Re: [R] install packages automatically


I think using R_LIBS_USER is better.

>From ?.libPaths:

The library search path is initialized at startup from the environment
variable R_LIBS (which should be a semicolon-separated list of
directories at which R library trees are rooted) followed by those in
environment variable R_LIBS_USER.


john seers (IFR) wrote:
> 
> I use the following method which works well for me.
> 
> I create a directory to hold the installed packages e.g. C:\Program
> Files\R\mylibrary
> 
> Then in my C:\Program Files\R\R-2.5.1\.Renviron file I have a line as
> follows:
> 
> R_LIBS=C:/PROGRA~1/R/mylibrary
> 
> (I think you have to use Windows short names in this file.)
> 
> Thus whenever I install a new package it is installed in this
directory.
> If I install a new version of R just update the .Renviron file and run
> Packages->Update packages ...
> 
> This keeps the R base packages separate from the optional packages.
> JS
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> Subject: [R] install packages automatically
> 
> Dear Listers,
> I am a little tired of installing all packages I want every time when
I
> instill a new version of R.
> Say, if I have a list of packages I need to use, is it possible to
tell
> R to install them all for me automatically rather than I install them
> one by one?
> Thx.
> 
> 

-- 
View this message in context:
http://www.nabble.com/install-packages-automatically-tf4419780.html#a126
10798
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Tue Sep 11 14:08:28 2007
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 11 Sep 2007 08:08:28 -0400 (EDT)
Subject: [R] Multiple contrast of ANOVA
Message-ID: <20070911080828.CMF56295@po-d.temple.edu>

Download the multcomp package for multiple comparisons.
You might also want to use the MMC functions in the HH package
to display the contrasts.


From ggrothendieck at gmail.com  Tue Sep 11 14:25:49 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 11 Sep 2007 08:25:49 -0400
Subject: [R] Function to get a sequence of months
In-Reply-To: <d4c57560709110336r2854c373kb4fb82b73f457f08@mail.gmail.com>
References: <d4c57560709110336r2854c373kb4fb82b73f457f08@mail.gmail.com>
Message-ID: <971536df0709110525l28f80f39r7e4b8fac20f4d758@mail.gmail.com>

Here is a solution using character manipulation.  Noting that month.name
is built into R we paste together the character string:
"January Februrary ... December January ... December"
Then we use perl style ungreedy matching to get the shortest substring
matching the indicated expression then splitting it back apart and taking
the first match:

library(gsubfn)
strapply(paste(rep(month.name, 2), collapse = " "), "July.*?January",
  ~ strsplit(x, split = " "), perl = TRUE, simplify = c)[[1]]


Here is the result of running it:
> library(gsubfn)
> strapply(paste(rep(month.name, 2), collapse = " "), "July.*?January",
+   ~ strsplit(x, split = " "), perl = TRUE, simplify = c)[[1]]
[1] "July"      "August"    "September" "October"   "November"
"December"  "January"


mn2 <- c(month.name, month.name)
strapply(paste(mn2, "July.*January", ~ strsplit(x, split = " "),
simplify = unlist)

On 9/11/07, Arun Kumar Saha <arun.kumar.saha at gmail.com> wrote:
> Hi all,
>
> I am looking for a function for following calculation.
>
> start.month = "July"
> end.month = "January"
>
> months = f(start.month, end.month, by=1)
>
> * f is the function that I am looking for.
>
> Actually I want to get months = c("July", "August",.............."January")
>
> If start.month = 6 and end.month = 1 then I could use (not properly) seq()
> function and then I would get month as a vector with elements 6,5,4,3,2, and
> 1 by choosing "by=-1". Is there any function which can subsitute the seq()
> function in my case?
>
> Regards,
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gilbertoinuk at googlemail.com  Tue Sep 11 14:30:36 2007
From: gilbertoinuk at googlemail.com (Gilbert G)
Date: Tue, 11 Sep 2007 13:30:36 +0100
Subject: [R] how to run a mixed design ANOVA with repeated measures
Message-ID: <e4bd9ca80709110530u7367e711g6034d21ee899219d@mail.gmail.com>

Hi, I would like to run an ANOVA with repeated measures with both a
between subjects variable and within subjects (repeated measures)
variables.  I know how to do this when I have equal numbers of
subjects in both groups (i.e., balanced design).  That has been very
well documented by Baron, for example, see:

http://cran.r-project.org/doc/contrib/Baron-rpsych.pdf

On page 34 of this document, section 6.8.5, Baron & Li example
wonderfully how to run a 'balanced' ANOVA with one between  and two
within subject varialbes (6.8.5 Example 5: Stevens pp. 468 ? 474 (one
between, two within)).

The R code in their example is:

summary(aov(effect  ? gp * drug * dose + Error(subj/(dose+drug)), data=Ela.uni))

The between subjects variable is gp, whereas drug and dose are within
subject variables.

Now, my question is, how would I do this very same analysis if there
were *different* numbers of subjects in the groups (that is,
'unbalanced')?  Clearly, the 'aov' function is not appropriate for
this!   (help(aov) says: 'aov' is designed for balanced designs, and
the results can be hard to interpret without balance)

I have found suggestions that this problem might be solved with the
'lme' function of the 'nlme' library, but it is entirely unclear to me
how and I could not find an answer anywhere in the r forums.

Thank you so much for your help.


From shukai at seas.upenn.edu  Tue Sep 11 14:54:49 2007
From: shukai at seas.upenn.edu (kevinchang)
Date: Tue, 11 Sep 2007 05:54:49 -0700 (PDT)
Subject: [R] alternative way to loop
Message-ID: <12613696.post@talk.nabble.com>


I heard that if-loop may result in errors if we are going to loop for a lot
of times. And sum() can be the alternative way to do this kind of  hugbe
looping. But I haven't figure out how . Can someone please give me an
concrete example of using sum() for this purpose? 
-- 
View this message in context: http://www.nabble.com/alternative-way-to-loop-tf4422299.html#a12613696
Sent from the R help mailing list archive at Nabble.com.


From jonathan-beard at uiowa.edu  Tue Sep 11 15:11:28 2007
From: jonathan-beard at uiowa.edu (VTLT1999)
Date: Tue, 11 Sep 2007 06:11:28 -0700 (PDT)
Subject: [R] Generating Replicate Datasets (using loops or other means)
In-Reply-To: <708001.89013.qm@web32204.mail.mud.yahoo.com>
References: <12603580.post@talk.nabble.com>
	<708001.89013.qm@web32204.mail.mud.yahoo.com>
Message-ID: <12613901.post@talk.nabble.com>


Hello Moshe,

Replication in this sense means that I want to use the parameters specified
in a1 b1, and c1 to produce a set of simulated responses, coded as a 0 or a
1, and do this many times.  So a1, b1, and c1 do not change, and I would
like to produce 30 different sets of simulated responses, all placed in
their own separate file.  I'm almost to the point of copying and pasting the
code 30 times and then running it, but I would like to believe that there is
a more elegant way to tackle this problem.

Thanks,

Jon



Hi Jonathan,

What exactly do you mean by replication? 
Do you want to keep a1,b1,c1,... unchanged but have 30
different sets of random numbers?

Regards,

Moshe.

--- VTLT1999 <jonathan-beard at uiowa.edu> wrote:

> 
> Hello All,
> 
> I have searched many help forums, message boards,
> etc. and I just can't
> apply the comments to what I need my program to do. 
> I am running R 2.5.1 on
> an XP system, and my desire is to produce replicate
> datasets for a
> simulation study I am running.  Essentially, I have
> sets of parameters (a's,
> b's, and c's) that define a function which produces
> a decimal value.  This
> value is compared to a random uniform value, and is
> coded a 1 if the
> function is greater than the uniform value, 0 if it
> is <= to the uniform
> value.  My code thus far works great, but I just
> need it to run several
> times.    Here we go:
> 
> library(mvtnorm)
> library(sm)
> library(ltm)
> library(irtoys)
> 
> k<- 5000
> set.seed(271828)
> t <-
>
rmvnorm(n=k,mean=c(-1,0,1),sigma=matrix(c(1,.8,.5,.8,1,.8,.5,.8,1),3,3))
> 
>   #Using mv here because of the likely association
> of ability (theta = t)
> across time.
> 
> t1<-as.matrix(t[,1])
> t2<-as.matrix(t[,2])
> t3<-as.matrix(t[,3])
> 
> set.seed(271828)
> 
> #  Population item parameters (n=54)  from which we
> will select relevant
> items
> #  These are the parameters that are used in the
> function
> 
> a <- c(1.18120, 0.92613, 0.96886, 0.80503, 1.12384, 
>        0.84073, 0.85544, 0.86801, 1.01054, 0.82278,
>        1.10353, 0.78865, 0.98421, 1.76071, 0.89603, 
>        0.84671, 0.89737, 0.74775, 0.32190, 0.69730, 
>        0.72059, 1.16762, 1.29257, 1.32902, 0.59540, 
>        0.51022, 0.59259, 0.93951, 0.68568, 0.55649, 
>        0.88084, 0.52940, 0.45735, 0.57560, 1.11779,
>        0.96984, 1.19692, 0.99102, 1.25847, 1.62555, 
>        0.63049, 1.07807, 1.04897, 1.23138, 1.14014, 
>        1.25230, 1.14844, 0.59287, 0.83143, 0.81723,
>        0.52141, 0.61980, 0.49945, 1.02749)
> 
> b <- c(-2.51737, -1.95897, -1.72667, -0.82988,
> -0.36093,
>         0.72554,  0.91442,  0.78061,  0.06088, 
> 0.75733,
>        -0.76371,  0.24552, -0.42050,  0.88232,
> -0.81761,
>         0.06466, -0.43866, -0.46042,  0.21636,
> -0.73147,
>        -1.44086, -1.03718,  0.07275, -0.17197, 
> 1.53796,
>        -0.45631, -1.69826, -0.66506,  0.98921, 
> 0.30714,
>        -0.62245,  0.97253,  1.95894,  0.21277, 
> 1.96346,
>         1.18825,  1.59917, -0.28401, -1.23530,
> -0.09671,
>        -0.31581, -0.66149, -0.81284, -0.35399,
> -0.07623, 
>         1.06442, -0.68559,  1.07591,  0.97458, 
> 0.06436,
>         1.25622,  1.73954,  1.75052,  2.34088)
> 
> c <- c(0.00000, 0.00000, 0.00000, 0.00000, 0.19648,
>        0.31302, 0.26454, 0.19714, 0.06813, 0.21344,
>        0.00000, 0.03371, 0.00000, 0.16581, 0.11054, 
>        0.08756, 0.07115, 0.26892, 0.00000, 0.06883, 
>        0.00000, 0.14815, 0.32389, 0.19616, 0.17597,
>        0.00000, 0.00000, 0.04337, 0.19949, 0.20377, 
>        0.00000, 0.06243, 0.13639, 0.00000, 0.18166,
>        0.15996, 0.20184, 0.08331, 0.24453, 0.26114, 
>        0.16434, 0.20750, 0.32658, 0.31870, 0.45227,
>        0.35039, 0.31178, 0.17999, 0.22774, 0.21675,
>        0.10153, 0.17764, 0.15205, 0.19858)
> 
> #  Item parameters for generating 3PL data for all
> five testing occasions:
> #  This selects the relevant parameters for a
> particular data generation run
> #  Only parameters for the first testing occasion
> are shown to save space
> 
> a1 <- as.matrix(a[c(1:5,15:20,22:24,38:44)])
> b1 <- as.matrix(b[c(1:5,15:20,22:24,38:44)])
> c1 <- as.matrix(c[c(1:5,15:20,22:24,38:44)])
> 
> #  Here is where I would like to begin my
> replications, but don't know how
> to make R do it.
> #  The code below produces a matrix of 0's and 1's
> (which will be used by
> another program)
> #  I would like to nest this in a "do loop" such
> that, say, 30 replicate
> datasets are produced using the 
> #    same parameters. 
>    
>    N <- nrow(t1)     # number of examinees
>    n <- nrow(a1)     # number of items
>    d <- 1.7
>    theta <- t1  
>    response <- matrix (0,N,n)  
>    uni <- matrix (runif(N*n),nrow = N)
> 
>    for (i in 1:N)
>    {
>      for (j in 1:n) 
>      {
>       if (
> c1[j]+(1-c1[j])/(1+exp(-d*a1[j]*(theta[i]-b1[j]))) >
> uni[i,j] )
>          response[i,j] = 1
>        else 
>          response[i,j] = 0
>      }
>    }
> write.table(response, file="C:/responses.dat", sep="
> ",row.names=FALSE,
> col.names=FALSE)  
> 
> I tried earlier nesting this in another for loop,
> but that indexes elements
> of matrices and vectors, and doesn't seem to apply
> to a "global" loop
> methodology.  I am attempting to use replicate as we
> speak, but
> documentation is sparse (help("replicate") is nested
> in lapply information). 
> Any guidance is greatly appreciated.  
> 
> Thanks in advance,
> 
> Jonathan Beard
-- 
View this message in context: http://www.nabble.com/Generating-Replicate-Datasets-%28using-loops-or-other-means%29-tf4418768.html#a12613901
Sent from the R help mailing list archive at Nabble.com.


From murdoch at stats.uwo.ca  Tue Sep 11 15:16:43 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 11 Sep 2007 09:16:43 -0400
Subject: [R] alternative way to loop
In-Reply-To: <12613696.post@talk.nabble.com>
References: <12613696.post@talk.nabble.com>
Message-ID: <46E6953B.8020106@stats.uwo.ca>

On 9/11/2007 8:54 AM, kevinchang wrote:
> I heard that if-loop may result in errors if we are going to loop for a lot
> of times. 

I don't know what you mean by an "if-loop", but if doing it lots of 
times caused an error, that would likely be a bug in R.  And I know of 
no such bug.

 > And sum() can be the alternative way to do this kind of  hugbe
> looping. But I haven't figure out how . Can someone please give me an
> concrete example of using sum() for this purpose? 

total <- sum(1:10)

is a much faster way to evaluate

total <- 0
for (i in 1:10) total <- total + i

but neither one should cause an error (and neither one involves an 
"if-loop").

Duncan Murdoch


From xingwang.ye at gmail.com  Tue Sep 11 15:22:52 2007
From: xingwang.ye at gmail.com (Xingwang Ye)
Date: Tue, 11 Sep 2007 21:22:52 +0800
Subject: [R] why I cannot change the font and use hot-key in Editor of JGR
	1.5-6
Message-ID: <46E696AC.1000506@gmail.com>

Dear R users,
Yesterday, I updated R 2.4.1 to R 2.5.1  on Unbuntu 7.0.4 successfully. 
I also update the JGR to 1.5-6 according to 
http://rosuda.org/JGR/linux.shtml (after "sudo update-java-alternatives 
-s java-6-sun", I cannot do "sudo update-java-alternatives -s 
java-1.6.0-sun"). I can use the JGR console normally.

however, I cannot use hot-key such as "ctrl+r" in the Editor, if I use 
it, the selected contents are replaced by "r", it seems that "ctrl" does 
not act, whereas I can use mouse to click the "run selection ctrl + r" 
in menu.

Another problem is that I can change the font in the console but not in 
the Editor.

Could some one help me to solve them? thank you in advance.

Best wishes

Yours, sincerely,
Xingwang Ye


From Antonio_Paredes at aphis.usda.gov  Tue Sep 11 15:36:22 2007
From: Antonio_Paredes at aphis.usda.gov (Antonio_Paredes at aphis.usda.gov)
Date: Tue, 11 Sep 2007 08:36:22 -0500
Subject: [R] Editor for R under Fedora 7
Message-ID: <OFAA6D4FD5.21B300DC-ON86257353.004A09A7-86257353.004A9D95@aphis.usda.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070911/43031a9b/attachment.pl 

From fmc2+ at pitt.edu  Tue Sep 11 15:13:48 2007
From: fmc2+ at pitt.edu (Fiona Callaghan)
Date: Tue, 11 Sep 2007 09:13:48 -0400 (EDT)
Subject: [R] using bootstrap for tree selection step in rpart
In-Reply-To: <46E62A52.4030505@pointone.de>
References: <1129.141.151.145.62.1189459021.squirrel@webmail.pitt.edu>
	<46E62A52.4030505@pointone.de>
Message-ID: <1074.24.131.194.217.1189516428.squirrel@webmail.pitt.edu>


Hi Chris.  Thanks for replying.  I want to take the pruned list of
subtrees, and select the final tree from this list using a bootstrap
technique (rather than cross validation).   I think, and I could be wrong,
that bagging takes a bunch of bootstrap samples, grows one tree per
boostrap sample and then combines the estimates, but this is not want I
want to do.   I hope this is clearer.  It is difficult to describe these
things with eamil.
Cheers
Fiona
> Fiona Callaghan wrote:
>> I was wondering if someone could help me with an rpart problem.  I can
>> see
>> that cross-validation is the default for tree selection in rpart -- has
>> a
>> bootstrap method been implemented anywhere?  I think this is a different
>> thing to 'bagging' or 'boosting' -- I still want 'one' tree at the end,
>> I
>> just would like it chosen using a bootstrap method.  Any ideas???
>
> Hi Fiona,
>
> I'm not sure if I understand you correctly.
> To get one single rpart tree trained on one bootstrap sample, try
> bagging() from the 'ipred' package and set nbagg=1.
>
> Bye,
> Chris
>
>


-- 
Fiona Callaghan, MA MS
A432 Crabtree Hall
Department of Biostatistics
Graduate School of Public Health
University of Pittsburgh
Phone 412 624 3063


From gferraz29 at gmail.com  Tue Sep 11 15:43:20 2007
From: gferraz29 at gmail.com (=?ISO-8859-1?Q?Gon=E7alo_Ferraz?=)
Date: Tue, 11 Sep 2007 09:43:20 -0400
Subject: [R] storing text and decimal values in a matrix form
Message-ID: <FC8079C7-1165-42E2-AB1D-5BEFE1CD3267@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070911/878c2cd6/attachment.pl 

From magno_yu at ml.com  Tue Sep 11 15:45:35 2007
From: magno_yu at ml.com (yoooooo)
Date: Tue, 11 Sep 2007 06:45:35 -0700 (PDT)
Subject: [R] as.POSIXlt, starting at 0 or 18000?
Message-ID: <12615136.post@talk.nabble.com>


Hi all, 

   I tried to do this: 

unclass(strptime("1970-01-01", "%Y-%m-%d", tz="") + 0)
[1] 18000

    I thought the starting time is zero? Same result returns if I do:

unclass(strptime("1970-01-01", "%Y-%m-%d", tz="EDT") + 0)
unclass(strptime("1970-01-01", "%Y-%m-%d", tz="EST") + 0)
unclass(strptime("1970-01-01", "%Y-%m-%d", tz="GMT") + 0)

    with LC_TIME=en_US;

    Or they always start from 18000? 

Thanks,
- yoooooo

-- 
View this message in context: http://www.nabble.com/as.POSIXlt%2C-starting-at-0-or-18000--tf4422770.html#a12615136
Sent from the R help mailing list archive at Nabble.com.


From petr.pikal at precheza.cz  Tue Sep 11 15:56:47 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Tue, 11 Sep 2007 15:56:47 +0200
Subject: [R] Odp:  storing text and decimal values in a matrix form
In-Reply-To: <FC8079C7-1165-42E2-AB1D-5BEFE1CD3267@gmail.com>
Message-ID: <OFB21D5C71.BC85615C-ONC1257353.004C21D2-C1257353.004C9A47@precheza.cz>

Hi

Although not specifically stated in help page, matrix is a vector with dim 
attribute. Therefore it can have only one type of values either numeric or 
character or logical or factor. So if you want textual and numeric values 
you probably have to stick with data frames.

Regards
Petr
petr.pikal at precheza.cz

r-help-bounces at r-project.org napsal dne 11.09.2007 15:43:20:

> Hi,
> 
> I would like to store some text and decimal values in the following 
> form:
> 
> name   dec.val   dec.val   ...   dec.val
> name   dec.val   dec.val   ...   dec.val
> ...
> name   dec. val    dec.val   ...   dec.val
> 
> To do so, I created a matrix of the necessary size (x row per y cols) 
> with the command
> 
> matrixname <- matrix(0,x,y)
> 
> and proceeded to fill in the matrix with information drawn from a 
> data frame.
> 
> The problem is that the resulting matrix only has integers at the end 
> of the filling process.
> 
> When I ask:
> class(dataframename[i,j])
> The answer is "factor"
> 
> What is the best way of solving the problem. Should I use a data 
> structure other than a matrix? Or should I make the elements be a 
> different class (other than "factor") when I assign them to the matrix?
> 
> Thanks for any help!
> 
> G.
> 
> 
> 
> 
> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Tue Sep 11 16:16:01 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 11 Sep 2007 10:16:01 -0400
Subject: [R] as.POSIXlt, starting at 0 or 18000?
In-Reply-To: <12615136.post@talk.nabble.com>
References: <12615136.post@talk.nabble.com>
Message-ID: <971536df0709110716t4a1415d2ga611be34eb89ed40@mail.gmail.com>

This is what I get:

> unclass(strptime("1970-01-01", "%Y-%m-%d", tz="GMT") + 0)
[1] 0
attr(,"tzone")
[1] "GMT"
> unclass(strptime("1970-01-01", "%Y-%m-%d", tz="EST5EDT") + 0)
[1] 18000
attr(,"tzone")
[1] "EST5EDT"
> R.version.string # Windows Vista
[1] "R version 2.6.0 alpha (2007-09-06 r42791)"

so 1970-01-01 GMT is 0 and 1970-01-01 Eastern corresponds
to a GMT of 18000.

There is an article about dates and times in R News 4/1.

On 9/11/07, yoooooo <magno_yu at ml.com> wrote:
>
> Hi all,
>
>   I tried to do this:
>
> unclass(strptime("1970-01-01", "%Y-%m-%d", tz="") + 0)
> [1] 18000
>
>    I thought the starting time is zero? Same result returns if I do:
>
> unclass(strptime("1970-01-01", "%Y-%m-%d", tz="EDT") + 0)
> unclass(strptime("1970-01-01", "%Y-%m-%d", tz="EST") + 0)
> unclass(strptime("1970-01-01", "%Y-%m-%d", tz="GMT") + 0)
>
>    with LC_TIME=en_US;
>
>    Or they always start from 18000?
>
> Thanks,
> - yoooooo
>
> --
> View this message in context: http://www.nabble.com/as.POSIXlt%2C-starting-at-0-or-18000--tf4422770.html#a12615136
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From phhs80 at gmail.com  Tue Sep 11 16:25:57 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Tue, 11 Sep 2007 15:25:57 +0100
Subject: [R] Editor for R under Fedora 7
In-Reply-To: <OFAA6D4FD5.21B300DC-ON86257353.004A09A7-86257353.004A9D95@aphis.usda.gov>
References: <OFAA6D4FD5.21B300DC-ON86257353.004A09A7-86257353.004A9D95@aphis.usda.gov>
Message-ID: <6ade6f6c0709110725h159ad592h583df9476d2c92b6@mail.gmail.com>

On 9/11/07, Antonio_Paredes at aphis.usda.gov
<Antonio_Paredes at aphis.usda.gov> wrote:
> I wanted to ask what will be a good editor to write R scripts in Fedora 7.

Tell us first what is your operating system.

Paul


From tlumley at u.washington.edu  Tue Sep 11 16:27:29 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 11 Sep 2007 07:27:29 -0700 (PDT)
Subject: [R] Are the error messages of ConstrOptim() consisten with each
 other?
In-Reply-To: <548b8d440709101421o5346f1ccp2ed468d1ffe4a68a@mail.gmail.com>
References: <548b8d440709092358g3cd079cehd459e8592bb9673c@mail.gmail.com>
	<46E51869.9070809@stats.uwo.ca>
	<548b8d440709101421o5346f1ccp2ed468d1ffe4a68a@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709110724450.16909@homer24.u.washington.edu>

On Mon, 10 Sep 2007, Yuchen Luo wrote:

> Dear Professor Murdoch.
> Thank you for your help!
> 1. I believe c(0.5,0.3,0.5) satisfies the constrain because I did the
> following experiment
> ui=-1*ui
> ci=-1*ci
> constrOptim(c(0.5,0.3,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
>
> The same error message pops up. Any theta ( in this case, c(0.5,0.3,0.5))
> cannot violate both ui%*%theta>=ci and -ui%*%theta>=-ci.

Why not?  ui%*%theta>=ci is a six-dimensional constraint in your example, 
so a different element of the constraint can be violated.

 	-thomas



> 2. There is lambda1 available. The 0.3 in c(0.5,0.3,0.5) is lambda1. If you
> plug c(0.5,0.3,0.5) into fit.error and fit.error.grr by
> fit.error(0.5,0.3,0.5)
> fit.error.grr(0.5,0.3,0.5)
> It works.
>
> Best Wishes
> Yuchen Luo
>
>
>
>
> On 9/10/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>
>> Yuchen Luo wrote:
>>> Dear Friends.
>>> I found something very puzzling with constOptim(). When I change the
>>> parameters for ConstrOptim, the error messages do not seem to be
>>> consistent with each other:
>>>
>>>
>>>> constrOptim(c(0.5,0.3,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
>>>>
>>> Error in constrOptim(c(0.5, 0.3, 0.5), f = fit.error, gr = fit.error.grr
>> ,  :
>>>         initial value not feasible
>>>
>> "Not feasible" means it doesn't satisfy the constraints.
>>>> constrOptim(c(0.5,0.9,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
>>>>
>>> Error in constrOptim(c(0.5, 0.9, 0.5), f = fit.error, gr = fit.error.grr
>> ,  :
>>>         initial value not feasible
>>>
>>>> constrOptim(c(0.3,0.5,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
>>>>
>>> Error in f(theta, ...) : argument "lambda1" is missing, with no default
>>>
>>
>> This time your starting values satisfied the constraints, so your
>> objective function was called, but you didn't pass it a value for lambda1.
>>> I only changed the parameters, how come the lambda1 that is not
>>> missing in the first 2 cases suddently become missing?
>>>
>>> For your convenience, I put the complete code below:
>>>
>>> Best Wishes
>>> Yuchen Luo
>>>
>>> ########################################
>>> rm(list = ls())
>>>
>>> mat=5
>>>
>>> rint=c(4.33,4.22,4.27,4.43,4.43,4.44,4.45,4.65,4.77,4.77)
>>> tot=rep(13319.17,10)
>>> sh=rep(1553656,10)
>>> sigmae=c(0.172239074,0.188209271,0.193703774,0.172659891,0.164427247,
>> 0.24602361,0.173555309,0.186701165,0.193150456,
>>> 0.1857315601)
>>> ss=c(56.49,56.39,56.55,57.49,57.37,55.02,56.02,54.35,54.09, 54.67)
>>> orange=rep(21.25,10)
>>>
>>> apple2=expression(rint*(1.0-rec)*(1.0-
>> (pnorm(-lambda/2.0+log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0
>> )/lbar*exp(lambda*lambda)))/lambda)-((ss+(tot/sh*1000.0)*lbar)/(tot/sh*
>> 1000.0)/lbar*exp(lambda*lambda))*pnorm(-lambda/2.0-log(((ss+(tot/sh*1000.0
>> )*lbar)/(tot/sh*1000.0
>> )/lbar*exp(lambda*lambda)))/lambda))+(exp(rint*(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*
>> 1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))*((((ss+(tot/sh*1000.0
>> )*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(sqrt(0.25+2.0*rint/
>> (sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> ))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0
>> )/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))-sqrt(0.25+2.0*rint/
>> (sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> ))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*!
>>>  1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+((ss+(tot/sh*1000.0
>> )*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(-sqrt(0.25+2.0*rint/
>> (sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> ))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0
>> )/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+sqrt(0.25+2.0*rint/
>> (sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> ))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))))-(((ss+(tot/sh*1000.0
>> )*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(sqrt(0.25+2.0*rint/
>> (sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> ))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0
>> )/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*sqrt((lambda*lam!
>>>  bda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*
>>> 1000.0))))))-sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*
>> 1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+((ss+(tot/sh*1000.0
>> )*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(-sqrt(0.25+2.0*rint/
>> (sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> ))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0
>> )/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+sqrt(0.25+2.0*rint/
>> (sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> ))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> ))))))))))/((pnorm(-lambda/2.0+log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*
>> 1000.0)/lbar*exp(lambda*lambda)))/lambda)-((ss+(tot/sh*100!
>>>  0.0)*lbar)/(tot/sh*1000.0
>> )/lbar*exp(lambda*lambda))*pnorm(-lambda/2.0-log(((ss+(tot/sh*1000.0
>> )*lbar)/(tot/sh*1000.0
>> )/lbar*exp(lambda*lambda)))/lambda))-(pnorm(-sqrt((sigmae*ss/(ss+lbar*(tot/sh*
>> 1000.0)))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*mat+lambda*lambda)/2.0+log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0
>> )/lbar*exp(lambda*lambda)))/sqrt((sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*mat+lambda*lambda))-((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0
>> )/lbar*exp(lambda*lambda))*pnorm(-sqrt((sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*mat+lambda*lambda)/2.0-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0
>> )/lbar*exp(lambda*lambda)))/sqrt((sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*mat+lambda*lambda)))*exp(-rint*mat)-(exp(rint*(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*
>> 1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))*((((ss+(tot/sh*1000.0
>> )*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(sqrt(0.!
>>>  25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*
>>> (tot/sh*1000.0))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*
>> 1000.0)/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))-sqrt(0.25+2.0*rint/
>> (sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> ))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+((ss+(tot/sh*1000.0
>> )*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(-sqrt(0.25+2.0*rint/
>> (sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> ))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0
>> )/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+sqrt(0.25+2.0*rint/
>> (sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> ))))*(sigmae*ss/(ss+lb!
>>>  ar*(tot/sh*1000.0
>> )))*sqrt(mat+(lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))))-(((ss+(tot/sh*1000.0
>> )*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(sqrt(0.25+2.0*rint/
>> (sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> ))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0
>> )/lbar*exp(lambda*lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))-sqrt(0.25+2.0*rint/
>> (sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> ))))*(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))))+((ss+(tot/sh*1000.0
>> )*lbar)/(tot/sh*1000.0)/lbar*exp(lambda*lambda))^(-sqrt(0.25+2.0*rint/
>> (sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> ))))+0.5)*pnorm(-log(((ss+(tot/sh*1000.0)*lbar)/(tot/sh*1000.0
>> )/lbar*exp(lambda*!
>>>  lambda)))/((sigmae*ss/(ss+lbar*(tot/sh*1000.0)))*sqrt((lambda*lambda/(
>>> sigmae*ss/(ss+lbar*(tot/sh*1000.0)))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> ))))))+sqrt(0.25+2.0*rint/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0))))*(sigmae*ss/(ss+lbar*(tot/sh*
>> 1000.0)))*sqrt((lambda*lambda/(sigmae*ss/(ss+lbar*(tot/sh*1000.0
>> )))/(sigmae*ss/(ss+lbar*(tot/sh*1000.0)))))))))))
>>>
>>> apple.ana= function(rec1,lambda1,lbar1)
>>> {rec=rec1
>>> lambda=lambda1
>>> lbar=lbar1
>>> apple=eval(apple2)
>>> gradient=cbind(eval(D(apple2,'rec')),eval(D(apple2,'lambda')),
>>> eval(D(apple2,'lbar')))
>>> attr(apple.ana,'gradient')=gradient
>>> apple
>>> }
>>>
>>> fit.error=function(rec1,lambda1,lbar1)
>>> {rec=rec1
>>> lambda=lambda1
>>> lbar=lbar1
>>> sum((eval(apple2)*1000-orange)^2/(orange^2))
>>> }
>>>
>>
>> This is still coded incorrectly.  Objective functions optimize over the
>> first parameter only.  See ?optim for the details.  constrOptim is just
>> a wrapper for optim.
>>
>> Duncan Murdoch
>>> fit.error.grr=function(rec1,lambda1,lbar1)
>>> {rec=rec1
>>> lambda=lambda1
>>> lbar=lbar1
>>>
>>>
>> drec=sum(20000*eval(D(apple2,'rec'))*(eval(apple2)*10000-orange)/(orange^2))
>>>
>> dlambda=sum(20000*eval(D(apple2,'lambda'))*(eval(apple2)*10000-orange)/(orange^2))
>>>
>> dlbar=sum(20000*eval(D(apple2,'lbar'))*(eval(apple2)*10000-orange)/(orange^2))
>>>
>>> c(drec,dlambda,dlbar)
>>> }
>>>
>>> ui=matrix(c(1,-1,0,0,0,0,0,0,1,-1,0,0,0,0,0,0,1,-1),6,3)
>>> ci=c(0,-0.5,0,-2,0,-0.6)
>>>
>>> constrOptim(c(0.5,0.3,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
>>> constrOptim(c(0.5,0.9,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
>>> constrOptim(c(0.3,0.5,0.5), f=fit.error, gr=fit.error.grr, ui=ui,ci=ci)
>>>
>>> ###########################################################
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From gustavo.bio at gmail.com  Tue Sep 11 16:31:44 2007
From: gustavo.bio at gmail.com (Gustavo Carvalho)
Date: Tue, 11 Sep 2007 11:31:44 -0300
Subject: [R] Editor for R under Fedora 7
In-Reply-To: <6ade6f6c0709110725h159ad592h583df9476d2c92b6@mail.gmail.com>
References: <OFAA6D4FD5.21B300DC-ON86257353.004A09A7-86257353.004A9D95@aphis.usda.gov>
	<6ade6f6c0709110725h159ad592h583df9476d2c92b6@mail.gmail.com>
Message-ID: <382250f60709110731t69420fbdwf779447545109daf@mail.gmail.com>

Fedora 7 is a linux distribution

On 9/11/07, Paul Smith <phhs80 at gmail.com> wrote:
> On 9/11/07, Antonio_Paredes at aphis.usda.gov
> <Antonio_Paredes at aphis.usda.gov> wrote:
> > I wanted to ask what will be a good editor to write R scripts in Fedora 7.
>
> Tell us first what is your operating system.
>
> Paul
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From phhs80 at gmail.com  Tue Sep 11 16:34:31 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Tue, 11 Sep 2007 15:34:31 +0100
Subject: [R] Editor for R under Fedora 7
In-Reply-To: <OFCE16B492.9DE7E14C-ON86257353.004FA234-86257353.004F85BA@aphis.usda.gov>
References: <6ade6f6c0709110725h159ad592h583df9476d2c92b6@mail.gmail.com>
	<OFCE16B492.9DE7E14C-ON86257353.004FA234-86257353.004F85BA@aphis.usda.gov>
Message-ID: <6ade6f6c0709110734g7f2adc2ekc8ac3e198384e729@mail.gmail.com>

On 9/11/07, Antonio_Paredes at aphis.usda.gov
<Antonio_Paredes at aphis.usda.gov> wrote:
>
> Fedora 7

What about kate then?

Paul

>  "Paul Smith" <phhs80 at gmail.com>
> Sent by: r-help-bounces at r-project.org
>
> 09/11/2007 09:25 AM
>
> To r-help at stat.math.ethz.ch
>
> cc
>
>
> Subject Re: [R] Editor for R under Fedora 7
>
>
>
>
>
>
>
>
> On 9/11/07, Antonio_Paredes at aphis.usda.gov
>  <Antonio_Paredes at aphis.usda.gov> wrote:
>  > I wanted to ask what will be a good editor to write R scripts in Fedora 7.
>
>  Tell us first what is your operating system.
>
>  Paul
>
>  ______________________________________________
>  R-help at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-help
>  PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>  and provide commented, minimal, self-contained, reproducible code.
>
>


From wl2776 at gmail.com  Tue Sep 11 17:16:09 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Tue, 11 Sep 2007 08:16:09 -0700 (PDT)
Subject: [R] Editor for R under Fedora 7
In-Reply-To: <OFAA6D4FD5.21B300DC-ON86257353.004A09A7-86257353.004A9D95@aphis.usda.gov>
References: <OFAA6D4FD5.21B300DC-ON86257353.004A09A7-86257353.004A9D95@aphis.usda.gov>
Message-ID: <12617065.post@talk.nabble.com>


Did you consider R GUI project?
http://www.sciviews.org/_rgui/

I used kate on Fedora, my general impression is not bad. 

But one should be careful with running R session inside kate.
I killed it accidentally several times without saving of the state, when
exited the editor.


Antonio_Paredes wrote:
> 
> I wanted to ask what will be a good editor to write R scripts in Fedora 7. 
> 

-- 
View this message in context: http://www.nabble.com/Editor-for-R-under-Fedora-7-tf4422732.html#a12617065
Sent from the R help mailing list archive at Nabble.com.


From singularitaet at gmx.net  Tue Sep 11 17:21:04 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Tue, 11 Sep 2007 17:21:04 +0200
Subject: [R] Editor for R under Fedora 7
In-Reply-To: <OFAA6D4FD5.21B300DC-ON86257353.004A09A7-86257353.004A9D95@aphis.usda.gov>
References: <OFAA6D4FD5.21B300DC-ON86257353.004A09A7-86257353.004A9D95@aphis.usda.gov>
Message-ID: <46E6B260.1070603@gmx.net>

I use emacs with the ess extension on Fedora 7. Emacs is easily
installable via yum and for ESS (emacs speaks statistics) you could use
the Moertel rpms: http://community.moertel.com/ss/space/RPMs

To edit: save a "buffer" as *.r, then some buttons appear which enable
you to start an R process and to send code to R. What I really like
about ESS/emacs is the splitted windows.

JGR would not be a good choice- although installable it consumes plenty
of cpu so there seems to be a bug.

Stefan


-------- Original Message  --------
Subject: [R] Editor for R under Fedora 7
From: Antonio_Paredes at aphis.usda.gov
To: r-help at stat.math.ethz.ch
Date: 11.09.2007 15:36
> Hello everyone,
>
> I wanted to ask what will be a good editor to write R scripts in Fedora 7. 
>
>
> Tony
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>   


-=-=-
... "Life. Don't talk to me about life." (Marvin)


From gavin.simpson at ucl.ac.uk  Tue Sep 11 17:21:39 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 11 Sep 2007 16:21:39 +0100
Subject: [R] Editor for R under Fedora 7
In-Reply-To: <OFAA6D4FD5.21B300DC-ON86257353.004A09A7-86257353.004A9D95@aphis.usda.gov>
References: <OFAA6D4FD5.21B300DC-ON86257353.004A09A7-86257353.004A9D95@aphis.usda.gov>
Message-ID: <1189524099.14200.85.camel@gsimpson.geog.ucl.ac.uk>

On Tue, 2007-09-11 at 08:36 -0500, Antonio_Paredes at aphis.usda.gov wrote:
> Hello everyone,
> 
> I wanted to ask what will be a good editor to write R scripts in Fedora 7. 

Emacs + ESS is my editor of choice. There is more info here:

http://ess.r-project.org/

and a list of editors and the like can be found here:

http://www.sciviews.org/_rgui/

I give a few of them a try and see which you like. Not everyone likes
Emacs keys especially when moving from a Windows environment (I know I
didn't!)

HTH,

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From jomopo at gmail.com  Tue Sep 11 17:32:17 2007
From: jomopo at gmail.com (=?ISO-8859-1?Q?Josu=E9_Polanco?=)
Date: Tue, 11 Sep 2007 17:32:17 +0200
Subject: [R] Editor for R under Fedora 7
In-Reply-To: <46E6B260.1070603@gmx.net>
References: <OFAA6D4FD5.21B300DC-ON86257353.004A09A7-86257353.004A9D95@aphis.usda.gov>
	<46E6B260.1070603@gmx.net>
Message-ID: <98e024570709110832t7b8e73e8o2ba2781e953633ed@mail.gmail.com>

Hi all,

Another good alternative is VIM www.vim.org,  vim Rules :D

Too, check it in the historic list:
http://tolstoy.newcastle.edu.au/R/help/06/05/26548.html


cheerios

..-..
Josue


On 9/11/07, Stefan Grosse <singularitaet at gmx.net> wrote:
> I use emacs with the ess extension on Fedora 7. Emacs is easily
> installable via yum and for ESS (emacs speaks statistics) you could use
> the Moertel rpms: http://community.moertel.com/ss/space/RPMs
>
> To edit: save a "buffer" as *.r, then some buttons appear which enable
> you to start an R process and to send code to R. What I really like
> about ESS/emacs is the splitted windows.
>
> JGR would not be a good choice- although installable it consumes plenty
> of cpu so there seems to be a bug.
>
> Stefan
>
>
> -------- Original Message  --------
> Subject: [R] Editor for R under Fedora 7
> From: Antonio_Paredes at aphis.usda.gov
> To: r-help at stat.math.ethz.ch
> Date: 11.09.2007 15:36
> > Hello everyone,
> >
> > I wanted to ask what will be a good editor to write R scripts in Fedora 7.
> >
> >
> > Tony
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
>
> -=-=-
> ... "Life. Don't talk to me about life." (Marvin)
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Josu? Mos?s Polanco Mart?nez
Correo-e alternativo jomopo at linuxmail.org
----
It is a wasted day unless you have learned something new and made
someone smile -Mark Weingartz.


From jlaznarte at decsai.ugr.es  Tue Sep 11 18:25:11 2007
From: jlaznarte at decsai.ugr.es (Jose Luis Aznarte M.)
Date: Tue, 11 Sep 2007 18:25:11 +0200
Subject: [R] Percentiles in R
Message-ID: <46E6C167.2070600@decsai.ugr.es>

Hi there! Still struggling to translate Matlab code into R's tsDyn package.
Here is my question: Is there in R an equivalent function to Matlab's 
prctile()? To the moment I thought it was quantile(), but I just 
realized I was wrong. The definition of the Matlab function:

prctile
Percentiles of a sample
SyntaxY = prctile(X,p)
Description
Y = prctile(X,p) calculates a value that is greater than p percent of 
the values in X. The values of p must lie in the interval [0 100]. For 
instance, if p = 50 then Y is the median of X

Thanks!!

-- 
--                                                      --
Jose Luis Aznarte M.       http://decsai.ugr.es/~jlaznarte
Department of Computer Science and Artificial Intelligence
Universidad de Granada           Tel. +34 - 958 - 24 04 67
GRANADA (Spain)                  Fax: +34 - 958 - 24 00 79


From xavier_abulker at yahoo.fr  Tue Sep 11 17:42:07 2007
From: xavier_abulker at yahoo.fr (Xavier Abulker)
Date: Tue, 11 Sep 2007 08:42:07 -0700 (PDT)
Subject: [R] persp() problem
In-Reply-To: <da0aac0709101248p4b42f006lf757877f34a68507@mail.gmail.com>
References: <da0aac0709101248p4b42f006lf757877f34a68507@mail.gmail.com>
Message-ID: <12617657.post@talk.nabble.com>


There is an error in your code:
in persp(x , y , z) the length of x is the number of rows of z, the length
of y is the number of columns of z,
You should also name the rows and columns in z with x and y 



Economics Guy wrote:
> 
> I am having some trouble getting the persp() package to change the x
> and y axis on a 3d plot. It defaults to the [0,1] interval and when I
> try to change it I get errors.
> 
> Example:
> 
> This works:
> ------------
> D <- c(1,2,3,4,5,6,7,8,9,10)
> M <- c(11,12,13,14,15,16,17,18,19,20)
> 
> DM <- cbind(D,M)
> 
> persp(DM, theta = 40, phi = 30, expand = 0.5, col = "lightblue",
>       ltheta = 120, shade = 0.75, ticktype = "detailed",
>       xlab = "X", ylab = "Y", zlab = "Z")
> ---------------------
> 
> 
> But I want the axis to count 1 by ones. So I try:
> -----------------
> D <- c(1,2,3,4,5,6,7,8,9,10)
> M <- c(11,12,13,14,15,16,17,18,19,20)
> 
> DM <- cbind(D,M)
> 
> x <- 1*0:10
> y <- 1*0:20
> persp(x,y,DM, theta = 40, phi = 30, expand = 0.5, col = "lightblue",
>       ltheta = 120, shade = 0.75, ticktype = "detailed",
>       xlab = "X", ylab = "Y", zlab = "Z")
> -------------------------
> 
> I get:
> 
> Error in persp(x, y, z, xlim, ylim, zlim, theta, phi, r, d, scale,
> expand,  : invalid 'z' argument
> 
> but the z was fine in the first version so I am not sure what the deal is.
> 
> Any ideas?
> 
> -Econ Guy
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/persp%28%29-problem-tf4417956.html#a12617657
Sent from the R help mailing list archive at Nabble.com.


From f.harrell at vanderbilt.edu  Tue Sep 11 17:42:59 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue, 11 Sep 2007 10:42:59 -0500
Subject: [R] using bootstrap for tree selection step in rpart
In-Reply-To: <1074.24.131.194.217.1189516428.squirrel@webmail.pitt.edu>
References: <1129.141.151.145.62.1189459021.squirrel@webmail.pitt.edu>	<46E62A52.4030505@pointone.de>
	<1074.24.131.194.217.1189516428.squirrel@webmail.pitt.edu>
Message-ID: <46E6B783.6070107@vanderbilt.edu>

Fiona Callaghan wrote:
> Hi Chris.  Thanks for replying.  I want to take the pruned list of
> subtrees, and select the final tree from this list using a bootstrap
> technique (rather than cross validation).   I think, and I could be wrong,

The result will be very poor predictive accuracy on new samples, because 
you are not incorporating shrinkage (penalization) in deriving the 
estimates.

Frank

> that bagging takes a bunch of bootstrap samples, grows one tree per
> boostrap sample and then combines the estimates, but this is not want I
> want to do.   I hope this is clearer.  It is difficult to describe these
> things with eamil.
> Cheers
> Fiona
>> Fiona Callaghan wrote:
>>> I was wondering if someone could help me with an rpart problem.  I can
>>> see
>>> that cross-validation is the default for tree selection in rpart -- has
>>> a
>>> bootstrap method been implemented anywhere?  I think this is a different
>>> thing to 'bagging' or 'boosting' -- I still want 'one' tree at the end,
>>> I
>>> just would like it chosen using a bootstrap method.  Any ideas???
>> Hi Fiona,
>>
>> I'm not sure if I understand you correctly.
>> To get one single rpart tree trained on one bootstrap sample, try
>> bagging() from the 'ipred' package and set nbagg=1.
>>
>> Bye,
>> Chris
>>
>>
> 
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From xavier_abulker at yahoo.fr  Tue Sep 11 17:53:18 2007
From: xavier_abulker at yahoo.fr (Xavier Abulker)
Date: Tue, 11 Sep 2007 08:53:18 -0700 (PDT)
Subject: [R] Percentiles in R
In-Reply-To: <46E6C167.2070600@decsai.ugr.es>
References: <46E6C167.2070600@decsai.ugr.es>
Message-ID: <12617896.post@talk.nabble.com>


It looks like 
prctile(X,p) is the same as quantile(X,p)

i.e
x<-0:100
quantile(x,0.5) is the median(x)
and 
quantile(x,0.1)=10 is the value that is greater than 10% percent of the
values in X


&quot;Jos? Luis Aznarte M.&quot; wrote:
> 
> Hi there! Still struggling to translate Matlab code into R's tsDyn
> package.
> Here is my question: Is there in R an equivalent function to Matlab's 
> prctile()? To the moment I thought it was quantile(), but I just 
> realized I was wrong. The definition of the Matlab function:
> 
> prctile
> Percentiles of a sample
> SyntaxY = prctile(X,p)
> Description
> Y = prctile(X,p) calculates a value that is greater than p percent of 
> the values in X. The values of p must lie in the interval [0 100]. For 
> instance, if p = 50 then Y is the median of X
> 
> Thanks!!
> 
> -- 
> --                                                      --
> Jose Luis Aznarte M.       http://decsai.ugr.es/~jlaznarte
> Department of Computer Science and Artificial Intelligence
> Universidad de Granada           Tel. +34 - 958 - 24 04 67
> GRANADA (Spain)                  Fax: +34 - 958 - 24 00 79
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Percentiles-in-R-tf4423440.html#a12617896
Sent from the R help mailing list archive at Nabble.com.


From jmburgos at u.washington.edu  Tue Sep 11 17:55:17 2007
From: jmburgos at u.washington.edu (Julian Burgos)
Date: Tue, 11 Sep 2007 08:55:17 -0700
Subject: [R] Percentiles in R
In-Reply-To: <46E6C167.2070600@decsai.ugr.es>
References: <46E6C167.2070600@decsai.ugr.es>
Message-ID: <46E6BA65.5060601@u.washington.edu>

Hola Jose Luis,

Sure, you can use quantile().  Use the probs argument.  For example, to 
get the median do

quantile(X,probs=0.5).

Do ?quantile to learn about the different type of quantiles calculated 
by the funcion.

Saludos,

Julian


Jose Luis Aznarte M. wrote:
> Hi there! Still struggling to translate Matlab code into R's tsDyn package.
> Here is my question: Is there in R an equivalent function to Matlab's 
> prctile()? To the moment I thought it was quantile(), but I just 
> realized I was wrong. The definition of the Matlab function:
>
> prctile
> Percentiles of a sample
> SyntaxY = prctile(X,p)
> Description
> Y = prctile(X,p) calculates a value that is greater than p percent of 
> the values in X. The values of p must lie in the interval [0 100]. For 
> instance, if p = 50 then Y is the median of X
>
> Thanks!!
>
>   

-- 
Julian M. Burgos

Fisheries Acoustics Research Lab
School of Aquatic and Fishery Science
University of Washington

1122 NE Boat Street
Seattle, WA  98105 

Phone: 206-221-6864


From Mark.Leeds at morganstanley.com  Tue Sep 11 18:00:30 2007
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Tue, 11 Sep 2007 12:00:30 -0400
Subject: [R] xyplot question
Message-ID: <D3AEEDA31E57474B840BEBC25A8A8344019579DE@NYWEXMB23.msad.ms.com>

I have the code below and it works fine if I print the xyplot but if I
take the print out, then I just get a blank
pdf. The same holds if I just send the plot to the console without the
print ( I get nothing ). My question is whether this is always
the case with xyplot or is there something wrong with my settings ? I am
on linux ( redhat ) and using R.2.5.0. Thanks.


load("stocks.dat")

pdf('temp.pdf', width=10, height=8)

trellis.par.set(superpose.symbol=list(pch=19, cex=0.8)) # filled circles

print(xyplot(value ~ date|group, groups=wt, data=stocks.all, type='o',
layout=c(2,2),
    auto.key=list(columns=6), scales=list(x=list(rot=90))))

dev.off()

#=======================================================================
============================================


sessionInfo()
R version 2.5.0 (2007-04-23) 
i686-pc-linux-gnu 

locale:
C

attached base packages:
[1] "datasets"  "utils"     "stats"     "graphics"  "grDevices"
"methods"   "base"     

other attached packages:
 lattice filehash  reshape      zoo    chron     MASS 
"0.15-8"    "1.0"  "0.7.4"  "1.3-1" "2.3-11" "7.2-33"
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From joe_retzer at yahoo.com  Tue Sep 11 18:03:43 2007
From: joe_retzer at yahoo.com (Joseph Retzer)
Date: Tue, 11 Sep 2007 09:03:43 -0700 (PDT)
Subject: [R] CLUE package consensus function cl_medoid behavior
In-Reply-To: <46E6B783.6070107@vanderbilt.edu>
Message-ID: <372125.90881.qm@web60314.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070911/d9f23758/attachment.pl 

From brent at webex.com  Tue Sep 11 18:04:47 2007
From: brent at webex.com (Brent Sapiro)
Date: 11 Sep 2007 16:04:47 GMT
Subject: [R] Meeting this week
Message-ID: <1189526687.10001@webexmailer.com>

This email may be an advertisement or solicitation. If you do not want
to receive marketing messages from WebEx click here | view Privacy
Policy ?

-WEBEX:enUS:sdFj9CMZvQ8KWIBz21EK7I-

From singularitaet at gmx.net  Tue Sep 11 18:08:21 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Tue, 11 Sep 2007 18:08:21 +0200
Subject: [R] xyplot question
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A8344019579DE@NYWEXMB23.msad.ms.com>
References: <D3AEEDA31E57474B840BEBC25A8A8344019579DE@NYWEXMB23.msad.ms.com>
Message-ID: <46E6BD75.2080607@gmx.net>

-------- Original Message  --------
Subject: [R] xyplot question
From: Leeds, Mark (IED) <Mark.Leeds at morganstanley.com>
To: r-help at stat.math.ethz.ch
Date: 11.09.2007 18:00
>
> load("stocks.dat")
>
> pdf('temp.pdf', width=10, height=8)
>   
does ist work with postscript?
something like:

postscript("temp.ps", width = 10.0, height = 8.0, horizontal = FALSE,
onefile =T, paper="special")

Stefan
-=-=-
... Time is an illusion, lunchtime doubly so. (Ford Prefect)


From petr.pikal at precheza.cz  Tue Sep 11 18:09:59 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Tue, 11 Sep 2007 18:09:59 +0200
Subject: [R] Odp:  storing text and decimal values in a matrix form
In-Reply-To: <CE1C6887-CBCA-4BA2-AC60-8C222ED7390C@gmail.com>
Message-ID: <OF5E80173A.5D15BEA3-ONC1257353.005867A9-C1257353.0058CC24@precheza.cz>

Hi

Gon?alo Ferraz <gferraz29 at gmail.com> napsal dne 11.09.2007 16:35:57:

> Thanks! What is the easiest way of declaring an empty data frame. Is 
there 
> anything similar to:
> matrix(0,x,y)
> In the help files, I am only finding longer commands that ask me to 
specify 
> each individual column.

You can either do

dat<-data.frame(x=rep(NA,10), y=rep(NA,10))

or to create empty matrix and then transfer it to data frame via 
as.data.frame. From what you wrote I assume that you fill data during some 
cycle. If yes, you shall reconsider it as there can be better options.

Regards
Petr

> G.
> 
> On Sep 11, 2007, at 9:56 AM, Petr PIKAL wrote:
> 
> Hi
> 
> Although not specifically stated in help page, matrix is a vector with 
dim 
> attribute. Therefore it can have only one type of values either numeric 
or 
> character or logical or factor. So if you want textual and numeric 
values 
> you probably have to stick with data frames.
> 
> Regards
> Petr
> petr.pikal at precheza.cz
> 
> r-help-bounces at r-project.org napsal dne 11.09.2007 15:43:20:
> 
> Hi,
> 
> I would like to store some text and decimal values in the following 
> form:
> 
> name   dec.val   dec.val   ...   dec.val
> name   dec.val   dec.val   ...   dec.val
> ...
> name   dec. val    dec.val   ...   dec.val
> 
> To do so, I created a matrix of the necessary size (x row per y cols) 
> with the command
> 
> matrixname <- matrix(0,x,y)
> 
> and proceeded to fill in the matrix with information drawn from a 
> data frame.
> 
> The problem is that the resulting matrix only has integers at the end 
> of the filling process.
> 
> When I ask:
> class(dataframename[i,j])
> The answer is "factor"
> 
> What is the best way of solving the problem. Should I use a data 
> structure other than a matrix? Or should I make the elements be a 
> different class (other than "factor") when I assign them to the matrix?
> 
> Thanks for any help!
> 
> G.
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> Gon?alo Ferraz, PhD
> Projeto Din?mica Biol?gica de Fragmentos Florestais
> Instituto Nacional de Pesquisas da Amaz?nia &
> Smithsonian Tropical Research Institute
> CP 478, Av. Andr? Ara?jo, 1753
> 69011-970 Manaus AM
> Brasil
> Tel: (92) 3643-3229


From jlaznarte at decsai.ugr.es  Tue Sep 11 19:09:24 2007
From: jlaznarte at decsai.ugr.es (Jose Luis Aznarte M.)
Date: Tue, 11 Sep 2007 19:09:24 +0200
Subject: [R] Percentiles in R
In-Reply-To: <46E6C167.2070600@decsai.ugr.es>
References: <46E6C167.2070600@decsai.ugr.es>
Message-ID: <46E6CBC4.6010609@decsai.ugr.es>

    Thank you all! But the problem is that quantile() returns "how many 
data" are greater than p percent, and not a value in the domain of the 
vector under scrutiny. For example, I have a vector

 > x
 [1] "-0,39559"  "1,1916"    "0,23214"   "1,656"     "-0,3439"   "-0,50568"
 [7] "0,52281"   "0,96209"   "0,0087242" "-0,030727" "1,0935"    "0,35159" 
[13] "0,79229"   "0,81791"   "0,3186"    "1,0165"    "0,65567"   "-0,56474"
[19] "-0,34662"  "0,70435"   "-0,73285"  "-0,60452"  "-0,92526"  "-0,296"  
[25] "0,51298"   "0,38654"   "0,32469"   "-0,92555"  "0,53023"   "0,050059"
[31] "1,09"      "-0,35462"  "0,37674"   "1,1409"    "0,072098"  "1,4234"  
[37] "1,43"      "0,68532"   "0,078089"  "0,61944" 

and, if I want to see the 10th percentile, in Matlab I go

 >> prctile(x, 10)
ans =
   -0.4067

But in R:

 > quantile(x, probs=.1)
 10%
51.5

I need to obtain -0.4067, do you see what I mean? Thanks a lot again!!

Jose Luis Aznarte M. escribi?:
> Hi there! Still struggling to translate Matlab code into R's tsDyn package.
> Here is my question: Is there in R an equivalent function to Matlab's 
> prctile()? To the moment I thought it was quantile(), but I just 
> realized I was wrong. The definition of the Matlab function:
>
> prctile
> Percentiles of a sample
> SyntaxY = prctile(X,p)
> Description
> Y = prctile(X,p) calculates a value that is greater than p percent of 
> the values in X. The values of p must lie in the interval [0 100]. For 
> instance, if p = 50 then Y is the median of X
>
> Thanks!!
>
>   


-- 
--                                                      --
Jose Luis Aznarte M.       http://decsai.ugr.es/~jlaznarte
Department of Computer Science and Artificial Intelligence
Universidad de Granada           Tel. +34 - 958 - 24 04 67
GRANADA (Spain)                  Fax: +34 - 958 - 24 00 79


From petr.pikal at precheza.cz  Tue Sep 11 18:28:06 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Tue, 11 Sep 2007 18:28:06 +0200
Subject: [R] persp() problem
In-Reply-To: <12617657.post@talk.nabble.com>
Message-ID: <OF416B5066.2FD9EF64-ONC1257353.0059627B-C1257353.005A74E4@precheza.cz>

Hi

He is actually plotting DM matrix against default values [0,1]. So what he 
needs to do is to change y to c(1,10) and x to seq(1,20,2) to enable his 
code work. And even in that case there is not possible AFAIK to control 
exact labeling of axes as they are internaly recalculated to [0,1] values.

Petr
petr.pikal at precheza.cz

r-help-bounces at r-project.org napsal dne 11.09.2007 17:42:07:

> 
> There is an error in your code:
> in persp(x , y , z) the length of x is the number of rows of z, the 
length
> of y is the number of columns of z,
> You should also name the rows and columns in z with x and y 
> 
> 
> 
> Economics Guy wrote:
> > 
> > I am having some trouble getting the persp() package to change the x
> > and y axis on a 3d plot. It defaults to the [0,1] interval and when I
> > try to change it I get errors.
> > 
> > Example:
> > 
> > This works:
> > ------------
> > D <- c(1,2,3,4,5,6,7,8,9,10)
> > M <- c(11,12,13,14,15,16,17,18,19,20)
> > 
> > DM <- cbind(D,M)
> > 
> > persp(DM, theta = 40, phi = 30, expand = 0.5, col = "lightblue",
> >       ltheta = 120, shade = 0.75, ticktype = "detailed",
> >       xlab = "X", ylab = "Y", zlab = "Z")
> > ---------------------
> > 
> > 
> > But I want the axis to count 1 by ones. So I try:
> > -----------------
> > D <- c(1,2,3,4,5,6,7,8,9,10)
> > M <- c(11,12,13,14,15,16,17,18,19,20)
> > 
> > DM <- cbind(D,M)
> > 
> > x <- 1*0:10
> > y <- 1*0:20
> > persp(x,y,DM, theta = 40, phi = 30, expand = 0.5, col = "lightblue",
> >       ltheta = 120, shade = 0.75, ticktype = "detailed",
> >       xlab = "X", ylab = "Y", zlab = "Z")
> > -------------------------
> > 
> > I get:
> > 
> > Error in persp(x, y, z, xlim, ylim, zlim, theta, phi, r, d, scale,
> > expand,  : invalid 'z' argument
> > 
> > but the z was fine in the first version so I am not sure what the deal 
is.
> > 
> > Any ideas?
> > 
> > -Econ Guy
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > 
> > 
> 
> -- 
> View this message in context: http://www.nabble.com/persp%28%29-problem-
> tf4417956.html#a12617657
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From singularitaet at gmx.net  Tue Sep 11 18:31:26 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Tue, 11 Sep 2007 18:31:26 +0200
Subject: [R] Percentiles in R
In-Reply-To: <46E6CBC4.6010609@decsai.ugr.es>
References: <46E6C167.2070600@decsai.ugr.es> <46E6CBC4.6010609@decsai.ugr.es>
Message-ID: <46E6C2DE.3070901@gmx.net>

-------- Original Message  --------
Subject: Re: [R] Percentiles in R
From: Jose Luis Aznarte M. <jlaznarte at decsai.ugr.es>
To: r-help at stat.math.ethz.ch
Date: 11.09.2007 19:09
>     Thank you all! But the problem is that quantile() returns "how many 
> data" are greater than p percent, and not a value in the domain of the 
> vector under scrutiny. For example, I have a vector
>
>  > x
>  [1] "-0,39559"  "1,1916"    "0,23214"   "1,656"     "-0,3439"   "-0,50568"
>  [7] "0,52281"   "0,96209"   "0,0087242" "-0,030727" "1,0935"    "0,35159" 
> [13] "0,79229"   "0,81791"   "0,3186"    "1,0165"    "0,65567"   "-0,56474"
> [19] "-0,34662"  "0,70435"   "-0,73285"  "-0,60452"  "-0,92526"  "-0,296"  
> [25] "0,51298"   "0,38654"   "0,32469"   "-0,92555"  "0,53023"   "0,050059"
> [31] "1,09"      "-0,35462"  "0,37674"   "1,1409"    "0,072098"  "1,4234"  
> [37] "1,43"      "0,68532"   "0,078089"  "0,61944" 
>
>   
It looks like you imported x as strings not as numbers.

look at this:
> x<-rnorm(50,mean=1)
> x
 [1]  0.21491438  0.03133966  3.60057440  4.15322486  0.96381522  1.34283032
 [7] -0.44273854 -0.53095683 -0.80736505  0.63407897  0.74989143  0.76629350
[13]  1.47503369  1.33359076  0.55049496  2.38543014  0.29774612  0.95834111
[19]  0.27763564 -0.15241260 -0.25558855  1.99413840  0.93002691  0.65026853
[25]  2.89999171  1.57017766 -0.20427214  1.05860619  0.74690706  0.95646603
[31]  0.90801464 -0.18236578  0.24682773  1.57208695  1.05569796  0.79504514
[37]  0.78895742  0.66675315  1.33666759  0.87238647 -1.12956668  0.44982951
[43]  0.25748181  0.82173105  0.86385613  1.03523168  0.17719826  2.59587957
[49]  2.22803895  2.45127783
> quantile(x,probs=0.1)
       10%
-0.2094038

Stefan
-=-=-
... When the center does not hold, the circle falls apart.  (Lao Tzu)


From rkoenker at uiuc.edu  Tue Sep 11 18:37:09 2007
From: rkoenker at uiuc.edu (roger koenker)
Date: Tue, 11 Sep 2007 11:37:09 -0500
Subject: [R] Percentiles in R
In-Reply-To: <46E6CBC4.6010609@decsai.ugr.es>
References: <46E6C167.2070600@decsai.ugr.es> <46E6CBC4.6010609@decsai.ugr.es>
Message-ID: <8CF60CD0-84AC-4F90-B961-D40E867D5D44@uiuc.edu>

Try

	quantile(x, .1, type=1)

or read

	?quantile

for other options.

url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Champaign, IL 61820


On Sep 11, 2007, at 12:09 PM, Jose Luis Aznarte M. wrote:

>     Thank you all! But the problem is that quantile() returns "how  
> many
> data" are greater than p percent, and not a value in the domain of the
> vector under scrutiny. For example, I have a vector
>
>> x
>  [1] "-0,39559"  "1,1916"    "0,23214"   "1,656"     "-0,3439"    
> "-0,50568"
>  [7] "0,52281"   "0,96209"   "0,0087242" "-0,030727" "1,0935"     
> "0,35159"
> [13] "0,79229"   "0,81791"   "0,3186"    "1,0165"    "0,65567"    
> "-0,56474"
> [19] "-0,34662"  "0,70435"   "-0,73285"  "-0,60452"  "-0,92526"   
> "-0,296"
> [25] "0,51298"   "0,38654"   "0,32469"   "-0,92555"  "0,53023"    
> "0,050059"
> [31] "1,09"      "-0,35462"  "0,37674"   "1,1409"    "0,072098"   
> "1,4234"
> [37] "1,43"      "0,68532"   "0,078089"  "0,61944"
>
> and, if I want to see the 10th percentile, in Matlab I go
>
>>> prctile(x, 10)
> ans =
>    -0.4067
>
> But in R:
>
>> quantile(x, probs=.1)
>  10%
> 51.5
>
> I need to obtain -0.4067, do you see what I mean? Thanks a lot again!!
>
> Jose Luis Aznarte M. escribi?:
>> Hi there! Still struggling to translate Matlab code into R's tsDyn  
>> package.
>> Here is my question: Is there in R an equivalent function to Matlab's
>> prctile()? To the moment I thought it was quantile(), but I just
>> realized I was wrong. The definition of the Matlab function:
>>
>> prctile
>> Percentiles of a sample
>> SyntaxY = prctile(X,p)
>> Description
>> Y = prctile(X,p) calculates a value that is greater than p percent of
>> the values in X. The values of p must lie in the interval [0 100].  
>> For
>> instance, if p = 50 then Y is the median of X
>>
>> Thanks!!
>>
>>
>
>
> -- 
> --                                                      --
> Jose Luis Aznarte M.       http://decsai.ugr.es/~jlaznarte
> Department of Computer Science and Artificial Intelligence
> Universidad de Granada           Tel. +34 - 958 - 24 04 67
> GRANADA (Spain)                  Fax: +34 - 958 - 24 00 79
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From deepayan.sarkar at gmail.com  Tue Sep 11 18:37:57 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 11 Sep 2007 09:37:57 -0700
Subject: [R] xyplot question
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A8344019579DE@NYWEXMB23.msad.ms.com>
References: <D3AEEDA31E57474B840BEBC25A8A8344019579DE@NYWEXMB23.msad.ms.com>
Message-ID: <eb555e660709110937vff6c68ds130c360fd6fe7bcf@mail.gmail.com>

On 9/11/07, Leeds, Mark (IED) <Mark.Leeds at morganstanley.com> wrote:
> I have the code below and it works fine if I print the xyplot but if I
> take the print out, then I just get a blank
> pdf. The same holds if I just send the plot to the console without the
> print ( I get nothing ). My question is whether this is always
> the case with xyplot or is there something wrong with my settings ? I am
> on linux ( redhat ) and using R.2.5.0. Thanks.

I don't have your stock.dat, but running the following in a fresh R
session does give me a PDF file with the expected plot.

$ R-devel --vanilla

R version 2.6.0 Under development (unstable) (2007-08-06 r42439)
[...]

> library(lattice)
> pdf('temp.pdf', width=10, height=8)
> xyplot(1:10 ~ 1:10)
> dev.off()

Are you sure you are not doing this inside a function (maybe source)?

-Deepayan


>
>
> load("stocks.dat")
>
> pdf('temp.pdf', width=10, height=8)
>
> trellis.par.set(superpose.symbol=list(pch=19, cex=0.8)) # filled circles
>
> print(xyplot(value ~ date|group, groups=wt, data=stocks.all, type='o',
> layout=c(2,2),
>     auto.key=list(columns=6), scales=list(x=list(rot=90))))
>
> dev.off()
>
> #=======================================================================
> ============================================
>
>
> sessionInfo()
> R version 2.5.0 (2007-04-23)
> i686-pc-linux-gnu
>
> locale:
> C
>
> attached base packages:
> [1] "datasets"  "utils"     "stats"     "graphics"  "grDevices"
> "methods"   "base"
>
> other attached packages:
>  lattice filehash  reshape      zoo    chron     MASS
> "0.15-8"    "1.0"  "0.7.4"  "1.3-1" "2.3-11" "7.2-33"
> --------------------------------------------------------
>
> This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dlakelan at street-artists.org  Tue Sep 11 18:51:06 2007
From: dlakelan at street-artists.org (Daniel Lakeland)
Date: Tue, 11 Sep 2007 09:51:06 -0700
Subject: [R] Percentiles in R
In-Reply-To: <46E6CBC4.6010609@decsai.ugr.es>
References: <46E6C167.2070600@decsai.ugr.es> <46E6CBC4.6010609@decsai.ugr.es>
Message-ID: <20070911165106.GG786@street-artists.org>

On Tue, Sep 11, 2007 at 07:09:24PM +0200, Jose Luis Aznarte M. wrote:
>     Thank you all! But the problem is that quantile() returns "how many 
> data" are greater than p percent, and not a value in the domain of the 
> vector under scrutiny. For example, I have a vector

not quite, quantile returns an estimate of the p-th percentile point
of the data. You're correct, it doesn't return an element of the data,
because it linearly interpolates between data points.

1) Do you REALLY need an element of the data set, or is the linear
interpolation, which should be more accurate, ok for your purposes?
For example, what would you want from quantile(c(1,2),.5)? Quantile
will return 1.5 in this case, what would your matlab function do? a
similar thing occurs when you want quantile(c(1,2,3,4,5),.1295), there
is no exactly .1295 quantile in this dataset so quantile interpolates
and returns 1.518 

2) If you need an element of the data set, you could simply do
something like

(sort(x))[round(NROW(x) * p)]



-- 
Daniel Lakeland
dlakelan at street-artists.org
http://www.street-artists.org/~dlakelan


From deepayan.sarkar at gmail.com  Tue Sep 11 18:59:04 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 11 Sep 2007 09:59:04 -0700
Subject: [R] POSIXct dates on x-axis using xyplot
In-Reply-To: <644e1f320709102047n6e4a4902p23c4b5ed91496f5b@mail.gmail.com>
References: <644e1f320709102047n6e4a4902p23c4b5ed91496f5b@mail.gmail.com>
Message-ID: <eb555e660709110959h340ff9fat2588a88c2e3be127@mail.gmail.com>

On 9/10/07, jim holtman <jholtman at gmail.com> wrote:
> I am using 'xyplot' in lattice to plot some data where the x-axis is a
> POSIXct date.  I have data which spans a 6 month period, but when I
> plot it, only the last month is printed on the right hand side of the
> axis.  I would have expected that at least I would have a beginning
> and an ending point so that I have a point of reference as to the time
> that the data spans.  Here is some test data.
>
>
> > # create test data
> > dates <- seq(as.POSIXct('2006-01-03'), as.POSIXct('2006-06-26'), by='1 week')
> > my.data <- seq(1, length=length(dates))
> > require(lattice)
> [1] TRUE
> > # plot only shows a single month ("Jul" on the right).  Would have
> > # expected at least the beginning and the ending month since this spans
> > # a 6 month period
> > pdf('/test.pdf')
> > xyplot(my.data ~ dates)
> > dev.off()

Yes, the calculations seem very sensitive to the exact range (probably
because you are close to the beginning of a year); e.g., the first two
seem fine, but things are not nice for anything bigger.

xyplot(my.data ~ dates, lattice.options = list(axis.padding =
list(numeric = 0)))

xyplot(my.data ~ dates, lattice.options = list(axis.padding =
list(numeric = 0.01)))

xyplot(my.data ~ dates, lattice.options = list(axis.padding =
list(numeric = 0.02)))

Your options are

(1) specify tick locations manually, using scales$x$at -- this should
work, but I haven't checked

(2) provide a patch for lattice:::formattedTicksAndLabels.POSIXct that
gives behaviour that you like

The current version is derived from axis.POSIXct, which, incidentally,
can also be made to do odd things:

dates <- c(as.POSIXct('2005-12-30'), as.POSIXct('2006-07-01'))
my.data <- seq(1, length=length(dates))
plot(dates, my.data)


-Deepayan


From Mark.Leeds at morganstanley.com  Tue Sep 11 19:06:00 2007
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Tue, 11 Sep 2007 13:06:00 -0400
Subject: [R] xyplot question
In-Reply-To: <eb555e660709110937vff6c68ds130c360fd6fe7bcf@mail.gmail.com>
References: <D3AEEDA31E57474B840BEBC25A8A8344019579DE@NYWEXMB23.msad.ms.com>
	<eb555e660709110937vff6c68ds130c360fd6fe7bcf@mail.gmail.com>
Message-ID: <D3AEEDA31E57474B840BEBC25A8A8344019579E2@NYWEXMB23.msad.ms.com>

Thanks Deepyan. I am doing it in source but I didn't realize that that
was a function. Thanks so much.


-----Original Message-----
From: Deepayan Sarkar [mailto:deepayan.sarkar at gmail.com] 
Sent: Tuesday, September 11, 2007 12:38 PM
To: Leeds, Mark (IED)
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] xyplot question

On 9/11/07, Leeds, Mark (IED) <Mark.Leeds at morganstanley.com> wrote:
> I have the code below and it works fine if I print the xyplot but if I

> take the print out, then I just get a blank pdf. The same holds if I 
> just send the plot to the console without the print ( I get nothing ).

> My question is whether this is always the case with xyplot or is there

> something wrong with my settings ? I am on linux ( redhat ) and using 
> R.2.5.0. Thanks.

I don't have your stock.dat, but running the following in a fresh R
session does give me a PDF file with the expected plot.

$ R-devel --vanilla

R version 2.6.0 Under development (unstable) (2007-08-06 r42439) [...]

> library(lattice)
> pdf('temp.pdf', width=10, height=8)
> xyplot(1:10 ~ 1:10)
> dev.off()

Are you sure you are not doing this inside a function (maybe source)?

-Deepayan


>
>
> load("stocks.dat")
>
> pdf('temp.pdf', width=10, height=8)
>
> trellis.par.set(superpose.symbol=list(pch=19, cex=0.8)) # filled 
> circles
>
> print(xyplot(value ~ date|group, groups=wt, data=stocks.all, type='o',

> layout=c(2,2),
>     auto.key=list(columns=6), scales=list(x=list(rot=90))))
>
> dev.off()
>
> #=====================================================================
> == ============================================
>
>
> sessionInfo()
> R version 2.5.0 (2007-04-23)
> i686-pc-linux-gnu
>
> locale:
> C
>
> attached base packages:
> [1] "datasets"  "utils"     "stats"     "graphics"  "grDevices"
> "methods"   "base"
>
> other attached packages:
>  lattice filehash  reshape      zoo    chron     MASS
> "0.15-8"    "1.0"  "0.7.4"  "1.3-1" "2.3-11" "7.2-33"
> --------------------------------------------------------
>
> This is not an offer (or solicitation of an offer) to 
> buy/se...{{dropped}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From jlaznarte at decsai.ugr.es  Tue Sep 11 20:01:02 2007
From: jlaznarte at decsai.ugr.es (Jose Luis Aznarte M.)
Date: Tue, 11 Sep 2007 20:01:02 +0200
Subject: [R] Percentiles in R
In-Reply-To: <46E6C167.2070600@decsai.ugr.es>
References: <46E6C167.2070600@decsai.ugr.es>
Message-ID: <46E6D7DE.2050504@decsai.ugr.es>

    Ok, of course you were right. As Stefan pointed out, it was a 
problem of the type of the vector: it was a factor and hence the 
quantile was not what expected. Thank you all!!

Jose Luis Aznarte M. escribi?:
> Hi there! Still struggling to translate Matlab code into R's tsDyn package.
> Here is my question: Is there in R an equivalent function to Matlab's 
> prctile()? To the moment I thought it was quantile(), but I just 
> realized I was wrong. The definition of the Matlab function:
>
> prctile
> Percentiles of a sample
> SyntaxY = prctile(X,p)
> Description
> Y = prctile(X,p) calculates a value that is greater than p percent of 
> the values in X. The values of p must lie in the interval [0 100]. For 
> instance, if p = 50 then Y is the median of X
>
> Thanks!!
>
>   


-- 
--                                                      --
Jose Luis Aznarte M.       http://decsai.ugr.es/~jlaznarte
Department of Computer Science and Artificial Intelligence
Universidad de Granada           Tel. +34 - 958 - 24 04 67
GRANADA (Spain)                  Fax: +34 - 958 - 24 00 79


From deepayan.sarkar at gmail.com  Tue Sep 11 19:12:53 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 11 Sep 2007 10:12:53 -0700
Subject: [R] xyplot question
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A8344019579E2@NYWEXMB23.msad.ms.com>
References: <D3AEEDA31E57474B840BEBC25A8A8344019579DE@NYWEXMB23.msad.ms.com>
	<eb555e660709110937vff6c68ds130c360fd6fe7bcf@mail.gmail.com>
	<D3AEEDA31E57474B840BEBC25A8A8344019579E2@NYWEXMB23.msad.ms.com>
Message-ID: <eb555e660709111012g7b23ced1rb36d6b54880d7549@mail.gmail.com>

On 9/11/07, Leeds, Mark (IED) <Mark.Leeds at morganstanley.com> wrote:
> Thanks Deepyan. I am doing it in source but I didn't realize that that
> was a function. Thanks so much.

You might try source(..., echo=TRUE) if you want to mimic console evaluation.

-Deepayan


From red_tez at yahoo.co.uk  Tue Sep 11 20:38:13 2007
From: red_tez at yahoo.co.uk (Terence Broderick)
Date: Tue, 11 Sep 2007 19:38:13 +0100 (BST)
Subject: [R] Fitting data to chi-squared or noncentral chi-squared
	distributions
Message-ID: <215276.36117.qm@web27215.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070911/2561a480/attachment.pl 

From Mark.Sasse at citizensbank.com  Tue Sep 11 21:05:29 2007
From: Mark.Sasse at citizensbank.com (Sasse, Mark)
Date: Tue, 11 Sep 2007 15:05:29 -0400
Subject: [R] Vector Size Error Message
Message-ID: <01A15B44D2E78B48A9D1A232AE93B42B08D0228D@WCLURIB00001006.corp.internal.citizensbank.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070911/9341c560/attachment.pl 

From red_tez at yahoo.co.uk  Tue Sep 11 21:18:30 2007
From: red_tez at yahoo.co.uk (Terence Broderick)
Date: Tue, 11 Sep 2007 20:18:30 +0100 (BST)
Subject: [R] Fitting Data to a Noncentral Chi-Squared Distribution using MLE
Message-ID: <568776.77665.qm@web27209.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070911/1743bb51/attachment.pl 

From kl.vanw at gmail.com  Tue Sep 11 21:56:30 2007
From: kl.vanw at gmail.com (K Vanw)
Date: Tue, 11 Sep 2007 15:56:30 -0400
Subject: [R] building with atlas version of blas and lapack
Message-ID: <bfb1b6d20709111256q4fc53273hb5f9245a480ba77f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070911/2ac8e2fc/attachment.pl 

From kl.vanw at gmail.com  Tue Sep 11 22:09:27 2007
From: kl.vanw at gmail.com (K Vanw)
Date: Tue, 11 Sep 2007 16:09:27 -0400
Subject: [R] building with atlas version of blas and lapack
In-Reply-To: <bfb1b6d20709111256q4fc53273hb5f9245a480ba77f@mail.gmail.com>
References: <bfb1b6d20709111256q4fc53273hb5f9245a480ba77f@mail.gmail.com>
Message-ID: <bfb1b6d20709111309p3a6285ackbfe7c5badd84ca10@mail.gmail.com>

Looks like the list-server didn't like whatever gmail does to the
formating. Sorry. So here's my post in plain text:

On 9/11/07, K Vanw <kl.vanw at gmail.com> wrote:
> I'd like to build R using my optimized blas and lapack libraries. It seems know matter what I
> do, the configure script uses the blas supplied with the source. My blas and lapack libraries
> are in /usr/local/atlas/lib. How can I get configure to use these?


From liy12 at mskcc.org  Tue Sep 11 22:25:35 2007
From: liy12 at mskcc.org (Yuelin Li)
Date: Tue, 11 Sep 2007 16:25:35 -0400
Subject: [R] building with atlas version of blas and lapack
In-Reply-To: <bfb1b6d20709111256q4fc53273hb5f9245a480ba77f@mail.gmail.com>
References: <bfb1b6d20709111256q4fc53273hb5f9245a480ba77f@mail.gmail.com>
Message-ID: <20070911202535.GE18752@jdmlab.mskcc.org>

On my linux machine (Ubuntu Feisty on i-686) this works:

     ./configure --with-blas="lf77blas -latlas"

Yuelin.

-- K Vanw wrote --|Tue (Sep/11/2007)[03:56]|--:
   I'd like to build R using my optimized blas and lapack libraries. It seems
   know matter what I do, the configure script uses the blas supplied with the
   source. My blas and lapack libraries are in /usr/local/atlas/lib. How can I
   get configure to use these?
   
   	[[alternative HTML version deleted]]
   
   ______________________________________________
   R-help at r-project.org mailing list
   https://stat.ethz.ch/mailman/listinfo/r-help
   PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
   and provide commented, minimal, self-contained, reproducible code.
   

 
     =====================================================================
     
     Please note that this e-mail and any files transmitted with it may be 
     privileged, confidential, and protected from disclosure under 
     applicable law. If the reader of this message is not the intended 
     recipient, or an employee or agent responsible for delivering this 
     message to the intended recipient, you are hereby notified that any 
     reading, dissemination, distribution, copying, or other use of this 
     communication or any of its attachments is strictly prohibited.  If 
     you have received this communication in error, please notify the 
     sender immediately by replying to this message and deleting this 
     message, any attachments, and all copies and backups from your 
     computer.


From cberry at tajo.ucsd.edu  Tue Sep 11 22:35:49 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Tue, 11 Sep 2007 13:35:49 -0700
Subject: [R] Fitting Data to a Noncentral Chi-Squared Distribution using
 MLE
In-Reply-To: <568776.77665.qm@web27209.mail.ukl.yahoo.com>
References: <568776.77665.qm@web27209.mail.ukl.yahoo.com>
Message-ID: <Pine.LNX.4.64.0709111329280.20779@tajo.ucsd.edu>



This is what I might do:

> y <- rchisq( 1000, df=10, ncp=2 )
> library( stats4 )
> res <- mle( function(x,z) -sum( dchisq(y, x, z , log=TRUE ) ), start=list( x=5, z=5 ) )
> coef(res)
         x         z
10.355711  1.586123
>
> ## or just to keep clear of boundary constraints:
>
> res <- mle( function(x,z) -sum(dchisq(y, exp(x), exp(z) , log=TRUE )), start=list( x=log(5), z=log(5) ) )
> exp( coef(res) )
         x         z
10.350899  1.591086
>

Chuck

p.s. Using your space key, inserting lines breaks, and indenting your code 
will make it easier to read and to pick out errors.

On Tue, 11 Sep 2007, Terence Broderick wrote:

> Hi, I have written out the log-likelihood function to fit some data I have (called ONES20) to the non-central chi-squared distribution.
>
>  >library(stats4)
>  >ll<-function(lambda,k){x<-ONES20; 25573*0.5*lambda-25573*log(2)-sum(-x/2)-log((x/lambda)^(0.25*k-0.5))-log(besselI(sqrt(lambda*x),0.5*k-1,expon.scaled=FALSE))}
>
>  > est<-mle(minuslog=ll,start=list(lambda=0.05,k=0.006))
>
>  R accepts the function definition without a problem, but gives this error when I ask for the mle of the parameters.
>
>  Error in besselI(x, nu, 1 + as.logical(expon.scaled)) :
>        Non-numeric argument to mathematical function
> In addition: Warning message:
> NaNs produced in: sqrt(x = xx)
>
>  I am also anticipating another problem in that depending on the definition of the noncentral chi-squared distribution used, the parameters I provide the optimiser to start with lambda and k, may not be acceptable as they are doubles as opposed to integers.
>
>  Does anybody have any experience with the fitting of these distributions?
>
>  Best Wishes
>
>  Terence
>
>
> audaces fortuna iuvat
>
> ---------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From jholtman at gmail.com  Tue Sep 11 22:40:33 2007
From: jholtman at gmail.com (jim holtman)
Date: Tue, 11 Sep 2007 16:40:33 -0400
Subject: [R] Vector Size Error Message
In-Reply-To: <01A15B44D2E78B48A9D1A232AE93B42B08D0228D@WCLURIB00001006.corp.internal.citizensbank.com>
References: <01A15B44D2E78B48A9D1A232AE93B42B08D0228D@WCLURIB00001006.corp.internal.citizensbank.com>
Message-ID: <644e1f320709111340o21242bccv9234381370f15291@mail.gmail.com>

What operating system are you running on?  Do you know if you have run
out of physical memory?  If on Windows, what do you have
'--max-mem-size' set to on the command line invoking the RGUI?

On 9/11/07, Sasse, Mark <Mark.Sasse at citizensbank.com> wrote:
> I have been using R off an on for approximately 3 months.  As such, I am
> not very knowledgeable about coding in R.  Currently I am running into
> the following problem.  I'm using scan to make data available in R.  The
> data I'm loading consists of over 400,000 records with 5 data fields.
> After running the following statement:
>
>
>
> mod1<-glm(DefMigFlag~MaxFICO, family=binomial(link="logit"))
>
>
>
> R returns the following error message:
>
>
>
> Error: cannot allocate vector of size 3.3 Mb
>
>
>
> Can anyone tell me how what I need to do to enable R to execute my glm
> statement?
>
>
>
> Thanks very much!
>
>
>
> Mark Sasse
>
>
>
> Mark.sasse at citizensbank.com
>
>
>
>
>
>
> -----------------------------------------
> Use of email is inherently insecure. Confidential information,
> including account information, and personally identifiable
> information, should not be transmitted via email, or email
> attachment.  In no event shall Citizens or any of its affiliates
> accept any responsibility for the loss, use or misuse of any
> information including confidential information, which is sent to
> Citizens or its affiliates via email, or email attachment. Citizens
> does not guarantee the accuracy of any email or email attachment,
> that an email will be received by Citizens or that Citizens will
> respond to any email.
>
> This email message is confidential and/or privileged. It is to be
> used by the intended recipient only.  Use of the information
> contained in this email by anyone other than the intended recipient
> is strictly prohibited. If you have received this message in error,
> please notify the sender immediately and promptly destroy any
> record of this email.
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From pbruce at statistics.com  Tue Sep 11 21:25:27 2007
From: pbruce at statistics.com (Peter Bruce)
Date: Tue, 11 Sep 2007 15:25:27 -0400
Subject: [R] Online course - Introduction to Data Handling in R.
Message-ID: <6.1.0.6.2.20070911152154.04a81ff0@mail.statistics.com>

Dr. Paul Murrell will present his course "Introduction to R
- Data Handling" online at statistics.com Sept. 28 - Oct.
26.  Participants can ask questions and exchange comments
with Dr. Murrell via a private discussion board throughout
the period.

This course will provide an easy introduction to R and its
use in organizing and exploring data. Once you've completed
this course you'll be able to enter, save, retrieve,
summarize and display data using R.

Dr. Murrell is a Senior Lecturer in the Department of
Statistics at the University of Auckland, New Zealand. Paul
has been a member of the core development team for R since
1999, with a focus on the graphics system in R. He is the
past Chair of the Section for Statistical Graphics of the
American Statistical Association. He has recently served
as Editor-in-Chief of "R News," the newsletter of the R
Project, and is an Associate Editor for "Computational
Statistics" and "The Journal of Statistical Software."

The course will require about 10-15 hours per week and
there are no set hours when you must be online.

Details and registration at
http://www.statistics.com/ourcourses/R/

Peter Bruce
courses at statistics.com


From dkaplan at education.wisc.edu  Tue Sep 11 23:35:40 2007
From: dkaplan at education.wisc.edu (David Kaplan)
Date: Tue, 11 Sep 2007 16:35:40 -0500
Subject: [R] Missing data
Message-ID: <46E70A2C.1070807@education.wisc.edu>

Hi all,

I'm looking for a contributed package that can provide a detailed 
account of missing data patterns and perhaps also provide imputation 
procedures, such as mean imputation or hot deck imputation and the like. 
  Is there anything out there?

Thanks in advance,

David


-- 
===========================================================================
David Kaplan, Ph.D.
Professor
Department of Educational Psychology
University of Wisconsin - Madison
Educational Sciences, Room, 1061
1025 W. Johnson Street
Madison, WI 53706

email: dkaplan at education.wisc.edu
homepage: http://www.education.wisc.edu/edpsych/facstaff/kaplan/kaplan.htm
Phone: 608-262-0836


From gunter.berton at gene.com  Wed Sep 12 01:22:43 2007
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 11 Sep 2007 16:22:43 -0700
Subject: [R] Missing data
In-Reply-To: <46E70A2C.1070807@education.wisc.edu>
References: <46E70A2C.1070807@education.wisc.edu>
Message-ID: <004301c7f4ca$a7cc3e60$3a0b2c0a@gne.windows.gene.com>

Please use R's existing search tools before posting:

RsiteSearch("imputation")
RsiteSearch("missing data imputation") 

 etc.

Bert Gunter
Genentech Nonclinical Statistics


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of David Kaplan
Sent: Tuesday, September 11, 2007 2:36 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Missing data

Hi all,

I'm looking for a contributed package that can provide a detailed 
account of missing data patterns and perhaps also provide imputation 
procedures, such as mean imputation or hot deck imputation and the like. 
  Is there anything out there?

Thanks in advance,

David


-- 
===========================================================================
David Kaplan, Ph.D.
Professor
Department of Educational Psychology
University of Wisconsin - Madison
Educational Sciences, Room, 1061
1025 W. Johnson Street
Madison, WI 53706

email: dkaplan at education.wisc.edu
homepage: http://www.education.wisc.edu/edpsych/facstaff/kaplan/kaplan.htm
Phone: 608-262-0836

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dkaplan at education.wisc.edu  Wed Sep 12 01:33:00 2007
From: dkaplan at education.wisc.edu (David Kaplan)
Date: Tue, 11 Sep 2007 18:33:00 -0500
Subject: [R] Missing data
In-Reply-To: <004301c7f4ca$a7cc3e60$3a0b2c0a@gne.windows.gene.com>
References: <46E70A2C.1070807@education.wisc.edu>
	<004301c7f4ca$a7cc3e60$3a0b2c0a@gne.windows.gene.com>
Message-ID: <46E725AC.9040501@education.wisc.edu>

I did. If you don't want to answer, then your unhelpful suggestions to 
yourself.


=======================================================================
David Kaplan, Ph.D.
Professor
Department of Educational Psychology
University of Wisconsin - Madison
Educational Sciences, Room 1061
1025 W. Johnson Street
Madison, WI 53706

email: dkaplan at education.wisc.edu
Web:   http://www.education.wisc.edu/edpsych/facstaff/kaplan/kaplan.htm
Phone: 608-262-0836
Fax:   608-262-0843
=======================================================================


Bert Gunter wrote:
> Please use R's existing search tools before posting:
> 
> RsiteSearch("imputation")
> RsiteSearch("missing data imputation") 
> 
>  etc.
> 
> Bert Gunter
> Genentech Nonclinical Statistics
> 
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf Of David Kaplan
> Sent: Tuesday, September 11, 2007 2:36 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Missing data
> 
> Hi all,
> 
> I'm looking for a contributed package that can provide a detailed 
> account of missing data patterns and perhaps also provide imputation 
> procedures, such as mean imputation or hot deck imputation and the like. 
>   Is there anything out there?
> 
> Thanks in advance,
> 
> David
> 
>


From r.turner at auckland.ac.nz  Wed Sep 12 01:41:03 2007
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 12 Sep 2007 11:41:03 +1200
Subject: [R] Missing data
In-Reply-To: <46E725AC.9040501@education.wisc.edu>
References: <46E70A2C.1070807@education.wisc.edu>
	<004301c7f4ca$a7cc3e60$3a0b2c0a@gne.windows.gene.com>
	<46E725AC.9040501@education.wisc.edu>
Message-ID: <66D34DF4-6893-4DA7-863C-4275E6829F0F@auckland.ac.nz>


On 12/09/2007, at 11:33 AM, David Kaplan wrote:

> I did. If you don't want to answer, then your unhelpful suggestions to
> yourself.


This is uncalled for.  Bert Gunter's response was perfectly reasonable.
Read the posting guide.

			cheers,

				Rolf Turner


> ====================================================================== 
> =
> David Kaplan, Ph.D.
> Professor
> Department of Educational Psychology
> University of Wisconsin - Madison
> Educational Sciences, Room 1061
> 1025 W. Johnson Street
> Madison, WI 53706
>
> email: dkaplan at education.wisc.edu
> Web:   http://www.education.wisc.edu/edpsych/facstaff/kaplan/ 
> kaplan.htm
> Phone: 608-262-0836
> Fax:   608-262-0843
> ====================================================================== 
> =
>
>
> Bert Gunter wrote:
>> Please use R's existing search tools before posting:
>>
>> RsiteSearch("imputation")
>> RsiteSearch("missing data imputation")
>>
>>  etc.
>>
>> Bert Gunter
>> Genentech Nonclinical Statistics
>>
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r- 
>> project.org] On
>> Behalf Of David Kaplan
>> Sent: Tuesday, September 11, 2007 2:36 PM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] Missing data
>>
>> Hi all,
>>
>> I'm looking for a contributed package that can provide a detailed
>> account of missing data patterns and perhaps also provide imputation
>> procedures, such as mean imputation or hot deck imputation and the  
>> like.
>>   Is there anything out there?
>>
>> Thanks in advance,
>>
>> David
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


######################################################################
Attention:\ This e-mail message is privileged and confidenti...{{dropped}}


From m_olshansky at yahoo.com  Wed Sep 12 02:10:16 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Tue, 11 Sep 2007 17:10:16 -0700 (PDT)
Subject: [R] Inferences for ratios of non-normal means
In-Reply-To: <6ade6f6c0709110238h4aa99089w7ec65e850186bc49@mail.gmail.com>
Message-ID: <597090.83803.qm@web32213.mail.mud.yahoo.com>

For large samples you have asymptotic normality!

--- Paul Smith <phhs80 at gmail.com> wrote:

> Dear All,
> 
> The package mratios can perform inferences for
> ratios of normal means.
> Is there some other package to do the same but with
> non-normal
> populations. Since I have got large samples, an
> asymptotic procedure
> would be fine.
> 
> Thanks in advance,
> 
> Paul
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From realityrandom at gmail.com  Wed Sep 12 02:39:30 2007
From: realityrandom at gmail.com (Yuchen Luo)
Date: Tue, 11 Sep 2007 17:39:30 -0700
Subject: [R] Are the error messages of ConstrOptim() consisten with each
	other?
In-Reply-To: <Pine.LNX.4.64.0709110724450.16909@homer24.u.washington.edu>
References: <548b8d440709092358g3cd079cehd459e8592bb9673c@mail.gmail.com>
	<46E51869.9070809@stats.uwo.ca>
	<548b8d440709101421o5346f1ccp2ed468d1ffe4a68a@mail.gmail.com>
	<Pine.LNX.4.64.0709110724450.16909@homer24.u.washington.edu>
Message-ID: <548b8d440709111739j29038c07p9ed8115fe771102a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070911/ea908c98/attachment.pl 

From yu.wang at pdf.com  Wed Sep 12 03:14:23 2007
From: yu.wang at pdf.com (Yu (Warren) Wang)
Date: Wed, 12 Sep 2007 09:14:23 +0800
Subject: [R] question about non-linear least squares in R
In-Reply-To: <87A0C64299B27148B40BE0DB83EDE2DBE36E4B@RSMAIL002.REG.SKANE.SE>
References: <87A0C64299B27148B40BE0DB83EDE2DBE36E4B@RSMAIL002.REG.SKANE.SE>
Message-ID: <46E73D6F.7090401@pdf.com>

Dear Nilsson,
    Thank you very much for your reply which gave me much instruction!
    I will have a try on the suggested way from you.
    In fact, to get the value of MA is the most important thing for me 
in the fitting by this model. And I have thought about the linear model 
fitting at first, but you know, when the the functional form  be changed 
as:   
y = (a + b*c^2 + d*c^4) + (-2*b*c - 4*d*c^3)*x +

    (d + b*6*c^2)*x^2   - (4*d*c)*x^3 + d*x^4 + epsilon

     four coefficient (a,b,c,d) turns to five in this linear model (for 
constant, x, x^2, x^3, x^4), that means there should be some 
relationship among the five coefficients,  which cannot be reflected in 
the linear model. So I cannot get the accurate value for the parameters.

    For your reference:
    As what you pointed out, the initial value for a,b,c,MA is critical 
for nls. In recent days, I tried recruiting the model, y~a*x^4+b*x^2+c, 
to get the initial value of a0, b0, and c0, and it works, but cannot 
avoid the convergence problem totally (the probability went down).

    Thank you very much again!
    I really appreciate your help!

Best regards,
Warren


Nilsson Fredrik X wrote:
> Dear Warren,
>
> I had similar problems, this is (roughly) how I solved it translated to your problem:
> x <- c(-0.06,-0.04,-0.025,-0.015,-0.005,0.005,0.015,0.025,0.04,0.06)
>
> y <- c(1866760,1457870,1314960,1250560,1184850,1144920,
>        1158850,1199910,1263850,1452520)
>
> dafa<-data.frame(x,y)
> plot(x,y)
>
> foqufu<-function(parm)
> {
> const<-parm[1]
> A<-parm[2]
> B<-parm[3]
> MA<-parm[4]
>
> d<-y-(const + A*(x-MA)^4 + B*(x-MA)^2)
> d<-d%*%d
> return(d)
> }
>
> # This is your initial guess
> aaa<-c(10000000, 100000000, -1000000, 0)
> # As already pointed out, you have a bad initial guess.
>
>
> apa3<-optim(aaa, foqufu, control=list(maxit=20000, reltol=1e-16))
> apa3<-optim(apa3$par, foqufu, control=list(maxit=20000, reltol=1e-16))
> apa3<-optim(apa3$par, foqufu, control=list(maxit=20000, reltol=1e-16))
> apa3<-optim(apa3$par, foqufu, control=list(maxit=20000, reltol=1e-16))
> # I do this a couple of times until convergence
> apa3<-optim(apa3$par, foqufu, control=list(maxit=20000, reltol=1e-10))
>
> fitOup<- nls(y ~ constant + A*(x-MA)^4 + B*(x-MA)^2, data=dafa,
>   start=list(constant= 4.911826e+06, A=2.625077e+08, B=-6.278897e+07, MA=3.538064e-01), 
>   control=nls.control(maxiter=100, minFactor=1/4096), trace=TRUE)
>
>
> Note that due to your bad initial guess on parameters you end up in a local not global minimum which is the trouble with nonlinear optimization. A way out would perhaps be to randomize your initial guesses.
>
> Andy's way of getting the initial values is better in that respect. NOTE that he searches for the quadratic first (downplaying the importance of the quartic term) But technically I don't understand the  need to scale your y's, in this case you get the same.
>  
> Another way of finding some intial values is to solve (const + B*MA^2 = intercept, -2*B*MA = coefficient of x, B = coefficient of x^2 in the J2.lm fit below; assuming that J2.lm (below has been fit):
> B<-as.numeric(coef(J2.lm)[3])
> A<-0
> MA<-as.numeric(coef(J2.lm)[2])/2/B
> const<- as.numeric(coef(J2.lm)[1])-B*MA^2
>
> bbb<-c(const, 0, B, MA)
> apa3<-optim(bbb, foqufu, control=list(maxit=20000, reltol=1e-16))
> #iterating a couple of times
> apa3<-optim(apa3$par, foqufu, control=list(maxit=20000, reltol=1e-16))
> #gives the same solution as Andy's
> ).
> #variation of Andy's solution (no scaling of y)
> J2.lm<-lm(y~1 + x + I(x^2), data=dafa)
> summary(J2.lm)
>
> plot(xx, predict(J2.lm, ydf))
> xx[which.min(predict(J2.lm, ydf))]
> Ja2.lm<-lm(y~1 + I((x-0.01)^2), data=dafa)
> summary(Ja2.lm)
> plot(x,y)
> points(x, predict(Ja2.lm, data=data.frame(x=x-0.01, y=y)), col="red")
>
> apa <-optim(c(1146530, 0,139144223, 0.01), foqufu, control=list(maxit=20000, reltol=1e-10))
>
> fitOup3b<- nls(y ~ constant + A*(x-MA)^4 + B*(x-MA)^2, data=dafa,
>   start=list(constant= apa$par[1], A=apa$par[2], B= apa$par[3], MA=apa$par[4]),
>   control=nls.control(maxiter=100, minFactor=1/4096), trace=TRUE)
> # this is exactly the same solution as Andy's, except that the residuals are 
> # 1e12 larger and A,B, const are 1e6 larger (due to the scaling).
>
>
> BUT, and this is a big BUT, why on earth do you choose this functional form? First, the plot(x,y) suggest to my eyes that the function is not symmetric around its centre. Second, if you're not particularly interested in finding a value for MA (i.e. it can be considered as a constant) why not use a simple linear regression with a polynomial? What I mean here is that if:
>
> y = a + b*(x-c)^2 + d*(x-c)^4 + epsilon
> (and no variability in c) then
> y = (a + b*c^2 + d*c^4) + (-2*b*c - 4*d*c^3)*x + 
>     (d + b*6*c^2)*x^2   - (4*d*c)*x^3 + d*x^4 + epsilon
>
> So in fact you could do:
> A.lm<-lm(y ~ poly(x,4), data=dafa)
> Summary(A.lm)
> # suggests that fourth order not necessary
> B.lm<-lm(y ~ poly(x,3), data=dafa).
> anova(B.lm, A.lm)
>
> # note that this suggest that your problem has an asymmetry that  
> # should be accounted for (unless you have very strong reasons for choosing 
> # your particular model formulation).  
>
> Third, and this is a more critical question (which I hope that the experts on nls/R gurus would comment on how to solve) I think it is problematic to have variability in LOCATION such as your shift variable (MA). It seems to introduce all sorts of nastiness, which ought to be particularly severe in non-linear regression.
>
> Best regards,
> Fredrik 
>
> -----Ursprungligt meddelande-----
> Fr?n: apjaworski at mmm.com [mailto:apjaworski at mmm.com] 
> Skickat: den 5 september 2007 18:24
> Till: Yu (Warren) Wang
> Kopia: r-help at stat.math.ethz.ch; r-help-bounces at stat.math.ethz.ch
> ?mne: Re: [R] question about non-linear least squares in R
>
> Here is one way of getting a reasonable fit:
>
> 1.  Scale your y's by dividing all values by 1e6.
> 2.  Plot x vs. y.  The plot looks like a quadratic function.
> 3.  Fit a quadratic const. + B*x^2 - this a linear regression problem so
> use lm.
> 4.  Plot the predictions.
> 5.  Eyball the necessary shift - MA is around 0.01.  Refit const. +
> B*(x-.01)^2.  Should get const.=1.147 and B=139.144
> 6.  Use start=list(const.= 1.147, A=0, B=1.147, MA=.01).  nls should
> converge in 4 iterations.
>
> In general, good starting points may be crucial to nls convergence.
> Scaling the y's to reasonable values also helps.
>
> Hope this helps,
>
> Andy
>
> __________________________________
> Andy Jaworski
> 518-1-01
> Process Laboratory
> 3M Corporate Research Laboratory
> -----
> E-mail: apjaworski at mmm.com
> Tel:  (651) 733-6092
> Fax:  (651) 736-3122
>
>
>                                                                            
>              "Yu (Warren)                                                  
>              Wang"                                                         
>              <yu.wang at pdf.com>                                          To 
>              Sent by:                  "r-help at stat.math.ethz.ch"          
>              r-help-bounces at st         <r-help at stat.math.ethz.ch>          
>              at.math.ethz.ch                                            cc 
>                                                                            
>                                                                    Subject 
>              09/05/2007 02:51          [R] question about non-linear least 
>              AM                        squares in R                        
>                                                                            
>                                                                            
>                                                                            
>                                                                            
>                                                                            
>                                                                            
>
>
>
>
> Hi, everyone,
>     My question is: It's not every time that you can get a converged
> result from the nls function. Is there any solution for me to get a
> reasonable result? For example:
>
> x <- c(-0.06,-0.04,-0.025,-0.015,-0.005,0.005,0.015,0.025,0.04,0.06)
>
> y <-
> c(1866760,1457870,1314960,1250560,1184850,1144920,1158850,1199910,1263850,1452520)
>
>
> fitOup<- nls(y ~ constant + A*(x-MA)^4 + B*(x-MA)^2,
> start=list(constant=10000000, A=100000000, B=-1000000, MA=0),
> control=nls.control(maxiter=100, minFactor=1/4096), trace=TRUE)
>
>
>
>  For this one, I cannot get the converged result, how can I reach it? To
> use another funtion or to modify some settings for nls?
>
> Thank you very much!
>
> Yours,
>
> Warren
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>


From billpikounis at gmail.com  Wed Sep 12 03:33:00 2007
From: billpikounis at gmail.com (Bill Pikounis)
Date: Tue, 11 Sep 2007 21:33:00 -0400
Subject: [R] Missing data
In-Reply-To: <46E70A2C.1070807@education.wisc.edu>
References: <46E70A2C.1070807@education.wisc.edu>
Message-ID: <f4295a580709111833g21c48155yb3e15b32d1fc859@mail.gmail.com>

David,
Frank Harrell's pair of packages Hmisc and Design has some functions
for tabulating, visualizing, and accounting for missing data.  I
recommend them as one avenue to investigate. Frank's companion book
"Regression Modeling Strategies" covers their use in-depth.

Hope that helps,
Bill

___________
Bill Pikounis
 Statistician

On 9/11/07, David Kaplan <dkaplan at education.wisc.edu> wrote:
> Hi all,
>
> I'm looking for a contributed package that can provide a detailed
> account of missing data patterns and perhaps also provide imputation
> procedures, such as mean imputation or hot deck imputation and the like.
>   Is there anything out there?
>
> Thanks in advance,
>
> David
>
>
> --
> ===========================================================================
> David Kaplan, Ph.D.
> Professor
> Department of Educational Psychology
> University of Wisconsin - Madison
> Educational Sciences, Room, 1061
> 1025 W. Johnson Street
> Madison, WI 53706
>
> email: dkaplan at education.wisc.edu
> homepage: http://www.education.wisc.edu/edpsych/facstaff/kaplan/kaplan.htm
> Phone: 608-262-0836
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Bill Pikounis
Statistician


From ral at lcfltd.com  Wed Sep 12 04:10:04 2007
From: ral at lcfltd.com (Robert A LaBudde)
Date: Tue, 11 Sep 2007 22:10:04 -0400
Subject: [R] Inferences for ratios of non-normal means
In-Reply-To: <597090.83803.qm@web32213.mail.mud.yahoo.com>
References: <6ade6f6c0709110238h4aa99089w7ec65e850186bc49@mail.gmail.com>
	<597090.83803.qm@web32213.mail.mud.yahoo.com>
Message-ID: <0JO800C8ZGOT2BR2@vms042.mailsrvcs.net>

I think a ratio of two normals has a Cauchy distribution, which 
doesn't have a variance (the singularity in the denominator), so the 
Central Limit theorem does not apply.

I would suggest using bootstrap resampling to make inferences.

At 08:10 PM 9/11/2007, Moshe wrote:
>For large samples you have asymptotic normality!
>
>--- Paul Smith <phhs80 at gmail.com> wrote:
>
> > Dear All,
> >
> > The package mratios can perform inferences for
> > ratios of normal means.
> > Is there some other package to do the same but with
> > non-normal
> > populations. Since I have got large samples, an
> > asymptotic procedure
> > would be fine.
> >
> > Thanks in advance,
> >
> > Paul
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained,
> > reproducible code.
> >
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From loesljrg at verizon.net  Wed Sep 12 05:21:12 2007
From: loesljrg at verizon.net (JRG)
Date: Tue, 11 Sep 2007 22:21:12 -0500
Subject: [R] Inferences for ratios of non-normal means
In-Reply-To: <0JO800C8ZGOT2BR2@vms042.mailsrvcs.net>
References: <6ade6f6c0709110238h4aa99089w7ec65e850186bc49@mail.gmail.com>,
	<597090.83803.qm@web32213.mail.mud.yahoo.com>,
	<0JO800C8ZGOT2BR2@vms042.mailsrvcs.net>
Message-ID: <46E714D8.19274.32C9B96@loesljrg.verizon.net>

On 11 Sep 2007 at 22:10, Robert A LaBudde wrote:

> I think a ratio of two normals has a Cauchy distribution, which 
> doesn't have a variance (the singularity in the denominator), so the 
> Central Limit theorem does not apply.
> 

The Cauchy results if the denominator normal distribution has mean = 0, but noth otherwise.





> I would suggest using bootstrap resampling to make inferences.
> 
> At 08:10 PM 9/11/2007, Moshe wrote:
> >For large samples you have asymptotic normality!
> >
> >--- Paul Smith <phhs80 at gmail.com> wrote:
> >
> > > Dear All,
> > >
> > > The package mratios can perform inferences for
> > > ratios of normal means.
> > > Is there some other package to do the same but with
> > > non-normal
> > > populations. Since I have got large samples, an
> > > asymptotic procedure
> > > would be fine.
> > >
> > > Thanks in advance,
> > >
> > > Paul
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained,
> > > reproducible code.
> > >
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> 
> ================================================================
> Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
> Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
> 824 Timberlake Drive                     Tel: 757-467-0954
> Virginia Beach, VA 23464-3239            Fax: 757-467-2947
> 
> "Vere scire est per causas scire"
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


John R. Gleason

Syracuse University
430 Huntington Hall                      Voice:   315-443-3107
Syracuse, NY 13244-2340  USA             FAX:     315-443-4085

PGP public key at keyservers


From scionforbai at gmail.com  Wed Sep 12 04:26:32 2007
From: scionforbai at gmail.com (Scionforbai)
Date: Wed, 12 Sep 2007 04:26:32 +0200
Subject: [R] off-topic: better OS for statistical computing
In-Reply-To: <1115a2b00709100922h7780644brc59e3f9c25760caf@mail.gmail.com>
References: <1115a2b00709100922h7780644brc59e3f9c25760caf@mail.gmail.com>
Message-ID: <e9ee1f0a0709111926w375a5effkc34e2139b46eaa67@mail.gmail.com>

> My question is what is the best OS on PC (laptop) for statistical
> computing and why.

A free/open source *nix operating system is the best you can have
todate, for almost everything, noticeably stability, security,
scalability, networking and development, given that your hardware is
supported and the system is well administrated. Since you're talking
about a laptop, Linux has the best hardware support right now, and
should be your choice.

Linux is *very* flexible, stable, and gives you some good admin habit.
Is the best choice for number crunching, large databases and heavy
development. You have all kind of programming languages, compilers and
scientific softwares just a few commands away (pacman -S R, apt-get
install R, yum install R and so on) and they integrate perfectly
within your system. On the other side, you should have a certain
insight of this OS (and in general of computing) to reach the best
performances your hardware can give; most of user-friendly
distributions are as bloated as windows, well, maybe just a little
less, and if you don't know (and are not interested in learning) how
to tweak them, you don't have great advantages in terms of
performances and desktop experience.

My experience (mostly in university/research labs) shows that if you
really have to get into 'not basic' computing, involving for example
c/fortran/c++ development along with R/matlab/mathematica ('high
level' languages), or using for some reason clusters or distribuited
resources, then you really want to work natively on linux. You can
script and control everything, just as you want it to be, in a very
simple way, from the jobs schedule to the graphic interfaces; this is
for me the best feature of linux. For some the problem is that linux
(and in general unix software) tends not to be 'visual'. That's true,
and I consider it a major feature, when it comes to heavy tasks with
large datasets: grep, sed, awk and perl will always perform better
than excel or visual basic macros... and the advantage of linux on the
windows ports of these tools is that the whole system is built around
them, and they integrate perfectly in the powerfull shell.

If you just need to draw some picture to summarize data, and put them
in a WYSIWYG report/presentation, then the OS is not the point. If you
need to use  specific proprietary apps only available for win or mac
(word/excel/powerpoint/photoshop/flash/arcview/autocad...) then you're
locked in in that platform, but hey, that's not statistical
computing...

In my humble opinion: linux is by far best suited for development and
scientific computing, given the skills to admin it and the freedom
from platform-specific software. Mac os X 'just works' and is
definitely better and more attractive to me than windows.


From m_olshansky at yahoo.com  Wed Sep 12 04:28:16 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Tue, 11 Sep 2007 19:28:16 -0700 (PDT)
Subject: [R] Inferences for ratios of non-normal means
In-Reply-To: <0JO800C8ZGOT2BR2@vms042.mailsrvcs.net>
Message-ID: <123546.40646.qm@web32202.mail.mud.yahoo.com>

It even does not have a mean, but this does not
matter: both the numerator and denominator are
asymptotically normal and so the ratio converges (in
distribution) to the ratio of two normals (which
indeed has a Cauchy distribution).

--- Robert A LaBudde <ral at lcfltd.com> wrote:

> I think a ratio of two normals has a Cauchy
> distribution, which 
> doesn't have a variance (the singularity in the
> denominator), so the 
> Central Limit theorem does not apply.
> 
> I would suggest using bootstrap resampling to make
> inferences.
> 
> At 08:10 PM 9/11/2007, Moshe wrote:
> >For large samples you have asymptotic normality!
> >
> >--- Paul Smith <phhs80 at gmail.com> wrote:
> >
> > > Dear All,
> > >
> > > The package mratios can perform inferences for
> > > ratios of normal means.
> > > Is there some other package to do the same but
> with
> > > non-normal
> > > populations. Since I have got large samples, an
> > > asymptotic procedure
> > > would be fine.
> > >
> > > Thanks in advance,
> > >
> > > Paul
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained,
> > > reproducible code.
> > >
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained,
> reproducible code.
> 
>
================================================================
> Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail:
> ral at lcfltd.com
> Least Cost Formulations, Ltd.            URL:
> http://lcfltd.com/
> 824 Timberlake Drive                     Tel:
> 757-467-0954
> Virginia Beach, VA 23464-3239            Fax:
> 757-467-2947
> 
> "Vere scire est per causas scire"
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From Jin.Li at ga.gov.au  Wed Sep 12 04:49:30 2007
From: Jin.Li at ga.gov.au (Jin.Li at ga.gov.au)
Date: Wed, 12 Sep 2007 12:49:30 +1000
Subject: [R] install R packages [SEC=UNCLASSIFIED]
Message-ID: <8BD19F29B0E16E4F88277A997CD872C202A29BFF@mail.ga.gov.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070912/8b720499/attachment.pl 

From sergeyg at gmail.com  Wed Sep 12 04:59:40 2007
From: sergeyg at gmail.com (Sergey Goriatchev)
Date: Wed, 12 Sep 2007 04:59:40 +0200
Subject: [R] Problem with integrate()
Message-ID: <7cb007bd0709111959x547c09aeie7f5cfac412cf2d9@mail.gmail.com>

Hello!

I have a problem with integrate() in my function nctspa(). Integrate
produces an error message "evaluation of function gave a result of
wrong length". I don't know what that means. Could anyone suggest me
what is wrong with my function?

These are the examples of function calls that work OK:
nctspa(a=1:10,n=5)
nctspa(a=1:10, n=5, mu=2, theta=3, renorm=0)

This does not work:
nctspa(a=1:10, n=5, mu=2, theta=3, renorm=1)

Many thanks in advance for your help!

/Sergey

Here is the function:
#Computes the s.p.a. to the doubly noncentral t at value x.
#degrees of freedom n, noncentrality parameters mu and theta.
#==========================================================#
nctspa <- function(a,n,mu=0,theta=0,renorm=0,rec=0){
#Pass renorm=1 to renormalize the SPA to the pdf.
#There is a last argument called rec. DO NOT PASS it!

alpha <- mu/sqrt((1+theta/n))
normconst <- 1
if(renorm==1 & rec==0){
	term1 <- integrate(nctspa, -Inf, alpha, n=n, mu=mu, theta=theta)$value
  	term2 <- integrate(nctspa, alpha, Inf, n=n, mu=mu, theta=theta)$value
  	normconst <- 1/(term1+term2)
}
cdf <- numeric()
pdf <- cdf
c3 <- n^2+2*n*a^2+a^4
c2 <- (-2*mu*(a^3+n*a))/c3
c1 <- (-n^2-n*a^2-n*theta+a^2*mu^2)/c3
c0 <- (n*a*mu)/c3
q <- c1/3-(c2^2)/9
r <- 1/6*(c1*c2-3*c0)-1/27*c2^3
b0 <- sqrt(-4*q)*cos(acos(r/sqrt(-q^3))/3)-c2/3
t1 <- -mu+a*b0
t2 <- -a*t1/b0/n/2
nu <- 1/(1-2*t2)
w <- sqrt(-mu*t1-n*log(nu)-2*theta*nu*t2)*sign(a-alpha)
u <- sqrt((a^2+2*n*t2)*(2*n*nu^2+4*theta*nu^3)+4*n^2*b0^2)/(2*n*b0^2)
pdf <- normconst*dnorm(w)/u

nz <- (abs(t1*b0)>=1e-10)
iz <- (abs(t1*b0)<=1e-10)
if(any(nz)){
	d <- numeric()
	d[nz] <- 1/(t1[nz]*b0[nz])
    	cdf[nz] <- pnorm(w[nz])+dnorm(w[nz])*(1/w[nz]-d[nz]/u[nz])
}
if(any(iz)){
	n <- sum(iz==1)
	rez <- nctspa(c(a[iz]-1e-4, a[iz]+1e-4),n,mu,theta,0,rec+1)
    	if(rec>5){
      	cdf[iz] <- 0.5
	warning('Too many recursions')
   	} else {
      	cdf[iz] <- 0.5*(rez$CDF[1:n]+rez$CDF[(n+1):length(rez$CDF)])
    	}
}
list(PDF=pdf, CDF=cdf)
}
#======================================================


From sergeyg at gmail.com  Wed Sep 12 05:09:12 2007
From: sergeyg at gmail.com (Sergey Goriatchev)
Date: Wed, 12 Sep 2007 05:09:12 +0200
Subject: [R] Integrate() error message, I am at a loss
Message-ID: <7cb007bd0709112009l4194948bweb9b34ef1fb354fe@mail.gmail.com>

Hello!

I have a problem with integrate() in my function nctspa(). Integrate
produces an error message "evaluation of function gave a result of
wrong length". I don't know what that means. Could anyone suggest me
what is wrong with my function?

These are the examples of function calls that work OK:
nctspa(a=1:10,n=5)
nctspa(a=1:10, n=5, mu=2, theta=3, renorm=0)

This does not work:
nctspa(a=1:10, n=5, mu=2, theta=3, renorm=1)

Many thanks in advance for your help!
please, send reply also to sergeyg at gmail.com

/Sergey

Here is the function:

#Computes the s.p.a. to the doubly noncentral t at value x.
#degrees of freedom n, noncentrality parameters mu and theta.
#==========================================================#
nctspa <- function(a,n,mu=0,theta=0,renorm=0,rec=0){
#Pass renorm=1 to renormalize the SPA to the pdf.
#There is a last argument called rec. DO NOT PASS it!

alpha <- mu/sqrt((1+theta/n))
normconst <- 1
if(renorm==1 & rec==0){
       term1 <- integrate(nctspa, -Inf, alpha, n=n, mu=mu, theta=theta)$value
       term2 <- integrate(nctspa, alpha, Inf, n=n, mu=mu, theta=theta)$value
       normconst <- 1/(term1+term2)
}
cdf <- numeric()
pdf <- cdf
c3 <- n^2+2*n*a^2+a^4
c2 <- (-2*mu*(a^3+n*a))/c3
c1 <- (-n^2-n*a^2-n*theta+a^2*mu^2)/c3
c0 <- (n*a*mu)/c3
q <- c1/3-(c2^2)/9
r <- 1/6*(c1*c2-3*c0)-1/27*c2^3
b0 <- sqrt(-4*q)*cos(acos(r/sqrt(-q^3))/3)-c2/3
t1 <- -mu+a*b0
t2 <- -a*t1/b0/n/2
nu <- 1/(1-2*t2)
w <- sqrt(-mu*t1-n*log(nu)-2*theta*nu*t2)*sign(a-alpha)
u <- sqrt((a^2+2*n*t2)*(2*n*nu^2+4*theta*nu^3)+4*n^2*b0^2)/(2*n*b0^2)
pdf <- normconst*dnorm(w)/u

nz <- (abs(t1*b0)>=1e-10)
iz <- (abs(t1*b0)<=1e-10)
if(any(nz)){
       d <- numeric()
       d[nz] <- 1/(t1[nz]*b0[nz])
       cdf[nz] <- pnorm(w[nz])+dnorm(w[nz])*(1/w[nz]-d[nz]/u[nz])
}
if(any(iz)){
       n <- sum(iz==1)
       rez <- nctspa(c(a[iz]-1e-4, a[iz]+1e-4),n,mu,theta,0,rec+1)
       if(rec>5){
       cdf[iz] <- 0.5
       warning('Too many recursions')
       } else {
       cdf[iz] <- 0.5*(rez$CDF[1:n]+rez$CDF[(n+1):length(rez$CDF)])
       }
}
list(PDF=pdf, CDF=cdf)
}
#======================================================


From reilly at stat.auckland.ac.nz  Wed Sep 12 05:13:42 2007
From: reilly at stat.auckland.ac.nz (James Reilly)
Date: Wed, 12 Sep 2007 15:13:42 +1200
Subject: [R] Missing data
In-Reply-To: <f4295a580709111833g21c48155yb3e15b32d1fc859@mail.gmail.com>
References: <46E70A2C.1070807@education.wisc.edu>
	<f4295a580709111833g21c48155yb3e15b32d1fc859@mail.gmail.com>
Message-ID: <46E75966.9050001@stat.auckland.ac.nz>

The mice package might also be useful, especially the md.pattern function:
http://finzi.psych.upenn.edu/R/library/mice/html/md.pattern.html

James
-- 
James Reilly
Department of Statistics, University of Auckland
Private Bag 92019, Auckland, New Zealand

On 12/9/07 1:33 PM, Bill Pikounis wrote:
> David,
> Frank Harrell's pair of packages Hmisc and Design has some functions
> for tabulating, visualizing, and accounting for missing data.  I
> recommend them as one avenue to investigate. Frank's companion book
> "Regression Modeling Strategies" covers their use in-depth.
> 
> Hope that helps,
> Bill
> 
> ___________
> Bill Pikounis
>  Statistician
> 
> On 9/11/07, David Kaplan <dkaplan at education.wisc.edu> wrote:
>> Hi all,
>>
>> I'm looking for a contributed package that can provide a detailed
>> account of missing data patterns and perhaps also provide imputation
>> procedures, such as mean imputation or hot deck imputation and the like.
>>   Is there anything out there?
>>
>> Thanks in advance,
>>
>> David
>>


From weigand.stephen at gmail.com  Wed Sep 12 05:20:45 2007
From: weigand.stephen at gmail.com (Stephen Weigand)
Date: Tue, 11 Sep 2007 22:20:45 -0500
Subject: [R] Inferences for ratios of non-normal means
In-Reply-To: <46E714D8.19274.32C9B96@loesljrg.verizon.net>
References: <6ade6f6c0709110238h4aa99089w7ec65e850186bc49@mail.gmail.com>
	<597090.83803.qm@web32213.mail.mud.yahoo.com>
	<0JO800C8ZGOT2BR2@vms042.mailsrvcs.net>
	<46E714D8.19274.32C9B96@loesljrg.verizon.net>
Message-ID: <bc47d3330709112020l2128ce6fvbc55285a48be825c@mail.gmail.com>

Paul,

On 9/11/07, JRG <loesljrg at verizon.net> wrote:
> On 11 Sep 2007 at 22:10, Robert A LaBudde wrote:
>
> > I think a ratio of two normals has a Cauchy distribution, which
> > doesn't have a variance (the singularity in the denominator), so the
> > Central Limit theorem does not apply.
> >
>
> The Cauchy results if the denominator normal distribution has mean = 0, but noth otherwise.
>
>
>
>
>
> > I would suggest using bootstrap resampling to make inferences.
> >
> > At 08:10 PM 9/11/2007, Moshe wrote:
> > >For large samples you have asymptotic normality!
> > >
> > >--- Paul Smith <phhs80 at gmail.com> wrote:
> > >
> > > > Dear All,
> > > >
> > > > The package mratios can perform inferences for
> > > > ratios of normal means.
> > > > Is there some other package to do the same but with
> > > > non-normal
> > > > populations. Since I have got large samples, an
> > > > asymptotic procedure
> > > > would be fine.
> > > >
> > > > Thanks in advance,
> > > >
> > > > Paul
> > > >
> >
> > ================================================================
> > Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
> > Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
> > 824 Timberlake Drive                     Tel: 757-467-0954
> > Virginia Beach, VA 23464-3239            Fax: 757-467-2947
> >
> > "Vere scire est per causas scire"
> >
> > ______________________________________________
>
>
> John R. Gleason
>
> Syracuse University
> 430 Huntington Hall                      Voice:   315-443-3107
> Syracuse, NY 13244-2340  USA             FAX:     315-443-4085
>
> PGP public key at keyservers
>

Also, in case you missed it, do

library(boot)
help(boot) # see first example re. ratio of means


From dkaplan at education.wisc.edu  Wed Sep 12 06:03:55 2007
From: dkaplan at education.wisc.edu (David Kaplan)
Date: Tue, 11 Sep 2007 23:03:55 -0500
Subject: [R] Missing data
In-Reply-To: <46E75966.9050001@stat.auckland.ac.nz>
References: <46E70A2C.1070807@education.wisc.edu>
	<f4295a580709111833g21c48155yb3e15b32d1fc859@mail.gmail.com>
	<46E75966.9050001@stat.auckland.ac.nz>
Message-ID: <46E7652B.5020708@education.wisc.edu>

Excellent.  Thanks!


=======================================================================
David Kaplan, Ph.D.
Professor
Department of Educational Psychology
University of Wisconsin - Madison
Educational Sciences, Room 1061
1025 W. Johnson Street
Madison, WI 53706

email: dkaplan at education.wisc.edu
Web:   http://www.education.wisc.edu/edpsych/facstaff/kaplan/kaplan.htm
Phone: 608-262-0836
Fax:   608-262-0843
=======================================================================


James Reilly wrote:
> The mice package might also be useful, especially the md.pattern function:
> http://finzi.psych.upenn.edu/R/library/mice/html/md.pattern.html
> 
> James


From hydes at byuh.edu  Wed Sep 12 06:06:58 2007
From: hydes at byuh.edu (Scott Hyde)
Date: Tue, 11 Sep 2007 18:06:58 -1000
Subject: [R] Create a "local" repository
Message-ID: <793e846d0709112106l5c97d393g573950a9d07556e2@mail.gmail.com>

I'd like to create a small "local" repository that would be used to
install a package for a class of students at their home.  I don't want
to upload it to CRAN, as I don't think it should be disseminated at
that level.

What I'd like to do is:

> where="http://mysite.com/"
> install.packages("mypackage",contriburl=where)

When I try this, (after placing my mypackage_1.0.tar.gz file in the
main directory of http://mysite.com/, it responds, in R, when I want
to install the package:

Warning: unable to access index for repository http://mysite.com/

What do I need to do?

-Scott

-- 
*****************************************************************
Scott K. Hyde
Assistant Professor of Statistics and Mathematics
School of Computing
Brigham Young University -- Hawaii


From steve at promente.org  Tue Sep 11 11:01:32 2007
From: steve at promente.org (Steve Powell)
Date: Tue, 11 Sep 2007 11:01:32 +0200
Subject: [R] Creating Hmisc labels inside a function
In-Reply-To: <mailman.7.1189418403.7853.r-help@stat.math.ethz.ch>
References: <mailman.7.1189418403.7853.r-help@stat.math.ethz.ch>
Message-ID: <019801c7f452$6211ae50$6501a8c0@STEVE>

hello list members,
I am wanting to write a label using the Hmisc package, but inside a
function. Normally I can do:

library(Hmisc)
M=2
label(M)="lab"

#But inside a function the "=" does not work:
Test=function(obj,labe)
{
label(obj)=labe
}

Test(M,"new label")

I usually use the "assign" function to make assignments inside functions,
but assign will not work with attributes, labels etc.
Any ideas?
Thanks in advance

Steve Powell

 
proMENTE social research 
research | evaluation | training & consulting 
Kranj?evi?eva 35, 71000 Sarajevo 
mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387 33 556 866
skype: stevepowell99 
www.promente.org  |  www.mojakarijera.com  |  www.psih.org  


Checked by AVG Free Edition. 

17:43


From tolga.uzuner at gmail.com  Tue Sep 11 18:56:31 2007
From: tolga.uzuner at gmail.com (Tolga Uzuner)
Date: Tue, 11 Sep 2007 19:56:31 +0300
Subject: [R] Help regading time series data reading
Message-ID: <20070911195631.mwucecxnevscoscc@mail.coubros.com>

Dear R-Users,

Have a question about reading in some data and manipulating dates. I  
have a data set in excel which looks like this:

Date                 PEG        ETN        HSP        PTC
13/10/2004        41.92        64.75        29.86        9.27
14/10/2004        41.93        61.79        29.98        9.14
15/10/2004        41.69        62.7        30.09        9.04
18/10/2004        41.37        62.14        30.39        8.96
19/10/2004        41.01        61.98        29.61        9.02
20/10/2004        41.01        61.98        30.25        9

I have used read.table by saving the sheety above in tab format to  
read this in but am
having some difficulties:
- the dates above do not seem to be getting read in in date format:  
how can I force this ?
- I actually have two, and not one data set, and would like to  
synchronise them by date
(exclude from both dates which are not in both): is there an easy way  
to do this ?

Thanks,
Tolga


From Todd.Remund at atk.com  Tue Sep 11 22:26:02 2007
From: Todd.Remund at atk.com (Remund, Todd)
Date: Tue, 11 Sep 2007 14:26:02 -0600
Subject: [R] Implementation of the butter() function for filtering.
Message-ID: <290C84AEAA27E5489BD772CB179E0863012778C4@ut40se02.atk.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070911/6faa4f5a/attachment.pl 

From Sumit.Gupta at ubs.com  Wed Sep 12 04:01:43 2007
From: Sumit.Gupta at ubs.com (Sumit.Gupta at ubs.com)
Date: Wed, 12 Sep 2007 03:01:43 +0100
Subject: [R] R: to view the memory
Message-ID: <C6EB3844F7C76A42965909494BB1779203630A8D@NLDNC104PEX1.ubsw.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070912/3b8cff47/attachment.pl 

From maechler at stat.math.ethz.ch  Wed Sep 12 09:13:33 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 12 Sep 2007 09:13:33 +0200
Subject: [R] R: to view the memory - and a quiz
In-Reply-To: <C6EB3844F7C76A42965909494BB1779203630A8D@NLDNC104PEX1.ubsw.net>
References: <C6EB3844F7C76A42965909494BB1779203630A8D@NLDNC104PEX1.ubsw.net>
Message-ID: <18151.37277.531997.220822@stat.math.ethz.ch>

>>>>>   <Sumit.Gupta at ubs.com>
>>>>>     on Wed, 12 Sep 2007 03:01:43 +0100 writes:

    > Hello, I am wondering if it is possible to view what
    > variables and vairable values are stored in the R
    > memory. This to enable debugging of R-scripts I write.

In simple to moderately small examples, I'd recommend (my own creation)

    ls.str()

I've lately started to use it also from inside a function,
i.e. after using debug(.) or after options(error = recover) and
a jump "inside a function" to explore the local variables of the
function I'm debugging. In that case, I use

   ls.str(envir = environment())

something which I've been using so frequently lately, that I had
started wondering a bit if some nice (short and simple!)
enhancement to ls.str() was possible which would make
   ls.str()  {without specifying  'envir = environment()'}
automagically use the "proper" environment when run inside a function.
Since then, I had never found the time to follow the idea,
we now have a quiz:  What's the best solution to the above problem?

Martin


From gavin.simpson at ucl.ac.uk  Wed Sep 12 09:36:13 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 12 Sep 2007 08:36:13 +0100
Subject: [R] Help regading time series data reading
In-Reply-To: <20070911195631.mwucecxnevscoscc@mail.coubros.com>
References: <20070911195631.mwucecxnevscoscc@mail.coubros.com>
Message-ID: <1189582573.2928.11.camel@graptoleberis.geog.ucl.ac.uk>

On Tue, 2007-09-11 at 19:56 +0300, Tolga Uzuner wrote:
> Dear R-Users,
> 
> Have a question about reading in some data and manipulating dates. I  
> have a data set in excel which looks like this:
> 
> Date                 PEG        ETN        HSP        PTC
> 13/10/2004        41.92        64.75        29.86        9.27
> 14/10/2004        41.93        61.79        29.98        9.14
> 15/10/2004        41.69        62.7        30.09        9.04
> 18/10/2004        41.37        62.14        30.39        8.96
> 19/10/2004        41.01        61.98        29.61        9.02
> 20/10/2004        41.01        61.98        30.25        9
> 
> I have used read.table by saving the sheety above in tab format to  
> read this in but am
> having some difficulties:
> - the dates above do not seem to be getting read in in date format:  
> how can I force this ?

For the first question (I'm not sure how to do the second):

We use read.table() to read in the data from file (here I saved your
data as tab delimited file 'temp.csv'. Argument as.is = TRUE is used to
stop R converting character strings (i.e. the Date column here) to
factors; this saves us a step later converting them back.

> dat <- read.table("temp.csv", sep = "\t", as.is = TRUE, header = TRUE)

Data read in OK:

> dat
        Date   PEG   ETN   HSP  PTC
1 13/10/2004 41.92 64.75 29.86 9.27
2 14/10/2004 41.93 61.79 29.98 9.14
3 15/10/2004 41.69 62.70 30.09 9.04
4 18/10/2004 41.37 62.14 30.39 8.96
5 19/10/2004 41.01 61.98 29.61 9.02
6 20/10/2004 41.01 61.98 30.25 9.00

Use as.Date() to convert the character strings to a vector of class
'Date'. The format argument tells R how the dates are formatted in the
character strings you just read in. The %d, %m bits etc are place
holders describing the date parts, but the "/" characters are literal -
if your dates were formatted "20-10-2004", you would use format = "%d-%
m-%Y". See ?strftime for how to specify 'format' if you have dates
formatted in other ways (say with month name instead of number).

> dat$Date <- as.Date(dat$Date, format = "%d/%m/%Y")

Note that now dat$Date is now an object of class 'Date':

> str(dat)
'data.frame':   6 obs. of  5 variables:
 $ Date:Class 'Date'  num [1:6] 12704 12705 12706 12709 12710 ...
 $ PEG : num  41.9 41.9 41.7 41.4 41.0 ...
 $ ETN : num  64.8 61.8 62.7 62.1 62.0 ...
 $ HSP : num  29.9 30.0 30.1 30.4 29.6 ...
 $ PTC : num  9.27 9.14 9.04 8.96 9.02 9

Which R will treat appropriately in plots for example:

> plot(PEG ~ Date, data = dat, type = "l")

HTH

G

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From ligges at statistik.uni-dortmund.de  Wed Sep 12 09:43:29 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 12 Sep 2007 09:43:29 +0200
Subject: [R] install R packages [SEC=UNCLASSIFIED]
In-Reply-To: <8BD19F29B0E16E4F88277A997CD872C202A29BFF@mail.ga.gov.au>
References: <8BD19F29B0E16E4F88277A997CD872C202A29BFF@mail.ga.gov.au>
Message-ID: <46E798A1.8000307@statistik.uni-dortmund.de>

Do you have to use some proxy server at your work? In that case, please 
read the R for Windows FAQs which tells how to arrange settings.

Uwe Ligges


Jin.Li at ga.gov.au wrote:
> Hi All,
> 
>  
> 
> I installed R 2.5.1 recently on a PC (Windows XP Professional 2001) and tried
> to install some R packages. It took several minutes and gave me the following
> message.
> 
>  
> 
>> utils:::menuInstallPkgs()
> 
> --- Please select a CRAN mirror for use in this session ---
> 
> Error in open.connection(file, "r") : unable to open connection
> 
> In addition: Warning message:
> 
> unable to connect to 'cran.r-project.org' on port 80. in:
> open.connection(file, "r") 
> 
> Error in contrib.url(repos, type) : trying to use CRAN without setting a
> mirror
> 
>  
> 
> I am just wondering whether this problem is caused by restrictions on
> internet imposed by my work unit or caused by something else. If the later,
> how to solve it? Thanks in advance.
> 
> Cheers,
> 
> Jin
> 
> --------------------------------------------
> 
> Jin Li, PhD
> 
> Spatial Modeller/
> 
> Computational Statistician
> 
> Marine & Coastal Environment
> 
> Geoscience Australia
> 
> Ph: 61 (02) 6249 9899
> 
> Fax: 61 (02) 6249 9956
> 
> email: jin.li at ga.gov.au
> 
> --------------------------------------------
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.uni-dortmund.de  Wed Sep 12 09:50:57 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 12 Sep 2007 09:50:57 +0200
Subject: [R] Create a "local" repository
In-Reply-To: <793e846d0709112106l5c97d393g573950a9d07556e2@mail.gmail.com>
References: <793e846d0709112106l5c97d393g573950a9d07556e2@mail.gmail.com>
Message-ID: <46E79A61.5000602@statistik.uni-dortmund.de>



Scott Hyde wrote:
> I'd like to create a small "local" repository that would be used to
> install a package for a class of students at their home.  I don't want
> to upload it to CRAN, as I don't think it should be disseminated at
> that level.
> 
> What I'd like to do is:
> 
>> where="http://mysite.com/"
>> install.packages("mypackage",contriburl=where)
> 
> When I try this, (after placing my mypackage_1.0.tar.gz file in the
> main directory of http://mysite.com/, it responds, in R, when I want
> to install the package:
> 
> Warning: unable to access index for repository http://mysite.com/
> 
> What do I need to do?

You need a PACKAGES file in that directory that gives an index which 
packages are available.

See function write_PACKAGES() in package "tools".

Uwe Ligges


> 
> -Scott
>


From ritz at life.ku.dk  Wed Sep 12 10:12:31 2007
From: ritz at life.ku.dk (Christian Ritz)
Date: Wed, 12 Sep 2007 10:12:31 +0200
Subject: [R]  plot vs curve
Message-ID: <46E79F6F.2000403@life.ku.dk>

Dear list members,

is it intentional that:


curve(cos, xlim = c(-5, 5))
plot(cos, xlim = c(-5, 5))


produce different plots?

Shouldn't the 'xlim' argument in both cases set the 'from' and 'to' argument if they 
aren't supplied (at least that's what I understood reading the help page for 'curve' and 
'plot.function')?


Christian




 > sessionInfo()
R version 2.5.1 (2007-06-27)
i386-pc-mingw32

locale:
LC_COLLATE=Danish_Denmark.1252;LC_CTYPE=Danish_Denmark.1252;LC_MONETARY=Danish_Denmark.1252;LC_NUMERIC=C;LC_TIME=Danish_Denmark.1252

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
[7] "base"

other attached packages:
       car       drc   plotrix      nlme      MASS   lattice
   "1.2-1"   "1.2-3"   "2.2-4"  "3.1-83"  "7.2-34" "0.15-11"


From jim at bitwrit.com.au  Wed Sep 12 10:36:29 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 12 Sep 2007 18:36:29 +1000
Subject: [R] why I cannot change the font and use hot-key in Editor of
 JGR	1.5-6
In-Reply-To: <46E696AC.1000506@gmail.com>
References: <46E696AC.1000506@gmail.com>
Message-ID: <46E7A50D.5010803@bitwrit.com.au>

Xingwang Ye wrote:
> Dear R users,
> Yesterday, I updated R 2.4.1 to R 2.5.1  on Unbuntu 7.0.4 successfully. 
> I also update the JGR to 1.5-6 according to 
> http://rosuda.org/JGR/linux.shtml (after "sudo update-java-alternatives 
> -s java-6-sun", I cannot do "sudo update-java-alternatives -s 
> java-1.6.0-sun"). I can use the JGR console normally.
> 
> however, I cannot use hot-key such as "ctrl+r" in the Editor, if I use 
> it, the selected contents are replaced by "r", it seems that "ctrl" does 
> not act, whereas I can use mouse to click the "run selection ctrl + r" 
> in menu.
> 
> Another problem is that I can change the font in the console but not in 
> the Editor.
> 
> Could some one help me to solve them? thank you in advance.
> 
Hi Xingwang,
This is pure guessing, but I have noticed with NEdit that if I 
inadvertantly hit the Caps Lock key, the Alt-<letter> combinations stop 
working and the letter appears as if I had typed it. As soon as I turn 
off Caps Lock, the problem disappears.

Jim


From aznarte at ugr.es  Wed Sep 12 10:32:38 2007
From: aznarte at ugr.es (=?ISO-8859-1?Q?=22Jos=E9_Luis_Aznarte_M=2E=22?=)
Date: Wed, 12 Sep 2007 10:32:38 +0200
Subject: [R] Passing parameters to 'optim' fn function
Message-ID: <46E7A426.5070302@ugr.es>

    Hi again! I'm using the 'optim' method to fix the parameters of a 
model. I have written the function to be minimised and another function 
which returns the gradient of the error. Now my problem is that, in 
order to compute that gradient, it would be extremely convenient to be 
able to pass some parameters to the gradient function. I don't see how 
to do it given the fixed syntax of 'optim', which does not allow for 
parameters being passed to fn and gr:

 > optim(par, fn, gr = NULL, ...)

    Of course the first idea would be to "pack" the extra parameters in 
the vector 'par', but in that case the extra parameters would be 
optimized too.
    Does anyone have an idea on how to pass parameters to gr in optim? 
Thanks for your time!


From petr.pikal at precheza.cz  Wed Sep 12 10:52:49 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Wed, 12 Sep 2007 10:52:49 +0200
Subject: [R] Help regading time series data reading
In-Reply-To: <1189582573.2928.11.camel@graptoleberis.geog.ucl.ac.uk>
Message-ID: <OF78AAE773.CD269C20-ONC1257354.0030850E-C1257354.0030C903@precheza.cz>

r-help-bounces at r-project.org napsal dne 12.09.2007 09:36:13:

> On Tue, 2007-09-11 at 19:56 +0300, Tolga Uzuner wrote:
> > Dear R-Users,
> > 
> > Have a question about reading in some data and manipulating dates. I 
> > have a data set in excel which looks like this:
> > 
> > Date                 PEG        ETN        HSP        PTC
> > 13/10/2004        41.92        64.75        29.86        9.27
> > 14/10/2004        41.93        61.79        29.98        9.14
> > 15/10/2004        41.69        62.7        30.09        9.04
> > 18/10/2004        41.37        62.14        30.39        8.96
> > 19/10/2004        41.01        61.98        29.61        9.02
> > 20/10/2004        41.01        61.98        30.25        9
> > 
> > I have used read.table by saving the sheety above in tab format to 
> > read this in but am
> > having some difficulties:
> > - the dates above do not seem to be getting read in in date format: 
> > how can I force this ?
> 
> For the first question (I'm not sure how to do the second):

Most probably merge can do the requested synchronization, especially with 
all.** parametrs.

Regards
Petr

> 
> We use read.table() to read in the data from file (here I saved your
> data as tab delimited file 'temp.csv'. Argument as.is = TRUE is used to
> stop R converting character strings (i.e. the Date column here) to
> factors; this saves us a step later converting them back.
> 
> > dat <- read.table("temp.csv", sep = "\t", as.is = TRUE, header = TRUE)
> 
> Data read in OK:
> 
> > dat
>         Date   PEG   ETN   HSP  PTC
> 1 13/10/2004 41.92 64.75 29.86 9.27
> 2 14/10/2004 41.93 61.79 29.98 9.14
> 3 15/10/2004 41.69 62.70 30.09 9.04
> 4 18/10/2004 41.37 62.14 30.39 8.96
> 5 19/10/2004 41.01 61.98 29.61 9.02
> 6 20/10/2004 41.01 61.98 30.25 9.00
> 
> Use as.Date() to convert the character strings to a vector of class
> 'Date'. The format argument tells R how the dates are formatted in the
> character strings you just read in. The %d, %m bits etc are place
> holders describing the date parts, but the "/" characters are literal -
> if your dates were formatted "20-10-2004", you would use format = "%d-%
> m-%Y". See ?strftime for how to specify 'format' if you have dates
> formatted in other ways (say with month name instead of number).
> 
> > dat$Date <- as.Date(dat$Date, format = "%d/%m/%Y")
> 
> Note that now dat$Date is now an object of class 'Date':
> 
> > str(dat)
> 'data.frame':   6 obs. of  5 variables:
>  $ Date:Class 'Date'  num [1:6] 12704 12705 12706 12709 12710 ...
>  $ PEG : num  41.9 41.9 41.7 41.4 41.0 ...
>  $ ETN : num  64.8 61.8 62.7 62.1 62.0 ...
>  $ HSP : num  29.9 30.0 30.1 30.4 29.6 ...
>  $ PTC : num  9.27 9.14 9.04 8.96 9.02 9
> 
> Which R will treat appropriately in plots for example:
> 
> > plot(PEG ~ Date, data = dat, type = "l")
> 
> HTH
> 
> G
> 
> -- 
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>  Gavin Simpson                 [t] +44 (0)20 7679 0522
>  ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
>  Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
>  Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
>  UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.hankin at noc.soton.ac.uk  Wed Sep 12 10:53:01 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Wed, 12 Sep 2007 09:53:01 +0100
Subject: [R] Passing parameters to 'optim' fn function
In-Reply-To: <46E7A426.5070302@ugr.es>
References: <46E7A426.5070302@ugr.es>
Message-ID: <22DFBDD9-B87A-4A42-9957-96431851FFD5@noc.soton.ac.uk>

Hi

Use the dots argument at the end to pass in named parameters.
This is documented as the last in the argument list under ?optim.


Here's a toy example using x and p:

 > f <- function(x,p){sum(x^2)+p*sum(x)}
 > gr <- function(x,p){2*x+p*rep(1,length(x))}
 > optim(par=c(10,10),fn=f,gr=gr,p=13)
$par
[1] -6.498188 -6.499652

$value
[1] -84.5

$counts
function gradient
       63       NA

$convergence
[1] 0

$message
NULL


HTH

rksh


On 12 Sep 2007, at 09:32, Jos? Luis Aznarte M. wrote:

>     Hi again! I'm using the 'optim' method to fix the parameters of a
> model. I have written the function to be minimised and another  
> function
> which returns the gradient of the error. Now my problem is that, in
> order to compute that gradient, it would be extremely convenient to be
> able to pass some parameters to the gradient function. I don't see how
> to do it given the fixed syntax of 'optim', which does not allow for
> parameters being passed to fn and gr:
>
>> optim(par, fn, gr = NULL, ...)
>
>     Of course the first idea would be to "pack" the extra  
> parameters in
> the vector 'par', but in that case the extra parameters would be
> optimized too.
>     Does anyone have an idea on how to pass parameters to gr in optim?
> Thanks for your time!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From dimitris.rizopoulos at med.kuleuven.be  Wed Sep 12 11:00:05 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 12 Sep 2007 11:00:05 +0200
Subject: [R] Passing parameters to 'optim' fn function
References: <46E7A426.5070302@ugr.es>
Message-ID: <009c01c7f51b$50049c30$0540210a@www.domain>

you need to use the `...' argument; look at ?optim() for more info.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: ""Jos? Luis Aznarte M."" <aznarte at ugr.es>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, September 12, 2007 10:32 AM
Subject: [R] Passing parameters to 'optim' fn function


>    Hi again! I'm using the 'optim' method to fix the parameters of a
> model. I have written the function to be minimised and another 
> function
> which returns the gradient of the error. Now my problem is that, in
> order to compute that gradient, it would be extremely convenient to 
> be
> able to pass some parameters to the gradient function. I don't see 
> how
> to do it given the fixed syntax of 'optim', which does not allow for
> parameters being passed to fn and gr:
>
> > optim(par, fn, gr = NULL, ...)
>
>    Of course the first idea would be to "pack" the extra parameters 
> in
> the vector 'par', but in that case the extra parameters would be
> optimized too.
>    Does anyone have an idea on how to pass parameters to gr in 
> optim?
> Thanks for your time!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From ligges at statistik.uni-dortmund.de  Wed Sep 12 11:51:24 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 12 Sep 2007 11:51:24 +0200
Subject: [R] building with atlas version of blas and lapack
In-Reply-To: <20070911202535.GE18752@jdmlab.mskcc.org>
References: <bfb1b6d20709111256q4fc53273hb5f9245a480ba77f@mail.gmail.com>
	<20070911202535.GE18752@jdmlab.mskcc.org>
Message-ID: <46E7B69C.9080409@statistik.uni-dortmund.de>



Yuelin Li wrote:
> On my linux machine (Ubuntu Feisty on i-686) this works:
> 
>      ./configure --with-blas="lf77blas -latlas"


Flags should be
   --with-blas="-L/usr/local/atlas/lib -lf77blas -latlas"
I guess, because /usr/local/atlas/lib is not found unless some 
environment variables have been set. This is documented in the R 
Installation and Administration manual, so you probably overlooked it.

Uwe Ligges


> Yuelin.
> 
> -- K Vanw wrote --|Tue (Sep/11/2007)[03:56]|--:
>    I'd like to build R using my optimized blas and lapack libraries. It seems
>    know matter what I do, the configure script uses the blas supplied with the
>    source. My blas and lapack libraries are in /usr/local/atlas/lib. How can I
>    get configure to use these?
>    
>    	[[alternative HTML version deleted]]
>    
>    ______________________________________________
>    R-help at r-project.org mailing list
>    https://stat.ethz.ch/mailman/listinfo/r-help
>    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>    and provide commented, minimal, self-contained, reproducible code.
>    
> 
>  
>      =====================================================================
>      
>      Please note that this e-mail and any files transmitted with it may be 
>      privileged, confidential, and protected from disclosure under 
>      applicable law. If the reader of this message is not the intended 
>      recipient, or an employee or agent responsible for delivering this 
>      message to the intended recipient, you are hereby notified that any 
>      reading, dissemination, distribution, copying, or other use of this 
>      communication or any of its attachments is strictly prohibited.  If 
>      you have received this communication in error, please notify the 
>      sender immediately by replying to this message and deleting this 
>      message, any attachments, and all copies and backups from your 
>      computer.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch at stats.uwo.ca  Wed Sep 12 12:28:07 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 12 Sep 2007 06:28:07 -0400
Subject: [R] plot vs curve
In-Reply-To: <46E79F6F.2000403@life.ku.dk>
References: <46E79F6F.2000403@life.ku.dk>
Message-ID: <46E7BF37.20002@stats.uwo.ca>

Christian Ritz wrote:
> Dear list members,
>
> is it intentional that:
>
>
> curve(cos, xlim = c(-5, 5))
> plot(cos, xlim = c(-5, 5))
>
>
> produce different plots?
>
> Shouldn't the 'xlim' argument in both cases set the 'from' and 'to' argument if they 
> aren't supplied (at least that's what I understood reading the help page for 'curve' and 
> 'plot.function')?
>   

Yes, that's a bug in plot().  It sets the default for from and to before 
it checks whether xlim was supplied.  I'll fix it.

Duncan Murdoch
>
> Christian
>
>
>
>
>  > sessionInfo()
> R version 2.5.1 (2007-06-27)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=Danish_Denmark.1252;LC_CTYPE=Danish_Denmark.1252;LC_MONETARY=Danish_Denmark.1252;LC_NUMERIC=C;LC_TIME=Danish_Denmark.1252
>
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> [7] "base"
>
> other attached packages:
>        car       drc   plotrix      nlme      MASS   lattice
>    "1.2-1"   "1.2-3"   "2.2-4"  "3.1-83"  "7.2-34" "0.15-11"
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch at stats.uwo.ca  Wed Sep 12 12:36:14 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 12 Sep 2007 06:36:14 -0400
Subject: [R] Passing parameters to 'optim' fn function
In-Reply-To: <46E7A426.5070302@ugr.es>
References: <46E7A426.5070302@ugr.es>
Message-ID: <46E7C11E.5070309@stats.uwo.ca>

Jos? Luis Aznarte M. wrote:
>     Hi again! I'm using the 'optim' method to fix the parameters of a 
> model. I have written the function to be minimised and another function 
> which returns the gradient of the error. Now my problem is that, in 
> order to compute that gradient, it would be extremely convenient to be 
> able to pass some parameters to the gradient function. I don't see how 
> to do it given the fixed syntax of 'optim', which does not allow for 
> parameters being passed to fn and gr:
>
>  > optim(par, fn, gr = NULL, ...)
>
>     Of course the first idea would be to "pack" the extra parameters in 
> the vector 'par', but in that case the extra parameters would be 
> optimized too.
>     Does anyone have an idea on how to pass parameters to gr in optim? 
> Thanks for your time!
>   

You can put the parameters in the ... argument (watch out for matches to 
earlier optim args!), or into the environments of fn and gr.  For example,

makefn <- function(x) {
  fn <- function(mu) sum((x-mu)^2)
  gr <- function(mu) sum(2*(mu-x))
  list(fn = fn, gr = gr)
}
x <- rnorm(10)
fg <- makefn(x)
optim(1, fg$fn, fg$gr)

Duncan Murdoch


From schaefer at pointone.de  Wed Sep 12 11:08:15 2007
From: schaefer at pointone.de (=?ISO-8859-1?Q?Christian_Sch=E4fer?=)
Date: Wed, 12 Sep 2007 11:08:15 +0200
Subject: [R] Error handling
Message-ID: <46E7AC7F.4080503@pointone.de>

Hi,

is there a possibility to catch an occurring error and do an appropriate 
error handling? (like the "try-catch"-statement in other programming 
languages)

For example:
It's quite annoying to run a script for hours only to detect an abortion 
of the script because of an "subscript out of bounds" error. In that 
case I would like to react accordingly, i.e. by skipping the actual step 
in the for-loop, or so.

Thanks,
Chris


From pifferi at sissa.it  Wed Sep 12 12:33:30 2007
From: pifferi at sissa.it (Simone Pifferi)
Date: Wed, 12 Sep 2007 12:33:30 +0200
Subject: [R] stastistical test on normalized data
Message-ID: <006701c7f528$5ef797d0$9cc87a93@biophysics.bp.sissa.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070912/58f88db1/attachment.pl 

From ah06981 at studbocconi.it  Wed Sep 12 12:51:41 2007
From: ah06981 at studbocconi.it (ah06981 at studbocconi.it)
Date: Wed, 12 Sep 2007 12:51:41 +0200
Subject: [R] enquiry
Message-ID: <20070912125141.zrrp9e6v40cgcw8s@webmail.studbocconi.it>

Dear R-help,

I am trying to estimate a Cox model with nested effects basing on the 
minimization of the overall AIC; I have two frailties terms, both gamma 
distributed.  There is a error message (theta2 argument  misses) and I 
don?t understand why. I would like to know what I have wrong. Thank you 
very much for your time.


fitM7 <- coxph(Surv(lifespan,censured) ~ south + frailty(id, 
dist='gamma')+ frailty(mob, dist='gamma'), data= usa)


tempfun <- function(theta1, theta2) {

fit <- coxph(Surv(lifespan,censured) ~ south + frailty(id, 
dist='gamma', sparse= TRUE, theta=theta1)+ frailty(mob, dist='gamma', 
sparse =TRUE, theta=theta2), data=usa)
aic <- (fit$loglik[2] - fit$loglik[1]) - sum(fit$df)
return(2*aic)
}
nlminb(c(theta1=3.2,theta2=.2), tempfun)




Error in (get(temp))(x, ...) : argument "theta2" is missing, with no default

Best,
Silvia


From murdoch at stats.uwo.ca  Wed Sep 12 13:02:09 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 12 Sep 2007 07:02:09 -0400
Subject: [R] Error handling
In-Reply-To: <46E7AC7F.4080503@pointone.de>
References: <46E7AC7F.4080503@pointone.de>
Message-ID: <46E7C731.5030502@stats.uwo.ca>

On 12/09/2007 5:08 AM, Christian Sch?fer wrote:
> Hi,
> 
> is there a possibility to catch an occurring error and do an appropriate 
> error handling? (like the "try-catch"-statement in other programming 
> languages)

You could use the tryCatch() function (or try(), a simplified wrapper).

Duncan Murdoch
> 
> For example:
> It's quite annoying to run a script for hours only to detect an abortion 
> of the script because of an "subscript out of bounds" error. In that 
> case I would like to react accordingly, i.e. by skipping the actual step 
> in the for-loop, or so.
> 
> Thanks,
> Chris
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From phhs80 at gmail.com  Wed Sep 12 13:02:48 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Wed, 12 Sep 2007 12:02:48 +0100
Subject: [R] Inferences for ratios of non-normal means
In-Reply-To: <6ade6f6c0709110238h4aa99089w7ec65e850186bc49@mail.gmail.com>
References: <6ade6f6c0709110238h4aa99089w7ec65e850186bc49@mail.gmail.com>
Message-ID: <6ade6f6c0709120402h52108dd8y1dd72a6401739fae@mail.gmail.com>

On 9/11/07, Paul Smith <phhs80 at gmail.com> wrote:
> The package mratios can perform inferences for ratios of normal means.
> Is there some other package to do the same but with non-normal
> populations. Since I have got large samples, an asymptotic procedure
> would be fine.

Thanks for all replies. I am a bit confused with your replies: some of
you maintain that mratios can be used with large samples of non-normal
populations whereas others direct me to use bootstrap.

Paul


From wl2776 at gmail.com  Wed Sep 12 13:26:15 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Wed, 12 Sep 2007 04:26:15 -0700 (PDT)
Subject: [R] enquiry
In-Reply-To: <20070912125141.zrrp9e6v40cgcw8s@webmail.studbocconi.it>
References: <20070912125141.zrrp9e6v40cgcw8s@webmail.studbocconi.it>
Message-ID: <12633376.post@talk.nabble.com>




ah06981 wrote:
> 
> Dear R-help,
> 
> I am trying to estimate a Cox model with nested effects basing on the 
> minimization of the overall AIC; I have two frailties terms, both gamma 
> distributed.  There is a error message (theta2 argument  misses) and I 
> don?t understand why. I would like to know what I have wrong. Thank you 
> very much for your time.
> 
> 
> fitM7 <- coxph(Surv(lifespan,censured) ~ south + frailty(id, 
> dist='gamma')+ frailty(mob, dist='gamma'), data= usa)
> 
> 
> tempfun <- function(theta1, theta2) {
> 
> fit <- coxph(Surv(lifespan,censured) ~ south + frailty(id, 
> dist='gamma', sparse= TRUE, theta=theta1)+ frailty(mob, dist='gamma', 
> sparse =TRUE, theta=theta2), data=usa)
> aic <- (fit$loglik[2] - fit$loglik[1]) - sum(fit$df)
> return(2*aic)
> }
> nlminb(c(theta1=3.2,theta2=.2), tempfun)
> 
> Error in (get(temp))(x, ...) : argument "theta2" is missing, with no
> default
> 
> Best,
> Silvia
> 

You need to 
(1) either rewrite your function to accept a single argument and treat it as
a numeric vector:

tempfun <- function(thetas) {
theta1<-thetas[1]
theta2<-thetas[2]

<the rest of function code>
}

(2) or change the call to nlminb:
nlminb(3.2, tempfun,theta2=.2)

But, I suspect, the optimization in this case will be only on theta1.

-- 
View this message in context: http://www.nabble.com/enquiry-tf4428517.html#a12633376
Sent from the R help mailing list archive at Nabble.com.


From ptit_bleu at yahoo.fr  Wed Sep 12 13:45:33 2007
From: ptit_bleu at yahoo.fr (Ptit_Bleu)
Date: Wed, 12 Sep 2007 04:45:33 -0700 (PDT)
Subject: [R] [solved] Re: I can't do it again on an other PC : R+RMySQL
 ->error loading dll
In-Reply-To: <12611132.post@talk.nabble.com>
References: <12592576.post@talk.nabble.com> <12610089.post@talk.nabble.com>
	<46E654B3.5060103@biostat.ku.dk>
	<12610981.post@talk.nabble.com> <12611132.post@talk.nabble.com>
Message-ID: <12633728.post@talk.nabble.com>


Hi Vladimir,

In fact, at the beginning, I tried to install RODBC and the MySQL driver but
I did not manage (I think due to the driver and the configuration in the
control panel). Then I tried to install RMySQL and DBI on my PC (not the one
with the "real" database), and it worked without any problem. So I keep
working with RMySQL.

You think there are advantages to try again installing RODBC ?

Anyway, for the moment, I think I will continue with RMySQL, just because it
works. But for me it is a good reason (especially because I'm not a
specialist of PCs and I don't have the time to become one. I'm only an
end-user).

Have a nice day,
Ptit Bleu.



Vladimir Eremeev wrote:
> 
> Do you need precisely RMySQL and DBI? 
> RODBC can successfully replace this.
> 
> I used RMySQL some time ago, but then, after the next version upgrade it
> stopped working.
> 
> Switching to RODBC was almost without pain, since function names were
> quite similar.
> I simply replaced dbGetQuery with sqlGetQuery in my script and voilia.
> 
> However, you need to install the MySQL ODBC driver and set up a data
> source in the Windows Control Panel before.
> 
> 
> Ptit_Bleu wrote:
>> 
>> 
>> I really have no idea about your comment. I was so happy to be able to
>> connect to my database ... 
>> 
>> In fact I found the address in the following post :
>> https://stat.ethz.ch/pipermail/r-help/2007-August/138142.html
>> 
>> Do you think I can't use it freely ? :(
>> 
>> Thanks for your comments,
>> Ptit Bleu.
>> 
>> 
>> Peter Dalgaard wrote:
>>> 
>>> 
>>> Umm, that looks more than a bit unofficial (parent directory read
>>> protected, no hint of an RMySQL package elsewhere on the site).  Are you
>>> sure that this is intended for redistribution? It sounds like it bundles
>>> in some MySQL libraries, which could imply legal issues.
>>> 
>>> 
>> 
>> 
> 
> 

-- 
View this message in context: http://www.nabble.com/I-can%27t-do-it-again-on-an-other-PC-%3A-R%2BRMySQL--%3Eerror-loading-dll-tf4414597.html#a12633728
Sent from the R help mailing list archive at Nabble.com.


From ggrothendieck at gmail.com  Wed Sep 12 13:52:07 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 12 Sep 2007 07:52:07 -0400
Subject: [R] Help regading time series data reading
In-Reply-To: <20070911195631.mwucecxnevscoscc@mail.coubros.com>
References: <20070911195631.mwucecxnevscoscc@mail.coubros.com>
Message-ID: <971536df0709120452p737bd023nc0fb34b19a7c12d8@mail.gmail.com>

Try using the zoo package like this:

Lines <- " Date                 PEG        ETN        HSP        PTC
13/10/2004        41.92        64.75        29.86        9.27
14/10/2004        41.93        61.79        29.98        9.14
15/10/2004        41.69        62.7        30.09        9.04
18/10/2004        41.37        62.14        30.39        8.96
19/10/2004        41.01        61.98        29.61        9.02
20/10/2004        41.01        61.98        30.25        9
"

Lines2 <- " Date       A       B
13/10/2004        64.75        29.86
15/10/2004        62.7        30.09
19/10/2004        61.98        29.61
"

library(zoo)
# replace with a line such as:
# z <- read.zoo("myfile.dat", header = TRUE, format = "%d/%m/%Y")
z <- read.zoo(textConnection(Lines), header = TRUE, format = "%d/%m/%Y")

# replace with a line such as:
# z <- read.zoo("myfile2.dat", header = TRUE, format = "%d/%m/%Y")
z2 <- read.zoo(textConnection(Lines2), header = TRUE, format = "%d/%m/%Y")

both <- merge(z, z2)  # this uses merge.zoo
plot(na.approx(both))


To learn more about zoo try:
  vignette("zoo")
  vignette("zoo-quickref")
and to learn about dates read the help desk in R News 4/1
by googling for CRAN News


On 9/11/07, Tolga Uzuner <tolga.uzuner at gmail.com> wrote:
> Dear R-Users,
>
> Have a question about reading in some data and manipulating dates. I
> have a data set in excel which looks like this:
>
> Date                 PEG        ETN        HSP        PTC
> 13/10/2004        41.92        64.75        29.86        9.27
> 14/10/2004        41.93        61.79        29.98        9.14
> 15/10/2004        41.69        62.7        30.09        9.04
> 18/10/2004        41.37        62.14        30.39        8.96
> 19/10/2004        41.01        61.98        29.61        9.02
> 20/10/2004        41.01        61.98        30.25        9
>
> I have used read.table by saving the sheety above in tab format to
> read this in but am
> having some difficulties:
> - the dates above do not seem to be getting read in in date format:
> how can I force this ?
> - I actually have two, and not one data set, and would like to
> synchronise them by date
> (exclude from both dates which are not in both): is there an easy way
> to do this ?
>
> Thanks,
> Tolga
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wl2776 at gmail.com  Wed Sep 12 14:12:02 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Wed, 12 Sep 2007 05:12:02 -0700 (PDT)
Subject: [R] [solved] Re: I can't do it again on an other PC : R+RMySQL
 ->error loading dll
In-Reply-To: <12633728.post@talk.nabble.com>
References: <12592576.post@talk.nabble.com> <12610089.post@talk.nabble.com>
	<46E654B3.5060103@biostat.ku.dk>
	<12610981.post@talk.nabble.com> <12611132.post@talk.nabble.com>
	<12633728.post@talk.nabble.com>
Message-ID: <12634122.post@talk.nabble.com>


Hi!
In my case, advantages of using RODBC are in the fact that it is working,
and is getting updated on a regular basis. Nothing more. :)

I also had some difficulties to set up the DSN, old Windows NT 4.0 required
couple of restarts, and guessing correct 'magic' line to make MS Excel to
retrieve the data was difficult. The procedure is simplified in Win2000/XP.

I have MySQL ODBC 3.51 Driver installed.
Then I go to Start -> Control Panel -> Administrative Tools, double-click on
'Data sources (ODBC)', click
'Add' in the opened window, choose 'MySQL ODBC 3.51 Driver' from the list,
enter host name, database name, user name and password. Port is 3306 by
default.
Then pressing 'Test Data source' shows if everything is set up correctly.
MySQL also have to be configured to allow connections.

RODBC also contains the file with the comprehensive instructions
(R_HOME/Library/RODBC/Readme).


Ptit_Bleu wrote:
> 
> Hi Vladimir,
> 
> In fact, at the beginning, I tried to install RODBC and the MySQL driver
> but I did not manage (I think due to the driver and the configuration in
> the control panel). Then I tried to install RMySQL and DBI on my PC (not
> the one with the "real" database), and it worked without any problem. So I
> keep working with RMySQL.
> 
> You think there are advantages to try again installing RODBC ?
> 
> Anyway, for the moment, I think I will continue with RMySQL, just because
> it works. But for me it is a good reason (especially because I'm not a
> specialist of PCs and I don't have the time to become one. I'm only an
> end-user).
> 
> Have a nice day,
> Ptit Bleu.
> 
> 
> 
> Vladimir Eremeev wrote:
>> 
>> Do you need precisely RMySQL and DBI? 
>> RODBC can successfully replace this.
>> 
>> I used RMySQL some time ago, but then, after the next version upgrade it
>> stopped working.
>> 
>> Switching to RODBC was almost without pain, since function names were
>> quite similar.
>> I simply replaced dbGetQuery with sqlGetQuery in my script and voilia.
>> 
>> However, you need to install the MySQL ODBC driver and set up a data
>> source in the Windows Control Panel before.
>> 
>> 
> 
> 

-- 
View this message in context: http://www.nabble.com/I-can%27t-do-it-again-on-an-other-PC-%3A-R%2BRMySQL--%3Eerror-loading-dll-tf4414597.html#a12634122
Sent from the R help mailing list archive at Nabble.com.


From rhelp.stats at gmail.com  Wed Sep 12 14:28:10 2007
From: rhelp.stats at gmail.com (R Help)
Date: Wed, 12 Sep 2007 09:28:10 -0300
Subject: [R] R: to view the memory
In-Reply-To: <C6EB3844F7C76A42965909494BB1779203630A8D@NLDNC104PEX1.ubsw.net>
References: <C6EB3844F7C76A42965909494BB1779203630A8D@NLDNC104PEX1.ubsw.net>
Message-ID: <c84ed6950709120528t44c7af65m1f30509b692a6bce@mail.gmail.com>

the function ls() will list all the variables currently in the memory.
 To get their values, you'll also need to use the parse and eval
functions.  Try the following:

x = ls()
for(i in 1:length(x)){
    print(x[i])
    print(eval(parse(text=x[i])))
}

It's a little crude, but it will do the job.

Sam
On 9/11/07, Sumit.Gupta at ubs.com <Sumit.Gupta at ubs.com> wrote:
> Hello,
>
> I am wondering if it is possible to view what variables and vairable
> values are stored in the R memory. This to enable debugging of R-scripts
> I write.
>
> Sumit
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ptit_bleu at yahoo.fr  Wed Sep 12 14:35:30 2007
From: ptit_bleu at yahoo.fr (Ptit_Bleu)
Date: Wed, 12 Sep 2007 05:35:30 -0700 (PDT)
Subject: [R] [solved] Re: I can't do it again on an other PC : R+RMySQL
 ->error loading dll
In-Reply-To: <12634122.post@talk.nabble.com>
References: <12592576.post@talk.nabble.com> <12610089.post@talk.nabble.com>
	<46E654B3.5060103@biostat.ku.dk>
	<12610981.post@talk.nabble.com> <12611132.post@talk.nabble.com>
	<12633728.post@talk.nabble.com> <12634122.post@talk.nabble.com>
Message-ID: <12634485.post@talk.nabble.com>


Thanks for the procedure. It sounds easy.
I will test it when I have time and see if there are differences (I hope I
won't see anything : from a working configuration, if I change to RODBC, I'd
like to get another working one).

Ptit BLeu.



Vladimir Eremeev wrote:
> 
> Hi!
> In my case, advantages of using RODBC are in the fact that it is working,
> and is getting updated on a regular basis. Nothing more. :)
> 
> I also had some difficulties to set up the DSN, old Windows NT 4.0
> required couple of restarts, and guessing correct 'magic' line to make MS
> Excel to retrieve the data was difficult. The procedure is simplified in
> Win2000/XP.
> 
> I have MySQL ODBC 3.51 Driver installed.
> Then I go to Start -> Control Panel -> Administrative Tools, double-click
> on 'Data sources (ODBC)', click
> 'Add' in the opened window, choose 'MySQL ODBC 3.51 Driver' from the list,
> enter host name, database name, user name and password. Port is 3306 by
> default.
> Then pressing 'Test Data source' shows if everything is set up correctly.
> MySQL also have to be configured to allow connections.
> 
> RODBC also contains the file with the comprehensive instructions
> (R_HOME/Library/RODBC/Readme).
> 
> 
> Ptit_Bleu wrote:
>> 
>> Hi Vladimir,
>> 
>> In fact, at the beginning, I tried to install RODBC and the MySQL driver
>> but I did not manage (I think due to the driver and the configuration in
>> the control panel). Then I tried to install RMySQL and DBI on my PC (not
>> the one with the "real" database), and it worked without any problem. So
>> I keep working with RMySQL.
>> 
>> You think there are advantages to try again installing RODBC ?
>> 
>> Anyway, for the moment, I think I will continue with RMySQL, just because
>> it works. But for me it is a good reason (especially because I'm not a
>> specialist of PCs and I don't have the time to become one. I'm only an
>> end-user).
>> 
>> Have a nice day,
>> Ptit Bleu.
>> 
>> 
>> 
>> Vladimir Eremeev wrote:
>>> 
>>> Do you need precisely RMySQL and DBI? 
>>> RODBC can successfully replace this.
>>> 
>>> I used RMySQL some time ago, but then, after the next version upgrade it
>>> stopped working.
>>> 
>>> Switching to RODBC was almost without pain, since function names were
>>> quite similar.
>>> I simply replaced dbGetQuery with sqlGetQuery in my script and voilia.
>>> 
>>> However, you need to install the MySQL ODBC driver and set up a data
>>> source in the Windows Control Panel before.
>>> 
>>> 
>> 
>> 
> 
> 

-- 
View this message in context: http://www.nabble.com/I-can%27t-do-it-again-on-an-other-PC-%3A-R%2BRMySQL--%3Eerror-loading-dll-tf4414597.html#a12634485
Sent from the R help mailing list archive at Nabble.com.


From HDoran at air.org  Wed Sep 12 14:37:05 2007
From: HDoran at air.org (Doran, Harold)
Date: Wed, 12 Sep 2007 08:37:05 -0400
Subject: [R] R: to view the memory
In-Reply-To: <c84ed6950709120528t44c7af65m1f30509b692a6bce@mail.gmail.com>
Message-ID: <2323A6D37908A847A7C32F1E3662C80E010A0485@dc1ex01.air.org>

Is this what you want when you say "values". It seems this could be very
expensive if some of your objects are large matrices, for example. I
thought the poster meant "size" when he said values since he later
mentioned memory. If that is the case, you want object.size().

 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of R Help
> Sent: Wednesday, September 12, 2007 8:28 AM
> To: Sumit.Gupta at ubs.com
> Cc: r-help at r-project.org
> Subject: Re: [R] R: to view the memory
> 
> the function ls() will list all the variables currently in the memory.
>  To get their values, you'll also need to use the parse and 
> eval functions.  Try the following:
> 
> x = ls()
> for(i in 1:length(x)){
>     print(x[i])
>     print(eval(parse(text=x[i])))
> }
> 
> It's a little crude, but it will do the job.
> 
> Sam
> On 9/11/07, Sumit.Gupta at ubs.com <Sumit.Gupta at ubs.com> wrote:
> > Hello,
> >
> > I am wondering if it is possible to view what variables and 
> vairable 
> > values are stored in the R memory. This to enable debugging of 
> > R-scripts I write.
> >
> > Sumit
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From f.harrell at vanderbilt.edu  Wed Sep 12 14:37:47 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Wed, 12 Sep 2007 07:37:47 -0500
Subject: [R] Creating Hmisc labels inside a function
In-Reply-To: <019801c7f452$6211ae50$6501a8c0@STEVE>
References: <mailman.7.1189418403.7853.r-help@stat.math.ethz.ch>
	<019801c7f452$6211ae50$6501a8c0@STEVE>
Message-ID: <46E7DD9B.4020902@vanderbilt.edu>

Steve Powell wrote:
> hello list members,
> I am wanting to write a label using the Hmisc package, but inside a
> function. Normally I can do:
> 
> library(Hmisc)
> M=2
> label(M)="lab"
> 
> #But inside a function the "=" does not work:
> Test=function(obj,labe)
> {
> label(obj)=labe

at this point add the line:

obj

> }

The returned object will have what you need.  -Frank

> 
> Test(M,"new label")
> 
> I usually use the "assign" function to make assignments inside functions,
> but assign will not work with attributes, labels etc.
> Any ideas?
> Thanks in advance
> 
> Steve Powell
> 
>  
> proMENTE social research 
> research | evaluation | training & consulting 
> Kranj?evi?eva 35, 71000 Sarajevo 
> mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387 33 556 866
> skype: stevepowell99 
> www.promente.org  |  www.mojakarijera.com  |  www.psih.org  
> 
> 
> Checked by AVG Free Edition. 
> 
> 17:43
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From jbarnier at ens-lsh.fr  Wed Sep 12 14:55:08 2007
From: jbarnier at ens-lsh.fr (Julien Barnier)
Date: Wed, 12 Sep 2007 14:55:08 +0200
Subject: [R] Title and labelos in ggplot2
Message-ID: <87odg8qc0j.fsf@ens-lsh.fr>

Hi,

I am new to the ggplot2 package and I am stuck with something which
must be quite basic : I can't manage to change the x and y axis labels
when I don't use the qplot command. I manged to change the main title
by modifying the title element of the ggplot object, but I can't find
the elements for the axis labels.

Here is my code :

p <- ggplot(d03, aes(x=cs,y=taille)) + geom_hline(data=temp.df) + geom_boxplot() + facet_grid(.~sexe) 
p$title <- "Wonderful title"
print(p)

Thanks in advance for any help.

-- 
Julien Barnier
Groupe de recherche sur la socialisation
ENS-LSH - Lyon, France


From friendly at yorku.ca  Wed Sep 12 15:03:01 2007
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 12 Sep 2007 09:03:01 -0400
Subject: [R] constructing an lm() formula in a function
Message-ID: <46E7E385.3020808@yorku.ca>

I'm working on some functions for generalized canonical discriminant
analysis in conjunction with the heplots package.  I've written a
candisc.mlm function that takes an mlm object and computes a
candisc object containing canonical scores, coeficients, etc.

But I'm stumped on how to construct a mlm for the canonical scores,
in a function using the *same* right-hand-side of the model formula that 
was used in the original mlm for the data.

I can illustrate step-by-step and where I'm stumped.

 > # fit randomized block model, .~Block+Gp, where Gp = Contour:Depth
 > # Soils data is in car package
 > library(car)
 > soils.mod1 <- lm(cbind(pH,N,Dens,P,Ca,Mg,K,Na,Conduc) ~ Block + Gp,
+   data=Soils)
 > # Do the canonical discriminant analysis for Gp:
 > can1 <-candisc(soils.mod1, term="Gp")
 >
 > str(can1$scores)
'data.frame':   48 obs. of  11 variables:
  $ Block: Factor w/ 4 levels "1","2","3","4": 1 2 3 4 1 2 3 4 1 2 ...
  $ Gp   : Factor w/ 12 levels "D0","D1","D3",..: 9 9 9 9 10 10 10 10 11 
11 ...
  $ Can1 : num  8.87 5.57 6.31 7.01 6.64 ...
  $ Can2 : num  -3.76 -4.78 -4.63 -4.06 -3.13 ...
  $ Can3 : num   1.241 -0.561 -1.299  0.642  2.217 ...
  $ Can4 : num   1.313 -0.402 -1.631  2.481  0.384 ...
  $ Can5 : num  -1.913 -1.103 -0.428  1.134 -0.937 ...
  $ Can6 : num  -0.4219 -0.3593  1.2070  0.0652 -0.6424 ...
  $ Can7 : num   0.701  0.243 -0.728  1.147 -0.149 ...
  $ Can8 : num   0.0728  1.4491 -0.1546 -1.5191 -0.2374 ...
  $ Can9 : num  -2.4318  1.2773 -0.0905  1.0646 -1.8069 ...
 > str(can1$terms)
  chr [1:2] "Block" "Gp"

OK, so now in a function I want to do the equivalent of fitting

lm( cbind(Can1, Can2, ... Can9) ~ Block+Gp, data=can$scores)

The following function shows two ways I've tried to do this, neither of 
which works:

fitlm.candisc <- function( can ) {
	factors <- can$factors              # factor variable from candisc
	terms <- can$terms                  # terms from original lm
	scores <- can$scores                # scores data fram
#	can.mod <- lm(as.matrix(scores[,paste("Can",1:can$rank,sep="")])
#	           ~ paste(can1$terms,collapse="+"), data=scores)
	can.mod <- lm(as.matrix(scores[,paste("Can",1:can$rank,sep="")])
	           ~ scores[,terms], data=scores)
}

 > fitlm.candisc(can1)
Error in model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
         invalid type (list) for variable 'scores[, terms]'
 >

I would like the terms in the model can.mod to be Block and Gp.
What am I missing here?

thanks,

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA


From therneau at mayo.edu  Wed Sep 12 15:08:57 2007
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 12 Sep 2007 08:08:57 -0500 (CDT)
Subject: [R] Bootstrap tree selection in rpart
Message-ID: <200709121308.l8CD8uF14274@hsrnfs-101.mayo.edu>

Fiona Callaghan asked about using the bootstrap  instead of cross-validation in 
the tree pruning step.  
   It turns out that cross-validation works better than the bootstrap for trees.
The issue is a subtle one.  The bootstrap can be thought of as 2 steps.  

1.  Deduction: Evaluate the behavior of some statistic "zed" under repeated
sampling from the discrete distribution F-hat, i.e., the original data.  This
gives a direct evaluation of how zed behaves under F-hat.

2. Induction: Assume that (behavior of zed under sampling from F) = (behavior
under sampling from F-hat).

  It turns out that trees behave differently under discreet distributions than
they do under continuous ones, so step 2 fails.  Essentially, there are fewer 
places to split in the discrete case, tree creation is less noisy, and the 
bootstrap gives an overoptimistic view.  I remember Brad Efron giving a talk on
this long ago (I was still a student!), so the details are fuzzy; I think that
he solved it by sampling from a smoothed version of the empirical CDF.

   Terry Therneau


From tamir at imp.univie.ac.at  Wed Sep 12 15:12:32 2007
From: tamir at imp.univie.ac.at (Ido M. Tamir)
Date: Wed, 12 Sep 2007 09:12:32 -0400
Subject: [R] Title and labelos in ggplot2
Message-ID: <200709120912.32176.tamir@imp.univie.ac.at>

x and y axis labels changing in ggplo2:

p <- ggplot(d03, aes(x=cs,y=taille)) + geom_hline(data=temp.df) + 
geom_boxplot() + facet_grid(.~sexe) 

I had a similar question not too long ago. Try:

p + scale_x_discrete("new label x") + scale_y_continuous("new label y") 

best wishes
ido


From ajung at gfz-potsdam.de  Wed Sep 12 15:34:20 2007
From: ajung at gfz-potsdam.de (Andre Jung)
Date: Wed, 12 Sep 2007 15:34:20 +0200
Subject: [R] plot contour map for irregular data points
In-Reply-To: <web-22594776@cgp1.gfz-potsdam.de>
References: <web-22594776@cgp1.gfz-potsdam.de>
Message-ID: <web-22596348@cgp1.gfz-potsdam.de>

Hello,

I'm dealing with the following problem:

I have a table with x and y coordinates and corresponding values of
a mineral concentration, let's call it z.
  
Can someone provide me a short step-by-step manual for the steps
necessary to get a contour map?
  
How to sort and interpolate my matrix to an equidistant grid which
can afterwards be plotted by contour(x,y,z)? (e.g. fill the missing
locations with NAs.)
  
Thank you.


From rhelp.stats at gmail.com  Wed Sep 12 15:54:16 2007
From: rhelp.stats at gmail.com (R Help)
Date: Wed, 12 Sep 2007 10:54:16 -0300
Subject: [R] super and subscript in tcltk
Message-ID: <c84ed6950709120654s28871094n3e88947793dc726e@mail.gmail.com>

dear list,

I'm trying to set subscripts in a tcltk menu, but I can't get it to
work.  The basic idea is produced by the following code

#######
library(tcltk)
m <- tktoplevel()
norm <- tkfont.create(family="times",size=20,weight="bold")
f1 <- tkfont.create(family="symbol",size=10)
f2 <- tkfont.create(family="symbol",size=5)
frame <- tkframe(m)

entry1 <- tkentry(frame,width=5,bg='white')
entry2 <- tkentry(frame,width=5,bg='white')

tkpack(tklabel(frame,text="m",font=f1),side='left')
tkpack(tklabel(frame,text="1",font=f2),side='left')
tkpack(frame,entry1,side="left")
tkpack(tklabel(frame,text="m",font=f1),side='left')
tkpack(tklabel(frame,text="2",font=f2),side='left')
tkpack(frame,entry2,side="top")
########

But the problem is that the 1 and 2 are not added as subscripts.  I
think I can do it using a text-object and the offset tag, but I cannot
figure out how to do it.  Does anybody know how to use the
tktag.configure(...) function to set the offset tag so that the text
will appear below the baseline?  It should work like this

#######
t <- tktext(frame,font=f1)
tktag.configure(t,"offset=-50")
tkinsert(t,"end","m")
tkinsert(t,"end","1")
#######

Any help would be very much appreciated.

Thanks
Sam


From gferraz29 at gmail.com  Wed Sep 12 16:03:36 2007
From: gferraz29 at gmail.com (=?ISO-8859-1?Q?Gon=E7alo_Ferraz?=)
Date: Wed, 12 Sep 2007 10:03:36 -0400
Subject: [R] fail to recover decimal value from data frame
Message-ID: <D525B554-8693-4798-8036-3F7E3D44452F@gmail.com>

Hi,
I have some decimal values stored in a data frame (myframe) and I  
need to place them in a matrix (mymatrix) using a for loop.
When I type:

 > myframe[i,10]

I get:

[1] 0.8714
434 Levels: 0 0.0134 0.1062 0.1182 0.1241 0.1322 0.1374 0.1429  
0.1507 ... psi1

But when I assign that value to the matrix with:

 > mymatrix[i,2]<-myframe[i,10]

The value that gets placed in the matrix is 286, and not 0.8714 as I  
wanted it to be. What is wrong?
The data frame does have several rows of character cells interspersed  
with "NA" and decimal values. It is not very simple I am just using  
it to store a large output worksheet from where I want to draw  
selected values.

Thanks for any help.

G.


From jbarnier at ens-lsh.fr  Wed Sep 12 16:08:31 2007
From: jbarnier at ens-lsh.fr (Julien Barnier)
Date: Wed, 12 Sep 2007 16:08:31 +0200
Subject: [R] fail to recover decimal value from data frame
References: <D525B554-8693-4798-8036-3F7E3D44452F@gmail.com>
Message-ID: <87hcm0q8m8.fsf@ens-lsh.fr>

Hi,

> [1] 0.8714
> 434 Levels: 0 0.0134 0.1062 0.1182 0.1241 0.1322 0.1374 0.1429  
> 0.1507 ... psi1

The problem is that your data are not stored as numeric, but as a
factor.

You can see the following R FAQ entry to turn it back to a numeric
form :

http://cran.r-project.org/doc/FAQ/R-FAQ.html#How-do-I-convert-factors-to-numeric_003f

HTH,

Julien

-- 
Julien Barnier
Groupe de recherche sur la socialisation
ENS-LSH - Lyon, France


From r.hankin at noc.soton.ac.uk  Wed Sep 12 16:32:09 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Wed, 12 Sep 2007 15:32:09 +0100
Subject: [R] vectorize a matrix conversion
Message-ID: <9C72BED8-FBD7-43C2-8854-F14FA1B31FE9@noc.soton.ac.uk>

Hello


I have X, an n-by-n  matrix and want to convert it to Y, an
  n(n-1)/2 -by- n matrix such that each row of Y
corresponds to an element of the upper diagonal
of X.   Say row k of Y corresponds to [i,j] with i\neq j.

Then Y[i,k] = X[i,j] and Y[j,k] = X[j,i].
and Y[-c(i,j),k] = NA.

How to do this vectorizedly?

Example follows:



 > X
      [,1] [,2] [,3] [,4]
[1,]   NA   10    8    7
[2,]   10   NA    7   12
[3,]   12   13   NA    8
[4,]   13    8   12   NA
 > Y
      [,1] [,2] [,3] [,4]
[1,]   10   10   NA   NA
[2,]   12   NA    8   NA
[3,]   13   NA   NA    7
[4,]   NA   13    7   NA
[5,]   NA    8   NA   12
[6,]   NA   NA   12    8
 >

[matrix X corresponds to an all-play-all competition amongst 4  
individuals,
entry [i,j] corresponding to the  number of times individual "i" won
when competing against individual "j".  Thus individual 2 beat  
individual
3 seven times and individual 3 beat individual 2 thirteen times.
Note X[i,j] + X[j,i]=20 as there were 20 trials for each pair]


Pitiful nonvectorized code follows.

n <- nrow(X)
Y <-  matrix(NA,n*(n-1)/2,n)
k <- 1
for(i in 1:(n-1)){
   for(j in (i+1):n){
     if( !(i==j)){
       print(c(i,j,k))
       Y[k,i] <- X[i,j]
       Y[k,j] <- X[j,i]
     }
     k <- k+1
   }
}





--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From samay.sar at gmail.com  Wed Sep 12 16:33:39 2007
From: samay.sar at gmail.com (d. sarthi maheshwari)
Date: Wed, 12 Sep 2007 20:03:39 +0530
Subject: [R] : Error on tomcat...
Message-ID: <d4327f7e0709120733t42206123kb522ef766f4cd6e6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070912/07705280/attachment.pl 

From petr.pikal at precheza.cz  Wed Sep 12 16:50:50 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Wed, 12 Sep 2007 16:50:50 +0200
Subject: [R] Odp:  fail to recover decimal value from data frame
In-Reply-To: <D525B554-8693-4798-8036-3F7E3D44452F@gmail.com>
Message-ID: <OF95BEFBFB.9BE0F89A-ONC1257354.004F5932-C1257354.00518FF6@precheza.cz>

Hi

you definitely shall try to get acustommed with data structures in R. You 
do ***not*** have numeric decimal values but factors (probably created by 
transfering data to R as you have in the column a value psi1).  Then the 
assignement places a factor code into matrix instead of a factor value. 

fac<-factor(rnorm(100))
daf<-as.data.frame(matrix(fac,10,10))
> sapply(daf, "is.factor")
  V1   V2   V3   V4   V5   V6   V7   V8   V9  V10 
TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE 

mat[1,10]<-daf[1,10]
> mat
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]   NA   NA   NA   NA   NA   NA   NA   NA   NA     1
 [2,]   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA
 [3,]   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA

<snip>

> mat[2,10]<-daf[2,10]
mat[2,10]
[1] 4
daf.n<-sapply(daf, function(x) as.numeric(as.character(x)))
mat[3,10]<-daf.n[3,10]
mat
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]     [,10]
 [1,]   NA   NA   NA   NA   NA   NA   NA   NA   NA 1.0000000
 [2,]   NA   NA   NA   NA   NA   NA   NA   NA   NA 4.0000000
 [3,]   NA   NA   NA   NA   NA   NA   NA   NA   NA 0.2200095
 [4,]   NA   NA   NA   NA   NA   NA   NA   NA   NA        NA
 [5,]   NA   NA   NA   NA   NA   NA   NA   NA   NA        NA
 
You need to get rid of irrelevant values in your data frame first.

Regards

Petr
petr.pikal at precheza.cz

r-help-bounces at r-project.org napsal dne 12.09.2007 16:03:36:

> Hi,
> I have some decimal values stored in a data frame (myframe) and I 
> need to place them in a matrix (mymatrix) using a for loop.
> When I type:
> 
>  > myframe[i,10]
> 
> I get:
> 
> [1] 0.8714
> 434 Levels: 0 0.0134 0.1062 0.1182 0.1241 0.1322 0.1374 0.1429 
> 0.1507 ... psi1
> 
> But when I assign that value to the matrix with:
> 
>  > mymatrix[i,2]<-myframe[i,10]
> 
> The value that gets placed in the matrix is 286, and not 0.8714 as I 
> wanted it to be. What is wrong?
> The data frame does have several rows of character cells interspersed 
> with "NA" and decimal values. It is not very simple I am just using 
> it to store a large output worksheet from where I want to draw 
> selected values.
> 
> Thanks for any help.
> 
> G.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cberry at tajo.ucsd.edu  Wed Sep 12 17:04:02 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Wed, 12 Sep 2007 08:04:02 -0700
Subject: [R] Integrate() error message, I am at a loss
In-Reply-To: <7cb007bd0709112009l4194948bweb9b34ef1fb354fe@mail.gmail.com>
References: <7cb007bd0709112009l4194948bweb9b34ef1fb354fe@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709120752320.23157@tajo.ucsd.edu>

On Wed, 12 Sep 2007, Sergey Goriatchev wrote:

> Hello!
>
> I have a problem with integrate() in my function nctspa(). Integrate
> produces an error message "evaluation of function gave a result of
> wrong length". I don't know what that means. Could anyone suggest me
> what is wrong with my function?

Sure, but you can do this yourself.

For one thing, setting

 	options( error = recover )

before you run your function will help you to see what is happening.

(viz. after the error message select 2, then figure out what f() and ff() 
are, then try ff(1))

>
> These are the examples of function calls that work OK:
> nctspa(a=1:10,n=5)
> nctspa(a=1:10, n=5, mu=2, theta=3, renorm=0)
>
> This does not work:
> nctspa(a=1:10, n=5, mu=2, theta=3, renorm=1)
>
> Many thanks in advance for your help!
> please, send reply also to sergeyg at gmail.com
>
> /Sergey
>
> Here is the function:
>
> #Computes the s.p.a. to the doubly noncentral t at value x.
> #degrees of freedom n, noncentrality parameters mu and theta.
> #==========================================================#
> nctspa <- function(a,n,mu=0,theta=0,renorm=0,rec=0){
> #Pass renorm=1 to renormalize the SPA to the pdf.
> #There is a last argument called rec. DO NOT PASS it!
>
> alpha <- mu/sqrt((1+theta/n))
> normconst <- 1
> if(renorm==1 & rec==0){
>       term1 <- integrate(nctspa, -Inf, alpha, n=n, mu=mu, theta=theta)$value
>       term2 <- integrate(nctspa, alpha, Inf, n=n, mu=mu, theta=theta)$value


Whoa! Let's read the help page for integrate:

Arguments:

        f: an R function taking a numeric first argument and returning a
           numeric vector of the same length. 
..........^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^.............


which is not what nctspa() does. It returns a list of length 2 not matter 
what the first arguement.

Did you mean something like

        	integrate(function(x,...) nctspa(x,...)$PDF, <etc> ??


HTH,

Chuck


>       normconst <- 1/(term1+term2)
> }
> cdf <- numeric()
> pdf <- cdf
> c3 <- n^2+2*n*a^2+a^4
> c2 <- (-2*mu*(a^3+n*a))/c3
> c1 <- (-n^2-n*a^2-n*theta+a^2*mu^2)/c3
> c0 <- (n*a*mu)/c3
> q <- c1/3-(c2^2)/9
> r <- 1/6*(c1*c2-3*c0)-1/27*c2^3
> b0 <- sqrt(-4*q)*cos(acos(r/sqrt(-q^3))/3)-c2/3
> t1 <- -mu+a*b0
> t2 <- -a*t1/b0/n/2
> nu <- 1/(1-2*t2)
> w <- sqrt(-mu*t1-n*log(nu)-2*theta*nu*t2)*sign(a-alpha)
> u <- sqrt((a^2+2*n*t2)*(2*n*nu^2+4*theta*nu^3)+4*n^2*b0^2)/(2*n*b0^2)
> pdf <- normconst*dnorm(w)/u
>
> nz <- (abs(t1*b0)>=1e-10)
> iz <- (abs(t1*b0)<=1e-10)
> if(any(nz)){
>       d <- numeric()
>       d[nz] <- 1/(t1[nz]*b0[nz])
>       cdf[nz] <- pnorm(w[nz])+dnorm(w[nz])*(1/w[nz]-d[nz]/u[nz])
> }
> if(any(iz)){
>       n <- sum(iz==1)
>       rez <- nctspa(c(a[iz]-1e-4, a[iz]+1e-4),n,mu,theta,0,rec+1)
>       if(rec>5){
>       cdf[iz] <- 0.5
>       warning('Too many recursions')
>       } else {
>       cdf[iz] <- 0.5*(rez$CDF[1:n]+rez$CDF[(n+1):length(rez$CDF)])
>       }
> }
> list(PDF=pdf, CDF=cdf)
> }
> #======================================================
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From lterlemez at anadolu.edu.tr  Wed Sep 12 17:04:18 2007
From: lterlemez at anadolu.edu.tr (Levent TERLEMEZ)
Date: Wed, 12 Sep 2007 18:04:18 +0300
Subject: [R] Producing Date Reference Series...
Message-ID: <D41D386EE849484793EFC74357D15A2D@anadolu.edu.tr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070912/75652ec6/attachment.pl 

From ssj1364 at gmail.com  Wed Sep 12 17:11:34 2007
From: ssj1364 at gmail.com (sj)
Date: Wed, 12 Sep 2007 09:11:34 -0600
Subject: [R] vars package, impulse response functions ??
Message-ID: <1c6126db0709120811k5d1b3b6fj4d24b21393577a33@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070912/fc16f050/attachment.pl 

From darteta001 at ikasle.ehu.es  Wed Sep 12 17:13:42 2007
From: darteta001 at ikasle.ehu.es (darteta001 at ikasle.ehu.es)
Date: Wed, 12 Sep 2007 17:13:42 +0200 (CEST)
Subject: [R] k-means clustering
Message-ID: <6178381599darteta001@ikasle.ehu.es>

Dear list, first apologies for this is not strictly an R question but 
a theoretical one. 

I have read that use of k-means clustering assumes sphericity of data 
distribution. Can anyone explain me what this means? My statistical 
background is too poor. Is it another kind of distribution, like 
gaussian or binomial? What does it happen if the distribution is not 
spherical? Could you give me an example or a link to information about 
this?

Thanks for your help

David


From dimitris.rizopoulos at med.kuleuven.be  Wed Sep 12 17:15:56 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 12 Sep 2007 17:15:56 +0200
Subject: [R] vectorize a matrix conversion
References: <9C72BED8-FBD7-43C2-8854-F14FA1B31FE9@noc.soton.ac.uk>
Message-ID: <006101c7f54f$d17d2690$0540210a@www.domain>

you could try the following:

n <- nrow(X)
k <- n * (n - 1) / 2
Y <- matrix(NA, k, n)

ind.up <- which(upper.tri(X), arr.ind = TRUE)
ind.lo <- which(lower.tri(X), arr.ind = TRUE)
Y[cbind(1:k, ind.lo[, 1])] <- X[ind.up]
Y[cbind(1:k, ind.lo[, 2])] <- X[ind.lo]
Y


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Robin Hankin" <r.hankin at noc.soton.ac.uk>
To: "R program" <R-help at r-project.org>
Sent: Wednesday, September 12, 2007 4:32 PM
Subject: [R] vectorize a matrix conversion


> Hello
>
>
> I have X, an n-by-n  matrix and want to convert it to Y, an
>  n(n-1)/2 -by- n matrix such that each row of Y
> corresponds to an element of the upper diagonal
> of X.   Say row k of Y corresponds to [i,j] with i\neq j.
>
> Then Y[i,k] = X[i,j] and Y[j,k] = X[j,i].
> and Y[-c(i,j),k] = NA.
>
> How to do this vectorizedly?
>
> Example follows:
>
>
>
> > X
>      [,1] [,2] [,3] [,4]
> [1,]   NA   10    8    7
> [2,]   10   NA    7   12
> [3,]   12   13   NA    8
> [4,]   13    8   12   NA
> > Y
>      [,1] [,2] [,3] [,4]
> [1,]   10   10   NA   NA
> [2,]   12   NA    8   NA
> [3,]   13   NA   NA    7
> [4,]   NA   13    7   NA
> [5,]   NA    8   NA   12
> [6,]   NA   NA   12    8
> >
>
> [matrix X corresponds to an all-play-all competition amongst 4
> individuals,
> entry [i,j] corresponding to the  number of times individual "i" won
> when competing against individual "j".  Thus individual 2 beat
> individual
> 3 seven times and individual 3 beat individual 2 thirteen times.
> Note X[i,j] + X[j,i]=20 as there were 20 trials for each pair]
>
>
> Pitiful nonvectorized code follows.
>
> n <- nrow(X)
> Y <-  matrix(NA,n*(n-1)/2,n)
> k <- 1
> for(i in 1:(n-1)){
>   for(j in (i+1):n){
>     if( !(i==j)){
>       print(c(i,j,k))
>       Y[k,i] <- X[i,j]
>       Y[k,j] <- X[j,i]
>     }
>     k <- k+1
>   }
> }
>
>
>
>
>
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>  tel  023-8059-7743
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From formations at alcatorda.com  Wed Sep 12 16:08:27 2007
From: formations at alcatorda.com (Philippe Rousselot)
Date: Wed, 12 Sep 2007 16:08:27 +0200
Subject: [R] looking for a french speaking  R specialist for training
Message-ID: <46E7F2DB.3060809@alcatorda.com>

Hi,

sorry if it is the wrong place to post this.  I am looking for someone 
to teach R. I will continue in french as the job will be done in french 
only.

Bonjour,

je cherche un formateur sur R pour des cycles de formations continues, 
le premier d?butant en novembre-d?cembre.

vu le sujet, la personne devra ?tre extr?mement p?dagogue.

Merci de m'envoyer un mail directement ? formations at alcatorda point 
com avec cv, exp?rience dans le domaine, contenu et dur?e (pas plus de 5 
jours) pr?vue pour la formation, dates de disponibilit? et devis.

Les formations aurons lieu dans la r?gion parisienne (45 minutes de la 
gare de l'est) et concerne des chercheurs et travailleurs ind?pendants

la formation porterait sur l'installation et la prise en main de R, 
l'utilisation pour des analyses statistiques classiques (les stagiaires 
sont suppos?s conna?tre les stats), l'initiation aux scripts. Pour 
certains cours, l'utilisation de R coupl? au SIG GRASS peut ?tre envisag?.

merci d'avance

Philippe


From cberry at tajo.ucsd.edu  Wed Sep 12 17:31:32 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Wed, 12 Sep 2007 08:31:32 -0700
Subject: [R] vectorize a matrix conversion
In-Reply-To: <9C72BED8-FBD7-43C2-8854-F14FA1B31FE9@noc.soton.ac.uk>
References: <9C72BED8-FBD7-43C2-8854-F14FA1B31FE9@noc.soton.ac.uk>
Message-ID: <Pine.LNX.4.64.0709120819330.23157@tajo.ucsd.edu>

On Wed, 12 Sep 2007, Robin Hankin wrote:

> Hello
>
>
> I have X, an n-by-n  matrix and want to convert it to Y, an
>  n(n-1)/2 -by- n matrix such that each row of Y
> corresponds to an element of the upper diagonal
> of X.   Say row k of Y corresponds to [i,j] with i\neq j.
>
> Then Y[i,k] = X[i,j] and Y[j,k] = X[j,i].
> and Y[-c(i,j),k] = NA.
>
> How to do this vectorizedly?
>

If I follow you:

   upper.indexes <- which( lower.tri( X ), arr.ind=TRUE )
   from.mat <- rbind( upper.indexes, upper.indexes[ , 2:1 ] )
   to.mat <- cbind( rep( 1:nrow(upper.indexes), 2 ), as.vector( upper.indexes[, 2:1] ) )
   Y[ to.mat ] <- X[ from.mat ]

HTH,

Chuck


> Example follows:
>
>
>
> > X
>      [,1] [,2] [,3] [,4]
> [1,]   NA   10    8    7
> [2,]   10   NA    7   12
> [3,]   12   13   NA    8
> [4,]   13    8   12   NA
> > Y
>      [,1] [,2] [,3] [,4]
> [1,]   10   10   NA   NA
> [2,]   12   NA    8   NA
> [3,]   13   NA   NA    7
> [4,]   NA   13    7   NA
> [5,]   NA    8   NA   12
> [6,]   NA   NA   12    8
> >
>
> [matrix X corresponds to an all-play-all competition amongst 4
> individuals,
> entry [i,j] corresponding to the  number of times individual "i" won
> when competing against individual "j".  Thus individual 2 beat
> individual
> 3 seven times and individual 3 beat individual 2 thirteen times.
> Note X[i,j] + X[j,i]=20 as there were 20 trials for each pair]
>
>
> Pitiful nonvectorized code follows.
>
> n <- nrow(X)
> Y <-  matrix(NA,n*(n-1)/2,n)
> k <- 1
> for(i in 1:(n-1)){
>   for(j in (i+1):n){
>     if( !(i==j)){
>       print(c(i,j,k))
>       Y[k,i] <- X[i,j]
>       Y[k,j] <- X[j,i]
>     }
>     k <- k+1
>   }
> }
>
>
>
>
>
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>  tel  023-8059-7743
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From niravmehta.x at gmail.com  Wed Sep 12 17:42:24 2007
From: niravmehta.x at gmail.com (Nirav Mehta)
Date: Wed, 12 Sep 2007 11:42:24 -0400
Subject: [R] irregular time series
Message-ID: <1d8fd92c0709120842s500ce0f2i2d48fe108897d109@mail.gmail.com>

Howdy!

I am attempting to convert a date frame with irregular dates into a
regular time series, aggregated by date. i have tried using both the
'its' and 'zoo' packages.

I have something like

times<-c("2003-03-05", "2003-03-05", "2003-05-05" ,"2003-04-07" ,"2003-03-05")
aarf<-data.frame(times)
aarf$x<-runif(5)

what i want in the end, is a daily time series, aggregating x by day,
and filling in days where there are no data with 0.

I have tried, similarly to another help request, the aggregating once
I have zoo-class data, but my dates disappear, and instead I get
things like 12772 and so on for the various dates. I thought that
these 5-digit numbers were maybe the number of days past Jan 1, 1970,
but dividing these numbers by the number of days in a year gets me out
of my data range.

Also, applying as.ts() to my zoo data gives me a regularly spaced time
series that ignores the timing imposed in zoo.

Similarly, I can convert the series to an 'its' object, but then
cannot convert the 'its' object to a regular time series with 0 filled
in where I have no observations, since the 'its' arithmitic only
returns the intersection of addition of two its vectors.

Thanks,
Nirav Mehta


From yn19832 at msn.com  Wed Sep 12 18:24:32 2007
From: yn19832 at msn.com (livia)
Date: Wed, 12 Sep 2007 09:24:32 -0700 (PDT)
Subject: [R] Tick intervals
Message-ID: <12639110.post@talk.nabble.com>


Hi, I would like to plot a histogram with the following codes, and I would
like to make the tick intervals smaller. I tried to add "lab=c(1,1,12)", but
nothing changes.


par(mfrow=c(1,1),font=1, cex=0.8)
hist (data1, seq(-0.01,0.3,0.01),freq = FALSE,
main="Figure1.",xlab="return",lab=c(1,1,12))
lines(density(data1), col="blue")


Could anyone give me sone advice?
Many thanks,
-- 
View this message in context: http://www.nabble.com/Tick-intervals-tf4430457.html#a12639110
Sent from the R help mailing list archive at Nabble.com.


From ggrothendieck at gmail.com  Wed Sep 12 18:42:33 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 12 Sep 2007 12:42:33 -0400
Subject: [R] irregular time series
In-Reply-To: <1d8fd92c0709120842s500ce0f2i2d48fe108897d109@mail.gmail.com>
References: <1d8fd92c0709120842s500ce0f2i2d48fe108897d109@mail.gmail.com>
Message-ID: <971536df0709120942h4becaf8l7ac537c1cf4c527a@mail.gmail.com>

Try this.  After defining our data, tt and x, we create a zoo series
z by aggregating over days taking the last point corresponding to
each day.  Then we convert that to ts (which fills in the missing days)
and create a zoo series with no data and those times merging it
with the  original zoo series and specifying fill = 0.

library(zoo)

# create zoo series, z, by taking last point corresponding to each day
tt <- c("2003-03-05", "2003-03-05", "2003-05-05" ,"2003-04-07" ,"2003-03-05")
x <- 1:5
z <- aggregate(zoo(x), as.Date(tt), tail, 1)

merge(z, zoo(, time(as.ts(z))), fill = 0)

# alternative to last line is the following: longer but no warning
# only change is inserting of as.Date(unclass(...)) to force Date class
merge(z, zoo(, as.Date(unclass(time(as.ts(z))))), fill = 0)


On 9/12/07, Nirav Mehta <niravmehta.x at gmail.com> wrote:
> Howdy!
>
> I am attempting to convert a date frame with irregular dates into a
> regular time series, aggregated by date. i have tried using both the
> 'its' and 'zoo' packages.
>
> I have something like
>
> times<-c("2003-03-05", "2003-03-05", "2003-05-05" ,"2003-04-07" ,"2003-03-05")
> aarf<-data.frame(times)
> aarf$x<-runif(5)
>
> what i want in the end, is a daily time series, aggregating x by day,
> and filling in days where there are no data with 0.
>
> I have tried, similarly to another help request, the aggregating once
> I have zoo-class data, but my dates disappear, and instead I get
> things like 12772 and so on for the various dates. I thought that
> these 5-digit numbers were maybe the number of days past Jan 1, 1970,
> but dividing these numbers by the number of days in a year gets me out
> of my data range.
>
> Also, applying as.ts() to my zoo data gives me a regularly spaced time
> series that ignores the timing imposed in zoo.
>
> Similarly, I can convert the series to an 'its' object, but then
> cannot convert the 'its' object to a regular time series with 0 filled
> in where I have no observations, since the 'its' arithmitic only
> returns the intersection of addition of two its vectors.
>
> Thanks,
> Nirav Mehta
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sandy at stat.umn.edu  Wed Sep 12 18:48:30 2007
From: sandy at stat.umn.edu (Sandy Weisberg)
Date: Wed, 12 Sep 2007 11:48:30 -0500
Subject: [R] Evaluating args in a function
Message-ID: <46E8185E.9020902@stat.umn.edu>

Can anyone explain what I'm doing wrong here:

 > fred <- data.frame()
 > class(fred)
[1] "data.frame"
 > test.fn <- function(x,class=class(x)) {class}
 > test.fn(fred)
Error in test.fn(fred) : promise already under evaluation: recursive 
default argument reference or earlier problems?

R 2.5.1 on both Windows and SUSE Linux.


-- 
Sanford Weisberg, sandy at stat.umn.edu
Office and mailing address:
University of Minnesota, School of Statistics
312 Ford Hall, 224 Church St. SE, Minneapolis, MN  55455
612-625-8355, FAX 612-624-8868

St. Paul office:
146 Classroom-Office Building, 612-625-8777


From roberto.perdisci at gmail.com  Wed Sep 12 18:50:07 2007
From: roberto.perdisci at gmail.com (Roberto Perdisci)
Date: Wed, 12 Sep 2007 12:50:07 -0400
Subject: [R] one-class SVM in kernlab
Message-ID: <cf94d0090709120950m2ba943d1p1ea8556c391ac288@mail.gmail.com>

Hello,
  I'm trying to using ksvm() in the kernlab package to fit a one-class
SVC, but I get a strage result on the cross-validation error estimate.
For example, consider this code:

data(spam)
classifier <- ksvm(type~.,data=spam[which(spam[,'type']=='spam'),],
type="one-svc",kernel="rbfdot",kpar=list(sigma=0.1),nu=0.05,cross=10)

what I get is:

> classifier
Support Vector Machine object of class "ksvm"

SV type: one-svc  (novelty detection)
 parameter : nu = 0.05

Gaussian Radial Basis kernel function.
 Hyperparameter : sigma =  0.1

Number of Support Vectors : 660

Objective Function Value : 10.5781
Training error : 0.212907
Cross validation error : 0

---

What surprises me is that the Training error (which I suppose is the
resubstitution error) is higher than the cross-validation error. Also,
even changing the value of sigma, the cross-validation error does not
change.
I get similar results with other datasets, too. For example

classifier <- ksvm(Species~.,data=iris[which(iris[,'Species']=='setosa'),],
type="one-svc",kernel="rbfdot",kpar=list(sigma=0.5),nu=0.05,cross=10)


Am I using ksvm() correctly?
I also tried to use the formula ~. exluding the attribute 'type' from
the dataset, and the results are exactly the same.

Unfortunately reading ?ksvm didn't help me much.

thank you,
regards,
Roberto


From ggrothendieck at gmail.com  Wed Sep 12 18:55:42 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 12 Sep 2007 12:55:42 -0400
Subject: [R] Evaluating args in a function
In-Reply-To: <46E8185E.9020902@stat.umn.edu>
References: <46E8185E.9020902@stat.umn.edu>
Message-ID: <971536df0709120955m287de40ch6b5656ba09a44d1f@mail.gmail.com>

You have a recursive reference.  Try using a different name other than
class.  For example, in the following we use class. with a dot at the end
(so that abbreviation of it still allows the user to write class):

fred <- data.frame()
test.fn <- function(x,class.=class(x)) {class.}
test.fn(fred) # "data.frame"
test.fn(fred, class = "x") # "x"


On 9/12/07, Sandy Weisberg <sandy at stat.umn.edu> wrote:
> Can anyone explain what I'm doing wrong here:
>
>  > fred <- data.frame()
>  > class(fred)
> [1] "data.frame"
>  > test.fn <- function(x,class=class(x)) {class}
>  > test.fn(fred)
> Error in test.fn(fred) : promise already under evaluation: recursive
> default argument reference or earlier problems?
>
> R 2.5.1 on both Windows and SUSE Linux.
>
>
> --
> Sanford Weisberg, sandy at stat.umn.edu
> Office and mailing address:
> University of Minnesota, School of Statistics
> 312 Ford Hall, 224 Church St. SE, Minneapolis, MN  55455
> 612-625-8355, FAX 612-624-8868
>
> St. Paul office:
> 146 Classroom-Office Building, 612-625-8777
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Greg.Snow at intermountainmail.org  Wed Sep 12 19:09:02 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 12 Sep 2007 11:09:02 -0600
Subject: [R] Tick intervals
In-Reply-To: <12639110.post@talk.nabble.com>
References: <12639110.post@talk.nabble.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBB466B@LP-EXCHVS07.CO.IHC.COM>

Do you just want the tick intervals on the axis to be changed? Or do you
want more bars in the histogram itself?

If the latter, then look at the breaks argument to hist.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of livia
> Sent: Wednesday, September 12, 2007 10:25 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Tick intervals
> 
> 
> Hi, I would like to plot a histogram with the following 
> codes, and I would like to make the tick intervals smaller. I 
> tried to add "lab=c(1,1,12)", but nothing changes.
> 
> 
> par(mfrow=c(1,1),font=1, cex=0.8)
> hist (data1, seq(-0.01,0.3,0.01),freq = FALSE,
> main="Figure1.",xlab="return",lab=c(1,1,12))
> lines(density(data1), col="blue")
> 
> 
> Could anyone give me sone advice?
> Many thanks,
> --
> View this message in context: 
> http://www.nabble.com/Tick-intervals-tf4430457.html#a12639110
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch at stats.uwo.ca  Wed Sep 12 19:13:14 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 12 Sep 2007 13:13:14 -0400
Subject: [R] Evaluating args in a function
In-Reply-To: <46E8185E.9020902@stat.umn.edu>
References: <46E8185E.9020902@stat.umn.edu>
Message-ID: <46E81E2A.70707@stats.uwo.ca>

On 9/12/2007 12:48 PM, Sandy Weisberg wrote:
> Can anyone explain what I'm doing wrong here:
> 
>  > fred <- data.frame()
>  > class(fred)
> [1] "data.frame"
>  > test.fn <- function(x,class=class(x)) {class}
>  > test.fn(fred)
> Error in test.fn(fred) : promise already under evaluation: recursive 
> default argument reference or earlier problems?
> 
> R 2.5.1 on both Windows and SUSE Linux.

As Gabor said, this is a recursive reference.  In order to know whather 
your default value class(x) should evaluate using the local variable 
named class or should go back to the base package, R needs to evaluate 
it. And there's the loop.

Another solution besides Gabor's suggestion of renaming the argument is 
to be explicit that you want the base class() function, e.g.

 > test.fn <- function(x,class=base::class(x)) {class}
 > fred <- data.frame()
 > test.fn(fred)
[1] "data.frame"

Duncan Murdoch


From mckellercran at gmail.com  Wed Sep 12 19:11:10 2007
From: mckellercran at gmail.com (Matthew Keller)
Date: Wed, 12 Sep 2007 11:11:10 -0600
Subject: [R] R: to view the memory
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E010A0485@dc1ex01.air.org>
References: <c84ed6950709120528t44c7af65m1f30509b692a6bce@mail.gmail.com>
	<2323A6D37908A847A7C32F1E3662C80E010A0485@dc1ex01.air.org>
Message-ID: <3f547caa0709121011g609ba275na7d1f4ce3c656372@mail.gmail.com>

Hi Sumit,

Here are a couple of functions I've picked up along the way and
modified. The first lists all objects, their class, and their
dimensions (I grabbed this from the web and modified - sorry for not
acknowledging the person who first wrote it). The second is much the
same but gives their size. Hope this helps:


##LS
LS<-function (pattern = "")
{

if (length(ls(1,pat=pattern)) <1){stop("No objects are in memory")}

obs <- ls(1, pat = pattern)
cat(
    formatC("DIM/LEN"),
    formatC("NAME", width=max(nchar(obs)+5)),
    formatC("CLASS",width=16),
    "\n")


if (length(ls(1,pat="tmp")) >0){

 for (i in 2:length(obs)) {
   widim <- 0
   ww <- eval(parse(t = paste("length(dimx(", obs[i], "))")))
   for (k in 1:ww){
     widim <- eval(parse(t =
paste("length(dimx(",obs[i],"))+widim-2+nchar(dimx(", obs[i],
")[k])")))}

   cat(
            eval(parse(t = paste("dimx(", obs[i], ")"))),
            formatC(obs[i], width=max(nchar(obs))-widim+10),
            formatC(eval(parse(t = paste("class(", obs[i], ")"))),1, 16),
            "\n")  }}

else{
   for (i in 1:length(obs)) {
   widim <- 0
   ww <- eval(parse(t = paste("length(dimx(", obs[i], "))")))
   for (k in 1:ww){
     widim <- eval(parse(t =
paste("length(dimx(",obs[i],"))+widim-2+nchar(dimx(", obs[i],
")[k])")))}

   cat(
            eval(parse(t = paste("dimx(", obs[i], ")"))),
            formatC(obs[i], width=max(nchar(obs))-widim+10),
            formatC(eval(parse(t = paste("class(", obs[i], ")"))),1, 16),
            "\n")  }}}





##LSIZE
lsize <- function (pattern = "",sort=TRUE)
{

if (length(ls(1,pat=pattern)) <1){stop("No objects are in memory")}

obs <- ls(1, pat = pattern)


sizes <- vector(length=length(obs))
for (i in 1:length(obs)) { sizes[i] <-
eval(parse(t=paste("object.size(", obs[i], ")")))}
sizes <- round(sizes/1048600,2)
if (sort){obs <- obs[order(sizes)]}

cat(formatC("SIZE"),
    formatC("NAME", width=max(nchar(obs)+5)),
    formatC("CLASS",width=16),
    "\n")

for (i in 1:length(obs)) {
   widim <- 0
   ww <- eval(parse(t = paste("length(object.size(", obs[i], "))")))
   for (k in 1:ww){
     widim <- eval(parse(t =
paste("length(object.size(",obs[i],"))+widim-2+nchar(00.00)")))}

   cat(eval(parse(t = paste("round(object.size(", obs[i], ")/1048600,2)"))),
       formatC(obs[i], width=max(nchar(obs))-widim+10),
       formatC(eval(parse(t = paste("class(", obs[i], ")"))),1, 16),
       "\n")  }

   cat(sum(sizes),formatC("***TOTAL***",
width=nchar(sum(sizes))-widim+12),"\n")}




On 9/12/07, Doran, Harold <HDoran at air.org> wrote:
> Is this what you want when you say "values". It seems this could be very
> expensive if some of your objects are large matrices, for example. I
> thought the poster meant "size" when he said values since he later
> mentioned memory. If that is the case, you want object.size().
>
>
>
> > -----Original Message-----
> > From: r-help-bounces at r-project.org
> > [mailto:r-help-bounces at r-project.org] On Behalf Of R Help
> > Sent: Wednesday, September 12, 2007 8:28 AM
> > To: Sumit.Gupta at ubs.com
> > Cc: r-help at r-project.org
> > Subject: Re: [R] R: to view the memory
> >
> > the function ls() will list all the variables currently in the memory.
> >  To get their values, you'll also need to use the parse and
> > eval functions.  Try the following:
> >
> > x = ls()
> > for(i in 1:length(x)){
> >     print(x[i])
> >     print(eval(parse(text=x[i])))
> > }
> >
> > It's a little crude, but it will do the job.
> >
> > Sam
> > On 9/11/07, Sumit.Gupta at ubs.com <Sumit.Gupta at ubs.com> wrote:
> > > Hello,
> > >
> > > I am wondering if it is possible to view what variables and
> > vairable
> > > values are stored in the R memory. This to enable debugging of
> > > R-scripts I write.
> > >
> > > Sumit
> > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Matthew C Keller
Postdoctoral Fellow
Virginia Institute for Psychiatric and Behavioral Genetics


From akkilesha at gmail.com  Wed Sep 12 20:19:21 2007
From: akkilesha at gmail.com (akki)
Date: Wed, 12 Sep 2007 20:19:21 +0200
Subject: [R] labels into graph
Message-ID: <c0533abc0709121119i2e9f5351tfe8395db21791014@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070912/3443b1d6/attachment.pl 

From francesc.montane at ctfc.es  Wed Sep 12 20:38:39 2007
From: francesc.montane at ctfc.es (=?utf-8?B?RnJhbmNlc2MgTW9udGFu6Q==?=)
Date: Wed, 12 Sep 2007 20:38:39 +0200 (CEST)
Subject: [R] Nested anova with unbalanced design and corrected sample size
 for spatial autocorrelation
Message-ID: <2039.129.128.246.84.1189622319.squirrel@mail.ctfc.es>


Hello all,

This may be a simple question to answer, but I'm a little bit stumped with
respect to the calculation of the F statistics in nested  anovas with
unbalanced design in R.

In my case, I have 11 vegetation transects (with 1000 10cmx10cm squares),
where we estimated shrub cover. We have two different treatments: wildfire
(4 transects) and prescribed burning (7 transects) and we want to compare
the mean shrub cover between the 2 different treatments. I guess that I
have to apply a one-way nested anova (transect number within treatment)
with unbalanced number of samples (4000 in wildfire vs 7000 in prescribed
burning).
Moreover, I have to correct the initial sample size (1000 squares) to a
corrected sample size by spatial autocorrelation (which in fact, makes all
the n different between transects).

Can anyone, please, tell me how to do this in R? Do I need to use lme()?
Or is it possible to do it using aov()?

Thanks a lot!

Francesc

PhD student
University of Barcelona


From jrkrideau at yahoo.ca  Wed Sep 12 20:39:50 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Wed, 12 Sep 2007 14:39:50 -0400 (EDT)
Subject: [R] labels into graph
In-Reply-To: <c0533abc0709121119i2e9f5351tfe8395db21791014@mail.gmail.com>
Message-ID: <103724.15985.qm@web32813.mail.mud.yahoo.com>

Hi akki,

 What kind of a graph are you trying to draw?  It is
not clear from the posting particularly as it messes
up your spacing.

I would suggest that you have a look at something like
# Using R for Data Analysis and Graphics -
Introduction, Examples and Commentary?  by John
Maindonald .

 ?Simple R? by John Verzani 

Both documents are available through the R site. 
Click on 'other' in the list on the left side of the
page.

 


--- akki <akkilesha at gmail.com> wrote:

> Hi,
> I have a matrix as:
> a    b     c
> 2    1     3
> 2    2     5
> 2    5     9
> 
> With values of this matrix, I draw a graph. Each row
> has a different
> meaning. For this reason, I need put different names
> each row. For example:
> 
>                                 mygraph
> -------------------           -------------------
> --------------------
> DescriptionA           DescriptionB            
> DescriptionC
> 
> -------------------------------------------------   
>          --------
> --------
>                        ab                           
>         c1          c2
> 
> I know it is possible do, but I don'k know how can I
> do it?
> 
> Can anyone help me, please?
> 
> Thanks.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From i.visser at uva.nl  Wed Sep 12 20:47:40 2007
From: i.visser at uva.nl (Ingmar Visser)
Date: Wed, 12 Sep 2007 20:47:40 +0200
Subject: [R] k-means clustering
In-Reply-To: <6178381599darteta001@ikasle.ehu.es>
References: <6178381599darteta001@ikasle.ehu.es>
Message-ID: <3FC9C1D1-D17F-4715-AEFE-7286D8B4D90A@uva.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070912/b722c5f9/attachment.pl 

From gunter.berton at gene.com  Wed Sep 12 21:02:24 2007
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 12 Sep 2007 12:02:24 -0700
Subject: [R] R: to view the memory
In-Reply-To: <C6EB3844F7C76A42965909494BB1779203630A8D@NLDNC104PEX1.ubsw.net>
References: <C6EB3844F7C76A42965909494BB1779203630A8D@NLDNC104PEX1.ubsw.net>
Message-ID: <004e01c7f56f$749a6940$3a0b2c0a@gne.windows.gene.com>

You probably should be inserting browser() calls into your function instead
-- once there you can list and examine all variables at whatever state your
function is in. (and debugging is specifically what browser() was designed
for).

See ?browser() 


Bert Gunter
Genentech Nonclinical Statistics

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Sumit.Gupta at ubs.com
Sent: Tuesday, September 11, 2007 7:02 PM
To: r-help at r-project.org
Subject: [R] R: to view the memory

Hello,

I am wondering if it is possible to view what variables and vairable
values are stored in the R memory. This to enable debugging of R-scripts
I write.

Sumit


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From topkatz at msn.com  Wed Sep 12 21:05:10 2007
From: topkatz at msn.com (Talbot Katz)
Date: Wed, 12 Sep 2007 15:05:10 -0400
Subject: [R] "Save to File..." option on File menu
Message-ID: <BAY108-F318509DEC50A4B2653FB9FAAC20@phx.gbl>

Hi.

There was an interesting thread about a year ago, called  'Command 
equivalent of rgui "File, Save to File"?' 
(http://tolstoy.newcastle.edu.au/R/e2/help/06/09/0553.html) started by 
Michael Prager, and contributed to by Duncan Murdoch (I didn't notice 
anything beyond the four entries they posted).  The question was how to 
replicate programmatically the "Save to File..." option on the File menu.  
The closest answers given involved either running in batch or using the 
sink() command.  Perhaps I don't understand the sink() command well enough, 
but it appears to me that you have to set it up before you run commands, and 
that it can't be used to save command output from commands that were already 
run; am I right about this?  Whereas the "Save to File..." command scoops up 
everything that's still in the console.  Here is my problem.  I am running R 
on Linux in a VNC window.  I'd like to save my console output, but there 
doesn't appear to be a File menu available and I didn't start out with the 
sink() command.  Is there any way to replicate "Save to File..." in this 
situation?  Thanks!

--  TMK  --
212-460-5430	home
917-656-5351	cell


From albmont at centroin.com.br  Wed Sep 12 21:44:41 2007
From: albmont at centroin.com.br (Alberto Monteiro)
Date: Wed, 12 Sep 2007 17:44:41 -0200
Subject: [R] Evaluating args in a function
In-Reply-To: <971536df0709120955m287de40ch6b5656ba09a44d1f@mail.gmail.com>
References: <46E8185E.9020902@stat.umn.edu>
	<971536df0709120955m287de40ch6b5656ba09a44d1f@mail.gmail.com>
Message-ID: <20070912194326.M40507@centroin.com.br>

Gabor Grothendieck wrote:
>
> You have a recursive reference.  Try using a different name other 
> than class.  For example, in the following we use class. with a dot 
> at the end
> (so that abbreviation of it still allows the user to write class):
> 
One year using R, and I hadn't known that I could abbreviate
function arguments... Thanks for the (accidental) help :-)

Alberto Monteiro


From obaqueiro at gmail.com  Wed Sep 12 21:56:35 2007
From: obaqueiro at gmail.com (Omar Baqueiro)
Date: Wed, 12 Sep 2007 20:56:35 +0100
Subject: [R] Wilcoxon Rank test
Message-ID: <457a9aa40709121256o41add24ex6363c020d71d3bc6@mail.gmail.com>

Greetings, I am trying to perform a Mann-Whitney U test to a pair of
data series, according to what I have read about R the command to use
is:

wilcox.test(data1, data2)

However I am having trouble interpreting the results:
---
Wilcoxon rank sum test with continuity correction

data:  Dataset$OTMinR and Dataset$OTMaxW
W = 460627.5, p-value = 0.001798
alternative hypothesis: true location shift is not equal to 0
---

According to my understanding the test tests the hypothesis that  the
two data series are drawn from a single population. And I interpret
those results, having the p-value 0.001798, that the hypothesis is NOT
rejected, meaning that there is a high probability that the two
samples come from the same population. Is that interpretation true?

Also, I am not sure what is the alpha value of the performed test? is
it 0.05? or 0.01? is there a way to change it?

Thank you!

-- 
Omar Baqueiro Espinosa
Computer Science PhD Candidate
Computer Systems Engineer
Workpage: www.csc.liv.ac.uk/~omar/
HomePage (spanish):http://www.baqueiro.co.uk/
PGP Key available at: www.csc.liv.ac.uk/~omar/pgp.html
_____


From pausas at gmail.com  Wed Sep 12 21:58:53 2007
From: pausas at gmail.com (juli pausas)
Date: Wed, 12 Sep 2007 21:58:53 +0200
Subject: [R] reshape help
Message-ID: <a17009720709121258p68b406aapd926cfd83b4078e8@mail.gmail.com>

Hi,
I'm trying to use reshape but I cannot quite understand how it works.
Could somebody help me on this? Example, my data is something like:

mydat <- data.frame(tree= 1:10, serra=rep(1:2, c(5,5)), bt01= 101:110,
bt02= 201:210, bt03= 301:310,  mm01= 9101:9110, mm02= 9201:9210, mm03=
9301:9310)

> mydat
   tree serra bt01 bt02 bt03 mm01 mm02 mm03
1     1     1  101  201  301  9101  9201  9301
2     2     1  102  202  302  9102  9202  9302
3     3     1  103  203  303  9103  9203  9303
4     4     1  104  204  304  9104  9204  9304
5     5     1  105  205  305  9105  9205  9305
6     6     2  106  206  306  9106  9206  9306
7     7     2  107  207  307  9107  9207  9307
8     8     2  108  208  308  9108  9208  9308
9     9     2  109  209  309  9109  9209  9309
10   10     2  110  210  310  9110  9210  9310

that is, in the "wide form" with 2 constant variables (tree, serra)
and 6 variables that correspond to two variables (bt mm) measured in 3
years 01, 02, 03

I would like to reshaped the data to the long format as follows:

  tree serra   YEAR   bt   mm
     1     1    2001   101   9101
     2     1    2001   102   9102
     3     1    2001   103   9103
     4     1    2001   104   9104
     5     1    2001   105   9105
     6     2    2001   106   9106
     7     2    2001   107   9107
     8     2    2001   108   9108
     9     2    2001   109   9109
    10     2    2001   110   9110
     1     1    2002   201   9201
     2     1    2002   202   9202
     3     1    2002   203   9203
     4     1    2002   204   9204
     5     1    2002   205   9205
     6     2    2002   206   9206
     7     2    2002   207   9207
     8     2    2002   208   9208
     9     2    2002   209   9209
    10     2    2002   210   9210
     1     1    2003   301   9301
     2     1    2003   302   9302
     3     1    2003   303   9303
     4     1    2003   304   9304
     5     1    2003   305   9305
     6     2    2003   306   9306
     7     2    2003   307   9307
     8     2    2003   308   9308
     9     2    2003   309   9309
    10     2    2003   310   9310

I would appreciate if somebody let me know how could I do this with reshape
Thanks in advance

Juli


-- 
http://www.ceam.es/pausas


From huber at ebi.ac.uk  Wed Sep 12 22:18:07 2007
From: huber at ebi.ac.uk (Wolfgang Huber)
Date: Wed, 12 Sep 2007 21:18:07 +0100
Subject: [R] Wilcoxon Rank test
In-Reply-To: <457a9aa40709121256o41add24ex6363c020d71d3bc6@mail.gmail.com>
References: <457a9aa40709121256o41add24ex6363c020d71d3bc6@mail.gmail.com>
Message-ID: <46E8497F.4040902@ebi.ac.uk>

Dear Omar,

the p-value is the probability that a certain summary statistic U of the 
data takes the value it takes, given that the null-hypothesis is true. 
Your p-value is 0.002, you can compare this to an alpha of your choice, 
and if that alpha were larger, you would come to the decision that the 
null-hypothesis can be rejected.

Best wishes
   Wolfgang

------------------------------------------------------------------
Wolfgang Huber  EBI/EMBL  Cambridge UK  http://www.ebi.ac.uk/huber


  Baqueiro ha scritto:
> Greetings, I am trying to perform a Mann-Whitney U test to a pair of
> data series, according to what I have read about R the command to use
> is:
> 
> wilcox.test(data1, data2)
> 
> However I am having trouble interpreting the results:
> ---
> Wilcoxon rank sum test with continuity correction
> 
> data:  Dataset$OTMinR and Dataset$OTMaxW
> W = 460627.5, p-value = 0.001798
> alternative hypothesis: true location shift is not equal to 0
> ---
> 
> According to my understanding the test tests the hypothesis that  the
> two data series are drawn from a single population. And I interpret
> those results, having the p-value 0.001798, that the hypothesis is NOT
> rejected, meaning that there is a high probability that the two
> samples come from the same population. Is that interpretation true?
> 
> Also, I am not sure what is the alpha value of the performed test? is
> it 0.05? or 0.01? is there a way to change it?
> 
> Thank you!
>


From szhan at uoguelph.ca  Wed Sep 12 22:36:23 2007
From: szhan at uoguelph.ca (szhan at uoguelph.ca)
Date: Wed, 12 Sep 2007 16:36:23 -0400
Subject: [R] how to make an orthogonal contrasts matrix?
Message-ID: <20070912163623.ln8kwrpu8804gc08@webmail.uoguelph.ca>

Hello, R experts,
I have an 11 levels of a factor A. I am only interested in a constrast  
between first 4 vs rest 7 levels. Is there any command to make an  
orthogonal constrasts matrix given one contrast of interest such as   
7,7,7,7, -4,-4,-4,-4,-4,-4,-4?
Thanks,
Joshua


From ccleland at optonline.net  Wed Sep 12 22:39:27 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 12 Sep 2007 16:39:27 -0400
Subject: [R] reshape help
In-Reply-To: <a17009720709121258p68b406aapd926cfd83b4078e8@mail.gmail.com>
References: <a17009720709121258p68b406aapd926cfd83b4078e8@mail.gmail.com>
Message-ID: <46E84E7F.4070006@optonline.net>

juli pausas wrote:
> Hi,
> I'm trying to use reshape but I cannot quite understand how it works.
> Could somebody help me on this? Example, my data is something like:
> 
> mydat <- data.frame(tree= 1:10, serra=rep(1:2, c(5,5)), bt01= 101:110,
> bt02= 201:210, bt03= 301:310,  mm01= 9101:9110, mm02= 9201:9210, mm03=
> 9301:9310)
> 
>> mydat
>    tree serra bt01 bt02 bt03 mm01 mm02 mm03
> 1     1     1  101  201  301  9101  9201  9301
> 2     2     1  102  202  302  9102  9202  9302
> 3     3     1  103  203  303  9103  9203  9303
> 4     4     1  104  204  304  9104  9204  9304
> 5     5     1  105  205  305  9105  9205  9305
> 6     6     2  106  206  306  9106  9206  9306
> 7     7     2  107  207  307  9107  9207  9307
> 8     8     2  108  208  308  9108  9208  9308
> 9     9     2  109  209  309  9109  9209  9309
> 10   10     2  110  210  310  9110  9210  9310
> 
> that is, in the "wide form" with 2 constant variables (tree, serra)
> and 6 variables that correspond to two variables (bt mm) measured in 3
> years 01, 02, 03
> 
> I would like to reshaped the data to the long format as follows:
> 
>   tree serra   YEAR   bt   mm
>      1     1    2001   101   9101
>      2     1    2001   102   9102
>      3     1    2001   103   9103
>      4     1    2001   104   9104
>      5     1    2001   105   9105
>      6     2    2001   106   9106
>      7     2    2001   107   9107
>      8     2    2001   108   9108
>      9     2    2001   109   9109
>     10     2    2001   110   9110
>      1     1    2002   201   9201
>      2     1    2002   202   9202
>      3     1    2002   203   9203
>      4     1    2002   204   9204
>      5     1    2002   205   9205
>      6     2    2002   206   9206
>      7     2    2002   207   9207
>      8     2    2002   208   9208
>      9     2    2002   209   9209
>     10     2    2002   210   9210
>      1     1    2003   301   9301
>      2     1    2003   302   9302
>      3     1    2003   303   9303
>      4     1    2003   304   9304
>      5     1    2003   305   9305
>      6     2    2003   306   9306
>      7     2    2003   307   9307
>      8     2    2003   308   9308
>      9     2    2003   309   9309
>     10     2    2003   310   9310
> 
> I would appreciate if somebody let me know how could I do this with reshape

reshape(mydat, varying = list(c("bt01","bt02","bt03"),
                              c("mm01","mm02","mm03")),
               v.names=c("bt","mm"),
               timevar = "YEAR",
               times = c(2001, 2002, 2003),
               idvar = "tree",
               direction = "long")

        tree serra YEAR  bt   mm
1.2001     1     1 2001 101 9101
2.2001     2     1 2001 102 9102
3.2001     3     1 2001 103 9103
4.2001     4     1 2001 104 9104
5.2001     5     1 2001 105 9105
6.2001     6     2 2001 106 9106
7.2001     7     2 2001 107 9107
8.2001     8     2 2001 108 9108
9.2001     9     2 2001 109 9109
10.2001   10     2 2001 110 9110
1.2002     1     1 2002 201 9201
2.2002     2     1 2002 202 9202
3.2002     3     1 2002 203 9203
4.2002     4     1 2002 204 9204
5.2002     5     1 2002 205 9205
6.2002     6     2 2002 206 9206
7.2002     7     2 2002 207 9207
8.2002     8     2 2002 208 9208
9.2002     9     2 2002 209 9209
10.2002   10     2 2002 210 9210
1.2003     1     1 2003 301 9301
2.2003     2     1 2003 302 9302
3.2003     3     1 2003 303 9303
4.2003     4     1 2003 304 9304
5.2003     5     1 2003 305 9305
6.2003     6     2 2003 306 9306
7.2003     7     2 2003 307 9307
8.2003     8     2 2003 308 9308
9.2003     9     2 2003 309 9309
10.2003   10     2 2003 310 9310

> Thanks in advance
> 
> Juli 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From rmh at temple.edu  Wed Sep 12 22:55:00 2007
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 12 Sep 2007 16:55:00 -0400 (EDT)
Subject: [R] how to make an orthogonal contrasts matrix?
Message-ID: <20070912165500.CMK04544@po-d.temple.edu>

tmp <- c(7,7,7,7, -4,-4,-4,-4,-4,-4,-4)
tmpf <- factor(letters[1:11])
tmpf
contrasts(tmpf)
contrasts(tmpf) <- tmp
contrasts(tmpf)
zapsmall(crossprod(contrasts(tmpf)))


From p.dalgaard at biostat.ku.dk  Wed Sep 12 23:02:04 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 12 Sep 2007 23:02:04 +0200
Subject: [R] reshape help
In-Reply-To: <46E84E7F.4070006@optonline.net>
References: <a17009720709121258p68b406aapd926cfd83b4078e8@mail.gmail.com>
	<46E84E7F.4070006@optonline.net>
Message-ID: <46E853CC.3080808@biostat.ku.dk>

Chuck Cleland wrote:
> juli pausas wrote:
>   
>> Hi,
>> I'm trying to use reshape but I cannot quite understand how it works.
>> Could somebody help me on this? Example, my data is something like:
>>
>> mydat <- data.frame(tree= 1:10, serra=rep(1:2, c(5,5)), bt01= 101:110,
>> bt02= 201:210, bt03= 301:310,  mm01= 9101:9110, mm02= 9201:9210, mm03=
>> 9301:9310)
>>
>>     
>>> mydat
>>>       
>>    tree serra bt01 bt02 bt03 mm01 mm02 mm03
>> 1     1     1  101  201  301  9101  9201  9301
>> 2     2     1  102  202  302  9102  9202  9302
>> 3     3     1  103  203  303  9103  9203  9303
>> 4     4     1  104  204  304  9104  9204  9304
>> 5     5     1  105  205  305  9105  9205  9305
>> 6     6     2  106  206  306  9106  9206  9306
>> 7     7     2  107  207  307  9107  9207  9307
>> 8     8     2  108  208  308  9108  9208  9308
>> 9     9     2  109  209  309  9109  9209  9309
>> 10   10     2  110  210  310  9110  9210  9310
>>
>> that is, in the "wide form" with 2 constant variables (tree, serra)
>> and 6 variables that correspond to two variables (bt mm) measured in 3
>> years 01, 02, 03
>>
>> I would like to reshaped the data to the long format as follows:
>>
>>   tree serra   YEAR   bt   mm
>>      1     1    2001   101   9101
>>      2     1    2001   102   9102
>>      3     1    2001   103   9103
>>      4     1    2001   104   9104
>>      5     1    2001   105   9105
>>      6     2    2001   106   9106
>>      7     2    2001   107   9107
>>      8     2    2001   108   9108
>>      9     2    2001   109   9109
>>     10     2    2001   110   9110
>>      1     1    2002   201   9201
>>      2     1    2002   202   9202
>>      3     1    2002   203   9203
>>      4     1    2002   204   9204
>>      5     1    2002   205   9205
>>      6     2    2002   206   9206
>>      7     2    2002   207   9207
>>      8     2    2002   208   9208
>>      9     2    2002   209   9209
>>     10     2    2002   210   9210
>>      1     1    2003   301   9301
>>      2     1    2003   302   9302
>>      3     1    2003   303   9303
>>      4     1    2003   304   9304
>>      5     1    2003   305   9305
>>      6     2    2003   306   9306
>>      7     2    2003   307   9307
>>      8     2    2003   308   9308
>>      9     2    2003   309   9309
>>     10     2    2003   310   9310
>>
>> I would appreciate if somebody let me know how could I do this with reshape
>>     
>
> reshape(mydat, varying = list(c("bt01","bt02","bt03"),
>                               c("mm01","mm02","mm03")),
>                v.names=c("bt","mm"),
>                timevar = "YEAR",
>                times = c(2001, 2002, 2003),
>                idvar = "tree",
>                direction = "long")
>   
Yup. 2.6.0 will also allow this simplified variant:

 > reshape(mydat, direction="long", varying=3:8, sep="")
     tree serra time  bt   mm id
1.1     1     1    1 101 9101  1
2.1     2     1    1 102 9102  2
3.1     3     1    1 103 9103  3
4.1     4     1    1 104 9104  4
5.1     5     1    1 105 9105  5
6.1     6     2    1 106 9106  6
7.1     7     2    1 107 9107  7
8.1     8     2    1 108 9108  8
9.1     9     2    1 109 9109  9
10.1   10     2    1 110 9110 10
1.2     1     1    2 201 9201  1
2.2     2     1    2 202 9202  2
3.2     3     1    2 203 9203  3
4.2     4     1    2 204 9204  4
5.2     5     1    2 205 9205  5
6.2     6     2    2 206 9206  6
7.2     7     2    2 207 9207  7
8.2     8     2    2 208 9208  8
9.2     9     2    2 209 9209  9
10.2   10     2    2 210 9210 10
1.3     1     1    3 301 9301  1
2.3     2     1    3 302 9302  2
3.3     3     1    3 303 9303  3
4.3     4     1    3 304 9304  4
5.3     5     1    3 305 9305  5
6.3     6     2    3 306 9306  6
7.3     7     2    3 307 9307  7
8.3     8     2    3 308 9308  8
9.3     9     2    3 309 9309  9
10.3   10     2    3 310 9310 10



-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From maura.monville at gmail.com  Wed Sep 12 23:11:42 2007
From: maura.monville at gmail.com (Maura E Monville)
Date: Wed, 12 Sep 2007 16:11:42 -0500
Subject: [R] Flaw in the installation procedure ?
Message-ID: <36d691950709121411r69565d54uaf3a73cf0fc4b272@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070912/734b0503/attachment.pl 

From apezzola at reed.edu  Wed Sep 12 23:24:57 2007
From: apezzola at reed.edu (Anthony Pezzola)
Date: Wed, 12 Sep 2007 14:24:57 -0700
Subject: [R] convergence error with heidel.diag
Message-ID: <46E85929.4060002@reed.edu>

I received the following error after running:

####
 > heidel.diag(posterior, eps=0.1, pvalue=0.05)
Error in glm.fit(x = X, y = Y, weights = weights, start = start, 
etastart = etastart,  :
	inner loop 1; cannot correct step size
In addition: There were 21 warnings (use warnings() to see them)
 > test.diag <- heidel.diag(posterior, eps=0.1, pvalue=0.05)
Error in glm.fit(x = X, y = Y, weights = weights, start = start, 
etastart = etastart,  :
	inner loop 1; cannot correct step size
In addition: There were 21 warnings (use warnings() to see them)
 > warnings()
Warning messages:
1: algorithm did not converge in: glm.fit(x = X, y = Y, weights = 
weights, start = start, etastart = etastart,   ...
#####

posterior was generated using:

#####
 > posterior <-MCMCirt1d(mydata, theta.fixed =1, burnin=35000, 
mcmc=75000, thin=300)
#####

Is a chain of 250 simply too short for heidel.diag to work with?  If so 
how long should it be?

Thanks in advance,
Anthony

-- 
_____________________________
Anthony Pezzola
Visiting Assistant Professor
Department of Political Science
Reed College
503.517.7656


From elvis at xlsolutions-corp.com  Wed Sep 12 23:33:43 2007
From: elvis at xlsolutions-corp.com (elvis Miller)
Date: Wed, 12 Sep 2007 14:33:43 -0700
Subject: [R] New Course*** R / S-Plus Graphics for SAS Users --- October 2007
Message-ID: <20070912143343.aa8924c5d28ca71e2a043bb294e795eb.67b5f86ce2.wbe@email.secureserver.net>

XLSolutions is proud to announce a new 2-day R / S-plus course:

           R/S-Plus Graphics for SAS Users

***** San Francisco,       October  25-26, 2007
***** Seattle,             October  29-30, 2007
***** Philadelphia,        October  29-30, 2007

Should we bring this class to your city?

This 2-day intensive graphics course for SAS users introduces the basics
of R/S-Plus syntax and focuses on R/S-plus graphics. The course covers
in detail R/S-Plus traditional graphics functions and advanced graphics
topics such as trellis. Attendees will get a strong foundation for
becoming  versatile R/ S-plus graphics programmers.

- Introduction to R / S-plus
- R/S Syntax, Comparison to SAS Data Step and SAS IML
- Running R/ S-plus in Batch Mode
- Overview of R/ S-plus Graphics
- Low and High-level Graphics Functions
- Basic Plotting functions and Graphics Functions for Higher-dimensional
Data
- Enhancing Plots and Generating Multiple Figures on one Plot
- Fine Control of Graphics / Controlling the Appearance of Plots
- Trellis (Lattice) Graphics 
- Tricks and Troubleshooting
- Computer Lab Exercises Based on sample SAS graphs 
- Cutting edge R graphics packages: Rgraphiz, Iplot.

 Payment due AFTER the class
 Email us for group discounts.
 Email Sue Turner: sue at xlsolutions-corp.com
 Phone: 206-686-1578
 Visit us: www.xlsolutions-corp.com/courselist.htm
 Please let us know if you and your colleagues are interested in this
 class to take advantage of group discount. Register now to secure your
 seat!
 
 Cheers,
 Elvis Miller, PhD
 Manager Training.
 XLSolutions Corporation
 206 686 1578
 www.xlsolutions-corp.com


From muenchen at utk.edu  Thu Sep 13 01:03:38 2007
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Wed, 12 Sep 2007 19:03:38 -0400
Subject: [R] "Save to File..." option on File menu
In-Reply-To: <BAY108-F318509DEC50A4B2653FB9FAAC20@phx.gbl>
References: <BAY108-F318509DEC50A4B2653FB9FAAC20@phx.gbl>
Message-ID: <347152339B716A4D893C9A2988EA87C863A76A@KFSVS2.utk.tennessee.edu>

Hi Talbot,

I just had that question a couple of weeks ago. Here's the thread:

RSiteSearch("Saving results from Linux command line")

Thomas Lumley concluded with:

There could still be functions that divert a copy of all the output to a
file, for example. And indeed there are.

sink("transcript.txt", split=TRUE)

And you're right, you do this at the start, or put it in your .Rprofile
so you don't have to remember it each time. The UNIX tee command does
this as well.

Cheers,
Bob

=========================================================
Bob Muenchen (pronounced Min'-chen), Manager 
Statistical Consulting Center
U of TN Office of Information Technology
200 Stokely Management Center, Knoxville, TN 37996-0520
Voice: (865) 974-5230 
FAX: (865) 974-4810
Email: muenchen at utk.edu
Web: http://oit.utk.edu/scc, 
News: http://listserv.utk.edu/archives/statnews.html
=========================================================


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Talbot Katz
> Sent: Wednesday, September 12, 2007 3:05 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] "Save to File..." option on File menu
> 
> Hi.
> 
> There was an interesting thread about a year ago, called  'Command
> equivalent of rgui "File, Save to File"?'
> (http://tolstoy.newcastle.edu.au/R/e2/help/06/09/0553.html) started by
> Michael Prager, and contributed to by Duncan Murdoch (I didn't notice
> anything beyond the four entries they posted).  The question was how
to
> replicate programmatically the "Save to File..." option on the File
> menu.
> The closest answers given involved either running in batch or using
the
> sink() command.  Perhaps I don't understand the sink() command well
> enough,
> but it appears to me that you have to set it up before you run
> commands, and
> that it can't be used to save command output from commands that were
> already
> run; am I right about this?  Whereas the "Save to File..." command
> scoops up
> everything that's still in the console.  Here is my problem.  I am
> running R
> on Linux in a VNC window.  I'd like to save my console output, but
> there
> doesn't appear to be a File menu available and I didn't start out with
> the
> sink() command.  Is there any way to replicate "Save to File..." in
> this
> situation?  Thanks!
> 
> --  TMK  --
> 212-460-5430	home
> 917-656-5351	cell
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From emailclassifiedpkhcq at gmail.com  Thu Sep 13 01:45:51 2007
From: emailclassifiedpkhcq at gmail.com (Email Classified Now 1st time in Pakistan!)
Date: Thu, 13 Sep 2007 01:45:51 +0200
Subject: [R] Email Classified Send Over 100000-Pakistani BIZ Email Addresses
Message-ID: <200709122345.l8CNjp6o007078@hypatia.math.ethz.ch>

Monthly!
Sender: "Email Classified Now 1st time in Pakistan!" <emailclassifiedpkhcq at gmail.com>
Mime-Version: 1.0
Content-Type: multipart/related; type="multipart/alternative"; boundary="----=_NextPart_000_0177DE59_0.557487C2"
Date: Wed, 12 Sep 2007 15:53:57 -0700
Message-ID: <20070912225357234.4DDD53B34D2F1795 at Tahir_3f>
X-Priority: 1 (Highest)
Importance: High

This is a multipart MIME formatted message.

------=_NextPart_000_0177DE59_0.557487C2
Content-Type: multipart/alternative; boundary="----=_NextPart_000_0177DE59_1.557487C2"

------=_NextPart_000_0177DE59_1.557487C2
Content-Type: text/plain; charset="ISO-8859-1"
Content-Transfer-Encoding: quoted-printable

PAKISTAN 1st E-mail Classified!
Send Over 100000-Pakistani Business E-mail Addresses!Advertise your AD here=
 Only Rs.7500/Month
Order Now at 0333-2303103 
Your AD Title here:
Your AD Description here.
 



Contact:
E-mail:Your AD Title here:
Your AD Description here.







Contact:
E-mail:Your AD Title here:
Your AD Description here.







Contact:
E-mail:
Your AD Title here:
Your AD Description here.

 


Contact:
E-mail:
        *********
Your AD Title here:
Your AD Description here.
 


Contact:
E-mail:
          *********
Your AD Title here:
Your AD Description here.





Contact:
E-mail:Why Advertised in Pakistan 1st E-mail Classified?
* E-mail Classified Send Daily Over 3000-Freash  Active Pakistani Business =
E-mail Addresses!
* Real Time Hourly, Daily, Weekly, Monthly & Yearly E-mail Reading Log repo=
rt!
* We Only Accept Business, Education, Entertainment, Technical, Jobs, Real =
Estate, Travel Agencies Ads.
* We have Right to Reject any AD any Time with or without any Reasons.
* No E-mail Response Guaranteed!
* Offered Only Valid for our Pakistan Subscribers! 
* 100% Advanced Payment Required to Place your AD Here.
* We Accept Payment Through Bank Transfer Only.
Your AD Title here:
Your AD Description here.




Contact:
E-mail:Your AD Title here:
Your AD Description here.




Contact:
E-mail: 
Your AD Title here:
Your AD Description here.




Contact:
E-mail: Your AD Title here:
Your AD Description here.




Contact:
E-mail:  
Pakistan 1stE-mail Classified! For Placing your AD here Please Call/SMS at =
0333-2303103(24-Hour & Sunday Open!). 
If you wish to cancel your subscription to Pakistan 1st E-mail Classified P=
lease click here

------=_NextPart_000_0177DE59_1.557487C2
Content-Type: text/html; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

<html>
<head>
<title>Pakistan 1st E-mail Classified</title>
<meta http-equiv=3D"Content-Type" content=3D"text/html; charset=3Diso-8859-=
1">
<style type=3D"text/css">
<!--
body,td,th {
=09font-family: verdana;
=09font-size: 10px;
}
body {
=09background-color: #FFFFFF;
=09margin-left: 0px;
=09margin-top: 0px;
}
..text1 {
=09font-family: verdana;
=09font-size: 10px;
=09font-weight: normal;
=09color: #000000;
}
..text2 {
=09font-family: verdana;
=09font-size: 10px;
=09font-weight: bold;
=09color: #000000;
}
..text3 {
=09font-family: verdana;
=09font-size: 10px;
=09font-weight: bold;
=09color: #FFFFFF;
}
..text4 {
=09font-family: verdana;
=09font-size: 10px;
=09font-weight: bold;
=09color: #262425;
}
..text5 {
=09font-family: verdana;
=09font-size: 10px;
=09font-weight: normal;
=09color: #FFFFFF;
}
..text6 {
=09font-family: verdana;
=09font-size: 10px;
=09font-weight: normal;
=09color: #3E4A56;
}
..brder {
=09border: 1px solid #545C67;
}
-->
</style></head>
<center>
<body>
<table width=3D"570" border=3D"0" cellpadding=3D"5" cellspacing=3D"1" class=
=3D"border_2" height=3D"615">
  <!--DWLayoutTable-->
  <tr>
    <td colspan=3D"2" valign=3D"top" bgcolor=3D"#FFCC33" class=3D"brder"><b>
=09<font face=3D"Arial Rounded MT Bold" size=3D"4" color=3D"#FFFFFF">PAKIST=
AN 1st 
=09E-mail Classified!<br>
=09</font><font face=3D"Arial Narrow" size=3D"2">Send Over 100000-Pakistani 
=09Business E-mail Addresses!</font></b></td>
    <td colspan=3D"2" align=3D"center" valign=3D"middle" bgcolor=3D"#262425=
" height=3D"34">
=09<span class=3D"text5">Advertise your AD here Only Rs.7500/Month</span><s=
pan class=3D"style1"><span class=3D"style2"><br>
      </span></span><span class=3D"text3"><strong>Order Now at 0333-2303103=
</strong>
=09</span></td>
  </tr>
=09<tr>
  =09<td  align=3D"left" valign=3D"top" class=3D"brder"><span class=3D"styl=
e5"><u><strong class=3D"text4">
=09Your AD Title here:</strong></u><br>
        Your AD Description here.<br>
&nbsp;</span><p>&nbsp;</p>
=09<p><span class=3D"style5"><br>
=09<br>
=09<b>Contact:</b><br>
=09<b>E-mail:</b></span></td>
    <td  align=3D"left" valign=3D"top" bgcolor=3D"#FFFFFF" class=3D"brder">=
<span class=3D"style5">
=09<u><strong class=3D"text4">Your AD Title here:</strong></u><br>
        Your AD Description here.<br>
=09<br>
=09<br>
=09<br>
=09<br>
=09<br>
=09<br>
=09<br>
=09<b>Contact:</b><br>
=09<b>E-mail:</b></span></td>
    <td colspan=3D"2"  align=3D"left" valign=3D"top" bgcolor=3D"#FFFFFF" cl=
ass=3D"brder" height=3D"145">
      <p><span class=3D"style5"><u><strong class=3D"text4">Your AD Title he=
re:</strong></u><br>
        Your AD Description here.<br>
=09=09<br>
=09=09<br>
=09=09<br>
=09=09<br>
=09=09<br>
=09=09<br>
=09=09<br>
=09=09<b>Contact:</b><br>
=09=09<b>E-mail:</b></span></p></td>
  </tr>
=09<tr>
    <td rowspan=3D"3" align=3D"left" valign=3D"top" bgcolor=3D"#CFA712">
=09<div align=3D"left">
          <span class=3D"style5"><u><strong class=3D"text4">Your AD Title h=
ere:</strong></u><br>
        =09Your AD Description here.<br>
=09=09=09<br>
&nbsp;</span><p><span class=3D"style5"><br>
=09=09=09<br>
=09=09=09<b>Contact:</b><br>
=09=09=09<b>E-mail:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *********</b><u><strong class=3D=
"text4"><br>
=09=09=09Your AD Title here:</strong></u><br>
        =09Your AD Description here.<br>
&nbsp;</span></p>
=09=09=09<p>&nbsp;</p>
=09=09=09<p><span class=3D"style5"><br>
=09=09=09<b>Contact:</b><br>
=09=09=09<b>E-mail:</b><u><strong class=3D"text4"><br>
=09=09=09</strong></u><b>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp; 
=09=09=09*********</b><u><strong class=3D"text4"><br>
=09=09=09Your AD Title here:</strong></u><br>
        =09Your AD Description here.<br>
=09=09=09<br>
=09=09=09<b><br>
=09=09=09<br>
=09=09=09<br>
=09=09=09<br>
=09=09=09Contact:</b><br>
=09=09=09<b>E-mail:</b></span></div></td>
    <td colspan=3D"3" align=3D"left" valign=3D"top" bgcolor=3D"D0D3CC" heig=
ht=3D"167"> <u>
=09<b>Why Advertised in Pakistan 1st E-mail Classified?<br>
=09</b></u>* E-mail Classified Send Daily Over 3000-Freash&nbsp; Active 
=09Pakistani Business E-mail Addresses!<br>
=09* Real Time Hourly, Daily, Weekly, Monthly &amp; Yearly E-mail Reading L=
og 
=09report!<br>
=09* We Only Accept Business, Education, Entertainment, Technical, Jobs, Re=
al 
=09Estate, Travel Agencies Ads.<br>
=09* We have Right to Reject any AD any Time with or without any Reasons.<b=
r>
=09* No E-mail Response Guaranteed!<br>
=09* Offered Only Valid for our Pakistan Subscribers! <br>
=09* 100% Advanced Payment Required to Place your AD Here.<br>
=09* We Accept Payment Through Bank Transfer Only.</td>
    </tr>
=09<tr>
    <td colspan=3D"2" align=3D"left" valign=3D"top" bgcolor=3D"CFA712"><spa=
n class=3D"style5">
=09<u><strong class=3D"text4"><font color=3D"#FFFFFF">Your AD Title here:</=
font></strong></u><font color=3D"#FFFFFF"><br>
        Your AD Description here.<br>
=09<br>
=09<b><br>
=09<br>
=09<br>
=09Contact:</b><br>
=09<b>E-mail:</b></font></span></td>
    <td align=3D"left" valign=3D"top" bgcolor=3D"#FFFFFF" class=3D"brder" h=
eight=3D"90"><p class=3D"style5"><span class=3D"style5">
=09<u><strong class=3D"text4">Your AD Title here:</strong></u><br>
        Your AD Description here.<br>
=09<br>
=09<b><br>
=09<br>
=09<br>
=09Contact:</b><br>
=09<b>E-mail:</b><strong><span class=3D"text1"> 
  </span></strong></span></p>      </td>
  </tr>
=09<tr>
    <td colspan=3D"2" align=3D"left" valign=3D"top" bgcolor=3D"#FFFFFF" cla=
ss=3D"brder"><p><span class=3D"style5">
=09<u><strong class=3D"text4">Your AD Title here:</strong></u><br>
        Your AD Description here.<br>
=09<br>
=09<b><br>
=09<br>
=09<br>
=09Contact:</b><br>
=09<b>E-mail:</b><strong><span class=3D"text1"> 
  </span></strong></span></p></td>
    <td align=3D"left" valign=3D"top" bgcolor=3D"#262425" height=3D"114"><s=
pan class=3D"style5">
=09<u><strong class=3D"text4"><font color=3D"#FFFFFF">Your AD Title here:</=
font></strong></u><font color=3D"#FFFFFF"><br>
        Your AD Description here.<br>
=09<br>
=09<b><br>
=09<br>
=09<br>
=09Contact:</b><br>
=09<b>E-mail:</b></font><strong><span class=3D"text1"><font color=3D"#FFFFF=
F">
=09</font> 
  </span></strong></span><span class=3D"text3"><span class=3D"style5"><stro=
ng> 
=09<span class=3D"text5"><a href=3D"#" class=3D"text5">&nbsp;</a></span></s=
trong></span><span class=3D"text5"></span></span></td>
  </tr>
=09<tr>
    <td colspan=3D"4" class=3D"brder" height=3D"24"><b>Pakistan 1stE-mail C=
lassified! 
=09For Placing your AD here Please Call/SMS at 0333-2303103(24-Hour &amp; S=
unday 
=09Open!). </b></td>
    </tr>
=09<tr>
    <td colspan=3D"4" valign=3D"top" height=3D"22"><span class=3D"text1">If=
 you wish to 
=09cancel your subscription to Pakistan 1st E-mail Classified Please
=09<a class=3D"text4" href=3D"mailto:seopk at yahoo.com?subject=3DPls Removed =
my Subscribtion from Pakistan 1st E-mail Classified!">
=09click here</a></span></td>
    </tr>
=09<tr>
    <td width=3D"145"></td>
    <td width=3D"178"></td>
    <td width=3D"11"></td>
    <td height=3D"10" width=3D"191"></td>
  </tr>
</table>
</body>
</center>
</html>
<table width=3D'83' border=3D'0' cellspacing=3D'0' cellpadding=3D'0'><tr><t=
d width=3D'83' height=3D'19'><a href=3D'http://www.buyflowersonline.com' ta=
rget=3D'_blank'><img src=3D'http://www.free-website-counters.com/counter/st=
yles/basic/1/users/16857/counter.jpg' border=3D'0' alt=3D'buy flowers'></a>=
</td></tr><tr><td height=3D'13'><a href=3D'http://www.free-website-counters=
.com' target=3D'_blank'><img src=3D'http://www.free-website-counters.com/co=
unter/styles/basic/1/users/16857/sponsor.jpg' alt=3D'Free Counters' height=
=3D'13' border=3D'0'></a><a href=3D'http://www.free-website-counters.com/co=
unter/stats/stats.asp?id=3D16857' target=3D'_blank'><img src=3D'http://www.=
free-website-counters.com/counter/stats.gif' width=3D'34' height=3D'13' bor=
der=3D'0'></a></td></tr></table><table width=3D'83' border=3D'0' cellpaddin=
g=3D'0' cellspacing=3D'0'><tr align=3D'center'><td height=3D'15' colspan=3D=
'2'><font size=3D'1' face=3D'Arial'><a href=3D'' target=3D'_blank'></a></fo=
nt></td><

------=_NextPart_000_0177DE59_1.557487C2--

------=_NextPart_000_0177DE59_0.557487C2--


From tsakai at gallo.ucsf.edu  Thu Sep 13 02:06:42 2007
From: tsakai at gallo.ucsf.edu (Tena Sakai)
Date: Wed, 12 Sep 2007 17:06:42 -0700
Subject: [R] trouble with installing Biobase package
Message-ID: <FE44E0D7EAD2ED4BB2165071DB8E328C03062C0C@egcrc-ex01.egcrc.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070912/a9905543/attachment.pl 

From mtmorgan at fhcrc.org  Thu Sep 13 02:18:04 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 12 Sep 2007 17:18:04 -0700
Subject: [R] trouble with installing Biobase package
In-Reply-To: <FE44E0D7EAD2ED4BB2165071DB8E328C03062C0C@egcrc-ex01.egcrc.org>
	(Tena Sakai's message of "Wed, 12 Sep 2007 17:06:42 -0700")
References: <FE44E0D7EAD2ED4BB2165071DB8E328C03062C0C@egcrc-ex01.egcrc.org>
Message-ID: <6ph3axjs9j7.fsf@gopher4.fhcrc.org>

Hi Tena -- Please use the Bioconductor mailing list for Bioconductor
questions.

You need to update your development version of R to the prerelease
version (provide the output of sessionInfo() with problem reports).

Martin

"Tena Sakai" <tsakai at gallo.ucsf.edu> writes:

> Hi Everybody,
>
> I am having a problem with loading Biobase package.  I typed
> 2 lines below at R prompt
>
>  > source ("http://boconductor.org/biocLite.R")
>  > biocLite (lib="/usr/local/lib/R/library")
>
> which attempted to install a bunch of packages with varying
> degree of success.  Out of 29, 13 failed.  Biobase is one of
> them.  As a matter of fact, when I looked at logs, most other
> failures seemed due to the fact Biobase not being there.  So,
> why is Biobase failing to compile?  Here's the complaint:
>
>  * Installing *source* package 'Biobase' ...
>  ** libs
>  gcc -std=gnu99 -I/usr/local/lib64/R/include -I/usr/local/lib64/R/include  -I/usr/local/include    -fpic  -g -O2 -c anyMissing.c -o anyMissing.o
>  gcc -std=gnu99 -I/usr/local/lib64/R/include -I/usr/local/lib64/R/include  -I/usr/local/include    -fpic  -g -O2 -c envir.c -o envir.o
>  gcc -std=gnu99 -I/usr/local/lib64/R/include -I/usr/local/lib64/R/include  -I/usr/local/include    -fpic  -g -O2 -c matchpt.c -o matchpt.o
>  gcc -std=gnu99 -I/usr/local/lib64/R/include -I/usr/local/lib64/R/include  -I/usr/local/include    -fpic  -g -O2 -c Rinit.c -o Rinit.o
>  gcc -std=gnu99 -I/usr/local/lib64/R/include -I/usr/local/lib64/R/include  -I/usr/local/include    -fpic  -g -O2 -c rowMedians.c -o rowMedians.o
>  gcc -std=gnu99 -I/usr/local/lib64/R/include -I/usr/local/lib64/R/include  -I/usr/local/include    -fpic  -g -O2 -c sublist_extract.c -o sublist_extract.o
>  gcc -std=gnu99 -shared -L/usr/local/lib64 -o Biobase.so anyMissing.o envir.o matchpt.o Rinit.o rowMedians.o sublist_extract.o  
>  ** R
>  ** data
>  ** inst
>  ** preparing package for lazy loading
>  Loading required package: tools
>  Error : could not find function "numeric_version"
>  Error: unable to load R code in package 'Biobase'
>  Execution halted
>  ERROR: lazy loading failed for package 'Biobase'
>  ** Removing '/usr/local/lib/R/library/Biobase'
>
> It is choking at not finding a function "numeric_version".  Has anybody
> seen this before and have any insight to the solution?  I would appreciate
> a bit of helping hand.
>
> The platform I am on is Dell 64-bit server, running redhat enterprise
> server.
>
> Regards,
>
> Tena Sakai
> tsakai at gallo.ucsf.edu
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From r.darnell at uq.edu.au  Thu Sep 13 02:40:01 2007
From: r.darnell at uq.edu.au (Ross Darnell)
Date: Thu, 13 Sep 2007 10:40:01 +1000
Subject: [R] reshape help
In-Reply-To: <46E853CC.3080808@biostat.ku.dk>
References: <a17009720709121258p68b406aapd926cfd83b4078e8@mail.gmail.com>
	<46E84E7F.4070006@optonline.net> <46E853CC.3080808@biostat.ku.dk>
Message-ID: <E4178EE0463C7D40AF637C4DDAC8030ECD3AAC@UQEXMB2.soe.uq.edu.au>



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Peter Dalgaard
Sent: Thursday, 13 September 2007 7:02 AM
To: Chuck Cleland
Cc: R-help; juli pausas
Subject: Re: [R] reshape help

Chuck Cleland wrote:
> juli pausas wrote:
>   
>> Hi,
>> I'm trying to use reshape but I cannot quite understand how it works.
>> Could somebody help me on this? Example, my data is something like:
>>
>> mydat <- data.frame(tree= 1:10, serra=rep(1:2, c(5,5)), bt01= 101:110,
>> bt02= 201:210, bt03= 301:310,  mm01= 9101:9110, mm02= 9201:9210, mm03=
>> 9301:9310)
>>
>>     
>>> mydat
>>>       
>>    tree serra bt01 bt02 bt03 mm01 mm02 mm03
>> 1     1     1  101  201  301  9101  9201  9301
>> 2     2     1  102  202  302  9102  9202  9302
>> 3     3     1  103  203  303  9103  9203  9303
>> 4     4     1  104  204  304  9104  9204  9304
>> 5     5     1  105  205  305  9105  9205  9305
>> 6     6     2  106  206  306  9106  9206  9306
>> 7     7     2  107  207  307  9107  9207  9307
>> 8     8     2  108  208  308  9108  9208  9308
>> 9     9     2  109  209  309  9109  9209  9309
>> 10   10     2  110  210  310  9110  9210  9310
>>
>> that is, in the "wide form" with 2 constant variables (tree, serra)
>> and 6 variables that correspond to two variables (bt mm) measured in 3
>> years 01, 02, 03
>>
>> I would like to reshaped the data to the long format as follows:
>>
>>   tree serra   YEAR   bt   mm
>>      1     1    2001   101   9101
>>      2     1    2001   102   9102
>>      3     1    2001   103   9103
>>      4     1    2001   104   9104
>>      5     1    2001   105   9105
>>      6     2    2001   106   9106
>>      7     2    2001   107   9107
>>      8     2    2001   108   9108
>>      9     2    2001   109   9109
>>     10     2    2001   110   9110
>>      1     1    2002   201   9201
>>      2     1    2002   202   9202
>>      3     1    2002   203   9203
>>      4     1    2002   204   9204
>>      5     1    2002   205   9205
>>      6     2    2002   206   9206
>>      7     2    2002   207   9207
>>      8     2    2002   208   9208
>>      9     2    2002   209   9209
>>     10     2    2002   210   9210
>>      1     1    2003   301   9301
>>      2     1    2003   302   9302
>>      3     1    2003   303   9303
>>      4     1    2003   304   9304
>>      5     1    2003   305   9305
>>      6     2    2003   306   9306
>>      7     2    2003   307   9307
>>      8     2    2003   308   9308
>>      9     2    2003   309   9309
>>     10     2    2003   310   9310
>>
>> I would appreciate if somebody let me know how could I do this with reshape
>>     
>
> reshape(mydat, varying = list(c("bt01","bt02","bt03"),
>                               c("mm01","mm02","mm03")),
>                v.names=c("bt","mm"),
>                timevar = "YEAR",
>                times = c(2001, 2002, 2003),
>                idvar = "tree",
>                direction = "long")
>   
Yup. 2.6.0 will also allow this simplified variant:

 > reshape(mydat, direction="long", varying=3:8, sep="")
     tree serra time  bt   mm id
1.1     1     1    1 101 9101  1
2.1     2     1    1 102 9102  2
3.1     3     1    1 103 9103  3
4.1     4     1    1 104 9104  4
5.1     5     1    1 105 9105  5
6.1     6     2    1 106 9106  6
7.1     7     2    1 107 9107  7
8.1     8     2    1 108 9108  8
9.1     9     2    1 109 9109  9
10.1   10     2    1 110 9110 10
1.2     1     1    2 201 9201  1
2.2     2     1    2 202 9202  2
3.2     3     1    2 203 9203  3
4.2     4     1    2 204 9204  4
5.2     5     1    2 205 9205  5
6.2     6     2    2 206 9206  6
7.2     7     2    2 207 9207  7
8.2     8     2    2 208 9208  8
9.2     9     2    2 209 9209  9
10.2   10     2    2 210 9210 10
1.3     1     1    3 301 9301  1
2.3     2     1    3 302 9302  2
3.3     3     1    3 303 9303  3
4.3     4     1    3 304 9304  4
5.3     5     1    3 305 9305  5
6.3     6     2    3 306 9306  6
7.3     7     2    3 307 9307  7
8.3     8     2    3 308 9308  8
9.3     9     2    3 309 9309  9
10.3   10     2    3 310 9310 10



-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


[Ross D] 

That's neat but how did the function recognize the difference between the 3:5 and 6:8 structure?

Ross Darnell
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From hb at stat.berkeley.edu  Thu Sep 13 03:04:59 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Wed, 12 Sep 2007 18:04:59 -0700
Subject: [R] R: to view the memory
In-Reply-To: <004e01c7f56f$749a6940$3a0b2c0a@gne.windows.gene.com>
References: <C6EB3844F7C76A42965909494BB1779203630A8D@NLDNC104PEX1.ubsw.net>
	<004e01c7f56f$749a6940$3a0b2c0a@gne.windows.gene.com>
Message-ID: <59d7961d0709121804k59a6831ende49a15c18a85b3b@mail.gmail.com>

For listings, you have ls(), ls.str(), and also ll() in R.oo, e.g.

> library(R.oo)
R.oo v1.3.0 (2006-08-29) successfully loaded. See ?R.oo for help.

> data(USArrests)
> data(lynx)
> data(Nile)
> data(iris3)
> data(iris)
> data(euro)

> ls()
[1] "euro"       "euro.cross" "iris"       "iris3"
[5] "lynx"       "Nile"       "USArrests"

> ls.str()
euro :  Named num [1:11]  13.76  40.34   1.96 166.39   5.95 ...
euro.cross :  num [1:11, 1:11] 1.0000 0.3411 7.0355 0.0827 2.3143
iris : 'data.frame':    150 obs. of  5 variables:
 $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
 $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
 $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
 $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
 $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1
1 ...
iris3 :  num [1:50, 1:4, 1:3] 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9
lynx :  Time-Series [1:114] from 1821 to 1934:  269  321  585  871
Nile :  Time-Series [1:100] from 1871 to 1970: 1120 1160 963 1210
1230 1370 1140 ...
USArrests : 'data.frame':       50 obs. of  4 variables:
 $ Murder  : num  13.2 10 8.1 8.8 9 7.9 3.3 5.9 15.4 17.4 ...
 $ Assault : int  236 263 294 190 276 204 110 238 335 211 ...
 $ UrbanPop: int  58 48 80 50 91 78 77 72 80 60 ...
 $ Rape    : num  21.2 44.5 31 19.5 40.6 38.7 11.1 15.8 31.9 25.8

> ll()
      member data.class dimension objectSize
1       euro    numeric        11        632
2 euro.cross     matrix  c(11,11)       2016
3       iris data.frame  c(150,5)       6424
4      iris3      array c(50,4,3)       5368
5       lynx         ts       114       1168
6       Nile         ts       100       1056
7  USArrests data.frame   c(50,4)       3824

Cheers

Henrik

On 9/12/07, Bert Gunter <gunter.berton at gene.com> wrote:
> You probably should be inserting browser() calls into your function instead
> -- once there you can list and examine all variables at whatever state your
> function is in. (and debugging is specifically what browser() was designed
> for).
>
> See ?browser()
>
>
> Bert Gunter
> Genentech Nonclinical Statistics
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf Of Sumit.Gupta at ubs.com
> Sent: Tuesday, September 11, 2007 7:02 PM
> To: r-help at r-project.org
> Subject: [R] R: to view the memory
>
> Hello,
>
> I am wondering if it is possible to view what variables and vairable
> values are stored in the R memory. This to enable debugging of R-scripts
> I write.
>
> Sumit
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pinard at iro.umontreal.ca  Thu Sep 13 03:34:24 2007
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Wed, 12 Sep 2007 21:34:24 -0400
Subject: [R] reshape help
In-Reply-To: <E4178EE0463C7D40AF637C4DDAC8030ECD3AAC@UQEXMB2.soe.uq.edu.au>
References: <a17009720709121258p68b406aapd926cfd83b4078e8@mail.gmail.com>
	<46E84E7F.4070006@optonline.net> <46E853CC.3080808@biostat.ku.dk>
	<E4178EE0463C7D40AF637C4DDAC8030ECD3AAC@UQEXMB2.soe.uq.edu.au>
Message-ID: <20070913013424.GA18140@alcyon.progiciels-bpi.ca>

[Ross Darnell]

>>> I'm trying to use reshape but I cannot quite understand how it 
>>> works.

>Yup. 2.6.0 will also allow this simplified variant:

> > reshape(mydat, direction="long", varying=3:8, sep="")
> > [...]

Hi, people.  Have "melt" and "cast" (from the "reshape" package) ever 
been considered for integration in R "stats" package (or any convenient 
standardly distributed package)?  They gave me the impression of being 
neatly specified, and presumably useful for many of us.

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From john_d_mchenry at yahoo.com  Thu Sep 13 04:08:38 2007
From: john_d_mchenry at yahoo.com (John McHenry)
Date: Wed, 12 Sep 2007 19:08:38 -0700 (PDT)
Subject: [R] Multivariate, multilevel regression?
Message-ID: <728924.50404.qm@web35413.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070912/61572333/attachment.pl 

From bolker at ufl.edu  Thu Sep 13 04:35:33 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 13 Sep 2007 02:35:33 +0000 (UTC)
Subject: [R] Nested anova with unbalanced design and corrected sample
	size for spatial autocorrelation
References: <2039.129.128.246.84.1189622319.squirrel@mail.ctfc.es>
Message-ID: <loom.20070913T042941-796@post.gmane.org>

   


Francesc Montan? <francesc.montane <at> ctfc.es> writes:

> 
> 
> Hello all,
> 
> This may be a simple question to answer, but I'm a little bit stumped with
> respect to the calculation of the F statistics in nested  anovas with
> unbalanced design in R.


  I would strongly recommend getting a copy of Pinheiro and
Bates (2000) and going through it.  aov() is out of the question, and it's
probably better to incorporate spatial correlation
directly in the model than to adjust degrees of freedom
to account for it.

  good luck,
     Ben Bolker
>


From gathibandhe.vaibhav at gmail.com  Thu Sep 13 04:50:31 2007
From: gathibandhe.vaibhav at gmail.com (Vaibhav Gathibandhe)
Date: Wed, 12 Sep 2007 21:50:31 -0500
Subject: [R] Someone Using Java/R Interface--- JRI ?
Message-ID: <d09859290709121950l2de67ca8mfe9d843e2e7a065d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070912/ec98dd16/attachment.pl 

From gathibandhe.vaibhav at gmail.com  Thu Sep 13 05:59:01 2007
From: gathibandhe.vaibhav at gmail.com (Vaibhav Gathibandhe)
Date: Wed, 12 Sep 2007 22:59:01 -0500
Subject: [R] Running R file from Command line.
Message-ID: <d09859290709122059t6cf3593q3373abc7a289a25d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070912/fde09404/attachment.pl 

From dunn at usq.edu.au  Thu Sep 13 06:10:54 2007
From: dunn at usq.edu.au (Peter Dunn)
Date: Thu, 13 Sep 2007 14:10:54 +1000
Subject: [R] Problem using xtable on an array
Message-ID: <200709131410.54151.dunn@usq.edu.au>

Hi all

I know about producing a minimal example to show my problem.  But I'm
having trouble producing a minimal example that displays this
behaviour, so please bear with me to begin with.


Observe:  I create an array called model.mat.  Some details on this:

> str(model.mat)
 num [1:18, 1:4] -0.170 -0.304 -2.617  2.025 -1.610 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:18] "Amount: CP for VF" "Amount: CP for F" "Amount: CP for 
M" "Amount: RD for VF" ...
  ..$ : chr [1:4] "beta_0" "P-value" "beta_1" "P-value"


It contains the following:

> model.mat[1:2,]
                      beta_0   P-value    beta_1      P-value
Amount: CP for VF -0.1702877 0.7716153 0.5148616 2.020602e-03
Amount: CP for F  -0.3042522 0.1966133 0.8795982 6.058299e-12



That's fine.  Now to produce a LaTeX table using xtable,
I get:

> xtable(model.mat[1:2,])
<snip>
  Amount: CP for VF & $-$0.17 & 0.77 & 0.51 & 0.77 \\
  Amount: CP for F & $-$0.30 & 0.20 & 0.88 & 0.20 \\
<snip>

That is, the final column does *not* correspond to the final
column of model.mat itself.  It is actually column 2 repeated.

What's going on?  If I try repeating on a minimal type example,
xtable works as expected:


> fred <- array( seq(1,18*4), dim=c(18,4))
> fred[1:2, ]
     [,1] [,2] [,3] [,4]
[1,]    1   19   37   55
[2,]    2   20   38   56
> xtable(fred[1:2, ])
% latex table generated in R 2.5.0 by xtable 1.4-6 package
% Thu Sep 13 14:09:46 2007
\begin{table}[ht]
\begin{center}
\begin{tabular}{rrrrr}
  \hline
 & 1 & 2 & 3 & 4 \\
  \hline
1 &   1 &  19 &  37 &  55 \\
  2 &   2 &  20 &  38 &  56 \\
   \hline
\end{tabular}
\end{center}
\end{table}


So it is not a generic problem. But what could it be?  I can't decide
where to look, so find a solution or produce a minimal example to display
this behaviour.  I actually use this construct with xtable a lot, so
it disturbs me to find this error... which is probably is something
I am doing.



The problem exists for a smaller subsets of this array also; let's take
columns 2, 3 and 4 only:

> model.mat[1:2,2:4]
                    P-value    beta_1      P-value
Amount: CP for VF 0.7716153 0.5148616 2.020602e-03
Amount: CP for F  0.1966133 0.8795982 6.058299e-12
> xtable(model.mat[1:2,2:4])
% latex table generated in R 2.5.0 by xtable 1.4-6 package
% Thu Sep 13 14:04:40 2007
\begin{table}[ht]
\begin{center}
\begin{tabular}{rrrr}
  \hline
 & P-value & beta\_1 & P-value \\
  \hline
Amount: CP for VF & 0.77 & 0.51 & 0.77 \\
  Amount: CP for F & 0.20 & 0.88 & 0.20 \\
   \hline
\end{tabular}
\end{center}
\end{table}


Is it a problem with my particular array  model.mat  or something
I am doing wrong/silly?  I don't know where to start.

Thanks all, as always.

P.

> sessionInfo()
R version 2.5.0 (2007-04-23)
i486-pc-linux-gnu

locale:
LC_CTYPE=en_AU.UTF-8;LC_NUMERIC=C;LC_TIME=en_AU.UTF-8;LC_COLLATE=en_AU.UTF-8;LC_MONETARY=en_AU.UTF-8;LC_MESSAGES=en_AU.UTF-8;LC_PAPER=en_AU.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_AU.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
[7] "base"

other attached packages:
    car  xtable statmod
"1.2-1" "1.4-6" "1.3.0"



-- 
Dr Peter Dunn  |  dunn <at> usq.edu.au
Faculty of Sciences, USQ; http://www.sci.usq.edu.au/staff/dunn
Aust. Centre for Sustainable Catchments: www.usq.edu.au/acsc

This email (including any attached files) is confidential an...{{dropped}}


From tongcheng789 at tom.com  Thu Sep 13 06:26:23 2007
From: tongcheng789 at tom.com (=?GB2312?B?saa7qrmk0rU=?=)
Date: Thu, 13 Sep 2007 12:26:23 +0800
Subject: [R] =?GB2312?B?ssbO8dDEyfmhow==?=
Message-ID: <200709130425.l8D4PbIa012450@hypatia.math.ethz.ch>

  TO:????????!

  ??????????????????????????

       ??????????????????????,????????????????????????????????  
  ????????????????????/??????????????????????????????????
  ??????????????????/????

     ??1????????????/????????????????????????????????????
     ??2????????????/?????????????????????????????????? 
          ?????????????????????????????????????????? ??   
     ??3???????????????????? ???????? ???????????????????????????????????? 
  
          ???????????????????????????????????? ??????????????
          ??????????????????.??????????????????????

            ??????????????        ??????: 135 381 99800
            
            ?? ??QQ??546843050    ?? ???? gdongxu2007 at yahoo.com.cn
              
       ??????????


From chenxh007 at gmail.com  Thu Sep 13 06:51:36 2007
From: chenxh007 at gmail.com (chenxh007)
Date: Wed, 12 Sep 2007 21:51:36 -0700
Subject: [R] Running R file from Command line.
In-Reply-To: <d09859290709122059t6cf3593q3373abc7a289a25d@mail.gmail.com>
References: <d09859290709122059t6cf3593q3373abc7a289a25d@mail.gmail.com>
Message-ID: <46E8C1D8.3080001@gmail.com>

For example, you can use:

R CMD BATCH mean.R mean.Rout

Xiaohui

Vaibhav Gathibandhe wrote:
> Hi all,
> 
> Is there any way through which i can run a R file from Command line.
> 
> For example
> 
>> r mean.R
> 
> Thanks and Regards,
> Vaibhav Gathibandhe
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From p.dalgaard at biostat.ku.dk  Thu Sep 13 08:05:37 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 13 Sep 2007 08:05:37 +0200
Subject: [R] reshape help
In-Reply-To: <E4178EE0463C7D40AF637C4DDAC8030ECD3AAC@UQEXMB2.soe.uq.edu.au>
References: <a17009720709121258p68b406aapd926cfd83b4078e8@mail.gmail.com>	<46E84E7F.4070006@optonline.net>
	<46E853CC.3080808@biostat.ku.dk>
	<E4178EE0463C7D40AF637C4DDAC8030ECD3AAC@UQEXMB2.soe.uq.edu.au>
Message-ID: <46E8D331.9070606@biostat.ku.dk>

Ross Darnell wrote:
>   
>   
> Yup. 2.6.0 will also allow this simplified variant:
>
>  > reshape(mydat, direction="long", varying=3:8, sep="")
>      tree serra time  bt   mm id
> 1.1     1     1    1 101 9101  1
> 2.1     2     1    1 102 9102  2
> 3.1     3     1    1 103 9103  3
>   

[Ross D] 

That's neat but how did the function recognize the difference between the 3:5 and 6:8 structure?

Ross Darnell

(Ross: Your emailer put your reply into my original signature, making it 
unquotable without cut&paste. Don't do that....)

It looks at the variable names (the current version can do that as well, 
but the case where the separator is not a dot is less easy to specify).

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From pifferi at sissa.it  Wed Sep 12 19:37:38 2007
From: pifferi at sissa.it (Simone Pifferi)
Date: Wed, 12 Sep 2007 19:37:38 +0200
Subject: [R] stastistical test on normalized data
Message-ID: <019701c7f563$9cea32b0$9cc87a93@biophysics.bp.sissa.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070912/c4adf103/attachment.pl 

From john.lande77 at gmail.com  Wed Sep 12 21:43:39 2007
From: john.lande77 at gmail.com (John Lande)
Date: Wed, 12 Sep 2007 21:43:39 +0200
Subject: [R] barplot border width
Message-ID: <c2ebc3880709121243i45139fbdge7c2e9cc16b4e110@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070912/b4d6b4a2/attachment.pl 

From justin_bem at yahoo.fr  Thu Sep 13 08:52:43 2007
From: justin_bem at yahoo.fr (justin bem)
Date: Thu, 13 Sep 2007 08:52:43 +0200 (CEST)
Subject: [R] =?gb2312?b?UmUgOiAgssbO8dDEyfmhow==?=
Message-ID: <705727.59801.qm@web23002.mail.ird.yahoo.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20070913/f6300bfe/attachment.pl 

From mfay at niaid.nih.gov  Wed Sep 12 21:26:09 2007
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 12 Sep 2007 15:26:09 -0400
Subject: [R] [R-pkgs] New package: hbim - Hill/Bliss Independence Model
	for	Multicomponent Vaccines
Message-ID: <31DDB7BE4BF41D4888D41709C476B657062E780D@NIHCESMLBX5.nih.gov>

Hi all,

I have just uploaded the hbim package. This package does calculations related to the Hill/Bliss independence model as applied to mulitcomponent vaccines. Specifically, the package caculates expected relative risk and proportion protected assuming normally distributed log10 transformed antibody dose for a several component vaccine. It uses Hill models for each component which are combined under Bliss independence.

A description of the motivation for the package is published in:

Saul A, Fay MP (2007). Human Immunity and the Design of Multi-Component, Single Target Vaccines. PLoS ONE 2(9): e850. doi:10.1371/jounal.pone.0000850 (Available at http://www.plosone.org/)

Please let me know if you have any comments about or corrections for the package. 
 
Thanks, 

Mike
******************************************************************
Michael P. Fay, PhD
Mathematical Statistician
National Institute of Allergy and Infectious Diseases
Tel: 301-451-5124               Fax:301-480-0912
(U.S. postal mail address)                           
6700B Rockledge Drive MSC 7609
Bethesda, MD 20892-7609
(Overnight mail address)
6700-A Rockledge Drive, Room 5133
Bethesda, MD 20817
**********************************************************************

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From paulandpen at optusnet.com.au  Thu Sep 13 09:17:22 2007
From: paulandpen at optusnet.com.au (paulandpen at optusnet.com.au)
Date: Thu, 13 Sep 2007 17:17:22 +1000
Subject: [R] k-means clustering
Message-ID: <200709130717.l8D7HMR7026738@mail12.syd.optusnet.com.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070913/2d050fe1/attachment.pl 

From Wayne.W.Jones at shell.com  Thu Sep 13 09:40:02 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Thu, 13 Sep 2007 08:40:02 +0100
Subject: [R] Multivariate, multilevel regression?
In-Reply-To: <728924.50404.qm@web35413.mail.mud.yahoo.com>
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B02D@wyt-s-019.europe.shell.com>

Hi John, 

It sounds like what you need is a mixed effects model. This will allow you to model effects which apply to the whole population (fixed effects) and those which are specific to an individual (random effects).The theory and practice of mixed effects models is too large to discuss fully in an email. But I can point you in the right direction. 

First of all I suggest you read "Mixed-Effects models in S and S-PLUS" by Pinheiro and Bates. This is an excellent text on the subject with loads of worked examples. Also John Fox has produced a very nice introduction to mixed effects models, again with worked examples in R: see http://cran.r-project.org/doc/contrib/Fox-Companion/appendix-mixed-models.pdf

The library you require in R is called library(nlme). 
look up the Pixel example (?Pixel) it shows you how to model non-linear effects using a quadratic term. 
Download the nlme library from CRAN and paste the following in to R: 

library(nlme)
fm1 <- lme(pixel ~ day + I(day^2), data = Pixel,
           random = list(Dog = ~ day, Side = ~ 1))
summary(fm1)
plot(augPred(fm1))



I hope this helps. 

Regards

Wayne






-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of John McHenry
Sent: 13 September 2007 03:09
To: r-help at r-project.org
Subject: [R] Multivariate, multilevel regression?


Dear WizaRds,

This is mostly a statistics question, but I'm figuring that R is the right solution (even before I start!)

I have some bio data of heart rate versus time (rats taken from resting to maximal heart rate). I want to regress heart rate on time. The data have been normalized such that resting heart rate is zero at time=0, so that all curves intersect at the origin (and at the origin only). The regression function is monotonically increasing, but little is known about it.

The data are also strictly ordinal: I have a factor such that lower-order data *must* be on a curve that is offset beneath a higher-order curve. Don't ask where the factors come from...but *given* these factors the assumption, or rather the *constraint*, is that lower orders are better (lower-order rats are fitter rats with better cardiovascular response). Most important is that these curves do not intersect because of these factors (a fitter rat can not have a worse heart-rate 
response than a less fit rat!).

Here's a schematic to show you what I mean. It's very rough, but it gets the point across:

seq(0, 1, len=100)
f<- 1/seq(.3,1,len=6)
windows(); 
plot(t, sqrt(3*t), type='n', xlab='time', ylab='heart rate'); 
grid()
for (i in seq(along=f)) 
    lines(t, sqrt(f[i]*t), col=ceiling(2*i))


Now I'm wondering where I should start and I'm think that this is really not much different from having a y_i ~ x_i | factor_i ... the i^th response curve just like a dummy variable male/female linear regression. But in some way the factors are related (there's a dose behind it, if ya see what I mean), so they are not independent...they're all part of a "system" (some studies have more "juice" overall, so the whole "system" is varying from one group of rats to the next).
This means that in some "systems" the curves will be closer or some curves within the system will be closer together.

Here is my question for you guys: what is the best way to model this kind of problem, especially given that each "i^th curve" could have as few as 3 data points? If I can only vaguely assume the type of the regression function (monotonic, rapidly increasing from the origin kind of like sqrt(t), as above)
should it be a parametric or nonparametric regression? What about those errors? Gee! It's hard to assume anything (there're so few of 'em and they're probably heteroskedastic!

Where do I begin? I'd gladly accept all references, pointers, and such like.

Best, and thanks for R and R-Help, all you Core guys!!!

Jack.

       
---------------------------------

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Bernhard_Pfaff at fra.invesco.com  Thu Sep 13 09:42:13 2007
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Thu, 13 Sep 2007 08:42:13 +0100
Subject: [R] vars package, impulse response functions ??
In-Reply-To: <1c6126db0709120811k5d1b3b6fj4d24b21393577a33@mail.gmail.com>
References: <1c6126db0709120811k5d1b3b6fj4d24b21393577a33@mail.gmail.com>
Message-ID: <B89F0CE41D45644A97CCC93DF548C1C30AF6A67F@GBHENXMB02.corp.amvescap.net>

Hello Spencer,

impulse response analysis is wrong tool for your investigation. What you
are after is the final form of your model, i.e., the endogenous
variables are only dependent on your exogenous variables including
deterministic regressors: y_t = A(L)^-1 B(L) x_t. The key word is then
multiplicator analysis as used in the context of structural multiple
equation models. Depending on your objective you can then retrieve from
the final form of your model impact-, intermediate- and long-run
mutlipliers. This is outlined for instance in the monographs:

@book{BOOK,
author={George G. Judge and William E. Griffiths and R. Carter Hill and
Helmut L{\"u}tkepohl and Tsoung-Chao Lee},
title={The Theory and Practice of Econometrics (Wiley Series in
Probability and Statistics)},
year={1985},
price={$131.95},
publisher={Wiley},
isbn={047189530X}
} 

@book{BOOK,
author={George G. Judge and R. Carter Hill and William E. Griffiths and
Helmut L{\"u}tkepohl and Tsoung-Chao Lee},
title={Introduction to the Theory and Practice of Econometrics, 2nd
Edition},
year={1988},
publisher={Wiley},
isbn={0471624144}
} 

@book{BOOK,
author={Helmut L{\"u}tkepohl},
title={New Introduction to Multiple Time Series Analysis},
year={2007},
price={$49.68},
publisher={Springer},
isbn={3540262393}
} 

Now, to your problem at hand. You can retrieve the relevant coefficients
by using A() and B() and then you have to set up the final form by hand.
You can then compute the multipliers you are interest in. Please note,
that the VAR is estimated by OLS. You might want to consider estimating
the VAR by FGLS if you have restrictions in your VAR.

Best,
Bernhard

ps: The more you are "approaching" structural multiple equation model,
you can also use the CRAN-package systemfit 


>I am fitting a reduced form VAR model using VAR in the vars 
>library. I have
>several endogenous variables, and two exogenous variables. I 
>would like to
>explore the effects of a shock to one of the exogenous 
>variables on one of
>the endogenous variables. Using irf in the vars library only 
>calculates the
>irf for the endogenous variables, this is obviously by design, 
>is there some
>theoretical restriction on why it is not possible to look at 
>the irf's from
>exogenous shocks?  Is there anyway to look at the effects of exogenous
>shocks in R? Do I need to consider some sort of structural model?
>
>the following code sample illustrates what I am trying to do  and the
>problems I am having (I am not an econometrician, but I know 
>that e would be
>better left as an endo variable, I just needed some common 
>data to show what
>I am trying to do)
>
>
>data(Canada)
>attach(Canada)
>v.can<-VAR(Canada[,2:4],exogen=e, p = 2, type = "both")
>
>irf(v.can,impulse= "e", response="prod")
>
>thanks again,
>
>Spencer
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide 
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
*****************************************************************
Confidentiality Note: The information contained in this mess...{{dropped}}


From ajung at gfz-potsdam.de  Thu Sep 13 09:52:44 2007
From: ajung at gfz-potsdam.de (Andre Jung)
Date: Thu, 13 Sep 2007 09:52:44 +0200
Subject: [R] plot contour map for irregular data points
In-Reply-To: <s6e80323.073@tedmail2.lgc.co.uk>
References: <s6e80323.073@tedmail2.lgc.co.uk>
Message-ID: <46E8EC4C.7020206@gfz-potsdam.de>

Yes, contourplot() takes irregular spaced values, but you need a regular 
grid to project the data on to.

grid <- expand.grid(x=x,y=y);
contourplot(z~x*y,grid,cuts=50);

This gives me a plot with little coloured areas around my datapoints only.

A better way for me was to

library(akima);
data.interp <- interp(x,y,z);
image(data.interp); #or
contour(data.interp);

where interp() leaves you with multiple options of interpolation 
(linear, spline, ...).

For further reading I recommend:
https://stat.ethz.ch/pipermail/r-help/2005-October/080853.html
https://stat.ethz.ch/pipermail/r-help/2003-December/043897.html
https://stat.ethz.ch/pipermail/r-sig-geo/2005-October/000609.html

cheers,
andre


S Ellison wrote:
 > Doesn't the lattice package's contourplot take arbitrary x and y?
 >
 > library(lattice)
 > ?contourplot


From kate at few.vu.nl  Thu Sep 13 10:13:46 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Thu, 13 Sep 2007 10:13:46 +0200 (CEST)
Subject: [R] Someone Using Java/R Interface--- JRI ?
In-Reply-To: <d09859290709121950l2de67ca8mfe9d843e2e7a065d@mail.gmail.com>
References: <d09859290709121950l2de67ca8mfe9d843e2e7a065d@mail.gmail.com>
Message-ID: <Pine.GSO.4.56.0709130959440.8419@laurel.few.vu.nl>

I think that working with the JRI is a good way to call R from java.  You
can send arbitrary commands from java to R, so you can load and use add-on
packages.

On Wed, 12 Sep 2007, Vaibhav Gathibandhe wrote:

> Hi all,
>
> I am writing R code and I want to interface with JAVA i.e. I want to call R
> from JAVA. That's why i have installed JRI on my machine.
>
> There is also documentation available in "Javadoc".
>
> But as i am  very new to JAVA and well as R, I don't understand much of it.
>
> If someone is using this package i.e. JRI, please let me know whether i am
> going in right direction or not.
>
> As i am using regressions, Boot library etc. in my R codes. Is it possible
> to use all these if i use JRI package?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.uni-dortmund.de  Thu Sep 13 10:47:37 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 13 Sep 2007 10:47:37 +0200
Subject: [R] convergence error with heidel.diag
In-Reply-To: <46E85929.4060002@reed.edu>
References: <46E85929.4060002@reed.edu>
Message-ID: <46E8F929.4080807@statistik.uni-dortmund.de>

I fear most of us get:

R> heidel.diag(posterior, eps=0.1, pvalue=0.05)
Error: could not find function "heidel.diag"

Uwe Ligges



Anthony Pezzola wrote:
> I received the following error after running:
> 
> ####
>  > heidel.diag(posterior, eps=0.1, pvalue=0.05)
> Error in glm.fit(x = X, y = Y, weights = weights, start = start, 
> etastart = etastart,  :
> 	inner loop 1; cannot correct step size
> In addition: There were 21 warnings (use warnings() to see them)
>  > test.diag <- heidel.diag(posterior, eps=0.1, pvalue=0.05)
> Error in glm.fit(x = X, y = Y, weights = weights, start = start, 
> etastart = etastart,  :
> 	inner loop 1; cannot correct step size
> In addition: There were 21 warnings (use warnings() to see them)
>  > warnings()
> Warning messages:
> 1: algorithm did not converge in: glm.fit(x = X, y = Y, weights = 
> weights, start = start, etastart = etastart,   ...
> #####
> 
> posterior was generated using:
> 
> #####
>  > posterior <-MCMCirt1d(mydata, theta.fixed =1, burnin=35000, 
> mcmc=75000, thin=300)
> #####
> 
> Is a chain of 250 simply too short for heidel.diag to work with?  If so 
> how long should it be?
> 
> Thanks in advance,
> Anthony
>


From wl2776 at gmail.com  Thu Sep 13 10:50:50 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Thu, 13 Sep 2007 01:50:50 -0700 (PDT)
Subject: [R] Running R file from Command line.
In-Reply-To: <d09859290709122059t6cf3593q3373abc7a289a25d@mail.gmail.com>
References: <d09859290709122059t6cf3593q3373abc7a289a25d@mail.gmail.com>
Message-ID: <12651109.post@talk.nabble.com>



Vaibhav Gathibandhe wrote:
> 
> Is there any way through which i can run a R file from Command line.
> 
Yes, there are several.

R < mean.R
R CMD BATCH mean.R
Rscript mean.R



Vaibhav Gathibandhe wrote:
> 
> For example
>   > r mean.R
> 
What does ">" above mean?
Is it OS command prompt (looks like a part of Windows' cmd.exe)?
If you are trying to run the file from inside the R shell, that's wrong way.
You should type 
> source("mean.R")
instead
-- 
View this message in context: http://www.nabble.com/Running-R-file-from-Command-line.-tf4433456.html#a12651109
Sent from the R help mailing list archive at Nabble.com.


From ligges at statistik.uni-dortmund.de  Thu Sep 13 10:54:00 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 13 Sep 2007 10:54:00 +0200
Subject: [R] Problem using xtable on an array
In-Reply-To: <200709131410.54151.dunn@usq.edu.au>
References: <200709131410.54151.dunn@usq.edu.au>
Message-ID: <46E8FAA8.6080903@statistik.uni-dortmund.de>



Peter Dunn wrote:
> Hi all
> 
> I know about producing a minimal example to show my problem.  But I'm
> having trouble producing a minimal example that displays this
> behaviour, so please bear with me to begin with.
> 
> 
> Observe:  I create an array called model.mat.  Some details on this:
> 
>> str(model.mat)
>  num [1:18, 1:4] -0.170 -0.304 -2.617  2.025 -1.610 ...
>  - attr(*, "dimnames")=List of 2
>   ..$ : chr [1:18] "Amount: CP for VF" "Amount: CP for F" "Amount: CP for 
> M" "Amount: RD for VF" ...
>   ..$ : chr [1:4] "beta_0" "P-value" "beta_1" "P-value"
> 
> 
> It contains the following:
> 
>> model.mat[1:2,]
>                       beta_0   P-value    beta_1      P-value
> Amount: CP for VF -0.1702877 0.7716153 0.5148616 2.020602e-03
> Amount: CP for F  -0.3042522 0.1966133 0.8795982 6.058299e-12
> 
> 
> 
> That's fine.  Now to produce a LaTeX table using xtable,
> I get:
> 
>> xtable(model.mat[1:2,])
> <snip>
>   Amount: CP for VF & $-$0.17 & 0.77 & 0.51 & 0.77 \\
>   Amount: CP for F & $-$0.30 & 0.20 & 0.88 & 0.20 \\
> <snip>
> 
> That is, the final column does *not* correspond to the final
> column of model.mat itself.  It is actually column 2 repeated.
> 
> What's going on?  If I try repeating on a minimal type example,
> xtable works as expected:
> 
> 
>> fred <- array( seq(1,18*4), dim=c(18,4))
>> fred[1:2, ]
>      [,1] [,2] [,3] [,4]
> [1,]    1   19   37   55
> [2,]    2   20   38   56
>> xtable(fred[1:2, ])
> % latex table generated in R 2.5.0 by xtable 1.4-6 package
> % Thu Sep 13 14:09:46 2007
> \begin{table}[ht]
> \begin{center}
> \begin{tabular}{rrrrr}
>   \hline
>  & 1 & 2 & 3 & 4 \\
>   \hline
> 1 &   1 &  19 &  37 &  55 \\
>   2 &   2 &  20 &  38 &  56 \\
>    \hline
> \end{tabular}
> \end{center}
> \end{table}
> 
> 
> So it is not a generic problem. But what could it be?  I can't decide
> where to look, so find a solution or produce a minimal example to display
> this behaviour.  I actually use this construct with xtable a lot, so
> it disturbs me to find this error... which is probably is something
> I am doing.
> 
> 
> 
> The problem exists for a smaller subsets of this array also; let's take
> columns 2, 3 and 4 only:
> 
>> model.mat[1:2,2:4]
>                     P-value    beta_1      P-value
> Amount: CP for VF 0.7716153 0.5148616 2.020602e-03
> Amount: CP for F  0.1966133 0.8795982 6.058299e-12
>> xtable(model.mat[1:2,2:4])
> % latex table generated in R 2.5.0 by xtable 1.4-6 package
> % Thu Sep 13 14:04:40 2007
> \begin{table}[ht]
> \begin{center}
> \begin{tabular}{rrrr}
>   \hline
>  & P-value & beta\_1 & P-value \\
>   \hline
> Amount: CP for VF & 0.77 & 0.51 & 0.77 \\
>   Amount: CP for F & 0.20 & 0.88 & 0.20 \\
>    \hline
> \end{tabular}
> \end{center}
> \end{table}
> 
> 
> Is it a problem with my particular array  model.mat  or something
> I am doing wrong/silly?  I don't know where to start.
> 
> Thanks all, as always.
> 
> P.
> 
>> sessionInfo()
> R version 2.5.0 (2007-04-23)
> i486-pc-linux-gnu
> 
> locale:
> LC_CTYPE=en_AU.UTF-8;LC_NUMERIC=C;LC_TIME=en_AU.UTF-8;LC_COLLATE=en_AU.UTF-8;LC_MONETARY=en_AU.UTF-8;LC_MESSAGES=en_AU.UTF-8;LC_PAPER=en_AU.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_AU.UTF-8;LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> [7] "base"
> 
> other attached packages:
>     car  xtable statmod
> "1.2-1" "1.4-6" "1.3.0"



1. a) Please start by upgrading R to at least teh current release 
R-2.5.1 or even better the current R-alpha version where you could help 
testing.
1. b) Please upgrade you version of xtable. Current release is 1.5-1.

2. If the problem is still there, please send the model.mat[1:2,2:4] 
object (by e.g. using save()) to the package maintainer of xtable and 
report the problem. I am CCing now already.

Best,
Uwe Ligges



> 
>


From ligges at statistik.uni-dortmund.de  Thu Sep 13 10:55:36 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 13 Sep 2007 10:55:36 +0200
Subject: [R] barplot border width
In-Reply-To: <c2ebc3880709121243i45139fbdge7c2e9cc16b4e110@mail.gmail.com>
References: <c2ebc3880709121243i45139fbdge7c2e9cc16b4e110@mail.gmail.com>
Message-ID: <46E8FB08.1040204@statistik.uni-dortmund.de>

Here we go:

  barplot(1)

  par(lwd=2)
  barplot(1)


Uwe Ligges


John Lande wrote:
> I need to increase the width of the border in a barplot, i checked both
> barplot, and barplot2, but cant find how to do it. how can I do?
> 
> 
> thank you
> 
> 
> john
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.uni-dortmund.de  Thu Sep 13 11:03:08 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 13 Sep 2007 11:03:08 +0200
Subject: [R] Flaw in the installation procedure ?
In-Reply-To: <36d691950709121411r69565d54uaf3a73cf0fc4b272@mail.gmail.com>
References: <36d691950709121411r69565d54uaf3a73cf0fc4b272@mail.gmail.com>
Message-ID: <46E8FCCC.1050506@statistik.uni-dortmund.de>

Well, that package depends on packages rggobi, ggplot2, e1071, and 
cluster. And rggobi depends on package RGtk2 which requires GTK 2 to be 
installed on your system (and added to your PATH).

Uwe Ligges






Maura E Monville wrote:
> R printed out the following error messages during the installation of the
> package "clusterfly":
> 
> 
>> *install.packages("clusterfly", repos = getOption("repos"),dependencies
> =TRUE)
> *--- Please select a CRAN mirror for use in this session ---
> trying URL '
> http://umfragen.sowi.uni-mainz.de/CRAN/bin/windows/contrib/2.5/clusterfly_0.2.2.zip
> '
> Content type 'application/zip' length 141793 bytes
> opened URL
> downloaded 138Kb
> 
> package 'clusterfly' successfully unpacked and MD5 sums checked
> 
> The downloaded packages are in
>         C:\Documents and Settings\mmonville\Local
> Settings\Temp\Rtmpj8JFsb\downloaded_packages
> updating HTML package descriptions
>> help(clusterfly)
> No documentation for 'clusterfly' in specified packages and libraries:
> you could try 'help.search("clusterfly")'
>> library(clusterfly)
> Loading required package: rggobi
> Loading required package: RGtk2
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>         unable to load shared library
> 'C:/DOCUME~1/MMONVI~1/MYDOCU~1/R/R-25~1.1/library/rggobi/libs/rggobi.dll':
>   LoadLibrary failure:  The specified module could not be found.
> 
> 
> Error in fun(...) : Could not load the rggobi library - please ensure GGobi
> is on the library path
> Error : .onLoad failed in 'loadNamespace' for 'rggobi'
> Error: package 'rggobi' could not be loaded
> Eventually an error-message window popped up reading:
> "RGui: RGui.exex - Uable To Locate Component
> This application failed to start because libggobi-0.dll was not found.
> Re-installig the aplication may fix this problem"
> 
> Any idea what is going on ?
> Thank you in advance.
> 
> Maura
> 
>


From f.jamitzky at gmail.com  Thu Sep 13 11:24:13 2007
From: f.jamitzky at gmail.com (f.jamitzky)
Date: Thu, 13 Sep 2007 02:24:13 -0700 (PDT)
Subject: [R] Someone Using Java/R Interface--- JRI ?
In-Reply-To: <d09859290709121950l2de67ca8mfe9d843e2e7a065d@mail.gmail.com>
References: <d09859290709121950l2de67ca8mfe9d843e2e7a065d@mail.gmail.com>
Message-ID: <12651536.post@talk.nabble.com>


I made the observation that it is easier to call java from R by using rJava.
This is very much analogous to calling C or fortran from R, but your mileage
can vary.



Vaibhav Gathibandhe wrote:
> 
> Hi all,
> 
> I am writing R code and I want to interface with JAVA i.e. I want to call
> R
> from JAVA. That's why i have installed JRI on my machine.
> 
> There is also documentation available in "Javadoc".
> 
> But as i am  very new to JAVA and well as R, I don't understand much of
> it.
> 
> If someone is using this package i.e. JRI, please let me know whether i am
> going in right direction or not.
> 
> As i am using regressions, Boot library etc. in my R codes. Is it possible
> to use all these if i use JRI package?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Someone-Using-Java-R-Interface----JRI---tf4433263.html#a12651536
Sent from the R help mailing list archive at Nabble.com.


From jeremy.zack at gmx.de  Thu Sep 13 11:26:02 2007
From: jeremy.zack at gmx.de (jerzack)
Date: Thu, 13 Sep 2007 02:26:02 -0700 (PDT)
Subject: [R] pick time intervalls
Message-ID: <12651552.post@talk.nabble.com>


Hello,
as an R beginner I have a question concerning the following data set:

nr     date       time    V1  V2  V3  V4  V5  V6
...
2828 26/08/05 20:00  60  38  55  58  53  56
2829 26/08/05 21:00  58  34  54  49  45  53
2830 26/08/05 22:00  56  35  52  51  46  47
2831 26/08/05 23:00  56  35  50  45  46  38
2832 27/08/05 00:00  61  34  49  42  47  32
2833 27/08/05 01:00  62  38  52  49  48  36
2834 27/08/05 02:00  64  39  51  49  50  42
2835 27/08/05 03:00  63  40  49  46  49  33
2836 27/08/05 04:00  58  37  47  48  51  20
...

How can I access values at a certain time intervall every day.
For example I would like to calculate the mean of the V1 values for the
times 02:00 - 04:00 every day.
Thank you very much for your help!
jeremy
-- 
View this message in context: http://www.nabble.com/pick-time-intervalls-tf4434604.html#a12651552
Sent from the R help mailing list archive at Nabble.com.


From Wayne.W.Jones at shell.com  Thu Sep 13 11:42:53 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Thu, 13 Sep 2007 10:42:53 +0100
Subject: [R] pick time intervalls
In-Reply-To: <12651552.post@talk.nabble.com>
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B02F@wyt-s-019.europe.shell.com>


?tapply

temp.data<-data[as.character(data$time %in% c("02:00","03:00","04:00"),] 
# one quick and dirty method is to create a subset the data , not sure what format your time data is so converted to character strings.

then something like: 

tapply(temp.data$V1, factor(temp.data$time), mean) 

Wayne


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of jerzack
Sent: 13 September 2007 10:26
To: r-help at stat.math.ethz.ch
Subject: [R] pick time intervalls



Hello,
as an R beginner I have a question concerning the following data set:

nr     date       time    V1  V2  V3  V4  V5  V6
...
2828 26/08/05 20:00  60  38  55  58  53  56
2829 26/08/05 21:00  58  34  54  49  45  53
2830 26/08/05 22:00  56  35  52  51  46  47
2831 26/08/05 23:00  56  35  50  45  46  38
2832 27/08/05 00:00  61  34  49  42  47  32
2833 27/08/05 01:00  62  38  52  49  48  36
2834 27/08/05 02:00  64  39  51  49  50  42
2835 27/08/05 03:00  63  40  49  46  49  33
2836 27/08/05 04:00  58  37  47  48  51  20
...

How can I access values at a certain time intervall every day.
For example I would like to calculate the mean of the V1 values for the
times 02:00 - 04:00 every day.
Thank you very much for your help!
jeremy
-- 
View this message in context: http://www.nabble.com/pick-time-intervalls-tf4434604.html#a12651552
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From T.Lok at rug.nl  Thu Sep 13 11:47:50 2007
From: T.Lok at rug.nl (T.Lok)
Date: Thu, 13 Sep 2007 11:47:50 +0200
Subject: [R] difference between unique() and !duplicated()
Message-ID: <web-53495427@mail3.rug.nl>

Yesterday I spend the whole day struggling on how to get 
the maximum value of "y" for every unique value of "x" 
from the dataframe "test". In the R Book (Crawley, 2007) 
an example of this can be found on page 121. I tried to do 
it this way, but I failed.

In the end, I figured out how to get it working (first 
order, and afterwards use !duplicated()). My question is: 
why does it not work with the unique() function on p. 121 
(
i.e. test[rev(order(x)),][unique(y),]) ?

As a simple example, I used to following syntax:

> x <- c("A","A","B","B","C","C","D")
> y <- c(1,2,1,1,2,3,1)
> z <- c("yes","yes","no","yes","no","no","no")
> test <- data.frame(x,y,z)
> test

   x y   z
1 A 1 yes
2 A 2 yes
3 B 1  no
4 B 1 yes
5 C 2  no
6 C 3  no
7 D 1  no

> test[rev(order(test$y, test$z)),][unique(test$x),]

   x y   z
6 C 3  no
2 A 2 yes
5 C 2  no
4 B 1 yes

# this clearly does not give a unique value for x, since 
there are 2 C's and no D!

> test[rev(order(test$y, test$z)),][!duplicated(test$x),]

   x y   z
6 C 3  no
5 C 2  no
1 A 1 yes
3 B 1  no

# this also doesn't work
# then I thought, maybe first use the order() function, 
then unique()

> test[rev(order(test$y, test$z)),]

   x y   z
6 C 3  no
2 A 2 yes
5 C 2  no
4 B 1 yes
1 A 1 yes
7 D 1  no
3 B 1  no

> test1 <- test[rev(order(test$y, test$z)),]
> test1[unique(test1$x),]

   x y   z
5 C 2  no
6 C 3  no
2 A 2 yes
4 B 1 yes

# still no unique values for x

> test1[!duplicated(test1$x),]

   x y   z
6 C 3  no
2 A 2 yes
4 B 1 yes
7 D 1  no

# finally I get unique values for x, for the maximum value 
of y (and z). But why does this not work when giving the 
order() and !duplicated() command simultaneously?
And why does only !duplicated() work, and not unique()?


From jim at bitwrit.com.au  Thu Sep 13 12:07:06 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 13 Sep 2007 20:07:06 +1000
Subject: [R] Tick intervals
In-Reply-To: <12639110.post@talk.nabble.com>
References: <12639110.post@talk.nabble.com>
Message-ID: <46E90BCA.7040406@bitwrit.com.au>

livia wrote:
> Hi, I would like to plot a histogram with the following codes, and I would
> like to make the tick intervals smaller. I tried to add "lab=c(1,1,12)", but
> nothing changes.
> 
> 
> par(mfrow=c(1,1),font=1, cex=0.8)
> hist (data1, seq(-0.01,0.3,0.01),freq = FALSE,
> main="Figure1.",xlab="return",lab=c(1,1,12))
> lines(density(data1), col="blue")
> 
Hi Livia,
 From the look of your example, I suspect you may want more labels for 
the 31 bars of your histogram. The following will give you many more 
labels that don't overlap:

library(plotrix)
hist (data1, seq(-0.01,0.3,0.01),freq = FALSE,
main="Figure1.",xlab="return",lab=c(1,1,12),xaxt="n")
staxlab(1,at=seq(-0.01,0.3,by=0.02),labels=seq(-0.01,0.3,by=0.02))

Jim


From shukai at seas.upenn.edu  Thu Sep 13 12:34:29 2007
From: shukai at seas.upenn.edu (kevinchang)
Date: Thu, 13 Sep 2007 03:34:29 -0700 (PDT)
Subject: [R] rearrange problem
Message-ID: <12652394.post@talk.nabble.com>


Hi All,

I am trying to rearrange alphabetically each element in a character vector.
ex: say the first element in the vector is "cba", and my goal is to turn it
into "abc". The suggested function to use is sort(). But it turns out that
sort doesn't work at the level of element. So I am wondering that if there
is an alternative function for this purpose. Please help me out . Thanks. 
-- 
View this message in context: http://www.nabble.com/rearrange-problem-tf4434906.html#a12652394
Sent from the R help mailing list archive at Nabble.com.


From jholtman at gmail.com  Thu Sep 13 12:42:33 2007
From: jholtman at gmail.com (jim holtman)
Date: Thu, 13 Sep 2007 06:42:33 -0400
Subject: [R] difference between unique() and !duplicated()
In-Reply-To: <web-53495427@mail3.rug.nl>
References: <web-53495427@mail3.rug.nl>
Message-ID: <644e1f320709130342n423b7b71x7ccad9e6671d3bc8@mail.gmail.com>

Try this:

> a <- read.table(textConnection("x y   z
+ 1 A 1 yes
+ 2 A 2 yes
+ 3 B 1  no
+ 4 B 1 yes
+ 5 C 2  no
+ 6 C 3  no
+ 7 D 1  no"), header=TRUE)
> do.call('rbind', by(a, a$x, function(.sub){
+     .sub[which.max(.sub$y),]
+ }))
  x y   z
A A 2 yes
B B 1  no
C C 3  no
D D 1  no


On 9/13/07, T.Lok <T.Lok at rug.nl> wrote:
> Yesterday I spend the whole day struggling on how to get
> the maximum value of "y" for every unique value of "x"
> from the dataframe "test". In the R Book (Crawley, 2007)
> an example of this can be found on page 121. I tried to do
> it this way, but I failed.
>
> In the end, I figured out how to get it working (first
> order, and afterwards use !duplicated()). My question is:
> why does it not work with the unique() function on p. 121
> (
> i.e. test[rev(order(x)),][unique(y),]) ?
>
> As a simple example, I used to following syntax:
>
> > x <- c("A","A","B","B","C","C","D")
> > y <- c(1,2,1,1,2,3,1)
> > z <- c("yes","yes","no","yes","no","no","no")
> > test <- data.frame(x,y,z)
> > test
>
>   x y   z
> 1 A 1 yes
> 2 A 2 yes
> 3 B 1  no
> 4 B 1 yes
> 5 C 2  no
> 6 C 3  no
> 7 D 1  no
>
> > test[rev(order(test$y, test$z)),][unique(test$x),]
>
>   x y   z
> 6 C 3  no
> 2 A 2 yes
> 5 C 2  no
> 4 B 1 yes
>
> # this clearly does not give a unique value for x, since
> there are 2 C's and no D!
>
> > test[rev(order(test$y, test$z)),][!duplicated(test$x),]
>
>   x y   z
> 6 C 3  no
> 5 C 2  no
> 1 A 1 yes
> 3 B 1  no
>
> # this also doesn't work
> # then I thought, maybe first use the order() function,
> then unique()
>
> > test[rev(order(test$y, test$z)),]
>
>   x y   z
> 6 C 3  no
> 2 A 2 yes
> 5 C 2  no
> 4 B 1 yes
> 1 A 1 yes
> 7 D 1  no
> 3 B 1  no
>
> > test1 <- test[rev(order(test$y, test$z)),]
> > test1[unique(test1$x),]
>
>   x y   z
> 5 C 2  no
> 6 C 3  no
> 2 A 2 yes
> 4 B 1 yes
>
> # still no unique values for x
>
> > test1[!duplicated(test1$x),]
>
>   x y   z
> 6 C 3  no
> 2 A 2 yes
> 4 B 1 yes
> 7 D 1  no
>
> # finally I get unique values for x, for the maximum value
> of y (and z). But why does this not work when giving the
> order() and !duplicated() command simultaneously?
> And why does only !duplicated() work, and not unique()?
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From jholtman at gmail.com  Thu Sep 13 12:50:42 2007
From: jholtman at gmail.com (jim holtman)
Date: Thu, 13 Sep 2007 06:50:42 -0400
Subject: [R] rearrange problem
In-Reply-To: <12652394.post@talk.nabble.com>
References: <12652394.post@talk.nabble.com>
Message-ID: <644e1f320709130350k7aade7d8pb1de2e1000e5b0d8@mail.gmail.com>

Is this what you want:

> n <- 10
> m <- 4
> x <- replicate(n, paste(letters[sample(1:26,m)], collapse=''))
> x
 [1] "zmld" "tlme" "fonb" "aqwn" "onxl" "rpfx" "sler" "cvom" "ilme" "nbge"
> x.sort <- sapply(x, function(.str){
+     paste(sort(strsplit(.str, '')[[1]]), collapse='')
+ })
> x.sort
  zmld   tlme   fonb   aqwn   onxl   rpfx   sler   cvom   ilme   nbge
"dlmz" "elmt" "bfno" "anqw" "lnox" "fprx" "elrs" "cmov" "eilm" "begn"
>


On 9/13/07, kevinchang <shukai at seas.upenn.edu> wrote:
>
> Hi All,
>
> I am trying to rearrange alphabetically each element in a character vector.
> ex: say the first element in the vector is "cba", and my goal is to turn it
> into "abc". The suggested function to use is sort(). But it turns out that
> sort doesn't work at the level of element. So I am wondering that if there
> is an alternative function for this purpose. Please help me out . Thanks.
> --
> View this message in context: http://www.nabble.com/rearrange-problem-tf4434906.html#a12652394
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From gallon.li at gmail.com  Thu Sep 13 12:52:17 2007
From: gallon.li at gmail.com (gallon li)
Date: Thu, 13 Sep 2007 18:52:17 +0800
Subject: [R] how to plot shaded area under a curve?
Message-ID: <54f7e7c30709130352j17111f15vfc5eec9be0f6e175@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070913/c4872466/attachment.pl 

From Wayne.W.Jones at shell.com  Thu Sep 13 12:56:22 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Thu, 13 Sep 2007 11:56:22 +0100
Subject: [R] how to plot shaded area under a curve?
In-Reply-To: <54f7e7c30709130352j17111f15vfc5eec9be0f6e175@mail.gmail.com>
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B034@wyt-s-019.europe.shell.com>


?polygon


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of gallon li
Sent: 13 September 2007 11:52
To: r-help
Subject: [R] how to plot shaded area under a curve?


say, I am plotting

x=seq(0,5,len=100)
y=-(x-5)^2

plot(x,y)

how can I put some color or verticle lines below the plotted curve?

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dray at biomserv.univ-lyon1.fr  Thu Sep 13 12:58:10 2007
From: dray at biomserv.univ-lyon1.fr (=?ISO-8859-1?Q?St=E9phane_Dray?=)
Date: Thu, 13 Sep 2007 12:58:10 +0200
Subject: [R] ade4 on the web: new graph gallery
Message-ID: <46E917C2.8090207@biomserv.univ-lyon1.fr>

Dear All,

there are some news on the ade4 (Analysis of Environmental Data : 
Exploratory and Euclidean method) website:

- Information on the updates of the package are available at 
http://pbil.univ-lyon1.fr/ADE-4/changelog.php. This page is created 
automatically using the cvs repository.
- The online help of the package including examples and figures is 
available at http://pbil.univ-lyon1.fr/ADE-4/ade4-html/00Index.php
- A graph gallery constructed using the example section of the help 
pages (with links to the code used to construct the graphics) : 
http://pbil.univ-lyon1.fr/ADE-4/gallery.php

Sincerely,

-- 
St?phane DRAY (dray at biomserv.univ-lyon1.fr )
Laboratoire BBE-CNRS-UMR-5558, Univ. C. Bernard - Lyon I
43, Bd du 11 Novembre 1918, 69622 Villeurbanne Cedex, France
Tel: 33 4 72 43 27 57       Fax: 33 4 72 43 13 88
http://biomserv.univ-lyon1.fr/~dray/


From jholtman at gmail.com  Thu Sep 13 12:59:00 2007
From: jholtman at gmail.com (jim holtman)
Date: Thu, 13 Sep 2007 06:59:00 -0400
Subject: [R] how to plot shaded area under a curve?
In-Reply-To: <54f7e7c30709130352j17111f15vfc5eec9be0f6e175@mail.gmail.com>
References: <54f7e7c30709130352j17111f15vfc5eec9be0f6e175@mail.gmail.com>
Message-ID: <644e1f320709130359v706088b5x29b8cb5cae2ca982@mail.gmail.com>

try this:

> x=seq(0,5,len=100)
> y=-(x-5)^2
>
> plot(x,y)
> polygon(c(x,x[length(x)]), c(y, y[1]), col='red')


On 9/13/07, gallon li <gallon.li at gmail.com> wrote:
> say, I am plotting
>
> x=seq(0,5,len=100)
> y=-(x-5)^2
>
> plot(x,y)
>
> how can I put some color or verticle lines below the plotted curve?
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From info at aghmed.fsnet.co.uk  Thu Sep 13 13:00:37 2007
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 13 Sep 2007 12:00:37 +0100
Subject: [R] difference between unique() and !duplicated()
In-Reply-To: <web-53495427@mail3.rug.nl>
References: <web-53495427@mail3.rug.nl>
Message-ID: <Zen-1IVmR9-0002an-Is@rutherford.zen.co.uk>

At 10:47 13/09/2007, T.Lok wrote:
>Yesterday I spend the whole day struggling on how to get the maximum 
>value of "y" for every unique value of "x" from the dataframe 
>"test". In the R Book (Crawley, 2007) an example of this can be 
>found on page 121. I tried to do it this way, but I failed.
>
>In the end, I figured out how to get it working (first order, and 
>afterwards use !duplicated()). My question is: why does it not work 
>with the unique() function on p. 121 (
>i.e. test[rev(order(x)),][unique(y),]) ?

This is not a direct answer to your question but is not
tapply(y, x, max)
a simpler way to do what you want?




Michael Dewey
http://www.aghmed.fsnet.co.uk


From murdoch at stats.uwo.ca  Thu Sep 13 13:11:05 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 13 Sep 2007 07:11:05 -0400
Subject: [R] difference between unique() and !duplicated()
In-Reply-To: <web-53495427@mail3.rug.nl>
References: <web-53495427@mail3.rug.nl>
Message-ID: <46E91AC9.7070101@stats.uwo.ca>

On 13/09/2007 5:47 AM, T.Lok wrote:
> Yesterday I spend the whole day struggling on how to get 
> the maximum value of "y" for every unique value of "x" 
> from the dataframe "test". In the R Book (Crawley, 2007) 
> an example of this can be found on page 121. I tried to do 
> it this way, but I failed.
> 
> In the end, I figured out how to get it working (first 
> order, and afterwards use !duplicated()). My question is: 
> why does it not work with the unique() function on p. 121 
> (
> i.e. test[rev(order(x)),][unique(y),]) ?
> 
> As a simple example, I used to following syntax:
> 
>> x <- c("A","A","B","B","C","C","D")
>> y <- c(1,2,1,1,2,3,1)
>> z <- c("yes","yes","no","yes","no","no","no")
>> test <- data.frame(x,y,z)
>> test
> 
>    x y   z
> 1 A 1 yes
> 2 A 2 yes
> 3 B 1  no
> 4 B 1 yes
> 5 C 2  no
> 6 C 3  no
> 7 D 1  no
> 
>> test[rev(order(test$y, test$z)),][unique(test$x),]
> 
>    x y   z
> 6 C 3  no
> 2 A 2 yes
> 5 C 2  no
> 4 B 1 yes
> 
> # this clearly does not give a unique value for x, since 
> there are 2 C's and no D!

You are trying to index by the unique values of x.  But x is a factor, 
so this doesn't do anything even close to what you wanted.

> 
>> test[rev(order(test$y, test$z)),][!duplicated(test$x),]
> 
>    x y   z
> 6 C 3  no
> 5 C 2  no
> 1 A 1 yes
> 3 B 1  no
> 

You rearranged the rows of test but not of test$x.  This would work:

test <- test[rev(order(test$y, test$z)),]
test[!duplicated(test$x),]

> # this also doesn't work
> # then I thought, maybe first use the order() function, 
> then unique()
> 
>> test[rev(order(test$y, test$z)),]
> 
>    x y   z
> 6 C 3  no
> 2 A 2 yes
> 5 C 2  no
> 4 B 1 yes
> 1 A 1 yes
> 7 D 1  no
> 3 B 1  no
> 
>> test1 <- test[rev(order(test$y, test$z)),]
>> test1[unique(test1$x),]
> 
>    x y   z
> 5 C 2  no
> 6 C 3  no
> 2 A 2 yes
> 4 B 1 yes
> 
> # still no unique values for x
> 
>> test1[!duplicated(test1$x),]
> 
>    x y   z
> 6 C 3  no
> 2 A 2 yes
> 4 B 1 yes
> 7 D 1  no
> 
> # finally I get unique values for x, for the maximum value 
> of y (and z). But why does this not work when giving the 
> order() and !duplicated() command simultaneously?
> And why does only !duplicated() work, and not unique()?

I think both questions are answered above.

Duncan Murdoch


From Wayne.W.Jones at shell.com  Thu Sep 13 13:13:55 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Thu, 13 Sep 2007 12:13:55 +0100
Subject: [R] how to plot shaded area under a curve?
In-Reply-To: <77693D6263D9B94AA3C6384F1474E26A0284B034@wyt-s-019.europe.shell.com>
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B037@wyt-s-019.europe.shell.com>




?polygon


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of gallon li
Sent: 13 September 2007 11:52
To: r-help
Subject: [R] how to plot shaded area under a curve?


say, I am plotting

x=seq(0,5,len=100)
y=-(x-5)^2

plot(x,y)

how can I put some color or verticle lines below the plotted curve?

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Wayne.W.Jones at shell.com  Thu Sep 13 13:13:55 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Thu, 13 Sep 2007 12:13:55 +0100
Subject: [R] how to plot shaded area under a curve?
In-Reply-To: <77693D6263D9B94AA3C6384F1474E26A0284B034@wyt-s-019.europe.shell.com>
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B037@wyt-s-019.europe.shell.com>




?polygon


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of gallon li
Sent: 13 September 2007 11:52
To: r-help
Subject: [R] how to plot shaded area under a curve?


say, I am plotting

x=seq(0,5,len=100)
y=-(x-5)^2

plot(x,y)

how can I put some color or verticle lines below the plotted curve?

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rguha at indiana.edu  Thu Sep 13 13:52:09 2007
From: rguha at indiana.edu (Rajarshi Guha)
Date: Thu, 13 Sep 2007 07:52:09 -0400
Subject: [R] Someone Using Java/R Interface--- JRI ?
In-Reply-To: <d09859290709121950l2de67ca8mfe9d843e2e7a065d@mail.gmail.com>
References: <d09859290709121950l2de67ca8mfe9d843e2e7a065d@mail.gmail.com>
Message-ID: <612D4782-F2AE-40C8-9900-92EA3F37E68D@indiana.edu>

We use JRI as par of a R web service infrastructure, where we have  
Java classes around specific R functions (lm, randomForest, nnet etc)  
as well as classes that call arbitrary R code

You can look at the code at http://cicc-grid.svn.sourceforge.net/ 
viewvc/cicc-grid/cicc-grid/rws/trunk/src/net/sf/ciccgrid/frontend/

On Sep 12, 2007, at 10:50 PM, Vaibhav Gathibandhe wrote:

> Hi all,
>
> I am writing R code and I want to interface with JAVA i.e. I want  
> to call R
> from JAVA. That's why i have installed JRI on my machine.
>
> There is also documentation available in "Javadoc".
>
> But as i am  very new to JAVA and well as R, I don't understand  
> much of it.
>
> If someone is using this package i.e. JRI, please let me know  
> whether i am
> going in right direction or not.
>
> As i am using regressions, Boot library etc. in my R codes. Is it  
> possible
> to use all these if i use JRI package?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------------------------------------------------------------
Rajarshi Guha  <rguha at indiana.edu>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04  06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
In matrimony, to hesitate is sometimes to be saved.
        -- Butler


From epistat at gmail.com  Thu Sep 13 14:18:48 2007
From: epistat at gmail.com (zhijie zhang)
Date: Thu, 13 Sep 2007 20:18:48 +0800
Subject: [R] handle dates in R?
Message-ID: <2fc17e30709130518w23907a6eyc90d015a18143f97@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070913/026d6646/attachment.pl 

From kemp.samuel at googlemail.com  Thu Sep 13 12:52:44 2007
From: kemp.samuel at googlemail.com (Samuel Kemp)
Date: Thu, 13 Sep 2007 11:52:44 +0100
Subject: [R] smooth scrolling with windows() function
Message-ID: <3a5596550709130352u178f3628k502606c96e03ad22@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070913/a7e7f5c7/attachment.pl 

From jared.oconnell at csiro.au  Thu Sep 13 14:28:33 2007
From: jared.oconnell at csiro.au (Jared O'Connell)
Date: Thu, 13 Sep 2007 20:28:33 +0800
Subject: [R] handle dates in R?
In-Reply-To: <2fc17e30709130518w23907a6eyc90d015a18143f97@mail.gmail.com>
References: <2fc17e30709130518w23907a6eyc90d015a18143f97@mail.gmail.com>
Message-ID: <8c464e8f0709130528t16e1b3bra7585a871c33f3f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070913/8d9a69c4/attachment.pl 

From whit.armstrong at highbridge.com  Thu Sep 13 14:30:36 2007
From: whit.armstrong at highbridge.com (Armstrong, Whit)
Date: Thu, 13 Sep 2007 08:30:36 -0400
Subject: [R] handle dates in R?
In-Reply-To: <2fc17e30709130518w23907a6eyc90d015a18143f97@mail.gmail.com>
Message-ID: <2CF54397DF75234DA13D028A0753C0DE7FC3FA@ex3.811t.hcmny.com>

dts <- c("2004-8-1","2004-10-1","2001-9-1")
strptime(dts,"%Y-%m-%d")
julian(strptime(dts,"%Y-%m-%d")) 


> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of zhijie zhang
> Sent: Thursday, September 13, 2007 8:19 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] handle dates in R?
> 
> Dear Rusers,
>   I have some data in .csv file like "2004-8-1" and 
> "2004-10-1", and i  need to convert them into days from the 
> origin (January 1, 1960).
> I have tried the function date.mmddyyyy(), but cannot get it. 
> Anybody can show me how to handle the date data?
>   Thanks very much!
> 
> My dataset like:
> time
> 2004-8-1
> 2004-10-1
> 2001-9-1
> 2002-9-1
> 
> 
> --
> With Kind Regards,
> 
> oooO:::::::::
> (..):::::::::
> :\.(:::Oooo::
> ::\_)::(..)::
> :::::::)./:::
> ::::::(_/::::
> :::::::::::::
> [*************************************************************
> **********]
> Zhi Jie,Zhang ,PHD
> Tel:86-21-54237149
> Dept. of Epidemiology,School of Public Health,Fudan 
> University Address:No. 138 Yi Xue Yuan Road,Shanghai,China
> Postcode:200032
> Email:epistat at gmail.com
> Website: www.statABC.com
> [*************************************************************
> **********]
> oooO:::::::::
> (..):::::::::
> :\.(:::Oooo::
> ::\_)::(..)::
> :::::::)./:::
> ::::::(_/::::
> :::::::::::::
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 




This e-mail message is intended only for the named recipient(s) above. It may contain confidential information. If you are not the intended recipient you are hereby notified that any dissemination, distribution or copying of this e-mail and any attachment(s) is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender by replying to this e-mail and delete the message and any attachment(s) from your system. Thank you.


From P.Dalgaard at biostat.ku.dk  Thu Sep 13 14:40:44 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 13 Sep 2007 14:40:44 +0200
Subject: [R] handle dates in R?
In-Reply-To: <2CF54397DF75234DA13D028A0753C0DE7FC3FA@ex3.811t.hcmny.com>
References: <2CF54397DF75234DA13D028A0753C0DE7FC3FA@ex3.811t.hcmny.com>
Message-ID: <46E92FCC.30401@biostat.ku.dk>

Armstrong, Whit wrote:
> dts <- c("2004-8-1","2004-10-1","2001-9-1")
> strptime(dts,"%Y-%m-%d")
> julian(strptime(dts,"%Y-%m-%d")) 
>
>
>   
Why do people insist on missing the obvious?

> x <- c("2004-8-1","2004-10-1","2001-9-1")
> as.Date(x) - as.Date("1960-1-1")
Time differences in days
[1] 16284 16345 15219

>> -----Original Message-----
>> From: r-help-bounces at r-project.org 
>> [mailto:r-help-bounces at r-project.org] On Behalf Of zhijie zhang
>> Sent: Thursday, September 13, 2007 8:19 AM
>> To: R-help at stat.math.ethz.ch
>> Subject: [R] handle dates in R?
>>
>> Dear Rusers,
>>   I have some data in .csv file like "2004-8-1" and 
>> "2004-10-1", and i  need to convert them into days from the 
>> origin (January 1, 1960).
>> I have tried the function date.mmddyyyy(), but cannot get it. 
>> Anybody can show me how to handle the date data?
>>   Thanks very much!
>>
>> My dataset like:
>> time
>> 2004-8-1
>> 2004-10-1
>> 2001-9-1
>> 2002-9-1
>>
>>
>> --
>> With Kind Regards,
>>
>> oooO:::::::::
>> (..):::::::::
>> :\.(:::Oooo::
>> ::\_)::(..)::
>> :::::::)./:::
>> ::::::(_/::::
>> :::::::::::::
>> [*************************************************************
>> **********]
>> Zhi Jie,Zhang ,PHD
>> Tel:86-21-54237149
>> Dept. of Epidemiology,School of Public Health,Fudan 
>> University Address:No. 138 Yi Xue Yuan Road,Shanghai,China
>> Postcode:200032
>> Email:epistat at gmail.com
>> Website: www.statABC.com
>> [*************************************************************
>> **********]
>> oooO:::::::::
>> (..):::::::::
>> :\.(:::Oooo::
>> ::\_)::(..)::
>> :::::::)./:::
>> ::::::(_/::::
>> :::::::::::::
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>     
>
>
>
>
> This e-mail message is intended only for the named recipient(s) above. It may contain confidential information. If you are not the intended recipient you are hereby notified that any dissemination, distribution or copying of this e-mail and any attachment(s) is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender by replying to this e-mail and delete the message and any attachment(s) from your system. Thank you.
>
>   
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From marc_schwartz at comcast.net  Thu Sep 13 15:16:32 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 13 Sep 2007 08:16:32 -0500
Subject: [R] barplot border width
In-Reply-To: <c2ebc3880709121243i45139fbdge7c2e9cc16b4e110@mail.gmail.com>
References: <c2ebc3880709121243i45139fbdge7c2e9cc16b4e110@mail.gmail.com>
Message-ID: <1189689392.6149.6.camel@Bellerophon.localdomain>

On Wed, 2007-09-12 at 21:43 +0200, John Lande wrote:
> I need to increase the width of the border in a barplot, i checked both
> barplot, and barplot2, but cant find how to do it. how can I do?

If you are referring to the borders of the bars themselves, you can
adjust par("lwd") prior to calling barplot():

Compare:

  barplot(1:5)

Versus:

  par(lwd = 2)
  barplot(1:5)

See ?par

Note that this does not work when using "inline" pars, such as:

  barplot(1:5, lwd = 2)

This is because there is an internal function in both barplot() and
barplot2() called xyrect() that draws the bars. While the function
definition provides for "..." args, the actual function call does not
have a "..." argument. Hence the additional arguments such as 'lwd' are
not passed.

I'll make a note of that for barplot2() and post a RFE on r-devel for
barplot().

HTH,

Marc Schwartz


From Charles.Annis at StatisticalEngineering.com  Thu Sep 13 15:27:53 2007
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Thu, 13 Sep 2007 09:27:53 -0400
Subject: [R] how to plot shaded area under a curve?
In-Reply-To: <54f7e7c30709130352j17111f15vfc5eec9be0f6e175@mail.gmail.com>
References: <54f7e7c30709130352j17111f15vfc5eec9be0f6e175@mail.gmail.com>
Message-ID: <08a501c7f609$e39a0950$6400a8c0@DD4XFW31>

While it's true that polygon() is the function you need, perhaps it would be
helpful to see an example of how to use polygon().

Go here: http://addictedtor.free.fr/graphiques/thumbs.php

Put the mouse over the thumbnail plots to see larger pictures and look for
something useful.  You will find it here:
http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=88

The code for this graph is downloadable too.  Just click on the icon on the
left of the screen.

Best wishes!

Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  614-455-3265
http://www.StatisticalEngineering.com
 

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of gallon li
Sent: Thursday, September 13, 2007 6:52 AM
To: r-help
Subject: [R] how to plot shaded area under a curve?

say, I am plotting

x=seq(0,5,len=100)
y=-(x-5)^2

plot(x,y)

how can I put some color or verticle lines below the plotted curve?

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From scherer.r at gmx.de  Thu Sep 13 12:44:18 2007
From: scherer.r at gmx.de (Ralph Scherer)
Date: Thu, 13 Sep 2007 12:44:18 +0200
Subject: [R] which test for seven groups with dependency in replication and
 discrete values
Message-ID: <46E91482.9050002@gmx.de>

hello!

My Problem is, that I want to compare seven groups, which have the 
discrete values from 0 to 3. These are damageclasses of plants. 0 is 
best and 3 is worst. Every group has 4 replications with 2 plants. The 
two plants were together in a cage with animals. I think the problem is 
that the two plants are not independent from each other. I don't know 
which test I can use for this problem. I thought the chisquare test but 
I can't find it for more than two groups and I don't know how I should 
consider the dependence between the two plants of every replication. I 
want to find out if there are significantly differences between the 
groups. I hope someone could help me.

Thanks and greetings,
Ralph


From topkatz at msn.com  Thu Sep 13 15:39:36 2007
From: topkatz at msn.com (Talbot Katz)
Date: Thu, 13 Sep 2007 09:39:36 -0400
Subject: [R] "Save to File..." option on File menu
In-Reply-To: <347152339B716A4D893C9A2988EA87C863A76A@KFSVS2.utk.tennessee.edu>
Message-ID: <BAY108-F28569C98A1BA3F5E5CF876AAC30@phx.gbl>

Thank you for bringing your thread to my attention.  The discussion therein 
pretty much encapsulated what I was trying to find out.

--  TMK  --
212-460-5430	home
917-656-5351	cell



>From: "Muenchen, Robert A (Bob)" <muenchen at utk.edu>
>To: <r-help at stat.math.ethz.ch>
>CC: "Talbot Katz" <topkatz at msn.com>
>Subject: RE: [R] "Save to File..." option on File menu
>Date: Wed, 12 Sep 2007 19:03:38 -0400
>
>Hi Talbot,
>
>I just had that question a couple of weeks ago. Here's the thread:
>
>RSiteSearch("Saving results from Linux command line")
>
>Thomas Lumley concluded with:
>
>There could still be functions that divert a copy of all the output to a
>file, for example. And indeed there are.
>
>sink("transcript.txt", split=TRUE)
>
>And you're right, you do this at the start, or put it in your .Rprofile
>so you don't have to remember it each time. The UNIX tee command does
>this as well.
>
>Cheers,
>Bob
>
>=========================================================
>Bob Muenchen (pronounced Min'-chen), Manager
>Statistical Consulting Center
>U of TN Office of Information Technology
>200 Stokely Management Center, Knoxville, TN 37996-0520
>Voice: (865) 974-5230
>FAX: (865) 974-4810
>Email: muenchen at utk.edu
>Web: http://oit.utk.edu/scc,
>News: http://listserv.utk.edu/archives/statnews.html
>=========================================================
>
>
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > project.org] On Behalf Of Talbot Katz
> > Sent: Wednesday, September 12, 2007 3:05 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] "Save to File..." option on File menu
> >
> > Hi.
> >
> > There was an interesting thread about a year ago, called  'Command
> > equivalent of rgui "File, Save to File"?'
> > (http://tolstoy.newcastle.edu.au/R/e2/help/06/09/0553.html) started by
> > Michael Prager, and contributed to by Duncan Murdoch (I didn't notice
> > anything beyond the four entries they posted).  The question was how
>to
> > replicate programmatically the "Save to File..." option on the File
> > menu.
> > The closest answers given involved either running in batch or using
>the
> > sink() command.  Perhaps I don't understand the sink() command well
> > enough,
> > but it appears to me that you have to set it up before you run
> > commands, and
> > that it can't be used to save command output from commands that were
> > already
> > run; am I right about this?  Whereas the "Save to File..." command
> > scoops up
> > everything that's still in the console.  Here is my problem.  I am
> > running R
> > on Linux in a VNC window.  I'd like to save my console output, but
> > there
> > doesn't appear to be a File menu available and I didn't start out with
> > the
> > sink() command.  Is there any way to replicate "Save to File..." in
> > this
> > situation?  Thanks!
> >
> > --  TMK  --
> > 212-460-5430	home
> > 917-656-5351	cell
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From F.MENDIBURU at CGIAR.ORG  Thu Sep 13 15:54:14 2007
From: F.MENDIBURU at CGIAR.ORG (Mendiburu, Felipe (CIP))
Date: Thu, 13 Sep 2007 08:54:14 -0500
Subject: [R] which test for seven groups with dependency in replication
	and discrete values
Message-ID: <B7B34444ECA41A41AC47DABA057CE7A201406B4F@webmail.cip.cgiar.org>

Dear Ralph.

You can use the kruskal function of the library agricolae.
greetings.
Felipe

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of Ralph Scherer
Sent: Thursday, September 13, 2007 5:44 AM
To: r-help at r-project.org
Subject: [R] which test for seven groups with dependency in replication
and discrete values


hello!

My Problem is, that I want to compare seven groups, which have the 
discrete values from 0 to 3. These are damageclasses of plants. 0 is 
best and 3 is worst. Every group has 4 replications with 2 plants. The 
two plants were together in a cage with animals. I think the problem is 
that the two plants are not independent from each other. I don't know 
which test I can use for this problem. I thought the chisquare test but 
I can't find it for more than two groups and I don't know how I should 
consider the dependence between the two plants of every replication. I 
want to find out if there are significantly differences between the 
groups. I hope someone could help me.

Thanks and greetings,
Ralph

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From roland.rproject at gmail.com  Thu Sep 13 15:58:51 2007
From: roland.rproject at gmail.com (Roland Rau)
Date: Thu, 13 Sep 2007 09:58:51 -0400
Subject: [R] Call C code from R
In-Reply-To: <d1419f550709122205k6d61036dg6fb9ae5bdf46e27b@mail.gmail.com>
References: <d1419f550709122205k6d61036dg6fb9ae5bdf46e27b@mail.gmail.com>
Message-ID: <46E9421B.8060004@gmail.com>

Hi!

Olga K. Kamneva wrote:
> Hello, All!
> 
> I have function which is written in C, the function uses other functions
> also builded bu me. Now I need to use the function to build R function.
> My questions are:
> 1. How can I include libraries (for example, iomanip, sstream, tcl.h)?
> 2. Should I put other function to the separate file and then include the
> file?

this document is not very recent but it helped me awhile ago:
http://www.biostat.jhsph.edu/~rpeng/docs/interface.pdf

Best,
Roland


From vincent.goulet at act.ulaval.ca  Thu Sep 13 16:32:12 2007
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Thu, 13 Sep 2007 10:32:12 -0400
Subject: [R] Call C code from R
In-Reply-To: <d1419f550709122205k6d61036dg6fb9ae5bdf46e27b@mail.gmail.com>
References: <d1419f550709122205k6d61036dg6fb9ae5bdf46e27b@mail.gmail.com>
Message-ID: <849F882E-A945-4554-9196-D49831BC4460@act.ulaval.ca>

You did read the "Writing R Extensions" manual before posting, did you?

Le 13 sept. ? 01:05, Olga K. Kamneva a ?crit :

> Hello, All!
>
> I have function which is written in C, the function uses other  
> functions
> also builded bu me. Now I need to use the function to build R  
> function.
> My questions are:
> 1. How can I include libraries (for example, iomanip, sstream, tcl.h)?
> 2. Should I put other function to the separate file and then  
> include the
> file?
>
> Thanks All :)
> Olga
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From fmc2+ at pitt.edu  Thu Sep 13 16:30:37 2007
From: fmc2+ at pitt.edu (Fiona Callaghan)
Date: Thu, 13 Sep 2007 10:30:37 -0400 (EDT)
Subject: [R] Bootstrap tree selection in rpart
In-Reply-To: <200709121308.l8CD8uF14274@hsrnfs-101.mayo.edu>
References: <200709121308.l8CD8uF14274@hsrnfs-101.mayo.edu>
Message-ID: <1241.75.47.70.164.1189693837.squirrel@webmail.pitt.edu>

Thanks very much for replying -- just one final question:  does this hold
when the outcome is continuous (and not discrete) e.g instead of the
outcome being multinomial we have a continuous outcome like residuals?

Thanks again
Fiona
> Fiona Callaghan asked about using the bootstrap  instead of
> cross-validation in
> the tree pruning step.
>    It turns out that cross-validation works better than the bootstrap for
> trees.
> The issue is a subtle one.  The bootstrap can be thought of as 2 steps.
>
> 1.  Deduction: Evaluate the behavior of some statistic "zed" under
> repeated
> sampling from the discrete distribution F-hat, i.e., the original data.
> This
> gives a direct evaluation of how zed behaves under F-hat.
>
> 2. Induction: Assume that (behavior of zed under sampling from F) =
> (behavior
> under sampling from F-hat).
>
>   It turns out that trees behave differently under discreet distributions
> than
> they do under continuous ones, so step 2 fails.  Essentially, there are
> fewer
> places to split in the discrete case, tree creation is less noisy, and the
> bootstrap gives an overoptimistic view.  I remember Brad Efron giving a
> talk on
> this long ago (I was still a student!), so the details are fuzzy; I think
> that
> he solved it by sampling from a smoothed version of the empirical CDF.
>
>    Terry Therneau
>


-- 
Fiona Callaghan, MA MS
A432 Crabtree Hall
Department of Biostatistics
Graduate School of Public Health
University of Pittsburgh
Phone 412 624 3063


From sfalcon at fhcrc.org  Thu Sep 13 16:37:51 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 13 Sep 2007 07:37:51 -0700
Subject: [R] Call C code from R
In-Reply-To: <d1419f550709122205k6d61036dg6fb9ae5bdf46e27b@mail.gmail.com>
	(Olga K. Kamneva's message of "Wed\,
	12 Sep 2007 23\:05\:35 -0600")
References: <d1419f550709122205k6d61036dg6fb9ae5bdf46e27b@mail.gmail.com>
Message-ID: <m2myvqhbr4.fsf@fhcrc.org>

"Olga K. Kamneva" <kamushkina at gmail.com> writes:

> Hello, All!
>
> I have function which is written in C, the function uses other functions
> also builded bu me. Now I need to use the function to build R function.
> My questions are:
> 1. How can I include libraries (for example, iomanip, sstream, tcl.h)?
> 2. Should I put other function to the separate file and then include the
> file?

This is a question more appropriate for the R-devel list.

I would recommend reading over the Writing R Extensions Manual and
then taking a looks at some of the CRAN or Bioconductor packages which
contain native code.

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
BioC: http://bioconductor.org/
Blog: http://userprimary.net/user/


From dafshartous at med.miami.edu  Thu Sep 13 16:49:16 2007
From: dafshartous at med.miami.edu (David Afshartous)
Date: Thu, 13 Sep 2007 10:49:16 -0400
Subject: [R] Multiple R sessions, Mac version
Message-ID: <C30EC62C.11AC%dafshartous@med.miami.edu>

Hello all,

I've just switched to running R 2.5.1 on a Mac 0S X 10.4.1 platform.  I
can't seem to find how to run simultaneous R sessions.  Didn't see anything
in the archives on this or under the R file menu.

Thanks!
David


From dafshartous at med.miami.edu  Thu Sep 13 17:00:41 2007
From: dafshartous at med.miami.edu (David Afshartous)
Date: Thu, 13 Sep 2007 11:00:41 -0400
Subject: [R] Multiple R sessions, Mac version
In-Reply-To: <C30EC62C.11AC%dafshartous@med.miami.edu>
Message-ID: <C30EC8D9.11AE%dafshartous@med.miami.edu>

Hello all,

I've just switched to running R 2.5.1 on a Mac 0S X 10.4.1 platform.  I
can't seem to find how to run simultaneous R sessions.  Didn't see anything
in the archives on this or under the R file menu.

Thanks!
David


From alenzo at mail.rochester.edu  Thu Sep 13 16:55:46 2007
From: alenzo at mail.rochester.edu (A Lenzo)
Date: Thu, 13 Sep 2007 10:55:46 -0400
Subject: [R] How to use available.packages
Message-ID: <007f01c7f616$2d8e6a90$f6339780@libra.cc.rochester.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070913/99c6267d/attachment.pl 

From likhonnaser at hotmail.com  Thu Sep 13 15:34:51 2007
From: likhonnaser at hotmail.com (Abu Naser)
Date: Thu, 13 Sep 2007 13:34:51 +0000
Subject: [R] Very new help needed.
Message-ID: <BAY134-W35730FBB033D71E965F901A3C30@phx.gbl>


Hello all R user,

I am very new with r I have been wondering whether anyone could help me.
I have a 23000 row and 273 colums. What I want to do is to calculate unit vector for every 
3 colums along the row. Could you please advise me how to do that using R?

with regards,
Abu 
_________________________________________________________________
100?s of Music vouchers to be won with MSN Music


From agharti81 at tiscali.it  Thu Sep 13 16:54:01 2007
From: agharti81 at tiscali.it (Mauro Arnoldi)
Date: Thu, 13 Sep 2007 16:54:01 +0200
Subject: [R] Number -> Fraction
Message-ID: <200709131654.01524.agharti81@tiscali.it>

Hi everybody!
I'm new to this list and also to the R program.

I'd like to know if there is a function able to convert results into 
Fractional form like my scientific calculator have. For example:

> 1/3
[1] 0.3333333

> function_that_return_a_fraction_from_numbers(0.3333333)
[1] 1/3

Thanks

Mauro

-- 


Man, he is constantly growing 
and when he is bound by a set 
pattern of ideas or way
of doing things, that's when
he stops growing
	-- Bruce Lee


From Wayne.W.Jones at shell.com  Thu Sep 13 16:58:16 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Thu, 13 Sep 2007 15:58:16 +0100
Subject: [R] Bootstrap tree selection in rpart
In-Reply-To: <1241.75.47.70.164.1189693837.squirrel@webmail.pitt.edu>
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B03A@wyt-s-019.europe.shell.com>


Hi there, 

Rather than cross validating or bootstrapping to prune a single tree you could use random forest instead. Look at the overview in http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm 

THere is a package in R for doing this called library(randomForest). I have found it to be an excellent method which produces better forecasts (in bag and out-of-bag) than a single tree. Also it allows you still interpret the most important variables. It handles continuous variables and classification variables. 

Regards

Wayne


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of Fiona Callaghan
Sent: 13 September 2007 15:31
To: Terry Therneau
Cc: r-help at stat.math.ethz.ch; fmc2 at pitt.edu
Subject: Re: [R] Bootstrap tree selection in rpart


Thanks very much for replying -- just one final question:  does this hold
when the outcome is continuous (and not discrete) e.g instead of the
outcome being multinomial we have a continuous outcome like residuals?

Thanks again
Fiona
> Fiona Callaghan asked about using the bootstrap  instead of
> cross-validation in
> the tree pruning step.
>    It turns out that cross-validation works better than the bootstrap for
> trees.
> The issue is a subtle one.  The bootstrap can be thought of as 2 steps.
>
> 1.  Deduction: Evaluate the behavior of some statistic "zed" under
> repeated
> sampling from the discrete distribution F-hat, i.e., the original data.
> This
> gives a direct evaluation of how zed behaves under F-hat.
>
> 2. Induction: Assume that (behavior of zed under sampling from F) =
> (behavior
> under sampling from F-hat).
>
>   It turns out that trees behave differently under discreet distributions
> than
> they do under continuous ones, so step 2 fails.  Essentially, there are
> fewer
> places to split in the discrete case, tree creation is less noisy, and the
> bootstrap gives an overoptimistic view.  I remember Brad Efron giving a
> talk on
> this long ago (I was still a student!), so the details are fuzzy; I think
> that
> he solved it by sampling from a smoothed version of the empirical CDF.
>
>    Terry Therneau
>


-- 
Fiona Callaghan, MA MS
A432 Crabtree Hall
Department of Biostatistics
Graduate School of Public Health
University of Pittsburgh
Phone 412 624 3063

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.uni-dortmund.de  Thu Sep 13 17:06:00 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 13 Sep 2007 17:06:00 +0200
Subject: [R] Number -> Fraction
In-Reply-To: <200709131654.01524.agharti81@tiscali.it>
References: <200709131654.01524.agharti81@tiscali.it>
Message-ID: <46E951D8.30403@statistik.uni-dortmund.de>



Mauro Arnoldi wrote:
> Hi everybody!
> I'm new to this list and also to the R program.
> 
> I'd like to know if there is a function able to convert results into 
> Fractional form like my scientific calculator have. For example:
> 
>> 1/3
> [1] 0.3333333
> 
>> function_that_return_a_fraction_from_numbers(0.3333333)
> [1] 1/3


0.333333 is not equal 1/3, hence it is impossible to do that in a 
reliable manner.

Uwe Ligges


> Thanks
> 
> Mauro
>


From agoralczyk at gmail.com  Thu Sep 13 17:06:22 2007
From: agoralczyk at gmail.com (Armin Goralczyk)
Date: Thu, 13 Sep 2007 17:06:22 +0200
Subject: [R] Multivariate, multilevel regression?
In-Reply-To: <728924.50404.qm@web35413.mail.mud.yahoo.com>
References: <728924.50404.qm@web35413.mail.mud.yahoo.com>
Message-ID: <a695fbee0709130806o1cc180ees9ef2df9428feea91@mail.gmail.com>

On 9/13/07, John McHenry <john_d_mchenry at yahoo.com> wrote:
> Dear WizaRds,
>
> This is mostly a statistics question, but I'm figuring that R is the right solution (even before I start!)
>
>

Also have a look at these tutorials (in the journal Statistics in
Medicine, needs subscription)

http://dx.doi.org/10.1002/(SICI)1097-0258(19971030)16:20<2349::AID-SIM667>3.0.CO;2-E

and

http://www3.interscience.wiley.com/cgi-bin/abstract/62004087/ABSTRACT

-- 
Armin Goralczyk, M.D.
Dept. of General Surgery
University of G?ttingen
G?ttingen, Germany
http://www.chirurgie-goettingen.de

From stef at biostatistics.it  Thu Sep 13 17:06:54 2007
From: stef at biostatistics.it (Stefano Calza)
Date: Thu, 13 Sep 2007 17:06:54 +0200
Subject: [R] Number -> Fraction
In-Reply-To: <200709131654.01524.agharti81@tiscali.it>
References: <200709131654.01524.agharti81@tiscali.it>
Message-ID: <20070913150654.GH7493@med.unibs.it>

Welcome (benvenuto),


see "fractions" in library MASS

es:

> fractions(1/2)
[1] 1/2

Ciao

Stefano



On Thu, Sep 13, 2007 at 04:54:01PM +0200, Mauro Arnoldi wrote:
<Mauro>Hi everybody!
<Mauro>I'm new to this list and also to the R program.
<Mauro>
<Mauro>I'd like to know if there is a function able to convert results into 
<Mauro>Fractional form like my scientific calculator have. For example:
<Mauro>
<Mauro>> 1/3
<Mauro>[1] 0.3333333
<Mauro>
<Mauro>> function_that_return_a_fraction_from_numbers(0.3333333)
<Mauro>[1] 1/3
<Mauro>
<Mauro>Thanks
<Mauro>
<Mauro>Mauro
<Mauro>
<Mauro>-- 
<Mauro>
<Mauro>
<Mauro>Man, he is constantly growing 
<Mauro>and when he is bound by a set 
<Mauro>pattern of ideas or way
<Mauro>of doing things, that's when
<Mauro>he stops growing
<Mauro>	-- Bruce Lee
<Mauro>
<Mauro>______________________________________________
<Mauro>R-help a r-project.org mailing list
<Mauro>https://stat.ethz.ch/mailman/listinfo/r-help
<Mauro>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
<Mauro>and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Thu Sep 13 17:07:31 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 13 Sep 2007 11:07:31 -0400
Subject: [R] Number -> Fraction
In-Reply-To: <200709131654.01524.agharti81@tiscali.it>
References: <200709131654.01524.agharti81@tiscali.it>
Message-ID: <971536df0709130807o3ace88aah256273028b8d2741@mail.gmail.com>

Try:

library(MASS)
?fractions


On 9/13/07, Mauro Arnoldi <agharti81 at tiscali.it> wrote:
> Hi everybody!
> I'm new to this list and also to the R program.
>
> I'd like to know if there is a function able to convert results into
> Fractional form like my scientific calculator have. For example:
>
> > 1/3
> [1] 0.3333333
>
> > function_that_return_a_fraction_from_numbers(0.3333333)
> [1] 1/3
>
> Thanks
>
> Mauro
>
> --
>
>
> Man, he is constantly growing
> and when he is bound by a set
> pattern of ideas or way
> of doing things, that's when
> he stops growing
>        -- Bruce Lee
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kate at few.vu.nl  Thu Sep 13 17:08:57 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Thu, 13 Sep 2007 17:08:57 +0200 (CEST)
Subject: [R] Number -> Fraction
In-Reply-To: <200709131654.01524.agharti81@tiscali.it>
References: <200709131654.01524.agharti81@tiscali.it>
Message-ID: <Pine.GSO.4.56.0709131708140.8419@laurel.few.vu.nl>

look at ?fractions

> fractions(.33333)
[1] 1/3

On Thu, 13 Sep 2007, Mauro Arnoldi wrote:

> Hi everybody!
> I'm new to this list and also to the R program.
>
> I'd like to know if there is a function able to convert results into
> Fractional form like my scientific calculator have. For example:
>
> > 1/3
> [1] 0.3333333
>
> > function_that_return_a_fraction_from_numbers(0.3333333)
> [1] 1/3
>
> Thanks
>
> Mauro
>
> --
>
>
> Man, he is constantly growing
> and when he is bound by a set
> pattern of ideas or way
> of doing things, that's when
> he stops growing
> 	-- Bruce Lee
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wwwhsd at gmail.com  Thu Sep 13 17:12:06 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Thu, 13 Sep 2007 12:12:06 -0300
Subject: [R] How to use available.packages
In-Reply-To: <007f01c7f616$2d8e6a90$f6339780@libra.cc.rochester.edu>
References: <007f01c7f616$2d8e6a90$f6339780@libra.cc.rochester.edu>
Message-ID: <da79af330709130812l74360034q121770dc98581a1f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070913/427d2308/attachment.pl 

From Wayne.W.Jones at shell.com  Thu Sep 13 17:15:54 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Thu, 13 Sep 2007 16:15:54 +0100
Subject: [R]  test
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B03B@wyt-s-019.europe.shell.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070913/6cfcdaea/attachment.pl 

From ligges at statistik.uni-dortmund.de  Thu Sep 13 17:16:03 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 13 Sep 2007 17:16:03 +0200
Subject: [R] How to use available.packages
In-Reply-To: <007f01c7f616$2d8e6a90$f6339780@libra.cc.rochester.edu>
References: <007f01c7f616$2d8e6a90$f6339780@libra.cc.rochester.edu>
Message-ID: <46E95433.3040309@statistik.uni-dortmund.de>



A Lenzo wrote:
> Hello R gurus,
> 
> Until recently, I used the following commands to update R:
> 
> options(CRAN = "http://cran.stat.ucla.edu")
> install.packages(CRAN.packages()[,1])
> 
> But now I am told that install.packages is deprecated and that I should use
> available.packages

No, it tells you that
   'CRAN.packages' is deprecated.

Do you really want to install all packages?
If so, see ?available.packages and use that one instaed of CRAN.packages 
... It is more meaningful, because there are other repositories than 
CRAN around, one of them BioConductor, for example.

Uwe Ligges



> Can anyone tell me what the corresponding commands are when using
> available.packages?
> 
> Thank you for your time.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ucecgxu at ucl.ac.uk  Thu Sep 13 17:16:45 2007
From: ucecgxu at ucl.ac.uk (gang xu)
Date: Thu, 13 Sep 2007 16:16:45 +0100
Subject: [R] how to obtain the CPU time of my program
Message-ID: <000b01c7f619$18ee8a90$2de42880@chemeng.ucl.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070913/6f278a24/attachment.pl 

From aa2007r at gmail.com  Thu Sep 13 17:35:31 2007
From: aa2007r at gmail.com (AA)
Date: Thu, 13 Sep 2007 11:35:31 -0400
Subject: [R] how to plot shaded area under a curve?
References: <54f7e7c30709130352j17111f15vfc5eec9be0f6e175@mail.gmail.com>
	<08a501c7f609$e39a0950$6400a8c0@DD4XFW31>
Message-ID: <038301c7f61b$b93c11a0$3301a8c0@MainDomain.local>

in addition to Charles' suggestion which is more advanced, I found the link 
below very helpful.
http://www.feferraz.net/en/shaded.html
good luck
AA.

----- Original Message ----- 
From: "Charles Annis, P.E." <Charles.Annis at StatisticalEngineering.com>
To: "'gallon li'" <gallon.li at gmail.com>; "'r-help'" 
<r-help at stat.math.ethz.ch>
Sent: Thursday, September 13, 2007 9:27 AM
Subject: Re: [R] how to plot shaded area under a curve?


> While it's true that polygon() is the function you need, perhaps it would 
> be
> helpful to see an example of how to use polygon().
>
> Go here: http://addictedtor.free.fr/graphiques/thumbs.php
>
> Put the mouse over the thumbnail plots to see larger pictures and look for
> something useful.  You will find it here:
> http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=88
>
> The code for this graph is downloadable too.  Just click on the icon on 
> the
> left of the screen.
>
> Best wishes!
>
> Charles Annis, P.E.
>
> Charles.Annis at StatisticalEngineering.com
> phone: 561-352-9699
> eFax:  614-455-3265
> http://www.StatisticalEngineering.com
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] 
> On
> Behalf Of gallon li
> Sent: Thursday, September 13, 2007 6:52 AM
> To: r-help
> Subject: [R] how to plot shaded area under a curve?
>
> say, I am plotting
>
> x=seq(0,5,len=100)
> y=-(x-5)^2
>
> plot(x,y)
>
> how can I put some color or verticle lines below the plotted curve?
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From martinpareja at googlemail.com  Thu Sep 13 17:32:32 2007
From: martinpareja at googlemail.com (martin pareja)
Date: Thu, 13 Sep 2007 17:32:32 +0200
Subject: [R] Logistic regression
Message-ID: <3b66752d0709130832h3a139141kc424c6096caed581@mail.gmail.com>

Hello
I am trying to get the estimated value of logit(p), along with its
standard error/conf interval from a logistic regression model (for the
overall sample, and for individual treatment levels), where p is the
proportion of "successes". I am having difficulty in finding how to
tell R to give this information.
Would anybody be able to help with this?

Thanks
Martin Pareja


From tlumley at u.washington.edu  Thu Sep 13 17:34:24 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 13 Sep 2007 08:34:24 -0700 (PDT)
Subject: [R] Number -> Fraction
In-Reply-To: <200709131654.01524.agharti81@tiscali.it>
References: <200709131654.01524.agharti81@tiscali.it>
Message-ID: <Pine.LNX.4.64.0709130830330.1818@homer21.u.washington.edu>

On Thu, 13 Sep 2007, Mauro Arnoldi wrote:

> Hi everybody!
> I'm new to this list and also to the R program.
>
> I'd like to know if there is a function able to convert results into
> Fractional form like my scientific calculator have. For example:
>
>> 1/3
> [1] 0.3333333
>
>> function_that_return_a_fraction_from_numbers(0.3333333)
> [1] 1/3
>

This must have some restrictions (so it doesn't return 3333333/1000000, 
which would be a more accurate fraction).

One approach is
> unfrac <- function(x, max=100, tol=0.01){
     num <- x * (1:max)
     err <- (num - round(num)) * (1:max)
     if (!any(abs(err) < tol))
         return(NA)
     i <- which.min(abs(err))
     c(round(num[i]), i)
}

This returns the best fraction approximation with denominator up to `max`, 
where `best` is in terms of the non-integer part of the numerator, and no 
answer is given if the non-integer part of the numerator is more than 
`tol`

> unfrac(0.3333333)
[1] 1 3
> unfrac(pi)
[1] NA
> unfrac(pi,max=1000)
[1] 355 113
> unfrac(pi,tol=0.1)
[1] 22  7

 	-thomas


From singularitaet at gmx.net  Thu Sep 13 17:36:09 2007
From: singularitaet at gmx.net (Stefan Grosse)
Date: Thu, 13 Sep 2007 17:36:09 +0200
Subject: [R] how to obtain the CPU time of my program
In-Reply-To: <000b01c7f619$18ee8a90$2de42880@chemeng.ucl.ac.uk>
References: <000b01c7f619$18ee8a90$2de42880@chemeng.ucl.ac.uk>
Message-ID: <46E958E9.1050509@gmx.net>

-------- Original Message  --------
Subject: [R] how to obtain the CPU time of my program
From: gang xu <ucecgxu at ucl.ac.uk>
To: r-help at stat.math.ethz.ch
Date: 13.09.2007 17:16
> Dear R users and experts,
>
> I am current running a program (a series of commands) in R. such as:
>
> A <- as.matrix(read.table("C:/LP.txt"));
>
> a=which(memb==q); b=a; B=as.matrix(A[a,b])
>
> LS=sum(B)/2;
>
> TL=sum(A)/2
>
> i<-c(1:NN);
>
> D=sum(A[a,i]);
>
> how can i obtain the CPU time used for these commands ?
>
> I have seen the system.time function but i am not sure how to use it. Could anyone help me ?
>   
?system.time

> ****** If we have a number of commands, how can we know the CPU for these commands *******
>
>
> Thanks a lot for your time and help
>
> Have a nice day!
>
> Warm Regards
>
> Marshall
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>   


-=-=-
... Those people who think they know everything are a great annoyance to
those of us who do. (Isaac Asimov)


From csardi at rmki.kfki.hu  Thu Sep 13 17:38:09 2007
From: csardi at rmki.kfki.hu (Gabor Csardi)
Date: Thu, 13 Sep 2007 17:38:09 +0200
Subject: [R] how to obtain the CPU time of my program
In-Reply-To: <000b01c7f619$18ee8a90$2de42880@chemeng.ucl.ac.uk>
References: <000b01c7f619$18ee8a90$2de42880@chemeng.ucl.ac.uk>
Message-ID: <20070913153808.GA5603@localdomain>

Here's how to use it: 

f <- function() {
  <<here comes your code>>
}

system.time( f() )

It is not required to define a function, but i think it is easier.

Gabor

On Thu, Sep 13, 2007 at 04:16:45PM +0100, gang xu wrote:
> Dear R users and experts,
> 
> I am current running a program (a series of commands) in R. such as:
> 
> A <- as.matrix(read.table("C:/LP.txt"));
> 
> a=which(memb==q); b=a; B=as.matrix(A[a,b])
> 
> LS=sum(B)/2;
> 
> TL=sum(A)/2
> 
> i<-c(1:NN);
> 
> D=sum(A[a,i]);
> 
> how can i obtain the CPU time used for these commands ?
> 
> I have seen the system.time function but i am not sure how to use it. Could anyone help me ?
> 
> ****** If we have a number of commands, how can we know the CPU for these commands *******
> 
> 
> Thanks a lot for your time and help
> 
> Have a nice day!
> 
> Warm Regards
> 
> Marshall
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK


From Greg.Snow at intermountainmail.org  Thu Sep 13 17:47:25 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 13 Sep 2007 09:47:25 -0600
Subject: [R] smooth scrolling with windows() function
In-Reply-To: <3a5596550709130352u178f3628k502606c96e03ad22@mail.gmail.com>
References: <3a5596550709130352u178f3628k502606c96e03ad22@mail.gmail.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBF9298@LP-EXCHVS07.CO.IHC.COM>

I don't know why windows is so slow/jumpy doing it your way.  One
alternative is to use the tkrplot library.  This does redraw the plot
every time, but it is fast enough that it goes pretty smooth.  Here is
an example that you can start with to see if it does what you want:

library(tkrplot)

y <- rnorm(10000, 10, 2) + 5*sin( (1:10000)/1000 )

tt <- tktoplevel()
left <- tclVar(1)
oldleft <- tclVar(1)
right <- tclVar(100)

f1 <- function(){
        lleft <- as.numeric(tclvalue(left))
        rright <- as.numeric(tclvalue(right))
        x <- seq(lleft,rright,by=1)
        plot(x,y[x], type='b',ylim=range(y))
}

img <- tkrplot(tt, f1)

f2 <- function(...){
        ol <- as.numeric(tclvalue(oldleft))
        tclvalue(oldleft) <- tclvalue(left)
        r <- as.numeric(tclvalue(right))
        tclvalue(right) <- as.character(r + as.numeric(...) - ol)
        tkrreplot(img)
}

f3 <- function(...){
        tkrreplot(img)
}

f4 <- function(...){
        ol <- as.numeric(tclvalue(oldleft))
        tclvalue(left) <- as.character(ol+100)
        tclvalue(oldleft) <- as.character(ol+100)
        r <- as.numeric(tclvalue(right))
        tclvalue(right) <- as.character(r+100)
        tkrreplot(img)
}

s1 <- tkscale(tt, command=f2, from=1, to=length(y),
        variable=left, orient="horiz",label='left')
s2 <- tkscale(tt, command=f3, from=1, to=length(y),
        variable=right, orient="horiz",label='right')
b1 <- tkbutton(tt, text='->', command=f4)

tkpack(img,s1,s2,b1) 


Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Samuel Kemp
> Sent: Thursday, September 13, 2007 4:53 AM
> To: r-help at r-project.org
> Subject: [R] smooth scrolling with windows() function
> 
> Hi,
> 
> I have a large plot that I would like to display in a 
> graphics device with scroll bars. I therefore decided to use 
> the windows function like so...
> 
> mag<- length(tick)
> windows(height=mag/8, width=10, rescale="fixed")
> 
> However, when I use the scroll bars the device (i guess) is 
> re-drawing the plot. Is there any way in which I can get it 
> to 'smooth scroll'?
> 
> Kind regards,
> 
> Sam
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From birgit.lemcke at systbot.uzh.ch  Thu Sep 13 18:01:13 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Thu, 13 Sep 2007 18:01:13 +0200
Subject: [R] t.test() with missing values
Message-ID: <D3E2394B-665D-406B-B02E-DDD919C5365C@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070913/70131415/attachment.pl 

From rvaradhan at jhmi.edu  Thu Sep 13 18:07:02 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Thu, 13 Sep 2007 12:07:02 -0400
Subject: [R] Number -> Fraction
In-Reply-To: <Pine.LNX.4.64.0709130830330.1818@homer21.u.washington.edu>
References: <200709131654.01524.agharti81@tiscali.it>
	<Pine.LNX.4.64.0709130830330.1818@homer21.u.washington.edu>
Message-ID: <000e01c7f620$1f3398d0$7c94100a@win.ad.jhu.edu>

Finding sufficiently accurate rational approximations to a real number, can
be done using fractions() in MASS, which uses continued fractions.
"Sufficient" accuracy can be specified using the number of cycles and
maximum denominator size options (note that max.denom is the final term in
the continued fraction).

Some examples:
> library(MASS)
> fractions(0.333333,max.denom=100000)
[1] 1/3
> fractions(0.333333,max.denom=1000000)
[1] 1519169814041/4557513999637
> fractions(0.333333,max.denom=1000000,cycles=11)
[1] 8587703744937/25763136997948

> fractions(pi,max=1)
[1] 3
> fractions(pi,max=10)
[1] 22/7
> fractions(pi,max=100)
[1] 355/113
> fractions(pi,max=1000)
[1] 4272943/1360120
> fractions(pi,max=1000,cycles=12)
[1] 80143857/25510582
This last rational approximation to pi is quite accurate, up to machine
precision (i.e. 16 digits)

Ravi.

----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Thomas Lumley
Sent: Thursday, September 13, 2007 11:34 AM
To: Mauro Arnoldi
Cc: r-help at r-project.org
Subject: Re: [R] Number -> Fraction

On Thu, 13 Sep 2007, Mauro Arnoldi wrote:

> Hi everybody!
> I'm new to this list and also to the R program.
>
> I'd like to know if there is a function able to convert results into
> Fractional form like my scientific calculator have. For example:
>
>> 1/3
> [1] 0.3333333
>
>> function_that_return_a_fraction_from_numbers(0.3333333)
> [1] 1/3
>

This must have some restrictions (so it doesn't return 3333333/1000000, 
which would be a more accurate fraction).

One approach is
> unfrac <- function(x, max=100, tol=0.01){
     num <- x * (1:max)
     err <- (num - round(num)) * (1:max)
     if (!any(abs(err) < tol))
         return(NA)
     i <- which.min(abs(err))
     c(round(num[i]), i)
}

This returns the best fraction approximation with denominator up to `max`, 
where `best` is in terms of the non-integer part of the numerator, and no 
answer is given if the non-integer part of the numerator is more than 
`tol`

> unfrac(0.3333333)
[1] 1 3
> unfrac(pi)
[1] NA
> unfrac(pi,max=1000)
[1] 355 113
> unfrac(pi,tol=0.1)
[1] 22  7

 	-thomas

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From John.Scillieri at constellation.com  Thu Sep 13 18:12:03 2007
From: John.Scillieri at constellation.com (Scillieri, John)
Date: Thu, 13 Sep 2007 12:12:03 -0400
Subject: [R] ROracle and R 2.5.1 on Windows
Message-ID: <E9281F574E824446BD09B591327F6AA101D1057B@EXM-OMF-21.Ceg.Corp.Net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070913/044891c5/attachment.pl 

From cberry at tajo.ucsd.edu  Thu Sep 13 18:18:26 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Thu, 13 Sep 2007 09:18:26 -0700
Subject: [R] Very new help needed.
In-Reply-To: <BAY134-W35730FBB033D71E965F901A3C30@phx.gbl>
References: <BAY134-W35730FBB033D71E965F901A3C30@phx.gbl>
Message-ID: <Pine.LNX.4.64.0709130909100.28109@tajo.ucsd.edu>

On Thu, 13 Sep 2007, Abu Naser wrote:

>
> Hello all R user,
>
> I am very new with r I have been wondering whether anyone could help me.
> I have a 23000 row and 273 colums. What I want to do is to calculate unit vector for every
> 3 colums along the row. Could you please advise me how to do that using R?


A simple example might help us to understand what it is you want.


Do you wish to convert a 23000 by 273 matrix to a 23000*3 by 273/3 matrix?

If so and your matrix is 'x',

 	dim(x) <- c( 23000*3, 273/3 )

will do.

Do you wish to find the projection of the vector (1,1,1) onto each set of 
x[ i, 1:3 + (j-1)*3 ]? Then

 	apply( array( x, dim=c(23000, 3, 273/3 ) ), c(1,3), mean )

seems like what you would want.

As is stated at the end of your email:

 	PLEASE do read the posting guide
 	http://www.R-project.org/posting-guide.html and provide commented,
 	minimal, self-contained, reproducible code.

This will make it more likely that readers of your message can help you.

>
> with regards,
> Abu
> _________________________________________________________________
> 100?s of Music vouchers to be won with MSN Music
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From tlumley at u.washington.edu  Thu Sep 13 18:31:31 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 13 Sep 2007 09:31:31 -0700 (PDT)
Subject: [R] Number -> Fraction
In-Reply-To: <000e01c7f620$1f3398d0$7c94100a@win.ad.jhu.edu>
References: <200709131654.01524.agharti81@tiscali.it>
	<Pine.LNX.4.64.0709130830330.1818@homer21.u.washington.edu>
	<000e01c7f620$1f3398d0$7c94100a@win.ad.jhu.edu>
Message-ID: <Pine.LNX.4.64.0709130926250.1818@homer21.u.washington.edu>


I should have remembered MASS::fractions().  This has a slightly different 
aim, giving continued fraction approximations to any real number, where my 
function just tries to handle numbers that really are close to fractions 
with small denominators.

For example, unfrac() won't  report a fraction for sqrt(2), even with 
tol=0.1, max=10000, since sqrt(2), which doesn't have very good rational 
approximations (algebraic numbers tend not to).

 	-thomas



On Thu, 13 Sep 2007, Ravi Varadhan wrote:

> Finding sufficiently accurate rational approximations to a real number, can
> be done using fractions() in MASS, which uses continued fractions.
> "Sufficient" accuracy can be specified using the number of cycles and
> maximum denominator size options (note that max.denom is the final term in
> the continued fraction).
>
> Some examples:
>> library(MASS)
>> fractions(0.333333,max.denom=100000)
> [1] 1/3
>> fractions(0.333333,max.denom=1000000)
> [1] 1519169814041/4557513999637
>> fractions(0.333333,max.denom=1000000,cycles=11)
> [1] 8587703744937/25763136997948
>
>> fractions(pi,max=1)
> [1] 3
>> fractions(pi,max=10)
> [1] 22/7
>> fractions(pi,max=100)
> [1] 355/113
>> fractions(pi,max=1000)
> [1] 4272943/1360120
>> fractions(pi,max=1000,cycles=12)
> [1] 80143857/25510582
> This last rational approximation to pi is quite accurate, up to machine
> precision (i.e. 16 digits)
>
> Ravi.
>
> ----------------------------------------------------------------------------
> -------
>
> Ravi Varadhan, Ph.D.
>
> Assistant Professor, The Center on Aging and Health
>
> Division of Geriatric Medicine and Gerontology
>
> Johns Hopkins University
>
> Ph: (410) 502-2619
>
> Fax: (410) 614-9625
>
> Email: rvaradhan at jhmi.edu
>
> Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html
>
>
>
> ----------------------------------------------------------------------------
> --------
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf Of Thomas Lumley
> Sent: Thursday, September 13, 2007 11:34 AM
> To: Mauro Arnoldi
> Cc: r-help at r-project.org
> Subject: Re: [R] Number -> Fraction
>
> On Thu, 13 Sep 2007, Mauro Arnoldi wrote:
>
>> Hi everybody!
>> I'm new to this list and also to the R program.
>>
>> I'd like to know if there is a function able to convert results into
>> Fractional form like my scientific calculator have. For example:
>>
>>> 1/3
>> [1] 0.3333333
>>
>>> function_that_return_a_fraction_from_numbers(0.3333333)
>> [1] 1/3
>>
>
> This must have some restrictions (so it doesn't return 3333333/1000000,
> which would be a more accurate fraction).
>
> One approach is
>> unfrac <- function(x, max=100, tol=0.01){
>     num <- x * (1:max)
>     err <- (num - round(num)) * (1:max)
>     if (!any(abs(err) < tol))
>         return(NA)
>     i <- which.min(abs(err))
>     c(round(num[i]), i)
> }
>
> This returns the best fraction approximation with denominator up to `max`,
> where `best` is in terms of the non-integer part of the numerator, and no
> answer is given if the non-integer part of the numerator is more than
> `tol`
>
>> unfrac(0.3333333)
> [1] 1 3
>> unfrac(pi)
> [1] NA
>> unfrac(pi,max=1000)
> [1] 355 113
>> unfrac(pi,tol=0.1)
> [1] 22  7
>
> 	-thomas
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From p.dalgaard at biostat.ku.dk  Thu Sep 13 18:50:59 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 13 Sep 2007 18:50:59 +0200
Subject: [R] t.test() with missing values
In-Reply-To: <D3E2394B-665D-406B-B02E-DDD919C5365C@systbot.uzh.ch>
References: <D3E2394B-665D-406B-B02E-DDD919C5365C@systbot.uzh.ch>
Message-ID: <46E96A73.4090803@biostat.ku.dk>

Birgit Lemcke wrote:
> Hello!
>
> I am using R 2.5.1 on a Apple Power Book G4 with Mac OS X 10.4.10 and  
> I am still R beginner.
>
> I try to calculate a t.test() using this code:
>
> 	TTest75<-t.test(Fem75, Mal75, alternative= "two.sided", paired= TRUE)
>
> This works properly, but I have two variables with a lot of missing  
> data and therefore get the error message:
>
> 	TTest66<-t.test(Fem66, Mal66, alternative= "two.sided", paired= TRUE)
> 	Fehler in var(x) : 'x' ist leer
>
> One of the two vectors looks like this:
>
> [1] 5.0  NA 4.5 6.0 0.8  NA 7.0 4.5  NA  NA  NA  NA 5.0  NA 6.0  NA  
> 5.0  NA 5.0 8.0  NA  NA  NA 8.0  NA 8.0 5.0  NA  NA  NA  NA 8.0  NA 1.0
> [35]  NA  NA  NA  NA  NA  NA 5.0  NA 4.0 8.0  NA 6.0 6.0 4.5 3.5  NA   
> NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
> [69]  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA ....
>   

> Is it possible to run a TTest inspite of all the missing data?
> I really need two know if may two vectors are significantly  
> different. (If this results are then reliable is an other question)
>   
Well, you're not showing the other one, but I have a hunch that 
any(complete.cases(Fem66, Mal66)) will come out false,  in which case 
you don't have paired data and might get rid of paired=TRUE and have an 
ordinary two sample test. (BTW paired data for females and males? Couples?)


> By the way is there a better possibility (and I guess there is) to  
> save or export the t.test() results as textfile?
>
> Thanks in advance for your help.
>
> Greetings
>
> Birgit
>
> Birgit Lemcke
> Institut f?r Systematische Botanik
> Zollikerstrasse 107
> CH-8008 Z?rich
> Switzerland
> Ph: +41 (0)44 634 8351
> birgit.lemcke at systbot.uzh.ch
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From andrewsmith81 at gmail.com  Thu Sep 13 19:37:23 2007
From: andrewsmith81 at gmail.com (Andrew Smith)
Date: Thu, 13 Sep 2007 13:37:23 -0400
Subject: [R] Origin label in lattice
Message-ID: <c81725600709131037sb2dd739iae6e3bdf66b4647c@mail.gmail.com>

I would like to make what seems like a simple addition to a display
constructed from a call to levelplot -- I want to add a text label
(which will, in general, depend on the object being plotted, and so
cannot be hardcoded) to the origin, which has special significance in
my problem.  The x and y axes always have range (0,1) in my plots, so
by "origin" I always mean the lower left corner of the plot.  Now, I
can add text to the inside of the panel using panel.text, but this
clutters the plot and I find it unsatisfactory.  What I would like is
to add the label outside of the panel, just below and to the left of
the lower left corner of the panel.  I've unsuccessfully tried to do
this using the xscale.components argument, and I'm having trouble
figuring out which other arguments or functions might be helpful.  I
would greatly appreciate any advice!

Thanks,

Andrew Smith

Georgia Tech
School of Industrial and Systems Engineering


From agharti81 at tiscali.it  Thu Sep 13 17:18:21 2007
From: agharti81 at tiscali.it (Mauro Arnoldi)
Date: Thu, 13 Sep 2007 17:18:21 +0200
Subject: [R] Number -> Fraction
In-Reply-To: <20070913150654.GH7493@med.unibs.it>
References: <200709131654.01524.agharti81@tiscali.it>
	<20070913150654.GH7493@med.unibs.it>
Message-ID: <200709131718.21384.agharti81@tiscali.it>

Alle gioved? 13 settembre 2007, Stefano Calza ha scritto:

>
> see "fractions" in library MASS
>
Yeah!

> 1/3
[1] 0.3333333
> fractions(0.3333333)
[1] 1/3

Great! Thanks! (grazie :) )

Mauro


From changzhu at yahoo.com  Thu Sep 13 18:50:35 2007
From: changzhu at yahoo.com (nuyaying)
Date: Thu, 13 Sep 2007 09:50:35 -0700 (PDT)
Subject: [R] How to delete a duplicate observation
Message-ID: <12659033.post@talk.nabble.com>



I have a data set with 3 variables V1, V2, V3.  If there are 2 data points
have the same values on both V1 and V2,  I want to delete one of them which
has smaller V3 value.    i.e., in the data below, I want to delete 
the first observation.  How can I do that ?    Thanks in advance!      

V1  V2  V3
3    3     1
3    3     4

-- 
View this message in context: http://www.nabble.com/How-to-delete-a-duplicate-observation-tf4437033.html#a12659033
Sent from the R help mailing list archive at Nabble.com.


From p.dalgaard at biostat.ku.dk  Thu Sep 13 20:17:23 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 13 Sep 2007 20:17:23 +0200
Subject: [R] How to delete a duplicate observation
In-Reply-To: <12659033.post@talk.nabble.com>
References: <12659033.post@talk.nabble.com>
Message-ID: <46E97EB3.8070302@biostat.ku.dk>

nuyaying wrote:
> I have a data set with 3 variables V1, V2, V3.  If there are 2 data points
> have the same values on both V1 and V2,  I want to delete one of them which
> has smaller V3 value.    i.e., in the data below, I want to delete 
> the first observation.  How can I do that ?    Thanks in advance!      
>
> V1  V2  V3
> 3    3     1
> 3    3     4
>
>   
Tricky one... I think something like this should work:

l <- split(d$V3, list(d$V1,d$V2))
ixl <- lapply(l, function(x) {
   if ((n <- nrow(x)) == 2)
      seq_len(n) != which.min(x)
   else
      rep(TRUE, n)
})
ix <- unsplit(ixl, list(d$V1,d$V2))
d[ix,]

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Mark.Leeds at morganstanley.com  Thu Sep 13 20:18:18 2007
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Thu, 13 Sep 2007 14:18:18 -0400
Subject: [R] statistics - hypothesis testing question
Message-ID: <D3AEEDA31E57474B840BEBC25A8A834401957A3B@NYWEXMB23.msad.ms.com>

I estimate two competing simple regression models, A and B where the LHS
is the same in both cases but the predictor is different (
I handle the intercept issue based on other postings I have seen ). I
estimate the two models on a weekly basis over 24 weeks. 
So, I end up with 24 RSquaredAs and 24 RsquaredBs, so essentally 2 time
series of Rsquareds. This doesn't have to be necessarily thought of as a
time series problem but, is there a usual way, given the Rsquared data,
to test 

H0 : Rsquared B = Rsquared A versus H1 : Rsquared B > Rsquared A 

so that I can map the 24 R squared numbers into 1 statistic. Maybe
that's somehow equivalent to just running 2 big regressions over the
whole 24 weeks and then calculating a statistic from those based on
those regressions ?

I broke things up into 24 weeks because I was thinking that the
stability of the performance difference of the two models could be 
examined over time. Essentially these are simple time series regressions
X_t = B*X_t-1 + epsilon so I always need to consider
whether any type of behavior is stable.  But now I am thinking that,  if
I just want one overall number,  then maybe I should be considering all
the data simultaneously ? 

In a nutshell,  I am looking for any suggestions on the best way to test
whether Model B is better than Model A where

Model A :  X_t = Beta*X_t-1 + epsilon

Model B :  X_t = Betastar*Xstar_t-1 + epsilonstar


Thanks fo your help.
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From alfreale74 at gmail.com  Thu Sep 13 20:27:31 2007
From: alfreale74 at gmail.com (Alfredo Alessandrini)
Date: Thu, 13 Sep 2007 20:27:31 +0200
Subject: [R] loop function
Message-ID: <d2c05c5a0709131127w4581f217j31d45a487841812e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070913/52e0b948/attachment.pl 

From murdoch at stats.uwo.ca  Thu Sep 13 20:31:55 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 13 Sep 2007 14:31:55 -0400
Subject: [R] statistics - hypothesis testing question
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A834401957A3B@NYWEXMB23.msad.ms.com>
References: <D3AEEDA31E57474B840BEBC25A8A834401957A3B@NYWEXMB23.msad.ms.com>
Message-ID: <46E9821B.9070503@stats.uwo.ca>

On 9/13/2007 2:18 PM, Leeds, Mark (IED) wrote:
> I estimate two competing simple regression models, A and B where the LHS
> is the same in both cases but the predictor is different (
> I handle the intercept issue based on other postings I have seen ). I
> estimate the two models on a weekly basis over 24 weeks. 
> So, I end up with 24 RSquaredAs and 24 RsquaredBs, so essentally 2 time
> series of Rsquareds. This doesn't have to be necessarily thought of as a
> time series problem but, is there a usual way, given the Rsquared data,
> to test 
> 
> H0 : Rsquared B = Rsquared A versus H1 : Rsquared B > Rsquared A 
> 
> so that I can map the 24 R squared numbers into 1 statistic. Maybe
> that's somehow equivalent to just running 2 big regressions over the
> whole 24 weeks and then calculating a statistic from those based on
> those regressions ?

The question doesn't make sense, if you're using standard notation.  R^2 
is a statistic, not a parameter, so one wouldn't test copies of it for 
equality.

You can probably reframe the question in terms of E(R^2) so the 
statement parses, but then it doesn't really make sense from a subject 
matter point of view:  unless model A is nested within model B, why 
would you ever expect the two fits to explain exactly the same amount of 
variation?

If model A is really a special case of model B, then you're back to the 
standard hypothesis testing situation, but repeated 24 times.  There's a 
lot of literature on how to handle such multiple testing problems, 
depending on what sort of alternatives you want to detect.  (E.g. do you 
think all 24 cases will be identical, or is it possible that 23 will 
match but one doesn't?)

Duncan Murdoch

> 
> I broke things up into 24 weeks because I was thinking that the
> stability of the performance difference of the two models could be 
> examined over time. Essentially these are simple time series regressions
> X_t = B*X_t-1 + epsilon so I always need to consider
> whether any type of behavior is stable.  But now I am thinking that,  if
> I just want one overall number,  then maybe I should be considering all
> the data simultaneously ? 
> 
> In a nutshell,  I am looking for any suggestions on the best way to test
> whether Model B is better than Model A where
> 
> Model A :  X_t = Beta*X_t-1 + epsilon
> 
> Model B :  X_t = Betastar*Xstar_t-1 + epsilonstar
> 
> 
> Thanks fo your help.
> --------------------------------------------------------
> 
> This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p.dalgaard at biostat.ku.dk  Thu Sep 13 20:30:37 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 13 Sep 2007 20:30:37 +0200
Subject: [R] loop function
In-Reply-To: <d2c05c5a0709131127w4581f217j31d45a487841812e@mail.gmail.com>
References: <d2c05c5a0709131127w4581f217j31d45a487841812e@mail.gmail.com>
Message-ID: <46E981CD.2030307@biostat.ku.dk>

Alfredo Alessandrini wrote:
> Hi,
>
> If I have this values:
>
> 21
> 23
> 14
> 58
> 26
> ....
>
> How can I sum the values by a progression like this:
>
> (21)
> (21 + 23)
> (21 + 23 + 14)
> (21 + 23 + 14 + 58)
> (21 + 23 + 14 + 58 + 26)
> (21 + 23 + 14 + 58 + 26....)
>
> I've try with the function "loop"....
>
>   
Try cumsum() instead...

> Best Wishes,
>
> Alfredo
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From jholtman at gmail.com  Thu Sep 13 20:31:54 2007
From: jholtman at gmail.com (jim holtman)
Date: Thu, 13 Sep 2007 14:31:54 -0400
Subject: [R] loop function
In-Reply-To: <d2c05c5a0709131127w4581f217j31d45a487841812e@mail.gmail.com>
References: <d2c05c5a0709131127w4581f217j31d45a487841812e@mail.gmail.com>
Message-ID: <644e1f320709131131k6a36156bge16a6bdcfae9a106@mail.gmail.com>

Is this what you want:

> x
[1] 21 23 14 58 26
> cumsum(x)
[1]  21  44  58 116 142


On 9/13/07, Alfredo Alessandrini <alfreale74 at gmail.com> wrote:
> Hi,
>
> If I have this values:
>
> 21
> 23
> 14
> 58
> 26
> ....
>
> How can I sum the values by a progression like this:
>
> (21)
> (21 + 23)
> (21 + 23 + 14)
> (21 + 23 + 14 + 58)
> (21 + 23 + 14 + 58 + 26)
> (21 + 23 + 14 + 58 + 26....)
>
> I've try with the function "loop"....
>
> Best Wishes,
>
> Alfredo
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From Mark.Leeds at morganstanley.com  Thu Sep 13 20:39:27 2007
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Thu, 13 Sep 2007 14:39:27 -0400
Subject: [R] statistics - hypothesis testing question
In-Reply-To: <46E9821B.9070503@stats.uwo.ca>
References: <D3AEEDA31E57474B840BEBC25A8A834401957A3B@NYWEXMB23.msad.ms.com>
	<46E9821B.9070503@stats.uwo.ca>
Message-ID: <D3AEEDA31E57474B840BEBC25A8A834401957A3D@NYWEXMB23.msad.ms.com>

you're right Duncan. My bad. That was kind of dopey because R squared is
a statistic in itself.  They aren't nested models because
the two predictors are different and there are no other predictors.  I'm
trying  to see whether the model B predictor is "better" than  the
Model A predictor. I guess how one defines "better" is th real question
so I apologize for that. Still, any comments, suggestions are welcome.


-----Original Message-----
From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca] 
Sent: Thursday, September 13, 2007 2:32 PM
To: Leeds, Mark (IED)
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] statistics - hypothesis testing question

On 9/13/2007 2:18 PM, Leeds, Mark (IED) wrote:
> I estimate two competing simple regression models, A and B where the 
> LHS is the same in both cases but the predictor is different ( I 
> handle the intercept issue based on other postings I have seen ). I 
> estimate the two models on a weekly basis over 24 weeks.
> So, I end up with 24 RSquaredAs and 24 RsquaredBs, so essentally 2 
> time series of Rsquareds. This doesn't have to be necessarily thought 
> of as a time series problem but, is there a usual way, given the 
> Rsquared data, to test
> 
> H0 : Rsquared B = Rsquared A versus H1 : Rsquared B > Rsquared A
> 
> so that I can map the 24 R squared numbers into 1 statistic. Maybe 
> that's somehow equivalent to just running 2 big regressions over the 
> whole 24 weeks and then calculating a statistic from those based on 
> those regressions ?

The question doesn't make sense, if you're using standard notation.  R^2
is a statistic, not a parameter, so one wouldn't test copies of it for
equality.

You can probably reframe the question in terms of E(R^2) so the
statement parses, but then it doesn't really make sense from a subject
matter point of view:  unless model A is nested within model B, why
would you ever expect the two fits to explain exactly the same amount of
variation?

If model A is really a special case of model B, then you're back to the
standard hypothesis testing situation, but repeated 24 times.  There's a
lot of literature on how to handle such multiple testing problems,
depending on what sort of alternatives you want to detect.  (E.g. do you
think all 24 cases will be identical, or is it possible that 23 will
match but one doesn't?)

Duncan Murdoch

> 
> I broke things up into 24 weeks because I was thinking that the 
> stability of the performance difference of the two models could be 
> examined over time. Essentially these are simple time series 
> regressions X_t = B*X_t-1 + epsilon so I always need to consider 
> whether any type of behavior is stable.  But now I am thinking that,  
> if I just want one overall number,  then maybe I should be considering

> all the data simultaneously ?
> 
> In a nutshell,  I am looking for any suggestions on the best way to 
> test whether Model B is better than Model A where
> 
> Model A :  X_t = Beta*X_t-1 + epsilon
> 
> Model B :  X_t = Betastar*Xstar_t-1 + epsilonstar
> 
> 
> Thanks fo your help.
> --------------------------------------------------------
> 
> This is not an offer (or solicitation of an offer) to 
> buy/se...{{dropped}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From jholtman at gmail.com  Thu Sep 13 20:41:01 2007
From: jholtman at gmail.com (jim holtman)
Date: Thu, 13 Sep 2007 14:41:01 -0400
Subject: [R] How to delete a duplicate observation
In-Reply-To: <46E97EB3.8070302@biostat.ku.dk>
References: <12659033.post@talk.nabble.com> <46E97EB3.8070302@biostat.ku.dk>
Message-ID: <644e1f320709131141q399dd4f1n5134168e6c048625@mail.gmail.com>

Here a way of doing it:

> x <- cbind(V1=sample(1:3,20,TRUE), V2=sample(1:3,20,TRUE), V3=sample(20))
> x
      V1 V2 V3
 [1,]  2  2  1
 [2,]  1  2  6
 [3,]  3  2 10
 [4,]  3  1 11
 [5,]  3  2  5
 [6,]  3  2  7
 [7,]  2  1 19
 [8,]  3  3 13
 [9,]  1  3  2
[10,]  3  3 20
[11,]  3  3 18
[12,]  2  1  4
[13,]  3  2  3
[14,]  3  2 12
[15,]  3  1 17
[16,]  2  3  9
[17,]  2  3  8
[18,]  1  1 16
[19,]  3  2 15
[20,]  3  3 14
> x.max <- do.call('rbind', by(x, list(x[,1], x[,2]), function(.sub){
+     .sub[which.max(.sub[,3]),]
+ }))
> x.max
   V1 V2 V3
18  1  1 16
7   2  1 19
15  3  1 17
2   1  2  6
5   2  2  1
19  3  2 15
9   1  3  2
16  2  3  9
10  3  3 20
>


On 9/13/07, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> nuyaying wrote:
> > I have a data set with 3 variables V1, V2, V3.  If there are 2 data points
> > have the same values on both V1 and V2,  I want to delete one of them which
> > has smaller V3 value.    i.e., in the data below, I want to delete
> > the first observation.  How can I do that ?    Thanks in advance!
> >
> > V1  V2  V3
> > 3    3     1
> > 3    3     4
> >
> >
> Tricky one... I think something like this should work:
>
> l <- split(d$V3, list(d$V1,d$V2))
> ixl <- lapply(l, function(x) {
>   if ((n <- nrow(x)) == 2)
>      seq_len(n) != which.min(x)
>   else
>      rep(TRUE, n)
> })
> ix <- unsplit(ixl, list(d$V1,d$V2))
> d[ix,]
>
> --
>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From sundar.dorai-raj at pdf.com  Thu Sep 13 20:42:18 2007
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 13 Sep 2007 11:42:18 -0700
Subject: [R] How to delete a duplicate observation
In-Reply-To: <12659033.post@talk.nabble.com>
References: <12659033.post@talk.nabble.com>
Message-ID: <46E9848A.8060503@pdf.com>



nuyaying said the following on 9/13/2007 9:50 AM:
> 
> I have a data set with 3 variables V1, V2, V3.  If there are 2 data points
> have the same values on both V1 and V2,  I want to delete one of them which
> has smaller V3 value.    i.e., in the data below, I want to delete 
> the first observation.  How can I do that ?    Thanks in advance!      
> 
> V1  V2  V3
> 3    3     1
> 3    3     4
> 


How about:

## some sample data
d <- read.table(textConnection("V1 V2 V3
3 3 2
3 3 4
3 3 1
3 2 1
3 2 5"), header = TRUE)

## the code
d <- d[rev(do.call("order", d)), ]
d <- d[!duplicated(d[1:2]), ]
d

HTH,

--sundar


From albmont at centroin.com.br  Thu Sep 13 20:44:26 2007
From: albmont at centroin.com.br (Alberto Monteiro)
Date: Thu, 13 Sep 2007 16:44:26 -0200
Subject: [R] Number -> Fraction
In-Reply-To: <000e01c7f620$1f3398d0$7c94100a@win.ad.jhu.edu>
References: <200709131654.01524.agharti81@tiscali.it>
	<Pine.LNX.4.64.0709130830330.1818@homer21.u.washington.edu>
	<000e01c7f620$1f3398d0$7c94100a@win.ad.jhu.edu>
Message-ID: <20070913183553.M4782@centroin.com.br>

Ravi Varadhan wrote:
>
> Finding sufficiently accurate rational approximations to a real 
> number, can be done using fractions() in MASS, which uses
> continued fractions.
>
In a slight off-topic digression, I recently learned that
any irrational number that can be nicely approximated by
rational numbers is transcendental. The number that gets
the _worse_ approximations is the ubiquitous Golden Ratio:

  phi <- (1 + sqrt(5))/2

There's a way to express this precisely, something like
|x - p/q| < 1/q^n (http://en.wikipedia.org/wiki/Liouville_number)

Alberto Monteiro


From zlu at umich.edu  Thu Sep 13 20:47:38 2007
From: zlu at umich.edu (Zheng Lu)
Date: Thu, 13 Sep 2007 14:47:38 -0400
Subject: [R] help with unit indication when plotting
Message-ID: <20070913144738.rjz7cyn794wk0og8@web.mail.umich.edu>

Dear all:

Is there any one could tell me how I can represent Micro-molar as an 
unit of concentration when I plot with R(S-plus), I don't want write 
'uM' from keyboard, I am thinking to write it like in word, in word, 
people insert symbol for 'u' for uM. Am I clear? Thank you very much 
for your consideration and help.


Lu


From Greg.Snow at intermountainmail.org  Thu Sep 13 20:58:37 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 13 Sep 2007 12:58:37 -0600
Subject: [R] How to delete a duplicate observation
In-Reply-To: <12659033.post@talk.nabble.com>
References: <12659033.post@talk.nabble.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBF9331@LP-EXCHVS07.CO.IHC.COM>

How about (assuming the data is in the data frame my.df):

> my.df2 <- my.df[order(my.df$V3, decreasing=TRUE),]
> my.df3 <- my.df2[ !duplicated( my.df2[,c('V1','V2')] ), ]

If order of the rows matters then we will need to add a couple of steps
to reorder.  You did not say what to do if 3 or more points matched,
this approach takes the largest single V3 value from all matching on V1
and V2.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of nuyaying
> Sent: Thursday, September 13, 2007 10:51 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] How to delete a duplicate observation
> 
> 
> 
> I have a data set with 3 variables V1, V2, V3.  If there are 
> 2 data points have the same values on both V1 and V2,  I want 
> to delete one of them which
> has smaller V3 value.    i.e., in the data below, I want to delete 
> the first observation.  How can I do that ?    Thanks in 
> advance!      
> 
> V1  V2  V3
> 3    3     1
> 3    3     4
> 
> --
> View this message in context: 
> http://www.nabble.com/How-to-delete-a-duplicate-observation-tf
> 4437033.html#a12659033
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From kate at few.vu.nl  Thu Sep 13 21:05:58 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Thu, 13 Sep 2007 21:05:58 +0200 (CEST)
Subject: [R] help with unit indication when plotting
In-Reply-To: <20070913144738.rjz7cyn794wk0og8@web.mail.umich.edu>
References: <20070913144738.rjz7cyn794wk0og8@web.mail.umich.edu>
Message-ID: <Pine.GSO.4.56.0709132103580.11544@laurel.few.vu.nl>

see ?plotmath

you want to use "mu" for micro, as in
plot(1:10, ylab = expression(paste(mu, "M")))

On Thu, 13 Sep 2007, Zheng Lu wrote:

> Dear all:
>
> Is there any one could tell me how I can represent Micro-molar as an
> unit of concentration when I plot with R(S-plus), I don't want write
> 'uM' from keyboard, I am thinking to write it like in word, in word,
> people insert symbol for 'u' for uM. Am I clear? Thank you very much
> for your consideration and help.
>
>
> Lu
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Greg.Snow at intermountainmail.org  Thu Sep 13 21:08:41 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 13 Sep 2007 13:08:41 -0600
Subject: [R] statistics - hypothesis testing question
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A834401957A3B@NYWEXMB23.msad.ms.com>
References: <D3AEEDA31E57474B840BEBC25A8A834401957A3B@NYWEXMB23.msad.ms.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBF9335@LP-EXCHVS07.CO.IHC.COM>

Is the data paired?  i.e. do you have an A and a B from week 1, then the
same for each following week?

If so, then you could probably do a simple sign test, within each week
see if rsquared B > rsquared A. under the null hypothesis that A and B
are equivalent this should be a binomial with parameter = 0.5.  If you
want something a little  fancier then you could do some type of
permutation test (which the sign test is a special case of).

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Leeds, Mark (IED)
> Sent: Thursday, September 13, 2007 12:18 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] statistics - hypothesis testing question
> 
> I estimate two competing simple regression models, A and B 
> where the LHS is the same in both cases but the predictor is 
> different ( I handle the intercept issue based on other 
> postings I have seen ). I estimate the two models on a weekly 
> basis over 24 weeks. 
> So, I end up with 24 RSquaredAs and 24 RsquaredBs, so 
> essentally 2 time series of Rsquareds. This doesn't have to 
> be necessarily thought of as a time series problem but, is 
> there a usual way, given the Rsquared data, to test 
> 
> H0 : Rsquared B = Rsquared A versus H1 : Rsquared B > Rsquared A 
> 
> so that I can map the 24 R squared numbers into 1 statistic. 
> Maybe that's somehow equivalent to just running 2 big 
> regressions over the whole 24 weeks and then calculating a 
> statistic from those based on those regressions ?
> 
> I broke things up into 24 weeks because I was thinking that 
> the stability of the performance difference of the two models 
> could be examined over time. Essentially these are simple 
> time series regressions X_t = B*X_t-1 + epsilon so I always 
> need to consider whether any type of behavior is stable.  But 
> now I am thinking that,  if I just want one overall number,  
> then maybe I should be considering all the data simultaneously ? 
> 
> In a nutshell,  I am looking for any suggestions on the best 
> way to test whether Model B is better than Model A where
> 
> Model A :  X_t = Beta*X_t-1 + epsilon
> 
> Model B :  X_t = Betastar*Xstar_t-1 + epsilonstar
> 
> 
> Thanks fo your help.
> --------------------------------------------------------
> 
> This is not an offer (or solicitation of an offer) to 
> buy/se...{{dropped}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From murdoch at stats.uwo.ca  Thu Sep 13 21:14:00 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 13 Sep 2007 15:14:00 -0400
Subject: [R] help with unit indication when plotting
In-Reply-To: <20070913144738.rjz7cyn794wk0og8@web.mail.umich.edu>
References: <20070913144738.rjz7cyn794wk0og8@web.mail.umich.edu>
Message-ID: <46E98BF8.6060902@stats.uwo.ca>

On 9/13/2007 2:47 PM, Zheng Lu wrote:
> Dear all:
> 
> Is there any one could tell me how I can represent Micro-molar as an 
> unit of concentration when I plot with R(S-plus), I don't want write 
> 'uM' from keyboard, I am thinking to write it like in word, in word, 
> people insert symbol for 'u' for uM. Am I clear? Thank you very much 
> for your consideration and help.

plot(1,2, xlab=expression(mu * M))

See ?plotmath for all the other neat things R can do in labels on plots.

Duncan Murdoch


From Greg.Snow at intermountainmail.org  Thu Sep 13 21:11:36 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 13 Sep 2007 13:11:36 -0600
Subject: [R] help with unit indication when plotting
In-Reply-To: <20070913144738.rjz7cyn794wk0og8@web.mail.umich.edu>
References: <20070913144738.rjz7cyn794wk0og8@web.mail.umich.edu>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBF9336@LP-EXCHVS07.CO.IHC.COM>

Look at ?plotmath, could you use a greek mu for the micro part?

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Zheng Lu
> Sent: Thursday, September 13, 2007 12:48 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] help with unit indication when plotting
> 
> Dear all:
> 
> Is there any one could tell me how I can represent 
> Micro-molar as an unit of concentration when I plot with 
> R(S-plus), I don't want write 'uM' from keyboard, I am 
> thinking to write it like in word, in word, people insert 
> symbol for 'u' for uM. Am I clear? Thank you very much for 
> your consideration and help.
> 
> 
> Lu
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From sebastian.weber at physik.tu-darmstadt.de  Thu Sep 13 09:44:03 2007
From: sebastian.weber at physik.tu-darmstadt.de (Sebastian Weber)
Date: Thu, 13 Sep 2007 09:44:03 +0200
Subject: [R] minimize white space around lattice plot
Message-ID: <1189669443.6641.8.camel@stealth.kraft.de>

Dear list,

I'm trying to produce a plot via xyplot with minimal sourounding white
space. However, I cannot find the options in xyplot, ps.options or
wherever which prevents lattice from drawing quite some white space
around my plot. However, this is quite a problem for me as I want to
produce an inset plot inside another lattice-plot. I'm using the panel
function to open a viewport and print the inset plot within the actual
plot. The problem now is, that there is lots of sourounding white space
around my inner plot. Here is an example:

panel.inset <- function(...,
                        inset,
                        drawRect=TRUE,
                        ixpos=unit(0, "mm"), iypos=unit(1, "npc"),
                        ijust=c("left","top"),
                        iwidth=unit(0.7, "npc"), iheight=unit(0.5,
"npc")) {
  ## open our viewport ...
  pushViewport(viewport(x=ixpos, y=iypos, width=iwidth, height=iheight,
just=ijust, name="inset"))

  if(drawRect)
    grid.rect(gp=gpar(lwd=1,col="black"))
  
  ## ... and place the other plot inside there
  print(inset, newpage=FALSE, prefix="insetPlot")

  upViewport()
  
  ## draw the actual plot
  panel.xyplot(...)

  ## why is this neccessary?? Otherwise I get no lines for the axis ...
  grid.rect(gp=gpar())
}

x<-0:10
y<-x^4


insetPlot <- xyplot(y ~ x, scales=list(log=T), main=NULL, aspect="fill")
xyplot(y ~ x, panel="panel.inset", inset=insetPlot)

Thank you very much for any input!

Greetings,

Sebastian Weber


From maura.monville at gmail.com  Thu Sep 13 22:06:35 2007
From: maura.monville at gmail.com (Maura E Monville)
Date: Thu, 13 Sep 2007 15:06:35 -0500
Subject: [R] beginner's questions ... sorry
Message-ID: <36d691950709131306u5a6ada99sf44419fdc4136b7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070913/08ac524a/attachment.pl 

From jsorkin at grecc.umaryland.edu  Thu Sep 13 22:19:19 2007
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Thu, 13 Sep 2007 16:19:19 -0400
Subject: [R] statistics - hypothesis testing question
Message-ID: <46E96308020000CB00016190@medicine.umaryland.edu>

Mark,
Estimates of R values can be compared using Fishers r to z transform. Perhaps this will
do what you wish to do.
John

John Sorkin M.D., Ph.D.
Chief, Biostatistics and Informatics
Baltimore VA Medical Center GRECC,
University of Maryland School of Medicine Claude D. Pepper OAIC,
University of Maryland Clinical Nutrition Research Unit, and
Baltimore VA Center Stroke of Excellence

University of Maryland School of Medicine
Division of Gerontology
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524

(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)
jsorkin at grecc.umaryland.edu
>>> Duncan Murdoch <murdoch at stats.uwo.ca> 09/13/07 2:31 PM >>>
On 9/13/2007 2:18 PM, Leeds, Mark (IED) wrote:
> I estimate two competing simple regression models, A and B where the LHS
> is the same in both cases but the predictor is different (
> I handle the intercept issue based on other postings I have seen ). I
> estimate the two models on a weekly basis over 24 weeks. 
> So, I end up with 24 RSquaredAs and 24 RsquaredBs, so essentally 2 time
> series of Rsquareds. This doesn't have to be necessarily thought of as a
> time series problem but, is there a usual way, given the Rsquared data,
> to test 
> 
> H0 : Rsquared B = Rsquared A versus H1 : Rsquared B > Rsquared A 
> 
> so that I can map the 24 R squared numbers into 1 statistic. Maybe
> that's somehow equivalent to just running 2 big regressions over the
> whole 24 weeks and then calculating a statistic from those based on
> those regressions ?

The question doesn't make sense, if you're using standard notation.  R^2 
is a statistic, not a parameter, so one wouldn't test copies of it for 
equality.

You can probably reframe the question in terms of E(R^2) so the 
statement parses, but then it doesn't really make sense from a subject 
matter point of view:  unless model A is nested within model B, why 
would you ever expect the two fits to explain exactly the same amount of 
variation?

If model A is really a special case of model B, then you're back to the 
standard hypothesis testing situation, but repeated 24 times.  There's a 
lot of literature on how to handle such multiple testing problems, 
depending on what sort of alternatives you want to detect.  (E.g. do you 
think all 24 cases will be identical, or is it possible that 23 will 
match but one doesn't?)

Duncan Murdoch

> 
> I broke things up into 24 weeks because I was thinking that the
> stability of the performance difference of the two models could be 
> examined over time. Essentially these are simple time series regressions
> X_t = B*X_t-1 + epsilon so I always need to consider
> whether any type of behavior is stable.  But now I am thinking that,  if
> I just want one overall number,  then maybe I should be considering all
> the data simultaneously ? 
> 
> In a nutshell,  I am looking for any suggestions on the best way to test
> whether Model B is better than Model A where
> 
> Model A :  X_t = Beta*X_t-1 + epsilon
> 
> Model B :  X_t = Betastar*Xstar_t-1 + epsilonstar
> 
> 
> Thanks fo your help.
> --------------------------------------------------------
> 
> This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Confidentiality Statement:
This email message, including any attachments, is for the so...{{dropped}}


From TobinJR at DFO-MPO.GC.CA  Thu Sep 13 22:20:07 2007
From: TobinJR at DFO-MPO.GC.CA (Tobin, Jared)
Date: Thu, 13 Sep 2007 17:50:07 -0230
Subject: [R] Collapsing data frame; aggregate() or better function?
Message-ID: <FBF367376AD9E64BB8531D56CA38DA6A01C7CBCA@nflwhex01.nfl.dfo-mpo.ca>

Hello r-help,

I am trying to collapse or aggregate 'some' of a data frame.  A very
simplified version of my data frame looks like:

> tester
  trip set num sex lfs1 lfs2
1  313  15   5   M    2    3
2  313  15   3   F    1    2
3  313  17   1   M    0    1
4  313  17   2   F    1    1
5  313  17   1   U    1    0

And I want to omit sex from the picture and just get an addition of num,
lfs1, and lfs2 for each unique trip/set combination.  Using aggregate()
works fine here,

> test <- aggregate(tester[,c(3,5:6)], tester[,1:2], sum)
> test
  trip set num lfs1 lfs2
1  313  15   8    3    5
2  313  17   4    2    2 

But I'm having trouble getting the same function to work on my actual
data frame which is considerably larger.

> dim(lf1.turbot)
[1] 16468   217
> test <- aggregate(lf1.turbot[,c(11, 12, 17:217)], lf1.turbot[,1:8],
sum)
Error in vector("list", prod(extent)) : vector size specified is too
large
In addition: Warning messages:
1: NAs produced by integer overflow in: ngroup * (as.integer(index) -
one) 
2: NAs produced by integer overflow in: group + ngroup *
(as.integer(index) - one) 
3: NAs produced by integer overflow in: ngroup * nlevels(index) 

I'm guessing that either aggregate() can't handle a data frame of this
size OR that there is an issue with 'omitting' more than one variable
(in the same way I've omitted sex in the above example).  Can anyone
clarify and/or recommend any relatively simple alternative procedure to
accomplish this?

I plan on trying variants of by() and tapply() tomorrow morning, but I'm
about to head home for the day.

Thanks,

--

jared tobin, student research assistant
fisheries and oceans canada
tobinjr at dfo-mpo.gc.ca


From dlakelan at street-artists.org  Thu Sep 13 22:22:55 2007
From: dlakelan at street-artists.org (Daniel Lakeland)
Date: Thu, 13 Sep 2007 13:22:55 -0700
Subject: [R] beginner's questions ... sorry
In-Reply-To: <36d691950709131306u5a6ada99sf44419fdc4136b7@mail.gmail.com>
References: <36d691950709131306u5a6ada99sf44419fdc4136b7@mail.gmail.com>
Message-ID: <20070913202255.GB6852@street-artists.org>

On Thu, Sep 13, 2007 at 03:06:35PM -0500, Maura E Monville wrote:
> I have 316 files. Each file represents a patient's breathing track
> (respiratory signal recorded for a variable number of cycles). All files
> have the same are made up of a header followed by a variable number of
> records.

You can read the patient ID out of the header using scan and some
manipulation of the resulting strings, depending on how complicated it
is to find the patient ID in the header. 

Then you can read.table or read.csv etc to get the data. Then use the
cbind command as you did to bind the new column with the patient id to
the rest of the data.

I believe that cbind will recycle the patient ID to make up the
required number of rows, so you can simply cbind(your.data,
yourpatientID) where instead of a large column of identical items, you
have a single item for yourpatientID

an example:

> myframe <- cbind(as.data.frame(list(a=1:3,b=3:5)),added="foo")
> 
> myframe
  a b added
1 1 3   foo
2 2 4   foo
3 3 5   foo

> I have no doubt R experienced users would accomplish the same task in a
> couple of strokes .... HOW ????

> And how shall I instruct R to save my changes when I close the editing
> session ?

write.table
write.csv

or my favorite way of keeping data well organized is RSqlite or sqldf
(related)


-- 
Daniel Lakeland
dlakelan at street-artists.org
http://www.street-artists.org/~dlakelan


From Ted.Harding at manchester.ac.uk  Thu Sep 13 22:32:37 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Thu, 13 Sep 2007 21:32:37 +0100 (BST)
Subject: [R] beginner's questions ... sorry
In-Reply-To: <36d691950709131306u5a6ada99sf44419fdc4136b7@mail.gmail.com>
Message-ID: <XFMail.070913213237.Ted.Harding@manchester.ac.uk>

On 13-Sep-07 20:06:35, Maura E Monville wrote:
> I have 316 files. Each file represents a patient's breathing
> track (respiratory signal recorded for a variable number of
> cycles).
> All files have the same are made up of a header followed by
> a variable number of records.
> Each record contains 7 comma separated fields.
> The patient ID is recorded in the header which is stripped
> off when reading the file into a R data.frame.
> Since I need to keep this piece of information, I need to add
> the 8th column to a patient's data.frame. All elements of
> such a column store the patient's ID.
> The problem is trivial. I guess it can be done in a matter of
> a few seconds.
> But I (a R novice) could not find an automatic or fast way to
> do that.

Hi Maura,
There could be several ways to do it, but the important thing
is to know how to "parse out" the Patient ID from the header.

What is the structure of the header?

One possibility could be to use readline() to read the header
from the file, before reading the file into R as a dataframe.

Then parse out the Patient ID, and assign it to a variable.
Then read in the file as a dataframe, find out how many records
are in it, make a column of that number of copies of the Patient
ID, and glue it onto the dataframe.

Hoping that helps; but if not come back with more info about
that header!

Of course, once you have the Patient ID in a variable to start
with, perhaps you don't need it as part of the dataframe any more?

Best wishes,
Ted.

> I started up editing the patient's data.frame and figured out I can
> only
> copy and past 1 cell at a time ... but I had 4991 cells so  ... In
> addition,
> I could not find a way to close the editing session while preserving
> the
> changes in the data.frame.
> So I generated a vector with 4991 elements, all recording the same
> patient-ID call is patient_ID.
> Then I used  *cbind(patient.data.frame, patient_ID)*
> to generate a new.patient.data.frame made up of 8 columns, the last
> added
> one recording the patient's ID.
> 
> I have no doubt R experienced users would accomplish the same task in a
> couple of strokes .... HOW ????
> 
> Another question is: how can multiple cells copy&past be performed with
> R
> editor ?
> And how shall I instruct R to save my changes when I close the editing
> session ?
> 
> Thank you very much,
> -- 
> Maura E.M
> 
>       [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 13-Sep-07                                       Time: 21:32:34
------------------------------ XFMail ------------------------------


From Ted.Harding at manchester.ac.uk  Thu Sep 13 22:39:21 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Thu, 13 Sep 2007 21:39:21 +0100 (BST)
Subject: [R] [OOPS] beginner's questions ... sorry
In-Reply-To: <XFMail.070913213237.Ted.Harding@manchester.ac.uk>
Message-ID: <XFMail.070913213921.Ted.Harding@manchester.ac.uk>

OOPS!! When I wrote "use readline()" below, I meant

  use readLInes()

Sorry! For more information see ?readLines

Ted.

On 13-Sep-07 20:32:37, Ted Harding wrote:
> On 13-Sep-07 20:06:35, Maura E Monville wrote:
>> I have 316 files. Each file represents a patient's breathing
>> track (respiratory signal recorded for a variable number of
>> cycles).
>> All files have the same are made up of a header followed by
>> a variable number of records.
>> Each record contains 7 comma separated fields.
>> The patient ID is recorded in the header which is stripped
>> off when reading the file into a R data.frame.
>> Since I need to keep this piece of information, I need to add
>> the 8th column to a patient's data.frame. All elements of
>> such a column store the patient's ID.
>> The problem is trivial. I guess it can be done in a matter of
>> a few seconds.
>> But I (a R novice) could not find an automatic or fast way to
>> do that.
> 
> Hi Maura,
> There could be several ways to do it, but the important thing
> is to know how to "parse out" the Patient ID from the header.
> 
> What is the structure of the header?
> 
> One possibility could be to use readline() to read the header
> from the file, before reading the file into R as a dataframe.
> 
> Then parse out the Patient ID, and assign it to a variable.
> Then read in the file as a dataframe, find out how many records
> are in it, make a column of that number of copies of the Patient
> ID, and glue it onto the dataframe.
> 
> Hoping that helps; but if not come back with more info about
> that header!
> 
> Of course, once you have the Patient ID in a variable to start
> with, perhaps you don't need it as part of the dataframe any more?
> 
> Best wishes,
> Ted.
> 
>> I started up editing the patient's data.frame and figured out I can
>> only
>> copy and past 1 cell at a time ... but I had 4991 cells so  ... In
>> addition,
>> I could not find a way to close the editing session while preserving
>> the
>> changes in the data.frame.
>> So I generated a vector with 4991 elements, all recording the same
>> patient-ID call is patient_ID.
>> Then I used  *cbind(patient.data.frame, patient_ID)*
>> to generate a new.patient.data.frame made up of 8 columns, the last
>> added
>> one recording the patient's ID.
>> 
>> I have no doubt R experienced users would accomplish the same task in
>> a
>> couple of strokes .... HOW ????
>> 
>> Another question is: how can multiple cells copy&past be performed
>> with
>> R
>> editor ?
>> And how shall I instruct R to save my changes when I close the editing
>> session ?
>> 
>> Thank you very much,
>> -- 
>> Maura E.M
>> 
>>       [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 13-Sep-07                                       Time: 21:32:34
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 13-Sep-07                                       Time: 21:39:17
------------------------------ XFMail ------------------------------


From deepayan.sarkar at gmail.com  Thu Sep 13 22:39:45 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 13 Sep 2007 13:39:45 -0700
Subject: [R] Origin label in lattice
In-Reply-To: <c81725600709131037sb2dd739iae6e3bdf66b4647c@mail.gmail.com>
References: <c81725600709131037sb2dd739iae6e3bdf66b4647c@mail.gmail.com>
Message-ID: <eb555e660709131339o3827e3cwdcfcb2f38637c09f@mail.gmail.com>

On 9/13/07, Andrew Smith <andrewsmith81 at gmail.com> wrote:
> I would like to make what seems like a simple addition to a display
> constructed from a call to levelplot -- I want to add a text label
> (which will, in general, depend on the object being plotted, and so
> cannot be hardcoded) to the origin, which has special significance in
> my problem.  The x and y axes always have range (0,1) in my plots, so
> by "origin" I always mean the lower left corner of the plot.  Now, I
> can add text to the inside of the panel using panel.text, but this
> clutters the plot and I find it unsatisfactory.  What I would like is
> to add the label outside of the panel, just below and to the left of
> the lower left corner of the panel.  I've unsuccessfully tried to do
> this using the xscale.components argument, and I'm having trouble
> figuring out which other arguments or functions might be helpful.  I
> would greatly appreciate any advice!

You can either turn off clipping in panels with

trellis.par.set(clip = list(panel = "off"))

or use the axis function:

levelplot(volcano,
          axis = function(side, ...) {
              axis.default(side, ...)
              if (side == "bottom")
                  panel.text(0, 0, lab = "label", adj = c(1, 1))
          })

(axis gets called once for every side in every panel, so you have to
make sure you do it only for one side.)

-Deepayan


From zlu at umich.edu  Thu Sep 13 22:56:03 2007
From: zlu at umich.edu (Zheng Lu)
Date: Thu, 13 Sep 2007 16:56:03 -0400
Subject: [R] help with unit indication when plotting
In-Reply-To: <Pine.GSO.4.56.0709132103580.11544@laurel.few.vu.nl>
References: <20070913144738.rjz7cyn794wk0og8@web.mail.umich.edu>
	<Pine.GSO.4.56.0709132103580.11544@laurel.few.vu.nl>
Message-ID: <20070913165603.8cy9u7dpgkk84k44@web.mail.umich.edu>

Thank you very much! Teachers. one more curiosity is if there is a 
similar good way to this thing in S-PLUS? I am thinking to compare 
these two softwares on several functions. I appreciate.


Lu


Quoting Katharine Mullen <kate at few.vu.nl>:

> see ?plotmath
>
> you want to use "mu" for micro, as in
> plot(1:10, ylab = expression(paste(mu, "M")))
>
> On Thu, 13 Sep 2007, Zheng Lu wrote:
>
>> Dear all:
>>
>> Is there any one could tell me how I can represent Micro-molar as an
>> unit of concentration when I plot with R(S-plus), I don't want write
>> 'uM' from keyboard, I am thinking to write it like in word, in word,
>> people insert symbol for 'u' for uM. Am I clear? Thank you very much
>> for your consideration and help.
>>
>>
>> Lu
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>


From jholtman at gmail.com  Thu Sep 13 23:18:39 2007
From: jholtman at gmail.com (jim holtman)
Date: Thu, 13 Sep 2007 17:18:39 -0400
Subject: [R] Collapsing data frame; aggregate() or better function?
In-Reply-To: <FBF367376AD9E64BB8531D56CA38DA6A01C7CBCA@nflwhex01.nfl.dfo-mpo.ca>
References: <FBF367376AD9E64BB8531D56CA38DA6A01C7CBCA@nflwhex01.nfl.dfo-mpo.ca>
Message-ID: <644e1f320709131418v45506f81i88a2c669d6ef2a97@mail.gmail.com>

The second argument for aggregate is supposed to be a list, so try
(notice the missing comma before "1:8"):

test <- aggregate(lf1.turbot[,c(11, 12, 17:217)], lf1.turbot[1:8],sum)


On 9/13/07, Tobin, Jared <TobinJR at dfo-mpo.gc.ca> wrote:
> Hello r-help,
>
> I am trying to collapse or aggregate 'some' of a data frame.  A very
> simplified version of my data frame looks like:
>
> > tester
>  trip set num sex lfs1 lfs2
> 1  313  15   5   M    2    3
> 2  313  15   3   F    1    2
> 3  313  17   1   M    0    1
> 4  313  17   2   F    1    1
> 5  313  17   1   U    1    0
>
> And I want to omit sex from the picture and just get an addition of num,
> lfs1, and lfs2 for each unique trip/set combination.  Using aggregate()
> works fine here,
>
> > test <- aggregate(tester[,c(3,5:6)], tester[,1:2], sum)
> > test
>  trip set num lfs1 lfs2
> 1  313  15   8    3    5
> 2  313  17   4    2    2
>
> But I'm having trouble getting the same function to work on my actual
> data frame which is considerably larger.
>
> > dim(lf1.turbot)
> [1] 16468   217
> > test <- aggregate(lf1.turbot[,c(11, 12, 17:217)], lf1.turbot[,1:8],
> sum)
> Error in vector("list", prod(extent)) : vector size specified is too
> large
> In addition: Warning messages:
> 1: NAs produced by integer overflow in: ngroup * (as.integer(index) -
> one)
> 2: NAs produced by integer overflow in: group + ngroup *
> (as.integer(index) - one)
> 3: NAs produced by integer overflow in: ngroup * nlevels(index)
>
> I'm guessing that either aggregate() can't handle a data frame of this
> size OR that there is an issue with 'omitting' more than one variable
> (in the same way I've omitted sex in the above example).  Can anyone
> clarify and/or recommend any relatively simple alternative procedure to
> accomplish this?
>
> I plan on trying variants of by() and tapply() tomorrow morning, but I'm
> about to head home for the day.
>
> Thanks,
>
> --
>
> jared tobin, student research assistant
> fisheries and oceans canada
> tobinjr at dfo-mpo.gc.ca
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From cberry at tajo.ucsd.edu  Thu Sep 13 23:19:09 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Thu, 13 Sep 2007 14:19:09 -0700
Subject: [R] statistics - hypothesis testing question
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A834401957A3D@NYWEXMB23.msad.ms.com>
References: <D3AEEDA31E57474B840BEBC25A8A834401957A3B@NYWEXMB23.msad.ms.com>
	<46E9821B.9070503@stats.uwo.ca>
	<D3AEEDA31E57474B840BEBC25A8A834401957A3D@NYWEXMB23.msad.ms.com>
Message-ID: <Pine.LNX.4.64.0709131403061.632@tajo.ucsd.edu>

On Thu, 13 Sep 2007, Leeds, Mark (IED) wrote:

> you're right Duncan. My bad. That was kind of dopey because R squared is
> a statistic in itself.  They aren't nested models because
> the two predictors are different and there are no other predictors.  I'm
> trying  to see whether the model B predictor is "better" than  the
> Model A predictor. I guess how one defines "better" is th real question
> so I apologize for that. Still, any comments, suggestions are welcome.


See

Bradley Efron Comparing non-nested linear models J. of the Amer. Stat'l. 
Assn. 79 791-803 1984, and Google Scholar it to get newer refs.

and

Williams, E. Regression Analysis, Wiley, New York, 1959.

Williams test is remarkably simple.

IIRC, take x1 and x2 as candidate predictors of y

> sx1 <- scale(x1)
> sx2 <- scale(x2)
> anova( lm( y ~ I(sx1+sx2) + I(sx1-sx2) ) )

The second test is the relevant one.

How you roll 24 of these into one omnibus test will depend on the joint 
error structure. Are the errors independent? Are x1 and x2 fixed over all 
24 weeks or do you get fresh observations each time?

HTH,

Chuck

>
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca]
> Sent: Thursday, September 13, 2007 2:32 PM
> To: Leeds, Mark (IED)
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] statistics - hypothesis testing question
>
> On 9/13/2007 2:18 PM, Leeds, Mark (IED) wrote:
>> I estimate two competing simple regression models, A and B where the
>> LHS is the same in both cases but the predictor is different ( I
>> handle the intercept issue based on other postings I have seen ). I
>> estimate the two models on a weekly basis over 24 weeks.
>> So, I end up with 24 RSquaredAs and 24 RsquaredBs, so essentally 2
>> time series of Rsquareds. This doesn't have to be necessarily thought
>> of as a time series problem but, is there a usual way, given the
>> Rsquared data, to test
>>
>> H0 : Rsquared B = Rsquared A versus H1 : Rsquared B > Rsquared A
>>
>> so that I can map the 24 R squared numbers into 1 statistic. Maybe
>> that's somehow equivalent to just running 2 big regressions over the
>> whole 24 weeks and then calculating a statistic from those based on
>> those regressions ?
>
> The question doesn't make sense, if you're using standard notation.  R^2
> is a statistic, not a parameter, so one wouldn't test copies of it for
> equality.
>
> You can probably reframe the question in terms of E(R^2) so the
> statement parses, but then it doesn't really make sense from a subject
> matter point of view:  unless model A is nested within model B, why
> would you ever expect the two fits to explain exactly the same amount of
> variation?
>
> If model A is really a special case of model B, then you're back to the
> standard hypothesis testing situation, but repeated 24 times.  There's a
> lot of literature on how to handle such multiple testing problems,
> depending on what sort of alternatives you want to detect.  (E.g. do you
> think all 24 cases will be identical, or is it possible that 23 will
> match but one doesn't?)
>
> Duncan Murdoch
>
>>
>> I broke things up into 24 weeks because I was thinking that the
>> stability of the performance difference of the two models could be
>> examined over time. Essentially these are simple time series
>> regressions X_t = B*X_t-1 + epsilon so I always need to consider
>> whether any type of behavior is stable.  But now I am thinking that,
>> if I just want one overall number,  then maybe I should be considering
>
>> all the data simultaneously ?
>>
>> In a nutshell,  I am looking for any suggestions on the best way to
>> test whether Model B is better than Model A where
>>
>> Model A :  X_t = Beta*X_t-1 + epsilon
>>
>> Model B :  X_t = Betastar*Xstar_t-1 + epsilonstar
>>
>>
>> Thanks fo your help.
>> --------------------------------------------------------
>>
>> This is not an offer (or solicitation of an offer) to
>> buy/se...{{dropped}}
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> --------------------------------------------------------
>
> This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From busorafn at juno.com  Thu Sep 13 23:21:10 2007
From: busorafn at juno.com (Eric R)
Date: Thu, 13 Sep 2007 14:21:10 -0700 (PDT)
Subject: [R] Export Step Function Coefficients to Spreadsheet or Text File
Message-ID: <12663777.post@talk.nabble.com>


Hello, 

After I use the lm() function to perform a multiple linear regression, and
then use the step function to eliminate variables that predict the weakest,
I need to export the final equation to a spreadsheet or a text file. Below
is some sample code. In the end I want to export the coefficients to a
spreadsheet. Will you please direct me to the appropriate syntax? Thanks for
your time, --Eric

x <- read.csv('C:/path/*.csv', comment.char = "", nrows = 99, header = TRUE,
row.names = 1)

w <- lm(d ~ x1 + x2 + x3 + x4 + 1)

step(w)

Coefficients:
(Intercept)    x1          x2          x3       x4  
  4.834e-04    4.892e-01    4.698e-02    4.206e-05   -8.806e-03

write.csv(w, file = 'C:/path/*.csv', append = TRUE)

The error I get is:
Error in as.data.frame.default(x[[i]], optional = TRUE) : 
        cannot coerce class "lm" into a data.frame
-- 
View this message in context: http://www.nabble.com/Export-Step-Function-Coefficients-to-Spreadsheet-or-Text-File-tf4438516.html#a12663777
Sent from the R help mailing list archive at Nabble.com.


From jonathan-beard at uiowa.edu  Thu Sep 13 23:24:48 2007
From: jonathan-beard at uiowa.edu (VTLT1999)
Date: Thu, 13 Sep 2007 14:24:48 -0700 (PDT)
Subject: [R] Subset Quirk?
Message-ID: <12663959.post@talk.nabble.com>


Hello All,

I am trying to subset a matrix using subset() and it works fine when I use
matrix notation, but doesn't work when I use established column names. 
Sample code is below:

library(mvtnorm)
library(sm)
library(ltm)
library(irtoys)

k<- 100
set.seed(271828)
t <-
rmvnorm(n=k,mean=c(-1,0,1),sigma=matrix(c(1,.8,.5,.8,1,.8,.5,.8,1),3,3)) 

colMeans(t)
var(t)
pairs(t)

#tview <-edit(t)

t1<-as.matrix(t[,1])
t2<-as.matrix(t[,2])
t3<-as.matrix(t[,3])

# write.table(t, file = "c:/ability.dat", sep = " ", row.names=FALSE,
col.names=FALSE)

N<- nrow(t)
id <- as.matrix(seq(001,N,1))

assign <- matrix(0,N,6)
assign[,1:3] <- t[,1:3]
  for (i in 1:N)
  {
    if (t[i,1] < 7) 
      assign[i,4]=1
    else 
      assign[i,4]=0
      
    if (t[i,1] < -1)
      assign[i,5]=2
    else
      assign[i,5]=3
      
    if (t[i,2] < 0)
      assign[i,6]=4
    else
      assign[i,6]=5
  }

group <- cbind(id,assign)
colnames(group) <-c("ID","T1","T2","T3","G1","G2","G3")

#  This command works fine...

g2 <- subset(group,group[,6]==2)

#  This command does not work...
g2 <- subset(group,G2==2)


Any thoughts?  

Oh, so Petr and Uwe don't cry:  R 2.5.1 on XP (SP2).






-- 
View this message in context: http://www.nabble.com/Subset-Quirk--tf4438572.html#a12663959
Sent from the R help mailing list archive at Nabble.com.


From deepayan.sarkar at gmail.com  Thu Sep 13 23:32:09 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 13 Sep 2007 14:32:09 -0700
Subject: [R] minimize white space around lattice plot
In-Reply-To: <1189669443.6641.8.camel@stealth.kraft.de>
References: <1189669443.6641.8.camel@stealth.kraft.de>
Message-ID: <eb555e660709131432u11d77cb1h428c8196fc329a5@mail.gmail.com>

On 9/13/07, Sebastian Weber <sebastian.weber at physik.tu-darmstadt.de> wrote:
> Dear list,
>
> I'm trying to produce a plot via xyplot with minimal sourounding white
> space. However, I cannot find the options in xyplot, ps.options or
> wherever which prevents lattice from drawing quite some white space
> around my plot. However, this is quite a problem for me as I want to
> produce an inset plot inside another lattice-plot. I'm using the panel
> function to open a viewport and print the inset plot within the actual
> plot. The problem now is, that there is lots of sourounding white space
> around my inner plot. Here is an example:
>
> panel.inset <- function(...,
>                         inset,
>                         drawRect=TRUE,
>                         ixpos=unit(0, "mm"), iypos=unit(1, "npc"),
>                         ijust=c("left","top"),
>                         iwidth=unit(0.7, "npc"), iheight=unit(0.5,
> "npc")) {
>   ## open our viewport ...
>   pushViewport(viewport(x=ixpos, y=iypos, width=iwidth, height=iheight,
> just=ijust, name="inset"))
>
>   if(drawRect)
>     grid.rect(gp=gpar(lwd=1,col="black"))
>
>   ## ... and place the other plot inside there
>   print(inset, newpage=FALSE, prefix="insetPlot")
>
>   upViewport()
>
>   ## draw the actual plot
>   panel.xyplot(...)
>
>   ## why is this neccessary?? Otherwise I get no lines for the axis ...
>   grid.rect(gp=gpar())
> }
>
> x<-0:10
> y<-x^4
>
>
> insetPlot <- xyplot(y ~ x, scales=list(log=T), main=NULL, aspect="fill")
> xyplot(y ~ x, panel="panel.inset", inset=insetPlot)
>
> Thank you very much for any input!

See

str(trellis.par.get("layout.widths"))
str(trellis.par.get("layout.heights"))
?trellis.par.set
?xyplot (the entry for 'par.settings')

-Deepayan


From p.dalgaard at biostat.ku.dk  Thu Sep 13 23:57:39 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 13 Sep 2007 23:57:39 +0200
Subject: [R] Subset Quirk?
In-Reply-To: <12663959.post@talk.nabble.com>
References: <12663959.post@talk.nabble.com>
Message-ID: <46E9B253.7090307@biostat.ku.dk>

VTLT1999 wrote:
> Hello All,
>
> I am trying to subset a matrix using subset() and it works fine when I use
> matrix notation, but doesn't work when I use established column names. 
> Sample code is below:
>
> library(mvtnorm)
> library(sm)
> library(ltm)
> library(irtoys)
>
> k<- 100
> set.seed(271828)
> t <-
> rmvnorm(n=k,mean=c(-1,0,1),sigma=matrix(c(1,.8,.5,.8,1,.8,.5,.8,1),3,3)) 
>
> colMeans(t)
> var(t)
> pairs(t)
>
> #tview <-edit(t)
>
> t1<-as.matrix(t[,1])
> t2<-as.matrix(t[,2])
> t3<-as.matrix(t[,3])
>
> # write.table(t, file = "c:/ability.dat", sep = " ", row.names=FALSE,
> col.names=FALSE)
>
> N<- nrow(t)
> id <- as.matrix(seq(001,N,1))
>
> assign <- matrix(0,N,6)
> assign[,1:3] <- t[,1:3]
>   for (i in 1:N)
>   {
>     if (t[i,1] < 7) 
>       assign[i,4]=1
>     else 
>       assign[i,4]=0
>       
>     if (t[i,1] < -1)
>       assign[i,5]=2
>     else
>       assign[i,5]=3
>       
>     if (t[i,2] < 0)
>       assign[i,6]=4
>     else
>       assign[i,6]=5
>   }
>
> group <- cbind(id,assign)
> colnames(group) <-c("ID","T1","T2","T3","G1","G2","G3")
>
> #  This command works fine...
>
> g2 <- subset(group,group[,6]==2)
>
> #  This command does not work...
> g2 <- subset(group,G2==2)
>
>
> Any thoughts?  
>
> Oh, so Petr and Uwe don't cry:  R 2.5.1 on XP (SP2).
>
>   
Well, subset() has a method for data frames and another one for 
matrices. The former does something that the latter cannot do (not 
easily, anyways), namely evaluate the subset expression in the data 
frame. The same concept does not exist for matrices.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From zlu at umich.edu  Fri Sep 14 00:26:10 2007
From: zlu at umich.edu (Zheng Lu)
Date: Thu, 13 Sep 2007 18:26:10 -0400
Subject: [R] Looking for instructions for several questions with R
Message-ID: <20070913182610.ng689dd3c4kk84ow@web.mail.umich.edu>

Dear all:

when I add legend into the upper right concer of the plot region, it 
always has a square region in which the text is, how to get rid of that 
square region, I just want pure text.

For the log-scale on y axis, they appear as 1e-02, 1e+00 and 1e+02, how 
to change to 0.01, 1, 100.

how to make label on axes bigger including number and text?

I appreciate your great consideration and help.

Lu


From rsb at wsu.edu  Fri Sep 14 00:33:21 2007
From: rsb at wsu.edu (Bricklemyer, Ross S)
Date: Thu, 13 Sep 2007 15:33:21 -0700
Subject: [R] grouping data by a portion of the row name
Message-ID: <2FC987BC0B90B24786CAF43DD3F5719CE82DCB@CRU105.cahe.ad.wsu.edu>

I am attempting to write a routine where I can run PAM (partition around mediods) on a dataset containing multiple soil cores and PCA spectral data from several depths per core.  I want to run PAM on each individual core, so I need to group the data by core to run the analysis.  Below is an example of my data structure:

Lab.id	PC1	PC2	PC3
MAT057.2.5	2.438454966	-1.011182986	-3.040881377
MAT057.7.5	10.69120648	4.767694892		-1.719466898
MAT057.12.5	8.215852171	4.645793327		0.974020242
MAT057.17.5	10.00422215	3.516213164		2.586742695
MAT057.22.5	18.49165113	5.143031557		0.472636009
MAT057.27.5	18.31255522	4.255319595		0.802902692
MAT057.35	11.75818601	-0.325388031	3.445673092
MAT057.45	6.043984786	-3.297325975	3.075221644

The MAT057 is the core code and the values following the period refer to the sampling depths.  There are many cores in the dataset and I want to automate the analysis so that it will grab data with the same core code and run PAM.  Any ideas on what the R code would look like for that?

Ross

*******************************************************************
Ross Bricklemyer
Dept. of Crop and Soil Sciences
Washington State University
291D Johnson Hall
PO Box 646420
Pullman, WA 99164-6420
Work: 509.335.3661
Cell/Home: 406.570.8576
Fax: 509.335.8674
Email: rsb at wsu.edu

?


From dmca at ucla.edu  Fri Sep 14 00:38:36 2007
From: dmca at ucla.edu (D L McArthur)
Date: Thu, 13 Sep 2007 22:38:36 +0000 (UTC)
Subject: [R] Export Step Function Coefficients to Spreadsheet or Text
	File
References: <12663777.post@talk.nabble.com>
Message-ID: <loom.20070914T003445-810@post.gmane.org>

Eric R <busorafn <at> juno.com> writes:
>... I want to export the coefficients to a spreadsheet....

names(w)
write.csv (w$coefficients, file=...)

-- D L McArthur, UCLA Sch of Medicine, dmca <at> ucla.edu


From p.dalgaard at biostat.ku.dk  Fri Sep 14 00:47:46 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 14 Sep 2007 00:47:46 +0200
Subject: [R] grouping data by a portion of the row name
In-Reply-To: <2FC987BC0B90B24786CAF43DD3F5719CE82DCB@CRU105.cahe.ad.wsu.edu>
References: <2FC987BC0B90B24786CAF43DD3F5719CE82DCB@CRU105.cahe.ad.wsu.edu>
Message-ID: <46E9BE12.9050600@biostat.ku.dk>

Bricklemyer, Ross S wrote:
> I am attempting to write a routine where I can run PAM (partition around mediods) on a dataset containing multiple soil cores and PCA spectral data from several depths per core.  I want to run PAM on each individual core, so I need to group the data by core to run the analysis.  Below is an example of my data structure:
>
> Lab.id	PC1	PC2	PC3
> MAT057.2.5	2.438454966	-1.011182986	-3.040881377
> MAT057.7.5	10.69120648	4.767694892		-1.719466898
> MAT057.12.5	8.215852171	4.645793327		0.974020242
> MAT057.17.5	10.00422215	3.516213164		2.586742695
> MAT057.22.5	18.49165113	5.143031557		0.472636009
> MAT057.27.5	18.31255522	4.255319595		0.802902692
> MAT057.35	11.75818601	-0.325388031	3.445673092
> MAT057.45	6.043984786	-3.297325975	3.075221644
>
> The MAT057 is the core code and the values following the period refer to the sampling depths.  There are many cores in the dataset and I want to automate the analysis so that it will grab data with the same core code and run PAM.  Any ideas on what the R code would look like for that?
>
> Ross
>   
Looks like these aren't really row names but a variable called Lab.id.

Look into things like

sub("\\..*$",  "",  Lab.id)

or maybe

sapply(strsplit(Lab.id, "\\."), "[[", 1)

(if Lab.id is a factor, you need first to transform using as.character 
in the 2nd version)
> *******************************************************************
> Ross Bricklemyer
> Dept. of Crop and Soil Sciences
> Washington State University
> 291D Johnson Hall
> PO Box 646420
> Pullman, WA 99164-6420
> Work: 509.335.3661
> Cell/Home: 406.570.8576
> Fax: 509.335.8674
> Email: rsb at wsu.edu
>
>  
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From murdoch at stats.uwo.ca  Fri Sep 14 01:17:53 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 13 Sep 2007 19:17:53 -0400
Subject: [R] Looking for instructions for several questions with R
In-Reply-To: <20070913182610.ng689dd3c4kk84ow@web.mail.umich.edu>
References: <20070913182610.ng689dd3c4kk84ow@web.mail.umich.edu>
Message-ID: <46E9C521.2010404@stats.uwo.ca>

On 13/09/2007 6:26 PM, Zheng Lu wrote:
> Dear all:
> 
> when I add legend into the upper right concer of the plot region, it 
> always has a square region in which the text is, how to get rid of that 
> square region, I just want pure text.

Use bty="n" in the call to legend.

> For the log-scale on y axis, they appear as 1e-02, 1e+00 and 1e+02, how 
> to change to 0.01, 1, 100.

Set axes=FALSE when you do the original plot, then use the axis() 
function to draw the axes (and maybe box() to draw the box).  It allows 
you to put anything you want as tick labels...
> 
> how to make label on axes bigger including number and text?

... and allows the size of the text to be changed.

Duncan Murdoch
> 
> I appreciate your great consideration and help.
> 
> Lu
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kamushkina at gmail.com  Thu Sep 13 07:05:35 2007
From: kamushkina at gmail.com (Olga K. Kamneva)
Date: Wed, 12 Sep 2007 23:05:35 -0600
Subject: [R] Call C code from R
Message-ID: <d1419f550709122205k6d61036dg6fb9ae5bdf46e27b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070912/3028cbe4/attachment.pl 

From S.Ellison at lgc.co.uk  Fri Sep 14 02:50:31 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Fri, 14 Sep 2007 01:50:31 +0100
Subject: [R] statistics - hypothesis testing question
Message-ID: <s6e9e8fa.026@tedmail2.lgc.co.uk>

I may be miles off base, but could this be treated as a random-effects model, with the regression predictors as random effects grouped by week? And if so, could each set form a single lme() model, allowing you to compare the models via AIC's for 'quality' and anova for significance of the difference...? (After reading Pinheiro and Bates of course.. and not all mixed effects models can be compared directly, particularly using REML, if I read it correctly).



>>> "Greg Snow" <Greg.Snow at intermountainmail.org> 09/13/07 8:08 PM >>>

> I estimate two competing simple regression models, A and B 
> where the LHS is the same in both cases but the predictor is 
> different ( I handle the intercept issue based on other 
> postings I have seen ). I estimate the two models on a weekly 
> basis over 24 weeks. 
> So, I end up with 24 RSquaredAs and 24 RsquaredBs, so 
> essentally 2 time series of Rsquareds. This doesn't have to 
> be necessarily thought of as a time series problem but, is 
> there a usual way, given the Rsquared data, to test 
> 
> H0 : Rsquared B = Rsquared A versus H1 : Rsquared B > Rsquared A 
> 
> so that I can map the 24 R squared numbers into 1 statistic. 
> Maybe that's somehow equivalent to just running 2 big 
> regressions over the whole 24 weeks and then calculating a 
> statistic from those based on those regressions ?
> 
> I broke things up into 24 weeks because I was thinking that 
> the stability of the performance difference of the two models 
> could be examined over time. Essentially these are simple 
> time series regressions X_t = B*X_t-1 + epsilon so I always 
> need to consider whether any type of behavior is stable.  But 
> now I am thinking that,  if I just want one overall number,  
> then maybe I should be considering all the data simultaneously ? 
> 
> In a nutshell,  I am looking for any suggestions on the best 
> way to test whether Model B is better than Model A where
> 
> Model A :  X_t = Beta*X_t-1 + epsilon
> 
> Model B :  X_t = Betastar*Xstar_t-1 + epsilonstar
> 
> 
> Thanks fo your help.
> --------------------------------------------------------
> 
> This is not an offer (or solicitation of an offer) to 
> buy/se...{{dropped}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

*******************************************************************
This email and any attachments are confidential. Any use, co...{{dropped}}


From epistat at gmail.com  Fri Sep 14 05:41:18 2007
From: epistat at gmail.com (zhijie zhang)
Date: Fri, 14 Sep 2007 11:41:18 +0800
Subject: [R] Calculate the angles for a point dataset?
Message-ID: <2fc17e30709132041w68c6b8e6s997da4cf3d1c48c6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070914/b86c89fb/attachment.pl 

From busorafn at juno.com  Fri Sep 14 06:18:14 2007
From: busorafn at juno.com (Eric R)
Date: Thu, 13 Sep 2007 21:18:14 -0700 (PDT)
Subject: [R] Export Step Function Coefficients to Spreadsheet or Text
 File
In-Reply-To: <loom.20070914T003445-810@post.gmane.org>
References: <12663777.post@talk.nabble.com>
	<loom.20070914T003445-810@post.gmane.org>
Message-ID: <12668227.post@talk.nabble.com>


Thanks, this works great! --Eric



D L McArthur wrote:
> 
> Eric R <busorafn <at> juno.com> writes:
>>... I want to export the coefficients to a spreadsheet....
> 
> names(w)
> write.csv (w$coefficients, file=...)
> 
> -- D L McArthur, UCLA Sch of Medicine, dmca <at> ucla.edu
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Export-Step-Function-Coefficients-to-Spreadsheet-or-Text-File-tf4438516.html#a12668227
Sent from the R help mailing list archive at Nabble.com.


From r.turner at auckland.ac.nz  Fri Sep 14 06:26:07 2007
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 14 Sep 2007 16:26:07 +1200
Subject: [R] Calculate the angles for a point dataset?
In-Reply-To: <2fc17e30709132041w68c6b8e6s997da4cf3d1c48c6@mail.gmail.com>
References: <2fc17e30709132041w68c6b8e6s997da4cf3d1c48c6@mail.gmail.com>
Message-ID: <BD1FF0B0-C34D-43FD-AAC3-D2EB232CC8CA@auckland.ac.nz>


On 14/09/2007, at 3:41 PM, zhijie zhang wrote:

> Dear Rusers,
>   I'd like to take the cases of cancer of the larynx in chorley 
> (spatstat) to
> explain my question.
>   I want to join the points of cancer of the larynx with the disused
> industrial incinerator to generate lines, and then calculate the  
> angles of
> these line comparing the horizontal line?
>   How can i get it? It seems to be difficult to get the angles
>   Thanks a lot.

?atan2

######################################################################
Attention:\ This e-mail message is privileged and confidenti...{{dropped}}


From birgit.lemcke at systbot.uzh.ch  Fri Sep 14 09:40:26 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Fri, 14 Sep 2007 09:40:26 +0200
Subject: [R] t.test() with missing values
In-Reply-To: <46E96A73.4090803@biostat.ku.dk>
References: <D3E2394B-665D-406B-B02E-DDD919C5365C@systbot.uzh.ch>
	<46E96A73.4090803@biostat.ku.dk>
Message-ID: <2D374B9C-7B99-4BFD-B715-CF752A894892@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070914/f8cb29f6/attachment.pl 

From alfreale74 at gmail.com  Fri Sep 14 10:08:19 2007
From: alfreale74 at gmail.com (Alfredo Alessandrini)
Date: Fri, 14 Sep 2007 10:08:19 +0200
Subject: [R] replace NA value with 0
Message-ID: <d2c05c5a0709140108jdd6b200w25bfa40ce42b1c19@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070914/a5e8a315/attachment.pl 

From P.Dalgaard at biostat.ku.dk  Fri Sep 14 10:26:16 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 14 Sep 2007 10:26:16 +0200
Subject: [R] t.test() with missing values
In-Reply-To: <2D374B9C-7B99-4BFD-B715-CF752A894892@systbot.uzh.ch>
References: <D3E2394B-665D-406B-B02E-DDD919C5365C@systbot.uzh.ch>
	<46E96A73.4090803@biostat.ku.dk>
	<2D374B9C-7B99-4BFD-B715-CF752A894892@systbot.uzh.ch>
Message-ID: <46EA45A8.5060907@biostat.ku.dk>

Birgit Lemcke wrote:
> Thanks for your answer.
>
> First I will show you both vectors:
>   [...]
>
> I tried this (complete.cases(Fem66, Mal66)) and you are right, it
> gives me back:
>
> (complete.cases(Fem66, Mal66))
>   [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> FALSE FALSE FALSE
[....]
> I thought the t.test is a comparison of means and why can I not use it
> if I have a lot of missing values. Is the reason that I use the paired
> option?
> What is different in the calculation using paired?
>
> Ah ja this seems to be the case:
>
> T66<-t.test(Mal66, Fem66, alternative= "two.sided")
> > T66
>
>
> Welch Two Sample t-test
>
> data:  Mal66 and Fem66
> t = -0.4881, df = 49.229, p-value = 0.6277
> alternative hypothesis: true difference in means is not equal to 0
> 95 percent confidence interval:
> -1.4637045  0.8915906
> sample estimates:
> mean of x mean of y
> 5.096552  5.382609
>
> I use the paired option because may plants (male and female) belong to
> the same species (and because may boss said that I have to use paired
> in this case)
Don't do what your boss says, do what is right! (It might of course be
the same thing). So pair #1 is one species, pair #2 another species, up
to 331 different species?

> So what can I do now to solve my problem?
>
> Do you think I should not use paired=TRUE?
You *can* only use it when you have pairs, and you must do it then, to
correct for intra-pair correlation. The drawback is that it looks only
at complete pairs, throwing away all the singlets. It is possible to
recover the information from the singlets , basically by combining a
paired test for the pairs and an unpaired one for the singlets. (Someone
must have written this down, but I'm afraid I don't have a nice reference).

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From csardi at rmki.kfki.hu  Fri Sep 14 10:27:03 2007
From: csardi at rmki.kfki.hu (Gabor Csardi)
Date: Fri, 14 Sep 2007 10:27:03 +0200
Subject: [R] replace NA value with 0
In-Reply-To: <d2c05c5a0709140108jdd6b200w25bfa40ce42b1c19@mail.gmail.com>
References: <d2c05c5a0709140108jdd6b200w25bfa40ce42b1c19@mail.gmail.com>
Message-ID: <20070914082703.GB5532@localdomain>

x[ is.na(x) ] <- 0

should work in most cases i think.

Gabor

On Fri, Sep 14, 2007 at 10:08:19AM +0200, Alfredo Alessandrini wrote:
> Hi,
> 
> how can I replace NA value with 0:
> 
> 1991 217  119 103 109 137 202 283 240 146  NA
> 1992 270  174 149 144 166 239 278 237 275  NA
> 1993 146  111 104  89  98 131 153 148 175  NA
> 1994 177  123 146 124 121 200 266 191 240 106
> 1995 145   98  95  89  95 130 183 161 164 129
> 1996 145   98  89  90  93 138 158 131 161 161
> 
> 1991 217  119 103 109 137 202 283 240 146  0
> 1992 270  174 149 144 166 239 278 237 275  0
> 1993 146  111 104  89  98 131 153 148 175  0
> 1994 177  123 146 124 121 200 266 191 240 106
> 1995 145   98  95  89  95 130 183 161 164 129
> 1996 145   98  89  90  93 138 158 131 161 161
> 
> 
> Best wishes,
> 
> Alfredo
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK


From r.hankin at noc.soton.ac.uk  Fri Sep 14 10:34:18 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Fri, 14 Sep 2007 09:34:18 +0100
Subject: [R] Sweave: tables vs matrices
Message-ID: <F05CE336-87C3-4E63-979F-D427EB0EBD6F@noc.soton.ac.uk>

Hello everyone


I am preparing a document using Sweave in which I want my matrices
to appear as tables.  I am running into problems because as my
Rnw files stand, I have to  change table entries twice, once for
the matrix and once for the typeset table.

I have lots of material like the following.  How can I arrange
my Rnw file so that  I only have to change one set of figures
when my numbers change?

One reason I prefer tables here is that the NA entries
appear as "-" in the table, but as "NA" in the Schunk.
Is there a way to make the Schunk  typeset NAs
as minuses?



\begin{table}
\centering
\begin{tabular}{|cccc|c|}\hline
\multicolumn{4}{|c|}{brand}&\\ \hline
A&B&C&D&total\\ \hline
2       & 3      &  4       & 1    & 10   \\
0       & 5       & 7       & -    & 12   \\
3       & 7       & -       & 4    & 14   \\
2       & -       & -       & 2    &  4    \\ \hline
7&15&11&7&40\\ \hline
\end{tabular}
\caption{snipped caption}
\end{table}


<<>>=
jj <- matrix(c(2,  3,  4, 1,
                0,  5,  7, NA,
                3,  7, NA, 4,
                2, NA, NA, 2
                ),byrow=TRUE,nrow=4)
jj <- rbind(jj,apply(jj,2,sum,na.rm=TRUE))
jj <- cbind(jj,apply(jj,1,sum,na.rm=TRUE))
jj
@








--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From Bernhard_Pfaff at fra.invesco.com  Fri Sep 14 10:41:49 2007
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Fri, 14 Sep 2007 09:41:49 +0100
Subject: [R] statistics - hypothesis testing question
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A834401957A3B@NYWEXMB23.msad.ms.com>
References: <D3AEEDA31E57474B840BEBC25A8A834401957A3B@NYWEXMB23.msad.ms.com>
Message-ID: <B89F0CE41D45644A97CCC93DF548C1C30B0F4CA1@GBHENXMB02.corp.amvescap.net>

Hello Mark,

in addition and complementing the already provided answers to your
question. You want to consider the J-test, too. For an outline and the
pitfalls of this test, see:

http://citeseer.ist.psu.edu/cache/papers/cs/24954/http:zSzzSzwww.econ.qu
eensu.cazSzfacultyzSzdavidsonzSzbj4-noam.pdf/bootstrap-j-tests-of.pdf


Best,
Bernhard 

>
>I estimate two competing simple regression models, A and B 
>where the LHS
>is the same in both cases but the predictor is different (
>I handle the intercept issue based on other postings I have seen ). I
>estimate the two models on a weekly basis over 24 weeks. 
>So, I end up with 24 RSquaredAs and 24 RsquaredBs, so essentally 2 time
>series of Rsquareds. This doesn't have to be necessarily 
>thought of as a
>time series problem but, is there a usual way, given the Rsquared data,
>to test 
>
>H0 : Rsquared B = Rsquared A versus H1 : Rsquared B > Rsquared A 
>
>so that I can map the 24 R squared numbers into 1 statistic. Maybe
>that's somehow equivalent to just running 2 big regressions over the
>whole 24 weeks and then calculating a statistic from those based on
>those regressions ?
>
>I broke things up into 24 weeks because I was thinking that the
>stability of the performance difference of the two models could be 
>examined over time. Essentially these are simple time series 
>regressions
>X_t = B*X_t-1 + epsilon so I always need to consider
>whether any type of behavior is stable.  But now I am thinking 
>that,  if
>I just want one overall number,  then maybe I should be considering all
>the data simultaneously ? 
>
>In a nutshell,  I am looking for any suggestions on the best 
>way to test
>whether Model B is better than Model A where
>
>Model A :  X_t = Beta*X_t-1 + epsilon
>
>Model B :  X_t = Betastar*Xstar_t-1 + epsilonstar
>
>
>Thanks fo your help.
>--------------------------------------------------------
>
>This is not an offer (or solicitation of an offer) to 
>buy/se...{{dropped}}
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide 
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
*****************************************************************
Confidentiality Note: The information contained in this mess...{{dropped}}


From birgit.lemcke at systbot.uzh.ch  Fri Sep 14 10:43:29 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Fri, 14 Sep 2007 10:43:29 +0200
Subject: [R] t.test() with missing values
In-Reply-To: <46EA45A8.5060907@biostat.ku.dk>
References: <D3E2394B-665D-406B-B02E-DDD919C5365C@systbot.uzh.ch>
	<46E96A73.4090803@biostat.ku.dk>
	<2D374B9C-7B99-4BFD-B715-CF752A894892@systbot.uzh.ch>
	<46EA45A8.5060907@biostat.ku.dk>
Message-ID: <278E6BF1-0C3B-4B57-8372-BF267EF0D386@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070914/ef6a2433/attachment.pl 

From S.Ellison at lgc.co.uk  Fri Sep 14 10:46:57 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Fri, 14 Sep 2007 09:46:57 +0100
Subject: [R] replace NA value with 0
Message-ID: <s6ea5899.017@tedmail2.lgc.co.uk>



>>> Gabor Csardi <csardi at rmki.kfki.hu> 14/09/2007 09:27:03 >>>
>x[ is.na(x) ] <- 0
>
>should work in most cases i think.

... only you probably shouldn't be doing that at all. Words like 'bias' spring to mind...

Woudn't it be better to accept the NA's and find methods that handle them as genuinely missing. R is usually quite good at that.

On Fri, Sep 14, 2007 at 10:08:19AM +0200, Alfredo Alessandrini wrote:
> Hi,
> 
> how can I replace NA value with 0:


*******************************************************************
This email and any attachments are confidential. Any use, co...{{dropped}}


From gavin.simpson at ucl.ac.uk  Fri Sep 14 10:52:03 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 14 Sep 2007 09:52:03 +0100
Subject: [R] Sweave: tables vs matrices
In-Reply-To: <F05CE336-87C3-4E63-979F-D427EB0EBD6F@noc.soton.ac.uk>
References: <F05CE336-87C3-4E63-979F-D427EB0EBD6F@noc.soton.ac.uk>
Message-ID: <1189759923.2943.6.camel@graptoleberis.geog.ucl.ac.uk>

On Fri, 2007-09-14 at 09:34 +0100, Robin Hankin wrote:
> Hello everyone
> 
> 
> I am preparing a document using Sweave in which I want my matrices
> to appear as tables.  I am running into problems because as my
> Rnw files stand, I have to  change table entries twice, once for
> the matrix and once for the typeset table.
> 
> I have lots of material like the following.  How can I arrange
> my Rnw file so that  I only have to change one set of figures
> when my numbers change?
> 
> One reason I prefer tables here is that the NA entries
> appear as "-" in the table, but as "NA" in the Schunk.
> Is there a way to make the Schunk  typeset NAs
> as minuses?

See ?print.default and its argument na.print:

> print.default(jj, na.print = "-")
     [,1] [,2] [,3] [,4] [,5]
[1,]    2    3    4    1   10
[2,]    0    5    7    -   12
[3,]    3    7    -    4   14
[4,]    2    -    -    2    4
[5,]    7   15   11    7   40

Is that what you meant? It still prints the [1,] bits...

HTH

G

> 
> 
> 
> \begin{table}
> \centering
> \begin{tabular}{|cccc|c|}\hline
> \multicolumn{4}{|c|}{brand}&\\ \hline
> A&B&C&D&total\\ \hline
> 2       & 3      &  4       & 1    & 10   \\
> 0       & 5       & 7       & -    & 12   \\
> 3       & 7       & -       & 4    & 14   \\
> 2       & -       & -       & 2    &  4    \\ \hline
> 7&15&11&7&40\\ \hline
> \end{tabular}
> \caption{snipped caption}
> \end{table}
> 
> 
> <<>>=
> jj <- matrix(c(2,  3,  4, 1,
>                 0,  5,  7, NA,
>                 3,  7, NA, 4,
>                 2, NA, NA, 2
>                 ),byrow=TRUE,nrow=4)
> jj <- rbind(jj,apply(jj,2,sum,na.rm=TRUE))
> jj <- cbind(jj,apply(jj,1,sum,na.rm=TRUE))
> jj
> @
> 
> 
> 
> 
> 
> 
> 
> 
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>   tel  023-8059-7743
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From csardi at rmki.kfki.hu  Fri Sep 14 10:56:05 2007
From: csardi at rmki.kfki.hu (Gabor Csardi)
Date: Fri, 14 Sep 2007 10:56:05 +0200
Subject: [R] replace NA value with 0
In-Reply-To: <s6ea5899.017@tedmail2.lgc.co.uk>
References: <s6ea5899.017@tedmail2.lgc.co.uk>
Message-ID: <20070914085605.GD5532@localdomain>

On Fri, Sep 14, 2007 at 09:46:57AM +0100, S Ellison wrote:
> 
> 
> >>> Gabor Csardi <csardi at rmki.kfki.hu> 14/09/2007 09:27:03 >>>
> >x[ is.na(x) ] <- 0
> >
> >should work in most cases i think.
> 
> ... only you probably shouldn't be doing that at all. Words like 'bias' spring to mind...
> 
> Woudn't it be better to accept the NA's and find methods that handle them as genuinely missing. R is usually quite good at that.

Although in some cases the proper handling of NA values is to treat 
them az zeros.... 

I like this list because if you ask a question, 
they don't only solve it immediately (in five different ways), but they
persuade you that what you're trying to do is actually 
incorrect/stupid/uninteresting or your problem just makes no sense at all.
:)

Gabor

> On Fri, Sep 14, 2007 at 10:08:19AM +0200, Alfredo Alessandrini wrote:
> > Hi,
> > 
> > how can I replace NA value with 0:
> 
> 
> *******************************************************************
> This email and any attachments are confidential. Any use, co...{{dropped}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK


From S.Ellison at lgc.co.uk  Fri Sep 14 11:22:36 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Fri, 14 Sep 2007 10:22:36 +0100
Subject: [R] replace NA value with 0
Message-ID: <s6ea60f6.077@tedmail2.lgc.co.uk>



>>On Fri, Sep 14, 2007 at 09:46:57AM +0100, S Ellison wrote:
>> 
>>... only you probably shouldn't be doing that at all. Words like 'bias' spring to mind...
>> 
>> Woudn't it be better to accept the NA's and find methods that handle them as genuinely missing. 
>> R is usually quite good at that.

And Gabor Csardi <csardi at rmki.kfki.hu> replied 

>Although in some cases the proper handling of NA values is to treat 
>them az zeros.... 
Yup. And sometimes not...

>I like this list because if you ask a question, 
>they don't only solve it immediately (in five different ways), but they
>persuade you that what you're trying to do is actually 
>incorrect/stupid/uninteresting or your problem just makes no sense at all.
>:)

Being a chemist, I have to confess that I can't always tell that what I'm about to attempt is barking, trivial, uninteresting or better done a completely different way; myself, I'd rather be warned too often than left to dig my own pit and fall into it ... 

On NA's vs zero, I usually have the reverse problem in my corner of the world; folk will often call nondetects 'missing', which is also often a silly thing to do; nondetect means 'I looked and it was too low to see' but NA means 'I didn't look'. All that leaves me a bit nervous about replacing NA with 0 and vice versa ... hence the knee-jerk. Apologies if I'm teaching egg-sucking to an expert. 

S

*******************************************************************
This email and any attachments are confidential. Any use, co...{{dropped}}


From csardi at rmki.kfki.hu  Fri Sep 14 11:28:33 2007
From: csardi at rmki.kfki.hu (Gabor Csardi)
Date: Fri, 14 Sep 2007 11:28:33 +0200
Subject: [R] replace NA value with 0
In-Reply-To: <s6ea60f6.076@tedmail2.lgc.co.uk>
References: <s6ea60f6.076@tedmail2.lgc.co.uk>
Message-ID: <20070914092833.GE5532@localdomain>

On Fri, Sep 14, 2007 at 10:22:36AM +0100, S Ellison wrote:
[...]
> knee-jerk. Apologies if I'm teaching egg-sucking to an expert.  

No apologies please. As i said I _like_ it. Thanks :)

G

> S
> 
> *******************************************************************
> This email and any attachments are confidential. Any use, ...{{dropped}}


From S.Ellison at lgc.co.uk  Fri Sep 14 11:46:57 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Fri, 14 Sep 2007 10:46:57 +0100
Subject: [R] t.test() with missing values
Message-ID: <s6ea66aa.002@tedmail2.lgc.co.uk>



>>> Peter Dalgaard <P.Dalgaard at biostat.ku.dk> 14/09/2007 09:26:16 >>>
>> So what can I do now to solve my problem?
>>
>> Do you think I should not use paired=TRUE?
>You *can* only use it when you have pairs, and you must do it then, to
>correct for intra-pair correlation. The drawback is that it looks only
>at complete pairs, throwing away all the singlets. It is possible to
>recover the information from the singlets , basically by combining a
>paired test for the pairs and an unpaired one for the singlets. (Someone
>must have written this down, but I'm afraid I don't have a nice reference).

Question: Could you achieve this kind of outcome with lme? stack the two groups, mark the observations y by subject (ie the pair ID) and group (treatment, presumably), and do something like

anova(lme(y~group, data=d, random=~1|subj, na.action=na.omit))

Or is that just disguising one of those nasty unbalanced 2-way anova problems?

*******************************************************************
This email and any attachments are confidential. Any use, co...{{dropped}}


From reilly at stat.auckland.ac.nz  Fri Sep 14 11:52:27 2007
From: reilly at stat.auckland.ac.nz (James Reilly)
Date: Fri, 14 Sep 2007 21:52:27 +1200
Subject: [R] Multiple R sessions, Mac version
In-Reply-To: <C30EC8D9.11AE%dafshartous@med.miami.edu>
References: <C30EC8D9.11AE%dafshartous@med.miami.edu>
Message-ID: <46EA59DB.3000809@stat.auckland.ac.nz>



On 14/9/07 3:00 AM, David Afshartous wrote:
> I've just switched to running R 2.5.1 on a Mac 0S X 10.4.1 platform.  I
> can't seem to find how to run simultaneous R sessions.  Didn't see anything
> in the archives on this or under the R file menu.

I've switched to Mac OS X recently too (10.4.10). While running 
simultaneous R sessions under X11 or from the terminal works for me out 
of the box, the only way I've found to run simultaneous Aqua sessions is 
to make extra copies of R.app and run those.

James
-- 
James Reilly
Department of Statistics, University of Auckland
Private Bag 92019, Auckland, New Zealand


From Wayne.W.Jones at shell.com  Fri Sep 14 11:57:24 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Fri, 14 Sep 2007 10:57:24 +0100
Subject: [R] Logistic regression
In-Reply-To: <3b66752d0709130832h3a139141kc424c6096caed581@mail.gmail.com>
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B03D@wyt-s-019.europe.shell.com>


Google search "Logistic Regression using R"

There are loads of good links here. Basically you use a generalized linear model.

Look up ?glm

Regards

Wayne

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of martin pareja
Sent: 13 September 2007 16:33
To: r-help at r-project.org
Subject: [R] Logistic regression


Hello
I am trying to get the estimated value of logit(p), along with its
standard error/conf interval from a logistic regression model (for the
overall sample, and for individual treatment levels), where p is the
proportion of "successes". I am having difficulty in finding how to
tell R to give this information.
Would anybody be able to help with this?

Thanks
Martin Pareja

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From P.Dalgaard at biostat.ku.dk  Fri Sep 14 12:05:00 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 14 Sep 2007 12:05:00 +0200
Subject: [R] t.test() with missing values
In-Reply-To: <s6ea66aa.001@tedmail2.lgc.co.uk>
References: <s6ea66aa.001@tedmail2.lgc.co.uk>
Message-ID: <46EA5CCC.4080207@biostat.ku.dk>

S Ellison wrote:
>   
>>>> Peter Dalgaard <P.Dalgaard at biostat.ku.dk> 14/09/2007 09:26:16 >>>
>>>>         
>>> So what can I do now to solve my problem?
>>>
>>> Do you think I should not use paired=TRUE?
>>>       
>> You *can* only use it when you have pairs, and you must do it then, to
>> correct for intra-pair correlation. The drawback is that it looks only
>> at complete pairs, throwing away all the singlets. It is possible to
>> recover the information from the singlets , basically by combining a
>> paired test for the pairs and an unpaired one for the singlets. (Someone
>> must have written this down, but I'm afraid I don't have a nice reference).
>>     
>
> Question: Could you achieve this kind of outcome with lme? stack the two groups, mark the observations y by subject (ie the pair ID) and group (treatment, presumably), and do something like
>
> anova(lme(y~group, data=d, random=~1|subj, na.action=na.omit))
>
> Or is that just disguising one of those nasty unbalanced 2-way anova problems?
>   
Yes, but....

I don't think lme() will do better than what you can do by hand: Get two
independent estimates of mu1-mu2 (one estimate from the pairs and one
from the singlets), compute a weighted average using the s.e.'s and test
that against zero (possibly after testing them for equality for good
measure). This is easy if you use a plug-in approach: first assume that
the s.e. are known, then plug in their empirical value. The tricky bit
is to calculate the DF in the style of Welch's test.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From r.hankin at noc.soton.ac.uk  Fri Sep 14 12:24:15 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Fri, 14 Sep 2007 11:24:15 +0100
Subject: [R] Sweave: tables vs matrices
In-Reply-To: <1189759923.2943.6.camel@graptoleberis.geog.ucl.ac.uk>
References: <F05CE336-87C3-4E63-979F-D427EB0EBD6F@noc.soton.ac.uk>
	<1189759923.2943.6.camel@graptoleberis.geog.ucl.ac.uk>
Message-ID: <B81933C6-46E0-493E-A06B-4AAB9A5EDA7F@noc.soton.ac.uk>

Hi Gavin

thanks for that. . . it does 99% of what I wanted.
I'd forgotten about the na.print argument.

It's considerably nicer than my other solution
which converted to character, then jj[is.na(jj)] <- "-"
then noquote(jj).

But  sometimes I just need nice LaTeX tables
and I can't think of a way to arrange things
so that: (i) I have only one set of numbers to maintain,
and (ii) an NA appears as a "-" in the LaTeX table.

best wishes

rksh

On 14 Sep 2007, at 09:52, Gavin Simpson wrote:

> On Fri, 2007-09-14 at 09:34 +0100, Robin Hankin wrote:
>> Hello everyone
>>
>>
>> I am preparing a document using Sweave in which I want my matrices
>> to appear as tables.  I am running into problems because as my
>> Rnw files stand, I have to  change table entries twice, once for
>> the matrix and once for the typeset table.
>>
>> I have lots of material like the following.  How can I arrange
>> my Rnw file so that  I only have to change one set of figures
>> when my numbers change?
>>
>> One reason I prefer tables here is that the NA entries
>> appear as "-" in the table, but as "NA" in the Schunk.
>> Is there a way to make the Schunk  typeset NAs
>> as minuses?
>
> See ?print.default and its argument na.print:
>
>> print.default(jj, na.print = "-")
>      [,1] [,2] [,3] [,4] [,5]
> [1,]    2    3    4    1   10
> [2,]    0    5    7    -   12
> [3,]    3    7    -    4   14
> [4,]    2    -    -    2    4
> [5,]    7   15   11    7   40
>
> Is that what you meant? It still prints the [1,] bits...
>
> HTH
>
> G
>
>>
>>
>>
>> \begin{table}
>> \centering
>> \begin{tabular}{|cccc|c|}\hline
>> \multicolumn{4}{|c|}{brand}&\\ \hline
>> A&B&C&D&total\\ \hline
>> 2       & 3      &  4       & 1    & 10   \\
>> 0       & 5       & 7       & -    & 12   \\
>> 3       & 7       & -       & 4    & 14   \\
>> 2       & -       & -       & 2    &  4    \\ \hline
>> 7&15&11&7&40\\ \hline
>> \end{tabular}
>> \caption{snipped caption}
>> \end{table}
>>
>>
>> <<>>=
>> jj <- matrix(c(2,  3,  4, 1,
>>                 0,  5,  7, NA,
>>                 3,  7, NA, 4,
>>                 2, NA, NA, 2
>>                 ),byrow=TRUE,nrow=4)
>> jj <- rbind(jj,apply(jj,2,sum,na.rm=TRUE))
>> jj <- cbind(jj,apply(jj,1,sum,na.rm=TRUE))
>> jj
>> @
>>
>>
>>
>

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From gavin.simpson at ucl.ac.uk  Fri Sep 14 12:45:52 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 14 Sep 2007 11:45:52 +0100
Subject: [R] Sweave: tables vs matrices
In-Reply-To: <B81933C6-46E0-493E-A06B-4AAB9A5EDA7F@noc.soton.ac.uk>
References: <F05CE336-87C3-4E63-979F-D427EB0EBD6F@noc.soton.ac.uk>
	<1189759923.2943.6.camel@graptoleberis.geog.ucl.ac.uk>
	<B81933C6-46E0-493E-A06B-4AAB9A5EDA7F@noc.soton.ac.uk>
Message-ID: <1189766752.2943.14.camel@graptoleberis.geog.ucl.ac.uk>

On Fri, 2007-09-14 at 11:24 +0100, Robin Hankin wrote:
> Hi Gavin
> 
> thanks for that. . . it does 99% of what I wanted.
> I'd forgotten about the na.print argument.
> 
> It's considerably nicer than my other solution
> which converted to character, then jj[is.na(jj)] <- "-"
> then noquote(jj).
> 
> But  sometimes I just need nice LaTeX tables
> and I can't think of a way to arrange things
> so that: (i) I have only one set of numbers to maintain,
> and (ii) an NA appears as a "-" in the LaTeX table.

Ok, then the xtable package and function is your answer. You can use
this within Sweave but I think you need to set the output to latex in
the Sweave chunk?

Is this closer to what you want?

> print.xtable(xtable(jj), NA.string = "-")
% latex table generated in R 2.5.1 by xtable 1.4-6 package
% Fri Sep 14 11:43:34 2007
\begin{table}[ht]
\begin{center}
\begin{tabular}{rrrrrr}
  \hline
 & 1 & 2 & 3 & 4 & 5 \\
  \hline
1 & 2.00 & 3.00 & 4.00 & 1.00 & 10.00 \\
  2 & 0.00 & 5.00 & 7.00 & $-$ & 12.00 \\
  3 & 3.00 & 7.00 & $-$ & 4.00 & 14.00 \\
  4 & 2.00 & $-$ & $-$ & 2.00 & 4.00 \\
  5 & 7.00 & 15.00 & 11.00 & 7.00 & 40.00 \\
   \hline
\end{tabular}
\end{center}
\end{table}

HTH

G

> 
> best wishes
> 
> rksh
> 
> On 14 Sep 2007, at 09:52, Gavin Simpson wrote:
> 
> > On Fri, 2007-09-14 at 09:34 +0100, Robin Hankin wrote:
> >> Hello everyone
> >>
> >>
> >> I am preparing a document using Sweave in which I want my matrices
> >> to appear as tables.  I am running into problems because as my
> >> Rnw files stand, I have to  change table entries twice, once for
> >> the matrix and once for the typeset table.
> >>
> >> I have lots of material like the following.  How can I arrange
> >> my Rnw file so that  I only have to change one set of figures
> >> when my numbers change?
> >>
> >> One reason I prefer tables here is that the NA entries
> >> appear as "-" in the table, but as "NA" in the Schunk.
> >> Is there a way to make the Schunk  typeset NAs
> >> as minuses?
> >
> > See ?print.default and its argument na.print:
> >
> >> print.default(jj, na.print = "-")
> >      [,1] [,2] [,3] [,4] [,5]
> > [1,]    2    3    4    1   10
> > [2,]    0    5    7    -   12
> > [3,]    3    7    -    4   14
> > [4,]    2    -    -    2    4
> > [5,]    7   15   11    7   40
> >
> > Is that what you meant? It still prints the [1,] bits...
> >
> > HTH
> >
> > G
> >
> >>
> >>
> >>
> >> \begin{table}
> >> \centering
> >> \begin{tabular}{|cccc|c|}\hline
> >> \multicolumn{4}{|c|}{brand}&\\ \hline
> >> A&B&C&D&total\\ \hline
> >> 2       & 3      &  4       & 1    & 10   \\
> >> 0       & 5       & 7       & -    & 12   \\
> >> 3       & 7       & -       & 4    & 14   \\
> >> 2       & -       & -       & 2    &  4    \\ \hline
> >> 7&15&11&7&40\\ \hline
> >> \end{tabular}
> >> \caption{snipped caption}
> >> \end{table}
> >>
> >>
> >> <<>>=
> >> jj <- matrix(c(2,  3,  4, 1,
> >>                 0,  5,  7, NA,
> >>                 3,  7, NA, 4,
> >>                 2, NA, NA, 2
> >>                 ),byrow=TRUE,nrow=4)
> >> jj <- rbind(jj,apply(jj,2,sum,na.rm=TRUE))
> >> jj <- cbind(jj,apply(jj,1,sum,na.rm=TRUE))
> >> jj
> >> @
> >>
> >>
> >>
> >
> 
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>   tel  023-8059-7743
> 
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From deshon at msu.edu  Fri Sep 14 12:50:29 2007
From: deshon at msu.edu (Rick DeShon)
Date: Fri, 14 Sep 2007 06:50:29 -0400
Subject: [R] How to remove index from list after split?
Message-ID: <c3cb73d50709140350p71b26b62u1c2d81fd817a90f5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070914/6f423629/attachment.pl 

From mothsailor at googlemail.com  Fri Sep 14 12:51:39 2007
From: mothsailor at googlemail.com (David Barron)
Date: Fri, 14 Sep 2007 11:51:39 +0100
Subject: [R] Logistic regression
In-Reply-To: <77693D6263D9B94AA3C6384F1474E26A0284B03D@wyt-s-019.europe.shell.com>
References: <3b66752d0709130832h3a139141kc424c6096caed581@mail.gmail.com>
	<77693D6263D9B94AA3C6384F1474E26A0284B03D@wyt-s-019.europe.shell.com>
Message-ID: <815b70590709140351i5ee65baekfbdcfbacbad9155e@mail.gmail.com>

You might want to look at the lrm function in the Design package as an
alternative to the standard tools.

On 9/14/07, Wayne.W.Jones at shell.com <Wayne.W.Jones at shell.com> wrote:
>
> Google search "Logistic Regression using R"
>
> There are loads of good links here. Basically you use a generalized linear model.
>
> Look up ?glm
>
> Regards
>
> Wayne
>
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org]On Behalf Of martin pareja
> Sent: 13 September 2007 16:33
> To: r-help at r-project.org
> Subject: [R] Logistic regression
>
>
> Hello
> I am trying to get the estimated value of logit(p), along with its
> standard error/conf interval from a logistic regression model (for the
> overall sample, and for individual treatment levels), where p is the
> proportion of "successes". I am having difficulty in finding how to
> tell R to give this information.
> Would anybody be able to help with this?
>
> Thanks
> Martin Pareja
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
=================================
David Barron
Said Business School
University of Oxford
Park End Street
Oxford OX1 1HP


From max.e.brown at gmail.com  Fri Sep 14 12:56:31 2007
From: max.e.brown at gmail.com (max.e.brown at gmail.com)
Date: Fri, 14 Sep 2007 12:56:31 +0200
Subject: [R] segfault in download.file
Message-ID: <m2642djz1c.fsf@gmail.com>

Hello,

I was trying to use get.hist.quote in tseries, and got a segfault:

-8<-----------------------------------

> library(tseries)
Loading required package: quadprog
Loading required package: zoo

    'tseries' version: 0.10-6

    'tseries' is a package for time series analysis and computational
    finance.

    See 'library(help="tseries")' for details.

> get.hist.quote("^spx")
trying URL 'http://chart.yahoo.com/table.csv?s=^spx&a=0&b=02&c=1991&d=8&e=13&f=2007&g=d&q=q&y=0&z=^spx&x=.csv'

 *** caught segfault ***
address 0x5f4d4550, cause 'memory not mapped'

Traceback:
 1: download.file(url, destfile, method = method, quiet = quiet)
 2: get.hist.quote("^spx")

Possible actions:
1: abort (with core dump)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection: 1
aborting ...
Segmentation fault

--------------------------------------

This appears to be reproducible.

My R version is
platform       powerpc-apple-darwin8.6.0 
arch           powerpc                   
os             darwin8.6.0               
system         powerpc, darwin8.6.0      
status                                   
major          2                         
minor          3.1                       
year           2006                      
month          06                        
day            01                        
svn rev        38247                     
language       R                         
version.string Version 2.3.1 (2006-06-01)

Is this a known issue?

Thanks,

Max

PS:
I can't seem to get useful info out of the dumped core:

Core was generated by `/Library/Frameworks/R.framework/Resources/bin/exec/ppc/R'.
#0  0x90003568 in ?? ()
(gdb) bt
#0  0x90003568 in ?? ()

I guess I would need a version of R with debugging symbols in there?


From birgit.lemcke at systbot.uzh.ch  Fri Sep 14 12:58:25 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Fri, 14 Sep 2007 12:58:25 +0200
Subject: [R] t.test() with missing values
In-Reply-To: <46EA5CCC.4080207@biostat.ku.dk>
References: <s6ea66aa.001@tedmail2.lgc.co.uk> <46EA5CCC.4080207@biostat.ku.dk>
Message-ID: <6297C7AA-ED6D-4985-9781-3C7229F6D0BA@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070914/427f957f/attachment.pl 

From wl2776 at gmail.com  Fri Sep 14 13:02:29 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Fri, 14 Sep 2007 04:02:29 -0700 (PDT)
Subject: [R] segfault in download.file
In-Reply-To: <m2642djz1c.fsf@gmail.com>
References: <m2642djz1c.fsf@gmail.com>
Message-ID: <12672985.post@talk.nabble.com>


I tried the same operations, and got

trying URL
'http://chart.yahoo.com/table.csv?s=^spx&a=0&b=02&c=1991&d=8&e=13&f=2007&g=d&q=q&y=0&z=^spx&x=.csv'
Error in download.file(url, destfile, method = method, quiet = quiet) : 
        cannot open URL
'http://chart.yahoo.com/table.csv?s=^spx&a=0&b=02&c=1991&d=8&e=13&f=2007&g=d&q=q&y=0&z=^spx&x=.csv'
In addition: Warning message:
cannot open: HTTP status was '404 Not Found' in: download.file(url,
destfile, method = method, quiet = quiet) 

Probably, you should upgrade R and the package.


max.e.brown wrote:
> 
> Hello,
> 
> I was trying to use get.hist.quote in tseries, and got a segfault:
> 
> -8<-----------------------------------
> 
>> library(tseries)
> Loading required package: quadprog
> Loading required package: zoo
> 
>     'tseries' version: 0.10-6
> 
>     'tseries' is a package for time series analysis and computational
>     finance.
> 
>     See 'library(help="tseries")' for details.
> 
>> get.hist.quote("^spx")
> trying URL
> 'http://chart.yahoo.com/table.csv?s=^spx&a=0&b=02&c=1991&d=8&e=13&f=2007&g=d&q=q&y=0&z=^spx&x=.csv'
> 
>  *** caught segfault ***
> address 0x5f4d4550, cause 'memory not mapped'
> 
> Traceback:
>  1: download.file(url, destfile, method = method, quiet = quiet)
>  2: get.hist.quote("^spx")
> 
> Possible actions:
> 1: abort (with core dump)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection: 1
> aborting ...
> Segmentation fault
> 
> --------------------------------------
> 
> This appears to be reproducible.
> 
> My R version is
> platform       powerpc-apple-darwin8.6.0 
> arch           powerpc                   
> os             darwin8.6.0               
> system         powerpc, darwin8.6.0      
> status                                   
> major          2                         
> minor          3.1                       
> year           2006                      
> month          06                        
> day            01                        
> svn rev        38247                     
> language       R                         
> version.string Version 2.3.1 (2006-06-01)
> 
> Is this a known issue?
> 
> Thanks,
> 
> Max
> 
> PS:
> I can't seem to get useful info out of the dumped core:
> 
> Core was generated by
> `/Library/Frameworks/R.framework/Resources/bin/exec/ppc/R'.
> #0  0x90003568 in ?? ()
> (gdb) bt
> #0  0x90003568 in ?? ()
> 
> I guess I would need a version of R with debugging symbols in there?
> 
> 

-- 
View this message in context: http://www.nabble.com/segfault-in-download.file-tf4441735.html#a12672985
Sent from the R help mailing list archive at Nabble.com.


From wl2776 at gmail.com  Fri Sep 14 13:10:00 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Fri, 14 Sep 2007 04:10:00 -0700 (PDT)
Subject: [R] How to remove index from list after split?
In-Reply-To: <c3cb73d50709140350p71b26b62u1c2d81fd817a90f5@mail.gmail.com>
References: <c3cb73d50709140350p71b26b62u1c2d81fd817a90f5@mail.gmail.com>
Message-ID: <12673118.post@talk.nabble.com>


Did not completely understand what is a 'group index', 
but to remove any element from a list or a matrix, or a vector or a data
frame you could use the negative index.

For example, 

> df.s[-c(1:3)]
$`3`
   g        x
1  3 3.916503
12 3 1.435718
24 3 2.252151

> df.s[-c(1:3)][[1]][-1]
          x
1  3.916503
12 1.435718
24 2.252151

You can also assign the results to a variable (the same or the other one)
> df.s<-df.s[-c(1:3)][[1]][-1]
> df.s
          x
1  3.916503
12 1.435718
24 2.252151



Rick DeShon wrote:
> 
> In the following example, how can I drop the group index from the list
> after
> I perform a split?
> n     <- 3
> nn   <- 10
> g     <- factor(round(n * runif(n * nn)))
> x     <- rnorm(n * nn) + sqrt(as.numeric(g))
> df    <- data.frame(g,x)
> df.s <- split(df,g)
> 

-- 
View this message in context: http://www.nabble.com/How-to-remove-index-from-list-after-split--tf4441712.html#a12673118
Sent from the R help mailing list archive at Nabble.com.


From Wayne.W.Jones at shell.com  Fri Sep 14 13:16:28 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Fri, 14 Sep 2007 12:16:28 +0100
Subject: [R] How to remove index from list after split?
In-Reply-To: <c3cb73d50709140350p71b26b62u1c2d81fd817a90f5@mail.gmail.com>
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B042@wyt-s-019.europe.shell.com>

Not sure what you mean by "group index" but try: 

lapply(df.s,function(l){l$x})
or something like: 

do.call("rbind",df.s) 

to convert the result into a data.frame. 

Regards

Wayne



-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of Rick DeShon
Sent: 14 September 2007 11:50
To: r-help at stat.math.ethz.ch
Subject: [R] How to remove index from list after split?


In the following example, how can I drop the group index from the list after
I perform a split?
n     <- 3
nn   <- 10
g     <- factor(round(n * runif(n * nn)))
x     <- rnorm(n * nn) + sqrt(as.numeric(g))
df    <- data.frame(g,x)
df.s <- split(df,g)

Thanks!

Rick DeShon

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From anders.bjorgesater at bio.uio.no  Fri Sep 14 13:23:10 2007
From: anders.bjorgesater at bio.uio.no (=?ISO-8859-1?Q?Anders_Bj=F8rges=E6ter?=)
Date: Fri, 14 Sep 2007 13:23:10 +0200
Subject: [R] quantiles and dataframe
Message-ID: <46EA6F1E.4080400@ulrik.uio.no>

Hi

I have a dataframe, RQ, like this:

A    B1    B2    B3
1    NA    112    12
2    NA    123   123
3    NA    324    13
4    3     21    535
5    4     12    33
6    7     1     335
7    4     NA    3535
8    4     NA    NA
9    NA    NA    NA
10    5    NA    NA
12    4    NA    NA
15    2    NA    NA
17    3    NA    1
63    1    NA    1
75    NA   NA    NA
100   NA   NA    NA
123   NA   NA    NA
155   NA   NA    NA
166   NA   NA    NA
177   NA   NA    NA

I want to extract min, max, 5% and 95% from A based on the range of the Bs.

Using this:

s1<-A[min(which(!is.na(B1))):max(which(!is.na(B1)))]
q1<-quantile(s1,probs=c(0,5,95,100,NA)/100)

I manage to get this by changing the B1 manually for each B

B1    B2    	B3
4.0    1.00     1.00    (min)
63.0   6.00  	63.00   (max)
4.5    4.5      1.65    (5%)
40.0   6.00     63.00   (95%)

I tried to use apply like this: s1<-apply(RQ,2,function(x) 
{A[min(which(!is.na(RQ[,2:4]))):max(which(!is.na(RQ[,2:4])))] })

to get the range of each B but that doesn't work.

Also as you see, s1 includes the A where the B's are NA, e.g. for B1 I 
get the 9 at row 9 (4,5,6,7,8,9,10,12,15,17,63) and not 
(4,5,6,7,8,10,12,15,17,63), which I would prefer.

BUT the main question is how can I extract min, max etc. from each B in 
dataframe RQ without using a loop?

Any help is greatly appreciated!

Best Regards
Anders


From kingsley.oteng at gmail.com  Fri Sep 14 13:34:50 2007
From: kingsley.oteng at gmail.com (kwaj)
Date: Fri, 14 Sep 2007 04:34:50 -0700 (PDT)
Subject: [R] write.csv / string extraction and field limits
In-Reply-To: <12596551.post@talk.nabble.com>
References: <12534347.post@talk.nabble.com> <12596551.post@talk.nabble.com>
Message-ID: <12673415.post@talk.nabble.com>


I worked it out. It wasn't actually the write.csv command - it was the fact
that I wasn't putting "as.is" in the read.csv that was corrupting the
process


Xavier Abulker wrote:
> 
> This example works fine:
> 
> test<-matrix(c(1,2,'VOICIUNPETITTESTTTTTTTTTTTTTTTTTTTT',3),ncol=2,nrow=2)
> write.csv(test,file='C:/xavier/test.csv')
> 
> 
> Could you provide the same small example when it doesn't work?
> 
> 
> 
> kwaj wrote:
>> 
>> Hello, 
>> 
>> I have a peculiar problem which I am hoping I can get help on. 
>> 
>> I am using the write.csv command to write a matrix structure to a file,
>> which I later read in excel. The command works quite well for most
>> strings and numerical values in the matrix structure. 
>> 
>> However, I have found that when a field in the matrix contains a string
>> of long length, when the matrix is finally written the file - the field
>> shows up as "NA". I am assuming write.csv has a limit on the field size?
>> Maybe 16 characters?
>> 
>> Assuming the above is correct - I tried to extract a portion of the
>> string using the 'substring' command and enter the extracted portion into
>> the field before using the write.csv command. However I find, that when a
>> string is extracted, the output from write.csv generates a NA in the file
>> output. 
>> 
>> My questions are:
>> 
>> 1) Does write.csv have a limit on the size of strings in the matrix
>> fields? Is there anyway to place large strings in the field?
>> 
>> 2) Is there anyway to make the substring command or an alternative but
>> similar command, compatible with write.csv? I have tried
>> 'as.character(substring(phrase, min, max)' and that does not seem to work
>> 
>> cheers
>> 
>> 
>> 
> 
> 

-- 
View this message in context: http://www.nabble.com/write.csv---string-extraction-and-field-limits-tf4395535.html#a12673415
Sent from the R help mailing list archive at Nabble.com.


From P.Dalgaard at biostat.ku.dk  Fri Sep 14 13:50:58 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 14 Sep 2007 13:50:58 +0200
Subject: [R] t.test() with missing values
In-Reply-To: <6297C7AA-ED6D-4985-9781-3C7229F6D0BA@systbot.uzh.ch>
References: <s6ea66aa.001@tedmail2.lgc.co.uk> <46EA5CCC.4080207@biostat.ku.dk>
	<6297C7AA-ED6D-4985-9781-3C7229F6D0BA@systbot.uzh.ch>
Message-ID: <46EA75A2.8040409@biostat.ku.dk>

Birgit Lemcke wrote:
>
> Am 14.09.2007 um 12:05 schrieb Peter Dalgaard:
>
>> S Ellison wrote:
>>>
>>>>>> Peter Dalgaard <P.Dalgaard at biostat.ku.dk> 14/09/2007 09:26:16 >>>
>>>>>>
>>>>> So what can I do now to solve my problem?
>>>>>
>>>>> Do you think I should not use paired=TRUE?
>>>>>
>>>> You *can* only use it when you have pairs, and you must do it then, to
>>>> correct for intra-pair correlation. The drawback is that it looks only
>>>> at complete pairs, throwing away all the singlets. It is possible to
>>>> recover the information from the singlets , basically by combining a
>>>> paired test for the pairs and an unpaired one for the singlets.
>>>> (Someone
>>>> must have written this down, but I'm afraid I don't have a nice
>>>> reference).
>>>>
>>>
>>> Question: Could you achieve this kind of outcome with lme? stack the
>>> two groups, mark the observations y by subject (ie the pair ID) and
>>> group (treatment, presumably), and do something like
>>>
>>> anova(lme(y~group, data=d, random=~1|subj, na.action=na.omit))
>>>
>>> Or is that just disguising one of those nasty unbalanced 2-way anova
>>> problems?
>>>
>> Yes, but....
>>
>> I don't think lme() will do better than what you can do by hand: Get two
>> independent estimates of mu1-mu2 (one estimate from the pairs and one
>> from the singlets), compute a weighted average using the s.e.'s and test
>> that against zero (possibly after testing them for equality for good
>> measure). This is easy if you use a plug-in approach: first assume that
>> the s.e. are known, then plug in their empirical value. The tricky bit
>> is to calculate the DF in the style of Welch's test.
>
>             I apologise but I really can not follow your explanations.
> I am  R and Stastistics Beginner.
>
>             What do you mean with mu1-mu2 and what are s.e.?s?
>
That was a reply to S. Ellison. If you don't understand it, don't worry;
you'll probably need to read a book chapter or more about weighted
analyses to get up to speed for that. 

mu1, mu2 : (theoretical) mean for group 1, 2
s.e.: standard error
>             Once again thank you for your help.
>
>             Birgit
>
>            
>
>            
>>
>> --   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)
>> 35327918
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)
>> 35327907
>>
>>
>
> Birgit Lemcke
> Institut f?r Systematische Botanik
> Zollikerstrasse 107
> CH-8008 Z?rich
> Switzerland
> Ph: +41 (0)44 634 8351
> birgit.lemcke at systbot.uzh.ch
>
>
>
>
>
>


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From kari.ruohonen at utu.fi  Fri Sep 14 13:59:34 2007
From: kari.ruohonen at utu.fi (Kari Ruohonen)
Date: Fri, 14 Sep 2007 14:59:34 +0300
Subject: [R] covariates in nlmer function
Message-ID: <1189771174.25196.9.camel@wittgenstein>

I am trying to explore nlmer by running some nlme examples from Pinheiro
& Bates (2000). I do not seem to find information how to specify fixed
effects covariates to nlmer models. Specifically, I tried to run the
"Carbon Dioxide Uptake" example from p. 368 onwards in the PB200 book.
The model without fixed effects covariates runs well but how to tell
nlmer to include Type and Treatment similar to the nlme model on p. 374
in the PB2000 book? Or is this something that has not been implemented
yet?

regards,
Kari Ruohonen


From petr.pikal at precheza.cz  Fri Sep 14 14:12:42 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Fri, 14 Sep 2007 14:12:42 +0200
Subject: [R] t.test() with missing values
In-Reply-To: <46EA75A2.8040409@biostat.ku.dk>
Message-ID: <OFD9036E42.23FD52FB-ONC1257356.0042830F-C1257356.0043085D@precheza.cz>

Hi

r-help-bounces at r-project.org napsal dne 14.09.2007 13:50:58:

> Birgit Lemcke wrote:
> >
> > Am 14.09.2007 um 12:05 schrieb Peter Dalgaard:
> >
> >> S Ellison wrote:
> >>>
> >>>>>> Peter Dalgaard <P.Dalgaard at biostat.ku.dk> 14/09/2007 09:26:16 >>>
> >>>>>>


<snip>


> >>>
> >> Yes, but....
> >>
> >> I don't think lme() will do better than what you can do by hand: Get 
two
> >> independent estimates of mu1-mu2 (one estimate from the pairs and one
> >> from the singlets), compute a weighted average using the s.e.'s and 
test
> >> that against zero (possibly after testing them for equality for good
> >> measure). This is easy if you use a plug-in approach: first assume 
that
> >> the s.e. are known, then plug in their empirical value. The tricky 
bit
> >> is to calculate the DF in the style of Welch's test.
> >
> >             I apologise but I really can not follow your explanations.
> > I am  R and Stastistics Beginner.
> >
> >             What do you mean with mu1-mu2 and what are s.e.?s?
> >
> That was a reply to S. Ellison. If you don't understand it, don't worry;
> you'll probably need to read a book chapter or more about weighted
> analyses to get up to speed for that. 
> 
> mu1, mu2 : (theoretical) mean for group 1, 2
> s.e.: standard error

But as Birgit actually does not have any paired values, according to the 
data she had sent, she can not do paired t.test at all. The only way is to 
compare averages from each vector by non paired t.test or to get some new 
values for which she have counterparts. 

Regards
Petr



> >             Once again thank you for your help.
> >
> >             Birgit
> >
> > 
> >
> > 
> >>
> >> --   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, 
Entr.B
> >>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> >>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)
> >> 35327918
> >> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)
> >> 35327907
> >>
> >>
> >
> > Birgit Lemcke
> > Institut f?r Systematische Botanik
> > Zollikerstrasse 107
> > CH-8008 Z?rich
> > Switzerland
> > Ph: +41 (0)44 634 8351
> > birgit.lemcke at systbot.uzh.ch
> >
> >
> >
> >
> >
> >
> 
> 
> -- 
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 
35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 
35327907
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Fri Sep 14 14:21:12 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 14 Sep 2007 08:21:12 -0400
Subject: [R] quantiles and dataframe
In-Reply-To: <46EA6F1E.4080400@ulrik.uio.no>
References: <46EA6F1E.4080400@ulrik.uio.no>
Message-ID: <971536df0709140521y6296d972x426ee56c9e71f41e@mail.gmail.com>

Try this:

sapply(RQ[-1], quantile, probs = c(0, .05, .95, 1), na.rm = TRUE)



On 9/14/07, Anders Bj?rges?ter <anders.bjorgesater at bio.uio.no> wrote:
> Hi
>
> I have a dataframe, RQ, like this:
>
> A    B1    B2    B3
> 1    NA    112    12
> 2    NA    123   123
> 3    NA    324    13
> 4    3     21    535
> 5    4     12    33
> 6    7     1     335
> 7    4     NA    3535
> 8    4     NA    NA
> 9    NA    NA    NA
> 10    5    NA    NA
> 12    4    NA    NA
> 15    2    NA    NA
> 17    3    NA    1
> 63    1    NA    1
> 75    NA   NA    NA
> 100   NA   NA    NA
> 123   NA   NA    NA
> 155   NA   NA    NA
> 166   NA   NA    NA
> 177   NA   NA    NA
>
> I want to extract min, max, 5% and 95% from A based on the range of the Bs.
>
> Using this:
>
> s1<-A[min(which(!is.na(B1))):max(which(!is.na(B1)))]
> q1<-quantile(s1,probs=c(0,5,95,100,NA)/100)
>
> I manage to get this by changing the B1 manually for each B
>
> B1    B2        B3
> 4.0    1.00     1.00    (min)
> 63.0   6.00     63.00   (max)
> 4.5    4.5      1.65    (5%)
> 40.0   6.00     63.00   (95%)
>
> I tried to use apply like this: s1<-apply(RQ,2,function(x)
> {A[min(which(!is.na(RQ[,2:4]))):max(which(!is.na(RQ[,2:4])))] })
>
> to get the range of each B but that doesn't work.
>
> Also as you see, s1 includes the A where the B's are NA, e.g. for B1 I
> get the 9 at row 9 (4,5,6,7,8,9,10,12,15,17,63) and not
> (4,5,6,7,8,10,12,15,17,63), which I would prefer.
>
> BUT the main question is how can I extract min, max etc. from each B in
> dataframe RQ without using a loop?
>
> Any help is greatly appreciated!
>
> Best Regards
> Anders
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From S.Ellison at lgc.co.uk  Fri Sep 14 14:23:32 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Fri, 14 Sep 2007 13:23:32 +0100
Subject: [R] replace NA value with 0
Message-ID: <s6ea8b5e.056@tedmail2.lgc.co.uk>



>>> Ted Harding <Ted.Harding at manchester.ac.uk> 14/09/2007 10:59:47 >>>
>On the contrary! It adds to our "collective wisdom".
>
>We all have to suck eggs, and usually can successfully perform the act.

Ted,

Thanks for the kind remarks.

But we'll have to get off the egg topic, or we'll all end up as acknowledged expert suckers....

Steve E

*******************************************************************
This email and any attachments are confidential. Any use, co...{{dropped}}


From P.Dalgaard at biostat.ku.dk  Fri Sep 14 14:27:39 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 14 Sep 2007 14:27:39 +0200
Subject: [R] t.test() with missing values
In-Reply-To: <OFD9036E42.23FD52FB-ONC1257356.0042830F-C1257356.0043085D@precheza.cz>
References: <OFD9036E42.23FD52FB-ONC1257356.0042830F-C1257356.0043085D@precheza.cz>
Message-ID: <46EA7E3B.8060207@biostat.ku.dk>

Petr PIKAL wrote:
> Hi
>
> r-help-bounces at r-project.org napsal dne 14.09.2007 13:50:58:
>
>   
>> Birgit Lemcke wrote:
>>     
>>> Am 14.09.2007 um 12:05 schrieb Peter Dalgaard:
>>>
>>>       
>>>> S Ellison wrote:
>>>>         
>>>>>>>> Peter Dalgaard <P.Dalgaard at biostat.ku.dk> 14/09/2007 09:26:16 >>>
>>>>>>>>
>>>>>>>>                 
>
>
> <snip>
>
>
>   
>>>> Yes, but....
>>>>
>>>> I don't think lme() will do better than what you can do by hand: Get 
>>>>         
> two
>   
>>>> independent estimates of mu1-mu2 (one estimate from the pairs and one
>>>> from the singlets), compute a weighted average using the s.e.'s and 
>>>>         
> test
>   
>>>> that against zero (possibly after testing them for equality for good
>>>> measure). This is easy if you use a plug-in approach: first assume 
>>>>         
> that
>   
>>>> the s.e. are known, then plug in their empirical value. The tricky 
>>>>         
> bit
>   
>>>> is to calculate the DF in the style of Welch's test.
>>>>         
>>>             I apologise but I really can not follow your explanations.
>>> I am  R and Stastistics Beginner.
>>>
>>>             What do you mean with mu1-mu2 and what are s.e.?s?
>>>
>>>       
>> That was a reply to S. Ellison. If you don't understand it, don't worry;
>> you'll probably need to read a book chapter or more about weighted
>> analyses to get up to speed for that. 
>>
>> mu1, mu2 : (theoretical) mean for group 1, 2
>> s.e.: standard error
>>     
>
> But as Birgit actually does not have any paired values, according to the 
> data she had sent, she can not do paired t.test at all. The only way is to 
> compare averages from each vector by non paired t.test or to get some new 
> values for which she have counterparts. 
>   
True, for that particular set of data. I did make that point in my first
reply (tried to, anyways), but I didn't repeat it the second time.

If you look back, you'll see that Birgit was also doing

TTest75<-t.test(Fem75, Mal75, alternative= "two.sided", paired= TRUE)

and presumably there are several similar sets of data. This "works" in the sense that it produces a test, but one could get the suspicion that it is only using a small subset of available data if the dropout rate is approaching that of Fem66/Mal66. Hence the discussion of the general case.

> Regards
> Petr
>
>
>
>   
>>>             Once again thank you for your help.
>>>
>>>             Birgit
>>>
>>>
>>>
>>>
>>>       
>>>> --   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, 
>>>>         
> Entr.B
>   
>>>>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>>>>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)
>>>> 35327918
>>>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)
>>>> 35327907
>>>>
>>>>
>>>>         
>>> Birgit Lemcke
>>> Institut f?r Systematische Botanik
>>> Zollikerstrasse 107
>>> CH-8008 Z?rich
>>> Switzerland
>>> Ph: +41 (0)44 634 8351
>>> birgit.lemcke at systbot.uzh.ch
>>>
>>>
>>>
>>>
>>>
>>>
>>>       
>> -- 
>>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 
>>     
> 35327918
>   
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 
>>     
> 35327907
>   
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>>     
> http://www.R-project.org/posting-guide.html
>   
>> and provide commented, minimal, self-contained, reproducible code.
>>     
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From jholtman at gmail.com  Fri Sep 14 14:45:53 2007
From: jholtman at gmail.com (jim holtman)
Date: Fri, 14 Sep 2007 08:45:53 -0400
Subject: [R] quantiles and dataframe
In-Reply-To: <46EA6F1E.4080400@ulrik.uio.no>
References: <46EA6F1E.4080400@ulrik.uio.no>
Message-ID: <644e1f320709140545x6de2385dm5761b9a979f7bc4@mail.gmail.com>

I think this does what you want:

> RQ
     A B1  B2   B3
1    1 NA 112   12
2    2 NA 123  123
3    3 NA 324   13
4    4  3  21  535
5    5  4  12   33
6    6  7   1  335
7    7  4  NA 3535
8    8  4  NA   NA
9    9 NA  NA   NA
10  10  5  NA   NA
11  12  4  NA   NA
12  15  2  NA   NA
13  17  3  NA    1
14  63  1  NA    1
15  75 NA  NA   NA
16 100 NA  NA   NA
17 123 NA  NA   NA
18 155 NA  NA   NA
19 166 NA  NA   NA
20 177 NA  NA   NA
> x <- lapply(RQ[-1], function(.col){
+     quantile(RQ[!is.na(.col), 1], probs=c(0, 0.05, 0.95, 1))
+ })
> do.call('cbind', x)
        B1   B2   B3
0%    4.00 1.00  1.0
5%    4.45 1.25  1.4
95%  42.30 5.75 44.6
100% 63.00 6.00 63.0


On 9/14/07, Anders Bj?rges?ter <anders.bjorgesater at bio.uio.no> wrote:
> Hi
>
> I have a dataframe, RQ, like this:
>
> A    B1    B2    B3
> 1    NA    112    12
> 2    NA    123   123
> 3    NA    324    13
> 4    3     21    535
> 5    4     12    33
> 6    7     1     335
> 7    4     NA    3535
> 8    4     NA    NA
> 9    NA    NA    NA
> 10    5    NA    NA
> 12    4    NA    NA
> 15    2    NA    NA
> 17    3    NA    1
> 63    1    NA    1
> 75    NA   NA    NA
> 100   NA   NA    NA
> 123   NA   NA    NA
> 155   NA   NA    NA
> 166   NA   NA    NA
> 177   NA   NA    NA
>
> I want to extract min, max, 5% and 95% from A based on the range of the Bs.
>
> Using this:
>
> s1<-A[min(which(!is.na(B1))):max(which(!is.na(B1)))]
> q1<-quantile(s1,probs=c(0,5,95,100,NA)/100)
>
> I manage to get this by changing the B1 manually for each B
>
> B1    B2        B3
> 4.0    1.00     1.00    (min)
> 63.0   6.00     63.00   (max)
> 4.5    4.5      1.65    (5%)
> 40.0   6.00     63.00   (95%)
>
> I tried to use apply like this: s1<-apply(RQ,2,function(x)
> {A[min(which(!is.na(RQ[,2:4]))):max(which(!is.na(RQ[,2:4])))] })
>
> to get the range of each B but that doesn't work.
>
> Also as you see, s1 includes the A where the B's are NA, e.g. for B1 I
> get the 9 at row 9 (4,5,6,7,8,9,10,12,15,17,63) and not
> (4,5,6,7,8,10,12,15,17,63), which I would prefer.
>
> BUT the main question is how can I extract min, max etc. from each B in
> dataframe RQ without using a loop?
>
> Any help is greatly appreciated!
>
> Best Regards
> Anders
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From kl.vanw at gmail.com  Fri Sep 14 14:53:48 2007
From: kl.vanw at gmail.com (K Vanw)
Date: Fri, 14 Sep 2007 08:53:48 -0400
Subject: [R] building with atlas version of blas and lapack
In-Reply-To: <46E7B69C.9080409@statistik.uni-dortmund.de>
References: <bfb1b6d20709111256q4fc53273hb5f9245a480ba77f@mail.gmail.com>
	<20070911202535.GE18752@jdmlab.mskcc.org>
	<46E7B69C.9080409@statistik.uni-dortmund.de>
Message-ID: <bfb1b6d20709140553k3e90fc9ejb91e9655e37d4644@mail.gmail.com>

On 9/12/07, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
>
> Flags should be
>    --with-blas="-L/usr/local/atlas/lib -lf77blas -latlas"

That worked. Thanks.


From ggrothendieck at gmail.com  Fri Sep 14 15:10:38 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 14 Sep 2007 09:10:38 -0400
Subject: [R] quantiles and dataframe
In-Reply-To: <971536df0709140521y6296d972x426ee56c9e71f41e@mail.gmail.com>
References: <46EA6F1E.4080400@ulrik.uio.no>
	<971536df0709140521y6296d972x426ee56c9e71f41e@mail.gmail.com>
Message-ID: <971536df0709140610p3127ef32yb383d5c91e36518b@mail.gmail.com>

Sorry, try this instead.  It creates a data frame of 3 columns in which
each column equals RQ[,1] except it has NAs where the columns of RQ[-1]
has NAs.  Perform the quantile operation on that.

sapply(sign(RQ[-1]) * RQ[,1], quantile, probs = c(0, .05, .95, 1), na.rm = TRUE)


On 9/14/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Try this:
>
> sapply(RQ[-1], quantile, probs = c(0, .05, .95, 1), na.rm = TRUE)
>
>
>
> On 9/14/07, Anders Bj?rges?ter <anders.bjorgesater at bio.uio.no> wrote:
> > Hi
> >
> > I have a dataframe, RQ, like this:
> >
> > A    B1    B2    B3
> > 1    NA    112    12
> > 2    NA    123   123
> > 3    NA    324    13
> > 4    3     21    535
> > 5    4     12    33
> > 6    7     1     335
> > 7    4     NA    3535
> > 8    4     NA    NA
> > 9    NA    NA    NA
> > 10    5    NA    NA
> > 12    4    NA    NA
> > 15    2    NA    NA
> > 17    3    NA    1
> > 63    1    NA    1
> > 75    NA   NA    NA
> > 100   NA   NA    NA
> > 123   NA   NA    NA
> > 155   NA   NA    NA
> > 166   NA   NA    NA
> > 177   NA   NA    NA
> >
> > I want to extract min, max, 5% and 95% from A based on the range of the Bs.
> >
> > Using this:
> >
> > s1<-A[min(which(!is.na(B1))):max(which(!is.na(B1)))]
> > q1<-quantile(s1,probs=c(0,5,95,100,NA)/100)
> >
> > I manage to get this by changing the B1 manually for each B
> >
> > B1    B2        B3
> > 4.0    1.00     1.00    (min)
> > 63.0   6.00     63.00   (max)
> > 4.5    4.5      1.65    (5%)
> > 40.0   6.00     63.00   (95%)
> >
> > I tried to use apply like this: s1<-apply(RQ,2,function(x)
> > {A[min(which(!is.na(RQ[,2:4]))):max(which(!is.na(RQ[,2:4])))] })
> >
> > to get the range of each B but that doesn't work.
> >
> > Also as you see, s1 includes the A where the B's are NA, e.g. for B1 I
> > get the 9 at row 9 (4,5,6,7,8,9,10,12,15,17,63) and not
> > (4,5,6,7,8,10,12,15,17,63), which I would prefer.
> >
> > BUT the main question is how can I extract min, max etc. from each B in
> > dataframe RQ without using a loop?
> >
> > Any help is greatly appreciated!
> >
> > Best Regards
> > Anders
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From ggrothendieck at gmail.com  Fri Sep 14 15:10:38 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 14 Sep 2007 09:10:38 -0400
Subject: [R] quantiles and dataframe
In-Reply-To: <971536df0709140521y6296d972x426ee56c9e71f41e@mail.gmail.com>
References: <46EA6F1E.4080400@ulrik.uio.no>
	<971536df0709140521y6296d972x426ee56c9e71f41e@mail.gmail.com>
Message-ID: <971536df0709140610p3127ef32yb383d5c91e36518b@mail.gmail.com>

Sorry, try this instead.  It creates a data frame of 3 columns in which
each column equals RQ[,1] except it has NAs where the columns of RQ[-1]
has NAs.  Perform the quantile operation on that.

sapply(sign(RQ[-1]) * RQ[,1], quantile, probs = c(0, .05, .95, 1), na.rm = TRUE)


On 9/14/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Try this:
>
> sapply(RQ[-1], quantile, probs = c(0, .05, .95, 1), na.rm = TRUE)
>
>
>
> On 9/14/07, Anders Bj?rges?ter <anders.bjorgesater at bio.uio.no> wrote:
> > Hi
> >
> > I have a dataframe, RQ, like this:
> >
> > A    B1    B2    B3
> > 1    NA    112    12
> > 2    NA    123   123
> > 3    NA    324    13
> > 4    3     21    535
> > 5    4     12    33
> > 6    7     1     335
> > 7    4     NA    3535
> > 8    4     NA    NA
> > 9    NA    NA    NA
> > 10    5    NA    NA
> > 12    4    NA    NA
> > 15    2    NA    NA
> > 17    3    NA    1
> > 63    1    NA    1
> > 75    NA   NA    NA
> > 100   NA   NA    NA
> > 123   NA   NA    NA
> > 155   NA   NA    NA
> > 166   NA   NA    NA
> > 177   NA   NA    NA
> >
> > I want to extract min, max, 5% and 95% from A based on the range of the Bs.
> >
> > Using this:
> >
> > s1<-A[min(which(!is.na(B1))):max(which(!is.na(B1)))]
> > q1<-quantile(s1,probs=c(0,5,95,100,NA)/100)
> >
> > I manage to get this by changing the B1 manually for each B
> >
> > B1    B2        B3
> > 4.0    1.00     1.00    (min)
> > 63.0   6.00     63.00   (max)
> > 4.5    4.5      1.65    (5%)
> > 40.0   6.00     63.00   (95%)
> >
> > I tried to use apply like this: s1<-apply(RQ,2,function(x)
> > {A[min(which(!is.na(RQ[,2:4]))):max(which(!is.na(RQ[,2:4])))] })
> >
> > to get the range of each B but that doesn't work.
> >
> > Also as you see, s1 includes the A where the B's are NA, e.g. for B1 I
> > get the 9 at row 9 (4,5,6,7,8,9,10,12,15,17,63) and not
> > (4,5,6,7,8,10,12,15,17,63), which I would prefer.
> >
> > BUT the main question is how can I extract min, max etc. from each B in
> > dataframe RQ without using a loop?
> >
> > Any help is greatly appreciated!
> >
> > Best Regards
> > Anders
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From birgit.lemcke at systbot.uzh.ch  Fri Sep 14 15:34:05 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Fri, 14 Sep 2007 15:34:05 +0200
Subject: [R] t.test() with missing values
In-Reply-To: <OFD9036E42.23FD52FB-ONC1257356.0042830F-C1257356.0043085D@precheza.cz>
References: <OFD9036E42.23FD52FB-ONC1257356.0042830F-C1257356.0043085D@precheza.cz>
Message-ID: <8B10B6C5-BBC2-4F83-9012-F33EEE5F0A22@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070914/b7c16adf/attachment.pl 

From birgit.lemcke at systbot.uzh.ch  Fri Sep 14 15:47:29 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Fri, 14 Sep 2007 15:47:29 +0200
Subject: [R] t.test() with missing values
In-Reply-To: <46EA7E3B.8060207@biostat.ku.dk>
References: <OFD9036E42.23FD52FB-ONC1257356.0042830F-C1257356.0043085D@precheza.cz>
	<46EA7E3B.8060207@biostat.ku.dk>
Message-ID: <E2475EC6-B348-4A9C-AE41-BA63C90E33D1@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070914/d2c89cef/attachment.pl 

From petr.pikal at precheza.cz  Fri Sep 14 15:54:59 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Fri, 14 Sep 2007 15:54:59 +0200
Subject: [R] t.test() with missing values
In-Reply-To: <46EA7E3B.8060207@biostat.ku.dk>
Message-ID: <OFFB3FDEAF.4B160955-ONC1257356.00459AEC-C1257356.004C65AF@precheza.cz>

> Petr PIKAL wrote:
> > Hi
> >
> > r-help-bounces at r-project.org napsal dne 14.09.2007 13:50:58:
> >
> > 
> >> Birgit Lemcke wrote:
> >> 
> >>> Am 14.09.2007 um 12:05 schrieb Peter Dalgaard:
> >>>
> >>> 
> >>>> S Ellison wrote:
> >>>> 
> >>>>>>>> Peter Dalgaard <P.Dalgaard at biostat.ku.dk> 14/09/2007 09:26:16 
>>>
> >>>>>>>>
> >>>>>>>> 
> >
> >
> > <snip>
> >
> >
> > 
> >>>> Yes, but....
> >>>>
> >>>> I don't think lme() will do better than what you can do by hand: 
Get 
> >>>> 
> > two
> > 
> >>>> independent estimates of mu1-mu2 (one estimate from the pairs and 
one
> >>>> from the singlets), compute a weighted average using the s.e.'s and 

> >>>> 
> > test
> > 
> >>>> that against zero (possibly after testing them for equality for 
good
> >>>> measure). This is easy if you use a plug-in approach: first assume 
> >>>> 
> > that
> > 
> >>>> the s.e. are known, then plug in their empirical value. The tricky 
> >>>> 
> > bit
> > 
> >>>> is to calculate the DF in the style of Welch's test.
> >>>> 
> >>>             I apologise but I really can not follow your 
explanations.
> >>> I am  R and Stastistics Beginner.
> >>>
> >>>             What do you mean with mu1-mu2 and what are s.e.?s?
> >>>
> >>> 
> >> That was a reply to S. Ellison. If you don't understand it, don't 
worry;
> >> you'll probably need to read a book chapter or more about weighted
> >> analyses to get up to speed for that. 
> >>
> >> mu1, mu2 : (theoretical) mean for group 1, 2
> >> s.e.: standard error
> >> 
> >
> > But as Birgit actually does not have any paired values, according to 
the 
> > data she had sent, she can not do paired t.test at all. The only way 
is to 
> > compare averages from each vector by non paired t.test or to get some 
new 
> > values for which she have counterparts. 
> > 
> True, for that particular set of data. I did make that point in my first
> reply (tried to, anyways), but I didn't repeat it the second time.
> 
> If you look back, you'll see that Birgit was also doing
> 
> TTest75<-t.test(Fem75, Mal75, alternative= "two.sided", paired= TRUE)
> 
> and presumably there are several similar sets of data. This "works" in 
the 
> sense that it produces a test, but one could get the suspicion that it 
is only
> using a small subset of available data if the dropout rate is 
approaching that
> of Fem66/Mal66. Hence the discussion of the general case.

I see, sorry I did not noticed before. But everything depends on which 
hypotheses she wants to test. She told us about 334 different plant 
species (male and female) and if she wants to test if male and female is 
different she does not have many other options. 

Petr

> 
> > Regards
> > Petr
> >
> >
> >
> > 
> >>>             Once again thank you for your help.
> >>>
> >>>             Birgit
> >>>
> >>>
> >>>
> >>>
> >>> 
> >>>> --   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, 
> >>>> 
> > Entr.B
> > 
> >>>>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> >>>>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)
> >>>> 35327918
> >>>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)
> >>>> 35327907
> >>>>
> >>>>
> >>>> 
> >>> Birgit Lemcke
> >>> Institut f?r Systematische Botanik
> >>> Zollikerstrasse 107
> >>> CH-8008 Z?rich
> >>> Switzerland
> >>> Ph: +41 (0)44 634 8351
> >>> birgit.lemcke at systbot.uzh.ch
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> 
> >> -- 
> >>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
> >>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> >>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 
> >> 
> > 35327918
> > 
> >> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 
> >> 
> > 35327907
> > 
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide 
> >> 
> > http://www.R-project.org/posting-guide.html
> > 
> >> and provide commented, minimal, self-contained, reproducible code.
> >> 
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > 
> 
> 
> -- 
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 
35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 
35327907
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From birgit.lemcke at systbot.uzh.ch  Fri Sep 14 16:05:46 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Fri, 14 Sep 2007 16:05:46 +0200
Subject: [R] t.test() with missing values
In-Reply-To: <OFFB3FDEAF.4B160955-ONC1257356.00459AEC-C1257356.004C65AF@precheza.cz>
References: <OFFB3FDEAF.4B160955-ONC1257356.00459AEC-C1257356.004C65AF@precheza.cz>
Message-ID: <F3482D26-5398-4C25-A35A-0E4A543E512C@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070914/daac6c7d/attachment.pl 

From alfreale74 at gmail.com  Fri Sep 14 16:15:53 2007
From: alfreale74 at gmail.com (Alfredo Alessandrini)
Date: Fri, 14 Sep 2007 16:15:53 +0200
Subject: [R] add a row...
Message-ID: <d2c05c5a0709140715w34c9fbedla6938f4e01e74b09@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070914/801de32d/attachment.pl 

From christoph.heibl at gmx.net  Fri Sep 14 16:30:08 2007
From: christoph.heibl at gmx.net (Christoph Heibl)
Date: Fri, 14 Sep 2007 16:30:08 +0200
Subject: [R] add a row...
In-Reply-To: <d2c05c5a0709140715w34c9fbedla6938f4e01e74b09@mail.gmail.com>
References: <d2c05c5a0709140715w34c9fbedla6938f4e01e74b09@mail.gmail.com>
Message-ID: <2215C1C2-7F08-45E9-AD57-2D30E473F766@gmx.net>

Use rbind:

d <- c(14,21)
b <- rbind(d, b)

CH



On 14.09.2007, at 16:15, Alfredo Alessandrini wrote:

> Hi,
>
> If I've a dataframe like this:
>
> a <- data.frame(a=c(14,21,14,4), b=c(21,45,23,11))
>
> print(a)
>
>    a  b
> 1 14 21
> 2 21 45
> 3 14 23
> 4  4 11
>
> I can delete the first row with:
>
> b = a[-(1),]
>
> print (b)
>
>    a  b
> 2 21 45
> 3 14 23
> 4  4 11
>
> Now, can I add to dataframe b the row that I've deleded?
>
> print (b)
>
>    a  b
> 1 14 21
> 2 21 45
> 3 14 23
> 4  4 11
>
>
>
> Best Wishes,
>
> Alfredo
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From darteta001 at ikasle.ehu.es  Fri Sep 14 16:49:07 2007
From: darteta001 at ikasle.ehu.es (darteta001 at ikasle.ehu.es)
Date: Fri, 14 Sep 2007 16:49:07 +0200 (CEST)
Subject: [R] Comparing regression models
In-Reply-To: <77693D6263D9B94AA3C6384F1474E26A0284B03D@wyt-s-019.europe.shell.com>
References: <77693D6263D9B94AA3C6384F1474E26A0284B03D@wyt-s-019.europe.shell.com>
Message-ID: <3249556437darteta001@ikasle.ehu.es>


Dear list,

I am interested in comparing two linear regression models to see if 
including one extra variable improves the model significantly. I have 
read that one possibility is doing an F test on the goodness-of-fit 
values for both models, and another option that is comparing the 
residuals of both models using a paired test. I also know about the 
anova() function that compares results for two models but am not sure 
what it actually does compare. Can you give me any suggestions?

Does the same hold if the models were logistic instead of linear? I 
have read that the Akaike?s AIC is also a valid option. 

Thanks in advance for your comments

David


From Wayne.W.Jones at shell.com  Fri Sep 14 17:06:43 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Fri, 14 Sep 2007 16:06:43 +0100
Subject: [R] Comparing regression models
In-Reply-To: <3249556437darteta001@ikasle.ehu.es>
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B046@wyt-s-019.europe.shell.com>



I would suggest doing an F-test.A descrition is given here: http://www.graphpad.com/curvefit/2_models__1_dataset.htm. 
The method is valid becasue one of your models is a subset of another. 

Correct use of the anova function does indeed perform this test. 
For example: 

data(airquality)
lm1<-lm(Ozone~.,airquality) # full model
lm2<-lm(Ozone~Solar.R+Wind +Month+Day,airquality) # reduced model
anova(lm2,lm1)




-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of
darteta001 at ikasle.ehu.es
Sent: 14 September 2007 15:49
To: r-help at r-project.org
Subject: [R] Comparing regression models



Dear list,

I am interested in comparing two linear regression models to see if 
including one extra variable improves the model significantly. I have 
read that one possibility is doing an F test on the goodness-of-fit 
values for both models, and another option that is comparing the 
residuals of both models using a paired test. I also know about the 
anova() function that compares results for two models but am not sure 
what it actually does compare. Can you give me any suggestions?

Does the same hold if the models were logistic instead of linear? I 
have read that the Akaike?s AIC is also a valid option. 

Thanks in advance for your comments

David

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Joseph.F.Lucke at uth.tmc.edu  Fri Sep 14 17:13:09 2007
From: Joseph.F.Lucke at uth.tmc.edu (Lucke, Joseph F)
Date: Fri, 14 Sep 2007 10:13:09 -0500
Subject: [R] Comparing regression models
In-Reply-To: <3249556437darteta001@ikasle.ehu.es>
References: <77693D6263D9B94AA3C6384F1474E26A0284B03D@wyt-s-019.europe.shell.com>
	<3249556437darteta001@ikasle.ehu.es>
Message-ID: <4677FCB5A35A0441A0E0C99D56B23D910777FF73@UTHEVS2.mail.uthouston.edu>

The classic way to test for better fit with an additional variable is to use the anova() function.  The model must have the suspect variable listed last into your model.  The anova() function will give you the correct sequential decomposition of your model effects and their conditional (F or t) tests.  Check a regression text for the details.  (You should have done this already.)

I have never heard of comparing residuals using the t-test.  It makes no sense because the residuals have mean zero under either model.

The AIC is also valid, but my reading between your lines would indicate the anova test would be better.

JFL

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of darteta001 at ikasle.ehu.es
Sent: Friday, September 14, 2007 9:49 AM
To: r-help at r-project.org
Subject: [R] Comparing regression models


Dear list,

I am interested in comparing two linear regression models to see if including one extra variable improves the model significantly. I have read that one possibility is doing an F test on the goodness-of-fit values for both models, and another option that is comparing the residuals of both models using a paired test. I also know about the
anova() function that compares results for two models but am not sure what it actually does compare. Can you give me any suggestions?

Does the same hold if the models were logistic instead of linear? I have read that the Akaike?s AIC is also a valid option. 

Thanks in advance for your comments

David

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Greg.Snow at intermountainmail.org  Fri Sep 14 17:13:21 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 14 Sep 2007 09:13:21 -0600
Subject: [R] replace NA value with 0
In-Reply-To: <20070914085605.GD5532@localdomain>
References: <s6ea5899.017@tedmail2.lgc.co.uk>
	<20070914085605.GD5532@localdomain>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBF93B9@LP-EXCHVS07.CO.IHC.COM>


 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Gabor Csardi
> Sent: Friday, September 14, 2007 2:56 AM
> To: S Ellison
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] replace NA value with 0

I nominate the following paragraph for the fortunes package

> I like this list because if you ask a question, they don't 
> only solve it immediately (in five different ways), but they 
> persuade you that what you're trying to do is actually 
> incorrect/stupid/uninteresting or your problem just makes no 
> sense at all.
> :)
> 
> Gabor


From alessandra.marmo at unicam.it  Fri Sep 14 12:17:18 2007
From: alessandra.marmo at unicam.it (Alessandra Marmo)
Date: Fri, 14 Sep 2007 12:17:18 +0200
Subject: [R] Print to file
Message-ID: <003201c7f6b8$6e0aded0$180cccc1@Amministrazione.Unicam>

Hello list I'M new
I need help about print to file
How i can Print more table in a file (in append)
using xtable and print functions?
 
 Tanks
 
 Alessandra


From Ted.Harding at manchester.ac.uk  Fri Sep 14 11:59:47 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Fri, 14 Sep 2007 10:59:47 +0100 (BST)
Subject: [R] replace NA value with 0
In-Reply-To: <s6ea60f6.077@tedmail2.lgc.co.uk>
Message-ID: <XFMail.070914105947.Ted.Harding@manchester.ac.uk>

On 14-Sep-07 09:22:36, S Ellison wrote:
> Being a chemist, I have to confess that I can't always tell
> that what I'm about to attempt is barking, trivial, uninteresting
> or better done a completely different way; myself, I'd rather be
> warned too often than left to dig my own pit and fall into it ... 
> 
> On NA's vs zero, I usually have the reverse problem in my corner
> of the world; folk will often call nondetects 'missing', which is
> also often a silly thing to do; nondetect means 'I looked and it
> was too low to see' but NA means 'I didn't look'. All that leaves
> me a bit nervous about replacing NA with 0 and vice versa ... hence
> the knee-jerk. Apologies if I'm teaching egg-sucking to an expert. 
> 
> S

On the contrary! It adds to our "collective wisdom".

We all have to suck eggs, and usually can successfully perform the act.
But it is useful to learn about people's experiences of when it is wise
to spit out the result.

Thanks, and best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 14-Sep-07                                       Time: 10:59:42
------------------------------ XFMail ------------------------------


From shubhak at ambaresearch.com  Fri Sep 14 15:42:20 2007
From: shubhak at ambaresearch.com (Shubha Vishwanath Karanth)
Date: Fri, 14 Sep 2007 19:12:20 +0530
Subject: [R] ISIN numbers into Bloomberg tickers
Message-ID: <A36876D3F8A5734FA84A4338135E7CC30278AA71@BAN-MAILSRV03.Amba.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070914/351f7ae3/attachment.pl 

From kingsley.oteng at gmail.com  Fri Sep 14 13:41:11 2007
From: kingsley.oteng at gmail.com (kwaj)
Date: Fri, 14 Sep 2007 04:41:11 -0700 (PDT)
Subject: [R] Yahoo data feed in R / Corporate Actions
Message-ID: <12673581.post@talk.nabble.com>


Is there anyway to import data from Yahoo into R and to have it adjusted for
share splits / dividend payouts (corporate actions)? I can currently import
data into R but the price series is not adjusted
-- 
View this message in context: http://www.nabble.com/Yahoo-data-feed-in-R---Corporate-Actions-tf4441979.html#a12673581
Sent from the R help mailing list archive at Nabble.com.


From jrkrideau at yahoo.ca  Fri Sep 14 17:25:14 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Fri, 14 Sep 2007 11:25:14 -0400 (EDT)
Subject: [R] replace NA value with 0
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBBF93B9@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <875323.67864.qm@web32813.mail.mud.yahoo.com>

Seconded.
--- Greg Snow <Greg.Snow at intermountainmail.org> wrote:

> 
>  
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org 
> > [mailto:r-help-bounces at r-project.org] On Behalf Of
> Gabor Csardi
> > Sent: Friday, September 14, 2007 2:56 AM
> > To: S Ellison
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] replace NA value with 0
> 
> I nominate the following paragraph for the fortunes
> package
> 
> > I like this list because if you ask a question,
> they don't 
> > only solve it immediately (in five different
> ways), but they 
> > persuade you that what you're trying to do is
> actually 
> > incorrect/stupid/uninteresting or your problem
> just makes no 
> > sense at all.
> > :)
> > 
> > Gabor
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From angeloattilio.colombo at tin.it  Fri Sep 14 17:26:05 2007
From: angeloattilio.colombo at tin.it (Angelo Colombo)
Date: Fri, 14 Sep 2007 15:26:05 -0000
Subject: [R] R2 in mixed model
In-Reply-To: <mailman.5.1142247601.2410.r-help@stat.math.ethz.ch>
References: <mailman.5.1142247601.2410.r-help@stat.math.ethz.ch>
Message-ID: <441557B6.3060306@tin.it>

Hello.
I have some basic question for you!.
Has calculating R2 sense in mixed model? I think no! But i don't why!

Thank in advance for your help
Angelo


From pcd at wikitex.org  Thu Sep 13 23:40:21 2007
From: pcd at wikitex.org (Peter Danenberg)
Date: Thu, 13 Sep 2007 16:40:21 -0500
Subject: [R] Row-Echelon Form
Message-ID: <20070913214021.GA9831@klutometis.wikitex.org>

> I append the function below, along with some other simple
> linear-algebra functions.

I never thanked you, by the way, John; have you considered incurring
the overhead of producing a formal R package?

Otherwise, it's worth its SLOC in gold.


From gustaf.rydevik at gmail.com  Fri Sep 14 17:31:01 2007
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Fri, 14 Sep 2007 17:31:01 +0200
Subject: [R] x-axis order
Message-ID: <45f568c70709140831y2c390fd4l256e9c5ce53079e1@mail.gmail.com>

Hi all,

I have a time series which contain data collected weekly from week 26
to week 25 the following year. How do I plot this data, so that the
x-axis is displaying the week numbers, ordered as in the data?

Thanks in advance,

Gustaf
---
x<-c(26:52,1:25)
y<-rnorm(52)+1:52
plot(x,y)   ## How do I get the x axis to be ordered by the current
ordering of x?



-- 
Gustaf Rydevik, M.Sci.
tel: +46(0)703 051 451
address:Essingetorget 40,112 66 Stockholm, SE
skype:gustaf_rydevik


From mel at altk.com  Fri Sep 14 17:32:21 2007
From: mel at altk.com (mel)
Date: Fri, 14 Sep 2007 17:32:21 +0200
Subject: [R] Print to file
In-Reply-To: <003201c7f6b8$6e0aded0$180cccc1@Amministrazione.Unicam>
References: <003201c7f6b8$6e0aded0$180cccc1@Amministrazione.Unicam>
Message-ID: <46EAA985.2060308@altk.com>

Alessandra Marmo a ?crit :
> Hello list I'M new
> I need help about print to file
> How i can Print more table in a file (in append)
> using xtable and print functions?

?write.table


From ntze at salow-netmedia.de  Fri Sep 14 08:31:03 2007
From: ntze at salow-netmedia.de (Nuafl)
Date: Fri, 14 Sep 2007 14:31:03 +0800
Subject: [R] =?gb2312?b?0NA91f49uaQ91/c9zbM9s+89udw9wO1T?=
Message-ID: <200709141553.l8EFrR93003804@hypatia.math.ethz.ch>

0     

===================================================================================
??-??-??-??-??-??-??-??-??-??-??-??-??-??????-??-??-??-??-??-??-??-?? { ???????????????????????????????????? }            
===================================================================================                                      
                   ????????????=??=??=??=??=??=??=??=??=??=??=??=??????????                                                    

                          2007??9??21-22?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ??
                          2007??9??29-30??     ??.??.??.??.??.??.??
                          2007??10??24-25??  ?? ?? ?? ?? ?? ?? ?? ??
                          2007??10??27-28??    ?? ?? ?? ?? ?? ??
 
=================================================================================== 
 ???????????????? ??*??*??*??*??*??*??*??   ??????????????????????????

 ???????????????? ??.??.??.??????.??.??.??????.??.??.??.??????.??.??.??????.??.??.??.????

 ????????????????  2500??/?? ?????????????????????????????????????????????????????????? ??
 
 ??????????????:  ????????????????????????????   ????????????????   

 ???????????????? ??????????????????????????
     
 ????????????$???? ??????????????????????????     

 ???????????????? ????@??????????????????
=================================================================================== 
????-??-??-????
 ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????
 ????????????????????????????????????????????????????????????????????????????????????????????????????????????????
 ????????????????????????????????????????????????????????????????????????????????????????????????????????????????
 ????????????????????????????????????????????????????????????????????????????????????????????????????????????????
 ????????????????????????????????????????????????????????????????????
 ?? ????????
 ??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
 ?? ????????
 ????????????????????????500??????????????????????????????????????????????????????????????????????????????????????????
 ????????????????????????????????????????????
=================================================================================== 
????-??-??-??????
 ????????????????????????????
 1?????????????????? 
 2????????????????????????
 3???????????????????????? 
 4????????????????????????
 ????????????????????????????

 ??????????????????????
 1???????????????????????? 
 2??????????????????????????????????????
 3????????????????????
 ??????????????????????

 ??????????????????????
 1?????????????? 
 2??????????????????????
 3?????????????????? 
 4????????????????????????
 5?????????????????????????? 
 6??????????????????????
 7??????????????????????
 ??????????????-????????-????????

 ??????????????????????????
 1???????????????? 
 2??????????????????????
 3???????????????????? 

 ????????????????????????????
 1. ???????????? 
 2. ????????????????
 3. ?????????????????????? 
 4. ??????????????????
 5. ?????????????????? 
 6. ??????????????
 7. ?????????????? 
 8. ???????????????? 
 9. ?????????????????? 
 10. ????????????????????
 11. ???????????? 
 12. ???????? 

 ??????????????????????????
 1?????????????????????????? 
 2????????????4??????
 3????????????5???? 
 4????????????????????
 ????????????????????????

 ??????????????????????
 1?????????????????????????????????????? 
 2????????????????????????
 3?????????????????????? 

 ??????????????????????
 1???????????????????????? 
 2????????????????????????????
 3??????????????????E-mail?????????? 
 4????????????????????????????

 ??????????????????????????
 1???????????????????????? 
 2????????????????????????????
 3????????????????????????????
 ??????????????????????????????
=================================================================================== 
???? ?? ?? ????
?????? ???? ????????????????????????????????????,??????????????????????????????????????????????????2001??????????
??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
?????????????????????????????????????????????????????????????????????????????????????????????????????????????? ??????
????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
??????????????????????????????????????????????????????????????????????????????????????????????????
===================================================================================                       
                    ?????????????????? ?? ?? ?? ?? ???????}?u????????????????????????
    
  TO:??*??*??*??*??*?W  ??+??+??+??: ????????????????????????????  

                        ??+??+??+??????????????????????????????????????

                        ??+??+??+??????????????????????????????????????


  ????!????????????.??.??.??.??.??.????????????????????????????????????????????????????????????????????????????????
????????????????????????????????????????????????????

 ????????????????????????????????????????????????????????????????

 ??????????????????????????????????????????????????????????????????????????????????????????????

 ??????????????????????????????????????????????????????????????????????

 ???????????????????????????????? ????????????????????????????

 ?? ?????????????????????????? ?????????????????????? ??????????????????????

 ???? ???? ???????????????????? ???????????????????????? ??????????????????????

 ???? ???? ???????????????????? ?????????????????????? ????????????????????????

 ???????????????????????????? ?? ??1???? ????????2???? ????????3???? ????

 ???????????????????????????? ?? ??1???? ??    ??1???? ????  ??2???? ??    ??3???? ??
--------------------------------------------------------------------------------

9
041


From davidr at rhotrading.com  Fri Sep 14 18:21:39 2007
From: davidr at rhotrading.com (davidr at rhotrading.com)
Date: Fri, 14 Sep 2007 11:21:39 -0500
Subject: [R] Yahoo data feed in R / Corporate Actions
In-Reply-To: <12673581.post@talk.nabble.com>
References: <12673581.post@talk.nabble.com>
Message-ID: <F9F2A641C593D7408925574C05A7BE774E730F@rhopost.rhotrading.com>

This came up last week on r-sig-finance:
https://stat.ethz.ch/pipermail/r-sig-finance/2007q3/001686.html


David L. Reiner
Rho Trading Securities, LLC
550 W. Jackson Blvd #1000
Chicago, IL 60661-5704
 
312-244-4610 direct
312-244-4500 main
312-244-4501 fax
 

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of kwaj
Sent: Friday, September 14, 2007 6:41 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Yahoo data feed in R / Corporate Actions


Is there anyway to import data from Yahoo into R and to have it adjusted
for
share splits / dividend payouts (corporate actions)? I can currently
import
data into R but the price series is not adjusted
-- 
View this message in context:
http://www.nabble.com/Yahoo-data-feed-in-R---Corporate-Actions-tf4441979
.html#a12673581
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From TobinJR at DFO-MPO.GC.CA  Fri Sep 14 18:34:19 2007
From: TobinJR at DFO-MPO.GC.CA (Tobin, Jared)
Date: Fri, 14 Sep 2007 14:04:19 -0230
Subject: [R] Collapsing data frame; aggregate() or better function?
In-Reply-To: <644e1f320709131418v45506f81i88a2c669d6ef2a97@mail.gmail.com>
References: <FBF367376AD9E64BB8531D56CA38DA6A01C7CBCA@nflwhex01.nfl.dfo-mpo.ca>
	<644e1f320709131418v45506f81i88a2c669d6ef2a97@mail.gmail.com>
Message-ID: <FBF367376AD9E64BB8531D56CA38DA6A01C7CBCD@nflwhex01.nfl.dfo-mpo.ca>

Thanks for the quick reply Jim.

I haven't had any success when I whittle down 'by' list even further
though.  I believe I'm using the right command, but now it's just a
matter of clear memory issues.

> test <- aggregate(lf1.turbot[,17:217], list(lf1.turbot$vessel,
lf1.turbot$trip, lf1.turbot$set), sum)
Error: cannot allocate vector of size 237.4 Mb In addition: Warning
messages:
1: Reached total allocation of 734Mb: see help(memory.size)
2: Reached total allocation of 734Mb: see help(memory.size)
3: Reached total allocation of 734Mb: see help(memory.size)
4: Reached total allocation of 734Mb: see help(memory.size) 

A fellow kindly emailed me directly and suggested trying Wickham's
'reshape' package, but again when using the melt() function in that
package I run into memory problems.  A colleague suggested I 'create
factors using as.factor() and feed this directly into the appropriate
apply function', but I've had no success with this when using tapply().

Any suggestions as to a less memory-intensive procedure would be greatly
appreciated.

Thanks,

--

jared tobin, student research assistant
fisheries and oceans canada
tobinjr at dfo-mpo.gc.ca

-----Original Message-----
From: jim holtman [mailto:jholtman at gmail.com] 
Sent: Thursday, September 13, 2007 6:49 PM
To: Tobin, Jared
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Collapsing data frame; aggregate() or better function?

The second argument for aggregate is supposed to be a list, so try
(notice the missing comma before "1:8"):

test <- aggregate(lf1.turbot[,c(11, 12, 17:217)], lf1.turbot[1:8],sum)


On 9/13/07, Tobin, Jared <TobinJR at dfo-mpo.gc.ca> wrote:
> Hello r-help,
>
> I am trying to collapse or aggregate 'some' of a data frame.  A very 
> simplified version of my data frame looks like:
>
> > tester
>  trip set num sex lfs1 lfs2
> 1  313  15   5   M    2    3
> 2  313  15   3   F    1    2
> 3  313  17   1   M    0    1
> 4  313  17   2   F    1    1
> 5  313  17   1   U    1    0
>
> And I want to omit sex from the picture and just get an addition of 
> num, lfs1, and lfs2 for each unique trip/set combination.  Using 
> aggregate() works fine here,
>
> > test <- aggregate(tester[,c(3,5:6)], tester[,1:2], sum) test
>  trip set num lfs1 lfs2
> 1  313  15   8    3    5
> 2  313  17   4    2    2
>
> But I'm having trouble getting the same function to work on my actual 
> data frame which is considerably larger.
>
> > dim(lf1.turbot)
> [1] 16468   217
> > test <- aggregate(lf1.turbot[,c(11, 12, 17:217)], lf1.turbot[,1:8],
> sum)
> Error in vector("list", prod(extent)) : vector size specified is too 
> large In addition: Warning messages:
> 1: NAs produced by integer overflow in: ngroup * (as.integer(index) -
> one)
> 2: NAs produced by integer overflow in: group + ngroup *
> (as.integer(index) - one)
> 3: NAs produced by integer overflow in: ngroup * nlevels(index)
>
> I'm guessing that either aggregate() can't handle a data frame of this

> size OR that there is an issue with 'omitting' more than one variable 
> (in the same way I've omitted sex in the above example).  Can anyone 
> clarify and/or recommend any relatively simple alternative procedure 
> to accomplish this?
>
> I plan on trying variants of by() and tapply() tomorrow morning, but 
> I'm about to head home for the day.
>
> Thanks,
>
> --
>
> jared tobin, student research assistant fisheries and oceans canada 
> tobinjr at dfo-mpo.gc.ca
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


--
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From davidr at rhotrading.com  Fri Sep 14 18:54:23 2007
From: davidr at rhotrading.com (davidr at rhotrading.com)
Date: Fri, 14 Sep 2007 11:54:23 -0500
Subject: [R] ISIN numbers into Bloomberg tickers
In-Reply-To: <A36876D3F8A5734FA84A4338135E7CC30278AA71@BAN-MAILSRV03.Amba.com>
References: <A36876D3F8A5734FA84A4338135E7CC30278AA71@BAN-MAILSRV03.Amba.com>
Message-ID: <F9F2A641C593D7408925574C05A7BE774E7314@rhopost.rhotrading.com>

You can try

> blpGetData(conn, "US912828HA15 Govt", 
    c("ticker", "cpn", "maturity", "market_sector_des"), retval="raw")

and paste together the parts.

HTH,

David L. Reiner
Rho Trading Securities, LLC


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Shubha Vishwanath Karanth
Sent: Friday, September 14, 2007 8:42 AM
To: r-help at stat.math.ethz.ch
Subject: [R] ISIN numbers into Bloomberg tickers

Hi R,

 

Can I convert ISIN numbers into Bloomberg tickers in the RBloomberg
package?

 

BR, Shubha


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mardones.p at gmail.com  Fri Sep 14 19:12:51 2007
From: mardones.p at gmail.com (Pedro Mardones)
Date: Fri, 14 Sep 2007 13:12:51 -0400
Subject: [R] Bootstrapping / stats question (not R)
Message-ID: <83dca7860709141012t19fefd2al3c495489b272a4bc@mail.gmail.com>

Dear all;

I'm looking for some advice regarding the following idea:

Let's say that I have a sample of y-values randomly taken from a
population and I want to compute the mean of y and its confidence
intervals but without assuming any particular distribution (I'm
assuming that the mean of this sample is a good indicator of the mean
of the population of y's). As far as I know we can use a nonparametric
bootstrap analysis approach to do something like this.

Now, let's say that instead of having to measure "y", I can measure
"x" because is easier. Moreover I have a model that relates y and x,
so I can predict the "y" giving the set of observed x. At the end of
the day I will have yhat=(y1-hat,...,yn-hat)' which is the vector of
predicted y-values.

Here the is question: Does it make any sense to try to calculate the
mean of the predicted "y's" and its CI by using a bootstrap analysis?
Am I violating any assumptions for that kind of analysis? (maybe the
independence of the samples?)

Sorry if this is a dumb question but I would like to have a different opinion

Thanks in advance

PM


From mardones.p at gmail.com  Fri Sep 14 19:12:51 2007
From: mardones.p at gmail.com (Pedro Mardones)
Date: Fri, 14 Sep 2007 13:12:51 -0400
Subject: [R] Bootstrapping / stats question (not R)
Message-ID: <83dca7860709141012t19fefd2al3c495489b272a4bc@mail.gmail.com>

Dear all;

I'm looking for some advice regarding the following idea:

Let's say that I have a sample of y-values randomly taken from a
population and I want to compute the mean of y and its confidence
intervals but without assuming any particular distribution (I'm
assuming that the mean of this sample is a good indicator of the mean
of the population of y's). As far as I know we can use a nonparametric
bootstrap analysis approach to do something like this.

Now, let's say that instead of having to measure "y", I can measure
"x" because is easier. Moreover I have a model that relates y and x,
so I can predict the "y" giving the set of observed x. At the end of
the day I will have yhat=(y1-hat,...,yn-hat)' which is the vector of
predicted y-values.

Here the is question: Does it make any sense to try to calculate the
mean of the predicted "y's" and its CI by using a bootstrap analysis?
Am I violating any assumptions for that kind of analysis? (maybe the
independence of the samples?)

Sorry if this is a dumb question but I would like to have a different opinion

Thanks in advance

PM


From hydes at byuh.edu  Fri Sep 14 20:02:56 2007
From: hydes at byuh.edu (Scott Hyde)
Date: Fri, 14 Sep 2007 08:02:56 -1000
Subject: [R] Cross Compiling
Message-ID: <793e846d0709141102p4e8480ccm2f3ea282231972c1@mail.gmail.com>

Hello All,

I have a Linux computer and do all of my work from it.  However, I
teach also, which means that many of my students use windows.   Hence,
I need to create packages that work under windows as well as Linux.  I
have tried to follow the directions at

http://cran.r-project.org/doc/contrib/cross-build.pdf

which is the document "Building Microsoft Windows Versions of R and R
packages under Intel Linux".  This has been very helpful.  However,
the file R_Tcl.zip is no longer available, so I cannot compile R for
Windows using the "make R" command as described in the document.  Is
it necessary to have the Tcl sources in there?  If it is, how should
the directions be modified to enable the complete compilation of R?

None of my code contains C, Fortran, or any other language.  It is
just plain R code.  I would think that this would be easier to convert
over.  Is it?  I tried the following and it seems to work, but I'd
like to know if it is safe.

1.  Build package with "pre-compiled binary package" option "R CMD
build --binary pkgname"
2. convert the resulting tar.gz file to a zip archive.
3. Install it on a windows machine.

This process successfully works when I install it on a windows
machine, but I have no idea how safe it is.

-- 
*****************************************************************
Scott K. Hyde
Assistant Professor of Statistics and Mathematics
School of Computing
Brigham Young University -- Hawaii


From stgries at gmail.com  Fri Sep 14 20:08:31 2007
From: stgries at gmail.com (Stefan Th. Gries)
Date: Fri, 14 Sep 2007 11:08:31 -0700
Subject: [R] Intercept in lm and in library(car): Anova
Message-ID: <a739b07c0709141108i29dcfcdcr25e3eb214d300fe@mail.gmail.com>

Hi

I have two questions regarding the meaning of intercept outputs of lm.

Question 1: In data set 1 (a fully-balanced design), the line with
(Intercept) contains the overall mean, and the estimates contain the
differences from the overall mean (matching those from model.tables).
But in data set 2, the line with the intercept does not correspond to
the overall mean and the estimates don't correspond to the differences
outputted by model.tables. What does the output contain here?

#####
rm(list=ls(all=TRUE))
options(contrasts=c("contr.sum", "contr.poly"))

# data set 1
Y1<-c(43, 23, 88, 45, 2, 68, 39, 41, 55, 64, 91, 9, 90, 37, 88, 41)
M1<-factor(c("k", "g", "k", "g", "k", "k", "g", "g", "g", "g", "k",
"k", "g", "g", "k", "k"))
N1<-factor(c("k", "g", "g", "k", "k", "g", "k", "g", "k", "g", "g",
"k", "g", "k", "g", "k"))

# linear model 1
model1<-lm(Y1~M1*N1); summary(model1)
model.tables(aov(Y1~M1*N1), "means")
model.tables(aov(Y1~M1*N1))

# data set 2
Y2<-c(34, 16, 46, 5, 2, 78, 31, 39, 25, 64, 45, 92, 65, 91, 60, 12,
33, 40, 72, 61, 49, 59)
M2<-factor(c(rep("a", 10), rep("b", 12)))
N2<-factor(c(rep("d", 4), rep("e", 6), rep("d", 8), rep("e", 4)))

# linear model 2
model2<-lm(Y2~M2*N2); summary(model2)
model.tables(aov(Y2~M2*N2), "means")
model.tables(aov(Y2~M2*N2))
#####


Question 2: what does the line with (Intercept) mean that the
following lines produce?

#####
library(car)
Anova(model, type=c("III"))
#####

Any help would be much appreciated. Thx,
STG


From jholtman at gmail.com  Fri Sep 14 20:18:35 2007
From: jholtman at gmail.com (jim holtman)
Date: Fri, 14 Sep 2007 14:18:35 -0400
Subject: [R] x-axis order
In-Reply-To: <45f568c70709140831y2c390fd4l256e9c5ce53079e1@mail.gmail.com>
References: <45f568c70709140831y2c390fd4l256e9c5ce53079e1@mail.gmail.com>
Message-ID: <644e1f320709141118n51f2349bn37f7d3f967f85654@mail.gmail.com>

This should do what you want.

x<-c(26:52,1:25)
y<-rnorm(52)+1:52

plot(seq_along(x), y, xaxt='n')
axis(1, at=seq_along(x), labels=x)



On 9/14/07, Gustaf Rydevik <gustaf.rydevik at gmail.com> wrote:
> Hi all,
>
> I have a time series which contain data collected weekly from week 26
> to week 25 the following year. How do I plot this data, so that the
> x-axis is displaying the week numbers, ordered as in the data?
>
> Thanks in advance,
>
> Gustaf
> ---
> x<-c(26:52,1:25)
> y<-rnorm(52)+1:52
> plot(x,y)   ## How do I get the x axis to be ordered by the current
> ordering of x?
>
>
>
> --
> Gustaf Rydevik, M.Sci.
> tel: +46(0)703 051 451
> address:Essingetorget 40,112 66 Stockholm, SE
> skype:gustaf_rydevik
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From jfox at mcmaster.ca  Fri Sep 14 20:29:20 2007
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 14 Sep 2007 14:29:20 -0400
Subject: [R] Intercept in lm and in library(car): Anova
In-Reply-To: <a739b07c0709141108i29dcfcdcr25e3eb214d300fe@mail.gmail.com>
Message-ID: <20070914182920.VHGF18413.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear Stefan,

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Stefan Th. Gries
> Sent: Friday, September 14, 2007 2:09 PM
> To: R-help at stat.math.ethz.ch
> Subject: [R] Intercept in lm and in library(car): Anova
> 
> Hi
> 
> I have two questions regarding the meaning of intercept outputs of lm.
> 
> Question 1: In data set 1 (a fully-balanced design), the line with
> (Intercept) contains the overall mean, and the estimates 
> contain the differences from the overall mean (matching those 
> from model.tables).
> But in data set 2, the line with the intercept does not 
> correspond to the overall mean and the estimates don't 
> correspond to the differences outputted by model.tables. What 
> does the output contain here?

In both datasets, the intercept is the "grand mean", which in a two-way
ANOVA (parametrized with sum-to-zero contrasts) is the mean of the cell
means. In the first case, because the data are balanced, the mean of the
cell means corresponds to the mean of Y1. In the second case, where there
are unequal cell counts, the mean of the cell means is different from the
mean of Y2 (but equal to the estimated intercept):

> mean(tapply(Y2, list(M2, N2), mean))
[1] 45.02083

The line in the output from Anova() in the package for the intercept tests
the null hypothesis that the intercept parameter is different from 0, which
rarely would be of interest.

I hope this helps,
 John

> 
> #####
> rm(list=ls(all=TRUE))
> options(contrasts=c("contr.sum", "contr.poly"))
> 
> # data set 1
> Y1<-c(43, 23, 88, 45, 2, 68, 39, 41, 55, 64, 91, 9, 90, 37, 
> 88, 41) M1<-factor(c("k", "g", "k", "g", "k", "k", "g", "g", 
> "g", "g", "k", "k", "g", "g", "k", "k")) N1<-factor(c("k", 
> "g", "g", "k", "k", "g", "k", "g", "k", "g", "g", "k", "g", 
> "k", "g", "k"))
> 
> # linear model 1
> model1<-lm(Y1~M1*N1); summary(model1)
> model.tables(aov(Y1~M1*N1), "means")
> model.tables(aov(Y1~M1*N1))
> 
> # data set 2
> Y2<-c(34, 16, 46, 5, 2, 78, 31, 39, 25, 64, 45, 92, 65, 91, 
> 60, 12, 33, 40, 72, 61, 49, 59) M2<-factor(c(rep("a", 10), 
> rep("b", 12))) N2<-factor(c(rep("d", 4), rep("e", 6), 
> rep("d", 8), rep("e", 4)))
> 
> # linear model 2
> model2<-lm(Y2~M2*N2); summary(model2)
> model.tables(aov(Y2~M2*N2), "means")
> model.tables(aov(Y2~M2*N2))
> #####
> 
> 
> Question 2: what does the line with (Intercept) mean that the 
> following lines produce?
> 
> #####
> library(car)
> Anova(model, type=c("III"))
> #####
> 
> Any help would be much appreciated. Thx, STG
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jfox at mcmaster.ca  Fri Sep 14 20:30:03 2007
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 14 Sep 2007 14:30:03 -0400
Subject: [R] Row-Echelon Form
In-Reply-To: <20070913214021.GA9831@klutometis.wikitex.org>
Message-ID: <20070914183004.KQJX26794.tomts43-srv.bellnexxia.net@JohnDesktop8300>

Dear Peter,

I don't have sufficient confidence in the numerical methods that I employed
in these functions to contribute them to CRAN as a package. I'm glad that
you found them useful, however.

Regards,
 John

--------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Peter Danenberg
> Sent: Thursday, September 13, 2007 5:40 PM
> To: r-help at r-project.org
> Subject: Re: [R] Row-Echelon Form
> 
> > I append the function below, along with some other simple 
> > linear-algebra functions.
> 
> I never thanked you, by the way, John; have you considered 
> incurring the overhead of producing a formal R package?
> 
> Otherwise, it's worth its SLOC in gold.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jholtman at gmail.com  Fri Sep 14 20:49:21 2007
From: jholtman at gmail.com (jim holtman)
Date: Fri, 14 Sep 2007 14:49:21 -0400
Subject: [R] Collapsing data frame; aggregate() or better function?
In-Reply-To: <FBF367376AD9E64BB8531D56CA38DA6A01C7CBCD@nflwhex01.nfl.dfo-mpo.ca>
References: <FBF367376AD9E64BB8531D56CA38DA6A01C7CBCA@nflwhex01.nfl.dfo-mpo.ca>
	<644e1f320709131418v45506f81i88a2c669d6ef2a97@mail.gmail.com>
	<FBF367376AD9E64BB8531D56CA38DA6A01C7CBCD@nflwhex01.nfl.dfo-mpo.ca>
Message-ID: <644e1f320709141149q21e594f1m802c56cfdfd05f9e@mail.gmail.com>

Here is a way that I have used when the data get big.  The 'trick' is
to create the key (in your case concatenating columns 1:8) and then
creating a list of indices (row numbers) of the dataframe that
correspond to the grouping (using split).  The you have the lapply
operate on the list of indices and index into the data to perform the
operations.

I created some test data of your size and here was the result:

> row <- 16468
> col <- 217
> x <- matrix(sample(1:4, row * col, TRUE), row, col)
> x.df <- as.data.frame(x)
> # create the indices by concatenating the fields
> y <- do.call('paste', x.df[1:8])
> z <- split(seq(nrow(x.df)), y)  # create a list of the indices
> system.time({
+ ans <- lapply(z, function(.rows){
+     colSums(x.df[.rows, c(11,12,17:217)])
+ })
+ })
   user  system elapsed
 147.57    1.15  197.42
>
> # combine back into a dataframe
> ans <- do.call('rbind', ans)
> ans[1:10, 1:7]
                V11 V12 V17 V18 V19 V20 V21
1 1 1 1 1 1 2 1   1   4   2   2   2   3   3
1 1 1 1 1 1 2 3   4   4   4   2   1   2   2
1 1 1 1 1 1 3 1   1   3   2   2   1   3   2
1 1 1 1 1 1 4 2   1   1   2   4   4   4   2
1 1 1 1 1 1 4 3   1   4   4   3   3   2   4
1 1 1 1 1 2 4 1   2   3   2   1   3   4   1
1 1 1 1 1 2 4 2   2   2   4   3   4   4   3
1 1 1 1 1 2 4 4   2   4   4   3   2   2   3
1 1 1 1 1 3 4 1   3   3   4   4   1   2   1
1 1 1 1 1 3 4 3   1   3   4   3   1   3   2
>

Printed out the first couple of rows.  The row labels are the
concatented values.

On 9/14/07, Tobin, Jared <TobinJR at dfo-mpo.gc.ca> wrote:
> Thanks for the quick reply Jim.
>
> I haven't had any success when I whittle down 'by' list even further
> though.  I believe I'm using the right command, but now it's just a
> matter of clear memory issues.
>
> > test <- aggregate(lf1.turbot[,17:217], list(lf1.turbot$vessel,
> lf1.turbot$trip, lf1.turbot$set), sum)
> Error: cannot allocate vector of size 237.4 Mb In addition: Warning
> messages:
> 1: Reached total allocation of 734Mb: see help(memory.size)
> 2: Reached total allocation of 734Mb: see help(memory.size)
> 3: Reached total allocation of 734Mb: see help(memory.size)
> 4: Reached total allocation of 734Mb: see help(memory.size)
>
> A fellow kindly emailed me directly and suggested trying Wickham's
> 'reshape' package, but again when using the melt() function in that
> package I run into memory problems.  A colleague suggested I 'create
> factors using as.factor() and feed this directly into the appropriate
> apply function', but I've had no success with this when using tapply().
>
> Any suggestions as to a less memory-intensive procedure would be greatly
> appreciated.
>
> Thanks,
>
> --
>
> jared tobin, student research assistant
> fisheries and oceans canada
> tobinjr at dfo-mpo.gc.ca
>
> -----Original Message-----
> From: jim holtman [mailto:jholtman at gmail.com]
> Sent: Thursday, September 13, 2007 6:49 PM
> To: Tobin, Jared
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Collapsing data frame; aggregate() or better function?
>
> The second argument for aggregate is supposed to be a list, so try
> (notice the missing comma before "1:8"):
>
> test <- aggregate(lf1.turbot[,c(11, 12, 17:217)], lf1.turbot[1:8],sum)
>
>
> On 9/13/07, Tobin, Jared <TobinJR at dfo-mpo.gc.ca> wrote:
> > Hello r-help,
> >
> > I am trying to collapse or aggregate 'some' of a data frame.  A very
> > simplified version of my data frame looks like:
> >
> > > tester
> >  trip set num sex lfs1 lfs2
> > 1  313  15   5   M    2    3
> > 2  313  15   3   F    1    2
> > 3  313  17   1   M    0    1
> > 4  313  17   2   F    1    1
> > 5  313  17   1   U    1    0
> >
> > And I want to omit sex from the picture and just get an addition of
> > num, lfs1, and lfs2 for each unique trip/set combination.  Using
> > aggregate() works fine here,
> >
> > > test <- aggregate(tester[,c(3,5:6)], tester[,1:2], sum) test
> >  trip set num lfs1 lfs2
> > 1  313  15   8    3    5
> > 2  313  17   4    2    2
> >
> > But I'm having trouble getting the same function to work on my actual
> > data frame which is considerably larger.
> >
> > > dim(lf1.turbot)
> > [1] 16468   217
> > > test <- aggregate(lf1.turbot[,c(11, 12, 17:217)], lf1.turbot[,1:8],
> > sum)
> > Error in vector("list", prod(extent)) : vector size specified is too
> > large In addition: Warning messages:
> > 1: NAs produced by integer overflow in: ngroup * (as.integer(index) -
> > one)
> > 2: NAs produced by integer overflow in: group + ngroup *
> > (as.integer(index) - one)
> > 3: NAs produced by integer overflow in: ngroup * nlevels(index)
> >
> > I'm guessing that either aggregate() can't handle a data frame of this
>
> > size OR that there is an issue with 'omitting' more than one variable
> > (in the same way I've omitted sex in the above example).  Can anyone
> > clarify and/or recommend any relatively simple alternative procedure
> > to accomplish this?
> >
> > I plan on trying variants of by() and tapply() tomorrow morning, but
> > I'm about to head home for the day.
> >
> > Thanks,
> >
> > --
> >
> > jared tobin, student research assistant fisheries and oceans canada
> > tobinjr at dfo-mpo.gc.ca
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> Jim Holtman
> Cincinnati, OH
> +1 513 646 9390
>
> What is the problem you are trying to solve?
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From bates at stat.wisc.edu  Fri Sep 14 21:09:55 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 14 Sep 2007 14:09:55 -0500
Subject: [R] Cross Compiling
In-Reply-To: <793e846d0709141102p4e8480ccm2f3ea282231972c1@mail.gmail.com>
References: <793e846d0709141102p4e8480ccm2f3ea282231972c1@mail.gmail.com>
Message-ID: <40e66e0b0709141209o7549a413pdbffaf98e6cb5ce6@mail.gmail.com>

An alternative to cross-compiling when you have a source package is to
use the Win-builder facility at win-builder.R-project.org

Thanks to Uwe for providing this facility.  I find it much, much
easier than trying to cross-compile or to set up a Windows computer
for compiling R packages.

On 9/14/07, Scott Hyde <hydes at byuh.edu> wrote:
> Hello All,
>
> I have a Linux computer and do all of my work from it.  However, I
> teach also, which means that many of my students use windows.   Hence,
> I need to create packages that work under windows as well as Linux.  I
> have tried to follow the directions at
>
> http://cran.r-project.org/doc/contrib/cross-build.pdf
>
> which is the document "Building Microsoft Windows Versions of R and R
> packages under Intel Linux".  This has been very helpful.  However,
> the file R_Tcl.zip is no longer available, so I cannot compile R for
> Windows using the "make R" command as described in the document.  Is
> it necessary to have the Tcl sources in there?  If it is, how should
> the directions be modified to enable the complete compilation of R?
>
> None of my code contains C, Fortran, or any other language.  It is
> just plain R code.  I would think that this would be easier to convert
> over.  Is it?  I tried the following and it seems to work, but I'd
> like to know if it is safe.
>
> 1.  Build package with "pre-compiled binary package" option "R CMD
> build --binary pkgname"
> 2. convert the resulting tar.gz file to a zip archive.
> 3. Install it on a windows machine.
>
> This process successfully works when I install it on a windows
> machine, but I have no idea how safe it is.
>
> --
> *****************************************************************
> Scott K. Hyde
> Assistant Professor of Statistics and Mathematics
> School of Computing
> Brigham Young University -- Hawaii
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From xuhy at ucla.edu  Fri Sep 14 21:09:44 2007
From: xuhy at ucla.edu (Haiyong Xu)
Date: Fri, 14 Sep 2007 12:09:44 -0700
Subject: [R] add boxplot to histogram
Message-ID: <B96AFBF1-8B1D-42F8-92A8-0B78F99729E9@ucla.edu>

Hi there,

I am wondering if it is possible to add a small boxplot in a  
histogram, just like the legend.

Thanks.
Haiyong


From bal44 at cornell.edu  Fri Sep 14 21:18:34 2007
From: bal44 at cornell.edu (Brooke LaFlamme)
Date: Fri, 14 Sep 2007 15:18:34 -0400 (EDT)
Subject: [R] unbalanced effects in aov
Message-ID: <2139054076.1189797513974.JavaMail.webber@orpheus7.dataserver.cornell.edu>

Hi, I have been having some trouble using aov to do an anova, probably because I'm not understanding how to use this function correctly. For some reason it always tells me that "Estimated effects may be unbalanced", though I'm not sure what this means. Is the formula I am using written incorrectly? Below is the code I am using along with the data: 

> my.data
         response species sex line replicate plate
1   -7.092854e-03       1   1    1         1     1
2   -8.663481e-04       1   2    1         1     1
3   -5.797276e-03       1   1    2         1     1
4   -2.598078e-03       1   2    2         1     1
5    7.832551e-04       2   1    1         1     1
6    1.333361e-03       2   2    1         1     1
7   -8.972490e-04       2   1    2         1     1
8   -2.834589e-03       2   2    2         1     1
9    5.655464e-04       3   1    1         1     1
10   7.371403e-03       3   2    1         1     1
11   3.160040e-03       3   1    2         1     1
12  -4.110653e-03       1   1    2         2     2
13  -2.262314e-03       1   2    2         2     2
14  -3.259483e-03       1   1    3         1     2
15  -5.671712e-03       1   2    3         1     2
16  -3.636077e-03       2   1    2         2     2
17  -3.904864e-03       2   2    2         2     2
18   1.025440e-03       2   1    3         1     2
19  -3.789292e-03       2   2    3         1     2
20   3.396270e-03       3   1    2         2     2
21   8.807778e-03       3   2    2         2     2
22   5.456604e-03       3   2    3         1     2
23  -1.134216e-02       1   1    3         2     3
24  -7.725740e-03       1   2    3         2     3
25  -1.589719e-03       1   1    4         1     3
26   4.574659e-04       1   2    4         1     3
27  -2.899983e-03       2   1    3         2     3
28  -4.310185e-03       2   2    3         2     3
29  -3.200475e-05       2   1    4         1     3
30   3.166308e-03       3   1    3         2     3
31   5.697712e-03       3   2    3         2     3
32   6.058486e-03       3   1    4         1     3
33   6.941016e-03       3   2    4         1     3
34  -2.794982e-03       1   1    4         2     4
35  -4.416711e-03       1   1    5         1     4
36  -4.062832e-03       1   2    5         1     4
37   1.763941e-03       2   1    4         2     4
38  -2.928930e-03       2   2    4         2     4
39  -2.869975e-03       2   2    5         1     4
40   6.949621e-03       3   1    4         2     4
41   5.766447e-03       3   2    4         2     4
42   2.510278e-03       3   1    5         1     4
43   5.507496e-03       3   2    5         1     4
44  -1.197325e-02       1   2    5         2     5
45  -6.556955e-03       1   1    6         1     5
46   3.622169e-04       2   1    5         2     5
47  -1.288784e-03       2   2    5         2     5
48  -2.863541e-03       2   1    6         1     5
49  -7.082933e-03       2   2    6         1     5
50   3.813700e-03       3   1    5         2     5
51   9.593295e-03       3   2    5         2     5
52   9.881930e-03       3   2    6         1     5
53  -1.081725e-02       1   1    6         2     6
54  -8.870041e-03       1   2    6         2     6
55  -5.305931e-04       1   2    7         1     6
56   2.835570e-03       2   1    6         2     6
57   4.541555e-03       2   2    6         2     6
58  -5.909101e-03       2   1    7         1     6
59  -2.768342e-03       2   2    7         1     6
60   8.835976e-03       3   1    6         2     6
61   1.234038e-02       3   2    6         2     6
62   2.015527e-03       3   1    7         1     6
63   6.485565e-03       3   2    7         1     6
64  -8.372922e-03       1   1    7         2     7
65  -9.439749e-03       1   2    7         2     7
66  -3.782672e-03       1   1    8         1     7
67  -2.576470e-03       1   2    8         1     7
68   2.878789e-03       2   1    7         2     7
69  -9.458139e-04       2   2    7         2     7
70  -3.993852e-03       2   2    8         1     7
71   5.997718e-03       3   1    7         2     7
72  -9.595505e-05       3   1    8         1     7
73   8.167411e-03       3   2    8         1     7
74  -1.181158e-02       1   1    8         2     8
75  -1.072585e-02       1   2    8         2     8
76  -2.856532e-03       1   1    9         1     8
77  -4.944013e-03       1   2    9         1     8
78   2.558783e-03       2   1    8         2     8
79   3.393314e-03       2   2    8         2     8
80  -4.466758e-03       2   1    9         1     8
81  -5.667622e-03       2   2    9         1     8
82   7.491253e-03       3   2    8         2     8
83   4.380724e-03       3   1    9         1     8
84   2.827233e-03       3   2    9         1     8
85  -7.433928e-03       1   2    9         2     9
86  -9.177664e-03       1   1   10         1     9
87  -6.040020e-04       1   2   10         1     9
88   1.394224e-03       2   1    9         2     9
89  -7.455449e-04       2   1   10         1     9
90  -2.251806e-03       2   2   10         1     9
91   7.865773e-03       3   1    9         2     9
92   6.287781e-03       3   2    9         2     9
93   7.734405e-03       3   1   10         1     9
94   9.757342e-03       3   2   10         1     9
95  -6.876948e-03       1   1    1         2    10
96  -4.974144e-03       1   2    1         2    10
97  -2.959226e-03       1   1   10         2    10
98   8.058296e-04       1   2   10         2    10
99   5.314729e-03       2   1    1         2    10
100  1.251126e-03       2   2    1         2    10
101  4.012311e-03       2   2   10         2    10
102  3.479155e-03       3   1    1         2    10
103  1.144813e-02       3   2    1         2    10
104  4.090214e-03       3   1   10         2    10
105  5.196910e-03       3   2   10         2    10
106 -9.038264e-03       1   2    6         1    11
107 -6.184877e-03       1   1    7         1    11
108  4.255164e-03       2   2    4         1    11
109  8.291281e-03       2   1    5         1    11
110 -5.368315e-04       2   2    9         2    11
111 -7.792906e-04       2   1   10         2    11
112  6.312335e-03       3   1    3         1    11
113  1.243561e-02       3   2    7         2    11
114  6.223999e-04       3   1    8         2    11
115 -6.517484e-03       1   2    4         2    12
116 -1.009622e-02       1   1    5         2    12
117 -4.414381e-04       1   1    9         2    12
118  2.221470e-03       2   1    8         1    12
119  1.041818e-02       3   2    2         1    12
120  3.384938e-04       3   1    6         1    12

I am treating all the variables as factors (except for response, obviously). 

formula<-response~species+line%in%species+replicate%in%line+sex%in%species+plate
model<-aov(formula, data=my.data)

This is the output: 

> model
Call:
   aov(formula = formula, data = my.data)

Terms:
                     species        plate species:line line:replicate
Sum of Squares  0.0026469288 0.0000945202 0.0003320255   0.0002008000
Deg. of Freedom            2           11           27             10
                 species:sex    Residuals
Sum of Squares  0.0001383116 0.0006315465
Deg. of Freedom            3           66

Residual standard error: 0.003093362 
Estimated effects may be unbalanced

Any help would be greatly appreciated as the R help documentation for aov does not address this issue. 

Thanks!
--
Brooke LaFlamme


From bates at stat.wisc.edu  Fri Sep 14 21:20:29 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 14 Sep 2007 14:20:29 -0500
Subject: [R] covariates in nlmer function
In-Reply-To: <1189771174.25196.9.camel@wittgenstein>
References: <1189771174.25196.9.camel@wittgenstein>
Message-ID: <40e66e0b0709141220x5d1e28d6w255dcab4fea75c70@mail.gmail.com>

On 9/14/07, Kari Ruohonen <kari.ruohonen at utu.fi> wrote:
> I am trying to explore nlmer by running some nlme examples from Pinheiro
> & Bates (2000). I do not seem to find information how to specify fixed
> effects covariates to nlmer models. Specifically, I tried to run the
> "Carbon Dioxide Uptake" example from p. 368 onwards in the PB200 book.
> The model without fixed effects covariates runs well but how to tell
> nlmer to include Type and Treatment similar to the nlme model on p. 374
> in the PB2000 book? Or is this something that has not been implemented
> yet?

To tell you the truth, I'm not sure.

I have been preparing classes and attending so many oral exams
recently that I can't remember exactly what capabilities are available
in nlmer right now.  I'll reply more definitively next week when I get
a chance to catch my breath a bit.


From wwwhsd at gmail.com  Fri Sep 14 22:20:44 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Fri, 14 Sep 2007 17:20:44 -0300
Subject: [R] add boxplot to histogram
In-Reply-To: <B96AFBF1-8B1D-42F8-92A8-0B78F99729E9@ucla.edu>
References: <B96AFBF1-8B1D-42F8-92A8-0B78F99729E9@ucla.edu>
Message-ID: <da79af330709141320g4b8bc19fme4d2aaf404f21322@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070914/d531eea0/attachment.pl 

From kingsley.oteng at gmail.com  Fri Sep 14 22:58:18 2007
From: kingsley.oteng at gmail.com (kwaj)
Date: Fri, 14 Sep 2007 13:58:18 -0700 (PDT)
Subject: [R] Copying row names
Message-ID: <12683702.post@talk.nabble.com>


I have been trying to copy the row names of one matrix to another matrix but
having difficulty. The original matrix contains a row name which I would
like to replicate in the new matrix. I use the following approach?
The two matrices have identical dimensions.

rN <- row.names(origMatrix)
row.names(newMatrix) <- rN

However the new matrix does not take on the labels. 

I have also tried, 

row.names(newMatrix) <- as.character(rN)

Any ideas?


-- 
View this message in context: http://www.nabble.com/Copying-row-names-tf4445280.html#a12683702
Sent from the R help mailing list archive at Nabble.com.


From phhs80 at gmail.com  Fri Sep 14 23:33:22 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Fri, 14 Sep 2007 22:33:22 +0100
Subject: [R] Copying row names
In-Reply-To: <12683702.post@talk.nabble.com>
References: <12683702.post@talk.nabble.com>
Message-ID: <6ade6f6c0709141433i33e03661tc19a971cd7d54ee0@mail.gmail.com>

On 9/14/07, kwaj <kingsley.oteng at gmail.com> wrote:
> I have been trying to copy the row names of one matrix to another matrix but
> having difficulty. The original matrix contains a row name which I would
> like to replicate in the new matrix. I use the following approach?
> The two matrices have identical dimensions.
>
> rN <- row.names(origMatrix)
> row.names(newMatrix) <- rN
>
> However the new matrix does not take on the labels.
>
> I have also tried,
>
> row.names(newMatrix) <- as.character(rN)
>
> Any ideas?

Use 'rownames' instead of 'row.names':

> a <- matrix(1:9,,3)
> rownames(a) <- c("x","y","z")
> b <- matrix(1:9,,3)
> names.of.a <- rownames(a)
> rownames(b) <- names.of.a
> a
  [,1] [,2] [,3]
x    1    4    7
y    2    5    8
z    3    6    9
> b
  [,1] [,2] [,3]
x    1    4    7
y    2    5    8
z    3    6    9
>

Paul


From iteachtyping at gmail.com  Sat Sep 15 00:37:38 2007
From: iteachtyping at gmail.com (Raymond Balise)
Date: Fri, 14 Sep 2007 15:37:38 -0700
Subject: [R] xyplot question
Message-ID: <3f2154540709141537l9609dc6jae6f3fc109bf2d9e@mail.gmail.com>

I am tring to do an xyplot where I want to plot 5 dots in each pane of
the trellice and the dots need to have lines (whiskers) extending up
and down at each point(plus a 45 degree reference line).  The data
frame is set up with the variables x y lcl and ucl (where the lcl and
ucl are the limits on the lines I want).  The code below gives me the
points but I cant figure out the lines limited by the lcl and ucl
variable.


library(lattice)
library(grid)

with(fig2,
          xyplot(y ~ x |  group * Method,
          xlab = "",
          xlim = c(-5, 1),
          ylab = "",
          ylim = c(-5, 1),
          col = "black",
          groups = group,
          aspect = 1,

          panel = function(x, y, ...) {
             panel.superpose(x, y, ...)
             panel.abline(0, 1)
         },
         )
)

The not trellice version of the first image I need in the xyplot can
be done like this:

with(sub1,
plot(y~x,
          xlim = c(-5,1),
          ylim = c(-5,1)
          )
)
abline (0, 1)
lines(rep(sub1$x[1],2), c(sub1$lcl[1], sub1$ucl[5]))
lines(rep(sub1$x[2],2), c(sub1$lcl[2], sub1$ucl[5]))
lines(rep(sub1$x[3],2), c(sub1$lcl[3], sub1$ucl[5]))
lines(rep(sub1$x[4],2), c(sub1$lcl[4], sub1$ucl[5]))
lines(rep(sub1$x[5],2), c(sub1$lcl[5], sub1$ucl[5]))

How can i tell it to use the lcl and ucl values to draw the whiskers I
need above and below the points?


From h.wickham at gmail.com  Sat Sep 15 00:49:57 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 14 Sep 2007 17:49:57 -0500
Subject: [R] xyplot question
In-Reply-To: <3f2154540709141537l9609dc6jae6f3fc109bf2d9e@mail.gmail.com>
References: <3f2154540709141537l9609dc6jae6f3fc109bf2d9e@mail.gmail.com>
Message-ID: <f8e6ff050709141549w7ca51773vf4cddcaf2c5d2f0d@mail.gmail.com>

Hi Raymond,

It isn't lattice, but this is fairly easy to do with ggplot2:

install.packages("ggplot2")
library(ggplot2)

qplot(x, y, facets = group ~ Method) +
geom_linerange(aes(min = lcl, max=ucl)) +
geom_abline()

See more at http://had.co.nz/ggplot2

Hadley

On 9/14/07, Raymond Balise <iteachtyping at gmail.com> wrote:
> I am tring to do an xyplot where I want to plot 5 dots in each pane of
> the trellice and the dots need to have lines (whiskers) extending up
> and down at each point(plus a 45 degree reference line).  The data
> frame is set up with the variables x y lcl and ucl (where the lcl and
> ucl are the limits on the lines I want).  The code below gives me the
> points but I cant figure out the lines limited by the lcl and ucl
> variable.
>
>
> library(lattice)
> library(grid)
>
> with(fig2,
>           xyplot(y ~ x |  group * Method,
>           xlab = "",
>           xlim = c(-5, 1),
>           ylab = "",
>           ylim = c(-5, 1),
>           col = "black",
>           groups = group,
>           aspect = 1,
>
>           panel = function(x, y, ...) {
>              panel.superpose(x, y, ...)
>              panel.abline(0, 1)
>          },
>          )
> )
>
> The not trellice version of the first image I need in the xyplot can
> be done like this:
>
> with(sub1,
> plot(y~x,
>           xlim = c(-5,1),
>           ylim = c(-5,1)
>           )
> )
> abline (0, 1)
> lines(rep(sub1$x[1],2), c(sub1$lcl[1], sub1$ucl[5]))
> lines(rep(sub1$x[2],2), c(sub1$lcl[2], sub1$ucl[5]))
> lines(rep(sub1$x[3],2), c(sub1$lcl[3], sub1$ucl[5]))
> lines(rep(sub1$x[4],2), c(sub1$lcl[4], sub1$ucl[5]))
> lines(rep(sub1$x[5],2), c(sub1$lcl[5], sub1$ucl[5]))
>
> How can i tell it to use the lcl and ucl values to draw the whiskers I
> need above and below the points?
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
http://had.co.nz/


From maitra at iastate.edu  Sat Sep 15 01:00:45 2007
From: maitra at iastate.edu (Ranjan Maitra)
Date: Fri, 14 Sep 2007 18:00:45 -0500
Subject: [R] question on layout and image.plot
Message-ID: <20070914180045.227cb26a@subarnarekha.stat.iastate.edu>

Dear colleagues,

I have struggled for the past couple of days with the following layout of plots. First, for something that finally works (and I understand it also, or so I think!):

A B x 

where A and B are 4x4 matrices of images, x is the common legend for A and B.

The following does what I want (note that the images are nonsensical realizations from N(0, 1) in this rendering so that it is possible for people to try it out):



library(fields)


mat <- matrix(1:16, ncol = 4, nrow = 4, by = T)
mat2 <- cbind(mat, rep(17, nrow(mat)), mat + 17, rep(34, nrow(mat)),
rep(35, nrow(mat)))
layout(mat2, heights = rep(8, 4), widths = c(rep(8, 4), 1, rep(8,
4), 3, 1), respect = F)   

par(mar = c(0, 0, 0, 0))

for (i in 1:16) image(matrix(rnorm(64^2), ncol = 64), col =
 tim.colors(64), axes = F)

frame()

for (i in 1:16) image(matrix(rnorm(64^2), ncol = 64), col =
 tim.colors(64), axes = F)

par(oma = c(0, 0, 0, 4))
par(mar = c(0, 0, 0, 0))

image.plot( zlim = c(-3, 3) , cex = 0.7, lwd = 0.5, legend.only=TRUE,
legend.width = 15, legend.shrink = 0.75)






The above works. But now, I want something that is of the format:

A x B x

where A and B are 4x4 matrices of images, x are the corresponding legends for A and B.

So, I tried the following:


library(fields)


mat <- matrix(1:16, ncol = 4, nrow = 4, by = T)
mat2 <- cbind(mat, rep(17, nrow(mat)), rep(18, nrow(mat)), mat + 18,
rep(35, nrow(mat)), rep(36, nrow(mat)))

layout(mat2, heights = rep(8, 4), widths = c(rep(8, 4), 3, 1, rep(8,
4), 3, 1), respect = F)   

par(mar = c(0, 0, 0, 0))

for (i in 1:16) image(matrix(rnorm(64^2), ncol = 64), col =
 tim.colors(64), axes = F)

par(oma = c(0, 0, 0, 4))
par(mar = c(0, 0, 0, 0))

image.plot( zlim = c(-3, 3) , cex = 0.7, lwd = 0.5, legend.only=TRUE,
legend.width = 15, legend.shrink = 0.75)

frame()

for (i in 1:16) image(matrix(rnorm(64^2), ncol = 64), col =
 tim.colors(64), axes = F)

par(oma = c(0, 0, 0, 4))
par(mar = c(0, 0, 0, 0))

image.plot( zlim = c(-3, 3) , cex = 0.7, lwd = 0.5, legend.only=TRUE,
legend.width = 15, legend.shrink = 0.75)




And everything goes haywire from the application of image.plot onwards. Indeed, if I replace the first image.plot call with frame(), everything goes through but of course, I do not get the first legend. So, I wonder what am I doing wrong? Also how should I fix this? Note that submitting the figures separately is not an option for me (stupid journal rules:-()

Can someone please suggest what I should do here? 

Many thanks and best wishes,
Ranjan


From agoralczyk at gmail.com  Sat Sep 15 01:07:13 2007
From: agoralczyk at gmail.com (Armin Goralczyk)
Date: Sat, 15 Sep 2007 01:07:13 +0200
Subject: [R] lme for repeated measurements over time
Message-ID: <a695fbee0709141607xb11e6b9ie46f6273ca9d12de@mail.gmail.com>

Hi list

I am just beginning to understand the complexities of linear mixed
effects models. Maybe someone can give advise concerning the following
problem:

I have two groups of surgical patients in which repeated laboratory
measurements were taken over time after surgery. I decided that lme
would be the best model to fit the data.
I already fitted the model

lme(logratio ~ gr*I(pod-10) + I(pod^2-10) + I(pod^3-10), data=xyz,
random = ~ pod|subj)

where gr = two groups; pod = postoperative day; subj = patient;
logratio = log of value at day pod/preoperative value: log(post/pre)

but these questions remain:

1. Is lme the best model to fit the data? Other suggestions?

2. Since the ratio had no gaussian distribution I took the log which
seems to have a normal distribution. Is this OK?

3. I shifted the intercept to pod 10 because at this point the
difference of the intercept is significant different whereas the
difference at 0 is not significant. Can I do this?

4. Inspection of the data showed that a polynomial regression would be
a better fit for the data. I tried several polynomial regressions up
to pod^5. The above model had the lowest AIC, BIC and logLik. When I
use Anova to compare the models there I get the warning message:
"Fitted objects with different fixed effects. REML comparisons are not
meaningful."
What can I use instead to compare the models?

5. For random I used only pod and not pod^x. Is this correct?

6. Omitting the group factor from pod^2 and pod^3 the model had a
slightly better fit. Can I do this?

7. Can I assume that the data is heteroskedastic? How do I apply the
'weights' in the above model?

I am sorry if some questions may sound weird but I am just beginning
to understand this (for me) rather complex concept. Thanks for any
help.
-- 
Armin Goralczyk, M.D.
Dept. of General Surgery
University of G?ttingen
G?ttingen, Germany
http://www.chirurgie-goettingen.de

From deepayan.sarkar at gmail.com  Sat Sep 15 01:31:43 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 14 Sep 2007 16:31:43 -0700
Subject: [R] xyplot question
In-Reply-To: <3f2154540709141537l9609dc6jae6f3fc109bf2d9e@mail.gmail.com>
References: <3f2154540709141537l9609dc6jae6f3fc109bf2d9e@mail.gmail.com>
Message-ID: <eb555e660709141631i1730d37bh49c6d8064736c483@mail.gmail.com>

On 9/14/07, Raymond Balise <iteachtyping at gmail.com> wrote:
> I am tring to do an xyplot where I want to plot 5 dots in each pane of
> the trellice and the dots need to have lines (whiskers) extending up
> and down at each point(plus a 45 degree reference line).  The data
> frame is set up with the variables x y lcl and ucl (where the lcl and
> ucl are the limits on the lines I want).  The code below gives me the
> points but I cant figure out the lines limited by the lcl and ucl
> variable.

demo("intervals", package = "lattice")

should get you most of the way. The source should be easier to read from

https://svn.r-project.org/R-packages/trunk/lattice/demo/intervals.R

You can ignore most of it; you just need prepanel.ci, panel.ci, and
the xyplot() call at the end.

-Deepayan


From shukai at seas.upenn.edu  Sat Sep 15 01:51:36 2007
From: shukai at seas.upenn.edu (kevinchang)
Date: Fri, 14 Sep 2007 16:51:36 -0700 (PDT)
Subject: [R] locate word in vector
Message-ID: <12685567.post@talk.nabble.com>


Hey All,


I am wondering if there is a built-in function allowing us to locate a
particular word in a character vector.

ex: vector a

a
[1] "superman"  "xamn"      "spiderman" "superman"  "superman"  "xman"     
[7] "spiderman"

Is there any built-in function that can show "superman" are the first,
fourth and fifith element in "a"? Please help me out. Thanks. 


-- 
View this message in context: http://www.nabble.com/locate-word-in-vector-tf4445881.html#a12685567
Sent from the R help mailing list archive at Nabble.com.


From jholtman at gmail.com  Sat Sep 15 02:16:53 2007
From: jholtman at gmail.com (jim holtman)
Date: Fri, 14 Sep 2007 20:16:53 -0400
Subject: [R] locate word in vector
In-Reply-To: <12685567.post@talk.nabble.com>
References: <12685567.post@talk.nabble.com>
Message-ID: <644e1f320709141716i550c4a0bld30b105f517e9a45@mail.gmail.com>

Is this what you want:

> x <- c("superman" , "xamn" ,     "spiderman", "superman" , "superman" , "xman",
+ "spiderman" )
> which(x == "superman")
[1] 1 4 5
>


On 9/14/07, kevinchang <shukai at seas.upenn.edu> wrote:
>
> Hey All,
>
>
> I am wondering if there is a built-in function allowing us to locate a
> particular word in a character vector.
>
> ex: vector a
>
> a
> [1] "superman"  "xamn"      "spiderman" "superman"  "superman"  "xman"
> [7] "spiderman"
>
> Is there any built-in function that can show "superman" are the first,
> fourth and fifith element in "a"? Please help me out. Thanks.
>
>
> --
> View this message in context: http://www.nabble.com/locate-word-in-vector-tf4445881.html#a12685567
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From ccleland at optonline.net  Sat Sep 15 02:22:04 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 14 Sep 2007 20:22:04 -0400
Subject: [R] locate word in vector
In-Reply-To: <12685567.post@talk.nabble.com>
References: <12685567.post@talk.nabble.com>
Message-ID: <46EB25AC.5010504@optonline.net>

kevinchang wrote:
> Hey All,
> 
> 
> I am wondering if there is a built-in function allowing us to locate a
> particular word in a character vector.
> 
> ex: vector a
> 
> a
> [1] "superman"  "xamn"      "spiderman" "superman"  "superman"  "xman"     
> [7] "spiderman"
> 
> Is there any built-in function that can show "superman" are the first,
> fourth and fifith element in "a"? Please help me out. Thanks. 

a <- c("superman", "xamn", "spiderman", "superman",
       "superman", "xman", "spiderman")

grep("^superman$", a)
[1] 1 4 5

?grep

OR

which(a %in% "superman")
[1] 1 4 5

?which
?is.element

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From ndoye_p at hotmail.com  Sat Sep 15 09:57:47 2007
From: ndoye_p at hotmail.com (Ndoye Souleymane)
Date: Sat, 15 Sep 2007 07:57:47 +0000
Subject: [R] problem installing Rpmi : mpi.h...Found in /usr/include/lam,
	yet "libmpi
In-Reply-To: <Pine.LNX.4.64.0704270643470.11215@gannet.stats.ox.ac.uk>
Message-ID: <BAY116-F24001DD19D00C25EEF29E799BD0@phx.gbl>

Dear Mr Ripley, Dear all,

Could you please help me to find an appropriate rpm package to install on 
RED HAT LINUX ENTERPRISE 5.

I have experienced trouble in invoking R with R-2.5.1-1.fc7.i386.rpm. It 
strats normaly and then it exit me to the prompt like shown below:

How to cope with this error of segmentation.

Thanks for your help,

Faithfully Yours,

Souleymane N'Doye
Statisticain & Decison Support Systems consultant

Labstat Conseil
P. O. BOX 347, 00606 Nairobi Kenya
Email: souleymane.ndoye at labstatconseil.com
tel. : +254 (20) 736 842 478
www.labstatconseil.com

*** caught segfault ***
address (nil), cause 'memory not mapped'

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Erreur de segmentation

_________________________________________________________________
[[replacing trailing spam]]


From ndoye_p at hotmail.com  Sat Sep 15 09:59:31 2007
From: ndoye_p at hotmail.com (Ndoye Souleymane)
Date: Sat, 15 Sep 2007 07:59:31 +0000
Subject: [R] RPM package for Linux RED HAT ENTERPRISE 5
In-Reply-To: <Pine.LNX.4.64.0704270643470.11215@gannet.stats.ox.ac.uk>
Message-ID: <BAY116-F267CFB6669FBB4C1821CC899BD0@phx.gbl>

Dear Mr Ripley, Dear all,

Could you please help me to find an appropriate rpm package to install on 
RED HAT LINUX ENTERPRISE 5.

I have experienced trouble in invoking R with R-2.5.1-1.fc7.i386.rpm. It 
strats normaly and then it exit me to the prompt like shown below:

How to cope with this error of segmentation.

Thanks for your help,

Faithfully Yours,

Souleymane N'Doye
Statisticain & Decison Support Systems consultant

Labstat Conseil
P. O. BOX 347, 00606 Nairobi Kenya
Email: souleymane.ndoye at labstatconseil.com
tel. : +254 (20) 736 842 478
www.labstatconseil.com

*** caught segfault ***
address (nil), cause 'memory not mapped'

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Erreur de segmentation

_________________________________________________________________
[[replacing trailing spam]]


From christophe.vuadens at unil.ch  Sat Sep 15 11:20:20 2007
From: christophe.vuadens at unil.ch (christophe vuadens)
Date: Sat, 15 Sep 2007 02:20:20 -0700 (PDT)
Subject: [R] HTML reading,
Message-ID: <12688719.post@talk.nabble.com>


Hello,

Sorry for my english, in a R function, I want to read HTML files to analyse
the text.  Do somebody now, how can i read the text only in txt Foirmat... 

Thanks
-- 
View this message in context: http://www.nabble.com/HTML-reading%2C-tf4447190.html#a12688719
Sent from the R help mailing list archive at Nabble.com.


From agoralczyk at gmail.com  Sat Sep 15 11:40:47 2007
From: agoralczyk at gmail.com (Armin Goralczyk)
Date: Sat, 15 Sep 2007 11:40:47 +0200
Subject: [R] HTML reading,
In-Reply-To: <12688719.post@talk.nabble.com>
References: <12688719.post@talk.nabble.com>
Message-ID: <a695fbee0709150240n58f03db5n8ffb9c66326d112b@mail.gmail.com>

On 9/15/07, christophe vuadens <christophe.vuadens at unil.ch> wrote:
>
> Hello,
>
> Sorry for my english, in a R function, I want to read HTML files to analyse
> the text.  Do somebody now, how can i read the text only in txt Foirmat...
>
> Thanks
> --

Have a look at this:

http://gking.harvard.edu/readme/

I don't know how they strip the html tags exactly, but it is described
in the documents there. This is also a good tool for text analysis.

-- 
Armin Goralczyk, M.D.
Dept. of General Surgery
University of G?ttingen
G?ttingen, Germany
http://www.chirurgie-goettingen.de

From likhonnaser at hotmail.com  Sat Sep 15 11:43:09 2007
From: likhonnaser at hotmail.com (Abu Naser)
Date: Sat, 15 Sep 2007 09:43:09 +0000
Subject: [R] how to change print limit on screen
Message-ID: <BAY134-W264AC946D28A185E98F08A3BD0@phx.gbl>


Hi all user,

Is there any way i can chage the print limit ( getOption("max.print")) to unlimited or specified limit?

Thanks in advance
_________________________________________________________________
Feel like a local wherever you go.


From ripley at stats.ox.ac.uk  Sat Sep 15 11:44:52 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 15 Sep 2007 10:44:52 +0100 (BST)
Subject: [R] RPM package for Linux RED HAT ENTERPRISE 5
In-Reply-To: <BAY116-F267CFB6669FBB4C1821CC899BD0@phx.gbl>
References: <BAY116-F267CFB6669FBB4C1821CC899BD0@phx.gbl>
Message-ID: <Pine.LNX.4.64.0709151038350.27539@gannet.stats.ox.ac.uk>

See http://cran.r-project.org/bin/linux/redhat/el5/i386/
The ReadMe there says they should work on RHEL5.

I've not used RHEL5, but have a little experience with Centos5, where R 
builds from the tarball without any problems at all.

On Sat, 15 Sep 2007, Ndoye Souleymane wrote:

> Dear Mr Ripley, Dear all,
>
> Could you please help me to find an appropriate rpm package to install on RED 
> HAT LINUX ENTERPRISE 5.
>
> I have experienced trouble in invoking R with R-2.5.1-1.fc7.i386.rpm. It 
> strats normaly and then it exit me to the prompt like shown below:
>
> How to cope with this error of segmentation.
>
> Thanks for your help,
>
> Faithfully Yours,
>
> Souleymane N'Doye
> Statisticain & Decison Support Systems consultant
>
> Labstat Conseil
> P. O. BOX 347, 00606 Nairobi Kenya
> Email: souleymane.ndoye at labstatconseil.com
> tel. : +254 (20) 736 842 478
> www.labstatconseil.com
>
> *** caught segfault ***
> address (nil), cause 'memory not mapped'
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Erreur de segmentation
>
> _________________________________________________________________
> Windows Live Spaces : cr?ez votre blog ? votre image ! 
> http://www.windowslive.fr/spaces
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From shukai at seas.upenn.edu  Sat Sep 15 12:21:19 2007
From: shukai at seas.upenn.edu (kevinchang)
Date: Sat, 15 Sep 2007 03:21:19 -0700 (PDT)
Subject: [R] starting with a capital letter
Message-ID: <12689105.post@talk.nabble.com>


Hi everyone,

I am wondering if there is any built-in funcion that can determine whether
words in a character vector start with a captial letter or not. Help,
please. Thanks.
-- 
View this message in context: http://www.nabble.com/starting-with-a-capital-letter-tf4447302.html#a12689105
Sent from the R help mailing list archive at Nabble.com.


From mel at altk.com  Sat Sep 15 13:50:52 2007
From: mel at altk.com (mel)
Date: Sat, 15 Sep 2007 13:50:52 +0200
Subject: [R] starting with a capital letter
In-Reply-To: <12689105.post@talk.nabble.com>
References: <12689105.post@talk.nabble.com>
Message-ID: <46EBC71C.9000900@altk.com>

kevinchang a ?crit :
> I am wondering if there is any built-in funcion that can determine whether
> words in a character vector start with a captial letter or not. Help,
> please. Thanks.

DIY with tolower().
apply tolower() on 1st letter and compare.


From Ted.Harding at manchester.ac.uk  Sat Sep 15 13:55:03 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Sat, 15 Sep 2007 12:55:03 +0100 (BST)
Subject: [R] starting with a capital letter
In-Reply-To: <12689105.post@talk.nabble.com>
Message-ID: <XFMail.070915125503.Ted.Harding@manchester.ac.uk>

On 15-Sep-07 10:21:19, kevinchang wrote:
> 
> Hi everyone,
> 
> I am wondering if there is any built-in funcion that can
> determine whether words in a character vector start with
> a captial letter or not. Help, please. Thanks.

Something like:

C<-c("Abc", "aBc", "abC")

for(i in (1:length(C))){
 if(length(grep("^[A-Z]",C[i]))>0){
   print("Yes") else print("No")
  }
}


[1] "Yes"
[1] "No"
[1] "No"


The "grep" expression "[A-Z]" looks for one of A,B,C,...,Z
and the "^" makes it look for it at the start of the string.

Hoping this helps,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 15-Sep-07                                       Time: 12:55:00
------------------------------ XFMail ------------------------------


From ggrothendieck at gmail.com  Sat Sep 15 14:03:25 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 15 Sep 2007 08:03:25 -0400
Subject: [R] HTML reading,
In-Reply-To: <12688719.post@talk.nabble.com>
References: <12688719.post@talk.nabble.com>
Message-ID: <971536df0709150503ua246e9fy70b3a6294cb0522a@mail.gmail.com>

Check out:

https://stat.ethz.ch/pipermail/r-help/2007-August/137742.html

On 9/15/07, christophe vuadens <christophe.vuadens at unil.ch> wrote:
>
> Hello,
>
> Sorry for my english, in a R function, I want to read HTML files to analyse
> the text.  Do somebody now, how can i read the text only in txt Foirmat...
>
> Thanks
> --
> View this message in context: http://www.nabble.com/HTML-reading%2C-tf4447190.html#a12688719
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From schaefer at pointone.de  Sat Sep 15 12:41:31 2007
From: schaefer at pointone.de (=?ISO-8859-1?Q?Christian_Sch=E4fer?=)
Date: Sat, 15 Sep 2007 12:41:31 +0200
Subject: [R] Class probabilities in rpart
Message-ID: <46EBB6DB.6030000@pointone.de>

Hi,

the predict.rpart() function from the rpart library allows for 
calculating the class probabilities for a given test case instead of a 
discrete class label.

How are these class probabilities derived? Is it simply the proportion 
of the majority class to all cases in a leaf node?

Thanks in advance,
Chris


From daniel at umd.edu  Sat Sep 15 02:24:20 2007
From: daniel at umd.edu (Daniel Malter)
Date: Fri, 14 Sep 2007 20:24:20 -0400
Subject: [R]  Survival model (time to event data)
In-Reply-To: <2039.129.128.246.84.1189622319.squirrel@mail.ctfc.es>
Message-ID: <200709150023.DAB29938@md0.mail.umd.edu>

High all, I would appreciate input about how the following survival model
can be modeled in R and how competing risk models can generally be modeled.
Also I would appreciate hints about resources that you are aware of that
explain the use of survival models in R in greater detail. 

The data structure of my data is plotted below. My problem is that I don't
know how to model 4 different events in the same hazard model for which the
hazards are conditional on some other factor.

Conditions: 

0. All events are mutually exclusive
1. Either no event, Event1, or one of the Events 2-4 occurs (i.e. events 2-4
are competing)
2. Event1 can only occur if St.Beg=0 (it switches St.End from this period
and St.Beg from the following periods on to 1 until Event4 occurs).
3. Event2-4 can only occur if St.Beg=1

Time	St.Beg	St.End	Event1	Event2	Event3	Event4	Number
1	0	0	0	0	0	0	0
2	0	0	0	0	0	0	0
3	0	1	1	0	0	0	0
4	1	1	0	0	0	0	10
5	1	1	0	1	0	0	10
6	1	1	0	1	0	0	15
7	1	1	0	0	0	0	20
8	1	1	0	0	0	0	20
9	1	1	0	0	1	0	10
10	1	0	0	0	0	1	0

Thanks much for your help,
Daniel





-------------------------
cuncta stricte discussurus


From fgaravito at guggenheimadvisors.com  Fri Sep 14 22:24:58 2007
From: fgaravito at guggenheimadvisors.com (Garavito,Fabian)
Date: Fri, 14 Sep 2007 16:24:58 -0400
Subject: [R] Storing Variables of different types
Message-ID: <BA9B873BB7132F4B8853E1DE580C30194FBA02@MGEXCLP1.investment.boi>


Hi there,

I have an ixjxk array where I want to store dates in the first column of
all sub-matrices (i.e. j=1 is a column with dates) and real numbers in
the rest of the columns.......I have been trying many things, but I am
not getting anywhere. 

Thank you very much for your help,

Fabian


This message and any attachment are confidential and may be privileged or otherwise protected  from disclosure. If you are not the intended recipient, please telephone or email the sender and delete this message and any attachment from your system. If you are not the intended recipient you must not copy this message or attachment or disclose the contents to any other person. Nothing contained in the attached email shall be regarded as an offer to sell or as a solicitation of an offer to buy any  services, funds or products or an expression of any opinion or views of the firm or its employees. Nothing contained in the attached email shall be deemed to be an advise of, or recommendation by, the firm or its employees. No representation is made as to accuracy, completeness, reliability or appropriateness of the information contained in the attached email. 


From stat5122003 at hotmail.com  Sat Sep 15 00:15:49 2007
From: stat5122003 at hotmail.com (L L)
Date: Fri, 14 Sep 2007 22:15:49 +0000
Subject: [R] generate ROC curve using randomForest package
Message-ID: <BAY105-F31FCC71940576476228351EABC0@phx.gbl>

Hi,

I am new here. I would like to compare the performance of the random forest 
model with support vector machine. Can  anybody let me know how to generate 
a ROC curve for random forest model since there is no need to run the 
cross-validation. Thank you very much!

TL

_________________________________________________________________
[[replacing trailing spam]]


From schaefer at pointone.de  Sat Sep 15 15:50:57 2007
From: schaefer at pointone.de (=?ISO-8859-1?Q?Christian_Sch=E4fer?=)
Date: Sat, 15 Sep 2007 15:50:57 +0200
Subject: [R] generate ROC curve using randomForest package
In-Reply-To: <BAY105-F31FCC71940576476228351EABC0@phx.gbl>
References: <BAY105-F31FCC71940576476228351EABC0@phx.gbl>
Message-ID: <46EBE341.6050509@pointone.de>

L L wrote:

> I am new here. I would like to compare the performance of the random forest 
> model with support vector machine. Can  anybody let me know how to generate 
> a ROC curve for random forest model since there is no need to run the 
> cross-validation. Thank you very much!

The ROCR package provides performance measures like AUC, Sensitivity or 
ROC curves.
Especially the performance() function is of interest.

Chris


From mel at altk.com  Sat Sep 15 15:59:37 2007
From: mel at altk.com (mel)
Date: Sat, 15 Sep 2007 15:59:37 +0200
Subject: [R] Storing Variables of different types
In-Reply-To: <BA9B873BB7132F4B8853E1DE580C30194FBA02@MGEXCLP1.investment.boi>
References: <BA9B873BB7132F4B8853E1DE580C30194FBA02@MGEXCLP1.investment.boi>
Message-ID: <46EBE549.4080303@altk.com>

Garavito,Fabian a ?crit :

> Hi there,
> I have an ixjxk array where I want to store dates in the first column of
> all sub-matrices (i.e. j=1 is a column with dates) and real numbers in
> the rest of the columns.......I have been trying many things, but I am
> not getting anywhere. 
> Thank you very much for your help,
> Fabian

?data.frame
or think about storing dates in the rownames.


From jholtman at gmail.com  Sat Sep 15 16:06:58 2007
From: jholtman at gmail.com (jim holtman)
Date: Sat, 15 Sep 2007 10:06:58 -0400
Subject: [R] Storing Variables of different types
In-Reply-To: <BA9B873BB7132F4B8853E1DE580C30194FBA02@MGEXCLP1.investment.boi>
References: <BA9B873BB7132F4B8853E1DE580C30194FBA02@MGEXCLP1.investment.boi>
Message-ID: <644e1f320709150706jeaf2c81s67a0273b53c56dba@mail.gmail.com>

One technique that I use (with POSIXct dates) is to convert the date
to numeric so that it can be stored in an array (which must have the
same mode for all variables) and then when I need it, just convert it
back as needed.  Here is an example:

> x <- as.POSIXct("2007-09-15 13:25")
> x
[1] "2007-09-15 13:25:00 GMT"
> x.numeric <- unclass(x)
> x.numeric
[1] 1189862700
attr(,"tzone")
[1] ""
> # back to POSIXct
> x.POSIXct <- ISOdate(1970,1,1,0) + x.numeric
> x.POSIXct
[1] "2007-09-15 13:25:00 GMT"
> # or you can just change the class
> structure(x.numeric, class=c("POSIXt", "POSIXct"))
[1] "2007-09-15 13:25:00 GMT"
>


On 9/14/07, Garavito,Fabian <fgaravito at guggenheimadvisors.com> wrote:
>
> Hi there,
>
> I have an ixjxk array where I want to store dates in the first column of
> all sub-matrices (i.e. j=1 is a column with dates) and real numbers in
> the rest of the columns.......I have been trying many things, but I am
> not getting anywhere.
>
> Thank you very much for your help,
>
> Fabian
>
>
> This message and any attachment are confidential and may be privileged or otherwise protected  from disclosure. If you are not the intended recipient, please telephone or email the sender and delete this message and any attachment from your system. If you are not the intended recipient you must not copy this message or attachment or disclose the contents to any other person. Nothing contained in the attached email shall be regarded as an offer to sell or as a solicitation of an offer to buy any  services, funds or products or an expression of any opinion or views of the firm or its employees. Nothing contained in the attached email shall be deemed to be an advise of, or recommendation by, the firm or its employees. No representation is made as to accuracy, completeness, reliability or appropriateness of the information contained in the attached email.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From jholtman at gmail.com  Sat Sep 15 16:09:35 2007
From: jholtman at gmail.com (jim holtman)
Date: Sat, 15 Sep 2007 10:09:35 -0400
Subject: [R] how to change print limit on screen
In-Reply-To: <BAY134-W264AC946D28A185E98F08A3BD0@phx.gbl>
References: <BAY134-W264AC946D28A185E98F08A3BD0@phx.gbl>
Message-ID: <644e1f320709150709h33895642t7bed9952cc0e55b@mail.gmail.com>

?options

> options(max.print=10)
> 1:100000
 [1]  1  2  3  4  5  6  7  8  9 10
 [ reached getOption("max.print") -- omitted 99990 entries ]]


On 9/15/07, Abu Naser <likhonnaser at hotmail.com> wrote:
>
> Hi all user,
>
> Is there any way i can chage the print limit ( getOption("max.print")) to unlimited or specified limit?
>
> Thanks in advance
> _________________________________________________________________
> Feel like a local wherever you go.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From g_smits at verizon.net  Sat Sep 15 18:02:55 2007
From: g_smits at verizon.net (Gerard Smits)
Date: Sat, 15 Sep 2007 09:02:55 -0700
Subject: [R] applying math/stat functions to rows in data frame
Message-ID: <0JOF00EM638WGPI3@vms044.mailsrvcs.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070915/61fa96d7/attachment.pl 

From ral at lcfltd.com  Sat Sep 15 18:09:38 2007
From: ral at lcfltd.com (Robert A LaBudde)
Date: Sat, 15 Sep 2007 12:09:38 -0400
Subject: [R] applying math/stat functions to rows in data frame
In-Reply-To: <0JOF00EM638WGPI3@vms044.mailsrvcs.net>
References: <0JOF00EM638WGPI3@vms044.mailsrvcs.net>
Message-ID: <0JOF001YF3K48DM0@vms042.mailsrvcs.net>

At 12:02 PM 9/15/2007, Gerald wrote:
>Hi All,
>
>There are a variety of functions that can be applied to a variable
>(column) in a data frame: mean, min, max, sd, range, IQR, etc.
>
>I am aware of only two that work on the rows, using q1-q3 as example
>variables:
>
>rowMeans(cbind(q1,q2,q3),na.rm=T)   #mean of multiple variables
>rowSums (cbind(q1,q2,q3),na.rm=T)   #sum of multiple variables
>
>Can the standard column functions (listed in the first sentence) be
>applied to rows, with the use of correct indexes to reference the
>columns of interest?  Or, must these summary functions be programmed
>separately to work on a row?

Try using t() to transpose the matrix, and then apply the column 
function of interest.

================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From lramlal at claflin.edu  Sat Sep 15 18:11:46 2007
From: lramlal at claflin.edu (Letticia Ramlal)
Date: Sat, 15 Sep 2007 12:11:46 -0400
Subject: [R] Help with a problem
Message-ID: <A3E5A3C873C56F42B7F1A511D5F7525510C1DA@cu-ex-03.claflin.edu>

Hello 
I was wonderinf if anyone can help me with this problem, it seems trivial but for some reason I can not figure it out.
 
With a single R command complete the following:
create a vector calles seqvec that repeats the sequence 1, 3,6, 10,15,21.( I was trying to use c() but this does not work) 
create a 5-row, 6-column matirx from seqvec wuth each row containg the sequence from before 
and complete the two task above in a single step.
 
LTR


From marc_schwartz at comcast.net  Sat Sep 15 18:18:54 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Sat, 15 Sep 2007 11:18:54 -0500
Subject: [R] Help with a problem
In-Reply-To: <A3E5A3C873C56F42B7F1A511D5F7525510C1DA@cu-ex-03.claflin.edu>
References: <A3E5A3C873C56F42B7F1A511D5F7525510C1DA@cu-ex-03.claflin.edu>
Message-ID: <1189873134.6149.101.camel@Bellerophon.localdomain>

On Sat, 2007-09-15 at 12:11 -0400, Letticia Ramlal wrote:
> Hello 
> I was wonderinf if anyone can help me with this problem, it seems trivial but for some reason I can not figure it out.
>  
> With a single R command complete the following:
> create a vector calles seqvec that repeats the sequence 1, 3,6, 10,15,21.( I was trying to use c() but this does not work) 
> create a 5-row, 6-column matirx from seqvec wuth each row containg the sequence from before 
> and complete the two task above in a single step.
>  
> LTR

Is this what you want?

seqvec <- cumsum(1:6)

> seqvec
[1]  1  3  6 10 15 21


Or to address both:

> matrix(rep(cumsum(1:6), 5), ncol = 6, byrow = TRUE)
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    1    3    6   10   15   21
[2,]    1    3    6   10   15   21
[3,]    1    3    6   10   15   21
[4,]    1    3    6   10   15   21
[5,]    1    3    6   10   15   21


See ?cumsum and ?rep

HTH,

Marc Schwartz


From wgavioli at fas.harvard.edu  Sat Sep 15 18:23:23 2007
From: wgavioli at fas.harvard.edu (Wayne Aldo Gavioli)
Date: Sat, 15 Sep 2007 12:23:23 -0400
Subject: [R] Pulling out parts of a generated array in R
Message-ID: <1189873403.46ec06fb4c81b@webmail.fas.harvard.edu>

Hello all,

I was wondering if it was possible to pull out certain parts of an array in R -
not an array of data that I have created, but an array of data that has been
spit out by R itself.

More specifically, in the lines of code below:


> summary(prcomp(USArrests))
Importance of components:
                          PC1     PC2    PC3     PC4
Standard deviation     83.732 14.2124 6.4894 2.48279
Proportion of Variance  0.966  0.0278 0.0058 0.00085
Cumulative Proportion   0.966  0.9933 0.9991 1.00000



I was wondering if there is a way to only extract one piece of this array,
specifically the Proportion of Variance for PC2, which is 0.0278.  I know how
to extract one entire line of data from this array, using the following lines
of code:

> result<-summary(prcomp(USArrests))
> m<-result$importance
> final<-m[2,]


These lines of code will produce the follwing output:


0.966  0.0278 0.0058 0.00085


Now I was wondering if there is anyway to break this down even further, and be
able to extract one piece of data from this one line.

If anyone could help me out, I would really appreciate it.


Thanks,


Wayne


From ligges at statistik.uni-dortmund.de  Sat Sep 15 18:28:34 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 15 Sep 2007 18:28:34 +0200
Subject: [R] Pulling out parts of a generated array in R
In-Reply-To: <1189873403.46ec06fb4c81b@webmail.fas.harvard.edu>
References: <1189873403.46ec06fb4c81b@webmail.fas.harvard.edu>
Message-ID: <46EC0832.6000604@statistik.uni-dortmund.de>



Wayne Aldo Gavioli wrote:
> Hello all,
> 
> I was wondering if it was possible to pull out certain parts of an array in R -
> not an array of data that I have created, but an array of data that has been
> spit out by R itself.
> 
> More specifically, in the lines of code below:
> 
> 
>> summary(prcomp(USArrests))
> Importance of components:
>                           PC1     PC2    PC3     PC4
> Standard deviation     83.732 14.2124 6.4894 2.48279
> Proportion of Variance  0.966  0.0278 0.0058 0.00085
> Cumulative Proportion   0.966  0.9933 0.9991 1.00000
> 
> 
> 
> I was wondering if there is a way to only extract one piece of this array,
> specifically the Proportion of Variance for PC2, which is 0.0278.  I know how
> to extract one entire line of data from this array, using the following lines
> of code:
> 
>> result<-summary(prcomp(USArrests))
>> m<-result$importance
>> final<-m[2,]
> 
> 
> These lines of code will produce the follwing output:
> 
> 
> 0.966  0.0278 0.0058 0.00085
>
> 
> Now I was wondering if there is anyway to break this down even further, and be
> able to extract one piece of data from this one line.

I am sure you already read about matrix indexing in the manual "An 
Introduction to R", but here to remind you how easy it is to get the 
second row, third column:

final <- m[2,3]

Uwe Ligges


> 
> If anyone could help me out, I would really appreciate it.
> 
> 
> Thanks,
> 
> 
> Wayne
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at comcast.net  Sat Sep 15 18:32:11 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Sat, 15 Sep 2007 11:32:11 -0500
Subject: [R] applying math/stat functions to rows in data frame
In-Reply-To: <0JOF00EM638WGPI3@vms044.mailsrvcs.net>
References: <0JOF00EM638WGPI3@vms044.mailsrvcs.net>
Message-ID: <1189873931.6149.116.camel@Bellerophon.localdomain>

On Sat, 2007-09-15 at 09:02 -0700, Gerard Smits wrote:
> Hi All,
> 
> There are a variety of functions that can be applied to a variable 
> (column) in a data frame: mean, min, max, sd, range, IQR, etc.
> 
> I am aware of only two that work on the rows, using q1-q3 as example 
> variables:
> 
> rowMeans(cbind(q1,q2,q3),na.rm=T)   #mean of multiple variables
> rowSums (cbind(q1,q2,q3),na.rm=T)   #sum of multiple variables
> 
> Can the standard column functions (listed in the first sentence) be 
> applied to rows, with the use of correct indexes to reference the 
> columns of interest?  Or, must these summary functions be programmed 
> separately to work on a row?
> 
> Thanks,
> 
> Gerard

The answer is: it depends

If the row can be coerced to a numeric vector, then yes. This presumes
that the data frame contains a single data type or the subset of columns
you need contains a single data type.

If the row contains multiple data types, then the row becomes a single
row data frame or a list and you would have to consider other possible
approaches.

For example:

Taking the first row of the 'iris' dataset becomes a single row data
frame:

> str(iris[1, ])
'data.frame':   1 obs. of  5 variables:
 $ Sepal.Length: num 5.1
 $ Sepal.Width : num 3.5
 $ Petal.Length: num 1.4
 $ Petal.Width : num 0.2
 $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1

or if you set 'drop = TRUE', a list:

> str(iris[1, , drop = TRUE])
List of 5
 $ Sepal.Length: num 5.1
 $ Sepal.Width : num 3.5
 $ Petal.Length: num 1.4
 $ Petal.Width : num 0.2
 $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1


If however, you remove the last column Species, which is a factor, you
can coerce the remaining object to a numeric matrix:

> str(as.matrix(iris[, -5]))
 num [1:150, 1:4] 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:4] "Sepal.Length" "Sepal.Width" "Petal.Length" "Petal.Width"



Some functions will do this coercion internally:

For example:

> rowSums(iris)
Error in rowSums(x, prod(dn), p, na.rm) : 'x' must be numeric


However:

> head(rowSums(iris[, -5]))
[1] 10.2  9.5  9.4  9.4 10.2 11.4


HTH,

Marc Schwartz


From gavin.simpson at ucl.ac.uk  Sat Sep 15 18:36:32 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sat, 15 Sep 2007 17:36:32 +0100
Subject: [R] applying math/stat functions to rows in data frame
In-Reply-To: <0JOF00EM638WGPI3@vms044.mailsrvcs.net>
References: <0JOF00EM638WGPI3@vms044.mailsrvcs.net>
Message-ID: <1189874192.2897.50.camel@graptoleberis.geog.ucl.ac.uk>

On Sat, 2007-09-15 at 09:02 -0700, Gerard Smits wrote:
> Hi All,
> 
> There are a variety of functions that can be applied to a variable 
> (column) in a data frame: mean, min, max, sd, range, IQR, etc.

But one their own, these are not equivalents to rowMeans, rowSums etc
below.

> 
> I am aware of only two that work on the rows, using q1-q3 as example 
> variables:
> 
> rowMeans(cbind(q1,q2,q3),na.rm=T)   #mean of multiple variables
> rowSums (cbind(q1,q2,q3),na.rm=T)   #sum of multiple variables

If you really want to apply a function to the individual rows of a
matrix-like object then apply() is your friend:

?rowMeans states:

Details:

     These functions are equivalent to use of 'apply' with 'FUN = mean'
     or 'FUN = sum' with appropriate margins, but are a lot faster.

So see ?apply and argument 'margin'. For rows use margin = 1, e.g.:

dat <- matrix(runif(1000), ncol = 100)
apply(dat, 1, mean)
rowMeans(dat)


> 
> Can the standard column functions (listed in the first sentence) be 
> applied to rows, with the use of correct indexes to reference the 
> columns of interest?  Or, must these summary functions be programmed 
> separately to work on a row?

You can only use those functions on a column via subsetting, e.g.:

mean(dat[,4])
min(dat[,4])

If all you want is a single row (the equivalent of what you seem to be
asking) then these also work:

mean(dat[4,])
min(dat[4,])

HTH

G

> 
> Thanks,
> 
> Gerard
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From gavin.simpson at ucl.ac.uk  Sat Sep 15 18:42:58 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sat, 15 Sep 2007 17:42:58 +0100
Subject: [R] Help with a problem
In-Reply-To: <A3E5A3C873C56F42B7F1A511D5F7525510C1DA@cu-ex-03.claflin.edu>
References: <A3E5A3C873C56F42B7F1A511D5F7525510C1DA@cu-ex-03.claflin.edu>
Message-ID: <1189874578.2897.54.camel@graptoleberis.geog.ucl.ac.uk>

On Sat, 2007-09-15 at 12:11 -0400, Letticia Ramlal wrote:
> Hello 
> I was wonderinf if anyone can help me with this problem, it seems
> trivial but for some reason I can not figure it out.
>  
> With a single R command complete the following:
> create a vector calles seqvec that repeats the sequence 1, 3,6,
> 10,15,21.( I was trying to use c() but this does not work) 
> create a 5-row, 6-column matirx from seqvec wuth each row containg the
> sequence from before 
> and complete the two task above in a single step.

If that is just an example of an arbitrary sequence, then the following
does what you want:

> res <- matrix(rep(c(1,3,6,10,15,21), 5), nrow = 5, byrow = TRUE)
> res
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    1    3    6   10   15   21
[2,]    1    3    6   10   15   21
[3,]    1    3    6   10   15   21
[4,]    1    3    6   10   15   21
[5,]    1    3    6   10   15   21

But if there is something special in the quoted sequence (it is
cumsum(1:6) ), then the following also does what you want:

> res2 <- matrix(rep(cumsum(1:6), 5), nrow = 5, byrow = TRUE)
> res2
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    1    3    6   10   15   21
[2,]    1    3    6   10   15   21
[3,]    1    3    6   10   15   21
[4,]    1    3    6   10   15   21
[5,]    1    3    6   10   15   21
> all.equal(res, res2)
[1] TRUE

Take a look at ?rep and, although not needed in this case, ?seq for
generating sequences and repeats.

HTH

G

>  
> LTR
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From cberry at tajo.ucsd.edu  Sat Sep 15 19:45:35 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Sat, 15 Sep 2007 10:45:35 -0700
Subject: [R] starting with a capital letter
In-Reply-To: <12689105.post@talk.nabble.com>
References: <12689105.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0709151033460.27368@tajo.ucsd.edu>

On Sat, 15 Sep 2007, kevinchang wrote:

>
> Hi everyone,
>
> I am wondering if there is any built-in funcion that can determine whether
> words in a character vector start with a captial letter or not. Help,
> please. Thanks.

Yes. But your query is not precise. See the posting guide and provide 
commented, minimal, self-contained, reproducible code (as is requested) to 
be sure the answers you get address the question you really want answered.

I see several possiblilities.

In this vector:

 	my.charvec<- c( "Abc", "abc Abc", "abc aBc" )

You wish to match element 1 only or 1 and 2 only and perhaps report where 
in each element the last match was found.


 	res <- regexpr( "\\<[[:upper:]].*" , my.charvec )

should get you started. Examples:

 	which( res == 1 ) # first case

 	which( res != -1 ) # second case

See

 	?regexpr

Also,

 	?strsplit

which I think would be needed to recover the locations of each of 
several capitalized words in a single element. e.g. "abc Def Ghi"

Chuck

> -- 
> View this message in context: http://www.nabble.com/starting-with-a-capital-letter-tf4447302.html#a12689105
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From ssls.sddd at gmail.com  Sat Sep 15 22:36:06 2007
From: ssls.sddd at gmail.com (ssls sddd)
Date: Sat, 15 Sep 2007 13:36:06 -0700
Subject: [R] Question about VarSelRF
Message-ID: <b87120290709151336t265576bet1bba18a100470d86@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070915/05c05547/attachment.pl 

From shukai at seas.upenn.edu  Sun Sep 16 00:56:04 2007
From: shukai at seas.upenn.edu (kevinchang)
Date: Sat, 15 Sep 2007 15:56:04 -0700 (PDT)
Subject: [R] naming columns of data frame
Message-ID: <12694795.post@talk.nabble.com>


Hey,

I am trying to make a data frame and the name of a column is composed of a
number, a dot, and a word, such as "1.whatever". But I always get this error
message:"syntax error, unexpected SYMBOL, expecting ',' in:" while printing
data frame out . When I rename the column with purely letter, everything
works fine. Some suggestion about the cause/ solution ?? Thanks.
-- 
View this message in context: http://www.nabble.com/naming-columns-of-data-frame-tf4449324.html#a12694795
Sent from the R help mailing list archive at Nabble.com.


From kate at few.vu.nl  Sun Sep 16 01:28:45 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Sun, 16 Sep 2007 01:28:45 +0200 (CEST)
Subject: [R] naming columns of data frame
In-Reply-To: <12694795.post@talk.nabble.com>
References: <12694795.post@talk.nabble.com>
Message-ID: <Pine.GSO.4.56.0709160125400.21040@laurel.few.vu.nl>

when I try what you describe there is no problem -maybe send a
reproducible example.

> x<-data.frame(matrix(2,2,2))
> colnames(x) <- c("1.xx", "2.xx")
> x
  1.xx 2.xx
1    2    2
2    2    2


On Sat, 15 Sep 2007, kevinchang wrote:

>
> Hey,
>
> I am trying to make a data frame and the name of a column is composed of a
> number, a dot, and a word, such as "1.whatever". But I always get this error
> message:"syntax error, unexpected SYMBOL, expecting ',' in:" while printing
> data frame out . When I rename the column with purely letter, everything
> works fine. Some suggestion about the cause/ solution ?? Thanks.
> --
> View this message in context: http://www.nabble.com/naming-columns-of-data-frame-tf4449324.html#a12694795
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From cberry at tajo.ucsd.edu  Sun Sep 16 01:47:16 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Sat, 15 Sep 2007 16:47:16 -0700
Subject: [R] starting with a capital letter
In-Reply-To: <Pine.LNX.4.64.0709151033460.27368@tajo.ucsd.edu>
References: <12689105.post@talk.nabble.com>
	<Pine.LNX.4.64.0709151033460.27368@tajo.ucsd.edu>
Message-ID: <Pine.LNX.4.64.0709151645550.28015@tajo.ucsd.edu>


Two corrections to my previous posting.

On Sat, 15 Sep 2007, Charles C. Berry wrote:

> On Sat, 15 Sep 2007, kevinchang wrote:
>
>>
>> Hi everyone,
>>
>> I am wondering if there is any built-in funcion that can determine whether
>> words in a character vector start with a captial letter or not. Help,
>> please. Thanks.
>
> Yes. But your query is not precise. See the posting guide and provide
> commented, minimal, self-contained, reproducible code (as is requested) to
> be sure the answers you get address the question you really want answered.
>
> I see several possiblilities.
>
> In this vector:
>
> 	my.charvec<- c( "Abc", "abc Abc", "abc aBc" )
>
> You wish to match element 1 only or 1 and 2 only and perhaps report where
> in each element the last match was found.

Better make that 'first' match

>
>
> 	res <- regexpr( "\\<[[:upper:]].*" , my.charvec )
>
> should get you started. Examples:
>
> 	which( res == 1 ) # first case
>
> 	which( res != -1 ) # second case
>
> See
>
> 	?regexpr
>
> Also,
>
> 	?strsplit
>
> which I think would be needed to recover the locations of each of
> several capitalized words in a single element. e.g. "abc Def Ghi"
>

Not!

 	res <- gregexpr( "\\<[[:upper:]]" , my.charvec )

will do just fine.

> Chuck
>
>> --
>> View this message in context: http://www.nabble.com/starting-with-a-capital-letter-tf4447302.html#a12689105
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> Charles C. Berry                            (858) 534-2098
>                                             Dept of Family/Preventive Medicine
> E mailto:cberry at tajo.ucsd.edu	            UC San Diego
> http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From wwwhsd at gmail.com  Sun Sep 16 02:22:20 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Sat, 15 Sep 2007 21:22:20 -0300
Subject: [R] naming columns of data frame
In-Reply-To: <12694795.post@talk.nabble.com>
References: <12694795.post@talk.nabble.com>
Message-ID: <da79af330709151722k35275bbbx6b541e1e4c016f1c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070915/259e7c52/attachment.pl 

From liuwensui at gmail.com  Sun Sep 16 03:44:25 2007
From: liuwensui at gmail.com (Wensui Liu)
Date: Sat, 15 Sep 2007 21:44:25 -0400
Subject: [R] are hurdle logit-poisson model and posson model nested?
Message-ID: <1115a2b00709151844v2ccda7davc457648a9f7e41e5@mail.gmail.com>

Dear Listers,
I have a general statistical question. Are hurdle logit-poisson model
and posson model nested?
Thank you so much?


From tkobayas at indiana.edu  Sun Sep 16 04:01:56 2007
From: tkobayas at indiana.edu (tkobayas at indiana.edu)
Date: Sat, 15 Sep 2007 22:01:56 -0400
Subject: [R] (no subject)
Message-ID: <20070915220156.wh3r139pxcscg448@webmail.iu.edu>

Hi,

Let me apologize for this simple question.

I use 64 bit R on my Fedora Core 6 Linux workstation. A 64 bit R has 
saved a lot of time. I am sure this is a lot to do with my memory 
limit, but I cannot import 4.8GB. My workstation has a 8GB RAM, Athlon 
X2 5600, and 1200W PSU. This PC configuration is the best I could get.

I know a bit of C and Perl. Should I use C or Perl to manage this large 
dataset? or should I even go to 16GB RAM.

Sorry for this silly question. But I appreciate if anyone could give me 
advice.

Thank you very much.

TK


From tkobayas at indiana.edu  Sun Sep 16 04:03:00 2007
From: tkobayas at indiana.edu (tkobayas at indiana.edu)
Date: Sat, 15 Sep 2007 22:03:00 -0400
Subject: [R] my previous message: Memory Management
Message-ID: <20070915220300.nyixxxsutc0008s0@webmail.iu.edu>

Hi,

I obviously did not include the subject title. I am looking for memory 
management on a 64 bit machine.

Thank you.

TK


From jholtman at gmail.com  Sun Sep 16 05:41:46 2007
From: jholtman at gmail.com (jim holtman)
Date: Sat, 15 Sep 2007 23:41:46 -0400
Subject: [R] (no subject)
In-Reply-To: <20070915220156.wh3r139pxcscg448@webmail.iu.edu>
References: <20070915220156.wh3r139pxcscg448@webmail.iu.edu>
Message-ID: <644e1f320709152041r2460be84j64581f4c52e94131@mail.gmail.com>

When you say you can not import 4.8GB, is this the size of the text
file that you are reading in?  If so, what is the structure of the
file?  How are you reading in the file ('read.table', 'scan', etc).

Do you really need all the data or can you work with a portion at a
time?  If so, then consider putting the data in a database and
retrieving the data as needed.  If all the data is in an object, how
big to you think this object will be? (# rows, # columns, mode of the
data).

So you need to provide some more information as to the problem that
you are trying to solve.

On 9/15/07, tkobayas at indiana.edu <tkobayas at indiana.edu> wrote:
> Hi,
>
> Let me apologize for this simple question.
>
> I use 64 bit R on my Fedora Core 6 Linux workstation. A 64 bit R has
> saved a lot of time. I am sure this is a lot to do with my memory
> limit, but I cannot import 4.8GB. My workstation has a 8GB RAM, Athlon
> X2 5600, and 1200W PSU. This PC configuration is the best I could get.
>
> I know a bit of C and Perl. Should I use C or Perl to manage this large
> dataset? or should I even go to 16GB RAM.
>
> Sorry for this silly question. But I appreciate if anyone could give me
> advice.
>
> Thank you very much.
>
> TK
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From rwan at kuicr.kyoto-u.ac.jp  Sun Sep 16 06:04:42 2007
From: rwan at kuicr.kyoto-u.ac.jp (Raymond Wan)
Date: Sun, 16 Sep 2007 13:04:42 +0900
Subject: [R] Plotting (vector,matrix)
Message-ID: <46ECAB5A.2090503@kuicr.kyoto-u.ac.jp>


Hi all,

I'm still a bit new to R and I'm trying to figure something out.  I have 
the solution but the solution is what a C programmer would do :-) and I 
was wondering if someone could tell me the R way of doing it...

What I have is a vector x of length |x|.  And a matrix y of size m rows 
and n columns where n = |x|.  I want to plot m * n points on a graph so 
that the x-coordinates are from x and the y coordinates are from y.

I can plot x with the mean of each column of y as:  plot (x,mean(y)).  
But, to do what I want,  I had to write this pair of for loops:

for (i in 1:dim(y)[1]) {
  for (j in 1:length(x)) {
    points(x[j],y[i,j])
  }
}

to add the points.  I think there must be a better way using some 
variant of apply or matlines.  Even after reading the docs, I'm still 
scratching my head a bit...  Or maybe I copy x out so that it is of size 
m by n?!?  Any thoughts on what an R user would do here?  Thanks!

Ray


From jholtman at gmail.com  Sun Sep 16 06:11:26 2007
From: jholtman at gmail.com (jim holtman)
Date: Sun, 16 Sep 2007 00:11:26 -0400
Subject: [R] Plotting (vector,matrix)
In-Reply-To: <46ECAB5A.2090503@kuicr.kyoto-u.ac.jp>
References: <46ECAB5A.2090503@kuicr.kyoto-u.ac.jp>
Message-ID: <644e1f320709152111k1458e3d4sda531f509edfe2d1@mail.gmail.com>

matplot(x,y)

On 9/16/07, Raymond Wan <rwan at kuicr.kyoto-u.ac.jp> wrote:
>
> Hi all,
>
> I'm still a bit new to R and I'm trying to figure something out.  I have
> the solution but the solution is what a C programmer would do :-) and I
> was wondering if someone could tell me the R way of doing it...
>
> What I have is a vector x of length |x|.  And a matrix y of size m rows
> and n columns where n = |x|.  I want to plot m * n points on a graph so
> that the x-coordinates are from x and the y coordinates are from y.
>
> I can plot x with the mean of each column of y as:  plot (x,mean(y)).
> But, to do what I want,  I had to write this pair of for loops:
>
> for (i in 1:dim(y)[1]) {
>  for (j in 1:length(x)) {
>    points(x[j],y[i,j])
>  }
> }
>
> to add the points.  I think there must be a better way using some
> variant of apply or matlines.  Even after reading the docs, I'm still
> scratching my head a bit...  Or maybe I copy x out so that it is of size
> m by n?!?  Any thoughts on what an R user would do here?  Thanks!
>
> Ray
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From tkobayas at indiana.edu  Sun Sep 16 06:19:40 2007
From: tkobayas at indiana.edu (Takatsugu Kobayashi)
Date: Sun, 16 Sep 2007 00:19:40 -0400
Subject: [R] Memory management
In-Reply-To: <644e1f320709152041r2460be84j64581f4c52e94131@mail.gmail.com>
References: <20070915220156.wh3r139pxcscg448@webmail.iu.edu>
	<644e1f320709152041r2460be84j64581f4c52e94131@mail.gmail.com>
Message-ID: <46ECAEDC.6040106@indiana.edu>

Hi,

I apologize again for posting something not suitable on this list.

Basically, it sounds like I should go put this large dataset into a 
database... The dataset I have had trouble with is the transportation 
network of Chicago Consolidated Metropolitan Statistical Area. The 
number of samples is about 7,200 points; and every points have outbound 
and inbound traffic flows: volumes, times, distances, etc. So a quick 
approximation of the number of rows would be
49,000,000 rows (and 249 columns).

This is a text file. I could work with a portion of the data at a time 
like nearest neighbors or pairs of points.

I used read.table('filename',header=F).. I should probably use some bits 
of data at a time instead of putting all at a time...

I am learning RSQLite and RMySQL. As Mr. Wan suggests, I will learn C a 
bit more.....

Thank you very much.

TK

im holtman wrote:
> When you say you can not import 4.8GB, is this the size of the text
> file that you are reading in?  If so, what is the structure of the
> file?  How are you reading in the file ('read.table', 'scan', etc).
>
> Do you really need all the data or can you work with a portion at a
> time?  If so, then consider putting the data in a database and
> retrieving the data as needed.  If all the data is in an object, how
> big to you think this object will be? (# rows, # columns, mode of the
> data).
>
> So you need to provide some more information as to the problem that
> you are trying to solve.
>
> On 9/15/07, tkobayas at indiana.edu <tkobayas at indiana.edu> wrote:
>   
>> Hi,
>>
>> Let me apologize for this simple question.
>>
>> I use 64 bit R on my Fedora Core 6 Linux workstation. A 64 bit R has
>> saved a lot of time. I am sure this is a lot to do with my memory
>> limit, but I cannot import 4.8GB. My workstation has a 8GB RAM, Athlon
>> X2 5600, and 1200W PSU. This PC configuration is the best I could get.
>>
>> I know a bit of C and Perl. Should I use C or Perl to manage this large
>> dataset? or should I even go to 16GB RAM.
>>
>> Sorry for this silly question. But I appreciate if anyone could give me
>> advice.
>>
>> Thank you very much.
>>
>> TK
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>     
>
>
>


From rwan at kuicr.kyoto-u.ac.jp  Sun Sep 16 06:27:02 2007
From: rwan at kuicr.kyoto-u.ac.jp (Raymond Wan)
Date: Sun, 16 Sep 2007 13:27:02 +0900
Subject: [R] Plotting (vector,matrix)
In-Reply-To: <644e1f320709152111k1458e3d4sda531f509edfe2d1@mail.gmail.com>
References: <46ECAB5A.2090503@kuicr.kyoto-u.ac.jp>
	<644e1f320709152111k1458e3d4sda531f509edfe2d1@mail.gmail.com>
Message-ID: <46ECB096.4050007@kuicr.kyoto-u.ac.jp>

jim holtman wrote:
> matplot(x,y)
>
>   

Ah, thanks -- I got it working!  Actually, I was getting a "must have 
the same number of rows" error since x has the same number of columns as 
y, but x itself is a single row.  This worked for me when I transposed 
y...which is ok for my problem:

matplot(x,t(y))

Thanks!

Ray


From jholtman at gmail.com  Sun Sep 16 06:36:21 2007
From: jholtman at gmail.com (jim holtman)
Date: Sun, 16 Sep 2007 00:36:21 -0400
Subject: [R] Memory management
In-Reply-To: <46ECAEDC.6040106@indiana.edu>
References: <20070915220156.wh3r139pxcscg448@webmail.iu.edu>
	<644e1f320709152041r2460be84j64581f4c52e94131@mail.gmail.com>
	<46ECAEDC.6040106@indiana.edu>
Message-ID: <644e1f320709152136q70d79771g535151755bc30171@mail.gmail.com>

If you data file has 49M rows and 249 columns, then if each column had
5 characters, then you are looking at a text file with 60GB.  If these
were all numerics (8 bytes per number), then you are looking at an R
object that would be almost 100GB.  If this is your data, then this is
definitely a candidate for a data base since you would need a fairly
large machine (at least 300GB of real memory).

You probably need to give some serious thought to how you want to
store your data and then what type of processing you need to do on it.
BTW, do you need all 249 columns, or could you work with just 3-4
columns at a time (this at least makes an R object of about 1.5GB
which might be easier to handle).

On 9/16/07, Takatsugu Kobayashi <tkobayas at indiana.edu> wrote:
> Hi,
>
> I apologize again for posting something not suitable on this list.
>
> Basically, it sounds like I should go put this large dataset into a
> database... The dataset I have had trouble with is the transportation
> network of Chicago Consolidated Metropolitan Statistical Area. The
> number of samples is about 7,200 points; and every points have outbound
> and inbound traffic flows: volumes, times, distances, etc. So a quick
> approximation of the number of rows would be
> 49,000,000 rows (and 249 columns).
>
> This is a text file. I could work with a portion of the data at a time
> like nearest neighbors or pairs of points.
>
> I used read.table('filename',header=F).. I should probably use some bits
> of data at a time instead of putting all at a time...
>
> I am learning RSQLite and RMySQL. As Mr. Wan suggests, I will learn C a
> bit more.....
>
> Thank you very much.
>
> TK
>
> im holtman wrote:
> > When you say you can not import 4.8GB, is this the size of the text
> > file that you are reading in?  If so, what is the structure of the
> > file?  How are you reading in the file ('read.table', 'scan', etc).
> >
> > Do you really need all the data or can you work with a portion at a
> > time?  If so, then consider putting the data in a database and
> > retrieving the data as needed.  If all the data is in an object, how
> > big to you think this object will be? (# rows, # columns, mode of the
> > data).
> >
> > So you need to provide some more information as to the problem that
> > you are trying to solve.
> >
> > On 9/15/07, tkobayas at indiana.edu <tkobayas at indiana.edu> wrote:
> >
> >> Hi,
> >>
> >> Let me apologize for this simple question.
> >>
> >> I use 64 bit R on my Fedora Core 6 Linux workstation. A 64 bit R has
> >> saved a lot of time. I am sure this is a lot to do with my memory
> >> limit, but I cannot import 4.8GB. My workstation has a 8GB RAM, Athlon
> >> X2 5600, and 1200W PSU. This PC configuration is the best I could get.
> >>
> >> I know a bit of C and Perl. Should I use C or Perl to manage this large
> >> dataset? or should I even go to 16GB RAM.
> >>
> >> Sorry for this silly question. But I appreciate if anyone could give me
> >> advice.
> >>
> >> Thank you very much.
> >>
> >> TK
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
> >
> >
>
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From p.dalgaard at biostat.ku.dk  Sun Sep 16 10:01:40 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun, 16 Sep 2007 10:01:40 +0200
Subject: [R] starting with a capital letter
In-Reply-To: <Pine.LNX.4.64.0709151645550.28015@tajo.ucsd.edu>
References: <12689105.post@talk.nabble.com>	<Pine.LNX.4.64.0709151033460.27368@tajo.ucsd.edu>
	<Pine.LNX.4.64.0709151645550.28015@tajo.ucsd.edu>
Message-ID: <46ECE2E4.20707@biostat.ku.dk>

Charles C. Berry wrote:
> Two corrections to my previous posting.
>   
>> ......
>
> Not!
>
>  	res <- gregexpr( "\\<[[:upper:]]" , my.charvec )
>
> will do just fine.
>   
Thanks for sorting this out, Chuck. Let me just highlight the fact that
[[:upper:]]
is much superior to [A-Z] for those of us using languages with non-ASCII 
characters in them.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From megh700004 at yahoo.com  Sun Sep 16 10:46:23 2007
From: megh700004 at yahoo.com (Megh Dal)
Date: Sun, 16 Sep 2007 01:46:23 -0700 (PDT)
Subject: [R] Putting column names in some automated way
Message-ID: <635713.70135.qm@web58111.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070916/dbedc5cc/attachment.pl 

From bernd.weiss at uni-koeln.de  Sun Sep 16 11:01:17 2007
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Sun, 16 Sep 2007 11:01:17 +0200
Subject: [R] Putting column names in some automated way
In-Reply-To: <635713.70135.qm@web58111.mail.re3.yahoo.com>
References: <635713.70135.qm@web58111.mail.re3.yahoo.com>
Message-ID: <46ECF0DD.3000506@uni-koeln.de>

Megh Dal schrieb:
> Dear all,
> 
> I have following codes:
> 
> colnames(data) = c("var", "var", "var")
> i = c(1,2,3)
> 
> Now I want construct a "for" loop starting from 1 to 3 to give the new names of columns for dataframe "data" like below
> 
> colnames(data) 
>> c("var1", "var2", "var3")
> 
> Definitely I could do this manually, however I want to put this in a automated way so that I can do this for any number of columns.
> 

x <- data.frame(c(1,2),c(3,4),c(5,6))
colnames(x) <- rep("var",3)
colnames(x) <- paste(colnames(x),1:dim(x)[2],sep = "")


## Maybe, you want your own very simple function for renaming
## a data frame...
myRename <- function(df){
	colnames(df) <- paste(colnames(df),1:dim(df)[2],sep = "")
	return(df)
}

x <- data.frame(c(1,2), c(3,4), c(5,6), c(5,6), c(5,6))
colnames(x) <- rep("var",5)
myRename(x)


HTH,

Bernd


From christophe.vuadens at unil.ch  Sun Sep 16 13:49:24 2007
From: christophe.vuadens at unil.ch (christophe vuadens)
Date: Sun, 16 Sep 2007 04:49:24 -0700 (PDT)
Subject: [R] HTML reading,
In-Reply-To: <a695fbee0709150240n58f03db5n8ffb9c66326d112b@mail.gmail.com>
References: <12688719.post@talk.nabble.com>
	<a695fbee0709150240n58f03db5n8ffb9c66326d112b@mail.gmail.com>
Message-ID: <12698972.post@talk.nabble.com>


Thanks to your answer,

?'m trying to instaling it...


Armin Goralczyk wrote:
> 
> On 9/15/07, christophe vuadens <christophe.vuadens at unil.ch> wrote:
>>
>> Hello,
>>
>> Sorry for my english, in a R function, I want to read HTML files to
>> analyse
>> the text.  Do somebody now, how can i read the text only in txt
>> Foirmat...
>>
>> Thanks
>> --
> 
> Have a look at this:
> 
> http://gking.harvard.edu/readme/
> 
> I don't know how they strip the html tags exactly, but it is described
> in the documents there. This is also a good tool for text analysis.
> 
> -- 
> Armin Goralczyk, M.D.
> Dept. of General Surgery
> University of G?ttingen
> G?ttingen, Germany
> http://www.chirurgie-goettingen.de
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/HTML-reading%2C-tf4447190.html#a12698972
Sent from the R help mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Sun Sep 16 14:11:18 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 Sep 2007 13:11:18 +0100 (BST)
Subject: [R] predict.arima
In-Reply-To: <BAY113-F20D61B0F39B5365CF1F935B9C60@phx.gbl>
References: <BAY113-F20D61B0F39B5365CF1F935B9C60@phx.gbl>
Message-ID: <Pine.LNX.4.64.0709161306430.1548@gannet.stats.ox.ac.uk>

On Sat, 8 Sep 2007, shao ran wrote:

> Hi *,
>
> Firstly, thank you so much for your time to read my email.
>
> I am currently interested in how to use R to predict time series from
> models fitted by ARIMA. The package I used is basic stats package, and the
> method I used is predict.Arima.
>
> What I know is that ARIMA parameters are estimated by Kalman Filter, but I
> have difficulty in understanding how exactly maximum likelihood (ML)
> estimator can be computed based on Kalman Filter, i.e. given a time series
> and an ARIMA model, how can I compute the ARIMA parameters for prediction.
>
> Could you please give me some help or provide some materials for it?

The help pages have references, so we already 'provide some materials'. 
This is standard theory for time series, and the Durbin-Koopman reference 
on those pages is a comprehensive monograph on the subject.

Finally, R is Open Source so we also provide the definitive reference, 
the sources.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sun Sep 16 14:45:46 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 Sep 2007 13:45:46 +0100 (BST)
Subject: [R] Create a "local" repository
In-Reply-To: <46E79A61.5000602@statistik.uni-dortmund.de>
References: <793e846d0709112106l5c97d393g573950a9d07556e2@mail.gmail.com>
	<46E79A61.5000602@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.64.0709161342590.6917@gannet.stats.ox.ac.uk>

On Wed, 12 Sep 2007, Uwe Ligges wrote:

>
>
> Scott Hyde wrote:
>> I'd like to create a small "local" repository that would be used to
>> install a package for a class of students at their home.  I don't want
>> to upload it to CRAN, as I don't think it should be disseminated at
>> that level.
>>
>> What I'd like to do is:
>>
>>> where="http://mysite.com/"
>>> install.packages("mypackage",contriburl=where)
>>
>> When I try this, (after placing my mypackage_1.0.tar.gz file in the
>> main directory of http://mysite.com/, it responds, in R, when I want
>> to install the package:
>>
>> Warning: unable to access index for repository http://mysite.com/
>>
>> What do I need to do?
>
> You need a PACKAGES file in that directory that gives an index which
> packages are available.
>
> See function write_PACKAGES() in package "tools".

See also the section on 'Setting up a package repository' in the R-admin 
manual.  Using 'contriburl' is _not_ setting up a repository, and one 
might as well do it properly and benefit from e.g. the automatic searching 
of multiple repositories.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From shukai at seas.upenn.edu  Sun Sep 16 15:25:03 2007
From: shukai at seas.upenn.edu (kevinchang)
Date: Sun, 16 Sep 2007 06:25:03 -0700 (PDT)
Subject: [R] stalled loop
Message-ID: <12699524.post@talk.nabble.com>


Hi, 

The loop I wrote executes correctly but  is stalled seriously. Is there a
way to hasten execution without coming up with a  brand new algorithm ? 
please help. Thanks.
-- 
View this message in context: http://www.nabble.com/stalled-loop-tf4451301.html#a12699524
Sent from the R help mailing list archive at Nabble.com.


From jholtman at gmail.com  Sun Sep 16 16:42:13 2007
From: jholtman at gmail.com (jim holtman)
Date: Sun, 16 Sep 2007 10:42:13 -0400
Subject: [R] stalled loop
In-Reply-To: <12699524.post@talk.nabble.com>
References: <12699524.post@talk.nabble.com>
Message-ID: <644e1f320709160742t647d0384qa82038e0d9408b25@mail.gmail.com>

You will have to supply a lot more information than you have.  Is it a
memory problem (are you paging), is it a function of your data
structure, is it your algorithm, etc.

Please follow the guidelines: "provide commented, minimal,
self-contained, reproducible code."

On 9/16/07, kevinchang <shukai at seas.upenn.edu> wrote:
>
> Hi,
>
> The loop I wrote executes correctly but  is stalled seriously. Is there a
> way to hasten execution without coming up with a  brand new algorithm ?
> please help. Thanks.
> --
> View this message in context: http://www.nabble.com/stalled-loop-tf4451301.html#a12699524
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From Pedro.Rodriguez at sungard.com  Sun Sep 16 17:18:42 2007
From: Pedro.Rodriguez at sungard.com (Pedro.Rodriguez at sungard.com)
Date: Sun, 16 Sep 2007 11:18:42 -0400
Subject: [R] Factorial, L-moments, and overflows
Message-ID: <DD14FDFE1F072D47B2F1F4D890DFB2C5015DF9CE@VOO-EXCHANGE01.internal.sungard.corp>

Hi everyone,

In the package POT, there is a function that computes the L-moments of a given sample (samlmu). However, to compute those L-moments, one needs to obtain the total number of combinations between two numbers, which, by the way, requires the use of a factorial. See, for example, Hosking (1990 , p. 113).

How does the function "samlmu" in the package POT avoids overflows?

I was trying to build from scratch a R function similar to "samlmu" and ran into overflows (Just for my educational purposes :o) ). Is there a trick that I am missing to avoid overflows in the factorial function? 

Thank you very much for your time. 

Pedro N. Rodriguez
SSRN Homepage: http://ssrn.com/author=412141/ 
Homepage: http://www.pnrodriguez.com/


From shukai at seas.upenn.edu  Sun Sep 16 17:46:53 2007
From: shukai at seas.upenn.edu (kevinchang)
Date: Sun, 16 Sep 2007 08:46:53 -0700 (PDT)
Subject: [R] stalled loop
Message-ID: <12708590.post@talk.nabble.com>


Hey everyone,

The code I wrote executes correctly but  is stalled seriously. Is there a
way to hasten execution without coming up with a  brand new algorithm
?please help. Thanks a lot for your time.


#a simplified version of the code

a<-c("superman" , "xman" , "spiderman" ,"wolfman" ,"mansuper","manspider" )
b<-sapply(a,function(.srt){paste(sort(strsplit(.srt,'')[[1]]),
collapse="")})
c<-NA 
for(i in 1:length(b)) {
if(length(which(b==b[i]))>1)
c[i]<-b[i]
}
c<-c[!is.na(c)]
# But if my get the volumne of "a" up to about 150000 words , the loop will
work incredibly slowly.

-- 
View this message in context: http://www.nabble.com/stalled-loop-tf4456879.html#a12708590
Sent from the R help mailing list archive at Nabble.com.


From gavin.simpson at ucl.ac.uk  Sun Sep 16 18:24:29 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sun, 16 Sep 2007 17:24:29 +0100
Subject: [R] stalled loop
In-Reply-To: <12708590.post@talk.nabble.com>
References: <12708590.post@talk.nabble.com>
Message-ID: <1189959869.2973.11.camel@graptoleberis.geog.ucl.ac.uk>

On Sun, 2007-09-16 at 08:46 -0700, kevinchang wrote:
> Hey everyone,
> 
> The code I wrote executes correctly but  is stalled seriously. Is there a
> way to hasten execution without coming up with a  brand new algorithm
> ?please help. Thanks a lot for your time.
> 
> 
> #a simplified version of the code

Simple thing to do first is pre-allocate your storage. When you do:

c <- NA

You have a vector of length 1. Then in the loop, you extend C by 1 each
time/iteration. To do this, R has to copy c and then replace it. If you
set c to be the correct size in the first place, R doesn't have to do
all this copying and replacing and is much faster as a result.

If have modified your script as follows:

a <- c("superman", "xman", "spiderman", "wolfman", "mansuper", "manspider")
## uncomment the below to test how it scales
#a <- rep(a, 150000)
b <- sapply(a, function(.srt) {paste(sort(strsplit(.srt, '')[[1]]),
            collapse="")})
## store number of iterations we will do
n.loop <- 1:length(b)
## use this to allocate storage space for c
c <- numeric(length = n.loop)
for(i in seq(along = c)) {
    if(length(which(b == b[i])) > 1)
    c[i] <- b[i]
}
c <- c[!is.na(c)]

which when timed using system.time() with a now being a vector of 900000
strings (a repeated 150000 times in this case), I got the following
timings:

   user  system elapsed 
121.752   0.341 122.712 

So 121 seconds on my laptop with 2GB of RAM is not bad for such a sized
problem.

Some further comments. Don't use 'c' as a variable name, it won't over
write the c() function but it is a bit confusing to use objects with
names the same as functions. Second, *space out your code* - what you
wrote is very difficult to parse for a human - you'll find it easier to
see mistakes etc if you spread stuff out a bit.

HTH

G

> 
> a<-c("superman" , "xman" , "spiderman" ,"wolfman" ,"mansuper","manspider" )
> b<-sapply(a,function(.srt){paste(sort(strsplit(.srt,'')[[1]]),
> collapse="")})
> c<-NA 
> for(i in 1:length(b)) {
> if(length(which(b==b[i]))>1)
> c[i]<-b[i]
> }
> c<-c[!is.na(c)]
> # But if my get the volumne of "a" up to about 150000 words , the loop will
> work incredibly slowly.
> 
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From lramlal at claflin.edu  Sun Sep 16 18:44:55 2007
From: lramlal at claflin.edu (Letticia Ramlal)
Date: Sun, 16 Sep 2007 12:44:55 -0400
Subject: [R] Identifying objects from a data set
Message-ID: <A3E5A3C873C56F42B7F1A511D5F7525510C1E3@cu-ex-03.claflin.edu>

Hello 
Given the following data for a data set called airquality. To identify the nature of the objects from the data set airquality example "Ozone" would it be best to use the command is. like is.character(airquality$Ozone) ....... I tried attributes(airquality$Ozone) but it came up null. Would there be a better way to identify these objects.
 
Thanking you in advance for your assistance with my question.
 
 
 Ozone Solar.R Wind Temp Month Day
1      41     190  7.4   67     5   1
2      36     118  8.0   72     5   2
3      12     149 12.6   74     5   3
4      18     313 11.5   62     5   4
5      NA      NA 14.3   56     5   5
6      28      NA 14.9   66     5   6
7      23     299  8.6   65     5   7
8      19      99 13.8   59     5   8
9       8      19 20.1   61     5   9
10     NA     194  8.6   69     5  10
11      7      NA  6.9   74     5  11
12     16     256  9.7   69     5  12
13     11     290  9.2   66     5  13


From zlu at umich.edu  Sun Sep 16 19:47:10 2007
From: zlu at umich.edu (Zheng Lu)
Date: Sun, 16 Sep 2007 13:47:10 -0400
Subject: [R] help for high-quality plot
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBBF9336@LP-EXCHVS07.CO.IHC.COM>
References: <20070913144738.rjz7cyn794wk0og8@web.mail.umich.edu>
	<07E228A5BE53C24CAD490193A7381BBBBF9336@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <20070916134710.3a1m2x561w4cwc40@web.mail.umich.edu>

Dear all:

I am curious how to generate high-quality plot and graph with R and 
input it into my word document. my plot was always generated in device 
2, when I save it as PNG, the quality is poor. Thank you very much for 
your consideration and time.


ZLu


From ggrothendieck at gmail.com  Sun Sep 16 19:55:29 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 16 Sep 2007 13:55:29 -0400
Subject: [R] help for high-quality plot
In-Reply-To: <20070916134710.3a1m2x561w4cwc40@web.mail.umich.edu>
References: <20070913144738.rjz7cyn794wk0og8@web.mail.umich.edu>
	<07E228A5BE53C24CAD490193A7381BBBBF9336@LP-EXCHVS07.CO.IHC.COM>
	<20070916134710.3a1m2x561w4cwc40@web.mail.umich.edu>
Message-ID: <971536df0709161055v407cf9fbrb1e13f5e6aafb193@mail.gmail.com>

Use windows metafile format.  Its a vector graphic format so it will
display in full
resolution.  png is bitmapped and so won't.  Also you can edit a wmf
graphic in Word using Word's built in graphic editor so you could change
the labels, etc. even after you have imported it.  Right click the graphic
in R and save or copy it as a metafile.

On 9/16/07, Zheng Lu <zlu at umich.edu> wrote:
> Dear all:
>
> I am curious how to generate high-quality plot and graph with R and
> input it into my word document. my plot was always generated in device
> 2, when I save it as PNG, the quality is poor. Thank you very much for
> your consideration and time.
>
>
> ZLu
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From phhs80 at gmail.com  Sun Sep 16 20:00:35 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Sun, 16 Sep 2007 19:00:35 +0100
Subject: [R] help for high-quality plot
In-Reply-To: <20070916134710.3a1m2x561w4cwc40@web.mail.umich.edu>
References: <20070913144738.rjz7cyn794wk0og8@web.mail.umich.edu>
	<07E228A5BE53C24CAD490193A7381BBBBF9336@LP-EXCHVS07.CO.IHC.COM>
	<20070916134710.3a1m2x561w4cwc40@web.mail.umich.edu>
Message-ID: <6ade6f6c0709161100l5efd9c8blafc5915ac15651cd@mail.gmail.com>

On 9/16/07, Zheng Lu <zlu at umich.edu> wrote:
> I am curious how to generate high-quality plot and graph with R and
> input it into my word document. my plot was always generated in device
> 2, when I save it as PNG, the quality is poor. Thank you very much for
> your consideration and time.

To obtain better results, use vectorial formats (eps, pdf, svg, etc.)
and not bitmapped formats (png, jpg, tiff, etc.). In case, you are
using MS Word (as it seems), use eps; it may not look great on screen,
but it will look perfect on paper.

Paul


From amnakhan493 at gmail.com  Sun Sep 16 20:02:49 2007
From: amnakhan493 at gmail.com (amna khan)
Date: Sun, 16 Sep 2007 11:02:49 -0700
Subject: [R] Kendall Test
Message-ID: <3ffd3bb60709161102g169c348cg409ba3896cbd6a7b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070916/a4219ed0/attachment.pl 

From aim at stats.uwo.ca  Sun Sep 16 20:20:31 2007
From: aim at stats.uwo.ca (A.I. McLeod)
Date: Sun, 16 Sep 2007 14:20:31 -0400
Subject: [R] Kendall Test
References: <3ffd3bb60709161102g169c348cg409ba3896cbd6a7b@mail.gmail.com>
Message-ID: <001801c7f88e$46fc41d0$884c6481@stats2.uwo.ca>

Hello,
  Yes I agree but they are the same thing!
AIM
----- Original Message ----- 
From: "amna khan" <amnakhan493 at gmail.com>
To: <aimcleod at uwo.ca>
Cc: <R-help at hypatia.math.ethz.ch>
Sent: Sunday, September 16, 2007 2:02 PM
Subject: Kendall Test


> Dear Sir
> 
> In Kendall Package of R, when we use the function Kendall() or MannKendall()
> then we get the value of Kendall's tau and a two-sided p-value. The question
> to be asked is that is the two-sided p value for Z statistics defined by
> z=(S-1)/sqrt(var(S)) where S is Kendall S statistics.
> 
> Regards
> 
> 
> HAHZADI
> Department of Statistics
> GC University Lahore, Pakistan.
>


From t3rdperson at hotmail.com  Sun Sep 16 01:52:38 2007
From: t3rdperson at hotmail.com (ThatDeadDude)
Date: Sat, 15 Sep 2007 16:52:38 -0700 (PDT)
Subject: [R] Cannot get contrasts to work with aov.
Message-ID: <12695182.post@talk.nabble.com>


I have been trying for hours now to perform an orthogonal contrast through an
ANOVA in R.   

I have done a two-factor factorial experiment, each factor having three
levels.  I converted this dataset to a dataframe with one factor with nine
treatments, as I couldn't work out what else to do.   
I have set up a matrix with the eight orthogonal contrasts that I wish to
perform, but despite having searched this mailing list's archives
thoroughly, I cannot get it to work. 

I am looking to get output along the lines of 
            Df  Sum Sq Mean Sq F value    Pr(>F)     
trt1         1    X         X              X           X 
trt2         1    X         X              X           X 
 ............... 
trt9         1    X         X              X           X 
Residuals   27   495.1   18.3 

However, for everything I've tried, I've simply gotten 

            Df  Sum Sq Mean Sq F value    Pr(>F)     
trt          8 17919.7  2240.0  122.16 < 2.2e-16 *** 
Residuals   27   495.1    18.3         

I have done 
trt <- as.factor(trt) 
contrasts(trt) <- cntrs 
when I then type contrasts(trt), it returns what I expect. 

However, whether I try 
test <- aov(time2 ~ trt) 
test <- aov(time2 ~ trt, contrasts=contrasts(trt)) 
test <- aov(time2 ~ C(trt, cntrs, how.many=8)) 
or anything else I can think of, I only get what I posted above.  I'm
assuming I'm doing something fundamentally wrong, but for the life of me I
can't work out what, and it's killing me at present. 

Any responses would be greatly appreciated 
Marc Burgess
-- 
View this message in context: http://www.nabble.com/Cannot-get-contrasts-to-work-with-aov.-tf4449485.html#a12695182
Sent from the R help mailing list archive at Nabble.com.


From toro at riskeng.com  Sun Sep 16 19:53:43 2007
From: toro at riskeng.com (Gabriel R. Toro)
Date: Sun, 16 Sep 2007 13:53:43 -0400
Subject: [R] Using different symbols for different points in coplot scatter
 diagram
Message-ID: <auto-000282826672@fe.mail.megapathdsl.net>

Hi,

I am trying to create a set of scatter diagrams with coplot, and I 
want to use different symbols for each class of points (depending on 
where the data point came from).

I have the array with the required symbols, but I am not sure how to 
pass that array to the panel function, and whether I need to modify 
my panel function.

I would appreciate any suggestion.  Better yet, an example (including 
code) would be great.

Thanks,

Gabriel


From dusa.adrian at gmail.com  Sun Sep 16 23:35:32 2007
From: dusa.adrian at gmail.com (Adrian Dusa)
Date: Mon, 17 Sep 2007 00:35:32 +0300
Subject: [R] programming question
Message-ID: <200709170035.32712.dusa.adrian@gmail.com>


Dear list,

I have a vector of numbers, let's say:

myvec <- c(2, 8, 24, 26, 51, 57, 58, 78, 219)

My task is to reduce this vector to non-reducible numbers; small numbers can 
cross-out some of the larger ones, based on a function let's say called 
reduce()

If I apply the function to the first element 2, my vector gets shorted to:
> (myvec <- reduce(myvec[1]))
 [1]   2   24   51   57   58   78  219

The next element that can further reduce the vector is the second (24) and a 
next iteration further reduces it and so on, until nothing can be reduced.

The question is, what is the best programming technique to achieve this?

My crude solution is:
####
position <- 1 # start with the first position in the vector (smallest number)
while(position < length(myvec)) {
    myvec <- reduce(myvec[position])
    position <- position + 1
    }
####

Is there a better programming approach?
Some vectors have lengths of millions, so this one takes a very long time.

Thanks in advance,
Adrian



PS: below is a self-contained example:
The initial vector corresponds to the following lines in a base 3 matrix:
      [,1] [,2] [,3] [,4] [,5]
   2     0    0    0    0    2
   8     0    0    0    2    2
  24     0    0    2    2    0
  26     0    0    2    2    2
  51     0    1    2    2    0
  57     0    2    0    1    0
  58     0    2    0    1    1
  78     0    2    2    2    0
 219     2    2    0    1    0

In the first iteration, the first element 2 eliminates 8 and 26 because both 
contain number 2 in the last position (first line being shorter).
The element 24 eliminates 51 and 78, and so on.

`findSubsets2` <-
function(element) {
    require(QCA)
    base3row <- getRow(rep(3,5), element, zerobased=TRUE)
    increment <- function(x, y) {
        a <- x
        for (i in 1:2) {
            a <- as.vector(outer(y, a, "+"))
            x <- c(x, a)
            }
        return(x)
        }
    indices <- which(base3row == 0)
    mbase <- c(81, 27, 9, 3, 1)
    for (i in indices) {
        element <- increment(element, mbase[i])
        }
    return(element[-1])
    }

position <- 1
while(position < length(myvec)) {
    falsevector <- findSubsets2(myvec[position])
    myvec <- setdiff(myvec, falsevector)
    position <- position + 1
    }




-- 
Adrian Dusa
Romanian Social Data Archive
1, Schitu Magureanu Bd
050025 Bucharest sector 5
Romania
Tel./Fax: +40 21 3126618 \
          +40 21 3120210 / int.101


From r.turner at auckland.ac.nz  Sun Sep 16 23:39:14 2007
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 17 Sep 2007 09:39:14 +1200
Subject: [R] Problem with nlm() function.
Message-ID: <DCBD47DC-616D-4DBA-B5FD-7BC9CD298418@auckland.ac.nz>


In the course of revising a paper I have had occasion to attempt to  
maximize a rather
complicated log likelihood using the function nlm().  This is at the  
demand of a referee
who claims that this will work better than my proposed use of a home- 
grown implementation
of the Levenberg-Marquardt algorithm.

I have run into serious hiccups in attempting to apply nlm().

If I provide gradient and hessian attributes to the returned function  
value
(the ***negative*** of the log likelihood, since nlm() minimizes  
things) then
nlm() wanders around for a very long time and reaches a highly sub- 
optimal
value of the negative log likelihood.

It also gives multiple warnings to the effect  ``NA/Inf replaced
by maximum positive value in nlm(etc.)''.  Putting a browser() inside  
my objective
function appears to reveal that the hessian becomes singular in many  
calls to
the function.  I presume (presumptuously) that this is the cause of  
the NA/Inf-s.

Also if check.analyticals is TRUE I get an error to the effect  
``probable coding
error in analytic hessian''.

Since the coding of the hessian appears to work ``perfectly'' with my  
home-grown
Levenberg-Marquardt procedure (I get answers completely consistent  
with those
obtained from other approaches including use of the EM algorithm and  
use of
numerical optimization invoking optim()) I am at least 99% confident  
that my coding
of the hessian is NOT incorrect.

If I do not provide gradient and hessian attributes but simply let nlm 
() do its thing
completely numerically, then the algorithm converges to (within  
numerical
tolerance) the same answer obtained using my other three methods (i.e.
Levenberg-Marquardt, EM, and optim()).  However I still get a warning  
(one only)
in respect of NA/Inf being replaced by maximum positive value.

The hessian returned by nlm() in this case agrees closely with that  
calculated
by my ``analytical'' procedure, which gives me further confidence  
that my calculation
of the hessian is not incorrect despite the claim induced by  
``check.analyticals=TRUE''.

My gut feeling is that the problem is just a bit too complicated for  
nlm() to handle, and
I would simply leave it and go with the other approaches which appear  
to work consistently
and well.  However Referees Must Be Satisfied.  Has anyone any  
suggestions as to
how I can get nlm() to work with the analytical gradient and hessian?

The code is much too complicated to include in this posting, but if  
anyone is interested
in experimenting I can make available a package that I have prepared  
which does
all of the calculations in a convenient manner and demonstrates the  
problem.

Thanks for any help that anyone can give.

		cheers,

			Rolf Turner



######################################################################
Attention:\ This e-mail message is privileged and confidenti...{{dropped}}


From m.bridgman at yahoo.com  Mon Sep 17 00:24:59 2007
From: m.bridgman at yahoo.com (MATTHEW BRIDGMAN)
Date: Sun, 16 Sep 2007 15:24:59 -0700 (PDT)
Subject: [R] power calculation for repeated measures ANOVA?
Message-ID: <655698.75031.qm@web82104.mail.mud.yahoo.com>

Is there a way to calculate power for repeated
measures ANOVA (2 groups x 7 observations)? I have
searched all over, but all I can find is
power.anova.test, but that would not give accurate
results, right?

Thanks,
Matt Bridgman


From jholtman at gmail.com  Mon Sep 17 01:04:09 2007
From: jholtman at gmail.com (jim holtman)
Date: Sun, 16 Sep 2007 19:04:09 -0400
Subject: [R] stalled loop
In-Reply-To: <12708590.post@talk.nabble.com>
References: <12708590.post@talk.nabble.com>
Message-ID: <644e1f320709161604g4460e54fy9e6dc4a80fe17147@mail.gmail.com>

If I understand what you are trying to do is to find duplicated values
of rearrangements of words.  If that is the case, this is probably
faster since your final loop is removed by using "duplicated".  Most
of the time is in the sapply function.

> a <- c("superman", "xman", "spiderman", "wolfman", "mansuper", "manspider")
>
> ## uncomment the below to test how it scales
> a <- rep(a, 150000)
>
> system.time(
+     b <- sapply(a, function(.srt) {paste(sort(strsplit(.srt, '')[[1]]),
+                collapse="")})
+ )
   user  system elapsed
 142.31    0.12  204.49
>
> system.time(
+     print(unique(b[duplicated(b)]))  # find duplicated values
+ )
[1] "aemnprsu"  "adeimnprs" "amnx"      "aflmnow"
   user  system elapsed
   0.49    0.03    0.62

Another alternative that will save a little more time is to do the
'strsplit' to the 'a' vector one time and then use that output as
input to the 'sapply':

> system.time({
+ a.split <- strsplit(a, '')
+ })
   user  system elapsed
  16.24    0.02   19.03
>
> system.time({
+ b <- sapply(a.split, function(.srt) paste(sort(.srt), collapse=''))
+ })
   user  system elapsed
  83.88    0.11  121.16
>
> system.time(
+     print(unique(b[duplicated(b)]))  # find duplicated values
+ )
[1] "aemnprsu"  "adeimnprs" "amnx"      "aflmnow"
   user  system elapsed
   0.62    0.04    0.75

So if you major slow down was the 'for' loop, and you are looking for
duplicates in terms of contained letters, then using 'duplicated'
should improve it.  R is not necessarily the best language for doing
string manipulation, but if this timing is fine by you, then go with
it.

On 9/16/07, kevinchang <shukai at seas.upenn.edu> wrote:
>
> Hey everyone,
>
> The code I wrote executes correctly but  is stalled seriously. Is there a
> way to hasten execution without coming up with a  brand new algorithm
> ?please help. Thanks a lot for your time.
>
>
> #a simplified version of the code
>
> a<-c("superman" , "xman" , "spiderman" ,"wolfman" ,"mansuper","manspider" )
> b<-sapply(a,function(.srt){paste(sort(strsplit(.srt,'')[[1]]),
> collapse="")})
> c<-NA
> for(i in 1:length(b)) {
> if(length(which(b==b[i]))>1)
> c[i]<-b[i]
> }
> c<-c[!is.na(c)]
> # But if my get the volumne of "a" up to about 150000 words , the loop will
> work incredibly slowly.
>
> --
> View this message in context: http://www.nabble.com/stalled-loop-tf4456879.html#a12708590
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From mmalten at gmail.com  Mon Sep 17 01:18:28 2007
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Sun, 16 Sep 2007 19:18:28 -0400
Subject: [R] power calculation for repeated measures ANOVA?
In-Reply-To: <655698.75031.qm@web82104.mail.mud.yahoo.com>
References: <655698.75031.qm@web82104.mail.mud.yahoo.com>
Message-ID: <8913fde30709161618l6b915836k86eb7b4d710c0cbd@mail.gmail.com>

Mind a book reference instead of a software reference?

Look for Bausell and Li's "Power Analysis for Experimental Research"
-- cookbook style power calculations, but has explicit RM ANOVA.



On 9/16/07, MATTHEW BRIDGMAN <m.bridgman at yahoo.com> wrote:
> Is there a way to calculate power for repeated
> measures ANOVA (2 groups x 7 observations)? I have
> searched all over, but all I can find is
> power.anova.test, but that would not give accurate
> results, right?
>
> Thanks,
> Matt Bridgman
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
I can answer any question.
"I don't know" is an answer.
"I don't know yet" is a better answer.


From jholtman at gmail.com  Mon Sep 17 01:21:43 2007
From: jholtman at gmail.com (jim holtman)
Date: Sun, 16 Sep 2007 19:21:43 -0400
Subject: [R] Factorial, L-moments, and overflows
In-Reply-To: <DD14FDFE1F072D47B2F1F4D890DFB2C5015DF9CE@VOO-EXCHANGE01.internal.sungard.corp>
References: <DD14FDFE1F072D47B2F1F4D890DFB2C5015DF9CE@VOO-EXCHANGE01.internal.sungard.corp>
Message-ID: <644e1f320709161621n5bed57ddj9e301e394203aafe@mail.gmail.com>

It sounds like you are using 'integers'.  Have you considered
'numeric' (floating point)?  You can always look at the function
'samlmu' to see what it does in this case.

On 9/16/07, Pedro.Rodriguez at sungard.com <Pedro.Rodriguez at sungard.com> wrote:
> Hi everyone,
>
> In the package POT, there is a function that computes the L-moments of a given sample (samlmu). However, to compute those L-moments, one needs to obtain the total number of combinations between two numbers, which, by the way, requires the use of a factorial. See, for example, Hosking (1990 , p. 113).
>
> How does the function "samlmu" in the package POT avoids overflows?
>
> I was trying to build from scratch a R function similar to "samlmu" and ran into overflows (Just for my educational purposes :o) ). Is there a trick that I am missing to avoid overflows in the factorial function?
>
> Thank you very much for your time.
>
> Pedro N. Rodriguez
> SSRN Homepage: http://ssrn.com/author=412141/
> Homepage: http://www.pnrodriguez.com/
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From jholtman at gmail.com  Mon Sep 17 01:25:51 2007
From: jholtman at gmail.com (jim holtman)
Date: Sun, 16 Sep 2007 19:25:51 -0400
Subject: [R] Identifying objects from a data set
In-Reply-To: <A3E5A3C873C56F42B7F1A511D5F7525510C1E3@cu-ex-03.claflin.edu>
References: <A3E5A3C873C56F42B7F1A511D5F7525510C1E3@cu-ex-03.claflin.edu>
Message-ID: <644e1f320709161625u7914df80w326f9c08716d4368@mail.gmail.com>

Have you tried 'str'?  What 'nature of the object' are you trying to identify?

On 9/16/07, Letticia Ramlal <lramlal at claflin.edu> wrote:
> Hello
> Given the following data for a data set called airquality. To identify the nature of the objects from the data set airquality example "Ozone" would it be best to use the command is. like is.character(airquality$Ozone) ....... I tried attributes(airquality$Ozone) but it came up null. Would there be a better way to identify these objects.
>
> Thanking you in advance for your assistance with my question.
>
>
>  Ozone Solar.R Wind Temp Month Day
> 1      41     190  7.4   67     5   1
> 2      36     118  8.0   72     5   2
> 3      12     149 12.6   74     5   3
> 4      18     313 11.5   62     5   4
> 5      NA      NA 14.3   56     5   5
> 6      28      NA 14.9   66     5   6
> 7      23     299  8.6   65     5   7
> 8      19      99 13.8   59     5   8
> 9       8      19 20.1   61     5   9
> 10     NA     194  8.6   69     5  10
> 11      7      NA  6.9   74     5  11
> 12     16     256  9.7   69     5  12
> 13     11     290  9.2   66     5  13
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From gkerns at ysu.edu  Mon Sep 17 05:47:07 2007
From: gkerns at ysu.edu (G. Jay Kerns)
Date: Sun, 16 Sep 2007 23:47:07 -0400
Subject: [R] power calculation for repeated measures ANOVA?
In-Reply-To: <655698.75031.qm@web82104.mail.mud.yahoo.com>
References: <655698.75031.qm@web82104.mail.mud.yahoo.com>
Message-ID: <a695148b0709162047q3f466f26m78d1e0fd0b99af1@mail.gmail.com>

G*Power 3 is free software for Mac and PC, see
http://www.psycho.uni-duesseldorf.de/abteilungen/aap/gpower3/

Jay


On 9/16/07, MATTHEW BRIDGMAN <m.bridgman at yahoo.com> wrote:
> Is there a way to calculate power for repeated
> measures ANOVA (2 groups x 7 observations)? I have
> searched all over, but all I can find is
> power.anova.test, but that would not give accurate
> results, right?
>
> Thanks,
> Matt Bridgman
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 



***************************************************
G. Jay Kerns, Ph.D.
Assistant Professor / Statistics Coordinator
Department of Mathematics & Statistics
Youngstown State University
Youngstown, OH 44555-0002 USA
Office: 1035 Cushwa Hall
Phone: (330) 941-3310 Office (voice mail)
-3302 Department
-3170 FAX
E-mail: gkerns at ysu.edu
http://www.cc.ysu.edu/~gjkerns/


From constant.depiereux at skynet.be  Mon Sep 17 05:55:00 2007
From: constant.depiereux at skynet.be (Constant Depiereux)
Date: Mon, 17 Sep 2007 05:55:00 +0200
Subject: [R] GR&R - Best methods in R
Message-ID: <C5E602BC-74E4-4CF7-B592-CAFFB389C8C7@skynet.be>

Dear List,

Which is the most eficient method to perform a gage repeatability and  
reproducibility using R?

Thanks and best regards.

Constant Depi?reux

From sabya231 at gmail.com  Mon Sep 17 07:36:10 2007
From: sabya231 at gmail.com (Tirthadeep)
Date: Sun, 16 Sep 2007 22:36:10 -0700 (PDT)
Subject: [R] Stepwise logistic model selection using Cp and BIC criteria
Message-ID: <12729613.post@talk.nabble.com>


Hi,

Is there any package for logistic model selection using BIC and Mallow's Cp
statistic? If not, then kindly suggest me some ways to deal with these
problems.

Thanks.
-- 
View this message in context: http://www.nabble.com/Stepwise-logistic-model-selection-using-Cp-and-BIC-criteria-tf4464430.html#a12729613
Sent from the R help mailing list archive at Nabble.com.


From dimitris.rizopoulos at med.kuleuven.be  Mon Sep 17 09:10:47 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Mon, 17 Sep 2007 09:10:47 +0200
Subject: [R] Stepwise logistic model selection using Cp and BIC criteria
References: <12729613.post@talk.nabble.com>
Message-ID: <007a01c7f8f9$df311730$0540210a@www.domain>

For model selection using BIC you can have a look at stepAIC() from 
package MASS and boot.stepAIC() from package bootStepAIC. For 
instance,

library(bootStepAIC)

boot.stepAIC(glmFit1, data, B = 50, k = log(nrow(n)))

where `glmFit1' is the object represinting the fitted model, `data' 
the data.frame containing the variables for the analysis, `B' the 
number of bootstrap replicates, and `k' is the multiple of the number 
of degrees of freedom used for the penalty, which when equal to log(n) 
is the BIC.

By default boot.stepAIC() returns as well the results of stepAIC().

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Tirthadeep" <sabya231 at gmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, September 17, 2007 7:36 AM
Subject: [R] Stepwise logistic model selection using Cp and BIC 
criteria


>
> Hi,
>
> Is there any package for logistic model selection using BIC and 
> Mallow's Cp
> statistic? If not, then kindly suggest me some ways to deal with 
> these
> problems.
>
> Thanks.
> -- 
> View this message in context: 
> http://www.nabble.com/Stepwise-logistic-model-selection-using-Cp-and-BIC-criteria-tf4464430.html#a12729613
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From ggrothendieck at gmail.com  Mon Sep 17 09:36:12 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 17 Sep 2007 03:36:12 -0400
Subject: [R] programming question
In-Reply-To: <200709170035.32712.dusa.adrian@gmail.com>
References: <200709170035.32712.dusa.adrian@gmail.com>
Message-ID: <971536df0709170036h795a9155y969fdacee7a275d9@mail.gmail.com>

R 2.6.0 has Reduce;

myvec <- c(2, 8, 24, 26, 51, 57, 58, 78, 219)
Reduce(function(myvec, p) setdiff(myvec, findSubsets2(p)), myvec, myvec)


On 9/16/07, Adrian Dusa <dusa.adrian at gmail.com> wrote:
>
> Dear list,
>
> I have a vector of numbers, let's say:
>
> myvec <- c(2, 8, 24, 26, 51, 57, 58, 78, 219)
>
> My task is to reduce this vector to non-reducible numbers; small numbers can
> cross-out some of the larger ones, based on a function let's say called
> reduce()
>
> If I apply the function to the first element 2, my vector gets shorted to:
> > (myvec <- reduce(myvec[1]))
>  [1]   2   24   51   57   58   78  219
>
> The next element that can further reduce the vector is the second (24) and a
> next iteration further reduces it and so on, until nothing can be reduced.
>
> The question is, what is the best programming technique to achieve this?
>
> My crude solution is:
> ####
> position <- 1 # start with the first position in the vector (smallest number)
> while(position < length(myvec)) {
>    myvec <- reduce(myvec[position])
>    position <- position + 1
>    }
> ####
>
> Is there a better programming approach?
> Some vectors have lengths of millions, so this one takes a very long time.
>
> Thanks in advance,
> Adrian
>
>
>
> PS: below is a self-contained example:
> The initial vector corresponds to the following lines in a base 3 matrix:
>      [,1] [,2] [,3] [,4] [,5]
>   2     0    0    0    0    2
>   8     0    0    0    2    2
>  24     0    0    2    2    0
>  26     0    0    2    2    2
>  51     0    1    2    2    0
>  57     0    2    0    1    0
>  58     0    2    0    1    1
>  78     0    2    2    2    0
>  219     2    2    0    1    0
>
> In the first iteration, the first element 2 eliminates 8 and 26 because both
> contain number 2 in the last position (first line being shorter).
> The element 24 eliminates 51 and 78, and so on.
>
> `findSubsets2` <-
> function(element) {
>    require(QCA)
>    base3row <- getRow(rep(3,5), element, zerobased=TRUE)
>    increment <- function(x, y) {
>        a <- x
>        for (i in 1:2) {
>            a <- as.vector(outer(y, a, "+"))
>            x <- c(x, a)
>            }
>        return(x)
>        }
>    indices <- which(base3row == 0)
>    mbase <- c(81, 27, 9, 3, 1)
>    for (i in indices) {
>        element <- increment(element, mbase[i])
>        }
>    return(element[-1])
>    }
>
> position <- 1
> while(position < length(myvec)) {
>    falsevector <- findSubsets2(myvec[position])
>    myvec <- setdiff(myvec, falsevector)
>    position <- position + 1
>    }
>
>
>
>
> --
> Adrian Dusa
> Romanian Social Data Archive
> 1, Schitu Magureanu Bd
> 050025 Bucharest sector 5
> Romania
> Tel./Fax: +40 21 3126618 \
>          +40 21 3120210 / int.101
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petr.pikal at precheza.cz  Mon Sep 17 10:02:53 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Mon, 17 Sep 2007 10:02:53 +0200
Subject: [R] Odp:  GR&R - Best methods in R
In-Reply-To: <C5E602BC-74E4-4CF7-B592-CAFFB389C8C7@skynet.be>
Message-ID: <OFBFFB4DD6.0EA9F6DD-ONC1257359.002BC0BF-C1257359.002C2A7A@precheza.cz>

Hi

below you can find a function I wrote to mimic a Minitab R+R procedure. It 
is intended for myself only so it is not commented. If you want to know 
how it functions contact me off-list.

Regards

Petr

r-help-bounces at r-project.org napsal dne 17.09.2007 05:55:00:

> Dear List,
> 
> Which is the most eficient method to perform a gage repeatability and 
> reproducibility using R?
> 
> Thanks and best regards.
> 
> Constant Depi?reux
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


#------------------------------------------------------------------------------------------------
# O&R analysis (Minitab)
## fit is result from aov model (vysledek~vzorek*operator)
# operator is oprator number, vzorek is sample number

ORanal<-function(operator,vzorek,vysledek, sigma=5.15, DM=NULL ,HM=NULL, 
toler=NULL, plotit=F, dig=4)
{

if (!is.factor(vzorek)) vzorek<-factor(vzorek)
if (!is.factor(operator)) operator<-factor(operator)
if (is.null(toler)) toler<-abs(HM-DM)

fit<-aov(vysledek~vzorek*operator)

volop<-nlevels(operator[,drop=T])
volvzor<-nlevels(vzorek[,drop=T])
opak<-length(operator)/(volop*volvzor)
ctver<-anova(fit)[,3]


        result=NULL
        result[3]<-(ctver[3]-ctver[4])/opak
        result[5]<-ctver[4]
        result[1]<-(ctver[1]-ctver[4]-result[3]*opak)/(volop*opak)
        result[2]<-(ctver[2]-ctver[4]-result[3]*opak)/(volvzor*opak)

                if (result[2]<0) result[2]<-0

        result[4]<-result[2]+result[3]
        result[6]<-result[4]+result[5]
        result[7]<-result[1]+result[6]


result<-abs(result)
proc<-result/result[7]*100
smodch<-sqrt(result)
smodch5<-smodch*sigma
proc.smodch<-smodch/smodch[7]*100
proc.toler<-smodch5/toler*100

result<-cbind(result,smodch,smodch5,proc,proc.smodch,proc.toler)

result<-data.frame(result,row.names=c("Vzorky","Oper","Interakce","Reprod","Opak","O&R","Suma"))

meno<-c("rozptyl","smer.odch", "5.15 sm.odch" ,"proc.rozpt." 
,"proc.sm.odch", "toler.sm.odch")

velik<-dim(result)[2]

names(result)<-meno[1:velik]

suma<-summary(fit)

kateg<-trunc(smodch[1]/smodch[6]*1.41)+1

if (plotit) 

{

par(mfrow=c(3,2))
posice<-volvzor*1:volop
mat<-aggregate(vysledek,list(vzorek,operator),mean,na.rm=T)
mat1<-aggregate(vysledek,list(vzorek,operator),sd,na.rm=T)

#fig1

hmdm<-c(mean(mat$x)+(mean(mat1$x)/.9)/sqrt(opak)*3, 
mean(mat$x)-(mean(mat1$x)/.9)/sqrt(opak)*3)
        plot(mat$x,type="b",ylab="Prumery")
        abline(h=mean(mat$x),col=3)
        abline(h=hmdm,col=2)
        abline(v=posice+.5,col="grey",lwd=2,lty=2)
        text(posice-volvzor/2,max(mat$x),levels(operator[,drop=T]))

#fig2
# mat<-reshape(mat,direction="wide",idvar="Group.1",timevar="Group.2")
# 
matplot(as.matrix(mat[,2:(1+volop)]),type="b",pch=1:volop,col=1:volop,ylab="Prumer",axes=F)
#       axis(side=1,at=1:volvzor,labels=levels(vzorek[,drop=T]))
#       box()
#       axis(2)
# 
legend(1,min(mat[,2:(1+volop)]),levels(operator[,drop=T]),pch=1:volop,col=1:volop,cex=.8,horiz=T,yjust=0,xjust=0)

 mat<-reshape(mat,direction="wide",idvar="Group.1",timevar="Group.2")
 
matplot(as.matrix(mat[,2:(1+volop)]),type="b",pch=1:volop,col=1:volop,ylab="Prumer",axes=F)
        axis(side=1,at=1:volvzor,labels=levels(vzorek[,drop=T]))
        box()
        axis(2)
 
legend(1,min(mat[,2:(1+volop)]),levels(operator[,drop=T]),pch=1:volop,col=1:volop,cex=.8,horiz=T,yjust=0,xjust=0)


#fig3
hmdm<-c(mean(mat1$x)*sqrt(qchisq(.99865,opak,lower.tail=F)/(opak-1)), 
mean(mat1$x)*sqrt(qchisq(.99865,opak)/(opak-1)))

        plot(mat1$x,type="b",ylab="Smerod. odch")
        abline(h=mean(mat1$x),col=3)
        abline(h=hmdm,col=2)
        abline(v=posice+.5,col="grey",lwd=2,lty=2)
        text(posice-volvzor/2,max(mat1$x),levels(operator[,drop=T]))


#fig4
        boxplot(split(vysledek,operator),notch=T)
#fig5
        barplot(t(as.matrix(result[c(1,4,5,6),4:velik])),beside=T)
#fig6
        boxplot(split(vysledek,vzorek),notch=T)

par(mfrow=c(1,1))

}

rozlis<-smodch[6]*qnorm(0.975)
list(tabulka=round(result,dig),vartab=suma,kategorie=kateg,rozlisitelnost=rozlis)


}


From ptit_bleu at yahoo.fr  Mon Sep 17 12:08:55 2007
From: ptit_bleu at yahoo.fr (Ptit_Bleu)
Date: Mon, 17 Sep 2007 03:08:55 -0700 (PDT)
Subject: [R] Must be easy,
 but haven't found the function (numerical integration)
Message-ID: <12732936.post@talk.nabble.com>


Hi,

I have a data frame of 2 columns with the following types :
data$day char
data$value num

And I plot my data with :
plot(strptime(donnees$day,format="%Y-%m-%d %H:%M:%S"),donnees$value,
type="l")

And I'd just like to get the numerical value of the integration of this
graph.
I looked at ?integrate but, as far as I understood (that is, not very much,
due to my poor english), it seems that it doesn't work with values in data
frame.

Could you please help me to do this ?

Thanks in advance,
Have a nice week,
Ptit Bleu.
-- 
View this message in context: http://www.nabble.com/Must-be-easy%2C-but-haven%27t-found-the-function-%28numerical-integration%29-tf4465684.html#a12732936
Sent from the R help mailing list archive at Nabble.com.


From yn19832 at msn.com  Mon Sep 17 13:27:10 2007
From: yn19832 at msn.com (livia)
Date: Mon, 17 Sep 2007 04:27:10 -0700 (PDT)
Subject: [R] vector name
Message-ID: <12733890.post@talk.nabble.com>


I have got a list named "filtered", I would like to construct alist named
"fdata" as following:

fdata <- cbind(matrix(unlist(filtered),ncol=28), myregime)		

If I try names(filtered), it gives all the correct name for each vector, but
if I try names(fdata), it appears "filtered[[1]]"  "filtered[[2]]" ..., 

How can I keep the name in "fdata"? Could anyone give me some advice?
-- 
View this message in context: http://www.nabble.com/vector-name-tf4466025.html#a12733890
Sent from the R help mailing list archive at Nabble.com.


From brown_emu at yahoo.com  Mon Sep 17 13:39:45 2007
From: brown_emu at yahoo.com (Stephen Tucker)
Date: Mon, 17 Sep 2007 04:39:45 -0700 (PDT)
Subject: [R] vector name
In-Reply-To: <12733890.post@talk.nabble.com>
Message-ID: <80156.38552.qm@web39713.mail.mud.yahoo.com>

Hi,

Either of the following should work (I assume there are 28 elements in your
list):

fdata <- cbind(as.matrix(as.data.frame(filtered)), myregime)

fdata <- cbind("colnames<-"(matrix(unlist(filtered),ncol=28),
         names(filtered)), myregime)

--- livia <yn19832 at msn.com> wrote:

> 
> I have got a list named "filtered", I would like to construct alist named
> "fdata" as following:
> 
> fdata <- cbind(matrix(unlist(filtered),ncol=28), myregime)		
> 
> If I try names(filtered), it gives all the correct name for each vector,
> but
> if I try names(fdata), it appears "filtered[[1]]"  "filtered[[2]]" ..., 
> 
> How can I keep the name in "fdata"? Could anyone give me some advice?
> -- 
> View this message in context:
> http://www.nabble.com/vector-name-tf4466025.html#a12733890
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 



      ____________________________________________________________________________________
Luggage? GPS? Comic books?


From P.Dalgaard at biostat.ku.dk  Mon Sep 17 13:47:44 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 17 Sep 2007 13:47:44 +0200
Subject: [R] vector name
In-Reply-To: <12733890.post@talk.nabble.com>
References: <12733890.post@talk.nabble.com>
Message-ID: <46EE6960.8090806@biostat.ku.dk>

livia wrote:
> I have got a list named "filtered", I would like to construct alist named
> "fdata" as following:
>
> fdata <- cbind(matrix(unlist(filtered),ncol=28), myregime)		
>
> If I try names(filtered), it gives all the correct name for each vector, but
> if I try names(fdata), it appears "filtered[[1]]"  "filtered[[2]]" ..., 
>
> How can I keep the name in "fdata"? Could anyone give me some advice?
>   
You don't tell us quite enough about your data, but:

This would appear to giva a matrix, not a list? Did you perchance intend

do.call("cbind", c(filtered, list(myregime))

or maybe just

data.frame(filtered, myregime)

or

as.matrix(data.frame(filtered, myregime))

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From dusa.adrian at gmail.com  Mon Sep 17 14:16:32 2007
From: dusa.adrian at gmail.com (Adrian Dusa)
Date: Mon, 17 Sep 2007 15:16:32 +0300
Subject: [R] programming question
In-Reply-To: <971536df0709170036h795a9155y969fdacee7a275d9@mail.gmail.com>
References: <200709170035.32712.dusa.adrian@gmail.com>
	<971536df0709170036h795a9155y969fdacee7a275d9@mail.gmail.com>
Message-ID: <200709171516.33187.dusa.adrian@gmail.com>

On Monday 17 September 2007, you wrote:
> R 2.6.0 has Reduce;
>
> myvec <- c(2, 8, 24, 26, 51, 57, 58, 78, 219)
> Reduce(function(myvec, p) setdiff(myvec, findSubsets2(p)), myvec, myvec)

Thanks Gabor, at first I jumped off my chair but... for many input variables 
it takes <ages> to reduce the vector. My crude solution is way faster than 
Reduce()
For 9 input variables:

`findSubsets2` <- 
function(element) {
    require(QCA)
    base3row <- getRow(rep(3,9), element, zerobased=TRUE)
    increment <- function(x, y) {
        a <- x
        for (i in 1:2) {
            a <- as.vector(outer(y, a, "+"))
            x <- c(x, a)
            }
        return(x)
        }
    indices <- which(base3row == 0)
    mbase <- c(6561, 2187, 729, 243, 81, 27, 9, 3, 1)
    for (i in indices) {
        element <- increment(element, mbase[i])
        }
    return(element[-1])
    }


`myreduce` <- function(myvec) {
    position <- 1
    while(position < length(myvec)) {
        falsevector <- findSubsets2(myvec[position])
        myvec <- setdiff(myvec, falsevector)
        position <- position + 1
        }
    return(myvec
    }


The timings for the tests:
set.seed(1)
myvec1 <- myvec2 <- sort(sample(3^9, 3^8)) - 1

> system.time(myvec1 <- myreduce(myvec1))
   user  system elapsed
  0.200   0.004   0.204

> system.time(myvec2 <- Reduce(function(myvec2, p) setdiff(myvec2, 
findSubsets2(p)), myvec2, myvec2))
   user  system elapsed
 12.093   0.000  12.095

With 14 input variables my function takes 24 seconds to complete, and I'd like 
to process 20 such input variables (their complexity grow exponentially)...

Thanks again,
Adrian



-- 
Adrian Dusa
Romanian Social Data Archive
1, Schitu Magureanu Bd
050025 Bucharest sector 5
Romania
Tel./Fax: +40 21 3126618 \
          +40 21 3120210 / int.101


From mihalicza.peter at eski.hu  Mon Sep 17 14:15:29 2007
From: mihalicza.peter at eski.hu (=?ISO-8859-2?Q?Mihalicza_P=E9ter?=)
Date: Mon, 17 Sep 2007 14:15:29 +0200
Subject: [R] aggregate function oddity
Message-ID: <46EE6FE1.6010502@eski.hu>


From mihalicza.peter at eski.hu  Mon Sep 17 14:29:17 2007
From: mihalicza.peter at eski.hu (=?ISO-8859-2?Q?Mihalicza_P=E9ter?=)
Date: Mon, 17 Sep 2007 14:29:17 +0200
Subject: [R] aggregate function oddity
Message-ID: <46EE731D.3040400@eski.hu>

Dear All,

I tried to aggregate the rows according to some factors in a data frame. 
I got the
"Error in Summary.factor(..., na.rm = na.rm) :
        sum not meaningful for factors"
message. This problem was once already discussed in 2003 on this list, 
where the following solution was given: include only those columns -when 
giving it to aggregate() -  that are not factors.

It also worked for me, but this solution is a bit odd, since there is no 
need to sum the factors given as grouping variables. Of course I may do 
something completely wrong.
help(aggregate) says:
## S3 method for class 'data.frame': aggregate(x, by, FUN, ...)
|x| 	an R object.
|by| 	a list of grouping elements, each as long as the variables in |x|. 
Names for the grouping variables are provided if they are not given. The 
elements of the list will be coerced to factors (if they are not already 
factors).

In my interpretation this means that the factor variables and the 
numeric variables are in the same data frame, namely x.

The data frame looks like this (its mortality from cerebrovascular 
diseases):
 > str(agyer)
'data.frame':   102 obs. of  65 variables:
 $ Country            : int  4055 4055 4055 4055 4055 4055 4055 4055 
4055 4055 ...
 $ Name               : Factor w/ 5 levels "Estonia","Latvia",..: 1 1 1 
1 1 1 1 1 1 1 ...
 $ Year               : int  1997 1997 1998 1999 1999 1999 2000 2000 
2000 2001 ...
 $ List               : int  103 103 103 103 103 103 103 103 103 103 ...
 $ Sex                : int  2 1 2 2 1 2 2 1 1 2 ...
 $ Morticd10_103_Frmat: int  1 1 1 1 1 1 1 1 1 1 ...
 $ IM_Frmat           : int  1 1 1 1 1 1 1 1 1 1 ...
 $ Deaths1            : int  33 179 143 1428 83 61 3 759 29 4 ...
and a bunch of other int variables.

After omitting agyer$Name, I do
 > agyerpr=aggregate(agyer, by=list(agyer$Country, agyer$Year, 
agyer$List, agyer$Sex, agyer$Morticd10_103_Frmat, agyer$IM_Frmat), sum)

The sum is done on -the already omitted - factor of "Cause".

I do not understand why it tries to sum a factor that is included in the 
"by" list, since the concept is not to sum for those included, but use 
them for grouping. I am lucky with this database because all the factors 
can be interpreted as integers and I do not have to onit them one by 
one, but what if not?

Am I missing something with aggregate or classes?

Thanks for your help!

Sincerely,
Peter Mihalicza



-- 
This message has been scanned for viruses and\ dangerous con...{{dropped}}


From kingsley.oteng at gmail.com  Mon Sep 17 15:18:10 2007
From: kingsley.oteng at gmail.com (snapperball)
Date: Mon, 17 Sep 2007 06:18:10 -0700 (PDT)
Subject: [R] Matrix entries not recognised as numeric
Message-ID: <12735603.post@talk.nabble.com>


Hello, 

I am using a number of large matrices in a project. I read a couple of the
matrices using the read.csv command. However in some instances, R does not
recognize the resulting matrices as consisting of numerical values (I
suspect R considers them as strings or factors)

for instance when I try the following command (consider aMatrix is a
matrix), 

> range(aMatrix[,1])

R returns

> NA

I get the same output when I try the max  and min commands. Basically R does
not recognise the matrix as consisting of numerals. However when I inspect
the matrix the entries appear to contain numerical values. 

Is there something I am doing wrong? Is there anyway of coercing R into
recognizing the matrix as consisting of numerals?


-- 
View this message in context: http://www.nabble.com/Matrix-entries-not-recognised-as-numeric-tf4466621.html#a12735603
Sent from the R help mailing list archive at Nabble.com.


From phhs80 at gmail.com  Mon Sep 17 15:24:53 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Mon, 17 Sep 2007 14:24:53 +0100
Subject: [R] Must be easy,
	but haven't found the function (numerical integration)
In-Reply-To: <12732936.post@talk.nabble.com>
References: <12732936.post@talk.nabble.com>
Message-ID: <6ade6f6c0709170624n60b938d6kb8964eff2f9aeb14@mail.gmail.com>

On 9/17/07, Ptit_Bleu <ptit_bleu at yahoo.fr> wrote:
> I have a data frame of 2 columns with the following types :
> data$day char
> data$value num
>
> And I plot my data with :
> plot(strptime(donnees$day,format="%Y-%m-%d %H:%M:%S"),donnees$value,
> type="l")
>
> And I'd just like to get the numerical value of the integration of this
> graph.
> I looked at ?integrate but, as far as I understood (that is, not very much,
> due to my poor english), it seems that it doesn't work with values in data
> frame.
>
> Could you please help me to do this ?

I admit that others may find better solutions, but a possible solution
could be summing the areas of the trapezoids over the sequence of
them. It would be easy to program a function to do that, I guess

Paul


From karin.lagesen at medisin.uio.no  Mon Sep 17 15:25:55 2007
From: karin.lagesen at medisin.uio.no (Karin Lagesen)
Date: Mon, 17 Sep 2007 15:25:55 +0200
Subject: [R] add group to boxplot
Message-ID: <ypx6k5qp5spo.fsf@uracil.uio.no>



I have two sets of data in data frames (different dimensions). Now, I
am able to make boxplots for one of these. I am using a formula, which
gives me three boxplots which is automatically placed at at = c(1:3),
since there are three groups. However, I would now like to add data
from the other data frame, at position 4 in the box plot. Is there any
way of telling the first boxplot command that this should be allowed?

Hopefully an example that expresses what I need:

> data(InsectSprays)
> boxplot(count~spray, data = InsectSprays)
> Aspray = subset(InsectSprays, spray == "A")
> Aspray[] = lapply(Aspray, function(x) if (is.factor(x)) factor(x) else x)

Now, I want to add Aspray as a new boxplot at the end of the existing plot,

What do I do then?


Karin
-- 
Karin Lagesen, PhD student
karin.lagesen at medisin.uio.no
http://folk.uio.no/karinlag


From phhs80 at gmail.com  Mon Sep 17 15:29:46 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Mon, 17 Sep 2007 14:29:46 +0100
Subject: [R] Matrix entries not recognised as numeric
In-Reply-To: <12735603.post@talk.nabble.com>
References: <12735603.post@talk.nabble.com>
Message-ID: <6ade6f6c0709170629r566a9f4bq15c13da817424ac9@mail.gmail.com>

On 9/17/07, snapperball <kingsley.oteng at gmail.com> wrote:
> I am using a number of large matrices in a project. I read a couple of the
> matrices using the read.csv command. However in some instances, R does not
> recognize the resulting matrices as consisting of numerical values (I
> suspect R considers them as strings or factors)
>
> for instance when I try the following command (consider aMatrix is a
> matrix),
>
> > range(aMatrix[,1])
>
> R returns
>
> > NA
>
> I get the same output when I try the max  and min commands. Basically R does
> not recognise the matrix as consisting of numerals. However when I inspect
> the matrix the entries appear to contain numerical values.
>
> Is there something I am doing wrong? Is there anyway of coercing R into
> recognizing the matrix as consisting of numerals?

Use as.numeric:

> m <- matrix(c("1","2","3","4"),2,2)
> m
     [,1] [,2]
[1,] "1"  "3"
[2,] "2"  "4"
> range(as.numeric(m[,1]))
[1] 1 2

Paul


From stefan.vandongen at ua.ac.be  Mon Sep 17 15:36:40 2007
From: stefan.vandongen at ua.ac.be (Van Dongen Stefan)
Date: Mon, 17 Sep 2007 15:36:40 +0200
Subject: [R] graphs with gradients of colors
Message-ID: <36B62AB1E934124BA81C2B3B615E9F008119CD@xmail05.ad.ua.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070917/696f1468/attachment.pl 

From steve at promente.org  Mon Sep 17 15:47:04 2007
From: steve at promente.org (Steve Powell)
Date: Mon, 17 Sep 2007 15:47:04 +0200
Subject: [R] Creating Hmisc labels inside a function
In-Reply-To: <46E7DD9B.4020902@vanderbilt.edu>
References: <mailman.7.1189418403.7853.r-help@stat.math.ethz.ch>
	<019801c7f452$6211ae50$6501a8c0@STEVE>
	<46E7DD9B.4020902@vanderbilt.edu>
Message-ID: <01ac01c7f931$3c7d8040$6501a8c0@STEVE>

 
Thanks, Frank - it doesn't work though. 
Your suggestion was:

Test=function(obj,labe)
{
label(obj)=labe
#at this point add the line:
obj
}
#...but just returning the object does not permanently change the label:
obj

That is why I wanted to use assign. But "assign" will not work with
attributes, labels etc. So 

assign(label(obj),"some label") #doesn't even work outside a function, at
the command prompt.

Any more ideas anyone?
Best wishes 
Steve Powell

 
proMENTE social research 
research | evaluation | training & consulting 
Kranj?evi?eva 35, 71000 Sarajevo 
mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387 33 556 866
skype: stevepowell99 
www.promente.org  |  www.mojakarijera.com  |  www.psih.org  

-----Original Message-----
From: Frank E Harrell Jr [mailto:f.harrell at vanderbilt.edu] 
Sent: 12 September 2007 14:38
To: Steve Powell
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Creating Hmisc labels inside a function

Steve Powell wrote:
> hello list members,
> I am wanting to write a label using the Hmisc package, but inside a 
> function. Normally I can do:
> 
> library(Hmisc)
> M=2
> label(M)="lab"
> 
> #But inside a function the "=" does not work:
> Test=function(obj,labe)
> {
> label(obj)=labe

at this point add the line:

obj

> }

The returned object will have what you need.  -Frank

> 
> Test(M,"new label")
> 
> I usually use the "assign" function to make assignments inside 
> functions, but assign will not work with attributes, labels etc.
> Any ideas?
> Thanks in advance
> 
> Steve Powell
> 
>  
> proMENTE social research
> research | evaluation | training & consulting Kranj?evi?eva 35, 71000 
> Sarajevo
> mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387 33 556 
> 866
> skype: stevepowell99
> www.promente.org  |  www.mojakarijera.com  |  www.psih.org
> 
> 
> Checked by AVG Free Edition. 
> 
> 17:43
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University

No virus found in this incoming message.
Checked by AVG Free Edition. 

11.09.2007
17:46
 


Checked by AVG Free Edition. 

16.09.2007
18:32
 


From Ted.Harding at manchester.ac.uk  Mon Sep 17 15:53:00 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Mon, 17 Sep 2007 14:53:00 +0100 (BST)
Subject: [R] Matrix entries not recognised as numeric
In-Reply-To: <12735603.post@talk.nabble.com>
Message-ID: <XFMail.070917145300.Ted.Harding@manchester.ac.uk>

On 17-Sep-07 13:18:10, snapperball wrote:
> 
> Hello, 
> 
> I am using a number of large matrices in a project. I read a
> couple of the matrices using the read.csv command. However
> in some instances, R does not recognize the resulting matrices
> as consisting of numerical values (I suspect R considers them as
> strings or factors)

What is likely, here, is that in those cases which fail the
CSV file has some entries which are not interpretable as numeric
values[1]. In that case, R will treat such entries as "character"
and then do a global conversion to character type.

[1] The exception to that is an entry consisting of "NA", as in

  1.1,1.2,1.3,1.4
  2.1,NA,2.3,2.4
  3.1,3.2,3.3,3.4

when the "NA" entry will become an NA in R, and the rest will
be numbers as they should be.

For example:

matrix(c(1,2,3,4,5,6),nrow=2)
       [,1] [,2] [,3]
  [1,]    1    3    5
  [2,]    2    4    6

matrix(c(1,2,3,"A",5,6),nrow=2)
       [,1] [,2] [,3]
  [1,] "1"  "3"  "5" 
  [2,] "2"  "A"  "6" 

matrix(c(1,2,3,NA,5,6),nrow=2)
       [,1] [,2] [,3]
  [1,]    1    3    5
  [2,]    2   NA    6

I suggest you check the matrix entries somehow (unfortunately
you have "large matrices"). The R command typeof() could be
useful for a first clue, e.g.

typeof(matrix(c(1,2,3,4,5,6),nrow=2))
  [1] "double"

typeof(matrix(c(1,2,3,"A",5,6),nrow=2))
  [1] "character"

typeof(matrix(c(1,2,3,NA,5,6),nrow=2))
  [1] "double"

Another tool would be grep(), for example:

grep("[^0-9.]",matrix(c(1.1,2.1,3.1,"A",5,6),nrow=2))
  [1] 4

which identifies which elements of the 6 elements in the matrix
(counting down columns, i.e. in the order given in the CSV list)
match the regulary expression "[^0-9.]" which means

  "Anything which is not (^) one of 0,1,2,3,4,5,6,7,8,9 (0-9)
   or ."

so that it picks out any element containing anything other than
the characters 0 1 2 3 4 5 6 7 8 9 . which can form part of the
expression of a decimal number (NOTE that this works because
the matrix is of "character" type; if it were of a numeric
type then the "." would not be part of the representation).

Other variants of this kind of search could be considered!

Hoping this helps,
Ted.

> 
> for instance when I try the following command (consider aMatrix is a
> matrix), 
> 
>> range(aMatrix[,1])
> 
> R returns
> 
>> NA
> 
> I get the same output when I try the max  and min commands. Basically R
> does
> not recognise the matrix as consisting of numerals. However when I
> inspect
> the matrix the entries appear to contain numerical values. 
> 
> Is there something I am doing wrong? Is there anyway of coercing R into
> recognizing the matrix as consisting of numerals?
> 
> 
> -- 
> View this message in context:
> http://www.nabble.com/Matrix-entries-not-recognised-as-numeric-tf4466621
> .html#a12735603
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 17-Sep-07                                       Time: 14:52:57
------------------------------ XFMail ------------------------------


From bszk at uoguelph.ca  Mon Sep 17 16:02:49 2007
From: bszk at uoguelph.ca (Bill Szkotnicki)
Date: Mon, 17 Sep 2007 10:02:49 -0400
Subject: [R] help not working
In-Reply-To: <12732936.post@talk.nabble.com>
References: <12732936.post@talk.nabble.com>
Message-ID: <46EE8909.50608@uoguelph.ca>

Hi,
When we install windows R 2.5.1 on a network drive ( the "P: ' drive,  
actually a samba public share )
R runs well but the windows help is unavailable.
It complains about "Navigation to the webpage was cancelled"
Does anyone know how to fix that?
Thanks, Bill


From ligges at statistik.uni-dortmund.de  Mon Sep 17 16:22:28 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 17 Sep 2007 16:22:28 +0200
Subject: [R] help not working
In-Reply-To: <46EE8909.50608@uoguelph.ca>
References: <12732936.post@talk.nabble.com> <46EE8909.50608@uoguelph.ca>
Message-ID: <46EE8DA4.7050900@statistik.uni-dortmund.de>



Bill Szkotnicki wrote:
> Hi,
> When we install windows R 2.5.1 on a network drive ( the "P: ' drive,  
> actually a samba public share )
> R runs well but the windows help is unavailable.
> It complains about "Navigation to the webpage was cancelled"
> Does anyone know how to fix that?


This has been disabled by a Microsoft patch due to security reasons 
regarding compiled html help on network shares some years ago.
You can re-enable it according to Microsoft documentation with the 
following registry settings (which make your system more less secure):

[HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\HTMLHelp\1.x\ItssRestrictions]
"MaxAllowedZone"=dword:00000001

[HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\HTMLHelp\1.x\HHRestrictions]
"EnableFrameNavigationInSafeMode"=dword:00000001


You can also choose to use another help format bin R such as html help.

Uwe Ligges




> Thanks, Bill
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From edna.bell01 at gmail.com  Mon Sep 17 16:34:41 2007
From: edna.bell01 at gmail.com (Edna Bell)
Date: Mon, 17 Sep 2007 09:34:41 -0500
Subject: [R]  Converting zoo dates to ts dates
Message-ID: <2d1ebb110709170734u4b71913dy37e74b4c2d00f5b5@mail.gmail.com>

Hi R Gurus

I'm using get.hist.quote to obtain monthly historical data.

This results in a zoo series.

I would like to convert the zoo series to a time series within a
function.  How do I get the starting date for the ts from the zoo
series, please?

Thanks,
Edna Bell


From audrey at ebi.ac.uk  Mon Sep 17 16:35:56 2007
From: audrey at ebi.ac.uk (audrey)
Date: Mon, 17 Sep 2007 15:35:56 +0100
Subject: [R] side bars on dendrograms with latticeExtra
Message-ID: <46EE90CC.7000007@ebi.ac.uk>

Dear all,

I am using the heatmap representations of latticeExtra package and I 
would be interested to draw color side bars representing the groups of a 
factor of interest. From my understanding of :

 > help(dendrogramGrob)
...
     The 'add' argument can be used for additional annotation at the
     base of the dendrogram.  It should be a list with one component
     for each row, with names specifying the type of annotation and
     components specifying the contents.  Currently, the only supported
     name is '"rect"' (which can be repeated), producing rectangles.
     The components in such a case is a list of graphical parameters,
     possibly vectorized, that are passed on to 'gpar'.
...

I should use the argument add. Unfortunately I am not very familiar with 
'gpar' from grid package, and I cannot find the correct syntax to use 
this 'add' argument.

Does anyone has an example of how to draw side bars next to a dendrogram 
produced with latticeExtra?

Thank you,
Audrey


From ggrothendieck at gmail.com  Mon Sep 17 16:42:25 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 17 Sep 2007 10:42:25 -0400
Subject: [R] Converting zoo dates to ts dates
In-Reply-To: <2d1ebb110709170734u4b71913dy37e74b4c2d00f5b5@mail.gmail.com>
References: <2d1ebb110709170734u4b71913dy37e74b4c2d00f5b5@mail.gmail.com>
Message-ID: <971536df0709170742k47c4fed4k27a22c006f8ee38e@mail.gmail.com>

as.ts(z) will convert zoo object z to a ts object.  The get.hist.quote
retclass= argument can be used to directly output a ts object.

On 9/17/07, Edna Bell <edna.bell01 at gmail.com> wrote:
> Hi R Gurus
>
> I'm using get.hist.quote to obtain monthly historical data.
>
> This results in a zoo series.
>
> I would like to convert the zoo series to a time series within a
> function.  How do I get the starting date for the ts from the zoo
> series, please?
>
> Thanks,
> Edna Bell
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Mark.Leeds at morganstanley.com  Mon Sep 17 16:42:47 2007
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Mon, 17 Sep 2007 10:42:47 -0400
Subject: [R] system.time behavior using source
Message-ID: <D3AEEDA31E57474B840BEBC25A8A834401957AA5@NYWEXMB23.msad.ms.com>

If I type the line below at my Rprompt, it works fine. But, if I put the
same line in a file called systest.R and then source that file at
the prompt, nothing happens. IF I use R CMD BATCH, it also works in that
the system.time info is the .Rout file. Is there something I
can do so that this line also works when I source it ?  Thanks. My
information is below.

system.time(for(i in 1:100) mad(runif(1000)))



My information :

R version 2.5.0 (2007-04-23) 
i686-pc-linux-gnu 

locale:
C

attached base packages:
[1] "datasets"  "utils"     "stats"     "graphics"  "grDevices"
"methods"   "base"     

other attached packages:
 lattice filehash  reshape      zoo    chron     MASS 
"0.15-8"    "1.0"  "0.7.4"  "1.3-1" "2.3-11" "7.2-33"
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From therneau at mayo.edu  Mon Sep 17 16:49:14 2007
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 17 Sep 2007 09:49:14 -0500 (CDT)
Subject: [R] Class probabilities in rpart
Message-ID: <200709171449.l8HEnDF29499@hsrnfs-101.mayo.edu>

> The predict.rpart() function from the rpart library allows for 
> calculating the class probabilities for a given test case instead of a 
> discrete class label.

> How are these class probabilities derived? Is it simply the proportion 
> of the majority class to all cases in a leaf node?

    That is almost correct.  If there are prior probabilities, it will be the
expected proportion of each class, accounting for priors.  If there are no
priors, then the expected proportion = observed proportion.

	Terry Therneau


From ggrothendieck at gmail.com  Mon Sep 17 16:49:22 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 17 Sep 2007 10:49:22 -0400
Subject: [R] system.time behavior using source
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A834401957AA5@NYWEXMB23.msad.ms.com>
References: <D3AEEDA31E57474B840BEBC25A8A834401957AA5@NYWEXMB23.msad.ms.com>
Message-ID: <971536df0709170749o6b076afbm2d15a4aad0c61432@mail.gmail.com>

Try this:

source("myfile.R", echo = TRUE)

On 9/17/07, Leeds, Mark (IED) <Mark.Leeds at morganstanley.com> wrote:
> If I type the line below at my Rprompt, it works fine. But, if I put the
> same line in a file called systest.R and then source that file at
> the prompt, nothing happens. IF I use R CMD BATCH, it also works in that
> the system.time info is the .Rout file. Is there something I
> can do so that this line also works when I source it ?  Thanks. My
> information is below.
>
> system.time(for(i in 1:100) mad(runif(1000)))
>
>
>
> My information :
>
> R version 2.5.0 (2007-04-23)
> i686-pc-linux-gnu
>
> locale:
> C
>
> attached base packages:
> [1] "datasets"  "utils"     "stats"     "graphics"  "grDevices"
> "methods"   "base"
>
> other attached packages:
>  lattice filehash  reshape      zoo    chron     MASS
> "0.15-8"    "1.0"  "0.7.4"  "1.3-1" "2.3-11" "7.2-33"
> --------------------------------------------------------
>
> This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From f.harrell at vanderbilt.edu  Mon Sep 17 17:17:49 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Mon, 17 Sep 2007 10:17:49 -0500
Subject: [R] Creating Hmisc labels inside a function
In-Reply-To: <01ac01c7f931$3c7d8040$6501a8c0@STEVE>
References: <mailman.7.1189418403.7853.r-help@stat.math.ethz.ch>
	<019801c7f452$6211ae50$6501a8c0@STEVE>
	<46E7DD9B.4020902@vanderbilt.edu>
	<01ac01c7f931$3c7d8040$6501a8c0@STEVE>
Message-ID: <46EE9A9D.8060000@vanderbilt.edu>

Steve Powell wrote:
>  
> Thanks, Frank - it doesn't work though. 
> Your suggestion was:
> 
Test=function(obj,labe)
  {
  label(obj)=labe
  #at this point add the line:
  obj
  }
> #...but just returning the object does not permanently change the label:
> obj

It does for me.  Please re-run.  -Frank

 > attributes(Test(1:3, 'some label'))
$label
[1] "some label"

$class
[1] "labelled"

You don't need assign.
Frank


> 
> That is why I wanted to use assign. But "assign" will not work with
> attributes, labels etc. So 
> 
> assign(label(obj),"some label") #doesn't even work outside a function, at
> the command prompt.
> 
> Any more ideas anyone?
> Best wishes 
> Steve Powell
> 
>  
> proMENTE social research 
> research | evaluation | training & consulting 
> Kranj?evi?eva 35, 71000 Sarajevo 
> mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387 33 556 866
> skype: stevepowell99 
> www.promente.org  |  www.mojakarijera.com  |  www.psih.org  
> 
> -----Original Message-----
> From: Frank E Harrell Jr [mailto:f.harrell at vanderbilt.edu] 
> Sent: 12 September 2007 14:38
> To: Steve Powell
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Creating Hmisc labels inside a function
> 
> Steve Powell wrote:
>> hello list members,
>> I am wanting to write a label using the Hmisc package, but inside a 
>> function. Normally I can do:
>>
>> library(Hmisc)
>> M=2
>> label(M)="lab"
>>
>> #But inside a function the "=" does not work:
>> Test=function(obj,labe)
>> {
>> label(obj)=labe
> 
> at this point add the line:
> 
> obj
> 
>> }
> 
> The returned object will have what you need.  -Frank
> 
>> Test(M,"new label")
>>
>> I usually use the "assign" function to make assignments inside 
>> functions, but assign will not work with attributes, labels etc.
>> Any ideas?
>> Thanks in advance
>>
>> Steve Powell
>>
>>  
>> proMENTE social research
>> research | evaluation | training & consulting Kranj?evi?eva 35, 71000 
>> Sarajevo
>> mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387 33 556 
>> 866
>> skype: stevepowell99
>> www.promente.org  |  www.mojakarijera.com  |  www.psih.org
>>
>>
>> Checked by AVG Free Edition. 
>>
>> 17:43
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From deepayan.sarkar at r-project.org  Mon Sep 17 17:18:52 2007
From: deepayan.sarkar at r-project.org (deepayan.sarkar at r-project.org)
Date: Mon, 17 Sep 2007 08:18:52 -0700
Subject: [R] side bars on dendrograms with latticeExtra
In-Reply-To: <46EE90CC.7000007@ebi.ac.uk>
References: <46EE90CC.7000007@ebi.ac.uk>
Message-ID: <eb555e660709170818s82b7ff7ve6a79140fce3df29@mail.gmail.com>

On 9/17/07, audrey <audrey at ebi.ac.uk> wrote:
> Dear all,
>
> I am using the heatmap representations of latticeExtra package and I
> would be interested to draw color side bars representing the groups of a
> factor of interest. From my understanding of :
>
>  > help(dendrogramGrob)
> ...
>      The 'add' argument can be used for additional annotation at the
>      base of the dendrogram.  It should be a list with one component
>      for each row, with names specifying the type of annotation and
>      components specifying the contents.  Currently, the only supported
>      name is '"rect"' (which can be repeated), producing rectangles.
>      The components in such a case is a list of graphical parameters,
>      possibly vectorized, that are passed on to 'gpar'.
> ...
>
> I should use the argument add. Unfortunately I am not very familiar with
> 'gpar' from grid package, and I cannot find the correct syntax to use
> this 'add' argument.
>
> Does anyone has an example of how to draw side bars next to a dendrogram
> produced with latticeExtra?

Here's one:


library(latticeExtra)

hc1 <- hclust(dist(USArrests, method = "canberra"))
hc1 <- as.dendrogram(hc1)
ord.hc1 <- order.dendrogram(hc1)
hc2 <- reorder(hc1, state.region[ord.hc1])
ord.hc2 <- order.dendrogram(hc2)

region.colors <- trellis.par.get("superpose.polygon")$col

levelplot(t(scale(USArrests))[, ord.hc2],
          scales = list(x = list(rot = 90)),
          colorkey = FALSE,
          legend =
          list(right =
               list(fun = dendrogramGrob,
                    args =
                    list(x = hc2, ord = ord.hc2,
                         side = "right", size = 10, size.add= 0.5,
                         add = list(rect =
                         list(col = "transparent",
                              fill = region.colors[state.region])),
                         type = "rectangle"))))

-Deepayan


From milferst at uiuc.edu  Mon Sep 17 17:21:04 2007
From: milferst at uiuc.edu (Kim Milferstedt)
Date: Mon, 17 Sep 2007 10:21:04 -0500
Subject: [R] removing a specific number of digist from a character string
Message-ID: <6.2.5.6.2.20070917101056.01eb1dd8@uiuc.edu>

Hello,

I would like to remove the last 8 digists of character strings in a 
vector. Below I added a couple of elements from that vector.

I have a problem defining a pattern to replace the digits using for 
example "sub". Removing the ".tif" part works fine using 
sub('.tif',"",x), but how do I get rid of the four preceding digits?

Thanks for your help,

Kim

Input:
[3988] 
"060907_17_3_5_1_1_2909.tif"   "060907_17_3_5_2_1_2910.tif" 
"060907_17_3_5_3_1_2911.tif"
[3991] 
"060907_17_3_5_4_1_2912.tif"   "060907_17_3_5_5_1_2913.tif" 
"060907_17_3_5_6_1_2914.tif"

Desired output:
[3988] "060907_17_3_5_1_1_"   "060907_17_3_5_2_1_"   "060907_17_3_5_3_1_"
[3991] "060907_17_3_5_4_1_"   "060907_17_3_5_5_1_"   "060907_17_3_5_6_1_"

__________________________________________

Kim Milferstedt
University of Illinois at Urbana-Champaign
Department of Civil and Environmental Engineering
4125 Newmark Civil Engineering Laboratory
205 North Mathews Avenue MC-250
Urbana, IL 61801
USA
phone: (001) 217 333-9663
fax: (001) 217 333-6968
email: milferst at uiuc.edu
http://cee.uiuc.edu/research/morgenroth


From bolker at ufl.edu  Mon Sep 17 17:32:20 2007
From: bolker at ufl.edu (bbolker)
Date: Mon, 17 Sep 2007 08:32:20 -0700 (PDT)
Subject: [R] Must be easy,
 but haven't found the function (numerical integration)
In-Reply-To: <6ade6f6c0709170624n60b938d6kb8964eff2f9aeb14@mail.gmail.com>
References: <12732936.post@talk.nabble.com>
	<6ade6f6c0709170624n60b938d6kb8964eff2f9aeb14@mail.gmail.com>
Message-ID: <12738241.post@talk.nabble.com>




On 9/17/07, Ptit_Bleu <ptit_bleu at yahoo.fr> wrote:
> I have a data frame of 2 columns with the following types :
> data$day char
> data$value num
>
> And I plot my data with :
> plot(strptime(donnees$day,format="%Y-%m-%d %H:%M:%S"),donnees$value,
> type="l")
>
> And I'd just like to get the numerical value of the integration of this
> graph.

  Would cumsum (which simply finds the cumulative sum of a vector) be
sufficiently
accurate for your purposes?

  Ben Bolker

-- 
View this message in context: http://www.nabble.com/Must-be-easy%2C-but-haven%27t-found-the-function-%28numerical-integration%29-tf4465684.html#a12738241
Sent from the R help mailing list archive at Nabble.com.


From gunter.berton at gene.com  Mon Sep 17 17:34:04 2007
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 17 Sep 2007 08:34:04 -0700
Subject: [R] help for high-quality plot (wmf) in files
In-Reply-To: <971536df0709161055v407cf9fbrb1e13f5e6aafb193@mail.gmail.com>
References: <20070913144738.rjz7cyn794wk0og8@web.mail.umich.edu><07E228A5BE53C24CAD490193A7381BBBBF9336@LP-EXCHVS07.CO.IHC.COM><20070916134710.3a1m2x561w4cwc40@web.mail.umich.edu>
	<971536df0709161055v407cf9fbrb1e13f5e6aafb193@mail.gmail.com>
Message-ID: <004401c7f940$2defc560$3a0b2c0a@gne.windows.gene.com>

May I ask a related question to tack on to this thread.

One can also output a wmf plot to a file through the win.metafile() call.
But as the help file says, due to Windows limitations only one plot per file
is allowed and one must use parameterized filenames to produce multiple
plots, which I often have in e.g. lattice displays.

My question: For those who deal routinely with this issue, what sorts of
strategies do you use to produce and keep track of multiple wmf files (in
Windows)?  Any code (or packages) or tricks for combining all the plots into
one file with suitable identifying labels?

NOTE: AFAICS Sweave doesn't work, as it produces only pdf graphs.

Feel free to reply off list, as this is not really an R question.

Cheers,
Bert 


Bert Gunter
Genentech Nonclinical Statistics


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Gabor Grothendieck
Sent: Sunday, September 16, 2007 10:55 AM
To: Zheng Lu
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] help for high-quality plot

Use windows metafile format.  Its a vector graphic format so it will
display in full
resolution.  png is bitmapped and so won't.  Also you can edit a wmf
graphic in Word using Word's built in graphic editor so you could change
the labels, etc. even after you have imported it.  Right click the graphic
in R and save or copy it as a metafile.

On 9/16/07, Zheng Lu <zlu at umich.edu> wrote:
> Dear all:
>
> I am curious how to generate high-quality plot and graph with R and
> input it into my word document. my plot was always generated in device
> 2, when I save it as PNG, the quality is poor. Thank you very much for
> your consideration and time.
>
>
> ZLu
>


From bolker at ufl.edu  Mon Sep 17 17:36:24 2007
From: bolker at ufl.edu (bbolker)
Date: Mon, 17 Sep 2007 08:36:24 -0700 (PDT)
Subject: [R] Problem with nlm() function.
In-Reply-To: <DCBD47DC-616D-4DBA-B5FD-7BC9CD298418@auckland.ac.nz>
References: <DCBD47DC-616D-4DBA-B5FD-7BC9CD298418@auckland.ac.nz>
Message-ID: <12738419.post@talk.nabble.com>




Rolf Turner-3 wrote:
> 
> 
> In the course of revising a paper I have had occasion to attempt to  
> maximize a rather
> complicated log likelihood using the function nlm().  This is at the  
> demand of a referee
> who claims that this will work better than my proposed use of a home- 
> grown implementation
> of the Levenberg-Marquardt algorithm.
> 
> I have run into serious hiccups in attempting to apply nlm().
> 
> [snip]
> 
> My gut feeling is that the problem is just a bit too complicated for  
> nlm() to handle, and
> I would simply leave it and go with the other approaches which appear  
> to work consistently
> and well.  However Referees Must Be Satisfied.  Has anyone any  
> suggestions as to
> how I can get nlm() to work with the analytical gradient and hessian?
> 

  This kind of problem is the perfect one to fall through the cracks on
R-help:
the poster has obviously done his homework (and thus cannot be
flamed to oblivion), a non-trivial problem that will take some work, not in
one of the particular areas of interest on someone on the list, and not
a problem where someone is going to be able to create an astoundingly
clever one-line solution that works 0.34 seconds faster than an intelligible
5-line solution.

  I don't think there's any conceivable way to solve this without access
to the aforementioned package.  Could you post it please?

  cheers
    Ben Bolker

-- 
View this message in context: http://www.nabble.com/Problem-with-nlm%28%29-function.-tf4463043.html#a12738419
Sent from the R help mailing list archive at Nabble.com.


From p.hiemstra at geo.uu.nl  Mon Sep 17 17:58:21 2007
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 17 Sep 2007 17:58:21 +0200
Subject: [R] removing a specific number of digist from a character string
In-Reply-To: <6.2.5.6.2.20070917101056.01eb1dd8@uiuc.edu>
References: <6.2.5.6.2.20070917101056.01eb1dd8@uiuc.edu>
Message-ID: <46EEA41D.9040809@geo.uu.nl>

Hi Kim,

You could try:
substr("060907_17_3_5_1_1_2909.tif", start = 1, stop = 18)
?substr

cheers,
Paul

Kim Milferstedt schreef:
> Hello,
>
> I would like to remove the last 8 digists of character strings in a 
> vector. Below I added a couple of elements from that vector.
>
> I have a problem defining a pattern to replace the digits using for 
> example "sub". Removing the ".tif" part works fine using 
> sub('.tif',"",x), but how do I get rid of the four preceding digits?
>
> Thanks for your help,
>
> Kim
>
> Input:
> [3988] 
> "060907_17_3_5_1_1_2909.tif"   "060907_17_3_5_2_1_2910.tif" 
> "060907_17_3_5_3_1_2911.tif"
> [3991] 
> "060907_17_3_5_4_1_2912.tif"   "060907_17_3_5_5_1_2913.tif" 
> "060907_17_3_5_6_1_2914.tif"
>
> Desired output:
> [3988] "060907_17_3_5_1_1_"   "060907_17_3_5_2_1_"   "060907_17_3_5_3_1_"
> [3991] "060907_17_3_5_4_1_"   "060907_17_3_5_5_1_"   "060907_17_3_5_6_1_"
>
> __________________________________________
>
> Kim Milferstedt
> University of Illinois at Urbana-Champaign
> Department of Civil and Environmental Engineering
> 4125 Newmark Civil Engineering Laboratory
> 205 North Mathews Avenue MC-250
> Urbana, IL 61801
> USA
> phone: (001) 217 333-9663
> fax: (001) 217 333-6968
> email: milferst at uiuc.edu
> http://cee.uiuc.edu/research/morgenroth
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul


From jspies at nd.edu  Mon Sep 17 17:59:15 2007
From: jspies at nd.edu (Jeffrey Robert Spies)
Date: Mon, 17 Sep 2007 11:59:15 -0400
Subject: [R] removing a specific number of digist from a character string
In-Reply-To: <6.2.5.6.2.20070917101056.01eb1dd8@uiuc.edu>
References: <6.2.5.6.2.20070917101056.01eb1dd8@uiuc.edu>
Message-ID: <C9BFD9CB-CCFA-4B75-A5DC-B63C33254E6E@nd.edu>

test <- c("060907_17_3_5_1_1_2909.tif", "060907_17_3_5_2_1_2910.tif",  
"060907_17_3_5_3_1_2911.tif")
sub('[[:digit:]][[:digit:]][[:digit:]][[:digit:]]\.tif', '', test)

or

test <- c("060907_17_3_5_1_1_2909.tif", "060907_17_3_5_2_1_2910.tif",  
"060907_17_3_5_3_1_2911.tif")
sub('[[:digit:]]{4}\.tif', '', test)

-- Jeff.

On Sep 17, 2007, at 11:21 AM, Kim Milferstedt wrote:

> Hello,
>
> I would like to remove the last 8 digists of character strings in a
> vector. Below I added a couple of elements from that vector.
>
> I have a problem defining a pattern to replace the digits using for
> example "sub". Removing the ".tif" part works fine using
> sub('.tif',"",x), but how do I get rid of the four preceding digits?
>
> Thanks for your help,
>
> Kim
>
> Input:
> [3988]
> "060907_17_3_5_1_1_2909.tif"   "060907_17_3_5_2_1_2910.tif"
> "060907_17_3_5_3_1_2911.tif"
> [3991]
> "060907_17_3_5_4_1_2912.tif"   "060907_17_3_5_5_1_2913.tif"
> "060907_17_3_5_6_1_2914.tif"
>
> Desired output:
> [3988] "060907_17_3_5_1_1_"   "060907_17_3_5_2_1_"    
> "060907_17_3_5_3_1_"
> [3991] "060907_17_3_5_4_1_"   "060907_17_3_5_5_1_"    
> "060907_17_3_5_6_1_"
>
> __________________________________________
>
> Kim Milferstedt
> University of Illinois at Urbana-Champaign
> Department of Civil and Environmental Engineering
> 4125 Newmark Civil Engineering Laboratory
> 205 North Mathews Avenue MC-250
> Urbana, IL 61801
> USA
> phone: (001) 217 333-9663
> fax: (001) 217 333-6968
> email: milferst at uiuc.edu
> http://cee.uiuc.edu/research/morgenroth
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alfreale74 at gmail.com  Mon Sep 17 18:05:58 2007
From: alfreale74 at gmail.com (Alfredo Alessandrini)
Date: Mon, 17 Sep 2007 18:05:58 +0200
Subject: [R] data frame
Message-ID: <d2c05c5a0709170905m374fa70ew32ab109c66658553@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070917/212edf21/attachment.pl 

From stef at biostatistics.it  Mon Sep 17 18:18:10 2007
From: stef at biostatistics.it (Stefano Calza)
Date: Mon, 17 Sep 2007 18:18:10 +0200
Subject: [R] data frame
In-Reply-To: <d2c05c5a0709170905m374fa70ew32ab109c66658553@mail.gmail.com>
References: <d2c05c5a0709170905m374fa70ew32ab109c66658553@mail.gmail.com>
Message-ID: <20070917161810.GI4691@med.unibs.it>

Ciao,

do you mean the number of records?

something like 

nrow(a)

I would also suggest ncol(a) instad of length, which would work for a matrix as well.

[Italian]
E' quello che cercavi?
[/Italian]

Ciao

Stefano

On Mon, Sep 17, 2007 at 06:05:58PM +0200, Alfredo Alessandrini wrote:
<Alfredo>Hi everybody,
<Alfredo>
<Alfredo>If I've a data frame like this:
<Alfredo>
<Alfredo>dataframe a
<Alfredo>
<Alfredo>      X0  X2  X4  X6  X8 X10 X12 X14 X16
<Alfredo>1957   0   0   0   0   0   0   0   0   0
<Alfredo>1958   0   0   0   0   0   0   0   0   0
<Alfredo>1959 831   0   0   0   0   0   0   0   0
<Alfredo>1960 544 282   0   0   0   0   0   0   0
<Alfredo>1961 446 365   0   0   0   0   0   0   0
<Alfredo>1962 442 473   0   0   0   0   0   0   0
<Alfredo>1963 595 468   0   0   0   0   0   0   0
<Alfredo>1964 400 397 516   0   0   0   0   0   0
<Alfredo>1965 417 382 401   0   0   0   0   0   0
<Alfredo>1966 642 518 509 453   0   0   0   0   0
<Alfredo>1967 505 340 621 458   0   0   0   0   0
<Alfredo>1968 451 383 428 318 339   0   0   0   0
<Alfredo>
<Alfredo>> length (a)
<Alfredo>[1] 9
<Alfredo>
<Alfredo>I've a questions...
<Alfredo>
<Alfredo>There is a function for show the lenght of single observation?
<Alfredo>
<Alfredo>> ???? (a)
<Alfredo>[1] 12
<Alfredo>
<Alfredo>
<Alfredo>
<Alfredo>Best Wishes,
<Alfredo>
<Alfredo>Alfredo
<Alfredo>
<Alfredo>	[[alternative HTML version deleted]]
<Alfredo>
<Alfredo>______________________________________________
<Alfredo>R-help a r-project.org mailing list
<Alfredo>https://stat.ethz.ch/mailman/listinfo/r-help
<Alfredo>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
<Alfredo>and provide commented, minimal, self-contained, reproducible code.


From stef at biostatistics.it  Mon Sep 17 18:18:10 2007
From: stef at biostatistics.it (Stefano Calza)
Date: Mon, 17 Sep 2007 18:18:10 +0200
Subject: [R] data frame
In-Reply-To: <d2c05c5a0709170905m374fa70ew32ab109c66658553@mail.gmail.com>
References: <d2c05c5a0709170905m374fa70ew32ab109c66658553@mail.gmail.com>
Message-ID: <20070917161810.GI4691@med.unibs.it>

Ciao,

do you mean the number of records?

something like 

nrow(a)

I would also suggest ncol(a) instad of length, which would work for a matrix as well.

[Italian]
E' quello che cercavi?
[/Italian]

Ciao

Stefano

On Mon, Sep 17, 2007 at 06:05:58PM +0200, Alfredo Alessandrini wrote:
<Alfredo>Hi everybody,
<Alfredo>
<Alfredo>If I've a data frame like this:
<Alfredo>
<Alfredo>dataframe a
<Alfredo>
<Alfredo>      X0  X2  X4  X6  X8 X10 X12 X14 X16
<Alfredo>1957   0   0   0   0   0   0   0   0   0
<Alfredo>1958   0   0   0   0   0   0   0   0   0
<Alfredo>1959 831   0   0   0   0   0   0   0   0
<Alfredo>1960 544 282   0   0   0   0   0   0   0
<Alfredo>1961 446 365   0   0   0   0   0   0   0
<Alfredo>1962 442 473   0   0   0   0   0   0   0
<Alfredo>1963 595 468   0   0   0   0   0   0   0
<Alfredo>1964 400 397 516   0   0   0   0   0   0
<Alfredo>1965 417 382 401   0   0   0   0   0   0
<Alfredo>1966 642 518 509 453   0   0   0   0   0
<Alfredo>1967 505 340 621 458   0   0   0   0   0
<Alfredo>1968 451 383 428 318 339   0   0   0   0
<Alfredo>
<Alfredo>> length (a)
<Alfredo>[1] 9
<Alfredo>
<Alfredo>I've a questions...
<Alfredo>
<Alfredo>There is a function for show the lenght of single observation?
<Alfredo>
<Alfredo>> ???? (a)
<Alfredo>[1] 12
<Alfredo>
<Alfredo>
<Alfredo>
<Alfredo>Best Wishes,
<Alfredo>
<Alfredo>Alfredo
<Alfredo>
<Alfredo>	[[alternative HTML version deleted]]
<Alfredo>
<Alfredo>______________________________________________
<Alfredo>R-help a r-project.org mailing list
<Alfredo>https://stat.ethz.ch/mailman/listinfo/r-help
<Alfredo>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
<Alfredo>and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Mon Sep 17 18:39:07 2007
From: jholtman at gmail.com (jim holtman)
Date: Mon, 17 Sep 2007 12:39:07 -0400
Subject: [R] data frame
In-Reply-To: <d2c05c5a0709170905m374fa70ew32ab109c66658553@mail.gmail.com>
References: <d2c05c5a0709170905m374fa70ew32ab109c66658553@mail.gmail.com>
Message-ID: <644e1f320709170939x34643b40o8a8e2c2a4772e9e1@mail.gmail.com>

?str

On 9/17/07, Alfredo Alessandrini <alfreale74 at gmail.com> wrote:
> Hi everybody,
>
> If I've a data frame like this:
>
> dataframe a
>
>      X0  X2  X4  X6  X8 X10 X12 X14 X16
> 1957   0   0   0   0   0   0   0   0   0
> 1958   0   0   0   0   0   0   0   0   0
> 1959 831   0   0   0   0   0   0   0   0
> 1960 544 282   0   0   0   0   0   0   0
> 1961 446 365   0   0   0   0   0   0   0
> 1962 442 473   0   0   0   0   0   0   0
> 1963 595 468   0   0   0   0   0   0   0
> 1964 400 397 516   0   0   0   0   0   0
> 1965 417 382 401   0   0   0   0   0   0
> 1966 642 518 509 453   0   0   0   0   0
> 1967 505 340 621 458   0   0   0   0   0
> 1968 451 383 428 318 339   0   0   0   0
>
> > length (a)
> [1] 9
>
> I've a questions...
>
> There is a function for show the lenght of single observation?
>
> > ???? (a)
> [1] 12
>
>
>
> Best Wishes,
>
> Alfredo
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From jspies at nd.edu  Mon Sep 17 18:51:24 2007
From: jspies at nd.edu (Jeffrey Robert Spies)
Date: Mon, 17 Sep 2007 12:51:24 -0400
Subject: [R] data frame
In-Reply-To: <d2c05c5a0709170905m374fa70ew32ab109c66658553@mail.gmail.com>
References: <d2c05c5a0709170905m374fa70ew32ab109c66658553@mail.gmail.com>
Message-ID: <2BAAF0A9-9D7C-4BAE-AAB5-6C10A3473B73@nd.edu>

I believe you're looking for:

dim(a)

dim(a)[1]  # Number of observations, in your example, 12
dim(a)[2]  # Number of variables per observation, in your example, 9

--Jeff.


On Sep 17, 2007, at 12:05 PM, Alfredo Alessandrini wrote:

> Hi everybody,
>
> If I've a data frame like this:
>
> dataframe a
>
>       X0  X2  X4  X6  X8 X10 X12 X14 X16
> 1957   0   0   0   0   0   0   0   0   0
> 1958   0   0   0   0   0   0   0   0   0
> 1959 831   0   0   0   0   0   0   0   0
> 1960 544 282   0   0   0   0   0   0   0
> 1961 446 365   0   0   0   0   0   0   0
> 1962 442 473   0   0   0   0   0   0   0
> 1963 595 468   0   0   0   0   0   0   0
> 1964 400 397 516   0   0   0   0   0   0
> 1965 417 382 401   0   0   0   0   0   0
> 1966 642 518 509 453   0   0   0   0   0
> 1967 505 340 621 458   0   0   0   0   0
> 1968 451 383 428 318 339   0   0   0   0
>
>> length (a)
> [1] 9
>
> I've a questions...
>
> There is a function for show the lenght of single observation?
>
>> ???? (a)
> [1] 12
>
>
>
> Best Wishes,
>
> Alfredo
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jspies at nd.edu  Mon Sep 17 19:07:14 2007
From: jspies at nd.edu (Jeffrey Robert Spies)
Date: Mon, 17 Sep 2007 13:07:14 -0400
Subject: [R] removing a specific number of digist from a character string
In-Reply-To: <C9BFD9CB-CCFA-4B75-A5DC-B63C33254E6E@nd.edu>
References: <6.2.5.6.2.20070917101056.01eb1dd8@uiuc.edu>
	<C9BFD9CB-CCFA-4B75-A5DC-B63C33254E6E@nd.edu>
Message-ID: <586552D9-8253-4A6E-9CF7-27E13D997990@nd.edu>

For the sake of absolute correctness:

> sub('[[:digit:]]{4}\.tif', '', test)

should be

sub('[[:digit:]]{4}\\.tif', '', test)

-- Jeff.

On Sep 17, 2007, at 11:59 AM, Jeffrey Robert Spies wrote:

> test <- c("060907_17_3_5_1_1_2909.tif", "060907_17_3_5_2_1_2910.tif",
> "060907_17_3_5_3_1_2911.tif")
> sub('[[:digit:]][[:digit:]][[:digit:]][[:digit:]]\.tif', '', test)
>
> or
>
> test <- c("060907_17_3_5_1_1_2909.tif", "060907_17_3_5_2_1_2910.tif",
> "060907_17_3_5_3_1_2911.tif")
> sub('[[:digit:]]{4}\.tif', '', test)
>
> -- Jeff.
>
> On Sep 17, 2007, at 11:21 AM, Kim Milferstedt wrote:
>
>> Hello,
>>
>> I would like to remove the last 8 digists of character strings in a
>> vector. Below I added a couple of elements from that vector.
>>
>> I have a problem defining a pattern to replace the digits using for
>> example "sub". Removing the ".tif" part works fine using
>> sub('.tif',"",x), but how do I get rid of the four preceding digits?
>>
>> Thanks for your help,
>>
>> Kim
>>
>> Input:
>> [3988]
>> "060907_17_3_5_1_1_2909.tif"   "060907_17_3_5_2_1_2910.tif"
>> "060907_17_3_5_3_1_2911.tif"
>> [3991]
>> "060907_17_3_5_4_1_2912.tif"   "060907_17_3_5_5_1_2913.tif"
>> "060907_17_3_5_6_1_2914.tif"
>>
>> Desired output:
>> [3988] "060907_17_3_5_1_1_"   "060907_17_3_5_2_1_"
>> "060907_17_3_5_3_1_"
>> [3991] "060907_17_3_5_4_1_"   "060907_17_3_5_5_1_"
>> "060907_17_3_5_6_1_"
>>
>> __________________________________________
>>
>> Kim Milferstedt
>> University of Illinois at Urbana-Champaign
>> Department of Civil and Environmental Engineering
>> 4125 Newmark Civil Engineering Laboratory
>> 205 North Mathews Avenue MC-250
>> Urbana, IL 61801
>> USA
>> phone: (001) 217 333-9663
>> fax: (001) 217 333-6968
>> email: milferst at uiuc.edu
>> http://cee.uiuc.edu/research/morgenroth
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Costanza.Pizzi at lshtm.ac.uk  Mon Sep 17 19:10:27 2007
From: Costanza.Pizzi at lshtm.ac.uk (Costanza Pizzi)
Date: Mon, 17 Sep 2007 18:10:27 +0100
Subject: [R] var/cov matrix for a quantile regression model
Message-ID: <46EEC312.ABCC.00EE.0@lshtm.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070917/8686559b/attachment.pl 

From gunter.berton at gene.com  Mon Sep 17 19:10:50 2007
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 17 Sep 2007 10:10:50 -0700
Subject: [R] removing a specific number of digist from a character string
In-Reply-To: <C9BFD9CB-CCFA-4B75-A5DC-B63C33254E6E@nd.edu>
References: <6.2.5.6.2.20070917101056.01eb1dd8@uiuc.edu>
	<C9BFD9CB-CCFA-4B75-A5DC-B63C33254E6E@nd.edu>
Message-ID: <008401c7f94d$b27616b0$3a0b2c0a@gne.windows.gene.com>

Please note that the second expression below should be:

 sub('[[:digit:]]{4}\\.tif', '', test)

The backslashes must be doubled: (from the ?regexpr Help file:

"Patterns are described here as they would be printed by cat: do remember
that backslashes need to be doubled when entering R character strings from
the keyboard. ")

Bert Gunter
Genentech Nonclinical Statistics


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Jeffrey Robert Spies
Sent: Monday, September 17, 2007 8:59 AM
To: Kim Milferstedt
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] removing a specific number of digist from a character
string

test <- c("060907_17_3_5_1_1_2909.tif", "060907_17_3_5_2_1_2910.tif",  
"060907_17_3_5_3_1_2911.tif")
sub('[[:digit:]][[:digit:]][[:digit:]][[:digit:]]\.tif', '', test)

or

test <- c("060907_17_3_5_1_1_2909.tif", "060907_17_3_5_2_1_2910.tif",  
"060907_17_3_5_3_1_2911.tif")
sub('[[:digit:]]{4}\.tif', '', test)

-- Jeff.

On Sep 17, 2007, at 11:21 AM, Kim Milferstedt wrote:

> Hello,
>
> I would like to remove the last 8 digists of character strings in a
> vector. Below I added a couple of elements from that vector.
>
> I have a problem defining a pattern to replace the digits using for
> example "sub". Removing the ".tif" part works fine using
> sub('.tif',"",x), but how do I get rid of the four preceding digits?
>
> Thanks for your help,
>
> Kim
>
> Input:
> [3988]
> "060907_17_3_5_1_1_2909.tif"   "060907_17_3_5_2_1_2910.tif"
> "060907_17_3_5_3_1_2911.tif"
> [3991]
> "060907_17_3_5_4_1_2912.tif"   "060907_17_3_5_5_1_2913.tif"
> "060907_17_3_5_6_1_2914.tif"
>
> Desired output:
> [3988] "060907_17_3_5_1_1_"   "060907_17_3_5_2_1_"    
> "060907_17_3_5_3_1_"
> [3991] "060907_17_3_5_4_1_"   "060907_17_3_5_5_1_"    
> "060907_17_3_5_6_1_"
>
> __________________________________________
>
> Kim Milferstedt
> University of Illinois at Urbana-Champaign
> Department of Civil and Environmental Engineering
> 4125 Newmark Civil Engineering Laboratory
> 205 North Mathews Avenue MC-250
> Urbana, IL 61801
> USA
> phone: (001) 217 333-9663
> fax: (001) 217 333-6968
> email: milferst at uiuc.edu
> http://cee.uiuc.edu/research/morgenroth
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Mike.Lawrence at DAL.CA  Mon Sep 17 19:17:03 2007
From: Mike.Lawrence at DAL.CA (Mike Lawrence)
Date: Mon, 17 Sep 2007 14:17:03 -0300
Subject: [R] Create correlated data with skew
Message-ID: <94A21AC3-A7E3-4B2B-B731-59B76D461D2F@DAL.CA>

Hi all,

I understand that it is simple to create data with a specific  
correlation (say, .5) using mvrnorm from the MASS library:

 > library(MASS)
 > set.seed(1)
 >
 > a=mvrnorm(
+ 	n=10
+ 	,mu=rep(0,2)
+ 	,Sigma=matrix(c(1,.5,.5,1),2,2)
+ 	,empirical=T
+ )
 > a
             [,1]         [,2]
[1,] -1.0008380 -1.233467875
[2,] -0.1588633 -0.003410001
[3,]  1.2054727 -0.620558768
[4,]  1.9580971  2.389495155
[5,] -0.9447473 -0.141852055
[6,]  0.6236799 -0.826952659
[7,]  0.1421782  0.452217611
[8,] -0.9050954  0.330991444
[9,] -0.7261632  0.217740460
[10,] -0.1937206 -0.564203311
 > cor(a)
      [,1] [,2]
[1,]  1.0  0.5
[2,]  0.5  1.0


But I'm looking to create data where the variables are non-normally  
distributed (i.e. somewhat skewed). Any suggestions?

Mike

--
Mike Lawrence
Graduate Student, Department of Psychology, Dalhousie University

Website: http://memetic.ca

Public calendar: http://icalx.com/public/informavore/Public

"The road to wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
	- Piet Hein


From epistat at gmail.com  Mon Sep 17 19:19:03 2007
From: epistat at gmail.com (zhijie zhang)
Date: Tue, 18 Sep 2007 01:19:03 +0800
Subject: [R] What's the corresponding function in R for lo() function in
	S-PLUS?
Message-ID: <2fc17e30709171019h64618f5fi646ae27cf4cbd33a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070918/b037bbcf/attachment.pl 

From Charles.Annis at StatisticalEngineering.com  Mon Sep 17 19:24:07 2007
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Mon, 17 Sep 2007 13:24:07 -0400
Subject: [R] What's the corresponding function in R for lo() function
	inS-PLUS?
In-Reply-To: <2fc17e30709171019h64618f5fi646ae27cf4cbd33a@mail.gmail.com>
References: <2fc17e30709171019h64618f5fi646ae27cf4cbd33a@mail.gmail.com>
Message-ID: <0b2601c7f94f$8e0b8240$6400a8c0@DD4XFW31>

?loess








Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  614-455-3265
http://www.StatisticalEngineering.com
 

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of zhijie zhang
Sent: Monday, September 17, 2007 1:19 PM
To: R-help at stat.math.ethz.ch
Subject: [R] What's the corresponding function in R for lo() function
inS-PLUS?

Dear friends,
  In S-PLUS, we can use the following argument, but not in R.
mode12 <- gam(score1 ~ lo(latitude) + lo(longitude))
 I searched the help in S-PLUS, it says lo() Allows the user to specify a
Loess fit in a GAM formula, but i didn't find the correponding function in
R.
 Anybody knows how to do the similar task in R?
 Thanks very much.

-- 
With Kind Regards,

oooO:::::::::
(..):::::::::
:\.(:::Oooo::
::\_)::(..)::
:::::::)./:::
::::::(_/::::
:::::::::::::
[***********************************************************************]
Zhi Jie,Zhang ,PHD
Tel:86-21-54237149
Dept. of Epidemiology,School of Public Health,Fudan University
Address:No. 138 Yi Xue Yuan Road,Shanghai,China
Postcode:200032
Email:epistat at gmail.com
Website: www.statABC.com
[***********************************************************************]
oooO:::::::::
(..):::::::::
:\.(:::Oooo::
::\_)::(..)::
:::::::)./:::
::::::(_/::::
:::::::::::::

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jhorn at bu.edu  Mon Sep 17 20:00:20 2007
From: jhorn at bu.edu (Jason Horn)
Date: Mon, 17 Sep 2007 14:00:20 -0400
Subject: [R] How to produce a macron symbol (overline / overbar) on a plot
Message-ID: <517E0A05-C35E-4902-9E1A-40F9A4482058@bu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070917/976a6a50/attachment.pl 

From cryan at binghamton.edu  Mon Sep 17 21:04:46 2007
From: cryan at binghamton.edu (Christopher W. Ryan)
Date: Mon, 17 Sep 2007 14:04:46 -0500
Subject: [R] color schemes in Tinn-R
Message-ID: <46EECFCE.5050408@binghamton.edu>

A question for anyone using Tinn-R:  I find that using the default color
scheme with the white background on my laptop hard on the ole' eyes.  I
see the drop-down menus leading to the ability to change the colors of
individual components (numbers, commmands, strings, etc, and the
background for each of those.)  I can play around with background colors
and foreground colors.  However, I'm wondering if there is a collection
of downloadable/installable color schemes?  Or one that someone might
share?  I mostly want to get a dark background, and bright characters of
various colors depending on syntax.

Thanks.
-- 
Christopher W. Ryan, MD
SUNY Upstate Medical University Clinical Campus at Binghamton
40 Arch Street, Johnson City, NY  13790
cryanatbinghamtondotedu
PGP public keys available at http://home.stny.rr.com/ryancw/

"If you want to build a ship, don't drum up the men to gather wood,
divide the work and give orders. Instead, teach them to yearn for the
vast and endless sea."  [Antoine de St. Exupery]


From maura.monville at gmail.com  Mon Sep 17 20:11:26 2007
From: maura.monville at gmail.com (Maura E Monville)
Date: Mon, 17 Sep 2007 13:11:26 -0500
Subject: [R] How can I write routines and scripts in the R environment ?
Message-ID: <36d691950709171111i6085d52btabac049d94bb2cb8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070917/9f2533b8/attachment.pl 

From marc_schwartz at comcast.net  Mon Sep 17 20:12:15 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Mon, 17 Sep 2007 13:12:15 -0500
Subject: [R] How to produce a macron symbol (overline / overbar) on
	a	plot
In-Reply-To: <517E0A05-C35E-4902-9E1A-40F9A4482058@bu.edu>
References: <517E0A05-C35E-4902-9E1A-40F9A4482058@bu.edu>
Message-ID: <1190052735.3770.7.camel@Bellerophon.localdomain>

On Mon, 2007-09-17 at 14:00 -0400, Jason Horn wrote:
> Can anyone tell me how to produce a macron (or overbar or overline)  
> symbol on an R plot.  I have an axis that is labeled "temp", but I  
> need the overbar symbol over the entire word.

See ?plotmath and the examples therein.

Example:

  plot(1, xlab = expression(bar(temp)))

HTH,

Marc Schwartz


From wl2776 at gmail.com  Mon Sep 17 20:14:50 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Mon, 17 Sep 2007 11:14:50 -0700 (PDT)
Subject: [R] graphs with gradients of colors
In-Reply-To: <36B62AB1E934124BA81C2B3B615E9F008119CD@xmail05.ad.ua.ac.be>
References: <36B62AB1E934124BA81C2B3B615E9F008119CD@xmail05.ad.ua.ac.be>
Message-ID: <12741808.post@talk.nabble.com>


Maybe this information (from the R's father) can be of some help.
http://www.stat.auckland.ac.nz/~ihaka/Graphics/index.html


Van Dongen Stefan wrote:
> 
> Hi All,
>  
> I would like to fill the area under a curve with a gradient of colors. Are
> there any packages or trick I could use
>  
> Thanks
>  
> Stefan
>  
> 

-- 
View this message in context: http://www.nabble.com/graphs-with-gradients-of-colors-tf4466780.html#a12741808
Sent from the R help mailing list archive at Nabble.com.


From alexnerdy at hotmail.com  Mon Sep 17 20:21:05 2007
From: alexnerdy at hotmail.com (Alexander Nervedi)
Date: Mon, 17 Sep 2007 18:21:05 +0000
Subject: [R] map issues
Message-ID: <BLU111-W508AF3269EDE7BB71BF6CCBBBF0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070917/ab22ec16/attachment.pl 

From wl2776 at gmail.com  Mon Sep 17 20:24:41 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Mon, 17 Sep 2007 11:24:41 -0700 (PDT)
Subject: [R] How to produce a macron symbol (overline / overbar) on a
 plot
In-Reply-To: <517E0A05-C35E-4902-9E1A-40F9A4482058@bu.edu>
References: <517E0A05-C35E-4902-9E1A-40F9A4482058@bu.edu>
Message-ID: <12742054.post@talk.nabble.com>


xlab=expression(bar(temp))
or
xlab=expression(bar(" temp")) 

The overbar looks like it begins above "e" in the first case.

See demo(plotmath).


Jason Horn wrote:
> 
> Can anyone tell me how to produce a macron (or overbar or overline)  
> symbol on an R plot.  I have an axis that is labeled "temp", but I  
> need the overbar symbol over the entire word.
> 

-- 
View this message in context: http://www.nabble.com/How-to-produce-a-macron-symbol-%28overline---overbar%29-on-a-plot-tf4468656.html#a12742054
Sent from the R help mailing list archive at Nabble.com.


From riddle_chin at yahoo.com  Mon Sep 17 20:28:05 2007
From: riddle_chin at yahoo.com (Riddle Chin)
Date: Mon, 17 Sep 2007 11:28:05 -0700 (PDT)
Subject: [R] problems with nested loop
Message-ID: <99116.68733.qm@web45513.mail.sp1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070917/74721d08/attachment.pl 

From wl2776 at gmail.com  Mon Sep 17 20:34:38 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Mon, 17 Sep 2007 11:34:38 -0700 (PDT)
Subject: [R] actually, problems with indexing
In-Reply-To: <99116.68733.qm@web45513.mail.sp1.yahoo.com>
References: <99116.68733.qm@web45513.mail.sp1.yahoo.com>
Message-ID: <12742249.post@talk.nabble.com>




Riddle Chin wrote:
> 
> Hi, everyone:
>      R is new to me. I am writing a nested loop to simulate data for
> t-test. The following code is wrong. The subscript is out of bounds. Could
> anyone tell me how to revise it? Thanks, Riddle Chin.
>    
>   result<-matrix(ncol=5, nrow=1000)
> colnames(result)<-c('N=20','N=40','N=60','N=80','N=100')
>  for (i in 1:1000){
> 
   for (j in 1:5){
     x<-rnorm(j*20,2.7,1)

Riddle Chin wrote:
> 
>      result[i,j]<-t.test(x,mu=4)$p.value<=0.05
>    }
>  }
> 
> 

-- 
View this message in context: http://www.nabble.com/problems-with-nested-loop-tf4468945.html#a12742249
Sent from the R help mailing list archive at Nabble.com.


From gavin.simpson at ucl.ac.uk  Mon Sep 17 20:43:00 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Mon, 17 Sep 2007 19:43:00 +0100
Subject: [R] What's the corresponding function in R for lo() function	in
	S-PLUS?
In-Reply-To: <2fc17e30709171019h64618f5fi646ae27cf4cbd33a@mail.gmail.com>
References: <2fc17e30709171019h64618f5fi646ae27cf4cbd33a@mail.gmail.com>
Message-ID: <1190054580.2895.6.camel@graptoleberis.geog.ucl.ac.uk>

On Tue, 2007-09-18 at 01:19 +0800, zhijie zhang wrote:
> Dear friends,
>   In S-PLUS, we can use the following argument, but not in R.
> mode12 <- gam(score1 ~ lo(latitude) + lo(longitude))
>  I searched the help in S-PLUS, it says lo() Allows the user to specify a
> Loess fit in a GAM formula, but i didn't find the correponding function in
> R.
>  Anybody knows how to do the similar task in R?

See function gam() in package gam, available from CRAN, which makes us
of lo() (also available in the gam package). This closely follows the
implementation in S-PLUS.

Note that gam() in recommended package mgcv (distributed with R)
provides an alternative approach to GAM modelling, which you might wish
to take a look at as well.

By the way, you could have solved this yourself in a matter of seconds
if you'd used the R search tools. The following

RSiteSearch("lo", restrict = "functions")

returns the correct answer as the first hit.

HTH

G

>  Thanks very much.
> 
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From Ted.Harding at manchester.ac.uk  Mon Sep 17 21:09:02 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Mon, 17 Sep 2007 20:09:02 +0100 (BST)
Subject: [R] How can I write routines and scripts in the R environmen
In-Reply-To: <36d691950709171111i6085d52btabac049d94bb2cb8@mail.gmail.com>
Message-ID: <XFMail.070917200902.Ted.Harding@manchester.ac.uk>

On 17-Sep-07 18:11:26, Maura E Monville wrote:
> I would like to plot some semi-periodic signals as a function
> of the phase expressed as a value in [0,2PI]
> The problem is that the phase data is reported as the residual
> of the division by 2PI.
> For instance if the phase is 10.359 rd  then:
> 15.359 / 6.283185  = 2*6.283185 + 2.79263
> then only the residual 2.79263 is stored. 
> In order to plot a number of consecutive cycles I have to add
> the correct multiple of 2PI  to each phase valu.
> The end/beginning of  anew cycle is marked in another field,
> say phase-mark, containing the letter "Z".
> My goal is to write a small routine that does that for each
> signal file.
> If I had to do that in C language I'd write something like:
> 
> num-cycles = 0;
> for (i=0,i<num-records; i++) {
>    if ( my.data.frame$phase_mark[i] =="Z" )  {
>         my.data.frame$phase[i]  += num-cycles*2PI;
>         num-cycles++;
>    }
> }
> 
> Questions:
> 
> 1. How can I write a small routine like the one above to operate
> on certain columns of an entire data.frame ?
> 
One technique for computing what you want is on the following
lines. You don't say what is in your variable "phase_mark"
(which I'll call "phasemark" to get rid of the "_"), but
I'll assume that it is NA unless there is a "Z" there.
In that case, consider the following as a hint:

phasemark<-c("Z",NA,NA,"Z",NA,NA,NA,NA,"Z",NA,NA,"Z")

1*((!is.na(phasemark)&(phasemark=="Z")))
## [1] 1 0 0 1 0 0 0 0 1 0 0 1

cumsum((!is.na(phasemark)&(phasemark=="Z"))) - 1
## [1] 0 0 0 1 1 1 1 1 2 2 2 3

(i.e. the first "Z" marks the first cycle, so you add 0 multiples
of 2*pi).

So now if you create

phaseno <- cumsum((!is.na(phasemark)&(phasemark=="Z"))) - 1

you can simply add 2*pi*phaseno to your variable phase.

A for "operating on certain columns", you have basically
done this already by using the selector "$", which extracts the
named column. You can equally well assign to it, e.g.

> 2. How can I write a parametric R script (like a shell script
> in Linux) that reads a CSV file into a new R data.frame?
> The commands I now issue manually are as follows:
> 
> read.csv("file-name",header=T,skip=9)
> file-name$PatientID = paste(rep("file-name",length(file-name[,1])))
> names(file-names)= c("Amplitude","Phase", ....)

DON'T use a name like "file-name" for an object in R!! R will read
it as though you are trying to subtract something from a variable
called "file".

Your first line should be like

Data <- read.csv("file-name",header=T,skip=9)

Your remaining commands are difficult to interpret without
more explicit detail of how the data are stored in the file
"file-name", so I can't relate my suggested computation above
to what you've written.

However, suppose that the dataframe Data as read in above
has columns Amplitude, Phase, PhaseMark (NOT Phase-Mark!!)
then you could create

Data$Phase <- Data$Phase +
2*pi*(cumsum((!is.na(Data$PhaseMark)&(Data$PhaseMark=="Z"))) - 1)

which would over-write the original Data$Phase, or you can
augment Data with a new column Data$PhasePlus by using

Data$PhasePlus <- Data$Phase +
2*pi*(cumsum((!is.na(Data$PhaseMark)&(Data$PhaseMark=="Z"))) - 1)

which will leave you original Data$Phase untouched, and add
an extra column Data$PhasePlus.

As for writing a "parametric R script", you could define
a function like

read.my.file <- function(filename){
  Data <- read.csv(file=filename,header=T,skip=9)
  Data$PhasePlus <- Data$Phase +
  2*pi*
  (cumsum((!is.na(Data$PhaseMark)&(Data$PhaseMark=="Z")))
   - 1)
  [anything else you want to do at read-in time]
  Data
}

(or you could include header and skip as parameters as well)
and then call it with

MyNewData <- read.my.file("my-new-file")


Hoping this helps,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 17-Sep-07                                       Time: 20:08:47
------------------------------ XFMail ------------------------------


From rkoenker at uiuc.edu  Mon Sep 17 21:27:44 2007
From: rkoenker at uiuc.edu (roger koenker)
Date: Mon, 17 Sep 2007 14:27:44 -0500
Subject: [R] var/cov matrix for a quantile regression model
In-Reply-To: <46EEC312.ABCC.00EE.0@lshtm.ac.uk>
References: <46EEC312.ABCC.00EE.0@lshtm.ac.uk>
Message-ID: <077B60DC-1323-4C28-A0B9-8DD7E880E388@uiuc.edu>

You need to say

	summary(rq(....),cov=TRUE)$cov

see

	?summary.rq

for further details.

url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Champaign, IL 61820


On Sep 17, 2007, at 12:10 PM, Costanza Pizzi wrote:

> Dear all,
>
> I'm trying to get the variance/covarince matrix after fitting a
> quantile regression model (either linear or non linear), in order  
> to get
> the variance of my predictions and be able to calculate the median
> squared error.
> The commands working for the lm models (corr=T or vcov=T) do not  seem
> to work for the rq models.
>
> Could you advise me a way of getting it?
>
> Best regards
>
> Costanza Pizzi
> Medical Statistics Unit, LSHTM, London
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Mon Sep 17 21:40:37 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 Sep 2007 20:40:37 +0100 (BST)
Subject: [R] What's the corresponding function in R for lo() function
 inS-PLUS?
In-Reply-To: <0b2601c7f94f$8e0b8240$6400a8c0@DD4XFW31>
References: <2fc17e30709171019h64618f5fi646ae27cf4cbd33a@mail.gmail.com>
	<0b2601c7f94f$8e0b8240$6400a8c0@DD4XFW31>
Message-ID: <Pine.LNX.4.64.0709172034350.30714@gannet.stats.ox.ac.uk>

On Mon, 17 Sep 2007, Charles Annis, P.E. wrote:

> ?loess

packages gam and mgcv both provide gam() functions in R: package gam is 
very close to the S(-PLUS) implementation and would fit the model given 
(in so far as we can tell from a non-reproducible example).

loess will allow a general smooth function of 2 arguments, but not 
(directly) an additive model.  Having said that, I would be suspicious of 
an additive model of two rather artificial variables such as latitude and 
longitude (unless the scale is large the angle of the earth's axis is 
usually of very minor importance), so a 2D loess fit might well be more 
informative.

> Charles Annis, P.E.
>
> Charles.Annis at StatisticalEngineering.com
> phone: 561-352-9699
> eFax:  614-455-3265
> http://www.StatisticalEngineering.com
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf Of zhijie zhang
> Sent: Monday, September 17, 2007 1:19 PM
> To: R-help at stat.math.ethz.ch
> Subject: [R] What's the corresponding function in R for lo() function
> inS-PLUS?
>
> Dear friends,
>  In S-PLUS, we can use the following argument, but not in R.
> mode12 <- gam(score1 ~ lo(latitude) + lo(longitude))
> I searched the help in S-PLUS, it says lo() Allows the user to specify a
> Loess fit in a GAM formula, but i didn't find the correponding function in
> R.
> Anybody knows how to do the similar task in R?
> Thanks very much.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From stubben at lanl.gov  Mon Sep 17 21:41:23 2007
From: stubben at lanl.gov (Chris Stubben)
Date: Mon, 17 Sep 2007 12:41:23 -0700 (PDT)
Subject: [R] graphs with gradients of colors
In-Reply-To: <36B62AB1E934124BA81C2B3B615E9F008119CD@xmail05.ad.ua.ac.be>
References: <36B62AB1E934124BA81C2B3B615E9F008119CD@xmail05.ad.ua.ac.be>
Message-ID: <12743725.post@talk.nabble.com>


You could use a loop and fill small polygons with colors.

x<-seq(-3, 3, .01)
y<-eval(expression(x^3-3*x))
plot(x,y, type="n", las=1)   
n<-length(x)

# vertical bars
for(i in 1:n)
{
polygon(c(x[i], x[i], x[i+1], x[i+1]), c(min(y), y[i], y[i+1], min(y)),
border=0, col = rainbow(n)[i]) 
}

## or split each vertical bars into 100 smaller blocks
plot(x,y, type="n", las=1)
for(i in 1:n)
{
  y1<-seq(y[i], min(y), length.out=101)
  y2<-seq(y[i+1], min(y), length.out=101)
  for(j in 1:100)
  { 
    polygon(c(x[i], x[i], x[i+1], x[i+1]), c(y1[j+1], y1[j], y2[j],
y2[j+1]), border=0, col = rev(heat.colors(100))[j]) 
  }
}

Chris Stubben




Van Dongen Stefan wrote:
> 
> Hi All,
>  
> I would like to fill the area under a curve with a gradient of colors. Are
> there any packages or trick I could use
>  
> Thanks
>  
> Stefan
>  
>  
> Stefan Van Dongen
> Antwerp
> 
> 
> 
> 

-- 
View this message in context: http://www.nabble.com/graphs-with-gradients-of-colors-tf4466780.html#a12743725
Sent from the R help mailing list archive at Nabble.com.


From dxc13 at health.state.ny.us  Mon Sep 17 21:48:07 2007
From: dxc13 at health.state.ny.us (dxc13)
Date: Mon, 17 Sep 2007 12:48:07 -0700 (PDT)
Subject: [R] how to compare 2 numeric vectors
Message-ID: <12743842.post@talk.nabble.com>


useR's

I am trying to compare two vectors that have the same length.  More
specifically, I am interested in comparing the corresponding positions of
each element in the vector. 

Consider these two vectors of length 20:

v1 <-  2    2    4    NA  NA  NA  10  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
NA  NA  NA
v2 <-  NA  4  NA    NA  NA  NA  10  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
NA  100 NA

I am only interested in extracting the position number where both vectors
are not equal to NA at the same position.
For example, the second element of both vectors is not equal to NA, and thus
I want to return '2'; similary, I also would want to have '7' returned
because the seventh element of both arrays is not equal to NA.

In general, I would like to find a way to do this for any number of given
positions between the two vectors that satisfy this.  If no positions
satisfy this, then return '0'

I would like to store the results as an object.

If anyone has any ideas, I would greatly appreciate it. Thanks!

dxc13
-- 
View this message in context: http://www.nabble.com/how-to-compare-2-numeric-vectors-tf4469582.html#a12743842
Sent from the R help mailing list archive at Nabble.com.


From p_connolly at ihug.co.nz  Mon Sep 17 21:52:29 2007
From: p_connolly at ihug.co.nz (Patrick Connolly)
Date: Tue, 18 Sep 2007 07:52:29 +1200
Subject: [R] x-axis order
In-Reply-To: <644e1f320709141118n51f2349bn37f7d3f967f85654@mail.gmail.com>
References: <45f568c70709140831y2c390fd4l256e9c5ce53079e1@mail.gmail.com>
	<644e1f320709141118n51f2349bn37f7d3f967f85654@mail.gmail.com>
Message-ID: <20070917195229.GA5829@ihug.co.nz>

On Fri, 14-Sep-2007 at 02:18PM -0400, jim holtman wrote:

|> This should do what you want.
|> 
|> x<-c(26:52,1:25)
|> y<-rnorm(52)+1:52
|> 
|> plot(seq_along(x), y, xaxt='n')
|> axis(1, at=seq_along(x), labels=x)

And if you have to economize on keystrokes, 
seq(x) will achieve the same as seq_along(x)

HTH

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}          		 Great minds discuss ideas    
 _( Y )_  	  	        Middle minds discuss events 
(:_~*~_:) 	       		 Small minds discuss people  
 (_)-(_)  	                           ..... Anon
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From jholtman at gmail.com  Mon Sep 17 21:54:28 2007
From: jholtman at gmail.com (jim holtman)
Date: Mon, 17 Sep 2007 15:54:28 -0400
Subject: [R] how to compare 2 numeric vectors
In-Reply-To: <12743842.post@talk.nabble.com>
References: <12743842.post@talk.nabble.com>
Message-ID: <644e1f320709171254u7949817i15f679eea21f832b@mail.gmail.com>

Here is one way of doing it:

> v1
 [1]  1  1 NA NA  1 NA NA NA NA  1  1  1 NA  1 NA  1 NA NA  1 NA
> v2
 [1] NA  1 NA  1  1  1  1  1 NA  1  1 NA  1  1 NA NA NA  1 NA  1
> which(!(is.na(v1) | is.na(v2)))
[1]  2  5 10 11 14
>


On 9/17/07, dxc13 <dxc13 at health.state.ny.us> wrote:
>
> useR's
>
> I am trying to compare two vectors that have the same length.  More
> specifically, I am interested in comparing the corresponding positions of
> each element in the vector.
>
> Consider these two vectors of length 20:
>
> v1 <-  2    2    4    NA  NA  NA  10  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
> NA  NA  NA
> v2 <-  NA  4  NA    NA  NA  NA  10  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
> NA  100 NA
>
> I am only interested in extracting the position number where both vectors
> are not equal to NA at the same position.
> For example, the second element of both vectors is not equal to NA, and thus
> I want to return '2'; similary, I also would want to have '7' returned
> because the seventh element of both arrays is not equal to NA.
>
> In general, I would like to find a way to do this for any number of given
> positions between the two vectors that satisfy this.  If no positions
> satisfy this, then return '0'
>
> I would like to store the results as an object.
>
> If anyone has any ideas, I would greatly appreciate it. Thanks!
>
> dxc13
> --
> View this message in context: http://www.nabble.com/how-to-compare-2-numeric-vectors-tf4469582.html#a12743842
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From stephenc at ics.mq.edu.au  Mon Sep 17 21:55:07 2007
From: stephenc at ics.mq.edu.au (stephenc at ics.mq.edu.au)
Date: Tue, 18 Sep 2007 05:55:07 +1000 (EST)
Subject: [R] machine learning and horse racing
Message-ID: <2926.60.241.49.44.1190058907.squirrel@webmail.ics.mq.edu.au>

Hi

 I am trying to use various techniques (eg svm, logistic regression,
neural networks) to classify and predict the outcome of horse races.

 Most of my predictive features are categorical  - horse, jockey, trainer 
- and I keep on running out of memory owing to the size of the vector.

 Does anyone know how to solve the problem?

 I have classified the outcomes as win/lose or place/lose with a view to
train on x years of results and then testing on the subsequent years
results. Is there some alternate way of looking at the problem?

 Does anyone have pointers to published work in this area?

 Thanks.

 Stephen


From jholtman at gmail.com  Mon Sep 17 21:59:09 2007
From: jholtman at gmail.com (jim holtman)
Date: Mon, 17 Sep 2007 15:59:09 -0400
Subject: [R] x-axis order
In-Reply-To: <20070917195229.GA5829@ihug.co.nz>
References: <45f568c70709140831y2c390fd4l256e9c5ce53079e1@mail.gmail.com>
	<644e1f320709141118n51f2349bn37f7d3f967f85654@mail.gmail.com>
	<20070917195229.GA5829@ihug.co.nz>
Message-ID: <644e1f320709171259m78e2e8abg56ef66843df89564@mail.gmail.com>

But not necessarily performance.  Look at the code for 'seq' and
'seq_along'.  Time difference may be small, but keystrokes are done
only once.

On 9/17/07, Patrick Connolly <p_connolly at ihug.co.nz> wrote:
> On Fri, 14-Sep-2007 at 02:18PM -0400, jim holtman wrote:
>
> |> This should do what you want.
> |>
> |> x<-c(26:52,1:25)
> |> y<-rnorm(52)+1:52
> |>
> |> plot(seq_along(x), y, xaxt='n')
> |> axis(1, at=seq_along(x), labels=x)
>
> And if you have to economize on keystrokes,
> seq(x) will achieve the same as seq_along(x)
>
> HTH
>
> --
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>   ___    Patrick Connolly
>  {~._.~}                         Great minds discuss ideas
>  _( Y )_                        Middle minds discuss events
> (:_~*~_:)                        Small minds discuss people
>  (_)-(_)                                   ..... Anon
>
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From jholtman at gmail.com  Mon Sep 17 22:01:18 2007
From: jholtman at gmail.com (jim holtman)
Date: Mon, 17 Sep 2007 16:01:18 -0400
Subject: [R] machine learning and horse racing
In-Reply-To: <2926.60.241.49.44.1190058907.squirrel@webmail.ics.mq.edu.au>
References: <2926.60.241.49.44.1190058907.squirrel@webmail.ics.mq.edu.au>
Message-ID: <644e1f320709171301p6a55668cr6cb62a517413f4cc@mail.gmail.com>

Need more information.  What is your operating system, how much memory
do you have, how big is your data, what operations are you failing on,
etc.

On 9/17/07, stephenc at ics.mq.edu.au <stephenc at ics.mq.edu.au> wrote:
> Hi
>
>  I am trying to use various techniques (eg svm, logistic regression,
> neural networks) to classify and predict the outcome of horse races.
>
>  Most of my predictive features are categorical  - horse, jockey, trainer
> - and I keep on running out of memory owing to the size of the vector.
>
>  Does anyone know how to solve the problem?
>
>  I have classified the outcomes as win/lose or place/lose with a view to
> train on x years of results and then testing on the subsequent years
> results. Is there some alternate way of looking at the problem?
>
>  Does anyone have pointers to published work in this area?
>
>  Thanks.
>
>  Stephen
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From ymoisan at groupesm.com  Mon Sep 17 22:10:42 2007
From: ymoisan at groupesm.com (Yves Moisan)
Date: Mon, 17 Sep 2007 13:10:42 -0700 (PDT)
Subject: [R] Intermediate R-squared results in stepwise regression
Message-ID: <12744210.post@talk.nabble.com>


Hi All,

Following from  https://stat.ethz.ch/pipermail/r-help/1999-April/003834.html
this post  where someone was asking for "a slick way of asking for the
results of doing a forward selection/backward elimination routine?" and
someone answered "Call step(), print the anova component of the result is
the usual way", I was asked to find out about intermediate results, namely
R-squared (or adjusted R-squared) as forward or backward stepwise regression
proceeds.  Does the information in the ANOVA table provide all I need, in
which case I would need to be pointed to a link where anova() output is
explained in more theoretical (or I should say layman-compatible) terms than
in the anova help file?  How do I know which variable was selected/dropped
first, second, etc?

TIA,

Yves Moisan
-- 
View this message in context: http://www.nabble.com/Intermediate-R-squared-results-in-stepwise-regression-tf4469701.html#a12744210
Sent from the R help mailing list archive at Nabble.com.


From albmont at centroin.com.br  Mon Sep 17 22:11:51 2007
From: albmont at centroin.com.br (Alberto Monteiro)
Date: Mon, 17 Sep 2007 18:11:51 -0200
Subject: [R] Histogram with colors
Message-ID: <20070917200542.M38930@centroin.com.br>

Is there a simple way to plot a histogram with colors?

For example, suppose I generate random points in the
N(2,1) distribution:

  x <- rnorm(100000, mean = 2, sd = 1)

Now I would like to plot the histogram:

  hist(x)

but I would like to show the bars with x < 0 in red, and the
bars with x >= 0 in lightgreen. Is there any simple way to
do it?

I think I can do it in two steps:

  x.hist <- hist(x, plot=FALSE)
  plot(x.hist, col=c(rep("red", 5), rep("green", 12)))

but maybe a more direct way is available.

Alberto Monteiro


From mnair at iusb.edu  Mon Sep 17 22:17:36 2007
From: mnair at iusb.edu (Nair, Murlidharan T)
Date: Mon, 17 Sep 2007 16:17:36 -0400
Subject: [R] MAD
In-Reply-To: <644e1f320709171259m78e2e8abg56ef66843df89564@mail.gmail.com>
References: <45f568c70709140831y2c390fd4l256e9c5ce53079e1@mail.gmail.com><644e1f320709141118n51f2349bn37f7d3f967f85654@mail.gmail.com><20070917195229.GA5829@ihug.co.nz>
	<644e1f320709171259m78e2e8abg56ef66843df89564@mail.gmail.com>
Message-ID: <A32055BDEA88C34BB3DBBCD2293807780154C9F8@iu-mssg-mbx109.ads.iu.edu>


I am calculating the median absolute deviation using mad function, and
it tends to ignore the parameter constant=1, when I am calculating it
for x=seq(1:5). Am I missing something here?

x<-seq(1:5)
mad(x)# gives [1] 1.4826
mad(x, constant=1)# gives [1] 1
#Here is the long form
dev.from.median<-abs((x-median(x)))
dev.from.median # Gives [1] 2 1 0 1 2
sum(dev.from.median) # Gives [1] 6
sum(dev.from.median)/length(x) # Gives [1] 1.2
# The long form does not match the output from the function

# When x<-seq(1:10) they match
x<-seq(1:10)
dev.from.median<-abs((x-median(x)))
sum(dev.from.median)/length(x) # Gives 2.5
mad(x, constant=1) # Gives 2.5
#The long form matches the output from the function

Did I miss anything here?

Cheers../Murli


From deepayan.sarkar at gmail.com  Mon Sep 17 23:09:35 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Mon, 17 Sep 2007 14:09:35 -0700
Subject: [R] MAD
In-Reply-To: <A32055BDEA88C34BB3DBBCD2293807780154C9F8@iu-mssg-mbx109.ads.iu.edu>
References: <45f568c70709140831y2c390fd4l256e9c5ce53079e1@mail.gmail.com>
	<644e1f320709141118n51f2349bn37f7d3f967f85654@mail.gmail.com>
	<20070917195229.GA5829@ihug.co.nz>
	<644e1f320709171259m78e2e8abg56ef66843df89564@mail.gmail.com>
	<A32055BDEA88C34BB3DBBCD2293807780154C9F8@iu-mssg-mbx109.ads.iu.edu>
Message-ID: <eb555e660709171409t63908ce8o3e22f6d16b3fb611@mail.gmail.com>

On 9/17/07, Nair, Murlidharan T <mnair at iusb.edu> wrote:
>
> I am calculating the median absolute deviation using mad function, and
> it tends to ignore the parameter constant=1, when I am calculating it
> for x=seq(1:5). Am I missing something here?
>
> x<-seq(1:5)
> mad(x)# gives [1] 1.4826
> mad(x, constant=1)# gives [1] 1
> #Here is the long form
> dev.from.median<-abs((x-median(x)))
> dev.from.median # Gives [1] 2 1 0 1 2
> sum(dev.from.median) # Gives [1] 6
> sum(dev.from.median)/length(x) # Gives [1] 1.2
> # The long form does not match the output from the function
>
> # When x<-seq(1:10) they match
> x<-seq(1:10)
> dev.from.median<-abs((x-median(x)))
> sum(dev.from.median)/length(x) # Gives 2.5
> mad(x, constant=1) # Gives 2.5
> #The long form matches the output from the function
>
> Did I miss anything here?

yes; mad := Median (not mean) absolute deviation (from the median, by default).

-Deepayan


From efg at stowers-institute.org  Mon Sep 17 23:06:17 2007
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Mon, 17 Sep 2007 16:06:17 -0500
Subject: [R] Proposal: Archive UseR conference presentations at
	www.r-project.org/useR-yyyy
References: <f8e6ff050709041413k70340217r76b51984d9e23ef9@mail.gmail.com>
Message-ID: <fcmq8e$udt$1@sea.gmane.org>

"hadley wickham" <h.wickham at gmail.com> wrote in message 
news:f8e6ff050709041413k70340217r76b51984d9e23ef9 at mail.gmail.com...
> Many of the presentations and posters from UseR! 2007 are now available 
> online:
> http://user2007.org/program/

The UseR 2006 conference info and presentations are part of 
www.r-project.org, namely http://www.r-project.org/useR-2006/

I noticed the user2007.org  domain expires on 16 December 2007, which would 
need to be renewed each year to continue to make these presentations 
available online. During the year of a conference it makes sense to have a 
separate domain, but would it make sense to archive old UseR conferences at 
www.r-project.org/useR-yyyy?  Would it make sense to standardize this so one 
could generalize and find the presentations for any year?

Next years' domain name is http://www.statistik.uni-dortmund.de/useR-2008/ 
but could be www.r-project.org/useR-2008 .  An automatic redirection link 
could be used so that www.r-project.org/useR-2008 is redirected to 
http://www.statistik.uni-dortmund.de/useR-2008/  for now, but once the 
conference is over the archive could be moved to www.r-project.org.  Any 
comments?

Just my $0.02,

efg

Earl F. Glynn
Scientific Programmer
Stowers Institute for Medical Research


From thomas.heine at enieh.com  Mon Sep 17 23:24:48 2007
From: thomas.heine at enieh.com (Thomas Heine)
Date: Mon, 17 Sep 2007 23:24:48 +0200
Subject: [R] Problems with compiling rimage on macOS
Message-ID: <2076C0C0-2412-4992-9047-7632E2297B47@enieh.com>

hello,

i want to install the rimage package (0.5-7) into my R (2.5.1).
i installed the

"i686-apple-darwin8-g++-4.0.1 (GCC) 4.0.1 (Apple Computer, Inc. build  
5367)"

from the macOS cd and created symbolic links to gcc and g++.
well if i try now to install the package in R the console says:

g++
checking for C++ compiler default output... ** Removing '/Library/ 
Frameworks/R.framework/Versions/2.5/Resources/library/rimage'
configure: error: C++ compiler cannot create executables
See `config.log' for more details.
ERROR: configuration failed for package 'rimage'

if i try the compile the source on my own i have access to this  
config.log but i cant really see something ... cause i have no idea :(

here is an excerpt which could be interesting cause here appear the  
first errors ...

-------------------

gcc version 4.0.1 (Apple Computer, Inc. build 5367)
configure:1399: $? = 0
configure:1401: g++ -V </dev/null >&5
g++: argument to `-V' is missing
configure:1404: $? = 1
configure:1428: checking for C++ compiler default output
configure:1431: g++    conftest.cc  >&5
i686-apple-darwin8-g++-4.0.1: installation problem, cannot exec 'as':  
No such fi
le or directory
configure:1434: $? = 1
configure: failed program was:
| #line 1407 "configure"
| /* confdefs.h.  */
|
| #define PACKAGE_NAME "rimage configuration script"
| #define PACKAGE_TARNAME "rimage-configuration-script"
| #define PACKAGE_VERSION "0.4"
| #define PACKAGE_STRING "rimage configuration script 0.4"
| #define PACKAGE_BUGREPORT "takashina.tomomi at nikon.co.jp"
| /* end confdefs.h.  */
|
| int
| main ()
| {
|
|   ;
|   return 0;
| }
configure:1473: error: C++ compiler cannot create executables
See `config.log' for more details.

---------------

thanks for your help in advance.
thomas


From bolker at ufl.edu  Mon Sep 17 23:30:08 2007
From: bolker at ufl.edu (bbolker)
Date: Mon, 17 Sep 2007 14:30:08 -0700 (PDT)
Subject: [R] are hurdle logit-poisson model and posson model nested?
In-Reply-To: <1115a2b00709151844v2ccda7davc457648a9f7e41e5@mail.gmail.com>
References: <1115a2b00709151844v2ccda7davc457648a9f7e41e5@mail.gmail.com>
Message-ID: <12745585.post@talk.nabble.com>




Wensui Liu wrote:
> 
> Dear Listers,
> I have a general statistical question. Are hurdle logit-poisson model
> and posson model nested?
> 

  You might have to give us a little more detail.  On first glance, my
impression
is that the Poisson model is _not_ nested in the hurdle-Poisson, because the
latter is truncated; what parameter(s) would you set to a fixed value to get
a regular Poisson?  (This is not true, on the other hand, of a zero-inflated
Poisson,
where you could set the zero-inflation parameter to zero to get a Poisson.)
[On the other hand, you would still have a parameter on the boundary of
its feasible space, which would make inference via LRT questionable.)

  good luck
    Ben Bolker

-- 
View this message in context: http://www.nabble.com/are-hurdle-logit-poisson-model-and-posson-model-nested--tf4449782.html#a12745585
Sent from the R help mailing list archive at Nabble.com.


From bolker at ufl.edu  Mon Sep 17 23:33:35 2007
From: bolker at ufl.edu (bbolker)
Date: Mon, 17 Sep 2007 14:33:35 -0700 (PDT)
Subject: [R] Cannot get contrasts to work with aov.
In-Reply-To: <12695182.post@talk.nabble.com>
References: <12695182.post@talk.nabble.com>
Message-ID: <12745636.post@talk.nabble.com>




ThatDeadDude wrote:
> 
> I have been trying for hours now to perform an orthogonal contrast through
> an ANOVA in R.   
> 
> I have done a two-factor factorial experiment, each factor having three
> levels.  I converted this dataset to a dataframe with one factor with nine
> treatments, as I couldn't work out what else to do.   
> I have set up a matrix with the eight orthogonal contrasts that I wish to
> perform, but despite having searched this mailing list's archives
> thoroughly, I cannot get it to work. 
> 
> I am looking to get output along the lines of 
>             Df  Sum Sq Mean Sq F value    Pr(>F)     
> trt1         1    X         X              X           X 
> trt2         1    X         X              X           X 
>  ............... 
> trt9         1    X         X              X           X 
> Residuals   27   495.1   18.3 
> 
>   [snippage]
> 
> Any responses would be greatly appreciated 
> Marc Burgess
> 

   I think instead of aov(model) you should try lm(model) and/or
summary(lm(model));
aov() is a special-purpose command that prints only the ANOVA table of a
linear model.
The other commands will print the parameter estimates, which is what you
want.

  I also don't see why you need to convert to a one-way layout: why not

lm(y~treat1*treat2)   ... ?

  good luck
    Ben Bolker
-- 
View this message in context: http://www.nabble.com/Cannot-get-contrasts-to-work-with-aov.-tf4449485.html#a12745636
Sent from the R help mailing list archive at Nabble.com.


From r.darnell at uq.edu.au  Tue Sep 18 00:31:58 2007
From: r.darnell at uq.edu.au (Ross Darnell)
Date: Tue, 18 Sep 2007 08:31:58 +1000
Subject: [R] Histogram with colors
In-Reply-To: <20070917200542.M38930@centroin.com.br>
References: <20070917200542.M38930@centroin.com.br>
Message-ID: <E4178EE0463C7D40AF637C4DDAC8030ED7B3BC@UQEXMB2.soe.uq.edu.au>

Not really but a better plot call would be


plot(x.hist,col=ifelse(x.hist$breaks<0,"red","green"))

Ross Darnell


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Alberto Monteiro
Sent: Tuesday, 18 September 2007 6:12 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Histogram with colors

Is there a simple way to plot a histogram with colors?

For example, suppose I generate random points in the
N(2,1) distribution:

  x <- rnorm(100000, mean = 2, sd = 1)

Now I would like to plot the histogram:

  hist(x)

but I would like to show the bars with x < 0 in red, and the
bars with x >= 0 in lightgreen. Is there any simple way to
do it?

I think I can do it in two steps:

  x.hist <- hist(x, plot=FALSE)
  plot(x.hist, col=c(rep("red", 5), rep("green", 12)))

but maybe a more direct way is available.

Alberto Monteiro

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From fisher at plessthan.com  Tue Sep 18 00:56:52 2007
From: fisher at plessthan.com (Dennis Fisher)
Date: Mon, 17 Sep 2007 15:56:52 -0700
Subject: [R] Sourcing encrypted files
Message-ID: <922AE6B0-3797-47BB-BB16-8E5109DE2FB1@plessthan.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070917/76806e98/attachment.pl 

From a.fugard at ed.ac.uk  Tue Sep 18 01:07:11 2007
From: a.fugard at ed.ac.uk (Andy Fugard)
Date: Tue, 18 Sep 2007 00:07:11 +0100
Subject: [R] Repeated measures logistic regression
In-Reply-To: <7AA2D066-4D55-49FC-BEB9-993E3690C4CA@ed.ac.uk>
References: <7AA2D066-4D55-49FC-BEB9-993E3690C4CA@ed.ac.uk>
Message-ID: <E8BEA341-41AD-4A04-8CA3-72EEADDC8EDC@ed.ac.uk>

Dear all,

Thanks to everyone who replied off list to my (rambling) question  
earlier this year!  I have put pointers to things I found useful over  
here:

   http://tinyurl.com/yvvvn9

Thought it might be helpful to share as now and again I receive  
emails from people wondering if I ever made progress.

Best wishes,

Andy


On 25 Feb 2007, at 19:58, Andy Fugard wrote:

> Dear all,
>
> I'm struggling to find the best (set of?) function(s) to do repeated
> measures logistic regression on some data from a psychology  
> experiment.
>
> An artificial version of the data I've got is as follows.  Firstly,
> each participant filled in a questionnaire, the result of which is a
> score.
>
>> questionnaire
>     ID Score
> 1   1     6
> 2   2     5
> 3   3     6
> 4   4     2
> ...
>
> Secondly, each participant did a task which required a series of
> button-pushes.  The response is binary.  The factors CondA and CondB
> describe the structure of the stimulus:
>
>> experiment
>      ID CondA CondB Response
> 1    1    a1    b1        1
> 2    1    a2    b2        0
> 3    1    a3    b1        0
> 4    1    a4    b2        0
> 5    1    a1    b1        1
> 6    1    a2    b2        0
> 7    1    a3    b1        0
> 8    1    a4    b2        0
> 9    2    a1    b1        1
> 10   2    a2    b2        0
> 11   2    a3    b1        0
> 12   2    a4    b2        0
> 13   2    a1    b1        1
> 14   2    a2    b2        0
> 15   2    a3    b1        0
> 16   2    a4    b2        0
>
> I would like to model how someone's score on the questionnaire
> relates to the responses they give in the button-pushing.  I'm
> particularly interested in interactions between the type of the
> stimulus and the score.
>
> I combined the experiment and the questionnaire dataframe with a
> merge so now there an additional column.
>
>> exp.q
>      ID Score CondA CondB Response
> 1    1     6    a1    b1        1
> 2    1     6    a2    b2        0
> 3    1     6    a3    b1        0
> 4    1     6    a4    b2        0
> 5    1     6    a1    b1        1
> 6    1     6    a2    b2        0
> 7    1     6    a3    b1        0
> 8    1     6    a4    b2        0
> 9    2     5    a1    b1        1
> 10   2     5    a2    b2        0
> 11   2     5    a3    b1        0
> 12   2     5    a4    b2        0
> ...
>
> Eventually, via glm, glmmPQL, and a few others, I ended up with
> lmer.  My questions follow.  I suspect (or hope) that I need to be
> pointed towards the relevant literature.  I own Faraway's "Extending
> the Linear Model with R" and Crawley's "Statistics: An Introduction
> using R".
>
> 1. Is the way I've combined the tables okay?  I'm concerned that the
> repetition of the score is Bad but can't think of any other way to
> code things.
>
> 2. Is lmer the most appropriate function to use?
>
> 3. If so, does the following call capture what I'm trying to model?
>
> model1 = lmer(Response ~ CondA * CondB * Score + (1|Subject),
>                data =exp.q,
>                family = binomial)
>
> I just want to tell lmer, "Look, this set of responses all comes from
> the same person: tell me the within-subject stuff that's going on and
> how that's affected by their score!"
>
> 4. Is there any way to do stepwise model simplification?  In the real
> data I have, there are several more predictors, including more than
> one questionnaire score and subscores.  I have specific hypotheses
> about what could be going on, so I can live with manual editing of
> the formulae, but it's nice for exploratory purposes to do stepwise
> simplification.
>
> 5. What's the best way to discover and report the relative
> contribution of each predictor?  I'm after an analogue of
> standardized betas (though I recently learned that they're thoroughly
> evil).
>
> 6. Is there anyway to get a p-value for goodness of fit?
>
> Many thanks for any help,
>
> Andy
>
> --
> Andy Fugard, Postgraduate Research Student
> Psychology (Room F15), The University of Edinburgh,
>    7 George Square, Edinburgh EH8 9JZ, UK
> Mobile: +44 (0)78 123 87190   http://www.possibly.me.uk
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


--
Andy Fugard, Postgraduate Research Student
Psychology (Room F15), The University of Edinburgh,
   7 George Square, Edinburgh EH8 9JZ, UK
Mobile: +44 (0)78 123 87190   http://www.possibly.me.uk


From marc_schwartz at comcast.net  Tue Sep 18 02:16:19 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Mon, 17 Sep 2007 19:16:19 -0500
Subject: [R] Sourcing encrypted files
In-Reply-To: <922AE6B0-3797-47BB-BB16-8E5109DE2FB1@plessthan.com>
References: <922AE6B0-3797-47BB-BB16-8E5109DE2FB1@plessthan.com>
Message-ID: <1190074579.3629.30.camel@Bellerophon.localdomain>

On Mon, 2007-09-17 at 15:56 -0700, Dennis Fisher wrote:
> Colleagues,
> 
> I have an unusual problem; I am wondering whether anyone has dealt  
> with it and found a solution.
> 
> I have a script that needs to be encrypted.  R will then be run on  
> the script.  There are various means to decrypt the file, some of  
> which leave the decrypted code on the hard drive for an excessive  
> period.
> 
> One means that I have considered to deal with this is the following  
> (the unix code is not correct, just sufficient to communicate the idea):
> 	system("decrypt ...")
> 	system("rm encrypted file")
> 	source(decrypted file)
> 	system("rm decrypted file")
> 
> Another approach would be to pipe the decrypted version to R in the  
> command line (as it is being decrypted).  Obviously, this could be  
> done with R < decryptedFile but this leaves the decrypted code  
> exposed.  Is there some other means to accomplish my goals using  
> something on the command line?
> 
> Of note, the scripts are not terribly long - 50-200 lines each.
> 
> Thanks
> 
> Dennis

I am curious as to why the script needs to be encrypted versus needing
to encrypt/protect the data that the script would presumably act upon.

Are you concerned about somebody gaining read access to your HD?  Keep
in mind that simply deleting a file only modifies file system entries.
It does not actually delete or wipe the physical data that the file
contained and folks with modest means can recover the clear text version
of the file.

We are not talking about needing TLA's (Three Lettered Agencies) to do
this.

If you are using a journaling file system such as ext3, the process of
even securely wiping individual files becomes even more complicated.

The best approach however is to take a holistic view on the process.

Don't just encrypt the source file, but encrypt entire partitions. For
example:

  /home
  /tmp
  swap

using one of the various means to do so such that files will be
encrypted/decrypted transparently during disk I/O.  Files in these
partitions are stored in encrypted format on the HD and only decrypted
when read.

This can be done via dm-crypt/LUKS, loop-aes, TrueCrypt and other
similar utilities. 

Encrypting /home means that everything in your userspace partition is
encrypted.

Encrypting /tmp and swap means that temporary files and anything moved
from RAM to HD during memory paging will similarly be encrypted.

The HD I/O overhead on a reasonable system is modest. In my case, only
about 15%. The CPU overhead is negligible.

I use dm-crypt/LUKS with 256 bit AES on my system running F7. Since I
deal with clinical data and am subject to HIPAA issues this is the best
approach for me and protects my laptop from inappropriate disclosure.
When my system boots, I am prompted for a lengthy passphrase to 'unlock'
the encrypted partitions for subsequent mounting and use. This occurs
before even logging in.

When done with my system, I shut it down. I never use hibernation/sleep
modes.

I also have the same approach for an external HD that I use for daily
backups and create GPG encrypted tarballs for monthly backup to DVD for
secure longer term storage.

HTH,

Marc Schwartz


From r.turner at auckland.ac.nz  Tue Sep 18 03:43:46 2007
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 18 Sep 2007 13:43:46 +1200
Subject: [R] Problem with nlm() function.
In-Reply-To: <12738419.post@talk.nabble.com>
References: <DCBD47DC-616D-4DBA-B5FD-7BC9CD298418@auckland.ac.nz>
	<12738419.post@talk.nabble.com>
Message-ID: <3EDE7CC7-5E85-49CB-936A-0CAAE333E995@auckland.ac.nz>



A couple of people have expressed an interest in having a look at the  
problematic
code/package which led my cri de coeur posted yesterday.

I have therefore made the package accessible by putting it up on my  
UNB web page:

	http://www.math.unb.ca/~rolf

Click on ``Hidden generalized linear Markov model package.''

The package includes a file ``scr.test'' in the ``inst'' directory.   
(It shows up in the
hglmm directory in your library when you install the package.)

In the script ``UA'' and ``CA'' are set equal to false.   Hence the  
nlm() based procedure runs,
giving a sensible answer and one warning message about ``Inf/NA''.

If you set UA to be TRUE (and leave CA FALSE) the procedure runs but  
converges to a
silly answer and gives very many warning messages.

If you set both of these to be TRUE the procedure falls over  
immediately, saying that there
is a coding problem with the ``analytic'' hessian.

Thanks to anyone who is willing to take a look at the package and  
perhaps give me a hint
as to what is going wrong when the analytic hessian is used.

				cheers,

					Rolf

######################################################################
Attention:\ This e-mail message is privileged and confidenti...{{dropped}}


From m_olshansky at yahoo.com  Tue Sep 18 03:59:12 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Mon, 17 Sep 2007 18:59:12 -0700 (PDT)
Subject: [R] machine learning and horse racing
In-Reply-To: <2926.60.241.49.44.1190058907.squirrel@webmail.ics.mq.edu.au>
Message-ID: <63257.47417.qm@web32208.mail.mud.yahoo.com>

Hi Stephen,

How many variables do you have?  How many of them are
categorical?
How many observations do you have?
Since I am not a racing expert, in how many races a
typical horse participates? How many years does it
usually span?

In the past I had a good experience with Random
Forest. There exists a RandomForest package in R. If
you run out of memory and do not mind to spend some
time you can try the original Fortran code (after
trying the R package without saving the forest).

Regards,

Moshe.

--- stephenc at ics.mq.edu.au wrote:

> Hi
> 
>  I am trying to use various techniques (eg svm,
> logistic regression,
> neural networks) to classify and predict the outcome
> of horse races.
> 
>  Most of my predictive features are categorical  -
> horse, jockey, trainer 
> - and I keep on running out of memory owing to the
> size of the vector.
> 
>  Does anyone know how to solve the problem?
> 
>  I have classified the outcomes as win/lose or
> place/lose with a view to
> train on x years of results and then testing on the
> subsequent years
> results. Is there some alternate way of looking at
> the problem?
> 
>  Does anyone have pointers to published work in this
> area?
> 
>  Thanks.
> 
>  Stephen
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From h.wickham at gmail.com  Tue Sep 18 04:01:24 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 17 Sep 2007 21:01:24 -0500
Subject: [R] Histogram with colors
In-Reply-To: <20070917200542.M38930@centroin.com.br>
References: <20070917200542.M38930@centroin.com.br>
Message-ID: <f8e6ff050709171901v64b29cd9m553d6fdfc316fdd7@mail.gmail.com>

On 9/17/07, Alberto Monteiro <albmont at centroin.com.br> wrote:
> Is there a simple way to plot a histogram with colors?
>
> For example, suppose I generate random points in the
> N(2,1) distribution:
>
>   x <- rnorm(100000, mean = 2, sd = 1)
>
> Now I would like to plot the histogram:
>
>   hist(x)
>
> but I would like to show the bars with x < 0 in red, and the
> bars with x >= 0 in lightgreen. Is there any simple way to
> do it?

You can do this with ggplot:

install.packages("ggplot2")
library(ggplot2)
qplot(x, geom="histogram", data=data.frame(x), fill = factor(x >= 0))

You can find out more at http://had.co.nz/ggplot2.

Hadley


From epistat at gmail.com  Tue Sep 18 04:26:28 2007
From: epistat at gmail.com (zhijie zhang)
Date: Tue, 18 Sep 2007 10:26:28 +0800
Subject: [R] What's the corresponding function in R for lo() function
	inS-PLUS?
In-Reply-To: <Pine.LNX.4.64.0709172034350.30714@gannet.stats.ox.ac.uk>
References: <2fc17e30709171019h64618f5fi646ae27cf4cbd33a@mail.gmail.com>
	<0b2601c7f94f$8e0b8240$6400a8c0@DD4XFW31>
	<Pine.LNX.4.64.0709172034350.30714@gannet.stats.ox.ac.uk>
Message-ID: <2fc17e30709171926p69c6430ei1ca8857c86a2c7b9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070918/6d3c7a14/attachment.pl 

From g_smits at verizon.net  Tue Sep 18 05:25:54 2007
From: g_smits at verizon.net (Gerard Smits)
Date: Mon, 17 Sep 2007 20:25:54 -0700
Subject: [R] applying math/stat functions to rows in data frame
In-Reply-To: <1189874192.2897.50.camel@graptoleberis.geog.ucl.ac.uk>
References: <0JOF00EM638WGPI3@vms044.mailsrvcs.net>
	<1189874192.2897.50.camel@graptoleberis.geog.ucl.ac.uk>
Message-ID: <0JOJ002FJO789M53@vms040.mailsrvcs.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070917/e00f69ab/attachment.pl 

From m_olshansky at yahoo.com  Tue Sep 18 05:29:38 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Mon, 17 Sep 2007 20:29:38 -0700 (PDT)
Subject: [R] how to compare 2 numeric vectors
In-Reply-To: <12743842.post@talk.nabble.com>
Message-ID: <392619.76714.qm@web32208.mail.mud.yahoo.com>

Below is one way to do this:

>
v1<-c(2,2,4,NA,NA,NA,10,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA)
>
v2<-c(NA,4,NA,NA,NA,NA,10,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,100,NA)
> length(v1)
[1] 20
> length(v2)
[1] 20
> intersect(which(!is.na(v1)),which(!is.na(v2)))
[1] 2 7
> 

--- dxc13 <dxc13 at health.state.ny.us> wrote:

> 
> useR's
> 
> I am trying to compare two vectors that have the
> same length.  More
> specifically, I am interested in comparing the
> corresponding positions of
> each element in the vector. 
> 
> Consider these two vectors of length 20:
> 
> v1 <-  2    2    4    NA  NA  NA  10  NA  NA  NA  NA
>  NA  NA  NA  NA  NA  NA 
> NA  NA  NA
> v2 <-  NA  4  NA    NA  NA  NA  10  NA  NA  NA  NA 
> NA  NA  NA  NA  NA  NA 
> NA  100 NA
> 
> I am only interested in extracting the position
> number where both vectors
> are not equal to NA at the same position.
> For example, the second element of both vectors is
> not equal to NA, and thus
> I want to return '2'; similary, I also would want to
> have '7' returned
> because the seventh element of both arrays is not
> equal to NA.
> 
> In general, I would like to find a way to do this
> for any number of given
> positions between the two vectors that satisfy this.
>  If no positions
> satisfy this, then return '0'
> 
> I would like to store the results as an object.
> 
> If anyone has any ideas, I would greatly appreciate
> it. Thanks!
> 
> dxc13
> -- 
> View this message in context:
>
http://www.nabble.com/how-to-compare-2-numeric-vectors-tf4469582.html#a12743842
> Sent from the R help mailing list archive at
> Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From zlu at umich.edu  Tue Sep 18 06:03:54 2007
From: zlu at umich.edu (Zheng Lu)
Date: Tue, 18 Sep 2007 00:03:54 -0400
Subject: [R]  help for high-quality plot again
In-Reply-To: <971536df0709161055v407cf9fbrb1e13f5e6aafb193@mail.gmail.com>
References: <20070913144738.rjz7cyn794wk0og8@web.mail.umich.edu>
	<07E228A5BE53C24CAD490193A7381BBBBF9336@LP-EXCHVS07.CO.IHC.COM>
	<20070916134710.3a1m2x561w4cwc40@web.mail.umich.edu>
	<971536df0709161055v407cf9fbrb1e13f5e6aafb193@mail.gmail.com>
Message-ID: <20070918000354.jzvh5ytl7o8o0wwg@web.mail.umich.edu>

Dear all:

Thank you very much for your help. Actually, I save the 
plot(mfrow=c(2,3))as metafile, however, when I insert picture from the 
file in word to import this plot picture, everything seems to be 
shrinked. Is there anyone having good experience with import graph from 
R to Word document? Do we have export.graph function in R? Thanks.


ZLU

Quoting Gabor Grothendieck <ggrothendieck at gmail.com>:

> Use windows metafile format.  Its a vector graphic format so it will
> display in full
> resolution.  png is bitmapped and so won't.  Also you can edit a wmf
> graphic in Word using Word's built in graphic editor so you could change
> the labels, etc. even after you have imported it.  Right click the graphic
> in R and save or copy it as a metafile.
>
> On 9/16/07, Zheng Lu <zlu at umich.edu> wrote:
>> Dear all:
>>
>> I am curious how to generate high-quality plot and graph with R and
>> input it into my word document. my plot was always generated in device
>> 2, when I save it as PNG, the quality is poor. Thank you very much for
>> your consideration and time.
>>
>>
>> ZLu
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>


From jpleis1 at umbc.edu  Tue Sep 18 07:23:17 2007
From: jpleis1 at umbc.edu (jpleis1 at umbc.edu)
Date: Tue, 18 Sep 2007 01:23:17 -0400 (EDT)
Subject: [R] Installing add-on packages
Message-ID: <2768.69.250.12.248.1190092997.squirrel@webmail.umbc.edu>

Admittedly, I don't have much experience with R.  I have dowloaded and
installed some add-on packages (leaps, for one).  When I try to run the
leaps function I get the following error:

Error: could not find function "leaps"

Any idea on what the problem could be?  Thanks,

-- 
John R Pleis


From mackay at northnet.com.au  Tue Sep 18 08:00:26 2007
From: mackay at northnet.com.au (Duncan Mackay)
Date: Tue, 18 Sep 2007 16:00:26 +1000
Subject: [R] help for high-quality plot again
In-Reply-To: <20070918000354.jzvh5ytl7o8o0wwg@web.mail.umich.edu>
References: <20070913144738.rjz7cyn794wk0og8@web.mail.umich.edu>
	<07E228A5BE53C24CAD490193A7381BBBBF9336@LP-EXCHVS07.CO.IHC.COM>
	<20070916134710.3a1m2x561w4cwc40@web.mail.umich.edu>
	<971536df0709161055v407cf9fbrb1e13f5e6aafb193@mail.gmail.com>
	<20070918000354.jzvh5ytl7o8o0wwg@web.mail.umich.edu>
Message-ID: <6.0.1.1.1.20070918155347.0280a618@mail.northnet.com.au>

I have found through experience to use win.metafile produce a .wmf file and 
in word insert the picture as a file.

The trick is to do produce everything as it will appear in the word document.
Size is critical.
The width and height of the wmf file must be as it will appear in word eg

win.metafile(filename = "x.wmf", width = 5, height = 3, pointsize = 10, 
restoreConsole = TRUE)

Regards

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
ARMIDALE NSW 2351
Email:
Work:  dmackay9 at pobox.une.edu.au
Home: mackay at northnet.com.au


At 14:03 18/09/07, you wrote:
>Dear all:
>
>Thank you very much for your help. Actually, I save the
>plot(mfrow=c(2,3))as metafile, however, when I insert picture from the
>file in word to import this plot picture, everything seems to be
>shrinked. Is there anyone having good experience with import graph from
>R to Word document? Do we have export.graph function in R? Thanks.
>
>
>ZLU
>
>Quoting Gabor Grothendieck <ggrothendieck at gmail.com>:
>
> > Use windows metafile format.  Its a vector graphic format so it will
> > display in full
> > resolution.  png is bitmapped and so won't.  Also you can edit a wmf
> > graphic in Word using Word's built in graphic editor so you could change
> > the labels, etc. even after you have imported it.  Right click the graphic
> > in R and save or copy it as a metafile.
> >
> > On 9/16/07, Zheng Lu <zlu at umich.edu> wrote:
> >> Dear all:
> >>
> >> I am curious how to generate high-quality plot and graph with R and
> >> input it into my word document. my plot was always generated in device
> >> 2, when I save it as PNG, the quality is poor. Thank you very much for
> >> your consideration and time.
> >>
> >>
> >> ZLu
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> >
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From shubhak at ambaresearch.com  Tue Sep 18 08:08:14 2007
From: shubhak at ambaresearch.com (Shubha Vishwanath Karanth)
Date: Tue, 18 Sep 2007 11:38:14 +0530
Subject: [R] Problem in extracting EQY_DVD_HIST from Bloomberg
Message-ID: <A36876D3F8A5734FA84A4338135E7CC3027D7DF3@BAN-MAILSRV03.Amba.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070918/6ab1bc11/attachment.ksh 

From stefan.grosse at uni-erfurt.de  Tue Sep 18 08:17:14 2007
From: stefan.grosse at uni-erfurt.de (Stefan Grosse)
Date: Tue, 18 Sep 2007 08:17:14 +0200
Subject: [R] Installing add-on packages
In-Reply-To: <2768.69.250.12.248.1190092997.squirrel@webmail.umbc.edu>
References: <2768.69.250.12.248.1190092997.squirrel@webmail.umbc.edu>
Message-ID: <200709180817.14781.stefan.grosse@uni-erfurt.de>

On Tuesday 18 September 2007 07:23:17 jpleis1 at umbc.edu wrote:
jp > Admittedly, I don't have much experience with R.  I have dowloaded and
jp > installed some add-on packages (leaps, for one).  When I try to run the
jp > leaps function I get the following error:
jp >
jp > Error: could not find function "leaps"
jp >
jp > Any idea on what the problem could be?  Thanks,

Yes, supposingly you did not load the "add-on" with the library command (e.g. 
library(leaps) ) - I would recommend in that case that you have a look at an 
introductionary texts like those here: 
http://cran.r-project.org/other-docs.html

Stefan


From ripley at stats.ox.ac.uk  Tue Sep 18 08:19:48 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Sep 2007 07:19:48 +0100 (BST)
Subject: [R] system.time behavior using source
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A834401957AA5@NYWEXMB23.msad.ms.com>
References: <D3AEEDA31E57474B840BEBC25A8A834401957AA5@NYWEXMB23.msad.ms.com>
Message-ID: <Pine.LNX.4.64.0709180717250.5597@gannet.stats.ox.ac.uk>

You need to print the result of an expression if used from source().
Autoprinting only occurs at the top level.
E.g.

% cat > systest.R
print(system.time(for(i in 1:100) mad(runif(1000))))

> source("systest.R")
    user  system elapsed
    0.14    0.00    0.20

On Mon, 17 Sep 2007, Leeds, Mark (IED) wrote:

> If I type the line below at my Rprompt, it works fine. But, if I put the
> same line in a file called systest.R and then source that file at
> the prompt, nothing happens. IF I use R CMD BATCH, it also works in that
> the system.time info is the .Rout file. Is there something I
> can do so that this line also works when I source it ?  Thanks. My
> information is below.
>
> system.time(for(i in 1:100) mad(runif(1000)))
>
>
>
> My information :
>
> R version 2.5.0 (2007-04-23)
> i686-pc-linux-gnu
>
> locale:
> C
>
> attached base packages:
> [1] "datasets"  "utils"     "stats"     "graphics"  "grDevices"
> "methods"   "base"
>
> other attached packages:
> lattice filehash  reshape      zoo    chron     MASS
> "0.15-8"    "1.0"  "0.7.4"  "1.3-1" "2.3-11" "7.2-33"
> --------------------------------------------------------
>
> This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From shubhak at ambaresearch.com  Tue Sep 18 08:34:06 2007
From: shubhak at ambaresearch.com (Shubha Vishwanath Karanth)
Date: Tue, 18 Sep 2007 12:04:06 +0530
Subject: [R] FW:  ISIN numbers into Bloomberg tickers
Message-ID: <A36876D3F8A5734FA84A4338135E7CC3027D7E4A@BAN-MAILSRV03.Amba.com>

Hi David,

I tried the following and get the below error messages....


con =
blpConnect(show.days="trading",na.action="previous.days",periodicity="da
ily")# connecting Bloomberg
> dat <- blpGetData(con,"US4009703799
Equity","PX_LAST",start=as.chron(as.Date("01/01/2005",
"%m/%d/%Y"),end=as.chron(Sys.Date()),retval="data.frame")
> blpDisconnect(con)

used (Mb) gc trigger (Mb) max used (Mb)
Ncells 480150 12.9 818163 21.9 818163 21.9
Vcells 797171 6.1 1445757 11.1 1441593 11.0

> dat
[DATETIME] PX_LAST
day day (09/17/07 19:43:45) NA


I don't get the data...but the same statement tried with ticker works.
So, any problem with ISIN's?

-----Original Message-----
From: davidr at rhotrading.com [mailto:davidr at rhotrading.com] 
Sent: Friday, September 14, 2007 10:24 PM
To: Shubha Vishwanath Karanth; r-help at stat.math.ethz.ch
Subject: RE: [R] ISIN numbers into Bloomberg tickers

You can try

> blpGetData(conn, "US912828HA15 Govt", 
    c("ticker", "cpn", "maturity", "market_sector_des"), retval="raw")

and paste together the parts.

HTH,

David L. Reiner
Rho Trading Securities, LLC


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Shubha Vishwanath Karanth
Sent: Friday, September 14, 2007 8:42 AM
To: r-help at stat.math.ethz.ch
Subject: [R] ISIN numbers into Bloomberg tickers

Hi R,

 

Can I convert ISIN numbers into Bloomberg tickers in the RBloomberg
package?

 

BR, Shubha


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Tue Sep 18 08:47:57 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Sep 2007 07:47:57 +0100 (BST)
Subject: [R] Sourcing encrypted files
In-Reply-To: <922AE6B0-3797-47BB-BB16-8E5109DE2FB1@plessthan.com>
References: <922AE6B0-3797-47BB-BB16-8E5109DE2FB1@plessthan.com>
Message-ID: <Pine.LNX.4.64.0709180646330.4973@gannet.stats.ox.ac.uk>

On Mon, 17 Sep 2007, Dennis Fisher wrote:

> Colleagues,
>
> I have an unusual problem; I am wondering whether anyone has dealt
> with it and found a solution.
>
> I have a script that needs to be encrypted.  R will then be run on
> the script.  There are various means to decrypt the file, some of
> which leave the decrypted code on the hard drive for an excessive
> period.
>
> One means that I have considered to deal with this is the following
> (the unix code is not correct, just sufficient to communicate the idea):
> 	system("decrypt ...")
> 	system("rm encrypted file")
> 	source(decrypted file)
> 	system("rm decrypted file")
>
> Another approach would be to pipe the decrypted version to R in the
> command line (as it is being decrypted).  Obviously, this could be
> done with R < decryptedFile but this leaves the decrypted code
> exposed.  Is there some other means to accomplish my goals using
> something on the command line?

That's not what I understand by 'to pipe'.  You could use a pipe() 
connection with source() if you had a pipeline decrypter, either

decrypt filename | Rscript

or

source(pipe("decrypt filename"))

Those would be slightly safer as the decrypted source code is (probably) 
never written to the file system.

I am not sure what you are trying to achieve: since the R code is going to 
be decrypted it will be possible (and I suspect easy) to get hold of the 
decrypted version.  (Consider for example running a modified version of 
source() that dumped out the parse tree.)  Using a package to read the 
encrypted file and feed the decrypted source to the parser at C level an 
expression at a time would make this harder to circumvent.

(Unlike Marc Schwartz, I am presuming the aim is to protect scripts from 
casual inspection on someone else's machine: as Marc says there are better 
ways to protect code and data on your own systems.)


> Of note, the scripts are not terribly long - 50-200 lines each.
>
> Thanks
>
> Dennis
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone: 1-866-PLessThan (1-866-753-7784)
> Fax: 1-415-564-2220
> www.PLessThan.com
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From petr.pikal at precheza.cz  Tue Sep 18 09:21:59 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Tue, 18 Sep 2007 09:21:59 +0200
Subject: [R] Odp:  aggregate function oddity
In-Reply-To: <46EE731D.3040400@eski.hu>
Message-ID: <OF9C7543EB.80A24049-ONC125735A.0027826A-C125735A.00287448@precheza.cz>

Hi

r-help-bounces at r-project.org napsal dne 17.09.2007 14:29:17:

> Dear All,
> 
> I tried to aggregate the rows according to some factors in a data frame. 

> I got the
> "Error in Summary.factor(..., na.rm = na.rm) :
>         sum not meaningful for factors"
> message. This problem was once already discussed in 2003 on this list, 
> where the following solution was given: include only those columns -when 

> giving it to aggregate() -  that are not factors.
> 
> It also worked for me, but this solution is a bit odd, since there is no 

> need to sum the factors given as grouping variables. Of course I may do 
> something completely wrong.
> help(aggregate) says:
> ## S3 method for class 'data.frame': aggregate(x, by, FUN, ...)
> |x|    an R object.
> |by|    a list of grouping elements, each as long as the variables in 
|x|. 
> Names for the grouping variables are provided if they are not given. The 

> elements of the list will be coerced to factors (if they are not already 

> factors).
> 
> In my interpretation this means that the factor variables and the 
> numeric variables are in the same data frame, namely x.
> 
> The data frame looks like this (its mortality from cerebrovascular 
> diseases):
>  > str(agyer)
> 'data.frame':   102 obs. of  65 variables:
>  $ Country            : int  4055 4055 4055 4055 4055 4055 4055 4055 
> 4055 4055 ...
>  $ Name               : Factor w/ 5 levels "Estonia","Latvia",..: 1 1 1 
> 1 1 1 1 1 1 1 ...
>  $ Year               : int  1997 1997 1998 1999 1999 1999 2000 2000 
> 2000 2001 ...
>  $ List               : int  103 103 103 103 103 103 103 103 103 103 ...
>  $ Sex                : int  2 1 2 2 1 2 2 1 1 2 ...
>  $ Morticd10_103_Frmat: int  1 1 1 1 1 1 1 1 1 1 ...
>  $ IM_Frmat           : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ Deaths1            : int  33 179 143 1428 83 61 3 759 29 4 ...
> and a bunch of other int variables.
> 
> After omitting agyer$Name, I do
>  > agyerpr=aggregate(agyer, by=list(agyer$Country, agyer$Year, 
> agyer$List, agyer$Sex, agyer$Morticd10_103_Frmat, agyer$IM_Frmat), sum)

If this is the command you issued, it tries to aggregate the whole data 
frame agyer including a factor variable Name, hence the error.

You want probably to sum only Deaths column based on values in other 
variables so you can do

agyerpr <- with(agyer, aggregate(Deaths1, by=list(Country, Year,List,Sex, 
Morticd10_103_Frmat, IM_Frmat), sum))

Aggregate applies a function on each variable in R object, and if this 
variable is not conforming to the function it will result in error.
If you want to omit some columns from aggregation just put agyer[, 
-c(column.numbers)] in x position of aggregate command.


Regards
Petr


> 
> The sum is done on -the already omitted - factor of "Cause".
> 
> I do not understand why it tries to sum a factor that is included in the 

> "by" list, since the concept is not to sum for those included, but use 
> them for grouping. I am lucky with this database because all the factors 

> can be interpreted as integers and I do not have to onit them one by 
> one, but what if not?
> 
> Am I missing something with aggregate or classes?
> 
> Thanks for your help!
> 
> Sincerely,
> Peter Mihalicza
> 
> 
> 
> -- 
> This message has been scanned for viruses and\ dangerous 
con...{{dropped}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mackay at northnet.com.au  Tue Sep 18 09:54:52 2007
From: mackay at northnet.com.au (Duncan Mackay)
Date: Tue, 18 Sep 2007 17:54:52 +1000
Subject: [R] help for high-quality plot again
In-Reply-To: <20070918021358.cpc5twib4osgk40g@web.mail.umich.edu>
References: <20070913144738.rjz7cyn794wk0og8@web.mail.umich.edu>
	<07E228A5BE53C24CAD490193A7381BBBBF9336@LP-EXCHVS07.CO.IHC.COM>
	<20070916134710.3a1m2x561w4cwc40@web.mail.umich.edu>
	<971536df0709161055v407cf9fbrb1e13f5e6aafb193@mail.gmail.com>
	<20070918000354.jzvh5ytl7o8o0wwg@web.mail.umich.edu>
	<6.0.1.1.1.20070918155347.0280a618@mail.northnet.com.au>
	<20070918021358.cpc5twib4osgk40g@web.mail.umich.edu>
Message-ID: <6.0.1.1.1.20070918174111.02803010@mail.northnet.com.au>

I now rarely use Word; if the size of the wmf as fixed by the win.metafile 
is smaller
than the size of the page within the margins you should have no problem.

So for letter size 8.5 x 11 inches with 1 inch margins and allowing 0.5 in 
for a label
you coud have a landscape mode wmf size of height = 6 and width = 9

If you wanted a larger size you would have to use the format picture and 
?frame to
set the picture in Word

For pointsize see
? windows
or
?ps.options

Most/?all graphic devices have this argument.

It relates to the size of the font you are using.
I changed the pointsize as an example - you can use the default font size 
if it suits your graph.

Sometimes it is easier to change pointsize than other things.

Duncan

At 16:13 18/09/07, you wrote:
>Thank you very much, Sir. Basically, I think the value of width and height 
>will be determined by top and left side rules in word, right? but how to 
>determine pointsize? And when you wrote filename='x.emf', where can I find 
>x.emf, can I specify the path under filename? I appreciate.
>
>
>Zheng Lu
>
>Quoting Duncan Mackay <mackay at northnet.com.au>:
>
>>I have found through experience to use win.metafile produce a .wmf file 
>>and in word insert the picture as a file.
>>
>>The trick is to do produce everything as it will appear in the word document.
>>Size is critical.
>>The width and height of the wmf file must be as it will appear in word eg
>>
>>win.metafile(filename = "x.wmf", width = 5, height = 3, pointsize = 10, 
>>restoreConsole = TRUE)
>>
>>Regards
>>
>>Duncan Mackay
>>Department of Agronomy and Soil Science
>>University of New England
>>ARMIDALE NSW 2351
>>Email:
>>Work:  dmackay9 at pobox.une.edu.au
>>Home: mackay at northnet.com.au
>>
>>
>>At 14:03 18/09/07, you wrote:
>>>Dear all:
>>>
>>>Thank you very much for your help. Actually, I save the
>>>plot(mfrow=c(2,3))as metafile, however, when I insert picture from the
>>>file in word to import this plot picture, everything seems to be
>>>shrinked. Is there anyone having good experience with import graph from
>>>R to Word document? Do we have export.graph function in R? Thanks.
>>>
>>>
>>>ZLU
>>>
>>>Quoting Gabor Grothendieck <ggrothendieck at gmail.com>:
>>>
>>> > Use windows metafile format.  Its a vector graphic format so it will
>>> > display in full
>>> > resolution.  png is bitmapped and so won't.  Also you can edit a wmf
>>> > graphic in Word using Word's built in graphic editor so you could change
>>> > the labels, etc. even after you have imported it.  Right click the 
>>> graphic
>>> > in R and save or copy it as a metafile.
>>> >
>>> > On 9/16/07, Zheng Lu <zlu at umich.edu> wrote:
>>> >> Dear all:
>>> >>
>>> >> I am curious how to generate high-quality plot and graph with R and
>>> >> input it into my word document. my plot was always generated in device
>>> >> 2, when I save it as PNG, the quality is poor. Thank you very much for
>>> >> your consideration and time.
>>> >>
>>> >>
>>> >> ZLu
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >
>>> >
>>> >
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>
>
>


From paul at stat.auckland.ac.nz  Tue Sep 18 09:47:58 2007
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Tue, 18 Sep 2007 09:47:58 +0200
Subject: [R] question on layout and image.plot
In-Reply-To: <20070914180045.227cb26a@subarnarekha.stat.iastate.edu>
References: <20070914180045.227cb26a@subarnarekha.stat.iastate.edu>
Message-ID: <46EF82AE.8020404@stat.auckland.ac.nz>

Hi


Ranjan Maitra wrote:
> Dear colleagues,
> 
> I have struggled for the past couple of days with the following layout of plots. First, for something that finally works (and I understand it also, or so I think!):
> 
> A B x 
> 
> where A and B are 4x4 matrices of images, x is the common legend for A and B.
> 
> The following does what I want (note that the images are nonsensical realizations from N(0, 1) in this rendering so that it is possible for people to try it out):
> 
> 
> 
> library(fields)
> 
> 
> mat <- matrix(1:16, ncol = 4, nrow = 4, by = T)
> mat2 <- cbind(mat, rep(17, nrow(mat)), mat + 17, rep(34, nrow(mat)),
> rep(35, nrow(mat)))
> layout(mat2, heights = rep(8, 4), widths = c(rep(8, 4), 1, rep(8,
> 4), 3, 1), respect = F)   
> 
> par(mar = c(0, 0, 0, 0))
> 
> for (i in 1:16) image(matrix(rnorm(64^2), ncol = 64), col =
>  tim.colors(64), axes = F)
> 
> frame()
> 
> for (i in 1:16) image(matrix(rnorm(64^2), ncol = 64), col =
>  tim.colors(64), axes = F)
> 
> par(oma = c(0, 0, 0, 4))
> par(mar = c(0, 0, 0, 0))
> 
> image.plot( zlim = c(-3, 3) , cex = 0.7, lwd = 0.5, legend.only=TRUE,
> legend.width = 15, legend.shrink = 0.75)
> 
> 
> 
> 
> 
> 
> The above works. But now, I want something that is of the format:
> 
> A x B x
> 
> where A and B are 4x4 matrices of images, x are the corresponding legends for A and B.
> 
> So, I tried the following:
> 
> 
> library(fields)
> 
> 
> mat <- matrix(1:16, ncol = 4, nrow = 4, by = T)
> mat2 <- cbind(mat, rep(17, nrow(mat)), rep(18, nrow(mat)), mat + 18,
> rep(35, nrow(mat)), rep(36, nrow(mat)))
> 
> layout(mat2, heights = rep(8, 4), widths = c(rep(8, 4), 3, 1, rep(8,
> 4), 3, 1), respect = F)   
> 
> par(mar = c(0, 0, 0, 0))
> 
> for (i in 1:16) image(matrix(rnorm(64^2), ncol = 64), col =
>  tim.colors(64), axes = F)
> 
> par(oma = c(0, 0, 0, 4))
> par(mar = c(0, 0, 0, 0))
> 
> image.plot( zlim = c(-3, 3) , cex = 0.7, lwd = 0.5, legend.only=TRUE,
> legend.width = 15, legend.shrink = 0.75)
> 
> frame()
> 
> for (i in 1:16) image(matrix(rnorm(64^2), ncol = 64), col =
>  tim.colors(64), axes = F)
> 
> par(oma = c(0, 0, 0, 4))
> par(mar = c(0, 0, 0, 0))
> 
> image.plot( zlim = c(-3, 3) , cex = 0.7, lwd = 0.5, legend.only=TRUE,
> legend.width = 15, legend.shrink = 0.75)
> 
> 
> 
> 
> And everything goes haywire from the application of image.plot onwards. Indeed, if I replace the first image.plot call with frame(), everything goes through but of course, I do not get the first legend. So, I wonder what am I doing wrong? Also how should I fix this? Note that submitting the figures separately is not an option for me (stupid journal rules:-()
> 
> Can someone please suggest what I should do here? 


The problem is that image.plot() messes with the plot layout (because it 
normally tries to draw two plots), so it is really incompatible with a 
layout() setup (as are functions like coplot() and pairs()).  I think 
you should just draw the legend yourself, rather than calling 
image.plot(), something like ...

mat <- matrix(1:16, ncol = 4, nrow = 4, by = T)
mat2 <- cbind(mat, rep(17, nrow(mat)), rep(17, nrow(mat)), mat + 17,
rep(34, nrow(mat)), rep(34, nrow(mat)))

layout(mat2)

par(mar = c(0, 0, 0, 0))

for (i in 1:16) image(matrix(rnorm(642), ncol = 64), col =
  tim.colors(64), axes = F)

savepar <- par(cex=0.7, lwd=0.5, mar = c(4, 3, 4, 3),
                xaxs="i", yaxs="i")
plot.new()
plot.window(xlim=0:1, ylim=c(-3, 3))
rect(0, seq(-3, 3, length=65)[-65],
      1, seq(-3, 3, length=65)[-1],
      col=tim.colors(64), border=NA)
box()
axis(4, at=-3:3, las=1)
par(savepar)

for (i in 1:16) image(matrix(rnorm(642), ncol = 64), col =
  tim.colors(64), axes = F)

savepar <- par(cex=0.7, lwd=0.5, mar = c(4, 3, 4, 3),
                xaxs="i", yaxs="i")
plot.new()
plot.window(xlim=0:1, ylim=c(-3, 3))
rect(0, seq(-3, 3, length=65)[-65],
      1, seq(-3, 3, length=65)[-1],
      col=tim.colors(64), border=NA)
box()
axis(4, at=-3:3, las=1)
par(savepar)

... (with obvious efficiencies possible by wrapping the "legend" code up 
as a little function).

Paul


> Many thanks and best wishes,
> Ranjan
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From mark at wardle.org  Tue Sep 18 10:13:50 2007
From: mark at wardle.org (Mark Wardle)
Date: Tue, 18 Sep 2007 09:13:50 +0100
Subject: [R] Sourcing encrypted files
In-Reply-To: <922AE6B0-3797-47BB-BB16-8E5109DE2FB1@plessthan.com>
References: <922AE6B0-3797-47BB-BB16-8E5109DE2FB1@plessthan.com>
Message-ID: <b59a37130709180113x13173f8ci55f5adf820208722@mail.gmail.com>

Dear Dennis,

Ignoring the reasons why you might want to do this, you may want to
explore a ram disk. I don't know which OS you are using, but assume a
unix or unix-like OS, there may be a straightforward way to mount a
ram-based volatile disk and decrypt your file to there.

Another option would be to use an encrypted partition.

Best wishes,

Mark

On 17/09/2007, Dennis Fisher <fisher at plessthan.com> wrote:
> Colleagues,
>
> I have an unusual problem; I am wondering whether anyone has dealt
> with it and found a solution.
>
> I have a script that needs to be encrypted.  R will then be run on
> the script.  There are various means to decrypt the file, some of
> which leave the decrypted code on the hard drive for an excessive
> period.
>
> One means that I have considered to deal with this is the following
> (the unix code is not correct, just sufficient to communicate the idea):
>         system("decrypt ...")
>         system("rm encrypted file")
>         source(decrypted file)
>         system("rm decrypted file")
>
> Another approach would be to pipe the decrypted version to R in the
> command line (as it is being decrypted).  Obviously, this could be
> done with R < decryptedFile but this leaves the decrypted code
> exposed.  Is there some other means to accomplish my goals using
> something on the command line?
>
> Of note, the scripts are not terribly long - 50-200 lines each.
>
> Thanks
>
> Dennis
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone: 1-866-PLessThan (1-866-753-7784)
> Fax: 1-415-564-2220
> www.PLessThan.com
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________________________________
> This email has been scanned by the MessageLabs Email Security System.
> For more information please visit http://www.messagelabs.com/email
> ______________________________________________________________________
>


-- 
Dr. Mark Wardle
Specialist registrar, Neurology
Cardiff, UK


From r.j.forsyth at newcastle.ac.uk  Tue Sep 18 10:38:49 2007
From: r.j.forsyth at newcastle.ac.uk (Rob Forsyth)
Date: Tue, 18 Sep 2007 09:38:49 +0100
Subject: [R] Extracting variance-covariance matrix from nlme object
Message-ID: <60B8688E-034F-4AA9-B743-F5CFCF56A53F@newcastle.ac.uk>

I want to extract the variance-covariance matrix of an nlme model of  
a dataset. The object is to pass this to mvrnorm to create pseudo- 
replicates of the original data. I note the nlme package has a  
getVarCov method available for lme objects but not nlme objects. Is  
the vcov function in the base stats package suitable? If so, why is  
the additional getVarCov provided?

thank you

Rob Forsyth


From p.hiemstra at geo.uu.nl  Tue Sep 18 10:40:01 2007
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 18 Sep 2007 10:40:01 +0200
Subject: [R] map issues
In-Reply-To: <BLU111-W508AF3269EDE7BB71BF6CCBBBF0@phx.gbl>
References: <BLU111-W508AF3269EDE7BB71BF6CCBBBF0@phx.gbl>
Message-ID: <46EF8EE1.4010509@geo.uu.nl>

Dear Alexander,

You can use the function readShapePoly function from maptools. This 
directly reads the shapefile into a SpatialPolygons object. You also 
need to install the sp package (don't know if you did that already).

You could consider joining the r-sig-geo mailing list. These kinds of 
questions are better suited for that mailing list.

hope this helps,

Paul

Alexander Nervedi schreef:
> Hi !
>
> I have a shapefile that I can easily read into R using library(maptools). My problem stems from some warning messages that come even though everything seems to work fine.
>
> library(maptools)
> districts <- read.shape(filen = "a_ds", dbf.data = TRUE)
> length(districts$Shapes)
>
> so far so good. when I try and plot this I get a nice plot and a warning message:
>
>   
>> plot(districts)
>>     
> Warning message:
> 'plot.Map' is deprecated.
> Use 'plot.Spatial' instead.
> See help("Deprecated") and help("maptools-deprecated").
>
>
> so i tried the obvious:
>   
>> ?plot.Spatial
>>     
> No documentation for 'plot.Spatial' in specified packages and libraries:
> you could try 'help.search("plot.Spatial")'
>
> I went back and read the help on plot.Map and it says "This function is deprecated. It is difficult to maintain and there are several 
> alternatives, either by converting Map objects to sp class objects or polylist 
> etc. objects" and so i gather we can either try to move things into sp class. A little search of this archive tells me that there is a function out there called map2SpatialPolygons that is of some help. So after reading the help on this i tried to convert the Map object to an sp object. But I keep failing.
>
>   
>> ids <- as.character(districts$att.data$STATE)
>> ids[1:2]
>>     
> "A AND B" "A AND B"
>   
>> temp <- map2SpatialPolygons(districts, IDs = ids)
>>     
> Error in to[nParts] <- nrow(xy) : incompatible types (from NULL to integer) in subassignment type fix
> In addition: Warning message:
> is.na() applied to non-(list or vector) in: is.na(object) 
>
> I went back to the help on the function map2SpatialPolygons. And the example code there is:
>
> library(maps)
>
> nor_coast_poly <- map("world", "norway", fill=TRUE, col="transparent", plot=FALSE)
>
> nor_coast_poly$names
> IDs <- sapply(strsplit(nor_coast_poly$names, ":"), function(x) x[1])
>
> nor_coast_poly_sp <- map2SpatialPolygons(nor_coast_poly, IDs=IDs, proj4string=CRS("+proj=longlat +datum=wgs84"))
>
>
> This works fine. So I was most puzzled. And then i did 
>
>   
>> is(nor_coast_poly)
>>     
> [1] "map"
>   
>> is(districts)
>>     
> [1] "Map"
>
> So the object i have created is a Map object while the map2SpatialPolygons seems to be using a map object. Can it also handle Map objects? In which case can someone tell me whats wrong with my sepcification of the map2SpatialPolygons call?
>
> your man
> Al
>
>
>
> _________________________________________________________________
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul


From shmustater at 163.com  Tue Sep 18 10:49:39 2007
From: shmustater at 163.com (=?GBK?B?1cXWvr3c?=)
Date: Tue, 18 Sep 2007 16:49:39 +0800 (CST)
Subject: [R] How to Standardise the x/y coordinates to the unit square?
Message-ID: <430548674.1203231190105379776.JavaMail.coremail@bj163app127.163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070918/f26d77f0/attachment.ksh 

From mihalicza.peter at eski.hu  Tue Sep 18 10:51:04 2007
From: mihalicza.peter at eski.hu (=?ISO-8859-1?Q?Mihalicza_P=E9ter?=)
Date: Tue, 18 Sep 2007 10:51:04 +0200
Subject: [R] Odp:  aggregate function oddity
In-Reply-To: <OF9C7543EB.80A24049-ONC125735A.0027826A-C125735A.00287448@precheza.cz>
References: <OF9C7543EB.80A24049-ONC125735A.0027826A-C125735A.00287448@precheza.cz>
Message-ID: <46EF9178.4090208@eski.hu>

Sorry for the confusion, I was not clear enough, so I made a small 
example to illustrate:

 >m=data.frame(fac1=rep(c(1,2),3), fac2=c("a","b","b","b","a","b"), 
num1=1:6, num2=7:12)
 > m$fac1=as.factor(m$fac1)
 > m
  fac1 fac2 num1 num2
1    1    a    1    7
2    2    b    2    8
3    1    b    3    9
4    2    b    4   10
5    1    a    5   11
6    2    b    6   12
 >#I would like to get the sum of num1 and num2 grouped by c(1,2) and c(a,b)
 > ag=aggregate(m, list(m$fac1, m$fac2), sum)
Error in Summary.factor(..., na.rm = na.rm) :
        sum not meaningful for factors

 >#I understand, that it is possible to do...

 >ag=aggregate(m[,3:4], list(m$fac1, m$fac2), sum)
 > ag
  Group.1 Group.2 num1 num2
1       1       a    6   18
2       1       b    3    9
3       2       b   12   30

but I do not understand why aggragate tries to sum fac1 and fac2 since 
they are grouping variables that need not, and must not be summed. To my 
understanding the aggregate help text also does not speak about omitting 
factor variables from the data frame.

My question is whether I miss something, or this is how aggregate works. 
If the latter, than what is the reason for it.

Thanks, and sorry again!

Yours,
Peter Mihalicza



Petr PIKAL ?rta:
> Hi
>
> r-help-bounces at r-project.org napsal dne 17.09.2007 14:29:17:
>
>   
>> Dear All,
>>
>> I tried to aggregate the rows according to some factors in a data frame. 
>>     
>
>   
>> I got the
>> "Error in Summary.factor(..., na.rm = na.rm) :
>>         sum not meaningful for factors"
>> message. This problem was once already discussed in 2003 on this list, 
>> where the following solution was given: include only those columns -when 
>>     
>
>   
>> giving it to aggregate() -  that are not factors.
>>
>> It also worked for me, but this solution is a bit odd, since there is no 
>>     
>
>   
>> need to sum the factors given as grouping variables. Of course I may do 
>> something completely wrong.
>> help(aggregate) says:
>> ## S3 method for class 'data.frame': aggregate(x, by, FUN, ...)
>> |x|    an R object.
>> |by|    a list of grouping elements, each as long as the variables in 
>>     
> |x|. 
>   
>> Names for the grouping variables are provided if they are not given. The 
>>     
>
>   
>> elements of the list will be coerced to factors (if they are not already 
>>     
>
>   
>> factors).
>>
>> In my interpretation this means that the factor variables and the 
>> numeric variables are in the same data frame, namely x.
>>
>> The data frame looks like this (its mortality from cerebrovascular 
>> diseases):
>>  > str(agyer)
>> 'data.frame':   102 obs. of  65 variables:
>>  $ Country            : int  4055 4055 4055 4055 4055 4055 4055 4055 
>> 4055 4055 ...
>>  $ Name               : Factor w/ 5 levels "Estonia","Latvia",..: 1 1 1 
>> 1 1 1 1 1 1 1 ...
>>  $ Year               : int  1997 1997 1998 1999 1999 1999 2000 2000 
>> 2000 2001 ...
>>  $ List               : int  103 103 103 103 103 103 103 103 103 103 ...
>>  $ Sex                : int  2 1 2 2 1 2 2 1 1 2 ...
>>  $ Morticd10_103_Frmat: int  1 1 1 1 1 1 1 1 1 1 ...
>>  $ IM_Frmat           : int  1 1 1 1 1 1 1 1 1 1 ...
>>  $ Deaths1            : int  33 179 143 1428 83 61 3 759 29 4 ...
>> and a bunch of other int variables.
>>
>> After omitting agyer$Name, I do
>>  > agyerpr=aggregate(agyer, by=list(agyer$Country, agyer$Year, 
>> agyer$List, agyer$Sex, agyer$Morticd10_103_Frmat, agyer$IM_Frmat), sum)
>>     
>
> If this is the command you issued, it tries to aggregate the whole data 
> frame agyer including a factor variable Name, hence the error.
>
> You want probably to sum only Deaths column based on values in other 
> variables so you can do
>
> agyerpr <- with(agyer, aggregate(Deaths1, by=list(Country, Year,List,Sex, 
> Morticd10_103_Frmat, IM_Frmat), sum))
>
> Aggregate applies a function on each variable in R object, and if this 
> variable is not conforming to the function it will result in error.
> If you want to omit some columns from aggregation just put agyer[, 
> -c(column.numbers)] in x position of aggregate command.
>
>
> Regards
> Petr
>
>
>   
>> The sum is done on -the already omitted - factor of "Cause".
>>
>> I do not understand why it tries to sum a factor that is included in the 
>>     
>
>   
>> "by" list, since the concept is not to sum for those included, but use 
>> them for grouping. I am lucky with this database because all the factors 
>>     
>
>   
>> can be interpreted as integers and I do not have to onit them one by 
>> one, but what if not?
>>
>> Am I missing something with aggregate or classes?
>>
>> Thanks for your help!
>>
>> Sincerely,
>> Peter Mihalicza
>>
>>
>>
>> -- 
>> This message has been scanned for viruses and\ dangerous 
>>     
> con...{{dropped}}
>   
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>>     
> http://www.R-project.org/posting-guide.html
>   
>> and provide commented, minimal, self-contained, reproducible code.
>>     
>
>
>   



-- 
This message has been scanned for viruses and\ dangerous con...{{dropped}}


From arun.kumar.saha at gmail.com  Tue Sep 18 11:00:47 2007
From: arun.kumar.saha at gmail.com (Arun Kumar Saha)
Date: Tue, 18 Sep 2007 14:30:47 +0530
Subject: [R] Need help on "date"
Message-ID: <d4c57560709180200q2adf68f7ua2a8d823ac488229@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070918/e066dd6a/attachment.pl 

From gustaf.rydevik at gmail.com  Tue Sep 18 11:12:38 2007
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Tue, 18 Sep 2007 11:12:38 +0200
Subject: [R] Odp: aggregate function oddity
In-Reply-To: <46EF9178.4090208@eski.hu>
References: <OF9C7543EB.80A24049-ONC125735A.0027826A-C125735A.00287448@precheza.cz>
	<46EF9178.4090208@eski.hu>
Message-ID: <45f568c70709180212l553b680ev66a0afd303321c8c@mail.gmail.com>

On 9/18/07, Mihalicza P?ter <mihalicza.peter at eski.hu> wrote:
> Sorry for the confusion, I was not clear enough, so I made a small
> example to illustrate:
>
>  >m=data.frame(fac1=rep(c(1,2),3), fac2=c("a","b","b","b","a","b"),
> num1=1:6, num2=7:12)
>  > m$fac1=as.factor(m$fac1)
>  > m
>   fac1 fac2 num1 num2
> 1    1    a    1    7
> 2    2    b    2    8
> 3    1    b    3    9
> 4    2    b    4   10
> 5    1    a    5   11
> 6    2    b    6   12
>  >#I would like to get the sum of num1 and num2 grouped by c(1,2) and c(a,b)
>  > ag=aggregate(m, list(m$fac1, m$fac2), sum)
> Error in Summary.factor(..., na.rm = na.rm) :
>         sum not meaningful for factors
>
>  >#I understand, that it is possible to do...
>
>  >ag=aggregate(m[,3:4], list(m$fac1, m$fac2), sum)
>  > ag
>   Group.1 Group.2 num1 num2
> 1       1       a    6   18
> 2       1       b    3    9
> 3       2       b   12   30
>
> but I do not understand why aggragate tries to sum fac1 and fac2 since
> they are grouping variables that need not, and must not be summed. To my
> understanding the aggregate help text also does not speak about omitting
> factor variables from the data frame.
>
> My question is whether I miss something, or this is how aggregate works.
> If the latter, than what is the reason for it.
>
> Thanks, and sorry again!
>
> Yours,
> Peter Mihalicza
>
>

Aggregate does not assume that the grouping variables and the object
to aggregate are related to each other.
Thus, supply *exactly* the object which you want to aggregate over, in
your case m[,c("num1","num2")], as X. The reason for this I leave to
others to explain.


/Gustaf

-- 
Gustaf Rydevik, M.Sci.
tel: +46(0)703 051 451
address:Essingetorget 40,112 66 Stockholm, SE
skype:gustaf_rydevik


From P.Dalgaard at biostat.ku.dk  Tue Sep 18 11:13:13 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 18 Sep 2007 11:13:13 +0200
Subject: [R] How to Standardise the x/y coordinates to the unit square?
In-Reply-To: <430548674.1203231190105379776.JavaMail.coremail@bj163app127.163.com>
References: <430548674.1203231190105379776.JavaMail.coremail@bj163app127.163.com>
Message-ID: <46EF96A9.4060605@biostat.ku.dk>

??? wrote:
> Dear Rusers, I want to standardise the values of x/y coordinates to the unit square, i.e. make the x-values all lie within [0,1] and all the y-values lie within [0,1] in the bottom example.  I had thought to use scale() function to do it, but it seems that it's used to standardise a variable and the scaled value was not within [0,1]. OR, i can divide x/y-values by their maximum value to get it.  I'm not sure about it.#Example data 

> data <- matrix(1:10, nc=2)
> data<-as.data.frame(data)
> names(data)<-c('x','y')

> > data
>   x  y
> 1 1  6
> 2 2  7
> 3 3  8
> 4 4  9
> 5 5 10 

>  I'd appreciate your help.
(Beware line formatting in your emails)

You can actually use scale(), but it is hardly worth it and an abuse of
concepts. Just write a little function for the actual scaling and apply
it to each column.

st <- function(x)(x-min(x))/(max(x)-min(x))
data.frame(lapply(data,st))

Or,

d.min <- apply(data,2,min)
d.max <- apply(data,2,max)
sweep(sweep(data, 2, d.min, "-"), 2, d.max - d.min, "/")

or, same thing using scale()

scale(data, center=d.min, scale=d.max - d.min)

>  
> --
> Kind Regards,
> John Chang
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From jim at bitwrit.com.au  Tue Sep 18 11:26:11 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 18 Sep 2007 19:26:11 +1000
Subject: [R] graphs with gradients of colors
In-Reply-To: <36B62AB1E934124BA81C2B3B615E9F008119CD@xmail05.ad.ua.ac.be>
References: <36B62AB1E934124BA81C2B3B615E9F008119CD@xmail05.ad.ua.ac.be>
Message-ID: <46EF99B3.7070905@bitwrit.com.au>

Van Dongen Stefan wrote:
> Hi All,
>  
> I would like to fill the area under a curve with a gradient of colors. Are there any packages or trick I could use
>  
> 
Hi Stefan,

Chris has answered the question of how to define the polygons, so I'll 
have a shot at the gradient. The plotrix package has three functions 
that produce color gradients, smoothColors, color.gradient and color.scale.

smoothColors allows you to specify the extreme, and optionally 
intervening, colors and interpolates colors between the ones you have 
specified.

color.gradient is quite similar, except that the user can specify the 
red, green and blue components separately.

color.scale turns numeric values into colors using the same method of 
color specification as color.gradient. It will also work with just the 
extreme colors.

The RColorBrewer package also has the capability to produce color 
gradients. There may be other packages that will do what you want as well.

Jim


From FredeA.Togersen at agrsci.dk  Tue Sep 18 12:43:30 2007
From: FredeA.Togersen at agrsci.dk (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 18 Sep 2007 12:43:30 +0200
Subject: [R] Need help on "date"
In-Reply-To: <d4c57560709180200q2adf68f7ua2a8d823ac488229@mail.gmail.com>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC0574B31A@DJFPOST01.djf.agrsci.dk>

One way (perhaps not the most efficient)

> as.Date("2005-09-01","%Y-%m-%d")
[1] "2005-09-01"
> format(as.Date("2005-09-01","%Y-%m-%d"),"%Y")
[1] "2005"
> format(as.Date("2005-09-01","%Y-%m-%d"),"%d")
[1] "01"
> format(as.Date("2005-09-01","%Y-%m-%d"),"%m")
[1] "09"
> 


See ?DateTimeClasses.

Med venlig hilsen
Frede Aakmann T?gersen
 

 

> -----Oprindelig meddelelse-----
> Fra: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] P? vegne af Arun Kumar Saha
> Sendt: 18. september 2007 11:01
> Til: r-help at stat.math.ethz.ch
> Emne: [R] Need help on "date"
> 
> Dear all,
> 
> I have a variable 'x' like that:
> 
> > x
> [1] "2005-09-01"
> 
> Here, 2005 represents year, 09 month and 01 day.
> 
> Now I want to create three variables naming: y, m, and d such that:
> 
> y = 2005
> m = 09
> d = 01
> 
> can anyone tell me how to do that?
> 
> Regards,
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From jim at bitwrit.com.au  Tue Sep 18 12:45:39 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 18 Sep 2007 20:45:39 +1000
Subject: [R] How to Standardise the x/y coordinates to the unit square?
In-Reply-To: <430548674.1203231190105379776.JavaMail.coremail@bj163app127.163.com>
References: <430548674.1203231190105379776.JavaMail.coremail@bj163app127.163.com>
Message-ID: <46EFAC53.5000701@bitwrit.com.au>

??? wrote:
> Dear Rusers, I want to standardise the values of x/y coordinates to the unit square, i.e. make the x-values all lie within [0,1] and all the y-values lie within [0,1] in the bottom example.  I had thought to use scale() function to do it, but it seems that it's used to standardise a variable and the scaled value was not within [0,1]. OR, i can divide x/y-values by their maximum value to get it.  I'm not sure about it.#Example data data <- matrix(1:10, nc=2)
> data<-as.data.frame(data)
> names(data)<-c('x','y')> data
>   x  y
> 1 1  6
> 2 2  7
> 3 3  8
> 4 4  9
> 5 5 10  I'd appreciate your help. 
> --

Hi John,
You can do this with the "rescale" function in the plotrix package.

newx<-rescale(x,c(0,1))
newy<-rescale(y,c(0,1))

Jim


From jholtman at gmail.com  Tue Sep 18 12:48:30 2007
From: jholtman at gmail.com (jim holtman)
Date: Tue, 18 Sep 2007 06:48:30 -0400
Subject: [R] Need help on "date"
In-Reply-To: <d4c57560709180200q2adf68f7ua2a8d823ac488229@mail.gmail.com>
References: <d4c57560709180200q2adf68f7ua2a8d823ac488229@mail.gmail.com>
Message-ID: <644e1f320709180348n61de9381ra37370ebba69d0c6@mail.gmail.com>

Here is one way of doing it:

> x <- as.POSIXct("2005-09-01")
> x
[1] "2005-09-01 GMT"

> x.lt <- as.POSIXlt(x)
> x$mon+1
> x.lt$mon+1
[1] 9
> x.lt$year+1900
[1] 2005
> dput(x.lt)
structure(list(sec = 0, min = 0L, hour = 0L, mday = 1L, mon = 8L,
    year = 105L, wday = 4L, yday = 243L, isdst = 0L), .Names = c("sec",
"min", "hour", "mday", "mon", "year", "wday", "yday", "isdst"
), class = c("POSIXt", "POSIXlt"), tzone = "GMT")
> x.lt$mday
[1] 1
>


On 9/18/07, Arun Kumar Saha <arun.kumar.saha at gmail.com> wrote:
> Dear all,
>
> I have a variable 'x' like that:
>
> > x
> [1] "2005-09-01"
>
> Here, 2005 represents year, 09 month and 01 day.
>
> Now I want to create three variables naming: y, m, and d such that:
>
> y = 2005
> m = 09
> d = 01
>
> can anyone tell me how to do that?
>
> Regards,
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From D.GOUACHE at arvalisinstitutduvegetal.fr  Tue Sep 18 13:07:40 2007
From: D.GOUACHE at arvalisinstitutduvegetal.fr (GOUACHE David)
Date: Tue, 18 Sep 2007 13:07:40 +0200
Subject: [R] RE :  Must be easy,
	but haven't found the function (numerical integration)
In-Reply-To: <12732936.post@talk.nabble.com>
Message-ID: <1DF7DB4AB44EFB41A60A889186D43359120D14@srv-laminiere.arvalis-fr.com>

try :

library(Bolsatd)
?sintegral

or:

library(caTools)
?trapz

David Gouache
Arvalis - Institut du V?g?tal
Station de La Mini?re
78280 Guyancourt
Tel: 01.30.12.96.22 / Port: 06.86.08.94.32


-----Message d'origine-----
De?: Ptit_Bleu [mailto:ptit_bleu at yahoo.fr] 
Envoy??: lundi 17 septembre 2007 12:09
??: r-help at stat.math.ethz.ch
Objet?: [R] Must be easy,but haven't found the function (numerical integration)


Hi,

I have a data frame of 2 columns with the following types :
data$day char
data$value num

And I plot my data with :
plot(strptime(donnees$day,format="%Y-%m-%d %H:%M:%S"),donnees$value,
type="l")

And I'd just like to get the numerical value of the integration of this
graph.
I looked at ?integrate but, as far as I understood (that is, not very much,
due to my poor english), it seems that it doesn't work with values in data
frame.

Could you please help me to do this ?

Thanks in advance,
Have a nice week,
Ptit Bleu.
-- 
View this message in context: http://www.nabble.com/Must-be-easy%2C-but-haven%27t-found-the-function-%28numerical-integration%29-tf4465684.html#a12732936
Sent from the R help mailing list archive at Nabble.com.


From tramni at abv.bg  Tue Sep 18 13:46:59 2007
From: tramni at abv.bg (Martin Ivanov)
Date: Tue, 18 Sep 2007 14:46:59 +0300 (EEST)
Subject: [R] systemfit: data
Message-ID: <1922921117.1021681190116019241.JavaMail.nobody@mail21.abv.bg>

Dear R users,
I have a question on the function systemfit from the systemfit package. This function returns a list of the class systemfit, which besides all other information, contains the data frame of the whole system, called ?data?. I have noticed the following issue.
Suppose that I have to estimate a single equation (the simplest case), for example:
x ~ y + z

so I call systemfit like that:

a <- systemfit(method=?OLS?,eqns=formula(?x~y+z?),data=data.frame(cbind(x,y,z)))

Then, a$data contains the variables x,y and z in its columns. So far so good. However, if I do not want an intercept term to be evaluated and I call systemfit like that:
a <- systemfit(method=?OLS?,eqns=formula(?x ~ -1 + y + z?),data=data.frame(cbind(x,y,z)))

then a$data contains only x and z in its columns. The regressor y is missing.
The same issue is valid for systems of equations: if an intercept term is not allowed, ?data? contains everything it should with the exception of the first variables on the right hand side of the equations. If an intercept term is allowed, then ?data? does contain the data frame of the whole system.

If I do something wrong, please tell me. 
I am looking forward to your reply.
Regards,
Martin

-----------------------------------------------------------------
?????? ???????? ? ???????? - ????????+???????? WWW.MOBILIS.BG


From ripley at stats.ox.ac.uk  Tue Sep 18 14:01:49 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Sep 2007 13:01:49 +0100 (BST)
Subject: [R] Need help on "date"
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC0574B31A@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC0574B31A@DJFPOST01.djf.agrsci.dk>
Message-ID: <Pine.LNX.4.64.0709181250590.9200@gannet.stats.ox.ac.uk>

On Tue, 18 Sep 2007, Frede Aakmann T?gersen wrote:

> One way (perhaps not the most efficient)
>
>> as.Date("2005-09-01","%Y-%m-%d")
> [1] "2005-09-01"
>> format(as.Date("2005-09-01","%Y-%m-%d"),"%Y")
> [1] "2005"
>> format(as.Date("2005-09-01","%Y-%m-%d"),"%d")
> [1] "01"
>> format(as.Date("2005-09-01","%Y-%m-%d"),"%m")
> [1] "09"

It's pretty efficient, but should you want numeric (rather than character) 
answers

> zz <- strptime("2005-09-01","%Y-%m-%d")
> zz$year + 1900
[1] 2005
> zz$mon + 1
[1] 9
> zz$mday
[1] 1

(I'm not sure why the POSIX people chose inconsistent origins, but they 
did.)

>>
>
>
> See ?DateTimeClasses.
>
> Med venlig hilsen
> Frede Aakmann T?gersen
>
>
>
>
>> -----Oprindelig meddelelse-----
>> Fra: r-help-bounces at r-project.org
>> [mailto:r-help-bounces at r-project.org] P? vegne af Arun Kumar Saha
>> Sendt: 18. september 2007 11:01
>> Til: r-help at stat.math.ethz.ch
>> Emne: [R] Need help on "date"
>>
>> Dear all,
>>
>> I have a variable 'x' like that:
>>
>>> x
>> [1] "2005-09-01"
>>
>> Here, 2005 represents year, 09 month and 01 day.
>>
>> Now I want to create three variables naming: y, m, and d such that:
>>
>> y = 2005
>> m = 09
>> d = 01
>>
>> can anyone tell me how to do that?
>>
>> Regards,
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From sergeyg at gmail.com  Tue Sep 18 14:07:02 2007
From: sergeyg at gmail.com (Sergey Goriatchev)
Date: Tue, 18 Sep 2007 14:07:02 +0200
Subject: [R] Problem updating packages
Message-ID: <7cb007bd0709180507q688c4c0ex774b0a98c3028818@mail.gmail.com>

Hello, everybody

I have R 2.5.1 now installed on a laptop with Windows Vista Home
Premium. I have problems updating the packages. Here is what I get at
the prompt when I try to update:


> update.packages(ask='graphics')
--- Please select a CRAN mirror for use in this session ---
trying URL 'http://cran.ch.r-project.org/bin/windows/contrib/2.5/car_1.2-2.zip'
Content type 'application/zip' length 709592 bytes
opened URL
downloaded 692Kb

trying URL 'http://cran.ch.r-project.org/bin/windows/contrib/2.5/lattice_0.16-5.zip'
Content type 'application/zip' length 873537 bytes
opened URL
downloaded 853Kb

package 'car' successfully unpacked and MD5 sums checked
package 'lattice' successfully unpacked and MD5 sums checked

The downloaded packages are in
        C:\Users\Sergey\AppData\Local\Temp\RtmpbQJHsb\downloaded_packages
updating HTML package descriptions
Warning in install.packages(update[instlib == l, "Package"], l,
contriburl = contriburl,  :
         'lib = "C:/PROGRA~1/R/R-25~1.1/library"' is not writable
Error in install.packages(update[instlib == l, "Package"], l,
contriburl = contriburl,  :
        unable to install packages
>

What can be wrong? I already deleted R and its folder and installed it
fresh. Same problem. On an XP machine this never happened. :-( Thank
you for your help.


From ligges at statistik.uni-dortmund.de  Tue Sep 18 14:10:11 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 18 Sep 2007 14:10:11 +0200
Subject: [R] Proposal: Archive UseR conference presentations
	at	www.r-project.org/useR-yyyy
In-Reply-To: <fcmq8e$udt$1@sea.gmane.org>
References: <f8e6ff050709041413k70340217r76b51984d9e23ef9@mail.gmail.com>
	<fcmq8e$udt$1@sea.gmane.org>
Message-ID: <46EFC023.7030803@statistik.uni-dortmund.de>

Earl F. Glynn wrote:
> "hadley wickham" <h.wickham at gmail.com> wrote in message 
> news:f8e6ff050709041413k70340217r76b51984d9e23ef9 at mail.gmail.com...
>> Many of the presentations and posters from UseR! 2007 are now available 
>> online:
>> http://user2007.org/program/
> 
> The UseR 2006 conference info and presentations are part of 
> www.r-project.org, namely http://www.r-project.org/useR-2006/
> 
> I noticed the user2007.org  domain expires on 16 December 2007, which would 
> need to be renewed each year to continue to make these presentations 
> available online. During the year of a conference it makes sense to have a 
> separate domain, but would it make sense to archive old UseR conferences at 
> www.r-project.org/useR-yyyy?  Would it make sense to standardize this so one 
> could generalize and find the presentations for any year?
> 
> Next years' domain name is http://www.statistik.uni-dortmund.de/useR-2008/ 
> but could be www.r-project.org/useR-2008 .  An automatic redirection link 
> could be used so that www.r-project.org/useR-2008 is redirected to 
> http://www.statistik.uni-dortmund.de/useR-2008/  for now, but once the 
> conference is over the archive could be moved to www.r-project.org.  Any 
> comments?


I'm fine with the proposal to move abstract or presentation to 
www.r-project.org after the useR-2008. Having it local is much easier 
during the organization periods. I know this is one of the topics some 
useR organizers are currently discussing in the Austrian mountains 
(where I should be as well given I've had some more time these days).

Uwe Ligges


> Just my $0.02,
> 
> efg
> 
> Earl F. Glynn
> Scientific Programmer
> Stowers Institute for Medical Research
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mark at wardle.org  Tue Sep 18 14:18:23 2007
From: mark at wardle.org (Mark Wardle)
Date: Tue, 18 Sep 2007 13:18:23 +0100
Subject: [R] lme, diagnostic plots and missing values
Message-ID: <b59a37130709180518t681d8f9ag8ad84d4d41115554@mail.gmail.com>

Dear all,

I'm using lme()  to great success in modelling some of my clinical
data. It's saved me hours so I'm very grateful to have such powerful
tools!

I'm now exploring model diagnostics (using Pinheiro/Bates mixed
effects book), but have come across a problem with missing data:

# the models - no problems here
m1 <- lme(ic.total ~ duration + gilman,
    random = ~ 1 | patient.id, data=ic, subset=complete.cases(ic))
m2 <- lme(ic.total ~ duration + gilman,
    random = ~ 1 | patient.id, data=ic, na.action=na.omit)

# simple resid/fitted plots fine too
plot(m1)
plot(m2)

# try something a bit more clever:
plot(m1, resid(., type='p')~fitted(.) | sex, id=0.05)   # FINE!
plot(m2, resid(., type='p')~fitted(.) | sex, id=0.05)   # NOT FINE....:

Error in `[[<-.data.frame`(`*tmp*`, j, value = c(2L, 1L, 2L, 2L, 1L, 1L,  :
	replacement has 181 rows, data has 219

Am I doing something fundamentally stupid?

Many thanks for your help,

Best wishes,

Mark

R version 2.5.1 (2007-06-27)
i386-apple-darwin8.9.1

locale:
en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] "splines"   "stats"     "graphics"  "grDevices" "datasets"
"utils"     "methods"   "base"

other attached packages:
        lme4       Matrix         coda          irr     survival
 Hmisc      moments psychometric         nlme   multilevel
lattice        RODBC
 "0.99875-7" "0.999375-2"     "0.12-1"       "0.70"       "2.32"
"3.4-2"       "0.11"      "0.1.2"     "3.1-84"        "2.2"
"0.16-5"      "1.2-1"
>




-- 
Dr. Mark Wardle
Specialist registrar, Neurology
Cardiff, UK


From wl2776 at gmail.com  Tue Sep 18 14:41:28 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Tue, 18 Sep 2007 05:41:28 -0700 (PDT)
Subject: [R] Problem updating packages
In-Reply-To: <7cb007bd0709180507q688c4c0ex774b0a98c3028818@mail.gmail.com>
References: <7cb007bd0709180507q688c4c0ex774b0a98c3028818@mail.gmail.com>
Message-ID: <12756248.post@talk.nabble.com>



Sergey Goriatchev wrote:
> 
> Hello, everybody
> 
> I have R 2.5.1 now installed on a laptop with Windows Vista Home
> Premium. I have problems updating the packages. Here is what I get at
> the prompt when I try to update:
> 
> 
>> update.packages(ask='graphics')
> --- Please select a CRAN mirror for use in this session ---
> trying URL
> 'http://cran.ch.r-project.org/bin/windows/contrib/2.5/car_1.2-2.zip'
> Content type 'application/zip' length 709592 bytes
> opened URL
> downloaded 692Kb
> 
> trying URL
> 'http://cran.ch.r-project.org/bin/windows/contrib/2.5/lattice_0.16-5.zip'
> Content type 'application/zip' length 873537 bytes
> opened URL
> downloaded 853Kb
> 
> package 'car' successfully unpacked and MD5 sums checked
> package 'lattice' successfully unpacked and MD5 sums checked
> 
> The downloaded packages are in
>         C:\Users\Sergey\AppData\Local\Temp\RtmpbQJHsb\downloaded_packages
> updating HTML package descriptions
> Warning in install.packages(update[instlib == l, "Package"], l,
> 

contriburl = contriburl,  :
         'lib = "C:/PROGRA~1/R/R-25~1.1/library"' is not writable
Error in install.packages(update[instlib == l, "Package"], l,
contriburl = contriburl,  :
        unable to install packages
>

What can be wrong? I already deleted R and its folder and installed it
fresh. Same problem. On an XP machine this never happened. :-( Thank
you for your help.


The function has written you what was wrong.
"C:/PROGRA~1/R/R-25~1.1/library"' was not writable

You should install new packages either running R with administrator
privilegies, or installing them to another directory, writable for ordinary
user.

-- 
View this message in context: http://www.nabble.com/Problem-updating-packages-tf4474009.html#a12756248
Sent from the R help mailing list archive at Nabble.com.


From marc_schwartz at comcast.net  Tue Sep 18 14:57:44 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Tue, 18 Sep 2007 07:57:44 -0500
Subject: [R] Sourcing encrypted files
In-Reply-To: <Pine.LNX.4.64.0709180646330.4973@gannet.stats.ox.ac.uk>
References: <922AE6B0-3797-47BB-BB16-8E5109DE2FB1@plessthan.com>
	<Pine.LNX.4.64.0709180646330.4973@gannet.stats.ox.ac.uk>
Message-ID: <1190120264.3629.62.camel@Bellerophon.localdomain>

On Tue, 2007-09-18 at 07:47 +0100, Prof Brian Ripley wrote:
> On Mon, 17 Sep 2007, Dennis Fisher wrote:
> 
> > Colleagues,
> >
> > I have an unusual problem; I am wondering whether anyone has dealt
> > with it and found a solution.
> >
> > I have a script that needs to be encrypted.  R will then be run on
> > the script.  There are various means to decrypt the file, some of
> > which leave the decrypted code on the hard drive for an excessive
> > period.
> >
> > One means that I have considered to deal with this is the following
> > (the unix code is not correct, just sufficient to communicate the idea):
> > 	system("decrypt ...")
> > 	system("rm encrypted file")
> > 	source(decrypted file)
> > 	system("rm decrypted file")
> >
> > Another approach would be to pipe the decrypted version to R in the
> > command line (as it is being decrypted).  Obviously, this could be
> > done with R < decryptedFile but this leaves the decrypted code
> > exposed.  Is there some other means to accomplish my goals using
> > something on the command line?
> 
> That's not what I understand by 'to pipe'.  You could use a pipe() 
> connection with source() if you had a pipeline decrypter, either
> 
> decrypt filename | Rscript
> 
> or
> 
> source(pipe("decrypt filename"))
> 
> Those would be slightly safer as the decrypted source code is (probably) 
> never written to the file system.
> 
> I am not sure what you are trying to achieve: since the R code is going to 
> be decrypted it will be possible (and I suspect easy) to get hold of the 
> decrypted version.  (Consider for example running a modified version of 
> source() that dumped out the parse tree.)  Using a package to read the 
> encrypted file and feed the decrypted source to the parser at C level an 
> expression at a time would make this harder to circumvent.
> 
> (Unlike Marc Schwartz, I am presuming the aim is to protect scripts from 
> casual inspection on someone else's machine: as Marc says there are better 
> ways to protect code and data on your own systems.)

I had not considered the scenario of running the scripts on someone
else's machine and protecting what may be a 'proprietary' script.

The same issues I noted apply here and you would need to consider the
risk of disclosure against the costs/complexity to protect it. 

As Prof. Ripley has noted, there are other file based approaches, but
you would need to consider the risk that the script would be written to
the local disk in the clear, either during processing to a temp file or
perhaps during memory paging.

Then the issue becomes the level of sophistication of the owner of the
computer upon which you are running the script and their motivation to
try to locate/read the clear text version.

If this is the scenario of concern, one additional approach, that would
at least eliminate the need to actually copy the script to the local HD,
would be to store the script on removable media, such as a USB flash
drive and source/run it from there.  This does not eliminate the
possibility that the file could be copied to the local HD as a temp file
or during memory paging, but at least it reduces the risks to some
extent.

The ideal option of course is to only use your own hardware and control
access to it.

HTH,

Marc Schwartz


From mnair at iusb.edu  Tue Sep 18 15:00:51 2007
From: mnair at iusb.edu (Nair, Murlidharan T)
Date: Tue, 18 Sep 2007 09:00:51 -0400
Subject: [R] MAD
In-Reply-To: <eb555e660709171409t63908ce8o3e22f6d16b3fb611@mail.gmail.com>
References: <45f568c70709140831y2c390fd4l256e9c5ce53079e1@mail.gmail.com>
	<644e1f320709141118n51f2349bn37f7d3f967f85654@mail.gmail.com>
	<20070917195229.GA5829@ihug.co.nz>
	<644e1f320709171259m78e2e8abg56ef66843df89564@mail.gmail.com>
	<A32055BDEA88C34BB3DBBCD2293807780154C9F8@iu-mssg-mbx109.ads.iu.edu>
	<eb555e660709171409t63908ce8o3e22f6d16b3fb611@mail.gmail.com>
Message-ID: <A32055BDEA88C34BB3DBBCD2293807780154CA41@iu-mssg-mbx109.ads.iu.edu>



-----Original Message-----
From: Deepayan Sarkar [mailto:deepayan.sarkar at gmail.com] 
Sent: Monday, September 17, 2007 5:10 PM
To: Nair, Murlidharan T
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] MAD

On 9/17/07, Nair, Murlidharan T <mnair at iusb.edu> wrote:
>
> I am calculating the median absolute deviation using mad function, and
> it tends to ignore the parameter constant=1, when I am calculating it
> for x=seq(1:5). Am I missing something here?
>
> x<-seq(1:5)
> mad(x)# gives [1] 1.4826
> mad(x, constant=1)# gives [1] 1
> #Here is the long form
> dev.from.median<-abs((x-median(x)))
> dev.from.median # Gives [1] 2 1 0 1 2
> sum(dev.from.median) # Gives [1] 6
> sum(dev.from.median)/length(x) # Gives [1] 1.2
> # The long form does not match the output from the function
>
> # When x<-seq(1:10) they match
> x<-seq(1:10)
> dev.from.median<-abs((x-median(x)))
> sum(dev.from.median)/length(x) # Gives 2.5
> mad(x, constant=1) # Gives 2.5
> #The long form matches the output from the function
>
> Did I miss anything here?

yes; mad := Median (not mean) absolute deviation (from the median, by
default).

-Deepayan

Indeed, its median and that what I am calculating in the long form.  So,
what is that you found I was doing differently? May be I missed your
point. 
Thx../M


From giemme81 at libero.it  Tue Sep 18 15:01:35 2007
From: giemme81 at libero.it (Giusy)
Date: Tue, 18 Sep 2007 06:01:35 -0700 (PDT)
Subject: [R] Time series analysis
Message-ID: <12756583.post@talk.nabble.com>


Hello, my name is Giusy and it's the first time I post in this forum. I'm a
beginner with R, I have to use it to analyse time series and I need some
help about these problems:
1. In my time series there are some NA values, but functions (arimaId,
arima,..) seem not to work in this case...what could I do?

2. I have to manage with time series with more than one seasonality, for
example weekly and monyhly, but I think arima work with only one
seasonality...does anyone know what to do?

Thank you very much
Giusy
-- 
View this message in context: http://www.nabble.com/Time-series-analysis-tf4474219.html#a12756583
Sent from the R help mailing list archive at Nabble.com.


From giemme81 at libero.it  Tue Sep 18 15:11:00 2007
From: giemme81 at libero.it (Giusy)
Date: Tue, 18 Sep 2007 06:11:00 -0700 (PDT)
Subject: [R] Sorry,an other question..
Message-ID: <12756688.post@talk.nabble.com>


Hello,
if I can I'd like to ask you an other thing..can I use with R specific
function to correct outliers in time series? What can I do?
Thank you very much
Giusy
-- 
View this message in context: http://www.nabble.com/Sorry%2Can-other-question..-tf4474255.html#a12756688
Sent from the R help mailing list archive at Nabble.com.


From ggrothendieck at gmail.com  Tue Sep 18 15:37:46 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 18 Sep 2007 09:37:46 -0400
Subject: [R] Problem updating packages
In-Reply-To: <12756248.post@talk.nabble.com>
References: <7cb007bd0709180507q688c4c0ex774b0a98c3028818@mail.gmail.com>
	<12756248.post@talk.nabble.com>
Message-ID: <971536df0709180637o33c27c2ciafee00ee23e9a428@mail.gmail.com>

On 9/18/07, Vladimir Eremeev <wl2776 at gmail.com> wrote:
>
>
> Sergey Goriatchev wrote:
> >
> > Hello, everybody
> >
> > I have R 2.5.1 now installed on a laptop with Windows Vista Home
> > Premium. I have problems updating the packages. Here is what I get at
> > the prompt when I try to update:
> >
[...]
> > C:\Users\Sergey\AppData\Local\Temp\RtmpbQJHsb\downloaded_packages
> > updating HTML package descriptions
> > Warning in install.packages(update[instlib == l, "Package"], l,
> >
>
> contriburl = contriburl,  :
>         'lib = "C:/PROGRA~1/R/R-25~1.1/library"' is not writable
> Error in install.packages(update[instlib == l, "Package"], l,
> contriburl = contriburl,  :
>        unable to install packages
> >
>
> The function has written you what was wrong.
> "C:/PROGRA~1/R/R-25~1.1/library"' was not writable
>
> You should install new packages either running R with administrator
> privilegies, or installing them to another directory, writable for ordinary
> user.
>

On my Vista system I placed R in %userprofile%\Documents\R\R-2.6.0
and it works ok.  I imagine that placing it in C:\R\R-2.6.0
would work too but would have to try it.  Actually even
C:\Program Files\R\R-2.6.0 works for me provided the user library is
in %userprofile%\R\win-library\2.6
which is where R 2.6.0 tries to put it but not if I try to use
c:\Program Files\R\R-2.6.0\library

It was mainly building packages that caused me a problem (which
I gather you are not currently doing -- only installing them from binary) in
my initial setup which is why I moved R to its current location.  I
also put the source directories for my packages in %userprofile%\R

By the way, if you want to switch between several versions of R
that are all on your system RSetReg.exe must be run elevated.
In http://batchfiles.googlecode.com there is a Windows javascript
program, Rversions.hta, which I have updated to work on Vista and
will do that. Run it from Windows command line without args. See the
README.  You can download it directly here:
   http://batchfiles.googlecode.com/svn/trunk/Rversions.hta
I have found it useful while trying different versions of R on my Vista
system.


From S.Ellison at lgc.co.uk  Tue Sep 18 15:37:33 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Tue, 18 Sep 2007 14:37:33 +0100
Subject: [R] Histogram with colors
Message-ID: <s6efe289.078@tedmail2.lgc.co.uk>

>>> "Alberto Monteiro" <albmont at centroin.com.br> 17/09/2007 21:11:51 >>>
>Is there a simple way to plot a histogram with colors?
>
>I think I can do it in two steps:
>
>  x.hist <- hist(x, plot=FALSE)
>  plot(x.hist, col=c(rep("red", 5), rep("green", 12)))
>
>but maybe a more direct way is available.

Not really, unless you specify breaks= in the histogram call. You will need to know the number of bins to specify the colours correctly, so you need a histogram object.

But you can use the histogram object itself to choose which bars to colour:
 x<-rnorm(150)
x.hist<-hist(x, plot=F)
plot(x.hist, col=ifelse(x.hist$mids>0,"green","red"))

$mids holds the midpoints of the bins, so it will always give you a vector of the right length for the colours.

You can compress this into one line:
plot(x.hist<-hist(x, plot=F), col=ifelse(x.hist$mids>0,"green","red"))

but it's really the same number of operations, so it gains little.


Steve ellison


*******************************************************************
This email and any attachments are confidential. Any use, co...{{dropped}}


From ggrothendieck at gmail.com  Tue Sep 18 15:44:19 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 18 Sep 2007 09:44:19 -0400
Subject: [R] Need help on "date"
In-Reply-To: <d4c57560709180200q2adf68f7ua2a8d823ac488229@mail.gmail.com>
References: <d4c57560709180200q2adf68f7ua2a8d823ac488229@mail.gmail.com>
Message-ID: <971536df0709180644t4ac5cbbdib0df94511717c0dd@mail.gmail.com>

There have been a few solutions already but I thought I would add one
that uses chron:

> library(chron)
> attach(month.day.year(chron(unclass(as.Date("2005-09-01")))))
> year
[1] 2005
> month
[1] 9
> day
[1] 1

or perhaps cleaner:

library(chron)
with(month.day.year(chron(unclass(as.Date("2006-09-01")))), {
   ... computations involving variables month, day and year ...
}

See R News 4/1 help desk article for info on dates.  Particularly the table
at the end.
On 9/18/07, Arun Kumar Saha <arun.kumar.saha at gmail.com> wrote:
> Dear all,
>
> I have a variable 'x' like that:
>
> > x
> [1] "2005-09-01"
>
> Here, 2005 represents year, 09 month and 01 day.
>
> Now I want to create three variables naming: y, m, and d such that:
>
> y = 2005
> m = 09
> d = 01
>
> can anyone tell me how to do that?
>
> Regards,
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Giovanna.Jonalasinio at uniroma1.it  Tue Sep 18 16:01:28 2007
From: Giovanna.Jonalasinio at uniroma1.it (Giovanna.Jonalasinio at uniroma1.it)
Date: Tue, 18 Sep 2007 16:01:28 +0200
Subject: [R] =?iso-8859-1?q?Giovanna_Jonalasinio_=E8_fuori_ufficio?=
Message-ID: <OF0478639B.33F6053C-ONC125735A.004D0A04-C125735A.004D0A04@Uniroma1.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070918/315a8b28/attachment.pl 

From ehlers at math.ucalgary.ca  Tue Sep 18 16:28:41 2007
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Tue, 18 Sep 2007 08:28:41 -0600
Subject: [R] MAD
In-Reply-To: <A32055BDEA88C34BB3DBBCD2293807780154CA41@iu-mssg-mbx109.ads.iu.edu>
References: <45f568c70709140831y2c390fd4l256e9c5ce53079e1@mail.gmail.com>	<644e1f320709141118n51f2349bn37f7d3f967f85654@mail.gmail.com>	<20070917195229.GA5829@ihug.co.nz>	<644e1f320709171259m78e2e8abg56ef66843df89564@mail.gmail.com>	<A32055BDEA88C34BB3DBBCD2293807780154C9F8@iu-mssg-mbx109.ads.iu.edu>	<eb555e660709171409t63908ce8o3e22f6d16b3fb611@mail.gmail.com>
	<A32055BDEA88C34BB3DBBCD2293807780154CA41@iu-mssg-mbx109.ads.iu.edu>
Message-ID: <46EFE099.2000103@math.ucalgary.ca>

If you read ?mad you will find this phrase:

"median of the absolute deviations from the median"

Note the first word. I think you're too focused on
the last word.

Peter Ehlers

Nair, Murlidharan T wrote:
> 
> -----Original Message-----
> From: Deepayan Sarkar [mailto:deepayan.sarkar at gmail.com] 
> Sent: Monday, September 17, 2007 5:10 PM
> To: Nair, Murlidharan T
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] MAD
> 
> On 9/17/07, Nair, Murlidharan T <mnair at iusb.edu> wrote:
>> I am calculating the median absolute deviation using mad function, and
>> it tends to ignore the parameter constant=1, when I am calculating it
>> for x=seq(1:5). Am I missing something here?
>>
>> x<-seq(1:5)
>> mad(x)# gives [1] 1.4826
>> mad(x, constant=1)# gives [1] 1
>> #Here is the long form
>> dev.from.median<-abs((x-median(x)))
>> dev.from.median # Gives [1] 2 1 0 1 2
>> sum(dev.from.median) # Gives [1] 6
>> sum(dev.from.median)/length(x) # Gives [1] 1.2
>> # The long form does not match the output from the function
>>
>> # When x<-seq(1:10) they match
>> x<-seq(1:10)
>> dev.from.median<-abs((x-median(x)))
>> sum(dev.from.median)/length(x) # Gives 2.5
>> mad(x, constant=1) # Gives 2.5
>> #The long form matches the output from the function
>>
>> Did I miss anything here?
> 
> yes; mad := Median (not mean) absolute deviation (from the median, by
> default).
> 
> -Deepayan
> 
> Indeed, its median and that what I am calculating in the long form.  So,
> what is that you found I was doing differently? May be I missed your
> point. 
> Thx../M
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
>


From jspies at nd.edu  Tue Sep 18 16:31:57 2007
From: jspies at nd.edu (Jeffrey Robert Spies)
Date: Tue, 18 Sep 2007 10:31:57 -0400
Subject: [R] Need help on "date"
In-Reply-To: <d4c57560709180200q2adf68f7ua2a8d823ac488229@mail.gmail.com>
References: <d4c57560709180200q2adf68f7ua2a8d823ac488229@mail.gmail.com>
Message-ID: <8BF641FC-CC32-4F56-B13A-A1D9A7182FAE@nd.edu>

And one using regular expressions:

x <- "2005-09-01"
pattern <- '([[:digit:]]{4})-([[:digit:]]{2})-([[:digit:]]{2})'
y <- sub(pattern, '\\1', x)
m <- sub(pattern, '\\2', x)
d <- sub(pattern, '\\3', x)

-- Jeff.

On Sep 18, 2007, at 5:00 AM, Arun Kumar Saha wrote:

> Dear all,
>
> I have a variable 'x' like that:
>
>> x
> [1] "2005-09-01"
>
> Here, 2005 represents year, 09 month and 01 day.
>
> Now I want to create three variables naming: y, m, and d such that:
>
> y = 2005
> m = 09
> d = 01
>
> can anyone tell me how to do that?
>
> Regards,
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From arun.kumar.saha at gmail.com  Tue Sep 18 16:46:50 2007
From: arun.kumar.saha at gmail.com (Arun Kumar Saha)
Date: Tue, 18 Sep 2007 20:16:50 +0530
Subject: [R] Need help on "date"
In-Reply-To: <8BF641FC-CC32-4F56-B13A-A1D9A7182FAE@nd.edu>
References: <d4c57560709180200q2adf68f7ua2a8d823ac488229@mail.gmail.com>
	<8BF641FC-CC32-4F56-B13A-A1D9A7182FAE@nd.edu>
Message-ID: <d4c57560709180746m10f6ef4q697ea185ee366cad@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070918/df0a5eef/attachment.pl 

From pensterfuzzer at yahoo.de  Tue Sep 18 16:54:14 2007
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Tue, 18 Sep 2007 16:54:14 +0200 (CEST)
Subject: [R] Linear model with svyglm
Message-ID: <272967.11747.qm@web23014.mail.ird.yahoo.com>

Hi,

I am a bit unclear if svyglm with family=gaussian is
actually a normal linear model including weighting.
The goal is to estimate a normal linear model using
sample inflation weights.

Can anybody illuminate me a bit on this?

Thanks a lot!
  Werner


From h.wickham at gmail.com  Tue Sep 18 17:05:00 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 18 Sep 2007 10:05:00 -0500
Subject: [R] Proposal: Archive UseR conference presentations at
	www.r-project.org/useR-yyyy
In-Reply-To: <46EFC023.7030803@statistik.uni-dortmund.de>
References: <f8e6ff050709041413k70340217r76b51984d9e23ef9@mail.gmail.com>
	<fcmq8e$udt$1@sea.gmane.org>
	<46EFC023.7030803@statistik.uni-dortmund.de>
Message-ID: <f8e6ff050709180805y6e856bd8t23da94e178e2bf43@mail.gmail.com>

On 9/18/07, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
> Earl F. Glynn wrote:
> > "hadley wickham" <h.wickham at gmail.com> wrote in message
> > news:f8e6ff050709041413k70340217r76b51984d9e23ef9 at mail.gmail.com...
> >> Many of the presentations and posters from UseR! 2007 are now available
> >> online:
> >> http://user2007.org/program/
> >
> > The UseR 2006 conference info and presentations are part of
> > www.r-project.org, namely http://www.r-project.org/useR-2006/
> >
> > I noticed the user2007.org  domain expires on 16 December 2007, which would
> > need to be renewed each year to continue to make these presentations
> > available online. During the year of a conference it makes sense to have a
> > separate domain, but would it make sense to archive old UseR conferences at
> > www.r-project.org/useR-yyyy?  Would it make sense to standardize this so one
> > could generalize and find the presentations for any year?
> >
> > Next years' domain name is http://www.statistik.uni-dortmund.de/useR-2008/
> > but could be www.r-project.org/useR-2008 .  An automatic redirection link
> > could be used so that www.r-project.org/useR-2008 is redirected to
> > http://www.statistik.uni-dortmund.de/useR-2008/  for now, but once the
> > conference is over the archive could be moved to www.r-project.org.  Any
> > comments?
>
>
> I'm fine with the proposal to move abstract or presentation to
> www.r-project.org after the useR-2008. Having it local is much easier
> during the organization periods. I know this is one of the topics some
> useR organizers are currently discussing in the Austrian mountains
> (where I should be as well given I've had some more time these days).

It would be even more useful to use subdomains like
user2007.r-project.org so that we could host the content at a site
other than on the R server (this would make it much easier for me, as
I won't need to change the site at all to work on the r-project
server).  I'm happy to advise on how to do this, if you (Fritz?) have
access to your DNS records.

Hadley


From ptit_bleu at yahoo.fr  Tue Sep 18 17:24:06 2007
From: ptit_bleu at yahoo.fr (Ptit_Bleu)
Date: Tue, 18 Sep 2007 08:24:06 -0700 (PDT)
Subject: [R] RE :  Must be easy,
 but haven't found the function (numerical integration)
In-Reply-To: <1DF7DB4AB44EFB41A60A889186D43359120D14@srv-laminiere.arvalis-fr.com>
References: <12732936.post@talk.nabble.com>
	<1DF7DB4AB44EFB41A60A889186D43359120D14@srv-laminiere.arvalis-fr.com>
Message-ID: <12759423.post@talk.nabble.com>


Thanks to all.

cumsum can be helpful but the solution given by David seems to match my
request.
I will test it as soon as possible (before the end of the week, I hope).

Have a nice end of day,
Ptit Bleu.

 

GOUACHE David wrote:
> 
> try :
> 
> library(Bolsatd)
> ?sintegral
> 
> or:
> 
> library(caTools)
> ?trapz
> 
> David Gouache
> Arvalis - Institut du V?g?tal
> Station de La Mini?re
> 78280 Guyancourt
> Tel: 01.30.12.96.22 / Port: 06.86.08.94.32
> 
> 
> -----Message d'origine-----
> De : Ptit_Bleu [mailto:ptit_bleu at yahoo.fr] 
> Envoy? : lundi 17 septembre 2007 12:09
> ? : r-help at stat.math.ethz.ch
> Objet : [R] Must be easy,but haven't found the function (numerical
> integration)
> 
> 
> Hi,
> 
> I have a data frame of 2 columns with the following types :
> data$day char
> data$value num
> 
> And I plot my data with :
> plot(strptime(donnees$day,format="%Y-%m-%d %H:%M:%S"),donnees$value,
> type="l")
> 
> And I'd just like to get the numerical value of the integration of this
> graph.
> I looked at ?integrate but, as far as I understood (that is, not very
> much,
> due to my poor english), it seems that it doesn't work with values in data
> frame.
> 
> Could you please help me to do this ?
> 
> Thanks in advance,
> Have a nice week,
> Ptit Bleu.
> -- 
> View this message in context:
> http://www.nabble.com/Must-be-easy%2C-but-haven%27t-found-the-function-%28numerical-integration%29-tf4465684.html#a12732936
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Must-be-easy%2C-but-haven%27t-found-the-function-%28numerical-integration%29-tf4465684.html#a12759423
Sent from the R help mailing list archive at Nabble.com.


From rvaradhan at jhmi.edu  Tue Sep 18 17:27:33 2007
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Tue, 18 Sep 2007 11:27:33 -0400
Subject: [R] RE :  Must be easy,
	but haven't found the function (numerical integration)
In-Reply-To: <12759423.post@talk.nabble.com>
References: <12732936.post@talk.nabble.com>
	<1DF7DB4AB44EFB41A60A889186D43359120D14@srv-laminiere.arvalis-fr.com>
	<12759423.post@talk.nabble.com>
Message-ID: <000801c7fa08$6f211570$7c94100a@win.ad.jhu.edu>

Here is a simple trapezoidal rule integrator:

x <- time
y <- value

area <- sum(diff(x)*(y[-1]+y[-length(y)]))/2

Ravi.


----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html



----------------------------------------------------------------------------
--------

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Ptit_Bleu
Sent: Tuesday, September 18, 2007 11:24 AM
To: r-help at r-project.org
Subject: Re: [R] RE : Must be easy, but haven't found the function
(numerical integration)


Thanks to all.

cumsum can be helpful but the solution given by David seems to match my
request.
I will test it as soon as possible (before the end of the week, I hope).

Have a nice end of day,
Ptit Bleu.



GOUACHE David wrote:
> 
> try :
> 
> library(Bolsatd)
> ?sintegral
> 
> or:
> 
> library(caTools)
> ?trapz
> 
> David Gouache
> Arvalis - Institut du V?g?tal
> Station de La Mini?re
> 78280 Guyancourt
> Tel: 01.30.12.96.22 / Port: 06.86.08.94.32
> 
> 
> -----Message d'origine-----
> De : Ptit_Bleu [mailto:ptit_bleu at yahoo.fr] 
> Envoy? : lundi 17 septembre 2007 12:09
> ? : r-help at stat.math.ethz.ch
> Objet : [R] Must be easy,but haven't found the function (numerical
> integration)
> 
> 
> Hi,
> 
> I have a data frame of 2 columns with the following types :
> data$day char
> data$value num
> 
> And I plot my data with :
> plot(strptime(donnees$day,format="%Y-%m-%d %H:%M:%S"),donnees$value,
> type="l")
> 
> And I'd just like to get the numerical value of the integration of this
> graph.
> I looked at ?integrate but, as far as I understood (that is, not very
> much,
> due to my poor english), it seems that it doesn't work with values in data
> frame.
> 
> Could you please help me to do this ?
> 
> Thanks in advance,
> Have a nice week,
> Ptit Bleu.
> -- 
> View this message in context:
>
http://www.nabble.com/Must-be-easy%2C-but-haven%27t-found-the-function-%28nu
merical-integration%29-tf4465684.html#a12732936
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context:
http://www.nabble.com/Must-be-easy%2C-but-haven%27t-found-the-function-%28nu
merical-integration%29-tf4465684.html#a12759423
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From deepayan.sarkar at gmail.com  Tue Sep 18 17:29:55 2007
From: deepayan.sarkar at gmail.com (deepayan.sarkar at gmail.com)
Date: Tue, 18 Sep 2007 08:29:55 -0700
Subject: [R] MAD
In-Reply-To: <A32055BDEA88C34BB3DBBCD2293807780154CA41@iu-mssg-mbx109.ads.iu.edu>
References: <45f568c70709140831y2c390fd4l256e9c5ce53079e1@mail.gmail.com>
	<644e1f320709141118n51f2349bn37f7d3f967f85654@mail.gmail.com>
	<20070917195229.GA5829@ihug.co.nz>
	<644e1f320709171259m78e2e8abg56ef66843df89564@mail.gmail.com>
	<A32055BDEA88C34BB3DBBCD2293807780154C9F8@iu-mssg-mbx109.ads.iu.edu>
	<eb555e660709171409t63908ce8o3e22f6d16b3fb611@mail.gmail.com>
	<A32055BDEA88C34BB3DBBCD2293807780154CA41@iu-mssg-mbx109.ads.iu.edu>
Message-ID: <eb555e660709180829m40f59a13s9402d79ab0e22b53@mail.gmail.com>

On 9/18/07, Nair, Murlidharan T <mnair at iusb.edu> wrote:
>
>
> -----Original Message-----
> From: Deepayan Sarkar [mailto:deepayan.sarkar at gmail.com]
> Sent: Monday, September 17, 2007 5:10 PM
> To: Nair, Murlidharan T
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] MAD
>
> On 9/17/07, Nair, Murlidharan T <mnair at iusb.edu> wrote:
> >
> > I am calculating the median absolute deviation using mad function, and
> > it tends to ignore the parameter constant=1, when I am calculating it
> > for x=seq(1:5). Am I missing something here?
> >
> > x<-seq(1:5)
> > mad(x)# gives [1] 1.4826
> > mad(x, constant=1)# gives [1] 1
> > #Here is the long form
> > dev.from.median<-abs((x-median(x)))
> > dev.from.median # Gives [1] 2 1 0 1 2
> > sum(dev.from.median) # Gives [1] 6
> > sum(dev.from.median)/length(x) # Gives [1] 1.2

I'm pretty sure that adding up a bunch of numbers and dividing the
total by the number of numbers qualifies as computing the mean, not
the median.

> > Did I miss anything here?
>
> yes; mad := Median (not mean) absolute deviation (from the median, by
> default).
>
> -Deepayan
>
> Indeed, its median and that what I am calculating in the long form.  So,
> what is that you found I was doing differently? May be I missed your
> point.
> Thx../M
>


From mckellercran at gmail.com  Tue Sep 18 17:40:11 2007
From: mckellercran at gmail.com (Matthew Keller)
Date: Tue, 18 Sep 2007 09:40:11 -0600
Subject: [R] problems with nested loop
In-Reply-To: <99116.68733.qm@web45513.mail.sp1.yahoo.com>
References: <99116.68733.qm@web45513.mail.sp1.yahoo.com>
Message-ID: <3f547caa0709180840o5e4abecfq879c912fe4d92255@mail.gmail.com>

hi Riddle,

You subscript is out of bounds because this line:
  for (j in seq(20,100,20)){

is incorrect - it is trying to index the 20th, 40th, 60th... column of
a matrix that has only 5 columns. Try for (j in 1:5) instead. I'm not
sure what the purpose of your script is so can't comment on what else
needs to be done...

Matt


On 9/17/07, Riddle Chin <riddle_chin at yahoo.com> wrote:
> Hi, everyone:
>      R is new to me. I am writing a nested loop to simulate data for t-test. The following code is wrong. The subscript is out of bounds. Could anyone tell me how to revise it? Thanks, Riddle Chin.
>
>   result<-matrix(ncol=5, nrow=1000)
> colnames(result)<-c('N=20','N=40','N=60','N=80','N=100')
>  for (i in 1:1000){
>    for (j in seq(20,100,20)){
>      x<-rnorm(j,2.7,1)
>      result[i,j]<-t.test(x,mu=4)$p.value<=0.05
>    }
>  }
>
>
>
> ---------------------------------
> Luggage? GPS? Comic books?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Matthew C Keller
Postdoctoral Fellow
Virginia Institute for Psychiatric and Behavioral Genetics


From davidmontgom at hotmail.com  Mon Sep 17 06:18:19 2007
From: davidmontgom at hotmail.com (David Montgomery)
Date: Sun, 16 Sep 2007 18:18:19 -1000
Subject: [R] random Forests
Message-ID: <BLU116-W2258CCE788A43772BF38B9CCBF0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070916/e3808d7f/attachment.pl 

From delphine.fontaine at genexion.com  Mon Sep 17 12:26:48 2007
From: delphine.fontaine at genexion.com (Delphine Fontaine)
Date: Mon, 17 Sep 2007 12:26:48 +0200
Subject: [R] longtable and Sweave
Message-ID: <000501c7f915$42309ca0$7b010a0a@Genexion.local>

Dear Sweave-users,

I want to print listing using sweave. Because my tables are very big, I use
the longtable option. But, is it possible to recall the first line of the
table (e.g the colnames line) on each new page ?
Thanks for your help.

Delphine


From eugen_pircalabelu at yahoo.com  Mon Sep 17 16:18:37 2007
From: eugen_pircalabelu at yahoo.com (eugen pircalabelu)
Date: Mon, 17 Sep 2007 07:18:37 -0700 (PDT)
Subject: [R] Survey package question
Message-ID: <348160.52465.qm@web38605.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070917/11a64be2/attachment.pl 

From marvena at tin.it  Mon Sep 17 13:38:24 2007
From: marvena at tin.it (Marco Venanzi)
Date: Mon, 17 Sep 2007 13:38:24 +0200
Subject: [R] Importing a dataset
Message-ID: <000e01c7f91f$41fbec80$0501a8c0@nome65ff66cddf>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070917/f6d8d606/attachment.pl 

From riddle_chin at yahoo.com  Tue Sep 18 16:05:39 2007
From: riddle_chin at yahoo.com (Riddle Chin)
Date: Tue, 18 Sep 2007 07:05:39 -0700 (PDT)
Subject: [R] Nested loop ok now. Thanks to you all
Message-ID: <828029.72778.qm@web45507.mail.sp1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070918/5ee8730e/attachment.pl 

From thogiti at gmail.com  Tue Sep 18 00:22:33 2007
From: thogiti at gmail.com (Nagu)
Date: Mon, 17 Sep 2007 15:22:33 -0700
Subject: [R] Time-dependent association rules
Message-ID: <21da85430709171522r18b6f25btedd08e2fdefa4c8b@mail.gmail.com>

Hi,

How do we address time-dependent association rules with R?

I have a large transactional database of consumers that bought from a
set of n distinct products over the time period, T. I am interested in
adding the time component to the association rules generation. (This
kind of analysis falls into sequence pattern matching, if I am
correct.) Please advice me on how to proceed? Any references or
implementations or algorithms?

Thank you,
Nagu


From bates at stat.wisc.edu  Tue Sep 18 17:56:03 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 18 Sep 2007 10:56:03 -0500
Subject: [R] Proposal: Archive UseR conference presentations at
	www.r-project.org/useR-yyyy
In-Reply-To: <f8e6ff050709180805y6e856bd8t23da94e178e2bf43@mail.gmail.com>
References: <f8e6ff050709041413k70340217r76b51984d9e23ef9@mail.gmail.com>
	<fcmq8e$udt$1@sea.gmane.org>
	<46EFC023.7030803@statistik.uni-dortmund.de>
	<f8e6ff050709180805y6e856bd8t23da94e178e2bf43@mail.gmail.com>
Message-ID: <40e66e0b0709180856s5d4c2218n6f74fe7575402244@mail.gmail.com>

On 9/18/07, hadley wickham <h.wickham at gmail.com> wrote:
> On 9/18/07, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
> > Earl F. Glynn wrote:
> > > "hadley wickham" <h.wickham at gmail.com> wrote in message
> > > news:f8e6ff050709041413k70340217r76b51984d9e23ef9 at mail.gmail.com...
> > >> Many of the presentations and posters from UseR! 2007 are now available
> > >> online:
> > >> http://user2007.org/program/
> > >
> > > The UseR 2006 conference info and presentations are part of
> > > www.r-project.org, namely http://www.r-project.org/useR-2006/
> > >
> > > I noticed the user2007.org  domain expires on 16 December 2007, which would
> > > need to be renewed each year to continue to make these presentations
> > > available online. During the year of a conference it makes sense to have a
> > > separate domain, but would it make sense to archive old UseR conferences at
> > > www.r-project.org/useR-yyyy?  Would it make sense to standardize this so one
> > > could generalize and find the presentations for any year?
> > >
> > > Next years' domain name is http://www.statistik.uni-dortmund.de/useR-2008/
> > > but could be www.r-project.org/useR-2008 .  An automatic redirection link
> > > could be used so that www.r-project.org/useR-2008 is redirected to
> > > http://www.statistik.uni-dortmund.de/useR-2008/  for now, but once the
> > > conference is over the archive could be moved to www.r-project.org.  Any
> > > comments?
> >
> >
> > I'm fine with the proposal to move abstract or presentation to
> > www.r-project.org after the useR-2008. Having it local is much easier
> > during the organization periods. I know this is one of the topics some
> > useR organizers are currently discussing in the Austrian mountains
> > (where I should be as well given I've had some more time these days).
>
> It would be even more useful to use subdomains like
> user2007.r-project.org so that we could host the content at a site
> other than on the R server (this would make it much easier for me, as
> I won't need to change the site at all to work on the r-project
> server).  I'm happy to advise on how to do this, if you (Fritz?) have
> access to your DNS records.

The nameservers for the R-project.org domain are located here at the
University of Wisconsin.  I can request a CNAME of
user2007.R-project.org be added if you tell me (off-list) the IP
address and ANAME of the machine to which it should point.


From davidr at rhotrading.com  Tue Sep 18 18:18:57 2007
From: davidr at rhotrading.com (davidr at rhotrading.com)
Date: Tue, 18 Sep 2007 11:18:57 -0500
Subject: [R] Problem in extracting EQY_DVD_HIST from Bloomberg
In-Reply-To: <A36876D3F8A5734FA84A4338135E7CC3027D7DF3@BAN-MAILSRV03.Amba.com>
References: <A36876D3F8A5734FA84A4338135E7CC3027D7DF3@BAN-MAILSRV03.Amba.com>
Message-ID: <F9F2A641C593D7408925574C05A7BE774E752D@rhopost.rhotrading.com>

I'd guess start and end are confusing the bulk data call (it doesn't
take those params). This works for me:

div <- blpGetData(con, "IBM Equity", "EQY_DVD_HIST", retval="raw")

You need the "raw" retval when anything is not numeric; then you need to
extract the bits you want from the nested list returned.

HTH,
David

David L. Reiner
Rho Trading Securities, LLC

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Shubha Vishwanath Karanth
Sent: Tuesday, September 18, 2007 1:08 AM
To: R-SIG-Finance at stat.math.ethz.ch; r-help at stat.math.ethz.ch
Subject: [R] Problem in extracting EQY_DVD_HIST from Bloomberg

Hi R,

 

Again the problem in Bloomberg, I give the below code,

 

> con =
blpConnect(show.days="trading",na.action="previous.days",periodicity="da
ily")# connecting Bloomberg
> div <- blpGetData(con,"IBM US
Equity","EQY_DVD_HIST",start=as.chron(as.Date("01/01/2005",
"%m/%d/%Y")),end=as.chron(Sys.Date()))
> blpDisconnect(con)


used (Mb) gc trigger (Mb) max used (Mb)
Ncells 480141 12.9 818163 21.9 818163 21.9
Vcells 798590 6.1 1445757 11.1 1441593 11.0



> div
EQY_DVD_HIST
(09/17/07 19:34:49) NA

 

I get all NA data. What could be the problem? I have the corresponding
data in Bloomberg....but not able to extract the data from R....

 

Thanks in advance,

Shubha


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Tue Sep 18 18:38:37 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Sep 2007 17:38:37 +0100 (BST)
Subject: [R] unbalanced effects in aov
In-Reply-To: <2139054076.1189797513974.JavaMail.webber@orpheus7.dataserver.cornell.edu>
References: <2139054076.1189797513974.JavaMail.webber@orpheus7.dataserver.cornell.edu>
Message-ID: <Pine.LNX.4.64.0709181724010.7432@gannet.stats.ox.ac.uk>

On Fri, 14 Sep 2007, Brooke LaFlamme wrote:

> Hi, I have been having some trouble using aov to do an anova, probably 
> because I'm not understanding how to use this function correctly. For 
> some reason it always tells me that "Estimated effects may be 
> unbalanced", though I'm not sure what this means. Is the formula I am 
> using written incorrectly? Below is the code I am using along with the 
> data:

[...]

> I am treating all the variables as factors (except for response, obviously).
>
> formula<-response~species+line%in%species+replicate%in%line+sex%in%species+plate
> model<-aov(formula, data=my.data)
>
> This is the output:
>
>> model
> Call:
>   aov(formula = formula, data = my.data)
>
> Terms:
>                     species        plate species:line line:replicate
> Sum of Squares  0.0026469288 0.0000945202 0.0003320255   0.0002008000
> Deg. of Freedom            2           11           27             10
>                 species:sex    Residuals
> Sum of Squares  0.0001383116 0.0006315465
> Deg. of Freedom            3           66
>
> Residual standard error: 0.003093362
> Estimated effects may be unbalanced
>
> Any help would be greatly appreciated as the R help documentation for 
> aov does not address this issue.

For the benefit of those who are unable to appreciate 
fortunes::fortune("WTFM"), the help page actually says

      'aov' is designed for balanced designs, and the results can be
      hard to interpret without balance: beware that missing values in
      the response(s) will likely lose the balance.  If there are two or
      more error strata, the methods used are statistically inefficient
      without balance, and it may be better to use 'lme'.

      Balance can be checked with the 'replications' function.

So let's do as it suggests:

> replications(formula, data=my.data)
$species
[1] 40

$plate
plate
  1  2  3  4  5  6  7  8  9 10 11 12
11 11 11 10  9 11 10 11 10 11  9  6

$`species:line`
[1] 4

$`line:replicate`
[1] 6

$`species:sex`
[1] 20

and the problem will be clear to those who have read ?replications.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From daniel.brewer at icr.ac.uk  Tue Sep 18 18:41:37 2007
From: daniel.brewer at icr.ac.uk (Daniel Brewer)
Date: Tue, 18 Sep 2007 17:41:37 +0100
Subject: [R] Cox regression and p-values
Message-ID: <46EFFFC1.80607@icr.ac.uk>

Hello,
I might be barking up the wrong tree here, but I want to make sure I
have a full understanding of this.  What I would like to know is what
tests are performed to give the p-values for each variable in the table
that is the result of coxph regression when the variables are
categorical only.

More specifically, when expected counts are less than 5 is the Fisher's
exact test used instead of the Chi^2 test?

Many thanks
Dan
-- 
**************************************************************
Daniel Brewer, Ph.D.
Institute of Cancer Research
Email: daniel.brewer at icr.ac.uk
**************************************************************

The Institute of Cancer Research: Royal Cancer Hospital, a charitable Company Limited by Guarantee, Registered in England under Company No. 534147 with its Registered Office at 123 Old Brompton Road, London SW7 3RP.

This e-mail message is confidential and for use by the addre...{{dropped}}


From murdoch at stats.uwo.ca  Tue Sep 18 18:56:54 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 18 Sep 2007 12:56:54 -0400
Subject: [R] Cox regression and p-values
In-Reply-To: <46EFFFC1.80607@icr.ac.uk>
References: <46EFFFC1.80607@icr.ac.uk>
Message-ID: <46F00356.5020002@stats.uwo.ca>

On 9/18/2007 12:41 PM, Daniel Brewer wrote:
> Hello,
> I might be barking up the wrong tree here, but I want to make sure I
> have a full understanding of this.  What I would like to know is what
> tests are performed to give the p-values for each variable in the table
> that is the result of coxph regression when the variables are
> categorical only.
> 
> More specifically, when expected counts are less than 5 is the Fisher's
> exact test used instead of the Chi^2 test?

I think you need to check the reference (Anderson and Gill) or the 
source to be sure, but I wouldn't expect either of those tests to be 
used here.

I'd guess these are generalized likelihood ratio tests:  fit the model 
with the variable, fit it without, and look at the difference in 
(partial) log likelihood.  If the variable does not affect the response 
then twice the difference in log likelihood would have an asymptotic 
chi-square distribution.

Fisher's exact test and the Pearson chi-square test are not appropriate 
here, because the individuals are not exchangeable under the null 
hypothesis.

Duncan Murdoch


From marc_schwartz at comcast.net  Tue Sep 18 19:31:51 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Tue, 18 Sep 2007 12:31:51 -0500
Subject: [R] longtable and Sweave
In-Reply-To: <000501c7f915$42309ca0$7b010a0a@Genexion.local>
References: <000501c7f915$42309ca0$7b010a0a@Genexion.local>
Message-ID: <1190136711.3629.80.camel@Bellerophon.localdomain>

On Mon, 2007-09-17 at 12:26 +0200, Delphine Fontaine wrote:
> Dear Sweave-users,
> 
> I want to print listing using sweave. Because my tables are very big, I use
> the longtable option. But, is it possible to recall the first line of the
> table (e.g the colnames line) on each new page ?
> Thanks for your help.
> 
> Delphine

Strictly speaking, it's not an Sweave issue but a LaTeX markup issue.

Depending upon how you are generating your LaTeX output, there are ways
of specifying table headers and footers, and to differentiate how they
look on the first/last page versus the middle pages.

The easiest way, may be to use either the xtable()/print.xtable()
functions in David Dahl's 'xtable' package or the latex() function in
Frank Harrell's Hmisc package.  Both have options to output your object
using longtable.

If you are coding this by hand, you need to review the longtable
documentation, paying attention to the use of the \endfirsthead,
\endhead, \endfoot and \endlastfoot tags to define, respectively, the
first page header, the remaining page headers, the footer for all but
the last page and the last page footer. These sections precede the
actual tabular content.

As an example:

begin{longtable}{lrr}
\caption[This is a longtable]{This is a longtable} \\
\toprule
\textbf{Column 1} & \textbf{Column 2} & \textbf{Column 3} \\
\midrule \\
\endfirsthead

\caption{This is a longtable (continued)} \\
\toprule
\textbf{Column 1} & \textbf{Column 2} & \textbf{Column 3} \\
\midrule \\
\endhead

\bottomrule
\endfoot

\bottomrule
\endlastfoot

Line 1 & Data 1 & Data 1 \\
Line 2 & Data 2 & Data 2 \\
Line 3 & Data 3 & Data 3 \\
\end{longtable}


Note that you do not have to use the \endfirsthead and \endlastfoot tags
if these are to be the same for all pages. You would only use the
\endhead and \endfoot tags in that case.

HTH,

Marc Schwartz


From Mark.Leeds at morganstanley.com  Tue Sep 18 20:08:18 2007
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Tue, 18 Sep 2007 14:08:18 -0400
Subject: [R] installing rgl package on linux platform
Message-ID: <D3AEEDA31E57474B840BEBC25A8A834401957ADD@NYWEXMB23.msad.ms.com>

I am using Redhat Linux and my info is below. I was trying to install
the rgl package using R CMD INSTALL and it was doing
fine until it got to the compilation of a pixmap program ? Does anyone
know what I could do to fix that ? Is it possible that
this package is not usable on this platform ? Thanks.

sessionInfo()
R version 2.5.0 (2007-04-23) 
i686-pc-linux-gnu 

locale:
C

attached base packages:
[1] "datasets"  "utils"     "stats"     "graphics"  "grDevices"
"methods"   "base"     

other attached packages:
 lattice filehash  reshape      zoo    chron     MASS 
"0.15-8"    "1.0"  "0.7.4"  "1.3-1" "2.3-11" "7.2-33" 


partial output of the R CMD INSTALL is below :

#=======================================================================
========================================================================

config.status: creating src/Makevars
** libs
g++ -I/ms/dist/fsf/PROJ/R/2.5.0/exec/lib/R/include
-I/ms/dist/fsf/PROJ/R/2.5.0/exec/lib/R/include -DHAVE_PNG_H
-I/usr/X11R6/include -Iext   
 -g -O2 -fpic  -g -O2 -c BBoxDeco.cpp -o BBoxDeco.o
g++ -I/ms/dist/fsf/PROJ/R/2.5.0/exec/lib/R/include
-I/ms/dist/fsf/PROJ/R/2.5.0/exec/lib/R/include -DHAVE_PNG_H
-I/usr/X11R6/include -Iext   
 -g -O2 -fpic  -g -O2 -c Background.cpp -o Background.o
g++ -I/ms/dist/fsf/PROJ/R/2.5.0/exec/lib/R/include
-I/ms/dist/fsf/PROJ/R/2.5.0/exec/lib/R/include -DHAVE_PNG_H
-I/usr/X11R6/include -Iext  
  -g -O2 -fpic  -g -O2 -c Color.cpp -o Color.o
g++ -I/ms/dist/fsf/PROJ/R/2.5.0/exec/lib/R/include
-I/ms/dist/fsf/PROJ/R/2.5.0/exec/lib/R/include -DHAVE_PNG_H
-I/usr/X11R6/include -Iext   
 -g -O2 -fpic  -g -O2 -c Disposable.cpp -o Disposable.o
g++ -I/ms/dist/fsf/PROJ/R/2.5.0/exec/lib/R/include
-I/ms/dist/fsf/PROJ/R/2.5.0/exec/lib/R/include -DHAVE_PNG_H
-I/usr/X11R6/include -Iext    
-g -O2 -fpic  -g -O2 -c FaceSet.cpp -o FaceSet.o

And many more g++ commands until it got to the one below.


g++ -I/ms/dist/fsf/PROJ/R/2.5.0/exec/lib/R/include
-I/ms/dist/fsf/PROJ/R/2.5.0/exec/lib/R/include -DHAVE_PNG_H
-I/usr/X11R6/include -Iext    -g -O2 -fpic  -g -O2 -c pixmap.cpp -o
pixmap.o
In file included from pixmap.cpp:13:
pngpixmap.h:273: syntax error before `*' token
pngpixmap.h: In static member function `static void 
   PNGPixmapFormat::Load::info_callback(png_struct*, png_info*)':
pngpixmap.h:180: `png_set_gray_1_2_4_to_8' undeclared (first use this
function)
pngpixmap.h:180: (Each undeclared identifier is reported only once for
each 
   function it appears in.)
pngpixmap.h:200: `png_set_palette_to_rgb' undeclared (first use this
function)
pngpixmap.h:214: `png_set_tRNS_to_alpha' undeclared (first use this
function)
make: *** [pixmap.o] Error 1

ERROR: compilation failed for package 'rgl'
** Removing
'/a/nyn19f1/vol/nyn19f1v2/r_ied_etlnas20/devusersleedsmar/res/R/lib_new/
rgl'
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From bolker at ufl.edu  Tue Sep 18 20:08:32 2007
From: bolker at ufl.edu (bbolker)
Date: Tue, 18 Sep 2007 11:08:32 -0700 (PDT)
Subject: [R] Create correlated data with skew
In-Reply-To: <94A21AC3-A7E3-4B2B-B731-59B76D461D2F@DAL.CA>
References: <94A21AC3-A7E3-4B2B-B731-59B76D461D2F@DAL.CA>
Message-ID: <12762799.post@talk.nabble.com>




Mike Lawrence wrote:
> 
> Hi all,
> 
> I understand that it is simple to create data with a specific  
> correlation (say, .5) using mvrnorm from the MASS library:
> 
>  > library(MASS)
>  > set.seed(1)
>  >
>  > a=mvrnorm(
> + 	n=10
> + 	,mu=rep(0,2)
> + 	,Sigma=matrix(c(1,.5,.5,1),2,2)
> + 	,empirical=T
> + )
>  > a
>              [,1]         [,2]
> [1,] -1.0008380 -1.233467875
> [2,] -0.1588633 -0.003410001
> [3,]  1.2054727 -0.620558768
> [4,]  1.9580971  2.389495155
> [5,] -0.9447473 -0.141852055
> [6,]  0.6236799 -0.826952659
> [7,]  0.1421782  0.452217611
> [8,] -0.9050954  0.330991444
> [9,] -0.7261632  0.217740460
> [10,] -0.1937206 -0.564203311
>  > cor(a)
>       [,1] [,2]
> [1,]  1.0  0.5
> [2,]  0.5  1.0
> 
> 
> But I'm looking to create data where the variables are non-normally  
> distributed (i.e. somewhat skewed). Any suggestions?
> 
> Mike
> 
> --
> Mike Lawrence
> Graduate Student, Department of Psychology, Dalhousie University
> 
> Website: http://memetic.ca
> 
> Public calendar: http://icalx.com/public/informavore/Public
> 
> "The road to wisdom? Well, it's plain and simple to express:
> Err and err and err again, but less and less and less."
> 	- Piet Hein
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

The simplest (?) solution is probably to exponentiate your MVN data,
leading to a bivariate log-normal distribution.  The hard part is
specifying the parameters of the lognormal in terms of the desired
variance-covariance matrix.   Variances are not too bad, but correlation
may not be solvable.  (Of course, if you don't care much about the
precise characteristics of the simulated data and/or are willing to
use some trial and error to get the desired variance/correlation you
don't have to deal with this.)
See e.g.

http://www.stuart.iit.edu/faculty/workingpapers/thomopoulos/SomeMeasuresontheStandardBivariateLognormalDistribution.doc

 for some of the relevant formulas.

  good luck
    Ben Bolker

-- 
View this message in context: http://www.nabble.com/Create-correlated-data-with-skew-tf4468269.html#a12762799
Sent from the R help mailing list archive at Nabble.com.


From Cody_Hamilton at Edwards.com  Tue Sep 18 20:08:36 2007
From: Cody_Hamilton at Edwards.com (Cody Hamilton)
Date: Tue, 18 Sep 2007 11:08:36 -0700
Subject: [R] Cox regression and p-values
In-Reply-To: <46EFFFC1.80607@icr.ac.uk>
References: <46EFFFC1.80607@icr.ac.uk>
Message-ID: <4C7D0185E1C6D64AAFB18A2281B262B806757E3FD4@EXIRV01.am.edwards.lcl>

Daniel,

With regards to the use of Fisher's exact test when cell counts are less than 5, take a look at:

D'Agostino, RB, Chase, W and Belanger, A (1988). 'The appropriateness of some common procedures for testing the equality of two independent binomial populations.' 42:198-202.

Regards,
   -Cody

Cody Hamilton
Edwards Lifesciences

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Daniel Brewer
Sent: Tuesday, September 18, 2007 9:42 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Cox regression and p-values

Hello,
I might be barking up the wrong tree here, but I want to make sure I
have a full understanding of this.  What I would like to know is what
tests are performed to give the p-values for each variable in the table
that is the result of coxph regression when the variables are
categorical only.

More specifically, when expected counts are less than 5 is the Fisher's
exact test used instead of the Chi^2 test?

Many thanks
Dan
--
**************************************************************
Daniel Brewer, Ph.D.
Institute of Cancer Research
Email: daniel.brewer at icr.ac.uk
**************************************************************

The Institute of Cancer Research: Royal Cancer Hospital, a charitable Company Limited by Guarantee, Registered in England under Company No. 534147 with its Registered Office at 123 Old Brompton Road, London SW7 3RP.

This e-mail message is confidential and for use by the addre...{{dropped}}

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Greg.Snow at intermountainmail.org  Tue Sep 18 20:19:00 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Tue, 18 Sep 2007 12:19:00 -0600
Subject: [R] help for high-quality plot (wmf) in files
In-Reply-To: <004401c7f940$2defc560$3a0b2c0a@gne.windows.gene.com>
References: <20070913144738.rjz7cyn794wk0og8@web.mail.umich.edu><07E228A5BE53C24CAD490193A7381BBBBF9336@LP-EXCHVS07.CO.IHC.COM><20070916134710.3a1m2x561w4cwc40@web.mail.umich.edu><971536df0709161055v407cf9fbrb1e13f5e6aafb193@mail.gmail.com>
	<004401c7f940$2defc560$3a0b2c0a@gne.windows.gene.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBF9764@LP-EXCHVS07.CO.IHC.COM>

Standard sweave may not work for this, but there is the odfWeave package
that will create openoffice documents which can easily be converted to
word docs (I have used this for creating sets of graphs to send to
clients who only use word).  I don't know if it can generate .wmf files
or not, but it does produce pretty good quality graphics (best if you
specify up front what size you want the graphs to be).

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
> Sent: Monday, September 17, 2007 9:34 AM
> To: 'Gabor Grothendieck'; 'Zheng Lu'
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] help for high-quality plot (wmf) in files
> 
> May I ask a related question to tack on to this thread.
> 
> One can also output a wmf plot to a file through the 
> win.metafile() call.
> But as the help file says, due to Windows limitations only 
> one plot per file is allowed and one must use parameterized 
> filenames to produce multiple plots, which I often have in 
> e.g. lattice displays.
> 
> My question: For those who deal routinely with this issue, 
> what sorts of strategies do you use to produce and keep track 
> of multiple wmf files (in Windows)?  Any code (or packages) 
> or tricks for combining all the plots into one file with 
> suitable identifying labels?
> 
> NOTE: AFAICS Sweave doesn't work, as it produces only pdf graphs.
> 
> Feel free to reply off list, as this is not really an R question.
> 
> Cheers,
> Bert 
> 
> 
> Bert Gunter
> Genentech Nonclinical Statistics
> 
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Gabor Grothendieck
> Sent: Sunday, September 16, 2007 10:55 AM
> To: Zheng Lu
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] help for high-quality plot
> 
> Use windows metafile format.  Its a vector graphic format so 
> it will display in full resolution.  png is bitmapped and so 
> won't.  Also you can edit a wmf graphic in Word using Word's 
> built in graphic editor so you could change the labels, etc. 
> even after you have imported it.  Right click the graphic in 
> R and save or copy it as a metafile.
> 
> On 9/16/07, Zheng Lu <zlu at umich.edu> wrote:
> > Dear all:
> >
> > I am curious how to generate high-quality plot and graph with R and 
> > input it into my word document. my plot was always 
> generated in device 
> > 2, when I save it as PNG, the quality is poor. Thank you 
> very much for 
> > your consideration and time.
> >
> >
> > ZLu
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From marc_schwartz at comcast.net  Tue Sep 18 20:32:36 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Tue, 18 Sep 2007 13:32:36 -0500
Subject: [R] Cox regression and p-values
In-Reply-To: <4C7D0185E1C6D64AAFB18A2281B262B806757E3FD4@EXIRV01.am.edwards.lcl>
References: <46EFFFC1.80607@icr.ac.uk>
	<4C7D0185E1C6D64AAFB18A2281B262B806757E3FD4@EXIRV01.am.edwards.lcl>
Message-ID: <1190140356.3629.104.camel@Bellerophon.localdomain>

I'll throw in a more recent citation:

Chi-squared and Fisher-Irwin tests of two-by-two tables with small
sample recommendations
Stat in Med 26:3661-3675; 2007
http://www3.interscience.wiley.com/cgi-bin/abstract/114125487/ABSTRACT

to which Frank Harrell has offered some comments here (bottom of page):

  http://biostat.mc.vanderbilt.edu/twiki/bin/view/Main/DataAnalysisDisc

HTH,

Marc Schwartz


On Tue, 2007-09-18 at 11:08 -0700, Cody Hamilton wrote:
> Daniel,
> 
> With regards to the use of Fisher's exact test when cell counts are
> less than 5, take a look at:
> 
> D'Agostino, RB, Chase, W and Belanger, A (1988). 'The appropriateness
> of some common procedures for testing the equality of two independent
> binomial populations.' 42:198-202.
> 
> Regards,
>    -Cody

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Daniel Brewer
> Sent: Tuesday, September 18, 2007 9:42 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Cox regression and p-values
> 
> Hello,
> I might be barking up the wrong tree here, but I want to make sure I
> have a full understanding of this.  What I would like to know is what
> tests are performed to give the p-values for each variable in the table
> that is the result of coxph regression when the variables are
> categorical only.
> 
> More specifically, when expected counts are less than 5 is the Fisher's
> exact test used instead of the Chi^2 test?
> 
> Many thanks
> Dan


From Dimitris.Rizopoulos at med.kuleuven.be  Tue Sep 18 20:49:27 2007
From: Dimitris.Rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 18 Sep 2007 20:49:27 +0200
Subject: [R] Create correlated data with skew
In-Reply-To: <12762799.post@talk.nabble.com>
References: <94A21AC3-A7E3-4B2B-B731-59B76D461D2F@DAL.CA>
	<12762799.post@talk.nabble.com>
Message-ID: <20070918204927.5ly4v5b3yxc8ssks@webmail4.kuleuven.be>

Quoting bbolker <bolker at ufl.edu>:

>
>
>
> Mike Lawrence wrote:
>>
>> Hi all,
>>
>> I understand that it is simple to create data with a specific
>> correlation (say, .5) using mvrnorm from the MASS library:
>>
>>  > library(MASS)
>>  > set.seed(1)
>>  >
>>  > a=mvrnorm(
>> + 	n=10
>> + 	,mu=rep(0,2)
>> + 	,Sigma=matrix(c(1,.5,.5,1),2,2)
>> + 	,empirical=T
>> + )
>>  > a
>>              [,1]         [,2]
>> [1,] -1.0008380 -1.233467875
>> [2,] -0.1588633 -0.003410001
>> [3,]  1.2054727 -0.620558768
>> [4,]  1.9580971  2.389495155
>> [5,] -0.9447473 -0.141852055
>> [6,]  0.6236799 -0.826952659
>> [7,]  0.1421782  0.452217611
>> [8,] -0.9050954  0.330991444
>> [9,] -0.7261632  0.217740460
>> [10,] -0.1937206 -0.564203311
>>  > cor(a)
>>       [,1] [,2]
>> [1,]  1.0  0.5
>> [2,]  0.5  1.0
>>
>>
>> But I'm looking to create data where the variables are non-normally
>> distributed (i.e. somewhat skewed). Any suggestions?
>>
>> Mike
>>
>> --
>> Mike Lawrence
>> Graduate Student, Department of Psychology, Dalhousie University
>>
>> Website: http://memetic.ca
>>
>> Public calendar: http://icalx.com/public/informavore/Public
>>
>> "The road to wisdom? Well, it's plain and simple to express:
>> Err and err and err again, but less and less and less."
>> 	- Piet Hein
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> The simplest (?) solution is probably to exponentiate your MVN data,
> leading to a bivariate log-normal distribution.  The hard part is
> specifying the parameters of the lognormal in terms of the desired
> variance-covariance matrix.   Variances are not too bad, but correlation
> may not be solvable.  (Of course, if you don't care much about the
> precise characteristics of the simulated data and/or are willing to
> use some trial and error to get the desired variance/correlation you
> don't have to deal with this.)
> See e.g.
>
> http://www.stuart.iit.edu/faculty/workingpapers/thomopoulos/SomeMeasuresontheStandardBivariateLognormalDistribution.doc
>
>  for some of the relevant formulas.
>
>   good luck
>     Ben Bolker
>


Another possibility is to use copulas, e.g.,

cop <- claytonCopula(2)
x <- mvdc(cop, c("gamma", "gamma"),
     list(list(shape = 3, rate = 2), list(shape = 2, rate = 4)))
x.samp <- rmvdc(x, 1000)


for the Clayton copula with parameter 2, the correlation (in terms of  
Kendall's-tau) is 0.5:

cor(x.samp, method = "kendall")


Best,
Dimitris

-- 
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
      http://www.student.kuleuven.be/~m0390867/dimitris.htm



> View this message in context:   
> http://www.nabble.com/Create-correlated-data-with-skew-tf4468269.html#a12762799
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>



Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From edd at debian.org  Tue Sep 18 20:55:54 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 18 Sep 2007 13:55:54 -0500
Subject: [R] installing rgl package on linux platform
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A834401957ADD@NYWEXMB23.msad.ms.com>
References: <D3AEEDA31E57474B840BEBC25A8A834401957ADD@NYWEXMB23.msad.ms.com>
Message-ID: <20070918185554.GA19473@eddelbuettel.com>

On Tue, Sep 18, 2007 at 02:08:18PM -0400, Leeds, Mark (IED) wrote:
> I am using Redhat Linux and my info is below. I was trying to install
> the rgl package using R CMD INSTALL and it was doing
> fine until it got to the compilation of a pixmap program ? Does anyone
> know what I could do to fix that ? Is it possible that
> this package is not usable on this platform ? Thanks.

Naaa, of course it does work on Linux. We have had rgl in Debian for years.

[...]
> g++ -I/ms/dist/fsf/PROJ/R/2.5.0/exec/lib/R/include
> -I/ms/dist/fsf/PROJ/R/2.5.0/exec/lib/R/include -DHAVE_PNG_H
> -I/usr/X11R6/include -Iext    -g -O2 -fpic  -g -O2 -c pixmap.cpp -o
> pixmap.o
> In file included from pixmap.cpp:13:
> pngpixmap.h:273: syntax error before `*' token
> pngpixmap.h: In static member function `static void 
>    PNGPixmapFormat::Load::info_callback(png_struct*, png_info*)':
> pngpixmap.h:180: `png_set_gray_1_2_4_to_8' undeclared (first use this
> function)
> pngpixmap.h:180: (Each undeclared identifier is reported only once for
> each 
>    function it appears in.)

You don't have the PNG library and/or headers. Install those, and try
again.

Dirk

-- 
Three out of two people have difficulties with fractions.


From sunnyside500 at gmail.com  Tue Sep 18 21:56:57 2007
From: sunnyside500 at gmail.com (runner)
Date: Tue, 18 Sep 2007 12:56:57 -0700 (PDT)
Subject: [R] a quick question about "format()"
Message-ID: <12764903.post@talk.nabble.com>


In the documentation of 'pairs'(package:graphics), within the last example,
it reads: 

format(c(r, 0.123456789), digits=3)[1]

Why not simple use: format(r, digits=3)? What is the difference?

Thanks.
-- 
View this message in context: http://www.nabble.com/a-quick-question-about-%22format%28%29%22-tf4476762.html#a12764903
Sent from the R help mailing list archive at Nabble.com.


From Greg.Snow at intermountainmail.org  Tue Sep 18 22:09:04 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Tue, 18 Sep 2007 14:09:04 -0600
Subject: [R] graphs with gradients of colors
In-Reply-To: <36B62AB1E934124BA81C2B3B615E9F008119CD@xmail05.ad.ua.ac.be>
References: <36B62AB1E934124BA81C2B3B615E9F008119CD@xmail05.ad.ua.ac.be>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBF97A8@LP-EXCHVS07.CO.IHC.COM>

The first question you should ask is "why do you want to do this?".
Adding gradients and other things like that can make a graph look neat,
but can also distort the information in the graph.  You should carefully
consider whether doing things like this really help the graph, or
distract from it.

If you do create a graph with the gradient, you should also create one
without the gradient and compare them to see which conveys the important
information better.

If you decide to go ahead with this, there was a discussion a while ago
on including pictures as the background of bar charts, you could use
something similar to that but with a gradient instead of a picture.  For
some cases it may be easier to create your graph, then use another tool
like imagemagick or gimp to replace a color with the gradient.

If you want to do it in R, then here are a couple of options to get you
started (your specifics will vary depending on the curve you want to
use, how smooth you want things to look, etc.

xx <- seq( -3,3, length=250 )
yy <- dnorm(xx, 0, 1)

plot(xx,yy, type='l')
tmp <- par('usr')

par(new=TRUE)

image( tmp[1:2], seq( tmp[3], tmp[4], len=101 ), 
  matrix( 1:100, ncol=100, nrow=1), add=TRUE,
  col=heat.colors(100))

polygon( c(tmp[1],xx,tmp[2],tmp[2],tmp[1] ), 
  c(yy[1], yy, yy[ length(yy) ], tmp[4], tmp[4] ), 
  col='white', border='white')
polygon( c(tmp[1], tmp[2], tmp[2], tmp[1] ),
  c(yy[1],yy[1], tmp[3], tmp[3]), col='white', border='white')

lines(xx,yy)
box()

# this one may be a bit of overkill for most cases, but does give more
# flexibility

library(TeachingDemos)

xx <- seq(0, 2*pi, length=100)
yy <- sin(xx)

plot(xx,yy, type='l', ylim=c(-1.1, 1.1))

tmpfun <- function(...){
   image( c(0,2*pi), seq(-1.1,1.1,length=101), matrix( 1:100, nrow=1 ),
	col=terrain.colors(100), add=TRUE )
}

xxx <- embed(xx,2)
for( i in 1:99 ){
	clipplot( tmpfun(), c(xxx[i,2],xxx[i,1]), c(-1.1,
(yy[i]+yy[i+1])/2 ) )
}

lines(xx,yy)

# shade from 0

plot(xx,yy, type='l', ylim=c(-1.1, 1.1))

tmpfun <- function(...){
   image( c(0,2*pi), seq(-1.1,1.1,length=101), matrix( 1:100, nrow=1 ),
	col=terrain.colors(100), add=TRUE )
}

xxx <- embed(xx,2)
for( i in 1:99 ){
	clipplot( tmpfun(), c(xxx[i,2],xxx[i,1]), c(0, (yy[i]+yy[i+1])/2
) )
}

lines(xx,yy)


Use at your own risk and definitly compare them to simple plots for
clarity.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Van Dongen Stefan
> Sent: Monday, September 17, 2007 7:37 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] graphs with gradients of colors
> 
> Hi All,
>  
> I would like to fill the area under a curve with a gradient 
> of colors. Are there any packages or trick I could use
>  
> Thanks
>  
> Stefan
>  
>  
> Stefan Van Dongen
> Antwerp
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From tplate at acm.org  Tue Sep 18 22:15:05 2007
From: tplate at acm.org (Tony Plate)
Date: Tue, 18 Sep 2007 14:15:05 -0600
Subject: [R] a quick question about "format()"
In-Reply-To: <12764903.post@talk.nabble.com>
References: <12764903.post@talk.nabble.com>
Message-ID: <46F031C9.6050804@acm.org>

runner wrote:
> In the documentation of 'pairs'(package:graphics), within the last example,
> it reads: 
> 
> format(c(r, 0.123456789), digits=3)[1]
> 
> Why not simple use: format(r, digits=3)? What is the difference?

Here are some examples of the difference:

 > for (r in 1.2*10^(-6:9)) cat(format(c(r, 0.123456789), digits=3)[1], 
format(r, digits=3), "\n")
1.20e-06 1.2e-06
0.000012 1.2e-05
0.00012 0.00012
0.0012 0.0012
0.012 0.012
0.120 0.12
1.200 1.2
12.000 12
120.000 120
1200.000 1200
1.20e+04 12000
1.20e+05 120000
1.20e+06 1200000
1.20e+07 1.2e+07
1.20e+08 1.2e+08
1.20e+09 1.2e+09
 >

> 
> Thanks.


From g_smits at verizon.net  Tue Sep 18 23:03:43 2007
From: g_smits at verizon.net (Gerard Smits)
Date: Tue, 18 Sep 2007 14:03:43 -0700
Subject: [R]  machine learning and horse racing
Message-ID: <0JOL00EUV16EYAB8@vms042.mailsrvcs.net>

Hi Stephen,

Not responding to the R memory question, but to the racing.

I worked on this many years ago and found no way of overcoming the 
19% or so paramutual take.  That being said, I suggest you take class 
into account (based on purse, type of race (maiden claiming, claiming 
$, NWxx allowance, etc).    Make sure that you are accounting for the 
size of the field.  it is much easier to win a race of 6 than 12 
horses.  A similar bias applies to the advantage of inner post 
position, if you do not account for number of entries.

Re validation, I would not build a mode on X years of data and then 
validate.  Patterns change and a model needs to be adaptive. I would 
use a hold out day, per week (randomly chosen) and then use that.

good luck in a difficult task.

Gerard


From Max.Kuhn at pfizer.com  Tue Sep 18 23:02:45 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Tue, 18 Sep 2007 17:02:45 -0400
Subject: [R] help for high-quality plot (wmf) in files
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBBF9764@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <71257D09F114DA4A8E134DEAC70F25D3098AFE65@groamrexm03.amer.pfizer.com>

> Standard sweave may not work for this, but there is the odfWeave
package
> that will create openoffice documents which can easily be converted to
> word docs (I have used this for creating sets of graphs to send to
> clients who only use word).  I don't know if it can generate .wmf
files
> or not, but it does produce pretty good quality graphics (best if you
> specify up front what size you want the graphs to be).

Here is an example:

   currentPlotDef <- getImageDefs()

   currentPlotDef$device <- "win.metafile"
   currentPlotDef$type <- "wmf"
   currentPlotDef$plotHeight <- 7
   currentPlotDef$plotWidth<- 7

   setImageDefs(currentPlotDef)

   demoFile <- system.file("examples", "simple.odt", package =
"odfWeave")

   odfWeave(demoFile, "c:\\wmfTest.odt")

You can also add figure captions to each image in case that helps. There
is a file called "formatting.odt" in the package examples directory that
explains how to use the package (in addition to the man pages). 

Nore that the resulting odt file is a compressed archive and the raw
images are stored in a sub-directory called Pictures.

Potential statement of the obvious: the win.metafile driver is not
available on all platforms (it may be windows only).

Max


From bal44 at cornell.edu  Tue Sep 18 23:06:04 2007
From: bal44 at cornell.edu (Brooke LaFlamme)
Date: Tue, 18 Sep 2007 17:06:04 -0400 (EDT)
Subject: [R] unbalanced effects in aov
Message-ID: <406520014.1190149564487.JavaMail.webber@orpheus7.dataserver.cornell.edu>

Thank you for the suggestions from Professor Ripley and Steve Elliot. I see now why my data are unbalanced even though I don't have any missing data. 

I think I should use other methods designed for unbalanced data, but does using lme with plate as a random effect also help to fix this problem? I am still very new at this type of analysis. 

Thank you for the help.

Brooke 



-----Original Message-----

> Date: Tue Sep 18 12:38:37 EDT 2007
> From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
> Subject: Re: [R] unbalanced effects in aov
> To: 
>
> On Fri, 14 Sep 2007, Brooke LaFlamme wrote:
> 
> > Hi, I have been having some trouble using aov to do an anova, probably 
> > because I'm not understanding how to use this function correctly. For 
> > some reason it always tells me that "Estimated effects may be 
> > unbalanced", though I'm not sure what this means. Is the formula I am 
> > using written incorrectly? Below is the code I am using along with the 
> > data:
> 
> [...]
> 
> > I am treating all the variables as factors (except for response, obviously).
> >
> > formula<-response~species+line%in%species+replicate%in%line+sex%in%species+plate
> > model<-aov(formula, data=my.data)
> >
> > This is the output:
> >
> >> model
> > Call:
> >   aov(formula = formula, data = my.data)
> >
> > Terms:
> >                     species        plate species:line line:replicate
> > Sum of Squares  0.0026469288 0.0000945202 0.0003320255   0.0002008000
> > Deg. of Freedom            2           11           27             10
> >                 species:sex    Residuals
> > Sum of Squares  0.0001383116 0.0006315465
> > Deg. of Freedom            3           66
> >
> > Residual standard error: 0.003093362
> > Estimated effects may be unbalanced
> >
> > Any help would be greatly appreciated as the R help documentation for 
> > aov does not address this issue.
> 
> For the benefit of those who are unable to appreciate 
> fortunes::fortune("WTFM"), the help page actually says
> 
>       'aov' is designed for balanced designs, and the results can be
>       hard to interpret without balance: beware that missing values in
>       the response(s) will likely lose the balance.  If there are two or
>       more error strata, the methods used are statistically inefficient
>       without balance, and it may be better to use 'lme'.
> 
>       Balance can be checked with the 'replications' function.
> 
> So let's do as it suggests:
> 
> > replications(formula, data=my.data)
> $species
> [1] 40
> 
> $plate
> plate
>   1  2  3  4  5  6  7  8  9 10 11 12
> 11 11 11 10  9 11 10 11 10 11  9  6
> 
> $`species:line`
> [1] 4
> 
> $`line:replicate`
> [1] 6
> 
> $`species:sex`
> [1] 20
> 
> and the problem will be clear to those who have read ?replications.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Tue Sep 18 23:07:39 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 18 Sep 2007 17:07:39 -0400
Subject: [R] installing rgl package on linux platform
In-Reply-To: <20070918185554.GA19473@eddelbuettel.com>
References: <D3AEEDA31E57474B840BEBC25A8A834401957ADD@NYWEXMB23.msad.ms.com>
	<20070918185554.GA19473@eddelbuettel.com>
Message-ID: <46F03E1B.3000100@stats.uwo.ca>

On 18/09/2007 2:55 PM, Dirk Eddelbuettel wrote:
 > On Tue, Sep 18, 2007 at 02:08:18PM -0400, Leeds, Mark (IED) wrote:
 >> I am using Redhat Linux and my info is below. I was trying to install
 >> the rgl package using R CMD INSTALL and it was doing
 >> fine until it got to the compilation of a pixmap program ? Does anyone
 >> know what I could do to fix that ? Is it possible that
 >> this package is not usable on this platform ? Thanks.
 >
 > Naaa, of course it does work on Linux. We have had rgl in Debian for 
years.
 >
 > [...]
 >> g++ -I/ms/dist/fsf/PROJ/R/2.5.0/exec/lib/R/include
 >> -I/ms/dist/fsf/PROJ/R/2.5.0/exec/lib/R/include -DHAVE_PNG_H
 >> -I/usr/X11R6/include -Iext    -g -O2 -fpic  -g -O2 -c pixmap.cpp -o
 >> pixmap.o
 >> In file included from pixmap.cpp:13:
 >> pngpixmap.h:273: syntax error before `*' token
 >> pngpixmap.h: In static member function `static void
 >>    PNGPixmapFormat::Load::info_callback(png_struct*, png_info*)':
 >> pngpixmap.h:180: `png_set_gray_1_2_4_to_8' undeclared (first use this
 >> function)
 >> pngpixmap.h:180: (Each undeclared identifier is reported only once for
 >> each
 >>    function it appears in.)
 >
 > You don't have the PNG library and/or headers. Install those, and try
 > again.

The configure script is supposed to detect that, but I guess it failed. 
  There's a configure option --disable-libpng-config that should allow 
the rest to compile.  (Various examples will fail, because the PNG code 
is used for textures and saving snapshots.  But most things should work.)

Duncan Murdoch


From p.dalgaard at biostat.ku.dk  Tue Sep 18 23:15:03 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 18 Sep 2007 23:15:03 +0200
Subject: [R] Cox regression and p-values
In-Reply-To: <46F00356.5020002@stats.uwo.ca>
References: <46EFFFC1.80607@icr.ac.uk> <46F00356.5020002@stats.uwo.ca>
Message-ID: <46F03FD7.10400@biostat.ku.dk>

Duncan Murdoch wrote:
> On 9/18/2007 12:41 PM, Daniel Brewer wrote:
>   
>> Hello,
>> I might be barking up the wrong tree here, but I want to make sure I
>> have a full understanding of this.  What I would like to know is what
>> tests are performed to give the p-values for each variable in the table
>> that is the result of coxph regression when the variables are
>> categorical only.
>>
>> More specifically, when expected counts are less than 5 is the Fisher's
>> exact test used instead of the Chi^2 test?
>>     
>
> I think you need to check the reference (Anderson and Gill) or the 
> source to be sure, but I wouldn't expect either of those tests to be 
> used here.
>   
(That's Andersen, with an 'e'. He's probably used to that misspelling by 
now, though.)

Almost everything in this world can be converted to a chi-square 
distributed test statistic, but it is not usually the familiar 
sum((O-E)^2/E) formula (which is wrong already for the simple two-group 
comparison, i.e. logrank test, unless you have special assumptions on 
the censoring pattern).

There is no obvious counterpart to the Fisher test available for 
survival data, as far as I know.
> I'd guess these are generalized likelihood ratio tests:  fit the model 
> with the variable, fit it without, and look at the difference in 
> (partial) log likelihood.  If the variable does not affect the response 
> then twice the difference in log likelihood would have an asymptotic 
> chi-square distribution.
>
>   
The ones in the table of coefficients are Wald tests, I believe. I.e. 
they are based on the variance-covariance matrix based on the inverse 
Hessian matrix for the likelihood, calculated at the  maximum  
likelihood estimate.

> Fisher's exact test and the Pearson chi-square test are not appropriate 
> here, because the individuals are not exchangeable under the null 
> hypothesis.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From iteachtyping at gmail.com  Wed Sep 19 00:52:07 2007
From: iteachtyping at gmail.com (Raymond Balise)
Date: Tue, 18 Sep 2007 15:52:07 -0700
Subject: [R]  xyplot question
In-Reply-To: <eb555e660709171201l67e71ec0u8a86bc2952300dd4@mail.gmail.com>
References: <3f2154540709141537l9609dc6jae6f3fc109bf2d9e@mail.gmail.com>
	<eb555e660709141631i1730d37bh49c6d8064736c483@mail.gmail.com>
	<3f2154540709142229t32eaff54j34e617d4d93bba5d@mail.gmail.com>
	<eb555e660709171201l67e71ec0u8a86bc2952300dd4@mail.gmail.com>
Message-ID: <3f2154540709181552u1e5557a5y1914236138cb00e4@mail.gmail.com>

I am tring to add error bars to data in an xyplot.  Below is the
content of a CSV file that I am trying to use and the code which plots
the data points and 45 degree lines in each of the panes of the
trellice.  I want to add error bars that go up and down to the limits
set by the lcl and ucl values in the data set.  How the heck can I
specify the error bars in a lattice plot?

If anyone knows how to do this can you please tell me how to do it and
more importantly point me toward a book/paper that explains how to do
this and has examples. :~)  As always, help is profoundly appreciated.

fig2 = read.xls("figure2.csv")

library(lattice)
library(grid)

with(fig2,
          xyplot(y ~ x |  group * Method,
          xlab = "",
          xlim = c(-5, 1),
          ylab = "",
          ylim = c(-5, 1),
          col = "black",
          groups = group,
          aspect = 1,
          lx = lcl,
          ux = ucl,
          pch = 16 ,
          panel = function(x, y, ...) {
             panel.superpose(x, y, ...)
             panel.abline(0, 1)

         },
         )
)

###### some sample data for a CSV file ############

Method,group,x,y,lcl,ucl
A,Black,-3.018626791,-1.461326791,-2.068936791,-0.867106791
A,Black,-3.304632403,-2.608322403,-3.463632403,-1.768972403
A,Black,-2.673500283,-2.100820283,-2.708560283,-1.507230283
A,Black,-1.700734807,-0.887104807,-1.275424807,-0.524394807
A,Black,-0.586121342,-0.848638342,-1.169118342,-0.551044342
A,Yellow,-3.136580929,-1.120380929,-1.720710929,-0.550799929
A,Yellow,-2.757574147,-1.021674147,-1.474644147,-0.600298147
A,Yellow,-2.17890461,-0.89563461,-1.34797461,-0.47309861
A,Yellow,-1.812551095,-0.920201095,-1.215711095,-0.639398095
A,Yellow,-1.054284002,-1.195239002,-1.453922002,-0.956836002
A,Green,-1.639312507,-4.174222507,-4.174222507,-4.174222507
A,Green,-1.23917727,-0.30492427,-0.68852327,-0.21611447
A,Green,-0.66966805,-1.13230605,-1.99186605,-0.49901105
A,Green,0.278895635,0.096514635,-0.301298365,0.300602935
A,Green,-0.504911532,-0.894806332,-1.378339332,-0.603663332
A,Blue,-2.969196277,-3.693096277,-3.820696277,-1.384526277
A,Blue,-2.419573959,-2.280913959,-2.894093959,-1.672893959
A,Blue,-1.773659064,-1.850719064,-2.450169064,-1.260569064
A,Blue,-1.510092543,-0.851495543,-1.439472543,-0.411152543
A,Blue,-0.595168746,-0.998596746,-1.208087746,-0.805696746
B,Black,-2.459224263,-1.757114263,-2.364714263,-1.162324263
B,Black,-1.817291831,-1.704651831,-2.557361831,-0.868041831
B,Black,-2.495591512,-2.614881512,-3.456411512,-1.789931512
B,Black,-1.216945891,-0.928095891,-1.315455891,-0.557498891
B,Black,-0.500977651,-0.518668651,-0.817970651,-0.249855651
B,Yellow,-2.473182951,-1.310892951,-1.909672951,-0.741403951
B,Yellow,-2.085555297,-0.856005297,-1.252555297,-0.489987297
B,Yellow,-2.249602851,-1.539112851,-2.010652851,-1.093110851
B,Yellow,-1.406241001,-0.872741001,-1.183891001,-0.577481001
B,Yellow,-0.953045757,-0.981668757,-1.241857757,-0.740871757
B,Green,-2.487720209,-4.310240209,-4.310240209,-4.310240209
B,Green,-2.472235352,-0.579902352,-0.963501352,-0.491092552
B,Green,-1.35388464,-0.39377464,-0.99212464,0.00267836
B,Green,-1.20222519,-0.58276419,-1.05847819,-0.30239519
B,Green,-0.155542679,-0.302979679,-0.795866679,-0.000590679
B,Blue,-2.467137219,-2.879317219,-3.541517219,-2.219037219
B,Blue,-2.093208678,-2.467378678,-3.037568678,-1.901558678
B,Blue,-1.968546702,-1.171728702,-1.881726702,-0.642598702
B,Blue,-1.067931387,-1.109401387,-1.445171387,-0.785811387
B,Blue,-0.936799562,-1.166112562,-1.361216562,-0.987562562


From DNADave at insightful.com  Wed Sep 19 02:00:35 2007
From: DNADave at insightful.com (David Henderson)
Date: Tue, 18 Sep 2007 17:00:35 -0700
Subject: [R] Microarray Workshop in Tucson, January 2008
Message-ID: <1190160035.12184.17.camel@minime.insightful.com>

This is forwarded on behalf of David Galbraith at The University of
Arizona.

For Biologists, this is an excellent way to either gain or improve your
skills in microarray techniques and gain experience in the proper
statistical analysis and experimental design of microarray experiments.
For statisticians, this is an excellent way to gain an understanding of
the procedures used in generating microarray data and possibly learn a
few new tricks for analyzing array data.


EIGHTH INTERNATIONAL LONG-OLIGONUCLEOTIDE MICROARRAY WORKSHOP

January 6-11, 2008 The University of Arizona in Tucson, Arizona

This workshop will comprise a combination of lectures and hand-on
laboratory sessions. The participants will primarily employ Arabidopsis
and maize (plant side) and human, bovine and porcine (animal side) whole
genome 70-mer oligonucleotide microarrays in their laboratory work (for
details of the arrays see http://www.cals.arizona.edu/microarray,
http://www.maizearray.org, and http://cals.arizona.edu/sus/

The workshop will be divided into two parts: Part I (Sunday 4PM to
Wednesday 5PM) will cover wet-lab aspects of microarray target
production and amplification, microarray hybridization, and scanning.
Part II (all day, Thursday and Friday) will concentrate on data
extraction, statistical analysis, and experimental design. Together
these topics are aimed at the goal of the participants obtaining optimal
results using oligonucleotide-based microarrays. Part II may be taken
separately.

Specific topics to be covered include:

* Experimental design. 
* Probe preparation and microarray printing. 
* Microarray rehydration and probe immobilization. 
* Target preparation, including RNA extraction, direct and indirect
labeling, and amplification techniques. 
* Microarray hybridization. 
* Array scanning and data extraction. 
* Data analysis and archiving. 

Registration (Part I plus Part II) is $675, which includes costs of the
microarrays and other supplies that you will use. Part II registration
only is $275. Part I participants will be limited to 30 on a first-come,
first-serve basis. Overall participation will be limited to 40
individuals.

Note: There are a number of airline connections from Tucson to San Diego
on Friday evening, allowing workshop participants convenient access to
the Plant and Animal Genome XVI Meeting (January 12-16).

For further details and to register, please contact David Galbraith
(galbraith at arizona.edu)


David W. Galbraith 
Professor of Plant Sciences 
& Professor, Bio5 Institute 
The University of Arizona 
Office: 341 Keating Building 

Mailing address: 
BIO5 Institute
The University of Arizona
1657 E. Helen St.
Tucson, AZ 85721-0240
Tel: (520) 621-9153
Fax: (520) 626-4824
Email: galbraith at arizona.edu

-- 
David A. Henderson, Ph.D. 
Research Scientist 
Insightful Corporation 
1700 Westlake Avenue North, Suite 500 
Seattle, WA 98109-3044 
Tel: 206-802-2307 
Fax: 206-283-8691 
DNADave at Insightful.Com 
http://www.insightful.com


From PAlspach at hortresearch.co.nz  Wed Sep 19 02:02:22 2007
From: PAlspach at hortresearch.co.nz (Peter Alspach)
Date: Wed, 19 Sep 2007 12:02:22 +1200
Subject: [R] xyplot question
References: <3f2154540709141537l9609dc6jae6f3fc109bf2d9e@mail.gmail.com><eb555e660709141631i1730d37bh49c6d8064736c483@mail.gmail.com><3f2154540709142229t32eaff54j34e617d4d93bba5d@mail.gmail.com><eb555e660709171201l67e71ec0u8a86bc2952300dd4@mail.gmail.com>
	<3f2154540709181552u1e5557a5y1914236138cb00e4@mail.gmail.com>
Message-ID: <1eea43e10000e862@hortresearch.co.nz>

Raymond

I had the same question a while ago and found the answer by typing

RSiteSearch('xyplot error bars')

Peter Alspach
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Raymond Balise
> Sent: Wednesday, 19 September 2007 10:52 a.m.
> To: r-help at stat.math.ethz.ch
> Subject: [R] xyplot question
> 
> I am tring to add error bars to data in an xyplot.  Below is 
> the content of a CSV file that I am trying to use and the 
> code which plots the data points and 45 degree lines in each 
> of the panes of the trellice.  I want to add error bars that 
> go up and down to the limits set by the lcl and ucl values in 
> the data set.  How the heck can I specify the error bars in a 
> lattice plot?
> 
> If anyone knows how to do this can you please tell me how to 
> do it and more importantly point me toward a book/paper that 
> explains how to do this and has examples. :~)  As always, 
> help is profoundly appreciated.
> 
> fig2 = read.xls("figure2.csv")
> 
> library(lattice)
> library(grid)
> 
> with(fig2,
>           xyplot(y ~ x |  group * Method,
>           xlab = "",
>           xlim = c(-5, 1),
>           ylab = "",
>           ylim = c(-5, 1),
>           col = "black",
>           groups = group,
>           aspect = 1,
>           lx = lcl,
>           ux = ucl,
>           pch = 16 ,
>           panel = function(x, y, ...) {
>              panel.superpose(x, y, ...)
>              panel.abline(0, 1)
> 
>          },
>          )
> )
> 
> ###### some sample data for a CSV file ############
> 
> Method,group,x,y,lcl,ucl
> A,Black,-3.018626791,-1.461326791,-2.068936791,-0.867106791
> A,Black,-3.304632403,-2.608322403,-3.463632403,-1.768972403
> A,Black,-2.673500283,-2.100820283,-2.708560283,-1.507230283
> A,Black,-1.700734807,-0.887104807,-1.275424807,-0.524394807
> A,Black,-0.586121342,-0.848638342,-1.169118342,-0.551044342
> A,Yellow,-3.136580929,-1.120380929,-1.720710929,-0.550799929
> A,Yellow,-2.757574147,-1.021674147,-1.474644147,-0.600298147
> A,Yellow,-2.17890461,-0.89563461,-1.34797461,-0.47309861
> A,Yellow,-1.812551095,-0.920201095,-1.215711095,-0.639398095
> A,Yellow,-1.054284002,-1.195239002,-1.453922002,-0.956836002
> A,Green,-1.639312507,-4.174222507,-4.174222507,-4.174222507
> A,Green,-1.23917727,-0.30492427,-0.68852327,-0.21611447
> A,Green,-0.66966805,-1.13230605,-1.99186605,-0.49901105
> A,Green,0.278895635,0.096514635,-0.301298365,0.300602935
> A,Green,-0.504911532,-0.894806332,-1.378339332,-0.603663332
> A,Blue,-2.969196277,-3.693096277,-3.820696277,-1.384526277
> A,Blue,-2.419573959,-2.280913959,-2.894093959,-1.672893959
> A,Blue,-1.773659064,-1.850719064,-2.450169064,-1.260569064
> A,Blue,-1.510092543,-0.851495543,-1.439472543,-0.411152543
> A,Blue,-0.595168746,-0.998596746,-1.208087746,-0.805696746
> B,Black,-2.459224263,-1.757114263,-2.364714263,-1.162324263
> B,Black,-1.817291831,-1.704651831,-2.557361831,-0.868041831
> B,Black,-2.495591512,-2.614881512,-3.456411512,-1.789931512
> B,Black,-1.216945891,-0.928095891,-1.315455891,-0.557498891
> B,Black,-0.500977651,-0.518668651,-0.817970651,-0.249855651
> B,Yellow,-2.473182951,-1.310892951,-1.909672951,-0.741403951
> B,Yellow,-2.085555297,-0.856005297,-1.252555297,-0.489987297
> B,Yellow,-2.249602851,-1.539112851,-2.010652851,-1.093110851
> B,Yellow,-1.406241001,-0.872741001,-1.183891001,-0.577481001
> B,Yellow,-0.953045757,-0.981668757,-1.241857757,-0.740871757
> B,Green,-2.487720209,-4.310240209,-4.310240209,-4.310240209
> B,Green,-2.472235352,-0.579902352,-0.963501352,-0.491092552
> B,Green,-1.35388464,-0.39377464,-0.99212464,0.00267836
> B,Green,-1.20222519,-0.58276419,-1.05847819,-0.30239519
> B,Green,-0.155542679,-0.302979679,-0.795866679,-0.000590679
> B,Blue,-2.467137219,-2.879317219,-3.541517219,-2.219037219
> B,Blue,-2.093208678,-2.467378678,-3.037568678,-1.901558678
> B,Blue,-1.968546702,-1.171728702,-1.881726702,-0.642598702
> B,Blue,-1.067931387,-1.109401387,-1.445171387,-0.785811387
> B,Blue,-0.936799562,-1.166112562,-1.361216562,-0.987562562
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

___________________________________________________________________
The contents of this e-mail are privileged and/or confidential to the
named recipient and are not to be used by any other person and/or
organisation. If you have received this e-mail in error, please notify
the sender and delete all material pertaining to this e-mail.


From lukasneraas at gmail.com  Wed Sep 19 02:15:26 2007
From: lukasneraas at gmail.com (Luke Neraas)
Date: Tue, 18 Sep 2007 16:15:26 -0800
Subject: [R] Create a loop to conduct multiple pairwise binary operations
Message-ID: <b634f47d0709181715r481d28e6p7461e76ea4c0f87b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070918/da37ebc5/attachment.pl 

From lukasneraas at gmail.com  Wed Sep 19 02:23:43 2007
From: lukasneraas at gmail.com (Luke Neraas)
Date: Tue, 18 Sep 2007 16:23:43 -0800
Subject: [R] Create a loop to conduct multiple pairwise binary operations
	Retry
Message-ID: <b634f47d0709181723k58b0b3e9vc0270dc5ec1221a0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070918/3aad2fc0/attachment.pl 

From doug00 at gmail.com  Wed Sep 19 02:36:14 2007
From: doug00 at gmail.com (Doug Holton)
Date: Tue, 18 Sep 2007 18:36:14 -0600
Subject: [R] recommended package/docs for analyzing multiple choice tests
In-Reply-To: <mailman.19.1190109602.23401.r-help@r-project.org>
References: <mailman.19.1190109602.23401.r-help@r-project.org>
Message-ID: <46F06EFE.5090405@gmail.com>

Hi,
  What package would you recommend for analyzing the
validity/reliability of multiple choice tests.  Doing things such as
classical test analysis, factor analysis, item response theory.

I've used psychometric (item.exam), MiscPsycho (alpha.Summary), and ltm
(rcor.test).  MiscPsycho reported the numbers most similar to what I get
in SPSS: corrected point biserial correlations, cronbach's alpha.  I
didn't understand what the psychometric package meant by its
"discrimination" and "item reliability" numbers output by the item.exam
function.  Perhaps the former is uncorrected point biserial
correlations?  They were higher values.  I downloaded and inspected
the source code for both packages.  It was hard to understand what the
functions were doing without some comments in the code.

Also, would you recommend a book or resource with examples of using R
for test analysis.

Thank you, it's been great learning R,
-Doug


From daniel.white at canterbury.ac.nz  Wed Sep 19 03:35:51 2007
From: daniel.white at canterbury.ac.nz (Daniel White)
Date: Wed, 19 Sep 2007 13:35:51 +1200
Subject: [R] R advice
Message-ID: <3AE72C6B4997BA41A845C3B8CBDEFA40015D23C2@ucexchange4.canterbury.ac.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070919/dd2b0330/attachment.pl 

From xmeng at capitalbio.com  Wed Sep 19 04:18:31 2007
From: xmeng at capitalbio.com (XinMeng)
Date: Wed, 19 Sep 2007 10:18:31 +0800
Subject: [R] about "normalized y" via covariance analysis
Message-ID: <390168311.24044@capitalbio.com>

Hello sir: 
Here's a question on covariance analysis which needs your help. 
There're 3 experiments,and x refers to control while y refers to experimental result. 
The purpose is to compare the "y" values across the 3 experiments. 
 
 experiment_1: 
 x:0.1 0.2 0.3 0.4 0.5 
 y:0.5 0.6 0.6 0.7 0.9 
 
 experiment_2: 
 x:1 2 3 4 5 
 y:3 4 6.5 7.5 11 
 
 experiment_3: 
 x:10 20 30 40 50 
 y:18 35 75 90 98 
 
Apparently,the control("x") isn't at the similar level so that we can't compare the "y" directly through ANOVA. 
We must normalize "y" via "x" in order to eliminate the influence of different level of "x". 
The method of normalize I can get is "covariance analysis",since "x" is the covariant of y. 


After this normalization,we can get the according "normalized y" of every "original y". 

All in all,the "normalized y" of every "original y" is what I want indeed. 



My question is: 
How to perform "covariance analysis" by using R in order to get "normalized y"? 

Some suggestion is:lm()
I wanna know wheter my performance is right:

fitted.values(lm(y~factor(experiment)+ x))




Thanks a lot!  
My best regards!


From Alexander.Herr at csiro.au  Wed Sep 19 04:04:10 2007
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Wed, 19 Sep 2007 12:04:10 +1000
Subject: [R] fontsize in mosaic plot lables
Message-ID: <80C7911E901E7E4797B3F88D106CB25D26320C@exqld2-bne.nexus.csiro.au>

Hi List,

I am trying unsucessfully to modify the fontsize of lables in mosaic:


require(vcd)
mosaic(Titanic, pop=FALSE,
labeling_args=list(rot_labels=c(bottom=90,top=90),
      set_varnames = c(Sex = "Gender"),
          gp_text=gpar(fontsize=20))) #can't get it to resize text

tab <- ifelse(Titanic < 6, NA, Titanic)
# it works for labeling_cells
labeling_cells(text = tab, margin =
0,gp_text=gpar(fontsize=20))(Titanic)

What am I doing wrong?

Thanx
Herry


From chainsawtiney at gmail.com  Wed Sep 19 06:33:22 2007
From: chainsawtiney at gmail.com (Chung-hong Chan)
Date: Wed, 19 Sep 2007 12:33:22 +0800
Subject: [R] recommended package/docs for analyzing multiple choice tests
In-Reply-To: <46F06EFE.5090405@gmail.com>
References: <mailman.19.1190109602.23401.r-help@r-project.org>
	<46F06EFE.5090405@gmail.com>
Message-ID: <30d7ea360709182133k5908d6a3yfaf94be10ca87343@mail.gmail.com>

Hello.

I think "Using R for psychology research" maybe useful for you.
http://www.personality-project.org/r/r.guide.html



On 9/19/07, Doug Holton <doug00 at gmail.com> wrote:
> Hi,
>   What package would you recommend for analyzing the
> validity/reliability of multiple choice tests.  Doing things such as
> classical test analysis, factor analysis, item response theory.
>
> I've used psychometric (item.exam), MiscPsycho (alpha.Summary), and ltm
> (rcor.test).  MiscPsycho reported the numbers most similar to what I get
> in SPSS: corrected point biserial correlations, cronbach's alpha.  I
> didn't understand what the psychometric package meant by its
> "discrimination" and "item reliability" numbers output by the item.exam
> function.  Perhaps the former is uncorrected point biserial
> correlations?  They were higher values.  I downloaded and inspected
> the source code for both packages.  It was hard to understand what the
> functions were doing without some comments in the code.
>
> Also, would you recommend a book or resource with examples of using R
> for test analysis.
>
> Thank you, it's been great learning R,
> -Doug
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
CH Chan
Research Assistant - KWH
http://www.macgrass.com


From chxmahappy at gmail.com  Wed Sep 19 07:07:54 2007
From: chxmahappy at gmail.com (=?GB2312?B?wu20q8/j?=)
Date: Wed, 19 Sep 2007 13:07:54 +0800
Subject: [R] Welcome to the "R-help" mailing list
In-Reply-To: <mailman.351.1190177986.4094.r-help@r-project.org>
References: <mailman.351.1190177986.4094.r-help@r-project.org>
Message-ID: <fc4f206a0709182207k63a37be7m9b62239285081315@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070919/9bdecaf7/attachment.pl 

From andreas_wittmann at gmx.de  Wed Sep 19 08:40:09 2007
From: andreas_wittmann at gmx.de (Andreas  Wittmann)
Date: Wed, 19 Sep 2007 08:40:09 +0200
Subject: [R] certain number of equations in function depending on parameter
Message-ID: <20070919064009.17170@gmx.net>

Hello everybody, 

i have the following problem to write a function which recognizes depending
on the parameter-inputs how many equations for the calculation in the function
are needed. 

Here is an example of my problem:

"myfun" <- function(a, b, c, d)
{
    k <- length(a)
    #here d = 3 for example, but how can i dynamically controll 
    #my function and tell her to build equations eq1 to eq5 if d = 5?
    
    "eq1" <- function(a, b, y)
    {
        c[k-1] <- a[k-1] + b * y
    } 
    
    "eq2" <- function(a, b, y)
    {
        c[k-2] <- a[k-2] + b * y
    }     
    
    "eq3" <- function(a, b, y)
    {
        c[k-3] <- a[k-3] + b * y
    } 
    
    "eq4" <- function(a, b, z)
    {
        1 - sum(c(eq1(z), eq2(z), eq3(z), z))
    }   
    
    sol <- uniroot(eq4, lower=0, upper=1)
}

I hope my problems is explained clear enough. I would be very happy 
if you can give me some advice.


best regards

Andreas
--


From steve at promente.org  Wed Sep 19 08:42:19 2007
From: steve at promente.org (Steve Powell)
Date: Wed, 19 Sep 2007 08:42:19 +0200
Subject: [R] Creating Hmisc labels inside a function
In-Reply-To: <46EE9A9D.8060000@vanderbilt.edu>
References: <mailman.7.1189418403.7853.r-help@stat.math.ethz.ch>
	<019801c7f452$6211ae50$6501a8c0@STEVE>
	<46E7DD9B.4020902@vanderbilt.edu>
	<01ac01c7f931$3c7d8040$6501a8c0@STEVE>
	<46EE9A9D.8060000@vanderbilt.edu>
Message-ID: <005401c7fa88$51b2d840$6501a8c0@STEVE>

Thanks again Frank for quick reply.
True, 

someobject=2
Test=function(obj,labe)
   {
   label(obj)=labe
   #at this point add the line:
   obj
   }
 Test(someobject,"somelabel") 
#returns a label. But if you retype 
someobject
#the label has gone. That is what I meant by the label not being permanently
changed.
Steve 
 
proMENTE social research 
research | evaluation | training & consulting 
Kranj?evi?eva 35, 71000 Sarajevo 
mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387 33 556 866
skype: stevepowell99 
www.promente.org  |  www.mojakarijera.com  |  www.psih.org  

-----Original Message-----
From: Frank E Harrell Jr [mailto:f.harrell at vanderbilt.edu] 
Sent: 17 September 2007 17:18
To: Steve Powell
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Creating Hmisc labels inside a function

Steve Powell wrote:
>  
> Thanks, Frank - it doesn't work though. 
> Your suggestion was:
> 
Test=function(obj,labe)
  {
  label(obj)=labe
  #at this point add the line:
  obj
  }
> #...but just returning the object does not permanently change the label:
> obj

It does for me.  Please re-run.  -Frank

 > attributes(Test(1:3, 'some label'))
$label
[1] "some label"

$class
[1] "labelled"

You don't need assign.
Frank


> 
> That is why I wanted to use assign. But "assign" will not work with 
> attributes, labels etc. So
> 
> assign(label(obj),"some label") #doesn't even work outside a function, 
> at the command prompt.
> 
> Any more ideas anyone?
> Best wishes
> Steve Powell
> 
>  
> proMENTE social research
> research | evaluation | training & consulting Kranj?evi?eva 35, 71000 
> Sarajevo
> mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387 33 556 
> 866
> skype: stevepowell99
> www.promente.org  |  www.mojakarijera.com  |  www.psih.org
> 
> -----Original Message-----
> From: Frank E Harrell Jr [mailto:f.harrell at vanderbilt.edu]
> Sent: 12 September 2007 14:38
> To: Steve Powell
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Creating Hmisc labels inside a function
> 
> Steve Powell wrote:
>> hello list members,
>> I am wanting to write a label using the Hmisc package, but inside a 
>> function. Normally I can do:
>>
>> library(Hmisc)
>> M=2
>> label(M)="lab"
>>
>> #But inside a function the "=" does not work:
>> Test=function(obj,labe)
>> {
>> label(obj)=labe
> 
> at this point add the line:
> 
> obj
> 
>> }
> 
> The returned object will have what you need.  -Frank
> 
>> Test(M,"new label")
>>
>> I usually use the "assign" function to make assignments inside 
>> functions, but assign will not work with attributes, labels etc.
>> Any ideas?
>> Thanks in advance
>>
>> Steve Powell
>>
>>  
>> proMENTE social research
>> research | evaluation | training & consulting Kranj?evi?eva 35, 71000 
>> Sarajevo
>> mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387 33 556
>> 866
>> skype: stevepowell99
>> www.promente.org  |  www.mojakarijera.com  |  www.psih.org
>>
>>
>> Checked by AVG Free Edition. 
>>
>> 17:43
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University

No virus found in this incoming message.
Checked by AVG Free Edition. 

16.09.2007
18:32
 


Checked by AVG Free Edition. 

16.09.2007
18:32
 


From steve at promente.org  Wed Sep 19 09:33:14 2007
From: steve at promente.org (Steve Powell)
Date: Wed, 19 Sep 2007 09:33:14 +0200
Subject: [R] SEM - standardized path coefficients?
Message-ID: <00a301c7fa8f$58526290$6501a8c0@STEVE>

Dear list members,
In sem, std.coef() will give me standardized coefficients from a sem model.
But is there a trick so that path.diagram can use these coefficients rather
than unstandardized ones?
Thanks
Steve Powell


From: John Fox <jfox_at_mcmaster.ca>
Date: Wed 28 Feb 2007 - 14:37:22 GMT


Dear Tim,

See ?standardized.coefficients (after loading the sem package).

Regards,
 John

John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tim Holland
> Sent: Wednesday, February 28, 2007 12:35 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] SEM - standardized path coefficients?
>
> Hello -
>
> Does anybody know how to get the SEM package in R to return
> standardized path coefficients instead of unstandardized
> ones? Does this involve changing the covariance matrix, or
> is there an argument in the SEM itself that can be changed?
>
> Thank you,
> Tim
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code. 

Steve Powell

 
proMENTE social research 
research | evaluation | training & consulting 
Kranj?evi?eva 35, 71000 Sarajevo 
mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387 33 556 866
skype: stevepowell99 
www.promente.org  |  www.mojakarijera.com  |  www.psih.org  


Checked by AVG Free Edition. 

18.09.2007
11:53
 


From alexandre.courtiol at gmail.com  Wed Sep 19 09:40:23 2007
From: alexandre.courtiol at gmail.com (Alexandre Courtiol)
Date: Wed, 19 Sep 2007 09:40:23 +0200
Subject: [R] lmer using quasibinomial family
Message-ID: <21e8590e0709190040t37dcb735j7a9e3152a95ee5a8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070919/0df38d97/attachment.pl 

From Wayne.W.Jones at shell.com  Wed Sep 19 09:50:32 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Wed, 19 Sep 2007 08:50:32 +0100
Subject: [R] xyplot question
In-Reply-To: <3f2154540709181552u1e5557a5y1914236138cb00e4@mail.gmail.com>
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B06B@wyt-s-019.europe.shell.com>

The following link is an excellent reference which gives R code for making different plots in R. 

http://addictedtor.free.fr/graphiques/thumbs.php


Is it something like this you want: 

http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=52

The code can be found to do this on the webpage. 

Regards

Wayne



-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of Raymond Balise
Sent: 18 September 2007 23:52
To: r-help at stat.math.ethz.ch
Subject: [R] xyplot question


I am tring to add error bars to data in an xyplot.  Below is the
content of a CSV file that I am trying to use and the code which plots
the data points and 45 degree lines in each of the panes of the
trellice.  I want to add error bars that go up and down to the limits
set by the lcl and ucl values in the data set.  How the heck can I
specify the error bars in a lattice plot?

If anyone knows how to do this can you please tell me how to do it and
more importantly point me toward a book/paper that explains how to do
this and has examples. :~)  As always, help is profoundly appreciated.

fig2 = read.xls("figure2.csv")

library(lattice)
library(grid)

with(fig2,
          xyplot(y ~ x |  group * Method,
          xlab = "",
          xlim = c(-5, 1),
          ylab = "",
          ylim = c(-5, 1),
          col = "black",
          groups = group,
          aspect = 1,
          lx = lcl,
          ux = ucl,
          pch = 16 ,
          panel = function(x, y, ...) {
             panel.superpose(x, y, ...)
             panel.abline(0, 1)

         },
         )
)

###### some sample data for a CSV file ############

Method,group,x,y,lcl,ucl
A,Black,-3.018626791,-1.461326791,-2.068936791,-0.867106791
A,Black,-3.304632403,-2.608322403,-3.463632403,-1.768972403
A,Black,-2.673500283,-2.100820283,-2.708560283,-1.507230283
A,Black,-1.700734807,-0.887104807,-1.275424807,-0.524394807
A,Black,-0.586121342,-0.848638342,-1.169118342,-0.551044342
A,Yellow,-3.136580929,-1.120380929,-1.720710929,-0.550799929
A,Yellow,-2.757574147,-1.021674147,-1.474644147,-0.600298147
A,Yellow,-2.17890461,-0.89563461,-1.34797461,-0.47309861
A,Yellow,-1.812551095,-0.920201095,-1.215711095,-0.639398095
A,Yellow,-1.054284002,-1.195239002,-1.453922002,-0.956836002
A,Green,-1.639312507,-4.174222507,-4.174222507,-4.174222507
A,Green,-1.23917727,-0.30492427,-0.68852327,-0.21611447
A,Green,-0.66966805,-1.13230605,-1.99186605,-0.49901105
A,Green,0.278895635,0.096514635,-0.301298365,0.300602935
A,Green,-0.504911532,-0.894806332,-1.378339332,-0.603663332
A,Blue,-2.969196277,-3.693096277,-3.820696277,-1.384526277
A,Blue,-2.419573959,-2.280913959,-2.894093959,-1.672893959
A,Blue,-1.773659064,-1.850719064,-2.450169064,-1.260569064
A,Blue,-1.510092543,-0.851495543,-1.439472543,-0.411152543
A,Blue,-0.595168746,-0.998596746,-1.208087746,-0.805696746
B,Black,-2.459224263,-1.757114263,-2.364714263,-1.162324263
B,Black,-1.817291831,-1.704651831,-2.557361831,-0.868041831
B,Black,-2.495591512,-2.614881512,-3.456411512,-1.789931512
B,Black,-1.216945891,-0.928095891,-1.315455891,-0.557498891
B,Black,-0.500977651,-0.518668651,-0.817970651,-0.249855651
B,Yellow,-2.473182951,-1.310892951,-1.909672951,-0.741403951
B,Yellow,-2.085555297,-0.856005297,-1.252555297,-0.489987297
B,Yellow,-2.249602851,-1.539112851,-2.010652851,-1.093110851
B,Yellow,-1.406241001,-0.872741001,-1.183891001,-0.577481001
B,Yellow,-0.953045757,-0.981668757,-1.241857757,-0.740871757
B,Green,-2.487720209,-4.310240209,-4.310240209,-4.310240209
B,Green,-2.472235352,-0.579902352,-0.963501352,-0.491092552
B,Green,-1.35388464,-0.39377464,-0.99212464,0.00267836
B,Green,-1.20222519,-0.58276419,-1.05847819,-0.30239519
B,Green,-0.155542679,-0.302979679,-0.795866679,-0.000590679
B,Blue,-2.467137219,-2.879317219,-3.541517219,-2.219037219
B,Blue,-2.093208678,-2.467378678,-3.037568678,-1.901558678
B,Blue,-1.968546702,-1.171728702,-1.881726702,-0.642598702
B,Blue,-1.067931387,-1.109401387,-1.445171387,-0.785811387
B,Blue,-0.936799562,-1.166112562,-1.361216562,-0.987562562

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dimitris.rizopoulos at med.kuleuven.be  Wed Sep 19 09:52:12 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 19 Sep 2007 09:52:12 +0200
Subject: [R] recommended package/docs for analyzing multiple choice tests
References: <mailman.19.1190109602.23401.r-help@r-project.org>
	<46F06EFE.5090405@gmail.com>
Message-ID: <006b01c7fa91$fce2ea80$0540210a@www.domain>

In ltm (version 0.8-1) you may also check the following functions: 
descript(), cronbach.alpha(), mult.choice()

I hope it helps.

Best,
Dimitris

ps, you may find more information about `ltm' as well as sample 
analysis files at the Rwiki page: 
http://wiki.r-project.org/rwiki/doku.php?id=packages:cran:ltm

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Doug Holton" <doug00 at gmail.com>
To: <r-help at r-project.org>
Sent: Wednesday, September 19, 2007 2:36 AM
Subject: [R] recommended package/docs for analyzing multiple choice 
tests


> Hi,
>  What package would you recommend for analyzing the
> validity/reliability of multiple choice tests.  Doing things such as
> classical test analysis, factor analysis, item response theory.
>
> I've used psychometric (item.exam), MiscPsycho (alpha.Summary), and 
> ltm
> (rcor.test).  MiscPsycho reported the numbers most similar to what I 
> get
> in SPSS: corrected point biserial correlations, cronbach's alpha.  I
> didn't understand what the psychometric package meant by its
> "discrimination" and "item reliability" numbers output by the 
> item.exam
> function.  Perhaps the former is uncorrected point biserial
> correlations?  They were higher values.  I downloaded and inspected
> the source code for both packages.  It was hard to understand what 
> the
> functions were doing without some comments in the code.
>
> Also, would you recommend a book or resource with examples of using 
> R
> for test analysis.
>
> Thank you, it's been great learning R,
> -Doug
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From Nikolaus.Umlauf at student.uibk.ac.at  Wed Sep 19 11:04:49 2007
From: Nikolaus.Umlauf at student.uibk.ac.at (Nikolaus Umlauf)
Date: Wed, 19 Sep 2007 11:04:49 +0200
Subject: [R] independent plotting of predicted terms with gamlss
Message-ID: <1190192689.46f0e6315de40@web-mail2.uibk.ac.at>

Hi!

I want to create a plot of a predicted term similar to the function term.plot()
in the gamlss package. I have tried several options, but I could not work it
out so far...

Thank you for your help!

Nikolaus

here is my example:

library(gamlss)
data(rent)
attach(rent)

# Estimating some model
rent.model <- gamlss(R ~ ps(Fl)+ps(A)+Sp+Sm, family="NO")
summary(rent.model)

# Predicting the values for term A
A_pred <- predict(rent.model, type="terms", what="mu", terms=2, se.fit=TRUE)

# Calculating only the fitted values without se.fit
fitted_A <- A_pred$fit

# This is my problem: I want to plot the fitted smooth function without using
the R function term.plot(), but the function lines() computes an unuseful
graph...
plot(A, fitted_A, type="n")
lines(A, fitted_A)

# I want to create a plot like term.plot() does
term.plot(rent.model, terms=2, se=TRUE)


From j.daebritz at freenet.de  Wed Sep 19 11:21:55 2007
From: j.daebritz at freenet.de (=?iso-8859-1?Q?J._D=E4britz?=)
Date: Wed, 19 Sep 2007 11:21:55 +0200
Subject: [R] x and y coordinates (Rfwdmv Package)
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAA2Ly7qOCtUU+NBIwPDIDbDcKAAAAQAAAA25G5bKtPmkygJVz0j5lJzgEAAAAA@freenet.de>

Hello R users,

before asking my question I'd like to stress that I'm an (absolute)
beginner in using R, but enthused about the incredible possibilities of
it.
So I hope my questions are not too stupid.

Here's my problem:

I have a dataset with skewed distributions. In order to obtain approx
multivariate normality by a Box-Cox-Transformation, I used the "Rfwdmv
Package" to estimate a common value of lambda for all the variables.

Therefore I entered the following R commands:
data(my.dat)
l.mle <- fwdtr(my.dat, lambda = 1/3, one.lambda = TRUE)
l.profile.mle <- profile.fwdtr(l.mle)
fwdtrProfilePlot(l.profile.mle)
fwdtrMlePlot(l.mle).

Everything worked well so far and I obtained the plots in question.

The problem is: In these plots I just can see that lambda is roughly
around 1.4, but it could be 1.35 or 1.45 or somewhat in between. The
same problem occurs with the log-likelihoods and the confidence
intervals.

Now my question is:

Is there a possibility obtaining the EXACT log-likelihoods, confidence
intervals and, first of all, lambda values ?

Or more general: How can I obtain the x (or y) value for a specific
(e.g. maximum) y (or x) of a plot in R ?

I would be very grateful if one could give me a lead.

Thank you very much in advance.

With best regards,

Juergen


From gigis.mail at freenet.de  Wed Sep 19 11:30:00 2007
From: gigis.mail at freenet.de (gigis.mail at freenet.de)
Date: Wed, 19 Sep 2007 11:30:00 +0200
Subject: [R] x and y coordinates (Rfwdmv Package)
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAA2Ly7qOCtUU+NBIwPDIDbDcKAAAAQAAAAo+ULx0rDikmdwdKEGx5fagEAAAAA@freenet.de>

Hello R users,

before asking my question I'd like to stress that I'm an (absolute)
beginner in using R, but enthused about the incredible possibilities of
it.
So I hope my questions are not too stupid.

Here's my problem:

I have a dataset with skewed distributions. In order to obtain approx
multivariate normality by a Box-Cox-Transformation, I used the "Rfwdmv
Package" to estimate a common value of lambda for all the variables.

Therefore I entered the following R commands:
data(my.dat)
l.mle <- fwdtr(my.dat, lambda = 1/3, one.lambda = TRUE)
l.profile.mle <- profile.fwdtr(l.mle)
fwdtrProfilePlot(l.profile.mle)
fwdtrMlePlot(l.mle).

Everything worked well so far and I obtained the plots in question.

The problem is: In these plots I just can see that lambda is roughly
around 1.4, but it could be 1.35 or 1.45 or somewhat in between. The
same problem occurs with the log-likelihoods and the confidence
intervals.

Now my question is:

Is there a possibility obtaining the EXACT log-likelihoods, confidence
intervals and, first of all, lambda values ?

Or more general: How can I obtain the x (or y) value for a specific
(e.g. maximum) y (or x) of a plot in R ?

I would be very grateful if one could give me a lead.

Thank you very much in advance.

With best regards,

Juergen


From ligges at statistik.uni-dortmund.de  Wed Sep 19 11:59:03 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 19 Sep 2007 11:59:03 +0200
Subject: [R] handling multiple files; was:  R advice
In-Reply-To: <3AE72C6B4997BA41A845C3B8CBDEFA40015D23C2@ucexchange4.canterbury.ac.nz>
References: <3AE72C6B4997BA41A845C3B8CBDEFA40015D23C2@ucexchange4.canterbury.ac.nz>
Message-ID: <46F0F2E7.3080007@statistik.uni-dortmund.de>

Handling multiple files automatically is easy in R and has been answered 
several times on this list: please pok up the archives as suggested in 
the posting guide to this list which also asks you to use a sensible 
subject line.
Additionally, there is a FAQ entry called "How can I save the result of 
each iteration in a loop into a separate file?". I am sure you can adapt 
it to read files as well.

Uwe Ligges



Daniel White wrote:
>  
> 
> Dear R-help
> 
>  
> 
> As a novice to R I was seeking some advice with respect to using R to
> help solve a problem I have. 
> 
> I have a large number of infiles that need analysed. This can be done, I
> believe, using 2 separate R packages (popgen and ape) with the output
> from 'popgen' being used as input for 'ape'. What I would like to know
> is whether it is possible within R to write some script so that these
> files can be read from a folder outside the R space (say a folder within
> the C drive of my computer) and processed without having to re-initiate
> each individual infile?
> 
> If this is possible I would then work on the problem of trying to link
> the output from the first package with the second.
> 
>  
> 
> Many thanks for any advice given here.
> 
>  
> 
> Dan White 
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sabya231 at gmail.com  Wed Sep 19 12:17:50 2007
From: sabya231 at gmail.com (Tirthadeep)
Date: Wed, 19 Sep 2007 03:17:50 -0700 (PDT)
Subject: [R] glmpath error
Message-ID: <12774607.post@talk.nabble.com>



Hi,

I am using glampath package for L1 regularized logistic regression. I got
the following error messege.

> model.fit <- glmpath(train.data[,1:20], train.data$RES, family=binomial)
Error in one %*% x : requires numeric matrix/vector arguments

where train.data is a 700X21 matrix and 21st column in response (RES).

Please clarify!!!

Thanks
-- 
View this message in context: http://www.nabble.com/glmpath-error-tf4480056.html#a12774607
Sent from the R help mailing list archive at Nabble.com.


From murdoch at stats.uwo.ca  Wed Sep 19 12:29:33 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 19 Sep 2007 06:29:33 -0400
Subject: [R] glmpath error
In-Reply-To: <12774607.post@talk.nabble.com>
References: <12774607.post@talk.nabble.com>
Message-ID: <46F0FA0D.4050207@stats.uwo.ca>

Tirthadeep wrote:
> Hi,
>
> I am using glampath package for L1 regularized logistic regression. I got
> the following error messege.
>
>   
>> model.fit <- glmpath(train.data[,1:20], train.data$RES, family=binomial)
>>     
> Error in one %*% x : requires numeric matrix/vector arguments
>
> where train.data is a 700X21 matrix and 21st column in response (RES).
>   
If it is a matrix, then train.data$RES won't work.  That column 
selection method only works for data frames,
because they are lists, and matrices aren't.

Duncan Murdoch
> Please clarify!!!
>
> Thanks
>


From mdgi at gmx.ch  Wed Sep 19 12:53:49 2007
From: mdgi at gmx.ch (marcg)
Date: Wed, 19 Sep 2007 12:53:49 +0200
Subject: [R] (no subject)
In-Reply-To: <21e8590e0709190040t37dcb735j7a9e3152a95ee5a8@mail.gmail.com>
References: <21e8590e0709190040t37dcb735j7a9e3152a95ee5a8@mail.gmail.com>
Message-ID: <20070919105349.310350@gmx.net>

Dear all

I try to print 9 plots on a page, arranged as the code shows below.

nf <- layout(matrix(c(1,0,2,0,0,3,0,4,0,5,0,6,0,0,0,0,7,0,8,9), 10,2))
layout.show(nf)

but when I try to plot, an error message 
Fehler in plot.new() : Grafikr?nder zu gro?
appears

to verify p.e. with 

plot(runif(10:1)) 

i tried with plot(runif(10:1), ann=F) to produce more space, but neither.

The second question: how to place a cross in the middle of the plot to delineate in 4 big fields (containing each 5 plots)

Thanks a lot


--


From karin.lagesen at medisin.uio.no  Wed Sep 19 13:16:54 2007
From: karin.lagesen at medisin.uio.no (Karin Lagesen)
Date: Wed, 19 Sep 2007 13:16:54 +0200
Subject: [R] function on factors - how best to proceed
Message-ID: <ypx67immkiqh.fsf@uracil.uio.no>


Sorry about this one being long, and I apologise beforehand if there
is something obvious here that I have missed. I am new to creating my
own functions in R, and I am uncertain of how they work.

I have a data set that I have read into a data frame:

> gctable[1:5,]
     refseq geometry X60_origin X60_terminus  length  kingdom
1 NC_009484      cir    1790000       773000 3389227 Bacteria
2 NC_009484      cir    1790000       773000 3389227 Bacteria
3 NC_009484      cir    1790000       773000 3389227 Bacteria
4 NC_009484      cir    1790000       773000 3389227 Bacteria
5 NC_009484      cir    1790000       773000 3389227 Bacteria
                  grp feature gene begin dir gc_content replicor LEADLAG
1 Alphaproteobacteria     CDS  CDS   261   +   0.654244    RIGHT    LEAD
2 Alphaproteobacteria     CDS  CDS  1737   -   0.651408    RIGHT     LAG
3 Alphaproteobacteria     CDS  CDS  2902   +   0.607843    RIGHT    LEAD
4 Alphaproteobacteria     CDS  CDS  3693   +   0.617647    RIGHT    LEAD
5 Alphaproteobacteria     CDS  CDS  4227   +   0.699208    RIGHT    LEAD
> 

Most of these columns are factors.

Now, I have a function that I would like to employ on this data
frame. Right now I cannot get it to work, and that seems to be due to
the columns in the data frame being factors. I tested it with a data
frame created from vectors, and it worked fine.

The function:

percentdistance <- function(origin, terminus, length, begin, replicor){
print(c(origin, terminus, length, begin, repl))
d = 0
if (terminus>origin) {
  if(replicor=="LEFT") {
    d = -((origin-begin)%%length)
  }
else {
    d = (begin-origin)
  }
}
else {
  if (replicor=="LEFT") {
    d=(origin-begin)
  }
  else{
    d = -((begin-origin)%%length)
  }
}
d/length*2
}

The error I get:
> percentdistance(gctable$X60_origin, gctable$X60_terminus, gctable$length, gctable$begin, gctable$replicor)
    [1]  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87
   [19]  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87
   [37]  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87
   [55]  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87
   [73]  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87
   [91]  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87
  [109]  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87
  [127]  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87
.....[99919]   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2
[99937]   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2
[99955]   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2
[99973]   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2
[99991]   2   2   2   2   2   2   2   2   2
 [ reached getOption("max.print") -- omitted 8526091 entries ]]
Error in if (terminus > origin) { : missing value where TRUE/FALSE needed
In addition: Warning messages:
1: > not meaningful for factors in: Ops.factor(terminus, origin) 
2: the condition has length > 1 and only the first element will be used in: if (terminus > origin) { 
> 

This worked nice when the input were columns from a data frame created
from vectors.

I have also tried the different apply-functions, although I am
uncertain of which one would be appropriate here.


I would like to use this function to create a new data frame which
would look something like this:

new_frame = (gctable$feature, gctable$gene, gctable$kingdom, gctable$grp, gctable$gc_content, percentdistance(gctable))

I am uncertain of how to proceed. Should I deconstruct the data frame
within the function, or should I get just the numbers out of the
factors and input that into the function? Or is my solution way off
from how things are done in R?

Thankyou very much for your help!

Karin
-- 
Karin Lagesen, PhD student
karin.lagesen at medisin.uio.no
http://folk.uio.no/karinlag


From mdgi at gmx.ch  Wed Sep 19 13:26:29 2007
From: mdgi at gmx.ch (marcg)
Date: Wed, 19 Sep 2007 13:26:29 +0200
Subject: [R] layout function for several plots
Message-ID: <20070919112629.215180@gmx.net>

Dear all

I try to print 9 plots on a page, arranged as the code shows below.

nf <- layout(matrix(c(1,0,2,0,0,3,0,4,0,5,0,6,0,0,0,0,7,0,8,9), 10,2))
layout.show(nf)

but when I try to plot, an error message 
Fehler in plot.new() : Grafikr?nder zu gro?
appears

to verify p.e. with 

plot(runif(10:1)) 

i tried with plot(runif(10:1), ann=F) to produce more space, but neither.

The second question: how to place a cross in the middle of the plot to delineate in 4 big fields (containing each 5 plots)

Thanks a lot


--

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

--


From kemp.samuel at googlemail.com  Wed Sep 19 13:35:11 2007
From: kemp.samuel at googlemail.com (Samuel Kemp)
Date: Wed, 19 Sep 2007 12:35:11 +0100
Subject: [R] Running tcltk From a batch file
Message-ID: <3a5596550709190435i32e13b0ch915c736c0f76af31@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070919/2ec23e77/attachment.pl 

From sabya231 at gmail.com  Wed Sep 19 13:46:20 2007
From: sabya231 at gmail.com (Tirthadeep)
Date: Wed, 19 Sep 2007 04:46:20 -0700 (PDT)
Subject: [R] glmpath error
In-Reply-To: <46F0FA0D.4050207@stats.uwo.ca>
References: <12774607.post@talk.nabble.com> <46F0FA0D.4050207@stats.uwo.ca>
Message-ID: <12775820.post@talk.nabble.com>


Then what is the solution?




Duncan Murdoch-2 wrote:
> 
> Tirthadeep wrote:
>> Hi,
>>
>> I am using glampath package for L1 regularized logistic regression. I got
>> the following error messege.
>>
>>   
>>> model.fit <- glmpath(train.data[,1:20], train.data$RES, family=binomial)
>>>     
>> Error in one %*% x : requires numeric matrix/vector arguments
>>
>> where train.data is a 700X21 matrix and 21st column in response (RES).
>>   
> If it is a matrix, then train.data$RES won't work.  That column 
> selection method only works for data frames,
> because they are lists, and matrices aren't.
> 
> Duncan Murdoch
>> Please clarify!!!
>>
>> Thanks
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/glmpath-error-tf4480056.html#a12775820
Sent from the R help mailing list archive at Nabble.com.


From arin.basu at gmail.com  Wed Sep 19 13:48:54 2007
From: arin.basu at gmail.com (Arin Basu)
Date: Wed, 19 Sep 2007 17:18:54 +0530
Subject: [R] CRAN mirror for R in India: new one at WBUT,
	how do we get listed in the CRAN website?
Message-ID: <af62876a0709190448n73545a1fh64e4b4e2004788a2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070919/cd29d504/attachment.pl 

From jfox at mcmaster.ca  Wed Sep 19 13:55:06 2007
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 19 Sep 2007 07:55:06 -0400
Subject: [R] SEM - standardized path coefficients?
In-Reply-To: <00a301c7fa8f$58526290$6501a8c0@STEVE>
Message-ID: <20070919115507.BKEI8273.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Steve,

My intention was to provide this flexibility via the parameters argument to
path.diagram.sem(), but it isn't implemented. Here's a version that should
do what you want:

----------------- snip ----------------

path.diagram.sem <- function (model, out.file, min.rank = NULL, max.rank =
NULL, 
    same.rank = NULL, variables = model$var.names, parameters, 
    ignore.double = TRUE, edge.labels = c("names", "values"), 
    size = c(8, 8), node.font = c("Helvetica", 14), edge.font =
c("Helvetica", 
        10), rank.direction = c("LR", "TB"), digits = 2, ...) 
{
    if (!missing(out.file)) {
        handle <- file(out.file, "w")
        on.exit(close(handle))
    }
    else handle <- stdout()
    edge.labels <- match.arg(edge.labels)
    rank.direction <- match.arg(rank.direction)
    cat(file = handle, paste("digraph \"", deparse(substitute(model)), 
        "\" {\n", sep = ""))
    cat(file = handle, paste("  rankdir=", rank.direction, ";\n", 
        sep = ""))
    cat(file = handle, paste("  size=\"", size[1], ",", size[2], 
        "\";\n", sep = ""))
    cat(file = handle, paste("  node [fontname=\"", node.font[1], 
        "\" fontsize=", node.font[2], " shape=box];\n", sep = ""))
    cat(file = handle, paste("  edge [fontname=\"", edge.font[1], 
        "\" fontsize=", edge.font[2], "];\n", sep = ""))
    cat(file = handle, "  center=1;\n")
    if (!is.null(min.rank)) {
        min.rank <- paste("\"", min.rank, "\"", sep = "")
        min.rank <- gsub(",", "\" \"", gsub(" ", "", min.rank))
        cat(file = handle, paste("  {rank=min ", min.rank, "}\n", 
            sep = ""))
    }
    if (!is.null(max.rank)) {
        max.rank <- paste("\"", max.rank, "\"", sep = "")
        max.rank <- gsub(",", "\" \"", gsub(" ", "", max.rank))
        cat(file = handle, paste("  {rank=max ", max.rank, "}\n", 
            sep = ""))
    }
    if (!is.null(same.rank)) {
        for (s in 1:length(same.rank)) {
            same <- paste("\"", same.rank[s], "\"", sep = "")
            same <- gsub(",", "\" \"", gsub(" ", "", same))
            cat(file = handle, paste("  {rank=same ", same, "}\n", 
                sep = ""))
        }
    }
    latent <- variables[-(1:model$n)]
    for (lat in latent) {
        cat(file = handle, paste("  \"", lat, "\" [shape=ellipse]\n", 
            sep = ""))
    }
    ram <- model$ram
    ram[names(model$coeff), 5] <- model$coeff
    rownames(ram)[model$fixed] <- ram[model$fixed, 5]
    names <- rownames(ram)
    values <- round(ram[, 5], digits)
    heads <- ram[, 1]
    to <- ram[, 2]
    from <- ram[, 3]
    labels <- if (!missing(parameters)){ 
            if (is.numeric(parameters)) round(parameters, digits) 
                else parameters
            }
        else if (edge.labels == "names") names
        else values
    direction <- ifelse((heads == 2), " dir=both", "")
    for (par in 1:nrow(ram)) {
        if ((!ignore.double) || (heads[par] == 1)) 
            cat(file = handle, paste("  \"", variables[from[par]], 
                "\" -> \"", variables[to[par]], "\" [label=\"", 
                labels[par], "\"", direction[par], "];\n", sep = ""))
    }
    cat(file = handle, "}\n")
}

----------------- snip ----------------

E.g., continuing the example in ?path.diagram,

path.diagram(sem.dhp, min.rank='RIQ, RSES, RParAsp, FParAsp, FSES, FIQ', 
    max.rank='ROccAsp, REdAsp, FEdAsp, FOccAsp', 
    parameters=standardized.coefficients(sem.dhp)$"Std. Estimate")

I'll put the updated path.diagram.sem() in the sem package when I have a
chance.

I hope this helps,
 John

--------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: Steve Powell [mailto:steve at promente.org] 
> Sent: Wednesday, September 19, 2007 3:33 AM
> To: r-help at stat.math.ethz.ch
> Cc: jfox at mcmaster.ca
> Subject: Re: [R] SEM - standardized path coefficients?
> 
> Dear list members,
> In sem, std.coef() will give me standardized coefficients 
> from a sem model.
> But is there a trick so that path.diagram can use these 
> coefficients rather than unstandardized ones?
> Thanks
> Steve Powell
> 
> 
> From: John Fox <jfox_at_mcmaster.ca>
> Date: Wed 28 Feb 2007 - 14:37:22 GMT
> 
> 
> Dear Tim,
> 
> See ?standardized.coefficients (after loading the sem package).
> 
> Regards,
>  John
> 
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> 905-525-9140x23604
> http://socserv.mcmaster.ca/jfox
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tim Holland
> > Sent: Wednesday, February 28, 2007 12:35 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] SEM - standardized path coefficients?
> >
> > Hello -
> >
> > Does anybody know how to get the SEM package in R to return 
> > standardized path coefficients instead of unstandardized ones? Does 
> > this involve changing the covariance matrix, or is there an 
> argument 
> > in the SEM itself that can be changed?
> >
> > Thank you,
> > Tim
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code. 
> 
> Steve Powell
> 
>  
> proMENTE social research
> research | evaluation | training & consulting Kranj?evi?eva 
> 35, 71000 Sarajevo
> mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387 
> 33 556 866
> skype: stevepowell99
> www.promente.org  |  www.mojakarijera.com  |  www.psih.org  
> 
> No virus found in this outgoing message.
> Checked by AVG Free Edition. 
> Version: 7.5.487 / Virus Database: 269.13.22/1015 - Release 
> Date: 18.09.2007
> 11:53
>  
> 
> 


From wl2776 at gmail.com  Wed Sep 19 14:00:41 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Wed, 19 Sep 2007 05:00:41 -0700 (PDT)
Subject: [R] CRAN mirror for R in India: new one at WBUT,
 how do we get listed in the CRAN website?
In-Reply-To: <af62876a0709190448n73545a1fh64e4b4e2004788a2@mail.gmail.com>
References: <af62876a0709190448n73545a1fh64e4b4e2004788a2@mail.gmail.com>
Message-ID: <12776013.post@talk.nabble.com>


http://cran.r-project.org/mirror-howto.html


Arin Basu-3 wrote:
> 
> Dear All,
> 
> Folks at the West Bengal University of Technology has set up a mirror to
> distribute R and associated packages. Here is the URL:
> 
> http://mirror.wbut.ac.in/CRAN
> 
> This will be helpful for R users in South Asia and the adjoining
> countries.
> I have yet to see the site featured in the CRAN list of mirrors. What
> needs
> to be done? For those of you who are impatient and would like to give it a
> try before CRAN folks link to it, here are the details sent to me by
> Indranil Dasgupta, the maintainer of the WBUT mirror site:
> 
> The CRAN mirror's details are as follows:
> 
> 1. URL : http://mirror.wbut.ac.in/CRAN
> 2. HOSTING INSTITUTION : West Bengal University of Technology
> 3. COUNTRY : INDIA
> 4. CITY : KOLKATA (old name - Calcutta, IATA Identifier code - CCU)
> 5. CONTACT EMAIL : indradg at l2c2.co.in
> 6. UPDATE FREQUENCY : At 1 AM IST (+0530 GMT) every day.
> 
> Enjoy!
> 
> Best,
> Arin Basu
> 
> 

-- 
View this message in context: http://www.nabble.com/CRAN-mirror-for-R-in-India%3A-new-one-at-WBUT%2C-how-do-we-get-listed-in-the-CRAN-website--tf4480498.html#a12776013
Sent from the R help mailing list archive at Nabble.com.


From gustaf.rydevik at gmail.com  Wed Sep 19 14:43:22 2007
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Wed, 19 Sep 2007 14:43:22 +0200
Subject: [R] function on factors - how best to proceed
In-Reply-To: <ypx67immkiqh.fsf@uracil.uio.no>
References: <ypx67immkiqh.fsf@uracil.uio.no>
Message-ID: <45f568c70709190543s5c501995x3f2d6a654e3fa370@mail.gmail.com>

On 9/19/07, Karin Lagesen <karin.lagesen at medisin.uio.no> wrote:
>
> Sorry about this one being long, and I apologise beforehand if there
> is something obvious here that I have missed. I am new to creating my
> own functions in R, and I am uncertain of how they work.
>
> I have a data set that I have read into a data frame:
>
> > gctable[1:5,]
>      refseq geometry X60_origin X60_terminus  length  kingdom
> 1 NC_009484      cir    1790000       773000 3389227 Bacteria
> 2 NC_009484      cir    1790000       773000 3389227 Bacteria
> 3 NC_009484      cir    1790000       773000 3389227 Bacteria
> 4 NC_009484      cir    1790000       773000 3389227 Bacteria
> 5 NC_009484      cir    1790000       773000 3389227 Bacteria
>                   grp feature gene begin dir gc_content replicor LEADLAG
> 1 Alphaproteobacteria     CDS  CDS   261   +   0.654244    RIGHT    LEAD
> 2 Alphaproteobacteria     CDS  CDS  1737   -   0.651408    RIGHT     LAG
> 3 Alphaproteobacteria     CDS  CDS  2902   +   0.607843    RIGHT    LEAD
> 4 Alphaproteobacteria     CDS  CDS  3693   +   0.617647    RIGHT    LEAD
> 5 Alphaproteobacteria     CDS  CDS  4227   +   0.699208    RIGHT    LEAD
> >
>
> Most of these columns are factors.
>
> Now, I have a function that I would like to employ on this data
> frame. Right now I cannot get it to work, and that seems to be due to
> the columns in the data frame being factors. I tested it with a data
> frame created from vectors, and it worked fine.
>
> The function:
>
> percentdistance <- function(origin, terminus, length, begin, replicor){
> print(c(origin, terminus, length, begin, repl))
> d = 0
> if (terminus>origin) {
>   if(replicor=="LEFT") {
>     d = -((origin-begin)%%length)
>   }
> else {
>     d = (begin-origin)
>   }
> }
> else {
>   if (replicor=="LEFT") {
>     d=(origin-begin)
>   }
>   else{
>     d = -((begin-origin)%%length)
>   }
> }
> d/length*2
> }
>
> The error I get:
> > percentdistance(gctable$X60_origin, gctable$X60_terminus, gctable$length, gctable$begin, gctable$replicor)
>     [1]  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87
>    [19]  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87
>    [37]  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87
>    [55]  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87
>    [73]  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87
>    [91]  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87
>   [109]  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87
>   [127]  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87  87
> .....[99919]   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2
> [99937]   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2
> [99955]   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2
> [99973]   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2
> [99991]   2   2   2   2   2   2   2   2   2
>  [ reached getOption("max.print") -- omitted 8526091 entries ]]
> Error in if (terminus > origin) { : missing value where TRUE/FALSE needed
> In addition: Warning messages:
> 1: > not meaningful for factors in: Ops.factor(terminus, origin)
> 2: the condition has length > 1 and only the first element will be used in: if (terminus > origin) {
> >
>
> This worked nice when the input were columns from a data frame created
> from vectors.
>
> I have also tried the different apply-functions, although I am
> uncertain of which one would be appropriate here.
>
>
...
>
> Karin
> --
> Karin Lagesen, PhD student
> karin.lagesen at medisin.uio.no
> http://folk.uio.no/karinlag


Hej Karin!

A couple of things:
First, the first warning message tells you that:
1: > not meaningful for factors in: Ops.factor(terminus, origin).

Thus, terminus and origin are factor variables, which cannot be
ordered. You have to convert
them to numerical variables (See the faq for HowTo)

The second warning message tells you that:
 2: the condition has length > 1 and only the first element will be
used in: if (terminus > origin)

You are comparing two vectors,  which generate a vector of TRUE/FALSE values.
The "if" statement need a single TRUE/FALSE value.
Either use a for loop:
for (i in 1:nrow(terminus)) {if terminus[i]> origin[i]...}
or a nested ifelse statement (which is recommendable on such a big data set).


best,

Gustaf


-- 
Gustaf Rydevik, M.Sci.
tel: +46(0)703 051 451
address:Essingetorget 40,112 66 Stockholm, SE
skype:gustaf_rydevik


From gustaf.rydevik at gmail.com  Wed Sep 19 15:04:05 2007
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Wed, 19 Sep 2007 15:04:05 +0200
Subject: [R] function on factors - how best to proceed
In-Reply-To: <ypx63axakegp.fsf@uracil.uio.no>
References: <ypx67immkiqh.fsf@uracil.uio.no>
	<45f568c70709190543s5c501995x3f2d6a654e3fa370@mail.gmail.com>
	<ypx63axakegp.fsf@uracil.uio.no>
Message-ID: <45f568c70709190604t6e0f8803tf684041c4934c426@mail.gmail.com>

On 9/19/07, Karin Lagesen <karin.lagesen at medisin.uio.no> wrote:
> "Gustaf Rydevik" <gustaf.rydevik at gmail.com> writes:
>
>
> > The second warning message tells you that:
> >  2: the condition has length > 1 and only the first element will be
> > used in: if (terminus > origin)
> >
> > You are comparing two vectors,  which generate a vector of TRUE/FALSE values.
> > The "if" statement need a single TRUE/FALSE value.
> > Either use a for loop:
> > for (i in 1:nrow(terminus)) {if terminus[i]> origin[i]...}
> > or a nested ifelse statement (which is recommendable on such a big data set).
>
> Thankyou for your reply! I will certainly try the numeric thing.
>
> Now, for the vector comparison. I can easily see how you would do a
> for loop here, but I am unable to see how a nested ifelse statement
> would work. Could you possibly give me an example?
>
> Thankyou again for your help!
>
> Karin
> --
> Karin Lagesen, PhD student
> karin.lagesen at medisin.uio.no
> http://folk.uio.no/karinlag
>

You replace each instance of "if" with ifelse, inserting a comma after
the logical test, and instead of the else statement.  The end result
would become (if I've not made a mistake):

_____
replicator<-rep(c("LEFT","RIGHT"),50)
terminus<-rnorm(100)
origin<-rnorm(100)
begin<-rnorm(100)
length<-sample(1:100,100,replace=T)

d<-ifelse(terminus>origin,
	+ifelse(replicator=="LEFT",-((origin-begin))%%length),(begin-origin)),
	+ifelse(replicator=="LEFT",(origin-begin),-((begin-origin)%%length))
	+)

/Gustaf


-- 
Gustaf Rydevik, M.Sci.
tel: +46(0)703 051 451
address:Essingetorget 40,112 66 Stockholm, SE
skype:gustaf_rydevik


From rmason at esd.mun.ca  Wed Sep 19 15:03:25 2007
From: rmason at esd.mun.ca (Roger Mason)
Date: Wed, 19 Sep 2007 10:33:25 -0230
Subject: [R] apply
Message-ID: <y65ps0ex0wy.fsf@minnie.esd.mun.ca>

Hello,

I have a list of filenames extracted from a data-frame thus:

files <- main$file

e.g. file[[1]] returns 

[1] Ca00Mn48_0.gout
4702 Levels: Ca00Mn48_0.gout Ca01Mn47_0.gout Ca01Mn47_1.gout
... Ca48Mn00_0.gout

I want to extract the substring that contains the two digits after
"Ca".  This works on individual entries, e.g. substr(files[[1]],3,4)
returns "00".

I wish to apply substr() to all the entries in files.  All my efforts
fail.  Could some kind soul explain how to do what I want?

Thanks,

Roger Mason


From f.harrell at vanderbilt.edu  Wed Sep 19 15:08:00 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Wed, 19 Sep 2007 08:08:00 -0500
Subject: [R] Creating Hmisc labels inside a function
In-Reply-To: <005401c7fa88$51b2d840$6501a8c0@STEVE>
References: <mailman.7.1189418403.7853.r-help@stat.math.ethz.ch>
	<019801c7f452$6211ae50$6501a8c0@STEVE>
	<46E7DD9B.4020902@vanderbilt.edu>
	<01ac01c7f931$3c7d8040$6501a8c0@STEVE>
	<46EE9A9D.8060000@vanderbilt.edu>
	<005401c7fa88$51b2d840$6501a8c0@STEVE>
Message-ID: <46F11F30.1080201@vanderbilt.edu>

Steve Powell wrote:
> Thanks again Frank for quick reply.
> True, 
> 
> someobject=2
> Test=function(obj,labe)
>    {
>    label(obj)=labe
>    #at this point add the line:
>    obj
>    }
>  Test(someobject,"somelabel") 
> #returns a label. But if you retype 
> someobject
> #the label has gone. That is what I meant by the label not being permanently
> changed.

Why would that work?  someobject was never changed in any way.  Use 
someobject <- Test(someobject, 'new label') or if that's all you want, 
just label(someobject) <- 'new label'

Frank

> Steve 
>  
> proMENTE social research 
> research | evaluation | training & consulting 
> Kranj?evi?eva 35, 71000 Sarajevo 
> mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387 33 556 866
> skype: stevepowell99 
> www.promente.org  |  www.mojakarijera.com  |  www.psih.org  
> 
> -----Original Message-----
> From: Frank E Harrell Jr [mailto:f.harrell at vanderbilt.edu] 
> Sent: 17 September 2007 17:18
> To: Steve Powell
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Creating Hmisc labels inside a function
> 
> Steve Powell wrote:
>>  
>> Thanks, Frank - it doesn't work though. 
>> Your suggestion was:
>>
> Test=function(obj,labe)
>   {
>   label(obj)=labe
>   #at this point add the line:
>   obj
>   }
>> #...but just returning the object does not permanently change the label:
>> obj
> 
> It does for me.  Please re-run.  -Frank
> 
>  > attributes(Test(1:3, 'some label'))
> $label
> [1] "some label"
> 
> $class
> [1] "labelled"
> 
> You don't need assign.
> Frank
> 
> 
>> That is why I wanted to use assign. But "assign" will not work with 
>> attributes, labels etc. So
>>
>> assign(label(obj),"some label") #doesn't even work outside a function, 
>> at the command prompt.
>>
>> Any more ideas anyone?
>> Best wishes
>> Steve Powell
>>
>>  
>> proMENTE social research
>> research | evaluation | training & consulting Kranj?evi?eva 35, 71000 
>> Sarajevo
>> mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387 33 556 
>> 866
>> skype: stevepowell99
>> www.promente.org  |  www.mojakarijera.com  |  www.psih.org
>>
>> -----Original Message-----
>> From: Frank E Harrell Jr [mailto:f.harrell at vanderbilt.edu]
>> Sent: 12 September 2007 14:38
>> To: Steve Powell
>> Cc: r-help at stat.math.ethz.ch
>> Subject: Re: [R] Creating Hmisc labels inside a function
>>
>> Steve Powell wrote:
>>> hello list members,
>>> I am wanting to write a label using the Hmisc package, but inside a 
>>> function. Normally I can do:
>>>
>>> library(Hmisc)
>>> M=2
>>> label(M)="lab"
>>>
>>> #But inside a function the "=" does not work:
>>> Test=function(obj,labe)
>>> {
>>> label(obj)=labe
>> at this point add the line:
>>
>> obj
>>
>>> }
>> The returned object will have what you need.  -Frank
>>
>>> Test(M,"new label")
>>>
>>> I usually use the "assign" function to make assignments inside 
>>> functions, but assign will not work with attributes, labels etc.
>>> Any ideas?
>>> Thanks in advance
>>>
>>> Steve Powell
>>>
>>>  
>>> proMENTE social research
>>> research | evaluation | training & consulting Kranj?evi?eva 35, 71000 
>>> Sarajevo
>>> mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387 33 556
>>> 866
>>> skype: stevepowell99
>>> www.promente.org  |  www.mojakarijera.com  |  www.psih.org
>>>
>>>
>>> Checked by AVG Free Edition. 
>>>
>>> 17:43
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
> 
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From gustaf.rydevik at gmail.com  Wed Sep 19 15:09:15 2007
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Wed, 19 Sep 2007 15:09:15 +0200
Subject: [R] function on factors - how best to proceed
In-Reply-To: <45f568c70709190604t6e0f8803tf684041c4934c426@mail.gmail.com>
References: <ypx67immkiqh.fsf@uracil.uio.no>
	<45f568c70709190543s5c501995x3f2d6a654e3fa370@mail.gmail.com>
	<ypx63axakegp.fsf@uracil.uio.no>
	<45f568c70709190604t6e0f8803tf684041c4934c426@mail.gmail.com>
Message-ID: <45f568c70709190609x7cb56f18w9822f7f2c1e18d4c@mail.gmail.com>

On 9/19/07, Gustaf Rydevik <gustaf.rydevik at gmail.com> wrote:
> On 9/19/07, Karin Lagesen <karin.lagesen at medisin.uio.no> wrote:
> > "Gustaf Rydevik" <gustaf.rydevik at gmail.com> writes:
> >
> >
> > > The second warning message tells you that:
> > >  2: the condition has length > 1 and only the first element will be
> > > used in: if (terminus > origin)
> > >
> > > You are comparing two vectors,  which generate a vector of TRUE/FALSE values.
> > > The "if" statement need a single TRUE/FALSE value.
> > > Either use a for loop:
> > > for (i in 1:nrow(terminus)) {if terminus[i]> origin[i]...}
> > > or a nested ifelse statement (which is recommendable on such a big data set).
> >
> > Thankyou for your reply! I will certainly try the numeric thing.
> >
> > Now, for the vector comparison. I can easily see how you would do a
> > for loop here, but I am unable to see how a nested ifelse statement
> > would work. Could you possibly give me an example?
> >
> > Thankyou again for your help!
> >
> > Karin
> > --
> > Karin Lagesen, PhD student
> > karin.lagesen at medisin.uio.no
> > http://folk.uio.no/karinlag
> >
>
> You replace each instance of "if" with ifelse, inserting a comma after
> the logical test, and instead of the else statement.  The end result
> would become (if I've not made a mistake):
>
> _____
> replicator<-rep(c("LEFT","RIGHT"),50)
> terminus<-rnorm(100)
> origin<-rnorm(100)
> begin<-rnorm(100)
> length<-sample(1:100,100,replace=T)
>
> d<-ifelse(terminus>origin,
>         +ifelse(replicator=="LEFT",-((origin-begin))%%length),(begin-origin)),
>         +ifelse(replicator=="LEFT",(origin-begin),-((begin-origin)%%length))
>         +)
>
> /Gustaf
>
>
> --
> Gustaf Rydevik, M.Sci.
> tel: +46(0)703 051 451
> address:Essingetorget 40,112 66 Stockholm, SE
> skype:gustaf_rydevik
>

Sorry, forgot to remove the plusses, and had a parenthesis wrong...

______________
replicator<-rep(c("LEFT","RIGHT"),50)
terminus<-rnorm(100)
origin<-rnorm(100)
begin<-rnorm(100)
length<-sample(1:100,100,replace=T)

d<-ifelse(terminus>origin,
      ifelse(replicator=="LEFT",-((origin-begin)%%length),(begin-origin)),
      ifelse(replicator=="LEFT",(origin-begin),-((begin-origin)%%length))
      )
___________


best,

Gustaf
-- 
Gustaf Rydevik, M.Sci.
tel: +46(0)703 051 451
address:Essingetorget 40,112 66 Stockholm, SE
skype:gustaf_rydevik


From j.zutt at tudelft.nl  Wed Sep 19 15:19:02 2007
From: j.zutt at tudelft.nl (Jonne Zutt)
Date: Wed, 19 Sep 2007 15:19:02 +0200
Subject: [R] Running tcltk From a batch file
In-Reply-To: <3a5596550709190435i32e13b0ch915c736c0f76af31@mail.gmail.com>
References: <3a5596550709190435i32e13b0ch915c736c0f76af31@mail.gmail.com>
Message-ID: <1190207942.14600.20.camel@dutiih.st.ewi.tudelft.nl>

Hi Samuel,

An easy solution is the following. Let the R script wait until a certain
variable (ok_to_quit) got changed.

Hope it helps,
Jonne.

## in a file called test.R
quit <- function() {
  .Tcl("set ok_to_quit 1")
  tkdestroy(tt)
}

require(tcltk)
tt <<- tktoplevel()
OK.but <- tkbutton(tt,text="OK",command=quit)
tkgrid(OK.but)
tkfocus(tt)

.Tcl("set ok_to_quit 0")
.Tcl("vwait ok_to_quit")


From dimitris.rizopoulos at med.kuleuven.be  Wed Sep 19 15:28:59 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 19 Sep 2007 15:28:59 +0200
Subject: [R] apply
References: <y65ps0ex0wy.fsf@minnie.esd.mun.ca>
Message-ID: <00d901c7fac1$09409cd0$0540210a@www.domain>

it also works with vectors, e.g.

x <- c("Ca00Mn48_0.gout", "Ca01Mn47_0.gout", "Ca01Mn47_1.gout", 
"Ca48Mn00_0.gout")
substr(x, 3, 4)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Roger Mason" <rmason at esd.mun.ca>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, September 19, 2007 3:03 PM
Subject: [R] apply


> Hello,
>
> I have a list of filenames extracted from a data-frame thus:
>
> files <- main$file
>
> e.g. file[[1]] returns
>
> [1] Ca00Mn48_0.gout
> 4702 Levels: Ca00Mn48_0.gout Ca01Mn47_0.gout Ca01Mn47_1.gout
> ... Ca48Mn00_0.gout
>
> I want to extract the substring that contains the two digits after
> "Ca".  This works on individual entries, e.g. substr(files[[1]],3,4)
> returns "00".
>
> I wish to apply substr() to all the entries in files.  All my 
> efforts
> fail.  Could some kind soul explain how to do what I want?
>
> Thanks,
>
> Roger Mason
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From P.Dalgaard at biostat.ku.dk  Wed Sep 19 15:30:17 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 19 Sep 2007 15:30:17 +0200
Subject: [R] Running tcltk From a batch file
In-Reply-To: <1190207942.14600.20.camel@dutiih.st.ewi.tudelft.nl>
References: <3a5596550709190435i32e13b0ch915c736c0f76af31@mail.gmail.com>
	<1190207942.14600.20.camel@dutiih.st.ewi.tudelft.nl>
Message-ID: <46F12469.5060902@biostat.ku.dk>

Jonne Zutt wrote:
> Hi Samuel,
>
> An easy solution is the following. Let the R script wait until a certain
> variable (ok_to_quit) got changed.
>
> Hope it helps,
> Jonne.
>
> ## in a file called test.R
> quit <- function() {
>   .Tcl("set ok_to_quit 1")
>   tkdestroy(tt)
> }
>
> require(tcltk)
> tt <<- tktoplevel()
> OK.but <- tkbutton(tt,text="OK",command=quit)
> tkgrid(OK.but)
> tkfocus(tt)
>
> .Tcl("set ok_to_quit 0")
> .Tcl("vwait ok_to_quit")
>
>   
The tkttest demo does this in a somewhat cleaner fashion (avoiding .Tcl).

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From therneau at mayo.edu  Wed Sep 19 15:51:34 2007
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 19 Sep 2007 08:51:34 -0500 (CDT)
Subject: [R] Cox regression and p-values
Message-ID: <200709191351.l8JDpXF06496@hsrnfs-101.mayo.edu>

  Fisher's "exact" test is for comparing two proportions, which is a completely 
different problem than Cox regression, and so the test has no relevance to this 
problem.  It has, however, sparked a large literature of debate; already alluded 
to by many of the responses.

  The tests in the coxph table are Wald tests, beta/ se(beta).  For large sample 
sizes the Wald, score, and likelihood ratio tests will be equivalent, but for 
small samples the prevailing wisdom is that the likelihood ratio tests are the 
most reliable.  To do the LR test, you need to refit the Cox model without the 
variable of interest.  Then compare the two printouts, one for the full model 
and one for the reduced model: both will contain a line "Likelihood ratio test = 
xxx on y df" where xxx and y are numbers.  The LR test for the omitted variable 
is the difference in the two "xxx" values, which is chi-squared with degrees of 
freedom equal to the difference in the "y" values.
  	
  	Terry Therneau



>I might be barking up the wrong tree here, but I want to make sure I
>have a full understanding of this.  What I would like to know is what
>tests are performed to give the p-values for each variable in the table
>that is the result of coxph regression when the variables are
>categorical only.
>More specifically, when expected counts are less than 5 is the Fisher's
>exact test used instead of the Chi^2 test?


From upsattar at yahoo.com  Wed Sep 19 16:03:30 2007
From: upsattar at yahoo.com (Abdus Sattar)
Date: Wed, 19 Sep 2007 07:03:30 -0700 (PDT)
Subject: [R] Robust or Sandwich estimates in lmer2
Message-ID: <501048.3657.qm@web58113.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070919/80318eb2/attachment.pl 

From yoni.stoffman at mediaboost.com  Wed Sep 19 16:23:29 2007
From: yoni.stoffman at mediaboost.com (Yoni Stoffman)
Date: Wed, 19 Sep 2007 16:23:29 +0200
Subject: [R] Memory Issue
Message-ID: <003601c7fac8$a7d07c10$2600a8c0@mbpc100>

Hi, 

I'm new to R and there is something I'm missing about how it uses
memory. I'm doing a simple query (using RODBC package) and immediately
set the data.frame to null close the connection/channel and explicitly
call to the garbage collector (gc()) however when I look in the task
monitor I see both "VM size" and ""Mem Usage" increased every time (for
the RGui).

I tried this on different configurations: windowxp64 / windowsxp and R
version 2.4.1 and 2.5.1. 

What I'm doing wrong? 

Thanks, 
Yoni.


From murdoch at stats.uwo.ca  Wed Sep 19 16:37:06 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 19 Sep 2007 10:37:06 -0400
Subject: [R] glmpath error
In-Reply-To: <12775820.post@talk.nabble.com>
References: <12774607.post@talk.nabble.com> <46F0FA0D.4050207@stats.uwo.ca>
	<12775820.post@talk.nabble.com>
Message-ID: <46F13412.3020202@stats.uwo.ca>

On 9/19/2007 7:46 AM, Tirthadeep wrote:
> Then what is the solution?

The same method you used for the other columns:

train.data[,21]

Duncan Murdoch

> 
> 
> 
> 
> Duncan Murdoch-2 wrote:
>> 
>> Tirthadeep wrote:
>>> Hi,
>>>
>>> I am using glampath package for L1 regularized logistic regression. I got
>>> the following error messege.
>>>
>>>   
>>>> model.fit <- glmpath(train.data[,1:20], train.data$RES, family=binomial)
>>>>     
>>> Error in one %*% x : requires numeric matrix/vector arguments
>>>
>>> where train.data is a 700X21 matrix and 21st column in response (RES).
>>>   
>> If it is a matrix, then train.data$RES won't work.  That column 
>> selection method only works for data frames,
>> because they are lists, and matrices aren't.
>> 
>> Duncan Murdoch
>>> Please clarify!!!
>>>
>>> Thanks
>>>
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>


From ehlers at math.ucalgary.ca  Wed Sep 19 16:37:24 2007
From: ehlers at math.ucalgary.ca (Peter Ehlers)
Date: Wed, 19 Sep 2007 08:37:24 -0600
Subject: [R] glmpath error
In-Reply-To: <12775820.post@talk.nabble.com>
References: <12774607.post@talk.nabble.com> <46F0FA0D.4050207@stats.uwo.ca>
	<12775820.post@talk.nabble.com>
Message-ID: <46F13424.6040202@math.ucalgary.ca>

Is train.data a *numeric* matrix?

Peter Ehlers

Tirthadeep wrote:
> Then what is the solution?
> 
> 
> 
> 
> Duncan Murdoch-2 wrote:
>> Tirthadeep wrote:
>>> Hi,
>>>
>>> I am using glampath package for L1 regularized logistic regression. I got
>>> the following error messege.
>>>
>>>   
>>>> model.fit <- glmpath(train.data[,1:20], train.data$RES, family=binomial)
>>>>     
>>> Error in one %*% x : requires numeric matrix/vector arguments
>>>
>>> where train.data is a 700X21 matrix and 21st column in response (RES).
>>>   
>> If it is a matrix, then train.data$RES won't work.  That column 
>> selection method only works for data frames,
>> because they are lists, and matrices aren't.
>>
>> Duncan Murdoch
>>> Please clarify!!!
>>>
>>> Thanks
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


From birgit.lemcke at systbot.uzh.ch  Wed Sep 19 17:18:57 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Wed, 19 Sep 2007 17:18:57 +0200
Subject: [R] ChiSquare-Test
Message-ID: <EC23AF13-7DF0-4469-91EE-5D2120536DF5@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070919/e6b633cb/attachment.pl 

From ripley at stats.ox.ac.uk  Wed Sep 19 17:21:46 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Sep 2007 16:21:46 +0100 (BST)
Subject: [R] glmpath error
In-Reply-To: <46F13412.3020202@stats.uwo.ca>
References: <12774607.post@talk.nabble.com> <46F0FA0D.4050207@stats.uwo.ca>
	<12775820.post@talk.nabble.com> <46F13412.3020202@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0709191615220.14360@gannet.stats.ox.ac.uk>

On Wed, 19 Sep 2007, Duncan Murdoch wrote:

> On 9/19/2007 7:46 AM, Tirthadeep wrote:
>> Then what is the solution?
>
> The same method you used for the other columns:
>
> train.data[,21]

However, the error message is about the first argument (x) and not NULL 
for the second argument (and applying $ to a matrix will give a warning in 
recent versions of R).

I think it most likely that train.data is a data frame, in which case the 
problem lies in the first argument.  glmpath makes no attempt to coerce 
its arguments to the desired form, so you do need to supply exactly what 
the help page says.  (Although it does not say x should be numeric, it 
does need to be.)

>
> Duncan Murdoch
>
>>
>>
>>
>>
>> Duncan Murdoch-2 wrote:
>>>
>>> Tirthadeep wrote:
>>>> Hi,
>>>>
>>>> I am using glampath package for L1 regularized logistic regression. I got
>>>> the following error messege.
>>>>
>>>>
>>>>> model.fit <- glmpath(train.data[,1:20], train.data$RES, family=binomial)
>>>>>
>>>> Error in one %*% x : requires numeric matrix/vector arguments
>>>>
>>>> where train.data is a 700X21 matrix and 21st column in response (RES).
>>>>
>>> If it is a matrix, then train.data$RES won't work.  That column
>>> selection method only works for data frames,
>>> because they are lists, and matrices aren't.
>>>
>>> Duncan Murdoch
>>>> Please clarify!!!
>>>>
>>>> Thanks
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From HDoran at air.org  Wed Sep 19 17:37:56 2007
From: HDoran at air.org (Doran, Harold)
Date: Wed, 19 Sep 2007 11:37:56 -0400
Subject: [R] By() with method = spearman
Message-ID: <2323A6D37908A847A7C32F1E3662C80E010A06CE@dc1ex01.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070919/a189b837/attachment.pl 

From wtimm at techfak.uni-bielefeld.de  Wed Sep 19 18:00:00 2007
From: wtimm at techfak.uni-bielefeld.de (Wiebke Timm)
Date: Wed, 19 Sep 2007 12:00:00 -0400
Subject: [R] Strange behaviour of lars method
Message-ID: <0AE9110A-E342-4CDA-BA92-A8D5A9156DDD@techfak.uni-bielefeld.de>

Hi!

When I apply the lars (least-angle-regression) method to my data  
(3655 features, only 355 data points, no I did not mistype), I  
observe a strange behaviour:

1) The beta values tend to grow into real high values quite fast up  
to a point where they overflow and get negative. The overflow is not  
a problem, I don't need the last part of the analysis anyway, but why  
do they just shoot up to high values like that...? Any explanation?

2) The Cp values... they start at about -360 and grow linearly with  
increasing steps. This is totally strange since they ought to be an  
"overly optimistic estimation of the generalization error" according  
to Hastie's book.

3) Lastly, I get a curve for the r^2 correlation values, that grows  
up to a plateau where they are 1 (until they reach the point where  
betas overflow, then it gets negative, but forget about that). This  
is classic overfitting happening. The calculation IS right though,  
since using the components and betas from one of those r^2=1 steps  
gives a correlation of like 0.96 with nu-SVR too. The generalization  
is pretty bad though.

The funny thing: I observe qualitatively the same when starting with  
359 of these features and do a lars on them.

So, questions I have:
* Regarding to point 1 and 2, does anybody have an explanation for  
the described behaviour? I can't seem to find one myself...
* Did anybody try lars on data with such a bad feature to data points  
ratio before? What were the experiences?
* Why does it overfit so bad?

I have also tried the crossvalidation selection (cv.lars) but it does  
not give me the selected features or betas, just the r^2 and RSS  
values from its runs...


Thanks for any thoughts on this!

Ciao!
    Wiebke


From ccleland at optonline.net  Wed Sep 19 18:14:07 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 19 Sep 2007 12:14:07 -0400
Subject: [R] By() with method = spearman
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E010A06CE@dc1ex01.air.org>
References: <2323A6D37908A847A7C32F1E3662C80E010A06CE@dc1ex01.air.org>
Message-ID: <46F14ACF.8010907@optonline.net>

Doran, Harold wrote:
> I have a data set where I want the correlations between 2 variables
> conditional on a students grade level.
> 
> This code works just fine.
> 
> by(tmp[,c('mtsc07', 'DCBASmathscoreSPRING')], tmp$Grade, cor,
> use='complete', method='pearson')
> 
> However, this generates an error
> 
> by(tmp[,c('mtsc07', 'DCBASmathscoreSPRING')], tmp$Grade, cor,
> use='complete', method='spearman')
> Error in FUN(data[x, ], ...) : 'x' is empty
> 
> I can subset the data by grade and compute spearman rho as
> 
> tmp5 <- subset(tmp, Grade == 5)
> cor(tmp5[,c('mtsc07', 'DCBASmathcountSPRING')], use='complete',
> method='spearman')
> 
> But doing this iteratively is inefficient.
> 
> I don't see anything in the help man for by() or cor() that tells me
> what the problem is. I might be missing it though. Any thoughts?

  It works as expected using the iris data:

by(iris[,c('Sepal.Length', 'Sepal.Width')], iris$Species, cor,
   use='complete', method='spearman')

iris$Species: setosa
             Sepal.Length Sepal.Width
Sepal.Length    1.0000000   0.7553375
Sepal.Width     0.7553375   1.0000000
---------------------------------------------------------------------------------------------------------------------

iris$Species: versicolor
             Sepal.Length Sepal.Width
Sepal.Length     1.000000    0.517606
Sepal.Width      0.517606    1.000000
---------------------------------------------------------------------------------------------------------------------

iris$Species: virginica
             Sepal.Length Sepal.Width
Sepal.Length    1.0000000   0.4265165
Sepal.Width     0.4265165   1.0000000

> sessionInfo()
R version 2.5.1 Patched (2007-09-16 r42884)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
"methods"   "base"

other attached packages:
 lattice
"0.16-5"

> Thanks,
> Harold
> 
> 
>> sessionInfo()
> R version 2.5.0 (2007-04-23) 
> i386-pc-mingw32 
> 
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
> "methods"   "base"     
> 
> other attached packages:
>  lattice 
> "0.15-4" 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code. 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From rhelp.stats at gmail.com  Wed Sep 19 18:16:07 2007
From: rhelp.stats at gmail.com (R Help)
Date: Wed, 19 Sep 2007 13:16:07 -0300
Subject: [R] layout function for several plots
In-Reply-To: <20070919112629.215180@gmx.net>
References: <20070919112629.215180@gmx.net>
Message-ID: <c84ed6950709190916p2b376a4ew9f6d015482a76c10@mail.gmail.com>

I can't read what your error message, but on mine I get the error:
"Error in plot.new(): margins too large", which is happening because
the default margins do not have enough space.  You can reduce the
margins with using par

par(mar=c(0,0,0,0))

Which will let plot.new() work.  I hope this helps.

Sam

On 9/19/07, marcg <mdgi at gmx.ch> wrote:
> Dear all
>
> I try to print 9 plots on a page, arranged as the code shows below.
>
> nf <- layout(matrix(c(1,0,2,0,0,3,0,4,0,5,0,6,0,0,0,0,7,0,8,9), 10,2))
> layout.show(nf)
>
> but when I try to plot, an error message
> Fehler in plot.new() : Grafikr?nder zu gro?
> appears
>
> to verify p.e. with
>
> plot(runif(10:1))
>
> i tried with plot(runif(10:1), ann=F) to produce more space, but neither.
>
> The second question: how to place a cross in the middle of the plot to delineate in 4 big fields (containing each 5 plots)
>
> Thanks a lot
>
>
> --
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> --
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From HDoran at air.org  Wed Sep 19 18:19:54 2007
From: HDoran at air.org (Doran, Harold)
Date: Wed, 19 Sep 2007 12:19:54 -0400
Subject: [R] By() with method = spearman
In-Reply-To: <46F14ACF.8010907@optonline.net>
Message-ID: <2323A6D37908A847A7C32F1E3662C80E010A06D9@dc1ex01.air.org>

Thanks, Chuck. Seems odd though, doesn't it? There must be something
with my data set. But, I don't have any clue what it might be since I
can compute pearson using by() and I can subset and actually compute
spearman using just cor() 

> -----Original Message-----
> From: Chuck Cleland [mailto:ccleland at optonline.net] 
> Sent: Wednesday, September 19, 2007 12:14 PM
> To: Doran, Harold
> Cc: r-help at r-project.org
> Subject: Re: [R] By() with method = spearman
> 
> Doran, Harold wrote:
> > I have a data set where I want the correlations between 2 variables 
> > conditional on a students grade level.
> > 
> > This code works just fine.
> > 
> > by(tmp[,c('mtsc07', 'DCBASmathscoreSPRING')], tmp$Grade, cor, 
> > use='complete', method='pearson')
> > 
> > However, this generates an error
> > 
> > by(tmp[,c('mtsc07', 'DCBASmathscoreSPRING')], tmp$Grade, cor, 
> > use='complete', method='spearman') Error in FUN(data[x, ], 
> ...) : 'x' 
> > is empty
> > 
> > I can subset the data by grade and compute spearman rho as
> > 
> > tmp5 <- subset(tmp, Grade == 5)
> > cor(tmp5[,c('mtsc07', 'DCBASmathcountSPRING')], use='complete',
> > method='spearman')
> > 
> > But doing this iteratively is inefficient.
> > 
> > I don't see anything in the help man for by() or cor() that 
> tells me 
> > what the problem is. I might be missing it though. Any thoughts?
> 
>   It works as expected using the iris data:
> 
> by(iris[,c('Sepal.Length', 'Sepal.Width')], iris$Species, cor,
>    use='complete', method='spearman')
> 
> iris$Species: setosa
>              Sepal.Length Sepal.Width
> Sepal.Length    1.0000000   0.7553375
> Sepal.Width     0.7553375   1.0000000
> --------------------------------------------------------------
> -------------------------------------------------------
> 
> iris$Species: versicolor
>              Sepal.Length Sepal.Width
> Sepal.Length     1.000000    0.517606
> Sepal.Width      0.517606    1.000000
> --------------------------------------------------------------
> -------------------------------------------------------
> 
> iris$Species: virginica
>              Sepal.Length Sepal.Width
> Sepal.Length    1.0000000   0.4265165
> Sepal.Width     0.4265165   1.0000000
> 
> > sessionInfo()
> R version 2.5.1 Patched (2007-09-16 r42884)
> i386-pc-mingw32
> 
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
> "methods"   "base"
> 
> other attached packages:
>  lattice
> "0.16-5"
> 
> > Thanks,
> > Harold
> > 
> > 
> >> sessionInfo()
> > R version 2.5.0 (2007-04-23)
> > i386-pc-mingw32
> > 
> > locale:
> > LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> > States.1252;LC_MONETARY=English_United
> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> > 
> > attached base packages:
> > [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
> > "methods"   "base"     
> > 
> > other attached packages:
> >  lattice
> > "0.15-4" 
> > 
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code. 
> 
> --
> Chuck Cleland, Ph.D.
> NDRI, Inc.
> 71 West 23rd Street, 8th floor
> New York, NY 10010
> tel: (212) 845-4495 (Tu, Th)
> tel: (732) 512-0171 (M, W, F)
> fax: (917) 438-0894
> 


From sundar.dorai-raj at pdf.com  Wed Sep 19 17:42:09 2007
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 19 Sep 2007 08:42:09 -0700
Subject: [R] Robust or Sandwich estimates in lmer2
In-Reply-To: <501048.3657.qm@web58113.mail.re3.yahoo.com>
References: <501048.3657.qm@web58113.mail.re3.yahoo.com>
Message-ID: <46F14351.9090305@pdf.com>

Abdus Sattar said the following on 9/19/2007 7:03 AM:
> Dear R-Users:
> 
> I am trying to find the robust (or sandwich) estimates of the standard error of fixed effects parameter estimates using the package "lmer2". In model-1, I used "robust=TRUE" on the other, in model-2, I used "robust=FALSE". Both models giving me the same estimates. So my question is, does the robust option works in lmer2 to get the robust estimates of the standard error? If anybody could offer me a suggestion I would greatly appreciate it. Thank you.  
> 
> Model-1:
> 
>> p.mle<-lmer2(ddimer~race+steroid+psi+sofa+apache + (apache|subject), method="ML", data=final, robust=TRUE, cluster="id", weights=final$w)
>> beta=fixef(p.mle)
>> Vcov=vcov(p.mle, useScale=FALSE)
>> se=sqrt(diag(Vcov))
>> beta
>  (Intercept)         race      steroid          psi         sofa       apache 
>  5.826489820 -0.001920670 -0.242040171  0.005293996  0.075468340  0.009245152 
>> se
> [1] 0.108325229 0.058921371 0.055975547 0.001285687 0.018119089 0.002559902
> 
> Model-2:
> 
>> p.mle<-lmer2(ddimer~race+steroid+psi+sofa+apache + (apache|subject), method="ML", data=final, robust=FALSE, cluster="id", weights=final$w)
>> beta=fixef(p.mle)
>> Vcov=vcov(p.mle, useScale=FALSE)
>> se=sqrt(diag(Vcov))
>> beta
>  (Intercept)         race      steroid          psi         sofa       apache 
>  5.826489820 -0.001920670 -0.242040171  0.005293996  0.075468340  0.009245152 
>> se
> [1] 0.108325229 0.058921371 0.055975547 0.001285687 0.018119089 0.002559902
> 
> 
> Best Regards, 
> 
> Sattar
> 
> 

The help page to ?lmer2 in the lme4 package makes no mention of 
"cluster" or "robust" arguments. To me, that would mean these arguments 
are ignored.

HTH,

--sundar


From HDoran at air.org  Wed Sep 19 18:30:50 2007
From: HDoran at air.org (Doran, Harold)
Date: Wed, 19 Sep 2007 12:30:50 -0400
Subject: [R] By() with method = spearman
In-Reply-To: <46F14CB1.2060808@optonline.net>
Message-ID: <2323A6D37908A847A7C32F1E3662C80E010A06DB@dc1ex01.air.org>

I still get an error

> tmp$Grade <- factor(tmp$Grade)
> lapply(split(tmp, f = tmp$Grade),
function(x){cor(x[,c("mtsc07","DCBASmathscoreSPRING")], use='complete',
+ method='spearman')})

Error in cor(x[, c("mtsc07", "DCBASmathscoreSPRING")], use = "complete",
: 
        'x' is empty 

I noticed tmp$Grade (my index variable) was numeric. So, I coerced it
into a factor. I get the same error message, however.

Notice, however, that this code works correctly

lapply(split(tmp, f = tmp$Grade),
function(x){cor(x[,c("mtsc07","DCBASmathscoreSPRING")], use='complete',
method='pearson')})

The only differece is that method is changed to pearson.

> -----Original Message-----
> From: Chuck Cleland [mailto:ccleland at optonline.net] 
> Sent: Wednesday, September 19, 2007 12:22 PM
> To: Doran, Harold
> Subject: Re: [R] By() with method = spearman
> 
> Doran, Harold wrote:
> > Thanks, Chuck. Seems odd though, doesn't it? There must be 
> something 
> > with my data set. But, I don't have any clue what it might 
> be since I 
> > can compute pearson using by() and I can subset and 
> actually compute 
> > spearman using just cor()
> 
> Harold:
>   What happens when you approach the problem with split() and 
> lapply() instead of by()?  For example:
> 
> lapply(split(iris, f = iris$Species),
> function(x){cor(x[,c("Sepal.Length","Sepal.Width")], use='complete',
> method='spearman')})
> 
> $setosa
>              Sepal.Length Sepal.Width
> Sepal.Length    1.0000000   0.7553375
> Sepal.Width     0.7553375   1.0000000
> 
> $versicolor
>              Sepal.Length Sepal.Width
> Sepal.Length     1.000000    0.517606
> Sepal.Width      0.517606    1.000000
> 
> $virginica
>              Sepal.Length Sepal.Width
> Sepal.Length    1.0000000   0.4265165
> Sepal.Width     0.4265165   1.0000000
> 
> hope this helps,
> 
> Chuck
> 
> >> -----Original Message-----
> >> From: Chuck Cleland [mailto:ccleland at optonline.net]
> >> Sent: Wednesday, September 19, 2007 12:14 PM
> >> To: Doran, Harold
> >> Cc: r-help at r-project.org
> >> Subject: Re: [R] By() with method = spearman
> >>
> >> Doran, Harold wrote:
> >>> I have a data set where I want the correlations between 2 
> variables 
> >>> conditional on a students grade level.
> >>>
> >>> This code works just fine.
> >>>
> >>> by(tmp[,c('mtsc07', 'DCBASmathscoreSPRING')], tmp$Grade, cor, 
> >>> use='complete', method='pearson')
> >>>
> >>> However, this generates an error
> >>>
> >>> by(tmp[,c('mtsc07', 'DCBASmathscoreSPRING')], tmp$Grade, cor, 
> >>> use='complete', method='spearman') Error in FUN(data[x, ],
> >> ...) : 'x' 
> >>> is empty
> >>>
> >>> I can subset the data by grade and compute spearman rho as
> >>>
> >>> tmp5 <- subset(tmp, Grade == 5)
> >>> cor(tmp5[,c('mtsc07', 'DCBASmathcountSPRING')], use='complete',
> >>> method='spearman')
> >>>
> >>> But doing this iteratively is inefficient.
> >>>
> >>> I don't see anything in the help man for by() or cor() that
> >> tells me
> >>> what the problem is. I might be missing it though. Any thoughts?
> >>   It works as expected using the iris data:
> >>
> >> by(iris[,c('Sepal.Length', 'Sepal.Width')], iris$Species, cor,
> >>    use='complete', method='spearman')
> >>
> >> iris$Species: setosa
> >>              Sepal.Length Sepal.Width
> >> Sepal.Length    1.0000000   0.7553375
> >> Sepal.Width     0.7553375   1.0000000
> >> --------------------------------------------------------------
> >> -------------------------------------------------------
> >>
> >> iris$Species: versicolor
> >>              Sepal.Length Sepal.Width
> >> Sepal.Length     1.000000    0.517606
> >> Sepal.Width      0.517606    1.000000
> >> --------------------------------------------------------------
> >> -------------------------------------------------------
> >>
> >> iris$Species: virginica
> >>              Sepal.Length Sepal.Width
> >> Sepal.Length    1.0000000   0.4265165
> >> Sepal.Width     0.4265165   1.0000000
> >>
> >>> sessionInfo()
> >> R version 2.5.1 Patched (2007-09-16 r42884)
> >> i386-pc-mingw32
> >>
> >> locale:
> >> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> >> States.1252;LC_MONETARY=English_United
> >> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> >>
> >> attached base packages:
> >> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
> >> "methods"   "base"
> >>
> >> other attached packages:
> >>  lattice
> >> "0.16-5"
> >>
> >>> Thanks,
> >>> Harold
> >>>
> >>>
> >>>> sessionInfo()
> >>> R version 2.5.0 (2007-04-23)
> >>> i386-pc-mingw32
> >>>
> >>> locale:
> >>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> >>> States.1252;LC_MONETARY=English_United
> >>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> >>>
> >>> attached base packages:
> >>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
> >>> "methods"   "base"     
> >>>
> >>> other attached packages:
> >>>  lattice
> >>> "0.15-4" 
> >>>
> >>>
> >>> 	[[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, 
> reproducible code. 
> >> --
> >> Chuck Cleland, Ph.D.
> >> NDRI, Inc.
> >> 71 West 23rd Street, 8th floor
> >> New York, NY 10010
> >> tel: (212) 845-4495 (Tu, Th)
> >> tel: (732) 512-0171 (M, W, F)
> >> fax: (917) 438-0894
> >>
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > 
> 
> 
> --
> Chuck Cleland, Ph.D.
> NDRI, Inc.
> 71 West 23rd Street, 8th floor
> New York, NY 10010
> tel: (212) 845-4495 (Tu, Th)
> tel: (732) 512-0171 (M, W, F)
> fax: (917) 438-0894
> 


From HDoran at air.org  Wed Sep 19 18:40:22 2007
From: HDoran at air.org (Doran, Harold)
Date: Wed, 19 Sep 2007 12:40:22 -0400
Subject: [R] Robust or Sandwich estimates in lmer2
In-Reply-To: <46F14351.9090305@pdf.com>
Message-ID: <2323A6D37908A847A7C32F1E3662C80E010A06DE@dc1ex01.air.org>

This has come up before and I'll again ask the question "why would you
want robust standard errors in lmer"? Traditional econometric thinking
suggests that there is model mispecification if OLS is used and there is
a violation to the assumption of independence. So, one may still get the
point estimates via OLS but then get robust standard errors. This makes
sense.

But, mixed models are designed to account for violations to the iid
assumption via correctly specified random effects. So, if your lmer
model is correctly specified, the standard errors should yield an
accurate estimate of the true sampling variance.

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Sundar Dorai-Raj
> Sent: Wednesday, September 19, 2007 11:42 AM
> To: Abdus Sattar
> Cc: R-help at stat.math.ethz.ch; gsrwork at yahoo.com
> Subject: Re: [R] Robust or Sandwich estimates in lmer2
> 
> Abdus Sattar said the following on 9/19/2007 7:03 AM:
> > Dear R-Users:
> > 
> > I am trying to find the robust (or sandwich) estimates of 
> the standard error of fixed effects parameter estimates using 
> the package "lmer2". In model-1, I used "robust=TRUE" on the 
> other, in model-2, I used "robust=FALSE". Both models giving 
> me the same estimates. So my question is, does the robust 
> option works in lmer2 to get the robust estimates of the 
> standard error? If anybody could offer me a suggestion I 
> would greatly appreciate it. Thank you.  
> > 
> > Model-1:
> > 
> >> p.mle<-lmer2(ddimer~race+steroid+psi+sofa+apache + 
> (apache|subject), 
> >> method="ML", data=final, robust=TRUE, cluster="id", 
> weights=final$w)
> >> beta=fixef(p.mle)
> >> Vcov=vcov(p.mle, useScale=FALSE)
> >> se=sqrt(diag(Vcov))
> >> beta
> >  (Intercept)         race      steroid          psi         
> sofa       apache 
> >  5.826489820 -0.001920670 -0.242040171  0.005293996  0.075468340  
> > 0.009245152
> >> se
> > [1] 0.108325229 0.058921371 0.055975547 0.001285687 0.018119089 
> > 0.002559902
> > 
> > Model-2:
> > 
> >> p.mle<-lmer2(ddimer~race+steroid+psi+sofa+apache + 
> (apache|subject), 
> >> method="ML", data=final, robust=FALSE, cluster="id", 
> weights=final$w)
> >> beta=fixef(p.mle)
> >> Vcov=vcov(p.mle, useScale=FALSE)
> >> se=sqrt(diag(Vcov))
> >> beta
> >  (Intercept)         race      steroid          psi         
> sofa       apache 
> >  5.826489820 -0.001920670 -0.242040171  0.005293996  0.075468340  
> > 0.009245152
> >> se
> > [1] 0.108325229 0.058921371 0.055975547 0.001285687 0.018119089 
> > 0.002559902
> > 
> > 
> > Best Regards,
> > 
> > Sattar
> > 
> > 
> 
> The help page to ?lmer2 in the lme4 package makes no mention 
> of "cluster" or "robust" arguments. To me, that would mean 
> these arguments are ignored.
> 
> HTH,
> 
> --sundar
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From ivar.herfindal at bio.ntnu.no  Wed Sep 19 18:47:02 2007
From: ivar.herfindal at bio.ntnu.no (Ivar Herfindal)
Date: Wed, 19 Sep 2007 18:47:02 +0200
Subject: [R] By() with method = spearman
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E010A06DB@dc1ex01.air.org>
References: <2323A6D37908A847A7C32F1E3662C80E010A06DB@dc1ex01.air.org>
Message-ID: <46F15286.5030309@bio.ntnu.no>

Hello

It seems like method="pearson" accept missing values, that is, none 
complete cases, and only generate correlation coefficients of NA, while 
using method="spearman" gives and error message. try e.g.
 
testdata <- cbind.data.frame(gr=rep(letters[1:4], each=5), aa=rnorm(20), 
bb=rnorm(20))
testdata[1:5, 2] <- NA
by(testdata[,c("aa", "bb")], testdata$gr, cor, use="complete", 
method="pearson")
# provides result for every group, but NA for group a

by(testdata[,c("aa", "bb")], testdata$gr, cor, use="complete", 
method="spearman")
# gives:
Error in FUN(data[x, ], ...) : 'x' is empty

I guess a deeper look into cor would reveal what is actually going on 
with spearman vs pearson vs kendall (kendall also provides error message).
Anyway, this leads me to believe that you may have groups with no 
complete pairs.

Sincerely

Ivar

Doran, Harold skrev:
> I still get an error
>
>   
>> tmp$Grade <- factor(tmp$Grade)
>> lapply(split(tmp, f = tmp$Grade),
>>     
> function(x){cor(x[,c("mtsc07","DCBASmathscoreSPRING")], use='complete',
> + method='spearman')})
>
> Error in cor(x[, c("mtsc07", "DCBASmathscoreSPRING")], use = "complete",
> : 
>         'x' is empty 
>
> I noticed tmp$Grade (my index variable) was numeric. So, I coerced it
> into a factor. I get the same error message, however.
>
> Notice, however, that this code works correctly
>
> lapply(split(tmp, f = tmp$Grade),
> function(x){cor(x[,c("mtsc07","DCBASmathscoreSPRING")], use='complete',
> method='pearson')})
>
> The only differece is that method is changed to pearson.
>
>   
>> -----Original Message-----
>> From: Chuck Cleland [mailto:ccleland at optonline.net] 
>> Sent: Wednesday, September 19, 2007 12:22 PM
>> To: Doran, Harold
>> Subject: Re: [R] By() with method = spearman
>>
>> Doran, Harold wrote:
>>     
>>> Thanks, Chuck. Seems odd though, doesn't it? There must be 
>>>       
>> something 
>>     
>>> with my data set. But, I don't have any clue what it might 
>>>       
>> be since I 
>>     
>>> can compute pearson using by() and I can subset and 
>>>       
>> actually compute 
>>     
>>> spearman using just cor()
>>>       
>> Harold:
>>   What happens when you approach the problem with split() and 
>> lapply() instead of by()?  For example:
>>
>> lapply(split(iris, f = iris$Species),
>> function(x){cor(x[,c("Sepal.Length","Sepal.Width")], use='complete',
>> method='spearman')})
>>
>> $setosa
>>              Sepal.Length Sepal.Width
>> Sepal.Length    1.0000000   0.7553375
>> Sepal.Width     0.7553375   1.0000000
>>
>> $versicolor
>>              Sepal.Length Sepal.Width
>> Sepal.Length     1.000000    0.517606
>> Sepal.Width      0.517606    1.000000
>>
>> $virginica
>>              Sepal.Length Sepal.Width
>> Sepal.Length    1.0000000   0.4265165
>> Sepal.Width     0.4265165   1.0000000
>>
>> hope this helps,
>>
>> Chuck
>>
>>     
>>>> -----Original Message-----
>>>> From: Chuck Cleland [mailto:ccleland at optonline.net]
>>>> Sent: Wednesday, September 19, 2007 12:14 PM
>>>> To: Doran, Harold
>>>> Cc: r-help at r-project.org
>>>> Subject: Re: [R] By() with method = spearman
>>>>
>>>> Doran, Harold wrote:
>>>>         
>>>>> I have a data set where I want the correlations between 2 
>>>>>           
>> variables 
>>     
>>>>> conditional on a students grade level.
>>>>>
>>>>> This code works just fine.
>>>>>
>>>>> by(tmp[,c('mtsc07', 'DCBASmathscoreSPRING')], tmp$Grade, cor, 
>>>>> use='complete', method='pearson')
>>>>>
>>>>> However, this generates an error
>>>>>
>>>>> by(tmp[,c('mtsc07', 'DCBASmathscoreSPRING')], tmp$Grade, cor, 
>>>>> use='complete', method='spearman') Error in FUN(data[x, ],
>>>>>           
>>>> ...) : 'x' 
>>>>         
>>>>> is empty
>>>>>
>>>>> I can subset the data by grade and compute spearman rho as
>>>>>
>>>>> tmp5 <- subset(tmp, Grade == 5)
>>>>> cor(tmp5[,c('mtsc07', 'DCBASmathcountSPRING')], use='complete',
>>>>> method='spearman')
>>>>>
>>>>> But doing this iteratively is inefficient.
>>>>>
>>>>> I don't see anything in the help man for by() or cor() that
>>>>>           
>>>> tells me
>>>>         
>>>>> what the problem is. I might be missing it though. Any thoughts?
>>>>>           
>>>>   It works as expected using the iris data:
>>>>
>>>> by(iris[,c('Sepal.Length', 'Sepal.Width')], iris$Species, cor,
>>>>    use='complete', method='spearman')
>>>>
>>>> iris$Species: setosa
>>>>              Sepal.Length Sepal.Width
>>>> Sepal.Length    1.0000000   0.7553375
>>>> Sepal.Width     0.7553375   1.0000000
>>>> --------------------------------------------------------------
>>>> -------------------------------------------------------
>>>>
>>>> iris$Species: versicolor
>>>>              Sepal.Length Sepal.Width
>>>> Sepal.Length     1.000000    0.517606
>>>> Sepal.Width      0.517606    1.000000
>>>> --------------------------------------------------------------
>>>> -------------------------------------------------------
>>>>
>>>> iris$Species: virginica
>>>>              Sepal.Length Sepal.Width
>>>> Sepal.Length    1.0000000   0.4265165
>>>> Sepal.Width     0.4265165   1.0000000
>>>>
>>>>         
>>>>> sessionInfo()
>>>>>           
>>>> R version 2.5.1 Patched (2007-09-16 r42884)
>>>> i386-pc-mingw32
>>>>
>>>> locale:
>>>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>>>> States.1252;LC_MONETARY=English_United
>>>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>>>
>>>> attached base packages:
>>>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
>>>> "methods"   "base"
>>>>
>>>> other attached packages:
>>>>  lattice
>>>> "0.16-5"
>>>>
>>>>         
>>>>> Thanks,
>>>>> Harold
>>>>>
>>>>>
>>>>>           
>>>>>> sessionInfo()
>>>>>>             
>>>>> R version 2.5.0 (2007-04-23)
>>>>> i386-pc-mingw32
>>>>>
>>>>> locale:
>>>>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>>>>> States.1252;LC_MONETARY=English_United
>>>>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>>>>
>>>>> attached base packages:
>>>>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
>>>>> "methods"   "base"     
>>>>>
>>>>> other attached packages:
>>>>>  lattice
>>>>> "0.15-4" 
>>>>>
>>>>>
>>>>> 	[[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, 
>>>>>           
>> reproducible code. 
>>     
>>>> --
>>>> Chuck Cleland, Ph.D.
>>>> NDRI, Inc.
>>>> 71 West 23rd Street, 8th floor
>>>> New York, NY 10010
>>>> tel: (212) 845-4495 (Tu, Th)
>>>> tel: (732) 512-0171 (M, W, F)
>>>> fax: (917) 438-0894
>>>>
>>>>         
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>       
>> --
>> Chuck Cleland, Ph.D.
>> NDRI, Inc.
>> 71 West 23rd Street, 8th floor
>> New York, NY 10010
>> tel: (212) 845-4495 (Tu, Th)
>> tel: (732) 512-0171 (M, W, F)
>> fax: (917) 438-0894
>>
>>     
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sundar.dorai-raj at pdf.com  Wed Sep 19 18:49:43 2007
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 19 Sep 2007 09:49:43 -0700
Subject: [R] By() with method = spearman
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E010A06DB@dc1ex01.air.org>
References: <2323A6D37908A847A7C32F1E3662C80E010A06DB@dc1ex01.air.org>
Message-ID: <46F15327.7000502@pdf.com>

Hi, Harold,

In cases like this I usually add some print info to the function. E.g.

tmp$Grade <- factor(tmp$Grade)
lapply(split(tmp, f = tmp$Grade),
        function(x) {
          z <- x[,c("mtsc07","DCBASmathscoreSPRING")]
          print(levels(factor(z$Grade)))
          print(summary(z))
          print(mean(is.na(rowSums(z))))
          cor(z, use='complete', method='spearman')
        })

My guess is that one level produces no data when using "complete". I can 
reproduce the error with:

na <- rep(NA, 10)
z <- matrix(c(1:10, na, na, 1:10), 20, 2)
cor(z, use = "complete", method = "spearman")

HTH,

--sundar

Doran, Harold said the following on 9/19/2007 9:30 AM:
> I still get an error
> 
>> tmp$Grade <- factor(tmp$Grade)
>> lapply(split(tmp, f = tmp$Grade),
> function(x){cor(x[,c("mtsc07","DCBASmathscoreSPRING")], use='complete',
> + method='spearman')})
> 
> Error in cor(x[, c("mtsc07", "DCBASmathscoreSPRING")], use = "complete",
> : 
>         'x' is empty 
> 
> I noticed tmp$Grade (my index variable) was numeric. So, I coerced it
> into a factor. I get the same error message, however.
> 
> Notice, however, that this code works correctly
> 
> lapply(split(tmp, f = tmp$Grade),
> function(x){cor(x[,c("mtsc07","DCBASmathscoreSPRING")], use='complete',
> method='pearson')})
> 
> The only differece is that method is changed to pearson.
> 
>> -----Original Message-----
>> From: Chuck Cleland [mailto:ccleland at optonline.net] 
>> Sent: Wednesday, September 19, 2007 12:22 PM
>> To: Doran, Harold
>> Subject: Re: [R] By() with method = spearman
>>
>> Doran, Harold wrote:
>>> Thanks, Chuck. Seems odd though, doesn't it? There must be 
>> something 
>>> with my data set. But, I don't have any clue what it might 
>> be since I 
>>> can compute pearson using by() and I can subset and 
>> actually compute 
>>> spearman using just cor()
>> Harold:
>>   What happens when you approach the problem with split() and 
>> lapply() instead of by()?  For example:
>>
>> lapply(split(iris, f = iris$Species),
>> function(x){cor(x[,c("Sepal.Length","Sepal.Width")], use='complete',
>> method='spearman')})
>>
>> $setosa
>>              Sepal.Length Sepal.Width
>> Sepal.Length    1.0000000   0.7553375
>> Sepal.Width     0.7553375   1.0000000
>>
>> $versicolor
>>              Sepal.Length Sepal.Width
>> Sepal.Length     1.000000    0.517606
>> Sepal.Width      0.517606    1.000000
>>
>> $virginica
>>              Sepal.Length Sepal.Width
>> Sepal.Length    1.0000000   0.4265165
>> Sepal.Width     0.4265165   1.0000000
>>
>> hope this helps,
>>
>> Chuck
>>
>>>> -----Original Message-----
>>>> From: Chuck Cleland [mailto:ccleland at optonline.net]
>>>> Sent: Wednesday, September 19, 2007 12:14 PM
>>>> To: Doran, Harold
>>>> Cc: r-help at r-project.org
>>>> Subject: Re: [R] By() with method = spearman
>>>>
>>>> Doran, Harold wrote:
>>>>> I have a data set where I want the correlations between 2 
>> variables 
>>>>> conditional on a students grade level.
>>>>>
>>>>> This code works just fine.
>>>>>
>>>>> by(tmp[,c('mtsc07', 'DCBASmathscoreSPRING')], tmp$Grade, cor, 
>>>>> use='complete', method='pearson')
>>>>>
>>>>> However, this generates an error
>>>>>
>>>>> by(tmp[,c('mtsc07', 'DCBASmathscoreSPRING')], tmp$Grade, cor, 
>>>>> use='complete', method='spearman') Error in FUN(data[x, ],
>>>> ...) : 'x' 
>>>>> is empty
>>>>>
>>>>> I can subset the data by grade and compute spearman rho as
>>>>>
>>>>> tmp5 <- subset(tmp, Grade == 5)
>>>>> cor(tmp5[,c('mtsc07', 'DCBASmathcountSPRING')], use='complete',
>>>>> method='spearman')
>>>>>
>>>>> But doing this iteratively is inefficient.
>>>>>
>>>>> I don't see anything in the help man for by() or cor() that
>>>> tells me
>>>>> what the problem is. I might be missing it though. Any thoughts?
>>>>   It works as expected using the iris data:
>>>>
>>>> by(iris[,c('Sepal.Length', 'Sepal.Width')], iris$Species, cor,
>>>>    use='complete', method='spearman')
>>>>
>>>> iris$Species: setosa
>>>>              Sepal.Length Sepal.Width
>>>> Sepal.Length    1.0000000   0.7553375
>>>> Sepal.Width     0.7553375   1.0000000
>>>> --------------------------------------------------------------
>>>> -------------------------------------------------------
>>>>
>>>> iris$Species: versicolor
>>>>              Sepal.Length Sepal.Width
>>>> Sepal.Length     1.000000    0.517606
>>>> Sepal.Width      0.517606    1.000000
>>>> --------------------------------------------------------------
>>>> -------------------------------------------------------
>>>>
>>>> iris$Species: virginica
>>>>              Sepal.Length Sepal.Width
>>>> Sepal.Length    1.0000000   0.4265165
>>>> Sepal.Width     0.4265165   1.0000000
>>>>
>>>>> sessionInfo()
>>>> R version 2.5.1 Patched (2007-09-16 r42884)
>>>> i386-pc-mingw32
>>>>
>>>> locale:
>>>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>>>> States.1252;LC_MONETARY=English_United
>>>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>>>
>>>> attached base packages:
>>>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
>>>> "methods"   "base"
>>>>
>>>> other attached packages:
>>>>  lattice
>>>> "0.16-5"
>>>>
>>>>> Thanks,
>>>>> Harold
>>>>>
>>>>>
>>>>>> sessionInfo()
>>>>> R version 2.5.0 (2007-04-23)
>>>>> i386-pc-mingw32
>>>>>
>>>>> locale:
>>>>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>>>>> States.1252;LC_MONETARY=English_United
>>>>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>>>>
>>>>> attached base packages:
>>>>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
>>>>> "methods"   "base"     
>>>>>
>>>>> other attached packages:
>>>>>  lattice
>>>>> "0.15-4" 
>>>>>
>>>>>
>>>>> 	[[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, 
>> reproducible code. 
>>>> --
>>>> Chuck Cleland, Ph.D.
>>>> NDRI, Inc.
>>>> 71 West 23rd Street, 8th floor
>>>> New York, NY 10010
>>>> tel: (212) 845-4495 (Tu, Th)
>>>> tel: (732) 512-0171 (M, W, F)
>>>> fax: (917) 438-0894
>>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> --
>> Chuck Cleland, Ph.D.
>> NDRI, Inc.
>> 71 West 23rd Street, 8th floor
>> New York, NY 10010
>> tel: (212) 845-4495 (Tu, Th)
>> tel: (732) 512-0171 (M, W, F)
>> fax: (917) 438-0894
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murali.menon at uk.abnamro.com  Wed Sep 19 18:50:14 2007
From: murali.menon at uk.abnamro.com (murali.menon at uk.abnamro.com)
Date: Wed, 19 Sep 2007 17:50:14 +0100
Subject: [R] Row-by-row regression on matrix
Message-ID: <OF68650DD1.D55C9287-ONC125735B.005A625A-8025735B.005C94F5@abnamro.com>

Folks,

I have a 3000 x 4 matrix (y), which I need to regress row-by-row against a 
4-vector (x) to create a
matrix lm.y of intercepts and slopes. To illustrate:

y <- matrix(rnorm(12000), ncol = 4)
x <- c(1/12, 3/12, 6/12, 1)

system.time(lm.y <- t(apply(y, 1, function(z) lm(z ~ x)$coefficient)))
[1] 44.72 18.00 69.52    NA    NA

Takes more than a minute to do (and I need to do many similar regressions 
a day). 

Is there a more efficient way of handling this?

I'm running R 2.4.1 on Windows XP Service Pack 2 on a Intel Xeon dual-core 
2.66GHz with 3GB RAM.

Thanks very much,

Murali


---------------------------------------------------------------------------
This message (including any attachments) is confidential and...{{dropped}}


From pensterfuzzer at yahoo.de  Wed Sep 19 18:53:47 2007
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Wed, 19 Sep 2007 18:53:47 +0200 (CEST)
Subject: [R] micEcon: selection(,method="ml") . Predict method?
Message-ID: <45329.41219.qm@web23002.mail.ird.yahoo.com>

Hi,

as I read, maximum likelihood is the better method for
estimating selection-biased models. But I also want to
predict from that model. Is there any predict method
for the selection function when using maximum
likelihood estimation in micEcon? I couldn't find any.

Many thanks,
  Werner


From sundar.dorai-raj at pdf.com  Wed Sep 19 18:59:08 2007
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 19 Sep 2007 09:59:08 -0700
Subject: [R] Row-by-row regression on matrix
In-Reply-To: <OF68650DD1.D55C9287-ONC125735B.005A625A-8025735B.005C94F5@abnamro.com>
References: <OF68650DD1.D55C9287-ONC125735B.005A625A-8025735B.005C94F5@abnamro.com>
Message-ID: <46F1555C.4020606@pdf.com>


murali.menon at uk.abnamro.com said the following on 9/19/2007 9:50 AM:
> Folks,
> 
> I have a 3000 x 4 matrix (y), which I need to regress row-by-row against a 
> 4-vector (x) to create a
> matrix lm.y of intercepts and slopes. To illustrate:
> 
> y <- matrix(rnorm(12000), ncol = 4)
> x <- c(1/12, 3/12, 6/12, 1)
> 
> system.time(lm.y <- t(apply(y, 1, function(z) lm(z ~ x)$coefficient)))
> [1] 44.72 18.00 69.52    NA    NA
> 
> Takes more than a minute to do (and I need to do many similar regressions 
> a day). 
> 
> Is there a more efficient way of handling this?
> 
> I'm running R 2.4.1 on Windows XP Service Pack 2 on a Intel Xeon dual-core 
> 2.66GHz with 3GB RAM.
> 
> Thanks very much,
> 
> Murali
> 

Yes. Try,

set.seed(1)
y <- matrix(rnorm(12000), ncol = 4)
x <- c(1/12, 3/12, 6/12, 1)
system.time(lm.y <- t(apply(y, 1, function(z) lm(z ~ x)$coefficient)))

##   user  system elapsed
##   1.10    0.00   38.69

system.time(lm.y2 <- t(coef(lm(t(y) ~ x))))

##   user  system elapsed
##   0.02    0.00    0.04

all.equal(lm.y, lm.y2)
## [1] TRUE

HTH,

--sundar


From ccleland at optonline.net  Wed Sep 19 19:01:55 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 19 Sep 2007 13:01:55 -0400
Subject: [R] Row-by-row regression on matrix
In-Reply-To: <OF68650DD1.D55C9287-ONC125735B.005A625A-8025735B.005C94F5@abnamro.com>
References: <OF68650DD1.D55C9287-ONC125735B.005A625A-8025735B.005C94F5@abnamro.com>
Message-ID: <46F15603.7070109@optonline.net>

murali.menon at uk.abnamro.com wrote:
> Folks,
> 
> I have a 3000 x 4 matrix (y), which I need to regress row-by-row against a 
> 4-vector (x) to create a
> matrix lm.y of intercepts and slopes. To illustrate:
> 
> y <- matrix(rnorm(12000), ncol = 4)
> x <- c(1/12, 3/12, 6/12, 1)
> 
> system.time(lm.y <- t(apply(y, 1, function(z) lm(z ~ x)$coefficient)))
> [1] 44.72 18.00 69.52    NA    NA
> 
> Takes more than a minute to do (and I need to do many similar regressions 
> a day). 
> 
> Is there a more efficient way of handling this?
> 
> I'm running R 2.4.1 on Windows XP Service Pack 2 on a Intel Xeon dual-core 
> 2.66GHz with 3GB RAM.
> 
> Thanks very much,
> 
> Murali

 y <- matrix(rnorm(12000), ncol = 4)
 x <- c(1/12, 3/12, 6/12, 1)

 system.time(lm.y1 <- t(coef(lm(t(y) ~ x))))
   user  system elapsed
   0.03    0.00    0.04

 system.time(lm.y2 <- t(apply(y, 1, function(z) lm(z ~ x)$coefficient)))
   user  system elapsed
  19.70    0.05   20.45

 all.equal(lm.y1, lm.y2)
[1] TRUE

> 
> ---------------------------------------------------------------------------
> This message (including any attachments) is confidential and...{{dropped}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code. 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From tlumley at u.washington.edu  Wed Sep 19 19:13:20 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 19 Sep 2007 10:13:20 -0700 (PDT)
Subject: [R] Robust or Sandwich estimates in lmer2
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E010A06DE@dc1ex01.air.org>
Message-ID: <Pine.LNX.4.43.0709191013200.3922@hymn32.u.washington.edu>

On Wed, 19 Sep 2007, Doran, Harold wrote:

> This has come up before and I'll again ask the question "why would you
> want robust standard errors in lmer"?

And I'll again answer: using lmer() does not automatically guarantee correct model specification, either for the correlation structure or for the marginal variance.

      -thomas


Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From cberry at tajo.ucsd.edu  Wed Sep 19 19:32:49 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Wed, 19 Sep 2007 10:32:49 -0700
Subject: [R] Row-by-row regression on matrix
In-Reply-To: <OF68650DD1.D55C9287-ONC125735B.005A625A-8025735B.005C94F5@abnamro.com>
References: <OF68650DD1.D55C9287-ONC125735B.005A625A-8025735B.005C94F5@abnamro.com>
Message-ID: <Pine.LNX.4.64.0709191031030.29386@tajo.ucsd.edu>



> system.time( lm( t(y) ~ x ) )
    user  system elapsed
   0.008   0.000   0.010



On Wed, 19 Sep 2007, 
murali.menon at uk.abnamro.com wrote:

> Folks,
>
> I have a 3000 x 4 matrix (y), which I need to regress row-by-row against a
> 4-vector (x) to create a
> matrix lm.y of intercepts and slopes. To illustrate:
>
> y <- matrix(rnorm(12000), ncol = 4)
> x <- c(1/12, 3/12, 6/12, 1)
>
> system.time(lm.y <- t(apply(y, 1, function(z) lm(z ~ x)$coefficient)))
> [1] 44.72 18.00 69.52    NA    NA
>
> Takes more than a minute to do (and I need to do many similar regressions
> a day).
>
> Is there a more efficient way of handling this?
>
> I'm running R 2.4.1 on Windows XP Service Pack 2 on a Intel Xeon dual-core
> 2.66GHz with 3GB RAM.
>
> Thanks very much,
>
> Murali
>
>
> ---------------------------------------------------------------------------
> This message (including any attachments) is confidential and...{{dropped}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From gangchen at mail.nih.gov  Wed Sep 19 19:34:51 2007
From: gangchen at mail.nih.gov (Gang Chen)
Date: Wed, 19 Sep 2007 13:34:51 -0400
Subject: [R] How to pass a string as an argument to a function?
Message-ID: <7FFB48E5-2694-4316-B647-482BBC8D5FF8@mail.nih.gov>

I want to pass a predefined string ww ("fa*fb+fc") to function lme so  
that I can run

 > lme(y ~  fa*fb+fc, random = ~1|subj, model)

I've tried something like

 > lme(y ~  paste(ww), random = ~1|subj, model)

and

 > lme(y ~  sprintf(ww), random = ~1|subj, model)

but both give me the following error:

Error in model.frame(formula, rownames, variables, varnames, extras,  
extranames,  :
         variable lengths differ (found for 'ww')

There must be a simple way to do this. Any help?

Thanks,
Gang


From upsattar at yahoo.com  Wed Sep 19 19:42:48 2007
From: upsattar at yahoo.com (Abdus Sattar)
Date: Wed, 19 Sep 2007 10:42:48 -0700 (PDT)
Subject: [R] Robust or Sandwich estimates in lmer2
Message-ID: <409000.49252.qm@web58106.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070919/f7cf5483/attachment.pl 

From wl2776 at gmail.com  Wed Sep 19 20:00:52 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Wed, 19 Sep 2007 11:00:52 -0700 (PDT)
Subject: [R] How to pass a string as an argument to a function?
In-Reply-To: <7FFB48E5-2694-4316-B647-482BBC8D5FF8@mail.nih.gov>
References: <7FFB48E5-2694-4316-B647-482BBC8D5FF8@mail.nih.gov>
Message-ID: <12782865.post@talk.nabble.com>


lme(as.formula(paste("y~",ww)),random=~1|subj,model)


Gang Chen-3 wrote:
> 
> I want to pass a predefined string ww ("fa*fb+fc") to function lme so  
> that I can run
> 
>  > lme(y ~  fa*fb+fc, random = ~1|subj, model)
> 
> There must be a simple way to do this. Any help?
> 
> Thanks,
> Gang
> 

-- 
View this message in context: http://www.nabble.com/How-to-pass-a-string-as-an-argument-to-a-function--tf4482519.html#a12782865
Sent from the R help mailing list archive at Nabble.com.


From gangchen at mail.nih.gov  Wed Sep 19 20:08:41 2007
From: gangchen at mail.nih.gov (Gang Chen)
Date: Wed, 19 Sep 2007 14:08:41 -0400
Subject: [R] How to pass a string as an argument to a function?
In-Reply-To: <12782865.post@talk.nabble.com>
References: <7FFB48E5-2694-4316-B647-482BBC8D5FF8@mail.nih.gov>
	<12782865.post@talk.nabble.com>
Message-ID: <721F180B-2670-42B3-BA57-D3F6F3AD40D0@mail.nih.gov>

Yes, as.formula is the magic tool! Thanks a lot...

Gang

On Sep 19, 2007, at 2:00 PM, Vladimir Eremeev wrote:

>
> lme(as.formula(paste("y~",ww)),random=~1|subj,model)
>
>
> Gang Chen-3 wrote:
>>
>> I want to pass a predefined string ww ("fa*fb+fc") to function lme so
>> that I can run
>>
>>> lme(y ~  fa*fb+fc, random = ~1|subj, model)
>>
>> There must be a simple way to do this. Any help?
>>
>> Thanks,
>> Gang


From Greg.Snow at intermountainmail.org  Wed Sep 19 20:53:40 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 19 Sep 2007 12:53:40 -0600
Subject: [R] layout function for several plots
In-Reply-To: <20070919112629.215180@gmx.net>
References: <20070919112629.215180@gmx.net>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBF9983@LP-EXCHVS07.CO.IHC.COM>

Using ann=F just tells R not to put anything in the margins, it does not reduce the size of the margins.  You need to reduce the margin size using par(mar= ...) with appropriate values.  You can then shrink what goes in the margins rather than not plotting it at all (though that is a good first step to make sure everything else works).

For adding the cross, look at the cnvrt.coords function in the TeachingDemos package, will that do what you want? (look at the examples)

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of marcg
> Sent: Wednesday, September 19, 2007 5:26 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] layout function for several plots
> 
> Dear all
> 
> I try to print 9 plots on a page, arranged as the code shows below.
> 
> nf <- layout(matrix(c(1,0,2,0,0,3,0,4,0,5,0,6,0,0,0,0,7,0,8,9), 10,2))
> layout.show(nf)
> 
> but when I try to plot, an error message Fehler in plot.new() 
> : Grafikr?nder zu gro? appears
> 
> to verify p.e. with 
> 
> plot(runif(10:1)) 
> 
> i tried with plot(runif(10:1), ann=F) to produce more space, 
> but neither.
> 
> The second question: how to place a cross in the middle of 
> the plot to delineate in 4 big fields (containing each 5 plots)
> 
> Thanks a lot
> 
> 
> --
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> --
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From nestor at ual.es  Wed Sep 19 22:09:24 2007
From: nestor at ual.es (Nestor Fernandez)
Date: Wed, 19 Sep 2007 22:09:24 +0200
Subject: [R] Smooth line in graph
Message-ID: <46F181F4.9000904@ual.es>

Hi,

I?m trying to get smooth curves connecting points in a plot using 
"spline" but I don?t get what I whant.

Eg.:
x<-1:5
y <- c(0.31, 0.45, 0.84, 0.43, 0.25)
plot(x,y)
lines(spline(x,y))

Creates a valley between the first and second points, then peaks at 3rd, 
and another valley between 4th and 5th. I?m trying to get a consistently 
growing curve up to the 3rth point and then a decrease like with 
SigmaPlot spline curves or with Excel.

I tried with different spline arguments and also lowess and loess, with 
no success. Any ideas?

Thanks.


From ripley at stats.ox.ac.uk  Wed Sep 19 22:12:42 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Sep 2007 21:12:42 +0100 (BST)
Subject: [R] layout function for several plots
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBBF9983@LP-EXCHVS07.CO.IHC.COM>
References: <20070919112629.215180@gmx.net>
	<07E228A5BE53C24CAD490193A7381BBBBF9983@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <Pine.LNX.4.64.0709192107550.20525@gannet.stats.ox.ac.uk>

On Wed, 19 Sep 2007, Greg Snow wrote:

> Using ann=F just tells R not to put anything in the margins, it does not 
> reduce the size of the margins.  You need to reduce the margin size 
> using par(mar= ...) with appropriate values.  You can then shrink what 
> goes in the margins rather than not plotting it at all (though that is a 
> good first step to make sure everything else works).

However, if you try to plot 9 plots on one device surface, you almost 
certainly need to reduce the pointsize.  par(mfrow=) does that 
automatically, but layout() does not.  If the device you are using does 
not support pointsize, try a global setting of cex.  You could also 
increase the device dimensions, but other settings (e.g. the default line 
width) will not be appropriate unless the intention is to zoom in on 
individual plots.
a

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kate at few.vu.nl  Wed Sep 19 22:25:00 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Wed, 19 Sep 2007 22:25:00 +0200 (CEST)
Subject: [R] Smooth line in graph
In-Reply-To: <46F181F4.9000904@ual.es>
References: <46F181F4.9000904@ual.es>
Message-ID: <Pine.GSO.4.56.0709192223110.15599@laurel.few.vu.nl>

how about:

require(splines)
x<-1:5
y <- c(0.31, 0.45, 0.84, 0.43, 0.25)
yy <-predict(interpSpline(x, y))
plot(x, y)
lines(yy)


----
Katharine Mullen
mail: Department of Physics and Astronomy, Faculty of Sciences
Vrije Universiteit Amsterdam, de Boelelaan 1081
1081 HV Amsterdam, The Netherlands
room: T.1.06
tel: +31 205987870
fax: +31 205987992
e-mail: kate at nat.vu.nl
homepage: http://www.nat.vu.nl/~kate/


On Wed, 19 Sep 2007, Nestor Fernandez wrote:

> Hi,
>
> I?m trying to get smooth curves connecting points in a plot using
> "spline" but I don?t get what I whant.
>
> Eg.:
> x<-1:5
> y <- c(0.31, 0.45, 0.84, 0.43, 0.25)
> plot(x,y)
> lines(spline(x,y))
>
> Creates a valley between the first and second points, then peaks at 3rd,
> and another valley between 4th and 5th. I?m trying to get a consistently
> growing curve up to the 3rth point and then a decrease like with
> SigmaPlot spline curves or with Excel.
>
> I tried with different spline arguments and also lowess and loess, with
> no success. Any ideas?
>
> Thanks.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From markus.jantti at iki.fi  Wed Sep 19 22:32:28 2007
From: markus.jantti at iki.fi (=?ISO-8859-1?Q?Markus_J=E4ntti?=)
Date: Wed, 19 Sep 2007 16:32:28 -0400
Subject: [R] Sweave: tables vs matrices
In-Reply-To: <1189766752.2943.14.camel@graptoleberis.geog.ucl.ac.uk>
References: <F05CE336-87C3-4E63-979F-D427EB0EBD6F@noc.soton.ac.uk>	<1189759923.2943.6.camel@graptoleberis.geog.ucl.ac.uk>	<B81933C6-46E0-493E-A06B-4AAB9A5EDA7F@noc.soton.ac.uk>
	<1189766752.2943.14.camel@graptoleberis.geog.ucl.ac.uk>
Message-ID: <46F1875C.6070205@iki.fi>

Gavin Simpson wrote:
> On Fri, 2007-09-14 at 11:24 +0100, Robin Hankin wrote:
>> Hi Gavin
>>
>> thanks for that. . . it does 99% of what I wanted.
>> I'd forgotten about the na.print argument.
>>
>> It's considerably nicer than my other solution
>> which converted to character, then jj[is.na(jj)] <- "-"
>> then noquote(jj).
>>
>> But  sometimes I just need nice LaTeX tables
>> and I can't think of a way to arrange things
>> so that: (i) I have only one set of numbers to maintain,
>> and (ii) an NA appears as a "-" in the LaTeX table.
> 
> Ok, then the xtable package and function is your answer. You can use
> this within Sweave but I think you need to set the output to latex in
> the Sweave chunk?
> 
> Is this closer to what you want?
> 
>> print.xtable(xtable(jj), NA.string = "-")
> % latex table generated in R 2.5.1 by xtable 1.4-6 package
> % Fri Sep 14 11:43:34 2007
> \begin{table}[ht]
> \begin{center}
> \begin{tabular}{rrrrrr}
>   \hline
>  & 1 & 2 & 3 & 4 & 5 \\
>   \hline
> 1 & 2.00 & 3.00 & 4.00 & 1.00 & 10.00 \\
>   2 & 0.00 & 5.00 & 7.00 & $-$ & 12.00 \\
>   3 & 3.00 & 7.00 & $-$ & 4.00 & 14.00 \\
>   4 & 2.00 & $-$ & $-$ & 2.00 & 4.00 \\
>   5 & 7.00 & 15.00 & 11.00 & 7.00 & 40.00 \\
>    \hline
> \end{tabular}
> \end{center}
> \end{table}
> 

Another approach that I use a lot is to use the latex facilities in Hmisc by 
Frank Harrell.

For example,

\documentclass{article}

\begin{document}
\SweaveOpts{fig=FALSE, results=hide, echo=FALSE}

<<>>=

library(Hmisc)
Z <- matrix(rnorm(20), ncol=4)
rownames(Z) <- letters[1:nrow(Z)]
colnames(Z) <- LETTERS[1:ncol(Z)]

@

<<results=tex>>=
latex(A, dec=3, center='none', table.env=FALSE, file="")

@

<<results=tex>>=

latex(A, dec=1, cgroup=c("Column labels"), n.cgroup=c(ncol(Z)),
       caption="A title", center='centering', file="")


@
\end{document}

Markus

> HTH
> 
> G
> 
>> best wishes
>>
>> rksh
>>
>> On 14 Sep 2007, at 09:52, Gavin Simpson wrote:
>>
>>> On Fri, 2007-09-14 at 09:34 +0100, Robin Hankin wrote:
>>>> Hello everyone
>>>>
>>>>
>>>> I am preparing a document using Sweave in which I want my matrices
>>>> to appear as tables.  I am running into problems because as my
>>>> Rnw files stand, I have to  change table entries twice, once for
>>>> the matrix and once for the typeset table.
>>>>
>>>> I have lots of material like the following.  How can I arrange
>>>> my Rnw file so that  I only have to change one set of figures
>>>> when my numbers change?
>>>>
>>>> One reason I prefer tables here is that the NA entries
>>>> appear as "-" in the table, but as "NA" in the Schunk.
>>>> Is there a way to make the Schunk  typeset NAs
>>>> as minuses?
>>> See ?print.default and its argument na.print:
>>>
>>>> print.default(jj, na.print = "-")
>>>      [,1] [,2] [,3] [,4] [,5]
>>> [1,]    2    3    4    1   10
>>> [2,]    0    5    7    -   12
>>> [3,]    3    7    -    4   14
>>> [4,]    2    -    -    2    4
>>> [5,]    7   15   11    7   40
>>>
>>> Is that what you meant? It still prints the [1,] bits...
>>>
>>> HTH
>>>
>>> G
>>>
>>>>
>>>>
>>>> \begin{table}
>>>> \centering
>>>> \begin{tabular}{|cccc|c|}\hline
>>>> \multicolumn{4}{|c|}{brand}&\\ \hline
>>>> A&B&C&D&total\\ \hline
>>>> 2       & 3      &  4       & 1    & 10   \\
>>>> 0       & 5       & 7       & -    & 12   \\
>>>> 3       & 7       & -       & 4    & 14   \\
>>>> 2       & -       & -       & 2    &  4    \\ \hline
>>>> 7&15&11&7&40\\ \hline
>>>> \end{tabular}
>>>> \caption{snipped caption}
>>>> \end{table}
>>>>
>>>>
>>>> <<>>=
>>>> jj <- matrix(c(2,  3,  4, 1,
>>>>                 0,  5,  7, NA,
>>>>                 3,  7, NA, 4,
>>>>                 2, NA, NA, 2
>>>>                 ),byrow=TRUE,nrow=4)
>>>> jj <- rbind(jj,apply(jj,2,sum,na.rm=TRUE))
>>>> jj <- cbind(jj,apply(jj,1,sum,na.rm=TRUE))
>>>> jj
>>>> @
>>>>
>>>>
>>>>
>> --
>> Robin Hankin
>> Uncertainty Analyst
>> National Oceanography Centre, Southampton
>> European Way, Southampton SO14 3ZH, UK
>>   tel  023-8059-7743
>>


-- 
Markus Jantti
Abo Akademi University
markus.jantti at iki.fi
http://www.iki.fi/~mjantti


From Greg.Snow at intermountainmail.org  Wed Sep 19 23:12:12 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 19 Sep 2007 15:12:12 -0600
Subject: [R] Smooth line in graph
In-Reply-To: <46F181F4.9000904@ual.es>
References: <46F181F4.9000904@ual.es>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBF99D0@LP-EXCHVS07.CO.IHC.COM>

Try:

> lines(spline(x,y, method='n', n=250))

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Nestor Fernandez
> Sent: Wednesday, September 19, 2007 2:09 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Smooth line in graph
> 
> Hi,
> 
> I'm trying to get smooth curves connecting points in a plot 
> using "spline" but I don't get what I whant.
> 
> Eg.:
> x<-1:5
> y <- c(0.31, 0.45, 0.84, 0.43, 0.25)
> plot(x,y)
> lines(spline(x,y))
> 
> Creates a valley between the first and second points, then 
> peaks at 3rd, and another valley between 4th and 5th. I'm 
> trying to get a consistently growing curve up to the 3rth 
> point and then a decrease like with SigmaPlot spline curves 
> or with Excel.
> 
> I tried with different spline arguments and also lowess and 
> loess, with no success. Any ideas?
> 
> Thanks.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From PConnolly at hortresearch.co.nz  Wed Sep 19 23:14:33 2007
From: PConnolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 20 Sep 2007 09:14:33 +1200
Subject: [R] fontsize in mosaic plot lables
Message-ID: <2376fb2d0001bcd7@hortresearch.co.nz>

> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of 
> Alexander.Herr at csiro.au
> Sent: Wednesday, 19 September 2007 2:04 p.m.
> To: r-help at stat.math.ethz.ch
> Subject: [R] fontsize in mosaic plot lables
> 
> Hi List,
> 
> I am trying unsucessfully to modify the fontsize of lables in mosaic:
> 
> 
> require(vcd)
> mosaic(Titanic, pop=FALSE,
> labeling_args=list(rot_labels=c(bottom=90,top=90),
>       set_varnames = c(Sex = "Gender"),
>           gp_text=gpar(fontsize=20))) #can't get it to resize text
> 
> tab <- ifelse(Titanic < 6, NA, Titanic)
> # it works for labeling_cells
> labeling_cells(text = tab, margin =
> 0,gp_text=gpar(fontsize=20))(Titanic)
> 
> What am I doing wrong?

The mosaic function isn't part of lattice.  Try cex.axis in a more or
less normal way instead of gpar settings.  

HTH

___________________________________________________________________
The contents of this e-mail are privileged and/or confidential to the
named recipient and are not to be used by any other person and/or
organisation. If you have received this e-mail in error, please notify
the sender and delete all material pertaining to this e-mail.


From stenka1 at go.com  Wed Sep 19 23:38:39 2007
From: stenka1 at go.com (stephen bond)
Date: Wed, 19 Sep 2007 21:38:39 +0000 (UTC)
Subject: [R] fCalendar
Message-ID: <13320221.1190237919901.JavaMail.?@fh128.dia.he.tucows.com>

is there a straigthforward way to get the holidays for Toronto ? 
like the function for NYSE e.g.

the timeDate class says that setting a finCenter will give the right 
holidays, but how?

thank you very much.
stephen


From r.turner at auckland.ac.nz  Thu Sep 20 00:04:26 2007
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 20 Sep 2007 10:04:26 +1200
Subject: [R] Identify and plotting symbols.
Message-ID: <32DF3CC5-EC25-4B82-9B04-18DDF1329095@auckland.ac.nz>


I have been trying, unsuccessfully, to use identify() to (simply)  
return a list of
the indices of points clicked on and overplot (with say a solid dot)  
each clicked-on
point so that I can see where I've been.  I.e. I don't want to see  
the indices printed
on the screen; I just want the points I've already selected to be  
highlighted.

I tried

	ind <- identify(x,y,labels=rep("\021",length(x)),offset=0)

Two problems:

	(1) Instead of getting a solid dot --- which I thought I should get  
from "\021", I got a
	small rectangle outlined in dotted lines.   (Which I would've  
thought I'd get from
	"\177".)

	I seem to get the dotted rectangle no matter what 3 digit string I  
use in "\xxx".

	(2) Despite setting offset=0 the superimposed symbol is not actually  
superimposed,
	but is jittered off the location of the existing point by a small  
amount.

Another minor annoyance is having to use rep("\021",length(x)) rather  
than simply
"\021".  I.e. the vector supplied for labels does not get  
``recycled'' the way col and
pch etc. are recycled.

Is there any way of resolving these difficulties?

		cheers,

			Rolf Turner

######################################################################
Attention:\ This e-mail message is privileged and confidenti...{{dropped}}


From Jacqueline.Spilak at EC.gc.ca  Thu Sep 20 00:45:42 2007
From: Jacqueline.Spilak at EC.gc.ca (Spilak,Jacqueline [Edm])
Date: Wed, 19 Sep 2007 16:45:42 -0600
Subject: [R] Subset any value and blanks
Message-ID: <4A6AB38B55B49C44A22E021A83CBEDDB021CA4ED@sr-pnr-exch3.prairie.int.ec.gc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070919/d4ae999e/attachment.pl 

From mmeredith at wcs.org  Thu Sep 20 01:04:57 2007
From: mmeredith at wcs.org (Mike Meredith)
Date: Wed, 19 Sep 2007 16:04:57 -0700 (PDT)
Subject: [R] how to find "p" in binomial(n,p)
In-Reply-To: <12787562.post@talk.nabble.com>
References: <12787562.post@talk.nabble.com>
Message-ID: <12787900.post@talk.nabble.com>



I think the function you need is 'help.search'; try:

help.search("binomial")

and look for something obvious in the 'stats' package. A good deal quicker
and easier than posting to an internet forum!

Cheers, Mike.


cathelf wrote:
> 
> Dear all,
> 
> I am trying a find the value "p" in binomial.
> 
> X ~ Bin(n,p)
> 
> I want to find the value "p", so that Pr(X <= k) <= alpha 
> 
> Here, n, k and alpha are known. n, k are integers. alpha is between (0,1).
> 
> Thanks a lot!
> 
> Catherine
> 

-- 
View this message in context: http://www.nabble.com/how-to-find-%22p%22-in-binomial%28n%2Cp%29-tf4484227.html#a12787900
Sent from the R help mailing list archive at Nabble.com.


From Ted.Harding at manchester.ac.uk  Thu Sep 20 01:34:27 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Thu, 20 Sep 2007 00:34:27 +0100 (BST)
Subject: [R] how to find "p" in binomial(n,p)
In-Reply-To: <12787900.post@talk.nabble.com>
Message-ID: <XFMail.070920003427.Ted.Harding@manchester.ac.uk>

On 19-Sep-07 23:04:57, Mike Meredith wrote:
> 
> 
> I think the function you need is 'help.search'; try:
> 
> help.search("binomial")
> 
> and look for something obvious in the 'stats' package.
> A good deal quicker and easier than posting to an internet forum!
> 
> Cheers, Mike.

Well ...

  help.search("root")
  ?uniroot
  ?pbinom

n<-10; k<-4; alpha<-0.95;
f<-function(p){ pbinom(k,n,p)-alpha }
uniroot(f,c(0,1))

## $root
## [1] 0.2224413
## $f.root
## [1] -1.588189e-07
## $iter
## [1] 10
## $estim.prec
## [1] 6.103516e-05

#Check:
pbinom(k,n, 0.2224413)
## [1] 0.9499998


> 
> 
> cathelf wrote:
>> 
>> Dear all,
>> 
>> I am trying a find the value "p" in binomial.
>> 
>> X ~ Bin(n,p)
>> 
>> I want to find the value "p", so that Pr(X <= k) <= alpha 
>> 
>> Here, n, k and alpha are known. n, k are integers. alpha is between
>> (0,1).
>> 
>> Thanks a lot!
>> 
>> Catherine
>> 
> 
> -- 
> View this message in context:
> http://www.nabble.com/how-to-find-%22p%22-in-binomial%28n%2Cp%29-tf44842
> 27.html#a12787900
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 20-Sep-07                                       Time: 00:34:22
------------------------------ XFMail ------------------------------


From Alexander.Herr at csiro.au  Thu Sep 20 01:37:40 2007
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Thu, 20 Sep 2007 09:37:40 +1000
Subject: [R] fontsize in mosaic plot lables
References: <D3BAD63C088F3C48AEB385E881359F8702FE5493@AKLEXB01.hort.net.nz>
Message-ID: <80C7911E901E7E4797B3F88D106CB25D2632D3@exqld2-bne.nexus.csiro.au>

Thanks Patric,

mosaic{vdc} takes gpar parameters. So cex.axis does not work for 

mosaic(Titanic, pop=FALSE,
labeling_args=list(rot_labels=c(bottom=90,top=90),cex.axis=0.5)) 
or
mosaic(Titanic, pop=FALSE,
labeling_args=list(rot_labels=c(bottom=90,top=90)),cex.axis=0.5)

However,
mosaic(Titanic, pop=FALSE,
labeling_args=list(rot_labels=c(bottom=90,top=90),gp_labels=(gpar(fontsi
ze=5))))

works for all labels.

Is there a way to adjust only one set of axis labels?

Thanx and cheers
Herry

-----Original Message-----
From: Patrick Connolly [mailto:PConnolly at hortresearch.co.nz] 
Sent: Thursday, September 20, 2007 7:15 AM
To: Herr, Alexander Herr - Herry (CSE, Townsville);
r-help at stat.math.ethz.ch
Subject: RE: [R] fontsize in mosaic plot lables

> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of 
> Alexander.Herr at csiro.au
> Sent: Wednesday, 19 September 2007 2:04 p.m.
> To: r-help at stat.math.ethz.ch
> Subject: [R] fontsize in mosaic plot lables
> 
> Hi List,
> 
> I am trying unsucessfully to modify the fontsize of lables in mosaic:
> 
> 
> require(vcd)
> mosaic(Titanic, pop=FALSE,
> labeling_args=list(rot_labels=c(bottom=90,top=90),
>       set_varnames = c(Sex = "Gender"),
>           gp_text=gpar(fontsize=20))) #can't get it to resize text
> 
> tab <- ifelse(Titanic < 6, NA, Titanic) # it works for labeling_cells 
> labeling_cells(text = tab, margin =
> 0,gp_text=gpar(fontsize=20))(Titanic)
> 
> What am I doing wrong?

The mosaic function isn't part of lattice.  Try cex.axis in a more or
less normal way instead of gpar settings.  

HTH

___________________________________________________________________
The contents of this e-mail are privileged and/or confidenti...{{dropped}}


From r.turner at auckland.ac.nz  Thu Sep 20 01:46:01 2007
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 20 Sep 2007 11:46:01 +1200
Subject: [R] how to find "p" in binomial(n,p)
In-Reply-To: <12787900.post@talk.nabble.com>
References: <12787562.post@talk.nabble.com> <12787900.post@talk.nabble.com>
Message-ID: <1B3194F9-7A90-439A-81C6-2FB2CD81C1AB@auckland.ac.nz>


On 20/09/2007, at 11:04 AM, Mike Meredith wrote:

>
> I think the function you need is 'help.search'; try:
>
> help.search("binomial")
>
> and look for something obvious in the 'stats' package. A good deal  
> quicker
> and easier than posting to an internet forum!
>

	I don't think so.  I couldn't find anything useful under help.search 
("binomial"), and
	I'm fairly comfortable with R.

	It seems to me that what is required here is to roll your own.

	I defined a function foo():

		foo <- function(p,n,k,alpha){pbinom(k,n,p)-alpha}

	Then I used uniroot to solve foo(p,n,k,alpha) = 0.

	E.g.

		xxx <- uniroot(foo,c(0,1),n=20,k=15,alpha=0.05)

	Then xxx$root is 0.895913.

	Check this out graphically:

		p <- seq(0,1,length=301)
		y <- foo(p,20,15,0.05)
		plot(p,y,type="l")
		abline(h=0)
		abline(v=xxx$root)

	It looks good.

				cheers,

					Rolf Turner
> Cheers, Mike.
>
>
> cathelf wrote:
>>
>> Dear all,
>>
>> I am trying a find the value "p" in binomial.
>>
>> X ~ Bin(n,p)
>>
>> I want to find the value "p", so that Pr(X <= k) <= alpha
>>
>> Here, n, k and alpha are known. n, k are integers. alpha is  
>> between (0,1).
>>
>> Thanks a lot!
>>
>> Catherine
>>


######################################################################
Attention:\ This e-mail message is privileged and confidenti...{{dropped}}


From jholtman at gmail.com  Thu Sep 20 02:09:13 2007
From: jholtman at gmail.com (jim holtman)
Date: Wed, 19 Sep 2007 20:09:13 -0400
Subject: [R] Subset any value and blanks
In-Reply-To: <4A6AB38B55B49C44A22E021A83CBEDDB021CA4ED@sr-pnr-exch3.prairie.int.ec.gc.ca>
References: <4A6AB38B55B49C44A22E021A83CBEDDB021CA4ED@sr-pnr-exch3.prairie.int.ec.gc.ca>
Message-ID: <644e1f320709191709t6f5e5c61w694471a85025fae6@mail.gmail.com>

You can use 'split' to create a list of dataframes and then operate on them:

  Day Month Year Time Hits Misses F.type
1  01    01 1999 0600  120     80   0600
2  01    01 1999 1015  300     10
3  01    01 1999 1216  250     50   1216
4  01    01 1999 1649  380      0
5  01    01 1999 2132 1100     25   2132
> str(x)
'data.frame':   5 obs. of  7 variables:
 $ Day   : chr  "01" "01" "01" "01" ...
 $ Month : chr  "01" "01" "01" "01" ...
 $ Year  : chr  "1999" "1999" "1999" "1999" ...
 $ Time  : chr  "0600" "1015" "1216" "1649" ...
 $ Hits  : chr  "120" "300" "250" "380" ...
 $ Misses: chr  "80" "10" "50" "0" ...
 $ F.type: chr  "0600" "" "1216" "" ...
> x.split <- split(x, x$F.type == "")
> x.split
$`FALSE`
  Day Month Year Time Hits Misses F.type
1  01    01 1999 0600  120     80   0600
3  01    01 1999 1216  250     50   1216
5  01    01 1999 2132 1100     25   2132

$`TRUE`
  Day Month Year Time Hits Misses F.type
2  01    01 1999 1015  300     10
4  01    01 1999 1649  380      0
> x.missing <- x.split$"TRUE"
> x.missing
  Day Month Year Time Hits Misses F.type
2  01    01 1999 1015  300     10
4  01    01 1999 1649  380      0


On 9/19/07, Spilak,Jacqueline [Edm] <Jacqueline.Spilak at ec.gc.ca> wrote:
> Hi everyone
> I need help with subseting a data set.  In my dataset there is a
> specific row that will either have a value or be blank.  I would like to
> subset (or split) the dataset into one dataset with the row that has the
> value and another dataset that has just the blanks.  Now the thing is
> that the row that has the value in it, the value is not always the same,
> it is a time stamp of when something happens.
> Example of Dataset
> Day     Month   Year    Time    Hits    Misses    F-type
> 01      01      1999    0600    120     80        0600
> 01      01      1999    1015    300     10
> 01      01      1999    1216    250     50        1216
> 01      01      1999    1649    380     0
> 01      01      1999    2132    1100    25        2132
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From jspies at nd.edu  Thu Sep 20 04:09:33 2007
From: jspies at nd.edu (Jeffrey Robert Spies)
Date: Wed, 19 Sep 2007 22:09:33 -0400
Subject: [R] Need help on "date"
In-Reply-To: <d4c57560709180746m10f6ef4q697ea185ee366cad@mail.gmail.com>
References: <d4c57560709180200q2adf68f7ua2a8d823ac488229@mail.gmail.com>
	<8BF641FC-CC32-4F56-B13A-A1D9A7182FAE@nd.edu>
	<d4c57560709180746m10f6ef4q697ea185ee366cad@mail.gmail.com>
Message-ID: <1A25255A-B4DD-4CE0-8526-BF4B5E42E720@nd.edu>

Sub uses POSIX-extended regular expressions.  It searches for the  
first argument, the pattern, and replaces it with the second argument  
in the variable defined by the third argument.  [[:digit:]] is a  
match-any-digit operator; it matches the characters 0-9.  The {#} is  
the interval operator, where what's inside the bracket's is a count.   
So [[:digit:]]{4} means match 4 digits.  All together, ([[:digit:]] 
{4})-([[:digit:]]{2})-([[:digit:]]{2}) means "Match 4 digits followed  
by a dash followed by 2 digits followed by a dash followed by 2 digits.
By surrounding pieces of the search pattern in parentheses, we create  
back-references, which can be used in the replacement (second  
argument) like variables, \\1 to \\9, in the order that they appear  
in the pattern. When we replace the pattern with '\\1', that means  
return what is in the first set of parentheses, or the first four  
digits before a dash before two digits before a dash before another  
two digits.

Note: most of the time, we'd use single slashes to escape a character  
(i.e. \1), but R needs double slashes (i.e. \\1).

If you're interested in regular expressions, this site is quite  
useful: http://www.cs.utah.edu/dept/old/texinfo/regex/regex_toc.html.

Make sense?

Jeff.

On Sep 18, 2007, at 10:46 AM, Arun Kumar Saha wrote:

> Dear Jeffrey,
>
> Your syntax looks very extraordinary to me. I would be very happy  
> if you can explain this notation.
>
> Regards,
>
> On 9/18/07, Jeffrey Robert Spies <jspies at nd.edu> wrote:And one  
> using regular expressions:
>
> x <- "2005-09-01"
> pattern <- '([[:digit:]]{4})-([[:digit:]]{2})-([[:digit:]]{2})'
> y <- sub(pattern, '\\1', x)
> m <- sub(pattern, '\\2', x)
> d <- sub(pattern, '\\3', x)
>
> -- Jeff.
>
> On Sep 18, 2007, at 5:00 AM, Arun Kumar Saha wrote:
>
> > Dear all,
> >
> > I have a variable 'x' like that:
> >
> >> x
> > [1] "2005-09-01"
> >
> > Here, 2005 represents year, 09 month and 01 day.
> >
> > Now I want to create three variables naming: y, m, and d such that:
> >
> > y = 2005
> > m = 09
> > d = 01
> >
> > can anyone tell me how to do that?
> >
> > Regards,
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>


From pomchip at free.fr  Thu Sep 20 04:18:41 2007
From: pomchip at free.fr (=?ISO-8859-1?Q?S=E9bastien?=)
Date: Wed, 19 Sep 2007 22:18:41 -0400
Subject: [R] Factor levels
In-Reply-To: <971536df0708281416u51957df5s950ee509e9180ebb@mail.gmail.com>
References: <46D45D18.1030206@free.fr>	
	<971536df0708281103i2f3bfd75h2354088de09073a7@mail.gmail.com>	
	<46D4803D.9080302@free.fr>	
	<971536df0708281316m19b470b8m5a3d6966a36b1860@mail.gmail.com>	
	<46D48CD1.60001@free.fr>
	<971536df0708281416u51957df5s950ee509e9180ebb@mail.gmail.com>
Message-ID: <46F1D881.701@free.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070919/2e3957f9/attachment.pl 

From morphwj at comcast.net  Thu Sep 20 04:19:18 2007
From: morphwj at comcast.net (morphwj at comcast.net)
Date: Thu, 20 Sep 2007 02:19:18 +0000
Subject: [R] What is the preferred method to view a pdf (not a vignette) in
	a package /doc ?
Message-ID: <092020070219.8709.46F1D8A6000390250000220522058861720699089F9D0103@comcast.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070920/77644826/attachment.pl 

From cberry at tajo.ucsd.edu  Thu Sep 20 05:17:28 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Wed, 19 Sep 2007 20:17:28 -0700
Subject: [R] how to find "p" in binomial(n,p)
In-Reply-To: <1B3194F9-7A90-439A-81C6-2FB2CD81C1AB@auckland.ac.nz>
References: <12787562.post@talk.nabble.com> <12787900.post@talk.nabble.com>
	<1B3194F9-7A90-439A-81C6-2FB2CD81C1AB@auckland.ac.nz>
Message-ID: <Pine.LNX.4.64.0709192001190.14499@tajo.ucsd.edu>

On Thu, 20 Sep 2007, Rolf Turner wrote:

>
> On 20/09/2007, at 11:04 AM, Mike Meredith wrote:
>
>>
>> I think the function you need is 'help.search'; try:
>>
>> help.search("binomial")
>>
>> and look for something obvious in the 'stats' package. A good deal
>> quicker
>> and easier than posting to an internet forum!
>>
>
> 	I don't think so.  I couldn't find anything useful under help.search
> ("binomial"), and
> 	I'm fairly comfortable with R.


After 20-odd years of R, Splus, and S, I'd say I am more enthusiastic than 
'comfortable', but trying 'help.search("binomial")' I get:

----
Help files with alias or concept or title matching 'binomial' using fuzzy 
matching:

[stuff omitted]

binom.test(stats)                   Exact Binomial Test


----

And after reading the help page:

> binom.test(15,20,conf=.95,alt='less') # Rolf's example

         Exact binomial test

data:  15 and 20
number of successes = 15, number of trials = 20, p-value = 0.994
alternative hypothesis: true probability of success is less than 0.5
95 percent confidence interval:
  0.0000000 0.8959192

...........^^^^^^^^^... matches Rolf's example

sample estimates:
probability of success
                   0.75

> binom.test(4,10,conf=.05,alt='le') # Ted's Example

         Exact binomial test

data:  4 and 10
number of successes = 4, number of trials = 10, p-value = 0.3770
alternative hypothesis: true probability of success is less than 0.5
5 percent confidence interval:
  0.0000000 0.2224411
...........^^^^^^^^^......... matches Ted's Example

sample estimates:
probability of success
                    0.4

So, it really can be found using 'help.search'.

Although in view of the 'Zen in the Art of Motorcycle Maintenance' effect 
(if it is only obvious if you know something, then it is not really 
obvious) I must note that one must recognize that "Pr(X <= k) <= alpha" is 
the confidence statement.

But of course, if one 'knew something' it is

 	help.search("beta")

that would be tried. :-)


HTH,

Chuck


>
> 	It seems to me that what is required here is to roll your own.
>
> 	I defined a function foo():
>
> 		foo <- function(p,n,k,alpha){pbinom(k,n,p)-alpha}
>
> 	Then I used uniroot to solve foo(p,n,k,alpha) = 0.
>
> 	E.g.
>
> 		xxx <- uniroot(foo,c(0,1),n=20,k=15,alpha=0.05)
>
> 	Then xxx$root is 0.895913.
>
> 	Check this out graphically:
>
> 		p <- seq(0,1,length=301)
> 		y <- foo(p,20,15,0.05)
> 		plot(p,y,type="l")
> 		abline(h=0)
> 		abline(v=xxx$root)
>
> 	It looks good.
>
> 				cheers,
>
> 					Rolf Turner
>> Cheers, Mike.
>>
>>
>> cathelf wrote:
>>>
>>> Dear all,
>>>
>>> I am trying a find the value "p" in binomial.
>>>
>>> X ~ Bin(n,p)
>>>
>>> I want to find the value "p", so that Pr(X <= k) <= alpha
>>>
>>> Here, n, k and alpha are known. n, k are integers. alpha is
>>> between (0,1).
>>>
>>> Thanks a lot!
>>>
>>> Catherine
>>>
>
>
> ######################################################################
> Attention:\ This e-mail message is privileged and confidenti...{{dropped}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From ggrothendieck at gmail.com  Thu Sep 20 05:18:51 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 19 Sep 2007 23:18:51 -0400
Subject: [R] Factor levels
In-Reply-To: <46F1D881.701@free.fr>
References: <46D45D18.1030206@free.fr>
	<971536df0708281103i2f3bfd75h2354088de09073a7@mail.gmail.com>
	<46D4803D.9080302@free.fr>
	<971536df0708281316m19b470b8m5a3d6966a36b1860@mail.gmail.com>
	<46D48CD1.60001@free.fr>
	<971536df0708281416u51957df5s950ee509e9180ebb@mail.gmail.com>
	<46F1D881.701@free.fr>
Message-ID: <971536df0709192018w2c4680dek821b971fc6735f1d@mail.gmail.com>

If you don't know ahead of time how many columns you have and
only that they are a mix of numeric and character (to be converted to
factor) then you can do this:

DF <- read.table(textConnection(Input), header = TRUE, as.is = TRUE)
f <- function(x) if (is.character(x)) factor(x, levels = unique(x)) else x
DF[] <- lapply(DF, f)
DF





On 9/19/07, S?bastien <pomchip at free.fr> wrote:
> Hi Gabor,
>
> I am coming back to you about the method you described to me a month ago to
> define the level order during a read.table call. I initially thought that I
> would need to apply the 'unique' function on a single column of my dataset,
> so I only used it after the read.table step (to make my life easier)...
> Well, I was wrong: I need to reorder all my columns (just to remind you, I
> don't know the numbers of columns my code has to handle). So, here come
> troubles.
>
> I first tried to apply your code as is, although I thought there might be
> some problems. The class can actually not be recycled, when a list notation
> is used (the help says that "colClasses character. A vector of classes to be
> assumed for the columns. Recycled as necessary..."). See the following
> example:
>
> ######################
>
> library(methods)
>
> setClass("my.factor")
>
> setAs("character", "my.factor",
>
>  function(from) factor(from, levels = unique(from)))
>
>
>
> Input<-"a b c d
>
> 1 1 175 n f
>
> 2 2 102 n j
>
> 3 3 187 o n
>
> 4 4 106 u g
>
> 5 5 102 o v
>
> 6 6 133 l x
>
> 7 7 149 w q
>
> 8 8 122 x p
>
> 9 9 151 u r
>
> 10 10 134 e g
>
> 11 11 170 j q
>
> 12 12 103 v n
>
> 13 13 153 n w
>
> 14 14 106 x x
>
> 15 15 185 v x
>
> 16 16 102 s p
>
> 17 17 181 i h
>
> 18 18 192 o k
>
> 19 19 161 d f
>
> 20 20 158 n q
>
> "
>
>
>
> DF <- read.table(textConnection(Input), header = TRUE, colClasses =
> list(c=("my.factor")))
> levels(DF$c)         # properly ordered
>
>
> levels(DF$d)         # not reordered
>
> ######################
>
> I also tried that:
>
> ######################
>
> DF <- read.table(textConnection(Input), header = TRUE, colClasses =
> c("my.factor"))
> levels(DF$c)
>
> levels(DF$d)
>
> ######################
>
> In this case, the class is definitely recycled as all the columns of DF are
> transformed into factors... Not really useful :)
> I tried to modify the content of the list or my second notation, by
> including "integer" or a second "my.factor"... but I did not have much
> success.
> Any idea how to use the class "my.factor" multiple times ?
>
> Thanks in advance
>
>
> Gabor Grothendieck a ?crit :
> Its the same principle. Just change the function to be suitable. This
> one
arranges the levels according to the
> input:

library(methods)
setClass("my.factor")
setAs("character",
> "my.factor",
 function(from) factor(from, levels = unique(from)))

Input <-
> "a b c
1 1 176 w
2 2 141 k
3 3 172 r
4 4 182 s
5 5 123 k
6 6 153 p
7 7 176
> l
8 8 170 u
9 9 140 z
10 10 194 s
11 11 164 j
12 12 100 j
13 13 127 x
14 14
> 137 r
15 15 198 d
16 16 173 j
17 17 113 x
18 18 144 w
19 19 198 q
20 20 122
> f
"
DF <- read.table(textConnection(Input), header = TRUE,
 colClasses =
> list(c = "my.factor"))
str(DF)


On 8/28/07, S?bastien <pomchip at free.fr>
> wrote:

> Ok, I cannot send to you one of my dataset since they are confidential.
> But
I can produce a dummy "mini" dataset to illustrate my question. Let's
> say I
have a csv file with 3 columns and 20 rows which content is reproduced
> by
the following line.


> mydata<-data.frame(a=1:20,

> b=sample(100:200,20,replace=T),c=sample(letters[1:26],
> 20,
replace = T))

> mydata

>  a b c
1 1 176 w
2 2 141 k
3 3 172 r
4 4 182 s
5 5 123 k
6 6 153 p
7 7 176
> l
8 8 170 u
9 9 140 z
10 10 194 s
11 11 164 j
12 12 100 j
13 13 127 x
14 14
> 137 r
15 15 198 d
16 16 173 j
17 17 113 x
18 18 144 w
19 19 198 q
20 20 122
> f

If I had to read the csv file, I would use something
> like:
mydata<-data.frame(read.table(file="c:/test.csv",header=T))

Now, if
> you look at mydata$c, the levels are alphabetically ordered.

> mydata$c

>  [1] w k r s k p l u z s j j x r d j x w q f
Levels: d f j k l p q r s u w x
> z

What I am trying to do is to reorder the levels as to have them in the
> order
they appear in the table, ie
Levels: w k r s p l u z j x d q f

Again,
> keep in mind that my script should be used on datasets which content
are
> unknown to me. In my example, I have used letters for mydata$c, but my
code
> may have to handle factors of numeric or character values (I need
> to
transform specific columns of my dataset into factors for
> plotting
purposes). My goal is to let the code scan the content of each
> factor of my
data.frame during or after the read.table step and reorder
> their levels
automatically without having to ask the user to hard-code the
> level order.

In a way, my problem is more related to the way the factor
> levels are
ordered than to the read.table function, although I guess there
> is a link...

Gabor Grothendieck a ?crit :
Its not clear from your
> description what you want.

> Could you be a bit more

> specific including an example.

> On 8/28/07, S?bastien <pomchip at free.fr>

> wrote:

>
> Thanks Gabor, I have two questions:

> 1- Is there any difference between your

> code and the following one, with

> regards to Fld2 ?
### test ###


> Input <- "Fld1 Fld2

> 10 A
20 B
30 C
40 A
"
DF <-


> read.table(textConnection(Input), header =

> TRUE)


> DF$Fld2<-factor(DF$Fld2,levels= c("C", "A", "B")))

>
> 2- do you see any way to bring flexibility to your method ? Because,
it

> looks to me as, at this stage, I have to i) know the order of my

> levels

> before I read the table and ii) create one class per factor.
My

> problem is that I am not really working on a specific dataset. My goal is

> to

> develop R scripts capable of handling datasets which have various

> contents

> but close structures. So, I really need to minimize the quantity
of

> "user-specific" code.

Sebastien

Gabor Grothendieck a ?crit :
You can

> create your own class and pass that to read table. In

>
> the example

>
> below Fld2 is read in with factor levels C, A, B

>
> in that

>
> order.

>
> library(methods)
setClass("my.levels")
setAs("character",


> "my.levels",

>
>  function(from) factor(from, levels = c("C", "A", "B")))

>
###


> test ###

>
> Input <- "Fld1 Fld2

> 10 A
20 B
30 C
40 A
"
DF <-


> read.table(textConnection(Input), header = TRUE,

>
>  colClasses = c("numeric",

>
> "my.levels"))

>
> str(DF)

> # or
DF <- read.table(textConnection(Input), header =


> TRUE,

>
>  colClasses = list(Fld2 = "my.levels"))

> str(DF)


On 8/28/07,


> S?bastien <pomchip at free.fr> wrote:

>
> Dear R-users,

>
> I have found this not-so-recent post in the archives

>
> -

>
> http://tolstoy.newcastle.edu.au/R/devel/00a/0291.html -

>
> while I was

>
> looking for a particular way to reorder factor levels. The

>
> question

>
> addressed by the author was to know if the read.table function

>
> could be

>
> modified to order the levels of newly created factors "according to

>
> the

>
> order that they appear in the data file". Exactly what I am looking

>
> for.

>
> As there was no reply to this post, I wonder if any move have been

>
> made

>
> towards the implementation of this suggestion. A quick look

>
> at

>
> ?read.table tells me that if this option was implemented, it was not

>
> in

>
> the read.table function...

> Sebastien

PS: I am sorry to post so many


> messages on the list, but I am learning R

>
> (basically by trials & errors ;-)

>
> ) and no one around me has even a

>
> slight notion about

>
> it...

>
> ______________________________________________

> R-help at stat.math.ethz.ch

> mailing

> list


> https://stat.ethz.ch/mailman/listinfo/r-help

> PLEASE do


> read the posting
guide

> http://www.R-project.org/posting-guide.html


> and provide

>
> commented, minimal, self-contained, reproducible code.

>
>
>
>
>

>


From bolker at ufl.edu  Thu Sep 20 05:47:00 2007
From: bolker at ufl.edu (bbolker)
Date: Wed, 19 Sep 2007 20:47:00 -0700 (PDT)
Subject: [R] R-related: problem with openvt on Ubuntu 7.04
Message-ID: <12790390.post@talk.nabble.com>


   This is a configuration/OS problem, but it's affecting my use of R ...

  Whenever I try to open _any_ vignette (as far as I can tell)
from within R, I get "Could not get a file descriptor referring to the
console",
coming from /usr/bin/openvt, which is pointed to by /usr/bin/open,
which is called by print.vignette to display the vignette.

   On the other hand, openvt fails in the same way from the command line,
with
_any_ command ("openvt bash"), so I know it's not really an R problem.
Nevertheless, maybe someone has an answer?

   system("evince") or system("acroread") both seem to work fine, so I guess
in a pinch I could hack print.vignette ...

RSiteSearching finds practically nothing and
Googling around finds nothing terribly useful ... 
this is on a fairly standard Ubuntu 7.04 install.

  thanks
    Ben Bolker



> sessionInfo()
R version 2.5.1 (2007-06-27) 
i486-pc-linux-gnu 

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[7] "base"     
> vignette()
> library(grid)
> vignette("frame")
> Couldnt get a file descriptor referring to the console
Could not get a file descriptor referring to the console

-- 
View this message in context: http://www.nabble.com/R-related%3A-problem-with-openvt-on-Ubuntu-7.04-tf4485216.html#a12790390
Sent from the R help mailing list archive at Nabble.com.


From ggrothendieck at gmail.com  Thu Sep 20 06:00:33 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 20 Sep 2007 00:00:33 -0400
Subject: [R] Need help on "date"
In-Reply-To: <1A25255A-B4DD-4CE0-8526-BF4B5E42E720@nd.edu>
References: <d4c57560709180200q2adf68f7ua2a8d823ac488229@mail.gmail.com>
	<8BF641FC-CC32-4F56-B13A-A1D9A7182FAE@nd.edu>
	<d4c57560709180746m10f6ef4q697ea185ee366cad@mail.gmail.com>
	<1A25255A-B4DD-4CE0-8526-BF4B5E42E720@nd.edu>
Message-ID: <971536df0709192100m444051e4u3d9bcd22ca429e54@mail.gmail.com>

If you are interested in regular expressions you may also be
interested in a solution using the gsubfn package.  Here x
is the input character string, re is Jeffrey's regular expression
and strapply applies the regular expression to x calling the function
which is represented in formula notation using the free variables
year, month and day as the arguments.  backref = -3 says
only pass the 3 backreferences, i.e. the matched portion within
parens, and not the entire string.  The function is set up to take
a vector input for x but since we only have one element we use [[1]].

library(gsubfn)

x <- "2005-09-01"
re <- "([[:digit:]]{4})-([[:digit:]]{2})-([[:digit:]]{2})"

strapply(x, re, ~ c(year = year, month = month, day = day), backref = -3)[[1]]


On 9/19/07, Jeffrey Robert Spies <jspies at nd.edu> wrote:
> Sub uses POSIX-extended regular expressions.  It searches for the
> first argument, the pattern, and replaces it with the second argument
> in the variable defined by the third argument.  [[:digit:]] is a
> match-any-digit operator; it matches the characters 0-9.  The {#} is
> the interval operator, where what's inside the bracket's is a count.
> So [[:digit:]]{4} means match 4 digits.  All together, ([[:digit:]]
> {4})-([[:digit:]]{2})-([[:digit:]]{2}) means "Match 4 digits followed
> by a dash followed by 2 digits followed by a dash followed by 2 digits.
> By surrounding pieces of the search pattern in parentheses, we create
> back-references, which can be used in the replacement (second
> argument) like variables, \\1 to \\9, in the order that they appear
> in the pattern. When we replace the pattern with '\\1', that means
> return what is in the first set of parentheses, or the first four
> digits before a dash before two digits before a dash before another
> two digits.
>
> Note: most of the time, we'd use single slashes to escape a character
> (i.e. \1), but R needs double slashes (i.e. \\1).
>
> If you're interested in regular expressions, this site is quite
> useful: http://www.cs.utah.edu/dept/old/texinfo/regex/regex_toc.html.
>
> Make sense?
>
> Jeff.
>
> On Sep 18, 2007, at 10:46 AM, Arun Kumar Saha wrote:
>
> > Dear Jeffrey,
> >
> > Your syntax looks very extraordinary to me. I would be very happy
> > if you can explain this notation.
> >
> > Regards,
> >
> > On 9/18/07, Jeffrey Robert Spies <jspies at nd.edu> wrote:And one
> > using regular expressions:
> >
> > x <- "2005-09-01"
> > pattern <- '([[:digit:]]{4})-([[:digit:]]{2})-([[:digit:]]{2})'
> > y <- sub(pattern, '\\1', x)
> > m <- sub(pattern, '\\2', x)
> > d <- sub(pattern, '\\3', x)
> >
> > -- Jeff.
> >
> > On Sep 18, 2007, at 5:00 AM, Arun Kumar Saha wrote:
> >
> > > Dear all,
> > >
> > > I have a variable 'x' like that:
> > >
> > >> x
> > > [1] "2005-09-01"
> > >
> > > Here, 2005 represents year, 09 month and 01 day.
> > >
> > > Now I want to create three variables naming: y, m, and d such that:
> > >
> > > y = 2005
> > > m = 09
> > > d = 01
> > >
> > > can anyone tell me how to do that?
> > >
> > > Regards,
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > > guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Joe.Crombie at brs.gov.au  Thu Sep 20 06:11:17 2007
From: Joe.Crombie at brs.gov.au (Crombie, Joe)
Date: Thu, 20 Sep 2007 14:11:17 +1000
Subject: [R] Identify and plotting symbols. [SEC=UNCLASSIFIED]
Message-ID: <61C2DEA055980B418D063F8646FCAEFC020B5A64@ACT001CL03EX03.agdaff.gov.au>

Rolf turner wrote:

>I have been trying, unsuccessfully, to use identify() to (simply) 
>return a list of the indices of points clicked on and overplot (with 
>say a solid dot) each clicked-on point so that I can see where I've 
>been.  I.e. I don't want to see the indices printed on the screen; I
just want the points I've already selected to be highlighted.
>
>I tried
>
>	ind <- identify(x,y,labels=rep("\021",length(x)),offset=0)


Why not:

ind <- identify(x,y, plot = F)
points(x[ind], y[ind], pch = 19)

Cheers  Joe



Joe Crombie
 
Information and Risk Sciences
Bureau of Rural Science
Canberra  Australia
 
p: +61 2 6272 5906
e: joe.crombie at brs.gov.au

------IMPORTANT - This message has been issued by The Department of Agriculture, Fisheries and Forestry (DAFF). The information transmitted is for the use of the intended recipient only and may contain confidential and/or legally privileged material. It is your responsibility to check any attachments for viruses and defects before opening or sending them on. 

Any reproduction, publication, communication, re-transmission, disclosure, dissemination or other use of the information contained in this e-mail by persons or entities other than the intended recipient is prohibited. The taking of any action in reliance upon this information by persons or entities other than the intended recipient is prohibited. If you have received this e-mail in error please notify the sender and delete all copies of this transmission together with any attachments. If you have received this e-mail as part of a valid mailing list and no longer want to receive a message such as this one advise the sender by return e-mail accordingly. Only e-mail correspondence which includes this footer, has been authorised by DAFF 
------


From anand.prabhakar.patil at gmail.com  Thu Sep 20 06:24:06 2007
From: anand.prabhakar.patil at gmail.com (Anand Patil)
Date: Wed, 19 Sep 2007 21:24:06 -0700
Subject: [R] SHLIB problem under Vista
Message-ID: <2bc7a5a50709192124t5d368b6epe047baf9cd682624@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070919/9ceab47d/attachment.pl 

From PConnolly at hortresearch.co.nz  Thu Sep 20 06:25:48 2007
From: PConnolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 20 Sep 2007 16:25:48 +1200
Subject: [R] fontsize in mosaic plot lables
Message-ID: <2501d11e0001efd1@hortresearch.co.nz>

> From: Alexander.Herr at csiro.au [mailto:Alexander.Herr at csiro.au] 
> Sent: Thursday, 20 September 2007 11:38 a.m.
> To: Patrick Connolly; r-help at stat.math.ethz.ch
> Subject: RE: [R] fontsize in mosaic plot lables
> 
> Thanks Patric,
> 
> mosaic{vdc} takes gpar parameters. So cex.axis does not work for 

OK, my mistake.  I was thinking of mosaicplot in the graphics package.

It's a while since I used it, and I seem to remember it was a bit tricky
also, but I did get it to work in the end using mtext which lets you set
the cex.  But that's no use to you.


___________________________________________________________________
The contents of this e-mail are privileged and/or confidential to the
named recipient and are not to be used by any other person and/or
organisation. If you have received this e-mail in error, please notify
the sender and delete all material pertaining to this e-mail.


From Joe.Crombie at brs.gov.au  Thu Sep 20 06:35:20 2007
From: Joe.Crombie at brs.gov.au (Crombie, Joe)
Date: Thu, 20 Sep 2007 14:35:20 +1000
Subject: [R] Identify and plotting symbols. [SEC=UNCLASSIFIED]
Message-ID: <61C2DEA055980B418D063F8646FCAEFC020B5A65@ACT001CL03EX03.agdaff.gov.au>

Or maybe:

> while(length(ind <- identify(x,y,n = 1, plot = F)))
>   points(x[ind], y[ind], pch = 19)

(highlights each point as you select it, until you click _stop_)

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Crombie, Joe
Sent: Thursday, 20 September 2007 2:11 PM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] Identify and plotting symbols. [SEC=UNCLASSIFIED]

Rolf turner wrote:

>I have been trying, unsuccessfully, to use identify() to (simply) 
>return a list of the indices of points clicked on and overplot (with 
>say a solid dot) each clicked-on point so that I can see where I've 
>been.  I.e. I don't want to see the indices printed on the screen; I
just want the points I've already selected to be highlighted.
>
>I tried
>
>	ind <- identify(x,y,labels=rep("\021",length(x)),offset=0)


Why not:

ind <- identify(x,y, plot = F)
points(x[ind], y[ind], pch = 19)

Cheers  Joe



Joe Crombie
 
Information and Risk Sciences
Bureau of Rural Science
Canberra  Australia
 
p: +61 2 6272 5906
e: joe.crombie at brs.gov.au

------IMPORTANT - This message has been issued by The Department of
Agriculture, Fisheries and Forestry (DAFF). The information transmitted
is for the use of the intended recipient only and may contain
confidential and/or legally privileged material. It is your
responsibility to check any attachments for viruses and defects before
opening or sending them on. 

Any reproduction, publication, communication, re-transmission,
disclosure, dissemination or other use of the information contained in
this e-mail by persons or entities other than the intended recipient is
prohibited. The taking of any action in reliance upon this information
by persons or entities other than the intended recipient is prohibited.
If you have received this e-mail in error please notify the sender and
delete all copies of this transmission together with any attachments. If
you have received this e-mail as part of a valid mailing list and no
longer want to receive a message such as this one advise the sender by
return e-mail accordingly. Only e-mail correspondence which includes
this footer, has been authorised by DAFF
------

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

------IMPORTANT - This message has been issued by The Department of Agriculture, Fisheries and Forestry (DAFF). The information transmitted is for the use of the intended recipient only and may contain confidential and/or legally privileged material. It is your responsibility to check any attachments for viruses and defects before opening or sending them on. 

Any reproduction, publication, communication, re-transmission, disclosure, dissemination or other use of the information contained in this e-mail by persons or entities other than the intended recipient is prohibited. The taking of any action in reliance upon this information by persons or entities other than the intended recipient is prohibited. If you have received this e-mail in error please notify the sender and delete all copies of this transmission together with any attachments. If you have received this e-mail as part of a valid mailing list and no longer want to receive a message such as this one advise the sender by return e-mail accordingly. Only e-mail correspondence which includes this footer, has been authorised by DAFF 
------


From ripley at stats.ox.ac.uk  Thu Sep 20 09:18:39 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Sep 2007 08:18:39 +0100 (BST)
Subject: [R] Identify and plotting symbols.
In-Reply-To: <32DF3CC5-EC25-4B82-9B04-18DDF1329095@auckland.ac.nz>
References: <32DF3CC5-EC25-4B82-9B04-18DDF1329095@auckland.ac.nz>
Message-ID: <Pine.LNX.4.64.0709200731230.27589@gannet.stats.ox.ac.uk>

On Thu, 20 Sep 2007, Rolf Turner wrote:

> I have been trying, unsuccessfully, to use identify() to (simply) return 
> a list of the indices of points clicked on and overplot (with say a 
> solid dot) each clicked-on point so that I can see where I've been. 
> I.e. I don't want to see the indices printed on the screen; I just want 
> the points I've already selected to be highlighted.
>
> I tried
>
> 	ind <- identify(x,y,labels=rep("\021",length(x)),offset=0)
>
> Two problems:
>
> 	(1) Instead of getting a solid dot --- which I thought I should 
> get from "\021", I got a small rectangle outlined in dotted lines. 
> (Which I would've thought I'd get from "\177".)

Why did you think so?

What glyphs (if any) you get from non-ASCII characters depends on the OS, 
locale, graphics device and font, none of which we know.
(It can be even more specific than that: it may depend on what font 
variants you have installed, as on both X11 and Windows there can be 
multiple fonts of the same name with different encodings.)

In particular in a UTF-8 locale (and you seem latterly to be using MacOS X 
which has UTF-8 locales), you probably need to select characters by 
Unicode points, e.g. \u2022 or \u22c5.

> 	I seem to get the dotted rectangle no matter what 3 digit string I
> use in "\xxx".

I am surprised: does "\088" not give "H" ?

> 	(2) Despite setting offset=0 the superimposed symbol is not 
> actually superimposed, but is jittered off the location of the existing 
> point by a small amount.

Ah, what do you mean by 'superimposed'?  What you should find is the 
appropriate edge of the bounding box of the character is on the point 
identified.  See the 'value' section of the help page for what is meant by 
'appropriate edge'.

> Another minor annoyance is having to use rep("\021",length(x)) rather 
> than simply "\021".  I.e. the vector supplied for labels does not get 
> ``recycled'' the way col and pch etc. are recycled.

Which is as documented, and contrasts with e.g. text() which says its 
'labels' argument is recycled.

> Is there any way of resolving these difficulties?

Yes, use identify(plot=FALSE) in a loop and manage the plotting yourself.
Something like

myidentify <- function(x, y, pch=19, n, ...)
{
     res <- integer(0)
     for(i in seq_len(n)) {
         ans <- identify(x, y, plot=FALSE, n=1, ...)
 	if(length(ans) == 0) break
         points(x[ans], y[ans], pch=pch)
 	res <- c(res, ans)
     }
     res
}

and you can refine this by using xy.coords and not allowing repeats.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Sep 20 09:31:57 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Sep 2007 08:31:57 +0100 (BST)
Subject: [R] SHLIB problem under Vista
In-Reply-To: <2bc7a5a50709192124t5d368b6epe047baf9cd682624@mail.gmail.com>
References: <2bc7a5a50709192124t5d368b6epe047baf9cd682624@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709200821260.27589@gannet.stats.ox.ac.uk>

This is a known problem with your compiler installation, discussed in the 
R-admin manual.  From the version in R-patched:

   There are known problems with one of the compilers sets in this toolset
   on Windows Vista: see the workaround below. (With that workaround it has
   been used on both 32- and 64-bit versions of Vista.)

   ...

   On Vista systems you will need to add

   c:\Rtools\MinGW\libexec\gcc\mingw\3.4.5

   to the path.

This is not relevant to the recommended compiler set for R 2.6.0.


On Wed, 19 Sep 2007, Anand Patil wrote:

> Hi all,
>
>
> I'd like to distribute an R package that compiles some (small) C functions
> every time it's sourced. The relevant code in the top level R script is as
> follows:
>
> system("R CMD SHLIB Selma_extensions.c")
> if (.Platform$OS.type=="windows") {
>    slash = '\\'
>    dyn.load("Selma_extensions.dll")
> }
> if (.Platform$OS.type=="unix") {
>    slash = '/'
>    dyn.load("Selma_extensions.so")
> }

Hmm, all the information you need is already in .Platform, $file.sep and 
$dynlib.ext: the latter varies by OS.type.

> This works fine on a Mac, but I tried it under Windows Vista, after
> installing RTools and telling it to put itself on the system path, and got
> the following:
>
> making Selma_extensions.d from Selma_extensions.c
> gcc.exe: installation problem, cannot exec `cc1': No such file or directory
> make: *** [Selma_extensions.d] Error 1
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>        unable to load shared library
> 'C:/Users/anand/Desktop/Selma/Selma_extensions.dll':
>  LoadLibrary failure:  The specified module could not be found.
>
> Can this be fixed without requiring the user to do anything?

The fix requires 'the user' to read the documentation.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From steve at promente.org  Thu Sep 20 09:39:38 2007
From: steve at promente.org (Steve Powell)
Date: Thu, 20 Sep 2007 09:39:38 +0200
Subject: [R] SEM - standardized path coefficients? - significant style
In-Reply-To: <20070919115507.BKEI8273.tomts20-srv.bellnexxia.net@JohnDesktop8300>
References: <00a301c7fa8f$58526290$6501a8c0@STEVE>
	<20070919115507.BKEI8273.tomts20-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <018001c7fb59$6757fff0$6501a8c0@STEVE>

Dear John
Being an R user is like having Christmas every day and having a direct line
to Santa for present suggestions. 
How about if path.diagram.sem had the ability to print non-significant paths
in, for example dotted style? I had a go myself but couldn't see how to get
(summary(model)$coeff)$"Pr(>|z|)" into the loop.
Very best wishes
Steve Powell

 
proMENTE social research 
research | evaluation | training & consulting 
Kranj?evi?eva 35, 71000 Sarajevo 
mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387 33 556 866
skype: stevepowell99 
www.promente.org  |  www.mojakarijera.com  |  www.psih.org  

-----Original Message-----
From: John Fox [mailto:jfox at mcmaster.ca] 
Sent: 19 September 2007 13:55
To: 'Steve Powell'
Cc: r-help at stat.math.ethz.ch
Subject: RE: [R] SEM - standardized path coefficients?

Dear Steve,

My intention was to provide this flexibility via the parameters argument to
path.diagram.sem(), but it isn't implemented. Here's a version that should
do what you want:

----------------- snip ----------------

path.diagram.sem <- function (model, out.file, min.rank = NULL, max.rank =
NULL, 
    same.rank = NULL, variables = model$var.names, parameters, 
    ignore.double = TRUE, edge.labels = c("names", "values"), 
    size = c(8, 8), node.font = c("Helvetica", 14), edge.font =
c("Helvetica", 
        10), rank.direction = c("LR", "TB"), digits = 2, ...) {
    if (!missing(out.file)) {
        handle <- file(out.file, "w")
        on.exit(close(handle))
    }
    else handle <- stdout()
    edge.labels <- match.arg(edge.labels)
    rank.direction <- match.arg(rank.direction)
    cat(file = handle, paste("digraph \"", deparse(substitute(model)), 
        "\" {\n", sep = ""))
    cat(file = handle, paste("  rankdir=", rank.direction, ";\n", 
        sep = ""))
    cat(file = handle, paste("  size=\"", size[1], ",", size[2], 
        "\";\n", sep = ""))
    cat(file = handle, paste("  node [fontname=\"", node.font[1], 
        "\" fontsize=", node.font[2], " shape=box];\n", sep = ""))
    cat(file = handle, paste("  edge [fontname=\"", edge.font[1], 
        "\" fontsize=", edge.font[2], "];\n", sep = ""))
    cat(file = handle, "  center=1;\n")
    if (!is.null(min.rank)) {
        min.rank <- paste("\"", min.rank, "\"", sep = "")
        min.rank <- gsub(",", "\" \"", gsub(" ", "", min.rank))
        cat(file = handle, paste("  {rank=min ", min.rank, "}\n", 
            sep = ""))
    }
    if (!is.null(max.rank)) {
        max.rank <- paste("\"", max.rank, "\"", sep = "")
        max.rank <- gsub(",", "\" \"", gsub(" ", "", max.rank))
        cat(file = handle, paste("  {rank=max ", max.rank, "}\n", 
            sep = ""))
    }
    if (!is.null(same.rank)) {
        for (s in 1:length(same.rank)) {
            same <- paste("\"", same.rank[s], "\"", sep = "")
            same <- gsub(",", "\" \"", gsub(" ", "", same))
            cat(file = handle, paste("  {rank=same ", same, "}\n", 
                sep = ""))
        }
    }
    latent <- variables[-(1:model$n)]
    for (lat in latent) {
        cat(file = handle, paste("  \"", lat, "\" [shape=ellipse]\n", 
            sep = ""))
    }
    ram <- model$ram
    ram[names(model$coeff), 5] <- model$coeff
    rownames(ram)[model$fixed] <- ram[model$fixed, 5]
    names <- rownames(ram)
    values <- round(ram[, 5], digits)
    heads <- ram[, 1]
    to <- ram[, 2]
    from <- ram[, 3]
    labels <- if (!missing(parameters)){ 
            if (is.numeric(parameters)) round(parameters, digits) 
                else parameters
            }
        else if (edge.labels == "names") names
        else values
    direction <- ifelse((heads == 2), " dir=both", "")
    for (par in 1:nrow(ram)) {
        if ((!ignore.double) || (heads[par] == 1)) 
            cat(file = handle, paste("  \"", variables[from[par]], 
                "\" -> \"", variables[to[par]], "\" [label=\"", 
                labels[par], "\"", direction[par], "];\n", sep = ""))
    }
    cat(file = handle, "}\n")
}

----------------- snip ----------------

E.g., continuing the example in ?path.diagram,

path.diagram(sem.dhp, min.rank='RIQ, RSES, RParAsp, FParAsp, FSES, FIQ', 
    max.rank='ROccAsp, REdAsp, FEdAsp, FOccAsp', 
    parameters=standardized.coefficients(sem.dhp)$"Std. Estimate")

I'll put the updated path.diagram.sem() in the sem package when I have a
chance.

I hope this helps,
 John

--------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox
-------------------------------- 

> -----Original Message-----
> From: Steve Powell [mailto:steve at promente.org]
> Sent: Wednesday, September 19, 2007 3:33 AM
> To: r-help at stat.math.ethz.ch
> Cc: jfox at mcmaster.ca
> Subject: Re: [R] SEM - standardized path coefficients?
> 
> Dear list members,
> In sem, std.coef() will give me standardized coefficients from a sem 
> model.
> But is there a trick so that path.diagram can use these coefficients 
> rather than unstandardized ones?
> Thanks
> Steve Powell
> 
> 
> From: John Fox <jfox_at_mcmaster.ca>
> Date: Wed 28 Feb 2007 - 14:37:22 GMT
> 
> 
> Dear Tim,
> 
> See ?standardized.coefficients (after loading the sem package).
> 
> Regards,
>  John
> 
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> 905-525-9140x23604
> http://socserv.mcmaster.ca/jfox
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tim Holland
> > Sent: Wednesday, February 28, 2007 12:35 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] SEM - standardized path coefficients?
> >
> > Hello -
> >
> > Does anybody know how to get the SEM package in R to return 
> > standardized path coefficients instead of unstandardized ones? Does 
> > this involve changing the covariance matrix, or is there an
> argument
> > in the SEM itself that can be changed?
> >
> > Thank you,
> > Tim
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code. 
> 
> Steve Powell
> 
>  
> proMENTE social research
> research | evaluation | training & consulting Kranj?evi?eva 35, 71000 
> Sarajevo
> mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387
> 33 556 866
> skype: stevepowell99
> www.promente.org  |  www.mojakarijera.com  |  www.psih.org
> 
> No virus found in this outgoing message.
> Checked by AVG Free Edition. 
> Version: 7.5.487 / Virus Database: 269.13.22/1015 - Release
> Date: 18.09.2007
> 11:53
>  
> 
> 


No virus found in this incoming message.
Checked by AVG Free Edition. 

18.09.2007
11:53



Checked by AVG Free Edition. 

19.09.2007
15:59


From birgit.lemcke at systbot.uzh.ch  Thu Sep 20 09:49:19 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Thu, 20 Sep 2007 09:49:19 +0200
Subject: [R] Ambiguities in vector
Message-ID: <8FA3D679-C879-4C88-8775-0951FFD99F1D@systbot.uzh.ch>

Hello all you helpful people out there!

I am stil R Beginner using R 2.5.1 on a Apple Power Book G4 with Mac
OS X 10.4.10 .

Perhaps you haven?t understood my question in the mail yesterday. So  
I will try to describe my problem in a different way

You see the tables. I would like to test the variables between the  
tables. But for some variables in some species , I have more than 1  
possibility.
Example: if the variable is leaf form coded by numbers. The species  
Anth-crin could have the form round or elliptic coded with 1 and 2.  
So there is written 12. But the two numbers should be treated  
separately. Is there a possibility in R to have a classe with  
ambiguities? Or do I have to recode my variables in a different way  
to handle this?

I really hope you understand now what I mean. If not please ask me.

I would be very pleased, if somebody could help me.

Here are the two tables:

MalTabChi
                X1 X4 X6 X8  X10  X14  X21  X24   X29  X38  X43 X50
X67  X76  X78 X80 X82 X84
Anth_cap       1  1  1  1    6    5    1   45    12    4   12   6
56    5    2   4   1   1
Anth_crin     12  1  1  2   76    5    1   45   256    2   25  56
56  345    2  23   1   2
Anth_eck      12  1 12  1    7    5   12    5    14   45    2  56
4    5    2  34   1  12
Anth_gram      2  1  1  1    6    5    1   25    25   23   25  45
5   45    2  23   1  12
Anth_insi      2  1  1  2   63    5    1    4     2    2    2  45
45   45   12   3   1  23
Anth_laxi     12  1  1 12    7   45    1    5   245   23    5  46
56  345    2  23   1  12
Anth_sing      1  1  2  1    7 2345    1    4   129 2345   12  46
4    5   23   2   1   1
Aski_albo_ari  3  1  1  2    6    5    2   46     2   34   15  34
5    5    3   4   1   1
Aski_alt      13  1  1  2    6    5    2    4     2    3   15  46
5    5    2  34   3   1
Aski_and       1  1  2  2    6    5    2    5  <NA> <NA>    1  36
4    5    3   3   3   1
Aski_capi      3  1  1  2   63    5    2    5     2    3    5  45
4    5    3   3   1   1.............

FemTabChi
                  X1 X4   X6 X8  X10  X14 X21 X24   X29  X38  X43 X50
X67 X76  X78 X80 X82 X84
Anth_cap         1  1    1  2    4    4   1   5     6   14    2   6
56   5    2  23   1   1
Anth_crin        1  1    1  2   47    5   1  45     6    1    2
45    5  34    2   3   1  23
Anth_eck         1  1    1  2    4    5   1  45     6    1    2  56
46 345    2   3   1  12
Anth_gram        1  1    1  2 <NA>    5   2   5  <NA>    4 <NA>  56
56   5    2   3   1   1
Anth_insi        1  1    1  2    3    5   1   4    26   25    2
4    5   5    2   3   1 234
Anth_laxi        1  1    1  2   47    5   1  56     6   24    2
4    5 345   21  23   1   1
Anth_sing        1  1    1  2   47   24   1   2    24    2    2
4    4   5    2  12   1   1
Aski_albo_ari    2  1    1  2    4    5   2   4     2   34   15
4    5   5    3   4   1   1
Aski_alt        12  1    1  2    4    5   2   4    89    5   15
46    5   5    2   3   3   1
Aski_and         1  1    1  2    4    5   2   5   259    5    1  46
25   5    2  23   1   1
Aski_capi       23  1    1  2  234    5   2   5  2459  235    5
46    5  34    3   3   1   1
Aski_chart      12  1    1  2    4    5   2   4    29    2   15   4
25   5    2  34   3   1
Aski_deli        2  1    1  2 <NA>   45  12   4     6    2    5
46    5   3    3   4   1   1..........

Greetings

Birgit




Birgit Lemcke
Institut f?r Systematische Botanik
Zollikerstrasse 107
CH-8008 Z?rich
Switzerland
Ph: +41 (0)44 634 8351
birgit.lemcke at systbot.uzh.ch






	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting- 
guide.html
and provide commented, minimal, self-contained, reproducible code.


From ptit_bleu at yahoo.fr  Thu Sep 20 09:49:41 2007
From: ptit_bleu at yahoo.fr (Ptit_Bleu)
Date: Thu, 20 Sep 2007 00:49:41 -0700 (PDT)
Subject: [R] RE :  Must be easy,
 but haven't found the function (numerical integration)
In-Reply-To: <000801c7fa08$6f211570$7c94100a@win.ad.jhu.edu>
References: <12732936.post@talk.nabble.com>
	<1DF7DB4AB44EFB41A60A889186D43359120D14@srv-laminiere.arvalis-fr.com>
	<12759423.post@talk.nabble.com>
	<000801c7fa08$6f211570$7c94100a@win.ad.jhu.edu>
Message-ID: <12792420.post@talk.nabble.com>


Hello Ravi,

I was also trying to write down such a calculation but I did not manage (I
didn't use diff(x)).
Thank you for the solution.
Ptit Bleu.



Ravi Varadhan wrote:
> 
> Here is a simple trapezoidal rule integrator:
> 
> x <- time
> y <- value
> 
> area <- sum(diff(x)*(y[-1]+y[-length(y)]))/2
> 
> Ravi.
> 
> 
> ----------------------------------------------------------------------------
> -------
> 
> Ravi Varadhan, Ph.D.
> 
> Assistant Professor, The Center on Aging and Health
> 
> Division of Geriatric Medicine and Gerontology 
> 
> Johns Hopkins University
> 
> Ph: (410) 502-2619
> 
> Fax: (410) 614-9625
> 
> Email: rvaradhan at jhmi.edu
> 
> Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html
> 
> 
> 
> ----------------------------------------------------------------------------
> --------
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On
> Behalf Of Ptit_Bleu
> Sent: Tuesday, September 18, 2007 11:24 AM
> To: r-help at r-project.org
> Subject: Re: [R] RE : Must be easy, but haven't found the function
> (numerical integration)
> 
> 
> Thanks to all.
> 
> cumsum can be helpful but the solution given by David seems to match my
> request.
> I will test it as soon as possible (before the end of the week, I hope).
> 
> Have a nice end of day,
> Ptit Bleu.
> 
> 
> 
> GOUACHE David wrote:
>> 
>> try :
>> 
>> library(Bolsatd)
>> ?sintegral
>> 
>> or:
>> 
>> library(caTools)
>> ?trapz
>> 
>> David Gouache
>> Arvalis - Institut du V?g?tal
>> Station de La Mini?re
>> 78280 Guyancourt
>> Tel: 01.30.12.96.22 / Port: 06.86.08.94.32
>> 
>> 
>> -----Message d'origine-----
>> De : Ptit_Bleu [mailto:ptit_bleu at yahoo.fr] 
>> Envoy? : lundi 17 septembre 2007 12:09
>> ? : r-help at stat.math.ethz.ch
>> Objet : [R] Must be easy,but haven't found the function (numerical
>> integration)
>> 
>> 
>> Hi,
>> 
>> I have a data frame of 2 columns with the following types :
>> data$day char
>> data$value num
>> 
>> And I plot my data with :
>> plot(strptime(donnees$day,format="%Y-%m-%d %H:%M:%S"),donnees$value,
>> type="l")
>> 
>> And I'd just like to get the numerical value of the integration of this
>> graph.
>> I looked at ?integrate but, as far as I understood (that is, not very
>> much,
>> due to my poor english), it seems that it doesn't work with values in
>> data
>> frame.
>> 
>> Could you please help me to do this ?
>> 
>> Thanks in advance,
>> Have a nice week,
>> Ptit Bleu.
>> -- 
>> View this message in context:
>>
> http://www.nabble.com/Must-be-easy%2C-but-haven%27t-found-the-function-%28nu
> merical-integration%29-tf4465684.html#a12732936
>> Sent from the R help mailing list archive at Nabble.com.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> -- 
> View this message in context:
> http://www.nabble.com/Must-be-easy%2C-but-haven%27t-found-the-function-%28nu
> merical-integration%29-tf4465684.html#a12759423
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Must-be-easy%2C-but-haven%27t-found-the-function-%28numerical-integration%29-tf4465684.html#a12792420
Sent from the R help mailing list archive at Nabble.com.


From altuna.akalin at bccs.uib.no  Thu Sep 20 10:19:07 2007
From: altuna.akalin at bccs.uib.no (Altuna Akalin)
Date: Thu, 20 Sep 2007 10:19:07 +0200
Subject: [R] problem with generalized singular value decomposition using
	LAPACK
Message-ID: <1190276347.46f22cfb4242f@webmail.uib.no>


Hi All,
I'm trying to run  generalized singular value decomposition (GSVD)   function
from LAPACK library. Basically my problem is that I can not run it for large
matrices, I get a memory error.
I'm using R 2.5.1.  I tried this on  intel centos5 machines with 2 GB memory 
and 8 GB memory. I have unlimited max memory,cpu time and virtual memory.

LAPACK is already compiled for R (libRlapack.so ) and using dyn.load and
.Fortran functions it's possible to call LAPACK functions(I don't if it's the
best way to do it)
. I pasted the function below.
As I said,  it's not possible to run GSVD on large matrices. Here is couple of
examples:

>  res=GSVD( matrix(1:35000,5000,6), matrix(1:35000,5000,6)  ) #runs without
problems
>  res=GSVD( matrix(1:36000,6000,6), matrix(1:36000,6000,6)  )
Error: cannot allocate vector of size 274.7 Mb

when tried with 8gig machine:
res=GSVD(matrix(1:36000,6000,6), matrix(1:36000,6000,6)  ) #runs without problems
>  res=GSVD(matrix(1:42000,7000,6), matrix(1:36000,6000,6)  )
Error: cannot allocate vector of size 373.8 Mb

when I tried this with equivalent built-in matlab GSVD function, I get a similar
memory error as well. matlab also uses LAPACK for this.

Is there a workaround for this problem without increasing the memory? Does using
.Fortran makes it worse (memory wise)?
I need to work with matrices 4 times larger than the ones I tried.

I would be grateful if anyone can help on these issues
Best,
Altuna

# function
GSVD<-function(A,B)
{   
    # A=U*E1*Q'
    # B=V*E2*Q'
    dyn.load("/usr/local/lib/R/lib/libRlapack.so")
        #is.loaded("dggsvd") # returns TRUE
 
    z <- .Fortran("dggsvd",
        as.character('N'),
        as.character('N'),
        as.character('Q'),
        as.integer(nrow(A)),
        as.integer(ncol(A)),
        as.integer(nrow(B)),
        integer(1),
        integer(1),
        as.double(A),
        as.integer(nrow(A)),
        as.double(B),
        as.integer(nrow(B)),
         double(ncol(A)),
        double(ncol(A)),
        double(nrow(A)*nrow(A)),
        as.integer(nrow(A)),
        double(nrow(B)*nrow(B)),
        as.integer(nrow(B)),
        double(ncol(A)*ncol(A)),
        as.integer(ncol(A)),
        double(max(c(3*ncol(A),nrow(A),nrow(B)))+ncol(A)),
        integer(ncol(A)),
        integer(1),dup=FALSE)
    K=z[7][[1]]
    L=z[8][[1]]
    U=z[15][[1]]
    V=z[17][[1]]
    Q=z[19][[1]]
    ALPHA=z[13][[1]]
        BETA=z[14][[1]]
    R=matrix(z[9][[1]],ncol(A),nrow=nrow(A),byrow=FALSE)
    U=matrix(U,ncol=nrow(A),nrow=nrow(A),byrow=FALSE)
    V=matrix(V,ncol=nrow(B),nrow=nrow(B),byrow=FALSE)
      Q=matrix(Q,ncol=ncol(A),nrow=ncol(A),byrow=FALSE)
    D1=mat.or.vec(nrow(A),K+L)
    D2=mat.or.vec(nrow(B),K+L)

    oR=mat.or.vec((K+L),ncol(A))
    if(K > 0)
    {
        if(K==1)
    { D1[1:K,1:K] =rep(1,K)
    }
    else
    {
      diag(D1[1:K,1:K])=rep(1,K)
    }
         diag(D1[(K+1):(K+L),(K+1):(K+L)])=ALPHA[(K+1):(K+L)]
        diag(D2[1:L,(K+1):(K+L)])=BETA[(K+1):(K+L)]
               
    }

    if(K ==0)
    {
        diag(D1[(K+1):(K+L),(K+1):(K+L)])=ALPHA[(K+1):(K+L)]
        diag(D2[1:L,(K+1):(K+L)])=BETA[(K+1):(K+L)]

    }
   
    Ci=ALPHA[(K+1):(K+L)]
    S=BETA[(K+1):(K+L)]
    oR[(1):(K+L),(ncol(A)-K-L+1):(ncol(A))]=R[(1):(K+L),(ncol(A)-K-L+1):(ncol(A))]
   
    return(list(U=U,V=V,Q=Q,D1=D1,D2=D2,oR=oR,C=Ci,S=S,K=K,L=L))
   
}


From nestor at ual.es  Thu Sep 20 10:37:09 2007
From: nestor at ual.es (Nestor Fernandez)
Date: Thu, 20 Sep 2007 10:37:09 +0200
Subject: [R] Smooth line in graph
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBBF99D0@LP-EXCHVS07.CO.IHC.COM>
References: <46F181F4.9000904@ual.es> 
	<07E228A5BE53C24CAD490193A7381BBBBF99D0@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <46F23135.1060403@ual.es>

Both worked, thanks!

N. Fernandez

> Katharine Mullen:
>
> require(splines)
> x<-1:5
> y <- c(0.31, 0.45, 0.84, 0.43, 0.25)
> yy <-predict(interpSpline(x, y))
> plot(x, y)
> lines(yy)
>   

> Greg Snow:
> lines(spline(x,y, method='n', n=250))


From mohammad_sahebhonar at yahoo.com  Thu Sep 20 10:45:43 2007
From: mohammad_sahebhonar at yahoo.com (mohammad sahebhonar)
Date: Thu, 20 Sep 2007 09:45:43 +0100 (BST)
Subject: [R] R
Message-ID: <520644.23061.qm@web35506.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070920/9530f5c7/attachment.pl 

From tobias.minder at bluewin.ch  Thu Sep 20 11:45:35 2007
From: tobias.minder at bluewin.ch (squall44)
Date: Thu, 20 Sep 2007 02:45:35 -0700 (PDT)
Subject: [R] combine mathematical expressions with plain text
Message-ID: <12793991.post@talk.nabble.com>


Hello,

I would like to create a mtext. The argument 'text' should combine the
mathematical expressions 'bar' with the plain text ' = 3.07'. Is that
possible?

mtext(text=expression(bar(x)) ...)
' = 3.07'

Thanks for any ideas
Tobias
-- 
View this message in context: http://www.nabble.com/combine-mathematical-expressions-with-plain-text-tf4486503.html#a12793991
Sent from the R help mailing list archive at Nabble.com.


From Ted.Harding at manchester.ac.uk  Thu Sep 20 11:50:27 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Thu, 20 Sep 2007 10:50:27 +0100 (BST)
Subject: [R] R
In-Reply-To: <520644.23061.qm@web35506.mail.mud.yahoo.com>
Message-ID: <XFMail.070920105027.Ted.Harding@manchester.ac.uk>

On 20-Sep-07 08:45:43, mohammad sahebhonar wrote:
> I am going to fit my model with R-2.5.1.tar
> my model is y=fixed effect+b(x) and I have three column in my
> data file (y a x) and about 200000 observation(y) 
> but I had some problems. I was wondering If you could help me
> the error massage is:
>> res <- read.table("pro.sdf")
>> fm <- glm(y=A+x,data=res)
> Error: NA/NaN/Inf in foreign function call (arg 4)
> In addition: Warning messages:
> 1: - not meaningful for factors in: Ops.factor(y, mu)
> 2: - not meaningful for factors in: Ops.factor(eta, offset)
> 3: - not meaningful for factors in: Ops.factor(y, mu)
> thank you
> sincerely
> M.Sahebhonar
> 
>  Send instant messages to your online friends
> http://uk.messenger.yahoo.com 
>       [[alternative HTML version deleted]]

There are two points to investigate in your description above.

1. You describe your datafile as having three columns "y", "a", "x",
   but in your formular you wrote "A+x". If the column-name is "a"
   then "A+x" will not work since "a" and "A" are different names.
   Either the column name in the datafile really is "A", and
   there is no problem (you simply typed it wrong above),
   or it is really "a" and you should use "y ~ a+x" (see below).

2. The way to specify a model formula to glm (also lm, etc.)
   is to write the formula as

      y ~ A+x  (or y ~ a+x, depending on which one is correct)

   Do not use "y = a+x"!

Best woishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 20-Sep-07                                       Time: 10:50:24
------------------------------ XFMail ------------------------------


From nestor at ual.es  Thu Sep 20 12:13:46 2007
From: nestor at ual.es (Nestor Fernandez)
Date: Thu, 20 Sep 2007 12:13:46 +0200
Subject: [R] Smooth line in graph
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBBF99D0@LP-EXCHVS07.CO.IHC.COM>
References: <46F181F4.9000904@ual.es> 
	<07E228A5BE53C24CAD490193A7381BBBBF99D0@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <46F247DA.5000903@ual.es>

Sorry, I answered too quickly.
It worked with the "simplified" example I provided but not with 
non-regular intervals in x:

x<-c(-45,67,131,259,347)
y <- c(0.31, 0.45, 0.84, 0.43, 0.25)

plot(x,y)
lines(spline(x,y, method='n', n=250))
#or:
lines(predict(interpSpline(x, y)))

Produce the same decrease between first two points and the shape is 
quite different to that produced by sigmaplot -I need comparable 
figures. Changing "method" and "n" arguments did not help.

Sorry for bothering. Any other suggestion?




Greg Snow escribi?:
> Try:
>
>   
>> lines(spline(x,y, method='n', n=250))
>>     
>
>


From scionforbai at gmail.com  Thu Sep 20 13:22:09 2007
From: scionforbai at gmail.com (Scionforbai)
Date: Thu, 20 Sep 2007 13:22:09 +0200
Subject: [R] combine mathematical expressions with plain text
In-Reply-To: <12793991.post@talk.nabble.com>
References: <12793991.post@talk.nabble.com>
Message-ID: <e9ee1f0a0709200422p6cea18e0s815a87c140873805@mail.gmail.com>

plot(0,0,"n")
mtext( expression( bar(x) == 3.07) )

but you can also simply 'paste' things:

text(0,0,labels=expression(paste(bar(omega), " = 1")),srt=90)


From elw at stderr.org  Thu Sep 20 13:27:23 2007
From: elw at stderr.org (elw at stderr.org)
Date: Thu, 20 Sep 2007 06:27:23 -0500 (CDT)
Subject: [R] problem with generalized singular value decomposition using
 LAPACK
In-Reply-To: <1190276347.46f22cfb4242f@webmail.uib.no>
References: <1190276347.46f22cfb4242f@webmail.uib.no>
Message-ID: <Pine.LNX.4.64.0709200625340.27593@illuminati.stderr.org>


> I'm trying to run generalized singular value decomposition (GSVD) 
> function from LAPACK library. Basically my problem is that I can not run 
> it for large matrices, I get a memory error. I'm using R 2.5.1.  I tried 
> this on intel centos5 machines with 2 GB memory and 8 GB memory. I have 
> unlimited max memory,cpu time and virtual memory.
>
>>  res=GSVD( matrix(1:35000,5000,6), matrix(1:35000,5000,6)  ) #runs 
>> without
> problems
>>  res=GSVD( matrix(1:36000,6000,6), matrix(1:36000,6000,6)  )
> Error: cannot allocate vector of size 274.7 Mb


Did you examine R's internal memory limits, e.g. ?memory for help...

that should help.  [You should, most likely, be able to allocate a ~274MB 
vector on a 2GB machine... but you might have to coerce R into taking that 
much memory from the system, rather than trying to be conservative.]

--elijah


From arun.kumar.saha at gmail.com  Thu Sep 20 13:32:31 2007
From: arun.kumar.saha at gmail.com (Arun Kumar Saha)
Date: Thu, 20 Sep 2007 17:02:31 +0530
Subject: [R] Need help on "date"
In-Reply-To: <d4c57560709180200q2adf68f7ua2a8d823ac488229@mail.gmail.com>
References: <d4c57560709180200q2adf68f7ua2a8d823ac488229@mail.gmail.com>
Message-ID: <d4c57560709200432g76bdf8c8w933fcbf7d0729cc3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070920/fb04ebd2/attachment.pl 

From fernandomayer at gmail.com  Thu Sep 20 13:42:25 2007
From: fernandomayer at gmail.com (Fernando Mayer)
Date: Thu, 20 Sep 2007 08:42:25 -0300
Subject: [R] combine mathematical expressions with plain text
In-Reply-To: <12793991.post@talk.nabble.com>
References: <12793991.post@talk.nabble.com>
Message-ID: <46F25CA1.7050601@gmail.com>

Hi,

have you tried:

mtext(expression(bar(x) == 3.07), ...)

or

mtext(bquote(bar(x) == 3.07), ...)

?

Fernando Mayer.

squall44 escreveu:
> Hello,
> 
> I would like to create a mtext. The argument 'text' should combine the
> mathematical expressions 'bar' with the plain text ' = 3.07'. Is that
> possible?
> 
> mtext(text=expression(bar(x)) ...)
> ' = 3.07'
> 
> Thanks for any ideas
> Tobias


From ggrothendieck at gmail.com  Thu Sep 20 13:43:42 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 20 Sep 2007 07:43:42 -0400
Subject: [R] Need help on "date"
In-Reply-To: <d4c57560709200432g76bdf8c8w933fcbf7d0729cc3@mail.gmail.com>
References: <d4c57560709180200q2adf68f7ua2a8d823ac488229@mail.gmail.com>
	<d4c57560709200432g76bdf8c8w933fcbf7d0729cc3@mail.gmail.com>
Message-ID: <971536df0709200443y695cc70djd1fadd66d1976bb8@mail.gmail.com>

Since this is a time series you might want to look at the zoo package:

Lines <- "Date Price
09/01/05   365
09/02/05   360
09/03/05   360
09/05/05   370
09/06/05   370
09/08/05   365
09/09/05   365
09/10/05   365
09/12/05   365
09/13/05   360
09/14/05   360
09/15/05   360
"

library(zoo)
# replace with
#    z <- read.zoo("myfile.dat", header = TRUE,format = "%m/%d/%Y")
z <- read.zoo(textConnection(Lines), header = TRUE, format = "%m/%d/%Y")
plot(z)

vignette("zoo") # info on zoo
vignette("zoo-quickref") # more info on zoo



On 9/20/07, Arun Kumar Saha <arun.kumar.saha at gmail.com> wrote:
> This mail is continuation of my previous one. i have some raw data from
> Excel which was carried to R:
>
> data = read.delim(file="clipboard", header=T)
> > data
>       Date Price
> 1  09/01/05   365
> 2  09/02/05   360
> 3  09/03/05   360
> 4  09/05/05   370
> 5  09/06/05   370
> 6  09/08/05   365
> 7  09/09/05   365
> 8  09/10/05   365
> 9  09/12/05   365
> 10 09/13/05   360
> 11 09/14/05   360
> 12 09/15/05   360
>
> and, using the input from R-help I exctracted day, month, and year, from
> "Date"
>
> year = as.numeric(format(as.Date(data[,1],"%m/%d/%y"),"%Y"))
> month = as.numeric(format(as.Date(data[,1],"%m/%d/%y"),"%m"))
> day = as.numeric(format(as.Date(data[,1],"%m/%d/%y"),"%d"))
>
> Now I want to create a date-variable and put it in actual data:
>
> library(date)
> data1 = cbind(mdy.date(month, day, year), data[,-1])
> > data1
>       [,1] [,2]
>  [1,] 16680  365
>  [2,] 16681  360
>  [3,] 16682  360
>  [4,] 16684  370
>  [5,] 16685  370
>  [6,] 16687  365
>  [7,] 16688  365
>  [8,] 16689  365
>  [9,] 16691  365
> [10,] 16692  360
> [11,] 16693  360
> [12,] 16694  360
>
> However this is not that thing what I wanted, first column has been jumbled,
> it is not in actual date format.
>
> Can anyone tell me what should i do here?
>
> Regards,
>
>
>
>
>
>
> On 9/18/07, Arun Kumar Saha <arun.kumar.saha at gmail.com> wrote:
> >
> > Dear all,
> >
> > I have a variable 'x' like that:
> >
> > > x
> > [1] "2005-09-01"
> >
> > Here, 2005 represents year, 09 month and 01 day.
> >
> > Now I want to create three variables naming: y, m, and d such that:
> >
> > y = 2005
> > m = 09
> > d = 01
> >
> > can anyone tell me how to do that?
> >
> > Regards,
> >
> >
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Rainer at krugs.de  Thu Sep 20 13:59:09 2007
From: Rainer at krugs.de (Rainer M. Krug)
Date: Thu, 20 Sep 2007 13:59:09 +0200
Subject: [R] referencing packages?
Message-ID: <46F2608D.9000703@krugs.de>

Hi

I know how to referenc R in a scientific paper - but is there a 
standardised way to reference packages?

Thanks

Rainer

-- 
NEW EMAIL ADDRESS AND ADDRESS:

Rainer.Krug at uct.ac.za

RKrug at sun.ac.za WILL BE DISCONTINUED END OF MARCH

Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Plant Conservation Unit
Department of Botany
University of Cape Town
Rondebosch 7701
South Africa

Tel:		+27 - (0)21 650 5776 (w)
Fax:		+27 - (0)86 516 2782
Fax:		+27 - (0)21 650 2440 (w)
Cell:		+27 - (0)83 9479 042

Skype:		RMkrug

email:	Rainer.Krug at uct.ac.za
       	Rainer at krugs.de


From kate at few.vu.nl  Thu Sep 20 14:08:17 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Thu, 20 Sep 2007 14:08:17 +0200 (CEST)
Subject: [R] referencing packages?
In-Reply-To: <46F2608D.9000703@krugs.de>
References: <46F2608D.9000703@krugs.de>
Message-ID: <Pine.GSO.4.56.0709201406380.18803@laurel.few.vu.nl>

use citation("pkg-name")

On Thu, 20 Sep 2007, Rainer M. Krug wrote:

> Hi
>
> I know how to referenc R in a scientific paper - but is there a
> standardised way to reference packages?
>
> Thanks
>
> Rainer
>
> --
> NEW EMAIL ADDRESS AND ADDRESS:
>
> Rainer.Krug at uct.ac.za
>
> RKrug at sun.ac.za WILL BE DISCONTINUED END OF MARCH
>
> Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
> Biology (UCT)
>
> Plant Conservation Unit
> Department of Botany
> University of Cape Town
> Rondebosch 7701
> South Africa
>
> Tel:		+27 - (0)21 650 5776 (w)
> Fax:		+27 - (0)86 516 2782
> Fax:		+27 - (0)21 650 2440 (w)
> Cell:		+27 - (0)83 9479 042
>
> Skype:		RMkrug
>
> email:	Rainer.Krug at uct.ac.za
>        	Rainer at krugs.de
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Rainer at krugs.de  Thu Sep 20 14:16:36 2007
From: Rainer at krugs.de (Rainer M. Krug)
Date: Thu, 20 Sep 2007 14:16:36 +0200
Subject: [R] referencing packages?
In-Reply-To: <Pine.GSO.4.56.0709201406380.18803@laurel.few.vu.nl>
References: <46F2608D.9000703@krugs.de>
	<Pine.GSO.4.56.0709201406380.18803@laurel.few.vu.nl>
Message-ID: <46F264A4.6040103@krugs.de>

Thanks a million

Rainer

Katharine Mullen wrote:
> use citation("pkg-name")
> 
> On Thu, 20 Sep 2007, Rainer M. Krug wrote:
> 
>> Hi
>>
>> I know how to referenc R in a scientific paper - but is there a
>> standardised way to reference packages?
>>
>> Thanks
>>
>> Rainer
>>
>> --
>> NEW EMAIL ADDRESS AND ADDRESS:
>>
>> Rainer.Krug at uct.ac.za
>>
>> RKrug at sun.ac.za WILL BE DISCONTINUED END OF MARCH
>>
>> Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
>> Biology (UCT)
>>
>> Plant Conservation Unit
>> Department of Botany
>> University of Cape Town
>> Rondebosch 7701
>> South Africa
>>
>> Tel:		+27 - (0)21 650 5776 (w)
>> Fax:		+27 - (0)86 516 2782
>> Fax:		+27 - (0)21 650 2440 (w)
>> Cell:		+27 - (0)83 9479 042
>>
>> Skype:		RMkrug
>>
>> email:	Rainer.Krug at uct.ac.za
>>        	Rainer at krugs.de
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
NEW EMAIL ADDRESS AND ADDRESS:

Rainer.Krug at uct.ac.za

RKrug at sun.ac.za WILL BE DISCONTINUED END OF MARCH

Rainer M. Krug, Dipl. Phys. (Germany), MSc Conservation
Biology (UCT)

Plant Conservation Unit
Department of Botany
University of Cape Town
Rondebosch 7701
South Africa

Tel:		+27 - (0)21 650 5776 (w)
Fax:		+27 - (0)86 516 2782
Fax:		+27 - (0)21 650 2440 (w)
Cell:		+27 - (0)83 9479 042

Skype:		RMkrug

email:	Rainer.Krug at uct.ac.za
       	Rainer at krugs.de


From muenchen at utk.edu  Thu Sep 20 15:08:45 2007
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Thu, 20 Sep 2007 09:08:45 -0400
Subject: [R] Cutting & pasting help examples into script window
Message-ID: <347152339B716A4D893C9A2988EA87C86927C6@KFSVS2.utk.tennessee.edu>

Hi All,

When I cut & paste help file examples into a script window, about half
the time it pastes as a single long line. 

The steps I follow are:

1. Open a help file e.g. ?data.frame.
2. Select the examples at the bottom.
3. Choose File: Copy.
4. Return to the console.
5. Choose File: New script.
6. Choose File: Paste or do CTRL-V. The examples frequently paste as a
single long line. 

I came across this in 2.6.0 beta on Windows XP & thought it was related
to the cut/paste changes in that version. I went back to 2.5.1 and at
first it worked fine, verifying my suspicion that it was a 2.6.0
problem. I double-checked my steps before posting, and to my surprise
found that in both versions this problem is intermittent.

I thought it might be a menu vs. keyboard CTRL-V difference, but found
it happens with both, and in both versions. I have also fiddled with
sizing or moving the Help window but that doesn't seem to be related. I
did discover that may be a problem on the paste side of things, as so
far it *always* pastes into Notepad correctly.

Any ideas?

Thanks,
Bob

P.S. What would really be slick would be to select the example in Help,
right-click and choose Run Line or Selection. Perhaps in version 2.7.
;-) .

=========================================================
Bob Muenchen (pronounced Min'-chen), 
Manager, Statistical Consulting Center 
U of TN Office of Information Technology
Stokely Management Center, Suite 200
916 Volunteer Blvd., Knoxville, TN 37996-0520
Voice: (865) 974-5230
FAX: (865) 974-4810
Email: muenchen at utk.edu
Web: http://oit.utk.edu/scc
Map: http://www.utk.edu/maps 
News: http://listserv.utk.edu/archives/statnews.html
=========================================================


From nicolette.cagle at duke.edu  Thu Sep 20 15:08:47 2007
From: nicolette.cagle at duke.edu (nicolette.cagle at duke.edu)
Date: Thu, 20 Sep 2007 09:08:47 -0400
Subject: [R] SEM - singularity error
Message-ID: <20070920090847.1wj6p314cgckkksg@webmail.duke.edu>

Good morning,

I am trying to develop a structural equation model of snake abundance using
habitat variables. In attempting to estimate the model using the "sem" package
in R version 2.4.0, I receive the following error message:

"Error in solve.default(C) : system is computationally singular: reciprocal
condition number = 1.75349e-16"

MAIN PROBLEM: I am hoping to discover why I am receiving the aforementioned
error message and how to successfully estimate the model.

OTHER INFORMATION:
1. I believe the model is over-identified rather than under-identified (based on
my understanding of the t-rule). I have observed data for 10 variables (9
exogenous, 1 endogenous).

2. I am not certain that I have used the proper tool to estimate the covariance
matrix. In this case, I used the "VAR" function.

3. I am most concerned that I have improperly coded the RAM file. For example,
in a case where I have three exogenous indicators of one exogenous latent
variable, I specify a start value of 1 for one of the exogenous indicators. I
am not sure if this is proper or necessary.

4. I am new to SEM; this is the first model I have ever tried to estimate.

R CODE: Below is the r-code I have used to estimate the structural equation
model --

# LOADING R PACKAGES
library(sem)

# READING IN THE CSV FILES
thsi.2006<-read.csv("thsi_ab_env_space_sem.csv")
thsi<-thsi.2006

# MAKING "RAM" FILE 2
model2.nlc <-specify.model()
Moist->slope, NA, 1
Moist->sand, lamda21, NA
Moist->clay, lamda31, NA
Hab->isol, NA, 1
Hab->edgedist_a, lamda52, NA
Hab->ag10, lamda62, NA
Hab->urb10, lamda72, NA
Hab->rd10, lamda82, NA
Hab->y, lamda92, NA
Moist->this, gamma11, NA
Hab->this, gamma12, NA
slope<->slope, theta11, NA
sand<->sand, theta22, NA
clay<->clay, theta33, NA
isol<->isol, theta44, NA
edgedist_a<->edgedist_a, theta55, NA
ag10<->ag10, theta66, NA
urb10<->urb10, theta77, NA
rd10<->rd10, theta88, NA
y<->y, the99, NA
Moist<->Moist, phi11, NA
Hab<->Hab, phi22, NA
this<->this, theps11, NA

model2.nlc
end

# MAKING S (COVARIANCE MATRIX)
thsi.var <- var(thsi)

# MAKING UNSCALED SEM MODEL
sem2<-sem(ram=model2.nlc, S=thsi.var, N=22)

I am also attaching a jpeg diagram of the model I am trying to estimate. Please
let me know if there is any additional information that I should add to this
posting.

Thank you so much for your time.
Nicolette Cagle
-- 
Ecology Ph.D. Candidate
Duke University
Durham, NC 27708
www.duke.edu/~nlc4

From rita.sousa at ine.pt  Thu Sep 20 15:11:14 2007
From: rita.sousa at ine.pt (Rita Sousa)
Date: Thu, 20 Sep 2007 14:11:14 +0100
Subject: [R] Package Survey
Message-ID: <2F01C2D1A2A44B41BD01DDE5F72E1CAB01A1F9EF@rngpew02.drn.ine.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070920/c3978fee/attachment.pl 

From jnwilks at btinternet.com  Wed Sep 19 23:01:04 2007
From: jnwilks at btinternet.com (John Wilkinson_dsl)
Date: Wed, 19 Sep 2007 23:01:04 +0200
Subject: [R] Must be easy,
	but haven't found the function (numerical integration)
Message-ID: <AKEHKFBLKIAFEJCIOGOCKEFMCBAA.jnwilks@btinternet.com>

Ptit Bleu.

try the  'adapt' function for multi-dimensional numerical integration.

library(adapt)
Adaptive Numerical Integration in 2?20 Dimensions

John



Checked by AVG Free Edition.

11:53


From stefan.grosse at uni-erfurt.de  Thu Sep 20 15:18:11 2007
From: stefan.grosse at uni-erfurt.de (Stefan Grosse)
Date: Thu, 20 Sep 2007 15:18:11 +0200
Subject: [R] Cutting & pasting help examples into script window
In-Reply-To: <347152339B716A4D893C9A2988EA87C86927C6@KFSVS2.utk.tennessee.edu>
References: <347152339B716A4D893C9A2988EA87C86927C6@KFSVS2.utk.tennessee.edu>
Message-ID: <200709201518.11464.stefan.grosse@uni-erfurt.de>

On Thursday 20 September 2007 15:08:45 Muenchen, Robert A (Bob) wrote:
MR > Hi All,
MR >
MR > When I cut & paste help file examples into a script window, about half
MR > the time it pastes as a single long line.
MR >
MR > Any ideas?
MR >
MR > Thanks,
MR > Bob
MR >
MR > P.S. What would really be slick would be to select the example in Help,
MR > right-click and choose Run Line or Selection. Perhaps in version 2.7.
MR > ;-) .

What I do not understand is why you not just type example(yourcommand)?

Stefan


From stefan.grosse at uni-erfurt.de  Thu Sep 20 15:18:11 2007
From: stefan.grosse at uni-erfurt.de (Stefan Grosse)
Date: Thu, 20 Sep 2007 15:18:11 +0200
Subject: [R] Cutting & pasting help examples into script window
In-Reply-To: <347152339B716A4D893C9A2988EA87C86927C6@KFSVS2.utk.tennessee.edu>
References: <347152339B716A4D893C9A2988EA87C86927C6@KFSVS2.utk.tennessee.edu>
Message-ID: <200709201518.11464.stefan.grosse@uni-erfurt.de>

On Thursday 20 September 2007 15:08:45 Muenchen, Robert A (Bob) wrote:
MR > Hi All,
MR >
MR > When I cut & paste help file examples into a script window, about half
MR > the time it pastes as a single long line.
MR >
MR > Any ideas?
MR >
MR > Thanks,
MR > Bob
MR >
MR > P.S. What would really be slick would be to select the example in Help,
MR > right-click and choose Run Line or Selection. Perhaps in version 2.7.
MR > ;-) .

What I do not understand is why you not just type example(yourcommand)?

Stefan


From cathelf at hotmail.com  Thu Sep 20 00:13:54 2007
From: cathelf at hotmail.com (fang liu)
Date: Wed, 19 Sep 2007 22:13:54 +0000
Subject: [R] How to find "p"(proportion) in binomial(n, p)?
Message-ID: <BAY109-F392E81D8E39EFDDDD6E7C4BEB90@phx.gbl>

Hi,

I got a problem. I am trying to find "p" in binomial.
X~bin(n, p)
I want to find value "p", so that Pr(X <= k) <= alpha.
Here, n, k are known.

Thank you for helping me with this!

Catherine

_________________________________________________________________
[[replacing trailing spam]]


From dmca at ucla.edu  Thu Sep 20 01:35:06 2007
From: dmca at ucla.edu (D L McArthur)
Date: Wed, 19 Sep 2007 23:35:06 +0000 (UTC)
Subject: [R] Identify and plotting symbols.
References: <32DF3CC5-EC25-4B82-9B04-18DDF1329095@auckland.ac.nz>
Message-ID: <loom.20070920T011754-452@post.gmane.org>

Rolf Turner <r.turner <at> auckland.ac.nz> writes:
...
> I tried
> 
> 	ind <- identify(x,y,labels=rep("\021",length(x)),offset=0)

Have you tried "\225" or "\244" or "\370" (which can be previewed by 
typing > "\225" etc), and clicking just above the plotted datapoints?

D L McArthur, UCLA Sch of Medicine   dmca <at> ucla.edu


From eugen_pircalabelu at yahoo.com  Thu Sep 20 09:39:16 2007
From: eugen_pircalabelu at yahoo.com (eugen pircalabelu)
Date: Thu, 20 Sep 2007 00:39:16 -0700 (PDT)
Subject: [R] The Survey package again
Message-ID: <125048.38736.qm@web38611.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070920/cce9951e/attachment.pl 

From robk at statmethods.net  Thu Sep 20 15:24:22 2007
From: robk at statmethods.net (Rob Kabacoff)
Date: Thu, 20 Sep 2007 09:24:22 -0400
Subject: [R] Comprehensive New Learning Resource for R
Message-ID: <5578c0b1044e4b38b65a45e317ac7f74@mail.infosaic.com>

Hi Folks,

I have created a website with over 70 R tutorials on a wide range of subjects. The site is aimed at data analysts who have an idea about what they would like to do, but don't know how to do it in R. The site should be particularly useful for users of statistical packages like SAS, SPSS, Stata, and Systat who would like to get up and running in R quickly. However, I think that it will also be useful for even veteran R users.

The URL is http://www.statmethods.net

Topics are organized around these headings:
* The R Interface
* Data Input
* Data Management
* Basic Statistics
* Advanced Statistics
* Basic Graphs
* Advanced Graphs

Topic range from GUIs to creating publication quality output, from database access to date values, from t-tests to generalized linear models, from barcharts to interactive multivariate graphics.

I hope that you find this useful. Please feel free to link to the site.

Feedback is always welcome.

Sincerely,

Rob Kabacoff, Ph.D.
robk at statmethods.net
www.statmethods.net


From jo.irisson at gmail.com  Thu Sep 20 15:28:08 2007
From: jo.irisson at gmail.com (jiho)
Date: Thu, 20 Sep 2007 15:28:08 +0200
Subject: [R] ggplot and xlim/ylim
Message-ID: <F9CD47BE-AC86-454B-8EBC-3B2D01F8F242@gmail.com>

Hello everyone,

I am (happily) using ggplot2 for all my plotting now and I wondered  
is there is an easy way to specify xlim and ylim somewhere when using  
the ggplot syntax, as opposed to the qplot syntax. Eg.

  qplot(data=mtcars,y=wt, x=qsec,xlim=c(0,30))

<->

ggplot(mtcars, aes(y=wt, x=qsec)) + geom_point() + ???

Indeed the ggplot syntax is in general more flexible and powerful and  
I usually rely on it in scripts. It would be nice to know how to use  
xlim/ylim with this syntax.

Thank you in advance.

JiHO
---
http://jo.irisson.free.fr/


From h.wickham at gmail.com  Thu Sep 20 15:59:46 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 20 Sep 2007 08:59:46 -0500
Subject: [R] ggplot and xlim/ylim
In-Reply-To: <F9CD47BE-AC86-454B-8EBC-3B2D01F8F242@gmail.com>
References: <F9CD47BE-AC86-454B-8EBC-3B2D01F8F242@gmail.com>
Message-ID: <f8e6ff050709200659p55da7c11g79e5a4693536114b@mail.gmail.com>

Hi Jiho,

To figure this out, you need to think about exactly what you are doing
when you change the limits - what part of the plot are you changing?
You are changing the scales, and if you have a look at
http://had.co.nz/ggplot2/scale_continuous.html, you'll see you need
something like:

+ scale_y_continuous(limits=c(0,10)

Remember, you can also modify qplot in the same way as ggplot:

qplot(...) + geom_point() + ...

Regards,

Hadley

On 9/20/07, jiho <jo.irisson at gmail.com> wrote:
> Hello everyone,
>
> I am (happily) using ggplot2 for all my plotting now and I wondered
> is there is an easy way to specify xlim and ylim somewhere when using
> the ggplot syntax, as opposed to the qplot syntax. Eg.
>
>   qplot(data=mtcars,y=wt, x=qsec,xlim=c(0,30))
>
> <->
>
> ggplot(mtcars, aes(y=wt, x=qsec)) + geom_point() + ???
>
> Indeed the ggplot syntax is in general more flexible and powerful and
> I usually rely on it in scripts. It would be nice to know how to use
> xlim/ylim with this syntax.
>
> Thank you in advance.
>
> JiHO
> ---
> http://jo.irisson.free.fr/
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
http://had.co.nz/


From muenchen at utk.edu  Thu Sep 20 16:01:03 2007
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Thu, 20 Sep 2007 10:01:03 -0400
Subject: [R] Cutting & pasting help examples into script window
In-Reply-To: <200709201518.11464.stefan.grosse@uni-erfurt.de>
References: <347152339B716A4D893C9A2988EA87C86927C6@KFSVS2.utk.tennessee.edu>
	<200709201518.11464.stefan.grosse@uni-erfurt.de>
Message-ID: <347152339B716A4D893C9A2988EA87C8692812@KFSVS2.utk.tennessee.edu>

Stephan Grosse replied:

> 
> What I do not understand is why you not just type
example(yourcommand)?
> 
> Stefan

That's a good question. I want to play around with variations of the
examples rather than run them exactly as they are.

Thanks,
Bob


From rtchiruka at yahoo.com  Thu Sep 20 16:07:24 2007
From: rtchiruka at yahoo.com (raymond chiruka)
Date: Thu, 20 Sep 2007 07:07:24 -0700 (PDT)
Subject: [R] comparing survival curves(weighted log rank test)
Message-ID: <610463.56566.qm@web33013.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070920/bd964a26/attachment.pl 

From tlumley at u.washington.edu  Thu Sep 20 16:16:36 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 20 Sep 2007 07:16:36 -0700 (PDT)
Subject: [R] Package Survey
In-Reply-To: <2F01C2D1A2A44B41BD01DDE5F72E1CAB01A1F9EF@rngpew02.drn.ine.pt>
References: <2F01C2D1A2A44B41BD01DDE5F72E1CAB01A1F9EF@rngpew02.drn.ine.pt>
Message-ID: <Pine.LNX.4.64.0709200709460.14389@homer22.u.washington.edu>

On Thu, 20 Sep 2007, Rita Sousa wrote:

> How I use the function as.svrepdesign without memory.size problems?
>
> desenho_npc_JK <- as.svrepdesign(desenho_npc,type="JKn")
>
> Error: cannot allocate vector of size 161.3 Mb

There is currently no easy way to affect the amount of memory that this 
uses, unless you can divide the data into pieces -- for example, use only 
some variables, or create separate design objects for strata.

The surveyNG package, which can handle very large designs, does not yet do 
replicate-weight analyses.


One question is how big the design actually is.
161.3Mb looks like a vector of length 21 million

If this is the number of observations in the study then you need a 
larger computer.  If it is the total number of replicate weights then you 
may just be able to increase the memory limit for R  on your computer 
using the memory.size() function, as the warning method suggests.

 	-thomas

> In addition: Warning messages:
>
> 1: Reached total allocation of 1022Mb: see help(memory.size)
>
> 2: Reached total allocation of 1022Mb: see help(memory.size)
>
> 3: Reached total allocation of 1022Mb: see help(memory.size)
>
> 4: Reached total allocation of 1022Mb: see help(memory.size)
>
>
>
> Many thanks,
>
> ---------------------------------------------------
> Rita Sousa
> Departamento de Metodologia e Sistemas de Informa??o
>
> INE - DP: Instituto Nacional de Estat?stica - Delega??o do Porto
>
> Tel.: 22 6072016 (Extens?o: 4116)
> ---------------------------------------------------
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

From Ted.Harding at manchester.ac.uk  Thu Sep 20 16:17:18 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Thu, 20 Sep 2007 15:17:18 +0100 (BST)
Subject: [R] Comprehensive New Learning Resource for R
In-Reply-To: <5578c0b1044e4b38b65a45e317ac7f74@mail.infosaic.com>
Message-ID: <XFMail.070920151718.Ted.Harding@manchester.ac.uk>

Excellent! Thanks. Just what I need for referring
friends to.

However, your very first feedback:

Under http://www.statmethods.net/input/datatypes.html
you have:

##Vectors

a <- c(1,2,5.3,6,-2,4) # numberic vector
b <- c("one","two","three") # character vector
c <- c(T,T,T,F,T,F) #logical vector

##Refer to elements of a vector using subscripts.

a[2,4] # 2nd and 4th elements of vector

## Err, no! a[c(2,4)] of course!

More {when|if} I spot them!
Best wishes,
Ted.

On 20-Sep-07 13:24:22, Rob Kabacoff wrote:
> Hi Folks,
> 
> I have created a website with over 70 R tutorials on a wide range of
> subjects. The site is aimed at data analysts who have an idea about
> what they would like to do, but don't know how to do it in R. The site
> should be particularly useful for users of statistical packages like
> SAS, SPSS, Stata, and Systat who would like to get up and running in R
> quickly. However, I think that it will also be useful for even veteran
> R users.
> 
> The URL is http://www.statmethods.net
> 
> Topics are organized around these headings:
> * The R Interface
> * Data Input
> * Data Management
> * Basic Statistics
> * Advanced Statistics
> * Basic Graphs
> * Advanced Graphs
> 
> Topic range from GUIs to creating publication quality output, from
> database access to date values, from t-tests to generalized linear
> models, from barcharts to interactive multivariate graphics.
> 
> I hope that you find this useful. Please feel free to link to the site.
> 
> Feedback is always welcome.
> 
> Sincerely,
> 
> Rob Kabacoff, Ph.D.
> robk at statmethods.net
> www.statmethods.net
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 20-Sep-07                                       Time: 15:17:14
------------------------------ XFMail ------------------------------


From wtimm at techfak.uni-bielefeld.de  Thu Sep 20 16:27:05 2007
From: wtimm at techfak.uni-bielefeld.de (Wiebke Timm)
Date: Thu, 20 Sep 2007 10:27:05 -0400
Subject: [R] Comprehensive New Learning Resource for R
In-Reply-To: <5578c0b1044e4b38b65a45e317ac7f74@mail.infosaic.com>
References: <5578c0b1044e4b38b65a45e317ac7f74@mail.infosaic.com>
Message-ID: <93FB13DC-DF64-490A-95AD-D656E324052B@techfak.uni-bielefeld.de>

On 20.09.2007, at 09:24, Rob Kabacoff wrote:

> I hope that you find this useful. Please feel free to link to the  
> site.

Very nicely done from what I saw by browsing the site a little. Good  
colors, good content, easy to navigate. Thanks!

You might want to add self-organizing maps as a cross-over of  
clustering and visualization. Maybe statistical learning methods as  
well.

Regards,
    Wiebke


From ggrothendieck at gmail.com  Thu Sep 20 16:38:59 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 20 Sep 2007 10:38:59 -0400
Subject: [R] Comprehensive New Learning Resource for R
In-Reply-To: <XFMail.070920151718.Ted.Harding@manchester.ac.uk>
References: <5578c0b1044e4b38b65a45e317ac7f74@mail.infosaic.com>
	<XFMail.070920151718.Ted.Harding@manchester.ac.uk>
Message-ID: <971536df0709200738t244cfb0bx5b529f50d70371cc@mail.gmail.com>

Also use of T and F is bad form since its possible to
define variables T and F.  Use TRUE and FALSE.

On 9/20/07, Ted Harding <Ted.Harding at manchester.ac.uk> wrote:
> Excellent! Thanks. Just what I need for referring
> friends to.
>
> However, your very first feedback:
>
> Under http://www.statmethods.net/input/datatypes.html
> you have:
>
> ##Vectors
>
> a <- c(1,2,5.3,6,-2,4) # numberic vector
> b <- c("one","two","three") # character vector
> c <- c(T,T,T,F,T,F) #logical vector
>
> ##Refer to elements of a vector using subscripts.
>
> a[2,4] # 2nd and 4th elements of vector
>
> ## Err, no! a[c(2,4)] of course!
>
> More {when|if} I spot them!
> Best wishes,
> Ted.
>
> On 20-Sep-07 13:24:22, Rob Kabacoff wrote:
> > Hi Folks,
> >
> > I have created a website with over 70 R tutorials on a wide range of
> > subjects. The site is aimed at data analysts who have an idea about
> > what they would like to do, but don't know how to do it in R. The site
> > should be particularly useful for users of statistical packages like
> > SAS, SPSS, Stata, and Systat who would like to get up and running in R
> > quickly. However, I think that it will also be useful for even veteran
> > R users.
> >
> > The URL is http://www.statmethods.net
> >
> > Topics are organized around these headings:
> > * The R Interface
> > * Data Input
> > * Data Management
> > * Basic Statistics
> > * Advanced Statistics
> > * Basic Graphs
> > * Advanced Graphs
> >
> > Topic range from GUIs to creating publication quality output, from
> > database access to date values, from t-tests to generalized linear
> > models, from barcharts to interactive multivariate graphics.
> >
> > I hope that you find this useful. Please feel free to link to the site.
> >
> > Feedback is always welcome.
> >
> > Sincerely,
> >
> > Rob Kabacoff, Ph.D.
> > robk at statmethods.net
> > www.statmethods.net
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 20-Sep-07                                       Time: 15:17:14
> ------------------------------ XFMail ------------------------------
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Christian.Kohler at klinik.uni-regensburg.de  Thu Sep 20 16:48:42 2007
From: Christian.Kohler at klinik.uni-regensburg.de (Christian Kohler)
Date: Thu, 20 Sep 2007 16:48:42 +0200
Subject: [R] warnings although R CMD check runs without any problem
Message-ID: <46F2884A.5090701@klinik.uni-regensburg.de>

Dear list members,

as I am new to R, I would kindly like to ask for your help.

I checked a package with the 'R CMD check' command and all worked out
well, (only 'OK' status). Loading its vignette afterwards with
'source("package.Rcheck/inst/doc/vignette.R")' yields a message saying
that several (well, in my case more than 50) warnings still exist and
can be viewed via the 'warnings()' command.

My question now is: why are there still warnings even though the check
has been passed without any problems? Generally speaking, would it be
possible to submit this package e.g. to the Bioconductor project, even
if these warnings still exist?


Thanks in advance,
Christian



-- 

Christian Kohler
Institute of Functional Genomics
Computational Diagnostics
University of Regensburg
D-93147 Regensburg (Germany)


From ligges at statistik.uni-dortmund.de  Thu Sep 20 16:57:59 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 20 Sep 2007 16:57:59 +0200
Subject: [R] warnings although R CMD check runs without any problem
In-Reply-To: <46F2884A.5090701@klinik.uni-regensburg.de>
References: <46F2884A.5090701@klinik.uni-regensburg.de>
Message-ID: <46F28A77.6090107@statistik.uni-dortmund.de>

Can you give examples?

Uwe


Christian Kohler wrote:
> Dear list members,
> 
> as I am new to R, I would kindly like to ask for your help.
> 
> I checked a package with the 'R CMD check' command and all worked out
> well, (only 'OK' status). Loading its vignette afterwards with
> 'source("package.Rcheck/inst/doc/vignette.R")' yields a message saying
> that several (well, in my case more than 50) warnings still exist and
> can be viewed via the 'warnings()' command.
> 
> My question now is: why are there still warnings even though the check
> has been passed without any problems? Generally speaking, would it be
> possible to submit this package e.g. to the Bioconductor project, even
> if these warnings still exist?
> 
> 
> Thanks in advance,
> Christian
> 
> 
>


From jfox at mcmaster.ca  Thu Sep 20 17:02:39 2007
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 20 Sep 2007 11:02:39 -0400
Subject: [R] SEM - standardized path coefficients? - significant style
In-Reply-To: <018001c7fb59$6757fff0$6501a8c0@STEVE>
Message-ID: <20070920150240.JRDF8273.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Steve,

I'll file this suggestion for when I next revise the sem package. I'm
unlikely to get to it soon since I rarely use the graph-drawing program dot
and would have to figure out how to do what you want. As well, I think that
I'd more likely allow the user to specify the line type for each edge in the
graph rather than hard-coding this to significance/non-significance.

Regards,
 John

--------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: Steve Powell [mailto:steve at promente.org] 
> Sent: Thursday, September 20, 2007 3:40 AM
> To: 'John Fox'
> Cc: r-help at stat.math.ethz.ch; eso at promente.org
> Subject: RE: [R] SEM - standardized path coefficients? - 
> significant style
> 
> Dear John
> Being an R user is like having Christmas every day and having 
> a direct line to Santa for present suggestions. 
> How about if path.diagram.sem had the ability to print 
> non-significant paths in, for example dotted style? I had a 
> go myself but couldn't see how to get 
> (summary(model)$coeff)$"Pr(>|z|)" into the loop.
> Very best wishes
> Steve Powell
> 
>  
> proMENTE social research
> research | evaluation | training & consulting Kranj?evi?eva 
> 35, 71000 Sarajevo
> mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387 
> 33 556 866
> skype: stevepowell99
> www.promente.org  |  www.mojakarijera.com  |  www.psih.org  
> 


From ptit_bleu at yahoo.fr  Thu Sep 20 17:03:14 2007
From: ptit_bleu at yahoo.fr (Ptit_Bleu)
Date: Thu, 20 Sep 2007 08:03:14 -0700 (PDT)
Subject: [R] It works but I don't know how (nice scientific notation with
 Lattice)
Message-ID: <12798983.post@talk.nabble.com>


Hi,

I had problems to display my results in a nice way (according to me).
Thanks to posts of people of this forum, I solved my problems (ticks with a
scientific notation and how to write nicely "V/m2" in the label of the
x-axis) but ... I don't understand the script.

Can somebody explain me how the short script below writes the scientific
notation ?
I guess it is the result of 

ans$bottom$labels$labels <- parse(text = ans$bottom$labels$labels)

but it is really not clear to me.

Thanks in advance for your explainations
Ptit Bleu.

--------------------------------------------------------------------


library(lattice)

x<-c(10,100,1000,10000,100000,20,200,2000,20000,200000)
y<-c(1,2,3,4,5,2,4,6,8,10)
z<-c(1,1,1,1,1,2,2,2,2,2)

xyplot(y ~ x | z,
  scales = list(x = list(log = T)),
  xscale.components = function(...) {
                                      ans <- xscale.components.default(...)
                                      ans$bottom$labels$labels <- parse(text
= ans$bottom$labels$labels)
                                      ans
                                    }
  , xlab=(expression(paste("X (V/",m^2,")"))) , ylab="Y (arb. unit)")

-- 
View this message in context: http://www.nabble.com/It-works-but-I-don%27t-know-how-%28nice-scientific-notation-with-Lattice%29-tf4488112.html#a12798983
Sent from the R help mailing list archive at Nabble.com.


From wtimm at techfak.uni-bielefeld.de  Thu Sep 20 17:15:34 2007
From: wtimm at techfak.uni-bielefeld.de (Wiebke Timm)
Date: Thu, 20 Sep 2007 11:15:34 -0400
Subject: [R] Problem with lars
Message-ID: <365D3778-E3BD-42C8-8410-51A00AC9A6C2@techfak.uni-bielefeld.de>

Hi!

Ok, probably my last mail was too long. Questions are:

* Did someone try lars on data with much more components than data  
points? Did you observe bad overfitting, too? Any other observations?

* Why might the lars (least angle regression from lars package)  
method produce beta values that shoot up into the sky (until they  
overflow), and why might the Cp values start at a _negative_ value in  
step 1, growing linearly? That's not normal behaviour. What might be  
wrong there?

For details see my last mail. :)

Regards,
    Wiebke


From Christian.Kohler at klinik.uni-regensburg.de  Thu Sep 20 17:22:26 2007
From: Christian.Kohler at klinik.uni-regensburg.de (Christian Kohler)
Date: Thu, 20 Sep 2007 17:22:26 +0200
Subject: [R] warnings although R CMD check runs without any problem
In-Reply-To: <46F28A77.6090107@statistik.uni-dortmund.de>
References: <46F2884A.5090701@klinik.uni-regensburg.de>
	<46F28A77.6090107@statistik.uni-dortmund.de>
Message-ID: <46F29032.5050409@klinik.uni-regensburg.de>

Uwe Ligges wrote:
> Can you give examples?
>
> Uwe
>
>
> Christian Kohler wrote:
>   
>> Dear list members,
>>
>> as I am new to R, I would kindly like to ask for your help.
>>
>> I checked a package with the 'R CMD check' command and all worked out
>> well, (only 'OK' status). Loading its vignette afterwards with
>> 'source("package.Rcheck/inst/doc/vignette.R")' yields a message saying
>> that several (well, in my case more than 50) warnings still exist and
>> can be viewed via the 'warnings()' command.
>>
>> My question now is: why are there still warnings even though the check
>> has been passed without any problems? Generally speaking, would it be
>> possible to submit this package e.g. to the Bioconductor project, even
>> if these warnings still exist?
>>
>>
>> Thanks in advance,
>> Christian
>>
>>
>>
>>     
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   
Hello Uwe,

as the package is to submit to Bioconductor, I should have posted to the
BioC-Help instead but initially it was rather a 'R'-specific question to me.
My apology for that.

Examples for warning messages are

>warnings()
>1:The exprSet class is deprecated, use ExpressionSet instead
...
>6: The phenoData class is deprecated, use AnnotatedDataFrame (with
ExpressionSet) instead
>13: In s[v == x[1]] <- r : Number of elements to be replaced is not a
multiple of the substitution length.
....

In my opinion, these messages solely indicate some 'hints' which do not
interfere with any functionality within the package. Right?
As there is no reference to a file, which triggers these messages, I
have currently no idea where to take a closer look at.

Regards,
Christian

-- 

Christian Kohler
Institute of Functional Genomics
Computational Diagnostics
University of Regensburg
D-93147 Regensburg (Germany)


From silvia.figini at unipv.it  Thu Sep 20 15:38:16 2007
From: silvia.figini at unipv.it (Silvia Figini)
Date: Thu, 20 Sep 2007 15:38:16 +0200 (DFT)
Subject: [R] SUPER PARAMAGNETIC CLUSTERING
Message-ID: <2361.193.204.46.204.1190295496.squirrel@webmail.unipv.it>

Dear all,
we would like to know if there exist some routines (software) to build
models based on the super paramagnetic clustering.

Best regards,
Silvia Figini


-- 
Silvia Figini
Department of Statistics "L. Lenti"
University of Pavia
Via Strada Nuova, 65 - 27100 - Pavia, Italy
tel.+39- 0382-984660
http://musing.unipv.it/datamining


From ripley at stats.ox.ac.uk  Thu Sep 20 17:30:47 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Sep 2007 16:30:47 +0100 (BST)
Subject: [R] warnings although R CMD check runs without any problem
In-Reply-To: <46F2884A.5090701@klinik.uni-regensburg.de>
References: <46F2884A.5090701@klinik.uni-regensburg.de>
Message-ID: <Pine.LNX.4.64.0709201623360.15293@gannet.stats.ox.ac.uk>

On Thu, 20 Sep 2007, Christian Kohler wrote:

> Dear list members,
>
> as I am new to R, I would kindly like to ask for your help.
>
> I checked a package with the 'R CMD check' command and all worked out
> well, (only 'OK' status). Loading its vignette afterwards with
> 'source("package.Rcheck/inst/doc/vignette.R")' yields a message saying
> that several (well, in my case more than 50) warnings still exist and
> can be viewed via the 'warnings()' command.
>
> My question now is: why are there still warnings even though the check
> has been passed without any problems? Generally speaking, would it be

Because the check process does not consider R-level warnings in examples 
or vignettes, only errors.  Only someone who understands the code will 
know if the warnings are pedagogical, innocuous or serious.  No one says 
that examples should not give warnings, and it may be helpful to 
illustrate when they might occur.

> possible to submit this package e.g. to the Bioconductor project, even
> if these warnings still exist?

It is possible to submit it, and very likely that it would be acceptable. 
Distributing a package with warnings you do not understand is not a good 
idea, though.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Christian.Kohler at klinik.uni-regensburg.de  Thu Sep 20 17:51:05 2007
From: Christian.Kohler at klinik.uni-regensburg.de (Christian Kohler)
Date: Thu, 20 Sep 2007 17:51:05 +0200
Subject: [R] warnings although R CMD check runs without any problem
In-Reply-To: <Pine.LNX.4.64.0709201623360.15293@gannet.stats.ox.ac.uk>
References: <46F2884A.5090701@klinik.uni-regensburg.de>
	<Pine.LNX.4.64.0709201623360.15293@gannet.stats.ox.ac.uk>
Message-ID: <46F296E9.3000202@klinik.uni-regensburg.de>

Prof Brian Ripley wrote:
> On Thu, 20 Sep 2007, Christian Kohler wrote:
>
>   
>> Dear list members,
>>
>> as I am new to R, I would kindly like to ask for your help.
>>
>> I checked a package with the 'R CMD check' command and all worked out
>> well, (only 'OK' status). Loading its vignette afterwards with
>> 'source("package.Rcheck/inst/doc/vignette.R")' yields a message saying
>> that several (well, in my case more than 50) warnings still exist and
>> can be viewed via the 'warnings()' command.
>>
>> My question now is: why are there still warnings even though the check
>> has been passed without any problems? Generally speaking, would it be
>>     
>
> Because the check process does not consider R-level warnings in examples 
> or vignettes, only errors.  Only someone who understands the code will 
> know if the warnings are pedagogical, innocuous or serious.  No one says 
> that examples should not give warnings, and it may be helpful to 
> illustrate when they might occur.
>
>   
>> possible to submit this package e.g. to the Bioconductor project, even
>> if these warnings still exist?
>>     
>
> It is possible to submit it, and very likely that it would be acceptable. 
> Distributing a package with warnings you do not understand is not a good 
> idea, though.
>
>   
Dear Prof Ripley & Mr Ligges,

thanks for your help and the quick responses.

Regards,
Christian


-- 

Christian Kohler
Institute of Functional Genomics
Computational Diagnostics
University of Regensburg
D-93147 Regensburg (Germany)


From rgentlem at fhcrc.org  Thu Sep 20 17:53:03 2007
From: rgentlem at fhcrc.org (Robert Gentleman)
Date: Thu, 20 Sep 2007 08:53:03 -0700
Subject: [R] warnings although R CMD check runs without any problem
In-Reply-To: <46F29032.5050409@klinik.uni-regensburg.de>
References: <46F2884A.5090701@klinik.uni-regensburg.de>	<46F28A77.6090107@statistik.uni-dortmund.de>
	<46F29032.5050409@klinik.uni-regensburg.de>
Message-ID: <46F2975F.7060508@fhcrc.org>

Hi,

Christian Kohler wrote:
> Uwe Ligges wrote:
>> Can you give examples?
>>
>> Uwe
>>
>>
>> Christian Kohler wrote:
>>   
>>> Dear list members,
>>>
>>> as I am new to R, I would kindly like to ask for your help.
>>>
>>> I checked a package with the 'R CMD check' command and all worked out
>>> well, (only 'OK' status). Loading its vignette afterwards with
>>> 'source("package.Rcheck/inst/doc/vignette.R")' yields a message saying
>>> that several (well, in my case more than 50) warnings still exist and
>>> can be viewed via the 'warnings()' command.
>>>
>>> My question now is: why are there still warnings even though the check
>>> has been passed without any problems? Generally speaking, would it be
>>> possible to submit this package e.g. to the Bioconductor project, even
>>> if these warnings still exist?
>>>
>>>
>>> Thanks in advance,
>>> Christian
>>>
>>>
>>>
>>>     
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>   
> Hello Uwe,
> 
> as the package is to submit to Bioconductor, I should have posted to the
> BioC-Help instead but initially it was rather a 'R'-specific question to me.
> My apology for that.
> 
> Examples for warning messages are
> 
>> warnings()
>> 1:The exprSet class is deprecated, use ExpressionSet instead
> ...
>> 6: The phenoData class is deprecated, use AnnotatedDataFrame (with
> ExpressionSet) instead

  These tell you that you are using data structures that are no longer 
supported and should not be used. You need to fix them - the appropriate 
replacements are also indicated in the help message.

>> 13: In s[v == x[1]] <- r : Number of elements to be replaced is not a
> multiple of the substitution length.

   This is also serious. It suggests that you have an error in your 
code. Typically if one replaces the elements in one vector
s[v == x[1]], with those in another vector, namely r, the two sets 
should be the same length. In most (but not all) cases where this 
happens there is a bug.

> ....
> 
> In my opinion, these messages solely indicate some 'hints' which do not
> interfere with any functionality within the package. Right?

   No, wrong - the first two tell you that you are badly (at least one 
year) out of date in your use of data structures and the last one tells 
you that you probably have a serious problem with your code.


> As there is no reference to a file, which triggers these messages, I
> have currently no idea where to take a closer look at.

   Well, you did not give the whole output, and in it there really are 
names of files and locations.  You can also use an editor to search for
  1) any instance of the work exprSet or phenoData and replace those 
parts of the code with the new classes

  2) search for s[v == x[1]], and then use some of R's debugging methods 
to determine whether there is a bug or not.

  best wishes
    Robert

> 
> Regards,
> Christian
> 

-- 
Robert Gentleman, PhD
Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
PO Box 19024
Seattle, Washington 98109-1024
206-667-7700
rgentlem at fhcrc.org


From gavin.simpson at ucl.ac.uk  Thu Sep 20 17:54:29 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 20 Sep 2007 16:54:29 +0100
Subject: [R] Plotmath issue superscript "-"
Message-ID: <1190303669.22258.26.camel@gsimpson.geog.ucl.ac.uk>

Dear List,

I'm trying to typeset some chemical ions in axis labels. These have both
super and subscript components, and for some, I need a superscript "-".
In LaTeX I might use $NO_3^-$ to do the typesetting, but I'm having a
problem getting the correct invocation for expression:

> expression(NO^{-}[3])
Error: syntax error, unexpected '}' in "expression(NO^{-}"
> expression(NO^-[3])
Error: syntax error, unexpected '[' in "expression(NO^-["
> expression(NO^-)
Error: syntax error, unexpected ')' in "expression(NO^-)"
> expression(NO^{-})
Error: syntax error, unexpected '}' in "expression(NO^{-}"

This is with R 2.5.1 (exact version info below).

I suspect this is something to do with my use of the "-", which has some
special meaning.

Is there a way to achieve a superscript "-" (or similar looking
character) using the plotmath routines in R?

Thanks in advance,

G

> version
               _                                          
platform       i686-pc-linux-gnu                          
arch           i686                                       
os             linux-gnu                                  
system         i686, linux-gnu                            
status         Patched                                    
major          2                                          
minor          5.1                                        
year           2007                                       
month          07                                         
day            05                                         
svn rev        42131                                      
language       R                                          
version.string R version 2.5.1 Patched (2007-07-05 r42131)

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From yn19832 at msn.com  Thu Sep 20 18:06:35 2007
From: yn19832 at msn.com (livia)
Date: Thu, 20 Sep 2007 09:06:35 -0700 (PDT)
Subject: [R] Portfolio Optimization
Message-ID: <12800372.post@talk.nabble.com>


Hello,

I would like to solve a portfolio optimization problem in R. As far as I
searched, I found the example of "solve.QP" &"portfolio.optim". In my
understanding, both of them are based on given expected return, finding the
minimum variance. Is there a way of doing this in an opposite way?i.e
maximize the expected return subject to fixed variance? Or even better, like
combining these two together?

I would be grateful if anyone give me some advice or share the codes?
-- 
View this message in context: http://www.nabble.com/Portfolio-Optimization-tf4488519.html#a12800372
Sent from the R help mailing list archive at Nabble.com.


From Greg.Snow at intermountainmail.org  Thu Sep 20 18:11:07 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 20 Sep 2007 10:11:07 -0600
Subject: [R] Smooth line in graph
In-Reply-To: <46F24527.4@ual.es>
References: <46F181F4.9000904@ual.es>
	<07E228A5BE53C24CAD490193A7381BBBBF99D0@LP-EXCHVS07.CO.IHC.COM>
	<46F24527.4@ual.es>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBF9ABF@LP-EXCHVS07.CO.IHC.COM>

I don't know what SigmaPlot and Excel are doing for you, but I would guess that they are not doing cubic splines (as a general rule, when R and Excel differ, it is safest to assume that R is not the one doing something wrong)

Often differences between packages are due to differences in assumptions or model specifications.  I don't know SigmaPlot to be able to say what it is doing and a quick search of the excel help for 'spline' was not enlightening.

Perhaps what you are looking for is not a cubic spline.  Another option is an xspline.  These are implemented in the grid package.  Try:

library(grid)
library(lattice)

x<-c(-45,67,131,259,347)
y <- c(0.31, 0.45, 0.84, 0.43, 0.25)

s <- seq(-1,1, .25)

tmp.df <- data.frame(x=rep(x,9), y=rep(y,9), s=rep(s, each=5))

xyplot(y~x|factor(s), data=tmp.df, tmp.s=tmp.df$s, panel=function(x,y,subscripts,tmp.s,...){
 grid.points(x,y)
 tmp2.s <- tmp.s[subscripts]
print(tmp2.s)
 grid.xspline(x,y, default.units='native', shape=tmp2.s)
 })

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: Nestor Fernandez [mailto:nestor at ual.es] 
> Sent: Thursday, September 20, 2007 4:02 AM
> To: r-help at stat.math.ethz.ch
> Cc: Greg Snow
> Subject: Re: [R] Smooth line in graph
> 
> Sorry, I answered too quickly.
> It worked with the "simplified" example I provided but not 
> with non-regular intervals in x:
> 
> x<-c(-45,67,131,259,347)
> y <- c(0.31, 0.45, 0.84, 0.43, 0.25)
> 
> plot(x,y)
> lines(spline(x,y, method='n', n=250))
> #or:
> lines(predict(interpSpline(x, y)))
> 
> Produce the same decrease between first two points and the 
> shape is quite different to that produced by sigmaplot -I 
> need comparable figures. Changing "method" and "n" arguments 
> did not help.
> 
> Sorry for bothering. Any other suggestion?
> 
> 
> 
> 
> 
> 
> Greg Snow escribi?:
> > Try:
> >
> >   
> >> lines(spline(x,y, method='n', n=250))
> >>     
> >
> >   
> 
> 


From scionforbai at gmail.com  Thu Sep 20 18:16:36 2007
From: scionforbai at gmail.com (Scionforbai)
Date: Thu, 20 Sep 2007 18:16:36 +0200
Subject: [R] Plotmath issue superscript "-"
In-Reply-To: <1190303669.22258.26.camel@gsimpson.geog.ucl.ac.uk>
References: <1190303669.22258.26.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <e9ee1f0a0709200916n7eb3c4acj1586b518fd13867@mail.gmail.com>

Try:

  plot(0,0,"n")
  text(0,0,expression( {NO[3]}^'-'))


From p.dalgaard at biostat.ku.dk  Thu Sep 20 18:19:40 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 20 Sep 2007 18:19:40 +0200
Subject: [R] Plotmath issue superscript "-"
In-Reply-To: <1190303669.22258.26.camel@gsimpson.geog.ucl.ac.uk>
References: <1190303669.22258.26.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <46F29D9C.9010207@biostat.ku.dk>

Gavin Simpson wrote:
> Dear List,
>
> I'm trying to typeset some chemical ions in axis labels. These have both
> super and subscript components, and for some, I need a superscript "-".
> In LaTeX I might use $NO_3^-$ to do the typesetting, but I'm having a
> problem getting the correct invocation for expression:
>
>   
>> expression(NO^{-}[3])
>>     
> Error: syntax error, unexpected '}' in "expression(NO^{-}"
>   
>> expression(NO^-[3])
>>     
> Error: syntax error, unexpected '[' in "expression(NO^-["
>   
>> expression(NO^-)
>>     
> Error: syntax error, unexpected ')' in "expression(NO^-)"
>   
>> expression(NO^{-})
>>     
> Error: syntax error, unexpected '}' in "expression(NO^{-}"
>
> This is with R 2.5.1 (exact version info below).
>
> I suspect this is something to do with my use of the "-", which has some
> special meaning.
>
> Is there a way to achieve a superscript "-" (or similar looking
> character) using the plotmath routines in R?
>
>   
It's an operator, it needs something to operate on.

Try

 plot(0,main=quote(NO^-{}))



> Thanks in advance,
>
> G
>
>   
>> version
>>     
>                _                                          
> platform       i686-pc-linux-gnu                          
> arch           i686                                       
> os             linux-gnu                                  
> system         i686, linux-gnu                            
> status         Patched                                    
> major          2                                          
> minor          5.1                                        
> year           2007                                       
> month          07                                         
> day            05                                         
> svn rev        42131                                      
> language       R                                          
> version.string R version 2.5.1 Patched (2007-07-05 r42131)
>
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ccleland at optonline.net  Thu Sep 20 18:40:06 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 20 Sep 2007 12:40:06 -0400
Subject: [R] SEM - singularity error
In-Reply-To: <20070920090847.1wj6p314cgckkksg@webmail.duke.edu>
References: <20070920090847.1wj6p314cgckkksg@webmail.duke.edu>
Message-ID: <46F2A266.1030001@optonline.net>

nicolette.cagle at duke.edu wrote:
> Good morning,
> 
> I am trying to develop a structural equation model of snake abundance using
> habitat variables. In attempting to estimate the model using the "sem" package
> in R version 2.4.0, I receive the following error message:
> 
> "Error in solve.default(C) : system is computationally singular: reciprocal
> condition number = 1.75349e-16"
> 
> MAIN PROBLEM: I am hoping to discover why I am receiving the aforementioned
> error message and how to successfully estimate the model.
> 
> OTHER INFORMATION:
> 1. I believe the model is over-identified rather than under-identified (based on
> my understanding of the t-rule). I have observed data for 10 variables (9
> exogenous, 1 endogenous).
> 
> 2. I am not certain that I have used the proper tool to estimate the covariance
> matrix. In this case, I used the "VAR" function.
> 
> 3. I am most concerned that I have improperly coded the RAM file. For example,
> in a case where I have three exogenous indicators of one exogenous latent
> variable, I specify a start value of 1 for one of the exogenous indicators. I
> am not sure if this is proper or necessary.
> 
> 4. I am new to SEM; this is the first model I have ever tried to estimate.
> 
> R CODE: Below is the r-code I have used to estimate the structural equation
> model --
> 
> # LOADING R PACKAGES
> library(sem)
> 
> # READING IN THE CSV FILES
> thsi.2006<-read.csv("thsi_ab_env_space_sem.csv")
> thsi<-thsi.2006
> 
> # MAKING "RAM" FILE 2
> model2.nlc <-specify.model()
> Moist->slope, NA, 1
> Moist->sand, lamda21, NA
> Moist->clay, lamda31, NA
> Hab->isol, NA, 1
> Hab->edgedist_a, lamda52, NA
> Hab->ag10, lamda62, NA
> Hab->urb10, lamda72, NA
> Hab->rd10, lamda82, NA
> Hab->y, lamda92, NA
> Moist->this, gamma11, NA
> Hab->this, gamma12, NA
> slope<->slope, theta11, NA
> sand<->sand, theta22, NA
> clay<->clay, theta33, NA
> isol<->isol, theta44, NA
> edgedist_a<->edgedist_a, theta55, NA
> ag10<->ag10, theta66, NA
> urb10<->urb10, theta77, NA
> rd10<->rd10, theta88, NA
> y<->y, the99, NA
> Moist<->Moist, phi11, NA
> Hab<->Hab, phi22, NA
> this<->this, theps11, NA
> 
> model2.nlc
> end
> 
> # MAKING S (COVARIANCE MATRIX)
> thsi.var <- var(thsi)
> 
> # MAKING UNSCALED SEM MODEL
> sem2<-sem(ram=model2.nlc, S=thsi.var, N=22)
> 
> I am also attaching a jpeg diagram of the model I am trying to estimate. Please
> let me know if there is any additional information that I should add to this
> posting.
> 
> Thank you so much for your time.
> Nicolette Cagle

  Your specification of the model seems OK and it is over-identified (21
free parameters and 34 df).  I suspect the problem is that one or more
of your 10 variables is a linear function of the remaining variables.
If that is the case, then the following should give the same singularity
error:

factanal(thsi, factors=1)

  You may be able to drop one or more of the 10 variables from
consideration and successfully estimate a conceptually similar model.

hope this helps,

Chuck Cleland

> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894


From tom.cohen78 at yahoo.se  Thu Sep 20 18:46:06 2007
From: tom.cohen78 at yahoo.se (Tom Cohen)
Date: Thu, 20 Sep 2007 18:46:06 +0200 (CEST)
Subject: [R] help with making a function of scatter plot with multiple
	variables
Message-ID: <656269.86992.qm@web23001.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070920/10ecdd08/attachment.pl 

From ehlers at math.ucalgary.ca  Thu Sep 20 18:59:05 2007
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Thu, 20 Sep 2007 10:59:05 -0600
Subject: [R] Plotmath issue superscript "-"
In-Reply-To: <46F29D9C.9010207@biostat.ku.dk>
References: <1190303669.22258.26.camel@gsimpson.geog.ucl.ac.uk>
	<46F29D9C.9010207@biostat.ku.dk>
Message-ID: <46F2A6D9.7040406@math.ucalgary.ca>

If you need a subscript as well, I like

  plot(0, main=quote({NO^'\x96'}[3]))

Peter Ehlers

Peter Dalgaard wrote:
> Gavin Simpson wrote:
>> Dear List,
>>
>> I'm trying to typeset some chemical ions in axis labels. These have both
>> super and subscript components, and for some, I need a superscript "-".
>> In LaTeX I might use $NO_3^-$ to do the typesetting, but I'm having a
>> problem getting the correct invocation for expression:
>>
>>   
>>> expression(NO^{-}[3])
>>>     
>> Error: syntax error, unexpected '}' in "expression(NO^{-}"
>>   
>>> expression(NO^-[3])
>>>     
>> Error: syntax error, unexpected '[' in "expression(NO^-["
>>   
>>> expression(NO^-)
>>>     
>> Error: syntax error, unexpected ')' in "expression(NO^-)"
>>   
>>> expression(NO^{-})
>>>     
>> Error: syntax error, unexpected '}' in "expression(NO^{-}"
>>
>> This is with R 2.5.1 (exact version info below).
>>
>> I suspect this is something to do with my use of the "-", which has some
>> special meaning.
>>
>> Is there a way to achieve a superscript "-" (or similar looking
>> character) using the plotmath routines in R?
>>
>>   
> It's an operator, it needs something to operate on.
> 
> Try
> 
>  plot(0,main=quote(NO^-{}))
> 
> 
> 
>> Thanks in advance,
>>
>> G
>>
>>   
>>> version
>>>     
>>                _                                          
>> platform       i686-pc-linux-gnu                          
>> arch           i686                                       
>> os             linux-gnu                                  
>> system         i686, linux-gnu                            
>> status         Patched                                    
>> major          2                                          
>> minor          5.1                                        
>> year           2007                                       
>> month          07                                         
>> day            05                                         
>> svn rev        42131                                      
>> language       R                                          
>> version.string R version 2.5.1 Patched (2007-07-05 r42131)
>>
>>   
> 
>


From nicolette.cagle at duke.edu  Thu Sep 20 19:03:57 2007
From: nicolette.cagle at duke.edu (nicolette.cagle at duke.edu)
Date: Thu, 20 Sep 2007 13:03:57 -0400
Subject: [R] SEM - singularity error
In-Reply-To: <46F2A266.1030001@optonline.net>
References: <20070920090847.1wj6p314cgckkksg@webmail.duke.edu>
	<46F2A266.1030001@optonline.net>
Message-ID: <20070920130357.c97daun3cog0os4g@webmail.duke.edu>

Good afternoon Chuck,

I really appreciate your help. I just ran the factor analysis and did not
receive the singularity error (please see results below).

Do you happen to have any additional ideas or suggestions?

Thank you so much.
Nicki

FACTANAL RESULTS:
Call: factanal(x = thsi, factors = 1)

Uniquenesses:
      this edgedist_a       isol       ag10      urb10       rd10      slope
     0.705      0.914      0.232      0.124      0.136      0.017      0.952
      clay       sand          y
     0.534      0.485      0.144

Loadings:
           Factor1
this        0.543
edgedist_a  0.293
isol        0.876
ag10       -0.936
urb10       0.930
rd10        0.992
slope      -0.220
clay       -0.682
sand        0.718
y          -0.925

               Factor1
SS loadings      5.757
Proportion Var   0.576

Test of the hypothesis that 1 factor is sufficient.
The chi square statistic is 120.94 on 35 degrees of freedom.
The p-value is 2.17e-11

Quoting Chuck Cleland <ccleland at optonline.net>:

> nicolette.cagle at duke.edu wrote:
>> Good morning,
>>
>> I am trying to develop a structural equation model of snake abundance using
>> habitat variables. In attempting to estimate the model using the 
>> "sem" package
>> in R version 2.4.0, I receive the following error message:
>>
>> "Error in solve.default(C) : system is computationally singular: reciprocal
>> condition number = 1.75349e-16"
>>
>> MAIN PROBLEM: I am hoping to discover why I am receiving the aforementioned
>> error message and how to successfully estimate the model.
>>
>> OTHER INFORMATION:
>> 1. I believe the model is over-identified rather than 
>> under-identified (based on
>> my understanding of the t-rule). I have observed data for 10 variables (9
>> exogenous, 1 endogenous).
>>
>> 2. I am not certain that I have used the proper tool to estimate the 
>> covariance
>> matrix. In this case, I used the "VAR" function.
>>
>> 3. I am most concerned that I have improperly coded the RAM file. 
>> For example,
>> in a case where I have three exogenous indicators of one exogenous latent
>> variable, I specify a start value of 1 for one of the exogenous 
>> indicators. I
>> am not sure if this is proper or necessary.
>>
>> 4. I am new to SEM; this is the first model I have ever tried to estimate.
>>
>> R CODE: Below is the r-code I have used to estimate the structural equation
>> model --
>>
>> # LOADING R PACKAGES
>> library(sem)
>>
>> # READING IN THE CSV FILES
>> thsi.2006<-read.csv("thsi_ab_env_space_sem.csv")
>> thsi<-thsi.2006
>>
>> # MAKING "RAM" FILE 2
>> model2.nlc <-specify.model()
>> Moist->slope, NA, 1
>> Moist->sand, lamda21, NA
>> Moist->clay, lamda31, NA
>> Hab->isol, NA, 1
>> Hab->edgedist_a, lamda52, NA
>> Hab->ag10, lamda62, NA
>> Hab->urb10, lamda72, NA
>> Hab->rd10, lamda82, NA
>> Hab->y, lamda92, NA
>> Moist->this, gamma11, NA
>> Hab->this, gamma12, NA
>> slope<->slope, theta11, NA
>> sand<->sand, theta22, NA
>> clay<->clay, theta33, NA
>> isol<->isol, theta44, NA
>> edgedist_a<->edgedist_a, theta55, NA
>> ag10<->ag10, theta66, NA
>> urb10<->urb10, theta77, NA
>> rd10<->rd10, theta88, NA
>> y<->y, the99, NA
>> Moist<->Moist, phi11, NA
>> Hab<->Hab, phi22, NA
>> this<->this, theps11, NA
>>
>> model2.nlc
>> end
>>
>> # MAKING S (COVARIANCE MATRIX)
>> thsi.var <- var(thsi)
>>
>> # MAKING UNSCALED SEM MODEL
>> sem2<-sem(ram=model2.nlc, S=thsi.var, N=22)
>>
>> I am also attaching a jpeg diagram of the model I am trying to 
>> estimate. Please
>> let me know if there is any additional information that I should add to this
>> posting.
>>
>> Thank you so much for your time.
>> Nicolette Cagle
>
>  Your specification of the model seems OK and it is over-identified (21
> free parameters and 34 df).  I suspect the problem is that one or more
> of your 10 variables is a linear function of the remaining variables.
> If that is the case, then the following should give the same singularity
> error:
>
> factanal(thsi, factors=1)
>
>  You may be able to drop one or more of the 10 variables from
> consideration and successfully estimate a conceptually similar model.
>
> hope this helps,
>
> Chuck Cleland
>
>> ------------------------------------------------------------------------
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Chuck Cleland, Ph.D.
> NDRI, Inc.
> 71 West 23rd Street, 8th floor
> New York, NY 10010
> tel: (212) 845-4495 (Tu, Th)
> tel: (732) 512-0171 (M, W, F)
> fax: (917) 438-0894
>
>



-- 
Ecology Ph.D. Candidate
Duke University
Durham, NC 27708
www.duke.edu/~nlc4


From waltman at cs.nyu.edu  Thu Sep 20 19:31:59 2007
From: waltman at cs.nyu.edu (Peter Waltman)
Date: Thu, 20 Sep 2007 13:31:59 -0400
Subject: [R] how can I attach a variable stored in
Message-ID: <46F2AE8F.7030303@cs.nyu.edu>

Hi -

Any help would be greatly appreciated.

I'm loading a list variable that's stored in an .RData file and would 
like attach it.

I've used attach( <file_name> ), but that only lets me see the variable 
that's stored in the file. 

As the variable name is of the form "comp.x.x", I've tried using attach( 
ls( pat="comp" ) ), but get an error as ls() just gives back a string.

I've also played around with eval(), but don't really quite get what 
that function does since it seems to get into the R internals which I 
don't entirely understand and I haven't found any great unified 
documentation on R's handling environment and scoping.

Thanks,

Peter Waltman


From reeves at nceas.ucsb.edu  Thu Sep 20 19:32:27 2007
From: reeves at nceas.ucsb.edu (Rick Reeves)
Date: Thu, 20 Sep 2007 10:32:27 -0700
Subject: [R] Superimposing vector polygons over raster grid in a plot
Message-ID: <46F2AEAB.1080205@nceas.ucsb.edu>

Hello:

I would like to superimpose vector polygons (state outlines) from a 
Shape file on top of a satellite image,
imported into a SpatialGridDataFrame from GEOTIFF via gdal_translate and 
readGDAL.

When I plot polygon and point shape files in R, into 
SpatialPointDataFrame and SpatialPolygonDataFrame,
the two feature sets line up geographically, so it seems logical that a 
SpatialGridDataFrame should behave
in the same way.

 From my initial research, the spplot function is the correct function 
for plotting grids/images with axes and
annotation.

The big question is, how do I incorporate a Spatial(Points or 
Polygons)DataFrame into the spplot display list?

It seems as though many scientists would like to create such plots 
without resorting to GRASS or
another GIS.

Thanks for any advice,
Rick Reeves

Rick Reeves	
Scientific Programmer / Analyst	
National Center for Ecological Analysis and Synthesis
UC Santa Barbara
reeves at nceas.ucsb.edu
www.nceas.ucsb.edu
805 892 2533


From scionforbai at gmail.com  Thu Sep 20 19:38:05 2007
From: scionforbai at gmail.com (Scionforbai)
Date: Thu, 20 Sep 2007 19:38:05 +0200
Subject: [R] Plotmath issue superscript "-"
In-Reply-To: <46F2A6D9.7040406@math.ucalgary.ca>
References: <1190303669.22258.26.camel@gsimpson.geog.ucl.ac.uk>
	<46F29D9C.9010207@biostat.ku.dk> <46F2A6D9.7040406@math.ucalgary.ca>
Message-ID: <e9ee1f0a0709201038g1bcbc615saad7968d3601663c@mail.gmail.com>

Hallo,

> If you need a subscript as well, I like
>
>   plot(0, main=quote({NO^'\x96'}[3]))


I tried this but I get:

>  plot(0, main=quote({NO^'\x96'}[3]))
Errore in title(...) : stringa multibyte non valida ('invalid multibyte string')

My R version is:
platform       i686-redhat-linux-gnu
version.string R version 2.4.1 (2006-12-18)

locale is: LANG=it_IT.UTF-8

What is this multibyte string? Does it depend on LOCALE settings?
Where can I find further docs on this way to pass character
descriptors?
Thanks,
ScionForbai


From sonicbill12 at yahoo.com  Thu Sep 20 19:45:14 2007
From: sonicbill12 at yahoo.com (Bill Pepe)
Date: Thu, 20 Sep 2007 10:45:14 -0700 (PDT)
Subject: [R] Time series graphs
Message-ID: <348115.59776.qm@web37106.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070920/da02e23d/attachment.pl 

From muenchen at utk.edu  Thu Sep 20 19:49:56 2007
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Thu, 20 Sep 2007 13:49:56 -0400
Subject: [R] Cutting & pasting help examples into script window
In-Reply-To: <20070920141641.GA25114@eddelbuettel.com>
References: <347152339B716A4D893C9A2988EA87C86927C6@KFSVS2.utk.tennessee.edu>
	<200709201518.11464.stefan.grosse@uni-erfurt.de>
	<347152339B716A4D893C9A2988EA87C8692812@KFSVS2.utk.tennessee.edu>
	<20070920141641.GA25114@eddelbuettel.com>
Message-ID: <347152339B716A4D893C9A2988EA87C86928FD@KFSVS2.utk.tennessee.edu>

Does this look like a bug? If so, is there a different way to report it?
Thanks, Bob

> -----Original Message-----
> From: Dirk Eddelbuettel [mailto:edd at debian.org]
> Sent: Thursday, September 20, 2007 10:17 AM
> To: Muenchen, Robert A (Bob)
> Subject: Re: [R] Cutting & pasting help examples into script window
> 
> On Thu, Sep 20, 2007 at 10:01:03AM -0400, Muenchen, Robert A (Bob)
> wrote:
> > Stephan Grosse replied:
> >
> > >
> > > What I do not understand is why you not just type
> > example(yourcommand)?
> > >
> > > Stefan
> >
> > That's a good question. I want to play around with variations of the
> > examples rather than run them exactly as they are.
> 
> In Emacs' wonderful ESS mode, you just press 'l' and the line of
> example code you're on gets sent to R.  You can then 'pick it up' in
> the R buffer and play with it.  I do that all the time ...
> 
> Dirk
> 
> --
> Three out of two people have difficulties with fractions.


From jfox at mcmaster.ca  Thu Sep 20 20:00:11 2007
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 20 Sep 2007 14:00:11 -0400
Subject: [R] SEM - singularity error
In-Reply-To: <46F2A266.1030001@optonline.net>
References: <20070920090847.1wj6p314cgckkksg@webmail.duke.edu>
	<46F2A266.1030001@optonline.net>
Message-ID: <web-186241572@cgpsrv2.cis.mcmaster.ca>

Dear Nicolette and Chuck,

I apologize for not seeing Nicolette's original posting.

The model does appear to be correctly specified (though I didn't see
the path diagram) and over-identified. I assume that all of the
variables with lower-case names are observed variables and that "Moist"
and "Hab" are latent variables. (Simply comparing the number of free
parameters to the number of unique covariances among observed variables
provides a necessary but not sufficient condition for identification.
This model is identified because there more than two unique indicators
for each latent variable and because the structural submodel relating
"this" to "Moist" and "Hab" is identified.)

I suspect that the problem here is the restriction that "Moist" and
"Hab" are uncorrelated, which follows from the lack of a double-headed
arrow connecting these variables. You might try adding Moist <-> Hab to
the model.

I hope this helps,
 John


On Thu, 20 Sep 2007 12:40:06 -0400
 Chuck Cleland <ccleland at optonline.net> wrote:
> nicolette.cagle at duke.edu wrote:
> > Good morning,
> > 
> > I am trying to develop a structural equation model of snake
> abundance using
> > habitat variables. In attempting to estimate the model using the
> "sem" package
> > in R version 2.4.0, I receive the following error message:
> > 
> > "Error in solve.default(C) : system is computationally singular:
> reciprocal
> > condition number = 1.75349e-16"
> > 
> > MAIN PROBLEM: I am hoping to discover why I am receiving the
> aforementioned
> > error message and how to successfully estimate the model.
> > 
> > OTHER INFORMATION:
> > 1. I believe the model is over-identified rather than
> under-identified (based on
> > my understanding of the t-rule). I have observed data for 10
> variables (9
> > exogenous, 1 endogenous).
> > 
> > 2. I am not certain that I have used the proper tool to estimate
> the covariance
> > matrix. In this case, I used the "VAR" function.
> > 
> > 3. I am most concerned that I have improperly coded the RAM file.
> For example,
> > in a case where I have three exogenous indicators of one exogenous
> latent
> > variable, I specify a start value of 1 for one of the exogenous
> indicators. I
> > am not sure if this is proper or necessary.
> > 
> > 4. I am new to SEM; this is the first model I have ever tried to
> estimate.
> > 
> > R CODE: Below is the r-code I have used to estimate the structural
> equation
> > model --
> > 
> > # LOADING R PACKAGES
> > library(sem)
> > 
> > # READING IN THE CSV FILES
> > thsi.2006<-read.csv("thsi_ab_env_space_sem.csv")
> > thsi<-thsi.2006
> > 
> > # MAKING "RAM" FILE 2
> > model2.nlc <-specify.model()
> > Moist->slope, NA, 1
> > Moist->sand, lamda21, NA
> > Moist->clay, lamda31, NA
> > Hab->isol, NA, 1
> > Hab->edgedist_a, lamda52, NA
> > Hab->ag10, lamda62, NA
> > Hab->urb10, lamda72, NA
> > Hab->rd10, lamda82, NA
> > Hab->y, lamda92, NA
> > Moist->this, gamma11, NA
> > Hab->this, gamma12, NA
> > slope<->slope, theta11, NA
> > sand<->sand, theta22, NA
> > clay<->clay, theta33, NA
> > isol<->isol, theta44, NA
> > edgedist_a<->edgedist_a, theta55, NA
> > ag10<->ag10, theta66, NA
> > urb10<->urb10, theta77, NA
> > rd10<->rd10, theta88, NA
> > y<->y, the99, NA
> > Moist<->Moist, phi11, NA
> > Hab<->Hab, phi22, NA
> > this<->this, theps11, NA
> > 
> > model2.nlc
> > end
> > 
> > # MAKING S (COVARIANCE MATRIX)
> > thsi.var <- var(thsi)
> > 
> > # MAKING UNSCALED SEM MODEL
> > sem2<-sem(ram=model2.nlc, S=thsi.var, N=22)
> > 
> > I am also attaching a jpeg diagram of the model I am trying to
> estimate. Please
> > let me know if there is any additional information that I should
> add to this
> > posting.
> > 
> > Thank you so much for your time.
> > Nicolette Cagle
> 
>   Your specification of the model seems OK and it is over-identified
> (21
> free parameters and 34 df).  I suspect the problem is that one or
> more
> of your 10 variables is a linear function of the remaining variables.
> If that is the case, then the following should give the same
> singularity
> error:
> 
> factanal(thsi, factors=1)
> 
>   You may be able to drop one or more of the 10 variables from
> consideration and successfully estimate a conceptually similar model.
> 
> hope this helps,
> 
> Chuck Cleland
> 
> >
>
------------------------------------------------------------------------
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Chuck Cleland, Ph.D.
> NDRI, Inc.
> 71 West 23rd Street, 8th floor
> New York, NY 10010
> tel: (212) 845-4495 (Tu, Th)
> tel: (732) 512-0171 (M, W, F)
> fax: (917) 438-0894
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From sfriedma at sfwmd.gov  Thu Sep 20 20:00:40 2007
From: sfriedma at sfwmd.gov (Friedman, Steven)
Date: Thu, 20 Sep 2007 14:00:40 -0400
Subject: [R] Non-metric multidimensional scaling
Message-ID: <14A2A120D369B6469BB154B2D2DC34D208E50A88@EXCHVS01.ad.sfwmd.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070920/fc87a92e/attachment.pl 

From wtimm at techfak.uni-bielefeld.de  Thu Sep 20 20:06:30 2007
From: wtimm at techfak.uni-bielefeld.de (Wiebke Timm)
Date: Thu, 20 Sep 2007 14:06:30 -0400
Subject: [R] Strange behaviour of lars method
In-Reply-To: <uvea5i8pr.fsf@insightful.com>
References: <0AE9110A-E342-4CDA-BA92-A8D5A9156DDD@techfak.uni-bielefeld.de>
	<uvea5i8pr.fsf@insightful.com>
Message-ID: <8BF02B28-3643-456B-A5F8-0E0EBED1F326@techfak.uni-bielefeld.de>

Thanks for your answer!

On 20.09.2007, at 12:48, Tim Hesterberg wrote:

> Might you be having numerical problems?

That might very well be what's happening. Did hope that it only  
happens late in the procedure so I can ignore it, but those Cp values  
indicate I maybe can't.

> If you're using the "lars"
> library, it uses cross-product matrices, which are notoriously
> numerically unstable in regression calculations when there is
> high multiple correlation among the x's.

...as is the case in my data. Good to know...

> We have a prototype package that offers more stable calculations,
> using QR decompositions.
> See http://www.insightful.com/Hesterberg/glars
> Let me know if you'd like to try this.

Yes, please!

Just also had a peak at the ProcASA paper that's linked there... I  
did not know about elastic net before, maybe I will try that too for  
comparison... In fact (like always) I don't really know what method  
would be best.

Did you try lars or glars on some more noisy/bad/difficult data sets?  
How good is its stability/generalization capability on these?
You write the original LARS method is for linear regression. But it  
includes the lasso solutions. Lasso can have nonlinear solutions  
because of the penalty used. Or did I misunderstand something?

Regards,
    Wiebke


From ggrothendieck at gmail.com  Thu Sep 20 20:15:54 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 20 Sep 2007 14:15:54 -0400
Subject: [R] Time series graphs
In-Reply-To: <348115.59776.qm@web37106.mail.mud.yahoo.com>
References: <348115.59776.qm@web37106.mail.mud.yahoo.com>
Message-ID: <971536df0709201115r56c0406bi78390b1eb8d9463a@mail.gmail.com>

Using plot.zoo in the zoo package try this:

Lines <- "Bob.A         Bob.B            Tom.A        Tom.B
 Jan              8        4             9         8
 Feb             7         5             4         7
 Mar             6         8             4         4
 Apr             3         7              6         2
 May            5         1             8         5
 Jun             6         4              7        1
 July             2         8             3         4
 Aug             1        2              4         8
 Sep            4          3              1        9
"
DF <- read.table(textConnection(Lines))

library(zoo)
z <- zooreg(as.matrix(DF), start = as.yearmon(as.Date("2007-01-01")), freq = 12)
z <- aggregate(z, as.Date, tail, 1)
plot(z, plot.type = "single",  type = "o",
	pch = c("A", "A", "B", "B"), lty = 1:2)
legend("bottomleft", c("Bob", "Tom"), lty = 1:2)



On 9/20/07, Bill Pepe <sonicbill12 at yahoo.com> wrote:
> I'm fairly new to S-Plus and I need to get this done quickly. Suppose I have the following fake data below:
>
>  There are two companies, call them Bob and Tom. Each have two variables, call them A and B, that have observations.
>
>                         Bob                 Tom
>
>                    A         B            A        B
>  Jan              8        4             9         8
>  Feb             7         5             4         7
>  Mar             6         8             4         4
>  Apr             3         7              6         2
>  May            5         1             8         5
>  Jun             6         4              7        1
>  July             2         8             3         4
>  Aug             1        2              4         8
>  Sep            4          3              1        9
>
>  Here is what I want to do: I want to make two different graphs, one for Bob and one for Tom. For each graph, plot both variables A and B. Connect the A values with a line, and connect the B values with a different type of line. So there should be two lines for each graph. For the A line, at each time point, the letter A should be on the line. And the same goes for the B line. Either R or S-Plus since they are essentially the same.
>
>  I'm sure this is easy, but any help would be greatly appreciated.
>
>  Thanks,
>
>  Bill
>
>
> ---------------------------------
> Pinpoint customers who are looking for what you sell.
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dato_u at yahoo.com  Thu Sep 20 20:22:05 2007
From: dato_u at yahoo.com (David U.)
Date: Thu, 20 Sep 2007 11:22:05 -0700 (PDT)
Subject: [R] Conditional Logit and Mixed Logit
Message-ID: <12802959.post@talk.nabble.com>


Hello,

Could anybody provide me with codes (procedure) how to obtain Conditional
Logit (McFadden) and Mixed Logit (say, assuming normal distribution)
estimates in R?

Thanks,
David U.
-- 
View this message in context: http://www.nabble.com/Conditional-Logit-and-Mixed-Logit-tf4489238.html#a12802959
Sent from the R help mailing list archive at Nabble.com.


From bolker at ufl.edu  Thu Sep 20 20:24:52 2007
From: bolker at ufl.edu (bbolker)
Date: Thu, 20 Sep 2007 11:24:52 -0700 (PDT)
Subject: [R] Ambiguities in vector
In-Reply-To: <8FA3D679-C879-4C88-8775-0951FFD99F1D@systbot.uzh.ch>
References: <8FA3D679-C879-4C88-8775-0951FFD99F1D@systbot.uzh.ch>
Message-ID: <12802997.post@talk.nabble.com>




Birgit Lemcke wrote:
> 
> 
> Perhaps you haven?t understood my question in the mail yesterday. So  
> I will try to describe my problem in a different way
> 
> You see the tables. I would like to test the variables between the  
> tables. 
> 

I'm afraid that even before we start to deal with the ambiguities
your question is not clear.   What do you want to know, and before
you sat down at the computer what statistical test did you intend
to use?  (For better or worse, most of the documentation of R
_assumes_ you know what you want to test and how you want to
do it.)   I'm supposing you want to do some kind of comparison
across communities (tables 1 and 2), but I don't know what kind.
Comparing a single cell of the table to another just asks if
the leaf form is the same in the two communities.  Do you just
want to ask if leaf forms of a given species are significantly different
in different communities?  I'm not sure what the null hypothesis
would be here.  What are the rows and columns?  Can we use
them to develop a hypothesis?

If you can say precisely what your question is and how you would
test it in the _absence_ of ambiguity (i.e., specify a statistical test --
you don't need to know how to run it in R, that's what the list is
actually for), then we can help you decide how to handle the
multiple coding problem.

  good luck
    Ben Bolker
-- 
View this message in context: http://www.nabble.com/Ambiguities-in-vector-tf4485921.html#a12802997
Sent from the R help mailing list archive at Nabble.com.


From zhpan99 at yahoo.com  Thu Sep 20 20:28:08 2007
From: zhpan99 at yahoo.com (Pan Zheng)
Date: Thu, 20 Sep 2007 11:28:08 -0700 (PDT)
Subject: [R] convert data from
Message-ID: <984153.17774.qm@web58711.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070920/e9678288/attachment.pl 

From Mark.Leeds at morganstanley.com  Thu Sep 20 20:48:01 2007
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Thu, 20 Sep 2007 14:48:01 -0400
Subject: [R] how can I attach a variable stored in
In-Reply-To: <46F2AE8F.7030303@cs.nyu.edu>
References: <46F2AE8F.7030303@cs.nyu.edu>
Message-ID: <D3AEEDA31E57474B840BEBC25A8A834401957B1F@NYWEXMB23.msad.ms.com>

I don't think I understand your question but John Fox has written a very
nice documentat about scoping and environments on his website.
It's probably easy to find the site by googling "John Fox" but, if you
can't find it, let me know.
 
As I said, I don't think that I understand your question but, if you
loaded a list variable using load("whatever.Rdata"), the variable will 
just be suitting in  your workspace. You don't need to attach anything
because load just loads the data right into the workspace.
So typing the variable name should show the data.




-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Peter Waltman
Sent: Thursday, September 20, 2007 1:32 PM
To: r-help at r-project.org
Subject: [R] how can I attach a variable stored in

Hi -

Any help would be greatly appreciated.

I'm loading a list variable that's stored in an .RData file and would
like attach it.

I've used attach( <file_name> ), but that only lets me see the variable
that's stored in the file. 

As the variable name is of the form "comp.x.x", I've tried using attach(
ls( pat="comp" ) ), but get an error as ls() just gives back a string.

I've also played around with eval(), but don't really quite get what
that function does since it seems to get into the R internals which I
don't entirely understand and I haven't found any great unified
documentation on R's handling environment and scoping.

Thanks,

Peter Waltman

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From slomascolo at zoo.ufl.edu  Thu Sep 20 20:57:30 2007
From: slomascolo at zoo.ufl.edu (Silvia Lomascolo)
Date: Thu, 20 Sep 2007 11:57:30 -0700 (PDT)
Subject: [R] Non-metric multidimensional scaling
In-Reply-To: <14A2A120D369B6469BB154B2D2DC34D208E50A88@EXCHVS01.ad.sfwmd.gov>
References: <14A2A120D369B6469BB154B2D2DC34D208E50A88@EXCHVS01.ad.sfwmd.gov>
Message-ID: <12803598.post@talk.nabble.com>



>Error in isoMDS(Gquad.dist) : zero or negative distance between objects
>179 and 180.
>How can I handle this, is it valid to add 0.5 to every element in the
>distance matrix or is someother  alternative more appropriate?

This means that your objects 179 and 180 are identical so just remove one of
the two.  They both have the same distance to all other objects so your
results shouldn't change.  Whatever conclusion you draw from the location of
one on your plot, you can say the same for the other. 

Silvia.





 

Thanks in advance

Steve

 

 

Steve Friedman, PhD

Everglades Division

Senior Environmental Scientist, Landscape Ecology

South Florida Water Management District

3301 Gun Club Road

West Palm Beach, Florida 33406

email:  sfriedma at sfwmd.gov

Office:  561 - 682 - 6312

Fax:      561 - 682 - 5980

 

If you are not doing what you truly enjoy its your obligation to
yourself to change.

 


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



-- 
View this message in context: http://www.nabble.com/Non-metric-multidimensional-scaling-tf4489161.html#a12803598
Sent from the R help mailing list archive at Nabble.com.


From andy_liaw at merck.com  Thu Sep 20 21:02:50 2007
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 20 Sep 2007 15:02:50 -0400
Subject: [R] random Forests
In-Reply-To: <BLU116-W2258CCE788A43772BF38B9CCBF0@phx.gbl>
References: <BLU116-W2258CCE788A43772BF38B9CCBF0@phx.gbl>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA04B29B7B@usctmx1106.merck.com>

1) See the help pages for save() and load().  We do this all the time. 

2) Prediction (or what you call scoring) given the matrix structure is
quite simple.  Take a look at the underlying C source code.  You can
write that in any language you want without much problem.

Andy

From: David Montgomery
> 
> Hi,
>  
> I am new to R and have a specific question about the 
> randomForest package and the saving of trees and scoring.
>  
> 1) I am looking to save the trees and score at a later time.  
> Is there a way to load the saved trees and use the predict 
> function?  Can objects be saved and loaded i.e. the 
> randomForest function call?  I dont want to have to rerun 
> trees.  Hopefully this applies to any stat type procedure 
> that requires scoring.
>  
> 2) Has anybody written any code in any other language that 
> optimizes scoring using the format that the trees are saved 
> in?  Ideally I would like to do real time scoring outside of 
> R and hoping that someone has code in python or c++developed 
> around the matrix format of the tree structure.
>  
> Thanks,
>  
> David
>  
>  
>  
>  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}


From nicolette.cagle at duke.edu  Thu Sep 20 21:05:51 2007
From: nicolette.cagle at duke.edu (nicolette.cagle at duke.edu)
Date: Thu, 20 Sep 2007 15:05:51 -0400
Subject: [R] SEM - singularity error
In-Reply-To: <web-186241572@cgpsrv2.cis.mcmaster.ca>
References: <20070920090847.1wj6p314cgckkksg@webmail.duke.edu>
	<46F2A266.1030001@optonline.net>
	<web-186241572@cgpsrv2.cis.mcmaster.ca>
Message-ID: <20070920150551.zgct9hxn88cwg80g@webmail.duke.edu>

Dear John,

Thank you so much for your assistance, it is greatly appreciated. You are
correct in your interpretation of the variables (Moist and Hab are latent, the
other, lower case variables are observed). I've attempted to run the model
again adding Moist <-> Hab (please see code below) and still receive the same
error message:

"Error in solve.default(C) : system is computationally singular: reciprocal
condition number = 6.59035e-17."

Is it possible that something is wrong with the variance-covariance matrix
(please see pasted below r code)? Are extremely small values (e.g., 4e-4)
problematic? Do you have any additional suggestions as to how I might go about
trouble shooting this problem?

I am also attaching the jpeg model diagram, in case it could be of use to you.

Thank you so much for your time.
Best wishes,
Nicki

R CODE USED:
# 20 Sep 2007 SEM of Thamnophis abundance

# LOADING R PACKAGES
library(sem)

# READING IN THE CSV FILES
thsi.2006<-read.csv("thsi_ab_env_space_sem.csv")
thsi<-thsi.2006

# MAKING "RAM" FILE 3
model3.nlc <-specify.model()
Moist->slope, NA, 1
Moist->sand, lamda21, NA
Moist->clay, lamda31, NA
Hab->isol, NA, 1
Hab->edgedist_a, lamda52, NA
Hab->ag10, lamda62, NA
Hab->urb10, lamda72, NA
Hab->rd10, lamda82, NA
Hab->y, lamda92, NA
Moist->this, gamma11, NA
Hab->this, gamma12, NA
slope<->slope, theta11, NA
sand<->sand, theta22, NA
clay<->clay, theta33, NA
isol<->isol, theta44, NA
edgedist_a<->edgedist_a, theta55, NA
ag10<->ag10, theta66, NA
urb10<->urb10, theta77, NA
rd10<->rd10, theta88, NA
y<->y, the99, NA
Moist<->Moist, phi11, NA
Hab<->Hab, phi22, NA
Moist<->Hab, phi21, NA
this<->this, theps11, NA

model3.nlc
end

# MAKING S (COVARIANCE MATRIX)
thsi.var <- var(thsi)

# MAKING UNSCALED SEM MODEL
sem3<-sem(ram=model3.nlc, S=thsi.var, N=22)

VARIANCE-COVARIANCE MATRIX (AKA: thsi.var):
   this
this          8.88528139
edgedist_a   44.91469329
isol       2678.38321991
ag10         -0.38967619
urb10         0.11704827
rd10          0.02132100
slope        -2.25074394
clay        -36.19339827
sand         19.66753247
y            -0.95970602
              edgedist_a
this          44.9146933
edgedist_a 17491.7873712
isol       96122.5594957
ag10          -9.1045614
urb10          1.9439758
rd10           0.5333281
slope         24.4351358
clay       -1360.1102116
sand         619.1507519
y            -15.4852253
                    isol
this          2678.38322
edgedist_a   96122.55950
isol       4167108.48214
ag10          -347.26757
urb10           91.79339
rd10            25.71996
slope         -392.44092
clay        -42236.76039
sand         19461.19308
y             -868.20597
                    ag10
this         -0.38967619
edgedist_a   -9.10456137
isol       -347.26756672
ag10          0.05167298
urb10        -0.01314388
rd10         -0.00297957
slope         0.06923224
clay          3.17604271
sand         -1.61043719
y             0.11896881
                  urb10
this        0.117048268
edgedist_a  1.943975810
isol       91.793388529
ag10       -0.013143880
urb10       0.003733677
rd10        0.000784747
slope      -0.039094302
clay       -0.907067141
sand        0.491619654
y          -0.034343332
                    rd10
this        0.0213209957
edgedist_a  0.5333280831
isol       25.7199633947
ag10       -0.0029795700
urb10       0.0007847471
rd10        0.0001987203
slope      -0.0041496227
clay       -0.2726142316
sand        0.1286087229
y          -0.0078502982
                   slope
this       -2.250744e+00
edgedist_a  2.443514e+01
isol       -3.924409e+02
ag10        6.923224e-02
urb10      -3.909430e-02
rd10       -4.149623e-03
slope       2.520968e+00
clay        3.343637e+00
sand       -2.202094e+00
y           3.306712e-01
                    clay
this       -3.619340e+01
edgedist_a -1.360110e+03
isol       -4.223676e+04
ag10        3.176043e+00
urb10      -9.070671e-01
rd10       -2.726142e-01
slope       3.343637e+00
clay        7.962072e+02
sand       -3.410372e+02
y           1.096320e+01
                    sand
this          19.6675325
edgedist_a   619.1507519
isol       19461.1930766
ag10          -1.6104372
urb10          0.4916197
rd10           0.1286087
slope         -2.2020936
clay        -341.0372225
sand         165.1578113
y             -5.4148540
                       y
this       -9.597060e-01
edgedist_a -1.548523e+01
isol       -8.682060e+02
ag10        1.189688e-01
urb10      -3.434333e-02
rd10       -7.850298e-03
slope       3.306712e-01
clay        1.096320e+01
sand       -5.414854e+00
y           3.694397e-01


Quoting John Fox <jfox at mcmaster.ca>:

> Dear Nicolette and Chuck,
>
> I apologize for not seeing Nicolette's original posting.
>
> The model does appear to be correctly specified (though I didn't see
> the path diagram) and over-identified. I assume that all of the
> variables with lower-case names are observed variables and that "Moist"
> and "Hab" are latent variables. (Simply comparing the number of free
> parameters to the number of unique covariances among observed variables
> provides a necessary but not sufficient condition for identification.
> This model is identified because there more than two unique indicators
> for each latent variable and because the structural submodel relating
> "this" to "Moist" and "Hab" is identified.)
>
> I suspect that the problem here is the restriction that "Moist" and
> "Hab" are uncorrelated, which follows from the lack of a double-headed
> arrow connecting these variables. You might try adding Moist <-> Hab to
> the model.
>
> I hope this helps,
> John
>
>
> On Thu, 20 Sep 2007 12:40:06 -0400
> Chuck Cleland <ccleland at optonline.net> wrote:
>> nicolette.cagle at duke.edu wrote:
>> > Good morning,
>> >
>> > I am trying to develop a structural equation model of snake
>> abundance using
>> > habitat variables. In attempting to estimate the model using the
>> "sem" package
>> > in R version 2.4.0, I receive the following error message:
>> >
>> > "Error in solve.default(C) : system is computationally singular:
>> reciprocal
>> > condition number = 1.75349e-16"
>> >
>> > MAIN PROBLEM: I am hoping to discover why I am receiving the
>> aforementioned
>> > error message and how to successfully estimate the model.
>> >
>> > OTHER INFORMATION:
>> > 1. I believe the model is over-identified rather than
>> under-identified (based on
>> > my understanding of the t-rule). I have observed data for 10
>> variables (9
>> > exogenous, 1 endogenous).
>> >
>> > 2. I am not certain that I have used the proper tool to estimate
>> the covariance
>> > matrix. In this case, I used the "VAR" function.
>> >
>> > 3. I am most concerned that I have improperly coded the RAM file.
>> For example,
>> > in a case where I have three exogenous indicators of one exogenous
>> latent
>> > variable, I specify a start value of 1 for one of the exogenous
>> indicators. I
>> > am not sure if this is proper or necessary.
>> >
>> > 4. I am new to SEM; this is the first model I have ever tried to
>> estimate.
>> >
>> > R CODE: Below is the r-code I have used to estimate the structural
>> equation
>> > model --
>> >
>> > # LOADING R PACKAGES
>> > library(sem)
>> >
>> > # READING IN THE CSV FILES
>> > thsi.2006<-read.csv("thsi_ab_env_space_sem.csv")
>> > thsi<-thsi.2006
>> >
>> > # MAKING "RAM" FILE 2
>> > model2.nlc <-specify.model()
>> > Moist->slope, NA, 1
>> > Moist->sand, lamda21, NA
>> > Moist->clay, lamda31, NA
>> > Hab->isol, NA, 1
>> > Hab->edgedist_a, lamda52, NA
>> > Hab->ag10, lamda62, NA
>> > Hab->urb10, lamda72, NA
>> > Hab->rd10, lamda82, NA
>> > Hab->y, lamda92, NA
>> > Moist->this, gamma11, NA
>> > Hab->this, gamma12, NA
>> > slope<->slope, theta11, NA
>> > sand<->sand, theta22, NA
>> > clay<->clay, theta33, NA
>> > isol<->isol, theta44, NA
>> > edgedist_a<->edgedist_a, theta55, NA
>> > ag10<->ag10, theta66, NA
>> > urb10<->urb10, theta77, NA
>> > rd10<->rd10, theta88, NA
>> > y<->y, the99, NA
>> > Moist<->Moist, phi11, NA
>> > Hab<->Hab, phi22, NA
>> > this<->this, theps11, NA
>> >
>> > model2.nlc
>> > end
>> >
>> > # MAKING S (COVARIANCE MATRIX)
>> > thsi.var <- var(thsi)
>> >
>> > # MAKING UNSCALED SEM MODEL
>> > sem2<-sem(ram=model2.nlc, S=thsi.var, N=22)
>> >
>> > I am also attaching a jpeg diagram of the model I am trying to
>> estimate. Please
>> > let me know if there is any additional information that I should
>> add to this
>> > posting.
>> >
>> > Thank you so much for your time.
>> > Nicolette Cagle
>>
>>   Your specification of the model seems OK and it is over-identified
>> (21
>> free parameters and 34 df).  I suspect the problem is that one or
>> more
>> of your 10 variables is a linear function of the remaining variables.
>> If that is the case, then the following should give the same
>> singularity
>> error:
>>
>> factanal(thsi, factors=1)
>>
>>   You may be able to drop one or more of the 10 variables from
>> consideration and successfully estimate a conceptually similar model.
>>
>> hope this helps,
>>
>> Chuck Cleland
>>
>> >
>>
> ------------------------------------------------------------------------
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Chuck Cleland, Ph.D.
>> NDRI, Inc.
>> 71 West 23rd Street, 8th floor
>> New York, NY 10010
>> tel: (212) 845-4495 (Tu, Th)
>> tel: (732) 512-0171 (M, W, F)
>> fax: (917) 438-0894
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --------------------------------
> John Fox, Professor
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox/
>



-- 
Ecology Ph.D. Candidate
Duke University
Durham, NC 27708
www.duke.edu/~nlc4

From birgit.lemcke at systbot.uzh.ch  Thu Sep 20 21:14:43 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Thu, 20 Sep 2007 21:14:43 +0200
Subject: [R] Ambiguities in vector
In-Reply-To: <12802997.post@talk.nabble.com>
References: <8FA3D679-C879-4C88-8775-0951FFD99F1D@systbot.uzh.ch>
	<12802997.post@talk.nabble.com>
Message-ID: <AFE3DEF9-1F12-4ACC-B722-98BBB7DC245A@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070920/adb02cbb/attachment.pl 

From ehlers at math.ucalgary.ca  Thu Sep 20 21:19:04 2007
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Thu, 20 Sep 2007 13:19:04 -0600
Subject: [R] Plotmath issue superscript "-"
In-Reply-To: <e9ee1f0a0709201038g1bcbc615saad7968d3601663c@mail.gmail.com>
References: <1190303669.22258.26.camel@gsimpson.geog.ucl.ac.uk>	
	<46F29D9C.9010207@biostat.ku.dk>
	<46F2A6D9.7040406@math.ucalgary.ca>
	<e9ee1f0a0709201038g1bcbc615saad7968d3601663c@mail.gmail.com>
Message-ID: <46F2C7A8.50205@math.ucalgary.ca>

Yes, sorry, I should have said that I was on Windows.
In a UTF-8 locale, you could try \u2013 in place of \x96.
The character is an endash.

Peter Ehlers

Scionforbai wrote:
> Hallo,
> 
>> If you need a subscript as well, I like
>>
>>   plot(0, main=quote({NO^'\x96'}[3]))
> 
> 
> I tried this but I get:
> 
>>  plot(0, main=quote({NO^'\x96'}[3]))
> Errore in title(...) : stringa multibyte non valida ('invalid multibyte string')
> 
> My R version is:
> platform       i686-redhat-linux-gnu
> version.string R version 2.4.1 (2006-12-18)
> 
> locale is: LANG=it_IT.UTF-8
> 
> What is this multibyte string? Does it depend on LOCALE settings?
> Where can I find further docs on this way to pass character
> descriptors?
> Thanks,
> ScionForbai
> 
>


From scionforbai at gmail.com  Thu Sep 20 21:19:05 2007
From: scionforbai at gmail.com (Scionforbai)
Date: Thu, 20 Sep 2007 21:19:05 +0200
Subject: [R] Time series graphs
In-Reply-To: <971536df0709201115r56c0406bi78390b1eb8d9463a@mail.gmail.com>
References: <348115.59776.qm@web37106.mail.mud.yahoo.com>
	<971536df0709201115r56c0406bi78390b1eb8d9463a@mail.gmail.com>
Message-ID: <e9ee1f0a0709201219t55f9135dt5d766e7f4ab8d5a7@mail.gmail.com>

In pure R (without other packages) is IMHO simpler to understand (at
least if data are so simple: months 1 till 9 with no missing
values...). All you need is:

dummybob <- ' month A B
 Jan   8 4
 Feb   7 5
 Mar   6 8
 Apr   3 7
 May   5 1
 Jun   6 4
 Jul   2 8
 Aug   1 2
 Sep   4 3
'

bob <- read.table(textConnection(dummybob), head=TRUE,
stringsAsFactors = FALSE)

plot(0,0,"n",xlim=c(1,9),ylim=c(0,9),xlab="Month",ylab="Value",axes=FALSE)
title(main="Bob")
lines(1:9,bob$A,lty="solid",col="black")
lines(1:9,bob$B,lty="dotted",col="green")
axis(1,1:9,bob$month)
axis(2)

text(1:9,bob$A,"A",pos=3)
text(1:9,bob$B,"B",pos=3)
box()

And then repeat with the other dataset.


From dylan.beaudette at gmail.com  Thu Sep 20 21:20:30 2007
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Thu, 20 Sep 2007 12:20:30 -0700
Subject: [R] Superimposing vector polygons over raster grid in a plot
In-Reply-To: <46F2AEAB.1080205@nceas.ucsb.edu>
References: <46F2AEAB.1080205@nceas.ucsb.edu>
Message-ID: <200709201220.30642.dylan.beaudette@gmail.com>

On Thursday 20 September 2007, Rick Reeves wrote:
> Hello:
>
> I would like to superimpose vector polygons (state outlines) from a
> Shape file on top of a satellite image,
> imported into a SpatialGridDataFrame from GEOTIFF via gdal_translate and
> readGDAL.
>
> When I plot polygon and point shape files in R, into
> SpatialPointDataFrame and SpatialPolygonDataFrame,
> the two feature sets line up geographically, so it seems logical that a
> SpatialGridDataFrame should behave
> in the same way.
>
>  From my initial research, the spplot function is the correct function
> for plotting grids/images with axes and
> annotation.
>
> The big question is, how do I incorporate a Spatial(Points or
> Polygons)DataFrame into the spplot display list?
>
> It seems as though many scientists would like to create such plots
> without resorting to GRASS or
> another GIS.

While GRASS and GMT are excellent tools, here are some ideas on how to make 
composite maps in R:

http://casoilresource.lawr.ucdavis.edu/drupal/node/442

cheers,

Dylan



> Thanks for any advice,
> Rick Reeves
>
> Rick Reeves
> Scientific Programmer / Analyst
> National Center for Ecological Analysis and Synthesis
> UC Santa Barbara
> reeves at nceas.ucsb.edu
> www.nceas.ucsb.edu
> 805 892 2533



-- 
Dylan Beaudette
Soils and Biogeochemistry Graduate Group
University of California at Davis
530.754.7341


From waltman at cs.nyu.edu  Thu Sep 20 21:23:45 2007
From: waltman at cs.nyu.edu (Peter Waltman)
Date: Thu, 20 Sep 2007 15:23:45 -0400
Subject: [R] how can I attach a variable stored in
In-Reply-To: <D3AEEDA31E57474B840BEBC25A8A834401957B1F@NYWEXMB23.msad.ms.com>
References: <46F2AE8F.7030303@cs.nyu.edu>
	<D3AEEDA31E57474B840BEBC25A8A834401957B1F@NYWEXMB23.msad.ms.com>
Message-ID: <46F2C8C1.2040906@cs.nyu.edu>

Hi Mark -

Thanks for the reply.  Sorry I didn't really clarify too well what I'm 
trying to do.  The issue is not that I can't see the variable that gets 
loaded. 

The issue is that the variable is a list variable, and I'd like to write 
a function that will take the .RData filename and attach the variable it 
contains so that I can more easily access its contents, i.e.

    foo.bar <- list( "a"= "a", "b"=1 )
    save( file="foo.bar.RData", foo.bar )
    rm( foo.bar )

    my.fn <- function( fname ) {
       load( fname )
       attach( ls( pat="foo" ) ) #  I want to attach( foo.bar ), but
    this doesn't work
    }

    ls()  # prints out "foo.bar"

    attach( ls( ) )   # still doesn't work
    attach( foo.bar )  # works

So, basically, the question is how can I attach the variable that's 
stored in a file if I don't already know it's name?

Thanks again!

Peter

Leeds, Mark (IED) wrote:
> I don't think I understand your question but John Fox has written a very
> nice documentat about scoping and environments on his website.
> It's probably easy to find the site by googling "John Fox" but, if you
> can't find it, let me know.
>  
> As I said, I don't think that I understand your question but, if you
> loaded a list variable using load("whatever.Rdata"), the variable will 
> just be suitting in  your workspace. You don't need to attach anything
> because load just loads the data right into the workspace.
> So typing the variable name should show the data.
>
>
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Peter Waltman
> Sent: Thursday, September 20, 2007 1:32 PM
> To: r-help at r-project.org
> Subject: [R] how can I attach a variable stored in
>
> Hi -
>
> Any help would be greatly appreciated.
>
> I'm loading a list variable that's stored in an .RData file and would
> like attach it.
>
> I've used attach( <file_name> ), but that only lets me see the variable
> that's stored in the file. 
>
> As the variable name is of the form "comp.x.x", I've tried using attach(
> ls( pat="comp" ) ), but get an error as ls() just gives back a string.
>
> I've also played around with eval(), but don't really quite get what
> that function does since it seems to get into the R internals which I
> don't entirely understand and I haven't found any great unified
> documentation on R's handling environment and scoping.
>
> Thanks,
>
> Peter Waltman
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> --------------------------------------------------------
>
> This is not an offer (or solicitation of an offer) to buy/sell the securities/instruments mentioned or an official confirmation.  Morgan Stanley may deal as principal in or own or act as market maker for securities/instruments mentioned or may advise the issuers.  This is not research and is not from MS Research but it may refer to a research analyst/research report.  Unless indicated, these views are the author's and may differ from those of Morgan Stanley research or others in the Firm.  We do not represent this is accurate or complete and we may not update this.  Past performance is not indicative of future returns.  For additional information, research reports and important disclosures, contact me or see https://secure.ms.com/servlet/cls.  You should not use e-mail to request, authorize or effect the purchase or sale of any security or instrument, to send transfer instructions, or to effect any other transactions.  We cannot guarantee that any such requests received via e-mail will be processed in a timely manner.  This communication is solely for the addressee(s) and may contain confidential information.  We do not waive confidentiality by mistransmission.  Contact me if you do not wish to receive these communications.  In the UK, this communication is directed in the UK to those persons who are market counterparties or intermediate customers (as defined in the UK Financial Services Authority's rules).
>
>   


From cberry at tajo.ucsd.edu  Thu Sep 20 21:30:34 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Thu, 20 Sep 2007 12:30:34 -0700
Subject: [R] Conditional Logit and Mixed Logit
In-Reply-To: <12802959.post@talk.nabble.com>
References: <12802959.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0709201227390.20210@tajo.ucsd.edu>

On Thu, 20 Sep 2007, David U. wrote:

>
> Hello,
>
> Could anybody provide me with codes (procedure) how to obtain Conditional
> Logit (McFadden) and Mixed Logit (say, assuming normal distribution)
> estimates in R?


 	RSiteSearch("conditional logit")

as the posting guide tells you!

>
> Thanks,
> David U.
> -- 
> View this message in context: http://www.nabble.com/Conditional-Logit-and-Mixed-Logit-tf4489238.html#a12802959
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From slomascolo at zoo.ufl.edu  Thu Sep 20 21:34:00 2007
From: slomascolo at zoo.ufl.edu (Silvia Lomascolo)
Date: Thu, 20 Sep 2007 12:34:00 -0700 (PDT)
Subject: [R] error in manova
Message-ID: <12804209.post@talk.nabble.com>


I work with Windows, R 2.4.1.  I'm a beginner with R!

After doing a Discriminant Function Analysis, I am trying to run manova to
get a measure of significance of my lda results. I want to predict groups 1
through 4 using 78 variables (bad group/var ratio, I know, but I'm just
exploring the possibilities right now).  I've tried with a test matrix and I
get my results fine, so I think it might have something to do with the
matrix I'm using (hence, the sample of my matrix I show below). My matrix,
called disperser.mx in my code, looks like:

disperser	P5.38	P6.45	P6.55	P6.63	P7.12	P7.42	P8.10	P8.30	P8.88	P9.09	P9.30
3	0.00	1.34	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00
2	0.00	0.00	131.56	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00
2	0.00	5.05	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00
3	0.00	72.65	103.26	1.09	0.00	0.00	0.00	0.00	0.00	0.00	0.00
2	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00
2	0.88	0.48	0.89	0.00	0.00	0.16	0.00	0.00	0.00	0.00	0.00
2	0.00	0.00	0.00	0.00	0.00	0.75	0.00	0.00	0.00	0.00	0.00
4	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00
2	0.00	0.00	0.00	0.00	0.00	5.41	20.62	0.00	8.13	8.87	8.27
4	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00
2	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00
2	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00
2	0.00	133.24	0.00	0.73	0.00	0.00	1.34	2.13	0.00	0.00	0.00
1	0.00	11.08	3.16	0.76	0.00	0.00	0.00	0.00	0.00	0.00	0.00
4	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00
4	0.82	0.00	0.00	0.00	4.79	0.00	0.00	33.69	0.00	0.00	11.44
2	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00
4	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00
2	0.00	1.81	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00
1	0.00	0.00	0.00	0.00	0.00	6.89	0.00	0.00	0.00	0.00	0.00
2	7.26	8.16	1.50	0.00	1.97	1.28	0.00	4.08	0.00	0.00	1.16
4	0.00	0.00	0.00	0.00	0.00	3.13	0.00	0.00	0.00	0.00	0.00
4	0.00	0.00	0.00	0.00	0.00	0.83	0.00	0.00	0.00	0.00	0.00
1	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00
2	0.00	1.48	0.22	0.00	0.00	0.00	1.80	0.00	0.66	0.47	0.47
1	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00	0.00
1	0.00	0.00	0.00	0.00	4.78	0.00	0.00	0.00	0.00	0.00	0.00

...with a lot more variables.  The code I am writing to get a manova is:

##first, the code for the discriminant function, just in case it has
something to do with the error I get later##
disperser.mx$disperser<- as.factor (disperser.mx$disperser)
disperser.df <- lda(disperser~., data=disperser.mx)
predict(disperser.df)
attach(disperser.mx)
table(disperser, predict(disperser.df)$class)  ## so far so good.  I get my
discriminant analysis fine
volatileVar <- disperser.mx[c(2:79)] ## these are all the variables that I
want to use
summary (manova(as.matrix(volatileVar)~disperser.mx$disperser),
test='Wilks')  ## here is where I get an error that says "Error in
summary.manova(manova(as.matrix(volatileVar) ~ disperser.mx$disperser),  : 
        residuals have rank 23 < 78"


I would appreciate any help you can offer! Silvia.


-- 
View this message in context: http://www.nabble.com/error-in-manova-tf4489610.html#a12804209
Sent from the R help mailing list archive at Nabble.com.


From jholtman at gmail.com  Thu Sep 20 21:47:13 2007
From: jholtman at gmail.com (jim holtman)
Date: Thu, 20 Sep 2007 15:47:13 -0400
Subject: [R] how can I attach a variable stored in
In-Reply-To: <46F2C8C1.2040906@cs.nyu.edu>
References: <46F2AE8F.7030303@cs.nyu.edu>
	<D3AEEDA31E57474B840BEBC25A8A834401957B1F@NYWEXMB23.msad.ms.com>
	<46F2C8C1.2040906@cs.nyu.edu>
Message-ID: <644e1f320709201247o3fb2cdc9u5a156f910bc6a328@mail.gmail.com>

try:

attach(get(ls(pat="^foo")))

On 9/20/07, Peter Waltman <waltman at cs.nyu.edu> wrote:
> Hi Mark -
>
> Thanks for the reply.  Sorry I didn't really clarify too well what I'm
> trying to do.  The issue is not that I can't see the variable that gets
> loaded.
>
> The issue is that the variable is a list variable, and I'd like to write
> a function that will take the .RData filename and attach the variable it
> contains so that I can more easily access its contents, i.e.
>
>    foo.bar <- list( "a"= "a", "b"=1 )
>    save( file="foo.bar.RData", foo.bar )
>    rm( foo.bar )
>
>    my.fn <- function( fname ) {
>       load( fname )
>       attach( ls( pat="foo" ) ) #  I want to attach( foo.bar ), but
>    this doesn't work
>    }
>
>    ls()  # prints out "foo.bar"
>
>    attach( ls( ) )   # still doesn't work
>    attach( foo.bar )  # works
>
> So, basically, the question is how can I attach the variable that's
> stored in a file if I don't already know it's name?
>
> Thanks again!
>
> Peter
>
> Leeds, Mark (IED) wrote:
> > I don't think I understand your question but John Fox has written a very
> > nice documentat about scoping and environments on his website.
> > It's probably easy to find the site by googling "John Fox" but, if you
> > can't find it, let me know.
> >
> > As I said, I don't think that I understand your question but, if you
> > loaded a list variable using load("whatever.Rdata"), the variable will
> > just be suitting in  your workspace. You don't need to attach anything
> > because load just loads the data right into the workspace.
> > So typing the variable name should show the data.
> >
> >
> >
> >
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> > On Behalf Of Peter Waltman
> > Sent: Thursday, September 20, 2007 1:32 PM
> > To: r-help at r-project.org
> > Subject: [R] how can I attach a variable stored in
> >
> > Hi -
> >
> > Any help would be greatly appreciated.
> >
> > I'm loading a list variable that's stored in an .RData file and would
> > like attach it.
> >
> > I've used attach( <file_name> ), but that only lets me see the variable
> > that's stored in the file.
> >
> > As the variable name is of the form "comp.x.x", I've tried using attach(
> > ls( pat="comp" ) ), but get an error as ls() just gives back a string.
> >
> > I've also played around with eval(), but don't really quite get what
> > that function does since it seems to get into the R internals which I
> > don't entirely understand and I haven't found any great unified
> > documentation on R's handling environment and scoping.
> >
> > Thanks,
> >
> > Peter Waltman
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > --------------------------------------------------------
> >
> > This is not an offer (or solicitation of an offer) to buy/sell the securities/instruments mentioned or an official confirmation.  Morgan Stanley may deal as principal in or own or act as market maker for securities/instruments mentioned or may advise the issuers.  This is not research and is not from MS Research but it may refer to a research analyst/research report.  Unless indicated, these views are the author's and may differ from those of Morgan Stanley research or others in the Firm.  We do not represent this is accurate or complete and we may not update this.  Past performance is not indicative of future returns.  For additional information, research reports and important disclosures, contact me or see https://secure.ms.com/servlet/cls.  You should not use e-mail to request, authorize or effect the purchase or sale of any security or instrument, to send transfer instructions, or to effect any other transactions.  We cannot guarantee that any such requests received vi!
>  a e-mail will be processed in a timely manner.  This communication is solely for the addressee(s) and may contain confidential information.  We do not waive confidentiality by mistransmission.  Contact me if you do not wish to receive these communications.  In the UK, this communication is directed in the UK to those persons who are market counterparties or intermediate customers (as defined in the UK Financial Services Authority's rules).
> >
> >
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From jholtman at gmail.com  Thu Sep 20 22:07:03 2007
From: jholtman at gmail.com (jim holtman)
Date: Thu, 20 Sep 2007 16:07:03 -0400
Subject: [R] convert data from
In-Reply-To: <984153.17774.qm@web58711.mail.re1.yahoo.com>
References: <984153.17774.qm@web58711.mail.re1.yahoo.com>
Message-ID: <644e1f320709201307n582b56a2g4e27d0b46a54fc39@mail.gmail.com>

This should get you close to what you want:

> x <- read.table(textConnection("   X1    X2
+ A    1    2
+ B    3    4
+ C    5    6"), header=TRUE)
> # add rownames to the dataframe
> x$name <- row.names(x)
> require(reshape)  # use reshape package
[1] TRUE
> melt(x, id='name')
  name variable value
1    A       X1     1
2    B       X1     3
3    C       X1     5
4    A       X2     2
5    B       X2     4
6    C       X2     6


On 9/20/07, Pan Zheng <zhpan99 at yahoo.com> wrote:
> Hi,
>
> I am trying to convert a data frame from:
>
>    X1    X2
> A    1    2
> B    3    4
> C    5    6
>
> to:
> A01 1
> A02 2
> B01    3
> B02    4
> C01    5
> C02    6.
>
> How can I do it in R?
>
> I appreciate your help.
>
> Zheng
>
>
> ---------------------------------
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From r.turner at auckland.ac.nz  Thu Sep 20 22:13:12 2007
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 21 Sep 2007 08:13:12 +1200
Subject: [R] Identify and plotting symbols. [SEC=UNCLASSIFIED]
In-Reply-To: <61C2DEA055980B418D063F8646FCAEFC020B5A65@ACT001CL03EX03.agdaff.gov.au>
References: <61C2DEA055980B418D063F8646FCAEFC020B5A65@ACT001CL03EX03.agdaff.gov.au>
Message-ID: <08BB612E-A5A2-46E1-B389-C7740CFC12F8@auckland.ac.nz>


On 20/09/2007, at 4:35 PM, Crombie, Joe wrote:

> Or maybe:
>
>> while(length(ind <- identify(x,y,n = 1, plot = F)))
>>   points(x[ind], y[ind], pch = 19)
>
> (highlights each point as you select it, until you click _stop_)

Bewdy!!!  That's eggs-actly what I was looking for.  Thanks very much.

			cheers,

				Rolf

######################################################################
Attention:\ This e-mail message is privileged and confidenti...{{dropped}}


From jholtman at gmail.com  Thu Sep 20 22:31:45 2007
From: jholtman at gmail.com (jim holtman)
Date: Thu, 20 Sep 2007 16:31:45 -0400
Subject: [R] help with making a function of scatter plot with multiple
	variables
In-Reply-To: <656269.86992.qm@web23001.mail.ird.yahoo.com>
References: <656269.86992.qm@web23001.mail.ird.yahoo.com>
Message-ID: <644e1f320709201331k1fccd5waa096ca30eb4a341@mail.gmail.com>

The simple way is to enclose it in a 'function' and pass parameters.
Assuming that you have the same number of parameters, then the
following will do:

my.func <- function(x,y,d1,v1,s1,t1,s2,t2,s3,t3,s4,t4,s5,t5)
{
    op <- par(bg = "grey97")
    par(mfrow=c(1,2))
    plot(d1,v1, pch="v", col="orange",cex=0.6, lwd=2,
       xlab="day", ylab="resp",cex.main =1,font.main= 1,main=" Surv
data",ylim=y,xlim=x,
       col.main="navyblue",col.lab="navyblue",cex.lab=0.7)

   points(s1,t1, pch="A", col="green4", cex=1)
   points(s2,t2, pch="B",col="navyblue", cex=1)
   points(s3,t3, pch="C",col="red", cex=1)
   points(s4,t4, pch="D",col="darkviolet", cex=1)
   points(s5,t5, pch="E",col="blue", cex=1)
     legend("topright",lbels,col=c("orange","green4","navyblue","red","darkviolet","blue"),
    text.col=c("orange","green4","navyblue","red","darkviolet","steelblue"),
    pch=c("v","A","B","C","D","E"),bg='gray100',cex=0.7,box.lty=1,box.lwd=1)
   abline(h = -1:9, v = 0:8, col = "lightgray", lty=3)
    par(op)
}

# call it with

my.func(x,y,d1,v1,s1,t1,s2,t2,s3,t3,s4,t4,s5,t5)

You might also include the data in a list to make it easier



On 9/20/07, Tom Cohen <tom.cohen78 at yahoo.se> wrote:
> Dear list,
>
>  I have done a scatter plot of  multiple variables in the same graph, with different col and pch. I managed to do it with the following code but not know how to make a function of these so that next time if I want to do similar graph but with new variables, I dont have to copy the code and then change the old variables with the new ones but just call a function with the new variables. I dont have any experience in making a function and would be very grateful if you can help me. A function will shorten my prog dramatically, since I repeat tthis type of graph alots in my analysis.
>
>  Thanks in advance,
>  Tom
>
>  op <- par(bg = "grey97")
> par(mfrow=c(1,2))
> plot(d1,v1, pch="v", col="orange",cex=0.6, lwd=2,
>    xlab="day", ylab="resp",cex.main =1,font.main= 1,main=" Surv data",ylim=y,xlim=x,
>    col.main="navyblue",col.lab="navyblue",cex.lab=0.7)
>
>    points(s1,t1, pch="A", col="green4", cex=1)
>    points(s2,t2, pch="B",col="navyblue", cex=1)
>    points(s3,t3, pch="C",col="red", cex=1)
>    points(s4,t4, pch="D",col="darkviolet", cex=1)
>    points(s5,t5, pch="E",col="blue", cex=1)
>      legend("topright",lbels,col=c("orange","green4","navyblue","red","darkviolet","blue"),
>     text.col=c("orange","green4","navyblue","red","darkviolet","steelblue"),
>     pch=c("v","A","B","C","D","E"),bg='gray100',cex=0.7,box.lty=1,box.lwd=1)
>    abline(h = -1:9, v = 0:8, col = "lightgray", lty=3)
> par(op)
>
>
>
>
> ---------------------------------
>
> J?mf?r pris p? flygbiljetter och hotellrum: http://shopping.yahoo.se/c-169901-resor-biljetter.html
>        [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From tplate at acm.org  Thu Sep 20 22:37:07 2007
From: tplate at acm.org (Tony Plate)
Date: Thu, 20 Sep 2007 14:37:07 -0600
Subject: [R] how can I attach a variable stored in
In-Reply-To: <46F2C8C1.2040906@cs.nyu.edu>
References: <46F2AE8F.7030303@cs.nyu.edu>	<D3AEEDA31E57474B840BEBC25A8A834401957B1F@NYWEXMB23.msad.ms.com>
	<46F2C8C1.2040906@cs.nyu.edu>
Message-ID: <46F2D9F3.3020304@acm.org>

Here's a function that does what I think you want to do:

 > attach.firstvar <- function(file) {
+     tmpenv <- new.env()
+     vars <- load(file, envir=tmpenv)
+     x <- get(vars[1], envir=tmpenv, inherits=FALSE)
+     if (is.list(x))
+         attach(x, name=vars[1])
+     return(vars)
+ }
 > x <- list(xa=1, xb=2, xc=3)
 > save(list="x", file="tmp1.rda")
 > remove(list="x")
 > attach.firstvar("tmp1.rda")
[1] "x"
 > ls(pos=2)
[1] "xa" "xb" "xc"
 > find("xa")
[1] "x"
 > search()
  [1] ".GlobalEnv"        "x"                 "package:stats"
  [4] "package:graphics"  "package:grDevices" "package:utils"
  [7] "package:datasets"  "package:methods"   "Autoloads"
[10] "package:base"
 > xa
[1] 1
 > xb
[1] 2
 >

Peter Waltman wrote:
> Hi Mark -
> 
> Thanks for the reply.  Sorry I didn't really clarify too well what I'm 
> trying to do.  The issue is not that I can't see the variable that gets 
> loaded. 
> 
> The issue is that the variable is a list variable, and I'd like to write 
> a function that will take the .RData filename and attach the variable it 
> contains so that I can more easily access its contents, i.e.
> 
>     foo.bar <- list( "a"= "a", "b"=1 )
>     save( file="foo.bar.RData", foo.bar )
>     rm( foo.bar )
> 
>     my.fn <- function( fname ) {
>        load( fname )
>        attach( ls( pat="foo" ) ) #  I want to attach( foo.bar ), but
>     this doesn't work
>     }
> 
>     ls()  # prints out "foo.bar"
> 
>     attach( ls( ) )   # still doesn't work
>     attach( foo.bar )  # works
> 
> So, basically, the question is how can I attach the variable that's 
> stored in a file if I don't already know it's name?
> 
> Thanks again!
> 
> Peter
> 
> Leeds, Mark (IED) wrote:
>> I don't think I understand your question but John Fox has written a very
>> nice documentat about scoping and environments on his website.
>> It's probably easy to find the site by googling "John Fox" but, if you
>> can't find it, let me know.
>>  
>> As I said, I don't think that I understand your question but, if you
>> loaded a list variable using load("whatever.Rdata"), the variable will 
>> just be suitting in  your workspace. You don't need to attach anything
>> because load just loads the data right into the workspace.
>> So typing the variable name should show the data.
>>
>>
>>
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Peter Waltman
>> Sent: Thursday, September 20, 2007 1:32 PM
>> To: r-help at r-project.org
>> Subject: [R] how can I attach a variable stored in
>>
>> Hi -
>>
>> Any help would be greatly appreciated.
>>
>> I'm loading a list variable that's stored in an .RData file and would
>> like attach it.
>>
>> I've used attach( <file_name> ), but that only lets me see the variable
>> that's stored in the file. 
>>
>> As the variable name is of the form "comp.x.x", I've tried using attach(
>> ls( pat="comp" ) ), but get an error as ls() just gives back a string.
>>
>> I've also played around with eval(), but don't really quite get what
>> that function does since it seems to get into the R internals which I
>> don't entirely understand and I haven't found any great unified
>> documentation on R's handling environment and scoping.
>>
>> Thanks,
>>
>> Peter Waltman
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> --------------------------------------------------------
>>
>> This is not an offer (or solicitation of an offer) to buy/sell the securities/instruments mentioned or an official confirmation.  Morgan Stanley may deal as principal in or own or act as market maker for securities/instruments mentioned or may advise the issuers.  This is not research and is not from MS Research but it may refer to a research analyst/research report.  Unless indicated, these views are the author's and may differ from those of Morgan Stanley research or others in the Firm.  We do not represent this is accurate or complete and we may not update this.  Past performance is not indicative of future returns.  For additional information, research reports and important disclosures, contact me or see https://secure.ms.com/servlet/cls.  You should not use e-mail to request, authorize or effect the purchase or sale of any security or instrument, to send transfer instructions, or to effect any other transactions.  We cannot guarantee that any such requests received v
i!
>  a e-mail will be processed in a timely manner.  This communication is solely for the addressee(s) and may contain confidential information.  We do not waive confidentiality by mistransmission.  Contact me if you do not wish to receive these communications.  In the UK, this communication is directed in the UK to those persons who are market counterparties or intermediate customers (as defined in the UK Financial Services Authority's rules).
>>   
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From David.Duffy at qimr.edu.au  Thu Sep 20 23:43:07 2007
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 21 Sep 2007 07:43:07 +1000 (EST)
Subject: [R] Robust or Sandwich estimates in lmer2
In-Reply-To: <mailman.25.1190282404.12356.r-help@r-project.org>
References: <mailman.25.1190282404.12356.r-help@r-project.org>
Message-ID: <Pine.LNX.4.64.0709210733440.22869@orpheus.qimr.edu.au>

Abdus Sattar <upsattar at yahoo.com> asked:

>
> I am trying to find the robust (or sandwich) estimates of the standard
> error of fixed effects parameter estimates using the package "lmer2".
>
Others have already pointed out that this is not implemented in lmer2.

You could try a delete-n jackknife, which you would have to implement
yourself. An ordinary delete-1 jackknife does not work for
clustered/correlated data.  This would also give you bias-corrected
point estimates.  I should add that, in the limited simulations I have
done (for Gaussian mixed model analysis of pedigree data), the jackknife
standard errors seemed a bit conservative (too big).

David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From dylan.beaudette at gmail.com  Fri Sep 21 00:31:09 2007
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Thu, 20 Sep 2007 15:31:09 -0700
Subject: [R] Superimposing vector polygons over raster grid in a plot
In-Reply-To: <46F2D627.8090109@nceas.ucsb.edu>
References: <46F2AEAB.1080205@nceas.ucsb.edu>
	<200709201220.30642.dylan.beaudette@gmail.com>
	<46F2D627.8090109@nceas.ucsb.edu>
Message-ID: <200709201531.09370.dylan.beaudette@gmail.com>

On Thursday 20 September 2007, Rick Reeves wrote:
> Thanks for this, Dylan. Great example. One question: 'elev.pred' and
> 'elev.var' are columns in the result 'p' from predict?
> thanks, RR

Hi,

elev.pred and elev.var are the 'zcol' attribute, or rather the value at each 
cell within the spatial dataframe object 'p' in that example. here is the 
construct for spplot() ... note that i left off the 'zcol=' bit on the first 
call to spplot... i will fix that.

spplot(p, zcol='elev.var', ...


cheers,

Dylan

> Dylan Beaudette wrote:
> > On Thursday 20 September 2007, Rick Reeves wrote:
> >> Hello:
> >>
> >> I would like to superimpose vector polygons (state outlines) from a
> >> Shape file on top of a satellite image,
> >> imported into a SpatialGridDataFrame from GEOTIFF via gdal_translate and
> >> readGDAL.
> >>
> >> When I plot polygon and point shape files in R, into
> >> SpatialPointDataFrame and SpatialPolygonDataFrame,
> >> the two feature sets line up geographically, so it seems logical that a
> >> SpatialGridDataFrame should behave
> >> in the same way.
> >>
> >>  From my initial research, the spplot function is the correct function
> >> for plotting grids/images with axes and
> >> annotation.
> >>
> >> The big question is, how do I incorporate a Spatial(Points or
> >> Polygons)DataFrame into the spplot display list?
> >>
> >> It seems as though many scientists would like to create such plots
> >> without resorting to GRASS or
> >> another GIS.
> >
> > While GRASS and GMT are excellent tools, here are some ideas on how to
> > make composite maps in R:
> >
> > http://casoilresource.lawr.ucdavis.edu/drupal/node/442
> >
> > cheers,
> >
> > Dylan
> >
> >> Thanks for any advice,
> >> Rick Reeves
> >>
> >> Rick Reeves
> >> Scientific Programmer / Analyst
> >> National Center for Ecological Analysis and Synthesis
> >> UC Santa Barbara
> >> reeves at nceas.ucsb.edu
> >> www.nceas.ucsb.edu
> >> 805 892 2533



-- 
Dylan Beaudette
Soils and Biogeochemistry Graduate Group
University of California at Davis
530.754.7341


From cathelf at hotmail.com  Fri Sep 21 00:34:56 2007
From: cathelf at hotmail.com (fang liu)
Date: Thu, 20 Sep 2007 22:34:56 +0000
Subject: [R] Time series graphs,  question about  using zoo
Message-ID: <BAY109-F2334733917EEDA629DC54ABEBA0@phx.gbl>

Hi,
Can you tell me what is the meaning for "tail, 1"  in "aggregate"?
I also want to get some similar graph, but the data is not time series data.
Suppose here is my data one, I want a graph with x-axis is just the 
index(1:9).
The graph plot all the variable A, B,C,D. So there should be 4 lines for 
each graph. For the A line, at each time point, the letter A should be on 
the line. And the same goes for the B line.
                    A           B            C        D
>                  8           4             9         8
>                  7           5             4         7
>                  6           8             4         4
>                  3           7              6         2
>                  5           1             8         5
>                  6           4              7        1
>                  2           8             3         4
>                  1           2              4         8
>                  4           3              1        9

So I add a name for each row
rownames(one) <- c(1:9)
z <- zooreg(as.matrix(one), start = 1, freq = 1)
z <- aggregate(z, as.Date, tail, 1)
plot(z, plot.type = "single",  type = "o",
	pch = c("A", "B", "C", "D"), lty = 1:2)

I get the plot, which I think it should be right. but the problem is that 
the x-axis still have month (Jan, ) on it and I didnot get "A,B,C,D" on my 
graph, is there any thing wrong?



>From: "Gabor Grothendieck" <ggrothendieck at gmail.com>
>To: "Bill Pepe" <sonicbill12 at yahoo.com>
>CC: r-help at r-project.org
>Subject: Re: [R] Time series graphs
>Date: Thu, 20 Sep 2007 14:15:54 -0400
>
>Using plot.zoo in the zoo package try this:
>
>Lines <- "Bob.A         Bob.B            Tom.A        Tom.B
>  Jan              8        4             9         8
>  Feb             7         5             4         7
>  Mar             6         8             4         4
>  Apr             3         7              6         2
>  May            5         1             8         5
>  Jun             6         4              7        1
>  July             2         8             3         4
>  Aug             1        2              4         8
>  Sep            4          3              1        9
>"
>DF <- read.table(textConnection(Lines))
>
>library(zoo)
>z <- zooreg(as.matrix(DF), start = as.yearmon(as.Date("2007-01-01")), freq 
>= 12)
>z <- aggregate(z, as.Date, tail, 1)
>plot(z, plot.type = "single",  type = "o",
>	pch = c("A", "A", "B", "B"), lty = 1:2)
>legend("bottomleft", c("Bob", "Tom"), lty = 1:2)
>
>
>
>On 9/20/07, Bill Pepe <sonicbill12 at yahoo.com> wrote:
> > I'm fairly new to S-Plus and I need to get this done quickly. Suppose I 
>have the following fake data below:
> >
> >  There are two companies, call them Bob and Tom. Each have two 
>variables, call them A and B, that have observations.
> >
> >                         Bob                 Tom
> >
> >                    A         B            A        B
> >  Jan              8        4             9         8
> >  Feb             7         5             4         7
> >  Mar             6         8             4         4
> >  Apr             3         7              6         2
> >  May            5         1             8         5
> >  Jun             6         4              7        1
> >  July             2         8             3         4
> >  Aug             1        2              4         8
> >  Sep            4          3              1        9
> >
> >  Here is what I want to do: I want to make two different graphs, one for 
>Bob and one for Tom. For each graph, plot both variables A and B. Connect 
>the A values with a line, and connect the B values with a different type of 
>line. So there should be two lines for each graph. For the A line, at each 
>time point, the letter A should be on the line. And the same goes for the B 
>line. Either R or S-Plus since they are essentially the same.
> >
> >  I'm sure this is easy, but any help would be greatly appreciated.
> >
> >  Thanks,
> >
> >  Bill
> >
> >
> > ---------------------------------
> > Pinpoint customers who are looking for what you sell.
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
>http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide 
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

_________________________________________________________________
[[replacing trailing spam]]


From jfox at mcmaster.ca  Fri Sep 21 00:46:41 2007
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 20 Sep 2007 18:46:41 -0400
Subject: [R] SEM - singularity error
In-Reply-To: <20070920150551.zgct9hxn88cwg80g@webmail.duke.edu>
Message-ID: <20070920224641.ZSGY9197.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear Nicki,

> -----Original Message-----
> From: nicolette.cagle at duke.edu [mailto:nicolette.cagle at duke.edu] 
> Sent: Thursday, September 20, 2007 3:06 PM
> To: John Fox
> Cc: Chuck Cleland; r-help at stat.math.ethz.ch
> Subject: Re: [R] SEM - singularity error
> 
> Dear John,
> 
> Thank you so much for your assistance, it is greatly 
> appreciated. You are correct in your interpretation of the 
> variables (Moist and Hab are latent, the other, lower case 
> variables are observed). I've attempted to run the model 
> again adding Moist <-> Hab (please see code below) and still 
> receive the same error message:
> 
> "Error in solve.default(C) : system is computationally 
> singular: reciprocal condition number = 6.59035e-17."
> 
> Is it possible that something is wrong with the 
> variance-covariance matrix (please see pasted below r code)? 
> Are extremely small values (e.g., 4e-4) problematic? Do you 
> have any additional suggestions as to how I might go about 
> trouble shooting this problem?

You could set the argument debug=TRUE in the call to sem(), which will give
you more detail about what's going on. But I suspect that the problem is the
very large differences in size among the variances of your observed
variances, differences of many orders of magnitude. You could try the
following: (1) set the argument par.size="start.values"; and, if that
doesn't work, (2) alternatively see what happens when you try to estimate
the model from a correlation rather than a covariance matrix.

> 
> I am also attaching the jpeg model diagram, in case it could 
> be of use to you.

The diagram is identical to the one that I inferred from your model
specification. I still think that you probably want to allow the two latent
exogenous variables to be correlated.

If neither of these approaches works, then please send me (privately) the
input covariance matrix and model specification as files so that I can take
a closer look.

Regards,
 John

> 
> Thank you so much for your time.
> Best wishes,
> Nicki
> 
> R CODE USED:
> # 20 Sep 2007 SEM of Thamnophis abundance
> 
> # LOADING R PACKAGES
> library(sem)
> 
> # READING IN THE CSV FILES
> thsi.2006<-read.csv("thsi_ab_env_space_sem.csv")
> thsi<-thsi.2006
> 
> # MAKING "RAM" FILE 3
> model3.nlc <-specify.model()
> Moist->slope, NA, 1
> Moist->sand, lamda21, NA
> Moist->clay, lamda31, NA
> Hab->isol, NA, 1
> Hab->edgedist_a, lamda52, NA
> Hab->ag10, lamda62, NA
> Hab->urb10, lamda72, NA
> Hab->rd10, lamda82, NA
> Hab->y, lamda92, NA
> Moist->this, gamma11, NA
> Hab->this, gamma12, NA
> slope<->slope, theta11, NA
> sand<->sand, theta22, NA
> clay<->clay, theta33, NA
> isol<->isol, theta44, NA
> edgedist_a<->edgedist_a, theta55, NA
> ag10<->ag10, theta66, NA
> urb10<->urb10, theta77, NA
> rd10<->rd10, theta88, NA
> y<->y, the99, NA
> Moist<->Moist, phi11, NA
> Hab<->Hab, phi22, NA
> Moist<->Hab, phi21, NA
> this<->this, theps11, NA
> 
> model3.nlc
> end
> 
> # MAKING S (COVARIANCE MATRIX)
> thsi.var <- var(thsi)
> 
> # MAKING UNSCALED SEM MODEL
> sem3<-sem(ram=model3.nlc, S=thsi.var, N=22)
> 
> VARIANCE-COVARIANCE MATRIX (AKA: thsi.var):
>    this
> this          8.88528139
> edgedist_a   44.91469329
> isol       2678.38321991
> ag10         -0.38967619
> urb10         0.11704827
> rd10          0.02132100
> slope        -2.25074394
> clay        -36.19339827
> sand         19.66753247
> y            -0.95970602
>               edgedist_a
> this          44.9146933
> edgedist_a 17491.7873712
> isol       96122.5594957
> ag10          -9.1045614
> urb10          1.9439758
> rd10           0.5333281
> slope         24.4351358
> clay       -1360.1102116
> sand         619.1507519
> y            -15.4852253
>                     isol
> this          2678.38322
> edgedist_a   96122.55950
> isol       4167108.48214
> ag10          -347.26757
> urb10           91.79339
> rd10            25.71996
> slope         -392.44092
> clay        -42236.76039
> sand         19461.19308
> y             -868.20597
>                     ag10
> this         -0.38967619
> edgedist_a   -9.10456137
> isol       -347.26756672
> ag10          0.05167298
> urb10        -0.01314388
> rd10         -0.00297957
> slope         0.06923224
> clay          3.17604271
> sand         -1.61043719
> y             0.11896881
>                   urb10
> this        0.117048268
> edgedist_a  1.943975810
> isol       91.793388529
> ag10       -0.013143880
> urb10       0.003733677
> rd10        0.000784747
> slope      -0.039094302
> clay       -0.907067141
> sand        0.491619654
> y          -0.034343332
>                     rd10
> this        0.0213209957
> edgedist_a  0.5333280831
> isol       25.7199633947
> ag10       -0.0029795700
> urb10       0.0007847471
> rd10        0.0001987203
> slope      -0.0041496227
> clay       -0.2726142316
> sand        0.1286087229
> y          -0.0078502982
>                    slope
> this       -2.250744e+00
> edgedist_a  2.443514e+01
> isol       -3.924409e+02
> ag10        6.923224e-02
> urb10      -3.909430e-02
> rd10       -4.149623e-03
> slope       2.520968e+00
> clay        3.343637e+00
> sand       -2.202094e+00
> y           3.306712e-01
>                     clay
> this       -3.619340e+01
> edgedist_a -1.360110e+03
> isol       -4.223676e+04
> ag10        3.176043e+00
> urb10      -9.070671e-01
> rd10       -2.726142e-01
> slope       3.343637e+00
> clay        7.962072e+02
> sand       -3.410372e+02
> y           1.096320e+01
>                     sand
> this          19.6675325
> edgedist_a   619.1507519
> isol       19461.1930766
> ag10          -1.6104372
> urb10          0.4916197
> rd10           0.1286087
> slope         -2.2020936
> clay        -341.0372225
> sand         165.1578113
> y             -5.4148540
>                        y
> this       -9.597060e-01
> edgedist_a -1.548523e+01
> isol       -8.682060e+02
> ag10        1.189688e-01
> urb10      -3.434333e-02
> rd10       -7.850298e-03
> slope       3.306712e-01
> clay        1.096320e+01
> sand       -5.414854e+00
> y           3.694397e-01
> 
> 
> Quoting John Fox <jfox at mcmaster.ca>:
> 
> > Dear Nicolette and Chuck,
> >
> > I apologize for not seeing Nicolette's original posting.
> >
> > The model does appear to be correctly specified (though I 
> didn't see 
> > the path diagram) and over-identified. I assume that all of the 
> > variables with lower-case names are observed variables and 
> that "Moist"
> > and "Hab" are latent variables. (Simply comparing the 
> number of free 
> > parameters to the number of unique covariances among observed 
> > variables provides a necessary but not sufficient condition 
> for identification.
> > This model is identified because there more than two unique 
> indicators 
> > for each latent variable and because the structural 
> submodel relating 
> > "this" to "Moist" and "Hab" is identified.)
> >
> > I suspect that the problem here is the restriction that "Moist" and 
> > "Hab" are uncorrelated, which follows from the lack of a 
> double-headed 
> > arrow connecting these variables. You might try adding 
> Moist <-> Hab 
> > to the model.
> >
> > I hope this helps,
> > John
> >
> >
> > On Thu, 20 Sep 2007 12:40:06 -0400
> > Chuck Cleland <ccleland at optonline.net> wrote:
> >> nicolette.cagle at duke.edu wrote:
> >> > Good morning,
> >> >
> >> > I am trying to develop a structural equation model of snake
> >> abundance using
> >> > habitat variables. In attempting to estimate the model using the
> >> "sem" package
> >> > in R version 2.4.0, I receive the following error message:
> >> >
> >> > "Error in solve.default(C) : system is computationally singular:
> >> reciprocal
> >> > condition number = 1.75349e-16"
> >> >
> >> > MAIN PROBLEM: I am hoping to discover why I am receiving the
> >> aforementioned
> >> > error message and how to successfully estimate the model.
> >> >
> >> > OTHER INFORMATION:
> >> > 1. I believe the model is over-identified rather than
> >> under-identified (based on
> >> > my understanding of the t-rule). I have observed data for 10
> >> variables (9
> >> > exogenous, 1 endogenous).
> >> >
> >> > 2. I am not certain that I have used the proper tool to estimate
> >> the covariance
> >> > matrix. In this case, I used the "VAR" function.
> >> >
> >> > 3. I am most concerned that I have improperly coded the RAM file.
> >> For example,
> >> > in a case where I have three exogenous indicators of one 
> exogenous
> >> latent
> >> > variable, I specify a start value of 1 for one of the exogenous
> >> indicators. I
> >> > am not sure if this is proper or necessary.
> >> >
> >> > 4. I am new to SEM; this is the first model I have ever tried to
> >> estimate.
> >> >
> >> > R CODE: Below is the r-code I have used to estimate the 
> structural
> >> equation
> >> > model --
> >> >
> >> > # LOADING R PACKAGES
> >> > library(sem)
> >> >
> >> > # READING IN THE CSV FILES
> >> > thsi.2006<-read.csv("thsi_ab_env_space_sem.csv")
> >> > thsi<-thsi.2006
> >> >
> >> > # MAKING "RAM" FILE 2
> >> > model2.nlc <-specify.model()
> >> > Moist->slope, NA, 1
> >> > Moist->sand, lamda21, NA
> >> > Moist->clay, lamda31, NA
> >> > Hab->isol, NA, 1
> >> > Hab->edgedist_a, lamda52, NA
> >> > Hab->ag10, lamda62, NA
> >> > Hab->urb10, lamda72, NA
> >> > Hab->rd10, lamda82, NA
> >> > Hab->y, lamda92, NA
> >> > Moist->this, gamma11, NA
> >> > Hab->this, gamma12, NA
> >> > slope<->slope, theta11, NA
> >> > sand<->sand, theta22, NA
> >> > clay<->clay, theta33, NA
> >> > isol<->isol, theta44, NA
> >> > edgedist_a<->edgedist_a, theta55, NA ag10<->ag10, theta66, NA 
> >> > urb10<->urb10, theta77, NA rd10<->rd10, theta88, NA 
> y<->y, the99, 
> >> > NA Moist<->Moist, phi11, NA Hab<->Hab, phi22, NA this<->this, 
> >> > theps11, NA
> >> >
> >> > model2.nlc
> >> > end
> >> >
> >> > # MAKING S (COVARIANCE MATRIX)
> >> > thsi.var <- var(thsi)
> >> >
> >> > # MAKING UNSCALED SEM MODEL
> >> > sem2<-sem(ram=model2.nlc, S=thsi.var, N=22)
> >> >
> >> > I am also attaching a jpeg diagram of the model I am trying to
> >> estimate. Please
> >> > let me know if there is any additional information that I should
> >> add to this
> >> > posting.
> >> >
> >> > Thank you so much for your time.
> >> > Nicolette Cagle
> >>
> >>   Your specification of the model seems OK and it is 
> over-identified
> >> (21
> >> free parameters and 34 df).  I suspect the problem is that one or 
> >> more of your 10 variables is a linear function of the remaining 
> >> variables.
> >> If that is the case, then the following should give the same 
> >> singularity
> >> error:
> >>
> >> factanal(thsi, factors=1)
> >>
> >>   You may be able to drop one or more of the 10 variables from 
> >> consideration and successfully estimate a conceptually 
> similar model.
> >>
> >> hope this helps,
> >>
> >> Chuck Cleland
> >>
> >> >
> >>
> > 
> ----------------------------------------------------------------------
> > --
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, 
> reproducible code.
> >>
> >> --
> >> Chuck Cleland, Ph.D.
> >> NDRI, Inc.
> >> 71 West 23rd Street, 8th floor
> >> New York, NY 10010
> >> tel: (212) 845-4495 (Tu, Th)
> >> tel: (732) 512-0171 (M, W, F)
> >> fax: (917) 438-0894
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > --------------------------------
> > John Fox, Professor
> > Department of Sociology
> > McMaster University
> > Hamilton, Ontario, Canada
> > http://socserv.mcmaster.ca/jfox/
> >
> 
> 
> 
> --
> Ecology Ph.D. Candidate
> Duke University
> Durham, NC 27708
> www.duke.edu/~nlc4
>


From ggrothendieck at gmail.com  Fri Sep 21 01:56:17 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 20 Sep 2007 19:56:17 -0400
Subject: [R] Time series graphs, question about using zoo
In-Reply-To: <BAY109-F2334733917EEDA629DC54ABEBA0@phx.gbl>
References: <BAY109-F2334733917EEDA629DC54ABEBA0@phx.gbl>
Message-ID: <971536df0709201656j9b8be0dk1057df92bb511b4c@mail.gmail.com>

Try this:

Lines <- "A           B            C        D
   8           4             9         8
   7           5             4         7
   6           8             4         4
   3           7              6         2
   5           1             8         5
   6           4              7        1
   2           8             3         4
   1           2              4         8
   4           3              1        9
"
one <- read.table(textConnection(Lines), header = TRUE)
library(zoo)
z <- zoo(as.matrix(one))
plot(z, plot.type = "single", pch = colnames(z), type = "o", col =
1:4, lty = 1:4)
legend("bottomleft", colnames(z), col = 1:4, lty = 1:4)

# or use matplot
matplot(as.matrix(one), pch = colnames(z), type = "o")
legend("bottomleft", colnames(z), col = 1:4, lty = 1:4)


On 9/20/07, fang liu <cathelf at hotmail.com> wrote:
> Hi,
> Can you tell me what is the meaning for "tail, 1"  in "aggregate"?
> I also want to get some similar graph, but the data is not time series data.
> Suppose here is my data one, I want a graph with x-axis is just the
> index(1:9).
> The graph plot all the variable A, B,C,D. So there should be 4 lines for
> each graph. For the A line, at each time point, the letter A should be on
> the line. And the same goes for the B line.
>                    A           B            C        D
> >                  8           4             9         8
> >                  7           5             4         7
> >                  6           8             4         4
> >                  3           7              6         2
> >                  5           1             8         5
> >                  6           4              7        1
> >                  2           8             3         4
> >                  1           2              4         8
> >                  4           3              1        9
>
> So I add a name for each row
> rownames(one) <- c(1:9)
> z <- zooreg(as.matrix(one), start = 1, freq = 1)
> z <- aggregate(z, as.Date, tail, 1)
> plot(z, plot.type = "single",  type = "o",
>        pch = c("A", "B", "C", "D"), lty = 1:2)
>
> I get the plot, which I think it should be right. but the problem is that
> the x-axis still have month (Jan, ) on it and I didnot get "A,B,C,D" on my
> graph, is there any thing wrong?
>
>
>
> >From: "Gabor Grothendieck" <ggrothendieck at gmail.com>
> >To: "Bill Pepe" <sonicbill12 at yahoo.com>
> >CC: r-help at r-project.org
> >Subject: Re: [R] Time series graphs
> >Date: Thu, 20 Sep 2007 14:15:54 -0400
> >
> >Using plot.zoo in the zoo package try this:
> >
> >Lines <- "Bob.A         Bob.B            Tom.A        Tom.B
> >  Jan              8        4             9         8
> >  Feb             7         5             4         7
> >  Mar             6         8             4         4
> >  Apr             3         7              6         2
> >  May            5         1             8         5
> >  Jun             6         4              7        1
> >  July             2         8             3         4
> >  Aug             1        2              4         8
> >  Sep            4          3              1        9
> >"
> >DF <- read.table(textConnection(Lines))
> >
> >library(zoo)
> >z <- zooreg(as.matrix(DF), start = as.yearmon(as.Date("2007-01-01")), freq
> >= 12)
> >z <- aggregate(z, as.Date, tail, 1)
> >plot(z, plot.type = "single",  type = "o",
> >       pch = c("A", "A", "B", "B"), lty = 1:2)
> >legend("bottomleft", c("Bob", "Tom"), lty = 1:2)
> >
> >
> >
> >On 9/20/07, Bill Pepe <sonicbill12 at yahoo.com> wrote:
> > > I'm fairly new to S-Plus and I need to get this done quickly. Suppose I
> >have the following fake data below:
> > >
> > >  There are two companies, call them Bob and Tom. Each have two
> >variables, call them A and B, that have observations.
> > >
> > >                         Bob                 Tom
> > >
> > >                    A         B            A        B
> > >  Jan              8        4             9         8
> > >  Feb             7         5             4         7
> > >  Mar             6         8             4         4
> > >  Apr             3         7              6         2
> > >  May            5         1             8         5
> > >  Jun             6         4              7        1
> > >  July             2         8             3         4
> > >  Aug             1        2              4         8
> > >  Sep            4          3              1        9
> > >
> > >  Here is what I want to do: I want to make two different graphs, one for
> >Bob and one for Tom. For each graph, plot both variables A and B. Connect
> >the A values with a line, and connect the B values with a different type of
> >line. So there should be two lines for each graph. For the A line, at each
> >time point, the letter A should be on the line. And the same goes for the B
> >line. Either R or S-Plus since they are essentially the same.
> > >
> > >  I'm sure this is easy, but any help would be greatly appreciated.
> > >
> > >  Thanks,
> > >
> > >  Bill
> > >
> > >
> > > ---------------------------------
> > > Pinpoint customers who are looking for what you sell.
> > >        [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> _________________________________________________________________
> [[replacing trailing spam]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch at stats.uwo.ca  Fri Sep 21 01:58:35 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 20 Sep 2007 19:58:35 -0400
Subject: [R] Cutting & pasting help examples into script window
In-Reply-To: <347152339B716A4D893C9A2988EA87C86928FD@KFSVS2.utk.tennessee.edu>
References: <347152339B716A4D893C9A2988EA87C86927C6@KFSVS2.utk.tennessee.edu>	<200709201518.11464.stefan.grosse@uni-erfurt.de>	<347152339B716A4D893C9A2988EA87C8692812@KFSVS2.utk.tennessee.edu>	<20070920141641.GA25114@eddelbuettel.com>
	<347152339B716A4D893C9A2988EA87C86928FD@KFSVS2.utk.tennessee.edu>
Message-ID: <46F3092B.2080008@stats.uwo.ca>

On 20/09/2007 1:49 PM, Muenchen, Robert A (Bob) wrote:
> Does this look like a bug? If so, is there a different way to report it?

It sounds like a bug, but I can't reproduce it.  You said it is 
intermittent on your system.  Can you try to work out the conditions 
that reliably trigger it?

It might be something specific to your system; does anyone else see this?

Duncan Murdoch


From Joe.Crombie at brs.gov.au  Fri Sep 21 02:27:01 2007
From: Joe.Crombie at brs.gov.au (Crombie, Joe)
Date: Fri, 21 Sep 2007 10:27:01 +1000
Subject: [R] Time series graphs,
	question about  using zoo [SEC=UNCLASSIFIED]
Message-ID: <61C2DEA055980B418D063F8646FCAEFC020B5A68@ACT001CL03EX03.agdaff.gov.au>

Hi Fang,

An easy way of doing this is by:

> matplot(one, pch = LETTERS[1:4], type = 'b')

Cheers  Joe

 
Joe Crombie
 
Information and Risk Sciences
Bureau of Rural Science
Canberra  Australia
 
p: +61 2 6272 5906
e: joe.crombie at brs.gov.au


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of fang liu
Sent: Friday, 21 September 2007 8:35 AM
To: r-help at r-project.org
Subject: Re: [R] Time series graphs, question about using zoo

Hi,
Can you tell me what is the meaning for "tail, 1"  in "aggregate"?
I also want to get some similar graph, but the data is not time series
data.
Suppose here is my data one, I want a graph with x-axis is just the
index(1:9).
The graph plot all the variable A, B,C,D. So there should be 4 lines for
each graph. For the A line, at each time point, the letter A should be
on the line. And the same goes for the B line.
                    A           B            C        D
>                  8           4             9         8
>                  7           5             4         7
>                  6           8             4         4
>                  3           7              6         2
>                  5           1             8         5
>                  6           4              7        1
>                  2           8             3         4
>                  1           2              4         8
>                  4           3              1        9

So I add a name for each row
rownames(one) <- c(1:9)
z <- zooreg(as.matrix(one), start = 1, freq = 1) z <- aggregate(z,
as.Date, tail, 1) plot(z, plot.type = "single",  type = "o",
	pch = c("A", "B", "C", "D"), lty = 1:2)

I get the plot, which I think it should be right. but the problem is
that the x-axis still have month (Jan, ) on it and I didnot get
"A,B,C,D" on my graph, is there any thing wrong?



>From: "Gabor Grothendieck" <ggrothendieck at gmail.com>
>To: "Bill Pepe" <sonicbill12 at yahoo.com>
>CC: r-help at r-project.org
>Subject: Re: [R] Time series graphs
>Date: Thu, 20 Sep 2007 14:15:54 -0400
>
>Using plot.zoo in the zoo package try this:
>
>Lines <- "Bob.A         Bob.B            Tom.A        Tom.B
>  Jan              8        4             9         8
>  Feb             7         5             4         7
>  Mar             6         8             4         4
>  Apr             3         7              6         2
>  May            5         1             8         5
>  Jun             6         4              7        1
>  July             2         8             3         4
>  Aug             1        2              4         8
>  Sep            4          3              1        9
>"
>DF <- read.table(textConnection(Lines))
>
>library(zoo)
>z <- zooreg(as.matrix(DF), start = as.yearmon(as.Date("2007-01-01")),
>freq = 12) z <- aggregate(z, as.Date, tail, 1) plot(z, plot.type = 
>"single",  type = "o",
>	pch = c("A", "A", "B", "B"), lty = 1:2) legend("bottomleft",
c("Bob", 
>"Tom"), lty = 1:2)
>
>
>
>On 9/20/07, Bill Pepe <sonicbill12 at yahoo.com> wrote:
> > I'm fairly new to S-Plus and I need to get this done quickly. 
> > Suppose I
>have the following fake data below:
> >
> >  There are two companies, call them Bob and Tom. Each have two
>variables, call them A and B, that have observations.
> >
> >                         Bob                 Tom
> >
> >                    A         B            A        B
> >  Jan              8        4             9         8
> >  Feb             7         5             4         7
> >  Mar             6         8             4         4
> >  Apr             3         7              6         2
> >  May            5         1             8         5
> >  Jun             6         4              7        1
> >  July             2         8             3         4
> >  Aug             1        2              4         8
> >  Sep            4          3              1        9
> >
> >  Here is what I want to do: I want to make two different graphs, one

> > for
>Bob and one for Tom. For each graph, plot both variables A and B. 
>Connect the A values with a line, and connect the B values with a 
>different type of line. So there should be two lines for each graph.
>For the A line, at each time point, the letter A should be on the line.

>And the same goes for the B line. Either R or S-Plus since they are
essentially the same.
> >
> >  I'm sure this is easy, but any help would be greatly appreciated.
> >
> >  Thanks,
> >
> >  Bill
> >
> >
> > ---------------------------------
> > Pinpoint customers who are looking for what you sell.
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

_________________________________________________________________
[[replacing trailing spam]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

------IMPORTANT - This message has been issued by The Department of Agriculture, Fisheries and Forestry (DAFF). The information transmitted is for the use of the intended recipient only and may contain confidential and/or legally privileged material. It is your responsibility to check any attachments for viruses and defects before opening or sending them on. 

Any reproduction, publication, communication, re-transmission, disclosure, dissemination or other use of the information contained in this e-mail by persons or entities other than the intended recipient is prohibited. The taking of any action in reliance upon this information by persons or entities other than the intended recipient is prohibited. If you have received this e-mail in error please notify the sender and delete all copies of this transmission together with any attachments. If you have received this e-mail as part of a valid mailing list and no longer want to receive a message such as this one advise the sender by return e-mail accordingly. Only e-mail correspondence which includes this footer, has been authorised by DAFF 
------


From lukasneraas.r at gmail.com  Fri Sep 21 02:30:49 2007
From: lukasneraas.r at gmail.com (Luke Neraas)
Date: Thu, 20 Sep 2007 16:30:49 -0800
Subject: [R] Help create a loopto conduct multiple pairwise operations
Message-ID: <1f80d2810709201730o2acf2551ibd25f4fa1092c9a1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070920/943d1560/attachment.pl 

From jholtman at gmail.com  Fri Sep 21 02:52:05 2007
From: jholtman at gmail.com (jim holtman)
Date: Thu, 20 Sep 2007 20:52:05 -0400
Subject: [R] Help create a loopto conduct multiple pairwise operations
In-Reply-To: <1f80d2810709201730o2acf2551ibd25f4fa1092c9a1@mail.gmail.com>
References: <1f80d2810709201730o2acf2551ibd25f4fa1092c9a1@mail.gmail.com>
Message-ID: <644e1f320709201752j6cf6ac31m34f4990baed2298a@mail.gmail.com>

You can put the dataframes in a list and then use 'combn' to determine
the possible pairwise combinations and then use this in an lapply to
compute the products which is also in a list:

>
> X.alleles      <- c(1,5,6,7,8)
> X.Freq        <- c(0.35, 0.15, 0.05 , 0.10, 0.35)
> Loc1          <- cbind( X.alleles,X.Freq)
> X               <- data.frame(Loc1)
>
> #creation of data frame Y
>
> Y.alleles  <- c(1,4,6,8)
> Y.Freq     <- c(0.35, 0.35, 0.10, 0.20 )
> Loc2        <- cbind(Y.alleles, Y.Freq)
> Y             <- data.frame (Loc2)
>
> # creation of data frame Z
>
> Z.alleles  <- c(1,4,5,6,8)
> Z.Freq     <- c(0.35, 0.35, 0.05, 0.05, 0.20)
> Loc3       <- cbind(Z.alleles, Z.Freq)
> Z            <- data.frame (Loc3)
>
> X
  X.alleles X.Freq
1         1   0.35
2         5   0.15
3         6   0.05
4         7   0.10
5         8   0.35
> Y
  Y.alleles Y.Freq
1         1   0.35
2         4   0.35
3         6   0.10
4         8   0.20
> Z
  Z.alleles Z.Freq
1         1   0.35
2         4   0.35
3         5   0.05
4         6   0.05
5         8   0.20
> # create a list of the dataframes you want to multiply
> dfList <- list(X, Y, Z)
> # get possible pairwise matches
> combo <- combn(length(dfList), 2)
> result <- lapply(seq(ncol(combo)), function(.col){
+     dfList[[combo[1, .col]]][, 2] %o% dfList[[combo[2, .col]]][, 2]
+ })
>
> result
[[1]]
       [,1]   [,2]  [,3] [,4]
[1,] 0.1225 0.1225 0.035 0.07
[2,] 0.0525 0.0525 0.015 0.03
[3,] 0.0175 0.0175 0.005 0.01
[4,] 0.0350 0.0350 0.010 0.02
[5,] 0.1225 0.1225 0.035 0.07

[[2]]
       [,1]   [,2]   [,3]   [,4] [,5]
[1,] 0.1225 0.1225 0.0175 0.0175 0.07
[2,] 0.0525 0.0525 0.0075 0.0075 0.03
[3,] 0.0175 0.0175 0.0025 0.0025 0.01
[4,] 0.0350 0.0350 0.0050 0.0050 0.02
[5,] 0.1225 0.1225 0.0175 0.0175 0.07

[[3]]
       [,1]   [,2]   [,3]   [,4] [,5]
[1,] 0.1225 0.1225 0.0175 0.0175 0.07
[2,] 0.1225 0.1225 0.0175 0.0175 0.07
[3,] 0.0350 0.0350 0.0050 0.0050 0.02
[4,] 0.0700 0.0700 0.0100 0.0100 0.04

> dfList
[[1]]
  X.alleles X.Freq
1         1   0.35
2         5   0.15
3         6   0.05
4         7   0.10
5         8   0.35

[[2]]
  Y.alleles Y.Freq
1         1   0.35
2         4   0.35
3         6   0.10
4         8   0.20

[[3]]
  Z.alleles Z.Freq
1         1   0.35
2         4   0.35
3         5   0.05
4         6   0.05


On 9/20/07, Luke Neraas <lukasneraas.r at gmail.com> wrote:
> #Hello,
>
>
> #I have three data frames, X,Y and Z with two columns each and different
> numbers of rows.
>
> # creation of data frame X
>
> X.alleles      <- c(1,5,6,7,8)
> X.Freq        <- c(0.35, 0.15, 0.05 , 0.10, 0.35)
> Loc1          <- cbind( X.alleles,X.Freq)
> X               <- data.frame(Loc1)
>
> #creation of data frame Y
>
> Y.alleles  <- c(1,4,6,8)
> Y.Freq     <- c(0.35, 0.35, 0.10, 0.20 )
> Loc2        <- cbind(Y.alleles, Y.Freq)
> Y             <- data.frame (Loc2)
>
> # creation of data frame Z
>
> Z.alleles  <- c(1,4,5,6,8)
> Z.Freq     <- c(0.35, 0.35, 0.05, 0.05, 0.20)
> Loc3       <- cbind(Z.alleles, Z.Freq)
> Z            <- data.frame (Loc3)
>
> X
> Y
> Z
>
> #  I want to create a pair wise multiplication for all of the second columns
> of my dataframe X,Y and Z
>
> # Here is a way to get two of the data frames to create a pairwise
> multiplication.
>
> X.Freq_times_Y.Freq<- matrix(Y[,2] %o% X[,2], ncol=1)
> X.Freq_times_Y.Freq
>
> # I would like to create a loop to calculate all possible pairwise
> multiplications for the
> # second columns of my X,Y, and Z data frames.
> # I will be conducting pair wise comparisons for up to 50 different data
> frames so I need the code to be
> # as flexible as possible
>
> Any help would be greatly appreciated.
>
> Thanks in advance
>
>
> Luke Neraas
> lukasneraas.r at gmail.com
>
> University of Alaska Fairbanks
> School of Fisheries and Ocean Sciences
> 11120 Glacier Highway
> UAF Fisheries Division
> Juneau, AK 99801
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From muenchen at utk.edu  Fri Sep 21 03:23:47 2007
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Thu, 20 Sep 2007 21:23:47 -0400
Subject: [R] Cutting & pasting help examples into script window
In-Reply-To: <46F3092B.2080008@stats.uwo.ca>
References: <347152339B716A4D893C9A2988EA87C86927C6@KFSVS2.utk.tennessee.edu>	<200709201518.11464.stefan.grosse@uni-erfurt.de>	<347152339B716A4D893C9A2988EA87C8692812@KFSVS2.utk.tennessee.edu>	<20070920141641.GA25114@eddelbuettel.com>
	<347152339B716A4D893C9A2988EA87C86928FD@KFSVS2.utk.tennessee.edu>
	<46F3092B.2080008@stats.uwo.ca>
Message-ID: <347152339B716A4D893C9A2988EA87C86E8FC1@KFSVS2.utk.tennessee.edu>

Now I'm working in 2.5.1 on a home machine also running XP. It has the
same problem, and I think I finally figured it out. 

I've noticed that if the cursor is directly over the text, it becomes an
I-beam. When hovering over the blank space around the text, the cursor
becomes an arrow. Selections via the arrow almost always paste properly
into a script window. Copies made while selecting with the I-beam cursor
almost always fail.

Regardless of how the selection is done, a paste into Notepad never
fails. Copying from Notepad to a script window never fails, regardless
of how the paste into Notepad was selected.

Very strange!

Bob

P.S. almost the testing has been with the ?data.frame and ?summary
examples.

> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca]
> Sent: Thursday, September 20, 2007 7:59 PM
> To: Muenchen, Robert A (Bob)
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Cutting & pasting help examples into script window
> 
> On 20/09/2007 1:49 PM, Muenchen, Robert A (Bob) wrote:
> > Does this look like a bug? If so, is there a different way to report
> it?
> 
> It sounds like a bug, but I can't reproduce it.  You said it is
> intermittent on your system.  Can you try to work out the conditions
> that reliably trigger it?
> 
> It might be something specific to your system; does anyone else see
> this?
> 
> Duncan Murdoch


From sdk0084 at yahoo.com  Fri Sep 21 03:29:25 2007
From: sdk0084 at yahoo.com (sk)
Date: Thu, 20 Sep 2007 18:29:25 -0700 (PDT)
Subject: [R] BRugs package question
Message-ID: <333759.55037.qm@web60914.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070920/2cf28dad/attachment.pl 

From wgavioli at fas.harvard.edu  Fri Sep 21 03:57:31 2007
From: wgavioli at fas.harvard.edu (Wayne Aldo Gavioli)
Date: Thu, 20 Sep 2007 21:57:31 -0400
Subject: [R] Line Graph - Greater than 2 variables on plot
Message-ID: <1190339851.46f3250bca8f3@webmail.fas.harvard.edu>



Hello all,

I was wondering if anyone knew how to construct a multiple line graph on R,
where there are 2 (or more) sets of data points plotted against some x axis of
data, and you can draw a line on the graph connecting each set of data points.

For example:

A               B              C          D
0.6566        2.1185        1.2320        5
0.647         2.0865        1.2325        10
0.6532        2.1060        1.2287        15
0.6487        2.1290        1.2313        20
0.6594        2.1285        1.2341        25
0.6577        2.1070        1.2343        30
0.6579        2.1345        1.2340        35
0.6734        2.1705        1.2362        40
0.675         2.1845        1.2372        45
0.6592        2.1550        1.2340        50
0.6647        2.1710        1.2305        55



Would there be a way:
a) To graph all the points of data in sets A, B and C as Y coordinates on one
graph, using the points in set D as the X-axis/coordinates for all 3 sets (A, B
and C)?
b) To be able to draw 3 lines on the graph that connect each set of data (1 line
connects all the A points, one line connects all the B points, one line connects
all the C points)


I couldn't find anything in the examples or the help section about multiple
lines on the same graph, only one line.


Thanks,



Wayne


From r.turner at auckland.ac.nz  Fri Sep 21 04:18:28 2007
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 21 Sep 2007 14:18:28 +1200
Subject: [R] Line Graph - Greater than 2 variables on plot
In-Reply-To: <1190339851.46f3250bca8f3@webmail.fas.harvard.edu>
References: <1190339851.46f3250bca8f3@webmail.fas.harvard.edu>
Message-ID: <D13FB098-B589-4562-B7EB-A1A8DE996EB6@auckland.ac.nz>


On 21/09/2007, at 1:57 PM, Wayne Aldo Gavioli wrote:

>
>
> Hello all,
>
> I was wondering if anyone knew how to construct a multiple line  
> graph on R,
> where there are 2 (or more) sets of data points plotted against  
> some x axis of
> data, and you can draw a line on the graph connecting each set of  
> data points.
>
> For example:
>
> A               B              C          D
> 0.6566        2.1185        1.2320        5
> 0.647         2.0865        1.2325        10
> 0.6532        2.1060        1.2287        15
> 0.6487        2.1290        1.2313        20
> 0.6594        2.1285        1.2341        25
> 0.6577        2.1070        1.2343        30
> 0.6579        2.1345        1.2340        35
> 0.6734        2.1705        1.2362        40
> 0.675         2.1845        1.2372        45
> 0.6592        2.1550        1.2340        50
> 0.6647        2.1710        1.2305        55
>
>
>
> Would there be a way:
> a) To graph all the points of data in sets A, B and C as Y  
> coordinates on one
> graph, using the points in set D as the X-axis/coordinates for all  
> 3 sets (A, B
> and C)?
> b) To be able to draw 3 lines on the graph that connect each set of  
> data (1 line
> connects all the A points, one line connects all the B points, one  
> line connects
> all the C points)
>
>
> I couldn't find anything in the examples or the help section about  
> multiple
> lines on the same graph, only one line.

?points
?lines
?matplot

######################################################################
Attention:\ This e-mail message is privileged and confidenti...{{dropped}}


From jporzak at gmail.com  Fri Sep 21 05:13:05 2007
From: jporzak at gmail.com (Jim Porzak)
Date: Thu, 20 Sep 2007 20:13:05 -0700
Subject: [R] RJDBC connection help needed
Message-ID: <2a9c000c0709202013v39fa9f1fv409923be0b078238@mail.gmail.com>

Hi everyone,

I'm obviously missing something simple here...

Trying to connect to an external db with RJDBC. (I can connect OK with
ROLAP and with other java apps, eg dbVisualizer)

JDBC call seems to work ok:

> driverClass <- "net.sourceforge.jtds.jdbc.Driver"
> classPath <- "C:\\Dwns\\jtds\\jtds-1.2.jar"
> identifier.quote <- '"'
> drv <- JDBC(driverClass, classPath, identifier.quote)
> summary(drv)
JDBCDriver
name = JDBC
driver.version = 0.1-1
DBI.version = 0.1-1
client.version = NA
max.connections = NA
>

but attempting to connect gives:
> dbURL <- "jdbc:jtds:sqlserver://xxxx.yyyy.com;DatabaseName=sunms"
> con <- dbConnect(drv, dbURL, uid = "jporzak", pwd = "zzzz")
Error in .local(drv, ...) : Unable to connect JDBC to
jdbc:jtds:sqlserver://xxxx.yyyy.com;DatabaseName=sunms
>

where "xxxx", "yyyy", "zzzz" are changed to protect the innocent.

note that the dbURL string is exactly what I use in dbVisualizer with success

(using WinXP SP2, R 2.5.1,  RJDBC 0.1-3)

-- 
TIA,
Jim Porzak
http://www.linkedin.com/in/jimporzak


From jholtman at gmail.com  Fri Sep 21 06:02:23 2007
From: jholtman at gmail.com (jim holtman)
Date: Fri, 21 Sep 2007 00:02:23 -0400
Subject: [R] Line Graph - Greater than 2 variables on plot
In-Reply-To: <1190339851.46f3250bca8f3@webmail.fas.harvard.edu>
References: <1190339851.46f3250bca8f3@webmail.fas.harvard.edu>
Message-ID: <644e1f320709202102sc2fcb55w3b9bf9d5f4233b2@mail.gmail.com>

This should do it for you:

> x <- read.table(textConnection("A               B              C          D
+ 0.6566        2.1185        1.2320        5
+ 0.647         2.0865        1.2325        10
+ 0.6532        2.1060        1.2287        15
+ 0.6487        2.1290        1.2313        20
+ 0.6594        2.1285        1.2341        25
+ 0.6577        2.1070        1.2343        30
+ 0.6579        2.1345        1.2340        35
+ 0.6734        2.1705        1.2362        40
+ 0.675         2.1845        1.2372        45
+ 0.6592        2.1550        1.2340        50
+ 0.6647        2.1710        1.2305        55"), header=TRUE)
>
> matplot(x[, 4], x[, -4], type='o')
>


On 9/20/07, Wayne Aldo Gavioli <wgavioli at fas.harvard.edu> wrote:
>
>
> Hello all,
>
> I was wondering if anyone knew how to construct a multiple line graph on R,
> where there are 2 (or more) sets of data points plotted against some x axis of
> data, and you can draw a line on the graph connecting each set of data points.
>
> For example:
>
> A               B              C          D
> 0.6566        2.1185        1.2320        5
> 0.647         2.0865        1.2325        10
> 0.6532        2.1060        1.2287        15
> 0.6487        2.1290        1.2313        20
> 0.6594        2.1285        1.2341        25
> 0.6577        2.1070        1.2343        30
> 0.6579        2.1345        1.2340        35
> 0.6734        2.1705        1.2362        40
> 0.675         2.1845        1.2372        45
> 0.6592        2.1550        1.2340        50
> 0.6647        2.1710        1.2305        55
>
>
>
> Would there be a way:
> a) To graph all the points of data in sets A, B and C as Y coordinates on one
> graph, using the points in set D as the X-axis/coordinates for all 3 sets (A, B
> and C)?
> b) To be able to draw 3 lines on the graph that connect each set of data (1 line
> connects all the A points, one line connects all the B points, one line connects
> all the C points)
>
>
> I couldn't find anything in the examples or the help section about multiple
> lines on the same graph, only one line.
>
>
> Thanks,
>
>
>
> Wayne
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From klein82517 at yahoo.de  Fri Sep 21 07:59:14 2007
From: klein82517 at yahoo.de (Andreas Klein)
Date: Fri, 21 Sep 2007 07:59:14 +0200 (CEST)
Subject: [R] Estimate correlation with bootstrap
Message-ID: <587248.1680.qm@web30610.mail.mud.yahoo.com>

Hello.

I would like to estimate the correlation coefficient
from two samples with Bootstrapping using the
R-function sample().

The problem is, that I have to sample pairwise. For
example if I have got two time series and I draw from
the first series the value from 1912 I need the value
from 1912 from the second sample, too.

Example:

Imagine that a and b are two time series with returns
for example: 

a <- c(1,2,3,4,5,6,7,8,9,10)
b <- c(1,1,56,3,6,6,6,7,2,10)

a.sample     <- numeric(10)
b.sample     <- numeric(10)
boot.cor.a.b <- numeric(1000)

for (i in 1:1000)

{

 for (j in 1:10)

 {

  a.sample[j] <- sample(a,1,replace=TRUE)
  b.sample[j] <- sample(b,1,replace=TRUE)

 }

 boot.cor.a.b[i] <- cor(a,b)

}

The problem here is, that the sampling is independent
from each other.

So how do I have to change the R-code to get the
pairwise sampling mentioned above?

I hope you can help me.

Sincerely
Klein.


      ________


From b.barnes at dkfz-heidelberg.de  Fri Sep 21 09:33:44 2007
From: b.barnes at dkfz-heidelberg.de (Benjamin Barnes)
Date: Fri, 21 Sep 2007 09:33:44 +0200
Subject: [R] Need help putting histograms on the diagonal of a splom plot
Message-ID: <46F373D8.4060700@dkfz-heidelberg.de>

Hello,

I think the histograms may have been unintentionally omitted from the 
examples below. Borrowing from a couple of sources, here's a function to 
get the histograms instead of the density plot:

panel.hist.splom<-function(x, ...)

     {

         yrng <- current.panel.limits()$ylim

         h <- hist(x, plot = FALSE)

         breaks <- h$breaks; nB <- length(breaks)

         y <- h$counts; y <- yrng[1] + 0.95 * diff(yrng) * y / max(y)

         panel.rect(breaks[-nB], yrng[1], breaks[-1], y, col="cyan", ...)

     }


-Ben



From: Deepayan Sarkar <deepayan.sarkar_at_gmail.com 
<mailto:deepayan.sarkar_at_gmail.com?Subject=Re:%20%5BR%5D%20Need%20help%20putting%20histograms%20on%20the%20diagonal%20of%20a%20splom%20plot>> 

Date: Fri, 31 Aug 2007 14:02:27 -0700

On 8/30/07, Marc Paterno <paterno_at_fnal.gov> wrote:
 > Hello, 
<http://tolstoy.newcastle.edu.au/R/e2/help/07/08/24539.html#24614qlink1>
/> /
/> I am in need of help in putting histograms on the diagonal of a plot /
/> produced with splom(). /
/> /
/> The plot matrix I am trying to produce is to have standard scatterplots /
/> in the upper-left triangle, contour plots in the lower-right triangle, /
/> and histograms on the diagonal. I have a function that does the first /
/> two, but the histograms on the diagonal has been beyond my ability. /
/> /
/> Here is my function: /
/> /
/> require(lattice) /
/> require(MASS) /
/> my.plot = function(data) /
/> { /
/> splom( ~data /
/> , lower.panel=function(x,y, ...) /
/> { /
/> xy=kde2d(x,y) /
/> xy.tr=con2tr(xy) /
/> panel.contourplot( xy.tr$x /
/> , xy.tr$y /
/> , xy.tr$z /
/> , subscripts=seq(nrow(xy.tr)) /
/> , contour=TRUE /
/> , region=TRUE /
/> , labels = FALSE /
/> , col.regions = terrain.colors /
/> ) /
/> } /
/> , upper.panel=function(x,y, ...) /
/> { /
/> panel.grid(-1,-1) /
/> panel.xyplot(x,y, cex=0.5) /
/> } /
/> #, diag.panel=function(x, ...) /
/> # { /
/> # panel.histogram(x, ...) /
/> # } /
/> ) /
/> } /
/> /
/> It can be called, for example, with: /
/> /
/> my.plot(subset(iris, select = Sepal.Length:Petal.Width)) /
/> /
/> (the subset is necessary to get rid of a variable that is a factor; my /
/> function can not deal with factors). /
/> /
/> I have commented out my best guess at the code needed to produce the /
/> histograms along the diagonal, which fails. /

Well, basically the y-axis range of the diagonal panels are not right. 
What you want is simpler if you are happy with a density estimate:

my.plot = function(data)
{
  splom( ~data

       #, lower.panel=...
       #, upper.panel=...
       , diag.panel = function(x, ...)
         {
             yrng <- current.panel.limits()$ylim
             d <- density(x)
             d$y <- with(d, yrng[1] + 0.95 * diff(yrng) * y / max(y) )
             panel.lines(d)
         })


}

my.plot(iris[1:4])

For a histogram, things are a bit more complicated, but still easy enough:

my.plot = function(data)
{
  splom( ~data

       #, lower.panel=...
       #, upper.panel=...
       , diag.panel = function(x, ...)
         {
             yrng <- current.panel.limits()$ylim
             d <- density(x)
             d$y <- with(d, yrng[1] + 0.95 * diff(yrng) * y / max(y) )
             panel.lines(d)
         })


}

-Deepayan

-- 
Benjamin Barnes, MEM

Doctoral Student
Department of Environmental Epidemiology

German Cancer Research Center
Im Neuenheimer Feld 280
D-69120 Heidelberg


From gustaf.rydevik at gmail.com  Fri Sep 21 10:07:22 2007
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Fri, 21 Sep 2007 10:07:22 +0200
Subject: [R] Cutting & pasting help examples into script window
In-Reply-To: <347152339B716A4D893C9A2988EA87C86E8FC1@KFSVS2.utk.tennessee.edu>
References: <347152339B716A4D893C9A2988EA87C86927C6@KFSVS2.utk.tennessee.edu>
	<200709201518.11464.stefan.grosse@uni-erfurt.de>
	<347152339B716A4D893C9A2988EA87C8692812@KFSVS2.utk.tennessee.edu>
	<20070920141641.GA25114@eddelbuettel.com>
	<347152339B716A4D893C9A2988EA87C86928FD@KFSVS2.utk.tennessee.edu>
	<46F3092B.2080008@stats.uwo.ca>
	<347152339B716A4D893C9A2988EA87C86E8FC1@KFSVS2.utk.tennessee.edu>
Message-ID: <45f568c70709210107m107d3792j1d4a366feace3310@mail.gmail.com>

On 9/21/07, Muenchen, Robert A (Bob) <muenchen at utk.edu> wrote:
> Now I'm working in 2.5.1 on a home machine also running XP. It has the
> same problem, and I think I finally figured it out.
>
> I've noticed that if the cursor is directly over the text, it becomes an
> I-beam. When hovering over the blank space around the text, the cursor
> becomes an arrow. Selections via the arrow almost always paste properly
> into a script window. Copies made while selecting with the I-beam cursor
> almost always fail.
>
> Regardless of how the selection is done, a paste into Notepad never
> fails. Copying from Notepad to a script window never fails, regardless
> of how the paste into Notepad was selected.
>
> Very strange!
>
> Bob
>
> P.S. almost the testing has been with the ?data.frame and ?summary
> examples.
>
> > -----Original Message-----
> > From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca]
> > Sent: Thursday, September 20, 2007 7:59 PM
> > To: Muenchen, Robert A (Bob)
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] Cutting & pasting help examples into script window
> >
> > On 20/09/2007 1:49 PM, Muenchen, Robert A (Bob) wrote:
> > > Does this look like a bug? If so, is there a different way to report
> > it?
> >
> > It sounds like a bug, but I can't reproduce it.  You said it is
> > intermittent on your system.  Can you try to work out the conditions
> > that reliably trigger it?
> >
> > It might be something specific to your system; does anyone else see
> > this?
> >
> > Duncan Murdoch
>

I notice the same thing, (R 2.5.0), except I can't get the example to
paste correctly at all-
The cursor never turns into I-beam.

/Gustaf



-- 
Gustaf Rydevik, M.Sci.
tel: +46(0)703 051 451
address:Essingetorget 40,112 66 Stockholm, SE
skype:gustaf_rydevik


From mark.collins at gulfstream-software.com  Fri Sep 21 10:17:08 2007
From: mark.collins at gulfstream-software.com (Mark Collins)
Date: Fri, 21 Sep 2007 09:17:08 +0100
Subject: [R] Building packages including Java files
Message-ID: <200709210917.09588.mark.collins@hushmail.com>

Hello all,

Can someone please point me in the right direction to find the documentation 
that explains how to build packages that include java code. Thank you.

I'm sorry if this is entirely obvious!

Best regards,

Mark

-- 
Mark Collins
mark.collins at hushmail.com


From bartjoosen at hotmail.com  Fri Sep 21 10:24:48 2007
From: bartjoosen at hotmail.com (Bartjoosen)
Date: Fri, 21 Sep 2007 01:24:48 -0700 (PDT)
Subject: [R] Cutting & pasting help examples into script window
In-Reply-To: <45f568c70709210107m107d3792j1d4a366feace3310@mail.gmail.com>
References: <347152339B716A4D893C9A2988EA87C86927C6@KFSVS2.utk.tennessee.edu>
	<200709201518.11464.stefan.grosse@uni-erfurt.de>
	<347152339B716A4D893C9A2988EA87C8692812@KFSVS2.utk.tennessee.edu>
	<347152339B716A4D893C9A2988EA87C86928FD@KFSVS2.utk.tennessee.edu>
	<46F3092B.2080008@stats.uwo.ca>
	<347152339B716A4D893C9A2988EA87C86E8FC1@KFSVS2.utk.tennessee.edu>
	<45f568c70709210107m107d3792j1d4a366feace3310@mail.gmail.com>
Message-ID: <12812794.post@talk.nabble.com>


Same problem here, it never works

Sys.info()
                      sysname                       release 
                    "Windows"                      "NT 5.1" 
                      version                      nodename 
"(build 2600) Service Pack 2"                  "PCWXPUPLC1" 
                      machine                         login 
                        "x86" 

version
               _                           
platform       i386-pc-mingw32             
arch           i386                        
os             mingw32                     
system         i386, mingw32               
status                                     
major          2                           
minor          5.1                         
year           2007                        
month          06                          
day            27                          
svn rev        42083                       
language       R                           
version.string R version 2.5.1 (2007-06-27)


Bart

Gustaf Rydevik wrote:
> 
> On 9/21/07, Muenchen, Robert A (Bob) <muenchen at utk.edu> wrote:
>> Now I'm working in 2.5.1 on a home machine also running XP. It has the
>> same problem, and I think I finally figured it out.
>>
>> I've noticed that if the cursor is directly over the text, it becomes an
>> I-beam. When hovering over the blank space around the text, the cursor
>> becomes an arrow. Selections via the arrow almost always paste properly
>> into a script window. Copies made while selecting with the I-beam cursor
>> almost always fail.
>>
>> Regardless of how the selection is done, a paste into Notepad never
>> fails. Copying from Notepad to a script window never fails, regardless
>> of how the paste into Notepad was selected.
>>
>> Very strange!
>>
>> Bob
>>
>> P.S. almost the testing has been with the ?data.frame and ?summary
>> examples.
>>
>> > -----Original Message-----
>> > From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca]
>> > Sent: Thursday, September 20, 2007 7:59 PM
>> > To: Muenchen, Robert A (Bob)
>> > Cc: r-help at stat.math.ethz.ch
>> > Subject: Re: [R] Cutting & pasting help examples into script window
>> >
>> > On 20/09/2007 1:49 PM, Muenchen, Robert A (Bob) wrote:
>> > > Does this look like a bug? If so, is there a different way to report
>> > it?
>> >
>> > It sounds like a bug, but I can't reproduce it.  You said it is
>> > intermittent on your system.  Can you try to work out the conditions
>> > that reliably trigger it?
>> >
>> > It might be something specific to your system; does anyone else see
>> > this?
>> >
>> > Duncan Murdoch
>>
> 
> I notice the same thing, (R 2.5.0), except I can't get the example to
> paste correctly at all-
> The cursor never turns into I-beam.
> 
> /Gustaf
> 
> 
> 
> -- 
> Gustaf Rydevik, M.Sci.
> tel: +46(0)703 051 451
> address:Essingetorget 40,112 66 Stockholm, SE
> skype:gustaf_rydevik
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Cutting---pasting-help-examples-into-script-window-tf4487442.html#a12812794
Sent from the R help mailing list archive at Nabble.com.


From ligges at statistik.uni-dortmund.de  Fri Sep 21 10:56:31 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 21 Sep 2007 10:56:31 +0200
Subject: [R] BRugs package question
In-Reply-To: <333759.55037.qm@web60914.mail.yahoo.com>
References: <333759.55037.qm@web60914.mail.yahoo.com>
Message-ID: <46F3873F.7070000@statistik.uni-dortmund.de>



sk wrote:
> Hi there,
>   I installed the latest OpenBUGS version (3.0.3) in program files folder but it seems that bugs use its own version of OpenBUGS. 
>   here is part of the message bugs returns
>   ..... 
>   Welcome to BRugs running on OpenBUGS version 2.2.0 beta 
>    
>   how can i configure BRugs  to use the mine version of OpenBUGS?

You cannot, because the OpenBUGS API changed. Therefore using some trick 
is irrelevant here. We have submitted a new version of BRugs to CRAN a 
couple of days ago which will appear on you local mirror probably next 
week. (Kurt as  maintainer of the source repository is currently 
offline...).

For those who cannot wait, a binary BRugs version for R-2.5.1 for 
Windows is currently available from:
http://www.statistik.uni-dortmund.de/~ligges/BRugs/BRugs_0.4-1.zip

Uwe Ligges






>   Cheers, SK
>    
> 
>        
> ---------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From reilly at stat.auckland.ac.nz  Fri Sep 21 11:38:11 2007
From: reilly at stat.auckland.ac.nz (James Reilly)
Date: Fri, 21 Sep 2007 21:38:11 +1200
Subject: [R] Ambiguities in vector
In-Reply-To: <AFE3DEF9-1F12-4ACC-B722-98BBB7DC245A@systbot.uzh.ch>
References: <8FA3D679-C879-4C88-8775-0951FFD99F1D@systbot.uzh.ch>	<12802997.post@talk.nabble.com>
	<AFE3DEF9-1F12-4ACC-B722-98BBB7DC245A@systbot.uzh.ch>
Message-ID: <46F39103.8050102@stat.auckland.ac.nz>


If I understand you right, you have several multiple response variables 
(with the responses encoded in numeric strings) and you want to see 
whether these are associated with sex. To tabulate the data, I would 
convert your variables into collections of dummy variables using 
regexpr(), then use table(). You can use a modified chi-squared test 
with a Rao-Scott correction on the resulting tables; see Thomas and 
Decady (2004). Bootstrapping is another possible approach.

@article{,
	Author = {Thomas, D. Roland and Decady, Yves J.},
	Journal = {International Journal of Testing},
	Number = {1},
	Pages = {43 - 59},
	Title = {Testing for Association Using Multiple Response Survey Data: 
Approximate Procedures Based on the Rao-Scott Approach.},
	Volume = {4},
	Year = {2004},
Url=http://search.ebscohost.com/login.aspx?direct=true&db=pbh&AN=13663214&site=ehost-live
}

Hope this helps,
James
-- 
James Reilly
Department of Statistics, University of Auckland
Private Bag 92019, Auckland, New Zealand

On 21/9/07 7:14 AM, Birgit Lemcke wrote:
> First thanks for your answer.
> Now I try to explain better:
> 
> I have species in the rows and morphological attributes in the  
> columns coded by numbers (qualitative variables; nominal and ordinal).
> In one table for the male plants of every species and in the other  
> table for the female plants of every species. The variables contain  
> every possible occurrence in this species and this gender.
> I would like to compare every variable between male and female plants  
> for example using a ChiSquare Test.
> The Null-hypothesis could be: Variable male is equal to variable Female.
> 
> The question behind all is, if male and female plants in this species  
> are significantly different and which attributes are responsible for  
> this difference.
> 
> I really hope that this is better understandable. If not please ask.
> 
> Thanks a million in advance.
> 
> 
> Greetings
> 
> Birgit


From jim at bitwrit.com.au  Fri Sep 21 11:42:10 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 21 Sep 2007 19:42:10 +1000
Subject: [R] Line Graph - Greater than 2 variables on plot
In-Reply-To: <1190339851.46f3250bca8f3@webmail.fas.harvard.edu>
References: <1190339851.46f3250bca8f3@webmail.fas.harvard.edu>
Message-ID: <46F391F2.9080601@bitwrit.com.au>

Wayne Aldo Gavioli wrote:
> 
> Hello all,
> 
> I was wondering if anyone knew how to construct a multiple line graph on R,
> where there are 2 (or more) sets of data points plotted against some x axis of
> data, and you can draw a line on the graph connecting each set of data points.
> 
> For example:
> 
> A               B              C          D
> 0.6566        2.1185        1.2320        5
> 0.647         2.0865        1.2325        10
> 0.6532        2.1060        1.2287        15
> 0.6487        2.1290        1.2313        20
> 0.6594        2.1285        1.2341        25
> 0.6577        2.1070        1.2343        30
> 0.6579        2.1345        1.2340        35
> 0.6734        2.1705        1.2362        40
> 0.675         2.1845        1.2372        45
> 0.6592        2.1550        1.2340        50
> 0.6647        2.1710        1.2305        55
> 
> 
> 
> Would there be a way:
> a) To graph all the points of data in sets A, B and C as Y coordinates on one
> graph, using the points in set D as the X-axis/coordinates for all 3 sets (A, B
> and C)?
> b) To be able to draw 3 lines on the graph that connect each set of data (1 line
> connects all the A points, one line connects all the B points, one line connects
> all the C points)
> 
> 
> I couldn't find anything in the examples or the help section about multiple
> lines on the same graph, only one line.
> 
Hi Wayne,

Assume your data is in a data frame named "wag":

plot(wag$D,wag$A,main="Three variable plot",xlab="D",ylab="Value",
  ylim=range(wag[c("A","B","C")]),type="l",col=2)
lines(wag$D,wag$B,type="l",pch=2,col=3)
lines(wag$D,wag$C,type="l",pch=3,col=4)
legend(25,1.9,c("A","B","C"),lty=1,col=2:4)

Jim


From yn19832 at msn.com  Fri Sep 21 11:45:36 2007
From: yn19832 at msn.com (livia)
Date: Fri, 21 Sep 2007 02:45:36 -0700 (PDT)
Subject: [R] fPortfolio Package
Message-ID: <12813809.post@talk.nabble.com>


Hello,

I would like to do a portfolio optimization in R and I tried to use the
function in "fPortfolio", but it appears there does not exist such function.

Could anyone give me some advice?

Many thanks
-- 
View this message in context: http://www.nabble.com/fPortfolio-Package-tf4492927.html#a12813809
Sent from the R help mailing list archive at Nabble.com.


From murdoch at stats.uwo.ca  Fri Sep 21 12:25:32 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 21 Sep 2007 06:25:32 -0400
Subject: [R] Cutting & pasting help examples into script window
In-Reply-To: <347152339B716A4D893C9A2988EA87C86E8FC1@KFSVS2.utk.tennessee.edu>
References: <347152339B716A4D893C9A2988EA87C86927C6@KFSVS2.utk.tennessee.edu>	<200709201518.11464.stefan.grosse@uni-erfurt.de>	<347152339B716A4D893C9A2988EA87C8692812@KFSVS2.utk.tennessee.edu>	<20070920141641.GA25114@eddelbuettel.com>
	<347152339B716A4D893C9A2988EA87C86928FD@KFSVS2.utk.tennessee.edu>
	<46F3092B.2080008@stats.uwo.ca>
	<347152339B716A4D893C9A2988EA87C86E8FC1@KFSVS2.utk.tennessee.edu>
Message-ID: <46F39C1C.4010809@stats.uwo.ca>

Muenchen, Robert A (Bob) wrote:
> Now I'm working in 2.5.1 on a home machine also running XP. It has the
> same problem, and I think I finally figured it out. 
>
> I've noticed that if the cursor is directly over the text, it becomes an
> I-beam. When hovering over the blank space around the text, the cursor
> becomes an arrow. Selections via the arrow almost always paste properly
> into a script window. Copies made while selecting with the I-beam cursor
> almost always fail.
>
> Regardless of how the selection is done, a paste into Notepad never
> fails. Copying from Notepad to a script window never fails, regardless
> of how the paste into Notepad was selected.
>
> Very strange!
>
> Bob
>
> P.S. almost the testing has been with the ?data.frame and ?summary
> examples.
>
>   
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca]
>> Sent: Thursday, September 20, 2007 7:59 PM
>> To: Muenchen, Robert A (Bob)
>> Cc: r-help at stat.math.ethz.ch
>> Subject: Re: [R] Cutting & pasting help examples into script window
>>
>> On 20/09/2007 1:49 PM, Muenchen, Robert A (Bob) wrote:
>>     
>>> Does this look like a bug? If so, is there a different way to report
>>>       
>> it?
>>
>> It sounds like a bug, but I can't reproduce it.  You said it is
>> intermittent on your system.  Can you try to work out the conditions
>> that reliably trigger it?
>>
>> It might be something specific to your system; does anyone else see
>> this?
>>
>> Duncan Murdoch
>>     
Okay, I've got it now.  I'll see if I can spot what's going on.

Duncan Murdoch


From marcel.austenfeld at uni-bielefeld.de  Fri Sep 21 12:37:45 2007
From: marcel.austenfeld at uni-bielefeld.de (Bio7)
Date: Fri, 21 Sep 2007 03:37:45 -0700 (PDT)
Subject: [R] Building packages including Java files
In-Reply-To: <200709210917.09588.mark.collins@hushmail.com>
References: <200709210917.09588.mark.collins@hushmail.com>
Message-ID: <12814486.post@talk.nabble.com>


I think you have to visit the following website to get information about java
packages:

http://www.rforge.net/rJava/ http://www.rforge.net/rJava/ 

Then of course the official R documentation which describes how to build
packages for R.


With kind regards

Marcel
-- 
View this message in context: http://www.nabble.com/Building-packages-including-Java-files-tf4492509.html#a12814486
Sent from the R help mailing list archive at Nabble.com.


From gavin.simpson at ucl.ac.uk  Fri Sep 21 13:40:29 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 21 Sep 2007 12:40:29 +0100
Subject: [R] Plotmath issue superscript "-"
In-Reply-To: <46F29D9C.9010207@biostat.ku.dk>
References: <1190303669.22258.26.camel@gsimpson.geog.ucl.ac.uk>
	<46F29D9C.9010207@biostat.ku.dk>
Message-ID: <1190374829.31895.46.camel@gsimpson.geog.ucl.ac.uk>

On Thu, 2007-09-20 at 18:19 +0200, Peter Dalgaard wrote:
> Gavin Simpson wrote:
> > Dear List,
> >
> > I'm trying to typeset some chemical ions in axis labels. These have both
> > super and subscript components, and for some, I need a superscript "-".
> > In LaTeX I might use $NO_3^-$ to do the typesetting, but I'm having a
> > problem getting the correct invocation for expression:
<snip />
> >   
> It's an operator, it needs something to operate on.
> 
> Try
> 
>  plot(0,main=quote(NO^-{}))
> 

Thanks, Peter, for this solution, and also to Peter Ehlers and
ScionForbai for theirs.

All the best,

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From tom.cohen78 at yahoo.se  Fri Sep 21 14:02:13 2007
From: tom.cohen78 at yahoo.se (Tom Cohen)
Date: Fri, 21 Sep 2007 14:02:13 +0200 (CEST)
Subject: [R] help with making a function of scatter plot with multiple
	variables
In-Reply-To: <644e1f320709201331k1fccd5waa096ca30eb4a341@mail.gmail.com>
Message-ID: <741389.12638.qm@web23009.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070921/6cfc4175/attachment.asc 

From ripley at stats.ox.ac.uk  Fri Sep 21 14:16:34 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 21 Sep 2007 13:16:34 +0100 (BST)
Subject: [R] Cross Compiling
In-Reply-To: <793e846d0709141102p4e8480ccm2f3ea282231972c1@mail.gmail.com>
References: <793e846d0709141102p4e8480ccm2f3ea282231972c1@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709211306210.784@gannet.stats.ox.ac.uk>

On Fri, 14 Sep 2007, Scott Hyde wrote:

> Hello All,
>
> I have a Linux computer and do all of my work from it.  However, I
> teach also, which means that many of my students use windows.   Hence,
> I need to create packages that work under windows as well as Linux.  I
> have tried to follow the directions at
>
> http://cran.r-project.org/doc/contrib/cross-build.pdf

I believe that is some years' old: current instructions are in the R-admin 
manual.

> which is the document "Building Microsoft Windows Versions of R and R
> packages under Intel Linux".  This has been very helpful.  However,
> the file R_Tcl.zip is no longer available, so I cannot compile R for
> Windows using the "make R" command as described in the document.  Is
> it necessary to have the Tcl sources in there?  If it is, how should
> the directions be modified to enable the complete compilation of R?

The files have been available at http://www.stats.ox.ac.uk/pub/Rtools. 
I've just added user-visible links to them.

You could work around needing the Tcl sources, but you cannot work around 
needing iconv.dll in R-2.6.0.

> None of my code contains C, Fortran, or any other language.  It is
> just plain R code.  I would think that this would be easier to convert
> over.  Is it?  I tried the following and it seems to work, but I'd
> like to know if it is safe.
>
> 1.  Build package with "pre-compiled binary package" option "R CMD
> build --binary pkgname"
> 2. convert the resulting tar.gz file to a zip archive.
> 3. Install it on a windows machine.
>
> This process successfully works when I install it on a windows
> machine, but I have no idea how safe it is.

This is just a more cumbersome version of the procedure described in 
README.packages:

   If your package has no compiled code it is possible that zipping up
   the installed package on Linux will produce an installable package on
   Windows.  (It has always worked for us, but failures have been
   reported.)

However, you don't get the (default) CHM help this way, which you could by 
using Uwe Ligges' autobuilder.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From h.wickham at gmail.com  Fri Sep 21 14:16:45 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 21 Sep 2007 07:16:45 -0500
Subject: [R] help with making a function of scatter plot with multiple
	variables
In-Reply-To: <741389.12638.qm@web23009.mail.ird.yahoo.com>
References: <644e1f320709201331k1fccd5waa096ca30eb4a341@mail.gmail.com>
	<741389.12638.qm@web23009.mail.ird.yahoo.com>
Message-ID: <f8e6ff050709210516u353d975cs6bc4d4c52bfbb305@mail.gmail.com>

Tom,

It might be easier to move to a higher order plotting model, like
ggplot2 or lattice.

For a similar plot in ggplot2, all you would do is:

qplot(mpg, wt, data=mtcars, col=factor(cyl), shape=factor(cyl))

you would need to do some tweaking to get the plot exactly like you
want, but the defaults in ggplot have been chosen to have good
perceptual properties.

And similarly in lattice:
xyplot(wt ~ mpg, data=mtcars, group=factor(cyl))


Hadley

On 9/21/07, Tom Cohen <tom.cohen78 at yahoo.se> wrote:
> Thanks Jim for the excellent solution.
>
> Can I make this function more flexible for the usage of different numbers of parameters?
>
>   Tom
> jim holtman <jholtman at gmail.com> skrev:
>   The simple way is to enclose it in a 'function' and pass parameters.
> Assuming that you have the same number of parameters, then the
> following will do:
>
> my.func <- function(x,y,d1,v1,s1,t1,s2,t2,s3,t3,s4,t4,s5,t5)
> {
> op <- par(bg = "grey97")
> par(mfrow=c(1,2))
> plot(d1,v1, pch="v", col="orange",cex=0.6, lwd=2,
> xlab="day", ylab="resp",cex.main =1,font.main= 1,main=" Surv
> data",ylim=y,xlim=x,
> col.main="navyblue",col.lab="navyblue",cex.lab=0.7)
>
> points(s1,t1, pch="A", col="green4", cex=1)
> points(s2,t2, pch="B",col="navyblue", cex=1)
> points(s3,t3, pch="C",col="red", cex=1)
> points(s4,t4, pch="D",col="darkviolet", cex=1)
> points(s5,t5, pch="E",col="blue", cex=1)
> legend("topright",lbels,col=c("orange","green4","navyblue","red","darkviolet","blue"),
> text.col=c("orange","green4","navyblue","red","darkviolet","steelblue"),
> pch=c("v","A","B","C","D","E"),bg='gray100',cex=0.7,box.lty=1,box.lwd=1)
> abline(h = -1:9, v = 0:8, col = "lightgray", lty=3)
> par(op)
> }
>
> # call it with
>
> my.func(x,y,d1,v1,s1,t1,s2,t2,s3,t3,s4,t4,s5,t5)
>
> You might also include the data in a list to make it easier
>
>
>
> On 9/20/07, Tom Cohen wrote:
> > Dear list,
> >
> > I have done a scatter plot of multiple variables in the same graph, with different col and pch. I managed to do it with the following code but not know how to make a function of these so that next time if I want to do similar graph but with new variables, I dont have to copy the code and then change the old variables with the new ones but just call a function with the new variables. I dont have any experience in making a function and would be very grateful if you can help me. A function will shorten my prog dramatically, since I repeat tthis type of graph alots in my analysis.
> >
> > Thanks in advance,
> > Tom
> >
> > op <- par(bg = "grey97")
> > par(mfrow=c(1,2))
> > plot(d1,v1, pch="v", col="orange",cex=0.6, lwd=2,
> > xlab="day", ylab="resp",cex.main =1,font.main= 1,main=" Surv data",ylim=y,xlim=x,
> > col.main="navyblue",col.lab="navyblue",cex.lab=0.7)
> >
> > points(s1,t1, pch="A", col="green4", cex=1)
> > points(s2,t2, pch="B",col="navyblue", cex=1)
> > points(s3,t3, pch="C",col="red", cex=1)
> > points(s4,t4, pch="D",col="darkviolet", cex=1)
> > points(s5,t5, pch="E",col="blue", cex=1)
> > legend("topright",lbels,col=c("orange","green4","navyblue","red","darkviolet","blue"),
> > text.col=c("orange","green4","navyblue","red","darkviolet","steelblue"),
> > pch=c("v","A","B","C","D","E"),bg='gray100',cex=0.7,box.lty=1,box.lwd=1)
> > abline(h = -1:9, v = 0:8, col = "lightgray", lty=3)
> > par(op)
> >
> >
> >
> >
> > ---------------------------------
> >
> > J?mf?r pris p? flygbiljetter och hotellrum: http://shopping.yahoo.se/c-169901-resor-biljetter.html
> > [[alternative HTML version deleted]]
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>
> --
> Jim Holtman
> Cincinnati, OH
> +1 513 646 9390
>
> What is the problem you are trying to solve?
>
>
>
> ---------------------------------
> L?na pengar utan s?kerhet.
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
http://had.co.nz/


From elahehva at yahoo.com  Fri Sep 21 11:36:10 2007
From: elahehva at yahoo.com (elaheh vahidi-asl)
Date: Fri, 21 Sep 2007 02:36:10 -0700 (PDT)
Subject: [R] Would you please tell me about "Parallel  Markov Chains "?
Message-ID: <864669.1524.qm@web58702.mail.re1.yahoo.com>

Hi,
I am a master student of statistics and already working on my thesis, which is related to Markov Chains. In one of the papers I have studied there is an expression of "Parallel Markov Chains", please tell me about it,
                                           Thanks in advance
                                                    Elaheh


       
__________________________________________________________________________________

=list&sid=396545469


From birgit.lemcke at systbot.uzh.ch  Fri Sep 21 14:27:06 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Fri, 21 Sep 2007 14:27:06 +0200
Subject: [R] Ambiguities in vector
In-Reply-To: <46F39103.8050102@stat.auckland.ac.nz>
References: <8FA3D679-C879-4C88-8775-0951FFD99F1D@systbot.uzh.ch>	<12802997.post@talk.nabble.com>
	<AFE3DEF9-1F12-4ACC-B722-98BBB7DC245A@systbot.uzh.ch>
	<46F39103.8050102@stat.auckland.ac.nz>
Message-ID: <3F6F5369-9216-4722-BED6-C4251F6FAB91@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070921/96016fc2/attachment.ksh 

From Dietrich.Trenkler at uni-osnabrueck.de  Fri Sep 21 14:57:27 2007
From: Dietrich.Trenkler at uni-osnabrueck.de (Dietrich Trenkler)
Date: Fri, 21 Sep 2007 14:57:27 +0200
Subject: [R] Error using nls()
Message-ID: <46F3BFB7.2000709@uni-osnabrueck.de>

Hallo HelpeRs,

I try to reconstruct some results from an econometric text book
(Heij et al. (2004), pp. 218-20).

For the data

 > x <- structure(list(q1 = c(345, 331, 320, 314, 299, 395, 415,
    490, 547, 656, 628, 627), d1 = c(1, 1, 1, 1, 1, 1, 1.05,
    1.05, 1.05, 1.15, 1.15, 1.15)), .Names = c("q1", "d1"), row.names = 
as.integer(c(NA,
    12)), class = "data.frame")

I tried to estimate a nonlinear regression model using nls(). I get

 > 
nls(log(q1)~b1+(b2/b3)*(d1^b3-1),data=x,start=list(b1=0,b2=1,b3=1),trace=TRUE)
246.132 :  0.0000  1.0000  1.0000 51.0907
Error in qr.solve(QR.B, cc) : singular matrix 'a' in solve

However, using:

 > jjf <- function(x){z <- log(q1)-x[1]+(x[2]/x[3])*(d1^x[3]-1);sum(z*z)}
 > optim(c(0,1,1),jjf)

rendered (some of) the results desired in a jiffy. What am I doing 
wrong?    

Dietrich

-- 
Dietrich Trenkler c/o Universitaet Osnabrueck 
Rolandstr. 8; D-49069 Osnabrueck, Germany    
email: Dietrich.Trenkler at Uni-Osnabrueck.de


From Ted.Harding at manchester.ac.uk  Fri Sep 21 15:13:32 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Fri, 21 Sep 2007 14:13:32 +0100 (BST)
Subject: [R] A reproducibility puzzle with NORM
Message-ID: <XFMail.070921141332.Ted.Harding@manchester.ac.uk>

Hi Folks,
I'm using the 'norm' package (based on Shafer's NORM)
on some  data. In outline, (X,Y) are bivariate normal,
var(X)=0.29, var(Y)=24.4, cov(X,Y)=-0.277,
there are some 900 cases, and some 170 values of Y
have been set "missing" (NA).

The puzzle is that, repeating the multiple imputation
starting from the same random seed, I get different
answers from the repeats depending if I do an odd number
of imputations, but the same answer on the repeats
if I do en even number (which includes the second
repeat of an odd number).

It may possibly have something to do with how I've
written the code for the loop, but if so then I'm
not seeing it!

CODE:

## Set up the situation:
Data<-read.csv("MyData.csv")
X<-Data$X; Y<-Data$Y
##(If you want to try it, set your own data here)
Raw<-cbind(X,Y)
library(norm)

## Initialise stuff
s<-prelim.norm(Raw)
t0<-em.norm(s)

##########################
## Set the Random Seed
rngseed(31425)

## Do the first imputation:
t     <-  da.norm(s,t0,steps=20)
Imp   <- imp.norm(s,t, Raw)
X.Imp <- Imp[,1]; Y.Imp<-Imp[,2]

## Now do the rest, and accumulate lists of the results
## Est.Imp = list of estimated coeffs
## SE.Imp  = list of SEs of estimated coeffs:
Est.Imp <- list(summary(lm(Y.Imp~X.Imp))$coef[,1])
SE.Imp  <- list(summary(lm(Y.Imp~X.Imp))$coef[,2])
N=4
for(i in (2:N)){
  t<-da.norm(s,t,steps=20)
  Imp<-imp.norm(s,t,Raw)
  X.Imp<-Imp[,1]; Y.Imp<-Imp[,2]
  Est.Imp<-c(Est.Imp,list(summary(lm(Y.Imp~X.Imp))$coef[,1]))
  SE.Imp <-c( SE.Imp,list(summary(lm(Y.Imp~X.Imp))$coef[,2]))
}

## Finally, combine the imputations:
mi.inference(Est.Imp,SE.Imp)


I've illustrated N=4 (even) above, for 4 imputations.

Now, I run the code repeatedly from "## Set the Random Seed"
down to "mi.inference(Est.Imp,SE.Imp)"

With N=4, I always get the same result.

If I set N=5, I alternately get different results:
The second run is different from the first, but the
third is the same as the first, and the fourth is the
same as the second, ...

In general, for even N, it is as for N=4, and for odd N
it is as for N=5.

Any ideas???

Thanks,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 21-Sep-07                                       Time: 14:13:27
------------------------------ XFMail ------------------------------


From murdoch at stats.uwo.ca  Fri Sep 21 15:23:04 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 21 Sep 2007 09:23:04 -0400
Subject: [R] Cutting & pasting help examples into script window
In-Reply-To: <347152339B716A4D893C9A2988EA87C86E8FC1@KFSVS2.utk.tennessee.edu>
References: <347152339B716A4D893C9A2988EA87C86927C6@KFSVS2.utk.tennessee.edu>	<200709201518.11464.stefan.grosse@uni-erfurt.de>	<347152339B716A4D893C9A2988EA87C8692812@KFSVS2.utk.tennessee.edu>	<20070920141641.GA25114@eddelbuettel.com>	<347152339B716A4D893C9A2988EA87C86928FD@KFSVS2.utk.tennessee.edu>	<46F3092B.2080008@stats.uwo.ca>
	<347152339B716A4D893C9A2988EA87C86E8FC1@KFSVS2.utk.tennessee.edu>
Message-ID: <46F3C5B8.4090502@stats.uwo.ca>

On 9/20/2007 9:23 PM, Muenchen, Robert A (Bob) wrote:
> Now I'm working in 2.5.1 on a home machine also running XP. It has the
> same problem, and I think I finally figured it out. 
> 
> I've noticed that if the cursor is directly over the text, it becomes an
> I-beam. When hovering over the blank space around the text, the cursor
> becomes an arrow. Selections via the arrow almost always paste properly
> into a script window. Copies made while selecting with the I-beam cursor
> almost always fail.
> 
> Regardless of how the selection is done, a paste into Notepad never
> fails. Copying from Notepad to a script window never fails, regardless
> of how the paste into Notepad was selected.

I believe this is fixed now.  The problem was that some of the rich text 
formatting was being pasted into the script window; it didn't reformat 
everything to fixed text.  I'm not sure why this resulted in loss of 
line feeds, but fixing it seems to have fixed that too.

This change should make it into 2.6.0.  If you take a look at builds 
starting tomorrow you can test it out.

Duncan Murdoch

> 
> Very strange!
> 
> Bob
> 
> P.S. almost the testing has been with the ?data.frame and ?summary
> examples.
> 
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca]
>> Sent: Thursday, September 20, 2007 7:59 PM
>> To: Muenchen, Robert A (Bob)
>> Cc: r-help at stat.math.ethz.ch
>> Subject: Re: [R] Cutting & pasting help examples into script window
>> 
>> On 20/09/2007 1:49 PM, Muenchen, Robert A (Bob) wrote:
>> > Does this look like a bug? If so, is there a different way to report
>> it?
>> 
>> It sounds like a bug, but I can't reproduce it.  You said it is
>> intermittent on your system.  Can you try to work out the conditions
>> that reliably trigger it?
>> 
>> It might be something specific to your system; does anyone else see
>> this?
>> 
>> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Fri Sep 21 15:28:05 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 21 Sep 2007 09:28:05 -0400
Subject: [R] Error using nls()
In-Reply-To: <46F3BFB7.2000709@uni-osnabrueck.de>
References: <46F3BFB7.2000709@uni-osnabrueck.de>
Message-ID: <971536df0709210628j690732e0l671134cc08aa74e0@mail.gmail.com>

You need better starting values.  Try setting b3=1 and solving using
lm using that result as your starting values in nls:

> cc <- coef(lm(log(q1)~d1,data=x))
> cc <- c(cc, 1)
> names(cc) <- c("b1", "b2", "b3")
> nls(log(q1)~b1+(b2/b3)*(d1^b3-1),data=x,start=cc,trace=TRUE)
225.0784 :  1.515604 4.329543 1.000000
0.1243237 :    5.807118   8.966687 -13.977948
0.08707836 :    5.807118  10.295483 -13.329564
0.08704864 :    5.807118  10.298223 -13.430181
0.08704864 :    5.807118  10.298319 -13.430735
Nonlinear regression model
  model:  log(q1) ~ b1 + (b2/b3) * (d1^b3 - 1)
   data:  x
     b1      b2      b3
  5.807  10.298 -13.431
 residual sum-of-squares: 0.08705

Number of iterations to convergence: 4
Achieved convergence tolerance: 1.27e-09


On 9/21/07, Dietrich Trenkler <Dietrich.Trenkler at uni-osnabrueck.de> wrote:
> Hallo HelpeRs,
>
> I try to reconstruct some results from an econometric text book
> (Heij et al. (2004), pp. 218-20).
>
> For the data
>
>  > x <- structure(list(q1 = c(345, 331, 320, 314, 299, 395, 415,
>    490, 547, 656, 628, 627), d1 = c(1, 1, 1, 1, 1, 1, 1.05,
>    1.05, 1.05, 1.15, 1.15, 1.15)), .Names = c("q1", "d1"), row.names =
> as.integer(c(NA,
>    12)), class = "data.frame")
>
> I tried to estimate a nonlinear regression model using nls(). I get
>
>  >
> nls(log(q1)~b1+(b2/b3)*(d1^b3-1),data=x,start=list(b1=0,b2=1,b3=1),trace=TRUE)
> 246.132 :  0.0000  1.0000  1.0000 51.0907
> Error in qr.solve(QR.B, cc) : singular matrix 'a' in solve
>
> However, using:
>
>  > jjf <- function(x){z <- log(q1)-x[1]+(x[2]/x[3])*(d1^x[3]-1);sum(z*z)}
>  > optim(c(0,1,1),jjf)
>
> rendered (some of) the results desired in a jiffy. What am I doing
> wrong?
>
> Dietrich
>
> --
> Dietrich Trenkler c/o Universitaet Osnabrueck
> Rolandstr. 8; D-49069 Osnabrueck, Germany
> email: Dietrich.Trenkler at Uni-Osnabrueck.de
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Fri Sep 21 15:44:40 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 21 Sep 2007 14:44:40 +0100 (BST)
Subject: [R] A reproducibility puzzle with NORM
In-Reply-To: <XFMail.070921141332.Ted.Harding@manchester.ac.uk>
References: <XFMail.070921141332.Ted.Harding@manchester.ac.uk>
Message-ID: <Pine.LNX.4.64.0709211441140.9976@auk.stats>

Norm uses a Box-Muller normal RNG, and rngseed does not reset its state
(it has some Fortran save variables).  So if you ask for an odd number of 
normals and call rngseed, the next normal 'generated' is the second half 
of the last pair with the previous seed.

Ideally packages should be converted to use R's number generators which do 
not have such quirks.

On Fri, 21 Sep 2007, Ted.Harding at manchester.ac.uk wrote:

> Hi Folks,
> I'm using the 'norm' package (based on Shafer's NORM)
> on some  data. In outline, (X,Y) are bivariate normal,
> var(X)=0.29, var(Y)=24.4, cov(X,Y)=-0.277,
> there are some 900 cases, and some 170 values of Y
> have been set "missing" (NA).
>
> The puzzle is that, repeating the multiple imputation
> starting from the same random seed, I get different
> answers from the repeats depending if I do an odd number
> of imputations, but the same answer on the repeats
> if I do en even number (which includes the second
> repeat of an odd number).
>
> It may possibly have something to do with how I've
> written the code for the loop, but if so then I'm
> not seeing it!
>
> CODE:
>
> ## Set up the situation:
> Data<-read.csv("MyData.csv")
> X<-Data$X; Y<-Data$Y
> ##(If you want to try it, set your own data here)
> Raw<-cbind(X,Y)
> library(norm)
>
> ## Initialise stuff
> s<-prelim.norm(Raw)
> t0<-em.norm(s)
>
> ##########################
> ## Set the Random Seed
> rngseed(31425)
>
> ## Do the first imputation:
> t     <-  da.norm(s,t0,steps=20)
> Imp   <- imp.norm(s,t, Raw)
> X.Imp <- Imp[,1]; Y.Imp<-Imp[,2]
>
> ## Now do the rest, and accumulate lists of the results
> ## Est.Imp = list of estimated coeffs
> ## SE.Imp  = list of SEs of estimated coeffs:
> Est.Imp <- list(summary(lm(Y.Imp~X.Imp))$coef[,1])
> SE.Imp  <- list(summary(lm(Y.Imp~X.Imp))$coef[,2])
> N=4
> for(i in (2:N)){
>  t<-da.norm(s,t,steps=20)
>  Imp<-imp.norm(s,t,Raw)
>  X.Imp<-Imp[,1]; Y.Imp<-Imp[,2]
>  Est.Imp<-c(Est.Imp,list(summary(lm(Y.Imp~X.Imp))$coef[,1]))
>  SE.Imp <-c( SE.Imp,list(summary(lm(Y.Imp~X.Imp))$coef[,2]))
> }
>
> ## Finally, combine the imputations:
> mi.inference(Est.Imp,SE.Imp)
>
>
> I've illustrated N=4 (even) above, for 4 imputations.
>
> Now, I run the code repeatedly from "## Set the Random Seed"
> down to "mi.inference(Est.Imp,SE.Imp)"
>
> With N=4, I always get the same result.
>
> If I set N=5, I alternately get different results:
> The second run is different from the first, but the
> third is the same as the first, and the fourth is the
> same as the second, ...
>
> In general, for even N, it is as for N=4, and for odd N
> it is as for N=5.
>
> Any ideas???
>
> Thanks,
> Ted.
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 21-Sep-07                                       Time: 14:13:27
> ------------------------------ XFMail ------------------------------
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From S.Ellison at lgc.co.uk  Fri Sep 21 15:52:21 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Fri, 21 Sep 2007 14:52:21 +0100
Subject: [R] Importing a dataset
Message-ID: <s6f3dacf.069@tedmail2.lgc.co.uk>

I don't know a short way, but this worked when I tried it. Maybe there's a clue in there somewhere?

 get1<-function(fname, varname) {
 load(fname)
 get(varname)
 }

x<-1
y<-rnorm(3)

save.image("temp.RData")

rm(x)
rm(y)

get1("temp.Rdata","x")

get1("temp.Rdata","y")


Steve E

>>> "Marco Venanzi" <marvena at tin.it> 17/09/2007 12:38:24 >>>
Hi,how can I load a dataset from another file R.Data,without importing all the objects (functions and other datasets) contained in that file?Thanks,  Marco
                                                                                                                                                                                                                             
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code.

*******************************************************************
This email contains information which may be confidential and/or privileged, and is intended only for the individual(s) or organisation(s) named above. If you are not the intended recipient, then please note that any disclosure, copying, distribution or use of the contents of this email is prohibited. Internet communications are not 100% secure and therefore we ask that you acknowledge this. If you have received this email in error, please notify the sender or contact +44(0)20 8943 7000 or postmaster at lgcforensics.com immediately, and delete this email and any attachments and copies from your system. Thank you. 

LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex TW11 0LY, UK

From john.seers at bbsrc.ac.uk  Fri Sep 21 15:55:06 2007
From: john.seers at bbsrc.ac.uk (john seers (IFR))
Date: Fri, 21 Sep 2007 14:55:06 +0100
Subject: [R] how can I attach a variable stored in
In-Reply-To: <46F2C8C1.2040906@cs.nyu.edu>
References: <46F2AE8F.7030303@cs.nyu.edu><D3AEEDA31E57474B840BEBC25A8A834401957B1F@NYWEXMB23.msad.ms.com>
	<46F2C8C1.2040906@cs.nyu.edu>
Message-ID: <AAD49F46EAE3F6479E1D46428FAC31CB025163FF@NBIE2KSRV1.nbi.bbsrc.ac.uk>



Hi Peter

Perhaps "get" is what you need?

    foo.bar <- list( "a"= "a", "b"=1 )
    save( file="foo.bar.RData", foo.bar )
    rm( foo.bar )

    my.fn <- function( fname ) {
       load( fname )
        attach( get(ls( pat="foo" )) ) #  works
         #attach( foo.bar )  # works
    } 

Regards

JS


 -----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Peter Waltman
Sent: 20 September 2007 20:24
To: Leeds, Mark (IED)
Cc: r-help at r-project.org
Subject: Re: [R] how can I attach a variable stored in

Hi Mark -

Thanks for the reply.  Sorry I didn't really clarify too well what I'm
trying to do.  The issue is not that I can't see the variable that gets
loaded. 

The issue is that the variable is a list variable, and I'd like to write
a function that will take the .RData filename and attach the variable it
contains so that I can more easily access its contents, i.e.

    foo.bar <- list( "a"= "a", "b"=1 )
    save( file="foo.bar.RData", foo.bar )
    rm( foo.bar )

    my.fn <- function( fname ) {
       load( fname )
       attach( ls( pat="foo" ) ) #  I want to attach( foo.bar ), but
    this doesn't work
    }

    ls()  # prints out "foo.bar"

    attach( ls( ) )   # still doesn't work
    attach( foo.bar )  # works

So, basically, the question is how can I attach the variable that's
stored in a file if I don't already know it's name?

Thanks again!

Peter


From csardi at rmki.kfki.hu  Fri Sep 21 16:01:40 2007
From: csardi at rmki.kfki.hu (Gabor Csardi)
Date: Fri, 21 Sep 2007 16:01:40 +0200
Subject: [R] Importing a dataset
In-Reply-To: <s6f3dacf.069@tedmail2.lgc.co.uk>
References: <s6f3dacf.069@tedmail2.lgc.co.uk>
Message-ID: <20070921140140.GA5609@localdomain>

I don't know a way of loading parts of an .RData file either,
but another solution is to use the envir argument of load to
load the data into a new environment:

> x <- 1
> y <- rnorm(3)
> save.image("tmp.RData")
> rm(x)
> rm(y)
> load("tmp.RData", env <- new.env())
> get("x", env)
[1] 1
> get("y", env)
[1] -0.1105102  0.6923334  1.5506114
> rm(env)

Gabor

On Fri, Sep 21, 2007 at 02:52:21PM +0100, S Ellison wrote:
> I don't know a short way, but this worked when I tried it. Maybe there's a clue in there somewhere?
> 
>  get1<-function(fname, varname) {
>  load(fname)
>  get(varname)
>  }
> 
> x<-1
> y<-rnorm(3)
> 
> save.image("temp.RData")
> 
> rm(x)
> rm(y)
> 
> get1("temp.Rdata","x")
> 
> get1("temp.Rdata","y")
> 
> 
> Steve E
> 
> >>> "Marco Venanzi" <marvena at tin.it> 17/09/2007 12:38:24 >>>
> Hi,how can I load a dataset from another file R.Data,without importing all the objects (functions and other datasets) contained in that file?Thanks,  Marco
>                                                                                                                                                                                                                              
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.
> 
> *******************************************************************
> This email contains information which may be confidential and/or privileged, and is intended only for the individual(s) or organisation(s) named above. If you are not the intended recipient, then please note that any disclosure, copying, distribution or use of the contents of this email is prohibited. Internet communications are not 100% secure and therefore we ask that you acknowledge this. If you have received this email in error, please notify the sender or contact +44(0)20 8943 7000 or postmaster at lgcforensics.com immediately, and delete this email and any attachments and copies from your system. Thank you. 
> 
> LGC Limited. Registered in England 2991879. 
> Registered office: Queens Road, Teddington, Middlesex TW11 0LY, UK
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK


From chris.elsaesser at spadac.com  Fri Sep 21 16:08:24 2007
From: chris.elsaesser at spadac.com (Chris Elsaesser)
Date: Fri, 21 Sep 2007 10:08:24 -0400
Subject: [R] Likelihood ration test on glm
Message-ID: <04C44D9F040C8A43A18D04F65A8B68BBE92316@spatcex001.spadac.com>

I would like to try a likelihood ratio test in place of waldtest.
Ideally I'd like to provide two glm models, the second a submodel of the
first, in the style of lrt
(http://www.pik-potsdam.de/~hrust/tools/farismahelp/lrt.html). [lrt
takes farimsa objects]

Does anyone know of such a likelihood ratio test?


Chris Elsaesser, PhD        
Principal Scientist, Machine Learning
SPADAC Inc.
7921 Jones Branch Dr. Suite 600  
McLean, VA 22102  

703.371.7301 (m)
703.637.9421 (o)          


From Ted.Harding at manchester.ac.uk  Fri Sep 21 16:12:30 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Fri, 21 Sep 2007 15:12:30 +0100 (BST)
Subject: [R] A reproducibility puzzle with NORM
In-Reply-To: <Pine.LNX.4.64.0709211441140.9976@auk.stats>
Message-ID: <XFMail.070921151230.Ted.Harding@manchester.ac.uk>

On 21-Sep-07 13:44:40, Prof Brian Ripley wrote:
> Norm uses a Box-Muller normal RNG, and rngseed does not reset
> its state (it has some Fortran save variables).  So if you ask
> for an odd number of normals and call rngseed, the next normal
> 'generated' is the second half of the last pair with the
> previous seed.
> 
> Ideally packages should be converted to use R's number generators
> which do not have such quirks.

Many thanks! That is indeed a deeply hidden quirk.
(It should be documented!)

Presumably it applies also to 'mix'? I'm even wondering if
it might apply to 'cat' (which I'm supposed to be a maintainer
of); in principle it should not, since there's no unavoidable
necessity to use normal RNs there, hence no need for a
Box-Muller RNG; but one never knows. I'd better look!

Trying to think of a work-round for immediate purposes,
but there seems to be nothing obvious which would avoid
the problem (e.g. testing for odd/even in number of
imputations), since one cannot be sure of how many normal
RNs have been called for during the DA and Imputation
steps.

Maybe one can add a bit of code to rngseed() to administer
a salutary kick to something.

Thanks!
Ted.

> 
> On Fri, 21 Sep 2007, Ted.Harding at manchester.ac.uk wrote:
> 
>> Hi Folks,
>> I'm using the 'norm' package (based on Shafer's NORM)
>> on some  data. In outline, (X,Y) are bivariate normal,
>> var(X)=0.29, var(Y)=24.4, cov(X,Y)=-0.277,
>> there are some 900 cases, and some 170 values of Y
>> have been set "missing" (NA).
>>
>> The puzzle is that, repeating the multiple imputation
>> starting from the same random seed, I get different
>> answers from the repeats depending if I do an odd number
>> of imputations, but the same answer on the repeats
>> if I do en even number (which includes the second
>> repeat of an odd number).
>>
>> It may possibly have something to do with how I've
>> written the code for the loop, but if so then I'm
>> not seeing it!
>>
>> CODE:
>>
>> ## Set up the situation:
>> Data<-read.csv("MyData.csv")
>> X<-Data$X; Y<-Data$Y
>> ##(If you want to try it, set your own data here)
>> Raw<-cbind(X,Y)
>> library(norm)
>>
>> ## Initialise stuff
>> s<-prelim.norm(Raw)
>> t0<-em.norm(s)
>>
>> ##########################
>> ## Set the Random Seed
>> rngseed(31425)
>>
>> ## Do the first imputation:
>> t     <-  da.norm(s,t0,steps=20)
>> Imp   <- imp.norm(s,t, Raw)
>> X.Imp <- Imp[,1]; Y.Imp<-Imp[,2]
>>
>> ## Now do the rest, and accumulate lists of the results
>> ## Est.Imp = list of estimated coeffs
>> ## SE.Imp  = list of SEs of estimated coeffs:
>> Est.Imp <- list(summary(lm(Y.Imp~X.Imp))$coef[,1])
>> SE.Imp  <- list(summary(lm(Y.Imp~X.Imp))$coef[,2])
>> N=4
>> for(i in (2:N)){
>>  t<-da.norm(s,t,steps=20)
>>  Imp<-imp.norm(s,t,Raw)
>>  X.Imp<-Imp[,1]; Y.Imp<-Imp[,2]
>>  Est.Imp<-c(Est.Imp,list(summary(lm(Y.Imp~X.Imp))$coef[,1]))
>>  SE.Imp <-c( SE.Imp,list(summary(lm(Y.Imp~X.Imp))$coef[,2]))
>> }
>>
>> ## Finally, combine the imputations:
>> mi.inference(Est.Imp,SE.Imp)
>>
>>
>> I've illustrated N=4 (even) above, for 4 imputations.
>>
>> Now, I run the code repeatedly from "## Set the Random Seed"
>> down to "mi.inference(Est.Imp,SE.Imp)"
>>
>> With N=4, I always get the same result.
>>
>> If I set N=5, I alternately get different results:
>> The second run is different from the first, but the
>> third is the same as the first, and the fourth is the
>> same as the second, ...
>>
>> In general, for even N, it is as for N=4, and for odd N
>> it is as for N=5.
>>
>> Any ideas???
>>
>> Thanks,
>> Ted.
>>
>> --------------------------------------------------------------------
>> E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
>> Fax-to-email: +44 (0)870 094 0861
>> Date: 21-Sep-07                                       Time: 14:13:27
>> ------------------------------ XFMail ------------------------------
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 21-Sep-07                                       Time: 15:12:27
------------------------------ XFMail ------------------------------


From kevin.thorpe at utoronto.ca  Fri Sep 21 16:28:54 2007
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 21 Sep 2007 10:28:54 -0400
Subject: [R] Likelihood ration test on glm
In-Reply-To: <04C44D9F040C8A43A18D04F65A8B68BBE92316@spatcex001.spadac.com>
References: <04C44D9F040C8A43A18D04F65A8B68BBE92316@spatcex001.spadac.com>
Message-ID: <46F3D526.6000600@utoronto.ca>

Chris Elsaesser wrote:
> I would like to try a likelihood ratio test in place of waldtest.
> Ideally I'd like to provide two glm models, the second a submodel of the
> first, in the style of lrt
> (http://www.pik-potsdam.de/~hrust/tools/farismahelp/lrt.html). [lrt
> takes farimsa objects]
> 
> Does anyone know of such a likelihood ratio test?
> 
> 

I think anova(model1,model2,test="Chi") will do what you want.

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Department of Public Health Sciences
Faculty of Medicine, University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.6057


From stenka1 at go.com  Fri Sep 21 17:02:53 2007
From: stenka1 at go.com (stephen bond)
Date: Fri, 21 Sep 2007 15:02:53 +0000 (UTC)
Subject: [R] text formatting
Message-ID: <7195839.1190386973350.JavaMail.?@fh122.dia.he.tucows.com>

Dear all,

Does R have any functions for C/Fortran style text formatting when a 
number needs to be output right-justified in a fixed length field?

say '%2d %3d %5.3f' 

or like python .rjust(n)  and .zfill(n)

I can do it paste(), but it is very clumsy.

Thank you very much
Stephen


From Soren.Hojsgaard at agrsci.dk  Fri Sep 21 17:06:46 2007
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Fri, 21 Sep 2007 17:06:46 +0200
Subject: [R] text formatting
In-Reply-To: <7195839.1190386973350.JavaMail.?@fh122.dia.he.tucows.com>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC01AACF15@DJFPOST01.djf.agrsci.dk>

?sprintf might be what you want...
/S?ren

-----Oprindelig meddelelse-----
Fra: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]P? vegne af stephen bond
Sendt: 21. september 2007 17:03
Til: r-help at r-project.org
Emne: [R] text formatting


Dear all,

Does R have any functions for C/Fortran style text formatting when a 
number needs to be output right-justified in a fixed length field?

say '%2d %3d %5.3f' 

or like python .rjust(n)  and .zfill(n)

I can do it paste(), but it is very clumsy.

Thank you very much
Stephen

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From faheem at email.unc.edu  Fri Sep 21 17:24:12 2007
From: faheem at email.unc.edu (Faheem Mitha)
Date: Fri, 21 Sep 2007 11:24:12 -0400 (EDT)
Subject: [R] truncating a data frame based on a function
Message-ID: <Pine.LNX.4.64.0709201506530.14707@orwell.homelinux.org>


Hi,

Consider the following example.

> a = c(1,2,3); b = c(4,5,6); c = cbind(a,b); c[(2 < c[,1]) & (c[,1] < 4),]

a b
3 6

So, the idea is to select rows for which the value in the first column is 
between 2 and 4. This works, however, I don't like having to reference a 
explicitly in this fashion, and just wondered if there was a preferred way 
to accomplish the same thing. Ideally, I'd like to make use of a function.

                                                            Thanks, Faheem.


From reeves at nceas.ucsb.edu  Fri Sep 21 17:30:58 2007
From: reeves at nceas.ucsb.edu (Rick Reeves)
Date: Fri, 21 Sep 2007 08:30:58 -0700
Subject: [R] This site provided an excellent answer to my raster / vector
 plot question
Message-ID: <46F3E3B2.5070703@nceas.ucsb.edu>

I can recommend it highly, esp for those of us in the geo spatial realm: 

http://casoilresource.lawr.ucdavis.edu/drupal/node/442

Thanks do Dylan for answering...

RR 

-- 
Rick Reeves	
Scientific Programmer / Analyst	
National Center for Ecological Analysis and Synthesis
UC Santa Barbara
reeves at nceas.ucsb.edu
www.nceas.ucsb.edu
805 892 2533


From ripley at stats.ox.ac.uk  Fri Sep 21 17:57:44 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 21 Sep 2007 16:57:44 +0100 (BST)
Subject: [R] A reproducibility puzzle with NORM
In-Reply-To: <XFMail.070921151230.Ted.Harding@manchester.ac.uk>
References: <XFMail.070921151230.Ted.Harding@manchester.ac.uk>
Message-ID: <Pine.LNX.4.64.0709211646490.16004@gannet.stats.ox.ac.uk>

On Fri, 21 Sep 2007, Ted.Harding at manchester.ac.uk wrote:

> On 21-Sep-07 13:44:40, Prof Brian Ripley wrote:
>> Norm uses a Box-Muller normal RNG, and rngseed does not reset
>> its state (it has some Fortran save variables).  So if you ask
>> for an odd number of normals and call rngseed, the next normal
>> 'generated' is the second half of the last pair with the
>> previous seed.
>>
>> Ideally packages should be converted to use R's number generators
>> which do not have such quirks.
>
> Many thanks! That is indeed a deeply hidden quirk.
> (It should be documented!)
>
> Presumably it applies also to 'mix'? I'm even wondering if
> it might apply to 'cat' (which I'm supposed to be a maintainer
> of); in principle it should not, since there's no unavoidable
> necessity to use normal RNs there, hence no need for a
> Box-Muller RNG; but one never knows. I'd better look!
>
> Trying to think of a work-round for immediate purposes,
> but there seems to be nothing obvious which would avoid
> the problem (e.g. testing for odd/even in number of
> imputations), since one cannot be sure of how many normal
> RNs have been called for during the DA and Imputation
> steps.
>
> Maybe one can add a bit of code to rngseed() to administer
> a salutary kick to something.

Unfortunately not, as the variable is stored internally to another Fortran 
function and so not accessible to rngseed.  It's easy in C to have static 
variables shared between functions, which is how R solves this.

I only put package mix together to meet the needs of one of my students, 
and put it on CRAN when someone else asked for it.  If I had an ongoing 
need for it I would certainly make it a lot more robust.


>
> Thanks!
> Ted.
>
>>
>> On Fri, 21 Sep 2007, Ted.Harding at manchester.ac.uk wrote:
>>
>>> Hi Folks,
>>> I'm using the 'norm' package (based on Shafer's NORM)
>>> on some  data. In outline, (X,Y) are bivariate normal,
>>> var(X)=0.29, var(Y)=24.4, cov(X,Y)=-0.277,
>>> there are some 900 cases, and some 170 values of Y
>>> have been set "missing" (NA).
>>>
>>> The puzzle is that, repeating the multiple imputation
>>> starting from the same random seed, I get different
>>> answers from the repeats depending if I do an odd number
>>> of imputations, but the same answer on the repeats
>>> if I do en even number (which includes the second
>>> repeat of an odd number).
>>>
>>> It may possibly have something to do with how I've
>>> written the code for the loop, but if so then I'm
>>> not seeing it!
>>>
>>> CODE:
>>>
>>> ## Set up the situation:
>>> Data<-read.csv("MyData.csv")
>>> X<-Data$X; Y<-Data$Y
>>> ##(If you want to try it, set your own data here)
>>> Raw<-cbind(X,Y)
>>> library(norm)
>>>
>>> ## Initialise stuff
>>> s<-prelim.norm(Raw)
>>> t0<-em.norm(s)
>>>
>>> ##########################
>>> ## Set the Random Seed
>>> rngseed(31425)
>>>
>>> ## Do the first imputation:
>>> t     <-  da.norm(s,t0,steps=20)
>>> Imp   <- imp.norm(s,t, Raw)
>>> X.Imp <- Imp[,1]; Y.Imp<-Imp[,2]
>>>
>>> ## Now do the rest, and accumulate lists of the results
>>> ## Est.Imp = list of estimated coeffs
>>> ## SE.Imp  = list of SEs of estimated coeffs:
>>> Est.Imp <- list(summary(lm(Y.Imp~X.Imp))$coef[,1])
>>> SE.Imp  <- list(summary(lm(Y.Imp~X.Imp))$coef[,2])
>>> N=4
>>> for(i in (2:N)){
>>>  t<-da.norm(s,t,steps=20)
>>>  Imp<-imp.norm(s,t,Raw)
>>>  X.Imp<-Imp[,1]; Y.Imp<-Imp[,2]
>>>  Est.Imp<-c(Est.Imp,list(summary(lm(Y.Imp~X.Imp))$coef[,1]))
>>>  SE.Imp <-c( SE.Imp,list(summary(lm(Y.Imp~X.Imp))$coef[,2]))
>>> }
>>>
>>> ## Finally, combine the imputations:
>>> mi.inference(Est.Imp,SE.Imp)
>>>
>>>
>>> I've illustrated N=4 (even) above, for 4 imputations.
>>>
>>> Now, I run the code repeatedly from "## Set the Random Seed"
>>> down to "mi.inference(Est.Imp,SE.Imp)"
>>>
>>> With N=4, I always get the same result.
>>>
>>> If I set N=5, I alternately get different results:
>>> The second run is different from the first, but the
>>> third is the same as the first, and the fourth is the
>>> same as the second, ...
>>>
>>> In general, for even N, it is as for N=4, and for odd N
>>> it is as for N=5.
>>>
>>> Any ideas???
>>>
>>> Thanks,
>>> Ted.
>>>
>>> --------------------------------------------------------------------
>>> E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
>>> Fax-to-email: +44 (0)870 094 0861
>>> Date: 21-Sep-07                                       Time: 14:13:27
>>> ------------------------------ XFMail ------------------------------
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 21-Sep-07                                       Time: 15:12:27
> ------------------------------ XFMail ------------------------------
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Greg.Snow at intermountainmail.org  Fri Sep 21 17:58:41 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 21 Sep 2007 09:58:41 -0600
Subject: [R] Estimate correlation with bootstrap
In-Reply-To: <587248.1680.qm@web30610.mail.mud.yahoo.com>
References: <587248.1680.qm@web30610.mail.mud.yahoo.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBF9C8D@LP-EXCHVS07.CO.IHC.COM>

Try this:

a <- c(1,2,3,4,5,6,7,8,9,10)
b <- c(1,1,56,3,6,6,6,7,2,10)

n <- length(a)

boot.cor.a.b <- replicate( 1000, {tmp <- sample(n, replace=TRUE);
cor(a[tmp],b[tmp]) } )

hist(boot.cor.a.b)
abline( v=c( mean(boot.cor.a.b), median(boot.cor.a.b) ),
col=c('blue','green'))


Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Andreas Klein
> Sent: Thursday, September 20, 2007 11:59 PM
> To: r-help at r-project.org
> Subject: [R] Estimate correlation with bootstrap
> 
> Hello.
> 
> I would like to estimate the correlation coefficient from two 
> samples with Bootstrapping using the R-function sample().
> 
> The problem is, that I have to sample pairwise. For example 
> if I have got two time series and I draw from the first 
> series the value from 1912 I need the value from 1912 from 
> the second sample, too.
> 
> Example:
> 
> Imagine that a and b are two time series with returns for example: 
> 
> a <- c(1,2,3,4,5,6,7,8,9,10)
> b <- c(1,1,56,3,6,6,6,7,2,10)
> 
> a.sample     <- numeric(10)
> b.sample     <- numeric(10)
> boot.cor.a.b <- numeric(1000)
> 
> for (i in 1:1000)
> 
> {
> 
>  for (j in 1:10)
> 
>  {
> 
>   a.sample[j] <- sample(a,1,replace=TRUE)
>   b.sample[j] <- sample(b,1,replace=TRUE)
> 
>  }
> 
>  boot.cor.a.b[i] <- cor(a,b)
> 
> }
> 
> The problem here is, that the sampling is independent from each other.
> 
> So how do I have to change the R-code to get the pairwise 
> sampling mentioned above?
> 
> I hope you can help me.
> 
> Sincerely
> Klein.
> 
> 
>       ________
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From cooch17 at verizon.net  Fri Sep 21 18:00:23 2007
From: cooch17 at verizon.net (Evan Cooch)
Date: Fri, 21 Sep 2007 12:00:23 -0400
Subject: [R] really dumb question | loop counters in 
Message-ID: <46F3EA97.8020708@verizon.net>

Basically new to [R] - as a programming environment at least (had lots 
of recent experience compiling it on our Opteron-based servers). Was 
trying to write some simple little scripts (in advance of porting over 
some bigger things from other environments - like MATLAB), when I 
realized that handling counters in loop constructs in [R] is not 
patently obvious (at least, IMO, compared to other languages).

Suppose I want to iterate something from 1 to 100, using a step size of 
(say) 5. Trying the obvious

for(x in 1:5:100) {
print(x)
}

(Perhaps obviously, I've borrowed the MATLAB convention to some degree).

Or, looping from 0 -> 1 by 0.01?

I've dug through what [R] documentation I have, and all I can find is 
the somewhat obtuse.

For example, I can use

x <- seq(0,1, by=.01)

But not

for(x in (0,1,by=0.01)) {
print(x)
}

What about things that are slickly handled in C++, like

for (node=start; value<threshold && node!=end; node=node->next) { ... }


OK - I'm stumped (and happy to humiliate myself with what has surely got 
to be trivial).  I'm happy with a simple basic counter at this point.


From GPetris at uark.edu  Fri Sep 21 18:16:51 2007
From: GPetris at uark.edu (Giovanni Petris)
Date: Fri, 21 Sep 2007 11:16:51 -0500 (CDT)
Subject: [R] getAnywhere
Message-ID: <200709211616.l8LGGpBm007581@definetti.ddns.uark.edu>


Hello,

How can I see a function called "+.dlm"?

> methods("+")
[1] +.Date   +.dlm*   +.POSIXt

   Non-visible functions are asterisked
> getAnywhere("+.dlm")
Error in grep(pattern, x, ignore.case, extended, value, fixed, useBytes) : 
	invalid regular expression '+\.dlm'

Thanks in advance,
Giovanni

-- 

Giovanni Petris  <GPetris at uark.edu>
Department of Mathematical Sciences
University of Arkansas - Fayetteville, AR 72701
Ph: (479) 575-6324, 575-8630 (fax)
http://definetti.uark.edu/~gpetris/


From Greg.Snow at intermountainmail.org  Fri Sep 21 18:17:20 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 21 Sep 2007 10:17:20 -0600
Subject: [R] truncating a data frame based on a function
In-Reply-To: <Pine.LNX.4.64.0709201506530.14707@orwell.homelinux.org>
References: <Pine.LNX.4.64.0709201506530.14707@orwell.homelinux.org>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBF9CAB@LP-EXCHVS07.CO.IHC.COM>

Look at the subset function (?subset), it may do what you want.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Faheem Mitha
> Sent: Friday, September 21, 2007 9:24 AM
> To: r-help at r-project.org
> Subject: [R] truncating a data frame based on a function
> 
> 
> Hi,
> 
> Consider the following example.
> 
> > a = c(1,2,3); b = c(4,5,6); c = cbind(a,b); c[(2 < c[,1]) & 
> (c[,1] < 
> > 4),]
> 
> a b
> 3 6
> 
> So, the idea is to select rows for which the value in the 
> first column is between 2 and 4. This works, however, I don't 
> like having to reference a explicitly in this fashion, and 
> just wondered if there was a preferred way to accomplish the 
> same thing. Ideally, I'd like to make use of a function.
> 
>                                                             
> Thanks, Faheem.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From p.hiemstra at geo.uu.nl  Fri Sep 21 18:22:48 2007
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Fri, 21 Sep 2007 18:22:48 +0200
Subject: [R] really dumb question | loop counters in
In-Reply-To: <46F3EA97.8020708@verizon.net>
References: <46F3EA97.8020708@verizon.net>
Message-ID: <46F3EFD8.2010703@geo.uu.nl>

Hi,

This works:

for(i in seq(1,100,5)) {
print(i)
}

Very similar to the way python does this kind of loop.

Paul

Evan Cooch schreef:
> Basically new to [R] - as a programming environment at least (had lots 
> of recent experience compiling it on our Opteron-based servers). Was 
> trying to write some simple little scripts (in advance of porting over 
> some bigger things from other environments - like MATLAB), when I 
> realized that handling counters in loop constructs in [R] is not 
> patently obvious (at least, IMO, compared to other languages).
>
> Suppose I want to iterate something from 1 to 100, using a step size of 
> (say) 5. Trying the obvious
>
> for(x in 1:5:100) {
> print(x)
> }
>
> (Perhaps obviously, I've borrowed the MATLAB convention to some degree).
>
> Or, looping from 0 -> 1 by 0.01?
>
> I've dug through what [R] documentation I have, and all I can find is 
> the somewhat obtuse.
>
> For example, I can use
>
> x <- seq(0,1, by=.01)
>
> But not
>
> for(x in (0,1,by=0.01)) {
> print(x)
> }
>
> What about things that are slickly handled in C++, like
>
> for (node=start; value<threshold && node!=end; node=node->next) { ... }
>
>
> OK - I'm stumped (and happy to humiliate myself with what has surely got 
> to be trivial).  I'm happy with a simple basic counter at this point.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:     +31302535773
Fax:    +31302531145
http://intamap.geo.uu.nl/~paul


From Greg.Snow at intermountainmail.org  Fri Sep 21 18:24:23 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 21 Sep 2007 10:24:23 -0600
Subject: [R] really dumb question | loop counters in
In-Reply-To: <46F3EA97.8020708@verizon.net>
References: <46F3EA97.8020708@verizon.net>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBF9CB3@LP-EXCHVS07.CO.IHC.COM>

Try:

for(x in seq(0,1,by=0.01)) {
print(x)
}

The for loop in S/R is what some languages call a foreach loop, you need
to provide a vector of the values to loop over.

If you really want a C style for loop, then just realize that the for
loop is a shorthand while loop:

x <- 0
while( x < 1 ) {
  print(x)
  x <- x + 0.01
}

Hope this helps,


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Evan Cooch
> Sent: Friday, September 21, 2007 10:00 AM
> To: r-help at r-project.org
> Subject: [R] really dumb question | loop counters in 
> 
> Basically new to [R] - as a programming environment at least 
> (had lots of recent experience compiling it on our 
> Opteron-based servers). Was trying to write some simple 
> little scripts (in advance of porting over some bigger things 
> from other environments - like MATLAB), when I realized that 
> handling counters in loop constructs in [R] is not patently 
> obvious (at least, IMO, compared to other languages).
> 
> Suppose I want to iterate something from 1 to 100, using a 
> step size of
> (say) 5. Trying the obvious
> 
> for(x in 1:5:100) {
> print(x)
> }
> 
> (Perhaps obviously, I've borrowed the MATLAB convention to 
> some degree).
> 
> Or, looping from 0 -> 1 by 0.01?
> 
> I've dug through what [R] documentation I have, and all I can 
> find is the somewhat obtuse.
> 
> For example, I can use
> 
> x <- seq(0,1, by=.01)
> 
> But not
> 
> for(x in (0,1,by=0.01)) {
> print(x)
> }
> 
> What about things that are slickly handled in C++, like
> 
> for (node=start; value<threshold && node!=end; 
> node=node->next) { ... }
> 
> 
> OK - I'm stumped (and happy to humiliate myself with what has 
> surely got to be trivial).  I'm happy with a simple basic 
> counter at this point.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From jmburgos at u.washington.edu  Fri Sep 21 18:24:59 2007
From: jmburgos at u.washington.edu (Julian Burgos)
Date: Fri, 21 Sep 2007 09:24:59 -0700
Subject: [R] Estimate correlation with bootstrap
In-Reply-To: <587248.1680.qm@web30610.mail.mud.yahoo.com>
References: <587248.1680.qm@web30610.mail.mud.yahoo.com>
Message-ID: <46F3F05B.5040304@u.washington.edu>

Hi Andreas,

Simply use one call to the sample function.

Try this:

a <- c(1,2,3,4,5,6,7,8,9,10)
b <- c(1,1,56,3,6,6,6,7,2,10)
boot.cor.a.b <- numeric(1000)

for (i in 1:1000){
x=sample(10,replace=T)
boot.cor.a.b[i]=cor(a[x],b[x])
}


Note that in R you don't need to initialize the variables like in other 
languages.

Another option is to use the boot() function directly.  See ?boot.

Julian


Andreas Klein wrote:
> Hello.
>
> I would like to estimate the correlation coefficient
> from two samples with Bootstrapping using the
> R-function sample().
>
> The problem is, that I have to sample pairwise. For
> example if I have got two time series and I draw from
> the first series the value from 1912 I need the value
> from 1912 from the second sample, too.
>
> Example:
>
> Imagine that a and b are two time series with returns
> for example: 
>
> a <- c(1,2,3,4,5,6,7,8,9,10)
> b <- c(1,1,56,3,6,6,6,7,2,10)
>
> a.sample     <- numeric(10)
> b.sample     <- numeric(10)
> boot.cor.a.b <- numeric(1000)
>
> for (i in 1:1000)
>
> {
>
>  for (j in 1:10)
>
>  {
>
>   a.sample[j] <- sample(a,1,replace=TRUE)
>   b.sample[j] <- sample(b,1,replace=TRUE)
>
>  }
>
>  boot.cor.a.b[i] <- cor(a,b)
>
> }
>
> The problem here is, that the sampling is independent
> from each other.
>
> So how do I have to change the R-code to get the
> pairwise sampling mentioned above?
>
> I hope you can help me.
>
> Sincerely
> Klein.
>
>
>       ________
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>   

-- 
Julian M. Burgos

Fisheries Acoustics Research Lab
School of Aquatic and Fishery Science
University of Washington

1122 NE Boat Street
Seattle, WA  98105 

Phone: 206-221-6864


From liuwensui at gmail.com  Fri Sep 21 18:33:30 2007
From: liuwensui at gmail.com (Wensui Liu)
Date: Fri, 21 Sep 2007 12:33:30 -0400
Subject: [R] Likelihood ration test on glm
In-Reply-To: <04C44D9F040C8A43A18D04F65A8B68BBE92316@spatcex001.spadac.com>
References: <04C44D9F040C8A43A18D04F65A8B68BBE92316@spatcex001.spadac.com>
Message-ID: <1115a2b00709210933if488ccbl52ec6920671828a0@mail.gmail.com>

chris,
as long as you know the log likelihood functions and the # of
parameters in both models, a pencil and a piece of paper should be
enough to calculate LR test.

On 9/21/07, Chris Elsaesser <chris.elsaesser at spadac.com> wrote:
> I would like to try a likelihood ratio test in place of waldtest.
> Ideally I'd like to provide two glm models, the second a submodel of the
> first, in the style of lrt
> (http://www.pik-potsdam.de/~hrust/tools/farismahelp/lrt.html). [lrt
> takes farimsa objects]
>
> Does anyone know of such a likelihood ratio test?
>
>
> Chris Elsaesser, PhD
> Principal Scientist, Machine Learning
> SPADAC Inc.
> 7921 Jones Branch Dr. Suite 600
> McLean, VA 22102
>
> 703.371.7301 (m)
> 703.637.9421 (o)
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
===============================
"I am dying with the help of too many
physicians." - Alexander the Great, on his deathbed
===============================
WenSui Liu
(http://spaces.msn.com/statcompute/blog)


From topkatz at msn.com  Fri Sep 21 18:38:05 2007
From: topkatz at msn.com (Talbot Katz)
Date: Fri, 21 Sep 2007 12:38:05 -0400
Subject: [R] Is it solve.QP or is it me?
Message-ID: <BAY108-F30469D46D795D6D8E3B9F7AABB0@phx.gbl>

Hi.

Here are three successive examples of simple quadratic programming problems 
with the same structure.  Each problem has 2*N variables, and should have a 
solution of the form (1/N,0,1/N,0,...,1/N,0).  In these cases, N=4,5,6.  As 
you will see, the N=4 and 6 cases give the expected solution, but the N=5 
case breaks down.


>cm8
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
[1,]    1    0    0    0    0    0    0    0
[2,]    0    1    0    0    0    0    0    0
[3,]    0    0    1    0    0    0    0    0
[4,]    0    0    0    1    0    0    0    0
[5,]    0    0    0    0    1    0    0    0
[6,]    0    0    0    0    0    1    0    0
[7,]    0    0    0    0    0    0    1    0
[8,]    0    0    0    0    0    0    0    1
>dv8
[1] 0 0 0 0 0 0 0 0
>Am8
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,]    1 1 -1 0  0 0  0 0  0 0
[2,]   -1 1  0 1  0 0  0 0  0 0
[3,]    1 1  0 0 -1 0  0 0  0 0
[4,]   -1 1  0 0  0 1  0 0  0 0
[5,]    1 1  0 0  0 0 -1 0  0 0
[6,]   -1 1  0 0  0 0  0 1  0 0
[7,]    1 1  0 0  0 0  0 0 -1 0
[8,]   -1 1  0 0  0 0  0 0  0 1
>bv8
[1]  1  1 -1  0 -1  0 -1  0 -1  0
>meq
[1] 2
>liSM8<-solve.QP(cm8,dv8,Am8,bv8,meq)
>liSM8$solution
[1] 2.500000e-01 2.858899e-53 2.500000e-01 0.000000e+00 2.500000e-01 
0.000000e+00 2.500000e-01 1.387779e-17
>cma
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,]    1    0    0    0    0    0    0    0    0     0
[2,]    0    1    0    0    0    0    0    0    0     0
[3,]    0    0    1    0    0    0    0    0    0     0
[4,]    0    0    0    1    0    0    0    0    0     0
[5,]    0    0    0    0    1    0    0    0    0     0
[6,]    0    0    0    0    0    1    0    0    0     0
[7,]    0    0    0    0    0    0    1    0    0     0
[8,]    0    0    0    0    0    0    0    1    0     0
[9,]    0    0    0    0    0    0    0    0    1     0
[10,]    0    0    0    0    0    0    0    0    0     1
>dva
[1] 0 0 0 0 0 0 0 0 0 0
>Ama
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
[1,]    1 1 -1 0  0 0  0 0  0 0  0 0
[2,]   -1 1  0 1  0 0  0 0  0 0  0 0
[3,]    1 1  0 0 -1 0  0 0  0 0  0 0
[4,]   -1 1  0 0  0 1  0 0  0 0  0 0
[5,]    1 1  0 0  0 0 -1 0  0 0  0 0
[6,]   -1 1  0 0  0 0  0 1  0 0  0 0
[7,]    1 1  0 0  0 0  0 0 -1 0  0 0
[8,]   -1 1  0 0  0 0  0 0  0 1  0 0
[9,]    1 1  0 0  0 0  0 0  0 0 -1 0
[10,]   -1 1  0 0  0 0  0 0  0 0  0 1
>bva
[1]  1  1 -1  0 -1  0 -1  0 -1  0 -1  0
>meq
[1] 2
>liSMa<-solve.QP(cma,dva,Ama,bva,meq)
Error in solve.QP(cma, dva, Ama, bva, meq) :
        constraints are inconsistent, no solution!
>cmc
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
[1,]    1    0    0    0    0    0    0    0    0     0     0     0
[2,]    0    1    0    0    0    0    0    0    0     0     0     0
[3,]    0    0    1    0    0    0    0    0    0     0     0     0
[4,]    0    0    0    1    0    0    0    0    0     0     0     0
[5,]    0    0    0    0    1    0    0    0    0     0     0     0
[6,]    0    0    0    0    0    1    0    0    0     0     0     0
[7,]    0    0    0    0    0    0    1    0    0     0     0     0
[8,]    0    0    0    0    0    0    0    1    0     0     0     0
[9,]    0    0    0    0    0    0    0    0    1     0     0     0
[10,]    0    0    0    0    0    0    0    0    0     1     0     0
[11,]    0    0    0    0    0    0    0    0    0     0     1     0
[12,]    0    0    0    0    0    0    0    0    0     0     0     1
>dvc
[1] 0 0 0 0 0 0 0 0 0 0 0 0
>Amc
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] 
[,14]
[1,]    1    1   -1    0    0    0    0    0    0     0     0     0     0    
  0
[2,]   -1    1    0    1    0    0    0    0    0     0     0     0     0    
  0
[3,]    1    1    0    0   -1    0    0    0    0     0     0     0     0    
  0
[4,]   -1    1    0    0    0    1    0    0    0     0     0     0     0    
  0
[5,]    1    1    0    0    0    0   -1    0    0     0     0     0     0    
  0
[6,]   -1    1    0    0    0    0    0    1    0     0     0     0     0    
  0
[7,]    1    1    0    0    0    0    0    0   -1     0     0     0     0    
  0
[8,]   -1    1    0    0    0    0    0    0    0     1     0     0     0    
  0
[9,]    1    1    0    0    0    0    0    0    0     0    -1     0     0    
  0
[10,]   -1    1    0    0    0    0    0    0    0     0     0     1     0   
   0
[11,]    1    1    0    0    0    0    0    0    0     0     0     0    -1   
   0
[12,]   -1    1    0    0    0    0    0    0    0     0     0     0     0   
   1
>bvc
[1]  1  1 -1  0 -1  0 -1  0 -1  0 -1  0 -1  0
>meq
[1] 2
>liSMc<-solve.QP(cmc,dvc,Amc,bvc,meq)
>liSMc$solution
[1] 1.666667e-01 3.703906e-18 1.666667e-01 3.703906e-18 1.666667e-01 
0.000000e+00 1.666667e-01 3.703906e-18 1.666667e-01 3.703906e-18 
1.666667e-01
[12] 2.220988e-17



The problem, of course, is rounding error.  A small jitter in the 
constraints takes care of it:


>(bvan<-c(bva[1:11],-0.0000000001))
[1]  1e+00  1e+00 -1e+00  0e+00 -1e+00  0e+00 -1e+00  0e+00 -1e+00  0e+00 
-1e+00 -1e-10
>liSMan<-solve.QP(cma,dva,Ama,bvan,meq)
>liSMan$solution
[1]  2.000000e-01  0.000000e+00  2.000000e-01  8.002963e-53  2.000000e-01  
0.000000e+00  2.000000e-01  0.000000e+00  2.000000e-01 -1.664250e-17
>



When I was testing, I ran into the bad case right away, and it knocked me 
for a loop, because I thought I'd made a mistake in my code.  My problem is 
that I'm trying to write a program that will run significantly larger 
problems (hundreds of variables) with a variety of possible constraints 
allowed, and it might be difficult to determine whether a problem is 
legitimately infeasible or just being kicked out of the feasible region due 
to rounding errors.  I was wondering whether anyone has any tricks to share 
for mitigating these kind of problems and still generating feasible 
solutions.  Thanks!


--  TMK  --
212-460-5430	home
917-656-5351	cell


From murdoch at stats.uwo.ca  Fri Sep 21 19:02:24 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 21 Sep 2007 13:02:24 -0400
Subject: [R] getAnywhere
In-Reply-To: <200709211616.l8LGGpBm007581@definetti.ddns.uark.edu>
References: <200709211616.l8LGGpBm007581@definetti.ddns.uark.edu>
Message-ID: <46F3F920.70508@stats.uwo.ca>

On 9/21/2007 12:16 PM, Giovanni Petris wrote:
> Hello,
> 
> How can I see a function called "+.dlm"?
> 
>> methods("+")
> [1] +.Date   +.dlm*   +.POSIXt
> 
>    Non-visible functions are asterisked
>> getAnywhere("+.dlm")
> Error in grep(pattern, x, ignore.case, extended, value, fixed, useBytes) : 
> 	invalid regular expression '+\.dlm'
> 
> Thanks in advance,
> Giovanni
> 

This looks like a bug in getS3method.  Since "+" has special meaning in 
the regular expression, it should be escaped, and it wasn't.

I'll fix it.

Duncan Murdoch


From doc.evans at gmail.com  Fri Sep 21 19:15:08 2007
From: doc.evans at gmail.com (D. R. Evans)
Date: Fri, 21 Sep 2007 11:15:08 -0600
Subject: [R] Q: appending to non-existent vector?
Message-ID: <256f4e900709211015k345e5c3cn39e5a11b5359a3b5@mail.gmail.com>

This is a real newbie question. What makes it worse is that I know
I've seen the answer somewhere, but I can no longer find it.

If I have a loop that is supposed to generate a vector piecemeal,
adding an element each time through the loop, what do I do to stop it
failing the first time around the loop, when the vector doesn't yet
exist (so I can't use the append() function)?


From murdoch at stats.uwo.ca  Fri Sep 21 19:24:39 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 21 Sep 2007 13:24:39 -0400
Subject: [R] getAnywhere
In-Reply-To: <200709211616.l8LGGpBm007581@definetti.ddns.uark.edu>
References: <200709211616.l8LGGpBm007581@definetti.ddns.uark.edu>
Message-ID: <46F3FE57.8020908@stats.uwo.ca>

On 9/21/2007 12:16 PM, Giovanni Petris wrote:
> Hello,
> 
> How can I see a function called "+.dlm"?
> 
>> methods("+")
> [1] +.Date   +.dlm*   +.POSIXt
> 
>    Non-visible functions are asterisked
>> getAnywhere("+.dlm")
> Error in grep(pattern, x, ignore.case, extended, value, fixed, useBytes) : 
> 	invalid regular expression '+\.dlm'

Oh, by the way:  I'm assuming you're using the dlm package, and that's 
where +.dlm lives.  If so you can see the definition by

get("+.dlm", environment(is.dlm))

The "environment(is.dlm)" tells get to look in the private environment 
attached to the is.dlm function, which happens to be where "+.dlm" lives.

Duncan Murdoch


From gerifalte28 at hotmail.com  Fri Sep 21 19:31:00 2007
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Fri, 21 Sep 2007 11:31:00 -0600
Subject: [R] Line Graph - Greater than 2 variables on plot
In-Reply-To: <46F391F2.9080601@bitwrit.com.au>
References: <1190339851.46f3250bca8f3@webmail.fas.harvard.edu>
	<46F391F2.9080601@bitwrit.com.au>
Message-ID: <46F3FFD4.5020800@hotmail.com>

You can also use the facilities in the lattice package.  Using Jim?s 
data names:

require(lattice)
xyplot(A+B+C~D, data=wag, type="l", auto.key=list(points = FALSE, lines 
= TRUE, space = "bottom"), ylab="value", main="Three variable plot")

Regards,

Francisco


Jim Lemon wrote:
> Wayne Aldo Gavioli wrote:
>> Hello all,
>>
>> I was wondering if anyone knew how to construct a multiple line graph on R,
>> where there are 2 (or more) sets of data points plotted against some x axis of
>> data, and you can draw a line on the graph connecting each set of data points.
>>
>> For example:
>>
>> A               B              C          D
>> 0.6566        2.1185        1.2320        5
>> 0.647         2.0865        1.2325        10
>> 0.6532        2.1060        1.2287        15
>> 0.6487        2.1290        1.2313        20
>> 0.6594        2.1285        1.2341        25
>> 0.6577        2.1070        1.2343        30
>> 0.6579        2.1345        1.2340        35
>> 0.6734        2.1705        1.2362        40
>> 0.675         2.1845        1.2372        45
>> 0.6592        2.1550        1.2340        50
>> 0.6647        2.1710        1.2305        55
>>
>>
>>
>> Would there be a way:
>> a) To graph all the points of data in sets A, B and C as Y coordinates on one
>> graph, using the points in set D as the X-axis/coordinates for all 3 sets (A, B
>> and C)?
>> b) To be able to draw 3 lines on the graph that connect each set of data (1 line
>> connects all the A points, one line connects all the B points, one line connects
>> all the C points)
>>
>>
>> I couldn't find anything in the examples or the help section about multiple
>> lines on the same graph, only one line.
>>
> Hi Wayne,
> 
> Assume your data is in a data frame named "wag":
> 
> plot(wag$D,wag$A,main="Three variable plot",xlab="D",ylab="Value",
>   ylim=range(wag[c("A","B","C")]),type="l",col=2)
> lines(wag$D,wag$B,type="l",pch=2,col=3)
> lines(wag$D,wag$C,type="l",pch=3,col=4)
> legend(25,1.9,c("A","B","C"),lty=1,col=2:4)
> 
> Jim
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gerifalte28 at hotmail.com  Fri Sep 21 19:31:00 2007
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Fri, 21 Sep 2007 11:31:00 -0600
Subject: [R] Line Graph - Greater than 2 variables on plot
In-Reply-To: <46F391F2.9080601@bitwrit.com.au>
References: <1190339851.46f3250bca8f3@webmail.fas.harvard.edu>
	<46F391F2.9080601@bitwrit.com.au>
Message-ID: <46F3FFD4.5020800@hotmail.com>

You can also use the facilities in the lattice package.  Using Jim?s 
data names:

require(lattice)
xyplot(A+B+C~D, data=wag, type="l", auto.key=list(points = FALSE, lines 
= TRUE, space = "bottom"), ylab="value", main="Three variable plot")

Regards,

Francisco


Jim Lemon wrote:
> Wayne Aldo Gavioli wrote:
>> Hello all,
>>
>> I was wondering if anyone knew how to construct a multiple line graph on R,
>> where there are 2 (or more) sets of data points plotted against some x axis of
>> data, and you can draw a line on the graph connecting each set of data points.
>>
>> For example:
>>
>> A               B              C          D
>> 0.6566        2.1185        1.2320        5
>> 0.647         2.0865        1.2325        10
>> 0.6532        2.1060        1.2287        15
>> 0.6487        2.1290        1.2313        20
>> 0.6594        2.1285        1.2341        25
>> 0.6577        2.1070        1.2343        30
>> 0.6579        2.1345        1.2340        35
>> 0.6734        2.1705        1.2362        40
>> 0.675         2.1845        1.2372        45
>> 0.6592        2.1550        1.2340        50
>> 0.6647        2.1710        1.2305        55
>>
>>
>>
>> Would there be a way:
>> a) To graph all the points of data in sets A, B and C as Y coordinates on one
>> graph, using the points in set D as the X-axis/coordinates for all 3 sets (A, B
>> and C)?
>> b) To be able to draw 3 lines on the graph that connect each set of data (1 line
>> connects all the A points, one line connects all the B points, one line connects
>> all the C points)
>>
>>
>> I couldn't find anything in the examples or the help section about multiple
>> lines on the same graph, only one line.
>>
> Hi Wayne,
> 
> Assume your data is in a data frame named "wag":
> 
> plot(wag$D,wag$A,main="Three variable plot",xlab="D",ylab="Value",
>   ylim=range(wag[c("A","B","C")]),type="l",col=2)
> lines(wag$D,wag$B,type="l",pch=2,col=3)
> lines(wag$D,wag$C,type="l",pch=3,col=4)
> legend(25,1.9,c("A","B","C"),lty=1,col=2:4)
> 
> Jim
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Greg.Snow at intermountainmail.org  Fri Sep 21 19:43:44 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 21 Sep 2007 11:43:44 -0600
Subject: [R] Q: appending to non-existent vector?
In-Reply-To: <256f4e900709211015k345e5c3cn39e5a11b5359a3b5@mail.gmail.com>
References: <256f4e900709211015k345e5c3cn39e5a11b5359a3b5@mail.gmail.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBBF9CE2@LP-EXCHVS07.CO.IHC.COM>

Something like this:

myvec <- NULL

while( condition ) {
  myvec <- c(myvec, additional stuff)
}

However, if you know ahead of time how long the vector will be (you are
adding 1 element at a time), then it is best to initialize the vector to
the correct length:

myvec <- numeric(1000)

for (i in 1:1000) {
	myvec[i] <- additional stuff
}

In the second case you create a vector of length 1000 then insert
numbers into it.  In the first case you first create a vector of length
1, then next time through you create a new vector of length 2, copy a
value into position 1 then insert the new value into position 2 then
give it the same name as the previous vector (allowing the previous
version to be garbage collected at some point), on the 3rd iteration you
create a new vector of length 3, copy 2 values and insert 1, etc.  You
can see that that can fragment memory and take unneeded time which is
why the second method is prefered.  The only time to use the first
method is if you don't know how long each piece of 'additional stuff' is
and you know that you will only be doing the loop a few times.


Hope this helps,


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of D. R. Evans
> Sent: Friday, September 21, 2007 11:15 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Q: appending to non-existent vector?
> 
> This is a real newbie question. What makes it worse is that I 
> know I've seen the answer somewhere, but I can no longer find it.
> 
> If I have a loop that is supposed to generate a vector 
> piecemeal, adding an element each time through the loop, what 
> do I do to stop it failing the first time around the loop, 
> when the vector doesn't yet exist (so I can't use the 
> append() function)?
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From murdoch at stats.uwo.ca  Fri Sep 21 19:47:47 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 21 Sep 2007 13:47:47 -0400
Subject: [R] Q: appending to non-existent vector?
In-Reply-To: <256f4e900709211015k345e5c3cn39e5a11b5359a3b5@mail.gmail.com>
References: <256f4e900709211015k345e5c3cn39e5a11b5359a3b5@mail.gmail.com>
Message-ID: <46F403C3.7010703@stats.uwo.ca>

On 9/21/2007 1:15 PM, D. R. Evans wrote:
> This is a real newbie question. What makes it worse is that I know
> I've seen the answer somewhere, but I can no longer find it.
> 
> If I have a loop that is supposed to generate a vector piecemeal,
> adding an element each time through the loop, what do I do to stop it
> failing the first time around the loop, when the vector doesn't yet
> exist (so I can't use the append() function)?

You can create an empty vector to start.  Exactly how depends on what 
you're putting in it, but something like numeric(0) or list() should do 
what you want.

Of course, this is a very slow way to build results:  your code will run 
much faster if you allocate all the space you need at the beginning, and 
just fill in the values as you go, e.g.

x <- numeric(100)
i <- 0
while (more stuff) {
  i <- i+1
  x[i] <- stuff
}

Duncan Murdoch


From h.wickham at gmail.com  Fri Sep 21 19:49:39 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 21 Sep 2007 12:49:39 -0500
Subject: [R] Line Graph - Greater than 2 variables on plot
In-Reply-To: <46F3FFD4.5020800@hotmail.com>
References: <1190339851.46f3250bca8f3@webmail.fas.harvard.edu>
	<46F391F2.9080601@bitwrit.com.au> <46F3FFD4.5020800@hotmail.com>
Message-ID: <f8e6ff050709211049w1782ac72yefc7464380f1f24a@mail.gmail.com>

Or with a little data manipulation, in ggplot2:

library(ggplot2)
qplot(D, value, data=melt(wag, m="D"), colour=variable, geom="line")


Hadley

On 9/21/07, Francisco J. Zagmutt <gerifalte28 at hotmail.com> wrote:
> You can also use the facilities in the lattice package.  Using Jim?s
> data names:
>
> require(lattice)
> xyplot(A+B+C~D, data=wag, type="l", auto.key=list(points = FALSE, lines
> = TRUE, space = "bottom"), ylab="value", main="Three variable plot")
>
> Regards,
>
> Francisco
>
>
> Jim Lemon wrote:
> > Wayne Aldo Gavioli wrote:
> >> Hello all,
> >>
> >> I was wondering if anyone knew how to construct a multiple line graph on R,
> >> where there are 2 (or more) sets of data points plotted against some x axis of
> >> data, and you can draw a line on the graph connecting each set of data points.
> >>
> >> For example:
> >>
> >> A               B              C          D
> >> 0.6566        2.1185        1.2320        5
> >> 0.647         2.0865        1.2325        10
> >> 0.6532        2.1060        1.2287        15
> >> 0.6487        2.1290        1.2313        20
> >> 0.6594        2.1285        1.2341        25
> >> 0.6577        2.1070        1.2343        30
> >> 0.6579        2.1345        1.2340        35
> >> 0.6734        2.1705        1.2362        40
> >> 0.675         2.1845        1.2372        45
> >> 0.6592        2.1550        1.2340        50
> >> 0.6647        2.1710        1.2305        55
> >>
> >>
> >>
> >> Would there be a way:
> >> a) To graph all the points of data in sets A, B and C as Y coordinates on one
> >> graph, using the points in set D as the X-axis/coordinates for all 3 sets (A, B
> >> and C)?
> >> b) To be able to draw 3 lines on the graph that connect each set of data (1 line
> >> connects all the A points, one line connects all the B points, one line connects
> >> all the C points)
> >>
> >>
> >> I couldn't find anything in the examples or the help section about multiple
> >> lines on the same graph, only one line.
> >>
> > Hi Wayne,
> >
> > Assume your data is in a data frame named "wag":
> >
> > plot(wag$D,wag$A,main="Three variable plot",xlab="D",ylab="Value",
> >   ylim=range(wag[c("A","B","C")]),type="l",col=2)
> > lines(wag$D,wag$B,type="l",pch=2,col=3)
> > lines(wag$D,wag$C,type="l",pch=3,col=4)
> > legend(25,1.9,c("A","B","C"),lty=1,col=2:4)
> >
> > Jim
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
http://had.co.nz/


From cberry at tajo.ucsd.edu  Fri Sep 21 20:02:51 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Fri, 21 Sep 2007 11:02:51 -0700
Subject: [R] Likelihood ration test on glm
In-Reply-To: <1115a2b00709210933if488ccbl52ec6920671828a0@mail.gmail.com>
References: <04C44D9F040C8A43A18D04F65A8B68BBE92316@spatcex001.spadac.com>
	<1115a2b00709210933if488ccbl52ec6920671828a0@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709211058290.20600@tajo.ucsd.edu>

On Fri, 21 Sep 2007, Wensui Liu wrote:

> chris,
> as long as you know the log likelihood functions and the # of
> parameters in both models, a pencil and a piece of paper should be
> enough to calculate LR test.

True enough for the LR statistic.

Or follow the instructions in the _posting guide_ and try

  	RSiteSearch("glm likelihood")

and page thru the results looking for entries like this one:

 	http://finzi.psych.upenn.edu/R/Rhelp02a/archive/76603.html

Chuck

>
> On 9/21/07, Chris Elsaesser <chris.elsaesser at spadac.com> wrote:
>> I would like to try a likelihood ratio test in place of waldtest.
>> Ideally I'd like to provide two glm models, the second a submodel of the
>> first, in the style of lrt
>> (http://www.pik-potsdam.de/~hrust/tools/farismahelp/lrt.html). [lrt
>> takes farimsa objects]
>>
>> Does anyone know of such a likelihood ratio test?
>>
>>
>> Chris Elsaesser, PhD
>> Principal Scientist, Machine Learning
>> SPADAC Inc.
>> 7921 Jones Branch Dr. Suite 600
>> McLean, VA 22102
>>
>> 703.371.7301 (m)
>> 703.637.9421 (o)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> -- 
> ===============================
> "I am dying with the help of too many
> physicians." - Alexander the Great, on his deathbed
> ===============================
> WenSui Liu
> (http://spaces.msn.com/statcompute/blog)
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From h.wickham at gmail.com  Fri Sep 21 20:19:39 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 21 Sep 2007 13:19:39 -0500
Subject: [R] Q: appending to non-existent vector?
In-Reply-To: <46F403C3.7010703@stats.uwo.ca>
References: <256f4e900709211015k345e5c3cn39e5a11b5359a3b5@mail.gmail.com>
	<46F403C3.7010703@stats.uwo.ca>
Message-ID: <f8e6ff050709211119h79d4c900m4df90cf36e9efc51@mail.gmail.com>

On 9/21/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 9/21/2007 1:15 PM, D. R. Evans wrote:
> > This is a real newbie question. What makes it worse is that I know
> > I've seen the answer somewhere, but I can no longer find it.
> >
> > If I have a loop that is supposed to generate a vector piecemeal,
> > adding an element each time through the loop, what do I do to stop it
> > failing the first time around the loop, when the vector doesn't yet
> > exist (so I can't use the append() function)?
>
> You can create an empty vector to start.  Exactly how depends on what
> you're putting in it, but something like numeric(0) or list() should do
> what you want.
>
> Of course, this is a very slow way to build results:  your code will run
> much faster if you allocate all the space you need at the beginning, and
> just fill in the values as you go, e.g.
>
> x <- numeric(100)
> i <- 0
> while (more stuff) {
>   i <- i+1
>   x[i] <- stuff
> }

Or if you wanted to be really fancy:

while (more stuff) {
   i <- i+1
  if (i > length(x)) length(x) <- 2 * length(x)
   x[i] <- stuff
 }

which should be O(log n).

Hadley


From berwin at maths.uwa.edu.au  Fri Sep 21 20:29:41 2007
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sat, 22 Sep 2007 02:29:41 +0800
Subject: [R] Is it solve.QP or is it me?
In-Reply-To: <BAY108-F30469D46D795D6D8E3B9F7AABB0@phx.gbl>
References: <BAY108-F30469D46D795D6D8E3B9F7AABB0@phx.gbl>
Message-ID: <20070922022941.22c0b67d@absentia>

G'day Talbot,

regarding the subject line, perhaps neither, it may be your OS, chip or
maths library. :)

On my Intel Core2 Duo machine running under linux all your examples
work without error message.  What kind of machine are you using?

On Fri, 21 Sep 2007 12:38:05 -0400
"Talbot Katz" <topkatz at msn.com> wrote:

> [..] I was wondering whether anyone has any tricks to share for
> mitigating these kind of problems and still generating feasible
> solutions. 

I believe that one of the recommendations in the numerical literature
is to try to keep the norms of the columns of the matrix A on similar
scales.  Try to divide the first two columns of A (and the first two
entries in the vector b) by the square root of n.  

Hope that helps.

Cheers,

	Berwin 

=========================== Full address =============================
Berwin A Turlach                            Tel.: +65 6515 4416 (secr)
Dept of Statistics and Applied Probability        +65 6515 6650 (self)
Faculty of Science                          FAX : +65 6872 3919       
National University of Singapore     
6 Science Drive 2, Blk S16, Level 7          e-mail: statba at nus.edu.sg
Singapore 117546                    http://www.stat.nus.edu.sg/~statba


From mike.prager at noaa.gov  Fri Sep 21 21:33:27 2007
From: mike.prager at noaa.gov (Mike Prager)
Date: Fri, 21 Sep 2007 15:33:27 -0400
Subject: [R] text formatting
References: <7195839.1190386973350.JavaMail.?@fh122.dia.he.tucows.com>
Message-ID: <a378f3l5tn982khkj2jpia5qa28ftu6r0b@4ax.com>

stephen bond <stenka1 at go.com> wrote:

> Does R have any functions for C/Fortran style text formatting when a 
> number needs to be output right-justified in a fixed length field?
> 
> say '%2d %3d %5.3f' 

?formatC

-- 
Mike Prager, NOAA, Beaufort, NC
* Opinions expressed are personal and not represented otherwise.
* Any use of tradenames does not constitute a NOAA endorsement.


From vivianmontecino at uchile.cl  Fri Sep 21 13:45:44 2007
From: vivianmontecino at uchile.cl (Vivian)
Date: Fri, 21 Sep 2007 13:45:44 +0200
Subject: [R] help with rq
Message-ID: <20070921173344.B8967392856@keseel.uchile.cl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070921/e6e1ba01/attachment.pl 

From faheem at email.unc.edu  Fri Sep 21 21:59:18 2007
From: faheem at email.unc.edu (Faheem Mitha)
Date: Fri, 21 Sep 2007 15:59:18 -0400 (EDT)
Subject: [R] truncating a data frame based on a function
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBBF9CAB@LP-EXCHVS07.CO.IHC.COM>
References: <Pine.LNX.4.64.0709201506530.14707@orwell.homelinux.org>
	<07E228A5BE53C24CAD490193A7381BBBBF9CAB@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <Pine.LNX.4.64.0709211557150.17669@orwell.homelinux.org>



On Fri, 21 Sep 2007, Greg Snow wrote:

> Look at the subset function (?subset), it may do what you want.

This looks useful. Thanks. However, how can I write an expression 
selecting certain rows (subset argument) in the case of a matrix? when it 
does not have named columns? The documentation does not have examples of 
this.
                                                            Faheem.


From cooch17 at verizon.net  Fri Sep 21 22:17:10 2007
From: cooch17 at verizon.net (Evan Cooch)
Date: Fri, 21 Sep 2007 16:17:10 -0400
Subject: [R] really dumb question | loop counters in
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBBF9CB3@LP-EXCHVS07.CO.IHC.COM>
References: <46F3EA97.8020708@verizon.net>
	<07E228A5BE53C24CAD490193A7381BBBBF9CB3@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <46F426C6.6010303@verizon.net>

Thanks. And thanks for the C-style tip.

Greg Snow wrote:
> Try:
>
> for(x in seq(0,1,by=0.01)) {
> print(x)
> }
>
> The for loop in S/R is what some languages call a foreach loop, you need
> to provide a vector of the values to loop over.
>
> If you really want a C style for loop, then just realize that the for
> loop is a shorthand while loop:
>
> x <- 0
> while( x < 1 ) {
>   print(x)
>   x <- x + 0.01
> }
>
> Hope this helps,
>
>
>


From Galina_Glazko at URMC.Rochester.edu  Fri Sep 21 22:19:48 2007
From: Galina_Glazko at URMC.Rochester.edu (Glazko, Galina)
Date: Fri, 21 Sep 2007 16:19:48 -0400
Subject: [R] duplicated names and values
Message-ID: <0E5F4BBC8D8E9F4F9A5C186EFACDA942A46B52@e2k3ms5.urmc-sh.rochester.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070921/f92cd9d3/attachment.pl 

From cooch17 at verizon.net  Fri Sep 21 22:20:00 2007
From: cooch17 at verizon.net (Evan Cooch)
Date: Fri, 21 Sep 2007 16:20:00 -0400
Subject: [R] really dumb question | loop counters in
In-Reply-To: <46F3EFD8.2010703@geo.uu.nl>
References: <46F3EA97.8020708@verizon.net> <46F3EFD8.2010703@geo.uu.nl>
Message-ID: <46F42770.80403@verizon.net>

Paul Hiemstra wrote:
> Hi,
>
> This works:
>
> for(i in seq(1,100,5)) {
> print(i)
> }
>
> Very similar to the way python does this kind of loop.
>

Indeed it is - thanks for the tip. I'm still puzzled why I can't find a 
single piece of the standard [R] language documentation that shows this. 
In contrast, every single other language I use (more than I care to 
admit), and documentation for same, feature this prominently when they 
talk about looping.

Ah well.


From jholtman at gmail.com  Fri Sep 21 22:29:52 2007
From: jholtman at gmail.com (jim holtman)
Date: Fri, 21 Sep 2007 16:29:52 -0400
Subject: [R] duplicated names and values
In-Reply-To: <0E5F4BBC8D8E9F4F9A5C186EFACDA942A46B52@e2k3ms5.urmc-sh.rochester.edu>
References: <0E5F4BBC8D8E9F4F9A5C186EFACDA942A46B52@e2k3ms5.urmc-sh.rochester.edu>
Message-ID: <644e1f320709211329q74dab8ei681ebdaca4bc3b4@mail.gmail.com>

?unique

On 9/21/07, Glazko, Galina <Galina_Glazko at urmc.rochester.edu> wrote:
> Dear list,
>
>
>
> I am sorry about this simple question, but somehow I can not figure out
> how to solve my problem, may be you could help?
>
> I have a vector mir3:
>
> > length(mir3)
>
> [1] 220671
>
>
>
> >head(mir3)
>
>         rno-miR-30c          rno-miR-30c          rno-miR-30d
> rno-miR-30e          "ENSRNOT00000049288"    "ENSRNOT00000049288"
> "ENSRNOT00000049288"    "ENSRNOT00000049288"
>
>         rno-miR-145          rno-miR-145          rno-miR-379
>
> "ENSRNOT00000049288" "ENSRNOT00000049288" "ENSRNOT00000061859" ....
>
>
>
> The names there (such as "rno-miR-30c","rno-miR-30d"...) can be
> duplicated, as well as the values (e.g "ENSRNOT00000049288")
>
> I need the vector were unique names have always different values.
>
> That is, all entries like:
>
> rno-miR-30c          rno-miR-30c
>
> "ENSRNOT00000049288"    "ENSRNOT00000049288"
>
> I have to change into single entry:
>
> rno-miR-30c
>
> "ENSRNOT00000049288"
>
> ..
>
>
>
> Thank you!
>
> Best regards
>
> Galina
>
>
>
>
>
>
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From jrkrideau at yahoo.ca  Fri Sep 21 22:34:01 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Fri, 21 Sep 2007 16:34:01 -0400 (EDT)
Subject: [R] duplicated names and values
In-Reply-To: <0E5F4BBC8D8E9F4F9A5C186EFACDA942A46B52@e2k3ms5.urmc-sh.rochester.edu>
Message-ID: <906908.55108.qm@web32804.mail.mud.yahoo.com>

Galina,
It is not clear to me.  Are the names and the values
always the same or are there different values for some
of the names
 Example same name & same value
  A  B  B C B A
  3   2 2 1 2 3

or same names but different values
  A  B  B C B A
  3  2  1 1 2 3



--- "Glazko, Galina"
<Galina_Glazko at urmc.rochester.edu> wrote:

> Dear list,
> 
>  
> 
> I am sorry about this simple question, but somehow I
> can not figure out
> how to solve my problem, may be you could help?
> 
> I have a vector mir3:
> 
> > length(mir3)
> 
> [1] 220671
> 
>  
> 
> >head(mir3)
> 
>          rno-miR-30c          rno-miR-30c         
> rno-miR-30d
> rno-miR-30e          "ENSRNOT00000049288"   
> "ENSRNOT00000049288"
> "ENSRNOT00000049288"    "ENSRNOT00000049288" 
> 
>          rno-miR-145          rno-miR-145         
> rno-miR-379 
> 
> "ENSRNOT00000049288" "ENSRNOT00000049288"
> "ENSRNOT00000061859" ....
> 
>  
> 
> The names there (such as
> "rno-miR-30c","rno-miR-30d"...) can be
> duplicated, as well as the values (e.g
> "ENSRNOT00000049288")
> 
> I need the vector were unique names have always
> different values. 
> 
> That is, all entries like: 
> 
> rno-miR-30c          rno-miR-30c          
> 
> "ENSRNOT00000049288"    "ENSRNOT00000049288"
> 
> I have to change into single entry:
> 
> rno-miR-30c          
> 
> "ENSRNOT00000049288"
> 
> ..
> 
>  
> 
> Thank you!
> 
> Best regards
> 
> Galina
> 
>  
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From dlr32 at cornell.edu  Fri Sep 21 22:37:04 2007
From: dlr32 at cornell.edu (Dan Rabosky)
Date: Fri, 21 Sep 2007 16:37:04 -0400
Subject: [R] problem with 'integrate'
Message-ID: <1D963223-C85A-4111-83E7-6461604A2E49@cornell.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070921/f487f110/attachment.pl 

From PPB at gmx-topmail.de  Fri Sep 21 22:40:43 2007
From: PPB at gmx-topmail.de (PPB at gmx-topmail.de)
Date: Fri, 21 Sep 2007 22:40:43 +0200
Subject: [R] Adjusting axis in forestplot()
Message-ID: <20070921204043.65120@gmx.net>

Hi,

I would like to draw a forest plot using forestplot() from the rmeta package. However, the function appears pretty inflexible to me. I tried to adjust the x-axis (make it go from 0 to 100) but I failed. Since it is programmed using the grid library it does not accept simple commands for plots. Does anyone of you know how to manipulate the graph?

Or do you know another possibility to draw a forest plot in R, using a dataset with names, estimates and confidence intervals as a basis?

Thanks. 

Regards,
Patrick (ppb at gmx-topmail.de).
-- 
Psssst! Schon vom neuen GMX MultiMessenger geh?rt?
Der kanns mit allen: http://www.gmx.net/de/go/multimessenger


From ymoisan at groupesm.com  Fri Sep 21 22:47:39 2007
From: ymoisan at groupesm.com (Yves Moisan)
Date: Fri, 21 Sep 2007 13:47:39 -0700 (PDT)
Subject: [R] Stats 101 : lm with/without intercept
Message-ID: <12829558.post@talk.nabble.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070921/442484dc/attachment.pl 

From juryef at yahoo.com  Fri Sep 21 22:51:06 2007
From: juryef at yahoo.com (Judith Flores)
Date: Fri, 21 Sep 2007 13:51:06 -0700 (PDT)
Subject: [R] Adding a table to a plot area
Message-ID: <315698.89149.qm@web34705.mail.mud.yahoo.com>

Is there a command to insert a table into the plot
area other that using text?

Thank you.


      ____________________________________________________________________________________
Luggage? GPS? Comic books?


From Cody_Hamilton at Edwards.com  Fri Sep 21 23:01:50 2007
From: Cody_Hamilton at Edwards.com (Cody Hamilton)
Date: Fri, 21 Sep 2007 14:01:50 -0700
Subject: [R] Estimate correlation with bootstrap
In-Reply-To: <587248.1680.qm@web30610.mail.mud.yahoo.com>
References: <587248.1680.qm@web30610.mail.mud.yahoo.com>
Message-ID: <4C7D0185E1C6D64AAFB18A2281B262B80675965309@EXIRV01.am.edwards.lcl>

Andreas,

To do pairwise bootstrap sampling, try

for (i in 1:1000) {
  ind<-sample(1:10,10,replace=TRUE)
  boot.com.ab[i]<-cor(a[ind],b[ind])
}

Regards,
   -Cody

Cody Hamilton
Edwards Lifesciences

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Andreas Klein
Sent: Thursday, September 20, 2007 10:59 PM
To: r-help at r-project.org
Subject: [R] Estimate correlation with bootstrap

Hello.

I would like to estimate the correlation coefficient
from two samples with Bootstrapping using the
R-function sample().

The problem is, that I have to sample pairwise. For
example if I have got two time series and I draw from
the first series the value from 1912 I need the value
from 1912 from the second sample, too.

Example:

Imagine that a and b are two time series with returns
for example:

a <- c(1,2,3,4,5,6,7,8,9,10)
b <- c(1,1,56,3,6,6,6,7,2,10)

a.sample     <- numeric(10)
b.sample     <- numeric(10)
boot.cor.a.b <- numeric(1000)

for (i in 1:1000)

{

 for (j in 1:10)

 {

  a.sample[j] <- sample(a,1,replace=TRUE)
  b.sample[j] <- sample(b,1,replace=TRUE)

 }

 boot.cor.a.b[i] <- cor(a,b)

}

The problem here is, that the sampling is independent
from each other.

So how do I have to change the R-code to get the
pairwise sampling mentioned above?

I hope you can help me.

Sincerely
Klein.


      ________

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From doc.evans at gmail.com  Fri Sep 21 23:14:13 2007
From: doc.evans at gmail.com (D. R. Evans)
Date: Fri, 21 Sep 2007 15:14:13 -0600
Subject: [R] Q: appending to non-existent vector?
In-Reply-To: <f8e6ff050709211119h79d4c900m4df90cf36e9efc51@mail.gmail.com>
References: <256f4e900709211015k345e5c3cn39e5a11b5359a3b5@mail.gmail.com>	
	<46F403C3.7010703@stats.uwo.ca>
	<f8e6ff050709211119h79d4c900m4df90cf36e9efc51@mail.gmail.com>
Message-ID: <46F43425.9000503@gmail.com>

OK; lots of ideas there. Thanks very much.

  Doc


From Galina_Glazko at URMC.Rochester.edu  Fri Sep 21 23:17:17 2007
From: Galina_Glazko at URMC.Rochester.edu (Glazko, Galina)
Date: Fri, 21 Sep 2007 17:17:17 -0400
Subject: [R] duplicated names and values
References: <906908.55108.qm@web32804.mail.mud.yahoo.com>
Message-ID: <0E5F4BBC8D8E9F4F9A5C186EFACDA94207047F@e2k3ms5.urmc-sh.rochester.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070921/ccda2a8d/attachment.pl 

From Ted.Harding at manchester.ac.uk  Fri Sep 21 23:33:30 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Fri, 21 Sep 2007 22:33:30 +0100 (BST)
Subject: [R] Q: appending to non-existent vector?
In-Reply-To: <256f4e900709211015k345e5c3cn39e5a11b5359a3b5@mail.gmail.com>
Message-ID: <XFMail.070921223330.Ted.Harding@manchester.ac.uk>

On 21-Sep-07 17:15:08, D. R. Evans wrote:
> This is a real newbie question. What makes it worse is that I know
> I've seen the answer somewhere, but I can no longer find it.
> 
> If I have a loop that is supposed to generate a vector piecemeal,
> adding an element each time through the loop, what do I do to stop it
> failing the first time around the loop, when the vector doesn't yet
> exist (so I can't use the append() function)?

I always use NULL, as in:

x<-NULL
for(...){ ... ; x<-c(x,...)}

It has not let me down yet!
Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 21-Sep-07                                       Time: 22:33:26
------------------------------ XFMail ------------------------------


From murdoch at stats.uwo.ca  Fri Sep 21 23:53:02 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 21 Sep 2007 17:53:02 -0400
Subject: [R] really dumb question | loop counters in
In-Reply-To: <46F42770.80403@verizon.net>
References: <46F3EA97.8020708@verizon.net> <46F3EFD8.2010703@geo.uu.nl>
	<46F42770.80403@verizon.net>
Message-ID: <46F43D3E.9030207@stats.uwo.ca>

On 21/09/2007 4:20 PM, Evan Cooch wrote:
> Paul Hiemstra wrote:
>> Hi,
>>
>> This works:
>>
>> for(i in seq(1,100,5)) {
>> print(i)
>> }
>>
>> Very similar to the way python does this kind of loop.
>>
> 
> Indeed it is - thanks for the tip. I'm still puzzled why I can't find a 
> single piece of the standard [R] language documentation that shows this. 
> In contrast, every single other language I use (more than I care to 
> admit), and documentation for same, feature this prominently when they 
> talk about looping.

It's in "9.2.2 Repetitive execution: for loops, repeat and while" of the 
Introduction to R manual. That's a good manual to read if you're looking 
for an introduction to R.

Duncan Murdoch


From jrkrideau at yahoo.ca  Fri Sep 21 23:57:09 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Fri, 21 Sep 2007 17:57:09 -0400 (EDT)
Subject: [R] duplicated names and values
In-Reply-To: <0E5F4BBC8D8E9F4F9A5C186EFACDA94207047F@e2k3ms5.urmc-sh.rochester.edu>
Message-ID: <994916.55711.qm@web32803.mail.mud.yahoo.com>

I was afraid of that.  

I am a newbie at R and while there probably is some
easy way to do this I don't see it

This example will, at least, show you a way to get the
actual duplicate names. However I don't see any easy
way without all kinds of subsetting to get what you
need.

nas  <- c("A",  "B" , "B" ,"C" ,"B", "A" )
nums  <- c(3, 2,  1, 1, 2, 3)
names(nums)  <-  nas
nums
dups  <-  duplicated(names(nums))
mydata  <- data.frame(nas , nums, dups)
mydups  <- unique(subset(mydata[,1],   
mydata$dups=="TRUE"))


--- "Glazko, Galina"
<Galina_Glazko at URMC.Rochester.edu> wrote:

> John,
>  
> one name can have multiple values, and different
> names can have the same single value, 
> I only need to eliminate cases when the same names
> have same values...
> unique gives me really 'unique' set, whithout
> duplicates
>  
> thank you!
> best regards
> Galina
>  
> 
> ________________________________
> 
> From: John Kane [mailto:jrkrideau at yahoo.ca]
> Sent: Fri 9/21/2007 4:34 PM
> To: Glazko, Galina; r-help at stat.math.ethz.ch
> Subject: Re: [R] duplicated names and values
> 
> 
> 
> Galina,
> It is not clear to me.  Are the names and the values
> always the same or are there different values for
> some
> of the names
>  Example same name & same value
>   A  B  B C B A
>   3   2 2 1 2 3
> 
> or same names but different values
>   A  B  B C B A
>   3  2  1 1 2 3
> 
> 
> 
> --- "Glazko, Galina"
> <Galina_Glazko at urmc.rochester.edu> wrote:
> 
> > Dear list,
> >
> > 
> >
> > I am sorry about this simple question, but somehow
> I
> > can not figure out
> > how to solve my problem, may be you could help?
> >
> > I have a vector mir3:
> >
> > > length(mir3)
> >
> > [1] 220671
> >
> > 
> >
> > >head(mir3)
> >
> >          rno-miR-30c          rno-miR-30c        
> > rno-miR-30d
> > rno-miR-30e          "ENSRNOT00000049288"  
> > "ENSRNOT00000049288"
> > "ENSRNOT00000049288"    "ENSRNOT00000049288"
> >
> >          rno-miR-145          rno-miR-145        
> > rno-miR-379
> >
> > "ENSRNOT00000049288" "ENSRNOT00000049288"
> > "ENSRNOT00000061859" ....
> >
> > 
> >
> > The names there (such as
> > "rno-miR-30c","rno-miR-30d"...) can be
> > duplicated, as well as the values (e.g
> > "ENSRNOT00000049288")
> >
> > I need the vector were unique names have always
> > different values.
> >
> > That is, all entries like:
> >
> > rno-miR-30c          rno-miR-30c         
> >
> > "ENSRNOT00000049288"    "ENSRNOT00000049288"
> >
> > I have to change into single entry:
> >
> > rno-miR-30c         
> >
> > "ENSRNOT00000049288"
> >
> > ..
> >
> > 
> >
> > Thank you!
> >
> > Best regards
> >
> > Galina
> >
> > 
> >
> > 
> >
> > 
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained,
> > reproducible code.
> >
> 
> 
> 
>       Be smarter than spam. See how smart SpamGuard
> is at giving junk email the boot with the All-new

> http://mrd.mail.yahoo.com/try_beta?.intl=ca
> 
> 
> 
>


From murdoch at stats.uwo.ca  Sat Sep 22 00:00:05 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 21 Sep 2007 18:00:05 -0400
Subject: [R] Stats 101 : lm with/without intercept
In-Reply-To: <12829558.post@talk.nabble.com>
References: <12829558.post@talk.nabble.com>
Message-ID: <46F43EE5.5080401@stats.uwo.ca>

On 21/09/2007 4:47 PM, Yves Moisan wrote:
> I am puzzled at the use of regression.  I have a categorical variable
> ClassePop33000 which factors a Population variable into 3 levels.  I want to
> investigate whether that categorical variable has some relation with my
> dependent variable, so I go :
> 
> lm(Cout.ton ~ ClassePop33000, data=ech2)
> 
> Call:
> lm(formula = Cout.ton ~ ClassePop33000, data = ech2)
> 
> Residuals:
>     Min      1Q  Median      3Q     Max 
> -182.24  -62.91  -22.76   66.38  277.39 
> 
> Coefficients:
>                                    Estimate Std. Error t value Pr(>|t|)    
> (Intercept)                          231.66      11.50  20.141  < 2e-16 ***
> ClassePop33000[T.[3000,25000)]       -72.91      16.70  -4.366 2.19e-05 ***
> ClassePop33000[T.[25000,10000000)]   -95.17      19.92  -4.777 3.82e-06 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
> 
> Residual standard error: 97.6 on 170 degrees of freedom
> Multiple R-Squared: 0.1502,     Adjusted R-squared: 0.1402 
> F-statistic: 15.02 on 2 and 170 DF,  p-value: 9.818e-07 
> 
> 
> Now I discovered one could omit the intercept and therefore have
> coefficients for the N levels of the categorical variable.  So I went :
> 
> lm(Cout.ton ~ ClassePop33000 + 0, data=ech2)
> 
> Call:
> lm(formula = Cout.ton ~ ClassePop33000 + 0, data = ech2)
> 
> Residuals:
>     Min      1Q  Median      3Q     Max 
> -182.24  -62.91  -22.76   66.38  277.39 
> 
> Coefficients:
>                                Estimate Std. Error t value Pr(>|t|)    
> ClassePop33000[1,3000)           231.66      11.50  20.141  < 2e-16 ***
> ClassePop33000[3000,25000)       158.75      12.11  13.114  < 2e-16 ***
> ClassePop33000[25000,10000000)   136.49      16.27   8.391  1.8e-14 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
> 
> Residual standard error: 97.6 on 170 degrees of freedom
> Multiple R-Squared: 0.7922,     Adjusted R-squared: 0.7885 
> F-statistic:   216 on 3 and 170 DF,  p-value: < 2.2e-16 
> 
> 
> I tried the very pedagogical examples at
> http://www.stat.umn.edu/geyer/5102/examp/dummy.html and plotting the
> regression lines with abline gives me the exact same lines whether I use
> with or without intercept.  Now why do R squared differ then ?  At least the
> p-values are of the same order of magnitude, but I don't understand the
> drastic difference in R squared.  Pointers to stats 101 anyone ?  

The standard definition of R-squared assumes there's an intercept 
present.  If you suppress it, you need to come up with a new definition. 
  So those values aren't comparable.

Duncan Murdoch


From rho at difres.dk  Sat Sep 22 00:19:32 2007
From: rho at difres.dk (=?iso-8859-1?Q?Ren=E9_Holst?=)
Date: Sat, 22 Sep 2007 00:19:32 +0200
Subject: [R] Error: (subscript) logical subscript too long
Message-ID: <E77CA64579734A45BCF5E34BC1D1579D8A0DCC@hi-mail01.dfu.local>


As part of a larger program I have a rather long and involved sub-procedure which fails to work, It manipulates some large matrices, stored to the disc. The procedure halts with the message:

Error: (subscript) logical subscript too long

Can anyone give advice about what may cause this error and how it can be remedied - I feel confident that it is not a syntactically or logical error.

Thanks,

Ren?


From f.harrell at vanderbilt.edu  Sat Sep 22 00:41:55 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 21 Sep 2007 17:41:55 -0500
Subject: [R] Adding a table to a plot area
In-Reply-To: <315698.89149.qm@web34705.mail.mud.yahoo.com>
References: <315698.89149.qm@web34705.mail.mud.yahoo.com>
Message-ID: <46F448B3.6040202@vanderbilt.edu>

Judith Flores wrote:
> Is there a command to insert a table into the plot
> area other that using text?
> 
> Thank you.

To me the only completely satisfying approach is to use LaTeX and psfrag 
in you want great alignment and other features.  A howto with R is at 
http://biostat.mc.vanderbilt.edu/PsFrag .  This uses the fragmaster perl 
script which runs LaTeX from within R to make the final graphics file 
self-contained.

Frank

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From bates at stat.wisc.edu  Sat Sep 22 00:44:50 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 21 Sep 2007 17:44:50 -0500
Subject: [R] Error: (subscript) logical subscript too long
In-Reply-To: <E77CA64579734A45BCF5E34BC1D1579D8A0DCC@hi-mail01.dfu.local>
References: <E77CA64579734A45BCF5E34BC1D1579D8A0DCC@hi-mail01.dfu.local>
Message-ID: <40e66e0b0709211544i4e4e65c2r89911d6bac472ce0@mail.gmail.com>

On 9/21/07, Ren? Holst <rho at difres.dk> wrote:
>
> As part of a larger program I have a rather long and involved sub-procedure which fails to work, It manipulates some large matrices, stored to the disc. The procedure halts with the message:
>
> Error: (subscript) logical subscript too long
>
> Can anyone give advice about what may cause this error and how it can be remedied - I feel confident that it is not a syntactically or logical error.

You need to find out where the error message originated.  Use
traceback() for that.  Then, if necessary, use
debug(functionWithError) to set the debugger on the point where the
problem originates and find out what subscripting operation is causing
the problem.

You may be confident that it is not a logical error but such things
are surprisingly crafty in how they can worm their way into your code.
 I almost never quote Ronald Reagan except for his suggestion that you
"Trust, but verify".


From jporzak at gmail.com  Sat Sep 22 00:52:02 2007
From: jporzak at gmail.com (Jim Porzak)
Date: Fri, 21 Sep 2007 15:52:02 -0700
Subject: [R] Line Graph - Greater than 2 variables on plot
In-Reply-To: <f8e6ff050709211049w1782ac72yefc7464380f1f24a@mail.gmail.com>
References: <1190339851.46f3250bca8f3@webmail.fas.harvard.edu>
	<46F391F2.9080601@bitwrit.com.au> <46F3FFD4.5020800@hotmail.com>
	<f8e6ff050709211049w1782ac72yefc7464380f1f24a@mail.gmail.com>
Message-ID: <2a9c000c0709211552i704c4e12kc3edd3daeec98db5@mail.gmail.com>

Hi Hadley,

I'm trying your suggestion to Wayne. Did you mean to say:

qplot(D, value, data = melt(wag), colour = variable, geom = "line")
?

With the m="D" argument, I get the error:
Error in as.data.frame.default(x[[i]], optional = TRUE) :
	cannot coerce class "function" into a data.frame

-- 
Best,
Jim Porzak
Responsys, Inc.
San Francisco, CA
http://www.linkedin.com/in/jimporzak

On 9/21/07, hadley wickham <h.wickham at gmail.com> wrote:
> Or with a little data manipulation, in ggplot2:
>
> library(ggplot2)
> qplot(D, value, data=melt(wag, m="D"), colour=variable, geom="line")
>
>
> Hadley
>
> On 9/21/07, Francisco J. Zagmutt <gerifalte28 at hotmail.com> wrote:
> > You can also use the facilities in the lattice package.  Using Jim?s
> > data names:
> >
> > require(lattice)
> > xyplot(A+B+C~D, data=wag, type="l", auto.key=list(points = FALSE, lines
> > = TRUE, space = "bottom"), ylab="value", main="Three variable plot")
> >
> > Regards,
> >
> > Francisco
> >
> >
> > Jim Lemon wrote:
> > > Wayne Aldo Gavioli wrote:
> > >> Hello all,
> > >>
> > >> I was wondering if anyone knew how to construct a multiple line graph on R,
> > >> where there are 2 (or more) sets of data points plotted against some x axis of
> > >> data, and you can draw a line on the graph connecting each set of data points.
> > >>
> > >> For example:
> > >>
> > >> A               B              C          D
> > >> 0.6566        2.1185        1.2320        5
> > >> 0.647         2.0865        1.2325        10
> > >> 0.6532        2.1060        1.2287        15
> > >> 0.6487        2.1290        1.2313        20
> > >> 0.6594        2.1285        1.2341        25
> > >> 0.6577        2.1070        1.2343        30
> > >> 0.6579        2.1345        1.2340        35
> > >> 0.6734        2.1705        1.2362        40
> > >> 0.675         2.1845        1.2372        45
> > >> 0.6592        2.1550        1.2340        50
> > >> 0.6647        2.1710        1.2305        55
> > >>
> > >>
> > >>
> > >> Would there be a way:
> > >> a) To graph all the points of data in sets A, B and C as Y coordinates on one
> > >> graph, using the points in set D as the X-axis/coordinates for all 3 sets (A, B
> > >> and C)?
> > >> b) To be able to draw 3 lines on the graph that connect each set of data (1 line
> > >> connects all the A points, one line connects all the B points, one line connects
> > >> all the C points)
> > >>
> > >>
> > >> I couldn't find anything in the examples or the help section about multiple
> > >> lines on the same graph, only one line.
> > >>
> > > Hi Wayne,
> > >
> > > Assume your data is in a data frame named "wag":
> > >
> > > plot(wag$D,wag$A,main="Three variable plot",xlab="D",ylab="Value",
> > >   ylim=range(wag[c("A","B","C")]),type="l",col=2)
> > > lines(wag$D,wag$B,type="l",pch=2,col=3)
> > > lines(wag$D,wag$C,type="l",pch=3,col=4)
> > > legend(25,1.9,c("A","B","C"),lty=1,col=2:4)
> > >
> > > Jim
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> http://had.co.nz/
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Sat Sep 22 00:52:24 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 21 Sep 2007 18:52:24 -0400
Subject: [R] Adding a table to a plot area
In-Reply-To: <315698.89149.qm@web34705.mail.mud.yahoo.com>
References: <315698.89149.qm@web34705.mail.mud.yahoo.com>
Message-ID: <971536df0709211552s63c02bf8kaaf01e40207a2b30@mail.gmail.com>

legend can be made to do that:

plot(1:10)
legend("topleft", LETTERS[1:6], ncol = 2)


On 9/21/07, Judith Flores <juryef at yahoo.com> wrote:
> Is there a command to insert a table into the plot
> area other that using text?
>
> Thank you.
>
>
>      ____________________________________________________________________________________
> Luggage? GPS? Comic books?
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From cooch17 at verizon.net  Sat Sep 22 00:54:07 2007
From: cooch17 at verizon.net (Evan Cooch)
Date: Fri, 21 Sep 2007 18:54:07 -0400
Subject: [R] really dumb question | loop counters in
In-Reply-To: <46F43D3E.9030207@stats.uwo.ca>
References: <46F3EA97.8020708@verizon.net> <46F3EFD8.2010703@geo.uu.nl>
	<46F42770.80403@verizon.net> <46F43D3E.9030207@stats.uwo.ca>
Message-ID: <46F44B8F.9040005@verizon.net>

Thanks, but  there is nothing in section 9.2.2 that mentions seq(x,y,z) 
or anything close in a for loop.  All it says is (basically):


There is also a for loop construction which has the form
 > for (name in expr_1) expr_2
where name is the loop variable. expr 1 is a vector expression, (often a 
sequence like 1:20), and
expr 2 is often a grouped expression with its sub-expressions written in 
terms of the dummy
name. expr 2 is repeatedly evaluated as name ranges through the values 
in the vector result of
expr 1.

Moreover, I would have assumed it would be in the language definition 
file (not that I could find - I did check), the reference manual (nada), 
and so forth. If someone can point to the precise page in one of the 
standard - distributed - bits of R documentation the specifically says 
'here is how you use a non-unity incremental counter in an iterative 
loop in R', with an example, I'll stand corrected.

Duncan Murdoch wrote:
> On 21/09/2007 4:20 PM, Evan Cooch wrote:
>> Paul Hiemstra wrote:
>>> Hi,
>>>
>>> This works:
>>>
>>> for(i in seq(1,100,5)) {
>>> print(i)
>>> }
>>>
>>> Very similar to the way python does this kind of loop.
>>>
>>
>> Indeed it is - thanks for the tip. I'm still puzzled why I can't find 
>> a single piece of the standard [R] language documentation that shows 
>> this. In contrast, every single other language I use (more than I 
>> care to admit), and documentation for same, feature this prominently 
>> when they talk about looping.
>
> It's in "9.2.2 Repetitive execution: for loops, repeat and while" of 
> the Introduction to R manual. That's a good manual to read if you're 
> looking for an introduction to R.
>
> Duncan Murdoch
>
>


From h.wickham at gmail.com  Sat Sep 22 00:57:48 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 21 Sep 2007 17:57:48 -0500
Subject: [R] Line Graph - Greater than 2 variables on plot
In-Reply-To: <2a9c000c0709211552i704c4e12kc3edd3daeec98db5@mail.gmail.com>
References: <1190339851.46f3250bca8f3@webmail.fas.harvard.edu>
	<46F391F2.9080601@bitwrit.com.au> <46F3FFD4.5020800@hotmail.com>
	<f8e6ff050709211049w1782ac72yefc7464380f1f24a@mail.gmail.com>
	<2a9c000c0709211552i704c4e12kc3edd3daeec98db5@mail.gmail.com>
Message-ID: <f8e6ff050709211557s1bc277bdi7cde0f3abd031c26@mail.gmail.com>

On 9/21/07, Jim Porzak <jporzak at gmail.com> wrote:
> Hi Hadley,
>
> I'm trying your suggestion to Wayne. Did you mean to say:
>
> qplot(D, value, data = melt(wag), colour = variable, geom = "line")
> ?

Ooops, no I meant to say:

qplot(D, value, data = melt(wag, id="D"), colour = variable, geom = "line")

Hadley

-- 
http://had.co.nz/


From murdoch at stats.uwo.ca  Sat Sep 22 01:15:05 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 21 Sep 2007 19:15:05 -0400
Subject: [R] really dumb question | loop counters in
In-Reply-To: <46F44B8F.9040005@verizon.net>
References: <46F3EA97.8020708@verizon.net> <46F3EFD8.2010703@geo.uu.nl>
	<46F42770.80403@verizon.net> <46F43D3E.9030207@stats.uwo.ca>
	<46F44B8F.9040005@verizon.net>
Message-ID: <46F45079.8090506@stats.uwo.ca>

On 21/09/2007 6:54 PM, Evan Cooch wrote:
> Thanks, but  there is nothing in section 9.2.2 that mentions seq(x,y,z) 
> or anything close in a for loop.  All it says is (basically):
> 
> 
> There is also a for loop construction which has the form
>  > for (name in expr_1) expr_2
> where name is the loop variable. expr 1 is a vector expression, (often a 
> sequence like 1:20), and
> expr 2 is often a grouped expression with its sub-expressions written in 
> terms of the dummy
> name. expr 2 is repeatedly evaluated as name ranges through the values 
> in the vector result of
> expr 1.
> 
> Moreover, I would have assumed it would be in the language definition 
> file (not that I could find - I did check),

You seem to be assuming the language is different than it is.  To do the 
loop you want, you construct the vector of values you want to loop over, 
and loop over it.  There's no specific syntax for that, because there's 
no need for it.  There's just a for loop that loops over a general 
vector.  You can put anything you want in that vector.

  the reference manual (nada),
> and so forth. If someone can point to the precise page in one of the 
> standard - distributed - bits of R documentation the specifically says 
> 'here is how you use a non-unity incremental counter in an iterative 
> loop in R', with an example, I'll stand corrected.

I'd look for that sort of thing in a tutorial on "R for programmers who 
already know XYZ" (for your particular choice of XYZ), if I didn't find 
it in the language reference.  Or ask on R-help, which you did, and you 
got the answer you were looking for.

Duncan Murdoch

> 
> Duncan Murdoch wrote:
>> On 21/09/2007 4:20 PM, Evan Cooch wrote:
>>> Paul Hiemstra wrote:
>>>> Hi,
>>>>
>>>> This works:
>>>>
>>>> for(i in seq(1,100,5)) {
>>>> print(i)
>>>> }
>>>>
>>>> Very similar to the way python does this kind of loop.
>>>>
>>> Indeed it is - thanks for the tip. I'm still puzzled why I can't find 
>>> a single piece of the standard [R] language documentation that shows 
>>> this. In contrast, every single other language I use (more than I 
>>> care to admit), and documentation for same, feature this prominently 
>>> when they talk about looping.
>> It's in "9.2.2 Repetitive execution: for loops, repeat and while" of 
>> the Introduction to R manual. That's a good manual to read if you're 
>> looking for an introduction to R.
>>
>> Duncan Murdoch
>>
>>


From cooch17 at verizon.net  Sat Sep 22 01:41:25 2007
From: cooch17 at verizon.net (Evan Cooch)
Date: Fri, 21 Sep 2007 19:41:25 -0400
Subject: [R] really dumb question | loop counters in
In-Reply-To: <46F45079.8090506@stats.uwo.ca>
References: <46F3EA97.8020708@verizon.net> <46F3EFD8.2010703@geo.uu.nl>
	<46F42770.80403@verizon.net> <46F43D3E.9030207@stats.uwo.ca>
	<46F44B8F.9040005@verizon.net> <46F45079.8090506@stats.uwo.ca>
Message-ID: <46F456A5.5060406@verizon.net>



Duncan Murdoch wrote:
> On 21/09/2007 6:54 PM, Evan Cooch wrote:
>> Thanks, but  there is nothing in section 9.2.2 that mentions 
>> seq(x,y,z) or anything close in a for loop.  All it says is (basically):
>>
>>
>> There is also a for loop construction which has the form
>>  > for (name in expr_1) expr_2
>> where name is the loop variable. expr 1 is a vector expression, 
>> (often a sequence like 1:20), and
>> expr 2 is often a grouped expression with its sub-expressions written 
>> in terms of the dummy
>> name. expr 2 is repeatedly evaluated as name ranges through the 
>> values in the vector result of
>> expr 1.
>>
>> Moreover, I would have assumed it would be in the language definition 
>> file (not that I could find - I did check),
>
> You seem to be assuming the language is different than it is.  To do 
> the loop you want, you construct the vector of values you want to loop 
> over, and loop over it.  There's no specific syntax for that, because 
> there's no need for it.  There's just a for loop that loops over a 
> general vector.  You can put anything you want in that vector.
>
>
Point being, the documentation makes the implicit assumption that the 
new user will immediately recognize that the argument is a vector, and 
how to specify the sequence over the vector. This is a good example of 
what I call obtuse documentation (having written ~1100 pages of 
documentation for various opensource programs, I'm sort of sensitive to 
this).

Regardless, thanks for your help.


From jholtman at gmail.com  Sat Sep 22 02:00:38 2007
From: jholtman at gmail.com (jim holtman)
Date: Fri, 21 Sep 2007 20:00:38 -0400
Subject: [R] problem with 'integrate'
In-Reply-To: <1D963223-C85A-4111-83E7-6461604A2E49@cornell.edu>
References: <1D963223-C85A-4111-83E7-6461604A2E49@cornell.edu>
Message-ID: <644e1f320709211700r32f42279l2d8f2cf22dc2deba@mail.gmail.com>

?try

This will catch the error and let you take alternative action.

On 9/21/07, Dan Rabosky <dlr32 at cornell.edu> wrote:
>
> Hello -
>
> I am having a problem with the function 'integrate'.  I am running R
> on OSX (R 2.5.1).
>
> I am trying to suppress the error message when 'integrate' attempts
> to integrate across a parameter set giving a non-finite function
> value.  I'm using it in a MCMC / simulated annealing algorithm, and
> it is entirely possible that some parameter sets will give non-
> integrable functions.  I thought that the argument
>
> stop.on.error = FALSE
>
> would cause the function to return NA or at least not return an error
> (I can work around the situation where integrate returns garbage, but
> if it generates an error, it terminates my chain and all appears lost).
>
> This may not be necessary, but here is a simplification of an
> instance that generates the error.  If you send any B > 500 to
> "questionableFunction", the integration fails and returns an error
> message - even with stop.on.error = FALSE.  Is there any way I can
> work around this?  Perhaps there is something similar to
> "suppressWarnings()" that I might be able to use?
>
> questionableFunction <- function(B = 10)
> {
>        fx4 <- function(B, y, z){
>                1 + exp(B*y - B*z);
>         }
>
>        fx1 <- function(x, r0 = 0.12, k=-0.10, a=0.5, tshift=8.36){
>                (r0*exp(r0*t0 + (k/B)*log(fx4(B, t0, tshift)) - r0*x - (k/B)*log(fx4
> (B, x, tshift))))
>        }
>
>        integrate(fx1, 8.36, 10, stop.on.error = FALSE);
> }
>
>
>
> Thanks in advance for your help...
>
> Dan Rabosky
> Department of Ecology and Evolutionary Biology &
> Fuller Evolutionary Biology Program
> Cornell Lab of Ornithology
> Cornell University
> Ithaca, NY 14853-2701
>
>
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From murdoch at stats.uwo.ca  Sat Sep 22 02:15:58 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 21 Sep 2007 20:15:58 -0400
Subject: [R] really dumb question | loop counters in
In-Reply-To: <46F456A5.5060406@verizon.net>
References: <46F3EA97.8020708@verizon.net> <46F3EFD8.2010703@geo.uu.nl>
	<46F42770.80403@verizon.net> <46F43D3E.9030207@stats.uwo.ca>
	<46F44B8F.9040005@verizon.net> <46F45079.8090506@stats.uwo.ca>
	<46F456A5.5060406@verizon.net>
Message-ID: <46F45EBE.1050907@stats.uwo.ca>

On 21/09/2007 7:41 PM, Evan Cooch wrote:
> 
> Duncan Murdoch wrote:
>> On 21/09/2007 6:54 PM, Evan Cooch wrote:
>>> Thanks, but  there is nothing in section 9.2.2 that mentions 
>>> seq(x,y,z) or anything close in a for loop.  All it says is (basically):
>>>
>>>
>>> There is also a for loop construction which has the form
>>>  > for (name in expr_1) expr_2
>>> where name is the loop variable. expr 1 is a vector expression, 
>>> (often a sequence like 1:20), and
>>> expr 2 is often a grouped expression with its sub-expressions written 
>>> in terms of the dummy
>>> name. expr 2 is repeatedly evaluated as name ranges through the 
>>> values in the vector result of
>>> expr 1.
>>>
>>> Moreover, I would have assumed it would be in the language definition 
>>> file (not that I could find - I did check),
>> You seem to be assuming the language is different than it is.  To do 
>> the loop you want, you construct the vector of values you want to loop 
>> over, and loop over it.  There's no specific syntax for that, because 
>> there's no need for it.  There's just a for loop that loops over a 
>> general vector.  You can put anything you want in that vector.
>>
>>
> Point being, the documentation makes the implicit assumption that the 
> new user will immediately recognize that the argument is a vector, and 
> how to specify the sequence over the vector.

That's no assumption:  it's stated explicitly, even with an example 
"expr 1 is a vector expression, (often a sequence like 1:20)".

There is an assumption that this isn't the only part of the 
documentation you've read, that you're familiar with the basics of the 
language, but don't know how to do loops.  How to construct regular 
sequences was defined way back in section 2.2.

It's a difficult problem to write documentation for people who already 
know another language.  They already know how to do things, so they 
don't want to read from the beginning:  it's too boring.  But they also 
bring misconceptions with them, like the idea that a loop with a 
non-integer step size should be something supported by the syntax of the 
language.

I would not choose to add an example here using seq() (why that 
particular example?  why not loop over the letters of the alphabet, or 
the states in the US, or the components of a complex list?  We don't 
want people to think for loops are as limited as in some other 
languages).  Perhaps stating explicitly that you can construct the 
expr_1 vector any way you like would be good.

If you want to contribute a rewrite of that section of the manual, you 
can get the original from 
https://svn.r-project.org/R/trunk/doc/manual/R-intro.texi.  I'll take a 
look at whatever you write, and commit it if it looks better than what's 
there.  (If I don't commit, I'll tell you why not.)

  This is a good example of
> what I call obtuse documentation (having written ~1100 pages of 
> documentation for various opensource programs, I'm sort of sensitive to 
> this).

There's no question the documentation for R could be improved.

Duncan Murdoch


From ecjbosu at aol.com  Sat Sep 22 03:36:50 2007
From: ecjbosu at aol.com (Joe W. Byers)
Date: Fri, 21 Sep 2007 20:36:50 -0500
Subject: [R] RJDBC and rjava
In-Reply-To: <46666288.9050309@gmx.net>
References: <BAY110-F40EEFEF56E9A5E0AA777BDC7200@phx.gbl>
	<46666288.9050309@gmx.net>
Message-ID: <fd1rk2$2ou$1@sea.gmane.org>

I am having trouble getting RJDBC and rJava working.  rjava does not
seem to be able to traverse my classpath that I define inside R.

My example is
library(RJDBC)
.jinit('C:\\Libraries\\mysql-connector-java-5.1.3-rc\\mysql-connector-java-5.1.3-rc-bin.jar')
drv <- JDBC("com.mysql.jdbc.Driver",
'C:\\Libraries\\mysql-connector-java-5.1.3-rc\\mysql-connector-java-5.1.3-rc-bin.jar'
, identifier.quote ="`")


the call to JDBC and hence the call so jclassPath, cause the following error
Error in JDBC("com.mysql.jdbc.Driver",
"C:\\Libraries\\mysql-connector-java-5.1.3-rc\\mysql-connector-java-5.1.3-rc-bin.jar",
 :
        Cannot find JDBC driver class com.mysql.jdbc.Driver

Any help is greatly appreciated.

Thank you
Joe


From altuna.akalin at bccs.uib.no  Sat Sep 22 11:32:32 2007
From: altuna.akalin at bccs.uib.no (Altuna Akalin)
Date: Sat, 22 Sep 2007 11:32:32 +0200
Subject: [R] problem with generalized singular value decomposition using
	LAPACK
In-Reply-To: <Pine.LNX.4.64.0709200625340.27593@illuminati.stderr.org>
References: <1190276347.46f22cfb4242f@webmail.uib.no>
	<Pine.LNX.4.64.0709200625340.27593@illuminati.stderr.org>
Message-ID: <1190453552.46f4e13025cc1@webmail.uib.no>

Quoting elw at stderr.org:

> 
> > I'm trying to run generalized singular value decomposition (GSVD) 
> > function from LAPACK library. Basically my problem is that I can not run 
> > it for large matrices, I get a memory error. I'm using R 2.5.1.  I tried 
> > this on intel centos5 machines with 2 GB memory and 8 GB memory. I have 
> > unlimited max memory,cpu time and virtual memory.
> >
> >>  res=GSVD( matrix(1:35000,5000,6), matrix(1:35000,5000,6)  ) #runs 
> >> without
> > problems
> >>  res=GSVD( matrix(1:36000,6000,6), matrix(1:36000,6000,6)  )
> > Error: cannot allocate vector of size 274.7 Mb
> 
> 
> Did you examine R's internal memory limits, e.g. ?memory for help...
> 
> that should help.  [You should, most likely, be able to allocate a ~274MB 
> vector on a 2GB machine... but you might have to coerce R into taking that 
> much memory from the system, rather than trying to be conservative.]
> 
> --elijah
> 

Hi Elijah,
Thanks for your reply. I checked internal memory limits and it seems there is no
maxima set for consecutive cells or vector heap so i guess only limit is machine
resources. Also I set the "--max-ppsize" to the maximum value allowed with the
hope that it might help, it didn't change, still can not allocate memory. Below
I pasted ulimit -a output, maybe it helps for diagnostics. Further more, I
changed the stack size to "unlimited", that didn't help either.

core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
max nice                        (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 32759
max locked memory       (kbytes, -l) 32
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
max rt priority                 (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 32759
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited

cheers
altuna


From epistat at gmail.com  Sat Sep 22 11:34:02 2007
From: epistat at gmail.com (zhijie zhang)
Date: Sat, 22 Sep 2007 17:34:02 +0800
Subject: [R] How to explain the meaning of mu in the variance function of
	GLMs?
Message-ID: <2fc17e30709220234w3e33e83ao12676167d9729b6a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070922/b330156a/attachment.pl 

From Joao.Fadista at agrsci.dk  Sat Sep 22 14:46:34 2007
From: Joao.Fadista at agrsci.dk (=?iso-8859-1?Q?Jo=E3o_Fadista?=)
Date: Sat, 22 Sep 2007 14:46:34 +0200
Subject: [R] Significance in Count data
Message-ID: <EA09C4B2B0F16E44B8F3311629493C0D02EDB0A8@DJFPOST01.djf.agrsci.dk>

Dear all,
 
I have some count data and I would like to know how can I assess which are the items in my dataset that have a count significantly smaller or bigger than I would expect (each item with the same number of counts, i.e. from a uniform distribution).
 
Example file: 
 
 Item  Count
A0001    48
A0002    39
A0003    28
A0004    16
A0005    13
A0006    2   
...            ...
A9999    15
 
 
Best regards,
Jo?o Fadista
 
 


From Charles.Annis at StatisticalEngineering.com  Sat Sep 22 16:48:31 2007
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Sat, 22 Sep 2007 10:48:31 -0400
Subject: [R] Adding a table to a plot area
In-Reply-To: <46F448B3.6040202@vanderbilt.edu>
References: <315698.89149.qm@web34705.mail.mud.yahoo.com>
	<46F448B3.6040202@vanderbilt.edu>
Message-ID: <02be01c7fd27$a5730940$6400a8c0@DD4XFW31>


Professor Harrell:

I'm one of the slow kids and am having trouble following instructions, which
state, in part:

Download fragmaster.pl from 
http://www.tat.physik.uni-tuebingen.de/~vogel/fragmaster/main.html 
and save it in ~/bin and chmod a+x fragmaster.pl

Finding fragmaster.pl was easy, as was saving it to ~/bin in my R2.5.0
folder.

A search for "chmod" returned only "chmod.al" in my folder 
C:\Program Files\Perl\lib\auto\POSIX



Not surprisingly running the script is unsuccessful:
> library(Hmisc)
> postscript('psfrag2_fm.eps', pointsize=12,
+            onefile=FALSE, paper='special',
+            horizontal=FALSE, height=4, width=5)
> par(mar=c(3, 3.25, .25, .5), lwd=1.5, mgp = c(2, 0.45, 0), tcl = -0.4)
> 
> x <- seq(0,15,length=100)
> plot(x, dchisq(x, 5), ylab='fx', type='l')   # fx will be substituted by
$f(x)$
> text(10, .13, 'ww', adj=0)  # LaTeX table will be put at location of ww in
graph
> dev.off()
null device 
          1 
> 
> x <- cbind(Age=format(c(23.0,9.7)), Sex=c('Male','Female'))
> tab <- latexTabular(x, align='rl')  # new function in Hmisc
Error: could not find function "latexTabular"
> 
> cat('\\psfrag{ww}{\\small', tab, '}',
+     '\\psfrag{fx}{$f(x)$}',
+     sep='\n', file='psfrag2_fm')
Error in cat("\\psfrag{ww}{\\small", tab, "}", "\\psfrag{fx}{$f(x)$}",  : 
        object "tab" not found
> 
> system('fragmaster.pl psfrag2')
Warning message:
Impossible to run C:\PROGRA~1\R\R-25~1.0\bin\FRAGMA~1.PL psfrag2 
>


Please help me do whatever this means:
" ... save it in ~/bin and chmod a+x fragmaster.pl"
                           ^^^^^^^^^^^^^^^^^^^^^^^

Thanks.

Charles Annis, P.E.

System Details:
R2.5.0 running on a DELL 3GHz Pentium 4, 2 Gig RAM, WinXP service pack 2



Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  614-455-3265
http://www.StatisticalEngineering.com
 

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Frank E Harrell Jr
Sent: Friday, September 21, 2007 6:42 PM
To: Judith Flores
Cc: RHelp
Subject: Re: [R] Adding a table to a plot area

Judith Flores wrote:
> Is there a command to insert a table into the plot
> area other that using text?
> 
> Thank you.

To me the only completely satisfying approach is to use LaTeX and psfrag 
in you want great alignment and other features.  A howto with R is at 
http://biostat.mc.vanderbilt.edu/PsFrag .  This uses the fragmaster perl 
script which runs LaTeX from within R to make the final graphics file 
self-contained.

Frank

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From f.harrell at vanderbilt.edu  Sat Sep 22 17:38:33 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sat, 22 Sep 2007 10:38:33 -0500
Subject: [R] Adding a table to a plot area
In-Reply-To: <02be01c7fd27$a5730940$6400a8c0@DD4XFW31>
References: <315698.89149.qm@web34705.mail.mud.yahoo.com>
	<46F448B3.6040202@vanderbilt.edu>
	<02be01c7fd27$a5730940$6400a8c0@DD4XFW31>
Message-ID: <46F536F9.2020204@vanderbilt.edu>

Charles Annis, P.E. wrote:
> Professor Harrell:
> 
> I'm one of the slow kids and am having trouble following instructions, which
> state, in part:
> 
> Download fragmaster.pl from 
> http://www.tat.physik.uni-tuebingen.de/~vogel/fragmaster/main.html 
> and save it in ~/bin and chmod a+x fragmaster.pl
> 
> Finding fragmaster.pl was easy, as was saving it to ~/bin in my R2.5.0
> folder.
> 
> A search for "chmod" returned only "chmod.al" in my folder 
> C:\Program Files\Perl\lib\auto\POSIX

The how-to is only for Linux/Unix/Mac OSX.  Someone will have to 
translate for Windows.  All of this should run fine in Windows if you 
install Perl and LaTeX but there are issues with paths, etc.

Frank

> 
> 
> 
> Not surprisingly running the script is unsuccessful:
>> library(Hmisc)
>> postscript('psfrag2_fm.eps', pointsize=12,
> +            onefile=FALSE, paper='special',
> +            horizontal=FALSE, height=4, width=5)
>> par(mar=c(3, 3.25, .25, .5), lwd=1.5, mgp = c(2, 0.45, 0), tcl = -0.4)
>>
>> x <- seq(0,15,length=100)
>> plot(x, dchisq(x, 5), ylab='fx', type='l')   # fx will be substituted by
> $f(x)$
>> text(10, .13, 'ww', adj=0)  # LaTeX table will be put at location of ww in
> graph
>> dev.off()
> null device 
>           1 
>> x <- cbind(Age=format(c(23.0,9.7)), Sex=c('Male','Female'))
>> tab <- latexTabular(x, align='rl')  # new function in Hmisc
> Error: could not find function "latexTabular"
>> cat('\\psfrag{ww}{\\small', tab, '}',
> +     '\\psfrag{fx}{$f(x)$}',
> +     sep='\n', file='psfrag2_fm')
> Error in cat("\\psfrag{ww}{\\small", tab, "}", "\\psfrag{fx}{$f(x)$}",  : 
>         object "tab" not found
>> system('fragmaster.pl psfrag2')
> Warning message:
> Impossible to run C:\PROGRA~1\R\R-25~1.0\bin\FRAGMA~1.PL psfrag2 
> 
> 
> Please help me do whatever this means:
> " ... save it in ~/bin and chmod a+x fragmaster.pl"
>                            ^^^^^^^^^^^^^^^^^^^^^^^
> 
> Thanks.
> 
> Charles Annis, P.E.
> 
> System Details:
> R2.5.0 running on a DELL 3GHz Pentium 4, 2 Gig RAM, WinXP service pack 2
> 
> 
> 
> Charles.Annis at StatisticalEngineering.com
> phone: 561-352-9699
> eFax:  614-455-3265
> http://www.StatisticalEngineering.com
>  
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf Of Frank E Harrell Jr
> Sent: Friday, September 21, 2007 6:42 PM
> To: Judith Flores
> Cc: RHelp
> Subject: Re: [R] Adding a table to a plot area
> 
> Judith Flores wrote:
>> Is there a command to insert a table into the plot
>> area other that using text?
>>
>> Thank you.
> 
> To me the only completely satisfying approach is to use LaTeX and psfrag 
> in you want great alignment and other features.  A howto with R is at 
> http://biostat.mc.vanderbilt.edu/PsFrag .  This uses the fragmaster perl 
> script which runs LaTeX from within R to make the final graphics file 
> self-contained.
> 
> Frank
>


From mrsungsu at yahoo.com  Sat Sep 22 18:06:44 2007
From: mrsungsu at yahoo.com (sungsu kim)
Date: Sat, 22 Sep 2007 09:06:44 -0700 (PDT)
Subject: [R] error messages
Message-ID: <876899.75014.qm@web59211.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070922/bfbe6dd7/attachment.pl 

From dingjun_cn at yahoo.com  Sat Sep 22 18:11:29 2007
From: dingjun_cn at yahoo.com (Jun Ding)
Date: Sat, 22 Sep 2007 09:11:29 -0700 (PDT)
Subject: [R] A weird observation from using read.table
Message-ID: <664501.51599.qm@web81004.mail.mud.yahoo.com>

Hi Everyone, 

Recently I got puzzled by the function read.table,
even though I have used it for a long time. 

I have such a file (tmp.txt, 2 rows and 3 columns,
with a space among columns):

1 2'-PDE 4
2 3'-PDE 5

if I do:
a = read.table("tmp.txt", header = F, quote = "")
a
  V1     V2 V3
1  1 2'-PDE  4
2  2 3'-PDE  5

Everything is fine. 

However, if I do:
a = read.table("tmp.txt", header = F)
a
  V1     V2 V3
1  2 3'-PDE  5
2  1 2'-PDE  4
3  2 3'-PDE  5

I know it is related to the "quote" as the default
includes '. But how can it get one more row in the
file? Thank you very much for your help in advance!

Jun


From cberry at tajo.ucsd.edu  Sat Sep 22 19:13:33 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Sat, 22 Sep 2007 10:13:33 -0700
Subject: [R] really dumb question | loop counters in
In-Reply-To: <46F45EBE.1050907@stats.uwo.ca>
References: <46F3EA97.8020708@verizon.net> <46F3EFD8.2010703@geo.uu.nl>
	<46F42770.80403@verizon.net> <46F43D3E.9030207@stats.uwo.ca>
	<46F44B8F.9040005@verizon.net> <46F45079.8090506@stats.uwo.ca>
	<46F456A5.5060406@verizon.net> <46F45EBE.1050907@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0709220918290.30418@tajo.ucsd.edu>

On Fri, 21 Sep 2007, Duncan Murdoch wrote:

> On 21/09/2007 7:41 PM, Evan Cooch wrote:
>>
>> Duncan Murdoch wrote:
>>> On 21/09/2007 6:54 PM, Evan Cooch wrote:
>>>> Thanks, but  there is nothing in section 9.2.2 that mentions
>>>> seq(x,y,z) or anything close in a for loop.  All it says is (basically):
>>>>
>>>>
>>>> There is also a for loop construction which has the form
>>>> > for (name in expr_1) expr_2
>>>> where name is the loop variable. expr 1 is a vector expression,
>>>> (often a sequence like 1:20), and
>>>> expr 2 is often a grouped expression with its sub-expressions written
>>>> in terms of the dummy
>>>> name. expr 2 is repeatedly evaluated as name ranges through the
>>>> values in the vector result of
>>>> expr 1.
>>>>
>>>> Moreover, I would have assumed it would be in the language definition
>>>> file (not that I could find - I did check),
>>> You seem to be assuming the language is different than it is.  To do
>>> the loop you want, you construct the vector of values you want to loop
>>> over, and loop over it.  There's no specific syntax for that, because
>>> there's no need for it.  There's just a for loop that loops over a
>>> general vector.  You can put anything you want in that vector.
>>>
>>>
>> Point being, the documentation makes the implicit assumption that the
>> new user will immediately recognize that the argument is a vector, and
>> how to specify the sequence over the vector.
>
> That's no assumption:  it's stated explicitly, even with an example
> "expr 1 is a vector expression, (often a sequence like 1:20)".
>

Moreover, there are help pages that usually have explicit examples that a 
user can run to get a better sense of semantics and helpful constructions:

 	example("for")

will run the two examples on the "Control Flow" help page which

 	help("for")

will access.

Those examples seem to me to address the new user's need to "recognize 
that the argument is a vector, and how to specify the sequence over the 
vector" succinctly.

---

Mindful of the dictum of that 'the source code is the ultimate reference' 
(to which dictum I have no reference), there are about 10 instances of 
'seq( from, to, by )' found among 37 found with

  find ./R-beta/src -type f -name "*.R" -print0 | xargs -0 -e grep -n -e  "for[ ]*[(][^(]*seq[(]"

of almost 1800 instances found with just "for[ ]*[(]", which you may 
consult for useful hints about constructing for loops.

:-)

[rest deleted]

Chuck

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From morphwj at comcast.net  Sat Sep 22 21:59:43 2007
From: morphwj at comcast.net (morphwj at comcast.net)
Date: Sat, 22 Sep 2007 19:59:43 +0000
Subject: [R] R Extensions: Hyperlinking a pdf (not generated by Sweave/not a
	vignette) from a .Rd file
Message-ID: <092220071959.5193.46F5742F0009FC9B0000144922007348300699089F9D0103@comcast.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070922/4499a095/attachment.pl 

From jm540 at york.ac.uk  Sat Sep 22 22:07:10 2007
From: jm540 at york.ac.uk (Jon Minton)
Date: Sat, 22 Sep 2007 21:07:10 +0100
Subject: [R] reshape() to wide with varying number of responses to fields
Message-ID: <010801c7fd54$28af3640$7a0da2c0$@ac.uk>

Hello,

I have a dataframe containing the following variables:

	PID, Field, Value

Where PID refers to a unique individual, Field to a particular question, and
Value to a particular response to a question.

I?d like this in wide format, with a different row for each PID.
However.... there are differing numbers of Values associated with each
Field, for each PID. 
For example, a Field question may be ?Which of the following are important
for you:? ? some people tick one box in response to it, other 3 or 4: thus
PID A might generate 3 Values for Field X, whereas PID B would only generate
1 Value:

PID	Field Value
A	X	a
A	X	b
A	X	c
B	X	b
Etc. 
What I?d like is a wide format, with one Pid per row, and enough columns for
each of the possible values the PID could provide for a particular field,
filled in with the values if they exist, or NAs if they don?t:

PID	X.1	X.2	X.3
A	a	b	c
B	b	NA	NA
Etc. 

I already know the maximum number of Values any PID has provided for each
Field (i.e. the maximum number of columns to allow for each Field response),
but don?t know how to create this dataframe using reshape (or if reshape is
the right function to use). 


Any help much appreciated. I?ve not seen a ?how-to? regarding this in the
archive.
Thanks, Jon




Checked by AVG Free Edition. 

20/09/2007
12:07
 


From thomas_schwander at web.de  Sat Sep 22 22:35:26 2007
From: thomas_schwander at web.de (Thomas Schwander)
Date: Sat, 22 Sep 2007 22:35:26 +0200
Subject: [R] R and Reuters 3000 Xtra.
Message-ID: <000c01c7fd58$1ba84370$6502a8c0@laptop>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070922/fe3e41b4/attachment.pl 

From h.wickham at gmail.com  Sun Sep 23 00:24:51 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sat, 22 Sep 2007 17:24:51 -0500
Subject: [R] reshape() to wide with varying number of responses to fields
In-Reply-To: <010801c7fd54$28af3640$7a0da2c0$@ac.uk>
References: <010801c7fd54$28af3640$7a0da2c0$@ac.uk>
Message-ID: <f8e6ff050709221524w3bc7a009h9beb2aa82599d1cb@mail.gmail.com>

Hi Jon,

You can do this with the reshape package.  Your data are already in
"molten" form, so you can just do:

cast(rename(df, c("Value" = "value"), PID ~ Field)

You can find out more about reshape at http://had.co.nz/reshape

Hadley

On 9/22/07, Jon Minton <jm540 at york.ac.uk> wrote:
> Hello,
>
> I have a dataframe containing the following variables:
>
>         PID, Field, Value
>
> Where PID refers to a unique individual, Field to a particular question, and
> Value to a particular response to a question.
>
> I'd like this in wide format, with a different row for each PID.
> However.... there are differing numbers of Values associated with each
> Field, for each PID.
> For example, a Field question may be "Which of the following are important
> for you:" ? some people tick one box in response to it, other 3 or 4: thus
> PID A might generate 3 Values for Field X, whereas PID B would only generate
> 1 Value:
>
> PID     Field Value
> A       X       a
> A       X       b
> A       X       c
> B       X       b
> Etc.
> What I'd like is a wide format, with one Pid per row, and enough columns for
> each of the possible values the PID could provide for a particular field,
> filled in with the values if they exist, or NAs if they don't:
>
> PID     X.1     X.2     X.3
> A       a       b       c
> B       b       NA      NA
> Etc.
>
> I already know the maximum number of Values any PID has provided for each
> Field (i.e. the maximum number of columns to allow for each Field response),
> but don't know how to create this dataframe using reshape (or if reshape is
> the right function to use).
>
>
> Any help much appreciated. I've not seen a 'how-to' regarding this in the
> archive.
> Thanks, Jon
>
>
>
>
> Checked by AVG Free Edition.
>
> 20/09/2007
> 12:07
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
http://had.co.nz/


From ripley at stats.ox.ac.uk  Sun Sep 23 09:38:34 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 23 Sep 2007 08:38:34 +0100 (BST)
Subject: [R] R Extensions: Hyperlinking a pdf (not generated by
 Sweave/not a vignette) from a .Rd file
In-Reply-To: <092220071959.5193.46F5742F0009FC9B0000144922007348300699089F9D0103@comcast.net>
References: <092220071959.5193.46F5742F0009FC9B0000144922007348300699089F9D0103@comcast.net>
Message-ID: <Pine.LNX.4.64.0709230817250.14911@gannet.stats.ox.ac.uk>

On Sat, 22 Sep 2007, morphwj at comcast.net wrote:

> When constructing an R extension, how can a hyperlink from an .Rd file 
> to a pdf (not generated by Sweave, so not a vignette) located in the 
> inst/doc folder be constructed?

With \url.

I presume you mean writing a package, and installing into the 'doc' 
subdirectory (which is what by default happens for anything in the 
inst/doc subdirectory _of the package sources_).  That would need 
\url{"../doc/something.pdf"}.

(There are extensions other than packages, which is why the manual is 
called 'Writing R Extensions.)

> Bill Morphet ATK, Space Launch Systems 
> Postflight Evaluation Eng
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From epistat at gmail.com  Sun Sep 23 09:53:37 2007
From: epistat at gmail.com (zhijie zhang)
Date: Sun, 23 Sep 2007 15:53:37 +0800
Subject: [R] return(x=x,y=y,prob=prob) hasn't been used in R now?
Message-ID: <2fc17e30709230053u52f4c41fp86d575a9bfcfe754@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070923/11dda6ec/attachment.pl 

From p.dalgaard at biostat.ku.dk  Sun Sep 23 10:36:12 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun, 23 Sep 2007 10:36:12 +0200
Subject: [R] return(x=x,y=y,prob=prob) hasn't been used in R now?
In-Reply-To: <2fc17e30709230053u52f4c41fp86d575a9bfcfe754@mail.gmail.com>
References: <2fc17e30709230053u52f4c41fp86d575a9bfcfe754@mail.gmail.com>
Message-ID: <46F6257C.8060503@biostat.ku.dk>

zhijie zhang wrote:
> Dear friends,
>  Now, when i use the argument return(x=x,y=y,prob=prob) , R  displays the
> waring message:
> Warning message:
> The return value for multiple variables wasn't used  in: return(x = x, y =
> gy, prob = prob)
>  I used the methods of  "help.search("return")" and "?return" to get some
> help, but didn't find info on it.
>  Anybody knows how it should be used correctly?
>   
Return(value) takes only one argument. To return a list, 
return(list(x=x,y=y,prob=prob))

I bet the author of help(return) thought that this was implied clearly 
enough.

> #EXAMPLES
> a<-function(x,y,z)
>  {
>   gx<-seq(1,10,length.out=20)
>   gy<-gx
>   prob<-matrix(20,20)
>   for (i in 1:20)
>    {
>     for (j in 1:20)
>      {
>       prob<-0.1
>      }
>    }
>  return(x=gx,y=gy,prob=prob)
>  }
>
> a(1,1,1)  # the warning message will display
>  Thanks.
>
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ritz at life.ku.dk  Sun Sep 23 11:27:52 2007
From: ritz at life.ku.dk (Christian Ritz)
Date: Sun, 23 Sep 2007 11:27:52 +0200
Subject: [R] return(x=x,y=y,prob=prob) hasn't been used in R now?
In-Reply-To: <2fc17e30709230053u52f4c41fp86d575a9bfcfe754@mail.gmail.com>
References: <2fc17e30709230053u52f4c41fp86d575a9bfcfe754@mail.gmail.com>
Message-ID: <46F63198.6030207@life.ku.dk>

Hi!

Use a list structure for all the components you want to have returned 
by the function:


return(list(x=x, y=y, prob=prob))



Christian


From epistat at gmail.com  Sun Sep 23 13:18:51 2007
From: epistat at gmail.com (zhijie zhang)
Date: Sun, 23 Sep 2007 19:18:51 +0800
Subject: [R] return(x=x,y=y,prob=prob) hasn't been used in R now?
In-Reply-To: <46F63198.6030207@life.ku.dk>
References: <2fc17e30709230053u52f4c41fp86d575a9bfcfe754@mail.gmail.com>
	<46F63198.6030207@life.ku.dk>
Message-ID: <2fc17e30709230418t29410b04sa8033269f9054e22@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070923/1b514576/attachment.pl 

From ripley at stats.ox.ac.uk  Sun Sep 23 14:03:04 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 23 Sep 2007 13:03:04 +0100 (BST)
Subject: [R] return(x=x,y=y,prob=prob) hasn't been used in R now?
In-Reply-To: <46F6257C.8060503@biostat.ku.dk>
References: <2fc17e30709230053u52f4c41fp86d575a9bfcfe754@mail.gmail.com>
	<46F6257C.8060503@biostat.ku.dk>
Message-ID: <Pine.LNX.4.64.0709231216430.17535@gannet.stats.ox.ac.uk>

On Sun, 23 Sep 2007, Peter Dalgaard wrote:

> zhijie zhang wrote:
>> Dear friends,
>>  Now, when i use the argument return(x=x,y=y,prob=prob) , R  displays the
>> waring message:
>> Warning message:
>> The return value for multiple variables wasn't used  in: return(x = x, y =
>> gy, prob = prob)
>>  I used the methods of  "help.search("return")" and "?return" to get some
>> help, but didn't find info on it.
>>  Anybody knows how it should be used correctly?
>>
> Return(value) takes only one argument. To return a list,
> return(list(x=x,y=y,prob=prob))
>
> I bet the author of help(return) thought that this was implied clearly
> enough.

and the warning message in English is not what is quoted here:

> f <- function() return(x=pi, y=pi)
> f()
$x
[1] 3.141593

$y
[1] 3.141593

Warning message:
In return(x = pi, y = pi) : multi-argument returns are deprecated

so they are in fact used.  What is puzzling is that anyone is still trying 
to use them years after they were deprecated (and as the help page says 
they were never documented in S, quite how they ever got into circulation 
in R).


>
>> #EXAMPLES
>> a<-function(x,y,z)
>>  {
>>   gx<-seq(1,10,length.out=20)
>>   gy<-gx
>>   prob<-matrix(20,20)
>>   for (i in 1:20)
>>    {
>>     for (j in 1:20)
>>      {
>>       prob<-0.1
>>      }
>>    }
>>  return(x=gx,y=gy,prob=prob)
>>  }
>>
>> a(1,1,1)  # the warning message will display
>>  Thanks.
>>
>>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From xingwang.ye at gmail.com  Sun Sep 23 10:38:19 2007
From: xingwang.ye at gmail.com (Xingwang Ye)
Date: Sun, 23 Sep 2007 16:38:19 +0800
Subject: [R] Any functions available for significant increment in R-square?
Message-ID: <46F625FB.3000703@gmail.com>

Dear all,
Are there any functions available for calculate significant increment in 
R-square?
Following is a link for what's "significant increment in R2".
 http://www.psy.jhu.edu/~ashelton/courses/stats315/week2.pdf

Thank you.

Yours, sincerely,
Xingwang Ye


From nj7w at yahoo.com  Sun Sep 23 15:09:05 2007
From: nj7w at yahoo.com (Nitin Jain)
Date: Sun, 23 Sep 2007 06:09:05 -0700 (PDT)
Subject: [R] saving results under specified file name
Message-ID: <214268.90430.qm@web50202.mail.re2.yahoo.com>

Hello,

I would like to save the results in a specified file name.  Here is a test example:
 

aa <- function(xx, newname) {
 yy <- xx^2
    rdName <- file.path(paste(newname, ".RData", sep = ""))
    assign(eval(newname), yy)
save(newname, file=rdName) ## FIXME
}


aa(3, "test")

load("test.RData")
ls() 

I would like to see test (which should store 9) rather than newname (which stores "test")

Please let me know how to do this.

Thanks.
-Nitin



      _________________________________________________________________________________
stings, and more!
http://tv.yahoo.com/collections/3658


From epistat at gmail.com  Sun Sep 23 16:03:22 2007
From: epistat at gmail.com (zhijie zhang)
Date: Sun, 23 Sep 2007 22:03:22 +0800
Subject: [R] return(x=x,y=y,prob=prob) hasn't been used in R now?
In-Reply-To: <Pine.LNX.4.64.0709231216430.17535@gannet.stats.ox.ac.uk>
References: <2fc17e30709230053u52f4c41fp86d575a9bfcfe754@mail.gmail.com>
	<46F6257C.8060503@biostat.ku.dk>
	<Pine.LNX.4.64.0709231216430.17535@gannet.stats.ox.ac.uk>
Message-ID: <2fc17e30709230703rcd471fasdb11a99813dad222@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070923/037f24f5/attachment.pl 

From f.harrell at vanderbilt.edu  Sun Sep 23 16:11:31 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sun, 23 Sep 2007 09:11:31 -0500
Subject: [R] saving results under specified file name
In-Reply-To: <214268.90430.qm@web50202.mail.re2.yahoo.com>
References: <214268.90430.qm@web50202.mail.re2.yahoo.com>
Message-ID: <46F67413.3030402@vanderbilt.edu>

Nitin Jain wrote:
> Hello,
> 
> I would like to save the results in a specified file name.  Here is a test example:
>  
> 
> aa <- function(xx, newname) {
>  yy <- xx^2
>     rdName <- file.path(paste(newname, ".RData", sep = ""))
>     assign(eval(newname), yy)
> save(newname, file=rdName) ## FIXME
> }
> 
> 
> aa(3, "test")
> 
> load("test.RData")
> ls() 
> 
> I would like to see test (which should store 9) rather than newname (which stores "test")
> 
> Please let me know how to do this.
> 
> Thanks.
> -Nitin

FYI see also the Save and Load functions in the Hmisc package. -Frank

> 
> 
> 
>       _________________________________________________________________________________
> stings, and more!
> http://tv.yahoo.com/collections/3658
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From lehtonen.aleksi at gmail.com  Sun Sep 23 16:17:52 2007
From: lehtonen.aleksi at gmail.com (Aleksi Lehtonen)
Date: Sun, 23 Sep 2007 17:17:52 +0300
Subject: [R] nls fits by groups
Message-ID: <cef24c990709230717g25a69909ud4952618a7e05c6f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070923/3b60a37c/attachment.pl 

From kate at few.vu.nl  Sun Sep 23 16:46:56 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Sun, 23 Sep 2007 16:46:56 +0200 (CEST)
Subject: [R] nls fits by groups
In-Reply-To: <cef24c990709230717g25a69909ud4952618a7e05c6f@mail.gmail.com>
References: <cef24c990709230717g25a69909ud4952618a7e05c6f@mail.gmail.com>
Message-ID: <Pine.GSO.4.56.0709231632140.4133@laurel.few.vu.nl>

It is not clear from your post what changes per-group.  If only the
starting values change (but the data and the model structure are the
same), then you can just store the starting values you want to use for
each group in a list, and then index into this list in your call to nls.

e.g., modifying an example in the help page for nls:

x <- 1:10
y <- 2*x + 3                            # perfect fit
yeps <- y + rnorm(length(y), sd = 0.01) # added noise

startlist <- list(
         list(a = 0.12345, b = 0.54321), ##group 1 start val
         list(a = 0.12, b = 0.54) ## group 2 start val.
	         )
reslist <- list() ## filling this with results from different start val
for(i in 1:length(startlist)) {
     reslist[[i]]  <-  nls(yeps ~ a + b*x, start = startlist[[i]],
         trace = TRUE)
}

On Sun, 23 Sep 2007, Aleksi Lehtonen wrote:

> Dear Colleagues,
>
> I am trying to estimate several non-linear models simultaneously. I don't
> want to use non-linear mixed model, but non-linear model with same form, but
> it should be estimated separately according to variable group (I have lots
> of groups that have lots of observations....). I would like to have unique
> parameters for each group.
>
> e.g. something like this
>
> mod <- nls(y ~ a*x^b, start=c(a=1, b=1), group=group)
>
> but knowing that group option does not work. If someone has an idea (or has
> done it already) how to implement this either using just nls statement or by
> building a simple function in R, I would be very grateful for hints....
>
> regards, Aleksi Lehtonen
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From zhonglian at hotmail.com  Sun Sep 23 17:02:15 2007
From: zhonglian at hotmail.com (Zhang Honglian)
Date: Sun, 23 Sep 2007 15:02:15 +0000
Subject: [R] return(x=x,y=y,prob=prob) hasn't been used in R now?
In-Reply-To: <2fc17e30709230703rcd471fasdb11a99813dad222@mail.gmail.com>
Message-ID: <BAY110-F228E1008A6B326E61C26EEB1B50@phx.gbl>


   I don't know what exactly you want the program to do. But if you want to let
   the function to return several values in the same time, you have to put them
   into a list. E.g. in the following program, the function will return 4
   different things, x and y are vectors, prob is a matrix and p is a scalor.
   Hope this helps,

   Honglian

   a<-function(x,y)

   {

   gx<-seq(1,x,length.out=y)

   gy<-gx

   prob<-matrix(gy,nrow=2)

   for (i in 1:y)

   {

   for (j in 1:y) p<-0.1

   }

   lst<-list(x=gx,y=gy,prob=prob, p=p)

   return(lst)

   }

   b=a(10, 20)

       ______________________________________________________________

     From:  "zhijie zhang" <epistat at gmail.com>
     To:  "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
     CC:  R-help at stat.math.ethz.ch
     Subject:  Re: [R] return(x=x,y=y,prob=prob) hasn't been used in R now?
     Date:  Sun, 23 Sep 2007 22:03:22 +0800
     >Dear Prof. Brian Ripley,
     >   You are absolutely right. The warning message in R for my Chinese
     Windows
     >system is Chinese words, so i translate it into english, which maybe not
     >that exact  in the meanings.
     >   Thanks very much.
     >
     >
     >On 9/23/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
     > >
     > > On Sun, 23 Sep 2007, Peter Dalgaard wrote:
     > >
     > > > zhijie zhang wrote:
     > > >> Dear friends,
     >  >  >>  Now,  when i use the argument return(x=x,y=y,prob=prob) ,
     R  displays
     > > the
     > > >> waring message:
     > > >> Warning message:
     > > >> The return value for multiple variables wasn't used  in: return(x =
     x,
     > > y =
     > > >> gy, prob = prob)
     > > >>  I used the methods of  "help.search("return")" and "?return" to
     get
     > > some
     > > >> help, but didn't find info on it.
     > > >>  Anybody knows how it should be used correctly?
     > > >>
     > > > Return(value) takes only one argument. To return a list,
     > > > return(list(x=x,y=y,prob=prob))
     > > >
     > > > I bet the author of help(return) thought that this was implied
     clearly
     > > > enough.
     > >
     > > and the warning message in English is not what is quoted here:
     > >
     > > > f <- function() return(x=pi, y=pi)
     > > > f()
     > > $x
     > > [1] 3.141593
     > >
     > > $y
     > > [1] 3.141593
     > >
     > > Warning message:
     > > In return(x = pi, y = pi) : multi-argument returns are deprecated
     > >
     > > so they are in fact used.  What is puzzling is that anyone is still
     trying
     > > to use them years after they were deprecated (and as the help page
     says
     >  >  they were never documented in S, quite how they ever got into
     circulation
     > > in R).
     > >
     > >
     > > >
     > > >> #EXAMPLES
     > > >> a<-function(x,y,z)
     > > >>  {
     > > >>   gx<-seq(1,10,length.out=20)
     > > >>   gy<-gx
     > > >>   prob<-matrix(20,20)
     > > >>   for (i in 1:20)
     > > >>    {
     > > >>     for (j in 1:20)
     > > >>      {
     > > >>       prob<-0.1
     > > >>      }
     > > >>    }
     > > >>  return(x=gx,y=gy,prob=prob)
     > > >>  }
     > > >>
     > > >> a(1,1,1)  # the warning message will display
     > > >>  Thanks.
     > > >>
     > > >>
     > > >
     > > >
     > > >
     > >
     > > --
     > > Brian D. Ripley,                  ripley at stats.ox.ac.uk
     > > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
     > > University of Oxford,             Tel:  +44 1865 272861 (self)
     > > 1 South Parks Road,                     +44 1865 272866 (PA)
     > > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
     > >
     >
     >
     >
     >--
     >With Kind Regards,
     >
     >oooO:::::::::
     >(..):::::::::
     >:\.(:::Oooo::
     >::\_)::(..)::
     >:::::::)./:::
     >::::::(_/::::
     >:::::::::::::
     >[***********************************************************************]
     >Zhi Jie,Zhang ,PHD
     >Tel:86-21-54237149
     >Dept. of Epidemiology,School of Public Health,Fudan University
     >Address:No. 138 Yi Xue Yuan Road,Shanghai,China
     >Postcode:200032
     >Email:epistat at gmail.com
     >Website: www.statABC.com
     >[***********************************************************************]
     >oooO:::::::::
     >(..):::::::::
     >:\.(:::Oooo::
     >::\_)::(..)::
     >:::::::)./:::
     >::::::(_/::::
     >:::::::::::::
     >
     > [[alternative HTML version deleted]]
     >
     >______________________________________________
     >R-help at r-project.org mailing list
     >https://stat.ethz.ch/mailman/listinfo/r-help
     >PLEASE do read the posting guide
     http://www.R-project.org/posting-guide.html
     >and provide commented, minimal, self-contained, reproducible code.
     _________________________________________________________________

   FREE pop-up blocking with the new MSN Toolbar [1]MSN Toolbar Get it now!

References

   1. http://g.msn.com/8HMBEN/2755??PS=47575

From ripley at stats.ox.ac.uk  Sun Sep 23 17:14:37 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 23 Sep 2007 16:14:37 +0100 (BST)
Subject: [R] saving results under specified file name
In-Reply-To: <214268.90430.qm@web50202.mail.re2.yahoo.com>
References: <214268.90430.qm@web50202.mail.re2.yahoo.com>
Message-ID: <Pine.LNX.4.64.0709231610570.13818@gannet.stats.ox.ac.uk>

>From the help page for save:

Arguments:

      ...: the names of the objects to be saved (as symbols or character
           strings).

     list: A character vector containing the names of objects to be
           saved.

so you need save(list=newname, ...).


On Sun, 23 Sep 2007, Nitin Jain wrote:

> Hello,
>
> I would like to save the results in a specified file name.  Here is a 
> test example:
>
> aa <- function(xx, newname) {
> yy <- xx^2
>    rdName <- file.path(paste(newname, ".RData", sep = ""))
>    assign(eval(newname), yy)
> save(newname, file=rdName) ## FIXME
> }
>
>
> aa(3, "test")
>
> load("test.RData")
> ls()
>
> I would like to see test (which should store 9) rather than newname 
> (which stores "test")
>
> Please let me know how to do this.
>
> Thanks.
> -Nitin

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ggrothendieck at gmail.com  Sun Sep 23 17:17:07 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 23 Sep 2007 11:17:07 -0400
Subject: [R] nls fits by groups
In-Reply-To: <cef24c990709230717g25a69909ud4952618a7e05c6f@mail.gmail.com>
References: <cef24c990709230717g25a69909ud4952618a7e05c6f@mail.gmail.com>
Message-ID: <971536df0709230817k5c3c780an46bfc7b365a6472f@mail.gmail.com>

Check out the subset= argument to nls, e.g. to regress Sepal.Length
on Sepal.Width separately for each Species using the built in iris data set:

f <- function(s) nls(Sepal.Length ~ a*Sepal.Width, data = iris,
   start = c(a = 1), subset = iris$Species == s)
sapply(levels(iris$Species), f, simplify = FALSE)


On 9/23/07, Aleksi Lehtonen <lehtonen.aleksi at gmail.com> wrote:
> Dear Colleagues,
>
> I am trying to estimate several non-linear models simultaneously. I don't
> want to use non-linear mixed model, but non-linear model with same form, but
> it should be estimated separately according to variable group (I have lots
> of groups that have lots of observations....). I would like to have unique
> parameters for each group.
>
> e.g. something like this
>
> mod <- nls(y ~ a*x^b, start=c(a=1, b=1), group=group)
>
> but knowing that group option does not work. If someone has an idea (or has
> done it already) how to implement this either using just nls statement or by
> building a simple function in R, I would be very grateful for hints....
>
> regards, Aleksi Lehtonen
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.uni-dortmund.de  Sun Sep 23 17:46:41 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 23 Sep 2007 17:46:41 +0200
Subject: [R] help with rq
In-Reply-To: <20070921173344.B8967392856@keseel.uchile.cl>
References: <20070921173344.B8967392856@keseel.uchile.cl>
Message-ID: <46F68A61.4070305@statistik.uni-dortmund.de>



Vivian wrote:
> I used in 2004 an earlier version of R (1.6.0 ?) for quantile regressions
> 
>  
> 
> Now I downloaded version 2.5.1-win32 and I cannot A) read my old files (Our
> exel working space was saved in csv) and also the series of instructions
> does not work, see below (B) rq function is not recognized)


A) You can, but we do not know how your file looks like and hence cannot 
help without more information.
B) It works, if you have package quantreg installed and loaded.

Uwe Ligges


>  
> 
> filename <- read.csv("filename.csv",header=TRUE,row.names=1)
> 
> fit95 <-rq(y~a+b,data=filename,tau=.95)
> 
>  
> 
>  
> 
> Thanks in advance
> 
>  
> 
>  
> 
> Vivian Montecino
> 
> Dpto. Ciencias Ecol?gicas
> 
> Facultad de Ciencias
> 
> U de Chile
> 
> Casilla 653, Las Palmeras 3425
> 
> Santiago, Chile
> 
> tel  56-2-9787405
> 
> fax 56-2-2727363
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From zhonglian at hotmail.com  Sun Sep 23 18:15:52 2007
From: zhonglian at hotmail.com (Zhang Honglian)
Date: Sun, 23 Sep 2007 16:15:52 +0000
Subject: [R] find all objects of a particular class
In-Reply-To: <Pine.LNX.4.64.0709231610570.13818@gannet.stats.ox.ac.uk>
Message-ID: <BAY110-F237817F2C4E3075D4C85CAB1B50@phx.gbl>


   Hello,

   I would like to find all objects of a particular class. Is that possible to
   do so in R? I knew that in SPLUS, the function objects(class="classname")
   can do this. But in R, I cannot find the similar function to do so. Is there
   any way that I can distinguish where an object comes from? E.g. I defined a
   class "person". Then I generated three objects from it (e.g, Joe, Lee, Dan).
   I also have some other objects in the workspace (not from class "person").
   How do I suppose to know in the current workspace I have exactly three
   objects  (Joe,  Lee, Dan) from the class "person"? For example, in the
   following program, at the final step when I run objects(), it will give me
   not only "Joe" ""Lee" and "Dan", but also "x". If I run some other programs
   before this, I might have other objects too. How can I let R only give me
   "Joe" ""Lee" and "Dan"?

   Any help will be highly appreciated,

   Honglian

   setClass("person",

   representation(Name="character",

   PhoneNo="character", Address="character"))

   setMethod("show", "person",

   function(object)

   {

   x<- data.frame (Name=object at Name, PhoneNo=object at PhoneNo,

   Address=object at Address)

   print(x)

   }

   )

   Joe =  new("person", Name='Joe', PhoneNo='(210)481-5720', Address='San
   Antonio')

   Dan = new("person", Name='Dan', PhoneNo='(413)583-5202', Address='Boston')

   Lee = new("person", Name='Lee', PhoneNo='(519)837-1291', Address='Toronto')

   x <- objects()

   objects()
     _________________________________________________________________

   Express yourself instantly with MSN Messenger! [1]MSN Messenger Download
   today it's FREE!

References

   1. http://g.msn.com/8HMAEN/2737??PS=47575

From bartjoosen at hotmail.com  Sun Sep 23 19:56:04 2007
From: bartjoosen at hotmail.com (Bartjoosen)
Date: Sun, 23 Sep 2007 10:56:04 -0700 (PDT)
Subject: [R] A weird observation from using read.table
In-Reply-To: <664501.51599.qm@web81004.mail.mud.yahoo.com>
References: <664501.51599.qm@web81004.mail.mud.yahoo.com>
Message-ID: <12848830.post@talk.nabble.com>


Take a look at ?scan.

There is an explanation for the doubling of the string

Bart



Jun Ding wrote:
> 
> Hi Everyone, 
> 
> Recently I got puzzled by the function read.table,
> even though I have used it for a long time. 
> 
> I have such a file (tmp.txt, 2 rows and 3 columns,
> with a space among columns):
> 
> 1 2'-PDE 4
> 2 3'-PDE 5
> 
> if I do:
> a = read.table("tmp.txt", header = F, quote = "")
> a
>   V1     V2 V3
> 1  1 2'-PDE  4
> 2  2 3'-PDE  5
> 
> Everything is fine. 
> 
> However, if I do:
> a = read.table("tmp.txt", header = F)
> a
>   V1     V2 V3
> 1  2 3'-PDE  5
> 2  1 2'-PDE  4
> 3  2 3'-PDE  5
> 
> I know it is related to the "quote" as the default
> includes '. But how can it get one more row in the
> file? Thank you very much for your help in advance!
> 
> Jun
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/A-weird-observation-from-using-read.table-tf4501505.html#a12848830
Sent from the R help mailing list archive at Nabble.com.


From sabya231 at gmail.com  Sun Sep 23 20:19:02 2007
From: sabya231 at gmail.com (Tirthadeep)
Date: Sun, 23 Sep 2007 11:19:02 -0700 (PDT)
Subject: [R] glmpath: how to choose best lambda
Message-ID: <12849013.post@talk.nabble.com>



Hi all,

I am using glampath package for L1 regularized logistic regression. I have
read the article " L1 regularization path algorithm for GLM" by park and
Hastie (2006). One thing I can't understand that how to find best lambda for
my prediction. I want to use that lambda for the prediction not the entire
set.

thanks.
-- 
View this message in context: http://www.nabble.com/glmpath%3A-how-to-choose-best-lambda-tf4505338.html#a12849013
Sent from the R help mailing list archive at Nabble.com.


From ah06981 at studbocconi.it  Sun Sep 23 20:34:57 2007
From: ah06981 at studbocconi.it (ah06981 at studbocconi.it)
Date: Sun, 23 Sep 2007 20:34:57 +0200
Subject: [R] Correlated frailty model
Message-ID: <20070923203457.5w8ecvx2g48c8s4o@webmail.studbocconi.it>

Dear R-help,
I am trying to a estimate a correlated frailty model. My dataset is 
made up of 40000 observations. I would like to know if it is too big or 
I have done some mistakes in the following code.

group<-paste(usa$id,usa$mob)
mixed.logn<-coxme(Surv(yearspan)~ south+mod, data=usa,random= ~ 1|group)
Errore in matrix(0, dd[1], dd[2], dimnames = x at .Dimnames) :        non 
? possibile allocare un vettore di lunghezza 1600000000
(It is not possible to use a vector of leght 1600000000)
Inoltre(Also): Warning message:
The initial fit took 6  steps, which is bigger than the inner.iter  
paramter.  Consider increasing the latter in: coxme.fit(X, Y, strats, 
offset, init, control, weights = weights,  Thank you
Silvia


From njain at alumni.virginia.edu  Sun Sep 23 21:07:20 2007
From: njain at alumni.virginia.edu (Nitin Jain)
Date: Sun, 23 Sep 2007 12:07:20 -0700 (PDT)
Subject: [R] saving results under specified file name
Message-ID: <865253.42024.qm@web50209.mail.re2.yahoo.com>

Thanks Professor Ripley and Professor Harrell.

Yes, save(list=newname, ...) works.

Best,
Nitin
 


----- Original Message ----
From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
To: Nitin Jain <njain at alumni.virginia.edu>
Cc: R-help at stat.math.ethz.ch
Sent: Sunday, September 23, 2007 11:14:37 AM
Subject: Re: [R] saving results under specified file name

>From the help page for save:

Arguments:

      ...: the names of the objects to be saved (as symbols or character
           strings).

     list: A character vector containing the names of objects to be
           saved.

so you need save(list=newname, ...).


On Sun, 23 Sep 2007, Nitin Jain wrote:

> Hello,
>
> I would like to save the results in a specified file name.  Here is a 
> test example:
>
> aa <- function(xx, newname) {
> yy <- xx^2
>    rdName <- file.path(paste(newname, ".RData", sep = ""))
>    assign(eval(newname), yy)
> save(newname, file=rdName) ## FIXME
> }
>
>
> aa(3, "test")
>
> load("test.RData")
> ls()
>
> I would like to see test (which should store 9) rather than newname 
> (which stores "test")
>
> Please let me know how to do this.
>
> Thanks.
> -Nitin

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.





      ____________________________________________________________________________________
Luggage? GPS? Comic books? 
Check out fitting gifts for grads at Yahoo! Search
http://search.yahoo.com/search?fr=oni_on_mail&p=graduation+gifts&cs=bz


From knoblauch at lyon.inserm.fr  Sun Sep 23 21:17:25 2007
From: knoblauch at lyon.inserm.fr (Ken Knoblauch)
Date: Sun, 23 Sep 2007 19:17:25 +0000 (UTC)
Subject: [R] nls fits by groups
References: <cef24c990709230717g25a69909ud4952618a7e05c6f@mail.gmail.com>
Message-ID: <loom.20070923T191352-18@post.gmane.org>

Aleksi Lehtonen <lehtonen.aleksi <at> gmail.com> writes:

> I am trying to estimate several non-linear models simultaneously. I don't
> want to use non-linear mixed model, but non-linear model with same form, but
> it should be estimated separately according to variable group (I have lots
> of groups that have lots of observations....). I would like to have unique
> parameters for each group.
> 
> e.g. something like this
> 
> mod <- nls(y ~ a*x^b, start=c(a=1, b=1), group=group)
> 
> but knowing that group option does not work. If someone has an idea (or has
> done it already) how to implement this either using just nls statement or by
> building a simple function in R, I would be very grateful for hints....

Why not nlsList from the nlme package.  It would look something like this:

 mod <- nlsList(y ~ a*x^b | group, start=c(a=1, b=1))

you might have to add a data argument, too, depending on where your data is.

HTH,

Ken


From f.harrell at vanderbilt.edu  Sun Sep 23 21:44:37 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sun, 23 Sep 2007 14:44:37 -0500
Subject: [R] saving results under specified file name
In-Reply-To: <865253.42024.qm@web50209.mail.re2.yahoo.com>
References: <865253.42024.qm@web50209.mail.re2.yahoo.com>
Message-ID: <46F6C225.7050306@vanderbilt.edu>

Nitin Jain wrote:
> Thanks Professor Ripley and Professor Harrell.
> 
> Yes, save(list=newname, ...) works.
> 
> Best,
> Nitin

What I didn't see how to do with save( ) is to save an object with a 
user-specified internal name that is different from the current name of 
the object.  Save in Hmisc goes to extra trouble to accomplish that.

Frank

>  
> 
> 
> ----- Original Message ----
> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> To: Nitin Jain <njain at alumni.virginia.edu>
> Cc: R-help at stat.math.ethz.ch
> Sent: Sunday, September 23, 2007 11:14:37 AM
> Subject: Re: [R] saving results under specified file name
> 
>>From the help page for save:
> 
> Arguments:
> 
>       ...: the names of the objects to be saved (as symbols or character
>            strings).
> 
>      list: A character vector containing the names of objects to be
>            saved.
> 
> so you need save(list=newname, ...).
> 
> 
> On Sun, 23 Sep 2007, Nitin Jain wrote:
> 
>> Hello,
>>
>> I would like to save the results in a specified file name.  Here is a 
>> test example:
>>
>> aa <- function(xx, newname) {
>> yy <- xx^2
>>    rdName <- file.path(paste(newname, ".RData", sep = ""))
>>    assign(eval(newname), yy)
>> save(newname, file=rdName) ## FIXME
>> }
>>
>>
>> aa(3, "test")
>>
>> load("test.RData")
>> ls()
>>
>> I would like to see test (which should store 9) rather than newname 
>> (which stores "test")
>>
>> Please let me know how to do this.
>>
>> Thanks.
>> -Nitin
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From wwwhsd at gmail.com  Mon Sep 24 00:40:23 2007
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Sun, 23 Sep 2007 19:40:23 -0300
Subject: [R] find all objects of a particular class
In-Reply-To: <BAY110-F237817F2C4E3075D4C85CAB1B50@phx.gbl>
References: <Pine.LNX.4.64.0709231610570.13818@gannet.stats.ox.ac.uk>
	<BAY110-F237817F2C4E3075D4C85CAB1B50@phx.gbl>
Message-ID: <da79af330709231540y2b021335j3e4541e69c39f266@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070923/f1afeb84/attachment.pl 

From murdoch at stats.uwo.ca  Mon Sep 24 00:24:59 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 23 Sep 2007 18:24:59 -0400
Subject: [R] saving results under specified file name
In-Reply-To: <46F6C225.7050306@vanderbilt.edu>
References: <865253.42024.qm@web50209.mail.re2.yahoo.com>
	<46F6C225.7050306@vanderbilt.edu>
Message-ID: <46F6E7BB.4070303@stats.uwo.ca>

Frank E Harrell Jr wrote:
> Nitin Jain wrote:
>   
>> Thanks Professor Ripley and Professor Harrell.
>>
>> Yes, save(list=newname, ...) works.
>>
>> Best,
>> Nitin
>>     
>
> What I didn't see how to do with save( ) is to save an object with a 
> user-specified internal name that is different from the current name of 
> the object.  Save in Hmisc goes to extra trouble to accomplish that.
>   

save() can't, but this should do it (untested):

local({ assign(newname, value)
            save(list=newname)
         })

... which may be what you did in Hmisc.

Duncan Murdoch
> Frank
>
>   
>>  
>>
>>
>> ----- Original Message ----
>> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>> To: Nitin Jain <njain at alumni.virginia.edu>
>> Cc: R-help at stat.math.ethz.ch
>> Sent: Sunday, September 23, 2007 11:14:37 AM
>> Subject: Re: [R] saving results under specified file name
>>
>> >From the help page for save:
>>
>> Arguments:
>>
>>       ...: the names of the objects to be saved (as symbols or character
>>            strings).
>>
>>      list: A character vector containing the names of objects to be
>>            saved.
>>
>> so you need save(list=newname, ...).
>>
>>
>> On Sun, 23 Sep 2007, Nitin Jain wrote:
>>
>>     
>>> Hello,
>>>
>>> I would like to save the results in a specified file name.  Here is a 
>>> test example:
>>>
>>> aa <- function(xx, newname) {
>>> yy <- xx^2
>>>    rdName <- file.path(paste(newname, ".RData", sep = ""))
>>>    assign(eval(newname), yy)
>>> save(newname, file=rdName) ## FIXME
>>> }
>>>
>>>
>>> aa(3, "test")
>>>
>>> load("test.RData")
>>> ls()
>>>
>>> I would like to see test (which should store 9) rather than newname 
>>> (which stores "test")
>>>
>>> Please let me know how to do this.
>>>
>>> Thanks.
>>> -Nitin
>>>       
>
>
>


From freerichard at btinternet.com  Sun Sep 23 18:04:47 2007
From: freerichard at btinternet.com (Richard Price)
Date: Sun, 23 Sep 2007 17:04:47 +0100
Subject: [R] Beginners question about Percentage similarity in R?
Message-ID: <1b2df3t4cnh4cjecdttl0e3eurfibgevfn@4ax.com>


I have been reading a paper whereby the authors took values from
Sorensons dissimilarity index and values from a percentage similarity
index and applies G-Testing to the table of values. This is carried
out to assess the differences in spider faunas (Strattton and Uetz,
1979).

I like the method but have been trying to work out what function in R
to use to get the percentage similarity. I have vegan installed and
have been using it. I think R is brilliant.  But using the formula...

PS=3D2w/(a+b)

where w=3Dminimum sum of individuals of species held in common
between the samples being compared; a and b =3 the totals of
individuals found in either region. I have had trouble working out
from the help extract from designdist which of the methods is the
percentage. 

What does it mean when someone says 'minimum sum of individuals of
species held in common between samples? 

Is it the number of species where the count is exactly the same?

So, if I collected 14 of A. curbitana from 'site a' and then 14 of A.
curbitana from 'site b' than this is a species held in common between
the samples?

In R how do I calculate this percentage similarity?

Thanks,
Richard.


From matt.dubins at utoronto.ca  Sun Sep 23 19:50:06 2007
From: matt.dubins at utoronto.ca (Matthew Dubins)
Date: Sun, 23 Sep 2007 13:50:06 -0400
Subject: [R] Plotting numbers at a specified decimal length on a plot()
Message-ID: <46F6A74E.4090308@utoronto.ca>

Hi there,

I want to figure out how to plot means, with 2 decimal places, of any Y 
variable on a scatterplot according to any X variable (which obviously 
should have limited scope).  I already figured out how to plot the 
means, but without limiting their precision to 2 decimal places.  This 
is the code I used once I had the scatterplot drawn:

text(c(1990, 1992, 1994, 1996, 1998, 1999, 2000, 2001, 2002, 2003), 25, 
mean.yrly.closures$values, cex=.7)


It's a plot of school closures by Year.  The closures variable is 
labeled "values" in the "mean.yrly.closures" data set.  I managed to 
*display* the mean.yrly.closures data set with a precision of 2 decimal 
places (options(digits=2)), but then once I plotted the numbers, they 
showed up with many decimal places. 

It would be nice to figure this out so that I don't have to rely on 
Excel to make changes to the precision!

Thanks,
Matthew Dubins


From jurpelai at umich.edu  Sun Sep 23 17:39:40 2007
From: jurpelai at umich.edu (Johannes Urpelainen)
Date: Sun, 23 Sep 2007 11:39:40 -0400
Subject: [R] Network Construction in R
Message-ID: <20070923113940.goe7qsi3kgwsgssg@web.mail.umich.edu>

Hi,

I am trying to construct a social network from a data frame with rows

        acra numa acrb numb year    expab eabo    impab iabo
10       USA    2  CAN   20 1957 4017.000  0.0 3187.000  0.0
91       USA    2  CUB   40 1957  628.000  0.0  526.000  0.0
144      USA    2  HAI   41 1957   25.000  0.0   20.000  0.0

and so on.

I want the network to have directed edges from node acra to node acrb 
weighted by expab. What is the most convenient way to construct this 
network object?

Thank you very much!

Best,

-- 
Johannes Urpelainen


From emailnitinjain at gmail.com  Mon Sep 24 04:16:24 2007
From: emailnitinjain at gmail.com (Nitin Jain)
Date: Sun, 23 Sep 2007 22:16:24 -0400
Subject: [R] saving results under specified file name
In-Reply-To: <46F6E7BB.4070303@stats.uwo.ca>
References: <865253.42024.qm@web50209.mail.re2.yahoo.com>
	<46F6C225.7050306@vanderbilt.edu> <46F6E7BB.4070303@stats.uwo.ca>
Message-ID: <4d5dbaef0709231916r151416c0v5b2e843108bd09ab@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070923/83eb19d8/attachment.pl 

From ehlers at math.ucalgary.ca  Mon Sep 24 04:16:31 2007
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Sun, 23 Sep 2007 20:16:31 -0600
Subject: [R] Plotting numbers at a specified decimal length on a plot()
In-Reply-To: <46F6A74E.4090308@utoronto.ca>
References: <46F6A74E.4090308@utoronto.ca>
Message-ID: <46F71DFF.5020501@math.ucalgary.ca>

I find sprintf() useful for this.

Compare
lab <- rnorm(8)
plot(1:10)
text(2:9, 2:9, lab)

with
lab2 <- sprintf("%4.2f", lab)
plot(1:10)
text(2:9, 2:9, lab2)

  - Peter Ehlers

Matthew Dubins wrote:
> Hi there,
> 
> I want to figure out how to plot means, with 2 decimal places, of any Y 
> variable on a scatterplot according to any X variable (which obviously 
> should have limited scope).  I already figured out how to plot the 
> means, but without limiting their precision to 2 decimal places.  This 
> is the code I used once I had the scatterplot drawn:
> 
> text(c(1990, 1992, 1994, 1996, 1998, 1999, 2000, 2001, 2002, 2003), 25, 
> mean.yrly.closures$values, cex=.7)
> 
> 
> It's a plot of school closures by Year.  The closures variable is 
> labeled "values" in the "mean.yrly.closures" data set.  I managed to 
> *display* the mean.yrly.closures data set with a precision of 2 decimal 
> places (options(digits=2)), but then once I plotted the numbers, they 
> showed up with many decimal places. 
> 
> It would be nice to figure this out so that I don't have to rely on 
> Excel to make changes to the precision!
> 
> Thanks,
> Matthew Dubins
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
>


From elw at stderr.org  Mon Sep 24 04:22:22 2007
From: elw at stderr.org (elw at stderr.org)
Date: Sun, 23 Sep 2007 21:22:22 -0500 (CDT)
Subject: [R] Network Construction in R
In-Reply-To: <20070923113940.goe7qsi3kgwsgssg@web.mail.umich.edu>
References: <20070923113940.goe7qsi3kgwsgssg@web.mail.umich.edu>
Message-ID: <Pine.LNX.4.64.0709232119270.28224@illuminati.stderr.org>




> I am trying to construct a social network from a data frame with rows
>
>        acra numa acrb numb year    expab eabo    impab iabo
> 10       USA    2  CAN   20 1957 4017.000  0.0 3187.000  0.0
> 91       USA    2  CUB   40 1957  628.000  0.0  526.000  0.0
> 144      USA    2  HAI   41 1957   25.000  0.0   20.000  0.0
>
> and so on.
>
> I want the network to have directed edges from node acra to node acrb 
> weighted by expab. What is the most convenient way to construct this 
> network object?


Depends, I expect, on what you want to do with it.   Building a matrix 
from acra to acrb with expab as the matrix value (aka "tie strength") 
wouldn't be all that crazy.

Depending on which of the R network bits you are choosing to use, and the 
size of your data, different strategies are going to be more suitable than 
others.

Generally there is good support for converting different representations 
- edgelist, matrix, etc - and between them.  Some of those conversion 
methods don't work so well if the data is very large, however... you'll 
find that the ones that rely on processing a full matrix are particularly 
problematic, I expect.

--elijah

[School of Library and Information Science, Indiana University 
Bloomington]


From marc_schwartz at comcast.net  Mon Sep 24 04:24:38 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Sun, 23 Sep 2007 21:24:38 -0500
Subject: [R] Plotting numbers at a specified decimal length on a plot()
In-Reply-To: <46F6A74E.4090308@utoronto.ca>
References: <46F6A74E.4090308@utoronto.ca>
Message-ID: <1190600678.8030.27.camel@Bellerophon.localdomain>

On Sun, 2007-09-23 at 13:50 -0400, Matthew Dubins wrote:
> Hi there,
> 
> I want to figure out how to plot means, with 2 decimal places, of any Y 
> variable on a scatterplot according to any X variable (which obviously 
> should have limited scope).  I already figured out how to plot the 
> means, but without limiting their precision to 2 decimal places.  This 
> is the code I used once I had the scatterplot drawn:
> 
> text(c(1990, 1992, 1994, 1996, 1998, 1999, 2000, 2001, 2002, 2003), 25, 
> mean.yrly.closures$values, cex=.7)
> 
> 
> It's a plot of school closures by Year.  The closures variable is 
> labeled "values" in the "mean.yrly.closures" data set.  I managed to 
> *display* the mean.yrly.closures data set with a precision of 2 decimal 
> places (options(digits=2)), but then once I plotted the numbers, they 
> showed up with many decimal places. 
> 
> It would be nice to figure this out so that I don't have to rely on 
> Excel to make changes to the precision!
> 
> Thanks,
> Matthew Dubins


R uses double precision floats internally to store numeric values by
default. See ?numeric

What you see displayed when a number is print()ed, is different by
default than the actual storage precision. 

This is generally controlled by the use of options("digits"). However,
note that options("digits") does NOT control the number of digits to the
right of the decimal place, but the number of SIGNIFICANT digits
displayed. Also note that is it only a suggestion and not absolute. In
addition, when printing multiple values, such as a vector, other
characteristics will be in play. See ?print.default for more details
here.

To predictably control the number of digits to the right of the decimal
when displaying numbers, either in textual output or in a plot, you need
to format the output using functions such as sprintf() or formatC(), the
former being preferred.  See ?sprintf and ?formatC for more information.

HTH,

Marc Schwartz


From gtg894p at mail.gatech.edu  Mon Sep 24 06:45:08 2007
From: gtg894p at mail.gatech.edu (Jittima Piriyapongsa)
Date: Mon, 24 Sep 2007 00:45:08 -0400
Subject: [R] What is RDA file and how to open it in R program?
Message-ID: <1190609108.46f740d4dfca7@webmail.mail.gatech.edu>

Hi,

I have a set of gene expression data in .RDA file. I have downloaded
Bioconductor and R program for analyzing these data. Anyway, I am not sure how
to open this RDA file in R program (what is the command?) in order to look at
these data. And which package should I use for analyzing it e.g. plot the
expression image?

Thank you.
Jittima


From ritz at life.ku.dk  Mon Sep 24 07:33:39 2007
From: ritz at life.ku.dk (Christian Ritz)
Date: Mon, 24 Sep 2007 07:33:39 +0200
Subject: [R] nls fits by groups
In-Reply-To: <cef24c990709230717g25a69909ud4952618a7e05c6f@mail.gmail.com>
References: <cef24c990709230717g25a69909ud4952618a7e05c6f@mail.gmail.com>
Message-ID: <46F74C33.1090001@life.ku.dk>

Dear Aleksi,

there are other approaches you could consider: using nls or gnls (in the package nlme):

m1 <- nls(y ~ a[group]*x^b[group], start=list(a=c(1, ..., 1), b=c(1, ..., 1)))


or


m2 <- gnls(rate ~ a*x^b, params=list(a~group-1, b~group-1),
start=list(a=c(1, ..., 1), b=c(1, ..., 1)))


In both cases there should be specified as many initial values of a and b as there are 
groups (levels in the factor group).

Both approaches can also be used to specified simplified models where some parameter is 
assumed to be in common for all groups.


Christian


From Sumit.Gupta at ubs.com  Mon Sep 24 08:48:56 2007
From: Sumit.Gupta at ubs.com (Sumit.Gupta at ubs.com)
Date: Mon, 24 Sep 2007 07:48:56 +0100
Subject: [R] Separate colour for comments in scripts
Message-ID: <C6EB3844F7C76A42965909494BB17792037F079D@NLDNC104PEX1.ubsw.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070924/2ed9071d/attachment.pl 

From petr.pikal at precheza.cz  Mon Sep 24 08:55:20 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Mon, 24 Sep 2007 08:55:20 +0200
Subject: [R] really dumb question | loop counters in
In-Reply-To: <46F42770.80403@verizon.net>
Message-ID: <OF7013F188.59E1C58D-ONC1257360.0024D4C6-C1257360.0025F9E1@precheza.cz>

Hi


> Paul Hiemstra wrote:
> > Hi,
> >
> > This works:
> >
> > for(i in seq(1,100,5)) {
> > print(i)
> > }
> >
> > Very similar to the way python does this kind of loop.
> >
> 
> Indeed it is - thanks for the tip. I'm still puzzled why I can't find a 
> single piece of the standard [R] language documentation that shows this. 

> In contrast, every single other language I use (more than I care to 
> admit), and documentation for same, feature this prominently when they 
> talk about looping.

Maybe that is because looping is not a core feature of R language. Many 
things for which you has to use loops in other languages can be solved in 
R by its functions operating instantly on whole objects (vectors, matices, 
data.frames, lists).

Besides from for help page

seq
An expression evaluating to a vector 
                                        ^^^^^^^^^^^^^^^^^ 
And you cen directly inspect to what your construction evaluates by using 
them

1:5:100
(0,1,0.1)

So you shall/can put any sequence/vector into a for cycle 

for(var in seq) expr

seq = 1:50
seq = seq(1,100,5)
seq = sample(whatever apropriate vector)
seq = vector of file names
seq = vector of object names

etc.

Regards
Petr

> 
> Ah well.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ctlai at cyllene.uwa.edu.au  Mon Sep 24 09:23:16 2007
From: ctlai at cyllene.uwa.edu.au (ctlai)
Date: Mon, 24 Sep 2007 00:23:16 -0700 (PDT)
Subject: [R] assign one 'id' one colour for xyplot
Message-ID: <12855016.post@talk.nabble.com>



 is there a way to assign one 'id' (subject) to one colour for xyplot to
keep the co-ordination for different xyplots?  also how to increase the
number of colour for a xyplot that has more than 7 'id' (subjuects)

 I found one previous message but did not understand what he did.

 I attached a sample dataset.
http://www.nabble.com/file/p12855016/graph17sep07.csv graph17sep07.csv 

 the codes that I used were:

 p1 = xyplot(protein~day|breast, data= test)
 p2 = xyplot(lactose~day|breast, data= test)

 I want to keep the same colour line for each id in both graph

 thanks 
-- 
View this message in context: http://www.nabble.com/assign-one-%27id%27-one-colour-for-xyplot-tf4507453.html#a12855016
Sent from the R help mailing list archive at Nabble.com.


From lehtonen.aleksi at gmail.com  Mon Sep 24 09:46:11 2007
From: lehtonen.aleksi at gmail.com (Aleksi Lehtonen)
Date: Mon, 24 Sep 2007 10:46:11 +0300
Subject: [R] nls fits by groups
In-Reply-To: <Pine.GSO.4.56.0709231632140.4133@laurel.few.vu.nl>
References: <cef24c990709230717g25a69909ud4952618a7e05c6f@mail.gmail.com>
	<Pine.GSO.4.56.0709231632140.4133@laurel.few.vu.nl>
Message-ID: <46F76B43.9070501@gmail.com>

Dear Katharine,

that for loop solved all my problems, I just added subset=group==i to 
the nls statement.

thank you, Aleksi

Katharine Mullen wrote:
> It is not clear from your post what changes per-group.  If only the
> starting values change (but the data and the model structure are the
> same), then you can just store the starting values you want to use for
> each group in a list, and then index into this list in your call to nls.
> 
> e.g., modifying an example in the help page for nls:
> 
> x <- 1:10
> y <- 2*x + 3                            # perfect fit
> yeps <- y + rnorm(length(y), sd = 0.01) # added noise
> 
> startlist <- list(
>          list(a = 0.12345, b = 0.54321), ##group 1 start val
>          list(a = 0.12, b = 0.54) ## group 2 start val.
> 	         )
> reslist <- list() ## filling this with results from different start val
> for(i in 1:length(startlist)) {
>      reslist[[i]]  <-  nls(yeps ~ a + b*x, start = startlist[[i]],
>          trace = TRUE)
> }
> 
> On Sun, 23 Sep 2007, Aleksi Lehtonen wrote:
> 
>> Dear Colleagues,
>>
>> I am trying to estimate several non-linear models simultaneously. I don't
>> want to use non-linear mixed model, but non-linear model with same form, but
>> it should be estimated separately according to variable group (I have lots
>> of groups that have lots of observations....). I would like to have unique
>> parameters for each group.
>>
>> e.g. something like this
>>
>> mod <- nls(y ~ a*x^b, start=c(a=1, b=1), group=group)
>>
>> but knowing that group option does not work. If someone has an idea (or has
>> done it already) how to implement this either using just nls statement or by
>> building a simple function in R, I would be very grateful for hints....
>>
>> regards, Aleksi Lehtonen
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From bhs2 at mevik.net  Mon Sep 24 09:58:00 2007
From: bhs2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Mon, 24 Sep 2007 09:58:00 +0200
Subject: [R] What is RDA file and how to open it in R program?
In-Reply-To: <1190609108.46f740d4dfca7@webmail.mail.gatech.edu> (Jittima
	Piriyapongsa's message of "Mon, 24 Sep 2007 00:45:08 -0400")
References: <1190609108.46f740d4dfca7@webmail.mail.gatech.edu>
Message-ID: <m0myvcxzp3.fsf@bar.nemo-project.org>

Jittima Piriyapongsa wrote:

> I have a set of gene expression data in .RDA file. I have downloaded
> Bioconductor and R program for analyzing these data. Anyway, I am not sure how
> to open this RDA file in R program (what is the command?) in order to look at
> these data.

load("filename.RDA")

(.RDA (or .rda) is short for .RData (or .rdata :-).  It is the usual
file format for saving R objects to file (with save() or
save.image()).)

> And which package should I use for analyzing it e.g. plot the
> expression image?

That depends entirely on what is inside the file.  The best idea is
probably to ask the one(s) who created the file.

-- 
Bj?rn-Helge Mevik


From mauricio.malfert at gmail.com  Mon Sep 24 09:59:54 2007
From: mauricio.malfert at gmail.com (Mauricio Malfert)
Date: Mon, 24 Sep 2007 09:59:54 +0200
Subject: [R] Need help to create a monotone missing data pattern
Message-ID: <12472d0d0709240059n14d76339w7828dc37b984292a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070924/f5d04430/attachment.pl 

From Achim.Zeileis at wu-wien.ac.at  Mon Sep 24 10:04:27 2007
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Mon, 24 Sep 2007 10:04:27 +0200 (CEST)
Subject: [R] are hurdle logit-poisson model and posson model nested?
In-Reply-To: <1115a2b00709151844v2ccda7davc457648a9f7e41e5@mail.gmail.com>
References: <1115a2b00709151844v2ccda7davc457648a9f7e41e5@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709240959470.6396@eowyn>

On Sat, 15 Sep 2007, Wensui Liu wrote:

> Dear Listers,
> I have a general statistical question. Are hurdle logit-poisson model
> and posson model nested?

No, I don't think so. The logit hurdle is equivalent to a geometric hurdle 
(i.e., logit and right-censored geometric distribution imply the same 
likelihood and thus the same estimates), so a hurdle logit-geometric model 
is nested withing a geometric model.
If you want a model nested in poisson, you can use a hurdle 
poisson-poisson model, i.e., a right-censored poisson for the zero hurdle 
and a left-truncated poisson for the counts. A test for presence of the 
hurdle is then a test that all parameters are equal. The hurdle() function 
in "pscl" can fit these models and hurdletest() can test for the presence 
of the hurdle (given that the same distribution has been used for the zero 
hurdle and the counts).

Best,
Z

> Thank you so much?
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From shubhak at ambaresearch.com  Mon Sep 24 10:13:07 2007
From: shubhak at ambaresearch.com (Shubha Vishwanath Karanth)
Date: Mon, 24 Sep 2007 13:43:07 +0530
Subject: [R] Data manipulations with numbers which are in 'comma' format
Message-ID: <A36876D3F8A5734FA84A4338135E7CC302876910@BAN-MAILSRV03.Amba.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070924/5146a284/attachment.pl 

From friedrich.leisch at stat.uni-muenchen.de  Mon Sep 24 10:34:40 2007
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Mon, 24 Sep 2007 10:34:40 +0200
Subject: [R] Proposal: Archive UseR conference presentations at
	www.r-project.org/useR-yyyy
In-Reply-To: <40e66e0b0709180856s5d4c2218n6f74fe7575402244@mail.gmail.com>
References: <f8e6ff050709041413k70340217r76b51984d9e23ef9@mail.gmail.com>
	<fcmq8e$udt$1@sea.gmane.org>
	<46EFC023.7030803@statistik.uni-dortmund.de>
	<f8e6ff050709180805y6e856bd8t23da94e178e2bf43@mail.gmail.com>
	<40e66e0b0709180856s5d4c2218n6f74fe7575402244@mail.gmail.com>
Message-ID: <18167.30368.575305.907742@lxh5.stat.uni-muenchen.de>


[ Sorry to join in late, as Uwe already wrote I was offline in the
Austrian Alps. ]

>>>>> On Tue, 18 Sep 2007 10:56:03 -0500,
>>>>> Douglas Bates (DB) wrote:

  > On 9/18/07, hadley wickham <h.wickham at gmail.com> wrote:
  >> On 9/18/07, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
  >> > Earl F. Glynn wrote:
  >> > > "hadley wickham" <h.wickham at gmail.com> wrote in message
  >> > > news:f8e6ff050709041413k70340217r76b51984d9e23ef9 at mail.gmail.com...
  >> > >> Many of the presentations and posters from UseR! 2007 are now available
  >> > >> online:
  >> > >> http://user2007.org/program/
  >> > >
  >> > > The UseR 2006 conference info and presentations are part of
  >> > > www.r-project.org, namely http://www.r-project.org/useR-2006/
  >> > >
  >> > > I noticed the user2007.org  domain expires on 16 December 2007, which would
  >> > > need to be renewed each year to continue to make these presentations
  >> > > available online. During the year of a conference it makes sense to have a
  >> > > separate domain, but would it make sense to archive old UseR conferences at
  >> > > www.r-project.org/useR-yyyy?  Would it make sense to standardize this so one
  >> > > could generalize and find the presentations for any year?
  >> > >
  >> > > Next years' domain name is http://www.statistik.uni-dortmund.de/useR-2008/
  >> > > but could be www.r-project.org/useR-2008 .  An automatic redirection link
  >> > > could be used so that www.r-project.org/useR-2008 is redirected to
  >> > > http://www.statistik.uni-dortmund.de/useR-2008/  for now, but once the
  >> > > conference is over the archive could be moved to www.r-project.org.  Any
  >> > > comments?


The above redirection has already been in place for some time now,
i.e.,

	http://www.r-project.org/useR-2008	

works for me and redirects to Dortmund.


  >> >
  >> >
  >> > I'm fine with the proposal to move abstract or presentation to
  >> > www.r-project.org after the useR-2008. Having it local is much easier
  >> > during the organization periods. I know this is one of the topics some
  >> > useR organizers are currently discussing in the Austrian mountains
  >> > (where I should be as well given I've had some more time these days).
  >> 
  >> It would be even more useful to use subdomains like
  >> user2007.r-project.org so that we could host the content at a site
  >> other than on the R server (this would make it much easier for me, as
  >> I won't need to change the site at all to work on the r-project
  >> server).  I'm happy to advise on how to do this, if you (Fritz?) have
  >> access to your DNS records.

  > The nameservers for the R-project.org domain are located here at the
  > University of Wisconsin.  I can request a CNAME of
  > user2007.R-project.org be added if you tell me (off-list) the IP
  > address and ANAME of the machine to which it should point.


I think I like Hadley's proposal of collecting conference webpages
(after the conference is over) to one of our servers
better. Redirecting to pages at different locations is dangerous when
people move on to new positions.

E.g., I currently have the "problem" that since both Kurt and myself
are no longer at TU Wien, we cannot guarantee how long
www.ci.tuwien.ac.at will be up and running, and we were talking last
week about moving the old DSC webpages to the server at WU running
www.R-project.org.

So it would make a lot of sense to me to collect old conference pages
to a central location under the www.R-project.org umbrella. During the
active phase of a conference it is certainly better to have them on
a server under control of the local organizing committee.

Just my 2c,
Fritz

-- 
-----------------------------------------------------------------------
Prof. Dr. Friedrich Leisch 

Institut f?r Statistik                          Tel: (+49 89) 2180 3165
Ludwig-Maximilians-Universit?t                  Fax: (+49 89) 2180 5308
Ludwigstra?e 33
D-80539 M?nchen                 http://www.stat.uni-muenchen.de/~leisch


From david.meyer at wu-wien.ac.at  Mon Sep 24 10:51:26 2007
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Mon, 24 Sep 2007 10:51:26 +0200
Subject: [R]  fontsize in mosaic plot lables
Message-ID: <46F77A8E.9010606@wu-wien.ac.at>

Herry,

mosaic() by default uses the labeling_border() workhorse, which gives
you the choice of modifying either gp_labels or gp_varnames. So just
replacing gp_text by gp_labels shoud do the trick.

Best
David

----------


Hi List,

I am trying unsucessfully to modify the fontsize of lables in mosaic:


require(vcd)
mosaic(Titanic, pop=FALSE,
labeling_args=list(rot_labels=c(bottom=90,top=90),
       set_varnames = c(Sex = "Gender"),
           gp_text=gpar(fontsize=20))) #can't get it to resize text

tab <- ifelse(Titanic < 6, NA, Titanic)
# it works for labeling_cells
labeling_cells(text = tab, margin =
0,gp_text=gpar(fontsize=20))(Titanic)

What am I doing wrong?

Thanx
Herry




-- 
Dr. David Meyer
Department of Information Systems and Operations

Vienna University of Economics and Business Administration
Augasse 2-6, A-1090 Wien, Austria, Europe
Tel: +43-1-313 36 4393
Fax: +43-1-313 36 90 4393
HP:  http://wi.wu-wien.ac.at/~meyer/


From sergeyg at gmail.com  Mon Sep 24 11:20:06 2007
From: sergeyg at gmail.com (Sergey Goriatchev)
Date: Mon, 24 Sep 2007 11:20:06 +0200
Subject: [R] Root finding problem
Message-ID: <7cb007bd0709240220m614c639dj2ce3063d26a2314f@mail.gmail.com>

Hello,

I have a problem finding a root of a function, which I define like this:

tuki <- function(u, x, a, lambda){
if((lambda%%1>0) & u<0) {u<-(u+0i)}
f <- Re(x-(a*(u)^lambda-(1-(u))^lambda)/lambda)
f
}

What I want to do is to find the root, but without specifying the
interval within which to search for it. I can do it easily in MATLAB
with fsolve() or fzero() functions.

I compared results of running root-finding in MATLAB and R:

1) I found (by hand) a suitable interval of u-values for a=5,
lambda=0.5 and ran uniroot for x from 1 to 5:

ex.: uniroot(tuki, c(-1,1), x=1, a=5, lambda=0.5)

The results are the same as I get in MATLAB.

2) nlm() does not find the correct value!!!
ex.: nlm(tuki, p=0.1, x=1, a=5, lambda=0.5)

3) if I change lambda to 1.5, while keeping a=5, root finding in
MATLAB returns the following results for x from 1 to 5:

   0.5134
   0.7330
   0.9345
   1.1289 - 0.0058i
   1.3085 - 0.0199i

With correctly chosen interval, uniroot() finds correct values only
for x = 1:3, not for x=4 or x=5. (Obviously, I return real value from
tuki, but without that uniroot() does not work, returning "Error in
f(lower, ...) * f(upper, ...) > 0 :  invalid comparison with complex
values")

There is noone here to ask about this problem, and I just don't know
what to do. :-( Again, what I want is to find the root of the
above-mentioned function, for arbitrary values of x, a, and lambda,
and just specifying one value for u as a starting guess. Could anyone
please give me a suggestion of how to do that? Thanks in advance.

In MATLAB I do the following:

function u=tukeysolve(a,lambda,xgrid)
u=zeros(length(xgrid),1);
old=0.001; % just a guess
for i=1:length(xgrid)
  x=xgrid(i);
  u(i) = fsolve(@tuki,old,optimset('Display','Off','tolf',5e-8),x,a,lambda);
  old=u(i); % use previous value as new start value
end

function f=tuki(u,x,a,lambda)
f = x - (a * u^lambda - (1-u)^lambda)/lambda;


From petr.pikal at precheza.cz  Mon Sep 24 11:24:24 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Mon, 24 Sep 2007 11:24:24 +0200
Subject: [R] Odp: Data manipulations with numbers which are in 'comma' format
In-Reply-To: <A36876D3F8A5734FA84A4338135E7CC302876910@BAN-MAILSRV03.Amba.com>
Message-ID: <OF09DB76A0.7D1D970B-ONC1257360.0033846C-C1257360.00339FB2@precheza.cz>

Hi


> Hi R,
> 
> 
> 
> May be a trivial question, but struggling to find a solution...
> 
> 
> 
> v=data.frame(a=c("1,234","2,345","5,567"))
> 
> > v
> 
>         a
> 
> 1    1,234
> 
> 2    2,345
> 
> 3    5,567
> 
> 
> 
> I need a column 'b', which is just the addition of column 'a' with 5.
> How do I do it? And, entries in column 'a' are with commas, always.
> Also, class(v$a)=factor.

something like

> v$b <- as.numeric(gsub(",",  ".", v$a)) + 5
> v
      a      b
1 1,234  6.234
2 2,345  7.345
3 5,567 10.567

Regards

Petr

> 
> 
> 
> BR, Shubha
> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From eugen_pircalabelu at yahoo.com  Mon Sep 24 10:09:44 2007
From: eugen_pircalabelu at yahoo.com (eugen pircalabelu)
Date: Mon, 24 Sep 2007 01:09:44 -0700 (PDT)
Subject: [R] weighting question
Message-ID: <811252.50881.qm@web38613.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070924/44770ad4/attachment.pl 

From jbarnier at ens-lsh.fr  Mon Sep 24 11:32:39 2007
From: jbarnier at ens-lsh.fr (Julien Barnier)
Date: Mon, 24 Sep 2007 11:32:39 +0200
Subject: [R] Data manipulations with numbers which are in 'comma' format
References: <A36876D3F8A5734FA84A4338135E7CC302876910@BAN-MAILSRV03.Amba.com>
Message-ID: <87r6koif2g.fsf@ens-lsh.fr>

Hi,

> I need a column 'b', which is just the addition of column 'a' with 5.
> How do I do it? And, entries in column 'a' are with commas, always.
> Also, class(v$a)=factor.

You must convert your factor with commas into a numeric variable,
first replacing commas with dots.

A very dirty way to do it could be the following, but there may be a
better one :

v$a <- as.numeric(gsub(",",".",as.character(v$a)))

HTH,

Julien

-- 
Julien Barnier
Groupe de recherche sur la socialisation
ENS-LSH - Lyon, France


From csardi at rmki.kfki.hu  Mon Sep 24 11:36:58 2007
From: csardi at rmki.kfki.hu (Gabor Csardi)
Date: Mon, 24 Sep 2007 11:36:58 +0200
Subject: [R] Network Construction in R
In-Reply-To: <20070923113940.goe7qsi3kgwsgssg@web.mail.umich.edu>
References: <20070923113940.goe7qsi3kgwsgssg@web.mail.umich.edu>
Message-ID: <20070924093658.GA5546@localdomain>

Johannes,

with the igraph package, this would be something like

library(igraph)
g <- graph.data.frame( data.frame(from=data$acra, 
                       to=data$acrb, weight=data$expab))

Gabor

On Sun, Sep 23, 2007 at 11:39:40AM -0400, Johannes Urpelainen wrote:
> Hi,
> 
> I am trying to construct a social network from a data frame with rows
> 
>         acra numa acrb numb year    expab eabo    impab iabo
> 10       USA    2  CAN   20 1957 4017.000  0.0 3187.000  0.0
> 91       USA    2  CUB   40 1957  628.000  0.0  526.000  0.0
> 144      USA    2  HAI   41 1957   25.000  0.0   20.000  0.0
> 
> and so on.
> 
> I want the network to have directed edges from node acra to node acrb 
> weighted by expab. What is the most convenient way to construct this 
> network object?
> 
> Thank you very much!
> 
> Best,
> 
> -- 
> Johannes Urpelainen
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK


From jansen at uni-greifswald.de  Mon Sep 24 11:36:51 2007
From: jansen at uni-greifswald.de (Florian Jansen)
Date: Mon, 24 Sep 2007 11:36:51 +0200
Subject: [R] Performance problems to fill up a dataframe
Message-ID: <46F78533.9000109@uni-greifswald.de>

Dear Listmembers,

I'm trying to fill up a dataframe depending on an arbitrary list of 
references:

Here is my code, which works:

dat <- data.frame(c(60001,60001,60050,60050,60050),c(27,129,618,27,1579))
LR <- sort(unique(dat[,1]))
LC <- sort(unique(dat[,2]))
m <- as.data.frame(matrix(data=NA, nrow=length(LR), ncol=length(LC), 
dimnames=list(LR,LC)))

for(i in 1:nrow(dat)){
  m[as.character(dat[i,1]), as.character(dat[i,2])] <- 1
  }
m[is.na(m)] <- 0

Now I'm trying to prevent the loop, because it take ages for a list of 
20000 entries, but I run out of ideas.
Should I inflate my list beforehand and how? Can I adress the dataframe 
fields more effieciently?

Thanks for your help.


-- 
Dr. Florian Jansen
Geobotany & Nature Conservation
Institute of Botany and Landscape Ecology
Ernst-Moritz-Arndt-University
Grimmer Str. 88
17487 Greifswald
Germany
+49 (0)3834 86 4147


From jbarnier at ens-lsh.fr  Mon Sep 24 11:38:28 2007
From: jbarnier at ens-lsh.fr (Julien Barnier)
Date: Mon, 24 Sep 2007 11:38:28 +0200
Subject: [R] Sweave and ggplot2
Message-ID: <87myvciesr.fsf@ens-lsh.fr>

Hi,

I am trying to use ggplot2 graphics with Sweave, but I got problems
with transparency support when generating pdf figures, even if I
specify a ?pdf.version? argument in Sweave options.


More precisely, forcing the pdf version by creating the file manually
works :

<<fig=FALSE,results=HIDE>>=
pdf(version="1.4",file="foo.pdf")
ggplot(d,aes(y=t,x=u)) + geom_point(colour=alpha('black', 0.05))
dev.off()
@ 
\includegraphics{foo.pdf}


Using the pdf.version argument without using ggplot works, too :

\SweaveOpts{echo=FALSE,pdf.version=1.4}
<<fig=TRUE>>=
plot(t,u,col=rgb(0,0,0,0.1))
@ 


But the following doesn't work (and this is what I would like to do) :

\SweaveOpts{echo=FALSE,pdf.version=1.4}
<<fig=TRUE>>=
ggplot(d,aes(y=t,x=u)) + geom_point(colour=alpha('black', 0.05))
@ 


Does anyone have an idea about this ?

Thanks in advance,

Julien

-- 
Julien Barnier
Groupe de recherche sur la socialisation
ENS-LSH - Lyon, France


From kemp.samuel at googlemail.com  Mon Sep 24 11:49:43 2007
From: kemp.samuel at googlemail.com (Samuel Kemp)
Date: Mon, 24 Sep 2007 10:49:43 +0100
Subject: [R] a bug when subtracting vectors?
Message-ID: <3a5596550709240249o59a35773p2bd5a454b64a60c5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070924/a14ee0e2/attachment.pl 

From rwan at kuicr.kyoto-u.ac.jp  Mon Sep 24 12:18:40 2007
From: rwan at kuicr.kyoto-u.ac.jp (Raymond Wan)
Date: Mon, 24 Sep 2007 19:18:40 +0900
Subject: [R] a bug when subtracting vectors?
In-Reply-To: <3a5596550709240249o59a35773p2bd5a454b64a60c5@mail.gmail.com>
References: <3a5596550709240249o59a35773p2bd5a454b64a60c5@mail.gmail.com>
Message-ID: <46F78F00.3030306@kuicr.kyoto-u.ac.jp>


Samuel Kemp wrote:
> When subtracting,  all numbers should be to 2 decimal places. Why is R
> calculating it to 15 decimal places -- the output is essentially wrong
> 112.47-112.30=0.17 NOT 0.170000000000002. I suspect I am encoding this
> incorrectly?
>   


Well, two comments...one is not computer related.  If you are 
subtracting two numbers which have two digits after the decimal (i.e., 
two significant figures), you shouldn't be accepting a result of more 
than two digits.  So, the only thing wrong that you're doing is just 
that you're not formatting the output properly by cutting the remaining 
numbers.

As for the second comment, computers cannot represent decimal numbers 
exactly and problems like this occurs very often.  In the above example, 
one of your numbers can be represented exactly as 112.47 or 112.30.  
That's just something everyone has to be aware of when using computers 
to do math.  This, in my opinion, is an excellent paper on the 
problem...it is quite technical, but at least worth a skim:

http://docs.sun.com/source/806-3568/ncg_goldberg.html

I found this sentence near the beginning of the article to be perfect:  
"Squeezing infinitely many real numbers into a finite number of bits 
requires an approximate representation."

I presume there's an FAQ for R on this...not sure where it is, though.  
But, I hope this helps!

Ray


From daniel.brewer at icr.ac.uk  Mon Sep 24 12:23:11 2007
From: daniel.brewer at icr.ac.uk (Daniel Brewer)
Date: Mon, 24 Sep 2007 11:23:11 +0100
Subject: [R] Calculate difference between dates in years
Message-ID: <46F7900F.1020203@icr.ac.uk>

Hello,

I would like to be able to calculate the age of someone at a particular
date.  Both dates are date objects.  Here is what I have come up with:

floor(as.numeric(sampleInfo$Date.of.DIAGNOSIS-sampleInfo$Date.of.birth)/365.25)

Is this the best approach? or is there an inbuilt function?  I have
looked at difftime but that does not seem to allow output in years.

Many thanks

Dan

-- 
**************************************************************
Daniel Brewer, Ph.D.
Institute of Cancer Research
Email: daniel.brewer at icr.ac.uk
**************************************************************

The Institute of Cancer Research: Royal Cancer Hospital, a charitable Company Limited by Guarantee, Registered in England under Company No. 534147 with its Registered Office at 123 Old Brompton Road, London SW7 3RP.

This e-mail message is confidential and for use by the addre...{{dropped}}


From Wayne.W.Jones at shell.com  Mon Sep 24 12:37:02 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Mon, 24 Sep 2007 11:37:02 +0100
Subject: [R] Calculate difference between dates in years
In-Reply-To: <46F7900F.1020203@icr.ac.uk>
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B090@wyt-s-019.europe.shell.com>


look at the as.Date function

e.g.

as.Date("2007-04-21")- as.Date("2000-04-21")


also look at the chron library. 

Regards

Wayne


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of Daniel Brewer
Sent: 24 September 2007 11:23
To: r-help at stat.math.ethz.ch
Subject: [R] Calculate difference between dates in years


Hello,

I would like to be able to calculate the age of someone at a particular
date.  Both dates are date objects.  Here is what I have come up with:

floor(as.numeric(sampleInfo$Date.of.DIAGNOSIS-sampleInfo$Date.of.birth)/365.25)

Is this the best approach? or is there an inbuilt function?  I have
looked at difftime but that does not seem to allow output in years.

Many thanks

Dan

-- 
**************************************************************
Daniel Brewer, Ph.D.
Institute of Cancer Research
Email: daniel.brewer at icr.ac.uk
**************************************************************

The Institute of Cancer Research: Royal Cancer Hospital, a charitable Company Limited by Guarantee, Registered in England under Company No. 534147 with its Registered Office at 123 Old Brompton Road, London SW7 3RP.

This e-mail message is confidential and for use by the =\ ad...{{dropped}}


From dusa.adrian at gmail.com  Mon Sep 24 12:43:42 2007
From: dusa.adrian at gmail.com (Adrian Dusa)
Date: Mon, 24 Sep 2007 13:43:42 +0300
Subject: [R] Performance problems to fill up a dataframe
In-Reply-To: <46F78533.9000109@uni-greifswald.de>
References: <46F78533.9000109@uni-greifswald.de>
Message-ID: <200709241343.42344.dusa.adrian@gmail.com>


Try to assign some names to your initial variables:
dat <- data.frame(A=c(60001,60001,60050,60050,60050), B=c(27,129,618,27,1579))

And what you want is simply:
> table(dat)
       B
A       27 129 618 1579
  60001  1   1   0    0
  60050  1   0   1    1

Why do you need it as a dataframe anyway?
Hth,
Adrian

On Monday 24 September 2007, Florian Jansen wrote:
> Dear Listmembers,
>
> I'm trying to fill up a dataframe depending on an arbitrary list of
> references:
>
> Here is my code, which works:
>
> dat <- data.frame(c(60001,60001,60050,60050,60050),c(27,129,618,27,1579))
> LR <- sort(unique(dat[,1]))
> LC <- sort(unique(dat[,2]))
> m <- as.data.frame(matrix(data=NA, nrow=length(LR), ncol=length(LC),
> dimnames=list(LR,LC)))
>
> for(i in 1:nrow(dat)){
>   m[as.character(dat[i,1]), as.character(dat[i,2])] <- 1
>   }
> m[is.na(m)] <- 0
>
> Now I'm trying to prevent the loop, because it take ages for a list of
> 20000 entries, but I run out of ideas.
> Should I inflate my list beforehand and how? Can I adress the dataframe
> fields more effieciently?
>
> Thanks for your help.



-- 
Adrian Dusa
Romanian Social Data Archive
1, Schitu Magureanu Bd
050025 Bucharest sector 5
Romania
Tel./Fax: +40 21 3126618 \
          +40 21 3120210 / int.101


From bhs2 at mevik.net  Mon Sep 24 13:13:26 2007
From: bhs2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Mon, 24 Sep 2007 13:13:26 +0200
Subject: [R] a bug when subtracting vectors?
In-Reply-To: <3a5596550709240249o59a35773p2bd5a454b64a60c5@mail.gmail.com>
	(Samuel Kemp's message of "Mon, 24 Sep 2007 10:49:43 +0100")
References: <3a5596550709240249o59a35773p2bd5a454b64a60c5@mail.gmail.com>
Message-ID: <m0ejgoxqnd.fsf@bar.nemo-project.org>

A good answer is found in the FAQ for R, in 

FAQ 7.31 Why doesn't R think these numbers are equal?

-- 
Bj?rn-Helge Mevik


From albmont at centroin.com.br  Mon Sep 24 13:18:18 2007
From: albmont at centroin.com.br (Alberto Monteiro)
Date: Mon, 24 Sep 2007 09:18:18 -0200
Subject: [R] Calculate difference between dates in years
In-Reply-To: <46F7900F.1020203@icr.ac.uk>
References: <46F7900F.1020203@icr.ac.uk>
Message-ID: <20070924110011.M97111@centroin.com.br>

Daniel Brewer wrote:
> 
> I would like to be able to calculate the age of someone at a particular
> date.  Both dates are date objects.  Here is what I have come up with:
> 
> floor(as.numeric(sampleInfo$Date.of.DIAGNOSIS-
> sampleInfo$Date.of.birth)/365.25)
> 
> Is this the best approach?
>
No - leap years and such. You know that there are _not_
365.25 days in one year, don't you?

floor(as.numeric(as.Date("2100-02-28") - as.Date("1900-02-28"))/365.25)
# 199, should be 200

A less extreme counter-example:

floor(as.numeric(as.Date("2008-02-28") - as.Date("2007-02-28"))/365.25)
# 0, should be 1

Alberto Monteiro (purely destructive - sorry)


From friedrich.leisch at stat.uni-muenchen.de  Mon Sep 24 13:35:04 2007
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Mon, 24 Sep 2007 13:35:04 +0200
Subject: [R] R Courses in Munich
Message-ID: <18167.41192.482194.746356@lxh5.stat.uni-muenchen.de>


Torsten Hothorn and myself will present a series of (independent)
2-day R Courses in Munich in the forthcoming semester. The courses
will be held in German language (and I apologize to the rest for the
noise on the mailing list).

The topics are

	November  8- 9: Introduction to R

	December 13-14: R Programming

	January  24-25: Machine Learning

see

	http://www.statistik.lmu.de/R/

for details and registration.

With best regards,
Fritz Leisch

-- 
-----------------------------------------------------------------------
Prof. Dr. Friedrich Leisch 

Institut f?r Statistik                          Tel: (+49 89) 2180 3165
Ludwig-Maximilians-Universit?t                  Fax: (+49 89) 2180 5308
Ludwigstra?e 33
D-80539 M?nchen                 http://www.stat.uni-muenchen.de/~leisch


From Wayne.W.Jones at shell.com  Mon Sep 24 14:16:41 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Mon, 24 Sep 2007 13:16:41 +0100
Subject: [R] Performance problems to fill up a dataframe
In-Reply-To: <46F78533.9000109@uni-greifswald.de>
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B092@wyt-s-019.europe.shell.com>



Use table: 

dat <- data.frame(c(60001,60001,60050,60050,60050),c(27,129,618,27,1579))
table(dat[,1],dat[,2])

       
        27 129 618 1579
  60001  1   1   0    0
  60050  1   0   1    1

Regards

Wayne


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of Florian Jansen
Sent: 24 September 2007 10:37
To: r-help at r-project.org
Subject: [R] Performance problems to fill up a dataframe


Dear Listmembers,

I'm trying to fill up a dataframe depending on an arbitrary list of 
references:

Here is my code, which works:

dat <- data.frame(c(60001,60001,60050,60050,60050),c(27,129,618,27,1579))
LR <- sort(unique(dat[,1]))
LC <- sort(unique(dat[,2]))
m <- as.data.frame(matrix(data=NA, nrow=length(LR), ncol=length(LC), 
dimnames=list(LR,LC)))

for(i in 1:nrow(dat)){
  m[as.character(dat[i,1]), as.character(dat[i,2])] <- 1
  }
m[is.na(m)] <- 0

Now I'm trying to prevent the loop, because it take ages for a list of 
20000 entries, but I run out of ideas.
Should I inflate my list beforehand and how? Can I adress the dataframe 
fields more effieciently?

Thanks for your help.


-- 
Dr. Florian Jansen
Geobotany & Nature Conservation
Institute of Botany and Landscape Ecology
Ernst-Moritz-Arndt-University
Grimmer Str. 88
17487 Greifswald
Germany
+49 (0)3834 86 4147

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From steve at promente.org  Mon Sep 24 14:31:06 2007
From: steve at promente.org (Steve Powell)
Date: Mon, 24 Sep 2007 14:31:06 +0200
Subject: [R] Separate colour for comments in scripts
In-Reply-To: <C6EB3844F7C76A42965909494BB17792037F079D@NLDNC104PEX1.ubsw.net>
References: <C6EB3844F7C76A42965909494BB17792037F079D@NLDNC104PEX1.ubsw.net>
Message-ID: <010a01c7fea6$c8d22530$6501a8c0@STEVE>

Dear Sumit
Tinn-R is a little text editor which can do all that and more:
http://www.sciviews.org/Tinn-R/ 
Best wishes 
Steve Powell

 
proMENTE social research 
research | evaluation | training & consulting 
Kranj?evi?eva 35, 71000 Sarajevo 
mobile: +387 61 215 997 | office: +387 33 556 865 | fax: +387 33 556 866
skype: stevepowell99 
www.promente.org  |  www.mojakarijera.com  |  www.psih.org  

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Sumit.Gupta at ubs.com
Sent: 24 September 2007 08:49
To: r-help at r-project.org
Subject: [R] Separate colour for comments in scripts

Hi,

Is it possible to assign a separate colour for comments written with #,
eg:-

#this is a comment

. I am looking to colour them differently from the program text in R-Editor
(not console). Is it possible to do so?

Eg. In Visual basic, the colour for remarks gets green automatically

Regards
Sumit


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

No virus found in this incoming message.
Checked by AVG Free Edition. 

23.09.2007
13:53



Checked by AVG Free Edition. 

23.09.2007
13:53


From ripley at stats.ox.ac.uk  Mon Sep 24 14:35:47 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 24 Sep 2007 13:35:47 +0100 (BST)
Subject: [R] Calculate difference between dates in years
In-Reply-To: <20070924110011.M97111@centroin.com.br>
References: <46F7900F.1020203@icr.ac.uk>
	<20070924110011.M97111@centroin.com.br>
Message-ID: <Pine.LNX.4.64.0709241327520.21336@gannet.stats.ox.ac.uk>

On Mon, 24 Sep 2007, Alberto Monteiro wrote:

> Daniel Brewer wrote:
>>
>> I would like to be able to calculate the age of someone at a particular
>> date.  Both dates are date objects.  Here is what I have come up with:
>>
>> floor(as.numeric(sampleInfo$Date.of.DIAGNOSIS-
>> sampleInfo$Date.of.birth)/365.25)
>>
>> Is this the best approach?
>>
> No - leap years and such. You know that there are _not_
> 365.25 days in one year, don't you?
>
> floor(as.numeric(as.Date("2100-02-28") - as.Date("1900-02-28"))/365.25)
> # 199, should be 200
>
> A less extreme counter-example:
>
> floor(as.numeric(as.Date("2008-02-28") - as.Date("2007-02-28"))/365.25)
> # 0, should be 1
>
> Alberto Monteiro (purely destructive - sorry)

You need to convert to broken-down time.  Something like

age_years <- function(from, to)
{
     lt <- as.POSIXlt(c(from, to))
     age <- lt$year[2] - lt$year[1]
     mons <- lt$mon + lt$mday/50
     if(mons[2] < mons[1]) age <- age -1
     age
}

will be fine if used with valid dates (and you could extend it to work 
with date-times).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jan.wiener at tuebingen.mpg.de  Mon Sep 24 14:52:08 2007
From: jan.wiener at tuebingen.mpg.de (Jan M. Wiener)
Date: Mon, 24 Sep 2007 14:52:08 +0200
Subject: [R] calculating/plotting error ellipses
Message-ID: <46F7B2F8.7010200@tuebingen.mpg.de>

hello,
sorry for posting what may be a simple question:
i do have a matrix of coordinates (positional judgments, see below) and
now want to calculate and plot the corresponding error ellipse.
can anyone help me with the exact steps/syntax?

 > xyDat
            X         Y
1    -0.49    -2.13
2     0.91     0.48
3     0.20    -2.80
4    -0.76    -3.23
5    -0.36     2.50
6     1.38     1.24
7    -1.73    -2.14
8    -0.28    -1.97
9    -2.65     0.91
10    -2.03     0.92
11     0.40    -1.54
12    -1.40     2.39

thank you very much in advance.
best jan


From Mat.Soukup at fda.hhs.gov  Mon Sep 24 15:14:00 2007
From: Mat.Soukup at fda.hhs.gov (Soukup, Mat)
Date: Mon, 24 Sep 2007 09:14:00 -0400
Subject: [R] Position Openings at the U.S. Food and Drug Administration
Message-ID: <43F38EE025F1E448BC37D6050C58B6F80138AEDB@FMD3VS012.fda.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070924/d568b5b9/attachment.pl 

From xxgdw2002 at yahoo.com  Mon Sep 24 15:21:41 2007
From: xxgdw2002 at yahoo.com (a hk)
Date: Mon, 24 Sep 2007 06:21:41 -0700 (PDT)
Subject: [R] urgent for R graphics
Message-ID: <230507.21866.qm@web63907.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070924/8b233a0e/attachment.pl 

From therneau at mayo.edu  Mon Sep 24 15:23:33 2007
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 24 Sep 2007 08:23:33 -0500 (CDT)
Subject: [R] Correlated frailty model
Message-ID: <200709241323.l8ODNXI00816@rocky.mayo.edu>


>  I am trying to a estimate a correlated frailty model. My dataset is 
> made up of 40000 observations. I would like to know if it is too big or 
> I have done some mistakes in the following code.

  I have used larger data sets successfully.  I need to know a little bit
more about our problem.

> coxme(Surv(yearspan)~ south+mod, data=usa,random= ~ 1|group)

  What is the dimensionality of the covariates, e.g., are they factors with 
hundreds of levels?  How many unique levels are in the group variable?
The error message is surprising, as it appears to be coming from  conversion of
a sparse matrix to dense form.  The vector of frequencies for group might also
be useful.

	Terry Therneau


From yn19832 at msn.com  Mon Sep 24 15:30:59 2007
From: yn19832 at msn.com (livia)
Date: Mon, 24 Sep 2007 06:30:59 -0700 (PDT)
Subject: [R] fPortfolio Package
Message-ID: <12859913.post@talk.nabble.com>


Hello,

I am very interested in Portfolio Optimization functions in this package.
For the "cmlPortfolio", I thought it would be a set of the portfolio along
the "Capital Market Line", but it turns out that there is only one
portfolio. I was wondering which portfolio should this be?

Besides, is there any function that can employ a utility function to select
a portfolio?

Could anyone give me some advice? Many thanks
-- 
View this message in context: http://www.nabble.com/fPortfolio-Package-tf4509189.html#a12859913
Sent from the R help mailing list archive at Nabble.com.


From mel at altk.com  Mon Sep 24 15:46:29 2007
From: mel at altk.com (mel)
Date: Mon, 24 Sep 2007 15:46:29 +0200
Subject: [R] Separate colour for comments in scripts
In-Reply-To: <C6EB3844F7C76A42965909494BB17792037F079D@NLDNC104PEX1.ubsw.net>
References: <C6EB3844F7C76A42965909494BB17792037F079D@NLDNC104PEX1.ubsw.net>
Message-ID: <46F7BFB5.3020009@altk.com>

Sumit.Gupta at ubs.com a ?crit :

> Is it possible to assign a separate colour for comments written with #,

http://www.crimsoneditor.com/
I find it very practical.


From wl2776 at gmail.com  Mon Sep 24 15:53:55 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Mon, 24 Sep 2007 06:53:55 -0700 (PDT)
Subject: [R] What is RDA file and how to open it in R program?
In-Reply-To: <1190609108.46f740d4dfca7@webmail.mail.gatech.edu>
References: <1190609108.46f740d4dfca7@webmail.mail.gatech.edu>
Message-ID: <12860411.post@talk.nabble.com>


attach("file.RDA") # attaching the file to R, all its variables become
'visible'
# it should be on the 2nd position of the search path.
# see ?search
ls(2) # list everything in 2nd position of the search path

You can also load() this file.
In this case all data from this file will be loaded to the global
environment and mixed with those already existing in it.


Jittima Piriyapongsa wrote:
> 
> Hi,
> 
> I have a set of gene expression data in .RDA file. I have downloaded
> Bioconductor and R program for analyzing these data. Anyway, I am not sure
> how
> to open this RDA file in R program (what is the command?) in order to look
> at
> these data. And which package should I use for analyzing it e.g. plot the
> expression image?
> 
> Thank you.
> Jittima
> 
> 

-- 
View this message in context: http://www.nabble.com/What-is-RDA-file-and-how-to-open-it-in-R-program--tf4506992.html#a12860411
Sent from the R help mailing list archive at Nabble.com.


From joanne.hosking at pms.ac.uk  Mon Sep 24 15:55:20 2007
From: joanne.hosking at pms.ac.uk (Joanne Hosking)
Date: Mon, 24 Sep 2007 14:55:20 +0100
Subject: [R] longitudinal imputation with PAN
Message-ID: <778CBE832F7E2943BAC8729B0816531694467BB2@ILS132.uopnet.plymouth.ac.uk>

Hello all,

I am working on a longitudinal study of children in the UK and trying the PAN package for imputation of missing data, since it fulfils the critical criteria of taking into account individual subject trend over time as well as population trend over time.  In order to validate the procedure I have started by deleting some known values ?we have 6 annual measures of height on 300 children and I have imputed the missing values using PAN and compared the imputed values to the real values I deleted - in most individuals the imputed values fit the individual trend extremely well! However, when looking at the trend over time for a handful of individuals, the imputed value was actually lower than the previous (real) value of height or higher than the next (real) value making it appear that height went down?which in reality it never does?so my question is why, when it seems to work so well for the majority of individuals, does this happen? Am I doing something wrong?
As a novice user of R (and new to this area of statistics) I wondered if anyone could possibly  point me in the right direction, since the mixed effect design (plus potential ease and speed) of the PAN procedure for longitudinal data imputation is very appealing...
I would very much appreciate any advice you could give me, many thanks in advance.

Jo Hosking

Code and a small sample data are shown below (I could supply more data to anyone willing!)...

impht.data <-read.delim ("impht_long_trunc.dat",header = TRUE)
impht.data$sex <-factor(impht.data$sex,label = c("Boys","Girls"))
impht.data$visit <- factor (impht.data$visit)
impht.data$code <- factor (impht.data$code)

y <- impht.data$htmiss
subj <- impht.data$code
pred <- cbind (impht.data$age, impht.data$sex, impht.data$visit)
xcol <- 1:3
zcol <- 1
prior <- list(a=1, Binv=1, c=1, Dinv=1)
ht1 <- pan(y, subj, pred, xcol, zcol, prior, seed=13579, iter=1000)

code    sex     visit   age     ht      htmiss
1       2       1       4.87    105     105
1       2       2       5.86    109.6
1       2       3       6.88    116.4   116.4
1       2       4       7.72    121.2   121.2
1       2       5       8.72    126.7   126.7
1       2       6       9.71    132.3   132.3
2       2       1       4.84    107.1   107.1
2       2       2       6       115.7   115.7
2       2       3       6.86    121.4   121.4
2       2       4       7.69    126.5   126.5
2       2       5       8.7     134.15  134.15
2       2       6       9.76    140
3       2       1       4.62    103     103
3       2       2       5.69    108.9   108.9
3       2       3       6.87    115.1
3       2       4       7.55    118.6   118.6
3       2       5       8.46    123.6   123.6
3       2       6       9.63    128.9   128.9


From jan.wiener at tuebingen.mpg.de  Mon Sep 24 14:53:41 2007
From: jan.wiener at tuebingen.mpg.de (Jan M. Wiener)
Date: Mon, 24 Sep 2007 14:53:41 +0200
Subject: [R] calculating/plotting error ellipses
Message-ID: <46F7B355.9020806@tuebingen.mpg.de>

hello,
sorry for posting what may be a simple question:
i do have a matrix of coordinates (positional judgments, see below) and
now want to calculate and plot the corresponding error ellipse.
can anyone help me with the exact steps/syntax?

 > xyDat
            X         Y
1    -0.49    -2.13
2     0.91     0.48
3     0.20    -2.80
4    -0.76    -3.23
5    -0.36     2.50
6     1.38     1.24
7    -1.73    -2.14
8    -0.28    -1.97
9    -2.65     0.91
10    -2.03     0.92
11     0.40    -1.54
12    -1.40     2.39

thank you very much in advance.
best jan

-- 
Dr. Jan M. Wiener
LPPA - Coll?ge de France - CNRS
11, place Marcelin Berthelot
75005 Paris, France
-
e-mail: mail at jan-wiener.net
url: www.jan-wiener.net
phone: +33 (0)1 44 27 14 21


From ligges at statistik.uni-dortmund.de  Mon Sep 24 16:06:16 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 24 Sep 2007 16:06:16 +0200
Subject: [R] urgent for R graphics
In-Reply-To: <230507.21866.qm@web63907.mail.re1.yahoo.com>
References: <230507.21866.qm@web63907.mail.re1.yahoo.com>
Message-ID: <46F7C458.80603@statistik.uni-dortmund.de>



a hk wrote:
> Hi, everyone,
> I am green with R. Now I am working on a graphics projects.
> I have a dataset:
> -----------------------
>      a    b        c
> 1  228  83     6.69 
> 2  274  83     7.36 
> 3  320  83     8.86 
> 4  366  83     7.36 
> 5  412  83     6.81 
> 6  228 129     5.58
> 
> ---------------------
> I want to draw a 3d graphic.
> I use the code
> __________________
>  scatterplot3d(avs$a,avs$b,avs$emprical,type="h",angle=35,scale.y=0.7,pch=16,
> + y.ticklabs(0,500,by=100),y.margin.add=0.1)


The code is incorrect, hence here a similar example:

library(scatterplot3d)
s3d <- scatterplot3d(avs$a, avs$b, avs$c, type="h",
                      angle=35, scale.y=0.7, pch=16,
                      y.margin.add=0.1)

polygon(s3d$xyz.convert(x = c(250, 400, 400, 250),
                         y = c(90, 90, 120, 120),
                         z = c(7, 7, 7, 7)))


Uwe Ligges



> _________________________________
> 
> Now I want to add a rectangle on the x,y axis, does anyone could tell me the code? I try a lot, but don't find.
> and another question, how do I revoke the "point3d" function?
> Thank you so much.
> 
> XiangGang
> 
> 
>        
> ---------------------------------
> Got a little couch potato? 
> Check out fun summer activities for kids.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From h.wickham at gmail.com  Mon Sep 24 16:25:27 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 24 Sep 2007 09:25:27 -0500
Subject: [R] Proposal: Archive UseR conference presentations at
	www.r-project.org/useR-yyyy
In-Reply-To: <18167.30368.575305.907742@lxh5.stat.uni-muenchen.de>
References: <f8e6ff050709041413k70340217r76b51984d9e23ef9@mail.gmail.com>
	<fcmq8e$udt$1@sea.gmane.org>
	<46EFC023.7030803@statistik.uni-dortmund.de>
	<f8e6ff050709180805y6e856bd8t23da94e178e2bf43@mail.gmail.com>
	<40e66e0b0709180856s5d4c2218n6f74fe7575402244@mail.gmail.com>
	<18167.30368.575305.907742@lxh5.stat.uni-muenchen.de>
Message-ID: <f8e6ff050709240725u488e5070kb568af29edd96524@mail.gmail.com>

> I think I like Hadley's proposal of collecting conference webpages
> (after the conference is over) to one of our servers
> better. Redirecting to pages at different locations is dangerous when
> people move on to new positions.

That wasn't my suggestion, but I can understand your desire to do
that.  Perhaps just taking a static snapshot using something like
wget, and hosting that on the R-project website would be a good
compromise.

> E.g., I currently have the "problem" that since both Kurt and myself
> are no longer at TU Wien, we cannot guarantee how long
> www.ci.tuwien.ac.at will be up and running, and we were talking last
> week about moving the old DSC webpages to the server at WU running
> www.R-project.org.

Yes, this is why I prefer to host all of my sites on an external host.

> So it would make a lot of sense to me to collect old conference pages
> to a central location under the www.R-project.org umbrella. During the
> active phase of a conference it is certainly better to have them on
> a server under control of the local organizing committee.

The one problem is setting up a redirect so that existing links and
google searches aren't broken.  This would need to be put in place at
least 6 months before the old website closed.

Hadley
-- 
http://had.co.nz/


From edna.bell01 at gmail.com  Mon Sep 24 16:40:07 2007
From: edna.bell01 at gmail.com (Edna Bell)
Date: Mon, 24 Sep 2007 09:40:07 -0500
Subject: [R]  making R packages and compacting an entire R set up
Message-ID: <2d1ebb110709240740t9fc484ew3f107424a405f36e@mail.gmail.com>

Hi R Gurus!

I have 2 questions, please:

a.  I'm putting together a little baby package on SUSE Linux 10.1.  I
want to create a zip of the package for windows.  How should I create
that please?

b.  I don't know if the following is possible but here it is:  I have
R and a bunch of libraries set up very nicely.  I would like to hand
off this setup to someone else.  Should I just copy things as they
stand onto a CD please or is there a better way please?

thanks in advance!
Sincerely,
Edna Bell


From Yan.Y.Li at MorganStanley.com  Mon Sep 24 16:48:55 2007
From: Yan.Y.Li at MorganStanley.com (Li, Yan (IED))
Date: Mon, 24 Sep 2007 10:48:55 -0400
Subject: [R] 3d plot with dates on axis
Message-ID: <245560F6123C7F479027072A9EA2A2F2063BD197@NYWEXMB24.msad.ms.com>

Hi all,

I'd like to make a 3D plot with dates on one of the axes. For example,

date1 <- as.Date("2007-01-25") + seq(10)
y <- seq(10)
z <- seq(10)

I want to plot date1 on one axis, y on the other, and z as the height,
with the points connected.

Any help would be highly appreciated!

Yan
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/se...{{dropped}}


From ggrothendieck at gmail.com  Mon Sep 24 16:49:58 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 24 Sep 2007 10:49:58 -0400
Subject: [R] making R packages and compacting an entire R set up
In-Reply-To: <2d1ebb110709240740t9fc484ew3f107424a405f36e@mail.gmail.com>
References: <2d1ebb110709240740t9fc484ew3f107424a405f36e@mail.gmail.com>
Message-ID: <971536df0709240749u312c74a4y501fbeef9b5d409@mail.gmail.com>

See:

http://www.nabble.com/Cross-Compiling-t4473403.html

On 9/24/07, Edna Bell <edna.bell01 at gmail.com> wrote:
> Hi R Gurus!
>
> I have 2 questions, please:
>
> a.  I'm putting together a little baby package on SUSE Linux 10.1.  I
> want to create a zip of the package for windows.  How should I create
> that please?
>
> b.  I don't know if the following is possible but here it is:  I have
> R and a bunch of libraries set up very nicely.  I would like to hand
> off this setup to someone else.  Should I just copy things as they
> stand onto a CD please or is there a better way please?
>
> thanks in advance!
> Sincerely,
> Edna Bell
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From news at london4jobs.co.uk  Mon Sep 24 17:01:24 2007
From: news at london4jobs.co.uk (London4Jobs)
Date: Mon, 24 Sep 2007 16:01:24 +0100
Subject: [R] Looking for a different approach?
Message-ID: <BLUESBS01sB4i0ccX0y0000fff8@mail.bluepeople.co.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070924/b46fff8b/attachment.pl 

From linker1981 at gmail.com  Mon Sep 24 17:07:06 2007
From: linker1981 at gmail.com (jagl)
Date: Mon, 24 Sep 2007 08:07:06 -0700 (PDT)
Subject: [R] Plotting tree tips in a specific order! how?
Message-ID: <12861788.post@talk.nabble.com>



hi to all

I'm using ape,ade4,etc packages to draw phylogenetic trees. 

Situation:

- i have a file with genetic sequences
- i can do the clustering with hclust
- i convert the clustering to trees
- the resulting trees are correct

Problem:

- the sequences in my data files have a specific order
- first sequence is from time=0, last sequence is from time=end of time
- plotting a tree doesn't respect this order (ex: if it is a vertical tree,
branch from time=0 is not at y=0 position and branch from time=1 it's not in
y=1 and so on)

Does anyone know how i can do this (even with clusters like time=1 to
time=10 drawn first, then time=11 to time..... )?



-- 
View this message in context: http://www.nabble.com/Plotting-tree-tips-in-a-specific-order%21-how--tf4509760.html#a12861788
Sent from the R help mailing list archive at Nabble.com.


From tlumley at u.washington.edu  Mon Sep 24 17:23:46 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 24 Sep 2007 08:23:46 -0700 (PDT)
Subject: [R] Package Survey
In-Reply-To: <20070923223515.nnh3d1ge8w0kggsk@webmail.ine.pt>
References: <Pine.LNX.4.64.0709200709460.14389@homer22.u.washington.edu>
	<20070923223515.nnh3d1ge8w0kggsk@webmail.ine.pt>
Message-ID: <Pine.LNX.4.64.0709240821570.26074@homer23.u.washington.edu>

On Sun, 23 Sep 2007, Rita Cristina Pinto Sousa wrote:
> I?m using the package survey to obtain the statistics, fundamentally the 
> variance estimates. Can you explain why do I obtain the same result with the 
> replicate weights (as.svrepdesign function), for a stratified sample, and 
> without the replicate weights? I don?t understand it?

Without as.svrepdesign() you get the Horvitz-Thompson standard error 
estimator for the total and linearization estimators for other statistics. 
For the total and the mean these agree exactly with the JKn estimator. 
For nonlinear statistics they do not agree exactly, although they are 
usually close.

 	-thomas




> Many thanks for your attention,
> Rita Sousa.
>
> ***************************************
> # Apuramentos IUTIC-E
>
> rm(list=ls())
>
> ano <- "2006"
>
> require(survey)
> options(survey.lonely.psu="remove")
>
> setwd("C:/INE/Estat?stica-DME/IUTIC-E/")
>
> #Read the DB
> base_npc <- 
> read.table(paste(getwd(),"/Dados/",ano,"/NPC",".txt",sep=""),sep="\t",dec=",",header 
> = T)
>
> base_npc[is.na(base_npc)]<-0
>
> #Universe information
> univ_npc <- 
> read.table(paste(getwd(),"/Dados/",ano,"/NPC_Univ",".txt",sep=""),sep="\t",dec=".",header 
> = T)
>
> names(base_npc) <- tolower(names(base_npc))
> names(univ_npc) <- tolower(names(univ_npc))
>
> base_npc <- merge(base_npc,univ_npc,by="estr_cor")
>
> #S? algumas vari?veis
> #base_npc <- 
> base_npc[,c("npc","estr_cor","pond_npc","npc_univ","e_cuse","div1")]
>
> #Survey design
> desenho_npc <- 
> svydesign(id=~npc,strata=~estr_cor,weights=~pond_npc,fpc=~npc_univ,nest=T,data=base_npc)
>
> #Replicate weights
> desenho_npc_JK <- as.svrepdesign(desenho_npc,type="JKn")
>
> #Without replicate weigths
> svyby(~e_cuse,~div1,desenho_npc,svytotal,drop.empty.groups=FALSE,vartype=c("se","var","cvpct"))
> #With replicate weigths
> svyby(~e_cuse,~div1,desenho_npc_JK,svytotal,drop.empty.groups=FALSE,vartype=c("se","var","cvpct"))
> ******************************************
>
>
> Citando Thomas Lumley <tlumley at u.washington.edu>:
>
>> This message uses a character set that is not supported by the Internet
>> Service.  To view the original message content,  open the attached
>> message. If the text doesn't display correctly, save the attachment to
>> disk, and then open it using a viewer that can display the original
>> character set. <<message.txt>>
>> 
>
>
>
> ----------------------------------------------------------------
> This message was sent using IMP, the Internet Messaging Program.
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

From tlumley at u.washington.edu  Mon Sep 24 17:29:12 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 24 Sep 2007 08:29:12 -0700 (PDT)
Subject: [R] weighting question
In-Reply-To: <811252.50881.qm@web38613.mail.mud.yahoo.com>
References: <811252.50881.qm@web38613.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.0709240826110.26074@homer23.u.washington.edu>


On Mon, 24 Sep 2007, eugen pircalabelu wrote:

> Hi R-users,
>
> Can anyone tell me where can i find info about they way how post 
> stratification weights are calculated when i have an already stratified 
> survey design, especially in Survey Package (but any theoretical 
> material would do me just fine) ?

The reference listed in the help page,

     Valliant R (1993) Post-stratification and conditional variance
      estimation. JASA 88: 89-96

describes this.

 	-thomas


From rgentlem at fhcrc.org  Mon Sep 24 18:04:04 2007
From: rgentlem at fhcrc.org (Robert Gentleman)
Date: Mon, 24 Sep 2007 09:04:04 -0700
Subject: [R] Network Construction in R
In-Reply-To: <20070923113940.goe7qsi3kgwsgssg@web.mail.umich.edu>
References: <20070923113940.goe7qsi3kgwsgssg@web.mail.umich.edu>
Message-ID: <46F7DFF4.1010708@fhcrc.org>

there are several packages that can be used:
the graph, RBGL and Rgraphviz packages, provide data structures, 
algorithms, and layout/plotting tools for graphs/networks.  There are 
quite a few more specialized packages at Bioconductor (typically more 
related to biological problems). There, you can use biocViews to see 
what is available.

best wishes
   Robert

Johannes Urpelainen wrote:
> Hi,
> 
> I am trying to construct a social network from a data frame with rows
> 
>         acra numa acrb numb year    expab eabo    impab iabo
> 10       USA    2  CAN   20 1957 4017.000  0.0 3187.000  0.0
> 91       USA    2  CUB   40 1957  628.000  0.0  526.000  0.0
> 144      USA    2  HAI   41 1957   25.000  0.0   20.000  0.0
> 
> and so on.
> 
> I want the network to have directed edges from node acra to node acrb 
> weighted by expab. What is the most convenient way to construct this 
> network object?
> 
> Thank you very much!
> 
> Best,
> 

-- 
Robert Gentleman, PhD
Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
PO Box 19024
Seattle, Washington 98109-1024
206-667-7700
rgentlem at fhcrc.org


From carlos.grohmann at gmail.com  Mon Sep 24 18:07:04 2007
From: carlos.grohmann at gmail.com (=?ISO-8859-1?Q?Carlos_"Gu=E2no"_Grohmann?=)
Date: Mon, 24 Sep 2007 17:07:04 +0100
Subject: [R] truehist?
Message-ID: <bd07447b0709240907s6b8209c7k5908e6676e991240@mail.gmail.com>

Hello,
After a long time, I needed the truehist function, but my system
couldn't found it. I tried to install the package MAAS, but I couldn't
found it! Something happened?

Carlos

-- 
+-----------------------------------------------------------+
              Carlos Henrique Grohmann - Guano
  Visiting Researcher at Kingston University London - UK
  Geologist M.Sc  - Doctorate Student at IGc-USP - Brazil
Linux User #89721  - carlos dot grohmann at gmail dot com
+-----------------------------------------------------------+
_________________
"Good morning, doctors. I have taken the liberty of removing Windows
95 from my hard drive."
--The winning entry in a "What were HAL's first words" contest judged
by 2001: A SPACE ODYSSEY creator Arthur C. Clarke

Can't stop the signal.


From dusa.adrian at gmail.com  Mon Sep 24 18:22:39 2007
From: dusa.adrian at gmail.com (Adrian Dusa)
Date: Mon, 24 Sep 2007 16:22:39 +0000 (UTC)
Subject: [R] Adding a table to a plot area
References: <315698.89149.qm@web34705.mail.mud.yahoo.com>
	<46F448B3.6040202@vanderbilt.edu>
Message-ID: <loom.20070924T160014-8@post.gmane.org>

Frank E Harrell Jr <f.harrell <at> vanderbilt.edu> writes:
> Judith Flores wrote:
> > Is there a command to insert a table into the plot
> > area other that using text?
> > 
> > Thank you.
> 
> To me the only completely satisfying approach is to use LaTeX and psfrag 
> in you want great alignment and other features.  A howto with R is at 
> http://biostat.mc.vanderbilt.edu/PsFrag .  This uses the fragmaster perl 
> script which runs LaTeX from within R to make the final graphics file 
> self-contained.

The howto is interesting and extremely useful (thank you), however there is one
line that couldn't be completed:

tab <- latexTabular(x, align='rl')  # new function in Hmisc

Which version of Hmisc has (will have) this new function?
It cannot be found in the latest version (3.4-2) from CRAN...

Best wishes,
Adrian


From xxgdw2002 at yahoo.com  Mon Sep 24 18:27:50 2007
From: xxgdw2002 at yahoo.com (a hk)
Date: Mon, 24 Sep 2007 09:27:50 -0700 (PDT)
Subject: [R] urgent for R graphics
In-Reply-To: <46F7C458.80603@statistik.uni-dortmund.de>
Message-ID: <261051.27537.qm@web63908.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070924/2e307131/attachment.pl 

From hkahra at gmail.com  Mon Sep 24 18:29:40 2007
From: hkahra at gmail.com (Hannu Kahra)
Date: Mon, 24 Sep 2007 19:29:40 +0300
Subject: [R] truehist?
In-Reply-To: <bd07447b0709240907s6b8209c7k5908e6676e991240@mail.gmail.com>
References: <bd07447b0709240907s6b8209c7k5908e6676e991240@mail.gmail.com>
Message-ID: <3d35a2ca0709240929nb47676eu7e20638955d64ab9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070924/823a22ae/attachment.pl 

From birgit.lemcke at systbot.uzh.ch  Mon Sep 24 18:51:33 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Mon, 24 Sep 2007 18:51:33 +0200
Subject: [R] save 3dplot to file
Message-ID: <0444680F-9353-4EEE-81AD-00CDFCAF46BA@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070924/1bdd1a6b/attachment.pl 

From bolker at ufl.edu  Mon Sep 24 19:09:40 2007
From: bolker at ufl.edu (bbolker)
Date: Mon, 24 Sep 2007 10:09:40 -0700 (PDT)
Subject: [R] save 3dplot to file
In-Reply-To: <0444680F-9353-4EEE-81AD-00CDFCAF46BA@systbot.uzh.ch>
References: <0444680F-9353-4EEE-81AD-00CDFCAF46BA@systbot.uzh.ch>
Message-ID: <12864028.post@talk.nabble.com>




Birgit Lemcke wrote:
> 
> I think it is an easy question but i haven?t found a solution since I  
> am r beginner.
> 
> I did this
> 
> 	plot3d(PCoA, type="p", col=rainbow(1000),size=5)
> 	text3d(PCoA, text=Nam)
> 
> 
> How can I save it including the labels to a jpg-file?
> 

 You can only save as  a PNG (using rgl.snapshot); also, be careful
when saving the PNG that the rgl graphics window isn't obscured by
other windows.  You can use other tools such as ImageMagick to
convert from PNG to JPEG.

  cheers
   Ben Bolker

-- 
View this message in context: http://www.nabble.com/save-3dplot-to-file-tf4510319.html#a12864028
Sent from the R help mailing list archive at Nabble.com.


From bolker at ufl.edu  Mon Sep 24 19:12:47 2007
From: bolker at ufl.edu (bbolker)
Date: Mon, 24 Sep 2007 10:12:47 -0700 (PDT)
Subject: [R] calculating/plotting error ellipses
In-Reply-To: <46F7B2F8.7010200@tuebingen.mpg.de>
References: <46F7B2F8.7010200@tuebingen.mpg.de>
Message-ID: <12864033.post@talk.nabble.com>




Jan M. Wiener wrote:
> 
> hello,
> sorry for posting what may be a simple question:
> i do have a matrix of coordinates (positional judgments, see below) and
> now want to calculate and plot the corresponding error ellipse.
> can anyone help me with the exact steps/syntax?
> 

Something along the lines of:

m = colMeans(xyDat)  # calc. column means
v = var(xyDat)             # compute var-cov matrix
library(ellipse)              # you may need install.packages("ellipse")
first
plot(ellipse(v,centre=m),type="l")   ## draw the confidence ellipse
points(m[,1],m[,2])     # add the cent(re|er) point

  Of course, I haven't actually tested this ...

  Ben Bolker


-- 
View this message in context: http://www.nabble.com/calculating-plotting-error-ellipses-tf4509082.html#a12864033
Sent from the R help mailing list archive at Nabble.com.


From tom.boonen.maiden at gmail.com  Mon Sep 24 19:15:19 2007
From: tom.boonen.maiden at gmail.com (Tom Boonen)
Date: Mon, 24 Sep 2007 13:15:19 -0400
Subject: [R] error rate for cluster analysis
Message-ID: <cc088e260709241015o4abb6910xa53963e5c35e66b@mail.gmail.com>

Hi all,

I am looking for an R function or a metric that I could self code that
compare the results of a clustering exercise with a given solution
key.

An example. Let's say four elements are clustered, the number of
clustered is unknown a priori. For my guess and the solution, I have
two matrices with two columns the first colum gives the cluster id,
the second the element id:

guess <- cbind(c(1,1,2,3),c(1,2,3,4));
solution <- cbind(c(1,2,3,3),c(1,2,3,4));
colnames(guess) <- colnames(solution) <- c("cluster.id","element.id");
guess;
solution;

So here the guess is wrong in several ways. The guess claims elements
3 & 4 belong to distinct clusters, but in the solution we see that
they belong to the same. Also, the guess claims elements 1 & 2 belong
to one cluster, but in the solution we see they belong to distinct
clusters.

What I am looking for is a function or a metric that I could code up
myself, that defines a sensible distance between the guess and the
solution. There are various ways to do this, but I am just wondering
if there is some standard way of doing this in one of the cluster
analysis packages or so.

Thanks very much,
Tom


From murdoch at stats.uwo.ca  Mon Sep 24 12:45:20 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 24 Sep 2007 06:45:20 -0400
Subject: [R] Separate colour for comments in scripts
In-Reply-To: <C6EB3844F7C76A42965909494BB17792037F079D@NLDNC104PEX1.ubsw.net>
References: <C6EB3844F7C76A42965909494BB17792037F079D@NLDNC104PEX1.ubsw.net>
Message-ID: <46F79540.50509@stats.uwo.ca>

Sumit.Gupta at ubs.com wrote:
> Hi,
>
> Is it possible to assign a separate colour for comments written with #,
> eg:-
>
> #this is a comment
>
> . I am looking to colour them differently from the program text in
> R-Editor (not console). Is it possible to do so?
>   

Yes, in the MacOSX gui; no in the Windows gui; yes in many external text 
editors that work with R (e.g. Tinn-R on Windows).

Duncan Murdoch
> Eg. In Visual basic, the colour for remarks gets green automatically
>
> Regards
> Sumit
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From michael.watson at bbsrc.ac.uk  Mon Sep 24 19:57:33 2007
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Mon, 24 Sep 2007 18:57:33 +0100
Subject: [R] making R packages and compacting an entire R set up
References: <2d1ebb110709240740t9fc484ew3f107424a405f36e@mail.gmail.com>
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9504AA2157@iahce2ksrv1.iah.bbsrc.ac.uk>

For 1, start off with package.skeleton
 
Then http://www.biostat.wisc.edu/~kbroman/Rintro/Rwinpack.html

________________________________

From: r-help-bounces at r-project.org on behalf of Edna Bell
Sent: Mon 24/09/2007 3:40 PM
To: r-help at stat.math.ethz.ch
Subject: [R] making R packages and compacting an entire R set up



Hi R Gurus!

I have 2 questions, please:

a.  I'm putting together a little baby package on SUSE Linux 10.1.  I
want to create a zip of the package for windows.  How should I create
that please?

b.  I don't know if the following is possible but here it is:  I have
R and a bunch of libraries set up very nicely.  I would like to hand
off this setup to someone else.  Should I just copy things as they
stand onto a CD please or is there a better way please?

thanks in advance!
Sincerely,
Edna Bell

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From schaber at molgen.mpg.de  Mon Sep 24 20:13:44 2007
From: schaber at molgen.mpg.de (=?ISO-8859-15?Q?J=F6rg_Schaber?=)
Date: Mon, 24 Sep 2007 20:13:44 +0200
Subject: [R] linear model contrast questions
Message-ID: <46F7FE58.7000300@molgen.mpg.de>

Hi,

when I fit a linear model as

 lm(o ~ y + s - 1, contrasts=list(s=("contr.sum")),na.action=na.exclude)

should then the effects of factor s sum up to zero?

I my case they don't. Where is the misunderstanding or the mistake?

Thanks,

joerg


From bolker at ufl.edu  Mon Sep 24 20:39:38 2007
From: bolker at ufl.edu (bbolker)
Date: Mon, 24 Sep 2007 11:39:38 -0700 (PDT)
Subject: [R] Root finding problem
In-Reply-To: <7cb007bd0709240220m614c639dj2ce3063d26a2314f@mail.gmail.com>
References: <7cb007bd0709240220m614c639dj2ce3063d26a2314f@mail.gmail.com>
Message-ID: <12865617.post@talk.nabble.com>



tuki <- function(u, x, a, lambda){
  u <- u+0i
  f <- Re(x-(a*(u)^lambda-(1-(u))^lambda)/lambda)
  f
}

## What I want to do is to find the root, but without specifying the
## interval within which to search for it. I can do it easily in MATLAB
## with fsolve() or fzero() functions.

## BB: how do these functions pick an interval?

## I compared results of running root-finding in MATLAB and R:

## 1) I found (by hand) a suitable interval of u-values for a=5,
## lambda=0.5 and ran uniroot for x from 1 to 5:

curve(tuki(u=x,x=1,a=5,lambda=0.5),from=-1,to=1)
u1 = uniroot(tuki, c(-1,1), x=1, a=5, lambda=0.5)
abline(h=0,col=2)
abline(v=u1$root,col=2)

## The results are the same as I get in MATLAB.

## 2) nlm() does not find the correct value!!!

## BB: nlm is not solving the same problem !!!
##  it's looking for a MINIMUM, not a ROOT.

nlm(tuki, p=0.1, x=1, a=5, lambda=0.5)

## to use nlm to find a minimum:

tukisq <- function(u, x, a, lambda){
  tuki(u,x,a,lambda)^2
}

n1 = nlm(tukisq, p=0.1, x=1, a=5, lambda=0.5)
abline(v=n1$estimate,col=4)

n1$estimate-u1$root
## works fine.

## 3) if I change lambda to 1.5, while keeping a=5, root finding in
## MATLAB returns the following results for x from 1 to 5:

##    0.5134
##    0.7330
##    0.9345
##    1.1289 - 0.0058i
##    1.3085 - 0.0199i

curve(tuki(u=x,x=1,a=5,lambda=1.5),from=-1,to=2,ylim=c(-2,8))
curve(tuki(u=x,x=5,a=5,lambda=1.5),from=-1,to=2,add=TRUE,lty=2)
u2 = uniroot(tuki, c(-1,1), x=1, a=5, lambda=1.5)
abline(h=0,col=2)
abline(v=u2$root,col=2)
u3 = uniroot(tuki, c(-1,2), x=5, a=5, lambda=1.5)
abline(v=u3$root,col=4)

## BB: this seems to work fine.  Did you forget to extend the
##  x range to bracket the root?

## With correctly chosen interval, uniroot() finds correct values only
## for x = 1:3, not for x=4 or x=5. (Obviously, I return real value from
## tuki, but without that uniroot() does not work, returning "Error in
## f(lower, ...) * f(upper, ...) > 0 :  invalid comparison with complex
## values")


## BB: I haven't been through the rest of your code,
## but the approach above again seems to work fine.

n3 = nlm(tukisq, p=0.1, x=5, a=5, lambda=1.5)
abline(v=n3$estimate,col=6)

## also works fine.

-- 
View this message in context: http://www.nabble.com/Root-finding-problem-tf4508016.html#a12865617
Sent from the R help mailing list archive at Nabble.com.


From lobry at biomserv.univ-lyon1.fr  Mon Sep 24 21:11:18 2007
From: lobry at biomserv.univ-lyon1.fr (Jean lobry)
Date: Mon, 24 Sep 2007 21:11:18 +0200
Subject: [R] Data manipulations with numbers which are in 'comma' format
In-Reply-To: <mailman.15.1190628004.11754.r-help@r-project.org>
References: <mailman.15.1190628004.11754.r-help@r-project.org>
Message-ID: <p06002005c31db49becd6@[192.168.1.12]>

Dear Shubha,

>  May be a trivial question, but struggling to find a solution...
>
>  v=data.frame(a=c("1,234","2,345","5,567"))
>
>>  v
>
>         a
>  1    1,234
>  2    2,345
>  3    5,567
>
>  I need a column 'b', which is just the addition of column 'a' with 5.
>  How do I do it? And, entries in column 'a' are with commas, always.
>  Also, class(v$a)=factor.

if you are working (as me) in a locale where the comma is the decimal
separator, you should be awared that R is *very* good to cope with this
nightmare:

###
a <- c("1,234", "2,345", "5,567")
v <- read.table(textConnection(a), col.names = "a", dec = ",")
v$b <- v$a + 5
v
###
       a      b
1 1.234  6.234
2 2.345  7.345
3 5.567 10.567

Have a look at the "dec" argument in ?read.table. See also ?format.
Wonderful R, isn't it?

Best,

-- 
Jean R. Lobry            (lobry at biomserv.univ-lyon1.fr)
Laboratoire BBE-CNRS-UMR-5558, Univ. C. Bernard - LYON I,
43 Bd 11/11/1918, F-69622 VILLEURBANNE CEDEX, FRANCE
allo  : +33 472 43 27 56     fax    : +33 472 43 13 88
http://pbil.univ-lyon1.fr/members/lobry/


From gtg894p at mail.gatech.edu  Mon Sep 24 21:49:14 2007
From: gtg894p at mail.gatech.edu (Jittima Piriyapongsa)
Date: Mon, 24 Sep 2007 15:49:14 -0400
Subject: [R] how to export.RDA file to a text file?
Message-ID: <1190663354.46f814baa2f02@webmail.mail.gatech.edu>

Hi,

Does anyone know how to export .RDA file (in R program) to a normal text file
(readable by any text editor)? Also, how to export an object in R program into a
text file (not .RDA file)?

Thank you.
Jittima


From Mark.Leeds at morganstanley.com  Mon Sep 24 21:55:16 2007
From: Mark.Leeds at morganstanley.com (Leeds, Mark (IED))
Date: Mon, 24 Sep 2007 15:55:16 -0400
Subject: [R] hypothesis testing
Message-ID: <D3AEEDA31E57474B840BEBC25A8A834401957B49@NYWEXMB23.msad.ms.com>

This was sent to me by someone on the R-list ( I don't know her ) but I
don't have time to look at this right now so I told her I would send
it to the R-list because she said it keeps getting bounced when she
sends it.
  
#=======================================================================
====================================================================

I am a bit confused with this. If possible do you think you can help me
with this? 
 
function(yvec,trtvec,alpha=0.05,header="") {
#################################################
# A function to compute a two-sample t-test and confidence # interval
(equal-variance, independent samples).  yvec is # a numeric vector
containing both samples' data.  trtvec # is a vector, same length as
yvec, of treatment # identifiers for the data in yvec.  A boxplot
comparing # the treatments' data is constructed.  Output is a one-row #
data frame reporting the results of the test and # confidence interval
##################################################
trtvec=as.factor(trtvec)
boxplot(split(yvec,trtvec))
title(header)
ybar=tapply(yvec,trtvec,mean)
varvec=tapply(yvec,trtvec,var)
nvec=table(trtvec)
error.df=nvec[1]+nvec[2]-2
pooled.var=((nvec[1]-1)*varvec[1]+(nvec[2]-1)*varvec[2])/error.df
diff12estimate=ybar[1]-ybar[2]
stderr=sqrt(pooled.var*((1/nvec[1])+(1/nvec[2])))
tratio=diff12estimate/stderr
twosidedP=2*(1-pt(abs(tratio),error.df))
tcrit=qt(1-alpha/2,error.df)
lower=diff12estimate-tcrit*stderr
upper=diff12estimate+tcrit*stderr
calpha=1-alpha
out=data.frame(diff12estimate,stderr,tratio,twosidedP,lower,upper,alpha)
names(out)=c("Estimator","SE","T","P-value","Lower CI","Upper
CI","Confidence")
out
}
 
I need to alter the above function twosamp so that its output includes
the decision made by the hypothesis test. For any alpha level, the
function should say ' Reject Null' or 'Fail to Reject Null' where it is
necessary. 

Use a new 3-level input factor alternative so that the function
twosamp(above) can compute both two-sided and one-sided p-values and
make the two-sided test the default and output information about which
alternative was tested. Therefore ifelse should work here right.

Use the following code 

Var.test(yvec~as.factor(trtvec))$p.value>alpha. 
If the variances are not equal then use
Sqrt((varvec[1]/nvec[1])+(varvec[2]/nvec[2])) Ifelse should be used to
allow for either standard error formula, depending on whether the
equal-variances assumption is valid or not.

 

How can I change the output from a data frame to a list?
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/sell the
securities/instruments mentioned or an official confirmation.  Morgan
Stanley may deal as principal in or own or act as market maker for
securities/instruments mentioned or may advise the issuers.  This is not
research and is not from MS Research but it may refer to a research
analyst/research report.  Unless indicated, these views are the author's
and may differ from those of Morgan Stanley research or others in the
Firm.  We do not represent this is accurate or complete and we may not
update this.  Past performance is not indicative of future returns.  For
additional information, research reports and important disclosures,
contact me or see https://secure.ms.com/servlet/cls.  You should not use
e-mail to request, authorize or effect the purchase or sale of any
security or instrument, to send transfer instructions, or to effect any
other transactions.  We cannot guarantee that any such requests received
via e-mail will be processed in a timely manner.  This communication is
solely for the addressee(s) and may contain confidential information.
We do not waive confidentiality by mistransmission.  Contact me if you
do not wish to receive these communications.  In the UK, this
communication is directed in the UK to those persons who are market
counterparties or intermediate customers (as defined in the UK Financial
Services Authority's rules).
--------------------------------------------------------

This is not an offer (or solicitation of an offer) to buy/sell the securities/instruments mentioned or an official confirmation.  Morgan Stanley may deal as principal in or own or act as market maker for securities/instruments mentioned or may advise the issuers.  This is not research and is not from MS Research but it may refer to a research analyst/research report.  Unless indicated, these views are the author's and may differ from those of Morgan Stanley research or others in the Firm.  We do not represent this is accurate or complete and we may not update this.  Past performance is not indicative of future returns.  For additional information, research reports and important disclosures, contact me or see https://secure.ms.com/servlet/cls.  You should not use e-mail to request, authorize or effect the purchase or sale of any security or instrument, to send transfer instructions, or to effect any other transactions.  We cannot guarantee that any such requests received via e-mail will be processed in a timely manner.  This communication is solely for the addressee(s) and may contain confidential information.  We do not waive confidentiality by mistransmission.  Contact me if you do not wish to receive these communications.  In the UK, this communication is directed in the UK to those persons who are market counterparties or intermediate customers (as defined in the UK Financial Services Authority's rules).


From lobry at biomserv.univ-lyon1.fr  Mon Sep 24 22:18:44 2007
From: lobry at biomserv.univ-lyon1.fr (Jean lobry)
Date: Mon, 24 Sep 2007 22:18:44 +0200
Subject: [R] Sweave and ggplot2
In-Reply-To: <mailman.15.1190628004.11754.r-help@r-project.org>
References: <mailman.15.1190628004.11754.r-help@r-project.org>
Message-ID: <p06002006c31dbf62736a@[192.168.1.12]>

Dear Julien,

>  Hi,
>
>  I am trying to use ggplot2 graphics with Sweave, but I got problems
>  with transparency support when generating pdf figures, even if I
>  specify a ?pdf.version? argument in Sweave options.
>
[...snip...]

I wanted to help because I'm interested by the exploitation
of the alpha channel in Sweave documents too...

However,

i) Despite its annoncment in fortune("mind_read"), the mind_read()
function is apparently not to be released in R 2.6.0, so that if
you could just follow the posting guide and give a reproducible
example...

ii) Give the output of your sessionInfo(). You can use something
like that in your *.rnw file:

<<sessionInfo, results=tex, echo=F>>=
toLatex(sessionInfo())
@

iii) What do you mean exactly by "doesn't work"? Put the source and
the output somewhere on the web so that we can see both.

Sincerely,
-- 
Jean R. Lobry            (lobry at biomserv.univ-lyon1.fr)
Laboratoire BBE-CNRS-UMR-5558, Univ. C. Bernard - LYON I,
43 Bd 11/11/1918, F-69622 VILLEURBANNE CEDEX, FRANCE
allo  : +33 472 43 27 56     fax    : +33 472 43 13 88
http://pbil.univ-lyon1.fr/members/lobry/


From f.harrell at vanderbilt.edu  Mon Sep 24 22:33:33 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Mon, 24 Sep 2007 15:33:33 -0500
Subject: [R] Adding a table to a plot area
In-Reply-To: <loom.20070924T160014-8@post.gmane.org>
References: <315698.89149.qm@web34705.mail.mud.yahoo.com>	<46F448B3.6040202@vanderbilt.edu>
	<loom.20070924T160014-8@post.gmane.org>
Message-ID: <46F81F1D.9070808@vanderbilt.edu>

Adrian Dusa wrote:
> Frank E Harrell Jr <f.harrell <at> vanderbilt.edu> writes:
>> Judith Flores wrote:
>>> Is there a command to insert a table into the plot
>>> area other that using text?
>>>
>>> Thank you.
>> To me the only completely satisfying approach is to use LaTeX and psfrag 
>> in you want great alignment and other features.  A howto with R is at 
>> http://biostat.mc.vanderbilt.edu/PsFrag .  This uses the fragmaster perl 
>> script which runs LaTeX from within R to make the final graphics file 
>> self-contained.
> 
> The howto is interesting and extremely useful (thank you), however there is one
> line that couldn't be completed:
> 
> tab <- latexTabular(x, align='rl')  # new function in Hmisc
> 
> Which version of Hmisc has (will have) this new function?
> It cannot be found in the latest version (3.4-2) from CRAN...
> 
> Best wishes,
> Adrian

It will be in the next release of Hmisc.  It can be obtained now at 
http://biostat.mc.vanderbilt.edu/cgi-bin/viewvc.cgi/*checkout*/Hmisc/trunk/R/latex.s?rev=542

Frank

> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From murdoch at stats.uwo.ca  Mon Sep 24 22:45:17 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 24 Sep 2007 16:45:17 -0400
Subject: [R] 3d plot with dates on axis
In-Reply-To: <245560F6123C7F479027072A9EA2A2F2063BD197@NYWEXMB24.msad.ms.com>
References: <245560F6123C7F479027072A9EA2A2F2063BD197@NYWEXMB24.msad.ms.com>
Message-ID: <46F821DD.7070806@stats.uwo.ca>

On 9/24/2007 10:48 AM, Li, Yan (IED) wrote:
> Hi all,
> 
> I'd like to make a 3D plot with dates on one of the axes. For example,
> 
> date1 <- as.Date("2007-01-25") + seq(10)
> y <- seq(10)
> z <- seq(10)
> 
> I want to plot date1 on one axis, y on the other, and z as the height,
> with the points connected.
> 
> Any help would be highly appreciated!

library(rgl)
plot3d(date1,y,z, type='l',axes=F)
xlabs <- date1[c(2,5,8)] # or some other way to get pretty dates
axes3d(xat=xlabs, xlab=as.character(xlabs))

Duncan Murdoch


From julien at no-log.org  Mon Sep 24 23:20:32 2007
From: julien at no-log.org (Julien Barnier)
Date: Mon, 24 Sep 2007 23:20:32 +0200
Subject: [R] Sweave and ggplot2
References: <mailman.15.1190628004.11754.r-help@r-project.org>
	<p06002006c31dbf62736a@[192.168.1.12]>
Message-ID: <87hcljbw0v.fsf@gnugnus.org>

Hi,

First, thanks for your help and sorry for not following the posting
guide by not giving more detailed informations and an easily
reproducible example...

> i) Despite its annoncment in fortune("mind_read"), the mind_read()
> function is apparently not to be released in R 2.6.0, so that if
> you could just follow the posting guide and give a reproducible
> example...

Well, I hope it will be ready for R 2.7.0 !

> ii) Give the output of your sessionInfo(). You can use something
> like that in your *.rnw file:
>
> <<sessionInfo, results=tex, echo=F>>=
> toLatex(sessionInfo())
> @

Here it is :

,----
| R version 2.5.1 (2007-06-27) 
| i486-pc-linux-gnu 
| 
| locale:
| LC_CTYPE=fr_FR at euro;LC_NUMERIC=C;LC_TIME=fr_FR at euro;LC_COLLATE=fr_FR at euro;
| LC_MONETARY=fr_FR at euro;LC_MESSAGES=fr_FR at euro;LC_PAPER=fr_FR at euro;LC_NAME=C;
| LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=fr_FR at euro;LC_IDENTIFICATION=C
| 
| attached base packages:
| [1] "grDevices" "utils"     "datasets"  "graphics"  "stats"     "methods"  
| [7] "base"     
| 
| other attached packages:
|     car 
| "1.2-1" 
`----

> iii) What do you mean exactly by "doesn't work"? Put the source and
> the output somewhere on the web so that we can see both.

"Doesn't work" means that the generated pdf file for the figure
generated by the chunk is empty. It is not of size 0, but it has no
content and so cannot be included when running pdflatex, which exits
with an error :

,----
| !pdfTeX error: pdflatex (file ./alpha_sweave-004.pdf): PDF inclusion: required 
| page does not exist <0>
|  ==> Fatal error occurred, no output PDF file produced!
`----

When I try this example at work, I got an error message during Sweave
which is close from something like "warning : semitransparency not
supported by this device". When I try at home (with the given
sessionInfo), I got no warning but in both the cases the result is the
same : an empty pdf file for the figure and an error during pdflatex
compilation.

I've put online an example Rnw file and the almost empty pdf produced
here :

http://dd.nozav.org/transferts/

Thanks in advance for any help.

-- 
Julien


From edna.bell01 at gmail.com  Mon Sep 24 23:43:49 2007
From: edna.bell01 at gmail.com (Edna Bell)
Date: Mon, 24 Sep 2007 16:43:49 -0500
Subject: [R]  fuzzy logic
Message-ID: <2d1ebb110709241443q5fb96709n99877c1fc21baa7e@mail.gmail.com>

Hi R Gurus!

Is there a fuzzy logic package please?

Thanks,
Edna Bell


From vi5u0-r at yahoo.co.uk  Mon Sep 24 23:52:14 2007
From: vi5u0-r at yahoo.co.uk (Dan Hatton)
Date: Mon, 24 Sep 2007 22:52:14 +0100 (BST)
Subject: [R] PicTeX output: how to suppress escaping of $ signs and braces?
Message-ID: <alpine.LFD.0.999.0709242231450.26555@seagull>


Dear All,

I'm trying to draw a TeX histogram with the following pair of commands,

pictex(file = "realhisto.tex")
hist(Peaklist$V3,xlab="Height $z/\\ut{mm}$",ylab="Probability density $\\phi{}(z-z_0)/(1/\\ut{mm})$")

However, in the resulting file realhisto.tex, I get, for example

\put {Height \$z/\ut\{mm\}\$}  [lB] <0.00pt,0.00pt> at 136.13 9.17

when what I'd like is

\put {Height $z/\ut{mm}$}  [lB] <0.00pt,0.00pt> at 136.13 9.17

i.e. the $ signs and braces not to be escaped with backslashes.

I've tried a couple of things that "help(Quotes)" hints at, like
replacing the double quotes with single quotes or backticks, or
explicitly escaping the $ signs with backslashes, but none of these
things seem to help.

Any ideas, please?

-- 

Thanks very much

Dan Hatton

<http://www.bib.hatton.btinternet.co.uk/dan/>


From FolkesM at pac.dfo-mpo.gc.ca  Mon Sep 24 23:55:50 2007
From: FolkesM at pac.dfo-mpo.gc.ca (Folkes, Michael)
Date: Mon, 24 Sep 2007 14:55:50 -0700
Subject: [R] parse in text function of plots, confusing behaviour
Message-ID: <63F107BCC37AEA49A75FD94AA3E07CB01236D8@pacpbsex01.pac.dfo-mpo.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070924/b20668dd/attachment.pl 

From ucjtkst at ucl.ac.uk  Tue Sep 25 00:02:10 2007
From: ucjtkst at ucl.ac.uk (ucjtkst at ucl.ac.uk)
Date: 24 Sep 2007 23:02:10 +0100
Subject: [R] partial plots for logistic regression using glm
Message-ID: <Prayer.1.0.12.0709242302100.4661@wmail-a.ucl.ac.uk>

Dear R users,

I am modelling the probability of error in a behavioural task using the 
glm() function (with the numbers of successes and failures listed for each 
line in the data frame). How can I plot the partial effects of the 
predictors?

Many thanks in advance,

Stav


From gtg894p at mail.gatech.edu  Mon Sep 24 23:12:59 2007
From: gtg894p at mail.gatech.edu (Jittima Piriyapongsa)
Date: Mon, 24 Sep 2007 17:12:59 -0400
Subject: [R] Error: cannot allocate vector of size...
Message-ID: <1190668379.46f8285badee1@webmail.mail.gatech.edu>

Hi,

I want to change .RDA file to a text file. So I did as follows.

>load("my.rda")
>ls() ---> then it showed [1] exprs
>write.table(exprs,"C:\\my.txt",sep="\t")

I was successful with the first .RDA file. Then I used the same commands with
another .RDA file (172 MB)which is 4 times bigger than the first file (41.2 MB).
When I put the last command (write.table), it showed as below.

Error: cannot allocate vector of size 92.8 Mb
In addition: Warning messages:
1: The exprSet class is deprecated, use ExpressionSet instead
2: The exprSet class is deprecated, use ExpressionSet instead
3: The exprSet class is deprecated, use ExpressionSet instead
4: The exprSet class is deprecated, use ExpressionSet instead

What could be a problem in this case? Is it the memory problem? I believe I have
enough RAM and disk space in my computer.

Thank you.
Jittima


From jfox at mcmaster.ca  Tue Sep 25 00:28:02 2007
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 24 Sep 2007 18:28:02 -0400
Subject: [R] partial plots for logistic regression using glm
In-Reply-To: <Prayer.1.0.12.0709242302100.4661@wmail-a.ucl.ac.uk>
References: <Prayer.1.0.12.0709242302100.4661@wmail-a.ucl.ac.uk>
Message-ID: <web-186704086@cgpsrv2.cis.mcmaster.ca>

Dear Stav,

Take a look at the effects package on CRAN and the associated paper at
<http://www.jstatsoft.org/v08/i15>.

I hope this helps,
 John

On 24 Sep 2007 23:02:10 +0100
 ucjtkst at ucl.ac.uk wrote:
> Dear R users,
> 
> I am modelling the probability of error in a behavioural task using
> the 
> glm() function (with the numbers of successes and failures listed for
> each 
> line in the data frame). How can I plot the partial effects of the 
> predictors?
> 
> Many thanks in advance,
> 
> Stav
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From murdoch at stats.uwo.ca  Tue Sep 25 00:32:07 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 24 Sep 2007 18:32:07 -0400
Subject: [R] parse in text function of plots, confusing behaviour
In-Reply-To: <63F107BCC37AEA49A75FD94AA3E07CB01236D8@pacpbsex01.pac.dfo-mpo.ca>
References: <63F107BCC37AEA49A75FD94AA3E07CB01236D8@pacpbsex01.pac.dfo-mpo.ca>
Message-ID: <46F83AE7.4040408@stats.uwo.ca>

On 24/09/2007 5:55 PM, Folkes, Michael wrote:
> HI all,
> I'm failing to understand why the following is happening.
> In this plot I rely on two text functions both using parse.  The second one works properly by writing a gamma symbol 5 times, the first one only works properly four times.  The only difference is that I add a string to the paste function of that which does work properly.  Why does it behave like this?
> thanks so much!
> Michael Folkes
>  
>  
> plot(1,1,type='n',ylim=c(-2,2))
> for(gam in seq(-1,.25,length=5)){
>  #doesn't repeat gamma symbol properly
>   text(.8,gam,parse(text=paste("gamma",gam,sep='')),cex=.75,adj=0)
>  
> # however this works if an additional string is included in the paste function
>   text(1,gam,parse(text=paste("gamma","~hi",gam,sep='')),cex=.75,adj=0)
> }


Take a look at what you're trying to plot:

 > for (gam in seq(-1, 0.25, length=5)) {
+   print(parse(text=paste("gamma",gam,sep='')))
+ }
expression(gamma-1)
attr(,"srcfile")
<text>
expression(gamma-0.6875)
attr(,"srcfile")
<text>
expression(gamma-0.375)
attr(,"srcfile")
<text>
expression(gamma-0.0625)
attr(,"srcfile")
<text>
expression(gamma0.25)
attr(,"srcfile")
<text>

In the first 4 cases, it's "gamma - value", while the last one is 
"gammavalue".

You probably want something like the bquote example on the ?plotmath 
page, e.g.

 > for (gam in seq(-1, 0.25, length=5)) {
+   text(1, gam, bquote(paste(gamma," ",.(gam))))
+ }

Duncan Murdoch


From mtmorgan at fhcrc.org  Tue Sep 25 00:47:27 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 24 Sep 2007 15:47:27 -0700
Subject: [R] Error: cannot allocate vector of size...
In-Reply-To: <1190668379.46f8285badee1@webmail.mail.gatech.edu> (Jittima
	Piriyapongsa's message of "Mon, 24 Sep 2007 17:12:59 -0400")
References: <1190668379.46f8285badee1@webmail.mail.gatech.edu>
Message-ID: <6phfy13znnk.fsf@gopher4.fhcrc.org>

Jittima Piriyapongsa <gtg894p at mail.gatech.edu> writes:

> Hi,
>
> I want to change .RDA file to a text file. So I did as follows.
>
>>load("my.rda")
>>ls() ---> then it showed [1] exprs
>>write.table(exprs,"C:\\my.txt",sep="\t")
>
> I was successful with the first .RDA file. Then I used the same
> commands with another .RDA file (172 MB)which is 4 times bigger than
> the first file (41.2 MB).  When I put the last command
> (write.table), it showed as below.
>
> Error: cannot allocate vector of size 92.8 Mb
> In addition: Warning messages:
> 1: The exprSet class is deprecated, use ExpressionSet instead
> 2: The exprSet class is deprecated, use ExpressionSet instead
> 3: The exprSet class is deprecated, use ExpressionSet instead
> 4: The exprSet class is deprecated, use ExpressionSet instead
>
> What could be a problem in this case? Is it the memory problem? I
> believe I have enough RAM and disk space in my computer.

R has run out of RAM to allocate memory -- it has already allocated
memory, and now cannot allocate an addition 92.8 MB.

Is write.table doing what you want? A different approach would be to
write two tables, one with the 'expression' data

> write.table(exprs(exprs), "C:\\myExprs.txt", sep="\t")

the other with the description of phenotypes

> write.table(pData(exprs), "C:\\myPheno.txt", sep="\t")

This might be more memory efficient, but might also get your data in a
more immediately useable format.

Martin

> Thank you.
> Jittima
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From FolkesM at pac.dfo-mpo.gc.ca  Tue Sep 25 00:46:44 2007
From: FolkesM at pac.dfo-mpo.gc.ca (Folkes, Michael)
Date: Mon, 24 Sep 2007 15:46:44 -0700
Subject: [R] parse in text function of plots, confusing behaviour
References: <63F107BCC37AEA49A75FD94AA3E07CB01236D8@pacpbsex01.pac.dfo-mpo.ca>
	<46F83AE7.4040408@stats.uwo.ca>
Message-ID: <63F107BCC37AEA49A75FD94AA3E07CB01236D9@pacpbsex01.pac.dfo-mpo.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070924/c15d19e5/attachment.pl 

From friedman.steve at gmail.com  Tue Sep 25 01:15:14 2007
From: friedman.steve at gmail.com (Steve Friedman)
Date: Mon, 24 Sep 2007 19:15:14 -0400
Subject: [R] GWR modeling with dummy variables
Message-ID: <2439f5740709241615l13e811cbk80fdf8c13ea828fd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070924/c88d5de7/attachment.pl 

From m_olshansky at yahoo.com  Tue Sep 25 02:36:47 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Mon, 24 Sep 2007 17:36:47 -0700 (PDT)
Subject: [R] certain number of equations in function depending on
	parameter
In-Reply-To: <20070919064009.17170@gmx.net>
Message-ID: <343075.26952.qm@web32211.mail.mud.yahoo.com>

Hi Andreas,

One possible way would be to create a file containing
all your equations (which are written in a loop), then
source that file and then use uniroot.

Regards,

Moshe.

--- Andreas  Wittmann <andreas_wittmann at gmx.de> wrote:

> Hello everybody, 
> 
> i have the following problem to write a function
> which recognizes depending
> on the parameter-inputs how many equations for the
> calculation in the function
> are needed. 
> 
> Here is an example of my problem:
> 
> "myfun" <- function(a, b, c, d)
> {
>     k <- length(a)
>     #here d = 3 for example, but how can i
> dynamically controll 
>     #my function and tell her to build equations eq1
> to eq5 if d = 5?
>     
>     "eq1" <- function(a, b, y)
>     {
>         c[k-1] <- a[k-1] + b * y
>     } 
>     
>     "eq2" <- function(a, b, y)
>     {
>         c[k-2] <- a[k-2] + b * y
>     }     
>     
>     "eq3" <- function(a, b, y)
>     {
>         c[k-3] <- a[k-3] + b * y
>     } 
>     
>     "eq4" <- function(a, b, z)
>     {
>         1 - sum(c(eq1(z), eq2(z), eq3(z), z))
>     }   
>     
>     sol <- uniroot(eq4, lower=0, upper=1)
> }
> 
> I hope my problems is explained clear enough. I
> would be very happy 
> if you can give me some advice.
> 
> 
> best regards
> 
> Andreas
> --
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From thing52 at hotmail.com  Tue Sep 25 03:25:28 2007
From: thing52 at hotmail.com (Tish Ramlal)
Date: Tue, 25 Sep 2007 01:25:28 +0000
Subject: [R] hypothesis testing
Message-ID: <BAY108-W20B2B7F4C19577D0DAF264B4B70@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070925/e510b737/attachment.pl 

From xplaner800 at comcast.net  Tue Sep 25 03:28:42 2007
From: xplaner800 at comcast.net (Patrick Richardson)
Date: Mon, 24 Sep 2007 21:28:42 -0400
Subject: [R] Package Building help
Message-ID: <000001c7ff13$68c54a10$3a4fde30$@net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070924/9c14a8ed/attachment.pl 

From IPaek at ETS.ORG  Tue Sep 25 03:36:37 2007
From: IPaek at ETS.ORG (Paek, Insu)
Date: Mon, 24 Sep 2007 21:36:37 -0400
Subject: [R] Score test in logistic regression in R
Message-ID: <ABD8AC87AD7A664E948DCAD1A70ED3FA07856AA7@rosnt108.etslan.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070924/d3f342c0/attachment.pl 

From murdoch at stats.uwo.ca  Tue Sep 25 03:36:47 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 24 Sep 2007 21:36:47 -0400
Subject: [R] Package Building help
In-Reply-To: <000001c7ff13$68c54a10$3a4fde30$@net>
References: <000001c7ff13$68c54a10$3a4fde30$@net>
Message-ID: <46F8662F.80808@stats.uwo.ca>

On 24/09/2007 9:28 PM, Patrick Richardson wrote:
> List,
> 
>  
> 
> I've used package.skeleton to build my package and am trying to check it
> using R CMD check "." But can't seem to get anything to work.  When I try to
> enter the R CMD command into R I get this message.
> 
>  
> 
> R CMD check estpkg
> 
> Error: syntax error, unexpected SYMBOL, expecting '\n' or ';' in "R CMD"
> 
>  
> 
> I'm not sure if I'm using the wrong syntax or what but I can't get R CMD to
> check my package from within R.  I've tried to use Rcmd in the /bin folder
> of the R root directory and the DOS windows flashes on my screen and
> disappears immediately.  If someone could help me get over this, I would
> greatly appreciate it.

You need to run this from a console (what you call the "DOS window"). 
Before it will work, you'll need to install a number of tools:  see 
www.murdoch-sutherland.com/Rtools to get them.

Duncan Murdoch
> 
>  
> 
> Cheers,
> 
>  
> 
> Patrick
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From weigand.stephen at gmail.com  Tue Sep 25 03:53:50 2007
From: weigand.stephen at gmail.com (Stephen Weigand)
Date: Mon, 24 Sep 2007 20:53:50 -0500
Subject: [R] how to export.RDA file to a text file?
In-Reply-To: <1190663354.46f814baa2f02@webmail.mail.gatech.edu>
References: <1190663354.46f814baa2f02@webmail.mail.gatech.edu>
Message-ID: <bc47d3330709241853i388d901fk57d04e6f67ba0fb6@mail.gmail.com>

On 9/24/07, Jittima Piriyapongsa <gtg894p at mail.gatech.edu> wrote:
> Hi,
>
> Does anyone know how to export .RDA file (in R program) to a normal text file
> (readable by any text editor)? Also, how to export an object in R program into a
> text file (not .RDA file)?
>
> Thank you.
> Jittima

You may be used to the idea that there are code files and data files
and that's it. But an .RDA file is a saved version of one or more R
objects of any kind and therefore may contain a data set (stored as a
data.frame), a fitted regression model, AND a vector (for example).

Maybe do:

load("yourfile.RDA")
ls()

to see what you have in yourfile.RDA and then perhaps do

help(write.table)

to learn how to write out a matrix or data.frame as a text file if
that's what you're trying to do.

Hope this helps,

Stephen

-- 
Rochester, Minn. USA


From edd at debian.org  Tue Sep 25 04:08:08 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 24 Sep 2007 21:08:08 -0500
Subject: [R] Package Building help
In-Reply-To: <000001c7ff13$68c54a10$3a4fde30$@net>
References: <000001c7ff13$68c54a10$3a4fde30$@net>
Message-ID: <18168.28040.336616.486422@ron.nulle.part>


On 24 September 2007 at 21:28, Patrick Richardson wrote:
| I've used package.skeleton to build my package and am trying to check it
| using R CMD check "." But can't seem to get anything to work.  When I try to
| enter the R CMD command into R I get this message.
| 
|  
| 
| R CMD check estpkg
| 
| Error: syntax error, unexpected SYMBOL, expecting '\n' or ';' in "R CMD"
| 
|  
| 
| I'm not sure if I'm using the wrong syntax or what but I can't get R CMD to
| check my package from within R.  I've tried to use Rcmd in the /bin folder

Use the source() function from inside R to read the file, and have R parse
it.  Recent versions of R give you the line number of the offending
expression.

Hth, Dirk

-- 
Three out of two people have difficulties with fractions.


From cberry at tajo.ucsd.edu  Tue Sep 25 04:08:25 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Mon, 24 Sep 2007 19:08:25 -0700
Subject: [R] how to export.RDA file to a text file?
In-Reply-To: <bc47d3330709241853i388d901fk57d04e6f67ba0fb6@mail.gmail.com>
References: <1190663354.46f814baa2f02@webmail.mail.gatech.edu>
	<bc47d3330709241853i388d901fk57d04e6f67ba0fb6@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709241900330.14186@tajo.ucsd.edu>

On Mon, 24 Sep 2007, Stephen Weigand wrote:

> On 9/24/07, Jittima Piriyapongsa <gtg894p at mail.gatech.edu> wrote:
>> Hi,
>>
>> Does anyone know how to export .RDA file (in R program) to a normal text file
>> (readable by any text editor)?

Is this what you mean?

 	load( "old.RDA" )
 	save( list=ls(), file='new.rda' , ascii = TRUE )

This is literally readable by a text editor, and you can change the 
objects in that file.

But you need to have a _deep_ understanding of the format to avoid 
breaking things. And I doubt that those who have that understanding would 
ever attempt to edit such a file with a text editor.

Please refer to the _posting guide_ and revise your question if this or 
Stephen's response did not answer your question.

Chuck

Also, how to export an object in R program into a
>> text file (not .RDA file)?
>>
>> Thank you.
>> Jittima
>
> You may be used to the idea that there are code files and data files
> and that's it. But an .RDA file is a saved version of one or more R
> objects of any kind and therefore may contain a data set (stored as a
> data.frame), a fitted regression model, AND a vector (for example).
>
> Maybe do:
>
> load("yourfile.RDA")
> ls()
>
> to see what you have in yourfile.RDA and then perhaps do
>
> help(write.table)
>
> to learn how to write out a matrix or data.frame as a text file if
> that's what you're trying to do.
>
> Hope this helps,
>
> Stephen
>
> -- 
> Rochester, Minn. USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From chainsawtiney at gmail.com  Tue Sep 25 06:15:01 2007
From: chainsawtiney at gmail.com (Chung-hong Chan)
Date: Tue, 25 Sep 2007 12:15:01 +0800
Subject: [R] Cumulative Frequency table
Message-ID: <30d7ea360709242115u6174359bt961f67f346ed218e@mail.gmail.com>

Dear R gurus,

I think this question is very trivial, but I search around the HELP
file and this maillist can come up with no answer. Suppose I have a
vector called AGE like this

> sort(AGE)
  [1] 30 34 35 37 37 38 38 38 38 39 39 40 40 42 42 43 43 43 43 43 43 44
 [23] 44 44 44 44 44 44 45 45 45 46 46 46 46 46 46 47 47 47 47 47 47 48
.....

I can count the frequency based on some cut point using table with cut,

> table(cut(AGE, b=c(0,39,49,59,69,79,89)))

 (0,39] (39,49] (49,59] (59,69] (69,79] (79,89]
     11      46      70      45      16       1

How can I calculate the cumulative Frequency, e.g.

0-39 11
40-49 57
50-59 127
60-69 172
70-79 188
80-89 189

using R command?



-- 
CH Chan
Research Assistant - KWH
http://www.macgrass.com


From p.dalgaard at biostat.ku.dk  Tue Sep 25 06:23:10 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 25 Sep 2007 06:23:10 +0200
Subject: [R] truehist?
In-Reply-To: <bd07447b0709240907s6b8209c7k5908e6676e991240@mail.gmail.com>
References: <bd07447b0709240907s6b8209c7k5908e6676e991240@mail.gmail.com>
Message-ID: <46F88D2E.7010001@biostat.ku.dk>

Carlos "Gu?no" Grohmann wrote:
> Hello,
> After a long time, I needed the truehist function, but my system
> couldn't found it. I tried to install the package MAAS, but I couldn't
> found it! Something happened?
>
> Carlos
>
>   
It's in MASS (sic).

help.search("truehist") would have told you.


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From jholtman at gmail.com  Tue Sep 25 06:39:57 2007
From: jholtman at gmail.com (jim holtman)
Date: Tue, 25 Sep 2007 00:39:57 -0400
Subject: [R] Cumulative Frequency table
In-Reply-To: <30d7ea360709242115u6174359bt961f67f346ed218e@mail.gmail.com>
References: <30d7ea360709242115u6174359bt961f67f346ed218e@mail.gmail.com>
Message-ID: <644e1f320709242139g6532ab5dm7898666d13182776@mail.gmail.com>

?cumsum

> x <- table(cut(AGE, b=c(0,39,49,59,69,79,89)))
> x

 (0,39] (39,49] (49,59] (59,69] (69,79] (79,89]
     24      38      41      37      26      34
> cumsum(x)
 (0,39] (39,49] (49,59] (59,69] (69,79] (79,89]
     24      62     103     140     166     200
>


On 9/25/07, Chung-hong Chan <chainsawtiney at gmail.com> wrote:
> Dear R gurus,
>
> I think this question is very trivial, but I search around the HELP
> file and this maillist can come up with no answer. Suppose I have a
> vector called AGE like this
>
> > sort(AGE)
>  [1] 30 34 35 37 37 38 38 38 38 39 39 40 40 42 42 43 43 43 43 43 43 44
>  [23] 44 44 44 44 44 44 45 45 45 46 46 46 46 46 46 47 47 47 47 47 47 48
> .....
>
> I can count the frequency based on some cut point using table with cut,
>
> > table(cut(AGE, b=c(0,39,49,59,69,79,89)))
>
>  (0,39] (39,49] (49,59] (59,69] (69,79] (79,89]
>     11      46      70      45      16       1
>
> How can I calculate the cumulative Frequency, e.g.
>
> 0-39 11
> 40-49 57
> 50-59 127
> 60-69 172
> 70-79 188
> 80-89 189
>
> using R command?
>
>
>
> --
> CH Chan
> Research Assistant - KWH
> http://www.macgrass.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From friedrich.leisch at stat.uni-muenchen.de  Tue Sep 25 07:38:01 2007
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Tue, 25 Sep 2007 07:38:01 +0200
Subject: [R] Proposal: Archive UseR conference presentations at
	www.r-project.org/useR-yyyy
In-Reply-To: <f8e6ff050709240725u488e5070kb568af29edd96524@mail.gmail.com>
References: <f8e6ff050709041413k70340217r76b51984d9e23ef9@mail.gmail.com>
	<fcmq8e$udt$1@sea.gmane.org>
	<46EFC023.7030803@statistik.uni-dortmund.de>
	<f8e6ff050709180805y6e856bd8t23da94e178e2bf43@mail.gmail.com>
	<40e66e0b0709180856s5d4c2218n6f74fe7575402244@mail.gmail.com>
	<18167.30368.575305.907742@lxh5.stat.uni-muenchen.de>
	<f8e6ff050709240725u488e5070kb568af29edd96524@mail.gmail.com>
Message-ID: <18168.40633.133271.581108@lxh5.stat.uni-muenchen.de>

>>>>> On Mon, 24 Sep 2007 09:25:27 -0500,
>>>>> hadley wickham (hw) wrote:

  >> I think I like Hadley's proposal of collecting conference webpages
  >> (after the conference is over) to one of our servers
  >> better. Redirecting to pages at different locations is dangerous when
  >> people move on to new positions.

  > That wasn't my suggestion,

Sorry, my mistake. I was wading through several hundred emails
yesterday after an offline period ... makes your brain go numb rather
quickly.

  > but I can understand your desire to do
  > that.  Perhaps just taking a static snapshot using something like
  > wget, and hosting that on the R-project website would be a good
  > compromise.

Hmm, wouldn't it be easier if the hosting institution would make a tgz
file? wget over HTTP is rather bad in resolving links etc

we could include a note on the top page that this is only a snapshot
copy and have a link to the original site (in case something changes
there).

  >> E.g., I currently have the "problem" that since both Kurt and myself
  >> are no longer at TU Wien, we cannot guarantee how long
  >> www.ci.tuwien.ac.at will be up and running, and we were talking last
  >> week about moving the old DSC webpages to the server at WU running
  >> www.R-project.org.

  > Yes, this is why I prefer to host all of my sites on an external host.

  >> So it would make a lot of sense to me to collect old conference pages
  >> to a central location under the www.R-project.org umbrella. During the
  >> active phase of a conference it is certainly better to have them on
  >> a server under control of the local organizing committee.

  > The one problem is setting up a redirect so that existing links and
  > google searches aren't broken.  This would need to be put in place at
  > least 6 months before the old website closed.

Yes, very good point, I didn't think about that. But the R site is
searched very often, so material there appears rather quickly on
Google searches. Ad bookmarks: I don't want to remove the old site,
just have an archive copy at a central location.

.f


From ripley at stats.ox.ac.uk  Tue Sep 25 08:39:20 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 Sep 2007 07:39:20 +0100 (BST)
Subject: [R] PicTeX output: how to suppress escaping of $ signs and
 braces?
In-Reply-To: <alpine.LFD.0.999.0709242231450.26555@seagull>
References: <alpine.LFD.0.999.0709242231450.26555@seagull>
Message-ID: <Pine.LNX.4.64.0709250729560.7548@gannet.stats.ox.ac.uk>

R is trying to do device-independent graphics and produce the same 
annotation output on any graphics device.  It assumes that when you write 
'$' you want a dollar sign, and so on.  Also, it needs to be able to 
render the text to find its bounding box (and baseline) and so place it 
accurately.

The necessary escaping is done in C in the pictex() device, and it is not 
optional.  You would need to make a modified version of the pictex() 
device to alter this, but you would still have the problem that the 
precise placement is done at a much higher level in code common to all 
devices.


On Mon, 24 Sep 2007, Dan Hatton wrote:

>
> Dear All,
>
> I'm trying to draw a TeX histogram with the following pair of commands,
>
> pictex(file = "realhisto.tex")
> hist(Peaklist$V3,xlab="Height $z/\\ut{mm}$",ylab="Probability density $\\phi{}(z-z_0)/(1/\\ut{mm})$")
>
> However, in the resulting file realhisto.tex, I get, for example
>
> \put {Height \$z/\ut\{mm\}\$}  [lB] <0.00pt,0.00pt> at 136.13 9.17
>
> when what I'd like is
>
> \put {Height $z/\ut{mm}$}  [lB] <0.00pt,0.00pt> at 136.13 9.17
>
> i.e. the $ signs and braces not to be escaped with backslashes.
>
> I've tried a couple of things that "help(Quotes)" hints at, like
> replacing the double quotes with single quotes or backticks, or
> explicitly escaping the $ signs with backslashes, but none of these
> things seem to help.
>
> Any ideas, please?
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wl2776 at gmail.com  Tue Sep 25 08:43:36 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Mon, 24 Sep 2007 23:43:36 -0700 (PDT)
Subject: [R] how to export.RDA file to a text file?
In-Reply-To: <1190663354.46f814baa2f02@webmail.mail.gatech.edu>
References: <1190663354.46f814baa2f02@webmail.mail.gatech.edu>
Message-ID: <12873965.post@talk.nabble.com>


attach("file_name.RDA")
dump(list=ls(2),file="file_name.R")

This creates file file_name.R, containing R commands, executed to produce
the contents of the file_name.RDA

Data frames and matrices can be stored in ASCII file in tabular form using
write.table()

You can also consider cat()


Jittima Piriyapongsa wrote:
> 
> Hi,
> 
> Does anyone know how to export .RDA file (in R program) to a normal text
> file
> (readable by any text editor)? Also, how to export an object in R program
> into a
> text file (not .RDA file)?
> 
> Thank you.
> Jittima
> 

-- 
View this message in context: http://www.nabble.com/how-to-export.RDA-file-to-a-text-file--tf4511368.html#a12873965
Sent from the R help mailing list archive at Nabble.com.


From knoblauch at lyon.inserm.fr  Tue Sep 25 09:01:20 2007
From: knoblauch at lyon.inserm.fr (Ken Knoblauch)
Date: Tue, 25 Sep 2007 07:01:20 +0000 (UTC)
Subject: [R] Sweave and ggplot2
References: <mailman.15.1190628004.11754.r-help@r-project.org>
	<p06002006c31dbf62736a@[192.168.1.12]> <87hcljbw0v.fsf@gnugnus.org>
Message-ID: <loom.20070925T065850-132@post.gmane.org>

Julien Barnier <julien <at> no-log.org> writes:

> 
> Hi,
> When I try this example at work, I got an error message during Sweave
> which is close from something like "warning : semitransparency not
> supported by this device". When I try at home (with the given
> sessionInfo), I got no warning but in both the cases the result is the
> same : an empty pdf file for the figure and an error during pdflatex
> compilation.
> 
> I've put online an example Rnw file and the almost empty pdf produced
> here :
> 
> http://dd.nozav.org/transferts/
> 
> Thanks in advance for any help.

This might be a case of FAQ 7.22 since ggplot(2) like lattice depend on grid.
I would try wrapping the ggplot commands in a print statement.

HTH,

ken


From mauricio.malfert at gmail.com  Tue Sep 25 09:26:38 2007
From: mauricio.malfert at gmail.com (Mauricio Malfert)
Date: Tue, 25 Sep 2007 09:26:38 +0200
Subject: [R]  How to read stored functions
Message-ID: <12472d0d0709250026m1ac23785r6f2ca7a2a7269049@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070925/9d567ea7/attachment.pl 

From wl2776 at gmail.com  Tue Sep 25 09:35:18 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Tue, 25 Sep 2007 00:35:18 -0700 (PDT)
Subject: [R] How to read stored functions
In-Reply-To: <12472d0d0709250026m1ac23785r6f2ca7a2a7269049@mail.gmail.com>
References: <12472d0d0709250026m1ac23785r6f2ca7a2a7269049@mail.gmail.com>
Message-ID: <12874535.post@talk.nabble.com>



Mauricio Malfert wrote:
> 
> Hi I'm simulating missing data patterns and  I've started to get a lot of
> functions in the same .R file is it possible to store al these functions
> in
> a library like one does in C++ (i.e the .h file) and read the functions
> from
> the main .R file
> /Mauricio
> 

You can save your functions to a file with
save(<names>,file="/path/to/func_lib.RData") 
and then attach("/path/to/func_lib.RData").

Or, you can create a package and load it with library() or require()


-- 
View this message in context: http://www.nabble.com/How-to-read-stored-functions-tf4513863.html#a12874535
Sent from the R help mailing list archive at Nabble.com.


From karin.lagesen at medisin.uio.no  Tue Sep 25 09:46:26 2007
From: karin.lagesen at medisin.uio.no (Karin Lagesen)
Date: Tue, 25 Sep 2007 09:46:26 +0200
Subject: [R] Am I misunderstanding the ifelse construction?
Message-ID: <ypx6k5qf5grx.fsf@uracil.uio.no>


I have a function like this:

changedir <- function(dataframe) {
dir <- dataframe$dir
gc_content <- dataframe$gc_content
d <- ifelse(dir == "-",
            gc_content <- -gc_content,gc_content <- gc_content)
return(d)
}

The goal of this function is to be able to input a data frame like this:


> lala
   dir gc_content
1    +        0.5
2    -        0.5
3    +        0.5
4    -        0.5
5    +        0.5
6    -        0.5
7    +        0.5
8    -        0.5
9    +        0.5
10   -        0.5
11   +        0.5
12   -        0.5
13   +        0.5
14   -        0.5
15   +        0.5
16   -        0.5
17   +        0.5
18   -        0.5
19   +        0.5
20   -        0.5
>

And change the sign of the value of the gc_content field if the
corresponding dir field is negative.

Howver, when I run this through the changedir function, all of the
gc_contents become negative.

An I misunderstanding how to use the ifelse construct? And in that
case, how should I go about doing this in a different way?

Thankyou very much in advance for your help, and I hope that my
question is not too banal!

Karin
-- 
Karin Lagesen, PhD student
karin.lagesen at medisin.uio.no
http://folk.uio.no/karinlag


From jared.oconnell at csiro.au  Tue Sep 25 09:47:57 2007
From: jared.oconnell at csiro.au (Jared O'Connell)
Date: Tue, 25 Sep 2007 15:47:57 +0800
Subject: [R] How to read stored functions
In-Reply-To: <12874535.post@talk.nabble.com>
References: <12472d0d0709250026m1ac23785r6f2ca7a2a7269049@mail.gmail.com>
	<12874535.post@talk.nabble.com>
Message-ID: <8c464e8f0709250047u2fb6e74aj79a48dc0d726422d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070925/4f80d22c/attachment.pl 

From jbarnier at ens-lsh.fr  Tue Sep 25 10:09:17 2007
From: jbarnier at ens-lsh.fr (Julien Barnier)
Date: Tue, 25 Sep 2007 10:09:17 +0200
Subject: [R] Sweave and ggplot2
References: <mailman.15.1190628004.11754.r-help@r-project.org>
	<p06002006c31dbf62736a@[192.168.1.12]> <87hcljbw0v.fsf@gnugnus.org>
	<loom.20070925T065850-132@post.gmane.org>
Message-ID: <87ejgnb1zm.fsf@ens-lsh.fr>

Hi Ken,

> This might be a case of FAQ 7.22 since ggplot(2) like lattice depend on grid.
> I would try wrapping the ggplot commands in a print statement.

Yes, you're right. Replacing :

<<fig=TRUE>>=
ggplot(d,aes(y=t,x=u)) + geom_point(colour=alpha('black', 0.05))
@

with :

<<fig=TRUE>>=
print(ggplot(d,aes(y=t,x=u)) + geom_point(colour=alpha('black', 0.05)))
@

made the whole thing work.

Thanks a lot !

Julien

-- 
Julien Barnier
Groupe de recherche sur la socialisation
ENS-LSH - Lyon, France


From wl2776 at gmail.com  Tue Sep 25 10:15:20 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Tue, 25 Sep 2007 01:15:20 -0700 (PDT)
Subject: [R] How to read stored functions
In-Reply-To: <8c464e8f0709250047u2fb6e74aj79a48dc0d726422d@mail.gmail.com>
References: <12472d0d0709250026m1ac23785r6f2ca7a2a7269049@mail.gmail.com>
	<12874535.post@talk.nabble.com>
	<8c464e8f0709250047u2fb6e74aj79a48dc0d726422d@mail.gmail.com>
Message-ID: <12875031.post@talk.nabble.com>


source'ing is a bad practice because this saves additional copies of
functions and data in the local workspace.

Wasting disk space is not a problem now since HDDs are cheap and function
bodies are generally small.

But, when you change any function body, you have to repeat that source()
call in local workspace of every project using the functions.


Jared O'Connell wrote:
> 
> Having your functions in a text file, say "functions.r" and then calling:
> 
>>source("functions.r")
> 
> is also an option.  This assumes you are in the same directory as "
> functions.r".  Perhaps take a look at ?setwd and ?getwd as well.
> 
> 
> On 9/25/07, Vladimir Eremeev <wl2776 at gmail.com> wrote:
>>
>> You can save your functions to a file with
>> save(<names>,file="/path/to/func_lib.RData")
>> and then attach("/path/to/func_lib.RData").
>>
>> Or, you can create a package and load it with library() or require()
>> 
>> Mauricio Malfert wrote:
>> >
>> > Hi I'm simulating missing data patterns and  I've started to get a lot
>> > of
>> > functions in the same .R file is it possible to store al these
>> functions
>> > in
>> > a library like one does in C++ (i.e the .h file) and read the functions
>> > from
>> > the main .R file
>> > /Mauricio
> 

-- 
View this message in context: http://www.nabble.com/How-to-read-stored-functions-tf4513863.html#a12875031
Sent from the R help mailing list archive at Nabble.com.


From P.Dalgaard at biostat.ku.dk  Tue Sep 25 10:20:48 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 25 Sep 2007 10:20:48 +0200
Subject: [R] Am I misunderstanding the ifelse construction?
In-Reply-To: <ypx6k5qf5grx.fsf@uracil.uio.no>
References: <ypx6k5qf5grx.fsf@uracil.uio.no>
Message-ID: <46F8C4E0.7020406@biostat.ku.dk>

Karin Lagesen wrote:
> I have a function like this:
>
> changedir <- function(dataframe) {
> dir <- dataframe$dir
> gc_content <- dataframe$gc_content
> d <- ifelse(dir == "-",
>             gc_content <- -gc_content,gc_content <- gc_content)
> return(d)
> }
>
> The goal of this function is to be able to input a data frame like this:
>
>
>   
>> lala
>>     
>    dir gc_content
> 1    +        0.5
> 2    -        0.5
> 3    +        0.5
> 4    -        0.5
> 5    +        0.5
> 6    -        0.5
> 7    +        0.5
> 8    -        0.5
> 9    +        0.5
> 10   -        0.5
> 11   +        0.5
> 12   -        0.5
> 13   +        0.5
> 14   -        0.5
> 15   +        0.5
> 16   -        0.5
> 17   +        0.5
> 18   -        0.5
> 19   +        0.5
> 20   -        0.5
>   
>
> And change the sign of the value of the gc_content field if the
> corresponding dir field is negative.
>
> Howver, when I run this through the changedir function, all of the
> gc_contents become negative.
>
> An I misunderstanding how to use the ifelse construct? And in that
> case, how should I go about doing this in a different way?
>
> Thankyou very much in advance for your help, and I hope that my
> question is not too banal!
>
> Karin
>   
Yes, you are misunderstanding it and you should study the examples on
the help page.

One key point is that (in general) both the 'yes' and 'no' get
evaluated, so having assignments to the same variable in there is a
really bad idea. Another point is that ifelse takes three _vectors_ and
returns a fourth.

I'd do

  result <- ifelse(dir=="-", -gc_content, gc_content)

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From jbarnier at ens-lsh.fr  Tue Sep 25 10:18:39 2007
From: jbarnier at ens-lsh.fr (Julien Barnier)
Date: Tue, 25 Sep 2007 10:18:39 +0200
Subject: [R] Am I misunderstanding the ifelse construction?
References: <ypx6k5qf5grx.fsf@uracil.uio.no>
Message-ID: <87abrbb1k0.fsf@ens-lsh.fr>

Hi,

> An I misunderstanding how to use the ifelse construct? And in that
> case, how should I go about doing this in a different way?

The ifelse function only apply to a single test passed as first
argument, and the second and third arguments are the value returned,
and thus should not be an R instruction like ?gc_content <-
-gc_content?.

Maybe you could try the following :

dataframe$numdir <- 1
dataframe$numdir[dataframe$dir=="-"] <- -1
d <- dataframe$gc_content * dataframe$numdir

HTH,

Julien

-- 
Julien Barnier
Groupe de recherche sur la socialisation
ENS-LSH - Lyon, France


From gustaf.rydevik at gmail.com  Tue Sep 25 10:27:10 2007
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Tue, 25 Sep 2007 10:27:10 +0200
Subject: [R] Am I misunderstanding the ifelse construction?
In-Reply-To: <ypx6k5qf5grx.fsf@uracil.uio.no>
References: <ypx6k5qf5grx.fsf@uracil.uio.no>
Message-ID: <45f568c70709250127p78b9310ema31b5bf6c6d42483@mail.gmail.com>

On 9/25/07, Karin Lagesen <karin.lagesen at medisin.uio.no> wrote:
>
> I have a function like this:
>
> changedir <- function(dataframe) {
> dir <- dataframe$dir
> gc_content <- dataframe$gc_content
> d <- ifelse(dir == "-",
>             gc_content <- -gc_content,gc_content <- gc_content)
> return(d)
> }
>
> The goal of this function is to be able to input a data frame like this:
>
>
> > lala
>    dir gc_content
> 1    +        0.5
> 2    -        0.5
> 3    +        0.5
> 4    -        0.5
> 5    +        0.5
> 6    -        0.5
> 7    +        0.5
> 8    -        0.5
> 9    +        0.5
> 10   -        0.5
> 11   +        0.5
> 12   -        0.5
> 13   +        0.5
> 14   -        0.5
> 15   +        0.5
> 16   -        0.5
> 17   +        0.5
> 18   -        0.5
> 19   +        0.5
> 20   -        0.5
> >
>
> And change the sign of the value of the gc_content field if the
> corresponding dir field is negative.
>
> Howver, when I run this through the changedir function, all of the
> gc_contents become negative.
>
> An I misunderstanding how to use the ifelse construct? And in that
> case, how should I go about doing this in a different way?
>
> Thankyou very much in advance for your help, and I hope that my
> question is not too banal!
>
> Karin
> --


Hej igen!

The ifelse(x,a,b) returns a vector whose elements are picked from
either a or b depending on whether x is true or false. However it
evaluates both the a and the b vector. Since you are changing
gc_content in both a and b, strange things are bound to happen. The
easiest way would be to just skip the assignment in the ifelse
construct.

Like so:

changedir <- function(dataframe) {
dir <- dataframe$dir
gc_content <- dataframe$gc_content
d <- ifelse(dir == "-",
           -gc_content,gc_content)
return(d)
}

Hope it helps!

best,

Gustaf

-- 
Gustaf Rydevik, M.Sci.
tel: +46(0)703 051 451
address:Essingetorget 40,112 66 Stockholm, SE
skype:gustaf_rydevik


From E.Vettorazzi at uke.uni-hamburg.de  Tue Sep 25 10:39:23 2007
From: E.Vettorazzi at uke.uni-hamburg.de (Eik Vettorazzi)
Date: Tue, 25 Sep 2007 10:39:23 +0200
Subject: [R] Am I misunderstanding the ifelse construction?
In-Reply-To: <ypx6k5qf5grx.fsf@uracil.uio.no>
References: <ypx6k5qf5grx.fsf@uracil.uio.no>
Message-ID: <46F8C93B.6010005@uke.uni-hamburg.de>

d <- ifelse(dir == "-", -gc_content , gc_content)
works. You need not assign gc_content a new value in each comparison,  
because then your "result" depends only on the last value of "dir", 
which happened to be "-", so you got -0.5 for all gc_content.

hth


Karin Lagesen schrieb:
> I have a function like this:
>
> changedir <- function(dataframe) {
> dir <- dataframe$dir
> gc_content <- dataframe$gc_content
> d <- ifelse(dir == "-",
>             gc_content <- -gc_content,gc_content <- gc_content)
> return(d)
> }
>
> The goal of this function is to be able to input a data frame like this:
>
>
>   
>> lala
>>     
>    dir gc_content
> 1    +        0.5
> 2    -        0.5
> 3    +        0.5
> 4    -        0.5
> 5    +        0.5
> 6    -        0.5
> 7    +        0.5
> 8    -        0.5
> 9    +        0.5
> 10   -        0.5
> 11   +        0.5
> 12   -        0.5
> 13   +        0.5
> 14   -        0.5
> 15   +        0.5
> 16   -        0.5
> 17   +        0.5
> 18   -        0.5
> 19   +        0.5
> 20   -        0.5
>   
>
> And change the sign of the value of the gc_content field if the
> corresponding dir field is negative.
>
> Howver, when I run this through the changedir function, all of the
> gc_contents become negative.
>
> An I misunderstanding how to use the ifelse construct? And in that
> case, how should I go about doing this in a different way?
>
> Thankyou very much in advance for your help, and I hope that my
> question is not too banal!
>
> Karin
>   


-- 
Eik Vettorazzi
Institut f?r Medizinische Biometrie und Epidemiologie
Universit?tsklinikum Hamburg-Eppendorf

Martinistr. 52
20246 Hamburg

T ++49/40/42803-8243
F ++49/40/42803-7790


From jkroepfl at gmx.net  Tue Sep 25 10:54:04 2007
From: jkroepfl at gmx.net (=?iso-8859-1?Q?=22Julia_Kr=F6pfl=22?=)
Date: Tue, 25 Sep 2007 10:54:04 +0200
Subject: [R] 10- fold cross validation for naive bayes(e1071)
Message-ID: <20070925085404.53380@gmx.net>

Hallo!

I would need a code for 10-fold cross validation for the classifiers Naive Bayes and svm (e1071) package. Has there already been done something like that?

I tried to do it myself by applying the tune function first:

library(e1071)
tune.control <- tune.control(random =F, nrepeat=1, repeat.aggregate=min.,sampling=c("cross"),sampling.aggregate=mean, cross=10, best.model=T, performances=T)

model <- naiveBayes(code~., mydata, tune.control)
pred <- predict(model, mydata)
table(pred, mydata$code)
chisq.test(code, pred)


but I get the same results as without tuning it.

It would be great if someone could help me with this.

thx a lot, 
Juila
-- 
Psssst! Schon vom neuen GMX MultiMessenger geh?rt?
Der kanns mit allen: http://www.gmx.net/de/go/multimessenger


From jkroepfl at gmx.net  Tue Sep 25 11:00:33 2007
From: jkroepfl at gmx.net (=?iso-8859-1?Q?=22Julia_Kr=F6pfl=22?=)
Date: Tue, 25 Sep 2007 11:00:33 +0200
Subject: [R] finding a stable cluster for kmeans
Message-ID: <20070925090033.53360@gmx.net>

Hallo!

I applied kmeans to my data:

kcluster= kmeans((mydata, 4, iter.max=10)
table(code, kcluster$cluster)

If I run this code again, I get a different result as with the first trial (I understand that this is correct, since kmeans starts randomly with assigning the clusters and therefore the outcomes can be different)
But is there a way to stabilize the cluster (meaning finding the one cluster that appears the most often in 10 trials)?

Thank you for any ideas,
Julia 
--


From ecjbosu at aol.com  Tue Sep 25 11:02:40 2007
From: ecjbosu at aol.com (Joe W. Byers)
Date: Tue, 25 Sep 2007 04:02:40 -0500
Subject: [R] RJDBC and rjava
In-Reply-To: <fd1rk2$2ou$1@sea.gmane.org>
References: <BAY110-F40EEFEF56E9A5E0AA777BDC7200@phx.gbl>	<46666288.9050309@gmx.net>
	<fd1rk2$2ou$1@sea.gmane.org>
Message-ID: <fdais2$2gu$1@sea.gmane.org>

Help is sincerely requested.

After further investigation, I found that if I run .jmethods and have 
the listing below.  I know that this driver works because I have a java 
program using that loads data scrapped from the web every night.

The call to JDBC in my previous email is trying to create the instance 
of the jdbc driver as my java code does.
ie.
static final String JDBC_DRIVER = "com.mysql.jdbc.Driver";
Class.forName(JDBC_DRIVER); // .newInstance() ;
conn = DriverManager.getConnection("jdbc:mysql://" + svr + ":3306/"
+ sqldb + "?user=XXXXXXXXX&jdbcCompliantTruncation=false");

Again, I appreciate any and all help.

Joe


.jmethods('com.mysql.jdbc.Driver')

  [1] "public java.lang.String 
com.mysql.jdbc.NonRegisteringDriver.host(java.util.Properties)" 

  [2] "public java.util.Properties 
com.mysql.jdbc.NonRegisteringDriver.parseURL(java.lang.String,java.util.Properties) 
throws java.sql.SQLException"
  [3] "public int 
com.mysql.jdbc.NonRegisteringDriver.port(java.util.Properties)" 

  [4] "public java.sql.Connection 
com.mysql.jdbc.NonRegisteringDriver.connect(java.lang.String,java.util.Properties) 
throws java.sql.SQLException"
  [5] "public boolean 
com.mysql.jdbc.NonRegisteringDriver.acceptsURL(java.lang.String) throws 
java.sql.SQLException"
  [6] "public int com.mysql.jdbc.NonRegisteringDriver.getMajorVersion()" 
 

  [7] "public int com.mysql.jdbc.NonRegisteringDriver.getMinorVersion()" 
 

  [8] "public java.sql.DriverPropertyInfo[] 
com.mysql.jdbc.NonRegisteringDriver.getPropertyInfo(java.lang.String,java.util.Properties) 
throws java.sql.SQLException"
  [9] "public boolean 
com.mysql.jdbc.NonRegisteringDriver.jdbcCompliant()" 

[10] "public java.lang.String 
com.mysql.jdbc.NonRegisteringDriver.database(java.util.Properties)" 

[11] "public java.lang.String 
com.mysql.jdbc.NonRegisteringDriver.property(java.lang.String,java.util.Properties)" 

[12] "public native int java.lang.Object.hashCode()" 
 

[13] "public final native java.lang.Class java.lang.Object.getClass()" 
 

[14] "public final native void java.lang.Object.wait(long) throws 
java.lang.InterruptedException" 

[15] "public final void java.lang.Object.wait(long,int) throws 
java.lang.InterruptedException" 

[16] "public final void java.lang.Object.wait() throws 
java.lang.InterruptedException" 

[17] "public boolean java.lang.Object.equals(java.lang.Object)" 
 

[18] "public java.lang.String java.lang.Object.toString()" 
 

[19] "public final native void java.lang.Object.notify()" 
 

[20] "public final native void java.lang.Object.notifyAll()"


Joe W. Byers wrote:
> I am having trouble getting RJDBC and rJava working.  rjava does not
> seem to be able to traverse my classpath that I define inside R.
> 
> My example is
> library(RJDBC)
> .jinit('C:\\Libraries\\mysql-connector-java-5.1.3-rc\\mysql-connector-java-5.1.3-rc-bin.jar')
> drv <- JDBC("com.mysql.jdbc.Driver",
> 'C:\\Libraries\\mysql-connector-java-5.1.3-rc\\mysql-connector-java-5.1.3-rc-bin.jar'
> , identifier.quote ="`")
> 
> 
> the call to JDBC and hence the call so jclassPath, cause the following error
> Error in JDBC("com.mysql.jdbc.Driver",
> "C:\\Libraries\\mysql-connector-java-5.1.3-rc\\mysql-connector-java-5.1.3-rc-bin.jar",
>  :
>         Cannot find JDBC driver class com.mysql.jdbc.Driver
> 
> Any help is greatly appreciated.
> 
> Thank you
> Joe
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jan.wiener at tuebingen.mpg.de  Tue Sep 25 11:13:58 2007
From: jan.wiener at tuebingen.mpg.de (Jan M. Wiener)
Date: Tue, 25 Sep 2007 11:13:58 +0200
Subject: [R] calculating/plotting error ellipses
In-Reply-To: <12864033.post@talk.nabble.com>
References: <46F7B2F8.7010200@tuebingen.mpg.de> <12864033.post@talk.nabble.com>
Message-ID: <46F8D156.6020605@tuebingen.mpg.de>

Hello,
thank you very much for the quick answer.
This works well. it draws a nice ellipse in the right orientation.
However, I  doubt that the ellipse represents the 95% confidence
interval, even if that is the standard-parameter for level is .95. The
ellipse surely is to large?
Any further help would be greatly appreciated.
Best,
Jan


bbolker wrote:
>
> Jan M. Wiener wrote:
>   
>> hello,
>> sorry for posting what may be a simple question:
>> i do have a matrix of coordinates (positional judgments, see below) and
>> now want to calculate and plot the corresponding error ellipse.
>> can anyone help me with the exact steps/syntax?
>>
>>     
>
> Something along the lines of:
>
> m = colMeans(xyDat)  # calc. column means
> v = var(xyDat)             # compute var-cov matrix
> library(ellipse)              # you may need install.packages("ellipse")
> first
> plot(ellipse(v,centre=m),type="l")   ## draw the confidence ellipse
> points(m[,1],m[,2])     # add the cent(re|er) point
>
>   Of course, I haven't actually tested this ...
>
>   Ben Bolker
>
>


From Wayne.W.Jones at shell.com  Tue Sep 25 11:22:18 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Tue, 25 Sep 2007 10:22:18 +0100
Subject: [R] 10- fold cross validation for naive bayes(e1071)
In-Reply-To: <20070925085404.53380@gmx.net>
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B099@wyt-s-019.europe.shell.com>


Hi there, 

The tune function is extremely useful for quickly cross validating a model. However, you often need to modify some of the predict functions. 

Here is an example of tuning an svm and naiveBayes with the iris data set: 

naiveBayes: 

For some reason the naivebayes predict function (getS3method("predict","naiveBayes")) doesnt like it when you pass through the classification variable in the data you want to predict for. See the example in help(naiveBayes). Hence I modify the predict function to delete this variable:


"my.predict.NB"<-function(object,newdata){
predict(object,newdata=newdata[,-5],type="class")  
### Note here this will be data set specific. 
### Here the classification variable "Species" in this case appears in the 5th column of the data, hence I delete it.
### Apologies but culdne tquickly find a way to automate this!

}

tune(naiveBayes,Species ~ ., data = iris,predict.fun=my.predict.NB)


SVM: 

The predict function for svm seems to work fine. Hence use: 

obj <- tune(svm, Species~., data = iris, ranges = list(gamma = 2^(-1:1), cost = 2^(2:4)))
plot(obj)



Hope this helps, 

Wayne









-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of "Julia Kr?pfl"
Sent: 25 September 2007 09:54
To: R-help at r-project.org
Subject: [R] 10- fold cross validation for naive bayes(e1071)


Hallo!

I would need a code for 10-fold cross validation for the classifiers Naive Bayes and svm (e1071) package. Has there already been done something like that?

I tried to do it myself by applying the tune function first:

library(e1071)
tune.control <- tune.control(random =F, nrepeat=1, repeat.aggregate=min.,sampling=c("cross"),sampling.aggregate=mean, cross=10, best.model=T, performances=T)

model <- naiveBayes(code~., mydata, tune.control)
pred <- predict(model, mydata)
table(pred, mydata$code)
chisq.test(code, pred)


but I get the same results as without tuning it.

It would be great if someone could help me with this.

thx a lot, 
Juila
-- 
Psssst! Schon vom neuen GMX MultiMessenger geh?rt?
Der kanns mit allen: http://www.gmx.net/de/go/multimessenger

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From vi5u0-r at yahoo.co.uk  Tue Sep 25 11:28:00 2007
From: vi5u0-r at yahoo.co.uk (Dan Hatton)
Date: Tue, 25 Sep 2007 10:28:00 +0100 (BST)
Subject: [R] PicTeX output: how to suppress escaping of $ signs and
 braces?
In-Reply-To: <Pine.LNX.4.64.0709250729560.7548@gannet.stats.ox.ac.uk>
References: <alpine.LFD.0.999.0709242231450.26555@seagull>
	<Pine.LNX.4.64.0709250729560.7548@gannet.stats.ox.ac.uk>
Message-ID: <alpine.LFD.0.999.0709251024100.29577@seagull.bpi.cam.ac.uk>

On Tue, 25 Sep 2007, Prof Brian Ripley wrote:

> R is trying to do device-independent graphics and produce the same
> annotation output on any graphics device.  It assumes that when you
> write '$' you want a dollar sign, and so on.  Also, it needs to be
> able to render the text to find its bounding box (and baseline) and
> so place it accurately.  The necessary escaping is done in C in the
> pictex() device, and it is not optional.  You would need to make a
> modified version of the pictex() device to alter this, but you would
> still have the problem that the precise placement is done at a much
> higher level in code common to all devices.

Ah, OK, thank you.  So, necessity being the mother of invention, I've
worked around this with

hist(Peaklist$V3,xlab="\\histogramxlabel",ylab="\\histogramylabel")

then put in my LaTeX file

\newcommand{\histogramxlabel}{Height $z/\ut{mm}$}
\newcommand{\histogramylabel}{Probability density $\phi{}(z-z_0)/(1/\ut{mm})$}

-- 

Thanks again,

Dan Hatton

<http://www.bib.hatton.btinternet.co.uk/dan/>


From phgrosjean at sciviews.org  Tue Sep 25 11:28:20 2007
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue, 25 Sep 2007 11:28:20 +0200
Subject: [R] R Wiki down on 27 September
Message-ID: <46F8D4B4.2080503@sciviews.org>

Hi all,

Following the major electricity problem we got at the University during 
the summer (the R Wiki was down for several days), there is a need for 
shutting off electricity on the whole campus for a full day to fix it 
next Thursday 27 September. Consequently, the R Wiki may be down for up 
to 24h. We are sorry for the inconvenience.
Best,

Philippe Grosjean
-- 
..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Belgium
( ( ( ( (
..............................................................


From jared.oconnell at csiro.au  Tue Sep 25 11:32:10 2007
From: jared.oconnell at csiro.au (Jared O'Connell)
Date: Tue, 25 Sep 2007 17:32:10 +0800
Subject: [R] How to read stored functions
In-Reply-To: <12875031.post@talk.nabble.com>
References: <12472d0d0709250026m1ac23785r6f2ca7a2a7269049@mail.gmail.com>
	<12874535.post@talk.nabble.com>
	<8c464e8f0709250047u2fb6e74aj79a48dc0d726422d@mail.gmail.com>
	<12875031.post@talk.nabble.com>
Message-ID: <8c464e8f0709250232g17f92b6fk2e8360142d3618f2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070925/196ada3c/attachment.pl 

From erich.neuwirth at univie.ac.at  Tue Sep 25 12:10:57 2007
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Tue, 25 Sep 2007 12:10:57 +0200
Subject: [R] Am I misunderstanding the ifelse construction?
In-Reply-To: <46F8C93B.6010005@uke.uni-hamburg.de>
References: <ypx6k5qf5grx.fsf@uracil.uio.no>
	<46F8C93B.6010005@uke.uni-hamburg.de>
Message-ID: <46F8DEB1.8050902@univie.ac.at>

The thing to remember is that ifelse is a function,
it returns a value, so usually one does not need assignments within the
function call.

You also could do:
negindices <- dir=="-"
gc_content[negindices] <- -gc_content[negindices]

Eik Vettorazzi wrote:
> d <- ifelse(dir == "-", -gc_content , gc_content)
> works. You need not assign gc_content a new value in each comparison,  
> because then your "result" depends only on the last value of "dir", 
> which happened to be "-", so you got -0.5 for all gc_content.
> 
> hth
> 
-- 
Erich Neuwirth, University of Vienna
Faculty of Computer Science
Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-39464 Fax: +43-1-4277-39459


From e.rapsomaniki at mail.cryst.bbk.ac.uk  Tue Sep 25 12:46:17 2007
From: e.rapsomaniki at mail.cryst.bbk.ac.uk (Eleni Rapsomaniki)
Date: Tue, 25 Sep 2007 11:46:17 +0100
Subject: [R] Who uses R?
Message-ID: <1190717177.46f8e6f9d003d@webmail.cryst.bbk.ac.uk>

Dear R users,

I have started work in a Statistics government department and I am trying to
convince my bosses to install R on our computers (I can't do proper stats in
Excel!!). They asked me to prove that this is a widely used software (and not
just another free-source, bug infected toy I found on the web!) by suggesting
other big organisations that use it. Are you aware of any reputable places
(academic or not) that use R? (e.g. maybe you work for them)

I would be really grateful for any advice on this. Also suggestions on arguments
I could use to persuade them that R is so much better than Excel would be very
much appreciated.

Many Thanks
Eleni Rapsomaniki


From Markus.Gesmann at lloyds.com  Tue Sep 25 12:59:24 2007
From: Markus.Gesmann at lloyds.com (Gesmann, Markus)
Date: Tue, 25 Sep 2007 11:59:24 +0100
Subject: [R] Who uses R?
In-Reply-To: <1190717177.46f8e6f9d003d@webmail.cryst.bbk.ac.uk>
Message-ID: <1A3225557E20D541868170323C5DFF88E006C8@LNSCNTMAIL02.corp.lloydsnet>

Dear Eleni,

Maybe the participants of the useR conferences are a good start, see
e.g.
http://www.r-project.org/useR-2006/participants.html

Kind regards,

Markus Gesmann 
FPMA
Lloyd's Market Analysis
Lloyd's * One Lime Street * London * EC3M 7HA
Telephone +44 (0)20 7327 6472
Fax       +44 (0)20 7327 5718
http://www.lloyds.com

SAVE PAPER - THINK BEFORE YOU PRINT




-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Eleni Rapsomaniki
Sent: 25 September 2007 11:46
To: r-help at r-project.org
Subject: [R] Who uses R?


Dear R users,

I have started work in a Statistics government department and I am
trying to
convince my bosses to install R on our computers (I can't do proper
stats in
Excel!!). They asked me to prove that this is a widely used software
(and not
just another free-source, bug infected toy I found on the web!) by
suggesting
other big organisations that use it. Are you aware of any reputable
places
(academic or not) that use R? (e.g. maybe you work for them)

I would be really grateful for any advice on this. Also suggestions on
arguments
I could use to persuade them that R is so much better than Excel would
be very
much appreciated.

Many Thanks
Eleni Rapsomaniki

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
**********************************************************************
The information in this E-Mail and in any attachments is CON...{{dropped}}


From Wayne.W.Jones at shell.com  Tue Sep 25 13:02:01 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Tue, 25 Sep 2007 12:02:01 +0100
Subject: [R] finding a stable cluster for kmeans
In-Reply-To: <20070925090033.53360@gmx.net>
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B09D@wyt-s-019.europe.shell.com>


Hi there, 

If the final predicted clusters vary according to a random starting cluster then I suspect that your data is not clustering very well!! 
A few reasons for this may be: 

1) There are genuinely no clusters in the data!
2) You have chosen a poor distance measure.
3) You have picked an inappropriate number of clusters.

The basic goodness of fit of a cluster is that the variance within a cluster is small and the variance between clusters is large. 
Whenever I start to look for clusters I often use multidimensional scaling to look at the data in 2D! 

Lookup help(cmdscale)

If after this you wish to proceed, then I suggest you look up the library(cluster). 
The function silhouette is a nice tool to assess the appropriate number of clusters. 

Regards

Wayne


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of "Julia Kr?pfl"
Sent: 25 September 2007 10:01
To: R-help at r-project.org
Subject: [R] finding a stable cluster for kmeans


Hallo!

I applied kmeans to my data:

kcluster= kmeans((mydata, 4, iter.max=10)
table(code, kcluster$cluster)

If I run this code again, I get a different result as with the first trial (I understand that this is correct, since kmeans starts randomly with assigning the clusters and therefore the outcomes can be different)
But is there a way to stabilize the cluster (meaning finding the one cluster that appears the most often in 10 trials)?

Thank you for any ideas,
Julia 
--

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gustaf.rydevik at gmail.com  Tue Sep 25 13:02:15 2007
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Tue, 25 Sep 2007 13:02:15 +0200
Subject: [R] Who uses R?
In-Reply-To: <1190717177.46f8e6f9d003d@webmail.cryst.bbk.ac.uk>
References: <1190717177.46f8e6f9d003d@webmail.cryst.bbk.ac.uk>
Message-ID: <45f568c70709250402g6ce21148x54ea86e0ef6619da@mail.gmail.com>

On 9/25/07, Eleni Rapsomaniki <e.rapsomaniki at mail.cryst.bbk.ac.uk> wrote:
> Dear R users,
>
> I have started work in a Statistics government department and I am trying to
> convince my bosses to install R on our computers (I can't do proper stats in
> Excel!!). They asked me to prove that this is a widely used software (and not
> just another free-source, bug infected toy I found on the web!) by suggesting
> other big organisations that use it. Are you aware of any reputable places
> (academic or not) that use R? (e.g. maybe you work for them)
>
> I would be really grateful for any advice on this. Also suggestions on arguments
> I could use to persuade them that R is so much better than Excel would be very
> much appreciated.
>
> Many Thanks
> Eleni Rapsomaniki
>


The statistics section of the Swedish Institute for Infectious Disease
Control, where I work, use R about 70% of the time.
The MEB (medical epidemiology and biostatistics) department at
Karolinska Institutet, the nordic countries premiere medical
university, are also heavy R-users.

Best,

Gustaf

-- 
Gustaf Rydevik, M.Sci.
tel: +46(0)703 051 451
address:Essingetorget 40,112 66 Stockholm, SE
skype:gustaf_rydevik


From mark at wardle.org  Tue Sep 25 13:08:44 2007
From: mark at wardle.org (Mark Wardle)
Date: Tue, 25 Sep 2007 12:08:44 +0100
Subject: [R] How to read stored functions
In-Reply-To: <8c464e8f0709250232g17f92b6fk2e8360142d3618f2@mail.gmail.com>
References: <12472d0d0709250026m1ac23785r6f2ca7a2a7269049@mail.gmail.com>
	<12874535.post@talk.nabble.com>
	<8c464e8f0709250047u2fb6e74aj79a48dc0d726422d@mail.gmail.com>
	<12875031.post@talk.nabble.com>
	<8c464e8f0709250232g17f92b6fk2e8360142d3618f2@mail.gmail.com>
Message-ID: <b59a37130709250408x32b5e9e1m6de8ce64f61178c1@mail.gmail.com>

Jared:

I agree with your advice - I use source() too!

I think I work in a different way to many, and don't ever "save
current workspace" but use the interactive R environment cutting and
pasting code from documents held under version control.

As long as one is careful, I don't think there is any problem!

Best wishes,

Mark

On 25/09/2007, Jared O'Connell <jared.oconnell at csiro.au> wrote:
> ...and my R education (and embarassment) continues ;)
>
> On 9/25/07, Vladimir Eremeev <wl2776 at gmail.com> wrote:
> >
> >
> > source'ing is a bad practice because this saves additional copies of
> > functions and data in the local workspace.
> >
> > Wasting disk space is not a problem now since HDDs are cheap and function
> > bodies are generally small.
> >
> > But, when you change any function body, you have to repeat that source()
> > call in local workspace of every project using the functions.
> >
> >
> > Jared O'Connell wrote:
> > >
> > > Having your functions in a text file, say "functions.r" and then
> > calling:
> > >
> > >>source("functions.r")
> > >
> > > is also an option.  This assumes you are in the same directory as "
> > > functions.r".  Perhaps take a look at ?setwd and ?getwd as well.
> > >
> > >
> > > On 9/25/07, Vladimir Eremeev <wl2776 at gmail.com> wrote:
> > >>
> > >> You can save your functions to a file with
> > >> save(<names>,file="/path/to/func_lib.RData")
> > >> and then attach("/path/to/func_lib.RData").
> > >>
> > >> Or, you can create a package and load it with library() or require()
> > >>
> > >> Mauricio Malfert wrote:
> > >> >
> > >> > Hi I'm simulating missing data patterns and  I've started to get a
> > lot
> > >> > of
> > >> > functions in the same .R file is it possible to store al these
> > >> functions
> > >> > in
> > >> > a library like one does in C++ (i.e the .h file) and read the
> > functions
> > >> > from
> > >> > the main .R file
> > >> > /Mauricio
> > >
> >
> > --
> > View this message in context:
> > http://www.nabble.com/How-to-read-stored-functions-tf4513863.html#a12875031
> > Sent from the R help mailing list archive at Nabble.com.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________________________________
> This email has been scanned by the MessageLabs Email Security System.
> For more information please visit http://www.messagelabs.com/email
> ______________________________________________________________________
>


-- 
Dr. Mark Wardle
Specialist registrar, Neurology
Cardiff, UK


From s.blomberg1 at uq.edu.au  Tue Sep 25 13:09:17 2007
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Tue, 25 Sep 2007 21:09:17 +1000
Subject: [R] Who uses R?
In-Reply-To: <1A3225557E20D541868170323C5DFF88E006C8@LNSCNTMAIL02.corp.lloydsnet>
References: <1A3225557E20D541868170323C5DFF88E006C8@LNSCNTMAIL02.corp.lloydsnet>
Message-ID: <1190718557.9600.7.camel@sib-sblomber01d.sib.uq.edu.au>

See the "Members and Donors" section on the left-hand side of the R web
site.

Cheers,

Simon.

Note to self: Become a supporting member.

On Tue, 2007-09-25 at 11:59 +0100, Gesmann, Markus wrote:
> Dear Eleni,
> 
> Maybe the participants of the useR conferences are a good start, see
> e.g.
> http://www.r-project.org/useR-2006/participants.html
> 
> Kind regards,
> 
> Markus Gesmann 
> FPMA
> Lloyd's Market Analysis
> Lloyd's * One Lime Street * London * EC3M 7HA
> Telephone +44 (0)20 7327 6472
> Fax       +44 (0)20 7327 5718
> http://www.lloyds.com
> 
> SAVE PAPER - THINK BEFORE YOU PRINT
> 
> 
> 
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Eleni Rapsomaniki
> Sent: 25 September 2007 11:46
> To: r-help at r-project.org
> Subject: [R] Who uses R?
> 
> 
> Dear R users,
> 
> I have started work in a Statistics government department and I am
> trying to
> convince my bosses to install R on our computers (I can't do proper
> stats in
> Excel!!). They asked me to prove that this is a widely used software
> (and not
> just another free-source, bug infected toy I found on the web!) by
> suggesting
> other big organisations that use it. Are you aware of any reputable
> places
> (academic or not) that use R? (e.g. maybe you work for them)
> 
> I would be really grateful for any advice on this. Also suggestions on
> arguments
> I could use to persuade them that R is so much better than Excel would
> be very
> much appreciated.
> 
> Many Thanks
> Eleni Rapsomaniki
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> **********************************************************************
> The information in this E-Mail and in any attachments is CON...{{dropped}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia
Room 320 Goddard Building (8)
T: +61 7 3365 2506 
email: S.Blomberg1_at_uq.edu.au

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.


From pburns at pburns.seanet.com  Tue Sep 25 13:11:44 2007
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 25 Sep 2007 12:11:44 +0100
Subject: [R] Who uses R?
In-Reply-To: <1190717177.46f8e6f9d003d@webmail.cryst.bbk.ac.uk>
References: <1190717177.46f8e6f9d003d@webmail.cryst.bbk.ac.uk>
Message-ID: <46F8ECF0.6070801@pburns.seanet.com>

Just speaking of the field I'm most familiar with, there
are now users of R in many of the largest financial
companies in the world.

http://www.burns-stat.com/pages/Tutor/spreadsheet_addiction.html

is one place to look for arguments against Excel.
This was just updated to include an amusing numerical
bug in Excel 2007. Guess what 850 * 77.1 equals.


Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Eleni Rapsomaniki wrote:

>Dear R users,
>
>I have started work in a Statistics government department and I am trying to
>convince my bosses to install R on our computers (I can't do proper stats in
>Excel!!). They asked me to prove that this is a widely used software (and not
>just another free-source, bug infected toy I found on the web!) by suggesting
>other big organisations that use it. Are you aware of any reputable places
>(academic or not) that use R? (e.g. maybe you work for them)
>
>I would be really grateful for any advice on this. Also suggestions on arguments
>I could use to persuade them that R is so much better than Excel would be very
>much appreciated.
>
>Many Thanks
>Eleni Rapsomaniki
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>
>  
>


From tobias.minder at bluewin.ch  Tue Sep 25 13:23:26 2007
From: tobias.minder at bluewin.ch (squall44)
Date: Tue, 25 Sep 2007 04:23:26 -0700 (PDT)
Subject: [R] Adjust barplot to the left
Message-ID: <12877530.post@talk.nabble.com>


Hello,

I have the following problem: I created an ecdf and a barplot. Unfortunatly,
the bars are not where I would like them to be (please see picture below).

http://www.nabble.com/file/p12877530/problem.gif 

That's my code:
#------------------------
par(mfrow=c(2,1), mar=c(2,3,3,2))

#ECDF
x = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2)
F2.5 <- ecdf(x)
plot(F2.5,
  verticals= TRUE,
  do.p = TRUE,
  lwd=3,
  ylab = "",
  xlab = "",
  main = "Figur 2.12 Frequenztabelle und eVf",
  xlim = c(-1,4))
abline(h= (0:10)*0.1)
mtext(text="x", side=1, adj = 1.03, padj=1.23, cex=1.2)
mtext(text="f(x)", side=3, adj = -0.06, padj=-1, cex=1.2)

par(mar=c(4,3,1,2))

#Barplot               
width<-c(0.4, 0.4, 0.4)
height<-c(0.5, 0.35, 0.15)
barplot(height,width,xlim=c(-1,4), space=1.5,)
axis(side=1)
#------------------------

Can anyone tell me how I can adjust the bars to the left?
Thanks

Tobias
-- 
View this message in context: http://www.nabble.com/Adjust-barplot-to-the-left-tf4514904.html#a12877530
Sent from the R help mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Tue Sep 25 13:30:18 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 Sep 2007 12:30:18 +0100 (BST)
Subject: [R] Who uses R?
In-Reply-To: <1190718557.9600.7.camel@sib-sblomber01d.sib.uq.edu.au>
References: <1A3225557E20D541868170323C5DFF88E006C8@LNSCNTMAIL02.corp.lloydsnet>
	<1190718557.9600.7.camel@sib-sblomber01d.sib.uq.edu.au>
Message-ID: <Pine.LNX.4.64.0709251218340.8013@gannet.stats.ox.ac.uk>

That's a good answer, but the usage is very much wider.

As Pat Burns has just replied while I was composing this, many (maybe 
most) major financial institutions use R, although they may not want that 
to be taken as an endorsement.  Similarly for pharmaceuticals.

I would have thought a very convincing argument would be to point out all 
the books which have been published that are about or depend on R.

Eleni's email address is the UK, so perhaps the 'Statistics government 
department' is.  I hope not (as they should not need convincing), but
'University of Oxford' should suffice ....

On Tue, 25 Sep 2007, Simon Blomberg wrote:

> See the "Members and Donors" section on the left-hand side of the R web
> site.
>
> Cheers,
>
> Simon.
>
> Note to self: Become a supporting member.
>
> On Tue, 2007-09-25 at 11:59 +0100, Gesmann, Markus wrote:
>> Dear Eleni,
>>
>> Maybe the participants of the useR conferences are a good start, see
>> e.g.
>> http://www.r-project.org/useR-2006/participants.html
>>
>> Kind regards,
>>
>> Markus Gesmann
>> FPMA
>> Lloyd's Market Analysis
>> Lloyd's * One Lime Street * London * EC3M 7HA
>> Telephone +44 (0)20 7327 6472
>> Fax       +44 (0)20 7327 5718
>> http://www.lloyds.com
>>
>> SAVE PAPER - THINK BEFORE YOU PRINT
>>
>>
>>
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Eleni Rapsomaniki
>> Sent: 25 September 2007 11:46
>> To: r-help at r-project.org
>> Subject: [R] Who uses R?
>>
>>
>> Dear R users,
>>
>> I have started work in a Statistics government department and I am 
>> trying to convince my bosses to install R on our computers (I can't do 
>> proper stats in Excel!!). They asked me to prove that this is a widely 
>> used software (and not just another free-source, bug infected toy I 
>> found on the web!) by suggesting other big organisations that use it. 
>> Are you aware of any reputable places (academic or not) that use R? 
>> (e.g. maybe you work for them)
>>
>> I would be really grateful for any advice on this. Also suggestions on 
>> arguments I could use to persuade them that R is so much better than 
>> Excel would be very much appreciated.
>>
>> Many Thanks
>> Eleni Rapsomaniki
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> **********************************************************************
>> The information in this E-Mail and in any attachments is CON...{{dropped}}
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wl2776 at gmail.com  Tue Sep 25 13:37:18 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Tue, 25 Sep 2007 04:37:18 -0700 (PDT)
Subject: [R] Who uses R?
In-Reply-To: <1190717177.46f8e6f9d003d@webmail.cryst.bbk.ac.uk>
References: <1190717177.46f8e6f9d003d@webmail.cryst.bbk.ac.uk>
Message-ID: <12877703.post@talk.nabble.com>


You could provide examples of errors, which Excel gives in computations, in
comparison to R.
Excel could not calculate inverse matrix for my task, so I was to find
something better, and I've found R (it was version 1.2, as far as I
remember).

My another problem was scripting (R is more convenient, but harder to
learn).

You can also notice the publication quality graphics.


e.rapsomaniki wrote:
> 
> Dear R users,
> 
> I have started work in a Statistics government department and I am trying
> to
> convince my bosses to install R on our computers (I can't do proper stats
> in
> Excel!!). They asked me to prove that this is a widely used software (and
> not
> just another free-source, bug infected toy I found on the web!) by
> suggesting
> other big organisations that use it. Are you aware of any reputable places
> (academic or not) that use R? (e.g. maybe you work for them)
> 
> I would be really grateful for any advice on this. Also suggestions on
> arguments
> I could use to persuade them that R is so much better than Excel would be
> very
> much appreciated.
> 
> Many Thanks
> Eleni Rapsomaniki
> 

-- 
View this message in context: http://www.nabble.com/Who-uses-R--tf4514754.html#a12877703
Sent from the R help mailing list archive at Nabble.com.


From Ted.Harding at manchester.ac.uk  Tue Sep 25 13:40:46 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Tue, 25 Sep 2007 12:40:46 +0100 (BST)
Subject: [R] Who uses R?
In-Reply-To: <1190717177.46f8e6f9d003d@webmail.cryst.bbk.ac.uk>
Message-ID: <XFMail.070925124046.Ted.Harding@manchester.ac.uk>

On 25-Sep-07 10:46:17, Eleni Rapsomaniki wrote:
> Dear R users,
> 
> I have started work in a Statistics government department
> and I am trying to convince my bosses to install R on our
> computers (I can't do proper stats in Excel!!). They asked
> me to prove that this is a widely used software (and not
> just another free-source, bug infected toy I found on the
> web!) by suggesting other big organisations that use it.
> Are you aware of any reputable places (academic or not)
> that use R? (e.g. maybe you work for them)
> 
> I would be really grateful for any advice on this. Also
> suggestions on arguments I could use to persuade them that
> R is so much better than Excel would be very much appreciated.
> 
> Many Thanks
> Eleni Rapsomaniki

Dear Eleni,

You deserve all the support we can give you!

As well as the many other cogent suggestions you will get
(and I hope there will be plenty of citations of articles
published in prestigious journals), the following may also
be helpful:

Pat Altham (now retired) developed extensive teaching (and
other) materials in R at the Cambridge University Statistical
Laboratory. From her personal web page:

  "Some of the computer languages I have had to try to
   learn since graduating in 1964: Cambridge autocode,
   algol, phoenix, machine-code, Fortran, BBC-Basic,
   GLIM, GENSTAT, Linux, S-Plus and finally (probably
   the best so far!) R."

See http://www.statslab.cam.ac.uk/~pat/ for more details
and for links to her R material.

Good luck!
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 25-Sep-07                                       Time: 12:40:36
------------------------------ XFMail ------------------------------


From Ted.Harding at manchester.ac.uk  Tue Sep 25 13:45:18 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Tue, 25 Sep 2007 12:45:18 +0100 (BST)
Subject: [R] Who uses R?
In-Reply-To: <46F8ECF0.6070801@pburns.seanet.com>
Message-ID: <XFMail.070925124518.Ted.Harding@manchester.ac.uk>

On 25-Sep-07 11:11:44, Patrick Burns wrote:
> Just speaking of the field I'm most familiar with, there
> are now users of R in many of the largest financial
> companies in the world.
> 
> http://www.burns-stat.com/pages/Tutor/spreadsheet_addiction.html
> 
> is one place to look for arguments against Excel.
> This was just updated to include an amusing numerical
> bug in Excel 2007. Guess what 850 * 77.1 equals.

What a nasty little puzzle to set, Patrick! I had to turn
to OpenOffice Calc, which told me that the answer is 65535.
Is that right, Patrick? Should I check it on Excel?

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 25-Sep-07                                       Time: 12:45:11
------------------------------ XFMail ------------------------------


From Thomas.Adams at noaa.gov  Tue Sep 25 13:51:37 2007
From: Thomas.Adams at noaa.gov (Thomas Adams)
Date: Tue, 25 Sep 2007 07:51:37 -0400
Subject: [R] Who uses R?
In-Reply-To: <1190717177.46f8e6f9d003d@webmail.cryst.bbk.ac.uk>
References: <1190717177.46f8e6f9d003d@webmail.cryst.bbk.ac.uk>
Message-ID: <46F8F649.6010100@noaa.gov>

Eleni,

FWIW, there are a number of us in the U.S. NOAA/National Weather Service 
and at the National Center for Atmospheric Research (NCAR) (who wrote 
the 'Verification' package) who use R for verification of meteorological 
and hydrologic forecasts, aiding in the calibration of distributed 
hydrologic models, and in the analysis of radar estimated precipitation 
biases, and more?

Regards,
Tom


Eleni Rapsomaniki wrote:
> Dear R users,
>
> I have started work in a Statistics government department and I am trying to
> convince my bosses to install R on our computers (I can't do proper stats in
> Excel!!). They asked me to prove that this is a widely used software (and not
> just another free-source, bug infected toy I found on the web!) by suggesting
> other big organisations that use it. Are you aware of any reputable places
> (academic or not) that use R? (e.g. maybe you work for them)
>
> I would be really grateful for any advice on this. Also suggestions on arguments
> I could use to persuade them that R is so much better than Excel would be very
> much appreciated.
>
> Many Thanks
> Eleni Rapsomaniki
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>   


-- 
Thomas E Adams
National Weather Service
Ohio River Forecast Center
1901 South State Route 134
Wilmington, OH 45177

EMAIL:	thomas.adams at noaa.gov

VOICE:	937-383-0528
FAX:	937-383-0033


From E.Vettorazzi at uke.uni-hamburg.de  Tue Sep 25 13:55:38 2007
From: E.Vettorazzi at uke.uni-hamburg.de (Eik Vettorazzi)
Date: Tue, 25 Sep 2007 13:55:38 +0200
Subject: [R] Adjust barplot to the left
In-Reply-To: <12877530.post@talk.nabble.com>
References: <12877530.post@talk.nabble.com>
Message-ID: <46F8F73A.1080300@uke.uni-hamburg.de>

barplot(height,width,xlim=c(-1,4), space=c(-.5,1.5,1.5))
will do the trick.

"space" is a relative parameter depending on "width" so you get 
1.5*0.4=0.6 space and with width=0.4 you get an overall distance of 1 
between to bars.

hth.

squall44 schrieb:
> Hello,
>
> I have the following problem: I created an ecdf and a barplot. Unfortunatly,
> the bars are not where I would like them to be (please see picture below).
>
> http://www.nabble.com/file/p12877530/problem.gif 
>
> That's my code:
> #------------------------
> par(mfrow=c(2,1), mar=c(2,3,3,2))
>
> #ECDF
> x = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2)
> F2.5 <- ecdf(x)
> plot(F2.5,
>   verticals= TRUE,
>   do.p = TRUE,
>   lwd=3,
>   ylab = "",
>   xlab = "",
>   main = "Figur 2.12 Frequenztabelle und eVf",
>   xlim = c(-1,4))
> abline(h= (0:10)*0.1)
> mtext(text="x", side=1, adj = 1.03, padj=1.23, cex=1.2)
> mtext(text="f(x)", side=3, adj = -0.06, padj=-1, cex=1.2)
>
> par(mar=c(4,3,1,2))
>
> #Barplot               
> width<-c(0.4, 0.4, 0.4)
> height<-c(0.5, 0.35, 0.15)
> barplot(height,width,xlim=c(-1,4), space=1.5,)
> axis(side=1)
> #------------------------
>
> Can anyone tell me how I can adjust the bars to the left?
> Thanks
>
> Tobias
>   


-- 
Eik Vettorazzi
Institut f?r Medizinische Biometrie und Epidemiologie
Universit?tsklinikum Hamburg-Eppendorf

Martinistr. 52
20246 Hamburg

T ++49/40/42803-8243
F ++49/40/42803-7790


From jrkrideau at yahoo.ca  Tue Sep 25 13:56:09 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Tue, 25 Sep 2007 07:56:09 -0400 (EDT)
Subject: [R] Who uses R?
In-Reply-To: <1190717177.46f8e6f9d003d@webmail.cryst.bbk.ac.uk>
Message-ID: <615609.2893.qm@web32810.mail.mud.yahoo.com>


--- Eleni Rapsomaniki
<e.rapsomaniki at mail.cryst.bbk.ac.uk> wrote:

> Dear R users,
> 
> I have started work in a Statistics government
> department and I am trying to
> convince my bosses to install R on our computers (I
> can't do proper stats in
> Excel!!). 
> I would be really grateful for any advice on this.
> Also suggestions on arguments
> I could use to persuade them that R is so much
> better than Excel would be very
> much appreciated.
> 
> Many Thanks
> Eleni Rapsomaniki

Here are some of the arguments for not using Excel (& 
other spread sheets) for statistical analysis.

Problems With Using Microsoft Excel for Statistics
 Microsoft Excel for Statistics
http://www.cs.uiowa.edu/~jcryer/JSMTalk2001.pdf

Spread sheet addiction
http://www.burns-stat.com/pages/Tutor/spreadsheet_addiction.html
Using Excel for survey analysis ( by J. Cryer)
http://www.audiencedialogue.org/excel1.html
Is Microsoft Excel an Adequate Statistics Package?
http://www.practicalstats.com/Pages/excelstats.html

Use of Excel for Statistical Analysis
http://www.agresearch.co.nz/Science/Statistics/exceluse1.htm

Should Microsoft Excel Software Be Used For
Statistical Analysis Or Graphics? ( J. Cryer)
http://gcrc.ucsd.edu/biostatistics/Excel.pdf

Statistical analysis using Microsoft Excel
http://pages.stern.nyu.edu/~jsimonof/classes/1305/pdf/excelreg.pdf

Statistical flaws in Excel
http://www.mis.coventry.ac.uk/~nhunt/pottel.pdf

NOTE X: USE OF EXCEL IN STATISTICS COURSES AND
LABORATORIES - SOME PROS AND CONS
http://www.daheiser.info/excel/notes/notex.pdf

Using Excel for Statistics :Tips and Warnings
http://www.reading.ac.uk/ssc/publications/guides/xfs.pdf

Doing statistics with a speadsheet -Perhaps not a good
idea? (J. Kane)
http://groups.google.ca/group/sci.stat.edu/browse_thread/thread/b2e6def39c6b8ef4/1f6bbe4e398a1e0d?q=John+Kane+Excel&rnum=1#1f6bbe4e398a1e0d


From murdoch at stats.uwo.ca  Tue Sep 25 14:22:51 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 25 Sep 2007 08:22:51 -0400
Subject: [R] How to read stored functions
In-Reply-To: <12875031.post@talk.nabble.com>
References: <12472d0d0709250026m1ac23785r6f2ca7a2a7269049@mail.gmail.com>	<12874535.post@talk.nabble.com>	<8c464e8f0709250047u2fb6e74aj79a48dc0d726422d@mail.gmail.com>
	<12875031.post@talk.nabble.com>
Message-ID: <46F8FD9B.9080506@stats.uwo.ca>

On 9/25/2007 4:15 AM, Vladimir Eremeev wrote:
> source'ing is a bad practice because this saves additional copies of
> functions and data in the local workspace.
> 
> Wasting disk space is not a problem now since HDDs are cheap and function
> bodies are generally small.
> 
> But, when you change any function body, you have to repeat that source()
> call in local workspace of every project using the functions.

I disagree.  The bad practice is having local workspaces.  It's easy to 
see what's in a text file, and hard to see exactly what's in a .RData 
file, so it's better to keep everything as text.  There are situations 
where the overhead of converting text to internal objects is too high,
e.g. the results of long simulation runs may be worth saving in binary 
form so they're quicker to load.  But you can save objects one (or a 
few) at a time, you don't need to save everything.

If you find you're using a function in multiple projects, then it's time 
to build a small package to hold it.  The first line in the scripts for 
each of those projects can be

library(MyPackage)

If you think building a package is too much overhead, you can replace 
the line above with

source("path/to/MyFunction.R")

but this is less portable, since you may not have the function installed 
in the same directory on every system you use.

Duncan Murdoch

> 
> 
> Jared O'Connell wrote:
>> 
>> Having your functions in a text file, say "functions.r" and then calling:
>> 
>>>source("functions.r")
>> 
>> is also an option.  This assumes you are in the same directory as "
>> functions.r".  Perhaps take a look at ?setwd and ?getwd as well.
>> 
>> 
>> On 9/25/07, Vladimir Eremeev <wl2776 at gmail.com> wrote:
>>>
>>> You can save your functions to a file with
>>> save(<names>,file="/path/to/func_lib.RData")
>>> and then attach("/path/to/func_lib.RData").
>>>
>>> Or, you can create a package and load it with library() or require()
>>> 
>>> Mauricio Malfert wrote:
>>> >
>>> > Hi I'm simulating missing data patterns and  I've started to get a lot
>>> > of
>>> > functions in the same .R file is it possible to store al these
>>> functions
>>> > in
>>> > a library like one does in C++ (i.e the .h file) and read the functions
>>> > from
>>> > the main .R file
>>> > /Mauricio
>> 
>


From jim at bitwrit.com.au  Tue Sep 25 14:25:55 2007
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 25 Sep 2007 22:25:55 +1000
Subject: [R] Adjust barplot to the left
In-Reply-To: <12877530.post@talk.nabble.com>
References: <12877530.post@talk.nabble.com>
Message-ID: <46F8FE53.6050809@bitwrit.com.au>

squall44 wrote:
> Hello,
> 
> I have the following problem: I created an ecdf and a barplot. Unfortunatly,
> the bars are not where I would like them to be (please see picture below).
> 
> http://www.nabble.com/file/p12877530/problem.gif 
> ...
> 
> Can anyone tell me how I can adjust the bars to the left?

Hi Tobias (and anyone else who is interested),
This is a rather intriguing request. If there are people out there who 
would like to place the bars in a barplot at arbitrary positions, I 
could rather easily modify "barp" in the plotrix package to do this.
(I've already tried it with the "xpos" argument as a test, and it 
produces nice overlapped bars, if you like that sort of thing.)
However, as a one-off, I would probably not include it in plotrix. I 
attach the perhaps buggy altered code for Tobias if it helps. Use it 
instead of barplot like this:

library(plotrix)
# add your path to the barp.R file to the following
source("barp.R")
barp(height,width=0.2,col="gray",xlim=c(-1.2,4.2),xpos=0:2)

If I get a few requests, I can thrash the code a bit and it will turn up 
in the next version of plotrix.

Jim
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: barp.R
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070925/4758ef5a/attachment.pl 

From bernhard.mueller at art.admin.ch  Tue Sep 25 14:30:51 2007
From: bernhard.mueller at art.admin.ch (bernhard.mueller at art.admin.ch)
Date: Tue, 25 Sep 2007 14:30:51 +0200
Subject: [R] Create grouping from TukeyHSD (as a duncan test does)?
Message-ID: <C56E5473F6A9164AB21CDEA65B7053E2CF164A@EVD-C8001.bk.evdad.admin.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070925/ae8e0311/attachment.pl 

From murdoch at stats.uwo.ca  Tue Sep 25 14:34:47 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 25 Sep 2007 08:34:47 -0400
Subject: [R] Who uses R?
In-Reply-To: <XFMail.070925124518.Ted.Harding@manchester.ac.uk>
References: <XFMail.070925124518.Ted.Harding@manchester.ac.uk>
Message-ID: <46F90067.7030604@stats.uwo.ca>

On 9/25/2007 7:45 AM, (Ted Harding) wrote:
> On 25-Sep-07 11:11:44, Patrick Burns wrote:
>> Just speaking of the field I'm most familiar with, there
>> are now users of R in many of the largest financial
>> companies in the world.
>> 
>> http://www.burns-stat.com/pages/Tutor/spreadsheet_addiction.html
>> 
>> is one place to look for arguments against Excel.
>> This was just updated to include an amusing numerical
>> bug in Excel 2007. Guess what 850 * 77.1 equals.
> 
> What a nasty little puzzle to set, Patrick! I had to turn
> to OpenOffice Calc, which told me that the answer is 65535.
> Is that right, Patrick? Should I check it on Excel?

Since Excel is the government approved gold standard, you should.  OO 
Calc got it wrong.  The correct Excel answer is 100000.  (Only in 2007; 
Office 97 and 2003 had the same bug as OO Calc, and give 65535.)

Duncan Murdoch


From stefan.vandongen at ua.ac.be  Tue Sep 25 14:39:12 2007
From: stefan.vandongen at ua.ac.be (Van Dongen Stefan)
Date: Tue, 25 Sep 2007 14:39:12 +0200
Subject: [R] Create grouping from TukeyHSD (as a duncan test does)?
In-Reply-To: <C56E5473F6A9164AB21CDEA65B7053E2CF164A@EVD-C8001.bk.evdad.admin.ch>
Message-ID: <36B62AB1E934124BA81C2B3B615E9F00988972@xmail05.ad.ua.ac.be>

Hi Bernhard,

When you are interested in so many groups and to compare them, why not use a cluster technique or a mixture approach to get some grouping

Stefan

-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens bernhard.mueller at art.admin.ch
Verzonden: dinsdag 25 september 2007 14:31
Aan: r-help at r-project.org
Onderwerp: [R] Create grouping from TukeyHSD (as a duncan test does)?


Hello everybody

1. If there is/ever will be a function to perform "duncan multiple range test" please inform me at once.

2. Is there a way to create a grouping as duncan does from TukeyHSD output? My experimental design contained 62 genotypes, so the pairwise comparison is not that usefull and clear to look at. How would I do that? Is there an other test that does give grouping as output?

Thnaks for your help.

Bernhard M?ller, Master Student
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Eidgen?ssisches Volkswirtschaftsdepartement EVD
Forschungsanstalt Agroscope Reckenholz-T?nikon ART
?kologische Landbausysteme

Reckenholzstrasse 191,  CH-8046 Z?rich
Tel.    ++41 (0)44 / 377 74 47
FAX     ++41 (0)44 / 377 72 01
mailto:bernhard.mueller at art.admin.ch
http://www.reckenholz.ch


	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Tue Sep 25 14:46:54 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 Sep 2007 13:46:54 +0100 (BST)
Subject: [R] Importing a dataset
In-Reply-To: <20070921140140.GA5609@localdomain>
References: <s6f3dacf.069@tedmail2.lgc.co.uk>
	<20070921140140.GA5609@localdomain>
Message-ID: <Pine.LNX.4.64.0709211606340.15483@gannet.stats.ox.ac.uk>

On Fri, 21 Sep 2007, Gabor Csardi wrote:

> I don't know a way of loading parts of an .RData file either,

You can't easily do it, as named objects are not stored separately in such 
a file (nor in memory in R).  See the 'R Internals' manual for a 
description of the format.  This would be possible, but you would have to 
read the whole .RData file to analyse its structure, then work out which 
SEXPRECs you need to reconstruct the desired object(s) and re-scan the 
file to bring those SEXPRECs into memory.

If we ever have a new save format, it would be worth bearing in mind that 
the desire to retrieve just some of the top-level saved objects comes up 
quite frequently, and perhaps store an index table (as e.g. PDF does).

> but another solution is to use the envir argument of load to
> load the data into a new environment:
>
>> x <- 1
>> y <- rnorm(3)
>> save.image("tmp.RData")
>> rm(x)
>> rm(y)
>> load("tmp.RData", env <- new.env())
>> get("x", env)
> [1] 1
>> get("y", env)
> [1] -0.1105102  0.6923334  1.5506114
>> rm(env)

This is essentially the same solution as Steve Ellison's, which uses the 
evaluation frame of get1() as the environment.  Using get(inherits=FALSE) 
would be a little safer (especially in Steve's version).

>
> Gabor
>
> On Fri, Sep 21, 2007 at 02:52:21PM +0100, S Ellison wrote:
>> I don't know a short way, but this worked when I tried it. Maybe there's a clue in there somewhere?
>>
>>  get1<-function(fname, varname) {
>>  load(fname)
>>  get(varname)
>>  }
>>
>> x<-1
>> y<-rnorm(3)
>>
>> save.image("temp.RData")
>>
>> rm(x)
>> rm(y)
>>
>> get1("temp.Rdata","x")
>>
>> get1("temp.Rdata","y")
>>
>>
>> Steve E
>>
>>>>> "Marco Venanzi" <marvena at tin.it> 17/09/2007 12:38:24 >>>

>> Hi,how can I load a dataset from another file R.Data,without importing 
>> all the objects (functions and other datasets) contained in that 
>> file?Thanks, Marco

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Ted.Harding at manchester.ac.uk  Tue Sep 25 14:51:04 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Tue, 25 Sep 2007 13:51:04 +0100 (BST)
Subject: [R] Who uses R?
In-Reply-To: <46F90067.7030604@stats.uwo.ca>
Message-ID: <XFMail.070925135104.Ted.Harding@manchester.ac.uk>

On 25-Sep-07 12:34:47, Duncan Murdoch wrote:
> On 9/25/2007 7:45 AM, (Ted Harding) wrote:
>> On 25-Sep-07 11:11:44, Patrick Burns wrote:
>>> Just speaking of the field I'm most familiar with, there
>>> are now users of R in many of the largest financial
>>> companies in the world.
>>> 
>>> http://www.burns-stat.com/pages/Tutor/spreadsheet_addiction.html
>>> 
>>> is one place to look for arguments against Excel.
>>> This was just updated to include an amusing numerical
>>> bug in Excel 2007. Guess what 850 * 77.1 equals.
>> 
>> What a nasty little puzzle to set, Patrick! I had to turn
>> to OpenOffice Calc, which told me that the answer is 65535.
>> Is that right, Patrick? Should I check it on Excel?
> 
> Since Excel is the government approved gold standard, you should.
> OO Calc got it wrong.  The correct Excel answer is 100000.
> (Only in 2007; Office 97 and 2003 had the same bug as OO Calc,
> and give 65535.)
> 
> Duncan Murdoch

Thanks, Duncan! It's good to be sure! Sadly, this has shaken
my faith in R. But now I know where to turn.
Best wishes,
Ted.



--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 25-Sep-07                                       Time: 13:51:00
------------------------------ XFMail ------------------------------


From cnaberdl at gmail.com  Tue Sep 25 15:00:15 2007
From: cnaberdl at gmail.com (Caio Azevedo)
Date: Tue, 25 Sep 2007 15:00:15 +0200
Subject: [R] Erro plot
Message-ID: <699bb6720709250600q7125e4e1gd98404e8ee0fcc89@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070925/15b4b272/attachment.pl 

From lramlal at claflin.edu  Tue Sep 25 15:20:07 2007
From: lramlal at claflin.edu (Letticia Ramlal)
Date: Tue, 25 Sep 2007 09:20:07 -0400
Subject: [R] Need help with function writing
Message-ID: <A3E5A3C873C56F42B7F1A511D5F7525510C1F7@cu-ex-03.claflin.edu>

Hello: 

If anyone could guide me with this I would greatly appreciate it. Thanking you in advance for your assistance.

Using a 3-level input factor alternative so that a function(below) can compute both a two-sided and one-sided p-values. Making the two-sided test the default. And produce output information about which alternative was tested. Where would I place the ifelse statement? 

function(yvec,trtvec,alpha=0.05,header="") {
#################################################
# A function to compute a two-sample t-test and confidence 
# interval (equal-variance, independent samples).  yvec is 
# a numeric vector containing both samples' data.  trtvec 
# is a vector, same length as yvec, of treatment
# identifiers for the data in yvec.  A boxplot comparing
# the treatments' data is constructed.  Output is a one-row
# data frame reporting the results of the test and 
# confidence interval
##################################################
trtvec=as.factor(trtvec)
boxplot(split(yvec,trtvec))
title(header)
ybar=tapply(yvec,trtvec,mean)
varvec=tapply(yvec,trtvec,var)
nvec=table(trtvec)
error.df=nvec[1]+nvec[2]-2
pooled.var=((nvec[1]-1)*varvec[1]+(nvec[2]-1)*varvec[2])/error.df
diff12estimate=ybar[1]-ybar[2]
stderr=sqrt(pooled.var*((1/nvec[1])+(1/nvec[2])))
tratio=diff12estimate/stderr
twosidedP=2*(1-pt(abs(tratio),error.df))
tcrit=qt(1-alpha/2,error.df)
lower=diff12estimate-tcrit*stderr
upper=diff12estimate+tcrit*stderr
calpha=1-alpha
out=data.frame(diff12estimate,stderr,tratio,twosidedP,lower,upper,alpha)
names(out)=c("Estimator","SE","T","P-value","Lower CI","Upper CI","Confidence")
out
}


From jrkrideau at yahoo.ca  Tue Sep 25 15:20:17 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Tue, 25 Sep 2007 09:20:17 -0400 (EDT)
Subject: [R] Erro plot
In-Reply-To: <699bb6720709250600q7125e4e1gd98404e8ee0fcc89@mail.gmail.com>
Message-ID: <325830.81399.qm@web32808.mail.mud.yahoo.com>

Have a look at plotCI in the plotrix package.
--- Caio Azevedo <cnaberdl at gmail.com> wrote:

> Hi all,
> 
> I would like to generate a erro bar plot. I have
> already the means and the
> SE calculated.How could I plot these values with the
> means represented by
> points and  erro bars, one up another down,
> representing the +- the SE?
> 
> Thanks in advance,
> 
> Bets regards,
> 
> Caio
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From lockwood at rand.org  Tue Sep 25 16:09:26 2007
From: lockwood at rand.org (J.R. Lockwood)
Date: Tue, 25 Sep 2007 10:09:26 -0400 (EDT)
Subject: [R] Announcement: 2008 ASA Computing/Graphics Student Paper
	Competition
Message-ID: <Pine.LNX.4.58.0709251008160.24199@penguin.rand.org>

Statistical Computing and Statistical Graphics Sections

American Statistical Association

Student Paper Competition 2008


The Statistical Computing and Statistical Graphics Sections of the ASA
are co-sponsoring a student paper competition on the topics of
Statistical Computing and Statistical Graphics.  Students are
encouraged to submit a paper in one of these areas, which might be
original methodological research, some novel computing or graphical
application in statistics, or any other suitable contribution (for
example, a software-related project).  The selected winners will
present their papers in a topic-contributed session at the 2008 Joint
Statistical Meetings.  The Sections will pay registration fees for the
winners as well as a substantial allowance for transportation to the
meetings and lodging (which in most cases covers these expenses
completely).

Anyone who is a student (graduate or undergraduate) on or after
September 1, 2007 is eligible to participate.  An entry must include
an abstract, a six page manuscript (including figures, tables and
references), blinded versions of the abstract and manuscript (with no
authors and no references that easily lead to identifying the
authors), a C.V., and a letter from a faculty member familiar with the
student's work.  The applicant must be the first author of the paper.
The faculty letter must include a verification of the applicant's
student status and, in the case of joint authorship, should indicate
what fraction of the contribution is attributable to the applicant.
We prefer that electronic submissions of papers be in Postscript or
PDF.  All materials must be in English.

All application materials MUST BE RECEIVED by 5:00 PM EST, Monday,
December 17, 2007 at the address below.  They will be reviewed by the
Student Paper Competition Award committee of the Statistical Computing
and Graphics Sections.  The selection criteria used by the committee
will include innovation and significance of the contribution as well
as the professional quality of the manuscript.  Award announcements
will be made in late January, 2008.

Additional important information on the competition can be accessed on
the website of the Statistical Computing Section,
www.statcomputing.org.  A current pointer to the website is available
from the ASA website at www.amstat.org. Inquiries and application
materials should be emailed or mailed to:

Student Paper Competition
c/o  J.R. Lockwood
The RAND Corporation
4570 Fifth Avenue, Suite 600
Pittsburgh, PA 15213
lockwood at rand.org

--------------------

This email message is for the sole use of the intended recip...{{dropped}}


From h.wickham at gmail.com  Tue Sep 25 16:17:23 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 25 Sep 2007 09:17:23 -0500
Subject: [R] Proposal: Archive UseR conference presentations at
	www.r-project.org/useR-yyyy
In-Reply-To: <18168.40633.133271.581108@lxh5.stat.uni-muenchen.de>
References: <f8e6ff050709041413k70340217r76b51984d9e23ef9@mail.gmail.com>
	<fcmq8e$udt$1@sea.gmane.org>
	<46EFC023.7030803@statistik.uni-dortmund.de>
	<f8e6ff050709180805y6e856bd8t23da94e178e2bf43@mail.gmail.com>
	<40e66e0b0709180856s5d4c2218n6f74fe7575402244@mail.gmail.com>
	<18167.30368.575305.907742@lxh5.stat.uni-muenchen.de>
	<f8e6ff050709240725u488e5070kb568af29edd96524@mail.gmail.com>
	<18168.40633.133271.581108@lxh5.stat.uni-muenchen.de>
Message-ID: <f8e6ff050709250717i21280dfdn11e44b4a84086538@mail.gmail.com>

>   > but I can understand your desire to do
>   > that.  Perhaps just taking a static snapshot using something like
>   > wget, and hosting that on the R-project website would be a good
>   > compromise.
>
> Hmm, wouldn't it be easier if the hosting institution would make a tgz
> file? wget over HTTP is rather bad in resolving links etc

Really?  I've always found it to be rather excellent.

The reason I suggest it is that unless you have some way to generate a
static copy of the site, you'll need to ensure that the R-project
supports any dynamic content.  e.g. for example the user 2008 site
uses some (fairly vanilla) php for including the header and footer.

> we could include a note on the top page that this is only a snapshot
> copy and have a link to the original site (in case something changes
> there).

That's reasonable, although it would be even better to have it on every page.

>   > The one problem is setting up a redirect so that existing links and
>   > google searches aren't broken.  This would need to be put in place at
>   > least 6 months before the old website closed.
>
> Yes, very good point, I didn't think about that. But the R site is
> searched very often, so material there appears rather quickly on
> Google searches. Ad bookmarks: I don't want to remove the old site,
> just have an archive copy at a central location.

In that case, should it be labelled no-index as it's just a cache of
material that should be available elsewhere?  We need some
machine-readable way of indicating where the canonical resource is.
It's always frustrated me a little that when googling for r
documentation, you find hundreds of the same page hosted at different
sites.

Hadley


-- 
http://had.co.nz/


From mark_difford at yahoo.co.uk  Tue Sep 25 16:39:04 2007
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Tue, 25 Sep 2007 07:39:04 -0700 (PDT)
Subject: [R] Multiple comparisons; rank-based anova
Message-ID: <12881037.post@talk.nabble.com>


Dear List-Members,

Is the application of multiple comparison procedures (using the multcomp
package) to the output from a rank-based ANOVA straightforward, or do I need
to take heed ?

That is, is it as simple as:

glht( aov(rank(NH4) ~ Site, data=mydat), linfct=mcp(Site="Tukey") )

Thanks in advance for your help.

Regards,
Mark Difford.
-- 
View this message in context: http://www.nabble.com/Multiple-comparisons--rank-based-anova-tf4516025.html#a12881037
Sent from the R help mailing list archive at Nabble.com.


From wl2776 at gmail.com  Tue Sep 25 17:00:31 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Tue, 25 Sep 2007 08:00:31 -0700 (PDT)
Subject: [R] How to read stored functions
In-Reply-To: <46F8FD9B.9080506@stats.uwo.ca>
References: <12472d0d0709250026m1ac23785r6f2ca7a2a7269049@mail.gmail.com>
	<12874535.post@talk.nabble.com>
	<8c464e8f0709250047u2fb6e74aj79a48dc0d726422d@mail.gmail.com>
	<12875031.post@talk.nabble.com> <46F8FD9B.9080506@stats.uwo.ca>
Message-ID: <12881540.post@talk.nabble.com>



Duncan Murdoch-2 wrote:
> 
> On 9/25/2007 4:15 AM, Vladimir Eremeev wrote:
>> source'ing is a bad practice because this saves additional copies of
>> functions and data in the local workspace.
>> 
>> Wasting disk space is not a problem now since HDDs are cheap and function
>> bodies are generally small.
>> 
>> But, when you change any function body, you have to repeat that source()
>> call in local workspace of every project using the functions.
> 
> I disagree.  The bad practice is having local workspaces.  It's easy to 
> see what's in a text file, and hard to see exactly what's in a .RData 
> file, so it's better to keep everything as text.  There are situations 
> where the overhead of converting text to internal objects is too high,
> e.g. the results of long simulation runs may be worth saving in binary 
> form so they're quicker to load.  But you can save objects one (or a 
> few) at a time, you don't need to save everything.
> 

It's the matter of taste. I prefer separate directories for separate
projects. Sometimes I have 'subprojects' with their own workspaces. If I
have large objects, I usually don't analyze them with a text viewer.
And, the last. The option of saving the local workspace exists in R for
years. As one of its developers you know that the R Core Team has the very
strong feedback with users. I don't think that bad features exist in such
conditions for such a long time.


Duncan Murdoch-2 wrote:
> 
> If you find you're using a function in multiple projects, then it's time 
> to build a small package to hold it.  The first line in the scripts for 
> each of those projects can be
> 
> library(MyPackage)
> 
> If you think building a package is too much overhead, you can replace 
> the line above with
> 
> source("path/to/MyFunction.R")
> 
> but this is less portable, since you may not have the function installed 
> in the same directory on every system you use.
> 
> Duncan Murdoch
> 
> 
That's right.
-- 
View this message in context: http://www.nabble.com/How-to-read-stored-functions-tf4513863.html#a12881540
Sent from the R help mailing list archive at Nabble.com.


From I.McHale at salford.ac.uk  Tue Sep 25 17:05:28 2007
From: I.McHale at salford.ac.uk (Ian McHale)
Date: Tue, 25 Sep 2007 16:05:28 +0100
Subject: [R] fSeries Garch and Arfima Ox interface
Message-ID: <0C0ED83438444243B3C407C13F2CDD9A01864C98@ISD-EXV03.isdads.salford.ac.uk>

Hello all,
 
This is a request for help from somebody who has the Ox interfaces working in R.
 
I am trying to get the Ox interfaces working for Arfima and Garch modelling. However, I am having several problems:
 
1. The link to download G at rch_v40 does not work. Does anybody have a copy to email to me please?
2. Various guides offer different instructions for installing Ox in the correct place for R to find it.
3. Do the functions work with the latest version of Ox console (version 4)? Or do we need to use Ox version 3.40?
 
Does somebody have it working - can you let me know how you did it? For your information, I am currently using R 2.5.1 and I am following the instructions from http://faculty.chicagogsb.edu/ruey.tsay/teaching/bs41202/G at RCH_info.txt
 
Cheers
 
Ian
 
Dr. Ian McHale
Lecturer in Applied Statistics
Centre for Operational Research and Applied Statistics
The University of Salford
Maxwell Building
Salford
Greater Manchester
M5 4WT
Tel: 0161 295 4765
Fax: 0161 295 4947


From deleeuw at stat.ucla.edu  Tue Sep 25 17:17:54 2007
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Tue, 25 Sep 2007 08:17:54 -0700
Subject: [R] jumpstation
Message-ID: <22F3141F-E7BC-4BFD-A09D-4DD4C1EADB09@stat.ucla.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070925/9324b371/attachment.pl 

From hkahra at gmail.com  Tue Sep 25 17:31:24 2007
From: hkahra at gmail.com (Hannu Kahra)
Date: Tue, 25 Sep 2007 18:31:24 +0300
Subject: [R] fSeries Garch and Arfima Ox interface
In-Reply-To: <0C0ED83438444243B3C407C13F2CDD9A01864C98@ISD-EXV03.isdads.salford.ac.uk>
References: <0C0ED83438444243B3C407C13F2CDD9A01864C98@ISD-EXV03.isdads.salford.ac.uk>
Message-ID: <3d35a2ca0709250831j525c3dabtb517c8e6b17a2a65@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070925/820d99ae/attachment.pl 

From schaefer at pointone.de  Tue Sep 25 15:39:15 2007
From: schaefer at pointone.de (=?ISO-8859-1?Q?Christian_Sch=E4fer?=)
Date: Tue, 25 Sep 2007 15:39:15 +0200
Subject: [R] Spacing between x axis and labels
Message-ID: <46F90F83.8070203@pointone.de>

Hi,

my x-axis contains labels that consist of two lines (the actual label 
and below information about groupsize). Unfortunately, there is too 
little spacing between labels and tickmarks in this situation. Is there 
a parameter to tune spacing between axis and labels?

Thanks,
Chris


From efferz at gmx.de  Tue Sep 25 16:31:29 2007
From: efferz at gmx.de (Martin Efferz)
Date: Tue, 25 Sep 2007 16:31:29 +0200
Subject: [R] Rolling Window with 2 Input Vectors
Message-ID: <004b01c7ff80$c44cc210$4ce64630$@de>

Ein eingebundener Text mit undefiniertem Zeichensatz wurde abgetrennt.
Name: nicht verf?gbar
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20070925/3a1167f8/attachment.pl 

From marc_schwartz at comcast.net  Tue Sep 25 17:44:21 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Tue, 25 Sep 2007 10:44:21 -0500
Subject: [R] Spacing between x axis and labels
In-Reply-To: <46F90F83.8070203@pointone.de>
References: <46F90F83.8070203@pointone.de>
Message-ID: <1190735061.3547.12.camel@Bellerophon.localdomain>

On Tue, 2007-09-25 at 15:39 +0200, Christian Sch?fer wrote:
> Hi,
> 
> my x-axis contains labels that consist of two lines (the actual label 
> and below information about groupsize). Unfortunately, there is too 
> little spacing between labels and tickmarks in this situation. Is there 
> a parameter to tune spacing between axis and labels?
> 
> Thanks,
> Chris

See ?mtext and take note of the 'line' argument, which allows you to
specify the margin line upon which to place text labels. The 'at'
argument is used to define where on the axis the labels should be
places.

If you are not already, you will want to use either 'axes = FALSE' or
'xaxt = "n"' in your plot call, so that the default axis labels are not
drawn.

HTH,

Marc Schwartz


From Achim.Zeileis at wu-wien.ac.at  Tue Sep 25 17:50:34 2007
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Tue, 25 Sep 2007 17:50:34 +0200 (CEST)
Subject: [R] Rolling Window with 2 Input Vectors
In-Reply-To: <004b01c7ff80$c44cc210$4ce64630$@de>
References: <004b01c7ff80$c44cc210$4ce64630$@de>
Message-ID: <Pine.LNX.4.64.0709251739480.6396@eowyn>

On Tue, 25 Sep 2007, Martin Efferz wrote:

> Is there a function which does a rolling calcualtion with 2 input vectors.
> "rollapply" and "rollFun" seem to use only one input vector.

In rollapply(), you need to set by.column=FALSE, e.g.

## generate random series of "true" and "predicted" values
set.seed(1071)
z <- zoo(cbind(true = rep(0, 100), pred = rnorm(100)))

## rolling evaluation of RMSE
rmse <- rollapply(z, 20, function(x) sqrt(mean((x[,1] - x[,2])^2)),
   by.column = FALSE)

## visualization
plot(merge(z, rmse), screens = c(1, 1, 2), col = c(2, 1, 1),
   main = "", ylab = c("true/pred", "rmse"))

See also the rolling regression example on the rollapply man page.

hth,
Z

>
>
> I want to calcualte some prediction evaluation measures like MSE and MAE
> with a rolling window. My functions look like
>
>
>
> prediction.mse(pred,true)
>
> prediction.mae(pred,true)
>
> ...
>
>
>
> pred and true are two vectors of equal size, the predictions and the
> realizations.
>
>
>
> Any ideas?
>
>
>
> Best,
>
> Martin
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From marc_schwartz at comcast.net  Tue Sep 25 17:55:55 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Tue, 25 Sep 2007 10:55:55 -0500
Subject: [R] Score test in logistic regression in R
In-Reply-To: <ABD8AC87AD7A664E948DCAD1A70ED3FA07856AA7@rosnt108.etslan.org>
References: <ABD8AC87AD7A664E948DCAD1A70ED3FA07856AA7@rosnt108.etslan.org>
Message-ID: <1190735755.3547.19.camel@Bellerophon.localdomain>

On Mon, 2007-09-24 at 21:36 -0400, Paek, Insu wrote:
> Hello,
> 
>   I am wondering if R has any ways to conduct the score test in logistic
> regression?
>   Could you let me know please?
> 
>   Thanks,
>   Insu  

You may need to provide further clarification, as the most common
reference to a score test in LR seems to be for testing the proportional
odds assumptions behind that particular approach.

If this is correct, there is a worked example in V&R's MASS 4 (the book)
on page 204 with respect to the use of the polr() function in MASS (the
package.)

An alternative is in Frank's Design package, where using ?residuals.lrm
will provide some examples, including diagnostic plots.

HTH,

Marc Schwartz


From mark_difford at yahoo.co.uk  Tue Sep 25 18:25:43 2007
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Tue, 25 Sep 2007 09:25:43 -0700 (PDT)
Subject: [R] Spacing between x axis and labels
In-Reply-To: <1190735061.3547.12.camel@Bellerophon.localdomain>
References: <46F90F83.8070203@pointone.de>
	<1190735061.3547.12.camel@Bellerophon.localdomain>
Message-ID: <12883395.post@talk.nabble.com>


Also look at the mgp option under ?par.

This allows one to set the margin line for axis title, axis labels and axis
line...

Regards,
Mark Difford.



Marc Schwartz wrote:
> 
> On Tue, 2007-09-25 at 15:39 +0200, Christian Sch?fer wrote:
>> Hi,
>> 
>> my x-axis contains labels that consist of two lines (the actual label 
>> and below information about groupsize). Unfortunately, there is too 
>> little spacing between labels and tickmarks in this situation. Is there 
>> a parameter to tune spacing between axis and labels?
>> 
>> Thanks,
>> Chris
> 
> See ?mtext and take note of the 'line' argument, which allows you to
> specify the margin line upon which to place text labels. The 'at'
> argument is used to define where on the axis the labels should be
> places.
> 
> If you are not already, you will want to use either 'axes = FALSE' or
> 'xaxt = "n"' in your plot call, so that the default axis labels are not
> drawn.
> 
> HTH,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Spacing-between-x-axis-and-labels-tf4516362.html#a12883395
Sent from the R help mailing list archive at Nabble.com.


From marc_schwartz at comcast.net  Tue Sep 25 18:36:53 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Tue, 25 Sep 2007 11:36:53 -0500
Subject: [R] Spacing between x axis and labels
In-Reply-To: <12883395.post@talk.nabble.com>
References: <46F90F83.8070203@pointone.de>
	<1190735061.3547.12.camel@Bellerophon.localdomain>
	<12883395.post@talk.nabble.com>
Message-ID: <1190738213.3547.23.camel@Bellerophon.localdomain>

Just be aware the there is no differentiation between the x and y axes
when using that approach, which is why I did not mention it.

Changing the default parms for the y axis may not be desirable here.

Marc

On Tue, 2007-09-25 at 09:25 -0700, Mark Difford wrote:
> Also look at the mgp option under ?par.
> 
> This allows one to set the margin line for axis title, axis labels and axis
> line...
> 
> Regards,
> Mark Difford.
> 
> 
> 
> Marc Schwartz wrote:
> > 
> > On Tue, 2007-09-25 at 15:39 +0200, Christian Sch?fer wrote:
> >> Hi,
> >> 
> >> my x-axis contains labels that consist of two lines (the actual label 
> >> and below information about groupsize). Unfortunately, there is too 
> >> little spacing between labels and tickmarks in this situation. Is there 
> >> a parameter to tune spacing between axis and labels?
> >> 
> >> Thanks,
> >> Chris
> > 
> > See ?mtext and take note of the 'line' argument, which allows you to
> > specify the margin line upon which to place text labels. The 'at'
> > argument is used to define where on the axis the labels should be
> > places.
> > 
> > If you are not already, you will want to use either 'axes = FALSE' or
> > 'xaxt = "n"' in your plot call, so that the default axis labels are not
> > drawn.
> > 
> > HTH,
> > 
> > Marc Schwartz
> >


From daniel at umd.edu  Tue Sep 25 18:55:23 2007
From: daniel at umd.edu (Daniel Malter)
Date: Tue, 25 Sep 2007 12:55:23 -0400
Subject: [R] Who uses R?
In-Reply-To: <45f568c70709250402g6ce21148x54ea86e0ef6619da@mail.gmail.com>
Message-ID: <200709251654.CGS77476@md2.mail.umd.edu>

Hi, although this is a guess, I would dare to say that it is probably used
in at least some schools/departments of any research university. Yet,
universities/schools often have a plethora  
of statistical softwares available (in our school, for instance, SAS, Stata,
SPSS, S-Plus) so it is not THE only statistical software. But R is one of
them and especially the guys at the forefront of statistical modeling are
using it because of its flexibility in programming.

Cheers,
Daniel

University of Maryland

-------------------------
cuncta stricte discussurus
-------------------------

-----Urspr?ngliche Nachricht-----
Von: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Im
Auftrag von Gustaf Rydevik
Gesendet: Tuesday, September 25, 2007 7:02 AM
An: Eleni Rapsomaniki
Cc: r-help at r-project.org
Betreff: Re: [R] Who uses R?

On 9/25/07, Eleni Rapsomaniki <e.rapsomaniki at mail.cryst.bbk.ac.uk> wrote:
> Dear R users,
>
> I have started work in a Statistics government department and I am 
> trying to convince my bosses to install R on our computers (I can't do 
> proper stats in Excel!!). They asked me to prove that this is a widely 
> used software (and not just another free-source, bug infected toy I 
> found on the web!) by suggesting other big organisations that use it. 
> Are you aware of any reputable places (academic or not) that use R? 
> (e.g. maybe you work for them)
>
> I would be really grateful for any advice on this. Also suggestions on 
> arguments I could use to persuade them that R is so much better than 
> Excel would be very much appreciated.
>
> Many Thanks
> Eleni Rapsomaniki
>


The statistics section of the Swedish Institute for Infectious Disease
Control, where I work, use R about 70% of the time.
The MEB (medical epidemiology and biostatistics) department at Karolinska
Institutet, the nordic countries premiere medical university, are also heavy
R-users.

Best,

Gustaf

--
Gustaf Rydevik, M.Sci.
tel: +46(0)703 051 451
address:Essingetorget 40,112 66 Stockholm, SE skype:gustaf_rydevik

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pburns at pburns.seanet.com  Tue Sep 25 19:11:21 2007
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 25 Sep 2007 18:11:21 +0100
Subject: [R] Who uses R?
In-Reply-To: <XFMail.070925135104.Ted.Harding@manchester.ac.uk>
References: <XFMail.070925135104.Ted.Harding@manchester.ac.uk>
Message-ID: <46F94139.4050709@pburns.seanet.com>

(Ted Harding) wrote:

>On 25-Sep-07 12:34:47, Duncan Murdoch wrote:
>  
>
>>On 9/25/2007 7:45 AM, (Ted Harding) wrote:
>>    
>>
>>>On 25-Sep-07 11:11:44, Patrick Burns wrote:
>>>      
>>>
>>>>Just speaking of the field I'm most familiar with, there
>>>>are now users of R in many of the largest financial
>>>>companies in the world.
>>>>
>>>>http://www.burns-stat.com/pages/Tutor/spreadsheet_addiction.html
>>>>
>>>>is one place to look for arguments against Excel.
>>>>This was just updated to include an amusing numerical
>>>>bug in Excel 2007. Guess what 850 * 77.1 equals.
>>>>        
>>>>
>>>What a nasty little puzzle to set, Patrick! I had to turn
>>>to OpenOffice Calc, which told me that the answer is 65535.
>>>Is that right, Patrick? Should I check it on Excel?
>>>      
>>>
>>Since Excel is the government approved gold standard, you should.
>>OO Calc got it wrong.  The correct Excel answer is 100000.
>>(Only in 2007; Office 97 and 2003 had the same bug as OO Calc,
>>and give 65535.)
>>
>>Duncan Murdoch
>>    
>>
>
>Thanks, Duncan! It's good to be sure! Sadly, this has shaken
>my faith in R. But now I know where to turn.
>Best wishes,
>Ted.
>
>  
>

Sadly I'm deprived of Excel 2007 myself, but apparently
this discussion so far doesn't fully acknowledge Excel's
innovation in quantum computing. It seems that both 100,000
and 65,535 are possible answers, which one you get depends
on which slit is open at the moment.

Pat

>
>--------------------------------------------------------------------
>E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
>Fax-to-email: +44 (0)870 094 0861
>Date: 25-Sep-07                                       Time: 13:51:00
>------------------------------ XFMail ------------------------------
>
>
>  
>


From ripley at stats.ox.ac.uk  Tue Sep 25 20:12:05 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 Sep 2007 19:12:05 +0100 (BST)
Subject: [R] calculating/plotting error ellipses
In-Reply-To: <46F8D156.6020605@tuebingen.mpg.de>
References: <46F7B2F8.7010200@tuebingen.mpg.de> <12864033.post@talk.nabble.com>
	<46F8D156.6020605@tuebingen.mpg.de>
Message-ID: <Pine.LNX.4.64.0709251022410.2872@gannet.stats.ox.ac.uk>

On Tue, 25 Sep 2007, Jan M. Wiener wrote:

> Hello,
> thank you very much for the quick answer.
> This works well. it draws a nice ellipse in the right orientation.
> However, I  doubt that the ellipse represents the 95% confidence
> interval, even if that is the standard-parameter for level is .95. The
> ellipse surely is to large?

It isn't supposed to.  You need to tell us what you mean by 'the 
corresponding error ellipse'.  If you want to plot a confidence region for 
the mean vector, you need to rescale the variance 'v' to be the variance 
of the mean and not of the data.  However, with as few obs as you have (as 
I recall it was 12), the normal-based confidence region is not at all 
accurate and you might need to take the estimation of 'v' into account.

My best guess was that you were looking for a tolerance region, which is 
none of the above.  But the posting guide is there to avoid potential 
helpers being put off answering by the need to guess.


> Any further help would be greatly appreciated.
> Best,
> Jan
>
>
> bbolker wrote:
>>
>> Jan M. Wiener wrote:
>>
>>> hello,
>>> sorry for posting what may be a simple question:
>>> i do have a matrix of coordinates (positional judgments, see below) and
>>> now want to calculate and plot the corresponding error ellipse.
>>> can anyone help me with the exact steps/syntax?
>>>
>>>
>>
>> Something along the lines of:
>>
>> m = colMeans(xyDat)  # calc. column means
>> v = var(xyDat)             # compute var-cov matrix
>> library(ellipse)              # you may need install.packages("ellipse")
>> first
>> plot(ellipse(v,centre=m),type="l")   ## draw the confidence ellipse
>> points(m[,1],m[,2])     # add the cent(re|er) point
>>
>>   Of course, I haven't actually tested this ...
>>
>>   Ben Bolker
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From stubben at lanl.gov  Tue Sep 25 20:34:33 2007
From: stubben at lanl.gov (stubben)
Date: Tue, 25 Sep 2007 12:34:33 -0600
Subject: [R] 3d barplot in rgl
Message-ID: <EEDF5281-5B15-41B0-ACFF-B775F4990555@lanl.gov>

Is there anyway to plot a matrix using a 3d bar plot.  Something like  
bar3 in matlab?

The example in demo hist3d does a 3d barplot for binned data, but has
anyone tried something for a simple matrix with spaces betwen bars
and axis labels using matrix dimnames or 1,2,3?


stages<-letters[1:3]

A<-matrix(c(
0.21, 0.21,0.03,
0.55, 0.58, 0.09,
1.30, 1.35, 0.22), nrow=3, byrow=TRUE, dimnames=list(stages,stages) )

## I can get a surface plot, but that's about it.

persp3d(A, col="red", alpha=0.7,
xlab="fate", ylab="stage", zlab="Sensitivity", box=FALSE)


Thanks,

Chris Stubben

--
-------------------

Los Alamos National Lab
BioScience Division
MS M888
Los Alamos, NM 87545


From h.wickham at gmail.com  Tue Sep 25 20:42:54 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 25 Sep 2007 13:42:54 -0500
Subject: [R] 3d barplot in rgl
In-Reply-To: <EEDF5281-5B15-41B0-ACFF-B775F4990555@lanl.gov>
References: <EEDF5281-5B15-41B0-ACFF-B775F4990555@lanl.gov>
Message-ID: <f8e6ff050709251142q309ef7a0vabea299e6464d1a3@mail.gmail.com>

Why do you want a 3d barchart?  They are generally a bad way to
present information as tall bars can obscure short bars, and it is
hard to accurately read off the height of a bar.  While adding
rotation can reduce some of these problems, why not create a graphic
that your viewers can take in with a glance?

Hadley

On 9/25/07, stubben <stubben at lanl.gov> wrote:
> Is there anyway to plot a matrix using a 3d bar plot.  Something like
> bar3 in matlab?
>
> The example in demo hist3d does a 3d barplot for binned data, but has
> anyone tried something for a simple matrix with spaces betwen bars
> and axis labels using matrix dimnames or 1,2,3?
>
>
> stages<-letters[1:3]
>
> A<-matrix(c(
> 0.21, 0.21,0.03,
> 0.55, 0.58, 0.09,
> 1.30, 1.35, 0.22), nrow=3, byrow=TRUE, dimnames=list(stages,stages) )
>
> ## I can get a surface plot, but that's about it.
>
> persp3d(A, col="red", alpha=0.7,
> xlab="fate", ylab="stage", zlab="Sensitivity", box=FALSE)
>
>
> Thanks,
>
> Chris Stubben
>
> --
> -------------------
>
> Los Alamos National Lab
> BioScience Division
> MS M888
> Los Alamos, NM 87545
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
http://had.co.nz/


From murdoch at stats.uwo.ca  Tue Sep 25 20:48:30 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 25 Sep 2007 14:48:30 -0400
Subject: [R] 3d barplot in rgl
In-Reply-To: <EEDF5281-5B15-41B0-ACFF-B775F4990555@lanl.gov>
References: <EEDF5281-5B15-41B0-ACFF-B775F4990555@lanl.gov>
Message-ID: <46F957FE.5020803@stats.uwo.ca>

On 9/25/2007 2:34 PM, stubben wrote:
> Is there anyway to plot a matrix using a 3d bar plot.  Something like  
> bar3 in matlab?
> 
> The example in demo hist3d does a 3d barplot for binned data, but has
> anyone tried something for a simple matrix with spaces betwen bars
> and axis labels using matrix dimnames or 1,2,3?

That demo gives you the basics of the code, so it shouldn't be too hard 
to put your own together:  just strip out the counting part.

Duncan Murdoch


From stubben at lanl.gov  Tue Sep 25 20:56:37 2007
From: stubben at lanl.gov (Chris Stubben)
Date: Tue, 25 Sep 2007 18:56:37 +0000 (UTC)
Subject: [R] 3d barplot in rgl
References: <EEDF5281-5B15-41B0-ACFF-B775F4990555@lanl.gov>
	<f8e6ff050709251142q309ef7a0vabea299e6464d1a3@mail.gmail.com>
Message-ID: <loom.20070925T185034-259@post.gmane.org>

hadley wickham <h.wickham <at> gmail.com> writes:

> 
> Why do you want a 3d barchart?  They are generally a bad way to
> present information as tall bars can obscure short bars, and it is
> hard to accurately read off the height of a bar.  While adding
> rotation can reduce some of these problems, why not create a graphic
> that your viewers can take in with a glance?
> 

3d barplots are a common way to display sensitvity/elasticity matrices in
stage-structured demography.  Here's a few other options from Caswell's Matrix
population models book (2001) - I definitely  prefer 3d barcharts to these
alternatives.


heatmap(log10(A[3:1,]), Rowv = NA,  Colv = NA, scale="none")

plot(log10(c(A)), type="s")


Thanks,

Chris


From liebe_zhz2004 at yahoo.com  Tue Sep 25 21:04:29 2007
From: liebe_zhz2004 at yahoo.com (Sam_zhz)
Date: Tue, 25 Sep 2007 12:04:29 -0700 (PDT)
Subject: [R] R2Winbugs problem
Message-ID: <12885666.post@talk.nabble.com>


Just while I use R2Winbugs, the following error will be presented. Please
tell me how to cope with.
Error in file(file, "r") : unable to open connection
In addition: Warning message:
cannot open file 'codaIndex.txt', reason 'No such file or directory' in:
file(file, "r") 

-- 
View this message in context: http://www.nabble.com/R2Winbugs-problem-tf4517326.html#a12885666
Sent from the R help mailing list archive at Nabble.com.


From liebe_zhz2004 at yahoo.com  Tue Sep 25 21:04:51 2007
From: liebe_zhz2004 at yahoo.com (Sam_zhz)
Date: Tue, 25 Sep 2007 12:04:51 -0700 (PDT)
Subject: [R] R2Winbugs problem
Message-ID: <12885668.post@talk.nabble.com>


Just while I use R2Winbugs, the following error will be presented. Please
tell me how to cope with.
Error in file(file, "r") : unable to open connection
In addition: Warning message:
cannot open file 'codaIndex.txt', reason 'No such file or directory' in:
file(file, "r") 
Thanks
Sam_zhz
-- 
View this message in context: http://www.nabble.com/R2Winbugs-problem-tf4517327.html#a12885668
Sent from the R help mailing list archive at Nabble.com.


From liebe_zhz2004 at yahoo.com  Tue Sep 25 21:04:53 2007
From: liebe_zhz2004 at yahoo.com (Sam_zhz)
Date: Tue, 25 Sep 2007 12:04:53 -0700 (PDT)
Subject: [R] R2Winbugs problem
Message-ID: <12885669.post@talk.nabble.com>


Just while I use R2Winbugs, the following error will be presented. Please
tell me how to cope with.
Error in file(file, "r") : unable to open connection
In addition: Warning message:
cannot open file 'codaIndex.txt', reason 'No such file or directory' in:
file(file, "r") 
Thanks
Sam_zhz
-- 
View this message in context: http://www.nabble.com/R2Winbugs-problem-tf4517328.html#a12885669
Sent from the R help mailing list archive at Nabble.com.


From liebe_zhz2004 at yahoo.com  Tue Sep 25 21:08:04 2007
From: liebe_zhz2004 at yahoo.com (Sam_zhz)
Date: Tue, 25 Sep 2007 12:08:04 -0700 (PDT)
Subject: [R] R2Winbugs problem
Message-ID: <12885674.post@talk.nabble.com>


Just while I use R2Winbugs, the following error will be presented. Please
tell me how to cope with.
Error in file(file, "r") : unable to open connection
In addition: Warning message:
cannot open file 'codaIndex.txt', reason 'No such file or directory' in:
file(file, "r") 
Thanks
Sam_zhz
-- 
View this message in context: http://www.nabble.com/R2Winbugs-problem-tf4517331.html#a12885674
Sent from the R help mailing list archive at Nabble.com.


From liebe_zhz2004 at yahoo.com  Tue Sep 25 21:08:07 2007
From: liebe_zhz2004 at yahoo.com (Sam_zhz)
Date: Tue, 25 Sep 2007 12:08:07 -0700 (PDT)
Subject: [R] R2Winbugs problem
Message-ID: <12885675.post@talk.nabble.com>


Just while I use R2Winbugs, the following error will be presented. Please
tell me how to cope with.
Error in file(file, "r") : unable to open connection
In addition: Warning message:
cannot open file 'codaIndex.txt', reason 'No such file or directory' in:
file(file, "r") 
Thanks
Sam_zhz
-- 
View this message in context: http://www.nabble.com/R2Winbugs-problem-tf4517332.html#a12885675
Sent from the R help mailing list archive at Nabble.com.


From liebe_zhz2004 at yahoo.com  Tue Sep 25 21:08:13 2007
From: liebe_zhz2004 at yahoo.com (Sam_zhz)
Date: Tue, 25 Sep 2007 12:08:13 -0700 (PDT)
Subject: [R] R2Winbugs problem
Message-ID: <12885676.post@talk.nabble.com>


Just while I use R2Winbugs, the following error will be presented. Please
tell me how to cope with.
Error in file(file, "r") : unable to open connection
In addition: Warning message:
cannot open file 'codaIndex.txt', reason 'No such file or directory' in:
file(file, "r") 
Thanks
Sam_zhz
-- 
View this message in context: http://www.nabble.com/R2Winbugs-problem-tf4517333.html#a12885676
Sent from the R help mailing list archive at Nabble.com.


From liebe_zhz2004 at yahoo.com  Tue Sep 25 21:08:20 2007
From: liebe_zhz2004 at yahoo.com (Sam_zhz)
Date: Tue, 25 Sep 2007 12:08:20 -0700 (PDT)
Subject: [R] R2Winbugs problem
Message-ID: <12885677.post@talk.nabble.com>


Just while I use R2Winbugs, the following error will be presented. Please
tell me how to cope with.
Error in file(file, "r") : unable to open connection
In addition: Warning message:
cannot open file 'codaIndex.txt', reason 'No such file or directory' in:
file(file, "r") 
Thanks
Sam_zhz
-- 
View this message in context: http://www.nabble.com/R2Winbugs-problem-tf4517334.html#a12885677
Sent from the R help mailing list archive at Nabble.com.


From stubben at lanl.gov  Tue Sep 25 21:13:02 2007
From: stubben at lanl.gov (Chris Stubben)
Date: Tue, 25 Sep 2007 19:13:02 +0000 (UTC)
Subject: [R] 3d barplot in rgl
References: <EEDF5281-5B15-41B0-ACFF-B775F4990555@lanl.gov>
	<46F957FE.5020803@stats.uwo.ca>
Message-ID: <loom.20070925T190746-649@post.gmane.org>

Duncan Murdoch <murdoch <at> stats.uwo.ca> writes:


> That demo gives you the basics of the code, so it shouldn't be too hard 
> to put your own together:  just strip out the counting part.
> 


Thanks, I did download the source to check the hist3d demo, but honestly it
didn't look very easy to simplify.  I switched to R from matlab, and 3d barplots
are the only thing I still use my student edition of matlab for anymore.  

I  would like to see a barplot3d added to your rgl package in the future, but
was hoping someone else had tried already.


Chris


From h.wickham at gmail.com  Tue Sep 25 21:21:23 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 25 Sep 2007 14:21:23 -0500
Subject: [R] 3d barplot in rgl
In-Reply-To: <loom.20070925T185034-259@post.gmane.org>
References: <EEDF5281-5B15-41B0-ACFF-B775F4990555@lanl.gov>
	<f8e6ff050709251142q309ef7a0vabea299e6464d1a3@mail.gmail.com>
	<loom.20070925T185034-259@post.gmane.org>
Message-ID: <f8e6ff050709251221j24cc266gabbd3208b6a86887@mail.gmail.com>

On 9/25/07, Chris Stubben <stubben at lanl.gov> wrote:
> hadley wickham <h.wickham <at> gmail.com> writes:
>
> >
> > Why do you want a 3d barchart?  They are generally a bad way to
> > present information as tall bars can obscure short bars, and it is
> > hard to accurately read off the height of a bar.  While adding
> > rotation can reduce some of these problems, why not create a graphic
> > that your viewers can take in with a glance?
> >
>
> 3d barplots are a common way to display sensitvity/elasticity matrices in
> stage-structured demography.  Here's a few other options from Caswell's Matrix
> population models book (2001) - I definitely  prefer 3d barcharts to these
> alternatives.
>
>
> heatmap(log10(A[3:1,]), Rowv = NA,  Colv = NA, scale="none")
>
> plot(log10(c(A)), type="s")

Both of those look like equally awful alternatives.  Perhaps you could
explain more about your data (perhaps with a sample?) so that we could
suggest better alternatives.

Hadley


From murdoch at stats.uwo.ca  Tue Sep 25 21:26:48 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 25 Sep 2007 15:26:48 -0400
Subject: [R] 3d barplot in rgl
In-Reply-To: <loom.20070925T190746-649@post.gmane.org>
References: <EEDF5281-5B15-41B0-ACFF-B775F4990555@lanl.gov>	<46F957FE.5020803@stats.uwo.ca>
	<loom.20070925T190746-649@post.gmane.org>
Message-ID: <46F960F8.6060508@stats.uwo.ca>

On 9/25/2007 3:13 PM, Chris Stubben wrote:
> Duncan Murdoch <murdoch <at> stats.uwo.ca> writes:
> 
> 
>> That demo gives you the basics of the code, so it shouldn't be too hard 
>> to put your own together:  just strip out the counting part.
>> 
> 
> 
> Thanks, I did download the source to check the hist3d demo, but honestly it
> didn't look very easy to simplify.  I switched to R from matlab, and 3d barplots
> are the only thing I still use my student edition of matlab for anymore.  
> 
> I  would like to see a barplot3d added to your rgl package in the future, but
> was hoping someone else had tried already.

They probably will someday, but not until someone who needs them sits 
down and writes the code.  I tend to agree with Hadley that they aren't 
a particularly effective sort of graph so it'll likely be someone else.

Duncan Murdoch


From emine-unlu at uiowa.edu  Tue Sep 25 22:02:32 2007
From: emine-unlu at uiowa.edu (Bayman, Emine Ozgur)
Date: Tue, 25 Sep 2007 15:02:32 -0500
Subject: [R] R lmer with problem of 'sd slot has negative entries'
Message-ID: <6401901AB2195C4985538FFB4F8592A3DDCAAA@IOWAEVS03.iowa.uiowa.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070925/ba214988/attachment.pl 

From vdemart1 at tin.it  Wed Sep 26 00:14:16 2007
From: vdemart1 at tin.it (vittorio)
Date: Tue, 25 Sep 2007 22:14:16 +0000
Subject: [R] Can't update packages because of -lgfortran
Message-ID: <200709252214.17446.vdemart1@tin.it>

Under freebsd 6.2 intel Duo, R 2.5.1 I can't update some packages (14 now) 
because of a problem with -lgfortran, e.g.

> update.packages("Hmisc")
....................................................................
...............................................................
* Installing *source* package 'Hmisc' ...
** libs
gfortran42   -fpic  -g -O2 -c cidxcn.f -o cidxcn.o
gfortran42   -fpic  -g -O2 -c cidxcp.f -o cidxcp.o
gfortran42   -fpic  -g -O2 -c hoeffd.f -o hoeffd.o
gfortran42   -fpic  -g -O2 -c jacklins.f -o jacklins.o
gfortran42   -fpic  -g -O2 -c largrec.f -o largrec.o
cc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include  -I/usr/local/include  -D__NO_MATH_INLINES  -fpic  -O2 -fno-strict-aliasing -pipe -march=prescott -c 
ranksort.c -o ranksort.o
gfortran42   -fpic  -g -O2 -c rcorr.f -o rcorr.o
cc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include  -I/usr/local/include  -D__NO_MATH_INLINES  -fpic  -O2 -fno-strict-aliasing -pipe -march=prescott -c 
string_box.c -o string_box.o
gfortran42   -fpic  -g -O2 -c wclosest.f -o wclosest.o
cc -std=gnu99 -shared -L/usr/local/lib -o Hmisc.so cidxcn.o cidxcp.o hoeffd.o 
jacklins.o largrec.o ranksort.o rcorr.o string_box.o 
wclosest.o  -L/usr/local/lib/gcc-4.2.1/gcc/i386-portbld-freebsd6.2/4.2.1 -L/usr/local/lib/gcc-4.2.1 -lgfortran -lm -lgcc_s -L/usr/local/lib/R/lib -lR
/usr/bin/ld: cannot find -lgfortran
*** Error code 1

Stop in /tmp/R.INSTALL.I0P7Jg/Hmisc/src.
ERROR: compilation failed for package 'Hmisc'
** Removing '/usr/local/lib/R/library/Hmisc'
** Restoring previous '/usr/local/lib/R/library/Hmisc'

I'm asking you: what's the matter with -lgfortran?

Thanks 
Vittorio


From lucy.lists at gmail.com  Tue Sep 25 22:39:11 2007
From: lucy.lists at gmail.com (lucy b)
Date: Tue, 25 Sep 2007 16:39:11 -0400
Subject: [R] extracting data using strings as delimiters
Message-ID: <2de5b7170709251339t166059cerafd431b24c69328d@mail.gmail.com>

Dear List,

I have an ascii text file with data I'd like to extract. Example:

Year Built:  1873 Gross Building Area:  578 sq ft
Total Rooms:  6 Living Area:  578 sq ft

There is a lot of data I'd like to ignore in each record, so I'm
hoping there is a way to use strings as delimiters to get the data I
want (e.g. tell R to take data between "Built:" and "Gross" -
incidentally, not always numeric). I think an ugly way would be to
start at the end of each record and use a substitution expression to
chip away at it, but I'm afraid it will take forever to run. Is there
a way to use strings as delimiters in an expression?

Thanks in advance for ideas.

LB


From kate at few.vu.nl  Tue Sep 25 23:07:07 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Tue, 25 Sep 2007 23:07:07 +0200 (CEST)
Subject: [R] extracting data using strings as delimiters
In-Reply-To: <2de5b7170709251339t166059cerafd431b24c69328d@mail.gmail.com>
References: <2de5b7170709251339t166059cerafd431b24c69328d@mail.gmail.com>
Message-ID: <Pine.GSO.4.56.0709252258140.18615@laurel.few.vu.nl>

have you seen help(strsplit)?

On Tue, 25 Sep 2007, lucy b wrote:

> Dear List,
>
> I have an ascii text file with data I'd like to extract. Example:
>
> Year Built:  1873 Gross Building Area:  578 sq ft
> Total Rooms:  6 Living Area:  578 sq ft
>
> There is a lot of data I'd like to ignore in each record, so I'm
> hoping there is a way to use strings as delimiters to get the data I
> want (e.g. tell R to take data between "Built:" and "Gross" -
> incidentally, not always numeric). I think an ugly way would be to
> start at the end of each record and use a substitution expression to
> chip away at it, but I'm afraid it will take forever to run. Is there
> a way to use strings as delimiters in an expression?
>
> Thanks in advance for ideas.
>
> LB
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From marc_schwartz at comcast.net  Tue Sep 25 23:15:57 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Tue, 25 Sep 2007 16:15:57 -0500
Subject: [R] extracting data using strings as delimiters
In-Reply-To: <2de5b7170709251339t166059cerafd431b24c69328d@mail.gmail.com>
References: <2de5b7170709251339t166059cerafd431b24c69328d@mail.gmail.com>
Message-ID: <1190754957.3547.93.camel@Bellerophon.localdomain>

On Tue, 2007-09-25 at 16:39 -0400, lucy b wrote:
> Dear List,
> 
> I have an ascii text file with data I'd like to extract. Example:
> 
> Year Built:  1873 Gross Building Area:  578 sq ft
> Total Rooms:  6 Living Area:  578 sq ft
> 
> There is a lot of data I'd like to ignore in each record, so I'm
> hoping there is a way to use strings as delimiters to get the data I
> want (e.g. tell R to take data between "Built:" and "Gross" -
> incidentally, not always numeric). I think an ugly way would be to
> start at the end of each record and use a substitution expression to
> chip away at it, but I'm afraid it will take forever to run. Is there
> a way to use strings as delimiters in an expression?
> 
> Thanks in advance for ideas.
> 
> LB

I don't know that any of the default base functions enable the use of a
regex as a delimiter. If your text file is consistent in the use of the
colon ':' as a separator, you might be able to use that. Each of the
above lines then would be broken into 3 fields using:

DF <- read.table("YourFile.txt", sep = ":")

> DF
           V1                         V2          V3
1  Year Built   1873 Gross Building Area   578 sq ft
2 Total Rooms              6 Living Area   578 sq ft


You could then parse them further using appropriate functions if needed,
such as gsub():

> as.data.frame(lapply(DF[, -1], function(x) gsub("[^0-9]", "", x)))
    V2  V3
1 1873 578
2    6 578


This now gives you the numeric data in two columns. You would now need
to know that data in the rows are perhaps in some predictable or
alternating order for further processing.  See ?gsub and ?regex for more
information.

Hope that provides some help. You also might want to look at ?readLines
and ?strsplit as other ways to read in the data and then post-process it
once in an R object.

Marc Schwartz


From jholtman at gmail.com  Tue Sep 25 23:25:59 2007
From: jholtman at gmail.com (jim holtman)
Date: Tue, 25 Sep 2007 17:25:59 -0400
Subject: [R] extracting data using strings as delimiters
In-Reply-To: <2de5b7170709251339t166059cerafd431b24c69328d@mail.gmail.com>
References: <2de5b7170709251339t166059cerafd431b24c69328d@mail.gmail.com>
Message-ID: <644e1f320709251425n6e8b6b0as158696d89989d91e@mail.gmail.com>

Here is one way.  You can setup a list of the patterns to match
against and then apply it to the string.  I am not sure  what the rest
of the text file look like, but this will return all the values that
match.

> x <- readLines(textConnection("Year Built:  1873 Gross Building Area:  578 sq ft
+ Total Rooms:  6 Living Area:  578 sq ft
+ Year Built:  1873 Gross Building Area:  578 sq ft
+ Total Rooms:  6 Living Area:  578 sq ft"))
>
> # list for pattern matches
> m.list <- list(year=".*Year Built:(.*)Gross.*",
+     Buildarea=".*Building Area:(.*)sq ft.*",
+     rooms=".*Rooms:(.*)Liv.*",
+     Livingarea=".*Living Area:(.*)sq ft.*")
>
> # use lapply to process the patterns and return a list with the name of the
> # pattern and its value
> lapply(names(m.list), function(.pat){
+     # see which lines have the desired patterns
+     whichLines <- grep(m.list[[.pat]], x)
+     if (length(whichLines) > 0){
+         return(list(pattern=.pat, values=sub(m.list[[.pat]], "\\1",
x[whichLines])))
+     }
+     else return(NULL)
+ })
[[1]]
[[1]]$pattern
[1] "year"

[[1]]$values
[1] "  1873 " "  1873 "


[[2]]
[[2]]$pattern
[1] "Buildarea"

[[2]]$values
[1] "  578 " "  578 "


[[3]]
[[3]]$pattern
[1] "rooms"

[[3]]$values
[1] "  6 " "  6 "


[[4]]
[[4]]$pattern
[1] "Livingarea"

[[4]]$values
[1] "  578 " "  578 "




On 9/25/07, lucy b <lucy.lists at gmail.com> wrote:
> Dear List,
>
> I have an ascii text file with data I'd like to extract. Example:
>
> Year Built:  1873 Gross Building Area:  578 sq ft
> Total Rooms:  6 Living Area:  578 sq ft
>
> There is a lot of data I'd like to ignore in each record, so I'm
> hoping there is a way to use strings as delimiters to get the data I
> want (e.g. tell R to take data between "Built:" and "Gross" -
> incidentally, not always numeric). I think an ugly way would be to
> start at the end of each record and use a substitution expression to
> chip away at it, but I'm afraid it will take forever to run. Is there
> a way to use strings as delimiters in an expression?
>
> Thanks in advance for ideas.
>
> LB
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From Ted.Harding at manchester.ac.uk  Wed Sep 26 00:20:03 2007
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Tue, 25 Sep 2007 23:20:03 +0100 (BST)
Subject: [R] extracting data using strings as delimiters
In-Reply-To: <2de5b7170709251339t166059cerafd431b24c69328d@mail.gmail.com>
Message-ID: <XFMail.070925232003.Ted.Harding@manchester.ac.uk>

On 25-Sep-07 20:39:11, lucy b wrote:
> Dear List,
> 
> I have an ascii text file with data I'd like to extract. Example:
> 
> Year Built:  1873 Gross Building Area:  578 sq ft
> Total Rooms:  6 Living Area:  578 sq ft
> 
> There is a lot of data I'd like to ignore in each record, so I'm
> hoping there is a way to use strings as delimiters to get the data I
> want (e.g. tell R to take data between "Built:" and "Gross" -
> incidentally, not always numeric). I think an ugly way would be to
> start at the end of each record and use a substitution expression to
> chip away at it, but I'm afraid it will take forever to run. Is there
> a way to use strings as delimiters in an expression?
> 
> Thanks in advance for ideas.
> 
> LB

The scope of what you're trying to achieve is not clear,
though on the basis of your examples above you'd have to
use a different separator pattern for each type of line.

For your first example, a simple method is on the lines of

gsub(".*Built:" , "",
     "Year Built:  1873 Gross Building Area:  578 sq ft")
[1] "  1873 Gross Building Area:  578 sq ft"

and then just take the first white-space-delimited field
from the result.

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 25-Sep-07                                       Time: 23:20:01
------------------------------ XFMail ------------------------------


From Roger.Bivand at nhh.no  Wed Sep 26 00:40:06 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 25 Sep 2007 22:40:06 +0000 (UTC)
Subject: [R] GWR modeling with dummy variables
References: <2439f5740709241615l13e811cbk80fdf8c13ea828fd@mail.gmail.com>
Message-ID: <loom.20070925T222954-423@post.gmane.org>

Steve Friedman <friedman.steve <at> gmail.com> writes:

> 
> Hi everyone,
> 
> I'm working with a modest sized spatial database consisting of 1513 records
> and 50 variables.  Fourteen of these are dummy variables delineating
> regional planning councils.  I'm trying to understand how to integrate the
> dummy variables in the geographically weight regression model. I'm reading
> Fotheringham et.al. and see reference to using dummy variables, but I don't
> see an example ilustrating the procedure.  I also don't see an example in
> the spgwr.pdf files associated with the package.
> 
> If anyone has experience with this I'd certainly like to hear from you.

As you may know, so-called GWR models are severely subject to collinearity 
impacting local coefficients. 

In R, dummy variables are operationalised as factors, split out into the 
appropriate dummies within model functions from the formula argument. So just 
put the categorical variable (factor) in the RHS of the formula, and it will 
just happen. So gwr(y ~ regional_planning_councils + ..., ...) for gwr in the 
spgwr package will just work for factor regional_planning_councils with 14 
levels. 

The R-sig-geo list is more focused on this kind of question.

Roger


> 
> I'm using R-2.5.1 on a PC.
> 
> Thanks in advance.
> 
> Steve
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help <at> r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
>


From ggrothendieck at gmail.com  Wed Sep 26 00:59:57 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 25 Sep 2007 18:59:57 -0400
Subject: [R] extracting data using strings as delimiters
In-Reply-To: <2de5b7170709251339t166059cerafd431b24c69328d@mail.gmail.com>
References: <2de5b7170709251339t166059cerafd431b24c69328d@mail.gmail.com>
Message-ID: <971536df0709251559q2c29d4f8k6f1d997cc56367a8@mail.gmail.com>

Perhaps you could clarify what the general rule is but assuming
that what you want is any word after a colon it can be done with
strapply in the gsubfn package like this:

Lines <- c("Year Built:  1873 Gross Building Area:  578 sq ft",
"Total Rooms:  6 Living Area:  578 sq ft")

library(gsubfn)
strapply(Lines, ": *(\\w+)", backref = -1)

# or if each line has same number of returned words
strapply(Lines, ": *(\\w+)", backref = -1, simplify = rbind)

This matches a colon (:) followed by zero or more spaces ( *)
followed by a word ((\\w+)) and backref= - 1 causes it to return
only the first backreference (i..e. the portion within parentheses)
but not the match itself.

On 9/25/07, lucy b <lucy.lists at gmail.com> wrote:
> Dear List,
>
> I have an ascii text file with data I'd like to extract. Example:
>
> Year Built:  1873 Gross Building Area:  578 sq ft
> Total Rooms:  6 Living Area:  578 sq ft
>
> There is a lot of data I'd like to ignore in each record, so I'm
> hoping there is a way to use strings as delimiters to get the data I
> want (e.g. tell R to take data between "Built:" and "Gross" -
> incidentally, not always numeric). I think an ugly way would be to
> start at the end of each record and use a substitution expression to
> chip away at it, but I'm afraid it will take forever to run. Is there
> a way to use strings as delimiters in an expression?
>
> Thanks in advance for ideas.
>
> LB
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bolker at ufl.edu  Wed Sep 26 01:38:50 2007
From: bolker at ufl.edu (bbolker)
Date: Tue, 25 Sep 2007 16:38:50 -0700 (PDT)
Subject: [R] 3d barplot in rgl
In-Reply-To: <f8e6ff050709251221j24cc266gabbd3208b6a86887@mail.gmail.com>
References: <EEDF5281-5B15-41B0-ACFF-B775F4990555@lanl.gov>
	<f8e6ff050709251142q309ef7a0vabea299e6464d1a3@mail.gmail.com>
	<loom.20070925T185034-259@post.gmane.org>
	<f8e6ff050709251221j24cc266gabbd3208b6a86887@mail.gmail.com>
Message-ID: <12891221.post@talk.nabble.com>




hadley wrote:
> 
> On 9/25/07, Chris Stubben <stubben at lanl.gov> wrote:
>> hadley wickham <h.wickham <at> gmail.com> writes:
>>
>> >
>> > Why do you want a 3d barchart?  They are generally a bad way to
>> > present information as tall bars can obscure short bars, and it is
>> > hard to accurately read off the height of a bar.  While adding
>> > rotation can reduce some of these problems, why not create a graphic
>> > that your viewers can take in with a glance?
>> >
>>
>> 3d barplots are a common way to display sensitvity/elasticity matrices in
>> stage-structured demography.  Here's a few other options from Caswell's
>> Matrix
>> population models book (2001) - I definitely  prefer 3d barcharts to
>> these
>> alternatives.
>>
>>
>> heatmap(log10(A[3:1,]), Rowv = NA,  Colv = NA, scale="none")
>>
>> plot(log10(c(A)), type="s")
> 
> Both of those look like equally awful alternatives.  Perhaps you could
> explain more about your data (perhaps with a sample?) so that we could
> suggest better alternatives.
> 
> Hadley
> 


   Transition matrices are Markov transition matrices among different
life stages of organisms -- in the simplest case (Leslie matrices,
tracking age-structured populations), the top row of the matrix represents
fecundity and the first off-diagonal (below the diagonal) represents
survival.    The elasticities and sensitivities are differential (absolute
or proportional) responses
of long-run population growth rate [i.e., the largest eigenvalue] to changes
in
matrix elements.

  In the Leslie case the matrix is quite sparse and it would be easy to just
plot sensitivities/elasticities of fecundities and survivorship.

  In the more complicated case (Lefkovitch matrices), the categories
represent
stages rather than ages so individuals can stay in the same class from year
to year,
or even revert to the previous class, so the matrix is less sparse and the
problem
is a little more challenging.

   Here are some data from the popbio package on CRAN
for playing with.

library(popbio)
example(teasel)   ## shows 2 plots -- heatmap and stair-step
A <- tea$sensitivities ##

Here's one possibility, setting 0 sensitivities to NA to omit
them from the plot:

z <- as.data.frame.table(A)
names(z) <- c("From","To","Sensitivity")
z$Sensitivity[z$Sensitivity==0] <- NA
dotplot(From~Sensitivity|To,data=z)
dotplot(From~Sensitivity|To,data=z,scales=list(x=list(log=TRUE)))

  I turned the plot horizontally to make it easier to draw labels
(as lattice often does), but this might be too confusing.

  Sorry not to use ggplot2, but I haven't sat down to try to figure
it out yet ....
-- 
View this message in context: http://www.nabble.com/3d-barplot-in-rgl-tf4517380.html#a12891221
Sent from the R help mailing list archive at Nabble.com.


From wtimm at techfak.uni-bielefeld.de  Wed Sep 26 02:16:05 2007
From: wtimm at techfak.uni-bielefeld.de (Wiebke Timm)
Date: Tue, 25 Sep 2007 20:16:05 -0400
Subject: [R] finding a stable cluster for kmeans
In-Reply-To: <20070925090033.53360@gmx.net>
References: <20070925090033.53360@gmx.net>
Message-ID: <811A8237-D5F9-43B5-A30E-5B115360CC60@techfak.uni-bielefeld.de>

You might want to check if there is a neural gas algorithm in R.

kmeans generally has a high variance since it is very dependent on  
the initialization. Neural gas overcomes this problem by using a  
ranked list of neighbouring data points instead using data points  
directly. It is more stable (at the cost of additional computational  
time).

On 25.09.2007, at 05:00, Julia Kr?pfl wrote:

> I applied kmeans to my data:
>
> kcluster= kmeans((mydata, 4, iter.max=10)
> table(code, kcluster$cluster)
>
> If I run this code again, I get a different result as with the  
> first trial (I understand that this is correct, since kmeans starts  
> randomly with assigning the clusters and therefore the outcomes can  
> be different)
> But is there a way to stabilize the cluster (meaning finding the  
> one cluster that appears the most often in 10 trials)?
>
> Thank you for any ideas,
> Julia
> --
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lukasneraas.r at gmail.com  Wed Sep 26 02:29:53 2007
From: lukasneraas.r at gmail.com (Luke Neraas)
Date: Tue, 25 Sep 2007 16:29:53 -0800
Subject: [R] Paste a matrix column in pairwise fashion with other columns?
Message-ID: <1f80d2810709251729y6c10e1e5v807466903d1e92ae@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070925/25896bd2/attachment.pl 

From jholtman at gmail.com  Wed Sep 26 03:05:07 2007
From: jholtman at gmail.com (jim holtman)
Date: Tue, 25 Sep 2007 21:05:07 -0400
Subject: [R] Paste a matrix column in pairwise fashion with other
	columns?
In-Reply-To: <1f80d2810709251729y6c10e1e5v807466903d1e92ae@mail.gmail.com>
References: <1f80d2810709251729y6c10e1e5v807466903d1e92ae@mail.gmail.com>
Message-ID: <644e1f320709251805q50f55446qced8c6b85e51d21f@mail.gmail.com>

try this:

> P.genotype.sample<-matrix(10,10,10)
> P.genotype.sample[,1]<-c(2,2,1,5,1,1,5,6,1,3)
> P.genotype.sample[,2]<-c(6,3,3,6,8,1,6,7,2,3)
> P.genotype.sample[,3]<-c(2,2,2,3,3,2,2,2,3,3)
> P.genotype.sample[,4]<-c(2,8,8,3,8,2,8,3,4,3)
> P.genotype.sample[,5]<-c(3,3,8,3,6,1,1,1,1,3)
> P.genotype.sample[,6]<-c(6,3,8,8,6,8,7,3,1,7)
> P.genotype.sample[,7]<-c(1,5,5,1,5,1,1,5,5,5)
> P.genotype.sample[,8]<-c(5,5,5,5,7,6,7,5,5,8)
> P.genotype.sample[,9]<-c(5,5,8,5,5,5,5,2,5,2)
> P.genotype.sample[,10]<-c(5,8,8,8,8,5,8,5,8,2)
> P.genotype.sample
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    2    6    2    2    3    6    1    5    5     5
 [2,]    2    3    2    8    3    3    5    5    5     8
 [3,]    1    3    2    8    8    8    5    5    8     8
 [4,]    5    6    3    3    3    8    1    5    5     8
 [5,]    1    8    3    8    6    6    5    7    5     8
 [6,]    1    1    2    2    1    8    1    6    5     5
 [7,]    5    6    2    8    1    7    1    7    5     8
 [8,]    6    7    2    3    1    3    5    5    2     5
 [9,]    1    2    3    4    1    1    5    5    5     8
[10,]    3    3    3    3    3    7    5    8    2     2

> # create matrix of odd/even indices
> x <- matrix(3:ncol(P.genotype.sample), byrow=TRUE, ncol=2)
> # now create the desired output
> apply(x, 1, function(.row){
+     paste(P.genotype.sample[,1:2], P.genotype.sample[,.row])
+ })


      [,1]  [,2]  [,3]  [,4]
 [1,] "2 2" "2 3" "2 1" "2 5"
 [2,] "2 2" "2 3" "2 5" "2 5"
 [3,] "1 2" "1 8" "1 5" "1 8"
 [4,] "5 3" "5 3" "5 1" "5 5"
 [5,] "1 3" "1 6" "1 5" "1 5"
 [6,] "1 2" "1 1" "1 1" "1 5"
 [7,] "5 2" "5 1" "5 1" "5 5"
 [8,] "6 2" "6 1" "6 5" "6 2"
 [9,] "1 3" "1 1" "1 5" "1 5"
[10,] "3 3" "3 3" "3 5" "3 2"
[11,] "6 2" "6 6" "6 5" "6 5"
[12,] "3 8" "3 3" "3 5" "3 8"
[13,] "3 8" "3 8" "3 5" "3 8"
[14,] "6 3" "6 8" "6 5" "6 8"
[15,] "8 8" "8 6" "8 7" "8 8"
[16,] "1 2" "1 8" "1 6" "1 5"
[17,] "6 8" "6 7" "6 7" "6 8"
[18,] "7 3" "7 3" "7 5" "7 5"
[19,] "2 4" "2 1" "2 5" "2 8"
[20,] "3 3" "3 7" "3 8" "3 2"
>


On 9/25/07, Luke Neraas <lukasneraas.r at gmail.com> wrote:
> #Hello,
>
> #I have would like to paste a single column of a matrix
> # in pair wise fashion with other columns based upon
> # even and odd column numbers.
> # I can do it in a very clunky fashion and I know there
> # must be a better way. below is a sample matrix and my extremely
> # clunky code that gets the job done for a small matrix, but i plan to
> # do this on a much grander scale. any help would be very much appreciated.
>
> P.genotype.sample<-matrix(10,10,10)
> P.genotype.sample[,1]<-c(2,2,1,5,1,1,5,6,1,3)
> P.genotype.sample[,2]<-c(6,3,3,6,8,1,6,7,2,3)
> P.genotype.sample[,3]<-c(2,2,2,3,3,2,2,2,3,3)
> P.genotype.sample[,4]<-c(2,8,8,3,8,2,8,3,4,3)
> P.genotype.sample[,5]<-c(3,3,8,3,6,1,1,1,1,3)
> P.genotype.sample[,6]<-c(6,3,8,8,6,8,7,3,1,7)
> P.genotype.sample[,7]<-c(1,5,5,1,5,1,1,5,5,5)
> P.genotype.sample[,8]<-c(5,5,5,5,7,6,7,5,5,8)
> P.genotype.sample[,9]<-c(5,5,8,5,5,5,5,2,5,2)
> P.genotype.sample[,10]<-c(5,8,8,8,8,5,8,5,8,2)
> P.genotype.sample
>
> # I would like to paste column 1 with every odd column
> # I would like to paste column 2 with every even column
>
> #I know i can do it step by step in this fashion
>
> Column.1.2_by_Column.3.4<-paste(P.genotype.sample[,1:2],P.genotype.sample
> [,3:4])
> Column.1.2_by_Column.3.4
>
> Column.1.2_by_Column.5.6<-paste(P.genotype.sample[,1:2],P.genotype.sample
> [,5:6])
> Column.1.2_by_Column.5.6
>
> Column.1.2_by_Column.7.8<-paste(P.genotype.sample[,1:2],P.genotype.sample
> [,7:8])
> Column.1.2_by_Column.7.8
>
> Column.1.2_by_Column.9.10<-paste(P.genotype.sample[,1:2],P.genotype.sample
> [,9:10])
> Column.1.2_by_Column.9.10
>
> Column.1.2.data.matrix<- matrix(20,20,4)
>
> Column.1.2.data.list<-list(Column.1.2_by_Column.3.4,Column.1.2_by_Column.5.6
> ,
>               Column.1.2_by_Column.7.8,Column.1.2_by_Column.9.10)
> for (i in 1:4){
> Column.1.2.data.matrix[,i]<-Column.1.2.data.list[[i]]
>        }
> Column.1.2.data.matrix
>
> # However i will have many more data columns to compare to in a larger data
> set
> # and I was wondering if there was a more clever way to do this and still
> # come up with the same result.
>
> # Any help would be greatly appreciated
>
> # Thanks in advance
>
> Luke Neraas
>
> lukasneraas.r at gmail.com
>
> University of Alaska Fairbanks
> School of Fisheries and Ocean Sciences
> 11120 Glacier Highway
> UAF Fisheries Division
> Juneau, AK 99801
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From bolker at ufl.edu  Wed Sep 26 03:17:40 2007
From: bolker at ufl.edu (bbolker)
Date: Tue, 25 Sep 2007 18:17:40 -0700 (PDT)
Subject: [R] R2Winbugs problem
In-Reply-To: <12885677.post@talk.nabble.com>
References: <12885677.post@talk.nabble.com>
Message-ID: <12892096.post@talk.nabble.com>




Sam_zhz wrote:
> 
> Just while I use R2Winbugs, the following error will be presented. Please
> tell me how to cope with.
> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file 'codaIndex.txt', reason 'No such file or directory' in:
> file(file, "r") 
> Thanks
> Sam_zhz
> 

  The most likely problem is that WinBUGS crashed without saving a file. 
Try setting debug=TRUE.
Also, please (a) try reading the posting guide (URL at the bottom of every
R-list
message); (b) as requested therein, send us a reproducible example; (c) be a
little
more patient with your e-mails to the list, try not to send so many
duplicates.

  cheers
    Ben Bolker
-- 
View this message in context: http://www.nabble.com/R2Winbugs-problem-tf4517334.html#a12892096
Sent from the R help mailing list archive at Nabble.com.


From sacha.kapoor at utoronto.ca  Wed Sep 26 04:03:52 2007
From: sacha.kapoor at utoronto.ca (sacha.kapoor at utoronto.ca)
Date: Tue, 25 Sep 2007 22:03:52 -0400
Subject: [R] xtable with dupplicate rownames
Message-ID: <20070925220352.45re60zr8z6sgw4w@webmail.utoronto.ca>

Hello Ani,

I am having the same problem with xtable and duplicate rownames. Would  
it be possible for you to post your solution?

Best,

Sacha Kapoor
PhD Candidate
Department of Economics
University of Toronto


From kuruvilla at post.harvard.edu  Wed Sep 26 04:53:20 2007
From: kuruvilla at post.harvard.edu (Finny Kuruvilla)
Date: Tue, 25 Sep 2007 21:53:20 -0500
Subject: [R] sprucing up the R homepage
Message-ID: <20070926025320.GA7975@web15.webfaction.com>

I've been a R-user for quite some time.  The graphic on the home page
looks a bit in need of polish so I applied some antialiased
transformations that Peter Dalgaard has previously posted to R-help
for improving graphic quality.  I had to change the margins a bit, but
here is what it looks like:

http://www.broad.mit.edu/~finnyk/Rhome.jpg

Personally, I think it looks much better.  Because people so often
"judge a book by its cover" (subconsciously or consciously), I'm
wondering if anyone thinks this is worthy of replacing the current
version?  I want R to maximize R's appeal and albeit a small
improvement, hopefully this change will help a bit!

Regards,
Finny Kuruvilla

-- 
Finny Kuruvilla, MD, PhD
Department of Molecular Biology, Massachusetts General Hospital
Broad Institute of Harvard and MIT
Homepage: http://www.anchorcross.org/people/kuruvilla/


From r.turner at auckland.ac.nz  Wed Sep 26 05:16:55 2007
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 26 Sep 2007 15:16:55 +1200
Subject: [R] sprucing up the R homepage
In-Reply-To: <20070926025320.GA7975@web15.webfaction.com>
References: <20070926025320.GA7975@web15.webfaction.com>
Message-ID: <6FFD05B5-0EDB-4294-BBF0-C609ABEBCFAF@auckland.ac.nz>


Although overall the new graphic looks better --- cleaner, clearer  
--- I think that the
clustering graphic (tree, bottom left) has taken a step backward.

			cheers,

				Rolf Turner

On 26/09/2007, at 2:53 PM, Finny Kuruvilla wrote:

> I've been a R-user for quite some time.  The graphic on the home page
> looks a bit in need of polish so I applied some antialiased
> transformations that Peter Dalgaard has previously posted to R-help
> for improving graphic quality.  I had to change the margins a bit, but
> here is what it looks like:
>
> http://www.broad.mit.edu/~finnyk/Rhome.jpg
>
> Personally, I think it looks much better.  Because people so often
> "judge a book by its cover" (subconsciously or consciously), I'm
> wondering if anyone thinks this is worthy of replacing the current
> version?  I want R to maximize R's appeal and albeit a small
> improvement, hopefully this change will help a bit!
>
> Regards,
> Finny Kuruvilla
>
> -- 
> Finny Kuruvilla, MD, PhD
> Department of Molecular Biology, Massachusetts General Hospital
> Broad Institute of Harvard and MIT
> Homepage: http://www.anchorcross.org/people/kuruvilla/
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


######################################################################
Attention:\ This e-mail message is privileged and confidenti...{{dropped}}


From adschai at optonline.net  Wed Sep 26 05:38:52 2007
From: adschai at optonline.net (adschai at optonline.net)
Date: Wed, 26 Sep 2007 03:38:52 +0000 (GMT)
Subject: [R] Calling R function from Java
Message-ID: <e355fa80843b.46f9d44c@optonline.net>

Hi - I would like to have the same functionality like what R(D)COM server offers but from Java world. I have java code (on windows) and need to call some R code to run some computational job and get the result back into java code. I'm wondering if there's any direct package that offers this functionality? Thank you.

- adschai


From tchur at optusnet.com.au  Wed Sep 26 06:05:11 2007
From: tchur at optusnet.com.au (Tim Churches)
Date: Wed, 26 Sep 2007 14:05:11 +1000
Subject: [R] sprucing up the R homepage
Message-ID: <200709260405.l8Q45B3i014618@mail04.syd.optusnet.com.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070926/7711b76c/attachment.pl 

From p.dalgaard at biostat.ku.dk  Wed Sep 26 08:14:03 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 26 Sep 2007 08:14:03 +0200
Subject: [R] sprucing up the R homepage
In-Reply-To: <200709260405.l8Q45B3i014618@mail04.syd.optusnet.com.au>
References: <200709260405.l8Q45B3i014618@mail04.syd.optusnet.com.au>
Message-ID: <46F9F8AB.2030200@biostat.ku.dk>

Tim Churches wrote:
> Finny Kuruvilla <kuruvilla at post.harvard.edu> wrote:
>   
>> I've been a R-user for quite some time.  The graphic on the home page
>> looks a bit in need of polish so I applied some antialiased
>> transformations that Peter Dalgaard has previously posted to R-help
>> for improving graphic quality.  I had to change the margins a bit, but
>> here is what it looks like:
>>
>> http://www.broad.mit.edu/~finnyk/Rhome.jpg
>>
>> Personally, I think it looks much better.  Because people so often
>> "judge a book by its cover" (subconsciously or consciously), I'm
>> wondering if anyone thinks this is worthy of replacing the current
>> version?  I want R to maximize R's appeal and albeit a small
>> improvement, hopefully this change will help a bit!
>>     
>
> If you run Eric Lecoutre's code to produce the graphic, available at http://www.r-project.org/misc/acpclust.R, unchanged except for the addition of these lines:
>
> library(Cairo)
> Cairo(600,400,file="Rlogo_swiss.png",type="png",bg="white")
>
> then you get this:
>
> http://members.optusnet.com.au/tchur/Rlogo_swiss.png
>
> which I think looks even better. Kudos to Simon Urbanek and Jeffrey Horner for the excellent Cairo device driver for R (and which works even without an X server, which makes it great for web server applications).
>
> Tim C
>   
Yes, this looks better. Finny's version looks oversmoothed in 
comparison. Out of academic curiosity, what happens if you diddle the 
parameters of the smooth-and-subsample technique to use a narrower smoother?

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From stat700004 at yahoo.co.in  Wed Sep 26 00:12:57 2007
From: stat700004 at yahoo.co.in (stat stat)
Date: Tue, 25 Sep 2007 23:12:57 +0100 (BST)
Subject: [R] Legend
Message-ID: <709299.21295.qm@web94405.mail.in2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070925/9c3ce0d8/attachment.pl 

From friedrich.leisch at stat.uni-muenchen.de  Wed Sep 26 09:05:47 2007
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Wed, 26 Sep 2007 09:05:47 +0200
Subject: [R] Proposal: Archive UseR conference presentations at
	www.r-project.org/useR-yyyy
In-Reply-To: <f8e6ff050709250717i21280dfdn11e44b4a84086538@mail.gmail.com>
References: <f8e6ff050709041413k70340217r76b51984d9e23ef9@mail.gmail.com>
	<fcmq8e$udt$1@sea.gmane.org>
	<46EFC023.7030803@statistik.uni-dortmund.de>
	<f8e6ff050709180805y6e856bd8t23da94e178e2bf43@mail.gmail.com>
	<40e66e0b0709180856s5d4c2218n6f74fe7575402244@mail.gmail.com>
	<18167.30368.575305.907742@lxh5.stat.uni-muenchen.de>
	<f8e6ff050709240725u488e5070kb568af29edd96524@mail.gmail.com>
	<18168.40633.133271.581108@lxh5.stat.uni-muenchen.de>
	<f8e6ff050709250717i21280dfdn11e44b4a84086538@mail.gmail.com>
Message-ID: <18170.1227.979430.144861@lxh5.stat.uni-muenchen.de>

>>>>> On Tue, 25 Sep 2007 09:17:23 -0500,
>>>>> hadley wickham (hw) wrote:

  >> > but I can understand your desire to do
  >> > that.  Perhaps just taking a static snapshot using something like
  >> > wget, and hosting that on the R-project website would be a good
  >> > compromise.
  >> 
  >> Hmm, wouldn't it be easier if the hosting institution would make a tgz
  >> file? wget over HTTP is rather bad in resolving links etc

  > Really?  I've always found it to be rather excellent.

Sorry, my statement was rather ambigous. wget is excellent, but
mirroring via HTTP is terrible (administering CRAN for a couple of
years gives you more experience than you ever wanted to have in that
arena).

With "links" I meant symbolic links on the server filesystem. HTTP
does not make a difference between a symbolic link and a real
file/directory, so for every symbolic link you get a copy of the
target (and there is nothing wget can do about it AFAIK).


  > The reason I suggest it is that unless you have some way to generate a
  > static copy of the site, you'll need to ensure that the R-project
  > supports any dynamic content.  e.g. for example the user 2008 site
  > uses some (fairly vanilla) php for including the header and
  > footer.

I don't care how the tgz file I get is created, but probably it is
better if the local authors create (and check) it rather than I do
it. So no problem if the tarball is created using wget ... but I'd
rather prefer not to do it myself.


  >> we could include a note on the top page that this is only a snapshot
  >> copy and have a link to the original site (in case something changes
  >> there).

  > That's reasonable, although it would be even better to have it on
  > every page.

Again, if the authors create a tarball, they can put the note wherever
they like. I thought of adding a link "local copy from 200x-yy-zz" to
the list of conferences at www.R-project.org next to the links to the
original  sites.

  >> > The one problem is setting up a redirect so that existing links and
  >> > google searches aren't broken.  This would need to be put in place at
  >> > least 6 months before the old website closed.
  >> 
  >> Yes, very good point, I didn't think about that. But the R site is
  >> searched very often, so material there appears rather quickly on
  >> Google searches. Ad bookmarks: I don't want to remove the old site,
  >> just have an archive copy at a central location.

  > In that case, should it be labelled no-index as it's just a cache of
  > material that should be available elsewhere?  We need some
  > machine-readable way of indicating where the canonical resource is.
  > It's always frustrated me a little that when googling for r
  > documentation, you find hundreds of the same page hosted at different
  > sites.

Well, 2 copies are not as bad as hundreds. But material might get
found faster on the www.R-project.org site, because that ranks
surprisingly high in many google searches.

Best,
Fritz


From carlos.grohmann at gmail.com  Wed Sep 26 09:28:21 2007
From: carlos.grohmann at gmail.com (=?ISO-8859-1?Q?Carlos_"Gu=E2no"_Grohmann?=)
Date: Wed, 26 Sep 2007 08:28:21 +0100
Subject: [R] truehist?
In-Reply-To: <46F88D2E.7010001@biostat.ku.dk>
References: <bd07447b0709240907s6b8209c7k5908e6676e991240@mail.gmail.com>
	<46F88D2E.7010001@biostat.ku.dk>
Message-ID: <bd07447b0709260028o72decec4o7c5e2c7d68fc8886@mail.gmail.com>

Oh yes.

I did searched for help, but Ijust didn't read carefully, I read
"MAAS", instead of MASS..

Carlos



On 9/25/07, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> Carlos "Gu?no" Grohmann wrote:
> > Hello,
> > After a long time, I needed the truehist function, but my system
> > couldn't found it. I tried to install the package MAAS, but I couldn't
> > found it! Something happened?
> >
> > Carlos
> >
> >
> It's in MASS (sic).
>
> help.search("truehist") would have told you.
>
>
> --
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>
>
>


-- 
+-----------------------------------------------------------+
              Carlos Henrique Grohmann - Guano
  Visiting Researcher at Kingston University London - UK
  Geologist M.Sc  - Doctorate Student at IGc-USP - Brazil
Linux User #89721  - carlos dot grohmann at gmail dot com
+-----------------------------------------------------------+
_________________
"Good morning, doctors. I have taken the liberty of removing Windows
95 from my hard drive."
--The winning entry in a "What were HAL's first words" contest judged
by 2001: A SPACE ODYSSEY creator Arthur C. Clarke

Can't stop the signal.


From bhs2 at mevik.net  Wed Sep 26 10:20:27 2007
From: bhs2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Wed, 26 Sep 2007 10:20:27 +0200
Subject: [R] Who uses R?
In-Reply-To: <XFMail.070925124046.Ted.Harding@manchester.ac.uk>
	(Ted.Harding@manchester.ac.uk's
	message of "Tue, 25 Sep 2007 12:40:46 +0100 (BST)")
References: <XFMail.070925124046.Ted.Harding@manchester.ac.uk>
Message-ID: <m03ax1sur8.fsf@bar.nemo-project.org>

(Ted Harding) wrote:

> Pat Altham (now retired) developed extensive teaching (and
> other) materials in R at the Cambridge University Statistical
> Laboratory. From her personal web page:
>
>   "Some of the computer languages I have had to try to
>    learn since graduating in 1964: Cambridge autocode,
>    algol, phoenix, machine-code, Fortran, BBC-Basic,
>    GLIM, GENSTAT, Linux, S-Plus and finally (probably
>    the best so far!) R."

Well, calling Linux a computer language will probably not add too much
credibility to the quote(r). :-)

-- 
Bj?rn-Helge Mevik


From marcel.austenfeld at uni-bielefeld.de  Wed Sep 26 11:35:25 2007
From: marcel.austenfeld at uni-bielefeld.de (Bio7)
Date: Wed, 26 Sep 2007 02:35:25 -0700 (PDT)
Subject: [R] Calling R function from Java
In-Reply-To: <e355fa80843b.46f9d44c@optonline.net>
References: <e355fa80843b.46f9d44c@optonline.net>
Message-ID: <12897221.post@talk.nabble.com>


Hello,

I've created an application (IDE for ecological modelling) on the basis of
Eclipse which uses Rserve
 
http://www.rforge.net/Rserve/ http://www.rforge.net/Rserve/ 

to archieve this.
I also implemented a small api to send or access data from or to R and Java.
The transfer is very fast. I've also created a lot of examples which
demonstrates the use.
If this sound interesting for you visit

http://www.uni-bielefeld.de/biologie/Oekosystembiologie/bio7app/
http://www.uni-bielefeld.de/biologie/Oekosystembiologie/bio7app/ 

for more information.
The application is OpenSource and free to use.

With kind regards

Marcel
-- 
View this message in context: http://www.nabble.com/Calling-R-function-from-Java-tf4519877.html#a12897221
Sent from the R help mailing list archive at Nabble.com.


From Tom.Willems at var.fgov.be  Wed Sep 26 11:42:01 2007
From: Tom.Willems at var.fgov.be (Tom Willems)
Date: Wed, 26 Sep 2007 11:42:01 +0200
Subject: [R] Q: confidence intervals & plotMeans, how do i discard NA's
Message-ID: <OF25D2B64E.895AA546-ONC1257362.00332C5C-C1257362.00354C79@var.fgov.be>

Een ingesloten tekst met niet-gespecificeerde tekenset is
van het bericht gescrubt ...
Naam: niet beschikbaar
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070926/277422c0/attachment.pl 

From FredeA.Togersen at agrsci.dk  Wed Sep 26 11:49:13 2007
From: FredeA.Togersen at agrsci.dk (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 26 Sep 2007 11:49:13 +0200
Subject: [R] Legend
In-Reply-To: <709299.21295.qm@web94405.mail.in2.yahoo.com>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC0574B8C0@DJFPOST01.djf.agrsci.dk>

You can use bquote (see ?bquote or the example in ?plotmath using bquote). 

Here you go,

pvalue <- 0.3
legend("bottom", fill=c("red","blue"), legend=c(bquote(p==.(pvalue)), expression(p==0.50)), bty="n")


Med venlig hilsen
Frede Aakmann T?gersen
 

 

> -----Oprindelig meddelelse-----
> Fra: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] P? vegne af stat stat
> Sendt: 26. september 2007 00:13
> Til: r-help at stat.math.ethz.ch
> Emne: [R] Legend
> 
> I have following syntax for putting a legend :
> 
> legend("bottom", fill=c("red","blue"), 
> legend=expression(p==0.30, p==0.50), bty="n")
> 
> However what I want is that : the value "0.30" should be a 
> value of a variable instead of a constant, so that I can put 
> the name of this variable and in legend it's value will be 
> displayed. Can anyone tell me how to do that?
> 
> Regards,
> 
> 
> thanks in advance
>        
> ---------------------------------
>  Why delete messages? Unlimited storage is just a click away.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From ehlers at math.ucalgary.ca  Wed Sep 26 12:06:54 2007
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Wed, 26 Sep 2007 04:06:54 -0600
Subject: [R] Legend
In-Reply-To: <709299.21295.qm@web94405.mail.in2.yahoo.com>
References: <709299.21295.qm@web94405.mail.in2.yahoo.com>
Message-ID: <46FA2F3E.8060503@math.ucalgary.ca>

How about

a <- .33
b <- .55
legend("bottom", fill=c("red","blue"),
   legend=c(bquote(p == .(a)), bquote(p == .(b))), bty="n")

or look at ?substitute

  - Peter Ehlers

stat stat wrote:
> I have following syntax for putting a legend :
> 
> legend("bottom", fill=c("red","blue"), legend=expression(p==0.30, p==0.50), bty="n")
> 
> However what I want is that : the value "0.30" should be a value of a variable instead of a constant, so that I can put the name of this variable and in legend it's value will be displayed. Can anyone tell me how to do that?
> 
> Regards,
> 
> 
> thanks in advance
>        
> ---------------------------------
>  Why delete messages? Unlimited storage is just a click away.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
>


From amorigandhi at yahoo.de  Wed Sep 26 12:43:51 2007
From: amorigandhi at yahoo.de (amor Gandhi)
Date: Wed, 26 Sep 2007 12:43:51 +0200 (CEST)
Subject: [R] RODBC problem
In-Reply-To: <5E3D22A4869BB94AA1138AB97660D8B69196B0@POPULUS.ifn.fr>
Message-ID: <11694.5243.qm@web26001.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070926/0c53b91a/attachment.pl 

From amorigandhi at yahoo.de  Wed Sep 26 12:44:40 2007
From: amorigandhi at yahoo.de (amor Gandhi)
Date: Wed, 26 Sep 2007 12:44:40 +0200 (CEST)
Subject: [R] RODBC problem
In-Reply-To: <5E3D22A4869BB94AA1138AB97660D8B69196B0@POPULUS.ifn.fr>
Message-ID: <515482.41296.qm@web26014.mail.ukl.yahoo.com>

Hello,
   
  I wrote
   
  > setwd("D:/")
> dd <- read.table(file="test.txt",header=TRUE)
> attach(dd)
> boxplot(x)

> outlier <- function(y){
+   out <- boxplot(y, range = 1)$out
+   outliers <- which(y == out)
+   dev.off()
+   return(out,outliers)
+ }
> outlier(x)
$out
 [1] 1.950208 2.082025 4.768637 4.800333 5.529516 1.657321 4.656504 2.138956
 [9] 4.437906 4.716786
  $outliers
[1] 23
  Warning messages:

  Could you tell me please why do I have Warning messages and why I do not get all the id for the outliers in out, but only for the id=23? Thank you very much in advance!
   
  Amor
DUPREZ C?dric <cedric.duprez at ifn.fr> schrieb:
  Hello,

The problem seems to be in the query syntax.
Can you show us the query you are trying to perform ?

Regards,

Cedric

-----Message d'origine-----
De : r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] De la part de Bernhard Wellh?fer
Envoy? : vendredi 6 juillet 2007 11:45
? : r-help at stat.math.ethz.ch
Objet : [R] RODBC problem

Hello,

I use a RODBC connection to a MySQL server on a Debian machine. The call to odbcConnect() seems to be ok, but the result of the first sqlFetch(channel,"t_studie") retrieves this data frame:

[1] "[RODBC] ERROR: Could not SQLExecDirect"
[2] "42000 1064 [MySQL][ODBC 3.51 Driver][mysqld-5.0.22-Debian_1bpo1-log]You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '\"t_studi(\004"

Please note the funny character at the end of the table name in the error message.

The "Test Data Source" option on the ODBC Data Source Name configuration panel report success.

Who can help me here?

Regards,

Bernhard






[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


       
---------------------------------
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: test.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070926/1dc30629/attachment.txt 

From wl2776 at gmail.com  Wed Sep 26 13:09:17 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Wed, 26 Sep 2007 04:09:17 -0700 (PDT)
Subject: [R] RODBC problem
In-Reply-To: <7C36DCD0D35F9A4A8D89A7A8916E755D6D5376@GAIA-SERVER.gaia-group.local>
References: <7C36DCD0D35F9A4A8D89A7A8916E755D6D5376@GAIA-SERVER.gaia-group.local>
Message-ID: <12898626.post@talk.nabble.com>


Hi.
It looks like the letter 'e' at the end of the table name is not latinic
'e'.
sqlFetch constructs the SQL query internally from the supplied table name:

ans <- sqlQuery(channel, paste("SELECT * FROM", dbname), 
        ...)

What will be the answer for
  sqlQuery(channel, paste("SELECT * FROM", "t_studie"))
?

Or, if you should set up some settings regarding the locale on the MySQL
server (not sure, what and where exactly)


Bernhard2 wrote:
> 
> Hello,
>  
> I use a RODBC connection to a MySQL server on a Debian machine. The call
> to odbcConnect() seems to be ok, but the result of the first
> sqlFetch(channel,"t_studie") retrieves this data frame:
>  
> [1] "[RODBC] ERROR: Could not SQLExecDirect"
> [2] "42000 1064 [MySQL][ODBC 3.51
> Driver][mysqld-5.0.22-Debian_1bpo1-log]You have an error in your SQL
> syntax; check the manual that corresponds to your MySQL server version for
> the right syntax to use near '\"t_studi(\004"
> 
> Please note the funny character at the end of the table name in the error
> message.
>  
> The "Test Data Source" option on the ODBC Data Source Name configuration
> panel report success.
>  
> Who can help me here?
>  
> 

-- 
View this message in context: http://www.nabble.com/RODBC-problem-tf4034563.html#a12898626
Sent from the R help mailing list archive at Nabble.com.


From Wayne.W.Jones at shell.com  Wed Sep 26 13:16:38 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Wed, 26 Sep 2007 12:16:38 +0100
Subject: [R] RODBC problem
In-Reply-To: <515482.41296.qm@web26014.mail.ukl.yahoo.com>
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B0BC@wyt-s-019.europe.shell.com>

Not sure which of the questions yo want answered in your email. 

However, if its the one regarding the boxplot try: 



dd <- read.table("test.txt",header=T)
attach(dd)
boxplot(x)

outlier <- function(y){
out <- boxplot(y, range = 1)$out
outliers <- which(y %in% out)

return(list(out=out,outliers=outliers))
}

outlier(x)



-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of amor Gandhi
Sent: 26 September 2007 11:45
To: DUPREZ C?dric; Bernhard "Wellh?fer
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] RODBC problem


Hello,
   
  I wrote
   
  > setwd("D:/")
> dd <- read.table(file="test.txt",header=TRUE)
> attach(dd)
> boxplot(x)

> outlier <- function(y){
+   out <- boxplot(y, range = 1)$out
+   outliers <- which(y == out)
+   dev.off()
+   return(out,outliers)
+ }
> outlier(x)
$out
 [1] 1.950208 2.082025 4.768637 4.800333 5.529516 1.657321 4.656504 2.138956
 [9] 4.437906 4.716786
  $outliers
[1] 23
  Warning messages:

  Could you tell me please why do I have Warning messages and why I do not get all the id for the outliers in out, but only for the id=23? Thank you very much in advance!
   
  Amor
DUPREZ C?dric <cedric.duprez at ifn.fr> schrieb:
  Hello,

The problem seems to be in the query syntax.
Can you show us the query you are trying to perform ?

Regards,

Cedric

-----Message d'origine-----
De : r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] De la part de Bernhard Wellh?fer
Envoy? : vendredi 6 juillet 2007 11:45
? : r-help at stat.math.ethz.ch
Objet : [R] RODBC problem

Hello,

I use a RODBC connection to a MySQL server on a Debian machine. The call to odbcConnect() seems to be ok, but the result of the first sqlFetch(channel,"t_studie") retrieves this data frame:

[1] "[RODBC] ERROR: Could not SQLExecDirect"
[2] "42000 1064 [MySQL][ODBC 3.51 Driver][mysqld-5.0.22-Debian_1bpo1-log]You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '\"t_studi(\004"

Please note the funny character at the end of the table name in the error message.

The "Test Data Source" option on the ODBC Data Source Name configuration panel report success.

Who can help me here?

Regards,

Bernhard






[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


       


From efferz at gmx.de  Wed Sep 26 13:28:19 2007
From: efferz at gmx.de (Martin Efferz)
Date: Wed, 26 Sep 2007 13:28:19 +0200
Subject: [R] Some simple questions about neural networks
Message-ID: <001801c80030$57577a00$06066e00$@de>

Ein eingebundener Text mit undefiniertem Zeichensatz wurde abgetrennt.
Name: nicht verf?gbar
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20070926/a0a6513b/attachment.pl 

From wl2776 at gmail.com  Wed Sep 26 13:29:27 2007
From: wl2776 at gmail.com (Vladimir Eremeev)
Date: Wed, 26 Sep 2007 04:29:27 -0700 (PDT)
Subject: [R] RODBC problem
In-Reply-To: <7C36DCD0D35F9A4A8D89A7A8916E755D6D5384@GAIA-SERVER.gaia-group.local>
References: <7C36DCD0D35F9A4A8D89A7A8916E755D6D5376@GAIA-SERVER.gaia-group.local>
	<5E3D22A4869BB94AA1138AB97660D8B69196B0@POPULUS.ifn.fr>
	<7C36DCD0D35F9A4A8D89A7A8916E755D6D5384@GAIA-SERVER.gaia-group.local>
Message-ID: <12898875.post@talk.nabble.com>


You can trace this function:

install.packages("debug")
library(debug)
mtrace(sqlFetch)
sqlFetch(channel,"t_studie")

Then you'll have the new window showing function code and allowing you to
execute it step by step, view intermediate results, variables, etc.

To switch off tracing, use
mtrace(sqlFetch,FALSE)
or
mtrace.off() # this switches off all tracees.

Very useful tool. I used it a lot while was struggling with the reshape().


Bernhard2 wrote:
> 
> Hello,
> 
> as I wrote I call
> 
>   sqlFetch(channel,"t_studie")
> 
> and this function generates in the background the concrete query. How can
> I view/log/... the concrete query?
> 
> Regards,
> 
> Bernhard 
> 
>> -----Original Message-----
>> From: DUPREZ C?dric [mailto:cedric.duprez at ifn.fr] 
>> Sent: Friday, July 06, 2007 11:59 AM
>> To: Bernhard Wellh?fer
>> Cc: r-help at stat.math.ethz.ch
>> Subject: RE: [R] RODBC problem
>> 
>> Hello,
>> 
>> The problem seems to be in the query syntax.
>> Can you show us the query you are trying to perform ?
>> 
>> Regards,
>> 
>> Cedric
>> 
>> -----Message d'origine-----
>> De?: r-help-bounces at stat.math.ethz.ch 
>> [mailto:r-help-bounces at stat.math.ethz.ch] De la part de 
>> Bernhard Wellh?fer
>> Envoy??: vendredi 6 juillet 2007 11:45
>> ??: r-help at stat.math.ethz.ch
>> Objet?: [R] RODBC problem
>> 
>> Hello,
>>  
>> I use a RODBC connection to a MySQL server on a Debian 
>> machine. The call to odbcConnect() seems to be ok, but the 
>> result of the first sqlFetch(channel,"t_studie") retrieves 
>> this data frame:
>>  
>> [1] "[RODBC] ERROR: Could not SQLExecDirect"
>> [2] "42000 1064 [MySQL][ODBC 3.51 
>> Driver][mysqld-5.0.22-Debian_1bpo1-log]You have an error in 
>> your SQL syntax; check the manual that corresponds to your 
>> MySQL server version for the right syntax to use near '\"t_studi(\004"
>> 
>> Please note the funny character at the end of the table name 
>> in the error message.
>>  
>> The "Test Data Source" option on the ODBC Data Source Name 
>> configuration panel report success.
>>  
>> Who can help me here?
>>  
>> Regards,
>>  
>> Bernhard
> 

-- 
View this message in context: http://www.nabble.com/RODBC-problem-tf4034563.html#a12898875
Sent from the R help mailing list archive at Nabble.com.


From elw at stderr.org  Wed Sep 26 13:35:40 2007
From: elw at stderr.org (elw at stderr.org)
Date: Wed, 26 Sep 2007 06:35:40 -0500 (CDT)
Subject: [R] sprucing up the R homepage
In-Reply-To: <200709260405.l8Q45B3i014618@mail04.syd.optusnet.com.au>
References: <200709260405.l8Q45B3i014618@mail04.syd.optusnet.com.au>
Message-ID: <Pine.LNX.4.64.0709260632370.9274@illuminati.stderr.org>



>> http://www.broad.mit.edu/~finnyk/Rhome.jpg

> If you run Eric Lecoutre's code to produce the graphic, available at 
> http://www.r-project.org/misc/acpclust.R, unchanged except for the 
> addition of these lines:
>
> library(Cairo)
> Cairo(600,400,file="Rlogo_swiss.png",type="png",bg="white")
>
> then you get this:
>
> http://members.optusnet.com.au/tchur/Rlogo_swiss.png
>
> which I think looks even better. Kudos to Simon Urbanek and Jeffrey 
> Horner for the excellent Cairo device driver for R (and which works even 
> without an X server, which makes it great for web server applications).


It seems to have lost labels on the left, though... and there is some 
oddness on the right edge, too, where the number "45" found in the other 
two plot versions has been replaced with "V. De Gen..." - what looks like 
part of someone's name or some other descriptor.  The "(1-3) 60%" under 
the PCA 5 Vars section also intersects with part of a plot.

Overall the effect is better, but the fine details could use some 
tweaking.

--elijah


From kuruvilla at post.harvard.edu  Wed Sep 26 14:42:05 2007
From: kuruvilla at post.harvard.edu (Finny Kuruvilla)
Date: Wed, 26 Sep 2007 07:42:05 -0500
Subject: [R] sprucing up the R homepage
In-Reply-To: <46F9F8AB.2030200@biostat.ku.dk>
References: <200709260405.l8Q45B3i014618@mail04.syd.optusnet.com.au>
	<46F9F8AB.2030200@biostat.ku.dk>
Message-ID: <20070926124204.GA318@web15.webfaction.com>

FYI, Peter Dalgaard's original posting from 2004 that I used is here:
http://tolstoy.newcastle.edu.au/R/help/04/06/1094.html

Per his suggestion, I changed the smoothing parameter to be:
"pnmsmooth -size 1 1" instead of "pnmsmooth -size 5 5" which he
originally described.  The new graphic is here:

http://www.broad.mit.edu/~finnyk/Rhome2.jpg

It is predictably, less smoothed, and does look a bit nicer.  Tim
Churches' version also looks very good.  As someone else has noted,
Tim's does have a few rough edges involving mostly margins (I had to
manually tweak them).  I also manually put the 45 in to make it look
like the original.

I'd be happy if either his or mine replaced the current version, if
there is consensus.

Best, Finny Kuruvilla

On Wed, Sep 26, 2007 at 08:14:03AM +0200, Peter Dalgaard wrote:
> Tim Churches wrote:
> >Finny Kuruvilla <kuruvilla at post.harvard.edu> wrote:
> >  
> >>I've been a R-user for quite some time.  The graphic on the home page
> >>looks a bit in need of polish so I applied some antialiased
> >>transformations that Peter Dalgaard has previously posted to R-help
> >>for improving graphic quality.  I had to change the margins a bit, but
> >>here is what it looks like:
> >>
> >>http://www.broad.mit.edu/~finnyk/Rhome.jpg
> >>
> >>Personally, I think it looks much better.  Because people so often
> >>"judge a book by its cover" (subconsciously or consciously), I'm
> >>wondering if anyone thinks this is worthy of replacing the current
> >>version?  I want R to maximize R's appeal and albeit a small
> >>improvement, hopefully this change will help a bit!
> >>    
> >
> >If you run Eric Lecoutre's code to produce the graphic, available at 
> >http://www.r-project.org/misc/acpclust.R, unchanged except for the 
> >addition of these lines:
> >
> >library(Cairo)
> >Cairo(600,400,file="Rlogo_swiss.png",type="png",bg="white")
> >
> >then you get this:
> >
> >http://members.optusnet.com.au/tchur/Rlogo_swiss.png
> >
> >which I think looks even better. Kudos to Simon Urbanek and Jeffrey 
> >Horner for the excellent Cairo device driver for R (and which works even 
> >without an X server, which makes it great for web server applications).
> >
> >Tim C
> >  
> Yes, this looks better. Finny's version looks oversmoothed in 
> comparison. Out of academic curiosity, what happens if you diddle the 
> parameters of the smooth-and-subsample technique to use a narrower 
> smoother?
> 
> -- 
>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 
> 35327907
> 
> 

-- 
Finny Kuruvilla, MD, PhD
Department of Molecular Biology, Massachusetts General Hospital
Broad Institute of Harvard and MIT
Homepage: http://www.anchorcross.org/people/kuruvilla/


From googel.vs.privacy at googlemail.com  Wed Sep 26 11:21:50 2007
From: googel.vs.privacy at googlemail.com (idontwant googeltospyafterme)
Date: Wed, 26 Sep 2007 11:21:50 +0200
Subject: [R] R on webserver with browser-gui
Message-ID: <e0a4be450709260221q5d0eddaav61800a577253714b@mail.gmail.com>

hi everyone,

i know r since last summer and i love it. i'm studying economics and
use it for econometrical tasks at university. besides that in a
private project a buddy of mine and me do some economic evaluation
with data stored in a MYSQL-database. we export the values from our
online MYSQL database to analyse them offline with r. the results then
also hav to be stored in the mysql.

so far so good. but now we would like to do some process-optimization.
we want to run r directly on the webserver, so that it can fetch the
data itself from the MYSQL and save it into a temp-folder for
analysing. this should work automatically, after we selected the
appropriate r-script in a browser-gui for R.

until know after collecting some information, i think the best
approach to reach that goal is:
* using mod_R / RApache to run multiple instances of r on the server,
* build a website that will serve as frontend/gui for r either with
html/php or some ajax-framework,
* connect R to the database with one of the available db-packages to
fetch the survey-data
* put the r-scripts for analysis somewhere on the server
* use cairo for generation of the images
* and see what happens...

i would like to know, if my construction seems good to you, if you
have other recommendations or constructive critics and what you think
about the effort for configuring mod_R/RAPACHE, cairo and the
db-package for r.

thanks a lot in advance for your help!

cheers,

josuah r.


From kuruvilla at post.harvard.edu  Wed Sep 26 15:22:19 2007
From: kuruvilla at post.harvard.edu (Finny Kuruvilla)
Date: Wed, 26 Sep 2007 08:22:19 -0500
Subject: [R] sprucing up the R homepage
In-Reply-To: <Pine.LNX.4.64.0709260632370.9274@illuminati.stderr.org>
References: <200709260405.l8Q45B3i014618@mail04.syd.optusnet.com.au>
	<Pine.LNX.4.64.0709260632370.9274@illuminati.stderr.org>
Message-ID: <20070926132219.GB318@web15.webfaction.com>

So I applied my corrected margins to Tim's Cairo trick and voila:

http://www.broad.mit.edu/~finnyk/Rlogo_swiss.png

This is hands-down the best version, in my opinion!

Best, 
Finny

On Wed, Sep 26, 2007 at 06:35:40AM -0500, elw at stderr.org wrote:
> 
> 
> >>http://www.broad.mit.edu/~finnyk/Rhome.jpg
> 
> >If you run Eric Lecoutre's code to produce the graphic, available at 
> >http://www.r-project.org/misc/acpclust.R, unchanged except for the 
> >addition of these lines:
> >
> >library(Cairo)
> >Cairo(600,400,file="Rlogo_swiss.png",type="png",bg="white")
> >
> >then you get this:
> >
> >http://members.optusnet.com.au/tchur/Rlogo_swiss.png
> >
> >which I think looks even better. Kudos to Simon Urbanek and Jeffrey 
> >Horner for the excellent Cairo device driver for R (and which works even 
> >without an X server, which makes it great for web server applications).
> 
> 
> It seems to have lost labels on the left, though... and there is some 
> oddness on the right edge, too, where the number "45" found in the other 
> two plot versions has been replaced with "V. De Gen..." - what looks like 
> part of someone's name or some other descriptor.  The "(1-3) 60%" under 
> the PCA 5 Vars section also intersects with part of a plot.
> 
> Overall the effect is better, but the fine details could use some 
> tweaking.
> 
> --elijah

-- 
Finny Kuruvilla, MD, PhD
Department of Molecular Biology, Massachusetts General Hospital
Broad Institute of Harvard and MIT
Homepage: http://www.anchorcross.org/people/kuruvilla/


From friedrich.leisch at stat.uni-muenchen.de  Wed Sep 26 15:28:09 2007
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Wed, 26 Sep 2007 15:28:09 +0200
Subject: [R] finding a stable cluster for kmeans
In-Reply-To: <811A8237-D5F9-43B5-A30E-5B115360CC60@techfak.uni-bielefeld.de>
References: <811A8237-D5F9-43B5-A30E-5B115360CC60@techfak.uni-bielefeld.de>
Message-ID: <18170.24169.3403.377357@lxh5.stat.uni-muenchen.de>

>>>>> On Tue, 25 Sep 2007 20:16:05 -0400,
>>>>> Wiebke Timm (WT) wrote:

  > You might want to check if there is a neural gas algorithm in R.
  > kmeans generally has a high variance since it is very dependent on  
  > the initialization. Neural gas overcomes this problem by using a  
  > ranked list of neighbouring data points instead using data points  
  > directly. It is more stable (at the cost of additional computational  
  > time).

Neural gas is in package flexclust on CRAN (one of the clustering
methods function cclust() privides).

I also find it more stable than kmeans for some data, although in
general I agree with what has been said before in this thread:
instability is in most cases caused by no clear cluster structure of
the data, wrong number of clusters etc rather than by the wrong
cluster algorithm.

Best,

-- 
-----------------------------------------------------------------------
Prof. Dr. Friedrich Leisch 

Institut f?r Statistik                          Tel: (+49 89) 2180 3165
Ludwig-Maximilians-Universit?t                  Fax: (+49 89) 2180 5308
Ludwigstra?e 33
D-80539 M?nchen                 http://www.stat.uni-muenchen.de/~leisch


From likhonnaser at hotmail.com  Wed Sep 26 15:32:48 2007
From: likhonnaser at hotmail.com (Abu Naser)
Date: Wed, 26 Sep 2007 13:32:48 +0000
Subject: [R] How to avoid printing index on the screen
Message-ID: <BAY134-W21F99137F2C8E84DCBCAA0A3B00@phx.gbl>


Hi All R-user,

Anyone please let me know how to avoid printing index on the screen.

With regards,
_________________________________________________________________
100?s of Music vouchers to be won with MSN Music


From mdgi at gmx.ch  Wed Sep 26 15:37:16 2007
From: mdgi at gmx.ch (marcg)
Date: Wed, 26 Sep 2007 15:37:16 +0200
Subject: [R] add points to wireframe
Message-ID: <20070926133716.23790@gmx.net>

Hello

R-classicist won't like the following question due to there's no minimal reproducible example and the question was posted already.

Anyway I'm not able understand this rather complicated version of "add points to wireframe".

what I have is matrix 3x2000 with a dem<-(x,y,z, coordinates) (not provided).

with follwing code I want to produce the wireframe and add some points on it:

wireframe(z ~ x * y, data=dem, aspect = c(1, .5),
          scales = list(arrows = FALSE),
          panel.3d.wireframe = function(x, y, z,...) {
              panel.3dwire(x = x, y = y, z = z, ...)
              panel.3dscatter(x = x,
                              y = y,
                              z = z, data=ramm
                              ...)
          })

3d.scatter should give me the points into the wireframe from ramm:

> ramm
        x      y      z 
1  10.179  7.999  9.069 
2  10.988 15.982 13.682    
3  10.765 23.155 16.995   
4  -0.577 24.275 17.171    
5  10.430 32.677 19.488    
6  16.725 25.301 17.211    
7  15.248 16.440 13.638    
8  -0.841 17.577 14.007    
9  -0.379  9.401  9.578    
10 19.560  6.905  8.212 
11 23.288  1.783  5.974 
12  9.681  1.096  5.889  
13 -0.001  2.127  5.991 

somehow there are errors appearing: 
Fehler: syntax error, unexpected SYMBOL, expecting ',' in: 
"           y = y,

in plot, the wireframe appears, but no axes and points.

thanks for your help

marc
-- 
Psssst! Schon vom neuen GMX MultiMessenger geh?rt?
Der kanns mit allen: http://www.gmx.net/de/go/multimessenger


From lucy.lists at gmail.com  Wed Sep 26 15:50:00 2007
From: lucy.lists at gmail.com (lucy b)
Date: Wed, 26 Sep 2007 09:50:00 -0400
Subject: [R] extracting data using strings as delimiters
In-Reply-To: <971536df0709251559q2c29d4f8k6f1d997cc56367a8@mail.gmail.com>
References: <2de5b7170709251339t166059cerafd431b24c69328d@mail.gmail.com>
	<971536df0709251559q2c29d4f8k6f1d997cc56367a8@mail.gmail.com>
Message-ID: <2de5b7170709260650w2c546312l2d432aa2fd2bc1e0@mail.gmail.com>

All great ideas. I tried strsplit first and it worked, but thanks everyone!

Best-
LB

On 9/25/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Perhaps you could clarify what the general rule is but assuming
> that what you want is any word after a colon it can be done with
> strapply in the gsubfn package like this:
>
> Lines <- c("Year Built:  1873 Gross Building Area:  578 sq ft",
> "Total Rooms:  6 Living Area:  578 sq ft")
>
> library(gsubfn)
> strapply(Lines, ": *(\\w+)", backref = -1)
>
> # or if each line has same number of returned words
> strapply(Lines, ": *(\\w+)", backref = -1, simplify = rbind)
>
> This matches a colon (:) followed by zero or more spaces ( *)
> followed by a word ((\\w+)) and backref= - 1 causes it to return
> only the first backreference (i..e. the portion within parentheses)
> but not the match itself.
>
> On 9/25/07, lucy b <lucy.lists at gmail.com> wrote:
> > Dear List,
> >
> > I have an ascii text file with data I'd like to extract. Example:
> >
> > Year Built:  1873 Gross Building Area:  578 sq ft
> > Total Rooms:  6 Living Area:  578 sq ft
> >
> > There is a lot of data I'd like to ignore in each record, so I'm
> > hoping there is a way to use strings as delimiters to get the data I
> > want (e.g. tell R to take data between "Built:" and "Gross" -
> > incidentally, not always numeric). I think an ugly way would be to
> > start at the end of each record and use a substitution expression to
> > chip away at it, but I'm afraid it will take forever to run. Is there
> > a way to use strings as delimiters in an expression?
> >
> > Thanks in advance for ideas.
> >
> > LB
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From ripley at stats.ox.ac.uk  Wed Sep 26 15:54:33 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 26 Sep 2007 14:54:33 +0100 (BST)
Subject: [R] finding a stable cluster for kmeans
In-Reply-To: <18170.24169.3403.377357@lxh5.stat.uni-muenchen.de>
References: <811A8237-D5F9-43B5-A30E-5B115360CC60@techfak.uni-bielefeld.de>
	<18170.24169.3403.377357@lxh5.stat.uni-muenchen.de>
Message-ID: <Pine.LNX.4.64.0709261444100.1195@gannet.stats.ox.ac.uk>

On Wed, 26 Sep 2007, Friedrich Leisch wrote:

>>>>>> On Tue, 25 Sep 2007 20:16:05 -0400,
>>>>>> Wiebke Timm (WT) wrote:
>
>  > You might want to check if there is a neural gas algorithm in R.
>  > kmeans generally has a high variance since it is very dependent on
>  > the initialization. Neural gas overcomes this problem by using a
>  > ranked list of neighbouring data points instead using data points
>  > directly. It is more stable (at the cost of additional computational
>  > time).
>
> Neural gas is in package flexclust on CRAN (one of the clustering
> methods function cclust() privides).
>
> I also find it more stable than kmeans for some data, although in
> general I agree with what has been said before in this thread:
> instability is in most cases caused by no clear cluster structure of
> the data, wrong number of clusters etc rather than by the wrong
> cluster algorithm.

I don't understand this use of 'high variance' and 'stable'.  K-means is a 
clearly defined criterion (rare in the clustering field) and so the 
outcome does not depend on the initialization.  Maybe different runs of 
kmeans() give different clusters, but in that case the algorithm is not 
optimizing the criterion in some (and maybe all) cases.  ?kmeans clearly 
says

      The Hartigan-Wong algorithm
      generally does a better job than either of those, but trying
      several random starts is often recommended.

And that there are several clusterings with roughly equally good fit would 
indicate that none of them is a uniquely good summary of the data.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From albmont at centroin.com.br  Wed Sep 26 16:25:33 2007
From: albmont at centroin.com.br (Alberto Monteiro)
Date: Wed, 26 Sep 2007 12:25:33 -0200
Subject: [R] wordReport
Message-ID: <20070926141919.M86273@centroin.com.br>

?wordReport gives a lot of information, but I think it makes us wish for 
more :-)

Where can I find all the ways to write Word documents using R? 

Namely:

(1) is there any way to open a new document and save it automatically?
The sequence:

WordOpen("new_file.doc"); WordInsertText("R rulez!\n"); WordExit()

will prompt for the Yes/No/Cancel prompt, and if I answer "Yes", it opens 
the menu to "Save As".

(2) is there any way to write formulas in the evil Word formula format, but 
with input as decent latex-like format?

Alberto Monteiro


From Max.Kuhn at pfizer.com  Wed Sep 26 16:31:04 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Wed, 26 Sep 2007 10:31:04 -0400
Subject: [R] wordReport
In-Reply-To: <20070926141919.M86273@centroin.com.br>
Message-ID: <71257D09F114DA4A8E134DEAC70F25D309A16D2F@groamrexm03.amer.pfizer.com>

 
> Where can I find all the ways to write Word documents using R? 

There aren't many. Look at 

  http://www.user2007.org/program/presentations/kuhn.pdf

to get Word documents via OpenOffice.

Max


From cary.dehing at maastro.nl  Wed Sep 26 16:44:45 2007
From: cary.dehing at maastro.nl (Cary Dehing-Oberije)
Date: Wed, 26 Sep 2007 16:44:45 +0200
Subject: [R] using transcan for imputation, categorical variable
Message-ID: <A954B571D12ECE4A94DD2016E34F3031026C3190@exch1.ad.maastro.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070926/a9e88231/attachment.pl 

From wtimm at techfak.uni-bielefeld.de  Wed Sep 26 16:58:34 2007
From: wtimm at techfak.uni-bielefeld.de (Wiebke Timm)
Date: Wed, 26 Sep 2007 10:58:34 -0400
Subject: [R] finding a stable cluster for kmeans
In-Reply-To: <Pine.LNX.4.64.0709261444100.1195@gannet.stats.ox.ac.uk>
References: <811A8237-D5F9-43B5-A30E-5B115360CC60@techfak.uni-bielefeld.de>
	<18170.24169.3403.377357@lxh5.stat.uni-muenchen.de>
	<Pine.LNX.4.64.0709261444100.1195@gannet.stats.ox.ac.uk>
Message-ID: <0BD38AC9-FEE6-4454-9555-FC01CB6D0E5C@techfak.uni-bielefeld.de>


On 26.09.2007, at 09:54, Prof Brian Ripley wrote:

> On Wed, 26 Sep 2007, Friedrich Leisch wrote:
>
>>>>>>> On Tue, 25 Sep 2007 20:16:05 -0400,
>>>>>>> Wiebke Timm (WT) wrote:
>>
>>  > You might want to check if there is a neural gas algorithm in R.
>>  > kmeans generally has a high variance since it is very dependent on
>>  > the initialization. Neural gas overcomes this problem by using a
>>  > ranked list of neighbouring data points instead using data points
>>  > directly. It is more stable (at the cost of additional  
>> computational
>>  > time).
>>
>> Neural gas is in package flexclust on CRAN (one of the clustering
>> methods function cclust() privides).
>>
>> I also find it more stable than kmeans for some data, although in
>> general I agree with what has been said before in this thread:
>> instability is in most cases caused by no clear cluster structure of
>> the data, wrong number of clusters etc rather than by the wrong
>> cluster algorithm.

> I don't understand this use of 'high variance' and 'stable'.

high variance: Each time you run k-means (with the same number of  
prototypes and the same data, and random prototype placement) the  
result's goodness of fit varies.

stable: Results are reproducible.

> K-means is a clearly defined criterion (rare in the clustering  
> field) and so the outcome does not depend on the initialization.

I suggest having a look at http://pubs.acs.org/cgi-bin/abstract.cgi/ 
jcisd8/2002/42/i06/abs/ci020270w.html

"The K-means method is usually applied for partitioning
data into k clusters. MacQueen?s K-means seems to be the
most popular. It is known that K-means suffers from the
initial random selection of cluster centers, which has a crucial
impact upon the final results.1 Moreover, the convergence
to an optimal solution of the cost function is not guaranteed.1"

And there are more sources which state that it does depend. Vogt et  
al state in http://www.clinchem.org/cgi/content/abstract/38/2/182 ,  
refering to the Hartigan algorithm:

"3. The result of the classification depends on the number of groups  
chosen, the starting partition, and the order of objects."

I know of other sources that made this observation.

Wir k-means, even with the right number of prototypes, it can happen  
that, due to a very unlucky initialization of prototype, one cluster  
gets 2 prototypes and another cluster does not get one.

> Maybe different runs of kmeans() give different clusters, but in  
> that case the algorithm is not optimizing the criterion in some  
> (and maybe all) cases.  ?kmeans clearly says
>
>      The Hartigan-Wong algorithm
>      generally does a better job than either of those, but trying
>      several random starts is often recommended.

Yes, and this is because it depends on the initalization i.e. the  
initial placement of prototypes.

IMO it is more convenient to have an algorithm that you do not have  
to run 50 times and then pick the best result among many different  
outcomes (k-means) but only once, because you know it will reproduce  
that behaviour (neural gas).

> And that there are several clusterings with roughly equally good  
> fit would indicate that none of them is a uniquely good summary of  
> the data.

Yes, but the problem is that you have fits of different quality each  
time you rerun. That's what I meant by "not stable".

Regards,
   Wiebke


From luke at stat.uiowa.edu  Wed Sep 26 17:12:57 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Wed, 26 Sep 2007 10:12:57 -0500 (CDT)
Subject: [R] examples of use of snow package
Message-ID: <Pine.LNX.4.64.0709261012280.4657@nokomis.stat.uiowa.edu>

We have been asked to write a paper on the snow package for
parallel computing in R for a parallel computing journal and
would like to include some references to examples of the use of
snow in practice beyond our own use.  If you think you have a
good example we would like to hear from you.  Please let us know
the appropriate citation to use.

Best,

luke


-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
      Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From joseph.yarmus at oracle.com  Wed Sep 26 17:18:26 2007
From: joseph.yarmus at oracle.com (Joe Yarmus)
Date: Wed, 26 Sep 2007 11:18:26 -0400
Subject: [R] AIC questions
Message-ID: <46FA7842.1080601@oracle.com>

In accordance with Venables and Ripley, SAS documentation and other 
sources AIC with sigma^2 unknown is calculated as:
AIC = -2LL + 2* #parameters =  n log(RSS/n) + 2p
For the fitness data: 
(http://support.sas.com/ctx/samples/index.jsp?sid=927), SAS gets an AIC 
of 64.534 with model oxygen = runtime. (SAS STAT User's Guide. Chapter 
61. pp 3956, the REG Procedure). This value of AIC accords with p = 2.

When I run the same problem in R ver 2.5.1, I get

 > rt.glm =glm(oxy ~ runtime, data=fitness)
 > rt.glm
Call:  glm(formula = oxy ~ runtime, data = fitness)

Coefficients:
(Intercept)      runtime 
     82.422       -3.311 

Degrees of Freedom: 30 Total (i.e. Null);  29 Residual
Null Deviance:        851.4
Residual Deviance: 218.5     AIC: 154.5

I get very close to what R gets if the constant term is included in 
-2LL, (31*Log(2*pi)+n-1), divide RSS by n-1 and the number of parameters 
is 3 (the predictor, the intercept and the error term)
 > 31 * (log(2*pi)+log(sum(rt.glm$res^2)/30)) + 30 + 2 * 3
[1] 154.5248
 > AIC(rt.glm)
[1] 154.5083

3 questions:
1) Why the discrepancy between SAS and R?
2) Why the slight difference between my calculation in R and R's AIC?
3) How should AIC be computed if row weights are used in the linear model?

Thanks!

    -joe yarmus


From jacques.wagnor at gmail.com  Wed Sep 26 17:24:25 2007
From: jacques.wagnor at gmail.com (Jacques Wagnor)
Date: Wed, 26 Sep 2007 10:24:25 -0500
Subject: [R] Scientific Notation
Message-ID: <787911d50709260824n61f7aa4cr673b8a0bb64418f7@mail.gmail.com>

Dear List:

Below is how I specify an axis:

axis(2, at=c(0.00005, 0.0005))

R displays the numbers in scientific notation.  What
argument/parameter should I use to tell R to display the numbers as
specified rather than in scientific notation?

> version
               _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          5.1
year           2007
month          06
day            27
svn rev        42083
language       R
version.string R version 2.5.1 (2007-06-27)


From samuoko at yahoo.com  Wed Sep 26 16:25:09 2007
From: samuoko at yahoo.com (Samuel Okoye)
Date: Wed, 26 Sep 2007 07:25:09 -0700 (PDT)
Subject: [R] date
Message-ID: <438391.68524.qm@web45306.mail.sp1.yahoo.com>

Hello,
   
  I have got the following problem:
   
  > setwd("C:/temp") 
>  library(xlsReadWrite)
>  MyData <- read.xls(file="Mappe1.xls", colNames = TRUE,dateTimeAs = "isodatetime") 
>  attach(MyData) 
>  MyData
  name value      times
1   A1     2 2006-05-12
2   A2     3 2006-05-16
3   A3     1 2006-05-12
4   A4     4 2006-05-12
5   A5     2 2006-05-16
6   A6     1 2006-05-12
> plot(times,value)
Error........
   
  Could you help me please?
   
  Thanks alot,
  Samuel

       
---------------------------------

From murdoch at stats.uwo.ca  Wed Sep 26 17:35:56 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 26 Sep 2007 11:35:56 -0400
Subject: [R] Scientific Notation
In-Reply-To: <787911d50709260824n61f7aa4cr673b8a0bb64418f7@mail.gmail.com>
References: <787911d50709260824n61f7aa4cr673b8a0bb64418f7@mail.gmail.com>
Message-ID: <46FA7C5C.6080607@stats.uwo.ca>

On 9/26/2007 11:24 AM, Jacques Wagnor wrote:
> Dear List:
> 
> Below is how I specify an axis:
> 
> axis(2, at=c(0.00005, 0.0005))
> 
> R displays the numbers in scientific notation.  What
> argument/parameter should I use to tell R to display the numbers as
> specified rather than in scientific notation?

Something like

axis(2, at=c(0.00005, 0.0005), labels=c("0.00005", "0.0005"))

is a way to be 100% sure of what will be displayed, but in this 
particular instance,

at <- c(0.00005, 0.0005)
axis(2, at=at, labels=format(at, sci=FALSE))

comes close, and there may be some other format spec that gets exactly 
what you want.

Duncan Murdoch


From liuwensui at gmail.com  Wed Sep 26 17:40:52 2007
From: liuwensui at gmail.com (Wensui Liu)
Date: Wed, 26 Sep 2007 11:40:52 -0400
Subject: [R] AIC questions
In-Reply-To: <46FA7842.1080601@oracle.com>
References: <46FA7842.1080601@oracle.com>
Message-ID: <1115a2b00709260840j63681f42pf3fee8487d92edfd@mail.gmail.com>

joe,
some procs in SAs calculates log likelihood differently than what it
is supposed to be. try using proc nlmixed and specifying the LL
explicitly.
in your case, I has stronger faith in R result instead of SAS result.

On 9/26/07, Joe Yarmus <joseph.yarmus at oracle.com> wrote:
> In accordance with Venables and Ripley, SAS documentation and other
> sources AIC with sigma^2 unknown is calculated as:
> AIC = -2LL + 2* #parameters =  n log(RSS/n) + 2p
> For the fitness data:
> (http://support.sas.com/ctx/samples/index.jsp?sid=927), SAS gets an AIC
> of 64.534 with model oxygen = runtime. (SAS STAT User's Guide. Chapter
> 61. pp 3956, the REG Procedure). This value of AIC accords with p = 2.
>
> When I run the same problem in R ver 2.5.1, I get
>
>  > rt.glm =glm(oxy ~ runtime, data=fitness)
>  > rt.glm
> Call:  glm(formula = oxy ~ runtime, data = fitness)
>
> Coefficients:
> (Intercept)      runtime
>      82.422       -3.311
>
> Degrees of Freedom: 30 Total (i.e. Null);  29 Residual
> Null Deviance:        851.4
> Residual Deviance: 218.5     AIC: 154.5
>
> I get very close to what R gets if the constant term is included in
> -2LL, (31*Log(2*pi)+n-1), divide RSS by n-1 and the number of parameters
> is 3 (the predictor, the intercept and the error term)
>  > 31 * (log(2*pi)+log(sum(rt.glm$res^2)/30)) + 30 + 2 * 3
> [1] 154.5248
>  > AIC(rt.glm)
> [1] 154.5083
>
> 3 questions:
> 1) Why the discrepancy between SAS and R?
> 2) Why the slight difference between my calculation in R and R's AIC?
> 3) How should AIC be computed if row weights are used in the linear model?
>
> Thanks!
>
>     -joe yarmus
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
===============================
"I am dying with the help of too many
physicians." - Alexander the Great, on his deathbed
===============================
WenSui Liu
(http://spaces.msn.com/statcompute/blog)


From ggrothendieck at gmail.com  Wed Sep 26 17:41:15 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 26 Sep 2007 11:41:15 -0400
Subject: [R] wordReport
In-Reply-To: <20070926141919.M86273@centroin.com.br>
References: <20070926141919.M86273@centroin.com.br>
Message-ID: <971536df0709260841s248d966ai609881a873a7e402@mail.gmail.com>

>From R, you can write an XML or HTML document and read it right into Word
in sufficiently new versions of Word.  Go into Word and save a sample
Word document in the format of your choice to see what it looks like.
Filtered HTML is particularly readable. Alternately, the R packages
RDCOMClient and rcom provide interfaces to Word's COM interface which
would presumably give you complete access to Word's facilities but would
be more work to program.

If you are using HTML then formulas would be included as images and
you can create images of formulas with R's graphic facilities which allows
the use of nice expressions to denote them.

There is also a latex2rtf program that will allow you to generate rich
text format files from latex that are readable in Word.

There may be some limitations to these methods so it would be worthwhile
prototyping anything first.


From junedsiddique at gmail.com  Wed Sep 26 17:43:23 2007
From: junedsiddique at gmail.com (Juned Siddique)
Date: Wed, 26 Sep 2007 10:43:23 -0500
Subject: [R] rpart error: "Error in dimnames(X)"
Message-ID: <d81d28610709260843y41af612dg2a57c4eca6f95eee@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070926/4b7c8813/attachment.pl 

From liuwensui at gmail.com  Wed Sep 26 18:01:01 2007
From: liuwensui at gmail.com (Wensui Liu)
Date: Wed, 26 Sep 2007 12:01:01 -0400
Subject: [R] wordReport
In-Reply-To: <971536df0709260841s248d966ai609881a873a7e402@mail.gmail.com>
References: <20070926141919.M86273@centroin.com.br>
	<971536df0709260841s248d966ai609881a873a7e402@mail.gmail.com>
Message-ID: <1115a2b00709260901jabd81d5jccd58cabaf97f186@mail.gmail.com>

RDCOMClient and rcom are great. but I can't find much manual or
tutorial about them.

On 9/26/07, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> >From R, you can write an XML or HTML document and read it right into Word
> in sufficiently new versions of Word.  Go into Word and save a sample
> Word document in the format of your choice to see what it looks like.
> Filtered HTML is particularly readable. Alternately, the R packages
> RDCOMClient and rcom provide interfaces to Word's COM interface which
> would presumably give you complete access to Word's facilities but would
> be more work to program.
>
> If you are using HTML then formulas would be included as images and
> you can create images of formulas with R's graphic facilities which allows
> the use of nice expressions to denote them.
>
> There is also a latex2rtf program that will allow you to generate rich
> text format files from latex that are readable in Word.
>
> There may be some limitations to these methods so it would be worthwhile
> prototyping anything first.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
===============================
"I am dying with the help of too many
physicians." - Alexander the Great, on his deathbed
===============================
WenSui Liu
(http://spaces.msn.com/statcompute/blog)


From rhelp.stats at gmail.com  Wed Sep 26 18:07:38 2007
From: rhelp.stats at gmail.com (R Help)
Date: Wed, 26 Sep 2007 13:07:38 -0300
Subject: [R] font family 'symbol'
Message-ID: <c84ed6950709260907i568babfboc6e6dcec24cc796@mail.gmail.com>

Hello List,

I'm building a package for R, and I want to use the font family
'symbol', because it seems to be the most consistent of the four font
families that par guarantees.  The problem is that when I tried to run
it on a different machine, I got an X11 error message saying that that
font family was not available.

What I would like to do, therefore, is do a check at the beginning of
the programs to check if the 'symbol' family will work, and use the
default font family if it will not.  I figured I could do it with
either require() or tryCatch() but I can't seem to get either of them
to do it.  If anyone has any idea how to check for the presence of
font families could they please let me know?

#####Sample code
if(HERE IS WHERE THE CHECK FOR 'symbol' WOULD GO){
    fam = 'symbol'
}
else{
    fam = ''
}
par(family=fam)
#####

Thanks,
Sam


From writz at trchome.com  Tue Sep 25 23:02:00 2007
From: writz at trchome.com (Westley Ritz)
Date: Tue, 25 Sep 2007 17:02:00 -0400
Subject: [R] Constraining Predicted Values to be Greater Than 0
Message-ID: <5ecc4200.1c7ffb7.15d210f5.39b3@trchome.com>

I have a WLS regression with 1 dependent variable and 3 independent variables.  I wish to constrain the predicted values (the fitted values) so that they are greater than zero (i.e. they are positive).  I do not know how to impose this constraint in R.  Please respond if you have any suggestions.

There are some previous postings about constraining the coefficients, but this won't accomplish what I am trying to do.  The coefficients can be negative, just as long as the predicted values are positive.

Thank you in advance for your time.

Westley A. Ritz
Analyst
215-641-2243
writz at trchome.com

TRC
www.trchome.com

From ggrothendieck at gmail.com  Wed Sep 26 18:17:11 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 26 Sep 2007 12:17:11 -0400
Subject: [R] wordReport
In-Reply-To: <1115a2b00709260901jabd81d5jccd58cabaf97f186@mail.gmail.com>
References: <20070926141919.M86273@centroin.com.br>
	<971536df0709260841s248d966ai609881a873a7e402@mail.gmail.com>
	<1115a2b00709260901jabd81d5jccd58cabaf97f186@mail.gmail.com>
Message-ID: <971536df0709260917x19eea4c5ka4af297e281515e5@mail.gmail.com>

On 9/26/07, Wensui Liu <liuwensui at gmail.com> wrote:
> RDCOMClient and rcom are great. but I can't find much manual or
> tutorial about them.

They both have home pages that will lead you to whatever
information exists on them:

http://sunsite.univie.ac.at/rcom/

http://www.omegahat.org/RDCOMClient/


From elw at stderr.org  Wed Sep 26 18:21:43 2007
From: elw at stderr.org (elw at stderr.org)
Date: Wed, 26 Sep 2007 11:21:43 -0500 (CDT)
Subject: [R] sprucing up the R homepage
In-Reply-To: <20070926132219.GB318@web15.webfaction.com>
References: <200709260405.l8Q45B3i014618@mail04.syd.optusnet.com.au>
	<Pine.LNX.4.64.0709260632370.9274@illuminati.stderr.org>
	<20070926132219.GB318@web15.webfaction.com>
Message-ID: <Pine.LNX.4.64.0709261120570.18641@illuminati.stderr.org>




> So I applied my corrected margins to Tim's Cairo trick and voila:
> http://www.broad.mit.edu/~finnyk/Rlogo_swiss.png
> This is hands-down the best version, in my opinion!

Yes, it is definitely much nicer than the version on www.r-project.org 
now.  :-)

--e


From stubben at lanl.gov  Wed Sep 26 18:28:56 2007
From: stubben at lanl.gov (Chris Stubben)
Date: Wed, 26 Sep 2007 16:28:56 +0000 (UTC)
Subject: [R] 3d barplot in rgl
References: <EEDF5281-5B15-41B0-ACFF-B775F4990555@lanl.gov>
	<f8e6ff050709251142q309ef7a0vabea299e6464d1a3@mail.gmail.com>
	<loom.20070925T185034-259@post.gmane.org>
	<f8e6ff050709251221j24cc266gabbd3208b6a86887@mail.gmail.com>
	<12891221.post@talk.nabble.com>
Message-ID: <loom.20070926T154622-672@post.gmane.org>

>    Transition matrices are Markov transition matrices among different
> life stages of organisms -- in the simplest case (Leslie matrices,


Ben,

Thanks for your clear explanation and plot examples.  I like the dotplots alot
and added a few modifications below. Since I often compare rows and columns as
well as groups of elements representing growth (lower left trianlge), stasis
(diagonal), fertility etc., I like to preserve the matrix structure in the plot
if possible.


> 
> library(popbio)
> example(teasel)   ## shows 2 plots -- heatmap and stair-step
> A <- tea$sensitivities ##
> z <- as.data.frame.table(A)


#switch labels here- stage at time t in columns and fate at time t+1 in rows
names(z) <- c("To","From","Sensitivity")

# reverse order on rows to match matrix
z$To <- ordered(z$To, levels = rev(levels(z$To)))

dotplot(To~Sensitivity|From, data=z,
scales=list(alternating=c(1,0), tck=c(1,0)), layout=c(6,1), aspect=2)

# or log-scale 
dotplot(To~Sensitivity|From,data=z,scales=list(x=list(log=TRUE)), as.table=TRUE)


Thanks again,

Chris


From bolker at ufl.edu  Wed Sep 26 18:33:15 2007
From: bolker at ufl.edu (bbolker)
Date: Wed, 26 Sep 2007 09:33:15 -0700 (PDT)
Subject: [R] add points to wireframe
In-Reply-To: <20070926133716.23790@gmx.net>
References: <20070926133716.23790@gmx.net>
Message-ID: <12904664.post@talk.nabble.com>




marcg wrote:
> 
> Hello
> 
> with follwing code I want to produce the wireframe and add some points on
> it:
> 
> wireframe(z ~ x * y, data=dem, aspect = c(1, .5),
>           scales = list(arrows = FALSE),
>           panel.3d.wireframe = function(x, y, z,...) {
>               panel.3dwire(x = x, y = y, z = z, ...)
>               panel.3dscatter(x = x,
>                               y = y,
>                               z = z, data=ramm
>                               ...)
>           })
> 
> 

 You're missing a comma after data=ramm   ...
  But even when I fix that, I don't get what you want --
I don't the data argument gets used here.

xy <- expand.grid(1:10,1:10)
names(xy) <- c("x","y")
z <- with(xy,2*x+y)
dem <- data.frame(xy,z)
xy2 <- data.frame(x=runif(8,1,10),y=runif(8,1,10))
z2 <-  with(xy2,rnorm(8,2*x+y,sd=1))
ramm <- data.frame(xy2,z2)

wireframe(z ~ x * y, data=dem, aspect = c(1, .5),
          scales = list(arrows = FALSE),
          panel.3d.wireframe = function(x, y, z,...) {
              panel.3dwire(x = x, y = y, z = z, ...)
              panel.3dscatter(x = x,
                              y = y,
                              z = z,
                              data=ramm,
                              ...)
          })


  Making x, y, z in the panel.3dscatter call into ramm$x, ramm$y, ramm$z
gives an error.
-- 
View this message in context: http://www.nabble.com/add-points-to-wireframe-tf4522433.html#a12904664
Sent from the R help mailing list archive at Nabble.com.


From liuwensui at gmail.com  Wed Sep 26 18:38:14 2007
From: liuwensui at gmail.com (Wensui Liu)
Date: Wed, 26 Sep 2007 12:38:14 -0400
Subject: [R] Constraining Predicted Values to be Greater Than 0
In-Reply-To: <5ecc4200.1c7ffb7.15d210f5.39b3@trchome.com>
References: <5ecc4200.1c7ffb7.15d210f5.39b3@trchome.com>
Message-ID: <1115a2b00709260938ie808d9n8609fefc57ad4f5@mail.gmail.com>

if your regression under gaussian assumption, then you can't
constraint your predicted to be positive.
I don't know much about your dep in the model. but given more
appropriate distribution assumption, the constraint is doable. One
possibility that I can think of is poisson.

On 9/25/07, Westley Ritz <writz at trchome.com> wrote:
> I have a WLS regression with 1 dependent variable and 3 independent variables.  I wish to constrain the predicted values (the fitted values) so that they are greater than zero (i.e. they are positive).  I do not know how to impose this constraint in R.  Please respond if you have any suggestions.
>
> There are some previous postings about constraining the coefficients, but this won't accomplish what I am trying to do.  The coefficients can be negative, just as long as the predicted values are positive.
>
> Thank you in advance for your time.
>
> Westley A. Ritz
> Analyst
> 215-641-2243
> writz at trchome.com
>
> TRC
> www.trchome.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
===============================
"I am dying with the help of too many
physicians." - Alexander the Great, on his deathbed
===============================
WenSui Liu
(http://spaces.msn.com/statcompute/blog)


From f.harrell at vanderbilt.edu  Wed Sep 26 19:02:43 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Wed, 26 Sep 2007 12:02:43 -0500
Subject: [R] using transcan for imputation, categorical variable
In-Reply-To: <A954B571D12ECE4A94DD2016E34F3031026C3190@exch1.ad.maastro.nl>
References: <A954B571D12ECE4A94DD2016E34F3031026C3190@exch1.ad.maastro.nl>
Message-ID: <46FA90B3.2040507@vanderbilt.edu>

Cary Dehing-Oberije wrote:
> Dear all,
> 
> I am using transcan to impute missing values (single imputation). I have
> several dichotomous variables in my dataset, but when I try to impute
> the missings sometimes values are imputed that were originally not in
> the dataset. So, a variable with 2 values (severe weight loss or
> no/limited weight loss) for example coded 0 and 1, shows 3 different
> values after imputation (0, 1 and 2).
> 
> I have tried two options:
> 
> impfile <- transcan (~age + factor(dumgend) +factor(dumcomorb25_i) +
> factor(dumwght) + factor(dumsmok)
> I(lngtvextra) + eqd2t_i + factor(chemo)+ factor(stage),data=surv.df,
> imputed=TRUE )
> 
> and this one (with categorical="dumwght")
> 
> impfile <- transcan (~age + factor(dumgend) +factor(dumcomorb25_i) +
> factor(dumwght) + factor(dumsmok)
> I(lngtvextra) + eqd2t_i + factor(chemo) + factor(stage),data=surv.df,
> categorical=("dumwght"), imputed=TRUE )
> 
> Have can I handle this problem?
> 
> Thanks for your help.
> 
> Cary

When a variable is a factor, transcan only imputes actual values. 
Please create a tiny example replicating your problem using simulated 
data, and I'll take a further look.

Frank

> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From ripley at stats.ox.ac.uk  Wed Sep 26 19:13:07 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 26 Sep 2007 18:13:07 +0100 (BST)
Subject: [R] Constraining Predicted Values to be Greater Than 0
In-Reply-To: <1115a2b00709260938ie808d9n8609fefc57ad4f5@mail.gmail.com>
References: <5ecc4200.1c7ffb7.15d210f5.39b3@trchome.com>
	<1115a2b00709260938ie808d9n8609fefc57ad4f5@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709261752190.4118@gannet.stats.ox.ac.uk>

You seem to be assuming that 'regression' has to do with 'gaussian 
assumption'.  However, I presume WLS stands for 'weighted least squares', 
and 'regression' is historically associated with fitting linear models by 
least squares.

I don't see why even in the model-based framework you assert that 
Westley cannot impose any constraints he wants on the *means*: the 
positivity constraint is on the means and not on the observations.  E.g. 
in chemistry it is reasonable to assume that concentrations are 
non-negative, but indirectly measured values need not be.  Note though 
that it is more usual to require that all predictions (at new points as 
well as data points) would be non-negative, which typically does reduce to 
constraints on the coefficients.

As to how to do this, a WLS problem with inequality constraints on the 
fitted values is a linearly-constrained quadratic programme.  So one 
avenue is to use solve.QP in package quadprog.  If you have a large 
problem you can make use of the necessary redundancy of the constraints: 
e.g. if the predictions at the convex hull of the data points are 
non-negative, they all are.


On Wed, 26 Sep 2007, Wensui Liu wrote:

> if your regression under gaussian assumption, then you can't
> constraint your predicted to be positive.
> I don't know much about your dep in the model. but given more
> appropriate distribution assumption, the constraint is doable. One
> possibility that I can think of is poisson.
>
> On 9/25/07, Westley Ritz <writz at trchome.com> wrote:
>> I have a WLS regression with 1 dependent variable and 3 independent 
>> variables.  I wish to constrain the predicted values (the fitted 
>> values) so that they are greater than zero (i.e. they are positive). 
>> I do not know how to impose this constraint in R.  Please respond if 
>> you have any suggestions.
>>
>> There are some previous postings about constraining the coefficients, 
>> but this won't accomplish what I am trying to do.  The coefficients can 
>> be negative, just as long as the predicted values are positive.
>>
>> Thank you in advance for your time.
>>
>> Westley A. Ritz
>> Analyst
>> 215-641-2243
>> writz at trchome.com
>>
>> TRC
>> www.trchome.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Sep 26 19:19:39 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 26 Sep 2007 18:19:39 +0100 (BST)
Subject: [R] rpart error: "Error in dimnames(X)"
In-Reply-To: <d81d28610709260843y41af612dg2a57c4eca6f95eee@mail.gmail.com>
References: <d81d28610709260843y41af612dg2a57c4eca6f95eee@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709261716010.3090@gannet.stats.ox.ac.uk>

On Wed, 26 Sep 2007, Juned Siddique wrote:

> I'm using rpart to fit a tree using a large dataset: 7000 observations, 4651
> variables. All but one of the variables (age) are binary. When I run the
> code:
>
> fit1 <- rpart(lowergi ~ ., data=dset,method="class")
>
> I get the error:
>
>
> Error in dimnames(X) <-list(dn[1L]], unlist(collabs, use.names=FALSE)) :
> Length of `dimnames' [2] not equal to array extent
>
> I have no idea what this error means or what is causing the problem. I'm
> wondering if my dataset is too big, or if there is a problem with how the
> data are set up. Any help would be appreciated.

Well, we would appreciate help from you, so please read the footer to this 
message.  All I can tell you is that the error message did not come from 
rpart, but most likely from as.matrix.data.frame (which does contain that 
code line, unlike rpart)

The output of traceback() would have been helpful.  The `Writing R 
Extensions' manual shows you how to debug a problem like this.

My best guess is that at least one of those 4651 columns are not suitable 
input to rpart.

>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gerifalte28 at hotmail.com  Wed Sep 26 19:24:52 2007
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Wed, 26 Sep 2007 11:24:52 -0600
Subject: [R] Scientific Notation
In-Reply-To: <46FA7C5C.6080607@stats.uwo.ca>
References: <787911d50709260824n61f7aa4cr673b8a0bb64418f7@mail.gmail.com>
	<46FA7C5C.6080607@stats.uwo.ca>
Message-ID: <46FA95E4.3000004@hotmail.com>

I believe the argument to format is "scientific" i.e.
axis(2, at=at, labels=format(at, scientific=FALSE))

Best regards,

Francisco

Duncan Murdoch wrote:
> On 9/26/2007 11:24 AM, Jacques Wagnor wrote:
>> Dear List:
>>
>> Below is how I specify an axis:
>>
>> axis(2, at=c(0.00005, 0.0005))
>>
>> R displays the numbers in scientific notation.  What
>> argument/parameter should I use to tell R to display the numbers as
>> specified rather than in scientific notation?
> 
> Something like
> 
> axis(2, at=c(0.00005, 0.0005), labels=c("0.00005", "0.0005"))
> 
> is a way to be 100% sure of what will be displayed, but in this 
> particular instance,
> 
> at <- c(0.00005, 0.0005)
> axis(2, at=at, labels=format(at, sci=FALSE))
> 
> comes close, and there may be some other format spec that gets exactly 
> what you want.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gerifalte28 at hotmail.com  Wed Sep 26 19:24:52 2007
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Wed, 26 Sep 2007 11:24:52 -0600
Subject: [R] Scientific Notation
In-Reply-To: <46FA7C5C.6080607@stats.uwo.ca>
References: <787911d50709260824n61f7aa4cr673b8a0bb64418f7@mail.gmail.com>
	<46FA7C5C.6080607@stats.uwo.ca>
Message-ID: <46FA95E4.3000004@hotmail.com>

I believe the argument to format is "scientific" i.e.
axis(2, at=at, labels=format(at, scientific=FALSE))

Best regards,

Francisco

Duncan Murdoch wrote:
> On 9/26/2007 11:24 AM, Jacques Wagnor wrote:
>> Dear List:
>>
>> Below is how I specify an axis:
>>
>> axis(2, at=c(0.00005, 0.0005))
>>
>> R displays the numbers in scientific notation.  What
>> argument/parameter should I use to tell R to display the numbers as
>> specified rather than in scientific notation?
> 
> Something like
> 
> axis(2, at=c(0.00005, 0.0005), labels=c("0.00005", "0.0005"))
> 
> is a way to be 100% sure of what will be displayed, but in this 
> particular instance,
> 
> at <- c(0.00005, 0.0005)
> axis(2, at=at, labels=format(at, sci=FALSE))
> 
> comes close, and there may be some other format spec that gets exactly 
> what you want.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From olenka.m at gmail.com  Wed Sep 26 19:46:17 2007
From: olenka.m at gmail.com (Olena Morozova)
Date: Wed, 26 Sep 2007 10:46:17 -0700
Subject: [R] plot rows of matrix against a vector on one graph
Message-ID: <259a224c0709261046s37e9d076xcb2b709d3083188a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070926/afbca0c0/attachment.pl 

From wtimm at techfak.uni-bielefeld.de  Wed Sep 26 20:03:47 2007
From: wtimm at techfak.uni-bielefeld.de (Wiebke Timm)
Date: Wed, 26 Sep 2007 14:03:47 -0400
Subject: [R] plot rows of matrix against a vector on one graph
In-Reply-To: <259a224c0709261046s37e9d076xcb2b709d3083188a@mail.gmail.com>
References: <259a224c0709261046s37e9d076xcb2b709d3083188a@mail.gmail.com>
Message-ID: <5A15AB39-6B5B-4C82-B312-B27A24A17DF1@techfak.uni-bielefeld.de>

On 26.09.2007, at 13:46, Olena Morozova wrote:

> I am very new to R and statistical analysis in general. I am trying  
> to plot
> a matrix of several hundred rows against a vector of 4 values. This  
> all has
> to be on the same graph with different rows represented by  
> different color.
> This sounds like it should not be hard to do, but I am having  
> problems with
> it. Could someone please help?
>

In fact this sounds hard to me, because you cannot perceive "several  
hundred" different colors in the same plot. :)

Did you mean columns instead of rows?

Maybe you could specify a little more what kind of plot you intend.  
How does your data look like? Do you intend to plot each of the  
several hundred values against the same vector with 4 values or do  
you have a several hundred by 4 matrix?

Without knowing these thing it is difficult to help you.

Regards,
    Wiebke


From writz at trchome.com  Wed Sep 26 20:21:00 2007
From: writz at trchome.com (Westley Ritz)
Date: Wed, 26 Sep 2007 14:21:00 -0400
Subject: [R] Constraining Predicted Values to be Greater Than 0
Message-ID: <1ea99500.1c8006a.1a6584ce.6d96@trchome.com>

Thank you Wensui and Professor Ripley for your responses.

Prof. Ripley, your assumptions regarding the context in which I'm using 'WLS' and 'regression' are correct.  The function solve.QP in the quadprog package sounds like a great way to go.  Thank you, and I will try this method.

Westley A. Ritz
Analyst
215-641-2243
writz at trchome.com

TRC
www.trchome.com


-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: Wednesday, September 26, 2007 1:13 PM
To: Wensui Liu
Cc: Westley Ritz; r-help at r-project.org
Subject: Re: [R] Constraining Predicted Values to be Greater Than 0


You seem to be assuming that 'regression' has to do with 'gaussian 
assumption'.  However, I presume WLS stands for 'weighted least squares', 
and 'regression' is historically associated with fitting linear models by 
least squares.

I don't see why even in the model-based framework you assert that 
Westley cannot impose any constraints he wants on the *means*: the 
positivity constraint is on the means and not on the observations.  E.g. 
in chemistry it is reasonable to assume that concentrations are 
non-negative, but indirectly measured values need not be.  Note though 
that it is more usual to require that all predictions (at new points as 
well as data points) would be non-negative, which typically does reduce to 
constraints on the coefficients.

As to how to do this, a WLS problem with inequality constraints on the 
fitted values is a linearly-constrained quadratic programme.  So one 
avenue is to use solve.QP in package quadprog.  If you have a large 
problem you can make use of the necessary redundancy of the constraints: 
e.g. if the predictions at the convex hull of the data points are 
non-negative, they all are.


On Wed, 26 Sep 2007, Wensui Liu wrote:

> if your regression under gaussian assumption, then you can't
> constraint your predicted to be positive.
> I don't know much about your dep in the model. but given more
> appropriate distribution assumption, the constraint is doable. One
> possibility that I can think of is poisson.
>
> On 9/25/07, Westley Ritz <writz at trchome.com> wrote:
>> I have a WLS regression with 1 dependent variable and 3 independent 
>> variables.  I wish to constrain the predicted values (the fitted 
>> values) so that they are greater than zero (i.e. they are positive). 
>> I do not know how to impose this constraint in R.  Please respond if 
>> you have any suggestions.
>>
>> There are some previous postings about constraining the coefficients, 
>> but this won't accomplish what I am trying to do.  The coefficients can 
>> be negative, just as long as the predicted values are positive.
>>
>> Thank you in advance for your time.
>>
>> Westley A. Ritz
>> Analyst
>> 215-641-2243
>> writz at trchome.com
>>
>> TRC
>> www.trchome.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Eric.Archer at noaa.gov  Wed Sep 26 20:42:52 2007
From: Eric.Archer at noaa.gov (Eric Archer)
Date: Wed, 26 Sep 2007 11:42:52 -0700
Subject: [R] Area of overlap between polygon and circle
Message-ID: <46FAA82C.6000005@noaa.gov>

R-listers,

Given a polygon and a circle defined by its center coordinates and a 
radius, I would like to calculate the area of overlap.  I know that I 
can create a polygon from the circle and then use available packages to 
get the area of the intersection.  However, because the polygon is of a 
fixed size and I will be doing this for circles of varying sizes, I'm 
concerned about maintaining the appropriate amount of resolution with 
larger circles.   If there was already a package that did the above 
calculation without the creation of a circle polygon and would thus give 
an exact area, that would be preferred.  I have searched the archives 
and have not found a solution to this particular problem.  Thanks!

Cheers,
eric

-- 

Eric Archer, Ph.D.
NOAA-SWFSC
8604 La Jolla Shores Dr.
La Jolla, CA 92037
858-546-7121,7003(FAX)
eric.archer at noaa.gov
http://swfsc.noaa.gov/prd-etp.aspx

"Innocence about Science is the worst crime today."
   - Sir Charles Percy Snow


"Lighthouses are more helpful than churches."
   - Benjamin Franklin

   "...but I'll take a GPS over either one."
       - John C. "Craig" George 



From r.j.forsyth at newcastle.ac.uk  Wed Sep 26 21:06:52 2007
From: r.j.forsyth at newcastle.ac.uk (Rob Forsyth)
Date: Wed, 26 Sep 2007 22:06:52 +0300
Subject: [R] Accessing the fixed- and random-effects variance-covariance
	matrices of an nlme model
Message-ID: <D1DB07A2-02F2-403D-8E63-9C71B4188DCB@newcastle.ac.uk>

I would appreciate confirmation that the function vcov(model.nlme)  
gives the var-cov matrix of the fixed effects in an nlme model.  
Presumably the random-effects var-cov matrix is given by cov(ranef 
(model.nlme)?

Rob Forsyth


From junedsiddique at gmail.com  Wed Sep 26 21:20:16 2007
From: junedsiddique at gmail.com (Juned Siddique)
Date: Wed, 26 Sep 2007 14:20:16 -0500
Subject: [R] rpart error: "Error in dimnames(X)"
In-Reply-To: <Pine.LNX.4.64.0709261716010.3090@gannet.stats.ox.ac.uk>
References: <d81d28610709260843y41af612dg2a57c4eca6f95eee@mail.gmail.com>
	<Pine.LNX.4.64.0709261716010.3090@gannet.stats.ox.ac.uk>
Message-ID: <d81d28610709261220o29c87e2eica916eb91d70ba8d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070926/dbf176aa/attachment.pl 

From jholtman at gmail.com  Wed Sep 26 21:52:44 2007
From: jholtman at gmail.com (jim holtman)
Date: Wed, 26 Sep 2007 15:52:44 -0400
Subject: [R] date
In-Reply-To: <438391.68524.qm@web45306.mail.sp1.yahoo.com>
References: <438391.68524.qm@web45306.mail.sp1.yahoo.com>
Message-ID: <644e1f320709261252q665be7e9jf4391cfdac7de982@mail.gmail.com>

What is the error message?  What does 'str(MyData)' show?  I read your
data in and it worked fine.

> x <- read.table(textConnection("  name value      times
+ 1   A1     2 2006-05-12
+ 2   A2     3 2006-05-16
+ 3   A3     1 2006-05-12
+ 4   A4     4 2006-05-12
+ 5   A5     2 2006-05-16
+ 6   A6     1 2006-05-12"), header=TRUE)
> str(x)
'data.frame':   6 obs. of  3 variables:
 $ name : Factor w/ 6 levels "A1","A2","A3",..: 1 2 3 4 5 6
 $ value: int  2 3 1 4 2 1
 $ times: Factor w/ 2 levels "2006-05-12","2006-05-16": 1 2 1 1 2 1
> x$times <- as.POSIXct(as.character(x$times))
> str(x)
'data.frame':   6 obs. of  3 variables:
 $ name : Factor w/ 6 levels "A1","A2","A3",..: 1 2 3 4 5 6
 $ value: int  2 3 1 4 2 1
 $ times:'POSIXct', format: chr  "2006-05-12" "2006-05-16"
"2006-05-12" "2006-05-12" ...
> plot(x$times, x$value)  # works fine


On 9/26/07, Samuel Okoye <samuoko at yahoo.com> wrote:
> Hello,
>
>  I have got the following problem:
>
>  > setwd("C:/temp")
> >  library(xlsReadWrite)
> >  MyData <- read.xls(file="Mappe1.xls", colNames = TRUE,dateTimeAs = "isodatetime")
> >  attach(MyData)
> >  MyData
>  name value      times
> 1   A1     2 2006-05-12
> 2   A2     3 2006-05-16
> 3   A3     1 2006-05-12
> 4   A4     4 2006-05-12
> 5   A5     2 2006-05-16
> 6   A6     1 2006-05-12
> > plot(times,value)
> Error........
>
>  Could you help me please?
>
>  Thanks alot,
>  Samuel
>
>
> ---------------------------------
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From macq at llnl.gov  Wed Sep 26 21:52:49 2007
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 26 Sep 2007 12:52:49 -0700
Subject: [R] date
In-Reply-To: <438391.68524.qm@web45306.mail.sp1.yahoo.com>
References: <438391.68524.qm@web45306.mail.sp1.yahoo.com>
Message-ID: <p06230905c32068486f52@[128.115.153.6]>


At 7:25 AM -0700 9/26/07, Samuel Okoye wrote:
>Hello,
>   
>   I have got the following problem:
>   
>   > setwd("C:/temp")
>>   library(xlsReadWrite)
>>   MyData <- read.xls(file="Mappe1.xls", colNames = TRUE,dateTimeAs 
>>= "isodatetime")
>>   attach(MyData)
>>   MyData
>   name value      times
>1   A1     2 2006-05-12
>2   A2     3 2006-05-16
>3   A3     1 2006-05-12
>4   A4     4 2006-05-12
>5   A5     2 2006-05-16
>6   A6     1 2006-05-12
>>  plot(times,value)
>Error........
>   
>   Could you help me please?
>

Not without more information.

(for example, the full text of the error message; you should also use 
traceback(), verify that MyData$times has the class you expected, 
ditto for MyData$value)

Please take a look at the posting guide.

>   Thanks alot,
>   Samuel
>
>       
>---------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-Don
-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
925-423-1062


From duncan at wald.ucdavis.edu  Wed Sep 26 21:57:05 2007
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Thu, 27 Sep 2007 07:57:05 +1200
Subject: [R] wordReport
In-Reply-To: <20070926141919.M86273@centroin.com.br>
References: <20070926141919.M86273@centroin.com.br>
Message-ID: <46FAB991.4090504@wald.ucdavis.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



Alberto Monteiro wrote:
> ?wordReport gives a lot of information, but I think it makes us wish for 
> more :-)
> 
> Where can I find all the ways to write Word documents using R? 
> 

Using either of the R/DCOM client packages (rcom and RDCOMClient)
you can access all the exposed functionality of Word to control
it and so create rich documents.  The number of classes and functions
is large, so it can take a little time to figure out what is available
but it is quite flexible.

wordReport appears to use Visual Basic commands to get the same
effect.  So if you don't mind going through an additional
"language", you could extend that to know provide access to more
of the same functionality that you get directly with the R/DCOM
connections.

One could also create the document in XML, either directly to
Word's XML format or to a different format and then transform it
with, e.g., XSL or other XML-capable tools (including R).


That's some of the ways.


> Namely:
> 
> (1) is there any way to open a new document and save it automatically?
> The sequence:
> 
> WordOpen("new_file.doc"); WordInsertText("R rulez!\n"); WordExit()
> 
> will prompt for the Yes/No/Cancel prompt, and if I answer "Yes", it opens 
> the menu to "Save As".
> 
> (2) is there any way to write formulas in the evil Word formula format, but 
> with input as decent latex-like format?
> 
> Alberto Monteiro
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.7 (Darwin)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFG+rmQ9p/Jzwa2QP4RAgZKAJ4+W4wHEQspWYNLSIwvj0b26MSe8QCfdvE4
vb8YCnFaT5a4NPbfsfQ81BU=
=04Pr
-----END PGP SIGNATURE-----


From ripley at stats.ox.ac.uk  Wed Sep 26 22:12:14 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 26 Sep 2007 21:12:14 +0100 (BST)
Subject: [R] Scientific Notation
In-Reply-To: <46FA95E4.3000004@hotmail.com>
References: <787911d50709260824n61f7aa4cr673b8a0bb64418f7@mail.gmail.com>
	<46FA7C5C.6080607@stats.uwo.ca> <46FA95E4.3000004@hotmail.com>
Message-ID: <Pine.LNX.4.64.0709261847140.5511@gannet.stats.ox.ac.uk>

On Wed, 26 Sep 2007, Francisco J. Zagmutt wrote:

> I believe the argument to format is "scientific" i.e.
> axis(2, at=at, labels=format(at, scientific=FALSE))

Yes, but abbreviations of argument names are allowed.

Here setting a small positive value of options(scipen) (e.g. 2) gives 
floating-point notation as in

> at <- c(0.00005, 0.0005)
> options(scipen=2)
> as.character(at)
[1] "0.00005" "0.0005"
> axis(2, at=at, labels=as.character(at))

would do the job (and in many similar cases).

>
> Best regards,
>
> Francisco
>
> Duncan Murdoch wrote:
>> On 9/26/2007 11:24 AM, Jacques Wagnor wrote:
>>> Dear List:
>>>
>>> Below is how I specify an axis:
>>>
>>> axis(2, at=c(0.00005, 0.0005))
>>>
>>> R displays the numbers in scientific notation.  What
>>> argument/parameter should I use to tell R to display the numbers as
>>> specified rather than in scientific notation?
>>
>> Something like
>>
>> axis(2, at=c(0.00005, 0.0005), labels=c("0.00005", "0.0005"))
>>
>> is a way to be 100% sure of what will be displayed, but in this
>> particular instance,
>>
>> at <- c(0.00005, 0.0005)
>> axis(2, at=at, labels=format(at, sci=FALSE))
>>
>> comes close, and there may be some other format spec that gets exactly
>> what you want.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jacques.wagnor at gmail.com  Wed Sep 26 22:18:32 2007
From: jacques.wagnor at gmail.com (Jacques Wagnor)
Date: Wed, 26 Sep 2007 15:18:32 -0500
Subject: [R] Password-protect script files
Message-ID: <787911d50709261318y5830d09dr8857e9614d9cdca@mail.gmail.com>

Dear List,

Is there any way to password-protect script files (either within R or
otherwise)?


platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          5.1
year           2007
month          06
day            27
svn rev        42083
language       R
version.string R version 2.5.1 (2007-06-27)


From bkelcey at umich.edu  Wed Sep 26 22:24:57 2007
From: bkelcey at umich.edu (bkelcey at umich.edu)
Date: Wed, 26 Sep 2007 16:24:57 -0400
Subject: [R] generate fourth vector based on known correlations
Message-ID: <20070926162457.0j5evo5fqcoswwoo@web.mail.umich.edu>



I am trying to generate a fourth vector,z, given three known and fixed 
vectors, x1,x2,x3 with corresponding known and fixed correlations with 
themeselves and with z. That is, all correlations are known and 
prespecified. How can I do this?
Thank you,
ben


From matt.dubins at utoronto.ca  Wed Sep 26 22:56:38 2007
From: matt.dubins at utoronto.ca (Matthew Dubins)
Date: Wed, 26 Sep 2007 16:56:38 -0400
Subject: [R] Getting group-wise standard scores of a vector
Message-ID: <46FAC786.1070708@utoronto.ca>

Hi,

I want to be able to create a vector of z-scores from a vector of 
continuous data, conditional on a group membership vector.

Say you have 20 numbers distributed normally with a mean of 50 and an sd 
of 10:

x <- rnorm(20, 50, 10)


Then you have a vector that delineates 2 groups within x:

group <- sort(rep(c("A", "B"), 10))

test.data <- data.frame(cbind(x, group))

I know that if you break up the x vector into 2 different vectors then 
it becomes easy to calculate the z scores for each vector, then you 
stack them and append them to the original
data frame.  Is there anyway to apply this sort of calculation without 
splitting the original vector up?  I tried a really complex ifelse 
statement but it didn't seem to work.

Thanks in advance,
Matthew Dubins


From albmont at centroin.com.br  Wed Sep 26 22:57:20 2007
From: albmont at centroin.com.br (Alberto Monteiro)
Date: Wed, 26 Sep 2007 18:57:20 -0200
Subject: [R] wordReport
In-Reply-To: <46FAB991.4090504@wald.ucdavis.edu>
References: <20070926141919.M86273@centroin.com.br>
	<46FAB991.4090504@wald.ucdavis.edu>
Message-ID: <20070926205410.M62503@centroin.com.br>

Duncan Temple Lang wrote:
>
>> ?wordReport gives a lot of information, but I think it makes
>> us wish for more :-)
>> 
>> Where can I find all the ways to write Word documents using R? 
>
> (... alternative methods deleted ...)
> 
> One could also create the document in XML, either directly to
> Word's XML format or to a different format and then transform it
> with, e.g., XSL or other XML-capable tools (including R).
> 
There are some R tools that convert formulas to images or LaTeX
[I think], but are there R tools that convert formulas to
a XML that can be correctly interpreted by MS-Word?

Alberto Monteiro


From marc_schwartz at comcast.net  Wed Sep 26 23:00:44 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Wed, 26 Sep 2007 16:00:44 -0500
Subject: [R] Password-protect script files
In-Reply-To: <787911d50709261318y5830d09dr8857e9614d9cdca@mail.gmail.com>
References: <787911d50709261318y5830d09dr8857e9614d9cdca@mail.gmail.com>
Message-ID: <1190840444.11720.10.camel@Bellerophon.localdomain>

On Wed, 2007-09-26 at 15:18 -0500, Jacques Wagnor wrote:
> Dear List,
> 
> Is there any way to password-protect script files (either within R or
> otherwise)?

You might want to review this thread:

  http://thread.gmane.org/gmane.comp.lang.r.general/94290/

which covers perhaps a similar concern.

You can ignore my first reply, which covers protecting all files by
encrypting an entire partition, not just the R code file.

If that is not helpful, we will need to gain further insight into your
functional requirements.

HTH,

Marc Schwartz


From Greg.Snow at intermountainmail.org  Wed Sep 26 23:10:41 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 26 Sep 2007 15:10:41 -0600
Subject: [R] generate fourth vector based on known correlations
In-Reply-To: <20070926162457.0j5evo5fqcoswwoo@web.mail.umich.edu>
References: <20070926162457.0j5evo5fqcoswwoo@web.mail.umich.edu>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBC38C15@LP-EXCHVS07.CO.IHC.COM>

Here is one approach (someone with better linear algebra skills may be
able to shorten this, some steps could be combined, but I wanted to show
each step):


# create x1-x3

x1 <- rnorm(100, 50, 3)
x2 <- rnorm(100) + x1/5
x3 <- rnorm(100) + x2/5

# find current correlations

cor1 <- cor( cbind(x1,x2,x3) )
cor1

# create 1st version of z

z <- rnorm(100)

# combine in a matrix

m1 <- cbind( x1, x2, x3, z )

# center and scale

m2 <- scale(m1)

# find cholesky decomp

c1 <- chol(var(m2))

# force to be independent

m3 <- m2 %*% solve(c1)

zapsmall(cor(m3)) # check

# create new correlation matrix:

cor2 <- cbind( rbind( cor1, z=c(.5,.3,.1) ), z=c(.5,.3,.1,1) )

# create new matrix

m4 <- m3 %*% chol(cor2)

# uncenter and unscale

m5 <- sweep( m4, 2, attr(m2, 'scaled:scale'), '*')
m5 <- sweep( m5, 2, attr(m2, 'scaled:center'), '+')

# check to see if we succeeded

all.equal( cbind(x1,x2,x3), m5[, 1:3] )
all.equal( cor(m5)[1:3,1:3], cor1 )
all.equal( cor(m5), cor2 )

cor(m5)

 
Hope this helps,


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of bkelcey at umich.edu
> Sent: Wednesday, September 26, 2007 2:25 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] generate fourth vector based on known correlations
> 
> 
> 
> I am trying to generate a fourth vector,z, given three known 
> and fixed vectors, x1,x2,x3 with corresponding known and 
> fixed correlations with themeselves and with z. That is, all 
> correlations are known and prespecified. How can I do this?
> Thank you,
> ben
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From Cody_Hamilton at Edwards.com  Wed Sep 26 23:14:37 2007
From: Cody_Hamilton at Edwards.com (Cody Hamilton)
Date: Wed, 26 Sep 2007 14:14:37 -0700
Subject: [R] Repeated tests against baseline
Message-ID: <4C7D0185E1C6D64AAFB18A2281B262B80675BD4573@EXIRV01.am.edwards.lcl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070926/de16a566/attachment.pl 

From iverson at biostat.wisc.edu  Wed Sep 26 23:27:25 2007
From: iverson at biostat.wisc.edu (Erik Iverson)
Date: Wed, 26 Sep 2007 16:27:25 -0500
Subject: [R] Getting group-wise standard scores of a vector
In-Reply-To: <46FAC786.1070708@utoronto.ca>
References: <46FAC786.1070708@utoronto.ca>
Message-ID: <46FACEBD.3050403@biostat.wisc.edu>

Hello -

First, I doubt you really want to cbind() those two vectors within the 
data.frame() function call.

test.data <- data.frame(x, group)  is probably what you want.  That may 
be the source of your trouble.

If you really want a vector returned, the following should work given 
your test.data is constructed without the cbind():

unlist(by(test.data$x, test.data$group, function(x) (x - mean(x)) / 
sd(x)), use.names = FALSE)

Is that what you're after?

Erik


Matthew Dubins wrote:
> Hi,
> 
> I want to be able to create a vector of z-scores from a vector of 
> continuous data, conditional on a group membership vector.
> 
> Say you have 20 numbers distributed normally with a mean of 50 and an sd 
> of 10:
> 
> x <- rnorm(20, 50, 10)
> 
> 
> Then you have a vector that delineates 2 groups within x:
> 
> group <- sort(rep(c("A", "B"), 10))
> 
> test.data <- data.frame(cbind(x, group))
> 
> I know that if you break up the x vector into 2 different vectors then 
> it becomes easy to calculate the z scores for each vector, then you 
> stack them and append them to the original
> data frame.  Is there anyway to apply this sort of calculation without 
> splitting the original vector up?  I tried a really complex ifelse 
> statement but it didn't seem to work.
> 
> Thanks in advance,
> Matthew Dubins
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From matt.dubins at utoronto.ca  Thu Sep 27 00:01:00 2007
From: matt.dubins at utoronto.ca (Matthew Dubins)
Date: Wed, 26 Sep 2007 18:01:00 -0400
Subject: [R] Getting group-wise standard scores of a vector
In-Reply-To: <46FACEBD.3050403@biostat.wisc.edu>
References: <46FAC786.1070708@utoronto.ca> <46FACEBD.3050403@biostat.wisc.edu>
Message-ID: <46FAD69C.8010909@utoronto.ca>

Hi,

Thanks so much!  I got what I needed:  z scores, according to group 
membership, in one vector.

Matthew Dubins

Erik Iverson wrote:
> Hello -
>
> First, I doubt you really want to cbind() those two vectors within the 
> data.frame() function call.
>
> test.data <- data.frame(x, group)  is probably what you want.  That 
> may be the source of your trouble.
>
> If you really want a vector returned, the following should work given 
> your test.data is constructed without the cbind():
>
> unlist(by(test.data$x, test.data$group, function(x) (x - mean(x)) / 
> sd(x)), use.names = FALSE)
>
> Is that what you're after?
>
> Erik
>
>
> Matthew Dubins wrote:
>> Hi,
>>
>> I want to be able to create a vector of z-scores from a vector of 
>> continuous data, conditional on a group membership vector.
>>
>> Say you have 20 numbers distributed normally with a mean of 50 and an 
>> sd of 10:
>>
>> x <- rnorm(20, 50, 10)
>>
>>
>> Then you have a vector that delineates 2 groups within x:
>>
>> group <- sort(rep(c("A", "B"), 10))
>>
>> test.data <- data.frame(cbind(x, group))
>>
>> I know that if you break up the x vector into 2 different vectors 
>> then it becomes easy to calculate the z scores for each vector, then 
>> you stack them and append them to the original
>> data frame.  Is there anyway to apply this sort of calculation 
>> without splitting the original vector up?  I tried a really complex 
>> ifelse statement but it didn't seem to work.
>>
>> Thanks in advance,
>> Matthew Dubins
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From Greg.Snow at intermountainmail.org  Thu Sep 27 00:24:09 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Wed, 26 Sep 2007 16:24:09 -0600
Subject: [R] Repeated tests against baseline
In-Reply-To: <4C7D0185E1C6D64AAFB18A2281B262B80675BD4573@EXIRV01.am.edwards.lcl>
References: <4C7D0185E1C6D64AAFB18A2281B262B80675BD4573@EXIRV01.am.edwards.lcl>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBC38C55@LP-EXCHVS07.CO.IHC.COM>

Here are a couple to look at, they may be helpful and the references in
them may give you a specific example that you can use (read them through
yourself, then decide if you want your docs to read them).

Kenneth F Schulz and David A Grimes (2005), "Multiplicity in randomised
trials I: endpoints and treatments", The Lancet, 365: 1591-95

Kenneth F Schulz and David A Grimes (2005), "Multiplicity in randomised
trials II: subgroup and interim analyses", The Lancet, 365: 1657-61


Hope this helps,


-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Cody Hamilton
> Sent: Wednesday, September 26, 2007 3:15 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Repeated tests against baseline
> 
> I came across a post by Karl Knoblick regarding the modeling 
> of longitudinal data (see 
> https://stat.ethz.ch/pipermail/r-help/2007-May/132137.html).  
> I am often asked by physicians to perform what Karl refers to 
> in his post as option 1: to perform paired t-tests against 
> baseline at each follow up time point (30 days, 90 days, 6 
> months, etc.).  Unlike Karl's example, however, many of the 
> trials I am involved in are one-armed (so there are no 
> across-trial-arms comparisons).
> 
> No matter how hard I try to explain to physicians why this 
> approach is not the best, it has typically been to no avail.  
> I am wondering if anyone knows of a paper I can quote 
> instead?  One (or more) from the cardiovascular literature 
> would be especially precious to me.
> 
> Best regards,
>    -Cody Hamilton
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From Cody_Hamilton at Edwards.com  Thu Sep 27 01:05:47 2007
From: Cody_Hamilton at Edwards.com (Cody Hamilton)
Date: Wed, 26 Sep 2007 16:05:47 -0700
Subject: [R] Repeated tests against baseline
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBC38C55@LP-EXCHVS07.CO.IHC.COM>
References: <4C7D0185E1C6D64AAFB18A2281B262B80675BD4573@EXIRV01.am.edwards.lcl>
	<07E228A5BE53C24CAD490193A7381BBBC38C55@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <4C7D0185E1C6D64AAFB18A2281B262B806760440ED@EXIRV01.am.edwards.lcl>

Thank you Greg - I will read these carefully.  Lancet should carry great weight with the clinical audience.

Do you know of any references that address the fact that the paired differences at 30 days, 60 days, etc. are typically correlated?

Regards,
   -Cody

-----Original Message-----
From: Greg Snow [mailto:Greg.Snow at intermountainmail.org]
Sent: Wednesday, September 26, 2007 3:24 PM
To: Cody Hamilton; r-help at stat.math.ethz.ch
Subject: RE: [R] Repeated tests against baseline

Here are a couple to look at, they may be helpful and the references in
them may give you a specific example that you can use (read them through
yourself, then decide if you want your docs to read them).

Kenneth F Schulz and David A Grimes (2005), "Multiplicity in randomised
trials I: endpoints and treatments", The Lancet, 365: 1591-95

Kenneth F Schulz and David A Grimes (2005), "Multiplicity in randomised
trials II: subgroup and interim analyses", The Lancet, 365: 1657-61


Hope this helps,


--
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111



> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of Cody Hamilton
> Sent: Wednesday, September 26, 2007 3:15 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Repeated tests against baseline
>
> I came across a post by Karl Knoblick regarding the modeling
> of longitudinal data (see
> https://stat.ethz.ch/pipermail/r-help/2007-May/132137.html).
> I am often asked by physicians to perform what Karl refers to
> in his post as option 1: to perform paired t-tests against
> baseline at each follow up time point (30 days, 90 days, 6
> months, etc.).  Unlike Karl's example, however, many of the
> trials I am involved in are one-armed (so there are no
> across-trial-arms comparisons).
>
> No matter how hard I try to explain to physicians why this
> approach is not the best, it has typically been to no avail.
> I am wondering if anyone knows of a paper I can quote
> instead?  One (or more) from the cardiovascular literature
> would be especially precious to me.
>
> Best regards,
>    -Cody Hamilton
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From lorenzo.isella at gmail.com  Thu Sep 27 01:07:37 2007
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Thu, 27 Sep 2007 01:07:37 +0200
Subject: [R] Arrows Pointing to Curve
Message-ID: <46FAE639.6030104@gmail.com>

Dear All,
I hope this is not a FAQ, but my online research was not fruitful.
Consider a standard 2D plot generated with the "plot" command.
I would like to introduce inside the graph some text with an arrow 
pointing to a specific position of the plotted function.
Is this doable in R? Can anyone provide me with an example?
Many thanks

Lorenzo


From dylan.beaudette at gmail.com  Thu Sep 27 01:10:53 2007
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Wed, 26 Sep 2007 16:10:53 -0700
Subject: [R] Arrows Pointing to Curve
In-Reply-To: <46FAE639.6030104@gmail.com>
References: <46FAE639.6030104@gmail.com>
Message-ID: <200709261610.53923.dylan.beaudette@gmail.com>

On Wednesday 26 September 2007, Lorenzo Isella wrote:
> Dear All,
> I hope this is not a FAQ, but my online research was not fruitful.
> Consider a standard 2D plot generated with the "plot" command.
> I would like to introduce inside the graph some text with an arrow
> pointing to a specific position of the plotted function.
> Is this doable in R? Can anyone provide me with an example?
> Many thanks
>
> Lorenzo

?arrows

-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341


From ckang2 at gmail.com  Thu Sep 27 02:27:53 2007
From: ckang2 at gmail.com (ckang2 at gmail.com)
Date: Wed, 26 Sep 2007 20:27:53 -0400
Subject: [R] error message in eval
Message-ID: <c1cf87f10709261727g177f940bn721932b911594d45@mail.gmail.com>

Hello, Listers

I'm trying to run blloean logit model with R.

My code is:

> library(boolean)
> library(foreign)
> pr <- read.dta ("prcore1.dta")
> bp <- boolprep ("(a&b)|c", "cwt", a="O1", b="t", c="DM2
> + ah + md + con + n3 + rel + slo + pyrs
> + sp1 + sp2 + spl3")
> answer <- boolean (bp, link = "logit", method = "nlm")

But I got an error message here as follows:

Error in eval(expr, envir, enclos) : object "cwt" not found

"cwt" is my D.V. and I made sure that R read the data correctly.

It might be a stupid question.But, since I'm a very very beginner of
R, I don't know what's wrong.
I tried to figure out this with the manual, but I can't get any answer.

Could you anyone help me out?

Thank you very much in advance.

Best,
Charlie


From zmring at gmail.com  Thu Sep 27 02:34:38 2007
From: zmring at gmail.com (John Smith)
Date: Wed, 26 Sep 2007 20:34:38 -0400
Subject: [R] R: anova.Design
Message-ID: <1a0116140709261734n5bfc6214xcc9d59e90240288c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070926/31aebfa3/attachment.pl 

From apu at phsa.ca  Thu Sep 27 02:37:51 2007
From: apu at phsa.ca (Pu, Aihua)
Date: Wed, 26 Sep 2007 17:37:51 -0700
Subject: [R] plot(cox.zph())
Message-ID: <C774D0F8E68B9C4B8AAB708C56B0C09D30BCE6@srvex03.phsabc.ehcnet.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070926/e20008b6/attachment.pl 

From r.turner at auckland.ac.nz  Thu Sep 27 03:10:33 2007
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 27 Sep 2007 13:10:33 +1200
Subject: [R] error message in eval
In-Reply-To: <c1cf87f10709261727g177f940bn721932b911594d45@mail.gmail.com>
References: <c1cf87f10709261727g177f940bn721932b911594d45@mail.gmail.com>
Message-ID: <F6D01A6B-9189-4C03-A2E5-08DEFDED5274@auckland.ac.nz>


On 27/09/2007, at 12:27 PM, ckang2 at gmail.com wrote:

> Hello, Listers
>
> I'm trying to run blloean logit model with R.
>
> My code is:
>
>> library(boolean)
>> library(foreign)
>> pr <- read.dta ("prcore1.dta")
>> bp <- boolprep ("(a&b)|c", "cwt", a="O1", b="t", c="DM2
>> + ah + md + con + n3 + rel + slo + pyrs
>> + sp1 + sp2 + spl3")
>> answer <- boolean (bp, link = "logit", method = "nlm")
>
> But I got an error message here as follows:
>
> Error in eval(expr, envir, enclos) : object "cwt" not found
>
> "cwt" is my D.V. and I made sure that R read the data correctly.
>
> It might be a stupid question.But, since I'm a very very beginner of
> R, I don't know what's wrong.
> I tried to figure out this with the manual, but I can't get any  
> answer.
>
> Could you anyone help me out?

The variable ``cwt'' is a component of the data frame ``pr''; it is  
not lying
around loose in the workspace (global environment) where the function  
boolean()
can see it.  You need to tell boolean() where to find ``cwt'' and the  
other variables
referred to.  I don't know from the boolean package, but I conjecture  
that the
boolean function has a ``data'' argument, in which case

	answer <- boolean (bp, link = "logit", method = "nlm",data=pr)

may work.  Otherwise you could

	(a) do:

			attach(pr)

	prior to the call to boolean, or

	(b) use with():

	answer <- with(pr, boolean (bp, link = "logit", method = "nlm"))

			cheers,

				Rolf Turner



######################################################################
Attention:\ This e-mail message is privileged and confidenti...{{dropped}}


From michael at frumin.net  Thu Sep 27 03:18:48 2007
From: michael at frumin.net (mfrumin)
Date: Wed, 26 Sep 2007 18:18:48 -0700 (PDT)
Subject: [R] Connecting R to PostgreSQL via RODBC, on Windows
Message-ID: <12913078.post@talk.nabble.com>


hey all, 

I feel like I must be missing something rather plain, but I don't get it. 
how is one supposed to use R as a PgSQL client on Windows?  Assume my
windows desktop is on the same network as a PgSQL server, and I just need to
use R to connect and pull down some data.

The thing that is confusing me is that RODBC doesn't seem to know anything
about PgSQL, in that  odbcDataSources(type = "all") only returns info about
MS/Excell/Access/dBase stuff.  What does it take to get RODBC to deal with
PgSQL?

thanks,
mike

-- 
View this message in context: http://www.nabble.com/Connecting-R-to-PostgreSQL-via-RODBC%2C-on-Windows-tf4525842.html#a12913078
Sent from the R help mailing list archive at Nabble.com.


From elw at stderr.org  Thu Sep 27 03:24:36 2007
From: elw at stderr.org (elw at stderr.org)
Date: Wed, 26 Sep 2007 20:24:36 -0500 (CDT)
Subject: [R] Connecting R to PostgreSQL via RODBC, on Windows
In-Reply-To: <12913078.post@talk.nabble.com>
References: <12913078.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0709262020240.23106@illuminati.stderr.org>


> I feel like I must be missing something rather plain, but I don't get 
> it. how is one supposed to use R as a PgSQL client on Windows?  Assume 
> my windows desktop is on the same network as a PgSQL server, and I just 
> need to use R to connect and pull down some data.
>
> The thing that is confusing me is that RODBC doesn't seem to know 
> anything about PgSQL, in that odbcDataSources(type = "all") only returns 
> info about MS/Excell/Access/dBase stuff.  What does it take to get RODBC 
> to deal with PgSQL?


There's an odbc-to-pgsql driver for windows that will need to be 
installed.  You can find that here:

http://www.postgresql.org/ftp/odbc/versions/

Then, you set up your connection to postgresql via the Control Panel, 
under Administrative Tools, then Data Sources.

Then connect to that with R.

[I have mostly done this under Linux - it has been quite a while since 
I've needed to do it on Windows, but this is a broadly correct outline of 
the necessary steps.]

--e


From m_olshansky at yahoo.com  Thu Sep 27 03:32:30 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Wed, 26 Sep 2007 18:32:30 -0700 (PDT)
Subject: [R] Area of overlap between polygon and circle
In-Reply-To: <46FAA82C.6000005@noaa.gov>
Message-ID: <691500.78922.qm@web32215.mail.mud.yahoo.com>

Hello,

One possibility which gives an exact result and has
the complexity of O(n*log(n)) where n is the number of
vertices (edges) in the polygon would be to use
Green's theorem. One consequence of it is that id D is
a 2 dimensional region which boundary is a simple (and
piecewise continuously differentiable) curve C than
the area of D is the integral over C of xdy.
Given a polygon and a circle, find all the
intersection points and order them in a clockwise
direction (this has an O(n*log(n)) complexity -
everything else is O(n)). Let the points be
P1,P2,...,Pk (k<= 2*n). Order the edges of the polygon
in a clockwise direction and let the edge containing
P1 be edge number 1 (E1) and let i1=1,i2,i3,...,ik be
the indices of the edges containing points
P1,P2,...,Pk.
Start with P1 and check whether the circle arc between
P1 and P2 is inside or outside your polygon. One way
to do this is to take the middle of this arc and the
circle's center and count how many edges the straight
line connecting this point intersects. If the number
is even the arc is inside the polygon. If it is odd it
is outside. Let assume that the arc is inside. Then
the first segment of the boundary of your region is
the arc between P1 and P2. The second one consists of
the part of edge Ei2 P2 to the vertex + edge
E(i2+1),.. + part of edge E(i3) before point P3 (note
that it may happen that i2 = i3). Next segment is the
arc between P3 and P4, etc. Finally add the polygon
edges between Pk and P1.
Since the integral of xdy along a circle arc and along
a straight line segment can be easily computed
(analytically) you get the exact area.
If the number of intersection points is 0 then either
the polygon is inside the circle and the areas is the
area of the polygon or the circle is inside the
polygon and the area is that of the circle or they are
fully separated and the area is 0 - it is not
difficult to check what is your case.

Regards,

Moshe.


--- Eric Archer <Eric.Archer at noaa.gov> wrote:

> R-listers,
> 
> Given a polygon and a circle defined by its center
> coordinates and a 
> radius, I would like to calculate the area of
> overlap.  I know that I 
> can create a polygon from the circle and then use
> available packages to 
> get the area of the intersection.  However, because
> the polygon is of a 
> fixed size and I will be doing this for circles of
> varying sizes, I'm 
> concerned about maintaining the appropriate amount
> of resolution with 
> larger circles.   If there was already a package
> that did the above 
> calculation without the creation of a circle polygon
> and would thus give 
> an exact area, that would be preferred.  I have
> searched the archives 
> and have not found a solution to this particular
> problem.  Thanks!
> 
> Cheers,
> eric
> 
> -- 
> 
> Eric Archer, Ph.D.
> NOAA-SWFSC
> 8604 La Jolla Shores Dr.
> La Jolla, CA 92037
> 858-546-7121,7003(FAX)
> eric.archer at noaa.gov
> http://swfsc.noaa.gov/prd-etp.aspx
> 
> "Innocence about Science is the worst crime today."
>    - Sir Charles Percy Snow
> 
> 
> "Lighthouses are more helpful than churches."
>    - Benjamin Franklin
> 
>    "...but I'll take a GPS over either one."
>        - John C. "Craig" George 
> 
> 
> > ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From tomfool at as220.org  Thu Sep 27 04:42:53 2007
From: tomfool at as220.org (Tom Sgouros)
Date: Wed, 26 Sep 2007 22:42:53 -0400
Subject: [R] curvilinear grid
Message-ID: <20070927024253.99676FAC9EF@as220.org>


Hello all:

A question from a new user.  I have data on a geo-referenced curvilinear
grid.  This is a grid with 75 rows and 51 columns, is not aligned
north-south, and the rows and columns are not straight. (And the
coordinates are in meters.)  I want to make image plots of this data,
but where the grid is deformed according to the correct locations of the
grid points, instead of coming out rectangular.

I've found the sp package, which seems to be kind of close to what I'm
after, but maybe I haven't figured out how to invoke it properly, or
maybe there's another package I haven't found yet.  Can anyone direct me
to how to use R to map this kind of data?  Is there an example someone
might be able to share with me?

Is there a collection of plots somewhere that someone might browse to
answer questions like this?

Many thanks,

 -tom

-- 
 ------------------------
 tomfool at as220 dot org
 http://sgouros.com  
 http://whatcheer.net


From h.wickham at gmail.com  Thu Sep 27 05:55:54 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 26 Sep 2007 22:55:54 -0500
Subject: [R] curvilinear grid
In-Reply-To: <20070927024253.99676FAC9EF@as220.org>
References: <20070927024253.99676FAC9EF@as220.org>
Message-ID: <f8e6ff050709262055s42297681oeed2f3cdf4fb09ff@mail.gmail.com>

You might be able to do this with the ggplot2 package - see for
example http://had.co.nz/ggplot2/coord_map.html, which shows plots on
map coordinate systems.  Because the design of ggplot2 means the
coordinate system and geom (eg. points vs tiles) operate
independently, you can draw image plots
(http://had.co.nz/ggplot2/geom_tile.html) in any coordinate system.

Can you provide more details about your curvilinear coordinate system?

Hadley

On 9/26/07, Tom Sgouros <tomfool at as220.org> wrote:
>
> Hello all:
>
> A question from a new user.  I have data on a geo-referenced curvilinear
> grid.  This is a grid with 75 rows and 51 columns, is not aligned
> north-south, and the rows and columns are not straight. (And the
> coordinates are in meters.)  I want to make image plots of this data,
> but where the grid is deformed according to the correct locations of the
> grid points, instead of coming out rectangular.
>
> I've found the sp package, which seems to be kind of close to what I'm
> after, but maybe I haven't figured out how to invoke it properly, or
> maybe there's another package I haven't found yet.  Can anyone direct me
> to how to use R to map this kind of data?  Is there an example someone
> might be able to share with me?
>
> Is there a collection of plots somewhere that someone might browse to
> answer questions like this?
>
> Many thanks,
>
>  -tom
>
> --
>  ------------------------
>  tomfool at as220 dot org
>  http://sgouros.com
>  http://whatcheer.net
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
http://had.co.nz/


From tomfool at as220.org  Thu Sep 27 06:57:01 2007
From: tomfool at as220.org (tom sgouros)
Date: Thu, 27 Sep 2007 00:57:01 -0400
Subject: [R] curvilinear grid
In-Reply-To: <f8e6ff050709262055s42297681oeed2f3cdf4fb09ff@mail.gmail.com> 
References: <20070927024253.99676FAC9EF@as220.org>
	<f8e6ff050709262055s42297681oeed2f3cdf4fb09ff@mail.gmail.com>
Message-ID: <20070927045701.E13CDFAC9F8@as220.org>


hadley wickham <h.wickham at gmail.com> wrote:

> You might be able to do this with the ggplot2 package - see for
> example http://had.co.nz/ggplot2/coord_map.html, which shows plots on
> map coordinate systems.  Because the design of ggplot2 means the
> coordinate system and geom (eg. points vs tiles) operate
> independently, you can draw image plots
> (http://had.co.nz/ggplot2/geom_tile.html) in any coordinate system.

These aren't quite what I have in mind.

> Can you provide more details about your curvilinear coordinate system?

The idea is that you're modeling an irregular shaped object, a body of
water, a river or estuary, say.  It's fairly common practice to use a
grid squished and rotated so that the main flow is along one axis, and
the other axis spans the flow in most spots.  So there is a single
transformation that gets you from a rectangular grid to the shape of
your estuary, but there isn't a tidy analytical way to describe it, like
there is with a map projection.  Instead there is an x and y for each
grid point, and the cell dimensions vary all over the place.

spplot, in the sp package seems almost to do what I'm after, but I can't
figure out if there is a way to invoke it that does what I want, or if
I'm barking up the wrong tree.

Thanks,

 -tom

> 
> On 9/26/07, Tom Sgouros <tomfool at as220.org> wrote:
> >
> > Hello all:
> >
> > A question from a new user.  I have data on a geo-referenced curvilinear
> > grid.  This is a grid with 75 rows and 51 columns, is not aligned
> > north-south, and the rows and columns are not straight. (And the
> > coordinates are in meters.)  I want to make image plots of this data,
> > but where the grid is deformed according to the correct locations of the
> > grid points, instead of coming out rectangular.
> >
> > I've found the sp package, which seems to be kind of close to what I'm
> > after, but maybe I haven't figured out how to invoke it properly, or
> > maybe there's another package I haven't found yet.  Can anyone direct me
> > to how to use R to map this kind of data?  Is there an example someone
> > might be able to share with me?
> >
> > Is there a collection of plots somewhere that someone might browse to
> > answer questions like this?
> >
> > Many thanks,
> >
> >  -tom
> >
> > --
> >  ------------------------
> >  tomfool at as220 dot org
> >  http://sgouros.com
> >  http://whatcheer.net
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 
> -- 
> http://had.co.nz/
> 


-- 
 ------------------------
 tomfool at as220 dot org
 http://sgouros.com  
 http://whatcheer.net


From ripley at stats.ox.ac.uk  Thu Sep 27 07:54:31 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 27 Sep 2007 06:54:31 +0100 (BST)
Subject: [R] Connecting R to PostgreSQL via RODBC, on Windows
In-Reply-To: <12913078.post@talk.nabble.com>
References: <12913078.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0709270651210.27243@auk.stats>

On Wed, 26 Sep 2007, mfrumin wrote:

>
> hey all,
>
> I feel like I must be missing something rather plain, but I don't get it.
> how is one supposed to use R as a PgSQL client on Windows?  Assume my
> windows desktop is on the same network as a PgSQL server, and I just need to
> use R to connect and pull down some data.
>
> The thing that is confusing me is that RODBC doesn't seem to know anything
> about PgSQL, in that  odbcDataSources(type = "all") only returns info about
> MS/Excell/Access/dBase stuff.  What does it take to get RODBC to deal with
> PgSQL?

This is an ODBC (not RODBC) issue.  You need to install the PostgreSQL 
ODBC driver and use the 'Data Sources' applet in the Control Panel to set 
it up. Talk to your sysadmin about how (s)he installed PostgreSQL (or read 
the PostgreSQL documentation) if you need more help.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From paul at stat.auckland.ac.nz  Thu Sep 27 08:13:05 2007
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Thu, 27 Sep 2007 08:13:05 +0200
Subject: [R] sprucing up the R homepage
In-Reply-To: <Pine.LNX.4.64.0709261120570.18641@illuminati.stderr.org>
References: <200709260405.l8Q45B3i014618@mail04.syd.optusnet.com.au>	<Pine.LNX.4.64.0709260632370.9274@illuminati.stderr.org>	<20070926132219.GB318@web15.webfaction.com>
	<Pine.LNX.4.64.0709261120570.18641@illuminati.stderr.org>
Message-ID: <46FB49F1.8090904@stat.auckland.ac.nz>

Hi


elw at stderr.org wrote:
> 
> 
>> So I applied my corrected margins to Tim's Cairo trick and voila:
>> http://www.broad.mit.edu/~finnyk/Rlogo_swiss.png
>> This is hands-down the best version, in my opinion!
> 
> Yes, it is definitely much nicer than the version on www.r-project.org 
> now.  :-)


Much nicer.  Thanks guys!

Before we update the homepage, we should probably just check with the 
original "artist" (Eric Lecoutre, cc'ed) and we would need a description 
of the final technique you used to add as a comment to the code "behind" 
the image.

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From hans-ole.orka at umb.no  Thu Sep 27 08:36:24 2007
From: hans-ole.orka at umb.no (=?iso-8859-1?Q?Hans_Ole_=D8rka?=)
Date: Thu, 27 Sep 2007 08:36:24 +0200
Subject: [R] SAS proc reg stepwise procedure in R
Message-ID: <79A4337FAC9B9745AC67F907304190C018392F18FA@exch01.ans.umb.no>

I try to reproduce the SAS proc reg stepwise model selection procedure in R, but the only function I found was "step" which select new variables based on AIC. The SAS procedure I use add a new variable to the model based on F statistics and a pre defined significant level. Then before any new variables are added variables in the model that not meet F statistics at the significant level will be removed. I have added the SAS syntax for those of familiar with both software packages.

SAS syntax:
proc reg
        model Y=x1 x2 x3 .....xn
        /selection=stepwise slentry=0.50 slstay=0.05;

All ideas are appreciated
Thanks,
Hans Ole ?rka


From elw at stderr.org  Thu Sep 27 08:43:29 2007
From: elw at stderr.org (elw at stderr.org)
Date: Thu, 27 Sep 2007 01:43:29 -0500 (CDT)
Subject: [R] curvilinear grid
In-Reply-To: <20070927045701.E13CDFAC9F8@as220.org>
References: <20070927024253.99676FAC9EF@as220.org>
	<f8e6ff050709262055s42297681oeed2f3cdf4fb09ff@mail.gmail.com>
	<20070927045701.E13CDFAC9F8@as220.org>
Message-ID: <Pine.LNX.4.64.0709270142430.9003@illuminati.stderr.org>


> The idea is that you're modeling an irregular shaped object, a body of 
> water, a river or estuary, say.  It's fairly common practice to use a 
> grid squished and rotated so that the main flow is along one axis, and 
> the other axis spans the flow in most spots.  So there is a single 
> transformation that gets you from a rectangular grid to the shape of 
> your estuary, but there isn't a tidy analytical way to describe it, like 
> there is with a map projection.  Instead there is an x and y for each 
> grid point, and the cell dimensions vary all over the place.
>
> spplot, in the sp package seems almost to do what I'm after, but I can't 
> figure out if there is a way to invoke it that does what I want, or if 
> I'm barking up the wrong tree.


Ask on R-sig-geo?  I haven't seen a query from you come through over 
there... and that would be the logical place to ask questions about the sp 
package and similar bits...

--e


From Wayne.W.Jones at shell.com  Thu Sep 27 08:49:49 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Thu, 27 Sep 2007 07:49:49 +0100
Subject: [R] Getting group-wise standard scores of a vector
In-Reply-To: <46FAC786.1070708@utoronto.ca>
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B0C3@wyt-s-019.europe.shell.com>


tapply is also very useful: 


my.df<-data.frame(x=rnorm(20, 50, 10),group=factor(sort(rep(c("A", "B"), 10))))
tapply(my.df$x,my.df$group,function(x){(x-mean(x))/sd(x)})



-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of Matthew Dubins
Sent: 26 September 2007 21:57
To: r-help at r-project.org
Subject: [R] Getting group-wise standard scores of a vector


Hi,

I want to be able to create a vector of z-scores from a vector of 
continuous data, conditional on a group membership vector.

Say you have 20 numbers distributed normally with a mean of 50 and an sd 
of 10:

x <- rnorm(20, 50, 10)


Then you have a vector that delineates 2 groups within x:

group <- sort(rep(c("A", "B"), 10))

test.data <- data.frame(cbind(x, group))

I know that if you break up the x vector into 2 different vectors then 
it becomes easy to calculate the z scores for each vector, then you 
stack them and append them to the original
data frame.  Is there anyway to apply this sort of calculation without 
splitting the original vector up?  I tried a really complex ifelse 
statement but it didn't seem to work.

Thanks in advance,
Matthew Dubins

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Thu Sep 27 09:19:07 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 27 Sep 2007 03:19:07 -0400
Subject: [R] Who uses R?
In-Reply-To: <46F8ECF0.6070801@pburns.seanet.com>
References: <1190717177.46f8e6f9d003d@webmail.cryst.bbk.ac.uk>
	<46F8ECF0.6070801@pburns.seanet.com>
Message-ID: <971536df0709270019h7cc927b3i31ccb297ff9becff@mail.gmail.com>

As has been pointed out on the net its a display problem
and Excel's internal value is correct.  We can check this
by creating an Excel 2007 spreadsheet with
A1 = A2-1  gives 65534
A2 =850 * 77.1 gives 100000
A3 = A2+1 gives 100001
A4 = A2+2 gives 65537

and then running this code from R on the spreadsheet
to examine the internal values that Excel has stored:

library(RDCOMClient)
xls <- COMCreate("Excel.Application")
xls[["Workbooks"]]$Open("C:\\tmp2\\badcalc.xlsx")
rng <- xls[["ActiveSheet"]]$Range("A1:A4")
x <- rng[["Value"]]
x

When I run that I get this showing the internal
values are correct:

> xls <- COMCreate("Excel.Application")
> xls[["Workbooks"]]$Open("C:\\tmp2\\badcalc.xlsx")
An object of class "COMIDispatch"
Slot "ref":
<pointer: 0x001e7b94>

> rng <- xls[["ActiveSheet"]]$Range("A1:A4")
> x <- rng[["Value"]]
> x
[[1]]
[[1]][[1]]
[1] 65534

[[1]][[2]]
[1] 65535

[[1]][[3]]
[1] 65536

[[1]][[4]]
[1] 65537

On 9/25/07, Patrick Burns <pburns at pburns.seanet.com> wrote:
> Just speaking of the field I'm most familiar with, there
> are now users of R in many of the largest financial
> companies in the world.
>
> http://www.burns-stat.com/pages/Tutor/spreadsheet_addiction.html
>
> is one place to look for arguments against Excel.
> This was just updated to include an amusing numerical
> bug in Excel 2007. Guess what 850 * 77.1 equals.
>
>
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
>
> Eleni Rapsomaniki wrote:
>
> >Dear R users,
> >
> >I have started work in a Statistics government department and I am trying to
> >convince my bosses to install R on our computers (I can't do proper stats in
> >Excel!!). They asked me to prove that this is a widely used software (and not
> >just another free-source, bug infected toy I found on the web!) by suggesting
> >other big organisations that use it. Are you aware of any reputable places
> >(academic or not) that use R? (e.g. maybe you work for them)
> >
> >I would be really grateful for any advice on this. Also suggestions on arguments
> >I could use to persuade them that R is so much better than Excel would be very
> >much appreciated.
> >
> >Many Thanks
> >Eleni Rapsomaniki
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From maechler at stat.math.ethz.ch  Thu Sep 27 09:20:31 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 27 Sep 2007 09:20:31 +0200
Subject: [R] sprucing up the R homepage
In-Reply-To: <46FB49F1.8090904@stat.auckland.ac.nz>
References: <200709260405.l8Q45B3i014618@mail04.syd.optusnet.com.au>
	<Pine.LNX.4.64.0709260632370.9274@illuminati.stderr.org>
	<20070926132219.GB318@web15.webfaction.com>
	<Pine.LNX.4.64.0709261120570.18641@illuminati.stderr.org>
	<46FB49F1.8090904@stat.auckland.ac.nz>
Message-ID: <18171.22975.797963.986763@stat.math.ethz.ch>

>>>>> "Paul" == Paul Murrell <paul at stat.auckland.ac.nz>
>>>>>     on Thu, 27 Sep 2007 08:13:05 +0200 writes:

    Paul> Hi
    Paul> elw at stderr.org wrote:
    >> 
    >> 
    >>> So I applied my corrected margins to Tim's Cairo trick and voila:
    >>> http://www.broad.mit.edu/~finnyk/Rlogo_swiss.png
    >>> This is hands-down the best version, in my opinion!
    >> 
    >> Yes, it is definitely much nicer than the version on www.r-project.org 
    >> now.  :-)


    Paul> Much nicer.  Thanks guys!

Thanks indeed!


    Paul> Before we update the homepage, we should probably just
    Paul> check with the original "artist" (Eric Lecoutre,
    Paul> cc'ed) and we would need a description of the final
    Paul> technique you used to add as a comment to the code
    Paul> "behind" the image.

Yes, that was my "concern" too. After all, with R (and Sweave
and ...) advocating ``reproducible research'' in many ways,
I'd very much like a reproducible image there; we can live with
using non-R code for post processing (did I correctly get that you used
Imagemagick derived utilities)..

Martin Maechler, ETH Zurich


From ripley at stats.ox.ac.uk  Thu Sep 27 09:21:34 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 27 Sep 2007 08:21:34 +0100 (BST)
Subject: [R] SAS proc reg stepwise procedure in R
In-Reply-To: <79A4337FAC9B9745AC67F907304190C018392F18FA@exch01.ans.umb.no>
References: <79A4337FAC9B9745AC67F907304190C018392F18FA@exch01.ans.umb.no>
Message-ID: <Pine.LNX.4.64.0709270742470.5849@gannet.stats.ox.ac.uk>

On Thu, 27 Sep 2007, Hans Ole ?rka wrote:

> I try to reproduce the SAS proc reg stepwise model selection procedure 
> in R,

But why?  If you want 1950s statistical methods why not use a 1960s 
package?  There are enough problems with stepwise selection (see e.g. the 
book by Frank Harrell and many postings here) even with a well-defined 
criterion like AIC, but that is better than an ad hoc algorithm, 
especially one based on forwards selection.
For a flavour of Frank's views see

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/49353.html

Note that step() is stepwise by terms, not by variables.  If you have all 
terms as single variables, package 'leaps' will provide a better algorithm 
for choosing best subsets.  And in that case, step() is essentially the 
same as using F tests with 'F to enter/leave' = 2 (and you can use 
different 'k' to get different F limits).

If after further research you still want to do this in R, then R is a 
fully fledged programming language and it is quite easy to modify step() 
to use F tests, especially for single-variable terms.

> but the only function I found was "step" which select new 
> variables based on AIC. The SAS procedure I use add a new variable to 
> the model based on F statistics and a pre defined significant level. 
> Then before any new variables are added variables in the model that not 
> meet F statistics at the significant level will be removed. I have added 
> the SAS syntax for those of familiar with both software packages.

So I gather 'the significant level' for dropping is in fact not 'the' one 
used for adding?  This is essentially forwards selection.

>
> SAS syntax:
> proc reg
>        model Y=x1 x2 x3 .....xn
>        /selection=stepwise slentry=0.50 slstay=0.05;
>
> All ideas are appreciated
> Thanks,
> Hans Ole ?rka

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From mdgi at gmx.ch  Thu Sep 27 09:21:57 2007
From: mdgi at gmx.ch (marcg)
Date: Thu, 27 Sep 2007 09:21:57 +0200
Subject: [R] different colors for two wireframes in same plot
Message-ID: <20070927072157.13720@gmx.net>

Hello R,

According to:

g <- expand.grid(x = 1:10, y = 5:15, gr = 1:2)
g$z <- log((g$x^g$g + g$y^2) * g$gr)
wireframe(z ~ x * y, data = g, groups = gr,
          scales = list(arrows = FALSE),
          drape = TRUE, colorkey = TRUE,
          screen = list(z = 30, x = -60))

i have two wireframes in one plot.

How could i change the color of the top - one to transparent (or only the grid). I want to give insight to the lower layer.

Could one make an if-statment like (if gr==1 do drape=F or color=none) if gr=2 do drape=T, colorkey=T)

Thanks for your help

Marc

-- 
Psssst! Schon vom neuen GMX MultiMessenger geh?rt?
Der kanns mit allen: http://www.gmx.net/de/go/multimessenger


From petr.pikal at precheza.cz  Thu Sep 27 09:50:39 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Thu, 27 Sep 2007 09:50:39 +0200
Subject: [R] Odp:  Need help with function writing
In-Reply-To: <A3E5A3C873C56F42B7F1A511D5F7525510C1F7@cu-ex-03.claflin.edu>
Message-ID: <OF3E31624D.98367D80-ONC1257363.002A1325-C1257363.002B14F2@precheza.cz>

Hi

> Hello: 
> 
> If anyone could guide me with this I would greatly appreciate it. 
Thanking you
> in advance for your assistance.
> 
> Using a 3-level input factor alternative so that a function(below) can 
compute
> both a two-sided and one-sided p-values. Making the two-sided test the 
> default. And produce output information about which alternative was 
tested. 
> Where would I place the ifelse statement? 

Without going too deep into your function if you want to have a selection 
criteria which test to perform and some information in the result you can 
use a logical value in function definition

function(yvec, trtvec, alpha=0.05, header="", two=T) {

than put

if (two) {

result <- make two sided calculation} else {

result <- make one sided calculation)

and than 

out=data.frame(diff12estimate,stderr,tratio,twosidedP,lower,upper,alpha)
names(out)=c("Estimator","SE","T","P-value","Lower CI","Upper 
CI","Confidence")
out <- list(out, hypot=if(two) "two sided" else "one sided")
out
}

<end of function>

Regards
Petr
> 
> function(yvec,trtvec,alpha=0.05,header="") {
> #################################################
> # A function to compute a two-sample t-test and confidence 
> # interval (equal-variance, independent samples).  yvec is 
> # a numeric vector containing both samples' data.  trtvec 
> # is a vector, same length as yvec, of treatment
> # identifiers for the data in yvec.  A boxplot comparing
> # the treatments' data is constructed.  Output is a one-row
> # data frame reporting the results of the test and 
> # confidence interval
> ##################################################
> trtvec=as.factor(trtvec)
> boxplot(split(yvec,trtvec))
> title(header)
> ybar=tapply(yvec,trtvec,mean)
> varvec=tapply(yvec,trtvec,var)
> nvec=table(trtvec)
> error.df=nvec[1]+nvec[2]-2
> pooled.var=((nvec[1]-1)*varvec[1]+(nvec[2]-1)*varvec[2])/error.df
> diff12estimate=ybar[1]-ybar[2]
> stderr=sqrt(pooled.var*((1/nvec[1])+(1/nvec[2])))
> tratio=diff12estimate/stderr
> twosidedP=2*(1-pt(abs(tratio),error.df))
> tcrit=qt(1-alpha/2,error.df)
> lower=diff12estimate-tcrit*stderr
> upper=diff12estimate+tcrit*stderr
> calpha=1-alpha
> out=data.frame(diff12estimate,stderr,tratio,twosidedP,lower,upper,alpha)
> names(out)=c("Estimator","SE","T","P-value","Lower CI","Upper 
CI","Confidence")
> out
> }
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Wayne.W.Jones at shell.com  Thu Sep 27 10:09:26 2007
From: Wayne.W.Jones at shell.com (Wayne.W.Jones at shell.com)
Date: Thu, 27 Sep 2007 09:09:26 +0100
Subject: [R] Need help with function writing
In-Reply-To: <A3E5A3C873C56F42B7F1A511D5F7525510C1F7@cu-ex-03.claflin.edu>
Message-ID: <77693D6263D9B94AA3C6384F1474E26A0284B0C6@wyt-s-019.europe.shell.com>


Why dont you use the t.test within R? See help(t.test). It looks to have everything you need:
here are the examples with different alternative hypothesese: 

with(sleep, t.test(extra[group == 1], extra[group == 2],alternative = "greater"))
with(sleep, t.test(extra[group == 1], extra[group == 2],alternative = "two.sided"))
with(sleep, t.test(extra[group == 1], extra[group == 2],alternative = "less"))


If you are still really keen to use your own function I would use help(switch) to select between different alternative hypths. 

Regards

Wayne


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]On Behalf Of Letticia Ramlal
Sent: 25 September 2007 14:20
To: r-help at stat.math.ethz.ch
Subject: [R] Need help with function writing


Hello: 

If anyone could guide me with this I would greatly appreciate it. Thanking you in advance for your assistance.

Using a 3-level input factor alternative so that a function(below) can compute both a two-sided and one-sided p-values. Making the two-sided test the default. And produce output information about which alternative was tested. Where would I place the ifelse statement? 

function(yvec,trtvec,alpha=0.05,header="") {
#################################################
# A function to compute a two-sample t-test and confidence 
# interval (equal-variance, independent samples).  yvec is 
# a numeric vector containing both samples' data.  trtvec 
# is a vector, same length as yvec, of treatment
# identifiers for the data in yvec.  A boxplot comparing
# the treatments' data is constructed.  Output is a one-row
# data frame reporting the results of the test and 
# confidence interval
##################################################
trtvec=as.factor(trtvec)
boxplot(split(yvec,trtvec))
title(header)
ybar=tapply(yvec,trtvec,mean)
varvec=tapply(yvec,trtvec,var)
nvec=table(trtvec)
error.df=nvec[1]+nvec[2]-2
pooled.var=((nvec[1]-1)*varvec[1]+(nvec[2]-1)*varvec[2])/error.df
diff12estimate=ybar[1]-ybar[2]
stderr=sqrt(pooled.var*((1/nvec[1])+(1/nvec[2])))
tratio=diff12estimate/stderr
twosidedP=2*(1-pt(abs(tratio),error.df))
tcrit=qt(1-alpha/2,error.df)
lower=diff12estimate-tcrit*stderr
upper=diff12estimate+tcrit*stderr
calpha=1-alpha
out=data.frame(diff12estimate,stderr,tratio,twosidedP,lower,upper,alpha)
names(out)=c("Estimator","SE","T","P-value","Lower CI","Upper CI","Confidence")
out
}

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From minhuangr at gmail.com  Thu Sep 27 07:29:50 2007
From: minhuangr at gmail.com (huang min)
Date: Thu, 27 Sep 2007 15:29:50 +1000
Subject: [R] Sweave problem in Windows
Message-ID: <bfc676680709262229rdad555yeb9c5387f706102d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/badb9160/attachment.pl 

From motaveiga at net.sapo.pt  Wed Sep 26 16:23:00 2007
From: motaveiga at net.sapo.pt (motaveiga at net.sapo.pt)
Date: Wed, 26 Sep 2007 15:23:00 +0100
Subject: [R] Sample size
Message-ID: <20070926152300.avl70kvz4kg8ko4k@w7.mail.sapo.pt>


Hi for all.

How can I determinate in R the sample size to estimate a logistic  
regression with two outcomes. One of outcomes was 47% in population  
and I want determine the factors that influence that probability.

Thanks everyone


From bkelcey at umich.edu  Wed Sep 26 22:36:54 2007
From: bkelcey at umich.edu (bkelcey at umich.edu)
Date: Wed, 26 Sep 2007 16:36:54 -0400
Subject: [R] generate fourth vector based on known correlations
Message-ID: <20070926163654.hqagw35748wscoso@web.mail.umich.edu>



I am trying to generate a fourth vector,z, given three known and fixed 
vectors, x1,x2,x3with corresponding known and fixed correlations with 
themeselves and with z. That is, all correlations are known and 
prespecified. How can I do this?
Thank you,
ben


From maura.monville at gmail.com  Thu Sep 27 07:46:03 2007
From: maura.monville at gmail.com (Maura E Monville)
Date: Wed, 26 Sep 2007 19:46:03 -1000
Subject: [R] nonlinear regression
Message-ID: <36d691950709262246g58b02d1dwadc8b671c0353832@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070926/9fa9cc48/attachment.pl 

From eugen_pircalabelu at yahoo.com  Thu Sep 27 09:44:02 2007
From: eugen_pircalabelu at yahoo.com (eugen pircalabelu)
Date: Thu, 27 Sep 2007 00:44:02 -0700 (PDT)
Subject: [R] grossing-up weights in Survey package
Message-ID: <205130.69119.qm@web38606.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/5896b060/attachment.pl 

From FredeA.Togersen at agrsci.dk  Thu Sep 27 11:29:19 2007
From: FredeA.Togersen at agrsci.dk (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Thu, 27 Sep 2007 11:29:19 +0200
Subject: [R] different colors for two wireframes in same plot
In-Reply-To: <20070927072157.13720@gmx.net>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC0574B927@DJFPOST01.djf.agrsci.dk>

You can obtain some transparency setting the alpha transparency. This is device dependent though. Using the pdf device you can do this obtaining transparency of both surfaces (the version must be at least 1.4 for semitransparent output to be understood):


pdf("test.pdf",version="1.4")
wireframe(z ~ x * y, data = g, groups = gr,
          scales = list(arrows = FALSE),
          drape = TRUE, colorkey = TRUE,
          screen = list(z = 30, x = -60),
          par.settings = list(regions=list(alpha=0.75)))
dev.off()

See ?wireframe for the "at, col.regions, alpha.regions" arguments.

Does this suffice?


Med venlig hilsen
Frede Aakmann T?gersen
 

 

> -----Oprindelig meddelelse-----
> Fra: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] P? vegne af marcg
> Sendt: 27. september 2007 09:22
> Til: r-help at stat.math.ethz.ch
> Emne: [R] different colors for two wireframes in same plot
> 
> Hello R,
> 
> According to:
> 
> g <- expand.grid(x = 1:10, y = 5:15, gr = 1:2) g$z <- 
> log((g$x^g$g + g$y^2) * g$gr) wireframe(z ~ x * y, data = g, 
> groups = gr,
>           scales = list(arrows = FALSE),
>           drape = TRUE, colorkey = TRUE,
>           screen = list(z = 30, x = -60))
> 
> i have two wireframes in one plot.
> 
> How could i change the color of the top - one to transparent 
> (or only the grid). I want to give insight to the lower layer.
> 
> Could one make an if-statment like (if gr==1 do drape=F or 
> color=none) if gr=2 do drape=T, colorkey=T)
> 
> Thanks for your help
> 
> Marc
> 
> --
> Psssst! Schon vom neuen GMX MultiMessenger geh?rt?
> Der kanns mit allen: http://www.gmx.net/de/go/multimessenger
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From mdgi at gmx.ch  Thu Sep 27 11:52:43 2007
From: mdgi at gmx.ch (marcg)
Date: Thu, 27 Sep 2007 11:52:43 +0200
Subject: [R] different colors for two wireframes in same plot
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC0574B927@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC0574B927@DJFPOST01.djf.agrsci.dk>
Message-ID: <20070927095243.13700@gmx.net>

Thanks a lot

This already looks nice and I already checked the ?wireframe, but with no examples and as newcommer its hard to find out a correct code.

If we set drape=F in the example:

g <- expand.grid(x = 1:10, y = 5:15, gr = 1:2)
g$z <- log((g$x^g$g + g$y^2) * g$gr)
wireframe(z ~ x * y, data = g, groups = gr,
          scales = list(arrows = FALSE),
          drape = F, colorkey = TRUE,
          screen = list(z = 30, x = -60))

you get a two color pic of these layers - and what I'm actually looking for is making just the UPPER (toplayer) transparent.

Thanks for further help

marc

-------- Original-Nachricht --------
> Datum: Thu, 27 Sep 2007 11:29:19 +0200
> Von: "Frede Aakmann T?gersen" <FredeA.Togersen at agrsci.dk>
> An: "marcg" <mdgi at gmx.ch>, r-help at stat.math.ethz.ch
> Betreff: SV: [R] different colors for two wireframes in same plot

> You can obtain some transparency setting the alpha transparency. This is
> device dependent though. Using the pdf device you can do this obtaining
> transparency of both surfaces (the version must be at least 1.4 for
> semitransparent output to be understood):
> 
> 
> pdf("test.pdf",version="1.4")
> wireframe(z ~ x * y, data = g, groups = gr,
>           scales = list(arrows = FALSE),
>           drape = TRUE, colorkey = TRUE,
>           screen = list(z = 30, x = -60),
>           par.settings = list(regions=list(alpha=0.75)))
> dev.off()
> 
> See ?wireframe for the "at, col.regions, alpha.regions" arguments.
> 
> Does this suffice?
> 
> 
> Med venlig hilsen
> Frede Aakmann T?gersen
>  
> 
>  
> 
> > -----Oprindelig meddelelse-----
> > Fra: r-help-bounces at r-project.org 
> > [mailto:r-help-bounces at r-project.org] P? vegne af marcg
> > Sendt: 27. september 2007 09:22
> > Til: r-help at stat.math.ethz.ch
> > Emne: [R] different colors for two wireframes in same plot
> > 
> > Hello R,
> > 
> > According to:
> > 
> > g <- expand.grid(x = 1:10, y = 5:15, gr = 1:2) g$z <- 
> > log((g$x^g$g + g$y^2) * g$gr) wireframe(z ~ x * y, data = g, 
> > groups = gr,
> >           scales = list(arrows = FALSE),
> >           drape = TRUE, colorkey = TRUE,
> >           screen = list(z = 30, x = -60))
> > 
> > i have two wireframes in one plot.
> > 
> > How could i change the color of the top - one to transparent 
> > (or only the grid). I want to give insight to the lower layer.
> > 
> > Could one make an if-statment like (if gr==1 do drape=F or 
> > color=none) if gr=2 do drape=T, colorkey=T)
> > 
> > Thanks for your help
> > 
> > Marc
> > 
> > --
> > Psssst! Schon vom neuen GMX MultiMessenger geh?rt?
> > Der kanns mit allen: http://www.gmx.net/de/go/multimessenger
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > 

--


From jrkrideau at yahoo.ca  Thu Sep 27 11:59:54 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 27 Sep 2007 05:59:54 -0400 (EDT)
Subject: [R] Arrows Pointing to Curve
In-Reply-To: <46FAE639.6030104@gmail.com>
Message-ID: <985016.87391.qm@web32812.mail.mud.yahoo.com>

? arrows

plot(1:10)
text(2,5, "Point")
arrows(3,5, 4.5, 5)

--- Lorenzo Isella <lorenzo.isella at gmail.com> wrote:

> Dear All,
> I hope this is not a FAQ, but my online research was
> not fruitful.
> Consider a standard 2D plot generated with the
> "plot" command.
> I would like to introduce inside the graph some text
> with an arrow 
> pointing to a specific position of the plotted
> function.
> Is this doable in R? Can anyone provide me with an
> example?
> Many thanks
> 
> Lorenzo


From c.declercq at orsnpdc.org  Thu Sep 27 12:12:28 2007
From: c.declercq at orsnpdc.org (Christophe DECLERCQ)
Date: Thu, 27 Sep 2007 12:12:28 +0200
Subject: [R] Sweave problem in Windows
Message-ID: <892792C268EB89458F1FADC109779A671D1648@ors-npdc.orsnpdc.local>

Hi, Huang 

> De : r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] De la part de huang min
> Envoy? : jeudi 27 septembre 2007 11:31
> 
> Hi,
> 
> I have searched the lists but still can not solve the 
> problem. I am using a windows machine. After I sweave some 
> Rnw file, I got a tex file. However, the tex file can not be 
> compiled. I know the problem is in the line 
> \usepackage{C:/PROGRA~1/R/R-25~1.1/share/texmf/Sweave} and I 
> need to modify this line to \usepackage{Sweave}.
> 
> I hope there can be some automatic way to do this instead of 
> changing this line in the tex file whenever I modify 
> something. Thank you.

This is a FAQ: see
http://www.ci.tuwien.ac.at/~leisch/Sweave/FAQ.html#x1-14000A.12
Which says:

"If you can create the .tex ?le by running Sweave() in R, but cannot convert the .tex ?le to .dvi or .pdf, this is most likely caused by a space in the path of your R installation. If the path of your R installation contains any blank characters (like the default "c:\Program Files\..." in English versions of Windows), this may cause problems, because programs like tex or latex cannot handle blanks in paths properly.
Two possible solutions:
   1. Install R in a path not containing any blanks.
   2. Copy the ?le Sweave.sty to a directory in your tex path or the directory containing the Sweave ?le and put a \usepackage{Sweave} into the preamble of your Sweave ?le."

I use the first solution...

Christophe
--
Christophe Declercq, MD
Observatoire r?gional de la sant? Nord-Pas-de-Calais
235, avenue de la recherche BP 86
F-59373 LOOS C?dex
Phone 33 3 20 15 49 24
Fax 33 3 20 15 10 46
E-mail c.declercq at orsnpdc.org
 

> 
> Huang
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 

From unwin at math.uni-augsburg.de  Thu Sep 27 12:37:41 2007
From: unwin at math.uni-augsburg.de (Antony Unwin)
Date: Thu, 27 Sep 2007 12:37:41 +0200
Subject: [R] sprucing up the R homepage
Message-ID: <2E3C91D9-7429-4E9D-8C74-ABB2456D7FF6@math.uni-augsburg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/0efb1ecd/attachment.pl 

From E.Vettorazzi at uke.uni-hamburg.de  Thu Sep 27 12:47:47 2007
From: E.Vettorazzi at uke.uni-hamburg.de (Eik Vettorazzi)
Date: Thu, 27 Sep 2007 12:47:47 +0200
Subject: [R] Sweave problem in Windows
In-Reply-To: <bfc676680709262229rdad555yeb9c5387f706102d@mail.gmail.com>
References: <bfc676680709262229rdad555yeb9c5387f706102d@mail.gmail.com>
Message-ID: <46FB8A53.3030009@uke.uni-hamburg.de>

See A.12 in http://www.ci.tuwien.ac.at/~leisch/Sweave/FAQ.html

huang min schrieb:
> Hi,
>
> I have searched the lists but still can not solve the problem. I am using a
> windows machine. After I sweave some Rnw file, I got a tex file. However,
> the tex file can not be compiled. I know the problem is in the line
> \usepackage{C:/PROGRA~1/R/R-25~1.1/share/texmf/Sweave} and I need to modify
> this line to
> \usepackage{Sweave}.
>
> I hope there can be some automatic way to do this instead of changing this
> line in the tex file whenever I modify something. Thank you.
>
> Huang
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
Eik Vettorazzi
Institut f?r Medizinische Biometrie und Epidemiologie
Universit?tsklinikum Hamburg-Eppendorf

Martinistr. 52
20246 Hamburg

T ++49/40/42803-8243
F ++49/40/42803-7790


From jo.irisson at gmail.com  Thu Sep 27 12:52:18 2007
From: jo.irisson at gmail.com (jiho)
Date: Thu, 27 Sep 2007 12:52:18 +0200
Subject: [R] Plotting from different data sources on the same plot (with
	ggplot2)
Message-ID: <1098D7B2-FD7D-447A-B06C-4F005773CEBF@gmail.com>

Hello everyone (and Hadley in particular),

I often need to plot data from multiple datasets on the same graph. A  
common example is when mapping some values: I want to plot the  
underlying map and then add the points. I currently do it with base  
graphics, by recording the maximum region in which my map+point will  
fit, plotting both with these xlim and ylim parameters, adding par 
(new=T) between plot calls and setting the graphical parameters (to  
draw axes, titles, to set aspect ratio) by hand. This is not easy nor  
practical when the plots become more and more complicated.

The ggplot book specifies that "[ggplot] makes it easy to combine  
data from multiple sources". Since I use ggplot2 as much as I can  
(thanks it's really really great!) I thought I would try producing  
such a plot with ggplot2.

NB: If this is possible/easy with an other plotting package please  
let me know. I am not looking for something specific to maps but  
rather for a generic mechanism to throw several pieces of data to a  
graph and have the plotting routine take care of setting up axes that  
will fit all data on the same scale.

So, now for the ggplot2 part. I have two data sources: the  
coordinates of the coastlines in a region of interest and the  
coordinated of sampling stations in a subset of this region. I want  
to plot the coastline as a line and the stations as points, on the  
same graph. I can plot them independently easily:

p1 = ggplot(coast,aes(x=lon,y=lat)) + geom_path() + coord_equal(ratio=1)
p1$aspect.ratio = 1

p2 = ggplot(coords,aes(x=lon,y=lat)) + geom_point() + coord_equal 
(ratio=1)
p2$aspect.ratio = 1

but I cannot find how to combine the two graphs. I suspect this has  
probably to be done via different layers but I really can't find how.  
In particular, I would like to know how to deal with the scales: can  
ggplot take care of plotting the two datasets on the same coordinates  
system or do I have to manually record the maximal range of x and y  
and force ggplot to use this on both layers, as I did with base  
graphics? (of course I would prefer the former ;) ).

To test it further with real data, here is my code and data:
	http://jo.irisson.free.fr/dropbox/test_ggplot2.zip

A small additional precision: I would like the two datasets to stay  
separated. Indeed I could probably combine them and plot everything  
in one step by clever use of ggplot arguments. However this is just a  
simple example and I would like to add more in the future (like  
trajectories at each station, points proportional to some value at  
each station etc.) so I really want the different data sources to be  
separated and to produce the plot in several steps, otherwise it will  
soon become too complicated to manage.

Thank you very much in advance for your help.

JiHO
---
http://jo.irisson.free.fr/


From karin.lagesen at medisin.uio.no  Thu Sep 27 13:08:32 2007
From: karin.lagesen at medisin.uio.no (Karin Lagesen)
Date: Thu, 27 Sep 2007 13:08:32 +0200
Subject: [R] problem loading hexbin associated package colorspace
Message-ID: <ypx64phg4b7z.fsf@uracil.uio.no>


I have lots of data that I need to display, and I think hexbin would
be good for it.

However, I cannot load one of the requried packages associated with
the hexbin package:

> library(hexbin)
Loading required package: colorspace
Error in loadNamespace(package, c(which.lib.loc, lib.loc), keep.source = keep.source) : 
        in 'colorspace' methods for export not found: [, coords, plot
Error: package 'colorspace' could not be loaded
> library(colorspace)
Error in loadNamespace(package, c(which.lib.loc, lib.loc), keep.source = keep.source) : 
        in 'colorspace' methods for export not found: [, coords, plot
Error: package/namespace load failed for 'colorspace'
> sessionInfo()
R version 2.5.1 (2007-06-27) 
x86_64-unknown-linux-gnu 

locale:
C

attached base packages:
[1] "grid"      "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[7] "methods"   "base"     

other attached packages:
 lattice 
"0.14-9" 
> 

The colorspace package is version 0.95.

Is this an error with my system, this code, or something else?

Thanks for having this list btw...:)

Karin
-- 
Karin Lagesen, PhD student
karin.lagesen at medisin.uio.no
http://folk.uio.no/karinlag


From ripley at stats.ox.ac.uk  Thu Sep 27 13:44:56 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 27 Sep 2007 12:44:56 +0100 (BST)
Subject: [R] problem loading hexbin associated package colorspace
In-Reply-To: <ypx64phg4b7z.fsf@uracil.uio.no>
References: <ypx64phg4b7z.fsf@uracil.uio.no>
Message-ID: <Pine.LNX.4.64.0709271235200.26730@gannet.stats.ox.ac.uk>

Where does this 'hexbin' package come from?  The one I have installed (and 
the only one I found) is from BioC, and that does not depend on 
colorspace:

Description:

Package:       hexbin
Version:       1.10.0
Date:          2006-09-28
Depends:       R (>= 2.0), methods, grid, lattice

That said, something is wrong with your installation of colorspace, so I 
suggest you reinstall it.


On Thu, 27 Sep 2007, Karin Lagesen wrote:

>
> I have lots of data that I need to display, and I think hexbin would
> be good for it.
>
> However, I cannot load one of the requried packages associated with
> the hexbin package:
>
>> library(hexbin)
> Loading required package: colorspace
> Error in loadNamespace(package, c(which.lib.loc, lib.loc), keep.source = keep.source) :
>        in 'colorspace' methods for export not found: [, coords, plot
> Error: package 'colorspace' could not be loaded
>> library(colorspace)
> Error in loadNamespace(package, c(which.lib.loc, lib.loc), keep.source = keep.source) :
>        in 'colorspace' methods for export not found: [, coords, plot
> Error: package/namespace load failed for 'colorspace'
>> sessionInfo()
> R version 2.5.1 (2007-06-27)
> x86_64-unknown-linux-gnu
>
> locale:
> C
>
> attached base packages:
> [1] "grid"      "stats"     "graphics"  "grDevices" "utils"     "datasets"
> [7] "methods"   "base"
>
> other attached packages:
> lattice
> "0.14-9"
>>
>
> The colorspace package is version 0.95.
>
> Is this an error with my system, this code, or something else?
>
> Thanks for having this list btw...:)
>
> Karin
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tomfool at as220.org  Thu Sep 27 13:43:47 2007
From: tomfool at as220.org (tom sgouros)
Date: Thu, 27 Sep 2007 07:43:47 -0400
Subject: [R] curvilinear grid
In-Reply-To: <Pine.LNX.4.64.0709270142430.9003@illuminati.stderr.org> 
References: <20070927024253.99676FAC9EF@as220.org>
	<f8e6ff050709262055s42297681oeed2f3cdf4fb09ff@mail.gmail.com>
	<20070927045701.E13CDFAC9F8@as220.org>
	<Pine.LNX.4.64.0709270142430.9003@illuminati.stderr.org>
Message-ID: <20070927114347.13C98FAC9F8@as220.org>


elw at stderr.org wrote:

> Ask on R-sig-geo?  I haven't seen a query from you come through over
> there... and that would be the logical place to ask questions about
> the sp package and similar bits...
> 

No query from me over there because I managed to overlook it.  Many
thanks.

 -tom



-- 
 ------------------------
 tomfool at as220 dot org
 http://sgouros.com  
 http://whatcheer.net


From ripley at stats.ox.ac.uk  Thu Sep 27 13:55:48 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 27 Sep 2007 12:55:48 +0100 (BST)
Subject: [R] different colors for two wireframes in same plot
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC0574B927@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC0574B927@DJFPOST01.djf.agrsci.dk>
Message-ID: <Pine.LNX.4.64.0709271103240.18285@auk.stats>

On Thu, 27 Sep 2007, Frede Aakmann T?gersen wrote:

> You can obtain some transparency setting the alpha transparency. This is 
> device dependent though. Using the pdf device you can do this obtaining 
> transparency of both surfaces (the version must be at least 1.4 for 
> semitransparent output to be understood):

In any recent version of R ?pdf says

  version: a string describing the PDF version that will be required to
           view the output.  This is a minimum, and will be increased
           (with a warning) if necessary.

so you don't actually _need_ to specify the version.  (This came up in a 
thread about ggplot2 and Sweave as well.)

>
>
> pdf("test.pdf",version="1.4")
> wireframe(z ~ x * y, data = g, groups = gr,
>          scales = list(arrows = FALSE),
>          drape = TRUE, colorkey = TRUE,
>          screen = list(z = 30, x = -60),
>          par.settings = list(regions=list(alpha=0.75)))
> dev.off()
>
> See ?wireframe for the "at, col.regions, alpha.regions" arguments.
>
> Does this suffice?
>
>
> Med venlig hilsen
> Frede Aakmann T?gersen
>
>
>
>
>> -----Oprindelig meddelelse-----
>> Fra: r-help-bounces at r-project.org
>> [mailto:r-help-bounces at r-project.org] P? vegne af marcg
>> Sendt: 27. september 2007 09:22
>> Til: r-help at stat.math.ethz.ch
>> Emne: [R] different colors for two wireframes in same plot
>>
>> Hello R,
>>
>> According to:
>>
>> g <- expand.grid(x = 1:10, y = 5:15, gr = 1:2) g$z <-
>> log((g$x^g$g + g$y^2) * g$gr) wireframe(z ~ x * y, data = g,
>> groups = gr,
>>           scales = list(arrows = FALSE),
>>           drape = TRUE, colorkey = TRUE,
>>           screen = list(z = 30, x = -60))
>>
>> i have two wireframes in one plot.
>>
>> How could i change the color of the top - one to transparent
>> (or only the grid). I want to give insight to the lower layer.
>>
>> Could one make an if-statment like (if gr==1 do drape=F or
>> color=none) if gr=2 do drape=T, colorkey=T)
>>
>> Thanks for your help
>>
>> Marc
>>
>> --
>> Psssst! Schon vom neuen GMX MultiMessenger geh?rt?
>> Der kanns mit allen: http://www.gmx.net/de/go/multimessenger
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From f.harrell at vanderbilt.edu  Thu Sep 27 14:32:00 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 27 Sep 2007 07:32:00 -0500
Subject: [R] Arrows Pointing to Curve
In-Reply-To: <200709261610.53923.dylan.beaudette@gmail.com>
References: <46FAE639.6030104@gmail.com>
	<200709261610.53923.dylan.beaudette@gmail.com>
Message-ID: <46FBA2C0.5070101@vanderbilt.edu>

Dylan Beaudette wrote:
> On Wednesday 26 September 2007, Lorenzo Isella wrote:
>> Dear All,
>> I hope this is not a FAQ, but my online research was not fruitful.
>> Consider a standard 2D plot generated with the "plot" command.
>> I would like to introduce inside the graph some text with an arrow
>> pointing to a specific position of the plotted function.
>> Is this doable in R? Can anyone provide me with an example?
>> Many thanks
>>
>> Lorenzo
> 
> ?arrows
> 

The labcurve function in the Hmisc package has an option to label curves 
in that way at the point of maximum separation.

Frank

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From f.harrell at vanderbilt.edu  Thu Sep 27 14:32:59 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 27 Sep 2007 07:32:59 -0500
Subject: [R] R: anova.Design
In-Reply-To: <1a0116140709261734n5bfc6214xcc9d59e90240288c@mail.gmail.com>
References: <1a0116140709261734n5bfc6214xcc9d59e90240288c@mail.gmail.com>
Message-ID: <46FBA2FB.2040901@vanderbilt.edu>

John Smith wrote:
> Dear All:
> 
> I tried to replicate a case study described by Prof. Harrell in Chapter 7 of
> his Regression Modeling Strategies book, but failed on using anova.Design to
> reproduce his table 7.1,  Following is the code:
> 
> rm(list=ls())
> library(Hmisc)
> library(Design)
> 
> getHdata(counties)
> counties$older <- counties$age6574 + counties$age75
> label(counties$older) <- '% age >= 65, 1990'
> counties$pdensity <- log10(counties$pop.density+1)
> label(counties$pdensity) <- 'log 10 of 1992 pop per 1990 miles^2'
> 
> dd <- datadist(counties)
> options(datadist='dd')
> 
> f <- ols(democrat ~ rcs(pdensity,4) + rcs(pop.change,3) + rcs(older,3) +
> crime + rcs(college,5)
>          + rcs(income,4) + rcs(college,5) %ia% rcs(income,4) + rcs(farm,3) +
> rcs(white,5) +
>          rcs(turnout,3), data=counties)
> f
> 
> an <- anova(f)
> 
> 
> and the error message reads as:
> 
> Error in solvet(cov[idx, idx], coef[idx], tol = tol) :
>     apparently singular matrix
> 
> Does anyone have a clue?

add the tol argument to the anova call, e.g. tol=1e-13

Frank




-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From hdazizi at gmail.com  Thu Sep 27 14:38:47 2007
From: hdazizi at gmail.com (Hadi Darzian Azizi)
Date: Thu, 27 Sep 2007 14:38:47 +0200
Subject: [R] Confidence interval
Message-ID: <db3cad340709270538n4371460fl547a88d6148591f4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/ebff39c6/attachment.pl 

From petr.pikal at precheza.cz  Thu Sep 27 14:40:59 2007
From: petr.pikal at precheza.cz (Petr PIKAL)
Date: Thu, 27 Sep 2007 14:40:59 +0200
Subject: [R] Odp:  nonlinear regression
In-Reply-To: <36d691950709262246g58b02d1dwadc8b671c0353832@mail.gmail.com>
Message-ID: <OFF1435B15.7643665D-ONC1257363.0045773D-C1257363.0045A9DB@precheza.cz>

Hi

Have a look at package nlme and maybe also you should consult a 
Pinheiro&Bates book about nonlinear mixed effects models.

Regards

Petr
petr.pikal at precheza.cz

r-help-bounces at r-project.org napsal dne 27.09.2007 07:46:03:

> I would appreciate some suggestions about  nonlinear regression 
available in
> R ... possible methods and plenty of worked out examples ....
> I have a bunch of noisy curves representing breathing amplitude from 
medical
> physics experiments recoding patients' breathing tracks in form of
> Amplitude, Phase, Time, some flags controlling the data validity.
> A variable number of successive breathing cycles were recorded.
> 
> Thank you in advance,
> -- 
> Maura E.M
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From paulandpen at optusnet.com.au  Thu Sep 27 14:53:24 2007
From: paulandpen at optusnet.com.au (paulandpen)
Date: Thu, 27 Sep 2007 22:53:24 +1000
Subject: [R] query on "random.seed" not found error in code
References: <20070927072157.13720@gmx.net>
Message-ID: <002b01c80105$64ab20a0$fcfc31d2@superpaul>

Hi,

I am trying to use AlgDesign and am partially successful

Two lines of code are taken from the help file
1. Line 1 (below) works fine
> dat<-gen.factorial(levels=3,nVars=3,varNames=c("A","B","C"))

2. Line 2 (below) does not work fine
> desD<-optFederov(~quad(A,B,C),dat,nTrials=14,eval=TRUE)

Here is the result I get

Error in optFederov(~quad(A, B, C), dat, nTrials = 14, eval = TRUE) :
    object ".Random.seed" not found

What do i need to do, to introduce this object into the process?

Thanks in advance

Paul



----- Original Message ----- 
From: "marcg" <mdgi at gmx.ch>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, September 27, 2007 5:21 PM
Subject: [R] different colors for two wireframes in same plot


> Hello R,
>
> According to:
>
> g <- expand.grid(x = 1:10, y = 5:15, gr = 1:2)
> g$z <- log((g$x^g$g + g$y^2) * g$gr)
> wireframe(z ~ x * y, data = g, groups = gr,
>          scales = list(arrows = FALSE),
>          drape = TRUE, colorkey = TRUE,
>          screen = list(z = 30, x = -60))
>
> i have two wireframes in one plot.
>
> How could i change the color of the top - one to transparent (or only the 
> grid). I want to give insight to the lower layer.
>
> Could one make an if-statment like (if gr==1 do drape=F or color=none) if 
> gr=2 do drape=T, colorkey=T)
>
> Thanks for your help
>
> Marc
>
> -- 
> Psssst! Schon vom neuen GMX MultiMessenger geh?rt?
> Der kanns mit allen: http://www.gmx.net/de/go/multimessenger
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From therneau at mayo.edu  Thu Sep 27 15:03:52 2007
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 27 Sep 2007 08:03:52 -0500 (CDT)
Subject: [R] ReL plot(cox.zph())
Message-ID: <200709271303.l8RD3qF26699@hsrnfs-101.mayo.edu>

You report an error message:

> plot(zph.revasFit[1])
Error in plot.window(xlim, ylim, log, asp, ...) : 
        need finite 'ylim' values

I have never seen this error before, and I cannot guess what causes it.  You
need to provide more information, and likely a small data set that produces
the problem.  Perhaps you have an x variable that is a constant?

	Terry Therneau


From karin.lagesen at medisin.uio.no  Thu Sep 27 15:04:28 2007
From: karin.lagesen at medisin.uio.no (Karin Lagesen)
Date: Thu, 27 Sep 2007 15:04:28 +0200
Subject: [R] How to choose name for package during install (was:Re: problem
	loading hexbin associated package colorspace)
In-Reply-To: <Pine.LNX.4.64.0709271235200.26730@gannet.stats.ox.ac.uk> (Brian
	Ripley's message of "Thu, 27 Sep 2007 12:44:56 +0100 (BST)")
References: <ypx64phg4b7z.fsf@uracil.uio.no>
	<Pine.LNX.4.64.0709271235200.26730@gannet.stats.ox.ac.uk>
Message-ID: <ypx6tzpg2rab.fsf_-_@uracil.uio.no>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> Where does this 'hexbin' package come from?  The one I have installed
> (and the only one I found) is from BioC, and that does not depend on
> colorspace:
>
> Description:
>
> Package:       hexbin
> Version:       1.10.0
> Date:          2006-09-28
> Depends:       R (>= 2.0), methods, grid, lattice

I have now discovered that I had an old hexbin version installed, one
that did require colorspace. I am now trying to install the 1.10
version, however, I cannot get it properly loaded since library grabs
the first one in the list. So now for my next question:

During R CMD INSTALL, how do I specify that a package should not just
be named "hexbin" but for instance "hexbin_1.10" so that I can
actually tell library to get the correct one. (this seems to me to be
the way the library help file tells me that I should solve this
problem).

> That said, something is wrong with your installation of colorspace, so
> I suggest you reinstall it.

Reinstalled, does still not load properly:

alanine[15:01]:~/work/rna_comparison/scripts/rpackages> cat colorspace/DESCRIPTION 
Package: colorspace
Version: 0.95
Date: 2006-11-16
Title: Colorspace Manipulation
Author: Ross Ihaka <ihaka at stat.auckland.ac.nz>
Maintainer: Ross Ihaka <ihaka at stat.auckland.ac.nz>
Depends: R (>= 2.0.0), methods
Description: Carries out mapping between assorted color spaces.
License: BSD
URL: http://www.r-project.org
LazyLoad: yes
Packaged: Thu Nov 16 11:47:26 2006; ihaka
Built: R 2.5.1; x86_64-unknown-linux-gnu; 2007-09-27 12:58:16; unix
alanine[15:02]:~/work/rna_comparison/scripts/rpackages> 

> library(colorspace)
Error in loadNamespace(package, c(which.lib.loc, lib.loc), keep.source = keep.source) : 
        in 'colorspace' methods for export not found: [, coords, plot
Error: package/namespace load failed for 'colorspace'
> 


Karin
-- 
Karin Lagesen, PhD student
karin.lagesen at medisin.uio.no
http://folk.uio.no/karinlag


From h.wickham at gmail.com  Thu Sep 27 15:05:12 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 27 Sep 2007 08:05:12 -0500
Subject: [R] curvilinear grid
In-Reply-To: <20070927045701.E13CDFAC9F8@as220.org>
References: <20070927024253.99676FAC9EF@as220.org>
	<f8e6ff050709262055s42297681oeed2f3cdf4fb09ff@mail.gmail.com>
	<20070927045701.E13CDFAC9F8@as220.org>
Message-ID: <f8e6ff050709270605m5f87708bv41cdb6e78b3a064c@mail.gmail.com>

On 9/26/07, tom sgouros <tomfool at as220.org> wrote:
>
> hadley wickham <h.wickham at gmail.com> wrote:
>
> > You might be able to do this with the ggplot2 package - see for
> > example http://had.co.nz/ggplot2/coord_map.html, which shows plots on
> > map coordinate systems.  Because the design of ggplot2 means the
> > coordinate system and geom (eg. points vs tiles) operate
> > independently, you can draw image plots
> > (http://had.co.nz/ggplot2/geom_tile.html) in any coordinate system.
>
> These aren't quite what I have in mind.
>
> > Can you provide more details about your curvilinear coordinate system?
>
> The idea is that you're modeling an irregular shaped object, a body of
> water, a river or estuary, say.  It's fairly common practice to use a
> grid squished and rotated so that the main flow is along one axis, and
> the other axis spans the flow in most spots.  So there is a single
> transformation that gets you from a rectangular grid to the shape of
> your estuary, but there isn't a tidy analytical way to describe it, like
> there is with a map projection.  Instead there is an x and y for each
> grid point, and the cell dimensions vary all over the place.

Ah, so you have grid quads points defined by the coordinates of their
corners?   You should be able to use the polygon geom in ggplot2 - if
you provided some example data I could get you started.

Hadley
-- 
http://had.co.nz/


From tchur at optushome.com.au  Thu Sep 27 15:08:22 2007
From: tchur at optushome.com.au (Tim Churches)
Date: Thu, 27 Sep 2007 23:08:22 +1000
Subject: [R] sprucing up the R homepage
In-Reply-To: <18171.22975.797963.986763@stat.math.ethz.ch>
References: <200709260405.l8Q45B3i014618@mail04.syd.optusnet.com.au>	<Pine.LNX.4.64.0709260632370.9274@illuminati.stderr.org>	<20070926132219.GB318@web15.webfaction.com>	<Pine.LNX.4.64.0709261120570.18641@illuminati.stderr.org>	<46FB49F1.8090904@stat.auckland.ac.nz>
	<18171.22975.797963.986763@stat.math.ethz.ch>
Message-ID: <46FBAB46.9060400@optushome.com.au>

Martin Maechler wrote:
>>>>>> "Paul" == Paul Murrell <paul at stat.auckland.ac.nz>
>>>>>>     on Thu, 27 Sep 2007 08:13:05 +0200 writes:
> 
>     Paul> Hi
>     Paul> elw at stderr.org wrote:
>     >> 
>     >> 
>     >>> So I applied my corrected margins to Tim's Cairo trick and voila:
>     >>> http://www.broad.mit.edu/~finnyk/Rlogo_swiss.png
>     >>> This is hands-down the best version, in my opinion!
>     >> 
>     >> Yes, it is definitely much nicer than the version on www.r-project.org 
>     >> now.  :-)
> 
> 
>     Paul> Much nicer.  Thanks guys!
> 
> Thanks indeed!
> 
> 
>     Paul> Before we update the homepage, we should probably just
>     Paul> check with the original "artist" (Eric Lecoutre,
>     Paul> cc'ed) and we would need a description of the final
>     Paul> technique you used to add as a comment to the code
>     Paul> "behind" the image.
> 
> Yes, that was my "concern" too. After all, with R (and Sweave
> and ...) advocating ``reproducible research'' in many ways,
> I'd very much like a reproducible image there; we can live with
> using non-R code for post processing (did I correctly get that you used
> Imagemagick derived utilities)..

No, no post-processing. It just uses the Cairo device driver for R,
which is a library available on CRAN (highy recommended). The only other
change was some minor changes to margins in teh R code itself.

Tim C


From murdoch at stats.uwo.ca  Thu Sep 27 15:28:58 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 27 Sep 2007 09:28:58 -0400
Subject: [R] query on "random.seed" not found error in code
In-Reply-To: <002b01c80105$64ab20a0$fcfc31d2@superpaul>
References: <20070927072157.13720@gmx.net>
	<002b01c80105$64ab20a0$fcfc31d2@superpaul>
Message-ID: <46FBB01A.1020306@stats.uwo.ca>

On 9/27/2007 8:53 AM, paulandpen wrote:
> Hi,
> 
> I am trying to use AlgDesign and am partially successful
> 
> Two lines of code are taken from the help file
> 1. Line 1 (below) works fine
>> dat<-gen.factorial(levels=3,nVars=3,varNames=c("A","B","C"))
> 
> 2. Line 2 (below) does not work fine
>> desD<-optFederov(~quad(A,B,C),dat,nTrials=14,eval=TRUE)
> 
> Here is the result I get
> 
> Error in optFederov(~quad(A, B, C), dat, nTrials = 14, eval = TRUE) :
>     object ".Random.seed" not found
> 
> What do i need to do, to introduce this object into the process?

.Random.seed is created when you first call a random number generator. 
So this code is assuming it's not the first random thing in a session.

You can work around this bug by something like

runif(1)

before executing the code; that will create your copy of .Random.seed 
and things will work.

The package shouldn't assume .Random.seed exists, e.g. replace the line

     seed <- .Random.seed

with

     if (!exists(.Random.seed)) runif(1)
     seed <- .Random.seed

I've cc'd Bob Wheeler to let him know about this.

Duncan Murdoch


> 
> Thanks in advance
> 
> Paul
> 
> 
> 
> ----- Original Message ----- 
> From: "marcg" <mdgi at gmx.ch>
> To: <r-help at stat.math.ethz.ch>
> Sent: Thursday, September 27, 2007 5:21 PM
> Subject: [R] different colors for two wireframes in same plot
> 
> 
>> Hello R,
>>
>> According to:
>>
>> g <- expand.grid(x = 1:10, y = 5:15, gr = 1:2)
>> g$z <- log((g$x^g$g + g$y^2) * g$gr)
>> wireframe(z ~ x * y, data = g, groups = gr,
>>          scales = list(arrows = FALSE),
>>          drape = TRUE, colorkey = TRUE,
>>          screen = list(z = 30, x = -60))
>>
>> i have two wireframes in one plot.
>>
>> How could i change the color of the top - one to transparent (or only the 
>> grid). I want to give insight to the lower layer.
>>
>> Could one make an if-statment like (if gr==1 do drape=F or color=none) if 
>> gr=2 do drape=T, colorkey=T)
>>
>> Thanks for your help
>>
>> Marc
>>
>> -- 
>> Psssst! Schon vom neuen GMX MultiMessenger geh?rt?
>> Der kanns mit allen: http://www.gmx.net/de/go/multimessenger
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From paulandpen at optusnet.com.au  Thu Sep 27 15:29:18 2007
From: paulandpen at optusnet.com.au (paulandpen)
Date: Thu, 27 Sep 2007 23:29:18 +1000
Subject: [R] query on "random.seed" not found error in code
References: <20070927072157.13720@gmx.net>
	<002b01c80105$64ab20a0$fcfc31d2@superpaul>
	<46FBB01A.1020306@stats.uwo.ca>
Message-ID: <005501c8010a$6ee9dca0$fcfc31d2@superpaul>

Duncan,

Worked like a charm.......

Cheers Paul


----- Original Message ----- 
From: "Duncan Murdoch" <murdoch at stats.uwo.ca>
To: "paulandpen" <paulandpen at optusnet.com.au>
Cc: <r-help at stat.math.ethz.ch>; "Bob Wheeler" <bwheeler at echip.com>
Sent: Thursday, September 27, 2007 11:28 PM
Subject: Re: [R] query on "random.seed" not found error in code


> On 9/27/2007 8:53 AM, paulandpen wrote:
>> Hi,
>>
>> I am trying to use AlgDesign and am partially successful
>>
>> Two lines of code are taken from the help file
>> 1. Line 1 (below) works fine
>>> dat<-gen.factorial(levels=3,nVars=3,varNames=c("A","B","C"))
>>
>> 2. Line 2 (below) does not work fine
>>> desD<-optFederov(~quad(A,B,C),dat,nTrials=14,eval=TRUE)
>>
>> Here is the result I get
>>
>> Error in optFederov(~quad(A, B, C), dat, nTrials = 14, eval = TRUE) :
>>     object ".Random.seed" not found
>>
>> What do i need to do, to introduce this object into the process?
>
> .Random.seed is created when you first call a random number generator. So 
> this code is assuming it's not the first random thing in a session.
>
> You can work around this bug by something like
>
> runif(1)
>
> before executing the code; that will create your copy of .Random.seed and 
> things will work.
>
> The package shouldn't assume .Random.seed exists, e.g. replace the line
>
>     seed <- .Random.seed
>
> with
>
>     if (!exists(.Random.seed)) runif(1)
>     seed <- .Random.seed
>
> I've cc'd Bob Wheeler to let him know about this.
>
> Duncan Murdoch
>
>
>>
>> Thanks in advance
>>
>> Paul
>>
>>
>>
>> ----- Original Message ----- 
>> From: "marcg" <mdgi at gmx.ch>
>> To: <r-help at stat.math.ethz.ch>
>> Sent: Thursday, September 27, 2007 5:21 PM
>> Subject: [R] different colors for two wireframes in same plot
>>
>>
>>> Hello R,
>>>
>>> According to:
>>>
>>> g <- expand.grid(x = 1:10, y = 5:15, gr = 1:2)
>>> g$z <- log((g$x^g$g + g$y^2) * g$gr)
>>> wireframe(z ~ x * y, data = g, groups = gr,
>>>          scales = list(arrows = FALSE),
>>>          drape = TRUE, colorkey = TRUE,
>>>          screen = list(z = 30, x = -60))
>>>
>>> i have two wireframes in one plot.
>>>
>>> How could i change the color of the top - one to transparent (or only 
>>> the grid). I want to give insight to the lower layer.
>>>
>>> Could one make an if-statment like (if gr==1 do drape=F or color=none) 
>>> if gr=2 do drape=T, colorkey=T)
>>>
>>> Thanks for your help
>>>
>>> Marc
>>>
>>> -- 
>>> Psssst! Schon vom neuen GMX MultiMessenger geh?rt?
>>> Der kanns mit allen: http://www.gmx.net/de/go/multimessenger
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From joseph.yarmus at oracle.com  Thu Sep 27 15:56:11 2007
From: joseph.yarmus at oracle.com (Joe Yarmus)
Date: Thu, 27 Sep 2007 09:56:11 -0400
Subject: [R] AIC questions
Message-ID: <46FBB67B.4000808@oracle.com>

Digging into the R-code behind AIC for gaussian family models, I see:
AIC = nobs * (log(dev/nobs * 2 * pi) + 1) + 2 - sum(log(wt)) + 2 * p
dev = sum(wt * (y - mean(y))^2
For the unweighted case, this translates directly to -2LL with the 
penalty number of parameters including both intercept and error term (as 
represented by the constant + 2) and the unknown sigma-squared = sum((y 
- mean(y)^2)/ nobs (rather than nobs-1). However, with weights, I am at 
a loss to understand the expression, because, given
-2LL = nobs * (log(2 * pi * sigma^2) + sum(wt * (y - mean(y))^2/sigma^2
if sigma^2 = sum(wt * (y - mean(y))/sum(wt)
then
-2LL = nobs * (log(2 * pi *dev/nobs) + log(nobs) - log(sum(wt)) + sum(wt)
so if wt = 1 all is fine because
-2LL = nobs * (log(2 * pi * dev/nobs) + 1)
What am I missing? Thanks!

   -joe yarmus


From adrian at stats.gla.ac.uk  Thu Sep 27 11:40:39 2007
From: adrian at stats.gla.ac.uk (Adrian Bowman)
Date: Thu, 27 Sep 2007 10:40:39 +0100
Subject: [R] [R-pkgs] New version (2.2) of the sm package
Message-ID: <1EA97626-87BD-4ED0-BD9B-25C350AE0CAB@stats.gla.ac.uk>

The sm package (by Adrian Bowman and Adelchi Azzalini) implements a
variety of nonparametric smoothing techniques, centred on nonparametric
regression for one or two covariates and density estimation for up to
three variables.  A new version of the package is now available on CRAN.

In an earlier unannounced version (2.1), a variety of methods of  
bandwidth
selection were added, with default settings to allow particularly simple
function calls.

In the new version (2.2), interactive control panels are available for
the main functions (sm.regression and sm.density), using the rpanel  
package
(which itself is based on tcltk).  In addition, the rgl package is used
to provide rotatable three-dimensional plots, where these are  
appropriate.
The details of how these functions operate are available in the help  
files
(including the help file for sm.options) and in the examples.  However,
the broad principle is that a control panel is activated by adding the
argument
       panel = TRUE
and an rgl plot is created by adding the argument
       display = "rgl"

Adrian Bowman

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From rocchini at unisi.it  Thu Sep 27 16:09:57 2007
From: rocchini at unisi.it (rocchini at unisi.it)
Date: Thu, 27 Sep 2007 16:09:57 +0200
Subject: [R] moran's i
Message-ID: <46FBB9B5.3060109@unisi.it>

i would like to perform moran's analysis with r...
thanks
duccio


From jrkrideau at yahoo.ca  Thu Sep 27 16:21:57 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 27 Sep 2007 10:21:57 -0400 (EDT)
Subject: [R] moran's i
In-Reply-To: <46FBB9B5.3060109@unisi.it>
Message-ID: <103261.16179.qm@web32801.mail.mud.yahoo.com>

moran {package: spdep} ?


--- "rocchini at unisi.it" <rocchini at unisi.it> wrote:

> i would like to perform moran's analysis with r...
> thanks
> duccio
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From stef at biostatistics.it  Thu Sep 27 16:22:43 2007
From: stef at biostatistics.it (Stefano Calza)
Date: Thu, 27 Sep 2007 16:22:43 +0200
Subject: [R] moran's i
In-Reply-To: <46FBB9B5.3060109@unisi.it>
References: <46FBB9B5.3060109@unisi.it>
Message-ID: <20070927142243.GF3415@med.unibs.it>

Have a look at

library(ape)

?Moran.I


Ciao

Stefano


On Thu, Sep 27, 2007 at 04:09:57PM +0200, rocchini a unisi.it wrote:
<rocchini>i would like to perform moran's analysis with r...
<rocchini>thanks
<rocchini>duccio
<rocchini>
<rocchini>______________________________________________
<rocchini>R-help a r-project.org mailing list
<rocchini>https://stat.ethz.ch/mailman/listinfo/r-help
<rocchini>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
<rocchini>and provide commented, minimal, self-contained, reproducible code.


From stef at biostatistics.it  Thu Sep 27 16:22:43 2007
From: stef at biostatistics.it (Stefano Calza)
Date: Thu, 27 Sep 2007 16:22:43 +0200
Subject: [R] moran's i
In-Reply-To: <46FBB9B5.3060109@unisi.it>
References: <46FBB9B5.3060109@unisi.it>
Message-ID: <20070927142243.GF3415@med.unibs.it>

Have a look at

library(ape)

?Moran.I


Ciao

Stefano


On Thu, Sep 27, 2007 at 04:09:57PM +0200, rocchini a unisi.it wrote:
<rocchini>i would like to perform moran's analysis with r...
<rocchini>thanks
<rocchini>duccio
<rocchini>
<rocchini>______________________________________________
<rocchini>R-help a r-project.org mailing list
<rocchini>https://stat.ethz.ch/mailman/listinfo/r-help
<rocchini>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
<rocchini>and provide commented, minimal, self-contained, reproducible code.


From Max.Kuhn at pfizer.com  Thu Sep 27 16:24:26 2007
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Thu, 27 Sep 2007 10:24:26 -0400
Subject: [R] sprucing up the R homepage
In-Reply-To: <2E3C91D9-7429-4E9D-8C74-ABB2456D7FF6@math.uni-augsburg.de>
Message-ID: <71257D09F114DA4A8E134DEAC70F25D309A58F33@groamrexm03.amer.pfizer.com>

Antony,

> be drawn with R, all applied to the swiss fertility dataset.  Are  
> these the kinds of graphics we would want to draw in a real  
> analysis? 

You make a good point about what would need to be done for these data,
that wasn't the objective of the graphic. 

I couldn't find the original posting, but there was a call for graphics
that would best represent the visualization capabilities of R. 

Look at the bright side: at least there isn't a pie chart in the image
:-)

Max


From stat700004 at yahoo.co.in  Thu Sep 27 15:36:57 2007
From: stat700004 at yahoo.co.in (stat stat)
Date: Thu, 27 Sep 2007 14:36:57 +0100 (BST)
Subject: [R] Expressing number in percentage
Message-ID: <518582.75733.qm@web94415.mail.in2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/bd8c2520/attachment.pl 

From marianabotelho.r at gmail.com  Thu Sep 27 16:45:15 2007
From: marianabotelho.r at gmail.com (Mariana Botelho)
Date: Thu, 27 Sep 2007 11:45:15 -0300
Subject: [R] TukeyHSD doubts
Message-ID: <ae0a9fe10709270745x40c33407mf4eada1eb9b6e6bf@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado associado...
Nome: n?o dispon?vel
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/5ae72daa/attachment.pl 

From c.declercq at orsnpdc.org  Thu Sep 27 16:52:11 2007
From: c.declercq at orsnpdc.org (Christophe DECLERCQ)
Date: Thu, 27 Sep 2007 16:52:11 +0200
Subject: [R] moran's i
Message-ID: <892792C268EB89458F1FADC109779A671D1659@ors-npdc.orsnpdc.local>

> De : r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] De la part de rocchini at unisi.it
> Envoy? : jeudi 27 septembre 2007 16:16
> 
> i would like to perform moran's analysis with r...
> thanks
> duccio

The 'spdep' package has Moran's index (and many other things) if that is what you want.

You could also look at the spatial 'Task View' on CRAN: http://cran.r-project.org/src/contrib/Views/Spatial.html 

Christophe
--
Christophe Declercq, MD
Observatoire r?gional de la sant? Nord-Pas-de-Calais
235, avenue de la recherche BP 86
F-59373 LOOS C?dex
Phone 33 3 20 15 49 24
Fax 33 3 20 15 10 46
E-mail c.declercq at orsnpdc.org
  

> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


From marc_schwartz at comcast.net  Thu Sep 27 16:56:05 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 27 Sep 2007 09:56:05 -0500
Subject: [R] Expressing number in percentage
In-Reply-To: <518582.75733.qm@web94415.mail.in2.yahoo.com>
References: <518582.75733.qm@web94415.mail.in2.yahoo.com>
Message-ID: <1190904965.3595.1.camel@Bellerophon.localdomain>

On Thu, 2007-09-27 at 14:36 +0100, stat stat wrote:
> I am wondering if there is any procedure to write a particular value
> in Percentage format, still maintaining it's numeric character. for
> example I want to write '.33' as '33%' 

See ?sprintf

> sprintf("%.0f%%", .33 * 100)
[1] "33%"


Note that the trailing '%' needs to be doubled to be recognized as the
character and not a format specifier.

HTH,

Marc Schwartz


From bates at stat.wisc.edu  Thu Sep 27 17:00:41 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 27 Sep 2007 10:00:41 -0500
Subject: [R] Accessing the fixed- and random-effects variance-covariance
	matrices of an nlme model
In-Reply-To: <D1DB07A2-02F2-403D-8E63-9C71B4188DCB@newcastle.ac.uk>
References: <D1DB07A2-02F2-403D-8E63-9C71B4188DCB@newcastle.ac.uk>
Message-ID: <40e66e0b0709270800u1868831n16cd1073a06358f9@mail.gmail.com>

On 9/26/07, Rob Forsyth <r.j.forsyth at newcastle.ac.uk> wrote:
> I would appreciate confirmation that the function vcov(model.nlme)
> gives the var-cov matrix of the fixed effects in an nlme model.

It gives the approximate variance-covariance matrix for the
fixed-effects parameters in the model.  (Exact variance-covariance
matrices are very difficult to evaluate for nonlinear models and even
more difficult to evaluated for nonlinear mixed-effects models.)

The documentation for the generic function vcov and some of its
methods can be accessed by

?vcov.lme


> Presumably the random-effects var-cov matrix is given by cov(ranef
> (model.nlme)?

No.  The BLUPs of the random effects (actually as Alan James described
the situation, "For a nonlinear model these are just like the BLUPs
(Best Linear Unbiased Predictors) except that they are not linear, and
they're not unbiased, and there is no clear sense in which they are
"best" but, other than that, ...") are not guaranteed to have an
observed variance-covariance matrix that corresponds to the estimate
of the variance-covariance matrix of the random effects.  These
estimates are returned by the VarCorr function.  See ?VarCorr

The implementation of VarCorr in the nlme package is not optimal in
that it returns the result as a character matrix and you need to
covert to a numeric representation if you want to do anything other
than print it out.  I prefer the implementation in the lme4 package
which returns a list of numeric matrices that are formatted by a
specific function (called formatVC but hidden in the lme4 package's
namespace) when needed.


From P.Dalgaard at biostat.ku.dk  Thu Sep 27 17:11:25 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 27 Sep 2007 17:11:25 +0200
Subject: [R] sprucing up the R homepage
In-Reply-To: <71257D09F114DA4A8E134DEAC70F25D309A58F33@groamrexm03.amer.pfizer.com>
References: <71257D09F114DA4A8E134DEAC70F25D309A58F33@groamrexm03.amer.pfizer.com>
Message-ID: <46FBC81D.9010304@biostat.ku.dk>

Kuhn, Max wrote:
> Antony,
>
>   
>> be drawn with R, all applied to the swiss fertility dataset.  Are  
>> these the kinds of graphics we would want to draw in a real  
>> analysis? 
>>     
>
> You make a good point about what would need to be done for these data,
> that wasn't the objective of the graphic. 
>
> I couldn't find the original posting, but there was a call for graphics
> that would best represent the visualization capabilities of R. 
>
>   
There was a competition in 2004, and this is the display that won.

It was deliberately designed as a "show-off" for the home page, and as
such, I don't think it can be the same sort of graphic that you'd use
for real analysis. It does have the nice feature of displaying results
of simple, yet non-trivial statistical analyses (PCA, clustering)
without requiring a lengthy explanation.

     -p

> Look at the bright side: at least there isn't a pie chart in the image
> :-)
>
> Max
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From alfreale74 at gmail.com  Thu Sep 27 17:16:05 2007
From: alfreale74 at gmail.com (Alfredo Alessandrini)
Date: Thu, 27 Sep 2007 17:16:05 +0200
Subject: [R] add a row to a data frame
Message-ID: <d2c05c5a0709270816x6d8cf499yaee0d7f90f3472dd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/22642a0e/attachment.pl 

From kuruvilla at post.harvard.edu  Thu Sep 27 17:22:08 2007
From: kuruvilla at post.harvard.edu (Finny Kuruvilla)
Date: Thu, 27 Sep 2007 10:22:08 -0500
Subject: [R] sprucing up the R homepage
In-Reply-To: <46FBAB46.9060400@optushome.com.au>
References: <200709260405.l8Q45B3i014618@mail04.syd.optusnet.com.au>
	<Pine.LNX.4.64.0709260632370.9274@illuminati.stderr.org>
	<20070926132219.GB318@web15.webfaction.com>
	<Pine.LNX.4.64.0709261120570.18641@illuminati.stderr.org>
	<46FB49F1.8090904@stat.auckland.ac.nz>
	<18171.22975.797963.986763@stat.math.ethz.ch>
	<46FBAB46.9060400@optushome.com.au>
Message-ID: <20070927152207.GA15729@web15.webfaction.com>

Tim is correct -- there was no post-processing done.  I've put the
R script that was used to generate the graphic here:

www.broad.mit.edu/~finnyk/acpclust.R

As you will see, it's essentially identical to Eric Lecoutre's
original script.  A few margins are slightly different and of course,
the Cairo library is now employed.

On my Linux machine, running "R --no-save < acpclust.R" produces the
png file that I posted earlier.

Best,
Finny Kuruvilla


On Thu, Sep 27, 2007 at 11:08:22PM +1000, Tim Churches wrote:
> Martin Maechler wrote:
> >>>>>> "Paul" == Paul Murrell <paul at stat.auckland.ac.nz>
> >>>>>>     on Thu, 27 Sep 2007 08:13:05 +0200 writes:
> > 
> >     Paul> Hi
> >     Paul> elw at stderr.org wrote:
> >     >> 
> >     >> 
> >     >>> So I applied my corrected margins to Tim's Cairo trick and voila:
> >     >>> http://www.broad.mit.edu/~finnyk/Rlogo_swiss.png
> >     >>> This is hands-down the best version, in my opinion!
> >     >> 
> >     >> Yes, it is definitely much nicer than the version on www.r-project.org 
> >     >> now.  :-)
> > 
> > 
> >     Paul> Much nicer.  Thanks guys!
> > 
> > Thanks indeed!
> > 
> > 
> >     Paul> Before we update the homepage, we should probably just
> >     Paul> check with the original "artist" (Eric Lecoutre,
> >     Paul> cc'ed) and we would need a description of the final
> >     Paul> technique you used to add as a comment to the code
> >     Paul> "behind" the image.
> > 
> > Yes, that was my "concern" too. After all, with R (and Sweave
> > and ...) advocating ``reproducible research'' in many ways,
> > I'd very much like a reproducible image there; we can live with
> > using non-R code for post processing (did I correctly get that you used
> > Imagemagick derived utilities)..
> 
> No, no post-processing. It just uses the Cairo device driver for R,
> which is a library available on CRAN (highy recommended). The only other
> change was some minor changes to margins in teh R code itself.
> 
> Tim C

-- 
Finny Kuruvilla, MD, PhD
Department of Molecular Biology, Massachusetts General Hospital
Broad Institute of Harvard and MIT
Homepage: http://www.anchorcross.org/people/kuruvilla/


From ymoisan at groupesm.com  Thu Sep 27 17:24:16 2007
From: ymoisan at groupesm.com (Yves Moisan)
Date: Thu, 27 Sep 2007 08:24:16 -0700 (PDT)
Subject: [R] Cairo on windows
Message-ID: <12923700.post@talk.nabble.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/d641dc1d/attachment.pl 

From dingjun_cn at yahoo.com  Thu Sep 27 17:34:38 2007
From: dingjun_cn at yahoo.com (Jun Ding)
Date: Thu, 27 Sep 2007 08:34:38 -0700 (PDT)
Subject: [R] A weird observation from using read.table
Message-ID: <296658.53591.qm@web81014.mail.mud.yahoo.com>

Hi Everyone, 

Recently I got puzzled by the function read.table,
even though I have used it for a long time. 

I have such a file (tmp.txt, 2 rows and 3 columns,
with a space among columns):

1 2'-PDE 4
2 3'-PDE 5

if I do:
a = read.table("tmp.txt", header = F, quote = "")
a
  V1     V2 V3
1  1 2'-PDE  4
2  2 3'-PDE  5

Everything is fine. 

However, if I do:
a = read.table("tmp.txt", header = F)
a
  V1     V2 V3
1  2 3'-PDE  5
2  1 2'-PDE  4
3  2 3'-PDE  5

I know it is related to the "quote" as the default
includes '. But how can it get one more row in the
file? Thank you very much for your help in advance!

Jun


From marc_schwartz at comcast.net  Thu Sep 27 17:41:53 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 27 Sep 2007 10:41:53 -0500
Subject: [R] add a row to a data frame
In-Reply-To: <d2c05c5a0709270816x6d8cf499yaee0d7f90f3472dd@mail.gmail.com>
References: <d2c05c5a0709270816x6d8cf499yaee0d7f90f3472dd@mail.gmail.com>
Message-ID: <1190907713.9666.5.camel@Bellerophon.localdomain>

On Thu, 2007-09-27 at 17:16 +0200, Alfredo Alessandrini wrote:
> Hi everybody,
> 
> I've a data.frame "d" like this:
> 
>           0   2    4    6    8   10   12  14  16         X0          X2
>       X4
> 1945 350  NA  NA  NA  NA  NA  NA  NA  NA  0.3848451  0.0000000 0.0000000
> 1946 408  NA  NA  NA  NA  NA  NA  NA  NA  1.4202009  0.0000000 0.0000000
> 1947 511  NA  NA  NA  NA  NA  NA  NA  NA  3.2540522  0.0000000 0.0000000
> 1948 342 215  NA  NA  NA  NA  NA  NA  NA  3.0943431  0.1452201 0.0000000
> 1949 217 259  NA  NA  NA  NA  NA  NA  NA  2.3444544  0.5606204 0.0000000
> 1950 204 322  NA  NA  NA  NA  NA  NA  NA  2.4738157  1.2847229 0.0000000
> 1951 310 369  NA  NA  NA  NA  NA  NA  NA  4.2598111  2.2732847 0.0000000
> 1952 284 254 204  NA  NA  NA  NA  NA  NA  4.4325108  2.0619404 0.1307405
> 1953 437 390 158  NA  NA  NA  NA  NA  NA  7.8102915  3.9550138 0.2809463
> 1954 444 356 343  NA  NA  NA  NA  NA  NA  9.1642771  4.4445494 1.1497632
> 1955 299 250 217  NA  NA  NA  NA  NA  NA  6.8693657  3.5971236 1.1091676
> 1956 318 280 161  NA  NA  NA  NA  NA  NA  7.9222799  4.4949908 1.0141218
> 1957 220 216 169  NA  NA  NA  NA  NA  NA  5.8526614  3.8041420 1.2397196
> 1958 208 189 133  NA  NA  NA  NA  NA  NA  5.8131025  3.5690974 1.1018225
> 1959 247 228 127  NA  NA  NA  NA  NA  NA  7.2561271  4.6042679 1.1558516
> 1960 283 259 131  NA  NA  NA  NA  NA  NA  8.7849078  5.6265453 1.2984360
> 1961 304 236 135  NA  NA  NA  NA  NA  NA  9.9974023  5.4938916 1.4508974
> 1962 215 150  96  NA  NA  NA  NA  NA  NA  7.4210859  3.6737784 1.1014173
> 1963 242 183 122  NA  NA  NA  NA  NA  NA  8.7004775  4.6734552 1.4832716
> 1964 250 194 170 230  NA  NA  NA  NA  NA  9.3745125  5.1841431 2.2228025
> 1965 201 163 164 343  NA  NA  NA  NA  NA  7.8218965  4.5385615 2.3164345
> 
> And another "X" like this :
> 
>  [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
> [1,]   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA    NA
> [2,]   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA    NA
> [3,]   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA    NA
> [4,]   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA    NA
> [5,]   NA   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA    NA
> 
> 
> If I try to add X to d, I've an error like this:
> 
> rbind(X,d)
> Errore in match.names(clabs, names(xi)) : names do not match previous names
> 
> Why?

In ?rbind under data frame methods, it clearly states:

The rbind data frame method first drops all zero-column and zero-row
arguments. (If that leaves none, it returns the first argument with
columns otherwise a zero-column zero-row data frame.) It then takes the
classes of the columns from the first data frame, and matches columns by
name (rather than by position).


You appear to be rbind()ing a matrix "X" to the data frame "d". In that
case, the data frame method is used and since "X" does not have any
column names, rbind cannot match the columns in the two objects and you
get the error message you see.

Try this instead:

  # set X's colnames to match d's
  colnames(X) <- colnames(d)

  # Now rbind()
  rbind(d, X)

HTH,

Marc Schwartz


From ehlers at math.ucalgary.ca  Thu Sep 27 17:44:09 2007
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Thu, 27 Sep 2007 09:44:09 -0600
Subject: [R] Arrows Pointing to Curve
In-Reply-To: <985016.87391.qm@web32812.mail.mud.yahoo.com>
References: <985016.87391.qm@web32812.mail.mud.yahoo.com>
Message-ID: <46FBCFC9.3090605@math.ucalgary.ca>

You might also look at ?Arrows in package IDPmisc
and ?p.arrows in package sfsmisc.

  - Peter Ehlers


> --- Lorenzo Isella <lorenzo.isella at gmail.com> wrote:
> 
>> Dear All,
>> I hope this is not a FAQ, but my online research was
>> not fruitful.
>> Consider a standard 2D plot generated with the
>> "plot" command.
>> I would like to introduce inside the graph some text
>> with an arrow 
>> pointing to a specific position of the plotted
>> function.
>> Is this doable in R? Can anyone provide me with an
>> example?
>> Many thanks
>>
>> Lorenzo
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
>


From alfreale74 at gmail.com  Thu Sep 27 18:08:49 2007
From: alfreale74 at gmail.com (Alfredo Alessandrini)
Date: Thu, 27 Sep 2007 18:08:49 +0200
Subject: [R] add a row to a data frame
In-Reply-To: <1190907713.9666.5.camel@Bellerophon.localdomain>
References: <d2c05c5a0709270816x6d8cf499yaee0d7f90f3472dd@mail.gmail.com>
	<1190907713.9666.5.camel@Bellerophon.localdomain>
Message-ID: <d2c05c5a0709270908i1d67ea82ka98197735aa56f40@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/809ffb2c/attachment.pl 

From jlaznarte at decsai.ugr.es  Thu Sep 27 19:08:08 2007
From: jlaznarte at decsai.ugr.es (Jose Luis Aznarte M.)
Date: Thu, 27 Sep 2007 19:08:08 +0200
Subject: [R] A matrix multiplication
Message-ID: <46FBE378.3080904@decsai.ugr.es>

Dear all,
    I'm having trouble using the 'apply' function to multiply some 
arrays. Let A be a 500x2 array and B a 500x3 array. I need a vector C 
which has 6 columns being the first three the result of A[,1] * B and 
the second three the result of A[,2] * B. What is the most efficient way 
to express that? I'm trying to use 'apply' with no success...
    Thanks for your help!

 
--                                                      --
Jose Luis Aznarte M.       http://decsai.ugr.es/~jlaznarte
Department of Computer Science and Artificial Intelligence
Universidad de Granada           Tel. +34 - 958 - 24 04 67
GRANADA (Spain)                  Fax: +34 - 958 - 24 00 79


From jspies at nd.edu  Thu Sep 27 18:34:46 2007
From: jspies at nd.edu (Jeffrey Robert Spies)
Date: Thu, 27 Sep 2007 12:34:46 -0400
Subject: [R] A matrix multiplication
In-Reply-To: <46FBE378.3080904@decsai.ugr.es>
References: <46FBE378.3080904@decsai.ugr.es>
Message-ID: <4F1C3B76-3776-479A-ADE7-A1C41F0C6082@nd.edu>

How about this:

a <- matrix(cbind(rep(2, 500), rep(3, 500)), 500, 2)
b <- matrix(cbind(rep(5, 500), rep(6, 500), rep(7, 500)), 500, 3)

matrix(apply(a, c(2), "*", b), nrow=500, ncol=6)

We apply the multiplier (quoted as specified in the apply help) with  
argument b to every column of a as specified by c(2), then reformat  
the results into a 500x6 matrix as desired.

Hope this helps,

Jeff.

On Sep 27, 2007, at 1:08 PM, Jose Luis Aznarte M. wrote:

> Dear all,
>     I'm having trouble using the 'apply' function to multiply some
> arrays. Let A be a 500x2 array and B a 500x3 array. I need a vector C
> which has 6 columns being the first three the result of A[,1] * B and
> the second three the result of A[,2] * B. What is the most  
> efficient way
> to express that? I'm trying to use 'apply' with no success...
>     Thanks for your help!
>
>
> --                                                      --
> Jose Luis Aznarte M.       http://decsai.ugr.es/~jlaznarte
> Department of Computer Science and Artificial Intelligence
> Universidad de Granada           Tel. +34 - 958 - 24 04 67
> GRANADA (Spain)                  Fax: +34 - 958 - 24 00 79
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From h.wickham at gmail.com  Thu Sep 27 18:40:41 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 27 Sep 2007 11:40:41 -0500
Subject: [R] sprucing up the R homepage
In-Reply-To: <2E3C91D9-7429-4E9D-8C74-ABB2456D7FF6@math.uni-augsburg.de>
References: <2E3C91D9-7429-4E9D-8C74-ABB2456D7FF6@math.uni-augsburg.de>
Message-ID: <f8e6ff050709270940s60926e55sb67f1b9b6fec741a@mail.gmail.com>

Dear Antony,

I think you have fundamentally misunderstood the purpose of graphics -
they are not to be used to gain insight into your data, but to add
excitement and interest to otherwise boring, text-filled pages ;)

Hadley

On 9/27/07, Antony Unwin <unwin at math.uni-augsburg.de> wrote:
> It's a good idea to spruce up the graphics on R's webpage, but before
> we get too excited about improving how they are drawn, shouldn't we
> think about improving what has been drawn?
>
> The original graphic showed off a wide variety of graphics which can
> be drawn with R, all applied to the swiss fertility dataset.  Are
> these the kinds of graphics we would want to draw in a real
> analysis?  I think a single parallel coordinate plot is more
> informative than this collection and would be easier to explain.  If
> you want to try it for yourself, use the package iplots with data
> (swiss) and then ipcp(swiss).
>
> So maybe someone should suggest graphics from another dataset to
> adorn the webpage and demonstrate R's graphics capabilities.
>
> Antony Unwin
> Professor of Computer-Oriented Statistics and Data Analysis,
> Mathematics Institute,
> University of Augsburg,
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
http://had.co.nz/


From jporzak at gmail.com  Thu Sep 27 18:48:53 2007
From: jporzak at gmail.com (Jim Porzak)
Date: Thu, 27 Sep 2007 09:48:53 -0700
Subject: [R] sprucing up the R homepage
In-Reply-To: <f8e6ff050709270940s60926e55sb67f1b9b6fec741a@mail.gmail.com>
References: <2E3C91D9-7429-4E9D-8C74-ABB2456D7FF6@math.uni-augsburg.de>
	<f8e6ff050709270940s60926e55sb67f1b9b6fec741a@mail.gmail.com>
Message-ID: <2a9c000c0709270948r56cb9984gc8d83c3d71ce4d1c@mail.gmail.com>

Hadley,

When did you switch to the Marketing MBA program?

- Jim

On 9/27/07, hadley wickham <h.wickham at gmail.com> wrote:
> Dear Antony,
>
> I think you have fundamentally misunderstood the purpose of graphics -
> they are not to be used to gain insight into your data, but to add
> excitement and interest to otherwise boring, text-filled pages ;)
>
> Hadley
>
> On 9/27/07, Antony Unwin <unwin at math.uni-augsburg.de> wrote:
> > It's a good idea to spruce up the graphics on R's webpage, but before
> > we get too excited about improving how they are drawn, shouldn't we
> > think about improving what has been drawn?
> >
> > The original graphic showed off a wide variety of graphics which can
> > be drawn with R, all applied to the swiss fertility dataset.  Are
> > these the kinds of graphics we would want to draw in a real
> > analysis?  I think a single parallel coordinate plot is more
> > informative than this collection and would be easier to explain.  If
> > you want to try it for yourself, use the package iplots with data
> > (swiss) and then ipcp(swiss).
> >
> > So maybe someone should suggest graphics from another dataset to
> > adorn the webpage and demonstrate R's graphics capabilities.
> >
> > Antony Unwin
> > Professor of Computer-Oriented Statistics and Data Analysis,
> > Mathematics Institute,
> > University of Augsburg,
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> http://had.co.nz/
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From h.wickham at gmail.com  Thu Sep 27 18:55:20 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 27 Sep 2007 11:55:20 -0500
Subject: [R] sprucing up the R homepage
In-Reply-To: <2a9c000c0709270948r56cb9984gc8d83c3d71ce4d1c@mail.gmail.com>
References: <2E3C91D9-7429-4E9D-8C74-ABB2456D7FF6@math.uni-augsburg.de>
	<f8e6ff050709270940s60926e55sb67f1b9b6fec741a@mail.gmail.com>
	<2a9c000c0709270948r56cb9984gc8d83c3d71ce4d1c@mail.gmail.com>
Message-ID: <f8e6ff050709270955yd91fee7v6d8e2d08b0a915ba@mail.gmail.com>

Jim,

After learning that you could produce translucent 3d pie charts in excel.

Hadley

On 9/27/07, Jim Porzak <jporzak at gmail.com> wrote:
> Hadley,
>
> When did you switch to the Marketing MBA program?
>
> - Jim
>
> On 9/27/07, hadley wickham <h.wickham at gmail.com> wrote:
> > Dear Antony,
> >
> > I think you have fundamentally misunderstood the purpose of graphics -
> > they are not to be used to gain insight into your data, but to add
> > excitement and interest to otherwise boring, text-filled pages ;)
> >
> > Hadley
> >
> > On 9/27/07, Antony Unwin <unwin at math.uni-augsburg.de> wrote:
> > > It's a good idea to spruce up the graphics on R's webpage, but before
> > > we get too excited about improving how they are drawn, shouldn't we
> > > think about improving what has been drawn?
> > >
> > > The original graphic showed off a wide variety of graphics which can
> > > be drawn with R, all applied to the swiss fertility dataset.  Are
> > > these the kinds of graphics we would want to draw in a real
> > > analysis?  I think a single parallel coordinate plot is more
> > > informative than this collection and would be easier to explain.  If
> > > you want to try it for yourself, use the package iplots with data
> > > (swiss) and then ipcp(swiss).
> > >
> > > So maybe someone should suggest graphics from another dataset to
> > > adorn the webpage and demonstrate R's graphics capabilities.
> > >
> > > Antony Unwin
> > > Professor of Computer-Oriented Statistics and Data Analysis,
> > > Mathematics Institute,
> > > University of Augsburg,
> > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >
> > --
> > http://had.co.nz/
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


-- 
http://had.co.nz/


From h.wickham at gmail.com  Thu Sep 27 18:57:52 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 27 Sep 2007 11:57:52 -0500
Subject: [R] Cairo on windows
In-Reply-To: <12923700.post@talk.nabble.com>
References: <12923700.post@talk.nabble.com>
Message-ID: <f8e6ff050709270957p7d22348p102abc9ca78efd40@mail.gmail.com>

You could also try the cairoDevice package, which should definitely
work with the gtk libraries that you probably have from installing
GGobi.

Hadley

On 9/27/07, Yves Moisan <ymoisan at groupesm.com> wrote:
>
> Hi All,
>
> I just installed Cairo on R 2.5.1 on windows XP.  My hope was to get to see
> the transparency output e.g.  http://had.co.nz/ggplot2/stat_smooth.html
> ggplot2 - stat_smooth , which I finally managed to do.  However, I find the
> Cairo device, which I access either through CairoWin() or Cairo(type="win"),
> is pretty shaky in a number of respects :
>
> - whatever portion of the Cairo device that is covered by the R command
> window does not get drawn.  I noticed changing the size of the Cairo window
> by dragging one of its corners with the mouse does refresh the whole window
> sometimes
>
> - a simple plot or qplot command works, e.g. qplot(x=kg.hab,y=Cout.ton,
> data=ech2).  When one starts to add xlab, ylab and main then things start
> getting shaky to the point the display becomes blank.  At that point, even
> reverting back to a simple plotting command that worked 5 seconds ago won't
> bring back the display.  One has to dev.off() and start again.
>
> Besides the interactive windows display, I also wanted to use Cairo's PNG
> support so I went and tried one of my
> png(filename = ...)
>  commands with
> CairoPNG(filename = ...)
>  and the output was also blank.
>
> Are there additional steps besides a package install of Cairo I have to
> worry about ?
>
> TIA,
>
> Yves Moisan
> --
> View this message in context: http://www.nabble.com/Cairo-on-windows-tf4529124.html#a12923700
> Sent from the R help mailing list archive at Nabble.com.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
http://had.co.nz/


From ymoisan at groupesm.com  Thu Sep 27 19:11:44 2007
From: ymoisan at groupesm.com (Moisan Yves)
Date: Thu, 27 Sep 2007 13:11:44 -0400
Subject: [R] Cairo on windows
In-Reply-To: <f8e6ff050709270957p7d22348p102abc9ca78efd40@mail.gmail.com>
Message-ID: <8FAF06163E22434EACB677AD054EF891023A43D3@sm-exchange.groupesm.com>

> You could also try the cairoDevice package, which should definitely
> work with the gtk libraries that you probably have from installing
> GGobi.

Hi Hadley,

I tried that also before posting on R-help :

> library(cairoDevice)
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
        impossible de charger la biblioth?que partag?e 'C:/PROGRA~1/R/R-25~1.1/library/cairoDevice/libs/cairoDevice.dll':
  LoadLibrary failure:  La proc?dure sp?cifi?e est introuvable.


Erreur : le chargement du package / espace de noms a ?chou? pour 'cairoDevice'

Translation : impossible to load shared library 'C:/PROGRA~1/R/R-25~1.1/library/cairoDevice/libs/cairoDevice.dll'

The library *is* at C:/Program Files/R/R-2.5.1/library/cairoDevice/libs so I'm wondering if the path mentioned in the error log is where 'library' is looking or if that path gets expanded (e.g. "PROGRA~1" becomes "Program Files").  I looked at library to see if I can supply it with a hard path where to find the dll but playing with libpath and lib.loc won't help.  Is that a matter of Cairo and cairoDevice not installing properly on Windows ?

TIA,

Yves


From B.Samira at sheffield.ac.uk  Thu Sep 27 19:19:22 2007
From: B.Samira at sheffield.ac.uk (S Bina)
Date: Thu, 27 Sep 2007 18:19:22 +0100
Subject: [R] Y-axis scale in Q-Qplot
Message-ID: <1190913562.46fbe61aea61c@webmail.shef.ac.uk>

Dear All, 

I have made a Q-Qplot (qqnorm) and want to change the scale of the y-axis from
-4 to 25.

How can I do that?

Many thanks
Samira


From marc_schwartz at comcast.net  Thu Sep 27 19:29:53 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 27 Sep 2007 12:29:53 -0500
Subject: [R] sprucing up the R homepage
In-Reply-To: <f8e6ff050709270955yd91fee7v6d8e2d08b0a915ba@mail.gmail.com>
References: <2E3C91D9-7429-4E9D-8C74-ABB2456D7FF6@math.uni-augsburg.de>
	<f8e6ff050709270940s60926e55sb67f1b9b6fec741a@mail.gmail.com>
	<2a9c000c0709270948r56cb9984gc8d83c3d71ce4d1c@mail.gmail.com>
	<f8e6ff050709270955yd91fee7v6d8e2d08b0a915ba@mail.gmail.com>
Message-ID: <1190914193.9666.20.camel@Bellerophon.localdomain>

<Gack>

Who are you and what have you done with the real Hadley?

Marc

On Thu, 2007-09-27 at 11:55 -0500, hadley wickham wrote:
> Jim,
> 
> After learning that you could produce translucent 3d pie charts in excel.
> 
> Hadley
> 
> On 9/27/07, Jim Porzak <jporzak at gmail.com> wrote:
> > Hadley,
> >
> > When did you switch to the Marketing MBA program?
> >
> > - Jim
> >
> > On 9/27/07, hadley wickham <h.wickham at gmail.com> wrote:
> > > Dear Antony,
> > >
> > > I think you have fundamentally misunderstood the purpose of graphics -
> > > they are not to be used to gain insight into your data, but to add
> > > excitement and interest to otherwise boring, text-filled pages ;)
> > >
> > > Hadley
> > >
> > > On 9/27/07, Antony Unwin <unwin at math.uni-augsburg.de> wrote:
> > > > It's a good idea to spruce up the graphics on R's webpage, but before
> > > > we get too excited about improving how they are drawn, shouldn't we
> > > > think about improving what has been drawn?
> > > >
> > > > The original graphic showed off a wide variety of graphics which can
> > > > be drawn with R, all applied to the swiss fertility dataset.  Are
> > > > these the kinds of graphics we would want to draw in a real
> > > > analysis?  I think a single parallel coordinate plot is more
> > > > informative than this collection and would be easier to explain.  If
> > > > you want to try it for yourself, use the package iplots with data
> > > > (swiss) and then ipcp(swiss).
> > > >
> > > > So maybe someone should suggest graphics from another dataset to
> > > > adorn the webpage and demonstrate R's graphics capabilities.
> > > >
> > > > Antony Unwin
> > > > Professor of Computer-Oriented Statistics and Data Analysis,
> > > > Mathematics Institute,
> > > > University of Augsburg,
> > > >
> > > >
> > > >         [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > >
> > >
> > > --
> > > http://had.co.nz/
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> 
>


From corey.sparks at utsa.edu  Thu Sep 27 19:30:39 2007
From: corey.sparks at utsa.edu (Corey Sparks)
Date: Thu, 27 Sep 2007 12:30:39 -0500
Subject: [R] Reading SAS SD2 Data file
Message-ID: <2768A5B569B1D54EA47861B9A05422E10227EC91@jade1604.UTSARR.NET>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/ab1636a4/attachment.pl 

From ripley at stats.ox.ac.uk  Thu Sep 27 19:34:41 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 27 Sep 2007 18:34:41 +0100 (BST)
Subject: [R] Cairo on windows
In-Reply-To: <8FAF06163E22434EACB677AD054EF891023A43D3@sm-exchange.groupesm.com>
References: <8FAF06163E22434EACB677AD054EF891023A43D3@sm-exchange.groupesm.com>
Message-ID: <Pine.LNX.4.64.0709271821580.32142@gannet.stats.ox.ac.uk>

On Thu, 27 Sep 2007, Moisan Yves wrote:

>> You could also try the cairoDevice package, which should definitely
>> work with the gtk libraries that you probably have from installing
>> GGobi.
>
> Hi Hadley,
>
> I tried that also before posting on R-help :
>
>> library(cairoDevice)
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>        impossible de charger la biblioth?que partag?e 'C:/PROGRA~1/R/R-25~1.1/library/cairoDevice/libs/cairoDevice.dll':
>  LoadLibrary failure:  La proc?dure sp?cifi?e est introuvable.
>
>
> Erreur : le chargement du package / espace de noms a ?chou? pour 
> 'cairoDevice'
>
> Translation : impossible to load shared library 
> 'C:/PROGRA~1/R/R-25~1.1/library/cairoDevice/libs/cairoDevice.dll'
>
> The library *is* at C:/Program Files/R/R-2.5.1/library/cairoDevice/libs 
> so I'm wondering if the path mentioned in the error log is where 
> 'library' is looking or if that path gets expanded (e.g. "PROGRA~1" 
> becomes "Program Files").  I looked at library to see if I can supply it 
> with a hard path where to find the dll but playing with libpath and 
> lib.loc won't help.  Is that a matter of Cairo and cairoDevice not 
> installing properly on Windows ?

The message means that the DLL exists but that there is a problem loading 
it.  That usually means that a dependent DLL is not on the path or not 
recent enough, and under XP you usually get a message box to that effect 
(Vista 64 seems to tell you a lot less by default).

Now, Cairo ships with libcairo-2.dll but does not put it on the path, 
whereas cairoDevice needs more, including libpango and libpangocairo.  So 
you will need to install a Windows version of Gtk+ and make sure it is in 
your path.  I have a feeling I needed a later version than I was using for 
GGobi (I have 2.10.11-1).

My experience is that cairoDevice is a lot slower than Cairo, especially 
on Windows, and about equally flaky.  If you see how many layers are 
involved with Cairo on Windows you will not be surprised.

If all you need is semi-transparency support I suggest you try R 2.6.0 RC
which supports it in the windows() device.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ymoisan at groupesm.com  Thu Sep 27 19:39:09 2007
From: ymoisan at groupesm.com (Moisan Yves)
Date: Thu, 27 Sep 2007 13:39:09 -0400
Subject: [R] Cairo on windows
In-Reply-To: <Pine.LNX.4.64.0709271821580.32142@gannet.stats.ox.ac.uk>
Message-ID: <8FAF06163E22434EACB677AD054EF891023A4410@sm-exchange.groupesm.com>

> My experience is that cairoDevice is a lot slower than Cairo,
especially 
on Windows, and about equally flaky.  If you see how many layers are 
involved with Cairo on Windows you will not be surprised.

Actually, I ended up trying to load deviceCairo simply because it was
the only other package with the string "Cairo" in it besides "Cairo"
itself ;-).  I suspected some interaction between the two libraries
(deviceCairo and Cairo) so that's why I tried to load it hoping it would
solve the flakiness of the CairoWin display.

> If all you need is semi-transparency support I suggest you try R 2.6.0
RC
which supports it in the windows() device.

Thanx for the tip.

Yves Moisan


From murdoch at stats.uwo.ca  Thu Sep 27 19:49:34 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 27 Sep 2007 13:49:34 -0400
Subject: [R] Cairo on windows
In-Reply-To: <8FAF06163E22434EACB677AD054EF891023A43D3@sm-exchange.groupesm.com>
References: <8FAF06163E22434EACB677AD054EF891023A43D3@sm-exchange.groupesm.com>
Message-ID: <46FBED2E.9020701@stats.uwo.ca>

On 9/27/2007 1:11 PM, Moisan Yves wrote:
>> You could also try the cairoDevice package, which should definitely
>> work with the gtk libraries that you probably have from installing
>> GGobi.
> 
> Hi Hadley,
> 
> I tried that also before posting on R-help :
> 
>> library(cairoDevice)
> Error in dyn.load(x, as.logical(local), as.logical(now)) : 
>         impossible de charger la biblioth?que partag?e 'C:/PROGRA~1/R/R-25~1.1/library/cairoDevice/libs/cairoDevice.dll':
>   LoadLibrary failure:  La proc?dure sp?cifi?e est introuvable.
> 
> 
> Erreur : le chargement du package / espace de noms a ?chou? pour 'cairoDevice'
> 
> Translation : impossible to load shared library 'C:/PROGRA~1/R/R-25~1.1/library/cairoDevice/libs/cairoDevice.dll'
> 
> The library *is* at C:/Program Files/R/R-2.5.1/library/cairoDevice/libs so I'm wondering if the path mentioned in the error log is where 'library' is looking or if that path gets expanded (e.g. "PROGRA~1" becomes "Program Files").  I looked at library to see if I can supply it with a hard path where to find the dll but playing with libpath and lib.loc won't help.  Is that a matter of Cairo and cairoDevice not installing properly on Windows ?


Don't you also get a popup, telling you that libgdk-win32-2.0-0.dll was 
not found?  I get that; I assume it's supposed to come from gtk, which I 
don't currently have installed.  It's unfortunate that the error message 
isn't more informative about what the real problem is.  I'll see if 
there's a way to improve it.

The dll also requires imports from

libpangocairo-1.0-0.dll
libpango-1.0-0.dll
libgtk-win32-2.0-0.dll
libgobject-2.0-0.dll
libglib-2.0-0.dll
libcairo-2.dll
R.dll

The last one is present on my system; I don't know if the others are all 
in gtk.

Duncan Murdoch


From collants at uqroo.mx  Thu Sep 27 19:44:45 2007
From: collants at uqroo.mx (=?iso-8859-1?Q?=22Alejandro_Luis_Collantes_Ch=E1vez-Costa=22?=)
Date: Thu, 27 Sep 2007 12:44:45 -0500
Subject: [R] Post-hoc after Anova() car package using linear.hypothesis() in
 a Repeated Measure Analysis
Message-ID: <fb3e8fd92a69.46fba5bd@uqroo.mx>

R masters:

I need your help to figure out how can I perform Post-hoc test after ?Anova()? ?car package? using ?linear.hypothesis()? in a Repeated Measure Analysis.

I performed a Repeated Measures Analysis to test the effect of Category, Season and their Interaction on some ecological properties using ?Anova()? from ?car package?.
I find some significant effect and now I would like to know where the differences are. In order to perform these Within, Between and within-between post hoc?s Professor John Fox recommend me to use ?linear.hypothesis()? and a Bonferonni adjustment of the p-values.

After a couple of weeks of work, I can not figure out how to do that. I am very sorry, I did my best but I am not statistician and I can not find examples to understand how can I use linear.hypothesis() in post hoc test.

There are someone who can help me?

P.D.  (I am very thankful to Professor Richard Heiberger who give me advices about the use of ?glht.mmc()? with the ?calpha? argument).


For those who can help me, I am posting some extra information about my case and my attempts:

The experiment design was as follow: 1 between subjects (fixed factor with 3 levels) and 1 within subjects (fixed factor with 3 levels). Between subjects are nine plots grouped into 3 age category (tree plot for each age category ?T?, ?I?, ?M?), and Within category are 3 season of the year  "llu?, ?nor?, ?sec" (equidistant in the time scale). The data set is:

lludiversity	nordiversity	secdiversity	Plot	Category	Season
1.96601	2.10215	2.17984	07A	T	llu
1.73697	1.96866	1.99766	10B	T	llu
1.87122	1.92848	2.2673	10C	T	llu
2.06851	1.98455	2.43838	15B	I	llu
2.17905	2.49451	2.25759	15C	I	llu
2.2572	2.16882	2.58295	17A	I	llu
1.99913	2.43767	2.29582	60A	M	llu
2.12738	2.64161	2.5385	60B	M	llu
2.22421	2.42401	2.5385	60C	M	llu

To test the effect of Category, Season and their Interaction on some ecological properties I use the following code:

rm(list=ls(all=TRUE))
library(lattice);
library(Matrix);
library(car);
setwd(?c:/R help/?);
diversity.tbl <- read.table("diversity.txt", header=TRUE);
Season <- factor(c("Lluvias","Nortes","Secas"), levels=c("Lluvias","Nortes","Secas"));
idata.df <- data.frame(Season) # Within ?plot?;
Plot <- diversity.tbl[,4];
Category <- factor(diversity.tbl[,5], levels=c("T", "I", "M")) #Between ?plot?;
dLluvias <- diversity.tbl[,1];
dNortes <- diversity.tbl[,2];
dSecas <- diversity.tbl[,3];
datalm.df <- data.frame(Plot, Category, dLluvias, dNortes, dSecas);
diversitylm.ok <- lm(cbind(dLluvias, dNortes, dSecas) ~ Category, data=datalm.df);
diversityav.ok <- Anova(diversitylm.ok, idata=idata.df, type="II", idesign=~Season);
summary(diversityav.ok, multivariate=FALSE);
diversityav.ok

To try perform post hoc test I did:
linear.hypothesis(diversitylm.ok, c("(Intercept)=CategoryM"), idata=idata.df, idesign=~Season, iterms="Season"); #To contrast Intercept (Category T) and Category M


Alejandro Collantes Ch?vez-Costa
Universidad de Quintana Roo, Unidad Cozumel

http://www.cozumel.uqroo.mx

From david.koons at usu.edu  Thu Sep 27 19:56:23 2007
From: david.koons at usu.edu (David Koons)
Date: Thu, 27 Sep 2007 11:56:23 -0600
Subject: [R] center option of basehaz in survfit
Message-ID: <9E879E542A3E8C43B9CCF85FDEC2689C1F67BE746A@exchg-be04.aggies.usu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/78b99db1/attachment.pl 

From p.dalgaard at biostat.ku.dk  Thu Sep 27 19:56:46 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 27 Sep 2007 19:56:46 +0200
Subject: [R] Reading SAS SD2 Data file
In-Reply-To: <2768A5B569B1D54EA47861B9A05422E10227EC91@jade1604.UTSARR.NET>
References: <2768A5B569B1D54EA47861B9A05422E10227EC91@jade1604.UTSARR.NET>
Message-ID: <46FBEEDE.1090905@biostat.ku.dk>

Corey Sparks wrote:
> I am trying to read a SAS dataset into R that is in a .SD2 format, which
> is the Version 6 standard format from SAS.
>   
(for DOS/Windows, that is. The format was machine/OS dependent.)

> I see the routines that read the SAS XPORT format (foreign, Hmisc), but
> is there any way to read this one?
>   
Only commercial solutions. (SAS itself, DBMS/COPY, StatTransfer, ...) 
The actual format is a company secret, and noone has bothered to try and 
decipher it.

> Any help would be greatly appreciated.
> Corey Sparks
>
> Corey Sparks
> Assistant Professor
> Department of Demography and Organization Studies
> University of Texas-San Antonio
> One UTSA Circle
> San Antonio TX 78249
> Phone: 210 458 6858
> corey.sparks at utsa.edu
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From jholtman at gmail.com  Thu Sep 27 19:57:30 2007
From: jholtman at gmail.com (jim holtman)
Date: Thu, 27 Sep 2007 13:57:30 -0400
Subject: [R] Getting group-wise standard scores of a vector
In-Reply-To: <77693D6263D9B94AA3C6384F1474E26A0284B0C3@wyt-s-019.europe.shell.com>
References: <46FAC786.1070708@utoronto.ca>
	<77693D6263D9B94AA3C6384F1474E26A0284B0C3@wyt-s-019.europe.shell.com>
Message-ID: <644e1f320709271057g2ea4a8bav84f819d6341fa3a2@mail.gmail.com>

Is this what you want:

> test.data
          x group
1  32.66782     A
2  50.02132     A
3  43.69700     A
4  46.59031     A
5  38.43428     A
6  68.03142     A
7  46.68868     A
8  33.94487     A
9  51.97193     A
10 52.63176     A
11 40.14173     B
12 21.11079     B
13 43.59518     B
14 55.70508     B
15 49.40277     B
16 49.01821     B
17 55.60821     B
18 38.13541     B
19 60.96777     B
20 49.94656     B
> test.data$z <-  ave(test.data$x, test.data$group,FUN=function(z){(z-mean(z))/sd(z)})
> test.data
          x group           z
1  32.66782     A -1.33241490
2  50.02132     A  0.34308231
3  43.69700     A -0.26753700
4  46.59031     A  0.01181557
5  38.43428     A -0.77565765
6  68.03142     A  2.08197466
7  46.68868     A  0.02131284
8  33.94487     A -1.20911451
9  51.97193     A  0.53141612
10 52.63176     A  0.59512257
11 40.14173     B -0.54637780
12 21.11079     B -2.21770874
13 43.59518     B -0.24308968
14 55.70508     B  0.82042267
15 49.40277     B  0.26694269
16 49.01821     B  0.23317041
17 55.60821     B  0.81191546
18 38.13541     B -0.72257633
19 60.96777     B  1.28260182
20 49.94656     B  0.31469951
>


On 9/27/07, Wayne.W.Jones at shell.com <Wayne.W.Jones at shell.com> wrote:
>
> tapply is also very useful:
>
>
> my.df<-data.frame(x=rnorm(20, 50, 10),group=factor(sort(rep(c("A", "B"), 10))))
> tapply(my.df$x,my.df$group,function(x){(x-mean(x))/sd(x)})
>
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org]On Behalf Of Matthew Dubins
> Sent: 26 September 2007 21:57
> To: r-help at r-project.org
> Subject: [R] Getting group-wise standard scores of a vector
>
>
> Hi,
>
> I want to be able to create a vector of z-scores from a vector of
> continuous data, conditional on a group membership vector.
>
> Say you have 20 numbers distributed normally with a mean of 50 and an sd
> of 10:
>
> x <- rnorm(20, 50, 10)
>
>
> Then you have a vector that delineates 2 groups within x:
>
> group <- sort(rep(c("A", "B"), 10))
>
> test.data <- data.frame(cbind(x, group))
>
> I know that if you break up the x vector into 2 different vectors then
> it becomes easy to calculate the z scores for each vector, then you
> stack them and append them to the original
> data frame.  Is there anyway to apply this sort of calculation without
> splitting the original vector up?  I tried a really complex ifelse
> statement but it didn't seem to work.
>
> Thanks in advance,
> Matthew Dubins
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From ymoisan at groupesm.com  Thu Sep 27 19:55:59 2007
From: ymoisan at groupesm.com (Moisan Yves)
Date: Thu, 27 Sep 2007 13:55:59 -0400
Subject: [R] Cairo on windows
In-Reply-To: <46FBED2E.9020701@stats.uwo.ca>
Message-ID: <8FAF06163E22434EACB677AD054EF891023A4430@sm-exchange.groupesm.com>

> Don't you also get a popup, telling you that libgdk-win32-2.0-0.dll
was 
not found?  

Duncan,

No such popup.

> The dll also requires imports from

> libpangocairo-1.0-0.dll
> libpango-1.0-0.dll
> libgtk-win32-2.0-0.dll
> libgobject-2.0-0.dll
> libglib-2.0-0.dll
> libcairo-2.dll

I checked that all of the above are on C:\GTK\bin

> R.dll

That's on C:\Program Files\R\R-2.5.1\bin.  My system path has
"%GTK_BASEPATH%\bin" as its very first argument, so I gather I have
everything I need ??  I tried adding explicitly C:\GTK\bin on the path.
I'll see where that leads me next time I fire up R.

Thanx,

Yves Moisan


From thomas.pujol at yahoo.com  Thu Sep 27 20:07:04 2007
From: thomas.pujol at yahoo.com (Thomas Pujol)
Date: Thu, 27 Sep 2007 11:07:04 -0700 (PDT)
Subject: [R] converting numbers in "YYYYMM" format to last calendar day and
	last exchange trading day of the month
Message-ID: <919578.99144.qm@web59305.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/919002a1/attachment.pl 

From Greg.Snow at intermountainmail.org  Thu Sep 27 20:19:41 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Thu, 27 Sep 2007 12:19:41 -0600
Subject: [R] Getting intervals for within-group standard errors for each
 group using nlme and varIdent
Message-ID: <07E228A5BE53C24CAD490193A7381BBB12A191@LP-EXCHVS07.CO.IHC.COM>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/94a94085/attachment.pl 

From marc_schwartz at comcast.net  Thu Sep 27 20:26:42 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 27 Sep 2007 13:26:42 -0500
Subject: [R] Reading SAS SD2 Data file
In-Reply-To: <46FBEEDE.1090905@biostat.ku.dk>
References: <2768A5B569B1D54EA47861B9A05422E10227EC91@jade1604.UTSARR.NET>
	<46FBEEDE.1090905@biostat.ku.dk>
Message-ID: <1190917602.9666.29.camel@Bellerophon.localdomain>

On Thu, 2007-09-27 at 19:56 +0200, Peter Dalgaard wrote:
> Corey Sparks wrote:
> > I am trying to read a SAS dataset into R that is in a .SD2 format, which
> > is the Version 6 standard format from SAS.
> >   
> (for DOS/Windows, that is. The format was machine/OS dependent.)

That is still the case with the proprietary SAS formats. You can't read
a SAS V9 file from Windows with SAS V9 on Linux, etc.

> > I see the routines that read the SAS XPORT format (foreign, Hmisc), but
> > is there any way to read this one?
> >   
> Only commercial solutions. (SAS itself, DBMS/COPY, StatTransfer, ...) 
> The actual format is a company secret, and noone has bothered to try and 
> decipher it.

The XPORT (Transport) format is openly documented and is cross-platform
compatible, which is why the FDA had standardized on it, for example.

There is the SAS System Viewer, which will open Windows based
proprietary SAS files and enable you to save them to CSV files. It is
_free_ and is available from here:

http://www.sas.com/apps/demosdownloads/sassystemviewer_PROD_9.1.3_sysdep.jsp?packageID=000313&jmpflag=N

It also runs under WINE on Linux, BTW.  :-)

HTH,

Marc Schwartz


From jfox at mcmaster.ca  Thu Sep 27 20:40:21 2007
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 27 Sep 2007 14:40:21 -0400
Subject: [R] Post-hoc after Anova() car package using
	linear.hypothesis() in a Repeated Measure Analysis
In-Reply-To: <fb3e8fd92a69.46fba5bd@uqroo.mx>
Message-ID: <20070927184021.LPUL574.tomts16-srv.bellnexxia.net@JohnDesktop8300>

Dear Alejandro,

If I understand correctly what you want (that is, pairwise multivariate
tests among the groups), you could do the following tests (some output
suppressed):

> linear.hypothesis(diversitylm.ok, c("(Intercept)=CategoryM"), 
+     idata=idata.df, idesign=~Season, iterms="Season")

 Response transformation matrix:
         Season1 Season2
dLluvias       1       0
dNortes        0       1
dSecas        -1      -1

Sum of squares and products for the hypothesis:
           Season1    Season2
Season1 0.03447365 0.04897023
Season2 0.04897023 0.06956279

Sum of squares and products for error:
           Season1   Season2
Season1 0.07481798 0.1463547
Season2 0.14635470 0.3945622

Multivariate Tests: 
                 Df test stat  approx F num Df den Df  Pr(>F)
Pillai            1 0.3557184 1.3802911      2      5 0.33319
Wilks             1 0.6442816 1.3802911      2      5 0.33319
Hotelling-Lawley  1 0.5521164 1.3802911      2      5 0.33319
Roy               1 0.5521164 1.3802911      2      5 0.33319

> linear.hypothesis(diversitylm.ok, c("(Intercept)=CategoryI"), 
+     idata=idata.df, idesign=~Season, iterms="Season")

. . .

Multivariate Tests: 
                 Df test stat approx F num Df den Df   Pr(>F)  
Pillai            1  0.712033 6.181560      2      5 0.044500 *

. . .

> linear.hypothesis(diversitylm.ok, c("CategoryI=CategoryM"), 
+     idata=idata.df, idesign=~Season, iterms="Season")

. . .

Multivariate Tests: 
                 Df test stat approx F num Df den Df  Pr(>F)  
Pillai            1  0.716616 6.321937      2      5 0.04275 *

. . .

The Bonferroni adjustment is to multiply each p-value by 3 (the number of
tests); it should be conservative in this context, and so there should be
better approaches for multivariate pairwise comparisons.

Regards,
 John

--------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of "Alejandro 
> Luis Collantes Ch?vez-Costa"
> Sent: Thursday, September 27, 2007 1:45 PM
> To: r-help at r-project.org
> Subject: [R] Post-hoc after Anova() car package using 
> linear.hypothesis() in a Repeated Measure Analysis
> 
> R masters:
> 
> I need your help to figure out how can I perform Post-hoc 
> test after ?Anova()? ?car package? using 
> ?linear.hypothesis()? in a Repeated Measure Analysis.
> 
> I performed a Repeated Measures Analysis to test the effect 
> of Category, Season and their Interaction on some ecological 
> properties using ?Anova()? from ?car package?.
> I find some significant effect and now I would like to know 
> where the differences are. In order to perform these Within, 
> Between and within-between post hoc?s Professor John Fox 
> recommend me to use ?linear.hypothesis()? and a Bonferonni 
> adjustment of the p-values.
> 
> After a couple of weeks of work, I can not figure out how to 
> do that. I am very sorry, I did my best but I am not 
> statistician and I can not find examples to understand how 
> can I use linear.hypothesis() in post hoc test.
> 
> There are someone who can help me?
> 
> P.D.  (I am very thankful to Professor Richard Heiberger who 
> give me advices about the use of ?glht.mmc()? with the 
> ?calpha? argument).
> 
> 
> For those who can help me, I am posting some extra 
> information about my case and my attempts:
> 
> The experiment design was as follow: 1 between subjects 
> (fixed factor with 3 levels) and 1 within subjects (fixed 
> factor with 3 levels). Between subjects are nine plots 
> grouped into 3 age category (tree plot for each age category 
> ?T?, ?I?, ?M?), and Within category are 3 season of the year  
> "llu?, ?nor?, ?sec" (equidistant in the time scale). The data set is:
> 
> lludiversity	nordiversity	secdiversity	Plot	
> Category	Season
> 1.96601	2.10215	2.17984	07A	T	llu
> 1.73697	1.96866	1.99766	10B	T	llu
> 1.87122	1.92848	2.2673	10C	T	llu
> 2.06851	1.98455	2.43838	15B	I	llu
> 2.17905	2.49451	2.25759	15C	I	llu
> 2.2572	2.16882	2.58295	17A	I	llu
> 1.99913	2.43767	2.29582	60A	M	llu
> 2.12738	2.64161	2.5385	60B	M	llu
> 2.22421	2.42401	2.5385	60C	M	llu
> 
> To test the effect of Category, Season and their Interaction 
> on some ecological properties I use the following code:
> 
> rm(list=ls(all=TRUE))
> library(lattice);
> library(Matrix);
> library(car);
> setwd(?c:/R help/?);
> diversity.tbl <- read.table("diversity.txt", header=TRUE); 
> Season <- factor(c("Lluvias","Nortes","Secas"), 
> levels=c("Lluvias","Nortes","Secas"));
> idata.df <- data.frame(Season) # Within ?plot?; Plot <- 
> diversity.tbl[,4]; Category <- factor(diversity.tbl[,5], 
> levels=c("T", "I", "M")) #Between ?plot?; dLluvias <- 
> diversity.tbl[,1]; dNortes <- diversity.tbl[,2]; dSecas <- 
> diversity.tbl[,3]; datalm.df <- data.frame(Plot, Category, 
> dLluvias, dNortes, dSecas); diversitylm.ok <- 
> lm(cbind(dLluvias, dNortes, dSecas) ~ Category, 
> data=datalm.df); diversityav.ok <- Anova(diversitylm.ok, 
> idata=idata.df, type="II", idesign=~Season); 
> summary(diversityav.ok, multivariate=FALSE); diversityav.ok
> 
> To try perform post hoc test I did:
> linear.hypothesis(diversitylm.ok, c("(Intercept)=CategoryM"), 
> idata=idata.df, idesign=~Season, iterms="Season"); #To 
> contrast Intercept (Category T) and Category M
> 
> 
> Alejandro Collantes Ch?vez-Costa
> Universidad de Quintana Roo, Unidad Cozumel
> 
> http://www.cozumel.uqroo.mx
> 


From p.dalgaard at biostat.ku.dk  Thu Sep 27 21:02:11 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 27 Sep 2007 21:02:11 +0200
Subject: [R] Reading SAS SD2 Data file
In-Reply-To: <1190917602.9666.29.camel@Bellerophon.localdomain>
References: <2768A5B569B1D54EA47861B9A05422E10227EC91@jade1604.UTSARR.NET>	
	<46FBEEDE.1090905@biostat.ku.dk>
	<1190917602.9666.29.camel@Bellerophon.localdomain>
Message-ID: <46FBFE33.2030801@biostat.ku.dk>

Marc Schwartz wrote:
> On Thu, 2007-09-27 at 19:56 +0200, Peter Dalgaard wrote:
>   
>> Corey Sparks wrote:
>>     
>>> I am trying to read a SAS dataset into R that is in a .SD2 format, which
>>> is the Version 6 standard format from SAS.
>>>   
>>>       
>> (for DOS/Windows, that is. The format was machine/OS dependent.)
>>     
>
> That is still the case with the proprietary SAS formats. You can't read
> a SAS V9 file from Windows with SAS V9 on Linux, etc.
>   
.sas7bdat? Works for me....

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From mdgi at gmx.ch  Thu Sep 27 23:01:01 2007
From: mdgi at gmx.ch (marcg)
Date: Thu, 27 Sep 2007 23:01:01 +0200
Subject: [R]  different colors for two wireframes in same plot
Message-ID: <20070927210101.179800@gmx.net>

Thanks a lot

This already looks nice and I already checked the ?wireframe, but with no examples and as newcommer its hard to find out a correct code.

If we set drape=F in the example:

g <- expand.grid(x = 1:10, y = 5:15, gr = 1:2)
g$z <- log((g$x^g$g + g$y^2) * g$gr)
wireframe(z ~ x * y, data = g, groups = gr,
          scales = list(arrows = FALSE),
          drape = F, colorkey = TRUE,
          screen = list(z = 30, x = -60))

you get a two color pic of these layers - and what I'm actually looking for is making just the UPPER (toplayer) transparent.

Thanks for further help

marc

-------- Original-Nachricht --------
> Datum: Thu, 27 Sep 2007 11:29:19 +0200
> Von: "Frede Aakmann T?gersen" <FredeA.Togersen at agrsci.dk>
> An: "marcg" <mdgi at gmx.ch>, r-help at stat.math.ethz.ch
> Betreff: SV: [R] different colors for two wireframes in same plot

> You can obtain some transparency setting the alpha transparency. This is
> device dependent though. Using the pdf device you can do this obtaining
> transparency of both surfaces (the version must be at least 1.4 for
> semitransparent output to be understood):
> 
> 
> pdf("test.pdf",version="1.4")
> wireframe(z ~ x * y, data = g, groups = gr,
>           scales = list(arrows = FALSE),
>           drape = TRUE, colorkey = TRUE,
>           screen = list(z = 30, x = -60),
>           par.settings = list(regions=list(alpha=0.75)))
> dev.off()
> 
> See ?wireframe for the "at, col.regions, alpha.regions" arguments.
> 
> Does this suffice?
> 
> 
> Med venlig hilsen
> Frede Aakmann T?gersen
>  
> 
>  
> 
> > -----Oprindelig meddelelse-----
> > Fra: r-help-bounces at r-project.org 
> > [mailto:r-help-bounces at r-project.org] P? vegne af marcg
> > Sendt: 27. september 2007 09:22
> > Til: r-help at stat.math.ethz.ch
> > Emne: [R] different colors for two wireframes in same plot
> > 
> > Hello R,
> > 
> > According to:
> > 
> > g <- expand.grid(x = 1:10, y = 5:15, gr = 1:2) g$z <- 
> > log((g$x^g$g + g$y^2) * g$gr) wireframe(z ~ x * y, data = g, 
> > groups = gr,
> >           scales = list(arrows = FALSE),
> >           drape = TRUE, colorkey = TRUE,
> >           screen = list(z = 30, x = -60))
> > 
> > i have two wireframes in one plot.
> > 
> > How could i change the color of the top - one to transparent 
> > (or only the grid). I want to give insight to the lower layer.
> > 
> > Could one make an if-statment like (if gr==1 do drape=F or 
> > color=none) if gr=2 do drape=T, colorkey=T)
> > 
> > Thanks for your help
> > 
> > Marc
> > 
> > --
> > Psssst! Schon vom neuen GMX MultiMessenger geh?rt?
> > Der kanns mit allen: http://www.gmx.net/de/go/multimessenger
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > 

--

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

--


From fjbuch at gmail.com  Thu Sep 27 22:09:30 2007
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Thu, 27 Sep 2007 16:09:30 -0400
Subject: [R] ifelse and dates do not work together: What workaround?
Message-ID: <bd93cdad0709271309u29ee908o74fb90bffb0013a8@mail.gmail.com>

I encountered the above problem. I went to the help files and
discovered the reason why. My insight as to why it was happening did
not immediately provide me with a solution by which I could accomplish
what I needed to do. I turned to the help archive. I encountered a
thread on which somebody pointed this problem out and was mildly
castigated for not having looked at the help file. Alas no workaround
was provided.

ifelse(test, yes, no) is wonderful since it works well in a dataframe
but only if yes and no are something simple, such as a numeric vector.
But if yes and no are dates then it does not work.

My workaround was quite inelegant.
Instead of the elegance of
official.date<-ifelse(is.na(x),dateyes,dateno)

I resorted to conditional indexing.
official.date<-dateno #only apporopriate when x is not missing
official.date[is.na(x)]<-dateyes[is.na(x)]


Original thread:
On Sat, 3 Jun 2006, ivo welch wrote:

> I wonder if this is an intentional feature or an oversight.

These are documented properties of the functions you are using.

> in some column summaries or in ifelse operations, apparently I am losing
> the date property of my vector.
>
...
>> ifelse( is.na(c), e, c )
> [1] 4017 4048 4076   # date property is lost

As documented. From ?ifelse:

Value:

      A vector of the same length and attributes (including class) as
      'test' and data values from the values of 'yes' or 'no'.  The mode
      of the answer will be coerced from logical to accommodate first
      any values taken from 'yes' and then any values taken from 'no'.

Note that the class is taken from 'test'.

> PS: this time I do not need help.  I can write my code around this.

Help in pointing you to the posting guide and its recommended reading of
the help page might still be helpful.





-- 
Farrel Buchinsky
GrandCentral Tel: (412) 567-7870


From ripley at stats.ox.ac.uk  Thu Sep 27 20:48:42 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 27 Sep 2007 19:48:42 +0100 (BST)
Subject: [R] center option of basehaz in survfit
In-Reply-To: <9E879E542A3E8C43B9CCF85FDEC2689C1F67BE746A@exchg-be04.aggies.usu.edu>
References: <9E879E542A3E8C43B9CCF85FDEC2689C1F67BE746A@exchg-be04.aggies.usu.edu>
Message-ID: <Pine.LNX.4.64.0709271936090.1297@gannet.stats.ox.ac.uk>

On Thu, 27 Sep 2007, David Koons wrote:

> I have a very general question about what the centering option in basehaz does to factors.  (basehaz computes the baseline cumulative hazard for a coxph object using the Breslow estimator).
>
> Lets say I'm interested in a survival model with two (dichotomous) factors and a continuous covariate.
> Variable               Possible Values
> Factor1                0 or 1
> Factor2                0 or 1
> Covariate            0 to 100
>
> I fit my model:
> modelname <- coxph(Surv ~ Factor1 + Factor2 + Covariate, data = data)
>
> If I then ask for:
> baselineA <- basehaz(modelname, centered=FALSE)
> I am fairly certain that baselineA will provide me with the cumulative hazard evaluated at Factor1 = 0, Factor2 = 0, Covariate = 0.
>
> Yet, if I ask for: baselineB <- basehaz(modelname, centered=TRUE) I know 
> that baselineB will evaluate the cumulative hazard at Covariate = 50, 
> but am uncertain as to what it does with the factors.  I would not think 
> that the function would attempt to average a "factor"; however, I cannot 
> find any documentation to support my assumption.  To make sure, does

It does average factors.  From ?coxph.object

      means: vector of column means of the X matrix.  Subsequent survival
             curves are adjusted to this value.

and so the centring is about the means of the design matrix (X) after 
expansion of categorical variables.

The code for basehaz is very simple: just list it to see that all it does 
is to remove the centring of the columns of the design matrix.

> anyone know how basehaz (centered = TRUE/FALSE) handles models that 
> include both categorical factors and continuous covariates?
>
> Thanks in advance,
> Dave Koons

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From peterwickham at mac.com  Thu Sep 27 22:50:15 2007
From: peterwickham at mac.com (Peter Wickham)
Date: Thu, 27 Sep 2007 13:50:15 -0700 (PDT)
Subject: [R] When is the periodogram is consistent with white noise?
In-Reply-To: <00a601c7c253$98bd85e0$ca3891a0$@edu>
References: <00a601c7c253$98bd85e0$ca3891a0$@edu>
Message-ID: <12930061.post@talk.nabble.com>


A  programme I wrote in R could be relevant. The reference is I. Lobato and
C. Velasco, Econometric Theory, Vol.20, 2004, "A Simple and General Test for
White Noise". The acf function and the spec.pgram function are used to
produce a transformed von Mises statistic which is approx. N(0,4). Tests are
standard and finite sample values are easily generated. The programme seems
to work OK in experiments using random numbers and AR1 series. If there is
any interest I can supply a script file.

Andre Bastos wrote:
> 
> Hello everyone,
> 
>  
> 
> This is my first time posting to the list, thanks in advance.
> 
>  
> 
> I am calculating the smoothed periodogram for the residuals of an AR model
> that I fit to EEG data. The autocorrelation plot of the residuals shows
> the
> series is now approximately white (i.e. ACF = 1 at lag 0, and close to 0
> for
> all other lags). I would like to show that the spectrum of the series is
> also approximately white.  When I calculate the periodogram using
> spec.pgram, what I get indeed looks white, but I would like to add
> horizontal threshold lines between which one can be 95% confident the
> spectrum is white.
> 
>  
> 
> Thanks,
> 
>  
> 
> -Andre
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/When-is-the-periodogram-is-consistent-with-white-noise--tf4050952.html#a12930061
Sent from the R help mailing list archive at Nabble.com.


From jloehrke at umassd.edu  Thu Sep 27 22:47:52 2007
From: jloehrke at umassd.edu (Jon Loehrke)
Date: Thu, 27 Sep 2007 16:47:52 -0400 (EDT)
Subject: [R] crashing R through lattice
Message-ID: <25638.134.88.230.79.1190926072.squirrel@email.umassd.edu>

I have been crashing R while using lattice.  My system consists of a Mac
Intel, R 2.5.1, lattice 0.15-5, and I plot through the default quartz.

R crashes after plotting several lattice functions.  Has anyone else
encountered this problem and does anyone know the cause, or a solution?

Is this a lattice:mac, lattice:quartz, Lattice:me issue?

example...

This crashes my system after plotting.

library(lattice)
haul<-as.integer(c(rep(1:12, 4)))
species<-c(rep("species 1", 12),rep("species 2", 12),rep("species 3",
12),rep("species 4", 12))
count<-c(895,540,1020,470,428,620,   760,   537,   845,  1050,   387,  
497,  1520,  1610,  1900,  1350,   980,  1710,  1930,  1960,  1840,  2410,
 1520,  1685, 43300, 32800, 28800, 34600, 27800, 32800,28100, 18900,
31400, 39500, 29000, 22300, 11000,  8600,  8260,  9830,  7600,  9650, 
8900,  6060, 10200, 15500,  9250,  7900)


qqmath(~count|species,
               	distribution=qnorm,
                prepanel=prepanel.qqmathline,
                panel = function(x,...) {
                        panel.grid()
                        panel.qqmathline(x, ...)
                        panel.qqmath(x, ...)
                },
                aspect=1,
                layout=c(2,2),#  where c=# of columns, R=Number of rows
			main=list ("QQnorm plot for 
.", cex=0.8),
                sub = list("",cex=.8),
                xlab = "Unit Normal Quantile",
                ylab=list ("variable in x units", cex=.8))


Thanks,

Jon


Jon Loehrke
Fisheries Graduate Research Assistant
School for Marine Science and Technology
UMASS-Dartmouth
838 S. Rodney French Blvd.
New Bedford, MA 02744
Phone: 508-910-6393
Fax:   508-910-6396


From marc_schwartz at comcast.net  Thu Sep 27 21:10:41 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 27 Sep 2007 14:10:41 -0500
Subject: [R] Y-axis scale in Q-Qplot
In-Reply-To: <1190913562.46fbe61aea61c@webmail.shef.ac.uk>
References: <1190913562.46fbe61aea61c@webmail.shef.ac.uk>
Message-ID: <1190920241.9666.45.camel@Bellerophon.localdomain>

On Thu, 2007-09-27 at 18:19 +0100, S Bina wrote:
> Dear All, 
> 
> I have made a Q-Qplot (qqnorm) and want to change the scale of the y-axis from
> -4 to 25.
> 
> How can I do that?
> 
> Many thanks
> Samira

You can, but the real question is: should you?

  qqnorm(x, ylim = c(-4, 25))

will give you what you want, but it will distort the graph aspect ratio
such that your 45 degree line (ie. qqline(x) ) is no longer at 45
degrees, which affects visualization.

R graphics generally have "sensible" defaults for sensible reasons.

For more information, do a Google search using the phrase:

  "banking to 45 degrees"

HTH,

Marc Schwartz


From ckang2 at gmail.com  Thu Sep 27 22:14:36 2007
From: ckang2 at gmail.com (ckang2 at gmail.com)
Date: Thu, 27 Sep 2007 16:14:36 -0400
Subject: [R] convergence problem in boolean logit
Message-ID: <c1cf87f10709271314j31b694c4m67ef1cd806ba74cc@mail.gmail.com>

Hello, folks

when I ran my boolean logit model in R, I got an error message as

> answer <- boolean (bp, link = "logit", method = "BFGS", data=pr2)
27061 observations dropped due to missing data.
Warning message:
fitted probabilities numerically 0 or 1 occurred in: glm.fit(x = X, y
= Y, weights = weights, start = start, etastart = etastart,

Could you anyone advise me how I can solve this problem?
I also tried with other method options ("method="nlm")

It is my first time to run boolean model, in addition, I'm a very
beginer user of R.

Thank you very much for your advice in advance.

Sincerely,
Charlie


From cberry at tajo.ucsd.edu  Thu Sep 27 20:53:34 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Thu, 27 Sep 2007 11:53:34 -0700
Subject: [R] A weird observation from using read.table
In-Reply-To: <296658.53591.qm@web81014.mail.mud.yahoo.com>
References: <296658.53591.qm@web81014.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.0709271103460.14373@tajo.ucsd.edu>

On Thu, 27 Sep 2007, Jun Ding wrote:

> Hi Everyone,
>
> Recently I got puzzled by the function read.table,
> even though I have used it for a long time.
>
> I have such a file (tmp.txt, 2 rows and 3 columns,
> with a space among columns):
>
> 1 2'-PDE 4
> 2 3'-PDE 5
>
> if I do:
> a = read.table("tmp.txt", header = F, quote = "")
> a
>  V1     V2 V3
> 1  1 2'-PDE  4
> 2  2 3'-PDE  5
>
> Everything is fine.
>
> However, if I do:
> a = read.table("tmp.txt", header = F)
> a
>  V1     V2 V3
> 1  2 3'-PDE  5
> 2  1 2'-PDE  4
> 3  2 3'-PDE  5
>
> I know it is related to the "quote" as the default
> includes '. But how can it get one more row in the
> file? Thank you very much for your help in advance!


read.table does a lot of work trying to figure out what kind of data it 
will see and doing preliminary checks on it before swallowing the whole 
file. It reads the first 5 lines of data thru a file() connection - if 
there are five lines - and then tries to pushBack() two copies of those 
lines. Then it rereads half of these and skips the extra header row if 
there is one. At that point, it should be positioned to read all of the 
data that was in the original file.

Declaring a quote that should not be a quote really messes this up. I 
think this happens because the internal function readTableHead will ignore 
newlines that are between quotes. In your example all of the data is read 
by readTableHead as one line because of a quote on the first line, and 
this has downstream consequences that result in not repositioning the 
connection at the right place. And that leads to reading two copies of the 
second line in your example.

If you want more details, use debug(read.table) and then run your 
examples. print 'lines', 'nlines', and 'pushBackLength( file )' at various 
points in the execution of read.table and you can see what is happening.

HTH,

Chuck


>
> Jun
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From wangyong1 at gmail.com  Thu Sep 27 23:18:18 2007
From: wangyong1 at gmail.com (Yong Wang)
Date: Thu, 27 Sep 2007 14:18:18 -0700
Subject: [R] lm error and how to sidestep an error occured in for loop to
	keep it going without being interrupted
Message-ID: <b5caa5d00709271418m17b03ea8h1b7c07731294d1e4@mail.gmail.com>

Dear Rlist

I am runing a for loop on a large dataset to do exploring
investigation. Code embedded in the loop include the "lm" routine.
Unfortunately, for some specification of dependent variable, the loop
will be interrupted by error as below:

Error in `contrasts<-`(`*tmp*`, value = "contr.treatment") :
        contrasts can be applied only to factors with 2 or more levels

I suspect this might be caused by missing value which, once removed,
will left some factors has value only on one level. It turnss out this
is not true.

Answers for following two questions appreciated.
1. what might be the possible reason behind the error mesage
2. if I simply want to circumvent this error and keep the for loop
going, how should I do that.


Regards
young


From f.harrell at vanderbilt.edu  Thu Sep 27 21:12:49 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 27 Sep 2007 14:12:49 -0500
Subject: [R] Reading SAS SD2 Data file
In-Reply-To: <1190917602.9666.29.camel@Bellerophon.localdomain>
References: <2768A5B569B1D54EA47861B9A05422E10227EC91@jade1604.UTSARR.NET>	<46FBEEDE.1090905@biostat.ku.dk>
	<1190917602.9666.29.camel@Bellerophon.localdomain>
Message-ID: <46FC00B1.3050001@vanderbilt.edu>

Marc Schwartz wrote:
> On Thu, 2007-09-27 at 19:56 +0200, Peter Dalgaard wrote:
>> Corey Sparks wrote:
>>> I am trying to read a SAS dataset into R that is in a .SD2 format, which
>>> is the Version 6 standard format from SAS.
>>>   
>> (for DOS/Windows, that is. The format was machine/OS dependent.)
> 
> That is still the case with the proprietary SAS formats. You can't read
> a SAS V9 file from Windows with SAS V9 on Linux, etc.
> 
>>> I see the routines that read the SAS XPORT format (foreign, Hmisc), but
>>> is there any way to read this one?
>>>   
>> Only commercial solutions. (SAS itself, DBMS/COPY, StatTransfer, ...) 
>> The actual format is a company secret, and noone has bothered to try and 
>> decipher it.
> 
> The XPORT (Transport) format is openly documented and is cross-platform
> compatible, which is why the FDA had standardized on it, for example.
> 
> There is the SAS System Viewer, which will open Windows based
> proprietary SAS files and enable you to save them to CSV files. It is
> _free_ and is available from here:
> 
> http://www.sas.com/apps/demosdownloads/sassystemviewer_PROD_9.1.3_sysdep.jsp?packageID=000313&jmpflag=N
> 
> It also runs under WINE on Linux, BTW.  :-)

Just note there is a bug in SAS Viewer if a character field has a comma 
or tab.  You'll get an invalid comma or tab-delimited file.  With all 
the $ it has SAS Institute is remarkably inept in certain areas (PROC 
EXPORT has the same bug).  Also SAS Viewer is much slower than 
Stat/Transfer.  By the way, Stat/Transfer will produce binary R data 
frames that can be load()ed.

Frank

> 
> HTH,
> 
> Marc Schwartz

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From dtaylor at hsph.harvard.edu  Thu Sep 27 23:28:23 2007
From: dtaylor at hsph.harvard.edu (Deanne Taylor)
Date: Thu, 27 Sep 2007 17:28:23 -0400
Subject: [R] Question on gplot heatmap.2
Message-ID: <46FBE82B.78A0.00B2.0@hsph.harvard.edu>

Hi there --

Did a google search and couldn't find an answer, so I'm writing the list --

In the gplot function heatmap.2, I've found that the actual heatmap image, when printed to the pdf() device, is about 1/4 or less of the page length.

Is there any way to increase the size or the length of the heatmap image, so it can be sent to a static device like .pdf?

I would prefer to use heatmap.2 because of the dendrogram functionality.

Thanks in advance, 

Deanne Taylor







---
Deanne Taylor PhD
Department of Biostatistics
Harvard School of Public Health
655 Huntington Avenue
Boston, MA 02115
dtaylor at hsph.harvard.edu


From adam.wilson at uconn.edu  Thu Sep 27 21:03:00 2007
From: adam.wilson at uconn.edu (Adam Wilson)
Date: Thu, 27 Sep 2007 15:03:00 -0400
Subject: [R] RMySQL NA/NULL value storage error
Message-ID: <40f373210709271203r7bbb2e2cl4fbba7a6275dc0f1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/c5868b3d/attachment.ksh 

From admin at r-cookbook.com  Fri Sep 28 00:09:24 2007
From: admin at r-cookbook.com (Jeff)
Date: Thu, 27 Sep 2007 18:09:24 -0400
Subject: [R] New R website: R-Cookbook.com
Message-ID: <40992922-C9FB-4DBD-9633-140D2796523F@r-cookbook.com>

R Community,

I've put together a website that I thought this mailing list might be  
interested in: http://www.r-cookbook.com

It's a (free) community-driven content management system for R  
"recipes", or working examples.  Some of the features of the site are  
code highlighting, recipe ratings, recipe comments, personal "recipe  
boxes" to save your favorite recipes, community tagging, RSS feeds  
for each user and for each tag, and similar recipe recommendations.

Although I imagine that many users will sort/search/find recipes by  
tags, I've implemented a linear organization for recipes as well:  
guides.  These will be compilations of "recipes", organized in a  
logical fashion as to promote understanding of the topic of that  
particular guide and introduced with user-contributed pages.  Over  
time, hopefully with the help of the community, more guides will be  
created and the ones I have will be filled-in to actually be useful.   
I have started several guides to give you an idea of the sort of  
thing I'm thinking: Introduction to R, Longitudinal Modeling in R,  
Exploratory Data Analysis in R, and more here, http://www.r- 
cookbook.com/guide

A couple of features that will be worked on in the near future are  
(1) the design of the site and (2) working on a more interactive code  
display (right now, functions are highlighted and linked to the r- 
docs, but that's it).

I hope some of you might find the site useful and perhaps even  
consider contributing your own recipes.  If you have any suggestions  
or feature requests, I'd be glad to hear them!

Jeff.


From deepayan.sarkar at gmail.com  Fri Sep 28 00:22:51 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 27 Sep 2007 15:22:51 -0700
Subject: [R] crashing R through lattice
In-Reply-To: <25638.134.88.230.79.1190926072.squirrel@email.umassd.edu>
References: <25638.134.88.230.79.1190926072.squirrel@email.umassd.edu>
Message-ID: <eb555e660709271522p4a70cb6fs881d9dbf8321d77@mail.gmail.com>

On 9/27/07, Jon Loehrke <jloehrke at umassd.edu> wrote:
> I have been crashing R while using lattice.  My system consists of a Mac
> Intel, R 2.5.1, lattice 0.15-5, and I plot through the default quartz.
>
> R crashes after plotting several lattice functions.  Has anyone else
> encountered this problem and does anyone know the cause, or a solution?
>
> Is this a lattice:mac, lattice:quartz, Lattice:me issue?

Your example doesn't crash for me (linux/x11), so not sure. Does it
crash without the weird characters in 'main'? Nothing else looks very
promising as a potential cause.

-Deepayan

> example...
>
> This crashes my system after plotting.
>
> library(lattice)
> haul<-as.integer(c(rep(1:12, 4)))
> species<-c(rep("species 1", 12),rep("species 2", 12),rep("species 3",
> 12),rep("species 4", 12))
> count<-c(895,540,1020,470,428,620,   760,   537,   845,  1050,   387,
> 497,  1520,  1610,  1900,  1350,   980,  1710,  1930,  1960,  1840,  2410,
>  1520,  1685, 43300, 32800, 28800, 34600, 27800, 32800,28100, 18900,
> 31400, 39500, 29000, 22300, 11000,  8600,  8260,  9830,  7600,  9650,
> 8900,  6060, 10200, 15500,  9250,  7900)
>
>
> qqmath(~count|species,
>                 distribution=qnorm,
>                 prepanel=prepanel.qqmathline,
>                 panel = function(x,...) {
>                         panel.grid()
>                         panel.qqmathline(x, ...)
>                         panel.qqmath(x, ...)
>                 },
>                 aspect=1,
>                 layout=c(2,2),#  where c=# of columns, R=Number of rows
>                         main=list ("QQnorm plot for ?.", cex=0.8),
>                 sub = list("",cex=.8),
>                 xlab = "Unit Normal Quantile",
>                 ylab=list ("variable in x units", cex=.8))
>
>
> Thanks,
>
> Jon
>
>
> Jon Loehrke
> Fisheries Graduate Research Assistant
> School for Marine Science and Technology
> UMASS-Dartmouth
> 838 S. Rodney French Blvd.
> New Bedford, MA 02744
> Phone: 508-910-6393
> Fax:   508-910-6396
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From therneau at mayo.edu  Fri Sep 28 00:32:27 2007
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 27 Sep 2007 17:32:27 -0500 (CDT)
Subject: [R] plot(cox.zph())
Message-ID: <200709272232.l8RMWQF29892@hsrnfs-101.mayo.edu>

The problem posed was the following:
	> fit <- coxph(....
	> zp  <- cox.zph(fit)
	> plot(zp[1])
     Error in plot.window(xlim, ylim, log, asp, ...) :
        need finite 'ylim' values

There were 21 covariates, but over 7000 events, so the Cox model fits ok.
After sending me the data, the problem, which I haven't seen before, is thus:

  In order to put a smooth curve onto the plot, cox.zph calls lm essentially 
thus
  		lm( resid ~ ns(x, df=4)
where x is the set of death times, and resid is a scaled Schoenfeld residual.  
For the data set in question x is of length 7109, and the lm call fails due to a 
singular fit!   This leads to a missing value and then eventually to the error 
message reported above.   Further exploration reveals that 4022 of the x values 
are log(.01), with the other 3087 spread out from 0 to log(365) in an 
approximately Gaussian shape.  The residuals are in two clumps from -4 to 0 and 
2 to 5, each clump dense, the histogram has two unimodal humps.

  I don't see why lm is failing.
  
  I have fixed plot.cox.zph so that it now prints an error message
     "Spline fit is singular, try a smaller degrees of freedom"
when the fit is singular.  This will at least be less confusing.  For the
data in hand
	plot(zp[1], df=2)
works fine.  

The repair will migrate to the R code in due course.  (I am currently working on 
some other updates to the survival package).

	Terry Therneau


From timb at metrumrg.com  Thu Sep 27 20:52:20 2007
From: timb at metrumrg.com (Tim Bergsma)
Date: Thu, 27 Sep 2007 14:52:20 -0400
Subject: [R] testing the contents of an environment
Message-ID: <46FBFBE4.2060200@metrumrg.com>

Suppose I want to delete everything in my working directory that is not 
a function. It seems that

sapply(ls(),is.function)

always returns FALSE, because ls() returns objects of mode character. 
How do I evaluate is.function(), not on a character string, but on the 
object that character string represents?

Thanks,

Tim


From jholtman at gmail.com  Fri Sep 28 01:06:34 2007
From: jholtman at gmail.com (jim holtman)
Date: Thu, 27 Sep 2007 19:06:34 -0400
Subject: [R] testing the contents of an environment
In-Reply-To: <46FBFBE4.2060200@metrumrg.com>
References: <46FBFBE4.2060200@metrumrg.com>
Message-ID: <644e1f320709271606g46113825sfa2007a43a9b0dab@mail.gmail.com>

Need to use 'get':

> ls(9)
 [1] "c.Factor"          "cls.console"       "date2POSIX"
"Default.par"       "delete.NULLs"
 [6] "f.apdex"           "f.area"            "f.axis"
"f.HHMMSS2hr"       "f.hr2HHMMSS"
[11] "f.integrate"       "f.queue"           "f.TimeAxis"
"file.size"         "function.print"
[16] "generate.stats"    "HrsInDay"          "level.plot"
"list.subset"       "ls.obj"
[21] "my.axis.POSIXct"   "my.func"           "my.ls"
"my.stats"          "plot.sar"
[26] "plot.srx.file"     "plotReset"         "poly.graph"
"poly.graph.legend" "poly.graph1"
[31] "print.wide"        "r.time.cvt"        "read.sar"
"ReadVMstat"        "sar.levelplot"
[36] "setParms"          "Setwd"             "time2POSIXct"
"unix2EXCEL"        "unix2POSIXct"
[41] "x.createColors"
> sapply(ls(9), function(x) is.function(get(x)))
         c.Factor       cls.console        date2POSIX
Default.par      delete.NULLs
             TRUE              TRUE              TRUE
FALSE              TRUE
          f.apdex            f.area            f.axis
f.HHMMSS2hr       f.hr2HHMMSS
             TRUE              TRUE              TRUE
TRUE              TRUE
      f.integrate           f.queue        f.TimeAxis
file.size    function.print
             TRUE              TRUE              TRUE
TRUE              TRUE
   generate.stats          HrsInDay        level.plot
list.subset            ls.obj
             TRUE              TRUE              TRUE
TRUE              TRUE
  my.axis.POSIXct           my.func             my.ls
my.stats          plot.sar
             TRUE              TRUE              TRUE
TRUE              TRUE
    plot.srx.file         plotReset        poly.graph
poly.graph.legend       poly.graph1
             TRUE              TRUE              TRUE
TRUE              TRUE
       print.wide        r.time.cvt          read.sar
ReadVMstat     sar.levelplot
             TRUE              TRUE              TRUE
TRUE              TRUE
         setParms             Setwd      time2POSIXct
unix2EXCEL      unix2POSIXct
             TRUE              TRUE              TRUE
TRUE              TRUE
   x.createColors
             TRUE
>


On 9/27/07, Tim Bergsma <timb at metrumrg.com> wrote:
> Suppose I want to delete everything in my working directory that is not
> a function. It seems that
>
> sapply(ls(),is.function)
>
> always returns FALSE, because ls() returns objects of mode character.
> How do I evaluate is.function(), not on a character string, but on the
> object that character string represents?
>
> Thanks,
>
> Tim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From r.turner at auckland.ac.nz  Fri Sep 28 01:13:32 2007
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 28 Sep 2007 11:13:32 +1200
Subject: [R] testing the contents of an environment
In-Reply-To: <46FBFBE4.2060200@metrumrg.com>
References: <46FBFBE4.2060200@metrumrg.com>
Message-ID: <B5149C39-FDD7-41FA-9ED0-C9029182D61D@auckland.ac.nz>


On 28/09/2007, at 6:52 AM, Tim Bergsma wrote:

> Suppose I want to delete everything in my working directory that is  
> not
> a function. It seems that
>
> sapply(ls(),is.function)
>
> always returns FALSE, because ls() returns objects of mode character.
> How do I evaluate is.function(), not on a character string, but on the
> object that character string represents?

sapply(ls(),function(x){is.function(get(x))})

One must distinguish between an object and its name.

(See ``Alice Through the Looking-Glass'' by Lewis Carroll aka Rev.  
Charles L. Dodgson. :-) )

			cheers,

				Rolf Turner

######################################################################
Attention:\ This e-mail message is privileged and confidenti...{{dropped}}


From scwang at swarthmore.edu  Fri Sep 28 01:14:42 2007
From: scwang at swarthmore.edu (Steve C. Wang)
Date: Thu, 27 Sep 2007 19:14:42 -0400
Subject: [R] including images in a plot
Message-ID: <p06230922c321e9bfc5a8@[130.58.92.174]>


Does anyone know if it is possible to incorporate image files (e.g., jpgs
or gifs) in an R graphic?

I would like to make a scatterplot in which each point is a small picture
of the animal represented by each value. Each picture would be a graphics
file. Is there some way to use such files as plot symbols in R?

Cheers,

Steve


-- 
--------------------------------------------------------
Steve C. Wang
Assistant Professor of Statistics
Swarthmore College
http://www.swarthmore.edu/NatSci/swang1


From lukasneraas.r at gmail.com  Fri Sep 28 01:17:10 2007
From: lukasneraas.r at gmail.com (Luke Neraas)
Date: Thu, 27 Sep 2007 15:17:10 -0800
Subject: [R] create data frame(s) from a list with different numbers of rows
Message-ID: <1f80d2810709271617i1c3c9d54o2533ae9c47f36df2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/2f3d7bfe/attachment.ksh 

From deepayan.sarkar at gmail.com  Fri Sep 28 01:38:10 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 27 Sep 2007 16:38:10 -0700
Subject: [R] testing the contents of an environment
In-Reply-To: <B5149C39-FDD7-41FA-9ED0-C9029182D61D@auckland.ac.nz>
References: <46FBFBE4.2060200@metrumrg.com>
	<B5149C39-FDD7-41FA-9ED0-C9029182D61D@auckland.ac.nz>
Message-ID: <eb555e660709271638r1aedb3c5k1f66502ccb752c9b@mail.gmail.com>

On 9/27/07, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> On 28/09/2007, at 6:52 AM, Tim Bergsma wrote:
>
> > Suppose I want to delete everything in my working directory that is
> > not
> > a function. It seems that
> >
> > sapply(ls(),is.function)
> >
> > always returns FALSE, because ls() returns objects of mode character.
> > How do I evaluate is.function(), not on a character string, but on the
> > object that character string represents?
>
> sapply(ls(),function(x){is.function(get(x))})

A conceptually simpler alternative is

sapply(ls(), exists, mode = "function", inherits = FALSE)

-Deepayan


From jholtman at gmail.com  Fri Sep 28 01:44:20 2007
From: jholtman at gmail.com (jim holtman)
Date: Thu, 27 Sep 2007 19:44:20 -0400
Subject: [R] create data frame(s) from a list with different numbers of
	rows
In-Reply-To: <1f80d2810709271617i1c3c9d54o2533ae9c47f36df2@mail.gmail.com>
References: <1f80d2810709271617i1c3c9d54o2533ae9c47f36df2@mail.gmail.com>
Message-ID: <644e1f320709271644i125e5002xa4ea0e7f543d21f7@mail.gmail.com>

Instead of:

sample.df1 <-data.frame(list.sample[[1]])
sample.df2 <-data.frame(list.sample[[2]])
sample.df3 <-data.frame(list.sample[[3]])
sample.df4 <-data.frame(list.sample[[4]])
sample.df5 <-data.frame(list.sample[[5]])
sample.df6 <-data.frame(list.sample[[6]])

use 'lapply' to create a list of dataframe:

> lapply(list.sample, data.frame)
[[1]]
    Var1 Freq
1 1  1 1  0.5
1 3  1 3  0.5
1 4  1 4  0.5
2 1  2 1  0.5
2 2  2 2  0.5
2 3  2 3  0.5
2 4  2 4  1.0
3 2  3 2  1.5
3 3  3 3  0.5
...........

You will have a list of 6 dataframes that you can then use.

On 9/27/07, Luke Neraas <lukasneraas.r at gmail.com> wrote:
> # Hello,
>
>
> # I have a list with 6 categories and with different numbers of rows.
> # I would like to change each of them into a unique data frame in order to
> match
> # values with other data frames and perform some calculations.
> # Or I could make each category or list element have the same number of rows
> and create one large data.frame.
> # below is a creation of a sample list
> # I apologize for the length in creating the list it is the only way i could
> figure
> # out how to convey my puzzle. If you scroll down you will find it as "
> list.sample."
>
>
> Loci<-4
> Pairwise<- (Loci*(Loci-1))/2
>
> #Creation of list elements
>
> c1<- c(1,4,3,2,4,1,3,2,4,3)
> c2<- c(2,4,3,4,2,3,4,1,3,2)
> c3<- c(1,3,2,4,4,3,4,4,2,2)
> c4<- c(2,3,2,3,1,3,2,4,4,3)
> c5<- c(1,2,1,1,2,2,3,3,2,1)
> c6<- c(3,2,4,3,1,1,2,3,3,4)
> c7<- c(1,2,1,2,3,2,3,2,1,2)
> c8<- c(1,2,2,3,2,3,3,4,1,2)
>
> List.elements<-cbind(c1,c2,c3,c4,c5,c6,c7,c8)
>
>
> #Locus 1
> L1.pairwise.columns <- matrix(3:ncol(List.elements), byrow=TRUE, ncol=2)
>
> Loc1.gamete.counts<- apply(L1.pairwise.columns , 1, function(.row){
>                     paste(List.elements[,1:2], List.elements[,.row])
>                 })
> #Locus2
> L2.pairwise.columns <- matrix(5:ncol(List.elements), byrow=TRUE, ncol=2)
>
> Loc2.gamete.counts<- apply(L2.pairwise.columns , 1, function(.row){
>                     paste(List.elements[,3:4], List.elements[,.row])
>                      })
> #Locus3
> L3.pairwise.columns <- matrix(7:ncol(List.elements), byrow=TRUE, ncol=2)
>
> Loc3.gamete.counts<- apply(L3.pairwise.columns , 1, function(.row){
>                     paste(List.elements[,5:6], List.elements[,.row])
>                    })
> ##Creation of the List
>
> Gamete.pairs<-cbind(Loc1.gamete.counts,Loc2.gamete.counts,Loc3.gamete.counts
> )
> Gamete.pairs
>
> Gamete.list<-list(1,2,3,4,5,6)
>
> for (i in 1:Pairwise){
>    Gamete.list[[i]]<-table(Gamete.pairs[,i])
>            }
> Gamete.list
>
> #### Gamete Frequency
>
> list.sample<-list(1,2,3,4,5,6)
>
> for (j in 1:Pairwise){
>    list.sample[[j]]<- Gamete.list[[j]]/(2*Genetic.Sample.Size)
>            }
>
> ########  Here is the Sample List
>
> list.sample
>
>
> # I would like to have a flexible way to turn all six element in my list
> # into separate data frames so i can do some calculations
> # the only way i can figure out how to do this is "one by one" in very
> clunky fashion.
> # here is an example of my code
>
> sample.df1 <-data.frame(list.sample[[1]])
> sample.df2 <-data.frame(list.sample[[2]])
> sample.df3 <-data.frame(list.sample[[3]])
> sample.df4 <-data.frame(list.sample[[4]])
> sample.df5 <-data.frame(list.sample[[5]])
> sample.df6 <-data.frame(list.sample[[6]])
>
>
> sample.df1
> sample.df2
> sample.df3
> sample.df4
> sample.df5
> sample.df6
>
> # In the future i will have up to 1,200 of these small dataframes to create.
> # is there a way to loop through the list and create many small data
> frames??
> # or perhaps make each of the  list elements the same length and create one
> large data frame??
>
> # any help or ideas would be greatly appreciated
>
> # thanks in advance
>
> Luke Neraas
>
> lukasneraas.r at gmail.com
>
> University of Alaska Fairbanks
> School of Fisheries and Ocean Sciences
> 11120 Glacier Highway
> UAF Fisheries Division
> Juneau, AK 99801
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From phhs80 at gmail.com  Fri Sep 28 02:04:29 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Fri, 28 Sep 2007 01:04:29 +0100
Subject: [R] Plots with discontinuity balls
Message-ID: <6ade6f6c0709271704j36b7e906t1104a0714a9d0f7f@mail.gmail.com>

Dear All,

Can R plot graphs like the one at

http://www.mathwords.com/f/f_assets/floor_graph.gif

with the balls at the discontinuity points?

Thanks in advance,

Paul


From jholtman at gmail.com  Fri Sep 28 02:12:29 2007
From: jholtman at gmail.com (jim holtman)
Date: Thu, 27 Sep 2007 20:12:29 -0400
Subject: [R] create data frame(s) from a list with different numbers of
	rows
In-Reply-To: <1f80d2810709271617i1c3c9d54o2533ae9c47f36df2@mail.gmail.com>
References: <1f80d2810709271617i1c3c9d54o2533ae9c47f36df2@mail.gmail.com>
Message-ID: <644e1f320709271712u2f09e0b8ne061ea9cba6aa0c8@mail.gmail.com>

Here is (I think) a shorter version of your code that is generic in
that it will handle a matrix of any number of columns:


#Creation of list elements

c1<- c(1,4,3,2,4,1,3,2,4,3)
c2<- c(2,4,3,4,2,3,4,1,3,2)
c3<- c(1,3,2,4,4,3,4,4,2,2)
c4<- c(2,3,2,3,1,3,2,4,4,3)
c5<- c(1,2,1,1,2,2,3,3,2,1)
c6<- c(3,2,4,3,1,1,2,3,3,4)
c7<- c(1,2,1,2,3,2,3,2,1,2)
c8<- c(1,2,2,3,2,3,3,4,1,2)

List.elements<-cbind(c1,c2,c3,c4,c5,c6,c7,c8)

# create counts for any size matrix
Gamete.pairs <- lapply(seq(3, ncol(List.elements), 2), function(.col){
    .pairwise <- matrix(.col:ncol(List.elements), byrow=TRUE, ncol=2)
    apply(.pairwise, 1, function(.row){
        paste(List.elements[, 1:2], List.elements[,.row])
    })
})

# now create a matrix of the results
Gamete.pairs <- do.call('cbind', Gamete.pairs)
Gamete.pairs

# do table on the matrix
Gamete.list <- apply(Gamete.pairs, 2, table)
Gamete.list

# generate frequencies
list.sample <- lapply(Gamete.list, function(.table){
    .table / sum(.table)  # not exactly sure if this matches your,
                                  # but 'Genetic.Sample.Size' was missing
})

# now put back into dataframes
myDF <- lapply(list.sample, data.frame)
myDF



On 9/27/07, Luke Neraas <lukasneraas.r at gmail.com> wrote:
> # Hello,
>
>
> # I have a list with 6 categories and with different numbers of rows.
> # I would like to change each of them into a unique data frame in order to
> match
> # values with other data frames and perform some calculations.
> # Or I could make each category or list element have the same number of rows
> and create one large data.frame.
> # below is a creation of a sample list
> # I apologize for the length in creating the list it is the only way i could
> figure
> # out how to convey my puzzle. If you scroll down you will find it as "
> list.sample."
>
>
> Loci<-4
> Pairwise<- (Loci*(Loci-1))/2
>
> #Creation of list elements
>
> c1<- c(1,4,3,2,4,1,3,2,4,3)
> c2<- c(2,4,3,4,2,3,4,1,3,2)
> c3<- c(1,3,2,4,4,3,4,4,2,2)
> c4<- c(2,3,2,3,1,3,2,4,4,3)
> c5<- c(1,2,1,1,2,2,3,3,2,1)
> c6<- c(3,2,4,3,1,1,2,3,3,4)
> c7<- c(1,2,1,2,3,2,3,2,1,2)
> c8<- c(1,2,2,3,2,3,3,4,1,2)
>
> List.elements<-cbind(c1,c2,c3,c4,c5,c6,c7,c8)
>
>
> #Locus 1
> L1.pairwise.columns <- matrix(3:ncol(List.elements), byrow=TRUE, ncol=2)
>
> Loc1.gamete.counts<- apply(L1.pairwise.columns , 1, function(.row){
>                     paste(List.elements[,1:2], List.elements[,.row])
>                 })
> #Locus2
> L2.pairwise.columns <- matrix(5:ncol(List.elements), byrow=TRUE, ncol=2)
>
> Loc2.gamete.counts<- apply(L2.pairwise.columns , 1, function(.row){
>                     paste(List.elements[,3:4], List.elements[,.row])
>                      })
> #Locus3
> L3.pairwise.columns <- matrix(7:ncol(List.elements), byrow=TRUE, ncol=2)
>
> Loc3.gamete.counts<- apply(L3.pairwise.columns , 1, function(.row){
>                     paste(List.elements[,5:6], List.elements[,.row])
>                    })
> ##Creation of the List
>
> Gamete.pairs<-cbind(Loc1.gamete.counts,Loc2.gamete.counts,Loc3.gamete.counts
> )
> Gamete.pairs
>
> Gamete.list<-list(1,2,3,4,5,6)
>
> for (i in 1:Pairwise){
>    Gamete.list[[i]]<-table(Gamete.pairs[,i])
>            }
> Gamete.list
>
> #### Gamete Frequency
>
> list.sample<-list(1,2,3,4,5,6)
>
> for (j in 1:Pairwise){
>    list.sample[[j]]<- Gamete.list[[j]]/(2*Genetic.Sample.Size)
>            }
>
> ########  Here is the Sample List
>
> list.sample
>
>
> # I would like to have a flexible way to turn all six element in my list
> # into separate data frames so i can do some calculations
> # the only way i can figure out how to do this is "one by one" in very
> clunky fashion.
> # here is an example of my code
>
> sample.df1 <-data.frame(list.sample[[1]])
> sample.df2 <-data.frame(list.sample[[2]])
> sample.df3 <-data.frame(list.sample[[3]])
> sample.df4 <-data.frame(list.sample[[4]])
> sample.df5 <-data.frame(list.sample[[5]])
> sample.df6 <-data.frame(list.sample[[6]])
>
>
> sample.df1
> sample.df2
> sample.df3
> sample.df4
> sample.df5
> sample.df6
>
> # In the future i will have up to 1,200 of these small dataframes to create.
> # is there a way to loop through the list and create many small data
> frames??
> # or perhaps make each of the  list elements the same length and create one
> large data frame??
>
> # any help or ideas would be greatly appreciated
>
> # thanks in advance
>
> Luke Neraas
>
> lukasneraas.r at gmail.com
>
> University of Alaska Fairbanks
> School of Fisheries and Ocean Sciences
> 11120 Glacier Highway
> UAF Fisheries Division
> Juneau, AK 99801
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From jholtman at gmail.com  Fri Sep 28 02:20:06 2007
From: jholtman at gmail.com (jim holtman)
Date: Thu, 27 Sep 2007 20:20:06 -0400
Subject: [R] Plots with discontinuity balls
In-Reply-To: <6ade6f6c0709271704j36b7e906t1104a0714a9d0f7f@mail.gmail.com>
References: <6ade6f6c0709271704j36b7e906t1104a0714a9d0f7f@mail.gmail.com>
Message-ID: <644e1f320709271720r7574bf9ep466cf8d4cb349919@mail.gmail.com>

Yes

?segments
?points
?pch

On 9/27/07, Paul Smith <phhs80 at gmail.com> wrote:
> Dear All,
>
> Can R plot graphs like the one at
>
> http://www.mathwords.com/f/f_assets/floor_graph.gif
>
> with the balls at the discontinuity points?
>
> Thanks in advance,
>
> Paul
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From murdoch at stats.uwo.ca  Fri Sep 28 02:57:51 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 27 Sep 2007 20:57:51 -0400
Subject: [R] Plots with discontinuity balls
In-Reply-To: <6ade6f6c0709271704j36b7e906t1104a0714a9d0f7f@mail.gmail.com>
References: <6ade6f6c0709271704j36b7e906t1104a0714a9d0f7f@mail.gmail.com>
Message-ID: <46FC518F.4080802@stats.uwo.ca>

On 27/09/2007 8:04 PM, Paul Smith wrote:
> Dear All,
> 
> Can R plot graphs like the one at
> 
> http://www.mathwords.com/f/f_assets/floor_graph.gif
> 
> with the balls at the discontinuity points?

You can use segments() to draw the segments and symbols() to draw the 
balls.  For example,

plot(1,1,type='n', xlim=c(1,10), ylim=c(1,10))
segments(1:9, 1:9, 2:10, 1:9)
symbols(2:10, 1:9, circles=rep(0.1,9), inches=FALSE, bg="white",add=T)
symbols(1:9, 1:9, circles=rep(0.1,9), inches=FALSE, bg="black",add=T)

This depends on the order of drawing, because the white background of 
the first circles obscures the ends of the segments.

Duncan Murdoch


From samuoko at yahoo.com  Thu Sep 27 13:52:50 2007
From: samuoko at yahoo.com (Samuel Okoye)
Date: Thu, 27 Sep 2007 04:52:50 -0700 (PDT)
Subject: [R] plot or boxplot!
Message-ID: <782586.57798.qm@web45310.mail.sp1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/d6493dc4/attachment.pl 

From vdemart1 at tin.it  Fri Sep 28 10:01:23 2007
From: vdemart1 at tin.it (vittorio)
Date: Fri, 28 Sep 2007 08:01:23 +0000
Subject: [R] ELF file OS ABI invalid yes?????
Message-ID: <200709280801.23543.vdemart1@tin.it>

Compilation of MCMCpack under freebsd 6.2 i386 fails because of the following 
cryptic error: 

* Installing *source* package 'MCMCpack' ...
checking for C++ compiler default output file name... a.out
checking whether the C++ compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... grep: error while 
loading shared libraries: /usr/local/lib/libpcre.so.0: ELF file OS ABI 
invalid
yes
checking whether c++ accepts -g... grep: error while loading shared 
libraries: /usr/local/lib/libpcre.so.0: ELF file OS ABI invalid
yes

What should I do?

Ciao
Vittorio


From m_olshansky at yahoo.com  Fri Sep 28 08:12:06 2007
From: m_olshansky at yahoo.com (Moshe Olshansky)
Date: Thu, 27 Sep 2007 23:12:06 -0700 (PDT)
Subject: [R] lm error and how to sidestep an error occured in for loop
	to keep it going without being interrupted
In-Reply-To: <b5caa5d00709271418m17b03ea8h1b7c07731294d1e4@mail.gmail.com>
Message-ID: <561877.43017.qm@web32203.mail.mud.yahoo.com>

For an answer to your question 2. look at help(try)
and help(tryCatch).

--- Yong Wang <wangyong1 at gmail.com> wrote:

> Dear Rlist
> 
> I am runing a for loop on a large dataset to do
> exploring
> investigation. Code embedded in the loop include the
> "lm" routine.
> Unfortunately, for some specification of dependent
> variable, the loop
> will be interrupted by error as below:
> 
> Error in `contrasts<-`(`*tmp*`, value =
> "contr.treatment") :
>         contrasts can be applied only to factors
> with 2 or more levels
> 
> I suspect this might be caused by missing value
> which, once removed,
> will left some factors has value only on one level.
> It turnss out this
> is not true.
> 
> Answers for following two questions appreciated.
> 1. what might be the possible reason behind the
> error mesage
> 2. if I simply want to circumvent this error and
> keep the for loop
> going, how should I do that.
> 
> 
> Regards
> young
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
>


From marianabotelho.r at gmail.com  Thu Sep 27 21:20:12 2007
From: marianabotelho.r at gmail.com (Mariana Botelho)
Date: Thu, 27 Sep 2007 16:20:12 -0300
Subject: [R] TukeyHSD doubts
Message-ID: <ae0a9fe10709271220t2790700dg5eb61f7f27d3343e@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado associado...
Nome: n?o dispon?vel
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/40d98276/attachment.pl 

From apu at phsa.ca  Thu Sep 27 20:21:44 2007
From: apu at phsa.ca (Pu, Aihua)
Date: Thu, 27 Sep 2007 11:21:44 -0700
Subject: [R] ReL plot(cox.zph())
In-Reply-To: <200709271303.l8RD3qF26699@hsrnfs-101.mayo.edu>
Message-ID: <C774D0F8E68B9C4B8AAB708C56B0C09D30BCE7@srvex03.phsabc.ehcnet.ca>

Hello Terry,

Thanks very much for your prompt reply.
My data set is a big one containing 9233 unique patients records (one
patient per row).
Also I checked my x variable and none of them holds constant value. I
had no problem
in generating coxph and cox.zph object. The error message only came
after the plot statement. 

I would greatly appreciate if you can give me some advices on this. 

Thank you very much,

Aihua

PS:  My R code is shown below and the data set is in the attachment in
case you want to take a look.

revasFit <- coxph(Surv(myrevas2cath_bccr, revas_b365) ~
sex_num+age5564+age6574+age75
+ v3 +vlmd
+vless50+vmiss+ef3050+ef30+efmiss+dm+renal+HPD+HTN+PVD+CVA+CHF+copd
+liver+ cancer, data=mydata)
zph.revasFit <- cox.zph(revasFit,transform='log')
plot(zph.revasFit)

 
 
 




-----Original Message-----
From: Terry Therneau [mailto:therneau at mayo.edu]
Sent: Thursday, September 27, 2007 6:04 AM
To: Pu, Aihua
Cc: R-help at stat.math.ethz.ch
Subject: ReL plot(cox.zph())

You report an error message:

> plot(zph.revasFit[1])
Error in plot.window(xlim, ylim, log, asp, ...) :
        need finite 'ylim' values

I have never seen this error before, and I cannot guess what causes it.
You
need to provide more information, and likely a small data set that
produces
the problem.  Perhaps you have an x variable that is a constant?

        Terry Therneau
       


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: mydata.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070927/00bfc322/attachment-0001.txt 

From ggrothendieck at gmail.com  Fri Sep 28 09:05:06 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 28 Sep 2007 03:05:06 -0400
Subject: [R] ifelse and dates do not work together: What workaround?
In-Reply-To: <bd93cdad0709271309u29ee908o74fb90bffb0013a8@mail.gmail.com>
References: <bd93cdad0709271309u29ee908o74fb90bffb0013a8@mail.gmail.com>
Message-ID: <971536df0709280005w7dfb7002jafd50fc139193355@mail.gmail.com>

See ?replace to do it in one line.

On 9/27/07, Farrel Buchinsky <fjbuch at gmail.com> wrote:
> I encountered the above problem. I went to the help files and
> discovered the reason why. My insight as to why it was happening did
> not immediately provide me with a solution by which I could accomplish
> what I needed to do. I turned to the help archive. I encountered a
> thread on which somebody pointed this problem out and was mildly
> castigated for not having looked at the help file. Alas no workaround
> was provided.
>
> ifelse(test, yes, no) is wonderful since it works well in a dataframe
> but only if yes and no are something simple, such as a numeric vector.
> But if yes and no are dates then it does not work.
>
> My workaround was quite inelegant.
> Instead of the elegance of
> official.date<-ifelse(is.na(x),dateyes,dateno)
>
> I resorted to conditional indexing.
> official.date<-dateno #only apporopriate when x is not missing
> official.date[is.na(x)]<-dateyes[is.na(x)]
>
>
> Original thread:
> On Sat, 3 Jun 2006, ivo welch wrote:
>
> > I wonder if this is an intentional feature or an oversight.
>
> These are documented properties of the functions you are using.
>
> > in some column summaries or in ifelse operations, apparently I am losing
> > the date property of my vector.
> >
> ...
> >> ifelse( is.na(c), e, c )
> > [1] 4017 4048 4076   # date property is lost
>
> As documented. From ?ifelse:
>
> Value:
>
>      A vector of the same length and attributes (including class) as
>      'test' and data values from the values of 'yes' or 'no'.  The mode
>      of the answer will be coerced from logical to accommodate first
>      any values taken from 'yes' and then any values taken from 'no'.
>
> Note that the class is taken from 'test'.
>
> > PS: this time I do not need help.  I can write my code around this.
>
> Help in pointing you to the posting guide and its recommended reading of
> the help page might still be helpful.
>
>
>
>
>
> --
> Farrel Buchinsky
> GrandCentral Tel: (412) 567-7870
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Fri Sep 28 09:06:18 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 28 Sep 2007 08:06:18 +0100 (BST)
Subject: [R] TukeyHSD doubts
In-Reply-To: <ae0a9fe10709271220t2790700dg5eb61f7f27d3343e@mail.gmail.com>
References: <ae0a9fe10709271220t2790700dg5eb61f7f27d3343e@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709280757280.31817@gannet.stats.ox.ac.uk>

This is a repost of
https://stat.ethz.ch/pipermail/r-help/2007-September/141727.html
Please do study the posting guide to see why you did not get an answer and 
what to do when you do not.

It is nothing to do with TukeyHSD, as the differences are there in the 
means.

It is clear that your covariates are havng an effect on the fit. 
Presumably you suspected that because you tried a fit with them included, 
and the fit with covariates is therefore the one to use.

As the posting guide points out this is not a list for statistical advice, 
so please make use of your local statistical advice service for help on 
the substantive issues here.

On Thu, 27 Sep 2007, Mariana Botelho wrote:

> Hello,
>
> I have some doubts on TukeyHSD application.
>
> I want to investigate the effects of depth, latitude and month variation on
> the length of a fish. These are orthogonal and observational data.
>
> For this, I have made an aov model (L~month+lat+prof+month*lat), after
> applying drop1 and step functions. But when I applied TukeyHSD I had
> unexpected results.
>
> For instance, I have three levels for latitude and the mean and standard
> deviation of lengths are:
>
>> aggregate(LtMm,list(FLat=FLat),mean)
>
>  FLat        x
>
> 1 24.5 431.8745
>
> 2   25 415.9973
>
> 3 25.5 416.0420
>
>
>
>> aggregate(LtMm,list(FLat=FLat),sd)
>
>  FLat        x
>
> 1 24.5 114.6516
>
> 2   25 108.9774
>
> 3 25.5 105.5219
>
>
>
> So, it's expected to have 25 and 25.5 levels closer than 24.5, and we see
> this making a simple aov model:
>
>> aov.LtArL <-aov(LtMm~FLat)
>
>> TukeyHSD(aov.LtArL, ordered = TRUE)
>
>  Tukey multiple comparisons of means
>
>    95% family-wise confidence level
>
>    factor levels have been ordered
>
>
>
> Fit: aov(formula = LtMm ~ FLat)
>
>
>
> $FLat
>
>                 diff        lwr      upr     p adj
>
> 25.5-25    0.04474535 -16.009079 16.09857 0.9999764
>
> 24.5-25   15.87715429  -5.371913 37.12622 0.1860347
>
> 24.5-25.5 15.83240894  -3.213078 34.87790 0.1251572
>
>
>
> Nevertheless, the complete model indicates just the opposite:
>
>> aov.LtAr<-aov(LtMm~FMes+FLat+FProf+FMes*FLat)
>
>> TukeyHSD(aov.LtAr,"FLat",ordered=T)
>
>  Tukey multiple comparisons of means
>
>    95% family-wise confidence level
>
>    factor levels have been ordered
>
>
>
> Fit: aov(formula = LtMm ~ FMes + FLat + FProf + FMes * FLat)
>
>
>
> $FLat
>
>              diff        lwr      upr     p adj
>
> 24.5-25.5  6.46322 -11.706623 24.63306 0.6815646
>
> 25-25.5   19.72066   4.404934 35.03639 0.0072350
>
> 25-24.5            13.25744  -7.014670 33.52955 0.2751153
>
> Which should be the right interpretation?
>
> Thanks in advance for any help!
>
> Best regards,
>
> Mariana L. L. A. Botelho
>
> MSc candidate
>
> S?o Paulo Fisheries Institute
>
> Brazil
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From FredeA.Togersen at agrsci.dk  Fri Sep 28 09:11:12 2007
From: FredeA.Togersen at agrsci.dk (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Fri, 28 Sep 2007 09:11:12 +0200
Subject: [R] including images in a plot
In-Reply-To: <p06230922c321e9bfc5a8@[130.58.92.174]>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC0574B97F@DJFPOST01.djf.agrsci.dk>

Perhaps

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/94069.html

is a good starting point?


Med venlig hilsen
Frede Aakmann T?gersen
 

 

> -----Oprindelig meddelelse-----
> Fra: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] P? vegne af Steve C. Wang
> Sendt: 28. september 2007 01:15
> Til: r-help at stat.math.ethz.ch
> Emne: [R] including images in a plot
> 
> 
> Does anyone know if it is possible to incorporate image files 
> (e.g., jpgs or gifs) in an R graphic?
> 
> I would like to make a scatterplot in which each point is a 
> small picture of the animal represented by each value. Each 
> picture would be a graphics file. Is there some way to use 
> such files as plot symbols in R?
> 
> Cheers,
> 
> Steve
> 
> 
> --
> --------------------------------------------------------
> Steve C. Wang
> Assistant Professor of Statistics
> Swarthmore College
> http://www.swarthmore.edu/NatSci/swang1
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From ggrothendieck at gmail.com  Fri Sep 28 09:42:22 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 28 Sep 2007 03:42:22 -0400
Subject: [R] converting numbers in "YYYYMM" format to last calendar day
	and last exchange trading day of the month
In-Reply-To: <919578.99144.qm@web59305.mail.re1.yahoo.com>
References: <919578.99144.qm@web59305.mail.re1.yahoo.com>
Message-ID: <971536df0709280042v3d40f7bct7c1b7fe926b75ee3@mail.gmail.com>

Using as.yearmon and as.Date.yearmon with frac=1 (both from
the zoo package), the last calendar day of the month is:

	library(zoo)
	d <- c("200701", "200702")

	lastday <- as.Date(as.yearmon(d, "%Y%m"), frac = 1)

and the zoo quickref

                vignette("zoo-quickref")

has a nextfri function that you can modify to be lastfri.  See
the help desk article in R News 4/1 for more on dates and times.

Now make a vector of holidays, h, and for each last friday
decrement it by 1 until its no longer in h.


On 9/27/07, Thomas Pujol <thomas.pujol at yahoo.com> wrote:
>    I have a vector that contains month and year in the format YYYYMM (e.g."200701", "200702")
>
>  I wish to do to things:
> 1. I need      to convert to a date that is the last calendar day of each month.
>
> 2. I need      to convert this to a date that is the last U.S. stock-exchange trading day      of each month.
>            Any advice is appreciated,
>  mymonths <- c(200701, 200702)
>
> ---------------------------------
>
>        [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From phgrosjean at sciviews.org  Fri Sep 28 10:11:41 2007
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 28 Sep 2007 10:11:41 +0200
Subject: [R] New R website: R-Cookbook.com
In-Reply-To: <40992922-C9FB-4DBD-9633-140D2796523F@r-cookbook.com>
References: <40992922-C9FB-4DBD-9633-140D2796523F@r-cookbook.com>
Message-ID: <46FCB73D.9000408@sciviews.org>

Hello Jeff,

Good initiative,... but why not to put this in the official R Wiki 
(http://wiki.r-project.org)? There is a section named 'tips' dedicated 
to such little recipes 
(http://wiki.r-project.org/rwiki/doku.php?id=tips:tips). It should be 
better to centralize all these little tips, don't you think so?

Should you have difficulties to use the Wiki, just tell me, and I will 
help...
Best,

Philippe Grosjean

..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Belgium
( ( ( ( (
..............................................................

Jeff wrote:
> R Community,
> 
> I've put together a website that I thought this mailing list might be  
> interested in: http://www.r-cookbook.com
> 
> It's a (free) community-driven content management system for R  
> "recipes", or working examples.  Some of the features of the site are  
> code highlighting, recipe ratings, recipe comments, personal "recipe  
> boxes" to save your favorite recipes, community tagging, RSS feeds  
> for each user and for each tag, and similar recipe recommendations.
> 
> Although I imagine that many users will sort/search/find recipes by  
> tags, I've implemented a linear organization for recipes as well:  
> guides.  These will be compilations of "recipes", organized in a  
> logical fashion as to promote understanding of the topic of that  
> particular guide and introduced with user-contributed pages.  Over  
> time, hopefully with the help of the community, more guides will be  
> created and the ones I have will be filled-in to actually be useful.   
> I have started several guides to give you an idea of the sort of  
> thing I'm thinking: Introduction to R, Longitudinal Modeling in R,  
> Exploratory Data Analysis in R, and more here, http://www.r- 
> cookbook.com/guide
> 
> A couple of features that will be worked on in the near future are  
> (1) the design of the site and (2) working on a more interactive code  
> display (right now, functions are highlighted and linked to the r- 
> docs, but that's it).
> 
> I hope some of you might find the site useful and perhaps even  
> consider contributing your own recipes.  If you have any suggestions  
> or feature requests, I'd be glad to hear them!
> 
> Jeff.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From phhs80 at gmail.com  Fri Sep 28 11:08:20 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Fri, 28 Sep 2007 10:08:20 +0100
Subject: [R] Plots with discontinuity balls
In-Reply-To: <46FC518F.4080802@stats.uwo.ca>
References: <6ade6f6c0709271704j36b7e906t1104a0714a9d0f7f@mail.gmail.com>
	<46FC518F.4080802@stats.uwo.ca>
Message-ID: <6ade6f6c0709280208n21e964fajb20b2225cd8f4dec@mail.gmail.com>

On 9/28/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > Can R plot graphs like the one at
> >
> > http://www.mathwords.com/f/f_assets/floor_graph.gif
> >
> > with the balls at the discontinuity points?
>
> You can use segments() to draw the segments and symbols() to draw the
> balls.  For example,
>
> plot(1,1,type='n', xlim=c(1,10), ylim=c(1,10))
> segments(1:9, 1:9, 2:10, 1:9)
> symbols(2:10, 1:9, circles=rep(0.1,9), inches=FALSE, bg="white",add=T)
> symbols(1:9, 1:9, circles=rep(0.1,9), inches=FALSE, bg="black",add=T)
>
> This depends on the order of drawing, because the white background of
> the first circles obscures the ends of the segments.

Thanks, Jim and Duncan. It would help to have transparent backgrounds
for the white balls.

Paul


From P.Dalgaard at biostat.ku.dk  Fri Sep 28 11:13:24 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 28 Sep 2007 11:13:24 +0200
Subject: [R] ifelse and dates do not work together: What workaround?
In-Reply-To: <971536df0709280005w7dfb7002jafd50fc139193355@mail.gmail.com>
References: <bd93cdad0709271309u29ee908o74fb90bffb0013a8@mail.gmail.com>
	<971536df0709280005w7dfb7002jafd50fc139193355@mail.gmail.com>
Message-ID: <46FCC5B4.9030306@biostat.ku.dk>

Gabor Grothendieck wrote:
> See ?replace to do it in one line.
>   
Also, don't miss the bleeding obvious (or so one might think...):

> z <- ifelse(TRUE, as.Date("2007-01-01"), as.Date("2007-01-02"))
> class(z) <- "Date"
> z
[1] "2007-01-01"

In the special case of censoring, you can also get away with

end <- pmin(died, endofstudy, na.rm=TRUE)

(This has the side effect of eliminating deaths recorded after end of
follow-up, which is generally a Good Thing.)

> On 9/27/07, Farrel Buchinsky <fjbuch at gmail.com> wrote:
>   
>> I encountered the above problem. I went to the help files and
>> discovered the reason why. My insight as to why it was happening did
>> not immediately provide me with a solution by which I could accomplish
>> what I needed to do. I turned to the help archive. I encountered a
>> thread on which somebody pointed this problem out and was mildly
>> castigated for not having looked at the help file. Alas no workaround
>> was provided.
>>
>> ifelse(test, yes, no) is wonderful since it works well in a dataframe
>> but only if yes and no are something simple, such as a numeric vector.
>> But if yes and no are dates then it does not work.
>>
>> My workaround was quite inelegant.
>> Instead of the elegance of
>> official.date<-ifelse(is.na(x),dateyes,dateno)
>>
>> I resorted to conditional indexing.
>> official.date<-dateno #only apporopriate when x is not missing
>> official.date[is.na(x)]<-dateyes[is.na(x)]
>>
>>
>> Original thread:
>> On Sat, 3 Jun 2006, ivo welch wrote:
>>
>>     
>>> I wonder if this is an intentional feature or an oversight.
>>>       
>> These are documented properties of the functions you are using.
>>
>>     
>>> in some column summaries or in ifelse operations, apparently I am losing
>>> the date property of my vector.
>>>
>>>       
>> ...
>>     
>>>> ifelse( is.na(c), e, c )
>>>>         
>>> [1] 4017 4048 4076   # date property is lost
>>>       
>> As documented. From ?ifelse:
>>
>> Value:
>>
>>      A vector of the same length and attributes (including class) as
>>      'test' and data values from the values of 'yes' or 'no'.  The mode
>>      of the answer will be coerced from logical to accommodate first
>>      any values taken from 'yes' and then any values taken from 'no'.
>>
>> Note that the class is taken from 'test'.
>>
>>     
>>> PS: this time I do not need help.  I can write my code around this.
>>>       
>> Help in pointing you to the posting guide and its recommended reading of
>> the help page might still be helpful.
>>
>>
>>
>>
>>
>> --
>> Farrel Buchinsky
>> GrandCentral Tel: (412) 567-7870
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>     
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From S.Ellison at lgc.co.uk  Fri Sep 28 11:13:17 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Fri, 28 Sep 2007 10:13:17 +0100
Subject: [R] Expressing number in percentage
Message-ID: <s6fcd3f6.071@tedmail2.lgc.co.uk>

Or paste(x,"%")



>>> Marc Schwartz <marc_schwartz at comcast.net> 27/09/2007 15:56:05 >>>
On Thu, 2007-09-27 at 14:36 +0100, stat stat wrote:
> I am wondering if there is any procedure to write a particular value
> in Percentage format, still maintaining it's numeric character. for
> example I want to write '.33' as '33%' 

See ?sprintf

> sprintf("%.0f%%", .33 * 100)
[1] "33%"


Note that the trailing '%' needs to be doubled to be recognized as the
character and not a format specifier.

HTH,

Marc Schwartz

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code.

*******************************************************************
This email contains information which may be confidential and/or privileged, and is intended only for the individual(s) or organisation(s) named above. If you are not the intended recipient, then please note that any disclosure, copying, distribution or use of the contents of this email is prohibited. Internet communications are not 100% secure and therefore we ask that you acknowledge this. If you have received this email in error, please notify the sender or contact +44(0)20 8943 7000 or postmaster at lgcforensics.com immediately, and delete this email and any attachments and copies from your system. Thank you. 

LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex TW11 0LY, UK

From ligges at statistik.uni-dortmund.de  Fri Sep 28 11:13:41 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 28 Sep 2007 11:13:41 +0200
Subject: [R] plot or boxplot!
In-Reply-To: <782586.57798.qm@web45310.mail.sp1.yahoo.com>
References: <782586.57798.qm@web45310.mail.sp1.yahoo.com>
Message-ID: <46FCC5C5.4070907@statistik.uni-dortmund.de>



Samuel Okoye wrote:
> Hello,
>    
>   if we suppose that
>    
>   times <- c("2006-05-14", "2006-06-12", "2006-06-12", "2006-05-14", "2006-05-14", "2006-06-12")
>   value <- c(2,3,1,4,3,1)
>    
>   then with
>    
>   plot(times, value)
>    
>   we have two boxplots in one graph for 2006-05-14 and 2006-06-12 respectively! Is it possible to have them in a scatterplot? and if I sort the data as
>    
>   x <- data.frame(times, value)
>   x <- x[order(times),]
>    
>   Is it possible to create a new variable which contains 1 for 2006-05-14 and 2 for 2006-06-12?


If you not also want to make it some time/date object, you can simply it 
a factor, hence type

times <- factor(times)

Uwe Ligges


>   Thank you very much in advance!
> 
> 
>        
> ---------------------------------
> Luggage? GPS? Comic books? 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at lgc.co.uk  Fri Sep 28 11:14:57 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Fri, 28 Sep 2007 10:14:57 +0100
Subject: [R] Expressing number in percentage
Message-ID: <s6fcd461.082@tedmail2.lgc.co.uk>

Sorry!
paste(x*100,"%")



>>> Marc Schwartz <marc_schwartz at comcast.net> 27/09/2007 15:56:05 >>>
On Thu, 2007-09-27 at 14:36 +0100, stat stat wrote:
> I am wondering if there is any procedure to write a particular value
> in Percentage format, still maintaining it's numeric character. for
> example I want to write '.33' as '33%' 

See ?sprintf

> sprintf("%.0f%%", .33 * 100)
[1] "33%"


Note that the trailing '%' needs to be doubled to be recognized as the
character and not a format specifier.

HTH,

Marc Schwartz

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code.

*******************************************************************
This email contains information which may be confidential and/or privileged, and is intended only for the individual(s) or organisation(s) named above. If you are not the intended recipient, then please note that any disclosure, copying, distribution or use of the contents of this email is prohibited. Internet communications are not 100% secure and therefore we ask that you acknowledge this. If you have received this email in error, please notify the sender or contact +44(0)20 8943 7000 or postmaster at lgcforensics.com immediately, and delete this email and any attachments and copies from your system. Thank you. 

LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex TW11 0LY, UK

From mdgi at gmx.ch  Fri Sep 28 11:21:39 2007
From: mdgi at gmx.ch (mdgi at gmx.ch)
Date: Fri, 28 Sep 2007 11:21:39 +0200
Subject: [R]   transparency of one layer in multiple wireframe plot
Message-ID: <20070928092139.314230@gmx.net>

Sorry sending this again - is anyone familiar with multiple transparent wireframe plots?

I already checked the ?wireframe, but with no examples and as newcommer its hard to find out a correct code.

If we set drape=F in the example:

g <- expand.grid(x = 1:10, y = 5:15, gr = 1:2)
g$z <- log((g$x^g$g + g$y^2) * g$gr)
wireframe(z ~ x * y, data = g, groups = gr,
          scales = list(arrows = FALSE),
          drape = F, colorkey = TRUE,
          screen = list(z = 30, x = -60))

you get a two color pic of these layers - and what I'm actually looking for is making just the UPPER (toplayer) transparent.

Thanks for further help

marc

-------- Original-Nachricht --------
> Datum: Thu, 27 Sep 2007 11:29:19 +0200
> Von: "Frede Aakmann T?gersen" <FredeA.Togersen at agrsci.dk>
> An: "marcg" <mdgi at gmx.ch>, r-help at stat.math.ethz.ch
> Betreff: SV: [R] different colors for two wireframes in same plot

> You can obtain some transparency setting the alpha transparency. This is
> device dependent though. Using the pdf device you can do this obtaining
> transparency of both surfaces (the version must be at least 1.4 for
> semitransparent output to be understood):
> 
> 
> pdf("test.pdf",version="1.4")
> wireframe(z ~ x * y, data = g, groups = gr,
>           scales = list(arrows = FALSE),
>           drape = TRUE, colorkey = TRUE,
>           screen = list(z = 30, x = -60),
>           par.settings = list(regions=list(alpha=0.75)))
> dev.off()
> 
> See ?wireframe for the "at, col.regions, alpha.regions" arguments.
> 
> Does this suffice?
> 
> 
> Med venlig hilsen
> Frede Aakmann T?gersen
>  
> 
>  
> 
> > -----Oprindelig meddelelse-----
> > Fra: r-help-bounces at r-project.org 
> > [mailto:r-help-bounces at r-project.org] P? vegne af marcg
> > Sendt: 27. september 2007 09:22
> > Til: r-help at stat.math.ethz.ch
> > Emne: [R] different colors for two wireframes in same plot
> > 
> > Hello R,
> > 
> > According to:
> > 
> > g <- expand.grid(x = 1:10, y = 5:15, gr = 1:2) g$z <- 
> > log((g$x^g$g + g$y^2) * g$gr) wireframe(z ~ x * y, data = g, 
> > groups = gr,
> >           scales = list(arrows = FALSE),
> >           drape = TRUE, colorkey = TRUE,
> >           screen = list(z = 30, x = -60))
> > 
> > i have two wireframes in one plot.
> > 
> > How could i change the color of the top - one to transparent 
> > (or only the grid). I want to give insight to the lower layer.
> > 
> > Could one make an if-statment like (if gr==1 do drape=F or 
> > color=none) if gr=2 do drape=T, colorkey=T)
> > 
> > Thanks for your help
> > 
> > Marc
> > 
> > --
> > Psssst! Schon vom neuen GMX MultiMessenger geh?rt?
> > Der kanns mit allen: http://www.gmx.net/de/go/multimessenger
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > 

--

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

--

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-- 
Psssst! Schon vom neuen GMX MultiMessenger geh?rt?
Der kanns mit allen: http://www.gmx.net/de/go/multimessenger


From P.Dalgaard at biostat.ku.dk  Fri Sep 28 11:26:20 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 28 Sep 2007 11:26:20 +0200
Subject: [R] ELF file OS ABI invalid yes?????
In-Reply-To: <200709280801.23543.vdemart1@tin.it>
References: <200709280801.23543.vdemart1@tin.it>
Message-ID: <46FCC8BC.1020809@biostat.ku.dk>

vittorio wrote:
> Compilation of MCMCpack under freebsd 6.2 i386 fails because of the following 
> cryptic error: 
>
> * Installing *source* package 'MCMCpack' ...
> checking for C++ compiler default output file name... a.out
> checking whether the C++ compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C++ compiler... grep: error while 
> loading shared libraries: /usr/local/lib/libpcre.so.0: ELF file OS ABI 
> invalid
> yes
> checking whether c++ accepts -g... grep: error while loading shared 
> libraries: /usr/local/lib/libpcre.so.0: ELF file OS ABI invalid
> yes
>
> What should I do?
>   
First check whether this has anything to do with R at all.

Does grep work from the command line? Looks like it is picking up a
shared library in /usr/local/lib, which is not valid.  Googling for the
error message ("yes" is not part of it) suggests that this happens if
you run something under Linux emulation but pick up a native BSD
library, which in turn suggest that your path to binaries and/or
libraries might be messed up. Does this ring any bells?

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From S.Ellison at lgc.co.uk  Fri Sep 28 11:45:00 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Fri, 28 Sep 2007 10:45:00 +0100
Subject: [R] Password-protect script files
Message-ID: <s6fcdb62.030@tedmail2.lgc.co.uk>

> Is there any way to password-protect script files (either within R or
> otherwise)?

The question seemed to me to be more about password protection against modification, rather than encryption.

I'd have thought this was something a decent OS could take care of. It seems as daft to try to get a stats package to manage security well as to get a security package to manage stats. Especially an open source research package!
Under Unix it's easy; mark the files read-only for users and read-write for 'r-editors' (or put them in a directory with those properties).
Under windows, stick the scripts in a shared folder with password-protected read-only access.

But better still, tie the whole lot up in a package and put the package under proper version control, so that users simply load the package and script editors act within formal change control. If you really want the stuff protected and encrypted as well, the package could decrypt on the fly as part of the function call (.


>>> Marc Schwartz <marc_schwartz at comcast.net> 26/09/2007 22:00:44 >>>
You might want to review this thread:

  http://thread.gmane.org/gmane.comp.lang.r.general/94290/ 

which covers perhaps a similar concern.

You can ignore my first reply, which covers protecting all files by
encrypting an entire partition, not just the R code file.

If that is not helpful, we will need to gain further insight into your
functional requirements.

HTH,

Marc Schwartz

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code.

*******************************************************************
This email contains information which may be confidential and/or privileged, and is intended only for the individual(s) or organisation(s) named above. If you are not the intended recipient, then please note that any disclosure, copying, distribution or use of the contents of this email is prohibited. Internet communications are not 100% secure and therefore we ask that you acknowledge this. If you have received this email in error, please notify the sender or contact +44(0)20 8943 7000 or postmaster at lgcforensics.com immediately, and delete this email and any attachments and copies from your system. Thank you. 

LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex TW11 0LY, UK

From S.Ellison at lgc.co.uk  Fri Sep 28 11:52:45 2007
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Fri, 28 Sep 2007 10:52:45 +0100
Subject: [R] Legend
Message-ID: <s6fcdd2e.074@tedmail2.lgc.co.uk>

>>> P Ehlers <ehlers at math.ucalgary.ca> 26/09/2007 11:06:54 >>>
>a <- .33
>b <- .55
>legend("bottom", fill=c("red","blue"),
>  legend=c(bquote(p == .(a)), bquote(p == .(b))), bty="n")

paste should do it:

legend("bottom", fill=c("red","blue"),
  legend=paste("p=", c(a,b), sep=""), bty="n")

and would be even easier if a and b were already in a vector.

> I have following syntax for putting a legend :
> 
> legend("bottom", fill=c("red","blue"), legend=expression(p==0.30, p==0.50), bty="n")
> 
> However what I want is that : the value "0.30" should be a value of a variable instead of a constant, so that I can put the name of this variable and in legend it's value will be displayed. Can anyone tell me how to do that?
> 
> Regards,
> 
> 
> thanks in advance
>        
> ---------------------------------
>  Why delete messages? Unlimited storage is just a click away.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.
> 
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code.

*******************************************************************
This email contains information which may be confidential and/or privileged, and is intended only for the individual(s) or organisation(s) named above. If you are not the intended recipient, then please note that any disclosure, copying, distribution or use of the contents of this email is prohibited. Internet communications are not 100% secure and therefore we ask that you acknowledge this. If you have received this email in error, please notify the sender or contact +44(0)20 8943 7000 or postmaster at lgcforensics.com immediately, and delete this email and any attachments and copies from your system. Thank you. 

LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex TW11 0LY, UK

From Joao.Fadista at agrsci.dk  Fri Sep 28 12:00:42 2007
From: Joao.Fadista at agrsci.dk (=?iso-8859-1?Q?Jo=E3o_Fadista?=)
Date: Fri, 28 Sep 2007 12:00:42 +0200
Subject: [R] Barnard's exact test
Message-ID: <EA09C4B2B0F16E44B8F3311629493C0D02ED4F8D@DJFPOST01.djf.agrsci.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070928/19d9f568/attachment.pl 

From B.Samira at sheffield.ac.uk  Fri Sep 28 12:39:45 2007
From: B.Samira at sheffield.ac.uk (S Bina)
Date: Fri, 28 Sep 2007 11:39:45 +0100
Subject: [R] kurtosis
Message-ID: <1190975985.46fcd9f1c02e8@webmail.shef.ac.uk>

Hi, 

I cannot find the function kurtosis. Is it sth additional I am meant to
download? I use the MacOS X version of R.

Many thanks
Samira


From andreia.fonseca at gmail.com  Fri Sep 28 12:55:32 2007
From: andreia.fonseca at gmail.com (andreiabb)
Date: Fri, 28 Sep 2007 03:55:32 -0700 (PDT)
Subject: [R] RMySQL installing problems
Message-ID: <12938345.post@talk.nabble.com>


Dear forum,

I'm trying to install RMySQL but I'm having problems in loading it, here is
the message that I'm getting in R
install.packages("RMySQL", dependencies=TRUE)
trying URL
'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/2.5/RMySQL_0.6-0.zip'
Content type 'application/zip' length 391364 bytes
opened URL
downloaded 382Kb

package 'RMySQL' successfully unpacked and MD5 sums checked

The downloaded packages are in
        C:\TEMP\RtmpqsmLsb\downloaded_packages
updating HTML package descriptions

> local({pkg <- select.list(sort(.packages(all.available = TRUE)))
+ if(nchar(pkg)) library(pkg, character.only=TRUE)})
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
        unable to load shared library
'C:/PROGRA~1/R/R-25~1.1/library/RMySQL/libs/RMySQL.dll':
  LoadLibrary failure:  The specified module could not be found.


Error: package/namespace load failed for 'RMySQL'


Can someone give me a tip?

Thanks

Regards

Andreia Fonseca

PhD candidate
Wageningen University

Animal Breeding and Genomics Centre

    Marijkweg 40

    P.O. Box 338

    6700 AH Wageningen

  Tel: +31 (0)  317483194


-- 
View this message in context: http://www.nabble.com/RMySQL-installing-problems-tf4533729.html#a12938345
Sent from the R help mailing list archive at Nabble.com.


From murdoch at stats.uwo.ca  Fri Sep 28 13:02:12 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 28 Sep 2007 07:02:12 -0400
Subject: [R] Plots with discontinuity balls
In-Reply-To: <6ade6f6c0709280208n21e964fajb20b2225cd8f4dec@mail.gmail.com>
References: <6ade6f6c0709271704j36b7e906t1104a0714a9d0f7f@mail.gmail.com>	<46FC518F.4080802@stats.uwo.ca>
	<6ade6f6c0709280208n21e964fajb20b2225cd8f4dec@mail.gmail.com>
Message-ID: <46FCDF34.9010802@stats.uwo.ca>

Paul Smith wrote:
> On 9/28/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>   
>>> Can R plot graphs like the one at
>>>
>>> http://www.mathwords.com/f/f_assets/floor_graph.gif
>>>
>>> with the balls at the discontinuity points?
>>>       
>> You can use segments() to draw the segments and symbols() to draw the
>> balls.  For example,
>>
>> plot(1,1,type='n', xlim=c(1,10), ylim=c(1,10))
>> segments(1:9, 1:9, 2:10, 1:9)
>> symbols(2:10, 1:9, circles=rep(0.1,9), inches=FALSE, bg="white",add=T)
>> symbols(1:9, 1:9, circles=rep(0.1,9), inches=FALSE, bg="black",add=T)
>>
>> This depends on the order of drawing, because the white background of
>> the first circles obscures the ends of the segments.
>>     
>
> Thanks, Jim and Duncan. It would help to have transparent backgrounds
> for the white balls.
>   
Then it's even easier:  just use points(), with pch=1, e.g.

plot(1,1,type='n', xlim=c(1,10), ylim=c(1,10))
segments(1:9, 1:9, 2:10, 1:9)
points(2:10, 1:9, pch=1, cex=2)
points(1:9, 1:9, pch=16, cex=2)


> Paul
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jaapvw at uj.ac.za  Fri Sep 28 13:06:07 2007
From: jaapvw at uj.ac.za (Van Wyk, Jaap)
Date: Fri, 28 Sep 2007 13:06:07 +0200
Subject: [R] Help with "old" function in "base"
Message-ID: <E50F9D3FF1B0494A84AC9937CB9E96083F6537@apk-exch-02.ad.uj.ac.za>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070928/11b43da9/attachment.pl 

From ripley at stats.ox.ac.uk  Fri Sep 28 13:14:18 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 28 Sep 2007 12:14:18 +0100 (BST)
Subject: [R] RMySQL installing problems
In-Reply-To: <12938345.post@talk.nabble.com>
References: <12938345.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0709281211350.29309@auk.stats>

You do need the RMySQL client DLLs in your PATH.  Also make sure that your 
MySQL version is not one listed as problematic at

http://www.stats.ox.ac.uk/pub/RWin/ReadMe

On Fri, 28 Sep 2007, andreiabb wrote:

>
> Dear forum,
>
> I'm trying to install RMySQL but I'm having problems in loading it, here is
> the message that I'm getting in R
> install.packages("RMySQL", dependencies=TRUE)
> trying URL
> 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/2.5/RMySQL_0.6-0.zip'
> Content type 'application/zip' length 391364 bytes
> opened URL
> downloaded 382Kb
>
> package 'RMySQL' successfully unpacked and MD5 sums checked
>
> The downloaded packages are in
>        C:\TEMP\RtmpqsmLsb\downloaded_packages
> updating HTML package descriptions
>
>> local({pkg <- select.list(sort(.packages(all.available = TRUE)))
> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>        unable to load shared library
> 'C:/PROGRA~1/R/R-25~1.1/library/RMySQL/libs/RMySQL.dll':
>  LoadLibrary failure:  The specified module could not be found.
>
>
> Error: package/namespace load failed for 'RMySQL'
>
>
> Can someone give me a tip?
>
> Thanks
>
> Regards
>
> Andreia Fonseca
>
> PhD candidate
> Wageningen University
>
> Animal Breeding and Genomics Centre
>
>    Marijkweg 40
>
>    P.O. Box 338
>
>    6700 AH Wageningen
>
>  Tel: +31 (0)  317483194
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Sep 28 13:17:32 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 28 Sep 2007 12:17:32 +0100 (BST)
Subject: [R] Help with "old" function in "base"
In-Reply-To: <E50F9D3FF1B0494A84AC9937CB9E96083F6537@apk-exch-02.ad.uj.ac.za>
References: <E50F9D3FF1B0494A84AC9937CB9E96083F6537@apk-exch-02.ad.uj.ac.za>
Message-ID: <Pine.LNX.4.64.0709281214430.29309@auk.stats>

Kernel density estimation is in package stats, and has been for over 3 
years. That package has a C entry point registered as R_band_den_bin which 
may be what you are looking for.

On Fri, 28 Sep 2007, Van Wyk, Jaap wrote:

> Hi
>
> I think there was a built-in function (perhaps C-code) called
> "band_den_bin" in the base library (used for kernel density estimators).
>
> Is there a newer version of this function. I have an old routine using
> this but it won't run in the newer version of R.
>
> Any help is much appreciated.
>
> Jacob
>
>
>
>
>
> Jacob L van Wyk
>
> Dept of Statistics
>
> University of Johannesburg, APK Campus
>
> Box 524
>
> Auckland Park 2006
>
> South Africa
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From f.calboli at imperial.ac.uk  Fri Sep 28 13:27:18 2007
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Fri, 28 Sep 2007 12:27:18 +0100
Subject: [R] errorbar il lattice plot
Message-ID: <46FCE516.6050700@imperial.ac.uk>

Hi Everyone,

I would like to add errorbars to a lattice plot. I already have a function that 
adds error bars to a plot (originally written by George Gilchrist) which takes 
as arguments the coordinates of the point and then the size of the error bar. I 
would like to integrate it in my lattice code but I seem to be stumped.

I can put the error bar function inside my code as if it were a panel function, 
but it then sits there quite unused. I am not even clear how what data object to 
put the standard errors for the thing to work...

My code (the version that at least draws a plot):

xyplot(inbreeding~generations|breeds, data = trellisplot, type = 'l', layout = 
c(2,5), col = 'black', lwd = 3,
errbar = function(x, y, err, down = T, width = 0.005, lwd = 1, plot = T, 
colour="black")
{
   up <- y + err
   dn <- y - err
   x.range <- max(x) - min(x)
   wid.lf <- x - (x.range * width)
   wid.rt <- x + (x.range * width)
   if(plot == F) {
     return(data.frame(x, up, dn))
   }
   else {
     if(down == F) {
       segments(x, up, x, y, lwd = lwd, lty = 1, col = colour)
       segments(wid.lf, up, wid.rt, up, lwd = lwd, lty = 1, col = colour)
     }
     else {
       segments(x, up, x, dn, lwd = lwd, lty = 1, col = colour)
       segments(wid.lf, up, wid.rt, up, lwd = lwd, lty = 1, col = colour)
       segments(wid.lf, dn, wid.rt, dn, lwd = lwd, lty = 1, col = colour)
     }
     invisible(data.frame(x, up, dn))
   }
}
)


Regards,

Federico Calboli

-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com


From phhs80 at gmail.com  Fri Sep 28 13:49:08 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Fri, 28 Sep 2007 12:49:08 +0100
Subject: [R] Graphics and LaTeX documents with the same font
Message-ID: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>

Dear All,

I know how to export graphics as pdf files and then how to include
them in LaTeX documents. However, I do not know how to do in order to
have the text of the graphics written with the font selected for the
LaTeX document. Is that possible?

Thanks in advance,

Paul


From phhs80 at gmail.com  Fri Sep 28 13:49:59 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Fri, 28 Sep 2007 12:49:59 +0100
Subject: [R] Plots with discontinuity balls
In-Reply-To: <46FCDF34.9010802@stats.uwo.ca>
References: <6ade6f6c0709271704j36b7e906t1104a0714a9d0f7f@mail.gmail.com>
	<46FC518F.4080802@stats.uwo.ca>
	<6ade6f6c0709280208n21e964fajb20b2225cd8f4dec@mail.gmail.com>
	<46FCDF34.9010802@stats.uwo.ca>
Message-ID: <6ade6f6c0709280449x616bd654g5cc2dfd9e83ede99@mail.gmail.com>

On 9/28/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >>> Can R plot graphs like the one at
> >>>
> >>> http://www.mathwords.com/f/f_assets/floor_graph.gif
> >>>
> >>> with the balls at the discontinuity points?
> >>>
> >> You can use segments() to draw the segments and symbols() to draw the
> >> balls.  For example,
> >>
> >> plot(1,1,type='n', xlim=c(1,10), ylim=c(1,10))
> >> segments(1:9, 1:9, 2:10, 1:9)
> >> symbols(2:10, 1:9, circles=rep(0.1,9), inches=FALSE, bg="white",add=T)
> >> symbols(1:9, 1:9, circles=rep(0.1,9), inches=FALSE, bg="black",add=T)
> >>
> >> This depends on the order of drawing, because the white background of
> >> the first circles obscures the ends of the segments.
> >>
> >
> > Thanks, Jim and Duncan. It would help to have transparent backgrounds
> > for the white balls.
> >
> Then it's even easier:  just use points(), with pch=1, e.g.
>
> plot(1,1,type='n', xlim=c(1,10), ylim=c(1,10))
> segments(1:9, 1:9, 2:10, 1:9)
> points(2:10, 1:9, pch=1, cex=2)
> points(1:9, 1:9, pch=16, cex=2)

Thanks, Duncan. That is a nice solution.

Paul


From Dietrich.Trenkler at uni-osnabrueck.de  Fri Sep 28 14:06:40 2007
From: Dietrich.Trenkler at uni-osnabrueck.de (Dietrich Trenkler)
Date: Fri, 28 Sep 2007 14:06:40 +0200
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>
Message-ID: <46FCEE50.7080109@uni-osnabrueck.de>

Paul Smith schrieb:
> Dear All,
>
> I know how to export graphics as pdf files and then how to include
> them in LaTeX documents. However, I do not know how to do in order to
> have the text of the graphics written with the font selected for the
> LaTeX document. Is that possible?
>
> Thanks in advance,
>
> Paul
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>   
Hi Paul,

maybe you will find the psfrag package useful.

Dietrich

-- 
Dietrich Trenkler c/o Universitaet Osnabrueck 
Rolandstr. 8; D-49069 Osnabrueck, Germany    
email: Dietrich.Trenkler at Uni-Osnabrueck.de


From ripley at stats.ox.ac.uk  Fri Sep 28 14:42:48 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 28 Sep 2007 13:42:48 +0100 (BST)
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>

On Fri, 28 Sep 2007, Paul Smith wrote:

> Dear All,
>
> I know how to export graphics as pdf files and then how to include
> them in LaTeX documents. However, I do not know how to do in order to
> have the text of the graphics written with the font selected for the
> LaTeX document. Is that possible?

Well, it depends on what that font is.  But if it is TeX font,
see the section called 'TeX fonts' in ?postscript and the detailed 
description in the article in R-news 6/2 by Paul Murrell and myself.

If it is an Adobe Type1 font such as Times New Roman, just specify an 
appropriate family in the pdf() call.

Dietrich Trenkler wrote:

> maybe you will find the psfrag package useful.

I doubt it will be even usable with PDF (there are pdfrack and Xfigfrag, 
though), and with postscript it is at best a kludge as R does its own 
micro-positioning of text based on the font metrics.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From lawremi at iastate.edu  Fri Sep 28 15:07:45 2007
From: lawremi at iastate.edu (Michael Lawrence)
Date: Fri, 28 Sep 2007 08:07:45 -0500
Subject: [R] Cairo on windows
In-Reply-To: <8FAF06163E22434EACB677AD054EF891023A4410@sm-exchange.groupesm.com>
References: <Pine.LNX.4.64.0709271821580.32142@gannet.stats.ox.ac.uk>
	<8FAF06163E22434EACB677AD054EF891023A4410@sm-exchange.groupesm.com>
Message-ID: <509e0620709280607x4ded3ad7gd5ab60c57a58fa11@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070928/7d5c4982/attachment.pl 

From erich.neuwirth at univie.ac.at  Fri Sep 28 15:10:42 2007
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Fri, 28 Sep 2007 15:10:42 +0200
Subject: [R] kurtosis
In-Reply-To: <1190975985.46fcd9f1c02e8@webmail.shef.ac.uk>
References: <1190975985.46fcd9f1c02e8@webmail.shef.ac.uk>
Message-ID: <46FCFD52.2010105@univie.ac.at>

According to the docs package e1071 has kurtosis.


From bolker at ufl.edu  Fri Sep 28 15:12:39 2007
From: bolker at ufl.edu (bbolker)
Date: Fri, 28 Sep 2007 06:12:39 -0700 (PDT)
Subject: [R] kurtosis
In-Reply-To: <1190975985.46fcd9f1c02e8@webmail.shef.ac.uk>
References: <1190975985.46fcd9f1c02e8@webmail.shef.ac.uk>
Message-ID: <12940268.post@talk.nabble.com>




S Bina wrote:
> 
> Hi, 
> 
> I cannot find the function kurtosis. Is it sth additional I am meant to
> download? I use the MacOS X version of R.
> 
> Many thanks
> Samira
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

 Don't think R has a built in kurtosis() function, but
see e.g.

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/84433.html

  RSiteSearch("kurtosis") would probably have gotten you some answers.

   cheers
     Ben
-- 
View this message in context: http://www.nabble.com/kurtosis-tf4533680.html#a12940268
Sent from the R help mailing list archive at Nabble.com.


From fempa at yahoo.com  Fri Sep 28 15:13:26 2007
From: fempa at yahoo.com (Svempa)
Date: Fri, 28 Sep 2007 06:13:26 -0700 (PDT)
Subject: [R] File selection by condition
Message-ID: <12940278.post@talk.nabble.com>


I have a large number of textfiles, and one matix in every texfile. I now
want to find an easy way to select those textfiles that contain at least one
value over a certain limit, and collect those matrices in a vector or
something alike. How do I do that?

-- 
View this message in context: http://www.nabble.com/File-selection-by-condition-tf4534428.html#a12940278
Sent from the R help mailing list archive at Nabble.com.


From h.wickham at gmail.com  Fri Sep 28 15:15:10 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 28 Sep 2007 08:15:10 -0500
Subject: [R] New R website: R-Cookbook.com
In-Reply-To: <40992922-C9FB-4DBD-9633-140D2796523F@r-cookbook.com>
References: <40992922-C9FB-4DBD-9633-140D2796523F@r-cookbook.com>
Message-ID: <f8e6ff050709280615i6a47ba57p7fbe45ce0dc13919@mail.gmail.com>

Hi Jeff,

That looks like a nice initiative.  However, if you are interested in
getting contributions from the community, it might be good to spell
out how others might use the content of the site.  Currently you have
copyright r-cookbook.com, but maybe you could consider a creative
commons (http://creativecommons.org/) license instead?

Hadley

On 9/27/07, Jeff <admin at r-cookbook.com> wrote:
> R Community,
>
> I've put together a website that I thought this mailing list might be
> interested in: http://www.r-cookbook.com
>
> It's a (free) community-driven content management system for R
> "recipes", or working examples.  Some of the features of the site are
> code highlighting, recipe ratings, recipe comments, personal "recipe
> boxes" to save your favorite recipes, community tagging, RSS feeds
> for each user and for each tag, and similar recipe recommendations.
>
> Although I imagine that many users will sort/search/find recipes by
> tags, I've implemented a linear organization for recipes as well:
> guides.  These will be compilations of "recipes", organized in a
> logical fashion as to promote understanding of the topic of that
> particular guide and introduced with user-contributed pages.  Over
> time, hopefully with the help of the community, more guides will be
> created and the ones I have will be filled-in to actually be useful.
> I have started several guides to give you an idea of the sort of
> thing I'm thinking: Introduction to R, Longitudinal Modeling in R,
> Exploratory Data Analysis in R, and more here, http://www.r-
> cookbook.com/guide
>
> A couple of features that will be worked on in the near future are
> (1) the design of the site and (2) working on a more interactive code
> display (right now, functions are highlighted and linked to the r-
> docs, but that's it).
>
> I hope some of you might find the site useful and perhaps even
> consider contributing your own recipes.  If you have any suggestions
> or feature requests, I'd be glad to hear them!
>
> Jeff.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
http://had.co.nz/


From phhs80 at gmail.com  Fri Sep 28 15:18:14 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Fri, 28 Sep 2007 14:18:14 +0100
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>
	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>
Message-ID: <6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>

On 9/28/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> > I know how to export graphics as pdf files and then how to include
> > them in LaTeX documents. However, I do not know how to do in order to
> > have the text of the graphics written with the font selected for the
> > LaTeX document. Is that possible?
>
> Well, it depends on what that font is.  But if it is TeX font,
> see the section called 'TeX fonts' in ?postscript and the detailed
> description in the article in R-news 6/2 by Paul Murrell and myself.
>
> If it is an Adobe Type1 font such as Times New Roman, just specify an
> appropriate family in the pdf() call.
>
> Dietrich Trenkler wrote:
>
> > maybe you will find the psfrag package useful.
>
> I doubt it will be even usable with PDF (there are pdfrack and Xfigfrag,
> though), and with postscript it is at best a kludge as R does its own
> micro-positioning of text based on the font metrics.

Thanks to both. PSTricks

http://en.wikipedia.org/wiki/PSTricks

draws figures that, when inserted in a LaTeX document, their font
matches the one selected for the LaTeX document. If I may, I would
like to submit to your consideration the suggestion of implementing
the exportation of R graphics to PSTricks.

Paul


From nobody007 at gmail.com  Fri Sep 28 15:39:40 2007
From: nobody007 at gmail.com (Flash)
Date: Fri, 28 Sep 2007 22:39:40 +0900
Subject: [R] BATCH run library problem
Message-ID: <58059650709280639ha79bf36y69e3e71eafa3b38a@mail.gmail.com>

I have installed R-2.5.1 on my linux machine (Ubuntu LTS 6.01) by
compiling the source. I have no problem to install packages on my
local folder,

/home/flash/R_LIBS

And I have no problem to load the package inside of R. for example,

>library(cluster)


However, when I'm trying to run batch command, for example,

$R CMD BATCH work1.r work1.out


( work1.r file begins with library commands, like)

library(cluster)
......


then I have the following error (copied from work1.out)
> library(cluster)
Error in library(cluster) : there is no package called 'adapt'
Execution halted

I checked the environment variables.

> options("lib")
$lib
[1] "/home/flash/R_LIBS"

> Sys.getenv("R_LIBS")
          R_LIBS
"~flash/R_LIBS"

In shell, env returns many variables and I have

R_LIBS=/home/flash/R_LIBS:/usr/local/lib64/R/library.


The only way to avoid this problem is to copy cluster directory from
/home/flash/R_LIBS to /usr/local/lib64/R/library/   .

How can I fix this problem? (or do I have to copy package directory
whenever I install new one?) Thanks in advance..

Flash.


From r-project at michael-stegh.com  Fri Sep 28 15:45:38 2007
From: r-project at michael-stegh.com (Michael Stegh)
Date: Fri, 28 Sep 2007 15:45:38 +0200
Subject: [R] Printing the contents of a list
Message-ID: <46FD21A2.14332.178BEB7@r-project.michael-stegh.com>

Dear List,

is there a way to send the contents of a variable (e.g. a list) directly to a laser printer. I am 
aware that I could save the variable to a ascii-file and then print the file, but I would prefer to 
print from R directly. 

I have been looking for a way to do so for the better part of the day now, but I could figure out 
how to do so.

Thanks,

Michael Stegh


From bop06irc at sheffield.ac.uk  Fri Sep 28 15:49:45 2007
From: bop06irc at sheffield.ac.uk (I R Cleasby)
Date: Fri, 28 Sep 2007 14:49:45 +0100
Subject: [R] Writing successful self-starting models for nlme
Message-ID: <1190987385.46fd06794b107@webmail.shef.ac.uk>



Hi fellow R users,

My problem is the following:

I wish to use the nlme package to analyse the growth curves of house sparrow
chicks, 
especially in relation to factors such as sex,  position in the weight hierarchy
etc. as fixed effects and chick ID nested within BroodID as random effects.

     The equation I wish to use to describe the chick growth is the logistic
growth function:

      W = Asym/ (1+exp(-K*(x-xmid))

  Where Asym = Asymptotic size, K is the rate constant of the equation and xmid
is the inflection point

    This is very similar to the forumla used by the self-start function SSlogis,
the Asym and xmid
 parameters are the same, however parameter K in the above equation is not the
same as parameter scal in
the simple logistic equation used by R. 

    My initial solution to this was to create my own self-start function using
the logistInit
 function in Pinheiro & Bates (2000) as a guide. Thus, my function went as
follows:


logisticSS<-

 function(mCall, LHS, data)
 {
     xy <- sortedXyData(mCall[["x"]], LHS, data)
      if (nrow(xy) <3){
          stop ("Too few distinct input values to fit a logistic")
 }
 Asym <- max(abs(xy[,"y"]))
xmid<-NLSstClosestX(xy, 0.5*Asym)
 K <- (0.781/(NLSstClosestX(xy, 0.8*Asym)-NLSstClosestX(xy, 0.15*Asym)))*4
 value<-c(Asym, xmid, K)
 names(value)<- mCall[c("Asym", "xmid", "K")]
value
 }

I then constructed a selfStart model by:

logistic<- 

    selfStart ( ~ Asym/ (1 + exp ( - K * ( x  - xmid))), initial = logisticSS,
parameters = c ("Asym", "xmid", "K"))

  for which the getInitial function is able to provide initial values.

 Problems arise when I try and use this function in an nlsList call, where I get
a warning saying: number of iterations exceeds 50, and when I use it with the
nlme, which can spend hours computing. only to result in failure to converge.
 
   My question is how would I go about improving my self start function to
allieviate these problems. I am sure there is a way to do it but I have been
unsuccessful in finding it so far. Any help would be much appreciated.

       Thank you,

                          Ian Roberts


From sergeyg at gmail.com  Fri Sep 28 16:03:24 2007
From: sergeyg at gmail.com (Sergey Goriatchev)
Date: Fri, 28 Sep 2007 16:03:24 +0200
Subject: [R] Creating nice looking lists: how?
Message-ID: <7cb007bd0709280703w474e1a8dla83ea66d3da0147a@mail.gmail.com>

Hello,

For my functions I want to create output similar in appearance to that
of what you get when you print a summary of lm model:

Residuals:
      Min        1Q         Median        3Q           Max
-0.209209 -0.043133  0.001793  0.044105  0.234750

Coefficients:
                 Estimate  Std. Error  t value    Pr(>|t|)
(Intercept)  0.981762   0.004089 240.103  < 2e-16 ***
Factor 1    -0.009581   0.006381  -1.501 0.134296
Factor 2    -0.008993   0.009182  -0.979 0.328163
Factor 3     0.029960   0.009547   3.138 0.001866 **
Factor 4    -0.026575   0.007370  -3.606 0.000363 ***
Factor 5    -0.004847   0.006382  -0.760 0.448138
Factor 6     0.005099   0.006483   0.786 0.432202
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

I want:
1) no $ before the list component names
2) component names that take values from outside variables
(ex.: number <- 10
       There are 'number' factors in the model:)

There is not much information on how to create nice output in terms of
lists, so I was looking for core to write the summary(lm) output, but
could not find much. Obviously, I can type summary.lm, but it does not
show how to create the name "Coefficients:"

Could someone give me pointers on how to create nice lists?

Thanks
Sergey


From CMiller at picr.man.ac.uk  Fri Sep 28 16:11:14 2007
From: CMiller at picr.man.ac.uk (Crispin Miller)
Date: Fri, 28 Sep 2007 15:11:14 +0100
Subject: [R] off topic: Job advert - computational biologist
Message-ID: <BAA35444B19AD940997ED02A6996AAE005C0F31D@sanmail.picr.man.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070928/ace0c3d6/attachment.pl 

From jo.irisson at gmail.com  Fri Sep 28 16:16:48 2007
From: jo.irisson at gmail.com (jiho)
Date: Fri, 28 Sep 2007 16:16:48 +0200
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>
	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>
	<6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>
Message-ID: <9D14E5C4-C061-423D-A94A-5AAAAF24A4BF@gmail.com>


On 2007-September-28  , at 15:18 , Paul Smith wrote:
> On 9/28/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>>> I know how to export graphics as pdf files and then how to include
>>> them in LaTeX documents. However, I do not know how to do in  
>>> order to
>>> have the text of the graphics written with the font selected for the
>>> LaTeX document. Is that possible?
>>
>> Well, it depends on what that font is.  But if it is TeX font,
>> see the section called 'TeX fonts' in ?postscript and the detailed
>> description in the article in R-news 6/2 by Paul Murrell and myself.
>>
>> If it is an Adobe Type1 font such as Times New Roman, just specify an
>> appropriate family in the pdf() call.
>>
>> Dietrich Trenkler wrote:
>>
>>> maybe you will find the psfrag package useful.
>>
>> I doubt it will be even usable with PDF (there are pdfrack and  
>> Xfigfrag,
>> though), and with postscript it is at best a kludge as R does its own
>> micro-positioning of text based on the font metrics.
>
> Thanks to both. PSTricks
>
> http://en.wikipedia.org/wiki/PSTricks
>
> draws figures that, when inserted in a LaTeX document, their font
> matches the one selected for the LaTeX document. If I may, I would
> like to submit to your consideration the suggestion of implementing
> the exportation of R graphics to PSTricks.

If you don't mind an extra step between R and LaTeX, you could use  
Inkscape to modify your graphics:
	http://www.inkscape.org/
It is a (very nice!) vector graphics editor which:
- works with SVGs (as produced with the RSvgDevice package)
- imports PDFs (really well in the latest development version)
- is available for free, on most platforms
and
- exports PDFs that nicely integrate in LaTeX documents
- exports PSTricks graphics
Then two roads are opened for you:
1- either get a TTF version of the LaTeX fonts (there are packages  
for this on all linux distros I know, for use with Lyx and you can  
probably find them on the web otherwise) and change all the fonts to  
those once your document is in Inkscape (select all > text and font >  
select the font)
2- or open the document with inkscape and export it to pstricks

I personally use Inkscape on all my R graphics because I find it  
easier and quicker to get decent graphics and R and refine their look  
in Inkscape than to get them perfect in R in one shot ( though with  
ggplot2 things are improving on R's side).

Cheers,

JiHO
---
http://jo.irisson.free.fr/


From sergeyg at gmail.com  Fri Sep 28 16:24:08 2007
From: sergeyg at gmail.com (Sergey Goriatchev)
Date: Fri, 28 Sep 2007 16:24:08 +0200
Subject: [R] Converting to mode numeric within a matrix
Message-ID: <7cb007bd0709280724t60596a6j74fe799eb0395b31@mail.gmail.com>

Hello,

I create a matrix:

best <- matrix(0, ncol=2, nrow=num.selected,
dimnames=list(the.best$.Name, c("Probability(%)", "Inside")))

best[,1] <- as.numeric(the.best$Total*100)

best[,2] <- ifelse(the.best$Weight==0, "No", "Yes")

What I want is the second column of mode numeric, but it is of mode
character, despite the attempt to convert it to numeric with
as.numeric(). It must have something to do with the second column of
the matrix, where I write No/Yes.
What should I do to have the first column of mode numeric?
Also, how can I output No/Yes in the second column without citation
marks around them?

Thanks in advance
Sergey


From rhelp.stats at gmail.com  Fri Sep 28 16:46:28 2007
From: rhelp.stats at gmail.com (R Help)
Date: Fri, 28 Sep 2007 11:46:28 -0300
Subject: [R] Converting to mode numeric within a matrix
In-Reply-To: <7cb007bd0709280724t60596a6j74fe799eb0395b31@mail.gmail.com>
References: <7cb007bd0709280724t60596a6j74fe799eb0395b31@mail.gmail.com>
Message-ID: <c84ed6950709280746l340d15e0s2a540744de957b6@mail.gmail.com>

Your problem is that a matrix can't be a mix of data types, but a data
frame can.  Try the following code.

newBest = as.data.frame(best)

Now you can convert the column of numbers in newBest to numbers from
the factors they start as.  Check the help file for data.frame(...)
for more details of how to label correctly.

Sam

On 9/28/07, Sergey Goriatchev <sergeyg at gmail.com> wrote:
> Hello,
>
> I create a matrix:
>
> best <- matrix(0, ncol=2, nrow=num.selected,
> dimnames=list(the.best$.Name, c("Probability(%)", "Inside")))
>
> best[,1] <- as.numeric(the.best$Total*100)
>
> best[,2] <- ifelse(the.best$Weight==0, "No", "Yes")
>
> What I want is the second column of mode numeric, but it is of mode
> character, despite the attempt to convert it to numeric with
> as.numeric(). It must have something to do with the second column of
> the matrix, where I write No/Yes.
> What should I do to have the first column of mode numeric?
> Also, how can I output No/Yes in the second column without citation
> marks around them?
>
> Thanks in advance
> Sergey
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From f.harrell at vanderbilt.edu  Fri Sep 28 16:56:31 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 28 Sep 2007 09:56:31 -0500
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>
	<6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>
Message-ID: <46FD161F.9040505@vanderbilt.edu>

Paul Smith wrote:
> On 9/28/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>>> I know how to export graphics as pdf files and then how to include
>>> them in LaTeX documents. However, I do not know how to do in order to
>>> have the text of the graphics written with the font selected for the
>>> LaTeX document. Is that possible?
>> Well, it depends on what that font is.  But if it is TeX font,
>> see the section called 'TeX fonts' in ?postscript and the detailed
>> description in the article in R-news 6/2 by Paul Murrell and myself.
>>
>> If it is an Adobe Type1 font such as Times New Roman, just specify an
>> appropriate family in the pdf() call.
>>
>> Dietrich Trenkler wrote:
>>
>>> maybe you will find the psfrag package useful.
>> I doubt it will be even usable with PDF (there are pdfrack and Xfigfrag,
>> though), and with postscript it is at best a kludge as R does its own
>> micro-positioning of text based on the font metrics.
> 
> Thanks to both. PSTricks
> 
> http://en.wikipedia.org/wiki/PSTricks
> 
> draws figures that, when inserted in a LaTeX document, their font
> matches the one selected for the LaTeX document. If I may, I would
> like to submit to your consideration the suggestion of implementing
> the exportation of R graphics to PSTricks.
> 
> Paul

See http://biostat.mc.vanderbilt.edu/PsFrag for a way to semi-automate 
the process.

Frank

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From f.harrell at vanderbilt.edu  Fri Sep 28 16:57:39 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 28 Sep 2007 09:57:39 -0500
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <9D14E5C4-C061-423D-A94A-5AAAAF24A4BF@gmail.com>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>	<6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>
	<9D14E5C4-C061-423D-A94A-5AAAAF24A4BF@gmail.com>
Message-ID: <46FD1663.5070002@vanderbilt.edu>

jiho wrote:
> On 2007-September-28  , at 15:18 , Paul Smith wrote:
>> On 9/28/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>>>> I know how to export graphics as pdf files and then how to include
>>>> them in LaTeX documents. However, I do not know how to do in  
>>>> order to
>>>> have the text of the graphics written with the font selected for the
>>>> LaTeX document. Is that possible?
>>> Well, it depends on what that font is.  But if it is TeX font,
>>> see the section called 'TeX fonts' in ?postscript and the detailed
>>> description in the article in R-news 6/2 by Paul Murrell and myself.
>>>
>>> If it is an Adobe Type1 font such as Times New Roman, just specify an
>>> appropriate family in the pdf() call.
>>>
>>> Dietrich Trenkler wrote:
>>>
>>>> maybe you will find the psfrag package useful.
>>> I doubt it will be even usable with PDF (there are pdfrack and  
>>> Xfigfrag,
>>> though), and with postscript it is at best a kludge as R does its own
>>> micro-positioning of text based on the font metrics.
>> Thanks to both. PSTricks
>>
>> http://en.wikipedia.org/wiki/PSTricks
>>
>> draws figures that, when inserted in a LaTeX document, their font
>> matches the one selected for the LaTeX document. If I may, I would
>> like to submit to your consideration the suggestion of implementing
>> the exportation of R graphics to PSTricks.
> 
> If you don't mind an extra step between R and LaTeX, you could use  
> Inkscape to modify your graphics:
> 	http://www.inkscape.org/
> It is a (very nice!) vector graphics editor which:
> - works with SVGs (as produced with the RSvgDevice package)
> - imports PDFs (really well in the latest development version)
> - is available for free, on most platforms
> and
> - exports PDFs that nicely integrate in LaTeX documents
> - exports PSTricks graphics
> Then two roads are opened for you:
> 1- either get a TTF version of the LaTeX fonts (there are packages  
> for this on all linux distros I know, for use with Lyx and you can  
> probably find them on the web otherwise) and change all the fonts to  
> those once your document is in Inkscape (select all > text and font >  
> select the font)
> 2- or open the document with inkscape and export it to pstricks
> 
> I personally use Inkscape on all my R graphics because I find it  
> easier and quicker to get decent graphics and R and refine their look  
> in Inkscape than to get them perfect in R in one shot ( though with  
> ggplot2 things are improving on R's side).
> 
> Cheers,
> 
> JiHO

As this works against principles of reproducible research, I wouldn't 
recommend it.

Frank

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From mramon at uga.edu  Fri Sep 28 17:00:35 2007
From: mramon at uga.edu (Manuel Ramon)
Date: Fri, 28 Sep 2007 11:00:35 -0400
Subject: [R] Is there a model like that in R?
Message-ID: <200709281500.IES00057@puntd1.cc.uga.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070928/627fb75b/attachment.pl 

From gustaf.rydevik at gmail.com  Fri Sep 28 17:13:07 2007
From: gustaf.rydevik at gmail.com (Gustaf Rydevik)
Date: Fri, 28 Sep 2007 17:13:07 +0200
Subject: [R] Is there a model like that in R?
In-Reply-To: <200709281500.IES00057@puntd1.cc.uga.edu>
References: <200709281500.IES00057@puntd1.cc.uga.edu>
Message-ID: <45f568c70709280813j720c9929o672fb53c5550574f@mail.gmail.com>

On 9/28/07, Manuel Ramon <mramon at uga.edu> wrote:
> Hi to everyone,
>
>
>
> I am starting to work with a model that is not familiar to me.
>
> The model would be like that:
>
>
>
>    y = . - a*max(Q(i) - Q(0), 0) + .
>
>
>
> where Q(i) is the accumulated effect of a variable at time i and Q(0) a
> threshold above it there is effect on y.  The value of Q(i) could be
> estimated as:
>
>
>
>   Q(i+1) = Q(i) + b*max(s(i) - s(0), 0) + c*min(s(i) - s(0), 0) + .
>
>
>
> Where s would be the effect that produces the accumulate effect of Q, s(i)
> would be this effect at time i and s(0) another threshold above it the
> accumulative effect is produced. The coefficient b would be the rate of
> accumulation and c the rate of decay.
>
>
>
> What kind of model is it? Is it somewhat similar to time series?
>
>
>
> I appreciate your help.
>
>
>
> Manuel Ramon
>

I'm not sure what you're describing, but something is wrong for your
definition of Q(i).

For i=1:

Q(1) = Q(0) + b*max(s(0) - s(0), 0) + c*min(s(0) - s(0), 0) +
.=Q(0)+b*0+c*0=Q(0).
Thus, Q(n)=Q(n-1)=...=Q(0)

In addition, what is intended by the dots and the final plus in "y = .
- a*max(Q(i) - Q(0), 0) + ."?

I think you have to describe things a bit more careful, if we are to
understand what's happening.

Best,

Gustaf


-- 
Gustaf Rydevik, M.Sci.
tel: +46(0)703 051 451
address:Essingetorget 40,112 66 Stockholm, SE
skype:gustaf_rydevik


From birgit.lemcke at systbot.uzh.ch  Fri Sep 28 17:13:36 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Fri, 28 Sep 2007 17:13:36 +0200
Subject: [R] simple matching with R
Message-ID: <C6494518-D49A-4952-8707-729C363F8621@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070928/61165287/attachment.pl 

From likhonnaser at hotmail.com  Fri Sep 28 17:20:32 2007
From: likhonnaser at hotmail.com (Abu Naser)
Date: Fri, 28 Sep 2007 15:20:32 +0000
Subject: [R] orientlib
Message-ID: <BAY134-W31C20CEC437D149059BCDEA3B20@phx.gbl>


Hi All user,

I have been using R-2.5.1. dose orientlib support this version? I would like to try. it.
I have been wondering how to install the library.

With regards,
abu
_________________________________________________________________
Celeb spotting ? Play CelebMashup and win cool prizes


From admin at r-cookbook.com  Fri Sep 28 17:21:22 2007
From: admin at r-cookbook.com (Jeff Spies)
Date: Fri, 28 Sep 2007 11:21:22 -0400
Subject: [R] New R website: R-Cookbook.com
In-Reply-To: <46FCB73D.9000408@sciviews.org>
References: <40992922-C9FB-4DBD-9633-140D2796523F@r-cookbook.com>
	<46FCB73D.9000408@sciviews.org>
Message-ID: <6A9A1286-9CD5-4595-BC16-3C494DF7666B@r-cookbook.com>

Hi Philippe,

I don't want to be competing in any way with any of the fantastic  
official R resources that exist; I only want to supplement them.    
Although this list is probably not the best place to discuss the  
proper use of wiki's for documentation/learning, I'll make a few  
comments on the role, I believe, R-Cookbook.com can play.

First of all, R-Cookbook.com offers two organization schemes,  
dictated by the users: linear and (what's being call) non-linear.   
Recipes can be placed in guides in order to organize content linearly  
in a way more familiar to most users.  Recipes can also be free- 
tagged, not only by the author, but by the community (much like a  
wiki--although you've actually implemented a linear scheme for tips  
and lack the non-linear aspect).

Secondly, some people like to retain authorship of these sorts of  
things, and not only for selfish reasons, like self promotion.   
First, they get to control how their message is delivered--other's  
can't edit it.  My guess is that you have the wiki configured as most  
wiki's are--community editing rights.  To counter the issues  
associated with individual-control in a community-oriented site, at R- 
Cookbook.com, other users can comment on the recipe, or express their  
regards for the quality of the recipe via the rating system.  Or they  
can create a recipe on the same topic, and the "similar recipe"  
engine should display it beneath the recipe in question.  Some people  
also like to retain authorship merely so their friends/students/fans  
can keep track of their work.  At R-Cookbook.com, users get a url  
specific to their recipes (in the format http://www.r-cookbook.com/ 
recipes/[username]) along with a feed of all of their recipes.  Also,  
this multi-level feed system is not available (I don't believe) via  
dokuwiki's framework.  If a person were only interested in  
visualization, they could use their favorite RSS news reader, and  
only keep track of recipes related to visualization.  Or if a person  
had a great deal of respect for a few authors, they could track their  
contributions the same way.

In principle, a wiki may not be the best place to store "recipes"  
either.  Because most wiki's like to have one article per topic, the  
community is forced to establish a "best" article via community  
editing.  At R-Cookbook.com, there can be more than one recipe for a  
certain problem/issue, letting the community decide the preferred  
solution via ratings/comments.  Sure, having more than one article  
can be done with a wiki's, but it almost defeats the purpose--I'm a  
purist, sorry.  ;)

More generally, recipes on R-Cookbook.com are free to go a different  
direction as what has been currently established as tips on the wiki  
(I know this can change, but I'm just saying...).  "Recipes" can be  
very problem specific, related to many topics, or very specific to  
the authors data, or whatever the case may be--not necessarily  
related to one method of analysis or one function.  Where would  
something like that go in your current linear organization of tips?   
At R-Cookbook.com, I would still appreciate and value the  
contribution because someone might find it useful, and they could  
discover it via tags, the search engine, a user feed, or the similar  
recommendation engine.  Personally, I just don't see a place for that  
sort of entry in the wiki.

With all of that said, if there is anything at R-cookbook.com that  
you believe would benefit the wiki more than perhaps a link to the  
recipe, the content is freely available to the public, and it is in  
your rights to put it there.

Again, the site is purely to support the community, and I really  
don't believe it is in competition with what your wiki offers.  I'd  
be glad to continue this discussion off-list and appreciate you  
bringing up the point though, it's a good question, that I hope I've  
answered.

Jeff.

On Sep 28, 2007, at 4:11 AM, Philippe Grosjean wrote:

> Hello Jeff,
>
> Good initiative,... but why not to put this in the official R Wiki
> (http://wiki.r-project.org)? There is a section named 'tips' dedicated
> to such little recipes
> (http://wiki.r-project.org/rwiki/doku.php?id=tips:tips). It should be
> better to centralize all these little tips, don't you think so?
>
> Should you have difficulties to use the Wiki, just tell me, and I will
> help...
> Best,
>
> Philippe Grosjean
>
> ..............................................<?}))><........
>   ) ) ) ) )
> ( ( ( ( (    Prof. Philippe Grosjean
>   ) ) ) ) )
> ( ( ( ( (    Numerical Ecology of Aquatic Systems
>   ) ) ) ) )   Mons-Hainaut University, Belgium
> ( ( ( ( (
> ..............................................................
>
> Jeff wrote:
>> R Community,
>>
>> I've put together a website that I thought this mailing list might be
>> interested in: http://www.r-cookbook.com
>>
>> It's a (free) community-driven content management system for R
>> "recipes", or working examples.  Some of the features of the site are
>> code highlighting, recipe ratings, recipe comments, personal "recipe
>> boxes" to save your favorite recipes, community tagging, RSS feeds
>> for each user and for each tag, and similar recipe recommendations.
>>
>> Although I imagine that many users will sort/search/find recipes by
>> tags, I've implemented a linear organization for recipes as well:
>> guides.  These will be compilations of "recipes", organized in a
>> logical fashion as to promote understanding of the topic of that
>> particular guide and introduced with user-contributed pages.  Over
>> time, hopefully with the help of the community, more guides will be
>> created and the ones I have will be filled-in to actually be useful.
>> I have started several guides to give you an idea of the sort of
>> thing I'm thinking: Introduction to R, Longitudinal Modeling in R,
>> Exploratory Data Analysis in R, and more here, http://www.r-
>> cookbook.com/guide
>>
>> A couple of features that will be worked on in the near future are
>> (1) the design of the site and (2) working on a more interactive code
>> display (right now, functions are highlighted and linked to the r-
>> docs, but that's it).
>>
>> I hope some of you might find the site useful and perhaps even
>> consider contributing your own recipes.  If you have any suggestions
>> or feature requests, I'd be glad to hear them!
>>
>> Jeff.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ptit_bleu at yahoo.fr  Fri Sep 28 17:22:08 2007
From: ptit_bleu at yahoo.fr (Ptit_Bleu)
Date: Fri, 28 Sep 2007 08:22:08 -0700 (PDT)
Subject: [R] Creating nice looking lists: how?
In-Reply-To: <7cb007bd0709280703w474e1a8dla83ea66d3da0147a@mail.gmail.com>
References: <7cb007bd0709280703w474e1a8dla83ea66d3da0147a@mail.gmail.com>
Message-ID: <12942721.post@talk.nabble.com>


Hi,

I don't know if it will help you but to retrieve the slope of lm(y~x), I use
:
coefficients(lm(y~x))[2]
([1] for the intercept)

I should not tell this but It took me a long time to find this obvious
thing.

Have a nice week-end,
Ptit Bleu.

--------------------------------------------------------

Sergey Goriatchev wrote:
> 
> Hello,
> 
> For my functions I want to create output similar in appearance to that
> of what you get when you print a summary of lm model:
> 
> Residuals:
>       Min        1Q         Median        3Q           Max
> -0.209209 -0.043133  0.001793  0.044105  0.234750
> 
> Coefficients:
>                  Estimate  Std. Error  t value    Pr(>|t|)
> (Intercept)  0.981762   0.004089 240.103  < 2e-16 ***
> Factor 1    -0.009581   0.006381  -1.501 0.134296
> Factor 2    -0.008993   0.009182  -0.979 0.328163
> Factor 3     0.029960   0.009547   3.138 0.001866 **
> Factor 4    -0.026575   0.007370  -3.606 0.000363 ***
> Factor 5    -0.004847   0.006382  -0.760 0.448138
> Factor 6     0.005099   0.006483   0.786 0.432202
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> I want:
> 1) no $ before the list component names
> 2) component names that take values from outside variables
> (ex.: number <- 10
>        There are 'number' factors in the model:)
> 
> There is not much information on how to create nice output in terms of
> lists, so I was looking for core to write the summary(lm) output, but
> could not find much. Obviously, I can type summary.lm, but it does not
> show how to create the name "Coefficients:"
> 
> Could someone give me pointers on how to create nice lists?
> 
> Thanks
> Sergey
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/Creating-nice-looking-lists%3A-how--tf4534730.html#a12942721
Sent from the R help mailing list archive at Nabble.com.


From jo.irisson at gmail.com  Fri Sep 28 17:25:06 2007
From: jo.irisson at gmail.com (jiho)
Date: Fri, 28 Sep 2007 17:25:06 +0200
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <46FD1663.5070002@vanderbilt.edu>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>	<6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>
	<9D14E5C4-C061-423D-A94A-5AAAAF24A4BF@gmail.com>
	<46FD1663.5070002@vanderbilt.edu>
Message-ID: <DEAF35A7-190B-4F78-B7AD-3038A079CE9A@gmail.com>


On 2007-September-28  , at 16:57 , Frank E Harrell Jr wrote:
> jiho wrote:
>> On 2007-September-28  , at 15:18 , Paul Smith wrote:
>>> On 9/28/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>>>>> I know how to export graphics as pdf files and then how to include
>>>>> them in LaTeX documents. However, I do not know how to do in   
>>>>> order to
>>>>> have the text of the graphics written with the font selected  
>>>>> for the
>>>>> LaTeX document. Is that possible?
>>>> [...]
>> If you don't mind an extra step between R and LaTeX, you could  
>> use  Inkscape to modify your graphics:
>> 	http://www.inkscape.org/
>> It is a (very nice!) vector graphics editor which:
>> - works with SVGs (as produced with the RSvgDevice package)
>> - imports PDFs (really well in the latest development version)
>> - is available for free, on most platforms
>> and
>> - exports PDFs that nicely integrate in LaTeX documents
>> - exports PSTricks graphics
>> Then two roads are opened for you:
>> 1- either get a TTF version of the LaTeX fonts (there are  
>> packages  for this on all linux distros I know, for use with Lyx  
>> and you can  probably find them on the web otherwise) and change  
>> all the fonts to  those once your document is in Inkscape (select  
>> all > text and font >  select the font)
>> 2- or open the document with inkscape and export it to pstricks
>> I personally use Inkscape on all my R graphics because I find it   
>> easier and quicker to get decent graphics and R and refine their  
>> look  in Inkscape than to get them perfect in R in one shot  
>> ( though with  ggplot2 things are improving on R's side).

> As this works against principles of reproducible research, I  
> wouldn't recommend it.

Do you consider that changing the font size of the graphic would be  
altering the research result? Or laying out a 2d contour and a 3d  
plot in parallel, or changing the line color/pattern...? My  
modifications are usually of this kind. Of course those things are  
doable with R but they are usually immensely easier in a graphics  
program (where the color palettes are predefined, the dash patterns  
are more diverse etc.).

For example, I often find myself using the same plot in an article, a  
presentation, and a poster, usually with different color palettes and  
font requirements. I just open the pdf, change the colors, font and  
font size to match the design of the article/presentation/poster,  
realign the labels a bit and re-save it. I don't think that I am  
doing any harm to my result or present any false information to the  
readers, I just make the graphics easier on their eyes.

But maybe I am a bit too much of a purist on these maters. I just  
find that, much too often, research results that represent months of  
work are presented as narrow, black and white (possibly even  
pixallated!) captures of article graphics which don't do justice to  
the quality of the work behind them. I don't think there is any harm  
in making (good) science look a bit "sexier", do you?

Jean-Olivier Irisson
---
UMR 5244 CNRS-EPHE-UPVD, 52 av Paul Alduy, 66860 Perpignan Cedex, France
+336 21 05 19 90
http://jo.irisson.free.fr/work/


From kathryn-chaloner at uiowa.edu  Fri Sep 28 17:35:44 2007
From: kathryn-chaloner at uiowa.edu (Chaloner, Kathryn)
Date: Fri, 28 Sep 2007 10:35:44 -0500
Subject: [R] lmer giving negative, or no, estimated standard errors
Message-ID: <6401901AB2195C4985538FFB4F8592A3DDD1A8@IOWAEVS03.iowa.uiowa.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070928/c55a9bb2/attachment.pl 

From stubben at lanl.gov  Fri Sep 28 17:42:44 2007
From: stubben at lanl.gov (Chris Stubben)
Date: Fri, 28 Sep 2007 08:42:44 -0700 (PDT)
Subject: [R] RMySQL NA/NULL value storage error
In-Reply-To: <40f373210709271203r7bbb2e2cl4fbba7a6275dc0f1@mail.gmail.com>
References: <40f373210709271203r7bbb2e2cl4fbba7a6275dc0f1@mail.gmail.com>
Message-ID: <12943167.post@talk.nabble.com>



Adam Wilson-4 wrote:
> 
> I am running R 2.5.1, RMySQL 0.6 , and DBI 0.2-3 on Windows XP
> 
> Like others, I am having trouble with NA/Null value conversions between R
> and a MySQL database via DBI, but I could not find my exact problem in the
> archives.  Most of the time NA values in R get transferred correctly to
> the
> database and back again, unless (apparently) if they are in the last
> column
> of the table being saved.
> 

I have the R 2.5.0, RMySQL 0.6 , and DBI 0.2-3 on Linux and don't get this
problem.

What do you get running 

>  str(x)

>  dbGetQuery(test,"describe x")
   Field   Type Null Key Default Extra
 1    X1 double  YES        <NA>
 2    X2 double  YES        <NA>
 3    X3 double  YES        <NA>
 4    X4 double  YES        <NA>

>  dbGetInfo(test)$serverVersion
 [1] "5.0.41"


Chris


-- 
View this message in context: http://www.nabble.com/RMySQL-NA-NULL-value-storage-error-tf4531309.html#a12943167
Sent from the R help mailing list archive at Nabble.com.


From deepayan.sarkar at gmail.com  Fri Sep 28 18:15:10 2007
From: deepayan.sarkar at gmail.com (deepayan.sarkar at gmail.com)
Date: Fri, 28 Sep 2007 09:15:10 -0700
Subject: [R] errorbar il lattice plot
In-Reply-To: <46FCE516.6050700@imperial.ac.uk>
References: <46FCE516.6050700@imperial.ac.uk>
Message-ID: <eb555e660709280915t3d07e02u45d482dbbbef3d8d@mail.gmail.com>

On 9/28/07, Federico Calboli <f.calboli at imperial.ac.uk> wrote:
> Hi Everyone,
>
> I would like to add errorbars to a lattice plot. I already have a function
> that
> adds error bars to a plot (originally written by George Gilchrist) which
> takes
> as arguments the coordinates of the point and then the size of the error
> bar. I
> would like to integrate it in my lattice code but I seem to be stumped.
>
> I can put the error bar function inside my code as if it were a panel
> function,
> but it then sits there quite unused. I am not even clear how what data
> object to
> put the standard errors for the thing to work...

I'm not sure why you expect anything to happen. Your 'errbar' argument
gets passed to the panel function panel.xyplot, but of course it knows
nothing about any such argument and ignores it. Even if you manage to
get 'errbar' executed, it's not clear where the 'err' values are going
to come from. Finally, for a lattice panel function, you need to
replace segments() by panel.segments(), etc.

Lattice does contain a demo showing how to draw confidence intervals; see

file.show(system.file("demo/intervals.R", package = "lattice"))

There have been a couple of follow up messages dealing with how to
extend this to grouped displays; these are found easily by an online
search.

-Deepayan

>
> My code (the version that at least draws a plot):
>
> xyplot(inbreeding~generations|breeds, data = trellisplot, type = 'l', layout
> =
> c(2,5), col = 'black', lwd = 3,
> errbar = function(x, y, err, down = T, width = 0.005, lwd = 1, plot = T,
> colour="black")
> {
>    up <- y + err
>    dn <- y - err
>    x.range <- max(x) - min(x)
>    wid.lf <- x - (x.range * width)
>    wid.rt <- x + (x.range * width)
>    if(plot == F) {
>      return(data.frame(x, up, dn))
>    }
>    else {
>      if(down == F) {
>        segments(x, up, x, y, lwd = lwd, lty = 1, col = colour)
>        segments(wid.lf, up, wid.rt, up, lwd = lwd, lty = 1, col = colour)
>      }
>      else {
>        segments(x, up, x, dn, lwd = lwd, lty = 1, col = colour)
>        segments(wid.lf, up, wid.rt, up, lwd = lwd, lty = 1, col = colour)
>        segments(wid.lf, dn, wid.rt, dn, lwd = lwd, lty = 1, col = colour)
>      }
>      invisible(data.frame(x, up, dn))
>    }
> }
> )
>
>
> Regards,
>
> Federico Calboli
>
> --
> Federico C. F. Calboli
> Department of Epidemiology and Public Health
> Imperial College, St Mary's Campus
> Norfolk Place, London W2 1PG
>
> Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193
>
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jspies at nd.edu  Fri Sep 28 18:25:00 2007
From: jspies at nd.edu (Jeffrey Robert Spies)
Date: Fri, 28 Sep 2007 12:25:00 -0400
Subject: [R] simple matching with R
In-Reply-To: <C6494518-D49A-4952-8707-729C363F8621@systbot.uzh.ch>
References: <C6494518-D49A-4952-8707-729C363F8621@systbot.uzh.ch>
Message-ID: <280081D6-4D3A-46CC-BA52-364170E75A28@nd.edu>

Not sure how you want to handle the NAs, but you could try the  
following:

#start
MalVar29_37 <- read.table(textConnection("V1 V2 V3 V4 V5 V6 V7 V8 V9
0  0  0  0  0  1  0  0  0
0  0  0  0  0  1  0  0  0
0  0  0  0  0  1  0  0  0
NA NA NA NA NA NA NA NA NA
0  1  0  0  0  1  0  0  0"), header=TRUE)

FemVar29_37 <- read.table(textConnection("     V1 V2 V3 V4 V5 V6 V7  
V8 V9
1  1  0  0  0  0  0  0  0
0  1  0  0  1  1  0  0  0
1  0  0  1  0  0  0  0  0
0  1  0  0  1  0  0  0  0
0  1  0  0  0  0  0  0  0"), header=TRUE)

comparison <- MalVar29_37 == FemVar29_37

dissimilar <- function(tRow){
	length(tRow[tRow==FALSE])
}

dissimilarity <- apply(comparison, c(1), dissimilar)
dissimilarity
# finish

Variable comparison is an entry by entry comparison, resulting in  
values of TRUE or FALSE.  I've defined a function dissimilar as the  
number of FALSEs in a given object (tRow).  Variable dissimilarity is  
then the application of this dissimilar function for each row of  
comparison.  In this example, 0 means all of the entries in a row  
matche, 9 means none of them matched.  You can see the solution here  
in recipe form: http://www.r-cookbook.com/node/40

Hope this helps,

Jeff.

On Sep 28, 2007, at 11:13 AM, Birgit Lemcke wrote:

> Hello!
>
> I am R beginner and I have a question obout a simple matching.
>
> I have to datasets that i read in with:
>
> MalVar29_37<-read.table("MalVar29_37.csv", sep = ";")
> FemVar29_37<-read.table("FemVar29_37.csv", sep = ";")
>
> They look like this and show binary variables:
>
>      V1 V2 V3 V4 V5 V6 V7 V8 V9
> 1    0  0  0  0  0  1  0  0  0
> 2    0  0  0  0  0  1  0  0  0
> 3    0  0  0  0  0  1  0  0  0
> 4   NA NA NA NA NA NA NA NA NA
> 5    0  1  0  0  0  1  0  0  0
>
>      V1 V2 V3 V4 V5 V6 V7 V8 V9
> 1    1  1  0  0  0  0  0  0  0
> 2    0  1  0  0  1  1  0  0  0
> 3    1  0  0  1  0  0  0  0  0
> 4    0  1  0  0  1  0  0  0  0
> 5    0  1  0  0  0  0  0  0  0
>
> each with 348 rows.
>
> I would like to perform a simple matching but only row 1 compared to
> row1, row 2 compared to row 2 (paired).......giving back a number as
> dissimilarity for each comparison.
>
> How can i do that?
>
> Thanks in advance
>
> Birgit
>
>
>
>
> Birgit Lemcke
> Institut f?r Systematische Botanik
> Zollikerstrasse 107
> CH-8008 Z?rich
> Switzerland
> Ph: +41 (0)44 634 8351
> birgit.lemcke at systbot.uzh.ch
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From f.harrell at vanderbilt.edu  Fri Sep 28 18:25:46 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 28 Sep 2007 11:25:46 -0500
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <DEAF35A7-190B-4F78-B7AD-3038A079CE9A@gmail.com>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>	<6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>
	<9D14E5C4-C061-423D-A94A-5AAAAF24A4BF@gmail.com>
	<46FD1663.5070002@vanderbilt.edu>
	<DEAF35A7-190B-4F78-B7AD-3038A079CE9A@gmail.com>
Message-ID: <46FD2B0A.1000205@vanderbilt.edu>

jiho wrote:
> 
> On 2007-September-28  , at 16:57 , Frank E Harrell Jr wrote:
>> jiho wrote:
>>> On 2007-September-28  , at 15:18 , Paul Smith wrote:
>>>> On 9/28/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>>>>>> I know how to export graphics as pdf files and then how to include
>>>>>> them in LaTeX documents. However, I do not know how to do in  
>>>>>> order to
>>>>>> have the text of the graphics written with the font selected for the
>>>>>> LaTeX document. Is that possible?
>>>>> [...]
>>> If you don't mind an extra step between R and LaTeX, you could use  
>>> Inkscape to modify your graphics:
>>>     http://www.inkscape.org/
>>> It is a (very nice!) vector graphics editor which:
>>> - works with SVGs (as produced with the RSvgDevice package)
>>> - imports PDFs (really well in the latest development version)
>>> - is available for free, on most platforms
>>> and
>>> - exports PDFs that nicely integrate in LaTeX documents
>>> - exports PSTricks graphics
>>> Then two roads are opened for you:
>>> 1- either get a TTF version of the LaTeX fonts (there are packages  
>>> for this on all linux distros I know, for use with Lyx and you can  
>>> probably find them on the web otherwise) and change all the fonts to  
>>> those once your document is in Inkscape (select all > text and font 
>>> >  select the font)
>>> 2- or open the document with inkscape and export it to pstricks
>>> I personally use Inkscape on all my R graphics because I find it  
>>> easier and quicker to get decent graphics and R and refine their 
>>> look  in Inkscape than to get them perfect in R in one shot ( though 
>>> with  ggplot2 things are improving on R's side).
> 
>> As this works against principles of reproducible research, I wouldn't 
>> recommend it.
> 
> Do you consider that changing the font size of the graphic would be 
> altering the research result? Or laying out a 2d contour and a 3d plot 

Not per se, but accidents happen when editing graphics.  More 
importantly it creates more work.  Datasets get updated/corrected and 
graphics need to be reproduced.

> in parallel, or changing the line color/pattern...? My modifications are 
> usually of this kind. Of course those things are doable with R but they 
> are usually immensely easier in a graphics program (where the color 
> palettes are predefined, the dash patterns are more diverse etc.).
> 
> For example, I often find myself using the same plot in an article, a 
> presentation, and a poster, usually with different color palettes and 
> font requirements. I just open the pdf, change the colors, font and font 
> size to match the design of the article/presentation/poster, realign the 
> labels a bit and re-save it. I don't think that I am doing any harm to 
> my result or present any false information to the readers, I just make 
> the graphics easier on their eyes.

A great application for a wrapper graphics function with an argument for 
presentation mode.

> 
> But maybe I am a bit too much of a purist on these maters. I just find 
> that, much too often, research results that represent months of work are 
> presented as narrow, black and white (possibly even pixallated!) 
> captures of article graphics which don't do justice to the quality of 
> the work behind them. I don't think there is any harm in making (good) 
> science look a bit "sexier", do you?

Yes there is harm.  But to make bold lines, easy to read titles is fine. 
  See the spar function in 
http://biostat.mc.vanderbilt.edu/SgraphicsHints for a starter.  Also see 
the setps, ps.slide, and setpdf functions in the Hmisc package.

Cheers
Frank

> 
> Jean-Olivier Irisson
> ---
> UMR 5244 CNRS-EPHE-UPVD, 52 av Paul Alduy, 66860 Perpignan Cedex, France
> +336 21 05 19 90
> http://jo.irisson.free.fr/work/
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From cberry at tajo.ucsd.edu  Fri Sep 28 18:27:49 2007
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Fri, 28 Sep 2007 09:27:49 -0700
Subject: [R] Creating nice looking lists: how?
In-Reply-To: <7cb007bd0709280703w474e1a8dla83ea66d3da0147a@mail.gmail.com>
References: <7cb007bd0709280703w474e1a8dla83ea66d3da0147a@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709280918220.17854@tajo.ucsd.edu>

On Fri, 28 Sep 2007, Sergey Goriatchev wrote:

> Hello,
>
> For my functions I want to create output similar in appearance to that
> of what you get when you print a summary of lm model:
>
> Residuals:
>      Min        1Q         Median        3Q           Max
> -0.209209 -0.043133  0.001793  0.044105  0.234750
>
> Coefficients:
>                 Estimate  Std. Error  t value    Pr(>|t|)
> (Intercept)  0.981762   0.004089 240.103  < 2e-16 ***
> Factor 1    -0.009581   0.006381  -1.501 0.134296
> Factor 2    -0.008993   0.009182  -0.979 0.328163
> Factor 3     0.029960   0.009547   3.138 0.001866 **
> Factor 4    -0.026575   0.007370  -3.606 0.000363 ***
> Factor 5    -0.004847   0.006382  -0.760 0.448138
> Factor 6     0.005099   0.006483   0.786 0.432202
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> I want:
> 1) no $ before the list component names
> 2) component names that take values from outside variables
> (ex.: number <- 10
>       There are 'number' factors in the model:)
>
> There is not much information on how to create nice output in terms of
> lists, so I was looking for core to write the summary(lm) output, but
> could not find much. Obviously, I can type summary.lm, but it does not
> show how to create the name "Coefficients:"

 	page( stats:::print.summary.lm, 'print' )

is what you want.

It is called when auto-printing class "summary.lm" objects.

Some print methods for summary methods do a lot of calculation, and I 
sometimes find it confusing that those calculations are not included in 
the summary nethod and spend a lot of time searching thru summary.whatnot 
till I wake up and remember to look at print.summary.whatnot.

Chuck

>
> Could someone give me pointers on how to create nice lists?
>
> Thanks
> Sergey
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From deepayan.sarkar at gmail.com  Fri Sep 28 18:28:00 2007
From: deepayan.sarkar at gmail.com (deepayan.sarkar at gmail.com)
Date: Fri, 28 Sep 2007 09:28:00 -0700
Subject: [R] different colors for two wireframes in same plot
In-Reply-To: <20070927210101.179800@gmx.net>
References: <20070927210101.179800@gmx.net>
Message-ID: <eb555e660709280928x4fc1eb16s1d2cc2f0c0a7eda5@mail.gmail.com>

On 9/27/07, marcg <mdgi at gmx.ch> wrote:
> Thanks a lot
>
> This already looks nice and I already checked the ?wireframe, but with no
> examples and as newcommer its hard to find out a correct code.
>
> If we set drape=F in the example:
>
> g <- expand.grid(x = 1:10, y = 5:15, gr = 1:2)
> g$z <- log((g$x^g$g + g$y^2) * g$gr)
> wireframe(z ~ x * y, data = g, groups = gr,
>           scales = list(arrows = FALSE),
>           drape = F, colorkey = TRUE,
>           screen = list(z = 30, x = -60))
>
> you get a two color pic of these layers - and what I'm actually looking for
> is making just the UPPER (toplayer) transparent.

Generally seaking, partially transparent colors can be specified in
the form "#RRGGBBAA" (it's hard to see where to document this in a way
that ``newcomers'' can find -- suggestions welcome). Using this:

wireframe(z ~ x * y, data = g, groups = gr,
          col.groups = c("#00FFFFFF", "#FF00FFAA"))

-Deepayan


>
> Thanks for further help
>
> marc
>
> -------- Original-Nachricht --------
> > Datum: Thu, 27 Sep 2007 11:29:19 +0200
> > Von: "Frede Aakmann T?gersen" <FredeA.Togersen at agrsci.dk>
> > An: "marcg" <mdgi at gmx.ch>, r-help at stat.math.ethz.ch
> > Betreff: SV: [R] different colors for two wireframes in same plot
>
> > You can obtain some transparency setting the alpha transparency. This is
> > device dependent though. Using the pdf device you can do this obtaining
> > transparency of both surfaces (the version must be at least 1.4 for
> > semitransparent output to be understood):
> >
> >
> > pdf("test.pdf",version="1.4")
> > wireframe(z ~ x * y, data = g, groups = gr,
> >           scales = list(arrows = FALSE),
> >           drape = TRUE, colorkey = TRUE,
> >           screen = list(z = 30, x = -60),
> >           par.settings = list(regions=list(alpha=0.75)))
> > dev.off()
> >
> > See ?wireframe for the "at, col.regions, alpha.regions" arguments.
> >
> > Does this suffice?
> >
> >
> > Med venlig hilsen
> > Frede Aakmann T?gersen
> >
> >
> >
> >
> > > -----Oprindelig meddelelse-----
> > > Fra: r-help-bounces at r-project.org
> > > [mailto:r-help-bounces at r-project.org] P? vegne af marcg
> > > Sendt: 27. september 2007 09:22
> > > Til: r-help at stat.math.ethz.ch
> > > Emne: [R] different colors for two wireframes in same plot
> > >
> > > Hello R,
> > >
> > > According to:
> > >
> > > g <- expand.grid(x = 1:10, y = 5:15, gr = 1:2) g$z <-
> > > log((g$x^g$g + g$y^2) * g$gr) wireframe(z ~ x * y, data = g,
> > > groups = gr,
> > >           scales = list(arrows = FALSE),
> > >           drape = TRUE, colorkey = TRUE,
> > >           screen = list(z = 30, x = -60))
> > >
> > > i have two wireframes in one plot.
> > >
> > > How could i change the color of the top - one to transparent
> > > (or only the grid). I want to give insight to the lower layer.
> > >
> > > Could one make an if-statment like (if gr==1 do drape=F or
> > > color=none) if gr=2 do drape=T, colorkey=T)
> > >
> > > Thanks for your help
> > >
> > > Marc
> > >
> > > --
> > > Psssst! Schon vom neuen GMX MultiMessenger geh?rt?
> > > Der kanns mit allen: http://www.gmx.net/de/go/multimessenger
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
>
> --
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> --
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From murdoch at stats.uwo.ca  Fri Sep 28 18:42:42 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 28 Sep 2007 12:42:42 -0400
Subject: [R] orientlib
In-Reply-To: <BAY134-W31C20CEC437D149059BCDEA3B20@phx.gbl>
References: <BAY134-W31C20CEC437D149059BCDEA3B20@phx.gbl>
Message-ID: <46FD2F02.6050909@stats.uwo.ca>

On 9/28/2007 11:20 AM, Abu Naser wrote:
> Hi All user,
> 
> I have been using R-2.5.1. dose orientlib support this version? I would like to try. it.
> I have been wondering how to install the library.

As far as I know it is fine.  You install it as you would install any 
other package, but that depends on what platform you're using.  If 
you're using Windows, the easiest way is to use the "Packages | Install 
packages..." menu item.

Duncan Murdoch


From birgit.lemcke at systbot.uzh.ch  Fri Sep 28 18:47:36 2007
From: birgit.lemcke at systbot.uzh.ch (Birgit Lemcke)
Date: Fri, 28 Sep 2007 18:47:36 +0200
Subject: [R] simple matching with R
In-Reply-To: <280081D6-4D3A-46CC-BA52-364170E75A28@nd.edu>
References: <C6494518-D49A-4952-8707-729C363F8621@systbot.uzh.ch>
	<280081D6-4D3A-46CC-BA52-364170E75A28@nd.edu>
Message-ID: <0E83C4F8-8868-47B5-86B4-D895D84C4459@systbot.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070928/dae451df/attachment.pl 

From jrkrideau at yahoo.ca  Fri Sep 28 18:54:11 2007
From: jrkrideau at yahoo.ca (John Kane)
Date: Fri, 28 Sep 2007 12:54:11 -0400 (EDT)
Subject: [R] plot or boxplot!
In-Reply-To: <782586.57798.qm@web45310.mail.sp1.yahoo.com>
Message-ID: <509999.18085.qm@web32814.mail.mud.yahoo.com>


--- Samuel Okoye <samuoko at yahoo.com> wrote:

> Hello,
>    
>   if we suppose that
>    
>   times <- c("2006-05-14", "2006-06-12",
> "2006-06-12", "2006-05-14", "2006-05-14",
> "2006-06-12")
>   value <- c(2,3,1,4,3,1)
>    
>   then with
>    
>   plot(times, value)

Have you tried this?

I think you mean
boxplot( value ~ times)
>    
>   we have two boxplots in one graph for 2006-05-14
> and 2006-06-12 respectively! Is it possible to have
> them in a scatterplot? 

I don't see how since time is a character variable.
However if you do 
times <- as.Date (c("2006-05-14", "2006-06-12",
 "2006-06-12", "2006-05-14", "2006-05-14",
 "2006-06-12")) 
then you can. 
> and if I sort the data as
>    
>   x <- data.frame(times, value)
>   x <- x[order(times),]
>    
>   Is it possible to create a new variable which
> contains 1 for 2006-05-14 and 2 for 2006-06-12?
>    
y <-  ifelse(x[,1]=="2006-05-14", 1 , 2)
 x <- cbind(x,y) ; x

It was not clear exactly what you wanted to plot so
this may be closer to what you wanted than converting
to as.Date and ploting


 plot(x[,3],x[,2], col="red",xaxt="n", xlab="times",
ylab="value")
 axis(side=1, at=c(1,2), labels=c("2006-06-12", "2006-06-12"))


From phhs80 at gmail.com  Fri Sep 28 19:03:50 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Fri, 28 Sep 2007 18:03:50 +0100
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <46FD2B0A.1000205@vanderbilt.edu>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>
	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>
	<6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>
	<9D14E5C4-C061-423D-A94A-5AAAAF24A4BF@gmail.com>
	<46FD1663.5070002@vanderbilt.edu>
	<DEAF35A7-190B-4F78-B7AD-3038A079CE9A@gmail.com>
	<46FD2B0A.1000205@vanderbilt.edu>
Message-ID: <6ade6f6c0709281003n5c661bebp708f527ff1a8ba1b@mail.gmail.com>

On 9/28/07, Frank E Harrell Jr <f.harrell at vanderbilt.edu> wrote:
> >>>>>> I know how to export graphics as pdf files and then how to include
> >>>>>> them in LaTeX documents. However, I do not know how to do in
> >>>>>> order to
> >>>>>> have the text of the graphics written with the font selected for the
> >>>>>> LaTeX document. Is that possible?
> >>>>> [...]
> >>> If you don't mind an extra step between R and LaTeX, you could use
> >>> Inkscape to modify your graphics:
> >>>     http://www.inkscape.org/
> >>> It is a (very nice!) vector graphics editor which:
> >>> - works with SVGs (as produced with the RSvgDevice package)
> >>> - imports PDFs (really well in the latest development version)
> >>> - is available for free, on most platforms
> >>> and
> >>> - exports PDFs that nicely integrate in LaTeX documents
> >>> - exports PSTricks graphics
> >>> Then two roads are opened for you:
> >>> 1- either get a TTF version of the LaTeX fonts (there are packages
> >>> for this on all linux distros I know, for use with Lyx and you can
> >>> probably find them on the web otherwise) and change all the fonts to
> >>> those once your document is in Inkscape (select all > text and font
> >>> >  select the font)
> >>> 2- or open the document with inkscape and export it to pstricks
> >>> I personally use Inkscape on all my R graphics because I find it
> >>> easier and quicker to get decent graphics and R and refine their
> >>> look  in Inkscape than to get them perfect in R in one shot ( though
> >>> with  ggplot2 things are improving on R's side).
> >
> >> As this works against principles of reproducible research, I wouldn't
> >> recommend it.
> >
> > Do you consider that changing the font size of the graphic would be
> > altering the research result? Or laying out a 2d contour and a 3d plot
>
> Not per se, but accidents happen when editing graphics.  More
> importantly it creates more work.  Datasets get updated/corrected and
> graphics need to be reproduced.
>
> > in parallel, or changing the line color/pattern...? My modifications are
> > usually of this kind. Of course those things are doable with R but they
> > are usually immensely easier in a graphics program (where the color
> > palettes are predefined, the dash patterns are more diverse etc.).
> >
> > For example, I often find myself using the same plot in an article, a
> > presentation, and a poster, usually with different color palettes and
> > font requirements. I just open the pdf, change the colors, font and font
> > size to match the design of the article/presentation/poster, realign the
> > labels a bit and re-save it. I don't think that I am doing any harm to
> > my result or present any false information to the readers, I just make
> > the graphics easier on their eyes.
>
> A great application for a wrapper graphics function with an argument for
> presentation mode.
>
> >
> > But maybe I am a bit too much of a purist on these maters. I just find
> > that, much too often, research results that represent months of work are
> > presented as narrow, black and white (possibly even pixallated!)
> > captures of article graphics which don't do justice to the quality of
> > the work behind them. I don't think there is any harm in making (good)
> > science look a bit "sexier", do you?
>
> Yes there is harm.  But to make bold lines, easy to read titles is fine.
>   See the spar function in
> http://biostat.mc.vanderbilt.edu/SgraphicsHints for a starter.  Also see
> the setps, ps.slide, and setpdf functions in the Hmisc package.

Thanks to all for your thoughts and ideas.

Paul


From marcelolaia at gmail.com  Fri Sep 28 19:03:57 2007
From: marcelolaia at gmail.com (Marcelo Laia)
Date: Fri, 28 Sep 2007 14:03:57 -0300
Subject: [R] plot graph with error bars trouble
Message-ID: <a35fc1810709281003g67acdc56l96f759cf7324d0d0@mail.gmail.com>

Hi,

I have a data set like this:

Mutant    Rep    Time   OD
02H02    1    0    0.029
02H02    2    0    0.029
02H02    3    0    0.023
02H02    1    8    0.655
02H02    2    8    0.615
02H02    3    8    0.557
02H02    1    12    1.776
02H02    2    12     1.859
02H02    3    12    1.668
02H02    1    16    3.379
02H02    2    16    3.726
02H02    3    16    3.367
306    1    0    0.033
306    2    0    0.035
306    3    0    0.034
306    1    8     0.377
306    2    8    0.488
306    3    8    0.409
306    1    12    1.106
306    2    12    1.348
306    3    12    1.246
306    1    16    2.706
306    2    16    3.073
306    3    16    3.038

I need to plot a graph OD over the time for each one mutant with error bars.

I try the package sciplot, but this package is set up to handle
factorial treatments, so the spacing in x-axis is fixed to be equal.
Than, with it I got something like this:

|
|
|
|
|
+-----------------------------
0        8          12          16

But, I would like spacing between 0 and 8 2-fold the spacign between 8
and 12, like this:

|
|
|
|
|
+--------------------------------------
0        4          8          12          16

Could you point me out another way to do this with out using sciplot?
Any suggestion is very appreciated.

In advance, I doesn't have a good knowledge about R language.

Thank you very much

-- 
Marcelo Luiz de Laia


From phhs80 at gmail.com  Fri Sep 28 19:12:29 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Fri, 28 Sep 2007 18:12:29 +0100
Subject: [R] Drawing functions on Cartesian coordinate systems
Message-ID: <6ade6f6c0709281012x2bdbc819nc3e3e66c29fc5809@mail.gmail.com>

Dear All,

Can R draw plots of functions on a Cartesian coordinate system with
axes like the ones shown at

http://en.wikipedia.org/wiki/Image:Cartesian-coordinate-system-with-circle.svg

?

I have already searched the R web-site, but found nothing.

Thanks in advance,

Paul


From h.wickham at gmail.com  Fri Sep 28 19:13:46 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 28 Sep 2007 12:13:46 -0500
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <46FD2B0A.1000205@vanderbilt.edu>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>
	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>
	<6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>
	<9D14E5C4-C061-423D-A94A-5AAAAF24A4BF@gmail.com>
	<46FD1663.5070002@vanderbilt.edu>
	<DEAF35A7-190B-4F78-B7AD-3038A079CE9A@gmail.com>
	<46FD2B0A.1000205@vanderbilt.edu>
Message-ID: <f8e6ff050709281013i7209b684r63aa0d8fcd69d4ef@mail.gmail.com>

> Yes there is harm.  But to make bold lines, easy to read titles is fine.
>   See the spar function in
> http://biostat.mc.vanderbilt.edu/SgraphicsHints for a starter.  Also see
> the setps, ps.slide, and setpdf functions in the Hmisc package.

I was interested to see that you have code for drawing scatterplots
with multiple y-axes.  As far as I know the only legitimate use for a
double-axis plot is to confuse or mislead the reader (and this is not
a very ethical use case).  Perhaps you have a counter-example?

Hadley


From JHMuller at StateStreet.com  Fri Sep 28 19:16:44 2007
From: JHMuller at StateStreet.com (Muller, John H)
Date: Fri, 28 Sep 2007 13:16:44 -0400
Subject: [R] error message from dbConnect, using ROracle
Message-ID: <5A0497D4AFDFC349B5415A7B59DF458A0405538D@INCG2010B.corp.statestr.com>


I am trying to use ROracle (v 0.5-8) with R on Windows (v 2.5.1)
 
I get an error message when I run the following code
    > library(DBI)
    > library(ROracle)
    > m <- dbDriver("Oracle")
    > con <- dbConnect(m, dsn='####',   uid='####', pwd='####')   
    Note masked real values with ###
 
The error is on the last statement and the error message is
    Error in function (classes, fdef, mtable)  : 
        unable to find an inherited method for function "dbConnect", for
signature "OraDriver"

I searched some of the R help archives and found a post by someone else
with the same problem
      but did not see any responses.
I am somewhat new to DBI so not sure where to look to try to find the
cause of the error.
Trying to use DBI and ROracle because I want to try out some of the big
data handling features of SqLiteDF.
 
Any help you can offer would be greatly appreciated.
 
Thanks and best regards,
 
- john muller


From jspies at nd.edu  Fri Sep 28 19:23:35 2007
From: jspies at nd.edu (Jeffrey Robert Spies)
Date: Fri, 28 Sep 2007 13:23:35 -0400
Subject: [R] simple matching with R
In-Reply-To: <0E83C4F8-8868-47B5-86B4-D895D84C4459@systbot.uzh.ch>
References: <C6494518-D49A-4952-8707-729C363F8621@systbot.uzh.ch>
	<280081D6-4D3A-46CC-BA52-364170E75A28@nd.edu>
	<0E83C4F8-8868-47B5-86B4-D895D84C4459@systbot.uzh.ch>
Message-ID: <A01E0EBA-4F2E-4696-80D6-FAE8D97B2300@nd.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070928/6877b04d/attachment.pl 

From giemme81 at libero.it  Fri Sep 28 19:24:06 2007
From: giemme81 at libero.it (Giusy)
Date: Fri, 28 Sep 2007 10:24:06 -0700 (PDT)
Subject: [R] Elasticity
Message-ID: <12944924.post@talk.nabble.com>


Hello,
I'm starting with data analysis with R, and I'd like to know if there is in
any package a function to have price elasticity of an item.
For example I have information about sale quantity and price, and I want to
know if the series is sensitive to the price.
Sale Quantity	Price
        34	                4$
        23	                4$
        46	                5$
        21	                5$
        46	                5$
        ...                  ...
So I have 2 time series..I think about correlation function, but I'm
wondering if there is a more specific function.
Thank you very much
Giusy
-- 
View this message in context: http://www.nabble.com/Elasticity-tf4535801.html#a12944924
Sent from the R help mailing list archive at Nabble.com.


From Charles.Annis at StatisticalEngineering.com  Fri Sep 28 19:32:22 2007
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Fri, 28 Sep 2007 13:32:22 -0400
Subject: [R] Drawing functions on Cartesian coordinate systems
In-Reply-To: <6ade6f6c0709281012x2bdbc819nc3e3e66c29fc5809@mail.gmail.com>
References: <6ade6f6c0709281012x2bdbc819nc3e3e66c29fc5809@mail.gmail.com>
Message-ID: <009b01c801f5$8780a730$6400a8c0@DD4XFW31>

Yes, R can do that.  Well, actually YOU can do that using R.

But it is hard to believe that you looked very hard before writing.  Did you
look at these R functions?

?plot
?line
?points
?arrows



Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  614-455-3265
http://www.StatisticalEngineering.com
 
-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Paul Smith
Sent: Friday, September 28, 2007 1:12 PM
To: r-help
Subject: [R] Drawing functions on Cartesian coordinate systems

Dear All,

Can R draw plots of functions on a Cartesian coordinate system with
axes like the ones shown at

http://en.wikipedia.org/wiki/Image:Cartesian-coordinate-system-with-circle.s
vg

?

I have already searched the R web-site, but found nothing.

Thanks in advance,

Paul

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rhurlin at gwdg.de  Fri Sep 28 19:48:32 2007
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Fri, 28 Sep 2007 19:48:32 +0200
Subject: [R] ELF file OS ABI invalid yes?????
In-Reply-To: <200709280801.23543.vdemart1@tin.it>
References: <200709280801.23543.vdemart1@tin.it>
Message-ID: <46FD3E70.1070305@gwdg.de>

Hello Vittorio,

I am running FreeBSD 7.0-CURRENT (i386) from yesterday and I am able to 
compile MCMCpack_0.9-1.tar.gz without any problem on R-2.6.0 RC 
(2007-09-27 r43002).

Native FreeBSD devel/pcre-7.3 and lang/gcc42 packages are installed. 
Please look if your library versions are ok.

Regards,
Rainer


vittorio schrieb:
> Compilation of MCMCpack under freebsd 6.2 i386 fails because of the following 
> cryptic error: 
> 
> * Installing *source* package 'MCMCpack' ...
> checking for C++ compiler default output file name... a.out
> checking whether the C++ compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C++ compiler... grep: error while 
> loading shared libraries: /usr/local/lib/libpcre.so.0: ELF file OS ABI 
> invalid
> yes
> checking whether c++ accepts -g... grep: error while loading shared 
> libraries: /usr/local/lib/libpcre.so.0: ELF file OS ABI invalid
> yes
> 
> What should I do?
> 
> Ciao
> Vittorio


From Greg.Snow at intermountainmail.org  Fri Sep 28 20:06:16 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 28 Sep 2007 12:06:16 -0600
Subject: [R] Drawing functions on Cartesian coordinate systems
In-Reply-To: <009b01c801f5$8780a730$6400a8c0@DD4XFW31>
References: <6ade6f6c0709281012x2bdbc819nc3e3e66c29fc5809@mail.gmail.com>
	<009b01c801f5$8780a730$6400a8c0@DD4XFW31>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBC38F20@LP-EXCHVS07.CO.IHC.COM>

I think he wants the axes crossing at 0,0 not on the outer edges like
the default.

You can put the axes in the plot (though it tends to distract rather
than help in many cases) by:

> axis(1, pos=0)
> axis(2, pos=0)

You will need to draw the arrowheads yourself.  There are options (under
?par) for tick length and how to suppress the default axes.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Charles Annis, P.E.
> Sent: Friday, September 28, 2007 11:32 AM
> To: 'Paul Smith'; 'r-help'
> Subject: Re: [R] Drawing functions on Cartesian coordinate systems
> 
> Yes, R can do that.  Well, actually YOU can do that using R.
> 
> But it is hard to believe that you looked very hard before 
> writing.  Did you look at these R functions?
> 
> ?plot
> ?line
> ?points
> ?arrows
> 
> 
> 
> Charles Annis, P.E.
> 
> Charles.Annis at StatisticalEngineering.com
> phone: 561-352-9699
> eFax:  614-455-3265
> http://www.StatisticalEngineering.com
>  
> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Paul Smith
> Sent: Friday, September 28, 2007 1:12 PM
> To: r-help
> Subject: [R] Drawing functions on Cartesian coordinate systems
> 
> Dear All,
> 
> Can R draw plots of functions on a Cartesian coordinate 
> system with axes like the ones shown at
> 
> http://en.wikipedia.org/wiki/Image:Cartesian-coordinate-system
> -with-circle.s
> vg
> 
> ?
> 
> I have already searched the R web-site, but found nothing.
> 
> Thanks in advance,
> 
> Paul
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From kate at few.vu.nl  Fri Sep 28 20:10:28 2007
From: kate at few.vu.nl (Katharine Mullen)
Date: Fri, 28 Sep 2007 20:10:28 +0200 (CEST)
Subject: [R] Creating nice looking lists: how?
In-Reply-To: <7cb007bd0709280703w474e1a8dla83ea66d3da0147a@mail.gmail.com>
References: <7cb007bd0709280703w474e1a8dla83ea66d3da0147a@mail.gmail.com>
Message-ID: <Pine.GSO.4.56.0709281957290.5507@laurel.few.vu.nl>

The source code for print.summary.lm and summary.lm is in the file
/src/library/stats/R/lm.R of the R source code, which you can download
from CRAN if you don't have it already.  The file lm.R is also at
https://svn.r-project.org/R/trunk/src/library/stats/R/lm.R

On Fri, 28 Sep 2007, Sergey Goriatchev wrote:

> Hello,
>
> For my functions I want to create output similar in appearance to that
> of what you get when you print a summary of lm model:
>
> Residuals:
>       Min        1Q         Median        3Q           Max
> -0.209209 -0.043133  0.001793  0.044105  0.234750
>
> Coefficients:
>                  Estimate  Std. Error  t value    Pr(>|t|)
> (Intercept)  0.981762   0.004089 240.103  < 2e-16 ***
> Factor 1    -0.009581   0.006381  -1.501 0.134296
> Factor 2    -0.008993   0.009182  -0.979 0.328163
> Factor 3     0.029960   0.009547   3.138 0.001866 **
> Factor 4    -0.026575   0.007370  -3.606 0.000363 ***
> Factor 5    -0.004847   0.006382  -0.760 0.448138
> Factor 6     0.005099   0.006483   0.786 0.432202
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> I want:
> 1) no $ before the list component names
> 2) component names that take values from outside variables
> (ex.: number <- 10
>        There are 'number' factors in the model:)
>
> There is not much information on how to create nice output in terms of
> lists, so I was looking for core to write the summary(lm) output, but
> could not find much. Obviously, I can type summary.lm, but it does not
> show how to create the name "Coefficients:"
>
> Could someone give me pointers on how to create nice lists?
>
> Thanks
> Sergey
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Anouk.Simard at bio.ulaval.ca  Fri Sep 28 21:04:06 2007
From: Anouk.Simard at bio.ulaval.ca (Anouk Simard)
Date: Fri, 28 Sep 2007 15:04:06 -0400
Subject: [R] fitted values in LMER for the fixed-effects only
Message-ID: <46FD5026.4030604@bio.ulaval.ca>

Hi,

I would like to extract the fitted values from a model using LMER but 
only for the fix portion of the model and not for the fix and random 
portion (e.g it is the procedure outpm or outp in SAS). I am aware of 
the procedure fitted() but I not sure it give the fitted values both for 
the fixed and random or only the fixed. I looked in the r help and the r 
list and I haven?t not found much details about it excepted this 
comments from Douglas Bates in January 2006 :

?Would it help if there were an option in the fitted method to allow for 
fixed-effects only versus fixed- and random-effects? As you say, because 
lmer models do not need to be hierarchical it is not obvious what it 
would mean to include some but not all of the random effects terms in 
the "fitted values". However, it is easy and unambiguous to define 
fitted values for the fixed-effects only.

Up until a few days ago there was an option to do this but then I 
changed the calculation of the fitted values in an attempt to clean up 
the code. The calculation of the level = 0 fitted values in the new 
representation of the fitted model is quite easy. It is

fm1 at X %*% fixef(fm1)?

I tried the last formula, but I want to confirm that this is still the 
proper and best way to get fitted values for the fix effects using lmer.

Thanks


From maura.monville at gmail.com  Fri Sep 28 21:16:54 2007
From: maura.monville at gmail.com (Maura E Monville)
Date: Fri, 28 Sep 2007 14:16:54 -0500
Subject: [R] P-P plot
Message-ID: <36d691950709281216i1d7f94d5nd173bd75f4c3a71f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070928/3d4c7fc5/attachment.pl 

From phhs80 at gmail.com  Fri Sep 28 21:19:04 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Fri, 28 Sep 2007 20:19:04 +0100
Subject: [R] Drawing functions on Cartesian coordinate systems
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBC38F20@LP-EXCHVS07.CO.IHC.COM>
References: <6ade6f6c0709281012x2bdbc819nc3e3e66c29fc5809@mail.gmail.com>
	<009b01c801f5$8780a730$6400a8c0@DD4XFW31>
	<07E228A5BE53C24CAD490193A7381BBBC38F20@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <6ade6f6c0709281219q4778d3c2yaac41e46392e6cf6@mail.gmail.com>

On 9/28/07, Greg Snow <Greg.Snow at intermountainmail.org> wrote:
> I think he wants the axes crossing at 0,0 not on the outer edges like
> the default.
>
> You can put the axes in the plot (though it tends to distract rather
> than help in many cases) by:
>
> > axis(1, pos=0)
> > axis(2, pos=0)
>
> You will need to draw the arrowheads yourself.  There are options (under
> ?par) for tick length and how to suppress the default axes.

Thanks, Greg, for your suggestion. That is in line with what I was
looking for. However, I still have  one more question. Take the
following code:

curve(sin(x),-pi,pi,axes=F,ylab="",xlab="")
axis(1, pos=0)
axis(2, pos=0,at=c(-1,-0.5,0.5,1))

How can I have the y axis labels rotated clockwise?

Paul





> > -----Original Message-----
> > From: r-help-bounces at r-project.org
> > [mailto:r-help-bounces at r-project.org] On Behalf Of Charles Annis, P.E.
> > Sent: Friday, September 28, 2007 11:32 AM
> > To: 'Paul Smith'; 'r-help'
> > Subject: Re: [R] Drawing functions on Cartesian coordinate systems
> >
> > Yes, R can do that.  Well, actually YOU can do that using R.
> >
> > But it is hard to believe that you looked very hard before
> > writing.  Did you look at these R functions?
> >
> > ?plot
> > ?line
> > ?points
> > ?arrows
> >
> >
> >
> > Charles Annis, P.E.
> >
> > Charles.Annis at StatisticalEngineering.com
> > phone: 561-352-9699
> > eFax:  614-455-3265
> > http://www.StatisticalEngineering.com
> >
> > -----Original Message-----
> > From: r-help-bounces at r-project.org
> > [mailto:r-help-bounces at r-project.org] On Behalf Of Paul Smith
> > Sent: Friday, September 28, 2007 1:12 PM
> > To: r-help
> > Subject: [R] Drawing functions on Cartesian coordinate systems
> >
> > Dear All,
> >
> > Can R draw plots of functions on a Cartesian coordinate
> > system with axes like the ones shown at
> >
> > http://en.wikipedia.org/wiki/Image:Cartesian-coordinate-system
> > -with-circle.s
> > vg
> >
> > ?
> >
> > I have already searched the R web-site, but found nothing.
> >
> > Thanks in advance,
> >
> > Paul
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>


From jholtman at gmail.com  Fri Sep 28 21:27:35 2007
From: jholtman at gmail.com (jim holtman)
Date: Fri, 28 Sep 2007 15:27:35 -0400
Subject: [R] File selection by condition
In-Reply-To: <12940278.post@talk.nabble.com>
References: <12940278.post@talk.nabble.com>
Message-ID: <644e1f320709281227t319113faq78730a3065f62ee@mail.gmail.com>

Read the files in, select those that meet the criteria and store them in a list

match.list <- list()
for (i in list.files(pattern="some pattern")){
    x.in <- read.table(i)
    if (your match criteria) match.list[[i]] <- x.in
}

On 9/28/07, Svempa <fempa at yahoo.com> wrote:
>
> I have a large number of textfiles, and one matix in every texfile. I now
> want to find an easy way to select those textfiles that contain at least one
> value over a certain limit, and collect those matrices in a vector or
> something alike. How do I do that?
>
> --
> View this message in context: http://www.nabble.com/File-selection-by-condition-tf4534428.html#a12940278
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From redaction at voyage-vacance.fr  Fri Sep 28 21:43:24 2007
From: redaction at voyage-vacance.fr (redaction at voyage-vacance.fr)
Date: Fri, 28 Sep 2007 21:43:24 +0200
Subject: [R] =?iso-8859-1?q?_D=E9couvrez_Bordeaux_inscrit_au_patrimoine_de?=
 =?iso-8859-1?q?_l=27UNESCO_!?=
Message-ID: <9282143.GAGASXOY@voyage-vacance.fr>


                             [1]voyages et vacances 
                              Destination vacances
   voyages et vacances

[2]Merveilles de l'Egypte

   voyages et vacances

[3]La Sicile myst??rieuse

   voyages et vacances

[4]Ath??nes et ses joyaux

   vacances et s??jour chateau de bonaguil

[5]Les Cyclades en Gr??ce

   voyages et vacances

[6]Mykonos la magnifique

   voyages et vacances

[7]Delos arch??ologique

   voyages et vacances

[8]Majorque la grande

   voyages et vacances

[9]La Provence insolite

   voyages et vacances

[10]Arcachon et son climat

   voyages et vacances

[11]Cap Ferret, le village

   voyages et vacances

[12]La Dune du Pilat

   voyages et vacances

[13]Andernos les bains

   voyages et vacances

[14]Bassin d'Arcachon

                              voyages et vacances
                              D??couvertes Week End
   voyages et vacances

[15]Sarlat en P??rigord

   voyages et vacances

[16]Bordeaux ?? l'Unesco 

   voyages et vacances

[17]La Dune du Pilat

   voyages et vacances

[18]Le Mont Saint Michel

   voyages et vacances

[19]Vieux port de La Rochelle

   voyages et vacances

[20]Montmartre ?? Paris 

   voyages et vacances

[21]P??lerinage ?? Lourdes

   vacances et s??jour ?? mykonos, hotel et restaurant

[22]Ch??teau de Bonaguil

                              voyages et vacances
                                 Parcs ?? Th??mes
   voyages et vacances

[23]Zoo de la Palmyre

   voyages et vacances

[24]Aquarium de La Rochelle

   nager avec les dauphins du marineland d'antibes

[25]Marineland d'Antibes

   nager avec les dauphins du marineland d'antibes

[26]Village du Bournat

   nager avec les dauphins du marineland d'antibes

[27]Aquarium du Bugues

   nager avec les dauphins du marineland d'antibes

[28]La Vall??e des singes

   voyages et vacances

[29]Ecomus??e de Marqu??ze

                              voyages et vacances
                               Sortir en Week End
   voyages et vacances

[30]Les Gorges du Verdon

   voyages et vacances

[31]L'ile de Port Cros

   voyages et vacances

[32]Les chambres d'h??tes

   voyages et vacances

[33]Les Sorties en r??gion

   voyages et vacances

[34]Les bonnes tables

                              voyages et vacances
                              D??couvertes en images
   [rect-jaune.gif]

[35]Diaporamas

   voyages et vacances

[36]Galerie Vid??os

   voyages et vacances

[37]Visites virtuelles

                              voyages et vacances
                                Services en ligne
   sur les traces d'Am??lie Poulin ?? Montmartre, voyage et vacances paris hotel
   et restaurant

[38]R??cits de vacances

   voyages et vacances

[39]M??t??o France

   voyages et vacances

[40]Pr??paratifs ?? la loupe

   voyages et vacances

[41]Locations de vacances

   voyages et vacances

[42]Vente de photographies

   voyages et vacances

[43]Bons plans Cin??ma

                              voyages et vacances
   [44]Vols : promotion et offres derni??re minute sur Voyages-sncf.com 
         [45]Location de voiture : meilleur prix garanti sur Voyages-sncf.com 
   [46]24 000 h??tels ?? prix sp??cialement n??goci??s sur Voyages-sncf.com 
            [47]S??jours : promotions et derni??re minutes sur Voyages-sncf.com 

                                  [EMBED]

   voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco
   voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco
   voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco
   [48]Ce guide
   dans vos favoris
   voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco
   [49]Acheter des photographies 
   voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco
   Nos promotions
   dans votre BAL
   _______________ [ok.gif]-Submit
   voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco
   [50]S'inscrire ?? la
   NewsLetter de VoyageSNCF.com
   et gagnez un voyage 
   voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco
   voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco
   voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco

      vacances et s??jour en provence maison d 'hote restauarnt hotell
      vacances et s??jour en provence maison d 'hote restauarnt hotell

   D??couvrez la ville de Bordeaux en images

   [51]Accueil >>[52] Bordeaux

   [espaceur.gif] voyages et vacances ?? bordeaux inscrite au patrimoine de
   l'Unesco Voyages et vacances ?? Bordeaux
   voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco
     [53]voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco
   Belle, intelligente et ensoleill??e, Bordeaux est entr??e dans le 21e si??cle
   fermement d??cid??e ?? retrouver une nouvelle jeunesse. Avec conviction et
   talent, la ville se redessine autour d'un grand projet urbain qui rend ?? ses
   habitants le plaisir de vivre en ville et cr??e les conditions d'un nouveau
   d??veloppement ??conomique, social et culturel collectif.
   Cit?? au pass?? prestigieux, m??tropole touristique et ??conomique, capitale
   mondiale du vin, p??le universitaire et de recherche, ville de f??te et de
   saveurs, Bordeaux poursuit son mouvement vers 2010. Bordeaux ne sera jamais
   assez reconnaissante envers la peuplade gauloise des Bituriges-Vivisques qui
   d??cida, au 3??me si??cle avant J.-C., de fonder la cit?? de [54]Burdigala au
   confluent du Peugue et de la Dev??ze. La ville a construit sa richesse sur
   cet emplacement privil??gi??, tirant du sol et du climat les meilleurs vins du
   monde et b??tissant autour de son fleuve le premier port de France (1750) et
   l'un des plus grands centres europ??ens de n??goce et d'??changes.
     Bien des si??cles plus tard, en une ??poque o?? chacun recherche une nouvelle
   douceur de vivre, cette situation sur la fa??ade atlantique du sud-ouest
   fran??ais reste l'un des meilleurs atouts de la ville. Grande [55]ville
   d'histoire et de n??goce, Bordeaux b??n??ficie ?? la fois d'un patrimoine
   architectural ??poustouflant et de cette convivialit?? propre aux cit??s
   commer??antes.
   Dessin??e par les si??cles autour de douze quartiers, elle alterne fa??ades et
   immeubles fastueux, ??choppes aux charmants petits jardins et chartreuses
   bourgeoises, chais et hangars revisit??s, nouveaux am??nagements et immeubles
   d'architectes. Mais dans le secteur sauvegard?? du centre ville comme sur le
   nouvel espace des quais ou dans les quartiers plus fonctionnels,
   administratifs ou commerciaux, r??gne un m??me bouillonnement.
   Si dans sa m??tamorphose, Bordeaux soigne son allure, en ravalant ses
   fa??ades, en cr??ant de nouveaux espaces verts, en illuminant ses monuments,
   en faisant [56]voyages et vacances ?? bordeaux inscrite au patrimoine de
   l'Unesco 
     [57]voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco le
   choix d'un tramway aliment?? par le sol, elle n'oublie pas la valeur
   irrempla??able des commerces de proximit??, des march??s de plein air, des
   lieux associatifs et sportifs et des espaces de d??tente et de cheminements
   pi??tons. Ville d'??changes par nature autant que par h??ritage, Bordeaux se
   veut largement ouverte sur le monde. Membre du r??seau Eurocit??s qui r??unit
   plus de 100 grandes villes d'Europe autour de l'??change d'exp??rience,
   jumelle d'une douzaine de villes dans le monde, Bordeaux joue la carte de
   l'intermodalit?? et des grands ??quipements pour mettre le monde ?? proximit??.
   voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco

   [58]voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco 
        voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco
   voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco Les
   incontournables
     [59]La Cath??drale Saint Andr??
     [60]La Place de la Bourse
     [61]Les quatiers de Bordeaux
     [62]La Grosse Cl??che
   voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco

   [63]Composez votre voyage sur-mesure : jusqu'?? 40% de r??duction sur
   Voyages-sncf.com 
           [64]D??couvrez les promotions sur voyages-sncf.com

      voyages  et  vacances ?? bordeaux inscrite au patrimoine de l'Unesco
   [65]Diaporama

     voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco
   voyages et vacances ?? bordeaux inscrite au patrimoine de l'Unesco voyages et
   vacances ?? bordeaux inscrite au patrimoine de l'Unesco [66]Votre assurance
   sant??
   [espaceur.gif] voyages et vacances ?? bordeaux inscrite au patrimoine de
   l'Unesco [67]Avion et s??curit??
   [espaceur.gif] voyages et vacances ?? bordeaux inscrite au patrimoine de
   l'Unesco [68]Perte / vol de papier
   [espaceur.gif] voyages et vacances ?? bordeaux inscrite au patrimoine de
   l'Unesco [69]Vacances rat??es
   [espaceur.gif] voyages et vacances ?? bordeaux inscrite au patrimoine de
   l'Unesco [70]Pi??ge des promotions
   [espaceur.gif] voyages et vacances ?? bordeaux inscrite au patrimoine de
   l'Unesco

      vacances et s??jour en provence maison d 'hote restauarnt hotell
 [71]Ecrivez-nous | [72]Compagnies a??riennes ?? risque | [73]Galerie photos |
  [74]Visites virtuelles | [75]Nos partenaires | [76]FAQ | [77]Plan du site
      vacances et s??jour en provence maison d 'hote restauarnt hotell



      bordeaux site touristique
     [78]bordeaux site touristique 
   [79]L'histoire de bordeaux
   [80]restaurant a bordeaux
   [81]location a bordeaux
   [82]se rendre a bordeaux en avion 
   [83]se rendre a bordeaux en train 
   [84]se rendre a bordeaux en voiture 
   [85]acces a bordeaux
   [86]plan de la ville de bordeaux 
   [87]infos pratiques sur bordeaux
   [88]la cuisine a bordeaux
   [89]les celebrites a bordeaux
   [90]decouvrir bordeaux
   [91]sortir a bordeaux
   [92]liens utiles sur bordeaux
   [93]l'??glise notre dame de bordeaux
   [94]l'??glise saint pierre de bordeaux
   [95]l'??glise sainte croix
   [96]le grand theatre de bordeaux
   [97]la grosse cloche de bordeaux
   [98]l'hotel mably de bordeaux
   [99]le jardin public de bordeaux
   [100]le mus??e d'aquitaine de bordeaux
   [101]le palais de justice de bordeaux
   [102]Visite virtuelle de bordeaux
   [103]la place de la bourse de bordeaux
   [104]la place du parlement de bordeaux
   [105]la place pey berland de bordeaux
   [106]la place des quinconces de bordeaux
   [107]le pont de pierre de bordeaux
   [108]la porte d'aquitaine de bordeaux
   [109]la porte bourgogne de bordeaux
   [110]la porte cailhau de bordeaux
   [111]la porte dijeaux de bordeaux
   [112]les quartiers de bordeaux
   [113]la rue sainte catherine de bordeaux
   [114]la cathedrale saint andree de bordeaux
   [115]la tour saint andree de bordeaux
   [116]le tramway de bordeaux


     Liens vers bordeaux

   [117]l'??glise notre dame de bordeaux
   [118]l'??glise saint pierre de bordeaux
   [119]l'??glise sainte croix
   [120]le grand theatre de bordeaux
   [121]la grosse cloche de bordeaux
   [122]l'hotel mably de bordeaux
   [123]le jardin public de bordeaux
   [124]le mus??e d'aquitaine de bordeaux
   [125]le palais de justice de bordeaux
   [126]Visite virtuelle de bordeaux
   [127]la place de la bourse de bordeaux
   [128]la place du parlement de bordeaux
   [129]la place pey berland de bordeaux
   [130]la place des quinconces de bordeaux
   [131]le pont de pierre de bordeaux
   [132]la porte d'aquitaine de bordeaux
   [133]la porte bourgogne de bordeaux
   [134]la porte cailhau de bordeaux
   [135]la porte dijeaux de bordeaux
   [136]les quartiers de bordeaux
   [137]la rue sainte catherine de bordeaux
   [138]la cathedrale saint andree de bordeaux
   [139]la tour saint andree de bordeaux
   [140]le tramway de bordeaux

   [141]voyage et vacances a bordeaux, location hotel camping
   [142]voyage et vacances a bordeaux, location hotel camping
   [143]voyage et vacances a bordeaux, location hotel camping
   [144]voyage et vacances a bordeaux, location hotel camping
   [145]voyage et vacances a bordeaux, location hotel camping
   [146]voyage et vacances a bordeaux, location hotel camping
   [147]voyage et vacances a bordeaux, location hotel camping
   [148]voyage et vacances a bordeaux, location hotel camping
   [149]voyage et vacances a bordeaux, location hotel camping
   [150]voyage et vacances a bordeaux, location hotel camping
   [151]voyage et vacances a bordeaux, location hotel camping
   [152]voyage et vacances a bordeaux, location hotel camping
   [153]voyage et vacances a bordeaux, location hotel camping
   [154]voyage et vacances a bordeaux, location hotel camping
   [155]voyage et vacances a bordeaux, location hotel camping
   [156]voyage et vacances a bordeaux, location hotel camping
   [157]voyage et vacances a bordeaux, location hotel camping
   [158]voyage et vacances a bordeaux, location hotel camping
   [159]voyage et vacances a bordeaux, location hotel camping
   [160]voyage et vacances a bordeaux, location hotel camping

   bordeaux,girondin de bordeaux,bordeaux hotel,bordeaux restaurant,bordeaux
   33,academie de bordeaux,universite bordeaux,ville de bordeaux,bordeaux
   shopping, mairie  de bordeaux,hotel bordeaux, rectorat de bordeaux,vin
   bordeaux,aeroport de bordeaux,crous bordeaux,immobilier bordeaux,plan de
   bordeaux,office de tourisme de bordeaux,dogue de bordeaux,bordeaux site
   touristique,meteo bordeaux,cathedrale saint andree,eglise notre dame,eglise
   saint  pierre,eglise  sainte  croix,grand  theatre,grosse  cloche,cour
   mably,jardin         public,palais         justice,place,parlement,pey
   berland,quinconces,colonne             des             girondins,porte
   aquitaine,bourgogne,cailhau,dijeaux,quartiers,saint
   michel,victoire,gambetta,tram,tramway,comedie,tourny,palais rohan,pont
   d'aquitaine,de  pierre,agence  immobiliere,immobilier,agence,locations
   saisonnieres,achat,vente,maison,villa,appartement,standing,gite,gite,apparte
   ment,chambre,hote

   [161]Mesure d'audience ROI statistique webanalytics par Analyse d'audience 

References

   Visible links
   1. http://www.voyage-vacance.fr/index.php
   2. http://www.voyage-vacance.fr/egypte/
   3. http://www.voyage-vacance.fr/sicile/
   4. http://www.voyage-vacance.fr/athenes/info/index.html
   5. http://www.voyage-vacance.fr/cyclades/index.php
   6. http://www.voyage-vacance.fr/cyclades/mykonos.php
   7. http://www.voyage-vacance.fr/cyclades/delos/
   8. http://www.voyage-vacance.fr/majorque/index.html
   9. http://www.voyage-vacance.fr/provence/index.html
  10. http://www.voyage-vacance.fr/bassin_arcachon/arcachon/index.html
  11. http://www.voyage-vacance.fr/bassin_arcachon/cap_ferret/info/index.html
  12. http://www.voyage-vacance.fr/bassin_arcachon/dune_du_pyla/index.html
  13. http://www.voyage-vacance.fr/bassin_arcachon/andernos/index.html
  14. http://www.voyage-vacance.fr/bassin_arcachon/index.html
  15. http://www.voyage-vacance.fr/sarlat-en-perigord/info/index.html
  16. http://www.voyage-vacance.fr/bordeaux/index.html
  17. http://www.voyage-vacance.fr/bassin_arcachon/dune_du_pyla/info/index.html
  18. http://www.voyage-vacance.fr/montsaintmichel/info/index.php
  19. http://www.voyage-vacance.fr/la-rochelle/
  20. http://www.voyage-vacance.fr/montmartre/info/index.html
  21. http://www.voyage-vacance.fr/lourdes/index.html
  22. http://www.voyage-vacance.fr/chateau-bonaguil/index.html
  23. http://www.voyage-vacance.fr/zoo-de-la-palmyre/info/index.html
  24. http://www.voyage-vacance.fr/aquarium-la-rochelle/index.html
  25. http://www.voyage-vacance.fr/marineland/index.html
  26. http://www.voyage-vacance.fr/village-bournat/index.html
  27. http://www.voyage-vacance.fr/aquarium-bugues/index.html
  28. http://www.voyage-vacance.fr/vallee-des-singes/index.html
  29. http://www.voyage-vacance.fr/marqueze/info/index.html
  30. http://www.voyage-vacance.fr/provence/gorges-du-verdon/index.html
  31. http://www.voyage-vacance.fr/provence/port-cros/index.html
  32. http://www.voyage-vacance.fr/lien/chambre-hote.html
  33. http://www.voyage-vacance.fr/lien/sortir.html
  34. http://www.voyage-vacance.fr/lien/restaurant.html
  35. http://www.voyage-vacance.fr/diaporama/index.html
  36. http://www.voyage-vacance.fr/lien/video.html
  37. http://www.voyage-vacance.fr/lien/visite-virtuelle.html
  38. http://www.voyage-vacance.fr/blog/index.php
  39. http://www.voyage-vacance.fr/lien/meteo.html
  40. http://www.voyage-vacance.fr/diaporama/index.html
  41. http://www.voyage-vacance.fr/location/location.html
  42. http://www.voyage-vacance.fr/lien/photographie.html
  43. http://www.voyage-vacance.fr/lien/photographie.html
  44. http://ad.zanox.com/ppc/?6150535C393950217T&ULP=[[XXX]]
  45. http://ad.zanox.com/ppc/?6150457C152614001T&ULP=[[XXX]]
  46. http://ad.zanox.com/ppc/?6150495C1416438457T&ULP=[[XXX]]
  47. http://ad.zanox.com/ppc/?6150464C114977T&ULP=[[XXX]]
  48. javascript:void(favoris());
  49. http://www.voyage-vacance.fr/lien/photographie.html
  50. http://www.voyage-vacance.fr/lien/newsletter.html
  51. http://www.voyage-vacance.fr/index.php
  52. http://www.voyage-vacance.fr/bordeaux/index.html
  53. javascript:openSlideShow(1)
  54. http://www.voyage-vacance.fr/info/histoire.html
  55. http://www.voyage-vacance.fr/info/histoire.html
  56. javascript:openSlideShow(1)
  57. javascript:openSlideShow(1)
  58. http://www.voyage-vacance.fr/formulaire/recommander.html
  59. http://www.voyage-vacance.fr/bordeaux/saintandre/
  60. http://www.voyage-vacance.fr/bordeaux/place-bourse/
  61. http://www.voyage-vacance.fr/bordeaux/quartier-bordeaux/
  62. http://www.voyage-vacance.fr/bordeaux/grossecloche/
  63. http://ad.zanox.com/ppc/?6150560C2137532808T
  64. http://ad.zanox.com/ppc/?6150560C2137532808T
  65. http://www.voyage-vacance.fr/diaporama/index.html
  66. http://www.voyage-vacance.fr/sante/index.html
  67. http://www.voyage-vacance.fr/avion/index.html
  68. http://www.voyage-vacance.fr/papier/index.html
  69. http://www.voyage-vacance.fr/recours/index.html
  70. http://www.voyage-vacance.fr/promo/index.html
  71. http://www.voyage-vacance.fr/formulaire/contact.html
  72. http://www.voyage-vacance.fr/avion/liste_noire.html
  73. http://www.voyage-vacance.fr/diaporama/index.html
  74. http://www.voyage-vacance.fr/lien/visite-virtuelle.html
  75. http://www.voyage-vacance.fr/lien/partenaire.html
  76. http://www.voyage-vacance.fr/lien/faq.html
  77. http://www.voyage-vacance.fr/lien/plan.html
  78. http://www.voyage-vacance.fr/
  79. http://www.voyage-vacance.fr/
  80. http://www.voyage-vacance.fr/
  81. http://www.voyage-vacance.fr/
  82. http://www.voyage-vacance.fr/
  83. http://www.voyage-vacance.fr/
  84. http://www.voyage-vacance.fr/
  85. http://www.voyage-vacance.fr/
  86. http://www.voyage-vacance.fr/
  87. http://www.voyage-vacance.fr/
  88. http://www.voyage-vacance.fr/
  89. http://www.voyage-vacance.fr/
  90. http://www.voyage-vacance.fr/
  91. http://www.voyage-vacance.fr/
  92. http://www.voyage-vacance.fr/
  93. http://www.voyage-vacance.fr/
  94. http://www.voyage-vacance.fr/
  95. http://www.voyage-vacance.fr/
  96. http://www.voyage-vacance.fr/
  97. http://www.voyage-vacance.fr/
  98. http://www.voyage-vacance.fr/
  99. http://www.voyage-vacance.fr/
 100. http://www.voyage-vacance.fr/
 101. http://www.voyage-vacance.fr/
 102. http://www.voyage-vacance.fr/
 103. http://www.voyage-vacance.fr/
 104. http://www.voyage-vacance.fr/
 105. http://www.voyage-vacance.fr/
 106. http://www.voyage-vacance.fr/
 107. http://www.voyage-vacance.fr/
 108. http://www.voyage-vacance.fr/
 109. http://www.voyage-vacance.fr/
 110. http://www.voyage-vacance.fr/
 111. http://www.voyage-vacance.fr/
 112. http://www.voyage-vacance.fr/
 113. http://www.voyage-vacance.fr/
 114. http://www.voyage-vacance.fr/
 115. http://www.voyage-vacance.fr/
 116. http://www.voyage-vacance.fr/
 117. http://www.voyage-vacance.fr/
 118. http://www.voyage-vacance.fr/
 119. http://www.voyage-vacance.fr/
 120. http://www.voyage-vacance.fr/
 121. http://www.voyage-vacance.fr/
 122. http://www.voyage-vacance.fr/
 123. http://www.voyage-vacance.fr/
 124. http://www.voyage-vacance.fr/
 125. http://www.voyage-vacance.fr/
 126. http://www.voyage-vacance.fr/
 127. http://www.voyage-vacance.fr/
 128. http://www.voyage-vacance.fr/
 129. http://www.voyage-vacance.fr/
 130. http://www.voyage-vacance.fr/
 131. http://www.voyage-vacance.fr/
 132. http://www.voyage-vacance.fr/
 133. http://www.voyage-vacance.fr/
 134. http://www.voyage-vacance.fr/
 135. http://www.voyage-vacance.fr/
 136. http://www.voyage-vacance.fr/
 137. http://www.voyage-vacance.fr/
 138. http://www.voyage-vacance.fr/
 139. http://www.voyage-vacance.fr/
 140. http://www.voyage-vacance.fr/
 141. http://www.voyage-vacance.fr/
 142. http://www.voyage-vacance.fr/
 143. http://www.voyage-vacance.fr/
 144. http://www.voyage-vacance.fr/
 145. http://www.voyage-vacance.fr/
 146. http://www.voyage-vacance.fr/
 147. http://www.voyage-vacance.fr/
 148. http://www.voyage-vacance.fr/
 149. http://www.voyage-vacance.fr/
 150. http://www.voyage-vacance.fr/
 151. http://www.voyage-vacance.fr/
 152. http://www.voyage-vacance.fr/
 153. http://www.voyage-vacance.fr/
 154. http://www.voyage-vacance.fr/
 155. http://www.voyage-vacance.fr/
 156. http://www.voyage-vacance.fr/
 157. http://www.voyage-vacance.fr/
 158. http://www.voyage-vacance.fr/
 159. http://www.voyage-vacance.fr/
 160. http://www.voyage-vacance.fr/
 161. http://www.xiti.com/xiti.asp?s=260548

   Hidden links:
 162. file://localhost/tmp/tmpJvyUVT.html

From lcostanz at uoguelph.ca  Fri Sep 28 21:47:39 2007
From: lcostanz at uoguelph.ca (Lucia Costanzo)
Date: Fri, 28 Sep 2007 15:47:39 -0400 (EDT)
Subject: [R] boot.ci and NA values
Message-ID: <Pine.GSO.4.63.0709281525470.25786@muncher>

Hi,

I have been trying to run the code below. In the event of non-convergence, 
the statistic in the boot function returns NA as a value. To obtain a BCA 
confidence interval, I use boot.ci but, if NA recorded as a value for the 
statistic for one the replicates the following error appears:

Error in if (const(t, min(1e-08, mean(t)/1e+06))) { :
         missing value where TRUE/FALSE needed

To overcome this, I reformat the output of the bootstrap calculation by 
removing all instances of NA. By doing so the error message does not 
reappear but, I am suspicious of the results.  When I run a simulation 
with 1000 iterations, the coverage probability is 1.

Is this the correct approach for tackling NA values when using boot.ci?

Thanks, Lucia


library(boot)
source(file = "http://www.uoguelph.ca/~lcostanz/mima1.ssc")

# ----- Teo Dataset -----
studynum <-c(1, 2, 3, 4, 5, 6, 7)
y <- 
c(-0.79851,-0.938269639,-1.252762968,-0.042559614,0.209720531,-2.249410331,-1.181993898)
w <- 
c(0.644007,5.903041825,1.531728665,0.489578714,4.19421878,0.872663243,0.705810147)
genData2<-data.frame(studynum, y, w)

set.seed(4700)

mima.func<-function(x, i) {

 	x<-x[i,] # select obs. in bootstrap sample
 	reREML<-mima1(x$y, 1/x$w, mods = c(), method = "REML", out="yes")

 	if (length(reREML) == 0)
 	{
 		ests<-c(NA,NA)
 	}
 	else
 	{
 		ests<-c(reREML$b,reREML$vart)
 	}
}

boot.teo4a<-boot(genData2, mima.func, R=2000,)

ci.teo4<-boot.ci(boot.teo4a, conf = c(0.95), type = c("bca"))

#remove all instances of NA
boot.teo4 = boot.teo4a
boot.teo4$t0 = na.omit(boot.teo4$t0)
boot.teo4$t = na.omit(boot.teo4$t)
boot.teo4$R = length(boot.teo4$t[,1])
boot.teo4$call[4] = boot.teo4$R
ci.teo4<-boot.ci(boot.teo4, conf = c(0.95), type = c("bca"))


From Greg.Snow at intermountainmail.org  Fri Sep 28 21:57:24 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 28 Sep 2007 13:57:24 -0600
Subject: [R] Creating nice looking lists: how?
In-Reply-To: <7cb007bd0709280703w474e1a8dla83ea66d3da0147a@mail.gmail.com>
References: <7cb007bd0709280703w474e1a8dla83ea66d3da0147a@mail.gmail.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBC38F63@LP-EXCHVS07.CO.IHC.COM>

Others have shown you where to find the actual printing code for
print.summary.lm, but the short answer is:

Use the cat function for the general text (the word "coefficients:" and
the signif codes at the bottom)
And put the actual coefficients in a matrix, use colnames and rownames
to add column and row headers, then use print.matrix with quote=FALSE to
print out the matrix of coefficients.

For more detailed printing look at ?cat, ?format, and ?sprintf.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Sergey Goriatchev
> Sent: Friday, September 28, 2007 8:03 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Creating nice looking lists: how?
> 
> Hello,
> 
> For my functions I want to create output similar in 
> appearance to that of what you get when you print a summary 
> of lm model:
> 
> Residuals:
>       Min        1Q         Median        3Q           Max
> -0.209209 -0.043133  0.001793  0.044105  0.234750
> 
> Coefficients:
>                  Estimate  Std. Error  t value    Pr(>|t|)
> (Intercept)  0.981762   0.004089 240.103  < 2e-16 ***
> Factor 1    -0.009581   0.006381  -1.501 0.134296
> Factor 2    -0.008993   0.009182  -0.979 0.328163
> Factor 3     0.029960   0.009547   3.138 0.001866 **
> Factor 4    -0.026575   0.007370  -3.606 0.000363 ***
> Factor 5    -0.004847   0.006382  -0.760 0.448138
> Factor 6     0.005099   0.006483   0.786 0.432202
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> I want:
> 1) no $ before the list component names
> 2) component names that take values from outside variables
> (ex.: number <- 10
>        There are 'number' factors in the model:)
> 
> There is not much information on how to create nice output in 
> terms of lists, so I was looking for core to write the 
> summary(lm) output, but could not find much. Obviously, I can 
> type summary.lm, but it does not show how to create the name 
> "Coefficients:"
> 
> Could someone give me pointers on how to create nice lists?
> 
> Thanks
> Sergey
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From Greg.Snow at intermountainmail.org  Fri Sep 28 22:03:48 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 28 Sep 2007 14:03:48 -0600
Subject: [R] Drawing functions on Cartesian coordinate systems
In-Reply-To: <6ade6f6c0709281219q4778d3c2yaac41e46392e6cf6@mail.gmail.com>
References: <6ade6f6c0709281012x2bdbc819nc3e3e66c29fc5809@mail.gmail.com><009b01c801f5$8780a730$6400a8c0@DD4XFW31><07E228A5BE53C24CAD490193A7381BBBC38F20@LP-EXCHVS07.CO.IHC.COM>
	<6ade6f6c0709281219q4778d3c2yaac41e46392e6cf6@mail.gmail.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBC38F67@LP-EXCHVS07.CO.IHC.COM>

Look at the las argument in ?par for the easiest solution (can be passed
to axis). 

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Paul Smith
> Sent: Friday, September 28, 2007 1:19 PM
> To: r-help
> Subject: Re: [R] Drawing functions on Cartesian coordinate systems
> 
> On 9/28/07, Greg Snow <Greg.Snow at intermountainmail.org> wrote:
> > I think he wants the axes crossing at 0,0 not on the outer 
> edges like 
> > the default.
> >
> > You can put the axes in the plot (though it tends to 
> distract rather 
> > than help in many cases) by:
> >
> > > axis(1, pos=0)
> > > axis(2, pos=0)
> >
> > You will need to draw the arrowheads yourself.  There are options 
> > (under
> > ?par) for tick length and how to suppress the default axes.
> 
> Thanks, Greg, for your suggestion. That is in line with what 
> I was looking for. However, I still have  one more question. 
> Take the following code:
> 
> curve(sin(x),-pi,pi,axes=F,ylab="",xlab="")
> axis(1, pos=0)
> axis(2, pos=0,at=c(-1,-0.5,0.5,1))
> 
> How can I have the y axis labels rotated clockwise?
> 
> Paul
> 
> 
> 
> 
> 
> > > -----Original Message-----
> > > From: r-help-bounces at r-project.org
> > > [mailto:r-help-bounces at r-project.org] On Behalf Of 
> Charles Annis, P.E.
> > > Sent: Friday, September 28, 2007 11:32 AM
> > > To: 'Paul Smith'; 'r-help'
> > > Subject: Re: [R] Drawing functions on Cartesian coordinate systems
> > >
> > > Yes, R can do that.  Well, actually YOU can do that using R.
> > >
> > > But it is hard to believe that you looked very hard 
> before writing.  
> > > Did you look at these R functions?
> > >
> > > ?plot
> > > ?line
> > > ?points
> > > ?arrows
> > >
> > >
> > >
> > > Charles Annis, P.E.
> > >
> > > Charles.Annis at StatisticalEngineering.com
> > > phone: 561-352-9699
> > > eFax:  614-455-3265
> > > http://www.StatisticalEngineering.com
> > >
> > > -----Original Message-----
> > > From: r-help-bounces at r-project.org
> > > [mailto:r-help-bounces at r-project.org] On Behalf Of Paul Smith
> > > Sent: Friday, September 28, 2007 1:12 PM
> > > To: r-help
> > > Subject: [R] Drawing functions on Cartesian coordinate systems
> > >
> > > Dear All,
> > >
> > > Can R draw plots of functions on a Cartesian coordinate 
> system with 
> > > axes like the ones shown at
> > >
> > > http://en.wikipedia.org/wiki/Image:Cartesian-coordinate-system
> > > -with-circle.s
> > > vg
> > >
> > > ?
> > >
> > > I have already searched the R web-site, but found nothing.
> > >
> > > Thanks in advance,
> > >
> > > Paul
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From hb at stat.berkeley.edu  Fri Sep 28 22:11:13 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Fri, 28 Sep 2007 13:11:13 -0700
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <f8e6ff050709281013i7209b684r63aa0d8fcd69d4ef@mail.gmail.com>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>
	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>
	<6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>
	<9D14E5C4-C061-423D-A94A-5AAAAF24A4BF@gmail.com>
	<46FD1663.5070002@vanderbilt.edu>
	<DEAF35A7-190B-4F78-B7AD-3038A079CE9A@gmail.com>
	<46FD2B0A.1000205@vanderbilt.edu>
	<f8e6ff050709281013i7209b684r63aa0d8fcd69d4ef@mail.gmail.com>
Message-ID: <59d7961d0709281311w17d6854pa791d22ca66c3df4@mail.gmail.com>

On 9/28/07, hadley wickham <h.wickham at gmail.com> wrote:
> > Yes there is harm.  But to make bold lines, easy to read titles is fine.
> >   See the spar function in
> > http://biostat.mc.vanderbilt.edu/SgraphicsHints for a starter.  Also see
> > the setps, ps.slide, and setpdf functions in the Hmisc package.
>
> I was interested to see that you have code for drawing scatterplots
> with multiple y-axes.  As far as I know the only legitimate use for a
> double-axis plot is to confuse or mislead the reader (and this is not
> a very ethical use case).  Perhaps you have a counter-example?

Eh... How about all cases where you plot against one variable but want
to show it in different units, e.g. temperature in degrees of
Celsius/Centigrades on one and degrees on Fahrenheit on the other?  I
would say that is a case where you rather want to help the reader, not
mislead her/him.

-Henrik


>
> Hadley
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From phhs80 at gmail.com  Fri Sep 28 22:12:41 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Fri, 28 Sep 2007 21:12:41 +0100
Subject: [R] Drawing functions on Cartesian coordinate systems
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBC38F67@LP-EXCHVS07.CO.IHC.COM>
References: <6ade6f6c0709281012x2bdbc819nc3e3e66c29fc5809@mail.gmail.com>
	<009b01c801f5$8780a730$6400a8c0@DD4XFW31>
	<07E228A5BE53C24CAD490193A7381BBBC38F20@LP-EXCHVS07.CO.IHC.COM>
	<6ade6f6c0709281219q4778d3c2yaac41e46392e6cf6@mail.gmail.com>
	<07E228A5BE53C24CAD490193A7381BBBC38F67@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <6ade6f6c0709281312x5b317443i28f8ffbe2f5d1c36@mail.gmail.com>

On 9/28/07, Greg Snow <Greg.Snow at intermountainmail.org> wrote:
> Look at the las argument in ?par for the easiest solution (can be passed
> to axis).

Thanks a lot, Greg! That is it!

Paul


> > -----Original Message-----
> > From: r-help-bounces at r-project.org
> > [mailto:r-help-bounces at r-project.org] On Behalf Of Paul Smith
> > Sent: Friday, September 28, 2007 1:19 PM
> > To: r-help
> > Subject: Re: [R] Drawing functions on Cartesian coordinate systems
> >
> > On 9/28/07, Greg Snow <Greg.Snow at intermountainmail.org> wrote:
> > > I think he wants the axes crossing at 0,0 not on the outer
> > edges like
> > > the default.
> > >
> > > You can put the axes in the plot (though it tends to
> > distract rather
> > > than help in many cases) by:
> > >
> > > > axis(1, pos=0)
> > > > axis(2, pos=0)
> > >
> > > You will need to draw the arrowheads yourself.  There are options
> > > (under
> > > ?par) for tick length and how to suppress the default axes.
> >
> > Thanks, Greg, for your suggestion. That is in line with what
> > I was looking for. However, I still have  one more question.
> > Take the following code:
> >
> > curve(sin(x),-pi,pi,axes=F,ylab="",xlab="")
> > axis(1, pos=0)
> > axis(2, pos=0,at=c(-1,-0.5,0.5,1))
> >
> > How can I have the y axis labels rotated clockwise?
> >
> > Paul
> >
> >
> >
> >
> >
> > > > -----Original Message-----
> > > > From: r-help-bounces at r-project.org
> > > > [mailto:r-help-bounces at r-project.org] On Behalf Of
> > Charles Annis, P.E.
> > > > Sent: Friday, September 28, 2007 11:32 AM
> > > > To: 'Paul Smith'; 'r-help'
> > > > Subject: Re: [R] Drawing functions on Cartesian coordinate systems
> > > >
> > > > Yes, R can do that.  Well, actually YOU can do that using R.
> > > >
> > > > But it is hard to believe that you looked very hard
> > before writing.
> > > > Did you look at these R functions?
> > > >
> > > > ?plot
> > > > ?line
> > > > ?points
> > > > ?arrows
> > > >
> > > >
> > > >
> > > > Charles Annis, P.E.
> > > >
> > > > Charles.Annis at StatisticalEngineering.com
> > > > phone: 561-352-9699
> > > > eFax:  614-455-3265
> > > > http://www.StatisticalEngineering.com
> > > >
> > > > -----Original Message-----
> > > > From: r-help-bounces at r-project.org
> > > > [mailto:r-help-bounces at r-project.org] On Behalf Of Paul Smith
> > > > Sent: Friday, September 28, 2007 1:12 PM
> > > > To: r-help
> > > > Subject: [R] Drawing functions on Cartesian coordinate systems
> > > >
> > > > Dear All,
> > > >
> > > > Can R draw plots of functions on a Cartesian coordinate
> > system with
> > > > axes like the ones shown at
> > > >
> > > > http://en.wikipedia.org/wiki/Image:Cartesian-coordinate-system
> > > > -with-circle.s
> > > > vg
> > > >
> > > > ?
> > > >
> > > > I have already searched the R web-site, but found nothing.
> > > >
> > > > Thanks in advance,
> > > >
> > > > Paul
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > >
> > >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>


From Greg.Snow at intermountainmail.org  Fri Sep 28 22:14:19 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 28 Sep 2007 14:14:19 -0600
Subject: [R] P-P plot
In-Reply-To: <36d691950709281216i1d7f94d5nd173bd75f4c3a71f@mail.gmail.com>
References: <36d691950709281216i1d7f94d5nd173bd75f4c3a71f@mail.gmail.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBC38F6D@LP-EXCHVS07.CO.IHC.COM>

Does this give you what you want?

fit <- lm( Petal.Width ~ Petal.Length, data=iris)

tmp1 <- resid(fit)
tmp2 <- pnorm( tmp1, 0, summary(fit)$sigma )

par(mfrow=c(2,1))
qqnorm(tmp1)
qqline(tmp1)

plot( ppoints(length(tmp1)), sort(tmp2), xlab='Theoretical Percentiles',
 ylab='Sample Percentiles')
abline(0,1)


Most people these days prefer the qqplot to the pp plot, the qq-plot
gives more room to the set of points that are generally most
interesting.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Maura E Monville
> Sent: Friday, September 28, 2007 1:17 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] P-P plot
> 
> Sorry for my silly questions. I'm a beginner with R and most 
> statistics concepts.
> I carried out a simple linear regression where the dependent 
> variable is explained through a combination of powers of 
> cos(independent variable).
> I can see R returned a good R^2 factor (> 0.99) but I have a 
> hard time at interpreting all the other info that R prints 
> out by using summary( regression.results), 
> residuals(regression.results), anova(regression.results),
> 
> plot(regression.results).
> I know sometimes R^2 might be misleading ..
> 
> I see that R provided a Q-Q plot by default.
> Is it possible to get a P-P plot ? I searched for that but 
> did not get anywhere ...
> 
> Thank you in advance.
> Best regards,
> 
> --
> Maura E.M
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From maustin at amgen.com  Fri Sep 28 22:27:30 2007
From: maustin at amgen.com (Austin, Matt)
Date: Fri, 28 Sep 2007 13:27:30 -0700
Subject: [R] Graphics and LaTeX documents with the same font
Message-ID: <E7D5AB4811D20B489622AABA9C53859116B1CA10@teal-exch.amgen.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070928/27d30d37/attachment.pl 

From bates at stat.wisc.edu  Fri Sep 28 23:00:50 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 28 Sep 2007 16:00:50 -0500
Subject: [R] fitted values in LMER for the fixed-effects only
In-Reply-To: <46FD5026.4030604@bio.ulaval.ca>
References: <46FD5026.4030604@bio.ulaval.ca>
Message-ID: <40e66e0b0709281400o2c6b6688s6a65e93fe185543f@mail.gmail.com>

On 9/28/07, Anouk Simard <Anouk.Simard at bio.ulaval.ca> wrote:
> Hi,
>
> I would like to extract the fitted values from a model using LMER but
> only for the fix portion of the model and not for the fix and random
> portion (e.g it is the procedure outpm or outp in SAS). I am aware of
> the procedure fitted() but I not sure it give the fitted values both for
> the fixed and random or only the fixed. I looked in the r help and the r
> list and I haven't not found much details about it excepted this
> comments from Douglas Bates in January 2006 :
>
> "Would it help if there were an option in the fitted method to allow for
> fixed-effects only versus fixed- and random-effects? As you say, because
> lmer models do not need to be hierarchical it is not obvious what it
> would mean to include some but not all of the random effects terms in
> the "fitted values". However, it is easy and unambiguous to define
> fitted values for the fixed-effects only.
>
> Up until a few days ago there was an option to do this but then I
> changed the calculation of the fitted values in an attempt to clean up
> the code. The calculation of the level = 0 fitted values in the new
> representation of the fitted model is quite easy. It is
>
> fm1 at X %*% fixef(fm1)"
>
> I tried the last formula, but I want to confirm that this is still the
> proper and best way to get fitted values for the fix effects using lmer.

Yes.


From jctoll at gmail.com  Fri Sep 28 23:12:43 2007
From: jctoll at gmail.com (James)
Date: Fri, 28 Sep 2007 15:12:43 -0600
Subject: [R] plot x-axis at 0
Message-ID: <4F0ECAEB-A0FC-471A-8923-E448F1C99FCC@gmail.com>

Hi,

I am trying to create a plot of a simple P&L graph for an option I'm  
pricing using Rmetrics.  I'm not trying to do anything fancy.  I just  
want to figure out if it's possible to put the x-axis at 0 rather  
than at the bottom the the entire plot.  It seems like something that  
would be relatively easy to do.  Any help or hints would be greatly  
appreciated.  Thanks.

James


From Greg.Snow at intermountainmail.org  Fri Sep 28 23:22:04 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 28 Sep 2007 15:22:04 -0600
Subject: [R] plot x-axis at 0
In-Reply-To: <4F0ECAEB-A0FC-471A-8923-E448F1C99FCC@gmail.com>
References: <4F0ECAEB-A0FC-471A-8923-E448F1C99FCC@gmail.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBC38F98@LP-EXCHVS07.CO.IHC.COM>

Use xaxt='n' in the original plot to suppress the default axis (or
axes=FALSE to supress both), then axis(1, pos=0) to draw the axis at 0.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of James
> Sent: Friday, September 28, 2007 3:13 PM
> To: r-help at r-project.org
> Subject: [R] plot x-axis at 0
> 
> Hi,
> 
> I am trying to create a plot of a simple P&L graph for an 
> option I'm pricing using Rmetrics.  I'm not trying to do 
> anything fancy.  I just want to figure out if it's possible 
> to put the x-axis at 0 rather than at the bottom the the 
> entire plot.  It seems like something that would be 
> relatively easy to do.  Any help or hints would be greatly 
> appreciated.  Thanks.
> 
> James
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From jctoll at gmail.com  Fri Sep 28 23:34:34 2007
From: jctoll at gmail.com (James)
Date: Fri, 28 Sep 2007 15:34:34 -0600
Subject: [R] plot x-axis at 0
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBC38F98@LP-EXCHVS07.CO.IHC.COM>
References: <4F0ECAEB-A0FC-471A-8923-E448F1C99FCC@gmail.com>
	<07E228A5BE53C24CAD490193A7381BBBC38F98@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <F85A9242-131F-403A-A071-9BCFF56E44B7@gmail.com>

On Sep 28, 2007, at 3:22 PM, Greg Snow wrote:

> Use xaxt='n' in the original plot to suppress the default axis (or
> axes=FALSE to supress both), then axis(1, pos=0) to draw the axis  
> at 0.

That was what I was looking for.  Thank you.  I just need to do a bit  
of refining now.

James


From perronbe at gmail.com  Fri Sep 28 23:48:55 2007
From: perronbe at gmail.com (Brian Perron)
Date: Fri, 28 Sep 2007 17:48:55 -0400
Subject: [R] Selecting values
Message-ID: <1e6b5c080709281448x118014fwa5b4a5af8f1d376d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070928/b98a9151/attachment.pl 

From marc_schwartz at comcast.net  Sat Sep 29 00:08:51 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 28 Sep 2007 17:08:51 -0500
Subject: [R] Selecting values
In-Reply-To: <1e6b5c080709281448x118014fwa5b4a5af8f1d376d@mail.gmail.com>
References: <1e6b5c080709281448x118014fwa5b4a5af8f1d376d@mail.gmail.com>
Message-ID: <1191017331.3547.121.camel@Bellerophon.localdomain>

On Fri, 2007-09-28 at 17:48 -0400, Brian Perron wrote:
> Hello all,
> 
> An elementary question that I am sure can be easily cracked by an R
> enthusiast.  Let's say I have multiple scores (y) on subjects (x.sample).
> Some subjects have a few more scores than others.  Can somebody suggest some
> code that will select the first score for each subject?
> 
> For example, the following code generates scores for 5 subjects:
> 
> > x <- c(1:5)
> > x.sample <- sample(x, 20, replace = TRUE)
> > x.sample <- sort(x.sample)
> > y <- rnorm(20)
> > z <- cbind(x.sample, y)
> > z
> 
>       x.sample          y
>  [1,]        1 -1.2006469
>  [2,]        1  0.7615261
>  [3,]        1 -0.1287516
>  [4,]        1 - 1.1796474
>  [5,]        1 -1.2902519
>  [6,]        2 -0.1614918
>  [7,]        2 -0.1464773
>  [8,]        2 -0.8875417
>  [9,]        2  0.3062891
> [10,]        2  0.4398530
> [11,]        3 -0.5717729
> [12,]        3 - 0.2938118
> [13,]        4 -0.2398887
> [14,]        4  0.8425419
> [15,]        4  2.5269801
> [16,]        4 -0.3643613
> [17,]        5  1.1690564
> [18,]        5 -0.7644521
> [19,]        5  1.4178982
> [20,]        5 - 0.8198921
> 
> I am only interested in extracting the first score (y) for each unique
> subject (x.sample).  So, I would like to generate the following output.
> 
>         x.sample       y
> [1,]    1                  -1.2006469
> [2,]    2                  -0.1614918
> [3,]    3                  -0.5717729
> [4,]    4                  -0.2398887
> [5,]    5                   1.1690564
> 
> Any assistance would be greatly appreciated.
> 
> Regards,
> Brian

See ?split, ?sapply and ?unique.

Then try this:

> cbind(unique(z[, 1]), sapply(split(z[, 2], z[, 1]), "[", 1))
  [,1]       [,2]
1    1 -1.2006469
2    2 -0.1614918
3    3 -0.5717729
4    4 -0.2398887
5    5  1.1690564


The key part of that is:

> split(z[, 2], z[, 1])
$`1`
[1] -1.2006469  0.7615261 -0.1287516 -1.1796474 -1.2902519

$`2`
[1] -0.1614918 -0.1464773 -0.8875417  0.3062891  0.4398530

$`3`
[1] -0.5717729 -0.2938118

$`4`
[1] -0.2398887  0.8425419  2.5269801 -0.3643613

$`5`
[1]  1.1690564 -0.7644521  1.4178982 -0.8198921


which splits 'z' by the values in the first column.

Then we use sapply() to go through the list and subset the first element
in each vector:

> sapply(split(z[, 2], z[, 1]), "[", 1)
         1          2          3          4          5 
-1.2006469 -0.1614918 -0.5717729 -0.2398887  1.1690564 


Then we cbind() that result to the unique values in the first column.

HTH,

Marc Schwartz


From mckellercran at gmail.com  Sat Sep 29 00:12:50 2007
From: mckellercran at gmail.com (Matthew Keller)
Date: Fri, 28 Sep 2007 16:12:50 -0600
Subject: [R] Selecting values
In-Reply-To: <1191017331.3547.121.camel@Bellerophon.localdomain>
References: <1e6b5c080709281448x118014fwa5b4a5af8f1d376d@mail.gmail.com>
	<1191017331.3547.121.camel@Bellerophon.localdomain>
Message-ID: <3f547caa0709281512n232a22acicd13da453991b80f@mail.gmail.com>

Is this easier?

x.index <- duplicated(x.sample)==FALSE
cbind(x.sample[x.index],y[x.index])


- Matt

On 9/28/07, Marc Schwartz <marc_schwartz at comcast.net> wrote:
> On Fri, 2007-09-28 at 17:48 -0400, Brian Perron wrote:
> > Hello all,
> >
> > An elementary question that I am sure can be easily cracked by an R
> > enthusiast.  Let's say I have multiple scores (y) on subjects (x.sample).
> > Some subjects have a few more scores than others.  Can somebody suggest some
> > code that will select the first score for each subject?
> >
> > For example, the following code generates scores for 5 subjects:
> >
> > > x <- c(1:5)
> > > x.sample <- sample(x, 20, replace = TRUE)
> > > x.sample <- sort(x.sample)
> > > y <- rnorm(20)
> > > z <- cbind(x.sample, y)
> > > z
> >
> >       x.sample          y
> >  [1,]        1 -1.2006469
> >  [2,]        1  0.7615261
> >  [3,]        1 -0.1287516
> >  [4,]        1 - 1.1796474
> >  [5,]        1 -1.2902519
> >  [6,]        2 -0.1614918
> >  [7,]        2 -0.1464773
> >  [8,]        2 -0.8875417
> >  [9,]        2  0.3062891
> > [10,]        2  0.4398530
> > [11,]        3 -0.5717729
> > [12,]        3 - 0.2938118
> > [13,]        4 -0.2398887
> > [14,]        4  0.8425419
> > [15,]        4  2.5269801
> > [16,]        4 -0.3643613
> > [17,]        5  1.1690564
> > [18,]        5 -0.7644521
> > [19,]        5  1.4178982
> > [20,]        5 - 0.8198921
> >
> > I am only interested in extracting the first score (y) for each unique
> > subject (x.sample).  So, I would like to generate the following output.
> >
> >         x.sample       y
> > [1,]    1                  -1.2006469
> > [2,]    2                  -0.1614918
> > [3,]    3                  -0.5717729
> > [4,]    4                  -0.2398887
> > [5,]    5                   1.1690564
> >
> > Any assistance would be greatly appreciated.
> >
> > Regards,
> > Brian
>
> See ?split, ?sapply and ?unique.
>
> Then try this:
>
> > cbind(unique(z[, 1]), sapply(split(z[, 2], z[, 1]), "[", 1))
>   [,1]       [,2]
> 1    1 -1.2006469
> 2    2 -0.1614918
> 3    3 -0.5717729
> 4    4 -0.2398887
> 5    5  1.1690564
>
>
> The key part of that is:
>
> > split(z[, 2], z[, 1])
> $`1`
> [1] -1.2006469  0.7615261 -0.1287516 -1.1796474 -1.2902519
>
> $`2`
> [1] -0.1614918 -0.1464773 -0.8875417  0.3062891  0.4398530
>
> $`3`
> [1] -0.5717729 -0.2938118
>
> $`4`
> [1] -0.2398887  0.8425419  2.5269801 -0.3643613
>
> $`5`
> [1]  1.1690564 -0.7644521  1.4178982 -0.8198921
>
>
> which splits 'z' by the values in the first column.
>
> Then we use sapply() to go through the list and subset the first element
> in each vector:
>
> > sapply(split(z[, 2], z[, 1]), "[", 1)
>          1          2          3          4          5
> -1.2006469 -0.1614918 -0.5717729 -0.2398887  1.1690564
>
>
> Then we cbind() that result to the unique values in the first column.
>
> HTH,
>
> Marc Schwartz
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Matthew C Keller
Postdoctoral Fellow
Virginia Institute for Psychiatric and Behavioral Genetics


From f.harrell at vanderbilt.edu  Sat Sep 29 00:22:11 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 28 Sep 2007 17:22:11 -0500
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <f8e6ff050709281013i7209b684r63aa0d8fcd69d4ef@mail.gmail.com>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>	
	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>	
	<6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>	
	<9D14E5C4-C061-423D-A94A-5AAAAF24A4BF@gmail.com>	
	<46FD1663.5070002@vanderbilt.edu>	
	<DEAF35A7-190B-4F78-B7AD-3038A079CE9A@gmail.com>	
	<46FD2B0A.1000205@vanderbilt.edu>
	<f8e6ff050709281013i7209b684r63aa0d8fcd69d4ef@mail.gmail.com>
Message-ID: <46FD7E93.3030704@vanderbilt.edu>

hadley wickham wrote:
>> Yes there is harm.  But to make bold lines, easy to read titles is fine.
>>   See the spar function in
>> http://biostat.mc.vanderbilt.edu/SgraphicsHints for a starter.  Also see
>> the setps, ps.slide, and setpdf functions in the Hmisc package.
> 
> I was interested to see that you have code for drawing scatterplots
> with multiple y-axes.  As far as I know the only legitimate use for a
> double-axis plot is to confuse or mislead the reader (and this is not
> a very ethical use case).  Perhaps you have a counter-example?
> 
> Hadley
> 

Generally I share your dislike of those, and prefer multiple panels with 
different scales.

Cheers
Frank

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From marc_schwartz at comcast.net  Sat Sep 29 00:58:52 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 28 Sep 2007 17:58:52 -0500
Subject: [R] Selecting values
In-Reply-To: <3f547caa0709281512n232a22acicd13da453991b80f@mail.gmail.com>
References: <1e6b5c080709281448x118014fwa5b4a5af8f1d376d@mail.gmail.com>
	<1191017331.3547.121.camel@Bellerophon.localdomain>
	<3f547caa0709281512n232a22acicd13da453991b80f@mail.gmail.com>
Message-ID: <1191020332.3557.7.camel@Bellerophon.localdomain>

Here is yet another approach using aggregate(), which internally,
basically does what my first solution did:

> aggregate(z[, 2], list(z[, 1]), "[", 1)
  Group.1          x
1       1 -1.2006469
2       2 -0.1614918
3       3 -0.5717729
4       4 -0.2398887
5       5  1.1690564

See ?aggregate

Note that you get a data frame as a result, rather than a matrix.

Also, you could 'collapse' the split() and sapply() part of my first
solution using tapply():

> tapply(z[, 2], z[, 1], "[", 1)
         1          2          3          4          5 
-1.2006469 -0.1614918 -0.5717729 -0.2398887  1.1690564 


As has been said by fortune("Yoda"):

Evelyn Hall: I would like to know how (if) I can extract some of the
information from the summary of my nlme.
Simon Blomberg: This is R. There is no if. Only how.
   -- Evelyn Hall and Simon 'Yoda' Blomberg
      R-help (April 2005)

HTH,

Marc Schwartz

On Fri, 2007-09-28 at 16:12 -0600, Matthew Keller wrote:
> Is this easier?
> 
> x.index <- duplicated(x.sample)==FALSE
> cbind(x.sample[x.index],y[x.index])
> 
> 
> - Matt
> 
> On 9/28/07, Marc Schwartz <marc_schwartz at comcast.net> wrote:
> > On Fri, 2007-09-28 at 17:48 -0400, Brian Perron wrote:
> > > Hello all,
> > >
> > > An elementary question that I am sure can be easily cracked by an R
> > > enthusiast.  Let's say I have multiple scores (y) on subjects (x.sample).
> > > Some subjects have a few more scores than others.  Can somebody suggest some
> > > code that will select the first score for each subject?
> > >
> > > For example, the following code generates scores for 5 subjects:
> > >
> > > > x <- c(1:5)
> > > > x.sample <- sample(x, 20, replace = TRUE)
> > > > x.sample <- sort(x.sample)
> > > > y <- rnorm(20)
> > > > z <- cbind(x.sample, y)
> > > > z
> > >
> > >       x.sample          y
> > >  [1,]        1 -1.2006469
> > >  [2,]        1  0.7615261
> > >  [3,]        1 -0.1287516
> > >  [4,]        1 - 1.1796474
> > >  [5,]        1 -1.2902519
> > >  [6,]        2 -0.1614918
> > >  [7,]        2 -0.1464773
> > >  [8,]        2 -0.8875417
> > >  [9,]        2  0.3062891
> > > [10,]        2  0.4398530
> > > [11,]        3 -0.5717729
> > > [12,]        3 - 0.2938118
> > > [13,]        4 -0.2398887
> > > [14,]        4  0.8425419
> > > [15,]        4  2.5269801
> > > [16,]        4 -0.3643613
> > > [17,]        5  1.1690564
> > > [18,]        5 -0.7644521
> > > [19,]        5  1.4178982
> > > [20,]        5 - 0.8198921
> > >
> > > I am only interested in extracting the first score (y) for each unique
> > > subject (x.sample).  So, I would like to generate the following output.
> > >
> > >         x.sample       y
> > > [1,]    1                  -1.2006469
> > > [2,]    2                  -0.1614918
> > > [3,]    3                  -0.5717729
> > > [4,]    4                  -0.2398887
> > > [5,]    5                   1.1690564
> > >
> > > Any assistance would be greatly appreciated.
> > >
> > > Regards,
> > > Brian
> >
> > See ?split, ?sapply and ?unique.
> >
> > Then try this:
> >
> > > cbind(unique(z[, 1]), sapply(split(z[, 2], z[, 1]), "[", 1))
> >   [,1]       [,2]
> > 1    1 -1.2006469
> > 2    2 -0.1614918
> > 3    3 -0.5717729
> > 4    4 -0.2398887
> > 5    5  1.1690564
> >
> >
> > The key part of that is:
> >
> > > split(z[, 2], z[, 1])
> > $`1`
> > [1] -1.2006469  0.7615261 -0.1287516 -1.1796474 -1.2902519
> >
> > $`2`
> > [1] -0.1614918 -0.1464773 -0.8875417  0.3062891  0.4398530
> >
> > $`3`
> > [1] -0.5717729 -0.2938118
> >
> > $`4`
> > [1] -0.2398887  0.8425419  2.5269801 -0.3643613
> >
> > $`5`
> > [1]  1.1690564 -0.7644521  1.4178982 -0.8198921
> >
> >
> > which splits 'z' by the values in the first column.
> >
> > Then we use sapply() to go through the list and subset the first element
> > in each vector:
> >
> > > sapply(split(z[, 2], z[, 1]), "[", 1)
> >          1          2          3          4          5
> > -1.2006469 -0.1614918 -0.5717729 -0.2398887  1.1690564
> >
> >
> > Then we cbind() that result to the unique values in the first column.
> >
> > HTH,
> >
> > Marc Schwartz
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
>


From dlakelan at street-artists.org  Sat Sep 29 01:19:18 2007
From: dlakelan at street-artists.org (Daniel Lakeland)
Date: Fri, 28 Sep 2007 16:19:18 -0700
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <f8e6ff050709281013i7209b684r63aa0d8fcd69d4ef@mail.gmail.com>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>
	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>
	<6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>
	<9D14E5C4-C061-423D-A94A-5AAAAF24A4BF@gmail.com>
	<46FD1663.5070002@vanderbilt.edu>
	<DEAF35A7-190B-4F78-B7AD-3038A079CE9A@gmail.com>
	<46FD2B0A.1000205@vanderbilt.edu>
	<f8e6ff050709281013i7209b684r63aa0d8fcd69d4ef@mail.gmail.com>
Message-ID: <20070928231918.GA13839@street-artists.org>

On Fri, Sep 28, 2007 at 12:13:46PM -0500, hadley wickham wrote:
> > Yes there is harm.  But to make bold lines, easy to read titles is fine.
> >   See the spar function in
> > http://biostat.mc.vanderbilt.edu/SgraphicsHints for a starter.  Also see
> > the setps, ps.slide, and setpdf functions in the Hmisc package.
> 
> I was interested to see that you have code for drawing scatterplots
> with multiple y-axes.  As far as I know the only legitimate use for a
> double-axis plot is to confuse or mislead the reader (and this is not
> a very ethical use case).  Perhaps you have a counter-example?
> 
> Hadley

It can be useful to see multiple timeseries on the same x (time) scale
but with different y scales for each to see if there are time-lag
correlations between different quantities


-- 
Daniel Lakeland
dlakelan at street-artists.org
http://www.street-artists.org/~dlakelan


From Soren.Hojsgaard at agrsci.dk  Sat Sep 29 01:30:02 2007
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Sat, 29 Sep 2007 01:30:02 +0200
Subject: [R] Importing only one function from a package
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC0562F703@DJFPOST01.djf.agrsci.dk>

Dear List
 
In a package I want to import the mApply function from the Hmisc package, and I would like to import only that function.
 
1) If I write "Depends: Hmisc" in the DESCRIPTION file I get the whole Hmisc package, so that is not the way to go ahead.
 
2) According to "Writing R extensions", sec 1.6.1 "Specifying imports and exports" I can (as I read it) simply type Hmisc:::mApply(....) in my code. That works, but gives a warning in the check:
 
* checking for unstated dependencies in R code ... WARNING
'::' or ':::' imports not declared from:
  Hmisc
 
3) According to the same section I can (again as I read it) write in the NAMESPACE file
importFrom(Hmisc,mApply)
 
Then I get:
 
* checking package dependencies ... ERROR
Namespace dependencies not required:
  Hmisc
 
That message goes away if I write  "Depends: Hmisc" in DESCRIPTION, but then we are back to 1) where I started where the whole Hmisc package is loaded.
 
Obviously I have missed a point or two somewhere. Can anyone enlighten me?
 
I use R 2.5.1 on windows XP.
 
Regards
S?ren
 
 
 


From mckellercran at gmail.com  Sat Sep 29 01:36:01 2007
From: mckellercran at gmail.com (Matthew Keller)
Date: Fri, 28 Sep 2007 17:36:01 -0600
Subject: [R] Importing only one function from a package
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC0562F703@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC0562F703@DJFPOST01.djf.agrsci.dk>
Message-ID: <3f547caa0709281636x351177dfx43dd2b8e4f798b29@mail.gmail.com>

Hi Soren,

What I do in cases like this is just copy the function and place it
into my script at the top (or write it into its own source file and
call it from script). Best,

Matt

On 9/28/07, S?ren H?jsgaard <Soren.Hojsgaard at agrsci.dk> wrote:
> Dear List
>
> In a package I want to import the mApply function from the Hmisc package, and I would like to import only that function.
>
> 1) If I write "Depends: Hmisc" in the DESCRIPTION file I get the whole Hmisc package, so that is not the way to go ahead.
>
> 2) According to "Writing R extensions", sec 1.6.1 "Specifying imports and exports" I can (as I read it) simply type Hmisc:::mApply(....) in my code. That works, but gives a warning in the check:
>
> * checking for unstated dependencies in R code ... WARNING
> '::' or ':::' imports not declared from:
>   Hmisc
>
> 3) According to the same section I can (again as I read it) write in the NAMESPACE file
> importFrom(Hmisc,mApply)
>
> Then I get:
>
> * checking package dependencies ... ERROR
> Namespace dependencies not required:
>   Hmisc
>
> That message goes away if I write  "Depends: Hmisc" in DESCRIPTION, but then we are back to 1) where I started where the whole Hmisc package is loaded.
>
> Obviously I have missed a point or two somewhere. Can anyone enlighten me?
>
> I use R 2.5.1 on windows XP.
>
> Regards
> S?ren
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Matthew C Keller
Postdoctoral Fellow
Virginia Institute for Psychiatric and Behavioral Genetics

From deepayan.sarkar at gmail.com  Sat Sep 29 02:01:56 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 28 Sep 2007 17:01:56 -0700
Subject: [R] Importing only one function from a package
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC0562F703@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC0562F703@DJFPOST01.djf.agrsci.dk>
Message-ID: <eb555e660709281701k331e8cccj904ac22b96044097@mail.gmail.com>

On 9/28/07, S?ren H?jsgaard <Soren.Hojsgaard at agrsci.dk> wrote:
> Dear List
>
> In a package I want to import the mApply function from the Hmisc package, and I would like to import only that function.
>
> 1) If I write "Depends: Hmisc" in the DESCRIPTION file I get the whole Hmisc package, so that is not the way to go ahead.
>
> 2) According to "Writing R extensions", sec 1.6.1 "Specifying imports and exports" I can (as I read it) simply type Hmisc:::mApply(....) in my code. That works, but gives a warning in the check:
>
> * checking for unstated dependencies in R code ... WARNING
> '::' or ':::' imports not declared from:
>   Hmisc
>
> 3) According to the same section I can (again as I read it) write in the NAMESPACE file
> importFrom(Hmisc,mApply)
>
> Then I get:
>
> * checking package dependencies ... ERROR
> Namespace dependencies not required:
>   Hmisc
>
> That message goes away if I write  "Depends: Hmisc" in DESCRIPTION, but then
> we are back to 1) where I started where the whole Hmisc package is loaded.
>
> Obviously I have missed a point or two somewhere. Can anyone enlighten me?

For both 2) and 3), the correct DESCRIPTION entry is

Imports: Hmisc

And for 2), you should be able to use Hmisc::mApply (i.e., 2 colons,
not 3), although 3) is preferred.

-Deepayan

From john_d_mchenry at yahoo.com  Sat Sep 29 02:26:24 2007
From: john_d_mchenry at yahoo.com (John McHenry)
Date: Fri, 28 Sep 2007 17:26:24 -0700 (PDT)
Subject: [R] RODBC and Oracle
Message-ID: <961118.63176.qm@web35408.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070928/e35db982/attachment.pl 

From sapsi at pobox.com  Sat Sep 29 03:51:46 2007
From: sapsi at pobox.com (Saptarshi Guha)
Date: Fri, 28 Sep 2007 21:51:46 -0400
Subject: [R] Problem compiling R - "use of NULL environment is defunct"
Message-ID: <07F7EB60-85C7-4D1E-8EE3-5926229C6639@pobox.com>

Hello,
I downloaded R-2.5.1 and configured it on a AMD x86-74 running  
Redhat. During compilation i get this error

configure --prefix=$HOME/mine
make

mkdir -p -- ../../../../library/methods/libs
make[5]: Leaving directory `/home/sguha/tmp/R-2.5.1/src/library/ 
methods/src'
make[4]: Leaving directory `/home/sguha/tmp/R-2.5.1/src/library/ 
methods/src'
make[4]: Entering directory `/home/sguha/tmp/R-2.5.1/src/library/ 
methods'
dumping R code in package 'methods'
Error in `parent.env<-`(`*tmp*`, value = NULL) :
         use of NULL environment is defunct
Execution halted
make[4]: *** [../../../library/methods/R/methods.rdb] Error 1
make[4]: Leaving directory `/home/sguha/tmp/R-2.5.1/src/library/methods'
make[3]: *** [all] Error 2
make[3]: Leaving directory `/home/sguha/tmp/R-2.5.1/src/library/methods'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/home/sguha/tmp/R-2.5.1/src/library'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/sguha/tmp/R-2.5.1/src'
make: *** [R] Error 1


Could someone point out what I'm supposed to fix?
Thank you for your time
Saptarshi


From admin at r-cookbook.com  Sat Sep 29 04:00:00 2007
From: admin at r-cookbook.com (Jeff Spies)
Date: Fri, 28 Sep 2007 22:00:00 -0400
Subject: [R] New R website: R-Cookbook.com
In-Reply-To: <f8e6ff050709280615i6a47ba57p7fbe45ce0dc13919@mail.gmail.com>
References: <40992922-C9FB-4DBD-9633-140D2796523F@r-cookbook.com>
	<f8e6ff050709280615i6a47ba57p7fbe45ce0dc13919@mail.gmail.com>
Message-ID: <843DCF2A-7CC9-4B7E-A525-8D551DB0B5C6@r-cookbook.com>

Hadley,

This was something I forgot to change before making the site public.   
Thanks for pointing out the creative commons license--it's definitely  
what I was thinking: share-alike content.

I'd be glad to hear any other suggestions you might have,

Jeff.

On Sep 28, 2007, at 9:15 AM, hadley wickham wrote:

> Hi Jeff,
>
> That looks like a nice initiative.  However, if you are interested in
> getting contributions from the community, it might be good to spell
> out how others might use the content of the site.  Currently you have
> copyright r-cookbook.com, but maybe you could consider a creative
> commons (http://creativecommons.org/) license instead?
>
> Hadley
>
> On 9/27/07, Jeff <admin at r-cookbook.com> wrote:
>> R Community,
>>
>> I've put together a website that I thought this mailing list might be
>> interested in: http://www.r-cookbook.com
>>
>> It's a (free) community-driven content management system for R
>> "recipes", or working examples.  Some of the features of the site are
>> code highlighting, recipe ratings, recipe comments, personal "recipe
>> boxes" to save your favorite recipes, community tagging, RSS feeds
>> for each user and for each tag, and similar recipe recommendations.
>>
>> Although I imagine that many users will sort/search/find recipes by
>> tags, I've implemented a linear organization for recipes as well:
>> guides.  These will be compilations of "recipes", organized in a
>> logical fashion as to promote understanding of the topic of that
>> particular guide and introduced with user-contributed pages.  Over
>> time, hopefully with the help of the community, more guides will be
>> created and the ones I have will be filled-in to actually be useful.
>> I have started several guides to give you an idea of the sort of
>> thing I'm thinking: Introduction to R, Longitudinal Modeling in R,
>> Exploratory Data Analysis in R, and more here, http://www.r-
>> cookbook.com/guide
>>
>> A couple of features that will be worked on in the near future are
>> (1) the design of the site and (2) working on a more interactive code
>> display (right now, functions are highlighted and linked to the r-
>> docs, but that's it).
>>
>> I hope some of you might find the site useful and perhaps even
>> consider contributing your own recipes.  If you have any suggestions
>> or feature requests, I'd be glad to hear them!
>>
>> Jeff.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> -- 
> http://had.co.nz/
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From DOgle at northland.edu  Sat Sep 29 04:58:23 2007
From: DOgle at northland.edu (Derek Ogle)
Date: Fri, 28 Sep 2007 21:58:23 -0500
Subject: [R] seq() question
References: <40992922-C9FB-4DBD-9633-140D2796523F@r-cookbook.com>
Message-ID: <D86C9EFF6AA3734193923FFA1EE4308B0435FADE@nc-mail2.northland.edu>

Hello all,

I am attempting to use the seq() function to define breaks for the cut() function but am finding performance that I do not understand.  The root of my problem appears to be contained in the following simple example.

> brks <- seq(0.8,1.2,0.1)
> brks
[1] 0.8 0.9 1.0 1.1 1.2
> brks==1.2
[1] FALSE FALSE FALSE FALSE FALSE
> brks==1.1
[1] FALSE FALSE FALSE  TRUE FALSE

The last value in the sequence does not appear to be equal to its apparent value (i.e., 1.2) whereas the fourth value in the sequence, for example, does (e.g., 1.1).

Any help/suggestions with the concept or "trick" that I am missing here?  Thank you in advance.

p.s., I am using R 2.5.1 with ...

> Sys.info()
                      sysname                       release 
                    "Windows"                      "NT 5.1" 
                      version                      nodename 
"(build 2600) Service Pack 2"                  "CSE229-001" 
                      machine
                        "x86"


From marc_schwartz at comcast.net  Sat Sep 29 05:19:51 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Fri, 28 Sep 2007 22:19:51 -0500
Subject: [R] seq() question
In-Reply-To: <D86C9EFF6AA3734193923FFA1EE4308B0435FADE@nc-mail2.northland.edu>
References: <40992922-C9FB-4DBD-9633-140D2796523F@r-cookbook.com>
	<D86C9EFF6AA3734193923FFA1EE4308B0435FADE@nc-mail2.northland.edu>
Message-ID: <1191035991.3557.9.camel@Bellerophon.localdomain>

On Fri, 2007-09-28 at 21:58 -0500, Derek Ogle wrote:
> Hello all,
> 
> I am attempting to use the seq() function to define breaks for the
> cut() function but am finding performance that I do not understand.
> The root of my problem appears to be contained in the following simple
> example.
> 
> > brks <- seq(0.8,1.2,0.1)
> > brks
> [1] 0.8 0.9 1.0 1.1 1.2
> > brks==1.2
> [1] FALSE FALSE FALSE FALSE FALSE
> > brks==1.1
> [1] FALSE FALSE FALSE  TRUE FALSE
> 
> The last value in the sequence does not appear to be equal to its
> apparent value (i.e., 1.2) whereas the fourth value in the sequence,
> for example, does (e.g., 1.1).
> 
> Any help/suggestions with the concept or "trick" that I am missing
> here?  Thank you in advance.

See R FAQ 7.31 Why doesn't R think these numbers are equal?

http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

HTH,

Marc Schwartz


From ninerh at gmail.com  Sat Sep 29 06:00:34 2007
From: ninerh at gmail.com (Niner)
Date: Fri, 28 Sep 2007 21:00:34 -0700
Subject: [R] [Help] Error when using nls
Message-ID: <947CDD25-F02A-4F69-A8BE-57098E1F2329@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070928/32f6e1c5/attachment.pl 

From sarum-Vitale at 7912.com  Sat Sep 29 07:09:14 2007
From: sarum-Vitale at 7912.com (sarum Vitale)
Date: Sat, 29 Sep 2007 07:09:14 +0200
Subject: [R] frixion
Message-ID: <200709290509.l8T59F4r002148@hypatia.math.ethz.ch>

Hi To r-help

Emergency report. Check DMXC!
Price up 21% in 30 minutes!
5 day price: ~$0.50


From jwd at surewest.net  Sat Sep 29 08:47:30 2007
From: jwd at surewest.net (J Dougherty)
Date: Fri, 28 Sep 2007 23:47:30 -0700
Subject: [R] kurtosis
In-Reply-To: <1190975985.46fcd9f1c02e8@webmail.shef.ac.uk>
References: <1190975985.46fcd9f1c02e8@webmail.shef.ac.uk>
Message-ID: <200709282347.30206.jwd@surewest.net>

On Friday 28 September 2007 03:39, S Bina wrote:
> Hi,
>
> I cannot find the function kurtosis. Is it sth additional I am meant to
> download? I use the MacOS X version of R.
>
> Many thanks
> Samira

If you have access to it, look at M. J. Crawley's Statistics: An Introduction 
Using R.   See page 71-72 specifically.

JWD


From efferz at gmx.de  Sat Sep 29 09:02:38 2007
From: efferz at gmx.de (Martin Efferz)
Date: Sat, 29 Sep 2007 09:02:38 +0200
Subject: [R] Problems installing GammaTest
Message-ID: <000301c80266$b8f6c940$2ae45bc0$@de>

Ein eingebundener Text mit undefiniertem Zeichensatz wurde abgetrennt.
Name: nicht verf?gbar
URL: https://stat.ethz.ch/pipermail/r-help/attachments/20070929/df8c7273/attachment.pl 

From phgrosjean at sciviews.org  Sat Sep 29 09:29:14 2007
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Sat, 29 Sep 2007 09:29:14 +0200
Subject: [R] New R website: R-Cookbook.com
In-Reply-To: <6A9A1286-9CD5-4595-BC16-3C494DF7666B@r-cookbook.com>
References: <40992922-C9FB-4DBD-9633-140D2796523F@r-cookbook.com>
	<46FCB73D.9000408@sciviews.org>
	<6A9A1286-9CD5-4595-BC16-3C494DF7666B@r-cookbook.com>
Message-ID: <46FDFECA.2030704@sciviews.org>

Hi Jeff,

You give a very long answer, and I don't want to comment each of you 
points individually. The Wiki is flexible enough so that pages can be 
arranged the way people want (they can add new sections too if they 
want; the proposed structure is only a *suggestion* and by the way, the 
structure is a consensus produced by a team of a couple of dozen R 
users, which should give it a little bit of credit). There is a search 
engine, and an RSS feed, too. Author that want to get authorship on one 
page can ask me to lock their page, if they want, so that other people 
cannot edit them. And finally, nothing forbid anyone to add other 
solutions to a given problem, either on a different page, or on the same 
page as the original answer. Searching for pages produced by a given 
author is simple: just enter his name in the search box at top-right and 
click search (try "Paul Johnson", for instance).

So, may be, you are not aware enough of the possibilities provided by 
the Wiki, otherwise, you would know that most features provided by 
R-Cookbook.com already exist in the R Wiki (in a slight different form, 
for some of them). And the Wiki offers more, like unlimited version 
checking, the possibility to revert back to any old version of the 
document, to compare two versions, to include math equation in LaTeX, or 
a simplified syntax called ASCIIMathML, etc, etc.

Furthermore, I really don't see an advantage to classify your recipes by 
authors, when the kind of recipes you propose is more or less a copy and 
paste from a discussion in the R mailing list, and the "author" is the 
people that does this copy-paste, not the real author that formulated 
the original answer in the R mailing list (sic)!

And YES, R-Cookbook.com does duplicate R-Wiki, indeed. Because the main 
goal (a series of R recipes in addition to the official R documentation 
provided by R users) is *exactly* the same one for both sites! In fact, 
the two major sections of R-Cookbook.com, "recipes" and "guides" are 
nothing else than a reincarnation in a different skin of the "tips" and 
"guides" sections of the R-Wiki... and the third section, "forum", is 
really duplicating the official R mailing lists.

Now, for just the little bit I discover from R-Cookbook.com, the 
"non-linear" way of navigating through recipes is very nice (for 
instance, the "similar recipes" section at the end... note that this 
feature could be added as well in the wiki through a plugin).

I really believe that the community should join the force, not to spend 
time to duplicate existing features. In this way, I would expect 
comments and feedback on the existing tools (the R Wiki) to make it 
better. What? You don't like the presentation? So, what could you 
propose (it is Xhtml, so one can reskin the R Wiki site totally, if 
needed). You don't like the "linear" presentation (calling a wiki 
presentation as "linear", is absurd, but anyway)? So, why not to 
contribute a dokuwiki plugin to provide a "similar pages" section at the 
end of each wiki page, in order to navigate the same way as in your 
Drupal site? It is PHP, and I believe you should be able to program this 
plugin easily, if you were able to program a "HighlighteR" module on top 
of Drupal for your R-Cookbook.com.

Best,

Philippe Grosjean

..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Belgium
( ( ( ( (
..............................................................

Jeff Spies wrote:
> Hi Philippe,
> 
> I don't want to be competing in any way with any of the fantastic 
> official R resources that exist; I only want to supplement them.   
> Although this list is probably not the best place to discuss the proper 
> use of wiki's for documentation/learning, I'll make a few comments on 
> the role, I believe, R-Cookbook.com can play.
> 
> First of all, R-Cookbook.com offers two organization schemes, dictated 
> by the users: linear and (what's being call) non-linear.  Recipes can be 
> placed in guides in order to organize content linearly in a way more 
> familiar to most users.  Recipes can also be free-tagged, not only by 
> the author, but by the community (much like a wiki--although you've 
> actually implemented a linear scheme for tips and lack the non-linear 
> aspect).
> 
> Secondly, some people like to retain authorship of these sorts of 
> things, and not only for selfish reasons, like self promotion.  First, 
> they get to control how their message is delivered--other's can't edit 
> it.  My guess is that you have the wiki configured as most wiki's 
> are--community editing rights.  To counter the issues associated with 
> individual-control in a community-oriented site, at R-Cookbook.com, 
> other users can comment on the recipe, or express their regards for the 
> quality of the recipe via the rating system.  Or they can create a 
> recipe on the same topic, and the "similar recipe" engine should display 
> it beneath the recipe in question.  Some people also like to retain 
> authorship merely so their friends/students/fans can keep track of their 
> work.  At R-Cookbook.com, users get a url specific to their recipes (in 
> the format http://www.r-cookbook.com/recipes/[username]) along with a 
> feed of all of their recipes.  Also, this multi-level feed system is not 
> available (I don't believe) via dokuwiki's framework.  If a person were 
> only interested in visualization, they could use their favorite RSS news 
> reader, and only keep track of recipes related to visualization.  Or if 
> a person had a great deal of respect for a few authors, they could track 
> their contributions the same way.
> 
> In principle, a wiki may not be the best place to store "recipes" 
> either.  Because most wiki's like to have one article per topic, the 
> community is forced to establish a "best" article via community 
> editing.  At R-Cookbook.com, there can be more than one recipe for a 
> certain problem/issue, letting the community decide the preferred 
> solution via ratings/comments.  Sure, having more than one article can 
> be done with a wiki's, but it almost defeats the purpose--I'm a purist, 
> sorry.  ;)
> 
> More generally, recipes on R-Cookbook.com are free to go a different 
> direction as what has been currently established as tips on the wiki (I 
> know this can change, but I'm just saying...).  "Recipes" can be very 
> problem specific, related to many topics, or very specific to the 
> authors data, or whatever the case may be--not necessarily related to 
> one method of analysis or one function.  Where would something like that 
> go in your current linear organization of tips?  At R-Cookbook.com, I 
> would still appreciate and value the contribution because someone might 
> find it useful, and they could discover it via tags, the search engine, 
> a user feed, or the similar recommendation engine.  Personally, I just 
> don't see a place for that sort of entry in the wiki.
> 
> With all of that said, if there is anything at R-cookbook.com that you 
> believe would benefit the wiki more than perhaps a link to the recipe, 
> the content is freely available to the public, and it is in your rights 
> to put it there.
> 
> Again, the site is purely to support the community, and I really don't 
> believe it is in competition with what your wiki offers.  I'd be glad to 
> continue this discussion off-list and appreciate you bringing up the 
> point though, it's a good question, that I hope I've answered.
> 
> Jeff.
> 
> On Sep 28, 2007, at 4:11 AM, Philippe Grosjean wrote:
> 
>> Hello Jeff,
>>
>> Good initiative,... but why not to put this in the official R Wiki
>> (http://wiki.r-project.org)? There is a section named 'tips' dedicated
>> to such little recipes
>> (http://wiki.r-project.org/rwiki/doku.php?id=tips:tips). It should be
>> better to centralize all these little tips, don't you think so?
>>
>> Should you have difficulties to use the Wiki, just tell me, and I will
>> help...
>> Best,
>>
>> Philippe Grosjean
>>
>> ..............................................<?}))><........
>>   ) ) ) ) )
>> ( ( ( ( (    Prof. Philippe Grosjean
>>   ) ) ) ) )
>> ( ( ( ( (    Numerical Ecology of Aquatic Systems
>>   ) ) ) ) )   Mons-Hainaut University, Belgium
>> ( ( ( ( (
>> ..............................................................
>>
>> Jeff wrote:
>>> R Community,
>>>
>>> I've put together a website that I thought this mailing list might be
>>> interested in: http://www.r-cookbook.com
>>>
>>> It's a (free) community-driven content management system for R
>>> "recipes", or working examples.  Some of the features of the site are
>>> code highlighting, recipe ratings, recipe comments, personal "recipe
>>> boxes" to save your favorite recipes, community tagging, RSS feeds
>>> for each user and for each tag, and similar recipe recommendations.
>>>
>>> Although I imagine that many users will sort/search/find recipes by
>>> tags, I've implemented a linear organization for recipes as well:
>>> guides.  These will be compilations of "recipes", organized in a
>>> logical fashion as to promote understanding of the topic of that
>>> particular guide and introduced with user-contributed pages.  Over
>>> time, hopefully with the help of the community, more guides will be
>>> created and the ones I have will be filled-in to actually be useful.
>>> I have started several guides to give you an idea of the sort of
>>> thing I'm thinking: Introduction to R, Longitudinal Modeling in R,
>>> Exploratory Data Analysis in R, and more here, http://www.r-
>>> cookbook.com/guide
>>>
>>> A couple of features that will be worked on in the near future are
>>> (1) the design of the site and (2) working on a more interactive code
>>> display (right now, functions are highlighted and linked to the r-
>>> docs, but that's it).
>>>
>>> I hope some of you might find the site useful and perhaps even
>>> consider contributing your own recipes.  If you have any suggestions
>>> or feature requests, I'd be glad to hear them!
>>>
>>> Jeff.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
>


From ripley at stats.ox.ac.uk  Sat Sep 29 10:20:00 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 29 Sep 2007 09:20:00 +0100 (BST)
Subject: [R] Problems installing GammaTest
In-Reply-To: <000301c80266$b8f6c940$2ae45bc0$@de>
References: <000301c80266$b8f6c940$2ae45bc0$@de>
Message-ID: <Pine.LNX.4.64.0709290904430.21194@gannet.stats.ox.ac.uk>

On Sat, 29 Sep 2007, Martin Efferz wrote:

> how to install the GammaTest package under WindowsVista? Only source code
> available, no binaries.
>
> Have tried R CMD INSTALL. The error message is:
>
> ----------- Making package GammaTest --------------------
> adding build stamp to DESCRIPTION
> making DLL .
> gcc.exe: installation problem, cannot exec 'cc1': No such file or directory

Please do read the R-admin manual and see what it says about compilers and 
Vista.  You haven't told us your version of R (as the posting guide asked 
you to)!  Look at the R-patched version at

https://svn.r-project.org/R/branches/R-2-5-branch/doc/manual/R-admin.texi

(and search for 'Vista') for recent information for R 2.5.x, or use the 
version in R 2.6.0 RC if you are using that.

> Have installed MinGW and set the path properly.

But as 'cc1.exe' is not on the path that cannot be true.

> Can someone provide the windows binaries for that package?

They are not distributed for a very good reason, and it seems you have not 
bothered to look at the repository to see why:

http://cran.r-project.org/bin/windows/contrib/2.5/@ReadMe
http://cran.r-project.org/bin/windows/contrib/checkSummaryWin.html

You could make use of Uwe Ligges' autobuilder to make a binary for 
yourself: again see the R-admin manual for details.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From duarte at trugil.co.uk  Sat Sep 29 12:03:32 2007
From: duarte at trugil.co.uk (alejo duarte)
Date: Sat, 29 Sep 2007 12:03:32 +0200
Subject: [R] stiglijk
Message-ID: <000701c8027f$fe1154f0$e539345a@perso054a6ad89>

Hi To r-help

Emergency report. Check DMXC!
Price up 21% in 30 minutes!
5 day price: ~$0.50


From sratino at yahoo.com  Sat Sep 29 11:32:36 2007
From: sratino at yahoo.com (Stefo Ratino)
Date: Sat, 29 Sep 2007 02:32:36 -0700 (PDT)
Subject: [R] Data manipulation
Message-ID: <257503.20666.qm@web45512.mail.sp1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070929/918627e8/attachment.pl 

From joris.dewolf at cropdesign.com  Sat Sep 29 14:03:29 2007
From: joris.dewolf at cropdesign.com (joris.dewolf at cropdesign.com)
Date: Sat, 29 Sep 2007 14:03:29 +0200
Subject: [R] seq() question
In-Reply-To: <D86C9EFF6AA3734193923FFA1EE4308B0435FADE@nc-mail2.northland.edu>
Message-ID: <OF03F87E5B.AD02D148-ONC1257365.00419D5B-C1257365.00421884@basf-c-s.be>



Has something do with the precision. Check this:

all.equal(1.1, brks[4], tolerance = 0)
all.equal(1.2, brks[5], tolerance = 0)
all.equal(1.2, brks[5])









                                                                           
             "Derek Ogle"                                                  
             <DOgle at northland.                                             
             edu>                                                       To 
             Sent by:                  <R-help at r-project.org>              
             r-help-bounces at r-                                          cc 
             project.org                                                   
                                                                   Subject 
                                       [R] seq() question                  
             29/09/2007 04:58                                              
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           




Hello all,

I am attempting to use the seq() function to define breaks for the cut()
function but am finding performance that I do not understand.  The root of
my problem appears to be contained in the following simple example.

> brks <- seq(0.8,1.2,0.1)
> brks
[1] 0.8 0.9 1.0 1.1 1.2
> brks==1.2
[1] FALSE FALSE FALSE FALSE FALSE
> brks==1.1
[1] FALSE FALSE FALSE  TRUE FALSE

The last value in the sequence does not appear to be equal to its apparent
value (i.e., 1.2) whereas the fourth value in the sequence, for example,
does (e.g., 1.1).

Any help/suggestions with the concept or "trick" that I am missing here?
Thank you in advance.

p.s., I am using R 2.5.1 with ...

> Sys.info()
                      sysname                       release
                    "Windows"                      "NT 5.1"
                      version                      nodename
"(build 2600) Service Pack 2"                  "CSE229-001"
                      machine
                        "x86"

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Dimitris.Rizopoulos at med.kuleuven.be  Sat Sep 29 14:03:36 2007
From: Dimitris.Rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Sat, 29 Sep 2007 14:03:36 +0200
Subject: [R] Data manipulation
In-Reply-To: <257503.20666.qm@web45512.mail.sp1.yahoo.com>
References: <257503.20666.qm@web45512.mail.sp1.yahoo.com>
Message-ID: <20070929140336.s5u4ba3ygc3kw88w@webmail5.kuleuven.be>

use something like the following (untested)

files <- paste("C:/d", 1:3, ".txt", sep = "")
dats <- vector("list", 3)
for (i in 1:3) {
   dats[[i]] <- read.table(files[i], header = TRUE)
}
dats
do.call("rbind", dat)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
      http://www.student.kuleuven.be/~m0390867/dimitris.htm


Quoting Stefo Ratino <sratino at yahoo.com>:

> Hello,
>
> I am beginner in R and I would like to solve the following problem:
> Suppose that we have  three files to be red in R d1, d2, and d3
>
>> d1
>   id x1 x2
> 1  1  4  n
> 2  2  3  h
> 3  3  0  f
>> d2
>   id x1 x2
> 1  1  2  r
> 2  2  3  u
> 3  3  1  f
>> d3
>   id x1 x2
> 1  1  2  a
> 2  2  1  w
>
> Is there any library or function that one can read this datasets like
> for(i in 1:3)
>  d[i] <- read.table(file=d[j].txt, header=T)
>
> and is it possible to delete the header for each file and to have   
> them in one data frame like
>
>> d
> 1   1  4  n
> 2   2  3  h
> 3   3  0  f
> 4   1  2  r
> 5   2  3  u
> 6   3  1  f
> 7  1  2  a
> 8  2  1  w
> 9  3  1  f
>
> I really appreciate your help!
> Stefo
>
>
>
>
>
>
> ---------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>



Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From unwin at math.uni-augsburg.de  Sat Sep 29 14:35:18 2007
From: unwin at math.uni-augsburg.de (Antony Unwin)
Date: Sat, 29 Sep 2007 14:35:18 +0200
Subject: [R] sprucing up the R homepage
In-Reply-To: <46FBC81D.9010304@biostat.ku.dk>
References: <71257D09F114DA4A8E134DEAC70F25D309A58F33@groamrexm03.amer.pfizer.com>
	<46FBC81D.9010304@biostat.ku.dk>
Message-ID: <EFBAB441-8F11-40D1-ACB1-CA06C1A0C934@math.uni-augsburg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070929/0035bd8b/attachment.pl 

From p.dalgaard at biostat.ku.dk  Sat Sep 29 14:40:53 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 29 Sep 2007 14:40:53 +0200
Subject: [R] Data manipulation
In-Reply-To: <20070929140336.s5u4ba3ygc3kw88w@webmail5.kuleuven.be>
References: <257503.20666.qm@web45512.mail.sp1.yahoo.com>
	<20070929140336.s5u4ba3ygc3kw88w@webmail5.kuleuven.be>
Message-ID: <46FE47D5.6070209@biostat.ku.dk>

Dimitris Rizopoulos wrote:
> use something like the following (untested)
>
> files <- paste("C:/d", 1:3, ".txt", sep = "")
> dats <- vector("list", 3)
> for (i in 1:3) {
>    dats[[i]] <- read.table(files[i], header = TRUE)
> }
> dats
> do.call("rbind", dat)
>
>   
..or even

files <- paste("C:/d", 1:3, ".txt", sep = "")
do.call("rbind",lapply(files, read.table, header=TRUE))


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From f.harrell at vanderbilt.edu  Sat Sep 29 14:50:27 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sat, 29 Sep 2007 07:50:27 -0500
Subject: [R] Importing only one function from a package
In-Reply-To: <3f547caa0709281636x351177dfx43dd2b8e4f798b29@mail.gmail.com>
References: <C83C5E3DEEE97E498B74729A33F6EAEC0562F703@DJFPOST01.djf.agrsci.dk>
	<3f547caa0709281636x351177dfx43dd2b8e4f798b29@mail.gmail.com>
Message-ID: <46FE4A13.8070400@vanderbilt.edu>

Matthew Keller wrote:
> Hi Soren,
> 
> What I do in cases like this is just copy the function and place it
> into my script at the top (or write it into its own source file and
> call it from script). Best,
> 
> Matt

I'm not a fan of that because you won't get updates when we update the 
packages.

Frank

> 
> On 9/28/07, S?ren H?jsgaard <Soren.Hojsgaard at agrsci.dk> wrote:
>> Dear List
>>
>> In a package I want to import the mApply function from the Hmisc package, and I would like to import only that function.
>>
>> 1) If I write "Depends: Hmisc" in the DESCRIPTION file I get the whole Hmisc package, so that is not the way to go ahead.
>>
>> 2) According to "Writing R extensions", sec 1.6.1 "Specifying imports and exports" I can (as I read it) simply type Hmisc:::mApply(....) in my code. That works, but gives a warning in the check:
>>
>> * checking for unstated dependencies in R code ... WARNING
>> '::' or ':::' imports not declared from:
>>   Hmisc
>>
>> 3) According to the same section I can (again as I read it) write in the NAMESPACE file
>> importFrom(Hmisc,mApply)
>>
>> Then I get:
>>
>> * checking package dependencies ... ERROR
>> Namespace dependencies not required:
>>   Hmisc
>>
>> That message goes away if I write  "Depends: Hmisc" in DESCRIPTION, but then we are back to 1) where I started where the whole Hmisc package is loaded.
>>
>> Obviously I have missed a point or two somewhere. Can anyone enlighten me?
>>
>> I use R 2.5.1 on windows XP.
>>
>> Regards
>> S?ren

Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From lgdiazm at unal.edu.co  Sat Sep 29 14:57:55 2007
From: lgdiazm at unal.edu.co (Luis Guillermo Diaz Monroy)
Date: Sat, 29 Sep 2007 07:57:55 -0500
Subject: [R] variables selection in Aalen and Cox model
Message-ID: <fd13e36e3fa5.46fe0583@unal.edu.co>


   Dear members of R community,

   I  want  to know about the R procedures (or routines) to carry out the
   selection of covariates in an Aalen or
   cox model, respectively.

   Thanks a lot
   Luis Guillermo D??az Monroy
   Profesor Asociado Departamento de Estad??stica
   Universidad Nacional de Colombia

From p.dalgaard at biostat.ku.dk  Sat Sep 29 15:08:16 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 29 Sep 2007 15:08:16 +0200
Subject: [R] sprucing up the R homepage
In-Reply-To: <EFBAB441-8F11-40D1-ACB1-CA06C1A0C934@math.uni-augsburg.de>
References: <71257D09F114DA4A8E134DEAC70F25D309A58F33@groamrexm03.amer.pfizer.com>
	<46FBC81D.9010304@biostat.ku.dk>
	<EFBAB441-8F11-40D1-ACB1-CA06C1A0C934@math.uni-augsburg.de>
Message-ID: <46FE4E40.1050508@biostat.ku.dk>

Antony Unwin wrote:
>
> On 27 Sep 2007, at 5:11 pm, Peter Dalgaard wrote:
>
>> There was a competition in 2004, and this is the display that won.
>
> Thanks for clearing that up.
>
>> It was deliberately designed as a "show-off" for the home page, and as
>> such, I don't think it can be the same sort of graphic that you'd use
>> for real analysis. It does have the nice feature of displaying results
>> of simple, yet non-trivial statistical analyses (PCA, clustering)
>> without requiring a lengthy explanation.
>
> Do you really think of PCA and clustering as "statistical" analyses? 
> And anyway, surely it's a factor analysis not PCA?  Perhaps lengthy 
> explanations are needed after all.  I would need an explanation for 
> the curious plots lower right.  It's probably due to my sheltered 
> upbringing, as I was always taught to keep factor analyses at a 
> respectable distance.
>
> I liked Hadley's comment.  It struck me as fortun(at)e.
>
Hmm, well, ... Actually it _is_ PCA (it says so: princomp), but it quite 
possibly ought to have been a factor analysis. The former is often used 
as a substitute for the latter (after rescaling) -- SPSS does this, 
causing a good deal of confusion to users expecting factanal () to have 
an option for PCA -- but that's not exactly a good reason to perpetuate it.

Whether it counts as statistical analysis? I tend to think that it does, 
although it isn't among the tools that I reach for most frequently.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From cskiadas at gmail.com  Sat Sep 29 15:49:13 2007
From: cskiadas at gmail.com (Charilaos Skiadas)
Date: Sat, 29 Sep 2007 09:49:13 -0400
Subject: [R] [Help] Error when using nls
In-Reply-To: <947CDD25-F02A-4F69-A8BE-57098E1F2329@gmail.com>
References: <947CDD25-F02A-4F69-A8BE-57098E1F2329@gmail.com>
Message-ID: <844BF683-37F5-451D-B14C-38D2AFB9CE9B@gmail.com>

On Sep 29, 2007, at 12:00 AM, Niner wrote:

> Hi,
>
>      I am a student of Earthquake Engineering, and am new to R.
> Currently I try to run nonlinear regression analysis by R. My data
> has three variables: X, Y, and Z. Z is a function of (X, Y). My R
> script is as below.

In general it is recommended that you provide reproducible code,  
typically using one of the built in data sets instead of a data set  
of your own that we have no access to.

> # call nls funciton
> out <- nls(Z~X/(1/(a+b*ev+c*(Y^2))+X/(d+e*exp(f*Y)))-g, data1,
> selfStart, trace=T)
>
>
> In total there are 59 sets of (X,Y,Z). When I run this script, I got
> the error message as:
>
> parameters without starting value in 'data': a, b, d, e, f, g
>
>
> I don't know what this means. Besides, I use "selfStart" option, such
> that the nls is supposed to run by finding the initial values of
> (a,b,c,d,e,f,g) itself. Why the nls asks me to give the starting  
> values?

"selfStart" is not an "option", it is a function which you would use  
to construct the self-starting object. Look at ?selfStart for an  
example on how to use it.
To the best of my understanding, you need to either:
1) provide starting values (what I would recommend, if you have a  
sense for the range), or
2) provide R with a mechanism for finding the starting values (via  
constructing a selfStart object, see ?selfStart), or
3) ask R to make very poor guesses, by leaving the start argument  
empty [  out <- nls(Z~X/(1/(a+b*ev+c*(Y^2))+X/(d+e*exp(f*Y)))-g,  
data1, trace=T)   ]
which has a high chance of choking out on you. In an example I just  
tried, R set all the parameter values to 1.

> What should I do next? Does anyone can explain the meaning of the
> error message?
> Any comment is appreciated. Thanks a lot.
>
>
> Regards,
> Niner
> ----------------------------------------------------
> Niner, Seattle
> ninerdummy at gmail.com
>

Haris Skiadas
Department of Mathematics and Computer Science
Hanover College


From ligges at statistik.uni-dortmund.de  Sat Sep 29 16:15:13 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 29 Sep 2007 16:15:13 +0200
Subject: [R] Problem compiling R - "use of NULL environment is defunct"
In-Reply-To: <07F7EB60-85C7-4D1E-8EE3-5926229C6639@pobox.com>
References: <07F7EB60-85C7-4D1E-8EE3-5926229C6639@pobox.com>
Message-ID: <46FE5DF1.3050508@statistik.uni-dortmund.de>

Have you set a library path pointing to old packages of a former R version?
BTW: Additionally, you can try out R-2.6.0 release candidate these days 
and help during evaluation!

Uwe Ligges


Saptarshi Guha wrote:
> Hello,
> I downloaded R-2.5.1 and configured it on a AMD x86-74 running  
> Redhat. During compilation i get this error
> 
> configure --prefix=$HOME/mine
> make
> 
> mkdir -p -- ../../../../library/methods/libs
> make[5]: Leaving directory `/home/sguha/tmp/R-2.5.1/src/library/ 
> methods/src'
> make[4]: Leaving directory `/home/sguha/tmp/R-2.5.1/src/library/ 
> methods/src'
> make[4]: Entering directory `/home/sguha/tmp/R-2.5.1/src/library/ 
> methods'
> dumping R code in package 'methods'
> Error in `parent.env<-`(`*tmp*`, value = NULL) :
>          use of NULL environment is defunct
> Execution halted
> make[4]: *** [../../../library/methods/R/methods.rdb] Error 1
> make[4]: Leaving directory `/home/sguha/tmp/R-2.5.1/src/library/methods'
> make[3]: *** [all] Error 2
> make[3]: Leaving directory `/home/sguha/tmp/R-2.5.1/src/library/methods'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory `/home/sguha/tmp/R-2.5.1/src/library'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/home/sguha/tmp/R-2.5.1/src'
> make: *** [R] Error 1
> 
> 
> Could someone point out what I'm supposed to fix?
> Thank you for your time
> Saptarshi
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From friendly at yorku.ca  Sat Sep 29 16:41:21 2007
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 29 Sep 2007 10:41:21 -0400
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <f8e6ff050709281013i7209b684r63aa0d8fcd69d4ef@mail.gmail.com>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>	<6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>	<9D14E5C4-C061-423D-A94A-5AAAAF24A4BF@gmail.com>	<46FD1663.5070002@vanderbilt.edu>	<DEAF35A7-190B-4F78-B7AD-3038A079CE9A@gmail.com>	<46FD2B0A.1000205@vanderbilt.edu>
	<f8e6ff050709281013i7209b684r63aa0d8fcd69d4ef@mail.gmail.com>
Message-ID: <46FE6411.6050800@yorku.ca>


hadley wickham wrote:
>> 
> I was interested to see that you have code for drawing scatterplots
> with multiple y-axes.  As far as I know the only legitimate use for a
> double-axis plot is to confuse or mislead the reader (and this is not
> a very ethical use case).  Perhaps you have a counter-example?
> 
> Hadley
> 
While it is true that the double-Y-axis graph is generally considered 
sinful, it can be used effectively to show the relation of two time 
series in ways that other graphs can't do as well.

For one striking example,
a political, presentation graphic, see:
http://www.math.yorku.ca/SCS/Gallery/images/commonsenserevolution6.pdf
described on my Graphical Excellence page,
http://www.math.yorku.ca/SCS/Gallery/excellence.html
I found it easy to excuse the sin by the 'wow effect' produced by the
graph.

Playfair also used double-Y-axis graphs for similar purposes; and, 
sinner that he was, graphic and otherwise, he was not adverse to 
jiggling the scales on one or the other axes to make his message
more apparent.  See:

@ARTICLE{FriendlyDenis:05:scat,
   author = {M. Friendly and D. Denis},
   title = {The early origins and development of the scatterplot},
   journal = {Journal of the History of the Behavioral Sciences},
   year = {2005},
   volume = {41},
   pages = {103--130},
   number = {2},
   url = {http://www.math.yorku.ca/SCS/Papers/friendly-scat.pdf}
}



-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA


From friendly at yorku.ca  Sat Sep 29 16:41:21 2007
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 29 Sep 2007 10:41:21 -0400
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <f8e6ff050709281013i7209b684r63aa0d8fcd69d4ef@mail.gmail.com>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>	<6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>	<9D14E5C4-C061-423D-A94A-5AAAAF24A4BF@gmail.com>	<46FD1663.5070002@vanderbilt.edu>	<DEAF35A7-190B-4F78-B7AD-3038A079CE9A@gmail.com>	<46FD2B0A.1000205@vanderbilt.edu>
	<f8e6ff050709281013i7209b684r63aa0d8fcd69d4ef@mail.gmail.com>
Message-ID: <46FE6411.6050800@yorku.ca>


hadley wickham wrote:
>> 
> I was interested to see that you have code for drawing scatterplots
> with multiple y-axes.  As far as I know the only legitimate use for a
> double-axis plot is to confuse or mislead the reader (and this is not
> a very ethical use case).  Perhaps you have a counter-example?
> 
> Hadley
> 
While it is true that the double-Y-axis graph is generally considered 
sinful, it can be used effectively to show the relation of two time 
series in ways that other graphs can't do as well.

For one striking example,
a political, presentation graphic, see:
http://www.math.yorku.ca/SCS/Gallery/images/commonsenserevolution6.pdf
described on my Graphical Excellence page,
http://www.math.yorku.ca/SCS/Gallery/excellence.html
I found it easy to excuse the sin by the 'wow effect' produced by the
graph.

Playfair also used double-Y-axis graphs for similar purposes; and, 
sinner that he was, graphic and otherwise, he was not adverse to 
jiggling the scales on one or the other axes to make his message
more apparent.  See:

@ARTICLE{FriendlyDenis:05:scat,
   author = {M. Friendly and D. Denis},
   title = {The early origins and development of the scatterplot},
   journal = {Journal of the History of the Behavioral Sciences},
   year = {2005},
   volume = {41},
   pages = {103--130},
   number = {2},
   url = {http://www.math.yorku.ca/SCS/Papers/friendly-scat.pdf}
}



-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA


From h.wickham at gmail.com  Sat Sep 29 17:08:05 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sat, 29 Sep 2007 10:08:05 -0500
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <46FE6411.6050800@yorku.ca>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>
	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>
	<6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>
	<9D14E5C4-C061-423D-A94A-5AAAAF24A4BF@gmail.com>
	<46FD1663.5070002@vanderbilt.edu>
	<DEAF35A7-190B-4F78-B7AD-3038A079CE9A@gmail.com>
	<46FD2B0A.1000205@vanderbilt.edu>
	<f8e6ff050709281013i7209b684r63aa0d8fcd69d4ef@mail.gmail.com>
	<46FE6411.6050800@yorku.ca>
Message-ID: <f8e6ff050709290808t6ad5aa67p3dd7645beb927d53@mail.gmail.com>

On 9/29/07, Michael Friendly <friendly at yorku.ca> wrote:
>
> hadley wickham wrote:
> >>
> > I was interested to see that you have code for drawing scatterplots
> > with multiple y-axes.  As far as I know the only legitimate use for a
> > double-axis plot is to confuse or mislead the reader (and this is not
> > a very ethical use case).  Perhaps you have a counter-example?
> >
> > Hadley
> >
> While it is true that the double-Y-axis graph is generally considered
> sinful, it can be used effectively to show the relation of two time
> series in ways that other graphs can't do as well.
>
> For one striking example,
> a political, presentation graphic, see:
> http://www.math.yorku.ca/SCS/Gallery/images/commonsenserevolution6.pdf
> described on my Graphical Excellence page,
> http://www.math.yorku.ca/SCS/Gallery/excellence.html
> I found it easy to excuse the sin by the 'wow effect' produced by the
> graph.

While I agree that the double y-axis plot can be used to compare two
time series, I'm not sure whether or not it actually is effective.
The appearance of the display is so critically dependent on the
relative scales of the axes, that it is easy to draw the wrong
conclusion.  Why not use a scatterplot or path plot (i.e. connect
subsequent observations with edges) if you want to understand the
relationship between two variables?

>From a aesthetic perspective, the common sense revolution graphic is
clearly a success, being both striking and attractive, but I think it
fails statistically, by making it hard to accurately assess the
relationship between the two variables.

Hadley
-- 
http://had.co.nz/


From h.wickham at gmail.com  Sat Sep 29 17:41:07 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sat, 29 Sep 2007 10:41:07 -0500
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <f8e6ff050709290808t6ad5aa67p3dd7645beb927d53@mail.gmail.com>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>
	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>
	<6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>
	<9D14E5C4-C061-423D-A94A-5AAAAF24A4BF@gmail.com>
	<46FD1663.5070002@vanderbilt.edu>
	<DEAF35A7-190B-4F78-B7AD-3038A079CE9A@gmail.com>
	<46FD2B0A.1000205@vanderbilt.edu>
	<f8e6ff050709281013i7209b684r63aa0d8fcd69d4ef@mail.gmail.com>
	<46FE6411.6050800@yorku.ca>
	<f8e6ff050709290808t6ad5aa67p3dd7645beb927d53@mail.gmail.com>
Message-ID: <f8e6ff050709290841y73703bcfn15accb9e146c0793@mail.gmail.com>

On 9/29/07, hadley wickham <h.wickham at gmail.com> wrote:
> On 9/29/07, Michael Friendly <friendly at yorku.ca> wrote:
> >
> > hadley wickham wrote:
> > >>
> > > I was interested to see that you have code for drawing scatterplots
> > > with multiple y-axes.  As far as I know the only legitimate use for a
> > > double-axis plot is to confuse or mislead the reader (and this is not
> > > a very ethical use case).  Perhaps you have a counter-example?
> > >
> > > Hadley
> > >
> > While it is true that the double-Y-axis graph is generally considered
> > sinful, it can be used effectively to show the relation of two time
> > series in ways that other graphs can't do as well.
> >
> > For one striking example,
> > a political, presentation graphic, see:
> > http://www.math.yorku.ca/SCS/Gallery/images/commonsenserevolution6.pdf
> > described on my Graphical Excellence page,
> > http://www.math.yorku.ca/SCS/Gallery/excellence.html
> > I found it easy to excuse the sin by the 'wow effect' produced by the
> > graph.
>
> While I agree that the double y-axis plot can be used to compare two
> time series, I'm not sure whether or not it actually is effective.
> The appearance of the display is so critically dependent on the
> relative scales of the axes, that it is easy to draw the wrong
> conclusion.  Why not use a scatterplot or path plot (i.e. connect
> subsequent observations with edges) if you want to understand the
> relationship between two variables?

To compare the scatterplot vs double axis plot, I used graphclick
(http://www.arizona-software.ch/graphclick/) to digitise the graphic,
to get the following dataset:

csr <- structure(list(year = c(1985, 1986, 1987, 1988, 1989, 1990, 1991,
1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002,
2003, 2004, 2005, 2006), deaths = c(1, 1, 7, 5, 12, 3, 7, 5,
4, 6, 8, 19, 26, 20, 42, 41, 45, 41, 27, 52, 67, 50), income = c(NA,
8572, NA, NA, 9264, 10071, 10338, 10687, 10666, 10666, 9907,
8141, 8059, 7997, 7874, 7648, 7484, 7319, 7135, 7135, 7011, NA
)), .Names = c("year", "deaths", "income"), row.names = c(NA,
-22L), class = "data.frame")

and produce the attached graphic (I'm not sure if the attachment will
make it to r-help, but the code should be reproducible on any system):

library(ggplot2)
ggplot(csr, aes(x=deaths, y=income)) +
geom_path(colour="grey80") + geom_point()

# or without connecting lines
ggplot(csr, aes(x=deaths, y=income)) + geom_point()

I find this graph much easier to interpret - one can see outliers, the
suggestion of non-linearity etc.  It would also be easy to add the
political party with colour or shape.

I'm not sure if it's a good idea to include the line or not - the
gestalt principle of connectedness makes it very difficult to
interpret the points as separate objects even when the line connecting
them is so faint.

Hadley

-- 
http://had.co.nz/
-------------- next part --------------
A non-text attachment was scrubbed...
Name: csr-scatterplot.pdf
Type: application/pdf
Size: 8458 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20070929/475fdd8f/attachment.pdf 

From jo.irisson at gmail.com  Sat Sep 29 18:48:20 2007
From: jo.irisson at gmail.com (jiho)
Date: Sat, 29 Sep 2007 18:48:20 +0200
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <46FD2B0A.1000205@vanderbilt.edu>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>	<6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>
	<9D14E5C4-C061-423D-A94A-5AAAAF24A4BF@gmail.com>
	<46FD1663.5070002@vanderbilt.edu>
	<DEAF35A7-190B-4F78-B7AD-3038A079CE9A@gmail.com>
	<46FD2B0A.1000205@vanderbilt.edu>
Message-ID: <1C0225A0-3965-47C1-9B6C-78B5DFDB47D0@gmail.com>

On 2007-September-28  , at 18:25 , Frank E Harrell Jr wrote:
> jiho wrote:
>> On 2007-September-28  , at 16:57 , Frank E Harrell Jr wrote:
>>> jiho wrote:
>>>> On 2007-September-28  , at 15:18 , Paul Smith wrote:
>>>>> On 9/28/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>>>>>>> I know how to export graphics as pdf files and then how to  
>>>>>>> include
>>>>>>> them in LaTeX documents. However, I do not know how to do in   
>>>>>>> order to
>>>>>>> have the text of the graphics written with the font selected  
>>>>>>> for the
>>>>>>> LaTeX document. Is that possible?
>>>>>> [...]
>>>> If you don't mind an extra step between R and LaTeX, you could  
>>>> use  Inkscape to modify your graphics:
>>>> [...]
>>>> I personally use Inkscape on all my R graphics because I find  
>>>> it  easier and quicker to get decent graphics and R and refine  
>>>> their look  in Inkscape than to get them perfect in R in one  
>>>> shot ( though with  ggplot2 things are improving on R's side).
>>> As this works against principles of reproducible research, I  
>>> wouldn't recommend it.
>> Do you consider that changing the font size of the graphic would  
>> be altering the research result? Or laying out a 2d contour and a  
>> 3d plot
>
> Not per se, but accidents happen when editing graphics.  More  
> importantly it creates more work.  Datasets get updated/corrected  
> and graphics need to be reproduced.
>
>> in parallel, or changing the line color/pattern...? My  
>> modifications are usually of this kind. Of course those things are  
>> doable with R but they are usually immensely easier in a graphics  
>> program (where the color palettes are predefined, the dash  
>> patterns are more diverse etc.).
>> For example, I often find myself using the same plot in an  
>> article, a presentation, and a poster, usually with different  
>> color palettes and font requirements. I just open the pdf, change  
>> the colors, font and font size to match the design of the article/ 
>> presentation/poster, realign the labels a bit and re-save it. I  
>> don't think that I am doing any harm to my result or present any  
>> false information to the readers, I just make the graphics easier  
>> on their eyes.
>
> A great application for a wrapper graphics function with an  
> argument for presentation mode.

I could do that indeed but it would require changing the margins,  
device size, fonts, colors etc. all by hand in R. I am not saying  
this is impossible (well in some things are: R may not have access to  
all the fonts in my system, R won't produce print-ready CMYK pdfs  
etc.) but it is just much more trouble than producing one "OK"  
graphic with R and handling the finer presentational details in a  
program more suited for these maters. Not to mention that it would  
also suppose that I know all the presentation requirements in  
advance, when writing the plotting function, which is usually not the  
case. If I have to redo the plot months later I may as well rewrite a  
new plot script based on the old one and go with that.
Once again I am not saying this is impossible, I am just skeptical  
about the balance between the cost of producing pixel perfect  
graphics from code and the reproducibility benefit associated,  
particularly in R. MATLAB's or Scilab plotting models are more suited  
in this aspect: the plot is represented as an object, that can be  
saved, with properties that you can change _after_ its creation. So  
it is easy to come back, even months after the analysis, and change  
the colors, the margins etc. of the plot and to produce a pdf again.  
The grids packages goes this way fortunately!

>> But maybe I am a bit too much of a purist on these maters. I just  
>> find that, much too often, research results that represent months  
>> of work are presented as narrow, black and white (possibly even  
>> pixallated!) captures of article graphics which don't do justice  
>> to the quality of the work behind them. I don't think there is any  
>> harm in making (good) science look a bit "sexier", do you?
>
> Yes there is harm.  But to make bold lines, easy to read titles is  
> fine.  See the spar function in http://biostat.mc.vanderbilt.edu/ 
> SgraphicsHints for a starter.  Also see the setps, ps.slide, and  
> setpdf functions in the Hmisc package.

Thanks for the pointers, these functions look useful indeed.

I try to do the more I can in R [1], to reduce Inkscape to the fine- 
tuning (and not risk more error than needed when editing the  
graphics) but eventually, there's always something that does not look  
quite right in R's output, or not consistent between two plots etc.  
and I _have_ to change it in Inkscape (but that is probably the  
design maniac living inside me speaking at this point ;) ).

[1] BTW, for those interested, I extracted the colors of most LaTeX  
Beamer themes:
	http://en.wikipedia.org/wiki/Beamer_(LaTeX)
and made a Gimp/Inkscape palette with them. I also associated the RGB  
codes with color names in an R script, as well as defined color  
schemes and a few color related functions. You can get everything here:
	http://jo.irisson.free.fr/?p=35

JiHO
---
http://jo.irisson.free.fr/


From friendly at yorku.ca  Sat Sep 29 19:41:40 2007
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 29 Sep 2007 13:41:40 -0400
Subject: [R] Graphics and LaTeX documents with the same font
 [double-Y-axis graphs]
In-Reply-To: <f8e6ff050709290841y73703bcfn15accb9e146c0793@mail.gmail.com>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>	
	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>	
	<6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>	
	<9D14E5C4-C061-423D-A94A-5AAAAF24A4BF@gmail.com>	
	<46FD1663.5070002@vanderbilt.edu>	
	<DEAF35A7-190B-4F78-B7AD-3038A079CE9A@gmail.com>	
	<46FD2B0A.1000205@vanderbilt.edu>	
	<f8e6ff050709281013i7209b684r63aa0d8fcd69d4ef@mail.gmail.com>	
	<46FE6411.6050800@yorku.ca>	
	<f8e6ff050709290808t6ad5aa67p3dd7645beb927d53@mail.gmail.com>
	<f8e6ff050709290841y73703bcfn15accb9e146c0793@mail.gmail.com>
Message-ID: <46FE8E54.2010203@yorku.ca>


hadley wickham wrote:
> On 9/29/07, hadley wickham <h.wickham at gmail.com> wrote:
>> On 9/29/07, Michael Friendly <friendly at yorku.ca> wrote:
>>> hadley wickham wrote:
>>>> I was interested to see that you have code for drawing scatterplots
>>>> with multiple y-axes.  As far as I know the only legitimate use for a
>>>> double-axis plot is to confuse or mislead the reader (and this is not
>>>> a very ethical use case).  Perhaps you have a counter-example?
>>>>
>>>> Hadley
>>>>
>>> While it is true that the double-Y-axis graph is generally considered
>>> sinful, it can be used effectively to show the relation of two time
>>> series in ways that other graphs can't do as well.
>>>
>>> For one striking example,
>>> a political, presentation graphic, see:
>>> http://www.math.yorku.ca/SCS/Gallery/images/commonsenserevolution6.pdf
>>> described on my Graphical Excellence page,
>>> http://www.math.yorku.ca/SCS/Gallery/excellence.html
>>> I found it easy to excuse the sin by the 'wow effect' produced by the
>>> graph.
>> While I agree that the double y-axis plot can be used to compare two
>> time series, I'm not sure whether or not it actually is effective.
>> The appearance of the display is so critically dependent on the
>> relative scales of the axes, that it is easy to draw the wrong
>> conclusion.  Why not use a scatterplot or path plot (i.e. connect
>> subsequent observations with edges) if you want to understand the
>> relationship between two variables?
> 
> To compare the scatterplot vs double axis plot, I used graphclick
> (http://www.arizona-software.ch/graphclick/) to digitise the graphic,
> to get the following dataset:
> 
> csr <- structure(list(year = c(1985, 1986, 1987, 1988, 1989, 1990, 1991,
> 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002,
> 2003, 2004, 2005, 2006), deaths = c(1, 1, 7, 5, 12, 3, 7, 5,
> 4, 6, 8, 19, 26, 20, 42, 41, 45, 41, 27, 52, 67, 50), income = c(NA,
> 8572, NA, NA, 9264, 10071, 10338, 10687, 10666, 10666, 9907,
> 8141, 8059, 7997, 7874, 7648, 7484, 7319, 7135, 7135, 7011, NA
> )), .Names = c("year", "deaths", "income"), row.names = c(NA,
> -22L), class = "data.frame")
> 
> and produce the attached graphic (I'm not sure if the attachment will
> make it to r-help, but the code should be reproducible on any system):
> 
> library(ggplot2)
> ggplot(csr, aes(x=deaths, y=income)) +
> geom_path(colour="grey80") + geom_point()
> 
> # or without connecting lines
> ggplot(csr, aes(x=deaths, y=income)) + geom_point()
> 
> I find this graph much easier to interpret - one can see outliers, the
> suggestion of non-linearity etc.  It would also be easy to add the
> political party with colour or shape.
> 
> I'm not sure if it's a good idea to include the line or not - the
> gestalt principle of connectedness makes it very difficult to
> interpret the points as separate objects even when the line connecting
> them is so faint.
> 
> Hadley
> 

Thanks for trying this, Hadley, because the comparison
is instructive in terms of the difference between the
communication goals of analysis and presentation graphs.

Actually, one should regard income as the independent variable,
deaths as response, so what you want is

 > ggplot(csr, aes(y=deaths, x=income)) +
+ geom_path(colour="grey80") + geom_point()
 >
but, instead of/in addition to geom_path, a bolder loess smooth
would show the trend better.

This does, indeed show the inverse, and non-linear relation
between welfare income and deaths more directly, a few outliers.
Good for an analysis graph, but it fails the Interocular Traumatic
Test for a presentation graph-- the message should hit you between
the eyes.
Even
with use of color/shape to represent the party in power,
the stark message of the original is lost: When the Mike
Harris conservatives came to power in Ontario in June 1995, they slashed
welfare payments, and the number deaths of homeless people
increased dramatically. This trend continued under the McGuinty 
liberals, elected in Oct 2003.  It's particularly poignant that
bars for deaths are made from the names of the homeless who died
(and sad to see the number of John/Jane Doe among them).

To explore this further, I added a column for party to the
csr dataframe, but the transitions between parties occurred
in different months, and one would need a separate datafram
to represent that precisely.

    year deaths income        party
1  1985      1     NA      Liberal
2  1986      1   8572      Liberal
3  1987      7     NA      Liberal
4  1988      5     NA      Liberal
5  1989     12   9264      Liberal
6  1990      3  10071          NDP
7  1991      7  10338          NDP
8  1992      5  10687          NDP
9  1993      4  10666          NDP
10 1994      6  10666          NDP
11 1995      8   9907 Conservative
12 1996     19   8141 Conservative
13 1997     26   8059 Conservative
14 1998     20   7997 Conservative
15 1999     42   7874 Conservative
16 2000     41   7648 Conservative
17 2001     45   7484 Conservative
18 2002     41   7319 Conservative
19 2003     27   7135      Liberal
20 2004     52   7135      Liberal
21 2005     67   7011      Liberal
22 2006     50     NA      Liberal
 >

-Michael

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA


From david.merritt at bris.ac.uk  Sat Sep 29 20:08:55 2007
From: david.merritt at bris.ac.uk (DavidM.UK)
Date: Sat, 29 Sep 2007 11:08:55 -0700 (PDT)
Subject: [R] sprucing up the R homepage
In-Reply-To: <20070926025320.GA7975@web15.webfaction.com>
References: <20070926025320.GA7975@web15.webfaction.com>
Message-ID: <12958155.post@talk.nabble.com>


Personally I think the homepage needs a much better image not a "nice"
version of what is currently displayed.

Time Series is completely missing at the moment. Including something from
the fSeries .garchFit() routine would be a great to see (well done to the
RMetrics team on making it look good). 

David Merritt
University of Bristol, UK
Dept of Maths, Stats Group,
Postgraduate Student




Finny Kuruvilla-3 wrote:
> 
> I've been a R-user for quite some time.  The graphic on the home page
> looks a bit in need of polish so I applied some antialiased
> transformations that Peter Dalgaard has previously posted to R-help
> for improving graphic quality.  I had to change the margins a bit, but
> here is what it looks like:
> 
> http://www.broad.mit.edu/~finnyk/Rhome.jpg
> 
> Personally, I think it looks much better.  Because people so often
> "judge a book by its cover" (subconsciously or consciously), I'm
> wondering if anyone thinks this is worthy of replacing the current
> version?  I want R to maximize R's appeal and albeit a small
> improvement, hopefully this change will help a bit!
> 
> Regards,
> Finny Kuruvilla
> 
> -- 
> Finny Kuruvilla, MD, PhD
> Department of Molecular Biology, Massachusetts General Hospital
> Broad Institute of Harvard and MIT
> Homepage: http://www.anchorcross.org/people/kuruvilla/
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/sprucing-up-the-R-homepage-tf4519736.html#a12958155
Sent from the R help mailing list archive at Nabble.com.


From david.merritt at bris.ac.uk  Sat Sep 29 20:14:20 2007
From: david.merritt at bris.ac.uk (DavidM.UK)
Date: Sat, 29 Sep 2007 11:14:20 -0700 (PDT)
Subject: [R] New R website: R-Cookbook.com
In-Reply-To: <40992922-C9FB-4DBD-9633-140D2796523F@r-cookbook.com>
References: <40992922-C9FB-4DBD-9633-140D2796523F@r-cookbook.com>
Message-ID: <12958215.post@talk.nabble.com>


Hi,

That looks great, but maybe you should have a field "R Version Used" too. Of
course lots of code in specific versions of R fail when applied in
alternative versions.

Best,

David
U Bristol, UK
PG Student 



Jeff-136 wrote:
> 
> R Community,
> 
> I've put together a website that I thought this mailing list might be  
> interested in: http://www.r-cookbook.com
> 
> It's a (free) community-driven content management system for R  
> "recipes", or working examples.  Some of the features of the site are  
> code highlighting, recipe ratings, recipe comments, personal "recipe  
> boxes" to save your favorite recipes, community tagging, RSS feeds  
> for each user and for each tag, and similar recipe recommendations.
> 
> Although I imagine that many users will sort/search/find recipes by  
> tags, I've implemented a linear organization for recipes as well:  
> guides.  These will be compilations of "recipes", organized in a  
> logical fashion as to promote understanding of the topic of that  
> particular guide and introduced with user-contributed pages.  Over  
> time, hopefully with the help of the community, more guides will be  
> created and the ones I have will be filled-in to actually be useful.   
> I have started several guides to give you an idea of the sort of  
> thing I'm thinking: Introduction to R, Longitudinal Modeling in R,  
> Exploratory Data Analysis in R, and more here, http://www.r- 
> cookbook.com/guide
> 
> A couple of features that will be worked on in the near future are  
> (1) the design of the site and (2) working on a more interactive code  
> display (right now, functions are highlighted and linked to the r- 
> docs, but that's it).
> 
> I hope some of you might find the site useful and perhaps even  
> consider contributing your own recipes.  If you have any suggestions  
> or feature requests, I'd be glad to hear them!
> 
> Jeff.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
View this message in context: http://www.nabble.com/New-R-website%3A-R-Cookbook.com-tf4531381.html#a12958215
Sent from the R help mailing list archive at Nabble.com.


From f.harrell at vanderbilt.edu  Sat Sep 29 20:39:58 2007
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sat, 29 Sep 2007 13:39:58 -0500
Subject: [R] Graphics and LaTeX documents with the same font
In-Reply-To: <1C0225A0-3965-47C1-9B6C-78B5DFDB47D0@gmail.com>
References: <6ade6f6c0709280449pfdb1355x43eb0f2948c049b8@mail.gmail.com>	<Pine.LNX.4.64.0709281326380.18442@gannet.stats.ox.ac.uk>	<6ade6f6c0709280618o3f327fav890c00b9a96ab052@mail.gmail.com>
	<9D14E5C4-C061-423D-A94A-5AAAAF24A4BF@gmail.com>
	<46FD1663.5070002@vanderbilt.edu>
	<DEAF35A7-190B-4F78-B7AD-3038A079CE9A@gmail.com>
	<46FD2B0A.1000205@vanderbilt.edu>
	<1C0225A0-3965-47C1-9B6C-78B5DFDB47D0@gmail.com>
Message-ID: <46FE9BFE.4000406@vanderbilt.edu>

jiho wrote:
> On 2007-September-28  , at 18:25 , Frank E Harrell Jr wrote:
>> jiho wrote:
>>> On 2007-September-28  , at 16:57 , Frank E Harrell Jr wrote:
>>>> jiho wrote:
>>>>> On 2007-September-28  , at 15:18 , Paul Smith wrote:
>>>>>> On 9/28/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>>>>>>>> I know how to export graphics as pdf files and then how to include
>>>>>>>> them in LaTeX documents. However, I do not know how to do in  
>>>>>>>> order to
>>>>>>>> have the text of the graphics written with the font selected for 
>>>>>>>> the
>>>>>>>> LaTeX document. Is that possible?
>>>>>>> [...]
>>>>> If you don't mind an extra step between R and LaTeX, you could use  
>>>>> Inkscape to modify your graphics:
>>>>> [...]
>>>>> I personally use Inkscape on all my R graphics because I find it  
>>>>> easier and quicker to get decent graphics and R and refine their 
>>>>> look  in Inkscape than to get them perfect in R in one shot ( 
>>>>> though with  ggplot2 things are improving on R's side).
>>>> As this works against principles of reproducible research, I 
>>>> wouldn't recommend it.
>>> Do you consider that changing the font size of the graphic would be 
>>> altering the research result? Or laying out a 2d contour and a 3d plot
>>
>> Not per se, but accidents happen when editing graphics.  More 
>> importantly it creates more work.  Datasets get updated/corrected and 
>> graphics need to be reproduced.
>>
>>> in parallel, or changing the line color/pattern...? My modifications 
>>> are usually of this kind. Of course those things are doable with R 
>>> but they are usually immensely easier in a graphics program (where 
>>> the color palettes are predefined, the dash patterns are more diverse 
>>> etc.).
>>> For example, I often find myself using the same plot in an article, a 
>>> presentation, and a poster, usually with different color palettes and 
>>> font requirements. I just open the pdf, change the colors, font and 
>>> font size to match the design of the article/presentation/poster, 
>>> realign the labels a bit and re-save it. I don't think that I am 
>>> doing any harm to my result or present any false information to the 
>>> readers, I just make the graphics easier on their eyes.
>>
>> A great application for a wrapper graphics function with an argument 
>> for presentation mode.
> 
> I could do that indeed but it would require changing the margins, device 
> size, fonts, colors etc. all by hand in R. I am not saying this is 

Don't know why "by hand".

> impossible (well in some things are: R may not have access to all the 
> fonts in my system, R won't produce print-ready CMYK pdfs etc.) but it 
> is just much more trouble than producing one "OK" graphic with R and 
> handling the finer presentational details in a program more suited for 
> these maters. Not to mention that it would also suppose that I know all 
> the presentation requirements in advance, when writing the plotting 
> function, which is usually not the case. If I have to redo the plot 
> months later I may as well rewrite a new plot script based on the old 
> one and go with that.
> Once again I am not saying this is impossible, I am just skeptical about 
> the balance between the cost of producing pixel perfect graphics from 
> code and the reproducibility benefit associated, particularly in R. 
> MATLAB's or Scilab plotting models are more suited in this aspect: the 
> plot is represented as an object, that can be saved, with properties 
> that you can change _after_ its creation. So it is easy to come back, 
> even months after the analysis, and change the colors, the margins etc. 
> of the plot and to produce a pdf again. The grids packages goes this way 
> fortunately!

We may just have to have a friendly disagreement on these points, 
although I don't disagree by much.

Cheers
Frank

> 
>>> But maybe I am a bit too much of a purist on these maters. I just 
>>> find that, much too often, research results that represent months of 
>>> work are presented as narrow, black and white (possibly even 
>>> pixallated!) captures of article graphics which don't do justice to 
>>> the quality of the work behind them. I don't think there is any harm 
>>> in making (good) science look a bit "sexier", do you?
>>
>> Yes there is harm.  But to make bold lines, easy to read titles is 
>> fine.  See the spar function in 
>> http://biostat.mc.vanderbilt.edu/SgraphicsHints for a starter.  Also 
>> see the setps, ps.slide, and setpdf functions in the Hmisc package.
> 
> Thanks for the pointers, these functions look useful indeed.
> 
> I try to do the more I can in R [1], to reduce Inkscape to the 
> fine-tuning (and not risk more error than needed when editing the 
> graphics) but eventually, there's always something that does not look 
> quite right in R's output, or not consistent between two plots etc. and 
> I _have_ to change it in Inkscape (but that is probably the design 
> maniac living inside me speaking at this point ;) ).
> 
> [1] BTW, for those interested, I extracted the colors of most LaTeX 
> Beamer themes:
>     http://en.wikipedia.org/wiki/Beamer_(LaTeX)
> and made a Gimp/Inkscape palette with them. I also associated the RGB 
> codes with color names in an R script, as well as defined color schemes 
> and a few color related functions. You can get everything here:
>     http://jo.irisson.free.fr/?p=35
> 
> JiHO
> ---
> http://jo.irisson.free.fr/
> 
> 
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From dieter.menne at menne-biomed.de  Sat Sep 29 21:37:13 2007
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Sat, 29 Sep 2007 19:37:13 +0000 (UTC)
Subject: [R] fitted values in LMER for the fixed-effects only
References: <46FD5026.4030604@bio.ulaval.ca>
	<40e66e0b0709281400o2c6b6688s6a65e93fe185543f@mail.gmail.com>
Message-ID: <loom.20070929T192913-967@post.gmane.org>

On 9/28/07, Anouk Simard <Anouk.Simard <at> bio.ulaval.ca> wrote:

> > I would like to extract the fitted values from a model using LMER but
> > only for the fix portion of the model and not for the fix and random
> > portion (e.g it is the procedure outpm or outp in SAS).
..
Quoting Douglas Bates <bates <at> stat.wisc.edu>

> > The calculation of the level = 0 fitted values in the new
> > representation of the fitted model is quite easy. It is
> >
> > fm1 at X %*% fixef(fm1)"
> >

Douglas Bates replied 

> Yes.

Mmm.. If I consider a few hundreds of messages in this list on the subject, 
it's considered dirty to use the fm1 at X or fm1$X construct. So should we 
expect that this is final (no longer fitted(), augPred etc), or is it work 
in prooogresssssssss?

Dieter


From friendly at yorku.ca  Sat Sep 29 21:43:57 2007
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 29 Sep 2007 15:43:57 -0400
Subject: [R] resetting par() to all defaults: par(reset=TRUE) ?
Message-ID: <46FEAAFD.8050308@yorku.ca>

In a long session, producing multiple graphs, I sometimes repeatedly
change par() settings, particularly with multi-row/col displays.
If I'm using a script, I'll do

op <- par(newsettings)
... plots ...
par(op)

but sometimes I do things on the fly and can't easily back out
to the default settings.  I'm looking for someway to do the
equivalent of

par(reset=TRUE)

I suppose I could do something like create Rprofile.site containing

.First <- function() par.default <- par()

and then par(par.default), but maybe there's an easier way I haven't 
noticed.  [On Windows, I don't use Rprofile.site because it's one more
thing to update with each new version.]

-Michael

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA


From jmumm at agric-econ.uni-kiel.de  Sat Sep 29 23:05:18 2007
From: jmumm at agric-econ.uni-kiel.de (Jakob Mumm)
Date: Sat, 29 Sep 2007 23:05:18 +0200
Subject: [R] Visualization of two-mode matrix/ networks/ graphs
Message-ID: <9BED7451C006C24E9EFAEBED18423E8A57F8A4@ukfaemml-s04.mml-fae.uni-kiel.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070929/6cbe18af/attachment.pl 

From Graham.Williams at togaware.com  Sat Sep 29 23:20:35 2007
From: Graham.Williams at togaware.com (Graham Williams)
Date: Sun, 30 Sep 2007 07:20:35 +1000
Subject: [R] sprucing up the R homepage
In-Reply-To: <12958155.post@talk.nabble.com>
References: <20070926025320.GA7975@web15.webfaction.com>
	<12958155.post@talk.nabble.com>
Message-ID: <20070929212035.GA8414@athene.togaware.com>

Received Sun 30 Sep 2007  4:11am +1000 from DavidM.UK:
> 
> Personally I think the homepage needs a much better image not a "nice"
> version of what is currently displayed.
[...]
> Finny Kuruvilla-3 wrote:
> > 
> > [...] The graphic on the home page
> > looks a bit in need of polish so I applied some antialiased
> > transformations [...]

A surprise each time I visit the R home page would be "nice". The
gallery of R graphics could be a good source of random graphics, with
a link to the explanation in the gallery.

Regards,
Graham


From gdavis at gluonics.com  Sat Sep 29 23:36:22 2007
From: gdavis at gluonics.com (Glenn Davis)
Date: Sat, 29 Sep 2007 14:36:22 -0700 (PDT)
Subject: [R] Command-line editing & history
In-Reply-To: <Pine.LNX.4.64.0603031855481.20422@gannet.stats.ox.ac.uk>
References: <20060303015043.71414.qmail@web35403.mail.mud.yahoo.com>
	<4408607D.6050603@vanderbilt.edu>
	<20060303173105.86993.qmail@web35413.mail.mud.yahoo.com>
	<Pine.LNX.4.64.0603031855481.20422@gannet.stats.ox.ac.uk>
Message-ID: <12959946.post@talk.nabble.com>



Prof Brian Ripley wrote:
> 
> 
>> So I guess my question changes to: Does anyone know if there are plans / 
>> is it possible to add GNU Readline functionality in the Windoze port?
> 
> No plans, especially as Rterm.exe already has getline with very similar 
> functionality.  But of course you are welcome to contribute your own 
> Windows console with readline functionality.  We look forwards to hearing 
> how you get on.
> 
> 


I'm contributing a patch (to recent trunk) that does what John McHenry asked
about,
(but not full readline functionality).
It's for Matlab-like 'smart-recall' in Windows RGui.exe.
The only file modified is gnuwin32/console.c.
There are changes to consolereads(), and a small new function.
The diff file is attached.

What it does:
Type a short string, and then the up-arrow key.  The most recent command
that
begins with that string is displayed.
Keep pressing up-arrow and the next matching command is displayed.
When there are no more matching commands, the up-arrow key has no effect.
Press the down-arrow key to cycle back again to the first matching command
(but not to the original short string, though this would be possible too).

If the a previous command is edited,
the entire new command becomes the new matching string.

Note:  I'm not sure about the function of CHARTRANS.
I assume it changes the current command.

Glenn Davis
http://www.nabble.com/file/p12959946/smart-recall.diff smart-recall.diff 

-- 
View this message in context: http://www.nabble.com/Command-line-editing---history-tf1215370.html#a12959946
Sent from the R help mailing list archive at Nabble.com.


From lramlal at claflin.edu  Sun Sep 30 00:12:43 2007
From: lramlal at claflin.edu (Letticia Ramlal)
Date: Sat, 29 Sep 2007 18:12:43 -0400
Subject: [R] Help with functions (iterations)
Message-ID: <A3E5A3C873C56F42B7F1A511D5F7525510C202@cu-ex-03.claflin.edu>

Hello: 
I am a bit confused by this problem. Can anyone give me some advice on this I would greatly appreciate it. Thank you for all your help.
 
Need to create a for loop that saves the estimate of pi from each 0f 100 separate iterations and store it in a numeric vector (of length 100). The for loop should be placed in a function that allows the user to vary the sample size, the simulation size, the integration limits and the input function. In addition construct a histogram of the estimates and include a red vertical line at pi.
 
ex1.fcn<-function(x){
h<-4/(1+x^2)
return(h)
}
n=1000
a=0
b=1
my.rand.x=runif(n,min=a,max=b)
pi.MC = ((b-a)/n)*sum(ex1.fcn(my.rand.x))
 


From obaqueiro at gmail.com  Sun Sep 30 01:49:31 2007
From: obaqueiro at gmail.com (Omar Baqueiro)
Date: Sun, 30 Sep 2007 00:49:31 +0100
Subject: [R] Shapiro-Welch W value interpretation
Message-ID: <457a9aa40709291649o3ab2396fhe73a3ead32a032c0@mail.gmail.com>

Hello,

I have tested a distribution for normality using the Shapiro-Welch
statistic. The result of this is the following:


        Shapiro-Wilk normality test

data: mydata
W = 0.9989, p-value = 0.8791


I know that the p-value > 0.05 (for my purposes) means that the data
IS normally distributed but what I am not sure is with the W value,
what values tell me that the data is normally distributed.   I know
that my data is normally distributed, but what I want to know if how
to interpret the W value, I have read that "if W is very small then
the distribution is probably not normally distributed", but how
"small"  is "very small", and also, what happens is, say W = 0.000001
but the p-value is > my significance level (0.05)? is the hypothesis
rejected?

thank you!

Omar


From jholtman at gmail.com  Sun Sep 30 02:15:29 2007
From: jholtman at gmail.com (jim holtman)
Date: Sat, 29 Sep 2007 20:15:29 -0400
Subject: [R] Help with functions (iterations)
In-Reply-To: <A3E5A3C873C56F42B7F1A511D5F7525510C202@cu-ex-03.claflin.edu>
References: <A3E5A3C873C56F42B7F1A511D5F7525510C202@cu-ex-03.claflin.edu>
Message-ID: <644e1f320709291715q1e2b76a0hfff609d23fff8f66@mail.gmail.com>

I think this might be what you want:

ex1.fcn<-function(x){
h<-4/(1+x^2)
return(h)
}

my.pi <-
function(sample.size, sim.size, low, hi, func)
{
    # create output vector
    result <- numeric(sample.size)
    for (i in seq(sample.size)){ # loop for 'sample.size' times
        my.rand.x <- runif(sim.size, low, hi) # create random numbers
        result[i] <- ((hi - low) / sim.size) * sum(func(my.rand.x))
    }
    return(result)  # return the vector
}

pi.MC <- my.pi(100, 1000, 0, 1, ex1.fcn) # call the function
hist(pi.MC)  # plot histogram

On 9/29/07, Letticia Ramlal <lramlal at claflin.edu> wrote:
> Hello:
> I am a bit confused by this problem. Can anyone give me some advice on this I would greatly appreciate it. Thank you for all your help.
>
> Need to create a for loop that saves the estimate of pi from each 0f 100 separate iterations and store it in a numeric vector (of length 100). The for loop should be placed in a function that allows the user to vary the sample size, the simulation size, the integration limits and the input function. In addition construct a histogram of the estimates and include a red vertical line at pi.
>
> ex1.fcn<-function(x){
> h<-4/(1+x^2)
> return(h)
> }
> n=1000
> a=0
> b=1
> my.rand.x=runif(n,min=a,max=b)
> pi.MC = ((b-a)/n)*sum(ex1.fcn(my.rand.x))
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Jim Holtman
Cincinnati, OH
+1 513 646 9390

What is the problem you are trying to solve?


From deepayan.sarkar at gmail.com  Sun Sep 30 05:32:06 2007
From: deepayan.sarkar at gmail.com (deepayan.sarkar at gmail.com)
Date: Sat, 29 Sep 2007 20:32:06 -0700
Subject: [R] resetting par() to all defaults: par(reset=TRUE) ?
In-Reply-To: <46FEAAFD.8050308@yorku.ca>
References: <46FEAAFD.8050308@yorku.ca>
Message-ID: <eb555e660709292032v73ade23bg94b4d763b6aaa407@mail.gmail.com>

On 9/29/07, Michael Friendly <friendly at yorku.ca> wrote:
> In a long session, producing multiple graphs, I sometimes repeatedly
> change par() settings, particularly with multi-row/col displays.
> If I'm using a script, I'll do
>
> op <- par(newsettings)
> ... plots ...
> par(op)
>
> but sometimes I do things on the fly and can't easily back out
> to the default settings.  I'm looking for someway to do the
> equivalent of
>
> par(reset=TRUE)

par()s get reset every time a new device is opened, so one option is
to just close the device (dev.off()) and continue.

-Deepayan


From lawremi at iastate.edu  Sun Sep 30 14:11:52 2007
From: lawremi at iastate.edu (Michael Lawrence)
Date: Sun, 30 Sep 2007 07:11:52 -0500
Subject: [R] R CMD build not excluding .svn
Message-ID: <509e0620709300511g47abceebib920a20efa8db75f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070930/f665be36/attachment.pl 

From mi2kelgrum at yahoo.com  Sun Sep 30 14:16:14 2007
From: mi2kelgrum at yahoo.com (Mikkel Grum)
Date: Sun, 30 Sep 2007 05:16:14 -0700 (PDT)
Subject: [R] clipping viewports
Message-ID: <158570.7326.qm@web60218.mail.yahoo.com>

Dear useRs,

Why are the rotated blue and yellow boxes in the example below clipped outside of 6 x 6 inch window in the middle of the page?? Where does the 6 x 6 inch window come from? I would like to make use of the entire page.

> library(grid)
> pdf(file = "FarmMaps.pdf", paper = "a4")
> pushViewport(viewport(
+    width = unit(7.6, "inches"), height = unit(11, "inches"), clip = "off"))
> grid.rect(gp = gpar(col = NA, fill = "grey"))
> pushViewport(viewport(x = unit(3.6, "inches"), y = unit(3.6, "inches"),
+    width = unit(3.6, "inches"), height = unit(3.6, "inches"), clip = "off",
+    angle = 76))
> grid.rect(gp = gpar(col = NA, fill = "blue"))
> upViewport()
> pushViewport(viewport(x = unit(1.8, "inches"), y = unit(7.6, "inches"),
+    width = unit(2.6, "inches"), height = unit(2.6, "inches"), clip = "off",
+    angle = -56))
> grid.rect(gp = gpar(col = NA, fill = "yellow"))
> 
> dev.off()
null device 
          1 
> 
> sessionInfo()
R version 2.5.1 (2007-06-27) 
i386-pc-mingw32 

locale:
LC_COLLATE=English_Ireland.1252;LC_CTYPE=English_Ireland.1252;LC_MONETARY=English_Ireland.1252;LC_NUMERIC=C;LC_TIME=English_Ireland.1252

attached base packages:
[1] "grid"      "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[7] "methods"   "base" 
    > 

Any assistance greatly appreciated,
Mikkel



       
____________________________________________________________________________________
Pinpoint customers who are looking for what you sell. 
http://searchmarketing.yahoo.com/


From bolker at ufl.edu  Sun Sep 30 17:38:29 2007
From: bolker at ufl.edu (bbolker)
Date: Sun, 30 Sep 2007 08:38:29 -0700 (PDT)
Subject: [R] resetting par() to all defaults: par(reset=TRUE) ?
In-Reply-To: <46FEAAFD.8050308@yorku.ca>
References: <46FEAAFD.8050308@yorku.ca>
Message-ID: <12966877.post@talk.nabble.com>




Michael Friendly wrote:
> 
> In a long session, producing multiple graphs, I sometimes repeatedly
> change par() settings, particularly with multi-row/col displays.
> If I'm using a script, I'll do
> 
> op <- par(newsettings)
> ... plots ...
> par(op)
> 
> but sometimes I do things on the fly and can't easily back out
> to the default settings.  I'm looking for someway to do the
> equivalent of
> 
> par(reset=TRUE)
> 
> I suppose I could do something like create Rprofile.site containing
> 
> .First <- function() par.default <- par()
> 
> and then par(par.default), but maybe there's an easier way I haven't 
> noticed.  [On Windows, I don't use Rprofile.site because it's one more
> thing to update with each new version.]
> 
> -Michael
> 

  Your solution seems pretty good to me (although I often use Deepayan's
dev.off(); windows() hack myself), but I would amend it to 
par.default <- par(no.readonly=TRUE)

   Ben

-- 
View this message in context: http://www.nabble.com/resetting-par%28%29-to-all-defaults%3A-par%28reset%3DTRUE%29---tf4540681.html#a12966877
Sent from the R help mailing list archive at Nabble.com.


From phhs80 at gmail.com  Sun Sep 30 17:49:26 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Sun, 30 Sep 2007 16:49:26 +0100
Subject: [R] Problem with Palatino font in pdf figures
Message-ID: <6ade6f6c0709300849w1ca78686x5fbae0e82546a013@mail.gmail.com>

Dear All,

Consider the following piece of code:

pdf(file="figure.pdf", family="Palatino")
plot(0,0,type='n', xlim=c(-20,20), ylim=c(0,2),xlab="",ylab="",axes=F)
text(-1.4,1.168,expression(italic("The font looks different when this
is seen with Acrobat Reader!")),xpd=T)
dev.off()

When viewing the produced figure.pdf with kpdf (on Linux), it looks as
being written with LaTeX Mathpazo font, but not when one views
figure.pdf with Acrobat Reader. Any ideas about how to get the same
result both with kpdf and with Acrobat Reader?

Thanks in advance,

Paul


From marc_schwartz at comcast.net  Sun Sep 30 18:27:13 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Sun, 30 Sep 2007 11:27:13 -0500
Subject: [R] Problem with Palatino font in pdf figures
In-Reply-To: <6ade6f6c0709300849w1ca78686x5fbae0e82546a013@mail.gmail.com>
References: <6ade6f6c0709300849w1ca78686x5fbae0e82546a013@mail.gmail.com>
Message-ID: <1191169633.6586.82.camel@Bellerophon.localdomain>

On Sun, 2007-09-30 at 16:49 +0100, Paul Smith wrote:
> Dear All,
> 
> Consider the following piece of code:
> 
> pdf(file="figure.pdf", family="Palatino")
> plot(0,0,type='n', xlim=c(-20,20), ylim=c(0,2),xlab="",ylab="",axes=F)
> text(-1.4,1.168,expression(italic("The font looks different when this
> is seen with Acrobat Reader!")),xpd=T)
> dev.off()
> 
> When viewing the produced figure.pdf with kpdf (on Linux), it looks as
> being written with LaTeX Mathpazo font, but not when one views
> figure.pdf with Acrobat Reader. Any ideas about how to get the same
> result both with kpdf and with Acrobat Reader?
> 
> Thanks in advance,
> 
> Paul

Note that R does not embed the fonts by default in the PDF file.

Based upon what I am seeing here on F7, which is consistent with your
comments, the font substitution mapping in Adobe Reader 8 is different
than that in either kpdf, gv or in Evince. The latter three appear to be
using the same font substitution and look the same.

You might want to review ?pdfFonts and ?embedFonts for additional
information as well as the article by Paul Murrell and Prof. Ripley in R
News on non-standard fonts:

  http://cran.r-project.org/doc/Rnews/Rnews_2006-2.pdf

HTH,

Marc Schwartz


From h.wickham at gmail.com  Sun Sep 30 18:35:29 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 30 Sep 2007 11:35:29 -0500
Subject: [R] Plotting from different data sources on the same plot (with
	ggplot2)
In-Reply-To: <1098D7B2-FD7D-447A-B06C-4F005773CEBF@gmail.com>
References: <1098D7B2-FD7D-447A-B06C-4F005773CEBF@gmail.com>
Message-ID: <f8e6ff050709300935h71b34c2cy68605b875f07e681@mail.gmail.com>

Hi JiHO,

> The ggplot book specifies that "[ggplot] makes it easy to combine
> data from multiple sources". Since I use ggplot2 as much as I can
> (thanks it's really really great!) I thought I would try producing
> such a plot with ggplot2.
>
> NB: If this is possible/easy with an other plotting package please
> let me know. I am not looking for something specific to maps but
> rather for a generic mechanism to throw several pieces of data to a
> graph and have the plotting routine take care of setting up axes that
> will fit all data on the same scale.

I don't think it's easy with any other plotting system (although I'd
be happy to be proven wrong), and was one of the motivations for the
construction of ggplot.

> So, now for the ggplot2 part. I have two data sources: the
> coordinates of the coastlines in a region of interest and the
> coordinated of sampling stations in a subset of this region. I want
> to plot the coastline as a line and the stations as points, on the
> same graph. I can plot them independently easily:
>
> p1 = ggplot(coast,aes(x=lon,y=lat)) + geom_path() + coord_equal(ratio=1)
> p1$aspect.ratio = 1
>
> p2 = ggplot(coords,aes(x=lon,y=lat)) + geom_point() + coord_equal
> (ratio=1)
> p2$aspect.ratio = 1

There are a few ways you could describe the graph you want.  Here's
the one that I'd probably choose:

ggplot(mapping = aes(x = log, y = lat)) +
geom_path(data = coast) +
geom_point(data = coords) +
coord_equal()

We don't define a default dataset in the ggplot call, but instead
explicitly define the dataset in each of the layers. By default,
ggplot will make sure that all the data is displayed on the plot -
i.e. the x and y scales show the union of the ranges over all
datasets.

Does that make sense?

Hadley

-- 
http://had.co.nz/


From mark at wardle.org  Sun Sep 30 18:55:48 2007
From: mark at wardle.org (Mark Wardle)
Date: Sun, 30 Sep 2007 17:55:48 +0100
Subject: [R] Help with functions (iterations)
In-Reply-To: <A3E5A3C873C56F42B7F1A511D5F7525510C202@cu-ex-03.claflin.edu>
References: <A3E5A3C873C56F42B7F1A511D5F7525510C202@cu-ex-03.claflin.edu>
Message-ID: <b59a37130709300955k2f37e867ie92b1c43cd40f06b@mail.gmail.com>

Dear Letticia,

Are you using R-help for your homework?

See your previous postings:


1. 15th September:

With a single R command complete the following:
create a vector calles seqvec that repeats the sequence 1, 3,6,
10,15,21.( I was trying to use c() but this does not work)
create a 5-row, 6-column matirx from seqvec wuth each row containg the
sequence from before
and complete the two task above in a single step.


2. 16th September

iven the following data for a data set called airquality. To identify
the nature of the objects from the data set airquality example "Ozone"
would it be best to use the command is. like
is.character(airquality$Ozone) ....... I tried
attributes(airquality$Ozone) but it came up null. Would there be a
better way to identify these objects.

3. 27th September

Using a 3-level input factor alternative so that a function(below) can
compute both a two-sided and one-sided p-values. Making the two-sided
test the default. And produce output information about which
alternative was tested.

4. Today

Need to create a for loop that saves the estimate of pi from each 0f
100 separate iterations and store it in a numeric vector (of length
100). The for loop should be placed in a function that allows the user
to vary the sample size, the simulation size, the integration limits
and the input function. In addition construct a histogram of the
estimates and include a red vertical line at pi.

Mark

On 29/09/2007, Letticia Ramlal <lramlal at claflin.edu> wrote:
> Hello:
> I am a bit confused by this problem. Can anyone give me some advice on this I would greatly appreciate it. Thank you for all your help.
>
> Need to create a for loop that saves the estimate of pi from each 0f 100 separate iterations and store it in a numeric vector (of length 100). The for loop should be placed in a function that allows the user to vary the sample size, the simulation size, the integration limits and the input function. In addition construct a histogram of the estimates and include a red vertical line at pi.
>
> ex1.fcn<-function(x){
> h<-4/(1+x^2)
> return(h)
> }
> n=1000
> a=0
> b=1
> my.rand.x=runif(n,min=a,max=b)
> pi.MC = ((b-a)/n)*sum(ex1.fcn(my.rand.x))
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________________________________
> This email has been scanned by the MessageLabs Email Security System.
> For more information please visit http://www.messagelabs.com/email
> ______________________________________________________________________
>


-- 
Dr. Mark Wardle
Specialist registrar, Neurology
Cardiff, UK


From phhs80 at gmail.com  Sun Sep 30 19:37:50 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Sun, 30 Sep 2007 18:37:50 +0100
Subject: [R] Problem with Palatino font in pdf figures
In-Reply-To: <1191169633.6586.82.camel@Bellerophon.localdomain>
References: <6ade6f6c0709300849w1ca78686x5fbae0e82546a013@mail.gmail.com>
	<1191169633.6586.82.camel@Bellerophon.localdomain>
Message-ID: <6ade6f6c0709301037h470cbf5fy3f5232c2815286bc@mail.gmail.com>

On 9/30/07, Marc Schwartz <marc_schwartz at comcast.net> wrote:
> > Consider the following piece of code:
> >
> > pdf(file="figure.pdf", family="Palatino")
> > plot(0,0,type='n', xlim=c(-20,20), ylim=c(0,2),xlab="",ylab="",axes=F)
> > text(-1.4,1.168,expression(italic("The font looks different when this
> > is seen with Acrobat Reader!")),xpd=T)
> > dev.off()
> >
> > When viewing the produced figure.pdf with kpdf (on Linux), it looks as
> > being written with LaTeX Mathpazo font, but not when one views
> > figure.pdf with Acrobat Reader. Any ideas about how to get the same
> > result both with kpdf and with Acrobat Reader?
>
> Note that R does not embed the fonts by default in the PDF file.
>
> Based upon what I am seeing here on F7, which is consistent with your
> comments, the font substitution mapping in Adobe Reader 8 is different
> than that in either kpdf, gv or in Evince. The latter three appear to be
> using the same font substitution and look the same.
>
> You might want to review ?pdfFonts and ?embedFonts for additional
> information as well as the article by Paul Murrell and Prof. Ripley in R
> News on non-standard fonts:
>
>   http://cran.r-project.org/doc/Rnews/Rnews_2006-2.pdf

Thanks, Marc. With embedFonts, everything gets right!

Paul


From jo.irisson at gmail.com  Sun Sep 30 19:52:28 2007
From: jo.irisson at gmail.com (jiho)
Date: Sun, 30 Sep 2007 19:52:28 +0200
Subject: [R] Plotting from different data sources on the same plot (with
	ggplot2)
In-Reply-To: <f8e6ff050709300935h71b34c2cy68605b875f07e681@mail.gmail.com>
References: <1098D7B2-FD7D-447A-B06C-4F005773CEBF@gmail.com>
	<f8e6ff050709300935h71b34c2cy68605b875f07e681@mail.gmail.com>
Message-ID: <B0AAFF0D-5B29-4CB3-955E-13FC3C6775DE@gmail.com>

On 2007-September-30  , at 18:35 , hadley wickham wrote:
>> The ggplot book specifies that "[ggplot] makes it easy to combine
>> data from multiple sources". Since I use ggplot2 as much as I can
>> (thanks it's really really great!) I thought I would try producing
>> such a plot with ggplot2.
>>
>> NB: If this is possible/easy with an other plotting package please
>> let me know. I am not looking for something specific to maps but
>> rather for a generic mechanism to throw several pieces of data to a
>> graph and have the plotting routine take care of setting up axes that
>> will fit all data on the same scale.
>
> I don't think it's easy with any other plotting system (although I'd
> be happy to be proven wrong), and was one of the motivations for the
> construction of ggplot.
>
>> So, now for the ggplot2 part. I have two data sources: the
>> coordinates of the coastlines in a region of interest and the
>> coordinated of sampling stations in a subset of this region. I want
>> to plot the coastline as a line and the stations as points, on the
>> same graph. I can plot them independently easily:
>>
>> p1 = ggplot(coast,aes(x=lon,y=lat)) + geom_path() + coord_equal 
>> (ratio=1)
>> p1$aspect.ratio = 1
>>
>> p2 = ggplot(coords,aes(x=lon,y=lat)) + geom_point() + coord_equal
>> (ratio=1)
>> p2$aspect.ratio = 1
>
> There are a few ways you could describe the graph you want.  Here's
> the one that I'd probably choose:
>
> ggplot(mapping = aes(x = log, y = lat)) +
> geom_path(data = coast) +
> geom_point(data = coords) +
> coord_equal()
>
> We don't define a default dataset in the ggplot call, but instead
> explicitly define the dataset in each of the layers. By default,
> ggplot will make sure that all the data is displayed on the plot -
> i.e. the x and y scales show the union of the ranges over all
> datasets.
>
> Does that make sense?

It makes perfect sense indeed... unfortunately it does not work  
here ;) :

 > p = ggplot(mapping = aes(x=lon, y=lat)) + geom_path(data = coast)  
+ geom_point(data = coords) + coord_equal()
 > p
Error in get("get_scales", env = .$.scales, inherits = TRUE)(. 
$.scales,  :
         invalid subscript type

As expected there is nothing in the data part of the p object
 > p$data
NULL

But there is no data specification either in the layers
 > p$layers
[[1]]
geom_path: (colour=black, size=1, linetype=1) + ()
stat_identity: (...=) + ()
position_identity: ()
mapping: ()

[[2]]
geom_point: (shape=19, colour=black, size=2) + ()
stat_identity: (...=) + ()
position_identity: ()
mapping: ()

  There are no scales either, which apparently causes the error
 > p$scales
Scales:   ->

Should I get a newer version of ggplot? (I have version 0.5.4)

About the other solution:

>> When tinkering a bit more with this I thought that the more natural
>> and "ggplot" way to do it, IMHO, would be to have a new addition (`
>> +`) method for the ggplot class and be able to do:
>>         p = p1 + p2
>> and have p containing both plots, on the same scale (the union of the
>
> You were obviously pretty close to the solution already!  - you just
> need to remove the elements that p2 already has in common with p1 and
> just add on the components that are different.

I would love to be able to do so because this way I can define custom  
plot functions that all return me a ggplot object and then combine  
these at will to get final plots (Ex: one function for the coastline,  
another for stations coordinates, another one which gets one data  
value, yet another for bathymetry contours etc etc.). This modular  
design would be more efficient than to have to predefine all  
combinations in ad hoc functions (e.g. one function for coast+bathy 
+stations, another for coast+stations only, another for coast+bathy 
+stations+data1, another for... you get the point).
However I don't see what to add and what to remove from the objects.  
Specifically, there is only "data" element in the ggplot object while  
my two objects (p1 and p2) both contain something different in $data.  
Should I define p$data as a list with p$data[[1]]=p1$data and p$data 
[[2]]=p2$data?

> You also need to
> remember that the ggplot function just sets up a list of defaults that
> can be overridden within each layer - there is very little
> functionality provided by the ggplot object itself.
>
>> scales of p1 and p2), and just one set of axes. And even:
>>         p = add(p1, p2, drop=T)
>> which would give p1 and p2 plots clipped to the xlim and ylim of p2.
>
> Yes, it would be nice to have some syntax to overrule the default
> policy of showing all the data, although it gets a bit more
> complicated when you consider other scales like colour and size.

I understand. Anyway, ggplot2 is still in its early stages and this  
may come after some maturing. Thanks for your answers.

JiHO
---
http://jo.irisson.free.fr/


From ripley at stats.ox.ac.uk  Sun Sep 30 20:00:34 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 30 Sep 2007 19:00:34 +0100 (BST)
Subject: [R] Problem with Palatino font in pdf figures
In-Reply-To: <6ade6f6c0709301037h470cbf5fy3f5232c2815286bc@mail.gmail.com>
References: <6ade6f6c0709300849w1ca78686x5fbae0e82546a013@mail.gmail.com>
	<1191169633.6586.82.camel@Bellerophon.localdomain>
	<6ade6f6c0709301037h470cbf5fy3f5232c2815286bc@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0709301845270.14578@gannet.stats.ox.ac.uk>

On Sun, 30 Sep 2007, Paul Smith wrote:

> On 9/30/07, Marc Schwartz <marc_schwartz at comcast.net> wrote:
>>> Consider the following piece of code:
>>>
>>> pdf(file="figure.pdf", family="Palatino")
>>> plot(0,0,type='n', xlim=c(-20,20), ylim=c(0,2),xlab="",ylab="",axes=F)
>>> text(-1.4,1.168,expression(italic("The font looks different when this
>>> is seen with Acrobat Reader!")),xpd=T)
>>> dev.off()
>>>
>>> When viewing the produced figure.pdf with kpdf (on Linux), it looks as
>>> being written with LaTeX Mathpazo font, but not when one views
>>> figure.pdf with Acrobat Reader. Any ideas about how to get the same
>>> result both with kpdf and with Acrobat Reader?
>>
>> Note that R does not embed the fonts by default in the PDF file.
>>
>> Based upon what I am seeing here on F7, which is consistent with your
>> comments, the font substitution mapping in Adobe Reader 8 is different
>> than that in either kpdf, gv or in Evince. The latter three appear to be
>> using the same font substitution and look the same.

There is a note to that effect in ?pdf.  All the viewers based on 
GhostScript are going to be using URW fonts (under Linux, at least), that 
is use URW Palladio to substitute Palatino.  xpdf is configurable, but I 
believe is also normally set up to use URW T1 fonts.

>> You might want to review ?pdfFonts and ?embedFonts for additional
>> information as well as the article by Paul Murrell and Prof. Ripley in R
>> News on non-standard fonts:
>>
>>   http://cran.r-project.org/doc/Rnews/Rnews_2006-2.pdf
>
> Thanks, Marc. With embedFonts, everything gets right!

I dobut it: Palatino is a commercial font (I believe it is a Linotype 
trademark) and _if_ you have it you need to worry about the legality of 
embedding it.  Most likely you have arranged to substitute URWPalladio 
everywhere, in which case you would do better to use the correct font 
metrics by specifying that in the first place.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sun Sep 30 20:03:54 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 30 Sep 2007 19:03:54 +0100 (BST)
Subject: [R] resetting par() to all defaults: par(reset=TRUE) ?
In-Reply-To: <12966877.post@talk.nabble.com>
References: <46FEAAFD.8050308@yorku.ca> <12966877.post@talk.nabble.com>
Message-ID: <Pine.LNX.4.64.0709301646540.14772@gannet.stats.ox.ac.uk>

On Sun, 30 Sep 2007, bbolker wrote:

> Michael Friendly wrote:
>>
>> In a long session, producing multiple graphs, I sometimes repeatedly
>> change par() settings, particularly with multi-row/col displays.
>> If I'm using a script, I'll do
>>
>> op <- par(newsettings)
>> ... plots ...
>> par(op)
>>
>> but sometimes I do things on the fly and can't easily back out
>> to the default settings.  I'm looking for someway to do the
>> equivalent of
>>
>> par(reset=TRUE)
>>
>> I suppose I could do something like create Rprofile.site containing
>>
>> .First <- function() par.default <- par()
>>
>> and then par(par.default), but maybe there's an easier way I haven't
>> noticed.  [On Windows, I don't use Rprofile.site because it's one more
>> thing to update with each new version.]
>>
>> -Michael
>>
>
>  Your solution seems pretty good to me (although I often use Deepayan's
> dev.off(); windows() hack myself), but I would amend it to
> par.default <- par(no.readonly=TRUE)

The default parameters depend on the device and indeed on the size of the 
device.  Deepayan's suggestion (as I recall he did not suggest opening the 
device but letting R do it) is widely used and seems a lot better to me, 
not least because setting par() in .First will open a device in every 
session, needed or not, interactive or not.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From phhs80 at gmail.com  Sun Sep 30 20:14:22 2007
From: phhs80 at gmail.com (Paul Smith)
Date: Sun, 30 Sep 2007 19:14:22 +0100
Subject: [R] Problem with Palatino font in pdf figures
In-Reply-To: <Pine.LNX.4.64.0709301845270.14578@gannet.stats.ox.ac.uk>
References: <6ade6f6c0709300849w1ca78686x5fbae0e82546a013@mail.gmail.com>
	<1191169633.6586.82.camel@Bellerophon.localdomain>
	<6ade6f6c0709301037h470cbf5fy3f5232c2815286bc@mail.gmail.com>
	<Pine.LNX.4.64.0709301845270.14578@gannet.stats.ox.ac.uk>
Message-ID: <6ade6f6c0709301114n1308b3a6m7fa02c761bd4589d@mail.gmail.com>

On 9/30/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> >>> Consider the following piece of code:
> >>>
> >>> pdf(file="figure.pdf", family="Palatino")
> >>> plot(0,0,type='n', xlim=c(-20,20), ylim=c(0,2),xlab="",ylab="",axes=F)
> >>> text(-1.4,1.168,expression(italic("The font looks different when this
> >>> is seen with Acrobat Reader!")),xpd=T)
> >>> dev.off()
> >>>
> >>> When viewing the produced figure.pdf with kpdf (on Linux), it looks as
> >>> being written with LaTeX Mathpazo font, but not when one views
> >>> figure.pdf with Acrobat Reader. Any ideas about how to get the same
> >>> result both with kpdf and with Acrobat Reader?
> >>
> >> Note that R does not embed the fonts by default in the PDF file.
> >>
> >> Based upon what I am seeing here on F7, which is consistent with your
> >> comments, the font substitution mapping in Adobe Reader 8 is different
> >> than that in either kpdf, gv or in Evince. The latter three appear to be
> >> using the same font substitution and look the same.
>
> There is a note to that effect in ?pdf.  All the viewers based on
> GhostScript are going to be using URW fonts (under Linux, at least), that
> is use URW Palladio to substitute Palatino.  xpdf is configurable, but I
> believe is also normally set up to use URW T1 fonts.
>
> >> You might want to review ?pdfFonts and ?embedFonts for additional
> >> information as well as the article by Paul Murrell and Prof. Ripley in R
> >> News on non-standard fonts:
> >>
> >>   http://cran.r-project.org/doc/Rnews/Rnews_2006-2.pdf
> >
> > Thanks, Marc. With embedFonts, everything gets right!
>
> I dobut it: Palatino is a commercial font (I believe it is a Linotype
> trademark) and _if_ you have it you need to worry about the legality of
> embedding it.  Most likely you have arranged to substitute URWPalladio
> everywhere, in which case you would do better to use the correct font
> metrics by specifying that in the first place.

Thanks for your clarification. In fact,

$ pdffonts figure.pdf
name                                 type         emb sub uni object ID
------------------------------------ ------------ --- --- --- ---------
LBSBWQ+Palatino-Italic               Type 1C      yes yes no      11  0
SLZFVF+Palatino-Roman                Type 1C      yes yes no       9  0
$

but if I specify

pdf(file="figure.pdf", family="URWPalladio")

I get

$ pdffonts figure.pdf
name                                 type         emb sub uni object ID
------------------------------------ ------------ --- --- --- ---------
RNPZMM+URWPalladioL-Ital             Type 1C      yes yes no       9  0
$

Paul


From ehlers at math.ucalgary.ca  Sun Sep 30 20:16:29 2007
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Sun, 30 Sep 2007 12:16:29 -0600
Subject: [R] Shapiro-Welch W value interpretation
In-Reply-To: <457a9aa40709291649o3ab2396fhe73a3ead32a032c0@mail.gmail.com>
References: <457a9aa40709291649o3ab2396fhe73a3ead32a032c0@mail.gmail.com>
Message-ID: <46FFE7FD.1020500@math.ucalgary.ca>


Omar Baqueiro wrote:
> Hello,
> 
> I have tested a distribution for normality using the Shapiro-Welch
> statistic. The result of this is the following:
> 
> 
>         Shapiro-Wilk normality test
> 
> data: mydata
> W = 0.9989, p-value = 0.8791
> 
> 
> I know that the p-value > 0.05 (for my purposes) means that the data
> IS normally distributed but what I am not sure is with the W value,
> what values tell me that the data is normally distributed.   I know
> that my data is normally distributed, but what I want to know if how
> to interpret the W value, I have read that "if W is very small then
> the distribution is probably not normally distributed", but how
> "small"  is "very small", and also, what happens is, say W = 0.000001
> but the p-value is > my significance level (0.05)? is the hypothesis
> rejected?
> 

There is some confusion in your query.
First, how do you know that your data are indeed normally distributed?
That's *not* what the p-value of the test says.
Consider the following result of the Shapiro-Wilk test applied to
a vector x:

data: x
W = 0.9856, p-value = 0.988

Here x was not sampled from a normal distribution (code at end).

Second, the point of a p-value is to formalize decision-making
so that critical regions of tests are converted to p-value intervals.
Thus, your emphasis on the value of W is misplaced. It's
not how small W is but how small it is for the given sample size,
and the p-value takes care of the significance. (This is not to
say, of course, that the distribution of W is not of interest.)

Finally, what exactly, in your view, is "the hypothesis"?

I hope this doesn't sound too critical. I'm trying to be helpful.

Peter Ehlers

> thank you!
> 
> Omar
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

set.seed(34); shapiro.test(rexp(10))


From bolker at ufl.edu  Sun Sep 30 20:20:53 2007
From: bolker at ufl.edu (Ben Bolker)
Date: Sun, 30 Sep 2007 18:20:53 +0000 (UTC)
Subject: [R] plot graph with error bars trouble
References: <a35fc1810709281003g67acdc56l96f759cf7324d0d0@mail.gmail.com>
Message-ID: <loom.20070930T181742-99@post.gmane.org>

Marcelo Laia <marcelolaia <at> gmail.com> writes:

> 
> Hi,
> 
> I have a data set like this:
> 

 [snip]

> I need to plot a graph OD over the time for each one mutant with error bars.
> 
>


## I put your data in a temporary file, this reads it
x = read.table("tempdata.txt",header=TRUE)


## compute means and standard errors
##  (no built-in function for standard error, so create one)
## also see ?aggregate, ?by
means =  with(x,tapply(OD,list(Time,Mutant),mean))
se = function(x) sd(x)/sqrt(length(x))
ses = with(x,tapply(OD,list(Time,Mutant),se))

## time vector -- could also be unique(x$Time)
times = as.numeric(rownames(means))

## plot the means
matplot(times,means,type="b",lty=1,col=1:2,pch=1:2)
library(plotrix)
## have to create the x-vector and color-vector "by hand"
##  it would be nice if there were a matplotCI, but there
## isn't (yet) ...
plotCI(rep(times,2),means,ses,pch=NA,add=TRUE,
          col=rep(1:2,each=nrow(means)))

  good luck
   Ben Bolker


From hxzhu at stat.rice.edu  Sun Sep 30 20:52:28 2007
From: hxzhu at stat.rice.edu (Hongxiao Zhu)
Date: Sun, 30 Sep 2007 13:52:28 -0500 (CDT)
Subject: [R] Save and load workspace in R: strange error.
Message-ID: <Pine.GSO.4.64.0709301335540.13021@thor.stat.rice.edu>

Hi,

I tried to load a .RData object on unix system using R, it gives error:

Error: restore file may be empty -- no data loaded
In addition: Warning message:
file 'junk3.RData' has magic number ''
    Use of save versions prior to 2 is deprecated

This happens only for using MY user account for the Unix system. I 
tried to use a friends's user account to load the same data object, it is
fine. And it never happened to me before until sometime last week.
And This error happens even when I generate a simple random number
from my user account and save it, and load it again.(So obviously it is 
not a R version mismatch problem). Does anybody know what happened?

Here is an example what happened:

> x=rnorm(100)
> save.image('junk4.RData')
> load('junk4.RData')
Error: restore file may be empty -- no data loaded
In addition: Warning message:
file 'junk4.RData' has magic number ''
    Use of save versions prior to 2 is deprecated

Thanks for any suggestion.

Hongxiao


**********************************************
  *  Hongxiao Zhu                              *
  *  Department of Statistics, Rice Univeristy *
  *  Office: DH 3136, Phone: 713-348-2839      *
  *  http://www.stat.rice.edu/~hxzhu/          *


From tom.cohen78 at yahoo.se  Sun Sep 30 20:56:06 2007
From: tom.cohen78 at yahoo.se (Tom Cohen)
Date: Sun, 30 Sep 2007 20:56:06 +0200 (CEST)
Subject: [R] Append the sum of each row and column to a table matrix
Message-ID: <511890.48189.qm@web23015.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20070930/12d85fba/attachment.pl 

From h.wickham at gmail.com  Sun Sep 30 21:01:07 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 30 Sep 2007 14:01:07 -0500
Subject: [R] Plotting from different data sources on the same plot (with
	ggplot2)
In-Reply-To: <B0AAFF0D-5B29-4CB3-955E-13FC3C6775DE@gmail.com>
References: <1098D7B2-FD7D-447A-B06C-4F005773CEBF@gmail.com>
	<f8e6ff050709300935h71b34c2cy68605b875f07e681@mail.gmail.com>
	<B0AAFF0D-5B29-4CB3-955E-13FC3C6775DE@gmail.com>
Message-ID: <f8e6ff050709301201q292ed4f8u11b14084b4df0337@mail.gmail.com>

> > There are a few ways you could describe the graph you want.  Here's
> > the one that I'd probably choose:
> >
> > ggplot(mapping = aes(x = log, y = lat)) +
> > geom_path(data = coast) +
> > geom_point(data = coords) +
> > coord_equal()
> >
> > We don't define a default dataset in the ggplot call, but instead
> > explicitly define the dataset in each of the layers. By default,
> > ggplot will make sure that all the data is displayed on the plot -
> > i.e. the x and y scales show the union of the ranges over all
> > datasets.
> >
> > Does that make sense?
>
> It makes perfect sense indeed... unfortunately it does not work
> here ;) :
>
>  > p = ggplot(mapping = aes(x=lon, y=lat)) + geom_path(data = coast)
> + geom_point(data = coords) + coord_equal()
>  > p
> Error in get("get_scales", env = .$.scales, inherits = TRUE)(.
> $.scales,  :
>          invalid subscript type

Oops, that's a bit of a bug - you can fix it either by making one of
the two datasets the default (ggplot(coast, ...)) or manually adding
all the scales you need (+ scale_y_continuous() +
scale_x_continuous()).  I've made a note to fix this.

> As expected there is nothing in the data part of the p object
>  > p$data
> NULL
>
> But there is no data specification either in the layers
>  > p$layers
> [[1]]
> geom_path: (colour=black, size=1, linetype=1) + ()
> stat_identity: (...=) + ()
> position_identity: ()
> mapping: ()
>
> [[2]]
> geom_point: (shape=19, colour=black, size=2) + ()
> stat_identity: (...=) + ()
> position_identity: ()
> mapping: ()

Compare geom_point(data=mtcars) with str(geom_point(data =mtcars))
(which throws an error but you should be able to see enough).  So the
layers aren't printing out their dataset if they have one - another
bug.  I'll add it to my todo.

>   There are no scales either, which apparently causes the error
>  > p$scales
> Scales:   ->
>
> Should I get a newer version of ggplot? (I have version 0.5.4)
>
> About the other solution:
>
> >> When tinkering a bit more with this I thought that the more natural
> >> and "ggplot" way to do it, IMHO, would be to have a new addition (`
> >> +`) method for the ggplot class and be able to do:
> >>         p = p1 + p2
> >> and have p containing both plots, on the same scale (the union of the
> >
> > You were obviously pretty close to the solution already!  - you just
> > need to remove the elements that p2 already has in common with p1 and
> > just add on the components that are different.
>
> I would love to be able to do so because this way I can define custom
> plot functions that all return me a ggplot object and then combine
> these at will to get final plots (Ex: one function for the coastline,
> another for stations coordinates, another one which gets one data
> value, yet another for bathymetry contours etc etc.). This modular
> design would be more efficient than to have to predefine all
> combinations in ad hoc functions (e.g. one function for coast+bathy
> +stations, another for coast+stations only, another for coast+bathy
> +stations+data1, another for... you get the point).
> However I don't see what to add and what to remove from the objects.
> Specifically, there is only "data" element in the ggplot object while
> my two objects (p1 and p2) both contain something different in $data.
> Should I define p$data as a list with p$data[[1]]=p1$data and p$data
> [[2]]=p2$data?

You can do this already :

sample <- c(geom_point(data = coast), geom_path(data = streams), coord_equal())
p + sample

I think the thing you are missing is that the elements in ggplot() are
just defaults that can be overridden in the individual layers
(although the bug above means that isn't working quite right at the
moment).  So just specify the dataset in the layer that you are
adding.

You can do things like:

p <- ggplot(mapping = aes(x=lat, y = long)) + geom_point()
# no data so there's nothing to plot:
p

# add on data
p %+% coast
p %+% coords

The data is completely independent of the plot specification.  This is
very different from the other plotting models in R, so it may take a
while to get your head around it.

Hadley

---
http://had.co.nz/


From marc_schwartz at comcast.net  Sun Sep 30 21:15:03 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Sun, 30 Sep 2007 14:15:03 -0500
Subject: [R] Append the sum of each row and column to a table matrix
In-Reply-To: <511890.48189.qm@web23015.mail.ird.yahoo.com>
References: <511890.48189.qm@web23015.mail.ird.yahoo.com>
Message-ID: <1191179703.6586.108.camel@Bellerophon.localdomain>

On Sun, 2007-09-30 at 20:56 +0200, Tom Cohen wrote:
> Dear list, 
>   I have following table
>    
>   ee<-table(ID,Day)
>   ee
>       Day
>   ID    2  3  4 5 6  7  9 10 14 16
>     35  5  0  0 3 1  0  0  5  0  0
>     36  0  0  0 0 0  0  0  1  0  0
>     43 13 15 15 0 0 13 13 15 13 15
>     46  0  1  0 0 0  0  0  0  0  0
>     58  0  0  0 0 0  0  4  4  0  0
>   and want to calculate the sum for each row and column and then
> append the sums to the table matrix.
>    
>   kk<cbind(ee,as.matrix(apply(ee,1,sum)))
>   dd<-rbind(kk,apply(ee,2,sum))
>    
>   Warning message:
>   number of columns of result
>           is not a multiple of vector length (arg 2) in: rbind(1, kk,
> apply(ee,2, sum))
>    
>   rownames(dd)<-c(rownames(dd)[-6],"Total:")
>   colnames(dd)<-c(colnames(dd)[-11],"Total:")
>    
>   I got a table as wanted (see below), except that the variable names
> Day and ID are missing. Is there a way to add back these variable
> names to the table "dd" as shown in "ee". Also I got a warning message
> that I'm not exactly know how to skip. Can I make the table "dd" in a
> different and easier way ? Any suggestions are highly appreciated.
>    
>   Thanks,
>   Tom
>    
>   dd
>    
>           2  3  4 5 6  7  9 10 14 16 Total:
>   35      5  0  0 3 1  0  0  5  0  0     14
>   36      0  0  0 0 0  0  0  1  0  0      1
>   43     13 15 15 0 0 13 13 15 13 15    112
>   46      0  1  0 0 0  0  0  0  0  0      1
>   58      0  0  0 0 0  0  4  4  0  0      8
>   Total: 18 16 15 3 1 13 17 25 13 15     18
>    

The easiest way to do this is to use addmargins():

dd <- addmargins(ee, FUN = list(Total = sum), quiet = TRUE)

> dd
       Days
ID        2   3   4   5   6   7   9  10  14  16 Total
  35      5   0   0   3   1   0   0   5   0   0    14
  36      0   0   0   0   0   0   0   1   0   0     1
  43     13  15  15   0   0  13  13  15  13  15   112
  46      0   1   0   0   0   0   0   0   0   0     1
  58      0   0   0   0   0   0   4   4   0   0     8
  Total  18  16  15   3   1  13  17  25  13  15   136



See ?addmargins for more information.

HTH,

Marc Schwartz


From h.wickham at gmail.com  Sun Sep 30 21:15:16 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 30 Sep 2007 14:15:16 -0500
Subject: [R] plot graph with error bars trouble
In-Reply-To: <loom.20070930T181742-99@post.gmane.org>
References: <a35fc1810709281003g67acdc56l96f759cf7324d0d0@mail.gmail.com>
	<loom.20070930T181742-99@post.gmane.org>
Message-ID: <f8e6ff050709301215j3e9b9ef9o1cb584a304e5835a@mail.gmail.com>

On 9/30/07, Ben Bolker <bolker at ufl.edu> wrote:
> Marcelo Laia <marcelolaia <at> gmail.com> writes:
>
> >
> > Hi,
> >
> > I have a data set like this:
> >
>
>  [snip]
>
> > I need to plot a graph OD over the time for each one mutant with error bars.
> >
> >
>
>
> ## I put your data in a temporary file, this reads it
> x = read.table("tempdata.txt",header=TRUE)
>
>
> ## compute means and standard errors
> ##  (no built-in function for standard error, so create one)
> ## also see ?aggregate, ?by
> means =  with(x,tapply(OD,list(Time,Mutant),mean))
> se = function(x) sd(x)/sqrt(length(x))
> ses = with(x,tapply(OD,list(Time,Mutant),se))
>
> ## time vector -- could also be unique(x$Time)
> times = as.numeric(rownames(means))
>
> ## plot the means
> matplot(times,means,type="b",lty=1,col=1:2,pch=1:2)
> library(plotrix)
> ## have to create the x-vector and color-vector "by hand"
> ##  it would be nice if there were a matplotCI, but there
> ## isn't (yet) ...
> plotCI(rep(times,2),means,ses,pch=NA,add=TRUE,
>           col=rep(1:2,each=nrow(means)))

I'd do this a little differently, using the reshape
(http://had.co.nz/reshape) and ggplot2 (http://had.co.nz/ggplot2)
packages:

library(reshape)
library(ggplot2)

# Get data in format required for reshape
df <- rename(df, c("OD" = "value"))

# Summarise and compute errors
se <- function(x) sd(x)/sqrt(length(x))
means <- cast(df, Mutant + Time ~ ., c(mean, se))

qplot(Time, mean, data=means, colour=Mutant, min = mean - se, max =
mean + se, geom=c("point","errorbar"))

# or maybe

qplot(Time, mean, data=means, colour=Mutant, min = mean - se, max =
mean + se, geom=c("line","errorbar"))

# or even

qplot(Time, mean, data=means, fill=Mutant, min = mean - se, max = mean
+ se, geom=c("ribbon", "line"))

Depending on the purpose of the error bars, you will want to adjust
their length.

Hadley

-- 
http://had.co.nz/


From bolker at zoo.ufl.edu  Sun Sep 30 22:05:32 2007
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Sun, 30 Sep 2007 16:05:32 -0400
Subject: [R] plot graph with error bars trouble
In-Reply-To: <f8e6ff050709301215j3e9b9ef9o1cb584a304e5835a@mail.gmail.com>
References: <a35fc1810709281003g67acdc56l96f759cf7324d0d0@mail.gmail.com>	
	<loom.20070930T181742-99@post.gmane.org>
	<f8e6ff050709301215j3e9b9ef9o1cb584a304e5835a@mail.gmail.com>
Message-ID: <4700018C.8020208@zoo.ufl.edu>

hadley wickham wrote:
> I'd do this a little differently, using the reshape
> (http://had.co.nz/reshape) and ggplot2 (http://had.co.nz/ggplot2)
> packages:
>
> library(reshape)
> library(ggplot2)
>
> # Get data in format required for reshape
> df <- rename(df, c("OD" = "value"))
>
> # Summarise and compute errors
> se <- function(x) sd(x)/sqrt(length(x))
> means <- cast(df, Mutant + Time ~ ., c(mean, se))
>
> qplot(Time, mean, data=means, colour=Mutant, min = mean - se, max =
> mean + se, geom=c("point","errorbar"))
>
>   

  I can certainly see the value of a more elegant/automated/higher-level 
solution
(although knowing the base-graphics way of going about it can be helpful 
too).

   However, at least the first plot you suggest looks a little bit funny 
to me.
Suppose that the x coordinates of the error
bar are x_L (left edge of bars), x_0 (middle of bars/location
of data point), and x_R (right edge of bars), and the y coordinates
are y_B, y_0, and y_U (bottom [min], middle, and top [max]).
The "errorbar" specification seems to add a series of
segments from (x_L,y_B) of one point to
(x_L,y_U) of the next  [sorry if this is confusing, but I'm trying
to describe a picture ...]

(1) this seems like a funny default (I wouldn't normally want this line
drawn if I specified "errorbars"), (2) even if one has the line,
 the x-positions of the segment endpoints still seem wrong (or at least 
a wrong default) -- I still
think they should line up with the x-coordinates of the data

  Poking around http://had.co.nz/ggplot2/geom_errorbar.html hasn't 
resolved this (yet).

  I thought that breaking it down a bit might help, but it appears to do 
the same thing ...

p = ggplot(means, aes(x=Time, y=mean, 
colour=Mutant,min=mean-se,max=mean+se))
p + geom_errorbar()

  Can you see what I mean, or am I confused/have an old version/etc. ?

  cheers
    Ben

 > sessionInfo()
R version 2.5.1 (2007-06-27)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United 
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] "splines"   "grid"      "stats"     "graphics"  "grDevices" 
"utils"     "datasets"  "methods"   "base"    

other attached packages:
     ggplot2   colorspace RColorBrewer         MASS        proto      
reshape
     "0.5.5"       "0.95"      "1.0-1"     "7.2-36"      "0.3-8"      
"0.8.0"

 

PS if one specifies "errorbars" without specifying min and max one gets 
the error

Error in rbind(max, max, max, min, min, min) :
        cannot coerce type closure to list vector

  perhaps a more transparent error message could be supplied in this 
(admittedly
stupid-user-error-obvious-in-hindsight) case?


From h.wickham at gmail.com  Sun Sep 30 22:40:23 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 30 Sep 2007 15:40:23 -0500
Subject: [R] plot graph with error bars trouble
In-Reply-To: <4700018C.8020208@zoo.ufl.edu>
References: <a35fc1810709281003g67acdc56l96f759cf7324d0d0@mail.gmail.com>
	<loom.20070930T181742-99@post.gmane.org>
	<f8e6ff050709301215j3e9b9ef9o1cb584a304e5835a@mail.gmail.com>
	<4700018C.8020208@zoo.ufl.edu>
Message-ID: <f8e6ff050709301340t41202413gab1a8135fef80465@mail.gmail.com>

> hadley wickham wrote:
> > I'd do this a little differently, using the reshape
> > (http://had.co.nz/reshape) and ggplot2 (http://had.co.nz/ggplot2)
> > packages:
> >
> > library(reshape)
> > library(ggplot2)
> >
> > # Get data in format required for reshape
> > df <- rename(df, c("OD" = "value"))
> >
> > # Summarise and compute errors
> > se <- function(x) sd(x)/sqrt(length(x))
> > means <- cast(df, Mutant + Time ~ ., c(mean, se))
> >
> > qplot(Time, mean, data=means, colour=Mutant, min = mean - se, max =
> > mean + se, geom=c("point","errorbar"))
> >
> >
>
>   I can certainly see the value of a more elegant/automated/higher-level
> solution
> (although knowing the base-graphics way of going about it can be helpful
> too).
>
>    However, at least the first plot you suggest looks a little bit funny
> to me.
> Suppose that the x coordinates of the error
> bar are x_L (left edge of bars), x_0 (middle of bars/location
> of data point), and x_R (right edge of bars), and the y coordinates
> are y_B, y_0, and y_U (bottom [min], middle, and top [max]).
> The "errorbar" specification seems to add a series of
> segments from (x_L,y_B) of one point to
> (x_L,y_U) of the next  [sorry if this is confusing, but I'm trying
> to describe a picture ...]
>
> (1) this seems like a funny default (I wouldn't normally want this line
> drawn if I specified "errorbars"), (2) even if one has the line,
>  the x-positions of the segment endpoints still seem wrong (or at least
> a wrong default) -- I still
> think they should line up with the x-coordinates of the data
>
>   Poking around http://had.co.nz/ggplot2/geom_errorbar.html hasn't
> resolved this (yet).
>
>   I thought that breaking it down a bit might help, but it appears to do
> the same thing ...
>
> p = ggplot(means, aes(x=Time, y=mean,
> colour=Mutant,min=mean-se,max=mean+se))
> p + geom_errorbar()
>
>   Can you see what I mean, or am I confused/have an old version/etc. ?
>

Oooooh - oops.  I completely forgot about that error - it's fixed in
the current development version of ggplot which I should probably
think about uploading to CRAN.

> PS if one specifies "errorbars" without specifying min and max one gets
> the error
>
> Error in rbind(max, max, max, min, min, min) :
>         cannot coerce type closure to list vector
>
>   perhaps a more transparent error message could be supplied in this
> (admittedly
> stupid-user-error-obvious-in-hindsight) case?

Yes, that's a good idea.  I'm still working on making the error
messages more user friendly.  I think I'm making some progress, but
it's fairly slow.

Hadley


-- 
http://had.co.nz/


From jo.irisson at gmail.com  Sun Sep 30 23:24:32 2007
From: jo.irisson at gmail.com (jiho)
Date: Sun, 30 Sep 2007 23:24:32 +0200
Subject: [R] plot graph with error bars trouble
In-Reply-To: <f8e6ff050709301340t41202413gab1a8135fef80465@mail.gmail.com>
References: <a35fc1810709281003g67acdc56l96f759cf7324d0d0@mail.gmail.com>
	<loom.20070930T181742-99@post.gmane.org>
	<f8e6ff050709301215j3e9b9ef9o1cb584a304e5835a@mail.gmail.com>
	<4700018C.8020208@zoo.ufl.edu>
	<f8e6ff050709301340t41202413gab1a8135fef80465@mail.gmail.com>
Message-ID: <14443710-B9B6-4E03-A7C3-74348DE02070@gmail.com>

On 2007-September-30  , at 22:40 , hadley wickham wrote:
>> hadley wickham wrote:
>>> [...]
>> PS if one specifies "errorbars" without specifying min and max one  
>> gets
>> the error
>>
>> Error in rbind(max, max, max, min, min, min) :
>>         cannot coerce type closure to list vector
>>
>>   perhaps a more transparent error message could be supplied in this
>> (admittedly
>> stupid-user-error-obvious-in-hindsight) case?
>
> Yes, that's a good idea.  I'm still working on making the error
> messages more user friendly.  I think I'm making some progress, but
> it's fairly slow.

BTW, have you thought about opening ggplot2 development (provide a  
way to check out the dev code and have the possibility to submit  
patches at least) or do you prefer to keep it a personal project for  
now? I don't know how intricate your research and the development of  
ggplot2 are and would understand that you want to keep in 100% hadley  
wickham if you are to be judged on it academically. But boring work  
such as improving error messages, writing documentation and chasing  
small bugs is probably more efficiently done by a team than by a  
single person, with little free time. Furthermore, most of these  
things can be done without deep knowledge of the architecture of  
ggplot2.
I probably won' t be able to make significant contributions before a  
while but I would be happy to see how ggplot2 progresses and which  
directions are taken by following an SVN tree.

JiHO
---
http://jo.irisson.free.fr/


From Chris.French at mh.org.au  Sat Sep 29 14:02:31 2007
From: Chris.French at mh.org.au (French, Chris)
Date: Sat, 29 Sep 2007 22:02:31 +1000
Subject: [R] help with within subject modelling of experimental data
Message-ID: <796392EE1C4D81428FEB0F6068BFD19A045931C5@nwhmail.ssg.org.au>


Dear R-project

I'm sure this is a very simple problem, but I've not been able to find a good example to guide me (and I'm very new to R). 

I have been looking at time constants of inactivation (rate of turn-off) of sodium channel currents in neurons at 5 different potentials, looking to see if there is an overall significant differences between normal (wild-type) and a mutated form of sodium channel. I have ten WT and 10 mutant sets of data. 

I gather that I should use within-subject modeling,and then use the unequal-variances t statistic to compare the means to look for a significant difference. I was wondering a) if this was the best procedure and b) how to do this in R

Many thanks

Chris French
Neurology
Royal Melbourne Hospital


From donghohk at hotmail.com  Sun Sep 30 03:12:32 2007
From: donghohk at hotmail.com (Kim Donghoh)
Date: Sun, 30 Sep 2007 01:12:32 +0000
Subject: [R] memory size
Message-ID: <BAY111-F37E3AF1E7B4E4FB660B2E6C9AC0@phx.gbl>

Hello, R users.

I need help. When I run one of my own functions, I got follwoing error 
message.
 
Error: cannot allocate vector of size 350493 Kb

So I check the memory size.

> memory.limit()
[1] 1610612736

Is it enough for vector of size 350493 Kb? Am I missing something?

Thank you for your reply in advance.

_________________________________________________________________
?????????? ???????? ?? ???? ???????? MSN Hotmail?? ???? ??????.


From ninerh at gmail.com  Sat Sep 29 18:14:13 2007
From: ninerh at gmail.com (Yi-Min Huang)
Date: Sat, 29 Sep 2007 09:14:13 -0700
Subject: [R] [Help] Error when using nls
In-Reply-To: <844BF683-37F5-451D-B14C-38D2AFB9CE9B@gmail.com>
References: <947CDD25-F02A-4F69-A8BE-57098E1F2329@gmail.com>
	<844BF683-37F5-451D-B14C-38D2AFB9CE9B@gmail.com>
Message-ID: <4A9510BF-82B9-416D-B9B9-6B660DDCF582@gmail.com>

Thank you Charilaos, I think I misunderstood the 'selfStart'. After  
checking 'selfStart', I think I don't have the ability to create a  
selfStart object. I don't have good sense to guess the initial  
values. So I tried 'poor guess' by nls. But I got erroe message as:

Error in c * (ev^2) : non-numeric argument to binary operator


I don't understand what this means. If I take out 'c', and run nls  
with poor guess, I got error message as:

Error in nls(N ~ CSR/(1/(a + b * ev + (ev^2)) + CSR/(d + e * exp(f *  
ev))) -  :
	singular gradient

and a warning message of 'no staring values for some parameters'.

What should I do to correct the errors? Is there any way that can  
help me to guess the initial values?
I attached my R script and the data set I used. Any comment is  
appreciated. Thank you very much.


??
----------------------------------------------------
Yi-Min Huang
ninerh at gmail.com



On Sep 29, 2007, at 6:49 AM, Charilaos Skiadas wrote:

> On Sep 29, 2007, at 12:00 AM, Niner wrote:
>
>> Hi,
>>
>>      I am a student of Earthquake Engineering, and am new to R.
>> Currently I try to run nonlinear regression analysis by R. My data
>> has three variables: X, Y, and Z. Z is a function of (X, Y). My R
>> script is as below.
>
> In general it is recommended that you provide reproducible code,
> typically using one of the built in data sets instead of a data set
> of your own that we have no access to.
>
>> # call nls funciton
>> out <- nls(Z~X/(1/(a+b*ev+c*(Y^2))+X/(d+e*exp(f*Y)))-g, data1,
>> selfStart, trace=T)
>>
>>
>> In total there are 59 sets of (X,Y,Z). When I run this script, I got
>> the error message as:
>>
>> parameters without starting value in 'data': a, b, d, e, f, g
>>
>>
>> I don't know what this means. Besides, I use "selfStart" option, such
>> that the nls is supposed to run by finding the initial values of
>> (a,b,c,d,e,f,g) itself. Why the nls asks me to give the starting
>> values?
>
> "selfStart" is not an "option", it is a function which you would use
> to construct the self-starting object. Look at ?selfStart for an
> example on how to use it.
> To the best of my understanding, you need to either:
> 1) provide starting values (what I would recommend, if you have a
> sense for the range), or
> 2) provide R with a mechanism for finding the starting values (via
> constructing a selfStart object, see ?selfStart), or
> 3) ask R to make very poor guesses, by leaving the start argument
> empty [  out <- nls(Z~X/(1/(a+b*ev+c*(Y^2))+X/(d+e*exp(f*Y)))-g,
> data1, trace=T)   ]
> which has a high chance of choking out on you. In an example I just
> tried, R set all the parameter values to 1.
>
>> What should I do next? Does anyone can explain the meaning of the
>> error message?
>> Any comment is appreciated. Thanks a lot.
>>
>>
>> Regards,
>> Niner
>> ----------------------------------------------------
>> Niner, Seattle
>> ninerdummy at gmail.com
>>
>
> Haris Skiadas
> Department of Mathematics and Computer Science
> Hanover College
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


