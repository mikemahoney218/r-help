From andrejfavia at ml1.net  Mon Jun  1 01:49:57 2015
From: andrejfavia at ml1.net (andrejfavia at ml1.net)
Date: Sun, 31 May 2015 19:49:57 -0400
Subject: [R] How do I move the horizontal axis in a plot so that it
 starts at the zero of the vertical axis?
Message-ID: <1433116197.2569072.283014113.14F69D8F@webmail.messagingengine.com>

Alright but then if I include an aspect ratio, the y-axis no longer
starts at 0 at the bottom of the plot.

x <- c(-2.5, -1.3, 0.6, 0.8, 2.1)
y <- c(0.3, 1.9, 1.4, 0.7, 1.1)

plot(x, y, ylim=c(0, 2), yaxs="i", asp=1.25)


From boris.steipe at utoronto.ca  Mon Jun  1 05:32:26 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 31 May 2015 23:32:26 -0400
Subject: [R] How do I move the horizontal axis in a plot so that it
	starts at the zero of the vertical axis?
In-Reply-To: <1433116197.2569072.283014113.14F69D8F@webmail.messagingengine.com>
References: <1433116197.2569072.283014113.14F69D8F@webmail.messagingengine.com>
Message-ID: <1080833B-5E6E-449B-BE6C-0D908C1903AF@utoronto.ca>

Like this?

x <- c(-2.5, -1.3, 0.6, 0.8, 2.1)
y <- c(0.3, 1.9, 1.4, 0.7, 1.1)

plot(x, y, ylim=c(0, 2), axes=FALSE, asp=1.25)
box()
abline(h=0)
axis(side=1, pos=0.0, lwd=0, lwd.ticks=1)
axis(side=2, lwd=0, lwd.ticks=1)

B.

On May 31, 2015, at 7:49 PM, andrejfavia at ml1.net wrote:

> x <- c(-2.5, -1.3, 0.6, 0.8, 2.1)
> y <- c(0.3, 1.9, 1.4, 0.7, 1.1)
> 
> plot(x, y, ylim=c(0, 2), yaxs="i", asp=1.25)


From ivo.welch at gmail.com  Mon Jun  1 12:24:18 2015
From: ivo.welch at gmail.com (ivo welch)
Date: Mon, 1 Jun 2015 12:24:18 +0200
Subject: [R] lattice contourplots
Message-ID: <CAPr7RtXxSg=REfBSPYQm2gQz34W2n-VYNW_ZYUGmwoM1BAOPLQ@mail.gmail.com>

Dear R (3.2.0, osx) experts:  I would like to create contourplots from
irregular data frames (i.e., not a matrix on a grid).    I am getting
inconsistent results from lattice contourplot().  sometimes it works
(quartz plot on contours), sometimes it doesn't (blank plot = nada).
I have tried variations from
http://stackoverflow.com/questions/10805093/contour-plot-from-data-frame
, but I do not understand the problem here.  contourplot gives no
error messages.

an example is

    require(lattice)

    d <- data.frame( x =  (1:30 + rnorm(30)), y = (1:30 + rnorm(30)) )
    d <- within(d, z <- sin(x+y))

    quartz()
    contourplot( z ~ x * y, data = d)

am I committing an error, or is there something more robust or at
least verbose, perhaps?

help appreciated.  /iaw

----
Ivo Welch (ivo.welch at gmail.com)
http://www.ivo-welch.info/


From jdnewmil at dcn.davis.CA.us  Mon Jun  1 13:02:00 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 01 Jun 2015 07:02:00 -0400
Subject: [R] lattice contourplots
In-Reply-To: <CAPr7RtXxSg=REfBSPYQm2gQz34W2n-VYNW_ZYUGmwoM1BAOPLQ@mail.gmail.com>
References: <CAPr7RtXxSg=REfBSPYQm2gQz34W2n-VYNW_ZYUGmwoM1BAOPLQ@mail.gmail.com>
Message-ID: <6B2AD50F-BC8D-42B4-8D40-379D5AE2853B@dcn.davis.CA.us>

What does quartz() have to do with this? If quartz is the problem, R-sig-mac would be a better place to ask. Or are you being bitten by R FAQ 7.22?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 1, 2015 6:24:18 AM EDT, ivo welch <ivo.welch at gmail.com> wrote:
>Dear R (3.2.0, osx) experts:  I would like to create contourplots from
>irregular data frames (i.e., not a matrix on a grid).    I am getting
>inconsistent results from lattice contourplot().  sometimes it works
>(quartz plot on contours), sometimes it doesn't (blank plot = nada).
>I have tried variations from
>http://stackoverflow.com/questions/10805093/contour-plot-from-data-frame
>, but I do not understand the problem here.  contourplot gives no
>error messages.
>
>an example is
>
>    require(lattice)
>
>    d <- data.frame( x =  (1:30 + rnorm(30)), y = (1:30 + rnorm(30)) )
>    d <- within(d, z <- sin(x+y))
>
>    quartz()
>    contourplot( z ~ x * y, data = d)
>
>am I committing an error, or is there something more robust or at
>least verbose, perhaps?
>
>help appreciated.  /iaw
>
>----
>Ivo Welch (ivo.welch at gmail.com)
>http://www.ivo-welch.info/
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Mon Jun  1 13:29:52 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 01 Jun 2015 07:29:52 -0400
Subject: [R] lattice contourplots
In-Reply-To: <6B2AD50F-BC8D-42B4-8D40-379D5AE2853B@dcn.davis.CA.us>
References: <CAPr7RtXxSg=REfBSPYQm2gQz34W2n-VYNW_ZYUGmwoM1BAOPLQ@mail.gmail.com>
	<6B2AD50F-BC8D-42B4-8D40-379D5AE2853B@dcn.davis.CA.us>
Message-ID: <A10F6E68-C0E2-4B14-99E6-6F078988FC40@dcn.davis.CA.us>

The help for for contourplot answers this question in the description of the formula (x) argument.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 1, 2015 7:02:00 AM EDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>What does quartz() have to do with this? If quartz is the problem,
>R-sig-mac would be a better place to ask. Or are you being bitten by R
>FAQ 7.22?
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                     Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>---------------------------------------------------------------------------
>
>Sent from my phone. Please excuse my brevity.
>
>On June 1, 2015 6:24:18 AM EDT, ivo welch <ivo.welch at gmail.com> wrote:
>>Dear R (3.2.0, osx) experts:  I would like to create contourplots from
>>irregular data frames (i.e., not a matrix on a grid).    I am getting
>>inconsistent results from lattice contourplot().  sometimes it works
>>(quartz plot on contours), sometimes it doesn't (blank plot = nada).
>>I have tried variations from
>>http://stackoverflow.com/questions/10805093/contour-plot-from-data-frame
>>, but I do not understand the problem here.  contourplot gives no
>>error messages.
>>
>>an example is
>>
>>    require(lattice)
>>
>>    d <- data.frame( x =  (1:30 + rnorm(30)), y = (1:30 + rnorm(30)) )
>>    d <- within(d, z <- sin(x+y))
>>
>>    quartz()
>>    contourplot( z ~ x * y, data = d)
>>
>>am I committing an error, or is there something more robust or at
>>least verbose, perhaps?
>>
>>help appreciated.  /iaw
>>
>>----
>>Ivo Welch (ivo.welch at gmail.com)
>>http://www.ivo-welch.info/
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ivo.welch at gmail.com  Mon Jun  1 14:39:29 2015
From: ivo.welch at gmail.com (ivo welch)
Date: Mon, 1 Jun 2015 14:39:29 +0200
Subject: [R] lattice contourplots
In-Reply-To: <A10F6E68-C0E2-4B14-99E6-6F078988FC40@dcn.davis.CA.us>
References: <CAPr7RtXxSg=REfBSPYQm2gQz34W2n-VYNW_ZYUGmwoM1BAOPLQ@mail.gmail.com>
	<6B2AD50F-BC8D-42B4-8D40-379D5AE2853B@dcn.davis.CA.us>
	<A10F6E68-C0E2-4B14-99E6-6F078988FC40@dcn.davis.CA.us>
Message-ID: <CAPr7RtX+DV2twe13+tNokw7+sTYecgpDGT5Or_7AG4Kd00hfJw@mail.gmail.com>

thank you.  yes, I got bitten by "FAQ 7.22: Why do lattice/trellis
graphics not work?"  It had never occurred to me that this could be
expected behavior or a FAQ.  (didn't show up in a google search for
contourplot.)  Unless one knows, this is a puzzler.  Thanks for the
pointer.  so, a minimum working example is

    require(lattice)
    d <- data.frame( expand.grid( x = seq(0,6,length.out=100), y =
seq(0,6,length.out=100) ) )
    d <- within(d, z <- sin( (x+y) ))
    xx <- contourplot( z ~ x * y, data = d)
    print(xx)  ## necessary in source code, but not in interactive mode

regards, /iaw


----
Ivo Welch (ivo.welch at gmail.com)
http://www.ivo-welch.info/
J. Fred Weston Professor of Finance
Anderson School at UCLA, C519
Director, UCLA Anderson Fink Center for Finance and Investments
Free Finance Textbook, http://book.ivo-welch.info/
Editor, Critical Finance Review, http://www.critical-finance-review.org/



On Mon, Jun 1, 2015 at 1:29 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> The help for for contourplot answers this question in the description of the formula (x) argument.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On June 1, 2015 7:02:00 AM EDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>What does quartz() have to do with this? If quartz is the problem,
>>R-sig-mac would be a better place to ask. Or are you being bitten by R
>>FAQ 7.22?
>>---------------------------------------------------------------------------
>>Jeff Newmiller                        The     .....       .....  Go
>>Live...
>>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>Go...
>>                                     Live:   OO#.. Dead: OO#..  Playing
>>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>/Software/Embedded Controllers)               .OO#.       .OO#.
>>rocks...1k
>>---------------------------------------------------------------------------
>>
>>Sent from my phone. Please excuse my brevity.
>>
>>On June 1, 2015 6:24:18 AM EDT, ivo welch <ivo.welch at gmail.com> wrote:
>>>Dear R (3.2.0, osx) experts:  I would like to create contourplots from
>>>irregular data frames (i.e., not a matrix on a grid).    I am getting
>>>inconsistent results from lattice contourplot().  sometimes it works
>>>(quartz plot on contours), sometimes it doesn't (blank plot = nada).
>>>I have tried variations from
>>>http://stackoverflow.com/questions/10805093/contour-plot-from-data-frame
>>>, but I do not understand the problem here.  contourplot gives no
>>>error messages.
>>>
>>>an example is
>>>
>>>    require(lattice)
>>>
>>>    d <- data.frame( x =  (1:30 + rnorm(30)), y = (1:30 + rnorm(30)) )
>>>    d <- within(d, z <- sin(x+y))
>>>
>>>    quartz()
>>>    contourplot( z ~ x * y, data = d)
>>>
>>>am I committing an error, or is there something more robust or at
>>>least verbose, perhaps?
>>>
>>>help appreciated.  /iaw
>>>
>>>----
>>>Ivo Welch (ivo.welch at gmail.com)
>>>http://www.ivo-welch.info/
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>


From wht_crl at yahoo.com  Mon Jun  1 15:46:15 2015
From: wht_crl at yahoo.com (carol white)
Date: Mon, 1 Jun 2015 13:46:15 +0000 (UTC)
Subject: [R] merge function
Message-ID: <749715693.2559022.1433166375876.JavaMail.yahoo@mail.yahoo.com>

Hi,By default the merge function should take the intersection of column names (if this is understood from by = intersect(names(x), names(y)), but it takes all columns. How to specify the intersection of column names?
?Thanks
Carol

	[[alternative HTML version deleted]]


From sreenath.rajur at macfast.ac.in  Mon Jun  1 13:12:14 2015
From: sreenath.rajur at macfast.ac.in (sreenath)
Date: Mon, 1 Jun 2015 04:12:14 -0700 (PDT)
Subject: [R] Colour gradient is not working.
Message-ID: <1433157134298-4708000.post@n4.nabble.com>

I have a table of 33291 rows. When i try to plot the graph with gradient
colour using "colorRampPalette" command but the out put graph is colourless
or in black colour.But when i try the same command with small values it is
working why it so?

Color <- colorRampPalette(c("red","blue"))

plot(x,y,col=Color(33292))




--
View this message in context: http://r.789695.n4.nabble.com/Colour-gradient-is-not-working-tp4708000.html
Sent from the R help mailing list archive at Nabble.com.


From bgunter.4567 at gmail.com  Mon Jun  1 16:04:50 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 1 Jun 2015 07:04:50 -0700
Subject: [R] merge function
In-Reply-To: <749715693.2559022.1433166375876.JavaMail.yahoo@mail.yahoo.com>
References: <749715693.2559022.1433166375876.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbRjXiKPWvZQZfPxfPpjf5imqD4ffRhVHzb1hHoajidK7A@mail.gmail.com>

1. Please read and follow the posting guide.

2. Reproducible example? (... at least I don't understand what you mean)

3. Plain text, not HTML.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Mon, Jun 1, 2015 at 6:46 AM, carol white via R-help <r-help at r-project.org
> wrote:

> Hi,By default the merge function should take the intersection of column
> names (if this is understood from by = intersect(names(x), names(y)), but
> it takes all columns. How to specify the intersection of column names?
>  Thanks
> Carol
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Mon Jun  1 16:29:41 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 1 Jun 2015 06:29:41 -0800
Subject: [R] merge function
In-Reply-To: <749715693.2559022.1433166375876.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <A4B79E34E82.00000061jrkrideau@inbox.com>

As Burt says it is not exactly clear what you want but is something like this what you are looking for?

dat1  <-  data.frame(aa = c("a", "b", "c"), bb = 1:3)
dat2  <-  data.frame(xx = c("b", "c", "d"), yy = 3:1)
merge(dat1, dat2, by.x = "aa", by.y = "xx")

For further reference here are some suggestions about asking questions on the R-help list.  In particular it is very helpful if data is supplied in dput() form (See ?dput for details)

John Kane
Kingston ON Canada


> -----Original Message-----
> From: r-help at r-project.org
> Sent: Mon, 1 Jun 2015 13:46:15 +0000 (UTC)
> To: r-help at r-project.org
> Subject: [R] merge function
> 
> Hi,By default the merge function should take the intersection of column
> names (if this is understood from by = intersect(names(x), names(y)), but
> it takes all columns. How to specify the intersection of column names?
> ?Thanks
> Carol
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From jrkrideau at inbox.com  Mon Jun  1 16:31:04 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 1 Jun 2015 06:31:04 -0800
Subject: [R] merge function
In-Reply-To: <A4B79E34E82.00000061jrkrideau@inbox.com>
References: <749715693.2559022.1433166375876.javamail.yahoo@mail.yahoo.com>
Message-ID: <A4BABB43C1F.00000067jrkrideau@inbox.com>

Let me try this again. Here are the links I forgot. My apologies.
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jrkrideau at inbox.com
> Sent: Mon, 1 Jun 2015 06:29:41 -0800
> To: wht_crl at yahoo.com, r-help at r-project.org
> Subject: RE: [R] merge function
> 
> As Burt says it is not exactly clear what you want but is something like
> this what you are looking for?
> 
> dat1  <-  data.frame(aa = c("a", "b", "c"), bb = 1:3)
> dat2  <-  data.frame(xx = c("b", "c", "d"), yy = 3:1)
> merge(dat1, dat2, by.x = "aa", by.y = "xx")
> 
> For further reference here are some suggestions about asking questions on
> the R-help list.  In particular it is very helpful if data is supplied in
> dput() form (See ?dput for details)
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: r-help at r-project.org
>> Sent: Mon, 1 Jun 2015 13:46:15 +0000 (UTC)
>> To: r-help at r-project.org
>> Subject: [R] merge function
>> 
>> Hi,By default the merge function should take the intersection of column
>> names (if this is understood from by = intersect(names(x), names(y)),
>> but
>> it takes all columns. How to specify the intersection of column names?
>> ?Thanks
>> Carol
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/manager

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From lists at dewey.myzen.co.uk  Mon Jun  1 16:32:22 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 01 Jun 2015 15:32:22 +0100
Subject: [R] merge function
In-Reply-To: <749715693.2559022.1433166375876.JavaMail.yahoo@mail.yahoo.com>
References: <749715693.2559022.1433166375876.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <556C6CF6.1010702@dewey.myzen.co.uk>



On 01/06/2015 14:46, carol white via R-help wrote:
> Hi,By default the merge function should take the intersection of column names

  (if this is understood from by = intersect(names(x), names(y)),

Dear Carol
The by parameter specifies which columns are used to merge by. Did you 
understand it to be which columns are retained in the result?

Just a hunch, and if not then you need to give us a toy example.



  but it takes all columns. How to specify the intersection of column names?
>   Thanks
> Carol
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From dcarlson at tamu.edu  Mon Jun  1 16:37:18 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 1 Jun 2015 14:37:18 +0000
Subject: [R] Colour gradient is not working.
In-Reply-To: <1433157134298-4708000.post@n4.nabble.com>
References: <1433157134298-4708000.post@n4.nabble.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68FCF1@mb02.ads.tamu.edu>

Your example is not reproducible. You pass 33292 colors to plot, but never specify how to use them so only the first color (red) is used. If it worked with a smaller number of colors, you were using something other than the default plot function. If it works with a smaller number of colors, but not more, you may have overloaded the plot device. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of sreenath
Sent: Monday, June 1, 2015 6:12 AM
To: r-help at r-project.org
Subject: [R] Colour gradient is not working.

I have a table of 33291 rows. When i try to plot the graph with gradient
colour using "colorRampPalette" command but the out put graph is colourless
or in black colour.But when i try the same command with small values it is
working why it so?

Color <- colorRampPalette(c("red","blue"))

plot(x,y,col=Color(33292))




--
View this message in context: http://r.789695.n4.nabble.com/Colour-gradient-is-not-working-tp4708000.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wht_crl at yahoo.com  Mon Jun  1 16:47:07 2015
From: wht_crl at yahoo.com (carol white)
Date: Mon, 1 Jun 2015 14:47:07 +0000 (UTC)
Subject: [R] merge function
In-Reply-To: <556C6CF6.1010702@dewey.myzen.co.uk>
References: <556C6CF6.1010702@dewey.myzen.co.uk>
Message-ID: <1901932587.2627049.1433170027121.JavaMail.yahoo@mail.yahoo.com>

I understood that by would take the intersection of names(x) and names(y), names(x) being the column names of x and names(y), column names of y.
if x has 5 col and the col names of x are col1, col2... col5 and y has 3 col and their names are col1, col2, col3, I thought that the merged data set will have 3 col, namely col1, col2, col3 but all 5 col, i.e. col1, col2... col5 are taken if nothing is specified for the by arg.
Cheers,
 


     On Monday, June 1, 2015 4:32 PM, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
   

 

On 01/06/2015 14:46, carol white via R-help wrote:
> Hi,By default the merge function should take the intersection of column names

? (if this is understood from by = intersect(names(x), names(y)),

Dear Carol
The by parameter specifies which columns are used to merge by. Did you 
understand it to be which columns are retained in the result?

Just a hunch, and if not then you need to give us a toy example.



? but it takes all columns. How to specify the intersection of column names?
>? Thanks
> Carol
>
> ??? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


  
	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Mon Jun  1 16:59:46 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 1 Jun 2015 10:59:46 -0400
Subject: [R] Colour gradient is not working.
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D68FCF1@mb02.ads.tamu.edu>
References: <1433157134298-4708000.post@n4.nabble.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D68FCF1@mb02.ads.tamu.edu>
Message-ID: <B59D2E2D-55B8-477F-9C26-176D2A312A79@utoronto.ca>

1. Don't use Nabble for the r-help mailing list.

2. Read the posting guide, and read http://adv-r.had.co.nz/Reproducibility.html

3. The following code works for me. Your error is not due to requesting too many colours...

n <- 100000
x <- rnorm(n)
y <- rnorm(n)
myPalette <- colorRampPalette(c("red", "blue"))
plot(x, y, pch = ".", col = myPalette(n))

... although (obviously) most of the 100,000 colour values are the same:

R > length(unique(myPalette(n)))
[1] 259



B.


On Jun 1, 2015, at 10:37 AM, David L Carlson <dcarlson at tamu.edu> wrote:

> Your example is not reproducible. You pass 33292 colors to plot, but never specify how to use them so only the first color (red) is used. If it worked with a smaller number of colors, you were using something other than the default plot function. If it works with a smaller number of colors, but not more, you may have overloaded the plot device. 
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of sreenath
> Sent: Monday, June 1, 2015 6:12 AM
> To: r-help at r-project.org
> Subject: [R] Colour gradient is not working.
> 
> I have a table of 33291 rows. When i try to plot the graph with gradient
> colour using "colorRampPalette" command but the out put graph is colourless
> or in black colour.But when i try the same command with small values it is
> working why it so?
> 
> Color <- colorRampPalette(c("red","blue"))
> 
> plot(x,y,col=Color(33292))
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Colour-gradient-is-not-working-tp4708000.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Mon Jun  1 17:15:47 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 1 Jun 2015 15:15:47 +0000
Subject: [R] Colour gradient is not working.
In-Reply-To: <1433157134298-4708000.post@n4.nabble.com>
References: <1433157134298-4708000.post@n4.nabble.com>
Message-ID: <D191C501.12C8FB%macqueen1@llnl.gov>

Try this
   plot(1:33292, 1:33292,col=Color(33292))
and then decide again whether or not it is working.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/1/15, 4:12 AM, "sreenath" <sreenath.rajur at macfast.ac.in> wrote:

>I have a table of 33291 rows. When i try to plot the graph with gradient
>colour using "colorRampPalette" command but the out put graph is
>colourless
>or in black colour.But when i try the same command with small values it is
>working why it so?
>
>Color <- colorRampPalette(c("red","blue"))
>
>plot(x,y,col=Color(33292))
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Colour-gradient-is-not-working-tp4708000.htm
>l
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From cadeb at usgs.gov  Mon Jun  1 17:16:03 2015
From: cadeb at usgs.gov (Cade, Brian)
Date: Mon, 1 Jun 2015 09:16:03 -0600
Subject: [R] alternatives to KS test applicable to K-samples
In-Reply-To: <F5122165-BEB9-4EA9-8AB0-712520E3036C@comcast.net>
References: <CAKyN3iBv73_FUsmH2S0nqsann4E-CqMPCt5+0XVwEX2PD50jzQ@mail.gmail.com>
	<CAM5M9BQzfdP9JKtKDvbd4uwHgjrNNwQDEOhi-q+cPhPHn26Jsg@mail.gmail.com>
	<F5122165-BEB9-4EA9-8AB0-712520E3036C@comcast.net>
Message-ID: <CAM5M9BQqZsZ59e1u8vAdH9guho1GP=q8Wq_A302B5uO+K=272w@mail.gmail.com>

Not sure what the issue is here.  If I click on the link I provided, I go
right to the USGS page where instructions for downloading the software are
provided.

Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326


On Sat, May 30, 2015 at 3:11 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On May 29, 2015, at 10:02 AM, Cade, Brian wrote:
>
> > Wensui:  There are the multi-response permutation procedures (MRPP) that
> > readily test the omnibus hypothesis of no distributional differences
> among
> > multiple samples for univariate or multivariate responses.  There also
> are
> > empirical coverage tests that test a similar hypothesis among multiple
> > samples but only for univariate responses.  Both are included in the USGS
> > Blossom package for R linked here:
> > https://www.fort.usgs.gov/products/23735 (not yet distributed via CRAN).
>
> I did not find a link to an actual package at that page nor on any of the
> others to which it linked.
>
> > The MRPP may also be available in other R packages on CRAN (vegan ?).
>
> There is an mrpp function in pkg:vegan although its help page description
> made me think it depended (at least in its default mode) on the
> squared-deviations from means. I'd suggest using CRAN Task View: Robust
> Statistical Methods  (Maintainer: Martin Maechler) for searching for
> alternative methods.
>
> --
> David.
>
>
> >
> > Brian
> >
> > Brian S. Cade, PhD
> >
> > U. S. Geological Survey
> > Fort Collins Science Center
> > 2150 Centre Ave., Bldg. C
> > Fort Collins, CO  80526-8818
> >
> > email:  cadeb at usgs.gov <brian_cade at usgs.gov>
> > tel:  970 226-9326
> >
> >
> > On Fri, May 29, 2015 at 10:31 AM, Wensui Liu <liuwensui at gmail.com>
> wrote:
> >
> >> Good morning, All
> >> I have a stat question not specifically related to the the programming
> >> language.
> >> To compare distributional consistency / discrepancy between two
> >> samples, we usually use kolmogorov-smirnov test, which is implemented
> >> in R with ks.test() or in SAS with "pro npar1way edf".
> >> I am wondering if there is any alternative to KS test that could be
> >> generalized to K-samples.
> >>
> >> Thanks and have a nice weekend.
> >>
> >> wensui
> >
>
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Jun  1 18:22:12 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 1 Jun 2015 09:22:12 -0700
Subject: [R] lattice contourplots
In-Reply-To: <CAPr7RtX+DV2twe13+tNokw7+sTYecgpDGT5Or_7AG4Kd00hfJw@mail.gmail.com>
References: <CAPr7RtXxSg=REfBSPYQm2gQz34W2n-VYNW_ZYUGmwoM1BAOPLQ@mail.gmail.com>
	<6B2AD50F-BC8D-42B4-8D40-379D5AE2853B@dcn.davis.CA.us>
	<A10F6E68-C0E2-4B14-99E6-6F078988FC40@dcn.davis.CA.us>
	<CAPr7RtX+DV2twe13+tNokw7+sTYecgpDGT5Or_7AG4Kd00hfJw@mail.gmail.com>
Message-ID: <AA7552ED-5EDF-49BA-BDEC-4F15CE37415E@comcast.net>


On Jun 1, 2015, at 5:39 AM, ivo welch wrote:

> thank you.  yes, I got bitten by "FAQ 7.22: Why do lattice/trellis
> graphics not work?"  It had never occurred to me that this could be
> expected behavior or a FAQ.  (didn't show up in a google search for
> contourplot.)  Unless one knows, this is a puzzler.  Thanks for the
> pointer.  so, a minimum working example is
> 
>    require(lattice)
>    d <- data.frame( expand.grid( x = seq(0,6,length.out=100), y =
> seq(0,6,length.out=100) ) )
>    d <- within(d, z <- sin( (x+y) ))
>    xx <- contourplot( z ~ x * y, data = d)
>    print(xx)  ## necessary in source code, but not in interactive mode

I do not think FAQ 7.22 was the problem. Look at the structure of your two different 'd' objects. One of them had the proper long form of an x-y grid with z values while the other one did not. (Also a Mac user but this has nothing to do with Macs.) I was getting a "blank plot" with your first version but getting the expected contours at minus 45 degrees for the second version regardless of any print commands. But my "blank plot had axes that had an appropriate range but was empty inside (no contours) so it wasn't a completely empty plotting event. I don't think `contourplot` was able to make any sense out of the completely irregular data in the first instance. I do agree with Newmiller's second guess that the description of x (i.e.formula) on the help page is the correct reference, but I think you misinterpreted his meaning. 

-- 
David.


> 
> regards, /iaw
> 
> 
> ----
> Ivo Welch (ivo.welch at gmail.com)
> http://www.ivo-welch.info/
> J. Fred Weston Professor of Finance
> Anderson School at UCLA, C519
> Director, UCLA Anderson Fink Center for Finance and Investments
> Free Finance Textbook, http://book.ivo-welch.info/
> Editor, Critical Finance Review, http://www.critical-finance-review.org/
> 
> 
> 
> On Mon, Jun 1, 2015 at 1:29 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> The help for for contourplot answers this question in the description of the formula (x) argument.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                      Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>> 
>> On June 1, 2015 7:02:00 AM EDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>> What does quartz() have to do with this? If quartz is the problem,
>>> R-sig-mac would be a better place to ask. Or are you being bitten by R
>>> FAQ 7.22?
>>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>>> Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>> Go...
>>>                                    Live:   OO#.. Dead: OO#..  Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>> rocks...1k
>>> ---------------------------------------------------------------------------
>>> 
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On June 1, 2015 6:24:18 AM EDT, ivo welch <ivo.welch at gmail.com> wrote:
>>>> Dear R (3.2.0, osx) experts:  I would like to create contourplots from
>>>> irregular data frames (i.e., not a matrix on a grid).    I am getting
>>>> inconsistent results from lattice contourplot().  sometimes it works
>>>> (quartz plot on contours), sometimes it doesn't (blank plot = nada).
>>>> I have tried variations from
>>>> http://stackoverflow.com/questions/10805093/contour-plot-from-data-frame
>>>> , but I do not understand the problem here.  contourplot gives no
>>>> error messages.
>>>> 
>>>> an example is
>>>> 
>>>>   require(lattice)
>>>> 
>>>>   d <- data.frame( x =  (1:30 + rnorm(30)), y = (1:30 + rnorm(30)) )
>>>>   d <- within(d, z <- sin(x+y))
>>>> 
>>>>   quartz()
>>>>   contourplot( z ~ x * y, data = d)
>>>> 
>>>> am I committing an error, or is there something more robust or at
>>>> least verbose, perhaps?
>>>> 
>>>> help appreciated.  /iaw
>>>> 
>>>> ----
>>>> Ivo Welch (ivo.welch at gmail.com)
>>>> http://www.ivo-welch.info/
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Mon Jun  1 18:32:11 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 1 Jun 2015 09:32:11 -0700
Subject: [R] merge function
In-Reply-To: <1901932587.2627049.1433170027121.JavaMail.yahoo@mail.yahoo.com>
References: <556C6CF6.1010702@dewey.myzen.co.uk>
	<1901932587.2627049.1433170027121.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbRxdBz2aSw_iSS2DLbqXPvxRCGLFW-QQydhAdEeykogyA@mail.gmail.com>

You do not appear to understand what merge() does. Go through the worked
examples in ?merge so that you do.

FWIW, I would agree that the Help file is cryptic and difficult to
understand. Perhaps going through a tutorial on database "join" operations
might help.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Mon, Jun 1, 2015 at 7:47 AM, carol white via R-help <r-help at r-project.org
> wrote:

> I understood that by would take the intersection of names(x) and names(y),
> names(x) being the column names of x and names(y), column names of y.
> if x has 5 col and the col names of x are col1, col2... col5 and y has 3
> col and their names are col1, col2, col3, I thought that the merged data
> set will have 3 col, namely col1, col2, col3 but all 5 col, i.e. col1,
> col2... col5 are taken if nothing is specified for the by arg.
> Cheers,
>
>
>
>      On Monday, June 1, 2015 4:32 PM, Michael Dewey <
> lists at dewey.myzen.co.uk> wrote:
>
>
>
>
> On 01/06/2015 14:46, carol white via R-help wrote:
> > Hi,By default the merge function should take the intersection of column
> names
>
>   (if this is understood from by = intersect(names(x), names(y)),
>
> Dear Carol
> The by parameter specifies which columns are used to merge by. Did you
> understand it to be which columns are retained in the result?
>
> Just a hunch, and if not then you need to give us a toy example.
>
>
>
>   but it takes all columns. How to specify the intersection of column
> names?
> >  Thanks
> > Carol
> >
> >     [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bhadrarajarshi9 at gmail.com  Mon Jun  1 22:03:55 2015
From: bhadrarajarshi9 at gmail.com (Rajarshi Bhadra)
Date: Tue, 2 Jun 2015 01:33:55 +0530
Subject: [R] Imposing linear binding constraint while using Rcgmin
Message-ID: <CAFOno_aNQsXjiT4Z+9Koxig=7ji83Lzv9e4iVXqVxLX+xGHXzg@mail.gmail.com>

Is there any way by which I can impose a linear binding constraint while
using Rcgmin for a non linear optimization exercise?

	[[alternative HTML version deleted]]


From ivo.welch at anderson.ucla.edu  Mon Jun  1 23:03:13 2015
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Mon, 1 Jun 2015 23:03:13 +0200
Subject: [R] combine trellis lattice contour plot with simple plot()
 points() and text() commands?
Message-ID: <CAPr7RtVD9Ey+1ET1RecxJeTUx0G3SPpOqgDSs7_Am1QT44KE6w@mail.gmail.com>

can I add ordinary graphics commands to a contourplot?  my naive
attempts are telling me that plot.new() has not yet been called when I
try to add text(1,1,"hi") or points( c(0,1), c(1,0) )?

[or do I need to rewrite another contourplot with the old graphics
system.  the basics are probably looking at adjacent points,
pretending that they are linear, and mark where a line between them
intercepts the level, and then hope that some sanity prevents me from
connecting disconnected levels.  not my plan...]

----
Ivo Welch (ivo.welch at gmail.com)
http://www.ivo-welch.info/


From jdnewmil at dcn.davis.CA.us  Mon Jun  1 23:32:34 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 01 Jun 2015 17:32:34 -0400
Subject: [R] lattice contourplots
In-Reply-To: <AA7552ED-5EDF-49BA-BDEC-4F15CE37415E@comcast.net>
References: <CAPr7RtXxSg=REfBSPYQm2gQz34W2n-VYNW_ZYUGmwoM1BAOPLQ@mail.gmail.com>
	<6B2AD50F-BC8D-42B4-8D40-379D5AE2853B@dcn.davis.CA.us>
	<A10F6E68-C0E2-4B14-99E6-6F078988FC40@dcn.davis.CA.us>
	<CAPr7RtX+DV2twe13+tNokw7+sTYecgpDGT5Or_7AG4Kd00hfJw@mail.gmail.com>
	<AA7552ED-5EDF-49BA-BDEC-4F15CE37415E@comcast.net>
Message-ID: <EA2F7220-5CFE-4132-AEAF-AAF6619930A8@dcn.davis.CA.us>

Sorry, my first response was too hasty. Per the help file you need to use some kind of interpolation method to resample whatever random data points you have in a regular grid before you give it to contourplot.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 1, 2015 12:22:12 PM EDT, David Winsemius <dwinsemius at comcast.net> wrote:
>
>On Jun 1, 2015, at 5:39 AM, ivo welch wrote:
>
>> thank you.  yes, I got bitten by "FAQ 7.22: Why do lattice/trellis
>> graphics not work?"  It had never occurred to me that this could be
>> expected behavior or a FAQ.  (didn't show up in a google search for
>> contourplot.)  Unless one knows, this is a puzzler.  Thanks for the
>> pointer.  so, a minimum working example is
>> 
>>    require(lattice)
>>    d <- data.frame( expand.grid( x = seq(0,6,length.out=100), y =
>> seq(0,6,length.out=100) ) )
>>    d <- within(d, z <- sin( (x+y) ))
>>    xx <- contourplot( z ~ x * y, data = d)
>>    print(xx)  ## necessary in source code, but not in interactive
>mode
>
>I do not think FAQ 7.22 was the problem. Look at the structure of your
>two different 'd' objects. One of them had the proper long form of an
>x-y grid with z values while the other one did not. (Also a Mac user
>but this has nothing to do with Macs.) I was getting a "blank plot"
>with your first version but getting the expected contours at minus 45
>degrees for the second version regardless of any print commands. But my
>"blank plot had axes that had an appropriate range but was empty inside
>(no contours) so it wasn't a completely empty plotting event. I don't
>think `contourplot` was able to make any sense out of the completely
>irregular data in the first instance. I do agree with Newmiller's
>second guess that the description of x (i.e.formula) on the help page
>is the correct reference, but I think you misinterpreted his meaning.


From jrkrideau at inbox.com  Tue Jun  2 00:04:39 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 1 Jun 2015 14:04:39 -0800
Subject: [R] merge function
In-Reply-To: <1901932587.2627049.1433170027121.JavaMail.yahoo@mail.yahoo.com>
References: <556c6cf6.1010702@dewey.myzen.co.uk>
Message-ID: <A8B08C83C6F.0000021Bjrkrideau@inbox.com>

Exactly what I thought too the first time I read ?merge. R sometimes has its own approach.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: r-help at r-project.org
> Sent: Mon, 1 Jun 2015 14:47:07 +0000 (UTC)
> To: lists at dewey.myzen.co.uk, r-help at r-project.org
> Subject: Re: [R] merge function
> 
> I understood that by would take the intersection of names(x) and
> names(y), names(x) being the column names of x and names(y), column names
> of y.
> if x has 5 col and the col names of x are col1, col2... col5 and y has 3
> col and their names are col1, col2, col3, I thought that the merged data
> set will have 3 col, namely col1, col2, col3 but all 5 col, i.e. col1,
> col2... col5 are taken if nothing is specified for the by arg.
> Cheers,
> 
> 
> 
>      On Monday, June 1, 2015 4:32 PM, Michael Dewey
> <lists at dewey.myzen.co.uk> wrote:
> 
> 
> 
> 
> On 01/06/2015 14:46, carol white via R-help wrote:
>> Hi,By default the merge function should take the intersection of column
>> names
> 
> ? (if this is understood from by = intersect(names(x), names(y)),
> 
> Dear Carol
> The by parameter specifies which columns are used to merge by. Did you
> understand it to be which columns are retained in the result?
> 
> Just a hunch, and if not then you need to give us a toy example.
> 
> 
> 
> ? but it takes all columns. How to specify the intersection of column
> names?
> >? Thanks
>> Carol
>> 
>> ??? [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From dwinsemius at comcast.net  Tue Jun  2 02:22:10 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 1 Jun 2015 17:22:10 -0700
Subject: [R] combine trellis lattice contour plot with simple plot()
	points() and text() commands?
In-Reply-To: <CAPr7RtVD9Ey+1ET1RecxJeTUx0G3SPpOqgDSs7_Am1QT44KE6w@mail.gmail.com>
References: <CAPr7RtVD9Ey+1ET1RecxJeTUx0G3SPpOqgDSs7_Am1QT44KE6w@mail.gmail.com>
Message-ID: <A5FC5054-6FB7-47FE-B3AD-5311CE48E0EF@comcast.net>


On Jun 1, 2015, at 2:03 PM, ivo welch wrote:

> can I add ordinary graphics commands to a contourplot?  my naive
> attempts are telling me that plot.new() has not yet been called when I
> try to add text(1,1,"hi") or points( c(0,1), c(1,0) )?

There are lattice equivalents to many of the base primitives. They can be used inside lattice/trellis functions or used later if the plots have been save to names.

?llines
?trellis.focus

Also take a look at the lattice Extra and gridBase packages for additional faclities like these.

Examples requested for demonstration ... as always but using your earleir example:

 myplot=     contourplot( z ~ x * y, data = d)
 myplot
 trellis.focus("panel",1,1)
 llines(x=3, y=1:5)  #draws a blue segment on the screen device
NULL
 trellis.unfocus()

But that is not going to change myplot. For that you need ?update.trellis or latticeExtra's version of "+".


-- 
david.
> 
> [or do I need to rewrite another contourplot with the old graphics
> system.  the basics are probably looking at adjacent points,
> pretending that they are linear, and mark where a line between them
> intercepts the level, and then hope that some sanity prevents me from
> connecting disconnected levels.  not my plan...]
> 
> ----
> Ivo Welch (ivo.welch at gmail.com)
> http://www.ivo-welch.info/
> 
> ____


David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Tue Jun  2 02:24:42 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 2 Jun 2015 10:24:42 +1000
Subject: [R] combine trellis lattice contour plot with simple plot()
 points() and text() commands?
In-Reply-To: <CAPr7RtVD9Ey+1ET1RecxJeTUx0G3SPpOqgDSs7_Am1QT44KE6w@mail.gmail.com>
References: <CAPr7RtVD9Ey+1ET1RecxJeTUx0G3SPpOqgDSs7_Am1QT44KE6w@mail.gmail.com>
Message-ID: <CA+8X3fU+R33sve5UmB3jbUC62D0s1G6rhixDdfwV3xiZGcdy+g@mail.gmail.com>

Hi Ivo,
Not in a sane way. Have a look at the latticeExtra package that allows
most of these things to be done.

Jim


On Tue, Jun 2, 2015 at 7:03 AM, ivo welch <ivo.welch at anderson.ucla.edu> wrote:
> can I add ordinary graphics commands to a contourplot?  my naive
> attempts are telling me that plot.new() has not yet been called when I
> try to add text(1,1,"hi") or points( c(0,1), c(1,0) )?
>
> [or do I need to rewrite another contourplot with the old graphics
> system.  the basics are probably looking at adjacent points,
> pretending that they are linear, and mark where a line between them
> intercepts the level, and then hope that some sanity prevents me from
> connecting disconnected levels.  not my plan...]
>
> ----
> Ivo Welch (ivo.welch at gmail.com)
> http://www.ivo-welch.info/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Tue Jun  2 02:44:26 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 2 Jun 2015 10:44:26 +1000
Subject: [R] combine trellis lattice contour plot with simple plot()
	points() and text() commands?
In-Reply-To: <CAPr7RtVD9Ey+1ET1RecxJeTUx0G3SPpOqgDSs7_Am1QT44KE6w@mail.gmail.com>
References: <CAPr7RtVD9Ey+1ET1RecxJeTUx0G3SPpOqgDSs7_Am1QT44KE6w@mail.gmail.com>
Message-ID: <000001d09ccd$473b9420$d5b2bc60$@bigpond.com>

Hi Ivo

If you want to add lines, text etc you can do that by a  lattice panel
function included in it would be panel.contour

something like (untested)

contourplot(...
                       panel = function(x,y, etc,...){
            
                                        panel.countorplot(x,y, etc)
 
                                       panel.lines(x,y,...)
                                       panel.text(....)
                                  }
)

and see also
library(lattice)
names(trellis.par.get())
and delve into the names that come up that are applicable

See the help page

? panel.lines which should cover most of what you need.
Remember that you may have to look at 
? grid::gpar for fine tuning of the arguments

Just finished a plot with panel.segments

panel.segments(xlocs - medsbar.len, meds,
               xlocs + medsbar.len, meds,
               lineend = 1, # grid gpar call for line ending
               lwd = 5,
               col = 2)

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of ivo welch
Sent: Tuesday, 2 June 2015 07:03
To: r-help
Subject: [R] combine trellis lattice contour plot with simple plot()
points() and text() commands?

can I add ordinary graphics commands to a contourplot?  my naive
attempts are telling me that plot.new() has not yet been called when I
try to add text(1,1,"hi") or points( c(0,1), c(1,0) )?

[or do I need to rewrite another contourplot with the old graphics
system.  the basics are probably looking at adjacent points,
pretending that they are linear, and mark where a line between them
intercepts the level, and then hope that some sanity prevents me from
connecting disconnected levels.  not my plan...]

----
Ivo Welch (ivo.welch at gmail.com)
http://www.ivo-welch.info/

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From simon.wood at bath.edu  Mon Jun  1 23:00:42 2015
From: simon.wood at bath.edu (Simon Wood)
Date: Mon, 01 Jun 2015 22:00:42 +0100
Subject: [R] How to make new predictions from a GAM with a spline forced
 through the origin
In-Reply-To: <10b60797f23b4d65a0163e5330c212ab@exch07.campus.bath.ac.uk>
References: <10b60797f23b4d65a0163e5330c212ab@exch07.campus.bath.ac.uk>
Message-ID: <556CC7FA.90000@bath.edu>

Hi Gavan,

After running the code in your message, do something like this...

xp <- c(.2,.3) ## x values for prediction
Xp <- PredictMat(sm,data.frame(x=xp))[,-3] ## prediction matrix
yp <- predict(b,list(X=Xp,off=rep(.6,2)))  ## call predict.gam
points(xp,yp,col=2) ## plot points

... hope that's clear enough, let me know if not.

best,
Simon


On 29/05/15 13:12, Gavan McGrath wrote:
> Hi,
>
> I?m followed an example to fit a GAM with a spline forced through a point, i.e. (0,0). This works fine from one of Simon?s examples however when it comes to making a prediction from a new set of x values I?m a bit stumped.
>
> In the example below a smooth term is constructed and the basis and penalties at x=0 are removed then the gam is fitted to a spline basis matrix X using spline penalties.
>
> Can someone suggest a way that I can make predictions at new  x  values based on the gam b below.
>
>
> Here is Simon Wood's example:
>
> library(mgcv)
> set.seed(0)
> n <- 100
> x <- runif(n)*4-1;x <- sort(x);
> f <- exp(4*x)/(1+exp(4*x));y <- f+rnorm(100)*0.1;plot(x,y)
> dat <- data.frame(x=x,y=y)
>
> ## Create a spline basis and penalty, making sure there is a knot
> ## at the constraint point, (0 here, but could be anywhere)
> knots <- data.frame(x=seq(-1,3,length=9)) ## create knots
> ## set up smoother...
> sm <- smoothCon(s(x,k=9,bs="cr"),dat,knots=knots)[[1]]
>
> ## 3rd parameter is value of spline at knot location 0,
> ## set it to 0 by dropping...
> X <- sm$X[,-3]        ## spline basis
> S <- sm$S[[1]][-3,-3] ## spline penalty
> off <- y*0 + .6       ## offset term to force curve through (0, .6)
>
> ## fit spline constrained through (0, .6)...
> b <- gam(y ~ X - 1 + offset(off),paraPen=list(X=list(S)))
> lines(x,predict(b))
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From mauricioromerolondono at gmail.com  Tue Jun  2 00:56:05 2015
From: mauricioromerolondono at gmail.com (Mauricio Romero)
Date: Mon, 1 Jun 2015 15:56:05 -0700
Subject: [R] Bug in raster projectRaster?
Message-ID: <CAPjE+LSRROW7HmaUh0g99s0uFpjwFUb5JJJf0Vn6s71ZDP=nog@mail.gmail.com>

Hi,

I'm sorry I cant post a reproducible example, but the data sets involve are
too large. I'm currently trying to create a mosaic from 2 different Landsat
7 scenes. One of them is in UTM 18 and the other in UTM 17. Before using
the mosaic command, I'm doing

LandsatTransform=projectRaster(from=LandsatUTM17, to=LandsatUTM18)

but i get a raster that is full of NAs and the following warning message

Warning message:
In .rasterFromRasterFile(grdfile, band = band, objecttype, ...) :
  size of values file does not match the number of cells (given the data
type)

Not sure what to do. Any help is really appreciated.

Thanks,

Mauricio

	[[alternative HTML version deleted]]


From Onoriode.Coast at csiro.au  Tue Jun  2 04:54:03 2015
From: Onoriode.Coast at csiro.au (Onoriode.Coast at csiro.au)
Date: Tue, 2 Jun 2015 02:54:03 +0000
Subject: [R] nls and four parameter estimates
Message-ID: <D736F454355006429DA41754A53FFDBB43D4E817@exmbx06-cdc.nexus.csiro.au>

Hello all!

I am trying to estimate four parameters (mu, sigma, theta and lambda) of a model
Using the nls package in R, I can only get it to work if I limit the number of parameters to be estimated to three (i.e. mu, sigma and theta) as in the first model - mod1 - below. Including a fourth parameter (lambda) like in the second model - mod2 - returns the following error messages

1.       Error in numericDeriv(form[[3L]], names(ind), env):

2.       Missing value or an infinity produced when evaluating the model

mod1<-nls(germ~1-(exp(-1*((psi-(theta/time)-mu)/sigma))),start=c(mu=-2.7, theta=3, sigma=3), data=ht)
mod1

mod2<-nls(germ~1-(exp(-1*((psi-(theta/time)-mu)/sigma)^lambda)),start=c(mu=-2.7, theta=3, sigma=3, lambda=-1.2), data=ht)
mod2

Please have a look at my code and tell how I might get it to work. A sample of my data is shown below. It has five levels of psi (0, -0.4, -0.8, -1.2 and -1.6).

psi

time

germ

0

1.333333

0

0

1.416667

0

0

1.5

0.04

0

1.583333

0.04

0

2.083333

0.08

0

2.166667

0.16

0

2.25

0.24

0

2.583333

0.64

0

2.666667

0.72

0

2.916667

1

.
.
.
-1.6

2.916667

0

-1.6

3.166667

0

-1.6

3.666667

0

-1.6

7.666667

0

-1.6

9.666667

0

-1.6

12.66667

0

-1.6

19.66667

0


Dr Onoriode Coast
Postdoctoral Fellow
Agriculture Flagship
CSIRO
E onoriode.coast at csiro.au T +61 2 6799 1541 M 0477 386 110
21888 Kamilaroi Highway, Narrabri, NSW, 2390 Australia
www.csiro.au

	[[alternative HTML version deleted]]


From kridox at ymail.com  Tue Jun  2 08:48:10 2015
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 2 Jun 2015 15:48:10 +0900
Subject: [R] Bug in raster projectRaster?
In-Reply-To: <CAPjE+LSRROW7HmaUh0g99s0uFpjwFUb5JJJf0Vn6s71ZDP=nog@mail.gmail.com>
References: <CAPjE+LSRROW7HmaUh0g99s0uFpjwFUb5JJJf0Vn6s71ZDP=nog@mail.gmail.com>
Message-ID: <CAAcyNCwySmPggWEBLV-+xvoCgFfxiYw-jpCt2DRYisoXJ_KptQ@mail.gmail.com>

Wrong list. This should have been posted here: r-sig-geo at r-project.org

Regards,
Pascal

On Tue, Jun 2, 2015 at 7:56 AM, Mauricio Romero
<mauricioromerolondono at gmail.com> wrote:
> Hi,
>
> I'm sorry I cant post a reproducible example, but the data sets involve are
> too large. I'm currently trying to create a mosaic from 2 different Landsat
> 7 scenes. One of them is in UTM 18 and the other in UTM 17. Before using
> the mosaic command, I'm doing
>
> LandsatTransform=projectRaster(from=LandsatUTM17, to=LandsatUTM18)
>
> but i get a raster that is full of NAs and the following warning message
>
> Warning message:
> In .rasterFromRasterFile(grdfile, band = band, objecttype, ...) :
>   size of values file does not match the number of cells (given the data
> type)
>
> Not sure what to do. Any help is really appreciated.
>
> Thanks,
>
> Mauricio
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From benjamin.dubreuil at weizmann.ac.il  Tue Jun  2 12:37:04 2015
From: benjamin.dubreuil at weizmann.ac.il (Benjamin Dubreuil)
Date: Tue, 2 Jun 2015 10:37:04 +0000
Subject: [R] Scatterplot : smoothing colors according to density of points
Message-ID: <6E68B6E864DACF4C890BA4AA3D87139238C71C83@IBWMBX02>

Hello everyone,

I have a data frame D with 4 columns id,X,Y,C.
I want to plot a simple scatter plot of D$X vs. D$Y and using D$C values as a color. (id is just a text string not used for the plot)

But actually, I don't want to use the raw values of D$C, I would prefer to calculate the average values of D$C according to the density of points in a fixed neighborhood.
In other words, I would like to smooth the colors according to the density of points.

I am looking for any function,package that could solve this.
So far, I've been looking at library MASS and the function kde2d which can calculate the density of points in 2 directions, but I don't see how I could then use this information to recalculate my D$C values.

Here is a piece of the matrix :
 > head(D)
      id         X         Y            C
1 O13297 44.444444  21.61220 -0.136651639
2 O13329 31.272085   4.01590 -0.117016949
3 O13525  6.865672   2.43884 -0.161173913
4 O13539 14.176245   7.81217 -0.075756757
5 O13541 73.275862   3.59012 -0.006988235
6 O13547 28.991597 258.99900 -0.013985507

> dim(D)
[1] 3616    4

> apply(D[,-1],2,range)
               X          Y          C
[1,]   0.3378378     0.0003 -0.7382222
[2,] 100.0000000 24556.4000  0.5582500
(Y is not linear, so I use log='y' in the plot function)

I used a palette of 100 colors ranging from Blue to Yellow to red.
>pal =  colorRampPalette(c("blue","yellow","red"))(100)

To make D$C values correspond to a color, I used a cut with the following breaks (101 breaks from -1.2 to 1.2):
> BREAKS
  [1] -1.2000 -0.8000 -0.4000 -0.3600 -0.3200 -0.2800 -0.2400 -0.2000 -0.1925
 [10] -0.1850 -0.1775 -0.1700 -0.1625 -0.1550 -0.1475 -0.1400 -0.1368 -0.1336
 [19] -0.1304 -0.1272 -0.1240 -0.1208 -0.1176 -0.1144 -0.1112 -0.1080 -0.1048
 [28] -0.1016 -0.0984 -0.0952 -0.0920 -0.0888 -0.0856 -0.0824 -0.0792 -0.0760
 [37] -0.0728 -0.0696 -0.0664 -0.0632 -0.0600 -0.0568 -0.0536 -0.0504 -0.0472
 [46] -0.0440 -0.0408 -0.0376 -0.0344 -0.0312 -0.0280 -0.0248 -0.0216 -0.0184
 [55] -0.0152 -0.0120 -0.0088 -0.0056 -0.0024  0.0008  0.0040  0.0072  0.0104
 [64]  0.0136  0.0168  0.0200  0.0232  0.0264  0.0296  0.0328  0.0360  0.0392
 [73]  0.0424  0.0456  0.0488  0.0520  0.0552  0.0584  0.0616  0.0648  0.0680
 [82]  0.0712  0.0744  0.0776  0.0808  0.0840  0.0872  0.0904  0.0936  0.0968
 [91]  0.1000  0.1250  0.1500  0.1750  0.2000  0.2250  0.2500  0.4875  0.7250
[100]  0.9625  1.2000
> C.levels = as.numeric(cut(D$C,breaks=BREAKS))
>length(C.levels)
[1] 3616

C.levels ranges from 2 to 98 and then to plot the colors I used pal[C.levels].
> plot( x=D$x, y=D$Y, col=pal[ C.levels ],log='y')



	[[alternative HTML version deleted]]


From sreenath.rajur at macfast.ac.in  Tue Jun  2 10:39:15 2015
From: sreenath.rajur at macfast.ac.in (sreenath)
Date: Tue, 2 Jun 2015 01:39:15 -0700 (PDT)
Subject: [R] Colour gradient is not working.
In-Reply-To: <D191C501.12C8FB%macqueen1@llnl.gov>
References: <1433157134298-4708000.post@n4.nabble.com>
	<D191C501.12C8FB%macqueen1@llnl.gov>
Message-ID: <1433234355275-4708036.post@n4.nabble.com>

sir i done this plot(1:33292, 1:33292,col=Color(33292)) command then it gives
the coloured line but again it is not working  in my data why?



--
View this message in context: http://r.789695.n4.nabble.com/Colour-gradient-is-not-working-tp4708000p4708036.html
Sent from the R help mailing list archive at Nabble.com.


From B.Ward at uea.ac.uk  Tue Jun  2 14:26:41 2015
From: B.Ward at uea.ac.uk (Benjamin Ward (ENV))
Date: Tue, 2 Jun 2015 12:26:41 +0000
Subject: [R] Combining multiple probability weights for the sample()
	function.
Message-ID: <142413609C0A60488585AB47438ECD9D0F684CC8@ueastfexch01.UEA.AC.UK>

Dear R-List,

I have a set of possibilities I want to sample from:

bases <- list(c('A', 'C'), c('A', 'G'), c('C', 'T'))
possibilities <- as.matrix(expand.grid(bases))

>possibilities
Var1 Var2 Var3
[1,] "A"  "A"  "C"
[2,] "C"  "A"  "C"
[3,] "A"  "G"  "C"
[4,] "C"  "G"  "C"
[5,] "A"  "A"  "T"
[6,] "C"  "A"  "T"
[7,] "A"  "G"  "T"
[8,] "C"  "G"  "T"

If I want to randomly sample one of these rows. If I do this, I find that it is 25% likely that my choice will have an identical first and last letter (e.g. [1,] "A"  "A"  "C"). It is also 25% likely that my choice will have an identical first and third letter (e.g. [4,] "C"  "G"  "C"). It is not likely at all that the second and third letter of my choice could be identical.

What I would like to do, is sample one of the rows, but given the constraint that the probability of drawing identical letters 1 and 2 should be 50% or 0.5, and at the same time the probability of drawing identical letters 1 and 3 should be 50%. I am unsure on how to do this, but I know it involves coming up with a modified set of weights for the sample() function. My progress is below, any advice is much appreciated.

Best Wishes,

Ben Ward, UEA.


So I have used the following code to come up with a matrix, which contains weighting according to each criteria:

possibilities <- as.matrix(expand.grid(bases))
  identities <- apply(possibilities, 1, function(x) c(x[1] == x[2], x[1] == x[3], x[2] == x[3]))
  prob <- matrix(rep(0, length(identities)), ncol = ncol(identities))
  consProb <- apply(identities, 1, function(x){0.5 / length(which(x))})
  polProb <- apply(identities, 1, function(x){0.5 / length(which(!x))})
  for(i in 1:nrow(identities)){
    prob[i, which(identities[i,])] <- consProb[i]
    prob[i, which(!identities[i,])] <- polProb[i]
  }
  rownames(prob) <- c("1==2", "1==3", "2==3")
  colnames(prob) <- apply(possibilities, 1, function(x)paste(x, collapse = ", "))

This code gives the following matrix:

                A, A, C    C, A, C          A, G, C        C, G, C       A, A, T         C, A, T       A, G, T       C, G, T
1==2 0.25000000 0.08333333 0.08333333 0.08333333 0.25000000 0.08333333 0.08333333 0.08333333
1==3 0.08333333 0.25000000 0.08333333 0.25000000 0.08333333 0.08333333 0.08333333 0.08333333
2==3 0.06250000 0.06250000 0.06250000 0.06250000 0.06250000 0.06250000 0.06250000 0.06250000

Each column is one of the choices from 'possibilities', and each row gives a series of weights based on three different criteria:

Row 1, that if it possible from the choices for letter 1 == letter 2, that combined chance be 50%.
Row 2, that if it possible from the choices for letter 1 == letter 3, that combined chance be 50%.
Row 3, that if it possible from the choices for letter 2 == letter 3, that combined chance be 50%.

So:

 If I used sample(x = 1:now(possibilities), size = 1, prob = prob[1,]) repeatedly, I expect about half the choices to contain identical letters 1 and 2.

 If I used sample(x = 1:now(possibilities), size = 1, prob = prob[2,]) repeatedly, I expect about half the choices to contain identical letters 1 and 3.

If I used sample(x = 1:now(possibilities), size = 1, prob = prob[3,]) repeatedly, I expect about half the choices to contain identical letters 2 and 3. Except that in this case, since it is not possible.

Note each row sums to 1.

What I would like to do - if it is possible - is combine these three sets of weights into one set, that when used with
sample(x = 1:nrow(possibilities, size = 1, prob = MAGICPROB) will give me a list of choices, where ~50% of them contain identical letters 1 and 2, AND ~50% of them contain identical letters 1 and 3, AND ~50% again contain identical letters 2 and 3 (except in this example as it is not possible from the choices).

Can multiple probability weightings be combined in such a manner?




	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Tue Jun  2 15:07:24 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 2 Jun 2015 09:07:24 -0400
Subject: [R] Colour gradient is not working.
In-Reply-To: <1433234355275-4708036.post@n4.nabble.com>
References: <1433157134298-4708000.post@n4.nabble.com>
	<D191C501.12C8FB%macqueen1@llnl.gov>
	<1433234355275-4708036.post@n4.nabble.com>
Message-ID: <CAM_vjunqUeo7cv6Pwo0sxGQ6qOyOujX4ZDPMXynajoReSiXwcg@mail.gmail.com>

> plot(1:33292, 1:33292,col=Color(33292))
Error in plot.xy(xy, type, ...) : could not find function "Color"

Please tell us what you're trying to accomplish. "not working" is rather vague.

Without a reproducible example that includes some sample data (fake is
fine), the code you used, and some clear idea of what output you
expect, it's impossible to figure out how to help you. Here are some
suggestions for creating a good reproducible example:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Sarah

On Tue, Jun 2, 2015 at 4:39 AM, sreenath <sreenath.rajur at macfast.ac.in> wrote:
> sir i done this plot(1:33292, 1:33292,col=Color(33292)) command then it gives
> the coloured line but again it is not working  in my data why?
>
>
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From nashjc at uottawa.ca  Tue Jun  2 15:21:28 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Tue, 02 Jun 2015 09:21:28 -0400
Subject: [R] Imposing linear binding constraint while using Rcgmin
In-Reply-To: <mailman.3.1433239202.17739.r-help@r-project.org>
References: <mailman.3.1433239202.17739.r-help@r-project.org>
Message-ID: <556DADD8.4020407@uottawa.ca>

I wrote Rcgmin to do bounds constraints only. Linear constraints are
much more complicated to include.

If your constraints are equality ones, you could "solve", but that could
make it awkward to evaluate the gradient.

For inequality constraints, especially if there are only a couple, I
think I'd try a penalty or barrier function. They tend to mess up the
scaling and slow things down, but generally give some idea of solutions.

Penalty function adds a penalty factor * "violation". Note that gradient
may need attention. i.e. penalizes being "outside" the constraint. No
use if you end up trying log(-something) or sqrt(-something).


Barrier adds cost "inside" the constraint to keep away from the
constraint. Generally you want it to be very small except "close",
and that is controlled by barrier control parameter. Again, you need to
watch the gradient is provided properly.

If possible avoid using numerical gradients for the penalty or barrier
because of the compromised scaling, though I would use them for a quick
and dirty test.

JN



> 
> Message: 18
> Date: Tue, 2 Jun 2015 01:33:55 +0530
> From: Rajarshi Bhadra <bhadrarajarshi9 at gmail.com>
> To: r-help at r-project.org
> Subject: [R] Imposing linear binding constraint while using Rcgmin
> Message-ID:
> 	<CAFOno_aNQsXjiT4Z+9Koxig=7ji83Lzv9e4iVXqVxLX+xGHXzg at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
> 
> Is there any way by which I can impose a linear binding constraint while
> using Rcgmin for a non linear optimization exercise?
> 
> 	[[alternative HTML version deleted]]
>


From nashjc at uottawa.ca  Tue Jun  2 15:26:37 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Tue, 02 Jun 2015 09:26:37 -0400
Subject: [R] nls and four parameter estimates
In-Reply-To: <mailman.3.1433239202.17739.r-help@r-project.org>
References: <mailman.3.1433239202.17739.r-help@r-project.org>
Message-ID: <556DAF0D.7070109@uottawa.ca>

Package nlmrt (function nlxb) tries to use symbolic derivatives. In
fact, Duncan Murdoch and I have a very slowly developing nls14 package
to substitute for nls that should advance this even further.

nlxb also allows "masked" (i.e., fixed) parameters, which would let you
combine your runs, fixing the fourth parameter for initial runs. It also
allows bounds constraints.

I suspect it should work better. I'd have tried it, but the data
provided was not easily decipherable. Was it HTML format?

JN

On 15-06-02 06:00 AM, r-help-request at r-project.org wrote:
> Message: 27
> Date: Tue, 2 Jun 2015 02:54:03 +0000
> From: <Onoriode.Coast at csiro.au>
> To: <r-help at r-project.org>
> Subject: [R] nls and four parameter estimates
> Message-ID:
> 	<D736F454355006429DA41754A53FFDBB43D4E817 at exmbx06-cdc.nexus.csiro.au>
> Content-Type: text/plain; charset="UTF-8"
> 
> Hello all!
> 
> I am trying to estimate four parameters (mu, sigma, theta and lambda) of a model
> Using the nls package in R, I can only get it to work if I limit the number of parameters to be estimated to three (i.e. mu, sigma and theta) as in the first model - mod1 - below. Including a fourth parameter (lambda) like in the second model - mod2 - returns the following error messages
> 
> 1.       Error in numericDeriv(form[[3L]], names(ind), env):
> 
> 2.       Missing value or an infinity produced when evaluating the model
> 
> mod1<-nls(germ~1-(exp(-1*((psi-(theta/time)-mu)/sigma))),start=c(mu=-2.7, theta=3, sigma=3), data=ht)
> mod1
> 
> mod2<-nls(germ~1-(exp(-1*((psi-(theta/time)-mu)/sigma)^lambda)),start=c(mu=-2.7, theta=3, sigma=3, lambda=-1.2), data=ht)
> mod2
> 
> Please have a look at my code and tell how I might get it to work. A sample of my data is shown below. It has five levels of psi (0, -0.4, -0.8, -1.2 and -1.6).
> 
> psi
> 
> time
> 
> germ
> 
> 0
> 
> 1.333333


From jvadams at usgs.gov  Tue Jun  2 15:51:01 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 2 Jun 2015 08:51:01 -0500
Subject: [R] Scatterplot : smoothing colors according to density of
	points
In-Reply-To: <6E68B6E864DACF4C890BA4AA3D87139238C71C83@IBWMBX02>
References: <6E68B6E864DACF4C890BA4AA3D87139238C71C83@IBWMBX02>
Message-ID: <CAN5YmCGEkKo0MvE63n0uo-CufA+syY4nxyZajz30rW2UCe8Sew@mail.gmail.com>

Try this.

Jean

D <- structure(list(
  id = structure(1:6, .Label = c("O13297", "O13329", "O13525",
    "O13539", "O13541", "O13547"), class = "factor"),
  X = c(44.444444, 31.272085, 6.865672, 14.176245, 73.275862,
    28.991597),
  Y = c(21.6122, 4.0159, 2.43884, 7.81217, 3.59012, 258.999)),
  .Names = c("id", "X", "Y"), class = "data.frame",
  row.names = c("1", "2", "3", "4", "5", "6"))

# define the number of colors
ncol <- 100
# define the radius of the neighborhood
distcut <- 30
pal <- colorRampPalette(c("blue", "yellow", "red"))(ncol)

# calculate the euclidean distance between all pairs of points, based on X,
Y coordinates
Ddist <- with(D, as.matrix(dist(cbind(X, Y), diag=TRUE, upper=TRUE)))
# count up the number of neighbors within distcut distance of each point
D$C <- apply(Ddist<distcut, 2, sum)
# use this count to define the levels (which will be then used to color
points in the plot
D$Clevels <- with(D,
  cut(C, breaks=seq(min(C), max(C), length.out=ncol+1),
    labels=FALSE, include.lowest=TRUE))

# plot the data
with(D, plot(X, Y, col=pal[Clevels], log="y", pch=16))



On Tue, Jun 2, 2015 at 5:37 AM, Benjamin Dubreuil <
benjamin.dubreuil at weizmann.ac.il> wrote:

> Hello everyone,
>
> I have a data frame D with 4 columns id,X,Y,C.
> I want to plot a simple scatter plot of D$X vs. D$Y and using D$C values
> as a color. (id is just a text string not used for the plot)
>
> But actually, I don't want to use the raw values of D$C, I would prefer to
> calculate the average values of D$C according to the density of points in a
> fixed neighborhood.
> In other words, I would like to smooth the colors according to the density
> of points.
>
> I am looking for any function,package that could solve this.
> So far, I've been looking at library MASS and the function kde2d which can
> calculate the density of points in 2 directions, but I don't see how I
> could then use this information to recalculate my D$C values.
>
> Here is a piece of the matrix :
>  > head(D)
>       id         X         Y            C
> 1 O13297 44.444444  21.61220 -0.136651639
> 2 O13329 31.272085   4.01590 -0.117016949
> 3 O13525  6.865672   2.43884 -0.161173913
> 4 O13539 14.176245   7.81217 -0.075756757
> 5 O13541 73.275862   3.59012 -0.006988235
> 6 O13547 28.991597 258.99900 -0.013985507
>
> > dim(D)
> [1] 3616    4
>
> > apply(D[,-1],2,range)
>                X          Y          C
> [1,]   0.3378378     0.0003 -0.7382222
> [2,] 100.0000000 24556.4000  0.5582500
> (Y is not linear, so I use log='y' in the plot function)
>
> I used a palette of 100 colors ranging from Blue to Yellow to red.
> >pal =  colorRampPalette(c("blue","yellow","red"))(100)
>
> To make D$C values correspond to a color, I used a cut with the following
> breaks (101 breaks from -1.2 to 1.2):
> > BREAKS
>   [1] -1.2000 -0.8000 -0.4000 -0.3600 -0.3200 -0.2800 -0.2400 -0.2000
> -0.1925
>  [10] -0.1850 -0.1775 -0.1700 -0.1625 -0.1550 -0.1475 -0.1400 -0.1368
> -0.1336
>  [19] -0.1304 -0.1272 -0.1240 -0.1208 -0.1176 -0.1144 -0.1112 -0.1080
> -0.1048
>  [28] -0.1016 -0.0984 -0.0952 -0.0920 -0.0888 -0.0856 -0.0824 -0.0792
> -0.0760
>  [37] -0.0728 -0.0696 -0.0664 -0.0632 -0.0600 -0.0568 -0.0536 -0.0504
> -0.0472
>  [46] -0.0440 -0.0408 -0.0376 -0.0344 -0.0312 -0.0280 -0.0248 -0.0216
> -0.0184
>  [55] -0.0152 -0.0120 -0.0088 -0.0056 -0.0024  0.0008  0.0040  0.0072
> 0.0104
>  [64]  0.0136  0.0168  0.0200  0.0232  0.0264  0.0296  0.0328  0.0360
> 0.0392
>  [73]  0.0424  0.0456  0.0488  0.0520  0.0552  0.0584  0.0616  0.0648
> 0.0680
>  [82]  0.0712  0.0744  0.0776  0.0808  0.0840  0.0872  0.0904  0.0936
> 0.0968
>  [91]  0.1000  0.1250  0.1500  0.1750  0.2000  0.2250  0.2500  0.4875
> 0.7250
> [100]  0.9625  1.2000
> > C.levels = as.numeric(cut(D$C,breaks=BREAKS))
> >length(C.levels)
> [1] 3616
>
> C.levels ranges from 2 to 98 and then to plot the colors I used
> pal[C.levels].
> > plot( x=D$x, y=D$Y, col=pal[ C.levels ],log='y')
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Tue Jun  2 15:57:05 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 2 Jun 2015 08:57:05 -0500
Subject: [R] Combining multiple probability weights for the sample()
	function.
In-Reply-To: <142413609C0A60488585AB47438ECD9D0F684CC8@ueastfexch01.UEA.AC.UK>
References: <142413609C0A60488585AB47438ECD9D0F684CC8@ueastfexch01.UEA.AC.UK>
Message-ID: <CAN5YmCE1n2BmsAz63iQOaKCFDzurUBbACs=Nc7Wd4Zk52C-nsw@mail.gmail.com>

Ben,

Perhaps I am missing something, but couldn't you simply reduce your
possibilities to:

possibilities[c(1, 5, 2, 4), ]
     Var1 Var2 Var3
[1,] "A"  "A"  "C"
[2,] "A"  "A"  "T"
[3,] "C"  "A"  "C"
[4,] "C"  "G"  "C"

If you sample from these four rows you will have a 50% chance that Var1 and
Var2 are equal and a 50% chance that Var1 and Var3 are equal.

Jean


On Tue, Jun 2, 2015 at 7:26 AM, Benjamin Ward (ENV) <B.Ward at uea.ac.uk>
wrote:

> Dear R-List,
>
> I have a set of possibilities I want to sample from:
>
> bases <- list(c('A', 'C'), c('A', 'G'), c('C', 'T'))
> possibilities <- as.matrix(expand.grid(bases))
>
> >possibilities
> Var1 Var2 Var3
> [1,] "A"  "A"  "C"
> [2,] "C"  "A"  "C"
> [3,] "A"  "G"  "C"
> [4,] "C"  "G"  "C"
> [5,] "A"  "A"  "T"
> [6,] "C"  "A"  "T"
> [7,] "A"  "G"  "T"
> [8,] "C"  "G"  "T"
>
> If I want to randomly sample one of these rows. If I do this, I find that
> it is 25% likely that my choice will have an identical first and last
> letter (e.g. [1,] "A"  "A"  "C"). It is also 25% likely that my choice will
> have an identical first and third letter (e.g. [4,] "C"  "G"  "C"). It is
> not likely at all that the second and third letter of my choice could be
> identical.
>
> What I would like to do, is sample one of the rows, but given the
> constraint that the probability of drawing identical letters 1 and 2 should
> be 50% or 0.5, and at the same time the probability of drawing identical
> letters 1 and 3 should be 50%. I am unsure on how to do this, but I know it
> involves coming up with a modified set of weights for the sample()
> function. My progress is below, any advice is much appreciated.
>
> Best Wishes,
>
> Ben Ward, UEA.
>
>
> So I have used the following code to come up with a matrix, which contains
> weighting according to each criteria:
>
> possibilities <- as.matrix(expand.grid(bases))
>   identities <- apply(possibilities, 1, function(x) c(x[1] == x[2], x[1]
> == x[3], x[2] == x[3]))
>   prob <- matrix(rep(0, length(identities)), ncol = ncol(identities))
>   consProb <- apply(identities, 1, function(x){0.5 / length(which(x))})
>   polProb <- apply(identities, 1, function(x){0.5 / length(which(!x))})
>   for(i in 1:nrow(identities)){
>     prob[i, which(identities[i,])] <- consProb[i]
>     prob[i, which(!identities[i,])] <- polProb[i]
>   }
>   rownames(prob) <- c("1==2", "1==3", "2==3")
>   colnames(prob) <- apply(possibilities, 1, function(x)paste(x, collapse =
> ", "))
>
> This code gives the following matrix:
>
>                 A, A, C    C, A, C          A, G, C        C, G, C
>  A, A, T         C, A, T       A, G, T       C, G, T
> 1==2 0.25000000 0.08333333 0.08333333 0.08333333 0.25000000 0.08333333
> 0.08333333 0.08333333
> 1==3 0.08333333 0.25000000 0.08333333 0.25000000 0.08333333 0.08333333
> 0.08333333 0.08333333
> 2==3 0.06250000 0.06250000 0.06250000 0.06250000 0.06250000 0.06250000
> 0.06250000 0.06250000
>
> Each column is one of the choices from 'possibilities', and each row gives
> a series of weights based on three different criteria:
>
> Row 1, that if it possible from the choices for letter 1 == letter 2, that
> combined chance be 50%.
> Row 2, that if it possible from the choices for letter 1 == letter 3, that
> combined chance be 50%.
> Row 3, that if it possible from the choices for letter 2 == letter 3, that
> combined chance be 50%.
>
> So:
>
>  If I used sample(x = 1:now(possibilities), size = 1, prob = prob[1,])
> repeatedly, I expect about half the choices to contain identical letters 1
> and 2.
>
>  If I used sample(x = 1:now(possibilities), size = 1, prob = prob[2,])
> repeatedly, I expect about half the choices to contain identical letters 1
> and 3.
>
> If I used sample(x = 1:now(possibilities), size = 1, prob = prob[3,])
> repeatedly, I expect about half the choices to contain identical letters 2
> and 3. Except that in this case, since it is not possible.
>
> Note each row sums to 1.
>
> What I would like to do - if it is possible - is combine these three sets
> of weights into one set, that when used with
> sample(x = 1:nrow(possibilities, size = 1, prob = MAGICPROB) will give me
> a list of choices, where ~50% of them contain identical letters 1 and 2,
> AND ~50% of them contain identical letters 1 and 3, AND ~50% again contain
> identical letters 2 and 3 (except in this example as it is not possible
> from the choices).
>
> Can multiple probability weightings be combined in such a manner?
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ecnolasco at gmail.com  Tue Jun  2 15:59:53 2015
From: ecnolasco at gmail.com (Erica Cseko Nolasco)
Date: Tue, 2 Jun 2015 10:59:53 -0300
Subject: [R] pairwise.t.test non numeric factors error
Message-ID: <CAMbrGjHztZFofwCAHrmMvQzycF6KcvSw50i=o_E0hcDoE0Rd3w@mail.gmail.com>

Dear listers,

I'm performing a PERMANOVA (adonis{vegan}) to compare the results (ROC,
TSS) of models based on two factors (model, algo). I was not able to find a
pairwise test for adonis, on PRIMER it would be a Tukey test. Though, I
chose to perform a pairwise.t.test what would be quite simple. However, no
matter I rearrange my response and factor vectors (as a factor or numeric)
it gives me the following error (the code on the bottom - Error in
complete.cases(x, y) :
  not all arguments have the same length). I also tried to make a list of
the vectors, but it also gives me the error 'Error in sort.list(y) : 'x'
must be atomic for 'sort.list' Have you called 'sort' on a list?'

I would appreciate any suggestions to solve this issue.

Best,

Erica

> setwd('D:\\Erica\\mestrado\\analises\\results')
> library(vegan)
> rest=read.table('results_permanova.txt',sep="\t",header=T)
> rest$modelN=as.numeric(rest$model)
> rest$algoN=as.numeric(rest$algo)
> data=rest[complete.cases(rest),]
> head(data)
  algo   pa  run model   ROC   TSS modelN algoN
1  ANN  PA1 RUN1   alt 0.947 0.867      2     2
2  ANN PA10 RUN1   alt 0.978 0.869      2     2
3  ANN PA11 RUN1   alt 0.993 0.931      2     2
4  ANN PA12 RUN1   alt 0.961 0.845      2     2
5  ANN PA13 RUN1   alt 0.988 0.960      2     2
6  ANN PA14 RUN1   alt 0.996 0.988      2     2
> summary(data)
      algo           pa         run             model           ROC
     TSS
 CTA    :240   PA10   : 120       :   0   alt      : 200   Min.   :0.5290
Min.   :0.0580
 FDA    :240   PA11   : 120   RUN1:2399   altPet   : 200   1st Qu.:0.8780
1st Qu.:0.7160
 GAM    :240   PA12   : 120               b1       : 200   Median :0.9350
Median :0.8270
 GBM    :240   PA13   : 120               b13      : 200   Mean   :0.9184
Mean   :0.7988
 GLM    :240   PA14   : 120               b13PETalt: 200   3rd Qu.:0.9790
3rd Qu.:0.9110
 MARS   :240   PA15   : 120               b14      : 200   Max.   :1.0000
Max.   :1.0000
 (Other):959   (Other):1679               (Other)  :1199

     modelN           algoN
 Min.   : 2.000   Min.   : 2.000
 1st Qu.: 4.500   1st Qu.: 4.000
 Median : 7.000   Median : 7.000
 Mean   : 7.498   Mean   : 6.502
 3rd Qu.:10.000   3rd Qu.: 9.000
 Max.   :13.000   Max.   :11.000

> tss=data$TSS
> summary(tss)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
 0.0580  0.7160  0.8270  0.7988  0.9110  1.0000
> mdl=factor(data$model)
> summary(mdl)
      alt    altPet        b1       b13 b13PETalt       b14       b18
 b7       pet      pluv
      200       200       200       200       200       200       200
200       200       200
     temp       tot
      200       199
> length(complete.cases(mdl,tss))
[1] 2399
> pairwise.t.test(tss,mdl,p.adj='bonf',paired=T,pool.sd = FALSE)
Error in complete.cases(x, y) :
  not all arguments have the same length
>

*Erica Csek? Nolasco*
Mestranda em Modelagem em Ci?ncias da Terra e do Ambiente
http://lattes.cnpq.br/2117508819823917
Universidade Estadual de Feira de Santana
Avenida Transnordestina s/n, Novo Horizonte
Feira de Santana - BA, Brasil CEP 44.036-900.

Graduate Student in Modeling of Environmental and Earth Sciences
http://lattes.cnpq.br/2117508819823917
Universidade Estadual de Feira de Santana
Transnordestina Ave, Novo Horizonte
Feira de Santana - BA, Brazil 44.036-900.

	[[alternative HTML version deleted]]


From ingorfano at hotmail.com  Tue Jun  2 17:49:14 2015
From: ingorfano at hotmail.com (valerio orfano)
Date: Tue, 2 Jun 2015 17:49:14 +0200
Subject: [R] Save the result of map.market function to HTML file?
Message-ID: <BLU436-SMTP1158396A69A1C66F80AB04DB4B50@phx.gbl>

HI All,

i need to call the tree map function in R to display my multiple disks usage, using ?portfolio' library. I need furthermore to generate multiple page each showing the treemap of each disk. It works fine if use pdf file , but my boss wants to save the result into an html file. Any help? I?ve tried with R2HTML library without success. The output of map.market is a ?gTree' object. Any help is appreciated.

library(portfolio)
data1 <- read.csv("C:/Users/Administrator/Desktop/prova_data1.txt", sep='\t', stringsAsFactors = FALSE)
data2 <- read.csv("C:/Users/Administrator/Desktop/prova_data2.txt", sep='\t', stringsAsFactors = FALSE)
data2 <- read.csv("C:/Users/Administrator/Desktop/prova_data3.txt", sep='\t', stringsAsFactors = FALSE)
pdf("C:/Users/Administrator/Desktop/treemap.pdf")
map.market(id = data1$Id, area = data1$size, group = data1$Storage, color = data1$col, lab=c(TRUE,TRUE), main="Test Map")
map.market(id = data2$Id, area = data2$size, group = data2$Storage, color = data2$col, lab=c(TRUE,TRUE), main="Test Map")
map.market(id = data3$Id, area = data3$size, group = data3$Storage, color = data3$col, lab=c(TRUE,TRUE), main="Test Map")
dev.off()

From wdunlap at tibco.com  Tue Jun  2 18:06:29 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 2 Jun 2015 09:06:29 -0700
Subject: [R] Colour gradient is not working.
In-Reply-To: <1433234355275-4708036.post@n4.nabble.com>
References: <1433157134298-4708000.post@n4.nabble.com>
	<D191C501.12C8FB%macqueen1@llnl.gov>
	<1433234355275-4708036.post@n4.nabble.com>
Message-ID: <CAF8bMcaYPQuxoc-s99uScwkV6Fx5mCs1Ubh-E_P5EZHyCHz0Ng@mail.gmail.com>

Points later in the input vectors may be obscuring earlier
points.  If that is the problem then use pch="." or cex=.2
(or some other small number) to make the plot symbols
smaller so they don't overlap as much.  Sometimes using
transparency helps also - try using adjustcolor(Color(n), alpha.f=0.5)
instead of Color(n).


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Jun 2, 2015 at 1:39 AM, sreenath <sreenath.rajur at macfast.ac.in>
wrote:

> sir i done this plot(1:33292, 1:33292,col=Color(33292)) command then it
> gives
> the coloured line but again it is not working  in my data why?
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Colour-gradient-is-not-working-tp4708000p4708036.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jacobwegelin at fastmail.fm  Tue Jun  2 20:20:16 2015
From: jacobwegelin at fastmail.fm (Jacob Wegelin)
Date: Tue, 2 Jun 2015 14:20:16 -0400
Subject: [R] nlme splines model.frame.default error
Message-ID: <alpine.OSX.2.20.1505291637210.35662@qqt.local>

I want to use a specialized function to compute knots on the fly to pass to splines::bs within a call to nlme::lme.

The specialized function will compute knots from the x-axis variable (the x argument in a call to splines::bs).

The syntax works with lm. But when I try it with lme, the following error is returned:

Error in model.frame.default(formula = ~why + eks + toydat + ID, data = list( :
   invalid type (list) for variable 'toydat'

Below is a simplified example showing the "desired syntax," which returns the error, and a workaround. I am mystified what inherently is wrong with the "desired syntax", since it works fine with stats::lm.

set.seed(5)
library(splines)
library(nlme)
NID<-5
toydat<-data.frame(eks=0:0:((2*NID)-1))
toydat$ID<-factor(rep(LETTERS[1:NID], each=2))
toydat
toydat$why<-with(toydat, as.integer(100*sin((eks / 7 * pi)^2) + rnorm(eks)/10))
customKnotsFn<-function(some)3.5
print(toydat)
print(summary(toydat))
print(customKnotsFn)

# lm has no trouble:

mylm<-lm(why~bs(eks,knots=customKnotsFn(some=toydat$eks)), data=toydat)
print(mylm$call)

#  The "desired syntax" returns an error:

lme(fixed=why~bs(eks,knots=customKnotsFn(some=toydat$eks)),random=~1|ID, data=toydat)

#  Removing the argument from customKnotsFn eliminates the error, but then customKnotsFn is useless for practical purposes:

lme(fixed=why~bs(eks,knots=customKnotsFn()),random=~1|ID, data=toydat)

#  Workaround returns no error:

mylme<- with(toydat, lme(fixed=why~bs(eks,knots=customKnotsFn(some=eks)),random=~1|ID))
print(mylme$call)

Of course, with the workaround the resulting mylme does not know where the data came from.

Why should a workaround be necessary? Is there something inherently misguided about the "desired syntax" (above)?

Thanks for any insight

Jacob Wegelin

> sessionInfo()
R version 3.1.3 (2015-03-09)
Platform: x86_64-apple-darwin10.8.0 (64-bit)
Running under: OS X 10.7.5 (Lion)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] nlme_3.1-120

loaded via a namespace (and not attached):
[1] grid_3.1.3      lattice_0.20-30


From dan.abner99 at gmail.com  Tue Jun  2 20:13:22 2015
From: dan.abner99 at gmail.com (Dan Abner)
Date: Tue, 2 Jun 2015 14:13:22 -0400
Subject: [R] Propensity Score Graph XXXX
Message-ID: <CAPRGo-=VSeekLXh-OT1pURP=sddUhRh1A2KLw2Ux1eT0LzH4hg@mail.gmail.com>

Hi all,

Does anyone know how to create a graph of propensity scores like the
one on the left in the attachment? I can easily generate the one on
the right: How does one force the respective histograms to share the
same rotated x-axis? Is it possible to set the horizontal white space
between these to graphs to 0 so that there is only the single line
running down the middle of the graph?

Thanks,

Dan
-------------- next part --------------
A non-text attachment was scrubbed...
Name: graphs.pdf
Type: application/pdf
Size: 179353 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150602/f9a1d2c0/attachment.pdf>

From ravsh98 at gmail.com  Tue Jun  2 21:59:22 2015
From: ravsh98 at gmail.com (ravishankar narayanan)
Date: Tue, 2 Jun 2015 14:59:22 -0500
Subject: [R] Help on Neural Network package
Message-ID: <CAAq71vYCdQA5yOs1gYpFeaOjkN03rHuPAKYaF2R=pO5O8q7jNA@mail.gmail.com>

Hi,

Developing a Neural Network in R to predict the quality of wine.Attached is
the Wine Data Set.Tried twice once by selecting specific features and once
by using all features to predict quality of wine

Each time I run the Neural Network I am getting a  huge error.Tried using
feature selection and also used all features
*With Feature Selection*

*winequal<-
neuralnet(quality~volatile.acidity+citric.acid+sulphates+alcohol,winetrain,hidden=2,lifesign="minimal",linear.output=FALSE,threshold=0.1)*





*hidden:2    thresh:0.1    rep:1/1    steps:      52  error:
8486.01111       time: 2.41secs*

*No feature selection*

*winequal1<-neuralnet(quality~fixed.acidity+volatile.acidity+citric.acid+residual.sugar+chlorides+free.sulfur.dioxide+total.sulfur.dioxide+density+pH*




*++sulphates+alcohol,winetrain1,hidden=4,lifesign="minimal",linear.output=FALSE,threshold=0.1)*

Model Produced:





*hidden: 4    thresh:0.1    rep: 1/1    steps:     26  error: 8486.08992
     time: 0.1 secs*

Is there any method I can use to reduce the error ? Changing the threshold
or the number of hidden layers does not help.Any tips will be
helpful.Thanks.

From cdetermanjr at gmail.com  Tue Jun  2 22:24:45 2015
From: cdetermanjr at gmail.com (Charles Determan)
Date: Tue, 2 Jun 2015 15:24:45 -0500
Subject: [R] Help on Neural Network package
In-Reply-To: <CAAq71vYCdQA5yOs1gYpFeaOjkN03rHuPAKYaF2R=pO5O8q7jNA@mail.gmail.com>
References: <CAAq71vYCdQA5yOs1gYpFeaOjkN03rHuPAKYaF2R=pO5O8q7jNA@mail.gmail.com>
Message-ID: <CAKxd1KNr5s6tssRreTu_nWeJUJxGfeOqji_TudDWea6Qq_Tq-w@mail.gmail.com>

You model is reaching the error threshold otherwise you would be receiving
an 'actual' error message.  You model is just converging very quickly.  If
you want to see the error reducing, change lifesign="minimal" to
lifesign="full" and set the lifesign.step=1 to make it very verbose for
this model.

Alternatively you could just look at winequal$result.matrix and you will
see how many steps were taken to reach the threshold as well as the
reached.threshold your model finished on.

Cheers,
Charles

On Tue, Jun 2, 2015 at 2:59 PM, ravishankar narayanan <ravsh98 at gmail.com>
wrote:

> Hi,
>
> Developing a Neural Network in R to predict the quality of wine.Attached is
> the Wine Data Set.Tried twice once by selecting specific features and once
> by using all features to predict quality of wine
>
> Each time I run the Neural Network I am getting a  huge error.Tried using
> feature selection and also used all features
> *With Feature Selection*
>
> *winequal<-
>
> neuralnet(quality~volatile.acidity+citric.acid+sulphates+alcohol,winetrain,hidden=2,lifesign="minimal",linear.output=FALSE,threshold=0.1)*
>
>
>
>
>
> *hidden:2    thresh:0.1    rep:1/1    steps:      52  error:
> 8486.01111       time: 2.41secs*
>
> *No feature selection*
>
>
> *winequal1<-neuralnet(quality~fixed.acidity+volatile.acidity+citric.acid+residual.sugar+chlorides+free.sulfur.dioxide+total.sulfur.dioxide+density+pH*
>
>
>
>
>
> *++sulphates+alcohol,winetrain1,hidden=4,lifesign="minimal",linear.output=FALSE,threshold=0.1)*
>
> Model Produced:
>
>
>
>
>
> *hidden: 4    thresh:0.1    rep: 1/1    steps:     26  error: 8486.08992
>      time: 0.1 secs*
>
> Is there any method I can use to reduce the error ? Changing the threshold
> or the number of hidden layers does not help.Any tips will be
> helpful.Thanks.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Jun  2 22:43:05 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 2 Jun 2015 13:43:05 -0700
Subject: [R] Propensity Score Graph XXXX
In-Reply-To: <CAPRGo-=VSeekLXh-OT1pURP=sddUhRh1A2KLw2Ux1eT0LzH4hg@mail.gmail.com>
References: <CAPRGo-=VSeekLXh-OT1pURP=sddUhRh1A2KLw2Ux1eT0LzH4hg@mail.gmail.com>
Message-ID: <6BFE6E92-943B-4F4E-879D-D903526EBDF6@comcast.net>


On Jun 2, 2015, at 11:13 AM, Dan Abner wrote:

> Hi all,
> 
> Does anyone know how to create a graph of propensity scores like the
> one on the left in the attachment? I can easily generate the one on
> the right: How does one force the respective histograms to share the
> same rotated x-axis? Is it possible to set the horizontal white space
> between these to graphs to 0 so that there is only the single line
> running down the middle of the graph?
> 

I think you will find that "pyramid" plots of this sort are in some packages and that similar requests (to get rid of the middle space) have been made in the past. Pyramid plots are often used by demographers to compare and display age distributions of both genders. Why not see if that work can be found with a search engine. I use this MarkMail link on my browser to search the Archive

http://markmail.org/search/?q=list%3Aorg.r-project.r-help

 ....(but you could also direct the Google Advanced Search function to the real Archives if you wanted:

https://stat.ethz.ch/pipermail/r-help/


> Thanks,
> 
> Dan
> <graphs.pdf>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From boris.steipe at utoronto.ca  Tue Jun  2 23:01:51 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 2 Jun 2015 17:01:51 -0400
Subject: [R] Propensity Score Graph XXXX
In-Reply-To: <6BFE6E92-943B-4F4E-879D-D903526EBDF6@comcast.net>
References: <CAPRGo-=VSeekLXh-OT1pURP=sddUhRh1A2KLw2Ux1eT0LzH4hg@mail.gmail.com>
	<6BFE6E92-943B-4F4E-879D-D903526EBDF6@comcast.net>
Message-ID: <F3729BB1-C557-4907-B224-77823F7DC826@utoronto.ca>

Easy to write - here's a quick piece of code (without bells and whistles though...)



dat1 <- rnorm(1000)
dat2 <- rgamma(3000, shape=3)

biHist <- function(d1, d2) {
	col1 <- "#FFCCBB"
	col2 <- "#BBCCFF"
	hAll <- hist(c(d1, d2))
	hD1 <- hist(d1, breaks=hAll$breaks)
	hD2 <- hist(d2, breaks=hAll$breaks)
	plot(NULL,
	     xlim = c(-1.05 * max(hD1$counts), 1.05 * max(hD2$counts)),
	     ylim = c(min(hAll$breaks), max(hAll$breaks)),
	     xlab = "frequencies",
	     ylab = "values",
	     xaxt = "n")
	axis(side = 1,
	     lwd = 0,
	     lwd.ticks = 1,
	     at = axTicks(1),
	     labels = abs(axTicks(1)))
	abline(v = 0)
	rect(-hD1$counts,
	     hAll$breaks[-length(hAll$breaks)],
	     0,
	     hAll$breaks[-1],
	     col=col1)
	rect(0,
	     hAll$breaks[-length(hAll$breaks)],
	     hD2$counts,
	     hAll$breaks[-1],
	     col=col2)
}

biHist(dat1, dat2)



Let me know in case this needs modifications that you can't easily make yourself
:-)


B.






On Jun 2, 2015, at 4:43 PM, David Winsemius <dwinsemius at comcast.net> wrote:

> 
> On Jun 2, 2015, at 11:13 AM, Dan Abner wrote:
> 
>> Hi all,
>> 
>> Does anyone know how to create a graph of propensity scores like the
>> one on the left in the attachment? I can easily generate the one on
>> the right: How does one force the respective histograms to share the
>> same rotated x-axis? Is it possible to set the horizontal white space
>> between these to graphs to 0 so that there is only the single line
>> running down the middle of the graph?
>> 
> 
> I think you will find that "pyramid" plots of this sort are in some packages and that similar requests (to get rid of the middle space) have been made in the past. Pyramid plots are often used by demographers to compare and display age distributions of both genders. Why not see if that work can be found with a search engine. I use this MarkMail link on my browser to search the Archive
> 
> http://markmail.org/search/?q=list%3Aorg.r-project.r-help
> 
> ....(but you could also direct the Google Advanced Search function to the real Archives if you wanted:
> 
> https://stat.ethz.ch/pipermail/r-help/
> 
> 
>> Thanks,
>> 
>> Dan
>> <graphs.pdf>______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jacobwegelin at fastmail.fm  Tue Jun  2 23:56:42 2015
From: jacobwegelin at fastmail.fm (Jacob Wegelin)
Date: Tue, 2 Jun 2015 17:56:42 -0400
Subject: [R] nlme splines model.frame.default error
In-Reply-To: <alpine.OSX.2.20.1505291637210.35662@qqt.local>
References: <alpine.OSX.2.20.1505291637210.35662@qqt.local>
Message-ID: <alpine.OSX.2.20.1506021750000.1721@qqt.local>

On 2015-06-02 Tue 14:20, Jacob Wegelin wrote:
> I want to use a specialized function to compute knots on the fly to pass to 
> splines::bs within a call to nlme::lme.
>
> The specialized function will compute knots from the x-axis variable (the x 
> argument in a call to splines::bs).
>
> The syntax works with lm. But when I try it with lme, the following error is 
> returned:
>
> Error in model.frame.default(formula = ~why + eks + toydat + ID, data = list( 
> :
>  invalid type (list) for variable 'toydat'
>
> Below is a simplified example showing the "desired syntax," which returns the 
> error, and a workaround. I am mystified what inherently is wrong with the 
> "desired syntax", since it works fine with stats::lm.
>
> set.seed(5)
> library(splines)
> library(nlme)
> NID<-5
> toydat<-data.frame(eks=0:0:((2*NID)-1))
> toydat$ID<-factor(rep(LETTERS[1:NID], each=2))
> toydat
> toydat$why<-with(toydat, as.integer(100*sin((eks / 7 * pi)^2) + 
> rnorm(eks)/10))
> customKnotsFn<-function(some)3.5
> print(toydat)
> print(summary(toydat))
> print(customKnotsFn)
>
> # lm has no trouble:
>
> mylm<-lm(why~bs(eks,knots=customKnotsFn(some=toydat$eks)), data=toydat)
> print(mylm$call)
>
> #  The "desired syntax" returns an error:
>
> lme(fixed=why~bs(eks,knots=customKnotsFn(some=toydat$eks)),random=~1|ID, 
> data=toydat)
>
> #  Removing the argument from customKnotsFn eliminates the error, but then 
> customKnotsFn is useless for practical purposes:
>
> lme(fixed=why~bs(eks,knots=customKnotsFn()),random=~1|ID, data=toydat)
>
> #  Workaround returns no error:
>
> mylme<- with(toydat, 
> lme(fixed=why~bs(eks,knots=customKnotsFn(some=eks)),random=~1|ID))
> print(mylme$call)

# Here is a perhaps slicker workaround:

mybs <-function(x, df) {
      myknots<-customKnotsFn(x)
      bs(x, knots=myknots)
}

lme(fixed=why~mybs(eks, df=2), random=~1|ID, data=toydat)

# But why cannot lme handle the "desired syntax"?


From drjimlemon at gmail.com  Wed Jun  3 02:29:31 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 3 Jun 2015 10:29:31 +1000
Subject: [R] Save the result of map.market function to HTML file?
In-Reply-To: <BLU436-SMTP1158396A69A1C66F80AB04DB4B50@phx.gbl>
References: <BLU436-SMTP1158396A69A1C66F80AB04DB4B50@phx.gbl>
Message-ID: <CA+8X3fW9dgEnVEO-a+9-JgB9=TpB3wVDQQEGftiazgL0gK30-g@mail.gmail.com>

Hi valerio,
This is a guess, but try running your code with "htmlize" (prettyR).
Change the "pdf" call to:

png("C:/Users/Administrator/Desktop/treemap1.png")
map.market(id = data1$Id, area = data1$size, group = data1$Storage,
 color = data1$col, lab=c(TRUE,TRUE), main="Test Map")
dev.off()
png("C:/Users/Administrator/Desktop/treemap2.png")
map.market(id = data2$Id, area = data2$size, group = data2$Storage,
 color = data2$col, lab=c(TRUE,TRUE), main="Test Map")
dev.off()
png("C:/Users/Administrator/Desktop/treemap3.png")
map.market(id = data3$Id, area = data3$size, group = data3$Storage,
 color = data3$col, lab=c(TRUE,TRUE), main="Test Map")
dev.off()

as I think you are producing three images.

# assume the code above is in a file "vo.R" in the R working directory
library(prettyR)
htmlize("vo.R")

This should produce a file "vo.html" with the plots in it.

Jim

On Wed, Jun 3, 2015 at 1:49 AM, valerio orfano <ingorfano at hotmail.com> wrote:
> HI All,
>
> i need to call the tree map function in R to display my multiple disks usage, using ?portfolio' library. I need furthermore to generate multiple page each showing the treemap of each disk. It works fine if use pdf file , but my boss wants to save the result into an html file. Any help? I?ve tried with R2HTML library without success. The output of map.market is a ?gTree' object. Any help is appreciated.
>
> library(portfolio)
> data1 <- read.csv("C:/Users/Administrator/Desktop/prova_data1.txt", sep='\t', stringsAsFactors = FALSE)
> data2 <- read.csv("C:/Users/Administrator/Desktop/prova_data2.txt", sep='\t', stringsAsFactors = FALSE)
> data2 <- read.csv("C:/Users/Administrator/Desktop/prova_data3.txt", sep='\t', stringsAsFactors = FALSE)
> pdf("C:/Users/Administrator/Desktop/treemap.pdf")
> map.market(id = data1$Id, area = data1$size, group = data1$Storage, color = data1$col, lab=c(TRUE,TRUE), main="Test Map")
> map.market(id = data2$Id, area = data2$size, group = data2$Storage, color = data2$col, lab=c(TRUE,TRUE), main="Test Map")
> map.market(id = data3$Id, area = data3$size, group = data3$Storage, color = data3$col, lab=c(TRUE,TRUE), main="Test Map")
> dev.off()
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Jun  3 03:34:08 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 3 Jun 2015 11:34:08 +1000
Subject: [R] pairwise.t.test non numeric factors error
In-Reply-To: <CAMbrGjHztZFofwCAHrmMvQzycF6KcvSw50i=o_E0hcDoE0Rd3w@mail.gmail.com>
References: <CAMbrGjHztZFofwCAHrmMvQzycF6KcvSw50i=o_E0hcDoE0Rd3w@mail.gmail.com>
Message-ID: <CA+8X3fV6zuJOUQ+yMx644N5K00+RHj3c+5xdL7uEFCxXdWxudw@mail.gmail.com>

Hi Erica,
The problem may be that you are specifying a grouping factor (mdl) in
which the group sizes are unequal. If one case in group "tot" is
missing, is it possible to identify the corresponding cases in the
other factor levels and delete them?

Jim


On Tue, Jun 2, 2015 at 11:59 PM, Erica Cseko Nolasco
<ecnolasco at gmail.com> wrote:
> Dear listers,
>
> I'm performing a PERMANOVA (adonis{vegan}) to compare the results (ROC,
> TSS) of models based on two factors (model, algo). I was not able to find a
> pairwise test for adonis, on PRIMER it would be a Tukey test. Though, I
> chose to perform a pairwise.t.test what would be quite simple. However, no
> matter I rearrange my response and factor vectors (as a factor or numeric)
> it gives me the following error (the code on the bottom - Error in
> complete.cases(x, y) :
>   not all arguments have the same length). I also tried to make a list of
> the vectors, but it also gives me the error 'Error in sort.list(y) : 'x'
> must be atomic for 'sort.list' Have you called 'sort' on a list?'
>
> I would appreciate any suggestions to solve this issue.
>
> Best,
>
> Erica
>
>> setwd('D:\\Erica\\mestrado\\analises\\results')
>> library(vegan)
>> rest=read.table('results_permanova.txt',sep="\t",header=T)
>> rest$modelN=as.numeric(rest$model)
>> rest$algoN=as.numeric(rest$algo)
>> data=rest[complete.cases(rest),]
>> head(data)
>   algo   pa  run model   ROC   TSS modelN algoN
> 1  ANN  PA1 RUN1   alt 0.947 0.867      2     2
> 2  ANN PA10 RUN1   alt 0.978 0.869      2     2
> 3  ANN PA11 RUN1   alt 0.993 0.931      2     2
> 4  ANN PA12 RUN1   alt 0.961 0.845      2     2
> 5  ANN PA13 RUN1   alt 0.988 0.960      2     2
> 6  ANN PA14 RUN1   alt 0.996 0.988      2     2
>> summary(data)
>       algo           pa         run             model           ROC
>      TSS
>  CTA    :240   PA10   : 120       :   0   alt      : 200   Min.   :0.5290
> Min.   :0.0580
>  FDA    :240   PA11   : 120   RUN1:2399   altPet   : 200   1st Qu.:0.8780
> 1st Qu.:0.7160
>  GAM    :240   PA12   : 120               b1       : 200   Median :0.9350
> Median :0.8270
>  GBM    :240   PA13   : 120               b13      : 200   Mean   :0.9184
> Mean   :0.7988
>  GLM    :240   PA14   : 120               b13PETalt: 200   3rd Qu.:0.9790
> 3rd Qu.:0.9110
>  MARS   :240   PA15   : 120               b14      : 200   Max.   :1.0000
> Max.   :1.0000
>  (Other):959   (Other):1679               (Other)  :1199
>
>      modelN           algoN
>  Min.   : 2.000   Min.   : 2.000
>  1st Qu.: 4.500   1st Qu.: 4.000
>  Median : 7.000   Median : 7.000
>  Mean   : 7.498   Mean   : 6.502
>  3rd Qu.:10.000   3rd Qu.: 9.000
>  Max.   :13.000   Max.   :11.000
>
>> tss=data$TSS
>> summary(tss)
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>  0.0580  0.7160  0.8270  0.7988  0.9110  1.0000
>> mdl=factor(data$model)
>> summary(mdl)
>       alt    altPet        b1       b13 b13PETalt       b14       b18
>  b7       pet      pluv
>       200       200       200       200       200       200       200
> 200       200       200
>      temp       tot
>       200       199
>> length(complete.cases(mdl,tss))
> [1] 2399
>> pairwise.t.test(tss,mdl,p.adj='bonf',paired=T,pool.sd = FALSE)
> Error in complete.cases(x, y) :
>   not all arguments have the same length
>>
>
> *Erica Csek? Nolasco*
> Mestranda em Modelagem em Ci?ncias da Terra e do Ambiente
> http://lattes.cnpq.br/2117508819823917
> Universidade Estadual de Feira de Santana
> Avenida Transnordestina s/n, Novo Horizonte
> Feira de Santana - BA, Brasil CEP 44.036-900.
>
> Graduate Student in Modeling of Environmental and Earth Sciences
> http://lattes.cnpq.br/2117508819823917
> Universidade Estadual de Feira de Santana
> Transnordestina Ave, Novo Horizonte
> Feira de Santana - BA, Brazil 44.036-900.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hannah.hlx at gmail.com  Wed Jun  3 05:06:44 2015
From: hannah.hlx at gmail.com (li li)
Date: Tue, 2 Jun 2015 23:06:44 -0400
Subject: [R] How to add legend to a dotplot
Message-ID: <CAHLnndZy+Q4_RAy6GuEj7dM6bYn0aKJPLvDUj3f6HAKpdD-gUQ@mail.gmail.com>

Hi all,
  I wanted to add the legend to a dotplot using legend funciton. If
does not seem to be working? Anyone have any suggestions?
  Thanks!
  Hanna


From drjimlemon at gmail.com  Wed Jun  3 06:03:15 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 3 Jun 2015 14:03:15 +1000
Subject: [R] How to add legend to a dotplot
In-Reply-To: <CAHLnndZy+Q4_RAy6GuEj7dM6bYn0aKJPLvDUj3f6HAKpdD-gUQ@mail.gmail.com>
References: <CAHLnndZy+Q4_RAy6GuEj7dM6bYn0aKJPLvDUj3f6HAKpdD-gUQ@mail.gmail.com>
Message-ID: <CA+8X3fWPooWiexF2wqcLA6g=ALYzaWpAS2saF0nMxB_aLtG=zA@mail.gmail.com>

Hi Hanna,
That is because "dotplot" is a lattice graphics function and "legend"
is a base graphics function. There are two things you can do to fix
this. One is to use the "dotchart" function in base graphics. The
other is to use simpleKey in the latticeExtra package for the legend.

Jim


On Wed, Jun 3, 2015 at 1:06 PM, li li <hannah.hlx at gmail.com> wrote:
> Hi all,
>   I wanted to add the legend to a dotplot using legend funciton. If
> does not seem to be working? Anyone have any suggestions?
>   Thanks!
>   Hanna
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Jun  3 00:51:21 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 3 Jun 2015 08:51:21 +1000
Subject: [R] Propensity Score Graph XXXX
In-Reply-To: <F3729BB1-C557-4907-B224-77823F7DC826@utoronto.ca>
References: <CAPRGo-=VSeekLXh-OT1pURP=sddUhRh1A2KLw2Ux1eT0LzH4hg@mail.gmail.com>
	<6BFE6E92-943B-4F4E-879D-D903526EBDF6@comcast.net>
	<F3729BB1-C557-4907-B224-77823F7DC826@utoronto.ca>
Message-ID: <CA+8X3fUt8T2JM5a2MQwvaP4a+vjU1vhNCC-dkUbXMP=C01J+rw@mail.gmail.com>

Hi Dan,
With a bit of arm-twisting, you can get pretty close with pyramid.plot
(plotrix).

lx<-c(0,0,0,0,0,0,0,0,0,0,0,0,0,20,30,55,60,60,70,80,100,90)
rx<-c(90,95,95,80,70,65,75,54,52,50,40,20,0,0,0,0,0,0,0,0,0,0)
library(plotrix)
x11(width=10)
pyramid.plot(lx,rx,labels=rep("",22),gap=0,top.labels=rep("",3),
 laxlab=seq(0,100,by=10),raxlab=seq(0,100,by=10),
 unit="",lxcol=rep("gray",22),rxcol=rep("gray",22),ppmar=c(4,6,2,6))
axis(2,at=c(1,11,22),labels=c(0,0.5,1),pos=-110)
mtext("Number of observed subjects",side=1,line=2)
mtext("Estimated probability of exposure",side=2,line=4.5)
par(xpd=TRUE)
arrows(c(-100,100),c(0,0),c(-110,110),c(0,0))
text(-85,17,"Actually exposed")
text(98,7,"Actually unexposed")
par(xpd=FALSE)

Jim

On Wed, Jun 3, 2015 at 7:01 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> Easy to write - here's a quick piece of code (without bells and whistles though...)
>
>
>
> dat1 <- rnorm(1000)
> dat2 <- rgamma(3000, shape=3)
>
> biHist <- function(d1, d2) {
>         col1 <- "#FFCCBB"
>         col2 <- "#BBCCFF"
>         hAll <- hist(c(d1, d2))
>         hD1 <- hist(d1, breaks=hAll$breaks)
>         hD2 <- hist(d2, breaks=hAll$breaks)
>         plot(NULL,
>              xlim = c(-1.05 * max(hD1$counts), 1.05 * max(hD2$counts)),
>              ylim = c(min(hAll$breaks), max(hAll$breaks)),
>              xlab = "frequencies",
>              ylab = "values",
>              xaxt = "n")
>         axis(side = 1,
>              lwd = 0,
>              lwd.ticks = 1,
>              at = axTicks(1),
>              labels = abs(axTicks(1)))
>         abline(v = 0)
>         rect(-hD1$counts,
>              hAll$breaks[-length(hAll$breaks)],
>              0,
>              hAll$breaks[-1],
>              col=col1)
>         rect(0,
>              hAll$breaks[-length(hAll$breaks)],
>              hD2$counts,
>              hAll$breaks[-1],
>              col=col2)
> }
>
> biHist(dat1, dat2)
>
>
>
> Let me know in case this needs modifications that you can't easily make yourself
> :-)
>
>
> B.
>
>
>
>
>
>
> On Jun 2, 2015, at 4:43 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>>
>> On Jun 2, 2015, at 11:13 AM, Dan Abner wrote:
>>
>>> Hi all,
>>>
>>> Does anyone know how to create a graph of propensity scores like the
>>> one on the left in the attachment? I can easily generate the one on
>>> the right: How does one force the respective histograms to share the
>>> same rotated x-axis? Is it possible to set the horizontal white space
>>> between these to graphs to 0 so that there is only the single line
>>> running down the middle of the graph?
>>>
>>
>> I think you will find that "pyramid" plots of this sort are in some packages and that similar requests (to get rid of the middle space) have been made in the past. Pyramid plots are often used by demographers to compare and display age distributions of both genders. Why not see if that work can be found with a search engine. I use this MarkMail link on my browser to search the Archive
>>
>> http://markmail.org/search/?q=list%3Aorg.r-project.r-help
>>
>> ....(but you could also direct the Google Advanced Search function to the real Archives if you wanted:
>>
>> https://stat.ethz.ch/pipermail/r-help/
>>
>>
>>> Thanks,
>>>
>>> Dan
>>> <graphs.pdf>______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Jun  3 03:25:26 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 3 Jun 2015 11:25:26 +1000
Subject: [R] Combining multiple probability weights for the sample()
	function.
In-Reply-To: <CAN5YmCE1n2BmsAz63iQOaKCFDzurUBbACs=Nc7Wd4Zk52C-nsw@mail.gmail.com>
References: <142413609C0A60488585AB47438ECD9D0F684CC8@ueastfexch01.UEA.AC.UK>
	<CAN5YmCE1n2BmsAz63iQOaKCFDzurUBbACs=Nc7Wd4Zk52C-nsw@mail.gmail.com>
Message-ID: <CA+8X3fWDHLh2mRM1Om1D=c2cQ8hgqjWRDeShHfcPM2LFmh2fOg@mail.gmail.com>

Hi Ben,
While Jean's answer looks correct, I think that there is something
amiss with your specification of the problem. You have eight
combinations in your "possibilities". So if you draw samples "x"
where:

If p(x = possibilities[1,] | possibilities[5,]) = 0.5 AND
 p(x = possibilities[2,] | possibilities[4,]) = 0.5

then:

p(x = possibilities[3,] | possibilities[6,] | possibilities[7,] |
possibilities[8,]) = 0

You state that you want the probability of drawing a triplet with
identical second and third bases to be zero, which is ensured by
having no such "possibilities" in the set to be sampled. This is the
constraint that forces the above, as the two conditions (identical
first and second, identical first and third) are disjunct and as the
sum of all probabilities cannot exceed one, four "possibilities" must
have probabilities of zero.

Jim


On Tue, Jun 2, 2015 at 11:57 PM, Adams, Jean <jvadams at usgs.gov> wrote:
> Ben,
>
> Perhaps I am missing something, but couldn't you simply reduce your
> possibilities to:
>
> possibilities[c(1, 5, 2, 4), ]
>      Var1 Var2 Var3
> [1,] "A"  "A"  "C"
> [2,] "A"  "A"  "T"
> [3,] "C"  "A"  "C"
> [4,] "C"  "G"  "C"
>
> If you sample from these four rows you will have a 50% chance that Var1 and
> Var2 are equal and a 50% chance that Var1 and Var3 are equal.
>
> Jean
>
>
> On Tue, Jun 2, 2015 at 7:26 AM, Benjamin Ward (ENV) <B.Ward at uea.ac.uk>
> wrote:
>
>> Dear R-List,
>>
>> I have a set of possibilities I want to sample from:
>>
>> bases <- list(c('A', 'C'), c('A', 'G'), c('C', 'T'))
>> possibilities <- as.matrix(expand.grid(bases))
>>
>> >possibilities
>> Var1 Var2 Var3
>> [1,] "A"  "A"  "C"
>> [2,] "C"  "A"  "C"
>> [3,] "A"  "G"  "C"
>> [4,] "C"  "G"  "C"
>> [5,] "A"  "A"  "T"
>> [6,] "C"  "A"  "T"
>> [7,] "A"  "G"  "T"
>> [8,] "C"  "G"  "T"
>>
>> If I want to randomly sample one of these rows. If I do this, I find that
>> it is 25% likely that my choice will have an identical first and last
>> letter (e.g. [1,] "A"  "A"  "C"). It is also 25% likely that my choice will
>> have an identical first and third letter (e.g. [4,] "C"  "G"  "C"). It is
>> not likely at all that the second and third letter of my choice could be
>> identical.
>>
>> What I would like to do, is sample one of the rows, but given the
>> constraint that the probability of drawing identical letters 1 and 2 should
>> be 50% or 0.5, and at the same time the probability of drawing identical
>> letters 1 and 3 should be 50%. I am unsure on how to do this, but I know it
>> involves coming up with a modified set of weights for the sample()
>> function. My progress is below, any advice is much appreciated.
>>
>> Best Wishes,
>>
>> Ben Ward, UEA.
>>
>>
>> So I have used the following code to come up with a matrix, which contains
>> weighting according to each criteria:
>>
>> possibilities <- as.matrix(expand.grid(bases))
>>   identities <- apply(possibilities, 1, function(x) c(x[1] == x[2], x[1]
>> == x[3], x[2] == x[3]))
>>   prob <- matrix(rep(0, length(identities)), ncol = ncol(identities))
>>   consProb <- apply(identities, 1, function(x){0.5 / length(which(x))})
>>   polProb <- apply(identities, 1, function(x){0.5 / length(which(!x))})
>>   for(i in 1:nrow(identities)){
>>     prob[i, which(identities[i,])] <- consProb[i]
>>     prob[i, which(!identities[i,])] <- polProb[i]
>>   }
>>   rownames(prob) <- c("1==2", "1==3", "2==3")
>>   colnames(prob) <- apply(possibilities, 1, function(x)paste(x, collapse =
>> ", "))
>>
>> This code gives the following matrix:
>>
>>                 A, A, C    C, A, C          A, G, C        C, G, C
>>  A, A, T         C, A, T       A, G, T       C, G, T
>> 1==2 0.25000000 0.08333333 0.08333333 0.08333333 0.25000000 0.08333333
>> 0.08333333 0.08333333
>> 1==3 0.08333333 0.25000000 0.08333333 0.25000000 0.08333333 0.08333333
>> 0.08333333 0.08333333
>> 2==3 0.06250000 0.06250000 0.06250000 0.06250000 0.06250000 0.06250000
>> 0.06250000 0.06250000
>>
>> Each column is one of the choices from 'possibilities', and each row gives
>> a series of weights based on three different criteria:
>>
>> Row 1, that if it possible from the choices for letter 1 == letter 2, that
>> combined chance be 50%.
>> Row 2, that if it possible from the choices for letter 1 == letter 3, that
>> combined chance be 50%.
>> Row 3, that if it possible from the choices for letter 2 == letter 3, that
>> combined chance be 50%.
>>
>> So:
>>
>>  If I used sample(x = 1:now(possibilities), size = 1, prob = prob[1,])
>> repeatedly, I expect about half the choices to contain identical letters 1
>> and 2.
>>
>>  If I used sample(x = 1:now(possibilities), size = 1, prob = prob[2,])
>> repeatedly, I expect about half the choices to contain identical letters 1
>> and 3.
>>
>> If I used sample(x = 1:now(possibilities), size = 1, prob = prob[3,])
>> repeatedly, I expect about half the choices to contain identical letters 2
>> and 3. Except that in this case, since it is not possible.
>>
>> Note each row sums to 1.
>>
>> What I would like to do - if it is possible - is combine these three sets
>> of weights into one set, that when used with
>> sample(x = 1:nrow(possibilities, size = 1, prob = MAGICPROB) will give me
>> a list of choices, where ~50% of them contain identical letters 1 and 2,
>> AND ~50% of them contain identical letters 1 and 3, AND ~50% again contain
>> identical letters 2 and 3 (except in this example as it is not possible
>> from the choices).
>>
>> Can multiple probability weightings be combined in such a manner?
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From glennmschultz at me.com  Wed Jun  3 02:32:10 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Wed, 03 Jun 2015 00:32:10 +0000 (GMT)
Subject: [R] ggplot stat_bin question
Message-ID: <c4a932f4-b6c7-421c-a90d-49b8fa5d030b@me.com>

All,

I am using gglpot to produce combination density and histogram plots, which are actually kinda cool, everything works well and the plots look nice. ?However after each plot run I receive the following message:

stat_bin: binwidth defaulted to range/30. Use 'bin width = x' to adjust this.

Below is the code I used to create the graph. ?I think I am pretty much following the examples in Hadley's ggplot2 book and really just need to eliminate the message as the graphs look fine. ?Any suggestions are appreciated.

Best Regards,
Glenn?

? Mdur.dist <- ggplot(OAS.Mdur, aes(x = value )) +
? ? geom_density(fill = "#56B4E9", colour = "#56B4E9", alpha = .6) +
? ? geom_histogram(aes(y =..density..), color = "lightgrey", fill = "#0072B2", bindwidth = .01) +
? ? theme_minimal() +
? ? #scale_x_continuous(breaks = seq(80,120, 5)) +
? ? labs(title = "Mod. Duration Distribution") +
? ? ylab("Density")+
? ? xlab("Path Mod. Duration") +
? ? theme(panel.grid.major = element_line(size = .25, color = "grey")) +
? ? theme(axis.text = element_text(size = 15)) +
? ? theme(axis.title = element_text(size = 20)) +?
? ? theme(legend.position = "none")


From tk9830 at gmail.com  Wed Jun  3 00:31:07 2015
From: tk9830 at gmail.com (t.k. t.k.)
Date: Wed, 3 Jun 2015 01:31:07 +0300
Subject: [R] Clarification about data/weekday conversion
Message-ID: <CA+AQxOqfCoON_wTtjeyTn59bXp9CZtNQpWB_k0tY2xZH6Gi0aw@mail.gmail.com>

Hi everyone
This is a general question.
I have imported a "Dates" variable as character. I used the "as.Date"
command and convert it to Date,format..

I want to change the display of the date to weekday (e.g., I want my time
series to be instead of 15-04-2010 as Friday-04-2010). I used the "format"
command but the variable reverts back to character. Is there a way to
change the day to weekday and my variable remain a "Date,format..."
variable?

these are the two lines I used as code

Hpc$Date1<- as.Date(Hpc$Date, "%d/%m/%Y")

Hpc$Date1<-format(Hpc$Date1, "%a %b %d %Y")

thanks in advance

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Jun  3 06:33:06 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 3 Jun 2015 14:33:06 +1000
Subject: [R] Clarification about data/weekday conversion
In-Reply-To: <CA+AQxOqfCoON_wTtjeyTn59bXp9CZtNQpWB_k0tY2xZH6Gi0aw@mail.gmail.com>
References: <CA+AQxOqfCoON_wTtjeyTn59bXp9CZtNQpWB_k0tY2xZH6Gi0aw@mail.gmail.com>
Message-ID: <CA+8X3fVH+RBwzEv_MpgBAA-n3pNT6OD+X12ZX8s3fSZc_768zw@mail.gmail.com>

Hi tk.tk.,
Once you have the date as a Date object, leave it that way for your
time series analysis. If you want to get labels (as opposed to date
values) in the format you request, do this:

date1<-"3/6/2015"
Date1<-as.Date(date1,"%d/%m/%Y")
[1] "2015-06-03"
# get a character date in the <long weekday>-<numeric month>-<long year> format
format(Date1,"%A-%m-%Y")
[1] "Wed-06-2015"

Jim


On Wed, Jun 3, 2015 at 8:31 AM, t.k. t.k. <tk9830 at gmail.com> wrote:
> Hi everyone
> This is a general question.
> I have imported a "Dates" variable as character. I used the "as.Date"
> command and convert it to Date,format..
>
> I want to change the display of the date to weekday (e.g., I want my time
> series to be instead of 15-04-2010 as Friday-04-2010). I used the "format"
> command but the variable reverts back to character. Is there a way to
> change the day to weekday and my variable remain a "Date,format..."
> variable?
>
> these are the two lines I used as code
>
> Hpc$Date1<- as.Date(Hpc$Date, "%d/%m/%Y")
>
> Hpc$Date1<-format(Hpc$Date1, "%a %b %d %Y")
>
> thanks in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Jun  3 06:38:51 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 2 Jun 2015 21:38:51 -0700
Subject: [R] Clarification about data/weekday conversion
In-Reply-To: <CA+AQxOqfCoON_wTtjeyTn59bXp9CZtNQpWB_k0tY2xZH6Gi0aw@mail.gmail.com>
References: <CA+AQxOqfCoON_wTtjeyTn59bXp9CZtNQpWB_k0tY2xZH6Gi0aw@mail.gmail.com>
Message-ID: <E4E803DD-6E95-406F-9BD3-4E8986F3FC1C@comcast.net>


On Jun 2, 2015, at 3:31 PM, t.k. t.k. wrote:

> Hi everyone
> This is a general question.
> I have imported a "Dates" variable as character. I used the "as.Date"
> command and convert it to Date,format..
> 
> I want to change the display of the date to weekday (e.g., I want my time
> series to be instead of 15-04-2010 as Friday-04-2010). I used the "format"
> command but the variable reverts back to character. Is there a way to
> change the day to weekday and my variable remain a "Date,format..."
> variable?
> 

Short answer: No. 
Longer answer: You _could_ define a new class which was named differently, but inherited from the Date class and make a print method for the new class. No guarantee about R time-series. That is a class with its own little universe. Seems to have dimensions that defy my understanding. Less comprehensible to me than the electron spin. But perhaps you meant something different than "time series"? Perhaps time sequence?



> these are the two lines I used as code
> 
> Hpc$Date1<- as.Date(Hpc$Date, "%d/%m/%Y")
> 
> Hpc$Date1<-format(Hpc$Date1, "%a %b %d %Y")
> 
> thanks in advance
> 
> 	[[alternative HTML version deleted]]
> 

And you _could_ learn to post in plain text.

-- 

David Winsemius
Alameda, CA, USA


From topijush at gmail.com  Wed Jun  3 08:13:56 2015
From: topijush at gmail.com (Pijush Das)
Date: Wed, 3 Jun 2015 11:43:56 +0530
Subject: [R] SVM error.
Message-ID: <CAGa91zi-JWkATb68Urn722FX9AZSG+2MpeSW3Ag8CVOY-9ewOQ@mail.gmail.com>

Dear Sir,

I am facing an error when I am trying to use svm and found similar kind of
problem faced by other. But I unable to solve the problem. The problem is
given below.

> rm(list=ls(all=TRUE))
> CombinedGeneList <- read.xlsx(file.choose(), sheet = 1, colNames =
TRUE,rowNames = TRUE)
> NoemalisedData <- read.xlsx(file.choose(), sheet=1,colNames =
TRUE,rowNames = TRUE)
> status<-NoemalisedData[1, ]
> FilterData <-NoemalisedData[rownames(CombinedGeneList), ]
> TFilterData <- t(FilterData)
> Tstatus <- t(status)
> x<-TFilterData
> y<-Tstatus
> model <- svm( x, y)
Error in colMeans(x, na.rm = TRUE) : 'x' must be numeric
>



Please solve the problem. I have tried it in many ways.
Waiting for your reply.
Thank you



With regards
Pijush

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Jun  3 08:34:06 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 3 Jun 2015 16:34:06 +1000
Subject: [R] SVM error.
In-Reply-To: <CAGa91zi-JWkATb68Urn722FX9AZSG+2MpeSW3Ag8CVOY-9ewOQ@mail.gmail.com>
References: <CAGa91zi-JWkATb68Urn722FX9AZSG+2MpeSW3Ag8CVOY-9ewOQ@mail.gmail.com>
Message-ID: <CA+8X3fUo4Mf-aDjfsr5iTAGv5BrZzujvHQhgWBiMCh1ABqyp8Q@mail.gmail.com>

Hi Pijush,
Without access to the data, we can only guess. However, in such cases
the problem is often a factor variable where you expect a numeric one.
Try this:

is.factor(x)

and if the answer is TRUE, you have found your problem.

Jim


On Wed, Jun 3, 2015 at 4:13 PM, Pijush Das <topijush at gmail.com> wrote:
> Dear Sir,
>
> I am facing an error when I am trying to use svm and found similar kind of
> problem faced by other. But I unable to solve the problem. The problem is
> given below.
>
>> rm(list=ls(all=TRUE))
>> CombinedGeneList <- read.xlsx(file.choose(), sheet = 1, colNames =
> TRUE,rowNames = TRUE)
>> NoemalisedData <- read.xlsx(file.choose(), sheet=1,colNames =
> TRUE,rowNames = TRUE)
>> status<-NoemalisedData[1, ]
>> FilterData <-NoemalisedData[rownames(CombinedGeneList), ]
>> TFilterData <- t(FilterData)
>> Tstatus <- t(status)
>> x<-TFilterData
>> y<-Tstatus
>> model <- svm( x, y)
> Error in colMeans(x, na.rm = TRUE) : 'x' must be numeric
>>
>
>
>
> Please solve the problem. I have tried it in many ways.
> Waiting for your reply.
> Thank you
>
>
>
> With regards
> Pijush
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Wed Jun  3 09:31:35 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 3 Jun 2015 09:31:35 +0200
Subject: [R] ggplot stat_bin question
In-Reply-To: <c4a932f4-b6c7-421c-a90d-49b8fa5d030b@me.com>
References: <c4a932f4-b6c7-421c-a90d-49b8fa5d030b@me.com>
Message-ID: <CAJuCY5yQG++a3PFTxNhmn-e1dzTJ7QnqwA=Hq7KXnGPcwLRbCQ@mail.gmail.com>

Dear Glenn,

Your code contains a typo: it has bindwidth instead of binwidth. Fixing
that will no longer show the message. AFAIK, the message is always
displayed when binwidth is not set. You can use suppressMessages() to hide
them.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-06-03 2:32 GMT+02:00 Glenn Schultz <glennmschultz at me.com>:

> All,
>
> I am using gglpot to produce combination density and histogram plots,
> which are actually kinda cool, everything works well and the plots look
> nice.  However after each plot run I receive the following message:
>
> stat_bin: binwidth defaulted to range/30. Use 'bin width = x' to adjust
> this.
>
> Below is the code I used to create the graph.  I think I am pretty much
> following the examples in Hadley's ggplot2 book and really just need to
> eliminate the message as the graphs look fine.  Any suggestions are
> appreciated.
>
> Best Regards,
> Glenn
>
>   Mdur.dist <- ggplot(OAS.Mdur, aes(x = value )) +
>     geom_density(fill = "#56B4E9", colour = "#56B4E9", alpha = .6) +
>     geom_histogram(aes(y =..density..), color = "lightgrey", fill =
> "#0072B2", bindwidth = .01) +
>     theme_minimal() +
>     #scale_x_continuous(breaks = seq(80,120, 5)) +
>     labs(title = "Mod. Duration Distribution") +
>     ylab("Density")+
>     xlab("Path Mod. Duration") +
>     theme(panel.grid.major = element_line(size = .25, color = "grey")) +
>     theme(axis.text = element_text(size = 15)) +
>     theme(axis.title = element_text(size = 20)) +
>     theme(legend.position = "none")
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dulcalma at bigpond.com  Wed Jun  3 09:49:40 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 3 Jun 2015 17:49:40 +1000
Subject: [R] How to add legend to a dotplot
In-Reply-To: <CAHLnndZy+Q4_RAy6GuEj7dM6bYn0aKJPLvDUj3f6HAKpdD-gUQ@mail.gmail.com>
References: <CAHLnndZy+Q4_RAy6GuEj7dM6bYn0aKJPLvDUj3f6HAKpdD-gUQ@mail.gmail.com>
Message-ID: <000701d09dd1$d959efa0$8c0dcee0$@bigpond.com>

Hi 
If you use the lattice package and not resort to other packages read the ?
xyplot carefully
There are several ways to put a key in the graph including auto.key if you
want something simple ie default
The examples at the bottom give some ideas

If you want something special you can use key = list(...) eg

           key      = list(text = list(labels = LETTERS[1:3],   cex  =
c(1,1,1) ),
                           title = "Farm", cex.title = 1,
                           points = list(pch = c(20,20,3),
                                         col = c("black","grey","grey")),
                           lines = list(lwd = c(2,1,2),
                                        lty = c(1,1,1),
                                        col = c("black","black","grey80")),
                            space = "bottom"),
which gives 3 columns: text points and lines.

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of li li
Sent: Wednesday, 3 June 2015 13:07
To: r-help
Subject: [R] How to add legend to a dotplot

Hi all,
  I wanted to add the legend to a dotplot using legend funciton. If
does not seem to be working? Anyone have any suggestions?
  Thanks!
  Hanna

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Jun  3 11:34:51 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 3 Jun 2015 19:34:51 +1000
Subject: [R] SVM error.
In-Reply-To: <CAGa91ziAx4mL=_CoGT50j1KcQ4WxayS4L4rfwnSKy8Rd9Z93gQ@mail.gmail.com>
References: <CAGa91zi-JWkATb68Urn722FX9AZSG+2MpeSW3Ag8CVOY-9ewOQ@mail.gmail.com>
	<CA+8X3fUo4Mf-aDjfsr5iTAGv5BrZzujvHQhgWBiMCh1ABqyp8Q@mail.gmail.com>
	<CAGa91ziAx4mL=_CoGT50j1KcQ4WxayS4L4rfwnSKy8Rd9Z93gQ@mail.gmail.com>
Message-ID: <CA+8X3fXKJ=hX13mA=geHPFUs7xynvOZbGbzCsb_0N6c1dAh9ag@mail.gmail.com>

Hi Pijush,
First, please keep the messages on the help list.

As far as I can determine, the "x" in your code above is a matrix of
character strings. When you transpose (t) the initial data frame, all
of the numbers are coerced to character mode as the columns must all
be of the same mode. The first column, being of character mode, causes
all of the other columns to be coerced to character. What you may want
to do is something like this:

FilterData<-NoemalisedData[,-1]
TFilterData <- t(FilterData)
x<-TFilterData
is.numeric(x)
[1] TRUE

This removes the first column of NoemalisedData so that the remaining
columns are numeric, and remain so after the transpose. If you are
using "svm" from the e1071 package, this might solve your problem.

Jim



On Wed, Jun 3, 2015 at 5:09 PM, Pijush Das <topijush at gmail.com> wrote:
> Hi Jim,
>
>
> First of all thank you for your immediate reply.
>
> please find the attachment. I am sending two excel file where
> the the first file (Data) contained the raw data and the list is also
> given in another file and the code has been send before. The variable named
> "NoemalisedData" is used to get the value from Data.excel file.
>
>
>
> Please try and send me the code. I am also trying it in my way.
>
> Thank you.
>
>
>
> With Regards
> Pijush
>
>
> On Wed, Jun 3, 2015 at 12:04 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Pijush,
>> Without access to the data, we can only guess. However, in such cases
>> the problem is often a factor variable where you expect a numeric one.
>> Try this:
>>
>> is.factor(x)
>>
>> and if the answer is TRUE, you have found your problem.
>>
>> Jim
>>
>>
>> On Wed, Jun 3, 2015 at 4:13 PM, Pijush Das <topijush at gmail.com> wrote:
>> > Dear Sir,
>> >
>> > I am facing an error when I am trying to use svm and found similar kind
>> > of
>> > problem faced by other. But I unable to solve the problem. The problem
>> > is
>> > given below.
>> >
>> >> rm(list=ls(all=TRUE))
>> >> CombinedGeneList <- read.xlsx(file.choose(), sheet = 1, colNames =
>> > TRUE,rowNames = TRUE)
>> >> NoemalisedData <- read.xlsx(file.choose(), sheet=1,colNames =
>> > TRUE,rowNames = TRUE)
>> >> status<-NoemalisedData[1, ]
>> >> FilterData <-NoemalisedData[rownames(CombinedGeneList), ]
>> >> TFilterData <- t(FilterData)
>> >> Tstatus <- t(status)
>> >> x<-TFilterData
>> >> y<-Tstatus
>> >> model <- svm( x, y)
>> > Error in colMeans(x, na.rm = TRUE) : 'x' must be numeric
>> >>
>> >
>> >
>> >
>> > Please solve the problem. I have tried it in many ways.
>> > Waiting for your reply.
>> > Thank you
>> >
>> >
>> >
>> > With regards
>> > Pijush
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From antoviral at gmail.com  Wed Jun  3 11:49:23 2015
From: antoviral at gmail.com (Antonello Preti)
Date: Wed, 3 Jun 2015 11:49:23 +0200
Subject: [R] Upload Error Occurred in uploading markdown file to RPubs
Message-ID: <CAPmpGDvdES3zhm0gPBU5yusniQFJT9LK7hoL7D+W9aW2kFpC5A@mail.gmail.com>

Hi, I do not know whether someone had the same problem and if s/he can help
me with some advice.

I'm using RPubs from RStudio to publish tutorials and exercises.

On June 2, I've published a Markdown post in RPubs with RStudio.
So, I'm sure the system can connect to Rpubs without any issues.

Some hours later, I've prepared another short Markdown post, an exercise
with ggmap (which plots maps from Google and other repositories).

I've got a message of error (Upload Error Occurred), with this
specification:
{"continueUrl":"
http://rpubs.com/publish/claim/84372/337a3056d40548f4ae3d1c3d7b1f2f34"}

I do not know what happens and what to do.
Thank you in advance,
Antonello

	[[alternative HTML version deleted]]


From jeremyclarkbio at gmail.com  Wed Jun  3 11:53:05 2015
From: jeremyclarkbio at gmail.com (Jeremy Clark)
Date: Wed, 3 Jun 2015 11:53:05 +0200
Subject: [R] Integration using nlsLM ?
Message-ID: <CACyTWRZJJ0dop5GdpLABHajLC69BQBbyzE-5bSnK6RFk-tdrEw@mail.gmail.com>

Dear All - I'm trying to integrate the following function via nlsLM - and I
think the problem is something to do with passing the correct arguments
(error is given below) - any help gratefully appreciated - many thanks.

library(minpack.lm)

dOM <- function(x, mu = 0, sigma = 1, log = FALSE)
 {
          if (any(sigma < 0))  stop(paste("sigma must be positive", "\n",
""))
loglik <- x*mu + log(sigma) + sigma*(1-exp(x*mu)) + log(mu)
       if(log==FALSE) ft  <- exp(loglik) else ft <- loglik
       ft
  }

vecA <- as.vector(seq(from = 1, to = 29, by = 1))
vecBy <- c(234, 255, 263, 276, 308, 329, 350, 345, 377, 391, 432, 474, 457,
483, 484, 510, 526, 492, 496, 481, 454, 447, 408, 379, 342, 284, 247, 207,
174)

dataframeleft <- data.frame(vecA, vecBy)
colnames(dataframeleft) <- c("vecA", "vecBy")

OMPD <- nlsLM(vecBy ~ alpha*dOM(vecA, mu, sigma),  data = dataframeleft,
start = c(alpha = 59000, mu = 0.086, sigma = 0.0013), lower = c(0, 0, 0),
upper = c(Inf, Inf, Inf),  control = nls.lm.control(maxiter = 1024, factor =
100, maxfev = 5000), trace = TRUE)

omfunction <- function(mygrid, object) {
predmyp1 <- predict(object = OMPD, x = mygrid, mu = mu, sigma = sigma)
predmyp <- as.vector(as.numeric(predmyp1))
return(predmyp)
}

omfunction(mygrid)

intom <- integrate(omfunction, object = OMPD, lower = 1, upper = 20)

## Error in integrate(omfunction, object = OMPD, lower = 1, upper = 20) :
##   evaluation of function gave a result of wrong length


From jeremyclarkbio at gmail.com  Wed Jun  3 12:30:34 2015
From: jeremyclarkbio at gmail.com (Jeremy Clark)
Date: Wed, 3 Jun 2015 12:30:34 +0200
Subject: [R] Graphs for scientific publication ?
Message-ID: <CACyTWRYGf0efZKYf=ssEGLa=cLe3qUfbPC5HBK-jy8S43NJCqA@mail.gmail.com>

The coding I've settled on to save file without clipping is:

library(gridExtra)
gt <- ggplot_gtable(ggplot_build(q3))
gt$layout$clip[gt$layout$name=="panel"] <- "off"
gt4 <- arrangeGrob(gt)
ggsave <- ggplot2::ggsave; body(ggsave) <- body(ggplot2::ggsave)[-2]
## from Baptiste
ggsave("gt.pdf", plot = gt4, width = 6, height = 6)
ggsave("gt.png", plot = gt4, width = 6, height = 6)

Part of the problem with plotmath is that as soon as paste is used the
syntax needed is different eg. substitute and substitute(paste( do not
accept the same syntax eg. == or "=".


From daniela.droguett.leon at gmail.com  Wed Jun  3 13:32:00 2015
From: daniela.droguett.leon at gmail.com (Daniela Droguett)
Date: Wed, 3 Jun 2015 08:32:00 -0300
Subject: [R] subset svydesign problem
Message-ID: <CABD9s96auNowXc6g_D9tQEdajkUjJMxqbKhdUG=GD3JAhz_mrQ@mail.gmail.com>

Hi,

it seems not possible to susbset a svydesign object (DBI svydesign) and use
variables to make the subset expression


uff<-c("14","15")

for (i in 1:length(uff))
{

subpnad<-subset(pnad, uf==uff[i] & v0302=='4')

}

the error is the following
Error in sqliteSendQuery(con, statement, bind.data) :
  error in statement: no such column: uff

I have tried to use eval to make the expression without sucess, then

for (i in 1:length(uff))
{

expr<-eval(paste0("uf==",uff[i]," & v0302=='4'))

subpnad<-subset(pnad, expr)

}

complains that "no such column: expr" exists.

how to solve that?

Thanks!

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Wed Jun  3 14:25:40 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 3 Jun 2015 04:25:40 -0800
Subject: [R] ggplot stat_bin question
In-Reply-To: <c4a932f4-b6c7-421c-a90d-49b8fa5d030b@me.com>
Message-ID: <BCC7BEE162D.00000875jrkrideau@inbox.com>

I don't think there is any reason to get rid of that message unless you have a presentation problem, that is, you are including that output in a paper. 

 All that is, AFAIK, is a notice that ggplot() is using the default binning rule.  You can change the number  of the bins if you need more granular or more agglomerated plots.  

It can be fu/informative  to change binwidth and see what is happening.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: glennmschultz at me.com
> Sent: Wed, 03 Jun 2015 00:32:10 +0000 (GMT)
> To: r-help at r-project.org
> Subject: [R] ggplot stat_bin question
> 
> All,
> 
> I am using gglpot to produce combination density and histogram plots,
> which are actually kinda cool, everything works well and the plots look
> nice. ?However after each plot run I receive the following message:
> 
> stat_bin: binwidth defaulted to range/30. Use 'bin width = x' to adjust
> this.
> 
> Below is the code I used to create the graph. ?I think I am pretty much
> following the examples in Hadley's ggplot2 book and really just need to
> eliminate the message as the graphs look fine. ?Any suggestions are
> appreciated.
> 
> Best Regards,
> Glenn
> 
> ? Mdur.dist <- ggplot(OAS.Mdur, aes(x = value )) +
> ? ? geom_density(fill = "#56B4E9", colour = "#56B4E9", alpha = .6) +
> ? ? geom_histogram(aes(y =..density..), color = "lightgrey", fill =
> "#0072B2", bindwidth = .01) +
> ? ? theme_minimal() +
> ? ? #scale_x_continuous(breaks = seq(80,120, 5)) +
> ? ? labs(title = "Mod. Duration Distribution") +
> ? ? ylab("Density")+
> ? ? xlab("Path Mod. Duration") +
> ? ? theme(panel.grid.major = element_line(size = .25, color = "grey")) +
> ? ? theme(axis.text = element_text(size = 15)) +
> ? ? theme(axis.title = element_text(size = 20)) +
> ? ? theme(legend.position = "none")

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From Thomas.Chesney at nottingham.ac.uk  Wed Jun  3 14:26:58 2015
From: Thomas.Chesney at nottingham.ac.uk (Thomas Chesney)
Date: Wed, 3 Jun 2015 13:26:58 +0100
Subject: [R] Adding columns to a 2D vector
Message-ID: <5EAA21940C65214F9C11DA5FBBC14F0B3FD89C29D6@EXCHANGE2.ad.nottingham.ac.uk>

I'd like to add some columns into the middle of this:

vec <- c(1, -1)
lst <- lapply(numeric(n-1), function(x) vec)
combos <- as.matrix(expand.grid(lst))
colnames(combos) <- NULL

The way I have used is:

combos2 <- matrix(NA, nrow=64, ncol=9)
combos2[,1] <- 0
combos2[,2] <- combos[,1]
combos2[,3] <- combos[,2]
combos2[,4] <- combos[,3]
combos2[,5] <- 0
combos2[,6] <- combos[,4]
combos2[,7] <- combos[,5]
combos2[,8] <- combos[,6]
combos2[,9] <- 0

But I guess there is an easier way - is there a way to simply insert new columns into combos?

BTW I know I could have shortened this a bit to:

combos2[,2:4] <- combos[,1:3]

==========

Also can anyone recommend a good source to explain my combos data type? I don't fully understand all the output of this:

str(combos)
 num [1:64, 1:6] 1 -1 1 -1 1 -1 1 -1 1 -1 ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : NULL

Thank you,

Thomas Chesney



This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please send it back to me, and immediately delete it. 

Please do not use, copy or disclose the information contained in this
message or in any attachment.  Any views or opinions expressed by the
author of this email do not necessarily reflect the views of the
University of Nottingham.

This message has been checked for viruses but the contents of an
attachment may still contain software viruses which could damage your
computer system, you are advised to perform your own checks. Email
communications with the University of Nottingham may be monitored as
permitted by UK legislation.


From ingorfano at hotmail.com  Wed Jun  3 14:32:20 2015
From: ingorfano at hotmail.com (valerio orfano)
Date: Wed, 3 Jun 2015 14:32:20 +0200
Subject: [R] Save the result of map.market function to HTML file?
In-Reply-To: <CA+8X3fW9dgEnVEO-a+9-JgB9=TpB3wVDQQEGftiazgL0gK30-g@mail.gmail.com>
References: <BLU436-SMTP1158396A69A1C66F80AB04DB4B50@phx.gbl>
	<CA+8X3fW9dgEnVEO-a+9-JgB9=TpB3wVDQQEGftiazgL0gK30-g@mail.gmail.com>
Message-ID: <BLU437-SMTP73FEADF571465F01A918ECB4B40@phx.gbl>

Hi Jim and thanx. Unfortunately it didn?t work out!!

any other help?

rgds valerio
On 03 Jun 2015, at 02:29, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi valerio,
> This is a guess, but try running your code with "htmlize" (prettyR).
> Change the "pdf" call to:
> 
> png("C:/Users/Administrator/Desktop/treemap1.png")
> map.market(id = data1$Id, area = data1$size, group = data1$Storage,
> color = data1$col, lab=c(TRUE,TRUE), main="Test Map")
> dev.off()
> png("C:/Users/Administrator/Desktop/treemap2.png")
> map.market(id = data2$Id, area = data2$size, group = data2$Storage,
> color = data2$col, lab=c(TRUE,TRUE), main="Test Map")
> dev.off()
> png("C:/Users/Administrator/Desktop/treemap3.png")
> map.market(id = data3$Id, area = data3$size, group = data3$Storage,
> color = data3$col, lab=c(TRUE,TRUE), main="Test Map")
> dev.off()
> 
> as I think you are producing three images.
> 
> # assume the code above is in a file "vo.R" in the R working directory
> library(prettyR)
> htmlize("vo.R")
> 
> This should produce a file "vo.html" with the plots in it.
> 
> Jim
> 
> On Wed, Jun 3, 2015 at 1:49 AM, valerio orfano <ingorfano at hotmail.com> wrote:
>> HI All,
>> 
>> i need to call the tree map function in R to display my multiple disks usage, using ?portfolio' library. I need furthermore to generate multiple page each showing the treemap of each disk. It works fine if use pdf file , but my boss wants to save the result into an html file. Any help? I?ve tried with R2HTML library without success. The output of map.market is a ?gTree' object. Any help is appreciated.
>> 
>> library(portfolio)
>> data1 <- read.csv("C:/Users/Administrator/Desktop/prova_data1.txt", sep='\t', stringsAsFactors = FALSE)
>> data2 <- read.csv("C:/Users/Administrator/Desktop/prova_data2.txt", sep='\t', stringsAsFactors = FALSE)
>> data2 <- read.csv("C:/Users/Administrator/Desktop/prova_data3.txt", sep='\t', stringsAsFactors = FALSE)
>> pdf("C:/Users/Administrator/Desktop/treemap.pdf")
>> map.market(id = data1$Id, area = data1$size, group = data1$Storage, color = data1$col, lab=c(TRUE,TRUE), main="Test Map")
>> map.market(id = data2$Id, area = data2$size, group = data2$Storage, color = data2$col, lab=c(TRUE,TRUE), main="Test Map")
>> map.market(id = data3$Id, area = data3$size, group = data3$Storage, color = data3$col, lab=c(TRUE,TRUE), main="Test Map")
>> dev.off()
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Wed Jun  3 14:43:34 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 3 Jun 2015 04:43:34 -0800
Subject: [R] Upload Error Occurred in uploading markdown file to RPubs
In-Reply-To: <CAPmpGDvdES3zhm0gPBU5yusniQFJT9LK7hoL7D+W9aW2kFpC5A@mail.gmail.com>
Message-ID: <BCEFB88336B.000008A7jrkrideau@inbox.com>

Hi Antonello,
I had never heard of Rpubs until now so I went and had a look.  It seems to have allowed me to register but I don't seem to be able to do anything. I tried goign to the support page (bottom of intro page) and go a message "This site is closed" so it may be they are down or having a few technical difficulties
Visit to site at approx 2115-06-03 08:42 EDT

John Kane
Kingston ON Canada


> -----Original Message-----
> From: antoviral at gmail.com
> Sent: Wed, 3 Jun 2015 11:49:23 +0200
> To: r-help at r-project.org
> Subject: [R] Upload Error Occurred in uploading markdown file to RPubs
> 
> Hi, I do not know whether someone had the same problem and if s/he can
> help
> me with some advice.
> 
> I'm using RPubs from RStudio to publish tutorials and exercises.
> 
> On June 2, I've published a Markdown post in RPubs with RStudio.
> So, I'm sure the system can connect to Rpubs without any issues.
> 
> Some hours later, I've prepared another short Markdown post, an exercise
> with ggmap (which plots maps from Google and other repositories).
> 
> I've got a message of error (Upload Error Occurred), with this
> specification:
> {"continueUrl":"
> http://rpubs.com/publish/claim/84372/337a3056d40548f4ae3d1c3d7b1f2f34"}
> 
> I do not know what happens and what to do.
> Thank you in advance,
> Antonello
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From sarah.goslee at gmail.com  Wed Jun  3 16:03:18 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 3 Jun 2015 10:03:18 -0400
Subject: [R] Adding columns to a 2D vector
In-Reply-To: <5EAA21940C65214F9C11DA5FBBC14F0B3FD89C29D6@EXCHANGE2.ad.nottingham.ac.uk>
References: <5EAA21940C65214F9C11DA5FBBC14F0B3FD89C29D6@EXCHANGE2.ad.nottingham.ac.uk>
Message-ID: <CAM_vjumYn5eAbPwBJNL9+vLD8ax3fJdOe-xzbXXrvyGbX2uFAA@mail.gmail.com>

Hi,

On Wed, Jun 3, 2015 at 8:26 AM, Thomas Chesney
<Thomas.Chesney at nottingham.ac.uk> wrote:
> I'd like to add some columns into the middle of this:
>
> vec <- c(1, -1)
> lst <- lapply(numeric(n-1), function(x) vec)
> combos <- as.matrix(expand.grid(lst))
> colnames(combos) <- NULL

This isn't quite reproducible, since n is undefined. I substituted
numeric(6), since that gives the right number of columns.

I'd take advantage of R's habit (bug or feature? your call!) of
repeating items as needed:
combos2 <- cbind(0, combos[, 1:3], 0, combos[, 4:6], 0)


> The way I have used is:
>
> combos2 <- matrix(NA, nrow=64, ncol=9)
> combos2[,1] <- 0
> combos2[,2] <- combos[,1]
> combos2[,3] <- combos[,2]
> combos2[,4] <- combos[,3]
> combos2[,5] <- 0
> combos2[,6] <- combos[,4]
> combos2[,7] <- combos[,5]
> combos2[,8] <- combos[,6]
> combos2[,9] <- 0
>
> But I guess there is an easier way - is there a way to simply insert new columns into combos?
>
> BTW I know I could have shortened this a bit to:
>
> combos2[,2:4] <- combos[,1:3]
>
> ==========
>
> Also can anyone recommend a good source to explain my combos data type? I don't fully understand all the output of this:
>
> str(combos)
>  num [1:64, 1:6] 1 -1 1 -1 1 -1 1 -1 1 -1 ...
>  - attr(*, "dimnames")=List of 2
>   ..$ : NULL
>   ..$ : NULL

Well, take a careful look.
The first line tells you that your matrix is numeric (matrices can
only contain elements of one type), that it has 64 rows and 6 columns,
and a bit of what the contents look like.
The second line tells you that your matrix has as attributes a list of
two dimnames, and the subsequent lines tell you that both row and
column names are NULL (because you set them that way!)

Try, for example, str(data.frame(combos)) and compare. Working through
the examples in ?str might also help.

Sarah


> Thank you,
>
> Thomas Chesney
>
>
>


From macqueen1 at llnl.gov  Wed Jun  3 16:31:47 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 3 Jun 2015 14:31:47 +0000
Subject: [R] Colour gradient is not working.
In-Reply-To: <CAF8bMcaYPQuxoc-s99uScwkV6Fx5mCs1Ubh-E_P5EZHyCHz0Ng@mail.gmail.com>
References: <1433157134298-4708000.post@n4.nabble.com>
	<D191C501.12C8FB%macqueen1@llnl.gov>
	<1433234355275-4708036.post@n4.nabble.com>
	<CAF8bMcaYPQuxoc-s99uScwkV6Fx5mCs1Ubh-E_P5EZHyCHz0Ng@mail.gmail.com>
Message-ID: <D1945C4A.12CD6C%macqueen1@llnl.gov>

Another trick if Bill is correct is to sort the data first, by whatever
variable the color is intended to represent.


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/2/15, 9:06 AM, "William Dunlap" <wdunlap at tibco.com> wrote:

>Points later in the input vectors may be obscuring earlier
>points.  If that is the problem then use pch="." or cex=.2
>(or some other small number) to make the plot symbols
>smaller so they don't overlap as much.  Sometimes using
>transparency helps also - try using adjustcolor(Color(n), alpha.f=0.5)
>instead of Color(n).
>
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>On Tue, Jun 2, 2015 at 1:39 AM, sreenath <sreenath.rajur at macfast.ac.in>
>wrote:
>
>> sir i done this plot(1:33292, 1:33292,col=Color(33292)) command then it
>> gives
>> the coloured line but again it is not working  in my data why?
>>
>>
>>
>> --
>> View this message in context:
>> 
>>http://r.789695.n4.nabble.com/Colour-gradient-is-not-working-tp4708000p47
>>08036.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From topijush at gmail.com  Wed Jun  3 11:01:58 2015
From: topijush at gmail.com (Pijush Das)
Date: Wed, 3 Jun 2015 14:31:58 +0530
Subject: [R] SVM error
Message-ID: <CAGa91zhFx8wBaLmUezCBG88LbXgOOy=QPeKR_61Z4Jp4cB1P_A@mail.gmail.com>

Dear Sir,


I am working with SVM recently, facing a problem which is given below.
If you able to solve the problem, please send me the code.


Thank you very much.

>library(e1071)
>library(openxlsx)

> List<- read.xlsx(file.choose(), sheet = 1, colNames=TRUE,rowNames = TRUE)
> Data<- read.xlsx(file.choose(), sheet=1,colNames = TRUE,rowNames = TRUE)
> status<-Data[1, ]
> FData <-Data[rownames(List), ]
> TFData <- t(FData)
> Tstatus <- t(status)
> x<-TFData
> y<-Tstatus
> model <- svm( x, y)
Error in colMeans(x, na.rm = TRUE) : 'x' must be numeric





With regards
Pijush

From amelia_marsh08 at yahoo.com  Wed Jun  3 11:09:27 2015
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Wed, 3 Jun 2015 09:09:27 +0000 (UTC)
Subject: [R] Splitting and arranging in ascending order
Message-ID: <759816911.2418939.1433322567037.JavaMail.yahoo@mail.yahoo.com>

Dear R forum

I have a data (actually its a big data and I am only giving part of my interest) as

my_dat = data.frame(instrument = c("EQ_0", "EQ_1", "EQ_10", "EQ_100", "EQ_2", "EQ_20", "IRS_0", "IRS_1", "IRS_10", "IRS_100", "IRS_2", "IRS_20"), mtm_value = c(23, 63, 8, 44, 68, 11, 83, 56, 73, 92, 14, 7))

> my_dat 
instrument mtm_value 
1        EQ_0     23 
2        EQ_1     63 
3       EQ_10    8 
4      EQ_100   44 
5        EQ_2     68 
6       EQ_20    11 
7       IRS_0    83 
8       IRS_1    56 
9      IRS_10   73 
10    IRS_100        92 
11      IRS_2   14 
12     IRS_20   7

I need to split the first column and arrange the output in the ascending order as shown below :

  instrument sr_no   mtm_value 

1          EQ          0      23 
2          EQ          1      63 
3          EQ          2      68 
4          EQ         10       8 
5          EQ         20      11 
6          EQ        100      44 
7         IRS         0      83 
8         IRS         1      56 
9         IRS         2      14 
10        IRS       10      73 
11        IRS       20       7 
12        IRS      100      92

I tried to use gsub, strsplit  but doesn't give me the required output.

Kindly guide

Regards

Amelia


From dah_069 at hotmail.com  Wed Jun  3 12:46:53 2015
From: dah_069 at hotmail.com (Don Hessey)
Date: Wed, 3 Jun 2015 06:46:53 -0400
Subject: [R] xpathSApply skip if text equals postseason
Message-ID: <SNT149-W72E78EE22C1C7CDAE7CD6EC2B40@phx.gbl>

I'm running into a road block here and I can't figure out what I'm doing wrong.  I need to skip over the link if the text equals postseason.  The text is in the second li in the xpaths below in my code. I tried li[not(.,"postseason")] as I thought that is what I needed to exclude the postseason link but it doesn't work. This link will show you an example of want I want to exclude under standard batting > game logs > postseason http://www.baseball-reference.com/players/j/jeterde01.shtml place this http://www.baseball-reference.com/players/j/jeterde01.shtml in playerURLs and you should season the postseason link returned.  How can I skip over the postseason link?  Thanks! #GET YEARS PLAYED LINKS 


yplist = NULL 

playerURLs <- paste("http://www.baseball-reference.com",datafile17[,c("hrefs")],sep="") 

for(thisplayerURL in playerURLs){ 

doc <- htmlParse(thisplayerURL) 
yplinks <- data.frame( 
  names =  xpathSApply(doc, '//*[@id="all_standard_batting"]/div//ul/li[2]/ul/li/a',xmlValue), 
  hrefs = xpathSApply(doc, '//*[@id="all_standard_batting"]/div/ul/li[2]/ul/li/a',xmlGetAttr,'href')) 

yplist = rbind(yplist, yplinks) 

} 

yplist[,c("hrefs")] 		 	   		  
	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Wed Jun  3 17:09:22 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 3 Jun 2015 15:09:22 +0000
Subject: [R] Clarification about data/weekday conversion
In-Reply-To: <CA+AQxOqfCoON_wTtjeyTn59bXp9CZtNQpWB_k0tY2xZH6Gi0aw@mail.gmail.com>
References: <CA+AQxOqfCoON_wTtjeyTn59bXp9CZtNQpWB_k0tY2xZH6Gi0aw@mail.gmail.com>
Message-ID: <D1945FF2.12CD8A%macqueen1@llnl.gov>

First of all, the as.Date() function converted it to the Date class (not
"Date,format..", and I'd suggest the terminology is important here).

> class('2015-4-1')
[1] "character"

> class( as.Date('2015-4-1') )
[1] "Date"


Second, the format() function always converts to character class.

> n <- 3
> class(n)
[1] "numeric"
> class(format(n))
[1] "character"


or, continuing the date example

> class( format( as.Date('2015-4-1'), '%a %b %d %Y' ) )
[1] "character"



Third, any variable can only be one class at a time (but see caveat
below). It can't be both character and Date class at the same time. So the
answer to your "Is there a way ..." question is no.


Your strategy for dealing with this depends on what you are trying to
accomplish.

For example, if you need to sort by date, then keep the Date class
version. If you want to use the "weekday" version to label things, use the
format() function to create the labels, but keep the Date class version of
the variable, as Jim suggested. If necessary, keep both versions, which I
would do like this (not keeping the original character version):

  Hpc$Date <- as.Date(Hpc$Date, "%d/%m/%Y")

  Hpc$DateC <- format(Hpc$Date, "%a %b %d %Y")


Then use one or the other of them, depending on what is needed.


Caveat: strictly speaking, an object can have more than one class in a
particular narrowly defined way. For example,

> class(Sys.time())
[1] "POSIXct" "POSIXt"


This was the basis of David's suggestion of creating a new class, but I
think that for your purposes at this time, you should stick with the "only
one class at a time" idea.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/2/15, 3:31 PM, "t.k. t.k." <tk9830 at gmail.com> wrote:

>Hi everyone
>This is a general question.
>I have imported a "Dates" variable as character. I used the "as.Date"
>command and convert it to Date,format..
>
>I want to change the display of the date to weekday (e.g., I want my time
>series to be instead of 15-04-2010 as Friday-04-2010). I used the "format"
>command but the variable reverts back to character. Is there a way to
>change the day to weekday and my variable remain a "Date,format..."
>variable?
>
>these are the two lines I used as code
>
>Hpc$Date1<- as.Date(Hpc$Date, "%d/%m/%Y")
>
>Hpc$Date1<-format(Hpc$Date1, "%a %b %d %Y")
>
>thanks in advance
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Wed Jun  3 17:21:35 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 03 Jun 2015 16:21:35 +0100
Subject: [R] Splitting and arranging in ascending order
In-Reply-To: <759816911.2418939.1433322567037.JavaMail.yahoo@mail.yahoo.com>
References: <759816911.2418939.1433322567037.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <556F1B7F.7040200@sapo.pt>

Hello,

Try the following.


tmp <- strsplit(as.character(my_dat$instrument), "_")
tmp <- t(as.data.frame(tmp))
tmp <- data.frame(instrument = tmp[,1],  sr_no = as.integer(tmp[, 2]), 
my_dat$mtm_value)
result <- tmp[order(tmp[, 1], tmp[, 2]), ]
rm(tmp)
rownames(result) <- NULL
result


Hope this helps,

Rui Barradas

Em 03-06-2015 10:09, Amelia Marsh escreveu:
> Dear R forum
>
> I have a data (actually its a big data and I am only giving part of my interest) as
>
> my_dat = data.frame(instrument = c("EQ_0", "EQ_1", "EQ_10", "EQ_100", "EQ_2", "EQ_20", "IRS_0", "IRS_1", "IRS_10", "IRS_100", "IRS_2", "IRS_20"), mtm_value = c(23, 63, 8, 44, 68, 11, 83, 56, 73, 92, 14, 7))
>
>> my_dat
> instrument mtm_value
> 1        EQ_0     23
> 2        EQ_1     63
> 3       EQ_10    8
> 4      EQ_100   44
> 5        EQ_2     68
> 6       EQ_20    11
> 7       IRS_0    83
> 8       IRS_1    56
> 9      IRS_10   73
> 10    IRS_100        92
> 11      IRS_2   14
> 12     IRS_20   7
>
> I need to split the first column and arrange the output in the ascending order as shown below :
>
>    instrument sr_no   mtm_value
>
> 1          EQ          0      23
> 2          EQ          1      63
> 3          EQ          2      68
> 4          EQ         10       8
> 5          EQ         20      11
> 6          EQ        100      44
> 7         IRS         0      83
> 8         IRS         1      56
> 9         IRS         2      14
> 10        IRS       10      73
> 11        IRS       20       7
> 12        IRS      100      92
>
> I tried to use gsub, strsplit  but doesn't give me the required output.
>
> Kindly guide
>
> Regards
>
> Amelia
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petr.pikal at precheza.cz  Wed Jun  3 17:24:06 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 3 Jun 2015 15:24:06 +0000
Subject: [R] Splitting and arranging in ascending order
In-Reply-To: <759816911.2418939.1433322567037.JavaMail.yahoo@mail.yahoo.com>
References: <759816911.2418939.1433322567037.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2F692@SRVEXCHMBX.precheza.cz>

Hi

there is probably easy solution by gsub but it is not my cup of tea so I used strsplit

spl<-data.frame(t(matrix(unlist(strsplit(as.character(my_dat$instrument), "_")),2)))
res<-data.frame(spl, my_dat$mtm_value)
> res
    X1  X2 my_dat.mtm_value
1   EQ   0               23
2   EQ   1               63
3   EQ  10                8
4   EQ 100               44
5   EQ   2               68
6   EQ  20               11
7  IRS   0               83
8  IRS   1               56
9  IRS  10               73
10 IRS 100               92
11 IRS   2               14
12 IRS  20                7

For ordering use ?order or ?sort. Changing column ?names is also trivial.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Amelia
> Marsh
> Sent: Wednesday, June 03, 2015 11:09 AM
> To: r-help at r-project.org
> Subject: [R] Splitting and arranging in ascending order
>
> Dear R forum
>
> I have a data (actually its a big data and I am only giving part of my
> interest) as
>
> my_dat = data.frame(instrument = c("EQ_0", "EQ_1", "EQ_10", "EQ_100",
> "EQ_2", "EQ_20", "IRS_0", "IRS_1", "IRS_10", "IRS_100", "IRS_2",
> "IRS_20"), mtm_value = c(23, 63, 8, 44, 68, 11, 83, 56, 73, 92, 14, 7))
>
> > my_dat
> instrument mtm_value
> 1        EQ_0     23
> 2        EQ_1     63
> 3       EQ_10    8
> 4      EQ_100   44
> 5        EQ_2     68
> 6       EQ_20    11
> 7       IRS_0    83
> 8       IRS_1    56
> 9      IRS_10   73
> 10    IRS_100        92
> 11      IRS_2   14
> 12     IRS_20   7
>
> I need to split the first column and arrange the output in the
> ascending order as shown below :
>
>   instrument sr_no   mtm_value
>
> 1          EQ          0      23
> 2          EQ          1      63
> 3          EQ          2      68
> 4          EQ         10       8
> 5          EQ         20      11
> 6          EQ        100      44
> 7         IRS         0      83
> 8         IRS         1      56
> 9         IRS         2      14
> 10        IRS       10      73
> 11        IRS       20       7
> 12        IRS      100      92
>
> I tried to use gsub, strsplit  but doesn't give me the required output.
>
> Kindly guide
>
> Regards
>
> Amelia
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ingorfano at hotmail.com  Wed Jun  3 17:32:03 2015
From: ingorfano at hotmail.com (valerio orfano)
Date: Wed, 3 Jun 2015 17:32:03 +0200
Subject: [R] R convert pdf/png to html
In-Reply-To: <SNT149-W72E78EE22C1C7CDAE7CD6EC2B40@phx.gbl>
References: <SNT149-W72E78EE22C1C7CDAE7CD6EC2B40@phx.gbl>
Message-ID: <BLU437-SMTP57CC431318B7FC3B3B8868B4B40@phx.gbl>

Hi All

Is there any chance in R to convert a png and/or pdf file into an html?
Any example?

I?ve tried htmlize but doesn?t work out!

Rgds valerio

From boris.steipe at utoronto.ca  Wed Jun  3 17:39:29 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 3 Jun 2015 11:39:29 -0400
Subject: [R] SVM error
In-Reply-To: <CAGa91zhFx8wBaLmUezCBG88LbXgOOy=QPeKR_61Z4Jp4cB1P_A@mail.gmail.com>
References: <CAGa91zhFx8wBaLmUezCBG88LbXgOOy=QPeKR_61Z4Jp4cB1P_A@mail.gmail.com>
Message-ID: <FADDED3C-8233-4F9D-B02D-AB21D9078077@utoronto.ca>

svm() needs a matrix as input but read.xlsx() produces a data frame.


B.



On Jun 3, 2015, at 5:01 AM, Pijush Das <topijush at gmail.com> wrote:

> Dear Sir,
> 
> 
> I am working with SVM recently, facing a problem which is given below.
> If you able to solve the problem, please send me the code.
> 
> 
> Thank you very much.
> 
>> library(e1071)
>> library(openxlsx)
> 
>> List<- read.xlsx(file.choose(), sheet = 1, colNames=TRUE,rowNames = TRUE)
>> Data<- read.xlsx(file.choose(), sheet=1,colNames = TRUE,rowNames = TRUE)
>> status<-Data[1, ]
>> FData <-Data[rownames(List), ]
>> TFData <- t(FData)
>> Tstatus <- t(status)
>> x<-TFData
>> y<-Tstatus
>> model <- svm( x, y)
> Error in colMeans(x, na.rm = TRUE) : 'x' must be numeric
> 
> 
> 
> 
> 
> With regards
> Pijush
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hannah.hlx at gmail.com  Wed Jun  3 17:56:16 2015
From: hannah.hlx at gmail.com (li li)
Date: Wed, 3 Jun 2015 11:56:16 -0400
Subject: [R] How to add legend to a dotplot
In-Reply-To: <000701d09dd1$d959efa0$8c0dcee0$@bigpond.com>
References: <CAHLnndZy+Q4_RAy6GuEj7dM6bYn0aKJPLvDUj3f6HAKpdD-gUQ@mail.gmail.com>
	<000701d09dd1$d959efa0$8c0dcee0$@bigpond.com>
Message-ID: <CAHLnndbtAupic-C-pPsTZ+0+A9Z=PCOe46JzJZVMHhEgi6PX3Q@mail.gmail.com>

Thank you! It worked.
   Hanna

2015-06-03 3:49 GMT-04:00, Duncan Mackay <dulcalma at bigpond.com>:
> Hi
> If you use the lattice package and not resort to other packages read the ?
> xyplot carefully
> There are several ways to put a key in the graph including auto.key if you
> want something simple ie default
> The examples at the bottom give some ideas
>
> If you want something special you can use key = list(...) eg
>
>            key      = list(text = list(labels = LETTERS[1:3],   cex  =
> c(1,1,1) ),
>                            title = "Farm", cex.title = 1,
>                            points = list(pch = c(20,20,3),
>                                          col = c("black","grey","grey")),
>                            lines = list(lwd = c(2,1,2),
>                                         lty = c(1,1,1),
>                                         col = c("black","black","grey80")),
>                             space = "bottom"),
> which gives 3 columns: text points and lines.
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of li li
> Sent: Wednesday, 3 June 2015 13:07
> To: r-help
> Subject: [R] How to add legend to a dotplot
>
> Hi all,
>   I wanted to add the legend to a dotplot using legend funciton. If
> does not seem to be working? Anyone have any suggestions?
>   Thanks!
>   Hanna
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From thierry.onkelinx at inbo.be  Wed Jun  3 17:56:28 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 3 Jun 2015 17:56:28 +0200
Subject: [R] Difference between 32-bit and 64-bit version
Message-ID: <CAJuCY5wA8kw0pPX5eTwWns6mik8vn17VbVuLgOQfD7SSYzJZ-Q@mail.gmail.com>

Dear all,

I'm a bit puzzled by the difference in an object when created in R 32-bit
and R 64-bit.

Consider the code below. test.rda is available at
https://drive.google.com/file/d/0BzBrlGSuB9n-NFBWeC1TR093Sms/view?usp=sharing

# Run in R 3.2.0 Windows 32-bit, lme4 1.1-8
library(lme4)
load("test.rda")
coef.32 <- coef(test)
save(coef.32, file = "32bit.rda")

# Run in R 3.2.0 Windows 64-bit, lme4 1.1-8
library(lme4)
load("~/test.rda")
coef.64 <- coef(test)
save(coef.64, file = "64bit.rda")


# Compare the results
# Run in R 3.2.0 Windows 32-bit, lme4 1.1-8
# Run in R 3.2.0 Windows 64-bit, lme4 1.1-8
library(lme4)
load("32bit.rda")
load("64bit.rda")
identical(coef.32, coef.64) # FALSE
identical(coef.32$fRow, coef.64$fRow) # FALSE
identical(coef.32$fLocation, coef.64$fLocation) # TRUE
identical(coef.32$fSubLocation, coef.64$fSubLocation) # TRUE

The first comparison is FALSE, because the second is FALSE. But why is the
second FALSE and the third and fourth TRUE?

My goal is the calculate a SHA1 hash on the coef(test) to track if the
coefficients of test have changed. I'd like to get the same hash on a
32-bit and 64-bit system. A simple hack would be to calculate the hash on
round(coef(test), 20). Is that a good or bad idea?

identical(round(coef.32$fRow, 20), round(coef.64$fRow, 20)) # TRUE

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Wed Jun  3 18:08:49 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 3 Jun 2015 12:08:49 -0400
Subject: [R] R convert pdf/png to html
In-Reply-To: <BLU437-SMTP57CC431318B7FC3B3B8868B4B40@phx.gbl>
References: <SNT149-W72E78EE22C1C7CDAE7CD6EC2B40@phx.gbl>
	<BLU437-SMTP57CC431318B7FC3B3B8868B4B40@phx.gbl>
Message-ID: <A6F4374B-8171-42B1-96F6-4B2A2E2818CC@utoronto.ca>

... as in: the png exists in a directory that is accessible to the server?

That would be as simple as creating a HTML document with the following contents:

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
  <head><title="Image"></head>
  <body><img src="myPNGimage.png"></body>
</html>


B.


On Jun 3, 2015, at 11:32 AM, valerio orfano <ingorfano at hotmail.com> wrote:

> Hi All
> 
> Is there any chance in R to convert a png and/or pdf file into an html?
> Any example?
> 
> I?ve tried htmlize but doesn?t work out!
> 
> Rgds valerio
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Jun  3 18:09:02 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 03 Jun 2015 12:09:02 -0400
Subject: [R] Difference between 32-bit and 64-bit version
In-Reply-To: <CAJuCY5wA8kw0pPX5eTwWns6mik8vn17VbVuLgOQfD7SSYzJZ-Q@mail.gmail.com>
References: <CAJuCY5wA8kw0pPX5eTwWns6mik8vn17VbVuLgOQfD7SSYzJZ-Q@mail.gmail.com>
Message-ID: <556F269E.5050904@gmail.com>

On 03/06/2015 11:56 AM, Thierry Onkelinx wrote:
> Dear all,
> 
> I'm a bit puzzled by the difference in an object when created in R 32-bit
> and R 64-bit.
> 
> Consider the code below. test.rda is available at
> https://drive.google.com/file/d/0BzBrlGSuB9n-NFBWeC1TR093Sms/view?usp=sharing
> 
> # Run in R 3.2.0 Windows 32-bit, lme4 1.1-8
> library(lme4)
> load("test.rda")
> coef.32 <- coef(test)
> save(coef.32, file = "32bit.rda")
> 
> # Run in R 3.2.0 Windows 64-bit, lme4 1.1-8
> library(lme4)
> load("~/test.rda")
> coef.64 <- coef(test)
> save(coef.64, file = "64bit.rda")
> 
> 
> # Compare the results
> # Run in R 3.2.0 Windows 32-bit, lme4 1.1-8
> # Run in R 3.2.0 Windows 64-bit, lme4 1.1-8
> library(lme4)
> load("32bit.rda")
> load("64bit.rda")
> identical(coef.32, coef.64) # FALSE
> identical(coef.32$fRow, coef.64$fRow) # FALSE
> identical(coef.32$fLocation, coef.64$fLocation) # TRUE
> identical(coef.32$fSubLocation, coef.64$fSubLocation) # TRUE
> 
> The first comparison is FALSE, because the second is FALSE. But why is the
> second FALSE and the third and fourth TRUE?
> 
> My goal is the calculate a SHA1 hash on the coef(test) to track if the
> coefficients of test have changed. I'd like to get the same hash on a
> 32-bit and 64-bit system. A simple hack would be to calculate the hash on
> round(coef(test), 20). Is that a good or bad idea?
> 
> identical(round(coef.32$fRow, 20), round(coef.64$fRow, 20)) # TRUE

Different math libraries round differently, so small differences are
expected.  This is FAQ 7.31.  In many cases the 32 bit calculations are
more accurate, because they tend to use more 80 bit extended precision
intermediate values, but that is not guaranteed.

Rounding before comparing makes sense, but I would use signif() instead
of round(), I would choose a relatively small number of significant
digits, and I would expect to see a few false positives:  if the true
value is 0 but some "random" noise is added, I'd expect values rounded
by signif() to be unequal.

Duncan Murdoch

> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From johnwasige at gmail.com  Wed Jun  3 18:32:35 2015
From: johnwasige at gmail.com (John Wasige)
Date: Wed, 3 Jun 2015 18:32:35 +0200
Subject: [R] Adding legend
Message-ID: <CAJgdCD6QHwvUyTBmFcycJPNBLiahquqCO9Dk7W1LLnupcdiRjg@mail.gmail.com>

?Hello community,

Could somebody help on how I can a legend to my heatmap plot. I need to
know what values from the data do colours ( "red","yellow",
"yellowgreen","lightblue4") represent from the data. The script is here
below and attached is the test dataset. Thanks for your help.

Hohn

########## script
?

?library(wq)

setwd("D:/data")
Pmid <- read.csv('D:/data/MyData1.csv')

Pmid.ts = ts(Pmid,start=c(1981,1),end=c(1995,12),frequency = 12)

# convert time series into vector
Pmid.ts.df = ts2df(Pmid.ts, mon1 = 1, addYr = F, omit = FALSE)
# convert vector into data matrix
Pmid.ts.dm = data.matrix(Pmid.ts.df)
# covnert data matrix into heatmap
Pmid_heatmap <- heatmap(Pmid.ts.dm, Rowv=NA, Colv=NA, col =
c("red","yellow", "yellowgreen","lightblue4"), scale="row")
# you can transpose the dataframe if you want to flip the image
Pmid_heatmap <- heatmap(t(Pmid.ts.dm), Rowv=NA, Colv=NA, col =
c("red","yellow", "yellowgreen","lightblue4"), scale="column")

##############

# example plot
jpeg(filename = "heatMap01.jpg",
     width = 800, height = 400, units = "px", pointsize = 6,
     quality = 100, bg = "white", res = 144, type = "cairo")
heatmap(t(Pmid.ts.dm), Rowv=NA, Colv=NA, col = c("red","yellow",
"yellowgreen","lightblue4"), scale="column", legend(40,
2,legend=c("Title","","Group1","Group2"), fill=c("white", "white",
"green","black"), border=FALSE, bty="n", y.intersp = 0.7, cex=0.7))
dev.off()?

From ingorfano at hotmail.com  Wed Jun  3 18:38:11 2015
From: ingorfano at hotmail.com (valerio orfano)
Date: Wed, 3 Jun 2015 18:38:11 +0200
Subject: [R] R convert pdf/png to html
In-Reply-To: <A6F4374B-8171-42B1-96F6-4B2A2E2818CC@utoronto.ca>
References: <SNT149-W72E78EE22C1C7CDAE7CD6EC2B40@phx.gbl>
	<BLU437-SMTP57CC431318B7FC3B3B8868B4B40@phx.gbl>
	<A6F4374B-8171-42B1-96F6-4B2A2E2818CC@utoronto.ca>
Message-ID: <BLU436-SMTP2536073DF8683728EBE8301B4B40@phx.gbl>

Hi Boris and thanx a lot

Which library should i be using to create html in R?

rgds valerio
On 03 Jun 2015, at 18:08, Boris Steipe <boris.steipe at utoronto.ca> wrote:

> ... as in: the png exists in a directory that is accessible to the server?
> 
> That would be as simple as creating a HTML document with the following contents:
> 
> <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
> <html>
>  <head><title="Image"></head>
>  <body><img src="myPNGimage.png"></body>
> </html>
> 
> 
> B.
> 
> 
> On Jun 3, 2015, at 11:32 AM, valerio orfano <ingorfano at hotmail.com> wrote:
> 
>> Hi All
>> 
>> Is there any chance in R to convert a png and/or pdf file into an html?
>> Any example?
>> 
>> I?ve tried htmlize but doesn?t work out!
>> 
>> Rgds valerio
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From johnwasige at gmail.com  Wed Jun  3 18:39:13 2015
From: johnwasige at gmail.com (John Wasige)
Date: Wed, 3 Jun 2015 18:39:13 +0200
Subject: [R] Adding legend
Message-ID: <CAJgdCD7KkVoz3Dc_gaSY_W0UQcdPtMjyaCAHbrXTgoKnc4-GZQ@mail.gmail.com>

?Hello community,

Could somebody help on how I can
?add ?
a legend to my heatmap plot. I need to know what values from the data do
colours ( "red","yellow", "yellowgreen","lightblue4") represent from the
data. The script is here below and attached is the test dataset. Thanks for
your help.

Hohn

########## script
?

?library(wq)

setwd("D:/data")
Pmid <- read.csv('D:/data/MyData1.csv')

Pmid.ts = ts(Pmid,start=c(1981,1),end=c(1995,12),frequency = 12)

# convert time series into vector
Pmid.ts.df = ts2df(Pmid.ts, mon1 = 1, addYr = F, omit = FALSE)
# convert vector into data matrix
Pmid.ts.dm = data.matrix(Pmid.ts.df)
# covnert data matrix into heatmap
Pmid_heatmap <- heatmap(Pmid.ts.dm, Rowv=NA, Colv=NA, col =
c("red","yellow", "yellowgreen","lightblue4"), scale="row")
# you can transpose the dataframe if you want to flip the image
Pmid_heatmap <- heatmap(t(Pmid.ts.dm), Rowv=NA, Colv=NA, col =
c("red","yellow", "yellowgreen","lightblue4"), scale="column")

##############

# example plot
jpeg(filename = "heatMap01.jpg",
     width = 800, height = 400, units = "px", pointsize = 6,
     quality = 100, bg = "white", res = 144, type = "cairo")
heatmap(t(Pmid.ts.dm), Rowv=NA, Colv=NA, col = c("red","yellow",
"yellowgreen","lightblue4"), scale="column", legend(40,
2,legend=c("Title","","Group1","Group2"), fill=c("white", "white",
"green","black"), border=FALSE, bty="n", y.intersp = 0.7, cex=0.7))
dev.off()?

From dwinsemius at comcast.net  Wed Jun  3 18:48:04 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 3 Jun 2015 09:48:04 -0700
Subject: [R] Graphs for scientific publication ?
In-Reply-To: <CACyTWRYGf0efZKYf=ssEGLa=cLe3qUfbPC5HBK-jy8S43NJCqA@mail.gmail.com>
References: <CACyTWRYGf0efZKYf=ssEGLa=cLe3qUfbPC5HBK-jy8S43NJCqA@mail.gmail.com>
Message-ID: <13369719-AD4F-45BA-A65E-F58BE80C6124@comcast.net>


On Jun 3, 2015, at 3:30 AM, Jeremy Clark wrote:

> The coding I've settled on to save file without clipping is:

What exactly was "clipping". You earlier complained about "jaggies". There was no restriction of the plotted lines to the plot area in the example you earlier presented. That's what I understand "clipping" to mean.

> 
> library(gridExtra)
> gt <- ggplot_gtable(ggplot_build(q3))
> gt$layout$clip[gt$layout$name=="panel"] <- "off"
> gt4 <- arrangeGrob(gt)
> ggsave <- ggplot2::ggsave; body(ggsave) <- body(ggplot2::ggsave)[-2]
> ## from Baptiste
> ggsave("gt.pdf", plot = gt4, width = 6, height = 6)
> ggsave("gt.png", plot = gt4, width = 6, height = 6)
> 
> Part of the problem with plotmath is that as soon as paste is used the
> syntax needed is different eg. substitute and substitute(paste( do not
> accept the same syntax eg. == or "=".
> 

There's not much context for this. If you are bothered that that you need "=" inside paste and `==` outside, then you just need to spend more time understanding expression syntax.  I have found that plotmath's `paste` usually ends up obscuring a proper understanding of expression syntax. Would be annotators reach for plotmath-`paste` because they missed the part about using "*" and "~" to separate tokens.... Oh wait ... now I remember there isn't really any section in the ?plotmath page that actually says that, is there? (Sorry, Not my area of responsibility. Took me years to learn this.)

Your other complaint about plotmath not supporting line-breaks is a recognized problem. Multi-element expression vectors are one strategy to consider.  You should also look at the grid.text function if you are working in the ggplot2-world and want fine-tuned control. You are already building a grid-based structure. (And to your whine that ggplot2 is not in base-R, consider that the grid package is.) Bert Gunter's suggestion that you purchase Murrell's "R Graphics" should be remembered. It is essentially the assembly language in which ggplot2 is written.

Learn to use bquote ... You had:

rsquaredlm = NULL
rsquaredlm[[6]] <- 3 ## false value
listr2 <- list(r2 = rsquaredlm[[6]])
eq1 <- substitute(italic(R)^2 == r2, listr2)
eqstr1 <- as.character(as.expression(eq1))
q3 <- p2 +  annotate(geom = "text", x = 20, y = 30, label = eqstr1,
parse = TRUE, vjust = 1)

The results from `bquote` appear to be handled properly within ggplot2-code. (Lattice functions do not like `bquote` for its expressions, since they are not actually in expression mode.)

rsquaredlm = NULL
rsquaredlm[[6]] <- 3 
 eq1 <- bquote(italic(R)^2 == .(rsquaredlm[[6]]))  # the value will be substituted in the plot
 eqstr1 <- as.character(as.expression(eq1))
q3 <- p2 +  annotate(geom = "text", x = 20, y = 30, label = eqstr1,
parse = TRUE, vjust = 1)

-- 

David Winsemius
Alameda, CA, USA


From macqueen1 at llnl.gov  Wed Jun  3 19:06:11 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 3 Jun 2015 17:06:11 +0000
Subject: [R] R convert pdf/png to html
In-Reply-To: <BLU436-SMTP2536073DF8683728EBE8301B4B40@phx.gbl>
References: <SNT149-W72E78EE22C1C7CDAE7CD6EC2B40@phx.gbl>
	<BLU437-SMTP57CC431318B7FC3B3B8868B4B40@phx.gbl>
	<A6F4374B-8171-42B1-96F6-4B2A2E2818CC@utoronto.ca>
	<BLU436-SMTP2536073DF8683728EBE8301B4B40@phx.gbl>
Message-ID: <D19481A1.12CE23%macqueen1@llnl.gov>

When it's as simple as in Boris's example, just use cat() statements.

Otherwise, go to CRAN, find the packages page ("Table of available
packages, sorted by name"), and search for "html"

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/3/15, 9:38 AM, "valerio orfano" <ingorfano at hotmail.com> wrote:

>Hi Boris and thanx a lot
>
>Which library should i be using to create html in R?
>
>rgds valerio
>On 03 Jun 2015, at 18:08, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>
>> ... as in: the png exists in a directory that is accessible to the
>>server?
>> 
>> That would be as simple as creating a HTML document with the following
>>contents:
>> 
>> <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
>>"http://www.w3.org/TR/html4/strict.dtd">
>> <html>
>>  <head><title="Image"></head>
>>  <body><img src="myPNGimage.png"></body>
>> </html>
>> 
>> 
>> B.
>> 
>> 
>> On Jun 3, 2015, at 11:32 AM, valerio orfano <ingorfano at hotmail.com>
>>wrote:
>> 
>>> Hi All
>>> 
>>> Is there any chance in R to convert a png and/or pdf file into an html?
>>> Any example?
>>> 
>>> I?ve tried htmlize but doesn?t work out!
>>> 
>>> Rgds valerio
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ecnolasco at gmail.com  Wed Jun  3 19:14:17 2015
From: ecnolasco at gmail.com (Erica Cseko Nolasco)
Date: Wed, 3 Jun 2015 14:14:17 -0300
Subject: [R] pairwise.t.test non numeric factors error
In-Reply-To: <CA+8X3fV6zuJOUQ+yMx644N5K00+RHj3c+5xdL7uEFCxXdWxudw@mail.gmail.com>
References: <CAMbrGjHztZFofwCAHrmMvQzycF6KcvSw50i=o_E0hcDoE0Rd3w@mail.gmail.com>
	<CA+8X3fV6zuJOUQ+yMx644N5K00+RHj3c+5xdL7uEFCxXdWxudw@mail.gmail.com>
Message-ID: <CAMbrGjEKmp+=J0WovW2Ydk_e1F6CfNcFodW2QF735fEF9n2=ew@mail.gmail.com>

Thanks Jim,

I removed the corresponding cases and tried again. What I discovery now is
if I run the function without paired = T (pairwise.t.test(x =
data$tss,data$pa) is works. However, if I add the paired = T
(pairwise.t.test(x = data$tss,data$pa,paired = T) is gives me the error ' Error
in complete.cases(x, y) :   not all arguments have the same length'. In
fact it seems to do a paired test even without the paired = T argument.
I really don't know why.

Regards,

*Erica Csek? Nolasco*
Mestranda em Modelagem em Ci?ncias da Terra e do Ambiente
http://lattes.cnpq.br/2117508819823917
Universidade Estadual de Feira de Santana
Avenida Transnordestina s/n, Novo Horizonte
Feira de Santana - BA, Brasil CEP 44.036-900.

Graduate Student in Modeling of Environmental and Earth Sciences
http://lattes.cnpq.br/2117508819823917
Universidade Estadual de Feira de Santana
Transnordestina Ave, Novo Horizonte
Feira de Santana - BA, Brazil 44.036-900.


2015-06-02 22:34 GMT-03:00 Jim Lemon <drjimlemon at gmail.com>:

> Hi Erica,
> The problem may be that you are specifying a grouping factor (mdl) in
> which the group sizes are unequal. If one case in group "tot" is
> missing, is it possible to identify the corresponding cases in the
> other factor levels and delete them?
>
> Jim
>
>
> On Tue, Jun 2, 2015 at 11:59 PM, Erica Cseko Nolasco
> <ecnolasco at gmail.com> wrote:
> > Dear listers,
> >
> > I'm performing a PERMANOVA (adonis{vegan}) to compare the results (ROC,
> > TSS) of models based on two factors (model, algo). I was not able to
> find a
> > pairwise test for adonis, on PRIMER it would be a Tukey test. Though, I
> > chose to perform a pairwise.t.test what would be quite simple. However,
> no
> > matter I rearrange my response and factor vectors (as a factor or
> numeric)
> > it gives me the following error (the code on the bottom - Error in
> > complete.cases(x, y) :
> >   not all arguments have the same length). I also tried to make a list of
> > the vectors, but it also gives me the error 'Error in sort.list(y) : 'x'
> > must be atomic for 'sort.list' Have you called 'sort' on a list?'
> >
> > I would appreciate any suggestions to solve this issue.
> >
> > Best,
> >
> > Erica
> >
> >> setwd('D:\\Erica\\mestrado\\analises\\results')
> >> library(vegan)
> >> rest=read.table('results_permanova.txt',sep="\t",header=T)
> >> rest$modelN=as.numeric(rest$model)
> >> rest$algoN=as.numeric(rest$algo)
> >> data=rest[complete.cases(rest),]
> >> head(data)
> >   algo   pa  run model   ROC   TSS modelN algoN
> > 1  ANN  PA1 RUN1   alt 0.947 0.867      2     2
> > 2  ANN PA10 RUN1   alt 0.978 0.869      2     2
> > 3  ANN PA11 RUN1   alt 0.993 0.931      2     2
> > 4  ANN PA12 RUN1   alt 0.961 0.845      2     2
> > 5  ANN PA13 RUN1   alt 0.988 0.960      2     2
> > 6  ANN PA14 RUN1   alt 0.996 0.988      2     2
> >> summary(data)
> >       algo           pa         run             model           ROC
> >      TSS
> >  CTA    :240   PA10   : 120       :   0   alt      : 200   Min.   :0.5290
> > Min.   :0.0580
> >  FDA    :240   PA11   : 120   RUN1:2399   altPet   : 200   1st Qu.:0.8780
> > 1st Qu.:0.7160
> >  GAM    :240   PA12   : 120               b1       : 200   Median :0.9350
> > Median :0.8270
> >  GBM    :240   PA13   : 120               b13      : 200   Mean   :0.9184
> > Mean   :0.7988
> >  GLM    :240   PA14   : 120               b13PETalt: 200   3rd Qu.:0.9790
> > 3rd Qu.:0.9110
> >  MARS   :240   PA15   : 120               b14      : 200   Max.   :1.0000
> > Max.   :1.0000
> >  (Other):959   (Other):1679               (Other)  :1199
> >
> >      modelN           algoN
> >  Min.   : 2.000   Min.   : 2.000
> >  1st Qu.: 4.500   1st Qu.: 4.000
> >  Median : 7.000   Median : 7.000
> >  Mean   : 7.498   Mean   : 6.502
> >  3rd Qu.:10.000   3rd Qu.: 9.000
> >  Max.   :13.000   Max.   :11.000
> >
> >> tss=data$TSS
> >> summary(tss)
> >    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> >  0.0580  0.7160  0.8270  0.7988  0.9110  1.0000
> >> mdl=factor(data$model)
> >> summary(mdl)
> >       alt    altPet        b1       b13 b13PETalt       b14       b18
> >  b7       pet      pluv
> >       200       200       200       200       200       200       200
> > 200       200       200
> >      temp       tot
> >       200       199
> >> length(complete.cases(mdl,tss))
> > [1] 2399
> >> pairwise.t.test(tss,mdl,p.adj='bonf',paired=T,pool.sd = FALSE)
> > Error in complete.cases(x, y) :
> >   not all arguments have the same length
> >>
> >
> > *Erica Csek? Nolasco*
> > Mestranda em Modelagem em Ci?ncias da Terra e do Ambiente
> > http://lattes.cnpq.br/2117508819823917
> > Universidade Estadual de Feira de Santana
> > Avenida Transnordestina s/n, Novo Horizonte
> > Feira de Santana - BA, Brasil CEP 44.036-900.
> >
> > Graduate Student in Modeling of Environmental and Earth Sciences
> > http://lattes.cnpq.br/2117508819823917
> > Universidade Estadual de Feira de Santana
> > Transnordestina Ave, Novo Horizonte
> > Feira de Santana - BA, Brazil 44.036-900.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Wed Jun  3 19:45:48 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 3 Jun 2015 13:45:48 -0400
Subject: [R] R convert pdf/png to html
In-Reply-To: <D19481A1.12CE23%macqueen1@llnl.gov>
References: <SNT149-W72E78EE22C1C7CDAE7CD6EC2B40@phx.gbl>
	<BLU437-SMTP57CC431318B7FC3B3B8868B4B40@phx.gbl>
	<A6F4374B-8171-42B1-96F6-4B2A2E2818CC@utoronto.ca>
	<BLU436-SMTP2536073DF8683728EBE8301B4B40@phx.gbl>
	<D19481A1.12CE23%macqueen1@llnl.gov>
Message-ID: <CA+vqiLFfHQy=q-3NdFLw6jX6o7G5hwy+3vryEJ8LcNuHcdfEFA@mail.gmail.com>

Or try the brand-new way:

http://www.r-pkg.org/search.html?q=html

--Ista

On Wed, Jun 3, 2015 at 1:06 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> When it's as simple as in Boris's example, just use cat() statements.
>
> Otherwise, go to CRAN, find the packages page ("Table of available
> packages, sorted by name"), and search for "html"
>
> -Don
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 6/3/15, 9:38 AM, "valerio orfano" <ingorfano at hotmail.com> wrote:
>
>>Hi Boris and thanx a lot
>>
>>Which library should i be using to create html in R?
>>
>>rgds valerio
>>On 03 Jun 2015, at 18:08, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>
>>> ... as in: the png exists in a directory that is accessible to the
>>>server?
>>>
>>> That would be as simple as creating a HTML document with the following
>>>contents:
>>>
>>> <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
>>>"http://www.w3.org/TR/html4/strict.dtd">
>>> <html>
>>>  <head><title="Image"></head>
>>>  <body><img src="myPNGimage.png"></body>
>>> </html>
>>>
>>>
>>> B.
>>>
>>>
>>> On Jun 3, 2015, at 11:32 AM, valerio orfano <ingorfano at hotmail.com>
>>>wrote:
>>>
>>>> Hi All
>>>>
>>>> Is there any chance in R to convert a png and/or pdf file into an html?
>>>> Any example?
>>>>
>>>> I?ve tried htmlize but doesn?t work out!
>>>>
>>>> Rgds valerio
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roger.bos at rothschild.com  Wed Jun  3 19:56:09 2015
From: roger.bos at rothschild.com (Bos, Roger)
Date: Wed, 3 Jun 2015 17:56:09 +0000
Subject: [R] R convert pdf/png to html
In-Reply-To: <CA+vqiLFfHQy=q-3NdFLw6jX6o7G5hwy+3vryEJ8LcNuHcdfEFA@mail.gmail.com>
References: <SNT149-W72E78EE22C1C7CDAE7CD6EC2B40@phx.gbl>
	<BLU437-SMTP57CC431318B7FC3B3B8868B4B40@phx.gbl>
	<A6F4374B-8171-42B1-96F6-4B2A2E2818CC@utoronto.ca>
	<BLU436-SMTP2536073DF8683728EBE8301B4B40@phx.gbl>
	<D19481A1.12CE23%macqueen1@llnl.gov>
	<CA+vqiLFfHQy=q-3NdFLw6jX6o7G5hwy+3vryEJ8LcNuHcdfEFA@mail.gmail.com>
Message-ID: <0765308CD028654885F30322557308D81EE74F3B@NYCSM0208.rth.ad.rothschild.com>

Valerio,

Actually htmlize works pretty well.  I used it for a long time.  If you want to get the most help from this forum you need to provide a reproducible example showing htmlize not working for you.

Nevertheless, today I would recommend going with RMarkdown.  It may be overkill for your example, but if you want to produce HTML output in the future, it is good to know:

http://rmarkdown.rstudio.com/

Thanks,

Roger








***************************************************************
This message and any attachments are for the named person's use only.
This message may contain confidential, proprietary or legally privileged
information. No right to confidential or privileged treatment
of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately
notify the sender by e-mail, delete the message, any attachments and all
copies from your system and destroy any hard copies. You must
not, directly or indirectly, use, disclose, distribute,
print or copy any part of this message or any attachments if you are not
the intended recipient.



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ista Zahn
Sent: Wednesday, June 03, 2015 1:46 PM
To: MacQueen, Don
Cc: r-help at r-project.org
Subject: Re: [R] R convert pdf/png to html

Or try the brand-new way:

http://www.r-pkg.org/search.html?q=html

--Ista

On Wed, Jun 3, 2015 at 1:06 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> When it's as simple as in Boris's example, just use cat() statements.
>
> Otherwise, go to CRAN, find the packages page ("Table of available
> packages, sorted by name"), and search for "html"
>
> -Don
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 6/3/15, 9:38 AM, "valerio orfano" <ingorfano at hotmail.com> wrote:
>
>>Hi Boris and thanx a lot
>>
>>Which library should i be using to create html in R?
>>
>>rgds valerio
>>On 03 Jun 2015, at 18:08, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>
>>> ... as in: the png exists in a directory that is accessible to the
>>>server?
>>>
>>> That would be as simple as creating a HTML document with the
>>>following
>>>contents:
>>>
>>> <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
>>>"http://www.w3.org/TR/html4/strict.dtd">
>>> <html>
>>>  <head><title="Image"></head>
>>>  <body><img src="myPNGimage.png"></body>  </html>
>>>
>>>
>>> B.
>>>
>>>
>>> On Jun 3, 2015, at 11:32 AM, valerio orfano <ingorfano at hotmail.com>
>>>wrote:
>>>
>>>> Hi All
>>>>
>>>> Is there any chance in R to convert a png and/or pdf file into an html?
>>>> Any example?
>>>>
>>>> I?ve tried htmlize but doesn?t work out!
>>>>
>>>> Rgds valerio
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From boris.steipe at utoronto.ca  Wed Jun  3 20:26:51 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 3 Jun 2015 14:26:51 -0400
Subject: [R] Combining multiple probability weights for the sample()
	function.
In-Reply-To: <142413609C0A60488585AB47438ECD9D0F684CC8@ueastfexch01.UEA.AC.UK>
References: <142413609C0A60488585AB47438ECD9D0F684CC8@ueastfexch01.UEA.AC.UK>
Message-ID: <7B72FA2F-F456-462D-9245-95430535CE7D@utoronto.ca>

If letters 1 and 2 must be equal with p=0.5, and 1 and 3 must be equal with p=0.5, then letter 1 must be the same as either 2 or 3. Therefore:

Choose a letter.
Make a pair of (letter, (not letter)).
Reverse the pair with p = 0.5
Concatenate your letter and the pair.


Is that what you need?


B.



On Jun 2, 2015, at 8:26 AM, Benjamin Ward (ENV) <B.Ward at uea.ac.uk> wrote:

> Dear R-List,
> 
> I have a set of possibilities I want to sample from:
> 
> bases <- list(c('A', 'C'), c('A', 'G'), c('C', 'T'))
> possibilities <- as.matrix(expand.grid(bases))
> 
>> possibilities
> Var1 Var2 Var3
> [1,] "A"  "A"  "C"
> [2,] "C"  "A"  "C"
> [3,] "A"  "G"  "C"
> [4,] "C"  "G"  "C"
> [5,] "A"  "A"  "T"
> [6,] "C"  "A"  "T"
> [7,] "A"  "G"  "T"
> [8,] "C"  "G"  "T"
> 
> If I want to randomly sample one of these rows. If I do this, I find that it is 25% likely that my choice will have an identical first and last letter (e.g. [1,] "A"  "A"  "C"). It is also 25% likely that my choice will have an identical first and third letter (e.g. [4,] "C"  "G"  "C"). It is not likely at all that the second and third letter of my choice could be identical.
> 
> What I would like to do, is sample one of the rows, but given the constraint that the probability of drawing identical letters 1 and 2 should be 50% or 0.5, and at the same time the probability of drawing identical letters 1 and 3 should be 50%. I am unsure on how to do this, but I know it involves coming up with a modified set of weights for the sample() function. My progress is below, any advice is much appreciated.
> 
> Best Wishes,
> 
> Ben Ward, UEA.
> 
> 
> So I have used the following code to come up with a matrix, which contains weighting according to each criteria:
> 
> possibilities <- as.matrix(expand.grid(bases))
>  identities <- apply(possibilities, 1, function(x) c(x[1] == x[2], x[1] == x[3], x[2] == x[3]))
>  prob <- matrix(rep(0, length(identities)), ncol = ncol(identities))
>  consProb <- apply(identities, 1, function(x){0.5 / length(which(x))})
>  polProb <- apply(identities, 1, function(x){0.5 / length(which(!x))})
>  for(i in 1:nrow(identities)){
>    prob[i, which(identities[i,])] <- consProb[i]
>    prob[i, which(!identities[i,])] <- polProb[i]
>  }
>  rownames(prob) <- c("1==2", "1==3", "2==3")
>  colnames(prob) <- apply(possibilities, 1, function(x)paste(x, collapse = ", "))
> 
> This code gives the following matrix:
> 
>                A, A, C    C, A, C          A, G, C        C, G, C       A, A, T         C, A, T       A, G, T       C, G, T
> 1==2 0.25000000 0.08333333 0.08333333 0.08333333 0.25000000 0.08333333 0.08333333 0.08333333
> 1==3 0.08333333 0.25000000 0.08333333 0.25000000 0.08333333 0.08333333 0.08333333 0.08333333
> 2==3 0.06250000 0.06250000 0.06250000 0.06250000 0.06250000 0.06250000 0.06250000 0.06250000
> 
> Each column is one of the choices from 'possibilities', and each row gives a series of weights based on three different criteria:
> 
> Row 1, that if it possible from the choices for letter 1 == letter 2, that combined chance be 50%.
> Row 2, that if it possible from the choices for letter 1 == letter 3, that combined chance be 50%.
> Row 3, that if it possible from the choices for letter 2 == letter 3, that combined chance be 50%.
> 
> So:
> 
> If I used sample(x = 1:now(possibilities), size = 1, prob = prob[1,]) repeatedly, I expect about half the choices to contain identical letters 1 and 2.
> 
> If I used sample(x = 1:now(possibilities), size = 1, prob = prob[2,]) repeatedly, I expect about half the choices to contain identical letters 1 and 3.
> 
> If I used sample(x = 1:now(possibilities), size = 1, prob = prob[3,]) repeatedly, I expect about half the choices to contain identical letters 2 and 3. Except that in this case, since it is not possible.
> 
> Note each row sums to 1.
> 
> What I would like to do - if it is possible - is combine these three sets of weights into one set, that when used with
> sample(x = 1:nrow(possibilities, size = 1, prob = MAGICPROB) will give me a list of choices, where ~50% of them contain identical letters 1 and 2, AND ~50% of them contain identical letters 1 and 3, AND ~50% again contain identical letters 2 and 3 (except in this example as it is not possible from the choices).
> 
> Can multiple probability weightings be combined in such a manner?
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From djnordlund at frontier.com  Wed Jun  3 21:28:28 2015
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Wed, 03 Jun 2015 12:28:28 -0700
Subject: [R] Combining multiple probability weights for the sample()
	function.
In-Reply-To: <7B72FA2F-F456-462D-9245-95430535CE7D@utoronto.ca>
References: <142413609C0A60488585AB47438ECD9D0F684CC8@ueastfexch01.UEA.AC.UK>
	<7B72FA2F-F456-462D-9245-95430535CE7D@utoronto.ca>
Message-ID: <556F555C.9070201@frontier.com>

On 6/3/2015 11:26 AM, Boris Steipe wrote:
> If letters 1 and 2 must be equal with p=0.5, and 1 and 3 must be equal with p=0.5, then letter 1 must be the same as either 2 or 3. Therefore:
>
> Choose a letter.
> Make a pair of (letter, (not letter)).
> Reverse the pair with p = 0.5
> Concatenate your letter and the pair.
>
>
> Is that what you need?
>
>
> B.
>
>
>
> On Jun 2, 2015, at 8:26 AM, Benjamin Ward (ENV) <B.Ward at uea.ac.uk> wrote:
>
>> Dear R-List,
>>
>> I have a set of possibilities I want to sample from:
>>
>> bases <- list(c('A', 'C'), c('A', 'G'), c('C', 'T'))
>> possibilities <- as.matrix(expand.grid(bases))
>>
>>> possibilities
>> Var1 Var2 Var3
>> [1,] "A"  "A"  "C"
>> [2,] "C"  "A"  "C"
>> [3,] "A"  "G"  "C"
>> [4,] "C"  "G"  "C"
>> [5,] "A"  "A"  "T"
>> [6,] "C"  "A"  "T"
>> [7,] "A"  "G"  "T"
>> [8,] "C"  "G"  "T"
>>
>> If I want to randomly sample one of these rows. If I do this, I find that it is 25% likely that my choice will have an identical first and last letter (e.g. [1,] "A"  "A"  "C"). It is also 25% likely that my choice will have an identical first and third letter (e.g. [4,] "C"  "G"  "C"). It is not likely at all that the second and third letter of my choice could be identical.
>>
>> What I would like to do, is sample one of the rows, but given the constraint that the probability of drawing identical letters 1 and 2 should be 50% or 0.5, and at the same time the probability of drawing identical letters 1 and 3 should be 50%. I am unsure on how to do this, but I know it involves coming up with a modified set of weights for the sample() function. My progress is below, any advice is much appreciated.
>>
>> Best Wishes,
>>
>> Ben Ward, UEA.
>>
>>
>> So I have used the following code to come up with a matrix, which contains weighting according to each criteria:
>>
>> possibilities <- as.matrix(expand.grid(bases))
>>   identities <- apply(possibilities, 1, function(x) c(x[1] == x[2], x[1] == x[3], x[2] == x[3]))
>>   prob <- matrix(rep(0, length(identities)), ncol = ncol(identities))
>>   consProb <- apply(identities, 1, function(x){0.5 / length(which(x))})
>>   polProb <- apply(identities, 1, function(x){0.5 / length(which(!x))})
>>   for(i in 1:nrow(identities)){
>>     prob[i, which(identities[i,])] <- consProb[i]
>>     prob[i, which(!identities[i,])] <- polProb[i]
>>   }
>>   rownames(prob) <- c("1==2", "1==3", "2==3")
>>   colnames(prob) <- apply(possibilities, 1, function(x)paste(x, collapse = ", "))
>>
>> This code gives the following matrix:
>>
>>                 A, A, C    C, A, C          A, G, C        C, G, C       A, A, T         C, A, T       A, G, T       C, G, T
>> 1==2 0.25000000 0.08333333 0.08333333 0.08333333 0.25000000 0.08333333 0.08333333 0.08333333
>> 1==3 0.08333333 0.25000000 0.08333333 0.25000000 0.08333333 0.08333333 0.08333333 0.08333333
>> 2==3 0.06250000 0.06250000 0.06250000 0.06250000 0.06250000 0.06250000 0.06250000 0.06250000
>>
>> Each column is one of the choices from 'possibilities', and each row gives a series of weights based on three different criteria:
>>
>> Row 1, that if it possible from the choices for letter 1 == letter 2, that combined chance be 50%.
>> Row 2, that if it possible from the choices for letter 1 == letter 3, that combined chance be 50%.
>> Row 3, that if it possible from the choices for letter 2 == letter 3, that combined chance be 50%.
>>
>> So:
>>
>> If I used sample(x = 1:now(possibilities), size = 1, prob = prob[1,]) repeatedly, I expect about half the choices to contain identical letters 1 and 2.
>>
>> If I used sample(x = 1:now(possibilities), size = 1, prob = prob[2,]) repeatedly, I expect about half the choices to contain identical letters 1 and 3.
>>
>> If I used sample(x = 1:now(possibilities), size = 1, prob = prob[3,]) repeatedly, I expect about half the choices to contain identical letters 2 and 3. Except that in this case, since it is not possible.
>>
>> Note each row sums to 1.
>>
>> What I would like to do - if it is possible - is combine these three sets of weights into one set, that when used with
>> sample(x = 1:nrow(possibilities, size = 1, prob = MAGICPROB) will give me a list of choices, where ~50% of them contain identical letters 1 and 2, AND ~50% of them contain identical letters 1 and 3, AND ~50% again contain identical letters 2 and 3 (except in this example as it is not possible from the choices).
>>
>> Can multiple probability weightings be combined in such a manner?
>>
>>

Ben,

If I correctly understand your requirements, you can't do what you are 
asking.  If you only have the eight possibilities that you list, then to 
get letters 1 and two to match 50% of the time you must select row 1 
with probability=.25 and row 5 with probability=.25.  To have the first 
and third letters match 50% of the time you must select rows 2 and 4 
each with probability=.25.  Those probabilities sum to 1, so you can 
never select any of the other rows.

Am I missing something?

Dan

-- 
Daniel Nordlund
Bothell, WA USA


From dwinsemius at comcast.net  Wed Jun  3 21:34:36 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 3 Jun 2015 12:34:36 -0700
Subject: [R] Adding legend
In-Reply-To: <CAJgdCD7KkVoz3Dc_gaSY_W0UQcdPtMjyaCAHbrXTgoKnc4-GZQ@mail.gmail.com>
References: <CAJgdCD7KkVoz3Dc_gaSY_W0UQcdPtMjyaCAHbrXTgoKnc4-GZQ@mail.gmail.com>
Message-ID: <271CAB2F-CE3A-46D8-9FB0-143C3B5E2620@comcast.net>


On Jun 3, 2015, at 9:39 AM, John Wasige wrote:

> ?Hello community,
> 
> Could somebody help on how I can
> ?add ?
> a legend to my heatmap plot. I need to know what values from the data do
> colours ( "red","yellow", "yellowgreen","lightblue4") represent from the
> data. The script is here below and attached is the test dataset. Thanks for
> your help.
> 

No data available but for your question refer first to ?heatmap where you are told that the col argument gets passed to `image`. In ?image you are told (in the zlim section of Details) that:

zlim	
the minimum and maximum z values for which colors should be plotted, defaulting to the range of the finite values of z. Each of the given colors will be used to color an equispaced interval of this range. The midpoints of the intervals cover the range, so that values just outside the range will be plotted.

You can, of course, look at the code for an example of how to reliably build such a mapping of a range to the number of colors. The Details section also has advice for the col parameter if you wanted a wider range of colors.

The gplots::heatmap.2 function is used widely and has legend (where it is called color key) settings.
-- 
David.

> Hohn
> 
> ########## script
> ?
> 
> ?library(wq)
> 
> setwd("D:/data")
> Pmid <- read.csv('D:/data/MyData1.csv')
> 
> Pmid.ts = ts(Pmid,start=c(1981,1),end=c(1995,12),frequency = 12)
> 
> # convert time series into vector
> Pmid.ts.df = ts2df(Pmid.ts, mon1 = 1, addYr = F, omit = FALSE)
> # convert vector into data matrix
> Pmid.ts.dm = data.matrix(Pmid.ts.df)
> # covnert data matrix into heatmap
> Pmid_heatmap <- heatmap(Pmid.ts.dm, Rowv=NA, Colv=NA, col =
> c("red","yellow", "yellowgreen","lightblue4"), scale="row")
> # you can transpose the dataframe if you want to flip the image
> Pmid_heatmap <- heatmap(t(Pmid.ts.dm), Rowv=NA, Colv=NA, col =
> c("red","yellow", "yellowgreen","lightblue4"), scale="column")
> 
> ##############
> 
> # example plot
> jpeg(filename = "heatMap01.jpg",
>     width = 800, height = 400, units = "px", pointsize = 6,
>     quality = 100, bg = "white", res = 144, type = "cairo")
> heatmap(t(Pmid.ts.dm), Rowv=NA, Colv=NA, col = c("red","yellow",
> "yellowgreen","lightblue4"), scale="column", legend(40,
> 2,legend=c("Title","","Group1","Group2"), fill=c("white", "white",
> "green","black"), border=FALSE, bty="n", y.intersp = 0.7, cex=0.7))
> dev.off()?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From f_j_rod at hotmail.com  Wed Jun  3 21:39:07 2015
From: f_j_rod at hotmail.com (Frank S.)
Date: Wed, 3 Jun 2015 21:39:07 +0200
Subject: [R] Greek letters with subscript numbers on x-axis
In-Reply-To: <alpine.BSF.2.00.1410310822530.42077@pedal.dcn.davis.ca.us>
References: <CAH-FEnjfDBZF2-1HWR0_ULd71Kfrd3z+ES13ZdXaj4wGD1OVOw@mail.gmail.com>,
	<CAH-FEnh+1DDFOsWNq5GF7p-iLpBOOUEaKst+NZGm1Pc-f+arvA@mail.gmail.com>,
	<26C7B3B6-6596-418C-9CC4-C65558E54F53@dcn.davis.CA.us>,
	<000f01cff518$92e14210$b8a3c630$@mcmaster.ca>,
	<alpine.BSF.2.00.1410310822530.42077@pedal.dcn.davis.ca.us>
Message-ID: <BAY168-W110DBCDE35CFDCF099B3682BAB40@phx.gbl>

Hi everyone, I have allocated greek letters with subscript numbers on x-axis of my R plot this way:
 plot(10:18, 30:38, lwd=2, xlim=c(10,18), ylim=c(30,38),  xaxt="n",  xlab="weights", ylab="value")
points(10:18, 30:38, pch=19)
axis(1, at=10:18, labels=c(expression(hat(lambda)[1]), expression(hat(lambda)[2]), expression(hat(lambda)[3]),
      expression(hat(lambda)[4]),expression(hat(lambda)[5]),expression(hat(lambda)[6]),
      expression(hat(lambda)[7]),expression(hat(lambda)[8]),expression(hat(lambda)[9])),  padj = 0.25) However, as you see in the last lines, it's not an efficient code. I think it could be done more efficiently with a loop. I've searched about this question and I've found some very similar question, but the given answer does not work (with do.call and lapply). Maybe another functions like substitute or parse. Does anybody can help me? Thanks a bunch!! Frank S. 		 	   		  
	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Wed Jun  3 21:45:43 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 03 Jun 2015 20:45:43 +0100
Subject: [R] pairwise.t.test non numeric factors error
In-Reply-To: <CAMbrGjEKmp+=J0WovW2Ydk_e1F6CfNcFodW2QF735fEF9n2=ew@mail.gmail.com>
References: <CAMbrGjHztZFofwCAHrmMvQzycF6KcvSw50i=o_E0hcDoE0Rd3w@mail.gmail.com>	<CA+8X3fV6zuJOUQ+yMx644N5K00+RHj3c+5xdL7uEFCxXdWxudw@mail.gmail.com>
	<CAMbrGjEKmp+=J0WovW2Ydk_e1F6CfNcFodW2QF735fEF9n2=ew@mail.gmail.com>
Message-ID: <556F5967.4030408@dewey.myzen.co.uk>

Just to be on the safe side, what is T? It is recommended to use TRUE in 
case you set T to something else. I think this is very unlikely to solve 
the problem but it is worth trying.

On 03/06/2015 18:14, Erica Cseko Nolasco wrote:
> Thanks Jim,
>
> I removed the corresponding cases and tried again. What I discovery now is
> if I run the function without paired = T (pairwise.t.test(x =
> data$tss,data$pa) is works. However, if I add the paired = T
> (pairwise.t.test(x = data$tss,data$pa,paired = T) is gives me the error ' Error
> in complete.cases(x, y) :   not all arguments have the same length'. In
> fact it seems to do a paired test even without the paired = T argument.
> I really don't know why.
>
> Regards,
>
> *Erica Csek? Nolasco*
> Mestranda em Modelagem em Ci?ncias da Terra e do Ambiente
> http://lattes.cnpq.br/2117508819823917
> Universidade Estadual de Feira de Santana
> Avenida Transnordestina s/n, Novo Horizonte
> Feira de Santana - BA, Brasil CEP 44.036-900.
>
> Graduate Student in Modeling of Environmental and Earth Sciences
> http://lattes.cnpq.br/2117508819823917
> Universidade Estadual de Feira de Santana
> Transnordestina Ave, Novo Horizonte
> Feira de Santana - BA, Brazil 44.036-900.
>
>
> 2015-06-02 22:34 GMT-03:00 Jim Lemon <drjimlemon at gmail.com>:
>
>> Hi Erica,
>> The problem may be that you are specifying a grouping factor (mdl) in
>> which the group sizes are unequal. If one case in group "tot" is
>> missing, is it possible to identify the corresponding cases in the
>> other factor levels and delete them?
>>
>> Jim
>>
>>
>> On Tue, Jun 2, 2015 at 11:59 PM, Erica Cseko Nolasco
>> <ecnolasco at gmail.com> wrote:
>>> Dear listers,
>>>
>>> I'm performing a PERMANOVA (adonis{vegan}) to compare the results (ROC,
>>> TSS) of models based on two factors (model, algo). I was not able to
>> find a
>>> pairwise test for adonis, on PRIMER it would be a Tukey test. Though, I
>>> chose to perform a pairwise.t.test what would be quite simple. However,
>> no
>>> matter I rearrange my response and factor vectors (as a factor or
>> numeric)
>>> it gives me the following error (the code on the bottom - Error in
>>> complete.cases(x, y) :
>>>    not all arguments have the same length). I also tried to make a list of
>>> the vectors, but it also gives me the error 'Error in sort.list(y) : 'x'
>>> must be atomic for 'sort.list' Have you called 'sort' on a list?'
>>>
>>> I would appreciate any suggestions to solve this issue.
>>>
>>> Best,
>>>
>>> Erica
>>>
>>>> setwd('D:\\Erica\\mestrado\\analises\\results')
>>>> library(vegan)
>>>> rest=read.table('results_permanova.txt',sep="\t",header=T)
>>>> rest$modelN=as.numeric(rest$model)
>>>> rest$algoN=as.numeric(rest$algo)
>>>> data=rest[complete.cases(rest),]
>>>> head(data)
>>>    algo   pa  run model   ROC   TSS modelN algoN
>>> 1  ANN  PA1 RUN1   alt 0.947 0.867      2     2
>>> 2  ANN PA10 RUN1   alt 0.978 0.869      2     2
>>> 3  ANN PA11 RUN1   alt 0.993 0.931      2     2
>>> 4  ANN PA12 RUN1   alt 0.961 0.845      2     2
>>> 5  ANN PA13 RUN1   alt 0.988 0.960      2     2
>>> 6  ANN PA14 RUN1   alt 0.996 0.988      2     2
>>>> summary(data)
>>>        algo           pa         run             model           ROC
>>>       TSS
>>>   CTA    :240   PA10   : 120       :   0   alt      : 200   Min.   :0.5290
>>> Min.   :0.0580
>>>   FDA    :240   PA11   : 120   RUN1:2399   altPet   : 200   1st Qu.:0.8780
>>> 1st Qu.:0.7160
>>>   GAM    :240   PA12   : 120               b1       : 200   Median :0.9350
>>> Median :0.8270
>>>   GBM    :240   PA13   : 120               b13      : 200   Mean   :0.9184
>>> Mean   :0.7988
>>>   GLM    :240   PA14   : 120               b13PETalt: 200   3rd Qu.:0.9790
>>> 3rd Qu.:0.9110
>>>   MARS   :240   PA15   : 120               b14      : 200   Max.   :1.0000
>>> Max.   :1.0000
>>>   (Other):959   (Other):1679               (Other)  :1199
>>>
>>>       modelN           algoN
>>>   Min.   : 2.000   Min.   : 2.000
>>>   1st Qu.: 4.500   1st Qu.: 4.000
>>>   Median : 7.000   Median : 7.000
>>>   Mean   : 7.498   Mean   : 6.502
>>>   3rd Qu.:10.000   3rd Qu.: 9.000
>>>   Max.   :13.000   Max.   :11.000
>>>
>>>> tss=data$TSS
>>>> summary(tss)
>>>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>>   0.0580  0.7160  0.8270  0.7988  0.9110  1.0000
>>>> mdl=factor(data$model)
>>>> summary(mdl)
>>>        alt    altPet        b1       b13 b13PETalt       b14       b18
>>>   b7       pet      pluv
>>>        200       200       200       200       200       200       200
>>> 200       200       200
>>>       temp       tot
>>>        200       199
>>>> length(complete.cases(mdl,tss))
>>> [1] 2399
>>>> pairwise.t.test(tss,mdl,p.adj='bonf',paired=T,pool.sd = FALSE)
>>> Error in complete.cases(x, y) :
>>>    not all arguments have the same length
>>>>
>>>
>>> *Erica Csek? Nolasco*
>>> Mestranda em Modelagem em Ci?ncias da Terra e do Ambiente
>>> http://lattes.cnpq.br/2117508819823917
>>> Universidade Estadual de Feira de Santana
>>> Avenida Transnordestina s/n, Novo Horizonte
>>> Feira de Santana - BA, Brasil CEP 44.036-900.
>>>
>>> Graduate Student in Modeling of Environmental and Earth Sciences
>>> http://lattes.cnpq.br/2117508819823917
>>> Universidade Estadual de Feira de Santana
>>> Transnordestina Ave, Novo Horizonte
>>> Feira de Santana - BA, Brazil 44.036-900.
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From wdunlap at tibco.com  Wed Jun  3 21:46:46 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 3 Jun 2015 12:46:46 -0700
Subject: [R] Greek letters with subscript numbers on x-axis
In-Reply-To: <BAY168-W110DBCDE35CFDCF099B3682BAB40@phx.gbl>
References: <CAH-FEnjfDBZF2-1HWR0_ULd71Kfrd3z+ES13ZdXaj4wGD1OVOw@mail.gmail.com>
	<CAH-FEnh+1DDFOsWNq5GF7p-iLpBOOUEaKst+NZGm1Pc-f+arvA@mail.gmail.com>
	<26C7B3B6-6596-418C-9CC4-C65558E54F53@dcn.davis.CA.us>
	<000f01cff518$92e14210$b8a3c630$@mcmaster.ca>
	<alpine.BSF.2.00.1410310822530.42077@pedal.dcn.davis.ca.us>
	<BAY168-W110DBCDE35CFDCF099B3682BAB40@phx.gbl>
Message-ID: <CAF8bMcafucUX2C4Gsdiu=y+nFiQuz8TtSYWM31MRp8i_ii9kHw@mail.gmail.com>

You can use
   labels=as.expression(lapply(1:9, function(i)bquote(hat(lambda)[.(i)])))

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Jun 3, 2015 at 12:39 PM, Frank S. <f_j_rod at hotmail.com> wrote:

> Hi everyone, I have allocated greek letters with subscript numbers on
> x-axis of my R plot this way:
>  plot(10:18, 30:38, lwd=2, xlim=c(10,18), ylim=c(30,38),  xaxt="n",
> xlab="weights", ylab="value")
> points(10:18, 30:38, pch=19)
> axis(1, at=10:18, labels=c(expression(hat(lambda)[1]),
> expression(hat(lambda)[2]), expression(hat(lambda)[3]),
>
> expression(hat(lambda)[4]),expression(hat(lambda)[5]),expression(hat(lambda)[6]),
>
> expression(hat(lambda)[7]),expression(hat(lambda)[8]),expression(hat(lambda)[9])),
> padj = 0.25) However, as you see in the last lines, it's not an efficient
> code. I think it could be done more efficiently with a loop. I've searched
> about this question and I've found some very similar question, but the
> given answer does not work (with do.call and lapply). Maybe another
> functions like substitute or parse. Does anybody can help me? Thanks a
> bunch!! Frank S.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Wed Jun  3 21:55:48 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 3 Jun 2015 21:55:48 +0200
Subject: [R] pairwise.t.test non numeric factors error
In-Reply-To: <CAMbrGjEKmp+=J0WovW2Ydk_e1F6CfNcFodW2QF735fEF9n2=ew@mail.gmail.com>
References: <CAMbrGjHztZFofwCAHrmMvQzycF6KcvSw50i=o_E0hcDoE0Rd3w@mail.gmail.com>
	<CA+8X3fV6zuJOUQ+yMx644N5K00+RHj3c+5xdL7uEFCxXdWxudw@mail.gmail.com>
	<CAMbrGjEKmp+=J0WovW2Ydk_e1F6CfNcFodW2QF735fEF9n2=ew@mail.gmail.com>
Message-ID: <4A59B185-F64C-48B5-AE10-49E319191D79@gmail.com>


> On 03 Jun 2015, at 19:14 , Erica Cseko Nolasco <ecnolasco at gmail.com> wrote:
> 
> Thanks Jim,
> 
> I removed the corresponding cases and tried again. What I discovery now is
> if I run the function without paired = T (pairwise.t.test(x =
> data$tss,data$pa) is works. However, if I add the paired = T
> (pairwise.t.test(x = data$tss,data$pa,paired = T) is gives me the error ' Error
> in complete.cases(x, y) :   not all arguments have the same length'. In
> fact it seems to do a paired test even without the paired = T argument.
> I really don't know why.

What makes you say that? It would be a pretty bad error if it did paired tests and data aren't paired/matched. Are you sure that you actually want paired tests?

-pd


> 
> Regards,
> 
> *Erica Csek? Nolasco*
> Mestranda em Modelagem em Ci?ncias da Terra e do Ambiente
> http://lattes.cnpq.br/2117508819823917
> Universidade Estadual de Feira de Santana
> Avenida Transnordestina s/n, Novo Horizonte
> Feira de Santana - BA, Brasil CEP 44.036-900.
> 
> Graduate Student in Modeling of Environmental and Earth Sciences
> http://lattes.cnpq.br/2117508819823917
> Universidade Estadual de Feira de Santana
> Transnordestina Ave, Novo Horizonte
> Feira de Santana - BA, Brazil 44.036-900.
> 
> 
> 2015-06-02 22:34 GMT-03:00 Jim Lemon <drjimlemon at gmail.com>:
> 
>> Hi Erica,
>> The problem may be that you are specifying a grouping factor (mdl) in
>> which the group sizes are unequal. If one case in group "tot" is
>> missing, is it possible to identify the corresponding cases in the
>> other factor levels and delete them?
>> 
>> Jim
>> 
>> 
>> On Tue, Jun 2, 2015 at 11:59 PM, Erica Cseko Nolasco
>> <ecnolasco at gmail.com> wrote:
>>> Dear listers,
>>> 
>>> I'm performing a PERMANOVA (adonis{vegan}) to compare the results (ROC,
>>> TSS) of models based on two factors (model, algo). I was not able to
>> find a
>>> pairwise test for adonis, on PRIMER it would be a Tukey test. Though, I
>>> chose to perform a pairwise.t.test what would be quite simple. However,
>> no
>>> matter I rearrange my response and factor vectors (as a factor or
>> numeric)
>>> it gives me the following error (the code on the bottom - Error in
>>> complete.cases(x, y) :
>>>  not all arguments have the same length). I also tried to make a list of
>>> the vectors, but it also gives me the error 'Error in sort.list(y) : 'x'
>>> must be atomic for 'sort.list' Have you called 'sort' on a list?'
>>> 
>>> I would appreciate any suggestions to solve this issue.
>>> 
>>> Best,
>>> 
>>> Erica
>>> 
>>>> setwd('D:\\Erica\\mestrado\\analises\\results')
>>>> library(vegan)
>>>> rest=read.table('results_permanova.txt',sep="\t",header=T)
>>>> rest$modelN=as.numeric(rest$model)
>>>> rest$algoN=as.numeric(rest$algo)
>>>> data=rest[complete.cases(rest),]
>>>> head(data)
>>>  algo   pa  run model   ROC   TSS modelN algoN
>>> 1  ANN  PA1 RUN1   alt 0.947 0.867      2     2
>>> 2  ANN PA10 RUN1   alt 0.978 0.869      2     2
>>> 3  ANN PA11 RUN1   alt 0.993 0.931      2     2
>>> 4  ANN PA12 RUN1   alt 0.961 0.845      2     2
>>> 5  ANN PA13 RUN1   alt 0.988 0.960      2     2
>>> 6  ANN PA14 RUN1   alt 0.996 0.988      2     2
>>>> summary(data)
>>>      algo           pa         run             model           ROC
>>>     TSS
>>> CTA    :240   PA10   : 120       :   0   alt      : 200   Min.   :0.5290
>>> Min.   :0.0580
>>> FDA    :240   PA11   : 120   RUN1:2399   altPet   : 200   1st Qu.:0.8780
>>> 1st Qu.:0.7160
>>> GAM    :240   PA12   : 120               b1       : 200   Median :0.9350
>>> Median :0.8270
>>> GBM    :240   PA13   : 120               b13      : 200   Mean   :0.9184
>>> Mean   :0.7988
>>> GLM    :240   PA14   : 120               b13PETalt: 200   3rd Qu.:0.9790
>>> 3rd Qu.:0.9110
>>> MARS   :240   PA15   : 120               b14      : 200   Max.   :1.0000
>>> Max.   :1.0000
>>> (Other):959   (Other):1679               (Other)  :1199
>>> 
>>>     modelN           algoN
>>> Min.   : 2.000   Min.   : 2.000
>>> 1st Qu.: 4.500   1st Qu.: 4.000
>>> Median : 7.000   Median : 7.000
>>> Mean   : 7.498   Mean   : 6.502
>>> 3rd Qu.:10.000   3rd Qu.: 9.000
>>> Max.   :13.000   Max.   :11.000
>>> 
>>>> tss=data$TSS
>>>> summary(tss)
>>>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>> 0.0580  0.7160  0.8270  0.7988  0.9110  1.0000
>>>> mdl=factor(data$model)
>>>> summary(mdl)
>>>      alt    altPet        b1       b13 b13PETalt       b14       b18
>>> b7       pet      pluv
>>>      200       200       200       200       200       200       200
>>> 200       200       200
>>>     temp       tot
>>>      200       199
>>>> length(complete.cases(mdl,tss))
>>> [1] 2399
>>>> pairwise.t.test(tss,mdl,p.adj='bonf',paired=T,pool.sd = FALSE)
>>> Error in complete.cases(x, y) :
>>>  not all arguments have the same length
>>>> 
>>> 
>>> *Erica Csek? Nolasco*
>>> Mestranda em Modelagem em Ci?ncias da Terra e do Ambiente
>>> http://lattes.cnpq.br/2117508819823917
>>> Universidade Estadual de Feira de Santana
>>> Avenida Transnordestina s/n, Novo Horizonte
>>> Feira de Santana - BA, Brasil CEP 44.036-900.
>>> 
>>> Graduate Student in Modeling of Environmental and Earth Sciences
>>> http://lattes.cnpq.br/2117508819823917
>>> Universidade Estadual de Feira de Santana
>>> Transnordestina Ave, Novo Horizonte
>>> Feira de Santana - BA, Brazil 44.036-900.
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ecnolasco at gmail.com  Wed Jun  3 22:05:16 2015
From: ecnolasco at gmail.com (Erica Cseko Nolasco)
Date: Wed, 3 Jun 2015 17:05:16 -0300
Subject: [R] pairwise.t.test non numeric factors error
In-Reply-To: <4A59B185-F64C-48B5-AE10-49E319191D79@gmail.com>
References: <CAMbrGjHztZFofwCAHrmMvQzycF6KcvSw50i=o_E0hcDoE0Rd3w@mail.gmail.com>
	<CA+8X3fV6zuJOUQ+yMx644N5K00+RHj3c+5xdL7uEFCxXdWxudw@mail.gmail.com>
	<CAMbrGjEKmp+=J0WovW2Ydk_e1F6CfNcFodW2QF735fEF9n2=ew@mail.gmail.com>
	<4A59B185-F64C-48B5-AE10-49E319191D79@gmail.com>
Message-ID: <CAMbrGjEQUFh_xVmEzXBa2dZwENPy98wvF5eDiD7aULEf2V28EQ@mail.gmail.com>

I tried using TRUE instead T, but it gave me the same error. (Script on the
bottom)
I really want a paired test and it seems to give me as we can see on the
following matrix.
No idea what is happening

> pairwise.t.test(x = data$tss,data$pa,p.adjust.method =
'bonferroni',paired=TRUE)
Error in complete.cases(x, y) :
  not all arguments have the same length

> pairwise.t.test(x = data$tss,data$algo,p.adjust.method = 'bonferroni')

Pairwise comparisons using t tests with pooled SD

data:  data$tss and data$algo

       ANN     CTA     FDA     GAM     GBM     GLM     MARS    MAXENT  RF

CTA    0.08118 -       -       -       -       -       -       -       -

FDA    0.00102 1.1e-11 -       -       -       -       -       -       -

GAM    1.00000 1.00000 1.2e-05 -       -       -       -       -       -

GBM    0.01081 5.9e-10 1.00000 0.00021 -       -       -       -       -

GLM    6.8e-06 3.8e-15 1.00000 3.3e-08 1.00000 -       -       -       -

MARS   0.16840 8.8e-08 1.00000 0.00620 1.00000 0.81420 -       -       -

MAXENT 0.07340 1.00000 8.6e-12 1.00000 4.8e-10 3.0e-15 7.4e-08 -       -

RF     1.4e-06 3.3e-16 1.00000 5.3e-09 1.00000 1.00000 0.35873 2.6e-16 -

SRE    < 2e-16 < 2e-16 < 2e-16 < 2e-16 < 2e-16 < 2e-16 < 2e-16 < 2e-16 <
2e-16

P value adjustment method: bonferroni

*Erica Csek? Nolasco*
Mestranda em Modelagem em Ci?ncias da Terra e do Ambiente
http://lattes.cnpq.br/2117508819823917
Universidade Estadual de Feira de Santana
Avenida Transnordestina s/n, Novo Horizonte
Feira de Santana - BA, Brasil CEP 44.036-900.

Graduate Student in Modeling of Environmental and Earth Sciences
http://lattes.cnpq.br/2117508819823917
Universidade Estadual de Feira de Santana
Transnordestina Ave, Novo Horizonte
Feira de Santana - BA, Brazil 44.036-900.


2015-06-03 16:55 GMT-03:00 peter dalgaard <pdalgd at gmail.com>:

>
> > On 03 Jun 2015, at 19:14 , Erica Cseko Nolasco <ecnolasco at gmail.com>
> wrote:
> >
> > Thanks Jim,
> >
> > I removed the corresponding cases and tried again. What I discovery now
> is
> > if I run the function without paired = T (pairwise.t.test(x =
> > data$tss,data$pa) is works. However, if I add the paired = T
> > (pairwise.t.test(x = data$tss,data$pa,paired = T) is gives me the error
> ' Error
> > in complete.cases(x, y) :   not all arguments have the same length'. In
> > fact it seems to do a paired test even without the paired = T argument.
> > I really don't know why.
>
> What makes you say that? It would be a pretty bad error if it did paired
> tests and data aren't paired/matched. Are you sure that you actually want
> paired tests?
>
> -pd
>
>
> >
> > Regards,
> >
> > *Erica Csek? Nolasco*
> > Mestranda em Modelagem em Ci?ncias da Terra e do Ambiente
> > http://lattes.cnpq.br/2117508819823917
> > Universidade Estadual de Feira de Santana
> > Avenida Transnordestina s/n, Novo Horizonte
> > Feira de Santana - BA, Brasil CEP 44.036-900.
> >
> > Graduate Student in Modeling of Environmental and Earth Sciences
> > http://lattes.cnpq.br/2117508819823917
> > Universidade Estadual de Feira de Santana
> > Transnordestina Ave, Novo Horizonte
> > Feira de Santana - BA, Brazil 44.036-900.
> >
> >
> > 2015-06-02 22:34 GMT-03:00 Jim Lemon <drjimlemon at gmail.com>:
> >
> >> Hi Erica,
> >> The problem may be that you are specifying a grouping factor (mdl) in
> >> which the group sizes are unequal. If one case in group "tot" is
> >> missing, is it possible to identify the corresponding cases in the
> >> other factor levels and delete them?
> >>
> >> Jim
> >>
> >>
> >> On Tue, Jun 2, 2015 at 11:59 PM, Erica Cseko Nolasco
> >> <ecnolasco at gmail.com> wrote:
> >>> Dear listers,
> >>>
> >>> I'm performing a PERMANOVA (adonis{vegan}) to compare the results (ROC,
> >>> TSS) of models based on two factors (model, algo). I was not able to
> >> find a
> >>> pairwise test for adonis, on PRIMER it would be a Tukey test. Though, I
> >>> chose to perform a pairwise.t.test what would be quite simple. However,
> >> no
> >>> matter I rearrange my response and factor vectors (as a factor or
> >> numeric)
> >>> it gives me the following error (the code on the bottom - Error in
> >>> complete.cases(x, y) :
> >>>  not all arguments have the same length). I also tried to make a list
> of
> >>> the vectors, but it also gives me the error 'Error in sort.list(y) :
> 'x'
> >>> must be atomic for 'sort.list' Have you called 'sort' on a list?'
> >>>
> >>> I would appreciate any suggestions to solve this issue.
> >>>
> >>> Best,
> >>>
> >>> Erica
> >>>
> >>>> setwd('D:\\Erica\\mestrado\\analises\\results')
> >>>> library(vegan)
> >>>> rest=read.table('results_permanova.txt',sep="\t",header=T)
> >>>> rest$modelN=as.numeric(rest$model)
> >>>> rest$algoN=as.numeric(rest$algo)
> >>>> data=rest[complete.cases(rest),]
> >>>> head(data)
> >>>  algo   pa  run model   ROC   TSS modelN algoN
> >>> 1  ANN  PA1 RUN1   alt 0.947 0.867      2     2
> >>> 2  ANN PA10 RUN1   alt 0.978 0.869      2     2
> >>> 3  ANN PA11 RUN1   alt 0.993 0.931      2     2
> >>> 4  ANN PA12 RUN1   alt 0.961 0.845      2     2
> >>> 5  ANN PA13 RUN1   alt 0.988 0.960      2     2
> >>> 6  ANN PA14 RUN1   alt 0.996 0.988      2     2
> >>>> summary(data)
> >>>      algo           pa         run             model           ROC
> >>>     TSS
> >>> CTA    :240   PA10   : 120       :   0   alt      : 200   Min.
>  :0.5290
> >>> Min.   :0.0580
> >>> FDA    :240   PA11   : 120   RUN1:2399   altPet   : 200   1st
> Qu.:0.8780
> >>> 1st Qu.:0.7160
> >>> GAM    :240   PA12   : 120               b1       : 200   Median
> :0.9350
> >>> Median :0.8270
> >>> GBM    :240   PA13   : 120               b13      : 200   Mean
>  :0.9184
> >>> Mean   :0.7988
> >>> GLM    :240   PA14   : 120               b13PETalt: 200   3rd
> Qu.:0.9790
> >>> 3rd Qu.:0.9110
> >>> MARS   :240   PA15   : 120               b14      : 200   Max.
>  :1.0000
> >>> Max.   :1.0000
> >>> (Other):959   (Other):1679               (Other)  :1199
> >>>
> >>>     modelN           algoN
> >>> Min.   : 2.000   Min.   : 2.000
> >>> 1st Qu.: 4.500   1st Qu.: 4.000
> >>> Median : 7.000   Median : 7.000
> >>> Mean   : 7.498   Mean   : 6.502
> >>> 3rd Qu.:10.000   3rd Qu.: 9.000
> >>> Max.   :13.000   Max.   :11.000
> >>>
> >>>> tss=data$TSS
> >>>> summary(tss)
> >>>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> >>> 0.0580  0.7160  0.8270  0.7988  0.9110  1.0000
> >>>> mdl=factor(data$model)
> >>>> summary(mdl)
> >>>      alt    altPet        b1       b13 b13PETalt       b14       b18
> >>> b7       pet      pluv
> >>>      200       200       200       200       200       200       200
> >>> 200       200       200
> >>>     temp       tot
> >>>      200       199
> >>>> length(complete.cases(mdl,tss))
> >>> [1] 2399
> >>>> pairwise.t.test(tss,mdl,p.adj='bonf',paired=T,pool.sd = FALSE)
> >>> Error in complete.cases(x, y) :
> >>>  not all arguments have the same length
> >>>>
> >>>
> >>> *Erica Csek? Nolasco*
> >>> Mestranda em Modelagem em Ci?ncias da Terra e do Ambiente
> >>> http://lattes.cnpq.br/2117508819823917
> >>> Universidade Estadual de Feira de Santana
> >>> Avenida Transnordestina s/n, Novo Horizonte
> >>> Feira de Santana - BA, Brasil CEP 44.036-900.
> >>>
> >>> Graduate Student in Modeling of Environmental and Earth Sciences
> >>> http://lattes.cnpq.br/2117508819823917
> >>> Universidade Estadual de Feira de Santana
> >>> Transnordestina Ave, Novo Horizonte
> >>> Feira de Santana - BA, Brazil 44.036-900.
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From jonsleepy at gmail.com  Wed Jun  3 23:44:19 2015
From: jonsleepy at gmail.com (Jon BR)
Date: Wed, 3 Jun 2015 17:44:19 -0400
Subject: [R] reshape a data frame
Message-ID: <CA+d7zeTtCb2mHZ8f-_P97byOXr4yGD-vf02pOFutWNqhQey_vA@mail.gmail.com>

Hello,

I would like to ask for some advice in reformatting a data frame such as
the following one:


gIN <- c("A_1","A_2","A_3","A_4","B_1","B_2")
bc1 <- c(1219.79, 1486.84, 1255.80, 941.87, 588.19, 304.02)
bc2 <- c(319.79, 186.84, 125.80, 94.87, 1008.19, 314.02)
group <- c("A","A","A","A","B","B")

ex <- data.frame("gIN" = gIN, "bc1" = bc1, "bc2"=bc2, "group" = group)

> ex
  gIN     bc1     bc2 group
1 A_1 1219.79  319.79     A
2 A_2 1486.84  186.84     A
3 A_3 1255.80  125.80     A
4 A_4  941.87   94.87     A
5 B_1  588.19 1008.19     B
6 B_2  304.02  314.02     B

I would like to reshape this data frame where all the columns that have
bc1, bc2,...etc are merged into a single column (call it bcX or something)
and the other variables are kept apart, the example solution follows:


> ex_reshaped
  gIN     bcX     group
1 A_1 1219.79       A
2 A_2 1486.84       A
3 A_3 1255.80       A
4 A_4  941.87        A
5 B_1  588.19      B
6 B_2  304.02       B
7 A_1 319.79       A
8 A_2 186.84       A
9 A_3 125.80       A
10 A_4 94.87       A
11 B_1 1008.19   B
12 B_2 314.02     B

Does anyone know of a package, and/or command to accomplish this?

Thank you

	[[alternative HTML version deleted]]


From jonsleepy at gmail.com  Thu Jun  4 00:25:02 2015
From: jonsleepy at gmail.com (Jon BR)
Date: Wed, 3 Jun 2015 18:25:02 -0400
Subject: [R] reshape a data frame
In-Reply-To: <CA+d7zeTtCb2mHZ8f-_P97byOXr4yGD-vf02pOFutWNqhQey_vA@mail.gmail.com>
References: <CA+d7zeTtCb2mHZ8f-_P97byOXr4yGD-vf02pOFutWNqhQey_vA@mail.gmail.com>
Message-ID: <CA+d7zeTHo6EgmKD2WyFkuLqNGmiTyBG-ZY1ocE2yES0+FsgKnw@mail.gmail.com>

I found the gather function from the tidyr package, which worked nicely:

gather(ex,bcX,value, bc1:bc2)
   gIN group bcX value
1  A_1     A     bc1  1219.79
2  A_2     A     bc1  1486.84
3  A_3     A     bc1  1255.80
4  A_4     A     bc1   941.87
5  B_1     B     bc1   588.19
6  B_2     B     bc1   304.02
7  A_1     A     bc2   319.79
8  A_2     A     bc2   186.84
9  A_3     A     bc2   125.80
10 A_4     A     bc2    94.87
11 B_1     B     bc2  1008.19
12 B_2     B     bc2   314.02

Thanks.





On Wed, Jun 3, 2015 at 5:44 PM, Jon BR <jonsleepy at gmail.com> wrote:

> Hello,
>
> I would like to ask for some advice in reformatting a data frame such as
> the following one:
>
>
> gIN <- c("A_1","A_2","A_3","A_4","B_1","B_2")
> bc1 <- c(1219.79, 1486.84, 1255.80, 941.87, 588.19, 304.02)
> bc2 <- c(319.79, 186.84, 125.80, 94.87, 1008.19, 314.02)
> group <- c("A","A","A","A","B","B")
>
> ex <- data.frame("gIN" = gIN, "bc1" = bc1, "bc2"=bc2, "group" = group)
>
> > ex
>   gIN     bc1     bc2 group
> 1 A_1 1219.79  319.79     A
> 2 A_2 1486.84  186.84     A
> 3 A_3 1255.80  125.80     A
> 4 A_4  941.87   94.87     A
> 5 B_1  588.19 1008.19     B
> 6 B_2  304.02  314.02     B
>
> I would like to reshape this data frame where all the columns that have
> bc1, bc2,...etc are merged into a single column (call it bcX or something)
> and the other variables are kept apart, the example solution follows:
>
>
> > ex_reshaped
>   gIN     bcX     group
> 1 A_1 1219.79       A
> 2 A_2 1486.84       A
> 3 A_3 1255.80       A
> 4 A_4  941.87        A
> 5 B_1  588.19      B
> 6 B_2  304.02       B
> 7 A_1 319.79       A
> 8 A_2 186.84       A
> 9 A_3 125.80       A
> 10 A_4 94.87       A
> 11 B_1 1008.19   B
> 12 B_2 314.02     B
>
> Does anyone know of a package, and/or command to accomplish this?
>
> Thank you
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Thu Jun  4 01:21:08 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 3 Jun 2015 15:21:08 -0800
Subject: [R] reshape a data frame
In-Reply-To: <CA+d7zeTHo6EgmKD2WyFkuLqNGmiTyBG-ZY1ocE2yES0+FsgKnw@mail.gmail.com>
References: <ca+d7zettcb2mhz8f-_p97byoxr4ygd-vf02pofutwnqhqey_va@mail.gmail.com>
Message-ID: <C280D31D6EE.00000510jrkrideau@inbox.com>


And I think this will do it too.

library(reshape2)
 
melt(ex, id.vars= c("gIN", "group"), 
       variable.name = "bc",
       value.name = "value", 
       na.rm = FALSE) 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jonsleepy at gmail.com
> Sent: Wed, 3 Jun 2015 18:25:02 -0400
> To: r-help at r-project.org
> Subject: Re: [R] reshape a data frame
> 
> I found the gather function from the tidyr package, which worked nicely:
> 
> gather(ex,bcX,value, bc1:bc2)
>    gIN group bcX value
> 1  A_1     A     bc1  1219.79
> 2  A_2     A     bc1  1486.84
> 3  A_3     A     bc1  1255.80
> 4  A_4     A     bc1   941.87
> 5  B_1     B     bc1   588.19
> 6  B_2     B     bc1   304.02
> 7  A_1     A     bc2   319.79
> 8  A_2     A     bc2   186.84
> 9  A_3     A     bc2   125.80
> 10 A_4     A     bc2    94.87
> 11 B_1     B     bc2  1008.19
> 12 B_2     B     bc2   314.02
> 
> Thanks.
> 
> 
> 
> 
> 
> On Wed, Jun 3, 2015 at 5:44 PM, Jon BR <jonsleepy at gmail.com> wrote:
> 
>> Hello,
>> 
>> I would like to ask for some advice in reformatting a data frame such as
>> the following one:
>> 
>> 
>> gIN <- c("A_1","A_2","A_3","A_4","B_1","B_2")
>> bc1 <- c(1219.79, 1486.84, 1255.80, 941.87, 588.19, 304.02)
>> bc2 <- c(319.79, 186.84, 125.80, 94.87, 1008.19, 314.02)
>> group <- c("A","A","A","A","B","B")
>> 
>> ex <- data.frame("gIN" = gIN, "bc1" = bc1, "bc2"=bc2, "group" = group)
>> 
>>> ex
>>   gIN     bc1     bc2 group
>> 1 A_1 1219.79  319.79     A
>> 2 A_2 1486.84  186.84     A
>> 3 A_3 1255.80  125.80     A
>> 4 A_4  941.87   94.87     A
>> 5 B_1  588.19 1008.19     B
>> 6 B_2  304.02  314.02     B
>> 
>> I would like to reshape this data frame where all the columns that have
>> bc1, bc2,...etc are merged into a single column (call it bcX or
>> something)
>> and the other variables are kept apart, the example solution follows:
>> 
>> 
>>> ex_reshaped
>>   gIN     bcX     group
>> 1 A_1 1219.79       A
>> 2 A_2 1486.84       A
>> 3 A_3 1255.80       A
>> 4 A_4  941.87        A
>> 5 B_1  588.19      B
>> 6 B_2  304.02       B
>> 7 A_1 319.79       A
>> 8 A_2 186.84       A
>> 9 A_3 125.80       A
>> 10 A_4 94.87       A
>> 11 B_1 1008.19   B
>> 12 B_2 314.02     B
>> 
>> Does anyone know of a package, and/or command to accomplish this?
>> 
>> Thank you
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From pdalgd at gmail.com  Thu Jun  4 01:50:10 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 4 Jun 2015 01:50:10 +0200
Subject: [R] pairwise.t.test non numeric factors error
In-Reply-To: <CAMbrGjEQUFh_xVmEzXBa2dZwENPy98wvF5eDiD7aULEf2V28EQ@mail.gmail.com>
References: <CAMbrGjHztZFofwCAHrmMvQzycF6KcvSw50i=o_E0hcDoE0Rd3w@mail.gmail.com>
	<CA+8X3fV6zuJOUQ+yMx644N5K00+RHj3c+5xdL7uEFCxXdWxudw@mail.gmail.com>
	<CAMbrGjEKmp+=J0WovW2Ydk_e1F6CfNcFodW2QF735fEF9n2=ew@mail.gmail.com>
	<4A59B185-F64C-48B5-AE10-49E319191D79@gmail.com>
	<CAMbrGjEQUFh_xVmEzXBa2dZwENPy98wvF5eDiD7aULEf2V28EQ@mail.gmail.com>
Message-ID: <51340581-4611-4515-9073-F89F954DFC4C@gmail.com>


> On 03 Jun 2015, at 22:05 , Erica Cseko Nolasco <ecnolasco at gmail.com> wrote:
> 
> I tried using TRUE instead T, but it gave me the same error. (Script on the bottom)
> I really want a paired test and it seems to give me as we can see on the following matrix. 
> No idea what is happening
> 

I get the impression that you really do not know the difference between the paired t test and the independent samples t test. Please read up on it, it is off-topic here.

-pd


> > pairwise.t.test(x = data$tss,data$pa,p.adjust.method = 'bonferroni',paired=TRUE)
> Error in complete.cases(x, y) : 
>   not all arguments have the same length
>   
> > pairwise.t.test(x = data$tss,data$algo,p.adjust.method = 'bonferroni')
> 
> 	Pairwise comparisons using t tests with pooled SD 
> 
> data:  data$tss and data$algo 
> 
>        ANN     CTA     FDA     GAM     GBM     GLM     MARS    MAXENT  RF     
> CTA    0.08118 -       -       -       -       -       -       -       -      
> FDA    0.00102 1.1e-11 -       -       -       -       -       -       -      
> GAM    1.00000 1.00000 1.2e-05 -       -       -       -       -       -      
> GBM    0.01081 5.9e-10 1.00000 0.00021 -       -       -       -       -      
> GLM    6.8e-06 3.8e-15 1.00000 3.3e-08 1.00000 -       -       -       -      
> MARS   0.16840 8.8e-08 1.00000 0.00620 1.00000 0.81420 -       -       -      
> MAXENT 0.07340 1.00000 8.6e-12 1.00000 4.8e-10 3.0e-15 7.4e-08 -       -      
> RF     1.4e-06 3.3e-16 1.00000 5.3e-09 1.00000 1.00000 0.35873 2.6e-16 -      
> SRE    < 2e-16 < 2e-16 < 2e-16 < 2e-16 < 2e-16 < 2e-16 < 2e-16 < 2e-16 < 2e-16
> 
> P value adjustment method: bonferroni  
> 
> Erica Csek? Nolasco
> Mestranda em Modelagem em Ci?ncias da Terra e do Ambiente
> http://lattes.cnpq.br/2117508819823917
> Universidade Estadual de Feira de Santana 
> Avenida Transnordestina s/n, Novo Horizonte
> Feira de Santana - BA, Brasil CEP 44.036-900.
> 
> Graduate Student in Modeling of Environmental and Earth Sciences
> http://lattes.cnpq.br/2117508819823917
> Universidade Estadual de Feira de Santana 
> Transnordestina Ave, Novo Horizonte
> Feira de Santana - BA, Brazil 44.036-900.
>   
> 
> 2015-06-03 16:55 GMT-03:00 peter dalgaard <pdalgd at gmail.com>:
> 
> > On 03 Jun 2015, at 19:14 , Erica Cseko Nolasco <ecnolasco at gmail.com> wrote:
> >
> > Thanks Jim,
> >
> > I removed the corresponding cases and tried again. What I discovery now is
> > if I run the function without paired = T (pairwise.t.test(x =
> > data$tss,data$pa) is works. However, if I add the paired = T
> > (pairwise.t.test(x = data$tss,data$pa,paired = T) is gives me the error ' Error
> > in complete.cases(x, y) :   not all arguments have the same length'. In
> > fact it seems to do a paired test even without the paired = T argument.
> > I really don't know why.
> 
> What makes you say that? It would be a pretty bad error if it did paired tests and data aren't paired/matched. Are you sure that you actually want paired tests?
> 
> -pd
> 
> 
> >
> > Regards,
> >
> > *Erica Csek? Nolasco*
> > Mestranda em Modelagem em Ci?ncias da Terra e do Ambiente
> > http://lattes.cnpq.br/2117508819823917
> > Universidade Estadual de Feira de Santana
> > Avenida Transnordestina s/n, Novo Horizonte
> > Feira de Santana - BA, Brasil CEP 44.036-900.
> >
> > Graduate Student in Modeling of Environmental and Earth Sciences
> > http://lattes.cnpq.br/2117508819823917
> > Universidade Estadual de Feira de Santana
> > Transnordestina Ave, Novo Horizonte
> > Feira de Santana - BA, Brazil 44.036-900.
> >
> >
> > 2015-06-02 22:34 GMT-03:00 Jim Lemon <drjimlemon at gmail.com>:
> >
> >> Hi Erica,
> >> The problem may be that you are specifying a grouping factor (mdl) in
> >> which the group sizes are unequal. If one case in group "tot" is
> >> missing, is it possible to identify the corresponding cases in the
> >> other factor levels and delete them?
> >>
> >> Jim
> >>
> >>
> >> On Tue, Jun 2, 2015 at 11:59 PM, Erica Cseko Nolasco
> >> <ecnolasco at gmail.com> wrote:
> >>> Dear listers,
> >>>
> >>> I'm performing a PERMANOVA (adonis{vegan}) to compare the results (ROC,
> >>> TSS) of models based on two factors (model, algo). I was not able to
> >> find a
> >>> pairwise test for adonis, on PRIMER it would be a Tukey test. Though, I
> >>> chose to perform a pairwise.t.test what would be quite simple. However,
> >> no
> >>> matter I rearrange my response and factor vectors (as a factor or
> >> numeric)
> >>> it gives me the following error (the code on the bottom - Error in
> >>> complete.cases(x, y) :
> >>>  not all arguments have the same length). I also tried to make a list of
> >>> the vectors, but it also gives me the error 'Error in sort.list(y) : 'x'
> >>> must be atomic for 'sort.list' Have you called 'sort' on a list?'
> >>>
> >>> I would appreciate any suggestions to solve this issue.
> >>>
> >>> Best,
> >>>
> >>> Erica
> >>>
> >>>> setwd('D:\\Erica\\mestrado\\analises\\results')
> >>>> library(vegan)
> >>>> rest=read.table('results_permanova.txt',sep="\t",header=T)
> >>>> rest$modelN=as.numeric(rest$model)
> >>>> rest$algoN=as.numeric(rest$algo)
> >>>> data=rest[complete.cases(rest),]
> >>>> head(data)
> >>>  algo   pa  run model   ROC   TSS modelN algoN
> >>> 1  ANN  PA1 RUN1   alt 0.947 0.867      2     2
> >>> 2  ANN PA10 RUN1   alt 0.978 0.869      2     2
> >>> 3  ANN PA11 RUN1   alt 0.993 0.931      2     2
> >>> 4  ANN PA12 RUN1   alt 0.961 0.845      2     2
> >>> 5  ANN PA13 RUN1   alt 0.988 0.960      2     2
> >>> 6  ANN PA14 RUN1   alt 0.996 0.988      2     2
> >>>> summary(data)
> >>>      algo           pa         run             model           ROC
> >>>     TSS
> >>> CTA    :240   PA10   : 120       :   0   alt      : 200   Min.   :0.5290
> >>> Min.   :0.0580
> >>> FDA    :240   PA11   : 120   RUN1:2399   altPet   : 200   1st Qu.:0.8780
> >>> 1st Qu.:0.7160
> >>> GAM    :240   PA12   : 120               b1       : 200   Median :0.9350
> >>> Median :0.8270
> >>> GBM    :240   PA13   : 120               b13      : 200   Mean   :0.9184
> >>> Mean   :0.7988
> >>> GLM    :240   PA14   : 120               b13PETalt: 200   3rd Qu.:0.9790
> >>> 3rd Qu.:0.9110
> >>> MARS   :240   PA15   : 120               b14      : 200   Max.   :1.0000
> >>> Max.   :1.0000
> >>> (Other):959   (Other):1679               (Other)  :1199
> >>>
> >>>     modelN           algoN
> >>> Min.   : 2.000   Min.   : 2.000
> >>> 1st Qu.: 4.500   1st Qu.: 4.000
> >>> Median : 7.000   Median : 7.000
> >>> Mean   : 7.498   Mean   : 6.502
> >>> 3rd Qu.:10.000   3rd Qu.: 9.000
> >>> Max.   :13.000   Max.   :11.000
> >>>
> >>>> tss=data$TSS
> >>>> summary(tss)
> >>>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> >>> 0.0580  0.7160  0.8270  0.7988  0.9110  1.0000
> >>>> mdl=factor(data$model)
> >>>> summary(mdl)
> >>>      alt    altPet        b1       b13 b13PETalt       b14       b18
> >>> b7       pet      pluv
> >>>      200       200       200       200       200       200       200
> >>> 200       200       200
> >>>     temp       tot
> >>>      200       199
> >>>> length(complete.cases(mdl,tss))
> >>> [1] 2399
> >>>> pairwise.t.test(tss,mdl,p.adj='bonf',paired=T,pool.sd = FALSE)
> >>> Error in complete.cases(x, y) :
> >>>  not all arguments have the same length
> >>>>
> >>>
> >>> *Erica Csek? Nolasco*
> >>> Mestranda em Modelagem em Ci?ncias da Terra e do Ambiente
> >>> http://lattes.cnpq.br/2117508819823917
> >>> Universidade Estadual de Feira de Santana
> >>> Avenida Transnordestina s/n, Novo Horizonte
> >>> Feira de Santana - BA, Brasil CEP 44.036-900.
> >>>
> >>> Graduate Student in Modeling of Environmental and Earth Sciences
> >>> http://lattes.cnpq.br/2117508819823917
> >>> Universidade Estadual de Feira de Santana
> >>> Transnordestina Ave, Novo Horizonte
> >>> Feira de Santana - BA, Brazil 44.036-900.
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From drjimlemon at gmail.com  Thu Jun  4 02:11:10 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 4 Jun 2015 10:11:10 +1000
Subject: [R] SVM error.
In-Reply-To: <CAGa91zg+bcU2-9KSw-ym3JfKErv3yQNoF7wKSHA+5C2TZGR2WA@mail.gmail.com>
References: <CAGa91zi-JWkATb68Urn722FX9AZSG+2MpeSW3Ag8CVOY-9ewOQ@mail.gmail.com>
	<CA+8X3fUo4Mf-aDjfsr5iTAGv5BrZzujvHQhgWBiMCh1ABqyp8Q@mail.gmail.com>
	<CAGa91ziAx4mL=_CoGT50j1KcQ4WxayS4L4rfwnSKy8Rd9Z93gQ@mail.gmail.com>
	<CA+8X3fXKJ=hX13mA=geHPFUs7xynvOZbGbzCsb_0N6c1dAh9ag@mail.gmail.com>
	<CAGa91zjRJa7n2GvZL5tGPO-ixu+feV1hobpg5bWWkLPQsxF8RA@mail.gmail.com>
	<CAGa91zg+bcU2-9KSw-ym3JfKErv3yQNoF7wKSHA+5C2TZGR2WA@mail.gmail.com>
Message-ID: <CA+8X3fVegJjp6yoKgY7+KAuxidBQ4Khd7n2Xohybq2ERV+PPBg@mail.gmail.com>

Hi Pijush,
As before, please keep the messages on the mailing list. In your
example above you have not defined "y", so the function is probably
complaining about being passed a NULL for the dependent variable. I
forgot to add in my previous message that I imported your data by
exporting it from XLSX format to CSV format and then removing the
second line, which seems to be a subsidiary header. If not removed,
that second line will also cause the data to be imported to R as
character mode variables because R reads the first line as a header
(variable names) and then tries to work out from the subsequent lines
the modes of the data. As the first line of "data" is of character
mode if the second line of the spreadsheet is not removed, everything
else will be demoted to that mode.

Jim

On Wed, Jun 3, 2015 at 11:51 PM, Pijush Das <topijush at gmail.com> wrote:
> Dear Jim,
>
> To overcome the "'x' must be numeric" error I found a easy solution, given
> below.
>
>
> p<-matrix( nrow=10, ncol=1630)
>
> for(i in 1:1630){
>   for(j in 1:10){
>     a<-FilterData[i,j]
>     p[j,i]<- as.numeric(a)
>
>   }
> }
>
>
> But I have faced another problem. which is :
>
>> model <- svm( p, y)
> Error in svm.default(p, y) :
>   Need numeric dependent variable for regression.
>
>
> Can you please try to solve this short of problem.
> I have also send an e-mail to the Maintainer of
> ?e1071? Package. Lets see what will they answer.
>
>
>
>
> Thanking you
>
>
>
> With regards
> Pijush.
>
>
> On Wed, Jun 3, 2015 at 4:09 PM, Pijush Das <topijush at gmail.com> wrote:
>>
>> Dear Jim,
>>
>>
>> Thank you very much for your kind help.
>> But the problem is still there.
>>
>>
>>
>> with regards
>> Pijush
>>


From drjimlemon at gmail.com  Thu Jun  4 02:12:57 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 4 Jun 2015 10:12:57 +1000
Subject: [R] Save the result of map.market function to HTML file?
In-Reply-To: <BLU437-SMTP73FEADF571465F01A918ECB4B40@phx.gbl>
References: <BLU436-SMTP1158396A69A1C66F80AB04DB4B50@phx.gbl>
	<CA+8X3fW9dgEnVEO-a+9-JgB9=TpB3wVDQQEGftiazgL0gK30-g@mail.gmail.com>
	<BLU437-SMTP73FEADF571465F01A918ECB4B40@phx.gbl>
Message-ID: <CA+8X3fXS4-11sLn89K+UrUNL_QNi=n+JOqmXvP35kmEN35R3SA@mail.gmail.com>

Hi valerio,
Any chance of letting me know how "it didn't work out"? For example
your code and the resulting error message.

Jim


On Wed, Jun 3, 2015 at 10:32 PM, valerio orfano <ingorfano at hotmail.com> wrote:
> Hi Jim and thanx. Unfortunately it didn?t work out!!
>
> any other help?
>
> rgds valerio
> On 03 Jun 2015, at 02:29, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi valerio,
>> This is a guess, but try running your code with "htmlize" (prettyR).
>> Change the "pdf" call to:
>>
>> png("C:/Users/Administrator/Desktop/treemap1.png")
>> map.market(id = data1$Id, area = data1$size, group = data1$Storage,
>> color = data1$col, lab=c(TRUE,TRUE), main="Test Map")
>> dev.off()
>> png("C:/Users/Administrator/Desktop/treemap2.png")
>> map.market(id = data2$Id, area = data2$size, group = data2$Storage,
>> color = data2$col, lab=c(TRUE,TRUE), main="Test Map")
>> dev.off()
>> png("C:/Users/Administrator/Desktop/treemap3.png")
>> map.market(id = data3$Id, area = data3$size, group = data3$Storage,
>> color = data3$col, lab=c(TRUE,TRUE), main="Test Map")
>> dev.off()
>>
>> as I think you are producing three images.
>>
>> # assume the code above is in a file "vo.R" in the R working directory
>> library(prettyR)
>> htmlize("vo.R")
>>
>> This should produce a file "vo.html" with the plots in it.
>>
>> Jim
>>
>> On Wed, Jun 3, 2015 at 1:49 AM, valerio orfano <ingorfano at hotmail.com> wrote:
>>> HI All,
>>>
>>> i need to call the tree map function in R to display my multiple disks usage, using ?portfolio' library. I need furthermore to generate multiple page each showing the treemap of each disk. It works fine if use pdf file , but my boss wants to save the result into an html file. Any help? I?ve tried with R2HTML library without success. The output of map.market is a ?gTree' object. Any help is appreciated.
>>>
>>> library(portfolio)
>>> data1 <- read.csv("C:/Users/Administrator/Desktop/prova_data1.txt", sep='\t', stringsAsFactors = FALSE)
>>> data2 <- read.csv("C:/Users/Administrator/Desktop/prova_data2.txt", sep='\t', stringsAsFactors = FALSE)
>>> data2 <- read.csv("C:/Users/Administrator/Desktop/prova_data3.txt", sep='\t', stringsAsFactors = FALSE)
>>> pdf("C:/Users/Administrator/Desktop/treemap.pdf")
>>> map.market(id = data1$Id, area = data1$size, group = data1$Storage, color = data1$col, lab=c(TRUE,TRUE), main="Test Map")
>>> map.market(id = data2$Id, area = data2$size, group = data2$Storage, color = data2$col, lab=c(TRUE,TRUE), main="Test Map")
>>> map.market(id = data3$Id, area = data3$size, group = data3$Storage, color = data3$col, lab=c(TRUE,TRUE), main="Test Map")
>>> dev.off()
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


From javascriptart25 at gmail.com  Thu Jun  4 00:02:40 2015
From: javascriptart25 at gmail.com (javascriptart25)
Date: Wed, 3 Jun 2015 15:02:40 -0700 (PDT)
Subject: [R] reshape a data frame
In-Reply-To: <CA+d7zeTtCb2mHZ8f-_P97byOXr4yGD-vf02pOFutWNqhQey_vA@mail.gmail.com>
References: <CA+d7zeTtCb2mHZ8f-_P97byOXr4yGD-vf02pOFutWNqhQey_vA@mail.gmail.com>
Message-ID: <CAJQxKh1Z8HTO3XELBqJSRM8JoCUdAtC15PU8vddkXxqHytVu5w@mail.gmail.com>

You can change ex <- data.frame("gIN" = gIN, "bc1" = bc1, "bc2"=bc2,
"group" = group)

to

ex <- data.frame("gIN" = c(gIN,gIN), "bcX" = c(bc1,bc2), "group" =
c(group,group))


On Wed, Jun 3, 2015 at 2:27 PM, hedelhusk [via R] <
ml-node+s789695n4708145h17 at n4.nabble.com> wrote:

> Hello,
>
> I would like to ask for some advice in reformatting a data frame such as
> the following one:
>
>
> gIN <- c("A_1","A_2","A_3","A_4","B_1","B_2")
> bc1 <- c(1219.79, 1486.84, 1255.80, 941.87, 588.19, 304.02)
> bc2 <- c(319.79, 186.84, 125.80, 94.87, 1008.19, 314.02)
> group <- c("A","A","A","A","B","B")
>
> ex <- data.frame("gIN" = gIN, "bc1" = bc1, "bc2"=bc2, "group" = group)
>
> > ex
>   gIN     bc1     bc2 group
> 1 A_1 1219.79  319.79     A
> 2 A_2 1486.84  186.84     A
> 3 A_3 1255.80  125.80     A
> 4 A_4  941.87   94.87     A
> 5 B_1  588.19 1008.19     B
> 6 B_2  304.02  314.02     B
>
> I would like to reshape this data frame where all the columns that have
> bc1, bc2,...etc are merged into a single column (call it bcX or something)
> and the other variables are kept apart, the example solution follows:
>
>
> > ex_reshaped
>   gIN     bcX     group
> 1 A_1 1219.79       A
> 2 A_2 1486.84       A
> 3 A_3 1255.80       A
> 4 A_4  941.87        A
> 5 B_1  588.19      B
> 6 B_2  304.02       B
> 7 A_1 319.79       A
> 8 A_2 186.84       A
> 9 A_3 125.80       A
> 10 A_4 94.87       A
> 11 B_1 1008.19   B
> 12 B_2 314.02     B
>
> Does anyone know of a package, and/or command to accomplish this?
>
> Thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> [hidden email] <http:///user/SendEmail.jtp?type=node&node=4708145&i=0>
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ------------------------------
>  If you reply to this email, your message will be added to the discussion
> below:
> http://r.789695.n4.nabble.com/reshape-a-data-frame-tp4708145.html
>  To start a new topic under R help, email
> ml-node+s789695n789696h98 at n4.nabble.com
> To unsubscribe from R, click here
> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=789695&code=amF2YXNjcmlwdGFydDI1QGdtYWlsLmNvbXw3ODk2OTV8NTgxOTIwNTYy>
> .
> NAML
> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://r.789695.n4.nabble.com/reshape-a-data-frame-tp4708145p4708146.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From topijush at gmail.com  Thu Jun  4 08:06:20 2015
From: topijush at gmail.com (Pijush Das)
Date: Thu, 4 Jun 2015 11:36:20 +0530
Subject: [R] SVM error
Message-ID: <CAGa91zhVyskaTeBcGSOTStoBQQRsDU+ap2d5a=Jqc6E5K0SARw@mail.gmail.com>

Dear Sir,

I have converted the data into numeric as the function read.excel read the
data file as a character (as it was said by David Meyer, maintainer of the
package e1071) and after that run the function svm. Then another error is
found there. The detail description of the code and error is given below.

Please check this code and try to solve the error.


> library(e1071)
> library("openxlsx")
>List <- read.xlsx(file.choose(), sheet = 1,colNames = TRUE,rowNames = TRUE)
>Data <- read.xlsx(file.choose(), sheet=1,colNames = TRUE,rowNames = TRUE)
> status<-Data[1, ]
> View(status)
> FilterData <-Data[rownames(List), ]
> View(FilterData)
> TFData<-matrix( nrow=10, ncol=1630)
> for(i in 1:1630){
+   for(j in 1:10){
+     a<-FilterData[i,j]
+     TFData[j,i]<- as.numeric(a)
+
+   }
+ }
> Tstatus <- t(status)
> x<-TFData
> is.numeric(x)
[1] TRUE
> y<-Tstatus
> model <- svm( x, y)
Error in svm.default(x, y) :
  Need numeric dependent variable for regression.

Please find the attached files, given below.

Thank You



With regards
Pijush

From ingorfano at hotmail.com  Thu Jun  4 09:52:43 2015
From: ingorfano at hotmail.com (valerio orfano)
Date: Thu, 4 Jun 2015 09:52:43 +0200
Subject: [R] Save the result of map.market function to HTML file?
In-Reply-To: <CA+8X3fXS4-11sLn89K+UrUNL_QNi=n+JOqmXvP35kmEN35R3SA@mail.gmail.com>
References: <BLU436-SMTP1158396A69A1C66F80AB04DB4B50@phx.gbl>
	<CA+8X3fW9dgEnVEO-a+9-JgB9=TpB3wVDQQEGftiazgL0gK30-g@mail.gmail.com>
	<BLU437-SMTP73FEADF571465F01A918ECB4B40@phx.gbl>
	<CA+8X3fXS4-11sLn89K+UrUNL_QNi=n+JOqmXvP35kmEN35R3SA@mail.gmail.com>
Message-ID: <BLU436-SMTP25344FD42BE5F93F99D8000B4B30@phx.gbl>

Belowe My code:

treemap.R
------------------------------------
library(portfolio)
library(sendmailR)
setwd("C:/Users/Administrator/Desktop")
data_all <- read.csv("prova_data.txt", sep='\t', stringsAsFactors = FALSE)
distinctstorage <- unique(data_all$Storage)
stor_var <- "Storage001"

filename <- paste(stor_var,".png",sep='')

png(filename)
print (stor_var)
data = data_all[data_all$Storage == stor_var,]
capacity <- data[data$Id == 'Capacity','size']
data <- data[data$Id != 'Capacity',]
storage <- data$Storage[1]
disk_used <- sum(data$size)
data$col <- seq(1,nrow(data),1)
col_free <- max(data$col + 1)
space_free <- capacity - disk_used
if (space_free < 1000)
{
col_free <- -17
}
data = rbind(data,c('Free',storage,free_space,col_free))
data$col <- as.numeric(data$col)
data$size <- as.numeric(data$size)
map.market(id = data$Id, area = data$size, group = data$Storage, color = data$col, lab=c(TRUE,TRUE), main="Test Map")
dev.off()



Script.R
???????????????
library(prettyR)
setwd("C:/Users/Administrator/Desktop")
htmlize("treemap.R","treemap")

Belowe the error i get

 htmlize("treemap.R","treemap")
Error in .geometry(width, height, units, res) : 
  object 'NAStorage001.png' not found


[[elided Hotmail spam]]

rgds valerio

On 04 Jun 2015, at 02:12, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi valerio,
> Any chance of letting me know how "it didn't work out"? For example
> your code and the resulting error message.
> 
> Jim
> 
> 
> On Wed, Jun 3, 2015 at 10:32 PM, valerio orfano <ingorfano at hotmail.com> wrote:
[[elided Hotmail spam]]
>> 
>> any other help?
>> 
>> rgds valerio
>> On 03 Jun 2015, at 02:29, Jim Lemon <drjimlemon at gmail.com> wrote:
>> 
>>> Hi valerio,
>>> This is a guess, but try running your code with "htmlize" (prettyR).
>>> Change the "pdf" call to:
>>> 
>>> png("C:/Users/Administrator/Desktop/treemap1.png")
>>> map.market(id = data1$Id, area = data1$size, group = data1$Storage,
>>> color = data1$col, lab=c(TRUE,TRUE), main="Test Map")
>>> dev.off()
>>> png("C:/Users/Administrator/Desktop/treemap2.png")
>>> map.market(id = data2$Id, area = data2$size, group = data2$Storage,
>>> color = data2$col, lab=c(TRUE,TRUE), main="Test Map")
>>> dev.off()
>>> png("C:/Users/Administrator/Desktop/treemap3.png")
>>> map.market(id = data3$Id, area = data3$size, group = data3$Storage,
>>> color = data3$col, lab=c(TRUE,TRUE), main="Test Map")
>>> dev.off()
>>> 
>>> as I think you are producing three images.
>>> 
>>> # assume the code above is in a file "vo.R" in the R working directory
>>> library(prettyR)
>>> htmlize("vo.R")
>>> 
>>> This should produce a file "vo.html" with the plots in it.
>>> 
>>> Jim
>>> 
>>> On Wed, Jun 3, 2015 at 1:49 AM, valerio orfano <ingorfano at hotmail.com> wrote:
>>>> HI All,
>>>> 
>>>> i need to call the tree map function in R to display my multiple disks usage, using ?portfolio' library. I need furthermore to generate multiple page each showing the treemap of each disk. It works fine if use pdf file , but my boss wants to save the result into an html file. Any help? I?ve tried with R2HTML library without success. The output of map.market is a ?gTree' object. Any help is appreciated.
>>>> 
>>>> library(portfolio)
>>>> data1 <- read.csv("C:/Users/Administrator/Desktop/prova_data1.txt", sep='\t', stringsAsFactors = FALSE)
>>>> data2 <- read.csv("C:/Users/Administrator/Desktop/prova_data2.txt", sep='\t', stringsAsFactors = FALSE)
>>>> data2 <- read.csv("C:/Users/Administrator/Desktop/prova_data3.txt", sep='\t', stringsAsFactors = FALSE)
>>>> pdf("C:/Users/Administrator/Desktop/treemap.pdf")
>>>> map.market(id = data1$Id, area = data1$size, group = data1$Storage, color = data1$col, lab=c(TRUE,TRUE), main="Test Map")
>>>> map.market(id = data2$Id, area = data2$size, group = data2$Storage, color = data2$col, lab=c(TRUE,TRUE), main="Test Map")
>>>> map.market(id = data3$Id, area = data3$size, group = data3$Storage, color = data3$col, lab=c(TRUE,TRUE), main="Test Map")
>>>> dev.off()
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 


From thierry.onkelinx at inbo.be  Thu Jun  4 09:59:01 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 4 Jun 2015 09:59:01 +0200
Subject: [R] Difference between 32-bit and 64-bit version
In-Reply-To: <556F269E.5050904@gmail.com>
References: <CAJuCY5wA8kw0pPX5eTwWns6mik8vn17VbVuLgOQfD7SSYzJZ-Q@mail.gmail.com>
	<556F269E.5050904@gmail.com>
Message-ID: <CAJuCY5zMZBtqCMPNNti8Ouc7hPV4q3H9hrm1M3OQHyYRko=J1w@mail.gmail.com>

Dear Duncan,

I had been thinking about FAQ 7.31. I tried to create a dummy dataset with
the same structure to replicate the problem with the need of sending my
dataset. However all of them gave identical() results between 32-bit and
64-bit. Note that coef()$fRow is a 1266 x 6 data.frame. Is it correct to
infer that tiny difference between 32-bit and 64-bit are possible but have
a low probability of occurring?

signif() makes indeed more sense than round(). Using 20 digits gives
identical results, 21 digits gives non identical results.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-06-03 18:09 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 03/06/2015 11:56 AM, Thierry Onkelinx wrote:
> > Dear all,
> >
> > I'm a bit puzzled by the difference in an object when created in R 32-bit
> > and R 64-bit.
> >
> > Consider the code below. test.rda is available at
> >
> https://drive.google.com/file/d/0BzBrlGSuB9n-NFBWeC1TR093Sms/view?usp=sharing
> >
> > # Run in R 3.2.0 Windows 32-bit, lme4 1.1-8
> > library(lme4)
> > load("test.rda")
> > coef.32 <- coef(test)
> > save(coef.32, file = "32bit.rda")
> >
> > # Run in R 3.2.0 Windows 64-bit, lme4 1.1-8
> > library(lme4)
> > load("~/test.rda")
> > coef.64 <- coef(test)
> > save(coef.64, file = "64bit.rda")
> >
> >
> > # Compare the results
> > # Run in R 3.2.0 Windows 32-bit, lme4 1.1-8
> > # Run in R 3.2.0 Windows 64-bit, lme4 1.1-8
> > library(lme4)
> > load("32bit.rda")
> > load("64bit.rda")
> > identical(coef.32, coef.64) # FALSE
> > identical(coef.32$fRow, coef.64$fRow) # FALSE
> > identical(coef.32$fLocation, coef.64$fLocation) # TRUE
> > identical(coef.32$fSubLocation, coef.64$fSubLocation) # TRUE
> >
> > The first comparison is FALSE, because the second is FALSE. But why is
> the
> > second FALSE and the third and fourth TRUE?
> >
> > My goal is the calculate a SHA1 hash on the coef(test) to track if the
> > coefficients of test have changed. I'd like to get the same hash on a
> > 32-bit and 64-bit system. A simple hack would be to calculate the hash on
> > round(coef(test), 20). Is that a good or bad idea?
> >
> > identical(round(coef.32$fRow, 20), round(coef.64$fRow, 20)) # TRUE
>
> Different math libraries round differently, so small differences are
> expected.  This is FAQ 7.31.  In many cases the 32 bit calculations are
> more accurate, because they tend to use more 80 bit extended precision
> intermediate values, but that is not guaranteed.
>
> Rounding before comparing makes sense, but I would use signif() instead
> of round(), I would choose a relatively small number of significant
> digits, and I would expect to see a few false positives:  if the true
> value is 0 but some "random" noise is added, I'd expect values rounded
> by signif() to be unequal.
>
> Duncan Murdoch
>
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From f_j_rod at hotmail.com  Thu Jun  4 09:59:52 2015
From: f_j_rod at hotmail.com (Frank S.)
Date: Thu, 4 Jun 2015 09:59:52 +0200
Subject: [R] Greek letters with subscript numbers on x-axis
In-Reply-To: <CAF8bMcafucUX2C4Gsdiu=y+nFiQuz8TtSYWM31MRp8i_ii9kHw@mail.gmail.com>
References: <CAH-FEnjfDBZF2-1HWR0_ULd71Kfrd3z+ES13ZdXaj4wGD1OVOw@mail.gmail.com>,
	<CAH-FEnh+1DDFOsWNq5GF7p-iLpBOOUEaKst+NZGm1Pc-f+arvA@mail.gmail.com>,
	<26C7B3B6-6596-418C-9CC4-C65558E54F53@dcn.davis.CA.us>
	<000f01cff518$92e14210$b8a3c630$@mcmaster.ca>,
	<alpine.BSF.2.00.1410310822530.42077@pedal.dcn.davis.ca.us>
	<BAY168-W110DBCDE35CFDCF099B3682BAB40@phx.gbl>,
	<CAF8bMcafucUX2C4Gsdiu=y+nFiQuz8TtSYWM31MRp8i_ii9kHw@mail.gmail.com>
Message-ID: <BAY168-W44A193BD2CF88170D96BE5BAB30@phx.gbl>

Thank you very much Bill,
 
Your answer to my question is exactly what I was trying to do in my R code.
 
Best regards.
 		 	   		  
	[[alternative HTML version deleted]]


From ingorfano at hotmail.com  Thu Jun  4 10:53:32 2015
From: ingorfano at hotmail.com (valerio orfano)
Date: Thu, 4 Jun 2015 10:53:32 +0200
Subject: [R] R convert pdf/png to html
In-Reply-To: <D19481A1.12CE23%macqueen1@llnl.gov>
References: <SNT149-W72E78EE22C1C7CDAE7CD6EC2B40@phx.gbl>
	<BLU437-SMTP57CC431318B7FC3B3B8868B4B40@phx.gbl>
	<A6F4374B-8171-42B1-96F6-4B2A2E2818CC@utoronto.ca>
	<BLU436-SMTP2536073DF8683728EBE8301B4B40@phx.gbl>
	<D19481A1.12CE23%macqueen1@llnl.gov>
Message-ID: <BLU436-SMTP197EBE3068F2ED9C29D9D86B4B30@phx.gbl>

I have the following code:

setwd("C:/Users/Administrator/Desktop")
cat("<!DOCTYPE html>",file="treemap.html", append=TRUE,sep='\n')
cat("<html>",file="treemap.html", append=TRUE,sep='\n')
cat("<body>",file="treemap.html", append=TRUE,sep='\n')
cat("<h1>TreeMap</h1>",file="treemap.html", append=TRUE,sep='\n')
cat("<img src='Storage001.png'>","treemap.html", append=TRUE,sep='\n')
cat("</body>",file="treemap.html", append=TRUE,sep='\n')
cat("</html>",file="treemap.html", append=TRUE,sep='\n')


but this tag is not getting written in html file
cat("<img src='Storage001.png'>","treemap.html", append=TRUE,sep='\n?)

so i cannot display the img my html

belowe the resulting html

<!DOCTYPE html>
<html>
<body>
<h1>TreeMap</h1>
</body>
</html>
<!DOCTYPE html>
<html>
<body>
<h1>TreeMap</h1>
</body>
</html>


Any help

rgds valerio
On 03 Jun 2015, at 19:06, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> When it's as simple as in Boris's example, just use cat() statements.
> 
> Otherwise, go to CRAN, find the packages page ("Table of available
> packages, sorted by name"), and search for "html"
> 
> -Don
> 
> -- 
> Don MacQueen
> 
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> 
> 
> 
> 
> 
> On 6/3/15, 9:38 AM, "valerio orfano" <ingorfano at hotmail.com> wrote:
> 
>> Hi Boris and thanx a lot
>> 
>> Which library should i be using to create html in R?
>> 
>> rgds valerio
>> On 03 Jun 2015, at 18:08, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>> 
>>> ... as in: the png exists in a directory that is accessible to the
>>> server?
>>> 
>>> That would be as simple as creating a HTML document with the following
>>> contents:
>>> 
>>> <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
>>> "http://www.w3.org/TR/html4/strict.dtd">
>>> <html>
>>> <head><title="Image"></head>
>>> <body><img src="myPNGimage.png"></body>
>>> </html>
>>> 
>>> 
>>> B.
>>> 
>>> 
>>> On Jun 3, 2015, at 11:32 AM, valerio orfano <ingorfano at hotmail.com>
>>> wrote:
>>> 
>>>> Hi All
>>>> 
>>>> Is there any chance in R to convert a png and/or pdf file into an html?
>>>> Any example?
>>>> 
>>>> I?ve tried htmlize but doesn?t work out!
>>>> 
>>>> Rgds valerio
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From ingorfano at hotmail.com  Thu Jun  4 11:00:49 2015
From: ingorfano at hotmail.com (valerio orfano)
Date: Thu, 4 Jun 2015 11:00:49 +0200
Subject: [R] R convert pdf/png to html
In-Reply-To: <BLU436-SMTP197EBE3068F2ED9C29D9D86B4B30@phx.gbl>
References: <SNT149-W72E78EE22C1C7CDAE7CD6EC2B40@phx.gbl>
	<BLU437-SMTP57CC431318B7FC3B3B8868B4B40@phx.gbl>
	<A6F4374B-8171-42B1-96F6-4B2A2E2818CC@utoronto.ca>
	<BLU436-SMTP2536073DF8683728EBE8301B4B40@phx.gbl>
	<D19481A1.12CE23%macqueen1@llnl.gov>
	<BLU436-SMTP197EBE3068F2ED9C29D9D86B4B30@phx.gbl>
Message-ID: <BLU437-SMTP142278EA2F6E4EF004D1D3B4B30@phx.gbl>

I forgot to use fie= treemap.html :)


On 04 Jun 2015, at 10:53, valerio orfano <ingorfano at hotmail.com> wrote:

> I have the following code:
> 
> setwd("C:/Users/Administrator/Desktop")
> cat("<!DOCTYPE html>",file="treemap.html", append=TRUE,sep='\n')
> cat("<html>",file="treemap.html", append=TRUE,sep='\n')
> cat("<body>",file="treemap.html", append=TRUE,sep='\n')
> cat("<h1>TreeMap</h1>",file="treemap.html", append=TRUE,sep='\n')
> cat("<img src='Storage001.png'>","treemap.html", append=TRUE,sep='\n')
> cat("</body>",file="treemap.html", append=TRUE,sep='\n')
> cat("</html>",file="treemap.html", append=TRUE,sep='\n')
> 
> 
> but this tag is not getting written in html file
> cat("<img src='Storage001.png'>","treemap.html", append=TRUE,sep='\n?)
> 
> so i cannot display the img my html
> 
> belowe the resulting html
> 
> <!DOCTYPE html>
> <html>
> <body>
> <h1>TreeMap</h1>
> </body>
> </html>
> <!DOCTYPE html>
> <html>
> <body>
> <h1>TreeMap</h1>
> </body>
> </html>
> 
> 
> Any help
> 
> rgds valerio
> On 03 Jun 2015, at 19:06, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> 
>> When it's as simple as in Boris's example, just use cat() statements.
>> 
>> Otherwise, go to CRAN, find the packages page ("Table of available
>> packages, sorted by name"), and search for "html"
>> 
>> -Don
>> 
>> -- 
>> Don MacQueen
>> 
>> Lawrence Livermore National Laboratory
>> 7000 East Ave., L-627
>> Livermore, CA 94550
>> 925-423-1062
>> 
>> 
>> 
>> 
>> 
>> On 6/3/15, 9:38 AM, "valerio orfano" <ingorfano at hotmail.com> wrote:
>> 
>>> Hi Boris and thanx a lot
>>> 
>>> Which library should i be using to create html in R?
>>> 
>>> rgds valerio
>>> On 03 Jun 2015, at 18:08, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>> 
>>>> ... as in: the png exists in a directory that is accessible to the
>>>> server?
>>>> 
>>>> That would be as simple as creating a HTML document with the following
>>>> contents:
>>>> 
>>>> <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
>>>> "http://www.w3.org/TR/html4/strict.dtd">
>>>> <html>
>>>> <head><title="Image"></head>
>>>> <body><img src="myPNGimage.png"></body>
>>>> </html>
>>>> 
>>>> 
>>>> B.
>>>> 
>>>> 
>>>> On Jun 3, 2015, at 11:32 AM, valerio orfano <ingorfano at hotmail.com>
>>>> wrote:
>>>> 
>>>>> Hi All
>>>>> 
>>>>> Is there any chance in R to convert a png and/or pdf file into an html?
>>>>> Any example?
>>>>> 
>>>>> I?ve tried htmlize but doesn?t work out!
>>>>> 
>>>>> Rgds valerio
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 


From sibylle.stoeckli at gmx.ch  Thu Jun  4 11:01:07 2015
From: sibylle.stoeckli at gmx.ch (=?iso-8859-1?Q?Sibylle_St=F6ckli?=)
Date: Thu, 4 Jun 2015 11:01:07 +0200
Subject: [R] Vegan_p-values_RDA
Message-ID: <32D6DDED-B8BC-435C-9B37-129A63CCE6F5@gmx.ch>

Dear R members,

I understand the main principles why R-Vegan does not provide p-values for the biplot scores and/or canonical coefficients (see also post on stackoverflow).

(i) We can obtain linear regression statistics and refit an ordination result as multiple response linear model (lm, see as.mlm.cca). This regression ignores residual unconstrained variation in the data. However, constrained ordination is based on iteration with regression. My question is now, how does ordination considers this unconstrained variation? By the unimodal distribution of the data (cca). By the selected distance matrix (Chi, Euclidian)? Or is the difference based on the fact, that ordination is a multivariate analyses?

(ii)  I think question (i) is the reason why I get difference between biplot scores (integral of rda) and scores() (equivalent of regression coefficients)
scores(PFcompUZL_h_rda, choices = 1:4, display = "bp", scaling = 0)
scores(PFcompUZL_h_rda)

Many thanks for your answer
Sibylle





	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Jun  4 11:53:25 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 04 Jun 2015 05:53:25 -0400
Subject: [R] Difference between 32-bit and 64-bit version
In-Reply-To: <CAJuCY5zMZBtqCMPNNti8Ouc7hPV4q3H9hrm1M3OQHyYRko=J1w@mail.gmail.com>
References: <CAJuCY5wA8kw0pPX5eTwWns6mik8vn17VbVuLgOQfD7SSYzJZ-Q@mail.gmail.com>	<556F269E.5050904@gmail.com>
	<CAJuCY5zMZBtqCMPNNti8Ouc7hPV4q3H9hrm1M3OQHyYRko=J1w@mail.gmail.com>
Message-ID: <55702015.8000807@gmail.com>

On 04/06/2015 3:59 AM, Thierry Onkelinx wrote:
> Dear Duncan,
> 
> I had been thinking about FAQ 7.31. I tried to create a dummy dataset
> with the same structure to replicate the problem with the need of
> sending my dataset. However all of them gave identical() results between
> 32-bit and 64-bit. Note that coef()$fRow is a 1266 x 6 data.frame. Is it
> correct to infer that tiny difference between 32-bit and 64-bit are
> possible but have a low probability of occurring?

Differences are rare, but it's hard to assign a probability to them.

Duncan Murdoch

> 
> signif() makes indeed more sense than round(). Using 20 digits gives
> identical results, 21 digits gives non identical results.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data. ~ John Tukey
> 
> 2015-06-03 18:09 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com>>:
> 
>     On 03/06/2015 11:56 AM, Thierry Onkelinx wrote:
>     > Dear all,
>     >
>     > I'm a bit puzzled by the difference in an object when created in R
>     32-bit
>     > and R 64-bit.
>     >
>     > Consider the code below. test.rda is available at
>     >
>     https://drive.google.com/file/d/0BzBrlGSuB9n-NFBWeC1TR093Sms/view?usp=sharing
>     >
>     > # Run in R 3.2.0 Windows 32-bit, lme4 1.1-8
>     > library(lme4)
>     > load("test.rda")
>     > coef.32 <- coef(test)
>     > save(coef.32, file = "32bit.rda")
>     >
>     > # Run in R 3.2.0 Windows 64-bit, lme4 1.1-8
>     > library(lme4)
>     > load("~/test.rda")
>     > coef.64 <- coef(test)
>     > save(coef.64, file = "64bit.rda")
>     >
>     >
>     > # Compare the results
>     > # Run in R 3.2.0 Windows 32-bit, lme4 1.1-8
>     > # Run in R 3.2.0 Windows 64-bit, lme4 1.1-8
>     > library(lme4)
>     > load("32bit.rda")
>     > load("64bit.rda")
>     > identical(coef.32, coef.64) # FALSE
>     > identical(coef.32$fRow, coef.64$fRow) # FALSE
>     > identical(coef.32$fLocation, coef.64$fLocation) # TRUE
>     > identical(coef.32$fSubLocation, coef.64$fSubLocation) # TRUE
>     >
>     > The first comparison is FALSE, because the second is FALSE. But
>     why is the
>     > second FALSE and the third and fourth TRUE?
>     >
>     > My goal is the calculate a SHA1 hash on the coef(test) to track if the
>     > coefficients of test have changed. I'd like to get the same hash on a
>     > 32-bit and 64-bit system. A simple hack would be to calculate the
>     hash on
>     > round(coef(test), 20). Is that a good or bad idea?
>     >
>     > identical(round(coef.32$fRow, 20), round(coef.64$fRow, 20)) # TRUE
> 
>     Different math libraries round differently, so small differences are
>     expected.  This is FAQ 7.31.  In many cases the 32 bit calculations are
>     more accurate, because they tend to use more 80 bit extended precision
>     intermediate values, but that is not guaranteed.
> 
>     Rounding before comparing makes sense, but I would use signif() instead
>     of round(), I would choose a relatively small number of significant
>     digits, and I would expect to see a few false positives:  if the true
>     value is 0 but some "random" noise is added, I'd expect values rounded
>     by signif() to be unequal.
> 
>     Duncan Murdoch
> 
>     >
>     > Best regards,
>     >
>     > ir. Thierry Onkelinx
>     > Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>     > Forest
>     > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>     > Kliniekstraat 25
>     > 1070 Anderlecht
>     > Belgium
>     >
>     > To call in the statistician after the experiment is done may be no more
>     > than asking him to perform a post-mortem examination: he may be able to say
>     > what the experiment died of. ~ Sir Ronald Aylmer Fisher
>     > The plural of anecdote is not data. ~ Roger Brinner
>     > The combination of some data and an aching desire for an answer does not
>     > ensure that a reasonable answer can be extracted from a given body of data.
>     > ~ John Tukey
>     >
>     >       [[alternative HTML version deleted]]
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>     >
> 
>


From drjimlemon at gmail.com  Thu Jun  4 12:01:56 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 4 Jun 2015 20:01:56 +1000
Subject: [R] Save the result of map.market function to HTML file?
In-Reply-To: <BLU436-SMTP25344FD42BE5F93F99D8000B4B30@phx.gbl>
References: <BLU436-SMTP1158396A69A1C66F80AB04DB4B50@phx.gbl>
	<CA+8X3fW9dgEnVEO-a+9-JgB9=TpB3wVDQQEGftiazgL0gK30-g@mail.gmail.com>
	<BLU437-SMTP73FEADF571465F01A918ECB4B40@phx.gbl>
	<CA+8X3fXS4-11sLn89K+UrUNL_QNi=n+JOqmXvP35kmEN35R3SA@mail.gmail.com>
	<BLU436-SMTP25344FD42BE5F93F99D8000B4B30@phx.gbl>
Message-ID: <CA+8X3fVa0vdkznGTcHmE_Ox67ifBW2vQY5ZLoDTO_na4rJkj-g@mail.gmail.com>

Hi valerio,
This is a great coincidence. I have been working on exactly this
problem in an analysis I have been conducting. When I supply a
character variable to the png function rather than an explicit string,
I get the same error in htmlize. Analyzing the error message, I
realized that it was not complaining about the filename, but about the
geometry of the device it was opening. When I added a width argument
to the command:

png(filename,width=480)

it worked fine. I'm not sure exactly what is happening and am
attempting to fix this at the moment, but if you try adding a width
argument (480 is the default width) it may work for you as well.
Alternatively you can specify the filename explicitly:

png("Storage001.png")

and that should work.

Jim

On Thu, Jun 4, 2015 at 5:52 PM, valerio orfano <ingorfano at hotmail.com> wrote:
> Belowe My code:
>
> treemap.R
> ------------------------------------
> library(portfolio)
> library(sendmailR)
> setwd("C:/Users/Administrator/Desktop")
> data_all <- read.csv("prova_data.txt", sep='\t', stringsAsFactors = FALSE)
> distinctstorage <- unique(data_all$Storage)
> stor_var <- "Storage001"
>
> filename <- paste(stor_var,".png",sep='')
>
> png(filename)
> print (stor_var)
> data = data_all[data_all$Storage == stor_var,]
> capacity <- data[data$Id == 'Capacity','size']
> data <- data[data$Id != 'Capacity',]
> storage <- data$Storage[1]
> disk_used <- sum(data$size)
> data$col <- seq(1,nrow(data),1)
> col_free <- max(data$col + 1)
> space_free <- capacity - disk_used
> if (space_free < 1000)
> {
> col_free <- -17
> }
> data = rbind(data,c('Free',storage,free_space,col_free))
> data$col <- as.numeric(data$col)
> data$size <- as.numeric(data$size)
> map.market(id = data$Id, area = data$size, group = data$Storage, color = data$col, lab=c(TRUE,TRUE), main="Test Map")
> dev.off()
>
>
>
> Script.R
> ???????????????
> library(prettyR)
> setwd("C:/Users/Administrator/Desktop")
> htmlize("treemap.R","treemap")
>
> Belowe the error i get
>
>  htmlize("treemap.R","treemap")
> Error in .geometry(width, height, units, res) :
>   object 'NAStorage001.png' not found
>
>
> Any help is appreciated!
>
> rgds valerio
>
> On 04 Jun 2015, at 02:12, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi valerio,
>> Any chance of letting me know how "it didn't work out"? For example
>> your code and the resulting error message.
>>
>> Jim
>>
>>
>> On Wed, Jun 3, 2015 at 10:32 PM, valerio orfano <ingorfano at hotmail.com> wrote:
>>> Hi Jim and thanx. Unfortunately it didn?t work out!!
>>>
>>> any other help?
>>>
>>> rgds valerio
>>> On 03 Jun 2015, at 02:29, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>>> Hi valerio,
>>>> This is a guess, but try running your code with "htmlize" (prettyR).
>>>> Change the "pdf" call to:
>>>>
>>>> png("C:/Users/Administrator/Desktop/treemap1.png")
>>>> map.market(id = data1$Id, area = data1$size, group = data1$Storage,
>>>> color = data1$col, lab=c(TRUE,TRUE), main="Test Map")
>>>> dev.off()
>>>> png("C:/Users/Administrator/Desktop/treemap2.png")
>>>> map.market(id = data2$Id, area = data2$size, group = data2$Storage,
>>>> color = data2$col, lab=c(TRUE,TRUE), main="Test Map")
>>>> dev.off()
>>>> png("C:/Users/Administrator/Desktop/treemap3.png")
>>>> map.market(id = data3$Id, area = data3$size, group = data3$Storage,
>>>> color = data3$col, lab=c(TRUE,TRUE), main="Test Map")
>>>> dev.off()
>>>>
>>>> as I think you are producing three images.
>>>>
>>>> # assume the code above is in a file "vo.R" in the R working directory
>>>> library(prettyR)
>>>> htmlize("vo.R")
>>>>
>>>> This should produce a file "vo.html" with the plots in it.
>>>>
>>>> Jim
>>>>
>>>> On Wed, Jun 3, 2015 at 1:49 AM, valerio orfano <ingorfano at hotmail.com> wrote:
>>>>> HI All,
>>>>>
>>>>> i need to call the tree map function in R to display my multiple disks usage, using ?portfolio' library. I need furthermore to generate multiple page each showing the treemap of each disk. It works fine if use pdf file , but my boss wants to save the result into an html file. Any help? I?ve tried with R2HTML library without success. The output of map.market is a ?gTree' object. Any help is appreciated.
>>>>>
>>>>> library(portfolio)
>>>>> data1 <- read.csv("C:/Users/Administrator/Desktop/prova_data1.txt", sep='\t', stringsAsFactors = FALSE)
>>>>> data2 <- read.csv("C:/Users/Administrator/Desktop/prova_data2.txt", sep='\t', stringsAsFactors = FALSE)
>>>>> data2 <- read.csv("C:/Users/Administrator/Desktop/prova_data3.txt", sep='\t', stringsAsFactors = FALSE)
>>>>> pdf("C:/Users/Administrator/Desktop/treemap.pdf")
>>>>> map.market(id = data1$Id, area = data1$size, group = data1$Storage, color = data1$col, lab=c(TRUE,TRUE), main="Test Map")
>>>>> map.market(id = data2$Id, area = data2$size, group = data2$Storage, color = data2$col, lab=c(TRUE,TRUE), main="Test Map")
>>>>> map.market(id = data3$Id, area = data3$size, group = data3$Storage, color = data3$col, lab=c(TRUE,TRUE), main="Test Map")
>>>>> dev.off()
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>


From thierry.onkelinx at inbo.be  Thu Jun  4 12:11:43 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 4 Jun 2015 12:11:43 +0200
Subject: [R] Difference between 32-bit and 64-bit version
In-Reply-To: <55702015.8000807@gmail.com>
References: <CAJuCY5wA8kw0pPX5eTwWns6mik8vn17VbVuLgOQfD7SSYzJZ-Q@mail.gmail.com>
	<556F269E.5050904@gmail.com>
	<CAJuCY5zMZBtqCMPNNti8Ouc7hPV4q3H9hrm1M3OQHyYRko=J1w@mail.gmail.com>
	<55702015.8000807@gmail.com>
Message-ID: <CAJuCY5yDkjacKqioXrYmnqzz3sgNTwkF1QSMAJQYmUVxo3N23w@mail.gmail.com>

"low probability of occurring" was just statisticians lingo for "rare" ;-)


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-06-04 11:53 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 04/06/2015 3:59 AM, Thierry Onkelinx wrote:
> > Dear Duncan,
> >
> > I had been thinking about FAQ 7.31. I tried to create a dummy dataset
> > with the same structure to replicate the problem with the need of
> > sending my dataset. However all of them gave identical() results between
> > 32-bit and 64-bit. Note that coef()$fRow is a 1266 x 6 data.frame. Is it
> > correct to infer that tiny difference between 32-bit and 64-bit are
> > possible but have a low probability of occurring?
>
> Differences are rare, but it's hard to assign a probability to them.
>
> Duncan Murdoch
>
> >
> > signif() makes indeed more sense than round(). Using 20 digits gives
> > identical results, 21 digits gives non identical results.
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> > and Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> > say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> > data. ~ John Tukey
> >
> > 2015-06-03 18:09 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com
> > <mailto:murdoch.duncan at gmail.com>>:
> >
> >     On 03/06/2015 11:56 AM, Thierry Onkelinx wrote:
> >     > Dear all,
> >     >
> >     > I'm a bit puzzled by the difference in an object when created in R
> >     32-bit
> >     > and R 64-bit.
> >     >
> >     > Consider the code below. test.rda is available at
> >     >
> >
> https://drive.google.com/file/d/0BzBrlGSuB9n-NFBWeC1TR093Sms/view?usp=sharing
> >     >
> >     > # Run in R 3.2.0 Windows 32-bit, lme4 1.1-8
> >     > library(lme4)
> >     > load("test.rda")
> >     > coef.32 <- coef(test)
> >     > save(coef.32, file = "32bit.rda")
> >     >
> >     > # Run in R 3.2.0 Windows 64-bit, lme4 1.1-8
> >     > library(lme4)
> >     > load("~/test.rda")
> >     > coef.64 <- coef(test)
> >     > save(coef.64, file = "64bit.rda")
> >     >
> >     >
> >     > # Compare the results
> >     > # Run in R 3.2.0 Windows 32-bit, lme4 1.1-8
> >     > # Run in R 3.2.0 Windows 64-bit, lme4 1.1-8
> >     > library(lme4)
> >     > load("32bit.rda")
> >     > load("64bit.rda")
> >     > identical(coef.32, coef.64) # FALSE
> >     > identical(coef.32$fRow, coef.64$fRow) # FALSE
> >     > identical(coef.32$fLocation, coef.64$fLocation) # TRUE
> >     > identical(coef.32$fSubLocation, coef.64$fSubLocation) # TRUE
> >     >
> >     > The first comparison is FALSE, because the second is FALSE. But
> >     why is the
> >     > second FALSE and the third and fourth TRUE?
> >     >
> >     > My goal is the calculate a SHA1 hash on the coef(test) to track if
> the
> >     > coefficients of test have changed. I'd like to get the same hash
> on a
> >     > 32-bit and 64-bit system. A simple hack would be to calculate the
> >     hash on
> >     > round(coef(test), 20). Is that a good or bad idea?
> >     >
> >     > identical(round(coef.32$fRow, 20), round(coef.64$fRow, 20)) # TRUE
> >
> >     Different math libraries round differently, so small differences are
> >     expected.  This is FAQ 7.31.  In many cases the 32 bit calculations
> are
> >     more accurate, because they tend to use more 80 bit extended
> precision
> >     intermediate values, but that is not guaranteed.
> >
> >     Rounding before comparing makes sense, but I would use signif()
> instead
> >     of round(), I would choose a relatively small number of significant
> >     digits, and I would expect to see a few false positives:  if the true
> >     value is 0 but some "random" noise is added, I'd expect values
> rounded
> >     by signif() to be unequal.
> >
> >     Duncan Murdoch
> >
> >     >
> >     > Best regards,
> >     >
> >     > ir. Thierry Onkelinx
> >     > Instituut voor natuur- en bosonderzoek / Research Institute for
> Nature and
> >     > Forest
> >     > team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> Assurance
> >     > Kliniekstraat 25
> >     > 1070 Anderlecht
> >     > Belgium
> >     >
> >     > To call in the statistician after the experiment is done may be no
> more
> >     > than asking him to perform a post-mortem examination: he may be
> able to say
> >     > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >     > The plural of anecdote is not data. ~ Roger Brinner
> >     > The combination of some data and an aching desire for an answer
> does not
> >     > ensure that a reasonable answer can be extracted from a given body
> of data.
> >     > ~ John Tukey
> >     >
> >     >       [[alternative HTML version deleted]]
> >     >
> >     > ______________________________________________
> >     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
> >     To UNSUBSCRIBE and more, see
> >     > https://stat.ethz.ch/mailman/listinfo/r-help
> >     > PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     > and provide commented, minimal, self-contained, reproducible code.
> >     >
> >
> >
>
>

	[[alternative HTML version deleted]]


From jacksonmrodrigues at gmail.com  Thu Jun  4 12:20:58 2015
From: jacksonmrodrigues at gmail.com (Jackson Rodrigues)
Date: Thu, 4 Jun 2015 12:20:58 +0200
Subject: [R] Help to solve an Error
Message-ID: <CAPL76w8SQMv5=oXwZbspgf82noF3Ojv=G08foXei7fuAJbtEfQ@mail.gmail.com>

Hi,



I want to apply the codes of Gavin Simpson from
http://www.fromthebottomoftheheap.net/2011/06/11/global-warming-since-1995-now-significant/
on my own data to detect trends in a subset. However, when I run:

> grecent <- subset(gtemp, subset = Year &gt;= 1995,select = c(Year,
Annual))

I get error:

Error: unexpected ';' in "grecent <- subset(gtemp, subset = Year &gt;"

I've tried to replace ";" with several things, but it does not work at all.

Could anyone help me to solve this "problem"?

Best Regards,

Jackson Rodrigues

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Jun  4 13:08:39 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 4 Jun 2015 07:08:39 -0400
Subject: [R] Help to solve an Error
In-Reply-To: <CAPL76w8SQMv5=oXwZbspgf82noF3Ojv=G08foXei7fuAJbtEfQ@mail.gmail.com>
References: <CAPL76w8SQMv5=oXwZbspgf82noF3Ojv=G08foXei7fuAJbtEfQ@mail.gmail.com>
Message-ID: <CAM_vjuknnK3H5-D1Kb+Wur2zPSk2u=ecOnRm5_61e=A1ZUVnEA@mail.gmail.com>

The dangers of HTML: &gt; should be > a greater than symbol.

grecent <- subset(gtemp, subset = Year >= 1995,select = c(Year, Annual))

I've copied Gavin so he can decide whether to fix it.

Sarah

On Thursday, June 4, 2015, Jackson Rodrigues <jacksonmrodrigues at gmail.com>
wrote:

> Hi,
>
>
>
> I want to apply the codes of Gavin Simpson from
>
> http://www.fromthebottomoftheheap.net/2011/06/11/global-warming-since-1995-now-significant/
> on my own data to detect trends in a subset. However, when I run:
>
> > grecent <- subset(gtemp, subset = Year &gt;= 1995,select = c(Year,
> Annual))
>
> I get error:
>
> Error: unexpected ';' in "grecent <- subset(gtemp, subset = Year &gt;"
>
> I've tried to replace ";" with several things, but it does not work at all.
>
> Could anyone help me to solve this "problem"?
>
> Best Regards,
>
> Jackson Rodrigues
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Jun  4 13:22:37 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 4 Jun 2015 21:22:37 +1000
Subject: [R] Help to solve an Error
In-Reply-To: <CAPL76w8SQMv5=oXwZbspgf82noF3Ojv=G08foXei7fuAJbtEfQ@mail.gmail.com>
References: <CAPL76w8SQMv5=oXwZbspgf82noF3Ojv=G08foXei7fuAJbtEfQ@mail.gmail.com>
Message-ID: <CA+8X3fWW3yE6jC01zK=NF9qmJEB=ro5umK427iXeDJzTOgKTRg@mail.gmail.com>

Hi Jackson,
It looks like you have picked up the HTML code for the right angle
bracket. Try replacing this with a right angle bracket:

grecent<-subset(gtemp,subset = Year>=1995,select = c(Year,Annual))

Jim


On Thu, Jun 4, 2015 at 8:20 PM, Jackson Rodrigues
<jacksonmrodrigues at gmail.com> wrote:
> Hi,
>
>
>
> I want to apply the codes of Gavin Simpson from
> http://www.fromthebottomoftheheap.net/2011/06/11/global-warming-since-1995-now-significant/
> on my own data to detect trends in a subset. However, when I run:
>
>> grecent <- subset(gtemp, subset = Year &gt;= 1995,select = c(Year,
> Annual))
>
> I get error:
>
> Error: unexpected ';' in "grecent <- subset(gtemp, subset = Year &gt;"
>
> I've tried to replace ";" with several things, but it does not work at all.
>
> Could anyone help me to solve this "problem"?
>
> Best Regards,
>
> Jackson Rodrigues
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Thu Jun  4 13:37:05 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 4 Jun 2015 03:37:05 -0800
Subject: [R] Help to solve an Error
In-Reply-To: <CAPL76w8SQMv5=oXwZbspgf82noF3Ojv=G08foXei7fuAJbtEfQ@mail.gmail.com>
Message-ID: <C8EDC98080F.00000C23jrkrideau@inbox.com>

It seems to be some kind of "translation" error from R (or the text editior) to HMTL. That &gt does not work.

Try
 grecent <- subset(gtemp,  Year >= 1995,
                  select = c(Year, Annual))




John Kane
Kingston ON Canada


> -----Original Message-----
> From: jacksonmrodrigues at gmail.com
> Sent: Thu, 4 Jun 2015 12:20:58 +0200
> To: r-help at r-project.org
> Subject: [R] Help to solve an Error
> 
> Hi,
> 
> 
> 
> I want to apply the codes of Gavin Simpson from
> http://www.fromthebottomoftheheap.net/2011/06/11/global-warming-since-1995-now-significant/
> on my own data to detect trends in a subset. However, when I run:
> 
>> grecent <- subset(gtemp, subset = Year &gt;= 1995,select = c(Year,
> Annual))
> 
> I get error:
> 
> Error: unexpected ';' in "grecent <- subset(gtemp, subset = Year &gt;"
> 
> I've tried to replace ";" with several things, but it does not work at
> all.
> 
> Could anyone help me to solve this "problem"?
> 
> Best Regards,
> 
> Jackson Rodrigues
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jrkrideau at inbox.com  Thu Jun  4 13:38:49 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 4 Jun 2015 03:38:49 -0800
Subject: [R] Help to solve an Error
In-Reply-To: <CA+8X3fWW3yE6jC01zK=NF9qmJEB=ro5umK427iXeDJzTOgKTRg@mail.gmail.com>
References: <capl76w8sqmv5=oxwzbspgf82nof3ojv=g08foxei7fuajbtefq@mail.gmail.com>
Message-ID: <C8F1A9E676B.00000C26jrkrideau@inbox.com>

Hi Jim,
It is an problem in Gavin Simpson's code itself. Bad translation from R to HMTL it appears

John Kane
Kingston ON Canada


> -----Original Message-----
> From: drjimlemon at gmail.com
> Sent: Thu, 4 Jun 2015 21:22:37 +1000
> To: jacksonmrodrigues at gmail.com
> Subject: Re: [R] Help to solve an Error
> 
> Hi Jackson,
> It looks like you have picked up the HTML code for the right angle
> bracket. Try replacing this with a right angle bracket:
> 
> grecent<-subset(gtemp,subset = Year>=1995,select = c(Year,Annual))
> 
> Jim
> 
> 
> On Thu, Jun 4, 2015 at 8:20 PM, Jackson Rodrigues
> <jacksonmrodrigues at gmail.com> wrote:
>> Hi,
>> 
>> 
>> 
>> I want to apply the codes of Gavin Simpson from
>> http://www.fromthebottomoftheheap.net/2011/06/11/global-warming-since-1995-now-significant/
>> on my own data to detect trends in a subset. However, when I run:
>> 
>>> grecent <- subset(gtemp, subset = Year &gt;= 1995,select = c(Year,
>> Annual))
>> 
>> I get error:
>> 
>> Error: unexpected ';' in "grecent <- subset(gtemp, subset = Year &gt;"
>> 
>> I've tried to replace ";" with several things, but it does not work at
>> all.
>> 
>> Could anyone help me to solve this "problem"?
>> 
>> Best Regards,
>> 
>> Jackson Rodrigues
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From ligges at statistik.tu-dortmund.de  Thu Jun  4 14:29:11 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 04 Jun 2015 14:29:11 +0200
Subject: [R] SVM error
In-Reply-To: <CAGa91zhVyskaTeBcGSOTStoBQQRsDU+ap2d5a=Jqc6E5K0SARw@mail.gmail.com>
References: <CAGa91zhVyskaTeBcGSOTStoBQQRsDU+ap2d5a=Jqc6E5K0SARw@mail.gmail.com>
Message-ID: <55704497.4080603@statistik.tu-dortmund.de>



On 04.06.2015 08:06, Pijush Das wrote:
> Dear Sir,
>
> I have converted the data into numeric as the function read.excel read the
> data file as a character (as it was said by David Meyer, maintainer of the
> package e1071) and after that run the function svm. Then another error is
> found there. The detail description of the code and error is given below.
>
> Please check this code and try to solve the error.

Make that Tstatus eitehr a factor (which I believe you want to) or also 
numeric.

Best,
Uwe Ligges



>
>
>> library(e1071)
>> library("openxlsx")
>> List <- read.xlsx(file.choose(), sheet = 1,colNames = TRUE,rowNames = TRUE)
>> Data <- read.xlsx(file.choose(), sheet=1,colNames = TRUE,rowNames = TRUE)
>> status<-Data[1, ]
>> View(status)
>> FilterData <-Data[rownames(List), ]
>> View(FilterData)
>> TFData<-matrix( nrow=10, ncol=1630)
>> for(i in 1:1630){
> +   for(j in 1:10){
> +     a<-FilterData[i,j]
> +     TFData[j,i]<- as.numeric(a)
> +
> +   }
> + }
>> Tstatus <- t(status)
>> x<-TFData
>> is.numeric(x)
> [1] TRUE
>> y<-Tstatus
>> model <- svm( x, y)
> Error in svm.default(x, y) :
>    Need numeric dependent variable for regression.
>
> Please find the attached files, given below.
>
> Thank You
>
>
>
> With regards
> Pijush
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Wade.A.Wall at usace.army.mil  Thu Jun  4 15:47:04 2015
From: Wade.A.Wall at usace.army.mil (Wall, Wade A ERDC-RDE-CERL-IL)
Date: Thu, 4 Jun 2015 13:47:04 +0000
Subject: [R] Passing strings with spaces to Python using system2 splits
 string at whitespace
Message-ID: <C1524BE4BF45454293B8DF38FB9B5ECA35D0DE79@MS-EX1VKS.erdc.dren.mil>

Hi all,

I am trying to pass arguments to a python script using R, but am running into a problem with the string being split on the white spaces. Investigation on the python end suggests that it is happening upstream from python, because other shells such as bash have generated similar errors.

Here is example code.

R script:

test = "./Example.py"
string1 = "ThisWorks"
string2 = "This doesn't"

system2('python',args = c(as.character(test),as.character(string1))) ## This works
system2('python',args = c(as.character(test),as.character(string2))) ## This doesn't

Python script:

from sys import argv
script, string = argv
print script
print string

What happens is that string 2 is splits into "This" and "doesn't". Does anyone know how to resolve this issue? Of course I can remove the white spaces, but that may be somewhat inconvenient.

Thanks for any help.


Wade



	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Jun  4 15:57:37 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 4 Jun 2015 06:57:37 -0700
Subject: [R] reshape a data frame
In-Reply-To: <CAJQxKh1Z8HTO3XELBqJSRM8JoCUdAtC15PU8vddkXxqHytVu5w@mail.gmail.com>
References: <CA+d7zeTtCb2mHZ8f-_P97byOXr4yGD-vf02pOFutWNqhQey_vA@mail.gmail.com>
	<CAJQxKh1Z8HTO3XELBqJSRM8JoCUdAtC15PU8vddkXxqHytVu5w@mail.gmail.com>
Message-ID: <CAGxFJbSL+AcefkObn+0Rr5YqGTMbfURh+=70bvW2zMsT2_6kVw@mail.gmail.com>

Yes. This is basic stuff, and it seems unnecessary to run to packages for
it, Knowledge of base R should suffice. It would appear that the OP would
benefit by going through an R tutorial or two.

Slightly more economical and more general -- and trickier -- than explicit
concatenation, which could get to be a drag with a lot of columns, is this:

> colms <- match(c("bc1","bc2"),names(ex))
> exnew <- cbind(z[,-colms],bcx=unlist(ex[,colms]))

> exnew
     gIN group     bcx
bc11 A_1     A 1219.79
bc12 A_2     A 1486.84
bc13 A_3     A 1255.80
bc14 A_4     A  941.87
bc15 B_1     B  588.19
bc16 B_2     B  304.02
bc21 A_1     A  319.79
bc22 A_2     A  186.84
bc23 A_3     A  125.80
bc24 A_4     A   94.87
bc25 B_1     B 1008.19
bc26 B_2     B  314.02

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Wed, Jun 3, 2015 at 3:02 PM, javascriptart25 <javascriptart25 at gmail.com>
wrote:

> You can change ex <- data.frame("gIN" = gIN, "bc1" = bc1, "bc2"=bc2,
> "group" = group)
>
> to
>
> ex <- data.frame("gIN" = c(gIN,gIN), "bcX" = c(bc1,bc2), "group" =
> c(group,group))
>
>
> On Wed, Jun 3, 2015 at 2:27 PM, hedelhusk [via R] <
> ml-node+s789695n4708145h17 at n4.nabble.com> wrote:
>
> > Hello,
> >
> > I would like to ask for some advice in reformatting a data frame such as
> > the following one:
> >
> >
> > gIN <- c("A_1","A_2","A_3","A_4","B_1","B_2")
> > bc1 <- c(1219.79, 1486.84, 1255.80, 941.87, 588.19, 304.02)
> > bc2 <- c(319.79, 186.84, 125.80, 94.87, 1008.19, 314.02)
> > group <- c("A","A","A","A","B","B")
> >
> > ex <- data.frame("gIN" = gIN, "bc1" = bc1, "bc2"=bc2, "group" = group)
> >
> > > ex
> >   gIN     bc1     bc2 group
> > 1 A_1 1219.79  319.79     A
> > 2 A_2 1486.84  186.84     A
> > 3 A_3 1255.80  125.80     A
> > 4 A_4  941.87   94.87     A
> > 5 B_1  588.19 1008.19     B
> > 6 B_2  304.02  314.02     B
> >
> > I would like to reshape this data frame where all the columns that have
> > bc1, bc2,...etc are merged into a single column (call it bcX or
> something)
> > and the other variables are kept apart, the example solution follows:
> >
> >
> > > ex_reshaped
> >   gIN     bcX     group
> > 1 A_1 1219.79       A
> > 2 A_2 1486.84       A
> > 3 A_3 1255.80       A
> > 4 A_4  941.87        A
> > 5 B_1  588.19      B
> > 6 B_2  304.02       B
> > 7 A_1 319.79       A
> > 8 A_2 186.84       A
> > 9 A_3 125.80       A
> > 10 A_4 94.87       A
> > 11 B_1 1008.19   B
> > 12 B_2 314.02     B
> >
> > Does anyone know of a package, and/or command to accomplish this?
> >
> > Thank you
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > [hidden email] <http:///user/SendEmail.jtp?type=node&node=4708145&i=0>
> > mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> > ------------------------------
> >  If you reply to this email, your message will be added to the discussion
> > below:
> > http://r.789695.n4.nabble.com/reshape-a-data-frame-tp4708145.html
> >  To start a new topic under R help, email
> > ml-node+s789695n789696h98 at n4.nabble.com
> > To unsubscribe from R, click here
> > <
> http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=789695&code=amF2YXNjcmlwdGFydDI1QGdtYWlsLmNvbXw3ODk2OTV8NTgxOTIwNTYy
> >
> > .
> > NAML
> > <
> http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml
> >
> >
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/reshape-a-data-frame-tp4708145p4708146.html
> Sent from the R help mailing list archive at Nabble.com.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Thu Jun  4 16:10:17 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 04 Jun 2015 09:10:17 -0500
Subject: [R] Passing strings with spaces to Python using system2 splits
 string at whitespace
In-Reply-To: <C1524BE4BF45454293B8DF38FB9B5ECA35D0DE79@MS-EX1VKS.erdc.dren.mil>
References: <C1524BE4BF45454293B8DF38FB9B5ECA35D0DE79@MS-EX1VKS.erdc.dren.mil>
Message-ID: <8206EF3F-289D-46EF-9F07-4120B91BEC49@me.com>

On Jun 4, 2015, at 8:47 AM, Wall, Wade A ERDC-RDE-CERL-IL <Wade.A.Wall at usace.army.mil> wrote:
> 
> Hi all,
> 
> I am trying to pass arguments to a python script using R, but am running into a problem with the string being split on the white spaces. Investigation on the python end suggests that it is happening upstream from python, because other shells such as bash have generated similar errors.
> 
> Here is example code.
> 
> R script:
> 
> test = "./Example.py"
> string1 = "ThisWorks"
> string2 = "This doesn't"
> 
> system2('python',args = c(as.character(test),as.character(string1))) ## This works
> system2('python',args = c(as.character(test),as.character(string2))) ## This doesn't
> 
> Python script:
> 
> from sys import argv
> script, string = argv
> print script
> print string
> 
> What happens is that string 2 is splits into "This" and "doesn't". Does anyone know how to resolve this issue? Of course I can remove the white spaces, but that may be somewhat inconvenient.
> 
> Thanks for any help.
> 
> 
> Wade


See ?shQuote

> shQuote(string2)
[1] ?\"This doesn?t\""


Regards,

Marc Schwartz


From john.archie.mckown at gmail.com  Thu Jun  4 16:14:20 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 4 Jun 2015 09:14:20 -0500
Subject: [R] Passing strings with spaces to Python using system2 splits
 string at whitespace
In-Reply-To: <C1524BE4BF45454293B8DF38FB9B5ECA35D0DE79@MS-EX1VKS.erdc.dren.mil>
References: <C1524BE4BF45454293B8DF38FB9B5ECA35D0DE79@MS-EX1VKS.erdc.dren.mil>
Message-ID: <CAAJSdjg_Qe0S0w6cB5OA2-1WL1PcKBqs=wO2ScmAOKZtTwOCUA@mail.gmail.com>

On Thu, Jun 4, 2015 at 8:47 AM, Wall, Wade A ERDC-RDE-CERL-IL <
Wade.A.Wall at usace.army.mil> wrote:

> Hi all,
>
> I am trying to pass arguments to a python script using R, but am running
> into a problem with the string being split on the white spaces.
> Investigation on the python end suggests that it is happening upstream from
> python, because other shells such as bash have generated similar errors.
>
> Here is example code.
>
> R script:
>
> test = "./Example.py"
> string1 = "ThisWorks"
> string2 = "This doesn't"
>
> system2('python',args = c(as.character(test),as.character(string1))) ##
> This works
> system2('python',args = c(as.character(test),as.character(string2))) ##
> This doesn't
>

?use shQuote, like:

system2('python',args=shQuote(c(as.character(test),as.character(string2))))?


> Python script:
>
> from sys import argv
> script, string = argv
> print script
> print string
>
> What happens is that string 2 is splits into "This" and "doesn't". Does
> anyone know how to resolve this issue? Of course I can remove the white
> spaces, but that may be somewhat inconvenient.
>
> Thanks for any help.
>
> Wade
>
>         [[alternative HTML version deleted]]
>

?Please don't use HTML email. It often causes messages to be unreadable?,
although not in this particular case.



>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
My sister opened a computer store in Hawaii. She sells C shells down by the
seashore.

If someone tell you that nothing is impossible:
Ask him to dribble a football.

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Thu Jun  4 17:17:43 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 4 Jun 2015 11:17:43 -0400
Subject: [R] R convert pdf/png to html
In-Reply-To: <BLU437-SMTP142278EA2F6E4EF004D1D3B4B30@phx.gbl>
References: <SNT149-W72E78EE22C1C7CDAE7CD6EC2B40@phx.gbl>
	<BLU437-SMTP57CC431318B7FC3B3B8868B4B40@phx.gbl>
	<A6F4374B-8171-42B1-96F6-4B2A2E2818CC@utoronto.ca>
	<BLU436-SMTP2536073DF8683728EBE8301B4B40@phx.gbl>
	<D19481A1.12CE23%macqueen1@llnl.gov>
	<BLU436-SMTP197EBE3068F2ED9C29D9D86B4B30@phx.gbl>
	<BLU437-SMTP142278EA2F6E4EF004D1D3B4B30@phx.gbl>
Message-ID: <CBC7C8E2-3E50-4FE4-9EE4-0A261995227D@utoronto.ca>

I'm glad this works for you. Myself, I would use paste() to collect the output to a single variable, then use one instance of cat() to write the whole thing to file. This saves you retyping ... file="treemap.html", append=TRUE,sep='\n' ... more than once and prevents errors such as the one you encountered.

The principle is called "DRY" - Do not Repeat Yourself. Perhaps the simplest yet most powerful way to write better code.

All the best,
B.




On Jun 4, 2015, at 5:00 AM, valerio orfano <ingorfano at hotmail.com> wrote:

> I forgot to use fie= treemap.html :)
> 
> 
> On 04 Jun 2015, at 10:53, valerio orfano <ingorfano at hotmail.com> wrote:
> 
>> I have the following code:
>> 
>> setwd("C:/Users/Administrator/Desktop")
>> cat("<!DOCTYPE html>",file="treemap.html", append=TRUE,sep='\n')
>> cat("<html>",file="treemap.html", append=TRUE,sep='\n')
>> cat("<body>",file="treemap.html", append=TRUE,sep='\n')
>> cat("<h1>TreeMap</h1>",file="treemap.html", append=TRUE,sep='\n')
>> cat("<img src='Storage001.png'>","treemap.html", append=TRUE,sep='\n')
>> cat("</body>",file="treemap.html", append=TRUE,sep='\n')
>> cat("</html>",file="treemap.html", append=TRUE,sep='\n')
>> 
>> 
>> but this tag is not getting written in html file
>> cat("<img src='Storage001.png'>","treemap.html", append=TRUE,sep='\n?)
>> 
>> so i cannot display the img my html
>> 
>> belowe the resulting html
>> 
>> <!DOCTYPE html>
>> <html>
>> <body>
>> <h1>TreeMap</h1>
>> </body>
>> </html>
>> <!DOCTYPE html>
>> <html>
>> <body>
>> <h1>TreeMap</h1>
>> </body>
>> </html>
>> 
>> 
>> Any help
>> 
>> rgds valerio
>> On 03 Jun 2015, at 19:06, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>> 
>>> When it's as simple as in Boris's example, just use cat() statements.
>>> 
>>> Otherwise, go to CRAN, find the packages page ("Table of available
>>> packages, sorted by name"), and search for "html"
>>> 
>>> -Don
>>> 
>>> -- 
>>> Don MacQueen
>>> 
>>> Lawrence Livermore National Laboratory
>>> 7000 East Ave., L-627
>>> Livermore, CA 94550
>>> 925-423-1062
>>> 
>>> 
>>> 
>>> 
>>> 
>>> On 6/3/15, 9:38 AM, "valerio orfano" <ingorfano at hotmail.com> wrote:
>>> 
>>>> Hi Boris and thanx a lot
>>>> 
>>>> Which library should i be using to create html in R?
>>>> 
>>>> rgds valerio
>>>> On 03 Jun 2015, at 18:08, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>>> 
>>>>> ... as in: the png exists in a directory that is accessible to the
>>>>> server?
>>>>> 
>>>>> That would be as simple as creating a HTML document with the following
>>>>> contents:
>>>>> 
>>>>> <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
>>>>> "http://www.w3.org/TR/html4/strict.dtd">
>>>>> <html>
>>>>> <head><title="Image"></head>
>>>>> <body><img src="myPNGimage.png"></body>
>>>>> </html>
>>>>> 
>>>>> 
>>>>> B.
>>>>> 
>>>>> 
>>>>> On Jun 3, 2015, at 11:32 AM, valerio orfano <ingorfano at hotmail.com>
>>>>> wrote:
>>>>> 
>>>>>> Hi All
>>>>>> 
>>>>>> Is there any chance in R to convert a png and/or pdf file into an html?
>>>>>> Any example?
>>>>>> 
>>>>>> I?ve tried htmlize but doesn?t work out!
>>>>>> 
>>>>>> Rgds valerio
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
> 


From dcarlson at tamu.edu  Thu Jun  4 17:42:25 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 4 Jun 2015 15:42:25 +0000
Subject: [R] reshape a data frame
In-Reply-To: <CAGxFJbSL+AcefkObn+0Rr5YqGTMbfURh+=70bvW2zMsT2_6kVw@mail.gmail.com>
References: <CA+d7zeTtCb2mHZ8f-_P97byOXr4yGD-vf02pOFutWNqhQey_vA@mail.gmail.com>
	<CAJQxKh1Z8HTO3XELBqJSRM8JoCUdAtC15PU8vddkXxqHytVu5w@mail.gmail.com>
	<CAGxFJbSL+AcefkObn+0Rr5YqGTMbfURh+=70bvW2zMsT2_6kVw@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D69096A@mb02.ads.tamu.edu>

Here are two ways using stack() and reshape() from base R. The "col" variable indicates which column the bcX value came from. Both are easy to scale up to multiple columns:

> exnew1 <- data.frame(ex$gIN, stack(ex, 2:3), ex$group)
> names(exnew1) <- c("gIn", "bcX", "col", "group")
> exnew1
   gIn     bcX col group
1  A_1 1219.79 bc1     A
2  A_2 1486.84 bc1     A
3  A_3 1255.80 bc1     A
4  A_4  941.87 bc1     A
5  B_1  588.19 bc1     B
6  B_2  304.02 bc1     B
7  A_1  319.79 bc2     A
8  A_2  186.84 bc2     A
9  A_3  125.80 bc2     A
10 A_4   94.87 bc2     A
11 B_1 1008.19 bc2     B
12 B_2  314.02 bc2     B
> 
> exnew2 <- reshape(ex, varying=2:3, v.names="bcX", timevar="col", 
+ direction="long")
> rownames(exnew2) <- NULL
> exnew2 <- exnew2[,c(1, 4, 3, 2)]
> exnew2
   gIN     bcX col group
1  A_1 1219.79   1     A
2  A_2 1486.84   1     A
3  A_3 1255.80   1     A
4  A_4  941.87   1     A
5  B_1  588.19   1     B
6  B_2  304.02   1     B
7  A_1  319.79   2     A
8  A_2  186.84   2     A
9  A_3  125.80   2     A
10 A_4   94.87   2     A
11 B_1 1008.19   2     B
12 B_2  314.02   2     B

To get bc1, bc2 instead of 1, 2 in the col field:

> exnew2 <- reshape(ex, varying=2:3, v.names="bcX", timevar="col",
+	times=colnames(ex)[2:3], direction="long")

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Thursday, June 4, 2015 8:58 AM
To: javascriptart25
Cc: r-help at r-project.org
Subject: Re: [R] reshape a data frame

Yes. This is basic stuff, and it seems unnecessary to run to packages for
it, Knowledge of base R should suffice. It would appear that the OP would
benefit by going through an R tutorial or two.

Slightly more economical and more general -- and trickier -- than explicit
concatenation, which could get to be a drag with a lot of columns, is this:

> colms <- match(c("bc1","bc2"),names(ex))
> exnew <- cbind(z[,-colms],bcx=unlist(ex[,colms]))

> exnew
     gIN group     bcx
bc11 A_1     A 1219.79
bc12 A_2     A 1486.84
bc13 A_3     A 1255.80
bc14 A_4     A  941.87
bc15 B_1     B  588.19
bc16 B_2     B  304.02
bc21 A_1     A  319.79
bc22 A_2     A  186.84
bc23 A_3     A  125.80
bc24 A_4     A   94.87
bc25 B_1     B 1008.19
bc26 B_2     B  314.02

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Wed, Jun 3, 2015 at 3:02 PM, javascriptart25 <javascriptart25 at gmail.com>
wrote:

> You can change ex <- data.frame("gIN" = gIN, "bc1" = bc1, "bc2"=bc2,
> "group" = group)
>
> to
>
> ex <- data.frame("gIN" = c(gIN,gIN), "bcX" = c(bc1,bc2), "group" =
> c(group,group))
>
>
> On Wed, Jun 3, 2015 at 2:27 PM, hedelhusk [via R] <
> ml-node+s789695n4708145h17 at n4.nabble.com> wrote:
>
> > Hello,
> >
> > I would like to ask for some advice in reformatting a data frame such as
> > the following one:
> >
> >
> > gIN <- c("A_1","A_2","A_3","A_4","B_1","B_2")
> > bc1 <- c(1219.79, 1486.84, 1255.80, 941.87, 588.19, 304.02)
> > bc2 <- c(319.79, 186.84, 125.80, 94.87, 1008.19, 314.02)
> > group <- c("A","A","A","A","B","B")
> >
> > ex <- data.frame("gIN" = gIN, "bc1" = bc1, "bc2"=bc2, "group" = group)
> >
> > > ex
> >   gIN     bc1     bc2 group
> > 1 A_1 1219.79  319.79     A
> > 2 A_2 1486.84  186.84     A
> > 3 A_3 1255.80  125.80     A
> > 4 A_4  941.87   94.87     A
> > 5 B_1  588.19 1008.19     B
> > 6 B_2  304.02  314.02     B
> >
> > I would like to reshape this data frame where all the columns that have
> > bc1, bc2,...etc are merged into a single column (call it bcX or
> something)
> > and the other variables are kept apart, the example solution follows:
> >
> >
> > > ex_reshaped
> >   gIN     bcX     group
> > 1 A_1 1219.79       A
> > 2 A_2 1486.84       A
> > 3 A_3 1255.80       A
> > 4 A_4  941.87        A
> > 5 B_1  588.19      B
> > 6 B_2  304.02       B
> > 7 A_1 319.79       A
> > 8 A_2 186.84       A
> > 9 A_3 125.80       A
> > 10 A_4 94.87       A
> > 11 B_1 1008.19   B
> > 12 B_2 314.02     B
> >
> > Does anyone know of a package, and/or command to accomplish this?
> >
> > Thank you
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > [hidden email] <http:///user/SendEmail.jtp?type=node&node=4708145&i=0>
> > mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> > ------------------------------
> >  If you reply to this email, your message will be added to the discussion
> > below:
> > http://r.789695.n4.nabble.com/reshape-a-data-frame-tp4708145.html
> >  To start a new topic under R help, email
> > ml-node+s789695n789696h98 at n4.nabble.com
> > To unsubscribe from R, click here
> > <
> http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=789695&code=amF2YXNjcmlwdGFydDI1QGdtYWlsLmNvbXw3ODk2OTV8NTgxOTIwNTYy
> >
> > .
> > NAML
> > <
> http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml
> >
> >
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/reshape-a-data-frame-tp4708145p4708146.html
> Sent from the R help mailing list archive at Nabble.com.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From amelia_marsh08 at yahoo.com  Thu Jun  4 10:17:26 2015
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Thu, 4 Jun 2015 08:17:26 +0000 (UTC)
Subject: [R] Splitting and arranging in ascending order
In-Reply-To: <556F1B7F.7040200@sapo.pt>
References: <556F1B7F.7040200@sapo.pt>
Message-ID: <571476131.2878555.1433405847016.JavaMail.yahoo@mail.yahoo.com>

Dear Sir,

Thanks for your guidance and sinecerly apologize for late reply from my end.

Regards

Amelia



On Wednesday, 3 June 2015 10:38 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
Hello,

Try the following.


tmp <- strsplit(as.character(my_dat$instrument), "_")
tmp <- t(as.data.frame(tmp))
tmp <- data.frame(instrument = tmp[,1],  sr_no = as.integer(tmp[, 2]), 
my_dat$mtm_value)
result <- tmp[order(tmp[, 1], tmp[, 2]), ]
rm(tmp)
rownames(result) <- NULL
result


Hope this helps,

Rui Barradas


Em 03-06-2015 10:09, Amelia Marsh escreveu:
> Dear R forum
>
> I have a data (actually its a big data and I am only giving part of my interest) as
>
> my_dat = data.frame(instrument = c("EQ_0", "EQ_1", "EQ_10", "EQ_100", "EQ_2", "EQ_20", "IRS_0", "IRS_1", "IRS_10", "IRS_100", "IRS_2", "IRS_20"), mtm_value = c(23, 63, 8, 44, 68, 11, 83, 56, 73, 92, 14, 7))
>
>> my_dat
> instrument mtm_value
> 1        EQ_0     23
> 2        EQ_1     63
> 3       EQ_10    8
> 4      EQ_100   44
> 5        EQ_2     68
> 6       EQ_20    11
> 7       IRS_0    83
> 8       IRS_1    56
> 9      IRS_10   73
> 10    IRS_100        92
> 11      IRS_2   14
> 12     IRS_20   7
>
> I need to split the first column and arrange the output in the ascending order as shown below :
>
>    instrument sr_no   mtm_value
>
> 1          EQ          0      23
> 2          EQ          1      63
> 3          EQ          2      68
> 4          EQ         10       8
> 5          EQ         20      11
> 6          EQ        100      44
> 7         IRS         0      83
> 8         IRS         1      56
> 9         IRS         2      14
> 10        IRS       10      73
> 11        IRS       20       7
> 12        IRS      100      92
>
> I tried to use gsub, strsplit  but doesn't give me the required output.
>
> Kindly guide
>
> Regards
>
> Amelia
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

>


From ese.rober at gmail.com  Thu Jun  4 12:42:56 2015
From: ese.rober at gmail.com (Yo Gmail)
Date: Thu, 4 Jun 2015 12:42:56 +0200
Subject: [R] Error running help.search("keywords")
Message-ID: <C5B2AF98-7BBB-4BF8-928C-93CEE7D87799@gmail.com>

Hi,

When running help.search(?linear algebra?) or any other valid search keyword the following error is being returned:

Error in help(db[i, "topic"], package = db[i, "Package"], lib.loc = lib,  : 
  'topic' should be a name, length-one character vector or reserved word

I have not installed the optional packages neither Tcl/Tk nor Texinfo.

Any ideas what the error could be, what can I do to fix it?

My sessionInfo() is:

R version 3.2.0 (2015-04-16)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.10.3 (Yosemite)

locale:
[1] es_ES.UTF-8/es_ES.UTF-8/es_ES.UTF-8/C/es_ES.UTF-8/es_ES.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods  
[7] base     

loaded via a namespace (and not attached):
[1] tools_3.2.0


And the library(help=?utils?) summary is:

Package:       utils
Version:       3.2.0
Priority:      base
Title:         The R Utils Package
Author:        R Core Team and contributors worldwide
Maintainer:    R Core Team <R-core at r-project.org>
Description:   R utility functions.
License:       Part of R 3.2.0
Built:         R 3.2.0; x86_64-apple-darwin13.4.0; 2015-04-20
               18:46:49 UTC; unix



I have also posted the question in StackOverflow:

'help.search()' error returned
http://stackoverflow.com/q/30640018/2214951?sem=2 <http://stackoverflow.com/q/30640018/2214951?sem=2>
	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Thu Jun  4 17:30:16 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Thu, 4 Jun 2015 15:30:16 +0000
Subject: [R] cannot run package anymore
Message-ID: <AEB16B1613D44C4793A7E6B6986B7A12010050FBB3@EX10-LIVE-MBN2.ad.kent.ac.uk>

Hello,
I have been using the midasr package for several month. Now I want to start it again and it does not work anymore. I have installed the newest R version but I get following message when I am trying to run midasr

install.packages("midasr")
trying URL 'http://cran.rstudio.com/bin/windows/contrib/3.2/midasr_0.4.zip'
Content type 'application/zip' length 256503 bytes (250 KB)
downloaded 250 KB

package 'midasr' successfully unpacked and MD5 sums checked

The downloaded binary packages are in
        C:\Users\tr206\AppData\Local\Temp\RtmpAlypYT\downloaded_packages
> library(midasr)
Loading required package: sandwich
Error in get(Info[i, 1], envir = env) :
  cannot open file 'C:/Users/tr206/Documents/R/R-3.2.0/library/zoo/R/zoo.rdb': No such file or directory
Error: package 'sandwich' could not be loaded

I have no idea why this happens. I have not done anything before.

What can I do to solve this problem?

Thanks in advance for your support.
T. Riedle

	[[alternative HTML version deleted]]


From rshepard at appl-ecosys.com  Thu Jun  4 18:07:47 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 4 Jun 2015 09:07:47 -0700 (PDT)
Subject: [R] cannot run package anymore
In-Reply-To: <AEB16B1613D44C4793A7E6B6986B7A12010050FBB3@EX10-LIVE-MBN2.ad.kent.ac.uk>
References: <AEB16B1613D44C4793A7E6B6986B7A12010050FBB3@EX10-LIVE-MBN2.ad.kent.ac.uk>
Message-ID: <alpine.LNX.2.11.1506040905450.25861@localhost>

On Thu, 4 Jun 2015, T.Riedle wrote:

> Error: package 'sandwich' could not be loaded
> I have no idea why this happens. I have not done anything before.

   Er, the answer is shown.

> What can I do to solve this problem?

   Install the latest sandwich (hold the mayo), then re-install the package
requiring this dependency.

Rich


From akshay at cosmicad.com  Thu Jun  4 17:55:42 2015
From: akshay at cosmicad.com (AKSHAYLAMBA)
Date: Thu, 4 Jun 2015 08:55:42 -0700 (PDT)
Subject: [R] Decision tree in R using csv files
Message-ID: <1433433342737-4708193.post@n4.nabble.com>

Hi
Pls check the attachment.  I am having some error while making a decision
tree in R .   Pls help.



--
View this message in context: http://r.789695.n4.nabble.com/Decision-tree-in-R-using-csv-files-tp4708193.html
Sent from the R help mailing list archive at Nabble.com.


From curtis.degasperi at gmail.com  Thu Jun  4 18:31:13 2015
From: curtis.degasperi at gmail.com (Curtis DeGasperi)
Date: Thu, 4 Jun 2015 09:31:13 -0700
Subject: [R] web scraping image
Message-ID: <CAApc6sQp4F_M12QXxKPP_7yTtNZAzyk2rYRm0=O1Hh_M4dxJ=w@mail.gmail.com>

I'm working on a script that downloads data from the USGS NWIS server.
dataRetrieval makes it easy to quickly get the data in a neat tabular
format, but I was also interested in getting the tabular text files -
also fairly easy for me using download.file.

However, I'm not skilled enough to work out how to download the nice
graphic files that can be produced dynamically from the USGS NWIS
server (for example:
http://nwis.waterdata.usgs.gov/nwis/peak?site_no=12144500&agency_cd=USGS&format=img)

My question is how do I get the image from this web page and save it
to a local directory? scrapeR returns the information from the page
and I suspect this is a possible solution path, but I don't know what
the next step is.

My code provided below works from a list I've created of USGS flow
gauging stations.

Curtis

## Code to process USGS daily flow data for high and low flow analysis
## Need to start with list of gauge ids to process
## Can't figure out how to automate download of images

require(dataRetrieval)
require(data.table)
require(scrapeR)

df <- read.csv("usgs_stations.csv", header=TRUE)

lstas <-length(df$siteno) #length of locator list

print(paste('Processsing...',df$name[1],' ',df$siteno[1], sep = ""))

datall <-  readNWISpeak(df$siteno[1])

for (a in 2:lstas) {
  # Print station being processed
  print(paste('Processsing...',df$name[a],' ',df$siteno[a], sep = ""))

  dat<-  readNWISpeak(df$siteno[a])

  datall <- rbind(datall,dat)

}

write.csv(datall, file = "usgs_peaks.csv")

# Retrieve ascii text files and graphics

for (a in 1:lstas) {

  print(paste('Processsing...',df$name[1],' ',df$siteno[1], sep = ""))

  graphic.url <-
paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=',df$siteno[a],'&agency_cd=USGS&format=img',
sep = "")
  peakfq.url <-
paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=',df$siteno[a],'&agency_cd=USGS&format=hn2',
sep = "")
  tab.url  <- paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=',df$siteno[a],'&agency_cd=USGS&format=rdb',
sep = "")

  graphic.fn <- paste('graphic_',df$siteno[a],'.gif', sep = "")
  peakfq.fn <- paste('peakfq_',df$siteno[a],'.txt', sep = "")
  tab.fn  <- paste('tab_',df$siteno[a],'.txt', sep = "")

  download.file(graphic.url,graphic.fn,mode='wb') # This apparently
doesn't work - file is empty
  download.file(peakfq.url,peakfq.fn)
  download.file(tab.url,tab.fn)
}

# scrapeR
pageSource<-scrape(url="http://nwis.waterdata.usgs.gov/nwis/peak?site_no=12144500&agency_cd=USGS&format=img",headers=TRUE,
parse=FALSE)
page<-scrape(object="pageSource")


From murdoch.duncan at gmail.com  Thu Jun  4 18:44:18 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 04 Jun 2015 12:44:18 -0400
Subject: [R] Error running help.search("keywords")
In-Reply-To: <C5B2AF98-7BBB-4BF8-928C-93CEE7D87799@gmail.com>
References: <C5B2AF98-7BBB-4BF8-928C-93CEE7D87799@gmail.com>
Message-ID: <55708062.4000800@gmail.com>

On 04/06/2015 6:42 AM, Yo Gmail wrote:
> Hi,
>
> When running help.search(?linear algebra?) or any other valid search keyword the following error is being returned:
>
> Error in help(db[i, "topic"], package = db[i, "Package"], lib.loc = lib,  :
>    'topic' should be a name, length-one character vector or reserved word
>
> I have not installed the optional packages neither Tcl/Tk nor Texinfo.
>
> Any ideas what the error could be, what can I do to fix it?

It's probably just your email, but R won't understand "smart quotes" 
like you use above.  But if you tried that, you'd get a different error:

 > help.search(?linear algebra?)
Error: unexpected input in "help.search(?"

Assuming what you really typed was using plain ASCII quotes, please try 
a recent R-patched version.  The search

help.search("linear algebra")

works fine for me there.

Duncan Murdoch

>
> My sessionInfo() is:
>
> R version 3.2.0 (2015-04-16)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.10.3 (Yosemite)
>
> locale:
> [1] es_ES.UTF-8/es_ES.UTF-8/es_ES.UTF-8/C/es_ES.UTF-8/es_ES.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> [7] base
>
> loaded via a namespace (and not attached):
> [1] tools_3.2.0
>
>
> And the library(help=?utils?) summary is:
>
> Package:       utils
> Version:       3.2.0
> Priority:      base
> Title:         The R Utils Package
> Author:        R Core Team and contributors worldwide
> Maintainer:    R Core Team <R-core at r-project.org>
> Description:   R utility functions.
> License:       Part of R 3.2.0
> Built:         R 3.2.0; x86_64-apple-darwin13.4.0; 2015-04-20
>                 18:46:49 UTC; unix
>
>
>
> I have also posted the question in StackOverflow:
>
> 'help.search()' error returned
> http://stackoverflow.com/q/30640018/2214951?sem=2 <http://stackoverflow.com/q/30640018/2214951?sem=2>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cgenolin at u-paris10.fr  Thu Jun  4 19:08:29 2015
From: cgenolin at u-paris10.fr (cgenolin)
Date: Thu, 4 Jun 2015 10:08:29 -0700 (PDT)
Subject: [R] is.na for S4 object
Message-ID: <1433437709373-4708201.post@n4.nabble.com>

Hi the list,

I have a variable y that is either NA or some S4 object. I would like to
know in which case I am, but it seems taht is.na does not work with S4
object, I get a warnings:

--- 8< ------------
setClass("myClass",slots=c(x="numeric"))
if(runif(1)>0.5){a <- new("myClass")}else{a <- NA}
is.na(a)
--- 8< ------------

Any solution?
Thanks 

Christophe




--
View this message in context: http://r.789695.n4.nabble.com/is-na-for-S4-object-tp4708201.html
Sent from the R help mailing list archive at Nabble.com.


From mtmorgan at fredhutch.org  Thu Jun  4 19:33:37 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Thu, 04 Jun 2015 10:33:37 -0700
Subject: [R] is.na for S4 object
In-Reply-To: <1433437709373-4708201.post@n4.nabble.com>
References: <1433437709373-4708201.post@n4.nabble.com>
Message-ID: <55708BF1.2010801@fredhutch.org>

On 06/04/2015 10:08 AM, cgenolin wrote:
> Hi the list,
>
> I have a variable y that is either NA or some S4 object. I would like to
> know in which case I am, but it seems taht is.na does not work with S4
> object, I get a warnings:
>
> --- 8< ------------
> setClass("myClass",slots=c(x="numeric"))
> if(runif(1)>0.5){a <- new("myClass")}else{a <- NA}
> is.na(a)
> --- 8< ------------
>
> Any solution?

getGeneric("is.na")

shows that it's an S4 generic, so implement a method

setMethod("is.na", "myClass", function(x) FALSE)

Martin

> Thanks
>
> Christophe
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/is-na-for-S4-object-tp4708201.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From therneau at mayo.edu  Thu Jun  4 19:56:02 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 04 Jun 2015 12:56:02 -0500
Subject: [R] Unwanted unicode
Message-ID: <2f3a88$p9clj@ironport10.mayo.edu>

I'm checking the survival package and get the following error. How do I find the offending 
line?  (There are a LOT of files in the man directory.)

Terry T.

------------------

* checking PDF version of manual ... WARNING
LaTeX errors when creating PDF version.
This typically indicates Rd problems.
LaTeX errors found:
! Package inputenc Error: Unicode char \u8:? not set up for use with LaTeX.


From istazahn at gmail.com  Thu Jun  4 21:39:22 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 4 Jun 2015 15:39:22 -0400
Subject: [R] Unwanted unicode
In-Reply-To: <2f3a88$p9clj@ironport10.mayo.edu>
References: <2f3a88$p9clj@ironport10.mayo.edu>
Message-ID: <CA+vqiLE1bvO8KqPR1iRoZ99+FBLonViaFNdSUp0p=k8FQuoFpA@mail.gmail.com>

If you use emacs you can use 'M-x find-grep-dired', select the
directory, and search for '?' (maybe won't work on Windows, I'm not
sure). If you are on Linux (OS X?) you can run the equivalent

find . \( -type f -exec grep -q -e \? \{\} \; \) -ls

in a terminal.

Best,
Ista

On Thu, Jun 4, 2015 at 1:56 PM, Therneau, Terry M., Ph.D.
<therneau at mayo.edu> wrote:
> I'm checking the survival package and get the following error. How do I find
> the offending line?  (There are a LOT of files in the man directory.)
>
> Terry T.
>
> ------------------
>
> * checking PDF version of manual ... WARNING
> LaTeX errors when creating PDF version.
> This typically indicates Rd problems.
> LaTeX errors found:
> ! Package inputenc Error: Unicode char \u8:? not set up for use with LaTeX.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Thu Jun  4 22:00:55 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 04 Jun 2015 15:00:55 -0500
Subject: [R] Unwanted unicode
In-Reply-To: <2f3a88$p9clj@ironport10.mayo.edu>
References: <2f3a88$p9clj@ironport10.mayo.edu>
Message-ID: <B34BF897-3048-4929-A6E9-6EC17B10EB89@me.com>

On Jun 4, 2015, at 12:56 PM, Therneau, Terry M., Ph.D. <therneau at mayo.edu> wrote:
> 
> I'm checking the survival package and get the following error. How do I find the offending line?  (There are a LOT of files in the man directory.)
> 
> Terry T.
> 
> ------------------
> 
> * checking PDF version of manual ... WARNING
> LaTeX errors when creating PDF version.
> This typically indicates Rd problems.
> LaTeX errors found:
> ! Package inputenc Error: Unicode char \u8:? not set up for use with LaTeX.


Terry, 

One possible option:

  require(tools)

  sapply(list.files(path = ?Path/To/Your/RD/Files", pattern = ".Rd"), 
         showNonASCIIfile)

See ?list.files and ?showNonASCIIfile

Regards,

Marc Schwartz


From matt at considine.net  Thu Jun  4 22:16:04 2015
From: matt at considine.net (matt at considine.net)
Date: Thu, 04 Jun 2015 15:16:04 -0500
Subject: [R] Reproducing a 3d yield curve plot from New York Times
Message-ID: <498ab7ebd8c09e87361c575b1c02e822@considine.net>

I am trying to closely reproduce the 3d yield curve chart that showed up 
in the New York Times in March, as seen here
   
http://www.nytimes.com/interactive/2015/03/19/upshot/3d-yield-curve-economic-growth.html?ref=economy&abt=0002&abg=0

Working with chartSeries3d0 gets me close, but not quite there :

library(xts)

chartSeries3d0 <-
   function(Z, theta=30, r=10, col=c("yellow","red"), smoother=1, 
border=NA, shade=.3,
            phi=10,scale=FALSE,expand=1,lphi=20,box=FALSE,  #mattc
            ltheta=20,  x.cex=.75, srt=0,...) {
     cnames <- colnames(Z)
     yred <- colorRampPalette(col)
     par(mar=c(3,1,1,1))
     time.axis <- axTicksByTime(Z,ticks.on="years",k=5)
     if(smoother > 1)
       Z <- as.xts(t(apply(Z,1,function(x) spline(as.vector(coredata(x)), 
n=smoother*length(x))$y)))
     pm <- persp(z=Z,
                 x=(1:NROW(Z))/length(time.axis),
                 y=(1:NCOL(Z))/smoother,
                 shade=shade, ltheta=ltheta,
                 r=r,
                 theta=theta,
                 phi=phi,expand=expand, #mattc
                 
col=rep(rep(yred(NCOL(Z)/smoother),each=smoother),each=(NROW(Z)-1)),
                 scale=scale, border=border,box=box,...)

     x_axis <- seq(1, NROW(Z), 
length.out=length(time.axis))/length(time.axis)
     y_axis <- seq(1, NCOL(Z), length.out=NCOL(Z)/smoother)/smoother

     # x-axis
     xy0 <- trans3d(x_axis,y_axis[1],0,pm)
     xy1 <- trans3d(x_axis,y_axis[1]-0.3,0,pm)
     lines(trans3d(x_axis,y_axis[1],0,pm),col="#555555")
     segments(xy0$x,xy0$y,xy1$x,xy1$y, col="#555555")
     #text(xy1$x, xy1$y, 
labels=as.character(format(index(Z)[x_axis*10],"%m/%d/%y")), pos=1, 
offset=.25,cex=x.cex, srt=srt)
     text(xy1$x, xy1$y, labels=names(time.axis), pos=1, 
offset=.25,cex=x.cex, srt=srt)

     # y-axis
     xy0 <- trans3d(x_axis[length(x_axis)], y_axis, 0, pm)
     xy1 <- trans3d(x_axis[length(x_axis)]+.3, y_axis, 0, pm)
     yz0 <- trans3d(x_axis[length(x_axis)], y_axis, 
coredata(Z)[NROW(Z),seq(1,NCOL(Z),by=smoother)], pm) # vertical y
     lines(trans3d(x_axis[length(x_axis)], y_axis, 0, pm),col="#555555")
     segments(xy0$x,xy0$y,xy1$x,xy1$y,col="#555555")
     text(xy1$x, xy1$y, labels=cnames, pos=4, offset=.5,cex=x.cex)

    # segments(xy0$x,xy0$y,yz0$x,yz0$y, col="#555555") # y-axis vertical 
lines

     # z-axis
     z_axis <- seq(trunc(min(Z,na.rm=TRUE)), round(max(Z, na.rm=TRUE)))
     xy0 <- trans3d(x_axis[length(x_axis)], y_axis[length(y_axis)], 
z_axis, pm)
     xy1 <- trans3d(x_axis[length(x_axis)]+0.3, y_axis[length(y_axis)], 
z_axis, pm)
     lines(trans3d(x_axis[length(x_axis)], y_axis[length(y_axis)], 
z_axis, pm))
     segments(xy0$x,xy0$y,xy1$x,xy1$y)
     text(xy1$x, xy1$y, labels=paste(z_axis,'%',sep=''), pos=1, 
offset=-.5,cex=x.cex)

     title("Yield Curve") #mattc
     par(mar=c(5.1,4.1,4.1,3.1))
     return(invisible(pm))
   }

term.structure <- structure(c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3.67, 3.4,
2.28, 2.15, 1.87, 1.68, 1.69, 1.76, 1.76, 1.77, 1.72, 1.69, 1.73,
1.7, 1.6, 1.48, 1.25, 1.2, 1.17, 1.21, 1.16, 1.13, 1.16, 0.81,
0.91, 0.98, 0.87, 0.96, 0.96, 0.9, 0.85, 0.95, 0.96, 0.83, 0.94,
1.17, 1.27, 1.45, 1.47, 1.73, 2.07, 1.89, 2.06, 2.51, 2.63, 2.7,
2.8, 2.99, 3.25, 3.41, 3.15, 3.77, 4, 4.01, 4.37, 4.47, 4.65,
4.6, 4.75, 4.54, 5.02, 5.12, 4.6, 5.18, 5.22, 4.75, 5, 5.24,
5.07, 4.8, 4.78, 4.28, 5.13, 4.02, 3.43, 4.01, 3.63, 2.76, 1.64,
2.07, 1.22, 1.17, 1.98, 1.6, 1.55, 1.63, 1.02, 0.12, 0.02, 0.11,
0.15, 0.16, 0.17, 0.04, 0.14, 0.17, 0.14, 0.11, 0.06, 0.01, 0.08,
0.04, 0.02, 0.09, 0.15, 0.14, 0.15, 0.17, 0.14, 0.16, 0.14, 0.14,
0.18, 0.07, 0.15, 0.13, 0.05, 0.02, 0.04, 0.01, 0.16, 0.01, 0.02,
0.02, 0.02, 0.01, 0.04, 0.08, 0.05, 0.07, 0.03, 0.04, 0.07, 0.09,
0.06, 0.09, 0.11, 0.02, 0.04, 0.07, 0.04, 0.03, 0.03, 0.02, 0.03,
0.02, 0.03, 0.03, 0.05, 0.01, 0.03, 0.04, 0.03, 0.02, 0.05, 0.02,
0.01, 0.02, 0.02, 0.01, 0.04, 0.03, 0.02, 8, 8.04, 8.07, 8.07,
8.01, 8, 7.74, 7.63, 7.37, 7.34, 7.24, 6.63, 6.37, 6.22, 5.92,
5.68, 5.71, 5.71, 5.7, 5.49, 5.26, 4.96, 4.47, 3.96, 3.94, 4.03,
4.15, 3.79, 3.79, 3.65, 3.25, 3.23, 2.75, 3.03, 3.38, 3.15, 2.96,
3.01, 2.95, 2.97, 3.13, 3.1, 3.1, 3.08, 2.98, 3.1, 3.21, 3.07,
3.05, 3.47, 3.56, 3.97, 4.31, 4.26, 4.39, 4.68, 4.8, 5.2, 5.72,
5.68, 6, 5.94, 5.88, 5.87, 5.81, 5.6, 5.6, 5.45, 5.4, 5.48, 5.48,
5.1, 5.05, 5.02, 5.13, 5.14, 5.18, 5.18, 5.32, 5.29, 5.14, 5.17,
5.13, 5.21, 5.15, 5.22, 5.35, 5.28, 4.96, 5.25, 5.25, 5.24, 5.06,
5.21, 5.22, 5.36, 5.19, 5.32, 5.16, 5, 5.03, 5.1, 5.1, 4.96,
4.37, 4.33, 4.57, 4.48, 4.48, 4.66, 4.49, 4.55, 4.66, 4.78, 4.75,
4.98, 4.88, 5.12, 5.3, 5.33, 5.76, 5.78, 5.88, 5.82, 5.63, 5.88,
6.27, 6.31, 6.23, 6.38, 6.21, 5.89, 4.99, 4.85, 4.3, 3.95, 3.63,
3.65, 3.54, 3.37, 2.4, 2.05, 1.78, 1.74, 1.76, 1.79, 1.79, 1.77,
1.74, 1.7, 1.71, 1.69, 1.57, 1.44, 1.22, 1.22, 1.18, 1.2, 1.14,
1.13, 1.11, 0.9, 0.96, 0.98, 0.95, 0.96, 0.93, 0.95, 0.92, 0.96,
0.95, 0.98, 1.08, 1.33, 1.45, 1.59, 1.71, 1.91, 2.23, 2.22, 2.51,
2.76, 2.79, 2.9, 2.99, 3.13, 3.42, 3.52, 3.55, 3.98, 3.95, 4.08,
4.47, 4.62, 4.63, 4.77, 4.86, 5.01, 5.1, 5.05, 4.89, 5.08, 5.03,
5.02, 5.12, 5.16, 5.04, 4.91, 4.73, 4.82, 4.96, 4.01, 3.82, 3.94,
3.15, 3.36, 1.96, 1.85, 1.38, 1.43, 1.89, 1.9, 1.68, 1.72, 0.92,
0.46, 0.01, 0.11, 0.24, 0.26, 0.21, 0.14, 0.14, 0.19, 0.18, 0.15,
0.14, 0.05, 0.06, 0.06, 0.08, 0.13, 0.16, 0.16, 0.16, 0.18, 0.15,
0.14, 0.16, 0.12, 0.17, 0.12, 0.15, 0.15, 0.09, 0.04, 0.06, 0.03,
0.1, 0.02, 0.02, 0.01, 0.01, 0.02, 0.06, 0.08, 0.07, 0.1, 0.07,
0.09, 0.11, 0.09, 0.1, 0.11, 0.08, 0.05, 0.07, 0.11, 0.07, 0.05,
0.04, 0.04, 0.04, 0.03, 0.02, 0.04, 0.06, 0.07, 0.02, 0.05, 0.05,
0.03, 0.04, 0.04, 0.03, 0.03, 0.02, 0.01, 0.02, 0.04, 0.02, 8.13,
8.14, 8.24, 8.44, 8.12, 8.02, 7.72, 7.74, 7.54, 7.46, 7.36, 6.73,
6.49, 6.32, 6.05, 5.83, 5.94, 5.95, 5.93, 5.6, 5.34, 5.03, 4.57,
4, 4.07, 4.14, 4.32, 3.97, 3.96, 3.77, 3.38, 3.35, 2.92, 3.29,
3.58, 3.38, 3.16, 3.14, 3.09, 3.07, 3.32, 3.22, 3.28, 3.21, 3.13,
3.28, 3.4, 3.3, 3.25, 3.72, 3.92, 4.45, 4.87, 4.83, 4.87, 5.03,
5.43, 5.72, 6.22, 6.51, 6.4, 6.19, 6.13, 6.08, 5.83, 5.59, 5.63,
5.53, 5.57, 5.55, 5.46, 5.17, 4.97, 5.05, 5.2, 5.3, 5.36, 5.37,
5.47, 5.49, 5.37, 5.3, 5.25, 5.33, 5.28, 5.39, 5.55, 5.53, 5.46,
5.34, 5.33, 5.39, 5.28, 5.32, 5.43, 5.45, 5.24, 5.33, 5.27, 5.24,
5.33, 5.24, 5.21, 5.03, 4.49, 4.36, 4.58, 4.55, 4.47, 4.7, 4.53,
4.66, 4.83, 5.04, 4.85, 5.21, 4.99, 5.28, 5.57, 5.74, 5.97, 6.02,
6.15, 6.12, 6.35, 6.23, 6.42, 6.38, 6.28, 6.36, 6.18, 5.7, 4.83,
4.7, 4.09, 3.97, 3.59, 3.63, 3.47, 3.31, 2.36, 1.95, 1.79, 1.83,
1.89, 1.87, 2.12, 1.91, 1.91, 1.75, 1.7, 1.67, 1.51, 1.43, 1.3,
1.23, 1.19, 1.19, 1.13, 1.15, 1.09, 0.98, 1.02, 1.06, 1.01, 1.04,
1.04, 1.02, 1.01, 1.01, 1.01, 1.17, 1.39, 1.68, 1.77, 1.79, 2,
2.13, 2.44, 2.59, 2.79, 3.01, 3.13, 3.17, 3.18, 3.34, 3.69, 3.74,
3.93, 4.26, 4.31, 4.37, 4.59, 4.74, 4.81, 4.91, 5.08, 5.24, 5.18,
5.11, 5.02, 5.13, 5.1, 5.09, 5.16, 5.12, 5.06, 5.03, 4.96, 4.93,
4.99, 4.21, 4.09, 4.09, 3.37, 3.49, 2.07, 1.83, 1.51, 1.64, 2.01,
2.17, 1.89, 1.97, 1.6, 0.94, 0.44, 0.27, 0.36, 0.45, 0.43, 0.29,
0.3, 0.35, 0.26, 0.24, 0.18, 0.16, 0.15, 0.2, 0.15, 0.19, 0.24,
0.25, 0.22, 0.22, 0.2, 0.19, 0.19, 0.17, 0.21, 0.19, 0.17, 0.18,
0.17, 0.11, 0.12, 0.1, 0.16, 0.05, 0.06, 0.06, 0.06, 0.06, 0.08,
0.13, 0.15, 0.15, 0.14, 0.16, 0.14, 0.14, 0.14, 0.16, 0.13, 0.11,
0.12, 0.13, 0.11, 0.09, 0.07, 0.1, 0.08, 0.05, 0.04, 0.08, 0.11,
0.1, 0.06, 0.08, 0.07, 0.05, 0.06, 0.07, 0.05, 0.05, 0.03, 0.05,
0.07, 0.12, 0.08, 8.08, 8.12, 8.35, 8.58, 8.22, 8.05, 7.72, 7.76,
7.69, 7.43, 7.31, 6.82, 6.51, 6.41, 6.28, 6.06, 6.16, 6.32, 6.19,
5.72, 5.42, 5.1, 4.69, 4.12, 4.23, 4.35, 4.54, 4.4, 4.24, 4.05,
3.62, 3.47, 3.06, 3.54, 3.83, 3.61, 3.39, 3.32, 3.32, 3.26, 3.62,
3.45, 3.53, 3.38, 3.39, 3.47, 3.65, 3.63, 3.53, 4.03, 4.5, 5.07,
5.38, 5.51, 5.37, 5.56, 5.96, 6.18, 6.91, 7.2, 6.84, 6.44, 6.49,
6.32, 5.8, 5.65, 5.67, 5.65, 5.65, 5.55, 5.36, 5.18, 4.9, 5.23,
5.41, 5.62, 5.77, 5.7, 5.85, 5.91, 5.71, 5.44, 5.38, 5.51, 5.58,
5.67, 6.02, 5.9, 5.78, 5.67, 5.45, 5.59, 5.47, 5.36, 5.52, 5.51,
5.24, 5.41, 5.41, 5.4, 5.42, 5.38, 5.38, 4.95, 4.41, 4.18, 4.53,
4.53, 4.51, 4.88, 4.72, 4.78, 4.97, 5.07, 5.13, 5.3, 5.22, 5.43,
5.7, 5.98, 6.3, 6.2, 6.28, 6.24, 6.37, 6.08, 6.07, 6.22, 6.07,
6.12, 5.92, 5.32, 4.6, 4.47, 4.09, 3.94, 3.63, 3.72, 3.53, 3.41,
2.49, 2.07, 2.06, 2.17, 2.29, 2.25, 2.7, 2.35, 2.34, 2.06, 1.8,
1.74, 1.53, 1.46, 1.56, 1.32, 1.31, 1.24, 1.19, 1.22, 1.13, 1.09,
1.28, 1.35, 1.15, 1.31, 1.39, 1.26, 1.28, 1.21, 1.2, 1.55, 1.83,
2.09, 2.13, 1.99, 2.21, 2.28, 2.63, 2.75, 2.96, 3.2, 3.35, 3.33,
3.32, 3.45, 3.8, 3.77, 4.01, 4.31, 4.34, 4.38, 4.58, 4.73, 4.82,
4.9, 5.07, 5.21, 5.11, 5.01, 4.91, 4.99, 4.94, 5, 5.09, 4.96,
4.9, 4.89, 4.95, 4.91, 4.85, 4.19, 4.05, 4.04, 3.26, 3.34, 2.11,
1.77, 1.55, 1.85, 2.22, 2.36, 2.27, 2.17, 1.78, 1.34, 0.9, 0.37,
0.51, 0.72, 0.57, 0.49, 0.47, 0.56, 0.48, 0.43, 0.4, 0.37, 0.27,
0.47, 0.3, 0.32, 0.41, 0.41, 0.34, 0.32, 0.29, 0.25, 0.27, 0.22,
0.27, 0.29, 0.26, 0.25, 0.3, 0.22, 0.18, 0.19, 0.2, 0.1, 0.13,
0.12, 0.12, 0.12, 0.13, 0.18, 0.19, 0.2, 0.18, 0.21, 0.16, 0.16,
0.17, 0.18, 0.18, 0.16, 0.15, 0.17, 0.14, 0.11, 0.14, 0.15, 0.11,
0.13, 0.1, 0.1, 0.13, 0.13, 0.1, 0.12, 0.13, 0.11, 0.1, 0.11,
0.12, 0.09, 0.13, 0.11, 0.13, 0.25, 0.17, 8.28, 8.43, 8.64, 8.96,
8.5, 8.24, 7.91, 8.07, 8.02, 7.77, 7.53, 7.15, 7.05, 7.04, 7.02,
6.8, 6.68, 6.9, 6.81, 6.36, 5.99, 5.7, 5.38, 4.77, 5.11, 5.27,
5.6, 5.46, 5.19, 4.83, 4.42, 4.15, 3.8, 4.4, 4.79, 4.56, 4.2,
3.92, 3.96, 3.83, 4.24, 4.03, 4.13, 3.88, 3.89, 3.99, 4.22, 4.25,
4.12, 4.67, 5.21, 5.73, 6.01, 6.19, 5.99, 6.17, 6.62, 6.84, 7.4,
7.69, 7.26, 6.79, 6.8, 6.6, 5.89, 5.79, 5.88, 5.85, 5.83, 5.61,
5.36, 5.18, 4.93, 5.44, 5.79, 6.03, 6.27, 6.11, 6.22, 6.34, 6.1,
5.77, 5.59, 5.88, 5.94, 6.09, 6.45, 6.29, 6.22, 6.08, 5.74, 5.97,
5.8, 5.63, 5.76, 5.66, 5.32, 5.55, 5.6, 5.59, 5.53, 5.49, 5.49,
4.91, 4.3, 4.12, 4.54, 4.54, 4.58, 5.13, 4.99, 5.08, 5.42, 5.53,
5.63, 5.73, 5.63, 5.79, 6.01, 6.24, 6.61, 6.53, 6.5, 6.68, 6.69,
6.38, 6.3, 6.18, 5.98, 5.94, 5.61, 5.11, 4.62, 4.41, 4.18, 4.3,
4.22, 4.25, 3.79, 3.64, 2.86, 2.44, 2.84, 3.07, 3.16, 3.06, 3.72,
3.24, 3.22, 2.9, 2.23, 2.14, 1.72, 1.68, 2.08, 1.61, 1.72, 1.53,
1.51, 1.51, 1.33, 1.32, 1.8, 1.95, 1.5, 1.85, 2.06, 1.84, 1.84,
1.66, 1.6, 2.31, 2.54, 2.7, 2.68, 2.41, 2.63, 2.56, 3.02, 3.08,
3.29, 3.59, 3.8, 3.66, 3.6, 3.66, 4.02, 3.84, 4.18, 4.4, 4.42,
4.41, 4.54, 4.69, 4.82, 4.87, 5.04, 5.16, 4.97, 4.79, 4.71, 4.71,
4.62, 4.82, 4.94, 4.65, 4.58, 4.6, 4.92, 4.87, 4.56, 4.15, 3.97,
3.94, 3.04, 3.05, 2.17, 1.65, 1.62, 2.29, 2.66, 2.63, 2.52, 2.36,
2, 1.56, 1, 0.76, 0.94, 1, 0.81, 0.91, 0.92, 1.11, 1.13, 0.97,
0.95, 0.9, 0.67, 1.14, 0.82, 0.81, 1.02, 0.97, 0.76, 0.61, 0.55,
0.47, 0.42, 0.34, 0.45, 0.61, 0.58, 0.69, 0.8, 0.61, 0.45, 0.45,
0.36, 0.2, 0.25, 0.25, 0.25, 0.25, 0.22, 0.3, 0.33, 0.27, 0.27,
0.33, 0.23, 0.22, 0.23, 0.3, 0.25, 0.25, 0.27, 0.25, 0.25, 0.22,
0.3, 0.36, 0.31, 0.39, 0.33, 0.31, 0.28, 0.38, 0.34, 0.33, 0.44,
0.42, 0.37, 0.47, 0.53, 0.48, 0.58, 0.5, 0.47, 0.67, 0.5, 8.36,
8.45, 8.69, 9.05, 8.53, 8.32, 8.04, 8.26, 8.19, 7.97, 7.67, 7.4,
7.3, 7.26, 7.3, 7.15, 7.1, 7.33, 7.21, 6.68, 6.28, 6.06, 5.76,
5.11, 5.65, 5.75, 6.17, 6.05, 5.75, 5.39, 4.97, 4.69, 4.34, 4.98,
5.36, 5.12, 4.72, 4.37, 4.42, 4.3, 4.63, 4.39, 4.5, 4.2, 4.24,
4.3, 4.55, 4.58, 4.44, 5.04, 5.66, 6.16, 6.36, 6.52, 6.33, 6.44,
6.92, 7.1, 7.62, 7.8, 7.39, 6.9, 6.92, 6.72, 5.95, 5.88, 6.02,
5.95, 5.91, 5.7, 5.41, 5.25, 5.06, 5.56, 5.91, 6.19, 6.44, 6.3,
6.39, 6.54, 6.28, 5.92, 5.7, 6.04, 6.08, 6.23, 6.6, 6.42, 6.37,
6.25, 5.81, 6.1, 5.88, 5.7, 5.8, 5.68, 5.35, 5.55, 5.61, 5.62,
5.54, 5.49, 5.48, 4.85, 4.26, 4.24, 4.54, 4.55, 4.57, 5.16, 5.07,
5.17, 5.51, 5.59, 5.7, 5.82, 5.7, 5.9, 6.05, 6.29, 6.65, 6.58,
6.44, 6.64, 6.66, 6.31, 6.24, 6.09, 5.91, 5.87, 5.52, 5.06, 4.67,
4.48, 4.33, 4.55, 4.49, 4.52, 4.06, 3.91, 3.22, 2.87, 3.3, 3.59,
3.7, 3.64, 4.31, 3.83, 3.73, 3.37, 2.67, 2.5, 2.02, 2.05, 2.51,
1.99, 2.16, 1.91, 1.93, 1.95, 1.58, 1.66, 2.33, 2.51, 1.95, 2.36,
2.56, 2.37, 2.35, 2.13, 1.99, 2.86, 3.1, 3.16, 3.09, 2.75, 2.89,
2.82, 3.29, 3.25, 3.43, 3.75, 3.96, 3.73, 3.65, 3.67, 4.06, 3.83,
4.18, 4.41, 4.41, 4.37, 4.49, 4.67, 4.83, 4.87, 5.03, 5.13, 4.93,
4.71, 4.62, 4.62, 4.52, 4.74, 4.85, 4.55, 4.54, 4.54, 4.88, 4.89,
4.55, 4.16, 4.03, 3.94, 3.09, 3.07, 2.27, 1.87, 1.79, 2.49, 2.93,
2.91, 2.81, 2.6, 2.28, 1.8, 1.27, 1, 1.32, 1.4, 1.15, 1.38, 1.42,
1.64, 1.62, 1.49, 1.45, 1.43, 1.12, 1.7, 1.38, 1.36, 1.6, 1.51,
1.26, 1, 0.84, 0.72, 0.64, 0.51, 0.72, 1.02, 0.98, 1.18, 1.29,
1.01, 0.79, 0.81, 0.55, 0.33, 0.42, 0.41, 0.41, 0.36, 0.3, 0.43,
0.51, 0.38, 0.35, 0.41, 0.3, 0.3, 0.31, 0.38, 0.34, 0.36, 0.42,
0.36, 0.36, 0.32, 0.52, 0.66, 0.61, 0.79, 0.63, 0.57, 0.56, 0.78,
0.69, 0.69, 0.9, 0.87, 0.79, 0.88, 1.02, 0.94, 1.07, 0.95, 0.88,
1.1, 0.81, 8.35, 8.44, 8.65, 9.04, 8.56, 8.35, 8.13, 8.5, 8.47,
8.24, 7.91, 7.68, 7.62, 7.66, 7.73, 7.63, 7.69, 7.9, 7.77, 7.34,
6.92, 6.74, 6.48, 5.93, 6.44, 6.58, 6.94, 6.91, 6.61, 6.29, 5.84,
5.6, 5.33, 5.9, 6.23, 6.04, 5.57, 5.21, 5.24, 5.14, 5.37, 5.05,
5.16, 4.8, 4.79, 4.83, 5.15, 5.21, 5.02, 5.6, 6.23, 6.64, 6.77,
6.97, 6.73, 6.81, 7.28, 7.48, 7.79, 7.83, 7.54, 7.06, 7.08, 6.88,
6.08, 5.98, 6.16, 6.07, 6.01, 5.81, 5.53, 5.38, 5.25, 5.73, 6.1,
6.4, 6.64, 6.47, 6.57, 6.73, 6.46, 6.1, 5.84, 6.21, 6.26, 6.39,
6.77, 6.57, 6.51, 6.4, 5.9, 6.22, 6, 5.72, 5.83, 5.71, 5.39,
5.59, 5.64, 5.65, 5.56, 5.47, 5.52, 4.91, 4.23, 4.24, 4.51, 4.56,
4.55, 5.21, 5.12, 5.24, 5.6, 5.67, 5.82, 5.88, 5.78, 5.97, 6.11,
6.36, 6.71, 6.61, 6.32, 6.56, 6.54, 6.18, 6.16, 5.98, 5.85, 5.83,
5.42, 4.99, 4.85, 4.7, 4.62, 4.97, 4.94, 4.97, 4.57, 4.46, 3.93,
3.66, 4.08, 4.38, 4.42, 4.27, 4.91, 4.53, 4.37, 4.09, 3.53, 3.22,
2.63, 2.81, 3.28, 2.78, 3.02, 2.69, 2.78, 2.85, 2.3, 2.46, 3.38,
3.46, 2.85, 3.27, 3.38, 3.25, 3.17, 3.01, 2.8, 3.63, 3.81, 3.81,
3.71, 3.33, 3.38, 3.3, 3.72, 3.63, 3.71, 4, 4.18, 3.9, 3.76,
3.72, 4.12, 3.87, 4.18, 4.45, 4.42, 4.35, 4.47, 4.61, 4.82, 4.92,
5.04, 5.1, 4.91, 4.7, 4.59, 4.57, 4.45, 4.7, 4.82, 4.52, 4.54,
4.51, 4.86, 4.92, 4.6, 4.25, 4.23, 4.16, 3.41, 3.45, 2.82, 2.5,
2.46, 3.03, 3.41, 3.34, 3.25, 3.1, 2.98, 2.8, 1.93, 1.55, 1.85,
1.99, 1.67, 2.02, 2.34, 2.54, 2.53, 2.39, 2.31, 2.31, 2.01, 2.69,
2.34, 2.3, 2.55, 2.43, 2.1, 1.79, 1.6, 1.33, 1.27, 1.17, 1.47,
2.01, 1.95, 2.13, 2.24, 1.97, 1.68, 1.76, 1.35, 0.96, 0.96, 0.99,
0.96, 0.83, 0.71, 0.87, 1.04, 0.82, 0.67, 0.72, 0.6, 0.59, 0.62,
0.72, 0.61, 0.72, 0.88, 0.77, 0.77, 0.68, 1.05, 1.41, 1.38, 1.62,
1.39, 1.31, 1.37, 1.75, 1.49, 1.51, 1.73, 1.69, 1.54, 1.62, 1.76,
1.63, 1.78, 1.62, 1.49, 1.65, 1.25, 8.39, 8.54, 8.7, 9.06, 8.64,
8.46, 8.28, 8.77, 8.73, 8.5, 8.18, 8, 7.89, 7.89, 7.96, 7.88,
7.92, 8.14, 8.03, 7.67, 7.29, 7.15, 6.99, 6.38, 6.92, 6.95, 7.25,
7.26, 7, 6.76, 6.27, 6.17, 5.94, 6.36, 6.61, 6.43, 6, 5.67, 5.72,
5.63, 5.8, 5.46, 5.5, 5.11, 5.11, 5.19, 5.53, 5.53, 5.34, 5.94,
6.59, 6.88, 6.99, 7.18, 6.92, 7, 7.46, 7.65, 7.84, 7.84, 7.58,
7.15, 7.17, 6.95, 6.18, 6.12, 6.35, 6.21, 6.11, 5.92, 5.68, 5.49,
5.46, 5.99, 6.3, 6.58, 6.78, 6.61, 6.68, 6.86, 6.6, 6.24, 5.97,
6.34, 6.4, 6.5, 6.89, 6.68, 6.61, 6.49, 5.99, 6.33, 6.11, 5.87,
5.89, 5.77, 5.51, 5.67, 5.74, 5.74, 5.63, 5.52, 5.56, 5.03, 4.38,
4.47, 4.7, 4.73, 4.72, 5.39, 5.38, 5.42, 5.83, 5.93, 6.1, 6.2,
6.1, 6.19, 6.28, 6.55, 6.75, 6.67, 6.28, 6.49, 6.52, 6.25, 6.19,
5.98, 5.93, 5.87, 5.5, 5.16, 5.08, 4.93, 4.86, 5.22, 5.27, 5.28,
4.86, 4.72, 4.37, 4.03, 4.55, 4.84, 4.82, 4.7, 5.29, 4.88, 4.77,
4.52, 4.09, 3.78, 3.25, 3.45, 3.88, 3.36, 3.55, 3.24, 3.35, 3.39,
2.87, 3.03, 3.98, 4, 3.41, 3.8, 3.89, 3.77, 3.68, 3.48, 3.33,
4.11, 4.26, 4.24, 4.13, 3.76, 3.79, 3.7, 4.07, 3.94, 3.92, 4.18,
4.33, 4.03, 3.86, 3.8, 4.19, 3.93, 4.23, 4.49, 4.45, 4.36, 4.49,
4.57, 4.83, 4.98, 5.06, 5.11, 4.93, 4.7, 4.6, 4.57, 4.45, 4.7,
4.82, 4.53, 4.58, 4.55, 4.87, 4.96, 4.67, 4.36, 4.38, 4.29, 3.64,
3.7, 3.19, 2.96, 2.88, 3.34, 3.68, 3.61, 3.56, 3.45, 3.38, 3.29,
2.35, 1.87, 2.27, 2.69, 2.28, 2.7, 3.06, 3.19, 3.14, 3.03, 2.93,
2.98, 2.69, 3.39, 3.08, 3.05, 3.28, 3.12, 2.75, 2.42, 2.3, 1.92,
1.91, 1.89, 2.16, 2.71, 2.71, 2.82, 2.9, 2.66, 2.37, 2.5, 2.09,
1.56, 1.43, 1.58, 1.53, 1.35, 1.24, 1.39, 1.61, 1.33, 1.03, 1.11,
0.98, 1.01, 1.04, 1.14, 1.04, 1.18, 1.38, 1.26, 1.24, 1.11, 1.55,
1.96, 2, 2.24, 2.02, 1.95, 2.1, 2.45, 2.13, 2.13, 2.3, 2.25,
2.06, 2.13, 2.24, 2.05, 2.22, 2.05, 1.89, 1.97, 1.53, 8.43, 8.51,
8.65, 9.04, 8.6, 8.43, 8.36, 8.86, 8.82, 8.65, 8.26, 8.08, 8.03,
8.02, 8.05, 8.02, 8.06, 8.24, 8.2, 7.82, 7.47, 7.47, 7.38, 6.71,
7.31, 7.27, 7.54, 7.61, 7.33, 7.14, 6.72, 6.62, 6.37, 6.8, 6.95,
6.7, 6.39, 6.03, 6.03, 6.05, 6.16, 5.8, 5.83, 5.45, 5.4, 5.43,
5.83, 5.83, 5.7, 6.15, 6.77, 7.06, 7.17, 7.34, 7.12, 7.19, 7.62,
7.81, 7.91, 7.84, 7.6, 7.22, 7.2, 7.07, 6.3, 6.21, 6.45, 6.28,
6.17, 6.03, 5.76, 5.58, 5.6, 6.13, 6.34, 6.66, 6.85, 6.73, 6.8,
6.96, 6.72, 6.37, 6.06, 6.43, 6.53, 6.56, 6.92, 6.72, 6.67, 6.51,
6.02, 6.34, 6.12, 5.84, 5.86, 5.75, 5.53, 5.62, 5.67, 5.68, 5.56,
5.44, 5.5, 5.05, 4.44, 4.64, 4.74, 4.65, 4.66, 5.29, 5.25, 5.36,
5.64, 5.81, 5.92, 5.98, 5.9, 6.02, 6.18, 6.45, 6.68, 6.42, 6.03,
6.23, 6.29, 6.03, 6.04, 5.73, 5.8, 5.77, 5.48, 5.12, 5.19, 4.92,
4.93, 5.35, 5.43, 5.42, 5.07, 4.85, 4.6, 4.3, 4.78, 5.07, 5.07,
4.88, 5.42, 5.11, 5.08, 4.86, 4.51, 4.14, 3.63, 3.93, 4.22, 3.83,
4, 3.71, 3.83, 3.89, 3.37, 3.54, 4.49, 4.45, 3.96, 4.33, 4.34,
4.27, 4.16, 3.99, 3.86, 4.53, 4.66, 4.62, 4.5, 4.13, 4.14, 4.05,
4.36, 4.24, 4.14, 4.36, 4.5, 4.21, 4, 3.94, 4.28, 4.02, 4.34,
4.57, 4.49, 4.39, 4.53, 4.55, 4.86, 5.07, 5.12, 5.15, 4.99, 4.74,
4.64, 4.61, 4.46, 4.71, 4.83, 4.56, 4.65, 4.63, 4.9, 5.03, 4.78,
4.54, 4.59, 4.48, 3.97, 4.04, 3.67, 3.53, 3.45, 3.77, 4.06, 3.99,
3.99, 3.83, 3.85, 4.01, 2.93, 2.25, 2.87, 3.02, 2.71, 3.16, 3.47,
3.53, 3.52, 3.4, 3.31, 3.41, 3.21, 3.85, 3.63, 3.61, 3.84, 3.69,
3.31, 2.97, 2.94, 2.47, 2.53, 2.63, 2.81, 3.3, 3.42, 3.42, 3.47,
3.32, 3.05, 3.18, 2.82, 2.23, 1.92, 2.17, 2.08, 1.89, 1.83, 1.98,
2.23, 1.95, 1.59, 1.67, 1.51, 1.57, 1.65, 1.72, 1.62, 1.78, 2.02,
1.89, 1.87, 1.7, 2.16, 2.52, 2.6, 2.78, 2.64, 2.57, 2.75, 3.04,
2.67, 2.66, 2.73, 2.67, 2.48, 2.53, 2.58, 2.35, 2.52, 2.35, 2.18,
2.17, 1.73, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
6.12, 6.46, 6.48, 6.29, 6.75, 7.23, 7.44, 7.58, 7.75, 7.46, 7.6,
7.98, 8.09, 8.1, 8.02, 7.81, 7.58, 7.54, 7.42, 6.72, 6.64, 6.88,
6.72, 6.6, 6.4, 6.2, 6.01, 6.07, 6.57, 6.83, 7.06, 7.17, 7.03,
7.07, 7.28, 7.05, 6.74, 6.45, 6.73, 6.86, 6.91, 7.22, 7.05, 6.99,
6.86, 6.35, 6.69, 6.47, 6.21, 6.12, 6.02, 5.88, 5.99, 6.02, 6.04,
5.9, 5.73, 5.81, 5.45, 5.17, 5.38, 5.33, 5.39, 5.35, 5.85, 5.92,
5.94, 6.15, 6.29, 6.4, 6.49, 6.47, 6.52, 6.62, 6.83, 6.72, 6.46,
6.2, 6.31, 6.42, 6.26, 6.13, 5.96, 6.13, 6.02, 5.78, 5.59, 5.65,
5.51, 5.6, 5.92, 5.95, 5.91, 5.61, 5.47, 5.45, 5.05, 5.54, 5.74,
5.68, 5.61, 6.03, 5.74, 5.77, 5.65, 5.41, 5.06, 4.75, 5.03, 5.18,
4.83, 4.93, 4.7, 4.84, 4.79, 4.36, 4.52, 5.43, 5.33, 4.91, 5.2,
5.2, 5.1, 5, 4.85, 4.77, 5.31, 5.39, 5.33, 5.24, 4.93, 4.89,
4.79, 5.03, 4.85, 4.64, 4.79, 4.88, 4.61, 4.4, 4.28, 4.56, 4.3,
4.62, 4.84, 4.81, 4.61, 4.74, 4.7, 5.07, 5.31, 5.35, 5.31, 5.17,
4.95, 4.84, 4.81, 4.66, 4.91, 5.02, 4.78, 4.92, 4.88, 5.1, 5.21,
5, 4.87, 4.89, 4.79, 4.44, 4.5, 4.35, 4.37, 4.3, 4.49, 4.74,
4.59, 4.63, 4.47, 4.43, 4.74, 3.71, 3.05, 3.86, 3.98, 3.61, 4.1,
4.34, 4.3, 4.29, 4.14, 4.02, 4.19, 4.07, 4.58, 4.38, 4.4, 4.55,
4.36, 4.05, 3.74, 3.74, 3.23, 3.38, 3.64, 3.8, 4.13, 4.33, 4.25,
4.29, 4.15, 3.91, 4.09, 3.77, 3.19, 2.66, 2.89, 2.77, 2.57, 2.59,
2.73, 3, 2.73, 2.27, 2.38, 2.21, 2.29, 2.42, 2.46, 2.37, 2.54,
2.79, 2.71, 2.71, 2.49, 2.95, 3.22, 3.34, 3.46, 3.41, 3.33, 3.54,
3.72, 3.35, 3.31, 3.31, 3.22, 3.05, 3.08, 3.07, 2.83, 2.98, 2.81,
2.62, 2.47, 2.05, 8.46, 8.54, 8.63, 9, 8.58, 8.41, 8.42, 8.99,
8.96, 8.78, 8.4, 8.26, 8.21, 8.19, 8.24, 8.2, 8.26, 8.42, 8.36,
8.06, 7.82, 7.91, 7.94, 7.41, 7.77, 7.8, 7.96, 8.06, 7.84, 7.79,
7.46, 7.42, 7.38, 7.63, 7.59, 7.4, 7.21, 6.9, 6.93, 6.95, 6.98,
6.68, 6.57, 6.09, 6.04, 5.96, 6.29, 6.35, 6.23, 6.67, 7.11, 7.31,
7.44, 7.63, 7.39, 7.46, 7.82, 7.97, 7.99, 7.89, 7.71, 7.46, 7.44,
7.34, 6.67, 6.63, 6.86, 6.65, 6.49, 6.34, 6.14, 5.96, 6.03, 6.48,
6.67, 6.89, 7, 6.9, 6.98, 7.13, 6.93, 6.66, 6.36, 6.65, 6.8,
6.8, 7.1, 6.95, 6.92, 6.8, 6.3, 6.61, 6.41, 6.15, 6.04, 5.93,
5.82, 5.92, 5.94, 5.95, 5.81, 5.62, 5.72, 5.3, 4.98, 5.15, 5.08,
5.09, 5.09, 5.57, 5.63, 5.68, 5.84, 5.98, 6.11, 6.07, 6.06, 6.16,
6.29, 6.48, 6.49, 6.15, 5.84, 5.97, 6.02, 5.9, 5.79, 5.67, 5.88,
5.79, 5.6, 5.46, 5.54, 5.34, 5.46, 5.78, 5.78, 5.75, 5.51, 5.39,
5.42, 4.89, 5.27, 5.48, 5.44, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, 4.51, 4.9, 5.17, 5.21, 5.19,
5.07, 4.88, 4.77, 4.72, 4.56, 4.81, 4.93, 4.68, 4.84, 4.81, 5.01,
5.12, 4.92, 4.83, 4.83, 4.74, 4.4, 4.45, 4.35, 4.41, 4.3, 4.49,
4.72, 4.53, 4.59, 4.43, 4.31, 4.35, 3.45, 2.69, 3.58, 3.71, 3.56,
4.05, 4.34, 4.32, 4.31, 4.18, 4.03, 4.23, 4.2, 4.63, 4.51, 4.55,
4.72, 4.53, 4.22, 3.91, 3.98, 3.52, 3.69, 3.99, 4.12, 4.34, 4.58,
4.49, 4.51, 4.4, 4.22, 4.38, 4.12, 3.6, 2.9, 3.16, 3.06, 2.89,
2.94, 3.08, 3.35, 3.12, 2.67, 2.76, 2.56, 2.68, 2.82, 2.85, 2.81,
2.95, 3.17, 3.1, 3.1, 2.88, 3.3, 3.52, 3.64, 3.7, 3.69, 3.63,
3.82, 3.96, 3.61, 3.59, 3.56, 3.47, 3.33, 3.34, 3.32, 3.09, 3.21,
3.07, 2.89, 2.75, 2.29), class = c("xts", "zoo"), .indexCLASS = "Date", 
tclass = "Date", .indexTZ = "UTC", tzone = "UTC", index = 
structure(c(633744000,
636163200, 638755200, 641433600, 644112000, 646617600, 649382400,
652060800, 654480000, 657331200, 659923200, 662601600, 665280000,
667699200, 670118400, 672969600, 675648000, 678067200, 680918400,
683510400, 686188800, 688867200, 691372800, 694137600, 696816000,
699235200, 702000000, 704592000, 707097600, 709862400, 712540800,
715219200, 717811200, 720403200, 723081600, 725760000, 728265600,
730684800, 733536000, 736128000, 738547200, 741398400, 743990400,
746755200, 749347200, 751852800, 754617600, 757296000, 759974400,
762393600, 765072000, 767577600, 770342400, 772934400, 775440000,
778291200, 780883200, 783561600, 786153600, 788745600, 791510400,
793929600, 796608000, 799027200, 801878400, 804470400, 807148800,
809827200, 812332800, 815097600, 817689600, 820195200, 823046400,
825552000, 828057600, 830822400, 833500800, 835920000, 838771200,
841363200, 844041600, 846720000, 849225600, 851990400, 854668800,
857088000, 859766400, 862358400, 864950400, 867628800, 870307200,
872812800, 875577600, 878256000, 880675200, 883526400, 886118400,
888537600, 891302400, 893894400, 896400000, 899164800, 901843200,
904521600, 907113600, 909705600, 912384000, 915062400, 917568000,
919987200, 922838400, 925430400, 927849600, 930700800, 933292800,
936057600, 938649600, 941155200, 943920000, 946598400, 949276800,
951782400, 954460800, 956880000, 959731200, 962323200, 965001600,
967680000, 970185600, 972950400, 975542400, 978048000, 980899200,
983318400, 985910400, 988588800, 991267200, 993772800, 996537600,
999216000, 1001635200, 1004486400, 1007078400, 1009756800, 1012435200,
1014854400, 1017273600, 1020124800, 1022803200, 1025222400, 1028073600,
1030665600, 1033344000, 1036022400, 1038528000, 1041292800, 1043971200,
1046390400, 1049068800, 1051660800, 1054252800, 1056931200, 1059609600,
1062115200, 1064880000, 1067558400, 1069977600, 1072828800, 1075420800,
1077840000, 1080691200, 1083283200, 1085702400, 1088553600, 1091145600,
1093910400, 1096502400, 1099008000, 1101772800, 1104451200, 1107129600,
1109548800, 1112227200, 1114732800, 1117497600, 1120089600, 1122595200,
1125446400, 1128038400, 1130716800, 1133308800, 1135900800, 1138665600,
1141084800, 1143763200, 1146182400, 1149033600, 1151625600, 1154304000,
1156982400, 1159488000, 1162252800, 1164844800, 1167350400, 1170201600,
1172620800, 1175212800, 1177891200, 1180569600, 1183075200, 1185840000,
1188518400, 1190937600, 1193788800, 1196380800, 1199059200, 1201737600,
1204243200, 1206921600, 1209513600, 1212105600, 1214784000, 1217462400,
1219968000, 1222732800, 1225411200, 1227830400, 1230681600, 1233273600,
1235692800, 1238457600, 1241049600, 1243555200, 1246320000, 1248998400,
1251676800, 1254268800, 1256860800, 1259539200, 1262217600, 1264723200,
1267142400, 1269993600, 1272585600, 1275004800, 1277856000, 1280448000,
1283212800, 1285804800, 1288310400, 1291075200, 1293753600, 1296432000,
1298851200, 1301529600, 1304035200, 1306800000, 1309392000, 1311897600,
1314748800, 1317340800, 1320019200, 1322611200, 1325203200, 1327968000,
1330473600, 1333065600, 1335744000, 1338422400, 1340928000, 1343692800,
1346371200, 1348790400, 1351641600, 1354233600, 1356912000, 1359590400,
1362009600, 1364428800, 1367280000, 1369958400, 1372377600, 1375228800,
1377820800, 1380499200, 1383177600, 1385683200, 1388448000, 1391126400,
1393545600, 1396224000, 1398816000, 1401408000, 1404086400, 1406764800,
1409270400, 1412035200, 1414713600, 1417132800, 1419984000, 1422403200
), tzone = "UTC", tclass = "Date"), .Dim = c(301L, 11L), .Dimnames = 
list(
     NULL, c("1M", "3M", "6M", "1Y", "2Y", "3Y", "5Y", "7Y", "10Y",
     "20Y", "30Y")))

chartSeries3d0(term.structure,r=1,col=c("lightblue","darkblue"),
                
border=NA,theta=45,ltheta=0,shade=0.15,smoother=1,phi=15,scale=FALSE,expand=0.75)

Can anyone suggest a different package to work with to get closer to the 
above-mentioned output?  I'm interested in figuring out how to smooth 
the color transitions, add the grid/gridlines and use a different set of 
color gradients when the values are negative.  Also, I realize that my 
colors transition along the wrong axis (1m, 3m, etc) rather than along 
y.

Thanks in advance.  I've tried to find a reference to this in the 
archives and have come up empty.  As well, I've tried to make this 
reproducible.
Matt


From dwinsemius at comcast.net  Thu Jun  4 22:39:11 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 4 Jun 2015 13:39:11 -0700
Subject: [R] Reproducing a 3d yield curve plot from New York Times
In-Reply-To: <498ab7ebd8c09e87361c575b1c02e822@considine.net>
References: <498ab7ebd8c09e87361c575b1c02e822@considine.net>
Message-ID: <626909F8-5443-4573-9560-613FE2C52180@comcast.net>

At the bottom you asked for package recs:

Karline Soetaert's (excuse any misspelling) plot3D package should be examined.

I didn't find the fine-grained example that I remember seeing but this is an example in RGL code:

http://markmail.org/message/wgetbk5h3f7zrfd4

-- 
David.


 On Jun 4, 2015, at 1:16 PM, matt at considine.net wrote:

> I am trying to closely reproduce the 3d yield curve chart that showed up in the New York Times in March, as seen here
>  http://www.nytimes.com/interactive/2015/03/19/upshot/3d-yield-curve-economic-growth.html?ref=economy&abt=0002&abg=0
> 
> Working with chartSeries3d0 gets me close, but not quite there :
> 
> library(xts)
> 
> chartSeries3d0 <-
>  function(Z, theta=30, r=10, col=c("yellow","red"), smoother=1, border=NA, shade=.3,
>           phi=10,scale=FALSE,expand=1,lphi=20,box=FALSE,  #mattc
>           ltheta=20,  x.cex=.75, srt=0,...) {
snipped code and data
> 
> Can anyone suggest a different package to work with to get closer to the above-mentioned output?  I'm interested in figuring out how to smooth the color transitions, add the grid/gridlines and use a different set of color gradients when the values are negative.  Also, I realize that my colors transition along the wrong axis (1m, 3m, etc) rather than along y.
> 
> Thanks in advance.  I've tried to find a reference to this in the archives and have come up empty.  As well, I've tried to make this reproducible.
> Matt
> 

I'm reasonably sure that MatLab has a function for this sort of dispaly and requests for duplicating it with R facilities have been satisfied.

-- 

David Winsemius
Alameda, CA, USA


From james_henson at suagcenter.com  Thu Jun  4 21:42:41 2015
From: james_henson at suagcenter.com (James F. Henson)
Date: Thu, 4 Jun 2015 19:42:41 +0000
Subject: [R] Dunnett Test in 'multicomp' package
Message-ID: <0CFDB87AFEBD36438EA1AFAF4ECA074F4ACF3D52@agc-exchange.suagcenter.net>

Greetings

Below is my code.

library("multcomp")
viaModel1 <- aov(libido ~ dose, data=viagraData)
dunnettModel <- glht(viaModel1 , linfct = mcp(dose = "Dunnett"), base = "placebo")

The code base="placebo" is ignored.  All treatments are compared to the first treatment in the order, which is "high dose".  It is possible to rearrange the order so that "placebo' is first, but this is inconvenient.

Thanks,
James F. Henson

	[[alternative HTML version deleted]]


From therneau at mayo.edu  Thu Jun  4 23:20:10 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 04 Jun 2015 16:20:10 -0500
Subject: [R] Unwanted unicode - solved
In-Reply-To: <B34BF897-3048-4929-A6E9-6EC17B10EB89@me.com>
References: <2f3a88$p9clj@ironport10.mayo.edu>
	<B34BF897-3048-4929-A6E9-6EC17B10EB89@me.com>
Message-ID: <2f3a88$pbobb@ironport10.mayo.edu>

Thanks to all.  The suggestion below by Marc Schwarz (the second I tried) showed the 
problem.  One of the references in one of the files had been pasted in and had a funky 
dash in its "111-196" page number.  It looked just fine in my emacs window so I hadn't 
picked it up.  There are 90 .Rd files so this saved me substantial time.

Terry T.


On 06/04/2015 03:00 PM, Marc Schwartz wrote:
> On Jun 4, 2015, at 12:56 PM, Therneau, Terry M., Ph.D. <therneau at mayo.edu> wrote:
>>
>> I'm checking the survival package and get the following error. How do I find the offending line?  (There are a LOT of files in the man directory.)
>>
>> Terry T.
>>
>> ------------------
>>
>> * checking PDF version of manual ... WARNING
>> LaTeX errors when creating PDF version.
>> This typically indicates Rd problems.
>> LaTeX errors found:
>> ! Package inputenc Error: Unicode char \u8:? not set up for use with LaTeX.
>
>
> Terry,
>
> One possible option:
>
>    require(tools)
>
>    sapply(list.files(path = ?Path/To/Your/RD/Files", pattern = ".Rd"),
>           showNonASCIIfile)
>
> See ?list.files and ?showNonASCIIfile
>
> Regards,
>
> Marc Schwartz
>


From rmh at temple.edu  Thu Jun  4 23:19:04 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 4 Jun 2015 17:19:04 -0400
Subject: [R] Dunnett Test in 'multicomp' package
In-Reply-To: <0CFDB87AFEBD36438EA1AFAF4ECA074F4ACF3D52@agc-exchange.suagcenter.net>
References: <0CFDB87AFEBD36438EA1AFAF4ECA074F4ACF3D52@agc-exchange.suagcenter.net>
Message-ID: <CAGx1TMD3eqOAVah4N-9E+AvEh7+6nGsfN_x1cqWpEOk4xD5Gyw@mail.gmail.com>

This example is based on ?glht

> data(warpbreaks)
> glht(amod, linfct = mcp(tension = "Dunnett"))

General Linear Hypotheses

Multiple Comparisons of Means: Dunnett Contrasts


Linear Hypotheses:
           Estimate
M - L == 0    -10.0
H - L == 0    -14.7
> levels(warpbreaks$tension)
[1] "L" "M" "H"
> warpbreaks$tension <- factor(warpbreaks$tension, levels=c("H","M","L"))
>        amod <- aov(breaks ~ tension, data = warpbreaks)
> glht(amod, linfct = mcp(tension = "Dunnett"))

General Linear Hypotheses

Multiple Comparisons of Means: Dunnett Contrasts


Linear Hypotheses:
           Estimate
M - H == 0     4.72
L - H == 0    14.72


Changing the order of the levels is easy.  Rearranging the data itself
is not necessary.

Rich

On Thu, Jun 4, 2015 at 3:42 PM, James F. Henson
<james_henson at suagcenter.com> wrote:
> Greetings
>
> Below is my code.
>
> library("multcomp")
> viaModel1 <- aov(libido ~ dose, data=viagraData)
> dunnettModel <- glht(viaModel1 , linfct = mcp(dose = "Dunnett"), base = "placebo")
>
> The code base="placebo" is ignored.  All treatments are compared to the first treatment in the order, which is "high dose".  It is possible to rearrange the order so that "placebo' is first, but this is inconvenient.
>
> Thanks,
> James F. Henson
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Fri Jun  5 00:14:42 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 4 Jun 2015 14:14:42 -0800
Subject: [R] Decision tree in R using csv files
In-Reply-To: <1433433342737-4708193.post@n4.nabble.com>
Message-ID: <CE7EFB5A2FF.000024D6jrkrideau@inbox.com>

No attachment. See http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html

John Kane
Kingston ON Canada


> -----Original Message-----
> From: akshay at cosmicad.com
> Sent: Thu, 4 Jun 2015 08:55:42 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] Decision tree in R using csv files
> 
> Hi
> Pls check the attachment.  I am having some error while making a decision
> tree in R .   Pls help.
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Decision-tree-in-R-using-csv-files-tp4708193.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From drjimlemon at gmail.com  Fri Jun  5 00:42:32 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 5 Jun 2015 08:42:32 +1000
Subject: [R] Help to solve an Error
In-Reply-To: <C8F1A9E676B.00000C26jrkrideau@inbox.com>
References: <capl76w8sqmv5=oxwzbspgf82nof3ojv=g08foxei7fuajbtefq@mail.gmail.com>
	<CA+8X3fWW3yE6jC01zK=NF9qmJEB=ro5umK427iXeDJzTOgKTRg@mail.gmail.com>
	<C8F1A9E676B.00000C26jrkrideau@inbox.com>
Message-ID: <CA+8X3fXM9DZitu7kFvfHca+VaWNCitKEcCoE14d=Z-+86mwP5w@mail.gmail.com>

Hi all,
Does this have something to do with "markdown"? I recently had to
write something using this and found it much more difficult than HTML.
One missed space or character, which is often hard to see, can turn a
whole line to garbage.

Jim


On Thu, Jun 4, 2015 at 9:38 PM, John Kane <jrkrideau at inbox.com> wrote:
> Hi Jim,
> It is an problem in Gavin Simpson's code itself. Bad translation from R to HMTL it appears
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: drjimlemon at gmail.com
>> Sent: Thu, 4 Jun 2015 21:22:37 +1000
>> To: jacksonmrodrigues at gmail.com
>> Subject: Re: [R] Help to solve an Error
>>
>> Hi Jackson,
>> It looks like you have picked up the HTML code for the right angle
>> bracket. Try replacing this with a right angle bracket:
>>
>> grecent<-subset(gtemp,subset = Year>=1995,select = c(Year,Annual))
>>
>> Jim
>>
>>
>> On Thu, Jun 4, 2015 at 8:20 PM, Jackson Rodrigues
>> <jacksonmrodrigues at gmail.com> wrote:
>>> Hi,
>>>
>>>
>>>
>>> I want to apply the codes of Gavin Simpson from
>>> http://www.fromthebottomoftheheap.net/2011/06/11/global-warming-since-1995-now-significant/
>>> on my own data to detect trends in a subset. However, when I run:
>>>
>>>> grecent <- subset(gtemp, subset = Year &gt;= 1995,select = c(Year,
>>> Annual))
>>>
>>> I get error:
>>>
>>> Error: unexpected ';' in "grecent <- subset(gtemp, subset = Year &gt;"
>>>
>>> I've tried to replace ";" with several things, but it does not work at
>>> all.
>>>
>>> Could anyone help me to solve this "problem"?
>>>
>>> Best Regards,
>>>
>>> Jackson Rodrigues
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> Check it out at http://www.inbox.com/earth
>
>


From drjimlemon at gmail.com  Fri Jun  5 00:59:04 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 5 Jun 2015 08:59:04 +1000
Subject: [R] web scraping image
In-Reply-To: <CAApc6sQp4F_M12QXxKPP_7yTtNZAzyk2rYRm0=O1Hh_M4dxJ=w@mail.gmail.com>
References: <CAApc6sQp4F_M12QXxKPP_7yTtNZAzyk2rYRm0=O1Hh_M4dxJ=w@mail.gmail.com>
Message-ID: <CA+8X3fV0aJw+E22JayV1GfM6JR_taZuA5FwGD3T_mfGfQy2nFA@mail.gmail.com>

Hi Chris,
I don't have the packages you are using, but tracing this indicates
that the page source contains the relative path of the graphic, in
this case:

/nwisweb/data/img/USGS.12144500.19581112.20140309..0.peak.pres.gif

and you already have the server URL:

nwis.waterdata.usgs.gov

getting the path out of the page source isn't difficult, just split
the text at double quotes and get the token following "img src=". If I
understand the arguments of "download.file" correctly, the path is the
graphic.fn argument and the server URL is the graphic.url argument. I
would paste them together and display the result to make sure that it
matches the image you want. When I did this, the correct image
appeared in my browser. I'm using Google Chrome, so I don't have to
prepend the http://

Jim

On Fri, Jun 5, 2015 at 2:31 AM, Curtis DeGasperi
<curtis.degasperi at gmail.com> wrote:
> I'm working on a script that downloads data from the USGS NWIS server.
> dataRetrieval makes it easy to quickly get the data in a neat tabular
> format, but I was also interested in getting the tabular text files -
> also fairly easy for me using download.file.
>
> However, I'm not skilled enough to work out how to download the nice
> graphic files that can be produced dynamically from the USGS NWIS
> server (for example:
> http://nwis.waterdata.usgs.gov/nwis/peak?site_no=12144500&agency_cd=USGS&format=img)
>
> My question is how do I get the image from this web page and save it
> to a local directory? scrapeR returns the information from the page
> and I suspect this is a possible solution path, but I don't know what
> the next step is.
>
> My code provided below works from a list I've created of USGS flow
> gauging stations.
>
> Curtis
>
> ## Code to process USGS daily flow data for high and low flow analysis
> ## Need to start with list of gauge ids to process
> ## Can't figure out how to automate download of images
>
> require(dataRetrieval)
> require(data.table)
> require(scrapeR)
>
> df <- read.csv("usgs_stations.csv", header=TRUE)
>
> lstas <-length(df$siteno) #length of locator list
>
> print(paste('Processsing...',df$name[1],' ',df$siteno[1], sep = ""))
>
> datall <-  readNWISpeak(df$siteno[1])
>
> for (a in 2:lstas) {
>   # Print station being processed
>   print(paste('Processsing...',df$name[a],' ',df$siteno[a], sep = ""))
>
>   dat<-  readNWISpeak(df$siteno[a])
>
>   datall <- rbind(datall,dat)
>
> }
>
> write.csv(datall, file = "usgs_peaks.csv")
>
> # Retrieve ascii text files and graphics
>
> for (a in 1:lstas) {
>
>   print(paste('Processsing...',df$name[1],' ',df$siteno[1], sep = ""))
>
>   graphic.url <-
> paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=',df$siteno[a],'&agency_cd=USGS&format=img',
> sep = "")
>   peakfq.url <-
> paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=',df$siteno[a],'&agency_cd=USGS&format=hn2',
> sep = "")
>   tab.url  <- paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=',df$siteno[a],'&agency_cd=USGS&format=rdb',
> sep = "")
>
>   graphic.fn <- paste('graphic_',df$siteno[a],'.gif', sep = "")
>   peakfq.fn <- paste('peakfq_',df$siteno[a],'.txt', sep = "")
>   tab.fn  <- paste('tab_',df$siteno[a],'.txt', sep = "")
>
>   download.file(graphic.url,graphic.fn,mode='wb') # This apparently
> doesn't work - file is empty
>   download.file(peakfq.url,peakfq.fn)
>   download.file(tab.url,tab.fn)
> }
>
> # scrapeR
> pageSource<-scrape(url="http://nwis.waterdata.usgs.gov/nwis/peak?site_no=12144500&agency_cd=USGS&format=img",headers=TRUE,
> parse=FALSE)
> page<-scrape(object="pageSource")
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From JSorkin at grecc.umaryland.edu  Fri Jun  5 02:38:10 2015
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Thu, 04 Jun 2015 20:38:10 -0400
Subject: [R] Finite mixture model: truncated normal and a normal distribution
Message-ID: <5570B732020000CB0012ED0C@smtp.medicine.umaryland.edu>

I am looking for software that will take data what appears to come from a series of low numbers coming from a left-truncated normal distribution and a series of higher numbers coming from a normal distribution and produce the mean, SD, and mixing proportion of the two source distributions. I have looked at mixtoolsmixtools but it is not exactly what I am looking for as it models two-normal distributions (i.e. the lower of the two distributions is NOT truncated).

Any suggestions for a package, or an analysis plan would be appreciated.

Thank you,
John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From dwinsemius at comcast.net  Fri Jun  5 04:56:18 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 4 Jun 2015 19:56:18 -0700
Subject: [R] Finite mixture model: truncated normal and a normal
	distribution
In-Reply-To: <5570B732020000CB0012ED0C@smtp.medicine.umaryland.edu>
References: <5570B732020000CB0012ED0C@smtp.medicine.umaryland.edu>
Message-ID: <3C447DB5-0772-4736-8F93-EB9C0BB50C8F@comcast.net>


On Jun 4, 2015, at 5:38 PM, John Sorkin wrote:

> I am looking for software that will take data what appears to come from a series of low numbers coming from a left-truncated normal distribution and a series of higher numbers coming from a normal distribution and produce the mean, SD, and mixing proportion of the two source distributions. I have looked at mixtoolsmixtools but it is not exactly what I am looking for as it models two-normal distributions (i.e. the lower of the two distributions is NOT truncated).
> 
> Any suggestions for a package, or an analysis plan would be appreciated.

Perhaps posting some data?

> 
> John David Sorkin M.D., Ph.D.


-- 
David Winsemius, MD
Alameda, CA, USA


From drjimlemon at gmail.com  Fri Jun  5 01:08:49 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 5 Jun 2015 09:08:49 +1000
Subject: [R] Dunnett Test in 'multicomp' package
In-Reply-To: <CAGx1TMD3eqOAVah4N-9E+AvEh7+6nGsfN_x1cqWpEOk4xD5Gyw@mail.gmail.com>
References: <0CFDB87AFEBD36438EA1AFAF4ECA074F4ACF3D52@agc-exchange.suagcenter.net>
	<CAGx1TMD3eqOAVah4N-9E+AvEh7+6nGsfN_x1cqWpEOk4xD5Gyw@mail.gmail.com>
Message-ID: <CA+8X3fUtyVe8Cg2tciNTgGbPSk5-s8H3tsLKfLp8Tpokag6fnQ@mail.gmail.com>

Hi James,
You can change the order of levels like this:

levels(viagraData$dose)<-c("placebo","low dose","high dose")

Although I don't know the exact names of the variable and its levels.

Jim

On Fri, Jun 5, 2015 at 7:19 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
> This example is based on ?glht
>
>> data(warpbreaks)
>> glht(amod, linfct = mcp(tension = "Dunnett"))
>
> General Linear Hypotheses
>
> Multiple Comparisons of Means: Dunnett Contrasts
>
>
> Linear Hypotheses:
>            Estimate
> M - L == 0    -10.0
> H - L == 0    -14.7
>> levels(warpbreaks$tension)
> [1] "L" "M" "H"
>> warpbreaks$tension <- factor(warpbreaks$tension, levels=c("H","M","L"))
>>        amod <- aov(breaks ~ tension, data = warpbreaks)
>> glht(amod, linfct = mcp(tension = "Dunnett"))
>
> General Linear Hypotheses
>
> Multiple Comparisons of Means: Dunnett Contrasts
>
>
> Linear Hypotheses:
>            Estimate
> M - H == 0     4.72
> L - H == 0    14.72
>
>
> Changing the order of the levels is easy.  Rearranging the data itself
> is not necessary.
>
> Rich
>
> On Thu, Jun 4, 2015 at 3:42 PM, James F. Henson
> <james_henson at suagcenter.com> wrote:
>> Greetings
>>
>> Below is my code.
>>
>> library("multcomp")
>> viaModel1 <- aov(libido ~ dose, data=viagraData)
>> dunnettModel <- glht(viaModel1 , linfct = mcp(dose = "Dunnett"), base = "placebo")
>>
>> The code base="placebo" is ignored.  All treatments are compared to the first treatment in the order, which is "high dose".  It is possible to rearrange the order so that "placebo' is first, but this is inconvenient.
>>
>> Thanks,
>> James F. Henson
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Fri Jun  5 07:01:29 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 5 Jun 2015 01:01:29 -0400
Subject: [R] Dunnett Test in 'multicomp' package
In-Reply-To: <CA+8X3fUtyVe8Cg2tciNTgGbPSk5-s8H3tsLKfLp8Tpokag6fnQ@mail.gmail.com>
References: <0CFDB87AFEBD36438EA1AFAF4ECA074F4ACF3D52@agc-exchange.suagcenter.net>
	<CAGx1TMD3eqOAVah4N-9E+AvEh7+6nGsfN_x1cqWpEOk4xD5Gyw@mail.gmail.com>
	<CA+8X3fUtyVe8Cg2tciNTgGbPSk5-s8H3tsLKfLp8Tpokag6fnQ@mail.gmail.com>
Message-ID: <CAGx1TMAxGqyQRPjb0cEf70+pDFV6+pEu-GVJTsxr=50h+83FTQ@mail.gmail.com>

Sorry, Jim

that doesn't do the right thing.

> tmp <- factor(c("mm", "cm", "dm", "m", "km"))
> levels(tmp)
[1] "cm" "dm" "km" "m"  "mm"
> tmp
[1] mm cm dm m  km
Levels: cm dm km m mm
> levels(tmp) <- c("mm", "cm", "dm", "m", "km")
> tmp
[1] km mm cm m  dm
Levels: mm cm dm m km
> ## back to the begining
> tmp <- factor(c("mm", "cm", "dm", "m", "km"))
> tmp
[1] mm cm dm m  km
Levels: cm dm km m mm
> tmp <- factor(tmp, levels=unique(tmp))
> tmp
[1] mm cm dm m  km
Levels: mm cm dm m km
>


Rich

On Thu, Jun 4, 2015 at 7:08 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi James,
> You can change the order of levels like this:
>
> levels(viagraData$dose)<-c("placebo","low dose","high dose")
>
> Although I don't know the exact names of the variable and its levels.
>
> Jim
>
> On Fri, Jun 5, 2015 at 7:19 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
>> This example is based on ?glht
>>
>>> data(warpbreaks)
>>> glht(amod, linfct = mcp(tension = "Dunnett"))
>>
>> General Linear Hypotheses
>>
>> Multiple Comparisons of Means: Dunnett Contrasts
>>
>>
>> Linear Hypotheses:
>>            Estimate
>> M - L == 0    -10.0
>> H - L == 0    -14.7
>>> levels(warpbreaks$tension)
>> [1] "L" "M" "H"
>>> warpbreaks$tension <- factor(warpbreaks$tension, levels=c("H","M","L"))
>>>        amod <- aov(breaks ~ tension, data = warpbreaks)
>>> glht(amod, linfct = mcp(tension = "Dunnett"))
>>
>> General Linear Hypotheses
>>
>> Multiple Comparisons of Means: Dunnett Contrasts
>>
>>
>> Linear Hypotheses:
>>            Estimate
>> M - H == 0     4.72
>> L - H == 0    14.72
>>
>>
>> Changing the order of the levels is easy.  Rearranging the data itself
>> is not necessary.
>>
>> Rich
>>
>> On Thu, Jun 4, 2015 at 3:42 PM, James F. Henson
>> <james_henson at suagcenter.com> wrote:
>>> Greetings
>>>
>>> Below is my code.
>>>
>>> library("multcomp")
>>> viaModel1 <- aov(libido ~ dose, data=viagraData)
>>> dunnettModel <- glht(viaModel1 , linfct = mcp(dose = "Dunnett"), base = "placebo")
>>>
>>> The code base="placebo" is ignored.  All treatments are compared to the first treatment in the order, which is "high dose".  It is possible to rearrange the order so that "placebo' is first, but this is inconvenient.
>>>
>>> Thanks,
>>> James F. Henson
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Fri Jun  5 09:48:03 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 05 Jun 2015 19:48:03 +1200
Subject: [R] [FORGED] Re:  Dunnett Test in 'multicomp' package
In-Reply-To: <CA+8X3fUtyVe8Cg2tciNTgGbPSk5-s8H3tsLKfLp8Tpokag6fnQ@mail.gmail.com>
References: <0CFDB87AFEBD36438EA1AFAF4ECA074F4ACF3D52@agc-exchange.suagcenter.net>	<CAGx1TMD3eqOAVah4N-9E+AvEh7+6nGsfN_x1cqWpEOk4xD5Gyw@mail.gmail.com>
	<CA+8X3fUtyVe8Cg2tciNTgGbPSk5-s8H3tsLKfLp8Tpokag6fnQ@mail.gmail.com>
Message-ID: <55715433.4060809@auckland.ac.nz>

On 05/06/15 11:08, Jim Lemon wrote:
> Hi James,
> You can change the order of levels like this:
>
> levels(viagraData$dose)<-c("placebo","low dose","high dose")

<SNIP>

As Richard Heiberger has pointed out, this is wrong.

What *does* work is:

viagraData$dose)<-factor(viagraData$dose,
                         levels=c("placebo","low dose","high dose")

This is a trap into which many a Young Player (including my very good 
self) has fallen.

cheers,

Rolf Turner



-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From cgenolin at u-paris10.fr  Fri Jun  5 09:10:46 2015
From: cgenolin at u-paris10.fr (cgenolin)
Date: Fri, 5 Jun 2015 00:10:46 -0700 (PDT)
Subject: [R] is.na for S4 object
In-Reply-To: <55708BF1.2010801@fredhutch.org>
References: <1433437709373-4708201.post@n4.nabble.com>
	<55708BF1.2010801@fredhutch.org>
Message-ID: <1433488246290-4708234.post@n4.nabble.com>

So easy!

Thanks a lot.



--
View this message in context: http://r.789695.n4.nabble.com/is-na-for-S4-object-tp4708201p4708234.html
Sent from the R help mailing list archive at Nabble.com.


From cgenolin at u-paris10.fr  Fri Jun  5 09:36:42 2015
From: cgenolin at u-paris10.fr (cgenolin)
Date: Fri, 5 Jun 2015 00:36:42 -0700 (PDT)
Subject: [R] S4 / operator "[" : Compatibility issue between lme4 and kml
Message-ID: <1433489802634-4708236.post@n4.nabble.com>

Hi all,

There is a compatibility issue between the package 'lme4' and my package
'kml'. I define the "[" operator. It works just fine in my package (1). If I
try to use the lme4 package, then it does no longer work (2). Moreover, it
has some kind of strange behavior (3). Do you know what is wrong? Any idea
of how I can correct that?

Here is a reproductible example, and the same code with the result follows.

Thanks for your help
Christophe

--- 8< ----------------- Code for reproductible example -------------------
library(kml)

### Creating some data
dn <- gald(1)
dn["traj"]

### using lme4
library(lme4)
dn["traj"]

### Re-defining the "["
setMethod(   ### Simplified version ###
  "[",
  signature=signature(x="ClusterLongData", i="character",
j="ANY",drop="ANY"),
  definition=function (x, i, j="missing", ..., drop = TRUE){
      x <- as(x, "LongData")
      return(x[i, j])
    }
)

dn["traj"]
dn["traj"]

--- 8< ----------------- Execution of the previous code -------------------

> library(kml)
Le chargement a n?cessit? le package : clv
Le chargement a n?cessit? le package : cluster
Le chargement a n?cessit? le package : class
Le chargement a n?cessit? le package : longitudinalData
Le chargement a n?cessit? le package : rgl
Le chargement a n?cessit? le package : misc3d
> dn <- gald(1)

 ###########
### (1) the "[" operator works just fine

> dn["traj"]
      t0   t1    t2    t3    t4   t5   t6    t7    t8    t9   t10
i1 -3.11 4.32  2.17  1.82  4.90 7.34 0.83 -2.70  5.36  4.96  3.16
i2 -7.11 1.40 -2.40 -2.96  4.31 0.50 1.25  0.52 -0.04  7.55  5.50
i3  2.80 6.23  6.08  2.87  2.58 2.88 6.58 -2.38  2.30 -1.74 -3.23
i4  2.24 0.91  6.50 10.92 11.32 7.79 7.78 10.69  9.15  1.07 -0.51

 ###########
### (2) using 'lme4', it does no longer work

> library(lme4)
Le chargement a n?cessit? le package : Matrix
Le chargement a n?cessit? le package : Rcpp
> dn["traj"]
Error in x[i, j] :
  erreur d'?valuation de l'argument 'j' lors de la s?lection d'une m?thode
pour la fonction '[' : Erreur : l'argument "j" est manquant, avec aucune
valeur par d?faut

 ###########
### (3) If I define again the "[", it does not work the first time I call
it, but it work the second time!
> setMethod(
+   "[",
+   signature=signature(x="ClusterLongData", i="character",
j="ANY",drop="ANY"),
+   definition=function (x, i, j="missing", ..., drop = TRUE){
+       x <- as(x, "LongData")
+       return(x[i, j])
+     }
+ )
[1] "["

### No working the first time I use it
> dn["traj"]
Error in dn["traj"] :
  l'argument "j" est manquant, avec aucune valeur par d?faut

### But working the second time
> dn["traj"]
      t0   t1    t2    t3    t4   t5   t6    t7    t8    t9   t10
i1 -3.11 4.32  2.17  1.82  4.90 7.34 0.83 -2.70  5.36  4.96  3.16
i2 -7.11 1.40 -2.40 -2.96  4.31 0.50 1.25  0.52 -0.04  7.55  5.50
i3  2.80 6.23  6.08  2.87  2.58 2.88 6.58 -2.38  2.30 -1.74 -3.23
i4  2.24 0.91  6.50 10.92 11.32 7.79 7.78 10.69  9.15  1.07 -0.51 



--
View this message in context: http://r.789695.n4.nabble.com/S4-operator-Compatibility-issue-between-lme4-and-kml-tp4708236.html
Sent from the R help mailing list archive at Nabble.com.


From wht_crl at yahoo.com  Fri Jun  5 10:40:04 2015
From: wht_crl at yahoo.com (carol white)
Date: Fri, 5 Jun 2015 08:40:04 +0000 (UTC)
Subject: [R] building a list in a loop
Message-ID: <998671763.5563706.1433493604506.JavaMail.yahoo@mail.yahoo.com>

It might be an easy question but how to construct correctly a list in a loop? 

The following doesn't work
before starting the loopd = NULL#in the loop, 1st iteration
d = list(d,c(1,2,3)d[[1]]
NULL

[[2]]
[1] 1 2 3#in the loop, 2nd iterationd=list(d,c(4,5,6)d
[[1]]
[[1]][[1]]
NULL

[[1]][[2]]
[1] 1 2 3


[[2]]
[1] 4 5 6
the goal is to have the result of d= list(c(1,2,3),c(4,5,6)) where the list components are not known out of the loop.
d[[1]]
[1] 1 2 3

[[2]]
[1] 4 5 6
Moreover, how to name the components of the list in the loop while constructing as the names are not known out of the loop, either? note that the name of the component is stored in a variable in the loop

d = NULL#name1 contains the name for c(1,2,3), how to give the name below?
d = list(d,c(1,2,3)
Thanks
?
	[[alternative HTML version deleted]]


From Gerrit.Eichner at math.uni-giessen.de  Fri Jun  5 10:47:43 2015
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Fri, 5 Jun 2015 10:47:43 +0200 (MEST)
Subject: [R] [FORGED] Re: Dunnett Test in 'multicomp' package
In-Reply-To: <55715433.4060809@auckland.ac.nz>
References: <0CFDB87AFEBD36438EA1AFAF4ECA074F4ACF3D52@agc-exchange.suagcenter.net>
	<CAGx1TMD3eqOAVah4N-9E+AvEh7+6nGsfN_x1cqWpEOk4xD5Gyw@mail.gmail.com>
	<CA+8X3fUtyVe8Cg2tciNTgGbPSk5-s8H3tsLKfLp8Tpokag6fnQ@mail.gmail.com>
	<55715433.4060809@auckland.ac.nz>
Message-ID: <Pine.SOC.4.64.1506051044270.25362@solcom.hrz.uni-giessen.de>

Hello, everyone,

aside from Rolf's hint (and Richard's warning!) you could also consider 
relevel():

viagraData$dose <- relevel( viagraData$dose, ref = "placebo")

  Hth  --  Gerrit

On Fri, 5 Jun 2015, Rolf Turner wrote:

> On 05/06/15 11:08, Jim Lemon wrote:
>> Hi James,
>> You can change the order of levels like this:
>> 
>> levels(viagraData$dose)<-c("placebo","low dose","high dose")
>
> <SNIP>
>
> As Richard Heiberger has pointed out, this is wrong.
>
> What *does* work is:
>
> viagraData$dose)<-factor(viagraData$dose,
>                        levels=c("placebo","low dose","high dose")
>
> This is a trap into which many a Young Player (including my very good self) 
> has fallen.
>
> cheers,
>
> Rolf Turner
>
>
>
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maechler at stat.math.ethz.ch  Fri Jun  5 11:33:46 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 5 Jun 2015 11:33:46 +0200
Subject: [R] S4 / operator "[" : Compatibility issue between lme4 and kml
In-Reply-To: <1433489802634-4708236.post@n4.nabble.com>
References: <1433489802634-4708236.post@n4.nabble.com>
Message-ID: <21873.27898.56531.204015@stat.math.ethz.ch>

>>>>> Christophe Genolini <cgenolin at u-paris10.fr>
>>>>>     on Fri, 5 Jun 2015 00:36:42 -0700 writes:

    > Hi all,
    > There is a compatibility issue between the package 'lme4' and my package
    > 'kml'. I define the "[" operator. It works just fine in my package (1). If I
    > try to use the lme4 package, then it does no longer work (2). Moreover, it
    > has some kind of strange behavior (3). Do you know what is wrong? Any idea
    > of how I can correct that?

    > Here is a reproductible example, and the same code with the result follows.

Dear Christophe,
can you please specify the exact sessionInfo() ?
(after loading both kml and lme4).

'Matrix' has been updated on CRAN very recently, and 
'lme4' is about to be update very soon,
so this *is* a somewhat interesting and important problem,
but the exact versions of the packages *do* matter.

Bonnes salutations!

Martin Maechler
ETH Zurich


   [........................]


From petr.pikal at precheza.cz  Fri Jun  5 11:34:18 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 5 Jun 2015 09:34:18 +0000
Subject: [R] building a list in a loop
In-Reply-To: <612345870.5624726.1433495908413.JavaMail.yahoo@mail.yahoo.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2FB94@SRVEXCHMBX.precheza.cz>
	<612345870.5624726.1433495908413.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2FBEF@SRVEXCHMBX.precheza.cz>

Hi

I do not understand. My mind reading ambilities are limited.

Where do you get your vectors from?

Instead of
vec<-vec+3*(i-1)

you can use any computation to create any object.

d<-list()
n=2
for (i in 1:n) {
s<-sample(1:26, 10, replace=FALSE)
rn<-rnorm(10)
y<-rn*s*rnorm(1)+rnorm(1)
fit<-lm(y~s)
d[[i]]<-fit
names(d)[i] <- paste(letters[round(mean(s))],i, sep="")
}

So my opinion is that the code for populating list is pretty general.

Petr

From: carol white [mailto:wht_crl at yahoo.com]
Sent: Friday, June 05, 2015 11:18 AM
To: PIKAL Petr
Subject: Re: [R] building a list in a loop

vectors c(1,2,3) etc were an example. the general case should be considered if it is a character vector with the unknown elements out of the loop. the same as the name. your code can't be generalized.


On Friday, June 5, 2015 11:13 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:

Hi

It is not clear what exactly do you want.

d<-list()
vec<-1:3
for (i in 1:2) {
vec<-vec+3*(i-1)
d[[i]]<-vec
#names(d)[i] <- paste("name",i)
}

You can add names in second loop or you can use names command in first loop.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of carol
> white via R-help
> Sent: Friday, June 05, 2015 10:40 AM
> To: R-help Help
> Subject: [R] building a list in a loop
>
> It might be an easy question but how to construct correctly a list in a
> loop?
>
> The following doesn't work
> before starting the loopd = NULL#in the loop, 1st iteration
> d = list(d,c(1,2,3)d[[1]]
> NULL
>
> [[2]]
> [1] 1 2 3#in the loop, 2nd iterationd=list(d,c(4,5,6)d
> [[1]]
> [[1]][[1]]
> NULL
>
> [[1]][[2]]
> [1] 1 2 3
>
>
> [[2]]
> [1] 4 5 6
> the goal is to have the result of d= list(c(1,2,3),c(4,5,6)) where the
> list components are not known out of the loop.
> d[[1]]
> [1] 1 2 3
>
> [[2]]
> [1] 4 5 6
> Moreover, how to name the components of the list in the loop while
> constructing as the names are not known out of the loop, either? note
> that the name of the component is stored in a variable in the loop
>
> d = NULL#name1 contains the name for c(1,2,3), how to give the name
> below?
> d = list(d,c(1,2,3)
> Thanks

>
>      [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-<http://www.r-project.org/posting->
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.



________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Jun  5 11:36:07 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 5 Jun 2015 09:36:07 +0000
Subject: [R] building a list in a loop
In-Reply-To: <1132165080.5605545.1433496074460.JavaMail.yahoo@mail.yahoo.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2FB94@SRVEXCHMBX.precheza.cz>
	<1132165080.5605545.1433496074460.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2FBFE@SRVEXCHMBX.precheza.cz>

Hi

Can you please specify how loop without index shall be constructed? It is rather new topic for me.

Petr

From: carol white [mailto:wht_crl at yahoo.com]
Sent: Friday, June 05, 2015 11:21 AM
To: PIKAL Petr
Subject: Re: [R] building a list in a loop

also consider a loop without index (not like for (i ...) where index could be used for the list construction)

Cheers,


On Friday, June 5, 2015 11:13 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:

Hi

It is not clear what exactly do you want.

d<-list()
vec<-1:3
for (i in 1:2) {
vec<-vec+3*(i-1)
d[[i]]<-vec
#names(d)[i] <- paste("name",i)
}

You can add names in second loop or you can use names command in first loop.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of carol
> white via R-help
> Sent: Friday, June 05, 2015 10:40 AM
> To: R-help Help
> Subject: [R] building a list in a loop
>
> It might be an easy question but how to construct correctly a list in a
> loop?
>
> The following doesn't work
> before starting the loopd = NULL#in the loop, 1st iteration
> d = list(d,c(1,2,3)d[[1]]
> NULL
>
> [[2]]
> [1] 1 2 3#in the loop, 2nd iterationd=list(d,c(4,5,6)d
> [[1]]
> [[1]][[1]]
> NULL
>
> [[1]][[2]]
> [1] 1 2 3
>
>
> [[2]]
> [1] 4 5 6
> the goal is to have the result of d= list(c(1,2,3),c(4,5,6)) where the
> list components are not known out of the loop.
> d[[1]]
> [1] 1 2 3
>
> [[2]]
> [1] 4 5 6
> Moreover, how to name the components of the list in the loop while
> constructing as the names are not known out of the loop, either? note
> that the name of the component is stored in a variable in the loop
>
> d = NULL#name1 contains the name for c(1,2,3), how to give the name
> below?
> d = list(d,c(1,2,3)
> Thanks

>
>      [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-<http://www.r-project.org/posting->
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.



________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Jun  5 12:04:32 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 5 Jun 2015 10:04:32 +0000
Subject: [R] building a list in a loop
In-Reply-To: <1946289606.5588789.1433497861395.JavaMail.yahoo@mail.yahoo.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2FBFE@SRVEXCHMBX.precheza.cz>
	<1946289606.5588789.1433497861395.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2FC77@SRVEXCHMBX.precheza.cz>

Hi

This I do not consider as a loop without index.  AFAIK i is index and the loop is executed twice. First with i equal to ?a? and second time with i equal to ?b?.

In that case you need to have some objects which are named ?a? or ?b?  and you can use it for selection or computing

d<-list(a=NULL, b=NULL)
for (i in c("a","b")) {
d[[i]]<-1:3
}

Cheers
Petr

From: carol white [mailto:wht_crl at yahoo.com]
Sent: Friday, June 05, 2015 11:51 AM
To: PIKAL Petr
Subject: Re: [R] building a list in a loop

for (i in c("a","b"))

best,



On Friday, June 5, 2015 11:36 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:

Hi

Can you please specify how loop without index shall be constructed? It is rather new topic for me.

Petr

From: carol white [mailto:wht_crl at yahoo.com]
Sent: Friday, June 05, 2015 11:21 AM
To: PIKAL Petr
Subject: Re: [R] building a list in a loop

also consider a loop without index (not like for (i ...) where index could be used for the list construction)

Cheers,


On Friday, June 5, 2015 11:13 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:

Hi

It is not clear what exactly do you want.

d<-list()
vec<-1:3
for (i in 1:2) {
vec<-vec+3*(i-1)
d[[i]]<-vec
#names(d)[i] <- paste("name",i)
}

You can add names in second loop or you can use names command in first loop.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of carol
> white via R-help
> Sent: Friday, June 05, 2015 10:40 AM
> To: R-help Help
> Subject: [R] building a list in a loop
>
> It might be an easy question but how to construct correctly a list in a
> loop?
>
> The following doesn't work
> before starting the loopd = NULL#in the loop, 1st iteration
> d = list(d,c(1,2,3)d[[1]]
> NULL
>
> [[2]]
> [1] 1 2 3#in the loop, 2nd iterationd=list(d,c(4,5,6)d
> [[1]]
> [[1]][[1]]
> NULL
>
> [[1]][[2]]
> [1] 1 2 3
>
>
> [[2]]
> [1] 4 5 6
> the goal is to have the result of d= list(c(1,2,3),c(4,5,6)) where the
> list components are not known out of the loop.
> d[[1]]
> [1] 1 2 3
>
> [[2]]
> [1] 4 5 6
> Moreover, how to name the components of the list in the loop while
> constructing as the names are not known out of the loop, either? note
> that the name of the component is stored in a variable in the loop
>
> d = NULL#name1 contains the name for c(1,2,3), how to give the name
> below?
> d = list(d,c(1,2,3)
> Thanks

>
>      [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-<http://www.r-project.org/posting->
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.



________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Jun  5 12:21:43 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 5 Jun 2015 12:21:43 +0200
Subject: [R] S4 / operator "[" : Compatibility issue between lme4 and kml
In-Reply-To: <21873.27898.56531.204015@stat.math.ethz.ch>
References: <1433489802634-4708236.post@n4.nabble.com>
	<21873.27898.56531.204015@stat.math.ethz.ch>
Message-ID: <21873.30775.834285.510817@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Fri, 5 Jun 2015 11:33:46 +0200 writes:

>>>>> Christophe Genolini <cgenolin at u-paris10.fr>
>>>>>     on Fri, 5 Jun 2015 00:36:42 -0700 writes:

    >> Hi all,
    >> There is a compatibility issue between the package 'lme4' and my package
    >> 'kml'. I define the "[" operator. It works just fine in my package (1). If I
    >> try to use the lme4 package, then it does no longer work (2). Moreover, it
    >> has some kind of strange behavior (3). Do you know what is wrong? Any idea
    >> of how I can correct that?

    >> Here is a reproductible example, and the same code with the result follows.

    > Dear Christophe,
    > can you please specify the exact sessionInfo() ?
    > (after loading both kml and lme4).

    > 'Matrix' has been updated on CRAN very recently, and 
    > 'lme4' is about to be update very soon,
    > so this *is* a somewhat interesting and important problem,
    > but the exact versions of the packages *do* matter.

As a matter of fact,  

1) the package versions don't seem to matter much.

2) lme4 is *not* involved directly:
   Much worse, it is the 'Matrix' package.

If you replace 'lme4' by 'Matrix' in your code, you get the same
symptoms.

... I'm investigating ..

Martin


From wht_crl at yahoo.com  Fri Jun  5 13:30:50 2015
From: wht_crl at yahoo.com (carol white)
Date: Fri, 5 Jun 2015 11:30:50 +0000 (UTC)
Subject: [R] building a list in a loop
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2FC77@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2FC77@SRVEXCHMBX.precheza.cz>
Message-ID: <1693519655.5608368.1433503850208.JavaMail.yahoo@mail.yahoo.com>

in this example can elements of the list be accessed by their name if their name is the value of a variable?el = "a"can the first element d[[1]] be accessed by el instead of the list index like d$a but via el?
Thanks
 


     On Friday, June 5, 2015 12:04 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
   

 #yiv1728143486 #yiv1728143486 _filtered #yiv1728143486 {font-family:Helvetica;} _filtered #yiv1728143486 {font-family:Helvetica;} _filtered #yiv1728143486 {font-family:Calibri;} _filtered #yiv1728143486 {font-family:Tahoma;}#yiv1728143486 p.yiv1728143486MsoNormal, #yiv1728143486 li.yiv1728143486MsoNormal, #yiv1728143486 div.yiv1728143486MsoNormal {margin:0cm;margin-bottom:.0001pt;font-size:12.0pt;}#yiv1728143486 a:link, #yiv1728143486 span.yiv1728143486MsoHyperlink {color:blue;text-decoration:underline;}#yiv1728143486 a:visited, #yiv1728143486 span.yiv1728143486MsoHyperlinkFollowed {color:purple;text-decoration:underline;}#yiv1728143486 p.yiv1728143486MsoAcetate, #yiv1728143486 li.yiv1728143486MsoAcetate, #yiv1728143486 div.yiv1728143486MsoAcetate {margin:0cm;margin-bottom:.0001pt;font-size:8.0pt;}#yiv1728143486 p.yiv1728143486msonormal, #yiv1728143486 li.yiv1728143486msonormal, #yiv1728143486 div.yiv1728143486msonormal {margin-right:0cm;margin-left:0cm;font-size:12.0pt;}#yiv1728143486 p.yiv1728143486msochpdefault, #yiv1728143486 li.yiv1728143486msochpdefault, #yiv1728143486 div.yiv1728143486msochpdefault {margin-right:0cm;margin-left:0cm;font-size:12.0pt;}#yiv1728143486 span.yiv1728143486msohyperlink {}#yiv1728143486 span.yiv1728143486msohyperlinkfollowed {}#yiv1728143486 span.yiv1728143486style-mailovzprvy17 {}#yiv1728143486 p.yiv1728143486msonormal1, #yiv1728143486 li.yiv1728143486msonormal1, #yiv1728143486 div.yiv1728143486msonormal1 {margin:0cm;margin-bottom:.0001pt;font-size:12.0pt;}#yiv1728143486 span.yiv1728143486msohyperlink1 {color:blue;text-decoration:underline;}#yiv1728143486 span.yiv1728143486msohyperlinkfollowed1 {color:purple;text-decoration:underline;}#yiv1728143486 span.yiv1728143486style-mailovzprvy171 {color:#1F497D;}#yiv1728143486 p.yiv1728143486msochpdefault1, #yiv1728143486 li.yiv1728143486msochpdefault1, #yiv1728143486 div.yiv1728143486msochpdefault1 {margin-right:0cm;margin-left:0cm;font-size:10.0pt;}#yiv1728143486 span.yiv1728143486TextbublinyChar {}#yiv1728143486 span.yiv1728143486StylE-mailovZprvy29 {color:#1F497D;}#yiv1728143486 .yiv1728143486MsoChpDefault {font-size:10.0pt;} _filtered #yiv1728143486 {margin:70.85pt 70.85pt 70.85pt 70.85pt;}#yiv1728143486 div.yiv1728143486WordSection1 {}#yiv1728143486 Hi?This I do not consider as a loop without index. ?AFAIK i is index and the loop is executed twice. First with i equal to ?a? and second time with i equal to ?b?. ?In that case you need to have some objects which are named?a? or ?b? ?and you can use it for selection or computing?d<-list(a=NULL, b=NULL)for (i in c("a","b")) {d[[i]]<-1:3}?CheersPetr?From: carol white [mailto:wht_crl at yahoo.com]
Sent: Friday, June 05, 2015 11:51 AM
To: PIKAL Petr
Subject: Re: [R] building a list in a loop?for (i in c("a","b"))?best,???On Friday, June 5, 2015 11:36 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:?Hi?Can you please specify how loop without index shall be constructed? It is rather new topic for me.?Petr?From: carol white [mailto:wht_crl at yahoo.com]
Sent: Friday, June 05, 2015 11:21 AM
To: PIKAL Petr
Subject: Re: [R] building a list in a loop?also consider a loop without index (not like for (i ...) where index could be used for the list construction)?Cheers,??On Friday, June 5, 2015 11:13 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:?Hi

It is not clear what exactly do you want.

d<-list()
vec<-1:3
for (i in 1:2) {
vec<-vec+3*(i-1)
d[[i]]<-vec
#names(d)[i] <- paste("name",i)
}

You can add names in second loop or you can use names command in first loop.

Cheers
Petr
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of carol
> white via R-help
> Sent: Friday, June 05, 2015 10:40 AM
> To: R-help Help
> Subject: [R] building a list in a loop
>
> It might be an easy question but how to construct correctly a list in a
> loop?
>
> The following doesn't work
> before starting the loopd = NULL#in the loop, 1st iteration
> d = list(d,c(1,2,3)d[[1]]
> NULL
>
> [[2]]
> [1] 1 2 3#in the loop, 2nd iterationd=list(d,c(4,5,6)d
> [[1]]
> [[1]][[1]]
> NULL
>
> [[1]][[2]]
> [1] 1 2 3
>
>
> [[2]]
> [1] 4 5 6
> the goal is to have the result of d= list(c(1,2,3),c(4,5,6)) where the
> list components are not known out of the loop.
> d[[1]]
> [1] 1 2 3
>
> [[2]]
> [1] 4 5 6
> Moreover, how to name the components of the list in the loop while
> constructing as the names are not known out of the loop, either? note
> that the name of the component is stored in a variable in the loop
>
> d = NULL#name1 contains the name for c(1,2,3), how to give the name
> below?
> d = list(d,c(1,2,3)
> Thanks
>
>? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.???Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.?
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


  
	[[alternative HTML version deleted]]


From wht_crl at yahoo.com  Fri Jun  5 13:38:16 2015
From: wht_crl at yahoo.com (carol white)
Date: Fri, 5 Jun 2015 11:38:16 +0000 (UTC)
Subject: [R] building a list in a loop
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2FC77@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2FC77@SRVEXCHMBX.precheza.cz>
Message-ID: <947572066.5635266.1433504296238.JavaMail.yahoo@mail.yahoo.com>

Here is the best solution that I found as the list is built in the embedded functions withtout using loop index, list elements' names etc
d = list()d[[length(d)+1]] = 1:3d[[length(d)+1]] = 4:6
Many thanks for your help
 


     On Friday, June 5, 2015 12:04 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
   

 #yiv1728143486 #yiv1728143486 _filtered #yiv1728143486 {font-family:Helvetica;} _filtered #yiv1728143486 {font-family:Helvetica;} _filtered #yiv1728143486 {font-family:Calibri;} _filtered #yiv1728143486 {font-family:Tahoma;}#yiv1728143486 p.yiv1728143486MsoNormal, #yiv1728143486 li.yiv1728143486MsoNormal, #yiv1728143486 div.yiv1728143486MsoNormal {margin:0cm;margin-bottom:.0001pt;font-size:12.0pt;}#yiv1728143486 a:link, #yiv1728143486 span.yiv1728143486MsoHyperlink {color:blue;text-decoration:underline;}#yiv1728143486 a:visited, #yiv1728143486 span.yiv1728143486MsoHyperlinkFollowed {color:purple;text-decoration:underline;}#yiv1728143486 p.yiv1728143486MsoAcetate, #yiv1728143486 li.yiv1728143486MsoAcetate, #yiv1728143486 div.yiv1728143486MsoAcetate {margin:0cm;margin-bottom:.0001pt;font-size:8.0pt;}#yiv1728143486 p.yiv1728143486msonormal, #yiv1728143486 li.yiv1728143486msonormal, #yiv1728143486 div.yiv1728143486msonormal {margin-right:0cm;margin-left:0cm;font-size:12.0pt;}#yiv1728143486 p.yiv1728143486msochpdefault, #yiv1728143486 li.yiv1728143486msochpdefault, #yiv1728143486 div.yiv1728143486msochpdefault {margin-right:0cm;margin-left:0cm;font-size:12.0pt;}#yiv1728143486 span.yiv1728143486msohyperlink {}#yiv1728143486 span.yiv1728143486msohyperlinkfollowed {}#yiv1728143486 span.yiv1728143486style-mailovzprvy17 {}#yiv1728143486 p.yiv1728143486msonormal1, #yiv1728143486 li.yiv1728143486msonormal1, #yiv1728143486 div.yiv1728143486msonormal1 {margin:0cm;margin-bottom:.0001pt;font-size:12.0pt;}#yiv1728143486 span.yiv1728143486msohyperlink1 {color:blue;text-decoration:underline;}#yiv1728143486 span.yiv1728143486msohyperlinkfollowed1 {color:purple;text-decoration:underline;}#yiv1728143486 span.yiv1728143486style-mailovzprvy171 {color:#1F497D;}#yiv1728143486 p.yiv1728143486msochpdefault1, #yiv1728143486 li.yiv1728143486msochpdefault1, #yiv1728143486 div.yiv1728143486msochpdefault1 {margin-right:0cm;margin-left:0cm;font-size:10.0pt;}#yiv1728143486 span.yiv1728143486TextbublinyChar {}#yiv1728143486 span.yiv1728143486StylE-mailovZprvy29 {color:#1F497D;}#yiv1728143486 .yiv1728143486MsoChpDefault {font-size:10.0pt;} _filtered #yiv1728143486 {margin:70.85pt 70.85pt 70.85pt 70.85pt;}#yiv1728143486 div.yiv1728143486WordSection1 {}#yiv1728143486 Hi?This I do not consider as a loop without index. ?AFAIK i is index and the loop is executed twice. First with i equal to ?a? and second time with i equal to ?b?. ?In that case you need to have some objects which are named?a? or ?b? ?and you can use it for selection or computing?d<-list(a=NULL, b=NULL)for (i in c("a","b")) {d[[i]]<-1:3}?CheersPetr?From: carol white [mailto:wht_crl at yahoo.com]
Sent: Friday, June 05, 2015 11:51 AM
To: PIKAL Petr
Subject: Re: [R] building a list in a loop?for (i in c("a","b"))?best,???On Friday, June 5, 2015 11:36 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:?Hi?Can you please specify how loop without index shall be constructed? It is rather new topic for me.?Petr?From: carol white [mailto:wht_crl at yahoo.com]
Sent: Friday, June 05, 2015 11:21 AM
To: PIKAL Petr
Subject: Re: [R] building a list in a loop?also consider a loop without index (not like for (i ...) where index could be used for the list construction)?Cheers,??On Friday, June 5, 2015 11:13 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:?Hi

It is not clear what exactly do you want.

d<-list()
vec<-1:3
for (i in 1:2) {
vec<-vec+3*(i-1)
d[[i]]<-vec
#names(d)[i] <- paste("name",i)
}

You can add names in second loop or you can use names command in first loop.

Cheers
Petr
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of carol
> white via R-help
> Sent: Friday, June 05, 2015 10:40 AM
> To: R-help Help
> Subject: [R] building a list in a loop
>
> It might be an easy question but how to construct correctly a list in a
> loop?
>
> The following doesn't work
> before starting the loopd = NULL#in the loop, 1st iteration
> d = list(d,c(1,2,3)d[[1]]
> NULL
>
> [[2]]
> [1] 1 2 3#in the loop, 2nd iterationd=list(d,c(4,5,6)d
> [[1]]
> [[1]][[1]]
> NULL
>
> [[1]][[2]]
> [1] 1 2 3
>
>
> [[2]]
> [1] 4 5 6
> the goal is to have the result of d= list(c(1,2,3),c(4,5,6)) where the
> list components are not known out of the loop.
> d[[1]]
> [1] 1 2 3
>
> [[2]]
> [1] 4 5 6
> Moreover, how to name the components of the list in the loop while
> constructing as the names are not known out of the loop, either? note
> that the name of the component is stored in a variable in the loop
>
> d = NULL#name1 contains the name for c(1,2,3), how to give the name
> below?
> d = list(d,c(1,2,3)
> Thanks
>
>? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.???Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.?
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


  
	[[alternative HTML version deleted]]


From knussear at mac.com  Fri Jun  5 13:45:25 2015
From: knussear at mac.com (Ken Nussear)
Date: Fri, 05 Jun 2015 04:45:25 -0700
Subject: [R] Are melt and dcast with ffdf possible?
Message-ID: <55718BD5.1070202@mac.com>

Having trouble getting melt and dcast to work with ffdf

 I'm trying to cast 3 columns to a square matrix

With a regular data.frame.....

comb <- expand.grid((1:10),(1:10))
dim(comb)
comb$Dist <- (1:100)
c.melt <- melt(comb, id.vars=c("Var1","Var2"))
dcast(c.melt,Var2~Var1)

goes from
> comb
    Var1 Var2 Dist
1      1    1    1
2      2    1    2
3      3    1    3
4      4    1    4
5      5    1    5
6      6    1    6
.....
to

> c.melt
    Var1 Var2 variable value
1      1    1     Dist     1
2      2    1     Dist     2
3      3    1     Dist     3
4      4    1     Dist     4
5      5    1     Dist     5
6      6    1     Dist     6
.....
to
> dcast(c.melt,Var1~Var2)
   Var1  1  2  3  4  5  6  7  8  9  10
1     1  1 11 21 31 41 51 61 71 81  91
2     2  2 12 22 32 42 52 62 72 82  92
3     3  3 13 23 33 43 53 63 73 83  93
4     4  4 14 24 34 44 54 64 74 84  94
5     5  5 15 25 35 45 55 65 75 85  95
6     6  6 16 26 36 46 56 66 76 86  96
7     7  7 17 27 37 47 57 67 77 87  97
8     8  8 18 28 38 48 58 68 78 88  98
9     9  9 19 29 39 49 59 69 79 89  99
10   10 10 20 30 40 50 60 70 80 90 100

no trouble.

With ffdf it breaks on the melt step
comb.ff <- expand.ffgrid(ff(1:10),ff(1:10))
dim(comb.ff)
comb.ff$Dist <- ff(1:100)


> comb.ff
ffdf (all open) dim=c(100,3), dimorder=c(1,2) row.names=NULL
ffdf virtual mapping
     PhysicalName VirtualVmode PhysicalVmode  AsIs VirtualIsMatrix
PhysicalIsMatrix PhysicalElementNo PhysicalFirstCol PhysicalLastCol
PhysicalIsOpen
Var1         Var1      integer       integer FALSE          
FALSE            FALSE                 1                1              
1           TRUE
Var2         Var2      integer       integer FALSE          
FALSE            FALSE                 2                1              
1           TRUE
Dist         Dist      integer       integer FALSE          
FALSE            FALSE                 3                1              
1           TRUE
ffdf data
    Var1 Var2 Dist
1      1    1    1
2      2    1    2
3      3    1    3
4      4    1    4
5      5    1    5
6      6    1    6
....
c.melt.ff <- melt(comb.ff, id.vars=c("Var1","Var2"))
> c.melt.ff
    value NA  NA
1       1  1   1
2       2  1   2
3       3  1   3
4       4  1   4
5       5  1   5
6       6  1   6
7       7  1   7
.....

Is it possible to use this method with ffdf?

I appreciate any help

Ken


From petr.pikal at precheza.cz  Fri Jun  5 14:00:18 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 5 Jun 2015 12:00:18 +0000
Subject: [R] building a list in a loop
In-Reply-To: <1693519655.5608368.1433503850208.JavaMail.yahoo@mail.yahoo.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2FC77@SRVEXCHMBX.precheza.cz>
	<1693519655.5608368.1433503850208.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2FD5A@SRVEXCHMBX.precheza.cz>

Hi

I do not understand. ?i? is variable and list elements are called by this variable

#constructing list
> d<-as.list(sample(letters[1:5], 5, replace=F))
> names(d) <- letters[1:5]
> d
$a
[1] "c"
$b
[1] "a"
$c
[1] "e"
$d
[1] "b"
$e
[1] "d"

#variable el
> el<-"a"

#result
> d[[el]]<-"whatever I want to put under name a"
> d
$a
[1] "whatever I want to put under name a"
$b
[1] "a"
$c
[1] "e"
$d
[1] "b"
$e
[1] "d"

Cheers
Petr


From: carol white [mailto:wht_crl at yahoo.com]
Sent: Friday, June 05, 2015 1:31 PM
To: PIKAL Petr
Cc: r-help at r-project.org
Subject: Re: [R] building a list in a loop

in this example can elements of the list be accessed by their name if their name is the value of a variable?
el = "a"
can the first element d[[1]] be accessed by el instead of the list index like d$a but via el?

Thanks


On Friday, June 5, 2015 12:04 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:

Hi

This I do not consider as a loop without index.  AFAIK i is index and the loop is executed twice. First with i equal to ?a? and second time with i equal to ?b?.

In that case you need to have some objects which are named ?a? or ?b?  and you can use it for selection or computing

d<-list(a=NULL, b=NULL)
for (i in c("a","b")) {
d[[i]]<-1:3
}

Cheers
Petr

From: carol white [mailto:wht_crl at yahoo.com]
Sent: Friday, June 05, 2015 11:51 AM
To: PIKAL Petr
Subject: Re: [R] building a list in a loop

for (i in c("a","b"))

best,



On Friday, June 5, 2015 11:36 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:

Hi

Can you please specify how loop without index shall be constructed? It is rather new topic for me.

Petr

From: carol white [mailto:wht_crl at yahoo.com]
Sent: Friday, June 05, 2015 11:21 AM
To: PIKAL Petr
Subject: Re: [R] building a list in a loop

also consider a loop without index (not like for (i ...) where index could be used for the list construction)

Cheers,


On Friday, June 5, 2015 11:13 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:

Hi

It is not clear what exactly do you want.

d<-list()
vec<-1:3
for (i in 1:2) {
vec<-vec+3*(i-1)
d[[i]]<-vec
#names(d)[i] <- paste("name",i)
}

You can add names in second loop or you can use names command in first loop.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of carol
> white via R-help
> Sent: Friday, June 05, 2015 10:40 AM
> To: R-help Help
> Subject: [R] building a list in a loop
>
> It might be an easy question but how to construct correctly a list in a
> loop?
>
> The following doesn't work
> before starting the loopd = NULL#in the loop, 1st iteration
> d = list(d,c(1,2,3)d[[1]]
> NULL
>
> [[2]]
> [1] 1 2 3#in the loop, 2nd iterationd=list(d,c(4,5,6)d
> [[1]]
> [[1]][[1]]
> NULL
>
> [[1]][[2]]
> [1] 1 2 3
>
>
> [[2]]
> [1] 4 5 6
> the goal is to have the result of d= list(c(1,2,3),c(4,5,6)) where the
> list components are not known out of the loop.
> d[[1]]
> [1] 1 2 3
>
> [[2]]
> [1] 4 5 6
> Moreover, how to name the components of the list in the loop while
> constructing as the names are not known out of the loop, either? note
> that the name of the component is stored in a variable in the loop
>
> d = NULL#name1 contains the name for c(1,2,3), how to give the name
> below?
> d = list(d,c(1,2,3)
> Thanks

>
>      [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-<http://www.r-project.org/posting->
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.



________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From roslinaump at gmail.com  Fri Jun  5 10:49:08 2015
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Fri, 5 Jun 2015 16:49:08 +0800
Subject: [R] if else statement for rain data to define zero for dry and one
	to wet
Message-ID: <CANTvJZL6oUjX_Qn9oJXuGKQ85Pjh5HK2q4JrOpafWdNMBvQstQ@mail.gmail.com>

Dear r-users,

I have a set of rain data:

X1950 X1951 X1952 X1953 X1954 X1955 X1956 X1957 X1958 X1959 X1960 X1961
X1962

1   0.0   0.0  14.3   0.0  13.5  13.2   4.0     0   3.3     0     0   0.0


2   0.0   0.0  21.9   0.0  10.9   6.6   2.1     0   0.0     0     0   0.0


3  25.3   6.7  18.6   0.8   2.3   0.0   8.0     0   0.0     0     0  11.0


4  12.7   3.4  37.2   0.9   8.4   0.0   5.8     0   0.0     0     0   5.5


5   0.0   0.0  58.3   3.6  21.1   4.2   3.0     0   0.0     0     0  15.9


I would like to go through each column and define each cell with value
greater than 0.1 mm will be 1 and else zero. Hence I would like to attach
the rain data and the category side by side:


1950   state

1 0.0    0

2 0.0    0

3 25.3   1

4 12.7   1

5 0.0    0


...


This is my code:


wet_dry  <- function(dt)

{ cl   <- length(dt)

  tresh  <- 0.1


  for (i in 1:cl)

  {  xi <- dt[,i]

     if (xi < tresh ) 0 else 1

  }

dd <- cbind(dt,xi)

dd

}


wet_dry(dt)


Results:

> wet_dry(dt)

   X1950 X1951 X1952 X1953 X1954 X1955 X1956 X1957 X1958 X1959 X1960 X1961
X1962 X1963 X1964 X1965 X1966 X1967 X1968 X1969 X1970 X1971 X1972 X1973
X1974 X1975 X1976 X1977

1    0.0   0.0  14.3   0.0  13.5  13.2   4.0   0.0   3.3   0.0   0.0   0.0
  4.2   0.0   2.2   0.0   4.4   5.1     0   7.2   0.0   0.0   0.0   5.1
0   0.0     0   0.3

2    0.0   0.0  21.9   0.0  10.9   6.6   2.1   0.0   0.0   0.0   0.0   0.0
  8.4   0.0   4.0   0.0   4.9   0.7     0   0.0   0.0   0.0   0.0   5.4
0   3.3     0   0.3

3   25.3   6.7  18.6   0.8   2.3   0.0   8.0   0.0   0.0   0.0   0.0  11.0
  4.2   0.0   2.0   0.0  14.2  17.1     0   0.0   0.0   0.0   0.0   2.1
0   1.7     0   4.4

4   12.7   3.4  37.2   0.9   8.4   0.0   5.8   0.0   0.0   0.0   0.0   5.5
  0.0   0.0   5.4   0.0   6.4  14.9     0  10.1   2.9 143.4   0.0   6.1
0   0.0     0  33.5


It does not work and give me the original data.  Why is that?


Thank you so much for your help.

	[[alternative HTML version deleted]]


From topijush at gmail.com  Fri Jun  5 12:57:46 2015
From: topijush at gmail.com (Pijush Das)
Date: Fri, 5 Jun 2015 16:27:46 +0530
Subject: [R] R to HTML problem
Message-ID: <CAGa91zi-_9kaC+UAsPdh0q+oC50VzY2w4nbr3sDps3pVJmCbbA@mail.gmail.com>

Hi r-help,


I am trying to develop a program in R where I want to display the
out put result in a HTML page. But I unable to put two tables side by side
which is required to me. Another problem is that I unable to put the title
in the center of the
page. The code is given below.


Please help me.

library(R2HTML)
filepath<-"C:/Users/Desktop/Selection"
target <- HTMLInitFile(filepath,filename="sample",
BackGroundColor="#FFFFFF")
HTML.title("Output of Class Prediction",file=target, HR=3)
HTML("<br>",file=target)
HTML("The output result is given below:",file=target)
HTML(iris[1:10,1:4], file=target,align = "left",Border = 1, innerBorder = 1)
HTML(iris[1:10,1:4], file=target,align = "left",Border = 1, innerBorder = 1)
HTMLEndFile()


Thank you.

Regards
Pijush

	[[alternative HTML version deleted]]


From johnwasige at gmail.com  Fri Jun  5 14:33:49 2015
From: johnwasige at gmail.com (John Wasige)
Date: Fri, 5 Jun 2015 14:33:49 +0200
Subject: [R] Changing colours for heatmap plot
Message-ID: <CAJgdCD6Tj-_FuYA0YHkNc78y+vR92DUPRg9tnAP34AWJqt+hNw@mail.gmail.com>

?Dear community,

Could somebody help on how I can change the colour for this plot in the
heatmap plot script below to something like c("green", "green", "black",
"green", "green", "black", "black", "green", "green", "black"):

######
library(gplots)
library(lattice)

### loading data
data <- read.csv('D:/Londa/MyData.csv')
rowcolNames <- list(as.character(1980:2009), month.abb)
air_data <- matrix(data ,
                   ncol = 12,
                   byrow = TRUE,
                   dimnames = rowcolNames)

print(levelplot(air_data,
                col.regions=heat.colors,
                xlab = "year",
                ylab = "month",
                main = "New #1"))?

##########

Thanks for your help

John

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Jun  5 14:35:42 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 5 Jun 2015 12:35:42 +0000
Subject: [R] if else statement for rain data to define zero for dry and
 one	to wet
In-Reply-To: <CANTvJZL6oUjX_Qn9oJXuGKQ85Pjh5HK2q4JrOpafWdNMBvQstQ@mail.gmail.com>
References: <CANTvJZL6oUjX_Qn9oJXuGKQ85Pjh5HK2q4JrOpafWdNMBvQstQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2FDAC@SRVEXCHMBX.precheza.cz>

Hi

I will not inspect your function as it is corrupted by HTML posting.

If your data frame is named rain

newrain <- (rain>.1)*1

gives you new data frame with reqired coding.

However I am not sure, what do you want to do next. Do you want to merge those 2 data frames so as coded column is beside original column? Why? What do you want to do with such merged data? It seems to me without sense.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> roslinazairimah zakaria
> Sent: Friday, June 05, 2015 10:49 AM
> To: r-help at r-project.org
> Subject: [R] if else statement for rain data to define zero for dry and
> one to wet
>
> Dear r-users,
>
> I have a set of rain data:
>
> X1950 X1951 X1952 X1953 X1954 X1955 X1956 X1957 X1958 X1959 X1960 X1961
> X1962
>
> 1   0.0   0.0  14.3   0.0  13.5  13.2   4.0     0   3.3     0     0
> 0.0
>
>
> 2   0.0   0.0  21.9   0.0  10.9   6.6   2.1     0   0.0     0     0
> 0.0
>
>
> 3  25.3   6.7  18.6   0.8   2.3   0.0   8.0     0   0.0     0     0
> 11.0
>
>
> 4  12.7   3.4  37.2   0.9   8.4   0.0   5.8     0   0.0     0     0
> 5.5
>
>
> 5   0.0   0.0  58.3   3.6  21.1   4.2   3.0     0   0.0     0     0
> 15.9
>
>
> I would like to go through each column and define each cell with value
> greater than 0.1 mm will be 1 and else zero. Hence I would like to
> attach the rain data and the category side by side:
>
>
> 1950   state
>
> 1 0.0    0
>
> 2 0.0    0
>
> 3 25.3   1
>
> 4 12.7   1
>
> 5 0.0    0
>
>
> ...
>
>
> This is my code:
>
>
> wet_dry  <- function(dt)
>
> { cl   <- length(dt)
>
>   tresh  <- 0.1
>
>
>   for (i in 1:cl)
>
>   {  xi <- dt[,i]
>
>      if (xi < tresh ) 0 else 1
>
>   }
>
> dd <- cbind(dt,xi)
>
> dd
>
> }
>
>
> wet_dry(dt)
>
>
> Results:
>
> > wet_dry(dt)
>
>    X1950 X1951 X1952 X1953 X1954 X1955 X1956 X1957 X1958 X1959 X1960
> X1961
> X1962 X1963 X1964 X1965 X1966 X1967 X1968 X1969 X1970 X1971 X1972 X1973
> X1974 X1975 X1976 X1977
>
> 1    0.0   0.0  14.3   0.0  13.5  13.2   4.0   0.0   3.3   0.0   0.0
> 0.0
>   4.2   0.0   2.2   0.0   4.4   5.1     0   7.2   0.0   0.0   0.0   5.1
> 0   0.0     0   0.3
>
> 2    0.0   0.0  21.9   0.0  10.9   6.6   2.1   0.0   0.0   0.0   0.0
> 0.0
>   8.4   0.0   4.0   0.0   4.9   0.7     0   0.0   0.0   0.0   0.0   5.4
> 0   3.3     0   0.3
>
> 3   25.3   6.7  18.6   0.8   2.3   0.0   8.0   0.0   0.0   0.0   0.0
> 11.0
>   4.2   0.0   2.0   0.0  14.2  17.1     0   0.0   0.0   0.0   0.0   2.1
> 0   1.7     0   4.4
>
> 4   12.7   3.4  37.2   0.9   8.4   0.0   5.8   0.0   0.0   0.0   0.0
> 5.5
>   0.0   0.0   5.4   0.0   6.4  14.9     0  10.1   2.9 143.4   0.0   6.1
> 0   0.0     0  33.5
>
>
> It does not work and give me the original data.  Why is that?
>
>
> Thank you so much for your help.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From sergio.fonda99 at gmail.com  Fri Jun  5 15:06:34 2015
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Fri, 5 Jun 2015 15:06:34 +0200
Subject: [R] Matrix of indexes to extract sparse data in dataframe
Message-ID: <CAJRuHor4q8CHPdQL4u3m-wLX2c=Q4wwLg=0UnGMZK=iOqwDWuw@mail.gmail.com>

I would like to avoid a "for loop" to get a vector of data taken from
rows of a data frame for specific columns.
An example is the following (I can't apply min to every row of df, this is
just an example):

c0=data.frame(a=c(3,-2,12,7,-23,17) , b=c(-1,-3,14,2,6,19))
c1=apply(c0,1,which.min)
> c1
[1] 2 2 1 2 1 1

I would like to get a result like the following call, but without
employing a "for loop":

d1=c(c0[1,c1[1]], c0[2,c1[2]], c0[3,c1[3]], c0[4,c1[4]], c0[5,c1[5]],
c0[6,c1[6]])
> d1
[1]  -1  -3  12   2 -23  17

Thanks a lot for any help!


From jrkrideau at inbox.com  Fri Jun  5 15:39:33 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 5 Jun 2015 05:39:33 -0800
Subject: [R] Matrix of indexes to extract sparse data in dataframe
In-Reply-To: <CAJRuHor4q8CHPdQL4u3m-wLX2c=Q4wwLg=0UnGMZK=iOqwDWuw@mail.gmail.com>
Message-ID: <D6922E39171.00000434jrkrideau@inbox.com>

d1  <-  apply(c0, 1, min)  I think does it.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: sergio.fonda99 at gmail.com
> Sent: Fri, 5 Jun 2015 15:06:34 +0200
> To: r-help at r-project.org
> Subject: [R] Matrix of indexes to extract sparse data in dataframe
> 
> I would like to avoid a "for loop" to get a vector of data taken from
> rows of a data frame for specific columns.
> An example is the following (I can't apply min to every row of df, this
> is
> just an example):
> 
> c0=data.frame(a=c(3,-2,12,7,-23,17) , b=c(-1,-3,14,2,6,19))
> c1=apply(c0,1,which.min)
>> c1
> [1] 2 2 1 2 1 1
> 
> I would like to get a result like the following call, but without
> employing a "for loop":
> 
> d1=c(c0[1,c1[1]], c0[2,c1[2]], c0[3,c1[3]], c0[4,c1[4]], c0[5,c1[5]],
> c0[6,c1[6]])
>> d1
> [1]  -1  -3  12   2 -23  17
> 
> Thanks a lot for any help!
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From jrkrideau at inbox.com  Fri Jun  5 15:41:45 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 5 Jun 2015 05:41:45 -0800
Subject: [R] if else statement for rain data to define zero for dry and
 one to wet
In-Reply-To: <CANTvJZL6oUjX_Qn9oJXuGKQ85Pjh5HK2q4JrOpafWdNMBvQstQ@mail.gmail.com>
Message-ID: <D69718E661A.0000043Bjrkrideau@inbox.com>

Please do not post in HTML. It made your posting unreadable.  R-help is a plain text list and when it removes all the HTML tags often the result is gibberish

Have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html for some suggestions on how to post to R-help.


John Kane
Kingston ON Canada


> -----Original Message-----
> From: roslinaump at gmail.com
> Sent: Fri, 5 Jun 2015 16:49:08 +0800
> To: r-help at r-project.org
> Subject: [R] if else statement for rain data to define zero for dry and
> one to wet
> 
> Dear r-users,
> 
> I have a set of rain data:
> 
> X1950 X1951 X1952 X1953 X1954 X1955 X1956 X1957 X1958 X1959 X1960 X1961
> X1962
> 
> 1   0.0   0.0  14.3   0.0  13.5  13.2   4.0     0   3.3     0     0   0.0
> 
> 
> 2   0.0   0.0  21.9   0.0  10.9   6.6   2.1     0   0.0     0     0   0.0
> 
> 
> 3  25.3   6.7  18.6   0.8   2.3   0.0   8.0     0   0.0     0     0  11.0
> 
> 
> 4  12.7   3.4  37.2   0.9   8.4   0.0   5.8     0   0.0     0     0   5.5
> 
> 
> 5   0.0   0.0  58.3   3.6  21.1   4.2   3.0     0   0.0     0     0  15.9
> 
> 
> I would like to go through each column and define each cell with value
> greater than 0.1 mm will be 1 and else zero. Hence I would like to attach
> the rain data and the category side by side:
> 
> 
> 1950   state
> 
> 1 0.0    0
> 
> 2 0.0    0
> 
> 3 25.3   1
> 
> 4 12.7   1
> 
> 5 0.0    0
> 
> 
> ...
> 
> 
> This is my code:
> 
> 
> wet_dry  <- function(dt)
> 
> { cl   <- length(dt)
> 
>   tresh  <- 0.1
> 
> 
>   for (i in 1:cl)
> 
>   {  xi <- dt[,i]
> 
>      if (xi < tresh ) 0 else 1
> 
>   }
> 
> dd <- cbind(dt,xi)
> 
> dd
> 
> }
> 
> 
> wet_dry(dt)
> 
> 
> Results:
> 
>> wet_dry(dt)
> 
>    X1950 X1951 X1952 X1953 X1954 X1955 X1956 X1957 X1958 X1959 X1960
> X1961
> X1962 X1963 X1964 X1965 X1966 X1967 X1968 X1969 X1970 X1971 X1972 X1973
> X1974 X1975 X1976 X1977
> 
> 1    0.0   0.0  14.3   0.0  13.5  13.2   4.0   0.0   3.3   0.0   0.0
> 0.0
>   4.2   0.0   2.2   0.0   4.4   5.1     0   7.2   0.0   0.0   0.0   5.1
> 0   0.0     0   0.3
> 
> 2    0.0   0.0  21.9   0.0  10.9   6.6   2.1   0.0   0.0   0.0   0.0
> 0.0
>   8.4   0.0   4.0   0.0   4.9   0.7     0   0.0   0.0   0.0   0.0   5.4
> 0   3.3     0   0.3
> 
> 3   25.3   6.7  18.6   0.8   2.3   0.0   8.0   0.0   0.0   0.0   0.0
> 11.0
>   4.2   0.0   2.0   0.0  14.2  17.1     0   0.0   0.0   0.0   0.0   2.1
> 0   1.7     0   4.4
> 
> 4   12.7   3.4  37.2   0.9   8.4   0.0   5.8   0.0   0.0   0.0   0.0
> 5.5
>   0.0   0.0   5.4   0.0   6.4  14.9     0  10.1   2.9 143.4   0.0   6.1
> 0   0.0     0  33.5
> 
> 
> It does not work and give me the original data.  Why is that?
> 
> 
> Thank you so much for your help.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From sergio.fonda99 at gmail.com  Fri Jun  5 15:46:49 2015
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Fri, 5 Jun 2015 15:46:49 +0200
Subject: [R] Matrix of indexes to extract sparse data in dataframe
In-Reply-To: <D6922E39171.00000434jrkrideau@inbox.com>
References: <CAJRuHor4q8CHPdQL4u3m-wLX2c=Q4wwLg=0UnGMZK=iOqwDWuw@mail.gmail.com>
	<D6922E39171.00000434jrkrideau@inbox.com>
Message-ID: <CAJRuHoq7rwGoJXjwDrZFYCe8tgTRkhhAZ3yVJ=yh2rasQ3=ydQ@mail.gmail.com>

Thank you, of course but I can't use that form as I told. My question is
about the possibility to enter in a dataframe with a matrix of indices and
get the corresponding values
Thanks again
 Il 05/giu/2015 15:39, "John Kane" <jrkrideau at inbox.com> ha scritto:

> d1  <-  apply(c0, 1, min)  I think does it.
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: sergio.fonda99 at gmail.com
> > Sent: Fri, 5 Jun 2015 15:06:34 +0200
> > To: r-help at r-project.org
> > Subject: [R] Matrix of indexes to extract sparse data in dataframe
> >
> > I would like to avoid a "for loop" to get a vector of data taken from
> > rows of a data frame for specific columns.
> > An example is the following (I can't apply min to every row of df, this
> > is
> > just an example):
> >
> > c0=data.frame(a=c(3,-2,12,7,-23,17) , b=c(-1,-3,14,2,6,19))
> > c1=apply(c0,1,which.min)
> >> c1
> > [1] 2 2 1 2 1 1
> >
> > I would like to get a result like the following call, but without
> > employing a "for loop":
> >
> > d1=c(c0[1,c1[1]], c0[2,c1[2]], c0[3,c1[3]], c0[4,c1[4]], c0[5,c1[5]],
> > c0[6,c1[6]])
> >> d1
> > [1]  -1  -3  12   2 -23  17
> >
> > Thanks a lot for any help!
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/password-manager
>
>
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri Jun  5 15:57:53 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 5 Jun 2015 13:57:53 +0000
Subject: [R] Matrix of indexes to extract sparse data in dataframe
In-Reply-To: <CAJRuHoq7rwGoJXjwDrZFYCe8tgTRkhhAZ3yVJ=yh2rasQ3=ydQ@mail.gmail.com>
References: <CAJRuHor4q8CHPdQL4u3m-wLX2c=Q4wwLg=0UnGMZK=iOqwDWuw@mail.gmail.com>
	<D6922E39171.00000434jrkrideau@inbox.com>
	<CAJRuHoq7rwGoJXjwDrZFYCe8tgTRkhhAZ3yVJ=yh2rasQ3=ydQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D690CC7@mb02.ads.tamu.edu>

You can select elements of a matrix using a 2 dimensional matrix that specifies the row/column number of the cells you want to extract:

> c2 <- cbind(seq_len(nrow(c0)), c1)
> c2
       c1
[1,] 1  2
[2,] 2  2
[3,] 3  1
[4,] 4  2
[5,] 5  1
[6,] 6  1
> d1 <- c0[c2]
> d1
[1]  -1  -3  12   2 -23  17

See the help page for [

?'['

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sergio Fonda
Sent: Friday, June 5, 2015 8:47 AM
To: John Kane
Cc: R-help
Subject: Re: [R] Matrix of indexes to extract sparse data in dataframe

Thank you, of course but I can't use that form as I told. My question is
about the possibility to enter in a dataframe with a matrix of indices and
get the corresponding values
Thanks again
 Il 05/giu/2015 15:39, "John Kane" <jrkrideau at inbox.com> ha scritto:

> d1  <-  apply(c0, 1, min)  I think does it.
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: sergio.fonda99 at gmail.com
> > Sent: Fri, 5 Jun 2015 15:06:34 +0200
> > To: r-help at r-project.org
> > Subject: [R] Matrix of indexes to extract sparse data in dataframe
> >
> > I would like to avoid a "for loop" to get a vector of data taken from
> > rows of a data frame for specific columns.
> > An example is the following (I can't apply min to every row of df, this
> > is
> > just an example):
> >
> > c0=data.frame(a=c(3,-2,12,7,-23,17) , b=c(-1,-3,14,2,6,19))
> > c1=apply(c0,1,which.min)
> >> c1
> > [1] 2 2 1 2 1 1
> >
> > I would like to get a result like the following call, but without
> > employing a "for loop":
> >
> > d1=c(c0[1,c1[1]], c0[2,c1[2]], c0[3,c1[3]], c0[4,c1[4]], c0[5,c1[5]],
> > c0[6,c1[6]])
> >> d1
> > [1]  -1  -3  12   2 -23  17
> >
> > Thanks a lot for any help!
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/password-manager
>
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From sergio.fonda99 at gmail.com  Fri Jun  5 16:05:07 2015
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Fri, 5 Jun 2015 16:05:07 +0200
Subject: [R] Matrix of indexes to extract sparse data in dataframe
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D690CC7@mb02.ads.tamu.edu>
References: <CAJRuHor4q8CHPdQL4u3m-wLX2c=Q4wwLg=0UnGMZK=iOqwDWuw@mail.gmail.com>
	<D6922E39171.00000434jrkrideau@inbox.com>
	<CAJRuHoq7rwGoJXjwDrZFYCe8tgTRkhhAZ3yVJ=yh2rasQ3=ydQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D690CC7@mb02.ads.tamu.edu>
Message-ID: <CAJRuHooy3Xth4fy4x26b5hnPpVWOeoy1yY6bsUW9p+vtgZB=Aw@mail.gmail.com>

Thank you very much!
Il 05/giu/2015 15:58, "David L Carlson" <dcarlson at tamu.edu> ha scritto:

> You can select elements of a matrix using a 2 dimensional matrix that
> specifies the row/column number of the cells you want to extract:
>
> > c2 <- cbind(seq_len(nrow(c0)), c1)
> > c2
>        c1
> [1,] 1  2
> [2,] 2  2
> [3,] 3  1
> [4,] 4  2
> [5,] 5  1
> [6,] 6  1
> > d1 <- c0[c2]
> > d1
> [1]  -1  -3  12   2 -23  17
>
> See the help page for [
>
> ?'['
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sergio
> Fonda
> Sent: Friday, June 5, 2015 8:47 AM
> To: John Kane
> Cc: R-help
> Subject: Re: [R] Matrix of indexes to extract sparse data in dataframe
>
> Thank you, of course but I can't use that form as I told. My question is
> about the possibility to enter in a dataframe with a matrix of indices and
> get the corresponding values
> Thanks again
>  Il 05/giu/2015 15:39, "John Kane" <jrkrideau at inbox.com> ha scritto:
>
> > d1  <-  apply(c0, 1, min)  I think does it.
> >
> > John Kane
> > Kingston ON Canada
> >
> >
> > > -----Original Message-----
> > > From: sergio.fonda99 at gmail.com
> > > Sent: Fri, 5 Jun 2015 15:06:34 +0200
> > > To: r-help at r-project.org
> > > Subject: [R] Matrix of indexes to extract sparse data in dataframe
> > >
> > > I would like to avoid a "for loop" to get a vector of data taken from
> > > rows of a data frame for specific columns.
> > > An example is the following (I can't apply min to every row of df, this
> > > is
> > > just an example):
> > >
> > > c0=data.frame(a=c(3,-2,12,7,-23,17) , b=c(-1,-3,14,2,6,19))
> > > c1=apply(c0,1,which.min)
> > >> c1
> > > [1] 2 2 1 2 1 1
> > >
> > > I would like to get a result like the following call, but without
> > > employing a "for loop":
> > >
> > > d1=c(c0[1,c1[1]], c0[2,c1[2]], c0[3,c1[3]], c0[4,c1[4]], c0[5,c1[5]],
> > > c0[6,c1[6]])
> > >> d1
> > > [1]  -1  -3  12   2 -23  17
> > >
> > > Thanks a lot for any help!
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ____________________________________________________________
> > Can't remember your password? Do you need a strong and secure password?
> > Use Password manager! It stores your passwords & protects your account.
> > Check it out at http://mysecurelogon.com/password-manager
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Jun  5 16:13:55 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 5 Jun 2015 16:13:55 +0200
Subject: [R] is.na for S4 object
In-Reply-To: <55708BF1.2010801@fredhutch.org>
References: <1433437709373-4708201.post@n4.nabble.com>
	<55708BF1.2010801@fredhutch.org>
Message-ID: <21873.44707.113907.560574@stat.math.ethz.ch>

>>>>> Martin Morgan <mtmorgan at fredhutch.org>
>>>>>     on Thu, 4 Jun 2015 10:33:37 -0700 writes:

    > On 06/04/2015 10:08 AM, cgenolin wrote:
    >> Hi the list,
    >> 
    >> I have a variable y that is either NA or some S4 object. I would like to
    >> know in which case I am, but it seems taht is.na does not work with S4
    >> object, I get a warnings:
    >> 
    >> --- 8< ------------
    >> setClass("myClass",slots=c(x="numeric"))
    >> if(runif(1)>0.5){a <- new("myClass")}else{a <- NA}
    >> is.na(a)
    >> --- 8< ------------
    >> 
    >> Any solution?

    > getGeneric("is.na")

    > shows that it's an S4 generic, so implement a method

    > setMethod("is.na", "myClass", function(x) FALSE)

    > Martin

For the present special case though,  a more efficient solution would be
to use  isS4(.)  instead of  !is.na(.)

another Martin 


    >> Thanks
    >> Christophe


From jdnewmil at dcn.davis.CA.us  Fri Jun  5 16:27:35 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 05 Jun 2015 07:27:35 -0700
Subject: [R] building a list in a loop
In-Reply-To: <998671763.5563706.1433493604506.JavaMail.yahoo@mail.yahoo.com>
References: <998671763.5563706.1433493604506.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <A599AC78-8D7B-4C33-AA64-2F77B22D408E@dcn.davis.CA.us>

Your explanation of the problem is unclear and your use of HTML formatting corrupts your code examples.

One issue is your reference to a loop while showing no loop nor input nor output. There is more than one construct for iterating in R. One problem you may be encountering is that you cannot change the vector over which you iterate in a for loop while you are in that loop. If that is your problem then you probably need to use something like a while loop. However your example is too abstract (and scrambled by HTML) for me to fix it.

To make your problem clearer [1], you could give us a dput of a sample input data object with a few elements (rows, columns, whatever) and build each element of your output without resorting to a loop. We could then suggest ways to use a loop to accomplish the same thing.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 5, 2015 1:40:04 AM PDT, carol white via R-help <r-help at r-project.org> wrote:
>It might be an easy question but how to construct correctly a list in a
>loop? 
>
>The following doesn't work
>before starting the loopd = NULL#in the loop, 1st iteration
>d = list(d,c(1,2,3)d[[1]]
>NULL
>
>[[2]]
>[1] 1 2 3#in the loop, 2nd iterationd=list(d,c(4,5,6)d
>[[1]]
>[[1]][[1]]
>NULL
>
>[[1]][[2]]
>[1] 1 2 3
>
>
>[[2]]
>[1] 4 5 6
>the goal is to have the result of d= list(c(1,2,3),c(4,5,6)) where the
>list components are not known out of the loop.
>d[[1]]
>[1] 1 2 3
>
>[[2]]
>[1] 4 5 6
>Moreover, how to name the components of the list in the loop while
>constructing as the names are not known out of the loop, either? note
>that the name of the component is stored in a variable in the loop
>
>d = NULL#name1 contains the name for c(1,2,3), how to give the name
>below?
>d = list(d,c(1,2,3)
>Thanks
>?
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Jun  5 16:57:08 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 5 Jun 2015 07:57:08 -0700
Subject: [R] building a list in a loop
In-Reply-To: <998671763.5563706.1433493604506.JavaMail.yahoo@mail.yahoo.com>
References: <998671763.5563706.1433493604506.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAF8bMcYBpEgO5be5Kgtawvi3vETWCnNf6U=Z2LD85OecPWmmog@mail.gmail.com>

Does the following do what you want?
> d <- list() # empty list
> for(i in 1:8) if (i %% 2 == 0) {
     newElement <- structure(list(i), names=LETTERS[i])
     d <- c(d, newElement)
  }
> str(d)
List of 4
 $ B: int 2
 $ D: int 4
 $ F: int 6
 $ H: int 8




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jun 5, 2015 at 1:40 AM, carol white via R-help <r-help at r-project.org
> wrote:

> It might be an easy question but how to construct correctly a list in a
> loop?
>
> The following doesn't work
> before starting the loopd = NULL#in the loop, 1st iteration
> d = list(d,c(1,2,3)d[[1]]
> NULL
>
> [[2]]
> [1] 1 2 3#in the loop, 2nd iterationd=list(d,c(4,5,6)d
> [[1]]
> [[1]][[1]]
> NULL
>
> [[1]][[2]]
> [1] 1 2 3
>
>
> [[2]]
> [1] 4 5 6
> the goal is to have the result of d= list(c(1,2,3),c(4,5,6)) where the
> list components are not known out of the loop.
> d[[1]]
> [1] 1 2 3
>
> [[2]]
> [1] 4 5 6
> Moreover, how to name the components of the list in the loop while
> constructing as the names are not known out of the loop, either? note that
> the name of the component is stored in a variable in the loop
>
> d = NULL#name1 contains the name for c(1,2,3), how to give the name below?
> d = list(d,c(1,2,3)
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From rmh at temple.edu  Fri Jun  5 17:05:58 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 5 Jun 2015 11:05:58 -0400
Subject: [R] [FORGED] Re: Dunnett Test in 'multicomp' package
In-Reply-To: <Pine.SOC.4.64.1506051044270.25362@solcom.hrz.uni-giessen.de>
References: <0CFDB87AFEBD36438EA1AFAF4ECA074F4ACF3D52@agc-exchange.suagcenter.net>
	<CAGx1TMD3eqOAVah4N-9E+AvEh7+6nGsfN_x1cqWpEOk4xD5Gyw@mail.gmail.com>
	<CA+8X3fUtyVe8Cg2tciNTgGbPSk5-s8H3tsLKfLp8Tpokag6fnQ@mail.gmail.com>
	<55715433.4060809@auckland.ac.nz>
	<Pine.SOC.4.64.1506051044270.25362@solcom.hrz.uni-giessen.de>
Message-ID: <CAGx1TMA5VcH5+xswMw1zSk+FEPAAdhc4AnhkoezTFdQKCLVLeg@mail.gmail.com>

One more note.  There is actually a valid reason to use `levels<-`, and that is
to change the spelling of the levels while maintaining the existing order.

> tmp <- factor(c("mm", "cm", "dm", "m", "km"))
> tmp
[1] mm cm dm m  km
Levels: cm dm km m mm
> levels(tmp) <- c("centimeter","decimeter","kilometer","meter","millimeter")
> tmp
[1] millimeter centimeter decimeter  meter      kilometer
5 Levels: centimeter decimeter kilometer ... millimeter
> levels(tmp)
[1] "centimeter" "decimeter"  "kilometer"  "meter"
[5] "millimeter"
>

Rich

On Fri, Jun 5, 2015 at 4:47 AM, Gerrit Eichner
<Gerrit.Eichner at math.uni-giessen.de> wrote:
> Hello, everyone,
>
> aside from Rolf's hint (and Richard's warning!) you could also consider
> relevel():
>
> viagraData$dose <- relevel( viagraData$dose, ref = "placebo")
>
>  Hth  --  Gerrit
>
>
> On Fri, 5 Jun 2015, Rolf Turner wrote:
>
>> On 05/06/15 11:08, Jim Lemon wrote:
>>>
>>> Hi James,
>>> You can change the order of levels like this:
>>>
>>> levels(viagraData$dose)<-c("placebo","low dose","high dose")
>>
>>
>> <SNIP>
>>
>> As Richard Heiberger has pointed out, this is wrong.
>>
>> What *does* work is:
>>
>> viagraData$dose)<-factor(viagraData$dose,
>>                        levels=c("placebo","low dose","high dose")
>>
>> This is a trap into which many a Young Player (including my very good
>> self) has fallen.
>>
>> cheers,
>>
>> Rolf Turner
>>
>>
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kmezhoud at gmail.com  Fri Jun  5 18:31:22 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Fri, 5 Jun 2015 17:31:22 +0100
Subject: [R] rename and color a list of list of list of values
Message-ID: <CALJKBv9oszoBFtgwtn3=kK5bjcn1JYibyGtwHun=vWeOt7Ypcg@mail.gmail.com>

Hi all,
I have a list like this

expBefore <-
list(HM450=list(brac_tcga=list("ATM"=0.19,"ATR"=0.02,"BRCA1"=0.02,"BRCA2"=0.89,"CHEK1"=0.71,"CHEK2"=0.03),

gbm_tcga=list("ATM"=0.19,"ATR"=0.02,"BRCA1"=0.02,"BRCA2"=0.89,"CHEK1"=0.71,"CHEK2"=0.03)
                ),

HM27=list(brac_tcga=list("ATM"=0.19,"ATR"=0.02,"BRCA1"=0.02,"BRCA2"=0.89,"CHEK1"=0.71,"CHEK2"=0.03),

gbm_tcga=list("ATM"=0.19,"ATR"=0.02,"BRCA1"=0.02,"BRCA2"=0.89,"CHEK1"=0.71,"CHEK2"=0.03)
     )
     )


and I would convert it to

expAfter <-list(
  list(
    name="HM450",
    children=list(
      list(name="brca_tcga",
           children=list(
             list(name="ATM", colour="110000"),
             list(name="ATR", colour="330000"),
             list(name="BRCA1", colour="550000"),
             list(name="BRCA2", colour="770000"),
             list(name="CHEK1", colour="990000"),
             list(name="CHEK2", colour="bb0000")

           ), colour="aa0000" # brca_tcga
           ),
        list(name="gbm_tcga",
            children=list(
              list(name="ATM", colour="001100"),
              list(name="ATR", colour="003300"),
              list(name="BRCA1", colour="005500"),
              list(name="BRCA2", colour="007700"),
              list(name="CHEK1", colour="009900"),
              list(name="CHEK2", colour="00bb00")
            ), colour="345345" # gbm_tcga
            )

           ), colour="ffa500" # HM450
  ),
  list(
    name="HM27",
    children=list(
      list(name="brca_tcga",
           children=list(
             list(name="ATM", colour="110000"),
             list(name="ATR", colour="330000"),
             list(name="BRCA1", colour="550000"),
             list(name="BRCA2", colour="770000"),
             list(name="CHEK1", colour="990000"),
             list(name="CHEK2", colour="bb0000")

           ), colour="aa0000" ##brca_tcga
           ),
      list(name="gbm_tcga",
           children=list(
             list(name="ATM", colour="001100"),
             list(name="ATR", colour="003300"),
             list(name="BRCA1", colour="005500"),
             list(name="BRCA2", colour="007700"),
             list(name="CHEK1", colour="009900"),
             list(name="CHEK2", colour="00bb00")
           ), colour="345345") #gbm_tcga

    ), colour="ff00ff"  #HM27
  )

);
any suggestion?
Thanks

	[[alternative HTML version deleted]]


From sven.templer at gmail.com  Fri Jun  5 19:12:18 2015
From: sven.templer at gmail.com (Sven E. Templer)
Date: Fri, 5 Jun 2015 19:12:18 +0200
Subject: [R] rename and color a list of list of list of values
In-Reply-To: <CALJKBv9oszoBFtgwtn3=kK5bjcn1JYibyGtwHun=vWeOt7Ypcg@mail.gmail.com>
References: <CALJKBv9oszoBFtgwtn3=kK5bjcn1JYibyGtwHun=vWeOt7Ypcg@mail.gmail.com>
Message-ID: <CAHuTOvr7Jx_B8=3tYV3XeOv6E88Da1bqtCa_d48NAh0BsxoWGw@mail.gmail.com>

Hi Karim,

you should learn ?Map to iterate along the list and supply mutliple list
arguments (there is also parallel:::mcMap for multicore).
The magic of the color code generation you figure out yourself, I guess...


Here 'i' intends to be the value, 'n' the name, e.g.

# returns color by character/numeric value:
magic_colour <- function (x) { ... }

# returns child
list_child <- function (i, n) { list(name=n, colour=magic_colour(i)) }

# returns parent
list_parent <- function (i, n) { list(name=n, children=Map(list_child, i,
names(i)), colour=magic_colour(n)) }

# get grandparent
grandparent <- Map(list_parent, expBefore, names(expBefore))


Hope this helps!

Best, S.


On 5 June 2015 at 18:31, Karim Mezhoud <kmezhoud at gmail.com> wrote:

> Hi all,
> I have a list like this
>
> expBefore <-
>
> list(HM450=list(brac_tcga=list("ATM"=0.19,"ATR"=0.02,"BRCA1"=0.02,"BRCA2"=0.89,"CHEK1"=0.71,"CHEK2"=0.03),
>
>
> gbm_tcga=list("ATM"=0.19,"ATR"=0.02,"BRCA1"=0.02,"BRCA2"=0.89,"CHEK1"=0.71,"CHEK2"=0.03)
>                 ),
>
>
> HM27=list(brac_tcga=list("ATM"=0.19,"ATR"=0.02,"BRCA1"=0.02,"BRCA2"=0.89,"CHEK1"=0.71,"CHEK2"=0.03),
>
>
> gbm_tcga=list("ATM"=0.19,"ATR"=0.02,"BRCA1"=0.02,"BRCA2"=0.89,"CHEK1"=0.71,"CHEK2"=0.03)
>      )
>      )
>
>
> and I would convert it to
>
> expAfter <-list(
>   list(
>     name="HM450",
>     children=list(
>       list(name="brca_tcga",
>            children=list(
>              list(name="ATM", colour="110000"),
>              list(name="ATR", colour="330000"),
>              list(name="BRCA1", colour="550000"),
>              list(name="BRCA2", colour="770000"),
>              list(name="CHEK1", colour="990000"),
>              list(name="CHEK2", colour="bb0000")
>
>            ), colour="aa0000" # brca_tcga
>            ),
>         list(name="gbm_tcga",
>             children=list(
>               list(name="ATM", colour="001100"),
>               list(name="ATR", colour="003300"),
>               list(name="BRCA1", colour="005500"),
>               list(name="BRCA2", colour="007700"),
>               list(name="CHEK1", colour="009900"),
>               list(name="CHEK2", colour="00bb00")
>             ), colour="345345" # gbm_tcga
>             )
>
>            ), colour="ffa500" # HM450
>   ),
>   list(
>     name="HM27",
>     children=list(
>       list(name="brca_tcga",
>            children=list(
>              list(name="ATM", colour="110000"),
>              list(name="ATR", colour="330000"),
>              list(name="BRCA1", colour="550000"),
>              list(name="BRCA2", colour="770000"),
>              list(name="CHEK1", colour="990000"),
>              list(name="CHEK2", colour="bb0000")
>
>            ), colour="aa0000" ##brca_tcga
>            ),
>       list(name="gbm_tcga",
>            children=list(
>              list(name="ATM", colour="001100"),
>              list(name="ATR", colour="003300"),
>              list(name="BRCA1", colour="005500"),
>              list(name="BRCA2", colour="007700"),
>              list(name="CHEK1", colour="009900"),
>              list(name="CHEK2", colour="00bb00")
>            ), colour="345345") #gbm_tcga
>
>     ), colour="ff00ff"  #HM27
>   )
>
> );
> any suggestion?
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Jun  5 19:52:34 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 5 Jun 2015 19:52:34 +0200
Subject: [R] S4 / operator "[" : Compatibility issue between lme4 and kml
In-Reply-To: <1433489802634-4708236.post@n4.nabble.com>
References: <1433489802634-4708236.post@n4.nabble.com>
Message-ID: <21873.57826.399322.204770@stat.math.ethz.ch>

>>>>> Christophe Genolini <cgenolin at u-paris10.fr>
>>>>>     on Fri, 5 Jun 2015 00:36:42 -0700 writes:

    > Hi all,
    > There is a compatibility issue between the package 'lme4' and my package
    > 'kml'. I define the "[" operator. It works just fine in my package (1). If I
    > try to use the lme4 package, then it does no longer work (2). Moreover, it
    > has some kind of strange behavior (3). Do you know what is wrong? Any idea
    > of how I can correct that?

    > Here is a reproductible example, and the same code with the result follows.

    > Thanks for your help
    > Christophe

  [ ... I'm providing slightly different code below .... ]

> --- 8< ----------------- Execution of the previous code -------------------

> > library(kml)
> Le chargement a n?cessit? le package : clv
> Le chargement a n?cessit? le package : cluster
> Le chargement a n?cessit? le package : class
> Le chargement a n?cessit? le package : longitudinalData
> Le chargement a n?cessit? le package : rgl
> Le chargement a n?cessit? le package : misc3d
> > dn <- gald(1)

>  ###########
> ### (1) the "[" operator works just fine

> > dn["traj"]
>       t0   t1    t2    t3    t4   t5   t6    t7    t8    t9   t10
> i1 -3.11 4.32  2.17  1.82  4.90 7.34 0.83 -2.70  5.36  4.96  3.16
> i2 -7.11 1.40 -2.40 -2.96  4.31 0.50 1.25  0.52 -0.04  7.55  5.50
> i3  2.80 6.23  6.08  2.87  2.58 2.88 6.58 -2.38  2.30 -1.74 -3.23
> i4  2.24 0.91  6.50 10.92 11.32 7.79 7.78 10.69  9.15  1.07 -0.51

>  ###########
> ### (2) using 'lme4', it does no longer work

> > library(lme4)
> Le chargement a n?cessit? le package : Matrix
> Le chargement a n?cessit? le package : Rcpp
> > dn["traj"]
> Error in x[i, j] :
>   erreur d'?valuation de l'argument 'j' lors de la s?lection d'une m?thode
> pour la fonction '[' : Erreur : l'argument "j" est manquant, avec aucune
> valeur par d?faut

>  ###########
> ### (3) If I define again the "[", it does not work the first time I call
> it, but it work the second time!
> > setMethod("[",
> +   signature=signature(x="ClusterLongData", i="character", j="ANY",drop="ANY"),
> +   definition=function (x, i, j="missing", ..., drop = TRUE){
> +       x <- as(x, "LongData")
> +       return(x[i, j])
> +     }
> + )
> [1] "["

> ### No working the first time I use it
> > dn["traj"]
> Error in dn["traj"] :
>   l'argument "j" est manquant, avec aucune valeur par d?faut

> ### But working the second time
> > dn["traj"]
>       t0   t1    t2    t3    t4   t5   t6    t7    t8    t9   t10
> i1 -3.11 4.32  2.17  1.82  4.90 7.34 0.83 -2.70  5.36  4.96  3.16
> i2 -7.11 1.40 -2.40 -2.96  4.31 0.50 1.25  0.52 -0.04  7.55  5.50
> i3  2.80 6.23  6.08  2.87  2.58 2.88 6.58 -2.38  2.30 -1.74 -3.23
> i4  2.24 0.91  6.50 10.92 11.32 7.79 7.78 10.69  9.15  1.07 -0.51 

I have made some investigations, but have to stop for now, and
leave this hopefully to others knowledgable about S4 method
dispatch, etc :

1) I am confident to say that you have uncovered an "unfelicity if
  not a bug" in R.

2) I am also pretty confident that the "[" methods that you
  define in 'kml' and in the package '

3) Diagnosing is not easy: As you have shown yourself above,
  in some situations the bug "bites" and if you repeat the *same*
  code, things work.

  This is related to the fact that S4 methods are __cached__
  (so next time they are found more quickly) under some
  circumstances, and the cache is cleared under other such circumstances.

3b) Actually, I am sure that we have seen +/- the same problem many
    months ago, in other contexts but did not get "down to it";
    and at the moment, I cannot quickly find where to look for
    the problem there...


##--- 8< ------------Commented (incl output) reproducible code--------------
library(kml)

### Creating some data
dn <- gald(1)
(dnt <- dn["traj"])

showMethods("[")
## Function: [ (package base)
## x="ClusterLongData", i="character"
## x="ListPartition", i="ANY"
## x="LongData", i="ANY"
## x="LongData", i="character"
##     (inherited from: x="LongData", i="ANY")
## x="LongData3d", i="ANY"
## x="nonStructure", i="ANY"
## x="ParChoice", i="ANY"
## x="ParKml", i="ANY"
## x="ParLongData", i="ANY"
## x="Partition", i="ANY"
## x="ParWindows", i="ANY"

### using Matrix  (or lme4, which 'Depends' on Matrix; hence same effect)
library(Matrix)
dn["traj"]
## Error in x[i, j] :
##   error in evaluating the argument 'j' in selecting a method for function '[': Error: argument "j" is missing, with no default
traceback()
## 3: x[i, j]
## 2: dn["traj"]
## 1: dn["traj"]
(ms <- methods(`[`)) ## 81 methods

##---- MM: debugging :
trace("[", browser, signature=c("ClusterLongData", "character", "missing",   "missing"))
trace("[", browser, signature=c("LongData",        "character", "character", "missing"))
dn["traj"]
## -> you get into the browser, just press   "c"   twice (once for each "trace")
## ==> it works !!

## Remove the tracing :
untrace("[", signature=c("ClusterLongData", "character", "missing",   "missing"))
untrace("[", signature=c("LongData",        "character", "character", "missing"))
dn["traj"]
## Error in dn["traj"] : argument "j" is missing, with no default

## Debugging only the *inner* function:
trace("[", browser, signature=c("LongData",        "character", "character", "missing"))
dn["traj"]
## Error ....
untrace("[", signature=c("LongData",        "character", "character", "missing"))

## Debugging only the *outer* function:
trace("[", browser, signature=c("ClusterLongData", "character", "missing",   "missing"))
dn["traj"] ## -> debugger, press 'c'
## it works!
##       t0    t1    t2   t3   t4   t5   t6    t7    t8    t9   t10
## i1  7.38  4.80  4.80 0.73 0.58 2.22 0.55 -1.05  0.79  5.20  4.43
## i2  1.55  2.01 -0.29 2.12 4.44 7.33 9.09  4.76 12.18  5.92  8.06
## i3 13.60 14.72 10.15 9.25 8.70 8.34 6.71  5.84  3.44  2.10  2.17
## i4 -7.49 -1.80  0.08 2.51 6.61 4.56 8.96  3.05  3.41 -2.62 -4.09
untrace("[", signature=c("ClusterLongData", "character", "missing",   "missing"))

##--- {end of reproducible code} --------------


From hannah.hlx at gmail.com  Fri Jun  5 20:26:24 2015
From: hannah.hlx at gmail.com (li li)
Date: Fri, 5 Jun 2015 14:26:24 -0400
Subject: [R] Confidence interval for the mean in the random intercept and
 random slople model
Message-ID: <CAHLnndaqQJC6gn-nF1tOagfkkYz7SPE7yBQ2e6UEsdFmQzAs8Q@mail.gmail.com>

Hi all,
  I am fitting a random slope and random intercept model usign lme
fucntion as shown below. Type is factor with two levels. I would like
to to find a confidence interval for mean of this model. Note that the
variance we use in finding the confidence interval should include the
variariance component from random effect.  Any suggestions?


## using lme function
> mod_lme <- lme(ti  ~ type*months, random=~ 1+months|lot, na.action=na.omit,
+ data=one, control = lmeControl(opt = "optim"))
> summary(mod_lme)
Linear mixed-effects model fit by REML
 Data: one
        AIC       BIC   logLik
  -82.60042 -70.15763 49.30021

Random effects:
 Formula: ~1 + months | lot
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 8.907584e-03 (Intr)
months      6.039781e-05 -0.096
Residual    4.471243e-02

Fixed effects: ti ~ type * months
                     Value   Std.Error DF   t-value p-value
(Intercept)     0.25831245 0.016891587 31 15.292373  0.0000
type            0.13502089 0.026676101  4  5.061493  0.0072
months          0.00804790 0.001218941 31  6.602368  0.0000
type:months -0.00693679 0.002981859 31 -2.326329  0.0267
 Correlation:
               (Intr) typPPQ months
type           -0.633
months         -0.785  0.497
type:months  0.321 -0.762 -0.409

Standardized Within-Group Residuals:
          Min            Q1           Med            Q3           Max
-2.162856e+00 -1.962972e-01 -2.771184e-05  3.749035e-01  2.088392e+00

Number of Observations: 39
Number of Groups: 6


From jfhenson1 at gmail.com  Fri Jun  5 16:12:20 2015
From: jfhenson1 at gmail.com (James Henson)
Date: Fri, 5 Jun 2015 09:12:20 -0500
Subject: [R] [FORGED] Re: Dunnett Test in 'multicomp' package
In-Reply-To: <Pine.SOC.4.64.1506051044270.25362@solcom.hrz.uni-giessen.de>
References: <0CFDB87AFEBD36438EA1AFAF4ECA074F4ACF3D52@agc-exchange.suagcenter.net>
	<CAGx1TMD3eqOAVah4N-9E+AvEh7+6nGsfN_x1cqWpEOk4xD5Gyw@mail.gmail.com>
	<CA+8X3fUtyVe8Cg2tciNTgGbPSk5-s8H3tsLKfLp8Tpokag6fnQ@mail.gmail.com>
	<55715433.4060809@auckland.ac.nz>
	<Pine.SOC.4.64.1506051044270.25362@solcom.hrz.uni-giessen.de>
Message-ID: <CABPq8JMdY1O3858=OBNsAQC=pRCFVZL0Z_2+03bERhe7So-pig@mail.gmail.com>

Thanks. A useful tip for a long-time SAS user.
James F. Henson

On Fri, Jun 5, 2015 at 3:47 AM, Gerrit Eichner <
Gerrit.Eichner at math.uni-giessen.de> wrote:

> Hello, everyone,
>
> aside from Rolf's hint (and Richard's warning!) you could also consider
> relevel():
>
> viagraData$dose <- relevel( viagraData$dose, ref = "placebo")
>
>  Hth  --  Gerrit
>
>
> On Fri, 5 Jun 2015, Rolf Turner wrote:
>
>  On 05/06/15 11:08, Jim Lemon wrote:
>>
>>> Hi James,
>>> You can change the order of levels like this:
>>>
>>> levels(viagraData$dose)<-c("placebo","low dose","high dose")
>>>
>>
>> <SNIP>
>>
>> As Richard Heiberger has pointed out, this is wrong.
>>
>> What *does* work is:
>>
>> viagraData$dose)<-factor(viagraData$dose,
>>                        levels=c("placebo","low dose","high dose")
>>
>> This is a trap into which many a Young Player (including my very good
>> self) has fallen.
>>
>> cheers,
>>
>> Rolf Turner
>>
>>
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From oluola2011 at yahoo.com  Fri Jun  5 19:43:23 2015
From: oluola2011 at yahoo.com (Olu Ola)
Date: Fri, 5 Jun 2015 10:43:23 -0700
Subject: [R] Error in eigen(nhatend)
Message-ID: <1433526203.5741.YahooMailBasic@web161604.mail.bf1.yahoo.com>

Hello,
I am estimating a nonlinear GMM and I got the following error message. I have searched online in other to understand what is going on but could not find help

> ngmm = optimx(par=b0, fn=object,gr=gred, method = c("BFGS","nlminb","nlm"), itnmax=10000, control=list(follow.on = TRUE,starttests=TRUE, save.failures=TRUE, trace=0))
Error in eigen(nhatend) : infinite or missing values in 'x'
In addition: Warning messages:
1: In optimx.run(par, optcfg$ufn, optcfg$ugr, optcfg$uhess, lower,  :
  Hessian is reported non-symmetric with asymmetry ratio NaN
2: Hessian forced symmetric 
Error in ans.ret[meth, ] <- c(ans$par, ans$value, ans$fevals, ans$gevals,  : 
  number of items to replace is not a multiple of replacement length
In addition: Warning message:
In optimx.run(par, optcfg$ufn, optcfg$ugr, optcfg$uhess, lower,  :
  Eigenvalue failure after method BFGS

A way forward will be highly appreciated.

Thank you


From drewmarticorena at awhere.com  Fri Jun  5 19:45:48 2015
From: drewmarticorena at awhere.com (Drew Marticorena)
Date: Fri, 5 Jun 2015 17:45:48 +0000
Subject: [R] "Updating Loaded Package" behavior
Message-ID: <BN3PR0801MB08976C17399611636977BEBACAB20@BN3PR0801MB0897.namprd08.prod.outlook.com>

Hello, I am trying to handle more gracefully the issue that occurs when one attempts to install a new version of a package whose library is currently loaded.  When one does this the functions in the package work but when one tries to view the documentation a warning pop is given and the following messages are in the terminal.


Error in fetch(key) : lazy-load database '' is corrupt
Warning message: In fetch(key) : internal error -3 in R_decompress1


When testing this behavior with other packages but installing old versions, loading the libraries, and then trying to update I sometimes get a popup message from Rstudio that begins


Updating Loaded Package

One or more of the packages that will be updated by this installation are currently loaded. Restarting R prior to updating these packages is strongly recommended. RStudio can restart R and then automatically continue the installation after restarting (all work and data will be preserved during the restart). Do you want to restart R prior to installing?


The popup asks if I want to restart the R session prior to installing.  This has never occurred with my own package, only ones I have gotten from CRAN.   I however can not reliably replicate this popup appearing.  For my purpose all of the work with the package will occur within RStudio.  Is there a way to force RStudio to show this popup when one tries to update an already loaded package/library in order to avoid having the user have to figure out why the documentation has all of a sudden stopped working?  Alternatively could the same thing be done at the command line forcing the user to acknowledge the issue and either progress with the install or first restart?


Thank you for any help or insights into this problem


drew marticorena



	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Fri Jun  5 23:32:17 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Fri, 5 Jun 2015 22:32:17 +0100
Subject: [R] rename and color a list of list of list of values
In-Reply-To: <CAHuTOvr7Jx_B8=3tYV3XeOv6E88Da1bqtCa_d48NAh0BsxoWGw@mail.gmail.com>
References: <CALJKBv9oszoBFtgwtn3=kK5bjcn1JYibyGtwHun=vWeOt7Ypcg@mail.gmail.com>
	<CAHuTOvr7Jx_B8=3tYV3XeOv6E88Da1bqtCa_d48NAh0BsxoWGw@mail.gmail.com>
Message-ID: <CALJKBv-VahtaxMwUHMX3X+-q0TH-oV+q+AsmGEOW0y6o6+yeyw@mail.gmail.com>

Thanks Sven,

I started with the first function.
The values are not in a list but in df. it is more easy for me

the output is a df:
 Genes    brca_tcga  gbm_tcga   color_brca      color_gbm
name1     v1                    v2            col1                 col2
name2     v3                    v4            col3                 col4
name3    v5                     v6            col5                 col6



attriColorGene <- function(df,colname, color=c(x,y,z)){
Max <- max(df, na.rm=TRUE)
Min <- min(df, na.rm=TRUE)
#"white","yellow", "darkgoldenrod3"
my.colors <- colorRampPalette(c(x,y,z )) #creates a function my.colors
which interpolates n colors between blue, white and red
color.df <- data.frame(colname=seq(Min,Max,1), paste("col_", colname,
sep="")=my.colors(Max- Min)) #generates 2001 colors from the color ramp
df.with.color <- merge(df, color.df, by=colname)
return(df.with.color)
}

for(i in 2:length(colnames(df)) ){
  colname <- colnames[i]
  attriColorGene(df,colname, color=c(x,y,z))
}


could you describe me the structure of the output of
magic_colour, list_child , list_parent?

Thanks
Karim



On Fri, Jun 5, 2015 at 6:12 PM, Sven E. Templer <sven.templer at gmail.com>
wrote:

> Hi Karim,
>
> you should learn ?Map to iterate along the list and supply mutliple list
> arguments (there is also parallel:::mcMap for multicore).
> The magic of the color code generation you figure out yourself, I guess...
>
>
> Here 'i' intends to be the value, 'n' the name, e.g.
>
> # returns color by character/numeric value:
> magic_colour <- function (x) { ... }
>
> # returns child
> list_child <- function (i, n) { list(name=n, colour=magic_colour(i)) }
>
> # returns parent
> list_parent <- function (i, n) { list(name=n, children=Map(list_child, i,
> names(i)), colour=magic_colour(n)) }
>
> # get grandparent
> grandparent <- Map(list_parent, expBefore, names(expBefore))
>
>
> Hope this helps!
>
> Best, S.
>
>
> On 5 June 2015 at 18:31, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>
>> Hi all,
>> I have a list like this
>>
>> expBefore <-
>>
>> list(HM450=list(brac_tcga=list("ATM"=0.19,"ATR"=0.02,"BRCA1"=0.02,"BRCA2"=0.89,"CHEK1"=0.71,"CHEK2"=0.03),
>>
>>
>> gbm_tcga=list("ATM"=0.19,"ATR"=0.02,"BRCA1"=0.02,"BRCA2"=0.89,"CHEK1"=0.71,"CHEK2"=0.03)
>>                 ),
>>
>>
>> HM27=list(brac_tcga=list("ATM"=0.19,"ATR"=0.02,"BRCA1"=0.02,"BRCA2"=0.89,"CHEK1"=0.71,"CHEK2"=0.03),
>>
>>
>> gbm_tcga=list("ATM"=0.19,"ATR"=0.02,"BRCA1"=0.02,"BRCA2"=0.89,"CHEK1"=0.71,"CHEK2"=0.03)
>>      )
>>      )
>>
>>
>> and I would convert it to
>>
>> expAfter <-list(
>>   list(
>>     name="HM450",
>>     children=list(
>>       list(name="brca_tcga",
>>            children=list(
>>              list(name="ATM", colour="110000"),
>>              list(name="ATR", colour="330000"),
>>              list(name="BRCA1", colour="550000"),
>>              list(name="BRCA2", colour="770000"),
>>              list(name="CHEK1", colour="990000"),
>>              list(name="CHEK2", colour="bb0000")
>>
>>            ), colour="aa0000" # brca_tcga
>>            ),
>>         list(name="gbm_tcga",
>>             children=list(
>>               list(name="ATM", colour="001100"),
>>               list(name="ATR", colour="003300"),
>>               list(name="BRCA1", colour="005500"),
>>               list(name="BRCA2", colour="007700"),
>>               list(name="CHEK1", colour="009900"),
>>               list(name="CHEK2", colour="00bb00")
>>             ), colour="345345" # gbm_tcga
>>             )
>>
>>            ), colour="ffa500" # HM450
>>   ),
>>   list(
>>     name="HM27",
>>     children=list(
>>       list(name="brca_tcga",
>>            children=list(
>>              list(name="ATM", colour="110000"),
>>              list(name="ATR", colour="330000"),
>>              list(name="BRCA1", colour="550000"),
>>              list(name="BRCA2", colour="770000"),
>>              list(name="CHEK1", colour="990000"),
>>              list(name="CHEK2", colour="bb0000")
>>
>>            ), colour="aa0000" ##brca_tcga
>>            ),
>>       list(name="gbm_tcga",
>>            children=list(
>>              list(name="ATM", colour="001100"),
>>              list(name="ATR", colour="003300"),
>>              list(name="BRCA1", colour="005500"),
>>              list(name="BRCA2", colour="007700"),
>>              list(name="CHEK1", colour="009900"),
>>              list(name="CHEK2", colour="00bb00")
>>            ), colour="345345") #gbm_tcga
>>
>>     ), colour="ff00ff"  #HM27
>>   )
>>
>> );
>> any suggestion?
>> Thanks
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From cgenolin at u-paris10.fr  Sat Jun  6 16:19:15 2015
From: cgenolin at u-paris10.fr (cgenolin)
Date: Sat, 6 Jun 2015 07:19:15 -0700 (PDT)
Subject: [R] S4 / operator "[" : Compatibility issue between lme4 and kml
In-Reply-To: <21873.57826.399322.204770@stat.math.ethz.ch>
References: <1433489802634-4708236.post@n4.nabble.com>
	<21873.57826.399322.204770@stat.math.ethz.ch>
Message-ID: <1433600355785-4708282.post@n4.nabble.com>

Thanks a lot for your time. Two questions:

1/ Shall I submit a bug report?

2/ In your point 2), I cannot find the verb... Is my english not good enough
to understand it, or is it a "not-ended" sentence?

:-)



--
View this message in context: http://r.789695.n4.nabble.com/S4-operator-Compatibility-issue-between-lme4-and-kml-tp4708236p4708282.html
Sent from the R help mailing list archive at Nabble.com.


From mtmorgan at fredhutch.org  Sat Jun  6 18:42:23 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Sat, 06 Jun 2015 09:42:23 -0700
Subject: [R] S4 / operator "[" : Compatibility issue between lme4 and kml
In-Reply-To: <21873.57826.399322.204770@stat.math.ethz.ch>
References: <1433489802634-4708236.post@n4.nabble.com>
	<21873.57826.399322.204770@stat.math.ethz.ch>
Message-ID: <557322EF.8030503@fredhutch.org>

On 06/05/2015 10:52 AM, Martin Maechler wrote:
>>>>>> Christophe Genolini <cgenolin at u-paris10.fr>
>>>>>>      on Fri, 5 Jun 2015 00:36:42 -0700 writes:
>
>      > Hi all,
>      > There is a compatibility issue between the package 'lme4' and my package
>      > 'kml'. I define the "[" operator. It works just fine in my package (1). If I
>      > try to use the lme4 package, then it does no longer work (2). Moreover, it
>      > has some kind of strange behavior (3). Do you know what is wrong? Any idea
>      > of how I can correct that?
>
>      > Here is a reproductible example, and the same code with the result follows.
>
>      > Thanks for your help
>      > Christophe
>
>    [ ... I'm providing slightly different code below .... ]
>
>> --- 8< ----------------- Execution of the previous code -------------------
>
>>> library(kml)
>> Le chargement a n?cessit? le package : clv
>> Le chargement a n?cessit? le package : cluster
>> Le chargement a n?cessit? le package : class
>> Le chargement a n?cessit? le package : longitudinalData
>> Le chargement a n?cessit? le package : rgl
>> Le chargement a n?cessit? le package : misc3d
>>> dn <- gald(1)
>
>>   ###########
>> ### (1) the "[" operator works just fine
>
>>> dn["traj"]
>>        t0   t1    t2    t3    t4   t5   t6    t7    t8    t9   t10
>> i1 -3.11 4.32  2.17  1.82  4.90 7.34 0.83 -2.70  5.36  4.96  3.16
>> i2 -7.11 1.40 -2.40 -2.96  4.31 0.50 1.25  0.52 -0.04  7.55  5.50
>> i3  2.80 6.23  6.08  2.87  2.58 2.88 6.58 -2.38  2.30 -1.74 -3.23
>> i4  2.24 0.91  6.50 10.92 11.32 7.79 7.78 10.69  9.15  1.07 -0.51
>
>>   ###########
>> ### (2) using 'lme4', it does no longer work
>
>>> library(lme4)
>> Le chargement a n?cessit? le package : Matrix
>> Le chargement a n?cessit? le package : Rcpp
>>> dn["traj"]
>> Error in x[i, j] :
>>    erreur d'?valuation de l'argument 'j' lors de la s?lection d'une m?thode
>> pour la fonction '[' : Erreur : l'argument "j" est manquant, avec aucune
>> valeur par d?faut
>
>>   ###########
>> ### (3) If I define again the "[", it does not work the first time I call
>> it, but it work the second time!
>>> setMethod("[",
>> +   signature=signature(x="ClusterLongData", i="character", j="ANY",drop="ANY"),
>> +   definition=function (x, i, j="missing", ..., drop = TRUE){

Your file has two definitions of

   setMethod("[", c("ClusterLongData", ...

I deleted the first one.

The second definition had

     signature=signature(x="ClusterLongData", i="character", j="ANY",drop="ANY"),

whereas probably you mean to say that you'll handle

     signature=signature(x="ClusterLongData", i="character",
                         j="missing", drop="ANY")

The next line says

     definition=function (x, i, j="missing", ..., drop = TRUE){

which provides a default value for 'j' when j is not provided by the user. Thus 
later when you say

    x[i, j]

you are performing dn["traj", "missing"] when probably you meant

   x[i, , drop=drop]

Making these changes, so the definition is

setMethod(
     "[",
     signature=signature(x="ClusterLongData", i="character", j="missing",
       drop="ANY"),
     definition=function (x, i, j, ..., drop = TRUE){
         if (is.numeric(i)) {
             stop("[ClusterLongData:getteur]: to get a clusters list, use ['ci']")
         }else{}
         if (i %in% c("criterionValues", "criterionValuesAsMatrix")){
             j <- x['criterionActif']
         }else{}
         if (i %in% c(CRITERION_NAMES, "criterionActif", CLUSTER_NAMES,
                      "criterionValues", "criterionValuesAsMatrix", "sorted",
                      "initializationMethod")) {
             x <- as(x, "ListPartition")
         }else{
             x <- as(x, "LongData")
         }
         x[i, , drop=drop]
     })

Allows operations to work correctly.

 > library(kml)
Loading required package: clv
Loading required package: cluster
Loading required package: class
Loading required package: longitudinalData
Loading required package: rgl
Loading required package: misc3d
 > library(Matrix)
 > x = gald(1)["traj"]
 > x
       t0    t1    t2    t3    t4    t5    t6    t7    t8    t9   t10
i1 -3.18 -1.19 -1.17  1.56 -0.70  1.78 -0.95 -2.00 -5.05  1.05  2.84
i2  3.51  1.72  6.97  6.09  7.81  8.33  9.54 14.38 16.14 12.82 13.86
i3  9.60 11.59  9.09  6.31  9.24  7.69  4.26 -0.80  2.70  1.63  1.21
i4 -0.54  3.80  6.05 10.41 12.60 12.32 10.33 11.05  7.89  5.21  0.67

It's hard to tell whether is an issue with the methods package, or just that 
Matrix offered a better nearest 'method' than those provided by kml / 
longitudinalData.



>> +       x <- as(x, "LongData")
>> +       return(x[i, j])
>> +     }
>> + )
>> [1] "["
>
>> ### No working the first time I use it
>>> dn["traj"]
>> Error in dn["traj"] :
>>    l'argument "j" est manquant, avec aucune valeur par d?faut
>
>> ### But working the second time
>>> dn["traj"]
>>        t0   t1    t2    t3    t4   t5   t6    t7    t8    t9   t10
>> i1 -3.11 4.32  2.17  1.82  4.90 7.34 0.83 -2.70  5.36  4.96  3.16
>> i2 -7.11 1.40 -2.40 -2.96  4.31 0.50 1.25  0.52 -0.04  7.55  5.50
>> i3  2.80 6.23  6.08  2.87  2.58 2.88 6.58 -2.38  2.30 -1.74 -3.23
>> i4  2.24 0.91  6.50 10.92 11.32 7.79 7.78 10.69  9.15  1.07 -0.51
>
> I have made some investigations, but have to stop for now, and
> leave this hopefully to others knowledgable about S4 method
> dispatch, etc :
>
> 1) I am confident to say that you have uncovered an "unfelicity if
>    not a bug" in R.
>
> 2) I am also pretty confident that the "[" methods that you
>    define in 'kml' and in the package '
>
> 3) Diagnosing is not easy: As you have shown yourself above,
>    in some situations the bug "bites" and if you repeat the *same*
>    code, things work.
>
>    This is related to the fact that S4 methods are __cached__
>    (so next time they are found more quickly) under some
>    circumstances, and the cache is cleared under other such circumstances.
>
> 3b) Actually, I am sure that we have seen +/- the same problem many
>      months ago, in other contexts but did not get "down to it";
>      and at the moment, I cannot quickly find where to look for
>      the problem there...
>
>
> ##--- 8< ------------Commented (incl output) reproducible code--------------
> library(kml)
>
> ### Creating some data
> dn <- gald(1)
> (dnt <- dn["traj"])
>
> showMethods("[")
> ## Function: [ (package base)
> ## x="ClusterLongData", i="character"
> ## x="ListPartition", i="ANY"
> ## x="LongData", i="ANY"
> ## x="LongData", i="character"
> ##     (inherited from: x="LongData", i="ANY")
> ## x="LongData3d", i="ANY"
> ## x="nonStructure", i="ANY"
> ## x="ParChoice", i="ANY"
> ## x="ParKml", i="ANY"
> ## x="ParLongData", i="ANY"
> ## x="Partition", i="ANY"
> ## x="ParWindows", i="ANY"
>
> ### using Matrix  (or lme4, which 'Depends' on Matrix; hence same effect)
> library(Matrix)
> dn["traj"]
> ## Error in x[i, j] :
> ##   error in evaluating the argument 'j' in selecting a method for function '[': Error: argument "j" is missing, with no default
> traceback()
> ## 3: x[i, j]
> ## 2: dn["traj"]
> ## 1: dn["traj"]
> (ms <- methods(`[`)) ## 81 methods
>
> ##---- MM: debugging :
> trace("[", browser, signature=c("ClusterLongData", "character", "missing",   "missing"))
> trace("[", browser, signature=c("LongData",        "character", "character", "missing"))
> dn["traj"]
> ## -> you get into the browser, just press   "c"   twice (once for each "trace")
> ## ==> it works !!
>
> ## Remove the tracing :
> untrace("[", signature=c("ClusterLongData", "character", "missing",   "missing"))
> untrace("[", signature=c("LongData",        "character", "character", "missing"))
> dn["traj"]
> ## Error in dn["traj"] : argument "j" is missing, with no default
>
> ## Debugging only the *inner* function:
> trace("[", browser, signature=c("LongData",        "character", "character", "missing"))
> dn["traj"]
> ## Error ....
> untrace("[", signature=c("LongData",        "character", "character", "missing"))
>
> ## Debugging only the *outer* function:
> trace("[", browser, signature=c("ClusterLongData", "character", "missing",   "missing"))
> dn["traj"] ## -> debugger, press 'c'
> ## it works!
> ##       t0    t1    t2   t3   t4   t5   t6    t7    t8    t9   t10
> ## i1  7.38  4.80  4.80 0.73 0.58 2.22 0.55 -1.05  0.79  5.20  4.43
> ## i2  1.55  2.01 -0.29 2.12 4.44 7.33 9.09  4.76 12.18  5.92  8.06
> ## i3 13.60 14.72 10.15 9.25 8.70 8.34 6.71  5.84  3.44  2.10  2.17
> ## i4 -7.49 -1.80  0.08 2.51 6.61 4.56 8.96  3.05  3.41 -2.62 -4.09
> untrace("[", signature=c("ClusterLongData", "character", "missing",   "missing"))
>
> ##--- {end of reproducible code} --------------
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From nashjc at uottawa.ca  Sat Jun  6 18:47:21 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Sat, 06 Jun 2015 12:47:21 -0400
Subject: [R] Error in eigen(nhatend)
In-Reply-To: <mailman.9.1433584802.5969.r-help@r-project.org>
References: <mailman.9.1433584802.5969.r-help@r-project.org>
Message-ID: <55732419.2090008@uottawa.ca>

It looks like the matrix nhatend (for Numerical Hessian AT END) has some
NAs or Infs.

Suggest you turn off the Hessian calculation by

argument   hessian=FALSE (that is the default)
and control=list(kkt=FALSE)  (the default is TRUE for "small" problems")

Then take the resulting final parameters and use the package numDeriv to
get the numerical hessian and try to see if you can then do eigen() on it.

optimx is really just a wrapper for a lot of the calculations people
want to do with optimizers, so diagnosing this kind of thing is best
done in a pedestrian fashion by trying to replicate the calculation
outside the package.

Note that the Jacobian of the gradient (from numDeriv) is more accurate
if you have analytic gradients than the hessian() function, which needs
two levels of differencing and can give poor approximations for many
functions. This may, in fact, be the source of the reported error.

Note also that there are a couple of (really stupid) typos in optimx and
Rvmmin packages. They don't affect most users. I've fixed them, but am
having trouble with reverse dependency checks, which I believe are
problems outside of my packages. However, I'm hoping to resolve those
issues before I post the fixed packages on CRAN.

JN


On 15-06-06 06:00 AM, r-help-request at r-project.org wrote:
> Message: 26
> Date: Fri, 5 Jun 2015 10:43:23 -0700
> From: Olu Ola <oluola2011 at yahoo.com>
> To: r-help at r-project.org
> Subject: [R] Error in eigen(nhatend)
> Message-ID:
> 	<1433526203.5741.YahooMailBasic at web161604.mail.bf1.yahoo.com>
> Content-Type: text/plain; charset=us-ascii
> 
> Hello,
> I am estimating a nonlinear GMM and I got the following error message. I have searched online in other to understand what is going on but could not find help
> 
>> > ngmm = optimx(par=b0, fn=object,gr=gred, method = c("BFGS","nlminb","nlm"), itnmax=10000, control=list(follow.on = TRUE,starttests=TRUE, save.failures=TRUE, trace=0))
> Error in eigen(nhatend) : infinite or missing values in 'x'
> In addition: Warning messages:
> 1: In optimx.run(par, optcfg$ufn, optcfg$ugr, optcfg$uhess, lower,  :
>   Hessian is reported non-symmetric with asymmetry ratio NaN
> 2: Hessian forced symmetric 
> Error in ans.ret[meth, ] <- c(ans$par, ans$value, ans$fevals, ans$gevals,  : 
>   number of items to replace is not a multiple of replacement length
> In addition: Warning message:
> In optimx.run(par, optcfg$ufn, optcfg$ugr, optcfg$uhess, lower,  :
>   Eigenvalue failure after method BFGS
> 
> A way forward will be highly appreciated.
> 
> Thank you


From blake at nceas.ucsb.edu  Sat Jun  6 00:32:18 2015
From: blake at nceas.ucsb.edu (Rachael Blake)
Date: Fri, 05 Jun 2015 15:32:18 -0700
Subject: [R] A-priori contrasts with type III sums of squares in R
Message-ID: <55722372.50105@nceas.ucsb.edu>

I am analyzing data using a factorial three-way ANOVA with a-priori 
contrasts and type III sums of squares. (Please don't comment about type 
I SS vs. type III SS. That's not the point of my question.  I have read 
at length about the choice between types of SS and have made my 
decision.) I get the contrasts like I need using summary.aov(), however 
that uses type I SS. When I use the Anova() function from library(car) 
to get type III SS, I don't get the contrasts. I have also tried using 
drop1() with the lm() model, but I get the same results as Anova() 
(without the contrasts).

Please advise on a statistical method in R to analyze data using 
factorial ANOVA with a-priori contrasts and type III SS as shown in my 
example below.

Sample data:
     DF <- structure(list(Code = structure(c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 
3L,
     3L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L, 7L, 7L, 7L, 8L, 8L, 8L, 9L, 
9L,
     9L, 10L, 10L, 10L, 11L, 11L, 11L, 12L, 12L, 12L), .Label = c("A",
     "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L"), class =
     "factor"), GzrTreat = structure(c(3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
     3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,  2L, 2L,
     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), contrasts = structure(c(1,
     -2, 1, 1, 0, -1), .Dim = c(3L, 2L), .Dimnames = list(c("I",
     "N", "R"), NULL)), .Label = c("I", "N", "R"), class = "factor"),
     BugTreat = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
     1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label =
     c("Immigration", "Initial", "None"), class = "factor"), TempTreat =
     structure(c(2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 
2L,
     2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L,
     1L, 1L, 1L, 1L, 1L), .Label = c("Not Warm", "Warmed"), class =
     "factor"), ShadeTreat = structure(c(2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L,
     2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
     1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L), .Label = 
c("Light",
     "Shaded"), class = "factor"), EpiChla = c(0.268482353, 0.423119608,
     0.579507843, 0.738839216, 0.727856863, 0.523960784, 0.405801961,
     0.335964706, 0.584441176, 0.557543137, 0.436456863, 0.563909804,
     0.432398039, 0.344956863, 0.340309804, 0.992884314, 0.938390196,
     0.663270588, 0.239833333, 0.62875098, 0.466011765, 0.536182353,
     0.340309804, 0.721172549, 0.752082353, 0.269372549, 0.198180392,
     1.298882353, 0.298354902, 0.913139216, 0.846129412, 0.922317647,
     0.727033333, 1.187662745, 0.35622549, 0.073547059), log_EpiChla =
     c(0.10328443, 0.153241402, 0.198521787, 0.240259426, 0.237507762,
     0.182973791, 0.147924145, 0.125794985, 0.19987612, 0.192440084,
     0.157292589, 0.194211702, 0.156063718, 0.128708355, 0.127205194,
     0.299482089, 0.287441205, 0.220962908, 0.093363308, 0.21185469,
     0.166137456, 0.186442772, 0.127205194, 0.235824411, 0.243554515,
     0.103589102, 0.078522208, 0.361516746, 0.113393422, 0.281746574,
     0.266262141, 0.283825153, 0.23730072, 0.339980371, 0.132331903,
     0.030821087), MeanZGrowthAFDM_g = c(0.00665, 0.003966667, 0.004466667,
     0.01705, 0.0139, 0.0129, 0.0081, 0.003833333, 0.00575, 0.011266667,
     0.0103, 0.009, 0.0052, 0.00595, 0.0105, 0.0091, 0.00905, 0.0045, 
0.0031,
     0.006466667, 0.0053, 0.009766667, 0.0181, 0.00725, 0, 0.0012, 5e-04,
     0.0076, 0.00615, 0.0814, NA, 0.0038, 0.00165, 0.0046, 0, 0.0015)),
     .Names = c("Code", "GzrTreat", "BugTreat", "TempTreat", "ShadeTreat",
     "EpiChla", "log_EpiChla", "MeanZGrowthAFDM_g"), class = "data.frame",
     row.names = c(NA, -36L))


Code:

     ## a-priori contrasts
     library(stats)
     contrasts(DF$GzrTreat) <- cbind(c(1,-2,1), c(1,0,-1))
     round(crossprod(contrasts(DF$GzrTreat)))
     c_labels <- list(GzrTreat=list('presence'=1, 'immigration'=2))

     ## model
     library(car)
     EpiLM <- lm(log_EpiChla~TempTreat*GzrTreat*ShadeTreat, DF)
     summary.aov(EpiLM, split=c_labels) ### MUST USE summary.aov(), to get
     #contrast results, but sadly this uses Type I SS
     Anova(EpiLM, split=c_labels, type="III") # Uses Type III SS, but NO
     #CONTRASTS!!!!!
     drop1(EpiLM, ~., test="F") # again, this does not print contrasts

     # I need contrast results like from summary.aov(), AND Type III SS
     # like from Anova()



-- 
Rachael E. Blake, PhD
Post-doctoral Associate


From drjimlemon at gmail.com  Sat Jun  6 09:50:23 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 6 Jun 2015 17:50:23 +1000
Subject: [R] if else statement for rain data to define zero for dry and
 one to wet
In-Reply-To: <D69718E661A.0000043Bjrkrideau@inbox.com>
References: <CANTvJZL6oUjX_Qn9oJXuGKQ85Pjh5HK2q4JrOpafWdNMBvQstQ@mail.gmail.com>
	<D69718E661A.0000043Bjrkrideau@inbox.com>
Message-ID: <CA+8X3fWLmmRj5TZg1hX5A1_yF-COROzeZVC1dApHqyjZbw0+cA@mail.gmail.com>

Hi rosalinazairimah,
I think the problem is that you are using "if" instead of "ifelse". Try this:

wet_dry<-function(x,thresh=0.1) {
 for(column in 1:dim(x)[2]) x[,column]<-ifelse(x[,column]>=thresh,1,0)
 return(x)
}
wet_dry(dt)

and see what you get.

Also, why can I read your message perfectly while everybody else can't?

Jim

>> -----Original Message-----
>> From: roslinaump at gmail.com
>> Sent: Fri, 5 Jun 2015 16:49:08 +0800
>> To: r-help at r-project.org
>> Subject: [R] if else statement for rain data to define zero for dry and
>> one to wet
>>
>> Dear r-users,
>>
>> I have a set of rain data:
>>
>> X1950 X1951 X1952 X1953 X1954 X1955 X1956 X1957 X1958 X1959 X1960 X1961
>> X1962
>>
>> 1   0.0   0.0  14.3   0.0  13.5  13.2   4.0     0   3.3     0     0   0.0
>>
>>
>> 2   0.0   0.0  21.9   0.0  10.9   6.6   2.1     0   0.0     0     0   0.0
>>
>>
>> 3  25.3   6.7  18.6   0.8   2.3   0.0   8.0     0   0.0     0     0  11.0
>>
>>
>> 4  12.7   3.4  37.2   0.9   8.4   0.0   5.8     0   0.0     0     0   5.5
>>
>>
>> 5   0.0   0.0  58.3   3.6  21.1   4.2   3.0     0   0.0     0     0  15.9
>>
>>
>> I would like to go through each column and define each cell with value
>> greater than 0.1 mm will be 1 and else zero. Hence I would like to attach
>> the rain data and the category side by side:
>>
>>
>> 1950   state
>>
>> 1 0.0    0
>>
>> 2 0.0    0
>>
>> 3 25.3   1
>>
>> 4 12.7   1
>>
>> 5 0.0    0
>>
>>
>> ...
>>
>>
>> This is my code:
>>
>>
>> wet_dry  <- function(dt)
>>
>> { cl   <- length(dt)
>>
>>   tresh  <- 0.1
>>
>>
>>   for (i in 1:cl)
>>
>>   {  xi <- dt[,i]
>>
>>      if (xi < tresh ) 0 else 1
>>
>>   }
>>
>> dd <- cbind(dt,xi)
>>
>> dd
>>
>> }
>>
>>
>> wet_dry(dt)
>>
>>
>> Results:
>>
>>> wet_dry(dt)
>>
>>    X1950 X1951 X1952 X1953 X1954 X1955 X1956 X1957 X1958 X1959 X1960
>> X1961
>> X1962 X1963 X1964 X1965 X1966 X1967 X1968 X1969 X1970 X1971 X1972 X1973
>> X1974 X1975 X1976 X1977
>>
>> 1    0.0   0.0  14.3   0.0  13.5  13.2   4.0   0.0   3.3   0.0   0.0
>> 0.0
>>   4.2   0.0   2.2   0.0   4.4   5.1     0   7.2   0.0   0.0   0.0   5.1
>> 0   0.0     0   0.3
>>
>> 2    0.0   0.0  21.9   0.0  10.9   6.6   2.1   0.0   0.0   0.0   0.0
>> 0.0
>>   8.4   0.0   4.0   0.0   4.9   0.7     0   0.0   0.0   0.0   0.0   5.4
>> 0   3.3     0   0.3
>>
>> 3   25.3   6.7  18.6   0.8   2.3   0.0   8.0   0.0   0.0   0.0   0.0
>> 11.0
>>   4.2   0.0   2.0   0.0  14.2  17.1     0   0.0   0.0   0.0   0.0   2.1
>> 0   1.7     0   4.4
>>
>> 4   12.7   3.4  37.2   0.9   8.4   0.0   5.8   0.0   0.0   0.0   0.0
>> 5.5
>>   0.0   0.0   5.4   0.0   6.4  14.9     0  10.1   2.9 143.4   0.0   6.1
>> 0   0.0     0  33.5
>>
>>
>> It does not work and give me the original data.  Why is that?
>>
>>
>> Thank you so much for your help.
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From roslinaump at gmail.com  Sat Jun  6 11:14:27 2015
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Sat, 6 Jun 2015 17:14:27 +0800
Subject: [R] if else statement for rain data to define zero for dry and
	one to wet
In-Reply-To: <CA+8X3fWLmmRj5TZg1hX5A1_yF-COROzeZVC1dApHqyjZbw0+cA@mail.gmail.com>
References: <CANTvJZL6oUjX_Qn9oJXuGKQ85Pjh5HK2q4JrOpafWdNMBvQstQ@mail.gmail.com>
	<D69718E661A.0000043Bjrkrideau@inbox.com>
	<CA+8X3fWLmmRj5TZg1hX5A1_yF-COROzeZVC1dApHqyjZbw0+cA@mail.gmail.com>
Message-ID: <CANTvJZK+s4pL+URjfo0w4hy6J77qv_ebDZ600B_wUXXb4qjaPQ@mail.gmail.com>

Thank you jim.

On Saturday, June 6, 2015, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi rosalinazairimah,
> I think the problem is that you are using "if" instead of "ifelse". Try
> this:
>
> wet_dry<-function(x,thresh=0.1) {
>  for(column in 1:dim(x)[2]) x[,column]<-ifelse(x[,column]>=thresh,1,0)
>  return(x)
> }
> wet_dry(dt)
>
> and see what you get.
>
> Also, why can I read your message perfectly while everybody else can't?
>
> Jim
>
> >> -----Original Message-----
> >> From: roslinaump at gmail.com <javascript:;>
> >> Sent: Fri, 5 Jun 2015 16:49:08 +0800
> >> To: r-help at r-project.org <javascript:;>
> >> Subject: [R] if else statement for rain data to define zero for dry and
> >> one to wet
> >>
> >> Dear r-users,
> >>
> >> I have a set of rain data:
> >>
> >> X1950 X1951 X1952 X1953 X1954 X1955 X1956 X1957 X1958 X1959 X1960 X1961
> >> X1962
> >>
> >> 1   0.0   0.0  14.3   0.0  13.5  13.2   4.0     0   3.3     0     0
>  0.0
> >>
> >>
> >> 2   0.0   0.0  21.9   0.0  10.9   6.6   2.1     0   0.0     0     0
>  0.0
> >>
> >>
> >> 3  25.3   6.7  18.6   0.8   2.3   0.0   8.0     0   0.0     0     0
> 11.0
> >>
> >>
> >> 4  12.7   3.4  37.2   0.9   8.4   0.0   5.8     0   0.0     0     0
>  5.5
> >>
> >>
> >> 5   0.0   0.0  58.3   3.6  21.1   4.2   3.0     0   0.0     0     0
> 15.9
> >>
> >>
> >> I would like to go through each column and define each cell with value
> >> greater than 0.1 mm will be 1 and else zero. Hence I would like to
> attach
> >> the rain data and the category side by side:
> >>
> >>
> >> 1950   state
> >>
> >> 1 0.0    0
> >>
> >> 2 0.0    0
> >>
> >> 3 25.3   1
> >>
> >> 4 12.7   1
> >>
> >> 5 0.0    0
> >>
> >>
> >> ...
> >>
> >>
> >> This is my code:
> >>
> >>
> >> wet_dry  <- function(dt)
> >>
> >> { cl   <- length(dt)
> >>
> >>   tresh  <- 0.1
> >>
> >>
> >>   for (i in 1:cl)
> >>
> >>   {  xi <- dt[,i]
> >>
> >>      if (xi < tresh ) 0 else 1
> >>
> >>   }
> >>
> >> dd <- cbind(dt,xi)
> >>
> >> dd
> >>
> >> }
> >>
> >>
> >> wet_dry(dt)
> >>
> >>
> >> Results:
> >>
> >>> wet_dry(dt)
> >>
> >>    X1950 X1951 X1952 X1953 X1954 X1955 X1956 X1957 X1958 X1959 X1960
> >> X1961
> >> X1962 X1963 X1964 X1965 X1966 X1967 X1968 X1969 X1970 X1971 X1972 X1973
> >> X1974 X1975 X1976 X1977
> >>
> >> 1    0.0   0.0  14.3   0.0  13.5  13.2   4.0   0.0   3.3   0.0   0.0
> >> 0.0
> >>   4.2   0.0   2.2   0.0   4.4   5.1     0   7.2   0.0   0.0   0.0   5.1
> >> 0   0.0     0   0.3
> >>
> >> 2    0.0   0.0  21.9   0.0  10.9   6.6   2.1   0.0   0.0   0.0   0.0
> >> 0.0
> >>   8.4   0.0   4.0   0.0   4.9   0.7     0   0.0   0.0   0.0   0.0   5.4
> >> 0   3.3     0   0.3
> >>
> >> 3   25.3   6.7  18.6   0.8   2.3   0.0   8.0   0.0   0.0   0.0   0.0
> >> 11.0
> >>   4.2   0.0   2.0   0.0  14.2  17.1     0   0.0   0.0   0.0   0.0   2.1
> >> 0   1.7     0   4.4
> >>
> >> 4   12.7   3.4  37.2   0.9   8.4   0.0   5.8   0.0   0.0   0.0   0.0
> >> 5.5
> >>   0.0   0.0   5.4   0.0   6.4  14.9     0  10.1   2.9 143.4   0.0   6.1
> >> 0   0.0     0  33.5
> >>
> >>
> >> It does not work and give me the original data.  Why is that?
> >>
> >>
> >> Thank you so much for your help.
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Sat Jun  6 21:35:33 2015
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 6 Jun 2015 15:35:33 -0400
Subject: [R] A-priori contrasts with type III sums of squares in R
In-Reply-To: <55722372.50105@nceas.ucsb.edu>
References: <55722372.50105@nceas.ucsb.edu>
Message-ID: <001701d0a08f$f4ee9bb0$decbd310$@mcmaster.ca>

Dear Rachel,

Anova() won't give you a breakdown of the SS for each term into 1 df
components (there is no split argument, as you can see if you look at
?Anova). Because, with the exception of GzrTreat, your contrasts are not
orthogonal in the row basis of the design (apparently you're using the
default "contr.treatment" coding), you also won't get sensible type-III
tests from Anova(). If you formulated the contrasts for the other factors
properly (using, e.g., contr.sum), you could get single df tests from
linearHypothesis() in the car package.

I hope this helps,
 John

-----------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox/




> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rachael
> Blake
> Sent: June-05-15 6:32 PM
> To: r-help at r-project.org
> Subject: [R] A-priori contrasts with type III sums of squares in R
> 
> I am analyzing data using a factorial three-way ANOVA with a-priori
> contrasts and type III sums of squares. (Please don't comment about type
> I SS vs. type III SS. That's not the point of my question.  I have read
> at length about the choice between types of SS and have made my
> decision.) I get the contrasts like I need using summary.aov(), however
> that uses type I SS. When I use the Anova() function from library(car)
> to get type III SS, I don't get the contrasts. I have also tried using
> drop1() with the lm() model, but I get the same results as Anova()
> (without the contrasts).
> 
> Please advise on a statistical method in R to analyze data using
> factorial ANOVA with a-priori contrasts and type III SS as shown in my
> example below.
> 
> Sample data:
>      DF <- structure(list(Code = structure(c(1L, 1L, 1L, 2L, 2L, 2L, 3L,
> 3L,
>      3L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L, 7L, 7L, 7L, 8L, 8L, 8L, 9L,
> 9L,
>      9L, 10L, 10L, 10L, 11L, 11L, 11L, 12L, 12L, 12L), .Label = c("A",
>      "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L"), class =
>      "factor"), GzrTreat = structure(c(3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L,
>      3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,  2L,
> 2L,
>      2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), contrasts = structure(c(1,
>      -2, 1, 1, 0, -1), .Dim = c(3L, 2L), .Dimnames = list(c("I",
>      "N", "R"), NULL)), .Label = c("I", "N", "R"), class = "factor"),
>      BugTreat = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>      1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>      3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label =
>      c("Immigration", "Initial", "None"), class = "factor"), TempTreat =
>      structure(c(2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
> 2L,
>      2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L,
>      1L, 1L, 1L, 1L, 1L), .Label = c("Not Warm", "Warmed"), class =
>      "factor"), ShadeTreat = structure(c(2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L,
>      2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
>      1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L), .Label =
> c("Light",
>      "Shaded"), class = "factor"), EpiChla = c(0.268482353, 0.423119608,
>      0.579507843, 0.738839216, 0.727856863, 0.523960784, 0.405801961,
>      0.335964706, 0.584441176, 0.557543137, 0.436456863, 0.563909804,
>      0.432398039, 0.344956863, 0.340309804, 0.992884314, 0.938390196,
>      0.663270588, 0.239833333, 0.62875098, 0.466011765, 0.536182353,
>      0.340309804, 0.721172549, 0.752082353, 0.269372549, 0.198180392,
>      1.298882353, 0.298354902, 0.913139216, 0.846129412, 0.922317647,
>      0.727033333, 1.187662745, 0.35622549, 0.073547059), log_EpiChla =
>      c(0.10328443, 0.153241402, 0.198521787, 0.240259426, 0.237507762,
>      0.182973791, 0.147924145, 0.125794985, 0.19987612, 0.192440084,
>      0.157292589, 0.194211702, 0.156063718, 0.128708355, 0.127205194,
>      0.299482089, 0.287441205, 0.220962908, 0.093363308, 0.21185469,
>      0.166137456, 0.186442772, 0.127205194, 0.235824411, 0.243554515,
>      0.103589102, 0.078522208, 0.361516746, 0.113393422, 0.281746574,
>      0.266262141, 0.283825153, 0.23730072, 0.339980371, 0.132331903,
>      0.030821087), MeanZGrowthAFDM_g = c(0.00665, 0.003966667,
> 0.004466667,
>      0.01705, 0.0139, 0.0129, 0.0081, 0.003833333, 0.00575, 0.011266667,
>      0.0103, 0.009, 0.0052, 0.00595, 0.0105, 0.0091, 0.00905, 0.0045,
> 0.0031,
>      0.006466667, 0.0053, 0.009766667, 0.0181, 0.00725, 0, 0.0012, 5e-
> 04,
>      0.0076, 0.00615, 0.0814, NA, 0.0038, 0.00165, 0.0046, 0, 0.0015)),
>      .Names = c("Code", "GzrTreat", "BugTreat", "TempTreat",
> "ShadeTreat",
>      "EpiChla", "log_EpiChla", "MeanZGrowthAFDM_g"), class =
> "data.frame",
>      row.names = c(NA, -36L))
> 
> 
> Code:
> 
>      ## a-priori contrasts
>      library(stats)
>      contrasts(DF$GzrTreat) <- cbind(c(1,-2,1), c(1,0,-1))
>      round(crossprod(contrasts(DF$GzrTreat)))
>      c_labels <- list(GzrTreat=list('presence'=1, 'immigration'=2))
> 
>      ## model
>      library(car)
>      EpiLM <- lm(log_EpiChla~TempTreat*GzrTreat*ShadeTreat, DF)
>      summary.aov(EpiLM, split=c_labels) ### MUST USE summary.aov(), to
> get
>      #contrast results, but sadly this uses Type I SS
>      Anova(EpiLM, split=c_labels, type="III") # Uses Type III SS, but NO
>      #CONTRASTS!!!!!
>      drop1(EpiLM, ~., test="F") # again, this does not print contrasts
> 
>      # I need contrast results like from summary.aov(), AND Type III SS
>      # like from Anova()
> 
> 
> 
> --
> Rachael E. Blake, PhD
> Post-doctoral Associate
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


---
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From djmuser at gmail.com  Sat Jun  6 22:55:44 2015
From: djmuser at gmail.com (Dennis Murphy)
Date: Sat, 6 Jun 2015 13:55:44 -0700
Subject: [R] if else statement for rain data to define zero for dry and
 one to wet
In-Reply-To: <CA+8X3fWLmmRj5TZg1hX5A1_yF-COROzeZVC1dApHqyjZbw0+cA@mail.gmail.com>
References: <CANTvJZL6oUjX_Qn9oJXuGKQ85Pjh5HK2q4JrOpafWdNMBvQstQ@mail.gmail.com>
	<D69718E661A.0000043Bjrkrideau@inbox.com>
	<CA+8X3fWLmmRj5TZg1hX5A1_yF-COROzeZVC1dApHqyjZbw0+cA@mail.gmail.com>
Message-ID: <CADv2QyGshTJw5Bf=X6jbzSdynLC5BHjwOKJR2zv9KDOvVDGQRw@mail.gmail.com>

I'm sorry, but I have to take issue with this particular use case of
ifelse(). When the goal is to generate a logical vector, ifelse() is
very inefficient. It's better to apply a logical condition directly to
the object in question and multiply the result by 1 to make it
numeric/integer rather than logical.

To illustrate this, consider the following toy example. The function
f1 replicates the suggestion to apply ifelse() columnwise (with the
additional overhead of preallocating storage for the result), whereas
the function f2 applies the logical condition on the matrix itself
using vectorization, with the recognition that a matrix is an atomic
vector with a dim attribute.

set.seed(5290)

# 1000 x 1000 matrix
m <- matrix(sample(c(0, 0.05, 0.2), 1e6, replace = TRUE), ncol = 1000)

f1 <- function(mat)
  {
     newmat <- matrix(NA, ncol = ncol(mat), nrow = nrow(mat))
     for(i in seq_len(ncol(mat)))
         newmat[, i] <- ifelse(mat[, i] > 0.1, 1, 0)
     newmat
  }

f2 <- function(mat) 1 * (mat > 0.1)


On my system, I got

> system.time(m1 <- f1(m))
   user  system elapsed
   0.14    0.00    0.14

> system.time(m2 <- f2(m))
   user  system elapsed
   0.01    0.00    0.01

> identical(m1, m2)
[1] TRUE

The all too common practice of using  ifelse(condition, 1, 0) on an
atomic vector is easily replaced by 1 * (condition), where the result
of condition is a logical atomic object coerced to numeric.

To reduce memory, one should better define f2 as

f2 <- function(mat) 1L * (mat > 0.1)

but doing so in this example no longer creates identical objects since

> typeof(m1)
[1] "double"

Thus, f1 is not only inefficient in terms of execution time, it's also
inefficient in terms of storage.

Given several recent warnings in this forum about the inefficiency of
ifelse() and the dozens of times I've seen the idiom implemented in f1
as a solution over the last several years (to which I have likely
contributed in my distant past as an R-helper), I felt compelled to
say something about this practice, which BTW extends not just to 0/1
return values but to
0/x return values, where x is a nonzero real number.

Dennis


On Sat, Jun 6, 2015 at 12:50 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi rosalinazairimah,
> I think the problem is that you are using "if" instead of "ifelse". Try this:
>
> wet_dry<-function(x,thresh=0.1) {
>  for(column in 1:dim(x)[2]) x[,column]<-ifelse(x[,column]>=thresh,1,0)
>  return(x)
> }
> wet_dry(dt)
>
> and see what you get.
>
> Also, why can I read your message perfectly while everybody else can't?
>
> Jim
>
>>> -----Original Message-----
>>> From: roslinaump at gmail.com
>>> Sent: Fri, 5 Jun 2015 16:49:08 +0800
>>> To: r-help at r-project.org
>>> Subject: [R] if else statement for rain data to define zero for dry and
>>> one to wet
>>>
>>> Dear r-users,
>>>
>>> I have a set of rain data:
>>>
>>> X1950 X1951 X1952 X1953 X1954 X1955 X1956 X1957 X1958 X1959 X1960 X1961
>>> X1962
>>>
>>> 1   0.0   0.0  14.3   0.0  13.5  13.2   4.0     0   3.3     0     0   0.0
>>>
>>>
>>> 2   0.0   0.0  21.9   0.0  10.9   6.6   2.1     0   0.0     0     0   0.0
>>>
>>>
>>> 3  25.3   6.7  18.6   0.8   2.3   0.0   8.0     0   0.0     0     0  11.0
>>>
>>>
>>> 4  12.7   3.4  37.2   0.9   8.4   0.0   5.8     0   0.0     0     0   5.5
>>>
>>>
>>> 5   0.0   0.0  58.3   3.6  21.1   4.2   3.0     0   0.0     0     0  15.9
>>>
>>>
>>> I would like to go through each column and define each cell with value
>>> greater than 0.1 mm will be 1 and else zero. Hence I would like to attach
>>> the rain data and the category side by side:
>>>
>>>
>>> 1950   state
>>>
>>> 1 0.0    0
>>>
>>> 2 0.0    0
>>>
>>> 3 25.3   1
>>>
>>> 4 12.7   1
>>>
>>> 5 0.0    0
>>>
>>>
>>> ...
>>>
>>>
>>> This is my code:
>>>
>>>
>>> wet_dry  <- function(dt)
>>>
>>> { cl   <- length(dt)
>>>
>>>   tresh  <- 0.1
>>>
>>>
>>>   for (i in 1:cl)
>>>
>>>   {  xi <- dt[,i]
>>>
>>>      if (xi < tresh ) 0 else 1
>>>
>>>   }
>>>
>>> dd <- cbind(dt,xi)
>>>
>>> dd
>>>
>>> }
>>>
>>>
>>> wet_dry(dt)
>>>
>>>
>>> Results:
>>>
>>>> wet_dry(dt)
>>>
>>>    X1950 X1951 X1952 X1953 X1954 X1955 X1956 X1957 X1958 X1959 X1960
>>> X1961
>>> X1962 X1963 X1964 X1965 X1966 X1967 X1968 X1969 X1970 X1971 X1972 X1973
>>> X1974 X1975 X1976 X1977
>>>
>>> 1    0.0   0.0  14.3   0.0  13.5  13.2   4.0   0.0   3.3   0.0   0.0
>>> 0.0
>>>   4.2   0.0   2.2   0.0   4.4   5.1     0   7.2   0.0   0.0   0.0   5.1
>>> 0   0.0     0   0.3
>>>
>>> 2    0.0   0.0  21.9   0.0  10.9   6.6   2.1   0.0   0.0   0.0   0.0
>>> 0.0
>>>   8.4   0.0   4.0   0.0   4.9   0.7     0   0.0   0.0   0.0   0.0   5.4
>>> 0   3.3     0   0.3
>>>
>>> 3   25.3   6.7  18.6   0.8   2.3   0.0   8.0   0.0   0.0   0.0   0.0
>>> 11.0
>>>   4.2   0.0   2.0   0.0  14.2  17.1     0   0.0   0.0   0.0   0.0   2.1
>>> 0   1.7     0   4.4
>>>
>>> 4   12.7   3.4  37.2   0.9   8.4   0.0   5.8   0.0   0.0   0.0   0.0
>>> 5.5
>>>   0.0   0.0   5.4   0.0   6.4  14.9     0  10.1   2.9 143.4   0.0   6.1
>>> 0   0.0     0  33.5
>>>
>>>
>>> It does not work and give me the original data.  Why is that?
>>>
>>>
>>> Thank you so much for your help.
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Sat Jun  6 23:48:13 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 6 Jun 2015 14:48:13 -0700
Subject: [R] if else statement for rain data to define zero for dry and
 one to wet
In-Reply-To: <CADv2QyGshTJw5Bf=X6jbzSdynLC5BHjwOKJR2zv9KDOvVDGQRw@mail.gmail.com>
References: <CANTvJZL6oUjX_Qn9oJXuGKQ85Pjh5HK2q4JrOpafWdNMBvQstQ@mail.gmail.com>
	<D69718E661A.0000043Bjrkrideau@inbox.com>
	<CA+8X3fWLmmRj5TZg1hX5A1_yF-COROzeZVC1dApHqyjZbw0+cA@mail.gmail.com>
	<CADv2QyGshTJw5Bf=X6jbzSdynLC5BHjwOKJR2zv9KDOvVDGQRw@mail.gmail.com>
Message-ID: <CAF8bMcZShP=wHCGOL4o3PMO1Fupbvf5KOwT_van-MHd3DZKNMw@mail.gmail.com>

Your f1() has an unneeded for loop in it.
   f1a <- function(mat) mat > 0.1, 1, 0)
would do the same thing in a bit less time.

However, I think that a simple
   mat > 0.1
would be preferable.  The resulting TRUEs and FALSEs
are easier to interpret than the 1s and 0s that f1a()
produces and arithmetic functions treat them TRUE
as 1 and FALSE as 0 internally.  E.g., mean(mat>0.1)
gives the proportion of wet(tish) days.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Jun 6, 2015 at 1:55 PM, Dennis Murphy <djmuser at gmail.com> wrote:

> I'm sorry, but I have to take issue with this particular use case of
> ifelse(). When the goal is to generate a logical vector, ifelse() is
> very inefficient. It's better to apply a logical condition directly to
> the object in question and multiply the result by 1 to make it
> numeric/integer rather than logical.
>
> To illustrate this, consider the following toy example. The function
> f1 replicates the suggestion to apply ifelse() columnwise (with the
> additional overhead of preallocating storage for the result), whereas
> the function f2 applies the logical condition on the matrix itself
> using vectorization, with the recognition that a matrix is an atomic
> vector with a dim attribute.
>
> set.seed(5290)
>
> # 1000 x 1000 matrix
> m <- matrix(sample(c(0, 0.05, 0.2), 1e6, replace = TRUE), ncol = 1000)
>
> f1 <- function(mat)
>   {
>      newmat <- matrix(NA, ncol = ncol(mat), nrow = nrow(mat))
>      for(i in seq_len(ncol(mat)))
>          newmat[, i] <- ifelse(mat[, i] > 0.1, 1, 0)
>      newmat
>   }
>
> f2 <- function(mat) 1 * (mat > 0.1)
>
>
> On my system, I got
>
> > system.time(m1 <- f1(m))
>    user  system elapsed
>    0.14    0.00    0.14
>
> > system.time(m2 <- f2(m))
>    user  system elapsed
>    0.01    0.00    0.01
>
> > identical(m1, m2)
> [1] TRUE
>
> The all too common practice of using  ifelse(condition, 1, 0) on an
> atomic vector is easily replaced by 1 * (condition), where the result
> of condition is a logical atomic object coerced to numeric.
>
> To reduce memory, one should better define f2 as
>
> f2 <- function(mat) 1L * (mat > 0.1)
>
> but doing so in this example no longer creates identical objects since
>
> > typeof(m1)
> [1] "double"
>
> Thus, f1 is not only inefficient in terms of execution time, it's also
> inefficient in terms of storage.
>
> Given several recent warnings in this forum about the inefficiency of
> ifelse() and the dozens of times I've seen the idiom implemented in f1
> as a solution over the last several years (to which I have likely
> contributed in my distant past as an R-helper), I felt compelled to
> say something about this practice, which BTW extends not just to 0/1
> return values but to
> 0/x return values, where x is a nonzero real number.
>
> Dennis
>
>
> On Sat, Jun 6, 2015 at 12:50 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> > Hi rosalinazairimah,
> > I think the problem is that you are using "if" instead of "ifelse". Try
> this:
> >
> > wet_dry<-function(x,thresh=0.1) {
> >  for(column in 1:dim(x)[2]) x[,column]<-ifelse(x[,column]>=thresh,1,0)
> >  return(x)
> > }
> > wet_dry(dt)
> >
> > and see what you get.
> >
> > Also, why can I read your message perfectly while everybody else can't?
> >
> > Jim
> >
> >>> -----Original Message-----
> >>> From: roslinaump at gmail.com
> >>> Sent: Fri, 5 Jun 2015 16:49:08 +0800
> >>> To: r-help at r-project.org
> >>> Subject: [R] if else statement for rain data to define zero for dry and
> >>> one to wet
> >>>
> >>> Dear r-users,
> >>>
> >>> I have a set of rain data:
> >>>
> >>> X1950 X1951 X1952 X1953 X1954 X1955 X1956 X1957 X1958 X1959 X1960 X1961
> >>> X1962
> >>>
> >>> 1   0.0   0.0  14.3   0.0  13.5  13.2   4.0     0   3.3     0     0
>  0.0
> >>>
> >>>
> >>> 2   0.0   0.0  21.9   0.0  10.9   6.6   2.1     0   0.0     0     0
>  0.0
> >>>
> >>>
> >>> 3  25.3   6.7  18.6   0.8   2.3   0.0   8.0     0   0.0     0     0
> 11.0
> >>>
> >>>
> >>> 4  12.7   3.4  37.2   0.9   8.4   0.0   5.8     0   0.0     0     0
>  5.5
> >>>
> >>>
> >>> 5   0.0   0.0  58.3   3.6  21.1   4.2   3.0     0   0.0     0     0
> 15.9
> >>>
> >>>
> >>> I would like to go through each column and define each cell with value
> >>> greater than 0.1 mm will be 1 and else zero. Hence I would like to
> attach
> >>> the rain data and the category side by side:
> >>>
> >>>
> >>> 1950   state
> >>>
> >>> 1 0.0    0
> >>>
> >>> 2 0.0    0
> >>>
> >>> 3 25.3   1
> >>>
> >>> 4 12.7   1
> >>>
> >>> 5 0.0    0
> >>>
> >>>
> >>> ...
> >>>
> >>>
> >>> This is my code:
> >>>
> >>>
> >>> wet_dry  <- function(dt)
> >>>
> >>> { cl   <- length(dt)
> >>>
> >>>   tresh  <- 0.1
> >>>
> >>>
> >>>   for (i in 1:cl)
> >>>
> >>>   {  xi <- dt[,i]
> >>>
> >>>      if (xi < tresh ) 0 else 1
> >>>
> >>>   }
> >>>
> >>> dd <- cbind(dt,xi)
> >>>
> >>> dd
> >>>
> >>> }
> >>>
> >>>
> >>> wet_dry(dt)
> >>>
> >>>
> >>> Results:
> >>>
> >>>> wet_dry(dt)
> >>>
> >>>    X1950 X1951 X1952 X1953 X1954 X1955 X1956 X1957 X1958 X1959 X1960
> >>> X1961
> >>> X1962 X1963 X1964 X1965 X1966 X1967 X1968 X1969 X1970 X1971 X1972 X1973
> >>> X1974 X1975 X1976 X1977
> >>>
> >>> 1    0.0   0.0  14.3   0.0  13.5  13.2   4.0   0.0   3.3   0.0   0.0
> >>> 0.0
> >>>   4.2   0.0   2.2   0.0   4.4   5.1     0   7.2   0.0   0.0   0.0   5.1
> >>> 0   0.0     0   0.3
> >>>
> >>> 2    0.0   0.0  21.9   0.0  10.9   6.6   2.1   0.0   0.0   0.0   0.0
> >>> 0.0
> >>>   8.4   0.0   4.0   0.0   4.9   0.7     0   0.0   0.0   0.0   0.0   5.4
> >>> 0   3.3     0   0.3
> >>>
> >>> 3   25.3   6.7  18.6   0.8   2.3   0.0   8.0   0.0   0.0   0.0   0.0
> >>> 11.0
> >>>   4.2   0.0   2.0   0.0  14.2  17.1     0   0.0   0.0   0.0   0.0   2.1
> >>> 0   1.7     0   4.4
> >>>
> >>> 4   12.7   3.4  37.2   0.9   8.4   0.0   5.8   0.0   0.0   0.0   0.0
> >>> 5.5
> >>>   0.0   0.0   5.4   0.0   6.4  14.9     0  10.1   2.9 143.4   0.0   6.1
> >>> 0   0.0     0  33.5
> >>>
> >>>
> >>> It does not work and give me the original data.  Why is that?
> >>>
> >>>
> >>> Thank you so much for your help.
> >>>
> >>>       [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jim.silverton at gmail.com  Sun Jun  7 05:04:49 2015
From: jim.silverton at gmail.com (Jim Silverton)
Date: Sat, 6 Jun 2015 23:04:49 -0400
Subject: [R] Simulating data from a nested design
Message-ID: <CAGPwjHx3f6=NRhYNxhV-7TSvDKDLEd22T2ndfRMmV0Q7Z0YE3w@mail.gmail.com>

Hi,
I am trying to 'create' a nested design with A, B nested in A and C nested
in B. C is random and the others are fixed.
Does anyone have any idea how to do this?
I would also like to try the other nested designs with all random  and all
effects fixed.

-- 
Thanks,
Jim.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Jun  7 07:39:18 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 7 Jun 2015 15:39:18 +1000
Subject: [R] R to HTML problem
In-Reply-To: <CAGa91zi-_9kaC+UAsPdh0q+oC50VzY2w4nbr3sDps3pVJmCbbA@mail.gmail.com>
References: <CAGa91zi-_9kaC+UAsPdh0q+oC50VzY2w4nbr3sDps3pVJmCbbA@mail.gmail.com>
Message-ID: <CA+8X3fUxGDQbC34DbuhFQ8HV1zrMaoTyt73chdopgVmunW0TcQ@mail.gmail.com>

Hi Pijush,
Does this do what you want?

#title~"Output of Class Prediction"
cat("The output result is given below\n")
iris.df<-cbind(iris[1:10,1:4],rep("",10),iris[1:10,1:4])
names(iris.df)<-c(names(iris)[1:4],"",names(iris)[1:4])
delim.table(iris.df,html=TRUE)

Save the result as "sample.R" in the R working directory and then:

library(prettyR)
htmlize("sample.R")

Jim


On Fri, Jun 5, 2015 at 8:57 PM, Pijush Das <topijush at gmail.com> wrote:
> Hi r-help,
>
>
> I am trying to develop a program in R where I want to display the
> out put result in a HTML page. But I unable to put two tables side by side
> which is required to me. Another problem is that I unable to put the title
> in the center of the
> page. The code is given below.
>
>
> Please help me.
>
> library(R2HTML)
> filepath<-"C:/Users/Desktop/Selection"
> target <- HTMLInitFile(filepath,filename="sample",
> BackGroundColor="#FFFFFF")
> HTML.title("Output of Class Prediction",file=target, HR=3)
> HTML("<br>",file=target)
> HTML("The output result is given below:",file=target)
> HTML(iris[1:10,1:4], file=target,align = "left",Border = 1, innerBorder = 1)
> HTML(iris[1:10,1:4], file=target,align = "left",Border = 1, innerBorder = 1)
> HTMLEndFile()
>
>
> Thank you.
>
> Regards
> Pijush
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From yelin at lbl.gov  Sun Jun  7 07:50:13 2015
From: yelin at lbl.gov (Ye Lin)
Date: Sat, 6 Jun 2015 22:50:13 -0700
Subject: [R] how to read a local JSON file
Message-ID: <CAAvu=bms6tLJncLtUw0nrqNsHjmDZehMxXx-BpFQT=b_6G2r8w@mail.gmail.com>

Hi All,

I downloaded a data file from dropbox and its in JSON format.

here is my code:
library(RJSONIO)
data <- fromJSON(file='C:/Users/Downloads/sample.json')
Lines <- readLines("C:/Users/Downloads/sample.json")
df <- as.data.frame(t(sapply(Lines, fromJSON)))

I got this error message:
incomplete final line found on 'C:/Users/Downloads/sample.json'

The file path is def correct, can anyone help me on this?

Thanks!

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Jun  7 07:57:57 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 7 Jun 2015 15:57:57 +1000
Subject: [R] Changing colours for heatmap plot
In-Reply-To: <CAJgdCD6Tj-_FuYA0YHkNc78y+vR92DUPRg9tnAP34AWJqt+hNw@mail.gmail.com>
References: <CAJgdCD6Tj-_FuYA0YHkNc78y+vR92DUPRg9tnAP34AWJqt+hNw@mail.gmail.com>
Message-ID: <CA+8X3fVm6v5Twy+=L92OztSNBSj6zpdAakTokugkfXVP5iPEOw@mail.gmail.com>

Hi John,
As heat.colors is a function that returns a vector of colors specified
by the "n" argument, you could write something like this:

my_custom_colors<-function(n,color_vector="lightgray")
return(rep(color_vector,length.out=n)))

and then pass the desired color vector to it:

green_n_black<-c("green", "green", "black",
"green", "green", "black", "black", "green", "green", "black")
my_custom_colors(12,green_n_black)
my_custom_colors(4,green_n_black)

Jim

On Fri, Jun 5, 2015 at 10:33 PM, John Wasige <johnwasige at gmail.com> wrote:
> Dear community,
>
> Could somebody help on how I can change the colour for this plot in the
> heatmap plot script below to something like c("green", "green", "black",
> "green", "green", "black", "black", "green", "green", "black"):
>
> ######
> library(gplots)
> library(lattice)
>
> ### loading data
> data <- read.csv('D:/Londa/MyData.csv')
> rowcolNames <- list(as.character(1980:2009), month.abb)
> air_data <- matrix(data ,
>                    ncol = 12,
>                    byrow = TRUE,
>                    dimnames = rowcolNames)
>
> print(levelplot(air_data,
>                 col.regions=heat.colors,
>                 xlab = "year",
>                 ylab = "month",
>                 main = "New #1"))
>
> ##########
>
> Thanks for your help
>
> John
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun Jun  7 08:01:16 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 7 Jun 2015 16:01:16 +1000
Subject: [R] how to read a local JSON file
In-Reply-To: <CAAvu=bms6tLJncLtUw0nrqNsHjmDZehMxXx-BpFQT=b_6G2r8w@mail.gmail.com>
References: <CAAvu=bms6tLJncLtUw0nrqNsHjmDZehMxXx-BpFQT=b_6G2r8w@mail.gmail.com>
Message-ID: <CA+8X3fXoM2QQQHdixKCQwVCWabaSgmpVpZ04BFpD41HYiPEDcQ@mail.gmail.com>

Hi Ye Lin,
Looks like the file was read, but there is no linefeed at the end of
the last line. You could probably stick one in using a text or hex
editor and you won't get the warning.

Jim


On Sun, Jun 7, 2015 at 3:50 PM, Ye Lin <yelin at lbl.gov> wrote:
> Hi All,
>
> I downloaded a data file from dropbox and its in JSON format.
>
> here is my code:
> library(RJSONIO)
> data <- fromJSON(file='C:/Users/Downloads/sample.json')
> Lines <- readLines("C:/Users/Downloads/sample.json")
> df <- as.data.frame(t(sapply(Lines, fromJSON)))
>
> I got this error message:
> incomplete final line found on 'C:/Users/Downloads/sample.json'
>
> The file path is def correct, can anyone help me on this?
>
> Thanks!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Sun Jun  7 09:10:24 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 7 Jun 2015 09:10:24 +0200
Subject: [R] how to read a local JSON file
In-Reply-To: <CAAvu=bms6tLJncLtUw0nrqNsHjmDZehMxXx-BpFQT=b_6G2r8w@mail.gmail.com>
References: <CAAvu=bms6tLJncLtUw0nrqNsHjmDZehMxXx-BpFQT=b_6G2r8w@mail.gmail.com>
Message-ID: <37B9697A-B782-4A63-B202-397682F4B892@xs4all.nl>


> On 07-06-2015, at 07:50, Ye Lin <yelin at lbl.gov> wrote:
> 
> Hi All,
> 
> I downloaded a data file from dropbox and its in JSON format.
> 
> here is my code:
> library(RJSONIO)
> data <- fromJSON(file='C:/Users/Downloads/sample.json')
> Lines <- readLines("C:/Users/Downloads/sample.json")
> df <- as.data.frame(t(sapply(Lines, fromJSON)))
> 
> I got this error message:
> incomplete final line found on 'C:/Users/Downloads/sample.json?
> 

It?s a warning NOT an error message. And it?s perfectly clear.

See here in the archives of R-help: https://stat.ethz.ch/pipermail/r-help/2011-December/298216.html

Take Lim Lemon?s advice: use a plain text editor , goto the last line in the file, goto to the end of the line and then press <Return> or <Enter> 

Berend

> The file path is def correct, can anyone help me on this?
> 
> Thanks!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Sun Jun  7 09:32:34 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 07 Jun 2015 08:32:34 +0100
Subject: [R] how to read a local JSON file
In-Reply-To: <37B9697A-B782-4A63-B202-397682F4B892@xs4all.nl>
References: <CAAvu=bms6tLJncLtUw0nrqNsHjmDZehMxXx-BpFQT=b_6G2r8w@mail.gmail.com>
	<37B9697A-B782-4A63-B202-397682F4B892@xs4all.nl>
Message-ID: <5573F392.9050205@stats.ox.ac.uk>

On 07/06/2015 08:10, Berend Hasselman wrote:
>
>> On 07-06-2015, at 07:50, Ye Lin <yelin at lbl.gov> wrote:
>>
>> Hi All,
>>
>> I downloaded a data file from dropbox and its in JSON format.
>>
>> here is my code:
>> library(RJSONIO)
>> data <- fromJSON(file='C:/Users/Downloads/sample.json')
>> Lines <- readLines("C:/Users/Downloads/sample.json")
>> df <- as.data.frame(t(sapply(Lines, fromJSON)))
>>
>> I got this error message:
>> incomplete final line found on 'C:/Users/Downloads/sample.json?
>>
>
> It?s a warning NOT an error message. And it?s perfectly clear.
>
> See here in the archives of R-help: https://stat.ethz.ch/pipermail/r-help/2011-December/298216.html
>
> Take Lim Lemon?s advice: use a plain text editor , goto the last line in the file, goto to the end of the line and then press <Return> or <Enter>

Or read the help (especially when replying):

     warn: logical.  Warn if a text file is missing a final EOL or if
           there are embedded nuls in the file.

If you know the file is not a normal text file, use warn = FALSE.



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From 538280 at gmail.com  Sun Jun  7 18:16:14 2015
From: 538280 at gmail.com (Greg Snow)
Date: Sun, 7 Jun 2015 10:16:14 -0600
Subject: [R] Simulating data from a nested design
In-Reply-To: <CAGPwjHx3f6=NRhYNxhV-7TSvDKDLEd22T2ndfRMmV0Q7Z0YE3w@mail.gmail.com>
References: <CAGPwjHx3f6=NRhYNxhV-7TSvDKDLEd22T2ndfRMmV0Q7Z0YE3w@mail.gmail.com>
Message-ID: <CAFEqCdwmmtrOFO-f4CcvZoAEaXWa2EKcaJyZuDvLfJgc_pxA4Q@mail.gmail.com>

The examples on the help page for the function "simfun" in the
TeachingDemos package have some examples of simulating data from
nested designs with some terms fixed and some random.  I don't think
any of the examples match your conditions exactly, but could be
modified to do so (changing a random effect to a fixed effect just
means using a specified mean for each level rather than choosing a
random value for each level).

On Sat, Jun 6, 2015 at 9:04 PM, Jim Silverton <jim.silverton at gmail.com> wrote:
> Hi,
> I am trying to 'create' a nested design with A, B nested in A and C nested
> in B. C is random and the others are fixed.
> Does anyone have any idea how to do this?
> I would also like to try the other nested designs with all random  and all
> effects fixed.
>
> --
> Thanks,
> Jim.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From nouri4 at yahoo.com  Sun Jun  7 05:25:42 2015
From: nouri4 at yahoo.com (knouri)
Date: Sun, 7 Jun 2015 03:25:42 +0000 (UTC)
Subject: [R] Cross-over Data with Kenward-Roger correction
Message-ID: <695109458.7792923.1433647542770.JavaMail.yahoo@mail.yahoo.com>

Dear all:for the folowing data, a two-period, two treatment (A=1 vs. B=2) cross-over is fitted
using the folowing SAS code.? 
data one;
input? Sbj? Seq ?Per? Trt? PEF;
cards;
1???? ?1?? 1?? 1?? 310
1???? ?1?? 2?? 2?? 270
4???? ?1?? 1?? 1?? 310
4???? ?1?? 2?? 2?? 260
6???? ?1?? 1?? 1?? 370
6???? ?1?? 2?? 2?? 300
7????? 1?? 1?? 1?? 410
7????? 1?? 2?? 2?? 390
10??? 1?? 1?? 1?? 250
10??? 1?? 2?? 2?? 210
11??? 1?? 1?? 1?? 380
11??? 1?? 2?? 2?? 350
14??? 1?? 1?? 1?? 330
14??? 1?? 2?? 2?? 365
2????? 2?? 1?? 2?? 370
2????? 2?? 2?? 1?? 385
3????? 2?? 1?? 2?? 310
3???? ?2?? 2?? 1?? 400
5???? ?2?? 1?? 2?? 380
5????? 2?? 2?? 1?? 410
9????? 2?? 1?? 2?? 290
9????? 2?? 2?? 1?? 320
12??? 2?? 1?? 2?? 260
12??? 2?? 2?? 1?? 340
13??? 2?? 1?? 2??? 90
13??? 2?? 2?? 1?? 220
;
run;
proc mixed data=one method=reml;
class Sbj Per Trt;
?? model PEF = Per Trt /ddfm=kr;
?? repeated Trt / sub=Sbj type=un r;
?? lsmeans Trt / cl alpha=0.05;
?? estimate 'B vs. A' Trt -1? 1 / alpha=0.1 cl;
run;
(where kr option is for Kenward-Roger method).I need to use R to reproduce the results similar to what the above SAS code generates.
I have used several R functions including lme, lmer with no success so far.Any advice will be greatly appreciated,Sincerely,
Keramat

	[[alternative HTML version deleted]]


From sinha.varuna85 at gmail.com  Sun Jun  7 11:31:41 2015
From: sinha.varuna85 at gmail.com (Varun Sinha)
Date: Sun, 7 Jun 2015 12:31:41 +0300
Subject: [R] source code for dbeta
Message-ID: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>

Hi,

I am trying to find the source code for dbeta function.

I tried edit(dbeta) and this is what I got:
> edit(dbeta)
function (x, shape1, shape2, ncp = 0, log = FALSE)
{
    if (missing(ncp))
        .Call(C_dbeta, x, shape1, shape2, log)
    else .Call(C_dnbeta, x, shape1, shape2, ncp, log)
}
<environment: namespace:stats>

It looks like it is calling calling C_dbeta, but I'm not sure. If it does,
how do I find it's source code?

Thank you!
Varun

	[[alternative HTML version deleted]]


From roslinaump at gmail.com  Sun Jun  7 16:57:52 2015
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Sun, 7 Jun 2015 22:57:52 +0800
Subject: [R] if else statement for rain data to define zero for dry and
 one to wet
In-Reply-To: <CAF8bMcZShP=wHCGOL4o3PMO1Fupbvf5KOwT_van-MHd3DZKNMw@mail.gmail.com>
References: <CANTvJZL6oUjX_Qn9oJXuGKQ85Pjh5HK2q4JrOpafWdNMBvQstQ@mail.gmail.com>
	<D69718E661A.0000043Bjrkrideau@inbox.com>
	<CA+8X3fWLmmRj5TZg1hX5A1_yF-COROzeZVC1dApHqyjZbw0+cA@mail.gmail.com>
	<CADv2QyGshTJw5Bf=X6jbzSdynLC5BHjwOKJR2zv9KDOvVDGQRw@mail.gmail.com>
	<CAF8bMcZShP=wHCGOL4o3PMO1Fupbvf5KOwT_van-MHd3DZKNMw@mail.gmail.com>
Message-ID: <CANTvJZL7R3DBQfkVNrm50iF-xbLGZvUOettDYYKCgyVNYVd+=Q@mail.gmail.com>

Dear all,

All works well. Thank you so much for your help.

D## Function 1
wet_dry1 <- function(x,thresh=0.1)
 { for(column in 1:dim(x)[2]) x[,column] <- ifelse(x[,column]>=thresh,1,0)
 return(x)
 }

wet_dry1(dt)


## Function 2
wet_dry2 <- ( dt >= 0.1)*1
wet_dry2

wet_total <- colSums(wet_dry2)
pp <- wet_total/nrow(dt)
pp


## Function 3
rain <- dt
wet_dry3 <- ifelse(rain >= 0.1, 1, 0)
wet_dry3

On Sun, Jun 7, 2015 at 5:48 AM, William Dunlap <wdunlap at tibco.com> wrote:

> Your f1() has an unneeded for loop in it.
>    f1a <- function(mat) mat > 0.1, 1, 0)
> would do the same thing in a bit less time.
>
> However, I think that a simple
>    mat > 0.1
> would be preferable.  The resulting TRUEs and FALSEs
> are easier to interpret than the 1s and 0s that f1a()
> produces and arithmetic functions treat them TRUE
> as 1 and FALSE as 0 internally.  E.g., mean(mat>0.1)
> gives the proportion of wet(tish) days.
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Sat, Jun 6, 2015 at 1:55 PM, Dennis Murphy <djmuser at gmail.com> wrote:
>
>> I'm sorry, but I have to take issue with this particular use case of
>> ifelse(). When the goal is to generate a logical vector, ifelse() is
>> very inefficient. It's better to apply a logical condition directly to
>> the object in question and multiply the result by 1 to make it
>> numeric/integer rather than logical.
>>
>> To illustrate this, consider the following toy example. The function
>> f1 replicates the suggestion to apply ifelse() columnwise (with the
>> additional overhead of preallocating storage for the result), whereas
>> the function f2 applies the logical condition on the matrix itself
>> using vectorization, with the recognition that a matrix is an atomic
>> vector with a dim attribute.
>>
>> set.seed(5290)
>>
>> # 1000 x 1000 matrix
>> m <- matrix(sample(c(0, 0.05, 0.2), 1e6, replace = TRUE), ncol = 1000)
>>
>> f1 <- function(mat)
>>   {
>>      newmat <- matrix(NA, ncol = ncol(mat), nrow = nrow(mat))
>>      for(i in seq_len(ncol(mat)))
>>          newmat[, i] <- ifelse(mat[, i] > 0.1, 1, 0)
>>      newmat
>>   }
>>
>> f2 <- function(mat) 1 * (mat > 0.1)
>>
>>
>> On my system, I got
>>
>> > system.time(m1 <- f1(m))
>>    user  system elapsed
>>    0.14    0.00    0.14
>>
>> > system.time(m2 <- f2(m))
>>    user  system elapsed
>>    0.01    0.00    0.01
>>
>> > identical(m1, m2)
>> [1] TRUE
>>
>> The all too common practice of using  ifelse(condition, 1, 0) on an
>> atomic vector is easily replaced by 1 * (condition), where the result
>> of condition is a logical atomic object coerced to numeric.
>>
>> To reduce memory, one should better define f2 as
>>
>> f2 <- function(mat) 1L * (mat > 0.1)
>>
>> but doing so in this example no longer creates identical objects since
>>
>> > typeof(m1)
>> [1] "double"
>>
>> Thus, f1 is not only inefficient in terms of execution time, it's also
>> inefficient in terms of storage.
>>
>> Given several recent warnings in this forum about the inefficiency of
>> ifelse() and the dozens of times I've seen the idiom implemented in f1
>> as a solution over the last several years (to which I have likely
>> contributed in my distant past as an R-helper), I felt compelled to
>> say something about this practice, which BTW extends not just to 0/1
>> return values but to
>> 0/x return values, where x is a nonzero real number.
>>
>> Dennis
>>
>>
>> On Sat, Jun 6, 2015 at 12:50 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> > Hi rosalinazairimah,
>> > I think the problem is that you are using "if" instead of "ifelse". Try
>> this:
>> >
>> > wet_dry<-function(x,thresh=0.1) {
>> >  for(column in 1:dim(x)[2]) x[,column]<-ifelse(x[,column]>=thresh,1,0)
>> >  return(x)
>> > }
>> > wet_dry(dt)
>> >
>> > and see what you get.
>> >
>> > Also, why can I read your message perfectly while everybody else can't?
>> >
>> > Jim
>> >
>> >>> -----Original Message-----
>> >>> From: roslinaump at gmail.com
>> >>> Sent: Fri, 5 Jun 2015 16:49:08 +0800
>> >>> To: r-help at r-project.org
>> >>> Subject: [R] if else statement for rain data to define zero for dry
>> and
>> >>> one to wet
>> >>>
>> >>> Dear r-users,
>> >>>
>> >>> I have a set of rain data:
>> >>>
>> >>> X1950 X1951 X1952 X1953 X1954 X1955 X1956 X1957 X1958 X1959 X1960
>> X1961
>> >>> X1962
>> >>>
>> >>> 1   0.0   0.0  14.3   0.0  13.5  13.2   4.0     0   3.3     0     0
>>  0.0
>> >>>
>> >>>
>> >>> 2   0.0   0.0  21.9   0.0  10.9   6.6   2.1     0   0.0     0     0
>>  0.0
>> >>>
>> >>>
>> >>> 3  25.3   6.7  18.6   0.8   2.3   0.0   8.0     0   0.0     0     0
>> 11.0
>> >>>
>> >>>
>> >>> 4  12.7   3.4  37.2   0.9   8.4   0.0   5.8     0   0.0     0     0
>>  5.5
>> >>>
>> >>>
>> >>> 5   0.0   0.0  58.3   3.6  21.1   4.2   3.0     0   0.0     0     0
>> 15.9
>> >>>
>> >>>
>> >>> I would like to go through each column and define each cell with value
>> >>> greater than 0.1 mm will be 1 and else zero. Hence I would like to
>> attach
>> >>> the rain data and the category side by side:
>> >>>
>> >>>
>> >>> 1950   state
>> >>>
>> >>> 1 0.0    0
>> >>>
>> >>> 2 0.0    0
>> >>>
>> >>> 3 25.3   1
>> >>>
>> >>> 4 12.7   1
>> >>>
>> >>> 5 0.0    0
>> >>>
>> >>>
>> >>> ...
>> >>>
>> >>>
>> >>> This is my code:
>> >>>
>> >>>
>> >>> wet_dry  <- function(dt)
>> >>>
>> >>> { cl   <- length(dt)
>> >>>
>> >>>   tresh  <- 0.1
>> >>>
>> >>>
>> >>>   for (i in 1:cl)
>> >>>
>> >>>   {  xi <- dt[,i]
>> >>>
>> >>>      if (xi < tresh ) 0 else 1
>> >>>
>> >>>   }
>> >>>
>> >>> dd <- cbind(dt,xi)
>> >>>
>> >>> dd
>> >>>
>> >>> }
>> >>>
>> >>>
>> >>> wet_dry(dt)
>> >>>
>> >>>
>> >>> Results:
>> >>>
>> >>>> wet_dry(dt)
>> >>>
>> >>>    X1950 X1951 X1952 X1953 X1954 X1955 X1956 X1957 X1958 X1959 X1960
>> >>> X1961
>> >>> X1962 X1963 X1964 X1965 X1966 X1967 X1968 X1969 X1970 X1971 X1972
>> X1973
>> >>> X1974 X1975 X1976 X1977
>> >>>
>> >>> 1    0.0   0.0  14.3   0.0  13.5  13.2   4.0   0.0   3.3   0.0   0.0
>> >>> 0.0
>> >>>   4.2   0.0   2.2   0.0   4.4   5.1     0   7.2   0.0   0.0   0.0
>>  5.1
>> >>> 0   0.0     0   0.3
>> >>>
>> >>> 2    0.0   0.0  21.9   0.0  10.9   6.6   2.1   0.0   0.0   0.0   0.0
>> >>> 0.0
>> >>>   8.4   0.0   4.0   0.0   4.9   0.7     0   0.0   0.0   0.0   0.0
>>  5.4
>> >>> 0   3.3     0   0.3
>> >>>
>> >>> 3   25.3   6.7  18.6   0.8   2.3   0.0   8.0   0.0   0.0   0.0   0.0
>> >>> 11.0
>> >>>   4.2   0.0   2.0   0.0  14.2  17.1     0   0.0   0.0   0.0   0.0
>>  2.1
>> >>> 0   1.7     0   4.4
>> >>>
>> >>> 4   12.7   3.4  37.2   0.9   8.4   0.0   5.8   0.0   0.0   0.0   0.0
>> >>> 5.5
>> >>>   0.0   0.0   5.4   0.0   6.4  14.9     0  10.1   2.9 143.4   0.0
>>  6.1
>> >>> 0   0.0     0  33.5
>> >>>
>> >>>
>> >>> It does not work and give me the original data.  Why is that?
>> >>>
>> >>>
>> >>> Thank you so much for your help.
>> >>>
>> >>>       [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide
>> >>> http://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From rosita21 at gmail.com  Sun Jun  7 21:49:39 2015
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Sun, 7 Jun 2015 20:49:39 +0100
Subject: [R] problems editing R console
Message-ID: <75897EAD-A89A-4E19-94BF-3E389DD08F1F@gmail.com>

Dear all,

I?m doing simulations on R, and as my code is being changed and improved I need to, sometimes, work in finished simulations, i.e, 

After my simulation is  over I need to settle another setting.
The problem is that I need to get back to the previous result.

When I save the result it saves as txt, so I can?t edit that result any more.

Imagine I save a setting and save the mean, nonetheless, in another setting the mean as problems, so I have to ask the median.

As I have to have the same statistics to all settings, nowadays I have to run my first setting again.

My advisor told me that I could save another way so I can ?edit? my first result. Is it possible?

I tried to save as "save my workplace", ? but after I don?t know what to do with it.

Can you please help me?
I know is a naive question, but I have to go through this every 3 days (time each simulation takes long). And my work is being delayed :(


Best,
RO



Atenciosamente,
Rosa Oliveira

-- 
____________________________________________________________________________


Rosa Celeste dos Santos Oliveira, 

E-mail: rosita21 at gmail.com
Tlm: +351 939355143 
Linkedin: https://pt.linkedin.com/in/rosacsoliveira
____________________________________________________________________________
"Many admire, few know"
Hippocrates


From msharp at txbiomed.org  Mon Jun  8 00:11:54 2015
From: msharp at txbiomed.org (Mark Sharp)
Date: Sun, 7 Jun 2015 22:11:54 +0000
Subject: [R] source code for dbeta
In-Reply-To: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>
References: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>
Message-ID: <963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>

Varun,

If you type dbeta at the command line you get the R source, which in this case tells you that the code is calling a compiled source. This is indicated by the line <bytecode: 0x7fc3bb1b84e0>

See the following. 
> dbeta
function (x, shape1, shape2, ncp = 0, log = FALSE) 
{
    if (missing(ncp)) 
        .Call(C_dbeta, x, shape1, shape2, log)
    else .Call(C_dnbeta, x, shape1, shape2, ncp, log)
}
<bytecode: 0x7fc3bb1b84e0>
<environment: namespace:stats>

Compiled code in a package

If you want to view compiled code in a package, you will need to download/unpack the package source. The installed binaries are not sufficient. A package's source code is available from the same CRAN (or CRAN compatible) repository that the package was originally installed from. The download.packages() function can get the package source for you.

Extracted from http://stackoverflow.com/questions/19226816/how-can-i-view-the-source-code-for-a-function

Mark


R. Mark Sharp, Ph.D.
msharp at TxBiomed.org


> On Jun 7, 2015, at 4:31 AM, Varun Sinha <sinha.varuna85 at gmail.com> wrote:
> 
> Hi,
> 
> I am trying to find the source code for dbeta function.
> 
> I tried edit(dbeta) and this is what I got:
>> edit(dbeta)
> function (x, shape1, shape2, ncp = 0, log = FALSE)
> {
>    if (missing(ncp))
>        .Call(C_dbeta, x, shape1, shape2, log)
>    else .Call(C_dnbeta, x, shape1, shape2, ncp, log)
> }
> <environment: namespace:stats>
> 
> It looks like it is calling calling C_dbeta, but I'm not sure. If it does,
> how do I find it's source code?
> 
> Thank you!
> Varun
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From msharp at txbiomed.org  Mon Jun  8 00:19:52 2015
From: msharp at txbiomed.org (Mark Sharp)
Date: Sun, 7 Jun 2015 22:19:52 +0000
Subject: [R] source code for dbeta
In-Reply-To: <963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>
References: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>
	<963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>
Message-ID: <C20EBA98-58CB-43E4-B941-CE79FC79E17C@txbiomed.org>

Varun,

I apologize. I hit send before completing.

Look at the source document in the link I provided. dbeta is part of the stats package, which is part of the core R system and I do not think it is available as a standalone package. The linked document provides instructions for finding base R compiled code.

Mark

R. Mark Sharp, Ph.D.
msharp at TxBiomed.org
> On Jun 7, 2015, at 5:11 PM, Mark Sharp <msharp at TxBiomed.org> wrote:
> 
> Varun,
> 
> If you type dbeta at the command line you get the R source, which in this case tells you that the code is calling a compiled source. This is indicated by the line <bytecode: 0x7fc3bb1b84e0>
> 
> See the following. 
>> dbeta
> function (x, shape1, shape2, ncp = 0, log = FALSE) 
> {
>    if (missing(ncp)) 
>        .Call(C_dbeta, x, shape1, shape2, log)
>    else .Call(C_dnbeta, x, shape1, shape2, ncp, log)
> }
> <bytecode: 0x7fc3bb1b84e0>
> <environment: namespace:stats>
> 
> Compiled code in a package
> 
> If you want to view compiled code in a package, you will need to download/unpack the package source. The installed binaries are not sufficient. A package's source code is available from the same CRAN (or CRAN compatible) repository that the package was originally installed from. The download.packages() function can get the package source for you.
> 
> Extracted from http://stackoverflow.com/questions/19226816/how-can-i-view-the-source-code-for-a-function
> 
> Mark
> 
> 
> R. Mark Sharp, Ph.D.
> msharp at TxBiomed.org
> 
> 
>> On Jun 7, 2015, at 4:31 AM, Varun Sinha <sinha.varuna85 at gmail.com> wrote:
>> 
>> Hi,
>> 
>> I am trying to find the source code for dbeta function.
>> 
>> I tried edit(dbeta) and this is what I got:
>>> edit(dbeta)
>> function (x, shape1, shape2, ncp = 0, log = FALSE)
>> {
>>   if (missing(ncp))
>>       .Call(C_dbeta, x, shape1, shape2, log)
>>   else .Call(C_dnbeta, x, shape1, shape2, ncp, log)
>> }
>> <environment: namespace:stats>
>> 
>> It looks like it is calling calling C_dbeta, but I'm not sure. If it does,
>> how do I find it's source code?
>> 
>> Thank you!
>> Varun
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Jun  8 01:06:51 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 07 Jun 2015 19:06:51 -0400
Subject: [R] source code for dbeta
In-Reply-To: <963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>
References: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>
	<963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>
Message-ID: <5574CE8B.3060309@gmail.com>

On 07/06/2015 6:11 PM, Mark Sharp wrote:
> Varun,
> 
> If you type dbeta at the command line you get the R source, which in this case tells you that the code is calling a compiled source. This is indicated by the line <bytecode: 0x7fc3bb1b84e0>

No, that says that the R code (what is shown) is compiled.  What
indicates that this is C code is the use of .Call.  The C_dbeta and
C_dnbeta objects are "NativeSymbolInfo" objects that hold the pointers
to the C entry points.

Since it is in a base package ("stats"), the source is in the R sources,
somewhere in  https://svn.r-project.org/R/trunk/src/library/stats/src.
You can search through those files for the dbeta or dnbeta functions.
The "C_" prefix is conventionally used in the R sources to indicate that
it is C code; generally you replace it with "do_" in the actual C code.
 This particular function is actually not really in the package source;
it's in the main part of the R sources, in file

https://svn.r-project.org/R/trunk/src/nmath/dbeta.c

(though it takes a few steps to get there, starting in the stats package
function do_dbeta).

Duncan Murdoch
> 
> See the following. 
>> dbeta
> function (x, shape1, shape2, ncp = 0, log = FALSE) 
> {
>     if (missing(ncp)) 
>         .Call(C_dbeta, x, shape1, shape2, log)
>     else .Call(C_dnbeta, x, shape1, shape2, ncp, log)
> }
> <bytecode: 0x7fc3bb1b84e0>
> <environment: namespace:stats>
> 
> Compiled code in a package
> 
> If you want to view compiled code in a package, you will need to download/unpack the package source. The installed binaries are not sufficient. A package's source code is available from the same CRAN (or CRAN compatible) repository that the package was originally installed from. The download.packages() function can get the package source for you.
> 
> Extracted from http://stackoverflow.com/questions/19226816/how-can-i-view-the-source-code-for-a-function
> 
> Mark
> 
> 
> R. Mark Sharp, Ph.D.
> msharp at TxBiomed.org
> 
> 
>> On Jun 7, 2015, at 4:31 AM, Varun Sinha <sinha.varuna85 at gmail.com> wrote:
>>
>> Hi,
>>
>> I am trying to find the source code for dbeta function.
>>
>> I tried edit(dbeta) and this is what I got:
>>> edit(dbeta)
>> function (x, shape1, shape2, ncp = 0, log = FALSE)
>> {
>>    if (missing(ncp))
>>        .Call(C_dbeta, x, shape1, shape2, log)
>>    else .Call(C_dnbeta, x, shape1, shape2, ncp, log)
>> }
>> <environment: namespace:stats>
>>
>> It looks like it is calling calling C_dbeta, but I'm not sure. If it does,
>> how do I find it's source code?
>>
>> Thank you!
>> Varun
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rosita21 at gmail.com  Mon Jun  8 00:58:07 2015
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Sun, 7 Jun 2015 23:58:07 +0100
Subject: [R] problems editing R console
In-Reply-To: <A58679E9-24C5-4481-9654-9BF57424D426@txbiomed.org>
References: <75897EAD-A89A-4E19-94BF-3E389DD08F1F@gmail.com>
	<A58679E9-24C5-4481-9654-9BF57424D426@txbiomed.org>
Message-ID: <C099D03B-A530-46DD-BB40-0D1050860EE2@gmail.com>

Dear Mark,


I?ll try to explain better.

Imagine I write:

library(foreign)
library(nlme)

set.seed(1000)
n.sample<-10000 #sample size
M <- 5
DP_x <- 2
x <- rnorm(n.sample,M,DP_x)
p <- pnorm(-3+x)  
y <- rbinom(n.sample,1,p)
dp_erro <- 0.01
erro <- rnorm(n.sample,0,dp_erro)
x.erro <- x+erro

but with a function, with 2000 simulations. 
I save my ?output? and I get X.erro in a .txt file. (text edit file).

I do another setting with DP_x=3 and save, and so on.

For some reason I realize I?ve done my simulation the wrong way and I have to apply a correction, for example:

x.erro = 1.4X+erro, i.e. in the truth I could use my first X and erro values in each setting, but as it is in a .txt file I can?t use them any more. Is there a way to save the results in a  format that I can use the values? Just apply my corrections and don?t have to do the 2000 simulations for each setting again?

My problem is that the function I use takes 3 days running, and just 500 simulations :(

Best,
RO


Atenciosamente,
Rosa Oliveira

-- 
____________________________________________________________________________


Rosa Celeste dos Santos Oliveira, 

E-mail: rosita21 at gmail.com
Tlm: +351 939355143 
Linkedin: https://pt.linkedin.com/in/rosacsoliveira
____________________________________________________________________________
"Many admire, few know"
Hippocrates

> On 07 Jun 2015, at 23:03, Mark Sharp <msharp at txbiomed.org> wrote:
> 
> I cannot understand your request as stated. Can you provide a small example?
> 
> Mark
> 
> R. Mark Sharp, Ph.D.
> msharp at TxBiomed.org
> 
>> On Jun 7, 2015, at 2:49 PM, Rosa Oliveira <rosita21 at gmail.com> wrote:
>> 
>> Dear all,
>> 
>> I?m doing simulations on R, and as my code is being changed and improved I need to, sometimes, work in finished simulations, i.e, 
>> 
>> After my simulation is  over I need to settle another setting.
>> The problem is that I need to get back to the previous result.
>> 
>> When I save the result it saves as txt, so I can?t edit that result any more.
>> 
>> Imagine I save a setting and save the mean, nonetheless, in another setting the mean as problems, so I have to ask the median.
>> 
>> As I have to have the same statistics to all settings, nowadays I have to run my first setting again.
>> 
>> My advisor told me that I could save another way so I can ?edit? my first result. Is it possible?
>> 
>> I tried to save as "save my workplace", ? but after I don?t know what to do with it.
>> 
>> Can you please help me?
>> I know is a naive question, but I have to go through this every 3 days (time each simulation takes long). And my work is being delayed :(
>> 
>> 
>> Best,
>> RO
>> 
>> 
>> 
>> Atenciosamente,
>> Rosa Oliveira
>> 
>> -- 
>> ____________________________________________________________________________
>> 
>> 
>> Rosa Celeste dos Santos Oliveira, 
>> 
>> E-mail: rosita21 at gmail.com
>> Tlm: +351 939355143 
>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>> ____________________________________________________________________________
>> "Many admire, few know"
>> Hippocrates
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 
> 
> 
> 


From ssefick at gmail.com  Mon Jun  8 02:16:59 2015
From: ssefick at gmail.com (stephen sefick)
Date: Sun, 7 Jun 2015 19:16:59 -0500
Subject: [R] problems editing R console
In-Reply-To: <C099D03B-A530-46DD-BB40-0D1050860EE2@gmail.com>
References: <75897EAD-A89A-4E19-94BF-3E389DD08F1F@gmail.com>
	<A58679E9-24C5-4481-9654-9BF57424D426@txbiomed.org>
	<C099D03B-A530-46DD-BB40-0D1050860EE2@gmail.com>
Message-ID: <CADKEMqgWW3kCe3Hvam44OtBRw7rr-rUzvvemjnNYyEoSOVHh-w@mail.gmail.com>

?saveRDS

On Sun, Jun 7, 2015 at 5:58 PM, Rosa Oliveira <rosita21 at gmail.com> wrote:

> Dear Mark,
>
>
> I?ll try to explain better.
>
> Imagine I write:
>
> library(foreign)
> library(nlme)
>
> set.seed(1000)
> n.sample<-10000 #sample size
> M <- 5
> DP_x <- 2
> x <- rnorm(n.sample,M,DP_x)
> p <- pnorm(-3+x)
> y <- rbinom(n.sample,1,p)
> dp_erro <- 0.01
> erro <- rnorm(n.sample,0,dp_erro)
> x.erro <- x+erro
>
> but with a function, with 2000 simulations.
> I save my ?output? and I get X.erro in a .txt file. (text edit file).
>
> I do another setting with DP_x=3 and save, and so on.
>
> For some reason I realize I?ve done my simulation the wrong way and I have
> to apply a correction, for example:
>
> x.erro = 1.4X+erro, i.e. in the truth I could use my first X and erro
> values in each setting, but as it is in a .txt file I can?t use them any
> more. Is there a way to save the results in a  format that I can use the
> values? Just apply my corrections and don?t have to do the 2000 simulations
> for each setting again?
>
> My problem is that the function I use takes 3 days running, and just 500
> simulations :(
>
> Best,
> RO
>
>
> Atenciosamente,
> Rosa Oliveira
>
> --
>
> ____________________________________________________________________________
>
>
> Rosa Celeste dos Santos Oliveira,
>
> E-mail: rosita21 at gmail.com
> Tlm: +351 939355143
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
>
> > On 07 Jun 2015, at 23:03, Mark Sharp <msharp at txbiomed.org> wrote:
> >
> > I cannot understand your request as stated. Can you provide a small
> example?
> >
> > Mark
> >
> > R. Mark Sharp, Ph.D.
> > msharp at TxBiomed.org
> >
> >> On Jun 7, 2015, at 2:49 PM, Rosa Oliveira <rosita21 at gmail.com> wrote:
> >>
> >> Dear all,
> >>
> >> I?m doing simulations on R, and as my code is being changed and
> improved I need to, sometimes, work in finished simulations, i.e,
> >>
> >> After my simulation is  over I need to settle another setting.
> >> The problem is that I need to get back to the previous result.
> >>
> >> When I save the result it saves as txt, so I can?t edit that result any
> more.
> >>
> >> Imagine I save a setting and save the mean, nonetheless, in another
> setting the mean as problems, so I have to ask the median.
> >>
> >> As I have to have the same statistics to all settings, nowadays I have
> to run my first setting again.
> >>
> >> My advisor told me that I could save another way so I can ?edit? my
> first result. Is it possible?
> >>
> >> I tried to save as "save my workplace", ? but after I don?t know what
> to do with it.
> >>
> >> Can you please help me?
> >> I know is a naive question, but I have to go through this every 3 days
> (time each simulation takes long). And my work is being delayed :(
> >>
> >>
> >> Best,
> >> RO
> >>
> >>
> >>
> >> Atenciosamente,
> >> Rosa Oliveira
> >>
> >> --
> >>
> ____________________________________________________________________________
> >>
> >>
> >> Rosa Celeste dos Santos Oliveira,
> >>
> >> E-mail: rosita21 at gmail.com
> >> Tlm: +351 939355143
> >> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
> >>
> ____________________________________________________________________________
> >> "Many admire, few know"
> >> Hippocrates
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> >
> >
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Jun  8 02:19:18 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 7 Jun 2015 17:19:18 -0700
Subject: [R] problems editing R console
In-Reply-To: <C099D03B-A530-46DD-BB40-0D1050860EE2@gmail.com>
References: <75897EAD-A89A-4E19-94BF-3E389DD08F1F@gmail.com>
	<A58679E9-24C5-4481-9654-9BF57424D426@txbiomed.org>
	<C099D03B-A530-46DD-BB40-0D1050860EE2@gmail.com>
Message-ID: <CAGxFJbTuKtNQ=jL2t2jyfZmsxe0uVj-xKSTRZty63gr3obmY5g@mail.gmail.com>

I believe that you need to learn to use a code editor/IDE. R is a
programming language.

See here:

http://www.rstudio.com/

or here:

http://www.sciviews.org/_rgui/

Otherwise, I also don't understand.


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Sun, Jun 7, 2015 at 3:58 PM, Rosa Oliveira <rosita21 at gmail.com> wrote:

> Dear Mark,
>
>
> I?ll try to explain better.
>
> Imagine I write:
>
> library(foreign)
> library(nlme)
>
> set.seed(1000)
> n.sample<-10000 #sample size
> M <- 5
> DP_x <- 2
> x <- rnorm(n.sample,M,DP_x)
> p <- pnorm(-3+x)
> y <- rbinom(n.sample,1,p)
> dp_erro <- 0.01
> erro <- rnorm(n.sample,0,dp_erro)
> x.erro <- x+erro
>
> but with a function, with 2000 simulations.
> I save my ?output? and I get X.erro in a .txt file. (text edit file).
>
> I do another setting with DP_x=3 and save, and so on.
>
> For some reason I realize I?ve done my simulation the wrong way and I have
> to apply a correction, for example:
>
> x.erro = 1.4X+erro, i.e. in the truth I could use my first X and erro
> values in each setting, but as it is in a .txt file I can?t use them any
> more. Is there a way to save the results in a  format that I can use the
> values? Just apply my corrections and don?t have to do the 2000 simulations
> for each setting again?
>
> My problem is that the function I use takes 3 days running, and just 500
> simulations :(
>
> Best,
> RO
>
>
> Atenciosamente,
> Rosa Oliveira
>
> --
>
> ____________________________________________________________________________
>
>
> Rosa Celeste dos Santos Oliveira,
>
> E-mail: rosita21 at gmail.com
> Tlm: +351 939355143
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
>
> > On 07 Jun 2015, at 23:03, Mark Sharp <msharp at txbiomed.org> wrote:
> >
> > I cannot understand your request as stated. Can you provide a small
> example?
> >
> > Mark
> >
> > R. Mark Sharp, Ph.D.
> > msharp at TxBiomed.org
> >
> >> On Jun 7, 2015, at 2:49 PM, Rosa Oliveira <rosita21 at gmail.com> wrote:
> >>
> >> Dear all,
> >>
> >> I?m doing simulations on R, and as my code is being changed and
> improved I need to, sometimes, work in finished simulations, i.e,
> >>
> >> After my simulation is  over I need to settle another setting.
> >> The problem is that I need to get back to the previous result.
> >>
> >> When I save the result it saves as txt, so I can?t edit that result any
> more.
> >>
> >> Imagine I save a setting and save the mean, nonetheless, in another
> setting the mean as problems, so I have to ask the median.
> >>
> >> As I have to have the same statistics to all settings, nowadays I have
> to run my first setting again.
> >>
> >> My advisor told me that I could save another way so I can ?edit? my
> first result. Is it possible?
> >>
> >> I tried to save as "save my workplace", ? but after I don?t know what
> to do with it.
> >>
> >> Can you please help me?
> >> I know is a naive question, but I have to go through this every 3 days
> (time each simulation takes long). And my work is being delayed :(
> >>
> >>
> >> Best,
> >> RO
> >>
> >>
> >>
> >> Atenciosamente,
> >> Rosa Oliveira
> >>
> >> --
> >>
> ____________________________________________________________________________
> >>
> >>
> >> Rosa Celeste dos Santos Oliveira,
> >>
> >> E-mail: rosita21 at gmail.com
> >> Tlm: +351 939355143
> >> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
> >>
> ____________________________________________________________________________
> >> "Many admire, few know"
> >> Hippocrates
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> >
> >
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From carlosviansi at gmail.com  Mon Jun  8 02:19:43 2015
From: carlosviansi at gmail.com (Carlos Andrade)
Date: Sun, 7 Jun 2015 14:19:43 -1000
Subject: [R] problems editing R console
In-Reply-To: <C099D03B-A530-46DD-BB40-0D1050860EE2@gmail.com>
References: <75897EAD-A89A-4E19-94BF-3E389DD08F1F@gmail.com>
	<A58679E9-24C5-4481-9654-9BF57424D426@txbiomed.org>
	<C099D03B-A530-46DD-BB40-0D1050860EE2@gmail.com>
Message-ID: <CA+KzQ4G59qGOwEDMzgCdRhsh73HOjSdtfCmW4K76z2m2uPAorw@mail.gmail.com>

Rosa,

Why not just re-load the .txt file (which I imagine be a data frame) and
then edit?

See: http://www.inside-r.org/r-doc/utils/read.table

*I would imagine something along the lines:*

simulation_results <-  read.table("path_to_text_file_of_simulation")
#Double check the parameters on the function documentation, I don't know
how your data looks like, specially header and column separator.

*For doing something like: *

x.erro = 1.4X+erro



*you would just need to use:*
simulation_results$x.erro <- 1.4*simulation_results$X + simulation$erro

*then save the simulation_results variable again.*

Also see...
http://stackoverflow.com/questions/8345759/how-to-save-a-data-frame-in-r




Carlos Andrade
http://carlosandrade.co

On Sun, Jun 7, 2015 at 12:58 PM, Rosa Oliveira <rosita21 at gmail.com> wrote:

> Dear Mark,
>
>
> I?ll try to explain better.
>
> Imagine I write:
>
> library(foreign)
> library(nlme)
>
> set.seed(1000)
> n.sample<-10000 #sample size
> M <- 5
> DP_x <- 2
> x <- rnorm(n.sample,M,DP_x)
> p <- pnorm(-3+x)
> y <- rbinom(n.sample,1,p)
> dp_erro <- 0.01
> erro <- rnorm(n.sample,0,dp_erro)
> x.erro <- x+erro
>
> but with a function, with 2000 simulations.
> I save my ?output? and I get X.erro in a .txt file. (text edit file).
>
> I do another setting with DP_x=3 and save, and so on.
>
> For some reason I realize I?ve done my simulation the wrong way and I have
> to apply a correction, for example:
>
> x.erro = 1.4X+erro, i.e. in the truth I could use my first X and erro
> values in each setting, but as it is in a .txt file I can?t use them any
> more. Is there a way to save the results in a  format that I can use the
> values? Just apply my corrections and don?t have to do the 2000 simulations
> for each setting again?
>
> My problem is that the function I use takes 3 days running, and just 500
> simulations :(
>
> Best,
> RO
>
>
> Atenciosamente,
> Rosa Oliveira
>
> --
>
> ____________________________________________________________________________
>
>
> Rosa Celeste dos Santos Oliveira,
>
> E-mail: rosita21 at gmail.com
> Tlm: +351 939355143
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
>
> > On 07 Jun 2015, at 23:03, Mark Sharp <msharp at txbiomed.org> wrote:
> >
> > I cannot understand your request as stated. Can you provide a small
> example?
> >
> > Mark
> >
> > R. Mark Sharp, Ph.D.
> > msharp at TxBiomed.org
> >
> >> On Jun 7, 2015, at 2:49 PM, Rosa Oliveira <rosita21 at gmail.com> wrote:
> >>
> >> Dear all,
> >>
> >> I?m doing simulations on R, and as my code is being changed and
> improved I need to, sometimes, work in finished simulations, i.e,
> >>
> >> After my simulation is  over I need to settle another setting.
> >> The problem is that I need to get back to the previous result.
> >>
> >> When I save the result it saves as txt, so I can?t edit that result any
> more.
> >>
> >> Imagine I save a setting and save the mean, nonetheless, in another
> setting the mean as problems, so I have to ask the median.
> >>
> >> As I have to have the same statistics to all settings, nowadays I have
> to run my first setting again.
> >>
> >> My advisor told me that I could save another way so I can ?edit? my
> first result. Is it possible?
> >>
> >> I tried to save as "save my workplace", ? but after I don?t know what
> to do with it.
> >>
> >> Can you please help me?
> >> I know is a naive question, but I have to go through this every 3 days
> (time each simulation takes long). And my work is being delayed :(
> >>
> >>
> >> Best,
> >> RO
> >>
> >>
> >>
> >> Atenciosamente,
> >> Rosa Oliveira
> >>
> >> --
> >>
> ____________________________________________________________________________
> >>
> >>
> >> Rosa Celeste dos Santos Oliveira,
> >>
> >> E-mail: rosita21 at gmail.com
> >> Tlm: +351 939355143
> >> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
> >>
> ____________________________________________________________________________
> >> "Many admire, few know"
> >> Hippocrates
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> >
> >
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From msharp at txbiomed.org  Mon Jun  8 02:30:29 2015
From: msharp at txbiomed.org (Mark Sharp)
Date: Mon, 8 Jun 2015 00:30:29 +0000
Subject: [R] problems editing R console
In-Reply-To: <C099D03B-A530-46DD-BB40-0D1050860EE2@gmail.com>
References: <75897EAD-A89A-4E19-94BF-3E389DD08F1F@gmail.com>
	<A58679E9-24C5-4481-9654-9BF57424D426@txbiomed.org>
	<C099D03B-A530-46DD-BB40-0D1050860EE2@gmail.com>
Message-ID: <492C5AF9-B366-412B-BCDB-2F6882CF311B@txbiomed.org>

Rosa,

See save() and load() functions for background. However, I suspect you will want to do something as described in the article in this link http://www.fromthebottomoftheheap.net/2012/04/01/saving-and-loading-r-objects/


Mark



R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org



> On Jun 7, 2015, at 5:58 PM, Rosa Oliveira <rosita21 at gmail.com> wrote:
> 
> Dear Mark,
> 
> 
> I?ll try to explain better.
> 
> Imagine I write:
> 
> library(foreign)
> library(nlme)
> 
> set.seed(1000)
> n.sample<-10000 #sample size
> M <- 5
> DP_x <- 2
> x <- rnorm(n.sample,M,DP_x)
> p <- pnorm(-3+x)  
> y <- rbinom(n.sample,1,p)
> dp_erro <- 0.01
> erro <- rnorm(n.sample,0,dp_erro)
> x.erro <- x+erro
> 
> but with a function, with 2000 simulations. 
> I save my ?output? and I get X.erro in a .txt file. (text edit file).
> 
> I do another setting with DP_x=3 and save, and so on.
> 
> For some reason I realize I?ve done my simulation the wrong way and I have to apply a correction, for example:
> 
> x.erro = 1.4X+erro, i.e. in the truth I could use my first X and erro values in each setting, but as it is in a .txt file I can?t use them any more. Is there a way to save the results in a  format that I can use the values? Just apply my corrections and don?t have to do the 2000 simulations for each setting again?
> 
> My problem is that the function I use takes 3 days running, and just 500 simulations :(
> 
> Best,
> RO
> 
> 
> Atenciosamente,
> Rosa Oliveira
> 
> -- 
> ____________________________________________________________________________
>  
> <smile.jpg>
> Rosa Celeste dos Santos Oliveira, 
> 
> E-mail: rosita21 at gmail.com
> Tlm: +351 939355143 
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
> 
>> On 07 Jun 2015, at 23:03, Mark Sharp <msharp at txbiomed.org> wrote:
>> 
>> I cannot understand your request as stated. Can you provide a small example?
>> 
>> Mark
>> 
>> R. Mark Sharp, Ph.D.
>> msharp at TxBiomed.org
>> 
>>> On Jun 7, 2015, at 2:49 PM, Rosa Oliveira <rosita21 at gmail.com> wrote:
>>> 
>>> Dear all,
>>> 
>>> I?m doing simulations on R, and as my code is being changed and improved I need to, sometimes, work in finished simulations, i.e, 
>>> 
>>> After my simulation is  over I need to settle another setting.
>>> The problem is that I need to get back to the previous result.
>>> 
>>> When I save the result it saves as txt, so I can?t edit that result any more.
>>> 
>>> Imagine I save a setting and save the mean, nonetheless, in another setting the mean as problems, so I have to ask the median.
>>> 
>>> As I have to have the same statistics to all settings, nowadays I have to run my first setting again.
>>> 
>>> My advisor told me that I could save another way so I can ?edit? my first result. Is it possible?
>>> 
>>> I tried to save as "save my workplace", ? but after I don?t know what to do with it.
>>> 
>>> Can you please help me?
>>> I know is a naive question, but I have to go through this every 3 days (time each simulation takes long). And my work is being delayed :(
>>> 
>>> 
>>> Best,
>>> RO
>>> 
>>> 
>>> 
>>> Atenciosamente,
>>> Rosa Oliveira
>>> 
>>> -- 
>>> ____________________________________________________________________________
>>> 
>>> 
>>> Rosa Celeste dos Santos Oliveira, 
>>> 
>>> E-mail: rosita21 at gmail.com
>>> Tlm: +351 939355143 
>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>>> ____________________________________________________________________________
>>> "Many admire, few know"
>>> Hippocrates
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> 
>> 
>> 
>> 
> 






From anindya55 at gmail.com  Mon Jun  8 08:54:53 2015
From: anindya55 at gmail.com (Anindya Sankar Dey)
Date: Mon, 8 Jun 2015 12:24:53 +0530
Subject: [R] Text Mining - Remove punctuation not removing quotes and dashes
Message-ID: <CAKC+_z-SC1H2BPE9xESC3NxU-Y3nvkLzSpbi3+GRfw3HcqyRdQ@mail.gmail.com>

Hi,

I have been doing some text mining. I created the DTM matrix using the
following steps.

corpus1<-VCorpus(VectorSource(resume1$Dat1))

corpus1<-tm_map(corpus1,content_transformer(tolower))

dtm<-DocumentTermMatrix(corpus1,
                               control = list(removePunctuation = TRUE,
                                              removeNumbers = TRUE,
                                              removeSparseTerms=TRUE,
                                                stopwords = TRUE))


?After all the run I am still getting words like -quotation, "fun, model"?
, etc.

What can I do about it. I do not need this dahses and extra quotations.

-- 
Anindya Sankar Dey

	[[alternative HTML version deleted]]


From rosita21 at gmail.com  Mon Jun  8 04:19:53 2015
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Mon, 8 Jun 2015 03:19:53 +0100
Subject: [R] problems editing R console
In-Reply-To: <492C5AF9-B366-412B-BCDB-2F6882CF311B@txbiomed.org>
References: <75897EAD-A89A-4E19-94BF-3E389DD08F1F@gmail.com>
	<A58679E9-24C5-4481-9654-9BF57424D426@txbiomed.org>
	<C099D03B-A530-46DD-BB40-0D1050860EE2@gmail.com>
	<492C5AF9-B366-412B-BCDB-2F6882CF311B@txbiomed.org>
Message-ID: <C1DA6CB4-2E97-4C07-AB50-321E85427965@gmail.com>

Thanks all off you ;)

I think I got it.

I was saving the workplace and loading it, but after that I wasn?t calling my data ;)


really naive.

Thanks very much.

best
RO

Atenciosamente,
Rosa Oliveira

-- 
____________________________________________________________________________


Rosa Celeste dos Santos Oliveira, 

E-mail: rosita21 at gmail.com
Tlm: +351 939355143 
Linkedin: https://pt.linkedin.com/in/rosacsoliveira
____________________________________________________________________________
"Many admire, few know"
Hippocrates

> On 08 Jun 2015, at 01:30, Mark Sharp <msharp at txbiomed.org> wrote:
> 
> Rosa,
> 
> See save() and load() functions for background. However, I suspect you will want to do something as described in the article in this link http://www.fromthebottomoftheheap.net/2012/04/01/saving-and-loading-r-objects/
> 
> 
> Mark
> 
> 
> 
> R. Mark Sharp, Ph.D.
> Director of Primate Records Database
> Southwest National Primate Research Center
> Texas Biomedical Research Institute
> P.O. Box 760549
> San Antonio, TX 78245-0549
> Telephone: (210)258-9476
> e-mail: msharp at TxBiomed.org
> 
> 
> 
>> On Jun 7, 2015, at 5:58 PM, Rosa Oliveira <rosita21 at gmail.com> wrote:
>> 
>> Dear Mark,
>> 
>> 
>> I?ll try to explain better.
>> 
>> Imagine I write:
>> 
>> library(foreign)
>> library(nlme)
>> 
>> set.seed(1000)
>> n.sample<-10000 #sample size
>> M <- 5
>> DP_x <- 2
>> x <- rnorm(n.sample,M,DP_x)
>> p <- pnorm(-3+x)  
>> y <- rbinom(n.sample,1,p)
>> dp_erro <- 0.01
>> erro <- rnorm(n.sample,0,dp_erro)
>> x.erro <- x+erro
>> 
>> but with a function, with 2000 simulations. 
>> I save my ?output? and I get X.erro in a .txt file. (text edit file).
>> 
>> I do another setting with DP_x=3 and save, and so on.
>> 
>> For some reason I realize I?ve done my simulation the wrong way and I have to apply a correction, for example:
>> 
>> x.erro = 1.4X+erro, i.e. in the truth I could use my first X and erro values in each setting, but as it is in a .txt file I can?t use them any more. Is there a way to save the results in a  format that I can use the values? Just apply my corrections and don?t have to do the 2000 simulations for each setting again?
>> 
>> My problem is that the function I use takes 3 days running, and just 500 simulations :(
>> 
>> Best,
>> RO
>> 
>> 
>> Atenciosamente,
>> Rosa Oliveira
>> 
>> -- 
>> ____________________________________________________________________________
>> 
>> <smile.jpg>
>> Rosa Celeste dos Santos Oliveira, 
>> 
>> E-mail: rosita21 at gmail.com
>> Tlm: +351 939355143 
>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>> ____________________________________________________________________________
>> "Many admire, few know"
>> Hippocrates
>> 
>>> On 07 Jun 2015, at 23:03, Mark Sharp <msharp at txbiomed.org> wrote:
>>> 
>>> I cannot understand your request as stated. Can you provide a small example?
>>> 
>>> Mark
>>> 
>>> R. Mark Sharp, Ph.D.
>>> msharp at TxBiomed.org
>>> 
>>>> On Jun 7, 2015, at 2:49 PM, Rosa Oliveira <rosita21 at gmail.com> wrote:
>>>> 
>>>> Dear all,
>>>> 
>>>> I?m doing simulations on R, and as my code is being changed and improved I need to, sometimes, work in finished simulations, i.e, 
>>>> 
>>>> After my simulation is  over I need to settle another setting.
>>>> The problem is that I need to get back to the previous result.
>>>> 
>>>> When I save the result it saves as txt, so I can?t edit that result any more.
>>>> 
>>>> Imagine I save a setting and save the mean, nonetheless, in another setting the mean as problems, so I have to ask the median.
>>>> 
>>>> As I have to have the same statistics to all settings, nowadays I have to run my first setting again.
>>>> 
>>>> My advisor told me that I could save another way so I can ?edit? my first result. Is it possible?
>>>> 
>>>> I tried to save as "save my workplace", ? but after I don?t know what to do with it.
>>>> 
>>>> Can you please help me?
>>>> I know is a naive question, but I have to go through this every 3 days (time each simulation takes long). And my work is being delayed :(
>>>> 
>>>> 
>>>> Best,
>>>> RO
>>>> 
>>>> 
>>>> 
>>>> Atenciosamente,
>>>> Rosa Oliveira
>>>> 
>>>> -- 
>>>> ____________________________________________________________________________
>>>> 
>>>> 
>>>> Rosa Celeste dos Santos Oliveira, 
>>>> 
>>>> E-mail: rosita21 at gmail.com
>>>> Tlm: +351 939355143 
>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>>>> ____________________________________________________________________________
>>>> "Many admire, few know"
>>>> Hippocrates
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>> 
> 
> 
> 
> 
> 


From sinha.varuna85 at gmail.com  Mon Jun  8 05:05:24 2015
From: sinha.varuna85 at gmail.com (Varun Sinha)
Date: Mon, 8 Jun 2015 06:05:24 +0300
Subject: [R] source code for dbeta
In-Reply-To: <5574CE8B.3060309@gmail.com>
References: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>
	<963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>
	<5574CE8B.3060309@gmail.com>
Message-ID: <CAF-rFrLU3CLqGB7A9UAgygthnhAtXhvcpAHwg5uuPZQ8TXt5Cg@mail.gmail.com>

Hi,

Thanks a lot. I downloaded the tar.gz file and I found the C code.

I would really appreciate it if you could field another question:
I have to use sql, and I have to perform various statistical calculations -
like integrate, dbeta etc. Sql does not have these functions, plus they are
very difficult to code. Would it be possible to use the C code, compile it
and deploy it in sql? Is that feasible, or even permitted?

Thanks once again, I'm very grateful.


On Mon, Jun 8, 2015 at 2:06 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 07/06/2015 6:11 PM, Mark Sharp wrote:
> > Varun,
> >
> > If you type dbeta at the command line you get the R source, which in
> this case tells you that the code is calling a compiled source. This is
> indicated by the line <bytecode: 0x7fc3bb1b84e0>
>
> No, that says that the R code (what is shown) is compiled.  What
> indicates that this is C code is the use of .Call.  The C_dbeta and
> C_dnbeta objects are "NativeSymbolInfo" objects that hold the pointers
> to the C entry points.
>
> Since it is in a base package ("stats"), the source is in the R sources,
> somewhere in  https://svn.r-project.org/R/trunk/src/library/stats/src.
> You can search through those files for the dbeta or dnbeta functions.
> The "C_" prefix is conventionally used in the R sources to indicate that
> it is C code; generally you replace it with "do_" in the actual C code.
>  This particular function is actually not really in the package source;
> it's in the main part of the R sources, in file
>
> https://svn.r-project.org/R/trunk/src/nmath/dbeta.c
>
> (though it takes a few steps to get there, starting in the stats package
> function do_dbeta).
>
> Duncan Murdoch
> >
> > See the following.
> >> dbeta
> > function (x, shape1, shape2, ncp = 0, log = FALSE)
> > {
> >     if (missing(ncp))
> >         .Call(C_dbeta, x, shape1, shape2, log)
> >     else .Call(C_dnbeta, x, shape1, shape2, ncp, log)
> > }
> > <bytecode: 0x7fc3bb1b84e0>
> > <environment: namespace:stats>
> >
> > Compiled code in a package
> >
> > If you want to view compiled code in a package, you will need to
> download/unpack the package source. The installed binaries are not
> sufficient. A package's source code is available from the same CRAN (or
> CRAN compatible) repository that the package was originally installed from.
> The download.packages() function can get the package source for you.
> >
> > Extracted from
> http://stackoverflow.com/questions/19226816/how-can-i-view-the-source-code-for-a-function
> >
> > Mark
> >
> >
> > R. Mark Sharp, Ph.D.
> > msharp at TxBiomed.org
> >
> >
> >> On Jun 7, 2015, at 4:31 AM, Varun Sinha <sinha.varuna85 at gmail.com>
> wrote:
> >>
> >> Hi,
> >>
> >> I am trying to find the source code for dbeta function.
> >>
> >> I tried edit(dbeta) and this is what I got:
> >>> edit(dbeta)
> >> function (x, shape1, shape2, ncp = 0, log = FALSE)
> >> {
> >>    if (missing(ncp))
> >>        .Call(C_dbeta, x, shape1, shape2, log)
> >>    else .Call(C_dnbeta, x, shape1, shape2, ncp, log)
> >> }
> >> <environment: namespace:stats>
> >>
> >> It looks like it is calling calling C_dbeta, but I'm not sure. If it
> does,
> >> how do I find it's source code?
> >>
> >> Thank you!
> >> Varun
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From topijush at gmail.com  Mon Jun  8 08:55:04 2015
From: topijush at gmail.com (Pijush Das)
Date: Mon, 8 Jun 2015 12:25:04 +0530
Subject: [R] R to HTML problem
Message-ID: <CAGa91zi7D5BMksPgsYVZ3O8icqEXhPXtAWrRS_Qv5j12cmUhFA@mail.gmail.com>

Dear Jim Lemon,


Thank you very much Jim for your help.


Regards,
Pijush

	[[alternative HTML version deleted]]


From bran.chri at gmail.com  Mon Jun  8 09:20:57 2015
From: bran.chri at gmail.com (=?UTF-8?B?Q2hyaXN0aWFuIEJyYW5kc3TDpHR0ZXI=?=)
Date: Mon, 08 Jun 2015 09:20:57 +0200
Subject: [R] Mean error message missing
Message-ID: <55754259.6020000@gmail.com>

Dear list,

I found an odd behavior of the mean function; it is allowed to do 
something that you probably shouldn't:
If you calculate mean() of a sequence of numbers (without declaring them 
as vector), mean() then just computes mean() of the first element. Is 
there a reason why there is no warning, like in sd for example?

Example code:
mean(1,2,3,4)
sd(1,2,3,4)

Best regards
Christian


From Achim.Zeileis at uibk.ac.at  Mon Jun  8 09:27:37 2015
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 8 Jun 2015 09:27:37 +0200 (CEST)
Subject: [R] Mean error message missing
In-Reply-To: <55754259.6020000@gmail.com>
References: <55754259.6020000@gmail.com>
Message-ID: <alpine.DEB.2.11.1506080926000.14779@paninaro.uibk.ac.at>

On Mon, 8 Jun 2015, Christian Brandst?tter wrote:

> Dear list,
>
> I found an odd behavior of the mean function; it is allowed to do something 
> that you probably shouldn't:
> If you calculate mean() of a sequence of numbers (without declaring them as 
> vector), mean() then just computes mean() of the first element. Is there a 
> reason why there is no warning, like in sd for example?

mean() - unlike sd() - is a generic function that has a '...' argument 
that is passed on to its methods. The default method which is called in 
your example also has a '...' argument (because the generic has it) but 
doesn't use it.

> Example code:
> mean(1,2,3,4)
> sd(1,2,3,4)
>
> Best regards
> Christian
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From shivibhatia at ymail.com  Mon Jun  8 10:08:09 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Mon, 8 Jun 2015 01:08:09 -0700 (PDT)
Subject: [R] Summarizing data based on Date
Message-ID: <1433750889045-4708328.post@n4.nabble.com>

Hi All,

I have a data set with 11000 rows & 19 columns. 
I have 2 columns on which I need to summarize the data:- Date & Weight.
Snapshot is :
Date                             
13/03/2015
31/03/2015
15/03/2015
17/03/2015
17/03/2015
11/3/2015
11/3/2015
19/03/2015

CHG_WT
0
0
0
770
3,730
70
10
500
Now I need to summarize  this data based on Day wise trend of weight however
I have tried bifurcating and truncating the date and saw multiple options
over the web - zoo package, iso week etc but I am not sure on how to reach
to this analysis.
If you experts can please suggest how to achieve the requirement.
Thanks, Shivi













--
View this message in context: http://r.789695.n4.nabble.com/Summarizing-data-based-on-Date-tp4708328.html
Sent from the R help mailing list archive at Nabble.com.


From petr.pikal at precheza.cz  Mon Jun  8 10:41:01 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 8 Jun 2015 08:41:01 +0000
Subject: [R] Summarizing data based on Date
In-Reply-To: <1433750889045-4708328.post@n4.nabble.com>
References: <1433750889045-4708328.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2FFDF@SRVEXCHMBX.precheza.cz>

Hi

Is your Date really Date or is it character? What is result of

str(Date)

If you want to det summaries for dates you can use

?aggregate

However in this case I strongly recommend to show us your data by

dput(yourdata)

and explain on the example what summary do you want.

I can be completely wrong but maybe

aggregate(CHG_WT, list(format(Date, "%d"), sum)

can get you required values.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shivi82
> Sent: Monday, June 08, 2015 10:08 AM
> To: r-help at r-project.org
> Subject: [R] Summarizing data based on Date
>
> Hi All,
>
> I have a data set with 11000 rows & 19 columns.
> I have 2 columns on which I need to summarize the data:- Date & Weight.
> Snapshot is :
> Date
> 13/03/2015
> 31/03/2015
> 15/03/2015
> 17/03/2015
> 17/03/2015
> 11/3/2015
> 11/3/2015
> 19/03/2015
>
> CHG_WT
> 0
> 0
> 0
> 770
> 3,730
> 70
> 10
> 500
> Now I need to summarize  this data based on Day wise trend of weight
> however I have tried bifurcating and truncating the date and saw
> multiple options over the web - zoo package, iso week etc but I am not
> sure on how to reach to this analysis.
> If you experts can please suggest how to achieve the requirement.
> Thanks, Shivi
>
>
>
>
>
>
>
>
>
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Summarizing-data-based-on-Date-
> tp4708328.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From shivibhatia at ymail.com  Mon Jun  8 11:23:06 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Mon, 8 Jun 2015 02:23:06 -0700 (PDT)
Subject: [R] Summarizing data based on Date
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2FFDF@SRVEXCHMBX.precheza.cz>
References: <1433750889045-4708328.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2FFDF@SRVEXCHMBX.precheza.cz>
Message-ID: <1433755386034-4708333.post@n4.nabble.com>

Hi Petr,
Thanks for the explanation below. 
I tried the code you supplied however it seems as my date is a factor hence
it is not working.
The error I got from the code was :

Error: unexpected symbol in:
"final<-aggregate(test$CHG_WT,list(format(test$CR_DT,"%d"),sum)
final"

str(test$CR_DT)- gives Factor with 31 levels 



--
View this message in context: http://r.789695.n4.nabble.com/Summarizing-data-based-on-Date-tp4708328p4708333.html
Sent from the R help mailing list archive at Nabble.com.


From meyners.m at pg.com  Mon Jun  8 12:01:42 2015
From: meyners.m at pg.com (Meyners, Michael)
Date: Mon, 8 Jun 2015 10:01:42 +0000
Subject: [R] mismatch between match and unique causing ecdf (well,
 approxfun) to fail
Message-ID: <AE85F2AAC98B094483D12EEA72230EBD72EAB104@GADC-EMB019.na.pg.com>

All,

I encountered the following issue with ecdf which was originally on a vector of length 10,000, but I have been able to reduce it to a minimal reproducible example (just to avoid questions why I'd want to do this for a vector of length 2...):

test2 = structure(list(X817 = 3.39824670255344, X4789 = 3.39824670255344), .Names = c("X817", "X4789"), row.names = 74L, class = "data.frame")
ecdf(test2) 

# Error in xy.coords(x, y) : 'x' and 'y' lengths differ

In an attempt to track this down, it occurs that 

unique(test2)
#       X817    X4789
#74 3.398247 3.398247

while 

match(test2, unique(test2))
#[1] 1 1

matches both values to the first one. This causes a hiccup in the call to ecdf, as this uses (an equivalent to) a call to approxfun with x = test2 and y = cumsum(tabulate(match(test2, unique(test2)))), the latter now containing one entry less than the former, so xy.coords fails.

I understand that the issue should be somehow related  to FAQ 7.31, but I would have hoped that unique and match would be using the same precision and hence both or neither would consider the two values identical, but not one match while unique doesn't. 

Last but not least, it doesn't really cause an issue on my end (other than breaking my code and hence out of a loop at first place...); rounding will help w/o noteworthy changes to the outcome, so no need to propose a workaround :-) I'd rather like to raise the issue and learn whether there is a purpose for this behavior, and/or whether there is a generic fix to this, or whether I am completely missing something.

Version info (under Windows 7): 
R version 3.2.0 (2015-04-16) -- "Full of Ingredients"
Platform: x86_64-w64-mingw32/x64 (64-bit)

Cheers, Michael 


From bran.chri at gmail.com  Mon Jun  8 12:04:47 2015
From: bran.chri at gmail.com (=?ISO-8859-15?Q?Christian_Brandst=E4tter?=)
Date: Mon, 08 Jun 2015 12:04:47 +0200
Subject: [R] Mean error message missing
In-Reply-To: <alpine.DEB.2.11.1506080926000.14779@paninaro.uibk.ac.at>
References: <55754259.6020000@gmail.com>
	<alpine.DEB.2.11.1506080926000.14779@paninaro.uibk.ac.at>
Message-ID: <557568BF.2020608@gmail.com>

Thank you for the explanation.
But if you take for instance plot.default(), being another generic 
function, it would not work like that:
plot(1,2,3,4), only plot(1,2) is accepted.


 From R-help (Usage):
## Default S3 method:
mean(x, trim = 0, na.rm = FALSE, ...)

What is puzzling, is that apparently na.rm (and trim, which is indicated in the help) is accepting numeric values.
mean(c(1,NA,10),10,TRUE)
mean(c(1,NA,10),10,FALSE)

This should give at least a warning in my opinion.

mean(c(1,NA,10),10,200)



On 08/06/2015 09:27, Achim Zeileis wrote:

> On Mon, 8 Jun 2015, Christian Brandst?tter wrote:
>
>> Dear list,
>>
>> I found an odd behavior of the mean function; it is allowed to do 
>> something that you probably shouldn't:
>> If you calculate mean() of a sequence of numbers (without declaring 
>> them as vector), mean() then just computes mean() of the first 
>> element. Is there a reason why there is no warning, like in sd for 
>> example?
>
> mean() - unlike sd() - is a generic function that has a '...' argument 
> that is passed on to its methods. The default method which is called 
> in your example also has a '...' argument (because the generic has it) 
> but doesn't use it.
>
>> Example code:
>> mean(1,2,3,4)
>> sd(1,2,3,4)
>>
>> Best regards
>> Christian
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


	[[alternative HTML version deleted]]


From meyners.m at pg.com  Mon Jun  8 12:51:26 2015
From: meyners.m at pg.com (Meyners, Michael)
Date: Mon, 8 Jun 2015 10:51:26 +0000
Subject: [R] mismatch between match and unique causing ecdf (well,
 approxfun) to fail
Message-ID: <AE85F2AAC98B094483D12EEA72230EBD72EAB293@GADC-EMB019.na.pg.com>

Aehm, adding on this: I incorrectly *assumed* without testing that rounding would help; it doesn't:

ecdf(round(test2,0)) 	# a rounding that is way too rough for my application...
#Error in xy.coords(x, y) : 'x' and 'y' lengths differ

Digging deeper: The initially mentioned call to unique() is not very helpful, as test2 is a data frame, so I get what I deserve, an unchanged data frame with 1 row. Still, the issue remains and can even be simplified further:

> ecdf(data.frame(a=3, b=4))
Empirical CDF 
Call: ecdf(data.frame(a = 3, b = 4))
 x[1:2] =      3,      4

works ok, but

> ecdf(data.frame(a=3, b=3))
Error in xy.coords(x, y) : 'x' and 'y' lengths differ

doesn't (same for a=b=1 or 2, so likely the same for any a=b). Instead, 

> ecdf(c(a=3, b=3))
Empirical CDF 
Call: ecdf(c(a = 3, b = 3))
 x[1:1] =      3

does the trick. From ?ecdf, I get that x should be a numeric vector - apparently, my misuse of the function by applying it to a row of a data frame (i.e. a data frame with one row). In all my other (dozens of) cases that worked ok, though but not for this particular one. A simple unlist() helps:

> ecdf(unlist(data.frame(a=3, b=3)))
Empirical CDF 
Call: ecdf(unlist(data.frame(a = 3, b = 3)))
 x[1:1] =      3

Yet, I'm even more confused than before: in my other data, there were also duplicated values in the vector (1-row-data frame), and it never caused any issue. For this particular example, it does. I must be missing something fundamental...
 
Michael

> -----Original Message-----
> From: Meyners, Michael
> Sent: Montag, 8. Juni 2015 12:02
> To: 'r-help at r-project.org'
> Subject: mismatch between match and unique causing ecdf (well,
> approxfun) to fail
> 
> All,
> 
> I encountered the following issue with ecdf which was originally on a vector
> of length 10,000, but I have been able to reduce it to a minimal reproducible
> example (just to avoid questions why I'd want to do this for a vector of
> length 2...):
> 
> test2 = structure(list(X817 = 3.39824670255344, X4789 = 3.39824670255344),
> .Names = c("X817", "X4789"), row.names = 74L, class = "data.frame")
> ecdf(test2)
> 
> # Error in xy.coords(x, y) : 'x' and 'y' lengths differ
> 
> In an attempt to track this down, it occurs that
> 
> unique(test2)
> #       X817    X4789
> #74 3.398247 3.398247
> 
> while
> 
> match(test2, unique(test2))
> #[1] 1 1
> 
> matches both values to the first one. This causes a hiccup in the call to ecdf,
> as this uses (an equivalent to) a call to approxfun with x = test2 and y =
> cumsum(tabulate(match(test2, unique(test2)))), the latter now containing
> one entry less than the former, so xy.coords fails.
> 
> I understand that the issue should be somehow related  to FAQ 7.31, but I
> would have hoped that unique and match would be using the same precision
> and hence both or neither would consider the two values identical, but not
> one match while unique doesn't.
> 
> Last but not least, it doesn't really cause an issue on my end (other than
> breaking my code and hence out of a loop at first place...); rounding will help
> w/o noteworthy changes to the outcome, so no need to propose a
> workaround :-) I'd rather like to raise the issue and learn whether there is a
> purpose for this behavior, and/or whether there is a generic fix to this, or
> whether I am completely missing something.
> 
> Version info (under Windows 7):
> R version 3.2.0 (2015-04-16) -- "Full of Ingredients"
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> Cheers, Michael


From shivibhatia at ymail.com  Mon Jun  8 12:48:16 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Mon, 8 Jun 2015 03:48:16 -0700 (PDT)
Subject: [R] Cannot Sum with DDPLY
Message-ID: <1433760496974-4708338.post@n4.nabble.com>

Hi All,
Kindly see the below code I have used:
maxorder<-ddply(test, ~ ORIGIN,summarize,Weight=sum(CHG_WT))

Here I have written the code to summarize values based on origin and total
weight however I am getting below error:
Error: ?sum? not meaningful for factors

Please advice. I need CHG_WT total for each state in the Origin column.




--
View this message in context: http://r.789695.n4.nabble.com/Cannot-Sum-with-DDPLY-tp4708338.html
Sent from the R help mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Mon Jun  8 13:20:18 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 08 Jun 2015 07:20:18 -0400
Subject: [R] source code for dbeta
In-Reply-To: <CAF-rFrLU3CLqGB7A9UAgygthnhAtXhvcpAHwg5uuPZQ8TXt5Cg@mail.gmail.com>
References: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>	<963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>	<5574CE8B.3060309@gmail.com>
	<CAF-rFrLU3CLqGB7A9UAgygthnhAtXhvcpAHwg5uuPZQ8TXt5Cg@mail.gmail.com>
Message-ID: <55757A72.9010605@gmail.com>

On 07/06/2015 11:05 PM, Varun Sinha wrote:
> Hi,
> 
> Thanks a lot. I downloaded the tar.gz file and I found the C code.
> 
> I would really appreciate it if you could field another question:
> I have to use sql, and I have to perform various statistical
> calculations - like integrate, dbeta etc. Sql does not have these
> functions, plus they are very difficult to code. Would it be possible to
> use the C code, compile it and deploy it in sql? Is that feasible, or
> even permitted?

It is permitted for local use only without conditions.  If you want to
deploy the application, your application must be licensed under the GPL.

As to the practicality:  see the Writing R Extensions manual, section
6.16, which describes how to link many math functions (I forget if dbeta
is included) into your own C code.  Linking those to your database
system will strongly depend on which database system you're using, and I
think for all of them the question would be off topic here.  You need to
ask on their help forum.

Duncan Murdoch


> 
> Thanks once again, I'm very grateful.
> 
> 
> On Mon, Jun 8, 2015 at 2:06 AM, Duncan Murdoch <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 07/06/2015 6:11 PM, Mark Sharp wrote:
>     > Varun,
>     >
>     > If you type dbeta at the command line you get the R source, which in this case tells you that the code is calling a compiled source. This is indicated by the line <bytecode: 0x7fc3bb1b84e0>
> 
>     No, that says that the R code (what is shown) is compiled.  What
>     indicates that this is C code is the use of .Call.  The C_dbeta and
>     C_dnbeta objects are "NativeSymbolInfo" objects that hold the pointers
>     to the C entry points.
> 
>     Since it is in a base package ("stats"), the source is in the R sources,
>     somewhere in  https://svn.r-project.org/R/trunk/src/library/stats/src.
>     You can search through those files for the dbeta or dnbeta functions.
>     The "C_" prefix is conventionally used in the R sources to indicate that
>     it is C code; generally you replace it with "do_" in the actual C code.
>      This particular function is actually not really in the package source;
>     it's in the main part of the R sources, in file
> 
>     https://svn.r-project.org/R/trunk/src/nmath/dbeta.c
> 
>     (though it takes a few steps to get there, starting in the stats package
>     function do_dbeta).
> 
>     Duncan Murdoch
>     >
>     > See the following.
>     >> dbeta
>     > function (x, shape1, shape2, ncp = 0, log = FALSE)
>     > {
>     >     if (missing(ncp))
>     >         .Call(C_dbeta, x, shape1, shape2, log)
>     >     else .Call(C_dnbeta, x, shape1, shape2, ncp, log)
>     > }
>     > <bytecode: 0x7fc3bb1b84e0>
>     > <environment: namespace:stats>
>     >
>     > Compiled code in a package
>     >
>     > If you want to view compiled code in a package, you will need to
>     download/unpack the package source. The installed binaries are not
>     sufficient. A package's source code is available from the same CRAN
>     (or CRAN compatible) repository that the package was originally
>     installed from. The download.packages() function can get the package
>     source for you.
>     >
>     > Extracted from
>     http://stackoverflow.com/questions/19226816/how-can-i-view-the-source-code-for-a-function
>     >
>     > Mark
>     >
>     >
>     > R. Mark Sharp, Ph.D.
>     > msharp at TxBiomed.org
>     >
>     >
>     >> On Jun 7, 2015, at 4:31 AM, Varun Sinha <sinha.varuna85 at gmail.com
>     <mailto:sinha.varuna85 at gmail.com>> wrote:
>     >>
>     >> Hi,
>     >>
>     >> I am trying to find the source code for dbeta function.
>     >>
>     >> I tried edit(dbeta) and this is what I got:
>     >>> edit(dbeta)
>     >> function (x, shape1, shape2, ncp = 0, log = FALSE)
>     >> {
>     >>    if (missing(ncp))
>     >>        .Call(C_dbeta, x, shape1, shape2, log)
>     >>    else .Call(C_dnbeta, x, shape1, shape2, ncp, log)
>     >> }
>     >> <environment: namespace:stats>
>     >>
>     >> It looks like it is calling calling C_dbeta, but I'm not sure. If
>     it does,
>     >> how do I find it's source code?
>     >>
>     >> Thank you!
>     >> Varun
>     >>
>     >>      [[alternative HTML version deleted]]
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     >> and provide commented, minimal, self-contained, reproducible code.
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>     >
> 
>


From murdoch.duncan at gmail.com  Mon Jun  8 13:25:06 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 08 Jun 2015 07:25:06 -0400
Subject: [R] Mean error message missing
In-Reply-To: <557568BF.2020608@gmail.com>
References: <55754259.6020000@gmail.com>	<alpine.DEB.2.11.1506080926000.14779@paninaro.uibk.ac.at>
	<557568BF.2020608@gmail.com>
Message-ID: <55757B92.9020107@gmail.com>

On 08/06/2015 6:04 AM, Christian Brandst?tter wrote:
> Thank you for the explanation.
> But if you take for instance plot.default(), being another generic 
> function, it would not work like that:
> plot(1,2,3,4), only plot(1,2) is accepted.
> 
> 
>  From R-help (Usage):
> ## Default S3 method:
> mean(x, trim = 0, na.rm = FALSE, ...)
> 
> What is puzzling, is that apparently na.rm (and trim, which is indicated in the help) is accepting numeric values.
> mean(c(1,NA,10),10,TRUE)
> mean(c(1,NA,10),10,FALSE)
> 
> This should give at least a warning in my opinion.

It is a common idiom in R programming to treat non-zero values as TRUE,
and zero as FALSE.  If every use of a number where a logical is needed
generated a warning, you'd be swamped with them.

Duncan Murdoch

> 
> mean(c(1,NA,10),10,200)
> 
> 
> 
> On 08/06/2015 09:27, Achim Zeileis wrote:
> 
>> On Mon, 8 Jun 2015, Christian Brandst?tter wrote:
>>
>>> Dear list,
>>>
>>> I found an odd behavior of the mean function; it is allowed to do 
>>> something that you probably shouldn't:
>>> If you calculate mean() of a sequence of numbers (without declaring 
>>> them as vector), mean() then just computes mean() of the first 
>>> element. Is there a reason why there is no warning, like in sd for 
>>> example?
>>
>> mean() - unlike sd() - is a generic function that has a '...' argument 
>> that is passed on to its methods. The default method which is called 
>> in your example also has a '...' argument (because the generic has it) 
>> but doesn't use it.
>>
>>> Example code:
>>> mean(1,2,3,4)
>>> sd(1,2,3,4)
>>>
>>> Best regards
>>> Christian
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bran.chri at gmail.com  Mon Jun  8 14:05:52 2015
From: bran.chri at gmail.com (=?UTF-8?B?Q2hyaXN0aWFuIEJyYW5kc3TDpHR0ZXI=?=)
Date: Mon, 08 Jun 2015 14:05:52 +0200
Subject: [R] Mean error message missing
In-Reply-To: <55757B92.9020107@gmail.com>
References: <55754259.6020000@gmail.com>	<alpine.DEB.2.11.1506080926000.14779@paninaro.uibk.ac.at>
	<557568BF.2020608@gmail.com> <55757B92.9020107@gmail.com>
Message-ID: <55758520.8020705@gmail.com>

Thank you very much, I didn't know that.

> On 08/06/2015 6:04 AM, Christian Brandst?tter wrote:
>> Thank you for the explanation.
>> But if you take for instance plot.default(), being another generic
>> function, it would not work like that:
>> plot(1,2,3,4), only plot(1,2) is accepted.
>>
>>
>>   From R-help (Usage):
>> ## Default S3 method:
>> mean(x, trim = 0, na.rm = FALSE, ...)
>>
>> What is puzzling, is that apparently na.rm (and trim, which is indicated in the help) is accepting numeric values.
>> mean(c(1,NA,10),10,TRUE)
>> mean(c(1,NA,10),10,FALSE)
>>
>> This should give at least a warning in my opinion.
> It is a common idiom in R programming to treat non-zero values as TRUE,
> and zero as FALSE.  If every use of a number where a logical is needed
> generated a warning, you'd be swamped with them.
>
> Duncan Murdoch
>
>> mean(c(1,NA,10),10,200)
>>
>>
>>
>> On 08/06/2015 09:27, Achim Zeileis wrote:
>>
>>> On Mon, 8 Jun 2015, Christian Brandst?tter wrote:
>>>
>>>> Dear list,
>>>>
>>>> I found an odd behavior of the mean function; it is allowed to do
>>>> something that you probably shouldn't:
>>>> If you calculate mean() of a sequence of numbers (without declaring
>>>> them as vector), mean() then just computes mean() of the first
>>>> element. Is there a reason why there is no warning, like in sd for
>>>> example?
>>> mean() - unlike sd() - is a generic function that has a '...' argument
>>> that is passed on to its methods. The default method which is called
>>> in your example also has a '...' argument (because the generic has it)
>>> but doesn't use it.
>>>
>>>> Example code:
>>>> mean(1,2,3,4)
>>>> sd(1,2,3,4)
>>>>
>>>> Best regards
>>>> Christian
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>
>> 	[[alternative HTML version deleted]]
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From petr.pikal at precheza.cz  Mon Jun  8 16:04:20 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 8 Jun 2015 14:04:20 +0000
Subject: [R] Summarizing data based on Date
In-Reply-To: <1433755386034-4708333.post@n4.nabble.com>
References: <1433750889045-4708328.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C2FFDF@SRVEXCHMBX.precheza.cz>
	<1433755386034-4708333.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C300F0@SRVEXCHMBX.precheza.cz>

Hi


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shivi82
> Sent: Monday, June 08, 2015 11:23 AM
> To: r-help at r-project.org
> Subject: Re: [R] Summarizing data based on Date
>
> Hi Petr,
> Thanks for the explanation below.
> I tried the code you supplied however it seems as my date is a factor
> hence it is not working.

So you need to change your factor to date.

see
?as.Date

as.Date(as.factor(Sys.Date()))

Cheers
Petr

> The error I got from the code was :
>
> Error: unexpected symbol in:
> "final<-aggregate(test$CHG_WT,list(format(test$CR_DT,"%d"),sum)
> final"
>
> str(test$CR_DT)- gives Factor with 31 levels
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Summarizing-data-based-on-Date-
> tp4708328p4708333.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Mon Jun  8 16:09:43 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 8 Jun 2015 14:09:43 +0000
Subject: [R] Cannot Sum with DDPLY
In-Reply-To: <1433760496974-4708338.post@n4.nabble.com>
References: <1433760496974-4708338.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C30101@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shivi82
> Sent: Monday, June 08, 2015 12:48 PM
> To: r-help at r-project.org
> Subject: [R] Cannot Sum with DDPLY
>
> Hi All,
> Kindly see the below code I have used:
> maxorder<-ddply(test, ~ ORIGIN,summarize,Weight=sum(CHG_WT))
>
> Here I have written the code to summarize values based on origin and
> total weight however I am getting below error:
> Error: ?sum? not meaningful for factors

I consider this error message as ***extremely*** informative. Your CHG_WT is actually the factor object and sum is not meaningful for factors.

Maybe it is time for you to check R-Intro document about objects and their differences before you continue with posting.

If CHG_WT shall be numeric you probably did not read it correctly for whatever reason.

Cheers
Petr


>
> Please advice. I need CHG_WT total for each state in the Origin column.
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Cannot-Sum-
> with-DDPLY-tp4708338.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jsorkin at grecc.umaryland.edu  Mon Jun  8 16:15:48 2015
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 08 Jun 2015 10:15:48 -0400
Subject: [R] Blank spaces are replaced by period in read.csv,
 I want to replace blacks with an underline
In-Reply-To: <55757A72.9010605@gmail.com>
References: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>
	<963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>
	<5574CE8B.3060309@gmail.com>
	<CAF-rFrLU3CLqGB7A9UAgygthnhAtXhvcpAHwg5uuPZQ8TXt5Cg@mail.gmail.com>
	<55757A72.9010605@gmail.com>
Message-ID: <55756B54020000CB0012F150@smtp.medicine.umaryland.edu>

I am reading a csv file. The column headers have spaces in them. The spaces are replaced by a period. I want to replace the space by another character (e.g. the underline) rather than the period. Can someone tell me how to accomplish this?Thank you,
John

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From dcarlson at tamu.edu  Mon Jun  8 16:21:29 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 8 Jun 2015 14:21:29 +0000
Subject: [R] Blank spaces are replaced by period in read.csv,
 I want to replace blacks with an underline
In-Reply-To: <55756B54020000CB0012F150@smtp.medicine.umaryland.edu>
References: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>
	<963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>
	<5574CE8B.3060309@gmail.com>
	<CAF-rFrLU3CLqGB7A9UAgygthnhAtXhvcpAHwg5uuPZQ8TXt5Cg@mail.gmail.com>
	<55757A72.9010605@gmail.com>
	<55756B54020000CB0012F150@smtp.medicine.umaryland.edu>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D69148A@mb02.ads.tamu.edu>

You can use gsub() to change the names:

> dat <- data.frame("Var 1"=rnorm(5, 10), "Var 2"=rnorm(5, 15))
> dat
      Var.1    Var.2
1  9.627122 14.15376
2 10.741617 16.92937
3  8.492926 15.23767
4 12.226146 15.19834
5  8.829982 14.46957
> names(dat) <- gsub("\\.", "_", names(dat))
> dat
      Var_1    Var_2
1  9.627122 14.15376
2 10.741617 16.92937
3  8.492926 15.23767
4 12.226146 15.19834
5  8.829982 14.46957

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of John Sorkin
Sent: Monday, June 8, 2015 9:16 AM
Cc: r-help at r-project.org
Subject: [R] Blank spaces are replaced by period in read.csv, I want to replace blacks with an underline

I am reading a csv file. The column headers have spaces in them. The spaces are replaced by a period. I want to replace the space by another character (e.g. the underline) rather than the period. Can someone tell me how to accomplish this?Thank you,
John

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for th...{{dropped:12}}


From sarah.goslee at gmail.com  Mon Jun  8 16:23:00 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 8 Jun 2015 10:23:00 -0400
Subject: [R] Blank spaces are replaced by period in read.csv,
 I want to replace blacks with an underline
In-Reply-To: <55756B54020000CB0012F150@smtp.medicine.umaryland.edu>
References: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>
	<963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>
	<5574CE8B.3060309@gmail.com>
	<CAF-rFrLU3CLqGB7A9UAgygthnhAtXhvcpAHwg5uuPZQ8TXt5Cg@mail.gmail.com>
	<55757A72.9010605@gmail.com>
	<55756B54020000CB0012F150@smtp.medicine.umaryland.edu>
Message-ID: <CAM_vjukaktO2Q=XnABzp8WKvwr1f2ROSq+RCoGFvQpocaAqfRw@mail.gmail.com>

Easiest? Use sub() to replace the periods after the fact.

You can also use the check.names or the col.names arguments to
read.table() to customize your import.

Sarah

On Mon, Jun 8, 2015 at 10:15 AM, John Sorkin
<jsorkin at grecc.umaryland.edu> wrote:
> I am reading a csv file. The column headers have spaces in them. The spaces are replaced by a period. I want to replace the space by another character (e.g. the underline) rather than the period. Can someone tell me how to accomplish this?Thank you,
> John
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From jsorkin at grecc.umaryland.edu  Mon Jun  8 16:24:37 2015
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 08 Jun 2015 10:24:37 -0400
Subject: [R] Blank spaces are replaced by period in read.csv,
 I want to replace blacks with an underline
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D69148A@mb02.ads.tamu.edu>
References: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>
	<963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>
	<5574CE8B.3060309@gmail.com>
	<CAF-rFrLU3CLqGB7A9UAgygthnhAtXhvcpAHwg5uuPZQ8TXt5Cg@mail.gmail.com>
	<55757A72.9010605@gmail.com>
	<55756B54020000CB0012F150@smtp.medicine.umaryland.edu>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D69148A@mb02.ads.tamu.edu>
Message-ID: <55756D65020000CB0012F15E@smtp.medicine.umaryland.edu>

David,I appreciate you suggestion, but it won't work for me. I need to replace the space for a period at the time the data are read, not afterward. My variables names have periods I want to keep, if I use your suggestion I will replace the period inserted when the data are read, as well as the period that I want to keep.
Thank you,
John 



John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

>>> David L Carlson <dcarlson at tamu.edu> 06/08/15 10:21 AM >>>
You can use gsub() to change the names:

> dat <- data.frame("Var 1"=rnorm(5, 10), "Var 2"=rnorm(5, 15))
> dat
      Var.1    Var.2
1  9.627122 14.15376
2 10.741617 16.92937
3  8.492926 15.23767
4 12.226146 15.19834
5  8.829982 14.46957
> names(dat) <- gsub("\\.", "_", names(dat))
> dat
      Var_1    Var_2
1  9.627122 14.15376
2 10.741617 16.92937
3  8.492926 15.23767
4 12.226146 15.19834
5  8.829982 14.46957

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of John Sorkin
Sent: Monday, June 8, 2015 9:16 AM
Cc: r-help at r-project.org
Subject: [R] Blank spaces are replaced by period in read.csv, I want to replace blacks with an underline

I am reading a csv file. The column headers have spaces in them. The spaces are replaced by a period. I want to replace the space by another character (e.g. the underline) rather than the period. Can someone tell me how to accomplish this?Thank you,
John

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


Call
Send SMS
Call from mobile
Add to Skype
You'll need Skype CreditFree via Skype



Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From msharp at txbiomed.org  Mon Jun  8 16:24:52 2015
From: msharp at txbiomed.org (Mark Sharp)
Date: Mon, 8 Jun 2015 14:24:52 +0000
Subject: [R] Blank spaces are replaced by period in read.csv,
 I want to replace blacks with an underline
In-Reply-To: <55756B54020000CB0012F150@smtp.medicine.umaryland.edu>
References: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>
	<963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>
	<5574CE8B.3060309@gmail.com>
	<CAF-rFrLU3CLqGB7A9UAgygthnhAtXhvcpAHwg5uuPZQ8TXt5Cg@mail.gmail.com>
	<55757A72.9010605@gmail.com>
	<55756B54020000CB0012F150@smtp.medicine.umaryland.edu>
Message-ID: <67237975-EA98-44EA-AED6-E4CF651478F9@txbiomed.org>

John,

I like using stringr or stringi for this type of thing. stringi is written in C and faster so I now typically use it. You can also use base functions. The main trick is the handy names() function.

> example <- data.frame("Col 1 A" = 1:3, "Col 1 B" = letters[1:3])
> example
  Col.1.A Col.1.B
1       1       a
2       2       b
3       3       c
> library(stringi)
> names(example) <- stri_replace_all_fixed(names(example), ".", "_")
> example
  Col_1_A Col_1_B
1       1       a
2       2       b
3       3       c

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org







> On Jun 8, 2015, at 9:15 AM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> 
> I am reading a csv file. The column headers have spaces in them. The spaces are replaced by a period. I want to replace the space by another character (e.g. the underline) rather than the period. Can someone tell me how to accomplish this?Thank you,
> John
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> 
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:12}}


From maechler at stat.math.ethz.ch  Mon Jun  8 16:42:43 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 8 Jun 2015 16:42:43 +0200
Subject: [R] mismatch between match and unique causing ecdf (well,
 approxfun) to fail
In-Reply-To: <AE85F2AAC98B094483D12EEA72230EBD72EAB293@GADC-EMB019.na.pg.com>
References: <AE85F2AAC98B094483D12EEA72230EBD72EAB293@GADC-EMB019.na.pg.com>
Message-ID: <21877.43491.335871.527297@stat.math.ethz.ch>


> Aehm, adding on this: I incorrectly *assumed* without testing that rounding would help; it doesn't:
> ecdf(round(test2,0)) 	# a rounding that is way too rough for my application...
> #Error in xy.coords(x, y) : 'x' and 'y' lengths differ
> 
> Digging deeper: The initially mentioned call to unique() is not very helpful, as test2 is a data frame, so I get what I deserve, an unchanged data frame with 1 row. Still, the issue remains and can even be simplified further:
> 
> > ecdf(data.frame(a=3, b=4))
> Empirical CDF 
> Call: ecdf(data.frame(a = 3, b = 4))
>  x[1:2] =      3,      4
> 
> works ok, but
> 
> > ecdf(data.frame(a=3, b=3))
> Error in xy.coords(x, y) : 'x' and 'y' lengths differ
> 
> doesn't (same for a=b=1 or 2, so likely the same for any a=b). Instead, 
> 
> > ecdf(c(a=3, b=3))
> Empirical CDF 
> Call: ecdf(c(a = 3, b = 3))
>  x[1:1] =      3
> 
> does the trick. From ?ecdf, I get that x should be a numeric vector - apparently, my misuse of the function by applying it to a row of a data frame (i.e. a data frame with one row). In all my other (dozens of) cases that worked ok, though but not for this particular one. A simple unlist() helps:

You were lucky.   To use a one-row data frame instead of a
numerical vector will typically *not* work unless ... well, you
are lucky.

No, do *not*  pass data frame rows instead of numeric vectors.

> 
> > ecdf(unlist(data.frame(a=3, b=3)))
> Empirical CDF 
> Call: ecdf(unlist(data.frame(a = 3, b = 3)))
>  x[1:1] =      3
> 
> Yet, I'm even more confused than before: in my other data, there were also duplicated values in the vector (1-row-data frame), and it never caused any issue. For this particular example, it does. I must be missing something fundamental...
>  

well.. I'm confused about why you are confused,
but if you are thinking about passing rows of data frames as
numeric vectors, this means you are sure that your data frame
only contains "classical numbers" (no factors, no 'Date's,
no...).

In such a case, transform your data frame to a numerical matrix
*once* preferably using  data.matrix(<d.fr>) instead of just  as.matrix(<d.fr>)
but in this case it should not matter.
Then *check* the result and then work with that matrix from then on.

All other things probably will continue to leave you confused ..
;-)

Martin Maechler, 
ETH Zurich


From murdoch.duncan at gmail.com  Mon Jun  8 16:42:45 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 08 Jun 2015 10:42:45 -0400
Subject: [R] Blank spaces are replaced by period in read.csv,
 I want to replace blacks with an underline
In-Reply-To: <CAM_vjukaktO2Q=XnABzp8WKvwr1f2ROSq+RCoGFvQpocaAqfRw@mail.gmail.com>
References: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>	<963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>	<5574CE8B.3060309@gmail.com>	<CAF-rFrLU3CLqGB7A9UAgygthnhAtXhvcpAHwg5uuPZQ8TXt5Cg@mail.gmail.com>	<55757A72.9010605@gmail.com>	<55756B54020000CB0012F150@smtp.medicine.umaryland.edu>
	<CAM_vjukaktO2Q=XnABzp8WKvwr1f2ROSq+RCoGFvQpocaAqfRw@mail.gmail.com>
Message-ID: <5575A9E5.3010603@gmail.com>

On 08/06/2015 10:23 AM, Sarah Goslee wrote:
> Easiest? Use sub() to replace the periods after the fact.
> 
> You can also use the check.names or the col.names arguments to
> read.table() to customize your import.

Yes, check.names is the right idea.  Use check.names = FALSE, then use
sub() or gsub() to replace the spaces with underscores.

Duncan Murdoch

> Sarah
> 
> On Mon, Jun 8, 2015 at 10:15 AM, John Sorkin
> <jsorkin at grecc.umaryland.edu> wrote:
>> I am reading a csv file. The column headers have spaces in them. The spaces are replaced by a period. I want to replace the space by another character (e.g. the underline) rather than the period. Can someone tell me how to accomplish this?Thank you,
>> John
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>>


From dcarlson at tamu.edu  Mon Jun  8 16:45:57 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 8 Jun 2015 14:45:57 +0000
Subject: [R] Blank spaces are replaced by period in read.csv,
 I want to replace blacks with an underline
In-Reply-To: <55756D65020000CB0012F15E@smtp.medicine.umaryland.edu>
References: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>
	<963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>
	<5574CE8B.3060309@gmail.com>
	<CAF-rFrLU3CLqGB7A9UAgygthnhAtXhvcpAHwg5uuPZQ8TXt5Cg@mail.gmail.com>
	<55757A72.9010605@gmail.com>
	<55756B54020000CB0012F150@smtp.medicine.umaryland.edu>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D69148A@mb02.ads.tamu.edu>
	<55756D65020000CB0012F15E@smtp.medicine.umaryland.edu>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D691547@mb02.ads.tamu.edu>

Then using Sarah's suggestion something like?

> dat <- read.table(text="
+ 'Var 1' Var.2
+ 1 6
+ 2 7
+ 3 8
+ 4 9
+ 5 10", header=TRUE, col.names=c("Var_1", "Var.2"))
> dat
  Var_1 Var.2
1     1     6
2     2     7
3     3     8
4     4     9
5     5    10

David C

From: John Sorkin [mailto:jsorkin at grecc.umaryland.edu] 
Sent: Monday, June 8, 2015 9:25 AM
To: David L Carlson
Cc: r-help at r-project.org
Subject: RE: [R] Blank spaces are replaced by period in read.csv, I want to replace blacks with an underline

David,
I appreciate you suggestion, but it won't work for me. I need to replace the space for a period at the time the data are read, not afterward. My variables names have periods I want to keep, if I use your suggestion I will replace the period inserted when the data are read, as well as the period that I want to keep.
Thank you,
John?


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of?Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

>>> David L Carlson <dcarlson at tamu.edu> 06/08/15 10:21 AM >>>
You can use gsub() to change the names:

> dat <- data.frame("Var 1"=rnorm(5, 10), "Var 2"=rnorm(5, 15))
> dat
Var.1 Var.2
1 9.627122 14.15376
2 10.741617 16.92937
3 8.492926 15.23767
4 12.226146 15.19834
5 8.829982 14.46957
> names(dat) <- gsub("\\.", "_", names(dat))
> dat
Var_1 Var_2
1 9.627122 14.15376
2 10.741617 16.92937
3 8.492926 15.23767
4 12.226146 15.19834
5 8.829982 14.46957

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of John Sorkin
Sent: Monday, June 8, 2015 9:16 AM
Cc: r-help at r-project.org
Subject: [R] Blank spaces are replaced by period in read.csv, I want to replace blacks with an underline

I am reading a csv file. The column headers have spaces in them. The spaces are replaced by a period. I want to replace the space by another character (e.g. the underline) rather than the period. Can someone tell me how to accomplish this?Thank you,
John

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for th...{{dropped:24}}


From thomas.hotz at tu-ilmenau.de  Fri Jun  5 13:16:23 2015
From: thomas.hotz at tu-ilmenau.de (Thomas Hotz)
Date: Fri, 5 Jun 2015 13:16:23 +0200
Subject: [R] [R-pkgs] New package stepR: fitting step-functions
Message-ID: <55718507.4090005@tu-ilmenau.de>

Dear R users,

It is my pleasure to announce the availability of package stepR (1.0-2) 
on CRAN.

The main purpose of the package is to fit piecewise constant functions 
(a.k.a. step-functions or block signals) to serial data in a fully 
data-driven manner under certain (Gaussian or non-Gaussian) 
distributional assumptions.

It mainly implements the algorithms described in the references below - 
in a (hopefully) user-friendly fashion.

Try

    library(stepR)
    example(smuceR) # for [1] and [2]
    example(jsmurf) # for [3]
    example(stepsel) # for [4]

to get an idea about what it can do, and how to use it.

We hope it proves useful; community feedback is therefore very welcome!

Best regards

Thomas Hotz
TU Ilmenau, Institute of Mathematics

References:

[1] Frick, K., Munk, A., and Sieling, H. (2014). Multiscale Change-Point 
Inference. With discussion and rejoinder by the authors. Journal of the 
Royal Statistical Society, Series B, 76(3), 495-580.
[2] Futschik, A., Hotz, T., Munk, A. Sieling, H. (2014). Multiresolution 
DNA partitioning: statistical evidence for segments. Bioinformatics,  
30(16), 2255-2262.
[3] Hotz, T., Sch?tte, O., Sieling, H., Polupanow, T., Diederichsen, U., 
Steinem, C., and Munk, A. (2013). Idealizing Ion Channel Recordings by a 
Jump Segmentation Multiresolution Filter. IEEE Transactions on 
NanoBioscience, 12(4), 376-386.
[4] Boysen, L., Kempe, A., Liebscher, V., Munk, A., Wittich, O. (2009). 
Consistencies and rates of convergence of jump-penalized least squares 
estimators. The Annals of Statistics, 37(1), 157-183.

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From Michael.Rustler at kompetenz-wasser.de  Mon Jun  8 14:47:02 2015
From: Michael.Rustler at kompetenz-wasser.de (Michael Rustler)
Date: Mon, 8 Jun 2015 12:47:02 +0000
Subject: [R] [R-pkgs] New R package kwb.hantush (0.2.1): calculation of
 groundwater mounding beneath an (stormwater) infiltration basin
Message-ID: <6FDA78647A9EF040B0BF9C6081518439340F8FA4@SourceMBX0.KWB.BERLIN>

Dear R users,

It is a pleasure for me to announce the availability of the new package kwb.hantush (0.2.1)? on CRAN. Its objective is the calculation of groundwater mounding beneath an (stormwater) infiltration basin by solving the Hantush (1967) equation. For checking the correct implementation of the algorithm the R modelling results were cross-checked against alternative models assessed in Carleton (2010) by using the same model parameterisation. 

References: 
[1] Carleton, G.B., 2010, Simulation of groundwater mounding beneath hypothetical stormwater infiltration basins: U.S. Geological Survey Scientific Investigations Report 2010-5102, 64 p.; http://pubs.usgs.gov/sir/2010/5102/ 

[2] Hantush, M.S. (1967): Growth and decay of groundwater-mounds in response to uniform percolation, Water Resources Research (March, 1967); http://doi.org/10.1029/WR003i001p00227 


How to get started ? 

* Firstly install the package from CRAN by using:  install.packages("kwb.hantush")

* Secondly visit http://kwb-r.github.io/kwb.hantush? for doing a short tutorial, which answers the following questions: 
	- How do I perform model runs ?

	- How accurate is the solution of the Hantush equation implemented in R compared to the a reference model 
	  (e.g. U.S. Geological Survey EXCEL spreadsheet solution, http://pubs.usgs.gov/sir/2010/5102/support/Hantush_USGS_SIR_2010-5102-1110.xlsm) ?

I hope it proves to be useful and community feedback is therefore very welcome!

Best Regards, 
Michael Rustler

--------------------------------------------
Dipl.-Geo?k. Michael Rustler
KompetenzZentrum Wasser Berlin gGmbH
Cicerostr. 24
D-10709 Berlin
Tel. +49 (0)30 53653 825
Fax +49 (0)30 53653 888
Email: michael.rustler at kompetenz-wasser.de
Homepage: www.kompetenz-wasser.de <http://www.kompetenz-wasser.de>
----------------------------------------------------------------
----------------------------------------------------------------
Gesch?ftsf?hrer:
Dipl.-Ing. Andreas Hartmann
Sitz der Gesellschaft: Berlin
Amtsgericht Charlottenburg
HRB 84461

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From retep.meissner at gmail.com  Mon Jun  8 12:31:15 2015
From: retep.meissner at gmail.com (Peter Meissner)
Date: Mon, 8 Jun 2015 12:31:15 +0200
Subject: [R] [R-pkgs] New version of wikipediatrend
Message-ID: <op.xzwp6dyq3euttn@zukd208>


Dear UseRs,


wikipediatrend - a package to retrieve Wikipedia page access statistics -  
has jumped from version 0.2 to 1.1.3 and now is more streamlined, feature  
richer, more tested and comes with a vignette as well as a lot of fun.


packge information: http://cran.rstudio.com/web/packages/wikipediatrend

vignette:            
http://cran.rstudio.com/web/packages/wikipediatrend/vignettes/using-wikipediatrend.html

project page:       https://github.com/petermeissner/wikipediatrend


Best, Peter




NEWS wikipediatrend
==========================================================================

version 1.1.3 // 2015-06-04 ...
--------------------------------------------------------------------------

- modifying vignette to comply with CRAN policies (dropping lines  
installing packages if not present)


version 1.1.2 // 2015-05-23 ...
--------------------------------------------------------------------------

- modifying caching to comply with CRAN policies

- changing default folder of cache file from temp (basename(tempdir())) to  
Rtemp ( tempdir() )


version 1.1.1 // 2015-05-23 ...
--------------------------------------------------------------------------

- adding ghrr as additional repo to comply with CRAN policies

- changing default folder of cache file from home (~) to temp  
(basename(tempdir()))


version 1.1.0 // 2015-05-21 ...
--------------------------------------------------------------------------

- feature: caching has been overhauled

- feature: wp_trend() now tries to guess if page was supplied as title  
with possible special characters or as (url-encoded) URL part and take  
care of  further processing

- bug-fix: special character support of the packages was lousy and  
preventing
the usage of articles of non-standard languages ( - especially on Windows)
   * introduction of the wp_df class to allow for a print.wp_df that
     a) shortens long strings on print
     b) does not use format() (format() causes UTF-8 characters to be  
replaced by "<U+xxxx>" strings (propably only))
   * using a package specific write_utf8_csv() and read_utf8_csv() to be  
able to store and cache data for articles with special character names      
(even under Windows, write.csv() does not allow enforcing a specific  
encoding)

- bug-fix / backward compatibility: with version 1.0.0 old parameters for
wp_trend() were causing errors

- bug-fix: wp_cache_reset() would stop with an error if called twice in a  
row - fixed


version 1.0.0 // 2015-04-01 ...
--------------------------------------------------------------------------

- api-change: option userAgent deleted: the default is to send information  
on
versions of R, wikipediatrend, curl as well as RCurl

- api-change: option requestFrom deleted: the default is to not send the  
header

- feature: wp_trend() now by default caches data retrievals in a temporary  
file

- feature: wp_trend(file="save.csv") now allows to specify a file where
retrievals are stored (this will always add to the already existing data)

- feature: wp_trend() now allows to specify more than one page and/or  
language
at a time. data than will be retrieved for every combination of
page-language and date

- feature: caching system is persistant wp_cache_file() will report file  
used for
caching; wp_cache_reset() will reset cache; wp_cache_load() will return its
content as data.frame()

- feature: while wp_trend() now (invisibly) returns only data from the  
current
request at hand the new function wp_cache() will retrieve data from cache  
files
(by default / if no file name is specified it retrieves data from  
.wp_trend_cache)

- api-change: the data returned by wp_trend(), cached in cache-file,  
retrieved by
wp_cache() does consist of more variables: date, count, project, title,
rank, month

- feature: testthat tests now check base functionality of the package

- bug-fix: non-existing page views for a month have led to an error, fixed.

- bug-fix: wp_trend() now checks date inputs better for logical  
inconsistencies


version 0.2.0 // 2014-11-01 ...
--------------------------------------------------------------------------

- first puplication on CRAN

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From sarah.goslee at gmail.com  Mon Jun  8 17:03:57 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 8 Jun 2015 11:03:57 -0400
Subject: [R] Blank spaces are replaced by period in read.csv,
 I want to replace blacks with an underline
In-Reply-To: <5575731C020000CB0012F178@smtp.medicine.umaryland.edu>
References: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>
	<963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>
	<5574CE8B.3060309@gmail.com>
	<CAF-rFrLU3CLqGB7A9UAgygthnhAtXhvcpAHwg5uuPZQ8TXt5Cg@mail.gmail.com>
	<55757A72.9010605@gmail.com>
	<55756B54020000CB0012F150@smtp.medicine.umaryland.edu>
	<CAM_vjukaktO2Q=XnABzp8WKvwr1f2ROSq+RCoGFvQpocaAqfRw@mail.gmail.com>
	<5575731C020000CB0012F178@smtp.medicine.umaryland.edu>
Message-ID: <CAM_vju=g_cYKr3SPyZDFKzpxu-J89wtenvEW3Y+UHAWGF-aHGg@mail.gmail.com>

I've taken the liberty of copying this back to the list, so that others can
participate in or benefit from the discussion.

On Mon, Jun 8, 2015 at 10:49 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
wrote:

> Sarah,
> I am not sure how I use check.names to replace every space in the names of
> my variables with an underline. Can you show me how to do this? My current
> code is as follows:
>

check.names just tells R not to reformat your column names. If they aren't
already what you want, you'll need to do something else.


> data <- read.csv("C:\\Users\\john\\Dropbox
> (Personal)\\HanlonMatt\\fullgenus3.csv")
>
> The problem I has is that my column names are not unique, e.g., I have
> multiple columns whose column names are (in CSV format):
> X Y, X Y, X Y, X Y
> R reads the names as follows:
> X.Y, X.Y.1, X.Y.2, X.Y.3
> I need to have the names look like:
> X_Y, X_Y.1, X_Y.2, X_Y.3
>

You've been saying that you want to replace every space with an underscore,
but that's not what your example shows. Instead, you want to let R import
the names and add the identifying number (though if you do it yourself you
can get the number to match the column number, which is neater), then
change the FIRST underscore to a period.

I'd import them with check.names=FALSE, then modify them explicitly:


> mynames <- c("x y", "x y", "x y", "x y")
> mynames
[1] "x y" "x y" "x y" "x y"
> mynames <- sub(" ", ".", mynames)
> mynames
[1] "x.y" "x.y" "x.y" "x.y"
> mynames <- paste(mynames, seq_along(mynames), sep="_")
> mynames
[1] "x.y_1" "x.y_2" "x.y_3" "x.y_4"


You could also let R modify them, then use sub() to change the first
underscore to a period and leave the rest alone.

Sarah

	[[alternative HTML version deleted]]


From jsorkin at grecc.umaryland.edu  Mon Jun  8 17:42:05 2015
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 08 Jun 2015 11:42:05 -0400
Subject: [R] Blank spaces are replaced by period in read.csv,
 I want to replace blacks with an underline
In-Reply-To: <CAM_vju=g_cYKr3SPyZDFKzpxu-J89wtenvEW3Y+UHAWGF-aHGg@mail.gmail.com>
References: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>
	<963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>
	<5574CE8B.3060309@gmail.com>
	<CAF-rFrLU3CLqGB7A9UAgygthnhAtXhvcpAHwg5uuPZQ8TXt5Cg@mail.gmail.com>
	<55757A72.9010605@gmail.com>
	<55756B54020000CB0012F150@smtp.medicine.umaryland.edu>
	<CAM_vjukaktO2Q=XnABzp8WKvwr1f2ROSq+RCoGFvQpocaAqfRw@mail.gmail.com>
	<5575731C020000CB0012F178@smtp.medicine.umaryland.edu>
	<CAM_vju=g_cYKr3SPyZDFKzpxu-J89wtenvEW3Y+UHAWGF-aHGg@mail.gmail.com>
Message-ID: <55757FC6020000CB0012F18E@smtp.medicine.umaryland.edu>

Sarah, 
Many, many thanks.
John

> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)


> On Jun 8, 2015, at 11:04 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> 
> I've taken the liberty of copying this back to the list, so that others can participate in or benefit from the discussion.
> 
>> On Mon, Jun 8, 2015 at 10:49 AM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
>> Sarah,
>> I am not sure how I use check.names to replace every space in the names of my variables with an underline. Can you show me how to do this? My current code is as follows:
> 
> check.names just tells R not to reformat your column names. If they aren't already what you want, you'll need to do something else. 
>  
>> data <- read.csv("C:\\Users\\john\\Dropbox (Personal)\\HanlonMatt\\fullgenus3.csv")
>> 
>> The problem I has is that my column names are not unique, e.g., I have multiple columns whose column names are (in CSV format):
>> X Y, X Y, X Y, X Y
>> R reads the names as follows:
>> X.Y, X.Y.1, X.Y.2, X.Y.3
>> I need to have the names look like:
>> X_Y, X_Y.1, X_Y.2, X_Y.3
> 
> You've been saying that you want to replace every space with an underscore, but that's not what your example shows. Instead, you want to let R import the names and add the identifying number (though if you do it yourself you can get the number to match the column number, which is neater), then change the FIRST underscore to a period.
> 
> I'd import them with check.names=FALSE, then modify them explicitly:
> 
> 
> > mynames <- c("x y", "x y", "x y", "x y")
> > mynames
> [1] "x y" "x y" "x y" "x y"
> > mynames <- sub(" ", ".", mynames)
> > mynames
> [1] "x.y" "x.y" "x.y" "x.y"
> > mynames <- paste(mynames, seq_along(mynames), sep="_")
> > mynames
> [1] "x.y_1" "x.y_2" "x.y_3" "x.y_4"
> 
> 
> You could also let R modify them, then use sub() to change the first underscore to a period and leave the rest alone.
> 
> Sarah

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From wdunlap at tibco.com  Mon Jun  8 17:56:07 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 8 Jun 2015 08:56:07 -0700
Subject: [R] Blank spaces are replaced by period in read.csv,
 I want to replace blacks with an underline
In-Reply-To: <CAM_vju=g_cYKr3SPyZDFKzpxu-J89wtenvEW3Y+UHAWGF-aHGg@mail.gmail.com>
References: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>
	<963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>
	<5574CE8B.3060309@gmail.com>
	<CAF-rFrLU3CLqGB7A9UAgygthnhAtXhvcpAHwg5uuPZQ8TXt5Cg@mail.gmail.com>
	<55757A72.9010605@gmail.com>
	<55756B54020000CB0012F150@smtp.medicine.umaryland.edu>
	<CAM_vjukaktO2Q=XnABzp8WKvwr1f2ROSq+RCoGFvQpocaAqfRw@mail.gmail.com>
	<5575731C020000CB0012F178@smtp.medicine.umaryland.edu>
	<CAM_vju=g_cYKr3SPyZDFKzpxu-J89wtenvEW3Y+UHAWGF-aHGg@mail.gmail.com>
Message-ID: <CAF8bMcZxigJ-YYHpq9dOC3_vJ=DHOwVhAQmZjmjOhEkUV+Ew+Q@mail.gmail.com>

   > mynames
   [1] "x.y" "x.y" "x.y" "x.y"
   > mynames <- paste(mynames, seq_along(mynames), sep="_")

In addition, if there were a variety of names in mynames and you
wanted to number each unique name separately you could use ave():

> origNames <- c("X", "Y", "Y", "X", "Z", "X")
> ave(origNames, origNames, FUN=function(x)paste0(x, "_", seq_along(x)))
[1] "X_1" "Y_1" "Y_2" "X_2" "Z_1" "X_3"
> ave(origNames, origNames,
    FUN=function(x)if(length(x)==1) x else paste0(x, "_", seq_along(x)))
[1] "X_1" "Y_1" "Y_2" "X_2" "Z"   "X_3"



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Jun 8, 2015 at 8:03 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:

> I've taken the liberty of copying this back to the list, so that others can
> participate in or benefit from the discussion.
>
> On Mon, Jun 8, 2015 at 10:49 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
> wrote:
>
> > Sarah,
> > I am not sure how I use check.names to replace every space in the names
> of
> > my variables with an underline. Can you show me how to do this? My
> current
> > code is as follows:
> >
>
> check.names just tells R not to reformat your column names. If they aren't
> already what you want, you'll need to do something else.
>
>
> > data <- read.csv("C:\\Users\\john\\Dropbox
> > (Personal)\\HanlonMatt\\fullgenus3.csv")
> >
> > The problem I has is that my column names are not unique, e.g., I have
> > multiple columns whose column names are (in CSV format):
> > X Y, X Y, X Y, X Y
> > R reads the names as follows:
> > X.Y, X.Y.1, X.Y.2, X.Y.3
> > I need to have the names look like:
> > X_Y, X_Y.1, X_Y.2, X_Y.3
> >
>
> You've been saying that you want to replace every space with an underscore,
> but that's not what your example shows. Instead, you want to let R import
> the names and add the identifying number (though if you do it yourself you
> can get the number to match the column number, which is neater), then
> change the FIRST underscore to a period.
>
> I'd import them with check.names=FALSE, then modify them explicitly:
>
>
> > mynames <- c("x y", "x y", "x y", "x y")
> > mynames
> [1] "x y" "x y" "x y" "x y"
> > mynames <- sub(" ", ".", mynames)
> > mynames
> [1] "x.y" "x.y" "x.y" "x.y"
> > mynames <- paste(mynames, seq_along(mynames), sep="_")
> > mynames
> [1] "x.y_1" "x.y_2" "x.y_3" "x.y_4"
>
>
> You could also let R modify them, then use sub() to change the first
> underscore to a period and leave the rest alone.
>
> Sarah
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon Jun  8 18:04:33 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 8 Jun 2015 18:04:33 +0200
Subject: [R] Blank spaces are replaced by period in read.csv,
	I want to replace blacks with an underline
In-Reply-To: <CAM_vju=g_cYKr3SPyZDFKzpxu-J89wtenvEW3Y+UHAWGF-aHGg@mail.gmail.com>
References: <CAF-rFr+0SubR5dRqfVkUibMySaAj9mnHme9S-HWXjFHWV0pT1Q@mail.gmail.com>
	<963E5A11-E630-463B-BD9D-47E18BB6A1CC@txbiomed.org>
	<5574CE8B.3060309@gmail.com>
	<CAF-rFrLU3CLqGB7A9UAgygthnhAtXhvcpAHwg5uuPZQ8TXt5Cg@mail.gmail.com>
	<55757A72.9010605@gmail.com>
	<55756B54020000CB0012F150@smtp.medicine.umaryland.edu>
	<CAM_vjukaktO2Q=XnABzp8WKvwr1f2ROSq+RCoGFvQpocaAqfRw@mail.gmail.com>
	<5575731C020000CB0012F178@smtp.medicine.umaryland.edu>
	<CAM_vju=g_cYKr3SPyZDFKzpxu-J89wtenvEW3Y+UHAWGF-aHGg@mail.gmail.com>
Message-ID: <69C0190D-9A90-4675-B117-C1B48E8FBB3B@gmail.com>


On 08 Jun 2015, at 17:03 , Sarah Goslee <sarah.goslee at gmail.com> wrote:

> 
> I'd import them with check.names=FALSE, then modify them explicitly:
> 
> 
>> mynames <- c("x y", "x y", "x y", "x y")
>> mynames
> [1] "x y" "x y" "x y" "x y"
>> mynames <- sub(" ", ".", mynames)
>> mynames
> [1] "x.y" "x.y" "x.y" "x.y"
>> mynames <- paste(mynames, seq_along(mynames), sep="_")
>> mynames
> [1] "x.y_1" "x.y_2" "x.y_3" "x.y_4"

Didn't he want x_y.1, not x.y_1? Obviously, just switch "." and "_" for that.

A potential improvement (in case not all columns are "x y") is to replace the last bit with make.unique(mynames).

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From curtis.degasperi at gmail.com  Mon Jun  8 20:09:09 2015
From: curtis.degasperi at gmail.com (Curtis DeGasperi)
Date: Mon, 8 Jun 2015 11:09:09 -0700
Subject: [R] web scraping image
Message-ID: <CAApc6sR9juytZc4Pdn5Ci+FBF5A=hWF567gR5wyZ2NKzqf_3jw@mail.gmail.com>

Thanks to Jim's prompting, I think I came up with a fairly painless way to
parse the HTML without having to write any parsing code myself using the
function getHTMLExternalFiles in the XML package. A working version of the
code follows:

## Code to process USGS peak flow data

require(dataRetrieval)
require(XML)

## Need to start with list of gauge ids to process

siteno <- c('12142000','12134500','12149000')

lstas <-length(siteno) #length of locator list

print(paste('Processsing...',siteno[1],' ',siteno[1], sep = ""))

datall <-  readNWISpeak(siteno[1])

for (a in 2:lstas) {
  # Print station being processed
  print(paste('Processsing...',siteno[a], sep = ""))

  dat<-  readNWISpeak(siteno[a])

  datall <- rbind(datall,dat)

}

write.csv(datall, file = "usgs_peaks.csv")

# Retrieve ascii text files and graphics
for (a in 1:lstas) {

  print(paste('Processsing...',siteno[a], sep = ""))

  graphic.url <-
paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=',siteno[a],'&agency_cd=USGS&format=img',
sep = "")
  usgs.img <- getHTMLExternalFiles(graphic.url)
  graphic.img <- paste('http://nwis.waterdata.usgs.gov',usgs.img, sep = "")

  peakfq.url <-
paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=',siteno[a],'&agency_cd=USGS&format=hn2',
sep = "")
  tab.url  <- paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=',siteno[a],'&agency_cd=USGS&format=rdb',
sep = "")

  graphic.fn <- paste('graphic_',siteno[a],'.gif', sep = "")
  peakfq.fn <- paste('peakfq_',siteno[a],'.txt', sep = "")
  tab.fn  <- paste('tab_',siteno[a],'.txt', sep = "")
  download.file(graphic.img,graphic.fn,mode='wb')
  download.file(peakfq.url,peakfq.fn)
  download.file(tab.url,tab.fn)
}

> ------------------------------
>
> Message: 34
> Date: Fri, 5 Jun 2015 08:59:04 +1000
> From: Jim Lemon <drjimlemon at gmail.com>
> To: Curtis DeGasperi <curtis.degasperi at gmail.com>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] web scraping image
> Message-ID:
>         <
CA+8X3fV0aJw+E22JayV1GfM6JR_taZuA5FwGD3T_mfGfQy2nFA at mail.gmail.com>
> Content-Type: text/plain; charset=UTF-8
>
> Hi Chris,
> I don't have the packages you are using, but tracing this indicates
> that the page source contains the relative path of the graphic, in
> this case:
>
> /nwisweb/data/img/USGS.12144500.19581112.20140309..0.peak.pres.gif
>
> and you already have the server URL:
>
> nwis.waterdata.usgs.gov
>
> getting the path out of the page source isn't difficult, just split
> the text at double quotes and get the token following "img src=". If I
> understand the arguments of "download.file" correctly, the path is the
> graphic.fn argument and the server URL is the graphic.url argument. I
> would paste them together and display the result to make sure that it
> matches the image you want. When I did this, the correct image
> appeared in my browser. I'm using Google Chrome, so I don't have to
> prepend the http://
>
> Jim
>
> On Fri, Jun 5, 2015 at 2:31 AM, Curtis DeGasperi
> <curtis.degasperi at gmail.com> wrote:
>> I'm working on a script that downloads data from the USGS NWIS server.
>> dataRetrieval makes it easy to quickly get the data in a neat tabular
>> format, but I was also interested in getting the tabular text files -
>> also fairly easy for me using download.file.
>>
>> However, I'm not skilled enough to work out how to download the nice
>> graphic files that can be produced dynamically from the USGS NWIS
>> server (for example:
>>
http://nwis.waterdata.usgs.gov/nwis/peak?site_no=12144500&agency_cd=USGS&format=img
)
>>
>> My question is how do I get the image from this web page and save it
>> to a local directory? scrapeR returns the information from the page
>> and I suspect this is a possible solution path, but I don't know what
>> the next step is.
>>
>> My code provided below works from a list I've created of USGS flow
>> gauging stations.
>>
>> Curtis
>>
>> ## Code to process USGS daily flow data for high and low flow analysis
>> ## Need to start with list of gauge ids to process
>> ## Can't figure out how to automate download of images
>>
>> require(dataRetrieval)
>> require(data.table)
>> require(scrapeR)
>>
>> df <- read.csv("usgs_stations.csv", header=TRUE)
>>
>> lstas <-length(df$siteno) #length of locator list
>>
>> print(paste('Processsing...',df$name[1],' ',df$siteno[1], sep = ""))
>>
>> datall <-  readNWISpeak(df$siteno[1])
>>
>> for (a in 2:lstas) {
>>   # Print station being processed
>>   print(paste('Processsing...',df$name[a],' ',df$siteno[a], sep = ""))
>>
>>   dat<-  readNWISpeak(df$siteno[a])
>>
>>   datall <- rbind(datall,dat)
>>
>> }
>>
>> write.csv(datall, file = "usgs_peaks.csv")
>>
>> # Retrieve ascii text files and graphics
>>
>> for (a in 1:lstas) {
>>
>>   print(paste('Processsing...',df$name[1],' ',df$siteno[1], sep = ""))
>>
>>   graphic.url <-
>> paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=
',df$siteno[a],'&agency_cd=USGS&format=img',
>> sep = "")
>>   peakfq.url <-
>> paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=
',df$siteno[a],'&agency_cd=USGS&format=hn2',
>> sep = "")
>>   tab.url  <- paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=
',df$siteno[a],'&agency_cd=USGS&format=rdb',
>> sep = "")
>>
>>   graphic.fn <- paste('graphic_',df$siteno[a],'.gif', sep = "")
>>   peakfq.fn <- paste('peakfq_',df$siteno[a],'.txt', sep = "")
>>   tab.fn  <- paste('tab_',df$siteno[a],'.txt', sep = "")
>>
>>   download.file(graphic.url,graphic.fn,mode='wb') # This apparently
>> doesn't work - file is empty
>>   download.file(peakfq.url,peakfq.fn)
>>   download.file(tab.url,tab.fn)
>> }
>>
>> # scrapeR
>> pageSource<-scrape(url="
http://nwis.waterdata.usgs.gov/nwis/peak?site_no=12144500&agency_cd=USGS&format=img
",headers=TRUE,
>> parse=FALSE)
>> page<-scrape(object="pageSource")
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wht_crl at yahoo.com  Mon Jun  8 21:50:44 2015
From: wht_crl at yahoo.com (carol white)
Date: Mon, 8 Jun 2015 19:50:44 +0000 (UTC)
Subject: [R] load a very big .RData - error reading from connection
Message-ID: <1058672396.7435065.1433793044137.JavaMail.yahoo@mail.yahoo.com>

Hi,How is it possible to load a very big .RData that can't be loaded it's very big and the following error msg is displayed

load(".RData")
Error: error reading from connection
Thanks
Carol
?
	[[alternative HTML version deleted]]


From c.danyluck at gmail.com  Mon Jun  8 23:48:37 2015
From: c.danyluck at gmail.com (Chad Danyluck)
Date: Mon, 8 Jun 2015 17:48:37 -0400
Subject: [R] Looping Through List of .csv Files to Work with Subsets of the
	Data
Message-ID: <CA+_f+RFM1q5E_MV4BJUGLR5NwPGSJtMLGahMWiTV8L2Z871-rQ@mail.gmail.com>

Hello,

I want to subset specific rows of data from 80 .csv files and write those
subsets into new .csv files. The data I want to subset starts on a
different row for each original .csv file. I've created variables that
identify which row the subset should start and end on, but I want to loop
through this process and I am not sure what to do. I've attempted to write
the loop below, albeit, much of it is pseudo code. If anyone can provide me
with some tips I'd appreciate it.

#### This data file is used to create the variables where the subsetting
starts and ends for each participant ####
mig.data <- read.csv("/Users/cdanyluck/Documents/Studies/MIG -
Dissertation/Data & Syntax/mig.data.csv")

# These are the variable names for the start and end of each subset of
relevant data (baseline, audio, and free)
participant.ids <- mig.processed.data$participant.id
participant.baseline.start <- mig.processed.data$baseline.row.start
participant.baseline.end <- mig.processed.data$baseline.row.end
participant.audio.start <- mig.processed.data$audio.meditation.row.start
participant.audio.end <- mig.processed.data$audio.meditation.row.end
participant.free.start <- mig.processed.data$free.meditation.row.start
participant.free.end <- mig.processed.data$free.meditation.row.end

# read into a list the individual files from which to subset the data
participant.files <- list.files("/Users/cdanyluck/Documents/Studies/MIG -
Dissertation/Data & Syntax/MIG_RAW DATA & TXT Files/Plain Text Files")

# loop through each participant
for (i in 1:length(participant.files)) {

    # get baseline rows
    results.baseline <-
participant.files[participant.baseline.start[i]:participant.baseline.end[i],]

    # get audio rows
    results.audio
<- participant.files[participant.audio.start[i]:participant.audio.end[i],]

    # get free rows
    results.free <-
participant.files[participant.free.start[i]:participant.free.end[i],]

    # write out participant relevant data
    write.csv(results.baseline, file="baseline[i].csv")
    write.csv(results.audio, file = "audio[i].csv")
    write.csv(results.free, file = "free[i].csv")

}

-- 
Chad M. Danyluck, MA
PhD Candidate, Psychology
University of Toronto



?There is nothing either good or bad but thinking makes it so.? - William
Shakespeare

	[[alternative HTML version deleted]]


From tanasa at gmail.com  Tue Jun  9 00:44:33 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Mon, 8 Jun 2015 15:44:33 -0700
Subject: [R] subsetting a dataframe
Message-ID: <CA+JEM0340Et1JpmH0UTSBT6wY1S+ExuejtYUtt3URNRN_WoDhQ@mail.gmail.com>

Dear all,

would appreciate your suggestions on subsetting a dataframe : please let's
consider an example dataframe df:

dd<-c(1,2,3)
rows<-c("A1","A2","A3")
columns<-c("B1","B2","B3")
numbers <- c(400, 500, 600)
df <- dataframe(dd,rows,columns, numbers)

and a vector : test_rows <-c("A1","A3") ;

how could I subset the dataframe df function of vector test_rows, in such a
way that only the lines of dataframe df (df$rows) that match the elements
of test_rows ("A1" and "A3") are listed ?

thank you very much,

-- bogdan

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Jun  9 01:09:44 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 8 Jun 2015 16:09:44 -0700
Subject: [R] subsetting a dataframe
In-Reply-To: <CA+JEM0340Et1JpmH0UTSBT6wY1S+ExuejtYUtt3URNRN_WoDhQ@mail.gmail.com>
References: <CA+JEM0340Et1JpmH0UTSBT6wY1S+ExuejtYUtt3URNRN_WoDhQ@mail.gmail.com>
Message-ID: <CAF8bMcbw9Op-gducpUuq9tgsakz9y852U0YMyE0bDUE327ps+A@mail.gmail.com>

Use is.element(elements,set), or its equivalent, elements %in% set:

df <- data.frame(dd = c(1, 2, 3),
                 rows = c("A1", "A2", "A3"),
                 columns = c("B1", "B2", "B3"),
                 numbers = c(400, 500, 600))
test_rows <-c("A1","A3")
df[ is.element(df$rows, test_rows), ]
#  dd rows columns numbers
#1  1   A1      B1     400
#3  3   A3      B3     600


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Jun 8, 2015 at 3:44 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:

> Dear all,
>
> would appreciate your suggestions on subsetting a dataframe : please let's
> consider an example dataframe df:
>
> dd<-c(1,2,3)
> rows<-c("A1","A2","A3")
> columns<-c("B1","B2","B3")
> numbers <- c(400, 500, 600)
> df <- dataframe(dd,rows,columns, numbers)
>
> and a vector : test_rows <-c("A1","A3") ;
>
> how could I subset the dataframe df function of vector test_rows, in such a
> way that only the lines of dataframe df (df$rows) that match the elements
> of test_rows ("A1" and "A3") are listed ?
>
> thank you very much,
>
> -- bogdan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Tue Jun  9 02:07:45 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Tue, 9 Jun 2015 00:07:45 +0000
Subject: [R] Looping Through List of .csv Files to Work with Subsets of
 the Data
In-Reply-To: <CA+_f+RFM1q5E_MV4BJUGLR5NwPGSJtMLGahMWiTV8L2Z871-rQ@mail.gmail.com>
References: <CA+_f+RFM1q5E_MV4BJUGLR5NwPGSJtMLGahMWiTV8L2Z871-rQ@mail.gmail.com>
Message-ID: <D19B7676.12D6AA%macqueen1@llnl.gov>

So you have 80 files, one for each participant?

It appears that from each of the 80 files you want to extract three
subsets of rows,
  one set for baseline
  one set for audio
  one set for "free"

What I think I would do, if the above is correct, is create one "master"
file. This file will have eight columns:
(I'll show an example column name, followed by a description)
  id  participant id
  fn   file name for that participant
  srb  start row for baseline
  erb  end row for baseline
  sra  start row for audio
  era  end row for audio
  srf  start row for free
  erf  end row for free

This may be fairly close to what you already have, but I'm not sure.

I would then load the master file into R
  mstf <- read.csv( {the master file} )

Then loop through its rows, and since each row has all the information
necessary to read the participant's individual file and identify which
rows to subset, a loop like this should work.

for (irow in seq(nrow(mstf$id))) {

  id <- mstf$id[irow]
  ## if id is numeric, e.g., 1, 2, 3 ... 80 then I would do this
  ## to ensure that the files sort properly when viewed by the operating
system
  idc <- formatC(id, width=2, flag='0')

  crnt.file <- read.csv( mstf$fn[irow] )

  ## base
  tmp.base <- crnt.file[ mstf$srb[irow]:mstf$erb[irow] , ]
  write.csv(tmp.base, file=paste0('baseline',idc,'.csv')


  ## audio
  tmp.audio <- crnt.file[ mstf$sra[irow]:mstf$era[irow] , ]
  write.csv(tmp.audio, file=paste0('audio',idc,'.csv')



  ## free
  tmp.free <- crnt.file[ mstf$srf[irow]:mstf$erf[irow] , ]
  write.csv(tmp.free, file=paste0('free',idc,'.csv')

}


Obviously, I can't test this. And there may be (likely are!) some typos in
it.

Note that it's not necessary to create variables that identify which row
the subset should start and end on; these are just looked up from the
master file when needed. Similarly, the three respective subsets are
stored in temporary data frames, because they are not (I presume) needed
when the whole thing is done. (if they were needed, then a different
strategy would be more appropriate)

There are different ways to index the loop. I just picked one.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/8/15, 2:48 PM, "Chad Danyluck" <c.danyluck at gmail.com> wrote:

>Hello,
>
>I want to subset specific rows of data from 80 .csv files and write those
>subsets into new .csv files. The data I want to subset starts on a
>different row for each original .csv file. I've created variables that
>identify which row the subset should start and end on, but I want to loop
>through this process and I am not sure what to do. I've attempted to write
>the loop below, albeit, much of it is pseudo code. If anyone can provide
>me
>with some tips I'd appreciate it.
>
>#### This data file is used to create the variables where the subsetting
>starts and ends for each participant ####
>mig.data <- read.csv("/Users/cdanyluck/Documents/Studies/MIG -
>Dissertation/Data & Syntax/mig.data.csv")
>
># These are the variable names for the start and end of each subset of
>relevant data (baseline, audio, and free)
>participant.ids <- mig.processed.data$participant.id
>participant.baseline.start <- mig.processed.data$baseline.row.start
>participant.baseline.end <- mig.processed.data$baseline.row.end
>participant.audio.start <- mig.processed.data$audio.meditation.row.start
>participant.audio.end <- mig.processed.data$audio.meditation.row.end
>participant.free.start <- mig.processed.data$free.meditation.row.start
>participant.free.end <- mig.processed.data$free.meditation.row.end
>
># read into a list the individual files from which to subset the data
>participant.files <- list.files("/Users/cdanyluck/Documents/Studies/MIG -
>Dissertation/Data & Syntax/MIG_RAW DATA & TXT Files/Plain Text Files")
>
># loop through each participant
>for (i in 1:length(participant.files)) {
>
>    # get baseline rows
>    results.baseline <-
>participant.files[participant.baseline.start[i]:participant.baseline.end[i
>],]
>
>    # get audio rows
>    results.audio
><- participant.files[participant.audio.start[i]:participant.audio.end[i],]
>
>    # get free rows
>    results.free <-
>participant.files[participant.free.start[i]:participant.free.end[i],]
>
>    # write out participant relevant data
>    write.csv(results.baseline, file="baseline[i].csv")
>    write.csv(results.audio, file = "audio[i].csv")
>    write.csv(results.free, file = "free[i].csv")
>
>}
>
>-- 
>Chad M. Danyluck, MA
>PhD Candidate, Psychology
>University of Toronto
>
>
>
>?There is nothing either good or bad but thinking makes it so.? - William
>Shakespeare
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From c.danyluck at gmail.com  Tue Jun  9 04:15:42 2015
From: c.danyluck at gmail.com (Chad Danyluck)
Date: Mon, 8 Jun 2015 22:15:42 -0400
Subject: [R] Looping Through List of .csv Files to Work with Subsets of
 the Data
In-Reply-To: <D19B7676.12D6AA%macqueen1@llnl.gov>
References: <CA+_f+RFM1q5E_MV4BJUGLR5NwPGSJtMLGahMWiTV8L2Z871-rQ@mail.gmail.com>
	<D19B7676.12D6AA%macqueen1@llnl.gov>
Message-ID: <CA+_f+RHEjz4xPFbVicW7nOWpwOdQ_mcjZwfHKxEXGi=A0B4Y_A@mail.gmail.com>

Thank you Don.

I've incorporated your suggestions which have helped me to understand how
loops work better than previously. However, the loop gets stuck trying to
read the current file:

mig.processed.data <- read.csv("/Users/cdanyluck/Documents/Studies/MIG -
Dissertation/Data & Syntax/mig.log.data.addition.csv")

## ASSUMPTION: Starting with augmented processedbook and correct
free.meditation.end
#### Read in all data files and Loop through to create new data files
segmented by the rows identified before ####

# get required data
participant.ids <- mig.processed.data$participant.id
participant.baseline.start <- mig.processed.data$baseline.row.start
participant.baseline.end <- mig.processed.data$baseline.row.end
participant.audio.start <- mig.processed.data$audio.meditation.row.start
participant.audio.end <- mig.processed.data$audio.meditation.row.end
participant.free.start <- mig.processed.data$free.meditation.row.start
participant.free.end <- mig.processed.data$free.meditation.row.end

participant.files <- list.files("/Users/cdanyluck/Documents/Studies/MIG -
Dissertation/Data & Syntax/MIG_RAW DATA & TXT Files/Plain Text Files")

for (i in 1:length(participant.files)) {

 id <- participant.files[i]

  ## if id is numeric, e.g., 1, 2, 3 ... 80 then I would do this
  ## to ensure that the files sort properly when viewed by the operating
#system
 idc <- formatC(id, width=3, flag='0')

#current file
  crnt.file[i] <- read.csv( participant.files[i] )

## base
  tmp.base <-
crnt.file[participant.baseline.start:participant.baseline.end, ]
  write.csv(tmp.base, file=paste0('baseline',idc,'.csv'))


  ## audio
  tmp.audio <- crnt.file[participant.audio.start:participant.audio.end, ]
  write.csv(tmp.audio, file=paste0('audio',idc,'.csv'))



  ## free
  tmp.free <- crnt.file[participant.free.start:participant.free.end, ]
  write.csv(tmp.free, file=paste0('free',idc,'.csv'))

}

The error message reads:

Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") : cannot open file '103.csv': No such file or directory

So it seems to be calling the first file in the list but getting stuck. Any
suggestions?

Best,

Chad

On Mon, Jun 8, 2015 at 8:07 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> So you have 80 files, one for each participant?
>
> It appears that from each of the 80 files you want to extract three
> subsets of rows,
>   one set for baseline
>   one set for audio
>   one set for "free"
>
> What I think I would do, if the above is correct, is create one "master"
> file. This file will have eight columns:
> (I'll show an example column name, followed by a description)
>   id  participant id
>   fn   file name for that participant
>   srb  start row for baseline
>   erb  end row for baseline
>   sra  start row for audio
>   era  end row for audio
>   srf  start row for free
>   erf  end row for free
>
> This may be fairly close to what you already have, but I'm not sure.
>
> I would then load the master file into R
>   mstf <- read.csv( {the master file} )
>
> Then loop through its rows, and since each row has all the information
> necessary to read the participant's individual file and identify which
> rows to subset, a loop like this should work.
>
> for (irow in seq(nrow(mstf$id))) {
>
>   id <- mstf$id[irow]
>   ## if id is numeric, e.g., 1, 2, 3 ... 80 then I would do this
>   ## to ensure that the files sort properly when viewed by the operating
> system
>   idc <- formatC(id, width=2, flag='0')
>
>   crnt.file <- read.csv( mstf$fn[irow] )
>
>   ## base
>   tmp.base <- crnt.file[ mstf$srb[irow]:mstf$erb[irow] , ]
>   write.csv(tmp.base, file=paste0('baseline',idc,'.csv')
>
>
>   ## audio
>   tmp.audio <- crnt.file[ mstf$sra[irow]:mstf$era[irow] , ]
>   write.csv(tmp.audio, file=paste0('audio',idc,'.csv')
>
>
>
>   ## free
>   tmp.free <- crnt.file[ mstf$srf[irow]:mstf$erf[irow] , ]
>   write.csv(tmp.free, file=paste0('free',idc,'.csv')
>
> }
>
>
> Obviously, I can't test this. And there may be (likely are!) some typos in
> it.
>
> Note that it's not necessary to create variables that identify which row
> the subset should start and end on; these are just looked up from the
> master file when needed. Similarly, the three respective subsets are
> stored in temporary data frames, because they are not (I presume) needed
> when the whole thing is done. (if they were needed, then a different
> strategy would be more appropriate)
>
> There are different ways to index the loop. I just picked one.
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 6/8/15, 2:48 PM, "Chad Danyluck" <c.danyluck at gmail.com> wrote:
>
> >Hello,
> >
> >I want to subset specific rows of data from 80 .csv files and write those
> >subsets into new .csv files. The data I want to subset starts on a
> >different row for each original .csv file. I've created variables that
> >identify which row the subset should start and end on, but I want to loop
> >through this process and I am not sure what to do. I've attempted to write
> >the loop below, albeit, much of it is pseudo code. If anyone can provide
> >me
> >with some tips I'd appreciate it.
> >
> >#### This data file is used to create the variables where the subsetting
> >starts and ends for each participant ####
> >mig.data <- read.csv("/Users/cdanyluck/Documents/Studies/MIG -
> >Dissertation/Data & Syntax/mig.data.csv")
> >
> ># These are the variable names for the start and end of each subset of
> >relevant data (baseline, audio, and free)
> >participant.ids <- mig.processed.data$participant.id
> >participant.baseline.start <- mig.processed.data$baseline.row.start
> >participant.baseline.end <- mig.processed.data$baseline.row.end
> >participant.audio.start <- mig.processed.data$audio.meditation.row.start
> >participant.audio.end <- mig.processed.data$audio.meditation.row.end
> >participant.free.start <- mig.processed.data$free.meditation.row.start
> >participant.free.end <- mig.processed.data$free.meditation.row.end
> >
> ># read into a list the individual files from which to subset the data
> >participant.files <- list.files("/Users/cdanyluck/Documents/Studies/MIG -
> >Dissertation/Data & Syntax/MIG_RAW DATA & TXT Files/Plain Text Files")
> >
> ># loop through each participant
> >for (i in 1:length(participant.files)) {
> >
> >    # get baseline rows
> >    results.baseline <-
> >participant.files[participant.baseline.start[i]:participant.baseline.end[i
> >],]
> >
> >    # get audio rows
> >    results.audio
> ><- participant.files[participant.audio.start[i]:participant.audio.end[i],]
> >
> >    # get free rows
> >    results.free <-
> >participant.files[participant.free.start[i]:participant.free.end[i],]
> >
> >    # write out participant relevant data
> >    write.csv(results.baseline, file="baseline[i].csv")
> >    write.csv(results.audio, file = "audio[i].csv")
> >    write.csv(results.free, file = "free[i].csv")
> >
> >}
> >
> >--
> >Chad M. Danyluck, MA
> >PhD Candidate, Psychology
> >University of Toronto
> >
> >
> >
> >?There is nothing either good or bad but thinking makes it so.? - William
> >Shakespeare
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Chad M. Danyluck, MA
PhD Candidate, Psychology
University of Toronto



?There is nothing either good or bad but thinking makes it so.? - William
Shakespeare

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Jun  9 04:28:03 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 8 Jun 2015 19:28:03 -0700
Subject: [R] Looping Through List of .csv Files to Work with Subsets of
 the Data
In-Reply-To: <CA+_f+RHEjz4xPFbVicW7nOWpwOdQ_mcjZwfHKxEXGi=A0B4Y_A@mail.gmail.com>
References: <CA+_f+RFM1q5E_MV4BJUGLR5NwPGSJtMLGahMWiTV8L2Z871-rQ@mail.gmail.com>
	<D19B7676.12D6AA%macqueen1@llnl.gov>
	<CA+_f+RHEjz4xPFbVicW7nOWpwOdQ_mcjZwfHKxEXGi=A0B4Y_A@mail.gmail.com>
Message-ID: <CAF8bMcYuE_CHC8grf2AdUuZbehRjmvE8EERGrZmVv3Gx0FbNcw@mail.gmail.com>

   participant.files <- list.files("/Users/cdanyluck/Documents/Studies/MIG -
Dissertation/Data & Syntax/MIG_RAW DATA & TXT Files/Plain Text Files")

Try adding the argument full.names=TRUE to that call to list.files().

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Jun 8, 2015 at 7:15 PM, Chad Danyluck <c.danyluck at gmail.com> wrote:

> Thank you Don.
>
> I've incorporated your suggestions which have helped me to understand how
> loops work better than previously. However, the loop gets stuck trying to
> read the current file:
>
> mig.processed.data <- read.csv("/Users/cdanyluck/Documents/Studies/MIG -
> Dissertation/Data & Syntax/mig.log.data.addition.csv")
>
> ## ASSUMPTION: Starting with augmented processedbook and correct
> free.meditation.end
> #### Read in all data files and Loop through to create new data files
> segmented by the rows identified before ####
>
> # get required data
> participant.ids <- mig.processed.data$participant.id
> participant.baseline.start <- mig.processed.data$baseline.row.start
> participant.baseline.end <- mig.processed.data$baseline.row.end
> participant.audio.start <- mig.processed.data$audio.meditation.row.start
> participant.audio.end <- mig.processed.data$audio.meditation.row.end
> participant.free.start <- mig.processed.data$free.meditation.row.start
> participant.free.end <- mig.processed.data$free.meditation.row.end
>
> participant.files <- list.files("/Users/cdanyluck/Documents/Studies/MIG -
> Dissertation/Data & Syntax/MIG_RAW DATA & TXT Files/Plain Text Files")
>
> for (i in 1:length(participant.files)) {
>
>  id <- participant.files[i]
>
>   ## if id is numeric, e.g., 1, 2, 3 ... 80 then I would do this
>   ## to ensure that the files sort properly when viewed by the operating
> #system
>  idc <- formatC(id, width=3, flag='0')
>
> #current file
>   crnt.file[i] <- read.csv( participant.files[i] )
>
> ## base
>   tmp.base <-
> crnt.file[participant.baseline.start:participant.baseline.end, ]
>   write.csv(tmp.base, file=paste0('baseline',idc,'.csv'))
>
>
>   ## audio
>   tmp.audio <- crnt.file[participant.audio.start:participant.audio.end, ]
>   write.csv(tmp.audio, file=paste0('audio',idc,'.csv'))
>
>
>
>   ## free
>   tmp.free <- crnt.file[participant.free.start:participant.free.end, ]
>   write.csv(tmp.free, file=paste0('free',idc,'.csv'))
>
> }
>
> The error message reads:
>
> Error in file(file, "rt") : cannot open the connection
> In addition: Warning message:
> In file(file, "rt") : cannot open file '103.csv': No such file or directory
>
> So it seems to be calling the first file in the list but getting stuck. Any
> suggestions?
>
> Best,
>
> Chad
>
> On Mon, Jun 8, 2015 at 8:07 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>
> > So you have 80 files, one for each participant?
> >
> > It appears that from each of the 80 files you want to extract three
> > subsets of rows,
> >   one set for baseline
> >   one set for audio
> >   one set for "free"
> >
> > What I think I would do, if the above is correct, is create one "master"
> > file. This file will have eight columns:
> > (I'll show an example column name, followed by a description)
> >   id  participant id
> >   fn   file name for that participant
> >   srb  start row for baseline
> >   erb  end row for baseline
> >   sra  start row for audio
> >   era  end row for audio
> >   srf  start row for free
> >   erf  end row for free
> >
> > This may be fairly close to what you already have, but I'm not sure.
> >
> > I would then load the master file into R
> >   mstf <- read.csv( {the master file} )
> >
> > Then loop through its rows, and since each row has all the information
> > necessary to read the participant's individual file and identify which
> > rows to subset, a loop like this should work.
> >
> > for (irow in seq(nrow(mstf$id))) {
> >
> >   id <- mstf$id[irow]
> >   ## if id is numeric, e.g., 1, 2, 3 ... 80 then I would do this
> >   ## to ensure that the files sort properly when viewed by the operating
> > system
> >   idc <- formatC(id, width=2, flag='0')
> >
> >   crnt.file <- read.csv( mstf$fn[irow] )
> >
> >   ## base
> >   tmp.base <- crnt.file[ mstf$srb[irow]:mstf$erb[irow] , ]
> >   write.csv(tmp.base, file=paste0('baseline',idc,'.csv')
> >
> >
> >   ## audio
> >   tmp.audio <- crnt.file[ mstf$sra[irow]:mstf$era[irow] , ]
> >   write.csv(tmp.audio, file=paste0('audio',idc,'.csv')
> >
> >
> >
> >   ## free
> >   tmp.free <- crnt.file[ mstf$srf[irow]:mstf$erf[irow] , ]
> >   write.csv(tmp.free, file=paste0('free',idc,'.csv')
> >
> > }
> >
> >
> > Obviously, I can't test this. And there may be (likely are!) some typos
> in
> > it.
> >
> > Note that it's not necessary to create variables that identify which row
> > the subset should start and end on; these are just looked up from the
> > master file when needed. Similarly, the three respective subsets are
> > stored in temporary data frames, because they are not (I presume) needed
> > when the whole thing is done. (if they were needed, then a different
> > strategy would be more appropriate)
> >
> > There are different ways to index the loop. I just picked one.
> >
> > --
> > Don MacQueen
> >
> > Lawrence Livermore National Laboratory
> > 7000 East Ave., L-627
> > Livermore, CA 94550
> > 925-423-1062
> >
> >
> >
> >
> >
> > On 6/8/15, 2:48 PM, "Chad Danyluck" <c.danyluck at gmail.com> wrote:
> >
> > >Hello,
> > >
> > >I want to subset specific rows of data from 80 .csv files and write
> those
> > >subsets into new .csv files. The data I want to subset starts on a
> > >different row for each original .csv file. I've created variables that
> > >identify which row the subset should start and end on, but I want to
> loop
> > >through this process and I am not sure what to do. I've attempted to
> write
> > >the loop below, albeit, much of it is pseudo code. If anyone can provide
> > >me
> > >with some tips I'd appreciate it.
> > >
> > >#### This data file is used to create the variables where the subsetting
> > >starts and ends for each participant ####
> > >mig.data <- read.csv("/Users/cdanyluck/Documents/Studies/MIG -
> > >Dissertation/Data & Syntax/mig.data.csv")
> > >
> > ># These are the variable names for the start and end of each subset of
> > >relevant data (baseline, audio, and free)
> > >participant.ids <- mig.processed.data$participant.id
> > >participant.baseline.start <- mig.processed.data$baseline.row.start
> > >participant.baseline.end <- mig.processed.data$baseline.row.end
> > >participant.audio.start <- mig.processed.data$audio.meditation.row.start
> > >participant.audio.end <- mig.processed.data$audio.meditation.row.end
> > >participant.free.start <- mig.processed.data$free.meditation.row.start
> > >participant.free.end <- mig.processed.data$free.meditation.row.end
> > >
> > ># read into a list the individual files from which to subset the data
> > >participant.files <- list.files("/Users/cdanyluck/Documents/Studies/MIG
> -
> > >Dissertation/Data & Syntax/MIG_RAW DATA & TXT Files/Plain Text Files")
> > >
> > ># loop through each participant
> > >for (i in 1:length(participant.files)) {
> > >
> > >    # get baseline rows
> > >    results.baseline <-
> >
> >participant.files[participant.baseline.start[i]:participant.baseline.end[i
> > >],]
> > >
> > >    # get audio rows
> > >    results.audio
> > ><-
> participant.files[participant.audio.start[i]:participant.audio.end[i],]
> > >
> > >    # get free rows
> > >    results.free <-
> > >participant.files[participant.free.start[i]:participant.free.end[i],]
> > >
> > >    # write out participant relevant data
> > >    write.csv(results.baseline, file="baseline[i].csv")
> > >    write.csv(results.audio, file = "audio[i].csv")
> > >    write.csv(results.free, file = "free[i].csv")
> > >
> > >}
> > >
> > >--
> > >Chad M. Danyluck, MA
> > >PhD Candidate, Psychology
> > >University of Toronto
> > >
> > >
> > >
> > >?There is nothing either good or bad but thinking makes it so.? -
> William
> > >Shakespeare
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>
> --
> Chad M. Danyluck, MA
> PhD Candidate, Psychology
> University of Toronto
>
>
>
> ?There is nothing either good or bad but thinking makes it so.? - William
> Shakespeare
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Thomas.Chesney at nottingham.ac.uk  Tue Jun  9 11:11:44 2015
From: Thomas.Chesney at nottingham.ac.uk (Thomas Chesney)
Date: Tue, 9 Jun 2015 10:11:44 +0100
Subject: [R] Unordered combinations with repetition
Message-ID: <5EAA21940C65214F9C11DA5FBBC14F0B3FD89C29F9@EXCHANGE2.ad.nottingham.ac.uk>

Does anyone know of a function that will return all unordered combinations of n elements from a list with repetition?

The combs function in caTools will do this without repetition:

combs(1:2, 2)

     [,1] [,2]
[1,]    1    2

What I'd like is:

1 1
1 2
2 2

Thank you,

Thomas Chesney



This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please send it back to me, and immediately delete it. 

Please do not use, copy or disclose the information contained in this
message or in any attachment.  Any views or opinions expressed by the
author of this email do not necessarily reflect the views of the
University of Nottingham.

This message has been checked for viruses but the contents of an
attachment may still contain software viruses which could damage your
computer system, you are advised to perform your own checks. Email
communications with the University of Nottingham may be monitored as
permitted by UK legislation.


From nicholas.wray at ntlworld.com  Tue Jun  9 11:52:40 2015
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Tue, 9 Jun 2015 10:52:40 +0100
Subject: [R] Unordered combinations with repetition
In-Reply-To: <5EAA21940C65214F9C11DA5FBBC14F0B3FD89C29F9@EXCHANGE2.ad.nottingham.ac.uk>
References: <5EAA21940C65214F9C11DA5FBBC14F0B3FD89C29F9@EXCHANGE2.ad.nottingham.ac.uk>
Message-ID: <CALcakBbs9+hrgMQ4O-SBf53px5OgB8pCfWruWEhXuY2sengSNA@mail.gmail.com>

You could try expand.grid -- you'd prob need to modify what's beneath

*a=c(0,1,2)*

*b=c(0,1)*

*c=c(0,1)*

*y<-list()*

*y[[1]]<-a*

*y[[2]]<-b*

*y[[3]]<-c*

*expand.grid(y)*

This code gives all combinations


On 9 June 2015 at 10:11, Thomas Chesney <Thomas.Chesney at nottingham.ac.uk>
wrote:

> Does anyone know of a function that will return all unordered combinations
> of n elements from a list with repetition?
>
> The combs function in caTools will do this without repetition:
>
> combs(1:2, 2)
>
>      [,1] [,2]
> [1,]    1    2
>
> What I'd like is:
>
> 1 1
> 1 2
> 2 2
>
> Thank you,
>
> Thomas Chesney
>
>
>
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please send it back to me, and immediately delete it.
>
> Please do not use, copy or disclose the information contained in this
> message or in any attachment.  Any views or opinions expressed by the
> author of this email do not necessarily reflect the views of the
> University of Nottingham.
>
> This message has been checked for viruses but the contents of an
> attachment may still contain software viruses which could damage your
> computer system, you are advised to perform your own checks. Email
> communications with the University of Nottingham may be monitored as
> permitted by UK legislation.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Thomas.Chesney at nottingham.ac.uk  Tue Jun  9 12:18:46 2015
From: Thomas.Chesney at nottingham.ac.uk (Thomas Chesney)
Date: Tue, 9 Jun 2015 11:18:46 +0100
Subject: [R] Unordered combinations with repetition
In-Reply-To: <CALcakBbs9+hrgMQ4O-SBf53px5OgB8pCfWruWEhXuY2sengSNA@mail.gmail.com>
References: <5EAA21940C65214F9C11DA5FBBC14F0B3FD89C29F9@EXCHANGE2.ad.nottingham.ac.uk>,
	<CALcakBbs9+hrgMQ4O-SBf53px5OgB8pCfWruWEhXuY2sengSNA@mail.gmail.com>
Message-ID: <5EAA21940C65214F9C11DA5FBBC14F0B3FD89C29FC@EXCHANGE2.ad.nottingham.ac.uk>

Thank you Nicholas.

I've found that Urnsamples in the prob package does it too:

urnsamples(1:2, size = 2, replace = TRUE, ordered = FALSE)

Thomas
________________________________________
From: WRAY NICHOLAS [nicholas.wray at ntlworld.com]
Sent: Tuesday, June 09, 2015 10:52 AM
To: Thomas Chesney
Cc: r-help at r-project.org
Subject: Re: [R] Unordered combinations with repetition

You could try expand.grid -- you'd prob need to modify what's beneath
a=c(0,1,2)
b=c(0,1)
c=c(0,1)
y<-list()
y[[1]]<-a
y[[2]]<-b
y[[3]]<-c
expand.grid(y)
This code gives all combinations


On 9 June 2015 at 10:11, Thomas Chesney <Thomas.Chesney at nottingham.ac.uk<mailto:Thomas.Chesney at nottingham.ac.uk>> wrote:
Does anyone know of a function that will return all unordered combinations of n elements from a list with repetition?

The combs function in caTools will do this without repetition:

combs(1:2, 2)

     [,1] [,2]
[1,]    1    2

What I'd like is:

1 1
1 2
2 2

Thank you,

Thomas Chesney



This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please send it back to me, and immediately delete it.

Please do not use, copy or disclose the information contained in this
message or in any attachment.  Any views or opinions expressed by the
author of this email do not necessarily reflect the views of the
University of Nottingham.

This message has been checked for viruses but the contents of an
attachment may still contain software viruses which could damage your
computer system, you are advised to perform your own checks. Email
communications with the University of Nottingham may be monitored as
permitted by UK legislation.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please send it back to me, and immediately delete it. 

Please do not use, copy or disclose the information contained in this
message or in any attachment.  Any views or opinions expressed by the
author of this email do not necessarily reflect the views of the
University of Nottingham.

This message has been checked for viruses but the contents of an
attachment may still contain software viruses which could damage your
computer system, you are advised to perform your own checks. Email
communications with the University of Nottingham may be monitored as
permitted by UK legislation.


From drjimlemon at gmail.com  Tue Jun  9 12:22:05 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 9 Jun 2015 20:22:05 +1000
Subject: [R] load a very big .RData - error reading from connection
In-Reply-To: <1058672396.7435065.1433793044137.JavaMail.yahoo@mail.yahoo.com>
References: <1058672396.7435065.1433793044137.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fVZFaEK=48kWKtnS+-t=+EfezSMi53h_moJQ6xm1kT5xQ@mail.gmail.com>

Hi carol,
Have you tried renaming the file to something like "my.RData"? And
just how big is it?

Jim


On Tue, Jun 9, 2015 at 5:50 AM, carol white via R-help
<r-help at r-project.org> wrote:
> Hi,How is it possible to load a very big .RData that can't be loaded it's very big and the following error msg is displayed
>
> load(".RData")
> Error: error reading from connection
> Thanks
> Carol
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From meyners.m at pg.com  Tue Jun  9 13:38:14 2015
From: meyners.m at pg.com (Meyners, Michael)
Date: Tue, 9 Jun 2015 11:38:14 +0000
Subject: [R] mismatch between match and unique causing ecdf (well,
 approxfun) to fail
In-Reply-To: <21877.43491.335871.527297@stat.math.ethz.ch>
References: <AE85F2AAC98B094483D12EEA72230EBD72EAB293@GADC-EMB019.na.pg.com>
	<21877.43491.335871.527297@stat.math.ethz.ch>
Message-ID: <AE85F2AAC98B094483D12EEA72230EBD72EAB866@GADC-EMB019.na.pg.com>

Thanks Martin. 
Yep, I understand it is documented and my code wasn't as it should've been -- the confusion comes from the fact that it worked ok for hundreds of situations that seem very much alike, but one situation breaks. I agree that you typically can't be sure about having only numerical data in the data frame, but I was sure I had by design (numeric results of simulations, so no factors or anything else) and was then sloppy in passing the rows of the data frame to ecdf. So wondering what makes this situation different from all the others I had... 
Anyway, point taken and working solution found, so all fine :-)
Cheers, Michael

> -----Original Message-----
> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
> Sent: Montag, 8. Juni 2015 16:43
> To: Meyners, Michael
> Cc: r-help at r-project.org
> Subject: Re: [R] mismatch between match and unique causing ecdf (well,
> approxfun) to fail
> 
> 
> > Aehm, adding on this: I incorrectly *assumed* without testing that
> rounding would help; it doesn't:
> > ecdf(round(test2,0)) 	# a rounding that is way too rough for my
> application...
> > #Error in xy.coords(x, y) : 'x' and 'y' lengths differ
> >
> > Digging deeper: The initially mentioned call to unique() is not very helpful,
> as test2 is a data frame, so I get what I deserve, an unchanged data frame
> with 1 row. Still, the issue remains and can even be simplified further:
> >
> > > ecdf(data.frame(a=3, b=4))
> > Empirical CDF
> > Call: ecdf(data.frame(a = 3, b = 4))
> >  x[1:2] =      3,      4
> >
> > works ok, but
> >
> > > ecdf(data.frame(a=3, b=3))
> > Error in xy.coords(x, y) : 'x' and 'y' lengths differ
> >
> > doesn't (same for a=b=1 or 2, so likely the same for any a=b).
> > Instead,
> >
> > > ecdf(c(a=3, b=3))
> > Empirical CDF
> > Call: ecdf(c(a = 3, b = 3))
> >  x[1:1] =      3
> >
> > does the trick. From ?ecdf, I get that x should be a numeric vector -
> apparently, my misuse of the function by applying it to a row of a data frame
> (i.e. a data frame with one row). In all my other (dozens of) cases that
> worked ok, though but not for this particular one. A simple unlist() helps:
> 
> You were lucky.   To use a one-row data frame instead of a
> numerical vector will typically *not* work unless ... well, you are lucky.
> 
> No, do *not*  pass data frame rows instead of numeric vectors.
> 
> >
> > > ecdf(unlist(data.frame(a=3, b=3)))
> > Empirical CDF
> > Call: ecdf(unlist(data.frame(a = 3, b = 3)))
> >  x[1:1] =      3
> >
> > Yet, I'm even more confused than before: in my other data, there were
> also duplicated values in the vector (1-row-data frame), and it never caused
> any issue. For this particular example, it does. I must be missing something
> fundamental...
> >
> 
> well.. I'm confused about why you are confused, but if you are thinking
> about passing rows of data frames as numeric vectors, this means you are
> sure that your data frame only contains "classical numbers" (no factors, no
> 'Date's, no...).
> 
> In such a case, transform your data frame to a numerical matrix
> *once* preferably using  data.matrix(<d.fr>) instead of just
> as.matrix(<d.fr>) but in this case it should not matter.
> Then *check* the result and then work with that matrix from then on.
> 
> All other things probably will continue to leave you confused ..
> ;-)
> 
> Martin Maechler,
> ETH Zurich


From shivibhatia at ymail.com  Tue Jun  9 14:01:23 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Tue, 9 Jun 2015 05:01:23 -0700 (PDT)
Subject: [R] Summarizing data based on Date
In-Reply-To: <1433750889045-4708328.post@n4.nabble.com>
References: <1433750889045-4708328.post@n4.nabble.com>
Message-ID: <1433851283695-4708384.post@n4.nabble.com>

Hi Petr 

I researched a lot over the net and R manual as well based on which I
revamped my code and came to the code as:
test$CR_DT <- as.Date(test$CR_DT, '%d-%b-%y')

iii<- aggregate(test$CHG_WT,list(format(test$CR_DT,"%m")),FUN=sum)

However it still gives me the error as below:
Error in Summary.factor(c(1L, 1L, 1L, 3286L, 1646L, 3241L, 1L, 1L, 1307L,  : 
  ?sum? not meaningful for factors. 

If could you guide on how to achieve the desired output. Thanks. 



--
View this message in context: http://r.789695.n4.nabble.com/Summarizing-data-based-on-Date-tp4708328p4708384.html
Sent from the R help mailing list archive at Nabble.com.


From wht_crl at yahoo.com  Tue Jun  9 12:38:14 2015
From: wht_crl at yahoo.com (carol white)
Date: Tue, 9 Jun 2015 10:38:14 +0000 (UTC)
Subject: [R] load a very big .RData - error reading from connection
In-Reply-To: <CA+8X3fVZFaEK=48kWKtnS+-t=+EfezSMi53h_moJQ6xm1kT5xQ@mail.gmail.com>
References: <CA+8X3fVZFaEK=48kWKtnS+-t=+EfezSMi53h_moJQ6xm1kT5xQ@mail.gmail.com>
Message-ID: <1349272455.7867600.1433846294177.JavaMail.yahoo@mail.yahoo.com>

yes and doesn't help.600MB
Thanks
Carol 


     On Tuesday, June 9, 2015 12:22 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
   

 Hi carol,
Have you tried renaming the file to something like "my.RData"? And
just how big is it?

Jim


On Tue, Jun 9, 2015 at 5:50 AM, carol white via R-help
<r-help at r-project.org> wrote:
> Hi,How is it possible to load a very big .RData that can't be loaded it's very big and the following error msg is displayed
>
> load(".RData")
> Error: error reading from connection
> Thanks
> Carol
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Jun  9 16:20:44 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 9 Jun 2015 14:20:44 +0000
Subject: [R] Summarizing data based on Date
In-Reply-To: <1433851283695-4708384.post@n4.nabble.com>
References: <1433750889045-4708328.post@n4.nabble.com>
	<1433851283695-4708384.post@n4.nabble.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6919DE@mb02.ads.tamu.edu>

What does the following command print out?

str(test)

The error message indicates that test$CHG_WT is not numeric.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shivi82
Sent: Tuesday, June 9, 2015 7:01 AM
To: r-help at r-project.org
Subject: Re: [R] Summarizing data based on Date

Hi Petr 

I researched a lot over the net and R manual as well based on which I
revamped my code and came to the code as:
test$CR_DT <- as.Date(test$CR_DT, '%d-%b-%y')

iii<- aggregate(test$CHG_WT,list(format(test$CR_DT,"%m")),FUN=sum)

However it still gives me the error as below:
Error in Summary.factor(c(1L, 1L, 1L, 3286L, 1646L, 3241L, 1L, 1L, 1307L,  : 
  ?sum? not meaningful for factors. 

If could you guide on how to achieve the desired output. Thanks. 



--
View this message in context: http://r.789695.n4.nabble.com/Summarizing-data-based-on-Date-tp4708328p4708384.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From boris.steipe at utoronto.ca  Tue Jun  9 17:44:07 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 9 Jun 2015 11:44:07 -0400
Subject: [R] load a very big .RData - error reading from connection
In-Reply-To: <1349272455.7867600.1433846294177.JavaMail.yahoo@mail.yahoo.com>
References: <CA+8X3fVZFaEK=48kWKtnS+-t=+EfezSMi53h_moJQ6xm1kT5xQ@mail.gmail.com>
	<1349272455.7867600.1433846294177.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <31C27B3C-C020-46D2-B9B2-3766AEBDF8FB@utoronto.ca>

There are several possible reasons and you have really told us nothing that might help isolating the problem. 600 MB is large, but not "very" large. R and your OS should not be expected to have a problem with files of that size. First of all, you'll need to document why you expect this should work in the first place.

- is the file where you think it is?  ?dir
- do you actually have read access? ?file.access
- was the file produced by a program that writes correctly formatted Rdata files?
- does this work with other files that are similarly formatted?

etc.


B.

On Jun 9, 2015, at 6:38 AM, carol white via R-help <r-help at r-project.org> wrote:

> yes and doesn't help.600MB
> Thanks
> Carol 
> 
> 
>     On Tuesday, June 9, 2015 12:22 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> 
> Hi carol,
> Have you tried renaming the file to something like "my.RData"? And
> just how big is it?
> 
> Jim
> 
> 
> On Tue, Jun 9, 2015 at 5:50 AM, carol white via R-help
> <r-help at r-project.org> wrote:
>> Hi,How is it possible to load a very big .RData that can't be loaded it's very big and the following error msg is displayed
>> 
>> load(".RData")
>> Error: error reading from connection
>> Thanks
>> Carol
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Tue Jun  9 17:56:29 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 9 Jun 2015 08:56:29 -0700
Subject: [R] Unordered combinations with repetition
In-Reply-To: <5EAA21940C65214F9C11DA5FBBC14F0B3FD89C29F9@EXCHANGE2.ad.nottingham.ac.uk>
References: <5EAA21940C65214F9C11DA5FBBC14F0B3FD89C29F9@EXCHANGE2.ad.nottingham.ac.uk>
Message-ID: <CAF8bMca7-Pf_8K-gsiq7sENTybiyZdtmN99o-HOL5Ns0WfRTVg@mail.gmail.com>

> combnWithRepetition <- function(n, k) combn(n+k-1, k) - seq(from=0, len=k)
> combnWithRepetition(2, 2)
     [,1] [,2] [,3]
[1,]    1    1    2
[2,]    1    2    2
> combnWithRepetition(3, 2)
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    1    1    1    2    2    3
[2,]    1    2    3    2    3    3



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Jun 9, 2015 at 2:11 AM, Thomas Chesney <
Thomas.Chesney at nottingham.ac.uk> wrote:

> Does anyone know of a function that will return all unordered combinations
> of n elements from a list with repetition?
>
> The combs function in caTools will do this without repetition:
>
> combs(1:2, 2)
>
>      [,1] [,2]
> [1,]    1    2
>
> What I'd like is:
>
> 1 1
> 1 2
> 2 2
>
> Thank you,
>
> Thomas Chesney
>
>
>
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please send it back to me, and immediately delete it.
>
> Please do not use, copy or disclose the information contained in this
> message or in any attachment.  Any views or opinions expressed by the
> author of this email do not necessarily reflect the views of the
> University of Nottingham.
>
> This message has been checked for viruses but the contents of an
> attachment may still contain software viruses which could damage your
> computer system, you are advised to perform your own checks. Email
> communications with the University of Nottingham may be monitored as
> permitted by UK legislation.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From yelin at lbl.gov  Tue Jun  9 18:24:22 2015
From: yelin at lbl.gov (Ye Lin)
Date: Tue, 9 Jun 2015 09:24:22 -0700
Subject: [R] how to reach a txt file like this?
Message-ID: <CAAvu=bk+HFWZT-uRXiBkJKh8v5jZYgjeDHzJkpZ+YPk4jy==JQ@mail.gmail.com>

?Hey All, I have a txt data file that looks like this:

?[{?ID???A???Name":"Tom", "Age":"18"},{?ID???B???Name":"Jim", "Age":"19"}]


?How can I read this into R as a data frame? I have used readLines to read
all the lines but dont know how to deal with column names and inputs.

Thanks for your help!?

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Tue Jun  9 18:42:05 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 9 Jun 2015 08:42:05 -0800
Subject: [R] Summarizing data based on Date
In-Reply-To: <1433851283695-4708384.post@n4.nabble.com>
References: <1433750889045-4708328.post@n4.nabble.com>
Message-ID: <0A74C162CD5.00000404jrkrideau@inbox.com>

Hi,

As David said have a look at str(test). You have a factor in there or else that weird "list(format(test$CR_DT,"%m"))" command in aggregate() is mucking things up.  What is "list(format(test$CR_DT,"%m"))" intended to do?  No ,a quick test says it is mucking something else up and not giving the us the factor problem. 

Here is your sample data and what I think is what you are trying to do. Note the data is supplied in dput() format which is the preferred way to supply sample data to the R-help list.  See http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html for more information.  I used lubridate's dmy() function rather than as.Date() to format the dates.

dat1  <-  structure(list(dd = structure(c(1426204800, 1427760000, 1426377600, 
1426550400, 1426550400, 1426032000, 1426032000, 1426723200), tzone = "UTC", class = c("POSIXct", 
"POSIXt")), wt = c(0, 0, 0, 770, 3.73, 70, 10, 500)), .Names = c("dd", 
"wt"), row.names = c(NA, -8L), class = "data.frame")

str(dat1)

aggregate(dat1$wt, list(dat1$dd), sum)


John Kane
Kingston ON Canada


> -----Original Message-----
> From: shivibhatia at ymail.com
> Sent: Tue, 9 Jun 2015 05:01:23 -0700 (PDT)
> To: r-help at r-project.org
> Subject: Re: [R] Summarizing data based on Date
> 
> Hi Petr
> 
> I researched a lot over the net and R manual as well based on which I
> revamped my code and came to the code as:
> test$CR_DT <- as.Date(test$CR_DT, '%d-%b-%y')
> 
> iii<- aggregate(test$CHG_WT,list(format(test$CR_DT,"%m")),FUN=sum)
> 
> However it still gives me the error as below:
> Error in Summary.factor(c(1L, 1L, 1L, 3286L, 1646L, 3241L, 1L, 1L, 1307L,
> :
>   ?sum? not meaningful for factors.
> 
> If could you guide on how to achieve the desired output. Thanks.
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Summarizing-data-based-on-Date-tp4708328p4708384.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
TRY FREE IM TOOLPACK at http://www.imtoolpack.com/default.aspx?rc=if5
Capture screenshots, upload images, edit and send them to your friends
through IMs, post on Twitter?, Facebook?, MySpace?, LinkedIn? ? FAST!


From wdunlap at tibco.com  Tue Jun  9 18:56:20 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 9 Jun 2015 09:56:20 -0700
Subject: [R] Unordered combinations with repetition
In-Reply-To: <CAF8bMca7-Pf_8K-gsiq7sENTybiyZdtmN99o-HOL5Ns0WfRTVg@mail.gmail.com>
References: <5EAA21940C65214F9C11DA5FBBC14F0B3FD89C29F9@EXCHANGE2.ad.nottingham.ac.uk>
	<CAF8bMca7-Pf_8K-gsiq7sENTybiyZdtmN99o-HOL5Ns0WfRTVg@mail.gmail.com>
Message-ID: <CAF8bMcaYA8ijBTgU8O9id+CjX4AjYkBr-4OwQ1dBqe960V28CA@mail.gmail.com>

That combnWithRepetition (based on combn) can use much
less memory (and time) than the algorithm in prob:::urnsamples.default
with replace=TRUE, ordered=FALSE.  Perhaps urnsamples()
could be updated to use combn instead of unique(as.matrix(expand.grid())).

See the urn chapter in Feller vol. 1.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Jun 9, 2015 at 8:56 AM, William Dunlap <wdunlap at tibco.com> wrote:

> > combnWithRepetition <- function(n, k) combn(n+k-1, k) - seq(from=0,
> len=k)
> > combnWithRepetition(2, 2)
>      [,1] [,2] [,3]
> [1,]    1    1    2
> [2,]    1    2    2
> > combnWithRepetition(3, 2)
>      [,1] [,2] [,3] [,4] [,5] [,6]
> [1,]    1    1    1    2    2    3
> [2,]    1    2    3    2    3    3
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Jun 9, 2015 at 2:11 AM, Thomas Chesney <
> Thomas.Chesney at nottingham.ac.uk> wrote:
>
>> Does anyone know of a function that will return all unordered
>> combinations of n elements from a list with repetition?
>>
>> The combs function in caTools will do this without repetition:
>>
>> combs(1:2, 2)
>>
>>      [,1] [,2]
>> [1,]    1    2
>>
>> What I'd like is:
>>
>> 1 1
>> 1 2
>> 2 2
>>
>> Thank you,
>>
>> Thomas Chesney
>>
>>
>>
>> This message and any attachment are intended solely for the addressee
>> and may contain confidential information. If you have received this
>> message in error, please send it back to me, and immediately delete it.
>>
>> Please do not use, copy or disclose the information contained in this
>> message or in any attachment.  Any views or opinions expressed by the
>> author of this email do not necessarily reflect the views of the
>> University of Nottingham.
>>
>> This message has been checked for viruses but the contents of an
>> attachment may still contain software viruses which could damage your
>> computer system, you are advised to perform your own checks. Email
>> communications with the University of Nottingham may be monitored as
>> permitted by UK legislation.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Tue Jun  9 19:15:46 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 9 Jun 2015 12:15:46 -0500
Subject: [R] how to reach a txt file like this?
In-Reply-To: <CAAvu=bk+HFWZT-uRXiBkJKh8v5jZYgjeDHzJkpZ+YPk4jy==JQ@mail.gmail.com>
References: <CAAvu=bk+HFWZT-uRXiBkJKh8v5jZYgjeDHzJkpZ+YPk4jy==JQ@mail.gmail.com>
Message-ID: <CAAJSdjhpPtz7HtP1YSMj4BdRVO+d99yUZPXQnHmrjoed-ix+Jg@mail.gmail.com>

On Tue, Jun 9, 2015 at 11:24 AM, Ye Lin <yelin at lbl.gov> wrote:

> ?Hey All, I have a txt data file that looks like this:
>
> ?[{?ID???A???Name":"Tom", "Age":"18"},{?ID???B???Name":"Jim", "Age":"19"}]
>
>
> ?How can I read this into R as a data frame? I have used readLines to read
> all the lines but dont know how to deal with column names and inputs.
>

?That looks like a JSON array of objects to me. I would look into
"jsonlite", "rjson", or "RJSONIO" on CRAN. You'll need to review them to
see which best meets your needs.?


>
> Thanks for your help!?
>
>         [[alternative HTML version deleted]]
>

? Please change to plain text. In many cases HTML displays poorly due to
the list trying to change it for you to plain text. And, in that case,
you'll likely be ignored.
?

-- 
Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.

My sister opened a computer store in Hawaii. She sells C shells down by the
seashore.
If someone tell you that nothing is impossible:
Ask him to dribble a football.

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From bob at rudis.net  Mon Jun  8 21:41:15 2015
From: bob at rudis.net (boB Rudis)
Date: Mon, 8 Jun 2015 15:41:15 -0400
Subject: [R] web scraping image
In-Reply-To: <CAApc6sR9juytZc4Pdn5Ci+FBF5A=hWF567gR5wyZ2NKzqf_3jw@mail.gmail.com>
References: <CAApc6sR9juytZc4Pdn5Ci+FBF5A=hWF567gR5wyZ2NKzqf_3jw@mail.gmail.com>
Message-ID: <CAJ4QxaOUS2hUYb=DOTY+8YVn7R_=s9Bg7qN=+5K82PnCK4PCpw@mail.gmail.com>

You can also do it with rvest & httr (but that does involve some "parsing"):

library(httr)
library(rvest)

url <- "http://nwis.waterdata.usgs.gov/nwis/peak?site_no=12144500&agency_cd=USGS&format=img"
html(url) %>%
  html_nodes("img") %>%
  html_attr("src") %>%
  paste0("http://nwis.waterdata.usgs.gov", .) %>%
  GET(write_disk("12144500.gif")) -> status

Very readable and can be made programmatic pretty easily, too. Plus:
avoids direct use of the XML library. Future versions will no doubt
swap xml2 for XML as well.

-Bob


On Mon, Jun 8, 2015 at 2:09 PM, Curtis DeGasperi
<curtis.degasperi at gmail.com> wrote:
> Thanks to Jim's prompting, I think I came up with a fairly painless way to
> parse the HTML without having to write any parsing code myself using the
> function getHTMLExternalFiles in the XML package. A working version of the
> code follows:
>
> ## Code to process USGS peak flow data
>
> require(dataRetrieval)
> require(XML)
>
> ## Need to start with list of gauge ids to process
>
> siteno <- c('12142000','12134500','12149000')
>
> lstas <-length(siteno) #length of locator list
>
> print(paste('Processsing...',siteno[1],' ',siteno[1], sep = ""))
>
> datall <-  readNWISpeak(siteno[1])
>
> for (a in 2:lstas) {
>   # Print station being processed
>   print(paste('Processsing...',siteno[a], sep = ""))
>
>   dat<-  readNWISpeak(siteno[a])
>
>   datall <- rbind(datall,dat)
>
> }
>
> write.csv(datall, file = "usgs_peaks.csv")
>
> # Retrieve ascii text files and graphics
> for (a in 1:lstas) {
>
>   print(paste('Processsing...',siteno[a], sep = ""))
>
>   graphic.url <-
> paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=',siteno[a],'&agency_cd=USGS&format=img',
> sep = "")
>   usgs.img <- getHTMLExternalFiles(graphic.url)
>   graphic.img <- paste('http://nwis.waterdata.usgs.gov',usgs.img, sep = "")
>
>   peakfq.url <-
> paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=',siteno[a],'&agency_cd=USGS&format=hn2',
> sep = "")
>   tab.url  <- paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=',siteno[a],'&agency_cd=USGS&format=rdb',
> sep = "")
>
>   graphic.fn <- paste('graphic_',siteno[a],'.gif', sep = "")
>   peakfq.fn <- paste('peakfq_',siteno[a],'.txt', sep = "")
>   tab.fn  <- paste('tab_',siteno[a],'.txt', sep = "")
>   download.file(graphic.img,graphic.fn,mode='wb')
>   download.file(peakfq.url,peakfq.fn)
>   download.file(tab.url,tab.fn)
> }
>
>> ------------------------------
>>
>> Message: 34
>> Date: Fri, 5 Jun 2015 08:59:04 +1000
>> From: Jim Lemon <drjimlemon at gmail.com>
>> To: Curtis DeGasperi <curtis.degasperi at gmail.com>
>> Cc: r-help mailing list <r-help at r-project.org>
>> Subject: Re: [R] web scraping image
>> Message-ID:
>>         <
> CA+8X3fV0aJw+E22JayV1GfM6JR_taZuA5FwGD3T_mfGfQy2nFA at mail.gmail.com>
>> Content-Type: text/plain; charset=UTF-8
>>
>> Hi Chris,
>> I don't have the packages you are using, but tracing this indicates
>> that the page source contains the relative path of the graphic, in
>> this case:
>>
>> /nwisweb/data/img/USGS.12144500.19581112.20140309..0.peak.pres.gif
>>
>> and you already have the server URL:
>>
>> nwis.waterdata.usgs.gov
>>
>> getting the path out of the page source isn't difficult, just split
>> the text at double quotes and get the token following "img src=". If I
>> understand the arguments of "download.file" correctly, the path is the
>> graphic.fn argument and the server URL is the graphic.url argument. I
>> would paste them together and display the result to make sure that it
>> matches the image you want. When I did this, the correct image
>> appeared in my browser. I'm using Google Chrome, so I don't have to
>> prepend the http://
>>
>> Jim
>>
>> On Fri, Jun 5, 2015 at 2:31 AM, Curtis DeGasperi
>> <curtis.degasperi at gmail.com> wrote:
>>> I'm working on a script that downloads data from the USGS NWIS server.
>>> dataRetrieval makes it easy to quickly get the data in a neat tabular
>>> format, but I was also interested in getting the tabular text files -
>>> also fairly easy for me using download.file.
>>>
>>> However, I'm not skilled enough to work out how to download the nice
>>> graphic files that can be produced dynamically from the USGS NWIS
>>> server (for example:
>>>
> http://nwis.waterdata.usgs.gov/nwis/peak?site_no=12144500&agency_cd=USGS&format=img
> )
>>>
>>> My question is how do I get the image from this web page and save it
>>> to a local directory? scrapeR returns the information from the page
>>> and I suspect this is a possible solution path, but I don't know what
>>> the next step is.
>>>
>>> My code provided below works from a list I've created of USGS flow
>>> gauging stations.
>>>
>>> Curtis
>>>
>>> ## Code to process USGS daily flow data for high and low flow analysis
>>> ## Need to start with list of gauge ids to process
>>> ## Can't figure out how to automate download of images
>>>
>>> require(dataRetrieval)
>>> require(data.table)
>>> require(scrapeR)
>>>
>>> df <- read.csv("usgs_stations.csv", header=TRUE)
>>>
>>> lstas <-length(df$siteno) #length of locator list
>>>
>>> print(paste('Processsing...',df$name[1],' ',df$siteno[1], sep = ""))
>>>
>>> datall <-  readNWISpeak(df$siteno[1])
>>>
>>> for (a in 2:lstas) {
>>>   # Print station being processed
>>>   print(paste('Processsing...',df$name[a],' ',df$siteno[a], sep = ""))
>>>
>>>   dat<-  readNWISpeak(df$siteno[a])
>>>
>>>   datall <- rbind(datall,dat)
>>>
>>> }
>>>
>>> write.csv(datall, file = "usgs_peaks.csv")
>>>
>>> # Retrieve ascii text files and graphics
>>>
>>> for (a in 1:lstas) {
>>>
>>>   print(paste('Processsing...',df$name[1],' ',df$siteno[1], sep = ""))
>>>
>>>   graphic.url <-
>>> paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=
> ',df$siteno[a],'&agency_cd=USGS&format=img',
>>> sep = "")
>>>   peakfq.url <-
>>> paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=
> ',df$siteno[a],'&agency_cd=USGS&format=hn2',
>>> sep = "")
>>>   tab.url  <- paste('http://nwis.waterdata.usgs.gov/nwis/peak?site_no=
> ',df$siteno[a],'&agency_cd=USGS&format=rdb',
>>> sep = "")
>>>
>>>   graphic.fn <- paste('graphic_',df$siteno[a],'.gif', sep = "")
>>>   peakfq.fn <- paste('peakfq_',df$siteno[a],'.txt', sep = "")
>>>   tab.fn  <- paste('tab_',df$siteno[a],'.txt', sep = "")
>>>
>>>   download.file(graphic.url,graphic.fn,mode='wb') # This apparently
>>> doesn't work - file is empty
>>>   download.file(peakfq.url,peakfq.fn)
>>>   download.file(tab.url,tab.fn)
>>> }
>>>
>>> # scrapeR
>>> pageSource<-scrape(url="
> http://nwis.waterdata.usgs.gov/nwis/peak?site_no=12144500&agency_cd=USGS&format=img
> ",headers=TRUE,
>>> parse=FALSE)
>>> page<-scrape(object="pageSource")
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Mon Jun  8 22:59:44 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 8 Jun 2015 20:59:44 +0000
Subject: [R] Cross-over Data with Kenward-Roger correction
References: <695109458.7792923.1433647542770.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <loom.20150608T224714-771@post.gmane.org>

knouri <nouri4 <at> yahoo.com> writes:

> 
> Dear all:for the folowing data, a two-period, two treatment (A=1 vs. B=2)
> cross-over is fitted
> using the folowing SAS code.? 
> data one;

[snip]

> run;
> proc mixed data=one method=reml;
> class Sbj Per Trt;
> ?? model PEF = Per Trt /ddfm=kr;
> ?? repeated Trt / sub=Sbj type=un r;
> ?? lsmeans Trt / cl alpha=0.05;
> ?? estimate 'B vs. A' Trt -1? 1 / alpha=0.1 cl;
> run;

> (where kr option is for Kenward-Roger method).I need to use R to
> reproduce the results similar to what the above SAS code generates.
> I have used several R functions including lme, lmer with no success
> so far.Any advice will be greatly appreciated,Sincerely, Keramat


This is more appropriate for r-sig-mixed-models at r-project.org.
Please post followups there.

The lmerTest and lsmeans packages will probably be useful.

As a statistical point, I don't understand why you can't just
do a paired t-test on these data??

dat <- read.table(header=TRUE,text=
"Sbj Seq Per Trt PEF
1 1 1 1 310
1 1 2 2 270
4 1 1 1 310
4 1 2 2 260
6 1 1 1 370
6 1 2 2 300
7 1 1 1 410
7 1 2 2 390
10 1 1 1 250
10 1 2 2 210
11 1 1 1 380
11 1 2 2 350
14 1 1 1 330
14 1 2 2 365
2 2 1 2 370
2 2 2 1 385
3 2 1 2 310
3 2 2 1 400
5 2 1 2 380
5 2 2 1 410
9 2 1 2 290
9 2 2 1 320
12 2 1 2 260
12 2 2 1 340
13 2 1 2 90
13 2 2 1 220")

library(lmerTest)
library(ggplot2); theme_set(theme_bw())
ggplot(dat,aes(x=Per,y=PEF,colour=factor(Trt)))+geom_point()+
    geom_line(colour="gray",aes(group=Sbj))+
        scale_x_continuous(breaks=c(1,2))
        
m1 <- lmer(PEF~Per+Trt +(Trt|Sbj), data=dat)

## warning about unidentifiability


From rlderickson at gmail.com  Tue Jun  9 01:07:13 2015
From: rlderickson at gmail.com (Ryan Derickson)
Date: Mon, 8 Jun 2015 19:07:13 -0400
Subject: [R] subsetting a dataframe
In-Reply-To: <CA+JEM0340Et1JpmH0UTSBT6wY1S+ExuejtYUtt3URNRN_WoDhQ@mail.gmail.com>
References: <CA+JEM0340Et1JpmH0UTSBT6wY1S+ExuejtYUtt3URNRN_WoDhQ@mail.gmail.com>
Message-ID: <CALSCBYoG7RrE9o1jWTTwnR4MgDpkTC2z6aFZi=toMNqESFfOYQ@mail.gmail.com>

Lots of ways to do this, I use %in% with bracket notation [row, column].
The empty column argument below returns all columns but you could have
conditional logic there as well.

dd[dd$rows %in% test_rows, ]



On Mon, Jun 8, 2015 at 6:44 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:

> Dear all,
>
> would appreciate your suggestions on subsetting a dataframe : please let's
> consider an example dataframe df:
>
> dd<-c(1,2,3)
> rows<-c("A1","A2","A3")
> columns<-c("B1","B2","B3")
> numbers <- c(400, 500, 600)
> df <- dataframe(dd,rows,columns, numbers)
>
> and a vector : test_rows <-c("A1","A3") ;
>
> how could I subset the dataframe df function of vector test_rows, in such a
> way that only the lines of dataframe df (df$rows) that match the elements
> of test_rows ("A1" and "A3") are listed ?
>
> thank you very much,
>
> -- bogdan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From p.jagadish at inrhythm-inc.com  Tue Jun  9 10:40:53 2015
From: p.jagadish at inrhythm-inc.com (jagadishpchary)
Date: Tue, 9 Jun 2015 01:40:53 -0700 (PDT)
Subject: [R] Cross tabulation with top one variable and side as multiple
 variables
Message-ID: <1433839253539-4708379.post@n4.nabble.com>

Hi:

I have a huge data with lot of variables and I need to check the trend
variations from year to year. In order to do so, I have to cross tabulate
the year variable as top (constant) and all the remaining variables as side
(attached the cross tabulation report). I have searched the forums but the
syntax I could find for cross tabulation is between 2 or 3 variables. So i
would request to provide a code which can print the data in the same way as
in the attached.  <http://r.789695.n4.nabble.com/file/n4708379/Untitled.png> 



--
View this message in context: http://r.789695.n4.nabble.com/Cross-tabulation-with-top-one-variable-and-side-as-multiple-variables-tp4708379.html
Sent from the R help mailing list archive at Nabble.com.


From boris.steipe at utoronto.ca  Tue Jun  9 19:20:58 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 9 Jun 2015 13:20:58 -0400
Subject: [R] how to reach a txt file like this?
In-Reply-To: <CAAvu=bk+HFWZT-uRXiBkJKh8v5jZYgjeDHzJkpZ+YPk4jy==JQ@mail.gmail.com>
References: <CAAvu=bk+HFWZT-uRXiBkJKh8v5jZYgjeDHzJkpZ+YPk4jy==JQ@mail.gmail.com>
Message-ID: <A77C8386-4502-405F-BA05-9C2E986380D9@utoronto.ca>

This is (almost) json data (but see NOTE below); there are several packages that deal with json, jsonlite for example.

R > data <- '[{"ID":"A", "Name":"Tom", "Age":"18"},{"ID":"B", "Name":"Jim", "Age":"19"}]'

R > install.packages("jsonlite")
R > library(jsonlite)

R > myDf <- fromJSON(data, simplifyDataFrame=TRUE)
R > str(myDf)
'data.frame':	2 obs. of  3 variables:
 $ ID  : chr  "A" "B"
 $ Name: chr  "Tom" "Jim"
 $ Age : chr  "18" "19"



NOTE: some of the quotation marks in your example are messed up, and some of your commas and colons seem to use an Asian font - i.e. they are UTF, not ASCII. You will need to clean up all the non ASCII characters that are syntactically important, otherwise things break.

Cheers,
Boris


On Jun 9, 2015, at 12:24 PM, Ye Lin <yelin at lbl.gov> wrote:

> ?Hey All, I have a txt data file that looks like this:
> 
> ?[{?ID???A???Name":"Tom", "Age":"18"},{?ID???B???Name":"Jim", "Age":"19"}]
> 
> 
> ?How can I read this into R as a data frame? I have used readLines to read
> all the lines but dont know how to deal with column names and inputs.
> 
> Thanks for your help!?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hannah.hlx at gmail.com  Tue Jun  9 19:39:15 2015
From: hannah.hlx at gmail.com (li li)
Date: Tue, 9 Jun 2015 13:39:15 -0400
Subject: [R] Warning message when using lmer function
Message-ID: <CAHLnndawPxKq9hXwf97H-6QuYUeMFCxOhbZ+aKP0=dvkUrcrww@mail.gmail.com>

I got the following warning message when using the lmer function.
Does anyone know what is the implication? Thanks!

Warning message:
In anova(model, ddf = "lme4") : bytecode version mismatch; using eval


From dwinsemius at comcast.net  Tue Jun  9 19:50:33 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 9 Jun 2015 10:50:33 -0700
Subject: [R] Cross tabulation with top one variable and side as multiple
	variables
In-Reply-To: <1433839253539-4708379.post@n4.nabble.com>
References: <1433839253539-4708379.post@n4.nabble.com>
Message-ID: <C201B4F1-5C8F-4CE4-90E3-6FAE1B5F8E2C@comcast.net>


On Jun 9, 2015, at 1:40 AM, jagadishpchary wrote:

> Hi:
> 
> I have a huge data with lot of variables and I need to check the trend
> variations from year to year. In order to do so, I have to cross tabulate
> the year variable as top (constant) and all the remaining variables as side
> (attached the cross tabulation report). I have searched the forums but the
> syntax I could find for cross tabulation is between 2 or 3 variables. So i
> would request to provide a code which can print the data in the same way as
> in the attached.  <http://r.789695.n4.nabble.com/file/n4708379/Untitled.png> 

I think you will find that people on this list expect you to provide data in the form of text rather than pictures. When I looked at the request there were two routes I considered: 1) combine margin.table with ftable and 2) investigate one of (but not both) of plyr or dply packages.
> 
> 
> View this message in context: http://r.789695.n4.nabble.com/Cross-tabulation-with-top-one-variable-and-side-as-multiple-variables-tp4708379.html
> Sent from the R help mailing list archive at Nabble.com.

Nabble is neither the R help mailing list nor its archive.

Nabble also removes this message from replies. You should read the material about the list.

> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rosita21 at gmail.com  Tue Jun  9 19:36:07 2015
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Tue, 9 Jun 2015 18:36:07 +0100
Subject: [R] graphs, need urgent help (deadline :( )
Message-ID: <10C1B087-6721-44B2-A347-851219672D30@gmail.com>

Hi,

another naive question (i?m pretty sure :( )


I?m trying to plot a multiple line graph:

         region	       sample	       factora	        factorb	       factorc
0.1	10	0.895	0.903	0.378
0.2	10	0.811	0.865	0.688
0.1	20	0.735	0.966	0.611
0.2	20	0.777	0.732	0.653
0.1	30	0.600	0.778	0.694
0.2	30	0.466	174.592	0.461
0.1	40	0.446	0.432	0.693
0.2	40	0.392	0.294	0.686



The first column should be the independent variable, the second should compute a bold line for sample(10) and dash line for sample 20.
The others variables are outcomes for each of the first scenarios, and so it should: the 3rd, 4th and 5th columns should be blue, red and green respectively. 


Resume :)

I should have a graph, in the x-axe should have the region and in the y axe, the factor.
Lines:
	1 - blue and bold for region 0.1, sample 10 and factor a
	2 - blue and dash for region 0.2, sample 10 and factor a
	3 - red and bold for region 0.1, sample 10 and factor b
	4 - red and dash for region 0.2, sample 10 and factor b
	5 - green and bold for region 0.1, sample 10 and factor c
	6 - green and dash for region 0.2, sample 10 and factor c

nonetheless the independent variable is nominal, I should plot a line graph.

Can anyone help me please?
I have my file as a cvs file, so I first read that file (that I know how to do :)).

But I have it in that format.

Best,
RO



Atenciosamente,
Rosa Oliveira

-- 
____________________________________________________________________________


Rosa Celeste dos Santos Oliveira, 

E-mail: rosita21 at gmail.com
Tlm: +351 939355143 
Linkedin: https://pt.linkedin.com/in/rosacsoliveira
____________________________________________________________________________
"Many admire, few know"
Hippocrates


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Tue Jun  9 20:39:57 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 09 Jun 2015 11:39:57 -0700
Subject: [R] Cross tabulation with top one variable and side as multiple
	variables
In-Reply-To: <1433839253539-4708379.post@n4.nabble.com>
References: <1433839253539-4708379.post@n4.nabble.com>
Message-ID: <64F3635C-858D-4B94-A7EA-F852239C4DF2@dcn.davis.CA.us>

There are two issues here... calculation and presentation. The table function from base R can work with many variables. If your data set is so large that you have problems with memory then you could investigate data.table or sqldf packages, which perform the computations but do not present the data in cross tabulation form. You could use table or perhaps the tables package to render the data into the desired form.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 9, 2015 1:40:53 AM PDT, jagadishpchary <p.jagadish at inrhythm-inc.com> wrote:
>Hi:
>
>I have a huge data with lot of variables and I need to check the trend
>variations from year to year. In order to do so, I have to cross
>tabulate
>the year variable as top (constant) and all the remaining variables as
>side
>(attached the cross tabulation report). I have searched the forums but
>the
>syntax I could find for cross tabulation is between 2 or 3 variables.
>So i
>would request to provide a code which can print the data in the same
>way as
>in the attached. 
><http://r.789695.n4.nabble.com/file/n4708379/Untitled.png> 
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Cross-tabulation-with-top-one-variable-and-side-as-multiple-variables-tp4708379.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From hannah.hlx at gmail.com  Tue Jun  9 21:57:34 2015
From: hannah.hlx at gmail.com (li li)
Date: Tue, 9 Jun 2015 15:57:34 -0400
Subject: [R] Different random intercepts but same random slope for groups
Message-ID: <CAHLnndZ4OOuXXkTM=Ga3fNByK=+zyrC36RUvM_vj8A55qrH+gA@mail.gmail.com>

Hi all,
  I'd like to fit a random intercept and random slope model. In my
data, there are three groups. I want to have different random
intercept for each group but the same random slope effect for all
three groups. I used the following R command.
However, there seems to be some problem. Any suggestions?



mod2 <- lmer(result  ~ group*time+(0+group1+ group2 +
group3+time|lot), na.action=na.omit, data=alldata)

> summary(mod2)
Model is not identifiable...
summary from lme4 is returned
some computational error has occurred in lmerTest
Linear mixed model fit by REML ['merModLmerTest']
Formula: result ~ group * time + (0 + group1 + group2 + group3 + time |
    lot)
   Data: alldata

REML criterion at convergence: 807.9

Scaled residuals:
    Min      1Q  Median      3Q     Max
-3.0112 -0.3364  0.0425  0.2903  3.2017

Random effects:
 Groups   Name     Variance Std.Dev. Corr
 lot      group1   0.00000 0.000
          group2   86.20156 9.284      NaN
          group3 55.91479 7.478      NaN  0.06
          time      0.02855 0.169      NaN -0.99  0.10
 Residual          39.91968 6.318
Number of obs: 119, groups:  lot, 15

Fixed effects:
                            Estimate Std. Error t value
(Intercept)                 100.1566     2.5108   39.89
group  group2        -2.9707     3.7490   -0.79
group  group3           -0.0717     2.8144   -0.03
time                         -0.1346     0.1780   -0.76
group  group2 :time   0.1450     0.2939    0.49
group  group3:time        0.1663     0.2152    0.77

Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.147314 (tol = 0.002, component 2)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge: degenerate  Hessian with 2 negative eigenvalues


From ramiro at precisionbioassay.com  Tue Jun  9 22:22:01 2015
From: ramiro at precisionbioassay.com (Ramiro Barrantes)
Date: Tue, 9 Jun 2015 20:22:01 +0000
Subject: [R] more complex by with data.table???
Message-ID: <C7338A7EFF31BB4D831BB06C00887789B2F91594@MBX023-W1-CA-2.exch023.domain.local>

Hello,

I am trying to do something that I am able to do with the "by" function within data.frame but can't figure out how to achieve with data.table.

Consider

dt<-data.table(name=c(rep("a",5),rep("b",6)),var1=0:10,var2=20:30,var3=40:50)
myFunction <- function(x) { mean(x) }

I am aware that I can do something like:

dt[, .(meanVar1=myFunction(var1)) ,by=.(name)]

but how could I do the equivalent of:

df<-data.frame(name=c(rep("a",5),rep("b",6)),var1=0:10,var2=20:30,var3=40:50)
myFunction <- function(x) { mean(x) }

columnNames <- c("var1","var2","var3")
result <- by(df, df$name, function(x) {
   output <- c()
   for(col in columnNames) {
     output[col] <- myFunction(x[,col])
   }
  output
})
do.call(rbind,result)

Thanks in advance,
Ramiro

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Jun  9 22:49:27 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 9 Jun 2015 22:49:27 +0200
Subject: [R] Different random intercepts but same random slope for groups
In-Reply-To: <CAHLnndZ4OOuXXkTM=Ga3fNByK=+zyrC36RUvM_vj8A55qrH+gA@mail.gmail.com>
References: <CAHLnndZ4OOuXXkTM=Ga3fNByK=+zyrC36RUvM_vj8A55qrH+gA@mail.gmail.com>
Message-ID: <CAJuCY5xPhnjyGokW5dSQXKTp7B5-6LZTdNrpeKYofO3Sx7B2mw@mail.gmail.com>

Your model is too complex for the data. This gives you two options: a)
simplify the model and b) get more data.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-06-09 21:57 GMT+02:00 li li <hannah.hlx at gmail.com>:

> Hi all,
>   I'd like to fit a random intercept and random slope model. In my
> data, there are three groups. I want to have different random
> intercept for each group but the same random slope effect for all
> three groups. I used the following R command.
> However, there seems to be some problem. Any suggestions?
>
>
>
> mod2 <- lmer(result  ~ group*time+(0+group1+ group2 +
> group3+time|lot), na.action=na.omit, data=alldata)
>
> > summary(mod2)
> Model is not identifiable...
> summary from lme4 is returned
> some computational error has occurred in lmerTest
> Linear mixed model fit by REML ['merModLmerTest']
> Formula: result ~ group * time + (0 + group1 + group2 + group3 + time |
>     lot)
>    Data: alldata
>
> REML criterion at convergence: 807.9
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -3.0112 -0.3364  0.0425  0.2903  3.2017
>
> Random effects:
>  Groups   Name     Variance Std.Dev. Corr
>  lot      group1   0.00000 0.000
>           group2   86.20156 9.284      NaN
>           group3 55.91479 7.478      NaN  0.06
>           time      0.02855 0.169      NaN -0.99  0.10
>  Residual          39.91968 6.318
> Number of obs: 119, groups:  lot, 15
>
> Fixed effects:
>                             Estimate Std. Error t value
> (Intercept)                 100.1566     2.5108   39.89
> group  group2        -2.9707     3.7490   -0.79
> group  group3           -0.0717     2.8144   -0.03
> time                         -0.1346     0.1780   -0.76
> group  group2 :time   0.1450     0.2939    0.49
> group  group3:time        0.1663     0.2152    0.77
>
> Warning messages:
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 0.147314 (tol = 0.002,
> component 2)
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge: degenerate  Hessian with 2 negative eigenvalues
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Tue Jun  9 23:18:36 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 9 Jun 2015 13:18:36 -0800
Subject: [R] Cross tabulation with top one variable and side as multiple
 variables
In-Reply-To: <1433839253539-4708379.post@n4.nabble.com>
Message-ID: <0CDED3E7D94.000007F9jrkrideau@inbox.com>

We probably should have a better idea of what the raw data looks like and perhaps a bit better idea of what the analyis is to show.  Have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html for some suggestions. In particular see the discussion about dput() for the best way to provide sample data to the help list.


John Kane
Kingston ON Canada


> -----Original Message-----
> From: p.jagadish at inrhythm-inc.com
> Sent: Tue, 9 Jun 2015 01:40:53 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] Cross tabulation with top one variable and side as multiple
> variables
> 
> Hi:
> 
> I have a huge data with lot of variables and I need to check the trend
> variations from year to year. In order to do so, I have to cross tabulate
> the year variable as top (constant) and all the remaining variables as
> side
> (attached the cross tabulation report). I have searched the forums but
> the
> syntax I could find for cross tabulation is between 2 or 3 variables. So
> i
> would request to provide a code which can print the data in the same way
> as
> in the attached.
> <http://r.789695.n4.nabble.com/file/n4708379/Untitled.png>
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Cross-tabulation-with-top-one-variable-and-side-as-multiple-variables-tp4708379.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From bgunter.4567 at gmail.com  Tue Jun  9 23:25:12 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 9 Jun 2015 14:25:12 -0700
Subject: [R] Different random intercepts but same random slope for groups
In-Reply-To: <CAJuCY5xPhnjyGokW5dSQXKTp7B5-6LZTdNrpeKYofO3Sx7B2mw@mail.gmail.com>
References: <CAHLnndZ4OOuXXkTM=Ga3fNByK=+zyrC36RUvM_vj8A55qrH+gA@mail.gmail.com>
	<CAJuCY5xPhnjyGokW5dSQXKTp7B5-6LZTdNrpeKYofO3Sx7B2mw@mail.gmail.com>
Message-ID: <CAGxFJbQdOe1_GcugBHvZwy5jujvRz+TVVFRzc0Ubwqnh+qmp6w@mail.gmail.com>

Thierry:

I don't think so. It looks to me like her syntax/understanding is confused.
I think the call should be:

mod2 <- lmer(result  ~ group*time+(group + time|lot), na.action=na.omit,
data=alldata)

Her request for "the same random slope for each group" -- I assume it's for
time -- means to me that the time slope will vary "randomly" by lot only,
the slope would be the same for all groups within the lot.

Of course, I may be wrong also. If so, I suggest that she follow the
posting guide and post at least head(alldata) using dput() to enable folks
to understand the structure of her data. And only on r-sig-mixed-models --
crossposting is frowned upon here and the mixed models list is the best bet
for this sort of question anyway.

As always, corrections and criticism welcome.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Tue, Jun 9, 2015 at 1:49 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Your model is too complex for the data. This gives you two options: a)
> simplify the model and b) get more data.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-06-09 21:57 GMT+02:00 li li <hannah.hlx at gmail.com>:
>
> > Hi all,
> >   I'd like to fit a random intercept and random slope model. In my
> > data, there are three groups. I want to have different random
> > intercept for each group but the same random slope effect for all
> > three groups. I used the following R command.
> > However, there seems to be some problem. Any suggestions?
> >
> >
> >
> > mod2 <- lmer(result  ~ group*time+(0+group1+ group2 +
> > group3+time|lot), na.action=na.omit, data=alldata)
> >
> > > summary(mod2)
> > Model is not identifiable...
> > summary from lme4 is returned
> > some computational error has occurred in lmerTest
> > Linear mixed model fit by REML ['merModLmerTest']
> > Formula: result ~ group * time + (0 + group1 + group2 + group3 + time |
> >     lot)
> >    Data: alldata
> >
> > REML criterion at convergence: 807.9
> >
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -3.0112 -0.3364  0.0425  0.2903  3.2017
> >
> > Random effects:
> >  Groups   Name     Variance Std.Dev. Corr
> >  lot      group1   0.00000 0.000
> >           group2   86.20156 9.284      NaN
> >           group3 55.91479 7.478      NaN  0.06
> >           time      0.02855 0.169      NaN -0.99  0.10
> >  Residual          39.91968 6.318
> > Number of obs: 119, groups:  lot, 15
> >
> > Fixed effects:
> >                             Estimate Std. Error t value
> > (Intercept)                 100.1566     2.5108   39.89
> > group  group2        -2.9707     3.7490   -0.79
> > group  group3           -0.0717     2.8144   -0.03
> > time                         -0.1346     0.1780   -0.76
> > group  group2 :time   0.1450     0.2939    0.49
> > group  group3:time        0.1663     0.2152    0.77
> >
> > Warning messages:
> > 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> :
> >   Model failed to converge with max|grad| = 0.147314 (tol = 0.002,
> > component 2)
> > 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> :
> >   Model failed to converge: degenerate  Hessian with 2 negative
> eigenvalues
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Wed Jun 10 00:18:46 2015
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 9 Jun 2015 18:18:46 -0400
Subject: [R] A-priori contrasts with type III sums of squares in R
In-Reply-To: <55775733.6040904@nceas.ucsb.edu>
References: <55722372.50105@nceas.ucsb.edu>
	<001701d0a08f$f4ee9bb0$decbd310$@mcmaster.ca>
	<55775733.6040904@nceas.ucsb.edu>
Message-ID: <001a01d0a302$40e8e010$c2baa030$@mcmaster.ca>

Dear Rachel,

How about this (using the data and model you sent originally)?

> linearHypothesis(EpiLM, "GzrTreatpresence = 0")
Linear hypothesis test

Hypothesis:
GzrTreatpresence = 0

Model 1: restricted model
Model 2: log_EpiChla ~ TempTreat * GzrTreat * ShadeTreat

  Res.Df     RSS Df  Sum of Sq      F Pr(>F)
1     25 0.12665                            
2     24 0.12623  1 0.00042195 0.0802 0.7794

> linearHypothesis(EpiLM, "GzrTreatimmigration = 0")
Linear hypothesis test

Hypothesis:
GzrTreatimmigration = 0

Model 1: restricted model
Model 2: log_EpiChla ~ TempTreat * GzrTreat * ShadeTreat

  Res.Df     RSS Df  Sum of Sq     F Pr(>F)
1     25 0.12623                           
2     24 0.12623  1 5.0931e-06 0.001 0.9754

Note that this tests main-effect contrasts in a model that includes
interactions to which the main effect is marginal. You should probably think
about whether you really want to do that.

BTW, the slides to which you refer are for *multivariate* linear models
(including repeated measures); you're using a univariate linear model.

Best,
 John

> -----Original Message-----
> From: Rachael Blake [mailto:blake at nceas.ucsb.edu]
> Sent: June-09-15 5:14 PM
> To: John Fox; r-help at r-project.org
> Subject: Re: [R] A-priori contrasts with type III sums of squares in R
> 
> Thank you for replying, John!
> 
> I am not using treatment contrasts in this analysis.  I am specifying
>            options(contrasts=c("contr.sum", "contr.poly"))
> earlier in my code in order to get interpretable results from the Type
> III SS.  However, I did not include that code in the example because it
> is not related to my initial question, and those contrasts are not of
> interest to me.  My interest is in my a-priori specified contrasts:
>           contrasts(All09$GzrTreat) <- cbind('presence'=c(1,-2,1),
> 'immigration'=c(1,0,-1))
> 
> I have made a valiant attempt to use linearHypothesis(), based on the
> example provided here
> https://web.warwick.ac.uk/statsdept/user2011/TalkSlides/Contributed/17Au
> g_1705_FocusV_4-Multivariate_1-Fox.pdf
> as well as other places.   I have tried two different ways of specifying
> my contrast matrix, but I keep getting error messages that I can not
> resolve.   My code based on that powerpoint presentation is as follows
> (still using the data included in my initial question):
> 
>          options(contrasts=c("contr.sum", "contr.poly"))
>          EpiLM <- lm(log_EpiChla~TempTreat*GzrTreat*ShadeTreat, All09)
>          Anova(EpiLM, type="III")
>          class(EpiLM)
>          contrasts(All09$GzrTreat) <- cbind('presence'=c(1,-2,1),
> 'immigration'=c(1,0,-1))
>          con <- contrasts(All09$GzrTreat) ; con
>          EpiLM2 <- update(EpiLM)
>          rownames(coef(EpiLM2))
>          linearHypothesis(model=EpiLM2,
> hypothesis.matrix=c("presence","immigration"), verbose=T)  # first
> attempt to implement
>          linearHypothesis(model=EpiLM2, hypothesis.matrix=con,
> verbose=T)                                              # second attempt
> to implement
> 
> 
> Thanks again for your reply.
> 
> -Rachael
> 
> 
> On 6/6/2015 12:35 PM, John Fox wrote:
> > Dear Rachel,
> >
> > Anova() won't give you a breakdown of the SS for each term into 1 df
> > components (there is no split argument, as you can see if you look at
> > ?Anova). Because, with the exception of GzrTreat, your contrasts are
> not
> > orthogonal in the row basis of the design (apparently you're using the
> > default "contr.treatment" coding), you also won't get sensible type-
> III
> > tests from Anova(). If you formulated the contrasts for the other
> factors
> > properly (using, e.g., contr.sum), you could get single df tests from
> > linearHypothesis() in the car package.
> >
> > I hope this helps,
> >   John
> >
> > -----------------------------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario, Canada
> > http://socserv.socsci.mcmaster.ca/jfox/
> >
> >
> >
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Rachael
> >> Blake
> >> Sent: June-05-15 6:32 PM
> >> To: r-help at r-project.org
> >> Subject: [R] A-priori contrasts with type III sums of squares in R
> >>
> >> I am analyzing data using a factorial three-way ANOVA with a-priori
> >> contrasts and type III sums of squares. (Please don't comment about
> type
> >> I SS vs. type III SS. That's not the point of my question.  I have
> read
> >> at length about the choice between types of SS and have made my
> >> decision.) I get the contrasts like I need using summary.aov(),
> however
> >> that uses type I SS. When I use the Anova() function from
> library(car)
> >> to get type III SS, I don't get the contrasts. I have also tried
> using
> >> drop1() with the lm() model, but I get the same results as Anova()
> >> (without the contrasts).
> >>
> >> Please advise on a statistical method in R to analyze data using
> >> factorial ANOVA with a-priori contrasts and type III SS as shown in
> my
> >> example below.
> >>
> >> Sample data:
> >>       DF <- structure(list(Code = structure(c(1L, 1L, 1L, 2L, 2L, 2L,
> 3L,
> >> 3L,
> >>       3L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L, 7L, 7L, 7L, 8L, 8L, 8L,
> 9L,
> >> 9L,
> >>       9L, 10L, 10L, 10L, 11L, 11L, 11L, 12L, 12L, 12L), .Label =
> c("A",
> >>       "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L"), class =
> >>       "factor"), GzrTreat = structure(c(3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L,
> >> 3L,
> >>       3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 2L,
> >> 2L,
> >>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), contrasts =
> structure(c(1,
> >>       -2, 1, 1, 0, -1), .Dim = c(3L, 2L), .Dimnames = list(c("I",
> >>       "N", "R"), NULL)), .Label = c("I", "N", "R"), class =
> "factor"),
> >>       BugTreat = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >>       1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >>       3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label =
> >>       c("Immigration", "Initial", "None"), class = "factor"),
> TempTreat =
> >>       structure(c(2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
> 2L,
> >> 2L,
> >>       2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L,
> >>       1L, 1L, 1L, 1L, 1L), .Label = c("Not Warm", "Warmed"), class =
> >>       "factor"), ShadeTreat = structure(c(2L, 2L, 2L, 1L, 1L, 1L, 2L,
> 2L,
> >>       2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
> >>       1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L), .Label =
> >> c("Light",
> >>       "Shaded"), class = "factor"), EpiChla = c(0.268482353,
> 0.423119608,
> >>       0.579507843, 0.738839216, 0.727856863, 0.523960784,
> 0.405801961,
> >>       0.335964706, 0.584441176, 0.557543137, 0.436456863,
> 0.563909804,
> >>       0.432398039, 0.344956863, 0.340309804, 0.992884314,
> 0.938390196,
> >>       0.663270588, 0.239833333, 0.62875098, 0.466011765, 0.536182353,
> >>       0.340309804, 0.721172549, 0.752082353, 0.269372549,
> 0.198180392,
> >>       1.298882353, 0.298354902, 0.913139216, 0.846129412,
> 0.922317647,
> >>       0.727033333, 1.187662745, 0.35622549, 0.073547059), log_EpiChla
> =
> >>       c(0.10328443, 0.153241402, 0.198521787, 0.240259426,
> 0.237507762,
> >>       0.182973791, 0.147924145, 0.125794985, 0.19987612, 0.192440084,
> >>       0.157292589, 0.194211702, 0.156063718, 0.128708355,
> 0.127205194,
> >>       0.299482089, 0.287441205, 0.220962908, 0.093363308, 0.21185469,
> >>       0.166137456, 0.186442772, 0.127205194, 0.235824411,
> 0.243554515,
> >>       0.103589102, 0.078522208, 0.361516746, 0.113393422,
> 0.281746574,
> >>       0.266262141, 0.283825153, 0.23730072, 0.339980371, 0.132331903,
> >>       0.030821087), MeanZGrowthAFDM_g = c(0.00665, 0.003966667,
> >> 0.004466667,
> >>       0.01705, 0.0139, 0.0129, 0.0081, 0.003833333, 0.00575,
> 0.011266667,
> >>       0.0103, 0.009, 0.0052, 0.00595, 0.0105, 0.0091, 0.00905,
> 0.0045,
> >> 0.0031,
> >>       0.006466667, 0.0053, 0.009766667, 0.0181, 0.00725, 0, 0.0012,
> 5e-
> >> 04,
> >>       0.0076, 0.00615, 0.0814, NA, 0.0038, 0.00165, 0.0046, 0,
> 0.0015)),
> >>       .Names = c("Code", "GzrTreat", "BugTreat", "TempTreat",
> >> "ShadeTreat",
> >>       "EpiChla", "log_EpiChla", "MeanZGrowthAFDM_g"), class =
> >> "data.frame",
> >>       row.names = c(NA, -36L))
> >>
> >>
> >> Code:
> >>
> >>       ## a-priori contrasts
> >>       library(stats)
> >>       contrasts(DF$GzrTreat) <- cbind(c(1,-2,1), c(1,0,-1))
> >>       round(crossprod(contrasts(DF$GzrTreat)))
> >>       c_labels <- list(GzrTreat=list('presence'=1, 'immigration'=2))
> >>
> >>       ## model
> >>       library(car)
> >>       EpiLM <- lm(log_EpiChla~TempTreat*GzrTreat*ShadeTreat, DF)
> >>       summary.aov(EpiLM, split=c_labels) ### MUST USE summary.aov(),
> to
> >> get
> >>       #contrast results, but sadly this uses Type I SS
> >>       Anova(EpiLM, split=c_labels, type="III") # Uses Type III SS,
> but NO
> >>       #CONTRASTS!!!!!
> >>       drop1(EpiLM, ~., test="F") # again, this does not print
> contrasts
> >>
> >>       # I need contrast results like from summary.aov(), AND Type III
> SS
> >>       # like from Anova()
> >>
> >>
> >>
> >> --
> >> Rachael E. Blake, PhD
> >> Post-doctoral Associate
> >>
> >>
> 
> --
> Rachael E. Blake, PhD
> Post-doctoral Associate


---
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From bbolker at gmail.com  Wed Jun 10 01:28:03 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 9 Jun 2015 23:28:03 +0000
Subject: [R] Different random intercepts but same random slope for groups
References: <CAHLnndZ4OOuXXkTM=Ga3fNByK=+zyrC36RUvM_vj8A55qrH+gA@mail.gmail.com>
Message-ID: <loom.20150610T012713-508@post.gmane.org>

li li <hannah.hlx <at> gmail.com> writes:

> 

[snip]

>   I'd like to fit a random intercept and random slope model. In my
> data, there are three groups. I want to have different random
> intercept for each group but the same random slope effect for all
> three groups. I used the following R command.
> However, there seems to be some problem. Any suggestions?

  Please do not cross-post to more than one R list (in this
case, r-sig-mixed-models is more appropriate, and you've already
gotten some answers there).
 
  Ben Bolker


From jholtman at gmail.com  Wed Jun 10 02:09:38 2015
From: jholtman at gmail.com (jim holtman)
Date: Tue, 9 Jun 2015 20:09:38 -0400
Subject: [R] more complex by with data.table???
In-Reply-To: <C7338A7EFF31BB4D831BB06C00887789B2F91594@MBX023-W1-CA-2.exch023.domain.local>
References: <C7338A7EFF31BB4D831BB06C00887789B2F91594@MBX023-W1-CA-2.exch023.domain.local>
Message-ID: <CAAxdm-6ijMnn5dxu4GdcLzZz9CwPXDOZzjhWUAY6mLrS5QEjBA@mail.gmail.com>

try this:

> dt[
+     , {
+         result <- list()
+         for (i in names(.SD)){
+             result[[i]] <- myFunction(unlist(.SD[, i, with = FALSE]))
+         }
+         result
+       }
+     , by = name
+     ]
   name var1 var2 var3
1:    a  2.0   22   42
2:    b  7.5   28   48
>



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Tue, Jun 9, 2015 at 4:22 PM, Ramiro Barrantes <
ramiro at precisionbioassay.com> wrote:

> Hello,
>
> I am trying to do something that I am able to do with the "by" function
> within data.frame but can't figure out how to achieve with data.table.
>
> Consider
>
>
> dt<-data.table(name=c(rep("a",5),rep("b",6)),var1=0:10,var2=20:30,var3=40:50)
> myFunction <- function(x) { mean(x) }
>
> I am aware that I can do something like:
>
> dt[, .(meanVar1=myFunction(var1)) ,by=.(name)]
>
> but how could I do the equivalent of:
>
>
> df<-data.frame(name=c(rep("a",5),rep("b",6)),var1=0:10,var2=20:30,var3=40:50)
> myFunction <- function(x) { mean(x) }
>
> columnNames <- c("var1","var2","var3")
> result <- by(df, df$name, function(x) {
>    output <- c()
>    for(col in columnNames) {
>      output[col] <- myFunction(x[,col])
>    }
>   output
> })
> do.call(rbind,result)
>
> Thanks in advance,
> Ramiro
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Wed Jun 10 02:17:19 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 9 Jun 2015 20:17:19 -0400
Subject: [R] more complex by with data.table???
In-Reply-To: <C7338A7EFF31BB4D831BB06C00887789B2F91594@MBX023-W1-CA-2.exch023.domain.local>
References: <C7338A7EFF31BB4D831BB06C00887789B2F91594@MBX023-W1-CA-2.exch023.domain.local>
Message-ID: <CA+vqiLFuAKF+y_skZLZbgx84JmEJL-xvUVj_TAgAyQga1EcMgg@mail.gmail.com>

Hi Ramiro,

There is a demonstration of this on the data.table wiki at
https://rawgit.com/wiki/Rdatatable/data.table/vignettes/datatable-intro-vignette.html.
You can do

dt[, lapply(.SD, mean), by=name]

or

dt[, as.list(colMeans(.SD)), by=name]

BTW, there are pretty straightforward ways to do this in base R as well, e.g,

data.frame(t(sapply(split(df[-1], df$name), colMeans)))

Best,
Ista

On Tue, Jun 9, 2015 at 4:22 PM, Ramiro Barrantes
<ramiro at precisionbioassay.com> wrote:
> Hello,
>
> I am trying to do something that I am able to do with the "by" function within data.frame but can't figure out how to achieve with data.table.
>
> Consider
>
> dt<-data.table(name=c(rep("a",5),rep("b",6)),var1=0:10,var2=20:30,var3=40:50)
> myFunction <- function(x) { mean(x) }
>
> I am aware that I can do something like:
>
> dt[, .(meanVar1=myFunction(var1)) ,by=.(name)]
>
> but how could I do the equivalent of:
>
> df<-data.frame(name=c(rep("a",5),rep("b",6)),var1=0:10,var2=20:30,var3=40:50)
> myFunction <- function(x) { mean(x) }
>
> columnNames <- c("var1","var2","var3")
> result <- by(df, df$name, function(x) {
>    output <- c()
>    for(col in columnNames) {
>      output[col] <- myFunction(x[,col])
>    }
>   output
> })
> do.call(rbind,result)
>
> Thanks in advance,
> Ramiro
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From yhbrent at yahoo.com  Wed Jun 10 06:14:47 2015
From: yhbrent at yahoo.com (Brent)
Date: Wed, 10 Jun 2015 04:14:47 +0000 (UTC)
Subject: [R] %OSn in time formats: is it only valid for formatting,
 but invalid for parsing?
Message-ID: <1767631662.24046.1433909687630.JavaMail.yahoo@mail.yahoo.com>

Consider this R code:
time = as.POSIXct(1433867059, origin = "1970-01-01")
print(time)
print( as.numeric(time) )

timeFormat = "%Y-%m-%d %H:%M:%OS3"
tz = "EST"

timestamp = format(time, format = timeFormat, tz = tz)
print(timestamp)

timeParsed = as.POSIXct(timestamp, format = timeFormat, tz = tz)
print(timeParsed)
print( as.numeric(timeParsed) )


If I paste that into Rgui on my Windows bos, which is running the latest (3.2.0) stable release, I get this:
> time = as.POSIXct(1433867059, origin = "1970-01-01")
> print(time)
[1] "2015-06-09 12:24:19 EDT"
> print( as.numeric(time) )
[1] 1433867059
> 
> timeFormat = "%Y-%m-%d %H:%M:%OS3"
> tz = "EST"
> 
> timestamp = format(time, format = timeFormat, tz = tz)
> print(timestamp)
[1] "2015-06-09 11:24:19.000"
> 
> timeParsed = as.POSIXct(timestamp, format = timeFormat, tz = tz)
> print(timeParsed)
[1] NA
> print( as.numeric(timeParsed) )
[1] NA

Notice how the time format, which ends with %OS3, produces the correct time stamp (a 3 digit millisecond resolution).

However, that same time format FAILS IN THE OPPOSITE DIRECTION: it cannot parse that time stamp back into the original POSIXct value; it barfs and parses NA.

Anyone know what is going on?

A web search found this link 
https://stackoverflow.com/questions/19062178/how-to-convert-specific-time-format-to-timestamp-in-r
where one of the commenters, Waldir Leoncio, in the first answer, appears to describe the same parsing bug with %OS3 that I do:
"use, for example, strptime(y, "%d.%m.%Y %H:%M:%OS3"), but it doesn't work for me. Henrik noted that the function's help page, ?strptime states that the %OS3 bit is OS-dependent. I'm using an updated Ubuntu 13.04 and using %OS3 yields NA."

The help page mentioned in the quote above likely is
https://stat.ethz.ch/R-manual/R-devel/library/base/html/strptime.html
which is unfortunately terse, merely saying
"Specific to R is %OSn, which for output gives the seconds truncated to 0 <= n <= 6 decimal places (and if %OS is not followed by a digit, it uses the setting of getOption("digits.secs"), or if that is unset, n = 3). Further, for strptime %OS will input seconds including fractional seconds. Note that %S ignores (and not rounds) fractional parts on output. "

That final senetence about strptime (i.e. parsing) is subtle: it says "for strptime %OS".  Note the absence of an 'n': it says %OS instead of %OSn.

Does that mean that %OSn can NOT be used for parsing, only for formatting?

That is what I have empirically found, but is it expected behavior or a bug?

Very annoying if expected behavior, since that means that I need different time formats for formatting and parsing.  Have never seen that before in any other language's date API.


From shivibhatia at ymail.com  Wed Jun 10 07:51:47 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Tue, 9 Jun 2015 22:51:47 -0700 (PDT)
Subject: [R] Summarizing data based on Date
In-Reply-To: <1433750889045-4708328.post@n4.nabble.com>
References: <1433750889045-4708328.post@n4.nabble.com>
Message-ID: <1433915507567-4708423.post@n4.nabble.com>

HI All,

I am able to get the desired result. Thanks for extending help. 
while reading the csv file I made some changes as :

Test<-read.csv("Testdata.csv", head=TRUE, stringsAsFactors = FALSE,
strip.white = TRUE)
with this character var were not changed to factors. 

Then aggregation was simple: 
aggregate(test$CHG_WT, list(test$CR_DT), sum)

However the output is not sorted based on Dates and the columns names
appearing as very different:

Group.1       x
1   1-Mar-15  909791
2  10-Mar-15  822436
3  11-Mar-15  848609
4  12-Mar-15  924842
5  13-Mar-15  895270
6  14-Mar-15  93238
7 2-Mar-15     731600

Can you all please suggest why the column names are so different and how I
could sort based on dates. I added the sort option in the above syntax 
aggregate(test$CHG_WT, list(test$CR_DT), sum,sort(test$CR_DT,decreasing =
TRUE))

But it gave me an error: 
Error in FUN(X[[i]], ...) : invalid 'type' (character) of argument
Thanks All. 




--
View this message in context: http://r.789695.n4.nabble.com/Summarizing-data-based-on-Date-tp4708328p4708423.html
Sent from the R help mailing list archive at Nabble.com.


From dmck at u.washington.edu  Tue Jun  9 20:23:53 2015
From: dmck at u.washington.edu (Don McKenzie)
Date: Tue, 9 Jun 2015 11:23:53 -0700
Subject: [R] graphs, need urgent help (deadline :( )
In-Reply-To: <10C1B087-6721-44B2-A347-851219672D30@gmail.com>
References: <10C1B087-6721-44B2-A347-851219672D30@gmail.com>
Message-ID: <FE94928E-A651-4E9F-9643-73635938C694@u.washington.edu>

The answer lies in learning to use the help (and knowing where to start).  Did you look at the tutorial that comes with the R installation?

?plot
?lines

?par   

In the last, look for the descriptions of ?col? and ?lty?.

Using plot() and lines(), and subsetting the four unique values of ?sample?, you can create your lines.

Here is a crude start, assuming your columns are part of a data frame called ?my.data?.   Untested...

plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)     # blue line, not dashed
.
.
.
lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)   # red dashed line


> On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com> wrote:
> 
> Hi,
> 
> another naive question (i?m pretty sure :( )
> 
> 
> I?m trying to plot a multiple line graph:
> 
>         region	       sample	       factora	        factorb	       factorc
> 0.1	10	0.895	0.903	0.378
> 0.2	10	0.811	0.865	0.688
> 0.1	20	0.735	0.966	0.611
> 0.2	20	0.777	0.732	0.653
> 0.1	30	0.600	0.778	0.694
> 0.2	30	0.466	174.592	0.461
> 0.1	40	0.446	0.432	0.693
> 0.2	40	0.392	0.294	0.686
> 
> 
> 
> The first column should be the independent variable, the second should compute a bold line for sample(10) and dash line for sample 20.

What about the other two values of ?sample??  

> The others variables are outcomes for each of the first scenarios, and so it should: the 3rd, 4th and 5th columns should be blue, red and green respectively. 
> 
> 
> Resume :)
> 
> I should have a graph, in the x-axe should have the region and in the y axe, the factor.
> Lines:
> 	1 - blue and bold for region 0.1, sample 10 and factor a
> 	2 - blue and dash for region 0.2, sample 10 and factor a
> 	3 - red and bold for region 0.1, sample 10 and factor b
> 	4 - red and dash for region 0.2, sample 10 and factor b
> 	5 - green and bold for region 0.1, sample 10 and factor c
> 	6 - green and dash for region 0.2, sample 10 and factor c

Not consistent with what you said above. These are no longer lines, but points.
> 
> nonetheless the independent variable is nominal, I should plot a line graph.
> 
> Can anyone help me please?
> I have my file as a cvs file, so I first read that file (that I know how to do :)).
> 
> But I have it in that format.
> 
> Best,
> RO
> 
> 
> 
> Atenciosamente,
> Rosa Oliveira
> 
> -- 
> ____________________________________________________________________________
> 
> 
> Rosa Celeste dos Santos Oliveira, 
> 
> E-mail: rosita21 at gmail.com
> Tlm: +351 939355143 
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




From blake at nceas.ucsb.edu  Tue Jun  9 23:14:27 2015
From: blake at nceas.ucsb.edu (Rachael Blake)
Date: Tue, 09 Jun 2015 14:14:27 -0700
Subject: [R] A-priori contrasts with type III sums of squares in R
In-Reply-To: <001701d0a08f$f4ee9bb0$decbd310$@mcmaster.ca>
References: <55722372.50105@nceas.ucsb.edu>
	<001701d0a08f$f4ee9bb0$decbd310$@mcmaster.ca>
Message-ID: <55775733.6040904@nceas.ucsb.edu>

Thank you for replying, John!

I am not using treatment contrasts in this analysis.  I am specifying
           options(contrasts=c("contr.sum", "contr.poly"))
earlier in my code in order to get interpretable results from the Type 
III SS.  However, I did not include that code in the example because it 
is not related to my initial question, and those contrasts are not of 
interest to me.  My interest is in my a-priori specified contrasts:
          contrasts(All09$GzrTreat) <- cbind('presence'=c(1,-2,1), 
'immigration'=c(1,0,-1))

I have made a valiant attempt to use linearHypothesis(), based on the 
example provided here
https://web.warwick.ac.uk/statsdept/user2011/TalkSlides/Contributed/17Aug_1705_FocusV_4-Multivariate_1-Fox.pdf
as well as other places.   I have tried two different ways of specifying 
my contrast matrix, but I keep getting error messages that I can not 
resolve.   My code based on that powerpoint presentation is as follows 
(still using the data included in my initial question):

         options(contrasts=c("contr.sum", "contr.poly"))
         EpiLM <- lm(log_EpiChla~TempTreat*GzrTreat*ShadeTreat, All09)
         Anova(EpiLM, type="III")
         class(EpiLM)
         contrasts(All09$GzrTreat) <- cbind('presence'=c(1,-2,1), 
'immigration'=c(1,0,-1))
         con <- contrasts(All09$GzrTreat) ; con
         EpiLM2 <- update(EpiLM)
         rownames(coef(EpiLM2))
         linearHypothesis(model=EpiLM2, 
hypothesis.matrix=c("presence","immigration"), verbose=T)  # first 
attempt to implement
         linearHypothesis(model=EpiLM2, hypothesis.matrix=con, 
verbose=T)                                              # second attempt 
to implement


Thanks again for your reply.

-Rachael


On 6/6/2015 12:35 PM, John Fox wrote:
> Dear Rachel,
>
> Anova() won't give you a breakdown of the SS for each term into 1 df
> components (there is no split argument, as you can see if you look at
> ?Anova). Because, with the exception of GzrTreat, your contrasts are not
> orthogonal in the row basis of the design (apparently you're using the
> default "contr.treatment" coding), you also won't get sensible type-III
> tests from Anova(). If you formulated the contrasts for the other factors
> properly (using, e.g., contr.sum), you could get single df tests from
> linearHypothesis() in the car package.
>
> I hope this helps,
>   John
>
> -----------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.socsci.mcmaster.ca/jfox/
>
>
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rachael
>> Blake
>> Sent: June-05-15 6:32 PM
>> To: r-help at r-project.org
>> Subject: [R] A-priori contrasts with type III sums of squares in R
>>
>> I am analyzing data using a factorial three-way ANOVA with a-priori
>> contrasts and type III sums of squares. (Please don't comment about type
>> I SS vs. type III SS. That's not the point of my question.  I have read
>> at length about the choice between types of SS and have made my
>> decision.) I get the contrasts like I need using summary.aov(), however
>> that uses type I SS. When I use the Anova() function from library(car)
>> to get type III SS, I don't get the contrasts. I have also tried using
>> drop1() with the lm() model, but I get the same results as Anova()
>> (without the contrasts).
>>
>> Please advise on a statistical method in R to analyze data using
>> factorial ANOVA with a-priori contrasts and type III SS as shown in my
>> example below.
>>
>> Sample data:
>>       DF <- structure(list(Code = structure(c(1L, 1L, 1L, 2L, 2L, 2L, 3L,
>> 3L,
>>       3L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L, 7L, 7L, 7L, 8L, 8L, 8L, 9L,
>> 9L,
>>       9L, 10L, 10L, 10L, 11L, 11L, 11L, 12L, 12L, 12L), .Label = c("A",
>>       "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L"), class =
>>       "factor"), GzrTreat = structure(c(3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L,
>>       3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,  2L,
>> 2L,
>>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), contrasts = structure(c(1,
>>       -2, 1, 1, 0, -1), .Dim = c(3L, 2L), .Dimnames = list(c("I",
>>       "N", "R"), NULL)), .Label = c("I", "N", "R"), class = "factor"),
>>       BugTreat = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>       1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>       3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label =
>>       c("Immigration", "Initial", "None"), class = "factor"), TempTreat =
>>       structure(c(2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
>> 2L,
>>       2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L,
>>       1L, 1L, 1L, 1L, 1L), .Label = c("Not Warm", "Warmed"), class =
>>       "factor"), ShadeTreat = structure(c(2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L,
>>       2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
>>       1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L), .Label =
>> c("Light",
>>       "Shaded"), class = "factor"), EpiChla = c(0.268482353, 0.423119608,
>>       0.579507843, 0.738839216, 0.727856863, 0.523960784, 0.405801961,
>>       0.335964706, 0.584441176, 0.557543137, 0.436456863, 0.563909804,
>>       0.432398039, 0.344956863, 0.340309804, 0.992884314, 0.938390196,
>>       0.663270588, 0.239833333, 0.62875098, 0.466011765, 0.536182353,
>>       0.340309804, 0.721172549, 0.752082353, 0.269372549, 0.198180392,
>>       1.298882353, 0.298354902, 0.913139216, 0.846129412, 0.922317647,
>>       0.727033333, 1.187662745, 0.35622549, 0.073547059), log_EpiChla =
>>       c(0.10328443, 0.153241402, 0.198521787, 0.240259426, 0.237507762,
>>       0.182973791, 0.147924145, 0.125794985, 0.19987612, 0.192440084,
>>       0.157292589, 0.194211702, 0.156063718, 0.128708355, 0.127205194,
>>       0.299482089, 0.287441205, 0.220962908, 0.093363308, 0.21185469,
>>       0.166137456, 0.186442772, 0.127205194, 0.235824411, 0.243554515,
>>       0.103589102, 0.078522208, 0.361516746, 0.113393422, 0.281746574,
>>       0.266262141, 0.283825153, 0.23730072, 0.339980371, 0.132331903,
>>       0.030821087), MeanZGrowthAFDM_g = c(0.00665, 0.003966667,
>> 0.004466667,
>>       0.01705, 0.0139, 0.0129, 0.0081, 0.003833333, 0.00575, 0.011266667,
>>       0.0103, 0.009, 0.0052, 0.00595, 0.0105, 0.0091, 0.00905, 0.0045,
>> 0.0031,
>>       0.006466667, 0.0053, 0.009766667, 0.0181, 0.00725, 0, 0.0012, 5e-
>> 04,
>>       0.0076, 0.00615, 0.0814, NA, 0.0038, 0.00165, 0.0046, 0, 0.0015)),
>>       .Names = c("Code", "GzrTreat", "BugTreat", "TempTreat",
>> "ShadeTreat",
>>       "EpiChla", "log_EpiChla", "MeanZGrowthAFDM_g"), class =
>> "data.frame",
>>       row.names = c(NA, -36L))
>>
>>
>> Code:
>>
>>       ## a-priori contrasts
>>       library(stats)
>>       contrasts(DF$GzrTreat) <- cbind(c(1,-2,1), c(1,0,-1))
>>       round(crossprod(contrasts(DF$GzrTreat)))
>>       c_labels <- list(GzrTreat=list('presence'=1, 'immigration'=2))
>>
>>       ## model
>>       library(car)
>>       EpiLM <- lm(log_EpiChla~TempTreat*GzrTreat*ShadeTreat, DF)
>>       summary.aov(EpiLM, split=c_labels) ### MUST USE summary.aov(), to
>> get
>>       #contrast results, but sadly this uses Type I SS
>>       Anova(EpiLM, split=c_labels, type="III") # Uses Type III SS, but NO
>>       #CONTRASTS!!!!!
>>       drop1(EpiLM, ~., test="F") # again, this does not print contrasts
>>
>>       # I need contrast results like from summary.aov(), AND Type III SS
>>       # like from Anova()
>>
>>
>>
>> --
>> Rachael E. Blake, PhD
>> Post-doctoral Associate
>>
>>

-- 
Rachael E. Blake, PhD
Post-doctoral Associate


From rosita21 at gmail.com  Wed Jun 10 02:53:55 2015
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Wed, 10 Jun 2015 01:53:55 +0100
Subject: [R] graphs, need urgent help (deadline :( )
In-Reply-To: <FE94928E-A651-4E9F-9643-73635938C694@u.washington.edu>
References: <10C1B087-6721-44B2-A347-851219672D30@gmail.com>
	<FE94928E-A651-4E9F-9643-73635938C694@u.washington.edu>
Message-ID: <D2FD6C5D-E38B-4317-9FFA-6CFA6AA0D20E@gmail.com>

Dear Don and all,

I?ve read the tutorial and tried several codes before posting :)
I?m really naive.



what I was trying to :  is something like the graph in the picture I drawee.




Is it more clear now? 

Atenciosamente,
Rosa Oliveira

-- 
____________________________________________________________________________


Rosa Celeste dos Santos Oliveira, 

E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
Tlm: +351 939355143 
Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
____________________________________________________________________________
"Many admire, few know"
Hippocrates

> On 09 Jun 2015, at 19:23, Don McKenzie <dmck at u.washington.edu <mailto:dmck at u.washington.edu>> wrote:
> 
> The answer lies in learning to use the help (and knowing where to start).  Did you look at the tutorial that comes with the R installation?
> 
> ?plot
> ?lines
> 
> ?par   
> 
> In the last, look for the descriptions of ?col? and ?lty?.
> 
> Using plot() and lines(), and subsetting the four unique values of ?sample?, you can create your lines.
> 
> Here is a crude start, assuming your columns are part of a data frame called ?my.data?.   Untested...
> 
> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)     # blue line, not dashed
> .
> .
> .
> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)   # red dashed line
> 
> 
>> On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>> wrote:
>> 
>> Hi,
>> 
>> another naive question (i?m pretty sure :( )
>> 
>> 
>> I?m trying to plot a multiple line graph:
>> 
>>         region	       sample	       factora	        factorb	       factorc
>> 0.1	10	0.895	0.903	0.378
>> 0.2	10	0.811	0.865	0.688
>> 0.1	20	0.735	0.966	0.611
>> 0.2	20	0.777	0.732	0.653
>> 0.1	30	0.600	0.778	0.694
>> 0.2	30	0.466	174.592	0.461
>> 0.1	40	0.446	0.432	0.693
>> 0.2	40	0.392	0.294	0.686
>> 
>> 
>> 
>> The first column should be the independent variable, the second should compute a bold line for sample(10) and dash line for sample 20.
> 
> What about the other two values of ?sample??  
> 
>> The others variables are outcomes for each of the first scenarios, and so it should: the 3rd, 4th and 5th columns should be blue, red and green respectively. 
>> 
>> 
>> Resume :)
>> 
>> I should have a graph, in the x-axe should have the region and in the y axe, the factor.
>> Lines:
>> 	1 - blue and bold for region 0.1, sample 10 and factor a
>> 	2 - blue and dash for region 0.2, sample 10 and factor a
>> 	3 - red and bold for region 0.1, sample 10 and factor b
>> 	4 - red and dash for region 0.2, sample 10 and factor b
>> 	5 - green and bold for region 0.1, sample 10 and factor c
>> 	6 - green and dash for region 0.2, sample 10 and factor c
> 
> Not consistent with what you said above. These are no longer lines, but points.
>> 
>> nonetheless the independent variable is nominal, I should plot a line graph.
>> 
>> Can anyone help me please?
>> I have my file as a cvs file, so I first read that file (that I know how to do :)).
>> 
>> But I have it in that format.
>> 
>> Best,
>> RO
>> 
>> 
>> 
>> Atenciosamente,
>> Rosa Oliveira
>> 
>> -- 
>> ____________________________________________________________________________
>> 
>> 
>> Rosa Celeste dos Santos Oliveira, 
>> 
>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>> Tlm: +351 939355143 
>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>> ____________________________________________________________________________
>> "Many admire, few know"
>> Hippocrates
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
> 
> <PastedGraphic-1.tiff>
> 


From dmck at u.washington.edu  Wed Jun 10 03:41:07 2015
From: dmck at u.washington.edu (Don McKenzie)
Date: Tue, 9 Jun 2015 18:41:07 -0700
Subject: [R] graphs, need urgent help [from Rosa Oliveira]
In-Reply-To: <D2FD6C5D-E38B-4317-9FFA-6CFA6AA0D20E@gmail.com>
References: <10C1B087-6721-44B2-A347-851219672D30@gmail.com>
	<FE94928E-A651-4E9F-9643-73635938C694@u.washington.edu>
	<D2FD6C5D-E38B-4317-9FFA-6CFA6AA0D20E@gmail.com>
Message-ID: <1A0C858D-305A-4188-90B3-54083BF41FFC@u.washington.edu>

The R function plot() will draw the first line and the two axes.  You need to tell it which subsample of your data to plot, as in my example below.
So start with those two observations for which ?sample? = 10.  But if you want separate lines for each unique value of ?sample?, your lines will connect
only two data points, because you have only two instances of each of those unique values, unlike the lines in your hand-drawn graph.

Another issue is that you have a huge outlier (value very much larger than the others) in the 6th row of ?factorb?.  Is this an error?  If not, your other lines will be indistinguishable when you try to plot everything.

Part of the reason no one else has responded may be that it appears that you are confused about your own data in a way that makes it very difficult for 
us to help you.  Can you get some basic advice from someone local?  I or someone else on the list could give you the code line-by-line that we THINK you need,
but it could be wrong, given the inconsistencies in what you have shown us, and that would make everything worse.

>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)     # blue line, not dashed

Did you try plotting just this line?  What happened?


> On Jun 9, 2015, at 5:53 PM, Rosa Oliveira <rosita21 at gmail.com> wrote:
> 
> Dear Don and all,
> 
> I?ve read the tutorial and tried several codes before posting :)
> I?m really naive.
> 
> 
> 
> what I was trying to :  is something like the graph in the picture I drawee.
> 
> 
> <FullSizeRender.jpg>
> 
> Is it more clear now? 
> 
> Atenciosamente,
> Rosa Oliveira
> 
> -- 
> ____________________________________________________________________________
>  
> <smile.jpg>
> Rosa Celeste dos Santos Oliveira, 
> 
> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
> Tlm: +351 939355143 
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
> 
>> On 09 Jun 2015, at 19:23, Don McKenzie <dmck at u.washington.edu <mailto:dmck at u.washington.edu>> wrote:
>> 
>> The answer lies in learning to use the help (and knowing where to start).  Did you look at the tutorial that comes with the R installation?
>> 
>> ?plot
>> ?lines
>> 
>> ?par   
>> 
>> In the last, look for the descriptions of ?col? and ?lty?.
>> 
>> Using plot() and lines(), and subsetting the four unique values of ?sample?, you can create your lines.
>> 
>> Here is a crude start, assuming your columns are part of a data frame called ?my.data?.   Untested...
>> 
>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)     # blue line, not dashed

Did you try plotting just this line?  What happened?

>> .
>> .
>> .
>> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)   # red dashed line
>> 
>> 
>>> On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>> wrote:
>>> 
>>> Hi,
>>> 
>>> another naive question (i?m pretty sure :( )
>>> 
>>> 
>>> I?m trying to plot a multiple line graph:
>>> 
>>>         region	       sample	       factora	        factorb	       factorc
>>> 0.1	10	0.895	0.903	0.378
>>> 0.2	10	0.811	0.865	0.688
>>> 0.1	20	0.735	0.966	0.611
>>> 0.2	20	0.777	0.732	0.653
>>> 0.1	30	0.600	0.778	0.694
>>> 0.2	30	0.466	174.592	0.461
>>> 0.1	40	0.446	0.432	0.693
>>> 0.2	40	0.392	0.294	0.686
>>> 
>>> 
>>> 
>>> The first column should be the independent variable, the second should compute a bold line for sample(10) and dash line for sample 20.
>> 
>> What about the other two values of ?sample??  
>> 
>>> The others variables are outcomes for each of the first scenarios, and so it should: the 3rd, 4th and 5th columns should be blue, red and green respectively. 
>>> 
>>> 
>>> Resume :)
>>> 
>>> I should have a graph, in the x-axe should have the region and in the y axe, the factor.
>>> Lines:
>>> 	1 - blue and bold for region 0.1, sample 10 and factor a
>>> 	2 - blue and dash for region 0.2, sample 10 and factor a
>>> 	3 - red and bold for region 0.1, sample 10 and factor b
>>> 	4 - red and dash for region 0.2, sample 10 and factor b
>>> 	5 - green and bold for region 0.1, sample 10 and factor c
>>> 	6 - green and dash for region 0.2, sample 10 and factor c
>> 
>> Not consistent with what you said above. These are no longer lines, but points.
>>> 
>>> nonetheless the independent variable is nominal, I should plot a line graph.
>>> 
>>> Can anyone help me please?
>>> I have my file as a cvs file, so I first read that file (that I know how to do :)).
>>> 
>>> But I have it in that format.
>>> 
>>> Best,
>>> RO
>>> 
>>> 
>>> 
>>> Atenciosamente,
>>> Rosa Oliveira
>>> 
>>> -- 
>>> ____________________________________________________________________________
>>> 
>>> 
>>> Rosa Celeste dos Santos Oliveira, 
>>> 
>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>> Tlm: +351 939355143 
>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>> ____________________________________________________________________________
>>> "Many admire, few know"
>>> Hippocrates
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> <PastedGraphic-1.tiff>
>> 
> 




From rosita21 at gmail.com  Wed Jun 10 03:48:42 2015
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Wed, 10 Jun 2015 02:48:42 +0100
Subject: [R] graphs, need urgent help [from Rosa Oliveira]
In-Reply-To: <1A0C858D-305A-4188-90B3-54083BF41FFC@u.washington.edu>
References: <10C1B087-6721-44B2-A347-851219672D30@gmail.com>
	<FE94928E-A651-4E9F-9643-73635938C694@u.washington.edu>
	<D2FD6C5D-E38B-4317-9FFA-6CFA6AA0D20E@gmail.com>
	<1A0C858D-305A-4188-90B3-54083BF41FFC@u.washington.edu>
Message-ID: <23EFA17D-E86A-4372-942C-19121F8B1169@gmail.com>

Dear Don,

I done the plot and the lines, and it?s  fine.
I?ll have 10 values on sample. It?s generating (on simulation), that?s why that huge outlier, and the other missing points.

The graph I?ve done, is just an example, just to illustrate what I have to get, but off course with 10 points in sample, and all the other specificityies.

Best,
RO

Atenciosamente,
Rosa Oliveira

-- 
____________________________________________________________________________


Rosa Celeste dos Santos Oliveira, 

E-mail: rosita21 at gmail.com
Tlm: +351 939355143 
Linkedin: https://pt.linkedin.com/in/rosacsoliveira
____________________________________________________________________________
"Many admire, few know"
Hippocrates

> On 10 Jun 2015, at 02:41, Don McKenzie <dmck at u.washington.edu> wrote:
> 
> The R function plot() will draw the first line and the two axes.  You need to tell it which subsample of your data to plot, as in my example below.
> So start with those two observations for which ?sample? = 10.  But if you want separate lines for each unique value of ?sample?, your lines will connect
> only two data points, because you have only two instances of each of those unique values, unlike the lines in your hand-drawn graph.
> 
> Another issue is that you have a huge outlier (value very much larger than the others) in the 6th row of ?factorb?.  Is this an error?  If not, your other lines will be indistinguishable when you try to plot everything.
> 
> Part of the reason no one else has responded may be that it appears that you are confused about your own data in a way that makes it very difficult for 
> us to help you.  Can you get some basic advice from someone local?  I or someone else on the list could give you the code line-by-line that we THINK you need,
> but it could be wrong, given the inconsistencies in what you have shown us, and that would make everything worse.
> 
>>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)     # blue line, not dashed
> 
> Did you try plotting just this line?  What happened?
> 
> 
>> On Jun 9, 2015, at 5:53 PM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>> wrote:
>> 
>> Dear Don and all,
>> 
>> I?ve read the tutorial and tried several codes before posting :)
>> I?m really naive.
>> 
>> 
>> 
>> what I was trying to :  is something like the graph in the picture I drawee.
>> 
>> 
>> <FullSizeRender.jpg>
>> 
>> Is it more clear now? 
>> 
>> Atenciosamente,
>> Rosa Oliveira
>> 
>> -- 
>> ____________________________________________________________________________
>>  
>> <smile.jpg>
>> Rosa Celeste dos Santos Oliveira, 
>> 
>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>> Tlm: +351 939355143 
>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>> ____________________________________________________________________________
>> "Many admire, few know"
>> Hippocrates
>> 
>>> On 09 Jun 2015, at 19:23, Don McKenzie <dmck at u.washington.edu <mailto:dmck at u.washington.edu>> wrote:
>>> 
>>> The answer lies in learning to use the help (and knowing where to start).  Did you look at the tutorial that comes with the R installation?
>>> 
>>> ?plot
>>> ?lines
>>> 
>>> ?par   
>>> 
>>> In the last, look for the descriptions of ?col? and ?lty?.
>>> 
>>> Using plot() and lines(), and subsetting the four unique values of ?sample?, you can create your lines.
>>> 
>>> Here is a crude start, assuming your columns are part of a data frame called ?my.data?.   Untested...
>>> 
>>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)     # blue line, not dashed
> 
> Did you try plotting just this line?  What happened?
> 
>>> .
>>> .
>>> .
>>> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)   # red dashed line
>>> 
>>> 
>>>> On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>> wrote:
>>>> 
>>>> Hi,
>>>> 
>>>> another naive question (i?m pretty sure :( )
>>>> 
>>>> 
>>>> I?m trying to plot a multiple line graph:
>>>> 
>>>>         region	       sample	       factora	        factorb	       factorc
>>>> 0.1	10	0.895	0.903	0.378
>>>> 0.2	10	0.811	0.865	0.688
>>>> 0.1	20	0.735	0.966	0.611
>>>> 0.2	20	0.777	0.732	0.653
>>>> 0.1	30	0.600	0.778	0.694
>>>> 0.2	30	0.466	174.592	0.461
>>>> 0.1	40	0.446	0.432	0.693
>>>> 0.2	40	0.392	0.294	0.686
>>>> 
>>>> 
>>>> 
>>>> The first column should be the independent variable, the second should compute a bold line for sample(10) and dash line for sample 20.
>>> 
>>> What about the other two values of ?sample??  
>>> 
>>>> The others variables are outcomes for each of the first scenarios, and so it should: the 3rd, 4th and 5th columns should be blue, red and green respectively. 
>>>> 
>>>> 
>>>> Resume :)
>>>> 
>>>> I should have a graph, in the x-axe should have the region and in the y axe, the factor.
>>>> Lines:
>>>> 	1 - blue and bold for region 0.1, sample 10 and factor a
>>>> 	2 - blue and dash for region 0.2, sample 10 and factor a
>>>> 	3 - red and bold for region 0.1, sample 10 and factor b
>>>> 	4 - red and dash for region 0.2, sample 10 and factor b
>>>> 	5 - green and bold for region 0.1, sample 10 and factor c
>>>> 	6 - green and dash for region 0.2, sample 10 and factor c
>>> 
>>> Not consistent with what you said above. These are no longer lines, but points.
>>>> 
>>>> nonetheless the independent variable is nominal, I should plot a line graph.
>>>> 
>>>> Can anyone help me please?
>>>> I have my file as a cvs file, so I first read that file (that I know how to do :)).
>>>> 
>>>> But I have it in that format.
>>>> 
>>>> Best,
>>>> RO
>>>> 
>>>> 
>>>> 
>>>> Atenciosamente,
>>>> Rosa Oliveira
>>>> 
>>>> -- 
>>>> ____________________________________________________________________________
>>>> 
>>>> 
>>>> Rosa Celeste dos Santos Oliveira, 
>>>> 
>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>> Tlm: +351 939355143 
>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>>> ____________________________________________________________________________
>>>> "Many admire, few know"
>>>> Hippocrates
>>>> 
>>>> 
>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> <PastedGraphic-1.tiff>
>>> 
>> 
> 
> <PastedGraphic-1.tiff>
> 


From mylisttech at gmail.com  Wed Jun 10 08:28:22 2015
From: mylisttech at gmail.com (My List)
Date: Wed, 10 Jun 2015 11:58:22 +0530
Subject: [R] How to validate the cluster analysis?
Message-ID: <CAFpdVnxaFXVkM0ELEFd7CG+nz9_vrH922ikxbyP0AtuKhOWzzg@mail.gmail.com>

All,

I am new to the world of statistics. I am interested in finding out the
validation techniques employed on a cluster analysis. Any point of
reference or site would be helpful. I have read about the clValid package
and usage of the function on cluster.stats() in the fpc package.

Thanks in Advance,
Harmeet

PS: I have marked this mail to both help and devel list. Is it ok?

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Wed Jun 10 12:33:34 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 10 Jun 2015 12:33:34 +0200
Subject: [R] Cross-over Data with Kenward-Roger correction
In-Reply-To: <loom.20150608T224714-771@post.gmane.org>
References: <695109458.7792923.1433647542770.JavaMail.yahoo@mail.yahoo.com>
	<loom.20150608T224714-771@post.gmane.org>
Message-ID: <03A92746-1D26-42FA-B746-C17674A2D458@gmail.com>


On 08 Jun 2015, at 22:59 , Ben Bolker <bbolker at gmail.com> wrote:

> As a statistical point, I don't understand why you can't just
> do a paired t-test on these data??

It's a cross-over trial, so you need to account for the period effect. However, a standard way of treating it is by to calculate period differences within subjects and use a t-test (welch or classical) to see if the differ according to sequence (trt1-trt2 or v.v.).

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From drjimlemon at gmail.com  Wed Jun 10 12:51:52 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 10 Jun 2015 20:51:52 +1000
Subject: [R] graphs, need urgent help (deadline :( )
In-Reply-To: <D2FD6C5D-E38B-4317-9FFA-6CFA6AA0D20E@gmail.com>
References: <10C1B087-6721-44B2-A347-851219672D30@gmail.com>
	<FE94928E-A651-4E9F-9643-73635938C694@u.washington.edu>
	<D2FD6C5D-E38B-4317-9FFA-6CFA6AA0D20E@gmail.com>
Message-ID: <CA+8X3fWPwaAVJPWtMiB4f2Vpa6Zf3jvq+i264UgTB_3FgoomGA@mail.gmail.com>

Hi Rosa,
Like Don, I can't work out what you want and I don't even have the
picture. For example, your specification of color and line type leaves
only one point for each color and line type, and the line from one
point to the same point is not going to show up. Here is a possibility
that may lead (eventually) to a solution.

library(plotrix)
par(tcl=-0.1)
gap.plot(x=rep(seq(10,45,by=5),3),
 y=unlist(my.data[,c("factora","factorb","factorc")]),
 main="A plot of factorial mystery",
 gap=c(1.1,174),ylim=c(0,175),ylab="factor score",xlab="Group",
 xticlab=c(" \n0.1\n10"," \n0.2\n10"," \n0.1\n20"," \n0.2\n20",
  " \n0.1\n30"," \n0.2\n30"," \n0.1\n40"," \n0.2\n40"),
 ytics=c(0,0.5,1,174.59),pch=rep(1:3,each=8),col=rep(c(4,2,3),each=8))
mtext(c("Region","Sample"),side=1,at=6,line=c(0,1))
lines(seq(10,45,by=5),my.data$factora,col=4)
lines(seq(10,45,by=5),my.data$factorb[c(1:5,NA,7,8)],col=2)
lines(seq(10,45,by=5),my.data$factorc,col=3)

Jim


On Wed, Jun 10, 2015 at 10:53 AM, Rosa Oliveira <rosita21 at gmail.com> wrote:
> Dear Don and all,
>
> I?ve read the tutorial and tried several codes before posting :)
> I?m really naive.
>
>
>
> what I was trying to :  is something like the graph in the picture I drawee.
>
>
>
>
> Is it more clear now?
>
> Atenciosamente,
> Rosa Oliveira
>
> --
> ____________________________________________________________________________
>
>
> Rosa Celeste dos Santos Oliveira,
>
> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
> Tlm: +351 939355143
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
>
>> On 09 Jun 2015, at 19:23, Don McKenzie <dmck at u.washington.edu <mailto:dmck at u.washington.edu>> wrote:
>>
>> The answer lies in learning to use the help (and knowing where to start).  Did you look at the tutorial that comes with the R installation?
>>
>> ?plot
>> ?lines
>>
>> ?par
>>
>> In the last, look for the descriptions of ?col? and ?lty?.
>>
>> Using plot() and lines(), and subsetting the four unique values of ?sample?, you can create your lines.
>>
>> Here is a crude start, assuming your columns are part of a data frame called ?my.data?.   Untested...
>>
>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)     # blue line, not dashed
>> .
>> .
>> .
>> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)   # red dashed line
>>
>>
>>> On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>> wrote:
>>>
>>> Hi,
>>>
>>> another naive question (i?m pretty sure :( )
>>>
>>>
>>> I?m trying to plot a multiple line graph:
>>>
>>>         region              sample          factora          factorb        factorc
>>> 0.1  10      0.895   0.903   0.378
>>> 0.2  10      0.811   0.865   0.688
>>> 0.1  20      0.735   0.966   0.611
>>> 0.2  20      0.777   0.732   0.653
>>> 0.1  30      0.600   0.778   0.694
>>> 0.2  30      0.466   174.592 0.461
>>> 0.1  40      0.446   0.432   0.693
>>> 0.2  40      0.392   0.294   0.686
>>>
>>>
>>>
>>> The first column should be the independent variable, the second should compute a bold line for sample(10) and dash line for sample 20.
>>
>> What about the other two values of ?sample??
>>
>>> The others variables are outcomes for each of the first scenarios, and so it should: the 3rd, 4th and 5th columns should be blue, red and green respectively.
>>>
>>>
>>> Resume :)
>>>
>>> I should have a graph, in the x-axe should have the region and in the y axe, the factor.
>>> Lines:
>>>      1 - blue and bold for region 0.1, sample 10 and factor a
>>>      2 - blue and dash for region 0.2, sample 10 and factor a
>>>      3 - red and bold for region 0.1, sample 10 and factor b
>>>      4 - red and dash for region 0.2, sample 10 and factor b
>>>      5 - green and bold for region 0.1, sample 10 and factor c
>>>      6 - green and dash for region 0.2, sample 10 and factor c
>>
>> Not consistent with what you said above. These are no longer lines, but points.
>>>
>>> nonetheless the independent variable is nominal, I should plot a line graph.
>>>
>>> Can anyone help me please?
>>> I have my file as a cvs file, so I first read that file (that I know how to do :)).
>>>
>>> But I have it in that format.
>>>
>>> Best,
>>> RO
>>>
>>>
>>>
>>> Atenciosamente,
>>> Rosa Oliveira
>>>
>>> --
>>> ____________________________________________________________________________
>>>
>>>
>>> Rosa Celeste dos Santos Oliveira,
>>>
>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>> Tlm: +351 939355143
>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>> ____________________________________________________________________________
>>> "Many admire, few know"
>>> Hippocrates
>>>
>>>
>>>      [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> <PastedGraphic-1.tiff>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dheeraj.khatri at abzooba.com  Wed Jun 10 12:20:59 2015
From: dheeraj.khatri at abzooba.com (khatri)
Date: Wed, 10 Jun 2015 03:20:59 -0700 (PDT)
Subject: [R] reading as date
Message-ID: <1433931659996-4708431.post@n4.nabble.com>

My date column is in following format : "%m/%d H:M:S" 
There is not mention of year in the data.So how can I read this using
strptime function.
I have tried strptime(dates,"%m/%d H:M:S") but this is returning NA.
Thanks



--
View this message in context: http://r.789695.n4.nabble.com/reading-as-date-tp4708431.html
Sent from the R help mailing list archive at Nabble.com.


From roslinaump at gmail.com  Wed Jun 10 09:46:46 2015
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Wed, 10 Jun 2015 15:46:46 +0800
Subject: [R] Change Julian function in SPlus to R date code
Message-ID: <CANTvJZLmV4Ry57FerFmp=jYpGw_a2Ue_TTzbMjq-QNqVad9pVg@mail.gmail.com>

Dear r-users,

I have a code in SPlus which use julian function.  What is the similar code
used in R?

define.date1<-function(dt1,mt1,mt2,nn,da)
{ mt2<-mt2+1
start<-julian(mt1, 1, nn, origin=c(month=1, day=1, year=1971))+1
end<-julian(mt2, 1, nn, origin=c(month=1, day=1, year=1971))+da
a<-dt1[start:end,]
am<-as.matrix(a[,5])
}

I have check the Date package in R but not so sure how to adjust it.

Thank you for any help given.

	[[alternative HTML version deleted]]


From maillists at nic.fi  Wed Jun 10 13:54:55 2015
From: maillists at nic.fi (K. Elo)
Date: Wed, 10 Jun 2015 14:54:55 +0300
Subject: [R] reading as date
In-Reply-To: <1433931659996-4708431.post@n4.nabble.com>
References: <1433931659996-4708431.post@n4.nabble.com>
Message-ID: <5578258F.4040905@nic.fi>

Hi!

10.06.2015, 13:20, khatri wrote:
> My date column is in following format : "%m/%d H:M:S"
> There is not mention of year in the data.So how can I read this using
> strptime function.
> I have tried strptime(dates,"%m/%d H:M:S") but this is returning NA.
> Thanks

How about:

strptime(dates,"%m/%d %H:%M:%S")

Some data could also be helpful for testing...

HTH,
Kimmo


From drjimlemon at gmail.com  Wed Jun 10 13:58:14 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 10 Jun 2015 21:58:14 +1000
Subject: [R] reading as date
In-Reply-To: <1433931659996-4708431.post@n4.nabble.com>
References: <1433931659996-4708431.post@n4.nabble.com>
Message-ID: <CA+8X3fU_TmEv=Fr5FkmUYkH7cx8Xpnh4gyRMKpsu_7JqSUsAAQ@mail.gmail.com>

Hi khatri,

strptime("6/20 21:56:32","%m/%d %H:%M:%S")
[1] "2015-06-20 21:56:32 AEST"

You forgot the % signs in the format for H:M:S

Jim

On Wed, Jun 10, 2015 at 8:20 PM, khatri <dheeraj.khatri at abzooba.com> wrote:
> My date column is in following format : "%m/%d H:M:S"
> There is not mention of year in the data.So how can I read this using
> strptime function.
> I have tried strptime(dates,"%m/%d H:M:S") but this is returning NA.
> Thanks
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/reading-as-date-tp4708431.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Wed Jun 10 14:08:44 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 10 Jun 2015 07:08:44 -0500
Subject: [R] Change Julian function in SPlus to R date code
In-Reply-To: <CANTvJZLmV4Ry57FerFmp=jYpGw_a2Ue_TTzbMjq-QNqVad9pVg@mail.gmail.com>
References: <CANTvJZLmV4Ry57FerFmp=jYpGw_a2Ue_TTzbMjq-QNqVad9pVg@mail.gmail.com>
Message-ID: <CAN5YmCEtGT_+MgdSE1fTfG0uCNZaevLa-5LGy18J+O6w4vUc5w@mail.gmail.com>

Try looking at the julian() function in base ...

?julian

Jean

On Wed, Jun 10, 2015 at 2:46 AM, roslinazairimah zakaria <
roslinaump at gmail.com> wrote:

> Dear r-users,
>
> I have a code in SPlus which use julian function.  What is the similar code
> used in R?
>
> define.date1<-function(dt1,mt1,mt2,nn,da)
> { mt2<-mt2+1
> start<-julian(mt1, 1, nn, origin=c(month=1, day=1, year=1971))+1
> end<-julian(mt2, 1, nn, origin=c(month=1, day=1, year=1971))+da
> a<-dt1[start:end,]
> am<-as.matrix(a[,5])
> }
>
> I have check the Date package in R but not so sure how to adjust it.
>
> Thank you for any help given.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From venkynov10 at gmail.com  Wed Jun 10 14:15:15 2015
From: venkynov10 at gmail.com (venkadesan venky)
Date: Wed, 10 Jun 2015 17:45:15 +0530
Subject: [R] Symbols to data set
Message-ID: <CAAM-fZ7p7CZ4HFkib-aBZqkpo=4M9Zzu+Sq9RVPO7szYJju1Mg@mail.gmail.com>

Hello Friends,

I have a data like this

place          Rupees          Percentage      Dollars

India          120000            52                    48
USA          78000              56                    40
UK             60000              50                   56

and i want to make Rupees column as a thousand Separator(Commas) and
Percentage column as a percentage symbol and Dollars column as a Dollars
symbols. by using one line command.

please help to find out this

	[[alternative HTML version deleted]]


From dheeraj.khatri at abzooba.com  Wed Jun 10 14:03:01 2015
From: dheeraj.khatri at abzooba.com (khatri)
Date: Wed, 10 Jun 2015 05:03:01 -0700 (PDT)
Subject: [R] reading as date
In-Reply-To: <5578258F.4040905@nic.fi>
References: <1433931659996-4708431.post@n4.nabble.com>
	<5578258F.4040905@nic.fi>
Message-ID: <1433937781684-4708441.post@n4.nabble.com>

Hey sorry for my typing.
I have actually used the same format with % that is 


> dd<-c("21/01 11:11:11")
> strptime(dd,"%d/%m H:M:S") 
[1] NA


it is giving NA.



--
View this message in context: http://r.789695.n4.nabble.com/reading-as-date-tp4708434p4708441.html
Sent from the R help mailing list archive at Nabble.com.


From ssefick at gmail.com  Wed Jun 10 14:26:25 2015
From: ssefick at gmail.com (stephen sefick)
Date: Wed, 10 Jun 2015 07:26:25 -0500
Subject: [R] How to validate the cluster analysis?
In-Reply-To: <CAFpdVnxaFXVkM0ELEFd7CG+nz9_vrH922ikxbyP0AtuKhOWzzg@mail.gmail.com>
References: <CAFpdVnxaFXVkM0ELEFd7CG+nz9_vrH922ikxbyP0AtuKhOWzzg@mail.gmail.com>
Message-ID: <CADKEMqh16h8d-yABW86mMcp_ZxUj_KSBzpBYO21ThR5mQSiqPQ@mail.gmail.com>

You could look at silhouette width in, I think, the cluster package.

Please excuse my brevity; this message was sent from my telephone.
On Jun 10, 2015 1:37 AM, "My List" <mylisttech at gmail.com> wrote:

> All,
>
> I am new to the world of statistics. I am interested in finding out the
> validation techniques employed on a cluster analysis. Any point of
> reference or site would be helpful. I have read about the clValid package
> and usage of the function on cluster.stats() in the fpc package.
>
> Thanks in Advance,
> Harmeet
>
> PS: I have marked this mail to both help and devel list. Is it ok?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Jun 10 14:44:56 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 10 Jun 2015 08:44:56 -0400
Subject: [R] reading as date
In-Reply-To: <1433937781684-4708441.post@n4.nabble.com>
References: <1433931659996-4708431.post@n4.nabble.com>
	<5578258F.4040905@nic.fi>
	<1433937781684-4708441.post@n4.nabble.com>
Message-ID: <CAM_vjumfYU7BrzGE6Vvc=4b5c6U6FAc9vCYkk4OdUnja6ShcYg@mail.gmail.com>

No really, what Jim said: you need the % for H:M:S as well.

> dd<-c("21/01 11:11:11")
> strptime(dd,"%d/%m %H:%M:%S")
[1] "2015-01-21 11:11:11 EST"

On Wed, Jun 10, 2015 at 8:03 AM, khatri <dheeraj.khatri at abzooba.com> wrote:
> Hey sorry for my typing.
> I have actually used the same format with % that is
>
>
>> dd<-c("21/01 11:11:11")
>> strptime(dd,"%d/%m H:M:S")
> [1] NA
>
>
> it is giving NA.
>
>
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From jdnewmil at dcn.davis.CA.us  Wed Jun 10 14:49:09 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 10 Jun 2015 05:49:09 -0700
Subject: [R] reading as date
In-Reply-To: <1433937781684-4708441.post@n4.nabble.com>
References: <1433931659996-4708431.post@n4.nabble.com>
	<5578258F.4040905@nic.fi>
	<1433937781684-4708441.post@n4.nabble.com>
Message-ID: <9D0DA71B-7475-4210-8CF2-A04E9B9BF88F@dcn.davis.CA.us>

Your example is not the same as the answers you have received. Look again.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 10, 2015 5:03:01 AM PDT, khatri <dheeraj.khatri at abzooba.com> wrote:
>Hey sorry for my typing.
>I have actually used the same format with % that is 
>
>
>> dd<-c("21/01 11:11:11")
>> strptime(dd,"%d/%m H:M:S") 
>[1] NA
>
>
>it is giving NA.
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/reading-as-date-tp4708434p4708441.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Wed Jun 10 15:04:32 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 10 Jun 2015 05:04:32 -0800
Subject: [R] Summarizing data based on Date
In-Reply-To: <1433915507567-4708423.post@n4.nabble.com>
References: <1433750889045-4708328.post@n4.nabble.com>
Message-ID: <1521260860C.00001072jrkrideau@inbox.com>

Hi Shivi

I think the names issue is just that that is aggregate()'s default. Just rename using ?names

For the 'sort' problem, AFAIK you cannot sort within aggregate(), at least not how you are doing it, nor do you want to do a sort().  You need ?order for what you want to do with a data.frame.

Sort is for vectors 

Does this do what you want?

dat1  <-  structure(list(dd = structure(c(1426204800, 1427760000, 1426377600,
1426550400, 1426550400, 1426032000, 1426032000, 1426723200), tzone = "UTC", class =
c("POSIXct",
"POSIXt")), wt = c(0, 0, 0, 770, 3.73, 70, 10, 500)), .Names = c("dd",
"wt"), row.names = c(NA, -8L), class = "data.frame")

str(dat1)

dat2  <-  aggregate(dat1$wt, list(dat1$dd), sum)

names(dat2)  <-  c("dd", "wt")

dat2 [order(dat2$dd),]

John Kane
Kingston ON Canada


> -----Original Message-----
> From: shivibhatia at ymail.com
> Sent: Tue, 9 Jun 2015 22:51:47 -0700 (PDT)
> To: r-help at r-project.org
> Subject: Re: [R] Summarizing data based on Date
> 
> HI All,
> 
> I am able to get the desired result. Thanks for extending help.
> while reading the csv file I made some changes as :
> 
> Test<-read.csv("Testdata.csv", head=TRUE, stringsAsFactors = FALSE,
> strip.white = TRUE)
> with this character var were not changed to factors.
> 
> Then aggregation was simple:
> aggregate(test$CHG_WT, list(test$CR_DT), sum)
> 
> However the output is not sorted based on Dates and the columns names
> appearing as very different:
> 
> Group.1       x
> 1   1-Mar-15  909791
> 2  10-Mar-15  822436
> 3  11-Mar-15  848609
> 4  12-Mar-15  924842
> 5  13-Mar-15  895270
> 6  14-Mar-15  93238
> 7 2-Mar-15     731600
> 
> Can you all please suggest why the column names are so different and how
> I
> could sort based on dates. I added the sort option in the above syntax
> aggregate(test$CHG_WT, list(test$CR_DT), sum,sort(test$CR_DT,decreasing =
> TRUE))
> 
> But it gave me an error:
> Error in FUN(X[[i]], ...) : invalid 'type' (character) of argument
> Thanks All.
> 
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Summarizing-data-based-on-Date-tp4708328p4708423.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From jrkrideau at inbox.com  Wed Jun 10 15:13:46 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 10 Jun 2015 05:13:46 -0800
Subject: [R] graphs, need urgent help (deadline :( )
In-Reply-To: <CA+8X3fWPwaAVJPWtMiB4f2Vpa6Zf3jvq+i264UgTB_3FgoomGA@mail.gmail.com>
References: <10c1b087-6721-44b2-a347-851219672d30@gmail.com>
	<d2fd6c5d-e38b-4317-9ffa-6cfa6aa0d20e@gmail.com>
	<fe94928e-a651-4e9f-9643-73635938c694@u.washington.edu>
Message-ID: <1535CE35A5D.00001088jrkrideau@inbox.com>

Hi Jim,

I was looking at that last night and had the same problem of visualizing what Rosa needed.  

Hi Rosa
This is nothing like what you wanted and I really don't understand your data but would something like this work as a substitute or am I completely lost?


dat1  <-  structure(list(region = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 
0.2), sample = c(10L, 10L, 20L, 20L, 30L, 30L, 40L, 40L), factora = c(0.895, 
0.811, 0.735, 0.777, 0.6, 0.466, 0.446, 0.392), factorb = c(0.903, 
0.865, 0.966, 0.732, 0.778, 0.592, 0.432, 0.294), factorc = c(0.37, 
0.688, 0.611, 0.653, 0.694, 0.461, 0.693, 0.686)), .Names = c("region", 
"sample", "factora", "factorb", "factorc"), class = "data.frame", row.names = c(NA, 
-8L))


mdat1  <-   melt(dat1, id.var = c("region", "sample"),
                    variable.name = "factor",
                    value.name = "value")
str(mdat1)
 
ggplot(mdat1, aes(region, value, colour = factor)) +
                geom_line() + facet_grid(sample ~ .)

John Kane
Kingston ON Canada


> -----Original Message-----
> From: drjimlemon at gmail.com
> Sent: Wed, 10 Jun 2015 20:51:52 +1000
> To: rosita21 at gmail.com
> Subject: Re: [R] graphs, need urgent help (deadline :( )
> 
> Hi Rosa,
> Like Don, I can't work out what you want and I don't even have the
> picture. For example, your specification of color and line type leaves
> only one point for each color and line type, and the line from one
> point to the same point is not going to show up. Here is a possibility
> that may lead (eventually) to a solution.
> 
> library(plotrix)
> par(tcl=-0.1)
> gap.plot(x=rep(seq(10,45,by=5),3),
>  y=unlist(my.data[,c("factora","factorb","factorc")]),
>  main="A plot of factorial mystery",
>  gap=c(1.1,174),ylim=c(0,175),ylab="factor score",xlab="Group",
>  xticlab=c(" \n0.1\n10"," \n0.2\n10"," \n0.1\n20"," \n0.2\n20",
>   " \n0.1\n30"," \n0.2\n30"," \n0.1\n40"," \n0.2\n40"),
>  ytics=c(0,0.5,1,174.59),pch=rep(1:3,each=8),col=rep(c(4,2,3),each=8))
> mtext(c("Region","Sample"),side=1,at=6,line=c(0,1))
> lines(seq(10,45,by=5),my.data$factora,col=4)
> lines(seq(10,45,by=5),my.data$factorb[c(1:5,NA,7,8)],col=2)
> lines(seq(10,45,by=5),my.data$factorc,col=3)
> 
> Jim
> 
> 
> On Wed, Jun 10, 2015 at 10:53 AM, Rosa Oliveira <rosita21 at gmail.com>
> wrote:
>> Dear Don and all,
>> 
>> I?ve read the tutorial and tried several codes before posting :)
>> I?m really naive.
>> 
>> 
>> 
>> what I was trying to :  is something like the graph in the picture I
>> drawee.
>> 
>> 
>> 
>> 
>> Is it more clear now?
>> 
>> Atenciosamente,
>> Rosa Oliveira
>> 
>> --
>> ____________________________________________________________________________
>> 
>> 
>> Rosa Celeste dos Santos Oliveira,
>> 
>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>> Tlm: +351 939355143
>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>> <https://pt.linkedin.com/in/rosacsoliveira>
>> ____________________________________________________________________________
>> "Many admire, few know"
>> Hippocrates
>> 
>>> On 09 Jun 2015, at 19:23, Don McKenzie <dmck at u.washington.edu
>>> <mailto:dmck at u.washington.edu>> wrote:
>>> 
>>> The answer lies in learning to use the help (and knowing where to
>>> start).  Did you look at the tutorial that comes with the R
>>> installation?
>>> 
>>> ?plot
>>> ?lines
>>> 
>>> ?par
>>> 
>>> In the last, look for the descriptions of ?col? and ?lty?.
>>> 
>>> Using plot() and lines(), and subsetting the four unique values of
>>> ?sample?, you can create your lines.
>>> 
>>> Here is a crude start, assuming your columns are part of a data frame
>>> called ?my.data?.   Untested...
>>> 
plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)
>>> # blue line, not dashed
>>> .
>>> .
>>> .
lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
>>> # red dashed line
>>> 
>>> 
>>>> On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com
>>>> <mailto:rosita21 at gmail.com>> wrote:
>>>> 
>>>> Hi,
>>>> 
>>>> another naive question (i?m pretty sure :( )
>>>> 
>>>> 
>>>> I?m trying to plot a multiple line graph:
>>>> 
>>>>         region              sample          factora          factorb
>>>> factorc
>>>> 0.1  10      0.895   0.903   0.378
>>>> 0.2  10      0.811   0.865   0.688
>>>> 0.1  20      0.735   0.966   0.611
>>>> 0.2  20      0.777   0.732   0.653
>>>> 0.1  30      0.600   0.778   0.694
>>>> 0.2  30      0.466   174.592 0.461
>>>> 0.1  40      0.446   0.432   0.693
>>>> 0.2  40      0.392   0.294   0.686
>>>> 
>>>> 
>>>> 
>>>> The first column should be the independent variable, the second should
>>>> compute a bold line for sample(10) and dash line for sample 20.
>>> 
>>> What about the other two values of ?sample??
>>> 
>>>> The others variables are outcomes for each of the first scenarios, and
>>>> so it should: the 3rd, 4th and 5th columns should be blue, red and
>>>> green respectively.
>>>> 
>>>> 
>>>> Resume :)
>>>> 
>>>> I should have a graph, in the x-axe should have the region and in the
>>>> y axe, the factor.
>>>> Lines:
>>>>      1 - blue and bold for region 0.1, sample 10 and factor a
>>>>      2 - blue and dash for region 0.2, sample 10 and factor a
>>>>      3 - red and bold for region 0.1, sample 10 and factor b
>>>>      4 - red and dash for region 0.2, sample 10 and factor b
>>>>      5 - green and bold for region 0.1, sample 10 and factor c
>>>>      6 - green and dash for region 0.2, sample 10 and factor c
>>> 
>>> Not consistent with what you said above. These are no longer lines, but
>>> points.
>>>> 
>>>> nonetheless the independent variable is nominal, I should plot a line
>>>> graph.
>>>> 
>>>> Can anyone help me please?
>>>> I have my file as a cvs file, so I first read that file (that I know
>>>> how to do :)).
>>>> 
>>>> But I have it in that format.
>>>> 
>>>> Best,
>>>> RO
>>>> 
>>>> 
>>>> 
>>>> Atenciosamente,
>>>> Rosa Oliveira
>>>> 
>>>> --
>>>> ____________________________________________________________________________
>>>> 
>>>> 
>>>> Rosa Celeste dos Santos Oliveira,
>>>> 
>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>> Tlm: +351 939355143
>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>>>> <https://pt.linkedin.com/in/rosacsoliveira>
>>>> ____________________________________________________________________________
>>>> "Many admire, few know"
>>>> Hippocrates
>>>> 
>>>> 
>>>>      [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
>>>> UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> <http://www.r-project.org/posting-guide.html>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> <PastedGraphic-1.tiff>
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jrkrideau at inbox.com  Wed Jun 10 15:22:37 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 10 Jun 2015 05:22:37 -0800
Subject: [R] How to validate the cluster analysis?
In-Reply-To: <CAFpdVnxaFXVkM0ELEFd7CG+nz9_vrH922ikxbyP0AtuKhOWzzg@mail.gmail.com>
Message-ID: <1549945E03D.000010A8jrkrideau@inbox.com>

Hi Harmeet,

Welcome to R-help but I think you are here too soon.  This is a list for helping people do things in R once they have some idea of what tey need to do  in terms of statistics etc.  There are mobs of stats experts here but this not the list you should be asking in unless I am misunderstanding you.


I'd suggest reading some texts on cluster analysis and enquiring in http://stats.stackexchange.com/ for some opinions and help.  

If I misunderstood where you are at in your project and need concrete advice on packages, please excuse me.  

If I did misunderstand then you might find http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html useful resources on how to frame questions here.  

John Kane
Kingston ON Canada


> -----Original Message-----
> From: mylisttech at gmail.com
> Sent: Wed, 10 Jun 2015 11:58:22 +0530
> To: r-help at r-project.org, r-devel at r-project.org
> Subject: [R] How to validate the cluster analysis?
> 
> All,
> 
> I am new to the world of statistics. I am interested in finding out the
> validation techniques employed on a cluster analysis. Any point of
> reference or site would be helpful. I have read about the clValid package
> and usage of the function on cluster.stats() in the fpc package.
> 
> Thanks in Advance,
> Harmeet
> 
> PS: I have marked this mail to both help and devel list. Is it ok?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From bob at rudis.net  Wed Jun 10 15:45:10 2015
From: bob at rudis.net (boB Rudis)
Date: Wed, 10 Jun 2015 09:45:10 -0400
Subject: [R] Change Julian function in SPlus to R date code
In-Reply-To: <CAN5YmCEtGT_+MgdSE1fTfG0uCNZaevLa-5LGy18J+O6w4vUc5w@mail.gmail.com>
References: <CANTvJZLmV4Ry57FerFmp=jYpGw_a2Ue_TTzbMjq-QNqVad9pVg@mail.gmail.com>
	<CAN5YmCEtGT_+MgdSE1fTfG0uCNZaevLa-5LGy18J+O6w4vUc5w@mail.gmail.com>
Message-ID: <CAJ4QxaO5Fzi4XmNKo3hkNC=yKcN8i7V93dzH-Ne6gmGkN4jtjA@mail.gmail.com>

The parameters for the built-in julian() are a bit different. This
should be what you can use:

start <- julian(as.Date(sprintf("%d-%d-%d", nn, mt1, 1)),
                origin=as.Date("1971-01-01"))
end <- julian(as.Date(sprintf("%d-%d-%d", nn, mt2, 1)),
              origin=as.Date("1971-01-01"))

On Wed, Jun 10, 2015 at 8:08 AM, Adams, Jean <jvadams at usgs.gov> wrote:
> Try looking at the julian() function in base ...
>
> ?julian
>
> Jean
>
> On Wed, Jun 10, 2015 at 2:46 AM, roslinazairimah zakaria <
> roslinaump at gmail.com> wrote:
>
>> Dear r-users,
>>
>> I have a code in SPlus which use julian function.  What is the similar code
>> used in R?
>>
>> define.date1<-function(dt1,mt1,mt2,nn,da)
>> { mt2<-mt2+1
>> start<-julian(mt1, 1, nn, origin=c(month=1, day=1, year=1971))+1
>> end<-julian(mt2, 1, nn, origin=c(month=1, day=1, year=1971))+da
>> a<-dt1[start:end,]
>> am<-as.matrix(a[,5])
>> }
>>
>> I have check the Date package in R but not so sure how to adjust it.
>>
>> Thank you for any help given.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Jun 10 16:19:54 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 10 Jun 2015 07:19:54 -0700
Subject: [R] How to validate the cluster analysis?
In-Reply-To: <1549945E03D.000010A8jrkrideau@inbox.com>
References: <1549945E03D.000010A8jrkrideau@inbox.com>
Message-ID: <C85D1044-976F-4AAF-8B10-7961A5D433EB@dcn.davis.CA.us>

>> PS: I have marked this mail to both help and devel list. Is it ok?

No.

>> 	[[alternative HTML version deleted]]

Failing to post in plain text format on this list can quickly lead to miscommunication.

Note that reading the Posting Guide would have addressed both of these issues.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 10, 2015 6:22:37 AM PDT, John Kane <jrkrideau at inbox.com> wrote:
>Hi Harmeet,
>
>Welcome to R-help but I think you are here too soon.  This is a list
>for helping people do things in R once they have some idea of what tey
>need to do  in terms of statistics etc.  There are mobs of stats
>experts here but this not the list you should be asking in unless I am
>misunderstanding you.
>
>
>I'd suggest reading some texts on cluster analysis and enquiring in
>http://stats.stackexchange.com/ for some opinions and help.  
>
>If I misunderstood where you are at in your project and need concrete
>advice on packages, please excuse me.  
>
>If I did misunderstand then you might find
>http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>and http://adv-r.had.co.nz/Reproducibility.html useful resources on how
>to frame questions here.  
>
>John Kane
>Kingston ON Canada
>
>
>> -----Original Message-----
>> From: mylisttech at gmail.com
>> Sent: Wed, 10 Jun 2015 11:58:22 +0530
>> To: r-help at r-project.org, r-devel at r-project.org
>> Subject: [R] How to validate the cluster analysis?
>> 
>> All,
>> 
>> I am new to the world of statistics. I am interested in finding out
>the
>> validation techniques employed on a cluster analysis. Any point of
>> reference or site would be helpful. I have read about the clValid
>package
>> and usage of the function on cluster.stats() in the fpc package.
>> 
>> Thanks in Advance,
>> Harmeet
>> 
>> PS: I have marked this mail to both help and devel list. Is it ok?
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>____________________________________________________________
>Can't remember your password? Do you need a strong and secure password?
>Use Password manager! It stores your passwords & protects your account.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Wed Jun 10 16:44:47 2015
From: jholtman at gmail.com (jim holtman)
Date: Wed, 10 Jun 2015 10:44:47 -0400
Subject: [R] Symbols to data set
In-Reply-To: <CAAM-fZ7p7CZ4HFkib-aBZqkpo=4M9Zzu+Sq9RVPO7szYJju1Mg@mail.gmail.com>
References: <CAAM-fZ7p7CZ4HFkib-aBZqkpo=4M9Zzu+Sq9RVPO7szYJju1Mg@mail.gmail.com>
Message-ID: <CAAxdm-64S5eA3Tw5Xb+CBR80JKVhv8izCWumCfddj-mxySajTw@mail.gmail.com>

Is this what you want:

> x <- read.table(text = "place          Rupees          Percentage
 Dollars
+ India          120000            52                    48
+ USA          78000              56                    40
+ UK             60000              50                   56"
+     , header = TRUE
+     , as.is = TRUE
+     )
> # add thousands separator
> x$Rupees <- formatC(x$Rupees, big.mark = ',')
> # add percent sign
> x$Percentage <- paste0(x$Percentage, "%")
> # add dollar sign
> x$Dollars <- paste0("$", x$Dollars)
> x
  place  Rupees Percentage Dollars
1 India 120,000        52%     $48
2   USA  78,000        56%     $40
3    UK  60,000        50%     $56
>




Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Wed, Jun 10, 2015 at 8:15 AM, venkadesan venky <venkynov10 at gmail.com>
wrote:

> Hello Friends,
>
> I have a data like this
>
> place          Rupees          Percentage      Dollars
>
> India          120000            52                    48
> USA          78000              56                    40
> UK             60000              50                   56
>
> and i want to make Rupees column as a thousand Separator(Commas) and
> Percentage column as a percentage symbol and Dollars column as a Dollars
> symbols. by using one line command.
>
> please help to find out this
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Wed Jun 10 18:40:16 2015
From: hannah.hlx at gmail.com (li li)
Date: Wed, 10 Jun 2015 12:40:16 -0400
Subject: [R] Different random intercepts but same random slope for groups
In-Reply-To: <CAGxFJbQdOe1_GcugBHvZwy5jujvRz+TVVFRzc0Ubwqnh+qmp6w@mail.gmail.com>
References: <CAHLnndZ4OOuXXkTM=Ga3fNByK=+zyrC36RUvM_vj8A55qrH+gA@mail.gmail.com>
	<CAJuCY5xPhnjyGokW5dSQXKTp7B5-6LZTdNrpeKYofO3Sx7B2mw@mail.gmail.com>
	<CAGxFJbQdOe1_GcugBHvZwy5jujvRz+TVVFRzc0Ubwqnh+qmp6w@mail.gmail.com>
Message-ID: <CAHLnndaBpMp-Jm+ns5xspPuXhF+qV_=bwDvbNgNs17K=FDSjWg@mail.gmail.com>

Thanks all for the reply,

I think what Bert specified is what I wanted. Thanks very much.
So this model allows different random intercept term but the same
random slope term for the three methods.

I have an additional question. I would like to require differnt
residual variance also for the three groups. Is that possible?

Thanks!!

2015-06-09 17:25 GMT-04:00, Bert Gunter <bgunter.4567 at gmail.com>:
> Thierry:
>
> I don't think so. It looks to me like her syntax/understanding is confused.
> I think the call should be:
>
> mod2 <- lmer(result  ~ group*time+(group + time|lot), na.action=na.omit,
> data=alldata)
>
> Her request for "the same random slope for each group" -- I assume it's for
> time -- means to me that the time slope will vary "randomly" by lot only,
> the slope would be the same for all groups within the lot.
>
> Of course, I may be wrong also. If so, I suggest that she follow the
> posting guide and post at least head(alldata) using dput() to enable folks
> to understand the structure of her data. And only on r-sig-mixed-models --
> crossposting is frowned upon here and the mixed models list is the best bet
> for this sort of question anyway.
>
> As always, corrections and criticism welcome.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge is
> certainly not wisdom."
>    -- Clifford Stoll
>
> On Tue, Jun 9, 2015 at 1:49 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Your model is too complex for the data. This gives you two options: a)
>> simplify the model and b) get more data.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>> 2015-06-09 21:57 GMT+02:00 li li <hannah.hlx at gmail.com>:
>>
>> > Hi all,
>> >   I'd like to fit a random intercept and random slope model. In my
>> > data, there are three groups. I want to have different random
>> > intercept for each group but the same random slope effect for all
>> > three groups. I used the following R command.
>> > However, there seems to be some problem. Any suggestions?
>> >
>> >
>> >
>> > mod2 <- lmer(result  ~ group*time+(0+group1+ group2 +
>> > group3+time|lot), na.action=na.omit, data=alldata)
>> >
>> > > summary(mod2)
>> > Model is not identifiable...
>> > summary from lme4 is returned
>> > some computational error has occurred in lmerTest
>> > Linear mixed model fit by REML ['merModLmerTest']
>> > Formula: result ~ group * time + (0 + group1 + group2 + group3 + time |
>> >     lot)
>> >    Data: alldata
>> >
>> > REML criterion at convergence: 807.9
>> >
>> > Scaled residuals:
>> >     Min      1Q  Median      3Q     Max
>> > -3.0112 -0.3364  0.0425  0.2903  3.2017
>> >
>> > Random effects:
>> >  Groups   Name     Variance Std.Dev. Corr
>> >  lot      group1   0.00000 0.000
>> >           group2   86.20156 9.284      NaN
>> >           group3 55.91479 7.478      NaN  0.06
>> >           time      0.02855 0.169      NaN -0.99  0.10
>> >  Residual          39.91968 6.318
>> > Number of obs: 119, groups:  lot, 15
>> >
>> > Fixed effects:
>> >                             Estimate Std. Error t value
>> > (Intercept)                 100.1566     2.5108   39.89
>> > group  group2        -2.9707     3.7490   -0.79
>> > group  group3           -0.0717     2.8144   -0.03
>> > time                         -0.1346     0.1780   -0.76
>> > group  group2 :time   0.1450     0.2939    0.49
>> > group  group3:time        0.1663     0.2152    0.77
>> >
>> > Warning messages:
>> > 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> :
>> >   Model failed to converge with max|grad| = 0.147314 (tol = 0.002,
>> > component 2)
>> > 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> :
>> >   Model failed to converge: degenerate  Hessian with 2 negative
>> eigenvalues
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From lisecahuzac at gmail.com  Wed Jun 10 17:44:00 2015
From: lisecahuzac at gmail.com (Lise Cahuzac)
Date: Wed, 10 Jun 2015 17:44:00 +0200
Subject: [R] PORT Library
Message-ID: <CABUiFXCmZX4kOrA3iN4mJGT7njCScvJ_4JZxNYJHRU=Wu+u_xA@mail.gmail.com>

I am looking for the documentation of the PORT algorithm used in order to
resolve problem of optimization on the software R.
I am using the package optimx which is using the PORT routines, but there
is not information about how it works. I have a code of convergence saying
: "See PORT documentation.  Code (82)"
If someone has the documentation can you send me the documentation?
Thank you very much.

	[[alternative HTML version deleted]]


From demmitba at gmail.com  Wed Jun 10 18:54:30 2015
From: demmitba at gmail.com (Brittany Demmitt)
Date: Wed, 10 Jun 2015 10:54:30 -0600
Subject: [R] powerTransform Convergence error
Message-ID: <01884BF7-08ED-48E8-9DBD-9F2C4E97EE2A@gmail.com>

Hello,

I am trying to use the powerTransform function in the package car to identify the lambda: transform my data.  However, I receive the following warning:

Warning message:
In estimateTransform(x, y, NULL, ...) :
  Convergence failure: return code = 1

I can not find a description of what return code =1  means for the car package.  How do I look that up, or does anyone know what the warning means?

Thank you so much!

Brittany
	[[alternative HTML version deleted]]


From dmck at u.washington.edu  Wed Jun 10 19:03:00 2015
From: dmck at u.washington.edu (Don McKenzie)
Date: Wed, 10 Jun 2015 10:03:00 -0700
Subject: [R] graphs, need urgent help (deadline :( )
In-Reply-To: <C77F744D-5A89-4AC7-8DFE-9073A33C3BEF@gmail.com>
References: <10c1b087-6721-44b2-a347-851219672d30@gmail.com>
	<d2fd6c5d-e38b-4317-9ffa-6cfa6aa0d20e@gmail.com>
	<fe94928e-a651-4e9f-9643-73635938c694@u.washington.edu>
	<1535CE35A5D.00001088jrkrideau@inbox.com>
	<C77F744D-5A89-4AC7-8DFE-9073A33C3BEF@gmail.com>
Message-ID: <8C64A81B-AB10-42AF-82DC-752CA2D7ECE0@u.washington.edu>


> On Jun 10, 2015, at 9:08 AM, Rosa Oliveira <rosita21 at gmail.com> wrote:
> 
> Dear All,
> 
> 
> I attach my data.
> 
> Dear Jim, 
> 
> when I run your code (even the one you send me, not in my data), I get: 
> 
> Don't know how to automatically pick scale for object of type function. Defaulting to continuous
> Error in data.frame(x = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1,  : 
>   arguments imply differing number of rows: 24, 0
> 
> 
> 
> Dear Don,
> 
> It?s meant that I will have 12 lines: 
> 3 factors - lines colors
> with 3 different values of ?sample? for each - line types
> 
> 
> [Three colors, one for each factor,
> and  three line types (lty=1,2,3), one for eachvalue of ?sample - preferable dash, thin and thick).
> 
> 
> in the X - I should have region (because I have 10 regions)
> for each region I have the outcome of 3 different treatments (factor)
> for each region and each treatment I have 3 different sample size.

But in your original post you had 4 sample sizes: 10,20,30,40.
> 
> I need to ?see? the the influence of the region in the treatment outcome for each sample size.
> 
> So, at the end I should have 9 lines
> 3 red (1 dash, 1 thin, 1 thick) - concerning factor a (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
> 3 blue (1 dash, 1 thin, 1 thick) - concerning factor b (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
> 3 green (1 dash, 1 thin, 1 thick) - concerning factor c (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
> 
> 
> 
> Hope this time is clear.
> 
> 
> I also though about doing 3 different graphs, each one for 1 different sample size, and in that case I should have 3 graphs each one with 3 lines
> 1 red to factor a, 1 blue to factor b and 1 green to factor c.
> 
> Do you all think is better?

A matter of style perhaps but I would use dotplots because you have only two data points for each ?line?.  The lines will be misleading.  You also could use 
panel plots, but given your skill set (unless someone wants to spend a fair bit of time with you), it?s probably best to stay as simple as possible.

But given your original post (cleaned up)   # untested: apologies for any typos

>        region              sample          factora          factorb 		factorc
> 	0.1  			10     	 0.895   		0.903   		0.378
> 	0.2  			10      	0.811  		 0.865  		 0.688
> 	0.1  			20      	0.735   		0.966   		0.611
> 	0.2  			20     	 0.777  		 0.732  		 0.653
> 	0.1  			30      	0.600   		0.778   		0.694
> 	0.2  			30     	 0.466  		 174.592 		0.461
> 	0.1  			40     	 0.446   		0.432   		0.693
> 	0.2  			40     	 0.392   		0.294  		 0.686


plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4,type=?l?,ylim=c(0,1),xlab=?region?,ylab=?factor")
lines(my.data$region[my.data$sample==10],my.data$factorb[my.data$sample==10],col=2)
lines(my.data$region[my.data$sample==10],my.data$factorc[my.data$sample==10],col=3)

lines(my.data$region[my.data$sample==20],my.data$factora[my.data$sample==20],col=4,lty=2)
lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
lines(my.data$region[my.data$sample==20],my.data$factorc[my.data$sample==20],col=3,lty=2)

#  Now do two more groups of 3, changing the parameter ?lty? to 3 and then 4


# Look at the syntax and note what changes and what stays constant. Do you see how this works?
# there will be what looks like a vertical line where sample = 30 and factorb = 174.592.  Do you see why?

# then you will need a legend

> Nonetheless I can?t do it :(
> 
> best,
> RO
> 
> 
> 
> Atenciosamente,
> Rosa Oliveira
> 
> -- 
> ____________________________________________________________________________
>  
> <smile.jpg>
> Rosa Celeste dos Santos Oliveira, 
> 
> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
> Tlm: +351 939355143 
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
> 
>> On 10 Jun 2015, at 14:13, John Kane <jrkrideau at inbox.com <mailto:jrkrideau at inbox.com>> wrote:
>> 
>> Hi Jim,
>> 
>> I was looking at that last night and had the same problem of visualizing what Rosa needed.  
>> 
>> Hi Rosa
>> This is nothing like what you wanted and I really don't understand your data but would something like this work as a substitute or am I completely lost?
>> 
>> 
>> dat1  <-  structure(list(region = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 
>> 0.2), sample = c(10L, 10L, 20L, 20L, 30L, 30L, 40L, 40L), factora = c(0.895, 
>> 0.811, 0.735, 0.777, 0.6, 0.466, 0.446, 0.392), factorb = c(0.903, 
>> 0.865, 0.966, 0.732, 0.778, 0.592, 0.432, 0.294), factorc = c(0.37, 
>> 0.688, 0.611, 0.653, 0.694, 0.461, 0.693, 0.686)), .Names = c("region", 
>> "sample", "factora", "factorb", "factorc"), class = "data.frame", row.names = c(NA, 
>> -8L))
>> 
>> 
>> mdat1  <-   melt(dat1, id.var = c("region", "sample"),
>>                    variable.name = "factor",
>>                    value.name = "value")
>> str(mdat1)
>> 
>> ggplot(mdat1, aes(region, value, colour = factor)) +
>>                geom_line() + facet_grid(sample ~ .)
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>
>>> Sent: Wed, 10 Jun 2015 20:51:52 +1000
>>> To: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>> Subject: Re: [R] graphs, need urgent help (deadline :( )
>>> 
>>> Hi Rosa,
>>> Like Don, I can't work out what you want and I don't even have the
>>> picture. For example, your specification of color and line type leaves
>>> only one point for each color and line type, and the line from one
>>> point to the same point is not going to show up. Here is a possibility
>>> that may lead (eventually) to a solution.
>>> 
>>> library(plotrix)
>>> par(tcl=-0.1)
>>> gap.plot(x=rep(seq(10,45,by=5),3),
>>> y=unlist(my.data[,c("factora","factorb","factorc")]),
>>> main="A plot of factorial mystery",
>>> gap=c(1.1,174),ylim=c(0,175),ylab="factor score",xlab="Group",
>>> xticlab=c(" \n0.1\n10"," \n0.2\n10"," \n0.1\n20"," \n0.2\n20",
>>>  " \n0.1\n30"," \n0.2\n30"," \n0.1\n40"," \n0.2\n40"),
>>> ytics=c(0,0.5,1,174.59),pch=rep(1:3,each=8),col=rep(c(4,2,3),each=8))
>>> mtext(c("Region","Sample"),side=1,at=6,line=c(0,1))
>>> lines(seq(10,45,by=5),my.data$factora,col=4)
>>> lines(seq(10,45,by=5),my.data$factorb[c(1:5,NA,7,8)],col=2)
>>> lines(seq(10,45,by=5),my.data$factorc,col=3)
>>> 
>>> Jim
>>> 
>>> 
>>> On Wed, Jun 10, 2015 at 10:53 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>> wrote:
>>>> Dear Don and all,
>>>> 
>>>> I?ve read the tutorial and tried several codes before posting :)
>>>> I?m really naive.
>>>> 
>>>> 
>>>> 
>>>> what I was trying to :  is something like the graph in the picture I
>>>> drawee.
>>>> 
>>>> 
>>>> 
>>>> 
>>>> Is it more clear now?
>>>> 
>>>> Atenciosamente,
>>>> Rosa Oliveira
>>>> 
>>>> --
>>>> ____________________________________________________________________________
>>>> 
>>>> 
>>>> Rosa Celeste dos Santos Oliveira,
>>>> 
>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>>> Tlm: +351 939355143
>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>>> <https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>>
>>>> ____________________________________________________________________________
>>>> "Many admire, few know"
>>>> Hippocrates
>>>> 
>>>>> On 09 Jun 2015, at 19:23, Don McKenzie <dmck at u.washington.edu <mailto:dmck at u.washington.edu>
>>>>> <mailto:dmck at u.washington.edu <mailto:dmck at u.washington.edu>>> wrote:
>>>>> 
>>>>> The answer lies in learning to use the help (and knowing where to
>>>>> start).  Did you look at the tutorial that comes with the R
>>>>> installation?
>>>>> 
>>>>> ?plot
>>>>> ?lines
>>>>> 
>>>>> ?par
>>>>> 
>>>>> In the last, look for the descriptions of ?col? and ?lty?.
>>>>> 
>>>>> Using plot() and lines(), and subsetting the four unique values of
>>>>> ?sample?, you can create your lines.
>>>>> 
>>>>> Here is a crude start, assuming your columns are part of a data frame
>>>>> called ?my.data?.   Untested...
>>>>> 
>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)
>>>>> # blue line, not dashed
>>>>> .
>>>>> .
>>>>> .
>> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
>>>>> # red dashed line
>>>>> 
>>>>> 
>>>>>> On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>>>> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>> wrote:
>>>>>> 
>>>>>> Hi,
>>>>>> 
>>>>>> another naive question (i?m pretty sure :( )
>>>>>> 
>>>>>> 
>>>>>> I?m trying to plot a multiple line graph:
>>>>>> 
>>>>>>        region              sample          factora          factorb
>>>>>> factorc
>>>>>> 0.1  10      0.895   0.903   0.378
>>>>>> 0.2  10      0.811   0.865   0.688
>>>>>> 0.1  20      0.735   0.966   0.611
>>>>>> 0.2  20      0.777   0.732   0.653
>>>>>> 0.1  30      0.600   0.778   0.694
>>>>>> 0.2  30      0.466   174.592 0.461
>>>>>> 0.1  40      0.446   0.432   0.693
>>>>>> 0.2  40      0.392   0.294   0.686
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> The first column should be the independent variable, the second should
>>>>>> compute a bold line for sample(10) and dash line for sample 20.
>>>>> 
>>>>> What about the other two values of ?sample??
>>>>> 
>>>>>> The others variables are outcomes for each of the first scenarios, and
>>>>>> so it should: the 3rd, 4th and 5th columns should be blue, red and
>>>>>> green respectively.
>>>>>> 
>>>>>> 
>>>>>> Resume :)
>>>>>> 
>>>>>> I should have a graph, in the x-axe should have the region and in the
>>>>>> y axe, the factor.
>>>>>> Lines:
>>>>>>     1 - blue and bold for region 0.1, sample 10 and factor a
>>>>>>     2 - blue and dash for region 0.2, sample 10 and factor a
>>>>>>     3 - red and bold for region 0.1, sample 10 and factor b
>>>>>>     4 - red and dash for region 0.2, sample 10 and factor b
>>>>>>     5 - green and bold for region 0.1, sample 10 and factor c
>>>>>>     6 - green and dash for region 0.2, sample 10 and factor c
>>>>> 
>>>>> Not consistent with what you said above. These are no longer lines, but
>>>>> points.
>>>>>> 
>>>>>> nonetheless the independent variable is nominal, I should plot a line
>>>>>> graph.
>>>>>> 
>>>>>> Can anyone help me please?
>>>>>> I have my file as a cvs file, so I first read that file (that I know
>>>>>> how to do :)).
>>>>>> 
>>>>>> But I have it in that format.
>>>>>> 
>>>>>> Best,
>>>>>> RO
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> Atenciosamente,
>>>>>> Rosa Oliveira
>>>>>> 
>>>>>> --
>>>>>> ____________________________________________________________________________
>>>>>> 
>>>>>> 
>>>>>> Rosa Celeste dos Santos Oliveira,
>>>>>> 
>>>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>>>>> Tlm: +351 939355143
>>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>>>>> <https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>>
>>>>>> ____________________________________________________________________________
>>>>>> "Many admire, few know"
>>>>>> Hippocrates
>>>>>> 
>>>>>> 
>>>>>>     [[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To
>>>>>> UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> <http://www.r-project.org/posting-guide.html>
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> <PastedGraphic-1.tiff>
>>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ____________________________________________________________
>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
>> Check it out at http://www.inbox.com/marineaquarium <http://www.inbox.com/marineaquarium>
>> 
>> 
> 




From dmck at u.washington.edu  Wed Jun 10 19:10:26 2015
From: dmck at u.washington.edu (Don McKenzie)
Date: Wed, 10 Jun 2015 10:10:26 -0700
Subject: [R] graphs, need urgent help (deadline :( )
In-Reply-To: <8C64A81B-AB10-42AF-82DC-752CA2D7ECE0@u.washington.edu>
References: <10c1b087-6721-44b2-a347-851219672d30@gmail.com>
	<d2fd6c5d-e38b-4317-9ffa-6cfa6aa0d20e@gmail.com>
	<fe94928e-a651-4e9f-9643-73635938c694@u.washington.edu>
	<1535CE35A5D.00001088jrkrideau@inbox.com>
	<C77F744D-5A89-4AC7-8DFE-9073A33C3BEF@gmail.com>
	<8C64A81B-AB10-42AF-82DC-752CA2D7ECE0@u.washington.edu>
Message-ID: <EC24A80A-5013-4ED3-8B5A-A41B1E54AD62@u.washington.edu>

For a legend, try (untested)

legend(0.15,0.9,c("factora","factorb","factorc"),col=c(4,2,3),lty=1)

If it overlaps data points move the first two arguments (0.15 and 0.9) around, or change the ?ylim? argument in the plot() to ~1.2.

to avoid clutter, put the line-types information in the figure caption (IMO)


> On Jun 10, 2015, at 10:03 AM, Don McKenzie <dmck at u.washington.edu> wrote:
> 
> 
>> On Jun 10, 2015, at 9:08 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>> wrote:
>> 
>> Dear All,
>> 
>> 
>> I attach my data.
>> 
>> Dear Jim, 
>> 
>> when I run your code (even the one you send me, not in my data), I get: 
>> 
>> Don't know how to automatically pick scale for object of type function. Defaulting to continuous
>> Error in data.frame(x = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1,  : 
>>   arguments imply differing number of rows: 24, 0
>> 
>> 
>> 
>> Dear Don,
>> 
>> It?s meant that I will have 12 lines: 
>> 3 factors - lines colors
>> with 3 different values of ?sample? for each - line types
>> 
>> 
>> [Three colors, one for each factor,
>> and  three line types (lty=1,2,3), one for eachvalue of ?sample - preferable dash, thin and thick).
>> 
>> 
>> in the X - I should have region (because I have 10 regions)
>> for each region I have the outcome of 3 different treatments (factor)
>> for each region and each treatment I have 3 different sample size.
> 
> But in your original post you had 4 sample sizes: 10,20,30,40.
>> 
>> I need to ?see? the the influence of the region in the treatment outcome for each sample size.
>> 
>> So, at the end I should have 9 lines
>> 3 red (1 dash, 1 thin, 1 thick) - concerning factor a (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>> 3 blue (1 dash, 1 thin, 1 thick) - concerning factor b (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>> 3 green (1 dash, 1 thin, 1 thick) - concerning factor c (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>> 
>> 
>> 
>> Hope this time is clear.
>> 
>> 
>> I also though about doing 3 different graphs, each one for 1 different sample size, and in that case I should have 3 graphs each one with 3 lines
>> 1 red to factor a, 1 blue to factor b and 1 green to factor c.
>> 
>> Do you all think is better?
> 
> A matter of style perhaps but I would use dotplots because you have only two data points for each ?line?.  The lines will be misleading.  You also could use 
> panel plots, but given your skill set (unless someone wants to spend a fair bit of time with you), it?s probably best to stay as simple as possible.
> 
> But given your original post (cleaned up)   # untested: apologies for any typos
> 
>>        region              sample          factora          factorb 		factorc
>> 	0.1  			10     	 0.895   		0.903   		0.378
>> 	0.2  			10      	0.811  		 0.865  		 0.688
>> 	0.1  			20      	0.735   		0.966   		0.611
>> 	0.2  			20     	 0.777  		 0.732  		 0.653
>> 	0.1  			30      	0.600   		0.778   		0.694
>> 	0.2  			30     	 0.466  		 174.592 		0.461
>> 	0.1  			40     	 0.446   		0.432   		0.693
>> 	0.2  			40     	 0.392   		0.294  		 0.686
> 
> 
> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4,type=?l?,ylim=c(0,1),xlab=?region?,ylab=?factor")
> lines(my.data$region[my.data$sample==10],my.data$factorb[my.data$sample==10],col=2)
> lines(my.data$region[my.data$sample==10],my.data$factorc[my.data$sample==10],col=3)
> 
> lines(my.data$region[my.data$sample==20],my.data$factora[my.data$sample==20],col=4,lty=2)
> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
> lines(my.data$region[my.data$sample==20],my.data$factorc[my.data$sample==20],col=3,lty=2)
> 
> #  Now do two more groups of 3, changing the parameter ?lty? to 3 and then 4
> 
> 
> # Look at the syntax and note what changes and what stays constant. Do you see how this works?
> # there will be what looks like a vertical line where sample = 30 and factorb = 174.592.  Do you see why?
> 
> # then you will need a legend
> 
>> Nonetheless I can?t do it :(
>> 
>> best,
>> RO
>> 
>> 
>> 
>> Atenciosamente,
>> Rosa Oliveira
>> 
>> -- 
>> ____________________________________________________________________________
>>  
>> <smile.jpg>
>> Rosa Celeste dos Santos Oliveira, 
>> 
>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>> Tlm: +351 939355143 
>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>> ____________________________________________________________________________
>> "Many admire, few know"
>> Hippocrates
>> 
>>> On 10 Jun 2015, at 14:13, John Kane <jrkrideau at inbox.com <mailto:jrkrideau at inbox.com>> wrote:
>>> 
>>> Hi Jim,
>>> 
>>> I was looking at that last night and had the same problem of visualizing what Rosa needed.  
>>> 
>>> Hi Rosa
>>> This is nothing like what you wanted and I really don't understand your data but would something like this work as a substitute or am I completely lost?
>>> 
>>> 
>>> dat1  <-  structure(list(region = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 
>>> 0.2), sample = c(10L, 10L, 20L, 20L, 30L, 30L, 40L, 40L), factora = c(0.895, 
>>> 0.811, 0.735, 0.777, 0.6, 0.466, 0.446, 0.392), factorb = c(0.903, 
>>> 0.865, 0.966, 0.732, 0.778, 0.592, 0.432, 0.294), factorc = c(0.37, 
>>> 0.688, 0.611, 0.653, 0.694, 0.461, 0.693, 0.686)), .Names = c("region", 
>>> "sample", "factora", "factorb", "factorc"), class = "data.frame", row.names = c(NA, 
>>> -8L))
>>> 
>>> 
>>> mdat1  <-   melt(dat1, id.var = c("region", "sample"),
>>>                    variable.name = "factor",
>>>                    value.name = "value")
>>> str(mdat1)
>>> 
>>> ggplot(mdat1, aes(region, value, colour = factor)) +
>>>                geom_line() + facet_grid(sample ~ .)
>>> 
>>> John Kane
>>> Kingston ON Canada
>>> 
>>> 
>>>> -----Original Message-----
>>>> From: drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>
>>>> Sent: Wed, 10 Jun 2015 20:51:52 +1000
>>>> To: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>> Subject: Re: [R] graphs, need urgent help (deadline :( )
>>>> 
>>>> Hi Rosa,
>>>> Like Don, I can't work out what you want and I don't even have the
>>>> picture. For example, your specification of color and line type leaves
>>>> only one point for each color and line type, and the line from one
>>>> point to the same point is not going to show up. Here is a possibility
>>>> that may lead (eventually) to a solution.
>>>> 
>>>> library(plotrix)
>>>> par(tcl=-0.1)
>>>> gap.plot(x=rep(seq(10,45,by=5),3),
>>>> y=unlist(my.data[,c("factora","factorb","factorc")]),
>>>> main="A plot of factorial mystery",
>>>> gap=c(1.1,174),ylim=c(0,175),ylab="factor score",xlab="Group",
>>>> xticlab=c(" \n0.1\n10"," \n0.2\n10"," \n0.1\n20"," \n0.2\n20",
>>>>  " \n0.1\n30"," \n0.2\n30"," \n0.1\n40"," \n0.2\n40"),
>>>> ytics=c(0,0.5,1,174.59),pch=rep(1:3,each=8),col=rep(c(4,2,3),each=8))
>>>> mtext(c("Region","Sample"),side=1,at=6,line=c(0,1))
>>>> lines(seq(10,45,by=5),my.data$factora,col=4)
>>>> lines(seq(10,45,by=5),my.data$factorb[c(1:5,NA,7,8)],col=2)
>>>> lines(seq(10,45,by=5),my.data$factorc,col=3)
>>>> 
>>>> Jim
>>>> 
>>>> 
>>>> On Wed, Jun 10, 2015 at 10:53 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>>> wrote:
>>>>> Dear Don and all,
>>>>> 
>>>>> I?ve read the tutorial and tried several codes before posting :)
>>>>> I?m really naive.
>>>>> 
>>>>> 
>>>>> 
>>>>> what I was trying to :  is something like the graph in the picture I
>>>>> drawee.
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> Is it more clear now?
>>>>> 
>>>>> Atenciosamente,
>>>>> Rosa Oliveira
>>>>> 
>>>>> --
>>>>> ____________________________________________________________________________
>>>>> 
>>>>> 
>>>>> Rosa Celeste dos Santos Oliveira,
>>>>> 
>>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>>>> Tlm: +351 939355143
>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>>>> <https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>>
>>>>> ____________________________________________________________________________
>>>>> "Many admire, few know"
>>>>> Hippocrates
>>>>> 
>>>>>> On 09 Jun 2015, at 19:23, Don McKenzie <dmck at u.washington.edu <mailto:dmck at u.washington.edu>
>>>>>> <mailto:dmck at u.washington.edu <mailto:dmck at u.washington.edu>>> wrote:
>>>>>> 
>>>>>> The answer lies in learning to use the help (and knowing where to
>>>>>> start).  Did you look at the tutorial that comes with the R
>>>>>> installation?
>>>>>> 
>>>>>> ?plot
>>>>>> ?lines
>>>>>> 
>>>>>> ?par
>>>>>> 
>>>>>> In the last, look for the descriptions of ?col? and ?lty?.
>>>>>> 
>>>>>> Using plot() and lines(), and subsetting the four unique values of
>>>>>> ?sample?, you can create your lines.
>>>>>> 
>>>>>> Here is a crude start, assuming your columns are part of a data frame
>>>>>> called ?my.data?.   Untested...
>>>>>> 
>>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)
>>>>>> # blue line, not dashed
>>>>>> .
>>>>>> .
>>>>>> .
>>> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
>>>>>> # red dashed line
>>>>>> 
>>>>>> 
>>>>>>> On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>>>>> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>> wrote:
>>>>>>> 
>>>>>>> Hi,
>>>>>>> 
>>>>>>> another naive question (i?m pretty sure :( )
>>>>>>> 
>>>>>>> 
>>>>>>> I?m trying to plot a multiple line graph:
>>>>>>> 
>>>>>>>        region              sample          factora          factorb
>>>>>>> factorc
>>>>>>> 0.1  10      0.895   0.903   0.378
>>>>>>> 0.2  10      0.811   0.865   0.688
>>>>>>> 0.1  20      0.735   0.966   0.611
>>>>>>> 0.2  20      0.777   0.732   0.653
>>>>>>> 0.1  30      0.600   0.778   0.694
>>>>>>> 0.2  30      0.466   174.592 0.461
>>>>>>> 0.1  40      0.446   0.432   0.693
>>>>>>> 0.2  40      0.392   0.294   0.686
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> The first column should be the independent variable, the second should
>>>>>>> compute a bold line for sample(10) and dash line for sample 20.
>>>>>> 
>>>>>> What about the other two values of ?sample??
>>>>>> 
>>>>>>> The others variables are outcomes for each of the first scenarios, and
>>>>>>> so it should: the 3rd, 4th and 5th columns should be blue, red and
>>>>>>> green respectively.
>>>>>>> 
>>>>>>> 
>>>>>>> Resume :)
>>>>>>> 
>>>>>>> I should have a graph, in the x-axe should have the region and in the
>>>>>>> y axe, the factor.
>>>>>>> Lines:
>>>>>>>     1 - blue and bold for region 0.1, sample 10 and factor a
>>>>>>>     2 - blue and dash for region 0.2, sample 10 and factor a
>>>>>>>     3 - red and bold for region 0.1, sample 10 and factor b
>>>>>>>     4 - red and dash for region 0.2, sample 10 and factor b
>>>>>>>     5 - green and bold for region 0.1, sample 10 and factor c
>>>>>>>     6 - green and dash for region 0.2, sample 10 and factor c
>>>>>> 
>>>>>> Not consistent with what you said above. These are no longer lines, but
>>>>>> points.
>>>>>>> 
>>>>>>> nonetheless the independent variable is nominal, I should plot a line
>>>>>>> graph.
>>>>>>> 
>>>>>>> Can anyone help me please?
>>>>>>> I have my file as a cvs file, so I first read that file (that I know
>>>>>>> how to do :)).
>>>>>>> 
>>>>>>> But I have it in that format.
>>>>>>> 
>>>>>>> Best,
>>>>>>> RO
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> Atenciosamente,
>>>>>>> Rosa Oliveira
>>>>>>> 
>>>>>>> --
>>>>>>> ____________________________________________________________________________
>>>>>>> 
>>>>>>> 
>>>>>>> Rosa Celeste dos Santos Oliveira,
>>>>>>> 
>>>>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>>>>>> Tlm: +351 939355143
>>>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>>>>>> <https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>>
>>>>>>> ____________________________________________________________________________
>>>>>>> "Many admire, few know"
>>>>>>> Hippocrates
>>>>>>> 
>>>>>>> 
>>>>>>>     [[alternative HTML version deleted]]
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To
>>>>>>> UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>>>> <http://www.r-project.org/posting-guide.html>
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>>> <PastedGraphic-1.tiff>
>>>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ____________________________________________________________
>>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
>>> Check it out at http://www.inbox.com/marineaquarium <http://www.inbox.com/marineaquarium>
>>> 
>>> 
>> 
> 
> <PastedGraphic-1.tiff>
> 




From dmck at u.washington.edu  Wed Jun 10 20:21:01 2015
From: dmck at u.washington.edu (Don McKenzie)
Date: Wed, 10 Jun 2015 11:21:01 -0700
Subject: [R] graphs, need urgent help (deadline :( )
In-Reply-To: <FD7328FB-306E-47A7-B0AC-A4EAC0B8AEF0@gmail.com>
References: <10c1b087-6721-44b2-a347-851219672d30@gmail.com>
	<d2fd6c5d-e38b-4317-9ffa-6cfa6aa0d20e@gmail.com>
	<fe94928e-a651-4e9f-9643-73635938c694@u.washington.edu>
	<1535CE35A5D.00001088jrkrideau@inbox.com>
	<C77F744D-5A89-4AC7-8DFE-9073A33C3BEF@gmail.com>
	<8C64A81B-AB10-42AF-82DC-752CA2D7ECE0@u.washington.edu>
	<EC24A80A-5013-4ED3-8B5A-A41B1E54AD62@u.washington.edu>
	<FD7328FB-306E-47A7-B0AC-A4EAC0B8AEF0@gmail.com>
Message-ID: <539C8546-72DE-46F4-AE62-9DB523676B36@u.washington.edu>

You need to substitute the real name of the data frame for ?my.data?.  That was just my example.  :-)

> On Jun 10, 2015, at 11:03 AM, Rosa Oliveira <rosita21 at gmail.com> wrote:
> 
> Sorry,
> 
> I taught I attached the cvs file :)
> 
> <therapy.csv>
> 
> 
> Don,
> 
> I tried, but I got an error:
> 
> > my.data$Region
>  [1]  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10
> > my.data$sample
>  [1]   50   50   50   50   50   50   50   50   50   50  250  250  250  250  250  250  250  250  250  250 1000 1000 1000 1000 1000 1000 1000 1000
> [29] 1000 1000
> > my.data$factor.a
>  [1] 0.895 0.811 0.685 0.777 0.600 0.466 0.446 0.392 0.256 0.198 0.136 0.121 0.875 0.777 0.685 0.626 0.550 0.466 0.384 0.330 0.060 0.138 0.065
> [24] 0.034 0.931 0.124 0.060 0.028 0.017 0.014
> 
> 
> > plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=?l?,xlab=?Region?,ylab=?factor")
> Error: unexpected input in "plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=??
> 
> 
> I?m really naive, right?
> 
> 
> Best,
> RO
> 
> 
> Atenciosamente,
> Rosa Oliveira
> 
> -- 
> ____________________________________________________________________________
>  
> <smile.jpg>
> 
> Rosa Celeste dos Santos Oliveira, 
> 
> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
> Tlm: +351 939355143 
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
> 
>> On 10 Jun 2015, at 18:10, Don McKenzie <dmck at u.washington.edu <mailto:dmck at u.washington.edu>> wrote:
>> 
>> For a legend, try (untested)
>> 
>> legend(0.15,0.9,c("factora","factorb","factorc"),col=c(4,2,3),lty=1)
>> 
>> If it overlaps data points move the first two arguments (0.15 and 0.9) around, or change the ?ylim? argument in the plot() to ~1.2.
>> 
>> to avoid clutter, put the line-types information in the figure caption (IMO)
>> 
>> 
>>> On Jun 10, 2015, at 10:03 AM, Don McKenzie <dmck at u.washington.edu <mailto:dmck at u.washington.edu>> wrote:
>>> 
>>> 
>>>> On Jun 10, 2015, at 9:08 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>> wrote:
>>>> 
>>>> Dear All,
>>>> 
>>>> 
>>>> I attach my data.
>>>> 
>>>> Dear Jim, 
>>>> 
>>>> when I run your code (even the one you send me, not in my data), I get: 
>>>> 
>>>> Don't know how to automatically pick scale for object of type function. Defaulting to continuous
>>>> Error in data.frame(x = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1,  : 
>>>>   arguments imply differing number of rows: 24, 0
>>>> 
>>>> 
>>>> 
>>>> Dear Don,
>>>> 
>>>> It?s meant that I will have 12 lines: 
>>>> 3 factors - lines colors
>>>> with 3 different values of ?sample? for each - line types
>>>> 
>>>> 
>>>> [Three colors, one for each factor,
>>>> and  three line types (lty=1,2,3), one for eachvalue of ?sample - preferable dash, thin and thick).
>>>> 
>>>> 
>>>> in the X - I should have region (because I have 10 regions)
>>>> for each region I have the outcome of 3 different treatments (factor)
>>>> for each region and each treatment I have 3 different sample size.
>>> 
>>> But in your original post you had 4 sample sizes: 10,20,30,40.
>>>> 
>>>> I need to ?see? the the influence of the region in the treatment outcome for each sample size.
>>>> 
>>>> So, at the end I should have 9 lines
>>>> 3 red (1 dash, 1 thin, 1 thick) - concerning factor a (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>>> 3 blue (1 dash, 1 thin, 1 thick) - concerning factor b (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>>> 3 green (1 dash, 1 thin, 1 thick) - concerning factor c (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>>> 
>>>> 
>>>> 
>>>> Hope this time is clear.
>>>> 
>>>> 
>>>> I also though about doing 3 different graphs, each one for 1 different sample size, and in that case I should have 3 graphs each one with 3 lines
>>>> 1 red to factor a, 1 blue to factor b and 1 green to factor c.
>>>> 
>>>> Do you all think is better?
>>> 
>>> A matter of style perhaps but I would use dotplots because you have only two data points for each ?line?.  The lines will be misleading.  You also could use 
>>> panel plots, but given your skill set (unless someone wants to spend a fair bit of time with you), it?s probably best to stay as simple as possible.
>>> 
>>> But given your original post (cleaned up)   # untested: apologies for any typos
>>> 
>>>>        region              sample          factora          factorb 		factorc
>>>> 	0.1  			10     	 0.895   		0.903   		0.378
>>>> 	0.2  			10      	0.811  		 0.865  		 0.688
>>>> 	0.1  			20      	0.735   		0.966   		0.611
>>>> 	0.2  			20     	 0.777  		 0.732  		 0.653
>>>> 	0.1  			30      	0.600   		0.778   		0.694
>>>> 	0.2  			30     	 0.466  		 174.592 		0.461
>>>> 	0.1  			40     	 0.446   		0.432   		0.693
>>>> 	0.2  			40     	 0.392   		0.294  		 0.686
>>> 
>>> 
>>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4,type=?l?,ylim=c(0,1),xlab=?region?,ylab=?factor")
>>> lines(my.data$region[my.data$sample==10],my.data$factorb[my.data$sample==10],col=2)
>>> lines(my.data$region[my.data$sample==10],my.data$factorc[my.data$sample==10],col=3)
>>> 
>>> lines(my.data$region[my.data$sample==20],my.data$factora[my.data$sample==20],col=4,lty=2)
>>> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
>>> lines(my.data$region[my.data$sample==20],my.data$factorc[my.data$sample==20],col=3,lty=2)
>>> 
>>> #  Now do two more groups of 3, changing the parameter ?lty? to 3 and then 4
>>> 
>>> 
>>> # Look at the syntax and note what changes and what stays constant. Do you see how this works?
>>> # there will be what looks like a vertical line where sample = 30 and factorb = 174.592.  Do you see why?
>>> 
>>> # then you will need a legend
>>> 
>>>> Nonetheless I can?t do it :(
>>>> 
>>>> best,
>>>> RO
>>>> 
>>>> 
>>>> 
>>>> Atenciosamente,
>>>> Rosa Oliveira
>>>> 
>>>> -- 
>>>> ____________________________________________________________________________
>>>>  
>>>> <smile.jpg>
>>>> Rosa Celeste dos Santos Oliveira, 
>>>> 
>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>> Tlm: +351 939355143 
>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>>> ____________________________________________________________________________
>>>> "Many admire, few know"
>>>> Hippocrates
>>>> 
>>>>> On 10 Jun 2015, at 14:13, John Kane <jrkrideau at inbox.com <mailto:jrkrideau at inbox.com>> wrote:
>>>>> 
>>>>> Hi Jim,
>>>>> 
>>>>> I was looking at that last night and had the same problem of visualizing what Rosa needed.  
>>>>> 
>>>>> Hi Rosa
>>>>> This is nothing like what you wanted and I really don't understand your data but would something like this work as a substitute or am I completely lost?
>>>>> 
>>>>> 
>>>>> dat1  <-  structure(list(region = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 
>>>>> 0.2), sample = c(10L, 10L, 20L, 20L, 30L, 30L, 40L, 40L), factora = c(0.895, 
>>>>> 0.811, 0.735, 0.777, 0.6, 0.466, 0.446, 0.392), factorb = c(0.903, 
>>>>> 0.865, 0.966, 0.732, 0.778, 0.592, 0.432, 0.294), factorc = c(0.37, 
>>>>> 0.688, 0.611, 0.653, 0.694, 0.461, 0.693, 0.686)), .Names = c("region", 
>>>>> "sample", "factora", "factorb", "factorc"), class = "data.frame", row.names = c(NA, 
>>>>> -8L))
>>>>> 
>>>>> 
>>>>> mdat1  <-   melt(dat1, id.var = c("region", "sample"),
>>>>>                    variable.name = "factor",
>>>>>                    value.name = "value")
>>>>> str(mdat1)
>>>>> 
>>>>> ggplot(mdat1, aes(region, value, colour = factor)) +
>>>>>                geom_line() + facet_grid(sample ~ .)
>>>>> 
>>>>> John Kane
>>>>> Kingston ON Canada
>>>>> 
>>>>> 
>>>>>> -----Original Message-----
>>>>>> From: drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>
>>>>>> Sent: Wed, 10 Jun 2015 20:51:52 +1000
>>>>>> To: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>>>> Subject: Re: [R] graphs, need urgent help (deadline :( )
>>>>>> 
>>>>>> Hi Rosa,
>>>>>> Like Don, I can't work out what you want and I don't even have the
>>>>>> picture. For example, your specification of color and line type leaves
>>>>>> only one point for each color and line type, and the line from one
>>>>>> point to the same point is not going to show up. Here is a possibility
>>>>>> that may lead (eventually) to a solution.
>>>>>> 
>>>>>> library(plotrix)
>>>>>> par(tcl=-0.1)
>>>>>> gap.plot(x=rep(seq(10,45,by=5),3),
>>>>>> y=unlist(my.data[,c("factora","factorb","factorc")]),
>>>>>> main="A plot of factorial mystery",
>>>>>> gap=c(1.1,174),ylim=c(0,175),ylab="factor score",xlab="Group",
>>>>>> xticlab=c(" \n0.1\n10"," \n0.2\n10"," \n0.1\n20"," \n0.2\n20",
>>>>>>  " \n0.1\n30"," \n0.2\n30"," \n0.1\n40"," \n0.2\n40"),
>>>>>> ytics=c(0,0.5,1,174.59),pch=rep(1:3,each=8),col=rep(c(4,2,3),each=8))
>>>>>> mtext(c("Region","Sample"),side=1,at=6,line=c(0,1))
>>>>>> lines(seq(10,45,by=5),my.data$factora,col=4)
>>>>>> lines(seq(10,45,by=5),my.data$factorb[c(1:5,NA,7,8)],col=2)
>>>>>> lines(seq(10,45,by=5),my.data$factorc,col=3)
>>>>>> 
>>>>>> Jim
>>>>>> 
>>>>>> 
>>>>>> On Wed, Jun 10, 2015 at 10:53 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>>>>> wrote:
>>>>>>> Dear Don and all,
>>>>>>> 
>>>>>>> I?ve read the tutorial and tried several codes before posting :)
>>>>>>> I?m really naive.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> what I was trying to :  is something like the graph in the picture I
>>>>>>> drawee.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> Is it more clear now?
>>>>>>> 
>>>>>>> Atenciosamente,
>>>>>>> Rosa Oliveira
>>>>>>> 
>>>>>>> --
>>>>>>> ____________________________________________________________________________
>>>>>>> 
>>>>>>> 
>>>>>>> Rosa Celeste dos Santos Oliveira,
>>>>>>> 
>>>>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>>>>>> Tlm: +351 939355143
>>>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>>>>>> <https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>>
>>>>>>> ____________________________________________________________________________
>>>>>>> "Many admire, few know"
>>>>>>> Hippocrates
>>>>>>> 
>>>>>>>> On 09 Jun 2015, at 19:23, Don McKenzie <dmck at u.washington.edu <mailto:dmck at u.washington.edu>
>>>>>>>> <mailto:dmck at u.washington.edu <mailto:dmck at u.washington.edu>>> wrote:
>>>>>>>> 
>>>>>>>> The answer lies in learning to use the help (and knowing where to
>>>>>>>> start).  Did you look at the tutorial that comes with the R
>>>>>>>> installation?
>>>>>>>> 
>>>>>>>> ?plot
>>>>>>>> ?lines
>>>>>>>> 
>>>>>>>> ?par
>>>>>>>> 
>>>>>>>> In the last, look for the descriptions of ?col? and ?lty?.
>>>>>>>> 
>>>>>>>> Using plot() and lines(), and subsetting the four unique values of
>>>>>>>> ?sample?, you can create your lines.
>>>>>>>> 
>>>>>>>> Here is a crude start, assuming your columns are part of a data frame
>>>>>>>> called ?my.data?.   Untested...
>>>>>>>> 
>>>>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)
>>>>>>>> # blue line, not dashed
>>>>>>>> .
>>>>>>>> .
>>>>>>>> .
>>>>> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
>>>>>>>> # red dashed line
>>>>>>>> 
>>>>>>>> 
>>>>>>>>> On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>>>>>>> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>> wrote:
>>>>>>>>> 
>>>>>>>>> Hi,
>>>>>>>>> 
>>>>>>>>> another naive question (i?m pretty sure :( )
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> I?m trying to plot a multiple line graph:
>>>>>>>>> 
>>>>>>>>>        region              sample          factora          factorb
>>>>>>>>> factorc
>>>>>>>>> 0.1  10      0.895   0.903   0.378
>>>>>>>>> 0.2  10      0.811   0.865   0.688
>>>>>>>>> 0.1  20      0.735   0.966   0.611
>>>>>>>>> 0.2  20      0.777   0.732   0.653
>>>>>>>>> 0.1  30      0.600   0.778   0.694
>>>>>>>>> 0.2  30      0.466   174.592 0.461
>>>>>>>>> 0.1  40      0.446   0.432   0.693
>>>>>>>>> 0.2  40      0.392   0.294   0.686
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> The first column should be the independent variable, the second should
>>>>>>>>> compute a bold line for sample(10) and dash line for sample 20.
>>>>>>>> 
>>>>>>>> What about the other two values of ?sample??
>>>>>>>> 
>>>>>>>>> The others variables are outcomes for each of the first scenarios, and
>>>>>>>>> so it should: the 3rd, 4th and 5th columns should be blue, red and
>>>>>>>>> green respectively.
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Resume :)
>>>>>>>>> 
>>>>>>>>> I should have a graph, in the x-axe should have the region and in the
>>>>>>>>> y axe, the factor.
>>>>>>>>> Lines:
>>>>>>>>>     1 - blue and bold for region 0.1, sample 10 and factor a
>>>>>>>>>     2 - blue and dash for region 0.2, sample 10 and factor a
>>>>>>>>>     3 - red and bold for region 0.1, sample 10 and factor b
>>>>>>>>>     4 - red and dash for region 0.2, sample 10 and factor b
>>>>>>>>>     5 - green and bold for region 0.1, sample 10 and factor c
>>>>>>>>>     6 - green and dash for region 0.2, sample 10 and factor c
>>>>>>>> 
>>>>>>>> Not consistent with what you said above. These are no longer lines, but
>>>>>>>> points.
>>>>>>>>> 
>>>>>>>>> nonetheless the independent variable is nominal, I should plot a line
>>>>>>>>> graph.
>>>>>>>>> 
>>>>>>>>> Can anyone help me please?
>>>>>>>>> I have my file as a cvs file, so I first read that file (that I know
>>>>>>>>> how to do :)).
>>>>>>>>> 
>>>>>>>>> But I have it in that format.
>>>>>>>>> 
>>>>>>>>> Best,
>>>>>>>>> RO
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Atenciosamente,
>>>>>>>>> Rosa Oliveira
>>>>>>>>> 
>>>>>>>>> --
>>>>>>>>> ____________________________________________________________________________
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Rosa Celeste dos Santos Oliveira,
>>>>>>>>> 
>>>>>>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>>>>>>>> Tlm: +351 939355143
>>>>>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>>>>>>>> <https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>>
>>>>>>>>> ____________________________________________________________________________
>>>>>>>>> "Many admire, few know"
>>>>>>>>> Hippocrates
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>>     [[alternative HTML version deleted]]
>>>>>>>>> 
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To
>>>>>>>>> UNSUBSCRIBE and more, see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>>>>>> <http://www.r-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>>
>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>> 
>>>>>>>> <PastedGraphic-1.tiff>
>>>>>>>> 
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> ____________________________________________________________
>>>>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
>>>>> Check it out at http://www.inbox.com/marineaquarium <http://www.inbox.com/marineaquarium>
>>>>> 
>>>>> 
>>>> 
>>> 
>>> <PastedGraphic-1.tiff>
>>> 
>> 
>> <PastedGraphic-1.tiff>
>> 
> 




From doggene at earthlink.net  Wed Jun 10 14:39:01 2015
From: doggene at earthlink.net (Liz Hare)
Date: Wed, 10 Jun 2015 08:39:01 -0400
Subject: [R] Split data frame into 250-row chunks
Message-ID: <9E2E1B7D-6A42-4A88-948F-9A29F0EEA988@earthlink.net>

Hi R-Experts,

I have a data.frame like this:

> head(map)
  chr snp   poscm   posbp    dist
1   1  M1 2.99043 3249189      NA
2   1  M2 3.06457 3273096 0.07414
3   1  M3 3.17018 3307151 0.10561
4   1  M4 3.20892 3319643 0.03874
5   1  M5 3.28120 3342947 0.07228
6   1  M6 3.29624 3347798 0.01504

I need to split this into chunks of 250 rows (there will usually be a last chunk with < 250 rows).

If I only had to extract one 250-line chunk, it would be easy:

map1 <- map[1:250, ]

or using subset().

I tried to make it a loop iterating through num and using beg and nd for starting and ending indices, but I couldn?t figure out how to reference all the variables I needed in this:

> chunks
    beg   nd let num
1     1  250   a   1
2   251  500   b   2
3   501  750   c   3
4   751 1000   d   4
5  1001 1250   e   5
6  1251 1500   f   6
7  1501 1750   g   7
8  1751 2000   h   8
9  2001 2250   i   9
10 2251 2500   j  10
?

Remembering that loops are not always the best answer in R, I looked at other options like split, following this example but not being able to adapt it from a vector to a data.frame version
http://stackoverflow.com/questions/3318333/split-a-vector-into-chunks-in-r <http://stackoverflow.com/questions/3318333/split-a-vector-into-chunks-in-r> (Yes, I?ve reviewed the language documentation). I checked out ddply and data.table, but couldn?t find a way to use them with index positions instead of column values.

Thanks,
Liz



	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Jun 10 15:33:42 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 10 Jun 2015 14:33:42 +0100
Subject: [R] reading as date
In-Reply-To: <1433937781684-4708441.post@n4.nabble.com>
References: <1433931659996-4708431.post@n4.nabble.com>	<5578258F.4040905@nic.fi>
	<1433937781684-4708441.post@n4.nabble.com>
Message-ID: <55783CB6.6070600@sapo.pt>

Hello,

Inline.

Em 10-06-2015 13:03, khatri escreveu:
> Hey sorry for my typing.
> I have actually used the same format with % that is

No you have not, like others allready have told you.
You need %H:%M:%S not H:M:S.

strptime(dd,"%d/%m %H:%M:%S")
[1] "2015-01-21 11:11:11 GMT"


Hope this helps,

>
>
>> dd<-c("21/01 11:11:11")
>> strptime(dd,"%d/%m H:M:S")
> [1] NA
>
>
> it is giving NA.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/reading-as-date-tp4708434p4708441.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rosita21 at gmail.com  Wed Jun 10 18:08:06 2015
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Wed, 10 Jun 2015 17:08:06 +0100
Subject: [R] graphs, need urgent help (deadline :( )
In-Reply-To: <1535CE35A5D.00001088jrkrideau@inbox.com>
References: <10c1b087-6721-44b2-a347-851219672d30@gmail.com>
	<d2fd6c5d-e38b-4317-9ffa-6cfa6aa0d20e@gmail.com>
	<fe94928e-a651-4e9f-9643-73635938c694@u.washington.edu>
	<1535CE35A5D.00001088jrkrideau@inbox.com>
Message-ID: <C77F744D-5A89-4AC7-8DFE-9073A33C3BEF@gmail.com>

Dear All,


I attach my data.

Dear Jim, 

when I run your code (even the one you send me, not in my data), I get: 

Don't know how to automatically pick scale for object of type function. Defaulting to continuous
Error in data.frame(x = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1,  : 
  arguments imply differing number of rows: 24, 0



Dear Don,

It?s meant that I will have 12 lines: 
3 factors - lines colors
with 3 different values of ?sample? for each - line types


[Three colors, one for each factor,
and  three line types (lty=1,2,3), one for eachvalue of ?sample - preferable dash, thin and thick).


in the X - I should have region (because I have 10 regions)
for each region I have the outcome of 3 different treatments (factor)
for each region and each treatment I have 3 different sample size.

I need to ?see? the the influence of the region in the treatment outcome for each sample size.

So, at the end I should have 9 lines
3 red (1 dash, 1 thin, 1 thick) - concerning factor a (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
3 blue (1 dash, 1 thin, 1 thick) - concerning factor b (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
3 green (1 dash, 1 thin, 1 thick) - concerning factor c (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)



Hope this time is clear.


I also though about doing 3 different graphs, each one for 1 different sample size, and in that case I should have 3 graphs each one with 3 lines
1 red to factor a, 1 blue to factor b and 1 green to factor c.

Do you all think is better?
Nonetheless I can?t do it :(

best,
RO



Atenciosamente,
Rosa Oliveira

-- 
____________________________________________________________________________


Rosa Celeste dos Santos Oliveira, 

E-mail: rosita21 at gmail.com
Tlm: +351 939355143 
Linkedin: https://pt.linkedin.com/in/rosacsoliveira
____________________________________________________________________________
"Many admire, few know"
Hippocrates

> On 10 Jun 2015, at 14:13, John Kane <jrkrideau at inbox.com> wrote:
> 
> Hi Jim,
> 
> I was looking at that last night and had the same problem of visualizing what Rosa needed.  
> 
> Hi Rosa
> This is nothing like what you wanted and I really don't understand your data but would something like this work as a substitute or am I completely lost?
> 
> 
> dat1  <-  structure(list(region = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1,
> 0.2), sample = c(10L, 10L, 20L, 20L, 30L, 30L, 40L, 40L), factora = c(0.895, 
> 0.811, 0.735, 0.777, 0.6, 0.466, 0.446, 0.392), factorb = c(0.903, 
> 0.865, 0.966, 0.732, 0.778, 0.592, 0.432, 0.294), factorc = c(0.37, 
> 0.688, 0.611, 0.653, 0.694, 0.461, 0.693, 0.686)), .Names = c("region",
> "sample", "factora", "factorb", "factorc"), class = "data.frame", row.names = c(NA, 
> -8L))
> 
> 
> mdat1  <-   melt(dat1, id.var = c("region", "sample"),
>                    variable.name = "factor",
>                    value.name = "value")
> str(mdat1)
> 
> ggplot(mdat1, aes(region, value, colour = factor)) +
>                geom_line() + facet_grid(sample ~ .)
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: drjimlemon at gmail.com
>> Sent: Wed, 10 Jun 2015 20:51:52 +1000
>> To: rosita21 at gmail.com
>> Subject: Re: [R] graphs, need urgent help (deadline :( )
>> 
>> Hi Rosa,
>> Like Don, I can't work out what you want and I don't even have the
>> picture. For example, your specification of color and line type leaves
>> only one point for each color and line type, and the line from one
>> point to the same point is not going to show up. Here is a possibility
>> that may lead (eventually) to a solution.
>> 
>> library(plotrix)
>> par(tcl=-0.1)
>> gap.plot(x=rep(seq(10,45,by=5),3),
>> y=unlist(my.data[,c("factora","factorb","factorc")]),
>> main="A plot of factorial mystery",
>> gap=c(1.1,174),ylim=c(0,175),ylab="factor score",xlab="Group",
>> xticlab=c(" \n0.1\n10"," \n0.2\n10"," \n0.1\n20"," \n0.2\n20",
>>  " \n0.1\n30"," \n0.2\n30"," \n0.1\n40"," \n0.2\n40"),
>> ytics=c(0,0.5,1,174.59),pch=rep(1:3,each=8),col=rep(c(4,2,3),each=8))
>> mtext(c("Region","Sample"),side=1,at=6,line=c(0,1))
>> lines(seq(10,45,by=5),my.data$factora,col=4)
>> lines(seq(10,45,by=5),my.data$factorb[c(1:5,NA,7,8)],col=2)
>> lines(seq(10,45,by=5),my.data$factorc,col=3)
>> 
>> Jim
>> 
>> 
>> On Wed, Jun 10, 2015 at 10:53 AM, Rosa Oliveira <rosita21 at gmail.com>
>> wrote:
>>> Dear Don and all,
>>> 
>>> I?ve read the tutorial and tried several codes before posting :)
>>> I?m really naive.
>>> 
>>> 
>>> 
>>> what I was trying to :  is something like the graph in the picture I
>>> drawee.
>>> 
>>> 
>>> 
>>> 
>>> Is it more clear now?
>>> 
>>> Atenciosamente,
>>> Rosa Oliveira
>>> 
>>> --
>>> ____________________________________________________________________________
>>> 
>>> 
>>> Rosa Celeste dos Santos Oliveira,
>>> 
>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>> Tlm: +351 939355143
>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>>> <https://pt.linkedin.com/in/rosacsoliveira>
>>> ____________________________________________________________________________
>>> "Many admire, few know"
>>> Hippocrates
>>> 
>>>> On 09 Jun 2015, at 19:23, Don McKenzie <dmck at u.washington.edu
>>>> <mailto:dmck at u.washington.edu>> wrote:
>>>> 
>>>> The answer lies in learning to use the help (and knowing where to
>>>> start).  Did you look at the tutorial that comes with the R
>>>> installation?
>>>> 
>>>> ?plot
>>>> ?lines
>>>> 
>>>> ?par
>>>> 
>>>> In the last, look for the descriptions of ?col? and ?lty?.
>>>> 
>>>> Using plot() and lines(), and subsetting the four unique values of
>>>> ?sample?, you can create your lines.
>>>> 
>>>> Here is a crude start, assuming your columns are part of a data frame
>>>> called ?my.data?.   Untested...
>>>> 
> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)
>>>> # blue line, not dashed
>>>> .
>>>> .
>>>> .
> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
>>>> # red dashed line
>>>> 
>>>> 
>>>>> On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com
>>>>> <mailto:rosita21 at gmail.com>> wrote:
>>>>> 
>>>>> Hi,
>>>>> 
>>>>> another naive question (i?m pretty sure :( )
>>>>> 
>>>>> 
>>>>> I?m trying to plot a multiple line graph:
>>>>> 
>>>>>        region              sample          factora          factorb
>>>>> factorc
>>>>> 0.1  10      0.895   0.903   0.378
>>>>> 0.2  10      0.811   0.865   0.688
>>>>> 0.1  20      0.735   0.966   0.611
>>>>> 0.2  20      0.777   0.732   0.653
>>>>> 0.1  30      0.600   0.778   0.694
>>>>> 0.2  30      0.466   174.592 0.461
>>>>> 0.1  40      0.446   0.432   0.693
>>>>> 0.2  40      0.392   0.294   0.686
>>>>> 
>>>>> 
>>>>> 
>>>>> The first column should be the independent variable, the second should
>>>>> compute a bold line for sample(10) and dash line for sample 20.
>>>> 
>>>> What about the other two values of ?sample??
>>>> 
>>>>> The others variables are outcomes for each of the first scenarios, and
>>>>> so it should: the 3rd, 4th and 5th columns should be blue, red and
>>>>> green respectively.
>>>>> 
>>>>> 
>>>>> Resume :)
>>>>> 
>>>>> I should have a graph, in the x-axe should have the region and in the
>>>>> y axe, the factor.
>>>>> Lines:
>>>>>     1 - blue and bold for region 0.1, sample 10 and factor a
>>>>>     2 - blue and dash for region 0.2, sample 10 and factor a
>>>>>     3 - red and bold for region 0.1, sample 10 and factor b
>>>>>     4 - red and dash for region 0.2, sample 10 and factor b
>>>>>     5 - green and bold for region 0.1, sample 10 and factor c
>>>>>     6 - green and dash for region 0.2, sample 10 and factor c
>>>> 
>>>> Not consistent with what you said above. These are no longer lines, but
>>>> points.
>>>>> 
>>>>> nonetheless the independent variable is nominal, I should plot a line
>>>>> graph.
>>>>> 
>>>>> Can anyone help me please?
>>>>> I have my file as a cvs file, so I first read that file (that I know
>>>>> how to do :)).
>>>>> 
>>>>> But I have it in that format.
>>>>> 
>>>>> Best,
>>>>> RO
>>>>> 
>>>>> 
>>>>> 
>>>>> Atenciosamente,
>>>>> Rosa Oliveira
>>>>> 
>>>>> --
>>>>> ____________________________________________________________________________
>>>>> 
>>>>> 
>>>>> Rosa Celeste dos Santos Oliveira,
>>>>> 
>>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>>> Tlm: +351 939355143
>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>>>>> <https://pt.linkedin.com/in/rosacsoliveira>
>>>>> ____________________________________________________________________________
>>>>> "Many admire, few know"
>>>>> Hippocrates
>>>>> 
>>>>> 
>>>>>     [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
>>>>> UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> <http://www.r-project.org/posting-guide.html>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> <PastedGraphic-1.tiff>
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
> Check it out at http://www.inbox.com/marineaquarium
> 
> 


From k.kowitski at icloud.com  Wed Jun 10 18:41:24 2015
From: k.kowitski at icloud.com (Kevin Kowitski)
Date: Wed, 10 Jun 2015 16:41:24 +0000 (GMT)
Subject: [R] Finding index of specific values in a data.frame
Message-ID: <38c771fc-7052-4b65-af9e-f2fb126cff41@me.com>

Hey everyone,?

? I am new to R and I am trying to find the index of all of the values in a data.frame. ? I have a .csv file that outputs pass, fail, error, and indeterminate readings. ?I have passed the data from the .csv to a data.frame, have performed the proper matching criteria to generate a data.frame of 0's and 1's, and am outputting the total 1's (therefore matches) found. ?I would also like to find the index of these values so that I can output a matrix containing the date and data point which has produced that match. Can anyone help set me in the right direction?

here is a github link to the code I have already generated for more clarity on the project:

https://github.com/KevinKowitski/datasciencecoursera/blob/master/ErrorCount.R

Thank you,?
Kevin

From jandeleeuw6 at gmail.com  Wed Jun 10 19:13:52 2015
From: jandeleeuw6 at gmail.com (Jan de Leeuw)
Date: Wed, 10 Jun 2015 10:13:52 -0700
Subject: [R] nonlinear MVA in R/knitr
Message-ID: <33A2A767-C4A1-42AF-8D3D-3227F84F8076@stat.ucla.edu>

http://rpubs.com/deleeuw/83572. The paper uses monotone B-splines and majorization in an R function that implements nonlinear generalizations of PCA, multiple regression, image analysis, SEM.? And much more. This extends methods in the CRAN package `aspect`. The theory has been around for 30 years but the technical improvements using R, RStudio, knitr are impressive, if I say so myself. The markdown file which contains all R and C code is at http://gifi.stat.ucla.edu/aspect.Rmd

===
Jan de Leeuw, Professor Emeritus, UCLA Statistics
8 N Stafford Street, Portland, OR 97217 ? 971-254-9331
email: deleeuw at stat.ucla.edu ? homepage: http://gifi.stat.ucla.edu


From rosita21 at gmail.com  Wed Jun 10 20:03:13 2015
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Wed, 10 Jun 2015 19:03:13 +0100
Subject: [R] graphs, need urgent help (deadline :( )
In-Reply-To: <EC24A80A-5013-4ED3-8B5A-A41B1E54AD62@u.washington.edu>
References: <10c1b087-6721-44b2-a347-851219672d30@gmail.com>
	<d2fd6c5d-e38b-4317-9ffa-6cfa6aa0d20e@gmail.com>
	<fe94928e-a651-4e9f-9643-73635938c694@u.washington.edu>
	<1535CE35A5D.00001088jrkrideau@inbox.com>
	<C77F744D-5A89-4AC7-8DFE-9073A33C3BEF@gmail.com>
	<8C64A81B-AB10-42AF-82DC-752CA2D7ECE0@u.washington.edu>
	<EC24A80A-5013-4ED3-8B5A-A41B1E54AD62@u.washington.edu>
Message-ID: <FD7328FB-306E-47A7-B0AC-A4EAC0B8AEF0@gmail.com>

Sorry,

I taught I attached the cvs file :)




Don,

I tried, but I got an error:

> my.data$Region
 [1]  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10
> my.data$sample
 [1]   50   50   50   50   50   50   50   50   50   50  250  250  250  250  250  250  250  250  250  250 1000 1000 1000 1000 1000 1000 1000 1000
[29] 1000 1000
> my.data$factor.a
 [1] 0.895 0.811 0.685 0.777 0.600 0.466 0.446 0.392 0.256 0.198 0.136 0.121 0.875 0.777 0.685 0.626 0.550 0.466 0.384 0.330 0.060 0.138 0.065
[24] 0.034 0.931 0.124 0.060 0.028 0.017 0.014


> plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=?l?,xlab=?Region?,ylab=?factor")
Error: unexpected input in "plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=??


I?m really naive, right?


Best,
RO


Atenciosamente,
Rosa Oliveira

-- 
____________________________________________________________________________


Rosa Celeste dos Santos Oliveira, 

E-mail: rosita21 at gmail.com
Tlm: +351 939355143 
Linkedin: https://pt.linkedin.com/in/rosacsoliveira
____________________________________________________________________________
"Many admire, few know"
Hippocrates

> On 10 Jun 2015, at 18:10, Don McKenzie <dmck at u.washington.edu> wrote:
> 
> For a legend, try (untested)
> 
> legend(0.15,0.9,c("factora","factorb","factorc"),col=c(4,2,3),lty=1)
> 
> If it overlaps data points move the first two arguments (0.15 and 0.9) around, or change the ?ylim? argument in the plot() to ~1.2.
> 
> to avoid clutter, put the line-types information in the figure caption (IMO)
> 
> 
>> On Jun 10, 2015, at 10:03 AM, Don McKenzie <dmck at u.washington.edu <mailto:dmck at u.washington.edu>> wrote:
>> 
>> 
>>> On Jun 10, 2015, at 9:08 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>> wrote:
>>> 
>>> Dear All,
>>> 
>>> 
>>> I attach my data.
>>> 
>>> Dear Jim, 
>>> 
>>> when I run your code (even the one you send me, not in my data), I get:
>>> 
>>> Don't know how to automatically pick scale for object of type function. Defaulting to continuous
>>> Error in data.frame(x = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1,  : 
>>>   arguments imply differing number of rows: 24, 0
>>> 
>>> 
>>> 
>>> Dear Don,
>>> 
>>> It?s meant that I will have 12 lines: 
>>> 3 factors - lines colors
>>> with 3 different values of ?sample? for each - line types
>>> 
>>> 
>>> [Three colors, one for each factor,
>>> and  three line types (lty=1,2,3), one for eachvalue of ?sample - preferable dash, thin and thick).
>>> 
>>> 
>>> in the X - I should have region (because I have 10 regions)
>>> for each region I have the outcome of 3 different treatments (factor)
>>> for each region and each treatment I have 3 different sample size.
>> 
>> But in your original post you had 4 sample sizes: 10,20,30,40.
>>> 
>>> I need to ?see? the the influence of the region in the treatment outcome for each sample size.
>>> 
>>> So, at the end I should have 9 lines
>>> 3 red (1 dash, 1 thin, 1 thick) - concerning factor a (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>> 3 blue (1 dash, 1 thin, 1 thick) - concerning factor b (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>> 3 green (1 dash, 1 thin, 1 thick) - concerning factor c (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>> 
>>> 
>>> 
>>> Hope this time is clear.
>>> 
>>> 
>>> I also though about doing 3 different graphs, each one for 1 different sample size, and in that case I should have 3 graphs each one with 3 lines
>>> 1 red to factor a, 1 blue to factor b and 1 green to factor c.
>>> 
>>> Do you all think is better?
>> 
>> A matter of style perhaps but I would use dotplots because you have only two data points for each ?line?.  The lines will be misleading.  You also could use 
>> panel plots, but given your skill set (unless someone wants to spend a fair bit of time with you), it?s probably best to stay as simple as possible.
>> 
>> But given your original post (cleaned up)   # untested: apologies for any typos
>> 
>>>        region              sample          factora          factorb 		factorc
>>> 	0.1  			10     	 0.895   		0.903   		0.378
>>> 	0.2  			10      	0.811  		 0.865  		 0.688
>>> 	0.1  			20      	0.735   		0.966   		0.611
>>> 	0.2  			20     	 0.777  		 0.732  		 0.653
>>> 	0.1  			30      	0.600   		0.778   		0.694
>>> 	0.2  			30     	 0.466  		 174.592 		0.461
>>> 	0.1  			40     	 0.446   		0.432   		0.693
>>> 	0.2  			40     	 0.392   		0.294  		 0.686
>> 
>> 
>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4,type=?l?,ylim=c(0,1),xlab=?region?,ylab=?factor")
>> lines(my.data$region[my.data$sample==10],my.data$factorb[my.data$sample==10],col=2)
>> lines(my.data$region[my.data$sample==10],my.data$factorc[my.data$sample==10],col=3)
>> 
>> lines(my.data$region[my.data$sample==20],my.data$factora[my.data$sample==20],col=4,lty=2)
>> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
>> lines(my.data$region[my.data$sample==20],my.data$factorc[my.data$sample==20],col=3,lty=2)
>> 
>> #  Now do two more groups of 3, changing the parameter ?lty? to 3 and then 4
>> 
>> 
>> # Look at the syntax and note what changes and what stays constant. Do you see how this works?
>> # there will be what looks like a vertical line where sample = 30 and factorb = 174.592.  Do you see why?
>> 
>> # then you will need a legend
>> 
>>> Nonetheless I can?t do it :(
>>> 
>>> best,
>>> RO
>>> 
>>> 
>>> 
>>> Atenciosamente,
>>> Rosa Oliveira
>>> 
>>> -- 
>>> ____________________________________________________________________________
>>>  
>>> <smile.jpg>
>>> Rosa Celeste dos Santos Oliveira, 
>>> 
>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>> Tlm: +351 939355143 
>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>> ____________________________________________________________________________
>>> "Many admire, few know"
>>> Hippocrates
>>> 
>>>> On 10 Jun 2015, at 14:13, John Kane <jrkrideau at inbox.com <mailto:jrkrideau at inbox.com>> wrote:
>>>> 
>>>> Hi Jim,
>>>> 
>>>> I was looking at that last night and had the same problem of visualizing what Rosa needed.  
>>>> 
>>>> Hi Rosa
>>>> This is nothing like what you wanted and I really don't understand your data but would something like this work as a substitute or am I completely lost?
>>>> 
>>>> 
>>>> dat1  <-  structure(list(region = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 
>>>> 0.2), sample = c(10L, 10L, 20L, 20L, 30L, 30L, 40L, 40L), factora = c(0.895, 
>>>> 0.811, 0.735, 0.777, 0.6, 0.466, 0.446, 0.392), factorb = c(0.903, 
>>>> 0.865, 0.966, 0.732, 0.778, 0.592, 0.432, 0.294), factorc = c(0.37,
>>>> 0.688, 0.611, 0.653, 0.694, 0.461, 0.693, 0.686)), .Names = c("region", 
>>>> "sample", "factora", "factorb", "factorc"), class = "data.frame", row.names = c(NA, 
>>>> -8L))
>>>> 
>>>> 
>>>> mdat1  <-   melt(dat1, id.var = c("region", "sample"),
>>>>                    variable.name = "factor",
>>>>                    value.name = "value")
>>>> str(mdat1)
>>>> 
>>>> ggplot(mdat1, aes(region, value, colour = factor)) +
>>>>                geom_line() + facet_grid(sample ~ .)
>>>> 
>>>> John Kane
>>>> Kingston ON Canada
>>>> 
>>>> 
>>>>> -----Original Message-----
>>>>> From: drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>
>>>>> Sent: Wed, 10 Jun 2015 20:51:52 +1000
>>>>> To: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>>> Subject: Re: [R] graphs, need urgent help (deadline :( )
>>>>> 
>>>>> Hi Rosa,
>>>>> Like Don, I can't work out what you want and I don't even have the
>>>>> picture. For example, your specification of color and line type leaves
>>>>> only one point for each color and line type, and the line from one
>>>>> point to the same point is not going to show up. Here is a possibility
>>>>> that may lead (eventually) to a solution.
>>>>> 
>>>>> library(plotrix)
>>>>> par(tcl=-0.1)
>>>>> gap.plot(x=rep(seq(10,45,by=5),3),
>>>>> y=unlist(my.data[,c("factora","factorb","factorc")]),
>>>>> main="A plot of factorial mystery",
>>>>> gap=c(1.1,174),ylim=c(0,175),ylab="factor score",xlab="Group",
>>>>> xticlab=c(" \n0.1\n10"," \n0.2\n10"," \n0.1\n20"," \n0.2\n20",
>>>>>  " \n0.1\n30"," \n0.2\n30"," \n0.1\n40"," \n0.2\n40"),
>>>>> ytics=c(0,0.5,1,174.59),pch=rep(1:3,each=8),col=rep(c(4,2,3),each=8))
>>>>> mtext(c("Region","Sample"),side=1,at=6,line=c(0,1))
>>>>> lines(seq(10,45,by=5),my.data$factora,col=4)
>>>>> lines(seq(10,45,by=5),my.data$factorb[c(1:5,NA,7,8)],col=2)
>>>>> lines(seq(10,45,by=5),my.data$factorc,col=3)
>>>>> 
>>>>> Jim
>>>>> 
>>>>> 
>>>>> On Wed, Jun 10, 2015 at 10:53 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>>>> wrote:
>>>>>> Dear Don and all,
>>>>>> 
>>>>>> I?ve read the tutorial and tried several codes before posting :)
>>>>>> I?m really naive.
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> what I was trying to :  is something like the graph in the picture I
>>>>>> drawee.
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> Is it more clear now?
>>>>>> 
>>>>>> Atenciosamente,
>>>>>> Rosa Oliveira
>>>>>> 
>>>>>> --
>>>>>> ____________________________________________________________________________
>>>>>> 
>>>>>> 
>>>>>> Rosa Celeste dos Santos Oliveira,
>>>>>> 
>>>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>>>>> Tlm: +351 939355143
>>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>>>>> <https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>>
>>>>>> ____________________________________________________________________________
>>>>>> "Many admire, few know"
>>>>>> Hippocrates
>>>>>> 
>>>>>>> On 09 Jun 2015, at 19:23, Don McKenzie <dmck at u.washington.edu <mailto:dmck at u.washington.edu>
>>>>>>> <mailto:dmck at u.washington.edu <mailto:dmck at u.washington.edu>>> wrote:
>>>>>>> 
>>>>>>> The answer lies in learning to use the help (and knowing where to
>>>>>>> start).  Did you look at the tutorial that comes with the R
>>>>>>> installation?
>>>>>>> 
>>>>>>> ?plot
>>>>>>> ?lines
>>>>>>> 
>>>>>>> ?par
>>>>>>> 
>>>>>>> In the last, look for the descriptions of ?col? and ?lty?.
>>>>>>> 
>>>>>>> Using plot() and lines(), and subsetting the four unique values of
>>>>>>> ?sample?, you can create your lines.
>>>>>>> 
>>>>>>> Here is a crude start, assuming your columns are part of a data frame
>>>>>>> called ?my.data?.   Untested...
>>>>>>> 
>>>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)
>>>>>>> # blue line, not dashed
>>>>>>> .
>>>>>>> .
>>>>>>> .
>>>> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
>>>>>>> # red dashed line
>>>>>>> 
>>>>>>> 
>>>>>>>> On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>>>>>> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>> wrote:
>>>>>>>> 
>>>>>>>> Hi,
>>>>>>>> 
>>>>>>>> another naive question (i?m pretty sure :( )
>>>>>>>> 
>>>>>>>> 
>>>>>>>> I?m trying to plot a multiple line graph:
>>>>>>>> 
>>>>>>>>        region              sample          factora          factorb
>>>>>>>> factorc
>>>>>>>> 0.1  10      0.895   0.903   0.378
>>>>>>>> 0.2  10      0.811   0.865   0.688
>>>>>>>> 0.1  20      0.735   0.966   0.611
>>>>>>>> 0.2  20      0.777   0.732   0.653
>>>>>>>> 0.1  30      0.600   0.778   0.694
>>>>>>>> 0.2  30      0.466   174.592 0.461
>>>>>>>> 0.1  40      0.446   0.432   0.693
>>>>>>>> 0.2  40      0.392   0.294   0.686
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> The first column should be the independent variable, the second should
>>>>>>>> compute a bold line for sample(10) and dash line for sample 20.
>>>>>>> 
>>>>>>> What about the other two values of ?sample??
>>>>>>> 
>>>>>>>> The others variables are outcomes for each of the first scenarios, and
>>>>>>>> so it should: the 3rd, 4th and 5th columns should be blue, red and
>>>>>>>> green respectively.
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Resume :)
>>>>>>>> 
>>>>>>>> I should have a graph, in the x-axe should have the region and in the
>>>>>>>> y axe, the factor.
>>>>>>>> Lines:
>>>>>>>>     1 - blue and bold for region 0.1, sample 10 and factor a
>>>>>>>>     2 - blue and dash for region 0.2, sample 10 and factor a
>>>>>>>>     3 - red and bold for region 0.1, sample 10 and factor b
>>>>>>>>     4 - red and dash for region 0.2, sample 10 and factor b
>>>>>>>>     5 - green and bold for region 0.1, sample 10 and factor c
>>>>>>>>     6 - green and dash for region 0.2, sample 10 and factor c
>>>>>>> 
>>>>>>> Not consistent with what you said above. These are no longer lines, but
>>>>>>> points.
>>>>>>>> 
>>>>>>>> nonetheless the independent variable is nominal, I should plot a line
>>>>>>>> graph.
>>>>>>>> 
>>>>>>>> Can anyone help me please?
>>>>>>>> I have my file as a cvs file, so I first read that file (that I know
>>>>>>>> how to do :)).
>>>>>>>> 
>>>>>>>> But I have it in that format.
>>>>>>>> 
>>>>>>>> Best,
>>>>>>>> RO
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Atenciosamente,
>>>>>>>> Rosa Oliveira
>>>>>>>> 
>>>>>>>> --
>>>>>>>> ____________________________________________________________________________
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Rosa Celeste dos Santos Oliveira,
>>>>>>>> 
>>>>>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>>>>>>> Tlm: +351 939355143
>>>>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>>>>>>> <https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>>
>>>>>>>> ____________________________________________________________________________
>>>>>>>> "Many admire, few know"
>>>>>>>> Hippocrates
>>>>>>>> 
>>>>>>>> 
>>>>>>>>     [[alternative HTML version deleted]]
>>>>>>>> 
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To
>>>>>>>> UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>>>>> <http://www.r-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>>
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>> 
>>>>>>> <PastedGraphic-1.tiff>
>>>>>>> 
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ____________________________________________________________
>>>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
>>>> Check it out at http://www.inbox.com/marineaquarium <http://www.inbox.com/marineaquarium>
>>>> 
>>>> 
>>> 
>> 
>> <PastedGraphic-1.tiff>
>> 
> 
> <PastedGraphic-1.tiff>
> 


From dmck at u.washington.edu  Wed Jun 10 20:22:16 2015
From: dmck at u.washington.edu (Don McKenzie)
Date: Wed, 10 Jun 2015 11:22:16 -0700
Subject: [R] graphs, need urgent help (deadline :( )
In-Reply-To: <539C8546-72DE-46F4-AE62-9DB523676B36@u.washington.edu>
References: <10c1b087-6721-44b2-a347-851219672d30@gmail.com>
	<d2fd6c5d-e38b-4317-9ffa-6cfa6aa0d20e@gmail.com>
	<fe94928e-a651-4e9f-9643-73635938c694@u.washington.edu>
	<1535CE35A5D.00001088jrkrideau@inbox.com>
	<C77F744D-5A89-4AC7-8DFE-9073A33C3BEF@gmail.com>
	<8C64A81B-AB10-42AF-82DC-752CA2D7ECE0@u.washington.edu>
	<EC24A80A-5013-4ED3-8B5A-A41B1E54AD62@u.washington.edu>
	<FD7328FB-306E-47A7-B0AC-A4EAC0B8AEF0@gmail.com>
	<539C8546-72DE-46F4-AE62-9DB523676B36@u.washington.edu>
Message-ID: <920C8ECF-A3DA-4048-9223-EC8E564BE2E4@u.washington.edu>

belay that ? something else is wrong

> On Jun 10, 2015, at 11:21 AM, Don McKenzie <dmck at u.washington.edu> wrote:
> 
> You need to substitute the real name of the data frame for ?my.data?.  That was just my example.  :-)
> 
>> On Jun 10, 2015, at 11:03 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>> wrote:
>> 
>> Sorry,
>> 
>> I taught I attached the cvs file :)
>> 
>> <therapy.csv>
>> 
>> 
>> Don,
>> 
>> I tried, but I got an error:
>> 
>> > my.data$Region
>>  [1]  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10
>> > my.data$sample
>>  [1]   50   50   50   50   50   50   50   50   50   50  250  250  250  250  250  250  250  250  250  250 1000 1000 1000 1000 1000 1000 1000 1000
>> [29] 1000 1000
>> > my.data$factor.a
>>  [1] 0.895 0.811 0.685 0.777 0.600 0.466 0.446 0.392 0.256 0.198 0.136 0.121 0.875 0.777 0.685 0.626 0.550 0.466 0.384 0.330 0.060 0.138 0.065
>> [24] 0.034 0.931 0.124 0.060 0.028 0.017 0.014
>> 
>> 
>> > plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=?l?,xlab=?Region?,ylab=?factor")
>> Error: unexpected input in "plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=??
>> 
>> 
>> I?m really naive, right?
>> 
>> 
>> Best,
>> RO
>> 
>> 
>> Atenciosamente,
>> Rosa Oliveira
>> 
>> -- 
>> ____________________________________________________________________________
>>  
>> <smile.jpg>
>> 
>> Rosa Celeste dos Santos Oliveira, 
>> 
>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>> Tlm: +351 939355143 
>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>> ____________________________________________________________________________
>> "Many admire, few know"
>> Hippocrates
>> 
>>> On 10 Jun 2015, at 18:10, Don McKenzie <dmck at u.washington.edu <mailto:dmck at u.washington.edu>> wrote:
>>> 
>>> For a legend, try (untested)
>>> 
>>> legend(0.15,0.9,c("factora","factorb","factorc"),col=c(4,2,3),lty=1)
>>> 
>>> If it overlaps data points move the first two arguments (0.15 and 0.9) around, or change the ?ylim? argument in the plot() to ~1.2.
>>> 
>>> to avoid clutter, put the line-types information in the figure caption (IMO)
>>> 
>>> 
>>>> On Jun 10, 2015, at 10:03 AM, Don McKenzie <dmck at u.washington.edu <mailto:dmck at u.washington.edu>> wrote:
>>>> 
>>>> 
>>>>> On Jun 10, 2015, at 9:08 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>> wrote:
>>>>> 
>>>>> Dear All,
>>>>> 
>>>>> 
>>>>> I attach my data.
>>>>> 
>>>>> Dear Jim, 
>>>>> 
>>>>> when I run your code (even the one you send me, not in my data), I get: 
>>>>> 
>>>>> Don't know how to automatically pick scale for object of type function. Defaulting to continuous
>>>>> Error in data.frame(x = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1,  : 
>>>>>   arguments imply differing number of rows: 24, 0
>>>>> 
>>>>> 
>>>>> 
>>>>> Dear Don,
>>>>> 
>>>>> It?s meant that I will have 12 lines: 
>>>>> 3 factors - lines colors
>>>>> with 3 different values of ?sample? for each - line types
>>>>> 
>>>>> 
>>>>> [Three colors, one for each factor,
>>>>> and  three line types (lty=1,2,3), one for eachvalue of ?sample - preferable dash, thin and thick).
>>>>> 
>>>>> 
>>>>> in the X - I should have region (because I have 10 regions)
>>>>> for each region I have the outcome of 3 different treatments (factor)
>>>>> for each region and each treatment I have 3 different sample size.
>>>> 
>>>> But in your original post you had 4 sample sizes: 10,20,30,40.
>>>>> 
>>>>> I need to ?see? the the influence of the region in the treatment outcome for each sample size.
>>>>> 
>>>>> So, at the end I should have 9 lines
>>>>> 3 red (1 dash, 1 thin, 1 thick) - concerning factor a (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>>>> 3 blue (1 dash, 1 thin, 1 thick) - concerning factor b (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>>>> 3 green (1 dash, 1 thin, 1 thick) - concerning factor c (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>>>> 
>>>>> 
>>>>> 
>>>>> Hope this time is clear.
>>>>> 
>>>>> 
>>>>> I also though about doing 3 different graphs, each one for 1 different sample size, and in that case I should have 3 graphs each one with 3 lines
>>>>> 1 red to factor a, 1 blue to factor b and 1 green to factor c.
>>>>> 
>>>>> Do you all think is better?
>>>> 
>>>> A matter of style perhaps but I would use dotplots because you have only two data points for each ?line?.  The lines will be misleading.  You also could use 
>>>> panel plots, but given your skill set (unless someone wants to spend a fair bit of time with you), it?s probably best to stay as simple as possible.
>>>> 
>>>> But given your original post (cleaned up)   # untested: apologies for any typos
>>>> 
>>>>>        region              sample          factora          factorb 		factorc
>>>>> 	0.1  			10     	 0.895   		0.903   		0.378
>>>>> 	0.2  			10      	0.811  		 0.865  		 0.688
>>>>> 	0.1  			20      	0.735   		0.966   		0.611
>>>>> 	0.2  			20     	 0.777  		 0.732  		 0.653
>>>>> 	0.1  			30      	0.600   		0.778   		0.694
>>>>> 	0.2  			30     	 0.466  		 174.592 		0.461
>>>>> 	0.1  			40     	 0.446   		0.432   		0.693
>>>>> 	0.2  			40     	 0.392   		0.294  		 0.686
>>>> 
>>>> 
>>>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4,type=?l?,ylim=c(0,1),xlab=?region?,ylab=?factor")
>>>> lines(my.data$region[my.data$sample==10],my.data$factorb[my.data$sample==10],col=2)
>>>> lines(my.data$region[my.data$sample==10],my.data$factorc[my.data$sample==10],col=3)
>>>> 
>>>> lines(my.data$region[my.data$sample==20],my.data$factora[my.data$sample==20],col=4,lty=2)
>>>> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
>>>> lines(my.data$region[my.data$sample==20],my.data$factorc[my.data$sample==20],col=3,lty=2)
>>>> 
>>>> #  Now do two more groups of 3, changing the parameter ?lty? to 3 and then 4
>>>> 
>>>> 
>>>> # Look at the syntax and note what changes and what stays constant. Do you see how this works?
>>>> # there will be what looks like a vertical line where sample = 30 and factorb = 174.592.  Do you see why?
>>>> 
>>>> # then you will need a legend
>>>> 
>>>>> Nonetheless I can?t do it :(
>>>>> 
>>>>> best,
>>>>> RO
>>>>> 
>>>>> 
>>>>> 
>>>>> Atenciosamente,
>>>>> Rosa Oliveira
>>>>> 
>>>>> -- 
>>>>> ____________________________________________________________________________
>>>>>  
>>>>> <smile.jpg>
>>>>> Rosa Celeste dos Santos Oliveira, 
>>>>> 
>>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>>> Tlm: +351 939355143 
>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>>>> ____________________________________________________________________________
>>>>> "Many admire, few know"
>>>>> Hippocrates
>>>>> 
>>>>>> On 10 Jun 2015, at 14:13, John Kane <jrkrideau at inbox.com <mailto:jrkrideau at inbox.com>> wrote:
>>>>>> 
>>>>>> Hi Jim,
>>>>>> 
>>>>>> I was looking at that last night and had the same problem of visualizing what Rosa needed.  
>>>>>> 
>>>>>> Hi Rosa
>>>>>> This is nothing like what you wanted and I really don't understand your data but would something like this work as a substitute or am I completely lost?
>>>>>> 
>>>>>> 
>>>>>> dat1  <-  structure(list(region = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 
>>>>>> 0.2), sample = c(10L, 10L, 20L, 20L, 30L, 30L, 40L, 40L), factora = c(0.895, 
>>>>>> 0.811, 0.735, 0.777, 0.6, 0.466, 0.446, 0.392), factorb = c(0.903, 
>>>>>> 0.865, 0.966, 0.732, 0.778, 0.592, 0.432, 0.294), factorc = c(0.37, 
>>>>>> 0.688, 0.611, 0.653, 0.694, 0.461, 0.693, 0.686)), .Names = c("region", 
>>>>>> "sample", "factora", "factorb", "factorc"), class = "data.frame", row.names = c(NA, 
>>>>>> -8L))
>>>>>> 
>>>>>> 
>>>>>> mdat1  <-   melt(dat1, id.var = c("region", "sample"),
>>>>>>                    variable.name = "factor",
>>>>>>                    value.name = "value")
>>>>>> str(mdat1)
>>>>>> 
>>>>>> ggplot(mdat1, aes(region, value, colour = factor)) +
>>>>>>                geom_line() + facet_grid(sample ~ .)
>>>>>> 
>>>>>> John Kane
>>>>>> Kingston ON Canada
>>>>>> 
>>>>>> 
>>>>>>> -----Original Message-----
>>>>>>> From: drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>
>>>>>>> Sent: Wed, 10 Jun 2015 20:51:52 +1000
>>>>>>> To: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>>>>> Subject: Re: [R] graphs, need urgent help (deadline :( )
>>>>>>> 
>>>>>>> Hi Rosa,
>>>>>>> Like Don, I can't work out what you want and I don't even have the
>>>>>>> picture. For example, your specification of color and line type leaves
>>>>>>> only one point for each color and line type, and the line from one
>>>>>>> point to the same point is not going to show up. Here is a possibility
>>>>>>> that may lead (eventually) to a solution.
>>>>>>> 
>>>>>>> library(plotrix)
>>>>>>> par(tcl=-0.1)
>>>>>>> gap.plot(x=rep(seq(10,45,by=5),3),
>>>>>>> y=unlist(my.data[,c("factora","factorb","factorc")]),
>>>>>>> main="A plot of factorial mystery",
>>>>>>> gap=c(1.1,174),ylim=c(0,175),ylab="factor score",xlab="Group",
>>>>>>> xticlab=c(" \n0.1\n10"," \n0.2\n10"," \n0.1\n20"," \n0.2\n20",
>>>>>>>  " \n0.1\n30"," \n0.2\n30"," \n0.1\n40"," \n0.2\n40"),
>>>>>>> ytics=c(0,0.5,1,174.59),pch=rep(1:3,each=8),col=rep(c(4,2,3),each=8))
>>>>>>> mtext(c("Region","Sample"),side=1,at=6,line=c(0,1))
>>>>>>> lines(seq(10,45,by=5),my.data$factora,col=4)
>>>>>>> lines(seq(10,45,by=5),my.data$factorb[c(1:5,NA,7,8)],col=2)
>>>>>>> lines(seq(10,45,by=5),my.data$factorc,col=3)
>>>>>>> 
>>>>>>> Jim
>>>>>>> 
>>>>>>> 
>>>>>>> On Wed, Jun 10, 2015 at 10:53 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>>>>>> wrote:
>>>>>>>> Dear Don and all,
>>>>>>>> 
>>>>>>>> I?ve read the tutorial and tried several codes before posting :)
>>>>>>>> I?m really naive.
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> what I was trying to :  is something like the graph in the picture I
>>>>>>>> drawee.
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Is it more clear now?
>>>>>>>> 
>>>>>>>> Atenciosamente,
>>>>>>>> Rosa Oliveira
>>>>>>>> 
>>>>>>>> --
>>>>>>>> ____________________________________________________________________________
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Rosa Celeste dos Santos Oliveira,
>>>>>>>> 
>>>>>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>>>>>>> Tlm: +351 939355143
>>>>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>>>>>>> <https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>>
>>>>>>>> ____________________________________________________________________________
>>>>>>>> "Many admire, few know"
>>>>>>>> Hippocrates
>>>>>>>> 
>>>>>>>>> On 09 Jun 2015, at 19:23, Don McKenzie <dmck at u.washington.edu <mailto:dmck at u.washington.edu>
>>>>>>>>> <mailto:dmck at u.washington.edu <mailto:dmck at u.washington.edu>>> wrote:
>>>>>>>>> 
>>>>>>>>> The answer lies in learning to use the help (and knowing where to
>>>>>>>>> start).  Did you look at the tutorial that comes with the R
>>>>>>>>> installation?
>>>>>>>>> 
>>>>>>>>> ?plot
>>>>>>>>> ?lines
>>>>>>>>> 
>>>>>>>>> ?par
>>>>>>>>> 
>>>>>>>>> In the last, look for the descriptions of ?col? and ?lty?.
>>>>>>>>> 
>>>>>>>>> Using plot() and lines(), and subsetting the four unique values of
>>>>>>>>> ?sample?, you can create your lines.
>>>>>>>>> 
>>>>>>>>> Here is a crude start, assuming your columns are part of a data frame
>>>>>>>>> called ?my.data?.   Untested...
>>>>>>>>> 
>>>>>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)
>>>>>>>>> # blue line, not dashed
>>>>>>>>> .
>>>>>>>>> .
>>>>>>>>> .
>>>>>> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
>>>>>>>>> # red dashed line
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>>> On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>>>>>>>> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>> wrote:
>>>>>>>>>> 
>>>>>>>>>> Hi,
>>>>>>>>>> 
>>>>>>>>>> another naive question (i?m pretty sure :( )
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> I?m trying to plot a multiple line graph:
>>>>>>>>>> 
>>>>>>>>>>        region              sample          factora          factorb
>>>>>>>>>> factorc
>>>>>>>>>> 0.1  10      0.895   0.903   0.378
>>>>>>>>>> 0.2  10      0.811   0.865   0.688
>>>>>>>>>> 0.1  20      0.735   0.966   0.611
>>>>>>>>>> 0.2  20      0.777   0.732   0.653
>>>>>>>>>> 0.1  30      0.600   0.778   0.694
>>>>>>>>>> 0.2  30      0.466   174.592 0.461
>>>>>>>>>> 0.1  40      0.446   0.432   0.693
>>>>>>>>>> 0.2  40      0.392   0.294   0.686
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> The first column should be the independent variable, the second should
>>>>>>>>>> compute a bold line for sample(10) and dash line for sample 20.
>>>>>>>>> 
>>>>>>>>> What about the other two values of ?sample??
>>>>>>>>> 
>>>>>>>>>> The others variables are outcomes for each of the first scenarios, and
>>>>>>>>>> so it should: the 3rd, 4th and 5th columns should be blue, red and
>>>>>>>>>> green respectively.
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Resume :)
>>>>>>>>>> 
>>>>>>>>>> I should have a graph, in the x-axe should have the region and in the
>>>>>>>>>> y axe, the factor.
>>>>>>>>>> Lines:
>>>>>>>>>>     1 - blue and bold for region 0.1, sample 10 and factor a
>>>>>>>>>>     2 - blue and dash for region 0.2, sample 10 and factor a
>>>>>>>>>>     3 - red and bold for region 0.1, sample 10 and factor b
>>>>>>>>>>     4 - red and dash for region 0.2, sample 10 and factor b
>>>>>>>>>>     5 - green and bold for region 0.1, sample 10 and factor c
>>>>>>>>>>     6 - green and dash for region 0.2, sample 10 and factor c
>>>>>>>>> 
>>>>>>>>> Not consistent with what you said above. These are no longer lines, but
>>>>>>>>> points.
>>>>>>>>>> 
>>>>>>>>>> nonetheless the independent variable is nominal, I should plot a line
>>>>>>>>>> graph.
>>>>>>>>>> 
>>>>>>>>>> Can anyone help me please?
>>>>>>>>>> I have my file as a cvs file, so I first read that file (that I know
>>>>>>>>>> how to do :)).
>>>>>>>>>> 
>>>>>>>>>> But I have it in that format.
>>>>>>>>>> 
>>>>>>>>>> Best,
>>>>>>>>>> RO
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Atenciosamente,
>>>>>>>>>> Rosa Oliveira
>>>>>>>>>> 
>>>>>>>>>> --
>>>>>>>>>> ____________________________________________________________________________
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Rosa Celeste dos Santos Oliveira,
>>>>>>>>>> 
>>>>>>>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>>>>>>>>> Tlm: +351 939355143
>>>>>>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>>>>>>>>> <https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>>
>>>>>>>>>> ____________________________________________________________________________
>>>>>>>>>> "Many admire, few know"
>>>>>>>>>> Hippocrates
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>>     [[alternative HTML version deleted]]
>>>>>>>>>> 
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To
>>>>>>>>>> UNSUBSCRIBE and more, see
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>>>>>>> <http://www.r-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>>
>>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>> 
>>>>>>>>> <PastedGraphic-1.tiff>
>>>>>>>>> 
>>>>>>>> 
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>>> ____________________________________________________________
>>>>>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
>>>>>> Check it out at http://www.inbox.com/marineaquarium <http://www.inbox.com/marineaquarium>
>>>>>> 
>>>>>> 
>>>>> 
>>>> 
>>>> <PastedGraphic-1.tiff>
>>>> 
>>> 
>>> <PastedGraphic-1.tiff>
>>> 
>> 
> 
> <PastedGraphic-1.tiff>
> 




From dmck at U.WASHINGTON.EDU  Wed Jun 10 20:32:59 2015
From: dmck at U.WASHINGTON.EDU (Don McKenzie)
Date: Wed, 10 Jun 2015 11:32:59 -0700
Subject: [R] graphs, need urgent help (deadline :( )
In-Reply-To: <FD7328FB-306E-47A7-B0AC-A4EAC0B8AEF0@gmail.com>
References: <10c1b087-6721-44b2-a347-851219672d30@gmail.com>
	<d2fd6c5d-e38b-4317-9ffa-6cfa6aa0d20e@gmail.com>
	<fe94928e-a651-4e9f-9643-73635938c694@u.washington.edu>
	<1535CE35A5D.00001088jrkrideau@inbox.com>
	<C77F744D-5A89-4AC7-8DFE-9073A33C3BEF@gmail.com>
	<8C64A81B-AB10-42AF-82DC-752CA2D7ECE0@u.washington.edu>
	<EC24A80A-5013-4ED3-8B5A-A41B1E54AD62@u.washington.edu>
	<FD7328FB-306E-47A7-B0AC-A4EAC0B8AEF0@gmail.com>
Message-ID: <9CEDC8C3-EF9B-4721-9900-F7A718129BC9@u.washington.edu>

You were caught by a mysterious issue that I don?t understand either.

plot(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.a[therapy.df$sample==50],col=4,type=?l?,xlab=?Region?,ylab=?factor")
Error: unexpected input in "plot(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.a[therapy.df$sample==50],col=4,type=??


but if I change the order of arguments to plot(), it?s fine

plot(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.a[therapy.df$sample==50],type="l",col=4,xlab="Region",ylab="factor?)

I don?t know what to tell you.  If someone wiser than I is still reading, maybe s(he) can explain.  Possibly a bug has crept into the call to ?par?, but ?bugs" suspected by non-experts like me usually turn out to be naive user errors.  

For your purposes, use the one that works.  :-)

> On Jun 10, 2015, at 11:03 AM, Rosa Oliveira <rosita21 at gmail.com> wrote:
> 
> Sorry,
> 
> I taught I attached the cvs file :)
> 
> <therapy.csv>
> 
> 
> Don,
> 
> I tried, but I got an error:
> 
> > my.data$Region
>  [1]  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10
> > my.data$sample
>  [1]   50   50   50   50   50   50   50   50   50   50  250  250  250  250  250  250  250  250  250  250 1000 1000 1000 1000 1000 1000 1000 1000
> [29] 1000 1000
> > my.data$factor.a
>  [1] 0.895 0.811 0.685 0.777 0.600 0.466 0.446 0.392 0.256 0.198 0.136 0.121 0.875 0.777 0.685 0.626 0.550 0.466 0.384 0.330 0.060 0.138 0.065
> [24] 0.034 0.931 0.124 0.060 0.028 0.017 0.014
> 
> 
> > plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=?l?,xlab=?Region?,ylab=?factor")
> Error: unexpected input in "plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=??
> 
> 
> I?m really naive, right?
> 
> 
> Best,
> RO
> 
> 
> Atenciosamente,
> Rosa Oliveira
> 
> -- 
> ____________________________________________________________________________
>  
> <smile.jpg>
> 
> Rosa Celeste dos Santos Oliveira, 
> 
> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
> Tlm: +351 939355143 
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
> 
>> On 10 Jun 2015, at 18:10, Don McKenzie <dmck at u.washington.edu <mailto:dmck at u.washington.edu>> wrote:
>> 
>> For a legend, try (untested)
>> 
>> legend(0.15,0.9,c("factora","factorb","factorc"),col=c(4,2,3),lty=1)
>> 
>> If it overlaps data points move the first two arguments (0.15 and 0.9) around, or change the ?ylim? argument in the plot() to ~1.2.
>> 
>> to avoid clutter, put the line-types information in the figure caption (IMO)
>> 
>> 
>>> On Jun 10, 2015, at 10:03 AM, Don McKenzie <dmck at u.washington.edu <mailto:dmck at u.washington.edu>> wrote:
>>> 
>>> 
>>>> On Jun 10, 2015, at 9:08 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>> wrote:
>>>> 
>>>> Dear All,
>>>> 
>>>> 
>>>> I attach my data.
>>>> 
>>>> Dear Jim, 
>>>> 
>>>> when I run your code (even the one you send me, not in my data), I get: 
>>>> 
>>>> Don't know how to automatically pick scale for object of type function. Defaulting to continuous
>>>> Error in data.frame(x = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1,  : 
>>>>   arguments imply differing number of rows: 24, 0
>>>> 
>>>> 
>>>> 
>>>> Dear Don,
>>>> 
>>>> It?s meant that I will have 12 lines: 
>>>> 3 factors - lines colors
>>>> with 3 different values of ?sample? for each - line types
>>>> 
>>>> 
>>>> [Three colors, one for each factor,
>>>> and  three line types (lty=1,2,3), one for eachvalue of ?sample - preferable dash, thin and thick).
>>>> 
>>>> 
>>>> in the X - I should have region (because I have 10 regions)
>>>> for each region I have the outcome of 3 different treatments (factor)
>>>> for each region and each treatment I have 3 different sample size.
>>> 
>>> But in your original post you had 4 sample sizes: 10,20,30,40.
>>>> 
>>>> I need to ?see? the the influence of the region in the treatment outcome for each sample size.
>>>> 
>>>> So, at the end I should have 9 lines
>>>> 3 red (1 dash, 1 thin, 1 thick) - concerning factor a (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>>> 3 blue (1 dash, 1 thin, 1 thick) - concerning factor b (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>>> 3 green (1 dash, 1 thin, 1 thick) - concerning factor c (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>>> 
>>>> 
>>>> 
>>>> Hope this time is clear.
>>>> 
>>>> 
>>>> I also though about doing 3 different graphs, each one for 1 different sample size, and in that case I should have 3 graphs each one with 3 lines
>>>> 1 red to factor a, 1 blue to factor b and 1 green to factor c.
>>>> 
>>>> Do you all think is better?
>>> 
>>> A matter of style perhaps but I would use dotplots because you have only two data points for each ?line?.  The lines will be misleading.  You also could use 
>>> panel plots, but given your skill set (unless someone wants to spend a fair bit of time with you), it?s probably best to stay as simple as possible.
>>> 
>>> But given your original post (cleaned up)   # untested: apologies for any typos
>>> 
>>>>        region              sample          factora          factorb 		factorc
>>>> 	0.1  			10     	 0.895   		0.903   		0.378
>>>> 	0.2  			10      	0.811  		 0.865  		 0.688
>>>> 	0.1  			20      	0.735   		0.966   		0.611
>>>> 	0.2  			20     	 0.777  		 0.732  		 0.653
>>>> 	0.1  			30      	0.600   		0.778   		0.694
>>>> 	0.2  			30     	 0.466  		 174.592 		0.461
>>>> 	0.1  			40     	 0.446   		0.432   		0.693
>>>> 	0.2  			40     	 0.392   		0.294  		 0.686
>>> 
>>> 
>>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4,type=?l?,ylim=c(0,1),xlab=?region?,ylab=?factor")
>>> lines(my.data$region[my.data$sample==10],my.data$factorb[my.data$sample==10],col=2)
>>> lines(my.data$region[my.data$sample==10],my.data$factorc[my.data$sample==10],col=3)
>>> 
>>> lines(my.data$region[my.data$sample==20],my.data$factora[my.data$sample==20],col=4,lty=2)
>>> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
>>> lines(my.data$region[my.data$sample==20],my.data$factorc[my.data$sample==20],col=3,lty=2)
>>> 
>>> #  Now do two more groups of 3, changing the parameter ?lty? to 3 and then 4
>>> 
>>> 
>>> # Look at the syntax and note what changes and what stays constant. Do you see how this works?
>>> # there will be what looks like a vertical line where sample = 30 and factorb = 174.592.  Do you see why?
>>> 
>>> # then you will need a legend
>>> 
>>>> Nonetheless I can?t do it :(
>>>> 
>>>> best,
>>>> RO
>>>> 
>>>> 
>>>> 
>>>> Atenciosamente,
>>>> Rosa Oliveira
>>>> 
>>>> -- 
>>>> ____________________________________________________________________________
>>>>  
>>>> <smile.jpg>
>>>> Rosa Celeste dos Santos Oliveira, 
>>>> 
>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>> Tlm: +351 939355143 
>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>>> ____________________________________________________________________________
>>>> "Many admire, few know"
>>>> Hippocrates
>>>> 
>>>>> On 10 Jun 2015, at 14:13, John Kane <jrkrideau at inbox.com <mailto:jrkrideau at inbox.com>> wrote:
>>>>> 
>>>>> Hi Jim,
>>>>> 
>>>>> I was looking at that last night and had the same problem of visualizing what Rosa needed.  
>>>>> 
>>>>> Hi Rosa
>>>>> This is nothing like what you wanted and I really don't understand your data but would something like this work as a substitute or am I completely lost?
>>>>> 
>>>>> 
>>>>> dat1  <-  structure(list(region = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 
>>>>> 0.2), sample = c(10L, 10L, 20L, 20L, 30L, 30L, 40L, 40L), factora = c(0.895, 
>>>>> 0.811, 0.735, 0.777, 0.6, 0.466, 0.446, 0.392), factorb = c(0.903, 
>>>>> 0.865, 0.966, 0.732, 0.778, 0.592, 0.432, 0.294), factorc = c(0.37, 
>>>>> 0.688, 0.611, 0.653, 0.694, 0.461, 0.693, 0.686)), .Names = c("region", 
>>>>> "sample", "factora", "factorb", "factorc"), class = "data.frame", row.names = c(NA, 
>>>>> -8L))
>>>>> 
>>>>> 
>>>>> mdat1  <-   melt(dat1, id.var = c("region", "sample"),
>>>>>                    variable.name = "factor",
>>>>>                    value.name = "value")
>>>>> str(mdat1)
>>>>> 
>>>>> ggplot(mdat1, aes(region, value, colour = factor)) +
>>>>>                geom_line() + facet_grid(sample ~ .)
>>>>> 
>>>>> John Kane
>>>>> Kingston ON Canada
>>>>> 
>>>>> 
>>>>>> -----Original Message-----
>>>>>> From: drjimlemon at gmail.com <mailto:drjimlemon at gmail.com>
>>>>>> Sent: Wed, 10 Jun 2015 20:51:52 +1000
>>>>>> To: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>>>> Subject: Re: [R] graphs, need urgent help (deadline :( )
>>>>>> 
>>>>>> Hi Rosa,
>>>>>> Like Don, I can't work out what you want and I don't even have the
>>>>>> picture. For example, your specification of color and line type leaves
>>>>>> only one point for each color and line type, and the line from one
>>>>>> point to the same point is not going to show up. Here is a possibility
>>>>>> that may lead (eventually) to a solution.
>>>>>> 
>>>>>> library(plotrix)
>>>>>> par(tcl=-0.1)
>>>>>> gap.plot(x=rep(seq(10,45,by=5),3),
>>>>>> y=unlist(my.data[,c("factora","factorb","factorc")]),
>>>>>> main="A plot of factorial mystery",
>>>>>> gap=c(1.1,174),ylim=c(0,175),ylab="factor score",xlab="Group",
>>>>>> xticlab=c(" \n0.1\n10"," \n0.2\n10"," \n0.1\n20"," \n0.2\n20",
>>>>>>  " \n0.1\n30"," \n0.2\n30"," \n0.1\n40"," \n0.2\n40"),
>>>>>> ytics=c(0,0.5,1,174.59),pch=rep(1:3,each=8),col=rep(c(4,2,3),each=8))
>>>>>> mtext(c("Region","Sample"),side=1,at=6,line=c(0,1))
>>>>>> lines(seq(10,45,by=5),my.data$factora,col=4)
>>>>>> lines(seq(10,45,by=5),my.data$factorb[c(1:5,NA,7,8)],col=2)
>>>>>> lines(seq(10,45,by=5),my.data$factorc,col=3)
>>>>>> 
>>>>>> Jim
>>>>>> 
>>>>>> 
>>>>>> On Wed, Jun 10, 2015 at 10:53 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>>>>> wrote:
>>>>>>> Dear Don and all,
>>>>>>> 
>>>>>>> I?ve read the tutorial and tried several codes before posting :)
>>>>>>> I?m really naive.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> what I was trying to :  is something like the graph in the picture I
>>>>>>> drawee.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> Is it more clear now?
>>>>>>> 
>>>>>>> Atenciosamente,
>>>>>>> Rosa Oliveira
>>>>>>> 
>>>>>>> --
>>>>>>> ____________________________________________________________________________
>>>>>>> 
>>>>>>> 
>>>>>>> Rosa Celeste dos Santos Oliveira,
>>>>>>> 
>>>>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>>>>>> Tlm: +351 939355143
>>>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>>>>>> <https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>>
>>>>>>> ____________________________________________________________________________
>>>>>>> "Many admire, few know"
>>>>>>> Hippocrates
>>>>>>> 
>>>>>>>> On 09 Jun 2015, at 19:23, Don McKenzie <dmck at u.washington.edu <mailto:dmck at u.washington.edu>
>>>>>>>> <mailto:dmck at u.washington.edu <mailto:dmck at u.washington.edu>>> wrote:
>>>>>>>> 
>>>>>>>> The answer lies in learning to use the help (and knowing where to
>>>>>>>> start).  Did you look at the tutorial that comes with the R
>>>>>>>> installation?
>>>>>>>> 
>>>>>>>> ?plot
>>>>>>>> ?lines
>>>>>>>> 
>>>>>>>> ?par
>>>>>>>> 
>>>>>>>> In the last, look for the descriptions of ?col? and ?lty?.
>>>>>>>> 
>>>>>>>> Using plot() and lines(), and subsetting the four unique values of
>>>>>>>> ?sample?, you can create your lines.
>>>>>>>> 
>>>>>>>> Here is a crude start, assuming your columns are part of a data frame
>>>>>>>> called ?my.data?.   Untested...
>>>>>>>> 
>>>>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)
>>>>>>>> # blue line, not dashed
>>>>>>>> .
>>>>>>>> .
>>>>>>>> .
>>>>> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
>>>>>>>> # red dashed line
>>>>>>>> 
>>>>>>>> 
>>>>>>>>> On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>>>>>>> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>> wrote:
>>>>>>>>> 
>>>>>>>>> Hi,
>>>>>>>>> 
>>>>>>>>> another naive question (i?m pretty sure :( )
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> I?m trying to plot a multiple line graph:
>>>>>>>>> 
>>>>>>>>>        region              sample          factora          factorb
>>>>>>>>> factorc
>>>>>>>>> 0.1  10      0.895   0.903   0.378
>>>>>>>>> 0.2  10      0.811   0.865   0.688
>>>>>>>>> 0.1  20      0.735   0.966   0.611
>>>>>>>>> 0.2  20      0.777   0.732   0.653
>>>>>>>>> 0.1  30      0.600   0.778   0.694
>>>>>>>>> 0.2  30      0.466   174.592 0.461
>>>>>>>>> 0.1  40      0.446   0.432   0.693
>>>>>>>>> 0.2  40      0.392   0.294   0.686
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> The first column should be the independent variable, the second should
>>>>>>>>> compute a bold line for sample(10) and dash line for sample 20.
>>>>>>>> 
>>>>>>>> What about the other two values of ?sample??
>>>>>>>> 
>>>>>>>>> The others variables are outcomes for each of the first scenarios, and
>>>>>>>>> so it should: the 3rd, 4th and 5th columns should be blue, red and
>>>>>>>>> green respectively.
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Resume :)
>>>>>>>>> 
>>>>>>>>> I should have a graph, in the x-axe should have the region and in the
>>>>>>>>> y axe, the factor.
>>>>>>>>> Lines:
>>>>>>>>>     1 - blue and bold for region 0.1, sample 10 and factor a
>>>>>>>>>     2 - blue and dash for region 0.2, sample 10 and factor a
>>>>>>>>>     3 - red and bold for region 0.1, sample 10 and factor b
>>>>>>>>>     4 - red and dash for region 0.2, sample 10 and factor b
>>>>>>>>>     5 - green and bold for region 0.1, sample 10 and factor c
>>>>>>>>>     6 - green and dash for region 0.2, sample 10 and factor c
>>>>>>>> 
>>>>>>>> Not consistent with what you said above. These are no longer lines, but
>>>>>>>> points.
>>>>>>>>> 
>>>>>>>>> nonetheless the independent variable is nominal, I should plot a line
>>>>>>>>> graph.
>>>>>>>>> 
>>>>>>>>> Can anyone help me please?
>>>>>>>>> I have my file as a cvs file, so I first read that file (that I know
>>>>>>>>> how to do :)).
>>>>>>>>> 
>>>>>>>>> But I have it in that format.
>>>>>>>>> 
>>>>>>>>> Best,
>>>>>>>>> RO
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Atenciosamente,
>>>>>>>>> Rosa Oliveira
>>>>>>>>> 
>>>>>>>>> --
>>>>>>>>> ____________________________________________________________________________
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Rosa Celeste dos Santos Oliveira,
>>>>>>>>> 
>>>>>>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com> <mailto:rosita21 at gmail.com <mailto:rosita21 at gmail.com>>
>>>>>>>>> Tlm: +351 939355143
>>>>>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>>>>>>>>> <https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>>
>>>>>>>>> ____________________________________________________________________________
>>>>>>>>> "Many admire, few know"
>>>>>>>>> Hippocrates
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>>     [[alternative HTML version deleted]]
>>>>>>>>> 
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To
>>>>>>>>> UNSUBSCRIBE and more, see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>>>>>> <http://www.r-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>>
>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>> 
>>>>>>>> <PastedGraphic-1.tiff>
>>>>>>>> 
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> ____________________________________________________________
>>>>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
>>>>> Check it out at http://www.inbox.com/marineaquarium <http://www.inbox.com/marineaquarium>
>>>>> 
>>>>> 
>>>> 
>>> 
>>> <PastedGraphic-1.tiff>
>>> 
>> 
>> <PastedGraphic-1.tiff>
>> 
> 




From dwinsemius at comcast.net  Wed Jun 10 21:18:13 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 10 Jun 2015 12:18:13 -0700
Subject: [R] Split data frame into 250-row chunks
In-Reply-To: <9E2E1B7D-6A42-4A88-948F-9A29F0EEA988@earthlink.net>
References: <9E2E1B7D-6A42-4A88-948F-9A29F0EEA988@earthlink.net>
Message-ID: <215EA26F-EF92-4852-A7D8-22FA75B01394@comcast.net>


On Jun 10, 2015, at 5:39 AM, Liz Hare wrote:

> Hi R-Experts,
> 
> I have a data.frame like this:
> 
>> head(map)
>  chr snp   poscm   posbp    dist
> 1   1  M1 2.99043 3249189      NA
> 2   1  M2 3.06457 3273096 0.07414
> 3   1  M3 3.17018 3307151 0.10561
> 4   1  M4 3.20892 3319643 0.03874
> 5   1  M5 3.28120 3342947 0.07228
> 6   1  M6 3.29624 3347798 0.01504
> 
> I need to split this into chunks of 250 rows (there will usually be a last chunk with < 250 rows).

split( map, trunc( 0:(nrow(map)-1 )/nrow(map) ) )

Untested. Designed to return a list with indices starting at "0".

> trunc( 0:19/5)
 [1] 0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3



> 
> If I only had to extract one 250-line chunk, it would be easy:
> 
> map1 <- map[1:250, ]
> 
> or using subset().
> 
> I tried to make it a loop iterating through num and using beg and nd for starting and ending indices, but I couldn?t figure out how to reference all the variables I needed in this:
> 
>> chunks
>    beg   nd let num
> 1     1  250   a   1
> 2   251  500   b   2
> 3   501  750   c   3
> 4   751 1000   d   4
> 5  1001 1250   e   5
> 6  1251 1500   f   6
> 7  1501 1750   g   7
> 8  1751 2000   h   8
> 9  2001 2250   i   9
> 10 2251 2500   j  10
> ?
> 
> Remembering that loops are not always the best answer in R, I looked at other options like split, following this example but not being able to adapt it from a vector to a data.frame version
> http://stackoverflow.com/questions/3318333/split-a-vector-into-chunks-in-r <http://stackoverflow.com/questions/3318333/split-a-vector-into-chunks-in-r> (Yes, I?ve reviewed the language documentation). I checked out ddply and data.table, but couldn?t find a way to use them with index positions instead of column values.
> 
> Thanks,
> Liz
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From marc_schwartz at me.com  Wed Jun 10 21:21:21 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 10 Jun 2015 14:21:21 -0500
Subject: [R] Split data frame into 250-row chunks
In-Reply-To: <9E2E1B7D-6A42-4A88-948F-9A29F0EEA988@earthlink.net>
References: <9E2E1B7D-6A42-4A88-948F-9A29F0EEA988@earthlink.net>
Message-ID: <ECE0CF46-C229-4E7D-9505-24E8EA2CA1CF@me.com>


> On Jun 10, 2015, at 7:39 AM, Liz Hare <doggene at earthlink.net> wrote:
> 
> Hi R-Experts,
> 
> I have a data.frame like this:
> 
>> head(map)
>  chr snp   poscm   posbp    dist
> 1   1  M1 2.99043 3249189      NA
> 2   1  M2 3.06457 3273096 0.07414
> 3   1  M3 3.17018 3307151 0.10561
> 4   1  M4 3.20892 3319643 0.03874
> 5   1  M5 3.28120 3342947 0.07228
> 6   1  M6 3.29624 3347798 0.01504
> 
> I need to split this into chunks of 250 rows (there will usually be a last chunk with < 250 rows).
> 
> If I only had to extract one 250-line chunk, it would be easy:
> 
> map1 <- map[1:250, ]
> 
> or using subset().
> 
> I tried to make it a loop iterating through num and using beg and nd for starting and ending indices, but I couldn?t figure out how to reference all the variables I needed in this:
> 
>> chunks
>    beg   nd let num
> 1     1  250   a   1
> 2   251  500   b   2
> 3   501  750   c   3
> 4   751 1000   d   4
> 5  1001 1250   e   5
> 6  1251 1500   f   6
> 7  1501 1750   g   7
> 8  1751 2000   h   8
> 9  2001 2250   i   9
> 10 2251 2500   j  10
> ?
> 
> Remembering that loops are not always the best answer in R, I looked at other options like split, following this example but not being able to adapt it from a vector to a data.frame version
> http://stackoverflow.com/questions/3318333/split-a-vector-into-chunks-in-r <http://stackoverflow.com/questions/3318333/split-a-vector-into-chunks-in-r> (Yes, I?ve reviewed the language documentation). I checked out ddply and data.table, but couldn?t find a way to use them with index positions instead of column values.
> 
> Thanks,
> Liz


Hi,

  map.split <- split(x, (as.numeric(rownames(map)) - 1) %/% 250)

That will create a list of data frames comprised of subsets of ?map?, each of which will have 250 records except, of course, for the last one.

Essentially, you are creating a grouping variable based upon the numeric row names modulo the length of the chunks that you want. For example, using the built-in ?iris? dataset, which has 150 rows:

> (as.numeric(rownames(iris)) - 1) %/% 50
  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 [34] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [67] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[100] 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
[133] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2

iris.split <- split(iris, (as.numeric(rownames(iris)) - 1) %/% 50)

> length(iris.split)
[1] 3

> lapply(iris.split, nrow)
$`0`
[1] 50

$`1`
[1] 50

$`2`
[1] 50


> lapply(iris.split, head)
$`0`
  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5          1.4         0.2  setosa
2          4.9         3.0          1.4         0.2  setosa
3          4.7         3.2          1.3         0.2  setosa
4          4.6         3.1          1.5         0.2  setosa
5          5.0         3.6          1.4         0.2  setosa
6          5.4         3.9          1.7         0.4  setosa

$`1`
   Sepal.Length Sepal.Width Petal.Length Petal.Width    Species
51          7.0         3.2          4.7         1.4 versicolor
52          6.4         3.2          4.5         1.5 versicolor
53          6.9         3.1          4.9         1.5 versicolor
54          5.5         2.3          4.0         1.3 versicolor
55          6.5         2.8          4.6         1.5 versicolor
56          5.7         2.8          4.5         1.3 versicolor

$`2`
    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species
101          6.3         3.3          6.0         2.5 virginica
102          5.8         2.7          5.1         1.9 virginica
103          7.1         3.0          5.9         2.1 virginica
104          6.3         2.9          5.6         1.8 virginica
105          6.5         3.0          5.8         2.2 virginica
106          7.6         3.0          6.6         2.1 virginica



Regards,

Marc Schwartz


From dwinsemius at comcast.net  Wed Jun 10 21:21:37 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 10 Jun 2015 12:21:37 -0700
Subject: [R] Finding index of specific values in a data.frame
In-Reply-To: <38c771fc-7052-4b65-af9e-f2fb126cff41@me.com>
References: <38c771fc-7052-4b65-af9e-f2fb126cff41@me.com>
Message-ID: <6F6B3F83-A08D-45F4-814C-1C32DD780694@comcast.net>


On Jun 10, 2015, at 9:41 AM, Kevin Kowitski wrote:

> Hey everyone, 
> 
>   I am new to R and I am trying to find the index of all of the values in a data.frame.   I have a .csv file that outputs pass, fail, error, and indeterminate readings.  I have passed the data from the .csv to a data.frame, have performed the proper matching criteria to generate a data.frame of 0's and 1's, and am outputting the total 1's (therefore matches) found.  I would also like to find the index of these values so that I can output a matrix containing the date and data point which has produced that match. Can anyone help set me in the right direction?
> 
> here is a github link to the code I have already generated for more clarity on the project:
> 
> https://github.com/KevinKowitski/datasciencecoursera/blob/master/ErrorCount.R

I think the coursera homework assignments are supposed to be discussed in a course-provided web-mediated mailing list.

It's unclear from the presentation why the `which` and `%in%` do not provide a solution. 
> 
> Thank you, 
> Kevin
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From marc_schwartz at me.com  Wed Jun 10 21:23:57 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 10 Jun 2015 14:23:57 -0500
Subject: [R] Split data frame into 250-row chunks
In-Reply-To: <ECE0CF46-C229-4E7D-9505-24E8EA2CA1CF@me.com>
References: <9E2E1B7D-6A42-4A88-948F-9A29F0EEA988@earthlink.net>
	<ECE0CF46-C229-4E7D-9505-24E8EA2CA1CF@me.com>
Message-ID: <308E4335-D0EA-4104-A392-EC08BDAAA8A9@me.com>


> On Jun 10, 2015, at 2:21 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
> 
> 
>> On Jun 10, 2015, at 7:39 AM, Liz Hare <doggene at earthlink.net> wrote:
>> 
>> Hi R-Experts,
>> 
>> I have a data.frame like this:
>> 
>>> head(map)
>> chr snp   poscm   posbp    dist
>> 1   1  M1 2.99043 3249189      NA
>> 2   1  M2 3.06457 3273096 0.07414
>> 3   1  M3 3.17018 3307151 0.10561
>> 4   1  M4 3.20892 3319643 0.03874
>> 5   1  M5 3.28120 3342947 0.07228
>> 6   1  M6 3.29624 3347798 0.01504
>> 
>> I need to split this into chunks of 250 rows (there will usually be a last chunk with < 250 rows).
>> 
>> If I only had to extract one 250-line chunk, it would be easy:
>> 
>> map1 <- map[1:250, ]
>> 
>> or using subset().
>> 
>> I tried to make it a loop iterating through num and using beg and nd for starting and ending indices, but I couldn?t figure out how to reference all the variables I needed in this:
>> 
>>> chunks
>>   beg   nd let num
>> 1     1  250   a   1
>> 2   251  500   b   2
>> 3   501  750   c   3
>> 4   751 1000   d   4
>> 5  1001 1250   e   5
>> 6  1251 1500   f   6
>> 7  1501 1750   g   7
>> 8  1751 2000   h   8
>> 9  2001 2250   i   9
>> 10 2251 2500   j  10
>> ?
>> 
>> Remembering that loops are not always the best answer in R, I looked at other options like split, following this example but not being able to adapt it from a vector to a data.frame version
>> http://stackoverflow.com/questions/3318333/split-a-vector-into-chunks-in-r <http://stackoverflow.com/questions/3318333/split-a-vector-into-chunks-in-r> (Yes, I?ve reviewed the language documentation). I checked out ddply and data.table, but couldn?t find a way to use them with index positions instead of column values.
>> 
>> Thanks,
>> Liz
> 
> 
> Hi,
> 
>  map.split <- split(x, (as.numeric(rownames(map)) - 1) %/% 250)



Shoot, typo in the above, it should be ?map?, not ?x?:

   map.split <- split(map, (as.numeric(rownames(map)) - 1) %/% 250)

Marc



> 
> That will create a list of data frames comprised of subsets of ?map?, each of which will have 250 records except, of course, for the last one.
> 
> Essentially, you are creating a grouping variable based upon the numeric row names modulo the length of the chunks that you want. For example, using the built-in ?iris? dataset, which has 150 rows:
> 
>> (as.numeric(rownames(iris)) - 1) %/% 50
>  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> [34] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
> [67] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
> [100] 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
> [133] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
> 
> iris.split <- split(iris, (as.numeric(rownames(iris)) - 1) %/% 50)
> 
>> length(iris.split)
> [1] 3
> 
>> lapply(iris.split, nrow)
> $`0`
> [1] 50
> 
> $`1`
> [1] 50
> 
> $`2`
> [1] 50
> 
> 
>> lapply(iris.split, head)
> $`0`
>  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> 1          5.1         3.5          1.4         0.2  setosa
> 2          4.9         3.0          1.4         0.2  setosa
> 3          4.7         3.2          1.3         0.2  setosa
> 4          4.6         3.1          1.5         0.2  setosa
> 5          5.0         3.6          1.4         0.2  setosa
> 6          5.4         3.9          1.7         0.4  setosa
> 
> $`1`
>   Sepal.Length Sepal.Width Petal.Length Petal.Width    Species
> 51          7.0         3.2          4.7         1.4 versicolor
> 52          6.4         3.2          4.5         1.5 versicolor
> 53          6.9         3.1          4.9         1.5 versicolor
> 54          5.5         2.3          4.0         1.3 versicolor
> 55          6.5         2.8          4.6         1.5 versicolor
> 56          5.7         2.8          4.5         1.3 versicolor
> 
> $`2`
>    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species
> 101          6.3         3.3          6.0         2.5 virginica
> 102          5.8         2.7          5.1         1.9 virginica
> 103          7.1         3.0          5.9         2.1 virginica
> 104          6.3         2.9          5.6         1.8 virginica
> 105          6.5         3.0          5.8         2.2 virginica
> 106          7.6         3.0          6.6         2.1 virginica
> 
> 
> 
> Regards,
> 
> Marc Schwartz
> 


From dwinsemius at comcast.net  Wed Jun 10 21:33:22 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 10 Jun 2015 12:33:22 -0700
Subject: [R] Split data frame into 250-row chunks
In-Reply-To: <215EA26F-EF92-4852-A7D8-22FA75B01394@comcast.net>
References: <9E2E1B7D-6A42-4A88-948F-9A29F0EEA988@earthlink.net>
	<215EA26F-EF92-4852-A7D8-22FA75B01394@comcast.net>
Message-ID: <DE5257CF-936C-411D-9162-DD70FEFC6B6B@comcast.net>


On Jun 10, 2015, at 12:18 PM, David Winsemius wrote:

> 
> On Jun 10, 2015, at 5:39 AM, Liz Hare wrote:
> 
>> Hi R-Experts,
>> 
>> I have a data.frame like this:
>> 
>>> head(map)
>> chr snp   poscm   posbp    dist
>> 1   1  M1 2.99043 3249189      NA
>> 2   1  M2 3.06457 3273096 0.07414
>> 3   1  M3 3.17018 3307151 0.10561
>> 4   1  M4 3.20892 3319643 0.03874
>> 5   1  M5 3.28120 3342947 0.07228
>> 6   1  M6 3.29624 3347798 0.01504
>> 
>> I need to split this into chunks of 250 rows (there will usually be a last chunk with < 250 rows).
> 
> split( map, trunc( 0:(nrow(map)-1 )/nrow(map) ) )
> 
> Untested. Designed to return a list with indices starting at "0".

Looking at Marc Schwartz' answer ( a smarter man than I) I see this should have been:

split( map, trunc( 0:(nrow(map)-1 )/250) )

-- 
David.

> 
>> trunc( 0:19/5)
> [1] 0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3
> 
> 
> 
>> 
>> If I only had to extract one 250-line chunk, it would be easy:
>> 
>> map1 <- map[1:250, ]
>> 
>> or using subset().
>> 
>> I tried to make it a loop iterating through num and using beg and nd for starting and ending indices, but I couldn?t figure out how to reference all the variables I needed in this:
>> 
>>> chunks
>>   beg   nd let num
>> 1     1  250   a   1
>> 2   251  500   b   2
>> 3   501  750   c   3
>> 4   751 1000   d   4
>> 5  1001 1250   e   5
>> 6  1251 1500   f   6
>> 7  1501 1750   g   7
>> 8  1751 2000   h   8
>> 9  2001 2250   i   9
>> 10 2251 2500   j  10
>> ?
>> 
>> Remembering that loops are not always the best answer in R, I looked at other options like split, following this example but not being able to adapt it from a vector to a data.frame version
>> http://stackoverflow.com/questions/3318333/split-a-vector-into-chunks-in-r <http://stackoverflow.com/questions/3318333/split-a-vector-into-chunks-in-r> (Yes, I?ve reviewed the language documentation). I checked out ddply and data.table, but couldn?t find a way to use them with index positions instead of column values.
>> 
>> Thanks,
>> Liz
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From roy.mendelssohn at noaa.gov  Wed Jun 10 21:42:14 2015
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Wed, 10 Jun 2015 12:42:14 -0700
Subject: [R] ggpairs question
Message-ID: <26D8D223-FF48-43AC-ACB9-91E6F199DC19@noaa.gov>

Hi All:

I am not totally grasping GGally, in particular how to customize ggpairs  (or maybe I need to use a different part of GGally for what I want). 

Toy example:

> dput(junk)
> structure(list(state1 = c(-1.78772815343945, 0.347049897473099, 
> -0.18529149576171, 1.79047951942822, 1.13345484683348), state2 = c(-0.100139614037992, 
> 0.399087158966048, 0.865472473022594, 1.02082121315014, 0.973526790943227
> )), .Names = c("state1", "state2"), row.names = c("1958-03-01", 
> "1958-04-01", "1958-05-01", "1958-06-01", "1958-07-01"), class = "data.frame")
> 
> ggpairs(junk,lower=list(continuous="smooth"))

What I would like to do is have the upper box(es) display a plot of the cross-correlations instead of just the printed values of the correlations.

Thanks for any help.

-Roy M.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From dmck at u.washington.edu  Wed Jun 10 21:07:27 2015
From: dmck at u.washington.edu (Don McKenzie)
Date: Wed, 10 Jun 2015 12:07:27 -0700
Subject: [R] graphs, need urgent help (deadline :( )
In-Reply-To: <FD7328FB-306E-47A7-B0AC-A4EAC0B8AEF0@gmail.com>
References: <10c1b087-6721-44b2-a347-851219672d30@gmail.com>
	<d2fd6c5d-e38b-4317-9ffa-6cfa6aa0d20e@gmail.com>
	<fe94928e-a651-4e9f-9643-73635938c694@u.washington.edu>
	<1535CE35A5D.00001088jrkrideau@inbox.com>
	<C77F744D-5A89-4AC7-8DFE-9073A33C3BEF@gmail.com>
	<8C64A81B-AB10-42AF-82DC-752CA2D7ECE0@u.washington.edu>
	<EC24A80A-5013-4ED3-8B5A-A41B1E54AD62@u.washington.edu>
	<FD7328FB-306E-47A7-B0AC-A4EAC0B8AEF0@gmail.com>
Message-ID: <6B65F415-42DE-4385-BCA7-9221B81EEFF8@u.washington.edu>

Here is code that IS tested.  I am sending Rosa the (ugly) output in a separate file.  Crazy problems with argument order; I never figured out
exactly what was wrong.


# therapy plot


 plot(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.a[therapy.df$sample==50],xlab="Region",ylab="factor",type="l",col=4,ylim=c(0,1.5))
lines(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.b[therapy.df$sample==50],col=2)
lines(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.c[therapy.df$sample==50],col=3)

lines(therapy.df$Region[therapy.df$sample==250],therapy.df$factor.a[therapy.df$sample==250],col=4,lty=2)
lines(therapy.df$Region[therapy.df$sample==250],therapy.df$factor.b[therapy.df$sample==250],col=2,lty=2)
lines(therapy.df$Region[therapy.df$sample==250],therapy.df$factor.c[therapy.df$sample==250],col=3,lty=2)

lines(therapy.df$Region[therapy.df$sample==1000],therapy.df$factor.a[therapy.df$sample==1000],col=4,lty=3)
lines(therapy.df$Region[therapy.df$sample==1000],therapy.df$factor.b[therapy.df$sample==1000],col=2,lty=3)
lines(therapy.df$Region[therapy.df$sample==1000],therapy.df$factor.c[therapy.df$sample==1000],col=3,lty=3)

legend(7,1.4,c("factor.a","factor.b","factor.c"),col=c(4,2,3),lty=1)



> On Jun 10, 2015, at 11:03 AM, Rosa Oliveira <rosita21 at gmail.com> wrote:
> 
> Sorry,
> 
> I taught I attached the cvs file :)
> 
> <therapy.csv>
> 
> 
> Don,
> 
> I tried, but I got an error:
> 
> > my.data$Region
>  [1]  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10
> > my.data$sample
>  [1]   50   50   50   50   50   50   50   50   50   50  250  250  250  250  250  250  250  250  250  250 1000 1000 1000 1000 1000 1000 1000 1000
> [29] 1000 1000
> > my.data$factor.a
>  [1] 0.895 0.811 0.685 0.777 0.600 0.466 0.446 0.392 0.256 0.198 0.136 0.121 0.875 0.777 0.685 0.626 0.550 0.466 0.384 0.330 0.060 0.138 0.065
> [24] 0.034 0.931 0.124 0.060 0.028 0.017 0.014
> 
> 
> > plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=?l?,xlab=?Region?,ylab=?factor")
> Error: unexpected input in "plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=??
> 
> 
> I?m really naive, right?
> 
> 
> Best,
> RO
> 
> 
> Atenciosamente,
> Rosa Oliveira
> 
> -- 
> ____________________________________________________________________________
>  
> <smile.jpg>
> 
> Rosa Celeste dos Santos Oliveira, 
> 
> E-mail: rosita21 at gmail.com
> Tlm: +351 939355143 
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
> 
>> On 10 Jun 2015, at 18:10, Don McKenzie <dmck at u.washington.edu> wrote:
>> 
>> For a legend, try (untested)
>> 
>> legend(0.15,0.9,c("factora","factorb","factorc"),col=c(4,2,3),lty=1)
>> 
>> If it overlaps data points move the first two arguments (0.15 and 0.9) around, or change the ?ylim? argument in the plot() to ~1.2.
>> 
>> to avoid clutter, put the line-types information in the figure caption (IMO)
>> 
>> 
>>> On Jun 10, 2015, at 10:03 AM, Don McKenzie <dmck at u.washington.edu> wrote:
>>> 
>>> 
>>>> On Jun 10, 2015, at 9:08 AM, Rosa Oliveira <rosita21 at gmail.com> wrote:
>>>> 
>>>> Dear All,
>>>> 
>>>> 
>>>> I attach my data.
>>>> 
>>>> Dear Jim, 
>>>> 
>>>> when I run your code (even the one you send me, not in my data), I get: 
>>>> 
>>>> Don't know how to automatically pick scale for object of type function. Defaulting to continuous
>>>> Error in data.frame(x = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1,  : 
>>>>   arguments imply differing number of rows: 24, 0
>>>> 
>>>> 
>>>> 
>>>> Dear Don,
>>>> 
>>>> It?s meant that I will have 12 lines: 
>>>> 3 factors - lines colors
>>>> with 3 different values of ?sample? for each - line types
>>>> 
>>>> 
>>>> [Three colors, one for each factor,
>>>> and  three line types (lty=1,2,3), one for eachvalue of ?sample - preferable dash, thin and thick).
>>>> 
>>>> 
>>>> in the X - I should have region (because I have 10 regions)
>>>> for each region I have the outcome of 3 different treatments (factor)
>>>> for each region and each treatment I have 3 different sample size.
>>> 
>>> But in your original post you had 4 sample sizes: 10,20,30,40.
>>>> 
>>>> I need to ?see? the the influence of the region in the treatment outcome for each sample size.
>>>> 
>>>> So, at the end I should have 9 lines
>>>> 3 red (1 dash, 1 thin, 1 thick) - concerning factor a (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>>> 3 blue (1 dash, 1 thin, 1 thick) - concerning factor b (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>>> 3 green (1 dash, 1 thin, 1 thick) - concerning factor c (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>>> 
>>>> 
>>>> 
>>>> Hope this time is clear.
>>>> 
>>>> 
>>>> I also though about doing 3 different graphs, each one for 1 different sample size, and in that case I should have 3 graphs each one with 3 lines
>>>> 1 red to factor a, 1 blue to factor b and 1 green to factor c.
>>>> 
>>>> Do you all think is better?
>>> 
>>> A matter of style perhaps but I would use dotplots because you have only two data points for each ?line?.  The lines will be misleading.  You also could use 
>>> panel plots, but given your skill set (unless someone wants to spend a fair bit of time with you), it?s probably best to stay as simple as possible.
>>> 
>>> But given your original post (cleaned up)   # untested: apologies for any typos
>>> 
>>>>        region              sample          factora          factorb 		factorc
>>>> 	0.1  			10     	 0.895   		0.903   		0.378
>>>> 	0.2  			10      	0.811  		 0.865  		 0.688
>>>> 	0.1  			20      	0.735   		0.966   		0.611
>>>> 	0.2  			20     	 0.777  		 0.732  		 0.653
>>>> 	0.1  			30      	0.600   		0.778   		0.694
>>>> 	0.2  			30     	 0.466  		 174.592 		0.461
>>>> 	0.1  			40     	 0.446   		0.432   		0.693
>>>> 	0.2  			40     	 0.392   		0.294  		 0.686
>>> 
>>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4,type=?l?,ylim=c(0,1),xlab=?region?,ylab=?factor")
>>> lines(my.data$region[my.data$sample==10],my.data$factorb[my.data$sample==10],col=2)
>>> lines(my.data$region[my.data$sample==10],my.data$factorc[my.data$sample==10],col=3)
>>> 
>>> lines(my.data$region[my.data$sample==20],my.data$factora[my.data$sample==20],col=4,lty=2)
>>> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
>>> lines(my.data$region[my.data$sample==20],my.data$factorc[my.data$sample==20],col=3,lty=2)
>>> 
>>> #  Now do two more groups of 3, changing the parameter ?lty? to 3 and then 4
>>> 
>>> # Look at the syntax and note what changes and what stays constant. Do you see how this works?
>>> # there will be what looks like a vertical line where sample = 30 and factorb = 174.592.  Do you see why?
>>> 
>>> # then you will need a legend
>>> 
>>>> Nonetheless I can?t do it :(
>>>> 
>>>> best,
>>>> RO
>>>> 
>>>> 
>>>> 
>>>> Atenciosamente,
>>>> Rosa Oliveira
>>>> 
>>>> -- 
>>>> ____________________________________________________________________________
>>>>  
>>>> <smile.jpg>
>>>> Rosa Celeste dos Santos Oliveira, 
>>>> 
>>>> E-mail: rosita21 at gmail.com
>>>> Tlm: +351 939355143 
>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>>>> ____________________________________________________________________________
>>>> "Many admire, few know"
>>>> Hippocrates
>>>> 
>>>>> On 10 Jun 2015, at 14:13, John Kane <jrkrideau at inbox.com> wrote:
>>>>> 
>>>>> Hi Jim,
>>>>> 
>>>>> I was looking at that last night and had the same problem of visualizing what Rosa needed.  
>>>>> 
>>>>> Hi Rosa
>>>>> This is nothing like what you wanted and I really don't understand your data but would something like this work as a substitute or am I completely lost?
>>>>> 
>>>>> 
>>>>> dat1  <-  structure(list(region = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 
>>>>> 0.2), sample = c(10L, 10L, 20L, 20L, 30L, 30L, 40L, 40L), factora = c(0.895, 
>>>>> 0.811, 0.735, 0.777, 0.6, 0.466, 0.446, 0.392), factorb = c(0.903, 
>>>>> 0.865, 0.966, 0.732, 0.778, 0.592, 0.432, 0.294), factorc = c(0.37, 
>>>>> 0.688, 0.611, 0.653, 0.694, 0.461, 0.693, 0.686)), .Names = c("region", 
>>>>> "sample", "factora", "factorb", "factorc"), class = "data.frame", row.names = c(NA, 
>>>>> -8L))
>>>>> 
>>>>> 
>>>>> mdat1  <-   melt(dat1, id.var = c("region", "sample"),
>>>>>                    variable.name = "factor",
>>>>>                    value.name = "value")
>>>>> str(mdat1)
>>>>> 
>>>>> ggplot(mdat1, aes(region, value, colour = factor)) +
>>>>>                geom_line() + facet_grid(sample ~ .)
>>>>> 
>>>>> John Kane
>>>>> Kingston ON Canada
>>>>> 
>>>>> 
>>>>>> -----Original Message-----
>>>>>> From: drjimlemon at gmail.com
>>>>>> Sent: Wed, 10 Jun 2015 20:51:52 +1000
>>>>>> To: rosita21 at gmail.com
>>>>>> Subject: Re: [R] graphs, need urgent help (deadline :( )
>>>>>> 
>>>>>> Hi Rosa,
>>>>>> Like Don, I can't work out what you want and I don't even have the
>>>>>> picture. For example, your specification of color and line type leaves
>>>>>> only one point for each color and line type, and the line from one
>>>>>> point to the same point is not going to show up. Here is a possibility
>>>>>> that may lead (eventually) to a solution.
>>>>>> 
>>>>>> library(plotrix)
>>>>>> par(tcl=-0.1)
>>>>>> gap.plot(x=rep(seq(10,45,by=5),3),
>>>>>> y=unlist(my.data[,c("factora","factorb","factorc")]),
>>>>>> main="A plot of factorial mystery",
>>>>>> gap=c(1.1,174),ylim=c(0,175),ylab="factor score",xlab="Group",
>>>>>> xticlab=c(" \n0.1\n10"," \n0.2\n10"," \n0.1\n20"," \n0.2\n20",
>>>>>>  " \n0.1\n30"," \n0.2\n30"," \n0.1\n40"," \n0.2\n40"),
>>>>>> ytics=c(0,0.5,1,174.59),pch=rep(1:3,each=8),col=rep(c(4,2,3),each=8))
>>>>>> mtext(c("Region","Sample"),side=1,at=6,line=c(0,1))
>>>>>> lines(seq(10,45,by=5),my.data$factora,col=4)
>>>>>> lines(seq(10,45,by=5),my.data$factorb[c(1:5,NA,7,8)],col=2)
>>>>>> lines(seq(10,45,by=5),my.data$factorc,col=3)
>>>>>> 
>>>>>> Jim
>>>>>> 
>>>>>> 
>>>>>> On Wed, Jun 10, 2015 at 10:53 AM, Rosa Oliveira <rosita21 at gmail.com>
>>>>>> wrote:
>>>>>>> Dear Don and all,
>>>>>>> 
>>>>>>> I?ve read the tutorial and tried several codes before posting :)
>>>>>>> I?m really naive.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> what I was trying to :  is something like the graph in the picture I
>>>>>>> drawee.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> Is it more clear now?
>>>>>>> 
>>>>>>> Atenciosamente,
>>>>>>> Rosa Oliveira
>>>>>>> 
>>>>>>> --
>>>>>>> ____________________________________________________________________________
>>>>>>> 
>>>>>>> 
>>>>>>> Rosa Celeste dos Santos Oliveira,
>>>>>>> 
>>>>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>>>>> Tlm: +351 939355143
>>>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>>>>>>> <https://pt.linkedin.com/in/rosacsoliveira>
>>>>>>> ____________________________________________________________________________
>>>>>>> "Many admire, few know"
>>>>>>> Hippocrates
>>>>>>> 
>>>>>>>> On 09 Jun 2015, at 19:23, Don McKenzie <dmck at u.washington.edu
>>>>>>>> <mailto:dmck at u.washington.edu>> wrote:
>>>>>>>> 
>>>>>>>> The answer lies in learning to use the help (and knowing where to
>>>>>>>> start).  Did you look at the tutorial that comes with the R
>>>>>>>> installation?
>>>>>>>> 
>>>>>>>> ?plot
>>>>>>>> ?lines
>>>>>>>> 
>>>>>>>> ?par
>>>>>>>> 
>>>>>>>> In the last, look for the descriptions of ?col? and ?lty?.
>>>>>>>> 
>>>>>>>> Using plot() and lines(), and subsetting the four unique values of
>>>>>>>> ?sample?, you can create your lines.
>>>>>>>> 
>>>>>>>> Here is a crude start, assuming your columns are part of a data frame
>>>>>>>> called ?my.data?.   Untested...
>>>>>>>> 
>>>>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)
>>>>>>>> # blue line, not dashed
>>>>>>>> .
>>>>>>>> .
>>>>>>>> .
>>>>> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
>>>>>>>> # red dashed line
>>>>>>>> 
>>>>>>>> 
>>>>>>>>> On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com
>>>>>>>>> <mailto:rosita21 at gmail.com>> wrote:
>>>>>>>>> 
>>>>>>>>> Hi,
>>>>>>>>> 
>>>>>>>>> another naive question (i?m pretty sure :( )
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> I?m trying to plot a multiple line graph:
>>>>>>>>> 
>>>>>>>>>        region              sample          factora          factorb
>>>>>>>>> factorc
>>>>>>>>> 0.1  10      0.895   0.903   0.378
>>>>>>>>> 0.2  10      0.811   0.865   0.688
>>>>>>>>> 0.1  20      0.735   0.966   0.611
>>>>>>>>> 0.2  20      0.777   0.732   0.653
>>>>>>>>> 0.1  30      0.600   0.778   0.694
>>>>>>>>> 0.2  30      0.466   174.592 0.461
>>>>>>>>> 0.1  40      0.446   0.432   0.693
>>>>>>>>> 0.2  40      0.392   0.294   0.686
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> The first column should be the independent variable, the second should
>>>>>>>>> compute a bold line for sample(10) and dash line for sample 20.
>>>>>>>> 
>>>>>>>> What about the other two values of ?sample??
>>>>>>>> 
>>>>>>>>> The others variables are outcomes for each of the first scenarios, and
>>>>>>>>> so it should: the 3rd, 4th and 5th columns should be blue, red and
>>>>>>>>> green respectively.
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Resume :)
>>>>>>>>> 
>>>>>>>>> I should have a graph, in the x-axe should have the region and in the
>>>>>>>>> y axe, the factor.
>>>>>>>>> Lines:
>>>>>>>>>     1 - blue and bold for region 0.1, sample 10 and factor a
>>>>>>>>>     2 - blue and dash for region 0.2, sample 10 and factor a
>>>>>>>>>     3 - red and bold for region 0.1, sample 10 and factor b
>>>>>>>>>     4 - red and dash for region 0.2, sample 10 and factor b
>>>>>>>>>     5 - green and bold for region 0.1, sample 10 and factor c
>>>>>>>>>     6 - green and dash for region 0.2, sample 10 and factor c
>>>>>>>> 
>>>>>>>> Not consistent with what you said above. These are no longer lines, but
>>>>>>>> points.
>>>>>>>>> 
>>>>>>>>> nonetheless the independent variable is nominal, I should plot a line
>>>>>>>>> graph.
>>>>>>>>> 
>>>>>>>>> Can anyone help me please?
>>>>>>>>> I have my file as a cvs file, so I first read that file (that I know
>>>>>>>>> how to do :)).
>>>>>>>>> 
>>>>>>>>> But I have it in that format.
>>>>>>>>> 
>>>>>>>>> Best,
>>>>>>>>> RO
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Atenciosamente,
>>>>>>>>> Rosa Oliveira
>>>>>>>>> 
>>>>>>>>> --
>>>>>>>>> ____________________________________________________________________________
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Rosa Celeste dos Santos Oliveira,
>>>>>>>>> 
>>>>>>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>>>>>>> Tlm: +351 939355143
>>>>>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>>>>>>>>> <https://pt.linkedin.com/in/rosacsoliveira>
>>>>>>>>> ____________________________________________________________________________
>>>>>>>>> "Many admire, few know"
>>>>>>>>> Hippocrates
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>>     [[alternative HTML version deleted]]
>>>>>>>>> 
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
>>>>>>>>> UNSUBSCRIBE and more, see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>> <http://www.r-project.org/posting-guide.html>
>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>> 
>>>>>>>> <PastedGraphic-1.tiff>
>>>>>>>> 
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> ____________________________________________________________
>>>>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
>>>>> Check it out at http://www.inbox.com/marineaquarium
>>>>> 
>>>>> 
>>>> 
>>> 
>>> <PastedGraphic-1.tiff>
>>> 
>> 
>> <PastedGraphic-1.tiff>
>> 
> 




From jfox at mcmaster.ca  Wed Jun 10 22:15:21 2015
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 10 Jun 2015 16:15:21 -0400
Subject: [R] powerTransform Convergence error
In-Reply-To: <01884BF7-08ED-48E8-9DBD-9F2C4E97EE2A@gmail.com>
References: <01884BF7-08ED-48E8-9DBD-9F2C4E97EE2A@gmail.com>
Message-ID: <web-562686486@cgpsrv2.cis.mcmaster.ca>

Dear Brittany,

As explained in ?powerTransform, this function uses optim() to optimize a generalized Box-Cox criterion. For explanation of return codes, see ?optim. 

In particular, code 1 indicates that the maximum number of iterations was exceeded. Although you might try increasing the permitted number of iterations or otherwise tweaking the arguments to optim(), your problem is probably ill-conditioned in some manner that is impossible to know without more information, such as your data.

I hope this helps,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
	

On Wed, 10 Jun 2015 10:54:30 -0600
 Brittany Demmitt <demmitba at gmail.com> wrote:
> Hello,
> 
> I am trying to use the powerTransform function in the package car to identify the lambda: transform my data.  However, I receive the following warning:
> 
> Warning message:
> In estimateTransform(x, y, NULL, ...) :
>   Convergence failure: return code = 1
> 
> I can not find a description of what return code =1  means for the car package.  How do I look that up, or does anyone know what the warning means?
> 
> Thank you so much!
> 
> Brittany
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From davidsmi at microsoft.com  Wed Jun 10 22:32:07 2015
From: davidsmi at microsoft.com (David Smith)
Date: Wed, 10 Jun 2015 20:32:07 +0000
Subject: [R] Revolutions blog: May 2015 roundup
Message-ID: <DM2PR0301MB08483692C64B5B6E15A1E1E9C8BD0@DM2PR0301MB0848.namprd03.prod.outlook.com>

Since 2008, Revolution Analytics staff and guests have written about R every weekday at the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month of particular interest to readers of r-help. 

In case you missed them, here are some articles related to R from the month of May:

RStudio 0.99 released with improved autocomplete and data viewer features: http://blog.revolutionanalytics.com/2015/05/rstudio-099-released.html

The new Naive Bayes classifier in the RevoScaleR package: http://blog.revolutionanalytics.com/2015/05/revoscalers-naive-bayes-classifier-rxnaivebayes.html

R is the most popular Predictive Analytics / Data Mining / Data Science software in the latest KDnuggets poll: http://blog.revolutionanalytics.com/2015/05/r-tops-2015-kdnuggets-software-poll-.html

A Shiny application predicts the winner of baseball games mid-game using R: http://blog.revolutionanalytics.com/2015/05/situational-baseball-analyzing-runs-potential-statistics.html

A list of open data sources you can use with R: http://blog.revolutionanalytics.com/2015/05/open-data-sets-you-can-use-with-r.html

Revolution R Open 3.2.0 now available http://blog.revolutionanalytics.com/2015/05/rro-320.html, following RRO 8.0.3 http://blog.revolutionanalytics.com/2015/05/revolution-r-open-803-now-available.html

A review of talks at the Extremely Large Databases conference, featuring Stephen Wolfram and John Chambers: http://blog.revolutionanalytics.com/2015/05/some-first-day-highlights-from-xldb.html

My TechCrunch article on the impact of open source software on business features several R examples: http://blog.revolutionanalytics.com/2015/05/open-soure-software-has-changed-the-way-we-do-business.html

You can improve performance of R even further by using Revolution R Open with Intel Phi coprocessors: http://blog.revolutionanalytics.com/2015/05/behold-the-power-of-parallel.html

New features in Revolution R Enterprise 7.4, now available: http://blog.revolutionanalytics.com/2015/05/announcing_rre7_4.html

The next release of SQL Server will run R in-database: http://blog.revolutionanalytics.com/2015/05/r-in-sql-server.html

Create embeddable, interactive graphics in R with htmlwidgets: http://blog.revolutionanalytics.com/2015/05/a-first-look-at-htmlwidgets.html

Computerworld reviews R packages for data wrangling: http://blog.revolutionanalytics.com/2015/05/computerworlds-list-of-r-packages-for-data-wrangling.html

A tutorial on using data stored in the Azure cloud with R: http://blog.revolutionanalytics.com/2015/05/using-azure-as-an-r-datasource.html

Using histograms as points in scatterplots, and other embedded plots in R: http://blog.revolutionanalytics.com/2015/05/digging-up-embedded-plots.html

A comparison of data frames, data.table, and dplyr with a random walks problem: http://blog.revolutionanalytics.com/2015/05/random-walks-and-datatable.html

A video on using R for human resources optimization: http://blog.revolutionanalytics.com/2015/05/data-science-in-hr.html

How to call R and Python from base SAS: http://blog.revolutionanalytics.com/2015/05/call-r-and-python-from-base-sas.html

General interest stories (not related to R) in the past month included: a song written by an iPhone (http://blog.revolutionanalytics.com/2015/05/because-its-friday-the-autocomplete-song.html), a Facebook algorithm that tells when "like" becomes "love" (http://blog.revolutionanalytics.com/2015/05/facebook-love.html), a map of light pollution (http://blog.revolutionanalytics.com/2015/05/because-its-friday-light-pollution-map.html), and a machine-learning application that tells you how old you look (http://blog.revolutionanalytics.com/2015/05/because-its-friday-how-old-do-you-look.html).

Meeting times for local R user groups (http://blog.revolutionanalytics.com/local-r-groups.html) can be found on the updated R Community Calendar at: http://blog.revolutionanalytics.com/calendar.html

If you're looking for more articles about R, you can find summaries from previous months at http://blog.revolutionanalytics.com/roundups/. You can receive daily blog posts via email using services like blogtrottr.com, or join the Revolution Analytics mailing list at http://revolutionanalytics.com/newsletter to be alerted to new articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions to me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Revolution Analytics (a Microsoft company)? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com
We are hiring engineers for Revolution R and Azure Machine Learning.
http://azuremljobs.github.io/


From dwinsemius at comcast.net  Wed Jun 10 22:41:52 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 10 Jun 2015 13:41:52 -0700
Subject: [R] Finding index of specific values in a data.frame
In-Reply-To: <71587269-58C6-4ED1-AC93-3EF2711A4F72@icloud.com>
References: <38c771fc-7052-4b65-af9e-f2fb126cff41@me.com>
	<6F6B3F83-A08D-45F4-814C-1C32DD780694@comcast.net>
	<71587269-58C6-4ED1-AC93-3EF2711A4F72@icloud.com>
Message-ID: <34C29BBE-B077-4E42-BF52-9BCA3A55DCFB@comcast.net>


On Jun 10, 2015, at 1:00 PM, Kevin Kowitski wrote:

> Oh I see, I'm sorry I just plopped it in GitHub for ease of help, I didn't notice I put it under coursera work. This task is not related to coursera, I will separate it out. 
> 
> -Kevin
> 
> Sent from my iPhone
> 
>> On Jun 10, 2015, at 3:21 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> 
>>> On Jun 10, 2015, at 9:41 AM, Kevin Kowitski wrote:
>>> 
>>> Hey everyone, 
>>> 
>>> I am new to R and I am trying to find the index of all of the values in a data.frame.   I have a .csv file that outputs pass, fail, error, and indeterminate readings.  I have passed the data from the .csv to a data.frame, have performed the proper matching criteria to generate a data.frame of 0's and 1's, and am outputting the total 1's (therefore matches) found.  I would also like to find the index of these values so that I can output a matrix containing the date and data point which has produced that match. Can anyone help set me in the right direction?

If you have a data.frame of all 1's and 0's, then this should give you the row and column indices of the 1's:

which(df==1, arr.ind=TRUE)

Just to test my presumption that the "==" function would coerce to a matrix suitable for the array index parameter to be effective, I tried with an available dataset: iris:

> str( which( iris[-5] > 3, arr.ind=TRUE) )
 int [1:316, 1:2] 1 2 3 4 5 6 7 8 9 10 ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:2] "row" "col"

Further help will require presentation using dput of a minimal reproducible dataset to work on. Github is not a bad way to deliver this but presenting pages of code is not a good way to present a problem.

-- 
David.

>>> 
>>> here is a github link to the code I have already generated for more clarity on the project:
>>> 
>>> https://github.com/KevinKowitski/datasciencecoursera/blob/master/ErrorCount.R
>> 
>> I think the coursera homework assignments are supposed to be discussed in a course-provided web-mediated mailing list.
>> 
>> It's unclear from the presentation why the `which` and `%in%` do not provide a solution. 
>>> 
>>> Thank you, 
>>> Kevin
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From f.harrell at Vanderbilt.Edu  Thu Jun 11 01:34:17 2015
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Wed, 10 Jun 2015 18:34:17 -0500
Subject: [R] Different behavior of model.matrix between R 3.2 and R 3.1.1
Message-ID: <5578C979.4020001@vanderbilt.edu>

For building design matrices for Cox proportional hazards models in the 
cph function in the rms package I have always used this construct:

Terms <- terms(formula, specials=c("strat", "cluster", "strata"), data=data)
specials <- attr(Terms, 'specials')
stra    <- specials$strat
Terms.ns     <- Terms
     if(length(stra)) {
       temp <- untangle.specials(Terms.ns, "strat", 1)
       Terms.ns <- Terms.ns[- temp$terms]    #uses [.terms function
     }
X <- model.matrix(Terms.ns, X)[, -1, drop=FALSE]

The Terms.ns logic removes stratification factor "main effects" so that 
if a stratification factor interacts with a non-stratification factor, 
only the interaction terms are included, not the strat. factor main 
effects. [In a Cox PH model stratification goes into the nonparametric 
survival curve part of the model].

Lately this logic quit working; model.matrix keeps the unneeded main 
effects in the design matrix.  Does anyone know what changed in R that 
could have caused this, and possibly a workaround?

Note that cph is a kind of front-end to the survival package's coxph 
function.  Therry Therneau uses more complex logic to construct the 
design matrix reliably.  I'd like to avoid that logic because it creates 
an overly wide design matrix before removing the unneeded columns.

Thanks for any assistance,
Frank


-- 
------------------------------------------------------------------------
Frank E Harrell Jr 	Professor and Chairman 	School of Medicine

	Department of *Biostatistics* 	*Vanderbilt University*


	[[alternative HTML version deleted]]


From knussear at mac.com  Thu Jun 11 01:49:52 2015
From: knussear at mac.com (Ken Nussear)
Date: Wed, 10 Jun 2015 16:49:52 -0700
Subject: [R] help with ff matrix indexing and value assignment
Message-ID: <5578CD20.8050504@mac.com>

Hi all

I'm trying to make some assignments to an ffdf using values coming in as
3 columns (row, col, values)

As an example with a regular matrix assigning data (d)  to row r and
column c from a data frame assigns the 3 specific values as desired
reg.mat <- matrix(0, nrow=5, ncol=5)
> reg.mat
     [,1] [,2] [,3] [,4] [,5]
[1,]    0    0    0    0    0
[2,]    0    0    0    0    0
[3,]    0    0    0    0    0
[4,]    0    0    0    0    0
[5,]    0    0    0    0    0


coldat <- data.frame(r = c(1,2,4), c = c(2,1,3), d=c(10,11,12))

> coldat
  r c  d
1 1 2 10
2 2 1 11
3 4 3 12

reg.mat[cbind(coldat$r, coldat$c)] <- coldat$d
> reg.mat
     [,1] [,2] [,3] [,4] [,5]
[1,]    0   10    0    0    0
[2,]   11    0    0    0    0
[3,]    0    0    0    0    0
[4,]    0    0   12    0    0
[5,]    0    0    0    0    0


However using an ff matrix with an incoming 3 column ffdf I cant seem to
get it to go...

ff.mat<-ff(as.integer(0), dim=c(5,5))

> tst.mat
ff (open) integer length=25 (25) dim=c(5,5) dimorder=c(1,2)
     [,1] [,2] [,3] [,4] [,5]
[1,]    0    0    0    0    0
[2,]    0    0    0    0    0
[3,]    0    0    0    0    0
[4,]    0    0    0    0    0
[5,]    0    0    0    0    0

coldatff <-
ffdf(r=ff(as.integer(c(1,2,4))),c=ff(as.integer(c(2,1,3))),d=ff(as.integer(c(10,11,12))))

> coldatff
ffdf (all open) dim=c(3,3), dimorder=c(1,2) row.names=NULL
ffdf virtual mapping
  PhysicalName VirtualVmode PhysicalVmode  AsIs VirtualIsMatrix
PhysicalIsMatrix PhysicalElementNo PhysicalFirstCol PhysicalLastCol
r            r      integer       integer FALSE          
FALSE            FALSE                 1                1               1
c            c      integer       integer FALSE          
FALSE            FALSE                 2                1               1
d            d      integer       integer FALSE          
FALSE            FALSE                 3                1               1
  PhysicalIsOpen
r           TRUE
c           TRUE
d           TRUE
ffdf data
   r  c  d
1  1  2 10
2  2  1 11
3  4  3 12

ff.mat[cbind(coldatff$r,coldatff$c)] <-coldatff$d

> ff.mat
ff (open) integer length=25 (25) dim=c(5,5) dimorder=c(1,2)
     [,1] [,2] [,3] [,4] [,5]
[1,]    0    0    0    0    0
[2,]    0    0    0    0    0
[3,]    0    0    0    0    0
[4,]    0    0    0    0    0
[5,]    0    0    0    0    0

Using cbind = still getting only zeros. Tried a few other methods I just
cant seem to wrap my head around how to do this.....

I had a look at ffindexset, but that looks like assigning whole rows at
a time.

I appreciate any help !!

Thanks

Ken


From zadig_1 at excite.com  Thu Jun 11 02:41:44 2015
From: zadig_1 at excite.com (ce)
Date: Wed, 10 Jun 2015 20:41:44 -0400
Subject: [R] Milisecond problem in as.POSIXct ?
Message-ID: <20150610204144.24020@web005.roc2.bluetie.com>

Dear all,

my main problem is with miliseconds. I have an array :

library(xts)
options(digits.secs = 3)
> x
[1] "2015-06-10 10:22:06.389 EDT" "2015-06-10 10:22:07.473 EDT"
[3] "2015-06-10 10:22:08.717 EDT" "2015-06-10 10:22:09.475 EDT"

> x[1]
[1] "2015-06-10 10:22:06.38 EDT"
> x[2]
[1] "2015-06-10 10:22:07.473 EDT"

why it cuts last digit of miliseconds 389 to 38 ? ( it doesn't cut 473 !! )

I try to dump it to post here:

> dump("x",file=stdout())

x <-
structure(c(1433946126.39, 1433946127.474, 1433946128.717, 1433946129.476
), tzone = "", tclass = c("POSIXct", "POSIXt"), class = c("POSIXct",
"POSIXt"))

new array becomes :

> x
[1] "2015-06-10 10:22:06.390 EDT" "2015-06-10 10:22:07.473 EDT"
[3] "2015-06-10 10:22:08.717 EDT" "2015-06-10 10:22:09.476 EDT"

this time first milisecond 389 became 390 ?  and last element 475 became 476 ?

I do some more tests :

as.POSIXct("2015-06-10 10:22:07.473",format='%Y-%m-%d %H:%M:%OS')
[1] "2015-06-10 10:22:07.473 EDT"

is correct, but :

as.POSIXct("2015-06-10 10:22:06.389",format='%Y-%m-%d %H:%M:%OS')
[1] "2015-06-10 10:22:06.388 EDT"

why miliseconds turn to 388 instead of 389 ?

or

 as.POSIXct("2015-06-10 10:22:07.478",format='%Y-%m-%d %H:%M:%OS')
[1] "2015-06-10 10:22:07.477 EDT"

 why it shows 477 instead of 478

> sessionInfo()
R version 3.2.0 (2015-04-16)
Platform: x86_64-suse-linux-gnu (64-bit)
Running under: openSUSE 13.2 (Harlequin) (x86_64)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] xts_0.9-7  zoo_1.7-12

loaded via a namespace (and not attached):
[1] tools_3.2.0     grid_3.2.0      lattice_0.20-31


From josh.m.ulrich at gmail.com  Thu Jun 11 03:05:51 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 10 Jun 2015 20:05:51 -0500
Subject: [R] Milisecond problem in as.POSIXct ?
In-Reply-To: <20150610204144.24020@web005.roc2.bluetie.com>
References: <20150610204144.24020@web005.roc2.bluetie.com>
Message-ID: <CAPPM_gR7bxdyAkxRuiUqYcKLEzXp=RReBQbT_v9WSTONPio-gw@mail.gmail.com>

This is known behavior with how POSIXt objects are printed.  See the
discussion on StackOverflow:
http://stackoverflow.com/questions/7726034/how-r-formats-posixct-with-fractional-seconds

On Wed, Jun 10, 2015 at 7:41 PM, ce <zadig_1 at excite.com> wrote:

> Dear all,
>
> my main problem is with miliseconds. I have an array :
>
> library(xts)
> options(digits.secs = 3)
> > x
> [1] "2015-06-10 10:22:06.389 EDT" "2015-06-10 10:22:07.473 EDT"
> [3] "2015-06-10 10:22:08.717 EDT" "2015-06-10 10:22:09.475 EDT"
>
> > x[1]
> [1] "2015-06-10 10:22:06.38 EDT"
> > x[2]
> [1] "2015-06-10 10:22:07.473 EDT"
>
> why it cuts last digit of miliseconds 389 to 38 ? ( it doesn't cut 473 !! )
>
> I try to dump it to post here:
>
> > dump("x",file=stdout())
>
> x <-
> structure(c(1433946126.39, 1433946127.474, 1433946128.717, 1433946129.476
> ), tzone = "", tclass = c("POSIXct", "POSIXt"), class = c("POSIXct",
> "POSIXt"))
>
> new array becomes :
>
> > x
> [1] "2015-06-10 10:22:06.390 EDT" "2015-06-10 10:22:07.473 EDT"
> [3] "2015-06-10 10:22:08.717 EDT" "2015-06-10 10:22:09.476 EDT"
>
> this time first milisecond 389 became 390 ?  and last element 475 became
> 476 ?
>
> I do some more tests :
>
> as.POSIXct("2015-06-10 10:22:07.473",format='%Y-%m-%d %H:%M:%OS')
> [1] "2015-06-10 10:22:07.473 EDT"
>
> is correct, but :
>
> as.POSIXct("2015-06-10 10:22:06.389",format='%Y-%m-%d %H:%M:%OS')
> [1] "2015-06-10 10:22:06.388 EDT"
>
> why miliseconds turn to 388 instead of 389 ?
>
> or
>
>  as.POSIXct("2015-06-10 10:22:07.478",format='%Y-%m-%d %H:%M:%OS')
> [1] "2015-06-10 10:22:07.477 EDT"
>
>  why it shows 477 instead of 478
>
> > sessionInfo()
> R version 3.2.0 (2015-04-16)
> Platform: x86_64-suse-linux-gnu (64-bit)
> Running under: openSUSE 13.2 (Harlequin) (x86_64)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] xts_0.9-7  zoo_1.7-12
>
> loaded via a namespace (and not attached):
> [1] tools_3.2.0     grid_3.2.0      lattice_0.20-31
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Thu Jun 11 03:13:24 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 10 Jun 2015 17:13:24 -0800
Subject: [R] graphs, need urgent help (deadline :( )
In-Reply-To: <6B65F415-42DE-4385-BCA7-9221B81EEFF8@u.washington.edu>
References: <fe94928e-a651-4e9f-9643-73635938c694@u.washington.edu>
	<1535ce35a5d.00001088jrkrideau@inbox.com>
	<8c64a81b-ab10-42af-82dc-752ca2d7ece0@u.washington.edu>
	<10c1b087-6721-44b2-a347-851219672d30@gmail.com>
	<ec24a80a-5013-4ed3-8b5a-a41b1e54ad62@u.washington.edu>
	<fd7328fb-306e-47a7-b0ac-a4eac0b8aef0@gmail.com>
	<d2fd6c5d-e38b-4317-9ffa-6cfa6aa0d20e@gmail.com>
	<c77f744d-5a89-4ac7-8dfe-9073a33c3bef@gmail.com>
Message-ID: <1B7E496868A.00000681jrkrideau@inbox.com>


Hi Don,
You got caught by the old curly quotation marks vs plain quotations problem.  My guess is  that at one point the code went through HTML or a word processor that automatically changes straight quotes " to curly ?  (if that comes through). 

A couple of long and painful debugging sessions a few years ago make me sensitive to such problems.

John Kane
Kingston ON Canada

-----Original Message-----
From: dmck at u.washington.edu
Sent: Wed, 10 Jun 2015 12:07:27 -0700
To: rosita21 at gmail.com
Subject: Re: [R] graphs, need urgent help (deadline :( )

Here is code that IS tested. ?I am sending Rosa the (ugly) output in a separate file. ?Crazy problems with argument order; I never figured out
exactly what was wrong.

# therapy plot

?plot(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.a[therapy.df$sample==50],xlab="Region",ylab="factor",type="l",col=4,ylim=c(0,1.5))
lines(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.b[therapy.df$sample==50],col=2)
lines(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.c[therapy.df$sample==50],col=3)

lines(therapy.df$Region[therapy.df$sample==250],therapy.df$factor.a[therapy.df$sample==250],col=4,lty=2)
lines(therapy.df$Region[therapy.df$sample==250],therapy.df$factor.b[therapy.df$sample==250],col=2,lty=2)
lines(therapy.df$Region[therapy.df$sample==250],therapy.df$factor.c[therapy.df$sample==250],col=3,lty=2)

lines(therapy.df$Region[therapy.df$sample==1000],therapy.df$factor.a[therapy.df$sample==1000],col=4,lty=3)
lines(therapy.df$Region[therapy.df$sample==1000],therapy.df$factor.b[therapy.df$sample==1000],col=2,lty=3)
lines(therapy.df$Region[therapy.df$sample==1000],therapy.df$factor.c[therapy.df$sample==1000],col=3,lty=3)

legend(7,1.4,c("factor.a","factor.b","factor.c"),col=c(4,2,3),lty=1)

	On Jun 10, 2015, at 11:03 AM, Rosa Oliveira <rosita21 at gmail.com> wrote:

Sorry,

I taught I attached the cvs file :)

<therapy.csv>

Don,

I tried, but I got an error:

> my.data$Region
?[1] ?1 ?2 ?3 ?4 ?5 ?6 ?7 ?8 ?9 10 ?1 ?2 ?3 ?4 ?5 ?6 ?7 ?8 ?9 10 ?1 ?2 ?3 ?4 ?5 ?6 ?7 ?8 ?9 10
> my.data$sample
?[1] ? 50 ? 50 ? 50 ? 50 ? 50 ? 50 ? 50 ? 50 ? 50 ? 50 ?250 ?250 ?250 ?250 ?250 ?250 ?250 ?250 ?250 ?250 1000 1000 1000 1000 1000 1000 1000 1000
[29] 1000 1000
> my.data$factor.a
?[1] 0.895 0.811 0.685 0.777 0.600 0.466 0.446 0.392 0.256 0.198 0.136 0.121 0.875 0.777 0.685 0.626 0.550 0.466 0.384 0.330 0.060 0.138 0.065
[24] 0.034 0.931 0.124 0.060 0.028 0.017 0.014

> plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=?l?,xlab=?Region?,ylab=?factor")
Error: unexpected input in "plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=??

I?m really naive, right?

Best,
RO

Atenciosamente,
Rosa Oliveira

--?
____________________________________________________________________________

<smile.jpg>

Rosa Celeste dos Santos Oliveira,?

E-mail:?rosita21 at gmail.com
Tlm: +351 939355143?
Linkedin:?https://pt.linkedin.com/in/rosacsoliveira
____________________________________________________________________________
"Many admire, few know"
Hippocrates

	On 10 Jun 2015, at 18:10, Don McKenzie <dmck at u.washington.edu> wrote:

For a legend, try (untested)

legend(0.15,0.9,c("factora","factorb","factorc"),col=c(4,2,3),lty=1)

If it overlaps data points move the first two arguments (0.15 and 0.9) around, or change the ?ylim? argument in the plot() to ~1.2.

to avoid clutter, put the line-types information in the figure caption (IMO)

	On Jun 10, 2015, at 10:03 AM, Don McKenzie <dmck at u.washington.edu> wrote:

	On Jun 10, 2015, at 9:08 AM, Rosa Oliveira <rosita21 at gmail.com> wrote:

Dear All,

I attach my data.

Dear Jim,?

when I run your code (even the one you send me, not in my data), I get:?

Don't know how to automatically pick scale for object of type function. Defaulting to continuous
Error in data.frame(x = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, ?:?
? arguments imply differing number of rows: 24, 0

Dear Don,

It?s meant that I will have 12 lines:?
3 factors - lines colors
with 3 different values of ?sample? for each - line types

[Three colors, one for each factor,
and ?three line types (lty=1,2,3), one for eachvalue of ?sample - preferable dash, thin and thick).

in the X - I should have region (because I have 10 regions)
for each region I have the outcome of 3 different treatments (factor)
for each region and each treatment I have 3 different sample size.

But in your original post you had 4 sample sizes: 10,20,30,40.

I need to ?see? the the influence of the region in the treatment outcome for each sample size.

So, at the end I should have 9 lines
3 red (1 dash, 1 thin, 1 thick) - concerning factor a (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
3 blue (1 dash, 1 thin, 1 thick) - concerning factor b (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
3 green (1 dash, 1 thin, 1 thick) - concerning factor c (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)

Hope this time is clear.

I also though about doing 3 different graphs, each one for 1 different sample size, and in that case I should have 3 graphs each one with 3 lines
1 red to factor a, 1 blue to factor b and 1 green to factor c.

Do you all think is better?

A matter of style perhaps but I would use dotplots because you have only two data points for each ?line?. ?The lines will be misleading. ?You also could use?
panel plots, but given your skill set (unless someone wants to spend a fair bit of time with you), it?s probably best to stay as simple as possible.

But given your original post (cleaned up) ? # untested: apologies for any typos

	? ? ? ?region ? ? ? ? ? ? ?sample ? ? ? ? ?factora ? ? ? ? ?factorb? factorc
 0.1 ? 10 ? ?? ?0.895 ?? 0.903 ?? 0.378
 0.2 ? 10 ? ? ? 0.811 ? ?0.865 ? ?0.688
 0.1 ? 20 ? ? ? 0.735 ?? 0.966 ?? 0.611
 0.2 ? 20 ? ?? ?0.777 ? ?0.732 ? ?0.653
 0.1 ? 30 ? ? ? 0.600 ?? 0.778 ?? 0.694
 0.2 ? 30 ? ?? ?0.466 ? ?174.592? 0.461
 0.1 ? 40 ? ?? ?0.446 ?? 0.432 ?? 0.693

 0.2 ? 40 ? ?? ?0.392 ?? 0.294 ? ?0.686

plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4,type=?l?,ylim=c(0,1),xlab=?region?,ylab=?factor")
lines(my.data$region[my.data$sample==10],my.data$factorb[my.data$sample==10],col=2)
lines(my.data$region[my.data$sample==10],my.data$factorc[my.data$sample==10],col=3)

lines(my.data$region[my.data$sample==20],my.data$factora[my.data$sample==20],col=4,lty=2)
lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
lines(my.data$region[my.data$sample==20],my.data$factorc[my.data$sample==20],col=3,lty=2)

# ?Now do two more groups of 3, changing the parameter ?lty? to 3 and then 4

# Look at the syntax and note what changes and what stays constant. Do you see how this works?
# there will be what looks like a vertical line where sample = 30 and factorb = 174.592. ?Do you see why?

# then you will need a legend

	Nonetheless I can?t do it :(

best,
RO

Atenciosamente,
Rosa Oliveira

--?
____________________________________________________________________________

<smile.jpg>
Rosa Celeste dos Santos Oliveira,?

E-mail:?rosita21 at gmail.com
Tlm: +351 939355143?
Linkedin:?https://pt.linkedin.com/in/rosacsoliveira
____________________________________________________________________________
"Many admire, few know"
Hippocrates

	On 10 Jun 2015, at 14:13, John Kane <jrkrideau at inbox.com> wrote:

Hi Jim,

I was looking at that last night and had the same problem of visualizing what Rosa needed. ?

Hi Rosa
This is nothing like what you wanted and I really don't understand your data but would something like this work as a substitute or am I completely lost?

dat1 ?<- ?structure(list(region = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1,?
0.2), sample = c(10L, 10L, 20L, 20L, 30L, 30L, 40L, 40L), factora = c(0.895,?
0.811, 0.735, 0.777, 0.6, 0.466, 0.446, 0.392), factorb = c(0.903,?
0.865, 0.966, 0.732, 0.778, 0.592, 0.432, 0.294), factorc = c(0.37,?
0.688, 0.611, 0.653, 0.694, 0.461, 0.693, 0.686)), .Names = c("region",?
"sample", "factora", "factorb", "factorc"), class = "data.frame", row.names = c(NA,?
-8L))

mdat1 ?<- ? melt(dat1, id.var = c("region", "sample"),
? ? ? ? ? ? ? ? ? ?variable.name = "factor",
? ? ? ? ? ? ? ? ? ?value.name = "value")
str(mdat1)

ggplot(mdat1, aes(region, value, colour = factor)) +
? ? ? ? ? ? ? ?geom_line() + facet_grid(sample ~ .)

John Kane
Kingston ON Canada

	-----Original Message-----
From:?drjimlemon at gmail.com
Sent: Wed, 10 Jun 2015 20:51:52 +1000
To:?rosita21 at gmail.com
Subject: Re: [R] graphs, need urgent help (deadline :( )

Hi Rosa,
Like Don, I can't work out what you want and I don't even have the
picture. For example, your specification of color and line type leaves
only one point for each color and line type, and the line from one
point to the same point is not going to show up. Here is a possibility
that may lead (eventually) to a solution.

library(plotrix)
par(tcl=-0.1)
gap.plot(x=rep(seq(10,45,by=5),3),
y=unlist(my.data[,c("factora","factorb","factorc")]),
main="A plot of factorial mystery",
gap=c(1.1,174),ylim=c(0,175),ylab="factor score",xlab="Group",
xticlab=c(" \n0.1\n10"," \n0.2\n10"," \n0.1\n20"," \n0.2\n20",
?" \n0.1\n30"," \n0.2\n30"," \n0.1\n40"," \n0.2\n40"),
ytics=c(0,0.5,1,174.59),pch=rep(1:3,each=8),col=rep(c(4,2,3),each=8))
mtext(c("Region","Sample"),side=1,at=6,line=c(0,1))
lines(seq(10,45,by=5),my.data$factora,col=4)
lines(seq(10,45,by=5),my.data$factorb[c(1:5,NA,7,8)],col=2)
lines(seq(10,45,by=5),my.data$factorc,col=3)

Jim

On Wed, Jun 10, 2015 at 10:53 AM, Rosa Oliveira <rosita21 at gmail.com>
wrote:

	Dear Don and all,

I?ve read the tutorial and tried several codes before posting :)
I?m really naive.

what I was trying to : ?is something like the graph in the picture I
drawee.

Is it more clear now?

Atenciosamente,
Rosa Oliveira

--
____________________________________________________________________________

Rosa Celeste dos Santos Oliveira,

E-mail:?rosita21 at gmail.com?<mailto:rosita21 at gmail.com>
Tlm: +351 939355143
Linkedin:?https://pt.linkedin.com/in/rosacsoliveira
<https://pt.linkedin.com/in/rosacsoliveira>
____________________________________________________________________________
"Many admire, few know"
Hippocrates

	On 09 Jun 2015, at 19:23, Don McKenzie <dmck at u.washington.edu
<mailto:dmck at u.washington.edu>> wrote:

The answer lies in learning to use the help (and knowing where to
start). ?Did you look at the tutorial that comes with the R
installation?

?plot
?lines

?par

In the last, look for the descriptions of ?col? and ?lty?.

Using plot() and lines(), and subsetting the four unique values of
?sample?, you can create your lines.

Here is a crude start, assuming your columns are part of a data frame
called ?my.data?. ? Untested...

plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)

	# blue line, not dashed
.
.
.

lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)

	# red dashed line

	On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com
<mailto:rosita21 at gmail.com>> wrote:

Hi,

another naive question (i?m pretty sure :( )

I?m trying to plot a multiple line graph:

? ? ? ?region ? ? ? ? ? ? ?sample ? ? ? ? ?factora ? ? ? ? ?factorb
factorc
0.1 ?10 ? ? ?0.895 ? 0.903 ? 0.378
0.2 ?10 ? ? ?0.811 ? 0.865 ? 0.688
0.1 ?20 ? ? ?0.735 ? 0.966 ? 0.611
0.2 ?20 ? ? ?0.777 ? 0.732 ? 0.653
0.1 ?30 ? ? ?0.600 ? 0.778 ? 0.694
0.2 ?30 ? ? ?0.466 ? 174.592 0.461
0.1 ?40 ? ? ?0.446 ? 0.432 ? 0.693
0.2 ?40 ? ? ?0.392 ? 0.294 ? 0.686

The first column should be the independent variable, the second should
compute a bold line for sample(10) and dash line for sample 20.

What about the other two values of ?sample??

	The others variables are outcomes for each of the first scenarios, and
so it should: the 3rd, 4th and 5th columns should be blue, red and
green respectively.

Resume :)

I should have a graph, in the x-axe should have the region and in the
y axe, the factor.
Lines:
? ? 1 - blue and bold for region 0.1, sample 10 and factor a
? ? 2 - blue and dash for region 0.2, sample 10 and factor a
? ? 3 - red and bold for region 0.1, sample 10 and factor b
? ? 4 - red and dash for region 0.2, sample 10 and factor b
? ? 5 - green and bold for region 0.1, sample 10 and factor c
? ? 6 - green and dash for region 0.2, sample 10 and factor c

Not consistent with what you said above. These are no longer lines, but
points.

nonetheless the independent variable is nominal, I should plot a line
graph.

Can anyone help me please?
I have my file as a cvs file, so I first read that file (that I know
how to do :)).

But I have it in that format.

Best,
RO

Atenciosamente,
Rosa Oliveira

--
____________________________________________________________________________

Rosa Celeste dos Santos Oliveira,

E-mail:?rosita21 at gmail.com?<mailto:rosita21 at gmail.com>
Tlm: +351 939355143
Linkedin:?https://pt.linkedin.com/in/rosacsoliveira
<https://pt.linkedin.com/in/rosacsoliveira>
____________________________________________________________________________
"Many admire, few know"
Hippocrates

? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org?<mailto:R-help at r-project.org> mailing list -- To
UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
<https://stat.ethz.ch/mailman/listinfo/r-help>
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.

<PastedGraphic-1.tiff>

______________________________________________
R-help at r-project.org?mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org?mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
Check it out at?http://www.inbox.com/marineaquarium

<PastedGraphic-1.tiff>

<PastedGraphic-1.tiff>

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From jrkrideau at inbox.com  Thu Jun 11 03:17:30 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 10 Jun 2015 17:17:30 -0800
Subject: [R] graphs, need urgent help (deadline :( )
In-Reply-To: <9CEDC8C3-EF9B-4721-9900-F7A718129BC9@u.washington.edu>
References: <fe94928e-a651-4e9f-9643-73635938c694@u.washington.edu>
	<1535ce35a5d.00001088jrkrideau@inbox.com>
	<8c64a81b-ab10-42af-82dc-752ca2d7ece0@u.washington.edu>
	<10c1b087-6721-44b2-a347-851219672d30@gmail.com>
	<ec24a80a-5013-4ed3-8b5a-a41b1e54ad62@u.washington.edu>
	<fd7328fb-306e-47a7-b0ac-a4eac0b8aef0@gmail.com>
	<d2fd6c5d-e38b-4317-9ffa-6cfa6aa0d20e@gmail.com>
	<c77f744d-5a89-4ac7-8dfe-9073a33c3bef@gmail.com>
Message-ID: <1B877ADDFBA.00000691jrkrideau@inbox.com>

You have curly quotes rather than plain ones here : col=4,type=?l?,xlab=?Region?,ylab=?factor")



John Kane
Kingston ON Canada

-----Original Message-----
From: dmck at u.washington.edu
Sent: Wed, 10 Jun 2015 11:32:59 -0700
To: rosita21 at gmail.com
Subject: Re: [R] graphs, need urgent help (deadline :( )

You were caught by a mysterious issue that I don?t understand either.

plot(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.a[therapy.df$sample==50],col=4,type=?l?,xlab=?Region?,ylab=?factor")

Error: unexpected input in "plot(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.a[therapy.df$sample==50],col=4,type=??

but if I change the order of arguments to plot(), it?s fine

plot(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.a[therapy.df$sample==50],type="l",col=4,xlab="Region",ylab="factor?)

I don?t know what to tell you. ?If someone wiser than I is still reading, maybe s(he) can explain. ?Possibly a bug has crept into the call to ?par?, but ?bugs" suspected by non-experts like me usually turn out to be naive user errors. ?

For your purposes, use the one that works. ?:-)

On Jun 10, 2015, at 11:03 AM, Rosa Oliveira <rosita21 at gmail.com> wrote:

Sorry,

I taught I attached the cvs file :)

<therapy.csv>

Don,

I tried, but I got an error:

> my.data$Region

?[1] ?1 ?2 ?3 ?4 ?5 ?6 ?7 ?8 ?9 10 ?1 ?2 ?3 ?4 ?5 ?6 ?7 ?8 ?9 10 ?1 ?2 ?3 ?4 ?5 ?6 ?7 ?8 ?9 10

> my.data$sample

?[1] ? 50 ? 50 ? 50 ? 50 ? 50 ? 50 ? 50 ? 50 ? 50 ? 50 ?250 ?250 ?250 ?250 ?250 ?250 ?250 ?250 ?250 ?250 1000 1000 1000 1000 1000 1000 1000 1000

[29] 1000 1000

> my.data$factor.a

?[1] 0.895 0.811 0.685 0.777 0.600 0.466 0.446 0.392 0.256 0.198 0.136 0.121 0.875 0.777 0.685 0.626 0.550 0.466 0.384 0.330 0.060 0.138 0.065

[24] 0.034 0.931 0.124 0.060 0.028 0.017 0.014

> plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=?l?,xlab=?Region?,ylab=?factor")

Error: unexpected input in "plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=??

I?m really naive, right?

Best,

RO

 Atenciosamente,
Rosa Oliveira

--?
____________________________________________________________________________

<smile.jpg>

Rosa Celeste dos Santos Oliveira,?

E-mail:?rosita21 at gmail.com
Tlm: +351 939355143?
Linkedin: https://pt.linkedin.com/in/rosacsoliveira [https://pt.linkedin.com/in/rosacsoliveira]
____________________________________________________________________________

"Many admire, few know"
Hippocrates

On 10 Jun 2015, at 18:10, Don McKenzie <dmck at u.washington.edu> wrote:

For a legend, try (untested)

legend(0.15,0.9,c("factora","factorb","factorc"),col=c(4,2,3),lty=1)

If it overlaps data points move the first two arguments (0.15 and 0.9) around, or change the ?ylim? argument in the plot() to ~1.2.

to avoid clutter, put the line-types information in the figure caption (IMO)

On Jun 10, 2015, at 10:03 AM, Don McKenzie <dmck at u.washington.edu> wrote:

On Jun 10, 2015, at 9:08 AM, Rosa Oliveira <rosita21 at gmail.com> wrote:

Dear All,

I attach my data.

Dear Jim,?

when I run your code (even the one you send me, not in my data), I get:?

Don't know how to automatically pick scale for object of type function. Defaulting to continuous

Error in data.frame(x = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, ?:?

? arguments imply differing number of rows: 24, 0

Dear Don,

It?s meant that I will have 12 lines:?

3 factors - lines colors

with 3 different values of ?sample? for each - line types

[Three colors, one for each factor,
and ?three line types (lty=1,2,3), one for eachvalue of ?sample - preferable dash, thin and thick).

in the X - I should have region (because I have 10 regions)

for each region I have the outcome of 3 different treatments (factor)

for each region and each treatment I have 3 different sample size.

But in your original post you had 4 sample sizes: 10,20,30,40.

I need to ?see? the the influence of the region in the treatment outcome for each sample size.

So, at the end I should have 9 lines

3 red (1 dash, 1 thin, 1 thick) - concerning factor a (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)

3 blue (1 dash, 1 thin, 1 thick) - concerning factor b (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)

3 green (1 dash, 1 thin, 1 thick) - concerning factor c (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)

Hope this time is clear.

I also though about doing 3 different graphs, each one for 1 different sample size, and in that case I should have 3 graphs each one with 3 lines

1 red to factor a, 1 blue to factor b and 1 green to factor c.

Do you all think is better?

A matter of style perhaps but I would use dotplots because you have only two data points for each ?line?. ?The lines will be misleading. ?You also could use?

panel plots, but given your skill set (unless someone wants to spend a fair bit of time with you), it?s probably best to stay as simple as possible.

But given your original post (cleaned up) ? # untested: apologies for any typos

? ? ? ?region ?????????????sample ?????????factora ?????????factorb? factorc
 0.1 ? 10 ???? ?0.895 ?? 0.903 ?? 0.378
 0.2 ? 10 ????? 0.811 ? ?0.865 ? ?0.688
 0.1 ? 20 ????? 0.735 ?? 0.966 ?? 0.611
 0.2 ? 20 ???? ?0.777 ? ?0.732 ? ?0.653
 0.1 ? 30 ????? 0.600 ?? 0.778 ?? 0.694
 0.2 ? 30 ???? ?0.466 ? ?174.592  0.461
 0.1 ? 40 ???? ?0.446 ?? 0.432 ?? 0.693

 0.2 ? 40 ???? ?0.392 ?? 0.294 ? ?0.686

plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4,type=?l?,ylim=c(0,1),xlab=?region?,ylab=?factor")

lines(my.data$region[my.data$sample==10],my.data$factorb[my.data$sample==10],col=2)

lines(my.data$region[my.data$sample==10],my.data$factorc[my.data$sample==10],col=3)

lines(my.data$region[my.data$sample==20],my.data$factora[my.data$sample==20],col=4,lty=2)

lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)

lines(my.data$region[my.data$sample==20],my.data$factorc[my.data$sample==20],col=3,lty=2)

# ?Now do two more groups of 3, changing the parameter ?lty? to 3 and then 4

# Look at the syntax and note what changes and what stays constant. Do you see how this works?

# there will be what looks like a vertical line where sample = 30 and factorb = 174.592. ?Do you see why?

# then you will need a legend

Nonetheless I can?t do it :(

best,

RO

 Atenciosamente,
Rosa Oliveira

--?
____________________________________________________________________________

<smile.jpg>
Rosa Celeste dos Santos Oliveira,?

E-mail:?rosita21 at gmail.com
Tlm: +351 939355143?
Linkedin: https://pt.linkedin.com/in/rosacsoliveira [https://pt.linkedin.com/in/rosacsoliveira]
____________________________________________________________________________

"Many admire, few know"
Hippocrates

On 10 Jun 2015, at 14:13, John Kane <jrkrideau at inbox.com> wrote:

Hi Jim,

I was looking at that last night and had the same problem of visualizing what Rosa needed. ?

Hi Rosa
This is nothing like what you wanted and I really don't understand your data but would something like this work as a substitute or am I completely lost?

dat1 ?<- ?structure(list(region = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 
0.2), sample = c(10L, 10L, 20L, 20L, 30L, 30L, 40L, 40L), factora = c(0.895, 
0.811, 0.735, 0.777, 0.6, 0.466, 0.446, 0.392), factorb = c(0.903, 
0.865, 0.966, 0.732, 0.778, 0.592, 0.432, 0.294), factorc = c(0.37, 
0.688, 0.611, 0.653, 0.694, 0.461, 0.693, 0.686)), .Names = c("region", 
"sample", "factora", "factorb", "factorc"), class = "data.frame", row.names = c(NA, 
-8L))

mdat1 ?<- ??melt(dat1, id.var = c("region", "sample"),
 ???????????????????variable.name = "factor",
 ???????????????????value.name = "value")
str(mdat1)

ggplot(mdat1, aes(region, value, colour = factor)) +
 ???????????????geom_line() + facet_grid(sample ~ .)

John Kane
Kingston ON Canada

	-----Original Message-----
From: drjimlemon at gmail.com
Sent: Wed, 10 Jun 2015 20:51:52 +1000
To: rosita21 at gmail.com
Subject: Re: [R] graphs, need urgent help (deadline :( )

Hi Rosa,
Like Don, I can't work out what you want and I don't even have the
picture. For example, your specification of color and line type leaves
only one point for each color and line type, and the line from one
point to the same point is not going to show up. Here is a possibility
that may lead (eventually) to a solution.

library(plotrix)
par(tcl=-0.1)
gap.plot(x=rep(seq(10,45,by=5),3),
 y=unlist(my.data[,c("factora","factorb","factorc")]),
 main="A plot of factorial mystery",
 gap=c(1.1,174),ylim=c(0,175),ylab="factor score",xlab="Group",
 xticlab=c(" \n0.1\n10"," \n0.2\n10"," \n0.1\n20"," \n0.2\n20",
 ?" \n0.1\n30"," \n0.2\n30"," \n0.1\n40"," \n0.2\n40"),
 ytics=c(0,0.5,1,174.59),pch=rep(1:3,each=8),col=rep(c(4,2,3),each=8))
mtext(c("Region","Sample"),side=1,at=6,line=c(0,1))
lines(seq(10,45,by=5),my.data$factora,col=4)
lines(seq(10,45,by=5),my.data$factorb[c(1:5,NA,7,8)],col=2)
lines(seq(10,45,by=5),my.data$factorc,col=3)

Jim

On Wed, Jun 10, 2015 at 10:53 AM, Rosa Oliveira <rosita21 at gmail.com>
wrote:

	Dear Don and all,

I?ve read the tutorial and tried several codes before posting :)
I?m really naive.

what I was trying to : ?is something like the graph in the picture I
drawee.

Is it more clear now?

Atenciosamente,
Rosa Oliveira

--
____________________________________________________________________________

Rosa Celeste dos Santos Oliveira,

E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
Tlm: +351 939355143
Linkedin: https://pt.linkedin.com/in/rosacsoliveira [https://pt.linkedin.com/in/rosacsoliveira]
<https://pt.linkedin.com/in/rosacsoliveira [https://pt.linkedin.com/in/rosacsoliveira]>
____________________________________________________________________________
"Many admire, few know"
Hippocrates

	On 09 Jun 2015, at 19:23, Don McKenzie <dmck at u.washington.edu
<mailto:dmck at u.washington.edu>> wrote:

The answer lies in learning to use the help (and knowing where to
start). ?Did you look at the tutorial that comes with the R
installation?

?plot
?lines

?par

In the last, look for the descriptions of ?col? and ?lty?.

Using plot() and lines(), and subsetting the four unique values of
?sample?, you can create your lines.

Here is a crude start, assuming your columns are part of a data frame
called ?my.data?. ??Untested...

plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)

	# blue line, not dashed
.
.
.

lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)

	# red dashed line

	On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com
<mailto:rosita21 at gmail.com>> wrote:

Hi,

another naive question (i?m pretty sure :( )

I?m trying to plot a multiple line graph:

 ???????region ?????????????sample ?????????factora ?????????factorb
factorc
0.1 ?10 ?????0.895 ??0.903 ??0.378
0.2 ?10 ?????0.811 ??0.865 ??0.688
0.1 ?20 ?????0.735 ??0.966 ??0.611
0.2 ?20 ?????0.777 ??0.732 ??0.653
0.1 ?30 ?????0.600 ??0.778 ??0.694
0.2 ?30 ?????0.466 ??174.592 0.461
0.1 ?40 ?????0.446 ??0.432 ??0.693
0.2 ?40 ?????0.392 ??0.294 ??0.686

The first column should be the independent variable, the second should
compute a bold line for sample(10) and dash line for sample 20.

What about the other two values of ?sample??

	The others variables are outcomes for each of the first scenarios, and
so it should: the 3rd, 4th and 5th columns should be blue, red and
green respectively.

Resume :)

I should have a graph, in the x-axe should have the region and in the
y axe, the factor.
Lines:
 ????1 - blue and bold for region 0.1, sample 10 and factor a
 ????2 - blue and dash for region 0.2, sample 10 and factor a
 ????3 - red and bold for region 0.1, sample 10 and factor b
 ????4 - red and dash for region 0.2, sample 10 and factor b
 ????5 - green and bold for region 0.1, sample 10 and factor c
 ????6 - green and dash for region 0.2, sample 10 and factor c

Not consistent with what you said above. These are no longer lines, but
points.

nonetheless the independent variable is nominal, I should plot a line
graph.

Can anyone help me please?
I have my file as a cvs file, so I first read that file (that I know
how to do :)).

But I have it in that format.

Best,
RO

Atenciosamente,
Rosa Oliveira

--
____________________________________________________________________________

Rosa Celeste dos Santos Oliveira,

E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
Tlm: +351 939355143
Linkedin: https://pt.linkedin.com/in/rosacsoliveira [https://pt.linkedin.com/in/rosacsoliveira]
<https://pt.linkedin.com/in/rosacsoliveira [https://pt.linkedin.com/in/rosacsoliveira]>
____________________________________________________________________________
"Many admire, few know"
Hippocrates

 ????[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
<https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]>
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html [http://www.r-project.org/posting-guide.html]
<http://www.r-project.org/posting-guide.html [http://www.r-project.org/posting-guide.html]>
and provide commented, minimal, self-contained, reproducible code.

<PastedGraphic-1.tiff>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html [http://www.r-project.org/posting-guide.html]
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html [http://www.r-project.org/posting-guide.html]
and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!

[http://www.inbox.com/marineaquarium]

 <PastedGraphic-1.tiff> 

 <PastedGraphic-1.tiff>

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From k.kowitski at icloud.com  Wed Jun 10 21:58:11 2015
From: k.kowitski at icloud.com (Kevin Kowitski)
Date: Wed, 10 Jun 2015 15:58:11 -0400
Subject: [R] Finding index of specific values in a data.frame
In-Reply-To: <6F6B3F83-A08D-45F4-814C-1C32DD780694@comcast.net>
References: <38c771fc-7052-4b65-af9e-f2fb126cff41@me.com>
	<6F6B3F83-A08D-45F4-814C-1C32DD780694@comcast.net>
Message-ID: <12E4A25E-D867-47C6-B208-6C4327121D57@icloud.com>

I did not realize that there is a coursers assignment similar to this. I am running this for data analysis at work, not for coursers. However I will look through the link you provided and see if it is applicable. 

Thanks,
Kevin

Sent from my iPhone

> On Jun 10, 2015, at 3:21 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Jun 10, 2015, at 9:41 AM, Kevin Kowitski wrote:
>> 
>> Hey everyone, 
>> 
>>  I am new to R and I am trying to find the index of all of the values in a data.frame.   I have a .csv file that outputs pass, fail, error, and indeterminate readings.  I have passed the data from the .csv to a data.frame, have performed the proper matching criteria to generate a data.frame of 0's and 1's, and am outputting the total 1's (therefore matches) found.  I would also like to find the index of these values so that I can output a matrix containing the date and data point which has produced that match. Can anyone help set me in the right direction?
>> 
>> here is a github link to the code I have already generated for more clarity on the project:
>> 
>> https://github.com/KevinKowitski/datasciencecoursera/blob/master/ErrorCount.R
> 
> I think the coursera homework assignments are supposed to be discussed in a course-provided web-mediated mailing list.
> 
> It's unclear from the presentation why the `which` and `%in%` do not provide a solution. 
>> 
>> Thank you, 
>> Kevin
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From k.kowitski at icloud.com  Wed Jun 10 22:00:10 2015
From: k.kowitski at icloud.com (Kevin Kowitski)
Date: Wed, 10 Jun 2015 16:00:10 -0400
Subject: [R] Finding index of specific values in a data.frame
In-Reply-To: <6F6B3F83-A08D-45F4-814C-1C32DD780694@comcast.net>
References: <38c771fc-7052-4b65-af9e-f2fb126cff41@me.com>
	<6F6B3F83-A08D-45F4-814C-1C32DD780694@comcast.net>
Message-ID: <71587269-58C6-4ED1-AC93-3EF2711A4F72@icloud.com>

Oh I see, I'm sorry I just plopped it in GitHub for ease of help, I didn't notice I put it under coursera work. This task is not related to coursera, I will separate it out. 

-Kevin

Sent from my iPhone

> On Jun 10, 2015, at 3:21 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Jun 10, 2015, at 9:41 AM, Kevin Kowitski wrote:
>> 
>> Hey everyone, 
>> 
>>  I am new to R and I am trying to find the index of all of the values in a data.frame.   I have a .csv file that outputs pass, fail, error, and indeterminate readings.  I have passed the data from the .csv to a data.frame, have performed the proper matching criteria to generate a data.frame of 0's and 1's, and am outputting the total 1's (therefore matches) found.  I would also like to find the index of these values so that I can output a matrix containing the date and data point which has produced that match. Can anyone help set me in the right direction?
>> 
>> here is a github link to the code I have already generated for more clarity on the project:
>> 
>> https://github.com/KevinKowitski/datasciencecoursera/blob/master/ErrorCount.R
> 
> I think the coursera homework assignments are supposed to be discussed in a course-provided web-mediated mailing list.
> 
> It's unclear from the presentation why the `which` and `%in%` do not provide a solution. 
>> 
>> Thank you, 
>> Kevin
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rosita21 at gmail.com  Wed Jun 10 23:18:49 2015
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Wed, 10 Jun 2015 22:18:49 +0100
Subject: [R] graphs, need urgent help (deadline :( )
In-Reply-To: <6B65F415-42DE-4385-BCA7-9221B81EEFF8@u.washington.edu>
References: <10c1b087-6721-44b2-a347-851219672d30@gmail.com>
	<d2fd6c5d-e38b-4317-9ffa-6cfa6aa0d20e@gmail.com>
	<fe94928e-a651-4e9f-9643-73635938c694@u.washington.edu>
	<1535CE35A5D.00001088jrkrideau@inbox.com>
	<C77F744D-5A89-4AC7-8DFE-9073A33C3BEF@gmail.com>
	<8C64A81B-AB10-42AF-82DC-752CA2D7ECE0@u.washington.edu>
	<EC24A80A-5013-4ED3-8B5A-A41B1E54AD62@u.washington.edu>
	<FD7328FB-306E-47A7-B0AC-A4EAC0B8AEF0@gmail.com>
	<6B65F415-42DE-4385-BCA7-9221B81EEFF8@u.washington.edu>
Message-ID: <6B15D88D-C8B0-4EF8-92D7-15C66C7C278E@gmail.com>

Dear Don, thank you very much.

I really wasn?t being able to figure the problem.

You were a big (huge) help.

Seeing the graphs, I think I?ll try to put the 3 settings (sample size)  in different graphs.

I?ll try to use trellis graphs :) using sample size as the ?factor?

Thank you very much ;)

 


Atenciosamente,
Rosa Oliveira

-- 
____________________________________________________________________________


Rosa Celeste dos Santos Oliveira, 

E-mail: rosita21 at gmail.com
Tlm: +351 939355143 
Linkedin: https://pt.linkedin.com/in/rosacsoliveira
____________________________________________________________________________
"Many admire, few know"
Hippocrates

> On 10 Jun 2015, at 20:07, Don McKenzie <dmck at u.washington.edu> wrote:
> 
> Here is code that IS tested.  I am sending Rosa the (ugly) output in a separate file.  Crazy problems with argument order; I never figured out
> exactly what was wrong.
> 
> 
> # therapy plot
> 
> 
>  plot(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.a[therapy.df$sample==50],xlab="Region",ylab="factor",type="l",col=4,ylim=c(0,1.5))
> lines(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.b[therapy.df$sample==50],col=2)
> lines(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.c[therapy.df$sample==50],col=3)
> 
> lines(therapy.df$Region[therapy.df$sample==250],therapy.df$factor.a[therapy.df$sample==250],col=4,lty=2)
> lines(therapy.df$Region[therapy.df$sample==250],therapy.df$factor.b[therapy.df$sample==250],col=2,lty=2)
> lines(therapy.df$Region[therapy.df$sample==250],therapy.df$factor.c[therapy.df$sample==250],col=3,lty=2)
> 
> lines(therapy.df$Region[therapy.df$sample==1000],therapy.df$factor.a[therapy.df$sample==1000],col=4,lty=3)
> lines(therapy.df$Region[therapy.df$sample==1000],therapy.df$factor.b[therapy.df$sample==1000],col=2,lty=3)
> lines(therapy.df$Region[therapy.df$sample==1000],therapy.df$factor.c[therapy.df$sample==1000],col=3,lty=3)
> 
> legend(7,1.4,c("factor.a","factor.b","factor.c"),col=c(4,2,3),lty=1)
> 
> 
> 
>> On Jun 10, 2015, at 11:03 AM, Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>> wrote:
>> 
>> Sorry,
>> 
>> I taught I attached the cvs file :)
>> 
>> <therapy.csv>
>> 
>> 
>> Don,
>> 
>> I tried, but I got an error:
>> 
>> > my.data$Region
>>  [1]  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10
>> > my.data$sample
>>  [1]   50   50   50   50   50   50   50   50   50   50  250  250  250  250  250  250  250  250  250  250 1000 1000 1000 1000 1000 1000 1000 1000
>> [29] 1000 1000
>> > my.data$factor.a
>>  [1] 0.895 0.811 0.685 0.777 0.600 0.466 0.446 0.392 0.256 0.198 0.136 0.121 0.875 0.777 0.685 0.626 0.550 0.466 0.384 0.330 0.060 0.138 0.065
>> [24] 0.034 0.931 0.124 0.060 0.028 0.017 0.014
>> 
>> 
>> > plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=?l?,xlab=?Region?,ylab=?factor")
>> Error: unexpected input in "plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=??
>> 
>> 
>> I?m really naive, right?
>> 
>> 
>> Best,
>> RO
>> 
>> 
>> Atenciosamente,
>> Rosa Oliveira
>> 
>> -- 
>> ____________________________________________________________________________
>>  
>> <smile.jpg>
>> 
>> Rosa Celeste dos Santos Oliveira, 
>> 
>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>> Tlm: +351 939355143 
>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>> ____________________________________________________________________________
>> "Many admire, few know"
>> Hippocrates
>> 
>>> On 10 Jun 2015, at 18:10, Don McKenzie <dmck at u.washington.edu> wrote:
>>> 
>>> For a legend, try (untested)
>>> 
>>> legend(0.15,0.9,c("factora","factorb","factorc"),col=c(4,2,3),lty=1)
>>> 
>>> If it overlaps data points move the first two arguments (0.15 and 0.9) around, or change the ?ylim? argument in the plot() to ~1.2.
>>> 
>>> to avoid clutter, put the line-types information in the figure caption (IMO)
>>> 
>>> 
>>>> On Jun 10, 2015, at 10:03 AM, Don McKenzie <dmck at u.washington.edu> wrote:
>>>> 
>>>> 
>>>>> On Jun 10, 2015, at 9:08 AM, Rosa Oliveira <rosita21 at gmail.com> wrote:
>>>>> 
>>>>> Dear All,
>>>>> 
>>>>> 
>>>>> I attach my data.
>>>>> 
>>>>> Dear Jim, 
>>>>> 
>>>>> when I run your code (even the one you send me, not in my data), I get: 
>>>>> 
>>>>> Don't know how to automatically pick scale for object of type function. Defaulting to continuous
>>>>> Error in data.frame(x = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1,  : 
>>>>>   arguments imply differing number of rows: 24, 0
>>>>> 
>>>>> 
>>>>> 
>>>>> Dear Don,
>>>>> 
>>>>> It?s meant that I will have 12 lines: 
>>>>> 3 factors - lines colors
>>>>> with 3 different values of ?sample? for each - line types
>>>>> 
>>>>> 
>>>>> [Three colors, one for each factor,
>>>>> and  three line types (lty=1,2,3), one for eachvalue of ?sample - preferable dash, thin and thick).
>>>>> 
>>>>> 
>>>>> in the X - I should have region (because I have 10 regions)
>>>>> for each region I have the outcome of 3 different treatments (factor)
>>>>> for each region and each treatment I have 3 different sample size.
>>>> 
>>>> But in your original post you had 4 sample sizes: 10,20,30,40.
>>>>> 
>>>>> I need to ?see? the the influence of the region in the treatment outcome for each sample size.
>>>>> 
>>>>> So, at the end I should have 9 lines
>>>>> 3 red (1 dash, 1 thin, 1 thick) - concerning factor a (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>>>> 3 blue (1 dash, 1 thin, 1 thick) - concerning factor b (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>>>> 3 green (1 dash, 1 thin, 1 thick) - concerning factor c (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
>>>>> 
>>>>> 
>>>>> 
>>>>> Hope this time is clear.
>>>>> 
>>>>> 
>>>>> I also though about doing 3 different graphs, each one for 1 different sample size, and in that case I should have 3 graphs each one with 3 lines
>>>>> 1 red to factor a, 1 blue to factor b and 1 green to factor c.
>>>>> 
>>>>> Do you all think is better?
>>>> 
>>>> A matter of style perhaps but I would use dotplots because you have only two data points for each ?line?.  The lines will be misleading.  You also could use 
>>>> panel plots, but given your skill set (unless someone wants to spend a fair bit of time with you), it?s probably best to stay as simple as possible.
>>>> 
>>>> But given your original post (cleaned up)   # untested: apologies for any typos
>>>> 
>>>>>        region              sample          factora          factorb 		factorc
>>>>> 	0.1  			10     	 0.895   		0.903   		0.378
>>>>> 	0.2  			10      	0.811  		 0.865  		 0.688
>>>>> 	0.1  			20      	0.735   		0.966   		0.611
>>>>> 	0.2  			20     	 0.777  		 0.732  		 0.653
>>>>> 	0.1  			30      	0.600   		0.778   		0.694
>>>>> 	0.2  			30     	 0.466  		 174.592 		0.461
>>>>> 	0.1  			40     	 0.446   		0.432   		0.693
>>>>> 	0.2  			40     	 0.392   		0.294  		 0.686
>>>> 
>>>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4,type=?l?,ylim=c(0,1),xlab=?region?,ylab=?factor")
>>>> lines(my.data$region[my.data$sample==10],my.data$factorb[my.data$sample==10],col=2)
>>>> lines(my.data$region[my.data$sample==10],my.data$factorc[my.data$sample==10],col=3)
>>>> 
>>>> lines(my.data$region[my.data$sample==20],my.data$factora[my.data$sample==20],col=4,lty=2)
>>>> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
>>>> lines(my.data$region[my.data$sample==20],my.data$factorc[my.data$sample==20],col=3,lty=2)
>>>> 
>>>> #  Now do two more groups of 3, changing the parameter ?lty? to 3 and then 4
>>>> 
>>>> # Look at the syntax and note what changes and what stays constant. Do you see how this works?
>>>> # there will be what looks like a vertical line where sample = 30 and factorb = 174.592.  Do you see why?
>>>> 
>>>> # then you will need a legend
>>>> 
>>>>> Nonetheless I can?t do it :(
>>>>> 
>>>>> best,
>>>>> RO
>>>>> 
>>>>> 
>>>>> 
>>>>> Atenciosamente,
>>>>> Rosa Oliveira
>>>>> 
>>>>> -- 
>>>>> ____________________________________________________________________________
>>>>>  
>>>>> <smile.jpg>
>>>>> Rosa Celeste dos Santos Oliveira, 
>>>>> 
>>>>> E-mail: rosita21 at gmail.com
>>>>> Tlm: +351 939355143 
>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>>>>> ____________________________________________________________________________
>>>>> "Many admire, few know"
>>>>> Hippocrates
>>>>> 
>>>>>> On 10 Jun 2015, at 14:13, John Kane <jrkrideau at inbox.com> wrote:
>>>>>> 
>>>>>> Hi Jim,
>>>>>> 
>>>>>> I was looking at that last night and had the same problem of visualizing what Rosa needed.  
>>>>>> 
>>>>>> Hi Rosa
>>>>>> This is nothing like what you wanted and I really don't understand your data but would something like this work as a substitute or am I completely lost?
>>>>>> 
>>>>>> 
>>>>>> dat1  <-  structure(list(region = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 
>>>>>> 0.2), sample = c(10L, 10L, 20L, 20L, 30L, 30L, 40L, 40L), factora = c(0.895, 
>>>>>> 0.811, 0.735, 0.777, 0.6, 0.466, 0.446, 0.392), factorb = c(0.903,
>>>>>> 0.865, 0.966, 0.732, 0.778, 0.592, 0.432, 0.294), factorc = c(0.37, 
>>>>>> 0.688, 0.611, 0.653, 0.694, 0.461, 0.693, 0.686)), .Names = c("region", 
>>>>>> "sample", "factora", "factorb", "factorc"), class = "data.frame", row.names = c(NA, 
>>>>>> -8L))
>>>>>> 
>>>>>> 
>>>>>> mdat1  <-   melt(dat1, id.var = c("region", "sample"),
>>>>>>                    variable.name = "factor",
>>>>>>                    value.name = "value")
>>>>>> str(mdat1)
>>>>>> 
>>>>>> ggplot(mdat1, aes(region, value, colour = factor)) +
>>>>>>                geom_line() + facet_grid(sample ~ .)
>>>>>> 
>>>>>> John Kane
>>>>>> Kingston ON Canada
>>>>>> 
>>>>>> 
>>>>>>> -----Original Message-----
>>>>>>> From: drjimlemon at gmail.com
>>>>>>> Sent: Wed, 10 Jun 2015 20:51:52 +1000
>>>>>>> To: rosita21 at gmail.com
>>>>>>> Subject: Re: [R] graphs, need urgent help (deadline :( )
>>>>>>> 
>>>>>>> Hi Rosa,
>>>>>>> Like Don, I can't work out what you want and I don't even have the
>>>>>>> picture. For example, your specification of color and line type leaves
>>>>>>> only one point for each color and line type, and the line from one
>>>>>>> point to the same point is not going to show up. Here is a possibility
>>>>>>> that may lead (eventually) to a solution.
>>>>>>> 
>>>>>>> library(plotrix)
>>>>>>> par(tcl=-0.1)
>>>>>>> gap.plot(x=rep(seq(10,45,by=5),3),
>>>>>>> y=unlist(my.data[,c("factora","factorb","factorc")]),
>>>>>>> main="A plot of factorial mystery",
>>>>>>> gap=c(1.1,174),ylim=c(0,175),ylab="factor score",xlab="Group",
>>>>>>> xticlab=c(" \n0.1\n10"," \n0.2\n10"," \n0.1\n20"," \n0.2\n20",
>>>>>>>  " \n0.1\n30"," \n0.2\n30"," \n0.1\n40"," \n0.2\n40"),
>>>>>>> ytics=c(0,0.5,1,174.59),pch=rep(1:3,each=8),col=rep(c(4,2,3),each=8))
>>>>>>> mtext(c("Region","Sample"),side=1,at=6,line=c(0,1))
>>>>>>> lines(seq(10,45,by=5),my.data$factora,col=4)
>>>>>>> lines(seq(10,45,by=5),my.data$factorb[c(1:5,NA,7,8)],col=2)
>>>>>>> lines(seq(10,45,by=5),my.data$factorc,col=3)
>>>>>>> 
>>>>>>> Jim
>>>>>>> 
>>>>>>> 
>>>>>>> On Wed, Jun 10, 2015 at 10:53 AM, Rosa Oliveira <rosita21 at gmail.com>
>>>>>>> wrote:
>>>>>>>> Dear Don and all,
>>>>>>>> 
>>>>>>>> I?ve read the tutorial and tried several codes before posting :)
>>>>>>>> I?m really naive.
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> what I was trying to :  is something like the graph in the picture I
>>>>>>>> drawee.
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Is it more clear now?
>>>>>>>> 
>>>>>>>> Atenciosamente,
>>>>>>>> Rosa Oliveira
>>>>>>>> 
>>>>>>>> --
>>>>>>>> ____________________________________________________________________________
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Rosa Celeste dos Santos Oliveira,
>>>>>>>> 
>>>>>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>>>>>> Tlm: +351 939355143
>>>>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>>>>>>>> <https://pt.linkedin.com/in/rosacsoliveira>
>>>>>>>> ____________________________________________________________________________
>>>>>>>> "Many admire, few know"
>>>>>>>> Hippocrates
>>>>>>>> 
>>>>>>>>> On 09 Jun 2015, at 19:23, Don McKenzie <dmck at u.washington.edu
>>>>>>>>> <mailto:dmck at u.washington.edu>> wrote:
>>>>>>>>> 
>>>>>>>>> The answer lies in learning to use the help (and knowing where to
>>>>>>>>> start).  Did you look at the tutorial that comes with the R
>>>>>>>>> installation?
>>>>>>>>> 
>>>>>>>>> ?plot
>>>>>>>>> ?lines
>>>>>>>>> 
>>>>>>>>> ?par
>>>>>>>>> 
>>>>>>>>> In the last, look for the descriptions of ?col? and ?lty?.
>>>>>>>>> 
>>>>>>>>> Using plot() and lines(), and subsetting the four unique values of
>>>>>>>>> ?sample?, you can create your lines.
>>>>>>>>> 
>>>>>>>>> Here is a crude start, assuming your columns are part of a data frame
>>>>>>>>> called ?my.data?.   Untested...
>>>>>>>>> 
>>>>>> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)
>>>>>>>>> # blue line, not dashed
>>>>>>>>> .
>>>>>>>>> .
>>>>>>>>> .
>>>>>> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
>>>>>>>>> # red dashed line
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>>> On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com
>>>>>>>>>> <mailto:rosita21 at gmail.com>> wrote:
>>>>>>>>>> 
>>>>>>>>>> Hi,
>>>>>>>>>> 
>>>>>>>>>> another naive question (i?m pretty sure :( )
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> I?m trying to plot a multiple line graph:
>>>>>>>>>> 
>>>>>>>>>>        region              sample          factora          factorb
>>>>>>>>>> factorc
>>>>>>>>>> 0.1  10      0.895   0.903   0.378
>>>>>>>>>> 0.2  10      0.811   0.865   0.688
>>>>>>>>>> 0.1  20      0.735   0.966   0.611
>>>>>>>>>> 0.2  20      0.777   0.732   0.653
>>>>>>>>>> 0.1  30      0.600   0.778   0.694
>>>>>>>>>> 0.2  30      0.466   174.592 0.461
>>>>>>>>>> 0.1  40      0.446   0.432   0.693
>>>>>>>>>> 0.2  40      0.392   0.294   0.686
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> The first column should be the independent variable, the second should
>>>>>>>>>> compute a bold line for sample(10) and dash line for sample 20.
>>>>>>>>> 
>>>>>>>>> What about the other two values of ?sample??
>>>>>>>>> 
>>>>>>>>>> The others variables are outcomes for each of the first scenarios, and
>>>>>>>>>> so it should: the 3rd, 4th and 5th columns should be blue, red and
>>>>>>>>>> green respectively.
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Resume :)
>>>>>>>>>> 
>>>>>>>>>> I should have a graph, in the x-axe should have the region and in the
>>>>>>>>>> y axe, the factor.
>>>>>>>>>> Lines:
>>>>>>>>>>     1 - blue and bold for region 0.1, sample 10 and factor a
>>>>>>>>>>     2 - blue and dash for region 0.2, sample 10 and factor a
>>>>>>>>>>     3 - red and bold for region 0.1, sample 10 and factor b
>>>>>>>>>>     4 - red and dash for region 0.2, sample 10 and factor b
>>>>>>>>>>     5 - green and bold for region 0.1, sample 10 and factor c
>>>>>>>>>>     6 - green and dash for region 0.2, sample 10 and factor c
>>>>>>>>> 
>>>>>>>>> Not consistent with what you said above. These are no longer lines, but
>>>>>>>>> points.
>>>>>>>>>> 
>>>>>>>>>> nonetheless the independent variable is nominal, I should plot a line
>>>>>>>>>> graph.
>>>>>>>>>> 
>>>>>>>>>> Can anyone help me please?
>>>>>>>>>> I have my file as a cvs file, so I first read that file (that I know
>>>>>>>>>> how to do :)).
>>>>>>>>>> 
>>>>>>>>>> But I have it in that format.
>>>>>>>>>> 
>>>>>>>>>> Best,
>>>>>>>>>> RO
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Atenciosamente,
>>>>>>>>>> Rosa Oliveira
>>>>>>>>>> 
>>>>>>>>>> --
>>>>>>>>>> ____________________________________________________________________________
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Rosa Celeste dos Santos Oliveira,
>>>>>>>>>> 
>>>>>>>>>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>>>>>>>>>> Tlm: +351 939355143
>>>>>>>>>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>>>>>>>>>> <https://pt.linkedin.com/in/rosacsoliveira>
>>>>>>>>>> ____________________________________________________________________________
>>>>>>>>>> "Many admire, few know"
>>>>>>>>>> Hippocrates
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>>     [[alternative HTML version deleted]]
>>>>>>>>>> 
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
>>>>>>>>>> UNSUBSCRIBE and more, see
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>> <http://www.r-project.org/posting-guide.html>
>>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>> 
>>>>>>>>> <PastedGraphic-1.tiff>
>>>>>>>>> 
>>>>>>>> 
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>>> ____________________________________________________________
>>>>>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
>>>>>> Check it out at http://www.inbox.com/marineaquarium
>>>>>> 
>>>>>> 
>>>>> 
>>>> 
>>>> <PastedGraphic-1.tiff>
>>>> 
>>> 
>>> <PastedGraphic-1.tiff>
>>> 
>> 
> 
> <PastedGraphic-1.tiff>
> 


From dmck at uw.edu  Thu Jun 11 04:07:45 2015
From: dmck at uw.edu (Don McKenzie)
Date: Wed, 10 Jun 2015 19:07:45 -0700
Subject: [R] graphs, need urgent help (deadline :( )
In-Reply-To: <1B877ADDFBA.00000691jrkrideau@inbox.com>
References: <fe94928e-a651-4e9f-9643-73635938c694@u.washington.edu>
	<1535ce35a5d.00001088jrkrideau@inbox.com>
	<8c64a81b-ab10-42af-82dc-752ca2d7ece0@u.washington.edu>
	<10c1b087-6721-44b2-a347-851219672d30@gmail.com>
	<ec24a80a-5013-4ed3-8b5a-a41b1e54ad62@u.washington.edu>
	<fd7328fb-306e-47a7-b0ac-a4eac0b8aef0@gmail.com>
	<d2fd6c5d-e38b-4317-9ffa-6cfa6aa0d20e@gmail.com>
	<c77f744d-5a89-4ac7-8dfe-9073a33c3bef@gmail.com>
	<1B877ADDFBA.00000691jrkrideau@inbox.com>
Message-ID: <D0CC263E-8762-4723-9A24-E5EA3B72BC8B@uw.edu>

Thanks John!  My eyes aren't good enough to see that. I actually checked (I thought). This was the default window on Mac console, for others who might care.

Sent from my iPad

> On Jun 10, 2015, at 6:17 PM, John Kane <jrkrideau at inbox.com> wrote:
> 
> You have curly quotes rather than plain ones here : col=4,type=?l?,xlab=?Region?,ylab=?factor")
> 
> 
> 
> John Kane
> Kingston ON Canada
> 
> -----Original Message-----
> From: dmck at u.washington.edu
> Sent: Wed, 10 Jun 2015 11:32:59 -0700
> To: rosita21 at gmail.com
> Subject: Re: [R] graphs, need urgent help (deadline :( )
> 
> You were caught by a mysterious issue that I don?t understand either.
> 
> plot(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.a[therapy.df$sample==50],col=4,type=?l?,xlab=?Region?,ylab=?factor")
> 
> Error: unexpected input in "plot(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.a[therapy.df$sample==50],col=4,type=??
> 
> but if I change the order of arguments to plot(), it?s fine
> 
> plot(therapy.df$Region[therapy.df$sample==50],therapy.df$factor.a[therapy.df$sample==50],type="l",col=4,xlab="Region",ylab="factor?)
> 
> I don?t know what to tell you.  If someone wiser than I is still reading, maybe s(he) can explain.  Possibly a bug has crept into the call to ?par?, but ?bugs" suspected by non-experts like me usually turn out to be naive user errors.  
> 
> For your purposes, use the one that works.  :-)
> 
> On Jun 10, 2015, at 11:03 AM, Rosa Oliveira <rosita21 at gmail.com> wrote:
> 
> Sorry,
> 
> I taught I attached the cvs file :)
> 
> <therapy.csv>
> 
> Don,
> 
> I tried, but I got an error:
> 
>> my.data$Region
> 
>  [1]  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10  1  2  3  4  5  6  7  8  9 10
> 
>> my.data$sample
> 
>  [1]   50   50   50   50   50   50   50   50   50   50  250  250  250  250  250  250  250  250  250  250 1000 1000 1000 1000 1000 1000 1000 1000
> 
> [29] 1000 1000
> 
>> my.data$factor.a
> 
>  [1] 0.895 0.811 0.685 0.777 0.600 0.466 0.446 0.392 0.256 0.198 0.136 0.121 0.875 0.777 0.685 0.626 0.550 0.466 0.384 0.330 0.060 0.138 0.065
> 
> [24] 0.034 0.931 0.124 0.060 0.028 0.017 0.014
> 
>> plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=?l?,xlab=?Region?,ylab=?factor")
> 
> Error: unexpected input in "plot(my.data$Region[my.data$sample==50],my.data$factor.a[my.data$sample==50],col=4,type=??
> 
> I?m really naive, right?
> 
> Best,
> 
> RO
> 
> Atenciosamente,
> Rosa Oliveira
> 
> -- 
> ____________________________________________________________________________
> 
> <smile.jpg>
> 
> Rosa Celeste dos Santos Oliveira, 
> 
> E-mail: rosita21 at gmail.com
> Tlm: +351 939355143 
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira [https://pt.linkedin.com/in/rosacsoliveira]
> ____________________________________________________________________________
> 
> "Many admire, few know"
> Hippocrates
> 
> On 10 Jun 2015, at 18:10, Don McKenzie <dmck at u.washington.edu> wrote:
> 
> For a legend, try (untested)
> 
> legend(0.15,0.9,c("factora","factorb","factorc"),col=c(4,2,3),lty=1)
> 
> If it overlaps data points move the first two arguments (0.15 and 0.9) around, or change the ?ylim? argument in the plot() to ~1.2.
> 
> to avoid clutter, put the line-types information in the figure caption (IMO)
> 
> On Jun 10, 2015, at 10:03 AM, Don McKenzie <dmck at u.washington.edu> wrote:
> 
> On Jun 10, 2015, at 9:08 AM, Rosa Oliveira <rosita21 at gmail.com> wrote:
> 
> Dear All,
> 
> I attach my data.
> 
> Dear Jim, 
> 
> when I run your code (even the one you send me, not in my data), I get: 
> 
> Don't know how to automatically pick scale for object of type function. Defaulting to continuous
> 
> Error in data.frame(x = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1,  : 
> 
>   arguments imply differing number of rows: 24, 0
> 
> Dear Don,
> 
> It?s meant that I will have 12 lines: 
> 
> 3 factors - lines colors
> 
> with 3 different values of ?sample? for each - line types
> 
> [Three colors, one for each factor,
> and  three line types (lty=1,2,3), one for eachvalue of ?sample - preferable dash, thin and thick).
> 
> in the X - I should have region (because I have 10 regions)
> 
> for each region I have the outcome of 3 different treatments (factor)
> 
> for each region and each treatment I have 3 different sample size.
> 
> But in your original post you had 4 sample sizes: 10,20,30,40.
> 
> I need to ?see? the the influence of the region in the treatment outcome for each sample size.
> 
> So, at the end I should have 9 lines
> 
> 3 red (1 dash, 1 thin, 1 thick) - concerning factor a (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
> 
> 3 blue (1 dash, 1 thin, 1 thick) - concerning factor b (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
> 
> 3 green (1 dash, 1 thin, 1 thick) - concerning factor c (dash for sample size 50, thin for sample size 250 and thick for sample size 1000)
> 
> Hope this time is clear.
> 
> I also though about doing 3 different graphs, each one for 1 different sample size, and in that case I should have 3 graphs each one with 3 lines
> 
> 1 red to factor a, 1 blue to factor b and 1 green to factor c.
> 
> Do you all think is better?
> 
> A matter of style perhaps but I would use dotplots because you have only two data points for each ?line?.  The lines will be misleading.  You also could use 
> 
> panel plots, but given your skill set (unless someone wants to spend a fair bit of time with you), it?s probably best to stay as simple as possible.
> 
> But given your original post (cleaned up)   # untested: apologies for any typos
> 
>        region              sample          factora          factorb  factorc
> 0.1   10       0.895    0.903    0.378
> 0.2   10       0.811    0.865    0.688
> 0.1   20       0.735    0.966    0.611
> 0.2   20       0.777    0.732    0.653
> 0.1   30       0.600    0.778    0.694
> 0.2   30       0.466    174.592  0.461
> 0.1   40       0.446    0.432    0.693
> 
> 0.2   40       0.392    0.294    0.686
> 
> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4,type=?l?,ylim=c(0,1),xlab=?region?,ylab=?factor")
> 
> lines(my.data$region[my.data$sample==10],my.data$factorb[my.data$sample==10],col=2)
> 
> lines(my.data$region[my.data$sample==10],my.data$factorc[my.data$sample==10],col=3)
> 
> lines(my.data$region[my.data$sample==20],my.data$factora[my.data$sample==20],col=4,lty=2)
> 
> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
> 
> lines(my.data$region[my.data$sample==20],my.data$factorc[my.data$sample==20],col=3,lty=2)
> 
> #  Now do two more groups of 3, changing the parameter ?lty? to 3 and then 4
> 
> # Look at the syntax and note what changes and what stays constant. Do you see how this works?
> 
> # there will be what looks like a vertical line where sample = 30 and factorb = 174.592.  Do you see why?
> 
> # then you will need a legend
> 
> Nonetheless I can?t do it :(
> 
> best,
> 
> RO
> 
> Atenciosamente,
> Rosa Oliveira
> 
> -- 
> ____________________________________________________________________________
> 
> <smile.jpg>
> Rosa Celeste dos Santos Oliveira, 
> 
> E-mail: rosita21 at gmail.com
> Tlm: +351 939355143 
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira [https://pt.linkedin.com/in/rosacsoliveira]
> ____________________________________________________________________________
> 
> "Many admire, few know"
> Hippocrates
> 
> On 10 Jun 2015, at 14:13, John Kane <jrkrideau at inbox.com> wrote:
> 
> Hi Jim,
> 
> I was looking at that last night and had the same problem of visualizing what Rosa needed.  
> 
> Hi Rosa
> This is nothing like what you wanted and I really don't understand your data but would something like this work as a substitute or am I completely lost?
> 
> dat1  <-  structure(list(region = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 
> 0.2), sample = c(10L, 10L, 20L, 20L, 30L, 30L, 40L, 40L), factora = c(0.895, 
> 0.811, 0.735, 0.777, 0.6, 0.466, 0.446, 0.392), factorb = c(0.903, 
> 0.865, 0.966, 0.732, 0.778, 0.592, 0.432, 0.294), factorc = c(0.37, 
> 0.688, 0.611, 0.653, 0.694, 0.461, 0.693, 0.686)), .Names = c("region", 
> "sample", "factora", "factorb", "factorc"), class = "data.frame", row.names = c(NA, 
> -8L))
> 
> mdat1  <-   melt(dat1, id.var = c("region", "sample"),
>                    variable.name = "factor",
>                    value.name = "value")
> str(mdat1)
> 
> ggplot(mdat1, aes(region, value, colour = factor)) +
>                geom_line() + facet_grid(sample ~ .)
> 
> John Kane
> Kingston ON Canada
> 
>    -----Original Message-----
> From: drjimlemon at gmail.com
> Sent: Wed, 10 Jun 2015 20:51:52 +1000
> To: rosita21 at gmail.com
> Subject: Re: [R] graphs, need urgent help (deadline :( )
> 
> Hi Rosa,
> Like Don, I can't work out what you want and I don't even have the
> picture. For example, your specification of color and line type leaves
> only one point for each color and line type, and the line from one
> point to the same point is not going to show up. Here is a possibility
> that may lead (eventually) to a solution.
> 
> library(plotrix)
> par(tcl=-0.1)
> gap.plot(x=rep(seq(10,45,by=5),3),
> y=unlist(my.data[,c("factora","factorb","factorc")]),
> main="A plot of factorial mystery",
> gap=c(1.1,174),ylim=c(0,175),ylab="factor score",xlab="Group",
> xticlab=c(" \n0.1\n10"," \n0.2\n10"," \n0.1\n20"," \n0.2\n20",
>  " \n0.1\n30"," \n0.2\n30"," \n0.1\n40"," \n0.2\n40"),
> ytics=c(0,0.5,1,174.59),pch=rep(1:3,each=8),col=rep(c(4,2,3),each=8))
> mtext(c("Region","Sample"),side=1,at=6,line=c(0,1))
> lines(seq(10,45,by=5),my.data$factora,col=4)
> lines(seq(10,45,by=5),my.data$factorb[c(1:5,NA,7,8)],col=2)
> lines(seq(10,45,by=5),my.data$factorc,col=3)
> 
> Jim
> 
> On Wed, Jun 10, 2015 at 10:53 AM, Rosa Oliveira <rosita21 at gmail.com>
> wrote:
> 
>    Dear Don and all,
> 
> I?ve read the tutorial and tried several codes before posting :)
> I?m really naive.
> 
> what I was trying to :  is something like the graph in the picture I
> drawee.
> 
> Is it more clear now?
> 
> Atenciosamente,
> Rosa Oliveira
> 
> --
> ____________________________________________________________________________
> 
> Rosa Celeste dos Santos Oliveira,
> 
> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
> Tlm: +351 939355143
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira [https://pt.linkedin.com/in/rosacsoliveira]
> <https://pt.linkedin.com/in/rosacsoliveira [https://pt.linkedin.com/in/rosacsoliveira]>
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
> 
>    On 09 Jun 2015, at 19:23, Don McKenzie <dmck at u.washington.edu
> <mailto:dmck at u.washington.edu>> wrote:
> 
> The answer lies in learning to use the help (and knowing where to
> start).  Did you look at the tutorial that comes with the R
> installation?
> 
> ?plot
> ?lines
> 
> ?par
> 
> In the last, look for the descriptions of ?col? and ?lty?.
> 
> Using plot() and lines(), and subsetting the four unique values of
> ?sample?, you can create your lines.
> 
> Here is a crude start, assuming your columns are part of a data frame
> called ?my.data?.   Untested...
> 
> plot(my.data$region[my.data$sample==10],my.data$factora[my.data$sample==10],col=4)
> 
>    # blue line, not dashed
> .
> .
> .
> 
> lines(my.data$region[my.data$sample==20],my.data$factorb[my.data$sample==20],col=2,lty=2)
> 
>    # red dashed line
> 
>    On Jun 9, 2015, at 10:36 AM, Rosa Oliveira <rosita21 at gmail.com
> <mailto:rosita21 at gmail.com>> wrote:
> 
> Hi,
> 
> another naive question (i?m pretty sure :( )
> 
> I?m trying to plot a multiple line graph:
> 
>        region              sample          factora          factorb
> factorc
> 0.1  10      0.895   0.903   0.378
> 0.2  10      0.811   0.865   0.688
> 0.1  20      0.735   0.966   0.611
> 0.2  20      0.777   0.732   0.653
> 0.1  30      0.600   0.778   0.694
> 0.2  30      0.466   174.592 0.461
> 0.1  40      0.446   0.432   0.693
> 0.2  40      0.392   0.294   0.686
> 
> The first column should be the independent variable, the second should
> compute a bold line for sample(10) and dash line for sample 20.
> 
> What about the other two values of ?sample??
> 
>    The others variables are outcomes for each of the first scenarios, and
> so it should: the 3rd, 4th and 5th columns should be blue, red and
> green respectively.
> 
> Resume :)
> 
> I should have a graph, in the x-axe should have the region and in the
> y axe, the factor.
> Lines:
>     1 - blue and bold for region 0.1, sample 10 and factor a
>     2 - blue and dash for region 0.2, sample 10 and factor a
>     3 - red and bold for region 0.1, sample 10 and factor b
>     4 - red and dash for region 0.2, sample 10 and factor b
>     5 - green and bold for region 0.1, sample 10 and factor c
>     6 - green and dash for region 0.2, sample 10 and factor c
> 
> Not consistent with what you said above. These are no longer lines, but
> points.
> 
> nonetheless the independent variable is nominal, I should plot a line
> graph.
> 
> Can anyone help me please?
> I have my file as a cvs file, so I first read that file (that I know
> how to do :)).
> 
> But I have it in that format.
> 
> Best,
> RO
> 
> Atenciosamente,
> Rosa Oliveira
> 
> --
> ____________________________________________________________________________
> 
> Rosa Celeste dos Santos Oliveira,
> 
> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
> Tlm: +351 939355143
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira [https://pt.linkedin.com/in/rosacsoliveira]
> <https://pt.linkedin.com/in/rosacsoliveira [https://pt.linkedin.com/in/rosacsoliveira]>
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
> 
>     [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
> <https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]>
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html [http://www.r-project.org/posting-guide.html]
> <http://www.r-project.org/posting-guide.html [http://www.r-project.org/posting-guide.html]>
> and provide commented, minimal, self-contained, reproducible code.
> 
> <PastedGraphic-1.tiff>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html [http://www.r-project.org/posting-guide.html]
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html [http://www.r-project.org/posting-guide.html]
> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
> Check it out at http://www.inbox.com/marineaquarium [http://www.inbox.com/marineaquarium]
> 
> <PastedGraphic-1.tiff> 
> 
> <PastedGraphic-1.tiff>
> 
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/manager
> 
> 


From sofie.waltl at uni-graz.at  Thu Jun 11 08:57:14 2015
From: sofie.waltl at uni-graz.at (Waltl, Sofie (sofie.waltl@uni-graz.at))
Date: Thu, 11 Jun 2015 08:57:14 +0200
Subject: [R] Quantile regression model with nonparametric effect and
	interaction
Message-ID: <9BC4D2B513C5954687686E9681FDB25719E1D350A6@ARTEMIS.pers.ad.uni-graz.at>

Dear all,

I would like to estimate a quantile regression model including a bivariate nonparametric term which should be interacted with a dummy variable, i.e.,
log p ~ year + f(a,b):year.
I tried to use Roger Koenker's quantreg package and the functions rqss and qss but it turns out that interactions are not possible in this setting. Also weights are not implemented yet to build a work-around. I am looking for something like the by-statement in Simon Wood's package mgcv. Does anything comparable exist?
I am grateful for any help on this issue.

Kind regards,
S. Waltl


	[[alternative HTML version deleted]]


From aroonalok.pyne at gmail.com  Thu Jun 11 10:32:56 2015
From: aroonalok.pyne at gmail.com (AROONALOK PYNE)
Date: Thu, 11 Jun 2015 14:02:56 +0530
Subject: [R] Issue with mcapply
Message-ID: <CAN2HEGQbYmc340bDgHTfzMRSU0CaikgXWBZRhhu=CKcjT9gjOQ@mail.gmail.com>

Please check this code :

library(parallel)
workerFunc <- function(n) { return(n^2) }
a <- function(){
  CurrentTime <- Sys.time()
  res <- lapply(values, workerFunc)
  TimeTaken <- Sys.time() - CurrentTime
  print(TimeTaken)
}
b <- function(){
  CurrentTime <- Sys.time()
  numWorkers <- detectCores()
  res <- mclapply(values, workerFunc, mc.cores = numWorkers-2)
  TimeTaken <- Sys.time() - CurrentTime
  print(TimeTaken)
}
c <- function(n){
  values <<- 1:n
  print("Evaluating a : ")
  a()
  print("Evaluating b : ")
  b()
}

For large values of n, the code calculates a() but the hangs indefinitely
on reaching b(). How do I correct it ?
I am using Ubuntu 14.04 and core i7 Processor

-- 
*AROONALOK PYNE*

BE Graduate
Department Of Computer Science And Engineering
Jadavpur University, Kolkata-32
India

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Jun 11 10:36:37 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 11 Jun 2015 08:36:37 +0000
Subject: [R] Summarizing data based on Date
In-Reply-To: <0A74C162CD5.00000404jrkrideau@inbox.com>
References: <1433750889045-4708328.post@n4.nabble.com>
	<0A74C162CD5.00000404jrkrideau@inbox.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C307C4@SRVEXCHMBX.precheza.cz>

Hi

I (wrongly) understood that Shivi82 wanted to summarise on month values. Therefore

format(test$CR_DT,"%m")

shall give you month number and list is required by aggregate.

All the problem was  in

test$CHG_WT

which seems to be a factor (for whatever reason)

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of John
> Kane
> Sent: Tuesday, June 09, 2015 6:42 PM
> To: Shivi82; r-help at r-project.org
> Subject: Re: [R] Summarizing data based on Date
>
> Hi,
>
> As David said have a look at str(test). You have a factor in there or
> else that weird "list(format(test$CR_DT,"%m"))" command in aggregate()
> is mucking things up.  What is "list(format(test$CR_DT,"%m"))" intended
> to do?  No ,a quick test says it is mucking something else up and not
> giving the us the factor problem.
>
> Here is your sample data and what I think is what you are trying to do.
> Note the data is supplied in dput() format which is the preferred way
> to supply sample data to the R-help list.  See
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-
> reproducible-example and http://adv-r.had.co.nz/Reproducibility.html
> for more information.  I used lubridate's dmy() function rather than
> as.Date() to format the dates.
>
> dat1  <-  structure(list(dd = structure(c(1426204800, 1427760000,
> 1426377600, 1426550400, 1426550400, 1426032000, 1426032000,
> 1426723200), tzone = "UTC", class = c("POSIXct", "POSIXt")), wt = c(0,
> 0, 0, 770, 3.73, 70, 10, 500)), .Names = c("dd", "wt"), row.names =
> c(NA, -8L), class = "data.frame")
>
> str(dat1)
>
> aggregate(dat1$wt, list(dat1$dd), sum)
>
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: shivibhatia at ymail.com
> > Sent: Tue, 9 Jun 2015 05:01:23 -0700 (PDT)
> > To: r-help at r-project.org
> > Subject: Re: [R] Summarizing data based on Date
> >
> > Hi Petr
> >
> > I researched a lot over the net and R manual as well based on which I
> > revamped my code and came to the code as:
> > test$CR_DT <- as.Date(test$CR_DT, '%d-%b-%y')
> >
> > iii<- aggregate(test$CHG_WT,list(format(test$CR_DT,"%m")),FUN=sum)
> >
> > However it still gives me the error as below:
> > Error in Summary.factor(c(1L, 1L, 1L, 3286L, 1646L, 3241L, 1L, 1L,
> > 1307L,
> > :
> >   ?sum? not meaningful for factors.
> >
> > If could you guide on how to achieve the desired output. Thanks.
> >
> >
> >
> > --
> > View this message in context:
> > http://r.789695.n4.nabble.com/Summarizing-data-based-on-Date-
> tp4708328
> > p4708384.html Sent from the R help mailing list archive at
> Nabble.com.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> TRY FREE IM TOOLPACK at http://www.imtoolpack.com/default.aspx?rc=if5
> Capture screenshots, upload images, edit and send them to your friends
> through IMs, post on Twitter?, Facebook?, MySpace?, LinkedIn? ? FAST!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Rainer at krugs.de  Thu Jun 11 10:45:31 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 11 Jun 2015 10:45:31 +0200
Subject: [R] Issue with mcapply
In-Reply-To: <CAN2HEGQbYmc340bDgHTfzMRSU0CaikgXWBZRhhu=CKcjT9gjOQ@mail.gmail.com>
	(AROONALOK PYNE's message of "Thu, 11 Jun 2015 14:02:56 +0530")
References: <CAN2HEGQbYmc340bDgHTfzMRSU0CaikgXWBZRhhu=CKcjT9gjOQ@mail.gmail.com>
Message-ID: <m28ubq4or8.fsf@krugs.de>

AROONALOK PYNE <aroonalok.pyne at gmail.com> writes:

> Please check this code :
>
> library(parallel)
> workerFunc <- function(n) { return(n^2) }
> a <- function(){
>   CurrentTime <- Sys.time()
>   res <- lapply(values, workerFunc)
>   TimeTaken <- Sys.time() - CurrentTime
>   print(TimeTaken)
> }
> b <- function(){
>   CurrentTime <- Sys.time()
>   numWorkers <- detectCores()
>   res <- mclapply(values, workerFunc, mc.cores = numWorkers-2)
>   TimeTaken <- Sys.time() - CurrentTime
>   print(TimeTaken)
> }
> c <- function(n){
>   values <<- 1:n
>   print("Evaluating a : ")
>   a()
>   print("Evaluating b : ")
>   b()
> }
>
> For large values of n, the code calculates a() but the hangs indefinitely
> on reaching b(). How do I correct it ?
> I am using Ubuntu 14.04 and core i7 Processor

Which version of R and what are "large values"?

I just did the following successfully:

,----
| > c(100)
| [1] "Evaluating a : "
| Time difference of 0.0002059937 secs
| [1] "Evaluating b : "
| Time difference of 0.02037406 secs
| > c(1000)
| [1] "Evaluating a : "
| Time difference of 0.001929998 secs
| [1] "Evaluating b : "
| Time difference of 0.01943302 secs
| > c(1000000)
| [1] "Evaluating a : "
| Time difference of 1.822959 secs
| [1] "Evaluating b : "
| Time difference of 1.46111 secs
| > c(10000000)
| [1] "Evaluating a : "
| Time difference of 23.55863 secs
| [1] "Evaluating b : "
| Time difference of 15.90938 secs
| >
`----

Cheers,

Rainer
-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 480 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150611/6a686214/attachment.bin>

From Rainer at krugs.de  Thu Jun 11 11:54:53 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 11 Jun 2015 11:54:53 +0200
Subject: [R] Issue with mcapply
In-Reply-To: <CAN2HEGRgfC03mWVcKY3fGJQHHsezB+55+OoYUJaQFpb_5xMjrA@mail.gmail.com>
	(AROONALOK PYNE's message of "Thu, 11 Jun 2015 14:25:45 +0530")
References: <CAN2HEGQbYmc340bDgHTfzMRSU0CaikgXWBZRhhu=CKcjT9gjOQ@mail.gmail.com>
	<m28ubq4or8.fsf@krugs.de>
	<CAN2HEGRgfC03mWVcKY3fGJQHHsezB+55+OoYUJaQFpb_5xMjrA@mail.gmail.com>
Message-ID: <m2wpza36z6.fsf@krugs.de>

Please keep this on the r-help mailing list.

AROONALOK PYNE <aroonalok.pyne at gmail.com> writes:

> R version 3.0.2 (2013-09-25)
>
>
> Large value : 9999999
>
>
> I rerun the code as c(10000000) for which your machine works fine but
> my code still hangs on reaching b(). I am running it from Linux
> Terminal.

Might be memory allocation issue (hardware)? I have 1GB of memory. If I
am not mistaken, all the data is copied into different R threads when
using mclapply - so the memory requirement is much bigger.

Cheers,

Rainer


>
>
> On Thu, Jun 11, 2015 at 2:15 PM, Rainer M Krug <Rainer at krugs.de> wrote:
>
>> AROONALOK PYNE <aroonalok.pyne at gmail.com> writes:
>>
>> > Please check this code :
>> >
>> > library(parallel)
>> > workerFunc <- function(n) { return(n^2) }
>> > a <- function(){
>> >   CurrentTime <- Sys.time()
>> >   res <- lapply(values, workerFunc)
>> >   TimeTaken <- Sys.time() - CurrentTime
>> >   print(TimeTaken)
>> > }
>> > b <- function(){
>> >   CurrentTime <- Sys.time()
>> >   numWorkers <- detectCores()
>> >   res <- mclapply(values, workerFunc, mc.cores = numWorkers-2)
>> >   TimeTaken <- Sys.time() - CurrentTime
>> >   print(TimeTaken)
>> > }
>> > c <- function(n){
>> >   values <<- 1:n
>> >   print("Evaluating a : ")
>> >   a()
>> >   print("Evaluating b : ")
>> >   b()
>> > }
>> >
>> > For large values of n, the code calculates a() but the hangs indefinitely
>> > on reaching b(). How do I correct it ?
>> > I am using Ubuntu 14.04 and core i7 Processor
>>
>> Which version of R and what are "large values"?
>>
>> I just did the following successfully:
>>
>> ,----
>> | > c(100)
>> | [1] "Evaluating a : "
>> | Time difference of 0.0002059937 secs
>> | [1] "Evaluating b : "
>> | Time difference of 0.02037406 secs
>> | > c(1000)
>> | [1] "Evaluating a : "
>> | Time difference of 0.001929998 secs
>> | [1] "Evaluating b : "
>> | Time difference of 0.01943302 secs
>> | > c(1000000)
>> | [1] "Evaluating a : "
>> | Time difference of 1.822959 secs
>> | [1] "Evaluating b : "
>> | Time difference of 1.46111 secs
>> | > c(10000000)
>> | [1] "Evaluating a : "
>> | Time difference of 23.55863 secs
>> | [1] "Evaluating b : "
>> | Time difference of 15.90938 secs
>> | >
>> `----
>>
>> Cheers,
>>
>> Rainer
>> --
>> Rainer M. Krug
>> email: Rainer<at>krugs<dot>de
>> PGP: 0x0F52F982
>>

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 480 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150611/1fbd7586/attachment.bin>

From aroonalok.pyne at gmail.com  Thu Jun 11 12:22:35 2015
From: aroonalok.pyne at gmail.com (AROONALOK PYNE)
Date: Thu, 11 Jun 2015 15:52:35 +0530
Subject: [R] Fwd: Issue with mcapply
In-Reply-To: <CAN2HEGRgfC03mWVcKY3fGJQHHsezB+55+OoYUJaQFpb_5xMjrA@mail.gmail.com>
References: <CAN2HEGQbYmc340bDgHTfzMRSU0CaikgXWBZRhhu=CKcjT9gjOQ@mail.gmail.com>
	<m28ubq4or8.fsf@krugs.de>
	<CAN2HEGRgfC03mWVcKY3fGJQHHsezB+55+OoYUJaQFpb_5xMjrA@mail.gmail.com>
Message-ID: <CAN2HEGREJ_YTOvt5Xq236jmY3+Vdkc6TPEpXEiB9pZGdjpJyWQ@mail.gmail.com>

---------- Forwarded message ----------
From: AROONALOK PYNE <aroonalok.pyne at gmail.com>
Date: Thu, Jun 11, 2015 at 2:25 PM
Subject: Re: Issue with mcapply
To: Rainer M Krug <Rainer at krugs.de>


R version 3.0.2 (2013-09-25)


Large value : 9999999


I rerun the code as c(10000000) for which your machine works fine but
my code still hangs on reaching b(). I am running it from Linux
Terminal.


On Thu, Jun 11, 2015 at 2:15 PM, Rainer M Krug <Rainer at krugs.de> wrote:

> AROONALOK PYNE <aroonalok.pyne at gmail.com> writes:
>
> > Please check this code :
> >
> > library(parallel)
> > workerFunc <- function(n) { return(n^2) }
> > a <- function(){
> >   CurrentTime <- Sys.time()
> >   res <- lapply(values, workerFunc)
> >   TimeTaken <- Sys.time() - CurrentTime
> >   print(TimeTaken)
> > }
> > b <- function(){
> >   CurrentTime <- Sys.time()
> >   numWorkers <- detectCores()
> >   res <- mclapply(values, workerFunc, mc.cores = numWorkers-2)
> >   TimeTaken <- Sys.time() - CurrentTime
> >   print(TimeTaken)
> > }
> > c <- function(n){
> >   values <<- 1:n
> >   print("Evaluating a : ")
> >   a()
> >   print("Evaluating b : ")
> >   b()
> > }
> >
> > For large values of n, the code calculates a() but the hangs indefinitely
> > on reaching b(). How do I correct it ?
> > I am using Ubuntu 14.04 and core i7 Processor
>
> Which version of R and what are "large values"?
>
> I just did the following successfully:
>
> ,----
> | > c(100)
> | [1] "Evaluating a : "
> | Time difference of 0.0002059937 secs
> | [1] "Evaluating b : "
> | Time difference of 0.02037406 secs
> | > c(1000)
> | [1] "Evaluating a : "
> | Time difference of 0.001929998 secs
> | [1] "Evaluating b : "
> | Time difference of 0.01943302 secs
> | > c(1000000)
> | [1] "Evaluating a : "
> | Time difference of 1.822959 secs
> | [1] "Evaluating b : "
> | Time difference of 1.46111 secs
> | > c(10000000)
> | [1] "Evaluating a : "
> | Time difference of 23.55863 secs
> | [1] "Evaluating b : "
> | Time difference of 15.90938 secs
> | >
> `----
>
> Cheers,
>
> Rainer
> --
> Rainer M. Krug
> email: Rainer<at>krugs<dot>de
> PGP: 0x0F52F982
>



-- 
*AROONALOK PYNE*

BE Graduate
Department Of Computer Science And Engineering
Jadavpur University, Kolkata-32
India





-- 
*AROONALOK PYNE*

BE Graduate
Department Of Computer Science And Engineering
Jadavpur University, Kolkata-32
India

	[[alternative HTML version deleted]]


From aroonalok.pyne at gmail.com  Thu Jun 11 12:23:05 2015
From: aroonalok.pyne at gmail.com (AROONALOK PYNE)
Date: Thu, 11 Jun 2015 15:53:05 +0530
Subject: [R] Fwd: Issue with mcapply
In-Reply-To: <CAN2HEGRQqyhcDezhYk=Ht5Zd1NGKK9N8kpbg48p6wOWKuwdueg@mail.gmail.com>
References: <CAN2HEGQbYmc340bDgHTfzMRSU0CaikgXWBZRhhu=CKcjT9gjOQ@mail.gmail.com>
	<m28ubq4or8.fsf@krugs.de>
	<CAN2HEGRgfC03mWVcKY3fGJQHHsezB+55+OoYUJaQFpb_5xMjrA@mail.gmail.com>
	<m2wpza36z6.fsf@krugs.de>
	<CAN2HEGRQqyhcDezhYk=Ht5Zd1NGKK9N8kpbg48p6wOWKuwdueg@mail.gmail.com>
Message-ID: <CAN2HEGQqTD4sDmVRtscTdLe+BCHKzs6=TEhj5fJjAraa-mOTSA@mail.gmail.com>

---------- Forwarded message ----------
From: AROONALOK PYNE <aroonalok.pyne at gmail.com>
Date: Thu, Jun 11, 2015 at 3:49 PM
Subject: Re: Issue with mcapply
To: Rainer M Krug <Rainer at krugs.de>


Hi,

My system has 4GB memory. On running htop command on linux terminal,  for
c(9999999), a() runnnng on single cpu core showed stats for 100% cpu
utilization. On reaching b(), the entire system hanged (no response and the
cpu utilization froze at 100%, RAM utilization never crossed 1.5 GB)



-- 
*AROONALOK PYNE*

BE Graduate
Department Of Computer Science And Engineering
Jadavpur University, Kolkata-32
India

	[[alternative HTML version deleted]]


From Rainer at krugs.de  Thu Jun 11 12:54:28 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 11 Jun 2015 12:54:28 +0200
Subject: [R] Issue with mcapply
In-Reply-To: <CAN2HEGRQqyhcDezhYk=Ht5Zd1NGKK9N8kpbg48p6wOWKuwdueg@mail.gmail.com>
	(AROONALOK PYNE's message of "Thu, 11 Jun 2015 15:49:23 +0530")
References: <CAN2HEGQbYmc340bDgHTfzMRSU0CaikgXWBZRhhu=CKcjT9gjOQ@mail.gmail.com>
	<m28ubq4or8.fsf@krugs.de>
	<CAN2HEGRgfC03mWVcKY3fGJQHHsezB+55+OoYUJaQFpb_5xMjrA@mail.gmail.com>
	<m2wpza36z6.fsf@krugs.de>
	<CAN2HEGRQqyhcDezhYk=Ht5Zd1NGKK9N8kpbg48p6wOWKuwdueg@mail.gmail.com>
Message-ID: <m2r3pi347v.fsf@krugs.de>


Again: please keep this on r-help!

AROONALOK PYNE <aroonalok.pyne at gmail.com> writes:

> Hi,
>
> My system has 4GB memory. On running htop command on linux terminal,  for
> c(9999999), a() runnnng on single cpu core showed stats for 100% cpu
> utilization. On reaching b(), the entire system hanged (no response and the
> cpu utilization froze at 100%, RAM utilization never crossed 1.5 GB)

Please read up on memory allocation in R. top (and htop) are not
appropriate to see if R has memory or not as vectors need to be
allocated in consecutive blocks.

There have been several questions about this on this list.

Cheers,

Rainer

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 480 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150611/11b243b9/attachment.bin>

From aroonalok.pyne at gmail.com  Thu Jun 11 12:56:19 2015
From: aroonalok.pyne at gmail.com (AROONALOK PYNE)
Date: Thu, 11 Jun 2015 16:26:19 +0530
Subject: [R] Issue with mcapply
In-Reply-To: <m2r3pi347v.fsf@krugs.de>
References: <CAN2HEGQbYmc340bDgHTfzMRSU0CaikgXWBZRhhu=CKcjT9gjOQ@mail.gmail.com>
	<m28ubq4or8.fsf@krugs.de>
	<CAN2HEGRgfC03mWVcKY3fGJQHHsezB+55+OoYUJaQFpb_5xMjrA@mail.gmail.com>
	<m2wpza36z6.fsf@krugs.de>
	<CAN2HEGRQqyhcDezhYk=Ht5Zd1NGKK9N8kpbg48p6wOWKuwdueg@mail.gmail.com>
	<m2r3pi347v.fsf@krugs.de>
Message-ID: <CAN2HEGRkGmC4d6O=NMWDT+5DshhGWo13E5gTf-w6NcS7ppJZmQ@mail.gmail.com>

Thanks a lot Rainer

On Thu, Jun 11, 2015 at 4:24 PM, Rainer M Krug <Rainer at krugs.de> wrote:

>
> Again: please keep this on r-help!
>
> AROONALOK PYNE <aroonalok.pyne at gmail.com> writes:
>
> > Hi,
> >
> > My system has 4GB memory. On running htop command on linux terminal,  for
> > c(9999999), a() runnnng on single cpu core showed stats for 100% cpu
> > utilization. On reaching b(), the entire system hanged (no response and
> the
> > cpu utilization froze at 100%, RAM utilization never crossed 1.5 GB)
>
> Please read up on memory allocation in R. top (and htop) are not
> appropriate to see if R has memory or not as vectors need to be
> allocated in consecutive blocks.
>
> There have been several questions about this on this list.
>
> Cheers,
>
> Rainer
>
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
> Biology, UCT), Dipl. Phys. (Germany)
>
> Centre of Excellence for Invasion Biology
> Stellenbosch University
> South Africa
>
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
>
> Fax (D):    +49 - (0)3 21 21 25 22 44
>
> email:      Rainer at krugs.de
>
> Skype:      RMkrug
>
> PGP: 0x0F52F982
>



-- 
*AROONALOK PYNE*

BE Graduate
Department Of Computer Science And Engineering
Jadavpur University, Kolkata-32
India

	[[alternative HTML version deleted]]


From shivibhatia at ymail.com  Thu Jun 11 13:11:11 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Thu, 11 Jun 2015 04:11:11 -0700 (PDT)
Subject: [R] Summarizing data based on Date
In-Reply-To: <1521260860C.00001072jrkrideau@inbox.com>
References: <1433750889045-4708328.post@n4.nabble.com>
	<1433915507567-4708423.post@n4.nabble.com>
	<1521260860C.00001072jrkrideau@inbox.com>
Message-ID: <1434021071791-4708500.post@n4.nabble.com>

Thank you John for spending time on this query and helping out.

It really helped me and finally i am able to achieve the desired results.
Thanks a ton to all others as well to spending time and furbishing solution.

Regards, Shivi



--
View this message in context: http://r.789695.n4.nabble.com/Summarizing-data-based-on-Date-tp4708328p4708500.html
Sent from the R help mailing list archive at Nabble.com.


From rkoenker at illinois.edu  Thu Jun 11 15:33:28 2015
From: rkoenker at illinois.edu (Roger Koenker)
Date: Thu, 11 Jun 2015 08:33:28 -0500
Subject: [R] Quantile regression model with nonparametric effect and
	interaction
In-Reply-To: <44082572115f485cae9b52473dc193ad@CITESHT2.ad.uillinois.edu>
References: <44082572115f485cae9b52473dc193ad@CITESHT2.ad.uillinois.edu>
Message-ID: <2758B1C2-E004-45EF-9BF9-78F2890784F6@illinois.edu>

The main effect trend seems rather dangerous,  why not just estimate the f?s in a loop?

url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Urbana, IL 61801


> On Jun 11, 2015, at 1:57 AM, Waltl, Sofie (sofie.waltl at uni-graz.at) <sofie.waltl at uni-graz.at> wrote:
> 
> Dear all,
> 
> I would like to estimate a quantile regression model including a bivariate nonparametric term which should be interacted with a dummy variable, i.e.,
> log p ~ year + f(a,b):year.
> I tried to use Roger Koenker's quantreg package and the functions rqss and qss but it turns out that interactions are not possible in this setting. Also weights are not implemented yet to build a work-around. I am looking for something like the by-statement in Simon Wood's package mgcv. Does anything comparable exist?
> I am grateful for any help on this issue.
> 
> Kind regards,
> S. Waltl
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From therneau at mayo.edu  Thu Jun 11 15:44:47 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 11 Jun 2015 08:44:47 -0500
Subject: [R] Different behavior of model.matrix between R 3.2 and R3.1.1
Message-ID: <2f3a88$qka42@ironport10.mayo.edu>

Frank,
   I'm not sure what is going on.  The following test function works for me in both 3.1.1 
and 3.2, i.e, the second model matrix has fewer columns.  As I indicated to you earlier, 
the coxph code removes the strata() columns after creating X because I found it easier to 
correctly create the assign attribute.

   Can you create a worked example?

require(survival)
testfun <- function(formula, data) {
     tform <- terms(formula, specials="strata")
     mf <- model.frame(tform, data)

     terms2 <- terms(mf)
     strat <- untangle.specials(terms2, "strata")
     if (length(strat$terms)) terms2 <- terms2[-strat$terms]
     X <- model.matrix(terms2, mf)
     X
}

tdata <- data.frame(y= 1:10, zed = 1:10, grp = factor(c(1,1,1,2,2,2,1,1,3,3)))

testfun(y ~ zed*grp, tdata)

testfun(y ~ strata(grp)*zed, tdata)


Terry T.

----- original message --

For building design matrices for Cox proportional hazards models in the
cph function in the rms package I have always used this construct:

Terms <- terms(formula, specials=c("strat", "cluster", "strata"), data=data)
specials <- attr(Terms, 'specials')
stra    <- specials$strat
Terms.ns     <- Terms
      if(length(stra)) {
        temp <- untangle.specials(Terms.ns, "strat", 1)
        Terms.ns <- Terms.ns[- temp$terms]    #uses [.terms function
      }
X <- model.matrix(Terms.ns, X)[, -1, drop=FALSE]

The Terms.ns logic removes stratification factor "main effects" so that
if a stratification factor interacts with a non-stratification factor,
only the interaction terms are included, not the strat. factor main
effects. [In a Cox PH model stratification goes into the nonparametric
survival curve part of the model].

Lately this logic quit working; model.matrix keeps the unneeded main
effects in the design matrix.  Does anyone know what changed in R that
could have caused this, and possibly a workaround?


-------


From drjimlemon at gmail.com  Thu Jun 11 11:06:33 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 11 Jun 2015 19:06:33 +1000
Subject: [R] graphs, need urgent help (deadline :( )
In-Reply-To: <D0CC263E-8762-4723-9A24-E5EA3B72BC8B@uw.edu>
References: <fe94928e-a651-4e9f-9643-73635938c694@u.washington.edu>
	<1535ce35a5d.00001088jrkrideau@inbox.com>
	<8c64a81b-ab10-42af-82dc-752ca2d7ece0@u.washington.edu>
	<10c1b087-6721-44b2-a347-851219672d30@gmail.com>
	<ec24a80a-5013-4ed3-8b5a-a41b1e54ad62@u.washington.edu>
	<fd7328fb-306e-47a7-b0ac-a4eac0b8aef0@gmail.com>
	<d2fd6c5d-e38b-4317-9ffa-6cfa6aa0d20e@gmail.com>
	<c77f744d-5a89-4ac7-8dfe-9073a33c3bef@gmail.com>
	<1B877ADDFBA.00000691jrkrideau@inbox.com>
	<D0CC263E-8762-4723-9A24-E5EA3B72BC8B@uw.edu>
Message-ID: <CA+8X3fU9kCH6yW=kTPGXgzzphAMqScxV0DCbR1rWZzHWVdim4Q@mail.gmail.com>

Rosa Oliveira wrote:

> Dear Jim,
>
> when I run your code (even the one you send me, not in my data), I get:
>
> Don't know how to automatically pick scale for object of type function. Defaulting to continuous
> Error in data.frame(x = c(0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1,  :
>  arguments imply differing number of rows: 24, 0

Well, let's agree on the data first. Using your original dataset:

my.data<-read.table(text="region sample factora factorb factorc
 0.1  10      0.895   0.903   0.378
 0.2  10      0.811   0.865   0.688
 0.1  20      0.735   0.966   0.611
 0.2  20      0.777   0.732   0.653
 0.1  30      0.600   0.778   0.694
 0.2  30      0.466   174.592 0.461
 0.1  40      0.446   0.432   0.693
 0.2  40      0.392   0.294   0.686",header=TRUE)
library(plotrix)
par(tcl=-0.1)
gap.plot(x=rep(seq(10,45,by=5),3),
 y=unlist(my.data[,c("factora","factorb","factorc")]),
 main="A plot of factorial mystery",
 gap=c(1.1,174),ylim=c(0,175),ylab="factor score",xlab="Group",
 xticlab=c(" \n0.1\n10"," \n0.2\n10"," \n0.1\n20"," \n0.2\n20",
  " \n0.1\n30"," \n0.2\n30"," \n0.1\n40"," \n0.2\n40"),
 ytics=c(0,0.5,1,174.59),pch=rep(1:3,each=8),col=rep(c(4,2,3),each=8))
mtext(c("Region","Sample"),side=1,at=6,line=c(0,1))
lines(seq(10,45,by=5),my.data$factora,col=4)
lines(seq(10,45,by=5),my.data$factorb[c(1:5,NA,7,8)],col=2)
lines(seq(10,45,by=5),my.data$factorc,col=3)
legend(18,1.8,c("factora","factorb","factorc"),pch=1:3,col=c(4,2,3))

This produces a plot, and I realize that it is not the one you
describe. As before, if you can let us know what is wrong with it,
maybe we can fix it.

Jim


From kris.singh at research.uwa.edu.au  Thu Jun 11 13:20:46 2015
From: kris.singh at research.uwa.edu.au (Kris Singh)
Date: Thu, 11 Jun 2015 19:20:46 +0800
Subject: [R] Boxplot function error-help required
Message-ID: <CAHXci1b7zrJt2Wt_wW3ZQCCD5PZ8-C=SQMa+x8=xDa0MynFLDw@mail.gmail.com>

Dear Sirm/Madam,

Just wondering if someone could help me.  I've tried running a code on R
and the code includes the following:

> Boxplot(~Acc_S$Acc, label=Acc_S$Subj)

But I receive the following  error message:

*Error: could not find function "Boxplot"*

I have tried installing all the packages but keep getting teh same error
message.  The code runs on my supervisors R program and produces a boxplot,
but doesn't on mine and am wondering if someone could assist me.

Thanks in advance,
Kris

-- 
*Kris Singh*
Provisional Psychologist

MPsych (Clinical Neuropsychology) / PhD Candidate
Sanders Building, Room 1.10
University of Western Australia
35 Stirling Highway
Crawley WA 6009

Phone: (08) 6488 1418
Email: kris.singh at research.uwa.edu.au

	[[alternative HTML version deleted]]


From king.s.t.0123 at gmail.com  Thu Jun 11 14:53:58 2015
From: king.s.t.0123 at gmail.com (Steven King)
Date: Thu, 11 Jun 2015 13:53:58 +0100
Subject: [R] poLCA - Latent Class Analysis - How long should analysis take?
Message-ID: <CAJg6zQxpV_t4ufp0AWto7FEDT2LsQ7RPqkeiuea8OCY6=qZcLg@mail.gmail.com>

This is the script i am working from.

library(poLCA) f <-
cbind(bq70,bq72_1,bq72_2,bq72_3,bq72_4,bq72_5,bq72_6,bq72_7,bq73a_1,bq73a_2,bq73a_3,bq73a_4)~
zq88+zq89+dm_zq101_2+dm_zq101_3+dm_zq101_4+dm_zq101_5+dm_zq101_6+dm_zq101_7+dm_zq101_8+dm_zq101_9
for(i in 2:14){max_II<--1000000 min_bic<-100000 for(j in 1:1024){
res<-poLCA(f,BESDATA,nclass=i,maxiter =1000,tol =
1e-5,na.rm=FALSE,probs.start=NULL,nrep=1,verbose=TRUE,calc.se=TRUE) if(res
bic<min_bic){min_bic<-resbic LCA_best_model<-res} }}

I would like to perform a latent class analysis, and also with a
regression. However, the above code takes my pc a very long time to
complete (intel core i5 4690k, 16gb ram).

Is it typical for poLCA to take this long?

Also, is there a line of code that I can use that will stop the loops for
each class once global maximum likelihood has been reached?

N = around 2000.

Thanks!

(very new to R) I use R studio by the way, in case it matters!

	[[alternative HTML version deleted]]


From sofie.waltl at uni-graz.at  Thu Jun 11 16:05:57 2015
From: sofie.waltl at uni-graz.at (Waltl, Sofie (sofie.waltl@uni-graz.at))
Date: Thu, 11 Jun 2015 16:05:57 +0200
Subject: [R] Quantile regression model with nonparametric effect and
 interaction
In-Reply-To: <2758B1C2-E004-45EF-9BF9-78F2890784F6@illinois.edu>
References: <44082572115f485cae9b52473dc193ad@CITESHT2.ad.uillinois.edu>
	<2758B1C2-E004-45EF-9BF9-78F2890784F6@illinois.edu>
Message-ID: <9BC4D2B513C5954687686E9681FDB25719E1D35166@ARTEMIS.pers.ad.uni-graz.at>

The idea is to move from regional dummies interacted with time dummies (model 1) to a smooth spline (defined on longitudes and latitudes) interacted with time dummies (model 2), i.e.,

Model 1: Log p ~ X\beta + REGION*YEAR
Model 2: Log p ~ X\beta + f(long, lat)*YEAR

Estimating the f's in a loop therefore does not really help...

-----Original Message-----
From: Roger Koenker [mailto:rkoenker at illinois.edu] 
Sent: Donnerstag, 11. Juni 2015 15:33
To: Waltl, Sofie (sofie.waltl at uni-graz.at)
Cc: r-help at r-project.org
Subject: Re: [R] Quantile regression model with nonparametric effect and interaction

The main effect trend seems rather dangerous,  why not just estimate the f's in a loop?

url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Urbana, IL 61801


> On Jun 11, 2015, at 1:57 AM, Waltl, Sofie (sofie.waltl at uni-graz.at) <sofie.waltl at uni-graz.at> wrote:
> 
> Dear all,
> 
> I would like to estimate a quantile regression model including a 
> bivariate nonparametric term which should be interacted with a dummy variable, i.e., log p ~ year + f(a,b):year.
> I tried to use Roger Koenker's quantreg package and the functions rqss and qss but it turns out that interactions are not possible in this setting. Also weights are not implemented yet to build a work-around. I am looking for something like the by-statement in Simon Wood's package mgcv. Does anything comparable exist?
> I am grateful for any help on this issue.
> 
> Kind regards,
> S. Waltl
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bharath-bhushan.damodaran at irisa.fr  Thu Jun 11 16:05:26 2015
From: bharath-bhushan.damodaran at irisa.fr (bharath)
Date: Thu, 11 Jun 2015 07:05:26 -0700 (PDT)
Subject: [R] Problem in ksvm prediction
Message-ID: <1434031526611-4708504.post@n4.nabble.com>

Dear all,

I am using ksvm in R for SVM classification. I trained the SVM classifier
with prob.model=TRUE. I have the two following outputs when I predicted.

1) label<-predict(model, TestData)
         I have classification accuracy about 93%, where as in another mode

2) Probvalues<-predict(model, TestData, type="probabilities")
    label<-max.col(Probvalues)

      I have the classification accuracy of 74%.

 I don't why there is a difference in two modes. It will be better if have
predict probability scores also for me.

Please let me know how to rectify the error or what could be the reason for
this difference?

Thanks in Advance

With Regards

Bharath Bhushan D



--
View this message in context: http://r.789695.n4.nabble.com/Problem-in-ksvm-prediction-tp4708504.html
Sent from the R help mailing list archive at Nabble.com.


From gabinpierlot at yahoo.fr  Thu Jun 11 17:05:34 2015
From: gabinpierlot at yahoo.fr (Pierlot Gabin)
Date: Thu, 11 Jun 2015 15:05:34 +0000 (UTC)
Subject: [R] Problem with Volcanoplot
Message-ID: <764586656.1978066.1434035134024.JavaMail.yahoo@mail.yahoo.com>

Hi all,?
I have a data frame composed by 25 numerical variables. I want to do a Spearman Correlation Volcano plot (i. e. x = correlation coefficient and y = -log10(p value))
I'm a begginer in R, so how can I do this ?
PS : Sorry for my English, this is not my mother tongue.

Thank you !
	[[alternative HTML version deleted]]


From rmh at temple.edu  Thu Jun 11 17:58:59 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 11 Jun 2015 11:58:59 -0400
Subject: [R] Boxplot function error-help required
In-Reply-To: <CAHXci1b7zrJt2Wt_wW3ZQCCD5PZ8-C=SQMa+x8=xDa0MynFLDw@mail.gmail.com>
References: <CAHXci1b7zrJt2Wt_wW3ZQCCD5PZ8-C=SQMa+x8=xDa0MynFLDw@mail.gmail.com>
Message-ID: <CAGx1TMADh5k+8cS+sek8hQKWRRu70BPPZetoeHD1P9y4P163+w@mail.gmail.com>

R is case sensitive.

try "boxplot" not "Boxplot"

On Thu, Jun 11, 2015 at 7:20 AM, Kris Singh
<kris.singh at research.uwa.edu.au> wrote:
> Dear Sirm/Madam,
>
> Just wondering if someone could help me.  I've tried running a code on R
> and the code includes the following:
>
>> Boxplot(~Acc_S$Acc, label=Acc_S$Subj)
>
> But I receive the following  error message:
>
> *Error: could not find function "Boxplot"*
>
> I have tried installing all the packages but keep getting teh same error
> message.  The code runs on my supervisors R program and produces a boxplot,
> but doesn't on mine and am wondering if someone could assist me.
>
> Thanks in advance,
> Kris
>
> --
> *Kris Singh*
> Provisional Psychologist
>
> MPsych (Clinical Neuropsychology) / PhD Candidate
> Sanders Building, Room 1.10
> University of Western Australia
> 35 Stirling Highway
> Crawley WA 6009
>
> Phone: (08) 6488 1418
> Email: kris.singh at research.uwa.edu.au
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Jun 11 18:16:59 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 11 Jun 2015 09:16:59 -0700
Subject: [R] Problem with Volcanoplot
In-Reply-To: <764586656.1978066.1434035134024.JavaMail.yahoo@mail.yahoo.com>
References: <764586656.1978066.1434035134024.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbRt2H9m4C-_08hc6Ai92pr31d89ky+tLguPS3y=Hp0gwg@mail.gmail.com>

Start by going through an R tutorial or two? You need to do some minimal
homework BEFORE posting here.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Thu, Jun 11, 2015 at 8:05 AM, Pierlot Gabin <gabinpierlot at yahoo.fr>
wrote:

> Hi all,
> I have a data frame composed by 25 numerical variables. I want to do a
> Spearman Correlation Volcano plot (i. e. x = correlation coefficient and y
> = -log10(p value))
> I'm a begginer in R, so how can I do this ?
> PS : Sorry for my English, this is not my mother tongue.
>
> Thank you !
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Thu Jun 11 22:44:30 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 11 Jun 2015 12:44:30 -0800
Subject: [R] Problem with Volcanoplot
In-Reply-To: <764586656.1978066.1434035134024.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <25B7EA8113B.00001451jrkrideau@inbox.com>

Do you already have an R package that will do a  Spearman
Correlation Volcano plot ?

What do the data look like?

Have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html
for some suggestions on how to ask a question on the R-help list.


Welcome to R and the R-help list.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: gabinpierlot at yahoo.fr
> Sent: Thu, 11 Jun 2015 15:05:34 +0000 (UTC)
> To: r-help at r-project.org
> Subject: [R] Problem with Volcanoplot
> 
> Hi all,
> I have a data frame composed by 25 numerical variables. I want to do a
> Spearman Correlation Volcano plot (i. e. x = correlation coefficient and
> y = -log10(p value))
> I'm a begginer in R, so how can I do this ?
> PS : Sorry for my English, this is not my mother tongue.
> 
> Thank you !
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jrkrideau at inbox.com  Thu Jun 11 23:19:04 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 11 Jun 2015 13:19:04 -0800
Subject: [R] Boxplot function error-help required
In-Reply-To: <CAHXci1b7zrJt2Wt_wW3ZQCCD5PZ8-C=SQMa+x8=xDa0MynFLDw@mail.gmail.com>
Message-ID: <2605303544E.000014E6jrkrideau@inbox.com>

Well it might have worked for your supervisor but I don't see how.  

As was mentioned it is boxplot , not Boxplot and the rest of the syntax looks dodgy to say the least.

Try 
boxplot(Acc_S$Subj ~ Acc_S$Acc)

I don't see how label = will work , ?boxplot says it should be names = and as the code stands even that would be redundant.  

In any case here is a quick and dirty example that seems to work. 

 dat1  <-  data.frame(aa = sample(letters[1:4], 20, replace = TRUE), bb = rnorm(20), cc = rnorm(20) )
boxplot(dat1$bb~ dat1$aa, names = c("alpha", "beta", "gamma", "delta"))


Have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html
 for some suggestions on how to ask questions here.

Good luck



John Kane
Kingston ON Canada


> -----Original Message-----
> From: kris.singh at research.uwa.edu.au
> Sent: Thu, 11 Jun 2015 19:20:46 +0800
> To: r-help at r-project.org
> Subject: [R] Boxplot function error-help required
> 
> Dear Sirm/Madam,
> 
> Just wondering if someone could help me.  I've tried running a code on R
> and the code includes the following:
> 
>> Boxplot(~Acc_S$Acc, label=Acc_S$Subj)
> 
> But I receive the following  error message:
> 
> *Error: could not find function "Boxplot"*
> 
> I have tried installing all the packages but keep getting teh same error
> message.  The code runs on my supervisors R program and produces a
> boxplot,
> but doesn't on mine and am wondering if someone could assist me.
> 
> Thanks in advance,
> Kris
> 
> --
> *Kris Singh*
> Provisional Psychologist
> 
> MPsych (Clinical Neuropsychology) / PhD Candidate
> Sanders Building, Room 1.10
> University of Western Australia
> 35 Stirling Highway
> Crawley WA 6009
> 
> Phone: (08) 6488 1418
> Email: kris.singh at research.uwa.edu.au
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From macqueen1 at llnl.gov  Thu Jun 11 23:44:39 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 11 Jun 2015 21:44:39 +0000
Subject: [R] Boxplot function error-help required
In-Reply-To: <CAHXci1b7zrJt2Wt_wW3ZQCCD5PZ8-C=SQMa+x8=xDa0MynFLDw@mail.gmail.com>
References: <CAHXci1b7zrJt2Wt_wW3ZQCCD5PZ8-C=SQMa+x8=xDa0MynFLDw@mail.gmail.com>
Message-ID: <D19F4E48.12DDBA%macqueen1@llnl.gov>

In addition to the other answers, I would suggest that the next time you
get the "could not find function" message, try like this:

 help.search('Boxplot')

Among the output from that you should see

  graphics::boxplot                         Box Plots

which should lead you to "boxplot" instead of "Boxplot".


You may see considerably more output from help.search(), depending on what
packages you have installed. For example, when I did it, I found that the
car package has a function named "Boxplot".

-Don


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/11/15, 4:20 AM, "Kris Singh" <kris.singh at research.uwa.edu.au> wrote:

>Dear Sirm/Madam,
>
>Just wondering if someone could help me.  I've tried running a code on R
>and the code includes the following:
>
>> Boxplot(~Acc_S$Acc, label=Acc_S$Subj)
>
>But I receive the following  error message:
>
>*Error: could not find function "Boxplot"*
>
>I have tried installing all the packages but keep getting teh same error
>message.  The code runs on my supervisors R program and produces a
>boxplot,
>but doesn't on mine and am wondering if someone could assist me.
>
>Thanks in advance,
>Kris
>
>-- 
>*Kris Singh*
>Provisional Psychologist
>
>MPsych (Clinical Neuropsychology) / PhD Candidate
>Sanders Building, Room 1.10
>University of Western Australia
>35 Stirling Highway
>Crawley WA 6009
>
>Phone: (08) 6488 1418
>Email: kris.singh at research.uwa.edu.au
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Jun 12 00:00:59 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 11 Jun 2015 15:00:59 -0700
Subject: [R] Boxplot function error-help required
In-Reply-To: <2605303544E.000014E6jrkrideau@inbox.com>
References: <2605303544E.000014E6jrkrideau@inbox.com>
Message-ID: <DDF8D46C-6DD2-4279-8F4A-FD501F4CB2AF@comcast.net>


On Jun 11, 2015, at 2:19 PM, John Kane wrote:

> Well it might have worked for your supervisor but I don't see how.  
> 
> As was mentioned it is boxplot , not Boxplot and the rest of the syntax looks dodgy to say the least.

There is a "Boxplot" function in package 'car' and it has a labels argument which would be partially matched by a label argument, since it precedes the dots in the arglist.

So I would try this:


library(car)
Boxplot(~Acc_S$Acc, label=Acc_S$Subj)

-- 
David.

> 
> Try 
> boxplot(Acc_S$Subj ~ Acc_S$Acc)
> 
> I don't see how label = will work , ?boxplot says it should be names = and as the code stands even that would be redundant.  
> 
> In any case here is a quick and dirty example that seems to work. 
> 
> dat1  <-  data.frame(aa = sample(letters[1:4], 20, replace = TRUE), bb = rnorm(20), cc = rnorm(20) )
> boxplot(dat1$bb~ dat1$aa, names = c("alpha", "beta", "gamma", "delta"))
> 
> 
> Have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html
> for some suggestions on how to ask questions here.
> 
> Good luck
> 
> 
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: kris.singh at research.uwa.edu.au
>> Sent: Thu, 11 Jun 2015 19:20:46 +0800
>> To: r-help at r-project.org
>> Subject: [R] Boxplot function error-help required
>> 
>> Dear Sirm/Madam,
>> 
>> Just wondering if someone could help me.  I've tried running a code on R
>> and the code includes the following:
>> 
>>> Boxplot(~Acc_S$Acc, label=Acc_S$Subj)
>> 
>> But I receive the following  error message:
>> 
>> *Error: could not find function "Boxplot"*
>> 
>> I have tried installing all the packages but keep getting teh same error
>> message.  The code runs on my supervisors R program and produces a
>> boxplot,
>> but doesn't on mine and am wondering if someone could assist me.
>> 
>> Thanks in advance,
>> Kris
>> 
>> --
>> *Kris Singh*
>> Provisional Psychologist
>> 
>> MPsych (Clinical Neuropsychology) / PhD Candidate
>> Sanders Building, Room 1.10
>> University of Western Australia
>> 35 Stirling Highway
>> Crawley WA 6009
>> 
>> Phone: (08) 6488 1418
>> Email: kris.singh at research.uwa.edu.au
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
> Visit http://www.inbox.com/photosharing to find out more!
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jfox at mcmaster.ca  Fri Jun 12 00:02:59 2015
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 11 Jun 2015 18:02:59 -0400
Subject: [R] powerTransform Convergence erro
In-Reply-To: <B52488DF-8C40-4BA9-9362-117DC7127816@gmail.com>
References: <01884BF7-08ED-48E8-9DBD-9F2C4E97EE2A@gmail.com>
	<web-562686486@cgpsrv2.cis.mcmaster.ca>
	<B52488DF-8C40-4BA9-9362-117DC7127816@gmail.com>
Message-ID: <web-562814187@cgpsrv2.cis.mcmaster.ca>

Dear Brittany,

There is an essentially perfect linear dependency among the variables in your data (note the last eigenvalue, which is 0 within rounding error):

> eigen(cor(problem.data.boxcox[,-1]), only.values=TRUE)
$values
 [1]  3.644257e+00  1.821582e+00  1.712152e+00  1.205091e+00  1.007231e+00  9.231163e-01  9.048724e-01
 [8]  8.718398e-01  8.379187e-01  7.371353e-01  6.334100e-01  5.235629e-01  4.757997e-01  4.246831e-01
[15]  2.773471e-01 -2.802502e-16

In addition, some of your variables have many tied values at the bottom of their distributions, making them very poor candidates for normalizing power transformations; for example,

> sum(problem.data.boxcox$variable2 == 1)
[1] 626

I hope this helps,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
	
	

On Thu, 11 Jun 2015 09:37:57 -0600
 Brittany Demmitt <demmitba at gmail.com> wrote:
> Hi John,
> 
> Thank you so much for the info!  I have attached the data in .csv format that is giving me the warning along with the command that I am running.  It i a data frame with 1510 sample IDs and then their values for 16 variables.  I am trying to transform the 16 variables.  I do not receive the warning when I run each variable independently, just when I run the entire dataframe at once.  However, I have run this command with other larger data frames all at once with no warnings, so I am not sure why it is not working now.
> 
> Any help is appreciated!  Thanks! :-)
> 
> Britt
> 
> Commands Run:
> 
> #read in the data frame
> problem.data.boxcox <- read.csv(?problem.data.boxcox.csv")
> 
> #run a power transformation  (I do not run that on the first column because it is just sample ids)
> 
> problem.data.boxcox.pT <- powerTransform(problem.data.boxcox[,-1])
> 
> Warning message:
> In estimateTransform(x, y, NULL, ...) :
>   Convergence failure: return code = 1
> 
> 
> 
> 
> 
> 
> 
> 
> 
> > On Jun 10, 2015, at 2:15 PM, John Fox <jfox at mcmaster.ca> wrote:
> > 
> > Dear Brittany,
> > 
> > As explained in ?powerTransform, this function uses optim() to optimize a generalized Box-Cox criterion. For explanation of return codes, see ?optim. 
> > 
> > In particular, code 1 indicates that the maximum number of iterations was exceeded. Although you might try increasing the permitted number of iterations or otherwise tweaking the arguments to optim(), your problem is probably ill-conditioned in some manner that is impossible to know without more information, such as your data.
> > 
> > I hope this helps,
> > John
> > 
> > ------------------------------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario, Canada
> > http://socserv.mcmaster.ca/jfox/
> > 	
> > 
> > On Wed, 10 Jun 2015 10:54:30 -0600
> > Brittany Demmitt <demmitba at gmail.com> wrote:
> >> Hello,
> >> 
> >> I am trying to use the powerTransform function in the package car to identify the lambda: transform my data.  However, I receive the following warning:
> >> 
> >> Warning message:
> >> In estimateTransform(x, y, NULL, ...) :
> >>  Convergence failure: return code = 1
> >> 
> >> I can not find a description of what return code =1  means for the car package.  How do I look that up, or does anyone know what the warning means?
> >> 
> >> Thank you so much!
> >> 
> >> Brittany
> >> 	[[alternative HTML version deleted]]
> >> 
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> > 
> > 
> > 	
> > 	
>


From dwinsemius at comcast.net  Fri Jun 12 00:05:36 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 11 Jun 2015 15:05:36 -0700
Subject: [R] Boxplot function error-help required
In-Reply-To: <D19F4E48.12DDBA%macqueen1@llnl.gov>
References: <CAHXci1b7zrJt2Wt_wW3ZQCCD5PZ8-C=SQMa+x8=xDa0MynFLDw@mail.gmail.com>
	<D19F4E48.12DDBA%macqueen1@llnl.gov>
Message-ID: <56FE720E-96F2-4687-B3DE-136A114C52D3@comcast.net>


On Jun 11, 2015, at 2:44 PM, MacQueen, Don wrote:

> In addition to the other answers, I would suggest that the next time you
> get the "could not find function" message, try like this:
> 
> help.search('Boxplot')

 Spencer Graves uses RSiteSearch() as the underlying function for sos::findFn

-- 
David.
> 
> Among the output from that you should see
> 
>  graphics::boxplot                         Box Plots
> 
> which should lead you to "boxplot" instead of "Boxplot".
> 
> 
> You may see considerably more output from help.search(), depending on what
> packages you have installed. For example, when I did it, I found that the
> car package has a function named "Boxplot".
> 
> -Don
> 
> 
> -- 
> Don MacQueen
> 
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> 
> 
> 
> 
> 
> On 6/11/15, 4:20 AM, "Kris Singh" <kris.singh at research.uwa.edu.au> wrote:
> 
>> Dear Sirm/Madam,
>> 
>> Just wondering if someone could help me.  I've tried running a code on R
>> and the code includes the following:
>> 
>>> Boxplot(~Acc_S$Acc, label=Acc_S$Subj)
>> 
>> But I receive the following  error message:
>> 
>> *Error: could not find function "Boxplot"*
>> 
>> I have tried installing all the packages but keep getting teh same error
>> message.  The code runs on my supervisors R program and produces a
>> boxplot,
>> but doesn't on mine and am wondering if someone could assist me.
>> 
>> Thanks in advance,
>> Kris
>> 
>> -- 
>> *Kris Singh*
>> Provisional Psychologist
>> 
>> MPsych (Clinical Neuropsychology) / PhD Candidate
>> Sanders Building, Room 1.10
>> University of Western Australia
>> 35 Stirling Highway
>> Crawley WA 6009
>> 
>> Phone: (08) 6488 1418
>> Email: kris.singh at research.uwa.edu.au
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From demmitba at gmail.com  Fri Jun 12 00:12:05 2015
From: demmitba at gmail.com (Brittany Demmitt)
Date: Thu, 11 Jun 2015 16:12:05 -0600
Subject: [R] powerTransform Convergence erro
In-Reply-To: <web-562814187@cgpsrv2.cis.mcmaster.ca>
References: <01884BF7-08ED-48E8-9DBD-9F2C4E97EE2A@gmail.com>
	<web-562686486@cgpsrv2.cis.mcmaster.ca>
	<B52488DF-8C40-4BA9-9362-117DC7127816@gmail.com>
	<web-562814187@cgpsrv2.cis.mcmaster.ca>
Message-ID: <37ED0E56-7C92-405D-B8AC-023EEC3A1B1C@gmail.com>

Hi John,

That does help, thanks!

Brittany


> On Jun 11, 2015, at 4:02 PM, John Fox <jfox at mcmaster.ca> wrote:
> 
> Dear Brittany,
> 
> There is an essentially perfect linear dependency among the variables in your data (note the last eigenvalue, which is 0 within rounding error):
> 
>> eigen(cor(problem.data.boxcox[,-1]), only.values=TRUE)
> $values
> [1]  3.644257e+00  1.821582e+00  1.712152e+00  1.205091e+00  1.007231e+00  9.231163e-01  9.048724e-01
> [8]  8.718398e-01  8.379187e-01  7.371353e-01  6.334100e-01  5.235629e-01  4.757997e-01  4.246831e-01
> [15]  2.773471e-01 -2.802502e-16
> 
> In addition, some of your variables have many tied values at the bottom of their distributions, making them very poor candidates for normalizing power transformations; for example,
> 
>> sum(problem.data.boxcox$variable2 == 1)
> [1] 626
> 
> I hope this helps,
> John
> 
> ------------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox/
> 	
> 	
> 
> On Thu, 11 Jun 2015 09:37:57 -0600
> Brittany Demmitt <demmitba at gmail.com> wrote:
>> Hi John,
>> 
>> Thank you so much for the info!  I have attached the data in .csv format that is giving me the warning along with the command that I am running.  It i a data frame with 1510 sample IDs and then their values for 16 variables.  I am trying to transform the 16 variables.  I do not receive the warning when I run each variable independently, just when I run the entire dataframe at once.  However, I have run this command with other larger data frames all at once with no warnings, so I am not sure why it is not working now.
>> 
>> Any help is appreciated!  Thanks! :-)
>> 
>> Britt
>> 
>> Commands Run:
>> 
>> #read in the data frame
>> problem.data.boxcox <- read.csv(?problem.data.boxcox.csv")
>> 
>> #run a power transformation  (I do not run that on the first column because it is just sample ids)
>> 
>> problem.data.boxcox.pT <- powerTransform(problem.data.boxcox[,-1])
>> 
>> Warning message:
>> In estimateTransform(x, y, NULL, ...) :
>>  Convergence failure: return code = 1
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>>> On Jun 10, 2015, at 2:15 PM, John Fox <jfox at mcmaster.ca> wrote:
>>> 
>>> Dear Brittany,
>>> 
>>> As explained in ?powerTransform, this function uses optim() to optimize a generalized Box-Cox criterion. For explanation of return codes, see ?optim. 
>>> 
>>> In particular, code 1 indicates that the maximum number of iterations was exceeded. Although you might try increasing the permitted number of iterations or otherwise tweaking the arguments to optim(), your problem is probably ill-conditioned in some manner that is impossible to know without more information, such as your data.
>>> 
>>> I hope this helps,
>>> John
>>> 
>>> ------------------------------------------------
>>> John Fox, Professor
>>> McMaster University
>>> Hamilton, Ontario, Canada
>>> http://socserv.mcmaster.ca/jfox/
>>> 	
>>> 
>>> On Wed, 10 Jun 2015 10:54:30 -0600
>>> Brittany Demmitt <demmitba at gmail.com> wrote:
>>>> Hello,
>>>> 
>>>> I am trying to use the powerTransform function in the package car to identify the lambda: transform my data.  However, I receive the following warning:
>>>> 
>>>> Warning message:
>>>> In estimateTransform(x, y, NULL, ...) :
>>>> Convergence failure: return code = 1
>>>> 
>>>> I can not find a description of what return code =1  means for the car package.  How do I look that up, or does anyone know what the warning means?
>>>> 
>>>> Thank you so much!
>>>> 
>>>> Brittany
>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 	
>>> 	
>> 
> 
> 	


From david.wagle at gmail.com  Thu Jun 11 18:31:15 2015
From: david.wagle at gmail.com (David Wagle)
Date: Thu, 11 Jun 2015 11:31:15 -0500
Subject: [R] Getting XML Data From Sharepoint
Message-ID: <CAJdTJyNY-qJkPcnkhqowDsQZciu5Z1jBapeH0Um_rQWNi1jZOQ@mail.gmail.com>

I'm trying, and so far failing, to extract data from a very large
SharePoint list.

I have a URL for getting XML from sharepoint:

http://
<site>/_vti_bin/owssvr.dll?Cmd=Display&List={GUID}&Query=*&XMLDATA=TRUE

When I do something like the following:

require(XML)
require(RCurl)

URL <- "http://
<site>/_vti_bin/owssvr.dll?Cmd=Display&List={GUID}&Query=*&XMLDATA=TRUE"
data = xmlParse(readLines(URL)


I get an authorization error back:

Error in file(con, "r") : cannot open the connection
In file(con, "r") : cannot open: HTTP status was '401 Unauthorized'

No problem I modifty things to this:

URL <- "http://
<site>/_vti_bin/owssvr.dll?Cmd=Display&List={GUID}&XMLDATA=TRUE"
w <- getURL(URL, userpwd="uname:password")
myDataFrame <- xmlParse(w)
.
.
.

it returns with:

internal error: Huge input lookup
internal error: Huge input lookup
Extra content at the end of the document
....

Help!

Thanks in advance

-- 
David A. Wagle
cell: 952-607-71741
linkedin: http://www.linkedin.com/in/davidwagle/

	[[alternative HTML version deleted]]


From k.kowitski at icloud.com  Thu Jun 11 21:25:55 2015
From: k.kowitski at icloud.com (Kevin Kowitski)
Date: Thu, 11 Jun 2015 19:25:55 +0000 (GMT)
Subject: [R] for loop incorrect row count
Message-ID: <6671f431-794d-471f-96a3-d48fca76aa1b@me.com>

Hey,?

? I am having an issue with a for loop that is intended to read index values by row and column so that it can pull out the valuable information. ?My issue is that I am using a data.frame(which(df==1, arr.ind=TRUE)) to find the index of the values in my data frame that are equal to 1. ?This outputs a data frame of 71 rows which is confirmed by the "nrows" function. ?However, when I try to break up the rows and columns using the code below I am producing two vectors of 75 values, even though there are only 71 and the for loop is from 1 to the value of 71. ?Am I making this task more complicated than it needs to be??

if(countRaw > 0){
			index_R_df<-rbind(index_R_df,data.frame(which(sapply(data2[0:24,], match, INDString, nomatch=0)==1, arr.ind=TRUE)))
			index_lengthR<-nrow(index_R_df)
			
				for (j in 1:index_lengthR){
					index_rowsR<-c(index_rowsR, index_R_df[j,1])
					index_colsR<-c(index_colsR, index_R_df[j,2])
					#rowsPass_R<-c(unique(index_rowsR))
					#collect_rows<-c(collect_rows, rowsPass_R)
					}

I'm sorry if this seems very novice, I'm new to R.?

-Kevin

From hlinder33 at gmail.com  Fri Jun 12 00:05:37 2015
From: hlinder33 at gmail.com (Hannah Linder)
Date: Thu, 11 Jun 2015 15:05:37 -0700
Subject: [R] GAMM - error when using spline smoother,
	only allowed to use tensor product
Message-ID: <CAKqaSd_MNT_DyXrKdXK-ct6qKoFrVaWi0Rs62+H4UhqkbUG4HA@mail.gmail.com>

Hello,

I am familiar with the basics of statistical regression models, including
GAMs, but I am stumped on a particular implementation issue.

I am constructing a GAMM to fit to data that is autocorrelated. On of my
covariates (covariate "4") is a sin function the represents time of day. It
is simply: sin.t <- sin(2*pi*seq(TT)/12), in this case TT is equal to my
number of data points, which is 336.

When I initially created a gamm model for my data, the equation looked as
shown:

gam=gamm(data1~s(covariates[1,],bs="cc")+s(covariates[3,],bs="cs")+s(covariates[4,],bs="cc"),family=gaussian(),correlation
= corARMA(p=2,q=0))

Note: Covariate "1" is a Julian day count, and covariate "3" is tidal range.

No matter how I change anything else about the equation, unless I change
the smoother to a tensor product for covariate 4 (i.e.,
te(covariates[4,])), I receive the following error:

Error in na.fail.default(list(Xr.1 = c(-0.00539071823269798,
0.00735538093451461,  :
  missing values in object
In addition: Warning message:
In sqrt(D) : NaNs produced

Does anyone know what may be going on? In addition, my data fit is much
better when I don't treat the sin covariate as cyclic, but that doesn't
seem appropriate to me, because a sin is naturally cyclic.

Any help is much appreciate, thank-you for your time!

Hannah

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Jun 12 01:48:40 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 11 Jun 2015 16:48:40 -0700
Subject: [R] for loop incorrect row count
In-Reply-To: <6671f431-794d-471f-96a3-d48fca76aa1b@me.com>
References: <6671f431-794d-471f-96a3-d48fca76aa1b@me.com>
Message-ID: <4962A14C-540C-47A1-838D-FC98FD273327@comcast.net>


On Jun 11, 2015, at 12:25 PM, Kevin Kowitski wrote:

> Hey, 
> 
>   I am having an issue with a for loop that is intended to read index values by row and column so that it can pull out the valuable information.  My issue is that I am using a data.frame(which(df==1, arr.ind=TRUE))

That would be coercing a matrix to a dataframe. But why?


> to find the index of the values in my data frame that are equal to 1.  This outputs a data frame of 71 rows which is confirmed by the "nrows" function.  However, when I try to break up the rows and columns using the code below I am producing two vectors of 75 values, even though there are only 71 and the for loop is from 1 to the value of 71.  Am I making this task more complicated than it needs to be? 
> 
> if(countRaw > 0){

How the value of countRow enters into this is entirely unclear.

> 			index_R_df<-rbind( index_R_df, data.frame(which(sapply(data2[0:24,],

R does NOT use zero-based indexing.


> match, INDString, nomatch=0)==1, arr.ind=TRUE)))

You need to explain what you are doing here. It's a bit too obscure to me how we should know that index_R_df will line up with the items would drop out of:

data.frame(which(sapply(data2[0:24,],match, INDString, nomatch=0)==1, arr.ind=TRUE)))

I would have expected some `name` to be followed by `[` then `which(...)`


> 			index_lengthR<-nrow(index_R_df)
> 			
> 				for (j in 1:index_lengthR){
> 					index_rowsR<-c(index_rowsR, index_R_df[j,1])
> 					index_colsR<-c(index_colsR, index_R_df[j,2])
> 					#rowsPass_R<-c(unique(index_rowsR))
> 					#collect_rows<-c(collect_rows, rowsPass_R)
> 					}
> 

There are too many missing here for me to do anything useful. You are either only giving us a fragment of code and using zero based  indexing. Without a data example, I'm throwing it back to you ot someone in the readership with better intuition or imagination than I possess.


> I'm sorry if this seems very novice, I'm new to R. 
> 
> -Kevin
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jrkrideau at inbox.com  Fri Jun 12 01:58:39 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 11 Jun 2015 15:58:39 -0800
Subject: [R] Boxplot function error-help required
In-Reply-To: <D19F4E48.12DDBA%macqueen1@llnl.gov>
References: <cahxci1b7zrjt2wt_ww3zqccd5pz8-c=sqma+x8=xda0mynfldw@mail.gmail.com>
Message-ID: <2769E0FD890.0000009Ajrkrideau@inbox.com>

Thanks Don,

I suspected there was a Boxplot() out there by was too lazy to look.  I still don't see how the original code would work if label only had onevalue but I must admit what Boxplot() is actually doing is still confusing me.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: macqueen1 at llnl.gov
> Sent: Thu, 11 Jun 2015 21:44:39 +0000
> To: kris.singh at research.uwa.edu.au, r-help at r-project.org
> Subject: Re: [R] Boxplot function error-help required
> 
> In addition to the other answers, I would suggest that the next time you
> get the "could not find function" message, try like this:
> 
>  help.search('Boxplot')
> 
> Among the output from that you should see
> 
>   graphics::boxplot                         Box Plots
> 
> which should lead you to "boxplot" instead of "Boxplot".
> 
> 
> You may see considerably more output from help.search(), depending on
> what
> packages you have installed. For example, when I did it, I found that the
> car package has a function named "Boxplot".
> 
> -Don
> 
> 
> --
> Don MacQueen
> 
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> 
> 
> 
> 
> 
> On 6/11/15, 4:20 AM, "Kris Singh" <kris.singh at research.uwa.edu.au> wrote:
> 
> >Dear Sirm/Madam,
>> 
> >Just wondering if someone could help me.  I've tried running a code on R
> >and the code includes the following:
>> 
>>> Boxplot(~Acc_S$Acc, label=Acc_S$Subj)
>> 
> >But I receive the following  error message:
>> 
> >*Error: could not find function "Boxplot"*
>> 
> >I have tried installing all the packages but keep getting teh same error
> >message.  The code runs on my supervisors R program and produces a
> >boxplot,
> >but doesn't on mine and am wondering if someone could assist me.
>> 
> >Thanks in advance,
> >Kris
>> 
> >--
> >*Kris Singh*
> >Provisional Psychologist
>> 
> >MPsych (Clinical Neuropsychology) / PhD Candidate
> >Sanders Building, Room 1.10
> >University of Western Australia
> >35 Stirling Highway
> >Crawley WA 6009
>> 
> >Phone: (08) 6488 1418
> >Email: kris.singh at research.uwa.edu.au
>> 
> >	[[alternative HTML version deleted]]
>> 
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From bgunter.4567 at gmail.com  Fri Jun 12 02:02:58 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 11 Jun 2015 17:02:58 -0700
Subject: [R] for loop incorrect row count
In-Reply-To: <4962A14C-540C-47A1-838D-FC98FD273327@comcast.net>
References: <6671f431-794d-471f-96a3-d48fca76aa1b@me.com>
	<4962A14C-540C-47A1-838D-FC98FD273327@comcast.net>
Message-ID: <CAGxFJbSKCgYQiuRwkR3C4qonMErLLUF36WP121tcXijYxT1XbQ@mail.gmail.com>

Oh, Swami, gazing into the crystal ball one can see ...


;-}

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Thu, Jun 11, 2015 at 4:48 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Jun 11, 2015, at 12:25 PM, Kevin Kowitski wrote:
>
> > Hey,
> >
> >   I am having an issue with a for loop that is intended to read index
> values by row and column so that it can pull out the valuable information.
> My issue is that I am using a data.frame(which(df==1, arr.ind=TRUE))
>
> That would be coercing a matrix to a dataframe. But why?
>
>
> > to find the index of the values in my data frame that are equal to 1.
> This outputs a data frame of 71 rows which is confirmed by the "nrows"
> function.  However, when I try to break up the rows and columns using the
> code below I am producing two vectors of 75 values, even though there are
> only 71 and the for loop is from 1 to the value of 71.  Am I making this
> task more complicated than it needs to be?
> >
> > if(countRaw > 0){
>
> How the value of countRow enters into this is entirely unclear.
>
> >                       index_R_df<-rbind( index_R_df,
> data.frame(which(sapply(data2[0:24,],
>
> R does NOT use zero-based indexing.
>
>
> > match, INDString, nomatch=0)==1, arr.ind=TRUE)))
>
> You need to explain what you are doing here. It's a bit too obscure to me
> how we should know that index_R_df will line up with the items would drop
> out of:
>
> data.frame(which(sapply(data2[0:24,],match, INDString, nomatch=0)==1,
> arr.ind=TRUE)))
>
> I would have expected some `name` to be followed by `[` then `which(...)`
>
>
> >                       index_lengthR<-nrow(index_R_df)
> >
> >                               for (j in 1:index_lengthR){
> >                                       index_rowsR<-c(index_rowsR,
> index_R_df[j,1])
> >                                       index_colsR<-c(index_colsR,
> index_R_df[j,2])
> >                                       #rowsPass_R<-c(unique(index_rowsR))
> >                                       #collect_rows<-c(collect_rows,
> rowsPass_R)
> >                                       }
> >
>
> There are too many missing here for me to do anything useful. You are
> either only giving us a fragment of code and using zero based  indexing.
> Without a data example, I'm throwing it back to you ot someone in the
> readership with better intuition or imagination than I possess.
>
>
> > I'm sorry if this seems very novice, I'm new to R.
> >
> > -Kevin
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Fri Jun 12 02:18:12 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 11 Jun 2015 16:18:12 -0800
Subject: [R] for loop incorrect row count
In-Reply-To: <4962A14C-540C-47A1-838D-FC98FD273327@comcast.net>
References: <6671f431-794d-471f-96a3-d48fca76aa1b@me.com>
Message-ID: <27959313CA2.000000C6jrkrideau@inbox.com>

Hi Kevin,

I don't even pretend to try to read it.  If David is having a problem I am going for tea.

I think we need some sample data (see ?dput for the best way to supply it) and an succinct description in English of what the problem is and what you need to get out of the data. 

I suspect because you are so used to programming in other languages you are jumping into one approach before you should. R can be very weird indeed for those used to working with "sensible" languages.  

Also have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html for some general suggestions about questions on the list etc.

BTW, the reason for using dput()  is that it provides a 'perfect' copy of your data.  Other ways of submitting sample data are less satisfactory. For example I tend to use 1 of 2 ways to read in text data especially if I am just grabbing some data from a problem on R-help and I may read in the data okay if I use one method  or, if for some reason I use the other method I might read in some data as numeric that should be a factor, etc. which makes troubleshooting just a bit difficult.  And which method I use can be a crap shoot. 


John Kane
Kingston ON Canada


> -----Original Message-----
> From: dwinsemius at comcast.net
> Sent: Thu, 11 Jun 2015 16:48:40 -0700
> To: k.kowitski at icloud.com
> Subject: Re: [R] for loop incorrect row count
> 
> 
> On Jun 11, 2015, at 12:25 PM, Kevin Kowitski wrote:
> 
>> Hey,
>> 
>>   I am having an issue with a for loop that is intended to read index
>> values by row and column so that it can pull out the valuable
>> information.  My issue is that I am using a data.frame(which(df==1,
>> arr.ind=TRUE))
> 
> That would be coercing a matrix to a dataframe. But why?
> 
> 
>> to find the index of the values in my data frame that are equal to 1.
>> This outputs a data frame of 71 rows which is confirmed by the "nrows"
>> function.  However, when I try to break up the rows and columns using
>> the code below I am producing two vectors of 75 values, even though
>> there are only 71 and the for loop is from 1 to the value of 71.  Am I
>> making this task more complicated than it needs to be?
>> 
>> if(countRaw > 0){
> 
> How the value of countRow enters into this is entirely unclear.
> 
>> 			index_R_df<-rbind( index_R_df, data.frame(which(sapply(data2[0:24,],
> 
> R does NOT use zero-based indexing.
> 
> 
>> match, INDString, nomatch=0)==1, arr.ind=TRUE)))
> 
> You need to explain what you are doing here. It's a bit too obscure to me
> how we should know that index_R_df will line up with the items would drop
> out of:
> 
> data.frame(which(sapply(data2[0:24,],match, INDString, nomatch=0)==1,
> arr.ind=TRUE)))
> 
> I would have expected some `name` to be followed by `[` then `which(...)`
> 
> 
>> 			index_lengthR<-nrow(index_R_df)
>> 
>> 				for (j in 1:index_lengthR){
>> 					index_rowsR<-c(index_rowsR, index_R_df[j,1])
>> 					index_colsR<-c(index_colsR, index_R_df[j,2])
>> 					#rowsPass_R<-c(unique(index_rowsR))
>> 					#collect_rows<-c(collect_rows, rowsPass_R)
>> 					}
>> 
> 
> There are too many missing here for me to do anything useful. You are
> either only giving us a fragment of code and using zero based  indexing.
> Without a data example, I'm throwing it back to you ot someone in the
> readership with better intuition or imagination than I possess.
> 
> 
>> I'm sorry if this seems very novice, I'm new to R.
>> 
>> -Kevin
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From tanasa at gmail.com  Fri Jun 12 05:40:03 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Thu, 11 Jun 2015 20:40:03 -0700
Subject: [R] accessing the ellements in an array and factors.
Message-ID: <CA+JEM003Eqrt69HVmh1ZgpzHhY8wv7f9Dn2RqcodV+EUAVAbAw@mail.gmail.com>

Dear all,

please could you please with a simple question : I do have an array of 32
elements, where each element is indexed by a name : eg :

list_triplet_wells <-c("A1:A2:A3", "A4:A5:A6 ",  "A7:A8:A9",   "A10:A11:A12
")
xxx <-array(0, dim=4)
dimnames(xxx) = list(list_triplet_wells)

>From another script, I have an output like :

> yyy
[1]   A1:A2:A3    B4:B5:B6
31 Levels:   B4:B5:B6    A1:A2:A3  ...   F4:F5:F6

so yyy seems to be a factor type. I would need to call the elements of xxx
array based on the elements of yyy; eg xxx[yyy].

How can I do this in order to circumvent the factor type of yyy ? Thanks a
lot,

bogdan

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Jun 12 06:08:13 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 11 Jun 2015 21:08:13 -0700
Subject: [R] accessing the ellements in an array and factors.
In-Reply-To: <CA+JEM003Eqrt69HVmh1ZgpzHhY8wv7f9Dn2RqcodV+EUAVAbAw@mail.gmail.com>
References: <CA+JEM003Eqrt69HVmh1ZgpzHhY8wv7f9Dn2RqcodV+EUAVAbAw@mail.gmail.com>
Message-ID: <DEC78A0C-BAB7-44E0-A02E-3D43E90DEED5@comcast.net>

Cross-posting to SO and Rhelp is deprecated.

On Jun 11, 2015, at 8:40 PM, Bogdan Tanasa wrote:

> Dear all,
> 
> please could you please with a simple question : I do have an array of 32
> elements, where each element is indexed by a name : eg :
> 
> list_triplet_wells <-c("A1:A2:A3", "A4:A5:A6 ",  "A7:A8:A9",   "A10:A11:A12
> ")
> xxx <-array(0, dim=4)
> dimnames(xxx) = list(list_triplet_wells)
> 
>> From another script, I have an output like :
> 
>> yyy
> [1]   A1:A2:A3    B4:B5:B6
> 31 Levels:   B4:B5:B6    A1:A2:A3  ...   F4:F5:F6
> 
> so yyy seems to be a factor type. I would need to call the elements of xxx
> array based on the elements of yyy; eg xxx[yyy].
> 
> How can I do this in order to circumvent the factor type of yyy ? Thanks a
> lot,
> 
> bogdan
> 
> 	[[alternative HTML version deleted]]
> 

As is posting in HTML.

> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From shivibhatia at ymail.com  Fri Jun 12 07:40:34 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Thu, 11 Jun 2015 22:40:34 -0700 (PDT)
Subject: [R] Missing Values in Table Statement
Message-ID: <1434087634952-4708534.post@n4.nabble.com>

HI All,

I need help on 2 issues as highlighted below"

A)I have 2 variables:- Sch_Time & Origin Name.
Now there are multiple instances where Scheduled time i.e. Sch_Time is
missing from each location hence i need to count how many instances do i
have split on location. 
the code i have is :
table(test$ORIGIN_NAME,is.na(test$SCH_TIME)) 
but with code it is not giving any value as TRUE & in FALSE all the values
are total count of scheduled departure.

Could you please suggest what should be the solution for the same. Would it
be because of var i am dealing with as result of typeof(test$ORIGIN_NAME) &
typeof(test$SCH_TIME) both result to character. 

B) In the cross table can we show the proportion of values under each head
as in %. 
table(test$CR_DT)/10765*100. Here i am trying to find how many values
appearing on a date basis where 10765 is my total data count.

Kindly let me know if i need to supply dput data. Thank you!!!




--
View this message in context: http://r.789695.n4.nabble.com/Missing-Values-in-Table-Statement-tp4708534.html
Sent from the R help mailing list archive at Nabble.com.


From petr.pikal at precheza.cz  Fri Jun 12 08:12:21 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 12 Jun 2015 06:12:21 +0000
Subject: [R] Missing Values in Table Statement
In-Reply-To: <1434087634952-4708534.post@n4.nabble.com>
References: <1434087634952-4708534.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C309DA@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shivi82
> Sent: Friday, June 12, 2015 7:41 AM
> To: r-help at r-project.org
> Subject: [R] Missing Values in Table Statement
>
> HI All,
>
> I need help on 2 issues as highlighted below"
>
> A)I have 2 variables:- Sch_Time & Origin Name.
> Now there are multiple instances where Scheduled time i.e. Sch_Time is
> missing from each location hence i need to count how many instances do
> i have split on location.
> the code i have is :
> table(test$ORIGIN_NAME,is.na(test$SCH_TIME))
> but with code it is not giving any value as TRUE & in FALSE all the
> values are total count of scheduled departure.

Table gives you count for each category of a factor. You say that you want count instances but then you complain you get them. I am puzzled.

>
> Could you please suggest what should be the solution for the same.
> Would it be because of var i am dealing with as result of
> typeof(test$ORIGIN_NAME) &
> typeof(test$SCH_TIME) both result to character.
>
> B) In the cross table can we show the proportion of values under each
> head as in %.
> table(test$CR_DT)/10765*100. Here i am trying to find how many values
> appearing on a date basis where 10765 is my total data count.

see also ?prop.table


>
> Kindly let me know if i need to supply dput data. Thank you!!!

It is way easier to understand your problem with reproducible example for which data is important part.

Cheers
Petr

>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Missing-
> Values-in-Table-Statement-tp4708534.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From shivibhatia at ymail.com  Fri Jun 12 08:27:47 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Thu, 11 Jun 2015 23:27:47 -0700 (PDT)
Subject: [R] Missing Values in Table Statement
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C309DA@SRVEXCHMBX.precheza.cz>
References: <1434087634952-4708534.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C309DA@SRVEXCHMBX.precheza.cz>
Message-ID: <1434090467055-4708537.post@n4.nabble.com>

Hi Petr,

Probably i did not explain my scenario clearly.
 table(test$ORIGIN_NAME,is.na(test$SCH_TIME)) is the syntax with which i am
trying to find per destination wise how many instances are there where
system failed to enter the scheduled delivery time & there are multiple
cases of these. I am expecting an output where TRUE and FALSE will give
number of observations either missing or non-missing. 

ORIGIN         ORIGIN_NAME DESTINATION      DESTINATION_NM  RPS_NO
DLI11            DELHI-11       NDA50                  NOIDA-50            
1350760
NDA50            NOIDA-50     DLI11                    DELHI-11            
1352692 


SCH_TIME  ACTUAL_DEP_DATE ACTUAL_DEP_TIME WAYBILLS TOTAL_PKG ACTUAL_WT
CHG_WT
6:00         13/03/2015                    6:30                      -          
0                  0                0
21:30       15/03/2015                   13:37                     28       
256           3419               3730


Hopefully i am able to make my self now clear. Thank you. 







--
View this message in context: http://r.789695.n4.nabble.com/Missing-Values-in-Table-Statement-tp4708534p4708537.html
Sent from the R help mailing list archive at Nabble.com.


From petr.pikal at precheza.cz  Fri Jun 12 08:57:12 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 12 Jun 2015 06:57:12 +0000
Subject: [R] Missing Values in Table Statement
In-Reply-To: <1434090467055-4708537.post@n4.nabble.com>
References: <1434087634952-4708534.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C309DA@SRVEXCHMBX.precheza.cz>
	<1434090467055-4708537.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C30A12@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shivi82
> Sent: Friday, June 12, 2015 8:28 AM
> To: r-help at r-project.org
> Subject: Re: [R] Missing Values in Table Statement
>
> Hi Petr,
>
> Probably i did not explain my scenario clearly.
>  table(test$ORIGIN_NAME,is.na(test$SCH_TIME)) is the syntax with which

This is what **I** get.

> table(test$ORIGIN_NAME,is.na(test$SCH_TIME))
Error in table(test$ORIGIN_NAME, is.na(test$SCH_TIME)) :
  object 'test' not found
>

> i am trying to find per destination wise how many instances are there
> where system failed to enter the scheduled delivery time & there are
> multiple cases of these. I am expecting an output where TRUE and FALSE

As I said output of table is not logical but numeric.

> will give number of observations either missing or non-missing.
>
> ORIGIN         ORIGIN_NAME DESTINATION      DESTINATION_NM  RPS_NO
> DLI11            DELHI-11       NDA50                  NOIDA-50
> 1350760
> NDA50            NOIDA-50     DLI11                    DELHI-11
> 1352692
>
>
> SCH_TIME  ACTUAL_DEP_DATE ACTUAL_DEP_TIME WAYBILLS TOTAL_PKG ACTUAL_WT
> CHG_WT
> 6:00         13/03/2015                    6:30                      -
> 0                  0                0
> 21:30       15/03/2015                   13:37                     28
> 256           3419               3730
>
>
> Hopefully i am able to make my self now clear. Thank you.

Not really.

Cheers
Petr


>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Missing-
> Values-in-Table-Statement-tp4708534p4708537.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pnsinha68 at gmail.com  Fri Jun 12 09:00:50 2015
From: pnsinha68 at gmail.com (Partha Sinha)
Date: Fri, 12 Jun 2015 12:30:50 +0530
Subject: [R] Views installation
Message-ID: <CADcgpJfrh5kwWOUvkfNNO-SS07mTQjpTPcjJMPHv8h6bNgbFvg@mail.gmail.com>

I want to install views  like machine learning and Bayesian using code
( write code and running the code once and it will install all
packages in those views rather than doing it twice).
Pl help
Parth


From shivibhatia at ymail.com  Fri Jun 12 08:47:18 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Thu, 11 Jun 2015 23:47:18 -0700 (PDT)
Subject: [R] Missing Values in Table Statement
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C30A12@SRVEXCHMBX.precheza.cz>
References: <1434087634952-4708534.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C309DA@SRVEXCHMBX.precheza.cz>
	<1434090467055-4708537.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C30A12@SRVEXCHMBX.precheza.cz>
Message-ID: <1434091638068-4708540.post@n4.nabble.com>

Hi Petr, Please see the output from dget as follows.

ORIGIN         ORIGIN_NAME DESTINATION      DESTINATION_NM  RPS_NO                                 
VENDOR_NAME     CR_DT SCHD_MRKT     VHL_NO vhl_cap
1      DLI11            DELHI-11       NDA50            NOIDA-50 1350760                                
RAJIV GAUTAM 13-Mar-15  SCHEDULE  HR63A0931       8
2      DLI11            DELHI-11       NDA50            NOIDA-50 1366368                                
RAJIV GAUTAM 31-Mar-15  SCHEDULE  HR63A0931       8
3      NDA50            NOIDA-50       DLI11            DELHI-11 1352692                                
RAJIV GAUTAM 15-Mar-15  SCHEDULE  HR63A0931       8
4      NDA50            NOIDA-50       NDA11            NOIDA-11 1354642                                
RAJIV GAUTAM 17-Mar-15    MARKET  HR63A0931       8
5      NDA50            NOIDA-50       DLI11            DELHI-11 1354642                                
RAJIV GAUTAM 17-Mar-15    MARKET  HR63A0931       8
      SCH_TIME ACTUAL_DEP_DATE ACTUAL_DEP_TIME WAYBILLS TOTAL_PKG ACTUAL_WT
CHG_WT                                                  RTE_CD
1         6:00      13/03/2015            6:30        -         0         0     
0                          DELHI-11-NOIDA-50(DLI11-NDA50)
2         6:00      31/03/2015            4:05        -         0         0     
0                          DELHI-11-NOIDA-50(DLI11-NDA50)
3        21:30      15/03/2015           13:37        -         0         0     
0                          NOIDA-50-DELHI-11(NDA50-DLI11)
4                   17/03/2015           20:15        3        40       744   
770                    NOIDA-50-DELHI-11(NDA50-NDA11-DLI11)
5                   17/03/2015           20:15       28       256      3419  
3730                    NOIDA-50-DELHI-11(NDA50-NDA11-DLI11)



--
View this message in context: http://r.789695.n4.nabble.com/Missing-Values-in-Table-Statement-tp4708534p4708540.html
Sent from the R help mailing list archive at Nabble.com.


From Achim.Zeileis at uibk.ac.at  Fri Jun 12 10:51:57 2015
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 12 Jun 2015 10:51:57 +0200 (CEST)
Subject: [R] Views installation
In-Reply-To: <CADcgpJfrh5kwWOUvkfNNO-SS07mTQjpTPcjJMPHv8h6bNgbFvg@mail.gmail.com>
References: <CADcgpJfrh5kwWOUvkfNNO-SS07mTQjpTPcjJMPHv8h6bNgbFvg@mail.gmail.com>
Message-ID: <alpine.DEB.2.11.1506121051330.11801@paninaro.uibk.ac.at>

On Fri, 12 Jun 2015, Partha Sinha wrote:

> I want to install views  like machine learning and Bayesian using code
> ( write code and running the code once and it will install all
> packages in those views rather than doing it twice).
> Pl help

I'm not sure what exactly you are looking for but

ctv::update.views(c("Bayesian", "MachineLearning"))

should get everything installed.

> Parth
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkrideau at inbox.com  Fri Jun 12 13:37:34 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 12 Jun 2015 03:37:34 -0800
Subject: [R] Missing Values in Table Statement
In-Reply-To: <1434087634952-4708534.post@n4.nabble.com>
Message-ID: <2D84126F00B.00000042jrkrideau@inbox.com>


If possible always supply  data in dput() form. 
John Kane
Kingston ON Canada

> Kindly let me know if i need to supply dput data. Thank you!!!

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From tanasa at gmail.com  Fri Jun 12 16:38:52 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Fri, 12 Jun 2015 07:38:52 -0700
Subject: [R] accessing the ellements in an array and factors.
In-Reply-To: <CA+8X3fUDCA=cVzzdotoYRXVToBW-en5a74DdfomBu8RURMW0uA@mail.gmail.com>
References: <CA+JEM003Eqrt69HVmh1ZgpzHhY8wv7f9Dn2RqcodV+EUAVAbAw@mail.gmail.com>
	<DEC78A0C-BAB7-44E0-A02E-3D43E90DEED5@comcast.net>
	<CA+8X3fUDCA=cVzzdotoYRXVToBW-en5a74DdfomBu8RURMW0uA@mail.gmail.com>
Message-ID: <CA+JEM01MZtnLUYwov15HTMVrGX2CgRv3Hj-m0JanibOky3V=QQ@mail.gmail.com>

Thanks Jim ! also found a second way to do by using as.character() eg :
as.character(yyy).


On Fri, Jun 12, 2015 at 3:06 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Bogdan,
> I seem to be able to do it like this:
>
> xxx <-array(0, dim=4)
> dimnames(xxx) = list(list_triplet_wells)
> xxx
>    A1:A2:A3   A4:A5:A6     A7:A8:A9 A10:A11:A12
>           0           0           0           0
> yyy<-factor(c("A1:A2:A3", "A4:A5:A6 ",  "A7:A8:A9",   "A10:A11:A12"))
> yyy
> [1] A1:A2:A3    A4:A5:A6    A7:A8:A9    A10:A11:A12
> Levels: A1:A2:A3 A10:A11:A12 A4:A5:A6  A7:A8:A9
> xxx[yyy[1]]
> A1:A2:A3
>        0
>
> Jim
>
>
> On Fri, Jun 12, 2015 at 2:08 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> > Cross-posting to SO and Rhelp is deprecated.
> >
> > On Jun 11, 2015, at 8:40 PM, Bogdan Tanasa wrote:
> >
> >> Dear all,
> >>
> >> please could you please with a simple question : I do have an array of
> 32
> >> elements, where each element is indexed by a name : eg :
> >>
> >> list_triplet_wells <-c("A1:A2:A3", "A4:A5:A6 ",  "A7:A8:A9",
>  "A10:A11:A12
> >> ")
> >> xxx <-array(0, dim=4)
> >> dimnames(xxx) = list(list_triplet_wells)
> >>
> >>> From another script, I have an output like :
> >>
> >>> yyy
> >> [1]   A1:A2:A3    B4:B5:B6
> >> 31 Levels:   B4:B5:B6    A1:A2:A3  ...   F4:F5:F6
> >>
> >> so yyy seems to be a factor type. I would need to call the elements of
> xxx
> >> array based on the elements of yyy; eg xxx[yyy].
> >>
> >> How can I do this in order to circumvent the factor type of yyy ?
> Thanks a
> >> lot,
> >>
> >> bogdan
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >
> > As is posting in HTML.
> >
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gary.nelson at state.ma.us  Fri Jun 12 17:39:48 2015
From: gary.nelson at state.ma.us (Nelson, Gary (MISC))
Date: Fri, 12 Jun 2015 11:39:48 -0400
Subject: [R] Help with abs function
In-Reply-To: <DE681B198BF90743B3B4BD64035E63F88C64E95830@ES-MSG-EMB-002.es.govt.state.ma.us>
References: <DE681B198BF90743B3B4BD64035E63F88C64E95830@ES-MSG-EMB-002.es.govt.state.ma.us>
Message-ID: <DE681B198BF90743B3B4BD64035E63F88C64E95831@ES-MSG-EMB-002.es.govt.state.ma.us>

I have come across some odd behavior (to me) using the abs() function that I wonder if anyone can explain.

Using  R version 3.2.0, I created a vector of absolute values using  the following code:

> tran<-c(7.2)
> tgrid<-c(7.1,7.4,7.3,7.1,7.3)
> dgrid<-abs(tgrid-tran)
> dgrid
[1] 0.1 0.2 0.1 0.1 0.1

When I tried to extract just the rows with values>0.1, I get

> dgrid[dgrid>0.1]
[1] 0.1 0.2 0.1

There should be only 1 value extracted.

However, if I enter the values by hand

> bgrid<-c(0.1,0.2,0.1,0.1,0.1)
> bgrid
[1] 0.1 0.2 0.1 0.1 0.1
> bgrid[bgrid>0.1]
[1] 0.2

The result is correct.  So why is this happening?

I did explore a little bit and found

> as.character(dgrid)
[1] "0.100000000000001"  "0.2"
[3] "0.0999999999999996" "0.100000000000001"
[5] "0.0999999999999996"

which shows the absolute values of the negative differences  are slightly greater than the difference of 0.1

Is this normal behavior for the abs() function?

Thanks,

Gary Nelson

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri Jun 12 17:48:29 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 12 Jun 2015 11:48:29 -0400
Subject: [R] Help with abs function
In-Reply-To: <DE681B198BF90743B3B4BD64035E63F88C64E95831@ES-MSG-EMB-002.es.govt.state.ma.us>
References: <DE681B198BF90743B3B4BD64035E63F88C64E95830@ES-MSG-EMB-002.es.govt.state.ma.us>
	<DE681B198BF90743B3B4BD64035E63F88C64E95831@ES-MSG-EMB-002.es.govt.state.ma.us>
Message-ID: <CAM_vjunLpMH-nM7LKwfyub2ubqJVo=Rw-psL0jWuxfjBsGiv-Q@mail.gmail.com>

Please read R FAQ 7.31.

On Fri, Jun 12, 2015 at 11:39 AM, Nelson, Gary (MISC)
<gary.nelson at state.ma.us> wrote:
> I have come across some odd behavior (to me) using the abs() function that I wonder if anyone can explain.
>
> Using  R version 3.2.0, I created a vector of absolute values using  the following code:
>
>> tran<-c(7.2)
>> tgrid<-c(7.1,7.4,7.3,7.1,7.3)
>> dgrid<-abs(tgrid-tran)
>> dgrid
> [1] 0.1 0.2 0.1 0.1 0.1
>
> When I tried to extract just the rows with values>0.1, I get
>
>> dgrid[dgrid>0.1]
> [1] 0.1 0.2 0.1
>
> There should be only 1 value extracted.
>
> However, if I enter the values by hand
>
>> bgrid<-c(0.1,0.2,0.1,0.1,0.1)
>> bgrid
> [1] 0.1 0.2 0.1 0.1 0.1
>> bgrid[bgrid>0.1]
> [1] 0.2
>
> The result is correct.  So why is this happening?
>
> I did explore a little bit and found
>
>> as.character(dgrid)
> [1] "0.100000000000001"  "0.2"
> [3] "0.0999999999999996" "0.100000000000001"
> [5] "0.0999999999999996"
>
> which shows the absolute values of the negative differences  are slightly greater than the difference of 0.1
>
> Is this normal behavior for the abs() function?
>
> Thanks,
>
> Gary Nelson
-- 
Sarah Goslee
http://www.functionaldiversity.org


From jdnewmil at dcn.davis.CA.us  Fri Jun 12 18:01:54 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 12 Jun 2015 09:01:54 -0700
Subject: [R] Help with abs function
In-Reply-To: <DE681B198BF90743B3B4BD64035E63F88C64E95831@ES-MSG-EMB-002.es.govt.state.ma.us>
References: <DE681B198BF90743B3B4BD64035E63F88C64E95830@ES-MSG-EMB-002.es.govt.state.ma.us>
	<DE681B198BF90743B3B4BD64035E63F88C64E95831@ES-MSG-EMB-002.es.govt.state.ma.us>
Message-ID: <FFD3AE11-0541-417D-B5A3-19E86F1E224F@dcn.davis.CA.us>

FAQ 7.31
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 12, 2015 8:39:48 AM PDT, "Nelson, Gary (MISC)" <gary.nelson at state.ma.us> wrote:
>I have come across some odd behavior (to me) using the abs() function
>that I wonder if anyone can explain.
>
>Using  R version 3.2.0, I created a vector of absolute values using 
>the following code:
>
>> tran<-c(7.2)
>> tgrid<-c(7.1,7.4,7.3,7.1,7.3)
>> dgrid<-abs(tgrid-tran)
>> dgrid
>[1] 0.1 0.2 0.1 0.1 0.1
>
>When I tried to extract just the rows with values>0.1, I get
>
>> dgrid[dgrid>0.1]
>[1] 0.1 0.2 0.1
>
>There should be only 1 value extracted.
>
>However, if I enter the values by hand
>
>> bgrid<-c(0.1,0.2,0.1,0.1,0.1)
>> bgrid
>[1] 0.1 0.2 0.1 0.1 0.1
>> bgrid[bgrid>0.1]
>[1] 0.2
>
>The result is correct.  So why is this happening?
>
>I did explore a little bit and found
>
>> as.character(dgrid)
>[1] "0.100000000000001"  "0.2"
>[3] "0.0999999999999996" "0.100000000000001"
>[5] "0.0999999999999996"
>
>which shows the absolute values of the negative differences  are
>slightly greater than the difference of 0.1
>
>Is this normal behavior for the abs() function?
>
>Thanks,
>
>Gary Nelson
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Fri Jun 12 19:28:59 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 12 Jun 2015 17:28:59 +0000
Subject: [R] Missing Values in Table Statement
In-Reply-To: <1434090467055-4708537.post@n4.nabble.com>
References: <1434087634952-4708534.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C309DA@SRVEXCHMBX.precheza.cz>
	<1434090467055-4708537.post@n4.nabble.com>
Message-ID: <D1A06140.12DF12%macqueen1@llnl.gov>

Maybe it will help if I create some fake data to illustrate what I think
you want:

set.seed(25)
tmp <- data.frame(origin=sample( letters[1:3], 25, replace=TRUE),
                  schd= sample( 1:5, 25, replace=TRUE)
                  )
tmp$schd[ c(5,7,18,22) ] <- NA

print(tmp)


table( tmp$origin, is.na(tmp$schd))
   
    FALSE TRUE
  a     9    1
  b     6    2
  c     6    1




## a little fancier

table( tmp$origin, ifelse(is.na(tmp$schd),'missing','available'))
   
    available missing
  a         9       1
  b         6       2
  c         6       1



For example, for schedule "b" there are 6 instances for which the sched
time has been entered and 2 where it has not.


In this example, the table() function is working correctly.

I don't think anyone understands what is wrong with the output you are
getting.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/11/15, 11:27 PM, "Shivi82" <shivibhatia at ymail.com> wrote:

>Hi Petr,
>
>Probably i did not explain my scenario clearly.
> table(test$ORIGIN_NAME,is.na(test$SCH_TIME)) is the syntax with which i
>am
>trying to find per destination wise how many instances are there where
>system failed to enter the scheduled delivery time & there are multiple
>cases of these. I am expecting an output where TRUE and FALSE will give
>number of observations either missing or non-missing.
>
>ORIGIN         ORIGIN_NAME DESTINATION      DESTINATION_NM  RPS_NO
>DLI11            DELHI-11       NDA50                  NOIDA-50
> 
>1350760
>NDA50            NOIDA-50     DLI11                    DELHI-11
> 
>1352692 
>
>
>SCH_TIME  ACTUAL_DEP_DATE ACTUAL_DEP_TIME WAYBILLS TOTAL_PKG ACTUAL_WT
>CHG_WT
>6:00         13/03/2015                    6:30                      -
>      
>0                  0                0
>21:30       15/03/2015                   13:37                     28
>  
>256           3419               3730
>
>
>Hopefully i am able to make my self now clear. Thank you.
>
>
>
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Missing-Values-in-Table-Statement-tp4708534p
>4708537.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mylisttech at gmail.com  Fri Jun 12 19:39:55 2015
From: mylisttech at gmail.com (MyList)
Date: Fri, 12 Jun 2015 23:09:55 +0530
Subject: [R] Marascuilo procedure
Message-ID: <7DEA4E15-0775-43D4-B6F2-9A472A96FFE7@gmail.com>

Hello All,

I am new to R and statistics.Pardon me if this a trivial question.

Can the Marascuilo procedure be applied to a 2 x c contingency table with c equal to 2 ? 

My understanding is that it is used to compare proportion between two variables and see which pairs are more significant to make the null hypothesis be rejected. Is this understanding correct?

Also, what post hoc tests can be used on categorical data using R. Can someone lead me to examples or links. I am interested in finding once the Null Hypothesis is rejected then which of the  categories are influencing. 

Null hypothesis (Ho) could be like - old ppl do not do more research before visiting a doctor.once Ho is rejected I want to find if out of old or young who actually do more research.

I am currently on a project on hypothesis testing , market survey categorical data based designed on a 7 scale lickert analysis.

Thanks in Advance.

- Harmeet

From thanoon.younis80 at gmail.com  Fri Jun 12 20:09:27 2015
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Fri, 12 Jun 2015 21:09:27 +0300
Subject: [R] problem in auto run iteration in R2OpenBUGS
Message-ID: <CABLo8nEju1MOp=g=x5jALipRKhe4ubu3E6uODqWALoDQEw3AZQ@mail.gmail.com>

Hi for all members in R community
I have a small problem in the code below when i call OpenBUGS
#Call OpenBUGS
    model= bugs(data,
                inits,
                parameters.to.save=parameters,
                model.file="D:/Run/model.txt",
                n.iter=5000,
                n.burnin=0,
                OpenBUGS.pgm =
                  "C:/Program Files/OpenBUGS/OpenBUGS323/OpenBUGS.exe",
                working.directory="D:/Run/",
                n.thin=2,
                n.chains=2,
                debug=TRUE,
                DIC=TRUE)

The problem is when the first iteration finish it stop directly without
rerun the second iteration so how can i run the iterations automatically.


Many thanks in advance
-- 
Thanoon Y. Thanoon
PhD Candidate
Department of Mathematical Sciences
Faculty of Science
University Technology Malaysia, UTM
E.Mail: Thanoon.younis80 at gmail.com
E.Mail: dawn_prayer80 at yahoo.com
Facebook:Thanoon Younis AL-Shakerchy
Twitter: Thanoon Alshakerchy
H.P:00601127550205

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Jun 12 20:10:34 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 12 Jun 2015 11:10:34 -0700
Subject: [R] Marascuilo procedure
In-Reply-To: <7DEA4E15-0775-43D4-B6F2-9A472A96FFE7@gmail.com>
References: <7DEA4E15-0775-43D4-B6F2-9A472A96FFE7@gmail.com>
Message-ID: <14A6D6E9-D8F5-44AF-8C70-1706300B477C@dcn.davis.CA.us>

Your question is about statistics, not R. Do read the Posting Guide to inform you for future questions. Meanwhile, you should probably go to stats.stackexchange.com.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 12, 2015 10:39:55 AM PDT, MyList <mylisttech at gmail.com> wrote:
>Hello All,
>
>I am new to R and statistics.Pardon me if this a trivial question.
>
>Can the Marascuilo procedure be applied to a 2 x c contingency table
>with c equal to 2 ? 
>
>My understanding is that it is used to compare proportion between two
>variables and see which pairs are more significant to make the null
>hypothesis be rejected. Is this understanding correct?
>
>Also, what post hoc tests can be used on categorical data using R. Can
>someone lead me to examples or links. I am interested in finding once
>the Null Hypothesis is rejected then which of the  categories are
>influencing. 
>
>Null hypothesis (Ho) could be like - old ppl do not do more research
>before visiting a doctor.once Ho is rejected I want to find if out of
>old or young who actually do more research.
>
>I am currently on a project on hypothesis testing , market survey
>categorical data based designed on a 7 scale lickert analysis.
>
>Thanks in Advance.
>
>- Harmeet
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pinkal08cece at gmail.com  Fri Jun 12 11:15:42 2015
From: pinkal08cece at gmail.com (Pinkal Patel)
Date: Fri, 12 Jun 2015 14:45:42 +0530
Subject: [R] memory isuue
Message-ID: <CA+jkS5pGKPf3+iucLU2gPU-VSFrqyXO+1Qqx_xbTWKgBKLeWew@mail.gmail.com>

Dear All,

Using "dist()" function, I have to calculate distance matrix for large
dataset (2,00,000*23) but problem of memory issue came. I had already try
by break of data into small and this idea is work but take more time, So I
want some other which reduce time.


Try to help me to solve out using parallel package (ff or others) or any
other way.

Thank you,
Pinkal Patel

	[[alternative HTML version deleted]]


From arfelizardo at isa.ulisboa.pt  Fri Jun 12 11:34:07 2015
From: arfelizardo at isa.ulisboa.pt (Ana Rodrigues)
Date: Fri, 12 Jun 2015 02:34:07 -0700 (PDT)
Subject: [R] Two factor nonparametric test
Message-ID: <1434101647441-4708545.post@n4.nabble.com>

I'm just starting to use R, so my question must be really basic... I need a
non parametric test for a two factor (4x3) design. What are the options in
R? If someone could tell me the functions names or even some script
examples, it would be great.
Thank you all =)



--
View this message in context: http://r.789695.n4.nabble.com/Two-factor-nonparametric-test-tp4708545.html
Sent from the R help mailing list archive at Nabble.com.


From drjimlemon at gmail.com  Fri Jun 12 12:06:45 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 12 Jun 2015 20:06:45 +1000
Subject: [R] accessing the ellements in an array and factors.
In-Reply-To: <DEC78A0C-BAB7-44E0-A02E-3D43E90DEED5@comcast.net>
References: <CA+JEM003Eqrt69HVmh1ZgpzHhY8wv7f9Dn2RqcodV+EUAVAbAw@mail.gmail.com>
	<DEC78A0C-BAB7-44E0-A02E-3D43E90DEED5@comcast.net>
Message-ID: <CA+8X3fUDCA=cVzzdotoYRXVToBW-en5a74DdfomBu8RURMW0uA@mail.gmail.com>

Hi Bogdan,
I seem to be able to do it like this:

xxx <-array(0, dim=4)
dimnames(xxx) = list(list_triplet_wells)
xxx
   A1:A2:A3   A4:A5:A6     A7:A8:A9 A10:A11:A12
          0           0           0           0
yyy<-factor(c("A1:A2:A3", "A4:A5:A6 ",  "A7:A8:A9",   "A10:A11:A12"))
yyy
[1] A1:A2:A3    A4:A5:A6    A7:A8:A9    A10:A11:A12
Levels: A1:A2:A3 A10:A11:A12 A4:A5:A6  A7:A8:A9
xxx[yyy[1]]
A1:A2:A3
       0

Jim


On Fri, Jun 12, 2015 at 2:08 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> Cross-posting to SO and Rhelp is deprecated.
>
> On Jun 11, 2015, at 8:40 PM, Bogdan Tanasa wrote:
>
>> Dear all,
>>
>> please could you please with a simple question : I do have an array of 32
>> elements, where each element is indexed by a name : eg :
>>
>> list_triplet_wells <-c("A1:A2:A3", "A4:A5:A6 ",  "A7:A8:A9",   "A10:A11:A12
>> ")
>> xxx <-array(0, dim=4)
>> dimnames(xxx) = list(list_triplet_wells)
>>
>>> From another script, I have an output like :
>>
>>> yyy
>> [1]   A1:A2:A3    B4:B5:B6
>> 31 Levels:   B4:B5:B6    A1:A2:A3  ...   F4:F5:F6
>>
>> so yyy seems to be a factor type. I would need to call the elements of xxx
>> array based on the elements of yyy; eg xxx[yyy].
>>
>> How can I do this in order to circumvent the factor type of yyy ? Thanks a
>> lot,
>>
>> bogdan
>>
>>       [[alternative HTML version deleted]]
>>
>
> As is posting in HTML.
>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From yarkovs at uwindsor.ca  Fri Jun 12 19:37:27 2015
From: yarkovs at uwindsor.ca (Nicole Yarkovsky)
Date: Fri, 12 Jun 2015 13:37:27 -0400
Subject: [R] Installing R 2.15.2 on Mac
Message-ID: <CAF0t158ptK3QR+dfAz7CUA6GqusR+qjbuV3-K63Ejmtvca=_WQ@mail.gmail.com>

Hello,

I'm trying to install the R integration add on for SPSS version 22 so that
I am able to use a specific R extension in SPSS.  For this, I have to
download an older version of R, version 2.15.2 to my MacBook Pro.  When I
try to download this older version, it says I cannot install it on my
hard-drive because I have to have Mac versions 10.5 or higher (I have
version 10.10, Yosemite).  I read through the FAQ but I did not come across
this topic.

Do you have any idea how I could install R version 2.15.2? Or any other
ways around this?

Thank you kindly,
Nicki
-- 
Nicole Yarkovsky, M.A.
Ph.D. Candidate, Clinical Psychology
University of Windsor
yarkovs at uwindsor.ca

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Fri Jun 12 20:38:42 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 12 Jun 2015 13:38:42 -0500
Subject: [R] Installing R 2.15.2 on Mac
In-Reply-To: <CAF0t158ptK3QR+dfAz7CUA6GqusR+qjbuV3-K63Ejmtvca=_WQ@mail.gmail.com>
References: <CAF0t158ptK3QR+dfAz7CUA6GqusR+qjbuV3-K63Ejmtvca=_WQ@mail.gmail.com>
Message-ID: <C9E74DA4-988D-4BB9-A794-38726B334F6C@me.com>


> On Jun 12, 2015, at 12:37 PM, Nicole Yarkovsky <yarkovs at uwindsor.ca> wrote:
> 
> Hello,
> 
> I'm trying to install the R integration add on for SPSS version 22 so that
> I am able to use a specific R extension in SPSS.  For this, I have to
> download an older version of R, version 2.15.2 to my MacBook Pro.  When I
> try to download this older version, it says I cannot install it on my
> hard-drive because I have to have Mac versions 10.5 or higher (I have
> version 10.10, Yosemite).  I read through the FAQ but I did not come across
> this topic.
> 
> Do you have any idea how I could install R version 2.15.2? Or any other
> ways around this?
> 
> Thank you kindly,
> Nicki


As this is Mac specific, it should really be posted to R-SIG-Mac:

  https://stat.ethz.ch/mailman/listinfo/r-sig-mac

That being said, Peter has a post here that touches on this issue:

  https://stat.ethz.ch/pipermail/r-help//2014-November/423169.html

which also raises the issue of why SPSS is requiring such an old version of R.

As to how to accomplish what Peter references, a Google search is likely to be enlightening.

Regards,

Marc Schwartz


From jdnewmil at dcn.davis.CA.us  Fri Jun 12 20:51:32 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 12 Jun 2015 11:51:32 -0700
Subject: [R] Installing R 2.15.2 on Mac
In-Reply-To: <CAF0t158ptK3QR+dfAz7CUA6GqusR+qjbuV3-K63Ejmtvca=_WQ@mail.gmail.com>
References: <CAF0t158ptK3QR+dfAz7CUA6GqusR+qjbuV3-K63Ejmtvca=_WQ@mail.gmail.com>
Message-ID: <6D82E833-9417-4381-81F1-BF54B30E526F@dcn.davis.CA.us>

Install an older OS. Your question really should be directed at SPSS support because they are the ones preventing you from installing a current version of R.

Please read the Posting Guide, as it addresses (among other things) the issue of support for old versions of R.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 12, 2015 10:37:27 AM PDT, Nicole Yarkovsky <yarkovs at uwindsor.ca> wrote:
>Hello,
>
>I'm trying to install the R integration add on for SPSS version 22 so
>that
>I am able to use a specific R extension in SPSS.  For this, I have to
>download an older version of R, version 2.15.2 to my MacBook Pro.  When
>I
>try to download this older version, it says I cannot install it on my
>hard-drive because I have to have Mac versions 10.5 or higher (I have
>version 10.10, Yosemite).  I read through the FAQ but I did not come
>across
>this topic.
>
>Do you have any idea how I could install R version 2.15.2? Or any other
>ways around this?
>
>Thank you kindly,
>Nicki


From bgunter.4567 at gmail.com  Fri Jun 12 22:31:32 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 12 Jun 2015 13:31:32 -0700
Subject: [R] Marascuilo procedure
In-Reply-To: <7DEA4E15-0775-43D4-B6F2-9A472A96FFE7@gmail.com>
References: <7DEA4E15-0775-43D4-B6F2-9A472A96FFE7@gmail.com>
Message-ID: <CAGxFJbTLeCs8Hqxc-+xo1akWfSXEaJ6KD9wW8BE1hHyocT5A9Q@mail.gmail.com>

If this matters -- i.e it is not merely a matter of homework or thesis work
-- I suggest you speak with a local statistical expert, as your statistical
understanding appears to be too confused to get much help from online
forums.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Fri, Jun 12, 2015 at 10:39 AM, MyList <mylisttech at gmail.com> wrote:

> Hello All,
>
> I am new to R and statistics.Pardon me if this a trivial question.
>
> Can the Marascuilo procedure be applied to a 2 x c contingency table with
> c equal to 2 ?
>
> My understanding is that it is used to compare proportion between two
> variables and see which pairs are more significant to make the null
> hypothesis be rejected. Is this understanding correct?
>
> Also, what post hoc tests can be used on categorical data using R. Can
> someone lead me to examples or links. I am interested in finding once the
> Null Hypothesis is rejected then which of the  categories are influencing.
>
> Null hypothesis (Ho) could be like - old ppl do not do more research
> before visiting a doctor.once Ho is rejected I want to find if out of old
> or young who actually do more research.
>
> I am currently on a project on hypothesis testing , market survey
> categorical data based designed on a 7 scale lickert analysis.
>
> Thanks in Advance.
>
> - Harmeet
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Jun 12 22:33:59 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 12 Jun 2015 13:33:59 -0700
Subject: [R] Two factor nonparametric test
In-Reply-To: <1434101647441-4708545.post@n4.nabble.com>
References: <1434101647441-4708545.post@n4.nabble.com>
Message-ID: <CAGxFJbQN2-yXwcLHfLL4KWyYhrTLxD4RtXK_+M3GCum1ureQaQ@mail.gmail.com>

google is your friend ...

?R nonparametric statistics  (and the like)

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Fri, Jun 12, 2015 at 2:34 AM, Ana Rodrigues <arfelizardo at isa.ulisboa.pt>
wrote:

> I'm just starting to use R, so my question must be really basic... I need a
> non parametric test for a two factor (4x3) design. What are the options in
> R? If someone could tell me the functions names or even some script
> examples, it would be great.
> Thank you all =)
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Two-factor-nonparametric-test-tp4708545.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From maitra.mbox.ignored at inbox.com  Fri Jun 12 22:54:36 2015
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Fri, 12 Jun 2015 15:54:36 -0500
Subject: [R] Installing R 2.15.2 on Mac
In-Reply-To: <CAF0t158ptK3QR+dfAz7CUA6GqusR+qjbuV3-K63Ejmtvca=_WQ@mail.gmail.com>
References: <CAF0t158ptK3QR+dfAz7CUA6GqusR+qjbuV3-K63Ejmtvca=_WQ@mail.gmail.com>
Message-ID: <20150612155436.68c2e187192d690aa7a80c7f@inbox.com>

Nicki,

I don't know if you will be doing any clustering using kmeans in R, but there was a bug in 2.15.2 and 2.15.3 IIRC. This was fixed in 3.0.

Btw, are there any capabilities of SPSS that you need and that R can't provide? 

Best wishes,
Ranjan

On Fri, 12 Jun 2015 13:37:27 -0400 Nicole Yarkovsky <yarkovs at uwindsor.ca> wrote:

> Hello,
> 
> I'm trying to install the R integration add on for SPSS version 22 so that
> I am able to use a specific R extension in SPSS.  For this, I have to
> download an older version of R, version 2.15.2 to my MacBook Pro.  When I
> try to download this older version, it says I cannot install it on my
> hard-drive because I have to have Mac versions 10.5 or higher (I have
> version 10.10, Yosemite).  I read through the FAQ but I did not come across
> this topic.
> 
> Do you have any idea how I could install R version 2.15.2? Or any other
> ways around this?
> 
> Thank you kindly,
> Nicki
> -- 
> Nicole Yarkovsky, M.A.
> Ph.D. Candidate, Clinical Psychology
> University of Windsor
> yarkovs at uwindsor.ca
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From ligges at statistik.tu-dortmund.de  Fri Jun 12 23:09:56 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 12 Jun 2015 23:09:56 +0200
Subject: [R] problem in auto run iteration in R2OpenBUGS
In-Reply-To: <CABLo8nEju1MOp=g=x5jALipRKhe4ubu3E6uODqWALoDQEw3AZQ@mail.gmail.com>
References: <CABLo8nEju1MOp=g=x5jALipRKhe4ubu3E6uODqWALoDQEw3AZQ@mail.gmail.com>
Message-ID: <557B4AA4.7070302@statistik.tu-dortmund.de>

Not sure from what you sent: The call looks fine, so you need to make 
inits, data and model file available, I think.
And perhaps more an OpenBUGS than an R question...

Best,
Uwe Ligges



On 12.06.2015 20:09, thanoon younis wrote:
> Hi for all members in R community
> I have a small problem in the code below when i call OpenBUGS
> #Call OpenBUGS
>      model= bugs(data,
>                  inits,
>                  parameters.to.save=parameters,
>                  model.file="D:/Run/model.txt",
>                  n.iter=5000,
>                  n.burnin=0,
>                  OpenBUGS.pgm =
>                    "C:/Program Files/OpenBUGS/OpenBUGS323/OpenBUGS.exe",
>                  working.directory="D:/Run/",
>                  n.thin=2,
>                  n.chains=2,
>                  debug=TRUE,
>                  DIC=TRUE)
>
> The problem is when the first iteration finish it stop directly without
> rerun the second iteration so how can i run the iterations automatically.
>
>
> Many thanks in advance
>


From tanasa at gmail.com  Sat Jun 13 02:28:58 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Fri, 12 Jun 2015 17:28:58 -0700
Subject: [R] display a matrix in colors
Message-ID: <CA+JEM03KQGBtbE0GbTV2JTbPAQq+nCk0ueHO7Fp4MmjTRF1z8w@mail.gmail.com>

Dear all,

please could you advise about the most convenient functions or libraries to
use in order to display a matrix as a heatmap/a color matrix ?

the matrix contains the values of 0, 10, 20, 30 or 100. thank you !

-- bogdan

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Jun 13 02:36:29 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 Jun 2015 17:36:29 -0700
Subject: [R] display a matrix in colors
In-Reply-To: <CA+JEM03KQGBtbE0GbTV2JTbPAQq+nCk0ueHO7Fp4MmjTRF1z8w@mail.gmail.com>
References: <CA+JEM03KQGBtbE0GbTV2JTbPAQq+nCk0ueHO7Fp4MmjTRF1z8w@mail.gmail.com>
Message-ID: <5A5FBFBB-5A14-45C6-A24F-ADB9A14FC38F@comcast.net>



On Jun 12, 2015, at 5:28 PM, Bogdan Tanasa wrote:

> Dear all,
> 
> please could you advise about the most convenient functions or libraries to
> use in order to display a matrix as a heatmap/a color matrix ?
> 
> the matrix contains the values of 0, 10, 20, 30 or 100. thank you !

What? You must have looked at `?heatmap` and the links on its help page, so what really is the question?

> 
> -- bogdan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From tanasa at gmail.com  Sat Jun 13 02:39:41 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Fri, 12 Jun 2015 17:39:41 -0700
Subject: [R] display a matrix in colors
In-Reply-To: <5A5FBFBB-5A14-45C6-A24F-ADB9A14FC38F@comcast.net>
References: <CA+JEM03KQGBtbE0GbTV2JTbPAQq+nCk0ueHO7Fp4MmjTRF1z8w@mail.gmail.com>
	<5A5FBFBB-5A14-45C6-A24F-ADB9A14FC38F@comcast.net>
Message-ID: <CA+JEM000yksGq5w5-JSTXUF6fiqYoLATK6rZkNxvGK+9nS40_g@mail.gmail.com>

Hi David, thanks, yes,

heatmap provides clustered heatmap, and I am looking for an unclustered
display of a matrix, and only to set up the color ranges. thanks for your
help !

-- bogdan

On Fri, Jun 12, 2015 at 5:36 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
>
> On Jun 12, 2015, at 5:28 PM, Bogdan Tanasa wrote:
>
> > Dear all,
> >
> > please could you advise about the most convenient functions or libraries
> to
> > use in order to display a matrix as a heatmap/a color matrix ?
> >
> > the matrix contains the values of 0, 10, 20, 30 or 100. thank you !
>
> What? You must have looked at `?heatmap` and the links on its help page,
> so what really is the question?
>
> >
> > -- bogdan
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Jun 13 05:41:00 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 13 Jun 2015 13:41:00 +1000
Subject: [R] display a matrix in colors
In-Reply-To: <CA+JEM000yksGq5w5-JSTXUF6fiqYoLATK6rZkNxvGK+9nS40_g@mail.gmail.com>
References: <CA+JEM03KQGBtbE0GbTV2JTbPAQq+nCk0ueHO7Fp4MmjTRF1z8w@mail.gmail.com>
	<5A5FBFBB-5A14-45C6-A24F-ADB9A14FC38F@comcast.net>
	<CA+JEM000yksGq5w5-JSTXUF6fiqYoLATK6rZkNxvGK+9nS40_g@mail.gmail.com>
Message-ID: <CA+8X3fUH2sa8oDO22eLZ6MjixWbmwhrDdwRiFTk3hmRScJq4HA@mail.gmail.com>

Hi Bogdan,
Have a look at color2D.matplot in the plotrix package - it's a bit
different from "image" and "heatmap".

Jim


On Sat, Jun 13, 2015 at 10:39 AM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> Hi David, thanks, yes,
>
> heatmap provides clustered heatmap, and I am looking for an unclustered
> display of a matrix, and only to set up the color ranges. thanks for your
> help !
>
> -- bogdan
>
> On Fri, Jun 12, 2015 at 5:36 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
>
>>
>>
>> On Jun 12, 2015, at 5:28 PM, Bogdan Tanasa wrote:
>>
>> > Dear all,
>> >
>> > please could you advise about the most convenient functions or libraries
>> to
>> > use in order to display a matrix as a heatmap/a color matrix ?
>> >
>> > the matrix contains the values of 0, 10, 20, 30 or 100. thank you !
>>
>> What? You must have looked at `?heatmap` and the links on its help page,
>> so what really is the question?
>>
>> >
>> > -- bogdan
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Jun 13 06:12:08 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 Jun 2015 21:12:08 -0700
Subject: [R] display a matrix in colors
In-Reply-To: <CA+JEM000yksGq5w5-JSTXUF6fiqYoLATK6rZkNxvGK+9nS40_g@mail.gmail.com>
References: <CA+JEM03KQGBtbE0GbTV2JTbPAQq+nCk0ueHO7Fp4MmjTRF1z8w@mail.gmail.com>
	<5A5FBFBB-5A14-45C6-A24F-ADB9A14FC38F@comcast.net>
	<CA+JEM000yksGq5w5-JSTXUF6fiqYoLATK6rZkNxvGK+9nS40_g@mail.gmail.com>
Message-ID: <A34EC87D-CE35-41B4-A88E-2CC817F01988@comcast.net>


On Jun 12, 2015, at 5:39 PM, Bogdan Tanasa wrote:

> Hi David, thanks, yes, 
> 
> heatmap provides clustered heatmap, and I am looking for an unclustered display of a matrix,

Please explain what "clustered"  means in the context of a heatmap.

> and only to set up the color ranges.

And that needs an explanation as well.

> thanks for your help !
> 
> -- bogdan 
> 
> On Fri, Jun 12, 2015 at 5:36 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
> On Jun 12, 2015, at 5:28 PM, Bogdan Tanasa wrote:
> 
> > Dear all,
> >
> > please could you advise about the most convenient functions or libraries to
> > use in order to display a matrix as a heatmap/a color matrix ?
> >
> > the matrix contains the values of 0, 10, 20, 30 or 100. thank you !
> 
> What? You must have looked at `?heatmap` and the links on its help page, so what really is the question?
> 
> >
> > -- bogdan
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From shivibhatia at ymail.com  Sat Jun 13 06:36:23 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Fri, 12 Jun 2015 21:36:23 -0700 (PDT)
Subject: [R] Missing Values in Table Statement
In-Reply-To: <D1A06140.12DF12%macqueen1@llnl.gov>
References: <1434087634952-4708534.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C309DA@SRVEXCHMBX.precheza.cz>
	<1434090467055-4708537.post@n4.nabble.com>
	<D1A06140.12DF12%macqueen1@llnl.gov>
Message-ID: <1434170183472-4708593.post@n4.nabble.com>

HI Don,

This is the exact result i need. However in my case i am not getting any
value under TRUE whereas FALSE captures total observations in each variable.
Please find the syntax and output from the code:
table(test$ORIGIN_NAME,is.na(test$SCH_TIME))

Output
                                 FALSE
  BAHADURGARH            15
  BAREILLY                    44
  BAWAL                        34
  DELHI-11                   2446
  DELHI-39                   170
  DELHI-40                   86
  DELHI NCR-12            1925

The data from str is attached:
data.frame':	10765 obs. of  18 variables:
 $ ORIGIN         : chr  "DLI11" "DLI11" "NDA50" "NDA50" ...
 $ ORIGIN_NAME    : chr  "DELHI-11" "DELHI-11" "NOIDA-50" "NOIDA-50" ...
 $ DESTINATION    : chr  "NDA50" "NDA50" "DLI11" "NDA11" ...
 $ DESTINATION_NM : chr  "NOIDA-50" "NOIDA-50" "DELHI-11" "NOIDA-11" ...
 $ RPS_NO         : int  1350760 1366368 1352692 1354642 1354642 1349180
1349180 1356091 1348591 1348591 ...
 $ VENDOR_NAME    : chr  "RAJIV GAUTAM" "RAJIV GAUTAM" "RAJIV GAUTAM" "RAJIV
GAUTAM" ...
 $ CR_DT          : chr  "13-Mar-15" "31-Mar-15" "15-Mar-15" "17-Mar-15" ...
 $ SCHD_MRKT      : chr  "SCHEDULE" "SCHEDULE" "SCHEDULE" "MARKET" ...
 $ VHL_NO         : chr  "HR63A0931" "HR63A0931" "HR63A0931" "HR63A0931" ...
 $ vhl_cap        : int  8 8 8 8 8 8 8 8 8 8 ...
 $ SCH_TIME       : chr  "6:00" "6:00" "21:30" "" ...
 $ ACTUAL_DEP_DATE: chr  "13/03/2015" "31/03/2015" "15/03/2015" "17/03/2015"
...
 $ ACTUAL_DEP_TIME: chr  "6:30" "4:05" "13:37" "20:15" ...
 $ WAYBILLS       : chr  "-" "-" "-" "3" ...
 $ TOTAL_PKG      : int  0 0 0 40 256 6 0 0 16 427 ...
 $ ACTUAL_WT      : int  0 0 0 744 3419 65 0 0 193 7223 ...
 $ CHG_WT         : int  0 0 0 770 3730 70 0 0 210 7310 ...
 $ RTE_CD         : chr  "DELHI-11-NOIDA-50(DLI11-NDA50)"
"DELHI-11-NOIDA-50(DLI11-NDA50)" "NOIDA-50-DELHI-11(NDA50-DLI11)"
"NOIDA-50-DELHI-11(NDA50-NDA11-DLI11)"
Scheduled time here is character, could this be the reason for the incorrect
result. 

Thanks, Shivi




--
View this message in context: http://r.789695.n4.nabble.com/Missing-Values-in-Table-Statement-tp4708534p4708593.html
Sent from the R help mailing list archive at Nabble.com.


From tanasa at gmail.com  Sat Jun 13 07:54:44 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Fri, 12 Jun 2015 22:54:44 -0700
Subject: [R] display a matrix in colors
In-Reply-To: <CA+8X3fUH2sa8oDO22eLZ6MjixWbmwhrDdwRiFTk3hmRScJq4HA@mail.gmail.com>
References: <CA+JEM03KQGBtbE0GbTV2JTbPAQq+nCk0ueHO7Fp4MmjTRF1z8w@mail.gmail.com>
	<5A5FBFBB-5A14-45C6-A24F-ADB9A14FC38F@comcast.net>
	<CA+JEM000yksGq5w5-JSTXUF6fiqYoLATK6rZkNxvGK+9nS40_g@mail.gmail.com>
	<CA+8X3fUH2sa8oDO22eLZ6MjixWbmwhrDdwRiFTk3hmRScJq4HA@mail.gmail.com>
Message-ID: <CA+JEM03tm4TrcVWZ+CmChsK+8Ry7wtStsz0HD-cy88BJ3ubCXg@mail.gmail.com>

Thanks, Jim. Yes, a good idea, shall I find more time, typically all these
little projects I am doing or asking are in big rush. Found some good
tutorials about heatmap.2 too:

http://www.inside-r.org/packages/cran/gplots/docs/heatmap.2

http://sebastianraschka.com/Articles/heatmaps_in_r.html

On Fri, Jun 12, 2015 at 8:41 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Bogdan,
> Have a look at color2D.matplot in the plotrix package - it's a bit
> different from "image" and "heatmap".
>
> Jim
>
>
> On Sat, Jun 13, 2015 at 10:39 AM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> > Hi David, thanks, yes,
> >
> > heatmap provides clustered heatmap, and I am looking for an unclustered
> > display of a matrix, and only to set up the color ranges. thanks for your
> > help !
> >
> > -- bogdan
> >
> > On Fri, Jun 12, 2015 at 5:36 PM, David Winsemius <dwinsemius at comcast.net
> >
> > wrote:
> >
> >>
> >>
> >> On Jun 12, 2015, at 5:28 PM, Bogdan Tanasa wrote:
> >>
> >> > Dear all,
> >> >
> >> > please could you advise about the most convenient functions or
> libraries
> >> to
> >> > use in order to display a matrix as a heatmap/a color matrix ?
> >> >
> >> > the matrix contains the values of 0, 10, 20, 30 or 100. thank you !
> >>
> >> What? You must have looked at `?heatmap` and the links on its help page,
> >> so what really is the question?
> >>
> >> >
> >> > -- bogdan
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> David Winsemius
> >> Alameda, CA, USA
> >>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tanasa at gmail.com  Sat Jun 13 07:57:28 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Fri, 12 Jun 2015 22:57:28 -0700
Subject: [R] display a matrix in colors
In-Reply-To: <A34EC87D-CE35-41B4-A88E-2CC817F01988@comcast.net>
References: <CA+JEM03KQGBtbE0GbTV2JTbPAQq+nCk0ueHO7Fp4MmjTRF1z8w@mail.gmail.com>
	<5A5FBFBB-5A14-45C6-A24F-ADB9A14FC38F@comcast.net>
	<CA+JEM000yksGq5w5-JSTXUF6fiqYoLATK6rZkNxvGK+9nS40_g@mail.gmail.com>
	<A34EC87D-CE35-41B4-A88E-2CC817F01988@comcast.net>
Message-ID: <CA+JEM02AhEvK4biqOymmwt8Sz5weYf53TbZ4KMpwUTrHvrKOhw@mail.gmail.com>

Thanks, David, for your time. I found some good tutorials on heatmap.2 and
it works :
https://www.packtpub.com/books/content/creating-your-first-heat-map-r

On Fri, Jun 12, 2015 at 9:12 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Jun 12, 2015, at 5:39 PM, Bogdan Tanasa wrote:
>
> > Hi David, thanks, yes,
> >
> > heatmap provides clustered heatmap, and I am looking for an unclustered
> display of a matrix,
>
> Please explain what "clustered"  means in the context of a heatmap.
>
> > and only to set up the color ranges.
>
> And that needs an explanation as well.
>
> > thanks for your help !
> >
> > -- bogdan
> >
> > On Fri, Jun 12, 2015 at 5:36 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> >
> > On Jun 12, 2015, at 5:28 PM, Bogdan Tanasa wrote:
> >
> > > Dear all,
> > >
> > > please could you advise about the most convenient functions or
> libraries to
> > > use in order to display a matrix as a heatmap/a color matrix ?
> > >
> > > the matrix contains the values of 0, 10, 20, 30 or 100. thank you !
> >
> > What? You must have looked at `?heatmap` and the links on its help page,
> so what really is the question?
> >
> > >
> > > -- bogdan
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From sreenath.rajur at macfast.ac.in  Sat Jun 13 07:09:56 2015
From: sreenath.rajur at macfast.ac.in (sreenath)
Date: Fri, 12 Jun 2015 22:09:56 -0700 (PDT)
Subject: [R] Colour gradient is not working.
In-Reply-To: <1433157134298-4708000.post@n4.nabble.com>
References: <1433157134298-4708000.post@n4.nabble.com>
Message-ID: <1434172196472-4708595.post@n4.nabble.com>

How can i use colour gradient according to y axis if the y values not
increasing gradualy



--
View this message in context: http://r.789695.n4.nabble.com/Colour-gradient-is-not-working-tp4708000p4708595.html
Sent from the R help mailing list archive at Nabble.com.


From boris.steipe at utoronto.ca  Sat Jun 13 15:17:59 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 13 Jun 2015 09:17:59 -0400
Subject: [R] Colour gradient is not working.
In-Reply-To: <1434172196472-4708595.post@n4.nabble.com>
References: <1433157134298-4708000.post@n4.nabble.com>
	<1434172196472-4708595.post@n4.nabble.com>
Message-ID: <713E2CE4-6B10-467C-931A-AACE9BDE41BB@utoronto.ca>

1. Don't ignore previous advice


On Jun 1, 2015, at 10:59 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:

> 1. Don't use Nabble for the r-help mailing list.
> 
> 2. Read the posting guide, and read http://adv-r.had.co.nz/Reproducibility.html
> 


2. Map your values to a range of integers that you can use as indices of your colour vector. The rank() function may be useful for this. However this is probably a bad idea from an information design point of view: it is likely that the resulting plot is misleading by presenting a continuity in colour where there is a discontinuity in values.


B.
PS. Seriously: don't ignore previous advice. I will not respond to further questions if you do.



On Jun 13, 2015, at 1:09 AM, sreenath <sreenath.rajur at macfast.ac.in> wrote:

> How can i use colour gradient according to y axis if the y values not
> increasing gradualy
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Colour-gradient-is-not-working-tp4708000p4708595.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thalitagabriella at gmail.com  Sat Jun 13 18:13:23 2015
From: thalitagabriella at gmail.com (Thalita Gabriella Zimmermann)
Date: Sat, 13 Jun 2015 18:13:23 +0200
Subject: [R] Post hoc ANCOVA
Message-ID: <CAEk6drWOO47y5tP7dinwsgOLWQzWYB8N41DqJhwuQfXb54Mjmg@mail.gmail.com>

My name is Thalita, and I am a Phd student from Brasil.

I am trying to do a post hoc of ANCOVA to compare three slopes with Tukey test.

I am using:

#percentagem: dependent variable
#tratamento: factor
#tempo: covariate


#ANCOVA

ancova(percentagem~tratamento*tempo, data=data)

summary(ancova(percentagem~tratamento*tempo, data=data))

mod<-ancova(percentagem~tratamento*tempo,data=data)

glht(mod, linfct=mcp(tratamento="Tukey"))

summary(glht(mod, linfct=mcp(tratamento="Tukey"))) ## but I think that

# compare just the intercep

So, I would like to know how can compare the three slopes.

I saw this page in internet
(https://stat.ethz.ch/pipermail/r-help/2012-February/303327.html), but
I did't understood how to compare.


Thankk you

Kind Regards

-- 

*Thalita Gabriella ZimmermannBi?loga, MSc.*
*Doutoranda em Bot?nica *


*Laborat?rio de Sementes - DIPEQInstituto de Pesquisas Jardim Bot?nico do
Rio de Janeiro*

	[[alternative HTML version deleted]]


From lessermatter at gmail.com  Sat Jun 13 21:16:14 2015
From: lessermatter at gmail.com (Matteo Villa)
Date: Sat, 13 Jun 2015 21:16:14 +0200
Subject: [R] Error in ginv(A) : 'X' must be a numeric or complex matrix
In-Reply-To: <CAOBWhm9paxC2YDoaCrd-GLHj24Kb_4sRfmYAUXJUFL8PPVcpRA@mail.gmail.com>
References: <CAOBWhm9paxC2YDoaCrd-GLHj24Kb_4sRfmYAUXJUFL8PPVcpRA@mail.gmail.com>
Message-ID: <CAOBWhm8puVpnaVfe3z9-8qhb10rMf+EqCZ_UjT6iN1=hHekxoA@mail.gmail.com>

Dear all,

I tried searching the archives for a problem that I encountered today, but
to no avail, so here I am sending my first e-mail to the list!
I am estimating a binary spatial autoregressive model via a Gibbs sampler.
When I do this with a neighborhood matrix, everything goes perfectly fine,
but when I switch to a distance matrix, the program stops almost
immediately, and outputs the infamous (but hardly ever occurring) line:
"Error in ginv(A) : 'X' must be a numeric or complex matrix"

What strikes me as odd is that when I try to compute the
generalized inverse myself, everything goes smoothly, and all the matrixes
seem to be numeric. Below you will find the data and code for the
replicable example.

Data for the replicable example:
https://gist.github.com/lessermatter/66b6488cfe6f5d7893bf

And here is the code (the error occurs after executing the final
line, which is also a toy model to be estimated through the bsar function):
https://gist.github.com/lessermatter/0284be117a19620750aa

Any ideas?

Kind regards,

Matteo Villa
Universit? degli Studi di Milano
Italy

	[[alternative HTML version deleted]]


From kris.singh at research.uwa.edu.au  Sat Jun 13 13:49:09 2015
From: kris.singh at research.uwa.edu.au (Kris Singh)
Date: Sat, 13 Jun 2015 19:49:09 +0800
Subject: [R] Boxplot function error-help required
In-Reply-To: <2769E0FD890.0000009Ajrkrideau@inbox.com>
References: <cahxci1b7zrjt2wt_ww3zqccd5pz8-c=sqma+x8=xda0mynfldw@mail.gmail.com>
	<D19F4E48.12DDBA%macqueen1@llnl.gov>
	<2769E0FD890.0000009Ajrkrideau@inbox.com>
Message-ID: <CAHXci1bKmiKq2f=YiLruiv2DfVNjntuqMU9ZZ63YVmrsZ+r15Q@mail.gmail.com>

Thank you all for the feedback.  I was actually amazed at not only the
number but quality of responses, and they were all helpful.  I have got it
working now, thanks again!

Kind regards,
Kris

2015-06-12 7:58 GMT+08:00 John Kane <jrkrideau at inbox.com>:

> Thanks Don,
>
> I suspected there was a Boxplot() out there by was too lazy to look.  I
> still don't see how the original code would work if label only had onevalue
> but I must admit what Boxplot() is actually doing is still confusing me.
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: macqueen1 at llnl.gov
> > Sent: Thu, 11 Jun 2015 21:44:39 +0000
> > To: kris.singh at research.uwa.edu.au, r-help at r-project.org
> > Subject: Re: [R] Boxplot function error-help required
> >
> > In addition to the other answers, I would suggest that the next time you
> > get the "could not find function" message, try like this:
> >
> >  help.search('Boxplot')
> >
> > Among the output from that you should see
> >
> >   graphics::boxplot                         Box Plots
> >
> > which should lead you to "boxplot" instead of "Boxplot".
> >
> >
> > You may see considerably more output from help.search(), depending on
> > what
> > packages you have installed. For example, when I did it, I found that the
> > car package has a function named "Boxplot".
> >
> > -Don
> >
> >
> > --
> > Don MacQueen
> >
> > Lawrence Livermore National Laboratory
> > 7000 East Ave., L-627
> > Livermore, CA 94550
> > 925-423-1062
> >
> >
> >
> >
> >
> > On 6/11/15, 4:20 AM, "Kris Singh" <kris.singh at research.uwa.edu.au>
> wrote:
> >
> > >Dear Sirm/Madam,
> >>
> > >Just wondering if someone could help me.  I've tried running a code on R
> > >and the code includes the following:
> >>
> >>> Boxplot(~Acc_S$Acc, label=Acc_S$Subj)
> >>
> > >But I receive the following  error message:
> >>
> > >*Error: could not find function "Boxplot"*
> >>
> > >I have tried installing all the packages but keep getting teh same error
> > >message.  The code runs on my supervisors R program and produces a
> > >boxplot,
> > >but doesn't on mine and am wondering if someone could assist me.
> >>
> > >Thanks in advance,
> > >Kris
> >>
> > >--
> > >*Kris Singh*
> > >Provisional Psychologist
> >>
> > >MPsych (Clinical Neuropsychology) / PhD Candidate
> > >Sanders Building, Room 1.10
> > >University of Western Australia
> > >35 Stirling Highway
> > >Crawley WA 6009
> >>
> > >Phone: (08) 6488 1418
> > >Email: kris.singh at research.uwa.edu.au
> >>
> > >     [[alternative HTML version deleted]]
> >>
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/manager
>
>
>


-- 
*Kris Singh*
Provisional Psychologist

MPsych (Clinical Neuropsychology) / PhD Candidate
Sanders Building, Room 1.10
University of Western Australia
35 Stirling Highway
Crawley WA 6009

Phone: (08) 6488 1418
Email: kris.singh at research.uwa.edu.au

	[[alternative HTML version deleted]]


From ramnik.bansal at gmail.com  Sat Jun 13 16:41:07 2015
From: ramnik.bansal at gmail.com (Ramnik Bansal)
Date: Sat, 13 Jun 2015 20:11:07 +0530
Subject: [R] R 3.2, Mac 10.10.3 : help.search showing error
Message-ID: <CAMLd9E6RZ6-QZfTpdxQbvkMr+b5UQL+p_DS3kjLbnB_tbgcWcw@mail.gmail.com>

Getting following error in using help.search

>utils::help.search("linear models")
Error in help(db[i, "topic"], package = db[i, "Package"], lib.loc = lib,  :
  'topic' should be a name, length-one character vector or reserved word


> example(help.search)

hlp.sr> help.search("linear models")    # In case you forgot how to fit
linear
Error in help(db[i, "topic"], package = db[i, "Package"], lib.loc = lib,  :
  'topic' should be a name, length-one character vector or reserved word


How to sort this?

	[[alternative HTML version deleted]]


From nia_gupta at yahoo.com  Sat Jun 13 17:04:50 2015
From: nia_gupta at yahoo.com (Nia Gupta)
Date: Sat, 13 Jun 2015 15:04:50 +0000 (UTC)
Subject: [R] Creating list with increasing string lengths
Message-ID: <813740194.2688370.1434207890501.JavaMail.yahoo@mail.yahoo.com>

Hello, 

I am trying to create a list where each name would have an increasing vector length. For example, I am trying to obtain something that looks like this: 

[[1]][1] 2
[[2]] 
[1] 2 4 

[[3]] 
[1] 1 2 3 
.....
The numbers generated would just be any random numbers. My thought was to use a for-loop and the sequence function but that doesn't seem to be working. Any help on this would be greatly appreciated. 

Thank you, 

Nia

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Jun 14 05:12:48 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 13 Jun 2015 20:12:48 -0700
Subject: [R] R 3.2, Mac 10.10.3 : help.search showing error
In-Reply-To: <CAMLd9E6RZ6-QZfTpdxQbvkMr+b5UQL+p_DS3kjLbnB_tbgcWcw@mail.gmail.com>
References: <CAMLd9E6RZ6-QZfTpdxQbvkMr+b5UQL+p_DS3kjLbnB_tbgcWcw@mail.gmail.com>
Message-ID: <F6F57E8C-3CCF-424C-B688-6AD25CBEE518@comcast.net>


On Jun 13, 2015, at 7:41 AM, Ramnik Bansal wrote:

> Getting following error in using help.search
> 
>> utils::help.search("linear models")
> Error in help(db[i, "topic"], package = db[i, "Package"], lib.loc = lib,  :
>  'topic' should be a name, length-one character vector or reserved word

I first tried this in a Mac running the SL version for R 3.1.2 and did not get this error. I updated my Mavericks laptop to R 3.2.0 and can now reproduce this error. It does not seem to depend on having a space in the argument. It seems to be thrown by this segment of code in the `help()`-function:

   ischar <- tryCatch(is.character(topic) && length(topic) == 
       1L, error = identity)
   if (inherits(ischar, "error")) 
       ischar <- FALSE
   if (!ischar) {
       reserved <- c("TRUE", "FALSE", "NULL", "Inf", "NaN", 
           "NA", "NA_integer_", "NA_real_", "NA_complex_", "NA_character_")
       stopic <- deparse(substitute(topic))
       if (!is.name(substitute(topic)) && !stopic %in% reserved) 
           stop("'topic' should be a name, length-one character vector or reserved word")

If gone through the `help.search` function code and cannot find where the `help` function is actually called. This seems unlikely to be a Mac-specific problem.

> 
> 
>> example(help.search)
> 
> hlp.sr> help.search("linear models")    # In case you forgot how to fit
> linear
> Error in help(db[i, "topic"], package = db[i, "Package"], lib.loc = lib,  :
>  'topic' should be a name, length-one character vector or reserved word
> 
> 
> How to sort this?
> 
> 	[[alternative HTML version deleted]]

David Winsemius
Alameda, CA, USA


From oriolebaltimore at gmail.com  Sun Jun 14 05:17:35 2015
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Sat, 13 Jun 2015 23:17:35 -0400
Subject: [R] matrix/df help populate NA
Message-ID: <CAL2fYnMWkgVb-Fez=Ytee2WUZzBo7oA+25xwskdcsPAgp=7RDA@mail.gmail.com>

Dear group:

I have two data frames. The column names of the two data frame has
some common variables but not identical.

my aim is to make 2  DFs more uniform by taking union of both colnames


For example: I have x1 and x2 matrices:

> x1
  Subject    A    B   C    D
1      x1  1.5 -1.3 0.4 -0.2
2      x2 -1.2 -0.3 0.3 -0.1
> x2
  Subject   A    D   F    H
1      x1 4.3 -2.4 1.3 -2.3
2      x2 2.4  0.1 0.5 -1.4

 cases = c('A','B','C','D','F','H')

for X2 I want to create newX2 DF.

> x3
  Subject   A  B  C    D   F    H
1      x1 4.3 NA NA -2.4 1.3 -2.3
2      x2 2.4 NA NA  0.1 0.5 -1.4


Since B and C are no existing in x2, I put NAs.

how can I create x3 matrix?



dput code:

x1 = structure(list(Subject = c("x1", "x2"), A = c(1.5, -1.2), B = c(-1.3,
-0.3), C = c(0.4, 0.3), D = c(-0.2, -0.1)), .Names = c("Subject",
"A", "B", "C", "D"), class = "data.frame", row.names = c(NA,
-2L))

x2 = structure(list(Subject = c("x1", "x2"), A = c(4.3, 2.4), D = c(-2.4,
0.1), F = c(1.3, 0.5), H = c(-2.3, -1.4)), .Names = c("Subject",
"A", "D", "F", "H"), class = "data.frame", row.names = c(NA,
-2L))


Could you please help how to create x3 with NAs incorporated.
adrian.


From jdnewmil at dcn.davis.CA.us  Sun Jun 14 06:08:31 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 13 Jun 2015 21:08:31 -0700
Subject: [R] matrix/df help populate NA
In-Reply-To: <CAL2fYnMWkgVb-Fez=Ytee2WUZzBo7oA+25xwskdcsPAgp=7RDA@mail.gmail.com>
References: <CAL2fYnMWkgVb-Fez=Ytee2WUZzBo7oA+25xwskdcsPAgp=7RDA@mail.gmail.com>
Message-ID: <FD51DCCA-31CD-48A0-BCC6-2BA187F4BAE3@dcn.davis.CA.us>

?merge

Particularly look at the all argument.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 13, 2015 8:17:35 PM PDT, Adrian Johnson <oriolebaltimore at gmail.com> wrote:
>Dear group:
>
>I have two data frames. The column names of the two data frame has
>some common variables but not identical.
>
>my aim is to make 2  DFs more uniform by taking union of both colnames
>
>
>For example: I have x1 and x2 matrices:
>
>> x1
>  Subject    A    B   C    D
>1      x1  1.5 -1.3 0.4 -0.2
>2      x2 -1.2 -0.3 0.3 -0.1
>> x2
>  Subject   A    D   F    H
>1      x1 4.3 -2.4 1.3 -2.3
>2      x2 2.4  0.1 0.5 -1.4
>
> cases = c('A','B','C','D','F','H')
>
>for X2 I want to create newX2 DF.
>
>> x3
>  Subject   A  B  C    D   F    H
>1      x1 4.3 NA NA -2.4 1.3 -2.3
>2      x2 2.4 NA NA  0.1 0.5 -1.4
>
>
>Since B and C are no existing in x2, I put NAs.
>
>how can I create x3 matrix?
>
>
>
>dput code:
>
>x1 = structure(list(Subject = c("x1", "x2"), A = c(1.5, -1.2), B =
>c(-1.3,
>-0.3), C = c(0.4, 0.3), D = c(-0.2, -0.1)), .Names = c("Subject",
>"A", "B", "C", "D"), class = "data.frame", row.names = c(NA,
>-2L))
>
>x2 = structure(list(Subject = c("x1", "x2"), A = c(4.3, 2.4), D =
>c(-2.4,
>0.1), F = c(1.3, 0.5), H = c(-2.3, -1.4)), .Names = c("Subject",
>"A", "D", "F", "H"), class = "data.frame", row.names = c(NA,
>-2L))
>
>
>Could you please help how to create x3 with NAs incorporated.
>adrian.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ramnik.bansal at gmail.com  Sun Jun 14 06:25:52 2015
From: ramnik.bansal at gmail.com (Ramnik Bansal)
Date: Sun, 14 Jun 2015 09:55:52 +0530
Subject: [R] R 3.2, Mac 10.10.3 : help.search showing error
In-Reply-To: <F6F57E8C-3CCF-424C-B688-6AD25CBEE518@comcast.net>
References: <CAMLd9E6RZ6-QZfTpdxQbvkMr+b5UQL+p_DS3kjLbnB_tbgcWcw@mail.gmail.com>
	<F6F57E8C-3CCF-424C-B688-6AD25CBEE518@comcast.net>
Message-ID: <CAMLd9E5b0X6kVs2U2Q=km+mSAxWdhjKskvn0_+JeMRmyxHkG7w@mail.gmail.com>

Thanks. But it seems to be an R 3.2.0 specific problem.

On Sun, Jun 14, 2015 at 8:42 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Jun 13, 2015, at 7:41 AM, Ramnik Bansal wrote:
>
> > Getting following error in using help.search
> >
> >> utils::help.search("linear models")
> > Error in help(db[i, "topic"], package = db[i, "Package"], lib.loc =
> lib,  :
> >  'topic' should be a name, length-one character vector or reserved word
>
> I first tried this in a Mac running the SL version for R 3.1.2 and did not
> get this error. I updated my Mavericks laptop to R 3.2.0 and can now
> reproduce this error. It does not seem to depend on having a space in the
> argument. It seems to be thrown by this segment of code in the
> `help()`-function:
>
>    ischar <- tryCatch(is.character(topic) && length(topic) ==
>        1L, error = identity)
>    if (inherits(ischar, "error"))
>        ischar <- FALSE
>    if (!ischar) {
>        reserved <- c("TRUE", "FALSE", "NULL", "Inf", "NaN",
>            "NA", "NA_integer_", "NA_real_", "NA_complex_", "NA_character_")
>        stopic <- deparse(substitute(topic))
>        if (!is.name(substitute(topic)) && !stopic %in% reserved)
>            stop("'topic' should be a name, length-one character vector or
> reserved word")
>
> If gone through the `help.search` function code and cannot find where the
> `help` function is actually called. This seems unlikely to be a
> Mac-specific problem.
>
> >
> >
> >> example(help.search)
> >
> > hlp.sr> help.search("linear models")    # In case you forgot how to fit
> > linear
> > Error in help(db[i, "topic"], package = db[i, "Package"], lib.loc =
> lib,  :
> >  'topic' should be a name, length-one character vector or reserved word
> >
> >
> > How to sort this?
> >
> >       [[alternative HTML version deleted]]
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Jun 14 07:00:13 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 13 Jun 2015 22:00:13 -0700
Subject: [R] R 3.2, Mac 10.10.3 : help.search showing error
In-Reply-To: <CAMLd9E5b0X6kVs2U2Q=km+mSAxWdhjKskvn0_+JeMRmyxHkG7w@mail.gmail.com>
References: <CAMLd9E6RZ6-QZfTpdxQbvkMr+b5UQL+p_DS3kjLbnB_tbgcWcw@mail.gmail.com>
	<F6F57E8C-3CCF-424C-B688-6AD25CBEE518@comcast.net>
	<CAMLd9E5b0X6kVs2U2Q=km+mSAxWdhjKskvn0_+JeMRmyxHkG7w@mail.gmail.com>
Message-ID: <26EC34FA-10FD-43B6-8D0F-4879797701D5@comcast.net>


On Jun 13, 2015, at 9:25 PM, Ramnik Bansal wrote:

> Thanks. But it seems to be an R 3.2.0 specific problem.

Exactly. That's why I needed to take the time to update my installation. I posted a message to R-devel after failing to find where the code was different in the two versions and not getting any understanding from tracing the 'help'-function. 

I do see in the R 3.1.2 version that this code:

if (!missing(pattern)) {
        if (!is.character(pattern) || (length(pattern) > 1L)) 
            stop(.wrong_args("pattern"), domain = NA)
        i <- pmatch(fields, FIELDS)
        if (anyNA(i)) 
            stop("incorrect field specification")
        else fields <- FIELDS[i]
   }

 was changed .... to this:

if (!missing(pattern)) {
       if (!is.character(pattern) || (length(pattern) > 1L)) 
           stop(.wrong_args("pattern"), domain = NA)
       i <- pmatch(fields, hsearch_db_fields)
       if (anyNA(i)) 
           stop("incorrect field specification")
       else fields <- hsearch_db_fields[i]
   }


And I see this in the NEWS file:

	? New function hsearch_db() in package utils for building and retrieving the help search database used byhelp.search(), along with functions for inspecting the concepts and keywords in the help search database.



-- 
David.
> 
> On Sun, Jun 14, 2015 at 8:42 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> On Jun 13, 2015, at 7:41 AM, Ramnik Bansal wrote:
> 
> > Getting following error in using help.search
> >
> >> utils::help.search("linear models")
> > Error in help(db[i, "topic"], package = db[i, "Package"], lib.loc = lib,  :
> >  'topic' should be a name, length-one character vector or reserved word
> 
> I first tried this in a Mac running the SL version for R 3.1.2 and did not get this error. I updated my Mavericks laptop to R 3.2.0 and can now reproduce this error. It does not seem to depend on having a space in the argument. It seems to be thrown by this segment of code in the `help()`-function:
> 
>    ischar <- tryCatch(is.character(topic) && length(topic) ==
>        1L, error = identity)
>    if (inherits(ischar, "error"))
>        ischar <- FALSE
>    if (!ischar) {
>        reserved <- c("TRUE", "FALSE", "NULL", "Inf", "NaN",
>            "NA", "NA_integer_", "NA_real_", "NA_complex_", "NA_character_")
>        stopic <- deparse(substitute(topic))
>        if (!is.name(substitute(topic)) && !stopic %in% reserved)
>            stop("'topic' should be a name, length-one character vector or reserved word")
> 
> If gone through the `help.search` function code and cannot find where the `help` function is actually called. This seems unlikely to be a Mac-specific problem.
> 
> >
> >
> >> example(help.search)
> >
> > hlp.sr> help.search("linear models")    # In case you forgot how to fit
> > linear
> > Error in help(db[i, "topic"], package = db[i, "Package"], lib.loc = lib,  :
> >  'topic' should be a name, length-one character vector or reserved word
> >
> >
> > How to sort this?
> >
> >       [[alternative HTML version deleted]]
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Sun Jun 14 07:06:21 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 13 Jun 2015 22:06:21 -0700
Subject: [R] Creating list with increasing string lengths
In-Reply-To: <813740194.2688370.1434207890501.JavaMail.yahoo@mail.yahoo.com>
References: <813740194.2688370.1434207890501.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbTAUnbBeZX=D2Txxr8txZ6Bw2pLH6nq14OJ_a60qEot6Q@mail.gmail.com>

Is this homework? Homework is deprecated here.

?lapply

is one of many possible approaches. If this is not homework, showing your
unsuccessful code would likely lead to a better learning experience for you.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Sat, Jun 13, 2015 at 8:04 AM, Nia Gupta via R-help <r-help at r-project.org>
wrote:

> Hello,
>
> I am trying to create a list where each name would have an increasing
> vector length. For example, I am trying to obtain something that looks like
> this:
>
> [[1]][1] 2
> [[2]]
> [1] 2 4
>
> [[3]]
> [1] 1 2 3
> .....
> The numbers generated would just be any random numbers. My thought was to
> use a for-loop and the sequence function but that doesn't seem to be
> working. Any help on this would be greatly appreciated.
>
> Thank you,
>
> Nia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Sun Jun 14 08:04:16 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 14 Jun 2015 08:04:16 +0200
Subject: [R] R 3.2, Mac 10.10.3 : help.search showing error
In-Reply-To: <CAMLd9E5b0X6kVs2U2Q=km+mSAxWdhjKskvn0_+JeMRmyxHkG7w@mail.gmail.com>
References: <CAMLd9E6RZ6-QZfTpdxQbvkMr+b5UQL+p_DS3kjLbnB_tbgcWcw@mail.gmail.com>
	<F6F57E8C-3CCF-424C-B688-6AD25CBEE518@comcast.net>
	<CAMLd9E5b0X6kVs2U2Q=km+mSAxWdhjKskvn0_+JeMRmyxHkG7w@mail.gmail.com>
Message-ID: <2727AFA1-E41C-4D6E-9B1B-959A6F0A4B63@xs4all.nl>


> On 14-06-2015, at 06:25, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
> 
> Thanks. But it seems to be an R 3.2.0 specific problem.
> 

I replied with the following to a similar message on R-devel.

????????????????????????
See this thread on R-SIG-Mac

https://stat.ethz.ch/pipermail/r-sig-mac/2015-April/011420.html

This may help.
Get R 3.2.0-patched or even the release candidate for R 3.2.1
????????????????????????

Berend


> On Sun, Jun 14, 2015 at 8:42 AM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> 
>> 
>> On Jun 13, 2015, at 7:41 AM, Ramnik Bansal wrote:
>> 
>>> Getting following error in using help.search
>>> 
>>>> utils::help.search("linear models")
>>> Error in help(db[i, "topic"], package = db[i, "Package"], lib.loc =
>> lib,  :
>>> 'topic' should be a name, length-one character vector or reserved word
>> 
>> I first tried this in a Mac running the SL version for R 3.1.2 and did not
>> get this error. I updated my Mavericks laptop to R 3.2.0 and can now
>> reproduce this error. It does not seem to depend on having a space in the
>> argument. It seems to be thrown by this segment of code in the
>> `help()`-function:
>> 
>>   ischar <- tryCatch(is.character(topic) && length(topic) ==
>>       1L, error = identity)
>>   if (inherits(ischar, "error"))
>>       ischar <- FALSE
>>   if (!ischar) {
>>       reserved <- c("TRUE", "FALSE", "NULL", "Inf", "NaN",
>>           "NA", "NA_integer_", "NA_real_", "NA_complex_", "NA_character_")
>>       stopic <- deparse(substitute(topic))
>>       if (!is.name(substitute(topic)) && !stopic %in% reserved)
>>           stop("'topic' should be a name, length-one character vector or
>> reserved word")
>> 
>> If gone through the `help.search` function code and cannot find where the
>> `help` function is actually called. This seems unlikely to be a
>> Mac-specific problem.
>> 
>>> 
>>> 
>>>> example(help.search)
>>> 
>>> hlp.sr> help.search("linear models")    # In case you forgot how to fit
>>> linear
>>> Error in help(db[i, "topic"], package = db[i, "Package"], lib.loc =
>> lib,  :
>>> 'topic' should be a name, length-one character vector or reserved word
>>> 
>>> 
>>> How to sort this?
>>> 
>>>      [[alternative HTML version deleted]]
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lessermatter at gmail.com  Sun Jun 14 10:07:25 2015
From: lessermatter at gmail.com (Matteo Villa)
Date: Sun, 14 Jun 2015 10:07:25 +0200
Subject: [R] Error in ginv(A) : 'X' must be a numeric or complex matrix
Message-ID: <CAOBWhm_ObxGpsXpJdy4gV+YzQF2zucCeixFJnsfEDAJq=17DZg@mail.gmail.com>

Dear all,

I encountered a problem that has been bugging me for some hours now,
and I still can't come up with a viable solution. I tried searching
the archives, but to no avail, so here I am sending my first e-mail to
the list!
I am estimating a binary spatial autoregressive model via a Gibbs
sampler. When I do this with a neighborhood matrix, everything goes
perfectly fine, but when I switch to a distance matrix, the program
stops almost immediately, and outputs the famous (but hardly ever
occurring):
"Error in ginv(A) : 'X' must be a numeric or complex matrix"

What strikes me as odd is that when I try to compute the generalized
inverse myself, everything goes smoothly, and all the matrixes seem to
be numeric. Below you will find the data and code for the replicable
example.

Data for the replicable example:
https://gist.github.com/lessermatter/66b6488cfe6f5d7893bf

And here is the code (the error occurs after executing the final line,
which is also a toy model to be estimated through the bsar function):
https://gist.github.com/lessermatter/0284be117a19620750aa

Any ideas?

Kind regards,

Matteo Villa
Universit? degli Studi di Milano
Italy


From drjimlemon at gmail.com  Sun Jun 14 13:02:03 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 14 Jun 2015 21:02:03 +1000
Subject: [R] Creating list with increasing string lengths
In-Reply-To: <CAGxFJbTAUnbBeZX=D2Txxr8txZ6Bw2pLH6nq14OJ_a60qEot6Q@mail.gmail.com>
References: <813740194.2688370.1434207890501.JavaMail.yahoo@mail.yahoo.com>
	<CAGxFJbTAUnbBeZX=D2Txxr8txZ6Bw2pLH6nq14OJ_a60qEot6Q@mail.gmail.com>
Message-ID: <CA+8X3fXy7hAaTX8rE=ZVVvAGEx7g0NRaj6wsG90aSxNV+wm2Bg@mail.gmail.com>

Hi Nia,
Many ways to do something like this, for example:

N<-6
sapply(1:N,function(x) return(sample(1:10,x,TRUE)))

I'll let you work out how to generalize this.

Jim


On Sun, Jun 14, 2015 at 3:06 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Is this homework? Homework is deprecated here.
>
> ?lapply
>
> is one of many possible approaches. If this is not homework, showing your
> unsuccessful code would likely lead to a better learning experience for you.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge is
> certainly not wisdom."
>    -- Clifford Stoll
>
> On Sat, Jun 13, 2015 at 8:04 AM, Nia Gupta via R-help <r-help at r-project.org>
> wrote:
>
>> Hello,
>>
>> I am trying to create a list where each name would have an increasing
>> vector length. For example, I am trying to obtain something that looks like
>> this:
>>
>> [[1]][1] 2
>> [[2]]
>> [1] 2 4
>>
>> [[3]]
>> [1] 1 2 3
>> .....
>> The numbers generated would just be any random numbers. My thought was to
>> use a for-loop and the sequence function but that doesn't seem to be
>> working. Any help on this would be greatly appreciated.
>>
>> Thank you,
>>
>> Nia
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Jun 14 17:18:18 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 14 Jun 2015 08:18:18 -0700
Subject: [R] R 3.2, Mac 10.10.3 : help.search showing error
In-Reply-To: <2727AFA1-E41C-4D6E-9B1B-959A6F0A4B63@xs4all.nl>
References: <CAMLd9E6RZ6-QZfTpdxQbvkMr+b5UQL+p_DS3kjLbnB_tbgcWcw@mail.gmail.com>
	<F6F57E8C-3CCF-424C-B688-6AD25CBEE518@comcast.net>
	<CAMLd9E5b0X6kVs2U2Q=km+mSAxWdhjKskvn0_+JeMRmyxHkG7w@mail.gmail.com>
	<2727AFA1-E41C-4D6E-9B1B-959A6F0A4B63@xs4all.nl>
Message-ID: <1FA3D4D1-9DE8-4668-8F03-1F2C58AA4553@comcast.net>


On Jun 13, 2015, at 11:04 PM, Berend Hasselman wrote:

> 
>> On 14-06-2015, at 06:25, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
>> 
>> Thanks. But it seems to be an R 3.2.0 specific problem.
>> 
> 
> I replied with the following to a similar message on R-devel.

There was no error either with using help() or using the Mac GUI package manager. Those were the reported difficulties previously reported.

> 
> ????????????????????????
> See this thread on R-SIG-Mac
> 
> https://stat.ethz.ch/pipermail/r-sig-mac/2015-April/011420.html
> 
> This may help.
> Get R 3.2.0-patched or even the release candidate for R 3.2.1
> ????????????????????????

 The error I am getting was from the most recent R 3.2.0 downloaded yesterday. There is no 3.2.0-Patched for Mavericks.  The release candidate, R 3.2.1 RC, is marked on the ATT Research webpage as failing Make and it indeed fails to launch. I would NOT recommend that anyone accept that advice. 

But maybe it is a Mac-specific problem. When I remove the crippled R 3.2.1 RC and reinstall the R 3.2.0 and run from a Terminal window I do not get the help.search() error. So copying to R SIG Mac, and will not copy R-help on any further efforts.

-- 
David.



> 
> Berend
> 
> 
>> On Sun, Jun 14, 2015 at 8:42 AM, David Winsemius <dwinsemius at comcast.net>
>> wrote:
>> 
>>> 
>>> On Jun 13, 2015, at 7:41 AM, Ramnik Bansal wrote:
>>> 
>>>> Getting following error in using help.search
>>>> 
>>>>> utils::help.search("linear models")
>>>> Error in help(db[i, "topic"], package = db[i, "Package"], lib.loc =
>>> lib,  :
>>>> 'topic' should be a name, length-one character vector or reserved word
>>> 
>>> I first tried this in a Mac running the SL version for R 3.1.2 and did not
>>> get this error. I updated my Mavericks laptop to R 3.2.0 and can now
>>> reproduce this error. It does not seem to depend on having a space in the
>>> argument. It seems to be thrown by this segment of code in the
>>> `help()`-function:
>>> 
>>>  ischar <- tryCatch(is.character(topic) && length(topic) ==
>>>      1L, error = identity)
>>>  if (inherits(ischar, "error"))
>>>      ischar <- FALSE
>>>  if (!ischar) {
>>>      reserved <- c("TRUE", "FALSE", "NULL", "Inf", "NaN",
>>>          "NA", "NA_integer_", "NA_real_", "NA_complex_", "NA_character_")
>>>      stopic <- deparse(substitute(topic))
>>>      if (!is.name(substitute(topic)) && !stopic %in% reserved)
>>>          stop("'topic' should be a name, length-one character vector or
>>> reserved word")
>>> 
>>> If gone through the `help.search` function code and cannot find where the
>>> `help` function is actually called. This seems unlikely to be a
>>> Mac-specific problem.
>>> 
>>>> 
>>>> 
>>>>> example(help.search)
>>>> 
>>>> hlp.sr> help.search("linear models")    # In case you forgot how to fit
>>>> linear
>>>> Error in help(db[i, "topic"], package = db[i, "Package"], lib.loc =
>>> lib,  :
>>>> 'topic' should be a name, length-one character vector or reserved word
>>>> 
>>>> 
>>>> How to sort this?
>>>> 
>>>>     [[alternative HTML version deleted]]
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 

David Winsemius
Alameda, CA, USA


From armandres at gmail.com  Sun Jun 14 18:15:12 2015
From: armandres at gmail.com (=?utf-8?Q?Andr=C3=A9s_Arag=C3=B3n_Mart=C3=ADnez?=)
Date: Sun, 14 Jun 2015 11:15:12 -0500
Subject: [R] Help with abs function
In-Reply-To: <FFD3AE11-0541-417D-B5A3-19E86F1E224F@dcn.davis.CA.us>
References: <DE681B198BF90743B3B4BD64035E63F88C64E95830@ES-MSG-EMB-002.es.govt.state.ma.us>
	<DE681B198BF90743B3B4BD64035E63F88C64E95831@ES-MSG-EMB-002.es.govt.state.ma.us>
	<FFD3AE11-0541-417D-B5A3-19E86F1E224F@dcn.davis.CA.us>
Message-ID: <5FAA0124-21BD-4154-BC0F-C14AAE402CC3@gmail.com>

Hi,

Just do the following:


> tran<-c(7.2)
> tgrid<-c(7.1,7.4,7.3,7.1,7.3)
> tgrid<-tgrid-tran
> tgrid
[1] -0.1  0.2  0.1 -0.1  0.1
> abs(tgrid[tgrid>0.1])
[1] 0.2

Andr?s



> El 12/06/2015, a las 11:01, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> escribi?:
> 
> FAQ 7.31
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On June 12, 2015 8:39:48 AM PDT, "Nelson, Gary (MISC)" <gary.nelson at state.ma.us> wrote:
>> I have come across some odd behavior (to me) using the abs() function
>> that I wonder if anyone can explain.
>> 
>> Using  R version 3.2.0, I created a vector of absolute values using 
>> the following code:
>> 
>>> tran<-c(7.2)
>>> tgrid<-c(7.1,7.4,7.3,7.1,7.3)
>>> dgrid<-abs(tgrid-tran)
>>> dgrid
>> [1] 0.1 0.2 0.1 0.1 0.1
>> 
>> When I tried to extract just the rows with values>0.1, I get
>> 
>>> dgrid[dgrid>0.1]
>> [1] 0.1 0.2 0.1
>> 
>> There should be only 1 value extracted.
>> 
>> However, if I enter the values by hand
>> 
>>> bgrid<-c(0.1,0.2,0.1,0.1,0.1)
>>> bgrid
>> [1] 0.1 0.2 0.1 0.1 0.1
>>> bgrid[bgrid>0.1]
>> [1] 0.2
>> 
>> The result is correct.  So why is this happening?
>> 
>> I did explore a little bit and found
>> 
>>> as.character(dgrid)
>> [1] "0.100000000000001"  "0.2"
>> [3] "0.0999999999999996" "0.100000000000001"
>> [5] "0.0999999999999996"
>> 
>> which shows the absolute values of the negative differences  are
>> slightly greater than the difference of 0.1
>> 
>> Is this normal behavior for the abs() function?
>> 
>> Thanks,
>> 
>> Gary Nelson
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ragia11 at hotmail.com  Mon Jun 15 01:04:47 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Mon, 15 Jun 2015 02:04:47 +0300
Subject: [R] most frequent value
Message-ID: <DUB125-W65D27771EC2F8823AB39C4B3B90@phx.gbl>

Dear group,
I have the following integer object

> a 

3 4 6 
3 3 6 

how to get the most frequent value (it should be 3)

and get nothing if no frequent one and all is equal

3 4 6 
3 4 6 
Thanks in advance
Ragia
 		 	   		  
	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Jun 15 01:35:05 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 15 Jun 2015 09:35:05 +1000
Subject: [R] most frequent value
In-Reply-To: <DUB125-W65D27771EC2F8823AB39C4B3B90@phx.gbl>
References: <DUB125-W65D27771EC2F8823AB39C4B3B90@phx.gbl>
Message-ID: <CA+8X3fX-6o=O4k43yvjWgNo2VsVQKdRJkthTe5ykYCYXUNEeXA@mail.gmail.com>

Hi Ragia,
The basic method is to use "table" and examine the result:

> a<-matrix(c(3,3,4,3,6,6),nrow=2)
> b<-matrix(c(3,3,4,4,6,6),nrow=2)
> table(a)
a
3 4 6
3 1 2

but you can get the modal value directly like this:

library(prettyR)
Mode(a)
[1] "3"
Mode(b)
[1] ">1 mode"

Jim

On Mon, Jun 15, 2015 at 9:04 AM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:
> Dear group,
> I have the following integer object
>
>> a
>
> 3 4 6
> 3 3 6
>
> how to get the most frequent value (it should be 3)
>
> and get nothing if no frequent one and all is equal
>
> 3 4 6
> 3 4 6
> Thanks in advance
> Ragia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Mon Jun 15 02:00:28 2015
From: jholtman at gmail.com (jim holtman)
Date: Sun, 14 Jun 2015 20:00:28 -0400
Subject: [R] matrix/df help populate NA
In-Reply-To: <CAL2fYnMWkgVb-Fez=Ytee2WUZzBo7oA+25xwskdcsPAgp=7RDA@mail.gmail.com>
References: <CAL2fYnMWkgVb-Fez=Ytee2WUZzBo7oA+25xwskdcsPAgp=7RDA@mail.gmail.com>
Message-ID: <CAAxdm-5nFizZgf_GuwdgxM6YnCAvz44dF=h7BrnJVv5Rp3NYZw@mail.gmail.com>

Is this what you want:

> x1 = structure(list(Subject = c("x1", "x2"), A = c(1.5, -1.2), B = c(-1.3,
+ -0.3), C = c(0.4, 0.3), D = c(-0.2, -0.1)), .Names = c("Subject",
+ "A", "B", "C", "D"), class = "data.frame", row.names = c(NA,
+ -2L))
>
> x2 = structure(list(Subject = c("x1", "x2"), A = c(4.3, 2.4), D = c(-2.4,
+ 0.1), F = c(1.3, 0.5), H = c(-2.3, -1.4)), .Names = c("Subject",
+ "A", "D", "F", "H"), class = "data.frame", row.names = c(NA,
+ -2L))
>
> # determine what the missing columns are and then add them to x2
> missing <- setdiff(colnames(x1), colnames(x2))
>
> new_x2 <- x2
>
> for (i in missing) new_x2[[i]] <- NA
>
> new_x2
  Subject   A    D   F    H  B  C
1      x1 4.3 -2.4 1.3 -2.3 NA NA
2      x2 2.4  0.1 0.5 -1.4 NA NA





Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sat, Jun 13, 2015 at 11:17 PM, Adrian Johnson <oriolebaltimore at gmail.com>
wrote:

> Dear group:
>
> I have two data frames. The column names of the two data frame has
> some common variables but not identical.
>
> my aim is to make 2  DFs more uniform by taking union of both colnames
>
>
> For example: I have x1 and x2 matrices:
>
> > x1
>   Subject    A    B   C    D
> 1      x1  1.5 -1.3 0.4 -0.2
> 2      x2 -1.2 -0.3 0.3 -0.1
> > x2
>   Subject   A    D   F    H
> 1      x1 4.3 -2.4 1.3 -2.3
> 2      x2 2.4  0.1 0.5 -1.4
>
>  cases = c('A','B','C','D','F','H')
>
> for X2 I want to create newX2 DF.
>
> > x3
>   Subject   A  B  C    D   F    H
> 1      x1 4.3 NA NA -2.4 1.3 -2.3
> 2      x2 2.4 NA NA  0.1 0.5 -1.4
>
>
> Since B and C are no existing in x2, I put NAs.
>
> how can I create x3 matrix?
>
>
>
> dput code:
>
> x1 = structure(list(Subject = c("x1", "x2"), A = c(1.5, -1.2), B = c(-1.3,
> -0.3), C = c(0.4, 0.3), D = c(-0.2, -0.1)), .Names = c("Subject",
> "A", "B", "C", "D"), class = "data.frame", row.names = c(NA,
> -2L))
>
> x2 = structure(list(Subject = c("x1", "x2"), A = c(4.3, 2.4), D = c(-2.4,
> 0.1), F = c(1.3, 0.5), H = c(-2.3, -1.4)), .Names = c("Subject",
> "A", "D", "F", "H"), class = "data.frame", row.names = c(NA,
> -2L))
>
>
> Could you please help how to create x3 with NAs incorporated.
> adrian.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Mon Jun 15 02:08:34 2015
From: jholtman at gmail.com (jim holtman)
Date: Sun, 14 Jun 2015 20:08:34 -0400
Subject: [R] Scatterplot : smoothing colors according to density of
	points
In-Reply-To: <CAN5YmCGEkKo0MvE63n0uo-CufA+syY4nxyZajz30rW2UCe8Sew@mail.gmail.com>
References: <6E68B6E864DACF4C890BA4AA3D87139238C71C83@IBWMBX02>
	<CAN5YmCGEkKo0MvE63n0uo-CufA+syY4nxyZajz30rW2UCe8Sew@mail.gmail.com>
Message-ID: <CAAxdm-693Eui3K4zqsh5zMDatM2f-vO=FhL0h20DHWs5EJ=sbw@mail.gmail.com>

check out the 'hexbin' package for making scatter plots that have a lot of
points overlapping in a small area.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Tue, Jun 2, 2015 at 9:51 AM, Adams, Jean <jvadams at usgs.gov> wrote:

> Try this.
>
> Jean
>
> D <- structure(list(
>   id = structure(1:6, .Label = c("O13297", "O13329", "O13525",
>     "O13539", "O13541", "O13547"), class = "factor"),
>   X = c(44.444444, 31.272085, 6.865672, 14.176245, 73.275862,
>     28.991597),
>   Y = c(21.6122, 4.0159, 2.43884, 7.81217, 3.59012, 258.999)),
>   .Names = c("id", "X", "Y"), class = "data.frame",
>   row.names = c("1", "2", "3", "4", "5", "6"))
>
> # define the number of colors
> ncol <- 100
> # define the radius of the neighborhood
> distcut <- 30
> pal <- colorRampPalette(c("blue", "yellow", "red"))(ncol)
>
> # calculate the euclidean distance between all pairs of points, based on X,
> Y coordinates
> Ddist <- with(D, as.matrix(dist(cbind(X, Y), diag=TRUE, upper=TRUE)))
> # count up the number of neighbors within distcut distance of each point
> D$C <- apply(Ddist<distcut, 2, sum)
> # use this count to define the levels (which will be then used to color
> points in the plot
> D$Clevels <- with(D,
>   cut(C, breaks=seq(min(C), max(C), length.out=ncol+1),
>     labels=FALSE, include.lowest=TRUE))
>
> # plot the data
> with(D, plot(X, Y, col=pal[Clevels], log="y", pch=16))
>
>
>
> On Tue, Jun 2, 2015 at 5:37 AM, Benjamin Dubreuil <
> benjamin.dubreuil at weizmann.ac.il> wrote:
>
> > Hello everyone,
> >
> > I have a data frame D with 4 columns id,X,Y,C.
> > I want to plot a simple scatter plot of D$X vs. D$Y and using D$C values
> > as a color. (id is just a text string not used for the plot)
> >
> > But actually, I don't want to use the raw values of D$C, I would prefer
> to
> > calculate the average values of D$C according to the density of points
> in a
> > fixed neighborhood.
> > In other words, I would like to smooth the colors according to the
> density
> > of points.
> >
> > I am looking for any function,package that could solve this.
> > So far, I've been looking at library MASS and the function kde2d which
> can
> > calculate the density of points in 2 directions, but I don't see how I
> > could then use this information to recalculate my D$C values.
> >
> > Here is a piece of the matrix :
> >  > head(D)
> >       id         X         Y            C
> > 1 O13297 44.444444  21.61220 -0.136651639
> > 2 O13329 31.272085   4.01590 -0.117016949
> > 3 O13525  6.865672   2.43884 -0.161173913
> > 4 O13539 14.176245   7.81217 -0.075756757
> > 5 O13541 73.275862   3.59012 -0.006988235
> > 6 O13547 28.991597 258.99900 -0.013985507
> >
> > > dim(D)
> > [1] 3616    4
> >
> > > apply(D[,-1],2,range)
> >                X          Y          C
> > [1,]   0.3378378     0.0003 -0.7382222
> > [2,] 100.0000000 24556.4000  0.5582500
> > (Y is not linear, so I use log='y' in the plot function)
> >
> > I used a palette of 100 colors ranging from Blue to Yellow to red.
> > >pal =  colorRampPalette(c("blue","yellow","red"))(100)
> >
> > To make D$C values correspond to a color, I used a cut with the following
> > breaks (101 breaks from -1.2 to 1.2):
> > > BREAKS
> >   [1] -1.2000 -0.8000 -0.4000 -0.3600 -0.3200 -0.2800 -0.2400 -0.2000
> > -0.1925
> >  [10] -0.1850 -0.1775 -0.1700 -0.1625 -0.1550 -0.1475 -0.1400 -0.1368
> > -0.1336
> >  [19] -0.1304 -0.1272 -0.1240 -0.1208 -0.1176 -0.1144 -0.1112 -0.1080
> > -0.1048
> >  [28] -0.1016 -0.0984 -0.0952 -0.0920 -0.0888 -0.0856 -0.0824 -0.0792
> > -0.0760
> >  [37] -0.0728 -0.0696 -0.0664 -0.0632 -0.0600 -0.0568 -0.0536 -0.0504
> > -0.0472
> >  [46] -0.0440 -0.0408 -0.0376 -0.0344 -0.0312 -0.0280 -0.0248 -0.0216
> > -0.0184
> >  [55] -0.0152 -0.0120 -0.0088 -0.0056 -0.0024  0.0008  0.0040  0.0072
> > 0.0104
> >  [64]  0.0136  0.0168  0.0200  0.0232  0.0264  0.0296  0.0328  0.0360
> > 0.0392
> >  [73]  0.0424  0.0456  0.0488  0.0520  0.0552  0.0584  0.0616  0.0648
> > 0.0680
> >  [82]  0.0712  0.0744  0.0776  0.0808  0.0840  0.0872  0.0904  0.0936
> > 0.0968
> >  [91]  0.1000  0.1250  0.1500  0.1750  0.2000  0.2250  0.2500  0.4875
> > 0.7250
> > [100]  0.9625  1.2000
> > > C.levels = as.numeric(cut(D$C,breaks=BREAKS))
> > >length(C.levels)
> > [1] 3616
> >
> > C.levels ranges from 2 to 98 and then to plot the colors I used
> > pal[C.levels].
> > > plot( x=D$x, y=D$Y, col=pal[ C.levels ],log='y')
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Mon Jun 15 03:41:10 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sun, 14 Jun 2015 20:41:10 -0500
Subject: [R] Milisecond problem in as.POSIXct ?
In-Reply-To: <CAPPM_gR7bxdyAkxRuiUqYcKLEzXp=RReBQbT_v9WSTONPio-gw@mail.gmail.com>
References: <20150610204144.24020@web005.roc2.bluetie.com>
	<CAPPM_gR7bxdyAkxRuiUqYcKLEzXp=RReBQbT_v9WSTONPio-gw@mail.gmail.com>
Message-ID: <CAPPM_gQiSmMFhA4f0WSj7D2LBfLbNkaDefyV3Kh4O8sqt-cEWA@mail.gmail.com>

On Wed, Jun 10, 2015 at 8:05 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
>
> This is known behavior with how POSIXt objects are printed.  See the discussion on StackOverflow: http://stackoverflow.com/questions/7726034/how-r-formats-posixct-with-fractional-seconds
>
To summarize the relevant portion of the discussion on StackOverflow:

I believe the behavior is due to truncating the fractional seconds
instead of rounding, combined with the floating point representation
of the POSIXct time (though I would need to take a closer look at
do_formatPOSIXlt to verify).  If you look at the underlying double
value of the POSIXct object, you can see why the printed value in the
first example below is 0.2s and the printed value for the second
example is 0.4s.

R> sprintf("%20.10f", as.POSIXct('2011-10-11 07:49:36.3', tz="UTC"))
[1] "1318319376.2999999523"
R> sprintf("%20.10f", as.POSIXct('2011-10-11 07:49:36.4', tz="UTC"))
[1] "1318319376.4000000954"

> On Wed, Jun 10, 2015 at 7:41 PM, ce <zadig_1 at excite.com> wrote:
>>
>> Dear all,
>>
>> my main problem is with miliseconds. I have an array :
>>
>> library(xts)
>> options(digits.secs = 3)
>> > x
>> [1] "2015-06-10 10:22:06.389 EDT" "2015-06-10 10:22:07.473 EDT"
>> [3] "2015-06-10 10:22:08.717 EDT" "2015-06-10 10:22:09.475 EDT"
>>
>> > x[1]
>> [1] "2015-06-10 10:22:06.38 EDT"
>> > x[2]
>> [1] "2015-06-10 10:22:07.473 EDT"
>>
>> why it cuts last digit of miliseconds 389 to 38 ? ( it doesn't cut 473 !! )
>>
>> I try to dump it to post here:
>>
>> > dump("x",file=stdout())
>>
>> x <-
>> structure(c(1433946126.39, 1433946127.474, 1433946128.717, 1433946129.476
>> ), tzone = "", tclass = c("POSIXct", "POSIXt"), class = c("POSIXct",
>> "POSIXt"))
>>
>> new array becomes :
>>
>> > x
>> [1] "2015-06-10 10:22:06.390 EDT" "2015-06-10 10:22:07.473 EDT"
>> [3] "2015-06-10 10:22:08.717 EDT" "2015-06-10 10:22:09.476 EDT"
>>
>> this time first milisecond 389 became 390 ?  and last element 475 became 476 ?
>>
>> I do some more tests :
>>
>> as.POSIXct("2015-06-10 10:22:07.473",format='%Y-%m-%d %H:%M:%OS')
>> [1] "2015-06-10 10:22:07.473 EDT"
>>
>> is correct, but :
>>
>> as.POSIXct("2015-06-10 10:22:06.389",format='%Y-%m-%d %H:%M:%OS')
>> [1] "2015-06-10 10:22:06.388 EDT"
>>
>> why miliseconds turn to 388 instead of 389 ?
>>
>> or
>>
>>  as.POSIXct("2015-06-10 10:22:07.478",format='%Y-%m-%d %H:%M:%OS')
>> [1] "2015-06-10 10:22:07.477 EDT"
>>
>>  why it shows 477 instead of 478
>>
>> > sessionInfo()
>> R version 3.2.0 (2015-04-16)
>> Platform: x86_64-suse-linux-gnu (64-bit)
>> Running under: openSUSE 13.2 (Harlequin) (x86_64)
>>
>> locale:
>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] xts_0.9-7  zoo_1.7-12
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.2.0     grid_3.2.0      lattice_0.20-31
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com


-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From f.harrell at Vanderbilt.Edu  Mon Jun 15 04:22:07 2015
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Sun, 14 Jun 2015 21:22:07 -0500
Subject: [R] Different behavior of model.matrix between R 3.2 and R3.1.1
In-Reply-To: <2f3a88$qka43@ironport10.mayo.edu>
References: <2f3a88$qka43@ironport10.mayo.edu>
Message-ID: <557E36CF.6010302@vanderbilt.edu>

Terry - your example didn't demonstrate the problem because the variable 
that interacted with strata (zed) was not a factor variable.

But I had stated the problem incorrectly.  It's not that there are too 
many strata terms; there are too many non-strata terms when the variable 
interacting with the stratification factor is a factor variable.  Here 
is a simple example, where I have attached no packages other than the 
basic startup packages.

strat <- function(x) x
d <- expand.grid(a=c('a1','a2'), b=c('b1','b2'))
d$y <- c(1,3,2,4)
f <- y ~ a * strat(b)
m <- model.frame(f, data=d)
Terms <- terms(f, specials='strat', data=d)
specials <- attr(Terms, 'specials')
temp <- survival:::untangle.specials(Terms, 'strat', 1)
Terms <- Terms[- temp$terms]
model.matrix(Terms, m)

   (Intercept) aa2 aa1:strat(b)b2 aa2:strat(b)b2
1           1   0              0              0
2           1   1              0              0
3           1   0              1              0
4           1   1              0              1
. . .

The column corresponding to a='a1' b='b2' should not be there 
(aa1:strat(b)b2).

This does seem to be a change in R.  Any help appreciated.

Note that after subsetting out strat terms using Terms[ - temp$terms], 
Terms attributes factor and term.labels are:

attr(,"factors")
          a a:strat(b)
y        0          0
a        1          2
strat(b) 0          1
attr(,"term.labels")
[1] "a"          "a:strat(b)"


Frank


On 06/11/2015 08:44 AM, Therneau, Terry M., Ph.D. wrote:
> Frank,
>    I'm not sure what is going on.  The following test function works for
> me in both 3.1.1 and 3.2, i.e, the second model matrix has fewer
> columns.  As I indicated to you earlier, the coxph code removes the
> strata() columns after creating X because I found it easier to correctly
> create the assign attribute.
>
>    Can you create a worked example?
>
> require(survival)
> testfun <- function(formula, data) {
>      tform <- terms(formula, specials="strata")
>      mf <- model.frame(tform, data)
>
>      terms2 <- terms(mf)
>      strat <- untangle.specials(terms2, "strata")
>      if (length(strat$terms)) terms2 <- terms2[-strat$terms]
>      X <- model.matrix(terms2, mf)
>      X
> }
>
> tdata <- data.frame(y= 1:10, zed = 1:10, grp =
> factor(c(1,1,1,2,2,2,1,1,3,3)))
>
> testfun(y ~ zed*grp, tdata)
>
> testfun(y ~ strata(grp)*zed, tdata)
>
>
> Terry T.
>
> ----- original message --
>
> For building design matrices for Cox proportional hazards models in the
> cph function in the rms package I have always used this construct:
>
> Terms <- terms(formula, specials=c("strat", "cluster", "strata"),
> data=data)
> specials <- attr(Terms, 'specials')
> stra    <- specials$strat
> Terms.ns     <- Terms
>       if(length(stra)) {
>         temp <- untangle.specials(Terms.ns, "strat", 1)
>         Terms.ns <- Terms.ns[- temp$terms]    #uses [.terms function
>       }
> X <- model.matrix(Terms.ns, X)[, -1, drop=FALSE]
>
> The Terms.ns logic removes stratification factor "main effects" so that
> if a stratification factor interacts with a non-stratification factor,
> only the interaction terms are included, not the strat. factor main
> effects. [In a Cox PH model stratification goes into the nonparametric
> survival curve part of the model].
>
> Lately this logic quit working; model.matrix keeps the unneeded main
> effects in the design matrix.  Does anyone know what changed in R that
> could have caused this, and possibly a workaround?
>
>
> -------
>
>

-- 
------------------------------------------------------------------------
Frank E Harrell Jr      	Professor and Chairman      	School of Medicine
	Department of *Biostatistics*      	*Vanderbilt University*


From oriolebaltimore at gmail.com  Mon Jun 15 06:58:53 2015
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Mon, 15 Jun 2015 00:58:53 -0400
Subject: [R] matrix/df help populate NA
In-Reply-To: <CAAxdm-5nFizZgf_GuwdgxM6YnCAvz44dF=h7BrnJVv5Rp3NYZw@mail.gmail.com>
References: <CAL2fYnMWkgVb-Fez=Ytee2WUZzBo7oA+25xwskdcsPAgp=7RDA@mail.gmail.com>
	<CAAxdm-5nFizZgf_GuwdgxM6YnCAvz44dF=h7BrnJVv5Rp3NYZw@mail.gmail.com>
Message-ID: <CAL2fYnOPPf1veTrvZkfXqwKEWVyFcXifxpWF44VW6XoX43AGMQ@mail.gmail.com>

Thank you very much. It worked!


On Sun, Jun 14, 2015 at 8:00 PM, jim holtman <jholtman at gmail.com> wrote:
> Is this what you want:
>
>> x1 = structure(list(Subject = c("x1", "x2"), A = c(1.5, -1.2), B = c(-1.3,
> + -0.3), C = c(0.4, 0.3), D = c(-0.2, -0.1)), .Names = c("Subject",
> + "A", "B", "C", "D"), class = "data.frame", row.names = c(NA,
> + -2L))
>>
>> x2 = structure(list(Subject = c("x1", "x2"), A = c(4.3, 2.4), D = c(-2.4,
> + 0.1), F = c(1.3, 0.5), H = c(-2.3, -1.4)), .Names = c("Subject",
> + "A", "D", "F", "H"), class = "data.frame", row.names = c(NA,
> + -2L))
>>
>> # determine what the missing columns are and then add them to x2
>> missing <- setdiff(colnames(x1), colnames(x2))
>>
>> new_x2 <- x2
>>
>> for (i in missing) new_x2[[i]] <- NA
>>
>> new_x2
>   Subject   A    D   F    H  B  C
> 1      x1 4.3 -2.4 1.3 -2.3 NA NA
> 2      x2 2.4  0.1 0.5 -1.4 NA NA
>
>
>
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Sat, Jun 13, 2015 at 11:17 PM, Adrian Johnson <oriolebaltimore at gmail.com>
> wrote:
>>
>> Dear group:
>>
>> I have two data frames. The column names of the two data frame has
>> some common variables but not identical.
>>
>> my aim is to make 2  DFs more uniform by taking union of both colnames
>>
>>
>> For example: I have x1 and x2 matrices:
>>
>> > x1
>>   Subject    A    B   C    D
>> 1      x1  1.5 -1.3 0.4 -0.2
>> 2      x2 -1.2 -0.3 0.3 -0.1
>> > x2
>>   Subject   A    D   F    H
>> 1      x1 4.3 -2.4 1.3 -2.3
>> 2      x2 2.4  0.1 0.5 -1.4
>>
>>  cases = c('A','B','C','D','F','H')
>>
>> for X2 I want to create newX2 DF.
>>
>> > x3
>>   Subject   A  B  C    D   F    H
>> 1      x1 4.3 NA NA -2.4 1.3 -2.3
>> 2      x2 2.4 NA NA  0.1 0.5 -1.4
>>
>>
>> Since B and C are no existing in x2, I put NAs.
>>
>> how can I create x3 matrix?
>>
>>
>>
>> dput code:
>>
>> x1 = structure(list(Subject = c("x1", "x2"), A = c(1.5, -1.2), B = c(-1.3,
>> -0.3), C = c(0.4, 0.3), D = c(-0.2, -0.1)), .Names = c("Subject",
>> "A", "B", "C", "D"), class = "data.frame", row.names = c(NA,
>> -2L))
>>
>> x2 = structure(list(Subject = c("x1", "x2"), A = c(4.3, 2.4), D = c(-2.4,
>> 0.1), F = c(1.3, 0.5), H = c(-2.3, -1.4)), .Names = c("Subject",
>> "A", "D", "F", "H"), class = "data.frame", row.names = c(NA,
>> -2L))
>>
>>
>> Could you please help how to create x3 with NAs incorporated.
>> adrian.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From petr.pikal at precheza.cz  Mon Jun 15 10:18:08 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 15 Jun 2015 08:18:08 +0000
Subject: [R] Missing Values in Table Statement
In-Reply-To: <1434170183472-4708593.post@n4.nabble.com>
References: <1434087634952-4708534.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C309DA@SRVEXCHMBX.precheza.cz>
	<1434090467055-4708537.post@n4.nabble.com>
	<D1A06140.12DF12%macqueen1@llnl.gov>
	<1434170183472-4708593.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C30C99@SRVEXCHMBX.precheza.cz>

Hi

Why you are so reluctant to use dput for sending us part of your data?

The result of str indicates that that SCH_TIME is character vector in which some values are time and others are **empty** strings. But empty string does not mean it is missing string.

***Empty bottle of whisky is not missing bottle of whisky***.

So is.na correctly finds that none of your values are missing.

see this example

test<-sample(letters[1:5], 10, replace=T)
test[5:7]<-NA
str(test)
 chr [1:10] "b" "a" "d" "e" NA NA NA "d" "d" "c"

table(is.na(test))

FALSE  TRUE
    7     3

test[5:7]<-""
str(test)
 chr [1:10] "b" "a" "d" "e" "" "" "" "d" "d" "c"
table(is.na(test))

FALSE
   10

Cheers
Petr





> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shivi82
> Sent: Saturday, June 13, 2015 6:36 AM
> To: r-help at r-project.org
> Subject: Re: [R] Missing Values in Table Statement
>
> HI Don,
>
> This is the exact result i need. However in my case i am not getting
> any value under TRUE whereas FALSE captures total observations in each
> variable.
> Please find the syntax and output from the code:
> table(test$ORIGIN_NAME,is.na(test$SCH_TIME))
>
> Output
>                                  FALSE
>   BAHADURGARH            15
>   BAREILLY                    44
>   BAWAL                        34
>   DELHI-11                   2446
>   DELHI-39                   170
>   DELHI-40                   86
>   DELHI NCR-12            1925
>
> The data from str is attached:
> data.frame':  10765 obs. of  18 variables:
>  $ ORIGIN         : chr  "DLI11" "DLI11" "NDA50" "NDA50" ...
>  $ ORIGIN_NAME    : chr  "DELHI-11" "DELHI-11" "NOIDA-50" "NOIDA-50"
> ...
>  $ DESTINATION    : chr  "NDA50" "NDA50" "DLI11" "NDA11" ...
>  $ DESTINATION_NM : chr  "NOIDA-50" "NOIDA-50" "DELHI-11" "NOIDA-11"
> ...
>  $ RPS_NO         : int  1350760 1366368 1352692 1354642 1354642
> 1349180
> 1349180 1356091 1348591 1348591 ...
>  $ VENDOR_NAME    : chr  "RAJIV GAUTAM" "RAJIV GAUTAM" "RAJIV GAUTAM"
> "RAJIV
> GAUTAM" ...
>  $ CR_DT          : chr  "13-Mar-15" "31-Mar-15" "15-Mar-15" "17-Mar-
> 15" ...
>  $ SCHD_MRKT      : chr  "SCHEDULE" "SCHEDULE" "SCHEDULE" "MARKET" ...
>  $ VHL_NO         : chr  "HR63A0931" "HR63A0931" "HR63A0931"
> "HR63A0931" ...
>  $ vhl_cap        : int  8 8 8 8 8 8 8 8 8 8 ...
>  $ SCH_TIME       : chr  "6:00" "6:00" "21:30" "" ...
>  $ ACTUAL_DEP_DATE: chr  "13/03/2015" "31/03/2015" "15/03/2015"
> "17/03/2015"
> ...
>  $ ACTUAL_DEP_TIME: chr  "6:30" "4:05" "13:37" "20:15" ...
>  $ WAYBILLS       : chr  "-" "-" "-" "3" ...
>  $ TOTAL_PKG      : int  0 0 0 40 256 6 0 0 16 427 ...
>  $ ACTUAL_WT      : int  0 0 0 744 3419 65 0 0 193 7223 ...
>  $ CHG_WT         : int  0 0 0 770 3730 70 0 0 210 7310 ...
>  $ RTE_CD         : chr  "DELHI-11-NOIDA-50(DLI11-NDA50)"
> "DELHI-11-NOIDA-50(DLI11-NDA50)" "NOIDA-50-DELHI-11(NDA50-DLI11)"
> "NOIDA-50-DELHI-11(NDA50-NDA11-DLI11)"
> Scheduled time here is character, could this be the reason for the
> incorrect result.
>
> Thanks, Shivi
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Missing-
> Values-in-Table-Statement-tp4708534p4708593.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ragia11 at hotmail.com  Mon Jun 15 12:48:14 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Mon, 15 Jun 2015 13:48:14 +0300
Subject: [R] community
In-Reply-To: <CA+8X3fX-6o=O4k43yvjWgNo2VsVQKdRJkthTe5ykYCYXUNEeXA@mail.gmail.com>
References: <DUB125-W65D27771EC2F8823AB39C4B3B90@phx.gbl>,
	<CA+8X3fX-6o=O4k43yvjWgNo2VsVQKdRJkthTe5ykYCYXUNEeXA@mail.gmail.com>
Message-ID: <DUB125-W730D8A014DDBB83DA020A3B3B80@phx.gbl>

Dear group
working on a graph..I parse the graph node by node and create cluster for set of nodes..firstly the number of clusters are not knowen
what kind of R object can I flexibly use as community, say I want M communities
C1,C2..CM
how can I define this ?

thanks in advance
Ragia
 		 	   		  
	[[alternative HTML version deleted]]


From therneau at mayo.edu  Mon Jun 15 16:05:39 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 15 Jun 2015 09:05:39 -0500
Subject: [R] Different behavior of model.matrix between R 3.2 and R3.1.1
In-Reply-To: <557E36CF.6010302@vanderbilt.edu>
References: <2f3a88$qka43@ironport10.mayo.edu>
	<557E36CF.6010302@vanderbilt.edu>
Message-ID: <2f3a88$r82p3@ironport10.mayo.edu>

Frank,
   I don't think there is any way to "fix" your problem except the way that I did it.

library(survival)
tdata <- data.frame(y=c(1,3,3,5, 5,7, 7,9, 9,13),
                     x1=factor(letters[c(1,1,1,1,1,2,2,2,2,2)]),
                     x2= c(1,2,1,2,1,2,1,2,1,2))

fit1 <- lm( y ~ x1 * strata(x2) - strata(x2), tdata)
coef(fit1)
        (Intercept)                x1b x1a:strata(x2)x2=2 x1b:strata(x2)x2=2
           3.000000           5.000000           1.000000           1.666667

Your code is calling model.matrix with the same model frame and terms structure as the lm 
call above (I checked).  In your case you know that the underlying model has 2 intercepts 
(strata), one for the group with x2=1 and another for the group with x2=2, but how is the 
model.matrix routine supposed to guess that?  It can't, so model.matrix returns the proper 
result for the lm call.  As seen above the result is not singular, while for the Cox model 
it is singular due to the extra intercept.

This is simply an extension of leaving the "intercept" term in the model and then removing 
that column from the returned X matrix, which is necessary to have the correct coding for 
ordinary factor variables, something we've both done since day 1.  In order for 
model.matrix to do the right thing with interactions, it has to know how many intercepts 
there actually are.

I've come to the conclusion that the entire thrust of 'contrasts' in S was wrong headed, 
i.e., the "remove redundant columns from the X matrix ahead of time" logic.  It is simply 
not possible for the model.matrix routine to guess correctly for all y and x combinations, 
something that been acknowledged in R by changing the default for "singular.ok" to TRUE. 
Dealing with this after the fact via a good contrast function (a la SAS -- heresy!) would 
have been a much better design choice.  But as long as I'm in R the coxph routine tries to 
be a good citizen.

Terry T.


From Mohan.Radhakrishnan at cognizant.com  Mon Jun 15 12:51:29 2015
From: Mohan.Radhakrishnan at cognizant.com (Mohan.Radhakrishnan at cognizant.com)
Date: Mon, 15 Jun 2015 10:51:29 +0000
Subject: [R] Error bars and CI
Message-ID: <E1B160F4999FD6449524E16C2CB94E0307691E80@CTSINCHNSXMBE.cts.com>

Hi,

I want to plot a line graph using this data. IDX is x-axis and V1 is y-axis.  I also want standard error bars and 99% CI to be shown. My code is given below. The section that plots the graph is the problem.  I don't see all the points in the line graph with error bars. How can I also show the 99% CI in the graph ?

      V1 IDX
1  0.987  21
2  0.585  22
3  0.770  23
4  0.711  24

library(stringr)
library(dplyr)
library(ggplot2)

data <- read.table("D:\\jmh\\jmh.txt",sep="\t")

final <-data %>%
           select(V1) %>%
              filter(grepl("^Iteration", V1)) %>%
        mutate(V1 = str_extract(V1, "\\d+\\.\\d*"))

final <- mutate(final,IDX = 1:n())

jc <- final %>%
              filter(IDX < 21)


#Convert to numeric
jc <- data.frame(sapply(jc, function(x) as.numeric(as.character(x))))

print(jc)

# The following section is the problem.

sem <- function(x){
       sd(x)/sqrt(length(x))
}

meanvalue <- apply(jc,2,mean)
semvalue <- apply(jc, 2, sem)

mean_sem <- data.frame(mean= meanvalue, sem= semvalue, group=names(jc))

#larger font
theme_set(theme_gray(base_size = 20))

#plot using ggplot
p <- ggplot(mean_sem, aes(x=group, y=mean)) +
              geom_line(stat='identity') +
              geom_errorbar(aes(ymin=mean-sem, ymax=mean+sem),
                           width=.2)
print(p)

Thanks,
Mohan
This e-mail and any files transmitted with it are for the sole use of the intended recipient(s) and may contain confidential and privileged information. If you are not the intended recipient(s), please reply to the sender and destroy all copies of the original message. Any unauthorized review, use, disclosure, dissemination, forwarding, printing or copying of this email, and/or any action taken in reliance on the contents of this e-mail is strictly prohibited and may be unlawful. Where permitted by applicable law, this e-mail and other e-mail communications sent to and from Cognizant e-mail addresses may be monitored.

	[[alternative HTML version deleted]]


From preet.balaji20 at gmail.com  Mon Jun 15 13:19:59 2015
From: preet.balaji20 at gmail.com (Preethi Balaji)
Date: Mon, 15 Jun 2015 12:19:59 +0100
Subject: [R]  Boxplot using a shapefile
Message-ID: <CABPcpMw4EZ2SQLBi36ZGuXZevzW3rWaw1So8MP-j283n=cZV2Q@mail.gmail.com>

Dear all,

I am trying to generate boxplots by giving a shapefile and an image as
input. The shapefile takes the pixel values from the image and shows
the distribution of pixels in the form of a boxplot.

Can somebody please tell me how I can execute this in R?

Many thanks!

-- 

Regards,
Preethi Malur Balaji | PhD Student
University College Cork | Cork, Ireland.


From humphrey.zhao at yahoo.com  Mon Jun 15 15:38:47 2015
From: humphrey.zhao at yahoo.com (Humphrey Zhao)
Date: Mon, 15 Jun 2015 13:38:47 +0000 (UTC)
Subject: [R] Question about saving the context crawled by getNodeSet into a
 document
Message-ID: <2035461594.3044713.1434375527335.JavaMail.yahoo@mail.yahoo.com>

Dear?Sir/Madam:

Thank?you?for?your?concern.?I?m?using?getNodeSet?in?XML?package?to?craw?data?from?web?pages,?and?I?need?to?save?it?as?a?document.?However,?I?tried?write.table,?write,?and?cat,?but?none?of?above?could?save?the?data.?The?error?messages?just?like?these:

>?ac<-getNodeSet(article,?"//div[@class='entry-content']")?#attention?to?the?majuscule>?write.table(ac[[1]],?file="E:/????????/article.txt")Error?in?as.data.frame.default(x[[i]],?optional?=?TRUE)?:?

??c("cannot?coerce?class?\"c(\"XMLInternalElementNode\",?\"XMLInternalNode\",?\"XMLAbstractNode\"\"?to?a?data.frame",?"cannot?coerce?class?\")\"?to?a?data.frame")

>?write(ac,?file="E:/????????/article.txt")Error?in?cat(list(...),?file,?sep,?fill,?labels,?append)?:?

??argument?1?(type?'list')?cannot?be?handled?by?'cat'

I?have?tried?to?force?the?data?from?getNodeSet?into?data?frame,?but?it?does?not?work?either:

>?tmp?<-?data.frame(ac)Error?in?as.data.frame.default(x[[i]],?optional?=?TRUE,?stringsAsFactors?=?stringsAsFactors)?:?

?????""XMLNodeSet""?????????

I?really?confused?how?to?save?the?data?crawled by getNodeSet into a document.?I?wonder?if?you?could?give?me?some?advice?on?solving?this?problem?with?R.?And?I?would?be?most?grateful?if?you?could?reply?at?your?earliest?convenience.?Looking?forward?to?hearing?from?you.?Thank?you?very?much.

?????????????????????????????????????Sincerely?yours?

?????????????????????????????????????Humphrey?Zhao
	[[alternative HTML version deleted]]


From perossichi at gmail.com  Mon Jun 15 05:50:54 2015
From: perossichi at gmail.com (Peter Rossi)
Date: Sun, 14 Jun 2015 20:50:54 -0700
Subject: [R] [R-pkgs] version 3.0-0 of bayesm
Message-ID: <CANGRwOarTpGUeOVJpyLABxtfrx7W19G+M5T7LQT1cB5_64gy-Q@mail.gmail.com>

Version 3.0-0 of bayesm is now on CRAN.

All MCMC routines in this version have been recoded using rcpp-Armadillo.
This results in speeds gains
of between 2 and 30 times faster (hierarchical and density estimation
routines are on the higher end of this range) than
in bayesm version 2.2-5.

The algorithm, rsurGibbs, has been improved for better speed as well as
recoded.

A Bayesian treatment of aggregate random coefficient models (with
instruments) has been added, see rbayesBLP.

peter rossi
thanks to Neil Fultz, Keunwoo Kim, and Wayne Taylor for their help in the
recoding.

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From djamilmaliou at gmail.com  Mon Jun 15 15:37:19 2015
From: djamilmaliou at gmail.com (MALIOU Djamil)
Date: Mon, 15 Jun 2015 06:37:19 -0700
Subject: [R] Request
Message-ID: <CAKa=VQNuEGOBzt9eHbFbi4r=4NaME=_-6TLNP0bmBzf5Btr5iA@mail.gmail.com>

Dear Sir or Madame,
I am a novice in R, and I want to perform a meta analysis of case control
studies (analytic), i want a step by step explanation if it's possible,
Thanks.
Cordially,

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Mon Jun 15 18:14:16 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 15 Jun 2015 17:14:16 +0100
Subject: [R] Request
In-Reply-To: <CAKa=VQNuEGOBzt9eHbFbi4r=4NaME=_-6TLNP0bmBzf5Btr5iA@mail.gmail.com>
References: <CAKa=VQNuEGOBzt9eHbFbi4r=4NaME=_-6TLNP0bmBzf5Btr5iA@mail.gmail.com>
Message-ID: <557EF9D8.4000008@dewey.myzen.co.uk>

Dear Djamil

On 15/06/2015 14:37, MALIOU Djamil wrote:
> Dear Sir or Madame,
> I am a novice in R, and I want to perform a meta analysis of case control
> studies (analytic), i want a step by step explanation if it's possible,

You can find details about packages which support meta-analysis in R in 
the Task View
http://CRAN.R-project.org/view=MetaAnalysis

Without more details of what you want to do it is hard to offer any more 
hints.

> Thanks.
> Cordially,
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From boris.steipe at utoronto.ca  Mon Jun 15 19:52:29 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 15 Jun 2015 13:52:29 -0400
Subject: [R] Boxplot using a shapefile
In-Reply-To: <CABPcpMw4EZ2SQLBi36ZGuXZevzW3rWaw1So8MP-j283n=cZV2Q@mail.gmail.com>
References: <CABPcpMw4EZ2SQLBi36ZGuXZevzW3rWaw1So8MP-j283n=cZV2Q@mail.gmail.com>
Message-ID: <566944AC-4584-45D0-9BDA-C79EEC6ECBD1@utoronto.ca>

Your workflow in principle is:

- read the image into an object for which you can obtain values-per-pixel in a 2D structure;
- read the shapefile and convert into a polygon;
- determine the bounding box of the polygon;
- use the inout() function of the splancs package to get a list of booleans for the
    points in the bounding box, TRUE if they are _inside_ the polygon;
- subset your image points to those for which inout() returns TRUE;
- plot as boxplot().

The CRAN taskview http://cran.r-project.org/web/views/MedicalImaging.html has a section on general image processing, guiding you to helpful packages.

Ask again if you get stuck - but(!):
- see here for some hints on how to ask questions productively:
  http://adv-r.had.co.nz/Reproducibility.html
  http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
- ... and please read the posting guide and don't post in HTML.


B.


On Jun 15, 2015, at 7:19 AM, Preethi Balaji <preet.balaji20 at gmail.com> wrote:

> Dear all,
> 
> I am trying to generate boxplots by giving a shapefile and an image as
> input. The shapefile takes the pixel values from the image and shows
> the distribution of pixels in the form of a boxplot.
> 
> Can somebody please tell me how I can execute this in R?
> 
> Many thanks!
> 
> -- 
> 
> Regards,
> Preethi Malur Balaji | PhD Student
> University College Cork | Cork, Ireland.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Jun 14 17:18:18 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 14 Jun 2015 08:18:18 -0700
Subject: [R] [R-SIG-Mac]  R 3.2, Mac 10.10.3 : help.search showing error
In-Reply-To: <2727AFA1-E41C-4D6E-9B1B-959A6F0A4B63@xs4all.nl>
References: <CAMLd9E6RZ6-QZfTpdxQbvkMr+b5UQL+p_DS3kjLbnB_tbgcWcw@mail.gmail.com>
	<F6F57E8C-3CCF-424C-B688-6AD25CBEE518@comcast.net>
	<CAMLd9E5b0X6kVs2U2Q=km+mSAxWdhjKskvn0_+JeMRmyxHkG7w@mail.gmail.com>
	<2727AFA1-E41C-4D6E-9B1B-959A6F0A4B63@xs4all.nl>
Message-ID: <1FA3D4D1-9DE8-4668-8F03-1F2C58AA4553@comcast.net>


On Jun 13, 2015, at 11:04 PM, Berend Hasselman wrote:

> 
>> On 14-06-2015, at 06:25, Ramnik Bansal <ramnik.bansal at gmail.com> wrote:
>> 
>> Thanks. But it seems to be an R 3.2.0 specific problem.
>> 
> 
> I replied with the following to a similar message on R-devel.

There was no error either with using help() or using the Mac GUI package manager. Those were the reported difficulties previously reported.

> 
> ????????????????????????
> See this thread on R-SIG-Mac
> 
> https://stat.ethz.ch/pipermail/r-sig-mac/2015-April/011420.html
> 
> This may help.
> Get R 3.2.0-patched or even the release candidate for R 3.2.1
> ????????????????????????

 The error I am getting was from the most recent R 3.2.0 downloaded yesterday. There is no 3.2.0-Patched for Mavericks.  The release candidate, R 3.2.1 RC, is marked on the ATT Research webpage as failing Make and it indeed fails to launch. I would NOT recommend that anyone accept that advice. 

But maybe it is a Mac-specific problem. When I remove the crippled R 3.2.1 RC and reinstall the R 3.2.0 and run from a Terminal window I do not get the help.search() error. So copying to R SIG Mac, and will not copy R-help on any further efforts.

-- 
David.



> 
> Berend
> 
> 
>> On Sun, Jun 14, 2015 at 8:42 AM, David Winsemius <dwinsemius at comcast.net>
>> wrote:
>> 
>>> 
>>> On Jun 13, 2015, at 7:41 AM, Ramnik Bansal wrote:
>>> 
>>>> Getting following error in using help.search
>>>> 
>>>>> utils::help.search("linear models")
>>>> Error in help(db[i, "topic"], package = db[i, "Package"], lib.loc =
>>> lib,  :
>>>> 'topic' should be a name, length-one character vector or reserved word
>>> 
>>> I first tried this in a Mac running the SL version for R 3.1.2 and did not
>>> get this error. I updated my Mavericks laptop to R 3.2.0 and can now
>>> reproduce this error. It does not seem to depend on having a space in the
>>> argument. It seems to be thrown by this segment of code in the
>>> `help()`-function:
>>> 
>>>  ischar <- tryCatch(is.character(topic) && length(topic) ==
>>>      1L, error = identity)
>>>  if (inherits(ischar, "error"))
>>>      ischar <- FALSE
>>>  if (!ischar) {
>>>      reserved <- c("TRUE", "FALSE", "NULL", "Inf", "NaN",
>>>          "NA", "NA_integer_", "NA_real_", "NA_complex_", "NA_character_")
>>>      stopic <- deparse(substitute(topic))
>>>      if (!is.name(substitute(topic)) && !stopic %in% reserved)
>>>          stop("'topic' should be a name, length-one character vector or
>>> reserved word")
>>> 
>>> If gone through the `help.search` function code and cannot find where the
>>> `help` function is actually called. This seems unlikely to be a
>>> Mac-specific problem.
>>> 
>>>> 
>>>> 
>>>>> example(help.search)
>>>> 
>>>> hlp.sr> help.search("linear models")    # In case you forgot how to fit
>>>> linear
>>>> Error in help(db[i, "topic"], package = db[i, "Package"], lib.loc =
>>> lib,  :
>>>> 'topic' should be a name, length-one character vector or reserved word
>>>> 
>>>> 
>>>> How to sort this?
>>>> 
>>>>     [[alternative HTML version deleted]]
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 

David Winsemius
Alameda, CA, USA

_______________________________________________
R-SIG-Mac mailing list
R-SIG-Mac at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mac


From Douglas.Federman at utoledo.edu  Mon Jun 15 22:12:50 2015
From: Douglas.Federman at utoledo.edu (Federman, Douglas)
Date: Mon, 15 Jun 2015 20:12:50 +0000
Subject: [R] search across a row for strings
Message-ID: <F1065E5D886F4D429259CDEAE3F83CB61AF48C99@msgdb20.utad.utoledo.edu>

I'm trying to do the following: search each patient's list of diagnoses for a specific code then create a new column based upon the the presence of the specific code.  
Simplified data follows:

con <- textConnection("
ID	DX1	DX2	DX3
1	4109	4280	7102
2	734	311	490
3	4011	42822	4101
")
df <- read.table(con, header = TRUE, strip.white = TRUE, colClasses="character")
#
# I would like to add a column such the result of searching for 410 would give:  The search string would always be at the start of a word and doesn't need regex.
#
# ID	DX1	DX2	DX3	htn
# 1	4109	4280	7102	1
# 2	734	311	490	0
# 3	4011	42822	4101	1
#
# The following  works but is slow and returns NA if the search string is not found:

for (i in 1:nrow(df)) {
    df[i,"htn"] <- any(sapply('410', function(x)  which( grepl(x, df[i, 2:4], fixed = TRUE) )))
}

Thanks in advance.  I never fail to learn new things from this list.

--
Who is wise? One who learns from every person.
Who is strong? One who overpowers his evil inclinations.
Who is rich? One who is satisfied with his lot.
Who is honorable? One who honors his fellows.
- Pirkei Avot [excerpt]


From sarah.goslee at gmail.com  Mon Jun 15 22:29:37 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 15 Jun 2015 16:29:37 -0400
Subject: [R] search across a row for strings
In-Reply-To: <F1065E5D886F4D429259CDEAE3F83CB61AF48C99@msgdb20.utad.utoledo.edu>
References: <F1065E5D886F4D429259CDEAE3F83CB61AF48C99@msgdb20.utad.utoledo.edu>
Message-ID: <CAM_vju=RPXdsX3cf_B=gyZNJDc6bQ4vz7_7HHZY1MQU82TBnEg@mail.gmail.com>

This faster than your version, and doesn't return NA:

df$htn <- apply(df[,2:4], 1, function(x)any(grepl("^410", x)))

> df
  ID  DX1   DX2  DX3   htn
1  1 4109  4280 7102  TRUE
2  2  734   311  490 FALSE
3  3 4011 42822 4101  TRUE

> system.time({
+  for(j in 1:10000) {
+   for (i in 1:nrow(df)) {
+     df[i,"htn"] <- any(sapply('410', function(x)  which( grepl(x,
df[i, 2:4], fixed = TRUE) )))
+   }
+  }
+ })
   user  system elapsed
  6.648   0.008   6.657
There were 50 or more warnings (use warnings() to see the first 50)
>
>
>
> system.time({
+  for(j in 1:10000) {
+   df$htn <- apply(df[,2:4], 1, function(x)any(grepl("^410", x)))
+  }
+ })
   user  system elapsed
  1.826   0.000   1.826


On Mon, Jun 15, 2015 at 4:12 PM, Federman, Douglas
<Douglas.Federman at utoledo.edu> wrote:
> I'm trying to do the following: search each patient's list of diagnoses for a specific code then create a new column based upon the the presence of the specific code.
> Simplified data follows:
>
> con <- textConnection("
> ID      DX1     DX2     DX3
> 1       4109    4280    7102
> 2       734     311     490
> 3       4011    42822   4101
> ")
> df <- read.table(con, header = TRUE, strip.white = TRUE, colClasses="character")
> #
> # I would like to add a column such the result of searching for 410 would give:  The search string would always be at the start of a word and doesn't need regex.
> #
> # ID    DX1     DX2     DX3     htn
> # 1     4109    4280    7102    1
> # 2     734     311     490     0
> # 3     4011    42822   4101    1
> #
> # The following  works but is slow and returns NA if the search string is not found:
>
> for (i in 1:nrow(df)) {
>     df[i,"htn"] <- any(sapply('410', function(x)  which( grepl(x, df[i, 2:4], fixed = TRUE) )))
> }
>
> Thanks in advance.  I never fail to learn new things from this list.
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From axel.urbiz at gmail.com  Mon Jun 15 22:32:41 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Mon, 15 Jun 2015 16:32:41 -0400
Subject: [R] Error in local package install
Message-ID: <CAAyVsX+nzTz4xVgA1uf1_CQV6ca3pnEs1M_X+mXeLdezpcRdHg@mail.gmail.com>

Hello,

I've built a windows binary package from my Mac using the help from this
site: http://win-builder.r-project.org

As expected, I got back the file "mypackage.zip". Also, the logs show no
errors.

Now, when I try to install on windows using the GUI "install package(s)
from local zip files", I get the following error:

> utils:::menuInstallLocal()
Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
:
  cannot open the connection
In addition: Warning messages:
1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
  cannot open compressed file 'mypackage/DESCRIPTION', probable reason 'No
such file or directory'

I've attempted to use the solutions from prior similar email threats with
no success. Btw - I've install all the packages dependencies prior to the
above. I'm on R 3.2.0.

Any guidance would be much appreciated.

Thank you.

Axel.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Jun 15 22:34:25 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 15 Jun 2015 13:34:25 -0700
Subject: [R] search across a row for strings
In-Reply-To: <F1065E5D886F4D429259CDEAE3F83CB61AF48C99@msgdb20.utad.utoledo.edu>
References: <F1065E5D886F4D429259CDEAE3F83CB61AF48C99@msgdb20.utad.utoledo.edu>
Message-ID: <B63BCB87-1594-48C5-9737-DCDBE15D61C3@comcast.net>


On Jun 15, 2015, at 1:12 PM, Federman, Douglas wrote:

> I'm trying to do the following: search each patient's list of diagnoses for a specific code then create a new column based upon the the presence of the specific code.  
> Simplified data follows:
> 
> con <- textConnection("
> ID	DX1	DX2	DX3
> 1	4109	4280	7102
> 2	734	311	490
> 3	4011	42822	4101
> ")
> df <- read.table(con, header = TRUE, strip.white = TRUE, colClasses="character")
> #
> # I would like to add a column such the result of searching for 410 would give:  The search string would always be at the start of a word and doesn't need regex.
> #
> # ID	DX1	DX2	DX3	htn
> # 1	4109	4280	7102	1
> # 2	734	311	490	0
> # 3	4011	42822	4101	1
> #
> # The following  works but is slow and returns NA if the search string is not found:
> 
> for (i in 1:nrow(df)) {
>    df[i,"htn"] <- any(sapply('410', function(x)  which( grepl(x, df[i, 2:4], fixed = TRUE) )))
> }

Is this any better?

> df$htn <-  apply(df[-1], 1, function(r) max( substr(r, 1,3) == "410" ))
> df
  ID  DX1   DX2  DX3 htn
1  1 4109  4280 7102   1
2  2  734   311  490   0
3  3 4011 42822 4101   1


Can add an na.rm=TRUE to the max call if warranted. `max` coerces logicals to integer.



-- 
David Winsemius
Alameda, CA, USA


From ligges at statistik.tu-dortmund.de  Mon Jun 15 23:41:51 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 15 Jun 2015 23:41:51 +0200
Subject: [R] Error in local package install
In-Reply-To: <CAAyVsX+nzTz4xVgA1uf1_CQV6ca3pnEs1M_X+mXeLdezpcRdHg@mail.gmail.com>
References: <CAAyVsX+nzTz4xVgA1uf1_CQV6ca3pnEs1M_X+mXeLdezpcRdHg@mail.gmail.com>
Message-ID: <557F469F.8060008@statistik.tu-dortmund.de>



On 15.06.2015 22:32, Axel Urbiz wrote:
> Hello,
>
> I've built a windows binary package from my Mac using the help from this
> site: http://win-builder.r-project.org
>
> As expected, I got back the file "mypackage.zip". Also, the logs show no
> errors.

No, you got a file packagename_version.zip.



> Now, when I try to install on windows using the GUI "install package(s)
> from local zip files", I get the following error:
>
>> utils:::menuInstallLocal()
> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
> :
>    cannot open the connection
> In addition: Warning messages:
> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>    cannot open compressed file 'mypackage/DESCRIPTION', probable reason 'No
> such file or directory'
>
> I've attempted to use the solutions from prior similar email threats with
> no success. Btw - I've install all the packages dependencies prior to the
> above. I'm on R 3.2.0.

please try the release condadate of R-3.2.1, R-3.2.0 had a bug for 
package installation from local zip files.

Best,
Uwe Ligges


> Any guidance would be much appreciated.
>
> Thank you.
>
> Axel.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From f.harrell at Vanderbilt.Edu  Tue Jun 16 00:36:57 2015
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Mon, 15 Jun 2015 17:36:57 -0500
Subject: [R] Different behavior of model.matrix between R 3.2 and R3.1.1
In-Reply-To: <2f3a88$r82p4@ironport10.mayo.edu>
References: <2f3a88$qka43@ironport10.mayo.edu>
	<557E36CF.6010302@vanderbilt.edu> <2f3a88$r82p4@ironport10.mayo.edu>
Message-ID: <557F5389.4020406@vanderbilt.edu>

Thank you very much Terry.  I'm still puzzled at why this worked a year 
ago.  What changed?  I'd very much like to reverse the change by setting 
an argument somewhere or manipulating the terms object.

I echo your sentiments about the general approach.

Frank


On 06/15/2015 09:05 AM, Therneau, Terry M., Ph.D. wrote:
> Frank,
>   I don't think there is any way to "fix" your problem except the way 
> that I did it.
>
> library(survival)
> tdata <- data.frame(y=c(1,3,3,5, 5,7, 7,9, 9,13),
>                     x1=factor(letters[c(1,1,1,1,1,2,2,2,2,2)]),
>                     x2= c(1,2,1,2,1,2,1,2,1,2))
>
> fit1 <- lm( y ~ x1 * strata(x2) - strata(x2), tdata)
> coef(fit1)
>        (Intercept)                x1b x1a:strata(x2)x2=2 
> x1b:strata(x2)x2=2
>           3.000000           5.000000           1.000000 1.666667
>
> Your code is calling model.matrix with the same model frame and terms 
> structure as the lm call above (I checked).  In your case you know 
> that the underlying model has 2 intercepts (strata), one for the group 
> with x2=1 and another for the group with x2=2, but how is the 
> model.matrix routine supposed to guess that?  It can't, so 
> model.matrix returns the proper result for the lm call.  As seen above 
> the result is not singular, while for the Cox model it is singular due 
> to the extra intercept.
>
> This is simply an extension of leaving the "intercept" term in the 
> model and then removing that column from the returned X matrix, which 
> is necessary to have the correct coding for ordinary factor variables, 
> something we've both done since day 1.  In order for model.matrix to 
> do the right thing with interactions, it has to know how many 
> intercepts there actually are.
>
> I've come to the conclusion that the entire thrust of 'contrasts' in S 
> was wrong headed, i.e., the "remove redundant columns from the X 
> matrix ahead of time" logic.  It is simply not possible for the 
> model.matrix routine to guess correctly for all y and x combinations, 
> something that been acknowledged in R by changing the default for 
> "singular.ok" to TRUE. Dealing with this after the fact via a good 
> contrast function (a la SAS -- heresy!) would have been a much better 
> design choice.  But as long as I'm in R the coxph routine tries to be 
> a good citizen.
>
> Terry T.

-- 
------------------------------------------------------------------------
Frank E Harrell Jr 	Professor and Chairman 	School of Medicine

	Department of *Biostatistics* 	*Vanderbilt University*


	[[alternative HTML version deleted]]


From bccguima at yahoo.com.br  Tue Jun 16 00:55:06 2015
From: bccguima at yahoo.com.br (bruno cid)
Date: Mon, 15 Jun 2015 22:55:06 +0000 (UTC)
Subject: [R] model selection
Message-ID: <1037704496.58893.1434408906756.JavaMail.yahoo@mail.yahoo.com>

Hi friends, 

Im trying to make a model selection comparing models built with "lm" function (package "stats") and "lme" function (package "nlme"). Do you know if there is a problem to compare these models with the function "AICtab" (package "bbmle). 

Thanks!!!?Bruno Cid Crespo Guimar?esMestre em EcologiaLaborat?rio de Ecologia e Conserva??o de Popula??esUniversidade Federal do Rio de Janeiro
	[[alternative HTML version deleted]]


From ghather at gmail.com  Tue Jun 16 01:32:34 2015
From: ghather at gmail.com (Greg Hather)
Date: Mon, 15 Jun 2015 19:32:34 -0400
Subject: [R] problem with nlme, environments, and packages
Message-ID: <CAOtVL=FoH=h6c3hAkBs-8dGQZEJzMgE-oDsxBC6CUAzkDugkow@mail.gmail.com>

Hello R users,

I encountered a strange problem while writing a package that uses the
nlme function.  First, I wrote some code that uses the nlme function,
and it ran without errors.  However, when I tried to put the code into
a package, the nlme function was unable to locate a function that was
used in the formula.  Could it be that nlme is looking in the wrong
environment?  I would appreciate any suggestions.  Below is a
reproducible example with the problem.

########### BEGIN EXAMPLE ##############

#' Fake package to show nlme error
#' @export

main_function <- function(x){
 library(nlme)
 result <- nlme(height ~ SSasymp(age, Asym, R0, lrc) +
nonlinear_function(age),
                data = Loblolly,
                fixed = Asym + R0 + lrc ~ 1,
                random = Asym ~ 1,
                start = c(Asym = 103, R0 = -8.5, lrc = -3.3))
 result
}

nonlinear_function <- function(x){
 log(x)
}

########### END EXAMPLE ##############

The above code can be installed as a package and run with the commands

library(devtools)
library(roxygen2)
setwd("C:/test")  # or any prefered directory
create("testPackage")
setwd("./testPackage")
document()
setwd("..")
install("testPackage")
main_function()

The output is

> main_function()
Error in eval(expr, envir, enclos) :
 could not find function "nonlinear_function"
>
> sessionInfo()
R version 3.1.3 (2015-03-09)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 8 x64 (build 9200)
locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252
attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
[7] base
other attached packages:
[1] nlme_3.1-120           testPackage_0.0.0.9000
[3] roxygen2_4.1.1         devtools_1.8.0
loaded via a namespace (and not attached):
[1] curl_0.8        digest_0.6.8    git2r_0.10.1
[4] grid_3.1.3      lattice_0.20-31 magrittr_1.5
[7] memoise_0.2.1   Rcpp_0.11.6     rversions_1.0.1
[10] stringi_0.4-1   stringr_1.0.0   tools_3.1.3
[13] xml2_0.1.1

Note that if I simply paste main_function and nonlinear_function into
the R console, then main_function() runs without errors.

Greg

	[[alternative HTML version deleted]]


From shivibhatia at ymail.com  Tue Jun 16 08:19:33 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Mon, 15 Jun 2015 23:19:33 -0700 (PDT)
Subject: [R] Missing Values in Table Statement
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C30C99@SRVEXCHMBX.precheza.cz>
References: <1434087634952-4708534.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C309DA@SRVEXCHMBX.precheza.cz>
	<1434090467055-4708537.post@n4.nabble.com>
	<D1A06140.12DF12%macqueen1@llnl.gov>
	<1434170183472-4708593.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C30C99@SRVEXCHMBX.precheza.cz>
Message-ID: <1434435573297-4708674.post@n4.nabble.com>

HI Petr,There is no reason for holding back the data from dput format. The
reason for not supplying is that i tried multiple times but it the output
what comes is not really user friendly is what i think.Not sure if i am
missing a trick somewhere as i tried both the dput and dget options. Though
as you highlighted below i will once again check the time column to see what
values are empty.Thanks, Shivi



--
View this message in context: http://r.789695.n4.nabble.com/Missing-Values-in-Table-Statement-tp4708534p4708674.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Jun 16 09:01:49 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 16 Jun 2015 07:01:49 +0000
Subject: [R] Missing Values in Table Statement
In-Reply-To: <1434435573297-4708674.post@n4.nabble.com>
References: <1434087634952-4708534.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C309DA@SRVEXCHMBX.precheza.cz>
	<1434090467055-4708537.post@n4.nabble.com>
	<D1A06140.12DF12%macqueen1@llnl.gov>
	<1434170183472-4708593.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C30C99@SRVEXCHMBX.precheza.cz>
	<1434435573297-4708674.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C30EC8@SRVEXCHMBX.precheza.cz>

Hi

actually output from dput is the most user friendly way of supplying data.

try just copy this part below

-----

temp <- structure(list(dusik = c(1814L, 2844L, 3121L, 3286L, 3515L, 2478L,
1891L), kyslik = c(5224L, 8632L, 9214L, 9765L, 10428L, 7403L,
5469L), co2 = c(20188L, 32118L, 35299L, 36781L, 39340L, 28136L,
20980L), pevnost = c(6.3, 5.82, 6.89, 5.49, 8.4, 8.6, 10.6),
    dlou = c(81.2, 102.6, 146.2, 87.2, 154.6, 177.1, 170.2),
    adit = structure(c(4L, 2L, 2L, 3L, 3L, 1L, 1L), .Label = c("adi",
    "cg100", "cg100mod", "nic"), class = "factor"), pridavek = c(0L,
    3L, 5L, 3L, 5L, 3L, 5L)), .Names = c("dusik", "kyslik", "co2",
"pevnost", "dlou", "adit", "pridavek"), class = "data.frame", row.names = c(NA,
-7L))

----

and put it to your R console. It will create object named temp as you can easily check.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shivi82
> Sent: Tuesday, June 16, 2015 8:20 AM
> To: r-help at r-project.org
> Subject: Re: [R] Missing Values in Table Statement
>
> HI Petr,There is no reason for holding back the data from dput format.
> The reason for not supplying is that i tried multiple times but it the
> output what comes is not really user friendly is what i think.Not sure
> if i am missing a trick somewhere as i tried both the dput and dget
> options. Though as you highlighted below i will once again check the
> time column to see what values are empty.Thanks, Shivi
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Missing-
> Values-in-Table-Statement-tp4708534p4708674.html
> Sent from the R help mailing list archive at Nabble.com.
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From murdoch.duncan at gmail.com  Tue Jun 16 12:48:49 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 16 Jun 2015 07:48:49 -0300
Subject: [R] problem with nlme, environments, and packages
In-Reply-To: <CAOtVL=FoH=h6c3hAkBs-8dGQZEJzMgE-oDsxBC6CUAzkDugkow@mail.gmail.com>
References: <CAOtVL=FoH=h6c3hAkBs-8dGQZEJzMgE-oDsxBC6CUAzkDugkow@mail.gmail.com>
Message-ID: <557FFF11.9020405@gmail.com>

On 15/06/2015 8:32 PM, Greg Hather wrote:
> Hello R users,
> 
> I encountered a strange problem while writing a package that uses the
> nlme function.  First, I wrote some code that uses the nlme function,
> and it ran without errors.  However, when I tried to put the code into
> a package, the nlme function was unable to locate a function that was
> used in the formula.  Could it be that nlme is looking in the wrong
> environment?  I would appreciate any suggestions.  Below is a
> reproducible example with the problem.

I haven't tested this (I don't use the devtools stuff), but I'd say
there are two likely possibilities:

1.  nlme() isn't evaluating the formula properly.

2.  Your test isn't doing what you think it is doing, because you have a
second copy of main_function in your global environment.

Assuming you can rule out 2, could you put together a tarball of the
package that I could actually run?

Duncan Murdoch


> 
> ########### BEGIN EXAMPLE ##############
> 
> #' Fake package to show nlme error
> #' @export
> 
> main_function <- function(x){
>  library(nlme)
>  result <- nlme(height ~ SSasymp(age, Asym, R0, lrc) +
> nonlinear_function(age),
>                 data = Loblolly,
>                 fixed = Asym + R0 + lrc ~ 1,
>                 random = Asym ~ 1,
>                 start = c(Asym = 103, R0 = -8.5, lrc = -3.3))
>  result
> }
> 
> nonlinear_function <- function(x){
>  log(x)
> }
> 
> ########### END EXAMPLE ##############
> 
> The above code can be installed as a package and run with the commands
> 
> library(devtools)
> library(roxygen2)
> setwd("C:/test")  # or any prefered directory
> create("testPackage")
> setwd("./testPackage")
> document()
> setwd("..")
> install("testPackage")
> main_function()
> 
> The output is
> 
>> main_function()
> Error in eval(expr, envir, enclos) :
>  could not find function "nonlinear_function"
>>
>> sessionInfo()
> R version 3.1.3 (2015-03-09)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 8 x64 (build 9200)
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> [7] base
> other attached packages:
> [1] nlme_3.1-120           testPackage_0.0.0.9000
> [3] roxygen2_4.1.1         devtools_1.8.0
> loaded via a namespace (and not attached):
> [1] curl_0.8        digest_0.6.8    git2r_0.10.1
> [4] grid_3.1.3      lattice_0.20-31 magrittr_1.5
> [7] memoise_0.2.1   Rcpp_0.11.6     rversions_1.0.1
> [10] stringi_0.4-1   stringr_1.0.0   tools_3.1.3
> [13] xml2_0.1.1
> 
> Note that if I simply paste main_function and nonlinear_function into
> the R console, then main_function() runs without errors.
> 
> Greg
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Roger.Bivand at nhh.no  Tue Jun 16 14:28:13 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 16 Jun 2015 12:28:13 +0000
Subject: [R] Boxplot using a shapefile
References: <CABPcpMw4EZ2SQLBi36ZGuXZevzW3rWaw1So8MP-j283n=cZV2Q@mail.gmail.com>
	<566944AC-4584-45D0-9BDA-C79EEC6ECBD1@utoronto.ca>
Message-ID: <loom.20150616T140816-86@post.gmane.org>

Boris Steipe <boris.steipe <at> utoronto.ca> writes:

> 
> Your workflow in principle is:
> 
> - read the image into an object for which you can obtain values-per-pixel
in a 2D structure;
> - read the shapefile and convert into a polygon;
> - determine the bounding box of the polygon;
> - use the inout() function of the splancs package to get a list of
booleans for the
>     points in the bounding box, TRUE if they are _inside_ the polygon;
> - subset your image points to those for which inout() returns TRUE;
> - plot as boxplot().
> 
> The CRAN taskview http://cran.r-project.org/web/views/MedicalImaging.html
has a section on general
> image processing, guiding you to helpful packages.

Actually, this is the wrong taskview if the data are as described, as
Spatial data are covered in the Spatial task view at:

http://cran.r-project.org/web/views/Spatial.html

The workflow as described is also muddled: "[T]he shapefile takes the 
pixel values from the image and shows the distribution of pixels in 
the form of a boxplot" doesn't actually mean anything without further
assumptions. 

A shapefile is an ESRI file format for GIS vector geometries (and
attributes) that may be polygons, lines or points, and has an associated
coordinate reference system; it is almost never used for other kinds of data. 

The "image" - presumably a GIS raster data file, should have the same
coordinate reference system, or be transformed to the same system (use
spTransform in the rgdal package, which is also the package you should use
for reading the input data as it correctly reads input coordinate reference
systems if available). 

The operation then needed is called an over() method in the sp package, and
extract() in the raster package. 

If the shapefile contains points, the over query is asking the value(s) of
the raster cells (pixels) at those points, given the same coordinate
reference systems - but only one boxplot. If lines, for each line you may
get a vector of values from raster cells intersected by the lines, and could
make a boxplot for each line; you may wish to weight each value by the
length of line in each cell. If polygons, as lines, with weighting by
intersection area.

The over vignette in the sp package is where you need to go to begin:

http://cran.r-project.org/web/packages/sp/vignettes/over.pdf

and the introduction to the raster package as a further reference:

http://cran.r-project.org/web/packages/raster/vignettes/Raster.pdf

> 
> Ask again if you get stuck - but(!):
> - see here for some hints on how to ask questions productively:
>   http://adv-r.had.co.nz/Reproducibility.html
>  
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> - ... and please read the posting guide and don't post in HTML.
> 

Definitely! And note that this is a question that is better suited to the
R-sig-geo list.

Hope this clarifies,

Roger

> B.
> 
> On Jun 15, 2015, at 7:19 AM, Preethi Balaji <preet.balaji20 <at>
gmail.com> wrote:
> 
> > Dear all,
> > 
> > I am trying to generate boxplots by giving a shapefile and an image as
> > input. The shapefile takes the pixel values from the image and shows
> > the distribution of pixels in the form of a boxplot.
> > 
> > Can somebody please tell me how I can execute this in R?
> > 
> > Many thanks!
> > 
> > -- 
> > 
> > Regards,
> > Preethi Malur Balaji | PhD Student
> > University College Cork | Cork, Ireland.


From axel.urbiz at gmail.com  Tue Jun 16 15:16:17 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Tue, 16 Jun 2015 09:16:17 -0400
Subject: [R] Error in local package install
In-Reply-To: <557F469F.8060008@statistik.tu-dortmund.de>
References: <CAAyVsX+nzTz4xVgA1uf1_CQV6ca3pnEs1M_X+mXeLdezpcRdHg@mail.gmail.com>
	<557F469F.8060008@statistik.tu-dortmund.de>
Message-ID: <CAAyVsXLgoZuYRp+c2wB1LXGoXoBeu+AonBisWj_59Ed-ZzM0wg@mail.gmail.com>

Thanks Uwe. Actually, the problem persists in R-3.2.1.

If it helps, the .zip file is here:

http://win-builder.r-project.org/yC8eUu09w3Ui/

Thank you,
Axel.



On Mon, Jun 15, 2015 at 5:41 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de
> wrote:

>
>
> On 15.06.2015 22:32, Axel Urbiz wrote:
>
>> Hello,
>>
>> I've built a windows binary package from my Mac using the help from this
>> site: http://win-builder.r-project.org
>>
>> As expected, I got back the file "mypackage.zip". Also, the logs show no
>> errors.
>>
>
> No, you got a file packagename_version.zip.
>
>
>
>  Now, when I try to install on windows using the GUI "install package(s)
>> from local zip files", I get the following error:
>>
>>  utils:::menuInstallLocal()
>>>
>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
>> :
>>    cannot open the connection
>> In addition: Warning messages:
>> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
>> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>    cannot open compressed file 'mypackage/DESCRIPTION', probable reason
>> 'No
>> such file or directory'
>>
>> I've attempted to use the solutions from prior similar email threats with
>> no success. Btw - I've install all the packages dependencies prior to the
>> above. I'm on R 3.2.0.
>>
>
> please try the release condadate of R-3.2.1, R-3.2.0 had a bug for package
> installation from local zip files.
>
> Best,
> Uwe Ligges
>
>
>  Any guidance would be much appreciated.
>>
>> Thank you.
>>
>> Axel.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From ghather at gmail.com  Tue Jun 16 15:34:16 2015
From: ghather at gmail.com (Greg Hather)
Date: Tue, 16 Jun 2015 09:34:16 -0400
Subject: [R] problem with nlme, environments, and packages
In-Reply-To: <557FFF11.9020405@gmail.com>
References: <CAOtVL=FoH=h6c3hAkBs-8dGQZEJzMgE-oDsxBC6CUAzkDugkow@mail.gmail.com>
	<557FFF11.9020405@gmail.com>
Message-ID: <CAOtVL=ErvqD_OjUe3oFn8JeFLW+wX1MBxo+iAmjpYQ0eobFJDw@mail.gmail.com>

Hi Duncan,

I checked the global environment, and it was empty, so I think that rules
out the second possibility.  I posted a tarball at

https://drive.google.com/file/d/0B8hBX90jtuLcaGtOUktqV2V4UUU/view?usp=sharing

Thank you for your help!

Greg

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Tue Jun 16 16:18:22 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 16 Jun 2015 16:18:22 +0200
Subject: [R] Error in local package install
In-Reply-To: <CAAyVsXLgoZuYRp+c2wB1LXGoXoBeu+AonBisWj_59Ed-ZzM0wg@mail.gmail.com>
References: <CAAyVsX+nzTz4xVgA1uf1_CQV6ca3pnEs1M_X+mXeLdezpcRdHg@mail.gmail.com>	<557F469F.8060008@statistik.tu-dortmund.de>
	<CAAyVsXLgoZuYRp+c2wB1LXGoXoBeu+AonBisWj_59Ed-ZzM0wg@mail.gmail.com>
Message-ID: <5580302E.3080109@statistik.tu-dortmund.de>



On 16.06.2015 15:16, Axel Urbiz wrote:
> Thanks Uwe. Actually, the problem persists in R-3.2.1.
>
> If it helps, the .zip file is here:
>
> http://win-builder.r-project.org/yC8eUu09w3Ui/


Works for me, but your error message is:


"cannot open compressed file 'mypackage/DESCRIPTION'"

which suggests you renamed the file?  You must not do that, just keep 
the filename "calibr_0.0.0.9000.zip".

Best,
Uwe Ligges


> Thank you,
> Axel.
>
>
>
> On Mon, Jun 15, 2015 at 5:41 PM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de
> <mailto:ligges at statistik.tu-dortmund.de>> wrote:
>
>
>
>     On 15.06.2015 22:32, Axel Urbiz wrote:
>
>         Hello,
>
>         I've built a windows binary package from my Mac using the help
>         from this
>         site: http://win-builder.r-project.org
>
>         As expected, I got back the file "mypackage.zip". Also, the logs
>         show no
>         errors.
>
>
>     No, you got a file packagename_version.zip.
>
>
>
>         Now, when I try to install on windows using the GUI "install
>         package(s)
>         from local zip files", I get the following error:
>
>             utils:::menuInstallLocal()
>
>         Error in read.dcf(file.path(pkgname, "DESCRIPTION"),
>         c("Package", "Type"))
>         :
>             cannot open the connection
>         In addition: Warning messages:
>         1: In unzip(zipname, exdir = dest) : error 1 in extracting from
>         zip file
>         2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>         "Type")) :
>             cannot open compressed file 'mypackage/DESCRIPTION',
>         probable reason 'No
>         such file or directory'
>
>         I've attempted to use the solutions from prior similar email
>         threats with
>         no success. Btw - I've install all the packages dependencies
>         prior to the
>         above. I'm on R 3.2.0.
>
>
>     please try the release condadate of R-3.2.1, R-3.2.0 had a bug for
>     package installation from local zip files.
>
>     Best,
>     Uwe Ligges
>
>
>         Any guidance would be much appreciated.
>
>         Thank you.
>
>         Axel.
>
>                  [[alternative HTML version deleted]]
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         and provide commented, minimal, self-contained, reproducible code.
>
>


From axel.urbiz at gmail.com  Tue Jun 16 16:33:29 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Tue, 16 Jun 2015 10:33:29 -0400
Subject: [R] Error in local package install
In-Reply-To: <5580302E.3080109@statistik.tu-dortmund.de>
References: <CAAyVsX+nzTz4xVgA1uf1_CQV6ca3pnEs1M_X+mXeLdezpcRdHg@mail.gmail.com>
	<557F469F.8060008@statistik.tu-dortmund.de>
	<CAAyVsXLgoZuYRp+c2wB1LXGoXoBeu+AonBisWj_59Ed-ZzM0wg@mail.gmail.com>
	<5580302E.3080109@statistik.tu-dortmund.de>
Message-ID: <CAAyVsXKgdm1wdYYUbtLtSiobF8mnrCaXJm=E+oV7tySROTKqmQ@mail.gmail.com>

Thanks again Uwe. I haven't renamed the file, only in the text sent to
R-help. Here's the error again I'm getting. Sorry, this s a bit
frustrating...

Thanks,
Axel


Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
:
  cannot open the connection
In addition: Warning messages:
1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
  cannot open compressed file 'calibr/DESCRIPTION', probable reason 'No
such file or directory'
>

On Tue, Jun 16, 2015 at 10:18 AM, Uwe Ligges <
ligges at statistik.tu-dortmund.de> wrote:

>
>
> On 16.06.2015 15:16, Axel Urbiz wrote:
>
>> Thanks Uwe. Actually, the problem persists in R-3.2.1.
>>
>> If it helps, the .zip file is here:
>>
>> http://win-builder.r-project.org/yC8eUu09w3Ui/
>>
>
>
> Works for me, but your error message is:
>
>
> "cannot open compressed file 'mypackage/DESCRIPTION'"
>
> which suggests you renamed the file?  You must not do that, just keep the
> filename "calibr_0.0.0.9000.zip".
>
> Best,
> Uwe Ligges
>
>
>  Thank you,
>> Axel.
>>
>>
>>
>> On Mon, Jun 15, 2015 at 5:41 PM, Uwe Ligges
>> <ligges at statistik.tu-dortmund.de
>> <mailto:ligges at statistik.tu-dortmund.de>> wrote:
>>
>>
>>
>>     On 15.06.2015 22:32, Axel Urbiz wrote:
>>
>>         Hello,
>>
>>         I've built a windows binary package from my Mac using the help
>>         from this
>>         site: http://win-builder.r-project.org
>>
>>         As expected, I got back the file "mypackage.zip". Also, the logs
>>         show no
>>         errors.
>>
>>
>>     No, you got a file packagename_version.zip.
>>
>>
>>
>>         Now, when I try to install on windows using the GUI "install
>>         package(s)
>>         from local zip files", I get the following error:
>>
>>             utils:::menuInstallLocal()
>>
>>         Error in read.dcf(file.path(pkgname, "DESCRIPTION"),
>>         c("Package", "Type"))
>>         :
>>             cannot open the connection
>>         In addition: Warning messages:
>>         1: In unzip(zipname, exdir = dest) : error 1 in extracting from
>>         zip file
>>         2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>>         "Type")) :
>>             cannot open compressed file 'mypackage/DESCRIPTION',
>>         probable reason 'No
>>         such file or directory'
>>
>>         I've attempted to use the solutions from prior similar email
>>         threats with
>>         no success. Btw - I've install all the packages dependencies
>>         prior to the
>>         above. I'm on R 3.2.0.
>>
>>
>>     please try the release condadate of R-3.2.1, R-3.2.0 had a bug for
>>     package installation from local zip files.
>>
>>     Best,
>>     Uwe Ligges
>>
>>
>>         Any guidance would be much appreciated.
>>
>>         Thank you.
>>
>>         Axel.
>>
>>                  [[alternative HTML version deleted]]
>>
>>         ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>         -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jun 16 16:57:03 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 16 Jun 2015 07:57:03 -0700
Subject: [R] model selection
In-Reply-To: <1037704496.58893.1434408906756.JavaMail.yahoo@mail.yahoo.com>
References: <1037704496.58893.1434408906756.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbSGGK8BDdzepF6Q8zuoP1iuY1zZi5dSBXVRKfva4DZ3Fg@mail.gmail.com>

Wrong list! This is about R. Post on a statistics list like
stats.stackexchange.com for statistics questions.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Mon, Jun 15, 2015 at 3:55 PM, bruno cid <bccguima at yahoo.com.br> wrote:

> Hi friends,
>
> Im trying to make a model selection comparing models built with "lm"
> function (package "stats") and "lme" function (package "nlme"). Do you know
> if there is a problem to compare these models with the function "AICtab"
> (package "bbmle).
>
> Thanks!!! Bruno Cid Crespo Guimar?esMestre em EcologiaLaborat?rio de
> Ecologia e Conserva??o de Popula??esUniversidade Federal do Rio de Janeiro
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jun 16 17:05:36 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 16 Jun 2015 08:05:36 -0700
Subject: [R] problem with nlme, environments, and packages
In-Reply-To: <CAOtVL=FoH=h6c3hAkBs-8dGQZEJzMgE-oDsxBC6CUAzkDugkow@mail.gmail.com>
References: <CAOtVL=FoH=h6c3hAkBs-8dGQZEJzMgE-oDsxBC6CUAzkDugkow@mail.gmail.com>
Message-ID: <CAGxFJbSD0pmsvwB6rAORVjhC5X5TkWQZ8yZANwmFRfFZ6hdyLg@mail.gmail.com>

An aside...

Just wanted to point out that:

fun <- function(x)log(x)

can be more simply replaced by:

fun <- log

Functions in R a full first class objects and can be treated as such. In
your example, this is still silly of course, but becomes relevant in
function calls where you can do things like

myfun <- function( FUN = log,...)

{ ...
something <- FUN(X)
...
}

Just in case this might be useful to you.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Mon, Jun 15, 2015 at 4:32 PM, Greg Hather <ghather at gmail.com> wrote:

> Hello R users,
>
> I encountered a strange problem while writing a package that uses the
> nlme function.  First, I wrote some code that uses the nlme function,
> and it ran without errors.  However, when I tried to put the code into
> a package, the nlme function was unable to locate a function that was
> used in the formula.  Could it be that nlme is looking in the wrong
> environment?  I would appreciate any suggestions.  Below is a
> reproducible example with the problem.
>
> ########### BEGIN EXAMPLE ##############
>
> #' Fake package to show nlme error
> #' @export
>
> main_function <- function(x){
>  library(nlme)
>  result <- nlme(height ~ SSasymp(age, Asym, R0, lrc) +
> nonlinear_function(age),
>                 data = Loblolly,
>                 fixed = Asym + R0 + lrc ~ 1,
>                 random = Asym ~ 1,
>                 start = c(Asym = 103, R0 = -8.5, lrc = -3.3))
>  result
> }
>
> nonlinear_function <- function(x){
>  log(x)
> }
>
> ########### END EXAMPLE ##############
>
> The above code can be installed as a package and run with the commands
>
> library(devtools)
> library(roxygen2)
> setwd("C:/test")  # or any prefered directory
> create("testPackage")
> setwd("./testPackage")
> document()
> setwd("..")
> install("testPackage")
> main_function()
>
> The output is
>
> > main_function()
> Error in eval(expr, envir, enclos) :
>  could not find function "nonlinear_function"
> >
> > sessionInfo()
> R version 3.1.3 (2015-03-09)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 8 x64 (build 9200)
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> [7] base
> other attached packages:
> [1] nlme_3.1-120           testPackage_0.0.0.9000
> [3] roxygen2_4.1.1         devtools_1.8.0
> loaded via a namespace (and not attached):
> [1] curl_0.8        digest_0.6.8    git2r_0.10.1
> [4] grid_3.1.3      lattice_0.20-31 magrittr_1.5
> [7] memoise_0.2.1   Rcpp_0.11.6     rversions_1.0.1
> [10] stringi_0.4-1   stringr_1.0.0   tools_3.1.3
> [13] xml2_0.1.1
>
> Note that if I simply paste main_function and nonlinear_function into
> the R console, then main_function() runs without errors.
>
> Greg
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From antunmilagros at gmail.com  Tue Jun 16 16:04:03 2015
From: antunmilagros at gmail.com (Milagros Antun)
Date: Tue, 16 Jun 2015 11:04:03 -0300
Subject: [R] Error working dsm: Error in fix.by(by.x,
 x) : 'by' must specify a uniquely valid column
Message-ID: <CAAyzcthUHNmiXhE_g=1mWVO0Vd726qUnzb6un4_8q5x2YbL28Q@mail.gmail.com>

Hello, I`m trying to use dsm package, *(library(Distance); library(dsm)*) ,
following Miller`s Appendix (
http://onlinelibrary.wiley.com/store/10.1111/2041-210X.12105/asset/supinfo/mee312105-sup-0001-AppendixS1.pdf?v=1&s=ced953b57365e5eb5753f0ad76dcc02c26918736
 ).

I work with three dataframes, whose str are:

*1) segdata:*
 data.frame': 193 obs. of  17 variables:
 $ Sample.Lab    : int  1 2 3 4 5 6 7 8 9 10 ...
 $ Transect.Label: Factor w/ 56 levels "1","100","101",..: 36 36 36 36 36
20 56 52 52 52 ...
 $ Effort        : int  1800 1800 1800 1800 1800 1800 1800 1800 1800 1800
...
 $ x             : num  4443636 4437817 4442085 4440564 4439117 ...
 $ y             : num  5267395 5271579 5268309 5269266 5270337 ...
 $ ID_ESTRATO    : int  3 2 3 2 2 2 2 2 4 2 ...
 $ NDVI2010      : num  1813 1816 1804 1807 1816 ...
 $ NDVI2011      : num  2007 1943 1935 1894 1893 ...
 $ NDVI2012      : num  1705 1736 1686 1691 1729 ...
 $ NDVI2013      : num  2206 2305 2145 2211 2279 ...
 $ PROM_NDVI     : num  2218 2313 2148 2206 2275 ...
 $ DIST_PUEST    : num  959 455 2652 3194 1394 ...
 $ DIST_CUADR    : num  1482.1 137.5 549.9 62.9 514.8 ...
 $ DIST_MOLIN    : num  794 5022 2519 4156 5715 ...
 $ X_4326        : num  -63.7 -63.8 -63.7 -63.7 -63.7 ...
 $ Y_4326        : num  -42.7 -42.7 -42.7 -42.7 -42.7 ...
 $ O.KM2_2015    : num  64.1 34.6 43.4 44.4 46.6 ...

*2) obsdata:*
'data.frame': 399 obs. of  6 variables:
 $ Especie.    : Factor w/ 1 level "Oveja": 1 1 1 1 1 1 1 1 1 1 ...
 $ size        : int  3 1 5 18 6 2 6 3 5 2 ...
 $ distance    : int  210 178 65 210 250 37 72 350 380 320 ...
 $ object      : int  1 2 5 7 8 13 14 20 30 31 ...
 $ Sample.Label: int  26 26 30 30 30 29 28 27 31 31 ...
 $ Effort      : num  1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 ...

*3)disdata*
'data.frame': 399 obs. of  7 variables:
 $ x       : num  4418278 4418667 4421229 4421308 4421308 ...
 $ y       : num  5299140 5298846 5295963 5295805 5295805 ...
 $ Especie.: Factor w/ 1 level "Oveja": 1 1 1 1 1 1 1 1 1 1 ...
 $ size    : int  3 1 5 18 6 2 6 3 5 2 ...
 $ distance: int  210 178 65 210 250 37 72 350 380 320 ...
 $ object  : int  1 2 5 7 8 13 14 20 30 31 ...
 $ Effort  : num  1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 1.8 ...


*First, I **fitted a detection function with the **script: *

*hr.model <-ds(distdata,truncation="10%",transect ="line",dht.group=
FALSE,key ="hr", convert.units = 1,adjustment =NULL) *

*And then, I tried to fit a  **very simple model, with the script:*


*mod1<-dsm(count ~ s(x,y, k=6), ddf.obj=hr.model, segdata, obsdata, engine
= "gam",convert.units = 1, family = quasipoisson(link = "log"),group =
FALSE,gamma = 1.4,control = list(keepData = TRUE),availability =
1,segment.area = NULL, weights = NULL)*

*Here I made a mistake, because R show me an Error: *


*Error in fix.by <http://fix.by/>(by.x, x) : 'by' must specify a uniquely
valid column*

*Does anybody can help me? Thanks in advance!*


*Milagros*
-- 
Lic. Ma. de los Milagros Ant?n
Centro Nacional Patag?nico-CONICET
Boulevard Brown 2915
9120 Puerto Madryn
Argentina
Tel. +54 (0) 280 4883184
Interno 1345
Fax +54 (0) 280 4883543

	[[alternative HTML version deleted]]


From humphrey.zhao at yahoo.com  Tue Jun 16 15:01:55 2015
From: humphrey.zhao at yahoo.com (Humphrey Zhao)
Date: Tue, 16 Jun 2015 13:01:55 +0000 (UTC)
Subject: [R] Question about XML package (accurately access one attribute in
 an multi-attribution node on the web page)
Message-ID: <633987273.3851112.1434459715900.JavaMail.yahoo@mail.yahoo.com>

Dear?Sir/Madam:

Thank?you for your attention to my question.?I?have downloaded?the source code of some web?pages?by?RCurl,?and?I?am?trying?to?extract?the?URL?from?them.?In?these?web?pages,?there?are?many?nodes?contains?the?same?URL,?such?like?the?followings:

<a?href=\"http://cos.name/2015/05/the-data-wisdom-for-data-science/\"?rel=\"bookmark\">

<a?href=\"http://blog.shakirm.com/2015/03/a-statistical-view-of-deep-learning-ii-auto-encoders-and-free-energy/\"?target=\"_blank\">

<a?href=\"http://cos.name/2015/05/the-data-wisdom-for-data-science/#more-10947\"?class=\"more-link\">

I?want?to?accurately?choose?the?URL?I?need(the "href"?in the?first?one),?and?I?tried?many?ways?the?most?accuracy?is?just?like?the?following:

library(XML)

#links<-getHTMLLinks(base.html,?xpQuery?=?"//a/@href")

links<-getHTMLLinks(base.html,?xpQuery?=?c("//a/href[@rel='bookmark']"))

However,?I?still?believe?that?there?is?a?correct?method?to?do?this?very?well,?but?I?could?not?find?it.?I?wonder?if?you?could?give?me?some?advice?on?solving?this?problem.?And?I?would?be?most?grateful?if?you?could?reply?at?your?earliest?convenience.?Looking?forward?to?hearing?from?you.?Thank?you?very?much.

?????????????????????????????????????Sincerely?yours?

?????????????????????????????????????Humphrey?Zhao
	[[alternative HTML version deleted]]


From preet.balaji20 at gmail.com  Tue Jun 16 14:38:46 2015
From: preet.balaji20 at gmail.com (Preethi Balaji)
Date: Tue, 16 Jun 2015 13:38:46 +0100
Subject: [R] Boxplot using a shapefile
In-Reply-To: <loom.20150616T140816-86@post.gmane.org>
References: <CABPcpMw4EZ2SQLBi36ZGuXZevzW3rWaw1So8MP-j283n=cZV2Q@mail.gmail.com>
	<566944AC-4584-45D0-9BDA-C79EEC6ECBD1@utoronto.ca>
	<loom.20150616T140816-86@post.gmane.org>
Message-ID: <CABPcpMz7Mjy6wdpD1p_4Sa2S-jw6vF_7o4Gq9KXvnKgv78+fvg@mail.gmail.com>

Dear all,

Thanks very much for your help! I will keep your suggestions in mind
and will get back to you if I get stuck!



On Tue, Jun 16, 2015 at 1:28 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> Boris Steipe <boris.steipe <at> utoronto.ca> writes:
>
>>
>> Your workflow in principle is:
>>
>> - read the image into an object for which you can obtain values-per-pixel
> in a 2D structure;
>> - read the shapefile and convert into a polygon;
>> - determine the bounding box of the polygon;
>> - use the inout() function of the splancs package to get a list of
> booleans for the
>>     points in the bounding box, TRUE if they are _inside_ the polygon;
>> - subset your image points to those for which inout() returns TRUE;
>> - plot as boxplot().
>>
>> The CRAN taskview http://cran.r-project.org/web/views/MedicalImaging.html
> has a section on general
>> image processing, guiding you to helpful packages.
>
> Actually, this is the wrong taskview if the data are as described, as
> Spatial data are covered in the Spatial task view at:
>
> http://cran.r-project.org/web/views/Spatial.html
>
> The workflow as described is also muddled: "[T]he shapefile takes the
> pixel values from the image and shows the distribution of pixels in
> the form of a boxplot" doesn't actually mean anything without further
> assumptions.
>
> A shapefile is an ESRI file format for GIS vector geometries (and
> attributes) that may be polygons, lines or points, and has an associated
> coordinate reference system; it is almost never used for other kinds of data.
>
> The "image" - presumably a GIS raster data file, should have the same
> coordinate reference system, or be transformed to the same system (use
> spTransform in the rgdal package, which is also the package you should use
> for reading the input data as it correctly reads input coordinate reference
> systems if available).
>
> The operation then needed is called an over() method in the sp package, and
> extract() in the raster package.
>
> If the shapefile contains points, the over query is asking the value(s) of
> the raster cells (pixels) at those points, given the same coordinate
> reference systems - but only one boxplot. If lines, for each line you may
> get a vector of values from raster cells intersected by the lines, and could
> make a boxplot for each line; you may wish to weight each value by the
> length of line in each cell. If polygons, as lines, with weighting by
> intersection area.
>
> The over vignette in the sp package is where you need to go to begin:
>
> http://cran.r-project.org/web/packages/sp/vignettes/over.pdf
>
> and the introduction to the raster package as a further reference:
>
> http://cran.r-project.org/web/packages/raster/vignettes/Raster.pdf
>
>>
>> Ask again if you get stuck - but(!):
>> - see here for some hints on how to ask questions productively:
>>   http://adv-r.had.co.nz/Reproducibility.html
>>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> - ... and please read the posting guide and don't post in HTML.
>>
>
> Definitely! And note that this is a question that is better suited to the
> R-sig-geo list.
>
> Hope this clarifies,
>
> Roger
>
>> B.
>>
>> On Jun 15, 2015, at 7:19 AM, Preethi Balaji <preet.balaji20 <at>
> gmail.com> wrote:
>>
>> > Dear all,
>> >
>> > I am trying to generate boxplots by giving a shapefile and an image as
>> > input. The shapefile takes the pixel values from the image and shows
>> > the distribution of pixels in the form of a boxplot.
>> >
>> > Can somebody please tell me how I can execute this in R?
>> >
>> > Many thanks!
>> >
>> > --
>> >
>> > Regards,
>> > Preethi Malur Balaji | PhD Student
>> > University College Cork | Cork, Ireland.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Regards,
Preethi Malur Balaji | PhD Student
University College Cork | Cork, Ireland.


From alemu.tadesse at gmail.com  Tue Jun 16 17:38:54 2015
From: alemu.tadesse at gmail.com (Alemu Tadesse)
Date: Tue, 16 Jun 2015 09:38:54 -0600
Subject: [R] reading daily snow depth data
Message-ID: <CACGkHRPJqi-2EV_+gYv9igBjw0AMT4C8VuzzeyqgEYKgETn6+w@mail.gmail.com>

Dear All,

I was going to read daily snow data  for each state and station/city from
the following link. I was not able to separate a given state's data from
the rest of the contents of the file, read the data to a data frame and
save it to file.

http://www1.ncdc.noaa.gov/pub/data/snowmonitoring/fema/06-2015-dlysndpth.txt

I really appreciate your time and help, and also appreciate any information
 for an alternative source.

Best,

Alemu

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Jun 16 18:20:00 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 16 Jun 2015 13:20:00 -0300
Subject: [R] problem with nlme, environments, and packages
In-Reply-To: <CAOtVL=ErvqD_OjUe3oFn8JeFLW+wX1MBxo+iAmjpYQ0eobFJDw@mail.gmail.com>
References: <CAOtVL=FoH=h6c3hAkBs-8dGQZEJzMgE-oDsxBC6CUAzkDugkow@mail.gmail.com>	<557FFF11.9020405@gmail.com>
	<CAOtVL=ErvqD_OjUe3oFn8JeFLW+wX1MBxo+iAmjpYQ0eobFJDw@mail.gmail.com>
Message-ID: <55804CB0.2010808@gmail.com>

On 16/06/2015 10:34 AM, Greg Hather wrote:
> Hi Duncan,
> 
> I checked the global environment, and it was empty, so I think that
> rules out the second possibility.  I posted a tarball at
> 
> https://drive.google.com/file/d/0B8hBX90jtuLcaGtOUktqV2V4UUU/view?usp=sharing
> 
> Thank you for your help!
> 
> Greg
> 

The problem is that nlme does a lot of evaluation of formula objects
without taking their associated environment into account.  Fixing it
doesn't look easy, because the evaluation happens in a lot of places.

One workaround is to put the appropriate environment(s) on the search
list before calling nlme().  This isn't perfect, because the search
order will be wrong, but it will get you something.

For example, your main_function could be

main_function <- function(x){

  library(nlme)
  attach(parent.env(env=environment()))
  result <- nlme(height ~ SSasymp(age, Asym, R0, lrc) +
nonlinear_function(age),
                 data = Loblolly,
                 fixed = Asym + R0 + lrc ~ 1,
                 random = Asym ~ 1,
                 start = c(Asym = 103, R0 = -8.5, lrc = -3.3))
  detach()
  result
}

Duncan


From ligges at statistik.tu-dortmund.de  Tue Jun 16 18:27:22 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 16 Jun 2015 18:27:22 +0200
Subject: [R] Error in local package install
In-Reply-To: <CAAyVsXKgdm1wdYYUbtLtSiobF8mnrCaXJm=E+oV7tySROTKqmQ@mail.gmail.com>
References: <CAAyVsX+nzTz4xVgA1uf1_CQV6ca3pnEs1M_X+mXeLdezpcRdHg@mail.gmail.com>	<557F469F.8060008@statistik.tu-dortmund.de>	<CAAyVsXLgoZuYRp+c2wB1LXGoXoBeu+AonBisWj_59Ed-ZzM0wg@mail.gmail.com>	<5580302E.3080109@statistik.tu-dortmund.de>
	<CAAyVsXKgdm1wdYYUbtLtSiobF8mnrCaXJm=E+oV7tySROTKqmQ@mail.gmail.com>
Message-ID: <55804E6A.5090605@statistik.tu-dortmund.de>



On 16.06.2015 16:33, Axel Urbiz wrote:
> Thanks again Uwe. I haven't renamed the file, only in the text sent to
> R-help. Here's the error again I'm getting. Sorry, this s a bit
> frustrating...

No idea. Perhaps the down load failed? Can you open the file using some 
zip software and extract the DESCRIPTION file?

Best,
Uwe Ligges


>
> Thanks,
> Axel
>
>
> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
> "Type")) :
>    cannot open the connection
> In addition: Warning messages:
> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>    cannot open compressed file 'calibr/DESCRIPTION', probable reason 'No
> such file or directory'
>  >
>
> On Tue, Jun 16, 2015 at 10:18 AM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de
> <mailto:ligges at statistik.tu-dortmund.de>> wrote:
>
>
>
>     On 16.06.2015 15:16, Axel Urbiz wrote:
>
>         Thanks Uwe. Actually, the problem persists in R-3.2.1.
>
>         If it helps, the .zip file is here:
>
>         http://win-builder.r-project.org/yC8eUu09w3Ui/
>
>
>
>     Works for me, but your error message is:
>
>
>     "cannot open compressed file 'mypackage/DESCRIPTION'"
>
>     which suggests you renamed the file?  You must not do that, just
>     keep the filename "calibr_0.0.0.9000.zip".
>
>     Best,
>     Uwe Ligges
>
>
>         Thank you,
>         Axel.
>
>
>
>         On Mon, Jun 15, 2015 at 5:41 PM, Uwe Ligges
>         <ligges at statistik.tu-dortmund.de
>         <mailto:ligges at statistik.tu-dortmund.de>
>         <mailto:ligges at statistik.tu-dortmund.de
>         <mailto:ligges at statistik.tu-dortmund.de>>> wrote:
>
>
>
>              On 15.06.2015 22:32, Axel Urbiz wrote:
>
>                  Hello,
>
>                  I've built a windows binary package from my Mac using
>         the help
>                  from this
>                  site: http://win-builder.r-project.org
>
>                  As expected, I got back the file "mypackage.zip". Also,
>         the logs
>                  show no
>                  errors.
>
>
>              No, you got a file packagename_version.zip.
>
>
>
>                  Now, when I try to install on windows using the GUI
>         "install
>                  package(s)
>                  from local zip files", I get the following error:
>
>                      utils:::menuInstallLocal()
>
>                  Error in read.dcf(file.path(pkgname, "DESCRIPTION"),
>                  c("Package", "Type"))
>                  :
>                      cannot open the connection
>                  In addition: Warning messages:
>                  1: In unzip(zipname, exdir = dest) : error 1 in
>         extracting from
>                  zip file
>                  2: In read.dcf(file.path(pkgname, "DESCRIPTION"),
>         c("Package",
>                  "Type")) :
>                      cannot open compressed file 'mypackage/DESCRIPTION',
>                  probable reason 'No
>                  such file or directory'
>
>                  I've attempted to use the solutions from prior similar
>         email
>                  threats with
>                  no success. Btw - I've install all the packages
>         dependencies
>                  prior to the
>                  above. I'm on R 3.2.0.
>
>
>              please try the release condadate of R-3.2.1, R-3.2.0 had a
>         bug for
>              package installation from local zip files.
>
>              Best,
>              Uwe Ligges
>
>
>                  Any guidance would be much appreciated.
>
>                  Thank you.
>
>                  Axel.
>
>                           [[alternative HTML version deleted]]
>
>                  ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org>
>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>         mailing list
>                  -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>                  PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>                  and provide commented, minimal, self-contained,
>         reproducible code.
>
>
>


From murdoch.duncan at gmail.com  Tue Jun 16 18:48:48 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 16 Jun 2015 13:48:48 -0300
Subject: [R] Error in local package install
In-Reply-To: <55804E6A.5090605@statistik.tu-dortmund.de>
References: <CAAyVsX+nzTz4xVgA1uf1_CQV6ca3pnEs1M_X+mXeLdezpcRdHg@mail.gmail.com>	<557F469F.8060008@statistik.tu-dortmund.de>	<CAAyVsXLgoZuYRp+c2wB1LXGoXoBeu+AonBisWj_59Ed-ZzM0wg@mail.gmail.com>	<5580302E.3080109@statistik.tu-dortmund.de>	<CAAyVsXKgdm1wdYYUbtLtSiobF8mnrCaXJm=E+oV7tySROTKqmQ@mail.gmail.com>
	<55804E6A.5090605@statistik.tu-dortmund.de>
Message-ID: <55805370.9030802@gmail.com>

On 16/06/2015 1:27 PM, Uwe Ligges wrote:
> 
> 
> On 16.06.2015 16:33, Axel Urbiz wrote:
>> Thanks again Uwe. I haven't renamed the file, only in the text sent to
>> R-help. Here's the error again I'm getting. Sorry, this s a bit
>> frustrating...
> 
> No idea. Perhaps the down load failed? Can you open the file using some 
> zip software and extract the DESCRIPTION file?

It may also be a permissions problem:  perhaps the file couldn't be
unzipped, because the user doesn't have write permission.  Are you
installing to the default library?  Perhaps you should try installing to
a personal library instead.

Duncan Murdoch
> 
> Best,
> Uwe Ligges
> 
> 
>>
>> Thanks,
>> Axel
>>
>>
>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>> "Type")) :
>>    cannot open the connection
>> In addition: Warning messages:
>> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
>> 2: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>    cannot open compressed file 'calibr/DESCRIPTION', probable reason 'No
>> such file or directory'
>>  >
>>
>> On Tue, Jun 16, 2015 at 10:18 AM, Uwe Ligges
>> <ligges at statistik.tu-dortmund.de
>> <mailto:ligges at statistik.tu-dortmund.de>> wrote:
>>
>>
>>
>>     On 16.06.2015 15:16, Axel Urbiz wrote:
>>
>>         Thanks Uwe. Actually, the problem persists in R-3.2.1.
>>
>>         If it helps, the .zip file is here:
>>
>>         http://win-builder.r-project.org/yC8eUu09w3Ui/
>>
>>
>>
>>     Works for me, but your error message is:
>>
>>
>>     "cannot open compressed file 'mypackage/DESCRIPTION'"
>>
>>     which suggests you renamed the file?  You must not do that, just
>>     keep the filename "calibr_0.0.0.9000.zip".
>>
>>     Best,
>>     Uwe Ligges
>>
>>
>>         Thank you,
>>         Axel.
>>
>>
>>
>>         On Mon, Jun 15, 2015 at 5:41 PM, Uwe Ligges
>>         <ligges at statistik.tu-dortmund.de
>>         <mailto:ligges at statistik.tu-dortmund.de>
>>         <mailto:ligges at statistik.tu-dortmund.de
>>         <mailto:ligges at statistik.tu-dortmund.de>>> wrote:
>>
>>
>>
>>              On 15.06.2015 22:32, Axel Urbiz wrote:
>>
>>                  Hello,
>>
>>                  I've built a windows binary package from my Mac using
>>         the help
>>                  from this
>>                  site: http://win-builder.r-project.org
>>
>>                  As expected, I got back the file "mypackage.zip". Also,
>>         the logs
>>                  show no
>>                  errors.
>>
>>
>>              No, you got a file packagename_version.zip.
>>
>>
>>
>>                  Now, when I try to install on windows using the GUI
>>         "install
>>                  package(s)
>>                  from local zip files", I get the following error:
>>
>>                      utils:::menuInstallLocal()
>>
>>                  Error in read.dcf(file.path(pkgname, "DESCRIPTION"),
>>                  c("Package", "Type"))
>>                  :
>>                      cannot open the connection
>>                  In addition: Warning messages:
>>                  1: In unzip(zipname, exdir = dest) : error 1 in
>>         extracting from
>>                  zip file
>>                  2: In read.dcf(file.path(pkgname, "DESCRIPTION"),
>>         c("Package",
>>                  "Type")) :
>>                      cannot open compressed file 'mypackage/DESCRIPTION',
>>                  probable reason 'No
>>                  such file or directory'
>>
>>                  I've attempted to use the solutions from prior similar
>>         email
>>                  threats with
>>                  no success. Btw - I've install all the packages
>>         dependencies
>>                  prior to the
>>                  above. I'm on R 3.2.0.
>>
>>
>>              please try the release condadate of R-3.2.1, R-3.2.0 had a
>>         bug for
>>              package installation from local zip files.
>>
>>              Best,
>>              Uwe Ligges
>>
>>
>>                  Any guidance would be much appreciated.
>>
>>                  Thank you.
>>
>>                  Axel.
>>
>>                           [[alternative HTML version deleted]]
>>
>>                  ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org>
>>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>>         mailing list
>>                  -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>                  PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>                  and provide commented, minimal, self-contained,
>>         reproducible code.
>>
>>
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From boris.steipe at utoronto.ca  Tue Jun 16 19:17:23 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 16 Jun 2015 13:17:23 -0400
Subject: [R] Question about XML package (accurately access one attribute
	in an multi-attribution node on the web page)
In-Reply-To: <633987273.3851112.1434459715900.JavaMail.yahoo@mail.yahoo.com>
References: <633987273.3851112.1434459715900.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <7485B8DB-4C31-424F-810A-672769B2BAB9@utoronto.ca>

Humphrey -

Any "correct" method requires you to specify _uniquely_ what you are looking for. If the bookmark keyword is necessary and unique, it appears you have a working solution. Or what else where you trying to accomplish?

Cheers,
Boris


On Jun 16, 2015, at 9:01 AM, Humphrey Zhao <humphrey.zhao at yahoo.com> wrote:

> Dear Sir/Madam:
> 
> Thank you for your attention to my question. I have downloaded the source code of some web pages by RCurl, and I am trying to extract the URL from them. In these web pages, there are many nodes contains the same URL, such like the followings:
> 
> <a href=\"http://cos.name/2015/05/the-data-wisdom-for-data-science/\" rel=\"bookmark\">
> 
> <a href=\"http://blog.shakirm.com/2015/03/a-statistical-view-of-deep-learning-ii-auto-encoders-and-free-energy/\" target=\"_blank\">
> 
> <a href=\"http://cos.name/2015/05/the-data-wisdom-for-data-science/#more-10947\" class=\"more-link\">
> 
> I want to accurately choose the URL I need(the "href" in the first one), and I tried many ways the most accuracy is just like the following:
> 
> library(XML)
> 
> #links<-getHTMLLinks(base.html, xpQuery = "//a/@href")
> 
> links<-getHTMLLinks(base.html, xpQuery = c("//a/href[@rel='bookmark']"))
> 
> However, I still believe that there is a correct method to do this very well, but I could not find it. I wonder if you could give me some advice on solving this problem. And I would be most grateful if you could reply at your earliest convenience. Looking forward to hearing from you. Thank you very much.
> 
>                                      Sincerely yours 
> 
>                                      Humphrey Zhao
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dimitri.liakhovitski at gmail.com  Tue Jun 16 19:24:36 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Tue, 16 Jun 2015 13:24:36 -0400
Subject: [R] dplyr - counting a number of specific values in each column -
 for all columns at once
Message-ID: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>

Hello!

I have a data frame:

md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c = c(1,3,4,3,5,5),
      device = c(1,1,2,2,3,3))
myvars = c("a", "b", "c")
md[2,3] <- NA
md[4,1] <- NA
md

I want to count number of 5s in each column - by device. I can do it like this:

library(dplyr)
group_by(md, device) %>%
summarise(counts.a = sum(a==5, na.rm = T),
          counts.b = sum(b==5, na.rm = T),
          counts.c = sum(c==5, na.rm = T))

However, in real life I'll have tons of variables (the length of
'myvars' can be very large) - so that I can't specify those counts.a,
counts.b, etc. manually - dozens of times.

Does dplyr allow to run the count of 5s on all 'myvars' columns at once?


-- 
Dimitri Liakhovitski


From clint at ecy.wa.gov  Tue Jun 16 19:40:08 2015
From: clint at ecy.wa.gov (Clint Bowman)
Date: Tue, 16 Jun 2015 10:40:08 -0700 (PDT)
Subject: [R] dplyr - counting a number of specific values in each column
 - for all columns at once
In-Reply-To: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
References: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
Message-ID: <alpine.LRH.2.11.1506161039040.4043@aeolus.ecy.wa.gov>

Any problem with

colSums(md==5, na.rm=T)

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Tue, 16 Jun 2015, Dimitri Liakhovitski wrote:

> Hello!
>
> I have a data frame:
>
> md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c = c(1,3,4,3,5,5),
>      device = c(1,1,2,2,3,3))
> myvars = c("a", "b", "c")
> md[2,3] <- NA
> md[4,1] <- NA
> md
>
> I want to count number of 5s in each column - by device. I can do it like this:
>
> library(dplyr)
> group_by(md, device) %>%
> summarise(counts.a = sum(a==5, na.rm = T),
>          counts.b = sum(b==5, na.rm = T),
>          counts.c = sum(c==5, na.rm = T))
>
> However, in real life I'll have tons of variables (the length of
> 'myvars' can be very large) - so that I can't specify those counts.a,
> counts.b, etc. manually - dozens of times.
>
> Does dplyr allow to run the count of 5s on all 'myvars' columns at once?
>
>
> -- 
> Dimitri Liakhovitski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dimitri.liakhovitski at gmail.com  Tue Jun 16 19:42:39 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Tue, 16 Jun 2015 13:42:39 -0400
Subject: [R] dplyr - counting a number of specific values in each column
 - for all columns at once
In-Reply-To: <alpine.LRH.2.11.1506161039040.4043@aeolus.ecy.wa.gov>
References: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
	<alpine.LRH.2.11.1506161039040.4043@aeolus.ecy.wa.gov>
Message-ID: <CAN2xGJY6SE_ysZTP7U90R_1qQEKaqgBvo0AdAMJnCnGYRsNtCA@mail.gmail.com>

No problem at all, Clint.
I was just trying to figure out of dplyr can do it.

On Tue, Jun 16, 2015 at 1:40 PM, Clint Bowman <clint at ecy.wa.gov> wrote:
> Any problem with
>
> colSums(md==5, na.rm=T)
>
> Clint Bowman                    INTERNET:       clint at ecy.wa.gov
> Air Quality Modeler             INTERNET:       clint at math.utah.edu
> Department of Ecology           VOICE:          (360) 407-6815
> PO Box 47600                    FAX:            (360) 407-7534
> Olympia, WA 98504-7600
>
>         USPS:           PO Box 47600, Olympia, WA 98504-7600
>         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>
>
> On Tue, 16 Jun 2015, Dimitri Liakhovitski wrote:
>
>> Hello!
>>
>> I have a data frame:
>>
>> md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c =
>> c(1,3,4,3,5,5),
>>      device = c(1,1,2,2,3,3))
>> myvars = c("a", "b", "c")
>> md[2,3] <- NA
>> md[4,1] <- NA
>> md
>>
>> I want to count number of 5s in each column - by device. I can do it like
>> this:
>>
>> library(dplyr)
>> group_by(md, device) %>%
>> summarise(counts.a = sum(a==5, na.rm = T),
>>          counts.b = sum(b==5, na.rm = T),
>>          counts.c = sum(c==5, na.rm = T))
>>
>> However, in real life I'll have tons of variables (the length of
>> 'myvars' can be very large) - so that I can't specify those counts.a,
>> counts.b, etc. manually - dozens of times.
>>
>> Does dplyr allow to run the count of 5s on all 'myvars' columns at once?
>>
>>
>> --
>> Dimitri Liakhovitski
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>



-- 
Dimitri Liakhovitski


From clint at ecy.wa.gov  Tue Jun 16 19:48:10 2015
From: clint at ecy.wa.gov (Clint Bowman)
Date: Tue, 16 Jun 2015 10:48:10 -0700 (PDT)
Subject: [R] dplyr - counting a number of specific values in each column
 - for all columns at once
In-Reply-To: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
References: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
Message-ID: <alpine.LRH.2.11.1506161042550.4043@aeolus.ecy.wa.gov>

It would help if I could see beyond my allergy meds.

A start could be:

colSums(subset(md,md$device==1)==5,na.rm=T)
colSums(subset(md,md$device==2)==5,na.rm=T)
colSums(subset(md,md$device==3)==5,na.rm=T)


Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Tue, 16 Jun 2015, Dimitri Liakhovitski wrote:

> Hello!
>
> I have a data frame:
>
> md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c = c(1,3,4,3,5,5),
>      device = c(1,1,2,2,3,3))
> myvars = c("a", "b", "c")
> md[2,3] <- NA
> md[4,1] <- NA
> md
>
> I want to count number of 5s in each column - by device. I can do it like this:
>
> library(dplyr)
> group_by(md, device) %>%
> summarise(counts.a = sum(a==5, na.rm = T),
>          counts.b = sum(b==5, na.rm = T),
>          counts.c = sum(c==5, na.rm = T))
>
> However, in real life I'll have tons of variables (the length of
> 'myvars' can be very large) - so that I can't specify those counts.a,
> counts.b, etc. manually - dozens of times.
>
> Does dplyr allow to run the count of 5s on all 'myvars' columns at once?
>
>
> -- 
> Dimitri Liakhovitski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Tue Jun 16 19:50:50 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 16 Jun 2015 10:50:50 -0700
Subject: [R] dplyr - counting a number of specific values in each column
 - for all columns at once
In-Reply-To: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
References: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
Message-ID: <CAGxFJbQ7dt5SRQhaxS0yTbcDm-GW1X2=N-vO3fDHkdN3qeco3Q@mail.gmail.com>

Well, dplyr seems a bit of overkill as it's so simple with plain old
vapply() in base R :


> dat <- data.frame (a=sample(1:5,10,rep=TRUE),
+                    b=sample(3:7,10,rep=TRUE),
+                    g = sample(7:9,10,rep=TRUE))

> vapply(dat,function(x)sum(x==5,na.rm=TRUE),1L)

a b g
5 4 0



Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Tue, Jun 16, 2015 at 10:24 AM, Dimitri Liakhovitski <
dimitri.liakhovitski at gmail.com> wrote:

> Hello!
>
> I have a data frame:
>
> md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c =
> c(1,3,4,3,5,5),
>       device = c(1,1,2,2,3,3))
> myvars = c("a", "b", "c")
> md[2,3] <- NA
> md[4,1] <- NA
> md
>
> I want to count number of 5s in each column - by device. I can do it like
> this:
>
> library(dplyr)
> group_by(md, device) %>%
> summarise(counts.a = sum(a==5, na.rm = T),
>           counts.b = sum(b==5, na.rm = T),
>           counts.c = sum(c==5, na.rm = T))
>
> However, in real life I'll have tons of variables (the length of
> 'myvars' can be very large) - so that I can't specify those counts.a,
> counts.b, etc. manually - dozens of times.
>
> Does dplyr allow to run the count of 5s on all 'myvars' columns at once?
>
>
> --
> Dimitri Liakhovitski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Tue Jun 16 19:56:11 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Tue, 16 Jun 2015 13:56:11 -0400
Subject: [R] dplyr - counting a number of specific values in each column
 - for all columns at once
In-Reply-To: <CAGxFJbQ7dt5SRQhaxS0yTbcDm-GW1X2=N-vO3fDHkdN3qeco3Q@mail.gmail.com>
References: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
	<CAGxFJbQ7dt5SRQhaxS0yTbcDm-GW1X2=N-vO3fDHkdN3qeco3Q@mail.gmail.com>
Message-ID: <CAN2xGJZy3_Mz0qSrzpkFuP9Zo24tsqj55TxE-mh7qkX5EYu_4w@mail.gmail.com>

Thank you, Bert.
I'll be honest - I am just learning dplyr and was wondering if one
could do it in dplyr.
But of course your solution is perfect...

On Tue, Jun 16, 2015 at 1:50 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Well, dplyr seems a bit of overkill as it's so simple with plain old
> vapply() in base R :
>
>
>> dat <- data.frame (a=sample(1:5,10,rep=TRUE),
> +                    b=sample(3:7,10,rep=TRUE),
> +                    g = sample(7:9,10,rep=TRUE))
>
>> vapply(dat,function(x)sum(x==5,na.rm=TRUE),1L)
>
> a b g
> 5 4 0
>
>
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge is
> certainly not wisdom."
>    -- Clifford Stoll
>
> On Tue, Jun 16, 2015 at 10:24 AM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
>>
>> Hello!
>>
>> I have a data frame:
>>
>> md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c =
>> c(1,3,4,3,5,5),
>>       device = c(1,1,2,2,3,3))
>> myvars = c("a", "b", "c")
>> md[2,3] <- NA
>> md[4,1] <- NA
>> md
>>
>> I want to count number of 5s in each column - by device. I can do it like
>> this:
>>
>> library(dplyr)
>> group_by(md, device) %>%
>> summarise(counts.a = sum(a==5, na.rm = T),
>>           counts.b = sum(b==5, na.rm = T),
>>           counts.c = sum(c==5, na.rm = T))
>>
>> However, in real life I'll have tons of variables (the length of
>> 'myvars' can be very large) - so that I can't specify those counts.a,
>> counts.b, etc. manually - dozens of times.
>>
>> Does dplyr allow to run the count of 5s on all 'myvars' columns at once?
>>
>>
>> --
>> Dimitri Liakhovitski
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Dimitri Liakhovitski


From dimitri.liakhovitski at gmail.com  Tue Jun 16 19:58:40 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Tue, 16 Jun 2015 13:58:40 -0400
Subject: [R] dplyr - counting a number of specific values in each column
 - for all columns at once
In-Reply-To: <CAN2xGJZy3_Mz0qSrzpkFuP9Zo24tsqj55TxE-mh7qkX5EYu_4w@mail.gmail.com>
References: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
	<CAGxFJbQ7dt5SRQhaxS0yTbcDm-GW1X2=N-vO3fDHkdN3qeco3Q@mail.gmail.com>
	<CAN2xGJZy3_Mz0qSrzpkFuP9Zo24tsqj55TxE-mh7qkX5EYu_4w@mail.gmail.com>
Message-ID: <CAN2xGJZUrcJVkkA49XFkPkufjEZxJzCSNQbjqxDfErzAJuT=0A@mail.gmail.com>

Except, of course, Bert, that you forgot that it had to be done by
device. Your solution ignores the device.

md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c = c(1,3,4,3,5,5),
      device = c(1,1,2,2,3,3))
myvars = c("a", "b", "c")
md[2,3] <- NA
md[4,1] <- NA
md
vapply(md[myvars], function(x) sum(x==5,na.rm=TRUE),1L)

But the result should be by device.

On Tue, Jun 16, 2015 at 1:56 PM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> Thank you, Bert.
> I'll be honest - I am just learning dplyr and was wondering if one
> could do it in dplyr.
> But of course your solution is perfect...
>
> On Tue, Jun 16, 2015 at 1:50 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> Well, dplyr seems a bit of overkill as it's so simple with plain old
>> vapply() in base R :
>>
>>
>>> dat <- data.frame (a=sample(1:5,10,rep=TRUE),
>> +                    b=sample(3:7,10,rep=TRUE),
>> +                    g = sample(7:9,10,rep=TRUE))
>>
>>> vapply(dat,function(x)sum(x==5,na.rm=TRUE),1L)
>>
>> a b g
>> 5 4 0
>>
>>
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>>
>> "Data is not information. Information is not knowledge. And knowledge is
>> certainly not wisdom."
>>    -- Clifford Stoll
>>
>> On Tue, Jun 16, 2015 at 10:24 AM, Dimitri Liakhovitski
>> <dimitri.liakhovitski at gmail.com> wrote:
>>>
>>> Hello!
>>>
>>> I have a data frame:
>>>
>>> md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c =
>>> c(1,3,4,3,5,5),
>>>       device = c(1,1,2,2,3,3))
>>> myvars = c("a", "b", "c")
>>> md[2,3] <- NA
>>> md[4,1] <- NA
>>> md
>>>
>>> I want to count number of 5s in each column - by device. I can do it like
>>> this:
>>>
>>> library(dplyr)
>>> group_by(md, device) %>%
>>> summarise(counts.a = sum(a==5, na.rm = T),
>>>           counts.b = sum(b==5, na.rm = T),
>>>           counts.c = sum(c==5, na.rm = T))
>>>
>>> However, in real life I'll have tons of variables (the length of
>>> 'myvars' can be very large) - so that I can't specify those counts.a,
>>> counts.b, etc. manually - dozens of times.
>>>
>>> Does dplyr allow to run the count of 5s on all 'myvars' columns at once?
>>>
>>>
>>> --
>>> Dimitri Liakhovitski
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>
>
> --
> Dimitri Liakhovitski



-- 
Dimitri Liakhovitski


From clint at ecy.wa.gov  Tue Jun 16 20:06:17 2015
From: clint at ecy.wa.gov (Clint Bowman)
Date: Tue, 16 Jun 2015 11:06:17 -0700 (PDT)
Subject: [R] dplyr - counting a number of specific values in each column
 - for all columns at once
In-Reply-To: <CAN2xGJZUrcJVkkA49XFkPkufjEZxJzCSNQbjqxDfErzAJuT=0A@mail.gmail.com>
References: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
	<CAGxFJbQ7dt5SRQhaxS0yTbcDm-GW1X2=N-vO3fDHkdN3qeco3Q@mail.gmail.com>
	<CAN2xGJZy3_Mz0qSrzpkFuP9Zo24tsqj55TxE-mh7qkX5EYu_4w@mail.gmail.com>
	<CAN2xGJZUrcJVkkA49XFkPkufjEZxJzCSNQbjqxDfErzAJuT=0A@mail.gmail.com>
Message-ID: <alpine.LRH.2.11.1506161105080.4043@aeolus.ecy.wa.gov>

May want to add headers but the following provides the device number with 
each set fo sums:

for (dev in (unique(md$device))) 
{cat(colSums(subset(md,md$device==dev)==5,na.rm=T),dev,"\n")}

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Tue, 16 Jun 2015, Dimitri Liakhovitski wrote:

> Except, of course, Bert, that you forgot that it had to be done by
> device. Your solution ignores the device.
>
> md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c = c(1,3,4,3,5,5),
>      device = c(1,1,2,2,3,3))
> myvars = c("a", "b", "c")
> md[2,3] <- NA
> md[4,1] <- NA
> md
> vapply(md[myvars], function(x) sum(x==5,na.rm=TRUE),1L)
>
> But the result should be by device.
>
> On Tue, Jun 16, 2015 at 1:56 PM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
>> Thank you, Bert.
>> I'll be honest - I am just learning dplyr and was wondering if one
>> could do it in dplyr.
>> But of course your solution is perfect...
>>
>> On Tue, Jun 16, 2015 at 1:50 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> Well, dplyr seems a bit of overkill as it's so simple with plain old
>>> vapply() in base R :
>>>
>>>
>>>> dat <- data.frame (a=sample(1:5,10,rep=TRUE),
>>> +                    b=sample(3:7,10,rep=TRUE),
>>> +                    g = sample(7:9,10,rep=TRUE))
>>>
>>>> vapply(dat,function(x)sum(x==5,na.rm=TRUE),1L)
>>>
>>> a b g
>>> 5 4 0
>>>
>>>
>>>
>>> Cheers,
>>> Bert
>>>
>>> Bert Gunter
>>>
>>> "Data is not information. Information is not knowledge. And knowledge is
>>> certainly not wisdom."
>>>    -- Clifford Stoll
>>>
>>> On Tue, Jun 16, 2015 at 10:24 AM, Dimitri Liakhovitski
>>> <dimitri.liakhovitski at gmail.com> wrote:
>>>>
>>>> Hello!
>>>>
>>>> I have a data frame:
>>>>
>>>> md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c =
>>>> c(1,3,4,3,5,5),
>>>>       device = c(1,1,2,2,3,3))
>>>> myvars = c("a", "b", "c")
>>>> md[2,3] <- NA
>>>> md[4,1] <- NA
>>>> md
>>>>
>>>> I want to count number of 5s in each column - by device. I can do it like
>>>> this:
>>>>
>>>> library(dplyr)
>>>> group_by(md, device) %>%
>>>> summarise(counts.a = sum(a==5, na.rm = T),
>>>>           counts.b = sum(b==5, na.rm = T),
>>>>           counts.c = sum(c==5, na.rm = T))
>>>>
>>>> However, in real life I'll have tons of variables (the length of
>>>> 'myvars' can be very large) - so that I can't specify those counts.a,
>>>> counts.b, etc. manually - dozens of times.
>>>>
>>>> Does dplyr allow to run the count of 5s on all 'myvars' columns at once?
>>>>
>>>>
>>>> --
>>>> Dimitri Liakhovitski
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>>
>>
>> --
>> Dimitri Liakhovitski
>
>
>
> -- 
> Dimitri Liakhovitski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dimitri.liakhovitski at gmail.com  Tue Jun 16 20:11:40 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Tue, 16 Jun 2015 14:11:40 -0400
Subject: [R] dplyr - counting a number of specific values in each column
 - for all columns at once
In-Reply-To: <alpine.LRH.2.11.1506161105080.4043@aeolus.ecy.wa.gov>
References: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
	<CAGxFJbQ7dt5SRQhaxS0yTbcDm-GW1X2=N-vO3fDHkdN3qeco3Q@mail.gmail.com>
	<CAN2xGJZy3_Mz0qSrzpkFuP9Zo24tsqj55TxE-mh7qkX5EYu_4w@mail.gmail.com>
	<CAN2xGJZUrcJVkkA49XFkPkufjEZxJzCSNQbjqxDfErzAJuT=0A@mail.gmail.com>
	<alpine.LRH.2.11.1506161105080.4043@aeolus.ecy.wa.gov>
Message-ID: <CAN2xGJaU_aew+v_v5ZpHn4Nx4F9sJPyCST=p1-FqCHuOWy=L-Q@mail.gmail.com>

Thank you, Clint.
That's the thing: it's relatively easy to do it in base, but the
resulting code is not THAT simple.
I thought dplyr would make it easy...

On Tue, Jun 16, 2015 at 2:06 PM, Clint Bowman <clint at ecy.wa.gov> wrote:
> May want to add headers but the following provides the device number with
> each set fo sums:
>
> for (dev in (unique(md$device)))
> {cat(colSums(subset(md,md$device==dev)==5,na.rm=T),dev,"\n")}
>
> Clint Bowman                    INTERNET:       clint at ecy.wa.gov
> Air Quality Modeler             INTERNET:       clint at math.utah.edu
> Department of Ecology           VOICE:          (360) 407-6815
> PO Box 47600                    FAX:            (360) 407-7534
> Olympia, WA 98504-7600
>
>         USPS:           PO Box 47600, Olympia, WA 98504-7600
>         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>
> On Tue, 16 Jun 2015, Dimitri Liakhovitski wrote:
>
>> Except, of course, Bert, that you forgot that it had to be done by
>> device. Your solution ignores the device.
>>
>> md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c =
>> c(1,3,4,3,5,5),
>>      device = c(1,1,2,2,3,3))
>> myvars = c("a", "b", "c")
>> md[2,3] <- NA
>> md[4,1] <- NA
>> md
>> vapply(md[myvars], function(x) sum(x==5,na.rm=TRUE),1L)
>>
>> But the result should be by device.
>>
>> On Tue, Jun 16, 2015 at 1:56 PM, Dimitri Liakhovitski
>> <dimitri.liakhovitski at gmail.com> wrote:
>>>
>>> Thank you, Bert.
>>> I'll be honest - I am just learning dplyr and was wondering if one
>>> could do it in dplyr.
>>> But of course your solution is perfect...
>>>
>>> On Tue, Jun 16, 2015 at 1:50 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>>>
>>>> Well, dplyr seems a bit of overkill as it's so simple with plain old
>>>> vapply() in base R :
>>>>
>>>>
>>>>> dat <- data.frame (a=sample(1:5,10,rep=TRUE),
>>>>
>>>> +                    b=sample(3:7,10,rep=TRUE),
>>>> +                    g = sample(7:9,10,rep=TRUE))
>>>>
>>>>> vapply(dat,function(x)sum(x==5,na.rm=TRUE),1L)
>>>>
>>>>
>>>> a b g
>>>> 5 4 0
>>>>
>>>>
>>>>
>>>> Cheers,
>>>> Bert
>>>>
>>>> Bert Gunter
>>>>
>>>> "Data is not information. Information is not knowledge. And knowledge is
>>>> certainly not wisdom."
>>>>    -- Clifford Stoll
>>>>
>>>> On Tue, Jun 16, 2015 at 10:24 AM, Dimitri Liakhovitski
>>>> <dimitri.liakhovitski at gmail.com> wrote:
>>>>>
>>>>>
>>>>> Hello!
>>>>>
>>>>> I have a data frame:
>>>>>
>>>>> md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c =
>>>>> c(1,3,4,3,5,5),
>>>>>       device = c(1,1,2,2,3,3))
>>>>> myvars = c("a", "b", "c")
>>>>> md[2,3] <- NA
>>>>> md[4,1] <- NA
>>>>> md
>>>>>
>>>>> I want to count number of 5s in each column - by device. I can do it
>>>>> like
>>>>> this:
>>>>>
>>>>> library(dplyr)
>>>>> group_by(md, device) %>%
>>>>> summarise(counts.a = sum(a==5, na.rm = T),
>>>>>           counts.b = sum(b==5, na.rm = T),
>>>>>           counts.c = sum(c==5, na.rm = T))
>>>>>
>>>>> However, in real life I'll have tons of variables (the length of
>>>>> 'myvars' can be very large) - so that I can't specify those counts.a,
>>>>> counts.b, etc. manually - dozens of times.
>>>>>
>>>>> Does dplyr allow to run the count of 5s on all 'myvars' columns at
>>>>> once?
>>>>>
>>>>>
>>>>> --
>>>>> Dimitri Liakhovitski
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>
>>>
>>>
>>>
>>> --
>>> Dimitri Liakhovitski
>>
>>
>>
>>
>> --
>> Dimitri Liakhovitski
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>



-- 
Dimitri Liakhovitski


From clint at ecy.wa.gov  Tue Jun 16 20:18:07 2015
From: clint at ecy.wa.gov (Clint Bowman)
Date: Tue, 16 Jun 2015 11:18:07 -0700 (PDT)
Subject: [R] dplyr - counting a number of specific values in each column
 - for all columns at once
In-Reply-To: <CAN2xGJaU_aew+v_v5ZpHn4Nx4F9sJPyCST=p1-FqCHuOWy=L-Q@mail.gmail.com>
References: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
	<CAGxFJbQ7dt5SRQhaxS0yTbcDm-GW1X2=N-vO3fDHkdN3qeco3Q@mail.gmail.com>
	<CAN2xGJZy3_Mz0qSrzpkFuP9Zo24tsqj55TxE-mh7qkX5EYu_4w@mail.gmail.com>
	<CAN2xGJZUrcJVkkA49XFkPkufjEZxJzCSNQbjqxDfErzAJuT=0A@mail.gmail.com>
	<alpine.LRH.2.11.1506161105080.4043@aeolus.ecy.wa.gov>
	<CAN2xGJaU_aew+v_v5ZpHn4Nx4F9sJPyCST=p1-FqCHuOWy=L-Q@mail.gmail.com>
Message-ID: <alpine.LRH.2.11.1506161115140.4043@aeolus.ecy.wa.gov>

Thanks, Dimitri.  Burt is the real wizard here--I'll bet he can conjure up 
an elegant solution.

For me, just reaching a desired endpoint is enough<g>.

Clint

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Tue, 16 Jun 2015, Dimitri Liakhovitski wrote:

> Thank you, Clint.
> That's the thing: it's relatively easy to do it in base, but the
> resulting code is not THAT simple.
> I thought dplyr would make it easy...
>
> On Tue, Jun 16, 2015 at 2:06 PM, Clint Bowman <clint at ecy.wa.gov> wrote:
>> May want to add headers but the following provides the device number with
>> each set fo sums:
>>
>> for (dev in (unique(md$device)))
>> {cat(colSums(subset(md,md$device==dev)==5,na.rm=T),dev,"\n")}
>>
>> Clint Bowman                    INTERNET:       clint at ecy.wa.gov
>> Air Quality Modeler             INTERNET:       clint at math.utah.edu
>> Department of Ecology           VOICE:          (360) 407-6815
>> PO Box 47600                    FAX:            (360) 407-7534
>> Olympia, WA 98504-7600
>>
>>         USPS:           PO Box 47600, Olympia, WA 98504-7600
>>         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>>
>> On Tue, 16 Jun 2015, Dimitri Liakhovitski wrote:
>>
>>> Except, of course, Bert, that you forgot that it had to be done by
>>> device. Your solution ignores the device.
>>>
>>> md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c =
>>> c(1,3,4,3,5,5),
>>>      device = c(1,1,2,2,3,3))
>>> myvars = c("a", "b", "c")
>>> md[2,3] <- NA
>>> md[4,1] <- NA
>>> md
>>> vapply(md[myvars], function(x) sum(x==5,na.rm=TRUE),1L)
>>>
>>> But the result should be by device.
>>>
>>> On Tue, Jun 16, 2015 at 1:56 PM, Dimitri Liakhovitski
>>> <dimitri.liakhovitski at gmail.com> wrote:
>>>>
>>>> Thank you, Bert.
>>>> I'll be honest - I am just learning dplyr and was wondering if one
>>>> could do it in dplyr.
>>>> But of course your solution is perfect...
>>>>
>>>> On Tue, Jun 16, 2015 at 1:50 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>>> wrote:
>>>>>
>>>>> Well, dplyr seems a bit of overkill as it's so simple with plain old
>>>>> vapply() in base R :
>>>>>
>>>>>
>>>>>> dat <- data.frame (a=sample(1:5,10,rep=TRUE),
>>>>>
>>>>> +                    b=sample(3:7,10,rep=TRUE),
>>>>> +                    g = sample(7:9,10,rep=TRUE))
>>>>>
>>>>>> vapply(dat,function(x)sum(x==5,na.rm=TRUE),1L)
>>>>>
>>>>>
>>>>> a b g
>>>>> 5 4 0
>>>>>
>>>>>
>>>>>
>>>>> Cheers,
>>>>> Bert
>>>>>
>>>>> Bert Gunter
>>>>>
>>>>> "Data is not information. Information is not knowledge. And knowledge is
>>>>> certainly not wisdom."
>>>>>    -- Clifford Stoll
>>>>>
>>>>> On Tue, Jun 16, 2015 at 10:24 AM, Dimitri Liakhovitski
>>>>> <dimitri.liakhovitski at gmail.com> wrote:
>>>>>>
>>>>>>
>>>>>> Hello!
>>>>>>
>>>>>> I have a data frame:
>>>>>>
>>>>>> md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c =
>>>>>> c(1,3,4,3,5,5),
>>>>>>       device = c(1,1,2,2,3,3))
>>>>>> myvars = c("a", "b", "c")
>>>>>> md[2,3] <- NA
>>>>>> md[4,1] <- NA
>>>>>> md
>>>>>>
>>>>>> I want to count number of 5s in each column - by device. I can do it
>>>>>> like
>>>>>> this:
>>>>>>
>>>>>> library(dplyr)
>>>>>> group_by(md, device) %>%
>>>>>> summarise(counts.a = sum(a==5, na.rm = T),
>>>>>>           counts.b = sum(b==5, na.rm = T),
>>>>>>           counts.c = sum(c==5, na.rm = T))
>>>>>>
>>>>>> However, in real life I'll have tons of variables (the length of
>>>>>> 'myvars' can be very large) - so that I can't specify those counts.a,
>>>>>> counts.b, etc. manually - dozens of times.
>>>>>>
>>>>>> Does dplyr allow to run the count of 5s on all 'myvars' columns at
>>>>>> once?
>>>>>>
>>>>>>
>>>>>> --
>>>>>> Dimitri Liakhovitski
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> Dimitri Liakhovitski
>>>
>>>
>>>
>>>
>>> --
>>> Dimitri Liakhovitski
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
>
>
> -- 
> Dimitri Liakhovitski
>


From charles.santana at gmail.com  Tue Jun 16 20:55:57 2015
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Tue, 16 Jun 2015 20:55:57 +0200
Subject: [R] Polysomnographic data analysis with R?
Message-ID: <CAH-FEnhQ0UfGaC-nj8JcJz5-teybaJqQ-zTvi03pUpPxQwJuDQ@mail.gmail.com>

Dear all,

Do you know if there is any R package or function we can use to analyze
polysomnographic data?

For example, something that can import an EDF file (or in a different
format) and can give some properties of the polysomnographic records like
periods of different sleep phases, etc.

I looked for it in the web and I didn't find. But maybe I used the wrong
key-words.

Any help will be much appreciated!

Best,

Charles
-- 
Um ax?! :)

--
Charles Novaes de Santana, PhD
http://www.imedea.uib-csic.es/~charles

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Tue Jun 16 21:21:50 2015
From: jholtman at gmail.com (jim holtman)
Date: Tue, 16 Jun 2015 15:21:50 -0400
Subject: [R] reading daily snow depth data
In-Reply-To: <CACGkHRPJqi-2EV_+gYv9igBjw0AMT4C8VuzzeyqgEYKgETn6+w@mail.gmail.com>
References: <CACGkHRPJqi-2EV_+gYv9igBjw0AMT4C8VuzzeyqgEYKgETn6+w@mail.gmail.com>
Message-ID: <CAAxdm-4ixstRtWN9KKq2E3npa-onCRWm5hf2Jzp4_bUUZVRmZQ@mail.gmail.com>

Here is an example of reading in the data.  After that it is a data frame
and should be able to process it with dplyr/data.table without much trouble:

> x <- readLines("
http://www1.ncdc.noaa.gov/pub/data/snowmonitoring/fema/06-2015-dlysndpth.txt
")
> writeLines(x, '/temp/snow.txt')  # save for testing
> head(x)
[1]
""

[2] "State:
AL"

[3] "   Lat     Lon  COOP# StnID State City/Station Name
County                     Elev      Jun 1      Jun 2      Jun 3      Jun
4      Jun 5      Jun 6      Jun 7      Jun 8      Jun 9      Jun10
Jun11      Jun12      Jun13      Jun14      Jun15      Jun16"
[4] " 33.59  -85.86 010272          AL ANNISTON ARPT ASOS
CALHOUN                      594      0.000      0.000      0.000
0.000      0.000      0.000      0.000      0.000      0.000
0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
[5] " 33.83  -85.78 014209          AL JACKSONVILLE
CALHOUN                      608  -9999.000  -9999.000  -9999.000
-9999.000  -9999.000      0.000      0.000  -9999.000  -9999.000
-9999.000  -9999.000  -9999.000  -9999.000  -9999.000  -9999.000  -9999.000"
[6] " 34.74  -87.60 015749          AL MUSCLE SHOALS AP
COLBERT                      540      0.000      0.000      0.000
0.000      0.000      0.000      0.000      0.000      0.000
0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
> z <- grepl("(^$)|(^State)|(^   Lat)", x)  # get lines to discard
> xm <- x[!z]  # remove info lines
> head(xm)
[1] " 33.59  -85.86 010272          AL ANNISTON ARPT ASOS
CALHOUN                      594      0.000      0.000      0.000
0.000      0.000      0.000      0.000      0.000      0.000
0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
[2] " 33.83  -85.78 014209          AL JACKSONVILLE
CALHOUN                      608  -9999.000  -9999.000  -9999.000
-9999.000  -9999.000      0.000      0.000  -9999.000  -9999.000
-9999.000  -9999.000  -9999.000  -9999.000  -9999.000  -9999.000  -9999.000"
[3] " 34.74  -87.60 015749          AL MUSCLE SHOALS AP
COLBERT                      540      0.000      0.000      0.000
0.000      0.000      0.000      0.000      0.000      0.000
0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
[4] " 31.32  -85.45 012372          AL DOTHAN FAA AIRPORT
DALE                         374      0.000      0.000      0.000
0.000      0.000      0.000      0.000      0.000      0.000
0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
[5] " 32.70  -87.58 013511          AL GREENSBORO
HALE                         220      0.000      0.000      0.000
0.000      0.000      0.000      0.000      0.000      0.000
0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
[6] " 33.57  -86.74 010831          AL BIRMINGHAM AP ASOS
JEFFERSON                    615      0.000      0.000      0.000
0.000      0.000      0.000      0.000      0.000      0.000
0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
>
> # read in the data
> xf <- textConnection(xm)
> snow <- read.fwf(xf
+         , width = c(6,8,7,10,3,32,26,6,rep(11,16))
+         , comment.char = ''
+         , as.is = TRUE
+         )
> str(snow)
'data.frame':   3067 obs. of  24 variables:
 $ V1 : num  33.6 33.8 34.7 31.3 32.7 ...
 $ V2 : num  -85.9 -85.8 -87.6 -85.5 -87.6 ...
 $ V3 : int  10272 14209 15749 12372 13511 10831 11225 14064 12245 15478 ...
 $ V4 : chr  "          " "          " "          " "          " ...
 $ V5 : chr  "AL " "AL " "AL " "AL " ...
 $ V6 : chr  "ANNISTON ARPT ASOS              "
"JACKSONVILLE                    " "MUSCLE SHOALS AP                "
"DOTHAN FAA AIRPORT              " ...
 $ V7 : chr  "CALHOUN                   " "CALHOUN                   "
"COLBERT                   " "DALE                      " ...
 $ V8 : int  594 608 540 374 220 615 461 624 100 215 ...
 $ V9 : num  0 -9999 0 0 0 ...
 $ V10: num  0 -9999 0 0 0 ...
 $ V11: num  0 -9999 0 0 0 ...
 $ V12: num  0 -9999 0 0 0 ...
 $ V13: num  0 -9999 0 0 0 ...
 $ V14: num  0 0 0 0 0 ...
 $ V15: num  0 0 0 0 0 ...
 $ V16: num  0 -9999 0 0 0 ...
 $ V17: num  0 -9999 0 0 0 ...
 $ V18: num  0 -9999 0 0 0 ...
 $ V19: num  0 -9999 0 0 0 ...
 $ V20: num  0 -9999 0 0 0 ...
 $ V21: num  0 -9999 0 0 0 ...
 $ V22: num  0 -9999 0 0 0 ...
 $ V23: num  0 -9999 0 0 0 ...
 $ V24: num  -9999 -9999 -9999 -9999 -9999 ...
> table(snow$V5)  # tally up the states
AK  AL  AR  AZ  CA  CO  CT  DE  FL  GA  HI  IA  ID  IL  IN  KS  KY  LA  MA
MD  ME  MI  MN  MO  MS  MT
 72  18  65  55  99 128  10   1  30  33   6 112  57 103  85  90  49  29
35  14  40  86  90 124  27 113
NC  ND  NE  NH  NJ  NM  NV  NY  OH  OK  OR  PA  RI  SC  SD  TN  TX  UT  VA
VT  WA  WI  WV  WY
 45  19 136  22  13  53  65  76  31 106  51  84   2  30  79  64 185  68
70  18  56 103  36  84
>


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Tue, Jun 16, 2015 at 11:38 AM, Alemu Tadesse <alemu.tadesse at gmail.com>
wrote:

> Dear All,
>
> I was going to read daily snow data  for each state and station/city from
> the following link. I was not able to separate a given state's data from
> the rest of the contents of the file, read the data to a data frame and
> save it to file.
>
>
> http://www1.ncdc.noaa.gov/pub/data/snowmonitoring/fema/06-2015-dlysndpth.txt
>
> I really appreciate your time and help, and also appreciate any information
>  for an alternative source.
>
> Best,
>
> Alemu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Tue Jun 16 21:47:59 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 16 Jun 2015 14:47:59 -0500
Subject: [R] dplyr - counting a number of specific values in each column
 - for all columns at once
In-Reply-To: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
References: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
Message-ID: <CABdHhvFNT96DUxijVAoP1Di1-4n92qzruvfFbD0NM1A0PxFtFw@mail.gmail.com>

On Tue, Jun 16, 2015 at 12:24 PM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> Hello!
>
> I have a data frame:
>
> md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c = c(1,3,4,3,5,5),
>       device = c(1,1,2,2,3,3))
> myvars = c("a", "b", "c")
> md[2,3] <- NA
> md[4,1] <- NA
> md
>
> I want to count number of 5s in each column - by device. I can do it like this:
>
> library(dplyr)
> group_by(md, device) %>%
> summarise(counts.a = sum(a==5, na.rm = T),
>           counts.b = sum(b==5, na.rm = T),
>           counts.c = sum(c==5, na.rm = T))
>
> However, in real life I'll have tons of variables (the length of
> 'myvars' can be very large) - so that I can't specify those counts.a,
> counts.b, etc. manually - dozens of times.
>
> Does dplyr allow to run the count of 5s on all 'myvars' columns at once?

md %>%
  group_by(device) %>%
  summarise_each(funs(sum(. == 5, na.rm = TRUE)))

Hadley

-- 
http://had.co.nz/


From bob at rudis.net  Tue Jun 16 21:50:55 2015
From: bob at rudis.net (boB Rudis)
Date: Tue, 16 Jun 2015 15:50:55 -0400
Subject: [R] reading daily snow depth data
In-Reply-To: <CAAxdm-4ixstRtWN9KKq2E3npa-onCRWm5hf2Jzp4_bUUZVRmZQ@mail.gmail.com>
References: <CACGkHRPJqi-2EV_+gYv9igBjw0AMT4C8VuzzeyqgEYKgETn6+w@mail.gmail.com>
	<CAAxdm-4ixstRtWN9KKq2E3npa-onCRWm5hf2Jzp4_bUUZVRmZQ@mail.gmail.com>
Message-ID: <CAJ4QxaOA-WvrnzMBszeFPdAAw_dqWJ1H4VgVURJ2cPRNqQ=eYQ@mail.gmail.com>

This look similar to snow data I used last year:
https://github.com/hrbrmstr/snowfirst/blob/master/R/snowfirst.R

All the data worked pretty well.

On Tue, Jun 16, 2015 at 3:21 PM, jim holtman <jholtman at gmail.com> wrote:
> Here is an example of reading in the data.  After that it is a data frame
> and should be able to process it with dplyr/data.table without much trouble:
>
>> x <- readLines("
> http://www1.ncdc.noaa.gov/pub/data/snowmonitoring/fema/06-2015-dlysndpth.txt
> ")
>> writeLines(x, '/temp/snow.txt')  # save for testing
>> head(x)
> [1]
> ""
>
> [2] "State:
> AL"
>
> [3] "   Lat     Lon  COOP# StnID State City/Station Name
> County                     Elev      Jun 1      Jun 2      Jun 3      Jun
> 4      Jun 5      Jun 6      Jun 7      Jun 8      Jun 9      Jun10
> Jun11      Jun12      Jun13      Jun14      Jun15      Jun16"
> [4] " 33.59  -85.86 010272          AL ANNISTON ARPT ASOS
> CALHOUN                      594      0.000      0.000      0.000
> 0.000      0.000      0.000      0.000      0.000      0.000
> 0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
> [5] " 33.83  -85.78 014209          AL JACKSONVILLE
> CALHOUN                      608  -9999.000  -9999.000  -9999.000
> -9999.000  -9999.000      0.000      0.000  -9999.000  -9999.000
> -9999.000  -9999.000  -9999.000  -9999.000  -9999.000  -9999.000  -9999.000"
> [6] " 34.74  -87.60 015749          AL MUSCLE SHOALS AP
> COLBERT                      540      0.000      0.000      0.000
> 0.000      0.000      0.000      0.000      0.000      0.000
> 0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
>> z <- grepl("(^$)|(^State)|(^   Lat)", x)  # get lines to discard
>> xm <- x[!z]  # remove info lines
>> head(xm)
> [1] " 33.59  -85.86 010272          AL ANNISTON ARPT ASOS
> CALHOUN                      594      0.000      0.000      0.000
> 0.000      0.000      0.000      0.000      0.000      0.000
> 0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
> [2] " 33.83  -85.78 014209          AL JACKSONVILLE
> CALHOUN                      608  -9999.000  -9999.000  -9999.000
> -9999.000  -9999.000      0.000      0.000  -9999.000  -9999.000
> -9999.000  -9999.000  -9999.000  -9999.000  -9999.000  -9999.000  -9999.000"
> [3] " 34.74  -87.60 015749          AL MUSCLE SHOALS AP
> COLBERT                      540      0.000      0.000      0.000
> 0.000      0.000      0.000      0.000      0.000      0.000
> 0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
> [4] " 31.32  -85.45 012372          AL DOTHAN FAA AIRPORT
> DALE                         374      0.000      0.000      0.000
> 0.000      0.000      0.000      0.000      0.000      0.000
> 0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
> [5] " 32.70  -87.58 013511          AL GREENSBORO
> HALE                         220      0.000      0.000      0.000
> 0.000      0.000      0.000      0.000      0.000      0.000
> 0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
> [6] " 33.57  -86.74 010831          AL BIRMINGHAM AP ASOS
> JEFFERSON                    615      0.000      0.000      0.000
> 0.000      0.000      0.000      0.000      0.000      0.000
> 0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
>>
>> # read in the data
>> xf <- textConnection(xm)
>> snow <- read.fwf(xf
> +         , width = c(6,8,7,10,3,32,26,6,rep(11,16))
> +         , comment.char = ''
> +         , as.is = TRUE
> +         )
>> str(snow)
> 'data.frame':   3067 obs. of  24 variables:
>  $ V1 : num  33.6 33.8 34.7 31.3 32.7 ...
>  $ V2 : num  -85.9 -85.8 -87.6 -85.5 -87.6 ...
>  $ V3 : int  10272 14209 15749 12372 13511 10831 11225 14064 12245 15478 ...
>  $ V4 : chr  "          " "          " "          " "          " ...
>  $ V5 : chr  "AL " "AL " "AL " "AL " ...
>  $ V6 : chr  "ANNISTON ARPT ASOS              "
> "JACKSONVILLE                    " "MUSCLE SHOALS AP                "
> "DOTHAN FAA AIRPORT              " ...
>  $ V7 : chr  "CALHOUN                   " "CALHOUN                   "
> "COLBERT                   " "DALE                      " ...
>  $ V8 : int  594 608 540 374 220 615 461 624 100 215 ...
>  $ V9 : num  0 -9999 0 0 0 ...
>  $ V10: num  0 -9999 0 0 0 ...
>  $ V11: num  0 -9999 0 0 0 ...
>  $ V12: num  0 -9999 0 0 0 ...
>  $ V13: num  0 -9999 0 0 0 ...
>  $ V14: num  0 0 0 0 0 ...
>  $ V15: num  0 0 0 0 0 ...
>  $ V16: num  0 -9999 0 0 0 ...
>  $ V17: num  0 -9999 0 0 0 ...
>  $ V18: num  0 -9999 0 0 0 ...
>  $ V19: num  0 -9999 0 0 0 ...
>  $ V20: num  0 -9999 0 0 0 ...
>  $ V21: num  0 -9999 0 0 0 ...
>  $ V22: num  0 -9999 0 0 0 ...
>  $ V23: num  0 -9999 0 0 0 ...
>  $ V24: num  -9999 -9999 -9999 -9999 -9999 ...
>> table(snow$V5)  # tally up the states
> AK  AL  AR  AZ  CA  CO  CT  DE  FL  GA  HI  IA  ID  IL  IN  KS  KY  LA  MA
> MD  ME  MI  MN  MO  MS  MT
>  72  18  65  55  99 128  10   1  30  33   6 112  57 103  85  90  49  29
> 35  14  40  86  90 124  27 113
> NC  ND  NE  NH  NJ  NM  NV  NY  OH  OK  OR  PA  RI  SC  SD  TN  TX  UT  VA
> VT  WA  WI  WV  WY
>  45  19 136  22  13  53  65  76  31 106  51  84   2  30  79  64 185  68
> 70  18  56 103  36  84
>>
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Tue, Jun 16, 2015 at 11:38 AM, Alemu Tadesse <alemu.tadesse at gmail.com>
> wrote:
>
>> Dear All,
>>
>> I was going to read daily snow data  for each state and station/city from
>> the following link. I was not able to separate a given state's data from
>> the rest of the contents of the file, read the data to a data frame and
>> save it to file.
>>
>>
>> http://www1.ncdc.noaa.gov/pub/data/snowmonitoring/fema/06-2015-dlysndpth.txt
>>
>> I really appreciate your time and help, and also appreciate any information
>>  for an alternative source.
>>
>> Best,
>>
>> Alemu
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dimitri.liakhovitski at gmail.com  Tue Jun 16 21:52:00 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Tue, 16 Jun 2015 15:52:00 -0400
Subject: [R] dplyr - counting a number of specific values in each column
 - for all columns at once
In-Reply-To: <CABdHhvFNT96DUxijVAoP1Di1-4n92qzruvfFbD0NM1A0PxFtFw@mail.gmail.com>
References: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
	<CABdHhvFNT96DUxijVAoP1Di1-4n92qzruvfFbD0NM1A0PxFtFw@mail.gmail.com>
Message-ID: <CAN2xGJZKtKa-hGQ9H=4ZQuBAY7Fji2EbwQ7bfY0i5RrmRDuQvw@mail.gmail.com>

Thank you guys - it's a great learning: 'summarise_each' and 'funs'

On Tue, Jun 16, 2015 at 3:47 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
> On Tue, Jun 16, 2015 at 12:24 PM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
>> Hello!
>>
>> I have a data frame:
>>
>> md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c = c(1,3,4,3,5,5),
>>       device = c(1,1,2,2,3,3))
>> myvars = c("a", "b", "c")
>> md[2,3] <- NA
>> md[4,1] <- NA
>> md
>>
>> I want to count number of 5s in each column - by device. I can do it like this:
>>
>> library(dplyr)
>> group_by(md, device) %>%
>> summarise(counts.a = sum(a==5, na.rm = T),
>>           counts.b = sum(b==5, na.rm = T),
>>           counts.c = sum(c==5, na.rm = T))
>>
>> However, in real life I'll have tons of variables (the length of
>> 'myvars' can be very large) - so that I can't specify those counts.a,
>> counts.b, etc. manually - dozens of times.
>>
>> Does dplyr allow to run the count of 5s on all 'myvars' columns at once?
>
> md %>%
>   group_by(device) %>%
>   summarise_each(funs(sum(. == 5, na.rm = TRUE)))
>
> Hadley
>
> --
> http://had.co.nz/



-- 
Dimitri Liakhovitski


From mbarrowc at vt.edu  Tue Jun 16 20:50:19 2015
From: mbarrowc at vt.edu (mikebarr)
Date: Tue, 16 Jun 2015 11:50:19 -0700 (PDT)
Subject: [R] mlogit error
Message-ID: <1434480619910-4708706.post@n4.nabble.com>

Hello,

I am trying to run a mixed logit model (panel form) with the mlogit package.
I am running into the following error: "Error in random.nb[, sel, drop = F]
: subscript out of bounds".

I have searched the R Help forum (and online) and see no instances of this
error. Below is the coding that I used which follows along with
"Discrete-Choice Logit Models with R" by Philip A. Viton
(http://facweb.knowlton.ohio-state.edu/pviton/courses2/crp5700/5700-mlogit.pdf).
My dataset consists of 244 individuals each answering 8 choices between 3
alternatives. 

> clogit <- read.csv("/Users/name/Desktop/DCEinR/R365.csv")
> save(clogit,file="/Users/name/Desktop/DCEinR/clogit.rdata")
> load("/Users/name/Desktop/DCEinR/clogit.rdata")
> clogit$mode.ids<-factor(rep(1:3,244))
> clogit$mode.ids<-factor(rep(1:3, 244), labels=c("c1","c2","sq"))
> clogit$indivs<-factor(rep(1:244,each=24))
> CLOGIT<-mlogit.data(clogit,shape="long",
> choice="choice",alt.var="mode.ids", id.var="indivs")
> CLOGIT.mxl <- mlogit(Choice~-1+ASC+Price+Payment+Penalty+Length+Local|0,
> CLOGIT, rpar=c(ASC='n', Price='n', Payment='n', Penalty='n', Length='n',
> Local='n'), R=100, halton=NA, print.level=0, panel=TRUE)

Are there any suggestions on: 1) what does this error mean; and 2) how to
fix this issue?

Thanks in advance.



--
View this message in context: http://r.789695.n4.nabble.com/mlogit-error-tp4708706.html
Sent from the R help mailing list archive at Nabble.com.


From jmtruppia at gmail.com  Tue Jun 16 18:36:37 2015
From: jmtruppia at gmail.com (Juan Manuel Truppia)
Date: Tue, 16 Jun 2015 16:36:37 +0000
Subject: [R] rdde : DDE connections on R
Message-ID: <CAO2XSvca3YeLmYzG4ObZMQadg5qV8neeGpq43zxkO4CV8VNR2g@mail.gmail.com>

Hi all, I'm building a new package for DDE connections on R. It's called
rdde and lives in https://bitbucket.org/juancentro/rdde.
It's in alpha stage, but operational. It has a very simple vignette which
explains the main reason you should try rdde vs tcltk2 (the only other
option available) : performance.
rdde allows the user to reuse connections (conversations). Establishing a
conversation is the most expensive operation in DDE.

Hope someone finds it useful

Regards

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jun 16 22:02:06 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 16 Jun 2015 13:02:06 -0700
Subject: [R] dplyr - counting a number of specific values in each column
 - for all columns at once
In-Reply-To: <CABdHhvFNT96DUxijVAoP1Di1-4n92qzruvfFbD0NM1A0PxFtFw@mail.gmail.com>
References: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
	<CABdHhvFNT96DUxijVAoP1Di1-4n92qzruvfFbD0NM1A0PxFtFw@mail.gmail.com>
Message-ID: <CAGxFJbTDQsKMY1G31oJCFr9=fEBw6j+-q2h7Utun_vpV+K4JEA@mail.gmail.com>

... my bad! -- I filed to read carefully.

A base syntax version is:

dat <- data.frame (a=sample(1:5,10,rep=TRUE),
                   b=sample(3:7,10,rep=TRUE),
                   g = sample(7:9,10,rep=TRUE))

dev <- sample(1:3,10,rep=TRUE)

sapply(dat,function(x)
  tapply(x,dev,function(x)sum(x==5,na.rm=TRUE)))

  a b g
1 2 0 0
2 1 3 0
3 2 1 0

I think, no matter what, that there are 2 loops here: An outer one by
column and an inner one by device within each column.

Being both old and lazy, I have found it easier and more natural to stick
with the basic functional syntax of the "apply" family of functions rather
than to learn an alternative database type syntax (and semantics). My
applications were never so large that the possible execution inefficiency
mattered. However, it certainly might for others.  And of course, what is
"natural" for me might not be for others.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Tue, Jun 16, 2015 at 12:47 PM, Hadley Wickham <h.wickham at gmail.com>
wrote:

> On Tue, Jun 16, 2015 at 12:24 PM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
> > Hello!
> >
> > I have a data frame:
> >
> > md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c =
> c(1,3,4,3,5,5),
> >       device = c(1,1,2,2,3,3))
> > myvars = c("a", "b", "c")
> > md[2,3] <- NA
> > md[4,1] <- NA
> > md
> >
> > I want to count number of 5s in each column - by device. I can do it
> like this:
> >
> > library(dplyr)
> > group_by(md, device) %>%
> > summarise(counts.a = sum(a==5, na.rm = T),
> >           counts.b = sum(b==5, na.rm = T),
> >           counts.c = sum(c==5, na.rm = T))
> >
> > However, in real life I'll have tons of variables (the length of
> > 'myvars' can be very large) - so that I can't specify those counts.a,
> > counts.b, etc. manually - dozens of times.
> >
> > Does dplyr allow to run the count of 5s on all 'myvars' columns at once?
>
> md %>%
>   group_by(device) %>%
>   summarise_each(funs(sum(. == 5, na.rm = TRUE)))
>
> Hadley
>
> --
> http://had.co.nz/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Jun 16 22:22:54 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 16 Jun 2015 20:22:54 +0000
Subject: [R] dplyr - counting a number of specific values in each column
 - for all columns at once
In-Reply-To: <CAGxFJbTDQsKMY1G31oJCFr9=fEBw6j+-q2h7Utun_vpV+K4JEA@mail.gmail.com>
References: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
	<CABdHhvFNT96DUxijVAoP1Di1-4n92qzruvfFbD0NM1A0PxFtFw@mail.gmail.com>
	<CAGxFJbTDQsKMY1G31oJCFr9=fEBw6j+-q2h7Utun_vpV+K4JEA@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D69346B@mb02.ads.tamu.edu>

Not in base, but in stats:

> aggregate(md[,-4]==5, list(device=md$device), sum, na.rm=TRUE)
  device a b c
1      1 1 2 0
2      2 0 1 0
3      3 1 0 2

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Tuesday, June 16, 2015 3:02 PM
To: Hadley Wickham
Cc: r-help
Subject: Re: [R] dplyr - counting a number of specific values in each column - for all columns at once

... my bad! -- I filed to read carefully.

A base syntax version is:

dat <- data.frame (a=sample(1:5,10,rep=TRUE),
                   b=sample(3:7,10,rep=TRUE),
                   g = sample(7:9,10,rep=TRUE))

dev <- sample(1:3,10,rep=TRUE)

sapply(dat,function(x)
  tapply(x,dev,function(x)sum(x==5,na.rm=TRUE)))

  a b g
1 2 0 0
2 1 3 0
3 2 1 0

I think, no matter what, that there are 2 loops here: An outer one by
column and an inner one by device within each column.

Being both old and lazy, I have found it easier and more natural to stick
with the basic functional syntax of the "apply" family of functions rather
than to learn an alternative database type syntax (and semantics). My
applications were never so large that the possible execution inefficiency
mattered. However, it certainly might for others.  And of course, what is
"natural" for me might not be for others.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Tue, Jun 16, 2015 at 12:47 PM, Hadley Wickham <h.wickham at gmail.com>
wrote:

> On Tue, Jun 16, 2015 at 12:24 PM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
> > Hello!
> >
> > I have a data frame:
> >
> > md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c =
> c(1,3,4,3,5,5),
> >       device = c(1,1,2,2,3,3))
> > myvars = c("a", "b", "c")
> > md[2,3] <- NA
> > md[4,1] <- NA
> > md
> >
> > I want to count number of 5s in each column - by device. I can do it
> like this:
> >
> > library(dplyr)
> > group_by(md, device) %>%
> > summarise(counts.a = sum(a==5, na.rm = T),
> >           counts.b = sum(b==5, na.rm = T),
> >           counts.c = sum(c==5, na.rm = T))
> >
> > However, in real life I'll have tons of variables (the length of
> > 'myvars' can be very large) - so that I can't specify those counts.a,
> > counts.b, etc. manually - dozens of times.
> >
> > Does dplyr allow to run the count of 5s on all 'myvars' columns at once?
>
> md %>%
>   group_by(device) %>%
>   summarise_each(funs(sum(. == 5, na.rm = TRUE)))
>
> Hadley
>
> --
> http://had.co.nz/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Jun 16 22:42:41 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 16 Jun 2015 13:42:41 -0700
Subject: [R] dplyr - counting a number of specific values in each column
	- for all columns at once
In-Reply-To: <alpine.LRH.2.11.1506161115140.4043@aeolus.ecy.wa.gov>
References: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
	<CAGxFJbQ7dt5SRQhaxS0yTbcDm-GW1X2=N-vO3fDHkdN3qeco3Q@mail.gmail.com>
	<CAN2xGJZy3_Mz0qSrzpkFuP9Zo24tsqj55TxE-mh7qkX5EYu_4w@mail.gmail.com>
	<CAN2xGJZUrcJVkkA49XFkPkufjEZxJzCSNQbjqxDfErzAJuT=0A@mail.gmail.com>
	<alpine.LRH.2.11.1506161105080.4043@aeolus.ecy.wa.gov>
	<CAN2xGJaU_aew+v_v5ZpHn4Nx4F9sJPyCST=p1-FqCHuOWy=L-Q@mail.gmail.com>
	<alpine.LRH.2.11.1506161115140.4043@aeolus.ecy.wa.gov>
Message-ID: <91C049EC-0F7B-4B34-80B9-BD5ABA51CEFA@comcast.net>


On Jun 16, 2015, at 11:18 AM, Clint Bowman wrote:

> Thanks, Dimitri.  Burt is the real wizard here--I'll bet he can conjure up an elegant solution.

This would be base method:

> by( md[-4]==5, md[4], colSums)
device: 1
a b c 
1 2 0 
----------------------------------------------------- 
device: 2
a b c 
1 1 0 
----------------------------------------------------- 
device: 3
a b c 
1 0 2 

You could adapt that to use myvars:

> by(md[myvars]==5, md[!names(md) %in% myvars],colSums)
device: 1
a b c 
1 2 0 
----------------------------------------------------- 
device: 2
a b c 
1 1 0 
----------------------------------------------------- 
device: 3
a b c 
1 0 2 

And if you want them smushed into a matrix then use rbind:

> do.call( rbind, by(md[myvars]==5, md[!names(md) %in% myvars],colSums))
  a b c
1 1 2 0
2 1 1 0
3 1 0 2

> 
> For me, just reaching a desired endpoint is enough<g>.
> 
> Clint
> 
> Clint Bowman			INTERNET:	clint at ecy.wa.gov
> Air Quality Modeler		INTERNET:	clint at math.utah.edu
> Department of Ecology		VOICE:		(360) 407-6815
> PO Box 47600			FAX:		(360) 407-7534
> Olympia, WA 98504-7600
> 
>        USPS:           PO Box 47600, Olympia, WA 98504-7600
>        Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
> 
> On Tue, 16 Jun 2015, Dimitri Liakhovitski wrote:
> 
>> Thank you, Clint.
>> That's the thing: it's relatively easy to do it in base, but the
>> resulting code is not THAT simple.
>> I thought dplyr would make it easy...
>> 
>> On Tue, Jun 16, 2015 at 2:06 PM, Clint Bowman <clint at ecy.wa.gov> wrote:
>>> May want to add headers but the following provides the device number with
>>> each set fo sums:
>>> 
>>> for (dev in (unique(md$device)))
>>> {cat(colSums(subset(md,md$device==dev)==5,na.rm=T),dev,"\n")}
>>> 
>>> Clint Bowman                    INTERNET:       clint at ecy.wa.gov
>>> Air Quality Modeler             INTERNET:       clint at math.utah.edu
>>> Department of Ecology           VOICE:          (360) 407-6815
>>> PO Box 47600                    FAX:            (360) 407-7534
>>> Olympia, WA 98504-7600
>>> 
>>>        USPS:           PO Box 47600, Olympia, WA 98504-7600
>>>        Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>>> 
>>> On Tue, 16 Jun 2015, Dimitri Liakhovitski wrote:
>>> 
>>>> Except, of course, Bert, that you forgot that it had to be done by
>>>> device. Your solution ignores the device.
>>>> 
>>>> md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c =
>>>> c(1,3,4,3,5,5),
>>>>     device = c(1,1,2,2,3,3))
>>>> myvars = c("a", "b", "c")
>>>> md[2,3] <- NA
>>>> md[4,1] <- NA
>>>> md
>>>> vapply(md[myvars], function(x) sum(x==5,na.rm=TRUE),1L)
>>>> 
>>>> But the result should be by device.
>>>> 
>>>> On Tue, Jun 16, 2015 at 1:56 PM, Dimitri Liakhovitski
>>>> <dimitri.liakhovitski at gmail.com> wrote:
>>>>> 
>>>>> Thank you, Bert.
>>>>> I'll be honest - I am just learning dplyr and was wondering if one
>>>>> could do it in dplyr.
>>>>> But of course your solution is perfect...
>>>>> 
>>>>> On Tue, Jun 16, 2015 at 1:50 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>> wrote:
>>>>>> 
>>>>>> Well, dplyr seems a bit of overkill as it's so simple with plain old
>>>>>> vapply() in base R :
>>>>>> 
>>>>>> 
>>>>>>> dat <- data.frame (a=sample(1:5,10,rep=TRUE),
>>>>>> 
>>>>>> +                    b=sample(3:7,10,rep=TRUE),
>>>>>> +                    g = sample(7:9,10,rep=TRUE))
>>>>>> 
>>>>>>> vapply(dat,function(x)sum(x==5,na.rm=TRUE),1L)
>>>>>> 
>>>>>> 
>>>>>> a b g
>>>>>> 5 4 0
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> Cheers,
>>>>>> Bert
>>>>>> 
>>>>>> Bert Gunter
>>>>>> 
>>>>>> "Data is not information. Information is not knowledge. And knowledge is
>>>>>> certainly not wisdom."
>>>>>>   -- Clifford Stoll
>>>>>> 
>>>>>> On Tue, Jun 16, 2015 at 10:24 AM, Dimitri Liakhovitski
>>>>>> <dimitri.liakhovitski at gmail.com> wrote:
>>>>>>> 
>>>>>>> 
>>>>>>> Hello!
>>>>>>> 
>>>>>>> I have a data frame:
>>>>>>> 
>>>>>>> md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c =
>>>>>>> c(1,3,4,3,5,5),
>>>>>>>      device = c(1,1,2,2,3,3))
>>>>>>> myvars = c("a", "b", "c")
>>>>>>> md[2,3] <- NA
>>>>>>> md[4,1] <- NA
>>>>>>> md
>>>>>>> 
>>>>>>> I want to count number of 5s in each column - by device. I can do it
>>>>>>> like
>>>>>>> this:
>>>>>>> 
>>>>>>> library(dplyr)
>>>>>>> group_by(md, device) %>%
>>>>>>> summarise(counts.a = sum(a==5, na.rm = T),
>>>>>>>          counts.b = sum(b==5, na.rm = T),
>>>>>>>          counts.c = sum(c==5, na.rm = T))
>>>>>>> 
>>>>>>> However, in real life I'll have tons of variables (the length of
>>>>>>> 'myvars' can be very large) - so that I can't specify those counts.a,
>>>>>>> counts.b, etc. manually - dozens of times.
>>>>>>> 
>>>>>>> Does dplyr allow to run the count of 5s on all 'myvars' columns at
>>>>>>> once?
>>>>>>> 
>>>>>>> 
>>>>>>> --
>>>>>>> Dimitri Liakhovitski
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>>> 
>>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> --
>>>>> Dimitri Liakhovitski
>>>> 
>>>> 
>>>> 
>>>> 
>>>> --
>>>> Dimitri Liakhovitski
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>> 
>> 
>> 
>> -- 
>> Dimitri Liakhovitski
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From alemu.tadesse at gmail.com  Tue Jun 16 22:47:26 2015
From: alemu.tadesse at gmail.com (Alemu Tadesse)
Date: Tue, 16 Jun 2015 14:47:26 -0600
Subject: [R] reading daily snow depth data
In-Reply-To: <CAJ4QxaOA-WvrnzMBszeFPdAAw_dqWJ1H4VgVURJ2cPRNqQ=eYQ@mail.gmail.com>
References: <CACGkHRPJqi-2EV_+gYv9igBjw0AMT4C8VuzzeyqgEYKgETn6+w@mail.gmail.com>
	<CAAxdm-4ixstRtWN9KKq2E3npa-onCRWm5hf2Jzp4_bUUZVRmZQ@mail.gmail.com>
	<CAJ4QxaOA-WvrnzMBszeFPdAAw_dqWJ1H4VgVURJ2cPRNqQ=eYQ@mail.gmail.com>
Message-ID: <CACGkHROgv2GhnECQaF6epLyUb3SiynLB81OUAN+72_uedA32rg@mail.gmail.com>

Thank you Jim and Bob. This is really big help for me.

Jim, this is your second time to help me out.
Best

Alemu


On Tue, Jun 16, 2015 at 1:50 PM, boB Rudis <bob at rudis.net> wrote:

> This look similar to snow data I used last year:
> https://github.com/hrbrmstr/snowfirst/blob/master/R/snowfirst.R
>
> All the data worked pretty well.
>
> On Tue, Jun 16, 2015 at 3:21 PM, jim holtman <jholtman at gmail.com> wrote:
> > Here is an example of reading in the data.  After that it is a data frame
> > and should be able to process it with dplyr/data.table without much
> trouble:
> >
> >> x <- readLines("
> >
> http://www1.ncdc.noaa.gov/pub/data/snowmonitoring/fema/06-2015-dlysndpth.txt
> > ")
> >> writeLines(x, '/temp/snow.txt')  # save for testing
> >> head(x)
> > [1]
> > ""
> >
> > [2] "State:
> > AL"
> >
> > [3] "   Lat     Lon  COOP# StnID State City/Station Name
> > County                     Elev      Jun 1      Jun 2      Jun 3      Jun
> > 4      Jun 5      Jun 6      Jun 7      Jun 8      Jun 9      Jun10
> > Jun11      Jun12      Jun13      Jun14      Jun15      Jun16"
> > [4] " 33.59  -85.86 010272          AL ANNISTON ARPT ASOS
> > CALHOUN                      594      0.000      0.000      0.000
> > 0.000      0.000      0.000      0.000      0.000      0.000
> > 0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
> > [5] " 33.83  -85.78 014209          AL JACKSONVILLE
> > CALHOUN                      608  -9999.000  -9999.000  -9999.000
> > -9999.000  -9999.000      0.000      0.000  -9999.000  -9999.000
> > -9999.000  -9999.000  -9999.000  -9999.000  -9999.000  -9999.000
> -9999.000"
> > [6] " 34.74  -87.60 015749          AL MUSCLE SHOALS AP
> > COLBERT                      540      0.000      0.000      0.000
> > 0.000      0.000      0.000      0.000      0.000      0.000
> > 0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
> >> z <- grepl("(^$)|(^State)|(^   Lat)", x)  # get lines to discard
> >> xm <- x[!z]  # remove info lines
> >> head(xm)
> > [1] " 33.59  -85.86 010272          AL ANNISTON ARPT ASOS
> > CALHOUN                      594      0.000      0.000      0.000
> > 0.000      0.000      0.000      0.000      0.000      0.000
> > 0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
> > [2] " 33.83  -85.78 014209          AL JACKSONVILLE
> > CALHOUN                      608  -9999.000  -9999.000  -9999.000
> > -9999.000  -9999.000      0.000      0.000  -9999.000  -9999.000
> > -9999.000  -9999.000  -9999.000  -9999.000  -9999.000  -9999.000
> -9999.000"
> > [3] " 34.74  -87.60 015749          AL MUSCLE SHOALS AP
> > COLBERT                      540      0.000      0.000      0.000
> > 0.000      0.000      0.000      0.000      0.000      0.000
> > 0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
> > [4] " 31.32  -85.45 012372          AL DOTHAN FAA AIRPORT
> > DALE                         374      0.000      0.000      0.000
> > 0.000      0.000      0.000      0.000      0.000      0.000
> > 0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
> > [5] " 32.70  -87.58 013511          AL GREENSBORO
> > HALE                         220      0.000      0.000      0.000
> > 0.000      0.000      0.000      0.000      0.000      0.000
> > 0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
> > [6] " 33.57  -86.74 010831          AL BIRMINGHAM AP ASOS
> > JEFFERSON                    615      0.000      0.000      0.000
> > 0.000      0.000      0.000      0.000      0.000      0.000
> > 0.000      0.000      0.000      0.000      0.000      0.000  -9999.000"
> >>
> >> # read in the data
> >> xf <- textConnection(xm)
> >> snow <- read.fwf(xf
> > +         , width = c(6,8,7,10,3,32,26,6,rep(11,16))
> > +         , comment.char = ''
> > +         , as.is = TRUE
> > +         )
> >> str(snow)
> > 'data.frame':   3067 obs. of  24 variables:
> >  $ V1 : num  33.6 33.8 34.7 31.3 32.7 ...
> >  $ V2 : num  -85.9 -85.8 -87.6 -85.5 -87.6 ...
> >  $ V3 : int  10272 14209 15749 12372 13511 10831 11225 14064 12245 15478
> ...
> >  $ V4 : chr  "          " "          " "          " "          " ...
> >  $ V5 : chr  "AL " "AL " "AL " "AL " ...
> >  $ V6 : chr  "ANNISTON ARPT ASOS              "
> > "JACKSONVILLE                    " "MUSCLE SHOALS AP                "
> > "DOTHAN FAA AIRPORT              " ...
> >  $ V7 : chr  "CALHOUN                   " "CALHOUN                   "
> > "COLBERT                   " "DALE                      " ...
> >  $ V8 : int  594 608 540 374 220 615 461 624 100 215 ...
> >  $ V9 : num  0 -9999 0 0 0 ...
> >  $ V10: num  0 -9999 0 0 0 ...
> >  $ V11: num  0 -9999 0 0 0 ...
> >  $ V12: num  0 -9999 0 0 0 ...
> >  $ V13: num  0 -9999 0 0 0 ...
> >  $ V14: num  0 0 0 0 0 ...
> >  $ V15: num  0 0 0 0 0 ...
> >  $ V16: num  0 -9999 0 0 0 ...
> >  $ V17: num  0 -9999 0 0 0 ...
> >  $ V18: num  0 -9999 0 0 0 ...
> >  $ V19: num  0 -9999 0 0 0 ...
> >  $ V20: num  0 -9999 0 0 0 ...
> >  $ V21: num  0 -9999 0 0 0 ...
> >  $ V22: num  0 -9999 0 0 0 ...
> >  $ V23: num  0 -9999 0 0 0 ...
> >  $ V24: num  -9999 -9999 -9999 -9999 -9999 ...
> >> table(snow$V5)  # tally up the states
> > AK  AL  AR  AZ  CA  CO  CT  DE  FL  GA  HI  IA  ID  IL  IN  KS  KY  LA
> MA
> > MD  ME  MI  MN  MO  MS  MT
> >  72  18  65  55  99 128  10   1  30  33   6 112  57 103  85  90  49  29
> > 35  14  40  86  90 124  27 113
> > NC  ND  NE  NH  NJ  NM  NV  NY  OH  OK  OR  PA  RI  SC  SD  TN  TX  UT
> VA
> > VT  WA  WI  WV  WY
> >  45  19 136  22  13  53  65  76  31 106  51  84   2  30  79  64 185  68
> > 70  18  56 103  36  84
> >>
> >
> >
> > Jim Holtman
> > Data Munger Guru
> >
> > What is the problem that you are trying to solve?
> > Tell me what you want to do, not how you want to do it.
> >
> > On Tue, Jun 16, 2015 at 11:38 AM, Alemu Tadesse <alemu.tadesse at gmail.com
> >
> > wrote:
> >
> >> Dear All,
> >>
> >> I was going to read daily snow data  for each state and station/city
> from
> >> the following link. I was not able to separate a given state's data from
> >> the rest of the contents of the file, read the data to a data frame and
> >> save it to file.
> >>
> >>
> >>
> http://www1.ncdc.noaa.gov/pub/data/snowmonitoring/fema/06-2015-dlysndpth.txt
> >>
> >> I really appreciate your time and help, and also appreciate any
> information
> >>  for an alternative source.
> >>
> >> Best,
> >>
> >> Alemu
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jun 16 23:53:23 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 16 Jun 2015 14:53:23 -0700
Subject: [R] dplyr - counting a number of specific values in each column
 - for all columns at once
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D69346B@mb02.ads.tamu.edu>
References: <CAN2xGJY-mb=yA8T-G+TFFRjKBAYncciBLDXn-iTtYW8YGun=ug@mail.gmail.com>
	<CABdHhvFNT96DUxijVAoP1Di1-4n92qzruvfFbD0NM1A0PxFtFw@mail.gmail.com>
	<CAGxFJbTDQsKMY1G31oJCFr9=fEBw6j+-q2h7Utun_vpV+K4JEA@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D69346B@mb02.ads.tamu.edu>
Message-ID: <CAGxFJbS2V24HkeLbBNhDXw+ZhMS2W8hRMs8TtB8pwKedeqgOuQ@mail.gmail.com>

Yes, indeed. Thanks, David.

But if you check, tapply, aggregate(), by(), etc. are all basically
wrappers to lapply() .So it's all a question of what syntax one feels most
comfortable with. However note that data.table, plyR stuff and perhaps
others are different in that they re-implement the underlying engines,
thereby gaining efficiencies that some folks may want as well as new syntax.


Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Tue, Jun 16, 2015 at 1:22 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> Not in base, but in stats:
>
> > aggregate(md[,-4]==5, list(device=md$device), sum, na.rm=TRUE)
>   device a b c
> 1      1 1 2 0
> 2      2 0 1 0
> 3      3 1 0 2
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert
> Gunter
> Sent: Tuesday, June 16, 2015 3:02 PM
> To: Hadley Wickham
> Cc: r-help
> Subject: Re: [R] dplyr - counting a number of specific values in each
> column - for all columns at once
>
> ... my bad! -- I filed to read carefully.
>
> A base syntax version is:
>
> dat <- data.frame (a=sample(1:5,10,rep=TRUE),
>                    b=sample(3:7,10,rep=TRUE),
>                    g = sample(7:9,10,rep=TRUE))
>
> dev <- sample(1:3,10,rep=TRUE)
>
> sapply(dat,function(x)
>   tapply(x,dev,function(x)sum(x==5,na.rm=TRUE)))
>
>   a b g
> 1 2 0 0
> 2 1 3 0
> 3 2 1 0
>
> I think, no matter what, that there are 2 loops here: An outer one by
> column and an inner one by device within each column.
>
> Being both old and lazy, I have found it easier and more natural to stick
> with the basic functional syntax of the "apply" family of functions rather
> than to learn an alternative database type syntax (and semantics). My
> applications were never so large that the possible execution inefficiency
> mattered. However, it certainly might for others.  And of course, what is
> "natural" for me might not be for others.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge is
> certainly not wisdom."
>    -- Clifford Stoll
>
> On Tue, Jun 16, 2015 at 12:47 PM, Hadley Wickham <h.wickham at gmail.com>
> wrote:
>
> > On Tue, Jun 16, 2015 at 12:24 PM, Dimitri Liakhovitski
> > <dimitri.liakhovitski at gmail.com> wrote:
> > > Hello!
> > >
> > > I have a data frame:
> > >
> > > md <- data.frame(a = c(3,5,4,5,3,5), b = c(5,5,5,4,4,1), c =
> > c(1,3,4,3,5,5),
> > >       device = c(1,1,2,2,3,3))
> > > myvars = c("a", "b", "c")
> > > md[2,3] <- NA
> > > md[4,1] <- NA
> > > md
> > >
> > > I want to count number of 5s in each column - by device. I can do it
> > like this:
> > >
> > > library(dplyr)
> > > group_by(md, device) %>%
> > > summarise(counts.a = sum(a==5, na.rm = T),
> > >           counts.b = sum(b==5, na.rm = T),
> > >           counts.c = sum(c==5, na.rm = T))
> > >
> > > However, in real life I'll have tons of variables (the length of
> > > 'myvars' can be very large) - so that I can't specify those counts.a,
> > > counts.b, etc. manually - dozens of times.
> > >
> > > Does dplyr allow to run the count of 5s on all 'myvars' columns at
> once?
> >
> > md %>%
> >   group_by(device) %>%
> >   summarise_each(funs(sum(. == 5, na.rm = TRUE)))
> >
> > Hadley
> >
> > --
> > http://had.co.nz/
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ghather at gmail.com  Wed Jun 17 02:52:18 2015
From: ghather at gmail.com (Greg Hather)
Date: Tue, 16 Jun 2015 20:52:18 -0400
Subject: [R] problem with nlme, environments, and packages
In-Reply-To: <55804CB0.2010808@gmail.com>
References: <CAOtVL=FoH=h6c3hAkBs-8dGQZEJzMgE-oDsxBC6CUAzkDugkow@mail.gmail.com>
	<557FFF11.9020405@gmail.com>
	<CAOtVL=ErvqD_OjUe3oFn8JeFLW+wX1MBxo+iAmjpYQ0eobFJDw@mail.gmail.com>
	<55804CB0.2010808@gmail.com>
Message-ID: <CAOtVL=Eoe=DOo4_O-ZViOm61UUmLRDtUk7EpJ=1ceD52MZjtLQ@mail.gmail.com>

Thank you, Duncan!  Your suggestion worked!

Greg

On Tue, Jun 16, 2015 at 12:20 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 16/06/2015 10:34 AM, Greg Hather wrote:
> > Hi Duncan,
> >
> > I checked the global environment, and it was empty, so I think that
> > rules out the second possibility.  I posted a tarball at
> >
> >
> https://drive.google.com/file/d/0B8hBX90jtuLcaGtOUktqV2V4UUU/view?usp=sharing
> >
> > Thank you for your help!
> >
> > Greg
> >
>
> The problem is that nlme does a lot of evaluation of formula objects
> without taking their associated environment into account.  Fixing it
> doesn't look easy, because the evaluation happens in a lot of places.
>
> One workaround is to put the appropriate environment(s) on the search
> list before calling nlme().  This isn't perfect, because the search
> order will be wrong, but it will get you something.
>
> For example, your main_function could be
>
> main_function <- function(x){
>
>   library(nlme)
>   attach(parent.env(env=environment()))
>   result <- nlme(height ~ SSasymp(age, Asym, R0, lrc) +
> nonlinear_function(age),
>                  data = Loblolly,
>                  fixed = Asym + R0 + lrc ~ 1,
>                  random = Asym ~ 1,
>                  start = c(Asym = 103, R0 = -8.5, lrc = -3.3))
>   detach()
>   result
> }
>
> Duncan
>

	[[alternative HTML version deleted]]


From mmuurr at gmail.com  Wed Jun 17 04:04:41 2015
From: mmuurr at gmail.com (Murat Tasan)
Date: Tue, 16 Jun 2015 20:04:41 -0600
Subject: [R] hash::hash(...) assignment & clearing
Message-ID: <CA+YV+HyGbrRhdmg8CoHn3nBb1apKG+qVvOdNc7+7gHL86NEsJA@mail.gmail.com>

The hash package implements hashmaps which must be cleared prior to
removal to free memory, e.g.:

> x <- hash(some_long_list_of_keys_and_values_here)
> clear(x)
> rm(x)

I first assumed this held for re-assignment, too... e.g. one should:

> x <- hash(some_long_list_of_keys_and_values_here)
> clear(x)
> x <- hash(some_other_long_list_of_keys_and_values_here)

With the clear(x) between the re-assignment of x to prevent memory leaks.

After some testing, though, I'm now not so sure.
I basically repeated this cycle:

> x <- hash(randomly_generated_long_list_of_keys_and_values_here)
> gc()

Memory usage grew only in the first few (3) cycles of this, but then
remained stable as x continued to be re-assigned.
Does anyone know if the assignment operator for a hash object has been
written to force a clear() operation?

Cheers,

-m


From k.kowitski at icloud.com  Wed Jun 17 01:31:11 2015
From: k.kowitski at icloud.com (Kevin Kowitski)
Date: Tue, 16 Jun 2015 23:31:11 +0000 (GMT)
Subject: [R] Exporting from R to Excel or .csv
Message-ID: <51c06627-6eab-4791-9fee-bb36a9e17338@me.com>

Hello,?

? Does anyone have some insight on how to; or where I can find better information on how to, export multiple data.frames of different dimensions to the same .csv or excel file?

-Kevin

From jdnewmil at dcn.davis.CA.us  Wed Jun 17 06:11:26 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 16 Jun 2015 23:11:26 -0500
Subject: [R] Exporting from R to Excel or .csv
In-Reply-To: <51c06627-6eab-4791-9fee-bb36a9e17338@me.com>
References: <51c06627-6eab-4791-9fee-bb36a9e17338@me.com>
Message-ID: <EE1F5DB6-1947-4078-BF9B-D29D44C80386@dcn.davis.CA.us>

A CSV with multiple data frames would not conform to the standard definition of a CSV file.

The XLConnect package can be used to generate Excel workbooks. There are other packages also, but they are mostly either too simplified to allow filling multiple sheets or too finicky for my taste. That said, I avoid creating such complex output formats as much as possible... one data frame = one file is much more portable.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 16, 2015 6:31:11 PM CDT, Kevin Kowitski <k.kowitski at icloud.com> wrote:
>Hello,?
>
>? Does anyone have some insight on how to; or where I can find better
>information on how to, export multiple data.frames of different
>dimensions to the same .csv or excel file?
>
>-Kevin
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From shivibhatia at ymail.com  Wed Jun 17 07:50:21 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Tue, 16 Jun 2015 22:50:21 -0700 (PDT)
Subject: [R] Restricting Decimal Places in the Output
Message-ID: <1434520221318-4708739.post@n4.nabble.com>

Good Morning All,

I have working on a data set where I am finding mean and median for weight
variable on a daily basis. 
The code:

aggr<-aggregate(retail$weight,list(retail$ship.date),mean)
This is giving me an accurate result however with 4 decimal places for the
mean weight. In order to restrict it i used the following syntax:

format(aggr,digits=2,justify = c("right"))
After the execution of this code i have mean weight but now there are no
decimal places. Could you please advice what is incorrect in the syntax.

Thank you, Shivi



--
View this message in context: http://r.789695.n4.nabble.com/Restricting-Decimal-Places-in-the-Output-tp4708739.html
Sent from the R help mailing list archive at Nabble.com.


From venkynov10 at gmail.com  Wed Jun 17 08:43:02 2015
From: venkynov10 at gmail.com (Venky)
Date: Wed, 17 Jun 2015 12:13:02 +0530
Subject: [R] cluster analysis
Message-ID: <CAAM-fZ5Vsohf7bXBVNCf4jX+6cbkUbKmSydhD3h=+T60LftbrQ@mail.gmail.com>

Hi friends,

I have data like this



Group
  Employee size WOE Employee size2 Weight of Evidence 1081680995 0
0.12875537 0.128755 -0.30761 1007079896 1 0.48380133 -0.46544 -0.70464
1000507407 2 0.26029825 -0.46544 0.070221 1006400720 3 0.12875537 0.128755
0.151385 1006916029 4 0.12875537 -0.05955 0.320269 1006717587 5 0.12875537
1002032301 6 0.12875537 1007021594 7 0.26029825 1007118066 8 0.26029825
In this data first variable (Employee size) has 10 rows and variable 2
(employee size2) has only 5 rows

Question 1:there are different number of rows so that, we can able to do
K-means cluster or not?
Question 2:If we run k-means clustering in R answer not coming  because of
NA exists

I have used dataset<-na.omit(dataset)

But that time also i cannot able to run clustering

Please help me to find this answer

	[[alternative HTML version deleted]]


From shivibhatia at ymail.com  Wed Jun 17 09:18:51 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Wed, 17 Jun 2015 00:18:51 -0700 (PDT)
Subject: [R] Aggregating on date at Monthly Level
Message-ID: <1434525531344-4708741.post@n4.nabble.com>

HI All, 
I have situation where i am aggregating weight on monthly and quarterly
level.
I need to summarize weight on variable ship date i.e. shipping date . As
this date is in a character format so used the conversion as:

Shipdate<-as.Date("retail$ship.date", format="%m-%d-%Y"). But when i see the
output of Shipdate the result is NA. 
typeof(Shipdate) gives me "double". I am not sure what this is var type
whereas class (Shipdate) is Date so i am a bit puzzled. 

Then i have created a new var which sums weight and gives me the desired
result- 
aggr<-aggregate(retail$weight,list(retail$ship.date),mean)

Now if i want to group the result on a Month level i used the below syntax
and gives me error:
cut.Date(aggr,breaks = "Month",labels = TRUE). "x must be numeric"- in the
above syntax i have created it as a list.

Is there an easier way to achieve what i am looking for. Kindly suggest. 
Thanks, Shivi



--
View this message in context: http://r.789695.n4.nabble.com/Aggregating-on-date-at-Monthly-Level-tp4708741.html
Sent from the R help mailing list archive at Nabble.com.


From petr.pikal at precheza.cz  Wed Jun 17 13:01:32 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 17 Jun 2015 11:01:32 +0000
Subject: [R] Restricting Decimal Places in the Output
In-Reply-To: <1434520221318-4708739.post@n4.nabble.com>
References: <1434520221318-4708739.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C312B7@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shivi82
> Sent: Wednesday, June 17, 2015 7:50 AM
> To: r-help at r-project.org
> Subject: [R] Restricting Decimal Places in the Output
>
> Good Morning All,
>
> I have working on a data set where I am finding mean and median for
> weight variable on a daily basis.
> The code:
>

How about

aggr<-aggregate(retail$weight,list(retail$ship.date),function(x) round(mean(x,2)))

Cheers
Petr

> This is giving me an accurate result however with 4 decimal places for
> the mean weight. In order to restrict it i used the following syntax:
>
> format(aggr,digits=2,justify = c("right")) After the execution of this
> code i have mean weight but now there are no decimal places. Could you
> please advice what is incorrect in the syntax.
>
> Thank you, Shivi
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Restricting-Decimal-Places-in-the-Output-
> tp4708739.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Wed Jun 17 13:13:44 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 17 Jun 2015 11:13:44 +0000
Subject: [R] cluster analysis
In-Reply-To: <CAAM-fZ5Vsohf7bXBVNCf4jX+6cbkUbKmSydhD3h=+T60LftbrQ@mail.gmail.com>
References: <CAAM-fZ5Vsohf7bXBVNCf4jX+6cbkUbKmSydhD3h=+T60LftbrQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C312D5@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Venky
> Sent: Wednesday, June 17, 2015 8:43 AM
> To: R Help R
> Subject: [R] cluster analysis
>
> Hi friends,
>
> I have data like this
>

In R or elsewhere?

>
>
> Group
>   Employee size WOE Employee size2 Weight of Evidence 1081680995 0
> 0.12875537 0.128755 -0.30761 1007079896 1 0.48380133 -0.46544 -0.70464
> 1000507407 2 0.26029825 -0.46544 0.070221 1006400720 3 0.12875537
> 0.128755
> 0.151385 1006916029 4 0.12875537 -0.05955 0.320269 1006717587 5
> 0.12875537
> 1002032301 6 0.12875537 1007021594 7 0.26029825 1007118066 8 0.26029825
> In this data first variable (Employee size) has 10 rows and variable 2
> (employee size2) has only 5 rows

Extremely messy due to HTML posting. Use plain text post as recommended by Posting Guide.

>
> Question 1:there are different number of rows so that, we can able to
> do K-means cluster or not?

I am not an expert but why not to try it?

> Question 2:If we run k-means clustering in R answer not coming  because
> of NA exists
>
> I have used dataset<-na.omit(dataset)
>
> But that time also i cannot able to run clustering

Perhaps not enough data remained after NA removing.

To get better answer you shall provide reproducible example or at least some usable data.

Cheers
Petr


>
> Please help me to find this answer
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Wed Jun 17 13:23:07 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 17 Jun 2015 11:23:07 +0000
Subject: [R] Aggregating on date at Monthly Level
In-Reply-To: <1434525531344-4708741.post@n4.nabble.com>
References: <1434525531344-4708741.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C312F1@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shivi82
> Sent: Wednesday, June 17, 2015 9:19 AM
> To: r-help at r-project.org
> Subject: [R] Aggregating on date at Monthly Level
>
> HI All,
> I have situation where i am aggregating weight on monthly and quarterly
> level.
> I need to summarize weight on variable ship date i.e. shipping date .
> As this date is in a character format so used the conversion as:
>
> Shipdate<-as.Date("retail$ship.date", format="%m-%d-%Y"). But when i
> see the output of Shipdate the result is NA.

Are you sure that format is in aggreement with ship.date?

> typeof(Shipdate) gives me "double". I am not sure what this is var type
> whereas class (Shipdate) is Date so i am a bit puzzled.
>
> Then i have created a new var which sums weight and gives me the
> desired
> result-
> aggr<-aggregate(retail$weight,list(retail$ship.date),mean)
>
> Now if i want to group the result on a Month level i used the below
> syntax and gives me error:
> cut.Date(aggr,breaks = "Month",labels = TRUE). "x must be numeric"- in
> the above syntax i have created it as a list.

AFAIK aggr is data frame with Group.1 column the ship.date and x column the mean weight for each ship.date. If you want to further aggregate on month you can use the same approach with second parameter in aggregate an indication of months. If you want something else you shall be more specific about your data and intended result.

>
> Is there an easier way to achieve what i am looking for. Kindly
> suggest.

Probably easiest way would be if you familiarise yourself with data types and operations e.g. by reading R-intro.

Cheers
Petr

> Thanks, Shivi
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Aggregating-on-date-at-Monthly-Level-
> tp4708741.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From drjimlemon at gmail.com  Wed Jun 17 13:46:29 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 17 Jun 2015 21:46:29 +1000
Subject: [R] Polysomnographic data analysis with R?
In-Reply-To: <CAH-FEnhQ0UfGaC-nj8JcJz5-teybaJqQ-zTvi03pUpPxQwJuDQ@mail.gmail.com>
References: <CAH-FEnhQ0UfGaC-nj8JcJz5-teybaJqQ-zTvi03pUpPxQwJuDQ@mail.gmail.com>
Message-ID: <CA+8X3fUYtwxkAoTVyyj=JNPMwBWU_=Cq=JHNPGUZy57yRqEc1w@mail.gmail.com>

Hi Charles,
This looks like the European Data Format (EDF and EDF+), which has a
complete file specification. If there is no existing R package, it
might be possible to write an import function from the specification,
something like the functions in the "foreign" package.

Jim


On Wed, Jun 17, 2015 at 4:55 AM, Charles Novaes de Santana
<charles.santana at gmail.com> wrote:
> Dear all,
>
> Do you know if there is any R package or function we can use to analyze
> polysomnographic data?
>
> For example, something that can import an EDF file (or in a different
> format) and can give some properties of the polysomnographic records like
> periods of different sleep phases, etc.
>
> I looked for it in the web and I didn't find. But maybe I used the wrong
> key-words.
>
> Any help will be much appreciated!
>
> Best,
>
> Charles
> --
> Um ax?! :)
>
> --
> Charles Novaes de Santana, PhD
> http://www.imedea.uib-csic.es/~charles
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From charles.santana at gmail.com  Wed Jun 17 14:15:29 2015
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Wed, 17 Jun 2015 14:15:29 +0200
Subject: [R] Polysomnographic data analysis with R?
In-Reply-To: <CA+8X3fUYtwxkAoTVyyj=JNPMwBWU_=Cq=JHNPGUZy57yRqEc1w@mail.gmail.com>
References: <CAH-FEnhQ0UfGaC-nj8JcJz5-teybaJqQ-zTvi03pUpPxQwJuDQ@mail.gmail.com>
	<CA+8X3fUYtwxkAoTVyyj=JNPMwBWU_=Cq=JHNPGUZy57yRqEc1w@mail.gmail.com>
Message-ID: <CAH-FEnhQx+bhwULzJvdYu-Ox4kmPx=oeq=F_VD9McvpOGJ1R4Q@mail.gmail.com>

Dear Jim,

Thank you for your response. Yes, it is the European Data Format you
mention. Actually we can read the data correctly, but I was wondering if
there is any package that can identify different sleep phases automatically
based on the data. I supposed such a package does not exist, it is really
difficult to automatize the identification of sleep phases based only on
data, but I asked here just in case.

Thanks for your attention!

Best,

Charles

On 17 June 2015 at 13:46, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Charles,
> This looks like the European Data Format (EDF and EDF+), which has a
> complete file specification. If there is no existing R package, it
> might be possible to write an import function from the specification,
> something like the functions in the "foreign" package.
>
> Jim
>
>
> On Wed, Jun 17, 2015 at 4:55 AM, Charles Novaes de Santana
> <charles.santana at gmail.com> wrote:
> > Dear all,
> >
> > Do you know if there is any R package or function we can use to analyze
> > polysomnographic data?
> >
> > For example, something that can import an EDF file (or in a different
> > format) and can give some properties of the polysomnographic records like
> > periods of different sleep phases, etc.
> >
> > I looked for it in the web and I didn't find. But maybe I used the wrong
> > key-words.
> >
> > Any help will be much appreciated!
> >
> > Best,
> >
> > Charles
> > --
> > Um ax?! :)
> >
> > --
> > Charles Novaes de Santana, PhD
> > http://www.imedea.uib-csic.es/~charles
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Um ax?! :)

--
Charles Novaes de Santana, PhD
http://www.imedea.uib-csic.es/~charles

	[[alternative HTML version deleted]]


From shivibhatia at ymail.com  Wed Jun 17 14:15:14 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Wed, 17 Jun 2015 05:15:14 -0700 (PDT)
Subject: [R] Restricting Decimal Places in the Output
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C312B7@SRVEXCHMBX.precheza.cz>
References: <1434520221318-4708739.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C312B7@SRVEXCHMBX.precheza.cz>
Message-ID: <1434543314466-4708755.post@n4.nabble.com>

Hi Petr,

The solution you shared worked though it does not show any decimal values.
The output is 
Group.1             x
1    1/1/2015    309450
2   1/10/2015   332780

Instead of mean i used sum & i think that should be fine. 
aggr<-aggregate(retail$weight,list(retail$ship.date),function(x)
round(sum(x,0)))

So if i change above code to x,1 it changes values to 
Group.1             x
1    1/1/2015    309451
2   1/10/2015   332781

Thanks, Shivi




--
View this message in context: http://r.789695.n4.nabble.com/Restricting-Decimal-Places-in-the-Output-tp4708739p4708755.html
Sent from the R help mailing list archive at Nabble.com.


From lists at dewey.myzen.co.uk  Wed Jun 17 14:48:07 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 17 Jun 2015 13:48:07 +0100
Subject: [R] Restricting Decimal Places in the Output
In-Reply-To: <1434543314466-4708755.post@n4.nabble.com>
References: <1434520221318-4708739.post@n4.nabble.com>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C312B7@SRVEXCHMBX.precheza.cz>
	<1434543314466-4708755.post@n4.nabble.com>
Message-ID: <55816C87.60800@dewey.myzen.co.uk>

Dear Shivi

On 17/06/2015 13:15, Shivi82 wrote:
> Hi Petr,
>
> The solution you shared worked though it does not show any decimal values.
> The output is
> Group.1             x
> 1    1/1/2015    309450
> 2   1/10/2015   332780
>
> Instead of mean i used sum & i think that should be fine.
> aggr<-aggregate(retail$weight,list(retail$ship.date),function(x)
> round(sum(x,0)))
>

That adds all the elements of x and zero and then rounds it

> So if i change above code to x,1 it changes values to

That will add all the elements of x and unity and then round it. Notice 
that your result has increased by unity each time.

I think you meant to write round(sum(x), 0) or round(sum(x), 1) as the 
case may be

> Group.1             x
> 1    1/1/2015    309451
> 2   1/10/2015   332781
>
> Thanks, Shivi
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Restricting-Decimal-Places-in-the-Output-tp4708739p4708755.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From petr.pikal at precheza.cz  Wed Jun 17 14:54:17 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 17 Jun 2015 12:54:17 +0000
Subject: [R] Restricting Decimal Places in the Output
In-Reply-To: <1434543314466-4708755.post@n4.nabble.com>
References: <1434520221318-4708739.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C312B7@SRVEXCHMBX.precheza.cz>
	<1434543314466-4708755.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3136F@SRVEXCHMBX.precheza.cz>

Hi

It does not make sense. How you can get same result counting mean and sum? The only way I can imagine is that you have only one value per date. So aggregate does virtually nothing.

round gives you n decimal places based on its second parameter.

> set.seed(111)
> x<-rnorm(1)
> x<-x*1000
> round(x,1)
[1] 235.2
> round(x,2)
[1] 235.22
> round(x,3)
[1] 235.221
> round(x,4)
[1] 235.2207
> round(x,10)
[1] 235.2207116

The last item has less than 10 decimal places due to my options("digits") setting.

> options(digits=20)
> round(x,10)
[1] 235.22071161369999

There are other ways to manipulate with printed digits. You can start with ?options

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shivi82
> Sent: Wednesday, June 17, 2015 2:15 PM
> To: r-help at r-project.org
> Subject: Re: [R] Restricting Decimal Places in the Output
>
> Hi Petr,
>
> The solution you shared worked though it does not show any decimal
> values.
> The output is
> Group.1             x
> 1    1/1/2015    309450
> 2   1/10/2015   332780
>
> Instead of mean i used sum & i think that should be fine.
> aggr<-aggregate(retail$weight,list(retail$ship.date),function(x)
> round(sum(x,0)))
>
> So if i change above code to x,1 it changes values to
> Group.1             x
> 1    1/1/2015    309451
> 2   1/10/2015   332781
>
> Thanks, Shivi
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Restricting-Decimal-Places-in-the-Output-
> tp4708739p4708755.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Mohan.Radhakrishnan at cognizant.com  Wed Jun 17 09:23:34 2015
From: Mohan.Radhakrishnan at cognizant.com (Mohan.Radhakrishnan at cognizant.com)
Date: Wed, 17 Jun 2015 07:23:34 +0000
Subject: [R] Error bars and CI
In-Reply-To: <CADv2QyHkq3=sZv8XC=_MveqhtwjOVQKHUb32DW0HpRXm1GsFOQ@mail.gmail.com>
References: <E1B160F4999FD6449524E16C2CB94E0307691E80@CTSINCHNSXMBE.cts.com>
	<CADv2QyHkq3=sZv8XC=_MveqhtwjOVQKHUb32DW0HpRXm1GsFOQ@mail.gmail.com>
Message-ID: <E1B160F4999FD6449524E16C2CB94E0307692E20@CTSINCHNSXMBE.cts.com>

Your sample code is working. But I am missing the logic when my dataset is involved.

My full dataset is this. It is the V1 column I am interested in.  I am not 'grouping' here.

      V1 IDX
1  0.796   1
2  0.542   2
3  0.510   3
4  0.617   4
5  0.482   5
6  0.387   6
7  0.272   7
8  0.536   8
9  0.498   9
10 0.402  10
11 0.328  11
12 0.542  12
13 0.299  13
14 0.647  14
15 0.291  15
16 0.815  16
17 0.680  17
18 0.363  18
19 0.560  19
20 0.334  20

Thanks,
Mohan

-----Original Message-----
From: Dennis Murphy [mailto:djmuser at gmail.com]
Sent: Tuesday, June 16, 2015 1:18 AM
To: Radhakrishnan, Mohan (Cognizant)
Subject: Re: [R] Error bars and CI

Hi:

Firstly, your dplyr code to generate the summary data frame is unnecessary and distracting, particularly since you didn't provide the input data set; you are asked to provide a *minimal* reproducible example, which you could easily have done with a built-in data set.
That said, to get what I perceive you want, I used the InsectSprays data from the autoloaded datasets package.

# Function to compute standard error of a mean sem <- function(x) sqrt(var(x)/length(x))

## Use insectSprays data for illustration ## Compute mean and SE of count for each level of spray

library(dplyr)
library(ggplot2)

insectSumm <- InsectSprays %>%
                  group_by(spray) %>%
                  summarise(mean = mean(count), se = sem(count))


# Since the x-variable is a factor, need to map group = 1 to # draw lines between factor levels. geom_pointrange() can be # used to produce the 99% CIs per factor level, geom_errorbar() # for the mean +/- SE. I ordered the geoms so that the errorbar # is last, but if you want it (mostly) overwritten, put the # geom_pointrange() call last.

ggplot(insectSumm, aes(x = spray, y = mean)) +
   theme_bw() +
   geom_line(aes(group = 1), size = 1, color = "darkorange") +
   geom_pointrange(aes(ymin = mean - qt(.995, 11) * se,
                      ymax = mean + qt(.995, 11) * se),
                   size = 1.5, color = "firebrick") +
   geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = 0.2,
                   size = 1)

Clearly, you can pipe all the way through the ggplot() call, but I wanted to check the contents of the summary data frame first.

Dennis

On Mon, Jun 15, 2015 at 3:51 AM,  <Mohan.Radhakrishnan at cognizant.com> wrote:
> Hi,
>
> I want to plot a line graph using this data. IDX is x-axis and V1 is y-axis.  I also want standard error bars and 99% CI to be shown. My code is given below. The section that plots the graph is the problem.  I don't see all the points in the line graph with error bars. How can I also show the 99% CI in the graph ?
>
>       V1 IDX
> 1  0.987  21
> 2  0.585  22
> 3  0.770  23
> 4  0.711  24
>
> library(stringr)
> library(dplyr)
> library(ggplot2)
>
> data <- read.table("D:\\jmh\\jmh.txt",sep="\t")
>
> final <-data %>%
>            select(V1) %>%
>               filter(grepl("^Iteration", V1)) %>%
>         mutate(V1 = str_extract(V1, "\\d+\\.\\d*"))
>
> final <- mutate(final,IDX = 1:n())
>
> jc <- final %>%
>               filter(IDX < 21)
>
>
> #Convert to numeric
> jc <- data.frame(sapply(jc, function(x) as.numeric(as.character(x))))
>
> print(jc)
>
> # The following section is the problem.
>
> sem <- function(x){
>        sd(x)/sqrt(length(x))
> }
>
> meanvalue <- apply(jc,2,mean)
> semvalue <- apply(jc, 2, sem)
>
> mean_sem <- data.frame(mean= meanvalue, sem= semvalue,
> group=names(jc))
>
> #larger font
> theme_set(theme_gray(base_size = 20))
>
> #plot using ggplot
> p <- ggplot(mean_sem, aes(x=group, y=mean)) +
>               geom_line(stat='identity') +
>               geom_errorbar(aes(ymin=mean-sem, ymax=mean+sem),
>                            width=.2)
> print(p)
>
> Thanks,
> Mohan
> This e-mail and any files transmitted with it are for the sole use of the intended recipient(s) and may contain confidential and privileged information. If you are not the intended recipient(s), please reply to the sender and destroy all copies of the original message. Any unauthorized review, use, disclosure, dissemination, forwarding, printing or copying of this email, and/or any action taken in reliance on the contents of this e-mail is strictly prohibited and may be unlawful. Where permitted by applicable law, this e-mail and other e-mail communications sent to and from Cognizant e-mail addresses may be monitored.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
This e-mail and any files transmitted with it are for the sole use of the intended recipient(s) and may contain confidential and privileged information. If you are not the intended recipient(s), please reply to the sender and destroy all copies of the original message. Any unauthorized review, use, disclosure, dissemination, forwarding, printing or copying of this email, and/or any action taken in reliance on the contents of this e-mail is strictly prohibited and may be unlawful. Where permitted by applicable law, this e-mail and other e-mail communications sent to and from Cognizant e-mail addresses may be monitored.

From Mohan.Radhakrishnan at cognizant.com  Wed Jun 17 10:13:16 2015
From: Mohan.Radhakrishnan at cognizant.com (Mohan.Radhakrishnan at cognizant.com)
Date: Wed, 17 Jun 2015 08:13:16 +0000
Subject: [R] Error bars and CI
References: <E1B160F4999FD6449524E16C2CB94E0307691E80@CTSINCHNSXMBE.cts.com>
	<CADv2QyHkq3=sZv8XC=_MveqhtwjOVQKHUb32DW0HpRXm1GsFOQ@mail.gmail.com> 
Message-ID: <E1B160F4999FD6449524E16C2CB94E0307692E6A@CTSINCHNSXMBE.cts.com>

I think it could be something like this. But the mean is for the entire set. Not groups.
I get a graph with this code but error bars are not there.


p<-ggplot(jc,aes(IDX,V1,colour=V1))
p <- p + stat_summary(fun.y=mean,geom="point")
p <- p + stat_summary(fun.y=mean,geom="line")
p <- p + stat_summary(fun.data=mean_cl_normal,conf.int = .99, geom="errorbar", width=0.2)


Thanks,
Mohan

-----Original Message-----
From: Radhakrishnan, Mohan (Cognizant)
Sent: Wednesday, June 17, 2015 12:54 PM
To: 'Dennis Murphy'
Cc: r-help at r-project.org
Subject: RE: [R] Error bars and CI

Your sample code is working. But I am missing the logic when my dataset is involved.

My full dataset is this. It is the V1 column I am interested in.  I am not 'grouping' here.

      V1 IDX
1  0.796   1
2  0.542   2
3  0.510   3
4  0.617   4
5  0.482   5
6  0.387   6
7  0.272   7
8  0.536   8
9  0.498   9
10 0.402  10
11 0.328  11
12 0.542  12
13 0.299  13
14 0.647  14
15 0.291  15
16 0.815  16
17 0.680  17
18 0.363  18
19 0.560  19
20 0.334  20

Thanks,
Mohan

-----Original Message-----
From: Dennis Murphy [mailto:djmuser at gmail.com]
Sent: Tuesday, June 16, 2015 1:18 AM
To: Radhakrishnan, Mohan (Cognizant)
Subject: Re: [R] Error bars and CI

Hi:

Firstly, your dplyr code to generate the summary data frame is unnecessary and distracting, particularly since you didn't provide the input data set; you are asked to provide a *minimal* reproducible example, which you could easily have done with a built-in data set.
That said, to get what I perceive you want, I used the InsectSprays data from the autoloaded datasets package.

# Function to compute standard error of a mean sem <- function(x) sqrt(var(x)/length(x))

## Use insectSprays data for illustration ## Compute mean and SE of count for each level of spray

library(dplyr)
library(ggplot2)

insectSumm <- InsectSprays %>%
                  group_by(spray) %>%
                  summarise(mean = mean(count), se = sem(count))


# Since the x-variable is a factor, need to map group = 1 to # draw lines between factor levels. geom_pointrange() can be # used to produce the 99% CIs per factor level, geom_errorbar() # for the mean +/- SE. I ordered the geoms so that the errorbar # is last, but if you want it (mostly) overwritten, put the # geom_pointrange() call last.

ggplot(insectSumm, aes(x = spray, y = mean)) +
   theme_bw() +
   geom_line(aes(group = 1), size = 1, color = "darkorange") +
   geom_pointrange(aes(ymin = mean - qt(.995, 11) * se,
                      ymax = mean + qt(.995, 11) * se),
                   size = 1.5, color = "firebrick") +
   geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = 0.2,
                   size = 1)

Clearly, you can pipe all the way through the ggplot() call, but I wanted to check the contents of the summary data frame first.

Dennis

On Mon, Jun 15, 2015 at 3:51 AM,  <Mohan.Radhakrishnan at cognizant.com> wrote:
> Hi,
>
> I want to plot a line graph using this data. IDX is x-axis and V1 is y-axis.  I also want standard error bars and 99% CI to be shown. My code is given below. The section that plots the graph is the problem.  I don't see all the points in the line graph with error bars. How can I also show the 99% CI in the graph ?
>
>       V1 IDX
> 1  0.987  21
> 2  0.585  22
> 3  0.770  23
> 4  0.711  24
>
> library(stringr)
> library(dplyr)
> library(ggplot2)
>
> data <- read.table("D:\\jmh\\jmh.txt",sep="\t")
>
> final <-data %>%
>            select(V1) %>%
>               filter(grepl("^Iteration", V1)) %>%
>         mutate(V1 = str_extract(V1, "\\d+\\.\\d*"))
>
> final <- mutate(final,IDX = 1:n())
>
> jc <- final %>%
>               filter(IDX < 21)
>
>
> #Convert to numeric
> jc <- data.frame(sapply(jc, function(x) as.numeric(as.character(x))))
>
> print(jc)
>
> # The following section is the problem.
>
> sem <- function(x){
>        sd(x)/sqrt(length(x))
> }
>
> meanvalue <- apply(jc,2,mean)
> semvalue <- apply(jc, 2, sem)
>
> mean_sem <- data.frame(mean= meanvalue, sem= semvalue,
> group=names(jc))
>
> #larger font
> theme_set(theme_gray(base_size = 20))
>
> #plot using ggplot
> p <- ggplot(mean_sem, aes(x=group, y=mean)) +
>               geom_line(stat='identity') +
>               geom_errorbar(aes(ymin=mean-sem, ymax=mean+sem),
>                            width=.2)
> print(p)
>
> Thanks,
> Mohan
> This e-mail and any files transmitted with it are for the sole use of the intended recipient(s) and may contain confidential and privileged information. If you are not the intended recipient(s), please reply to the sender and destroy all copies of the original message. Any unauthorized review, use, disclosure, dissemination, forwarding, printing or copying of this email, and/or any action taken in reliance on the contents of this e-mail is strictly prohibited and may be unlawful. Where permitted by applicable law, this e-mail and other e-mail communications sent to and from Cognizant e-mail addresses may be monitored.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
This e-mail and any files transmitted with it are for the sole use of the intended recipient(s) and may contain confidential and privileged information. If you are not the intended recipient(s), please reply to the sender and destroy all copies of the original message. Any unauthorized review, use, disclosure, dissemination, forwarding, printing or copying of this email, and/or any action taken in reliance on the contents of this e-mail is strictly prohibited and may be unlawful. Where permitted by applicable law, this e-mail and other e-mail communications sent to and from Cognizant e-mail addresses may be monitored.

From mmurenu at tiscali.it  Wed Jun 17 11:58:23 2015
From: mmurenu at tiscali.it (Matteo)
Date: Wed, 17 Jun 2015 11:58:23 +0200
Subject: [R] how to call rbind using arguments from a list
Message-ID: <007c01d0a8e4$263bd690$72b383b0$@tiscali.it>

Hello R users,

I am trying to run the command rbind gathering the name of tables to bind
from a list argument.

Unfortunately I am not able to obtain it.

I would appreciate any suggestions.  Below is a reproducible example with
the problem.

Thanks

Matteo

 

##############################################################

ZA<-data.frame(x = 1:2, y = 1:10,z=letters[1:5])

ZB<-data.frame(x = 1, y = 5:24,z=letters[2])

a<-as.list(ls(pattern= "^Z?"));a

#############################################################

I_would_like_ZC<-rbind(ZA,ZB)  # this is what I would like to have

#############################################################

b<-(paste(a, collapse = ','))

call("rbind",(b)) # I am not able to remove ""

b<-noquote(paste(a, collapse = ','))

call("rbind",(b)) # I am not able to remove  ""


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Jun 17 16:33:40 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 17 Jun 2015 07:33:40 -0700
Subject: [R] how to call rbind using arguments from a list
In-Reply-To: <007c01d0a8e4$263bd690$72b383b0$@tiscali.it>
References: <007c01d0a8e4$263bd690$72b383b0$@tiscali.it>
Message-ID: <CAGxFJbQJj+68Uq+TRZnaUrCNbboDA4ib9rNkfNQr4f-t=R3e3A@mail.gmail.com>

1.  It should be:

a<-as.list(ls(pattern= "^Z."))

to get "Z" at the beginning and 1 further character.

2. Use do.call() instead of call(). The latter does not evaluate the call;
the former does.

3. But most important,  the "args" argument of do.call() must be a list of
names, not character strings. This can be obtained using as.name().

This can all be effected by:

a<-as.list(ls(pattern= "^Z."))
do.call(rbind,lapply(a,as.name))


-- and please post in plain text, not HTML, as HTML often gets mangled when
reproduced on this plain text list.



Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Wed, Jun 17, 2015 at 2:58 AM, Matteo <mmurenu at tiscali.it> wrote:

> Hello R users,
>
> I am trying to run the command rbind gathering the name of tables to bind
> from a list argument.
>
> Unfortunately I am not able to obtain it.
>
> I would appreciate any suggestions.  Below is a reproducible example with
> the problem.
>
> Thanks
>
> Matteo
>
>
>
> ##############################################################
>
> ZA<-data.frame(x = 1:2, y = 1:10,z=letters[1:5])
>
> ZB<-data.frame(x = 1, y = 5:24,z=letters[2])
>
> a<-as.list(ls(pattern= "^Z?"));a
>
> #############################################################
>
> I_would_like_ZC<-rbind(ZA,ZB)  # this is what I would like to have
>
> #############################################################
>
> b<-(paste(a, collapse = ','))
>
> call("rbind",(b)) # I am not able to remove ""
>
> b<-noquote(paste(a, collapse = ','))
>
> call("rbind",(b)) # I am not able to remove  ""
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bernardo_brandaum at yahoo.com.br  Wed Jun 17 18:28:08 2015
From: bernardo_brandaum at yahoo.com.br (Bernardo Santos)
Date: Wed, 17 Jun 2015 16:28:08 +0000 (UTC)
Subject: [R] problem in function specieslevel of bipartite
Message-ID: <1876135427.472956.1434558488245.JavaMail.yahoo@mail.yahoo.com>

Dear all,
I have data for an bipartite mutualistic interaction network and I am trying to generate network metrics for this data set.
All metrics could be calculated correctly. However, when trying to run specieslevel function of the package "bipartite", I have the following problem:
xx <- specieslevel(matt)
Erro em data.frame(degree = c(16, 11, 6, 5, 6, 4, 5, 4, 2, 5, 7, 4, 4,? : 
? string multibyte inv?lida 4
orxx <- specieslevel(matt, index="species strength")
Erro em data.frame(`species strength` = c(8.60588008182592, 3.82680284670328,? : 
? string multibyte inv?lida 4
Do you have a clue on what may be the problem?
Thanks in advance!Best,Bernardo Niebuhr


	[[alternative HTML version deleted]]


From alemu.tadesse at gmail.com  Wed Jun 17 18:55:28 2015
From: alemu.tadesse at gmail.com (Alemu Tadesse)
Date: Wed, 17 Jun 2015 10:55:28 -0600
Subject: [R] Merra hourly data
Message-ID: <CACGkHRPi9a7M77eafKR310JYU=zZVwZr_VEL4-uuBrO8F6BiVg@mail.gmail.com>

I am wondering if any has a script to download hourly Merra data (I am
interested in wind speed and temperature)

Thank you for your help

AT

	[[alternative HTML version deleted]]


From careyshan at gmail.com  Wed Jun 17 19:31:13 2015
From: careyshan at gmail.com (Shane Carey)
Date: Wed, 17 Jun 2015 18:31:13 +0100
Subject: [R] Replace values in a dataframe
Message-ID: <CA+jRDxBipTT3rObEB3FPCV8cWt-cxD7BhtZNoJrYSpXZAOX_Gg@mail.gmail.com>

Hey all,

I have a dataframe that consists of:

structure(list(Color = c("5", "<4","5", "<5", "5"), Unit = c("Hazen",
"Hazen",
"Hazen", "Hazen", "Hazen")), .Names = c("Color", "Unit"), row.names =
c("1:2",
"1:3", "1:4", "1:5","1:6"), class = "data.frame")

I need to find the <4 and have a new column with the result of 4 ? 2 = 2

Similarly

I need to find the <5 and have the new column with the result of 5 ? 2 = 2.5


All other numeric values would be added to the new column also to end up
with:



  Color New value Unit 1:2 5 5 Hazen 1:3 <4 2 Hazen 1:4 5 5 Hazen 1:5 <5
2.5 Hazen 1:6 5 5 Hazen



Thanks for your help!!

-- 
Shane

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Jun 17 19:44:32 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 17 Jun 2015 13:44:32 -0400
Subject: [R] Replace values in a dataframe
In-Reply-To: <CA+jRDxBipTT3rObEB3FPCV8cWt-cxD7BhtZNoJrYSpXZAOX_Gg@mail.gmail.com>
References: <CA+jRDxBipTT3rObEB3FPCV8cWt-cxD7BhtZNoJrYSpXZAOX_Gg@mail.gmail.com>
Message-ID: <CAM_vjun6i1g4Fp4zW+r-SzHCx8q-X6xtZ3C5pRxKg-oW465Eow@mail.gmail.com>

Hi Shane,

On Wed, Jun 17, 2015 at 1:31 PM, Shane Carey <careyshan at gmail.com> wrote:
> Hey all,
>
> I have a dataframe that consists of:
>
> structure(list(Color = c("5", "<4","5", "<5", "5"), Unit = c("Hazen",
> "Hazen",
> "Hazen", "Hazen", "Hazen")), .Names = c("Color", "Unit"), row.names =
> c("1:2",
> "1:3", "1:4", "1:5","1:6"), class = "data.frame")

Thanks for providing data.

>
> I need to find the <4 and have a new column with the result of 4 ? 2 = 2
>
> Similarly
>
> I need to find the <5 and have the new column with the result of 5 ? 2 = 2.5

Are "<4" and "<5" the only possible non-numeric values? If so, this is
an easy way to do it:

> mydata <- structure(list(Color = c("5", "<4","5", "<5", "5"), Unit = c("Hazen",
+ "Hazen",
+ "Hazen", "Hazen", "Hazen")), .Names = c("Color", "Unit"), row.names =
+ c("1:2",
+ "1:3", "1:4", "1:5","1:6"), class = "data.frame")
> mydata
    Color  Unit
1:2     5 Hazen
1:3    <4 Hazen
1:4     5 Hazen
1:5    <5 Hazen
1:6     5 Hazen
> mydata$NewColor <- ifelse(mydata$Color == "<4", 4/2, ifelse(mydata$Color == "<5", 5/2, as.numeric(mydata$Color)))
> mydata
    Color  Unit NewColor
1:2     5 Hazen      5.0
1:3    <4 Hazen      2.0
1:4     5 Hazen      5.0
1:5    <5 Hazen      2.5
1:6     5 Hazen      5.0

This will throw a warning message that you can safely ignore.


> All other numeric values would be added to the new column also to end up
> with:
>
>   Color New value Unit 1:2 5 5 Hazen 1:3 <4 2 Hazen 1:4 5 5 Hazen 1:5 <5
> 2.5 Hazen 1:6 5 5 Hazen

Bonus points for providing data, demerits for posting in HTML so your
email got mangled.

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From bgunter.4567 at gmail.com  Wed Jun 17 20:12:47 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 17 Jun 2015 11:12:47 -0700
Subject: [R] Replace values in a dataframe
In-Reply-To: <CA+jRDxBipTT3rObEB3FPCV8cWt-cxD7BhtZNoJrYSpXZAOX_Gg@mail.gmail.com>
References: <CA+jRDxBipTT3rObEB3FPCV8cWt-cxD7BhtZNoJrYSpXZAOX_Gg@mail.gmail.com>
Message-ID: <CAGxFJbS=ut=PGVqVEatWV24qJ6FiPEuJe2hM=N-7gMJnkL24bA@mail.gmail.com>

Is the following what you want:

(z is your data frame)

> change <-c("2","2.5")
> names(change) <- c("<4","<5")

(note: this can be automated using regular expressions and will work for
lots more values to change. Sarah's ifelse() solution is fine for the
example, but becomes too cumbersome (as she intimated) for more values.)

> z$newcol <- with(z,{
+   for(nm in names(change))Color[Color == nm]<-change[nm]
+   as.numeric(Color)
+ })
> z
    Color  Unit newcol
1:2     5 Hazen    5.0
1:3    <4 Hazen    2.0
1:4     5 Hazen    5.0
1:5    <5 Hazen    2.5
1:6     5 Hazen    5.0

Incidentally, if this is how you are attempting to deal with censored data,
it may be a very bad idea. For why, consult a local statistician or post on
a statistics list like stats.stackexchange.com

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Wed, Jun 17, 2015 at 10:31 AM, Shane Carey <careyshan at gmail.com> wrote:

> Hey all,
>
> I have a dataframe that consists of:
>
> structure(list(Color = c("5", "<4","5", "<5", "5"), Unit = c("Hazen",
> "Hazen",
> "Hazen", "Hazen", "Hazen")), .Names = c("Color", "Unit"), row.names =
> c("1:2",
> "1:3", "1:4", "1:5","1:6"), class = "data.frame")
>
> I need to find the <4 and have a new column with the result of 4 ? 2 = 2
>
> Similarly
>
> I need to find the <5 and have the new column with the result of 5 ? 2 =
> 2.5
>
>
> All other numeric values would be added to the new column also to end up
> with:
>
>
>
>   Color New value Unit 1:2 5 5 Hazen 1:3 <4 2 Hazen 1:4 5 5 Hazen 1:5 <5
> 2.5 Hazen 1:6 5 5 Hazen
>
>
>
> Thanks for your help!!
>
> --
> Shane
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From sjkiss at gmail.com  Wed Jun 17 20:39:31 2015
From: sjkiss at gmail.com (Simon Kiss)
Date: Wed, 17 Jun 2015 14:39:31 -0400
Subject: [R] mlogit.effects()
Message-ID: <4980EEAB-0419-4164-AA43-9C544D5AB530@gmail.com>

Dear colleagues,
I am struggling mightily with the mlogit package.  First, the reason that I am using mlogit as opposed to multinom() in nnet is because my data is ranked, not just ordinal.  So, I?m really trying to fit an exploded logit or rank-ordered model.  All of the covariates of interest are individual-specific, none are alternative specific.  The code below produces a model with my covariates of interest, so that is good. But, I cannot get predict.mlogit or effects.mlogit to work *at all*.  The help package is quite unclear as to how to format the sample data that is fed to either of those two functions.
Can any one help in that regard?  Failing that, can anyone provide a suggestion for an alternative way of modelling ranked categorical data? I?m aware of the pmr and Rankcluster packages. The former however is also poorly documented and the latter is computationally intense to select clusters.  
I?m trying to do this as simply as possible while remaining loyal to the ranked structure of the data. 

Thanks, Simon Kiss

#Loadpackages 
library(RCurl)
library(mlogit)
library(tidyr)
library(dplyr)
#URL where data is stored
dat.url<-      'https://raw.githubusercontent.com/sjkiss/Survey/master/mlogit.out.csv'
#Get data
dat<-read.csv(dat.url)
#Complete cases only as it seems mlogit cannot handle missing values or tied data which in this case you might get because of median imputation
dat<-dat[complete.cases(dat),]
#Tidy data to get it into long format
dat.out<-dat %>%
  gather(Open, Rank, -c(1,9:12)) %>%
  arrange(X, Open, Rank)
#Create mlogit object
mlogit.out<-mlogit.data(dat.out, shape='long',alt.var='Open',choice='Rank', ranked=TRUE,chid.var='X')
#Fit Model
mod1<-mlogit(Rank~1|gender+age+economic+Job,data=mlogit.out)


From ortiz.onate.carlos at gmail.com  Wed Jun 17 17:08:00 2015
From: ortiz.onate.carlos at gmail.com (=?UTF-8?Q?Carlos_Ortiz_O=C3=B1ate?=)
Date: Wed, 17 Jun 2015 17:08:00 +0200
Subject: [R] Problems using nlmrt package
Message-ID: <CAFbOcM3_P6AMDDzUWZcfp22HLQsAxo=qrvEkxBnYgwGzUNW4eg@mail.gmail.com>

Hello to everybody,

I want to implement a non-linear least square curve fitting and I am using
the package "nlmrt", concretely the function nlxb. I have a dataset with
three variables and 176 values, one response variables (R) and two
predicting variables (T and H). When I fit a model of the form R ~
a*b^((T-10)/10) to my data using the function nlxb seems to be all ok with
a complet output; the same happens when I fit a model R ~ a + b*H - c*H^2.
But due to my research interest, when I try to fit a model result of the
product of the above models (R ~ (b1*b2^((T-10)/10))*(b3 + b4*H - b5*H^2) I
do obtain NA values in the SE, tstat and pval fields from the nlxb output,
as showed below:

nlmrt class object: x
residual sumsquares =  25348  on  176 observations
    after  4    Jacobian and  5 function evaluations
  name            coeff          SE       tstat      pval
gradient    JSingval
R10            0.0619936            NA         NA         NA
7.494e-06        8822
Q10              2.27113            NA         NA         NA
5.422e-08       217.5
a                 133.85            NA         NA         NA
-2.288e-09       75.96
b                56.8145            NA         NA         NA
8.058e-09       0.658
c                1.11775            NA         NA         NA
2.8e-07   1.928e-15



I would like to know which error do you think I am making. Attached is the
document which contain the data.

Thank you very much in advance,

Carlos.

-- 
Carlos Ortiz O?ate

PhD student

Department of Agricultural Production

Technical University of Madrid

e-mail: ortiz.onate.carlos at gmail.com <teba at life.ku.dk>
-------------- next part --------------
R	T	H
36.47	14.10	5.95
34.28	14.25	5.65
35.86	14.90	7.78
38.18	18.10	4.53
33.52	14.40	6.15
29.44	14.60	4.55
34.79	14.80	6.78
20.38	16.70	3.58
26.70	14.90	3.00
33.30	14.90	3.65
20.28	15.00	3.58
51.18	16.90	2.78
29.76	14.90	2.48
14.90	15.10	2.40
21.05	15.30	3.10
16.18	17.10	2.85
26.50	11.40	10.85
37.69	11.90	7.08
37.37	11.90	7.30
27.02	12.00	5.83
42.16	7.20	26.03
47.75	7.70	20.15
53.05	7.90	17.78
26.48	8.00	13.53
47.50	7.20	11.45
28.47	7.40	20.85
45.62	7.40	15.23
42.31	7.90	16.45
18.10	4.10	27.35
27.71	5.50	17.58
34.27	5.60	28.33
27.75	5.70	21.03
33.09	4.20	37.28
19.05	4.20	41.63
14.08	4.80	36.48
23.15	5.30	28.93
24.64	4.30	31.48
35.80	4.40	33.50
23.41	4.40	32.63
29.63	4.60	25.25
78.01	10.00	25.45
60.40	10.20	28.28
61.32	10.20	32.35
48.25	10.30	28.45
54.62	11.00	18.63
55.19	11.10	21.18
69.03	11.80	22.03
64.01	14.40	15.78
41.20	12.70	16.43
39.20	12.80	12.63
35.20	12.90	12.88
79.98	15.30	11.03
69.60	13.80	27.65
64.32	14.00	18.20
93.22	14.30	24.58
91.86	15.80	22.23
50.28	14.40	4.73
37.03	14.50	5.03
47.23	14.90	5.33
47.65	16.80	3.93
48.68	14.90	8.38
73.43	14.90	10.00
47.31	15.10	7.38
75.10	15.90	11.93
45.40	12.60	10.13
47.86	12.90	9.28
49.39	13.10	12.05
37.27	13.70	5.53
41.63	8.40	11.43
53.83	9.10	11.48
36.66	9.20	8.85
44.03	9.60	11.23
45.94	5.90	29.70
60.64	6.60	14.98
48.91	6.60	23.83
47.02	6.60	25.13
13.62	1.30	14.98
24.86	1.60	13.75
27.28	1.80	17.08
28.16	2.20	14.13
23.29	2.60	39.65
23.23	2.60	36.35
25.10	2.70	36.05
25.68	3.40	32.85
54.88	9.90	26.80
39.19	10.50	25.23
59.74	10.90	25.03
42.39	12.50	26.23
49.24	6.80	30.65
52.70	7.00	30.00
49.18	7.50	29.43
69.69	7.60	29.30
56.05	9.80	28.78
45.72	9.90	26.53
56.07	10.30	28.70
48.40	11.80	29.25
39.10	14.60	11.15
58.45	14.90	9.58
78.41	15.50	6.50
65.89	15.70	12.05
45.25	13.40	5.40
45.87	14.00	5.00
32.47	14.40	7.05
46.08	16.70	1.65
43.08	16.70	4.18
50.24	17.10	6.43
39.22	17.60	4.83
26.41	17.70	5.30
37.58	12.30	5.78
20.67	12.90	3.15
25.80	12.90	2.63
27.71	13.20	3.80
22.74	13.20	4.50
17.18	13.40	4.50
17.95	13.70	5.75
15.77	14.30	4.75
80.91	6.60	24.25
37.71	6.80	17.00
60.88	7.30	17.50
47.62	7.30	15.00
45.92	4.40	27.50
19.28	5.70	19.50
32.94	6.10	22.25
52.46	6.40	19.50
20.03	1.20	25.88
26.29	1.90	23.75
25.09	2.40	21.00
35.26	2.80	23.10
11.00	1.30	27.60
23.49	1.60	22.70
48.21	2.40	21.38
17.76	3.10	24.95
10.95	1.70	27.60
20.90	1.80	24.95
28.61	1.90	22.70
47.77	2.00	21.38
24.96	3.10	19.55
20.90	6.10	19.75
24.63	6.20	17.45
27.10	6.20	22.30
28.96	10.00	18.70
32.04	10.00	15.80
44.78	10.20	19.60
50.55	10.80	21.40
33.81	11.70	9.80
42.71	12.00	12.60
42.32	12.10	11.90
56.49	16.80	11.20
53.77	12.50	12.10
81.96	12.80	12.00
67.85	13.40	9.00
38.25	13.60	9.90
58.57	16.00	3.40
44.80	16.00	3.40
27.37	16.30	3.00
52.12	18.30	5.10
15.24	13.60	1.70
8.97	13.90	1.80
13.60	14.20	3.90
4.24	14.30	2.60
25.73	13.40	3.80
24.97	13.50	3.10
29.62	13.50	3.90
23.37	13.60	7.10
34.60	10.40	17.60
35.98	10.50	9.70
42.13	10.60	10.60
43.51	11.50	6.80
43.17	8.80	14.60
34.13	9.10	9.80
51.48	9.40	11.00
42.47	9.40	8.30
12.27	6.00	26.30
27.19	6.10	17.20
26.06	6.40	20.70
36.07	6.50	19.90

From sarah.bazzocco at vhir.org  Wed Jun 17 16:57:24 2015
From: sarah.bazzocco at vhir.org (Sarah Bazzocco)
Date: Wed, 17 Jun 2015 16:57:24 +0200 (CEST)
Subject: [R] help
In-Reply-To: <1149763207.942010.1434550111614.JavaMail.root@servirmail2>
Message-ID: <697942359.942828.1434553044803.JavaMail.root@servirmail2>




Hello, 

? 

I am a R-beginner and I need some help.?The question is very simple: I need to do a pearson correlations (r,p-value and FDR with BH) from an Expression array (with several thousand genes for lets say 20 cell lines)?with some features of those cell lines. 



My problem I have is the organization of the excel sheets and how to introduce the data into R and run the script. I though the easiest and more organized for me would be two expcel sheets: 

1- Only Expression data (in rows the?genes and in colums cell lines) 

2- Only the features (In row the features (e.g. a) growth rate, b) sensitivity to some drugs) and in columns the cell lines). 



-->That would creat both sheets with 20 colums. 



Now I would like to get a correlation of the gene 1: the expression of all lines with the growth rate. 

the same for gene2... and soforth. I sould obtain as many r,p and BH(FDR) as genes there are. 

the same I would need to do for the sensitivity... and so on. 



Do you think this is doable? I am not at all a bioinformatic expert, so all help is very welcome. 



Thank you very much! 



Kind regards, 



Sarah 



-- 


Sarah Bazzocco, PhD student 
Group of Molecular Oncology, 
CIBBIM-Nanomedicine, 
Vall d'Hebron Hospital Research Institute, 
Passeig Vall d'Hebron 119-129, 
Barcelona 08035, Spain. 
Tel: +34-93-489-4056 

Fax: +34-93-489-3893 
Email: sarah.bazzocco at vhir.org 


	[[alternative HTML version deleted]]


From grams_robins at yahoo.com  Wed Jun 17 19:47:16 2015
From: grams_robins at yahoo.com (Grams Robins)
Date: Wed, 17 Jun 2015 17:47:16 +0000 (UTC)
Subject: [R] Replace values in a dataframe
In-Reply-To: <CA+jRDxBipTT3rObEB3FPCV8cWt-cxD7BhtZNoJrYSpXZAOX_Gg@mail.gmail.com>
References: <CA+jRDxBipTT3rObEB3FPCV8cWt-cxD7BhtZNoJrYSpXZAOX_Gg@mail.gmail.com>
Message-ID: <838690759.541310.1434563236345.JavaMail.yahoo@mail.yahoo.com>

Try this:?
dat=structure(list(Color = c("5", "<4","5", "<5", "5"), Unit = c("Hazen","Hazen","Hazen", "Hazen", "Hazen")), .Names = c("Color", "Unit"), row.names =c("1:2","1:3", "1:4", "1:5","1:6"), class = "data.frame")
dat=as.data.frame(dat)dat$col2 <- rep(" ", nrow(dat))dat[dat$Color == "<4", ][, "col2"] <- "2"dat[dat$Color == "<5", ][, "col2"] <- "2.5" 



     On Wednesday, June 17, 2015 1:33 PM, Shane Carey <careyshan at gmail.com> wrote:
   

 Hey all,

I have a dataframe that consists of:

structure(list(Color = c("5", "<4","5", "<5", "5"), Unit = c("Hazen",
"Hazen",
"Hazen", "Hazen", "Hazen")), .Names = c("Color", "Unit"), row.names =
c("1:2",
"1:3", "1:4", "1:5","1:6"), class = "data.frame")

I need to find the <4 and have a new column with the result of 4 ? 2 = 2

Similarly

I need to find the <5 and have the new column with the result of 5 ? 2 = 2.5


All other numeric values would be added to the new column also to end up
with:



? Color New value Unit 1:2 5 5 Hazen 1:3 <4 2 Hazen 1:4 5 5 Hazen 1:5 <5
2.5 Hazen 1:6 5 5 Hazen



Thanks for your help!!

-- 
Shane

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From grams_robins at yahoo.com  Wed Jun 17 19:52:24 2015
From: grams_robins at yahoo.com (Grams Robins)
Date: Wed, 17 Jun 2015 17:52:24 +0000 (UTC)
Subject: [R] Proc Mixed variance of random effects in R
Message-ID: <480114444.560625.1434563544236.JavaMail.yahoo@mail.yahoo.com>

Hi,?I'm trying to convert the following SAS code in R to get the same result that I get from SAS. Here is the SAS code:
    DATA plants; 
    INPUT  sample $  treatmt $ y ; 
    cards; 

    1   trt1    6.426264755 
    1   trt1    6.95419631 
    1   trt1    6.64385619 
    1   trt2    7.348728154 
    1   trt2    6.247927513 
    1   trt2    6.491853096 
    2   trt1    2.807354922 
    2   trt1    2.584962501 
    2   trt1    3.584962501 
    2   trt2    3.906890596 
    2   trt2    3 
    2   trt2    3.459431619 
    3   trt1    2 
    3   trt1    4.321928095 
    3   trt1    3.459431619 
    3   trt2    3.807354922 
    3   trt2    3 
    3   trt2    2.807354922 
    4   trt1    0 
    4   trt1    0 
    4   trt1    0 
    4   trt2    0 
    4   trt2    0 
    4   trt2    0 
    ; 
    RUN; 

    PROC MIXED ASYCOV NOBOUND  DATA=plants ALPHA=0.05 method=ML; 
    CLASS sample treatmt; 
    MODEL  y = treatmt ; 
    RANDOM int treatmt/ subject=sample ; 
    RUN; I get the following covariance estimates from SAS:Intercept sample ==> 5.5795treatmt sample ==> -0.08455Residual ==> 0.3181I tried the following in R, but I get different results.   options(contrasts = c(factor = "contr.SAS", ordered = "contr.poly"))
    df$sample=as.factor(df$sample) 
    lmer(y~ 1+treatmt+(1+treatmt|sample),REML=FALSE, data = df) Since the results from R are standard deviations, I have to square all results to get the variances.    sample==> 2.357412^2 = 5.557391
    sample*treatmt==>0.004977^2 = 2.477053e-05
    residual==>0.517094^2 = 0.2673862As shown above, the results from SAS and R are different. Do you know how to get the exact values in R?I appreciate any help.Thanks,Gram

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Wed Jun 17 22:55:26 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 18 Jun 2015 08:55:26 +1200
Subject: [R] how to call rbind using arguments from a list
In-Reply-To: <007c01d0a8e4$263bd690$72b383b0$@tiscali.it>
References: <007c01d0a8e4$263bd690$72b383b0$@tiscali.it>
Message-ID: <5581DEBE.8000702@auckland.ac.nz>


I *think* you want:

    ZC <- do.call(rbind,lapply(a,get))

But why do you make "a" a *list* of names rather than a vector of names? 
Generally one uses lists to hold "complicated" structures.
A sequence of character scalars is best stored in an atomic vector.

cheers,

Rolf Turner

P. S.  Thank you for providing a reproducible example! :-)

R. T.

On 17/06/15 21:58, Matteo wrote:
> Hello R users,
>
> I am trying to run the command rbind gathering the name of tables to bind
> from a list argument.
>
> Unfortunately I am not able to obtain it.
>
> I would appreciate any suggestions.  Below is a reproducible example with
> the problem.
>
> Thanks
>
> Matteo
>
>
>
> ##############################################################
>
> ZA<-data.frame(x = 1:2, y = 1:10,z=letters[1:5])
>
> ZB<-data.frame(x = 1, y = 5:24,z=letters[2])
>
> a<-as.list(ls(pattern= "^Z?"));a
>
> #############################################################
>
> I_would_like_ZC<-rbind(ZA,ZB)  # this is what I would like to have
>
> #############################################################
>
> b<-(paste(a, collapse = ','))
>
> call("rbind",(b)) # I am not able to remove ""
>
> b<-noquote(paste(a, collapse = ','))
>
> call("rbind",(b)) # I am not able to remove  ""


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From tr206 at kent.ac.uk  Wed Jun 17 22:57:31 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Wed, 17 Jun 2015 20:57:31 +0000
Subject: [R] generating a data frame for plm regression
Message-ID: <AEB16B1613D44C4793A7E6B6986B7A1201005191C5@EX10-LIVE-MBN2.ad.kent.ac.uk>

Hi everybody,

I am working with the plm package. I am struggling with the generation of the data frame in the plm() function. An example of my data are found in the attachment and I want to run a pooled regression on those. Hence, I need to generate a data frame using pdata.frame() function and this is what I get:

pdata.frame(plm.CoVaR,index=c("Sector","Date"))->data
> head(data,100)
             Sector       Date   DeltaCoVaR
1-01/02/2000      1 01/02/2000 -2.331174662
1-01/02/2001      1 01/02/2001 -2.091099896
1-01/02/2002      1 01/02/2002 -2.126445804
1-01/02/2005      1 01/02/2005 -1.580493046
1-01/02/2006      1 01/02/2006 -1.648100073
1-01/02/2007      1 01/02/2007 -1.494696604

The problem is that I do not understand the first column. Furthermore, I have daily data but the variables are not sorted by their date. The ordering looks confusing and some years are omitted in the R output.

What is wrong here? Can anybody help me?

Thanks in advance.


From syen04 at gmail.com  Thu Jun 18 07:10:39 2015
From: syen04 at gmail.com (Steven Yen)
Date: Thu, 18 Jun 2015 01:10:39 -0400
Subject: [R] Read text file
Message-ID: <558252CF.8090502@gmail.com>

How do I read a block of space-delimited numbers into a column vector 
using the read.table command? Thank you.

-- 
Steven Yen


From wdunlap at tibco.com  Thu Jun 18 07:26:31 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 17 Jun 2015 22:26:31 -0700
Subject: [R] Read text file
In-Reply-To: <558252CF.8090502@gmail.com>
References: <558252CF.8090502@gmail.com>
Message-ID: <CAF8bMcaqu1EjyHF-cpaoANFGb32_4TJXZ+ECOiA9XW-+T=EC7A@mail.gmail.com>

I am not sure what you mean by "a block", but you can probably use
scan() instead of read.table():
  > txt <- "1 21 41 61 81"
  > d <- data.frame(Numbers=scan(text=txt, what="numeric", quiet=TRUE))
  > d
    Numbers
  1       1
  2      21
  3      41
  4      61
  5      81


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Jun 17, 2015 at 10:10 PM, Steven Yen <syen04 at gmail.com> wrote:

> How do I read a block of space-delimited numbers into a column vector
> using the read.table command? Thank you.
>
> --
> Steven Yen
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From olivier.crouzet at univ-nantes.fr  Thu Jun 18 07:28:03 2015
From: olivier.crouzet at univ-nantes.fr (Olivier Crouzet)
Date: Thu, 18 Jun 2015 05:28:03 +0000
Subject: [R] Read text file
In-Reply-To: <558252CF.8090502@gmail.com>
References: <558252CF.8090502@gmail.com>
Message-ID: <931513047-1434605290-cardhu_decombobulator_blackberry.rim.net-222725088-@b3.c4.bise7.blackberry>

Hi, 

I think that you need scan() but you should at least give us an example of your text data.

Olivier.

--
Olivier Crouzet
LLING - Laboratoire de Linguistique de Nantes - EA3827
Universit? de Nantes

-----Original Message-----
From: Steven Yen <syen04 at gmail.com>
Sender: "R-help" <r-help-bounces at r-project.org>Date: Thu, 18 Jun 2015 01:10:39 
To: r-help<r-help at r-project.org>
Reply-To: syen04 at gmail.com
Subject: [R] Read text file

How do I read a block of space-delimited numbers into a column vector 
using the read.table command? Thank you.

-- 
Steven Yen

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From andrewcd at berkeley.edu  Thu Jun 18 04:23:18 2015
From: andrewcd at berkeley.edu (Andrew Crane-Droesch)
Date: Wed, 17 Jun 2015 19:23:18 -0700
Subject: [R] Is there a convenient way of extracting the matrix `solve(X %*%
 t(X) + PENALTY)` from an additive model fit in mgcv?
In-Reply-To: <55822A6A.4010703@gmail.com>
References: <55822A6A.4010703@gmail.com>
Message-ID: <55822B96.4070502@berkeley.edu>

The title says it all. An additive model can be fit by `solve(X %*% t(X) 
+ PENALTY)%*%t(X)%*%y` (though of course there are more efficient ways 
to do it). I want the matrix `solve(X %*% t(X) + PENALTY)` from a fitted 
gam object. GAM objects can be a bit tricky to navigate -- is there a 
convenient way of extracting this?

Happy to explain why I'm interested in this to anyone who would like to 
know, off-list.

Many thanks!
Andrew


From shivibhatia at ymail.com  Thu Jun 18 09:21:35 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Thu, 18 Jun 2015 00:21:35 -0700 (PDT)
Subject: [R] Grouping in R
Message-ID: <1434612095170-4708800.post@n4.nabble.com>

Hi All,

I am working on a data where the total row count is 250000+ and have approx.
20 variables. One of the var on which i need to summarize the data is
Consignor i.e. seller name. 

Now the issue here is after deleting all the duplicate names i still have
55000 unique customer name and i am not sure on how to summarize the data.

Is there a possibility that i could create 8 or 10 groups based on the
weight or booking they made from our company and eventually all 55000
customers would fall under these 10 groups. Then it could be easier for me
to analyze in which group there is a variance on a month on month level.




--
View this message in context: http://r.789695.n4.nabble.com/Grouping-in-R-tp4708800.html
Sent from the R help mailing list archive at Nabble.com.


From thierry.onkelinx at inbo.be  Thu Jun 18 09:54:50 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 18 Jun 2015 09:54:50 +0200
Subject: [R] Proc Mixed variance of random effects in R
In-Reply-To: <480114444.560625.1434563544236.JavaMail.yahoo@mail.yahoo.com>
References: <480114444.560625.1434563544236.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAJuCY5wtTGR=0S5pk3F8gpJf46JH_R5C=uP_+8Tj4yriuJKMsQ@mail.gmail.com>

Dear Gram,

A few things first: Please don't post in HTML, it mangles your text.
R-sig-mixed model is a better list for questions on mixed models. Send
further replies only to that list and not to r-help.

You are probably not fitting the same model in R as the one in SAS. Please
provide the equations of the SAS model and then you can help you translate
that into R code. You are assuming that we all speak SAS, but this is an R
mailing list. The lingua franca among statistical software is mathematics.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-06-17 19:52 GMT+02:00 Grams Robins <grams_robins at yahoo.com>:

> Hi, I'm trying to convert the following SAS code in R to get the same
> result that I get from SAS. Here is the SAS code:
>     DATA plants;
>     INPUT  sample $  treatmt $ y ;
>     cards;
>
>     1   trt1    6.426264755
>     1   trt1    6.95419631
>     1   trt1    6.64385619
>     1   trt2    7.348728154
>     1   trt2    6.247927513
>     1   trt2    6.491853096
>     2   trt1    2.807354922
>     2   trt1    2.584962501
>     2   trt1    3.584962501
>     2   trt2    3.906890596
>     2   trt2    3
>     2   trt2    3.459431619
>     3   trt1    2
>     3   trt1    4.321928095
>     3   trt1    3.459431619
>     3   trt2    3.807354922
>     3   trt2    3
>     3   trt2    2.807354922
>     4   trt1    0
>     4   trt1    0
>     4   trt1    0
>     4   trt2    0
>     4   trt2    0
>     4   trt2    0
>     ;
>     RUN;
>
>     PROC MIXED ASYCOV NOBOUND  DATA=plants ALPHA=0.05 method=ML;
>     CLASS sample treatmt;
>     MODEL  y = treatmt ;
>     RANDOM int treatmt/ subject=sample ;
>     RUN; I get the following covariance estimates from SAS:Intercept
> sample ==> 5.5795treatmt sample ==> -0.08455Residual ==> 0.3181I tried the
> following in R, but I get different results.   options(contrasts = c(factor
> = "contr.SAS", ordered = "contr.poly"))
>     df$sample=as.factor(df$sample)
>     lmer(y~ 1+treatmt+(1+treatmt|sample),REML=FALSE, data = df) Since the
> results from R are standard deviations, I have to square all results to get
> the variances.    sample==> 2.357412^2 = 5.557391
>     sample*treatmt==>0.004977^2 = 2.477053e-05
>     residual==>0.517094^2 = 0.2673862As shown above, the results from SAS
> and R are different. Do you know how to get the exact values in R?I
> appreciate any help.Thanks,Gram
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From pd.mes at cbs.dk  Thu Jun 18 11:04:58 2015
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Thu, 18 Jun 2015 11:04:58 +0200
Subject: [R] R 3.2.1 liftoff
Message-ID: <7442C2E6-39F7-4EF5-9670-245B096EEC05@cbs.dk>

The build system sent R-3.2.1.tar.gz (codename "World-Famous Astronaut") in orbit this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.2.1.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard


These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:


MD5 (AUTHORS) = eb97a5cd38acb1cfc6408988bffef765
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 181370b39076e34f64b842257076cd5c
MD5 (INSTALL) = 3964b9119adeaab9ceb633773fc94aac
MD5 (NEWS) = 6342bc1164e9f8e17713f47cff1910b4
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 8e2f4d1d5228663ae598a09bf1e2bc6b
MD5 (R-latest.tar.gz) = c2aac8b40f84e08e7f8c9068de9239a3
MD5 (README) = aece1dfbd18c1760128c3787f5456af6
MD5 (RESOURCES) = a59076c1ac7e9bab0f0a38b3f57a3914
MD5 (THANKS) = ba00f6cc68a823e1741cfa6011f40ccb
MD5 (R-3/R-3.2.1.tar.gz) = c2aac8b40f84e08e7f8c9068de9239a3


This is the relevant part of the NEWS file

CHANGES IN R 3.2.1:

  NEW FEATURES:

    * utf8ToInt() now checks that its input is valid UTF-8 and returns
      NA if it is not.

    * install.packages() now allows type = "both" with repos = NULL if
      it can infer the type of file.

    * nchar(x, *) and nzchar(x) gain a new argument keepNA which
      governs how the result for NAs in x is determined.  For the R
      3.2.x series, the default remains FALSE which is fully back
      compatible.  From R 3.3.0, the default will change to keepNA = NA
      and you are advised to consider this for code portability.

    * news() more flexibly extracts dates from package NEWS.Rd files.

    * lengths(x) now also works (trivially) for atomic x and hence can
      be used more generally as an efficient replacement of sapply(x,
      length) and similar.

    * The included version of PCRE has been updated to 8.37, a bug-fix
      release.

    * diag() no longer duplicates a matrix when extracting its
      diagonal.

    * as.character.srcref() gains an argument to allow characters
      corresponding to a range of source references to be extracted.

  BUG FIXES:

    * acf() and ccf() now guarantee values strictly in [-1,1] (instead
      of sometimes very slightly outside). PR#15832.

    * as.integer("111111111111") now gives NA (with a warning) as it
      does for the corresponding numeric or negative number coercions.
      Further, as.integer(M + 0.1) now gives M (instead of NA) when M
      is the maximal representable integer.

    * On some platforms nchar(x, "c") and nchar(x, "w") would return
      values (possibly NA) for inputs which were declared to be UTF-8
      but were not, or for invalid strings without a marked encoding in
      a multi-byte locale, rather than give an error.  Additional
      checks have been added to mitigate this.

    * apply(a, M, function(u) c(X = ., Y = .)) again has dimnames
      containing "X" and "Y" (as in R < 3.2.0).

    * (Windows only) In some cases, the --clean option to R CMD INSTALL
      could fail.  (PR#16178)

    * (Windows only) choose.files() would occasionally include
      characters from the result of an earlier call in the result of a
      later one.  (PR#16270)

    * A change in RSiteSearch() in R 3.2.0 caused it to submit invalid
      URLs.  (PR#16329)

    * Rscript and command line R silently ignored incomplete statements
      at the end of a script; now they are reported as parse errors.
      (PR#16350)

    * Parse data for very long strings was not stored.  (PR#16354)

    * plotNode(), the workhorse of the plot method for "dendrogram"s is
      no longer recursive, thanks to Suharto Anggono, and hence also
      works for deeply nested dendrograms.  (PR#15215)

    * The parser could overflow internally when given numbers in
      scientific format with extremely large exponents.  (PR#16358)

    * If the CRAN mirror was not set, install.packages(type = "both")
      and related functions could repeatedly query the user for it.
      (Part of PR#16362)

    * The low-level functions .rowSums() etc. did not check the length
      of their argument, so could segfault. (PR#16367)

    * The quietly argument of library() is now correctly propagated
      from .getRequiredPackages2().

    * Under some circumstances using the internal PCRE when building R
      fron source would cause external libs such as -llzma to be
      omitted from the main link.

    * The .Primitive default methods of the logic operators, i.e., !, &
      and |, now give correct error messages when appropriate, e.g.,
      for `&`(TRUE) or `!`().  (PR#16385)

    * cummax(x) now correctly propagates NAs also when x is of type
      integer and begins with an NA.

    * summaryRprof() could fail when the profile contained only two
      records.  (PR#16395)

    * HTML vignettes opened using vignette() did not support links into
      the rest of the HTML help system.  (Links worked properly when
      the vignette was opened using browseVignettes() or from within
      the help system.)

    * arima(*, xreg = .) (for d >= 1) computes estimated variances
      based on a the number of effective observations as in R version
      3.0.1 and earlier.  (PR#16278)

    * slotNames(.) is now correct for "signature" objects (mostly used
      internally in methods).

    * On some systems, the first string comparison after a locale
      change would result in NA.

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From p.jagadish at inrhythm-inc.com  Thu Jun 18 08:46:24 2015
From: p.jagadish at inrhythm-inc.com (jagadishpchary)
Date: Wed, 17 Jun 2015 23:46:24 -0700 (PDT)
Subject: [R] Cross tabulation with top one variable and side as multiple
 variables
In-Reply-To: <1433839253539-4708379.post@n4.nabble.com>
References: <1433839253539-4708379.post@n4.nabble.com>
Message-ID: <1434609984386-4708799.post@n4.nabble.com>

I think my explanation in the post is not giving the full details on the job
to be done. Sorry for that. Here is what I am doing..

1.	I have a SPSS data set with more than 2000 variables. However for test
purpose I have created a temporary data set with 5 variables which I am
reading it to R environment (Attached the test.sav file).
2.	There is a variable called ?TREND? which has the year data. So all I need
to do is cross tabulate the variables with this Trend variable. 
In SPSS the syntax would be

CTABLES
/VLABELS VARIABLES =ALL DISPLAY=LABEL
/TABLES (AGET +SEXT +EDUCRT +JOBRT ) [COUNT F40.0] by TREND.

The final cross tabulation results are placed in the attached excel report
with sheet name ?Results?.

As I am new to R  - I tried searching the forums for the cross tabulation
with top variable constant and multiple variables as side however I could
not find it. Anyhow I tried using the below syntax :

Xtabs ( ~ AGET +SEXT +EDUCRT +JOBRT + TREND, data=mydata)
summary(~AGET +SEXT +EDUCRT +JOBRT, data= mydata, fun=table)
ftable (mydata, row.vars=c("AGET ", " SEXT ", " EDUCRT " , ?JOBRT?),
col.vars="TREND")

the results are not identical to what I am getting in SPSS

Hence I would request to suggest me a R code that helps me in getting the
results as shown in the attached excel report with sheet name ?Results?.
Test.sav <http://r.789695.n4.nabble.com/file/n4708799/Test.sav>  
Cross_tabulation.xlsx
<http://r.789695.n4.nabble.com/file/n4708799/Cross_tabulation.xlsx>  




--
View this message in context: http://r.789695.n4.nabble.com/Cross-tabulation-with-top-one-variable-and-side-as-multiple-variables-tp4708379p4708799.html
Sent from the R help mailing list archive at Nabble.com.


From sarah.bazzocco at vhir.org  Thu Jun 18 10:19:55 2015
From: sarah.bazzocco at vhir.org (Sarah Bazzocco)
Date: Thu, 18 Jun 2015 10:19:55 +0200 (CEST)
Subject: [R] Correlation matrix for pearson correlation (r,p,BH(FDR))
In-Reply-To: <1418689503.944316.1434612203956.JavaMail.root@servirmail2>
Message-ID: <81248373.944863.1434615595629.JavaMail.root@servirmail2>

This post was called "help" before, I changed the Subject.
Thanks for the comments.
Here the example: (I have the two lists saved as .csv and I can open them in R)

Sheet one- Genes (10 genes expression, not binary, meaured in 10 cell lines)
> genes
     Genes  Cell.line1 Cell.line2  Cell.line3  Cell.line4  Cell.line5
1   KCNAB3 12.02005181 11.1400910 15.60381163 13.44151596 25.37161030
2    KCNB1  0.02457449  1.3028535  0.81538294  0.59318327  0.15332321
3    KCNB2  0.44791862  0.1060137  0.09864136  0.00000000  0.00000000
4     KERA  0.06090217  0.0000000  0.03352993  0.03634781  0.04190912
5   KGFLP1  0.02450101  0.0000000  0.00000000  0.00000000  0.00000000
6   KGFLP2  0.00000000  0.0000000  0.00000000  0.00000000  0.00000000
7    KHDC1  0.00000000  0.0000000  0.00000000  0.00000000  0.00000000
8   KHDC1L  2.31894450  2.8252262  5.29099724  7.44183228  1.94629741
9   KHDC3L  0.00000000  0.0000000  0.00000000  0.00000000  0.00000000
10 KHDRBS1  0.00000000  0.0000000  0.00000000  0.00000000  0.00000000
   Cell.line6 Cell.line7  Cell.line8  Cell.line9 Cell.line10
1  8.12373424 7.67506261 24.43776341 18.33244818    9.224225
2  4.18181234 1.65268403  5.98346320  1.51423807    0.000000
3  0.05857207 0.05945414  0.20733924  0.05830982    0.000000
4  0.00000000 0.00000000  0.07752608  0.01585643   16.664245
5  0.02563099 0.03902548  0.00000000  0.00000000    0.000000
6  0.00000000 0.00000000  0.00000000  0.00000000    0.000000
7  0.00000000 0.00000000  0.00000000  0.00000000    0.000000
8  8.56022436 7.50838343  7.17964645  3.28602729    0.000000
9  0.00000000 0.00000000  0.00000000  0.00000000    3.598534
10 0.00000000 0.03081180  0.00000000  0.00000000    2.600173

Sheet two - features (2 features(Growth rate,drug sensitivity for 10 cell lines)
> features
         Cell.line Cell.line1 Cell.line2 Cell.line3 Cell.line4 Cell.line5
1      Growth rate         NA         NA         NA      51.41         NA
2 Drug sensitivity       5.03       6.57          8       1.26          3
  Cell.line6 Cell.line7 Cell.line8 Cell.line9 Cell.line10
1      41.33      26.76      24.19         NA          NA
2       1.40       1.88       1.33       5.05        9.12

What I found:
corr.test {psych}
corr.test(x, y = NULL, use = "pairwise",method="pearson",adjust="BH",alpha=.01)
--> I adjusted the original command to what I need (BH insted og holm) and alpha=.01 insted of 0.05.

I would be very happy, if someone could show me how to use this command, in particular how to refer as x and y to the two sheets I have (Genes and Features). I would take it from there.

Thanks a lot in advance.

Sarah






----- Original Message -----
From: "Rainer Schuermann" <Rainer.Schuermann at gmx.net>
To: "Sarah Bazzocco" <sarah.bazzocco at vhir.org>
Sent: Thursday, 18 June, 2015 8:14:56 AM
Subject: Re: [R] help



Hi Sarah, 

? 

Not an answer to our question but a piece of well intended advice: 

? 

1. Don't post HTML but plain text. Not only that people will tell you this in a sometimes not very friendly manner - using HTML actually does make posts illegible in this mailing list. Code, and R _is_ code, is always plain text. 

? 

2. Don't pose an abstract problem - this looks too much like "Can you please do my work for me". Show us what you have tried already, and people will happily jump in and provide their thoughts and advice. 

? 

3. Always make sure that you ave a reproducible example in your mail, and a set of data of the same type and structure you are using - ideally using dput(). 

? 

See further advice here 

? 

PLEASE do read the posting guide ? http://www.R-project.org/posting-guide.html 

and provide commented, minimal, self-contained, reproducible code. 

? 

and here: 

? 

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example 

? 

For your problem, R has an immense wealth of ideas and solutions. 

? 

Rgds, 

Rainer 

? 

? 

? 

On Wed June 17 2015 16:57:24 Sarah Bazzocco wrote: 

> 

> Hello, 

> 

> ? 

> 

> I am a R-beginner and I need some help.?The question is very simple: I need to do a pearson correlations (r,p-value and FDR with BH) from an Expression array (with several thousand genes for lets say 20 cell lines)?with some features of those cell lines. 

> 

> 

> 

> My problem I have is the organization of the excel sheets and how to introduce the data into R and run the script. I though the easiest and more organized for me would be two expcel sheets: 

> 

> 1- Only Expression data (in rows the?genes and in colums cell lines) 

> 

> 2- Only the features (In row the features (e.g. a) growth rate, b) sensitivity to some drugs) and in columns the cell lines). 

> 

> 

> 

> -->That would creat both sheets with 20 colums. 

> 

> 

> 

> Now I would like to get a correlation of the gene 1: the expression of all lines with the growth rate. 

> 

> the same for gene2... and soforth. I sould obtain as many r,p and BH(FDR) as genes there are. 

> 

> the same I would need to do for the sensitivity... and so on. 

> 

> 

> 

> Do you think this is doable? I am not at all a bioinformatic expert, so all help is very welcome. 

> 

> 

> 

> Thank you very much! 

> 

> 

> 

> Kind regards, 

> 

> 

> 

> Sarah 

> 

> 

> 

> 

? 

-- 


Sarah Bazzocco, PhD student 
Group of Molecular Oncology, 
CIBBIM-Nanomedicine, 
Vall d'Hebron Hospital Research Institute, 
Passeig Vall d'Hebron 119-129, 
Barcelona 08035, Spain. 
Tel: +34-93-489-4056 

Fax: +34-93-489-3893 
Email: sarah.bazzocco at vhir.org 



-- 


Sarah Bazzocco, PhD student 
Group of Molecular Oncology, 
CIBBIM-Nanomedicine, 
Vall d'Hebron Hospital Research Institute, 
Passeig Vall d'Hebron 119-129, 
Barcelona 08035, Spain. 
Tel: +34-93-489-4056 

Fax: +34-93-489-3893 
Email: sarah.bazzocco at vhir.org 


From petr.pikal at precheza.cz  Thu Jun 18 11:54:10 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 18 Jun 2015 09:54:10 +0000
Subject: [R] Grouping in R
In-Reply-To: <1434612095170-4708800.post@n4.nabble.com>
References: <1434612095170-4708800.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C31577@SRVEXCHMBX.precheza.cz>

Hi

We can only guess what you really want.

Maybe this.

set.seed(111)
cust<-sample(letters[1:5], 500, replace =T)
value<-sample(1:1000, 500)
month<-sample(1:12, 500, replace=T)
dat<-data.frame(cust, value, month)
dat.ag<-aggregate(dat$value, list(dat$month, dat$cust), sum)

> head(dat.ag)
  Group.1 Group.2    x
1       1       a 2444
2       2       a 6234
3       3       a 6082
4       4       a 3691
5       5       a 3044
6       6       a 3534

dput(dat.ag)
structure(list(Group.1 = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
10L, 11L, 12L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
12L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 1L, 2L,
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 1L, 2L, 3L, 4L, 5L,
6L, 7L, 8L, 9L, 10L, 11L, 12L), Group.2 = structure(c(1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L), .Label = c("a", "b",
"c", "d", "e"), class = "factor"), x = c(2444L, 6234L, 6082L,
3691L, 3044L, 3534L, 7444L, 1819L, 2295L, 4774L, 3659L, 1159L,
6592L, 1272L, 8245L, 2324L, 5189L, 3935L, 2945L, 2386L, 2796L,
2869L, 3142L, 4657L, 4411L, 6223L, 3266L, 3842L, 6056L, 7472L,
3879L, 7135L, 4544L, 4498L, 2703L, 3409L, 2748L, 2288L, 2654L,
4995L, 4626L, 5543L, 2162L, 4681L, 5853L, 6229L, 3001L, 5274L,
3852L, 2635L, 5643L, 2809L, 2988L, 3756L, 5180L, 2997L, 4883L,
4208L, 2669L, 3151L)), .Names = c("Group.1", "Group.2", "x"), row.names = c(NA,
-60L), class = "data.frame")
>

But maybe something different. Who knows?

If you wanted grouping by value use

?cut or ?findInterval

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shivi82
> Sent: Thursday, June 18, 2015 9:22 AM
> To: r-help at r-project.org
> Subject: [R] Grouping in R
>
> Hi All,
>
> I am working on a data where the total row count is 250000+ and have
> approx.
> 20 variables. One of the var on which i need to summarize the data is
> Consignor i.e. seller name.
>
> Now the issue here is after deleting all the duplicate names i still
> have 55000 unique customer name and i am not sure on how to summarize
> the data.
>
> Is there a possibility that i could create 8 or 10 groups based on the
> weight or booking they made from our company and eventually all 55000
> customers would fall under these 10 groups. Then it could be easier for
> me to analyze in which group there is a variance on a month on month
> level.
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Grouping-
> in-R-tp4708800.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Mohan.Radhakrishnan at cognizant.com  Thu Jun 18 11:43:12 2015
From: Mohan.Radhakrishnan at cognizant.com (Mohan.Radhakrishnan at cognizant.com)
Date: Thu, 18 Jun 2015 09:43:12 +0000
Subject: [R] Error bars and CI
In-Reply-To: <CADv2QyE=PW7PWXXn3jdm9LtzuNtN4NrjPOKh7hAHCCof-9VqJw@mail.gmail.com>
References: <E1B160F4999FD6449524E16C2CB94E0307691E80@CTSINCHNSXMBE.cts.com>
	<CADv2QyHkq3=sZv8XC=_MveqhtwjOVQKHUb32DW0HpRXm1GsFOQ@mail.gmail.com>
	<E1B160F4999FD6449524E16C2CB94E0307692E6A@CTSINCHNSXMBE.cts.com>
	<CADv2QyE=PW7PWXXn3jdm9LtzuNtN4NrjPOKh7hAHCCof-9VqJw@mail.gmail.com>
Message-ID: <E1B160F4999FD6449524E16C2CB94E0307693587@CTSINCHNSXMBE.cts.com>

Hi Dennis,
                         I have copied the 'r' group. Could you explain ? Why can't we compute CI and error bars using this data set ?
The graph generated has equal-sized error bars and a 99% confidence band. Groups are not needed here. But the error bar and CI calculations could be incorrect but I am able to draw this.

      V1 IDX
1  0.796   1
2  0.542   2
3  0.510   3
4  0.617   4
5  0.482   5
6  0.387   6
7  0.272   7
8  0.536   8
9  0.498   9
10 0.402  10
11 0.328  11
12 0.542  12
13 0.299  13
14 0.647  14
15 0.291  15
16 0.815  16
17 0.680  17
18 0.363  18
19 0.560  19
20 0.334  20

Assume the dataframe is 'jc'.

print(summary(jc$V1))
error <- qt(0.995,df=length(jc$V1)-1)*sd(jc$V1)/sqrt(length(jc$V1))
error1 <- mean(jc$V1)-error
error2 <- mean(jc$V1)+error
print(error1)
print(error2)

q <- qplot(geom = "line",jc$IDX,jc$V1, colour='red')+geom_errorbar(aes(x=jc$IDX, ymin=jc$V1-sd(jc$V1), ymax=jc$V1+sd(jc$V1)), width=0.25)+
                geom_ribbon(aes(x=jc$IDX, y=jc$V1, ymin=error1, ymax=error2),fill="ivory2",alpha = 0.4)+
                xlab('Iterations') + ylab("Java Collections")+theme_bw()


Thanks,
Mohan

-----Original Message-----
From: Dennis Murphy [mailto:djmuser at gmail.com]
Sent: Wednesday, June 17, 2015 8:42 PM
To: Radhakrishnan, Mohan (Cognizant)
Subject: Re: [R] Error bars and CI

Q: How do you expect to get error bars when you plot "groups" having samples of size 1? If you "are not grouping", then what is the point of trying to manufacture variation where none exists? I'd suggest you think a little more deeply about what you can achieve with the available data.

This plot visualizes the data you posted. Every point is accounted for. I named the input data frame DF.

ggplot(DF, aes(x = IDX, y = V1)) +
   geom_line() + geom_point()

If you don't have replicate data at each unique x-value you want to plot, you cannot legitimately plot error bars, confidence intervals or any other visual that describes a (summary of) a distribution. If the values of V1 are supposed to represent averages that come from other data set, then you should have a corresponding column of standard deviations/standard errors, and *then* you can plot error bars, CIs, etc. Without a legitimate measure of variation in your input data frame, I don't see how you can possibly generate a line graph with accompanying error bars/CIs.

Dennis

On Wed, Jun 17, 2015 at 1:13 AM,  <Mohan.Radhakrishnan at cognizant.com> wrote:
> I think it could be something like this. But the mean is for the entire set. Not groups.
> I get a graph with this code but error bars are not there.
>
>
> p<-ggplot(jc,aes(IDX,V1,colour=V1))
> p <- p + stat_summary(fun.y=mean,geom="point")
> p <- p + stat_summary(fun.y=mean,geom="line")
> p <- p + stat_summary(fun.data=mean_cl_normal,conf.int = .99,
> geom="errorbar", width=0.2)
>
>
> Thanks,
> Mohan
>
> -----Original Message-----
> From: Radhakrishnan, Mohan (Cognizant)
> Sent: Wednesday, June 17, 2015 12:54 PM
> To: 'Dennis Murphy'
> Cc: r-help at r-project.org
> Subject: RE: [R] Error bars and CI
>
> Your sample code is working. But I am missing the logic when my dataset is involved.
>
> My full dataset is this. It is the V1 column I am interested in.  I am not 'grouping' here.
>
>       V1 IDX
> 1  0.796   1
> 2  0.542   2
> 3  0.510   3
> 4  0.617   4
> 5  0.482   5
> 6  0.387   6
> 7  0.272   7
> 8  0.536   8
> 9  0.498   9
> 10 0.402  10
> 11 0.328  11
> 12 0.542  12
> 13 0.299  13
> 14 0.647  14
> 15 0.291  15
> 16 0.815  16
> 17 0.680  17
> 18 0.363  18
> 19 0.560  19
> 20 0.334  20
>
> Thanks,
> Mohan
>
> -----Original Message-----
> From: Dennis Murphy [mailto:djmuser at gmail.com]
> Sent: Tuesday, June 16, 2015 1:18 AM
> To: Radhakrishnan, Mohan (Cognizant)
> Subject: Re: [R] Error bars and CI
>
> Hi:
>
> Firstly, your dplyr code to generate the summary data frame is unnecessary and distracting, particularly since you didn't provide the input data set; you are asked to provide a *minimal* reproducible example, which you could easily have done with a built-in data set.
> That said, to get what I perceive you want, I used the InsectSprays data from the autoloaded datasets package.
>
> # Function to compute standard error of a mean sem <- function(x)
> sqrt(var(x)/length(x))
>
> ## Use insectSprays data for illustration ## Compute mean and SE of
> count for each level of spray
>
> library(dplyr)
> library(ggplot2)
>
> insectSumm <- InsectSprays %>%
>                   group_by(spray) %>%
>                   summarise(mean = mean(count), se = sem(count))
>
>
> # Since the x-variable is a factor, need to map group = 1 to # draw lines between factor levels. geom_pointrange() can be # used to produce the 99% CIs per factor level, geom_errorbar() # for the mean +/- SE. I ordered the geoms so that the errorbar # is last, but if you want it (mostly) overwritten, put the # geom_pointrange() call last.
>
> ggplot(insectSumm, aes(x = spray, y = mean)) +
>    theme_bw() +
>    geom_line(aes(group = 1), size = 1, color = "darkorange") +
>    geom_pointrange(aes(ymin = mean - qt(.995, 11) * se,
>                       ymax = mean + qt(.995, 11) * se),
>                    size = 1.5, color = "firebrick") +
>    geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = 0.2,
>                    size = 1)
>
> Clearly, you can pipe all the way through the ggplot() call, but I wanted to check the contents of the summary data frame first.
>
> Dennis
>
> On Mon, Jun 15, 2015 at 3:51 AM,  <Mohan.Radhakrishnan at cognizant.com> wrote:
>> Hi,
>>
>> I want to plot a line graph using this data. IDX is x-axis and V1 is y-axis.  I also want standard error bars and 99% CI to be shown. My code is given below. The section that plots the graph is the problem.  I don't see all the points in the line graph with error bars. How can I also show the 99% CI in the graph ?
>>
>>       V1 IDX
>> 1  0.987  21
>> 2  0.585  22
>> 3  0.770  23
>> 4  0.711  24
>>
>> library(stringr)
>> library(dplyr)
>> library(ggplot2)
>>
>> data <- read.table("D:\\jmh\\jmh.txt",sep="\t")
>>
>> final <-data %>%
>>            select(V1) %>%
>>               filter(grepl("^Iteration", V1)) %>%
>>         mutate(V1 = str_extract(V1, "\\d+\\.\\d*"))
>>
>> final <- mutate(final,IDX = 1:n())
>>
>> jc <- final %>%
>>               filter(IDX < 21)
>>
>>
>> #Convert to numeric
>> jc <- data.frame(sapply(jc, function(x) as.numeric(as.character(x))))
>>
>> print(jc)
>>
>> # The following section is the problem.
>>
>> sem <- function(x){
>>        sd(x)/sqrt(length(x))
>> }
>>
>> meanvalue <- apply(jc,2,mean)
>> semvalue <- apply(jc, 2, sem)
>>
>> mean_sem <- data.frame(mean= meanvalue, sem= semvalue,
>> group=names(jc))
>>
>> #larger font
>> theme_set(theme_gray(base_size = 20))
>>
>> #plot using ggplot
>> p <- ggplot(mean_sem, aes(x=group, y=mean)) +
>>               geom_line(stat='identity') +
>>               geom_errorbar(aes(ymin=mean-sem, ymax=mean+sem),
>>                            width=.2)
>> print(p)
>>
>> Thanks,
>> Mohan
>> This e-mail and any files transmitted with it are for the sole use of the intended recipient(s) and may contain confidential and privileged information. If you are not the intended recipient(s), please reply to the sender and destroy all copies of the original message. Any unauthorized review, use, disclosure, dissemination, forwarding, printing or copying of this email, and/or any action taken in reliance on the contents of this e-mail is strictly prohibited and may be unlawful. Where permitted by applicable law, this e-mail and other e-mail communications sent to and from Cognizant e-mail addresses may be monitored.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> This e-mail and any files transmitted with it are for the sole use of the intended recipient(s) and may contain confidential and privileged information. If you are not the intended recipient(s), please reply to the sender and destroy all copies of the original message. Any unauthorized review, use, disclosure, dissemination, forwarding, printing or copying of this email, and/or any action taken in reliance on the contents of this e-mail is strictly prohibited and may be unlawful. Where permitted by applicable law, this e-mail and other e-mail communications sent to and from Cognizant e-mail addresses may be monitored.
This e-mail and any files transmitted with it are for the sole use of the intended recipient(s) and may contain confidential and privileged information. If you are not the intended recipient(s), please reply to the sender and destroy all copies of the original message. Any unauthorized review, use, disclosure, dissemination, forwarding, printing or copying of this email, and/or any action taken in reliance on the contents of this e-mail is strictly prohibited and may be unlawful. Where permitted by applicable law, this e-mail and other e-mail communications sent to and from Cognizant e-mail addresses may be monitored.

From ii54250 at msn.com  Thu Jun 18 13:01:53 2015
From: ii54250 at msn.com (IOANNA IOANNOU)
Date: Thu, 18 Jun 2015 12:01:53 +0100
Subject: [R] Completing Unordered Categorical missing variables using
	package mi
Message-ID: <DUB116-DS3034F578DCAFE1521244B5F3A50@phx.gbl>

Hello all, 

 

A perhaps simple question. I am trying to complete unordered categorical
missing data using mi package. There are two variables with missing data:
Mat and Use. The problem is that the Use has several categories and somehow
this means I can't plot the results as I get this error. Any idea how to fix
the problem?

Any help much appreciated, 

Best, 

Ioanna

 

new<-read(Sample.csv)

new$Use<-factor(new$Use)

MissingData <- missing_data.frame(new)

MissingData <- change(MissingData, y = "DS", what = "type", to =
"ordered-categorical")

 

# STEP 3: look deeper

summary(MissingData)

summary(MissingData at patterns)

show(MissingData)

hist(MissingData)

 

 

# STEP 4: impute

## Not run: 

IMPsample <- mi(MissingData)

 

 

#STEP5: diagnostics

Plot(IMPsample)

 

Error in `rownames<-`(`*tmp*`, value = c("Oc11", "Oc12", "Oc13", "Oc14",  : 

  length of 'dimnames' [1] not equal to array extent

 


From drjimlemon at gmail.com  Thu Jun 18 14:05:27 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 18 Jun 2015 22:05:27 +1000
Subject: [R] Polysomnographic data analysis with R?
In-Reply-To: <CAH-FEnhQx+bhwULzJvdYu-Ox4kmPx=oeq=F_VD9McvpOGJ1R4Q@mail.gmail.com>
References: <CAH-FEnhQ0UfGaC-nj8JcJz5-teybaJqQ-zTvi03pUpPxQwJuDQ@mail.gmail.com>
	<CA+8X3fUYtwxkAoTVyyj=JNPMwBWU_=Cq=JHNPGUZy57yRqEc1w@mail.gmail.com>
	<CAH-FEnhQx+bhwULzJvdYu-Ox4kmPx=oeq=F_VD9McvpOGJ1R4Q@mail.gmail.com>
Message-ID: <CA+8X3fXy+k4rBqE-LgAmFy99uj3eo5ap8if0fF5eatjkZKEk9Q@mail.gmail.com>

Hi Charles,
As I don't know what sort of data you are using, I can only guess. If
you want to visualize the sleep patterns and events, it is fairly easy
to extract these from the sleep example on the EDF format page and
display them.

sleep_stages<-list(labels=c("Sleep stage W",
 "Sleep stage N1",
 "Sleep stage N2",
 "Sleep stage N3",
 "Sleep stage N2",
 "Sleep stage N3",
 "Sleep stage N2"),
 starts=c(0,660,960,1140,1440,1620,1890),
 ends=c(660,960,1140,1440,1620,1890,1920))
library(plotrix)
gantt.chart(sleep_stages,vgridlab=seq(0,2000,by=100),
 vgridpos=seq(0,2000,by=100),main="Sleep recording",
 taskcolors=2:5)
abline(v=c(660,742,993,1019,1526,1620,1634))
sleep_events<-c("Lights off","Turning right side -> back",
 "Limb movement R+L leg","Limb movement R leg",
 "Obstructive apnea","Obstructive apnea",
 "Turning back -> left side")
staxlab(side=1,at=c(660,742,993,1019,1526,1620,1634),
 labels=sleep_events,pos=0.555,
 top.line=1,nlines=4,cex=0.7)

Jim


On Wed, Jun 17, 2015 at 10:15 PM, Charles Novaes de Santana
<charles.santana at gmail.com> wrote:
> Dear Jim,
>
> Thank you for your response. Yes, it is the European Data Format you
> mention. Actually we can read the data correctly, but I was wondering if
> there is any package that can identify different sleep phases automatically
> based on the data. I supposed such a package does not exist, it is really
> difficult to automatize the identification of sleep phases based only on
> data, but I asked here just in case.
>
> Thanks for your attention!
>
> Best,
>
> Charles
>
> On 17 June 2015 at 13:46, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Charles,
>> This looks like the European Data Format (EDF and EDF+), which has a
>> complete file specification. If there is no existing R package, it
>> might be possible to write an import function from the specification,
>> something like the functions in the "foreign" package.
>>
>> Jim
>>
>>
>> On Wed, Jun 17, 2015 at 4:55 AM, Charles Novaes de Santana
>> <charles.santana at gmail.com> wrote:
>> > Dear all,
>> >
>> > Do you know if there is any R package or function we can use to analyze
>> > polysomnographic data?
>> >
>> > For example, something that can import an EDF file (or in a different
>> > format) and can give some properties of the polysomnographic records
>> > like
>> > periods of different sleep phases, etc.
>> >
>> > I looked for it in the web and I didn't find. But maybe I used the wrong
>> > key-words.
>> >
>> > Any help will be much appreciated!
>> >
>> > Best,
>> >
>> > Charles
>> > --
>> > Um ax?! :)
>> >
>> > --
>> > Charles Novaes de Santana, PhD
>> > http://www.imedea.uib-csic.es/~charles
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Um ax?! :)
>
> --
> Charles Novaes de Santana, PhD
> http://www.imedea.uib-csic.es/~charles


From ii54250 at msn.com  Thu Jun 18 15:15:54 2015
From: ii54250 at msn.com (IOANNA IOANNOU)
Date: Thu, 18 Jun 2015 14:15:54 +0100
Subject: [R] FW: Completing Unordered Categorical missing variables using
	package mi
In-Reply-To: <001801d0a9b6$3119f0b0$934dd210$@msn.com>
References: <001801d0a9b6$3119f0b0$934dd210$@msn.com>
Message-ID: <DUB116-DS360A0FF59B5B18184D2E26F3A50@phx.gbl>

 

Hello all, 

 

A perhaps simple question. I am trying to complete unordered categorical
missing data using mi package. There are two variables with missing data:
Mat and Use. The problem is that the Use has several categories and somehow
this means I can't plot the results as I get this error. Any idea how to fix
the problem?

Any help much appreciated, 

Best, 

Ioanna

 

new<-read(Sample.csv)

new$Use<-factor(new$Use)

MissingData <- missing_data.frame(new)

MissingData <- change(MissingData, y = "DS", what = "type", to =
"ordered-categorical")

 

# STEP 3: look deeper

summary(MissingData)

summary(MissingData at patterns)

show(MissingData)

hist(MissingData)

 

 

# STEP 4: impute

## Not run: 

IMPsample <- mi(MissingData)

 

 

#STEP5: diagnostics

Plot(IMPsample)

 

Error in `rownames<-`(`*tmp*`, value = c("Oc11", "Oc12", "Oc13", "Oc14",  : 

  length of 'dimnames' [1] not equal to array extent

 

Data

new

      DS  Use Material     Surface    IM

31237  3 Oc22     Wood   95.710401 3.148

48947  1 Oc19     Wood  124.427200 1.762

7038   5 Oc11     Wood  142.113800 1.890

8150   3 Oc32    Steel   70.709451 2.530

43471  1 Oc19       NA    3.609650 1.597

24815  5 Oc11     Wood  121.541500 3.638

8683   2 Oc11     Wood   80.341550 2.242

47303  1 Oc39       NA   19.018000 1.410

27467  5 Oc11     Wood   86.799050 3.782

35026  2 Oc11     Wood  113.185700 2.565

50635  5 Oc19       NA   28.169550 3.887

9459   2 Oc11     Wood   40.825350 1.779

14042  2 Oc13    Steel   36.233100 4.293

17393  3 Oc11     Wood   56.069700 2.833

21157  5 Oc11     Wood   89.254700 4.958

42345  2 Oc19       NA    2.973600 0.468

4372   5 Oc11     Wood    7.872750 3.950

16654  5 Oc11     Wood   75.315600 6.395

47335  1 Oc19       NA   14.564400 1.781

49609  5 Oc19       NA   17.249000 3.545

4973   5 Oc19     Wood   28.511699 3.243

44784  2 Oc19       NA    4.473000 2.328

29581  5 Oc11     Wood   96.884250 4.378

31949  3 Oc11     Wood  126.996500 3.225

7352   5 Oc11     Wood   71.905200 3.430

43139  1 Oc19       NA  133.573551 1.849

43350  2 Oc19       NA    3.739350 1.205

11592  2 Oc11     Wood   72.146800 2.906

33767  3 Oc11     Wood   91.578001 2.905

51748  5 Oc39       NA    9.108800 3.138

21160  5 Oc12     Wood  100.677100 4.268

34390  2 Oc12     Wood  120.401199 1.603

23255  5 Oc12     Wood  122.333801 5.557

38414  2 Oc21    Steel   69.686100 3.021

48810  3 Oc29     Wood   79.609950 3.670

44611  2 Oc19       NA   15.328000 1.480

17905  3 Oc11     Wood   61.188500 1.857

35509  2 Oc11     Wood  160.180349 2.511

10252  2 Oc11     Wood   94.414799 1.446

47152  2 Oc19     Wood   12.160450 2.285

43221  2 Oc11     Wood   70.796299 1.361

32569  3 Oc11     Wood   97.269300 2.842

5671   5 Oc11     Wood   84.672250 3.050

1157   3 Oc11     Wood   79.297800 2.612

3441   2 Oc11     Wood  112.435650 2.105

36678  5 Oc21     Wood   27.223500 4.017

52241  5 Oc19     Wood    3.946150 3.373

4688   5 Oc11     Wood   68.009700 3.766

42933  2 Oc19     Wood    3.946801 2.039

31048  5 Oc11     Wood   25.172301 3.633

28660  1 Oc11     Wood  133.387099 1.285

22726  5 Oc12     Wood  216.952900 7.550

22397  5 Oc11     Wood  115.320750 5.825

41008  3 Oc11     Wood   97.253199 1.960

49054  3 Oc21       NA    8.542800 1.329

5594   5 Oc41       RC  264.505000 3.185

45379  3 Oc41     Wood   39.357100 2.909

17498  3 Oc11     Wood   45.544750 1.459

1176   5 Oc11     Wood   87.020400 2.750

33055  1 Oc11     Wood   55.777250 1.437

37071  5 Oc32     Wood  201.629599 3.287

53813  5 Oc19     Wood   56.919600 4.322

11037  2 Oc11     Wood  107.886600 1.479

14453  2 Oc11     Wood  106.369949 2.508

3767   1 Oc11     Wood   71.325500 2.012

52303  5 Oc29       NA    8.916150 6.092

19706  5 Oc19     Wood   25.936699 6.417

37658  5 Oc14     Wood   65.761651 4.317

26195  1 Oc12     Wood   82.510849 0.835

35808  3 Oc13     Wood   54.798851 2.337

6035   5 Oc12     Wood  286.075700 3.905

33383  3 Oc11     Wood   96.809150 2.560

43497  1 Oc19       NA   13.039000 1.103

41777  5   NA       NA   47.153349 2.658

12024  2 Oc11     Wood   19.851000 2.567

39538  1 Oc19       NA   31.996200 2.108

15553  3 Oc19     Wood  197.062201 2.559

31522  3 Oc11     Wood  129.499700 2.906

11916  2 Oc11     Wood   58.358951 2.939

9688   2 Oc11     Wood  106.568201 1.822

1690   3 Oc11     Wood  202.613700 2.290

977    3 Oc11     Wood  179.321800 1.987

12410  2 Oc14    Steel  108.682100 2.821

52428  5 Oc19       NA   36.041699 6.042

14109  2 Oc21    Steel  130.929300 4.178

52769  5 Oc31     Wood   18.525650 2.187

11324  1 Oc11     Wood   94.108351 1.456

12394  2 Oc21       RC 1836.975800 2.415

35991  3 Oc11     Wood  114.716550 2.664

4006   5 Oc39    Steel  309.854000 4.041

43404  2 Oc19       RC   27.745400 1.772

12680  1 Oc21       RC  327.789699 2.669

43607  1 Oc29       NA    5.812499 2.406

33590  3 Oc11     Wood    8.115450 3.183

16230  5 Oc32     Wood  610.293850 6.312

19815  5 Oc11     Wood   89.220350 6.122

4520   5 Oc19     Wood   64.060800 3.248

13684  5 Oc13     Wood   56.124300 5.455

38537  5 Oc21       NA   16.287000 3.270

39657  1 Oc19  Masonry   33.016850 1.705

46738  1 Oc19  Masonry    8.274750 2.268

48304  1 Oc41       NA   11.023500 1.340

25526  5 Oc11     Wood   38.092050 3.400

31818  3 Oc11     Wood   74.741200 2.957

49039  1 Oc19     Wood   26.981200 1.660

7721   3 Oc13     Wood  138.895000 1.620

37074  5 Oc32       RC 1022.963850 3.165

253    3 Oc11     Wood  110.980550 3.450

37050  5 Oc39     Wood   85.076700 3.425

49396  3 Oc29       NA   42.180450 2.044

16432  5 Oc11     Wood   14.516700 6.685

19825  5 Oc11     Wood   79.850800 5.805

37808  5 Oc12     Wood   22.258000 6.500

11931  2 Oc31     Wood    4.754801 2.691

54705  5 Oc52    Steel   22.149050 3.730

49243  3 Oc41       NA   15.386600 3.225

22228  5 Oc11     Wood   66.384300 7.130

19650  3 Oc19     Wood  183.575500 0.786

38384  1 Oc11     Wood   13.056799 2.072

46314  1 Oc39     Wood   34.994200 1.046

38055  5 Oc22    Steel 2376.595001 6.680

309    3 Oc19     Wood  262.443700 2.402

10410  2 Oc11     Wood   97.889400 1.125

13732  3 Oc11     Wood   31.174701 2.146

4072   5 Oc11     Wood   84.427000 4.502

27637  5 Oc11     Wood  102.724099 3.862

16383  5 Oc11     Wood  109.650200 6.319

17287  5 Oc11     Wood  178.604650 0.828

14319  3 Oc11     Wood   28.284451 3.662

38933  0 Oc19       NA   74.362200 1.915

653    2 Oc11     Wood  101.894350 2.427

28381  1 Oc11     Wood   74.662700 1.167

5245   5 Oc19     Wood   49.041400 3.295

10622  2 Oc11     Wood  182.785600 1.332

6015   5 Oc11     Wood  102.267250 2.961

2860   2 Oc11     Wood  129.606700 2.132

53764  5 Oc19       NA    2.226350 4.218

9165   2 Oc11     Wood  112.198350 1.639

21738  5 Oc11     Wood  193.646300 6.375

29152  1 Oc11  Masonry  126.956551 1.398

29473  1 Oc11     Wood  116.963500 1.297

49030  2 Oc19       NA    3.076849 1.292

6409   5 Oc11     Wood   71.559400 2.820

32834  1 Oc11     Wood  191.312099 1.040

6174   5 Oc11     Wood   68.417351 3.125

48700  3 Oc19       NA   13.087300 2.207

54246  5 Oc39     Wood   23.193300 5.701

20891  5 Oc22     Wood   48.977900 6.368

5569   5 Oc11     Wood  112.890051 3.062

26900  5 Oc11     Wood   75.308800 3.982

34282  3 Oc11     Wood   98.636400 2.124

36821  5 Oc11     Wood   35.633750 4.358

839    1 Oc11     Wood   96.719899 1.520

2115   3 Oc19     Wood   96.171801 2.725

3628   1 Oc11     Wood   91.017200 1.277

42766  2 Oc19       NA    4.107900 1.146

47389  1 Oc19       NA    6.752700 0.477

44397  1 Oc19       NA   19.453200 1.712

42148  5 Oc19       NA  115.429750 2.707

30878  3 Oc11     Wood   73.016301 3.727

26881  1 Oc11     Wood  101.604100 1.013

28615  3 Oc22     Wood  313.150399 3.438

15659  3 Oc11     Wood   85.379750 2.347

20772  5 Oc11     Wood   94.530500 5.687

9190   2 Oc11     Wood   86.149100 1.576

21905  5 Oc11     Wood  128.124851 6.313

13342  5 Oc11     Wood   63.338500 4.733

33391  5 Oc32     Wood   87.569600 2.763

31901  3 Oc11     Wood  116.920451 2.478

50713  5 Oc19     Wood 1088.068400 4.433

34860  3 Oc11     Wood   87.190301 2.614

55024  5 Oc39       NA  114.418900 3.638

1518   3 Oc19     Wood   57.937901 2.220

775    2 Oc11     Wood    6.419100 1.874

44361  2 Oc29       NA  228.655249 2.489

18223  3 Oc11     Wood   76.449050 2.351

43388  0 Oc11     Wood  155.973150 1.293

53611  5 Oc11     Wood   91.223350 3.298

54250  5 Oc22     Wood   43.027800 5.360

51390  5 Oc19       NA   20.285000 1.243

30256  5 Oc11     Wood  164.783051 3.682

41463  5 Oc19     Wood   23.332800 3.120

31829  3 Oc11     Wood  112.339650 2.628

11076  3 Oc32     Wood  270.922800 1.244

20353  5 Oc11     Wood   74.456400 6.367

30688  2 Oc22    Steel  151.500400 2.950

31118  3 Oc11     Wood  106.786401 3.232

7938   3 Oc11     Wood  121.130100 2.223

35911  1 Oc11  Masonry   15.574700 1.523

51553  5 Oc11     Wood  101.935799 3.991

8429   2 Oc11     Wood   78.870399 2.336

30658  3 Oc19     Wood    7.628100 3.488

35621  1 Oc11     Wood   68.351600 1.884

32819  1 Oc12     Wood   81.169299 0.988

21750  5 Oc11     Wood   13.560199 6.293

33110  1 Oc11     Wood  137.288199 0.949

16804  5 Oc19    Steel   94.925000 5.424

10766  2 Oc11     Wood  110.352050 1.364

33043  1 Oc11  Masonry  108.804000 1.566

2525   1 Oc11     Wood  103.651900 2.775

50546  5 Oc19       NA    3.624000 4.055

10907  2 Oc11     Wood  172.653550 1.668

33379  3 Oc11     Wood   58.839049 3.677

48738  3 Oc11     Wood   92.931500 3.133

45818  2 Oc41       NA   38.355550 3.243

11172  2 Oc11     Wood  107.776200 0.245

40021  3 Oc11       NA    6.439400 3.143

45784  2 Oc19     Wood    9.796599 2.837

13301  5 Oc29  Masonry  231.604100 6.087

52666  5 Oc39     Wood  150.817901 3.632

16043  2 Oc22     Wood   50.981850 2.047

32931  1 Oc11     Wood   78.446501 0.935

24495  1 Oc12     Wood  134.953350 1.272

6006   5 Oc11     Wood  102.931801 2.768

15849  3 Oc11     Wood   80.187700 3.168

16116  2 Oc11     Wood   66.488600 2.763

36393  3 Oc11     Wood   82.420400 2.452

18041  3 Oc11     Wood  110.072900 2.658

36759  5 Oc19     Wood   46.591250 3.892

47427  1 Oc19       NA   18.062000 1.726

26659  1 Oc11     Wood  103.383900 1.648

54503  5 Oc19     Wood    6.632950 5.672

18346  3 Oc19     Wood   16.242450 1.377

43181  1 Oc19       NA   13.249600 1.514

16749  5 Oc13     Wood   29.878150 6.702

10509  2 Oc11     Wood   93.246150 1.560

12470  2 Oc11     Wood   93.381800 2.175

22514  5 Oc22  Masonry  119.784100 7.350

26684  1 Oc11     Wood  171.935201 1.530

47024  2 Oc11     Wood   37.760099 2.765

47549  1 Oc14     Wood   88.233800 1.539

14542  2 Oc19     Wood  112.179151 2.613

14548  2 Oc11     Wood  112.626950 2.386

44712  2 Oc19       NA    4.881700 2.101

54292  5 Oc19       NA    6.387600 7.305

42465  3 Oc19       NA    8.382800 0.071

50619  5 Oc19       NA   22.139551 4.082

18801  5 Oc11     Wood   79.048600 6.592

26907  5 Oc21    Steel  179.362801 4.118

44647  2 Oc19       NA    9.710499 1.523

53884  5   NA       NA    4.031301 5.733

17643  3 Oc19    Steel   53.442200 1.726

43555  1 Oc19     Wood   34.725400 2.031

50096  5 Oc19     Wood   11.685301 3.568

28338  3 Oc11     Wood  188.588949 3.547

14567  2 Oc11     Wood  102.271749 2.432

35229  3 Oc19     Wood  105.644650 2.907

54897  5 Oc39       NA   20.005850 3.392

43850  2 Oc19       NA    6.962800 0.618

23579  1 Oc11     Wood   21.967049 0.964

3911   5 Oc39    Steel  205.837100 5.655

11479  2 Oc11     Wood   99.143149 1.978

54780  5 Oc52       NA   10.819650 5.948

22294  5 Oc11     Wood   53.430601 6.842

49024  2 Oc19       NA    4.879450 1.353

20718  5 Oc11     Wood  105.222002 5.300

26194  1 Oc12     Wood   84.928300 0.503

3367   1 Oc11     Wood   88.040298 0.968

1739   2 Oc11     Wood  117.838700 2.573

38747  3 Oc29     Wood   79.019850 1.060

39564  2 Oc19       NA    4.477000 2.177

30646  3 Oc11     Wood  122.447250 3.557

41903  5 Oc29     Wood   86.908001 2.610

16245  5 Oc11     Wood   61.719000 5.410

50614  5 Oc19       NA   11.426900 3.941

24830  5 Oc11     Wood  129.197750 3.395

18775  5 Oc11     Wood  136.926350 6.070

41319  3 Oc19     Wood   76.514249 2.438

23014  4 Oc31    Steel 1989.326200 5.873

12580  2 Oc22       RC   58.098150 2.269

39381  1 Oc19       NA    5.029000 2.265

48634  3 Oc19       NA   11.585400 2.322

15812  3 Oc41     Wood  462.183200 2.932

38651  5 Oc31     Wood   83.293699 6.317

49498  3 Oc21     Wood  120.639800 3.052

10668  2 Oc11     Wood   66.690701 1.880

40389  3 Oc11     Wood    8.225700 2.602

24463  1 Oc11     Wood   11.705949 2.075

55092  5 Oc39       NA   11.127200 3.390

34442  1 Oc12       RC  188.031750 1.534

28174  3 Oc11  Masonry  147.856200 3.638

4554   5 Oc13     Wood  122.192000 3.760

22177  5 Oc31    Steel 1224.195600 6.403

41914  5 Oc19       NA    5.653600 3.068

3523   1 Oc11     Wood  138.554900 1.755

25453  5 Oc12     Wood  158.640450 3.945

54450  5 Oc11       NA    9.816400 7.402

33577  3 Oc11     Wood  165.150250 3.268

28060  5 Oc11     Wood  114.928550 3.331

28721  1 Oc11     Wood  103.077350 1.638

38783  1 Oc19       NA   10.094450 0.857

14335  3 Oc11     Wood   70.515600 2.488

44932  3 Oc29       NA    5.967300 2.172

37656  2 Oc41       RC   31.681150 2.986

33687  3 Oc39    Steel 1162.853150 3.072

19868  5 Oc11     Wood   66.196449 6.158

17699  3 Oc11     Wood   39.427450 2.587

5373   5 Oc12     Wood  110.626501 3.108

35351  1 Oc19     Wood   80.164500 2.255

19036  2 Oc52    Steel  285.649800 5.023

 


From erguerrag at uc.cl  Thu Jun 18 14:16:30 2015
From: erguerrag at uc.cl (Ernesto Guerra)
Date: Thu, 18 Jun 2015 09:16:30 -0300
Subject: [R] adjusted values for CI in a within-subjects design
Message-ID: <CANXMtT_Af6JOtffjrPzVHj1rRq0W44dZ6hfccs0i65TQd3Y2PQ@mail.gmail.com>

Dear R-ers,
I am trying to adjust the values of a within-items, within-subjects design
(the experimental conditions are within subjects), to calculate between
subjects confidence intervals (CI). I am following the recommendations from
O'Brien & Cousineau (2014; see also Cousineau, 2005; Morey, 2008 for
similar solutions). So, formula is the following.

# formula for corrected CI:
# Y = Xsj - Xj. + X..
# where...
# Xsj = single value of a trial of a time window per participant
# Xj. = participants mean on that conditions across trials
# X.. = overall mean on that condition
# W = sqrt(J/(J-1))*(Y - Y.j) + Y.j
# where...
# J = sqrt(f/(f-1))
# f = total number of measures per subject
# Y.j = mean for a condition across participants
# W = the corrected value from which we can calculate the CI between
subjects.

I've written a code that does that using a dataset of random values (0,1),
but with the same structure that the actual dataset for which I hope to
calculate corrected CI.

fixprop subj trial time
        1    1     1    1
        0    1     1    2
        1    1     1    3
        0    1     1    4
        0    1     1    5
        0    1     1    6

The experiments deliver the time course of an effect (similar to
longitudinal data), meaning, we have N time steps in which the effect is
modulated. I've tested the script with this dummy dataset of 4
participants, 10 items, and 400 time steps, and it works nicely. The tricky
part here is that in the real experiments, we have many more participants,
items and time steps. Thus, the adjustment needs to be done many many
times.

With the dummy dataset the process takes about 6 seconds,
> proc.time() - ptm
   user  system elapsed
   4.53    0.06    6.03

but when I've added a bit more data (10 participants, 125 trials, 400 time
steps), the scritp takes more than an hour,
> proc.time() - ptm
   user  system elapsed
3483.64  879.31 4456.86

So, I don't even want to try doing this with real data, in which we have
thousands of times steps, and generally over 50 participants (although less
items in general, perhaps 40 or 50).

QUESTION: does anyone know how could I optimize my script, such as it does
not take forever?

Here is the script.

library(doBy)
library(plotrix)
library(matrixStats)
library(doBy)
library(bear)
library(ggplot2)
library(reshape)

rm(list=ls())       # clear memory
setwd (??) # set directory
infile = "test.txt"                                                    #
"test.txt" is the name of the fixation report
data = read.delim(file=infile, header=T, sep="\t")      # load the file
data = data[with(data, order(subj,trial)), ]                # data need to
be organized by part, by trials
head(data)

subj = unique(data$subj)
np=length(subj); np # how many participants
trial = unique(data$trial)
nt=length(trial); nt # how many items
timewindows = unique(data$time)
twsn=length(timewindows); twsn # how many time steps

critcoln = 1 #column in which we find the dependent variable
ncoln = 4 #total number of columns of your file
f = 2 #total number of conditions per subject

tm <- cbind(rep(c(critcoln:twsn), each=(nt*np)))
newvar <- cbind(rep(c((critcoln+ncoln):(critcoln+ncoln)),
each=(nt*np*twsn)))
subj <- cbind(rep(1:np, each=nt, times=twsn))
count <-cbind(rep(c(1:1), each=(nt*np*twsn)))

####################################

X..data = summaryBy(fixprop ~ time, FUN = mean, keep.names=T, data=data)
Xj.data = summaryBy(fixprop ~ subj + time, FUN = mean, keep.names=T,
data=data)

ptm <- proc.time()
prev_tw = 0
prev_subj = 0
j = 0
t = 0
for (i in 1:(nrow(data)))
{
  curr_tw = tm[i]
  curr_subj = subj[i]
  if (prev_subj < curr_subj)
  {j = j + 1}
  Y. = data[i,critcoln] - Xj.data[j,3]
  if (prev_tw < curr_tw)
  {t = t + 1}
  Y = Y. + X..data[t,2]
  data[i,newvar[i]] <- Y
  prev_tw = curr_tw
  prev_subj = curr_subj
}
proc.time() - ptm
colnames(data)[ncoln+1] <- 'fixprop_adj'

Y.jdata = summaryBy(fixprop_adj ~ subj + time, FUN = mean, keep.names=T,
data=data)

J = sqrt(f/(f-1)) #correction factor
newvar <- cbind(rep(c((critcoln+ncoln+1):(critcoln+ncoln+1)),
each=(nt*np*twsn)))

prev_tw = 0
t = 0
for (i in 1:(nrow(data)))
{
  curr_tw = tm[i]
  if (prev_tw < curr_tw)
  {t = t + 1}
  W = J*((data[i,ncoln+1]) - Y.jdata[t,3]) + Y.jdata[t,3]
  data[i,newvar[i]] <- W
  prev_tw = curr_tw
}
proc.time() - ptm
colnames(data)[ncoln+2] <- 'fixprop_final'

That's all. The processes that really take long are the "for" loops, I know
loops are not the best, but I couldn't think of a process that can do this
better so far...

Any comments, suggestions, criticisms and questions are welcome...
Cheers,
Ernesto.

	[[alternative HTML version deleted]]


From bcrombie at utk.edu  Thu Jun 18 15:09:29 2015
From: bcrombie at utk.edu (bcrombie)
Date: Thu, 18 Jun 2015 06:09:29 -0700 (PDT)
Subject: [R] How to round only one df row & how to keep 3rd sigdif if zero
Message-ID: <1434632969822-4708819.post@n4.nabble.com>

# How do I round only one row of a dataframe?
# After transposing a dataframe of counts & rates, all values took on the
most # of signif digits in the dataset (rates), but I want counts to remain
only one digit.
# Also, how can I keep 3 significant digits in R when the 3rd is a zero?
count <- c(1, 2, 3)
rate <- c(16.7, 33.3, 50.0)
a <- data.frame(count,rate)
a
# count rate
# 1     1 16.7
# 2     2 33.3
# 3     3 50.0
a <- t(a)
a
# [,1] [,2] [,3]
# count  1.0  2.0    3
# rate  16.7 33.3   50



--
View this message in context: http://r.789695.n4.nabble.com/How-to-round-only-one-df-row-how-to-keep-3rd-sigdif-if-zero-tp4708819.html
Sent from the R help mailing list archive at Nabble.com.


From cbryant at andrew.cmu.edu  Thu Jun 18 16:32:34 2015
From: cbryant at andrew.cmu.edu (Courtney Bryant)
Date: Thu, 18 Jun 2015 14:32:34 +0000
Subject: [R] help for lay person assisting R user with disability
Message-ID: <FB6064C7F3602142A01160BD26730530016F3D8A@PGH-MSGMB-03.andrew.ad.cmu.edu>

Good Morning,
I am currently working with a disabled R user who is a student here at CMU.  The student has both sight and mobility issues.  The student has asked for an assistant who is well versed in R to enter data for her, which we are having a hard time finding.  I would like information from R developers/users about how/how well R interfaces with Excel (an easier skill set to find!)   In your opinion, could it be as easy as uploading data from excel into R?  

Also, do you know of a way to enlarge the R interface or otherwise assist in making the program accessible to a low vision person?  My  limited understanding leads me to believe that screen magnifiers like zoom text don't work particularly well.  If you have information on that, I would very much appreciate it.  

Thanks for your help and for bearing with me!
Courtney



Courtney Bryant, EOS Specialist 
Equal Opportunity Services, Human Resources
Carnegie Mellon University
412-268-3930 | cbryant at andrew.cmu.edu 


From petr.pikal at precheza.cz  Thu Jun 18 16:55:36 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 18 Jun 2015 14:55:36 +0000
Subject: [R] How to round only one df row & how to keep 3rd sigdif if
 zero
In-Reply-To: <1434632969822-4708819.post@n4.nabble.com>
References: <1434632969822-4708819.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3173C@SRVEXCHMBX.precheza.cz>

Hi

You need to distinguish between an object and printing an object on console. When you print an object you can use several options for formating.

?sprintf, ?formatC

> formatC(t(a), digits=1, format="f")
      [,1]   [,2]   [,3]
count "1.0"  "2.0"  "3.0"
rate  "16.7" "33.3" "50.0"
>

Also when you transpose "a" the result is not data frame but matrix.

> str(t(a))
 num [1:2, 1:3] 1 16.7 2 33.3 3 50
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:2] "count" "rate"
  ..$ : NULL
> str(a)
'data.frame':   3 obs. of  2 variables:
 $ count: num  1 2 3
 $ rate : num  16.7 33.3 50
>

If you used google or other internet search options you would get plenty of results yourself.

try "formatting numbers R"

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> bcrombie
> Sent: Thursday, June 18, 2015 3:09 PM
> To: r-help at r-project.org
> Subject: [R] How to round only one df row & how to keep 3rd sigdif if
> zero
>
> # How do I round only one row of a dataframe?
> # After transposing a dataframe of counts & rates, all values took on
> the most # of signif digits in the dataset (rates), but I want counts
> to remain only one digit.
> # Also, how can I keep 3 significant digits in R when the 3rd is a
> zero?
> count <- c(1, 2, 3)
> rate <- c(16.7, 33.3, 50.0)
> a <- data.frame(count,rate)
> a
> # count rate
> # 1     1 16.7
> # 2     2 33.3
> # 3     3 50.0
> a <- t(a)
> a
> # [,1] [,2] [,3]
> # count  1.0  2.0    3
> # rate  16.7 33.3   50
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-
> round-only-one-df-row-how-to-keep-3rd-sigdif-if-zero-tp4708819.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Thu Jun 18 17:03:35 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 18 Jun 2015 15:03:35 +0000
Subject: [R] help for lay person assisting R user with disability
In-Reply-To: <FB6064C7F3602142A01160BD26730530016F3D8A@PGH-MSGMB-03.andrew.ad.cmu.edu>
References: <FB6064C7F3602142A01160BD26730530016F3D8A@PGH-MSGMB-03.andrew.ad.cmu.edu>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3174F@SRVEXCHMBX.precheza.cz>

Hi

I believe that others come with more elaborated answers.

Probably easiest way how to transfer Excel data to R is:

select rectangular area you want to transfer, preferably with sensible header.

pres Ctrl-C

In R enter command
object <- read.delim("clipboard")

possibly with header or NA options.

However this approach is not reproducible (you lose information about data source in .Rhistory), so there are other ways (e.g. through saved CSV file) but they can be more tricky.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Courtney Bryant
> Sent: Thursday, June 18, 2015 4:33 PM
> To: r-help at R-project.org
> Subject: [R] help for lay person assisting R user with disability
>
> Good Morning,
> I am currently working with a disabled R user who is a student here at
> CMU.  The student has both sight and mobility issues.  The student has
> asked for an assistant who is well versed in R to enter data for her,
> which we are having a hard time finding.  I would like information from
> R developers/users about how/how well R interfaces with Excel (an
> easier skill set to find!)   In your opinion, could it be as easy as
> uploading data from excel into R?
>
> Also, do you know of a way to enlarge the R interface or otherwise
> assist in making the program accessible to a low vision person?  My
> limited understanding leads me to believe that screen magnifiers like
> zoom text don't work particularly well.  If you have information on
> that, I would very much appreciate it.
>
> Thanks for your help and for bearing with me!
> Courtney
>
>
>
> Courtney Bryant, EOS Specialist
> Equal Opportunity Services, Human Resources Carnegie Mellon University
> 412-268-3930 | cbryant at andrew.cmu.edu
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From dcarlson at tamu.edu  Thu Jun 18 17:09:58 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 18 Jun 2015 15:09:58 +0000
Subject: [R] Cross tabulation with top one variable and side as multiple
 variables
In-Reply-To: <1434609984386-4708799.post@n4.nabble.com>
References: <1433839253539-4708379.post@n4.nabble.com>
	<1434609984386-4708799.post@n4.nabble.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D69AF32@mb02.ads.tamu.edu>

They do not match because xtabs() in R produces a multidimensional array (one dimension for each variable). Looking at your spreadsheet on nabble, it appears that SPSS is just creating 4 crosstabulations with TREND against each of the other variables. That is easily done in R, but for tested code, you need to give us reproducible data using dput(). I get an error using read.spss() on your uploaded file. You should also read some of the extensive free documentation available on R. The ftable() function creates a two dimensional representation of that 5-dimensional array. But your spreadsheet is just a stack of two-dimensional tables. You could get there with the margin.table() function, but unless you really need the 5-dimensional array, you probably want something more like:

rowvars <- c("AGET", "SEXT", "EDUCRT",  "JOBRT")
table.lst <- lapply(rowvars, function(x) xtabs(~x+TREND))

That would give you a list containing a crosstabulation table between each of the variables and TREND. A spreadsheet with 2000 tables seems a bit unwieldy so you might want to give some thought to what you really want as output.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of jagadishpchary
Sent: Thursday, June 18, 2015 1:46 AM
To: r-help at r-project.org
Subject: Re: [R] Cross tabulation with top one variable and side as multiple variables

I think my explanation in the post is not giving the full details on the job
to be done. Sorry for that. Here is what I am doing..

1.	I have a SPSS data set with more than 2000 variables. However for test
purpose I have created a temporary data set with 5 variables which I am
reading it to R environment (Attached the test.sav file).
2.	There is a variable called ?TREND? which has the year data. So all I need
to do is cross tabulate the variables with this Trend variable. 
In SPSS the syntax would be

CTABLES
/VLABELS VARIABLES =ALL DISPLAY=LABEL
/TABLES (AGET +SEXT +EDUCRT +JOBRT ) [COUNT F40.0] by TREND.

The final cross tabulation results are placed in the attached excel report
with sheet name ?Results?.

As I am new to R  - I tried searching the forums for the cross tabulation
with top variable constant and multiple variables as side however I could
not find it. Anyhow I tried using the below syntax :

Xtabs ( ~ AGET +SEXT +EDUCRT +JOBRT + TREND, data=mydata)
summary(~AGET +SEXT +EDUCRT +JOBRT, data= mydata, fun=table)
ftable (mydata, row.vars=c("AGET ", " SEXT ", " EDUCRT " , ?JOBRT?),
col.vars="TREND")

the results are not identical to what I am getting in SPSS

Hence I would request to suggest me a R code that helps me in getting the
results as shown in the attached excel report with sheet name ?Results?.
Test.sav <http://r.789695.n4.nabble.com/file/n4708799/Test.sav>  
Cross_tabulation.xlsx
<http://r.789695.n4.nabble.com/file/n4708799/Cross_tabulation.xlsx>  




--
View this message in context: http://r.789695.n4.nabble.com/Cross-tabulation-with-top-one-variable-and-side-as-multiple-variables-tp4708379p4708799.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From ggrothendieck at gmail.com  Thu Jun 18 17:15:30 2015
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 18 Jun 2015 11:15:30 -0400
Subject: [R] help for lay person assisting R user with disability
In-Reply-To: <FB6064C7F3602142A01160BD26730530016F3D8A@PGH-MSGMB-03.andrew.ad.cmu.edu>
References: <FB6064C7F3602142A01160BD26730530016F3D8A@PGH-MSGMB-03.andrew.ad.cmu.edu>
Message-ID: <CAP01uRkVt9S2w+9NFxcbmmtxFkg1RWjb_Aqqq8ROsESv7T8BbA@mail.gmail.com>

On Thu, Jun 18, 2015 at 10:32 AM, Courtney Bryant <cbryant at andrew.cmu.edu>
wrote:

> Good Morning,
> I am currently working with a disabled R user who is a student here at
> CMU.  The student has both sight and mobility issues.  The student has
> asked for an assistant who is well versed in R to enter data for her, which
> we are having a hard time finding.  I would like information from R
> developers/users about how/how well R interfaces with Excel (an easier
> skill set to find!)   In your opinion, could it be as easy as uploading
> data from excel into R?
>
> Also, do you know of a way to enlarge the R interface or otherwise assist
> in making the program accessible to a low vision person?  My  limited
> understanding leads me to believe that screen magnifiers like zoom text
> don't work particularly well.  If you have information on that, I would
> very much appreciate it.
>
> Thanks for your help and for bearing with me!
> Courtney
>
>
1. If the data file is in the form of a rectangular table with rows and
columns and the first row is a header row then if, in Excel, it is saved as
a .csv file it can be read into R like this:

   DF <- read.csv("/Users/JoeDoe/myspreadsheet.csv")

2. The openxlsx, readxl (and a number of other packages) can alternetely be
used to directly read in an xls or xlsx file, e.g.

  install.packages("readxl")
  library(readxl)
  DF <- read_excel("/Users/JoeDoe/myspreadsheet.xlsx")

3. The Windows magnifier that comes with Windows does work with R.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Thu Jun 18 17:41:43 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 18 Jun 2015 15:41:43 +0000
Subject: [R] help for lay person assisting R user with disability
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3174F@SRVEXCHMBX.precheza.cz>
References: <FB6064C7F3602142A01160BD26730530016F3D8A@PGH-MSGMB-03.andrew.ad.cmu.edu>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3174F@SRVEXCHMBX.precheza.cz>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D69BF9B@mb02.ads.tamu.edu>

You may have people knowledgeable about R there at Carnegie Mellon since it hosts a mirror for R software (one of 18 in the US). As Petr pointed out it is relatively easy to transfer information from an Excel spreadsheet to R by cutting and pasting (the method he suggested is for Windows computers) or by saving the file in a tab delimited or comma separated format so data entry should not be a problem assuming the data are arranged in a consistent format. 

As for the interface, there are a number of ways of interacting with R, but the default method involves a command window that allows you to type commands. On Windows it is called the R Console and the GUI Preferences option on the Edit menu tab allows you to choose the font, its size, and the number of rows and columns. For example changing the default size of 10 to 24 makes the type and the window larger. If the settings are saved, they should be preserved when the program is restarted.

There are also some graphical user interfaces for R that may be easier to use such as R Commander.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL Petr
Sent: Thursday, June 18, 2015 10:04 AM
To: Courtney Bryant; r-help at R-project.org
Subject: Re: [R] help for lay person assisting R user with disability

Hi

I believe that others come with more elaborated answers.

Probably easiest way how to transfer Excel data to R is:

select rectangular area you want to transfer, preferably with sensible header.

pres Ctrl-C

In R enter command
object <- read.delim("clipboard")

possibly with header or NA options.

However this approach is not reproducible (you lose information about data source in .Rhistory), so there are other ways (e.g. through saved CSV file) but they can be more tricky.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Courtney Bryant
> Sent: Thursday, June 18, 2015 4:33 PM
> To: r-help at R-project.org
> Subject: [R] help for lay person assisting R user with disability
>
> Good Morning,
> I am currently working with a disabled R user who is a student here at
> CMU.  The student has both sight and mobility issues.  The student has
> asked for an assistant who is well versed in R to enter data for her,
> which we are having a hard time finding.  I would like information from
> R developers/users about how/how well R interfaces with Excel (an
> easier skill set to find!)   In your opinion, could it be as easy as
> uploading data from excel into R?
>
> Also, do you know of a way to enlarge the R interface or otherwise
> assist in making the program accessible to a low vision person?  My
> limited understanding leads me to believe that screen magnifiers like
> zoom text don't work particularly well.  If you have information on
> that, I would very much appreciate it.
>
> Thanks for your help and for bearing with me!
> Courtney
>
>
>
> Courtney Bryant, EOS Specialist
> Equal Opportunity Services, Human Resources Carnegie Mellon University
> 412-268-3930 | cbryant at andrew.cmu.edu
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From john.archie.mckown at gmail.com  Thu Jun 18 18:17:54 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 18 Jun 2015 11:17:54 -0500
Subject: [R] help for lay person assisting R user with disability
In-Reply-To: <FB6064C7F3602142A01160BD26730530016F3D8A@PGH-MSGMB-03.andrew.ad.cmu.edu>
References: <FB6064C7F3602142A01160BD26730530016F3D8A@PGH-MSGMB-03.andrew.ad.cmu.edu>
Message-ID: <CAAJSdjh7bBW73CXUA33_YQ_zKJSqu86h1e2NfvuMVyD+nhgMZA@mail.gmail.com>

On Thu, Jun 18, 2015 at 9:32 AM, Courtney Bryant <cbryant at andrew.cmu.edu>
wrote:

> Good Morning,
> I am currently working with a disabled R user who is a student here at
> CMU.  The student has both sight and mobility issues.  The student has
> asked for an assistant who is well versed in R to enter data for her, which
> we are having a hard time finding.  I would like information from R
> developers/users about how/how well R interfaces with Excel (an easier
> skill set to find!)   In your opinion, could it be as easy as uploading
> data from excel into R?
>
> Also, do you know of a way to enlarge the R interface or otherwise assist
> in making the program accessible to a low vision person?  My  limited
> understanding leads me to believe that screen magnifiers like zoom text
> don't work particularly well.  If you have information on that, I would
> very much appreciate it.
>
> Thanks for your help and for bearing with me!
> Courtney
>

I am a bit confused (a normal condition for me). Is the student writing R
code or is the student running a application written in R? Also, since you
mentioned Excel, I am assuming that the student is using a PC running
Windows as opposed to Linux or a Mac.

If the student is writing R code, then I'd suggest that your computer
support person install Rstudio. It is cost free and can be downloaded here:
http://www.rstudio.com/ . The installer can then customize Rstudio to use a
really large font, if that would be helpful. Please forgive my lack of
knowledge about accessibility issues. If the student has trouble typing
(mobility issue?), this likely won't help. Would a speech to text / text to
speech interface help instead of a screen magnifier? I know next to nothing
about these tools, other than that they exist.

===

If the student is running an R application (which is what "enter data for
her" implies to me), then any accessibility issues would need to be
addressed in the application itself. But I don't understand why a "data
entry" assistant would need any skills in R itself in order to enter data
into it. But without knowing more, that's about all that I can say. One
thought: CMU has a college teaching "electrical and computer engineering".
Depending on what that means, perhaps someone from that college (professor,
TA, or grad student) could see what your student is doing and perhaps have
some insights on how to help. Or is there a "computer club" on campus where
some geeky student might be found? You might look here:
http://www.club.cc.cmu.edu/ If these are true geeks (and the web site
sounds promising), then a lure of beer & pizza would likely be irresistible
<grin>.

===

For interfacing R with Excel, you might want to look at RExcel here:
http://rcom.univie.ac.at/download.html#RExcel . It has a free student
version. But is this more for an Excel user who wants to use R for
analysis, not an R user wanting to use Excel for "data entry".



-- 
Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.

My sister opened a computer store in Hawaii. She sells C shells down by the
seashore.
If someone tell you that nothing is impossible:
Ask him to dribble a football.

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Jun 18 18:39:39 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 18 Jun 2015 13:39:39 -0300
Subject: [R] help for lay person assisting R user with disability
In-Reply-To: <FB6064C7F3602142A01160BD26730530016F3D8A@PGH-MSGMB-03.andrew.ad.cmu.edu>
References: <FB6064C7F3602142A01160BD26730530016F3D8A@PGH-MSGMB-03.andrew.ad.cmu.edu>
Message-ID: <5582F44B.5090008@gmail.com>

On 18/06/2015 11:32 AM, Courtney Bryant wrote:
> Good Morning,
> I am currently working with a disabled R user who is a student here at CMU.  The student has both sight and mobility issues.  The student has asked for an assistant who is well versed in R to enter data for her, which we are having a hard time finding.  I would like information from R developers/users about how/how well R interfaces with Excel (an easier skill set to find!)   In your opinion, could it be as easy as uploading data from excel into R?  
> 
> Also, do you know of a way to enlarge the R interface or otherwise assist in making the program accessible to a low vision person?  My  limited understanding leads me to believe that screen magnifiers like zoom text don't work particularly well.  If you have information on that, I would very much appreciate it.  
> 

There was an article not too long ago in the R Journal about this issue;
you can read it here:

http://journal.r-project.org/archive/2013-1/godfrey.pdf

I think the main R thing that has changed since then is the rise in the
prominence and maturity of RStudio.  At that time the author didn't find
it very easy to use, but it might be worth investigating again.

The author put together a web page

http://r-resources.massey.ac.nz/StatSoftware/

that you might find useful as well.

Duncan Murdoch


From bcrombie at utk.edu  Thu Jun 18 18:13:20 2015
From: bcrombie at utk.edu (Crombie, Burnette N)
Date: Thu, 18 Jun 2015 16:13:20 +0000
Subject: [R] How to round only one df row & how to keep 3rd sigdif if
	zero
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3173C@SRVEXCHMBX.precheza.cz>
References: <1434632969822-4708819.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3173C@SRVEXCHMBX.precheza.cz>
Message-ID: <BY2PR0201MB069653833711A02A10947D0CD5A50@BY2PR0201MB0696.namprd02.prod.outlook.com>

Thanks for taking the time to share your thoughts, PP.  I always extensively google & search before resorting to R forum.  In my real dataset, not in the example I created for the forum, I had tried converting the matrix to a dataframe but it retained the unwanted format.  And, these tables are being used in a report generated with the rtf package, so I have to get the format right for outside the console.  Because of another unrelated issue, though, I had to use a different approach to creating the dataframe with counts/rates added, so the issue was circumvented.  Cheers.

-----Original Message-----
From: PIKAL Petr [mailto:petr.pikal at precheza.cz] 
Sent: Thursday, June 18, 2015 10:56 AM
To: Crombie, Burnette N; r-help at r-project.org
Subject: RE: [R] How to round only one df row & how to keep 3rd sigdif if zero

Hi

You need to distinguish between an object and printing an object on console. When you print an object you can use several options for formating.

?sprintf, ?formatC

> formatC(t(a), digits=1, format="f")
      [,1]   [,2]   [,3]
count "1.0"  "2.0"  "3.0"
rate  "16.7" "33.3" "50.0"
>

Also when you transpose "a" the result is not data frame but matrix.

> str(t(a))
 num [1:2, 1:3] 1 16.7 2 33.3 3 50
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:2] "count" "rate"
  ..$ : NULL
> str(a)
'data.frame':   3 obs. of  2 variables:
 $ count: num  1 2 3
 $ rate : num  16.7 33.3 50
>

If you used google or other internet search options you would get plenty of results yourself.

try "formatting numbers R"

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of 
> bcrombie
> Sent: Thursday, June 18, 2015 3:09 PM
> To: r-help at r-project.org
> Subject: [R] How to round only one df row & how to keep 3rd sigdif if 
> zero
>
> # How do I round only one row of a dataframe?
> # After transposing a dataframe of counts & rates, all values took on 
> the most # of signif digits in the dataset (rates), but I want counts 
> to remain only one digit.
> # Also, how can I keep 3 significant digits in R when the 3rd is a 
> zero?
> count <- c(1, 2, 3)
> rate <- c(16.7, 33.3, 50.0)
> a <- data.frame(count,rate)
> a
> # count rate
> # 1     1 16.7
> # 2     2 33.3
> # 3     3 50.0
> a <- t(a)
> a
> # [,1] [,2] [,3]
> # count  1.0  2.0    3
> # rate  16.7 33.3   50
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-
> round-only-one-df-row-how-to-keep-3rd-sigdif-if-zero-tp4708819.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html and provide commented, minimal, self-contained, 
> reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From doggene at earthlink.net  Thu Jun 18 18:41:41 2015
From: doggene at earthlink.net (Liz Hare)
Date: Thu, 18 Jun 2015 12:41:41 -0400
Subject: [R] help for lay person assisting R user with disability
In-Reply-To: <CAAJSdjh7bBW73CXUA33_YQ_zKJSqu86h1e2NfvuMVyD+nhgMZA@mail.gmail.com>
References: <FB6064C7F3602142A01160BD26730530016F3D8A@PGH-MSGMB-03.andrew.ad.cmu.edu>
	<CAAJSdjh7bBW73CXUA33_YQ_zKJSqu86h1e2NfvuMVyD+nhgMZA@mail.gmail.com>
Message-ID: <65591B85-35D7-4138-83DB-07F481899508@earthlink.net>

Hi Courtney and John,

The RStudio environment mentioned below will not work with speech output (I tried with Window-Eyes awhile ago). Some of my clients use it but I have no experience with it. Since the student is partially sighted, they might be able to customize the environment with big fonts and contrast, I?m just not sure.

Using a screen reader like Window-Eyes, the student could use the R GUI environment, although it?s a little frustrating because it doesn?t speak a lot and you need to use the mouse keys a lot.

The other option if you have to stick with Windows  is to run R at the command prompt, which makes interaction slightly easier but you?d have to figure out how to log the output.

What is being recommended for the rest of the students in the class? Ideally, this student?s experience should be as close as possible to the others?. 

Liz
> On Jun 18, 2015, at 12:17 PM, John McKown <john.archie.mckown at gmail.com> wrote:
> 
> On Thu, Jun 18, 2015 at 9:32 AM, Courtney Bryant <cbryant at andrew.cmu.edu>
> wrote:
> 
>> Good Morning,
>> I am currently working with a disabled R user who is a student here at
>> CMU.  The student has both sight and mobility issues.  The student has
>> asked for an assistant who is well versed in R to enter data for her, which
>> we are having a hard time finding.  I would like information from R
>> developers/users about how/how well R interfaces with Excel (an easier
>> skill set to find!)   In your opinion, could it be as easy as uploading
>> data from excel into R?
>> 
>> Also, do you know of a way to enlarge the R interface or otherwise assist
>> in making the program accessible to a low vision person?  My  limited
>> understanding leads me to believe that screen magnifiers like zoom text
>> don't work particularly well.  If you have information on that, I would
>> very much appreciate it.
>> 
>> Thanks for your help and for bearing with me!
>> Courtney
>> 
> 
> I am a bit confused (a normal condition for me). Is the student writing R
> code or is the student running a application written in R? Also, since you
> mentioned Excel, I am assuming that the student is using a PC running
> Windows as opposed to Linux or a Mac.
> 
> If the student is writing R code, then I'd suggest that your computer
> support person install Rstudio. It is cost free and can be downloaded here:
> http://www.rstudio.com/ . The installer can then customize Rstudio to use a
> really large font, if that would be helpful. Please forgive my lack of
> knowledge about accessibility issues. If the student has trouble typing
> (mobility issue?), this likely won't help. Would a speech to text / text to
> speech interface help instead of a screen magnifier? I know next to nothing
> about these tools, other than that they exist.
> 
> ===
> 
> If the student is running an R application (which is what "enter data for
> her" implies to me), then any accessibility issues would need to be
> addressed in the application itself. But I don't understand why a "data
> entry" assistant would need any skills in R itself in order to enter data
> into it. But without knowing more, that's about all that I can say. One
> thought: CMU has a college teaching "electrical and computer engineering".
> Depending on what that means, perhaps someone from that college (professor,
> TA, or grad student) could see what your student is doing and perhaps have
> some insights on how to help. Or is there a "computer club" on campus where
> some geeky student might be found? You might look here:
> http://www.club.cc.cmu.edu/ If these are true geeks (and the web site
> sounds promising), then a lure of beer & pizza would likely be irresistible
> <grin>.
> 
> ===
> 
> For interfacing R with Excel, you might want to look at RExcel here:
> http://rcom.univie.ac.at/download.html#RExcel . It has a free student
> version. But is this more for an Excel user who wants to use R for
> analysis, not an R user wanting to use Excel for "data entry".
> 
> 
> 
> -- 
> Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.
> 
> My sister opened a computer store in Hawaii. She sells C shells down by the
> seashore.
> If someone tell you that nothing is impossible:
> Ask him to dribble a football.
> 
> He's about as useful as a wax frying pan.
> 
> 10 to the 12th power microphones = 1 Megaphone
> 
> Maranatha! <><
> John McKown
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Liz Hare, PhD
Dog Genetics LLC
doggene at earthlink.net
http://www.doggenetics.com <http://www.doggenetics.com/>

	[[alternative HTML version deleted]]


From clint at ecy.wa.gov  Thu Jun 18 18:51:32 2015
From: clint at ecy.wa.gov (Clint Bowman)
Date: Thu, 18 Jun 2015 09:51:32 -0700 (PDT)
Subject: [R] help for lay person assisting R user with disability
In-Reply-To: <65591B85-35D7-4138-83DB-07F481899508@earthlink.net>
References: <FB6064C7F3602142A01160BD26730530016F3D8A@PGH-MSGMB-03.andrew.ad.cmu.edu>
	<CAAJSdjh7bBW73CXUA33_YQ_zKJSqu86h1e2NfvuMVyD+nhgMZA@mail.gmail.com>
	<65591B85-35D7-4138-83DB-07F481899508@earthlink.net>
Message-ID: <alpine.LRH.2.11.1506180947280.4043@aeolus.ecy.wa.gov>

Almost 20 years ago my son was in the DO-IT program at the University of 
Washington <http://www.washington.edu/doit/>.  They have been very 
proactive in reaching out to other institutions.

They have been solving problems such as yours and I suspect can suggest 
several workable solutions.

Clint

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Thu, 18 Jun 2015, Liz Hare wrote:

> Hi Courtney and John,
>
> The RStudio environment mentioned below will not work with speech output (I tried with Window-Eyes awhile ago). Some of my clients use it but I have no experience with it. Since the student is partially sighted, they might be able to customize the environment with big fonts and contrast, I?m just not sure.
>
> Using a screen reader like Window-Eyes, the student could use the R GUI environment, although it?s a little frustrating because it doesn?t speak a lot and you need to use the mouse keys a lot.
>
> The other option if you have to stick with Windows  is to run R at the command prompt, which makes interaction slightly easier but you?d have to figure out how to log the output.
>
> What is being recommended for the rest of the students in the class? Ideally, this student?s experience should be as close as possible to the others?.
>
> Liz
>> On Jun 18, 2015, at 12:17 PM, John McKown <john.archie.mckown at gmail.com> wrote:
>>
>> On Thu, Jun 18, 2015 at 9:32 AM, Courtney Bryant <cbryant at andrew.cmu.edu>
>> wrote:
>>
>>> Good Morning,
>>> I am currently working with a disabled R user who is a student here at
>>> CMU.  The student has both sight and mobility issues.  The student has
>>> asked for an assistant who is well versed in R to enter data for her, which
>>> we are having a hard time finding.  I would like information from R
>>> developers/users about how/how well R interfaces with Excel (an easier
>>> skill set to find!)   In your opinion, could it be as easy as uploading
>>> data from excel into R?
>>>
>>> Also, do you know of a way to enlarge the R interface or otherwise assist
>>> in making the program accessible to a low vision person?  My  limited
>>> understanding leads me to believe that screen magnifiers like zoom text
>>> don't work particularly well.  If you have information on that, I would
>>> very much appreciate it.
>>>
>>> Thanks for your help and for bearing with me!
>>> Courtney
>>>
>>
>> I am a bit confused (a normal condition for me). Is the student writing R
>> code or is the student running a application written in R? Also, since you
>> mentioned Excel, I am assuming that the student is using a PC running
>> Windows as opposed to Linux or a Mac.
>>
>> If the student is writing R code, then I'd suggest that your computer
>> support person install Rstudio. It is cost free and can be downloaded here:
>> http://www.rstudio.com/ . The installer can then customize Rstudio to use a
>> really large font, if that would be helpful. Please forgive my lack of
>> knowledge about accessibility issues. If the student has trouble typing
>> (mobility issue?), this likely won't help. Would a speech to text / text to
>> speech interface help instead of a screen magnifier? I know next to nothing
>> about these tools, other than that they exist.
>>
>> ===
>>
>> If the student is running an R application (which is what "enter data for
>> her" implies to me), then any accessibility issues would need to be
>> addressed in the application itself. But I don't understand why a "data
>> entry" assistant would need any skills in R itself in order to enter data
>> into it. But without knowing more, that's about all that I can say. One
>> thought: CMU has a college teaching "electrical and computer engineering".
>> Depending on what that means, perhaps someone from that college (professor,
>> TA, or grad student) could see what your student is doing and perhaps have
>> some insights on how to help. Or is there a "computer club" on campus where
>> some geeky student might be found? You might look here:
>> http://www.club.cc.cmu.edu/ If these are true geeks (and the web site
>> sounds promising), then a lure of beer & pizza would likely be irresistible
>> <grin>.
>>
>> ===
>>
>> For interfacing R with Excel, you might want to look at RExcel here:
>> http://rcom.univie.ac.at/download.html#RExcel . It has a free student
>> version. But is this more for an Excel user who wants to use R for
>> analysis, not an R user wanting to use Excel for "data entry".
>>
>>
>>
>> --
>> Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.
>>
>> My sister opened a computer store in Hawaii. She sells C shells down by the
>> seashore.
>> If someone tell you that nothing is impossible:
>> Ask him to dribble a football.
>>
>> He's about as useful as a wax frying pan.
>>
>> 10 to the 12th power microphones = 1 Megaphone
>>
>> Maranatha! <><
>> John McKown
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> Liz Hare, PhD
> Dog Genetics LLC
> doggene at earthlink.net
> http://www.doggenetics.com <http://www.doggenetics.com/>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From bgunter.4567 at gmail.com  Thu Jun 18 18:57:31 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 18 Jun 2015 09:57:31 -0700
Subject: [R] help for lay person assisting R user with disability
In-Reply-To: <FB6064C7F3602142A01160BD26730530016F3D8A@PGH-MSGMB-03.andrew.ad.cmu.edu>
References: <FB6064C7F3602142A01160BD26730530016F3D8A@PGH-MSGMB-03.andrew.ad.cmu.edu>
Message-ID: <CAGxFJbTw-0XvFvace_x_O6bm3VHFsVF92m8FfNg6haZXQ-RA9A@mail.gmail.com>

Given that neither you nor the student are (skilled?) R users, I think you
would do better contacting someone locally for help -- there will be many
in the statistics and social sciences departments (among others).

There are several R packages that interface with Excel (e.g. RExcel), but
it may merely be a matter of reading in text files via R's native
facilities (e.g. read.csv ) . A local resource can best help you sort out
what would work best in your situation imho.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Thu, Jun 18, 2015 at 7:32 AM, Courtney Bryant <cbryant at andrew.cmu.edu>
wrote:

> Good Morning,
> I am currently working with a disabled R user who is a student here at
> CMU.  The student has both sight and mobility issues.  The student has
> asked for an assistant who is well versed in R to enter data for her, which
> we are having a hard time finding.  I would like information from R
> developers/users about how/how well R interfaces with Excel (an easier
> skill set to find!)   In your opinion, could it be as easy as uploading
> data from excel into R?
>
> Also, do you know of a way to enlarge the R interface or otherwise assist
> in making the program accessible to a low vision person?  My  limited
> understanding leads me to believe that screen magnifiers like zoom text
> don't work particularly well.  If you have information on that, I would
> very much appreciate it.
>
> Thanks for your help and for bearing with me!
> Courtney
>
>
>
> Courtney Bryant, EOS Specialist
> Equal Opportunity Services, Human Resources
> Carnegie Mellon University
> 412-268-3930 | cbryant at andrew.cmu.edu
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Rainer.Schuermann at gmx.net  Thu Jun 18 19:09:35 2015
From: Rainer.Schuermann at gmx.net (Rainer Schuermann)
Date: Thu, 18 Jun 2015 19:09:35 +0200
Subject: [R] Correlation matrix for pearson correlation (r,p,BH(FDR))
In-Reply-To: <81248373.944863.1434615595629.JavaMail.root@servirmail2>
References: <81248373.944863.1434615595629.JavaMail.root@servirmail2>
Message-ID: <1472447.h6hjy2kHAf@bonn>

The way the sample data is provided is not useful. I have re-built your data, please find the dput() version below (and pls check whether I got it right...).

This is not my area of competence at all, but from what I see from the help page is that the expected parameters are, among others:

x	A matrix or dataframe
y	A second matrix or dataframe __with the same number of rows as x__

I hope that somebody with a better understanding of your intention is able to pick up from here, with the sample data in useful format.

Rgds,
Rainer


dput( genes )
structure(list(Genes = structure(1:10, .Label = c("KCNAB3", "KCNB1", 
"KCNB2", "KERA", "KGFLP1", "KGFLP2", "KHDC1", "KHDC1L", "KHDC3L", 
"KHDRBS1"), class = "factor"), Cell.line1 = c(12.02005181, 0.02457449, 
0.44791862, 0.06090217, 0.02450101, 0, 0, 2.3189445, 0, 0), Cell.line2 = c(11.140091, 
1.3028535, 0.1060137, 0, 0, 0, 0, 2.8252262, 0, 0), Cell.line3 = c(15.60381163, 
0.81538294, 0.09864136, 0.03352993, 0, 0, 0, 5.29099724, 0, 0
), Cell.line4 = c(13.44151596, 0.59318327, 0, 0.03634781, 0, 
0, 0, 7.44183228, 0, 0), Cell.line5 = c(25.3716103, 0.15332321, 
0, 0.04190912, 0, 0, 0, 1.94629741, 0, 0), Cell.line6 = c(8.12373424, 
4.18181234, 0.05857207, 0, 0.02563099, 0, 0, 8.56022436, 0, 0
), Cell.line7 = c(7.67506261, 1.65268403, 0.05945414, 0, 0.03902548, 
0, 0, 7.50838343, 0, 0.0308118), Cell.line8 = c(24.43776341, 
5.9834632, 0.20733924, 0.07752608, 0, 0, 0, 7.17964645, 0, 0), 
    Cell.line9 = c(18.33244818, 1.51423807, 0.05830982, 0.01585643, 
    0, 0, 0, 3.28602729, 0, 0), Cell.line10 = c(9.224225, 0, 
    0, 16.664245, 0, 0, 0, 0, 3.598534, 2.600173)), .Names = c("Genes", 
"Cell.line1", "Cell.line2", "Cell.line3", "Cell.line4", "Cell.line5", 
"Cell.line6", "Cell.line7", "Cell.line8", "Cell.line9", "Cell.line10"
), row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "9", 
"10"), class = "data.frame")

dput( features )
structure(list(Cell.line = c("Growth rate", "Drug sensitivity"
), Cell.line1 = c(NA, "41.33"), Cell.line2 = c(NA, "26.76"), 
    Cell.line3 = c(NA, "24.19"), Cell.line4 = c("51.41", NA), 
    Cell.line5 = c(NA_character_, NA_character_), Cell.line6 = c("5.03", 
    "1.40"), Cell.line7 = c("6.57", "1.88"), Cell.line8 = c("8", 
    "1.33"), Cell.line9 = c("1.26", "5.05"), Cell.line10 = c("3", 
    "9.12")), .Names = c("Cell.line", "Cell.line1", "Cell.line2", 
"Cell.line3", "Cell.line4", "Cell.line5", "Cell.line6", "Cell.line7", 
"Cell.line8", "Cell.line9", "Cell.line10"), row.names = c(NA, 
-2L), class = "data.frame")


On Thu June 18 2015 10:19:55 Sarah Bazzocco wrote:
> This post was called "help" before, I changed the Subject.
> Thanks for the comments.
> Here the example: (I have the two lists saved as .csv and I can open them in R)
> 
> Sheet one- Genes (10 genes expression, not binary, meaured in 10 cell lines)
> > genes
>      Genes  Cell.line1 Cell.line2  Cell.line3  Cell.line4  Cell.line5
> 1   KCNAB3 12.02005181 11.1400910 15.60381163 13.44151596 25.37161030
> 2    KCNB1  0.02457449  1.3028535  0.81538294  0.59318327  0.15332321
> 3    KCNB2  0.44791862  0.1060137  0.09864136  0.00000000  0.00000000
> 4     KERA  0.06090217  0.0000000  0.03352993  0.03634781  0.04190912
> 5   KGFLP1  0.02450101  0.0000000  0.00000000  0.00000000  0.00000000
> 6   KGFLP2  0.00000000  0.0000000  0.00000000  0.00000000  0.00000000
> 7    KHDC1  0.00000000  0.0000000  0.00000000  0.00000000  0.00000000
> 8   KHDC1L  2.31894450  2.8252262  5.29099724  7.44183228  1.94629741
> 9   KHDC3L  0.00000000  0.0000000  0.00000000  0.00000000  0.00000000
> 10 KHDRBS1  0.00000000  0.0000000  0.00000000  0.00000000  0.00000000
>    Cell.line6 Cell.line7  Cell.line8  Cell.line9 Cell.line10
> 1  8.12373424 7.67506261 24.43776341 18.33244818    9.224225
> 2  4.18181234 1.65268403  5.98346320  1.51423807    0.000000
> 3  0.05857207 0.05945414  0.20733924  0.05830982    0.000000
> 4  0.00000000 0.00000000  0.07752608  0.01585643   16.664245
> 5  0.02563099 0.03902548  0.00000000  0.00000000    0.000000
> 6  0.00000000 0.00000000  0.00000000  0.00000000    0.000000
> 7  0.00000000 0.00000000  0.00000000  0.00000000    0.000000
> 8  8.56022436 7.50838343  7.17964645  3.28602729    0.000000
> 9  0.00000000 0.00000000  0.00000000  0.00000000    3.598534
> 10 0.00000000 0.03081180  0.00000000  0.00000000    2.600173
> 
> Sheet two - features (2 features(Growth rate,drug sensitivity for 10 cell lines)
> > features
>          Cell.line Cell.line1 Cell.line2 Cell.line3 Cell.line4 Cell.line5
> 1      Growth rate         NA         NA         NA      51.41         NA
> 2 Drug sensitivity       5.03       6.57          8       1.26          3
>   Cell.line6 Cell.line7 Cell.line8 Cell.line9 Cell.line10
> 1      41.33      26.76      24.19         NA          NA
> 2       1.40       1.88       1.33       5.05        9.12
> 
> What I found:
> corr.test {psych}
> corr.test(x, y = NULL, use = "pairwise",method="pearson",adjust="BH",alpha=.01)
> --> I adjusted the original command to what I need (BH insted og holm) and alpha=.01 insted of 0.05.
> 
> I would be very happy, if someone could show me how to use this command, in particular how to refer as x and y to the two sheets I have (Genes and Features). I would take it from there.
> 
> Thanks a lot in advance.
> 
> Sarah


From peter.langfelder at gmail.com  Thu Jun 18 20:52:18 2015
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Thu, 18 Jun 2015 11:52:18 -0700
Subject: [R] Correlation matrix for pearson correlation (r,p,BH(FDR))
In-Reply-To: <81248373.944863.1434615595629.JavaMail.root@servirmail2>
References: <1418689503.944316.1434612203956.JavaMail.root@servirmail2>
	<81248373.944863.1434615595629.JavaMail.root@servirmail2>
Message-ID: <CA+hbrhWwJ-NDLae3JA6pQR4eC0K-JBjcV4rZC6n95+OJa_Fe-Q@mail.gmail.com>

You have multiple options. I will advertise my own solution - install
the package WGCNA, installation instructions at

http://labs.genetics.ucla.edu/horvath/CoexpressionNetwork/Rpackages/WGCNA/#cranInstall

then you can use the function
cp = corAndPvalue(t(genes), t(features)).

You need to transpose both because the function expects variables in
columns and samples in rows.

This will give you a list whose components include 'cor' (matrix of
the correlation values) and 'p' (matrix of the Student p-values). To
get a matrix of the corresponding FDR, use

fdr = apply(cp$p, 2, p.adjust, method = "fdr")

Hope this helps,

Peter


On Thu, Jun 18, 2015 at 1:19 AM, Sarah Bazzocco <sarah.bazzocco at vhir.org> wrote:
> This post was called "help" before, I changed the Subject.
> Thanks for the comments.
> Here the example: (I have the two lists saved as .csv and I can open them in R)
>
> Sheet one- Genes (10 genes expression, not binary, meaured in 10 cell lines)
>> genes
>      Genes  Cell.line1 Cell.line2  Cell.line3  Cell.line4  Cell.line5
> 1   KCNAB3 12.02005181 11.1400910 15.60381163 13.44151596 25.37161030
> 2    KCNB1  0.02457449  1.3028535  0.81538294  0.59318327  0.15332321
> 3    KCNB2  0.44791862  0.1060137  0.09864136  0.00000000  0.00000000
> 4     KERA  0.06090217  0.0000000  0.03352993  0.03634781  0.04190912
> 5   KGFLP1  0.02450101  0.0000000  0.00000000  0.00000000  0.00000000
> 6   KGFLP2  0.00000000  0.0000000  0.00000000  0.00000000  0.00000000
> 7    KHDC1  0.00000000  0.0000000  0.00000000  0.00000000  0.00000000
> 8   KHDC1L  2.31894450  2.8252262  5.29099724  7.44183228  1.94629741
> 9   KHDC3L  0.00000000  0.0000000  0.00000000  0.00000000  0.00000000
> 10 KHDRBS1  0.00000000  0.0000000  0.00000000  0.00000000  0.00000000
>    Cell.line6 Cell.line7  Cell.line8  Cell.line9 Cell.line10
> 1  8.12373424 7.67506261 24.43776341 18.33244818    9.224225
> 2  4.18181234 1.65268403  5.98346320  1.51423807    0.000000
> 3  0.05857207 0.05945414  0.20733924  0.05830982    0.000000
> 4  0.00000000 0.00000000  0.07752608  0.01585643   16.664245
> 5  0.02563099 0.03902548  0.00000000  0.00000000    0.000000
> 6  0.00000000 0.00000000  0.00000000  0.00000000    0.000000
> 7  0.00000000 0.00000000  0.00000000  0.00000000    0.000000
> 8  8.56022436 7.50838343  7.17964645  3.28602729    0.000000
> 9  0.00000000 0.00000000  0.00000000  0.00000000    3.598534
> 10 0.00000000 0.03081180  0.00000000  0.00000000    2.600173
>
> Sheet two - features (2 features(Growth rate,drug sensitivity for 10 cell lines)
>> features
>          Cell.line Cell.line1 Cell.line2 Cell.line3 Cell.line4 Cell.line5
> 1      Growth rate         NA         NA         NA      51.41         NA
> 2 Drug sensitivity       5.03       6.57          8       1.26          3
>   Cell.line6 Cell.line7 Cell.line8 Cell.line9 Cell.line10
> 1      41.33      26.76      24.19         NA          NA
> 2       1.40       1.88       1.33       5.05        9.12
>
> What I found:
> corr.test {psych}
> corr.test(x, y = NULL, use = "pairwise",method="pearson",adjust="BH",alpha=.01)
> --> I adjusted the original command to what I need (BH insted og holm) and alpha=.01 insted of 0.05.
>
> I would be very happy, if someone could show me how to use this command, in particular how to refer as x and y to the two sheets I have (Genes and Features). I would take it from there.
>
> Thanks a lot in advance.
>
> Sarah
>
>
>
>
>
>
> ----- Original Message -----
> From: "Rainer Schuermann" <Rainer.Schuermann at gmx.net>
> To: "Sarah Bazzocco" <sarah.bazzocco at vhir.org>
> Sent: Thursday, 18 June, 2015 8:14:56 AM
> Subject: Re: [R] help
>
>
>
> Hi Sarah,
>
>
>
> Not an answer to our question but a piece of well intended advice:
>
>
>
> 1. Don't post HTML but plain text. Not only that people will tell you this in a sometimes not very friendly manner - using HTML actually does make posts illegible in this mailing list. Code, and R _is_ code, is always plain text.
>
>
>
> 2. Don't pose an abstract problem - this looks too much like "Can you please do my work for me". Show us what you have tried already, and people will happily jump in and provide their thoughts and advice.
>
>
>
> 3. Always make sure that you ave a reproducible example in your mail, and a set of data of the same type and structure you are using - ideally using dput().
>
>
>
> See further advice here
>
>
>
> PLEASE do read the posting guide   http://www.R-project.org/posting-guide.html
>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> and here:
>
>
>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
>
>
> For your problem, R has an immense wealth of ideas and solutions.
>
>
>
> Rgds,
>
> Rainer
>
>
>
>
>
>
>
> On Wed June 17 2015 16:57:24 Sarah Bazzocco wrote:
>
>>
>
>> Hello,
>
>>
>
>> ?
>
>>
>
>> I am a R-beginner and I need some help.?The question is very simple: I need to do a pearson correlations (r,p-value and FDR with BH) from an Expression array (with several thousand genes for lets say 20 cell lines)?with some features of those cell lines.
>
>>
>
>>
>
>>
>
>> My problem I have is the organization of the excel sheets and how to introduce the data into R and run the script. I though the easiest and more organized for me would be two expcel sheets:
>
>>
>
>> 1- Only Expression data (in rows the?genes and in colums cell lines)
>
>>
>
>> 2- Only the features (In row the features (e.g. a) growth rate, b) sensitivity to some drugs) and in columns the cell lines).
>
>>
>
>>
>
>>
>
>> -->That would creat both sheets with 20 colums.
>
>>
>
>>
>
>>
>
>> Now I would like to get a correlation of the gene 1: the expression of all lines with the growth rate.
>
>>
>
>> the same for gene2... and soforth. I sould obtain as many r,p and BH(FDR) as genes there are.
>
>>
>
>> the same I would need to do for the sensitivity... and so on.
>
>>
>
>>
>
>>
>
>> Do you think this is doable? I am not at all a bioinformatic expert, so all help is very welcome.
>
>>
>
>>
>
>>
>
>> Thank you very much!
>
>>
>
>>
>
>>
>
>> Kind regards,
>
>>
>
>>
>
>>
>
>> Sarah
>
>>
>
>>
>
>>
>
>>
>
>
>
> --
>
>
> Sarah Bazzocco, PhD student
> Group of Molecular Oncology,
> CIBBIM-Nanomedicine,
> Vall d'Hebron Hospital Research Institute,
> Passeig Vall d'Hebron 119-129,
> Barcelona 08035, Spain.
> Tel: +34-93-489-4056
>
> Fax: +34-93-489-3893
> Email: sarah.bazzocco at vhir.org
>
>
>
> --
>
>
> Sarah Bazzocco, PhD student
> Group of Molecular Oncology,
> CIBBIM-Nanomedicine,
> Vall d'Hebron Hospital Research Institute,
> Passeig Vall d'Hebron 119-129,
> Barcelona 08035, Spain.
> Tel: +34-93-489-4056
>
> Fax: +34-93-489-3893
> Email: sarah.bazzocco at vhir.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From f_j_rod at hotmail.com  Thu Jun 18 21:40:59 2015
From: f_j_rod at hotmail.com (Frank S.)
Date: Thu, 18 Jun 2015 21:40:59 +0200
Subject: [R] Sign of specific elements of a vector
Message-ID: <BAY168-W7457447610F7CA9EA26332BAA50@phx.gbl>

Hi everyone,
 
I have an "x" vector and I would want to change the sign every 20 elements. For this puspose,
I wrote the following code:
 
set.seed(1)
x <- rnorm(100)
x
x[seq(20,100, by=20)] <- -x[seq(20,100, by=20)]
x
 
However, I'm afraid  it is a rudimentary form to get the desired result. II wonder wether there is a cool way to do so, that is, for example with apply or sign function.
 
Thans in advanced for your help!

Frank S.
 		 	   		  
	[[alternative HTML version deleted]]


From paul at stat.auckland.ac.nz  Thu Jun 18 21:41:40 2015
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Fri, 19 Jun 2015 07:41:40 +1200
Subject: [R] help for lay person assisting R user with disability
In-Reply-To: <FB6064C7F3602142A01160BD26730530016F3D8A@PGH-MSGMB-03.andrew.ad.cmu.edu>
References: <FB6064C7F3602142A01160BD26730530016F3D8A@PGH-MSGMB-03.andrew.ad.cmu.edu>
Message-ID: <55831EF4.8050307@stat.auckland.ac.nz>

Hi

Jonathon Godfrey has published some information and guidelines on the 
accessibility of R (and other stat software), e.g., ...

http://r-resources.massey.ac.nz/StatSoftware/
http://journal.r-project.org/archive/2013-1/godfrey.pdf

Paul

On 06/19/15 02:32, Courtney Bryant wrote:
> Good Morning, I am currently working with a disabled R user who is a
> student here at CMU.  The student has both sight and mobility issues.
> The student has asked for an assistant who is well versed in R to
> enter data for her, which we are having a hard time finding.  I would
> like information from R developers/users about how/how well R
> interfaces with Excel (an easier skill set to find!)   In your
> opinion, could it be as easy as uploading data from excel into R?
>
> Also, do you know of a way to enlarge the R interface or otherwise
> assist in making the program accessible to a low vision person?  My
> limited understanding leads me to believe that screen magnifiers like
> zoom text don't work particularly well.  If you have information on
> that, I would very much appreciate it.
>
> Thanks for your help and for bearing with me! Courtney
>
>
>
> Courtney Bryant, EOS Specialist Equal Opportunity Services, Human
> Resources Carnegie Mellon University 412-268-3930 |
> cbryant at andrew.cmu.edu
>
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and provide
> commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From bgunter.4567 at gmail.com  Thu Jun 18 22:07:48 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 18 Jun 2015 13:07:48 -0700
Subject: [R] Sign of specific elements of a vector
In-Reply-To: <BAY168-W7457447610F7CA9EA26332BAA50@phx.gbl>
References: <BAY168-W7457447610F7CA9EA26332BAA50@phx.gbl>
Message-ID: <CAGxFJbRbPxHqXd1Xf2x2jMpO1OWHhh-WaH8dDY+drpWU4SYVxw@mail.gmail.com>

Your **is** the "coolest" and most efficient way to do this. It's
vectorized -- apply() stuff is not.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

On Thu, Jun 18, 2015 at 12:40 PM, Frank S. <f_j_rod at hotmail.com> wrote:

> Hi everyone,
>
> I have an "x" vector and I would want to change the sign every 20
> elements. For this puspose,
> I wrote the following code:
>
> set.seed(1)
> x <- rnorm(100)
> x
> x[seq(20,100, by=20)] <- -x[seq(20,100, by=20)]
> x
>
> However, I'm afraid  it is a rudimentary form to get the desired result.
> II wonder wether there is a cool way to do so, that is, for example with
> apply or sign function.
>
> Thans in advanced for your help!
>
> Frank S.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From cbryant at andrew.cmu.edu  Thu Jun 18 19:41:43 2015
From: cbryant at andrew.cmu.edu (Courtney Bryant)
Date: Thu, 18 Jun 2015 17:41:43 +0000
Subject: [R] help for lay person assisting R user with disability
In-Reply-To: <65591B85-35D7-4138-83DB-07F481899508@earthlink.net>
References: <FB6064C7F3602142A01160BD26730530016F3D8A@PGH-MSGMB-03.andrew.ad.cmu.edu>
	<CAAJSdjh7bBW73CXUA33_YQ_zKJSqu86h1e2NfvuMVyD+nhgMZA@mail.gmail.com>
	<65591B85-35D7-4138-83DB-07F481899508@earthlink.net>
Message-ID: <FB6064C7F3602142A01160BD26730530016F4110@PGH-MSGMB-03.andrew.ad.cmu.edu>

Hi Liz,
This is a particularly sticky case ? the student is attempting to get a PhD but is currently in between programs until her current project (which we?re attempting to hire an assistant for, or better yet some up with a solution she can work on her own) is completed and ?accepted? in some way.
I believe her main access issue is around mobility, she has little use of her hands.  I wasn?t sure if sight was as much of an issue, but from what I?ve learned here it seems that enlarging the text itself is easy enough.  I will double check with her about her computer ? at the end of the day, if she is game, perhaps I could provide her with a mac.

Courtney Bryant, EOS Specialist
Equal Opportunity Services, Human Resources
Carnegie Mellon University
412-268-3930 | cbryant at andrew.cmu.edu<mailto:cbryant at andrew.cmu.edu>



From: Liz Hare [mailto:doggene at earthlink.net]
Sent: Thursday, June 18, 2015 12:42 PM
To: John McKown
Cc: Courtney Bryant; r-help at R-project.org
Subject: Re: [R] help for lay person assisting R user with disability

Hi Courtney and John,

The RStudio environment mentioned below will not work with speech output (I tried with Window-Eyes awhile ago). Some of my clients use it but I have no experience with it. Since the student is partially sighted, they might be able to customize the environment with big fonts and contrast, I?m just not sure.

Using a screen reader like Window-Eyes, the student could use the R GUI environment, although it?s a little frustrating because it doesn?t speak a lot and you need to use the mouse keys a lot.

The other option if you have to stick with Windows  is to run R at the command prompt, which makes interaction slightly easier but you?d have to figure out how to log the output.

What is being recommended for the rest of the students in the class? Ideally, this student?s experience should be as close as possible to the others?.

Liz
On Jun 18, 2015, at 12:17 PM, John McKown <john.archie.mckown at gmail.com<mailto:john.archie.mckown at gmail.com>> wrote:

On Thu, Jun 18, 2015 at 9:32 AM, Courtney Bryant <cbryant at andrew.cmu.edu<mailto:cbryant at andrew.cmu.edu>>
wrote:


Good Morning,
I am currently working with a disabled R user who is a student here at
CMU.  The student has both sight and mobility issues.  The student has
asked for an assistant who is well versed in R to enter data for her, which
we are having a hard time finding.  I would like information from R
developers/users about how/how well R interfaces with Excel (an easier
skill set to find!)   In your opinion, could it be as easy as uploading
data from excel into R?

Also, do you know of a way to enlarge the R interface or otherwise assist
in making the program accessible to a low vision person?  My  limited
understanding leads me to believe that screen magnifiers like zoom text
don't work particularly well.  If you have information on that, I would
very much appreciate it.

Thanks for your help and for bearing with me!
Courtney

I am a bit confused (a normal condition for me). Is the student writing R
code or is the student running a application written in R? Also, since you
mentioned Excel, I am assuming that the student is using a PC running
Windows as opposed to Linux or a Mac.

If the student is writing R code, then I'd suggest that your computer
support person install Rstudio. It is cost free and can be downloaded here:
http://www.rstudio.com/ . The installer can then customize Rstudio to use a
really large font, if that would be helpful. Please forgive my lack of
knowledge about accessibility issues. If the student has trouble typing
(mobility issue?), this likely won't help. Would a speech to text / text to
speech interface help instead of a screen magnifier? I know next to nothing
about these tools, other than that they exist.

===

If the student is running an R application (which is what "enter data for
her" implies to me), then any accessibility issues would need to be
addressed in the application itself. But I don't understand why a "data
entry" assistant would need any skills in R itself in order to enter data
into it. But without knowing more, that's about all that I can say. One
thought: CMU has a college teaching "electrical and computer engineering".
Depending on what that means, perhaps someone from that college (professor,
TA, or grad student) could see what your student is doing and perhaps have
some insights on how to help. Or is there a "computer club" on campus where
some geeky student might be found? You might look here:
http://www.club.cc.cmu.edu/ If these are true geeks (and the web site
sounds promising), then a lure of beer & pizza would likely be irresistible
<grin>.

===

For interfacing R with Excel, you might want to look at RExcel here:
http://rcom.univie.ac.at/download.html#RExcel . It has a free student
version. But is this more for an Excel user who wants to use R for
analysis, not an R user wanting to use Excel for "data entry".



--
Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.

My sister opened a computer store in Hawaii. She sells C shells down by the
seashore.
If someone tell you that nothing is impossible:
Ask him to dribble a football.

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

            [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Liz Hare, PhD
Dog Genetics LLC
doggene at earthlink.net<mailto:doggene at earthlink.net>
http://www.doggenetics.com


	[[alternative HTML version deleted]]


From pertsou at yahoo.gr  Thu Jun 18 19:55:27 2015
From: pertsou at yahoo.gr (Endy)
Date: Thu, 18 Jun 2015 17:55:27 +0000 (UTC)
Subject: [R] R problem
Message-ID: <189004898.2200206.1434650127599.JavaMail.yahoo@mail.yahoo.com>

Hi, R users.
I am using windows 7 ultimate, as an OS, and the R version
3.2.0. This combination creates some problems when I run R.  The problem focuses on the command ?source?.
More precisely, suppose that we have a main function, let call it mainfn, which
calls within it another function, call it subfn, with the command     source(?C:\\Program
Files\\. . .\\subfn.txt?).
 The files with the R
code of the two functions, mainfn and subfn, are .txt files. First I load the
mainfn  function using       File->  Source R code?      and I get
>source(?C:\\Program Files\\ . . .\\mainfn.txt?)
Then I run the mainfn 
>mainfn ()
and I get 
Error in file(filename, "r", encoding = encoding)
: 
  cannot open the
connection
Any suggestion what goes wrong?
> 


From marc_schwartz at me.com  Thu Jun 18 22:21:29 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 18 Jun 2015 15:21:29 -0500
Subject: [R] Sign of specific elements of a vector
In-Reply-To: <CAGxFJbRbPxHqXd1Xf2x2jMpO1OWHhh-WaH8dDY+drpWU4SYVxw@mail.gmail.com>
References: <BAY168-W7457447610F7CA9EA26332BAA50@phx.gbl>
	<CAGxFJbRbPxHqXd1Xf2x2jMpO1OWHhh-WaH8dDY+drpWU4SYVxw@mail.gmail.com>
Message-ID: <3AA12A76-1E11-4B23-92AE-99B681215DA1@me.com>

Just to augment Bert?s comment, other options are likely to introduce some level of overhead that while perhaps looking better, will not be materially faster. Depending upon the length of your vector, you could do some testing to see.

One thing that might yield a little bit of performance improvement would be to pre-calculate the indices:

set.seed(1)
x <- rnorm(100)
IND <- seq(20,100, by=20)

> IND
[1]  20  40  60  80 100

> x[IND]
[1]  0.5939013  0.7631757 -0.1350546 -0.5895209 -0.4734006

x[IND] <- -x[IND]

> x[IND]
[1] -0.5939013 -0.7631757  0.1350546  0.5895209  0.4734006


But unless your vector is very large, I suspect the performance gain may be minimal in real time.

Regards,

Marc Schwartz


> On Jun 18, 2015, at 3:07 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Your **is** the "coolest" and most efficient way to do this. It's
> vectorized -- apply() stuff is not.
> 
> Cheers,
> Bert
> 
> Bert Gunter
> 
> "Data is not information. Information is not knowledge. And knowledge is
> certainly not wisdom."
>   -- Clifford Stoll
> 
> On Thu, Jun 18, 2015 at 12:40 PM, Frank S. <f_j_rod at hotmail.com> wrote:
> 
>> Hi everyone,
>> 
>> I have an "x" vector and I would want to change the sign every 20
>> elements. For this puspose,
>> I wrote the following code:
>> 
>> set.seed(1)
>> x <- rnorm(100)
>> x
>> x[seq(20,100, by=20)] <- -x[seq(20,100, by=20)]
>> x
>> 
>> However, I'm afraid  it is a rudimentary form to get the desired result.
>> II wonder wether there is a cool way to do so, that is, for example with
>> apply or sign function.
>> 
>> Thans in advanced for your help!
>> 
>> Frank S.


From wdunlap at tibco.com  Thu Jun 18 22:41:55 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 18 Jun 2015 13:41:55 -0700
Subject: [R] R problem
In-Reply-To: <189004898.2200206.1434650127599.JavaMail.yahoo@mail.yahoo.com>
References: <189004898.2200206.1434650127599.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAF8bMcai45jkPwDV55LpfEVuFWvDOgkDk0p+oVR7ON1KnzWDag@mail.gmail.com>

Usually, along with that error message, you get a warning
that gives a few details about the problem, like the name
of the file and the reason it could be opened.  E.g.,
  > filename <- "no\\such\\file.blah.blah"
  > file(filename, "r", encoding="UTF-8")
  Error in file(filename, "r", encoding = "UTF-8") :
    cannot open the connection
  In addition: Warning message:
  In file(filename, "r", encoding = "UTF-8") :
    cannot open file 'no\such\file.blah.blah': No such file or directory
Did you suppress warnings?


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Jun 18, 2015 at 10:55 AM, Endy <pertsou at yahoo.gr> wrote:

> Hi, R users.
> I am using windows 7 ultimate, as an OS, and the R version
> 3.2.0. This combination creates some problems when I run R.  The problem
> focuses on the command ?source?.
> More precisely, suppose that we have a main function, let call it mainfn,
> which
> calls within it another function, call it subfn, with the command
>  source(?C:\\Program
> Files\\. . .\\subfn.txt?).
>  The files with the R
> code of the two functions, mainfn and subfn, are .txt files. First I load
> the
> mainfn  function using       File->  Source R code?      and I get
> >source(?C:\\Program Files\\ . . .\\mainfn.txt?)
> Then I run the mainfn
> >mainfn ()
> and I get
> Error in file(filename, "r", encoding = encoding)
> :
>   cannot open the
> connection
> Any suggestion what goes wrong?
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From simon.wood at bath.edu  Thu Jun 18 22:14:01 2015
From: simon.wood at bath.edu (Simon Wood)
Date: Thu, 18 Jun 2015 21:14:01 +0100
Subject: [R] Is there a convenient way of extracting the matrix `solve(X
 %*% t(X) + PENALTY)` from an additive model fit in mgcv?
In-Reply-To: <f60413299f044fcd8d422339ee9da2f3@exch07.campus.bath.ac.uk>
References: <55822A6A.4010703@gmail.com>
	<f60413299f044fcd8d422339ee9da2f3@exch07.campus.bath.ac.uk>
Message-ID: <55832689.9090905@bath.edu>

Yes...

## example fit...
  library(mgcv)
  set.seed(2) ## simulate some data...
  dat <- gamSim(1,n=400,dist="normal",scale=2)
  b <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),data=dat)
## extract the thing required in the title....
  b$Vp/b$sig2

best,
Simon


On 18/06/15 03:23, Andrew Crane-Droesch wrote:
> The title says it all. An additive model can be fit by `solve(X %*% t(X)
> + PENALTY)%*%t(X)%*%y` (though of course there are more efficient ways
> to do it). I want the matrix `solve(X %*% t(X) + PENALTY)` from a fitted
> gam object. GAM objects can be a bit tricky to navigate -- is there a
> convenient way of extracting this?
>
> Happy to explain why I'm interested in this to anyone who would like to
> know, off-list.
>
> Many thanks!
> Andrew
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From andrewcd at berkeley.edu  Thu Jun 18 22:23:55 2015
From: andrewcd at berkeley.edu (Andrew Crane-Droesch)
Date: Thu, 18 Jun 2015 13:23:55 -0700
Subject: [R] Is there a convenient way of extracting the matrix `solve(X
 %*% t(X) + PENALTY)` from an additive model fit in mgcv?
In-Reply-To: <55832689.9090905@bath.edu>
References: <55822A6A.4010703@gmail.com>
	<f60413299f044fcd8d422339ee9da2f3@exch07.campus.bath.ac.uk>
	<55832689.9090905@bath.edu>
Message-ID: <558328DB.7010801@berkeley.edu>

...That should have been obvious!  I'm a little embarrassed!

Thanks,
Andrew

**
On 06/18/2015 01:14 PM, Simon Wood wrote:
> Yes...
>
> ## example fit...
>  library(mgcv)
>  set.seed(2) ## simulate some data...
>  dat <- gamSim(1,n=400,dist="normal",scale=2)
>  b <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),data=dat)
> ## extract the thing required in the title....
>  b$Vp/b$sig2
>
> best,
> Simon
>
>
> On 18/06/15 03:23, Andrew Crane-Droesch wrote:
>> The title says it all. An additive model can be fit by `solve(X %*% t(X)
>> + PENALTY)%*%t(X)%*%y` (though of course there are more efficient ways
>> to do it). I want the matrix `solve(X %*% t(X) + PENALTY)` from a fitted
>> gam object. GAM objects can be a bit tricky to navigate -- is there a
>> convenient way of extracting this?
>>
>> Happy to explain why I'm interested in this to anyone who would like to
>> know, off-list.
>>
>> Many thanks!
>> Andrew
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From gianni.lavaredo at gmail.com  Fri Jun 19 02:42:08 2015
From: gianni.lavaredo at gmail.com (gianni lavaredo)
Date: Thu, 18 Jun 2015 18:42:08 -0600
Subject: [R] Repeated Measures ANOVA and Missing Values in the data set
Message-ID: <CAJ6JbR88fsjtnztvWog_iUzrGXEKAqBE0XWGVwWZja71wPva0w@mail.gmail.com>

I am doing Repeated Measures ANOVA with missing values. When i run my model
i get this error message.




*aov.out = aov(values ~ time + Error(subject/time), data=mydata2)Warning
message:In aov(values ~ time + Error(subject/time), data = mydata2) :
Error() model is singular*

The missing Values are not a error of my instrument. They mean the element
of my analysis is absent and i want to consider this.

thanks in advance

these are my data:

subject <- c(1,2,3,4,5,6,7,8,9,10)
time1 <- c(5040,3637,6384,5309,5420,3549,NA,5140,3890,3910)
time2 <- c(5067, 3668, NA, 6489, NA, 3922, 3408, 6613, 4063, 3937)
time3 <- c( 3278, 3814, 8745, 4760, 4911, 5716, 5547, 5844, 4914, 4390)
time4 <- c(   0, 2971,    0, 2776, 2128, 1208, 2935, 2739, 3054, 3363)
time5 <- c(4161, 3483, 6728, 5008, 5562, 4380, 4006, 7536, 3805, 3923)
time6 <- c( 3604, 3411, 2523, 3264, 3578, 2941, 2939,   NA, 3612, 3604)
mydata <- data.frame(time1, time2, time3, time4, time5, time6)
mydata2 = stack(mydata)
subject  = factor(rep(subject,6))
mydata2[3] = subject
colnames(mydata2) = c("values", "time", "subject")
aov.out = aov(values ~ time + Error(subject/time), data=mydata2)
summary(aov.out)
model.tables(aov.out,"means")

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Jun 19 06:33:57 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 18 Jun 2015 21:33:57 -0700
Subject: [R] Sign of specific elements of a vector
In-Reply-To: <3AA12A76-1E11-4B23-92AE-99B681215DA1@me.com>
References: <BAY168-W7457447610F7CA9EA26332BAA50@phx.gbl>
	<CAGxFJbRbPxHqXd1Xf2x2jMpO1OWHhh-WaH8dDY+drpWU4SYVxw@mail.gmail.com>
	<3AA12A76-1E11-4B23-92AE-99B681215DA1@me.com>
Message-ID: <6B7C9027-F1D1-49BD-8738-452290BCDEBE@comcast.net>


On Jun 18, 2015, at 1:21 PM, Marc Schwartz wrote:

> Just to augment Bert?s comment, other options are likely to introduce some level of overhead that while perhaps looking better, will not be materially faster. Depending upon the length of your vector, you could do some testing to see.
> 

Another method which depends upon R recycling of vector arguments:

x <- x*c(rep(1,19), -1)

Might be a bit faster:

> set.seed(1)
> x <- rnorm(1e6)
> system.time(x <- x*c(rep(1,19), -1))
   user  system elapsed 
  0.005   0.000   0.005 
> set.seed(1)
> system.time({
+ IND <- seq(20,length(x), by=20)
+ x[IND] <- -x[IND]})
   user  system elapsed 
  0.010   0.001   0.011 

-- 
David.

> One thing that might yield a little bit of performance improvement would be to pre-calculate the indices:
> 
> set.seed(1)
> x <- rnorm(100)
> IND <- seq(20,100, by=20)
> 
>> IND
> [1]  20  40  60  80 100
> 
>> x[IND]
> [1]  0.5939013  0.7631757 -0.1350546 -0.5895209 -0.4734006
> 
> x[IND] <- -x[IND]
> 
>> x[IND]
> [1] -0.5939013 -0.7631757  0.1350546  0.5895209  0.4734006
> 
> 
> But unless your vector is very large, I suspect the performance gain may be minimal in real time.
> 
> Regards,
> 
> Marc Schwartz
> 
> 
>> On Jun 18, 2015, at 3:07 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> 
>> Your **is** the "coolest" and most efficient way to do this. It's
>> vectorized -- apply() stuff is not.
>> 
>> Cheers,
>> Bert
>> 
>> Bert Gunter
>> 
>> "Data is not information. Information is not knowledge. And knowledge is
>> certainly not wisdom."
>>  -- Clifford Stoll
>> 
>> On Thu, Jun 18, 2015 at 12:40 PM, Frank S. <f_j_rod at hotmail.com> wrote:
>> 
>>> Hi everyone,
>>> 
>>> I have an "x" vector and I would want to change the sign every 20
>>> elements. For this puspose,
>>> I wrote the following code:
>>> 
>>> set.seed(1)
>>> x <- rnorm(100)
>>> x
>>> x[seq(20,100, by=20)] <- -x[seq(20,100, by=20)]
>>> x
>>> 
>>> However, I'm afraid  it is a rudimentary form to get the desired result.
>>> II wonder wether there is a cool way to do so, that is, for example with
>>> apply or sign function.
>>> 
>>> Thans in advanced for your help!
>>> 
>>> Frank S.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From stephane.adamowicz at avignon.inra.fr  Fri Jun 19 10:06:43 2015
From: stephane.adamowicz at avignon.inra.fr (=?iso-8859-1?Q?St=E9phane_Adamowicz?=)
Date: Fri, 19 Jun 2015 10:06:43 +0200
Subject: [R] Repeated Measures ANOVA and Missing Values in the data set
In-Reply-To: <CAJ6JbR88fsjtnztvWog_iUzrGXEKAqBE0XWGVwWZja71wPva0w@mail.gmail.com>
References: <CAJ6JbR88fsjtnztvWog_iUzrGXEKAqBE0XWGVwWZja71wPva0w@mail.gmail.com>
Message-ID: <FF7215E1-2920-446F-B56F-3B5C5FFFBA7F@avignon.inra.fr>

This happens because your model should be :

aov.out = aov(values ~ time + Error(subject), data=mydata2)

This will not generate any error.
However, you should be aware that aov is not suitable for unbalanced data, for which it will give inconsistent results.

In such case, you can use the lme function :

require(nlme)
aov2 <- lme(fixed= values~time, random=~1|subject, na.action=na.omit, data=mydata2)
summary(aov2)
anova(aov2)


Le 19 juin 2015 ? 02:42, gianni lavaredo <gianni.lavaredo at gmail.com> a ?crit :

> I am doing Repeated Measures ANOVA with missing values. When i run my model
> i get this error message.
> 
> 
> 
> 
> *aov.out = aov(values ~ time + Error(subject/time), data=mydata2)Warning
> message:In aov(values ~ time + Error(subject/time), data = mydata2) :
> Error() model is singular*
> 
> The missing Values are not a error of my instrument. They mean the element
> of my analysis is absent and i want to consider this.
> 
> thanks in advance
> 
> these are my data:
> 
> subject <- c(1,2,3,4,5,6,7,8,9,10)
> time1 <- c(5040,3637,6384,5309,5420,3549,NA,5140,3890,3910)
> time2 <- c(5067, 3668, NA, 6489, NA, 3922, 3408, 6613, 4063, 3937)
> time3 <- c( 3278, 3814, 8745, 4760, 4911, 5716, 5547, 5844, 4914, 4390)
> time4 <- c(   0, 2971,    0, 2776, 2128, 1208, 2935, 2739, 3054, 3363)
> time5 <- c(4161, 3483, 6728, 5008, 5562, 4380, 4006, 7536, 3805, 3923)
> time6 <- c( 3604, 3411, 2523, 3264, 3578, 2941, 2939,   NA, 3612, 3604)
> mydata <- data.frame(time1, time2, time3, time4, time5, time6)
> mydata2 = stack(mydata)
> subject  = factor(rep(subject,6))
> mydata2[3] = subject
> colnames(mydata2) = c("values", "time", "subject")
> aov.out = aov(values ~ time + Error(subject/time), data=mydata2)
> summary(aov.out)
> model.tables(aov.out,"means")
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



 
St?phane Adamowicz
Chercheur / Scientist
stephane.adamowicz at paca.inra.fr
Centre PACA - UR 1115 PSH
Tel. : +33 1 (0)4 32 72 24 35
Fax : +33 1 (0)4 32 72 24 32
228, route de l'A?rodrome
84 914 Avignon Cedex 9
France
www.inra.fr


From f_j_rod at hotmail.com  Fri Jun 19 12:36:12 2015
From: f_j_rod at hotmail.com (Frank S.)
Date: Fri, 19 Jun 2015 12:36:12 +0200
Subject: [R] Sign of specific elements of a vector
In-Reply-To: <6B7C9027-F1D1-49BD-8738-452290BCDEBE@comcast.net>
References: <BAY168-W7457447610F7CA9EA26332BAA50@phx.gbl>,
	<CAGxFJbRbPxHqXd1Xf2x2jMpO1OWHhh-WaH8dDY+drpWU4SYVxw@mail.gmail.com>,
	<3AA12A76-1E11-4B23-92AE-99B681215DA1@me.com>,
	<6B7C9027-F1D1-49BD-8738-452290BCDEBE@comcast.net>
Message-ID: <BAY168-W64B2E180E1803DD4A61DFABAA40@phx.gbl>

Thank you for all your observations and comments!!
 
As you suggest, the option x <- x*c(rep(1,19), -1) is a more elegant and a fast way!
 
Frank S.
 
> From: dwinsemius at comcast.net
> Date: Thu, 18 Jun 2015 21:33:57 -0700
> To: marc_schwartz at me.com
> CC: r-help at r-project.org
> Subject: Re: [R] Sign of specific elements of a vector
> 
> 
> On Jun 18, 2015, at 1:21 PM, Marc Schwartz wrote:
> 
> > Just to augment Bert?s comment, other options are likely to introduce some level of overhead that while perhaps looking better, will not be materially faster. Depending upon the length of your vector, you could do some testing to see.
> > 
> 
> Another method which depends upon R recycling of vector arguments:
> 
> x <- x*c(rep(1,19), -1)
> 
> Might be a bit faster:
> 
> > set.seed(1)
> > x <- rnorm(1e6)
> > system.time(x <- x*c(rep(1,19), -1))
>    user  system elapsed 
>   0.005   0.000   0.005 
> > set.seed(1)
> > system.time({
> + IND <- seq(20,length(x), by=20)
> + x[IND] <- -x[IND]})
>    user  system elapsed 
>   0.010   0.001   0.011 
> 
> -- 
> David.
> 
> > One thing that might yield a little bit of performance improvement would be to pre-calculate the indices:
> > 
> > set.seed(1)
> > x <- rnorm(100)
> > IND <- seq(20,100, by=20)
> > 
> >> IND
> > [1]  20  40  60  80 100
> > 
> >> x[IND]
> > [1]  0.5939013  0.7631757 -0.1350546 -0.5895209 -0.4734006
> > 
> > x[IND] <- -x[IND]
> > 
> >> x[IND]
> > [1] -0.5939013 -0.7631757  0.1350546  0.5895209  0.4734006
> > 
> > 
> > But unless your vector is very large, I suspect the performance gain may be minimal in real time.
> > 
> > Regards,
> > 
> > Marc Schwartz
> > 
> > 
> >> On Jun 18, 2015, at 3:07 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >> 
> >> Your **is** the "coolest" and most efficient way to do this. It's
> >> vectorized -- apply() stuff is not.
> >> 
> >> Cheers,
> >> Bert
> >> 
> >> Bert Gunter
> >> 
> >> "Data is not information. Information is not knowledge. And knowledge is
> >> certainly not wisdom."
> >>  -- Clifford Stoll
> >> 
> >> On Thu, Jun 18, 2015 at 12:40 PM, Frank S. <f_j_rod at hotmail.com> wrote:
> >> 
> >>> Hi everyone,
> >>> 
> >>> I have an "x" vector and I would want to change the sign every 20
> >>> elements. For this puspose,
> >>> I wrote the following code:
> >>> 
> >>> set.seed(1)
> >>> x <- rnorm(100)
> >>> x
> >>> x[seq(20,100, by=20)] <- -x[seq(20,100, by=20)]
> >>> x
> >>> 
> >>> However, I'm afraid  it is a rudimentary form to get the desired result.
> >>> II wonder wether there is a cool way to do so, that is, for example with
> >>> apply or sign function.
> >>> 
> >>> Thans in advanced for your help!
> >>> 
> >>> Frank S.
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
 		 	   		  
	[[alternative HTML version deleted]]


From sigbert at wiwi.hu-berlin.de  Fri Jun 19 14:14:11 2015
From: sigbert at wiwi.hu-berlin.de (Sigbert Klinke)
Date: Fri, 19 Jun 2015 14:14:11 +0200
Subject: [R] Setting two default CRAN servers under Windows/RStudio
Message-ID: <55840793.6000205@wiwi.hu-berlin.de>

Hi,

we are running in our network a non-public CRAN mirror. I got it working
with the entry in "Rprofile.site"

local({r <- getOption("repos")
       r["CRAN"] <- "http://local.cran.server"
       options(repos=r)
})

In case that our CRAN mirror does not work we want to send the R/RStudio
users to a public server. I tried

1.
local({r <- getOption("repos")
       r["CRAN"] <- c("CRAN"="http://local.cran.server", r)
       options(repos=r)
})

-> install.packages offered the list of public mirrors

2.
local({r <- getOption("repos")
       r["CRAN"] <- c(r, "CRAN"="http://local.cran.server")
       options(repos=r)
})

-> packages are taken from cran.rstudio.com

3.
local({r <- getOption("repos")
       r["CRAN"] <- c(r["CRAN"], "CRAN"="http://local.cran.server",
r["CRANextra"])
       options(repos=r)
})

-> packages are taken from cran.rstudio.com

None of the solutions worked under RStudio, the packages are always
installed from the public servers. Any ideas?

Thanks Sigbert

From murdoch.duncan at gmail.com  Fri Jun 19 15:31:38 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 19 Jun 2015 09:31:38 -0400
Subject: [R] Setting two default CRAN servers under Windows/RStudio
In-Reply-To: <55840793.6000205@wiwi.hu-berlin.de>
References: <55840793.6000205@wiwi.hu-berlin.de>
Message-ID: <558419BA.7040508@gmail.com>

On 19/06/2015 8:14 AM, Sigbert Klinke wrote:
> Hi,
> 
> we are running in our network a non-public CRAN mirror. I got it working
> with the entry in "Rprofile.site"
> 
> local({r <- getOption("repos")
>        r["CRAN"] <- "http://local.cran.server"
>        options(repos=r)
> })
> 
> In case that our CRAN mirror does not work we want to send the R/RStudio
> users to a public server. I tried
> 
> 1.
> local({r <- getOption("repos")
>        r["CRAN"] <- c("CRAN"="http://local.cran.server", r)
>        options(repos=r)
> })
> 
> -> install.packages offered the list of public mirrors
> 
> 2.
> local({r <- getOption("repos")
>        r["CRAN"] <- c(r, "CRAN"="http://local.cran.server")
>        options(repos=r)
> })
> 
> -> packages are taken from cran.rstudio.com
> 
> 3.
> local({r <- getOption("repos")
>        r["CRAN"] <- c(r["CRAN"], "CRAN"="http://local.cran.server",
> r["CRANextra"])
>        options(repos=r)
> })
> 
> -> packages are taken from cran.rstudio.com
> 
> None of the solutions worked under RStudio, the packages are always
> installed from the public servers. Any ideas?

Your options seem to be trying to put a length two vector into a single
entry.  Just create a vector like

r <- c(localCRAN = "http://local.cran.server", r)

and you'll get a length two vector instead.

Duncan Murdoch

Duncan Murdoch


From thierry.onkelinx at inbo.be  Fri Jun 19 15:32:40 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 19 Jun 2015 15:32:40 +0200
Subject: [R] Setting two default CRAN servers under Windows/RStudio
In-Reply-To: <55840793.6000205@wiwi.hu-berlin.de>
References: <55840793.6000205@wiwi.hu-berlin.de>
Message-ID: <CAJuCY5xdr7nquiSfsizC=LdFFTMvCaPq5g1Rs5snwBibj50Xig@mail.gmail.com>

We have this in our Rprofile.site This works fine. It checks each mirror
and installs (or updates) the latest version available on all mirrors. e.g.
abc 0.1 on RStudio and abc 0.2 on RForge, then abc 0.2 from RForge gets
installed/updated.

options(
  repos = c(
    RStudio = "http://cran.rstudio.com/",
    RForge = "http://r-forge.r-project.org",
    Belgium = "http://www.freestatistics.org/cran/",
    CRAN = "http://cran.at.r-project.org/",
    Oxford = "http://www.stats.ox.ac.uk/pub/RWin"
  ),
  install.packages.check.source = "no"
)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-06-19 14:14 GMT+02:00 Sigbert Klinke <sigbert at wiwi.hu-berlin.de>:

> Hi,
>
> we are running in our network a non-public CRAN mirror. I got it working
> with the entry in "Rprofile.site"
>
> local({r <- getOption("repos")
>        r["CRAN"] <- "http://local.cran.server"
>        options(repos=r)
> })
>
> In case that our CRAN mirror does not work we want to send the R/RStudio
> users to a public server. I tried
>
> 1.
> local({r <- getOption("repos")
>        r["CRAN"] <- c("CRAN"="http://local.cran.server", r)
>        options(repos=r)
> })
>
> -> install.packages offered the list of public mirrors
>
> 2.
> local({r <- getOption("repos")
>        r["CRAN"] <- c(r, "CRAN"="http://local.cran.server")
>        options(repos=r)
> })
>
> -> packages are taken from cran.rstudio.com
>
> 3.
> local({r <- getOption("repos")
>        r["CRAN"] <- c(r["CRAN"], "CRAN"="http://local.cran.server",
> r["CRANextra"])
>        options(repos=r)
> })
>
> -> packages are taken from cran.rstudio.com
>
> None of the solutions worked under RStudio, the packages are always
> installed from the public servers. Any ideas?
>
> Thanks Sigbert
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jmtruppia at gmail.com  Fri Jun 19 13:38:23 2015
From: jmtruppia at gmail.com (Juan Manuel Truppia)
Date: Fri, 19 Jun 2015 11:38:23 +0000
Subject: [R] rdde : A package for DDE connections
Message-ID: <CAO2XSvcjvPjHV7Xerp+QXpEeFCL5rP5Ku0jmTkGbzVoQfhhrBA@mail.gmail.com>

Hi all, I'm building a new package for DDE connections on R. It's
called rdde and lives in https <https://bitbucket.org/juancentro/rdde>://
<https://bitbucket.org/juancentro/rdde>bitbucket.org
<https://bitbucket.org/juancentro/rdde>/
<https://bitbucket.org/juancentro/rdde>juancentro
<https://bitbucket.org/juancentro/rdde>/
<https://bitbucket.org/juancentro/rdde>rdde
<https://bitbucket.org/juancentro/rdde>.

It's in alpha stage, but fully operational. It has a very simple vignette
which explains the main reason you should try rdde vs tcltk2 (the only
other option available) : performance.

rdde allows the user to reuse connections (conversations). Establishing a
conversation is the most expensive operation in DDE.

Hope someone finds it useful

Regards

	[[alternative HTML version deleted]]


From topijush at gmail.com  Fri Jun 19 16:02:52 2015
From: topijush at gmail.com (Pijush Das)
Date: Fri, 19 Jun 2015 19:32:52 +0530
Subject: [R] Heatmap.2 error
Message-ID: <CAGa91zhB=ihDUfx68JzupCJ0awWt5naRDHOeWtFwX2pyNKOecQ@mail.gmail.com>

Dear Sir,

Please help me solving the error occurring during the execution of the code
given below.


library("openxlsx")
library(gplots)
library("RColorBrewer")

rix <- read.xlsx(file.choose(), sheet = 1, colNames = TRUE,rowNames = TRUE)
rawdata <- data.matrix(rix)


colors =
c(seq(-2,-0.5,length=100),seq(-0.5,1,length=100),seq(1,2,length=100))
my_palette <- colorRampPalette(c("green", "black", "red"))(n = 299)

 heatmap.2(rawdata, col=my_palette, scale="row",  key=TRUE, symkey=FALSE,
density.info="none", trace="none", cexRow=0.5, Rowv = FALSE, Colv=FALSE,
breaks=colors)


Error in seq.default(min.raw, max.raw, by = min(diff(breaks)/4)) :  invalid
(to - from)/by in seq(.)
In addition: Warning messages:
1: In heatmap.2(rawdata, col = my_palette, scale = "row", key = TRUE,  :
  Using scale="row" or scale="column" when breaks arespecified can produce
unpredictable results.Please consider using only one or the other.
2: In heatmap.2(rawdata, col = my_palette, scale = "row", key = TRUE,  :
  Discrepancy: Rowv is FALSE, while dendrogram is `none'. Omitting row
dendogram.
>

Please find the data set attached with the email.


Thanking you.

Regards
Pijush

From jvadams at usgs.gov  Fri Jun 19 22:41:39 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 19 Jun 2015 15:41:39 -0500
Subject: [R] Heatmap.2 error
In-Reply-To: <CAGa91zhB=ihDUfx68JzupCJ0awWt5naRDHOeWtFwX2pyNKOecQ@mail.gmail.com>
References: <CAGa91zhB=ihDUfx68JzupCJ0awWt5naRDHOeWtFwX2pyNKOecQ@mail.gmail.com>
Message-ID: <CAN5YmCFxTn5vH-pFfCsYyTczG5VW9zbqR-ARiMLuiR05DpeUBA@mail.gmail.com>

Pijush,

The error is a result of you having repeated color values.  The warnings
can be addressed by changing the arguments that you use.  Attachments are
removed from posts to R Help, so I used different data to show you an
example.

Jean


library(gplots)

data(mtcars)
x  <- as.matrix(mtcars[1:6, 3:4])
x[1:3, ] <- -x[1:3, ]

colors1 <- c(seq(-170, 0, 10), seq(0, 370, 10))
my_palette1 <- colorRampPalette(c("green", "black",
"red"))(n=length(colors1)-1)
heatmap.2(x, col=my_palette1, breaks=colors1, symkey=FALSE, density.info
="none",
  trace="none", dendrogram="none")

colors2 <- unique(colors1)
my_palette2 <- colorRampPalette(c("green", "black",
"red"))(n=length(colors2)-1)
heatmap.2(x, col=my_palette2, breaks=colors2, symkey=FALSE, density.info
="none",
  trace="none", dendrogram="none")


On Fri, Jun 19, 2015 at 9:02 AM, Pijush Das <topijush at gmail.com> wrote:

> Dear Sir,
>
> Please help me solving the error occurring during the execution of the code
> given below.
>
>
> library("openxlsx")
> library(gplots)
> library("RColorBrewer")
>
> rix <- read.xlsx(file.choose(), sheet = 1, colNames = TRUE,rowNames = TRUE)
> rawdata <- data.matrix(rix)
>
>
> colors =
> c(seq(-2,-0.5,length=100),seq(-0.5,1,length=100),seq(1,2,length=100))
> my_palette <- colorRampPalette(c("green", "black", "red"))(n = 299)
>
>  heatmap.2(rawdata, col=my_palette, scale="row",  key=TRUE, symkey=FALSE,
> density.info="none", trace="none", cexRow=0.5, Rowv = FALSE, Colv=FALSE,
> breaks=colors)
>
>
> Error in seq.default(min.raw, max.raw, by = min(diff(breaks)/4)) :  invalid
> (to - from)/by in seq(.)
> In addition: Warning messages:
> 1: In heatmap.2(rawdata, col = my_palette, scale = "row", key = TRUE,  :
>   Using scale="row" or scale="column" when breaks arespecified can produce
> unpredictable results.Please consider using only one or the other.
> 2: In heatmap.2(rawdata, col = my_palette, scale = "row", key = TRUE,  :
>   Discrepancy: Rowv is FALSE, while dendrogram is `none'. Omitting row
> dendogram.
> >
>
> Please find the data set attached with the email.
>
>
> Thanking you.
>
> Regards
> Pijush
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From CABondar at cbe.ab.ca  Fri Jun 19 21:59:06 2015
From: CABondar at cbe.ab.ca (Bondar, Cory A)
Date: Fri, 19 Jun 2015 19:59:06 +0000
Subject: [R] desperatly seeking immediate  help
Message-ID: <A3D05CDB272DCD44876E8CB581AD26B1AD7DB22F@S400CBE182.org.cbe.ab.ca>

Hi
I have 2 statistical questions I have to have answered today using r studio and it is not working right. I think I just do not know how to properly code it.

	[[alternative HTML version deleted]]


From pamela.foggia at gmail.com  Fri Jun 19 23:32:59 2015
From: pamela.foggia at gmail.com (Pamela Foggia)
Date: Fri, 19 Jun 2015 23:32:59 +0200
Subject: [R] Help with categorical predicrots in regression models
Message-ID: <CALLwW6GVuMsz3Ha_xtneDKokm4BrF9mrQinv6diPWppHpbEurw@mail.gmail.com>

Hello,
In my regression models (linear and logistic models) I have two predictor
variables, both are categorical variables: DEGREE and REGION.

DEGREE is for educational level, that is an ordinal variable with five
levels (0-LT HIGH SCHOOL, 1-HIGH SCHOOL, 2-JUNIOR COLLEGE, 3-BACHELOR,
4-GRADUATE).

REGION is for the region of the respondent, that is a nominal variable with
9 levels (1-NEW ENGLAND, 2-MIDDLE ATLANTIC, 3-E. NOR. CENTRAL, 4-W. NOR.
CENTRAL, 5-SOUTH ATLANTIC, 6-E. SOU. CENTRAL, 7-W. SOU. CENTRAL, 8-
 MOUNTAIN, 9-PACIFIC).

In many examples I read that, in order to use correctly these predictors as
categorical variables, I have to use before the FACTOR function, for
example in this way

fit1 <- lm(Z ~ factor(X) + factor(Y))
fit2 <- glm(W ~ factor(x) + factor(Y), family=binomial(link="logit"))

obtaining the following output for the logistic regression

                               coef.est coef.se
(Intercept)                 1.027    0.263
factor(DEGREE)1         0.301    0.134
factor(DEGREE)2         0.340    0.211
factor(DEGREE)3         0.748    0.168
factor(DEGREE)4         1.267    0.237
...

where clearly Z is a continuous variable and W is a binary variable. My
question is: as far as the ordinal variable X is concerned, would it be
more correct to use the ORDERED function rather than FACTOR? I mean an
operation like this

fit1 <- lm(Z ~ ordered(X) + factor(Y))
fit2 <- glm(W ~ ordered(x) + factor(Y), family=binomial(link="logit"))

where I obtain a different output like this

                                    coef.est coef.se
(Intercept)                      1.558    0.241
ordered(DEGREE).L           0.942    0.157
ordered(DEGREE).Q          0.215    0.160
ordered(DEGREE).C          0.118    0.111
ordered(DEGREE)^4        -0.106    0.143
...

What do the letters L, Q, C and the power ^4 (which I find in the output)
mean?

Thanks in advance

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sat Jun 20 04:25:34 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 20 Jun 2015 14:25:34 +1200
Subject: [R] desperatly seeking immediate  help
In-Reply-To: <A3D05CDB272DCD44876E8CB581AD26B1AD7DB22F@S400CBE182.org.cbe.ab.ca>
References: <A3D05CDB272DCD44876E8CB581AD26B1AD7DB22F@S400CBE182.org.cbe.ab.ca>
Message-ID: <5584CF1E.5040705@auckland.ac.nz>

On 20/06/15 07:59, Bondar, Cory A wrote:

> Hi I have 2 statistical questions I have to have answered today using
> r studio and it is not working right. I think I just do not know how
> to properly code it.

require(fortunes)
fortune("brain surgery")

cheers,

Rolf Turner

-- Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From dwinsemius at comcast.net  Sat Jun 20 07:05:03 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 19 Jun 2015 22:05:03 -0700
Subject: [R] Help with categorical predicrots in regression models
In-Reply-To: <CALLwW6GVuMsz3Ha_xtneDKokm4BrF9mrQinv6diPWppHpbEurw@mail.gmail.com>
References: <CALLwW6GVuMsz3Ha_xtneDKokm4BrF9mrQinv6diPWppHpbEurw@mail.gmail.com>
Message-ID: <E09836A1-61FB-493A-AE9D-3D7559A6276A@comcast.net>


On Jun 19, 2015, at 2:32 PM, Pamela Foggia wrote:

> Hello,
> In my regression models (linear and logistic models) I have two predictor
> variables, both are categorical variables: DEGREE and REGION.
> 
> DEGREE is for educational level, that is an ordinal variable with five
> levels (0-LT HIGH SCHOOL, 1-HIGH SCHOOL, 2-JUNIOR COLLEGE, 3-BACHELOR,
> 4-GRADUATE).
> 
> REGION is for the region of the respondent, that is a nominal variable with
> 9 levels (1-NEW ENGLAND, 2-MIDDLE ATLANTIC, 3-E. NOR. CENTRAL, 4-W. NOR.
> CENTRAL, 5-SOUTH ATLANTIC, 6-E. SOU. CENTRAL, 7-W. SOU. CENTRAL, 8-
> MOUNTAIN, 9-PACIFIC).
> 
> In many examples I read that, in order to use correctly these predictors as
> categorical variables, I have to use before the FACTOR function,

Please do _not_ capitalize the `factor` function name. R is _not_ SAS.

> for
> example in this way
> 
> fit1 <- lm(Z ~ factor(X) + factor(Y))
> fit2 <- glm(W ~ factor(x) + factor(Y), family=binomial(link="logit"))
> 
> obtaining the following output for the logistic regression
> 
>                               coef.est coef.se
> (Intercept)                 1.027    0.263
> factor(DEGREE)1         0.301    0.134
> factor(DEGREE)2         0.340    0.211
> factor(DEGREE)3         0.748    0.168
> factor(DEGREE)4         1.267    0.237
> ...
> 
> where clearly Z is a continuous variable and W is a binary variable. My

> question is: as far as the ordinal variable X is concerned, would it be
> more correct to use the ORDERED function rather than FACTOR?

That really would depend on the hypotheses under consideration, wouldn't it? 

> I mean an
> operation like this
> 
> fit1 <- lm(Z ~ ordered(X) + factor(Y))
> fit2 <- glm(W ~ ordered(x) + factor(Y), family=binomial(link="logit"))
> 
> where I obtain a different output like this
> 
>                                    coef.est coef.se
> (Intercept)                      1.558    0.241
> ordered(DEGREE).L           0.942    0.157
> ordered(DEGREE).Q          0.215    0.160
> ordered(DEGREE).C          0.118    0.111
> ordered(DEGREE)^4        -0.106    0.143
> ...

Clearly that output does not match the regression call.

> 
> What do the letters L, Q, C and the power ^4 (which I find in the output)
> mean?

The default set of contrasts for an ordered factor are the orthogonal polynomial contrasts of degree (nothing to do with your factor name) n-1 where there are n levels to the factor.

If this doesn't make sense, then you need to do further research to improve your understanding of polynomial contrasts. (They are messy.) You can limit the contrasts to only a linear "degree". You can find further information regarding polynomial contrasts at ?contr.poly and ?C

It's possible that this will be helpful:

DEGREE <- C( DEGREE, poly, 1)  # Only linear contrast
fit2 <- glm(W ~ DEGREE + factor(REGION), family=binomial(link="logit"))

And refrain from then using `ordered` in the formula.

-- 
David.
> 
> Thanks in advance
> 
> 	[[alternative HTML version deleted]]

This is a mailing list that request plain text. It's not hard to do in gmail.

Please read ....

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From eddie.ck.ho at gmail.com  Sat Jun 20 14:00:30 2015
From: eddie.ck.ho at gmail.com (Eddie Ho)
Date: Sat, 20 Jun 2015 22:00:30 +1000
Subject: [R] data.table package problem
Message-ID: <CAMCU_AT8ANBpmNeGjVnjD7u5pXt16c+nnvKe5D=erqLoipU+SA@mail.gmail.com>

Hi all,
  I am new to R and currently learning through a book. Everything works
until I try package "data.table". I am using R3.2.1 and RStudio 0.99.441.
Package "data.table" is version 1.9.4.

 > require(data.table)
Loading required package: data.table data.table 1.9.4
For help type: ?data.table *** NB: by=.EACHI is now explicit. See README to
restore previous behaviour. Warning message: package ?data.table? was built
under R version 3.2.1

  The problem is I can't invoke tables()

> tables()Error in paste("%", nchar(m[1, "NROW"]), "s", sep = "") :
  4 arguments passed to .Internal(nchar) which requires 3


   or setkey

> setkey(theDT, D)Error in setkeyv(x, cols, verbose = verbose, physical = physical) :
  4 arguments passed to .Internal(nchar) which requires 3


   Would you please help me to investigate what's wrong with my
installation?

Thanks,
Eddie

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Jun 20 18:52:37 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 20 Jun 2015 09:52:37 -0700
Subject: [R] data.table package problem
In-Reply-To: <CAMCU_AT8ANBpmNeGjVnjD7u5pXt16c+nnvKe5D=erqLoipU+SA@mail.gmail.com>
References: <CAMCU_AT8ANBpmNeGjVnjD7u5pXt16c+nnvKe5D=erqLoipU+SA@mail.gmail.com>
Message-ID: <04BE1E2E-5969-43DA-8073-30DE6BA474C5@comcast.net>


On Jun 20, 2015, at 5:00 AM, Eddie Ho wrote:

> Hi all,
>  I am new to R and currently learning through a book. Everything works
> until I try package "data.table". I am using R3.2.1 and RStudio 0.99.441.
> Package "data.table" is version 1.9.4.
> 
>> require(data.table)
> Loading required package: data.table data.table 1.9.4
> For help type: ?data.table *** NB: by=.EACHI is now explicit. See README to
> restore previous behaviour. Warning message: package ?data.table? was built
> under R version 3.2.1
> 
>  The problem is I can't invoke tables()
> 

I'm unable to reproduce on a Mac(Yosemite) with data.table 1.9.4
>> tables()Error in paste("%", nchar(m[1, "NROW"]), "s", sep = "") :
>  4 arguments passed to .Internal(nchar) which requires 3

I don't really know the answer, but there was also an error related to an installation of pkg:forecast that was posted on SO today that has a similar error message about the number of arguments passed to nchar, but that questioner was on version 3.2.0.

http://stackoverflow.com/questions/30955508/r-cannot-load-package-forecast-due-to-namespace-error

I see in the news() that nchar was given a new argument in version 3.2.1 and you got a warning when loading data.table, so I wonder if you may not really have 3.2.1 installed, since you got that warning.

new$Text[ grep("nchar", news$Text) ]

You should post the results of sessionInfo().

-- 
David.


> 
> 
>   or setkey
> 
>> setkey(theDT, D)Error in setkeyv(x, cols, verbose = verbose, physical = physical) :
>  4 arguments passed to .Internal(nchar) which requires 3
> 
> 
>   Would you please help me to investigate what's wrong with my
> installation?
> 
> Thanks,
> Eddie
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From amy_valach at swissonline.ch  Sun Jun 21 00:04:45 2015
From: amy_valach at swissonline.ch (amyv)
Date: Sat, 20 Jun 2015 15:04:45 -0700 (PDT)
Subject: [R] Manipulating text and linear regression in openair scatterPlot
 function
Message-ID: <1434837885774-4708893.post@n4.nabble.com>

Hi all,

I'm working with the openair package scatterPlot function and am trying to
change/add/remove the line text of the linear regression, e.g. change the
font size, split it into 2 rows, just show the equation OR the R^2 value or
even remove both but leave the linear regression line.

Simple example:

scatterPlot(data, x, y, linear = TRUE)

#I can change the font size using:

scatterPlot(data, x, y, linear = TRUE,
par.settings=list(fontsize=list(text=18)))

I would be really grateful if someone could point me in the right direction.
Thanks!

Amy



--
View this message in context: http://r.789695.n4.nabble.com/Manipulating-text-and-linear-regression-in-openair-scatterPlot-function-tp4708893.html
Sent from the R help mailing list archive at Nabble.com.


From tanasa at gmail.com  Sun Jun 21 02:18:51 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Sat, 20 Jun 2015 17:18:51 -0700
Subject: [R] sorting a dataframe
Message-ID: <CA+JEM03ZJQjBbNe-_-+HxU9nN--v0tTxrHFmB4CrcsYvU2JWtA@mail.gmail.com>

Dear all,

I am looking for a suggestion please regarding sorting a dataframe with
alphanumerical components :

let's assume we have :

A = c("A1","A10","A11","A2")
B = c(1,2,3,4)

C = data.frame(A,B)

how could I sort C data.frame in such a way that we have at the end :

C$A in the order : "A1", "A2", "A10", "A11". thank you very much,

-- bogdan

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Jun 21 03:15:40 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 20 Jun 2015 18:15:40 -0700
Subject: [R] sorting a dataframe
In-Reply-To: <CA+JEM03ZJQjBbNe-_-+HxU9nN--v0tTxrHFmB4CrcsYvU2JWtA@mail.gmail.com>
References: <CA+JEM03ZJQjBbNe-_-+HxU9nN--v0tTxrHFmB4CrcsYvU2JWtA@mail.gmail.com>
Message-ID: <5C52CDFE-C43A-496A-BDA0-66416B217338@comcast.net>


On Jun 20, 2015, at 5:18 PM, Bogdan Tanasa wrote:

> Dear all,
> 
> I am looking for a suggestion please regarding sorting a dataframe with
> alphanumerical components :
> 
> let's assume we have :
> 
> A = c("A1","A10","A11","A2")
> B = c(1,2,3,4)
> 
> C = data.frame(A,B)
> 
> how could I sort C data.frame in such a way that we have at the end :
> 
> C$A in the order : "A1", "A2", "A10", "A11". thank you very much,

Do a search on `mixedorder` and` mixedsort`. They are function names in pkg:gtools

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun Jun 21 03:27:52 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 20 Jun 2015 18:27:52 -0700
Subject: [R] Manipulating text and linear regression in openair
	scatterPlot function
In-Reply-To: <1434837885774-4708893.post@n4.nabble.com>
References: <1434837885774-4708893.post@n4.nabble.com>
Message-ID: <0D055927-5013-4B59-B8F8-0CEB1D0E4522@comcast.net>


On Jun 20, 2015, at 3:04 PM, amyv wrote:

> Hi all,
> 
> I'm working with the openair package scatterPlot function and am trying to
> change/add/remove the line text of the linear regression, e.g. change the
> font size, split it into 2 rows, just show the equation OR the R^2 value or
> even remove both but leave the linear regression line.
> 
> Simple example:
> 
> scatterPlot(data, x, y, linear = TRUE)
> 
> #I can change the font size using:
> 
> scatterPlot(data, x, y, linear = TRUE,
> par.settings=list(fontsize=list(text=18)))

What "equation" or "text" are you seeing? Split? .... split what? There no 'data'-object in your posting and when I use the first example in the help page for ?scatterPlot I see nothing that matches up with you request.


> 
> I would be really grateful if someone could point me in the right direction.

And we would be grateful if you would post a question that made sense. Please read this material and do read about this mailing list, rather than persisting in the delusion that Nabble is the Rhelp mailing list.
========
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
++++++++

David Winsemius
Alameda, CA, USA


From tanasa at gmail.com  Sun Jun 21 03:33:25 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Sat, 20 Jun 2015 18:33:25 -0700
Subject: [R] sorting a dataframe
In-Reply-To: <5C52CDFE-C43A-496A-BDA0-66416B217338@comcast.net>
References: <CA+JEM03ZJQjBbNe-_-+HxU9nN--v0tTxrHFmB4CrcsYvU2JWtA@mail.gmail.com>
	<5C52CDFE-C43A-496A-BDA0-66416B217338@comcast.net>
Message-ID: <CA+JEM03BAUSDRq6ZyRZR2K7d-LFLsKNJY7Rc_tfZsSmdo0L-FA@mail.gmail.com>

thank you all, it is working fine. happy weekend ;) !

On Sat, Jun 20, 2015 at 6:15 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Jun 20, 2015, at 5:18 PM, Bogdan Tanasa wrote:
>
> > Dear all,
> >
> > I am looking for a suggestion please regarding sorting a dataframe with
> > alphanumerical components :
> >
> > let's assume we have :
> >
> > A = c("A1","A10","A11","A2")
> > B = c(1,2,3,4)
> >
> > C = data.frame(A,B)
> >
> > how could I sort C data.frame in such a way that we have at the end :
> >
> > C$A in the order : "A1", "A2", "A10", "A11". thank you very much,
>
> Do a search on `mixedorder` and` mixedsort`. They are function names in
> pkg:gtools
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From eddie.ck.ho at gmail.com  Sun Jun 21 04:46:41 2015
From: eddie.ck.ho at gmail.com (Eddie Ho)
Date: Sun, 21 Jun 2015 12:46:41 +1000
Subject: [R] data.table package problem
In-Reply-To: <04BE1E2E-5969-43DA-8073-30DE6BA474C5@comcast.net>
References: <CAMCU_AT8ANBpmNeGjVnjD7u5pXt16c+nnvKe5D=erqLoipU+SA@mail.gmail.com>
	<04BE1E2E-5969-43DA-8073-30DE6BA474C5@comcast.net>
Message-ID: <CAMCU_ATCnU+tD=9kgztwbxq4vwtmc_5bdF6zN08=Wu_63+=0Fw@mail.gmail.com>

Hi David,
   Thanks a lot, you saved my day. I installed R 3.2.0 on 7th June and then
installed package data.table on 20th June. When I installed data.table, it
downloaded "data.table" built under R 3.2.1. After I upgraded R to 3.2.1,
data.table is working now.

Regards,
Eddie

On Sun, Jun 21, 2015 at 2:52 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Jun 20, 2015, at 5:00 AM, Eddie Ho wrote:
>
> > Hi all,
> >  I am new to R and currently learning through a book. Everything works
> > until I try package "data.table". I am using R3.2.1 and RStudio 0.99.441.
> > Package "data.table" is version 1.9.4.
> >
> >> require(data.table)
> > Loading required package: data.table data.table 1.9.4
> > For help type: ?data.table *** NB: by=.EACHI is now explicit. See README
> to
> > restore previous behaviour. Warning message: package ?data.table? was
> built
> > under R version 3.2.1
> >
> >  The problem is I can't invoke tables()
> >
>
> I'm unable to reproduce on a Mac(Yosemite) with data.table 1.9.4
> >> tables()Error in paste("%", nchar(m[1, "NROW"]), "s", sep = "") :
> >  4 arguments passed to .Internal(nchar) which requires 3
>
> I don't really know the answer, but there was also an error related to an
> installation of pkg:forecast that was posted on SO today that has a similar
> error message about the number of arguments passed to nchar, but that
> questioner was on version 3.2.0.
>
>
> http://stackoverflow.com/questions/30955508/r-cannot-load-package-forecast-due-to-namespace-error
>
> I see in the news() that nchar was given a new argument in version 3.2.1
> and you got a warning when loading data.table, so I wonder if you may not
> really have 3.2.1 installed, since you got that warning.
>
> new$Text[ grep("nchar", news$Text) ]
>
> You should post the results of sessionInfo().
>
> --
> David.
>
>
> >
> >
> >   or setkey
> >
> >> setkey(theDT, D)Error in setkeyv(x, cols, verbose = verbose, physical =
> physical) :
> >  4 arguments passed to .Internal(nchar) which requires 3
> >
> >
> >   Would you please help me to investigate what's wrong with my
> > installation?
> >
> > Thanks,
> > Eddie
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Jun 21 07:10:38 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 21 Jun 2015 15:10:38 +1000
Subject: [R] Manipulating text and linear regression in openair
 scatterPlot function
In-Reply-To: <0D055927-5013-4B59-B8F8-0CEB1D0E4522@comcast.net>
References: <1434837885774-4708893.post@n4.nabble.com>
	<0D055927-5013-4B59-B8F8-0CEB1D0E4522@comcast.net>
Message-ID: <CA+8X3fVC4c8Nap81Dm2P61Vvm_D=YjNF6jP6ADd0F0U1smetsw@mail.gmail.com>

Hi Amy,
The line at the top of the plot is formatted and displayed somewhere
In the 700+ lines of the scatterPlot code. I was unable to find where
that is, so the best option is to email the maintainer of the package:

david.carslaw at york.ac.uk

Jim


On Sun, Jun 21, 2015 at 11:27 AM, David Winsemius
<dwinsemius at comcast.net> wrote:
>
> On Jun 20, 2015, at 3:04 PM, amyv wrote:
>
>> Hi all,
>>
>> I'm working with the openair package scatterPlot function and am trying to
>> change/add/remove the line text of the linear regression, e.g. change the
>> font size, split it into 2 rows, just show the equation OR the R^2 value or
>> even remove both but leave the linear regression line.
>>
>> Simple example:
>>
>> scatterPlot(data, x, y, linear = TRUE)
>>
>> #I can change the font size using:
>>
>> scatterPlot(data, x, y, linear = TRUE,
>> par.settings=list(fontsize=list(text=18)))
>
> What "equation" or "text" are you seeing? Split? .... split what? There no 'data'-object in your posting and when I use the first example in the help page for ?scatterPlot I see nothing that matches up with you request.
>
>
>>
>> I would be really grateful if someone could point me in the right direction.
>
> And we would be grateful if you would post a question that made sense. Please read this material and do read about this mailing list, rather than persisting in the delusion that Nabble is the Rhelp mailing list.
> ========
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ++++++++
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From d.miro1089 at gmail.com  Sun Jun 21 03:29:15 2015
From: d.miro1089 at gmail.com (Diego Miro)
Date: Sat, 20 Jun 2015 22:29:15 -0300
Subject: [R] sorting a dataframe
In-Reply-To: <CA+JEM03ZJQjBbNe-_-+HxU9nN--v0tTxrHFmB4CrcsYvU2JWtA@mail.gmail.com>
References: <CA+JEM03ZJQjBbNe-_-+HxU9nN--v0tTxrHFmB4CrcsYvU2JWtA@mail.gmail.com>
Message-ID: <CAKZ33Q99FU2cf+wYUpWwv4jXuuft87FQtX=uK9TdavnN9rAP9g@mail.gmail.com>

Bogdan,

Follow my suggestion.

letter <- substring(A, 1, 1)
number <- substring(A, 2, nchar(A))
new.data <- paste0(letter, formatC(as.numeric(number), width = 2, flag =
"0"))
Em 20/06/2015 21:21, "Bogdan Tanasa" <tanasa at gmail.com> escreveu:

> Dear all,
>
> I am looking for a suggestion please regarding sorting a dataframe with
> alphanumerical components :
>
> let's assume we have :
>
> A = c("A1","A10","A11","A2")
> B = c(1,2,3,4)
>
> C = data.frame(A,B)
>
> how could I sort C data.frame in such a way that we have at the end :
>
> C$A in the order : "A1", "A2", "A10", "A11". thank you very much,
>
> -- bogdan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Jun 21 19:52:55 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 21 Jun 2015 10:52:55 -0700
Subject: [R] sorting a dataframe
In-Reply-To: <CAKZ33Q99FU2cf+wYUpWwv4jXuuft87FQtX=uK9TdavnN9rAP9g@mail.gmail.com>
References: <CA+JEM03ZJQjBbNe-_-+HxU9nN--v0tTxrHFmB4CrcsYvU2JWtA@mail.gmail.com>
	<CAKZ33Q99FU2cf+wYUpWwv4jXuuft87FQtX=uK9TdavnN9rAP9g@mail.gmail.com>
Message-ID: <CAGxFJbRcr0cw5GPf9s7gr3yss7y3dDsXp93msR9zTUF+ici6sQ@mail.gmail.com>

Diego:

Nonsense! Look at the results of your code -- you have failed to order
the results as had been requested by the OP. It's also unnecessarily
complicated. The following suffices (where I have used regular
expressions rather substring() to get the numeric part of the strings
-- **assuming** that the strings always consist of letters followed by
numeric digits).

> A = c("A1","A10","A11","A2")
>  B = c(1,2,3,4)
>  dat = data.frame(A,B)
>
> numbs <- as.numeric(gsub("[^[:digit:]]+","",dat$A))
> newdat <- dat[order(numbs),]
> newdat
    A B
1  A1 1
4  A2 4
2 A10 2
3 A11 3

Cheers,
Bert



Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sat, Jun 20, 2015 at 6:29 PM, Diego Miro <d.miro1089 at gmail.com> wrote:
> Bogdan,
>
> Follow my suggestion.
>
> letter <- substring(A, 1, 1)
> number <- substring(A, 2, nchar(A))
> new.data <- paste0(letter, formatC(as.numeric(number), width = 2, flag =
> "0"))
> Em 20/06/2015 21:21, "Bogdan Tanasa" <tanasa at gmail.com> escreveu:
>
>> Dear all,
>>
>> I am looking for a suggestion please regarding sorting a dataframe with
>> alphanumerical components :
>>
>> let's assume we have :
>>
>> A = c("A1","A10","A11","A2")
>> B = c(1,2,3,4)
>>
>> C = data.frame(A,B)
>>
>> how could I sort C data.frame in such a way that we have at the end :
>>
>> C$A in the order : "A1", "A2", "A10", "A11". thank you very much,
>>
>> -- bogdan
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tanasa at gmail.com  Sun Jun 21 20:03:49 2015
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Sun, 21 Jun 2015 11:03:49 -0700
Subject: [R] sorting a dataframe
In-Reply-To: <CAGxFJbRcr0cw5GPf9s7gr3yss7y3dDsXp93msR9zTUF+ici6sQ@mail.gmail.com>
References: <CA+JEM03ZJQjBbNe-_-+HxU9nN--v0tTxrHFmB4CrcsYvU2JWtA@mail.gmail.com>
	<CAKZ33Q99FU2cf+wYUpWwv4jXuuft87FQtX=uK9TdavnN9rAP9g@mail.gmail.com>
	<CAGxFJbRcr0cw5GPf9s7gr3yss7y3dDsXp93msR9zTUF+ici6sQ@mail.gmail.com>
Message-ID: <CA+JEM02YCa_FadJ9BjzRyrnpYAXo7GZv_1MxwGn-A5pU_bVM+w@mail.gmail.com>

Thank you all again. It works with :

library("gtools")
dat[mixedorder(A),]

considering :

A = c("A1","A10","A11","A2")
B = c(1,2,3,4)
 dat = data.frame(A,B


On Sun, Jun 21, 2015 at 10:52 AM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> Diego:
>
> Nonsense! Look at the results of your code -- you have failed to order
> the results as had been requested by the OP. It's also unnecessarily
> complicated. The following suffices (where I have used regular
> expressions rather substring() to get the numeric part of the strings
> -- **assuming** that the strings always consist of letters followed by
> numeric digits).
>
> > A = c("A1","A10","A11","A2")
> >  B = c(1,2,3,4)
> >  dat = data.frame(A,B)
> >
> > numbs <- as.numeric(gsub("[^[:digit:]]+","",dat$A))
> > newdat <- dat[order(numbs),]
> > newdat
>     A B
> 1  A1 1
> 4  A2 4
> 2 A10 2
> 3 A11 3
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
>
>
> On Sat, Jun 20, 2015 at 6:29 PM, Diego Miro <d.miro1089 at gmail.com> wrote:
> > Bogdan,
> >
> > Follow my suggestion.
> >
> > letter <- substring(A, 1, 1)
> > number <- substring(A, 2, nchar(A))
> > new.data <- paste0(letter, formatC(as.numeric(number), width = 2, flag =
> > "0"))
> > Em 20/06/2015 21:21, "Bogdan Tanasa" <tanasa at gmail.com> escreveu:
> >
> >> Dear all,
> >>
> >> I am looking for a suggestion please regarding sorting a dataframe with
> >> alphanumerical components :
> >>
> >> let's assume we have :
> >>
> >> A = c("A1","A10","A11","A2")
> >> B = c(1,2,3,4)
> >>
> >> C = data.frame(A,B)
> >>
> >> how could I sort C data.frame in such a way that we have at the end :
> >>
> >> C$A in the order : "A1", "A2", "A10", "A11". thank you very much,
> >>
> >> -- bogdan
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From aragorn168b at gmail.com  Sun Jun 21 20:55:10 2015
From: aragorn168b at gmail.com (Arunkumar Srinivasan)
Date: Sun, 21 Jun 2015 20:55:10 +0200
Subject: [R] more complex by with data.table???
In-Reply-To: <CA+vqiLFuAKF+y_skZLZbgx84JmEJL-xvUVj_TAgAyQga1EcMgg@mail.gmail.com>
References: <C7338A7EFF31BB4D831BB06C00887789B2F91594@MBX023-W1-CA-2.exch023.domain.local>
	<CA+vqiLFuAKF+y_skZLZbgx84JmEJL-xvUVj_TAgAyQga1EcMgg@mail.gmail.com>
Message-ID: <CAAf756OFb6bHt0enjbEETJbBxJQHyRUW=n=SLR6hzFiij2GUNA@mail.gmail.com>

Ramiro,

`dt[, lapply(.SD, mean), by=name]` is the idiomatic way.

I suggest reading through the new HTML vignettes at
https://github.com/Rdatatable/data.table/wiki/Getting-started

Ista, thanks for linking to the new vignette.


On Wed, Jun 10, 2015 at 2:17 AM, Ista Zahn <istazahn at gmail.com> wrote:
> Hi Ramiro,
>
> There is a demonstration of this on the data.table wiki at
> https://rawgit.com/wiki/Rdatatable/data.table/vignettes/datatable-intro-vignette.html.
> You can do
>
> dt[, lapply(.SD, mean), by=name]
>
> or
>
> dt[, as.list(colMeans(.SD)), by=name]
>
> BTW, there are pretty straightforward ways to do this in base R as well, e.g,
>
> data.frame(t(sapply(split(df[-1], df$name), colMeans)))
>
> Best,
> Ista
>
> On Tue, Jun 9, 2015 at 4:22 PM, Ramiro Barrantes
> <ramiro at precisionbioassay.com> wrote:
>> Hello,
>>
>> I am trying to do something that I am able to do with the "by" function within data.frame but can't figure out how to achieve with data.table.
>>
>> Consider
>>
>> dt<-data.table(name=c(rep("a",5),rep("b",6)),var1=0:10,var2=20:30,var3=40:50)
>> myFunction <- function(x) { mean(x) }
>>
>> I am aware that I can do something like:
>>
>> dt[, .(meanVar1=myFunction(var1)) ,by=.(name)]
>>
>> but how could I do the equivalent of:
>>
>> df<-data.frame(name=c(rep("a",5),rep("b",6)),var1=0:10,var2=20:30,var3=40:50)
>> myFunction <- function(x) { mean(x) }
>>
>> columnNames <- c("var1","var2","var3")
>> result <- by(df, df$name, function(x) {
>>    output <- c()
>>    for(col in columnNames) {
>>      output[col] <- myFunction(x[,col])
>>    }
>>   output
>> })
>> do.call(rbind,result)
>>
>> Thanks in advance,
>> Ramiro
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wujuan22 at gmail.com  Sun Jun 21 21:15:36 2015
From: wujuan22 at gmail.com (Juan Wu)
Date: Sun, 21 Jun 2015 15:15:36 -0400
Subject: [R] two problems
Message-ID: <CAKeKpMM_Ei_UsMZiCk50fmT8TfHGgc6udZhbcsYj6oj_xc7Jgw@mail.gmail.com>

Hi, list experts

I am totally a new user of the R package. I just tried to use qcomhd, but
it gives me an error alarm, as below.

qcomhd(RT1, RT2, q = seq(.1, .9, by=.1))
Error: could not find function "qcomhd"

Then I try to install it, however, it seems that I am not able to install
it. Also, in my screen, some chaos characters appear. I do not know the
reason.

> install.packages("qcomhd")
Installing package into
?:/Users/kh645-admin/Documents/R/win-library/3.1?(as ?ib?is unspecified)
Warning in install.packages :
  package ?comhd?is not available (for R version 3.1.2)

A second question is to closely follow this thread *[R] Vincentizing
Reaction Time data in R*

Gabriel, have you find a good solution for your searching? I am also
interested in the vincentizing RT method. Either in R or Matlab would be
okay for me.

Thanks in advance,
J

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Jun 21 23:30:31 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 21 Jun 2015 14:30:31 -0700
Subject: [R] two problems
In-Reply-To: <CAKeKpMM_Ei_UsMZiCk50fmT8TfHGgc6udZhbcsYj6oj_xc7Jgw@mail.gmail.com>
References: <CAKeKpMM_Ei_UsMZiCk50fmT8TfHGgc6udZhbcsYj6oj_xc7Jgw@mail.gmail.com>
Message-ID: <94CDD6D7-E1E0-4D1A-B2F9-4E871AE5933B@dcn.davis.CA.us>

I an not aware of any function or package named qcomhd in base R or in the CRAN contributed packages, nor did it turn up when I went searching for it there, so your failure to access it seems unsurprising.

Google does find some references to a Github package called WRS that supposedly contains such a function, but the reason given for not distributing it on CRAN is simply that the package does not contain full documentation. This rather pathetic excuse points out that such a package is likely to be very unhelpful for any new user of R. I would suggest that you learn a bit more about using R before diving into such murky waters, but if you want to push forward you will need to use a search engine and perhaps make email contact with the package author if you need help.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 21, 2015 12:15:36 PM PDT, Juan Wu <wujuan22 at gmail.com> wrote:
>Hi, list experts
>
>I am totally a new user of the R package. I just tried to use qcomhd,
>but
>it gives me an error alarm, as below.
>
>qcomhd(RT1, RT2, q = seq(.1, .9, by=.1))
>Error: could not find function "qcomhd"
>
>Then I try to install it, however, it seems that I am not able to
>install
>it. Also, in my screen, some chaos characters appear. I do not know the
>reason.
>
>> install.packages("qcomhd")
>Installing package into
>?:/Users/kh645-admin/Documents/R/win-library/3.1?(as ?ib?is
>unspecified)
>Warning in install.packages :
>  package ?comhd?is not available (for R version 3.1.2)
>
>A second question is to closely follow this thread *[R] Vincentizing
>Reaction Time data in R*
>
>Gabriel, have you find a good solution for your searching? I am also
>interested in the vincentizing RT method. Either in R or Matlab would
>be
>okay for me.
>
>Thanks in advance,
>J
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From oluola2011 at yahoo.com  Mon Jun 22 04:29:47 2015
From: oluola2011 at yahoo.com (Olu Ola)
Date: Sun, 21 Jun 2015 19:29:47 -0700
Subject: [R] Obtaining the Hessian for the last iteration of a BFGS in optimx
Message-ID: <1434940187.73323.YahooMailBasic@web161604.mail.bf1.yahoo.com>

Hello,
I am running a BFGS using optimx and would like to obtain the Hessian for the last iteration.

How can I go about this?

Thank you


From bob at rudis.net  Tue Jun 16 12:40:49 2015
From: bob at rudis.net (boB Rudis)
Date: Tue, 16 Jun 2015 06:40:49 -0400
Subject: [R] [R-pkgs] Version 0.8.5 of metricsgraphics is on CRAN
Message-ID: <CAJ4QxaMg5_rHUf5s26O9V5G14OgzEBSHPaca5y-EZVA1bqq5aA@mail.gmail.com>

Version 0.8.5 of metricsgraphics is now on CRAN.

It provides an 'htmlwidgets' interface to the 'MetricsGraphics.js'
('D3'-based) charting
library which is geared towards displaying time-series data. There are
routines for scatterplots, histograms and even 'grid.arrange'-like
functionality for laying out multiple charts.

-Bob

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From mylisttech at gmail.com  Mon Jun 22 12:41:51 2015
From: mylisttech at gmail.com (My List)
Date: Mon, 22 Jun 2015 16:11:51 +0530
Subject: [R] CHAID Usage in R
Message-ID: <CAFpdVnyP_xbcr4nwQRD6435qKQYmGa4b8axr9od7gU_Dh6GsXg@mail.gmail.com>

All:

I am trying to implement CHAID decision tree. Can anyone please help me to
know which package can be used for it or lead me to the documentation to
the same.

I did read a web page says that only the source for the CHAID package is
available. Kindly,advice on the package to be used.

Thanks in advance,
Harmeet

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Mon Jun 22 13:00:05 2015
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 22 Jun 2015 13:00:05 +0200 (CEST)
Subject: [R] CHAID Usage in R
In-Reply-To: <CAFpdVnyP_xbcr4nwQRD6435qKQYmGa4b8axr9od7gU_Dh6GsXg@mail.gmail.com>
References: <CAFpdVnyP_xbcr4nwQRD6435qKQYmGa4b8axr9od7gU_Dh6GsXg@mail.gmail.com>
Message-ID: <alpine.DEB.2.11.1506221254270.8383@paninaro.uibk.ac.at>

On Mon, 22 Jun 2015, My List wrote:

> All:
>
> I am trying to implement CHAID decision tree. Can anyone please help me to
> know which package can be used for it or lead me to the documentation to
> the same.

A CHAID implementation is available on R-Forge at:
https://R-Forge.R-project.org/R/?group_id=343

In recent versions of R you should be able to install the package from 
within R via: install.packages("CHAID", repos="http://R-Forge.R-project.org")

The package contains manual pages.

As an alternative to CHAID you might want to use some more recently 
developed statistical algorithms for classification trees, see e.g.,
http://CRAN.R-project.org/view=MachineLearning

In particular, the ctree() function from package "partykit" is based on 
similar ideas but is more flexible with respect to the distribution of 
dependent and explanatory variables.

> I did read a web page says that only the source for the CHAID package is
> available. Kindly,advice on the package to be used.
>
> Thanks in advance,
> Harmeet
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dom1jaski at gmail.com  Mon Jun 22 07:20:44 2015
From: dom1jaski at gmail.com (Dominik Jaskierniak)
Date: Mon, 22 Jun 2015 15:20:44 +1000
Subject: [R] gen.inits error for non-linear hierarchical model using
	R2winBUGS
Message-ID: <CAPPhAkE=_h=ZrT1NuokuSR0a3AQMnHxnOoNK15epBb6+52PCMw@mail.gmail.com>

Hi,


I am relatively new to Bayesian statistics and am trying to apply a
non-linear hierarchical model using R2winBUGS on some tree stocking density
data. I am hoping someone may be able to help me find the reason why
R2winBUGS is giving me the following error:


*gen.inits cannot be executed (is greyed out)*


Even though I get this error, the code still produces output. For
parameters that converge, the model produces output that seem reasonable
but there are two parameters (mean_N0 sigma_N0 in below code) that are not
mixing well (not converging) when I use two chains.   The chains seem to
start around the initial value (i.e. mean_N0 starts at 4800.5 and 4799.5,
whereas sigma_N0 starts at 800.5 and 799.5) but don?t move far from those
values. The mean values for both parameters are about 0.5 off from the
initial values set. I am not sure whether the above error is causing this
convergence problem.


I have exhausted my investigations into this problem and am now hoping
someone may be able to see what is causing my problem in the below winBUGS
or R code.  I would greatly appreciate your time if you could help.


Kind Regards


Dom Jaskierniak



WINBUGS CODE

  model {

    ## loop over data for likelihood

    for(i in 1:Ntotal){

      N[i] <- log(N0[P_ID_Bug[i]] - 25)-(Age[i]/(Beta_0 + Beta_1*Age[i]))  #
LogSDen_Ha ~ log(N0 - 25)-(Age/(Beta_0 + Beta_1*Age))

      Y[i] ~ dnorm(N[i],tauY)

    }

    tauY ~ dgamma(1.0E-3, 1.0E-3)

    Beta_0 ~ dnorm(9,0.25)

    Beta_1 ~ dnorm(0.16,400)



## hierarchical model for each Plots intercept & slope

    for (p in 1:P_ID_Length) {

                N0[p] ~ dgamma(r_N0, lambda_N0)

    }

    mean_N0 ~ dnorm(5000,1.0E-6)

    sigma_N0 ~ dnorm(5000,0.25E-6)

    lambda_N0 <- mean_N0/(sigma_N0*sigma_N0)

    r_N0 <- mean_N0 * lambda_N0

  }



R CODE



data <- list(P_ID_Length = length(P_ID),

             P_ID_Bug = P_ID_Bug,

             Age=Grouped_SDen$Age,

             Y =Grouped_SDen$LogSDen_Ha,

             Ntotal=nrow(Grouped_SDen))



inits1 <- list(N0= rep(coef(NLS_SDen_Log_1)[[1]], P_ID_Length),

     Beta_0 = coef(NLS_SDen_Log_1)[[2]],

     Beta_1 = coef(NLS_SDen_Log_1)[[3]],

     tauY = 20,

     mean_N0 = 4800,

     sigma_N0 = 800

    )



inits2 <- list(N0= rep(coef(NLS_SDen_Log_1)[[1]], P_ID_Length),

     Beta_0 = coef(NLS_SDen_Log_1)[[2]],

     Beta_1 = coef(NLS_SDen_Log_1)[[3]],

     tauY = 20,

     mean_N0 = 4800,

     sigma_N0 = 800

    )

inits <- list(inits1, inits2)

parameters <- c("N0", "Beta_0", "Beta_1", "tauY", "mean_N0", "sigma_N0")

sims <- bugs(model.file=
"C:/WS/Post-Doc/TINNR/PAPER_4_WinBugs/Stocking_Growth.bug",

             data = data,

             parameters = parameters,

             inits = inits,

             n.chains = 2,

             n.iter = 1000,

             n.burnin = 500,

             n.thin = 2,

             debug=TRUE,

             bugs.directory = "C:/Program Files/WinBUGS14/")

	[[alternative HTML version deleted]]


From AshokVarma.Nadakuduti at cognizant.com  Mon Jun 22 07:54:25 2015
From: AshokVarma.Nadakuduti at cognizant.com (AshokVarma.Nadakuduti at cognizant.com)
Date: Mon, 22 Jun 2015 05:54:25 +0000
Subject: [R] issue in running timeseries forecasting related package
Message-ID: <EAA865A6DDBB6C4FB20A175EBAA53BBC17CCF3FF@CTSINCHNSXMBM.cts.com>

Hi,


I am trying to run packages timeseries, forecast, xts packages to execute some task. I was using this R-console for 8months. I had never faced any issue. Now, It's throwing an error saying 'Error: could not find function "forecast" Similarly for other packages as well. Could you please share any info that could solve this issue.



Thanks,

Ashok



This e-mail and any files transmitted with it are for the sole use of the intended recipient(s) and may contain confidential and privileged information. If you are not the intended recipient(s), please reply to the sender and destroy all copies of the original message. Any unauthorized review, use, disclosure, dissemination, forwarding, printing or copying of this email, and/or any action taken in reliance on the contents of this e-mail is strictly prohibited and may be unlawful. Where permitted by applicable law, this e-mail and other e-mail communications sent to and from Cognizant e-mail addresses may be monitored.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Jun 22 15:33:49 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 22 Jun 2015 13:33:49 +0000
Subject: [R] issue in running timeseries forecasting related package
In-Reply-To: <EAA865A6DDBB6C4FB20A175EBAA53BBC17CCF3FF@CTSINCHNSXMBM.cts.com>
References: <EAA865A6DDBB6C4FB20A175EBAA53BBC17CCF3FF@CTSINCHNSXMBM.cts.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C31BD5@SRVEXCHMBX.precheza.cz>

Hi

Please some aditional info:

version

sessionInfo()

Did you install new packages/R version?

Did you load the package by library(xts)?

And preferably no HTML post.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> AshokVarma.Nadakuduti at cognizant.com
> Sent: Monday, June 22, 2015 7:54 AM
> To: r-help at r-project.org
> Subject: [R] issue in running timeseries forecasting related package
>
> Hi,
>
>
> I am trying to run packages timeseries, forecast, xts packages to
> execute some task. I was using this R-console for 8months. I had never
> faced any issue. Now, It's throwing an error saying 'Error: could not
> find function "forecast" Similarly for other packages as well. Could
> you please share any info that could solve this issue.
>
>
>
> Thanks,
>
> Ashok
>
>
>
> This e-mail and any files transmitted with it are for the sole use of
> the intended recipient(s) and may contain confidential and privileged
> information. If you are not the intended recipient(s), please reply to
> the sender and destroy all copies of the original message. Any
> unauthorized review, use, disclosure, dissemination, forwarding,
> printing or copying of this email, and/or any action taken in reliance
> on the contents of this e-mail is strictly prohibited and may be
> unlawful. Where permitted by applicable law, this e-mail and other e-
> mail communications sent to and from Cognizant e-mail addresses may be
> monitored.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Mohan.Radhakrishnan at cognizant.com  Mon Jun 22 14:23:14 2015
From: Mohan.Radhakrishnan at cognizant.com (Mohan.Radhakrishnan at cognizant.com)
Date: Mon, 22 Jun 2015 12:23:14 +0000
Subject: [R] Simple monte carlo
Message-ID: <E1B160F4999FD6449524E16C2CB94E030772A517@CTSINCHNSXMBE.cts.com>

Hi,
       I am a developer and I code 'R'. We have some project tasks and durations(Expected, 50% - Average Case and 90% - Worst Case ) and I am trying to understand how a simulation of this using monte carlo would help. Most of the websites deal with either the math or some commercial package. I don't want to use Excel because I use Eclipse StatET environment.

What kind of distribution should I use ? Is there a simpler explanation of a practical schedule distribution calculation ?

Thanks,
Mohan
This e-mail and any files transmitted with it are for the sole use of the intended recipient(s) and may contain confidential and privileged information. If you are not the intended recipient(s), please reply to the sender and destroy all copies of the original message. Any unauthorized review, use, disclosure, dissemination, forwarding, printing or copying of this email, and/or any action taken in reliance on the contents of this e-mail is strictly prohibited and may be unlawful. Where permitted by applicable law, this e-mail and other e-mail communications sent to and from Cognizant e-mail addresses may be monitored.

	[[alternative HTML version deleted]]


From Michael.Laviolette at dhhs.state.nh.us  Mon Jun 22 15:46:42 2015
From: Michael.Laviolette at dhhs.state.nh.us (Michael.Laviolette at dhhs.state.nh.us)
Date: Mon, 22 Jun 2015 09:46:42 -0400
Subject: [R] Omitting NA's using dcast (reshape2 package)
Message-ID: <OF8C1A12AE.38880897-ON85257E5E.004D6FDF-85257E6C.004BB05F@dhhs.state.nh.us>


I'm using the "dcast" function from Hadley's "reshape2" package to do some
tabulations. I can't get it to exclude NA's in the variables being
tabulated. Here's a simple example.

v1 <- c(rep("A", 5), rep("B", 5), NA)
v2 <- c("X", "Y", "Y", "Z", "Z", "X", "Y", "Y", "Z", NA, "Z")
v3 <- c(rep("a", 4), "c", "a", "b", NA, "c", "b", "c")
df <- data.frame(v1, v2, v3)
rm(v1, v2, v3)

library(reshape2)
dcast(df, v1 ~ v2, length, margins = TRUE)

#      v1 X Y Z NA (all)
# 1     A 1 2 2  0     5
# 2     B 1 2 1  1     5
# 3  <NA> 0 0 1  0     1
# 4 (all) 2 4 4  1    11
# "drop" argument has no effect
# na.omit will skip all records with any missing value

What I want is this:

#      v1 X Y Z (all)
# 1     A 1 2 2     5
# 2     B 1 2 1     4
# 3 (all) 2 4 3     9

Does anyone have any ideas?
Thanks,
Mike L.


From jdnewmil at dcn.davis.CA.us  Mon Jun 22 16:02:52 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 22 Jun 2015 07:02:52 -0700
Subject: [R] issue in running timeseries forecasting related package
In-Reply-To: <EAA865A6DDBB6C4FB20A175EBAA53BBC17CCF3FF@CTSINCHNSXMBM.cts.com>
References: <EAA865A6DDBB6C4FB20A175EBAA53BBC17CCF3FF@CTSINCHNSXMBM.cts.com>
Message-ID: <2626DEF5-3E5F-4EBB-B8D3-9E2D6D0B499B@dcn.davis.CA.us>

With so little to go on, we are not likely to be much help. A reproducible example and output of sessionInfo would be the minimum information that the Posting Guide would tell you to provide.

A wild guess is that you need to have a conversation with your system administrator. If your R version has upgraded in the second digit (e.g. 3.1.2 to 3.2.0) then you may need to refresh your personal package library with contributed packages protested for your new version of R.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 21, 2015 10:54:25 PM PDT, AshokVarma.Nadakuduti at cognizant.com wrote:
>Hi,
>
>
>I am trying to run packages timeseries, forecast, xts packages to
>execute some task. I was using this R-console for 8months. I had never
>faced any issue. Now, It's throwing an error saying 'Error: could not
>find function "forecast" Similarly for other packages as well. Could
>you please share any info that could solve this issue.
>
>
>
>Thanks,
>
>Ashok
>
>
>
>This e-mail and any files transmitted with it are for the sole use of
>the intended recipient(s) and may contain confidential and privileged
>information. If you are not the intended recipient(s), please reply to
>the sender and destroy all copies of the original message. Any
>unauthorized review, use, disclosure, dissemination, forwarding,
>printing or copying of this email, and/or any action taken in reliance
>on the contents of this e-mail is strictly prohibited and may be
>unlawful. Where permitted by applicable law, this e-mail and other
>e-mail communications sent to and from Cognizant e-mail addresses may
>be monitored.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Mon Jun 22 18:42:52 2015
From: tmrsg11 at gmail.com (C W)
Date: Mon, 22 Jun 2015 12:42:52 -0400
Subject: [R] sampling rows with values never sampled before
Message-ID: <CAE2FW2kq8cWmeuqinfd4SzdK=c7cTmrAnKsGi=-k+ctdset15Q@mail.gmail.com>

Hello R list,

I am have question about sampling unique coordinate values.

Here's how my data looks like

> dat <- cbind(x1 = rep(1:5, 3), x2 = rep(c(3.7, 2.9, 5.2), each=5))
> dat
      x1  x2
 [1,]  1 3.7
 [2,]  2 3.7
 [3,]  3 3.7
 [4,]  4 3.7
 [5,]  5 3.7
 [6,]  1 2.9
 [7,]  2 2.9
 [8,]  3 2.9
 [9,]  4 2.9
[10,]  5 2.9
[11,]  1 5.2
[12,]  2 5.2
[13,]  3 5.2
[14,]  4 5.2
[15,]  5 5.2


If I sampled (1, 3.7), then, I don't want (1, 2.9) or (2, 3.7).

I want to avoid either the first or second coordinate repeated.  It leads
to undefined matrix inversion.

I thought of using sampling(), but not sure about applying it to a data
frame.

Thanks in advance,

Mike

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Mon Jun 22 18:52:56 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 22 Jun 2015 11:52:56 -0500
Subject: [R] ASA Conference on Statistical Practice - deadline Thursday
Message-ID: <CAN5YmCG7w9zofvEm2C60vP+56Tc9=LqeJWxkQJsCM_yHw5HHCg@mail.gmail.com>

R users,

Abstracts are now being accepted for the
     2016 ASA Conference on Statistical Practice,
     February 18-20,
     San Diego, CA, USA.

Past conference attendees have shown particular interest in R,
reproducibility, and data visualization.

The deadline for submission is June 25.  Presentations will be 35 minutes
long and fall into four broad themes:
     Communication, Impact, and Career Development
     Data Modeling and Analysis
     Big Data Prediction and Analytics
     Software, Programming, and Graphics

Abstracts may be submitted at
http://www.amstat.org/meetings/csp/2016/abstracts.cfm

Thank you.

Jean V. Adams
on behalf of the ASA-CSP 2016 Steering Committee



`?.,,  ><(((?>   `?.,,  ><(((?>   `?.,,  ><(((?>

Jean V. Adams
Statistician
U.S. Geological Survey
Great Lakes Science Center
223 East Steinfest Road
Antigo, WI 54409  USA
http://www.glsc.usgs.gov
http://profile.usgs.gov/jvadams

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Mon Jun 22 19:09:43 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 22 Jun 2015 12:09:43 -0500
Subject: [R] sampling rows with values never sampled before
In-Reply-To: <CAE2FW2kq8cWmeuqinfd4SzdK=c7cTmrAnKsGi=-k+ctdset15Q@mail.gmail.com>
References: <CAE2FW2kq8cWmeuqinfd4SzdK=c7cTmrAnKsGi=-k+ctdset15Q@mail.gmail.com>
Message-ID: <CAN5YmCFRfSg0SH7oRMNgdiD_mjYES=_i070JTkUaW-XtDuAd0A@mail.gmail.com>

Mike,

There may be a more efficient way to do this, but this works on your
example.

# mix up the order of the rows
mix <- dat[order(runif(dim(dat)[1])), ]

# get rid of duplicate x1s and x2s
sub <- mix[!duplicated(mix[, "x1"]) & !duplicated(mix[, "x2"]), ]
sub

Jean

On Mon, Jun 22, 2015 at 11:42 AM, C W <tmrsg11 at gmail.com> wrote:

> Hello R list,
>
> I am have question about sampling unique coordinate values.
>
> Here's how my data looks like
>
> > dat <- cbind(x1 = rep(1:5, 3), x2 = rep(c(3.7, 2.9, 5.2), each=5))
> > dat
>       x1  x2
>  [1,]  1 3.7
>  [2,]  2 3.7
>  [3,]  3 3.7
>  [4,]  4 3.7
>  [5,]  5 3.7
>  [6,]  1 2.9
>  [7,]  2 2.9
>  [8,]  3 2.9
>  [9,]  4 2.9
> [10,]  5 2.9
> [11,]  1 5.2
> [12,]  2 5.2
> [13,]  3 5.2
> [14,]  4 5.2
> [15,]  5 5.2
>
>
> If I sampled (1, 3.7), then, I don't want (1, 2.9) or (2, 3.7).
>
> I want to avoid either the first or second coordinate repeated.  It leads
> to undefined matrix inversion.
>
> I thought of using sampling(), but not sure about applying it to a data
> frame.
>
> Thanks in advance,
>
> Mike
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Jun 22 19:25:05 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 22 Jun 2015 17:25:05 +0000
Subject: [R] Omitting NA's using dcast (reshape2 package)
In-Reply-To: <OF8C1A12AE.38880897-ON85257E5E.004D6FDF-85257E6C.004BB05F@dhhs.state.nh.us>
References: <OF8C1A12AE.38880897-ON85257E5E.004D6FDF-85257E6C.004BB05F@dhhs.state.nh.us>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D69D833@mb02.ads.tamu.edu>

You could apply na.omit() to just the columns you are using:

>  dcast(na.omit(df[,1:2]), v1 ~ v2, length, margins = TRUE)
Using v2 as value column: use value.var to override.
     v1 X Y Z (all)
1     A 1 2 2     5
2     B 1 2 1     4
3 (all) 2 4 3     9

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael.Laviolette at dhhs.state.nh.us
Sent: Monday, June 22, 2015 8:47 AM
To: r-help at r-project.org
Subject: [R] Omitting NA's using dcast (reshape2 package)


I'm using the "dcast" function from Hadley's "reshape2" package to do some
tabulations. I can't get it to exclude NA's in the variables being
tabulated. Here's a simple example.

v1 <- c(rep("A", 5), rep("B", 5), NA)
v2 <- c("X", "Y", "Y", "Z", "Z", "X", "Y", "Y", "Z", NA, "Z")
v3 <- c(rep("a", 4), "c", "a", "b", NA, "c", "b", "c")
df <- data.frame(v1, v2, v3)
rm(v1, v2, v3)

library(reshape2)
dcast(df, v1 ~ v2, length, margins = TRUE)

#      v1 X Y Z NA (all)
# 1     A 1 2 2  0     5
# 2     B 1 2 1  1     5
# 3  <NA> 0 0 1  0     1
# 4 (all) 2 4 4  1    11
# "drop" argument has no effect
# na.omit will skip all records with any missing value

What I want is this:

#      v1 X Y Z (all)
# 1     A 1 2 2     5
# 2     B 1 2 1     4
# 3 (all) 2 4 3     9

Does anyone have any ideas?
Thanks,
Mike L.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From djnordlund at frontier.com  Mon Jun 22 20:19:04 2015
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Mon, 22 Jun 2015 11:19:04 -0700
Subject: [R] sampling rows with values never sampled before
In-Reply-To: <CAE2FW2kq8cWmeuqinfd4SzdK=c7cTmrAnKsGi=-k+ctdset15Q@mail.gmail.com>
References: <CAE2FW2kq8cWmeuqinfd4SzdK=c7cTmrAnKsGi=-k+ctdset15Q@mail.gmail.com>
Message-ID: <55885198.3080607@frontier.com>

On 6/22/2015 9:42 AM, C W wrote:
> Hello R list,
>
> I am have question about sampling unique coordinate values.
>
> Here's how my data looks like
>
>> dat <- cbind(x1 = rep(1:5, 3), x2 = rep(c(3.7, 2.9, 5.2), each=5))
>> dat
>        x1  x2
>   [1,]  1 3.7
>   [2,]  2 3.7
>   [3,]  3 3.7
>   [4,]  4 3.7
>   [5,]  5 3.7
>   [6,]  1 2.9
>   [7,]  2 2.9
>   [8,]  3 2.9
>   [9,]  4 2.9
> [10,]  5 2.9
> [11,]  1 5.2
> [12,]  2 5.2
> [13,]  3 5.2
> [14,]  4 5.2
> [15,]  5 5.2
>
>
> If I sampled (1, 3.7), then, I don't want (1, 2.9) or (2, 3.7).
>
> I want to avoid either the first or second coordinate repeated.  It leads
> to undefined matrix inversion.
>
> I thought of using sampling(), but not sure about applying it to a data
> frame.
>
> Thanks in advance,
>
> Mike
>

I am not sure you gave us enough information to solve your real world 
problem.  But I have a few comments and a potential solution.

1. In your example the unique values in in x1 are completely crossed 
with the unique values in x2.
2. since you don't want duplicates of either number, then the maximum 
number of samples that you can take is the minimum number of unique 
values in either vector, x1 or x2 (in this case x2 with 3 unique values).
3. Sample without replace from the smallest set of unique values first.
4. Sample without replacement from the larger set second.

 > x <- 1:5
 > xx <- c(3.7, 2.9, 5.2)
 > s2 <- sample(xx,2, replace=FALSE)
 > s1 <- sample(x,2, replace=FALSE)
 > samp <- cbind(s1,s2)
 >
 > samp
      s1  s2
[1,]  5 3.7
[2,]  1 5.2
 >

Your actual data is probably larger, and the unique values in each 
vector may not be completely crossed, in which case the task is a little 
harder.  In that case, you could remove values from your data as you 
sample.  This may not be efficient, but it will work.

smpl <- function(dat, size){
   mysamp <- numeric(0)
   for(i in 1:size) {
     s <- dat[sample(nrow(dat),1),]
     mysamp <- rbind(mysamp,s, deparse.level=0)
     dat <- dat[!(dat[,1]==s[1] | dat[,2]==s[2]),]
     }
   mysamp
}


This is just an example of how you might approach your real world 
problem.  There is no error checking, and for large samples it may not 
scale well.


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Bothell, WA USA


From AshokVarma.Nadakuduti at cognizant.com  Mon Jun 22 16:00:08 2015
From: AshokVarma.Nadakuduti at cognizant.com (AshokVarma.Nadakuduti at cognizant.com)
Date: Mon, 22 Jun 2015 14:00:08 +0000
Subject: [R] issue in running timeseries forecasting related package
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C31BD5@SRVEXCHMBX.precheza.cz>
References: <EAA865A6DDBB6C4FB20A175EBAA53BBC17CCF3FF@CTSINCHNSXMBM.cts.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C31BD5@SRVEXCHMBX.precheza.cz>
Message-ID: <EAA865A6DDBB6C4FB20A175EBAA53BBC17CD35DA@CTSINCHNSXMBM.cts.com>

Hi Petr,

Thanks for the mail. Please find below the required information

Version: R-3.1.1 console

sessionInfo(): Attached the session info for your reference

Did you install new packages/R version? No

Did you load the package by library(xts)? Yes. I was able to run all the functions related to timeseries till Thursday. Not sure why this problem has come all of a sudden

Regards,
Ashok

-----Original Message-----
From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
Sent: Monday, June 22, 2015 7:04 PM
To: Nadakuduti, Ashok Varma (Cognizant); r-help at r-project.org
Subject: RE: issue in running timeseries forecasting related package

Hi

Please some aditional info:

Version:

sessionInfo()

Did you install new packages/R version?

Did you load the package by library(xts)?

And preferably no HTML post.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> AshokVarma.Nadakuduti at cognizant.com
> Sent: Monday, June 22, 2015 7:54 AM
> To: r-help at r-project.org
> Subject: [R] issue in running timeseries forecasting related package
>
> Hi,
>
>
> I am trying to run packages timeseries, forecast, xts packages to
> execute some task. I was using this R-console for 8months. I had never
> faced any issue. Now, It's throwing an error saying 'Error: could not
> find function "forecast" Similarly for other packages as well. Could
> you please share any info that could solve this issue.
>
>
>
> Thanks,
>
> Ashok
>
>
>
> This e-mail and any files transmitted with it are for the sole use of
> the intended recipient(s) and may contain confidential and privileged
> information. If you are not the intended recipient(s), please reply to
> the sender and destroy all copies of the original message. Any
> unauthorized review, use, disclosure, dissemination, forwarding,
> printing or copying of this email, and/or any action taken in reliance
> on the contents of this e-mail is strictly prohibited and may be
> unlawful. Where permitted by applicable law, this e-mail and other e-
> mail communications sent to and from Cognizant e-mail addresses may be
> monitored.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html and provide commented, minimal, self-contained,
> reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
This e-mail and any files transmitted with it are for the sole use of the intended recipient(s) and may contain confidential and privileged information. If you are not the intended recipient(s), please reply to the sender and destroy all copies of the original message. Any unauthorized review, use, disclosure, dissemination, forwarding, printing or copying of this email, and/or any action taken in reliance on the contents of this e-mail is strictly prohibited and may be unlawful. Where permitted by applicable law, this e-mail and other e-mail communications sent to and from Cognizant e-mail addresses may be monitored.
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: session info.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150622/6d7c2bdc/attachment.txt>

From synapse123 at gmail.com  Mon Jun 22 19:46:01 2015
From: synapse123 at gmail.com (synapse 123)
Date: Mon, 22 Jun 2015 12:46:01 -0500
Subject: [R] Random Forest -
Message-ID: <CA+3XiH9GnY2C8nfjG5fmJwOD3DhmTc7aoNb2n-ioW5dODe+vpA@mail.gmail.com>

Hi
I wanted to know if I cn use Random Forest in R for time to event data. I
cannot use Random Survival Forest since my data is not censored. Any
suggestions.

Thanks
Azi

	[[alternative HTML version deleted]]


From glennmschultz at me.com  Mon Jun 22 22:09:07 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Mon, 22 Jun 2015 20:09:07 +0000 (GMT)
Subject: [R] spline basis
Message-ID: <26ec7dc1-25e6-414d-a193-b85a9cdafcc5@me.com>

I have the following code which creates a spline function

x <- c(1, 12, 24, 36, 60, 120, 200, 240, 300, 360)
y <- c(.2, 8, 8, 8, 8, 8, 8, 8, 18, 50)


Baseline <- cbind(x,y)
Turnover <- splinefun(Baseline[,1], Baseline[,2], method = "natural")
plot(Turnover(seq(1, 360, 1)), type = "l")

If I change the Y ordinates the spline changes accordingly. ?However, the code is the same on inspection. ?Thus, I figure the basis must be stored somewhere. ?I have look through the documentation and cannot find its location. ?Can anyone enlighten me on what is going on and where I can find the basis matrix??

From dwinsemius at comcast.net  Mon Jun 22 23:25:56 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 22 Jun 2015 14:25:56 -0700
Subject: [R] spline basis
In-Reply-To: <26ec7dc1-25e6-414d-a193-b85a9cdafcc5@me.com>
References: <26ec7dc1-25e6-414d-a193-b85a9cdafcc5@me.com>
Message-ID: <33FC8860-DFC5-477B-8FD9-21BA65F68C76@comcast.net>


On Jun 22, 2015, at 1:09 PM, Glenn Schultz wrote:

> I have the following code which creates a spline function
> 
> x <- c(1, 12, 24, 36, 60, 120, 200, 240, 300, 360)
> y <- c(.2, 8, 8, 8, 8, 8, 8, 8, 18, 50)
> 
> 
> Baseline <- cbind(x,y)
> Turnover <- splinefun(Baseline[,1], Baseline[,2], method = "natural")
> plot(Turnover(seq(1, 360, 1)), type = "l")
> 
> If I change the Y ordinates the spline changes accordingly.  However, the code is the same on inspection.  Thus, I figure the basis must be stored somewhere.  I have look through the documentation and cannot find its location.  Can anyone enlighten me on what is going on and where I can find the basis matrix? 

The Trunover-object is actually a closure with both a function call and an enclosing environment:

> Turnover
function (x, deriv = 0L) 
{
    deriv <- as.integer(deriv)
    if (deriv < 0L || deriv > 3L) 
        stop("'deriv' must be between 0 and 3")
    if (deriv > 0L) {
        z0 <- double(z$n)
        z[c("y", "b", "c")] <- switch(deriv, list(y = z$b, b = 2 * 
            z$c, c = 3 * z$d), list(y = 2 * z$c, b = 6 * z$d, 
            c = z0), list(y = 6 * z$d, b = z0, c = z0))
        z[["d"]] <- z0
    }
    res <- .splinefun(x, z)
    if (deriv > 0 && z$method == 2 && any(ind <- x <= z$x[1L])) 
        res[ind] <- ifelse(deriv == 1, z$y[1L], 0)
    res
}
<bytecode: 0x3b00a0ea8>
<environment: 0x37f324158>

> ls(envir=environment(Turnover))
[1] "z"
> environment(Turnover)$z
$method
[1] 2

$n
[1] 10

$x
 [1]   1  12  24  36  60 120 200 240 300 360

$y
 [1]  0.2  8.0  8.0  8.0  8.0  8.0  8.0  8.0 18.0 50.0

$b
 [1]  0.891067507  0.345137714 -0.094715653  0.033724898 -0.012918083
 [6]  0.006114335 -0.011309452  0.030871189  0.362608232  0.618695884

$c
 [1]  0.000000e+00 -4.962998e-02  1.297553e-02 -2.272155e-03
 [5]  3.286972e-04 -1.149022e-05 -2.063071e-04  1.260823e-03
 [9]  4.268128e-03  0.000000e+00

$d
 [1] -1.503939e-03  1.739042e-03 -4.235469e-04  3.612294e-05
 [5] -1.889930e-06 -8.117371e-07  1.222609e-05  1.670725e-05
 [9] -2.371182e-05  0.000000e+00

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From tmrsg11 at gmail.com  Tue Jun 23 00:13:17 2015
From: tmrsg11 at gmail.com (C W)
Date: Mon, 22 Jun 2015 18:13:17 -0400
Subject: [R] sampling rows with values never sampled before
In-Reply-To: <55885198.3080607@frontier.com>
References: <CAE2FW2kq8cWmeuqinfd4SzdK=c7cTmrAnKsGi=-k+ctdset15Q@mail.gmail.com>
	<55885198.3080607@frontier.com>
Message-ID: <CAE2FW2nne4exH5g+5iJxgUz7-xH=H72V07gwnNBJUeK9N+DUQA@mail.gmail.com>

Hi Jean,

Thanks!

Daniel,
Yes, you are absolutely right.  I want sampled vectors to be as different
as possible.

I added a little more to the earlier data set.
        x1  x2  x3
 [1,]  1 3.7  2.1
 [2,]  2 3.7  5.3
 [3,]  3 3.7  6.2
 [4,]  4 3.7  8.9
 [5,]  5 3.7  4.1
 [6,]  1 2.9  2.1
 [7,]  2 2.9  5.3
 [8,]  3 2.9  6.2
 [9,]  4 2.9  8.9
[10,]  5 2.9 4.1
[11,]  1 5.2 2.1
[12,]  2 5.2 5.3
[13,]  3 5.2 6.2
[14,]  4 5.2 8.9
[15,]  5 5.2 4.1

If I sampled row, 1, 6, 11, solving the system of equations will not be
possible.  So, I am avoiding "similar vectors".

Thanks,

Mike


On Mon, Jun 22, 2015 at 2:19 PM, Daniel Nordlund <djnordlund at frontier.com>
wrote:

> On 6/22/2015 9:42 AM, C W wrote:
>
>> Hello R list,
>>
>> I am have question about sampling unique coordinate values.
>>
>> Here's how my data looks like
>>
>>  dat <- cbind(x1 = rep(1:5, 3), x2 = rep(c(3.7, 2.9, 5.2), each=5))
>>> dat
>>>
>>        x1  x2
>>   [1,]  1 3.7
>>   [2,]  2 3.7
>>   [3,]  3 3.7
>>   [4,]  4 3.7
>>   [5,]  5 3.7
>>   [6,]  1 2.9
>>   [7,]  2 2.9
>>   [8,]  3 2.9
>>   [9,]  4 2.9
>> [10,]  5 2.9
>> [11,]  1 5.2
>> [12,]  2 5.2
>> [13,]  3 5.2
>> [14,]  4 5.2
>> [15,]  5 5.2
>>
>>
>> If I sampled (1, 3.7), then, I don't want (1, 2.9) or (2, 3.7).
>>
>> I want to avoid either the first or second coordinate repeated.  It leads
>> to undefined matrix inversion.
>>
>> I thought of using sampling(), but not sure about applying it to a data
>> frame.
>>
>> Thanks in advance,
>>
>> Mike
>>
>>
> I am not sure you gave us enough information to solve your real world
> problem.  But I have a few comments and a potential solution.
>
> 1. In your example the unique values in in x1 are completely crossed with
> the unique values in x2.
> 2. since you don't want duplicates of either number, then the maximum
> number of samples that you can take is the minimum number of unique values
> in either vector, x1 or x2 (in this case x2 with 3 unique values).
> 3. Sample without replace from the smallest set of unique values first.
> 4. Sample without replacement from the larger set second.
>
> > x <- 1:5
> > xx <- c(3.7, 2.9, 5.2)
> > s2 <- sample(xx,2, replace=FALSE)
> > s1 <- sample(x,2, replace=FALSE)
> > samp <- cbind(s1,s2)
> >
> > samp
>      s1  s2
> [1,]  5 3.7
> [2,]  1 5.2
> >
>
> Your actual data is probably larger, and the unique values in each vector
> may not be completely crossed, in which case the task is a little harder.
> In that case, you could remove values from your data as you sample.  This
> may not be efficient, but it will work.
>
> smpl <- function(dat, size){
>   mysamp <- numeric(0)
>   for(i in 1:size) {
>     s <- dat[sample(nrow(dat),1),]
>     mysamp <- rbind(mysamp,s, deparse.level=0)
>     dat <- dat[!(dat[,1]==s[1] | dat[,2]==s[2]),]
>     }
>   mysamp
> }
>
>
> This is just an example of how you might approach your real world
> problem.  There is no error checking, and for large samples it may not
> scale well.
>
>
> Hope this is helpful,
>
> Dan
>
> --
> Daniel Nordlund
> Bothell, WA USA
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Jun 23 01:24:35 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 22 Jun 2015 16:24:35 -0700
Subject: [R] Random Forest -
In-Reply-To: <CA+3XiH9GnY2C8nfjG5fmJwOD3DhmTc7aoNb2n-ioW5dODe+vpA@mail.gmail.com>
References: <CA+3XiH9GnY2C8nfjG5fmJwOD3DhmTc7aoNb2n-ioW5dODe+vpA@mail.gmail.com>
Message-ID: <C82B4C80-EC11-4C4C-A5CA-80F464FDD83E@comcast.net>


On Jun 22, 2015, at 10:46 AM, synapse 123 wrote:

> Hi
> I wanted to know if I cn use Random Forest in R for time to event data. I
> cannot use Random Survival Forest since my data is not censored. Any
> suggestions.
> 

I'm not sure why that should be a problem for RandomSurvivalForests. It's not a problem for regular survival analysis.

 If you used RandomForest with time to event as the outcome without dividing by for the number at risk in time intervals from start, you would be applying a different metric for risk.

-- 
David Winsemius
Alameda, CA, USA


From denis.chabot at me.com  Tue Jun 23 05:17:36 2015
From: denis.chabot at me.com (Denis Chabot)
Date: Mon, 22 Jun 2015 23:17:36 -0400
Subject: [R] repeated measures: multiple comparisons with pairwise.t.test
 and multcomp disagree
Message-ID: <5C2FF04C-262D-4D96-A493-A62F149DA76A@me.com>

Hi,

I am working on a problem which I think can be handled as a repeated measures analysis, and I have read many tutorials about how to do this with R. This part goes well, but I get stuck with the multiple comparisons I'd like to run afterward. I tried two methods that I have seen in my readings, but their results are quite different and I don't know which one to trust.

The two approaches are pairwise.t.test() and multcomp, although the latter is not available after a repeated-measures aov model, but it is after a lme. 

I have a physiological variable measured frequently on each of 67 animals. These are then summarized with a quantile for each animal. To check the effect of experiment duration, I recalculated the quantile for each animal 4 times, using different subset of the data (so the shortest subset is part of all other subsets, the second subset is included in the 2 others, etc.). I handle this as 4 repeated (non-independent) measurements for each animal, and want to see if the average value (for 67 animals) differs for the 4 different durations.

Because animals with high values for this physiological trait have larger differences between the 4 durations than animals with low values, the observations were log transformed.

I attach the small data set (Rda format) here, but it can be obtained here if the attachment gets stripped:
<https://dl.dropboxusercontent.com/u/612902/RepMeasData.Rda>

The data.frame is simply called Data.
My code is

load("RepMeasData.Rda")
Data_Long = melt(Data, id="Case")
names(Data_Long) = c("Case","Duration", "SMR")
Data_Long$SMR = log10(Data_Long$SMR)

# I only show essential code to reproduce my opposing results
mixmod = lme(SMR ~ Duration, data = Data_Long, random = ~ 1 | Case)
anova(mixmod)
posthoc <- glht(mixmod, linfct = mcp(Duration = "Tukey"))
summary(posthoc)
	 Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: lme.formula(fixed = SMR ~ Duration, data = Data_Long, random = ~1 | 
    Case)

Linear Hypotheses:
                  Estimate Std. Error z value Pr(>|z|)    
Set2 - Set1 == 0 -0.006135   0.003375  -1.818    0.265    
Set3 - Set1 == 0 -0.002871   0.003375  -0.851    0.830    
Set4 - Set1 == 0  0.015395   0.003375   4.561   <1e-04 ***
Set3 - Set2 == 0  0.003264   0.003375   0.967    0.768    
Set4 - Set2 == 0  0.021530   0.003375   6.379   <1e-04 ***
Set4 - Set3 == 0  0.018266   0.003375   5.412   <1e-04 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
(Adjusted p values reported -- single-step method)

with(Data_Long, pairwise.t.test(SMR, Duration, p.adjust.method="holm", paired=T))
	Pairwise comparisons using paired t tests 

data:  SMR and Duration 

     Set1    Set2    Set3   
Set2 < 2e-16 -       -      
Set3 0.11118 0.10648 -      
Set4 0.00475 7.9e-05 0.00034

P value adjustment method: holm 

So the difference between sets 1 and 2 goes from non significant to very significant, depending on method.

I have other examples with essentially the same type of data and sometimes the two approches differ in the opposing way. In the example shown here, multcomp was more conservative, in some others it yielded a larger number of significant differences.

I admit not mastering all the intricacies of multcomp, but I have used multcomp and other methods of doing multiple comparisons many times before (but never with a repeated measures design), and always found the results very similar. When there were small differences, I trusted multcomp. This time, I get rather large differences and I am worried that I am doing something wrong.

Thanks in advance,

Denis Chabot
Fisheries & Oceans Canada

sessionInfo()
R version 3.2.0 (2015-04-16)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.10.3 (Yosemite)

locale:
[1] fr_CA.UTF-8/fr_CA.UTF-8/fr_CA.UTF-8/C/fr_CA.UTF-8/fr_CA.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] multcomp_1.4-0  TH.data_1.0-6   survival_2.38-1 mvtnorm_1.0-2   nlme_3.1-120    car_2.0-25      reshape2_1.4.1 

loaded via a namespace (and not attached):
 [1] Rcpp_0.11.5      magrittr_1.5     splines_3.2.0    MASS_7.3-40      lattice_0.20-31  minqa_1.2.4      stringr_1.0.0   
 [8] plyr_1.8.2       tools_3.2.0      nnet_7.3-9       pbkrtest_0.4-2   parallel_3.2.0   grid_3.2.0       mgcv_1.8-6      
[15] quantreg_5.11    lme4_1.1-7       Matrix_1.2-0     nloptr_1.0.4     codetools_0.2-11 sandwich_2.3-3   stringi_0.4-1   
[22] SparseM_1.6      zoo_1.7-12        

From petr.pikal at precheza.cz  Tue Jun 23 08:09:43 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 23 Jun 2015 06:09:43 +0000
Subject: [R] issue in running timeseries forecasting related package
In-Reply-To: <EAA865A6DDBB6C4FB20A175EBAA53BBC17CD35DA@CTSINCHNSXMBM.cts.com>
References: <EAA865A6DDBB6C4FB20A175EBAA53BBC17CCF3FF@CTSINCHNSXMBM.cts.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C31BD5@SRVEXCHMBX.precheza.cz>
	<EAA865A6DDBB6C4FB20A175EBAA53BBC17CD35DA@CTSINCHNSXMBM.cts.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C31C98@SRVEXCHMBX.precheza.cz>

Hi

It is weird. Maybe others could come with some sensible answer. I would try to start R with -vanilla switch

Rgui.exe --vanilla

and try if everything is OK. If yes, you could start loading packages and see how all is working. If not  I think that the only option is reinstaling R and packges although it is tedious.

Cheers
Petr


> -----Original Message-----
> From: AshokVarma.Nadakuduti at cognizant.com
> [mailto:AshokVarma.Nadakuduti at cognizant.com]
> Sent: Monday, June 22, 2015 4:00 PM
> To: PIKAL Petr; r-help at r-project.org
> Subject: RE: issue in running timeseries forecasting related package
>
> Hi Petr,
>
> Thanks for the mail. Please find below the required information
>
> Version: R-3.1.1 console
>
> sessionInfo(): Attached the session info for your reference
>
> Did you install new packages/R version? No
>
> Did you load the package by library(xts)? Yes. I was able to run all
> the functions related to timeseries till Thursday. Not sure why this
> problem has come all of a sudden
>
> Regards,
> Ashok
>
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: Monday, June 22, 2015 7:04 PM
> To: Nadakuduti, Ashok Varma (Cognizant); r-help at r-project.org
> Subject: RE: issue in running timeseries forecasting related package
>
> Hi
>
> Please some aditional info:
>
> Version:
>
> sessionInfo()
>
> Did you install new packages/R version?
>
> Did you load the package by library(xts)?
>
> And preferably no HTML post.
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > AshokVarma.Nadakuduti at cognizant.com
> > Sent: Monday, June 22, 2015 7:54 AM
> > To: r-help at r-project.org
> > Subject: [R] issue in running timeseries forecasting related package
> >
> > Hi,
> >
> >
> > I am trying to run packages timeseries, forecast, xts packages to
> > execute some task. I was using this R-console for 8months. I had
> never
> > faced any issue. Now, It's throwing an error saying 'Error: could not
> > find function "forecast" Similarly for other packages as well. Could
> > you please share any info that could solve this issue.
> >
> >
> >
> > Thanks,
> >
> > Ashok
> >
> >
> >
> > This e-mail and any files transmitted with it are for the sole use of
> > the intended recipient(s) and may contain confidential and privileged
> > information. If you are not the intended recipient(s), please reply
> to
> > the sender and destroy all copies of the original message. Any
> > unauthorized review, use, disclosure, dissemination, forwarding,
> > printing or copying of this email, and/or any action taken in
> reliance
> > on the contents of this e-mail is strictly prohibited and may be
> > unlawful. Where permitted by applicable law, this e-mail and other e-
> > mail communications sent to and from Cognizant e-mail addresses may
> be
> > monitored.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
> ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
>
> This e-mail and any documents attached to it may be confidential and
> are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into
> a contract in any time, for any reason, and without stating any
> reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer)
> excludes any acceptance of the offer on the part of the recipient
> containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in
> which he/she is expressly authorized to do so in writing, and such
> authorization or power of attorney is submitted to the recipient or the
> person represented by the recipient, or the existence of such
> authorization is known to the recipient of the person represented by
> the recipient.
> This e-mail and any files transmitted with it are for the sole use of
> the intended recipient(s) and may contain confidential and privileged
> information. If you are not the intended recipient(s), please reply to
> the sender and destroy all copies of the original message. Any
> unauthorized review, use, disclosure, dissemination, forwarding,
> printing or copying of this email, and/or any action taken in reliance
> on the contents of this e-mail is strictly prohibited and may be
> unlawful. Where permitted by applicable law, this e-mail and other e-
> mail communications sent to and from Cognizant e-mail addresses may be
> monitored.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ragia11 at hotmail.com  Tue Jun 23 08:51:29 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Tue, 23 Jun 2015 09:51:29 +0300
Subject: [R] numeric of length 1
Message-ID: <DUB125-W10C5D212C9BD3CF6775318B3A00@phx.gbl>

Dear group,
I have the following object

> pr_sub$vector[1]
        14 
0.07782809 

> class( pr_sub$vector[1])
[1] "numeric"

 > length( pr_sub$vector[1])
[1] 1
how can I separate  pr_sub$vector[1]

and get 14 only

thanks in advance
Ragia
 		 	   		  
	[[alternative HTML version deleted]]


From Gerrit.Eichner at math.uni-giessen.de  Tue Jun 23 08:58:58 2015
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 23 Jun 2015 08:58:58 +0200 (MEST)
Subject: [R] numeric of length 1
In-Reply-To: <DUB125-W10C5D212C9BD3CF6775318B3A00@phx.gbl>
References: <DUB125-W10C5D212C9BD3CF6775318B3A00@phx.gbl>
Message-ID: <Pine.SOC.4.64.1506230857480.14084@solcom.hrz.uni-giessen.de>

Hi, Ragia,

use

> names( pr_sub$vector[ 1])

  Regards  --  Gerrit


On Tue, 23 Jun 2015, Ragia Ibrahim wrote:

> Dear group,
> I have the following object
>
>> pr_sub$vector[1]
>        14
> 0.07782809
>
>> class( pr_sub$vector[1])
> [1] "numeric"
>
> > length( pr_sub$vector[1])
> [1] 1
> how can I separate  pr_sub$vector[1]
>
> and get 14 only
>
> thanks in advance
> Ragia
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dominique.katshunga at uct.ac.za  Tue Jun 23 14:07:11 2015
From: dominique.katshunga at uct.ac.za (Dominique Katshunga)
Date: Tue, 23 Jun 2015 12:07:11 +0000
Subject: [R] Copula package - normalCopula() param order
Message-ID: <CDBC94FDA5C7204F9AE549D1A620514C8C0B5A26@srvwinexc002.wf.uct.ac.za>

Dear all,
In an attempt to generate a sample of observations from a four dimensional copula from the package Copula, I got the following warning message and all the observations are NA's:
Warning messages:
1: In rmvnorm(n, sigma = getSigma(copula)) :
  sigma is numerically not positive definite
2: In sqrt(ev$values) : NaNs produced

I used the following lines (I want all the variables to be negatively correlated):

Ncop=normalCopula(c(-0.95,-0.95,-0.95,-0.95,-0.95,-0.95),dim=4,dispstr="un")
mv_4dim=mvdc(Ncop,c("norm","norm","norm","norm"),list(list(mean=0,sd=2),list(mean=2.1,sd=1.5),list(mean=5,sd=2),list(mean=4.5,sd=0.5)))
sample_4dim=rMvdc(1000,mv_4dim)

What am doing wrong ?

Dominique Katshunga
==============
Lecturer in Statistical Sciences Department
University of Cape Town
Tel. 021 6504669
Fax. 021 6504773
email: dominique.katshunga at uct.ac.za<mailto:dominique.katshunga at uct.ac.za>

________________________________
UNIVERSITY OF CAPE TOWN

This e-mail is subject to the UCT ICT policies and e-mai...{{dropped:12}}


From thierry.onkelinx at inbo.be  Tue Jun 23 14:15:02 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 23 Jun 2015 14:15:02 +0200
Subject: [R] repeated measures: multiple comparisons with
 pairwise.t.test and multcomp disagree
In-Reply-To: <5C2FF04C-262D-4D96-A493-A62F149DA76A@me.com>
References: <5C2FF04C-262D-4D96-A493-A62F149DA76A@me.com>
Message-ID: <CAJuCY5xMk1=662vX9x50TvnGx3_qHHphL8sU67cOoEFVCqcJtg@mail.gmail.com>

Dear Denis,

It's not multcomp which is too conservative, it is the pairwise t-test
which is too liberal. The pairwise t-test doesn't take the random
effect of Case into account.

Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-06-23 5:17 GMT+02:00 Denis Chabot <denis.chabot at me.com>:
> Hi,
>
> I am working on a problem which I think can be handled as a repeated measures analysis, and I have read many tutorials about how to do this with R. This part goes well, but I get stuck with the multiple comparisons I'd like to run afterward. I tried two methods that I have seen in my readings, but their results are quite different and I don't know which one to trust.
>
> The two approaches are pairwise.t.test() and multcomp, although the latter is not available after a repeated-measures aov model, but it is after a lme.
>
> I have a physiological variable measured frequently on each of 67 animals. These are then summarized with a quantile for each animal. To check the effect of experiment duration, I recalculated the quantile for each animal 4 times, using different subset of the data (so the shortest subset is part of all other subsets, the second subset is included in the 2 others, etc.). I handle this as 4 repeated (non-independent) measurements for each animal, and want to see if the average value (for 67 animals) differs for the 4 different durations.
>
> Because animals with high values for this physiological trait have larger differences between the 4 durations than animals with low values, the observations were log transformed.
>
> I attach the small data set (Rda format) here, but it can be obtained here if the attachment gets stripped:
> <https://dl.dropboxusercontent.com/u/612902/RepMeasData.Rda>
>
> The data.frame is simply called Data.
> My code is
>
> load("RepMeasData.Rda")
> Data_Long = melt(Data, id="Case")
> names(Data_Long) = c("Case","Duration", "SMR")
> Data_Long$SMR = log10(Data_Long$SMR)
>
> # I only show essential code to reproduce my opposing results
> mixmod = lme(SMR ~ Duration, data = Data_Long, random = ~ 1 | Case)
> anova(mixmod)
> posthoc <- glht(mixmod, linfct = mcp(Duration = "Tukey"))
> summary(posthoc)
>          Simultaneous Tests for General Linear Hypotheses
>
> Multiple Comparisons of Means: Tukey Contrasts
>
>
> Fit: lme.formula(fixed = SMR ~ Duration, data = Data_Long, random = ~1 |
>     Case)
>
> Linear Hypotheses:
>                   Estimate Std. Error z value Pr(>|z|)
> Set2 - Set1 == 0 -0.006135   0.003375  -1.818    0.265
> Set3 - Set1 == 0 -0.002871   0.003375  -0.851    0.830
> Set4 - Set1 == 0  0.015395   0.003375   4.561   <1e-04 ***
> Set3 - Set2 == 0  0.003264   0.003375   0.967    0.768
> Set4 - Set2 == 0  0.021530   0.003375   6.379   <1e-04 ***
> Set4 - Set3 == 0  0.018266   0.003375   5.412   <1e-04 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> (Adjusted p values reported -- single-step method)
>
> with(Data_Long, pairwise.t.test(SMR, Duration, p.adjust.method="holm", paired=T))
>         Pairwise comparisons using paired t tests
>
> data:  SMR and Duration
>
>      Set1    Set2    Set3
> Set2 < 2e-16 -       -
> Set3 0.11118 0.10648 -
> Set4 0.00475 7.9e-05 0.00034
>
> P value adjustment method: holm
>
> So the difference between sets 1 and 2 goes from non significant to very significant, depending on method.
>
> I have other examples with essentially the same type of data and sometimes the two approches differ in the opposing way. In the example shown here, multcomp was more conservative, in some others it yielded a larger number of significant differences.
>
> I admit not mastering all the intricacies of multcomp, but I have used multcomp and other methods of doing multiple comparisons many times before (but never with a repeated measures design), and always found the results very similar. When there were small differences, I trusted multcomp. This time, I get rather large differences and I am worried that I am doing something wrong.
>
> Thanks in advance,
>
> Denis Chabot
> Fisheries & Oceans Canada
>
> sessionInfo()
> R version 3.2.0 (2015-04-16)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.10.3 (Yosemite)
>
> locale:
> [1] fr_CA.UTF-8/fr_CA.UTF-8/fr_CA.UTF-8/C/fr_CA.UTF-8/fr_CA.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] multcomp_1.4-0  TH.data_1.0-6   survival_2.38-1 mvtnorm_1.0-2   nlme_3.1-120    car_2.0-25      reshape2_1.4.1
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.11.5      magrittr_1.5     splines_3.2.0    MASS_7.3-40      lattice_0.20-31  minqa_1.2.4      stringr_1.0.0
>  [8] plyr_1.8.2       tools_3.2.0      nnet_7.3-9       pbkrtest_0.4-2   parallel_3.2.0   grid_3.2.0       mgcv_1.8-6
> [15] quantreg_5.11    lme4_1.1-7       Matrix_1.2-0     nloptr_1.0.4     codetools_0.2-11 sandwich_2.3-3   stringi_0.4-1
> [22] SparseM_1.6      zoo_1.7-12
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jon.skoien at jrc.ec.europa.eu  Tue Jun 23 10:04:26 2015
From: jon.skoien at jrc.ec.europa.eu (Jon Skoien)
Date: Tue, 23 Jun 2015 10:04:26 +0200
Subject: [R] sampling rows with values never sampled before
In-Reply-To: <CAE2FW2nne4exH5g+5iJxgUz7-xH=H72V07gwnNBJUeK9N+DUQA@mail.gmail.com>
References: <CAE2FW2kq8cWmeuqinfd4SzdK=c7cTmrAnKsGi=-k+ctdset15Q@mail.gmail.com>
	<55885198.3080607@frontier.com>
	<CAE2FW2nne4exH5g+5iJxgUz7-xH=H72V07gwnNBJUeK9N+DUQA@mail.gmail.com>
Message-ID: <5589130A.9020005@jrc.ec.europa.eu>

If df is the data.frame with values and you want nn samples, then this 
is a slightly different approach:

# example data.frame:
df = data.frame(a1 = sample(1:20,50, replace = TRUE),
                             a2 =  sample(seq(0.1,10,length.out = 
30),50, replace = TRUE),
                             a3 = sample(seq(0.3, 20,length.out = 
20),50,replace = TRUE))
nrow = dim(df)[1] # 50
ncol = dim(df)[2]  # 3

# start by randomizing the order in your data.frame
randomOrder = sample(1:nrow, nrow, replace = FALSE)
dff = df[randomOrder,]

# find and remove all duplicates from all columns. With this you will 
only keep the first instance of any unique value:
rem = NULL
for (ic in 1:ncol) rem = c(rem, which(duplicated(dff[, ic])))
if (length(rem) > 0) dff = dff[-unique(rem),]

# Reduce to the length you need
if (dim(dff)[1] > nn)  res = dff[1:nn,] else res = dff

I am not sure how this scales if you have a really big data, and whether 
you could get some FAQ 7.31 problems depending on how you fill your 
data.frame.

Cheers,
Jon

On 6/23/2015 12:13 AM, C W wrote:
> Hi Jean,
>
> Thanks!
>
> Daniel,
> Yes, you are absolutely right.  I want sampled vectors to be as different
> as possible.
>
> I added a little more to the earlier data set.
>          x1  x2  x3
>   [1,]  1 3.7  2.1
>   [2,]  2 3.7  5.3
>   [3,]  3 3.7  6.2
>   [4,]  4 3.7  8.9
>   [5,]  5 3.7  4.1
>   [6,]  1 2.9  2.1
>   [7,]  2 2.9  5.3
>   [8,]  3 2.9  6.2
>   [9,]  4 2.9  8.9
> [10,]  5 2.9 4.1
> [11,]  1 5.2 2.1
> [12,]  2 5.2 5.3
> [13,]  3 5.2 6.2
> [14,]  4 5.2 8.9
> [15,]  5 5.2 4.1
>
> If I sampled row, 1, 6, 11, solving the system of equations will not be
> possible.  So, I am avoiding "similar vectors".
>
> Thanks,
>
> Mike
>
>
> On Mon, Jun 22, 2015 at 2:19 PM, Daniel Nordlund <djnordlund at frontier.com>
> wrote:
>
>> On 6/22/2015 9:42 AM, C W wrote:
>>
>>> Hello R list,
>>>
>>> I am have question about sampling unique coordinate values.
>>>
>>> Here's how my data looks like
>>>
>>>   dat <- cbind(x1 = rep(1:5, 3), x2 = rep(c(3.7, 2.9, 5.2), each=5))
>>>> dat
>>>>
>>>         x1  x2
>>>    [1,]  1 3.7
>>>    [2,]  2 3.7
>>>    [3,]  3 3.7
>>>    [4,]  4 3.7
>>>    [5,]  5 3.7
>>>    [6,]  1 2.9
>>>    [7,]  2 2.9
>>>    [8,]  3 2.9
>>>    [9,]  4 2.9
>>> [10,]  5 2.9
>>> [11,]  1 5.2
>>> [12,]  2 5.2
>>> [13,]  3 5.2
>>> [14,]  4 5.2
>>> [15,]  5 5.2
>>>
>>>
>>> If I sampled (1, 3.7), then, I don't want (1, 2.9) or (2, 3.7).
>>>
>>> I want to avoid either the first or second coordinate repeated.  It leads
>>> to undefined matrix inversion.
>>>
>>> I thought of using sampling(), but not sure about applying it to a data
>>> frame.
>>>
>>> Thanks in advance,
>>>
>>> Mike
>>>
>>>
>> I am not sure you gave us enough information to solve your real world
>> problem.  But I have a few comments and a potential solution.
>>
>> 1. In your example the unique values in in x1 are completely crossed with
>> the unique values in x2.
>> 2. since you don't want duplicates of either number, then the maximum
>> number of samples that you can take is the minimum number of unique values
>> in either vector, x1 or x2 (in this case x2 with 3 unique values).
>> 3. Sample without replace from the smallest set of unique values first.
>> 4. Sample without replacement from the larger set second.
>>
>>> x <- 1:5
>>> xx <- c(3.7, 2.9, 5.2)
>>> s2 <- sample(xx,2, replace=FALSE)
>>> s1 <- sample(x,2, replace=FALSE)
>>> samp <- cbind(s1,s2)
>>>
>>> samp
>>       s1  s2
>> [1,]  5 3.7
>> [2,]  1 5.2
>> Your actual data is probably larger, and the unique values in each vector
>> may not be completely crossed, in which case the task is a little harder.
>> In that case, you could remove values from your data as you sample.  This
>> may not be efficient, but it will work.
>>
>> smpl <- function(dat, size){
>>    mysamp <- numeric(0)
>>    for(i in 1:size) {
>>      s <- dat[sample(nrow(dat),1),]
>>      mysamp <- rbind(mysamp,s, deparse.level=0)
>>      dat <- dat[!(dat[,1]==s[1] | dat[,2]==s[2]),]
>>      }
>>    mysamp
>> }
>>
>>
>> This is just an example of how you might approach your real world
>> problem.  There is no error checking, and for large samples it may not
>> scale well.
>>
>>
>> Hope this is helpful,
>>
>> Dan
>>
>> --
>> Daniel Nordlund
>> Bothell, WA USA
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Jon Olav Sk?ien
Joint Research Centre - European Commission
Institute for Environment and Sustainability (IES)
Climate Risk Management Unit

Via Fermi 2749, TP 100-01,  I-21027 Ispra (VA), ITALY

jon.skoien at jrc.ec.europa.eu
Tel:  +39 0332 789205

Disclaimer: Views expressed in this email are those of the individual and do not necessarily represent official views of the European Commission.


From mylisttech at gmail.com  Tue Jun 23 16:07:22 2015
From: mylisttech at gmail.com (My List)
Date: Tue, 23 Jun 2015 19:37:22 +0530
Subject: [R] Usage of vcd packages.
Message-ID: <CAFpdVnzx-_Kj7n4mO4fAx+W2-2a2grQ_i2nHFUdv++X42NYnFQ@mail.gmail.com>

All,

I am new to the vcd package and new to R too.

1) I have a lickert analysis based data set.
2) I am doing a hypothesis tests on the variables ( like, is there a
relationship between the choice of a Doctor based on the Patients Income ,
that's just one example)
3) I am building contingency tables ( R x C) and running chiqsqr.test on
these tables.

These are mostly 2 x 2 tables. In some cases I am getting very low counts
of the variables in these ( R x C )  tables. I wanted to know at what point
do I need to use

chisqr.test with correction
fishers exact test

How do I show if there is any association between the variables in the R x
C setup?Should be I  using oddratio() or or assocstats() or should I use
Cramers V test for 2 x 2 tables.

Please, advice or lead me to a source.

*Example of Case - Age of patients and If the Dr Justified a Diagnostic
Test on them.*







DrJustifyDgntTstNo

DrJustifyDgntTstYes



Age21-40

1

91



Age41-50

4

30



GtrThan51

3

50








Thanks in advance,
Harmeet

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jun 23 16:08:38 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 23 Jun 2015 07:08:38 -0700
Subject: [R] repeated measures: multiple comparisons with
 pairwise.t.test and multcomp disagree
In-Reply-To: <5C2FF04C-262D-4D96-A493-A62F149DA76A@me.com>
References: <5C2FF04C-262D-4D96-A493-A62F149DA76A@me.com>
Message-ID: <CAGxFJbS1SwnvFAZsa9Kd0CRGdq-+L+dWNbVfZuL0s7bQgYAK4w@mail.gmail.com>

Yours is (primarily) a statistical question, not a question about R,
and so off topic here. Post on a statistics list, like
stats.stackexchange.com instead. Better yet, consult a local
statistician. This is a thorny and difficult matter and, as you have
already discovered, is "full of sound and fury, signifying nothing."
(or, at least, what's being signaled depends exactly on what question
is being asked, which is why this is a mess).

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Mon, Jun 22, 2015 at 8:17 PM, Denis Chabot <denis.chabot at me.com> wrote:
> Hi,
>
> I am working on a problem which I think can be handled as a repeated measures analysis, and I have read many tutorials about how to do this with R. This part goes well, but I get stuck with the multiple comparisons I'd like to run afterward. I tried two methods that I have seen in my readings, but their results are quite different and I don't know which one to trust.
>
> The two approaches are pairwise.t.test() and multcomp, although the latter is not available after a repeated-measures aov model, but it is after a lme.
>
> I have a physiological variable measured frequently on each of 67 animals. These are then summarized with a quantile for each animal. To check the effect of experiment duration, I recalculated the quantile for each animal 4 times, using different subset of the data (so the shortest subset is part of all other subsets, the second subset is included in the 2 others, etc.). I handle this as 4 repeated (non-independent) measurements for each animal, and want to see if the average value (for 67 animals) differs for the 4 different durations.
>
> Because animals with high values for this physiological trait have larger differences between the 4 durations than animals with low values, the observations were log transformed.
>
> I attach the small data set (Rda format) here, but it can be obtained here if the attachment gets stripped:
> <https://dl.dropboxusercontent.com/u/612902/RepMeasData.Rda>
>
> The data.frame is simply called Data.
> My code is
>
> load("RepMeasData.Rda")
> Data_Long = melt(Data, id="Case")
> names(Data_Long) = c("Case","Duration", "SMR")
> Data_Long$SMR = log10(Data_Long$SMR)
>
> # I only show essential code to reproduce my opposing results
> mixmod = lme(SMR ~ Duration, data = Data_Long, random = ~ 1 | Case)
> anova(mixmod)
> posthoc <- glht(mixmod, linfct = mcp(Duration = "Tukey"))
> summary(posthoc)
>          Simultaneous Tests for General Linear Hypotheses
>
> Multiple Comparisons of Means: Tukey Contrasts
>
>
> Fit: lme.formula(fixed = SMR ~ Duration, data = Data_Long, random = ~1 |
>     Case)
>
> Linear Hypotheses:
>                   Estimate Std. Error z value Pr(>|z|)
> Set2 - Set1 == 0 -0.006135   0.003375  -1.818    0.265
> Set3 - Set1 == 0 -0.002871   0.003375  -0.851    0.830
> Set4 - Set1 == 0  0.015395   0.003375   4.561   <1e-04 ***
> Set3 - Set2 == 0  0.003264   0.003375   0.967    0.768
> Set4 - Set2 == 0  0.021530   0.003375   6.379   <1e-04 ***
> Set4 - Set3 == 0  0.018266   0.003375   5.412   <1e-04 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> (Adjusted p values reported -- single-step method)
>
> with(Data_Long, pairwise.t.test(SMR, Duration, p.adjust.method="holm", paired=T))
>         Pairwise comparisons using paired t tests
>
> data:  SMR and Duration
>
>      Set1    Set2    Set3
> Set2 < 2e-16 -       -
> Set3 0.11118 0.10648 -
> Set4 0.00475 7.9e-05 0.00034
>
> P value adjustment method: holm
>
> So the difference between sets 1 and 2 goes from non significant to very significant, depending on method.
>
> I have other examples with essentially the same type of data and sometimes the two approches differ in the opposing way. In the example shown here, multcomp was more conservative, in some others it yielded a larger number of significant differences.
>
> I admit not mastering all the intricacies of multcomp, but I have used multcomp and other methods of doing multiple comparisons many times before (but never with a repeated measures design), and always found the results very similar. When there were small differences, I trusted multcomp. This time, I get rather large differences and I am worried that I am doing something wrong.
>
> Thanks in advance,
>
> Denis Chabot
> Fisheries & Oceans Canada
>
> sessionInfo()
> R version 3.2.0 (2015-04-16)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.10.3 (Yosemite)
>
> locale:
> [1] fr_CA.UTF-8/fr_CA.UTF-8/fr_CA.UTF-8/C/fr_CA.UTF-8/fr_CA.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] multcomp_1.4-0  TH.data_1.0-6   survival_2.38-1 mvtnorm_1.0-2   nlme_3.1-120    car_2.0-25      reshape2_1.4.1
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.11.5      magrittr_1.5     splines_3.2.0    MASS_7.3-40      lattice_0.20-31  minqa_1.2.4      stringr_1.0.0
>  [8] plyr_1.8.2       tools_3.2.0      nnet_7.3-9       pbkrtest_0.4-2   parallel_3.2.0   grid_3.2.0       mgcv_1.8-6
> [15] quantreg_5.11    lme4_1.1-7       Matrix_1.2-0     nloptr_1.0.4     codetools_0.2-11 sandwich_2.3-3   stringi_0.4-1
> [22] SparseM_1.6      zoo_1.7-12
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From devazresearch at gmail.com  Tue Jun 23 16:48:45 2015
From: devazresearch at gmail.com (DzR)
Date: Tue, 23 Jun 2015 20:18:45 +0530
Subject: [R] Lavaan
Message-ID: <558971ce.43e8420a.97818.0a8d@mx.google.com>

Dear Senior users of R/R Studio,

I am very new to this environment hence am unable to plot the SEM models including use of graphic package ggplot.

Request for some help in getting the plots please.

Thanks,

-----
Deva

From sarah.goslee at gmail.com  Tue Jun 23 17:33:29 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 23 Jun 2015 11:33:29 -0400
Subject: [R] Lavaan
In-Reply-To: <558971ce.43e8420a.97818.0a8d@mx.google.com>
References: <558971ce.43e8420a.97818.0a8d@mx.google.com>
Message-ID: <CAM_vjunR5=ihG8LGk4mHu0Vb=82wExMO-yAYB_5Q-2NqqB9g4w@mail.gmail.com>

Hi,

There are various tutorials for lavaan online, and even an entire book
on the R package. Have you worked through those examples and tutorials
successfully? If so, a clearer description of what you've tried and
what failed is required to be able to help you.

Without a reproducible example that includes some sample data (fake is
fine), the code you used, and some clear idea of what output you
expect, it's impossible to figure out how to help you. Here are some
suggestions for creating a good reproducible example:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Sarah

On Tue, Jun 23, 2015 at 10:48 AM, DzR <devazresearch at gmail.com> wrote:
> Dear Senior users of R/R Studio,
>
> I am very new to this environment hence am unable to plot the SEM models including use of graphic package ggplot.
>
> Request for some help in getting the plots please.
>
> Thanks,
>
> -----
> Deva

-- 
Sarah Goslee
http://www.functionaldiversity.org


From batholdy at googlemail.com  Tue Jun 23 17:54:35 2015
From: batholdy at googlemail.com (Martin Batholdy)
Date: Tue, 23 Jun 2015 17:54:35 +0200
Subject: [R] set par options once for entire R session
References: <3FC1DBA3-2908-4487-BC15-FBB49640D9DF@googlemail.com>
Message-ID: <E825A2BB-BC65-4BFA-A8DC-3F66BF240057@googlemail.com>

Hi,

I would like to set plot-options via par() and keep them for all plots that are created thereafter.
Currently after each plot device the parameters I can set with par() are reseted to their default value, at least on a Mac (R 3.2.1).

Is there a way to define the parameters for plotting once at the beginning and then keep them for an entire R session?


Thank you!


From petr.pikal at precheza.cz  Tue Jun 23 18:05:28 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 23 Jun 2015 16:05:28 +0000
Subject: [R] time management graph
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C31F7E@SRVEXCHMBX.precheza.cz>

Dear all

Did anybody tried to do time management graphs in R?

I could do some aggregation

xtabs(duration~person+Typ, data=temp)

but I would like to make also a graph to show which task (Typ) and when was done by which person. The closest I came till this evening is following graph, but it is not exactly what I want.

library(ggplot2)
p<-ggplot(temp, aes(x=time, y=Typ, colour=person))
p+geom_line()

If anybody can focus me to proper functions or packages I would be greatful.

Here are the data.

temp <- structure(list(Akce = structure(c(16L, 18L, 20L, 13L, 1L, 15L,
4L, 12L, 8L, 22L, 16L, 15L, 5L, 24L, 13L, 16L, 6L, 1L, 15L, 11L,
1L, 5L, 24L, 7L, 1L, 10L, 21L, 23L, 3L, 2L, 9L, 14L, 17L, 20L,
13L, 14L, 19L, 14L, 4L, 1L, 15L, 5L, 24L, 13L, 15L, 1L, 14L,
11L, 15L, 5L, 24L, 7L, 1L, 10L, 14L, 23L, 3L, 2L, 9L), .Label = c("a",
"b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l", "m", "n",
"o", "p", "q", "r", "s", "t", "u", "v", "w", "x"), class = "factor"),
    Typ = structure(c(4L, 6L, 6L, 6L, 2L, 6L, 6L, 1L, 1L, 8L,
    4L, 6L, 6L, 6L, 6L, 4L, 1L, 2L, 6L, 5L, 2L, 6L, 6L, 6L, 2L,
    3L, 4L, 6L, 7L, 4L, 4L, 7L, 7L, 6L, 6L, 7L, 6L, 7L, 6L, 2L,
    6L, 6L, 6L, 6L, 6L, 2L, 7L, 5L, 6L, 6L, 6L, 6L, 2L, 3L, 7L,
    6L, 7L, 4L, 4L), .Label = c("A", "B", "C", "D", "E", "F",
    "G", "H"), class = "factor"), person = structure(c(1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("One",
    "Two"), class = "factor"), time = structure(c(1435038600,
    1435039200, 1435039800, 1435040100, 1435040400, 1435040760,
    1435042200, 1435042680, 1435043220, 1435043400, 1435043700,
    1435044300, 1435044600, 1435045200, 1435046400, 1435046700,
    1435047000, 1435047300, 1435047600, 1435048800, 1435050600,
    1435051200, 1435051800, 1435053300, 1435053900, 1435054500,
    1435060800, 1435061700, 1435062000, 1435064400, 1435068000,
    1435038600, 1435039200, 1435039800, 1435040100, 1435040280,
    1435041060, 1435041600, 1435042200, 1435042800, 1435043400,
    1435044600, 1435045200, 1435046400, 1435047000, 1435047300,
    1435047600, 1435048800, 1435050600, 1435051200, 1435051800,
    1435053300, 1435053900, 1435054500, 1435060800, 1435061700,
    1435062000, 1435065600, 1435068000), class = c("POSIXct",
    "POSIXt"), tzone = ""), duration = c(10, 10, 5, 5, 6, 24,
    8, 9, 3, 5, 10, 5, 10, 20, 5, 5, 5, 5, 20, 30, 10, 10, 25,
    10, 10, 105, 15, 5, 40, 60, NA, 10, 10, 5, 3, 13, 9, 10,
    10, 10, 20, 10, 20, 10, 5, 5, 20, 30, 10, 10, 25, 10, 10,
    105, 15, 5, 60, 40, NA)), .Names = c("Akce", "Typ", "person",
"time", "duration"), class = "data.frame", row.names = c(NA,
-59L))
>

Best regards
Petr


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From devazresearch at gmail.com  Tue Jun 23 18:47:05 2015
From: devazresearch at gmail.com (deva d)
Date: Tue, 23 Jun 2015 22:17:05 +0530
Subject: [R] Lavaan
In-Reply-To: <CAM_vjunR5=ihG8LGk4mHu0Vb=82wExMO-yAYB_5Q-2NqqB9g4w@mail.gmail.com>
References: <558971ce.43e8420a.97818.0a8d@mx.google.com>
	<CAM_vjunR5=ihG8LGk4mHu0Vb=82wExMO-yAYB_5Q-2NqqB9g4w@mail.gmail.com>
Message-ID: <CAKuYVCVwrUjKnTeA9uhyKYnwfZ_MrK7669OW7y=JQv1qU35T-Q@mail.gmail.com>

i am attaching a .csv file, and the associated code worked out in R Studio.

i used the lavaan and sem packages, and conducted it.

now, i wish to draw the SEM model, as is available in AMOS other packages
and how does one draw the covariance arrows in R.

ONE STATISTICS oriented question - how can one provide interpretation for
negative coefficients.

kindly guide.

thanks and regds,





taxliability <- read.csv("~/R WORK SPACE/taxliability.csv")
>   View(taxliability)
> model <-'tax~ inc + exp + svg + inv'
> fit <- sem(model, data = taxliability)
Error: could not find function "sem"
> library("lavaan", lib.loc="~/R/win-library/3.2")
This is lavaan 0.5-18
lavaan is BETA software! Please report any bugs.
> fit <- sem(model, data = taxliability)
Warning message:
In lav_model_vcov(lavmodel = lavmodel, lavsamplestats = lavsamplestats,  :
  lavaan WARNING: could not compute standard errors!
  lavaan NOTE: this may be a symptom that the model is not identified.

> library("sem", lib.loc="~/R/win-library/3.2")
Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]])
:
  there is no package called ?htmlwidgets?
Error: package or namespace load failed for ?sem?
> fit <- sem(model, data = taxliability)
Warning message:
In lav_model_vcov(lavmodel = lavmodel, lavsamplestats = lavsamplestats,  :
  lavaan WARNING: could not compute standard errors!
  lavaan NOTE: this may be a symptom that the model is not identified.

> summary(fit,rsq=T, fit.measures=TRUE)
lavaan (0.5-18) converged normally after   1 iterations

  Number of observations                            66

  Estimator                                         ML
  Minimum Function Test Statistic                0.000
  Degrees of freedom                                 0

Model test baseline model:

  Minimum Function Test Statistic              160.444
  Degrees of freedom                                 4
  P-value                                        0.000

User model versus baseline model:

  Comparative Fit Index (CFI)                    1.000
  Tucker-Lewis Index (TLI)                       1.000

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -3441.453
  Loglikelihood unrestricted model (H1)      -3441.453

  Number of free parameters                          5
  Akaike (AIC)                                6892.905
  Bayesian (BIC)                              6903.854
  Sample-size adjusted Bayesian (BIC)         6888.113

Root Mean Square Error of Approximation:

  RMSEA                                          0.000
  90 Percent Confidence Interval          0.000  0.000
  P-value RMSEA <= 0.05                          1.000

Standardized Root Mean Square Residual:

  SRMR                                           0.000

Parameter estimates:

  Information                                 Expected
  Standard Errors                             Standard

                   Estimate  Std.err  Z-value  P(>|z|)
Regressions:
  tax ~
    inc               0.103
    exp              -0.023
    svg              -0.073
    inv               0.222

Variances:
    tax           4662558.169

R-Square:

    tax               0.912

 semPlot
Error: object 'semPlot' not found
> library("semPlot", lib.loc="~/R/win-library/3.2")
Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]])
:
  there is no package called ?htmlwidgets?
Error: package or namespace load failed for ?semPlot?
> semPlot::
Error: unexpected end of line in "semPlot::"
>




*....*

*Deva*


...............



*in search of knowledge, everyday something is added ....*

*in search of wisdom, everyday something is dropped  ... an old Chinese
Proverb*
:::::::::::::::::::::::::

On Tue, Jun 23, 2015 at 9:03 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Hi,
>
> There are various tutorials for lavaan online, and even an entire book
> on the R package. Have you worked through those examples and tutorials
> successfully? If so, a clearer description of what you've tried and
> what failed is required to be able to help you.
>
> Without a reproducible example that includes some sample data (fake is
> fine), the code you used, and some clear idea of what output you
> expect, it's impossible to figure out how to help you. Here are some
> suggestions for creating a good reproducible example:
>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> Sarah
>
> On Tue, Jun 23, 2015 at 10:48 AM, DzR <devazresearch at gmail.com> wrote:
> > Dear Senior users of R/R Studio,
> >
> > I am very new to this environment hence am unable to plot the SEM models
> including use of graphic package ggplot.
> >
> > Request for some help in getting the plots please.
> >
> > Thanks,
> >
> > -----
> > Deva
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>

From g.kautzmann at gmail.com  Tue Jun 23 18:19:31 2015
From: g.kautzmann at gmail.com (Guillaume Kautzmann)
Date: Tue, 23 Jun 2015 18:19:31 +0200
Subject: [R] 3D point cloud fitting
Message-ID: <CAA3YVcYUiqCvkDbdyO5esc9OFTc8Gair_NFiYQd5JXeckdUC+A@mail.gmail.com>

Hi all,

Hopefully I post that correctly as I use "r-help" for the first time.
I wish to best-fit a 3D point cloud on another one, preferably with a
least-square adjustement method. Is there any existing solution (package,
function,...) available?
Here is a sample of my data where I want to fit the nominal on the measured
points (identification by the name), the point clouds are not matching
perfectly.

measured points:
   Name X Y Z  LH 17320.201 270.705 -344.385  LL 17319.695 270.709 -356.391
RH 17320.215 -269.783 -344.623  RL 17319.738 -269.791 -356.642

nominal points
   Name X Y Z  LH 4.627 270.1359368 -346.0554962  LL 4.63 270.1264744
-358.0371904  RH 4.336 -270.2775009 -346.043514  RL 4.29 -270.2889739
-358.0252081  R 4.581 -270.251483 -274.4168414  L 4.531 270.1487988
-274.4168417  C 0 0 0
Thanks in advance,
Guillaume

	[[alternative HTML version deleted]]


From tevang3 at gmail.com  Tue Jun 23 18:45:25 2015
From: tevang3 at gmail.com (Thomas Evangelidis)
Date: Tue, 23 Jun 2015 19:45:25 +0300
Subject: [R] ANOVA for multiple repeated measurements
Message-ID: <CAACvdx0s4idbiApqMhytLgpwBA9QPfcD0_Q9A+xy6rwUcOgFRg@mail.gmail.com>

?Greetings,

My dataset consist of the following columns:

Specimen C_flex   C_rigid   tau_flex    tau_rigid    R_flex
R_rigid1         0.1782   0.2975    0.3290      0.3223       0.4338
0.51002         0.0527   0.1097    0.1780      0.1038       0.2364
0.1086.....

where C, tau and R are statistical metrics that asses the performance of a
method in two modes, "flex" and "rigid. Essentially my data are paired,
they consist of 18 specimens which were analysed twice by my method, once
in "flex" mode and once in "rigid" mode, and I quantified the performance
of each specimen in each mode using 3 statistical metrics (C, tau, R). What
I want is to assess weather the overall performance of the method in the
two modes ("flex", "rigid") is significantly different. Or in other words,
whether the difference (C_flex, tau_flex, R_flex) vs (C_rigid, tau_rigid,
R_rigid) is statistically significant. Could someone give a hint of what
type of ANOVA I must use in R or point me to a relevant post?

PS: the most relevant R tutorial I found was this:
http://rtutorialseries.blogspot.cz/2011/02/r-tutorial-series-two-way-repeated.html
The author's dataset is like this:

subject schoolAge10 schoolAge15 schoolAge20 workAge10 workAge15
workAge201        1           5           5           3         1
   3        52        2           5           5           3         1
       3        5

But I am not sure whether he assess the significance of the difference
(schoolAge10, schoolAge15, schoolAge20) vs (workAge10 workAge15,
workAge20), or schoolAge10 vs workAge10 && schoolAge15 vs workAge15 &&
schoolAge20 vs workAge20.
?
thanks in advance,
Thomas

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jun 23 19:34:55 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 23 Jun 2015 10:34:55 -0700
Subject: [R] set par options once for entire R session
In-Reply-To: <E825A2BB-BC65-4BFA-A8DC-3F66BF240057@googlemail.com>
References: <3FC1DBA3-2908-4487-BC15-FBB49640D9DF@googlemail.com>
	<E825A2BB-BC65-4BFA-A8DC-3F66BF240057@googlemail.com>
Message-ID: <CAGxFJbS6-sZf6cwz27BqZkUn+oOYzJ2LPwW7EodRgeCaryPA-g@mail.gmail.com>

Martin:

One simple approach: write your own graphics functions that are simple
wrappers to the plot functions you use that set the par() values as
you wish. You could even put them in a package that is loaded at
startup. See ?Startup

My understanding is that so long as a graphics device remains open,
new plots on it will reuse the same par() settings. See,e.g.
?plot.new.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Jun 23, 2015 at 8:54 AM, Martin Batholdy via R-help
<r-help at r-project.org> wrote:
> Hi,
>
> I would like to set plot-options via par() and keep them for all plots that are created thereafter.
> Currently after each plot device the parameters I can set with par() are reseted to their default value, at least on a Mac (R 3.2.1).
>
> Is there a way to define the parameters for plotting once at the beginning and then keep them for an entire R session?
>
>
> Thank you!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From syen04 at gmail.com  Tue Jun 23 23:39:37 2015
From: syen04 at gmail.com (Steven Yen)
Date: Tue, 23 Jun 2015 17:39:37 -0400
Subject: [R] Call to a function
In-Reply-To: <5589D070.4070900@gmail.com>
References: <5589D070.4070900@gmail.com>
Message-ID: <5589D219.5070001@gmail.com>

Dear Members
I have a data frame as generated below. I like to be able to call a
function both with a vector and a vector (mydata$v1) in that data frame
(v1). The first call works, but the second does not. Can someone help me
with the second call? Thanks!!

---
mydata<-data.frame(matrix(1:20,ncol=2))
colnames(mydata) <-c("v1","v2")
summary(mydata)

aaa<-function(data,w=w){
   if(is.vector(w)){
     out<-mean(w)
   } else {
     out<-mean(data[wt])
   }
return(out)
}

aaa(mydata,mydata$v1)
aaa(mydata,"v1")      # want this call to work

---
Printout with error message

> mydata<-data.frame(matrix(1:20,ncol=2))
> colnames(mydata) <-c("v1","v2")
> summary(mydata)
        v1              v2
  Min.   : 1.00   Min.   :11.00
  1st Qu.: 3.25   1st Qu.:13.25
  Median : 5.50   Median :15.50
  Mean   : 5.50   Mean   :15.50
  3rd Qu.: 7.75   3rd Qu.:17.75
  Max.   :10.00   Max.   :20.00
>
> aaa<-function(data,w=w){
+   if(is.vector(w)){
+     out<-mean(w)
+   } else {
+     out<-mean(data[wt])
+   }
+ return(out)
+ }
> aaa(mydata,mydata$v1)
[1] 5.5
> aaa(mydata,"v1")
[1] NA
Warning message:
In mean.default(w) : argument is not numeric or logical: returning NA
>


From bob at rudis.net  Wed Jun 24 00:20:51 2015
From: bob at rudis.net (boB Rudis)
Date: Tue, 23 Jun 2015 18:20:51 -0400
Subject: [R] Call to a function
In-Reply-To: <5589D219.5070001@gmail.com>
References: <5589D070.4070900@gmail.com> <5589D219.5070001@gmail.com>
Message-ID: <CAJ4QxaNuMjXbRwDafabHTN1iDT95+ZS0mhdJsrGfRqnskR0JMQ@mail.gmail.com>

You can do something like:

aaa <- function(data, w=w) {
  if (class(w) %in% c("integer", "numeric", "double")) {
    out <- mean(w)
  } else {
    out <- mean(data[, w])
  }
  return(out)
}

(there are some typos in your function you may want to double check, too)

On Tue, Jun 23, 2015 at 5:39 PM, Steven Yen <syen04 at gmail.com> wrote:
> mydata<-data.frame(matrix(1:20,ncol=2))
> colnames(mydata) <-c("v1","v2")
> summary(mydata)
>
> aaa<-function(data,w=w){
>   if(is.vector(w)){
>     out<-mean(w)
>   } else {
>     out<-mean(data[wt])
>   }
> return(out)
> }
>
> aaa(mydata,mydata$v1)
> aaa(mydata,"v1")      # want this call to work


From syen04 at gmail.com  Wed Jun 24 01:37:03 2015
From: syen04 at gmail.com (Steven Yen)
Date: Tue, 23 Jun 2015 19:37:03 -0400
Subject: [R] Call to a function
In-Reply-To: <CAJ4QxaNuMjXbRwDafabHTN1iDT95+ZS0mhdJsrGfRqnskR0JMQ@mail.gmail.com>
References: <5589D070.4070900@gmail.com> <5589D219.5070001@gmail.com>
	<CAJ4QxaNuMjXbRwDafabHTN1iDT95+ZS0mhdJsrGfRqnskR0JMQ@mail.gmail.com>
Message-ID: <5589ED9F.7020801@gmail.com>

Thanks! From this I learn the much needed class statement

     if (class(wt)=="character") wt <- x[, wt]

which serves my need in a bigger project.

Steven Yen

On 6/23/2015 6:20 PM, boB Rudis wrote:
> You can do something like:
>
> aaa <- function(data, w=w) {
>    if (class(w) %in% c("integer", "numeric", "double")) {
>      out <- mean(w)
>    } else {
>      out <- mean(data[, w])
>    }
>    return(out)
> }
>
> (there are some typos in your function you may want to double check, too)
>
> On Tue, Jun 23, 2015 at 5:39 PM, Steven Yen <syen04 at gmail.com> wrote:
>> mydata<-data.frame(matrix(1:20,ncol=2))
>> colnames(mydata) <-c("v1","v2")
>> summary(mydata)
>>
>> aaa<-function(data,w=w){
>>    if(is.vector(w)){
>>      out<-mean(w)
>>    } else {
>>      out<-mean(data[wt])
>>    }
>> return(out)
>> }
>>
>> aaa(mydata,mydata$v1)
>> aaa(mydata,"v1")      # want this call to work
>

-- 
Steven Yen
My e-mail alert:
https://youtu.be/9UwEAruhyhY?list=PLpwR3gb9OGHP1BzgVuO9iIDdogVOijCtO


From bgunter.4567 at gmail.com  Wed Jun 24 02:53:33 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 23 Jun 2015 17:53:33 -0700
Subject: [R] Call to a function
In-Reply-To: <5589D219.5070001@gmail.com>
References: <5589D070.4070900@gmail.com>
	<5589D219.5070001@gmail.com>
Message-ID: <CAGxFJbQ0f6wdPpKLr3APuERuGVwvBia-fvo45MHrDX+QaqR7dA@mail.gmail.com>

?with

e.g. with(mydata,aaa(v1))

-- Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Jun 23, 2015 at 2:39 PM, Steven Yen <syen04 at gmail.com> wrote:
> Dear Members
> I have a data frame as generated below. I like to be able to call a
> function both with a vector and a vector (mydata$v1) in that data frame
> (v1). The first call works, but the second does not. Can someone help me
> with the second call? Thanks!!
>
> ---
> mydata<-data.frame(matrix(1:20,ncol=2))
> colnames(mydata) <-c("v1","v2")
> summary(mydata)
>
> aaa<-function(data,w=w){
>   if(is.vector(w)){
>     out<-mean(w)
>   } else {
>     out<-mean(data[wt])
>   }
> return(out)
> }
>
> aaa(mydata,mydata$v1)
> aaa(mydata,"v1")      # want this call to work
>
> ---
> Printout with error message
>
>> mydata<-data.frame(matrix(1:20,ncol=2))
>> colnames(mydata) <-c("v1","v2")
>> summary(mydata)
>
>        v1              v2
>  Min.   : 1.00   Min.   :11.00
>  1st Qu.: 3.25   1st Qu.:13.25
>  Median : 5.50   Median :15.50
>  Mean   : 5.50   Mean   :15.50
>  3rd Qu.: 7.75   3rd Qu.:17.75
>  Max.   :10.00   Max.   :20.00
>>
>>
>> aaa<-function(data,w=w){
>
> +   if(is.vector(w)){
> +     out<-mean(w)
> +   } else {
> +     out<-mean(data[wt])
> +   }
> + return(out)
> + }
>>
>> aaa(mydata,mydata$v1)
>
> [1] 5.5
>>
>> aaa(mydata,"v1")
>
> [1] NA
> Warning message:
> In mean.default(w) : argument is not numeric or logical: returning NA
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From steve.taylor at aut.ac.nz  Wed Jun 24 02:56:26 2015
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Wed, 24 Jun 2015 00:56:26 +0000
Subject: [R] Call to a function
In-Reply-To: <5589ED9F.7020801@gmail.com>
References: <5589D070.4070900@gmail.com> <5589D219.5070001@gmail.com>
	<CAJ4QxaNuMjXbRwDafabHTN1iDT95+ZS0mhdJsrGfRqnskR0JMQ@mail.gmail.com>
	<5589ED9F.7020801@gmail.com>
Message-ID: <CCE952776B6679469977532BD863C39CB2B11745@Patterson.autuni.aut.ac.nz>

Note that objects can have more than one class, in which case your == and %in% might not work as expected.  

Better to use inherits().

cheers,
    Steve

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Steven Yen
Sent: Wednesday, 24 June 2015 11:37a
To: boB Rudis
Cc: r-help mailing list
Subject: Re: [R] Call to a function

Thanks! From this I learn the much needed class statement

     if (class(wt)=="character") wt <- x[, wt]

which serves my need in a bigger project.

Steven Yen

On 6/23/2015 6:20 PM, boB Rudis wrote:
> You can do something like:
>
> aaa <- function(data, w=w) {
>    if (class(w) %in% c("integer", "numeric", "double")) {
>      out <- mean(w)
>    } else {
>      out <- mean(data[, w])
>    }
>    return(out)
> }
>
> (there are some typos in your function you may want to double check, too)
>
> On Tue, Jun 23, 2015 at 5:39 PM, Steven Yen <syen04 at gmail.com> wrote:
>> mydata<-data.frame(matrix(1:20,ncol=2))
>> colnames(mydata) <-c("v1","v2")
>> summary(mydata)
>>
>> aaa<-function(data,w=w){
>>    if(is.vector(w)){
>>      out<-mean(w)
>>    } else {
>>      out<-mean(data[wt])
>>    }
>> return(out)
>> }
>>
>> aaa(mydata,mydata$v1)
>> aaa(mydata,"v1")      # want this call to work
>

-- 
Steven Yen
My e-mail alert:
https://youtu.be/9UwEAruhyhY?list=PLpwR3gb9OGHP1BzgVuO9iIDdogVOijCtO

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gianni.lavaredo at gmail.com  Wed Jun 24 03:28:52 2015
From: gianni.lavaredo at gmail.com (gianni lavaredo)
Date: Tue, 23 Jun 2015 19:28:52 -0600
Subject: [R] Repeated Measures ANOVA and the Bonferroni post hoc test
 different results of significantly
Message-ID: <CAJ6JbR8Cjfcp+qncHYkQnQhDEBr+OFRYzBvsy1tv1_H75cDcSw@mail.gmail.com>

Hi All and thanks for Help

I am doing an Repeated Measures ANOVA and the Bonferroni post hoc test for
my data using R project. The ANOVA gives a significantly difference between
the data but not the  Bonferroni post hoc test.

    > anova(aov2)
                numDF denDF   F-value p-value
    (Intercept)     1  1366 110.51125  <.0001
    time            5  1366   9.84684  <.0001

while

    > pairwise.t.test(x=table.metric2$value, g=table.metric2$time,
p.adj="bonf")

            Pairwise comparisons using t tests with pooled SD

    data:  table.metric2$value and table.metric2$time

        Su1 Su2 Su3 Su4 Su5
    Su2 1   -   -   -   -
    Su3 1   1   -   -   -
    Su4 1   1   1   -   -
    Su5 1   1   1   1   -
    Su6 1   1   1   1   1

    P value adjustment method: bonferroni

These are my data with the code used


    plot <- c(rep(1:275))

    Su1 <- c(13.5584,0.0000,2.0710,0.4826,1.2761,1.6690,3.5188,
13.7578,0.0000,0.0000,0.0004,0.0000,0.0000,0.0000,4.4634,3.0151,2.1719,5.2861,4.9651,0.7908,0.0000,0.0000,0.0000,0.0000,

0.0000,5.2749,5.4706,4.4416,3.2166,0.0000,0.1929,0.0000,0.0000,0.0000,0.0000,0.0000,4.6765,1.7761,4.3579,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,

0.0000,6.1794,2.4194,1.4319,0.0000,0.0327,0.0000,0.4633,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0018,0.0000,0.0000,

0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,

0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.5425,0.5274,2.0883,0.6024,0.0000,0.0018,0.0000,0.0000,0.0015,0.0012,0.0000,0.0000,0.0000,

0.4560,2.1256,0.0295,0.0328,0.0000,1.6447,0.0428,0.0067,0.0058,0.0000,0.0000,0.0000,0.0001,0.3317,0.2898,3.5134,0.1539,0.0199,0.0000,0.0494,0.1159,2.0976,0.0644,0.9730,

0.0010,0.5074,0.0003,0.0000,0.1188,1.8818,0.0000,0.1213,0.3585,7.3932,0.5492,0.0045,0.9879,0.0010,0.7625,0.1695,0.1211,0.3164,2.6750,3.8926,0.0000,3.4626,0.0000,5.8339,

6.7315,0.0244,4.8770,2.6237,2.3700,0.5338,0.0215,3.2196,1.9811,3.3825,3.3929,1.5426,0.9165,
10.6561,3.2154,4.1531,5.3381,3.9432,4.8675,0.0047,0.0026,0.2058,1.8509,0.3697,
    0.3131,0.0707,4.7908,6.4087,
10.3670,5.7662,4.0460,3.2571,9.1767,0.0116,0.0908,0.0053,0.1480,0.9063,5.4331,5.7945,
14.4097,6.9635,7.0637,0.1064,9.9095, 11.8432, 10.0234,0.0000,
    0.0491,5.0472,5.3094,5.1657, 14.3944,7.6244,0.0034,1.4953,
14.7658,6.1775,7.1567,0.0296,0.0911,3.5552,4.9543,3.1200,1.9774,0.0000,4.1663,0.0000,2.3672,0.0638,1.8952,4.1948,
    6.4229,
10.7573,0.0008,1.3818,6.0011,3.6791,9.7816,1.5203,0.8616,1.5483,5.4174,2.7070,2.1627,0.0000,1.7360,3.7292,2.4638,7.4498,4.2343,6.8263,3.2410,0.0001,0.0001,9.7424,
    4.2861,2.9912,0.4316,
11.6082,2.0138,0.0002,1.8783,0.9934,0.2983,1.4013,0.1429)

    Su2 <- c(10.4361,0.0000,2.3346,0.5769,1.3392,1.5908,3.5759,
13.3183,0.0005,0.0000,0.0019,0.0000,0.0000,0.0000,4.4862,3.0418,2.3991,5.4263,4.9456,0.6907,0.0000,0.0007,0.0000,0.0000,

0.0000,5.1065,5.1748,4.2888,3.3633,0.0000,0.1791,0.0000,0.0000,0.0000,0.0000,0.0000,5.3485,1.9216,4.2880,0.0000,0.0001,0.0001,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,

0.0000,6.3664,2.2888,1.4636,0.0000,0.0282,0.0000,0.5838,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0013,0.0000,0.0000,

0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0002,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,

0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.6240,0.6401,1.9324,0.6263,0.0000,0.0020,0.0000,0.0001,0.0039,0.0018,0.0000,0.0000,0.0000,

0.4321,1.9815,0.0528,0.0350,0.0000,1.6519,0.0328,0.0153,0.0171,0.0000,0.0000,0.0000,0.0000,0.3966,0.2957,3.4653,0.1473,0.0038,0.0000,0.0774,0.1180,2.2780,0.0611,0.9490,

0.0024,0.8337,0.0000,0.0000,0.1531,1.9778,0.0000,0.1171,0.3485,7.2378,0.7476,0.0028,1.2072,0.0015,0.7425,0.1352,0.1908,0.3092,2.3735,3.9768,0.0000,3.8786,0.0000,6.5420,

6.8490,0.0256,5.8268,2.7856,2.4640,0.6399,0.0215,5.3411,1.7939,3.3401,3.2942,1.4990,0.9264,
10.6864,3.3749,4.7978,5.2929,3.8639,5.3890,0.0027,0.0486,0.2105,1.8514,0.3526,
    0.3146,0.0950,4.8061,6.2244,
10.1131,5.8538,3.8861,4.4240,9.5952,0.0255,0.0533,0.0085,0.1742,1.0188,7.7153,5.4663,14.6060,6.8725,6.7284,0.0841,
10.2016, 11.3384,9.8938,0.0000,
    0.0749,5.0774,7.2876,5.2040, 14.7609,7.7862,0.0005,1.4099,
14.8639,6.8801,7.2587,0.0125,0.0513,3.1338,7.1539,3.1733,1.9729,0.0000,4.5081,0.0000,2.1572,0.0452,1.8866,8.0198,
    9.7868,
10.8746,0.0000,1.5011,6.0825,3.6705,9.9171,1.7091,0.8267,1.4186,6.4235,2.9303,1.9019,0.0000,1.5869,4.4028,2.4186,7.7739,4.6728,8.7722,3.9859,0.0001,0.0001,
10.1583,
    5.4758,2.8977,0.9716,
11.5342,2.6111,0.0000,1.7497,1.0041,0.3273,1.1953,0.2289)

    Su3 <-
c(12.5808,0.0000,2.7244,0.1119,1.2633,0.9702,2.4513,2.4419,0.0014,0.0000,0.0000,0.0000,0.0019,0.0105,3.5392,2.4033,2.1847,5.5912,4.8628,0.9449,0.0000,0.0000,0.0000,0.0000,

0.0000,4.2928,5.0754,3.4644,2.8663,0.0066,0.0043,0.0000,0.0000,0.0000,0.0000,0.0000,3.5292,1.4846,4.6333,0.0000,0.0003,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,

0.0000,7.0110,2.7508,2.0824,0.0001,0.0001,0.0000,0.0770,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0023,0.0000,0.0000,

0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,

0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.4546,0.1491,2.2391,0.4464,0.0000,0.0007,0.0000,0.0000,0.0000,0.0238,0.0000,0.0000,0.0000,

0.5663,1.5734,0.0247,0.0259,0.0000,0.6823,0.0101,0.0000,0.1171,0.0000,0.0000,0.0000,0.0000,0.1110,0.0960,2.2888,0.1338,0.0000,0.0000,0.0294,0.1273,2.3082,0.0081,0.6343,

0.0021,0.1690,0.0000,0.0000,0.3456,1.7644,0.0000,0.0175,0.1027,9.8583,0.5133,0.0002,0.8704,0.0000,0.0850,0.1183,0.0949,0.0369,2.8741,1.0065,0.0000,4.6330,0.0000,7.7170,

7.7201,0.0038,3.7342,2.6457,1.6262,0.2836,0.0008,2.2052,2.6186,3.1951,5.4121,0.5787,1.4276,
12.5830,5.0891,3.7475,4.8317,0.3612,5.0634,0.0001,0.0002,0.2396,2.8372,0.5667,

0.0024,0.0396,4.4980,6.6203,11.8869,7.5642,4.4144,1.1202,7.8870,0.0214,0.0323,0.0000,0.1492,1.0881,3.4938,6.4025,
13.7996,5.3475,7.2365,0.4289, 10.5106, 12.1750,7.8348,0.0000,
    0.0104,0.0126,4.7145,3.5840,11.1274,7.1017,0.4464,1.3384,
14.9060,4.1969,7.7008,0.0214,0.0022,2.6731,1.7724,3.0937,1.3026,1.1184,1.0817,0.0000,1.6675,0.0879,1.6432,4.3482,
    3.5927,3.3646,0.0000,1.2088,2.6632,2.6712,
10.0635,6.1788,0.9486,0.8011,2.5326,5.1218,0.1574,0.0000,1.7523,5.2613,2.8762,6.7293,7.9969,3.7011,1.9242,0.0002,0.0000,6.8359,

3.4735,4.8440,1.0125,4.3772,1.9227,0.0034,1.0078,2.7654,0.0246,0.4001,0.2570)

    Su4 <-
c(NA,0.0001,NA,0.3616,0.2848,1.5804,3.2575,6.9722,0.0000,0.0053,0.0001,0.0000,0.0002,0.0000,4.9185,3.6967,1.9675,7.7624,4.0516,0.7658,0.0001,0.0018,0.0000,0.0000,

0.0000,5.4964,5.2645,5.0756,1.9665,0.0011,0.3481,0.0001,0.0000,0.0000,0.0000,0.0000,4.6501,1.6375,1.1133,0.0016,0.0063,0.0007,0.0000,0.0001,0.0008,0.0000,0.0000,0.0000,

0.0000,5.9308,2.0694,0.3611,0.0035,0.0126,0.0000,0.4887,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0001,0.0000,0.0000,

0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0002,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,

0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.6246,0.4996,1.2273,0.5902,0.0000,0.0016,0.0000,0.0000,0.0004,0.0010,0.0000,0.0000,0.0000,

0.4431,1.6631,0.0234,0.0230,0.0000,1.4833,0.0134,0.0321,0.0283,0.0000,0.0000,0.0000,0.0000,0.2446,0.1740,3.4582,0.0757,0.0092,0.0000,0.0202,0.1099,2.1932,0.0565,0.9499,

0.0176,0.2146,0.0001,0.0000,0.1009,1.8096,0.0000,0.0413,0.2970,7.6015,0.4349,0.0121,0.8901,0.0024,0.4629,0.0843,0.0934,0.2790,2.5034,3.0369,0.0000,4.1673,0.0000,6.2014,

5.6363,0.0211,5.2860,2.7722,1.7316,0.3452,0.0099,2.6113,1.8183,3.2228,3.1208,1.4761,0.9326,9.7211,4.4282,4.0727,5.1978,3.3293,5.8666,0.0013,0.0413,0.0958,1.3760,0.2844,
    0.1587,0.0197,3.4947,6.2988,
10.5278,5.6255,3.7482,4.0839,9.5720,0.0113,0.0060,0.0005,0.2592,1.1092,6.5303,5.7979,
15.0240,6.6722,7.0578,0.0507,9.6608, 12.2310,7.6133,0.0002,
    0.0147,4.6729,4.1950,5.4444, 13.3876,8.7654,0.0001,1.3864,
15.5325,5.2633,9.7407,0.0160,0.0069,3.3050,7.6701,2.8048,1.1736,0.0000,4.8370,0.0000,1.4801,0.0014,1.3862,7.8413,
    3.9453,11.0588,0.0000,1.7270,6.0988,4.2754,
10.7927,1.1768,0.6381,0.1779,6.2290,2.9297,0.4520,0.0012,0.9822,6.6041,2.8147,6.9679,3.5493,9.5997,4.5469,0.0007,0.0004,6.7922,
    5.2609,2.4192,0.0459,
10.4127,3.9877,0.0000,1.1876,0.8595,0.5107,0.8049,0.1749)

    Su5 <- c(10.4824,0.0000,2.0018,0.2817,1.0086,1.1640,2.6718,
11.2732,0.0000,0.0000,0.0003,0.0000,0.0000,0.0000,5.1846,3.1089,1.6050,5.3045,5.1410,0.7458,0.0000,0.0000,0.0000,0.0000,

0.0000,5.8211,5.6094,4.2910,2.6412,0.0000,0.0404,0.0000,0.0000,0.0000,0.0000,0.0000,4.8222,1.7778,1.6938,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,

0.0000,5.3706,2.1161,0.5845,0.0000,0.0154,0.0000,0.6280,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0001,0.0000,0.0000,

0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,

0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.5967,0.6631,1.2776,0.8574,0.0000,0.0010,0.0000,0.0000,0.0016,0.0010,0.0000,0.0000,0.0000,

0.4013,1.7534,0.0341,0.0360,0.0000,1.8029,0.0163,0.0280,0.0541,0.0000,0.0000,0.0000,0.0000,0.2873,0.2288,3.3035,0.0943,0.0277,0.0000,0.0273,0.1230,1.1606,0.0553,0.9261,

0.0006,0.2793,0.0001,0.0000,0.0702,1.7861,0.0000,0.0441,0.6919,7.2771,0.4737,0.0001,0.9996,0.0028,0.7776,0.0760,0.2064,0.3322,2.1804,3.8545,0.0000,3.8377,0.0000,6.0567,

6.7315,0.0168,6.6603,2.2872,2.7505,0.6174,0.0235,2.5142,1.3832,3.0431,2.3944,1.4855,0.5978,9.6032,3.2907,3.7126,5.1397,3.7415,5.0454,0.0003,0.0361,0.0761,1.4128,0.3045,

0.4881,0.0392,3.8213,5.8874,9.9054,4.9779,3.2351,4.7589,9.2551,0.0108,0.0184,0.0086,0.1905,1.0657,8.1882,5.5578,
14.6536,7.3801,7.8668,0.0315,9.0087, 10.1677,9.6868,0.0001,
    0.0797,5.6032,5.4432,5.9958, 15.4570,8.1095,0.0000,1.1854,
14.0602,5.9429,8.4364,0.0056,0.0163,4.0671,5.5083,3.2078,1.8711,0.0000,6.0628,0.0000,1.8110,0.0941,1.8252,8.3102,

9.3829,5.5418,0.0000,1.4030,8.6327,4.3226,9.3724,1.6725,1.0198,1.4480,6.7463,1.7035,1.3542,0.0000,1.4079,4.2148,2.6589,7.3225,4.6582,9.1156,4.0312,0.0000,0.0000,9.2176,

5.5112,2.1917,0.5516,9.7061,2.7556,0.0000,1.0919,1.0696,0.5361,1.0160,0.1019)

    Su6 <-
c(9.3294,0.0001,1.7365,0.2030,0.5796,0.3794,2.4745,0.0104,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,2.2045,2.8210,1.0607,4.9375,0.0892,1.1530,0.0000,0.0000,0.0000,0.0000,

0.0000,5.5562,5.9813,4.6396,3.0815,0.0000,0.1245,0.0000,0.0000,0.0000,0.0000,0.0000,4.4952,1.3822,5.3511,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,

0.0000,2.4023,0.3491,2.0235,0.0000,0.0469,0.0000,0.3316,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,

0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,

0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.5361,0.5083,2.4144,1.6541,0.0000,0.0009,0.0000,0.0000,0.0007,0.0084,0.0000,0.0000,0.0000,

0.7155,2.4862,2.8153,2.0548,0.0000,1.0062,0.1725,0.0028,0.0404,0.0000,0.0000,0.0000,0.0000,2.0952,1.8754,2.3209,0.1329,0.0025,0.0000,0.0134,0.1656,1.9201,0.0624,0.9148,

0.2393,1.8717,0.0000,0.0000,0.2733,1.3219,0.0000,0.0502,0.4294,6.5172,0.4368,0.0001,2.5930,0.0024,1.1465,0.0857,0.1336,0.1791,2.2427,1.7424,0.0000,4.5865,0.0000,7.4015,

5.1587,0.0953,1.9529,1.7191,2.6812,1.0850,0.0133,3.5750,1.3194,2.2280,2.7217,2.5155,0.6812,
10.1853,0.3850,4.3999,3.9028,1.5311,5.2335,0.0006,0.0359,0.2206,1.5833,0.1611,
    0.2389,0.2579,4.7568,5.7652,
11.4255,3.1828,1.8413,3.6434,6.6662,0.0148,0.0166,0.0284,0.4646,1.2736,5.3859,6.2033,
14.0715,5.1563,7.2547,0.0163,9.8463,9.7350,7.7685,0.0015,
    0.0694,2.4957,5.9204,3.0981, 13.9429,6.0630,0.0000,0.4167,
16.6025,8.0124,6.8630,0.0314,0.0453,5.1017,7.6560,2.2824,1.6168,0.0000,1.5369,0.0000,1.4277,0.1390,1.3599,5.5345,
    7.0305,4.4969,0.0000,1.4448,3.2237,3.5196,
11.8150,1.1668,0.5838,1.5561,2.9927,1.8511,1.4603,0.0000,1.2046,1.1346,2.0005,7.2672,6.1411,3.1801,1.8131,0.0005,0.0000,4.1790,
    3.8307,1.0645,NA,NA,0.0119,0.0001,1.1278,0.1273,0.0837,0.0863,0.6916)

    table.metric <- data.frame(plot,Su1, Su2, Su3, Su4, Su5, Su6)
    plot <- table.metric$plot
    table.metric$plot <- NULL
    table.metric2 <- stack(table.metric)
    plot.metrics = factor(rep(plot,6))
    table.metric2[3] = plot.metrics
    names(table.metric2) <- c("value", "time", "plot")
    aov2 <- lme(fixed= value~time, random=~1|plot, na.action=na.omit,
data=table.metric2)
    summary(aov2)
    anova(aov2)
    pairwise.t.test(x=table.metric2$value, g=table.metric2$time,
p.adj="bonf")

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Jun 24 03:47:25 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 23 Jun 2015 18:47:25 -0700
Subject: [R] 3D point cloud fitting
In-Reply-To: <CAA3YVcYUiqCvkDbdyO5esc9OFTc8Gair_NFiYQd5JXeckdUC+A@mail.gmail.com>
References: <CAA3YVcYUiqCvkDbdyO5esc9OFTc8Gair_NFiYQd5JXeckdUC+A@mail.gmail.com>
Message-ID: <46572E0D-0086-451B-A224-B9024EA4EC39@dcn.davis.CA.us>

Your question seems unclear, and you posted using HTML which makes things even less clear (see the Posting Guide). Sharing data on the making list is much more effective using the dput function as described in [1].

I note that your X values are very different, but your Y and Z values are similar. Do you want to estimate a regression model X( Y, Z ) from your nominal data and replace the X values in your measured data?

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 23, 2015 9:19:31 AM PDT, Guillaume Kautzmann <g.kautzmann at gmail.com> wrote:
>Hi all,
>
>Hopefully I post that correctly as I use "r-help" for the first time.
>I wish to best-fit a 3D point cloud on another one, preferably with a
>least-square adjustement method. Is there any existing solution
>(package,
>function,...) available?
>Here is a sample of my data where I want to fit the nominal on the
>measured
>points (identification by the name), the point clouds are not matching
>perfectly.
>
>measured points:
>Name X Y Z  LH 17320.201 270.705 -344.385  LL 17319.695 270.709
>-356.391
>RH 17320.215 -269.783 -344.623  RL 17319.738 -269.791 -356.642
>
>nominal points
>   Name X Y Z  LH 4.627 270.1359368 -346.0554962  LL 4.63 270.1264744
>-358.0371904  RH 4.336 -270.2775009 -346.043514  RL 4.29 -270.2889739
>-358.0252081  R 4.581 -270.251483 -274.4168414  L 4.531 270.1487988
>-274.4168417  C 0 0 0
>Thanks in advance,
>Guillaume
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From t-haitani at akane.waseda.jp  Wed Jun 24 01:47:17 2015
From: t-haitani at akane.waseda.jp (Tomosumi Haitani)
Date: Wed, 24 Jun 2015 08:47:17 +0900
Subject: [R] Error in lsmeans function
Message-ID: <web-56490919@besv02.spw.secure-premium.ne.jp>

Dear members,

I would like to conduct nonparametric two way ANOVA (repeated 
measures) and post hoc test by using ARTool and lsmeans package.
I have the following data,

> x<-runif(120)
> A<-gl(3,40,labels=c("a1","a2","a3"))
> B<-gl(2,20,120,labels=c("b1","b2"))
> ID<-gl(20,1,120)
> data<-data.frame(ID,x,A,B)

Then, I use art function in the "ARTool" package,
> dataART<-art(x~A*B+(1|ID),data=data)

But when I use lsmeans function in "lsmeans" package for post hoc 
test, the next error is shown.
> lsmeans(artlm(dataART, "A"), pairwise ~ A)
NOTE: Results may be misleading due to involvement in interactions
$lsmeans
Error in format.default(nm[j], width = nchar(m[1, j]), just = "left") 
:
   4 arguments passed to .Internal(nchar) which requires 3

Would you mind telling me what is wrong?

Best Regards,


From akashdeep.hk at iqss.co.in  Wed Jun 24 07:15:54 2015
From: akashdeep.hk at iqss.co.in (akashdeep)
Date: Tue, 23 Jun 2015 22:15:54 -0700 (PDT)
Subject: [R] Returning the coefficient parameters from JRI
Message-ID: <1435122954110-4708987.post@n4.nabble.com>

Hi,

 I am trying to  run R summary command through JRI to get the result for
mulitvariate Linear Regression

 eg. result <- lm(Performance Score ~ Department+Grade,data = StudentData)
      summary(result)

  on running the above cmd using in R Console will fetch me below result:

Call:
lm(formula = Performace.Score ~ Department + Grade, data = tree)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.0146 -0.8472  0.1206  0.1528  1.3193 

Coefficients:
                                Estimate Std. Error t value Pr(>|t|)    
(Intercept)                    1.9085381  0.2063188   9.250   <2e-16 ***
DepartmentCentral Projects    -0.0618622  0.2086085  -0.297    0.767    
DepartmentConsulting Services -0.0529854  0.2104055  -0.252    0.801    
DepartmentDistribution        -0.2280968  0.2268197  -1.006    0.315    
DepartmentExecutive            0.0896884  0.4008410   0.224    0.823    
DepartmentFinance             -0.1366400  0.2503824  -0.546    0.585    
DepartmentHR                  -0.2093362  0.2544092  -0.823    0.411    
DepartmentIT                  -0.0301757  0.2236310  -0.135    0.893    
DepartmentLocal Projects       0.1047488  0.2099865   0.499    0.618    
DepartmentOperations           0.1009253  0.2078236   0.486    0.627    
DepartmentR&D                 -0.0436125  0.2115470  -0.206    0.837    
DepartmentSales               -0.1824861  0.2310936  -0.790    0.430    
Grade                          0.0002534  0.0139614   0.018    0.986    
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.6768 on 1492 degrees of freedom
Multiple R-squared:  0.0195,    Adjusted R-squared:  0.01161 
F-statistic: 2.472 on 12 and 1492 DF,  p-value: 0.00335



Now, When i try to run the same command through JRI and trying to get only
coefficients for same data ,will fetch below result :


[REAL* (1.9085381360123104, -0.061862224682688656, -0.0529853865573166,
-0.22809675152091768, 0.0896883836938513, -0.13664002290293625,
-0.20933620214453777, -0.03017568582453441, 0.10474877352108226,
0.10092534733241249, -0.04361245714602103, -0.1824861159548225,
2.5335432769115444E-4, 0.20631884004542614, 0.20860854811530719,
0.21040549853856627, 0.2268197334540003, 0.4008409534398062,
0.25038238782600725, 0.2544092401777455, 0.22363101707542418,
0.20998649433526015, 0.20782362789029826, 0.21154702570507078,
0.23109359545008445, 0.013961381053987209, 9.250430719715656,
-0.29654693080215805, -0.2518251040269494, -1.0056301012591409,
0.22375054974845454, -0.5457253766502479, -0.8228325433395539,
-0.13493515443055484, 0.49883576490325376, 0.48562980233261505,
-0.20615963283182023, -0.7896632340650002, 0.018146795557793288,
7.495625279329623E-20, 0.7668537059840453, 0.8012109343341197,
0.31475660028966584, 0.8229820424275262, 0.5853363050818626,
0.4107347156441347, 0.8926813449490922, 0.6179686247435434,
0.6273009677306218, 0.8366943459235678, 0.42984994326833603,
0.9855241729402933)]


>From the above result what i get from JRI,will fetch me only coefficient
values not the parameters like what we get in R Console(Departments list and
Grade in this Case).

So,my question is  how to get coefficient values along with parameters.


Thanks,
Akash



--
View this message in context: http://r.789695.n4.nabble.com/Returning-the-coefficient-parameters-from-JRI-tp4708987.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Wed Jun 24 08:50:39 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 23 Jun 2015 23:50:39 -0700
Subject: [R] Call to a function
In-Reply-To: <CAJ4QxaNuMjXbRwDafabHTN1iDT95+ZS0mhdJsrGfRqnskR0JMQ@mail.gmail.com>
References: <5589D070.4070900@gmail.com> <5589D219.5070001@gmail.com>
	<CAJ4QxaNuMjXbRwDafabHTN1iDT95+ZS0mhdJsrGfRqnskR0JMQ@mail.gmail.com>
Message-ID: <9E24BDB2-E2B1-4111-98AE-83F5561ACE7C@comcast.net>


On Jun 23, 2015, at 3:20 PM, boB Rudis wrote:

> You can do something like:
> 
> aaa <- function(data, w=w) {
>  if (class(w) %in% c("integer", "numeric", "double")) {

I think you will find that inherits(w, "numeric") is more compact and safer. Both "integer" and "double" do inherit from "numeric" (and "double" is equivalent to "numeric")

The test for 'is.vector' is also going to produce some surprises. List-objects may pass that test:

> sum( list(1,2,3))
Error in sum(list(1, 2, 3)) : invalid 'type' (list) of argument

> is.vector( list(1,2,3))
[1] TRUE


> x=1:4
> attr(x, "some_attr") <- "something"
> is.vector(x)
[1] FALSE


-- 
David.
>    out <- mean(w)
>  } else {
>    out <- mean(data[, w])
>  }
>  return(out)
> }
> 
> (there are some typos in your function you may want to double check, too)
> 
> On Tue, Jun 23, 2015 at 5:39 PM, Steven Yen <syen04 at gmail.com> wrote:
>> mydata<-data.frame(matrix(1:20,ncol=2))
>> colnames(mydata) <-c("v1","v2")
>> summary(mydata)
>> 
>> aaa<-function(data,w=w){
>>  if(is.vector(w)){
>>    out<-mean(w)
>>  } else {
>>    out<-mean(data[wt])
>>  }
>> return(out)
>> }
>> 
>> aaa(mydata,mydata$v1)
>> aaa(mydata,"v1")      # want this call to work
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From maechler at stat.math.ethz.ch  Wed Jun 24 09:20:57 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 24 Jun 2015 09:20:57 +0200
Subject: [R] 'class(.) == **' [was 'Call to a function']
In-Reply-To: <CCE952776B6679469977532BD863C39CB2B11745@Patterson.autuni.aut.ac.nz>
References: <5589D070.4070900@gmail.com> <5589D219.5070001@gmail.com>
	<CAJ4QxaNuMjXbRwDafabHTN1iDT95+ZS0mhdJsrGfRqnskR0JMQ@mail.gmail.com>
	<5589ED9F.7020801@gmail.com>
	<CCE952776B6679469977532BD863C39CB2B11745@Patterson.autuni.aut.ac.nz>
Message-ID: <21898.23129.223595.340119@stat.math.ethz.ch>

>>>>> Steve Taylor <steve.taylor at aut.ac.nz>
>>>>>     on Wed, 24 Jun 2015 00:56:26 +0000 writes:

    > Note that objects can have more than one class, in which case your == and %in% might not work as expected.  

    > Better to use inherits().

    > cheers,
    > Steve

Yes indeed, as Steve said, really do!  

The use of   (class(.) == "....")   it is error prone and
against the philosophy of classes (S3 or S4 or ..) in R :

Classes can "extend" other classes or "inherit" from them;
S3 examples in "base R"  are
 - glm() objects which are "glm"
   but also inherit from "lm"
 - multivariate time-series are "mts" and "ts"
 - The time-date objects  POSIXt , POSIXct, POSIXlt

==> do work  with  inherits(<obj>, <class))
or  possibly       is( <obj>, <class>)


We've seen this use of	

     class(.) == ".."    (or '!=" or  %in% ...)

in too many places;  though it may work fine in your test cases,
it is wrong to be used in generality e.g. inside a function you
provide for more general use,
and is best  replaced with the use of inherits() / is()
everywhere  "out of principle".

Martin Maechler
ETH Zurich


From jdnewmil at dcn.davis.CA.us  Wed Jun 24 09:22:14 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 24 Jun 2015 00:22:14 -0700
Subject: [R] Returning the coefficient parameters from JRI
In-Reply-To: <1435122954110-4708987.post@n4.nabble.com>
References: <1435122954110-4708987.post@n4.nabble.com>
Message-ID: <BC772EE5-91A5-4183-A4E5-2B16DC4FB40C@dcn.davis.CA.us>

I don't use JRI, but the data seem to be there. If you are looking for the row names, try ?rownames.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 23, 2015 10:15:54 PM PDT, akashdeep <akashdeep.hk at iqss.co.in> wrote:
>Hi,
>
>I am trying to  run R summary command through JRI to get the result for
>mulitvariate Linear Regression
>
>eg. result <- lm(Performance Score ~ Department+Grade,data =
>StudentData)
>      summary(result)
>
>on running the above cmd using in R Console will fetch me below result:
>
>Call:
>lm(formula = Performace.Score ~ Department + Grade, data = tree)
>
>Residuals:
>    Min      1Q  Median      3Q     Max 
>-1.0146 -0.8472  0.1206  0.1528  1.3193 
>
>Coefficients:
>                               Estimate Std. Error t value Pr(>|t|)    
>(Intercept)                    1.9085381  0.2063188   9.250   <2e-16
>***
>DepartmentCentral Projects    -0.0618622  0.2086085  -0.297    0.767   
>
>DepartmentConsulting Services -0.0529854  0.2104055  -0.252    0.801   
>
>DepartmentDistribution        -0.2280968  0.2268197  -1.006    0.315   
>
>DepartmentExecutive            0.0896884  0.4008410   0.224    0.823   
>
>DepartmentFinance             -0.1366400  0.2503824  -0.546    0.585   
>
>DepartmentHR                  -0.2093362  0.2544092  -0.823    0.411   
>
>DepartmentIT                  -0.0301757  0.2236310  -0.135    0.893   
>
>DepartmentLocal Projects       0.1047488  0.2099865   0.499    0.618   
>
>DepartmentOperations           0.1009253  0.2078236   0.486    0.627   
>
>DepartmentR&D                 -0.0436125  0.2115470  -0.206    0.837   
>
>DepartmentSales               -0.1824861  0.2310936  -0.790    0.430   
>
>Grade                          0.0002534  0.0139614   0.018    0.986   
>
>---
>Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>Residual standard error: 0.6768 on 1492 degrees of freedom
>Multiple R-squared:  0.0195,    Adjusted R-squared:  0.01161 
>F-statistic: 2.472 on 12 and 1492 DF,  p-value: 0.00335
>
>
>
>Now, When i try to run the same command through JRI and trying to get
>only
>coefficients for same data ,will fetch below result :
>
>
>[REAL* (1.9085381360123104, -0.061862224682688656, -0.0529853865573166,
>-0.22809675152091768, 0.0896883836938513, -0.13664002290293625,
>-0.20933620214453777, -0.03017568582453441, 0.10474877352108226,
>0.10092534733241249, -0.04361245714602103, -0.1824861159548225,
>2.5335432769115444E-4, 0.20631884004542614, 0.20860854811530719,
>0.21040549853856627, 0.2268197334540003, 0.4008409534398062,
>0.25038238782600725, 0.2544092401777455, 0.22363101707542418,
>0.20998649433526015, 0.20782362789029826, 0.21154702570507078,
>0.23109359545008445, 0.013961381053987209, 9.250430719715656,
>-0.29654693080215805, -0.2518251040269494, -1.0056301012591409,
>0.22375054974845454, -0.5457253766502479, -0.8228325433395539,
>-0.13493515443055484, 0.49883576490325376, 0.48562980233261505,
>-0.20615963283182023, -0.7896632340650002, 0.018146795557793288,
>7.495625279329623E-20, 0.7668537059840453, 0.8012109343341197,
>0.31475660028966584, 0.8229820424275262, 0.5853363050818626,
>0.4107347156441347, 0.8926813449490922, 0.6179686247435434,
>0.6273009677306218, 0.8366943459235678, 0.42984994326833603,
>0.9855241729402933)]
>
>
>>From the above result what i get from JRI,will fetch me only
>coefficient
>values not the parameters like what we get in R Console(Departments
>list and
>Grade in this Case).
>
>So,my question is  how to get coefficient values along with parameters.
>
>
>Thanks,
>Akash
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Returning-the-coefficient-parameters-from-JRI-tp4708987.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Wed Jun 24 09:57:27 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 24 Jun 2015 09:57:27 +0200
Subject: [R] Repeated Measures ANOVA and the Bonferroni post hoc test
	different results of significantly
In-Reply-To: <CAJ6JbR8Cjfcp+qncHYkQnQhDEBr+OFRYzBvsy1tv1_H75cDcSw@mail.gmail.com>
References: <CAJ6JbR8Cjfcp+qncHYkQnQhDEBr+OFRYzBvsy1tv1_H75cDcSw@mail.gmail.com>
Message-ID: <5DECD6BD-3C7A-4724-AC2B-5FED699C716B@gmail.com>


> On 24 Jun 2015, at 03:28 , gianni lavaredo <gianni.lavaredo at gmail.com> wrote:
> 
> 
> I am doing an Repeated Measures ANOVA and the Bonferroni post hoc test for
> my data using R project. The ANOVA gives a significantly difference between
> the data but not the  Bonferroni post hoc test.
> 
>> anova(aov2)
>                numDF denDF   F-value p-value
>    (Intercept)     1  1366 110.51125  <.0001
>    time            5  1366   9.84684  <.0001
> 
> while
> 
>> pairwise.t.test(x=table.metric2$value, g=table.metric2$time,
> p.adj="bonf")


And? 

Notice that pairwise.t.test does not take the plot variable into account. It might if you use paired=TRUE, *IF* your data layout allows it (so that when you split the data by times, observations in each subvector are from the same plots in the same order). 

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dnbarron at gmail.com  Wed Jun 24 10:39:14 2015
From: dnbarron at gmail.com (David Barron)
Date: Wed, 24 Jun 2015 09:39:14 +0100
Subject: [R] Lavaan
In-Reply-To: <CAKuYVCVwrUjKnTeA9uhyKYnwfZ_MrK7669OW7y=JQv1qU35T-Q@mail.gmail.com>
References: <558971ce.43e8420a.97818.0a8d@mx.google.com>
	<CAM_vjunR5=ihG8LGk4mHu0Vb=82wExMO-yAYB_5Q-2NqqB9g4w@mail.gmail.com>
	<CAKuYVCVwrUjKnTeA9uhyKYnwfZ_MrK7669OW7y=JQv1qU35T-Q@mail.gmail.com>
Message-ID: <CAHuze_LucAC8OjbNKWoPraZMYaQdKTFP5A_owRP6qbaakdiVLQ@mail.gmail.com>

Does the package semPlot not do what you want?  I notice that you got
an error when you used library(semPlot) because you don't have all the
dependencies installed. When you have semPlot working, it should be
able to produce a graphical output of the results, including
'covariance arrows'.

David

On 23 June 2015 at 17:47, deva d <devazresearch at gmail.com> wrote:
> i am attaching a .csv file, and the associated code worked out in R Studio.
>
> i used the lavaan and sem packages, and conducted it.
>
> now, i wish to draw the SEM model, as is available in AMOS other packages
> and how does one draw the covariance arrows in R.
>
> ONE STATISTICS oriented question - how can one provide interpretation for
> negative coefficients.
>
> kindly guide.
>
> thanks and regds,
>
>
>
>
>
> taxliability <- read.csv("~/R WORK SPACE/taxliability.csv")
>>   View(taxliability)
>> model <-'tax~ inc + exp + svg + inv'
>> fit <- sem(model, data = taxliability)
> Error: could not find function "sem"
>> library("lavaan", lib.loc="~/R/win-library/3.2")
> This is lavaan 0.5-18
> lavaan is BETA software! Please report any bugs.
>> fit <- sem(model, data = taxliability)
> Warning message:
> In lav_model_vcov(lavmodel = lavmodel, lavsamplestats = lavsamplestats,  :
>   lavaan WARNING: could not compute standard errors!
>   lavaan NOTE: this may be a symptom that the model is not identified.
>
>> library("sem", lib.loc="~/R/win-library/3.2")
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]])
> :
>   there is no package called ?htmlwidgets?
> Error: package or namespace load failed for ?sem?
>> fit <- sem(model, data = taxliability)
> Warning message:
> In lav_model_vcov(lavmodel = lavmodel, lavsamplestats = lavsamplestats,  :
>   lavaan WARNING: could not compute standard errors!
>   lavaan NOTE: this may be a symptom that the model is not identified.
>
>> summary(fit,rsq=T, fit.measures=TRUE)
> lavaan (0.5-18) converged normally after   1 iterations
>
>   Number of observations                            66
>
>   Estimator                                         ML
>   Minimum Function Test Statistic                0.000
>   Degrees of freedom                                 0
>
> Model test baseline model:
>
>   Minimum Function Test Statistic              160.444
>   Degrees of freedom                                 4
>   P-value                                        0.000
>
> User model versus baseline model:
>
>   Comparative Fit Index (CFI)                    1.000
>   Tucker-Lewis Index (TLI)                       1.000
>
> Loglikelihood and Information Criteria:
>
>   Loglikelihood user model (H0)              -3441.453
>   Loglikelihood unrestricted model (H1)      -3441.453
>
>   Number of free parameters                          5
>   Akaike (AIC)                                6892.905
>   Bayesian (BIC)                              6903.854
>   Sample-size adjusted Bayesian (BIC)         6888.113
>
> Root Mean Square Error of Approximation:
>
>   RMSEA                                          0.000
>   90 Percent Confidence Interval          0.000  0.000
>   P-value RMSEA <= 0.05                          1.000
>
> Standardized Root Mean Square Residual:
>
>   SRMR                                           0.000
>
> Parameter estimates:
>
>   Information                                 Expected
>   Standard Errors                             Standard
>
>                    Estimate  Std.err  Z-value  P(>|z|)
> Regressions:
>   tax ~
>     inc               0.103
>     exp              -0.023
>     svg              -0.073
>     inv               0.222
>
> Variances:
>     tax           4662558.169
>
> R-Square:
>
>     tax               0.912
>
>  semPlot
> Error: object 'semPlot' not found
>> library("semPlot", lib.loc="~/R/win-library/3.2")
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]])
> :
>   there is no package called ?htmlwidgets?
> Error: package or namespace load failed for ?semPlot?
>> semPlot::
> Error: unexpected end of line in "semPlot::"
>>
>
>
>
>
> *....*
>
> *Deva*
>
>
> ...............
>
>
>
> *in search of knowledge, everyday something is added ....*
>
> *in search of wisdom, everyday something is dropped  ... an old Chinese
> Proverb*
> :::::::::::::::::::::::::
>
> On Tue, Jun 23, 2015 at 9:03 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>
>> Hi,
>>
>> There are various tutorials for lavaan online, and even an entire book
>> on the R package. Have you worked through those examples and tutorials
>> successfully? If so, a clearer description of what you've tried and
>> what failed is required to be able to help you.
>>
>> Without a reproducible example that includes some sample data (fake is
>> fine), the code you used, and some clear idea of what output you
>> expect, it's impossible to figure out how to help you. Here are some
>> suggestions for creating a good reproducible example:
>>
>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>
>> Sarah
>>
>> On Tue, Jun 23, 2015 at 10:48 AM, DzR <devazresearch at gmail.com> wrote:
>> > Dear Senior users of R/R Studio,
>> >
>> > I am very new to this environment hence am unable to plot the SEM models
>> including use of graphic package ggplot.
>> >
>> > Request for some help in getting the plots please.
>> >
>> > Thanks,
>> >
>> > -----
>> > Deva
>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From shawjw at gmail.com  Wed Jun 24 12:27:58 2015
From: shawjw at gmail.com (James Shaw)
Date: Wed, 24 Jun 2015 06:27:58 -0400
Subject: [R] Combining estimates from multiple regressions
Message-ID: <CAHHxdpE8syrYYM600_FqQ_E-FV-ieQ3sq2J3+9yQSCxc1qg7hg@mail.gmail.com>

I am interested in using quantile regression to fit the following model at
different quantiles of a response variable:

(1)  y = b0 + b1*g1 + b2*g2 + B*Z

where b0 is an intercept, g1 and g2 are dummy variables for 2 of 3
independent groups, and Z is a matrix of covariates to be adjusted for in
the estimation (e.g., age, gender).  The problem is that estimates for g2
and g1 are not estimable at all quantiles.  To overcome this, one option is
to fit a separate model for each group (i.e., group 0, which is reflected
by intercept above, group 1, and group 2):

(2)  y = b11 + B1*Z (model for group 0)
(3)  y = b12 + B2*Z (model for group 1)
(4)  y = b13 + B3*Z (model for group 2)

This would correspond to fitting a single model in which group membership
was interacted with all covariates, albeit some of the interaction terms
would not be estimable for the reason noted above.  However, I ultimately
would like to base inferences on a single set of estimates.

Can anyone suggest an approach to combine estimates from models (2)-(4),
perhaps through weighted averaging, to generate estimates for the model
presented in (1) above?  An approach is not immediately clear to me since
the group effects are subsumed in the intercepts in (2)-(4), whereas (1)
includes separate estimates of group effects instead of a single weighted
average.

Regards,

Jim

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Jun 24 12:50:28 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 24 Jun 2015 20:50:28 +1000
Subject: [R] time management graph
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C31F7E@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C31F7E@SRVEXCHMBX.precheza.cz>
Message-ID: <CA+8X3fUytrGskmQU2v5aG0Dy276KZvPh9Sr07Xm5YRKv==B6mg@mail.gmail.com>

Hi Petr,
I'm not exactly sure this is what you are looking for, but try:

start_indices<-which(!is.na(temp$duration))
pp_gantt_info<-list(
 labels=paste(as.character(temp$person[start_indices]),
 temp$Akce,temp$Typ,sep="-"),
 starts=temp$time[start_indices],
 ends=temp$time[start_indices+1],
require(plotrix)
vgridpos<-as.POSIXct(strptime(
 paste("2015-06-23 ",c(16,17,18,19,20,21,22,23),":00:00",sep=""),
 format="%Y-%m-%d %H:%M:%S"))
vgridlab<-paste(c(16,17,18,19,20,21,22,23),":00",sep="")
gantt.chart(pp_gantt_info,vgridpos=vgridpos,vgridlab=vgridlab)

Jim


On Wed, Jun 24, 2015 at 2:05 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Dear all
>
> Did anybody tried to do time management graphs in R?
>
> I could do some aggregation
>
> xtabs(duration~person+Typ, data=temp)
>
> but I would like to make also a graph to show which task (Typ) and when was done by which person. The closest I came till this evening is following graph, but it is not exactly what I want.
>
> library(ggplot2)
> p<-ggplot(temp, aes(x=time, y=Typ, colour=person))
> p+geom_line()
>
> If anybody can focus me to proper functions or packages I would be greatful.
>
> Here are the data.
>
> temp <- structure(list(Akce = structure(c(16L, 18L, 20L, 13L, 1L, 15L,
> 4L, 12L, 8L, 22L, 16L, 15L, 5L, 24L, 13L, 16L, 6L, 1L, 15L, 11L,
> 1L, 5L, 24L, 7L, 1L, 10L, 21L, 23L, 3L, 2L, 9L, 14L, 17L, 20L,
> 13L, 14L, 19L, 14L, 4L, 1L, 15L, 5L, 24L, 13L, 15L, 1L, 14L,
> 11L, 15L, 5L, 24L, 7L, 1L, 10L, 14L, 23L, 3L, 2L, 9L), .Label = c("a",
> "b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l", "m", "n",
> "o", "p", "q", "r", "s", "t", "u", "v", "w", "x"), class = "factor"),
>     Typ = structure(c(4L, 6L, 6L, 6L, 2L, 6L, 6L, 1L, 1L, 8L,
>     4L, 6L, 6L, 6L, 6L, 4L, 1L, 2L, 6L, 5L, 2L, 6L, 6L, 6L, 2L,
>     3L, 4L, 6L, 7L, 4L, 4L, 7L, 7L, 6L, 6L, 7L, 6L, 7L, 6L, 2L,
>     6L, 6L, 6L, 6L, 6L, 2L, 7L, 5L, 6L, 6L, 6L, 6L, 2L, 3L, 7L,
>     6L, 7L, 4L, 4L), .Label = c("A", "B", "C", "D", "E", "F",
>     "G", "H"), class = "factor"), person = structure(c(1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("One",
>     "Two"), class = "factor"), time = structure(c(1435038600,
>     1435039200, 1435039800, 1435040100, 1435040400, 1435040760,
>     1435042200, 1435042680, 1435043220, 1435043400, 1435043700,
>     1435044300, 1435044600, 1435045200, 1435046400, 1435046700,
>     1435047000, 1435047300, 1435047600, 1435048800, 1435050600,
>     1435051200, 1435051800, 1435053300, 1435053900, 1435054500,
>     1435060800, 1435061700, 1435062000, 1435064400, 1435068000,
>     1435038600, 1435039200, 1435039800, 1435040100, 1435040280,
>     1435041060, 1435041600, 1435042200, 1435042800, 1435043400,
>     1435044600, 1435045200, 1435046400, 1435047000, 1435047300,
>     1435047600, 1435048800, 1435050600, 1435051200, 1435051800,
>     1435053300, 1435053900, 1435054500, 1435060800, 1435061700,
>     1435062000, 1435065600, 1435068000), class = c("POSIXct",
>     "POSIXt"), tzone = ""), duration = c(10, 10, 5, 5, 6, 24,
>     8, 9, 3, 5, 10, 5, 10, 20, 5, 5, 5, 5, 20, 30, 10, 10, 25,
>     10, 10, 105, 15, 5, 40, 60, NA, 10, 10, 5, 3, 13, 9, 10,
>     10, 10, 20, 10, 20, 10, 5, 5, 20, 30, 10, 10, 25, 10, 10,
>     105, 15, 5, 60, 40, NA)), .Names = c("Akce", "Typ", "person",
> "time", "duration"), class = "data.frame", row.names = c(NA,
> -59L))
>>
>
> Best regards
> Petr
>
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From batholdy at googlemail.com  Wed Jun 24 13:08:54 2015
From: batholdy at googlemail.com (Martin Batholdy)
Date: Wed, 24 Jun 2015 13:08:54 +0200
Subject: [R] define absolute size in plots ... possible?
Message-ID: <724F4DCA-7CB0-49C3-B3B4-2E2A268A6EA4@googlemail.com>

Hi,

I would like to define the size for tick-marks, axis-titles, legends, drawing symbols etc. absolute,
meaning that regardless of the size of the plot device, the font-size / character size is the same.

Thus if I output my plot with pdf(width=5, height=5) or pdf(width=15, height=15), the font-size / symbol-size remains the same.


Is that possible in R?


Thank you!

From murdoch.duncan at gmail.com  Wed Jun 24 13:17:17 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 24 Jun 2015 07:17:17 -0400
Subject: [R] define absolute size in plots ... possible?
In-Reply-To: <724F4DCA-7CB0-49C3-B3B4-2E2A268A6EA4@googlemail.com>
References: <724F4DCA-7CB0-49C3-B3B4-2E2A268A6EA4@googlemail.com>
Message-ID: <558A91BD.4030701@gmail.com>

On 24/06/2015 7:08 AM, Martin Batholdy via R-help wrote:
> Hi,
> 
> I would like to define the size for tick-marks, axis-titles, legends, drawing symbols etc. absolute,
> meaning that regardless of the size of the plot device, the font-size / character size is the same.
> 
> Thus if I output my plot with pdf(width=5, height=5) or pdf(width=15, height=15), the font-size / symbol-size remains the same.
> 
> 
> Is that possible in R?

That's the default, isn't it?

You need to give some reproducible code and explain what you don't like
about the results.

Duncan Murdoch


From thierry.onkelinx at inbo.be  Wed Jun 24 13:48:04 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 24 Jun 2015 13:48:04 +0200
Subject: [R] time management graph
In-Reply-To: <CA+8X3fUytrGskmQU2v5aG0Dy276KZvPh9Sr07Xm5YRKv==B6mg@mail.gmail.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C31F7E@SRVEXCHMBX.precheza.cz>
	<CA+8X3fUytrGskmQU2v5aG0Dy276KZvPh9Sr07Xm5YRKv==B6mg@mail.gmail.com>
Message-ID: <CAJuCY5w=2tANVAX4Xs=ZcEMrB7avAJbLCcTeSmGMurrcvT2n4A@mail.gmail.com>

Another option would be to use segments instead of lines.

library(lubridate)
temp$end <- temp$time + minutes(temp$duration)
library(ggplot2)
ggplot(temp, aes(x=time, xend = end, y=Typ, yend = Typ, colour=person)) +
geom_segment()


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-06-24 12:50 GMT+02:00 Jim Lemon <drjimlemon at gmail.com>:

> Hi Petr,
> I'm not exactly sure this is what you are looking for, but try:
>
> start_indices<-which(!is.na(temp$duration))
> pp_gantt_info<-list(
>  labels=paste(as.character(temp$person[start_indices]),
>  temp$Akce,temp$Typ,sep="-"),
>  starts=temp$time[start_indices],
>  ends=temp$time[start_indices+1],
> require(plotrix)
> vgridpos<-as.POSIXct(strptime(
>  paste("2015-06-23 ",c(16,17,18,19,20,21,22,23),":00:00",sep=""),
>  format="%Y-%m-%d %H:%M:%S"))
> vgridlab<-paste(c(16,17,18,19,20,21,22,23),":00",sep="")
> gantt.chart(pp_gantt_info,vgridpos=vgridpos,vgridlab=vgridlab)
>
> Jim
>
>
> On Wed, Jun 24, 2015 at 2:05 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> > Dear all
> >
> > Did anybody tried to do time management graphs in R?
> >
> > I could do some aggregation
> >
> > xtabs(duration~person+Typ, data=temp)
> >
> > but I would like to make also a graph to show which task (Typ) and when
> was done by which person. The closest I came till this evening is following
> graph, but it is not exactly what I want.
> >
> > library(ggplot2)
> > p<-ggplot(temp, aes(x=time, y=Typ, colour=person))
> > p+geom_line()
> >
> > If anybody can focus me to proper functions or packages I would be
> greatful.
> >
> > Here are the data.
> >
> > temp <- structure(list(Akce = structure(c(16L, 18L, 20L, 13L, 1L, 15L,
> > 4L, 12L, 8L, 22L, 16L, 15L, 5L, 24L, 13L, 16L, 6L, 1L, 15L, 11L,
> > 1L, 5L, 24L, 7L, 1L, 10L, 21L, 23L, 3L, 2L, 9L, 14L, 17L, 20L,
> > 13L, 14L, 19L, 14L, 4L, 1L, 15L, 5L, 24L, 13L, 15L, 1L, 14L,
> > 11L, 15L, 5L, 24L, 7L, 1L, 10L, 14L, 23L, 3L, 2L, 9L), .Label = c("a",
> > "b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l", "m", "n",
> > "o", "p", "q", "r", "s", "t", "u", "v", "w", "x"), class = "factor"),
> >     Typ = structure(c(4L, 6L, 6L, 6L, 2L, 6L, 6L, 1L, 1L, 8L,
> >     4L, 6L, 6L, 6L, 6L, 4L, 1L, 2L, 6L, 5L, 2L, 6L, 6L, 6L, 2L,
> >     3L, 4L, 6L, 7L, 4L, 4L, 7L, 7L, 6L, 6L, 7L, 6L, 7L, 6L, 2L,
> >     6L, 6L, 6L, 6L, 6L, 2L, 7L, 5L, 6L, 6L, 6L, 6L, 2L, 3L, 7L,
> >     6L, 7L, 4L, 4L), .Label = c("A", "B", "C", "D", "E", "F",
> >     "G", "H"), class = "factor"), person = structure(c(1L, 1L,
> >     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("One",
> >     "Two"), class = "factor"), time = structure(c(1435038600,
> >     1435039200, 1435039800, 1435040100, 1435040400, 1435040760,
> >     1435042200, 1435042680, 1435043220, 1435043400, 1435043700,
> >     1435044300, 1435044600, 1435045200, 1435046400, 1435046700,
> >     1435047000, 1435047300, 1435047600, 1435048800, 1435050600,
> >     1435051200, 1435051800, 1435053300, 1435053900, 1435054500,
> >     1435060800, 1435061700, 1435062000, 1435064400, 1435068000,
> >     1435038600, 1435039200, 1435039800, 1435040100, 1435040280,
> >     1435041060, 1435041600, 1435042200, 1435042800, 1435043400,
> >     1435044600, 1435045200, 1435046400, 1435047000, 1435047300,
> >     1435047600, 1435048800, 1435050600, 1435051200, 1435051800,
> >     1435053300, 1435053900, 1435054500, 1435060800, 1435061700,
> >     1435062000, 1435065600, 1435068000), class = c("POSIXct",
> >     "POSIXt"), tzone = ""), duration = c(10, 10, 5, 5, 6, 24,
> >     8, 9, 3, 5, 10, 5, 10, 20, 5, 5, 5, 5, 20, 30, 10, 10, 25,
> >     10, 10, 105, 15, 5, 40, 60, NA, 10, 10, 5, 3, 13, 9, 10,
> >     10, 10, 20, 10, 20, 10, 5, 5, 20, 30, 10, 10, 25, 10, 10,
> >     105, 15, 5, 60, 40, NA)), .Names = c("Akce", "Typ", "person",
> > "time", "duration"), class = "data.frame", row.names = c(NA,
> > -59L))
> >>
> >
> > Best regards
> > Petr
> >
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
> strany p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> > If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> > The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering into
> a contract in any time, for any reason, and without stating any reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> > - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From D.Bebber at exeter.ac.uk  Wed Jun 24 11:29:10 2015
From: D.Bebber at exeter.ac.uk (Bebber, Dan)
Date: Wed, 24 Jun 2015 09:29:10 +0000
Subject: [R] spacetime stConstruct gives wrong dimensions for long table
Message-ID: <D1B036F4.16570%d.bebber@exeter.ac.uk>

I have a large spatiotemporal database (131 spatial locations, 9 years of
daily weather data) in long table format which I would like to convert to
an ST object.

> head(tempmean)
           site  lat    lon  alt                              var year mth
day value       date doy numdate
518941 27015260 6.02 -75.37 1680 AVERAGE DAILY TEMPERATURE VALUES 2006   1
  1  16.9 2006-01-01 001   13149
518942 27015260 6.02 -75.37 1680 AVERAGE DAILY TEMPERATURE VALUES 2006   1
  2  16.4 2006-01-02 002   13150
518943 27015260 6.02 -75.37 1680 AVERAGE DAILY TEMPERATURE VALUES 2006   1
  3  16.9 2006-01-03 003   13151
518944 27015260 6.02 -75.37 1680 AVERAGE DAILY TEMPERATURE VALUES 2006   1
  4  16.1 2006-01-04 004   13152
518945 27015260 6.02 -75.37 1680 AVERAGE DAILY TEMPERATURE VALUES 2006   1
  5  16.6 2006-01-05 005   13153
518946 27015260 6.02 -75.37 1680 AVERAGE DAILY TEMPERATURE VALUES 2006   1
  6  16.7 2006-01-06 006   13154


The data.frame is ?ragged?, i.e. not all sites are represented by all
dates, and there are some NA values in the data.

I took a subset of the data (4 sites, 31 days in January 2006, for which
all site/date combinations are present) and tried

> st <- stConstruct(tempmean, 3:2, 10)
> summary(st)
Object of class STIDF
 with Dimensions (s, t, attr): (124, 124, 9)
[[Spatial:]]
Object of class SpatialPoints
Coordinates:
       min    max
lon -76.45 -73.11
lat   2.11   7.07
Is projected: NA 
proj4string : [NA]
Number of points: 124
[[Temporal:]]
     Index              timeIndex
 Min.   :2006-01-01   Min.   :  1.00
 1st Qu.:2006-01-08   1st Qu.: 31.75
 Median :2006-01-16   Median : 62.50
 Mean   :2006-01-16   Mean   : 62.50
 3rd Qu.:2006-01-24   3rd Qu.: 93.25
 Max.   :2006-01-31   Max.   :124.00


This is incorrect: There should be 4 spatial dimensions and 31 timepoints.

What am I doing wrong?

Thanks,
Dan

Dr Dan Bebber
Senior Research Fellow
Biosciences
University of Exeter





From batholdy at googlemail.com  Wed Jun 24 15:02:10 2015
From: batholdy at googlemail.com (Martin Batholdy)
Date: Wed, 24 Jun 2015 15:02:10 +0200
Subject: [R] define absolute size in plots ... possible?
In-Reply-To: <558A91BD.4030701@gmail.com>
References: <724F4DCA-7CB0-49C3-B3B4-2E2A268A6EA4@googlemail.com>
	<558A91BD.4030701@gmail.com>
Message-ID: <B510EDEE-1DCE-4961-9DDD-E69E26929D97@googlemail.com>

Hi,

> That's the default, isn't it?


I am sorry ? one of my plots was actually set up with mfrow.
But the documentation actually explains the change in cex when using mfrow;

"In a layout with exactly two rows and columns the base value of "cex" is reduced by a factor of 0.83: if there are three or more of either rows or columns, the reduction factor is 0.66.?


On 24 Jun 2015, at 13:17 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 24/06/2015 7:08 AM, Martin Batholdy via R-help wrote:
>> Hi,
>> 
>> I would like to define the size for tick-marks, axis-titles, legends, drawing symbols etc. absolute,
>> meaning that regardless of the size of the plot device, the font-size / character size is the same.
>> 
>> Thus if I output my plot with pdf(width=5, height=5) or pdf(width=15, height=15), the font-size / symbol-size remains the same.
>> 
>> 
>> Is that possible in R?
> 
> That's the default, isn't it?
> 
> You need to give some reproducible code and explain what you don't like
> about the results.
> 
> Duncan Murdoch
> 


From rab45 at pitt.edu  Wed Jun 24 15:02:24 2015
From: rab45 at pitt.edu (Rick Bilonick)
Date: Wed, 24 Jun 2015 09:02:24 -0400
Subject: [R] Lavaan
In-Reply-To: <558971ce.43e8420a.97818.0a8d@mx.google.com>
References: <558971ce.43e8420a.97818.0a8d@mx.google.com>
Message-ID: <558AAA60.5040706@pitt.edu>

Have you considered using the semPlot package? It works nicely with 
lavaan models (among other sem packages). There is also the DiagrammeR 
package.

Rick

On 06/23/2015 10:48 AM, DzR wrote:
> Dear Senior users of R/R Studio,
>
> I am very new to this environment hence am unable to plot the SEM models including use of graphic package ggplot.
>
> Request for some help in getting the plots please.
>
> Thanks,
>
> -----
> Deva
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Richard A. Bilonick, PhD
Assistant Professor
Dept. of Ophthalmology, School of Medicine
Dept. of Biostatistics, Graduate School of Public Health
Dept. of Orthodontics, School of Dental Medicine
University of Pittsburgh
Principal Investigator for the Pittsburgh Aerosol Research
  and Inhalation Epidemiology Study (PARIES)
412 647 5756


From petr.pikal at precheza.cz  Wed Jun 24 16:33:35 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 24 Jun 2015 14:33:35 +0000
Subject: [R] time management graph
In-Reply-To: <CAJuCY5w=2tANVAX4Xs=ZcEMrB7avAJbLCcTeSmGMurrcvT2n4A@mail.gmail.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C31F7E@SRVEXCHMBX.precheza.cz>
	<CA+8X3fUytrGskmQU2v5aG0Dy276KZvPh9Sr07Xm5YRKv==B6mg@mail.gmail.com>
	<CAJuCY5w=2tANVAX4Xs=ZcEMrB7avAJbLCcTeSmGMurrcvT2n4A@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C321E9@SRVEXCHMBX.precheza.cz>

Hi Thierry

Thanks a lot. This is the option I found later.

Still not 100% satisfactory. Maybe somebody did similar task and will have different opinion how to visualise such data.

Jim?s gant diagrams are worth consideration so I will try to elaborate it further.

Cheers
Petr

From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
Sent: Wednesday, June 24, 2015 1:48 PM
To: PIKAL Petr
Cc: r-help at r-project.org
Subject: Re: [R] time management graph

Another option would be to use segments instead of lines.

library(lubridate)
temp$end <- temp$time + minutes(temp$duration)
library(ggplot2)
ggplot(temp, aes(x=time, xend = end, y=Typ, yend = Typ, colour=person)) + geom_segment()


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2015-06-24 12:50 GMT+02:00 Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>>:
Hi Petr,
I'm not exactly sure this is what you are looking for, but try:

start_indices<-which(!is.na<http://is.na>(temp$duration))
pp_gantt_info<-list(
 labels=paste(as.character(temp$person[start_indices]),
 temp$Akce,temp$Typ,sep="-"),
 starts=temp$time[start_indices],
 ends=temp$time[start_indices+1],
require(plotrix)
vgridpos<-as.POSIXct(strptime(
 paste("2015-06-23 ",c(16,17,18,19,20,21,22,23),":00:00",sep=""),
 format="%Y-%m-%d %H:%M:%S"))
vgridlab<-paste(c(16,17,18,19,20,21,22,23),":00",sep="")
gantt.chart(pp_gantt_info,vgridpos=vgridpos,vgridlab=vgridlab)

Jim


On Wed, Jun 24, 2015 at 2:05 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
> Dear all
>
> Did anybody tried to do time management graphs in R?
>
> I could do some aggregation
>
> xtabs(duration~person+Typ, data=temp)
>
> but I would like to make also a graph to show which task (Typ) and when was done by which person. The closest I came till this evening is following graph, but it is not exactly what I want.
>
> library(ggplot2)
> p<-ggplot(temp, aes(x=time, y=Typ, colour=person))
> p+geom_line()
>
> If anybody can focus me to proper functions or packages I would be greatful.
>
> Here are the data.
>
> temp <- structure(list(Akce = structure(c(16L, 18L, 20L, 13L, 1L, 15L,
> 4L, 12L, 8L, 22L, 16L, 15L, 5L, 24L, 13L, 16L, 6L, 1L, 15L, 11L,
> 1L, 5L, 24L, 7L, 1L, 10L, 21L, 23L, 3L, 2L, 9L, 14L, 17L, 20L,
> 13L, 14L, 19L, 14L, 4L, 1L, 15L, 5L, 24L, 13L, 15L, 1L, 14L,
> 11L, 15L, 5L, 24L, 7L, 1L, 10L, 14L, 23L, 3L, 2L, 9L), .Label = c("a",
> "b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l", "m", "n",
> "o", "p", "q", "r", "s", "t", "u", "v", "w", "x"), class = "factor"),
>     Typ = structure(c(4L, 6L, 6L, 6L, 2L, 6L, 6L, 1L, 1L, 8L,
>     4L, 6L, 6L, 6L, 6L, 4L, 1L, 2L, 6L, 5L, 2L, 6L, 6L, 6L, 2L,
>     3L, 4L, 6L, 7L, 4L, 4L, 7L, 7L, 6L, 6L, 7L, 6L, 7L, 6L, 2L,
>     6L, 6L, 6L, 6L, 6L, 2L, 7L, 5L, 6L, 6L, 6L, 6L, 2L, 3L, 7L,
>     6L, 7L, 4L, 4L), .Label = c("A", "B", "C", "D", "E", "F",
>     "G", "H"), class = "factor"), person = structure(c(1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("One",
>     "Two"), class = "factor"), time = structure(c(1435038600,
>     1435039200, 1435039800, 1435040100, 1435040400, 1435040760,
>     1435042200, 1435042680, 1435043220, 1435043400, 1435043700,
>     1435044300, 1435044600, 1435045200, 1435046400, 1435046700,
>     1435047000, 1435047300, 1435047600, 1435048800, 1435050600,
>     1435051200, 1435051800, 1435053300, 1435053900, 1435054500,
>     1435060800, 1435061700, 1435062000, 1435064400, 1435068000,
>     1435038600, 1435039200, 1435039800, 1435040100, 1435040280,
>     1435041060, 1435041600, 1435042200, 1435042800, 1435043400,
>     1435044600, 1435045200, 1435046400, 1435047000, 1435047300,
>     1435047600, 1435048800, 1435050600, 1435051200, 1435051800,
>     1435053300, 1435053900, 1435054500, 1435060800, 1435061700,
>     1435062000, 1435065600, 1435068000), class = c("POSIXct",
>     "POSIXt"), tzone = ""), duration = c(10, 10, 5, 5, 6, 24,
>     8, 9, 3, 5, 10, 5, 10, 20, 5, 5, 5, 5, 20, 30, 10, 10, 25,
>     10, 10, 105, 15, 5, 40, 60, NA, 10, 10, 5, 3, 13, 9, 10,
>     10, 10, 20, 10, 20, 10, 5, 5, 20, 30, 10, 10, 25, 10, 10,
>     105, 15, 5, 60, 40, NA)), .Names = c("Akce", "Typ", "person",
> "time", "duration"), class = "data.frame", row.names = c(NA,
> -59L))
>>
>
> Best regards
> Petr
>
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Jun 24 16:33:45 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 24 Jun 2015 07:33:45 -0700
Subject: [R] Combining estimates from multiple regressions
In-Reply-To: <CAHHxdpE8syrYYM600_FqQ_E-FV-ieQ3sq2J3+9yQSCxc1qg7hg@mail.gmail.com>
References: <CAHHxdpE8syrYYM600_FqQ_E-FV-ieQ3sq2J3+9yQSCxc1qg7hg@mail.gmail.com>
Message-ID: <CAGxFJbTsKVAcYtXhdCUe-J0zm_GM3Wx7EgDJFaN_MHSt5djdYA@mail.gmail.com>

Not an answer to your question, but you should not be using "dummy"
variables in R. Use factors instead. Please read a R tutorial or text
-- there are many -- to learn how to fit models in R. You might also
wish to consult a local statistician or post on a statistics list like
stats.stackexchange.com for statistics questions, which are off topic
here.

Further, when you post here, please read and follow the posting guide
(below) and post in plain text, not HTML.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Wed, Jun 24, 2015 at 3:27 AM, James Shaw <shawjw at gmail.com> wrote:
> I am interested in using quantile regression to fit the following model at
> different quantiles of a response variable:
>
> (1)  y = b0 + b1*g1 + b2*g2 + B*Z
>
> where b0 is an intercept, g1 and g2 are dummy variables for 2 of 3
> independent groups, and Z is a matrix of covariates to be adjusted for in
> the estimation (e.g., age, gender).  The problem is that estimates for g2
> and g1 are not estimable at all quantiles.  To overcome this, one option is
> to fit a separate model for each group (i.e., group 0, which is reflected
> by intercept above, group 1, and group 2):
>
> (2)  y = b11 + B1*Z (model for group 0)
> (3)  y = b12 + B2*Z (model for group 1)
> (4)  y = b13 + B3*Z (model for group 2)
>
> This would correspond to fitting a single model in which group membership
> was interacted with all covariates, albeit some of the interaction terms
> would not be estimable for the reason noted above.  However, I ultimately
> would like to base inferences on a single set of estimates.
>
> Can anyone suggest an approach to combine estimates from models (2)-(4),
> perhaps through weighted averaging, to generate estimates for the model
> presented in (1) above?  An approach is not immediately clear to me since
> the group effects are subsumed in the intercepts in (2)-(4), whereas (1)
> includes separate estimates of group effects instead of a single weighted
> average.
>
> Regards,
>
> Jim
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Wed Jun 24 16:36:01 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 24 Jun 2015 16:36:01 +0200
Subject: [R] time management graph
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C321E9@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C31F7E@SRVEXCHMBX.precheza.cz>
	<CA+8X3fUytrGskmQU2v5aG0Dy276KZvPh9Sr07Xm5YRKv==B6mg@mail.gmail.com>
	<CAJuCY5w=2tANVAX4Xs=ZcEMrB7avAJbLCcTeSmGMurrcvT2n4A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C321E9@SRVEXCHMBX.precheza.cz>
Message-ID: <CAJuCY5ycChSeiO5ySjH9UGvH1iKdcmGLOoWA6V8LOLwy7NjFug@mail.gmail.com>

Maybe something like the punch cards on github?
https://github.com/hadley/ggplot2/graphs/punch-card

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-06-24 16:33 GMT+02:00 PIKAL Petr <petr.pikal at precheza.cz>:

>  Hi Thierry
>
>
>
> Thanks a lot. This is the option I found later.
>
>
>
> Still not 100% satisfactory. Maybe somebody did similar task and will have
> different opinion how to visualise such data.
>
>
>
> Jim?s gant diagrams are worth consideration so I will try to elaborate it
> further.
>
>
>
> Cheers
>
> Petr
>
>
>
> *From:* Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
> *Sent:* Wednesday, June 24, 2015 1:48 PM
> *To:* PIKAL Petr
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] time management graph
>
>
>
> Another option would be to use segments instead of lines.
>
>
>
> library(lubridate)
>
> temp$end <- temp$time + minutes(temp$duration)
>
> library(ggplot2)
>
> ggplot(temp, aes(x=time, xend = end, y=Typ, yend = Typ, colour=person)) +
> geom_segment()
>
>
>
>
>   ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
>
> 2015-06-24 12:50 GMT+02:00 Jim Lemon <drjimlemon at gmail.com>:
>
> Hi Petr,
> I'm not exactly sure this is what you are looking for, but try:
>
> start_indices<-which(!is.na(temp$duration))
> pp_gantt_info<-list(
>  labels=paste(as.character(temp$person[start_indices]),
>  temp$Akce,temp$Typ,sep="-"),
>  starts=temp$time[start_indices],
>  ends=temp$time[start_indices+1],
> require(plotrix)
> vgridpos<-as.POSIXct(strptime(
>  paste("2015-06-23 ",c(16,17,18,19,20,21,22,23),":00:00",sep=""),
>  format="%Y-%m-%d %H:%M:%S"))
> vgridlab<-paste(c(16,17,18,19,20,21,22,23),":00",sep="")
> gantt.chart(pp_gantt_info,vgridpos=vgridpos,vgridlab=vgridlab)
>
> Jim
>
>
> On Wed, Jun 24, 2015 at 2:05 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> > Dear all
> >
> > Did anybody tried to do time management graphs in R?
> >
> > I could do some aggregation
> >
> > xtabs(duration~person+Typ, data=temp)
> >
> > but I would like to make also a graph to show which task (Typ) and when
> was done by which person. The closest I came till this evening is following
> graph, but it is not exactly what I want.
> >
> > library(ggplot2)
> > p<-ggplot(temp, aes(x=time, y=Typ, colour=person))
> > p+geom_line()
> >
> > If anybody can focus me to proper functions or packages I would be
> greatful.
> >
> > Here are the data.
> >
> > temp <- structure(list(Akce = structure(c(16L, 18L, 20L, 13L, 1L, 15L,
> > 4L, 12L, 8L, 22L, 16L, 15L, 5L, 24L, 13L, 16L, 6L, 1L, 15L, 11L,
> > 1L, 5L, 24L, 7L, 1L, 10L, 21L, 23L, 3L, 2L, 9L, 14L, 17L, 20L,
> > 13L, 14L, 19L, 14L, 4L, 1L, 15L, 5L, 24L, 13L, 15L, 1L, 14L,
> > 11L, 15L, 5L, 24L, 7L, 1L, 10L, 14L, 23L, 3L, 2L, 9L), .Label = c("a",
> > "b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l", "m", "n",
> > "o", "p", "q", "r", "s", "t", "u", "v", "w", "x"), class = "factor"),
> >     Typ = structure(c(4L, 6L, 6L, 6L, 2L, 6L, 6L, 1L, 1L, 8L,
> >     4L, 6L, 6L, 6L, 6L, 4L, 1L, 2L, 6L, 5L, 2L, 6L, 6L, 6L, 2L,
> >     3L, 4L, 6L, 7L, 4L, 4L, 7L, 7L, 6L, 6L, 7L, 6L, 7L, 6L, 2L,
> >     6L, 6L, 6L, 6L, 6L, 2L, 7L, 5L, 6L, 6L, 6L, 6L, 2L, 3L, 7L,
> >     6L, 7L, 4L, 4L), .Label = c("A", "B", "C", "D", "E", "F",
> >     "G", "H"), class = "factor"), person = structure(c(1L, 1L,
> >     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("One",
> >     "Two"), class = "factor"), time = structure(c(1435038600,
> >     1435039200, 1435039800, 1435040100, 1435040400, 1435040760,
> >     1435042200, 1435042680, 1435043220, 1435043400, 1435043700,
> >     1435044300, 1435044600, 1435045200, 1435046400, 1435046700,
> >     1435047000, 1435047300, 1435047600, 1435048800, 1435050600,
> >     1435051200, 1435051800, 1435053300, 1435053900, 1435054500,
> >     1435060800, 1435061700, 1435062000, 1435064400, 1435068000,
> >     1435038600, 1435039200, 1435039800, 1435040100, 1435040280,
> >     1435041060, 1435041600, 1435042200, 1435042800, 1435043400,
> >     1435044600, 1435045200, 1435046400, 1435047000, 1435047300,
> >     1435047600, 1435048800, 1435050600, 1435051200, 1435051800,
> >     1435053300, 1435053900, 1435054500, 1435060800, 1435061700,
> >     1435062000, 1435065600, 1435068000), class = c("POSIXct",
> >     "POSIXt"), tzone = ""), duration = c(10, 10, 5, 5, 6, 24,
> >     8, 9, 3, 5, 10, 5, 10, 20, 5, 5, 5, 5, 20, 30, 10, 10, 25,
> >     10, 10, 105, 15, 5, 40, 60, NA, 10, 10, 5, 3, 13, 9, 10,
> >     10, 10, 20, 10, 20, 10, 5, 5, 20, 30, 10, 10, 25, 10, 10,
> >     105, 15, 5, 60, 40, NA)), .Names = c("Akce", "Typ", "person",
> > "time", "duration"), class = "data.frame", row.names = c(NA,
> > -59L))
> >>
> >
> > Best regards
> > Petr
> >
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
> strany p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> > If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> > The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering into
> a contract in any time, for any reason, and without stating any reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> > - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> ------------------------------
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Jun 24 16:51:40 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 24 Jun 2015 14:51:40 +0000
Subject: [R] time management graph
In-Reply-To: <CA+8X3fUytrGskmQU2v5aG0Dy276KZvPh9Sr07Xm5YRKv==B6mg@mail.gmail.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C31F7E@SRVEXCHMBX.precheza.cz>
	<CA+8X3fUytrGskmQU2v5aG0Dy276KZvPh9Sr07Xm5YRKv==B6mg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C32203@SRVEXCHMBX.precheza.cz>

Hi Jim

Thanks a lot.

gantt.chart is worth trying, beside Thierry's segment solution. I need to think it over if it can be better for visualisation.

Cheers
Petr


> -----Original Message-----
> From: Jim Lemon [mailto:drjimlemon at gmail.com]
> Sent: Wednesday, June 24, 2015 12:50 PM
> To: PIKAL Petr
> Cc: r-help at r-project.org
> Subject: Re: [R] time management graph
>
> Hi Petr,
> I'm not exactly sure this is what you are looking for, but try:
>
> start_indices<-which(!is.na(temp$duration))
> pp_gantt_info<-list(
>  labels=paste(as.character(temp$person[start_indices]),
>  temp$Akce,temp$Typ,sep="-"),
>  starts=temp$time[start_indices],
>  ends=temp$time[start_indices+1],
> require(plotrix)
> vgridpos<-as.POSIXct(strptime(
>  paste("2015-06-23 ",c(16,17,18,19,20,21,22,23),":00:00",sep=""),
>  format="%Y-%m-%d %H:%M:%S"))
> vgridlab<-paste(c(16,17,18,19,20,21,22,23),":00",sep="")
> gantt.chart(pp_gantt_info,vgridpos=vgridpos,vgridlab=vgridlab)
>
> Jim
>
>
> On Wed, Jun 24, 2015 at 2:05 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> > Dear all
> >
> > Did anybody tried to do time management graphs in R?
> >
> > I could do some aggregation
> >
> > xtabs(duration~person+Typ, data=temp)
> >
> > but I would like to make also a graph to show which task (Typ) and
> when was done by which person. The closest I came till this evening is
> following graph, but it is not exactly what I want.
> >
> > library(ggplot2)
> > p<-ggplot(temp, aes(x=time, y=Typ, colour=person))
> > p+geom_line()
> >
> > If anybody can focus me to proper functions or packages I would be
> greatful.
> >
> > Here are the data.
> >
> > temp <- structure(list(Akce = structure(c(16L, 18L, 20L, 13L, 1L,
> 15L,
> > 4L, 12L, 8L, 22L, 16L, 15L, 5L, 24L, 13L, 16L, 6L, 1L, 15L, 11L, 1L,
> > 5L, 24L, 7L, 1L, 10L, 21L, 23L, 3L, 2L, 9L, 14L, 17L, 20L, 13L, 14L,
> > 19L, 14L, 4L, 1L, 15L, 5L, 24L, 13L, 15L, 1L, 14L, 11L, 15L, 5L, 24L,
> > 7L, 1L, 10L, 14L, 23L, 3L, 2L, 9L), .Label = c("a", "b", "c", "d",
> > "e", "f", "g", "h", "i", "j", "k", "l", "m", "n", "o", "p", "q", "r",
> > "s", "t", "u", "v", "w", "x"), class = "factor"),
> >     Typ = structure(c(4L, 6L, 6L, 6L, 2L, 6L, 6L, 1L, 1L, 8L,
> >     4L, 6L, 6L, 6L, 6L, 4L, 1L, 2L, 6L, 5L, 2L, 6L, 6L, 6L, 2L,
> >     3L, 4L, 6L, 7L, 4L, 4L, 7L, 7L, 6L, 6L, 7L, 6L, 7L, 6L, 2L,
> >     6L, 6L, 6L, 6L, 6L, 2L, 7L, 5L, 6L, 6L, 6L, 6L, 2L, 3L, 7L,
> >     6L, 7L, 4L, 4L), .Label = c("A", "B", "C", "D", "E", "F",
> >     "G", "H"), class = "factor"), person = structure(c(1L, 1L,
> >     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label =
> c("One",
> >     "Two"), class = "factor"), time = structure(c(1435038600,
> >     1435039200, 1435039800, 1435040100, 1435040400, 1435040760,
> >     1435042200, 1435042680, 1435043220, 1435043400, 1435043700,
> >     1435044300, 1435044600, 1435045200, 1435046400, 1435046700,
> >     1435047000, 1435047300, 1435047600, 1435048800, 1435050600,
> >     1435051200, 1435051800, 1435053300, 1435053900, 1435054500,
> >     1435060800, 1435061700, 1435062000, 1435064400, 1435068000,
> >     1435038600, 1435039200, 1435039800, 1435040100, 1435040280,
> >     1435041060, 1435041600, 1435042200, 1435042800, 1435043400,
> >     1435044600, 1435045200, 1435046400, 1435047000, 1435047300,
> >     1435047600, 1435048800, 1435050600, 1435051200, 1435051800,
> >     1435053300, 1435053900, 1435054500, 1435060800, 1435061700,
> >     1435062000, 1435065600, 1435068000), class = c("POSIXct",
> >     "POSIXt"), tzone = ""), duration = c(10, 10, 5, 5, 6, 24,
> >     8, 9, 3, 5, 10, 5, 10, 20, 5, 5, 5, 5, 20, 30, 10, 10, 25,
> >     10, 10, 105, 15, 5, 40, 60, NA, 10, 10, 5, 3, 13, 9, 10,
> >     10, 10, 20, 10, 20, 10, 5, 5, 20, 30, 10, 10, 25, 10, 10,
> >     105, 15, 5, 60, 40, NA)), .Names = c("Akce", "Typ", "person",
> > "time", "duration"), class = "data.frame", row.names = c(NA,
> > -59L))
> >>
> >
> > Best regards
> > Petr

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From shawjw at gmail.com  Wed Jun 24 16:59:00 2015
From: shawjw at gmail.com (James Shaw)
Date: Wed, 24 Jun 2015 10:59:00 -0400
Subject: [R] Combining estimates from multiple regressions
In-Reply-To: <CAGxFJbTsKVAcYtXhdCUe-J0zm_GM3Wx7EgDJFaN_MHSt5djdYA@mail.gmail.com>
References: <CAHHxdpE8syrYYM600_FqQ_E-FV-ieQ3sq2J3+9yQSCxc1qg7hg@mail.gmail.com>
	<CAGxFJbTsKVAcYtXhdCUe-J0zm_GM3Wx7EgDJFaN_MHSt5djdYA@mail.gmail.com>
Message-ID: <CAHHxdpE728wkq8fC0y=Xm2+qhGoe=VvyHbQR_H=i4z6rM3oLrw@mail.gmail.com>

Thanks for the suggestions, Gunter.



On Wed, Jun 24, 2015 at 10:33 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Not an answer to your question, but you should not be using "dummy"
> variables in R. Use factors instead. Please read a R tutorial or text
> -- there are many -- to learn how to fit models in R. You might also
> wish to consult a local statistician or post on a statistics list like
> stats.stackexchange.com for statistics questions, which are off topic
> here.
>
> Further, when you post here, please read and follow the posting guide
> (below) and post in plain text, not HTML.
>
> Cheers,
> Bert
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
>
>
> On Wed, Jun 24, 2015 at 3:27 AM, James Shaw <shawjw at gmail.com> wrote:
>> I am interested in using quantile regression to fit the following model at
>> different quantiles of a response variable:
>>
>> (1)  y = b0 + b1*g1 + b2*g2 + B*Z
>>
>> where b0 is an intercept, g1 and g2 are dummy variables for 2 of 3
>> independent groups, and Z is a matrix of covariates to be adjusted for in
>> the estimation (e.g., age, gender).  The problem is that estimates for g2
>> and g1 are not estimable at all quantiles.  To overcome this, one option is
>> to fit a separate model for each group (i.e., group 0, which is reflected
>> by intercept above, group 1, and group 2):
>>
>> (2)  y = b11 + B1*Z (model for group 0)
>> (3)  y = b12 + B2*Z (model for group 1)
>> (4)  y = b13 + B3*Z (model for group 2)
>>
>> This would correspond to fitting a single model in which group membership
>> was interacted with all covariates, albeit some of the interaction terms
>> would not be estimable for the reason noted above.  However, I ultimately
>> would like to base inferences on a single set of estimates.
>>
>> Can anyone suggest an approach to combine estimates from models (2)-(4),
>> perhaps through weighted averaging, to generate estimates for the model
>> presented in (1) above?  An approach is not immediately clear to me since
>> the group effects are subsumed in the intercepts in (2)-(4), whereas (1)
>> includes separate estimates of group effects instead of a single weighted
>> average.
>>
>> Regards,
>>
>> Jim
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Wed Jun 24 17:40:02 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 24 Jun 2015 15:40:02 +0000
Subject: [R] set par options once for entire R session
In-Reply-To: <E825A2BB-BC65-4BFA-A8DC-3F66BF240057@googlemail.com>
References: <3FC1DBA3-2908-4487-BC15-FBB49640D9DF@googlemail.com>
	<E825A2BB-BC65-4BFA-A8DC-3F66BF240057@googlemail.com>
Message-ID: <D1B01850.12F76E%macqueen1@llnl.gov>

The Details section of ?par starts of with:

 "Each device has its own set of graphical parameters."

(So this is not Mac-specific.)

Strictly speaking, the options you set with par() are not "reset" when you
open a new graphics device. Rather, when a new device is opened, it is
initialized with default values of graphics parameters.

If you can find where those default values are stored (in a brief search I
did not find them), then perhaps you can change them at session startup
time.

I haven't tested this, but you might be able to make things a little more
convenient by defining a function

  mypar <- function() par( {set whatever values you want} )

Then whenever you open a new device, immediately call that function:

pdf()
mypar()
plot(x,y)
dev.off()

png()
mypar()
plot(x,y)
dev.of()

And so on.



-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/23/15, 8:54 AM, "R-help on behalf of Martin Batholdy via R-help"
<r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:

>Hi,
>
>I would like to set plot-options via par() and keep them for all plots
>that are created thereafter.
>Currently after each plot device the parameters I can set with par() are
>reseted to their default value, at least on a Mac (R 3.2.1).
>
>Is there a way to define the parameters for plotting once at the
>beginning and then keep them for an entire R session?
>
>
>Thank you!
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rcodeplayer at gmail.com  Wed Jun 24 15:10:02 2015
From: rcodeplayer at gmail.com (R codeplayer)
Date: Wed, 24 Jun 2015 15:10:02 +0200
Subject: [R] R lattice : labeling of matrix groups of different size with
	strips
Message-ID: <CAKy6djnrm2rW3SSRy4eWk9xeRdMFksA+GhaJPR6-27560nWtTQ@mail.gmail.com>

In R lattice, I am trying to label predefined groups of rows in a
matrix of data with strips. Currently, the length of the strips fail
to match the different sizes of the groups as the data representation
only allows groups with the same size.

One possibility to solve this might be to suppress the display of
NAs, but I did not find any configuration to realize
this in Lattice.

The example code below shows a matrix (m) with 8 rows and 4 columns.
Group 1 contains row 1-5 and group 2 contains row 6-8. The lattice
output is attached below the code.

Thank you for your time



library(lattice)

m <- matrix(c(1,1,1,0,0,0,0,0,
            0,0,1,1,1,0,0,0,
            0,0,0,0,1,1,1,0,
            0,0,0,0,0,0,1,1),nrow=8,ncol=4)

group1 <- m[1:5,]
group2 <- m[6:nrow(m),]

plotMatrix <- array(dim=c(5,4,2))
dimnames(plotMatrix) <- list(rep("",5), c("a","b","c","d"),c("group1","group2"))
plotMatrix[,,1]<- group1
plotMatrix[1:3,,2] <- group2

trellis.device(device = "pdf",file ="lattice_strips.pdf",width=14,height=10)
print(levelplot(plotMatrix,colorkey=F,xlab="",ylab=""))
dev.off()
-------------- next part --------------
A non-text attachment was scrubbed...
Name: lattice_strips.pdf
Type: application/pdf
Size: 4678 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150624/e6b7d4ac/attachment.pdf>

From edwinvanl at gmail.com  Wed Jun 24 17:07:22 2015
From: edwinvanl at gmail.com (Edwin van Leeuwen)
Date: Wed, 24 Jun 2015 15:07:22 +0000
Subject: [R] Rcpp cpp11 and R CMD build
Message-ID: <CACv9t7NasaVy52ukJxZ5WmsT9jN_BxQ2AK1jMH85wi7rMiawyA@mail.gmail.com>

Hi all,

I've just started using Rcpp and am trying to get cpp11 support working. As
suggested I added [[Rcpp:plugins(cpp11)]] to my source file and a test
function:
// [[Rcpp::export]]
int useCpp11() {
  auto x = 10;
  return x;
}

This works fine when using:
sourceCpp(filename)
from R, but I would like to be able to compile the package from the command
line.
R CMD build mypackage
fails with the following error:
R CMD build ../fluEvidenceSynthesis
* checking for file ?../fluEvidenceSynthesis/DESCRIPTION? ... OK
* preparing ?fluEvidenceSynthesis?:
* checking DESCRIPTION meta-information ... OK
* cleaning src
* installing the package to process help pages
      -----------------------------------
* installing *source* package ?fluEvidenceSynthesis? ...
** libs
g++ -I/usr/share/R/include -DNDEBUG
-I"/home/edwin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/include"
-I"/home/edwin/R/x86_64-pc-linux-gnu-library/3.2/BH/include"   -fpic  -g
-O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c RcppExports.cpp -o
RcppExports.o
g++ -I/usr/share/R/include -DNDEBUG
-I"/home/edwin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/include"
-I"/home/edwin/R/x86_64-pc-linux-gnu-library/3.2/BH/include"   -fpic  -g
-O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c rcpp_hello_world.cpp -o
rcpp_hello_world.o
rcpp_hello_world.cpp: In function ?int useCpp11()?:
rcpp_hello_world.cpp:33:10: error: ?x? does not name a type
     auto x = 10;
          ^
rcpp_hello_world.cpp:34:12: error: ?x? was not declared in this scope
     return x;
            ^
make: *** [rcpp_hello_world.o] Error 1
ERROR: compilation failed for package ?fluEvidenceSynthesis?
* removing ?/tmp/RtmpWdUduu/Rinst2b601aa285e9/fluEvidenceSynthesis?
      -----------------------------------
ERROR: package installation failed


Any help appreciated.

Cheers, Edwin

	[[alternative HTML version deleted]]


From cdetermanjr at gmail.com  Wed Jun 24 18:50:13 2015
From: cdetermanjr at gmail.com (Charles Determan)
Date: Wed, 24 Jun 2015 11:50:13 -0500
Subject: [R] Rcpp cpp11 and R CMD build
In-Reply-To: <CACv9t7NasaVy52ukJxZ5WmsT9jN_BxQ2AK1jMH85wi7rMiawyA@mail.gmail.com>
References: <CACv9t7NasaVy52ukJxZ5WmsT9jN_BxQ2AK1jMH85wi7rMiawyA@mail.gmail.com>
Message-ID: <CAKxd1KP=apWDo+sg2HU6oOPSCP=tTNci2wadjF-wdLoyE_VZBw@mail.gmail.com>

Hi Edwin,

If you look at the build output you will notice that the C++11 compiler
flag is not being used.  I just created a small package using Rcpp11 and
your function and it worked without a problem.  I can't give you a specific
reason without seeing your package but there are some possibilities I would
guess right away.

1. Make sure you are 'LinkingTo' Rcpp11 in your DESCRIPTION
2. Unless you are using some custom Makevars file, you should set
'SystemRequirements: C++11' in your DESCRIPTION

Charles

On Wed, Jun 24, 2015 at 10:07 AM, Edwin van Leeuwen <edwinvanl at gmail.com>
wrote:

> Hi all,
>
> I've just started using Rcpp and am trying to get cpp11 support working. As
> suggested I added [[Rcpp:plugins(cpp11)]] to my source file and a test
> function:
> // [[Rcpp::export]]
> int useCpp11() {
>   auto x = 10;
>   return x;
> }
>
> This works fine when using:
> sourceCpp(filename)
> from R, but I would like to be able to compile the package from the command
> line.
> R CMD build mypackage
> fails with the following error:
> R CMD build ../fluEvidenceSynthesis
> * checking for file ?../fluEvidenceSynthesis/DESCRIPTION? ... OK
> * preparing ?fluEvidenceSynthesis?:
> * checking DESCRIPTION meta-information ... OK
> * cleaning src
> * installing the package to process help pages
>       -----------------------------------
> * installing *source* package ?fluEvidenceSynthesis? ...
> ** libs
> g++ -I/usr/share/R/include -DNDEBUG
> -I"/home/edwin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/include"
> -I"/home/edwin/R/x86_64-pc-linux-gnu-library/3.2/BH/include"   -fpic  -g
> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c RcppExports.cpp -o
> RcppExports.o
> g++ -I/usr/share/R/include -DNDEBUG
> -I"/home/edwin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/include"
> -I"/home/edwin/R/x86_64-pc-linux-gnu-library/3.2/BH/include"   -fpic  -g
> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c rcpp_hello_world.cpp -o
> rcpp_hello_world.o
> rcpp_hello_world.cpp: In function ?int useCpp11()?:
> rcpp_hello_world.cpp:33:10: error: ?x? does not name a type
>      auto x = 10;
>           ^
> rcpp_hello_world.cpp:34:12: error: ?x? was not declared in this scope
>      return x;
>             ^
> make: *** [rcpp_hello_world.o] Error 1
> ERROR: compilation failed for package ?fluEvidenceSynthesis?
> * removing ?/tmp/RtmpWdUduu/Rinst2b601aa285e9/fluEvidenceSynthesis?
>       -----------------------------------
> ERROR: package installation failed
>
>
> Any help appreciated.
>
> Cheers, Edwin
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From cdetermanjr at gmail.com  Wed Jun 24 19:01:52 2015
From: cdetermanjr at gmail.com (Charles Determan)
Date: Wed, 24 Jun 2015 12:01:52 -0500
Subject: [R] Rcpp cpp11 and R CMD build
In-Reply-To: <CACv9t7OFh_Snd2xyKc_=FVBOhPkHG9q2Vs9GXtygG2Vvwr-ipw@mail.gmail.com>
References: <CACv9t7NasaVy52ukJxZ5WmsT9jN_BxQ2AK1jMH85wi7rMiawyA@mail.gmail.com>
	<CAKxd1KP=apWDo+sg2HU6oOPSCP=tTNci2wadjF-wdLoyE_VZBw@mail.gmail.com>
	<CACv9t7OFh_Snd2xyKc_=FVBOhPkHG9q2Vs9GXtygG2Vvwr-ipw@mail.gmail.com>
Message-ID: <CAKxd1KOk3t9SLSkpRuiTsjy9BKTHiyFD78A3q_MRhqs7gb=wVw@mail.gmail.com>

Glad to help,

The SystemRequirements is for a package.  I believe the example in the
gallery is intended to demonstrate a function where if you set the
CXX_FLAGS with:

Sys.setenv("PKG_CXXFLAGS"="-std=c++11")

And then compiled a single *.cpp file with Rcpp::sourceCpp("test.cpp")
I believe it should work fine.  But for package purposes you want the
user to not have to care about setting flags manually.
It ultimately just comes down to context.

Regards,

Charles


On Wed, Jun 24, 2015 at 11:57 AM, Edwin van Leeuwen <edwinvanl at gmail.com>
wrote:

> Thank you! I was missing the SystemRequirements. I guess it could be
> useful to add this to the example given here:
> http://gallery.rcpp.org/articles/simple-lambda-func-c++11/
>
> Cheers, Edwin
>
> On Wed, 24 Jun 2015 at 17:50 Charles Determan <cdetermanjr at gmail.com>
> wrote:
>
>> Hi Edwin,
>>
>> If you look at the build output you will notice that the C++11 compiler
>> flag is not being used.  I just created a small package using Rcpp11 and
>> your function and it worked without a problem.  I can't give you a specific
>> reason without seeing your package but there are some possibilities I would
>> guess right away.
>>
>> 1. Make sure you are 'LinkingTo' Rcpp11 in your DESCRIPTION
>> 2. Unless you are using some custom Makevars file, you should set
>> 'SystemRequirements: C++11' in your DESCRIPTION
>>
>> Charles
>>
>> On Wed, Jun 24, 2015 at 10:07 AM, Edwin van Leeuwen <edwinvanl at gmail.com>
>> wrote:
>>
>>> Hi all,
>>>
>>> I've just started using Rcpp and am trying to get cpp11 support working.
>>> As
>>> suggested I added [[Rcpp:plugins(cpp11)]] to my source file and a test
>>> function:
>>> // [[Rcpp::export]]
>>> int useCpp11() {
>>>   auto x = 10;
>>>   return x;
>>> }
>>>
>>> This works fine when using:
>>> sourceCpp(filename)
>>> from R, but I would like to be able to compile the package from the
>>> command
>>> line.
>>> R CMD build mypackage
>>> fails with the following error:
>>> R CMD build ../fluEvidenceSynthesis
>>> * checking for file ?../fluEvidenceSynthesis/DESCRIPTION? ... OK
>>> * preparing ?fluEvidenceSynthesis?:
>>> * checking DESCRIPTION meta-information ... OK
>>> * cleaning src
>>> * installing the package to process help pages
>>>       -----------------------------------
>>> * installing *source* package ?fluEvidenceSynthesis? ...
>>> ** libs
>>> g++ -I/usr/share/R/include -DNDEBUG
>>> -I"/home/edwin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/include"
>>> -I"/home/edwin/R/x86_64-pc-linux-gnu-library/3.2/BH/include"   -fpic  -g
>>> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c RcppExports.cpp -o
>>> RcppExports.o
>>> g++ -I/usr/share/R/include -DNDEBUG
>>> -I"/home/edwin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/include"
>>> -I"/home/edwin/R/x86_64-pc-linux-gnu-library/3.2/BH/include"   -fpic  -g
>>> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c rcpp_hello_world.cpp
>>> -o
>>> rcpp_hello_world.o
>>> rcpp_hello_world.cpp: In function ?int useCpp11()?:
>>> rcpp_hello_world.cpp:33:10: error: ?x? does not name a type
>>>      auto x = 10;
>>>           ^
>>> rcpp_hello_world.cpp:34:12: error: ?x? was not declared in this scope
>>>      return x;
>>>             ^
>>> make: *** [rcpp_hello_world.o] Error 1
>>> ERROR: compilation failed for package ?fluEvidenceSynthesis?
>>> * removing ?/tmp/RtmpWdUduu/Rinst2b601aa285e9/fluEvidenceSynthesis?
>>>       -----------------------------------
>>> ERROR: package installation failed
>>>
>>>
>>> Any help appreciated.
>>>
>>> Cheers, Edwin
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>

	[[alternative HTML version deleted]]


From devazresearch at gmail.com  Wed Jun 24 19:30:16 2015
From: devazresearch at gmail.com (deva d)
Date: Wed, 24 Jun 2015 23:00:16 +0530
Subject: [R] Lavaan
In-Reply-To: <558AAA60.5040706@pitt.edu>
References: <558971ce.43e8420a.97818.0a8d@mx.google.com>
	<558AAA60.5040706@pitt.edu>
Message-ID: <CAKuYVCXRmcOXza7ADF7jfA210fS__J8TG+enjcis46knAoGe2Q@mail.gmail.com>

i tried the semPlot but it flopped. various other packages also did not
perform. i will try the DiagrammeR package and revert.

meanwhile, i tried going to the onyx package and its neat, though i have
yet to spend some time on it to familiarise myself with the nuts and bolts
of the process.




*....*

*Deva*
*F-13*
*iResearch at NITIE*
*my 'research engine' *

...............



*in search of knowledge, everyday something is added ....*

*in search of wisdom, everyday something is dropped  ... an old Chinese
Proverb*
:::::::::::::::::::::::::

On Wed, Jun 24, 2015 at 6:32 PM, Rick Bilonick <rab45 at pitt.edu> wrote:

> Have you considered using the semPlot package? It works nicely with lavaan
> models (among other sem packages). There is also the DiagrammeR package.
>
> Rick
>
>
> On 06/23/2015 10:48 AM, DzR wrote:
>
>> Dear Senior users of R/R Studio,
>>
>> I am very new to this environment hence am unable to plot the SEM models
>> including use of graphic package ggplot.
>>
>> Request for some help in getting the plots please.
>>
>> Thanks,
>>
>> -----
>> Deva
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Richard A. Bilonick, PhD
> Assistant Professor
> Dept. of Ophthalmology, School of Medicine
> Dept. of Biostatistics, Graduate School of Public Health
> Dept. of Orthodontics, School of Dental Medicine
> University of Pittsburgh
> Principal Investigator for the Pittsburgh Aerosol Research
>  and Inhalation Epidemiology Study (PARIES)
> 412 647 5756
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chl948 at mail.usask.ca  Wed Jun 24 19:45:14 2015
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Wed, 24 Jun 2015 11:45:14 -0600
Subject: [R] Broken links (???) in R-FAQ
Message-ID: <558AECAA.5060805@mail.usask.ca>

Could you kindly check if the following links are working fine in the 
R-FAQ page at <http://cran.r-project.org/doc/FAQ/R-FAQ.html>?  The links 
listed in the below seem to be broken.  I hope these links are fixed in 
the very near future.

Under the section 2.6 Are there Unix-like binaries for R?,

  * http://CRAN.R-project.org/bin/linux/debian/README

Under the section 2.10 What is CRAN?,

  * http://cran.au.R-project.org/
  * http://cran.pt.R-project.org/

Under the section 2.14 What is R-Forge?,

  * GForge <www.gforge.org>

Under the section 3.1 What is S?,

  * http://cm.bell-labs.com/cm/ms/departments/sia/Sbook/
  * http://cm.bell-labs.com/cm/ms/departments/sia/S/history.html

Under the section 4 R Web Interfaces,
  * http://rwiki.sciviews.org/doku.php?id=faq-r#web_interfaces
  * Rserve <http://stats.math.uni-augsburg.de/Rserve/>

Under the section 5.1.4 Add-on packages from Bioconductor,

  * Bioconductor software packages 
<http://www.bioconductor.org/packages/bioc/>

Under the section 7.39 How do I create a plot with two y-axes?,
  * http://rwiki.sciviews.org/doku.php?id=tips:graphics-base:2yaxes

I appreciate your helps!

Chel Hee Lee


From chl948 at mail.usask.ca  Wed Jun 24 19:52:35 2015
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Wed, 24 Jun 2015 11:52:35 -0600
Subject: [R] Broken links (???) in rw-FAQ
Message-ID: <558AEE63.70908@mail.usask.ca>

Could you also kindly check the following links in the rw-FAQ manual at 
<http://cran.r-project.org/bin/windows/base/rw-FAQ.html>??  The links 
list in the below seem to be broken.   I hope these links are fixed in 
the very near future.

Under the section 2.4 Can I customize the installation?

  * Setup (http://jrsoftware.org/ishelp.php) for details.

Under the section 3.3 I want to run R in Chinese/Japanese/Korean

  * 
http://msdn.microsoft.com/library/default.asp?url=/library/en-us/vccore98/html/_crt_language_and_country_strings.asp

Under the section 2.26 There is no tilde on my keyboard!

  * http://office.microsoft.com/en-us/word/HP052590631033.aspx

This link is in fact moved to

https://support.office.com/en-us/article/HP052590631?CorrelationId=98eaa529-e95a-4628-90ac-1a1da4526b17

Under the section 2.24 Does R run under Windows Vista/7/8/Server 2008?

  * 
http://windowsvistablog.com/blogs/windowsvista/archive/2007/01/23/security-features-vs-convenience.aspx

I appreciate your help!

Chel Hee Lee


From gmbegnis at yahoo.it  Wed Jun 24 20:26:33 2015
From: gmbegnis at yahoo.it (giacomo begnis)
Date: Wed, 24 Jun 2015 18:26:33 +0000 (UTC)
Subject: [R] create a dummy variables for companies with complete history.
Message-ID: <139890578.925548.1435170393135.JavaMail.yahoo@mail.yahoo.com>

Hi, I have a dataset ?(728 obs) containing three variables code of a company, year and revenue. Some companies have a complete history of 5 years, others have not a complete history (for instance observations for three or four years).I would like to determine the companies with a complete history using a dummy variables.I have written the following program but there is somehting wrong because the dummy variable that I have create is always equal to zero.Can somebody help me?Thanks, gm

z<-read.table(file="c:/Rp/cddat.txt", sep="", header=T)
attach(z)
n<-length(z$cod) ?// number of obs dataset

d1<-numeric(n) ? // dummy variable

for (i in 5:n) ?{
?? if (z$cod[i]==z$cod[i-4]) ? ? ? ? ? ? // cod is the code of a company? ? ? ? ? ? ?{ d1[i]<=1} else { d1[i]<=0} ? ? ? ? ?// d1=1 for a company with complete history, d1=0 if the history is not complete??}d1
When I run the program d1 is always equal to zero. Why?
Once I have create the dummy variable with subset I obtains the code of the companies with a complete history and finally with a merge ?I determine a panel of companies with a complete history.But how to determine correctly d1?My best regards, gm



	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Jun 24 20:49:00 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 24 Jun 2015 14:49:00 -0400
Subject: [R] create a dummy variables for companies with complete
	history.
In-Reply-To: <139890578.925548.1435170393135.JavaMail.yahoo@mail.yahoo.com>
References: <139890578.925548.1435170393135.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAM_vjumF8QOcD4Ek-YTSxpFKpRVYboCWWZYwqRvgEGaz=DFCQQ@mail.gmail.com>

Please repost your question in plain text rather than HTML - you can
see below that your code got rather mangled. Please also include some
sample data using dput() - made-up data of similar form is fine, but
it's very hard to answer a question based on guessing what the data
look like.

Sarah

On Wed, Jun 24, 2015 at 2:26 PM, giacomo begnis <gmbegnis at yahoo.it> wrote:
> Hi, I have a dataset  (728 obs) containing three variables code of a company, year and revenue. Some companies have a complete history of 5 years, others have not a complete history (for instance observations for three or four years).I would like to determine the companies with a complete history using a dummy variables.I have written the following program but there is somehting wrong because the dummy variable that I have create is always equal to zero.Can somebody help me?Thanks, gm
>
> z<-read.table(file="c:/Rp/cddat.txt", sep="", header=T)
> attach(z)
> n<-length(z$cod)  // number of obs dataset
>
> d1<-numeric(n)   // dummy variable
>
> for (i in 5:n)  {
>    if (z$cod[i]==z$cod[i-4])             // cod is the code of a company             { d1[i]<=1} else { d1[i]<=0}          // d1=1 for a company with complete history, d1=0 if the history is not complete  }d1
> When I run the program d1 is always equal to zero. Why?
> Once I have create the dummy variable with subset I obtains the code of the companies with a complete history and finally with a merge  I determine a panel of companies with a complete history.But how to determine correctly d1?My best regards, gm
>
>
>
>         [[alternative HTML version deleted]]
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From lists at dewey.myzen.co.uk  Wed Jun 24 21:11:46 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 24 Jun 2015 20:11:46 +0100
Subject: [R] create a dummy variables for companies with complete
	history.
In-Reply-To: <139890578.925548.1435170393135.JavaMail.yahoo@mail.yahoo.com>
References: <139890578.925548.1435170393135.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <558B00F2.3050008@dewey.myzen.co.uk>

Comments below

On 24/06/2015 19:26, giacomo begnis wrote:
> Hi, I have a dataset  (728 obs) containing three variables code of a company, year and revenue. Some companies have a complete history of 5 years, others have not a complete history (for instance observations for three or four years).I would like to determine the companies with a complete history using a dummy variables.I have written the following program but there is somehting wrong because the dummy variable that I have create is always equal to zero.Can somebody help me?Thanks, gm
>
> z<-read.table(file="c:/Rp/cddat.txt", sep="", header=T)
> attach(z)
> n<-length(z$cod)  // number of obs dataset
>

Could also use nrow(z)

> d1<-numeric(n)   // dummy variable
>
> for (i in 5:n)  {
>     if (z$cod[i]==z$cod[i-4])             // cod is the code of a company

              { d1[i]<=1} else { d1[i]<=0}          // d1=1 for a 
company with complete history, d1=0 if the history is not complete  }d1

Did you really type <= which means less than or equals to? If so, try 
replacing it with <- and see what happens.

> When I run the program d1 is always equal to zero. Why?
> Once I have create the dummy variable with subset I obtains the code of the companies with a complete history and finally with a merge  I determine a panel of companies with a complete history.But how to determine correctly d1?My best regards, gm
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From bgunter.4567 at gmail.com  Wed Jun 24 21:13:05 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 24 Jun 2015 12:13:05 -0700
Subject: [R] repeated measures: multiple comparisons with
 pairwise.t.test and multcomp disagree
In-Reply-To: <A10A6826-3042-4D3E-A101-E59F14EC24AA@me.com>
References: <5C2FF04C-262D-4D96-A493-A62F149DA76A@me.com>
	<CAJuCY5xMk1=662vX9x50TvnGx3_qHHphL8sU67cOoEFVCqcJtg@mail.gmail.com>
	<A10A6826-3042-4D3E-A101-E59F14EC24AA@me.com>
Message-ID: <CAGxFJbQ4HzZ74ZkAf3eEAhkRSawXwjGYpHRzG=wChN2wAU53iA@mail.gmail.com>

I would **strongly** recommend that you speak with a local statistical
expert before proceeding further. Your obsession with statistical
significance is very dangerous. (see the current issue of SIGNIFICANCE
for some explanation).

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Wed, Jun 24, 2015 at 10:30 AM, Denis Chabot <denis.chabot at me.com> wrote:
> Thank you, Thierry. And yes, Bert, it turns out that it is more of a statistical question after all, but again, since my question used specific R functions, R experts are well placed to help me.
>
> As pairewise.t.test was recommended in a few tutorials about repeated-measure Anovas, I assumed it took into account the fact that the measures were indeed repeated, so thank you for pointing out that it does not.
>
> But my reason for not accepting the result of multcomp went further than this. Before deciding to test 4 different durations, I had tested only two of them, corresponding to sets 1 and 2 of my example. I used a paired t test (as in t test for paired samples). I had a very significant effect, i.e. the mean of the differences calculated for each subject was significantly different from zero.
>
> After adding two other durations and switching from my paired t test to a repeated measures design, these same 2 sets are no longer different. I think the explanation is lack of homogeneity of variances. I thought a log transformation of the raw data had been sufficient to fix this, and a Levene test on the variances of the 4 sets found no problem in this regard.
>
> But maybe it is the variance of all the possible differences (set 1 vs 2, etc, for a total of 6 differences calculated for each subject) that matters.  I just calculated these and they range from 1.788502e-05 to 1.462171e-03. A Levene test on these 6 "groups" showed that their variances were heterogeneous.
>
> I think I'll stay away from  the "repeated measures followed by multiple comparisons" and just report my 6 t tests for paired samples, correcting the p-level for the number of comparisons with, say, the Sidak method (p for significance is then 0.0085).
>
> Thanks for your help.
>
> Denis
>
>> Le 2015-06-23 ? 08:15, Thierry Onkelinx <thierry.onkelinx at inbo.be> a ?crit :
>>
>> Dear Denis,
>>
>> It's not multcomp which is too conservative, it is the pairwise t-test
>> which is too liberal. The pairwise t-test doesn't take the random
>> effect of Case into account.
>>
>> Best regards,
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>>
>>
>> 2015-06-23 5:17 GMT+02:00 Denis Chabot <denis.chabot at me.com>:
>>> Hi,
>>>
>>> I am working on a problem which I think can be handled as a repeated measures analysis, and I have read many tutorials about how to do this with R. This part goes well, but I get stuck with the multiple comparisons I'd like to run afterward. I tried two methods that I have seen in my readings, but their results are quite different and I don't know which one to trust.
>>>
>>> The two approaches are pairwise.t.test() and multcomp, although the latter is not available after a repeated-measures aov model, but it is after a lme.
>>>
>>> I have a physiological variable measured frequently on each of 67 animals. These are then summarized with a quantile for each animal. To check the effect of experiment duration, I recalculated the quantile for each animal 4 times, using different subset of the data (so the shortest subset is part of all other subsets, the second subset is included in the 2 others, etc.). I handle this as 4 repeated (non-independent) measurements for each animal, and want to see if the average value (for 67 animals) differs for the 4 different durations.
>>>
>>> Because animals with high values for this physiological trait have larger differences between the 4 durations than animals with low values, the observations were log transformed.
>>>
>>> I attach the small data set (Rda format) here, but it can be obtained here if the attachment gets stripped:
>>> <https://dl.dropboxusercontent.com/u/612902/RepMeasData.Rda>
>>>
>>> The data.frame is simply called Data.
>>> My code is
>>>
>>> load("RepMeasData.Rda")
>>> Data_Long = melt(Data, id="Case")
>>> names(Data_Long) = c("Case","Duration", "SMR")
>>> Data_Long$SMR = log10(Data_Long$SMR)
>>>
>>> # I only show essential code to reproduce my opposing results
>>> mixmod = lme(SMR ~ Duration, data = Data_Long, random = ~ 1 | Case)
>>> anova(mixmod)
>>> posthoc <- glht(mixmod, linfct = mcp(Duration = "Tukey"))
>>> summary(posthoc)
>>>        Simultaneous Tests for General Linear Hypotheses
>>>
>>> Multiple Comparisons of Means: Tukey Contrasts
>>>
>>>
>>> Fit: lme.formula(fixed = SMR ~ Duration, data = Data_Long, random = ~1 |
>>>   Case)
>>>
>>> Linear Hypotheses:
>>>                 Estimate Std. Error z value Pr(>|z|)
>>> Set2 - Set1 == 0 -0.006135   0.003375  -1.818    0.265
>>> Set3 - Set1 == 0 -0.002871   0.003375  -0.851    0.830
>>> Set4 - Set1 == 0  0.015395   0.003375   4.561   <1e-04 ***
>>> Set3 - Set2 == 0  0.003264   0.003375   0.967    0.768
>>> Set4 - Set2 == 0  0.021530   0.003375   6.379   <1e-04 ***
>>> Set4 - Set3 == 0  0.018266   0.003375   5.412   <1e-04 ***
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> (Adjusted p values reported -- single-step method)
>>>
>>> with(Data_Long, pairwise.t.test(SMR, Duration, p.adjust.method="holm", paired=T))
>>>       Pairwise comparisons using paired t tests
>>>
>>> data:  SMR and Duration
>>>
>>>    Set1    Set2    Set3
>>> Set2 < 2e-16 -       -
>>> Set3 0.11118 0.10648 -
>>> Set4 0.00475 7.9e-05 0.00034
>>>
>>> P value adjustment method: holm
>>>
>>> So the difference between sets 1 and 2 goes from non significant to very significant, depending on method.
>>>
>>> I have other examples with essentially the same type of data and sometimes the two approches differ in the opposing way. In the example shown here, multcomp was more conservative, in some others it yielded a larger number of significant differences.
>>>
>>> I admit not mastering all the intricacies of multcomp, but I have used multcomp and other methods of doing multiple comparisons many times before (but never with a repeated measures design), and always found the results very similar. When there were small differences, I trusted multcomp. This time, I get rather large differences and I am worried that I am doing something wrong.
>>>
>>> Thanks in advance,
>>>
>>> Denis Chabot
>>> Fisheries & Oceans Canada
>>>
>>> sessionInfo()
>>> R version 3.2.0 (2015-04-16)
>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>> Running under: OS X 10.10.3 (Yosemite)
>>>
>>> locale:
>>> [1] fr_CA.UTF-8/fr_CA.UTF-8/fr_CA.UTF-8/C/fr_CA.UTF-8/fr_CA.UTF-8
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] multcomp_1.4-0  TH.data_1.0-6   survival_2.38-1 mvtnorm_1.0-2   nlme_3.1-120    car_2.0-25      reshape2_1.4.1
>>>
>>> loaded via a namespace (and not attached):
>>> [1] Rcpp_0.11.5      magrittr_1.5     splines_3.2.0    MASS_7.3-40      lattice_0.20-31  minqa_1.2.4      stringr_1.0.0
>>> [8] plyr_1.8.2       tools_3.2.0      nnet_7.3-9       pbkrtest_0.4-2   parallel_3.2.0   grid_3.2.0       mgcv_1.8-6
>>> [15] quantreg_5.11    lme4_1.1-7       Matrix_1.2-0     nloptr_1.0.4     codetools_0.2-11 sandwich_2.3-3   stringi_0.4-1
>>> [22] SparseM_1.6      zoo_1.7-12
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


From denis.chabot at me.com  Wed Jun 24 19:30:37 2015
From: denis.chabot at me.com (Denis Chabot)
Date: Wed, 24 Jun 2015 13:30:37 -0400
Subject: [R] repeated measures: multiple comparisons with
 pairwise.t.test and multcomp disagree
In-Reply-To: <CAJuCY5xMk1=662vX9x50TvnGx3_qHHphL8sU67cOoEFVCqcJtg@mail.gmail.com>
References: <5C2FF04C-262D-4D96-A493-A62F149DA76A@me.com>
	<CAJuCY5xMk1=662vX9x50TvnGx3_qHHphL8sU67cOoEFVCqcJtg@mail.gmail.com>
Message-ID: <A10A6826-3042-4D3E-A101-E59F14EC24AA@me.com>

Thank you, Thierry. And yes, Bert, it turns out that it is more of a statistical question after all, but again, since my question used specific R functions, R experts are well placed to help me.

As pairewise.t.test was recommended in a few tutorials about repeated-measure Anovas, I assumed it took into account the fact that the measures were indeed repeated, so thank you for pointing out that it does not.

But my reason for not accepting the result of multcomp went further than this. Before deciding to test 4 different durations, I had tested only two of them, corresponding to sets 1 and 2 of my example. I used a paired t test (as in t test for paired samples). I had a very significant effect, i.e. the mean of the differences calculated for each subject was significantly different from zero.

After adding two other durations and switching from my paired t test to a repeated measures design, these same 2 sets are no longer different. I think the explanation is lack of homogeneity of variances. I thought a log transformation of the raw data had been sufficient to fix this, and a Levene test on the variances of the 4 sets found no problem in this regard.

But maybe it is the variance of all the possible differences (set 1 vs 2, etc, for a total of 6 differences calculated for each subject) that matters.  I just calculated these and they range from 1.788502e-05 to 1.462171e-03. A Levene test on these 6 "groups" showed that their variances were heterogeneous.

I think I'll stay away from  the "repeated measures followed by multiple comparisons" and just report my 6 t tests for paired samples, correcting the p-level for the number of comparisons with, say, the Sidak method (p for significance is then 0.0085).

Thanks for your help. 

Denis

> Le 2015-06-23 ? 08:15, Thierry Onkelinx <thierry.onkelinx at inbo.be> a ?crit :
> 
> Dear Denis,
> 
> It's not multcomp which is too conservative, it is the pairwise t-test
> which is too liberal. The pairwise t-test doesn't take the random
> effect of Case into account.
> 
> Best regards,
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> 
> 
> 2015-06-23 5:17 GMT+02:00 Denis Chabot <denis.chabot at me.com>:
>> Hi,
>> 
>> I am working on a problem which I think can be handled as a repeated measures analysis, and I have read many tutorials about how to do this with R. This part goes well, but I get stuck with the multiple comparisons I'd like to run afterward. I tried two methods that I have seen in my readings, but their results are quite different and I don't know which one to trust.
>> 
>> The two approaches are pairwise.t.test() and multcomp, although the latter is not available after a repeated-measures aov model, but it is after a lme.
>> 
>> I have a physiological variable measured frequently on each of 67 animals. These are then summarized with a quantile for each animal. To check the effect of experiment duration, I recalculated the quantile for each animal 4 times, using different subset of the data (so the shortest subset is part of all other subsets, the second subset is included in the 2 others, etc.). I handle this as 4 repeated (non-independent) measurements for each animal, and want to see if the average value (for 67 animals) differs for the 4 different durations.
>> 
>> Because animals with high values for this physiological trait have larger differences between the 4 durations than animals with low values, the observations were log transformed.
>> 
>> I attach the small data set (Rda format) here, but it can be obtained here if the attachment gets stripped:
>> <https://dl.dropboxusercontent.com/u/612902/RepMeasData.Rda>
>> 
>> The data.frame is simply called Data.
>> My code is
>> 
>> load("RepMeasData.Rda")
>> Data_Long = melt(Data, id="Case")
>> names(Data_Long) = c("Case","Duration", "SMR")
>> Data_Long$SMR = log10(Data_Long$SMR)
>> 
>> # I only show essential code to reproduce my opposing results
>> mixmod = lme(SMR ~ Duration, data = Data_Long, random = ~ 1 | Case)
>> anova(mixmod)
>> posthoc <- glht(mixmod, linfct = mcp(Duration = "Tukey"))
>> summary(posthoc)
>>        Simultaneous Tests for General Linear Hypotheses
>> 
>> Multiple Comparisons of Means: Tukey Contrasts
>> 
>> 
>> Fit: lme.formula(fixed = SMR ~ Duration, data = Data_Long, random = ~1 |
>>   Case)
>> 
>> Linear Hypotheses:
>>                 Estimate Std. Error z value Pr(>|z|)
>> Set2 - Set1 == 0 -0.006135   0.003375  -1.818    0.265
>> Set3 - Set1 == 0 -0.002871   0.003375  -0.851    0.830
>> Set4 - Set1 == 0  0.015395   0.003375   4.561   <1e-04 ***
>> Set3 - Set2 == 0  0.003264   0.003375   0.967    0.768
>> Set4 - Set2 == 0  0.021530   0.003375   6.379   <1e-04 ***
>> Set4 - Set3 == 0  0.018266   0.003375   5.412   <1e-04 ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> (Adjusted p values reported -- single-step method)
>> 
>> with(Data_Long, pairwise.t.test(SMR, Duration, p.adjust.method="holm", paired=T))
>>       Pairwise comparisons using paired t tests
>> 
>> data:  SMR and Duration
>> 
>>    Set1    Set2    Set3
>> Set2 < 2e-16 -       -
>> Set3 0.11118 0.10648 -
>> Set4 0.00475 7.9e-05 0.00034
>> 
>> P value adjustment method: holm
>> 
>> So the difference between sets 1 and 2 goes from non significant to very significant, depending on method.
>> 
>> I have other examples with essentially the same type of data and sometimes the two approches differ in the opposing way. In the example shown here, multcomp was more conservative, in some others it yielded a larger number of significant differences.
>> 
>> I admit not mastering all the intricacies of multcomp, but I have used multcomp and other methods of doing multiple comparisons many times before (but never with a repeated measures design), and always found the results very similar. When there were small differences, I trusted multcomp. This time, I get rather large differences and I am worried that I am doing something wrong.
>> 
>> Thanks in advance,
>> 
>> Denis Chabot
>> Fisheries & Oceans Canada
>> 
>> sessionInfo()
>> R version 3.2.0 (2015-04-16)
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> Running under: OS X 10.10.3 (Yosemite)
>> 
>> locale:
>> [1] fr_CA.UTF-8/fr_CA.UTF-8/fr_CA.UTF-8/C/fr_CA.UTF-8/fr_CA.UTF-8
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> other attached packages:
>> [1] multcomp_1.4-0  TH.data_1.0-6   survival_2.38-1 mvtnorm_1.0-2   nlme_3.1-120    car_2.0-25      reshape2_1.4.1
>> 
>> loaded via a namespace (and not attached):
>> [1] Rcpp_0.11.5      magrittr_1.5     splines_3.2.0    MASS_7.3-40      lattice_0.20-31  minqa_1.2.4      stringr_1.0.0
>> [8] plyr_1.8.2       tools_3.2.0      nnet_7.3-9       pbkrtest_0.4-2   parallel_3.2.0   grid_3.2.0       mgcv_1.8-6
>> [15] quantreg_5.11    lme4_1.1-7       Matrix_1.2-0     nloptr_1.0.4     codetools_0.2-11 sandwich_2.3-3   stringi_0.4-1
>> [22] SparseM_1.6      zoo_1.7-12
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From edwinvanl at gmail.com  Wed Jun 24 18:57:17 2015
From: edwinvanl at gmail.com (Edwin van Leeuwen)
Date: Wed, 24 Jun 2015 16:57:17 +0000
Subject: [R] Rcpp cpp11 and R CMD build
In-Reply-To: <CAKxd1KP=apWDo+sg2HU6oOPSCP=tTNci2wadjF-wdLoyE_VZBw@mail.gmail.com>
References: <CACv9t7NasaVy52ukJxZ5WmsT9jN_BxQ2AK1jMH85wi7rMiawyA@mail.gmail.com>
	<CAKxd1KP=apWDo+sg2HU6oOPSCP=tTNci2wadjF-wdLoyE_VZBw@mail.gmail.com>
Message-ID: <CACv9t7OFh_Snd2xyKc_=FVBOhPkHG9q2Vs9GXtygG2Vvwr-ipw@mail.gmail.com>

Thank you! I was missing the SystemRequirements. I guess it could be useful
to add this to the example given here:
http://gallery.rcpp.org/articles/simple-lambda-func-c++11/

Cheers, Edwin

On Wed, 24 Jun 2015 at 17:50 Charles Determan <cdetermanjr at gmail.com> wrote:

> Hi Edwin,
>
> If you look at the build output you will notice that the C++11 compiler
> flag is not being used.  I just created a small package using Rcpp11 and
> your function and it worked without a problem.  I can't give you a specific
> reason without seeing your package but there are some possibilities I would
> guess right away.
>
> 1. Make sure you are 'LinkingTo' Rcpp11 in your DESCRIPTION
> 2. Unless you are using some custom Makevars file, you should set
> 'SystemRequirements: C++11' in your DESCRIPTION
>
> Charles
>
> On Wed, Jun 24, 2015 at 10:07 AM, Edwin van Leeuwen <edwinvanl at gmail.com>
> wrote:
>
>> Hi all,
>>
>> I've just started using Rcpp and am trying to get cpp11 support working.
>> As
>> suggested I added [[Rcpp:plugins(cpp11)]] to my source file and a test
>> function:
>> // [[Rcpp::export]]
>> int useCpp11() {
>>   auto x = 10;
>>   return x;
>> }
>>
>> This works fine when using:
>> sourceCpp(filename)
>> from R, but I would like to be able to compile the package from the
>> command
>> line.
>> R CMD build mypackage
>> fails with the following error:
>> R CMD build ../fluEvidenceSynthesis
>> * checking for file ?../fluEvidenceSynthesis/DESCRIPTION? ... OK
>> * preparing ?fluEvidenceSynthesis?:
>> * checking DESCRIPTION meta-information ... OK
>> * cleaning src
>> * installing the package to process help pages
>>       -----------------------------------
>> * installing *source* package ?fluEvidenceSynthesis? ...
>> ** libs
>> g++ -I/usr/share/R/include -DNDEBUG
>> -I"/home/edwin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/include"
>> -I"/home/edwin/R/x86_64-pc-linux-gnu-library/3.2/BH/include"   -fpic  -g
>> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c RcppExports.cpp -o
>> RcppExports.o
>> g++ -I/usr/share/R/include -DNDEBUG
>> -I"/home/edwin/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/include"
>> -I"/home/edwin/R/x86_64-pc-linux-gnu-library/3.2/BH/include"   -fpic  -g
>> -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c rcpp_hello_world.cpp -o
>> rcpp_hello_world.o
>> rcpp_hello_world.cpp: In function ?int useCpp11()?:
>> rcpp_hello_world.cpp:33:10: error: ?x? does not name a type
>>      auto x = 10;
>>           ^
>> rcpp_hello_world.cpp:34:12: error: ?x? was not declared in this scope
>>      return x;
>>             ^
>> make: *** [rcpp_hello_world.o] Error 1
>> ERROR: compilation failed for package ?fluEvidenceSynthesis?
>> * removing ?/tmp/RtmpWdUduu/Rinst2b601aa285e9/fluEvidenceSynthesis?
>>       -----------------------------------
>> ERROR: package installation failed
>>
>>
>> Any help appreciated.
>>
>> Cheers, Edwin
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From goutyl at 163.com  Wed Jun 24 19:36:32 2015
From: goutyl at 163.com (Jianwen Luo)
Date: Thu, 25 Jun 2015 01:36:32 +0800
Subject: [R] Read large '.csv' files from zipped file
Message-ID: <2015062501363071055825@163.com>

Hi all,
    I use ireadLines function to iterate large '.csv' files from '.zip' file. When I execute the nextElem function in R console, I can only fetch the first line of file content no matter how many times . Example code show as bellow.
> library(iterators) 
> con<-unz(description='g:\\hourly_WIND_2013.zip',filename='hourly_WIND_2013.csv') 
> it<-ireadLines(con) 
> nextElem(it) 
[1] "\"State Code\",\"County Code\",\"Site Num\",\"Parameter Code\",\"POC\",\"Latitude\",\"Longitude\",\"Datum\",\"Parameter Name\",\"Date Local\",\"Time Local\",\"Date GMT\",\"Time GMT\",\"Sample Measurement\",\"Units of Measure\",\"MDL\",\"Uncertainty\",\"Qualifier\",\"Method Type\",\"Method Name\",\"State Name\",\"County Name\",\"Date of Last Change\"" 
> nextElem(it) 
[1] "\"State Code\",\"County Code\",\"Site Num\",\"Parameter Code\",\"POC\",\"Latitude\",\"Longitude\",\"Datum\",\"Parameter Name\",\"Date Local\",\"Time Local\",\"Date GMT\",\"Time GMT\",\"Sample Measurement\",\"Units of Measure\",\"MDL\",\"Uncertainty\",\"Qualifier\",\"Method Type\",\"Method Name\",\"State Name\",\"County Name\",\"Date of Last Change\"" 
> 
    Can anybody tell me what did i missed?

Regards



Jianwen Luo

	[[alternative HTML version deleted]]


From mail at florianlosch.de  Wed Jun 24 18:11:41 2015
From: mail at florianlosch.de (Florian Losch)
Date: Wed, 24 Jun 2015 09:11:41 -0700 (PDT)
Subject: [R] Draw maps on arbitrary Projections
Message-ID: <1435162301128-4709014.post@n4.nabble.com>

I have spatial data from the WRF-model. I don't know what kind of projection
was used to produce these data (neither longitude nor latitude are constant
at any borders), but I have 2D matrixes for each longitude and latitude. The
area covered is North America. How can I add a map using these 2D matrixes? 



--
View this message in context: http://r.789695.n4.nabble.com/Draw-maps-on-arbitrary-Projections-tp4709014.html
Sent from the R help mailing list archive at Nabble.com.


From sallcock at bournemouth.ac.uk  Wed Jun 24 18:34:43 2015
From: sallcock at bournemouth.ac.uk (Samantha Allcock)
Date: Wed, 24 Jun 2015 16:34:43 +0000
Subject: [R] Plotting legend outside of chart area
Message-ID: <894df63327f4467cbd2d6e8c4eea1464@Tremail.bournemouth.ac.uk>

Hello,

I am trying to add a legend to my PCA plot so that it looks neat. I think plotting this outside of the chart area would be good but I cannot seem to fathom the correct code for this. I wondered if anyone could help please?

The code I am using is as follows:

grp<- with(Matan, cut(R_category_no,14, labels=1:14))
cols <- c("grey0", "wheat", "red", "cyan", "orange", "darkolivegreen2", "purple3",
"royalblue", "burlywood4", "orchid", "forestgreen", "green",
"gray", "yellow1")
plot(geopca, display="sites", scaling=3, type="n")
points(geopca, display="sites", scaling=3, col=cols[grp], pch=16)

legend("bottomright", col=c("grey0", "wheat", "red", "cyan", "orange", "darkolivegreen2",
"purple3", "royalblue", "burlywood4", "orchid", "forestgreen", "green",
"gray", "yellow1"), c("Control type 1", "Control type 2",
"External/Courtyard", "Midden", "Animal Occupation",
"External fire installations and ashy deposits",
"Internal fire installations and ashy deposits", "Hearth make-up",
"Floors and surfaces", "Plasters and clay features", "Storage features",
"Platforms and benches", "Mortars", "Roofs and roofing materials"), pch=16,
cex=0.75, bty="n")

Thank you for your time in advance


Dr Samantha Lee Allcock
Faculty of Science and Technology
Department of Archaeology, Anthropology and Forensic Science
Christchurch House Rm: C133
Bournemouth University
Talbot Campus
Poole
BH12 5BB
Tel: 01202 9(62474)

sallcock at bournemouth.ac.uk<mailto:sallcock at bournemouth.ac.uk>
research.bournemouth.ac.uk/2014/07/inea-project-2


BU is a Disability Two Ticks Employer and has signed up to the Mindful Employer charter. Information about the accessibility of University buildings can be found on the BU DisabledGo webpages This email is intended only for the person to whom it is addressed and may contain confidential information. If you have received this email in error, please notify the sender and delete this email, which must not be copied, distributed or disclosed to any other person. Any views or opinions presented are solely those of the author and do not necessarily represent those of Bournemouth University or its subsidiary companies. Nor can any contract be formed on behalf of the University or its subsidiary companies via email.

	[[alternative HTML version deleted]]


From winash12 at gmail.com  Wed Jun 24 18:49:24 2015
From: winash12 at gmail.com (ashwinD12 .)
Date: Wed, 24 Jun 2015 22:19:24 +0530
Subject: [R] Need some help with converting MATLAB .m script to R
Message-ID: <CAH0LXy5sPdMzPSBa6Dho4octOPH1Ag6EyQQQWnLWqyZgpAC5Kw@mail.gmail.com>

Hello,
         I have few scripts that have been written in MATLAB. I need to
translate or convert them into R. They all deal with reading in a netcdf
file and doing some plots. I managed to read in the netcdf file with these
API calls

# Read input file

input_dir = "/home/aan/aa/data/r"
file = "RRR"

input_file = file.path(input_dir,file)

library(ncdf4)

Upto this everything works. Here is the MATLAB code for which I need help

% Plot continental boundaries (rotated latitude/longitude)
figure;
inp.COAST_RLON.data ( inp.COAST_RLON.data< -900 ) = NaN;
inp.COAST_RLAT.data ( inp.COAST_RLAT.data< -900 ) = NaN;
plot(inp.COAST_RLON.data,inp.COAST_RLAT.data,'k');


Regards,
Ashwin.

	[[alternative HTML version deleted]]


From Peter.Alspach at plantandfood.co.nz  Wed Jun 24 22:13:45 2015
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Thu, 25 Jun 2015 08:13:45 +1200
Subject: [R] Plotting legend outside of chart area
In-Reply-To: <894df63327f4467cbd2d6e8c4eea1464@Tremail.bournemouth.ac.uk>
References: <894df63327f4467cbd2d6e8c4eea1464@Tremail.bournemouth.ac.uk>
Message-ID: <E41B375B7520DE4A8C60781AC60B754501EBAAA48D@AKLEXM01.PFR.CO.NZ>

Tena koe Samantha

You probably need to set some graphics parameters such as xpd and mar (see ?par), and then give the ? and y location of the legend rather than 'bottomright' (see ?legend).

HTH ....

Peter Alspach

PS Please don't post in html (see the posting guide) ... P 

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Samantha Allcock
Sent: Thursday, 25 June 2015 4:35 a.m.
To: 'r-help at r-project.org'
Subject: [R] Plotting legend outside of chart area

Hello,

I am trying to add a legend to my PCA plot so that it looks neat. I think plotting this outside of the chart area would be good but I cannot seem to fathom the correct code for this. I wondered if anyone could help please?

The code I am using is as follows:

grp<- with(Matan, cut(R_category_no,14, labels=1:14)) cols <- c("grey0", "wheat", "red", "cyan", "orange", "darkolivegreen2", "purple3", "royalblue", "burlywood4", "orchid", "forestgreen", "green", "gray", "yellow1") plot(geopca, display="sites", scaling=3, type="n") points(geopca, display="sites", scaling=3, col=cols[grp], pch=16)

legend("bottomright", col=c("grey0", "wheat", "red", "cyan", "orange", "darkolivegreen2", "purple3", "royalblue", "burlywood4", "orchid", "forestgreen", "green", "gray", "yellow1"), c("Control type 1", "Control type 2", "External/Courtyard", "Midden", "Animal Occupation", "External fire installations and ashy deposits", "Internal fire installations and ashy deposits", "Hearth make-up", "Floors and surfaces", "Plasters and clay features", "Storage features", "Platforms and benches", "Mortars", "Roofs and roofing materials"), pch=16, cex=0.75, bty="n")

Thank you for your time in advance


Dr Samantha Lee Allcock
Faculty of Science and Technology
Department of Archaeology, Anthropology and Forensic Science Christchurch House Rm: C133 Bournemouth University Talbot Campus Poole
BH12 5BB
Tel: 01202 9(62474)

sallcock at bournemouth.ac.uk<mailto:sallcock at bournemouth.ac.uk>
research.bournemouth.ac.uk/2014/07/inea-project-2


BU is a Disability Two Ticks Employer and has signed up to the Mindful Employer charter. Information about the accessibility of University buildings can be found on the BU DisabledGo webpages This email is intended only for the person to whom it is addressed and may contain confidential information. If you have received this email in error, please notify the sender and delete this email, which must not be copied, distributed or disclosed to any other person. Any views or opinions presented are solely those of the author and do not necessarily represent those of Bournemouth University or its subsidiary companies. Nor can any contract be formed on behalf of the University or its subsidiary companies via email.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
The contents of this e-mail are confidential and may be ...{{dropped:14}}


From edd at debian.org  Wed Jun 24 22:17:44 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 24 Jun 2015 20:17:44 +0000
Subject: [R] Rcpp cpp11 and R CMD build
References: <CACv9t7NasaVy52ukJxZ5WmsT9jN_BxQ2AK1jMH85wi7rMiawyA@mail.gmail.com>
	<CAKxd1KP=apWDo+sg2HU6oOPSCP=tTNci2wadjF-wdLoyE_VZBw@mail.gmail.com>
	<CACv9t7OFh_Snd2xyKc_=FVBOhPkHG9q2Vs9GXtygG2Vvwr-ipw@mail.gmail.com>
Message-ID: <loom.20150624T221543-737@post.gmane.org>

Edwin van Leeuwen <edwinvanl <at> gmail.com> writes:

> 
> Thank you! I was missing the SystemRequirements. I guess it could be useful
> to add this to the example given here:
> http://gallery.rcpp.org/articles/simple-lambda-func-c++11/

No. 

If you actually read the Rcpp documentation--eg the Rcpp Attributes vignette-
--then you'd know the difference between plugin use via sourceCpp() and 
proper package development. 

Which is what we recommend.  We also ask that Rcpp-related questions be asked 
on the rcpp-devel list as they are mostly out-of-context here.

Thanks,  Dirk


From dcarlson at tamu.edu  Wed Jun 24 22:36:59 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 24 Jun 2015 20:36:59 +0000
Subject: [R] create a dummy variables for companies with
	complete	history.
In-Reply-To: <558B00F2.3050008@dewey.myzen.co.uk>
References: <139890578.925548.1435170393135.JavaMail.yahoo@mail.yahoo.com>
	<558B00F2.3050008@dewey.myzen.co.uk>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D69E250@mb02.ads.tamu.edu>

You may want to consider another way of getting your answer that takes advantage of some of R's features:

> # Make some example data
> cods <- LETTERS[1:10] # Ten companies
> yrs <- 2010:2014 # 5 years
> set.seed(42) # Set random seed so we all get the same values
> # Chances of revenue for a given year are 95%
> rev <- round(rbinom(50, 1, .95)*runif(50, 25, 50), 2)
> z <- data.frame(expand.grid(year=yrs, cod=cods)[, 2:1], rev)
> # Remove years with missing (0) revenue
> z <- z[z$rev > 1, ]
> str(z)
'data.frame':   45 obs. of  3 variables:
 $ cod : Factor w/ 10 levels "A","B","C","D",..: 1 1 1 1 1 2 2 2 2 2 ...
 $ year: int  2010 2011 2012 2013 2014 2010 2011 2012 2013 2014 ...
 $ rev : num  33.3 33.7 35 44.6 26 ...
> 
> # Construct the dummy variable
> tbl <- xtabs(~cod+year, z)
> tbl
   year
cod 2010 2011 2012 2013 2014
  A    1    1    1    1    1
  B    1    1    1    1    1
  C    1    1    1    1    1
  D    1    0    1    1    1
  E    1    1    0    1    1
  F    1    1    1    1    1
  G    1    1    1    1    1
  H    1    1    1    1    1
  I    1    1    1    0    1
  J    0    1    1    0    1
> dummy <- as.integer(apply(tbl, 1, all))
> dummy
 [1] 1 1 1 0 0 1 1 1 0 0

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael Dewey
Sent: Wednesday, June 24, 2015 2:12 PM
To: giacomo begnis; r-help at r-project.org
Subject: Re: [R] create a dummy variables for companies with complete history.

Comments below

On 24/06/2015 19:26, giacomo begnis wrote:
> Hi, I have a dataset  (728 obs) containing three variables code of a company, year and revenue. Some companies have a complete history of 5 years, others have not a complete history (for instance observations for three or four years).I would like to determine the companies with a complete history using a dummy variables.I have written the following program but there is somehting wrong because the dummy variable that I have create is always equal to zero.Can somebody help me?Thanks, gm
>
> z<-read.table(file="c:/Rp/cddat.txt", sep="", header=T)
> attach(z)
> n<-length(z$cod)  // number of obs dataset
>

Could also use nrow(z)

> d1<-numeric(n)   // dummy variable
>
> for (i in 5:n)  {
>     if (z$cod[i]==z$cod[i-4])             // cod is the code of a company

              { d1[i]<=1} else { d1[i]<=0}          // d1=1 for a 
company with complete history, d1=0 if the history is not complete  }d1

Did you really type <= which means less than or equals to? If so, try 
replacing it with <- and see what happens.

> When I run the program d1 is always equal to zero. Why?
> Once I have create the dummy variable with subset I obtains the code of the companies with a complete history and finally with a merge  I determine a panel of companies with a complete history.But how to determine correctly d1?My best regards, gm
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From n.l.pace at utah.edu  Wed Jun 24 22:39:55 2015
From: n.l.pace at utah.edu (Nathan Pace)
Date: Wed, 24 Jun 2015 20:39:55 +0000
Subject: [R] unlisting dplyr do output
Message-ID: <D1B071B8.62210%n.l.pace@utah.edu>

I used the dplyr do function to apply a kernel regression smoother to a 3
column data table (grouping index, x, y) with about 7 M rows and 45000
groups.

This runs quickly, about 1-2 minutes.

It creates an data table (44,326 by 2) - grouping index, kernel smoothing
output.

The kernel smoothing output is a list of two element lists (x, smoothed y).

I used a for loop to unlist this into a data table.

  for (i in 1:nrow(do object)) {
df <- bind_rows(list(df,
                                  data.frame(grouping index = do object[i],
                                             x = do object[[i]]$x,
                                             y = do object[[i]]$smoothed
y)))
}


This takes about 100 minutes.

Any guidance for a faster (more elegant?) solution will be appreciated.

Nathan 


From msharp at txbiomed.org  Wed Jun 24 23:00:59 2015
From: msharp at txbiomed.org (Mark Sharp)
Date: Wed, 24 Jun 2015 21:00:59 +0000
Subject: [R] create a dummy variables for companies with complete
	history.
In-Reply-To: <139890578.925548.1435170393135.JavaMail.yahoo@mail.yahoo.com>
References: <139890578.925548.1435170393135.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <BF2F2917-2EAB-4212-AAB6-3300F4727003@txbiomed.org>

Giacomo,

Please include some representative data. It is not clear why your offset of 4 (z$cod[i - 4]) is going to be an accurate surrogate for complete data.

Since I do not have your data set or its true structure I am having to guess.
# make 5 copies of 200 companies
companies <- paste0(rep(LETTERS[1:4], 5, each = 50), rep(1:50, 5))
companies <- companies[order(companies)]
years <- rep(1:5, 200)
z <- data.frame(cod = companies, year = years,
                revenue = round(rnorm(1000, mean = 100000, sd = 10000)))
# trim this down to the 728 rows you have by pulling out records at random
set.seed(1) # so that you can repeat these results
z <- z[sample.int(1000, 728), ]
z <- z[order(z$cod, z$year), ]

#No matter how you order these data, your offset approach will not tell you which companies have full records.
> head(z, 10)
   cod year revenue
1   A1    1  112192
2   A1    2  105840
4   A1    4  112357
5   A1    5   91772
7  A10    2  102601
8  A10    3  105183
11 A11    1  101269
12 A11    2  100719
14 A11    4   86138
15 A11    5  105044

#You can do something like the following.

counts <- table(z$cod)
complete <- names(counts[as.integer(counts) == 5])
# It is probably better to keep the dummy variable inside the dataframe.
z$complete <- ifelse(z$cod %in% complete, TRUE, FALSE)

> head(z, 20)
   cod year revenue complete
1   A1    1  112192    FALSE
2   A1    2  105840    FALSE
4   A1    4  112357    FALSE
5   A1    5   91772    FALSE
7  A10    2  102601    FALSE
8  A10    3  105183    FALSE
11 A11    1  101269    FALSE
12 A11    2  100719    FALSE
14 A11    4   86138    FALSE
15 A11    5  105044    FALSE
20 A12    5   95872    FALSE
21 A13    1   78513     TRUE
22 A13    2   90502     TRUE
23 A13    3  108683     TRUE
24 A13    4  110711     TRUE
25 A13    5   87842     TRUE
28 A14    3   99939    FALSE
30 A14    5  111289    FALSE
31 A15    1  100930    FALSE
32 A15    2   93765    FALSE
> 
Do not use HTML. Use plain text. The character string "//" is not a comment indicator in R. Do not use attach(). It does not do anything in your example, but it is poor practice. Always write out TRUE and FALSE
R. Mark Sharp, Ph.D.
msharp at TxBiomed.org





> On Jun 24, 2015, at 1:26 PM, giacomo begnis <gmbegnis at yahoo.it> wrote:
> 
> Hi, I have a dataset  (728 obs) containing three variables code of a company, year and revenue. Some companies have a complete history of 5 years, others have not a complete history (for instance observations for three or four years).I would like to determine the companies with a complete history using a dummy variables.I have written the following program but there is somehting wrong because the dummy variable that I have create is always equal to zero.Can somebody help me?Thanks, gm
> 
> z<-read.table(file="c:/Rp/cddat.txt", sep="", header=T)
> attach(z)
> n<-length(z$cod)  // number of obs dataset
> 
> d1<-numeric(n)   // dummy variable
> 
> for (i in 5:n)  {
>    if (z$cod[i]==z$cod[i-4])             // cod is the code of a company             { d1[i]<=1} else { d1[i]<=0}          // d1=1 for a company with complete history, d1=0 if the history is not complete  }d1
> When I run the program d1 is always equal to zero. Why?
> Once I have create the dummy variable with subset I obtains the code of the companies with a complete history and finally with a merge  I determine a panel of companies with a complete history.But how to determine correctly d1?My best regards, gm
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Jun 24 23:37:56 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 24 Jun 2015 14:37:56 -0700
Subject: [R] repeated measures: multiple comparisons with
	pairwise.t.test and multcomp disagree
In-Reply-To: <CAGxFJbQ4HzZ74ZkAf3eEAhkRSawXwjGYpHRzG=wChN2wAU53iA@mail.gmail.com>
References: <5C2FF04C-262D-4D96-A493-A62F149DA76A@me.com>
	<CAJuCY5xMk1=662vX9x50TvnGx3_qHHphL8sU67cOoEFVCqcJtg@mail.gmail.com>
	<A10A6826-3042-4D3E-A101-E59F14EC24AA@me.com>
	<CAGxFJbQ4HzZ74ZkAf3eEAhkRSawXwjGYpHRzG=wChN2wAU53iA@mail.gmail.com>
Message-ID: <AB2EFD9F-CB61-41CC-A7DB-8F5CAFDB3C20@dcn.davis.CA.us>

Bert, can you be more specific about which article for those of us who don't subscribe?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 24, 2015 12:13:05 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>I would **strongly** recommend that you speak with a local statistical
>expert before proceeding further. Your obsession with statistical
>significance is very dangerous. (see the current issue of SIGNIFICANCE
>for some explanation).
>
>Cheers,
>Bert
>Bert Gunter
>
>"Data is not information. Information is not knowledge. And knowledge
>is certainly not wisdom."
>   -- Clifford Stoll
>
>
>On Wed, Jun 24, 2015 at 10:30 AM, Denis Chabot <denis.chabot at me.com>
>wrote:
>> Thank you, Thierry. And yes, Bert, it turns out that it is more of a
>statistical question after all, but again, since my question used
>specific R functions, R experts are well placed to help me.
>>
>> As pairewise.t.test was recommended in a few tutorials about
>repeated-measure Anovas, I assumed it took into account the fact that
>the measures were indeed repeated, so thank you for pointing out that
>it does not.
>>
>> But my reason for not accepting the result of multcomp went further
>than this. Before deciding to test 4 different durations, I had tested
>only two of them, corresponding to sets 1 and 2 of my example. I used a
>paired t test (as in t test for paired samples). I had a very
>significant effect, i.e. the mean of the differences calculated for
>each subject was significantly different from zero.
>>
>> After adding two other durations and switching from my paired t test
>to a repeated measures design, these same 2 sets are no longer
>different. I think the explanation is lack of homogeneity of variances.
>I thought a log transformation of the raw data had been sufficient to
>fix this, and a Levene test on the variances of the 4 sets found no
>problem in this regard.
>>
>> But maybe it is the variance of all the possible differences (set 1
>vs 2, etc, for a total of 6 differences calculated for each subject)
>that matters.  I just calculated these and they range from 1.788502e-05
>to 1.462171e-03. A Levene test on these 6 "groups" showed that their
>variances were heterogeneous.
>>
>> I think I'll stay away from  the "repeated measures followed by
>multiple comparisons" and just report my 6 t tests for paired samples,
>correcting the p-level for the number of comparisons with, say, the
>Sidak method (p for significance is then 0.0085).
>>
>> Thanks for your help.
>>
>> Denis
>>
>>> Le 2015-06-23 ? 08:15, Thierry Onkelinx <thierry.onkelinx at inbo.be> a
>?crit :
>>>
>>> Dear Denis,
>>>
>>> It's not multcomp which is too conservative, it is the pairwise
>t-test
>>> which is too liberal. The pairwise t-test doesn't take the random
>>> effect of Case into account.
>>>
>>> Best regards,
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for
>Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no
>>> more than asking him to perform a post-mortem examination: he may be
>>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does
>>> not ensure that a reasonable answer can be extracted from a given
>body
>>> of data. ~ John Tukey
>>>
>>>
>>> 2015-06-23 5:17 GMT+02:00 Denis Chabot <denis.chabot at me.com>:
>>>> Hi,
>>>>
>>>> I am working on a problem which I think can be handled as a
>repeated measures analysis, and I have read many tutorials about how to
>do this with R. This part goes well, but I get stuck with the multiple
>comparisons I'd like to run afterward. I tried two methods that I have
>seen in my readings, but their results are quite different and I don't
>know which one to trust.
>>>>
>>>> The two approaches are pairwise.t.test() and multcomp, although the
>latter is not available after a repeated-measures aov model, but it is
>after a lme.
>>>>
>>>> I have a physiological variable measured frequently on each of 67
>animals. These are then summarized with a quantile for each animal. To
>check the effect of experiment duration, I recalculated the quantile
>for each animal 4 times, using different subset of the data (so the
>shortest subset is part of all other subsets, the second subset is
>included in the 2 others, etc.). I handle this as 4 repeated
>(non-independent) measurements for each animal, and want to see if the
>average value (for 67 animals) differs for the 4 different durations.
>>>>
>>>> Because animals with high values for this physiological trait have
>larger differences between the 4 durations than animals with low
>values, the observations were log transformed.
>>>>
>>>> I attach the small data set (Rda format) here, but it can be
>obtained here if the attachment gets stripped:
>>>> <https://dl.dropboxusercontent.com/u/612902/RepMeasData.Rda>
>>>>
>>>> The data.frame is simply called Data.
>>>> My code is
>>>>
>>>> load("RepMeasData.Rda")
>>>> Data_Long = melt(Data, id="Case")
>>>> names(Data_Long) = c("Case","Duration", "SMR")
>>>> Data_Long$SMR = log10(Data_Long$SMR)
>>>>
>>>> # I only show essential code to reproduce my opposing results
>>>> mixmod = lme(SMR ~ Duration, data = Data_Long, random = ~ 1 | Case)
>>>> anova(mixmod)
>>>> posthoc <- glht(mixmod, linfct = mcp(Duration = "Tukey"))
>>>> summary(posthoc)
>>>>        Simultaneous Tests for General Linear Hypotheses
>>>>
>>>> Multiple Comparisons of Means: Tukey Contrasts
>>>>
>>>>
>>>> Fit: lme.formula(fixed = SMR ~ Duration, data = Data_Long, random =
>~1 |
>>>>   Case)
>>>>
>>>> Linear Hypotheses:
>>>>                 Estimate Std. Error z value Pr(>|z|)
>>>> Set2 - Set1 == 0 -0.006135   0.003375  -1.818    0.265
>>>> Set3 - Set1 == 0 -0.002871   0.003375  -0.851    0.830
>>>> Set4 - Set1 == 0  0.015395   0.003375   4.561   <1e-04 ***
>>>> Set3 - Set2 == 0  0.003264   0.003375   0.967    0.768
>>>> Set4 - Set2 == 0  0.021530   0.003375   6.379   <1e-04 ***
>>>> Set4 - Set3 == 0  0.018266   0.003375   5.412   <1e-04 ***
>>>> ---
>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>> (Adjusted p values reported -- single-step method)
>>>>
>>>> with(Data_Long, pairwise.t.test(SMR, Duration,
>p.adjust.method="holm", paired=T))
>>>>       Pairwise comparisons using paired t tests
>>>>
>>>> data:  SMR and Duration
>>>>
>>>>    Set1    Set2    Set3
>>>> Set2 < 2e-16 -       -
>>>> Set3 0.11118 0.10648 -
>>>> Set4 0.00475 7.9e-05 0.00034
>>>>
>>>> P value adjustment method: holm
>>>>
>>>> So the difference between sets 1 and 2 goes from non significant to
>very significant, depending on method.
>>>>
>>>> I have other examples with essentially the same type of data and
>sometimes the two approches differ in the opposing way. In the example
>shown here, multcomp was more conservative, in some others it yielded a
>larger number of significant differences.
>>>>
>>>> I admit not mastering all the intricacies of multcomp, but I have
>used multcomp and other methods of doing multiple comparisons many
>times before (but never with a repeated measures design), and always
>found the results very similar. When there were small differences, I
>trusted multcomp. This time, I get rather large differences and I am
>worried that I am doing something wrong.
>>>>
>>>> Thanks in advance,
>>>>
>>>> Denis Chabot
>>>> Fisheries & Oceans Canada
>>>>
>>>> sessionInfo()
>>>> R version 3.2.0 (2015-04-16)
>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>> Running under: OS X 10.10.3 (Yosemite)
>>>>
>>>> locale:
>>>> [1] fr_CA.UTF-8/fr_CA.UTF-8/fr_CA.UTF-8/C/fr_CA.UTF-8/fr_CA.UTF-8
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods  
>base
>>>>
>>>> other attached packages:
>>>> [1] multcomp_1.4-0  TH.data_1.0-6   survival_2.38-1 mvtnorm_1.0-2  
>nlme_3.1-120    car_2.0-25      reshape2_1.4.1
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] Rcpp_0.11.5      magrittr_1.5     splines_3.2.0    MASS_7.3-40 
>    lattice_0.20-31  minqa_1.2.4      stringr_1.0.0
>>>> [8] plyr_1.8.2       tools_3.2.0      nnet_7.3-9      
>pbkrtest_0.4-2   parallel_3.2.0   grid_3.2.0       mgcv_1.8-6
>>>> [15] quantreg_5.11    lme4_1.1-7       Matrix_1.2-0    
>nloptr_1.0.4     codetools_0.2-11 sandwich_2.3-3   stringi_0.4-1
>>>> [22] SparseM_1.6      zoo_1.7-12
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Jun 24 23:55:03 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 24 Jun 2015 14:55:03 -0700
Subject: [R] repeated measures: multiple comparisons with
 pairwise.t.test and multcomp disagree
In-Reply-To: <AB2EFD9F-CB61-41CC-A7DB-8F5CAFDB3C20@dcn.davis.CA.us>
References: <5C2FF04C-262D-4D96-A493-A62F149DA76A@me.com>
	<CAJuCY5xMk1=662vX9x50TvnGx3_qHHphL8sU67cOoEFVCqcJtg@mail.gmail.com>
	<A10A6826-3042-4D3E-A101-E59F14EC24AA@me.com>
	<CAGxFJbQ4HzZ74ZkAf3eEAhkRSawXwjGYpHRzG=wChN2wAU53iA@mail.gmail.com>
	<AB2EFD9F-CB61-41CC-A7DB-8F5CAFDB3C20@dcn.davis.CA.us>
Message-ID: <CAGxFJbTm+UcsiGkgE94rc-jPqP+s2s9Sk+W6+rnNONMTLywR9w@mail.gmail.com>

Andrew Gelman's "Working Through Some Issues" and the two Letters to
the Editor that follow responding to the editorial decision to ban P
values from The Journal of Basic and Applied Social Psychology (BASP).
You may wish also to read ASA President's David Morgenstern's
reflexive and entirely predictable reaction (P-values are OK; it's
their abuse/misuse that is the problem) in the June 2015 Amstat News.

While I have lots of personal opinions on this, this is not the venue
to (further?) air them. If you wish to engage me -- pro or con; I
welcome both -- please respond privately. I will not comment further
on list.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Wed, Jun 24, 2015 at 2:37 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Bert, can you be more specific about which article for those of us who don't subscribe?
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On June 24, 2015 12:13:05 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>I would **strongly** recommend that you speak with a local statistical
>>expert before proceeding further. Your obsession with statistical
>>significance is very dangerous. (see the current issue of SIGNIFICANCE
>>for some explanation).
>>
>>Cheers,
>>Bert
>>Bert Gunter
>>
>>"Data is not information. Information is not knowledge. And knowledge
>>is certainly not wisdom."
>>   -- Clifford Stoll
>>
>>
>>On Wed, Jun 24, 2015 at 10:30 AM, Denis Chabot <denis.chabot at me.com>
>>wrote:
>>> Thank you, Thierry. And yes, Bert, it turns out that it is more of a
>>statistical question after all, but again, since my question used
>>specific R functions, R experts are well placed to help me.
>>>
>>> As pairewise.t.test was recommended in a few tutorials about
>>repeated-measure Anovas, I assumed it took into account the fact that
>>the measures were indeed repeated, so thank you for pointing out that
>>it does not.
>>>
>>> But my reason for not accepting the result of multcomp went further
>>than this. Before deciding to test 4 different durations, I had tested
>>only two of them, corresponding to sets 1 and 2 of my example. I used a
>>paired t test (as in t test for paired samples). I had a very
>>significant effect, i.e. the mean of the differences calculated for
>>each subject was significantly different from zero.
>>>
>>> After adding two other durations and switching from my paired t test
>>to a repeated measures design, these same 2 sets are no longer
>>different. I think the explanation is lack of homogeneity of variances.
>>I thought a log transformation of the raw data had been sufficient to
>>fix this, and a Levene test on the variances of the 4 sets found no
>>problem in this regard.
>>>
>>> But maybe it is the variance of all the possible differences (set 1
>>vs 2, etc, for a total of 6 differences calculated for each subject)
>>that matters.  I just calculated these and they range from 1.788502e-05
>>to 1.462171e-03. A Levene test on these 6 "groups" showed that their
>>variances were heterogeneous.
>>>
>>> I think I'll stay away from  the "repeated measures followed by
>>multiple comparisons" and just report my 6 t tests for paired samples,
>>correcting the p-level for the number of comparisons with, say, the
>>Sidak method (p for significance is then 0.0085).
>>>
>>> Thanks for your help.
>>>
>>> Denis
>>>
>>>> Le 2015-06-23 ? 08:15, Thierry Onkelinx <thierry.onkelinx at inbo.be> a
>>?crit :
>>>>
>>>> Dear Denis,
>>>>
>>>> It's not multcomp which is too conservative, it is the pairwise
>>t-test
>>>> which is too liberal. The pairwise t-test doesn't take the random
>>>> effect of Case into account.
>>>>
>>>> Best regards,
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek / Research Institute for
>>Nature
>>>> and Forest
>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>>Assurance
>>>> Kliniekstraat 25
>>>> 1070 Anderlecht
>>>> Belgium
>>>>
>>>> To call in the statistician after the experiment is done may be no
>>>> more than asking him to perform a post-mortem examination: he may be
>>>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does
>>>> not ensure that a reasonable answer can be extracted from a given
>>body
>>>> of data. ~ John Tukey
>>>>
>>>>
>>>> 2015-06-23 5:17 GMT+02:00 Denis Chabot <denis.chabot at me.com>:
>>>>> Hi,
>>>>>
>>>>> I am working on a problem which I think can be handled as a
>>repeated measures analysis, and I have read many tutorials about how to
>>do this with R. This part goes well, but I get stuck with the multiple
>>comparisons I'd like to run afterward. I tried two methods that I have
>>seen in my readings, but their results are quite different and I don't
>>know which one to trust.
>>>>>
>>>>> The two approaches are pairwise.t.test() and multcomp, although the
>>latter is not available after a repeated-measures aov model, but it is
>>after a lme.
>>>>>
>>>>> I have a physiological variable measured frequently on each of 67
>>animals. These are then summarized with a quantile for each animal. To
>>check the effect of experiment duration, I recalculated the quantile
>>for each animal 4 times, using different subset of the data (so the
>>shortest subset is part of all other subsets, the second subset is
>>included in the 2 others, etc.). I handle this as 4 repeated
>>(non-independent) measurements for each animal, and want to see if the
>>average value (for 67 animals) differs for the 4 different durations.
>>>>>
>>>>> Because animals with high values for this physiological trait have
>>larger differences between the 4 durations than animals with low
>>values, the observations were log transformed.
>>>>>
>>>>> I attach the small data set (Rda format) here, but it can be
>>obtained here if the attachment gets stripped:
>>>>> <https://dl.dropboxusercontent.com/u/612902/RepMeasData.Rda>
>>>>>
>>>>> The data.frame is simply called Data.
>>>>> My code is
>>>>>
>>>>> load("RepMeasData.Rda")
>>>>> Data_Long = melt(Data, id="Case")
>>>>> names(Data_Long) = c("Case","Duration", "SMR")
>>>>> Data_Long$SMR = log10(Data_Long$SMR)
>>>>>
>>>>> # I only show essential code to reproduce my opposing results
>>>>> mixmod = lme(SMR ~ Duration, data = Data_Long, random = ~ 1 | Case)
>>>>> anova(mixmod)
>>>>> posthoc <- glht(mixmod, linfct = mcp(Duration = "Tukey"))
>>>>> summary(posthoc)
>>>>>        Simultaneous Tests for General Linear Hypotheses
>>>>>
>>>>> Multiple Comparisons of Means: Tukey Contrasts
>>>>>
>>>>>
>>>>> Fit: lme.formula(fixed = SMR ~ Duration, data = Data_Long, random =
>>~1 |
>>>>>   Case)
>>>>>
>>>>> Linear Hypotheses:
>>>>>                 Estimate Std. Error z value Pr(>|z|)
>>>>> Set2 - Set1 == 0 -0.006135   0.003375  -1.818    0.265
>>>>> Set3 - Set1 == 0 -0.002871   0.003375  -0.851    0.830
>>>>> Set4 - Set1 == 0  0.015395   0.003375   4.561   <1e-04 ***
>>>>> Set3 - Set2 == 0  0.003264   0.003375   0.967    0.768
>>>>> Set4 - Set2 == 0  0.021530   0.003375   6.379   <1e-04 ***
>>>>> Set4 - Set3 == 0  0.018266   0.003375   5.412   <1e-04 ***
>>>>> ---
>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>> (Adjusted p values reported -- single-step method)
>>>>>
>>>>> with(Data_Long, pairwise.t.test(SMR, Duration,
>>p.adjust.method="holm", paired=T))
>>>>>       Pairwise comparisons using paired t tests
>>>>>
>>>>> data:  SMR and Duration
>>>>>
>>>>>    Set1    Set2    Set3
>>>>> Set2 < 2e-16 -       -
>>>>> Set3 0.11118 0.10648 -
>>>>> Set4 0.00475 7.9e-05 0.00034
>>>>>
>>>>> P value adjustment method: holm
>>>>>
>>>>> So the difference between sets 1 and 2 goes from non significant to
>>very significant, depending on method.
>>>>>
>>>>> I have other examples with essentially the same type of data and
>>sometimes the two approches differ in the opposing way. In the example
>>shown here, multcomp was more conservative, in some others it yielded a
>>larger number of significant differences.
>>>>>
>>>>> I admit not mastering all the intricacies of multcomp, but I have
>>used multcomp and other methods of doing multiple comparisons many
>>times before (but never with a repeated measures design), and always
>>found the results very similar. When there were small differences, I
>>trusted multcomp. This time, I get rather large differences and I am
>>worried that I am doing something wrong.
>>>>>
>>>>> Thanks in advance,
>>>>>
>>>>> Denis Chabot
>>>>> Fisheries & Oceans Canada
>>>>>
>>>>> sessionInfo()
>>>>> R version 3.2.0 (2015-04-16)
>>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>>> Running under: OS X 10.10.3 (Yosemite)
>>>>>
>>>>> locale:
>>>>> [1] fr_CA.UTF-8/fr_CA.UTF-8/fr_CA.UTF-8/C/fr_CA.UTF-8/fr_CA.UTF-8
>>>>>
>>>>> attached base packages:
>>>>> [1] stats     graphics  grDevices utils     datasets  methods
>>base
>>>>>
>>>>> other attached packages:
>>>>> [1] multcomp_1.4-0  TH.data_1.0-6   survival_2.38-1 mvtnorm_1.0-2
>>nlme_3.1-120    car_2.0-25      reshape2_1.4.1
>>>>>
>>>>> loaded via a namespace (and not attached):
>>>>> [1] Rcpp_0.11.5      magrittr_1.5     splines_3.2.0    MASS_7.3-40
>>    lattice_0.20-31  minqa_1.2.4      stringr_1.0.0
>>>>> [8] plyr_1.8.2       tools_3.2.0      nnet_7.3-9
>>pbkrtest_0.4-2   parallel_3.2.0   grid_3.2.0       mgcv_1.8-6
>>>>> [15] quantreg_5.11    lme4_1.1-7       Matrix_1.2-0
>>nloptr_1.0.4     codetools_0.2-11 sandwich_2.3-3   stringi_0.4-1
>>>>> [22] SparseM_1.6      zoo_1.7-12
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>


From friendly at yorku.ca  Thu Jun 25 00:04:36 2015
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 25 Jun 2015 00:04:36 +0200
Subject: [R] Usage of vcd packages.
In-Reply-To: <CAFpdVnzx-_Kj7n4mO4fAx+W2-2a2grQ_i2nHFUdv++X42NYnFQ@mail.gmail.com>
References: <CAFpdVnzx-_Kj7n4mO4fAx+W2-2a2grQ_i2nHFUdv++X42NYnFQ@mail.gmail.com>
Message-ID: <558B2974.7040908@yorku.ca>

On 6/23/15 4:07 PM, My List wrote:
> All,
>
> I am new to the vcd package and new to R too.
Welcome to R and glad you found the vcd package.
>
> 1) I have a lickert analysis based data set.
> 2) I am doing a hypothesis tests on the variables ( like, is there a
> relationship between the choice of a Doctor based on the Patients Income ,
> that's just one example)
> 3) I am building contingency tables ( R x C) and running chiqsqr.test on
> these tables.
>
> These are mostly 2 x 2 tables. In some cases I am getting very low counts
> of the variables in these ( R x C )  tables. I wanted to know at what point
> do I need to use
Your questions are reasonable concerns for someone doing this sort of 
analysis with possibly small cell counts, but without any details,
you are really asking for statistical consulting help, rather than
R-help, and you would be better off posting your questions to
http://stats.stackexchange.com/


> How do I show if there is any association between the variables in the R x
> C setup?Should be I  using oddratio() or or assocstats() or should I use
> Cramers V test for 2 x 2 tables.
odds ratios, Cramer`s V etc. are different ways of quantifying the 
degree of association, with different metrics and different 
interpretations of the numbers.

>
> Please, advice or lead me to a source.
Perhaps the notes from my old short course on categorical data might be 
useful, particularly lecture 2

http://www.datavis.ca/courses/VCD/

More generally, since you`re using vcd, you may find more comfort with 
the visual methods fourfold(), mosaic() and friends than with the
numerical summaries.
>
> *Example of Case - Age of patients and If the Dr Justified a Diagnostic
> Test on them.*
>
>
>
>
>
>
>
> DrJustifyDgntTstNo
>
> DrJustifyDgntTstYes
>
>
>
> Age21-40
>
> 1
>
> 91
>
>
>
> Age41-50
>
> 4
>
> 30
>
>
>
> GtrThan51
>
> 3
>
> 50
>
>
>
>
>
>
>
>
> Thanks in advance,
> Harmeet
>
> 	[[alternative HTML version deleted]]
>


From dwinsemius at comcast.net  Thu Jun 25 00:15:49 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 24 Jun 2015 15:15:49 -0700
Subject: [R] Broken links (???) in rw-FAQ
In-Reply-To: <558AEE63.70908@mail.usask.ca>
References: <558AEE63.70908@mail.usask.ca>
Message-ID: <191EF1B6-A58C-496F-955B-4F3094E66C90@comcast.net>


On Jun 24, 2015, at 10:52 AM, Chel Hee Lee wrote:

> Could you also kindly check the following links in the rw-FAQ manual at <http://cran.r-project.org/bin/windows/base/rw-FAQ.html>??  The links list in the below seem to be broken.   I hope these links are fixed in the very near future.
> 
> Under the section 2.4 Can I customize the installation?
> 
> * Setup (http://jrsoftware.org/ishelp.php) for details.
> 
> Under the section 3.3 I want to run R in Chinese/Japanese/Korean
> 
> * http://msdn.microsoft.com/library/default.asp?url=/library/en-us/vccore98/html/_crt_language_and_country_strings.asp
> 
> Under the section 2.26 There is no tilde on my keyboard!
> 
> * http://office.microsoft.com/en-us/word/HP052590631033.aspx

With regard to this one, there was a discussion of this just yesterday in StackOverflow (relative to Italian keyboards which don't seem to be mentioned in the current version of the rw-FAQ). Admittedly this material is not immediately relevant to a windows setup since the question was coming from a Linux user.

http://stackoverflow.com/questions/31015152/how-to-type-tilde-in-r

 http://superuser.com/questions/667622/italian-keyboard-entering-the-tilde-and-backtick-characters-without-cha

Looking at some of the linked material, it appears that Windows and Linux have distinctly different answers to tilde-deficient keyboard concerns, so there might be a reason to move a more general answer to R-FAQ and perhaps include material in the section on Internationalization? I could find no mention of tilde-problems in the R-FAQ or the Admin/Setup document.

> 
> This link is in fact moved to
> 
> https://support.office.com/en-us/article/HP052590631?CorrelationId=98eaa529-e95a-4628-90ac-1a1da4526b17

That link was 404-ed when I tried it.

> Under the section 2.24 Does R run under Windows Vista/7/8/Server 2008?
> 
> * http://windowsvistablog.com/blogs/windowsvista/archive/2007/01/23/security-features-vs-convenience.aspx
> 
> I appreciate your help!
> 
> Chel Hee Lee
> 
-- 

David Winsemius
Alameda, CA, USA


From dulcalma at bigpond.com  Thu Jun 25 02:15:07 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 25 Jun 2015 10:15:07 +1000
Subject: [R] R lattice : labeling of matrix groups of different size
	with	strips
In-Reply-To: <CAKy6djnrm2rW3SSRy4eWk9xeRdMFksA+GhaJPR6-27560nWtTQ@mail.gmail.com>
References: <CAKy6djnrm2rW3SSRy4eWk9xeRdMFksA+GhaJPR6-27560nWtTQ@mail.gmail.com>
Message-ID: <000901d0aedb$fefb0940$fcf11bc0$@bigpond.com>

Hi

I am not sure what you want

plotMatrix
, , group1

  a b c d
1 1 0 0 0
2 1 0 0 0
3 1 1 0 0
4 0 1 0 0
5 0 1 1 0

, , group2

   a  b  c  d
1  0  0  1  0
2  0  0  1  1
3  0  0  0  1
4 NA NA NA NA
5 NA NA NA NA

If you do not want to show the NA's without giving them a different colour then here is a cludgy way of doing things

print(
levelplot(plotMatrix[1:3,,2],
          page     = function(n){
                       grid.text(paste("group2"),
                                 x = 0.5,
                                 y = 0.96,
                                 default.units = "npc",
                                 just = c("left", "bottom"),
                                 gp = gpar(fontsize = 12) )
                      },
          colorkey = F,
          xlab = "",
          ylab=""),
position = c(0.2,0,0.8,0.5), more = TRUE)
print(
levelplot(plotMatrix[,,1],
          page     = function(n){
                       grid.text(paste("group1"),
                                 x = 0.5,
                                 y = 0.96,
                                 default.units = "npc",
                                 just = c("left", "bottom"),
                                 gp = gpar(fontsize = 12) )
                      },
          colorkey = F,
          xlab = "",
         ylab=""),
position = c(0,0.5,1,1), more = FALSE)

It will depend on your device so you will have to amend the position settings of group n and size of plots.

using the page argument saves having to do a panel function 

If you wanted to have the strip that is a different matter

Regards

Duncan

PS Does this suit?

library(latticeExtra)
c(levelplot(plotMatrix[,,1],colorkey=F,xlab="",ylab=""),levelplot(plotMatrix[1:3,,2],colorkey=F,xlab="",ylab=""))

just using the defaults. have not got time to explore further
you may have to annotate groups by grid.text  with or without trellis.focus

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au 
 



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of R codeplayer
Sent: Wednesday, 24 June 2015 23:10
To: r-help at r-project.org
Subject: [R] R lattice : labeling of matrix groups of different size with strips

In R lattice, I am trying to label predefined groups of rows in a
matrix of data with strips. Currently, the length of the strips fail
to match the different sizes of the groups as the data representation
only allows groups with the same size.

One possibility to solve this might be to suppress the display of
NAs, but I did not find any configuration to realize
this in Lattice.

The example code below shows a matrix (m) with 8 rows and 4 columns.
Group 1 contains row 1-5 and group 2 contains row 6-8. The lattice
output is attached below the code.

Thank you for your time



library(lattice)

m <- matrix(c(1,1,1,0,0,0,0,0,
            0,0,1,1,1,0,0,0,
            0,0,0,0,1,1,1,0,
            0,0,0,0,0,0,1,1),nrow=8,ncol=4)

group1 <- m[1:5,]
group2 <- m[6:nrow(m),]

plotMatrix <- array(dim=c(5,4,2))
dimnames(plotMatrix) <- list(rep("",5), c("a","b","c","d"),c("group1","group2"))
plotMatrix[,,1]<- group1
plotMatrix[1:3,,2] <- group2

trellis.device(device = "pdf",file ="lattice_strips.pdf",width=14,height=10)
print(levelplot(plotMatrix,colorkey=F,xlab="",ylab=""))
dev.off()


From mdsumner at gmail.com  Thu Jun 25 02:57:07 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 25 Jun 2015 00:57:07 +0000
Subject: [R] Draw maps on arbitrary Projections
In-Reply-To: <1435162301128-4709014.post@n4.nabble.com>
References: <1435162301128-4709014.post@n4.nabble.com>
Message-ID: <CAAcGz9-mir=Vz2CW94vtej4JOSyGSZ_f7FQEMWVpueu0BFVYww@mail.gmail.com>

The easiest way is to find out what the actual projection is, and
reconstruct a sensible representation of the grid.

Usually you have to guess, but it's possible to figure out. You *can* plot
by building a proper mesh in longlat, but my preference is full rescue. You
need to know the projection and its particulars, i.e. google suggests its
Lambert Conformal Conic but you also need datum/ellipsoid, standard
parallels, and central longitude/latitude at a minimum.

If you can point to an actual example and some trail of where it came from
someone could help.

Also, R-Sig-Geo is a specialized mailing list for this stuff.
Cheers, Mike.

On Thu, 25 Jun 2015 at 06:08 Florian Losch <mail at florianlosch.de> wrote:

> I have spatial data from the WRF-model. I don't know what kind of
> projection
> was used to produce these data (neither longitude nor latitude are constant
> at any borders), but I have 2D matrixes for each longitude and latitude.
> The
> area covered is North America. How can I add a map using these 2D matrixes?
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Draw-maps-on-arbitrary-Projections-tp4709014.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Xinyuan.Zou at tamu.edu  Thu Jun 25 03:49:28 2015
From: Xinyuan.Zou at tamu.edu (karlmalone32)
Date: Wed, 24 Jun 2015 18:49:28 -0700 (PDT)
Subject: [R] Cannot Connect to R server
Message-ID: <1435196968852-4709039.post@n4.nabble.com>

My RStudio has a wired problem. When I run library(the package I have
successfully installed), RStudio has no response. After endless waiting, an
error message comes out saying R cannot connect to the R server. Both my R
and RStudio are perfectly updated. Anyone can help me out? I appreciate.



--
View this message in context: http://r.789695.n4.nabble.com/Cannot-Connect-to-R-server-tp4709039.html
Sent from the R help mailing list archive at Nabble.com.


From sigbert at wiwi.hu-berlin.de  Thu Jun 25 11:03:59 2015
From: sigbert at wiwi.hu-berlin.de (Sigbert Klinke)
Date: Thu, 25 Jun 2015 11:03:59 +0200
Subject: [R] Setting two default CRAN servers under Windows/RStudio
In-Reply-To: <CAJuCY5xdr7nquiSfsizC=LdFFTMvCaPq5g1Rs5snwBibj50Xig@mail.gmail.com>
References: <55840793.6000205@wiwi.hu-berlin.de>
	<CAJuCY5xdr7nquiSfsizC=LdFFTMvCaPq5g1Rs5snwBibj50Xig@mail.gmail.com>
Message-ID: <558BC3FF.7050008@wiwi.hu-berlin.de>

Hi,

I tried the following:

local({r <- getOption("repos")
       r["CRAN"]   <- "http://local.cran.server/"
       r["MIRROR"] <- "http://cran.mirror/"
       options(repos=r)
})

But: R seems always to take the "CRAN" entry first, therefore I put our
local mirror there.

If a R session starts and the "CRAN" server is not available then a
package is taken from the "MIRROR" server. If the server comes up during
the session then the next install.packages will use the "CRAN" server.

But if the "CRAN" server becomes unavailable during a session then the
"MIRROR" server is not checked and I get an error message "download of
package 'xyz' failed".

Any ideas?

Sigbert

Am 19.06.2015 um 15:32 schrieb Thierry Onkelinx:
> We have this in our Rprofile.site This works fine. It checks each mirror
> and installs (or updates) the latest version available on all mirrors. e.g.
> abc 0.1 on RStudio and abc 0.2 on RForge, then abc 0.2 from RForge gets
> installed/updated.
> 
> options(
>   repos = c(
>     RStudio = "http://cran.rstudio.com/",
>     RForge = "http://r-forge.r-project.org",
>     Belgium = "http://www.freestatistics.org/cran/",
>     CRAN = "http://cran.at.r-project.org/",
>     Oxford = "http://www.stats.ox.ac.uk/pub/RWin"
>   ),
>   install.packages.check.source = "no"
> )


-- 
http://u.hu-berlin.de/sk


From francesca.pancotto at gmail.com  Thu Jun 25 11:26:53 2015
From: francesca.pancotto at gmail.com (Francesca)
Date: Thu, 25 Jun 2015 11:26:53 +0200
Subject: [R] Collecting output of regressions in an intelligent way
Message-ID: <CAKFaUKg3mm5kH0gwYgGUV+fmbK8u1uqvXQHxYSS5vW1AkYxoBg@mail.gmail.com>

Dear R Contributors
I am asking for some suggestions on how to organize output of a series of
regressions and tests in an intelligent way.
I estimate a series of Var models with increasing numbers of lags and the
perform a Wald test to control Granger Causality: I would like to learn a
way to do it that allows me not to produce copy and past code.

This is what I do:
Estimate var models with increasing number of lags,

V.6<-VAR(cbind(index1,ma_fin),p=6,type="both")
V.7<-VAR(cbind(index1,ma_fin),p=7,type="both")
V.8<-VAR(cbind(index1,ma_fin),p=8,type="both")
V.9<-VAR(cbind(index1,ma_fin),p=9,type="both")

then observe results and control significance of regressors:

summary(V.6)
summary(V.7)
summary(V.8)
summary(V.9)
summary(V.10)

then use the estimated var to perform the test:

wald_fin7.1<-wald.test(b=coef(V.7$varresult[[1]]),
Sigma=vcov(V.7$varresult[[1]]), Terms=c(2,4,6,8,10,12))
wald_fin8.1<-wald.test(b=coef(V.8$varresult[[1]]),
Sigma=vcov(V.8$varresult[[1]]), Terms=c(2,4,6,8,10,12,14))
wald_fin9.1<-wald.test(b=coef(V.9$varresult[[1]]),
Sigma=vcov(V.9$varresult[[1]]), Terms=c(2,4,6,8,10,12,14,16))
wald_fin10.1<-wald.test(b=coef(V.10$varresult[[1]]),
Sigma=vcov(V.10$varresult[[1]]), Terms=c(2,4,6,8,10,12,14,16,18))

#then collect tests result in a table:

wald_fin<-rbind(wald_fin7.1$result$chi2,
                wald_fin12.1$result$chi2,wald_fin21.1$result$chi2,
                wald_fin7.2$result$chi2,
                wald_fin12.2$result$chi2,wald_fin21.2$result$chi2)


My idea is that it is possible to create all this variable with a loop
across the objects names but it is a level of coding much higher than my
personal knowledge and ability.

I hope anyone can help

Thanks in advance


-- 

Francesca

----------------------------------
Francesca Pancotto, PhD
Universit? di Modena e Reggio Emilia
Viale A. Allegri, 9
40121 Reggio Emilia
Office: +39 0522 523264
Web: https://sites.google.com/site/francescapancotto/
----------------------------------

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Jun 25 12:54:58 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 25 Jun 2015 20:54:58 +1000
Subject: [R] Broken links (???) in R-FAQ
In-Reply-To: <558AECAA.5060805@mail.usask.ca>
References: <558AECAA.5060805@mail.usask.ca>
Message-ID: <CA+8X3fUPGJzAxu9Zfvhkzwo+y3-3qzYD0hNvWaxi-=z_AcwOQw@mail.gmail.com>

Hi Chel Hee,
The last link (for FAQ 7.39) is dead and the domain
(rwiki.sciviews.org) is not there either.

Jim


On Thu, Jun 25, 2015 at 3:45 AM, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
> Could you kindly check if the following links are working fine in the R-FAQ
> page at <http://cran.r-project.org/doc/FAQ/R-FAQ.html>?  The links listed in
> the below seem to be broken.  I hope these links are fixed in the very near
> future.
>
> Under the section 2.6 Are there Unix-like binaries for R?,
>
>  * http://CRAN.R-project.org/bin/linux/debian/README
>
> Under the section 2.10 What is CRAN?,
>
>  * http://cran.au.R-project.org/
>  * http://cran.pt.R-project.org/
>
> Under the section 2.14 What is R-Forge?,
>
>  * GForge <www.gforge.org>
>
> Under the section 3.1 What is S?,
>
>  * http://cm.bell-labs.com/cm/ms/departments/sia/Sbook/
>  * http://cm.bell-labs.com/cm/ms/departments/sia/S/history.html
>
> Under the section 4 R Web Interfaces,
>  * http://rwiki.sciviews.org/doku.php?id=faq-r#web_interfaces
>  * Rserve <http://stats.math.uni-augsburg.de/Rserve/>
>
> Under the section 5.1.4 Add-on packages from Bioconductor,
>
>  * Bioconductor software packages
> <http://www.bioconductor.org/packages/bioc/>
>
> Under the section 7.39 How do I create a plot with two y-axes?,
>  * http://rwiki.sciviews.org/doku.php?id=tips:graphics-base:2yaxes
>
> I appreciate your helps!
>
> Chel Hee Lee
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Jun 25 13:01:34 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 25 Jun 2015 21:01:34 +1000
Subject: [R] set par options once for entire R session
In-Reply-To: <D1B01850.12F76E%macqueen1@llnl.gov>
References: <3FC1DBA3-2908-4487-BC15-FBB49640D9DF@googlemail.com>
	<E825A2BB-BC65-4BFA-A8DC-3F66BF240057@googlemail.com>
	<D1B01850.12F76E%macqueen1@llnl.gov>
Message-ID: <CA+8X3fVNVf_cOu1Cb6pRjVbsZfxm_CeuLtLgYL2XtXoon3-g0w@mail.gmail.com>

Hi Martin,
Depending upon what device parameters you want to set, you can write a
wrapper for the device call that includes the parameters:

my.x11<-function() {
 x11(family="sans",font=2)
}

Then just call the wrapper instead of the device function. You could
make a little package with all of the devices you wish to use and just
load the package at the beginning of your R session.

Jim


On Thu, Jun 25, 2015 at 1:40 AM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> The Details section of ?par starts of with:
>
>  "Each device has its own set of graphical parameters."
>
> (So this is not Mac-specific.)
>
> Strictly speaking, the options you set with par() are not "reset" when you
> open a new graphics device. Rather, when a new device is opened, it is
> initialized with default values of graphics parameters.
>
> If you can find where those default values are stored (in a brief search I
> did not find them), then perhaps you can change them at session startup
> time.
>
> I haven't tested this, but you might be able to make things a little more
> convenient by defining a function
>
>   mypar <- function() par( {set whatever values you want} )
>
> Then whenever you open a new device, immediately call that function:
>
> pdf()
> mypar()
> plot(x,y)
> dev.off()
>
> png()
> mypar()
> plot(x,y)
> dev.of()
>
> And so on.
>
>
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 6/23/15, 8:54 AM, "R-help on behalf of Martin Batholdy via R-help"
> <r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:
>
>>Hi,
>>
>>I would like to set plot-options via par() and keep them for all plots
>>that are created thereafter.
>>Currently after each plot device the parameters I can set with par() are
>>reseted to their default value, at least on a Mac (R 3.2.1).
>>
>>Is there a way to define the parameters for plotting once at the
>>beginning and then keep them for an entire R session?
>>
>>
>>Thank you!
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From aasdelat at aim.com  Thu Jun 25 13:16:45 2015
From: aasdelat at aim.com (Antonio Serrano)
Date: Thu, 25 Jun 2015 07:16:45 -0400
Subject: [R] Plotting legend outside of chart area
In-Reply-To: <894df63327f4467cbd2d6e8c4eea1464@Tremail.bournemouth.ac.uk>
References: <894df63327f4467cbd2d6e8c4eea1464@Tremail.bournemouth.ac.uk>
Message-ID: <14e2a6f2cdf-26f7-1a4d9@webprd-m49.mail.aol.com>

First, you have to increase the bottom margin to have enough space for the legend.
You do it like this:
par(
    mar = c(6,4,4,2)
)

>From R help:
     ?mar? A numerical vector of the form ?c(bottom, left, top, right)?
          which gives the number of lines of margin to be specified on
          the four sides of the plot.  The default is ?c(5, 4, 4, 2) +
          0.1?.
So, we have increased the first number from 5 to 6 to have mor space at the bottom.

Then, in the legend(), you have to add the option:
inset = c(0, -0.2),

>From R help:
   inset: inset distance(s) from the margins as a fraction of the plot
          region when legend is placed by keyword.
Change the -0.2 and the 6 in the par(mar) until you get a nice chart

 

 

Antonio Serrano
aasdelat at aim.com
?

 

 

-----Original Message-----
From: Samantha Allcock <sallcock at bournemouth.ac.uk>
To: 'r-help at r-project.org' <r-help at r-project.org>
Sent: Wed, Jun 24, 2015 10:08 pm
Subject: [R] Plotting legend outside of chart area


Hello,

I am trying to add a legend to my PCA plot so that it looks neat. I
think plotting this outside of the chart area would be good but I cannot seem to
fathom the correct code for this. I wondered if anyone could help please?

The
code I am using is as follows:

grp<- with(Matan, cut(R_category_no,14,
labels=1:14))
cols <- c("grey0", "wheat", "red", "cyan", "orange",
"darkolivegreen2", "purple3",
"royalblue", "burlywood4", "orchid",
"forestgreen", "green",
"gray", "yellow1")
plot(geopca, display="sites",
scaling=3, type="n")
points(geopca, display="sites", scaling=3, col=cols[grp],
pch=16)

legend("bottomright", col=c("grey0", "wheat", "red", "cyan",
"orange", "darkolivegreen2",
"purple3", "royalblue", "burlywood4", "orchid",
"forestgreen", "green",
"gray", "yellow1"), c("Control type 1", "Control type
2",
"External/Courtyard", "Midden", "Animal Occupation",
"External fire
installations and ashy deposits",
"Internal fire installations and ashy
deposits", "Hearth make-up",
"Floors and surfaces", "Plasters and clay
features", "Storage features",
"Platforms and benches", "Mortars", "Roofs and
roofing materials"), pch=16,
cex=0.75, bty="n")

Thank you for your time in
advance


Dr Samantha Lee Allcock
Faculty of Science and
Technology
Department of Archaeology, Anthropology and Forensic
Science
Christchurch House Rm: C133
Bournemouth University
Talbot
Campus
Poole
BH12 5BB
Tel: 01202
9(62474)

sallcock at bournemouth.ac.uk<mailto:sallcock at bournemouth.ac.uk>
research.bournemouth.ac.uk/2014/07/inea-project-2


BU
is a Disability Two Ticks Employer and has signed up to the Mindful Employer
charter. Information about the accessibility of University buildings can be
found on the BU DisabledGo webpages This email is intended only for the person
to whom it is addressed and may contain confidential information. If you have
received this email in error, please notify the sender and delete this email,
which must not be copied, distributed or disclosed to any other person. Any
views or opinions presented are solely those of the author and do not
necessarily represent those of Bournemouth University or its subsidiary
companies. Nor can any contract be formed on behalf of the University or its
subsidiary companies via email.

	[[alternative HTML version
deleted]]

______________________________________________
R-help at r-project.org
mailing list -- To UNSUBSCRIBE and more,
see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting
guide http://www.R-project.org/posting-guide.html
and provide commented,
minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Thu Jun 25 14:51:13 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 25 Jun 2015 07:51:13 -0500
Subject: [R] Collecting output of regressions in an intelligent way
In-Reply-To: <CAKFaUKg3mm5kH0gwYgGUV+fmbK8u1uqvXQHxYSS5vW1AkYxoBg@mail.gmail.com>
References: <CAKFaUKg3mm5kH0gwYgGUV+fmbK8u1uqvXQHxYSS5vW1AkYxoBg@mail.gmail.com>
Message-ID: <CAN5YmCF+ofbw5S6tJCwqjq8Tu+7foWcwtYixZrWdkfL=DTUwpQ@mail.gmail.com>

Francesca,

You don't provide any example data, so the code that I am provided is
untested, but here is one way to put your commands into a loop.


# define range of p values you want to use
ps <- 6:10
# create an empty list to collect the results
waldchi <- vector("list", length(ps))

# loop through the p values
for(i in seq(ps)) {
  v.p <- VAR(cbind(index1, ma_fin), p=ps[i], type="both")
  print(summary(v.p)
  wald_finp.1 <- wald.test(
    b=coef(V.p$varresult[[1]]),
    Sigma=vcov(V.p$varresult[[1]]),
    Terms=seq(from=2, by=2, length=ps[i]-1))
  waldchi[[i]] <- wald_finp.1$result$chi2
}

# combine the results
wald_fin <- do.call(rbind, waldchi)

Jean


On Thu, Jun 25, 2015 at 4:26 AM, Francesca <francesca.pancotto at gmail.com>
wrote:

> Dear R Contributors
> I am asking for some suggestions on how to organize output of a series of
> regressions and tests in an intelligent way.
> I estimate a series of Var models with increasing numbers of lags and the
> perform a Wald test to control Granger Causality: I would like to learn a
> way to do it that allows me not to produce copy and past code.
>
> This is what I do:
> Estimate var models with increasing number of lags,
>
> V.6<-VAR(cbind(index1,ma_fin),p=6,type="both")
> V.7<-VAR(cbind(index1,ma_fin),p=7,type="both")
> V.8<-VAR(cbind(index1,ma_fin),p=8,type="both")
> V.9<-VAR(cbind(index1,ma_fin),p=9,type="both")
>
> then observe results and control significance of regressors:
>
> summary(V.6)
> summary(V.7)
> summary(V.8)
> summary(V.9)
> summary(V.10)
>
> then use the estimated var to perform the test:
>
> wald_fin7.1<-wald.test(b=coef(V.7$varresult[[1]]),
> Sigma=vcov(V.7$varresult[[1]]), Terms=c(2,4,6,8,10,12))
> wald_fin8.1<-wald.test(b=coef(V.8$varresult[[1]]),
> Sigma=vcov(V.8$varresult[[1]]), Terms=c(2,4,6,8,10,12,14))
> wald_fin9.1<-wald.test(b=coef(V.9$varresult[[1]]),
> Sigma=vcov(V.9$varresult[[1]]), Terms=c(2,4,6,8,10,12,14,16))
> wald_fin10.1<-wald.test(b=coef(V.10$varresult[[1]]),
> Sigma=vcov(V.10$varresult[[1]]), Terms=c(2,4,6,8,10,12,14,16,18))
>
> #then collect tests result in a table:
>
> wald_fin<-rbind(wald_fin7.1$result$chi2,
>                 wald_fin12.1$result$chi2,wald_fin21.1$result$chi2,
>                 wald_fin7.2$result$chi2,
>                 wald_fin12.2$result$chi2,wald_fin21.2$result$chi2)
>
>
> My idea is that it is possible to create all this variable with a loop
> across the objects names but it is a level of coding much higher than my
> personal knowledge and ability.
>
> I hope anyone can help
>
> Thanks in advance
>
>
> --
>
> Francesca
>
> ----------------------------------
> Francesca Pancotto, PhD
> Universit? di Modena e Reggio Emilia
> Viale A. Allegri, 9
> 40121 Reggio Emilia
> Office: +39 0522 523264
> Web: https://sites.google.com/site/francescapancotto/
> ----------------------------------
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From rcodeplayer at gmail.com  Thu Jun 25 13:01:24 2015
From: rcodeplayer at gmail.com (R codeplayer)
Date: Thu, 25 Jun 2015 13:01:24 +0200
Subject: [R] R lattice : labeling of matrix groups of different size
	with strips
In-Reply-To: <000901d0aedb$fefb0940$fcf11bc0$@bigpond.com>
References: <CAKy6djnrm2rW3SSRy4eWk9xeRdMFksA+GhaJPR6-27560nWtTQ@mail.gmail.com>
	<000901d0aedb$fefb0940$fcf11bc0$@bigpond.com>
Message-ID: <CAKy6dj=d8W7RiBiy=L4DaiODrCmhfDiFvNnmdX3spZxckOxU0g@mail.gmail.com>

Hi Duncan,


thank you very much for your help.


Originally, I thought that it is possible to use a different data
representation and then to automatically create the plots and strips
in lattice.

Based on your suggestion, I could write the code for an annotated
levelplot of the two groups (code is shown below).

An open question is how to display the two groups with the same aspect
ratio for the rows.


> plotMatrix
> , , group1
>
>   a b c d
> 1 1 0 0 0
> 2 1 0 0 0
> 3 1 1 0 0
> 4 0 1 0 0
> 5 0 1 1 0
>
> , , group2
>
>    a  b  c  d
> 1  0  0  1  0
> 2  0  0  1  1
> 3  0  0  0  1
> 4 NA NA NA NA
> 5 NA NA NA NA

library(gridExtra)

trellis.device(device = "pdf",file
="lattice_annotated_groups.pdf",width=8,height=5)

#The aspect="fill" option was added to coerce the same height of the 2 plots
#panel.text was used instead of grid.text to avoid using the
latticeExtra package

plot1 <- levelplot(plotMatrix[,,1],
             page = function(n)
             panel.text("group 1",
                 x = 0.5,
                 y = 0.96),
             colorkey = F,
             xlab = "",
             ylab="",
             aspect="fill")

pm <- plotMatrix[1:3,,2]
colnames(pm) <- rep("",ncol(pm))

plot2 <-levelplot(pm,
            page = function(n)
            panel.text(
                "group 2",
                 x = 0.5,
                 y = 0.96),
            colorkey = F,
            xlab = "",
            ylab="",
            aspect="fill")


grid.arrange(plot1,plot2,ncol=2)
dev.off()
-------------- next part --------------
A non-text attachment was scrubbed...
Name: lattice_annotated_groups.pdf
Type: application/pdf
Size: 4703 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150625/0827d74f/attachment.pdf>

From j.bayat194 at gmail.com  Thu Jun 25 13:48:10 2015
From: j.bayat194 at gmail.com (javad bayat)
Date: Thu, 25 Jun 2015 16:18:10 +0430
Subject: [R] CCA package
Message-ID: <CANTxAmJMqKgWP9gNYwun7ijKqEWMARQtUKwb6THOf9hCBPwY+g@mail.gmail.com>

Dear R users;
I am using CCA package to calculate the correlation between two data set.
Every time that I run my codes, I get the following error;
"the leading minor of order 5 is not positive definite".
Please help me to fix it.
Many thanks.

-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From mar.lamack at hotmail.com  Thu Jun 25 16:26:32 2015
From: mar.lamack at hotmail.com (L... L...)
Date: Thu, 25 Jun 2015 11:26:32 -0300
Subject: [R] quantile of a discrete random variable
Message-ID: <BLU175-W4139A1930F41E5526D907D96AE0@phx.gbl>

Dear all, is there a general method for calculating the quantile of a discrete random variable? If yes, is there a R function to do this?
Best regards
Marcelo Lamack


 		 	   		  
	[[alternative HTML version deleted]]


From chl948 at mail.usask.ca  Thu Jun 25 16:36:52 2015
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Thu, 25 Jun 2015 08:36:52 -0600
Subject: [R] Broken links (???) in R-FAQ
In-Reply-To: <CA+8X3fUPGJzAxu9Zfvhkzwo+y3-3qzYD0hNvWaxi-=z_AcwOQw@mail.gmail.com>
References: <558AECAA.5060805@mail.usask.ca>
	<CA+8X3fUPGJzAxu9Zfvhkzwo+y3-3qzYD0hNvWaxi-=z_AcwOQw@mail.gmail.com>
Message-ID: <558C1204.20100@mail.usask.ca>

Thank you so much, Jim.  Yes, I also see that the wiki 
(rwiki.sciviews.org) is not found.

Chel Hee Lee

On 15-06-25 04:54 AM, Jim Lemon wrote:
> Hi Chel Hee,
> The last link (for FAQ 7.39) is dead and the domain
> (rwiki.sciviews.org) is not there either.
>
> Jim
>
>
> On Thu, Jun 25, 2015 at 3:45 AM, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
>> Could you kindly check if the following links are working fine in the R-FAQ
>> page at <http://cran.r-project.org/doc/FAQ/R-FAQ.html>?  The links listed in
>> the below seem to be broken.  I hope these links are fixed in the very near
>> future.
>>
>> Under the section 2.6 Are there Unix-like binaries for R?,
>>
>>   * http://CRAN.R-project.org/bin/linux/debian/README
>>
>> Under the section 2.10 What is CRAN?,
>>
>>   * http://cran.au.R-project.org/
>>   * http://cran.pt.R-project.org/
>>
>> Under the section 2.14 What is R-Forge?,
>>
>>   * GForge <www.gforge.org>
>>
>> Under the section 3.1 What is S?,
>>
>>   * http://cm.bell-labs.com/cm/ms/departments/sia/Sbook/
>>   * http://cm.bell-labs.com/cm/ms/departments/sia/S/history.html
>>
>> Under the section 4 R Web Interfaces,
>>   * http://rwiki.sciviews.org/doku.php?id=faq-r#web_interfaces
>>   * Rserve <http://stats.math.uni-augsburg.de/Rserve/>
>>
>> Under the section 5.1.4 Add-on packages from Bioconductor,
>>
>>   * Bioconductor software packages
>> <http://www.bioconductor.org/packages/bioc/>
>>
>> Under the section 7.39 How do I create a plot with two y-axes?,
>>   * http://rwiki.sciviews.org/doku.php?id=tips:graphics-base:2yaxes
>>
>> I appreciate your helps!
>>
>> Chel Hee Lee
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From chl948 at mail.usask.ca  Thu Jun 25 16:42:27 2015
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Thu, 25 Jun 2015 08:42:27 -0600
Subject: [R] Broken links (???) in rw-FAQ
In-Reply-To: <191EF1B6-A58C-496F-955B-4F3094E66C90@comcast.net>
References: <558AEE63.70908@mail.usask.ca>
	<191EF1B6-A58C-496F-955B-4F3094E66C90@comcast.net>
Message-ID: <558C1353.8010904@mail.usask.ca>

Thank you so much, David!   I also confirmed that the link moved is not 
found.

Chel Hee Lee

On 15-06-24 04:15 PM, David Winsemius wrote:
>
> On Jun 24, 2015, at 10:52 AM, Chel Hee Lee wrote:
>
>> Could you also kindly check the following links in the rw-FAQ manual at <http://cran.r-project.org/bin/windows/base/rw-FAQ.html>??  The links list in the below seem to be broken.   I hope these links are fixed in the very near future.
>>
>> Under the section 2.4 Can I customize the installation?
>>
>> * Setup (http://jrsoftware.org/ishelp.php) for details.
>>
>> Under the section 3.3 I want to run R in Chinese/Japanese/Korean
>>
>> * http://msdn.microsoft.com/library/default.asp?url=/library/en-us/vccore98/html/_crt_language_and_country_strings.asp
>>
>> Under the section 2.26 There is no tilde on my keyboard!
>>
>> * http://office.microsoft.com/en-us/word/HP052590631033.aspx
>
> With regard to this one, there was a discussion of this just yesterday in StackOverflow (relative to Italian keyboards which don't seem to be mentioned in the current version of the rw-FAQ). Admittedly this material is not immediately relevant to a windows setup since the question was coming from a Linux user.
>
> http://stackoverflow.com/questions/31015152/how-to-type-tilde-in-r
>
>   http://superuser.com/questions/667622/italian-keyboard-entering-the-tilde-and-backtick-characters-without-cha
>
> Looking at some of the linked material, it appears that Windows and Linux have distinctly different answers to tilde-deficient keyboard concerns, so there might be a reason to move a more general answer to R-FAQ and perhaps include material in the section on Internationalization? I could find no mention of tilde-problems in the R-FAQ or the Admin/Setup document.
>
>>
>> This link is in fact moved to
>>
>> https://support.office.com/en-us/article/HP052590631?CorrelationId=98eaa529-e95a-4628-90ac-1a1da4526b17
>
> That link was 404-ed when I tried it.
>
>> Under the section 2.24 Does R run under Windows Vista/7/8/Server 2008?
>>
>> * http://windowsvistablog.com/blogs/windowsvista/archive/2007/01/23/security-features-vs-convenience.aspx
>>
>> I appreciate your help!
>>
>> Chel Hee Lee
>>


From dwinsemius at comcast.net  Thu Jun 25 17:18:22 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 25 Jun 2015 08:18:22 -0700
Subject: [R] Cannot Connect to R server
In-Reply-To: <1435196968852-4709039.post@n4.nabble.com>
References: <1435196968852-4709039.post@n4.nabble.com>
Message-ID: <285464D4-FA41-4867-AA3B-BB8BAEF7EC20@comcast.net>


On Jun 24, 2015, at 6:49 PM, karlmalone32 wrote:

> My RStudio has a wired problem. When I run library(the package I have
> successfully installed), RStudio has no response. After endless waiting, an
> error message comes out saying R cannot connect to the R server. Both my R
> and RStudio are perfectly updated. Anyone can help me out? I appreciate.

Have you considered posting this question in the RStudio support forum?

(Reason for lack of direct response to poster: The Nabble origin has caused a lot of bounce-backs that then get me disconnected from Rhelp.)

> 
> Do read these --->

-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-- 
David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Thu Jun 25 17:30:19 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 25 Jun 2015 15:30:19 +0000
Subject: [R] quantile of a discrete random variable
In-Reply-To: <BLU175-W4139A1930F41E5526D907D96AE0@phx.gbl>
References: <BLU175-W4139A1930F41E5526D907D96AE0@phx.gbl>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D69E4E5@mb02.ads.tamu.edu>

There is a function called quantile() that provides 9 methods of computing quantiles, three of which are appropriate for discontinuous data. Type

?quantile

at the command prompt for details.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of L... L...
Sent: Thursday, June 25, 2015 9:27 AM
To: r-help at r-project.org
Subject: [R] quantile of a discrete random variable

Dear all, is there a general method for calculating the quantile of a discrete random variable? If yes, is there a R function to do this?
Best regards
Marcelo Lamack


 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Jun 25 17:34:23 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 25 Jun 2015 08:34:23 -0700
Subject: [R] quantile of a discrete random variable
In-Reply-To: <BLU175-W4139A1930F41E5526D907D96AE0@phx.gbl>
References: <BLU175-W4139A1930F41E5526D907D96AE0@phx.gbl>
Message-ID: <814888BB-E1CF-4B7C-9F7A-715E3FA3C7C0@comcast.net>


On Jun 25, 2015, at 7:26 AM, L... L... wrote:

> Dear all, is there a general method for calculating the quantile of a discrete random variable? If yes, is there a R function to do this?

The `quantile` function would seem to be the first place to go. It may depend on the object-type of your representation of the "random variable".

?quantile                 # to see the help page

The default of type=7 may not be what you want, but I suspect one of the other types would be appropriate. You could also cobble something together along the lines of:

 list(x= as.numeric(names(table(x))), y=cumsum(table(x))/sum(x) )

Could use the result of ecdf(and then reversing x and y for evaluation.).

>    		  
> 	[[alternative HTML version deleted]]
This is a plain text mailing list
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Jun 25 17:46:29 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 25 Jun 2015 08:46:29 -0700
Subject: [R] CCA package
In-Reply-To: <CANTxAmJMqKgWP9gNYwun7ijKqEWMARQtUKwb6THOf9hCBPwY+g@mail.gmail.com>
References: <CANTxAmJMqKgWP9gNYwun7ijKqEWMARQtUKwb6THOf9hCBPwY+g@mail.gmail.com>
Message-ID: <A22484EA-9DDB-46F9-A741-75D13964F266@comcast.net>

Dear Javad;

Please stop copying r-help-owner with messages intended for r-help.

David (one of the several moderators)

On Jun 25, 2015, at 4:48 AM, javad bayat wrote:

> Dear R users;
> I am using CCA package to calculate the correlation between two data set. Every time that I run my codes, I get the following error;
> "the leading minor of order 5 is not positive definite".
> Please help me to fix it.
> Many thanks.
> 
> -- 
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com

David Winsemius
Alameda, CA, USA


From mar.lamack at hotmail.com  Thu Jun 25 17:59:18 2015
From: mar.lamack at hotmail.com (L... L...)
Date: Thu, 25 Jun 2015 12:59:18 -0300
Subject: [R] quantile of a discrete random variabel --- again
Message-ID: <BLU175-W3528DCC27C0716096B0B9A96AE0@phx.gbl>

I thank all for your reply. My question was not well formulated.
I will do it again:
Suppose that the random variable X is discrete with probability mass function (pmf) F (binomial, poisson, ....) not necessarily available in R.
Is there a general method to get the quantiles (as qbinom, qpois, .....) or which is the method(s) used to get the quantiles (used in qbinom, qpois, .....)?
Regards
ML 		 	   		  
	[[alternative HTML version deleted]]


From peterenos at ymail.com  Thu Jun 25 17:40:25 2015
From: peterenos at ymail.com (Peter Tuju)
Date: Thu, 25 Jun 2015 15:40:25 +0000 (UTC)
Subject: [R] Extracting data from a file containing data
In-Reply-To: <mailman.5.1435226402.27672.r-help@r-project.org>
References: <mailman.5.1435226402.27672.r-help@r-project.org>
Message-ID: <10566589.1335238.1435246825924.JavaMail.yahoo@mail.yahoo.com>

I have the data as attached. For each nino region, I want to get the mean of the seasons January and February (JF), March, April and may (MAM), June, July and August (JJA), and October, November and December (OND) as columns of each nino regions. and have my result as;For example;
For NINO1.2Years???? JF????? MAMA???? JJA????? OND?1982?1983??? .??? .???? .2012
Any guide please!


_____________
Peter? E. Tuju
Dar es Salaam
T A N Z A N I A
----------------------
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Nino_indices.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150625/8fbee2b8/attachment.txt>

From bgunter.4567 at gmail.com  Thu Jun 25 19:27:54 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 25 Jun 2015 10:27:54 -0700
Subject: [R] quantile of a discrete random variabel --- again
In-Reply-To: <BLU175-W3528DCC27C0716096B0B9A96AE0@phx.gbl>
References: <BLU175-W3528DCC27C0716096B0B9A96AE0@phx.gbl>
Message-ID: <CAGxFJbRFh7Nw6edUwNQeWdzizm0QYAOw+wWEQLp2d0hd0CxiLw@mail.gmail.com>

Well, presumably you have the pmf and can create a matrix of the form:
(where mypmf is your pmf)

x <- seq_len(1000) ## or whatever your discrete support sorted in
increasing order

## for individual quantile q:

max(x[cumsum(mypmf(x)) <= q] )

## This probably could be vectorized for a vector of quantiles . I
leave that to others both cleverer and more motivated than I.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Thu, Jun 25, 2015 at 8:59 AM, L... L... <mar.lamack at hotmail.com> wrote:
> I thank all for your reply. My question was not well formulated.
> I will do it again:
> Suppose that the random variable X is discrete with probability mass function (pmf) F (binomial, poisson, ....) not necessarily available in R.
> Is there a general method to get the quantiles (as qbinom, qpois, .....) or which is the method(s) used to get the quantiles (used in qbinom, qpois, .....)?
> Regards
> ML
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu Jun 25 20:25:52 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 25 Jun 2015 18:25:52 +0000
Subject: [R] Extracting data from a file containing data
In-Reply-To: <10566589.1335238.1435246825924.JavaMail.yahoo@mail.yahoo.com>
References: <mailman.5.1435226402.27672.r-help@r-project.org>
	<10566589.1335238.1435246825924.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D69E60B@mb02.ads.tamu.edu>

First, create a variable (a factor) for your categories (did you really intend to exclude September?).

Then use the aggregate function.

?factor
?aggregate

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Peter Tuju
Sent: Thursday, June 25, 2015 10:40 AM
To: r-help at r-project.org
Subject: Re: [R] Extracting data from a file containing data

I have the data as attached. For each nino region, I want to get the mean of the seasons January and February (JF), March, April and may (MAM), June, July and August (JJA), and October, November and December (OND) as columns of each nino regions. and have my result as;For example;
For NINO1.2Years???? JF????? MAMA???? JJA????? OND?1982?1983??? .??? .???? .2012
Any guide please!


_____________
Peter? E. Tuju
Dar es Salaam
T A N Z A N I A
----------------------

From jholtman at gmail.com  Thu Jun 25 20:51:38 2015
From: jholtman at gmail.com (jim holtman)
Date: Thu, 25 Jun 2015 14:51:38 -0400
Subject: [R] Extracting data from a file containing data
In-Reply-To: <10566589.1335238.1435246825924.JavaMail.yahoo@mail.yahoo.com>
References: <mailman.5.1435226402.27672.r-help@r-project.org>
	<10566589.1335238.1435246825924.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAxdm-6o2+U1ETKK5YSgfDqkm63HLuQ2NqWnSV=M8nHJt5i6-g@mail.gmail.com>

What happened to September?  Just disregard?


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Thu, Jun 25, 2015 at 11:40 AM, Peter Tuju <peterenos at ymail.com> wrote:

> I have the data as attached. For each nino region, I want to get the mean
> of the seasons January and February (JF), March, April and may (MAM), June,
> July and August (JJA), and October, November and December (OND) as columns
> of each nino regions. and have my result as;For example;
> For NINO1.2Years     JF      MAMA     JJA      OND 1982 1983    .    .
> .2012
> Any guide please!
>
>
> _____________
> Peter  E. Tuju
> Dar es Salaam
> T A N Z A N I A
> ----------------------
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Thu Jun 25 21:12:57 2015
From: jholtman at gmail.com (jim holtman)
Date: Thu, 25 Jun 2015 15:12:57 -0400
Subject: [R] Extracting data from a file containing data
In-Reply-To: <10566589.1335238.1435246825924.JavaMail.yahoo@mail.yahoo.com>
References: <mailman.5.1435226402.27672.r-help@r-project.org>
	<10566589.1335238.1435246825924.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAxdm-5N1Ebjy-jysXWPjDuTarCnc2BTEN218zm5Nyd7on1tvA@mail.gmail.com>

try this:

> input <- read.table("C:\\Users\\jh52822\\Downloads\\Nino_indices.txt"
+                     , header = TRUE
+                     , as.is = TRUE
+                     )
> # create factors
> input$season <- factor(c(rep("JF", 2), rep("MAM", 3), rep("JJA", 3)
+         , NA, rep("OND", 3)
+         )[input$MON], levels = c("JF", "MAM", "JJA", "OND"))
>
> # leave off the MON (-2) column from the data
> res <- aggregate(. ~ season + YR, data = input[, -2], FUN = 'mean')
> head(res,10)
   season   YR  NINO1.2       ANOM    NINO3     ANOM.1    NINO4     ANOM.2
 NINO3.4     ANOM.3
1      JF 1982 24.89000 -0.3750000 26.12500  0.1250000 28.25500  0.0550000
26.71000  0.0650000
2     MAM 1982 24.56000 -0.8366667 27.48333  0.2433333 28.94000  0.4466667
27.92000  0.3033333
3     JJA 1982 22.37000  0.6800000 26.68333  1.0033333 29.39333  0.6200000
28.26000  1.0300000
4     OND 1982 24.55333  2.8200000 27.70667  2.6933333 29.25333  0.6600000
28.88667  2.2500000
5      JF 1983 27.75500  2.4900000 28.92000  2.9200000 28.89500  0.6950000
29.24500  2.6000000
6     MAM 1983 28.47667  3.0800000 29.06333  1.8233333 28.89667  0.4033333
28.94333  1.3266667
7     JJA 1983 25.72333  4.0333333 26.88000  1.2000000 28.63667 -0.1366667
27.28000  0.0500000
8     OND 1983 22.25667  0.5233333 24.40667 -0.6066667 27.77667 -0.8166667
25.68000 -0.9566667
9      JF 1984 24.68000 -0.5850000 25.52000 -0.4800000 27.44500 -0.7550000
26.01500 -0.6300000
10    MAM 1984 24.79667 -0.6000000 26.97333 -0.2666667 27.62000 -0.8733333
27.21333 -0.4033333
>



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Thu, Jun 25, 2015 at 11:40 AM, Peter Tuju <peterenos at ymail.com> wrote:

> I have the data as attached. For each nino region, I want to get the mean
> of the seasons January and February (JF), March, April and may (MAM), June,
> July and August (JJA), and October, November and December (OND) as columns
> of each nino regions. and have my result as;For example;
> For NINO1.2Years     JF      MAMA     JJA      OND 1982 1983    .    .
> .2012
> Any guide please!
>
>
> _____________
> Peter  E. Tuju
> Dar es Salaam
> T A N Z A N I A
> ----------------------
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Thu Jun 25 22:25:37 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 25 Jun 2015 16:25:37 -0400
Subject: [R] dplyr, summarize_each, mean - dealing with NAs
Message-ID: <CAN2xGJboVi7nzERczGJvfBnPFTYf-ahUMR=fvY7YXPf3JiTnJw@mail.gmail.com>

Hello!

I have a data frame md:

    md <- data.frame(x = c(3,5,4,5,3,5), y = c(5,5,5,4,4,1), z = c(1,3,4,3,5,5),
          device1 = c("c","a","a","b","c","c"), device2 =
c("B","A","A","A","B","B"))
    md[2,3] <- NA
    md[4,1] <- NA
    md

I want to calculate means by device1 / device2 combinations using dplyr:

    library(dplyr)
    md %>% group_by(device1, device2) %>% summarise_each(funs(mean))

However, I am getting some NAs. I want the NAs to be ignored (na.rm =
TRUE) - I tried, but the function doesn't want to accept this
argument.
Both these lines result in error:

    md %>% group_by(device1, device2) %>% summarise_each(funs(mean),
na.rm = TRUE)
    md %>% group_by(device1, device2) %>% summarise_each(funs(mean,
na.rm = TRUE))

Thank you for your advice!


-- 
Dimitri Liakhovitski


From dimitri.liakhovitski at gmail.com  Thu Jun 25 22:35:17 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 25 Jun 2015 16:35:17 -0400
Subject: [R] dplyr, summarize_each, mean - dealing with NAs
In-Reply-To: <CAN2xGJboVi7nzERczGJvfBnPFTYf-ahUMR=fvY7YXPf3JiTnJw@mail.gmail.com>
References: <CAN2xGJboVi7nzERczGJvfBnPFTYf-ahUMR=fvY7YXPf3JiTnJw@mail.gmail.com>
Message-ID: <CAN2xGJafmaz0ATb956Outsnv_=pQOL-X0fNud1QN6EnJWJ=udw@mail.gmail.com>

Just want to clarify - I know how to do it using base R. I just want
to figure out how to do it in dplyr. This i what I want to achieve:

myvars <- c("x","y","z")
aggregate(md[myvars], by = md[c("device1","device2")], mean, na.rm = T)

Thank you!

On Thu, Jun 25, 2015 at 4:25 PM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> Hello!
>
> I have a data frame md:
>
>     md <- data.frame(x = c(3,5,4,5,3,5), y = c(5,5,5,4,4,1), z = c(1,3,4,3,5,5),
>           device1 = c("c","a","a","b","c","c"), device2 =
> c("B","A","A","A","B","B"))
>     md[2,3] <- NA
>     md[4,1] <- NA
>     md
>
> I want to calculate means by device1 / device2 combinations using dplyr:
>
>     library(dplyr)
>     md %>% group_by(device1, device2) %>% summarise_each(funs(mean))
>
> However, I am getting some NAs. I want the NAs to be ignored (na.rm =
> TRUE) - I tried, but the function doesn't want to accept this
> argument.
> Both these lines result in error:
>
>     md %>% group_by(device1, device2) %>% summarise_each(funs(mean),
> na.rm = TRUE)
>     md %>% group_by(device1, device2) %>% summarise_each(funs(mean,
> na.rm = TRUE))
>
> Thank you for your advice!
>
>
> --
> Dimitri Liakhovitski



-- 
Dimitri Liakhovitski


From dimitri.liakhovitski at gmail.com  Thu Jun 25 22:37:52 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 25 Jun 2015 16:37:52 -0400
Subject: [R] dplyr, summarize_each, mean - dealing with NAs
In-Reply-To: <CAN2xGJafmaz0ATb956Outsnv_=pQOL-X0fNud1QN6EnJWJ=udw@mail.gmail.com>
References: <CAN2xGJboVi7nzERczGJvfBnPFTYf-ahUMR=fvY7YXPf3JiTnJw@mail.gmail.com>
	<CAN2xGJafmaz0ATb956Outsnv_=pQOL-X0fNud1QN6EnJWJ=udw@mail.gmail.com>
Message-ID: <CAN2xGJaGGEZOY38C3Sz9AigT9LPYSRwU5aBqu7PXd_DZMT2N3w@mail.gmail.com>

I found the answer:

md %>% group_by(device1, device2) %>% summarise_each(funs(mean(.,
na.rm = TRUE)))

On Thu, Jun 25, 2015 at 4:35 PM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> Just want to clarify - I know how to do it using base R. I just want
> to figure out how to do it in dplyr. This i what I want to achieve:
>
> myvars <- c("x","y","z")
> aggregate(md[myvars], by = md[c("device1","device2")], mean, na.rm = T)
>
> Thank you!
>
> On Thu, Jun 25, 2015 at 4:25 PM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
>> Hello!
>>
>> I have a data frame md:
>>
>>     md <- data.frame(x = c(3,5,4,5,3,5), y = c(5,5,5,4,4,1), z = c(1,3,4,3,5,5),
>>           device1 = c("c","a","a","b","c","c"), device2 =
>> c("B","A","A","A","B","B"))
>>     md[2,3] <- NA
>>     md[4,1] <- NA
>>     md
>>
>> I want to calculate means by device1 / device2 combinations using dplyr:
>>
>>     library(dplyr)
>>     md %>% group_by(device1, device2) %>% summarise_each(funs(mean))
>>
>> However, I am getting some NAs. I want the NAs to be ignored (na.rm =
>> TRUE) - I tried, but the function doesn't want to accept this
>> argument.
>> Both these lines result in error:
>>
>>     md %>% group_by(device1, device2) %>% summarise_each(funs(mean),
>> na.rm = TRUE)
>>     md %>% group_by(device1, device2) %>% summarise_each(funs(mean,
>> na.rm = TRUE))
>>
>> Thank you for your advice!
>>
>>
>> --
>> Dimitri Liakhovitski
>
>
>
> --
> Dimitri Liakhovitski



-- 
Dimitri Liakhovitski


From therneau at mayo.edu  Thu Jun 25 23:18:34 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 25 Jun 2015 16:18:34 -0500
Subject: [R] prmatrix and print.matrix
Message-ID: <2f3a88$ti78n@ironport10.mayo.edu>

The help page for prmatrix states that it only exists for backwards compatability and 
strongly hints at using print.matrix instead.
  However, there does not seem to be a print.matrix() function.

The help page for print mentions a zero.print option, but that does not appear to affect 
matrices.  This (or something like it) is what I was looking for.

Am I overlooking something?

Terry Therneau


From rafaelcarneirocosta.rc at gmail.com  Thu Jun 25 23:29:19 2015
From: rafaelcarneirocosta.rc at gmail.com (Rafael Costa)
Date: Thu, 25 Jun 2015 18:29:19 -0300
Subject: [R] Codependents Cycles
Message-ID: <CAOy3Z4BxUSokAYop9-4HRLEWAOxUpKKHDd0vK7oT0rwziGUiVw@mail.gmail.com>

Dear R users,

Where can I find the codes to test codependent cycles? This test was
presented on paper "Codependents Cycles" (Vahid and Engle, 1997).

I am looking forward  any help.

Thanks in advance ,

Rafael Costa.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Jun 26 00:32:40 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 25 Jun 2015 15:32:40 -0700
Subject: [R] dplyr, summarize_each, mean - dealing with NAs
In-Reply-To: <CAN2xGJboVi7nzERczGJvfBnPFTYf-ahUMR=fvY7YXPf3JiTnJw@mail.gmail.com>
References: <CAN2xGJboVi7nzERczGJvfBnPFTYf-ahUMR=fvY7YXPf3JiTnJw@mail.gmail.com>
Message-ID: <949B8E49-8238-4B1C-99FD-9B11791FD18E@comcast.net>


On Jun 25, 2015, at 1:25 PM, Dimitri Liakhovitski wrote:

> Hello!
> 
> I have a data frame md:
> 
>    md <- data.frame(x = c(3,5,4,5,3,5), y = c(5,5,5,4,4,1), z = c(1,3,4,3,5,5),
>          device1 = c("c","a","a","b","c","c"), device2 =
> c("B","A","A","A","B","B"))
>    md[2,3] <- NA
>    md[4,1] <- NA
>    md
> 
> I want to calculate means by device1 / device2 combinations using dplyr:
> 
>    library(dplyr)
>    md %>% group_by(device1, device2) %>% summarise_each(funs(mean))
> 
> However, I am getting some NAs. I want the NAs to be ignored (na.rm =
> TRUE) - I tried, but the function doesn't want to accept this
> argument.


The help page for the `funs`-function has several examples:

This succeeds:

   md %>% group_by(device1, device2) %>% summarise_each(funs(mean( ., na.rm=TRUE))))


> Both these lines result in error:
> 
>    md %>% group_by(device1, device2) %>% summarise_each(funs(mean),
> na.rm = TRUE)
>    md %>% group_by(device1, device2) %>% summarise_each(funs(mean,
> na.rm = TRUE))
> 
> Thank you for your advice!
> 
> 
> -- 
> Dimitri Liakhovitski
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From shidaxia at yahoo.com  Fri Jun 26 01:04:19 2015
From: shidaxia at yahoo.com (Shi, Tao)
Date: Thu, 25 Jun 2015 23:04:19 +0000 (UTC)
Subject: [R] how to change the "ff" properties of a "ff"-related R object
 after the original "ff" output folder has been moved
Message-ID: <1874071689.1386771.1435273459583.JavaMail.yahoo@mail.yahoo.com>

Hi all,

I'm new to "ff" package through the using Bioconductor package "crlmm".  Here is my problem:

I've created a few R objects (e.g. an CNSet) using crlmm based on my data and save them in a .RData file.  crlmm heavily uses ff package to store results on a local folder.  For certain reasons, I have moved the ff output folder to somewhere else.  Now when I go back to R, I can't open those CNSet, for example, anymore, as the file has a property still storing the old ff output folder path. 

My question is: is there a quick way to change these paths to the new one, so I don't have to re-run the own analysis.

Many thanks!

Tao


From dulcalma at bigpond.com  Fri Jun 26 04:16:49 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 26 Jun 2015 12:16:49 +1000
Subject: [R] R lattice : labeling of matrix groups of different
	size	with strips
In-Reply-To: <CAKy6dj=d8W7RiBiy=L4DaiODrCmhfDiFvNnmdX3spZxckOxU0g@mail.gmail.com>
References: <CAKy6djnrm2rW3SSRy4eWk9xeRdMFksA+GhaJPR6-27560nWtTQ@mail.gmail.com>	<000901d0aedb$fefb0940$fcf11bc0$@bigpond.com>
	<CAKy6dj=d8W7RiBiy=L4DaiODrCmhfDiFvNnmdX3spZxckOxU0g@mail.gmail.com>
Message-ID: <000c01d0afb6$297e8310$7c7b8930$@bigpond.com>

I am not sure that changing the aspect ratio by using 
levelplot(plotMatrix[,,2],
                 aspect = 1/0.6,
                 ...)

will do the job as I seem to remember doing something like that when first looking at your problem. There were unwanted side effects

using grid.arrange is the quick way to fill the plot area, I rarely use it

You may be better off by using print - I have not got your original data so I can only guess
eg

print(plot2, position = c(0.2,0,0.8,0.5), more = TRUE)
print(plot1 position = c(0,0.5,1.1), more = FALSE)

You may have to fiddle with the position values for plot2 to get it right.

If the text of plot2 is too small then you could put a line in to get plot2
par.settings = list(fontsize = list(text = 12.5, points = 8)),  
this is device dependent and you may need to change it

 Regards

Duncan


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of R codeplayer
Sent: Thursday, 25 June 2015 21:01
To: r-help at r-project.org
Subject: Re: [R] R lattice : labeling of matrix groups of different size with strips

Hi Duncan,


thank you very much for your help.


Originally, I thought that it is possible to use a different data
representation and then to automatically create the plots and strips
in lattice.

Based on your suggestion, I could write the code for an annotated
levelplot of the two groups (code is shown below).

An open question is how to display the two groups with the same aspect
ratio for the rows.


> plotMatrix
> , , group1
>
>   a b c d
> 1 1 0 0 0
> 2 1 0 0 0
> 3 1 1 0 0
> 4 0 1 0 0
> 5 0 1 1 0
>
> , , group2
>
>    a  b  c  d
> 1  0  0  1  0
> 2  0  0  1  1
> 3  0  0  0  1
> 4 NA NA NA NA
> 5 NA NA NA NA

library(gridExtra)

trellis.device(device = "pdf",file
="lattice_annotated_groups.pdf",width=8,height=5)

#The aspect="fill" option was added to coerce the same height of the 2 plots
#panel.text was used instead of grid.text to avoid using the
latticeExtra package

plot1 <- levelplot(plotMatrix[,,1],
             page = function(n)
             panel.text("group 1",
                 x = 0.5,
                 y = 0.96),
             colorkey = F,
             xlab = "",
             ylab="",
             aspect="fill")

pm <- plotMatrix[1:3,,2]
colnames(pm) <- rep("",ncol(pm))

plot2 <-levelplot(pm,
            page = function(n)
            panel.text(
                "group 2",
                 x = 0.5,
                 y = 0.96),
            colorkey = F,
            xlab = "",
            ylab="",
            aspect="fill")


grid.arrange(plot1,plot2,ncol=2)
dev.off()


From syen04 at gmail.com  Fri Jun 26 04:48:20 2015
From: syen04 at gmail.com (Steven Yen)
Date: Thu, 25 Jun 2015 22:48:20 -0400
Subject: [R] 'class(.) == **' [was 'Call to a function']
In-Reply-To: <21898.23129.223595.340119@stat.math.ethz.ch>
References: <5589D070.4070900@gmail.com> <5589D219.5070001@gmail.com>
	<CAJ4QxaNuMjXbRwDafabHTN1iDT95+ZS0mhdJsrGfRqnskR0JMQ@mail.gmail.com>
	<5589ED9F.7020801@gmail.com>
	<CCE952776B6679469977532BD863C39CB2B11745@Patterson.autuni.aut.ac.nz>
	<21898.23129.223595.340119@stat.math.ethz.ch>
Message-ID: <558CBD74.7050705@gmail.com>

Thanks to all for the help. I have learned much about "inherit" and 
"class". I like to know about one additional option, and that is to use 
a calling parameter without the quotation marks, similar to the linear 
regression syntax:

lm(data=mydata,weights=wt)

Below is a simple set of codes to calculate weighted means with 
generated data in data frame "mydata". As annotated below, I like the 
following call to work (without the quotations):

wmean(mydata,wt=weight)

Thank you!
----

mydata<-matrix(1:20,ncol=2)
mydata<-cbind(mydata,runif(10,0,1))
colnames(mydata)<-c("y","x","weight")
mydata<-as.data.frame(mydata)

wmean <- function(data,wt){
   if (inherits(wt,what="character")) wt<-data[,wt]
   wt<-wt/mean(wt)
   Mean<-NULL
   for (i in 1:ncol(data)){
     Mean[i] <- sum(data[,i]*wt)/sum(wt)
   }
   list("Mean: ",Mean)
}
wmean(mydata,wt="weight") # This works
wmean(mydata,wt=weight)   # <= Like this to work
reg<-lm(data=mydata,weights=weight) # ? lm

On 6/24/2015 3:20 AM, Martin Maechler wrote:
>>>>>> Steve Taylor <steve.taylor at aut.ac.nz>
>>>>>>      on Wed, 24 Jun 2015 00:56:26 +0000 writes:
>
>      > Note that objects can have more than one class, in which case your == and %in% might not work as expected.
>
>      > Better to use inherits().
>
>      > cheers,
>      > Steve
>
> Yes indeed, as Steve said, really do!
>
> The use of   (class(.) == "....")   it is error prone and
> against the philosophy of classes (S3 or S4 or ..) in R :
>
> Classes can "extend" other classes or "inherit" from them;
> S3 examples in "base R"  are
>   - glm() objects which are "glm"
>     but also inherit from "lm"
>   - multivariate time-series are "mts" and "ts"
>   - The time-date objects  POSIXt , POSIXct, POSIXlt
>
> ==> do work  with  inherits(<obj>, <class))
> or  possibly       is( <obj>, <class>)
>
>
> We've seen this use of	
>
>       class(.) == ".."    (or '!=" or  %in% ...)
>
> in too many places;  though it may work fine in your test cases,
> it is wrong to be used in generality e.g. inside a function you
> provide for more general use,
> and is best  replaced with the use of inherits() / is()
> everywhere  "out of principle".
>
> Martin Maechler
> ETH Zurich
>

-- 
Steven Yen
My e-mail alert:
https://youtu.be/9UwEAruhyhY?list=PLpwR3gb9OGHP1BzgVuO9iIDdogVOijCtO


From dwinsemius at comcast.net  Fri Jun 26 05:53:07 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 25 Jun 2015 20:53:07 -0700
Subject: [R] how to change the "ff" properties of a "ff"-related R
	object after the original "ff" output folder has been moved
In-Reply-To: <1874071689.1386771.1435273459583.JavaMail.yahoo@mail.yahoo.com>
References: <1874071689.1386771.1435273459583.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <100F322A-507D-4417-B0AA-A19A1381FCBE@comcast.net>


On Jun 25, 2015, at 4:04 PM, Shi, Tao via R-help wrote:

> Hi all,
> 
> I'm new to "ff" package through the using Bioconductor package "crlmm".  Here is my problem:
> 
> I've created a few R objects (e.g. an CNSet) using crlmm based on my data and save them in a .RData file.  crlmm heavily uses ff package to store results on a local folder.  For certain reasons, I have moved the ff output folder to somewhere else.  Now when I go back to R, I can't open those CNSet, for example, anymore, as the file has a property still storing the old ff output folder path. 
> 
> My question is: is there a quick way to change these paths to the new one, so I don't have to re-run the own analysis.
> 

The way to approach this is to create a small example that illustrates teh problem. In many case all will becove clear, but if not then you will have something that you can then post ... IN R CODE ... that will let us (most of whom are not ff-urers) see the problem.

--
David Winsemius
Alameda, CA, USA


From mylisttech at gmail.com  Fri Jun 26 07:34:58 2015
From: mylisttech at gmail.com (My List)
Date: Fri, 26 Jun 2015 11:04:58 +0530
Subject: [R] VCD package - Setting confidence interval for oddsratio and
	loddsratio
Message-ID: <CAFpdVnzKTMdifrBpWs4PmWkHKi=MuTq3ty6ebcynKyzNpeKWyw@mail.gmail.com>

All:

I am using oddsratio() and loddsratio() from the VCD package. How do I set
the confidence interval for the these functions.I want to set it 95 %.I
have thought that the odds ratio functions don't need confidence interval
for calculation , but yes for interpretation they use confidence intervals,
with the Z statistic.

I apologize if I am wrong in my thinking.

Thanks in Advance,
Harmeet

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Jun 26 08:39:18 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 25 Jun 2015 23:39:18 -0700
Subject: [R] 'class(.) == **' [was 'Call to a function']
In-Reply-To: <558CBD74.7050705@gmail.com>
References: <5589D070.4070900@gmail.com> <5589D219.5070001@gmail.com>
	<CAJ4QxaNuMjXbRwDafabHTN1iDT95+ZS0mhdJsrGfRqnskR0JMQ@mail.gmail.com>
	<5589ED9F.7020801@gmail.com>
	<CCE952776B6679469977532BD863C39CB2B11745@Patterson.autuni.aut.ac.nz>
	<21898.23129.223595.340119@stat.math.ethz.ch>
	<558CBD74.7050705@gmail.com>
Message-ID: <AAAB00B7-5474-404B-83E0-9EB8C4AA14E2@comcast.net>


On Jun 25, 2015, at 7:48 PM, Steven Yen wrote:

> Thanks to all for the help. I have learned much about "inherit" and "class". I like to know about one additional option, and that is to use a calling parameter without the quotation marks, similar to the linear regression syntax:
> 
> lm(data=mydata,weights=wt)
> 
> Below is a simple set of codes to calculate weighted means with generated data in data frame "mydata". As annotated below, I like the following call to work (without the quotations):
> 
> wmean(mydata,wt=weight)

Let's start with the call. If you are to execute this,  then names `mydata` and `weight` each must have a value.

> 
> Thank you!
> ----
> 
> mydata<-matrix(1:20,ncol=2)

OK. There is a value having been assigned to `mydata`

> mydata<-cbind(mydata,runif(10,0,1))

And now augmented.

> colnames(mydata)<-c("y","x","weight")

And a names attribute added for its columns.

> mydata<-as.data.frame(mydata)
> 
> wmean <- function(data,wt){
>  if (inherits(wt,what="character")) wt<-data[,wt]
>  wt<-wt/mean(wt)

Here's the problem. If `wt` was of mode "character", then you cannot divide it by a number, since the RHS will be evaluated first. You really should read the error messages!

Perhaps you meant:

wt <-  data[, wt]/mean(data[ , wt]

But if you did, then it's rather confusing (but possible) to assign the value to the same name as the column of the matrix.


>  Mean<-NULL

Why do that? If you remove it from the workspace then you cannot assign a value using indexed assignment as you apparently intend to do. Should have been

Mean <- numeric( ncol(data) )


>  for (i in 1:ncol(data)){
>    Mean[i] <- sum(data[,i]*wt)/sum(wt)

There is a bit of a confusion here. `wt` started out as a character value. I guess you could do this.

>  }
>  list("Mean: ",Mean)

Wrong syntax for lists. Suspect you want 	

   list(Mean=Mean)


> }
> wmean(mydata,wt="weight") # This works
> wmean(mydata,wt=weight)   # <= Like this to work

So were you planning to execute this first?

weight="weight" #?

-- 
David.


> reg<-lm(data=mydata,weights=weight) # ? lm
> 
> On 6/24/2015 3:20 AM, Martin Maechler wrote:
>>>>>>> Steve Taylor <steve.taylor at aut.ac.nz>
>>>>>>>     on Wed, 24 Jun 2015 00:56:26 +0000 writes:
>> 
>>     > Note that objects can have more than one class, in which case your == and %in% might not work as expected.
>> 
>>     > Better to use inherits().
>> 
>>     > cheers,
>>     > Steve
>> 
>> Yes indeed, as Steve said, really do!
>> 
>> The use of   (class(.) == "....")   it is error prone and
>> against the philosophy of classes (S3 or S4 or ..) in R :
>> 
>> Classes can "extend" other classes or "inherit" from them;
>> S3 examples in "base R"  are
>>  - glm() objects which are "glm"
>>    but also inherit from "lm"
>>  - multivariate time-series are "mts" and "ts"
>>  - The time-date objects  POSIXt , POSIXct, POSIXlt
>> 
>> ==> do work  with  inherits(<obj>, <class))
>> or  possibly       is( <obj>, <class>)
>> 
>> 
>> We've seen this use of	
>> 
>>      class(.) == ".."    (or '!=" or  %in% ...)
>> 
>> in too many places;  though it may work fine in your test cases,
>> it is wrong to be used in generality e.g. inside a function you
>> provide for more general use,
>> and is best  replaced with the use of inherits() / is()
>> everywhere  "out of principle".
>> 
>> Martin Maechler
>> ETH Zurich
>> 
> 
> -- 
> Steven Yen
> My e-mail alert:
> https://youtu.be/9UwEAruhyhY?list=PLpwR3gb9OGHP1BzgVuO9iIDdogVOijCtO
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rcodeplayer at gmail.com  Fri Jun 26 06:07:08 2015
From: rcodeplayer at gmail.com (R codeplayer)
Date: Fri, 26 Jun 2015 06:07:08 +0200
Subject: [R] R lattice : labeling of matrix groups of different size
	with strips
In-Reply-To: <000c01d0afb6$297e8310$7c7b8930$@bigpond.com>
References: <CAKy6djnrm2rW3SSRy4eWk9xeRdMFksA+GhaJPR6-27560nWtTQ@mail.gmail.com>
	<000901d0aedb$fefb0940$fcf11bc0$@bigpond.com>
	<CAKy6dj=d8W7RiBiy=L4DaiODrCmhfDiFvNnmdX3spZxckOxU0g@mail.gmail.com>
	<000c01d0afb6$297e8310$7c7b8930$@bigpond.com>
Message-ID: <CAKy6djku8K97E=pL-G123v5rx0uA591fddLXnBEN7RSFW=Q-VQ@mail.gmail.com>

Hi Duncan,


thank you so much for your help.


2015-06-26 4:16 GMT+02:00 Duncan Mackay <dulcalma at bigpond.com>:
> I am not sure that changing the aspect ratio by using
> levelplot(plotMatrix[,,2],
>                  aspect = 1/0.6,
>                  ...)

I already experimented with different values of aspect but I newer get
the height of the groups to match


>
> will do the job as I seem to remember doing something like that when first looking at your problem. There were unwanted side effects
>
> using grid.arrange is the quick way to fill the plot area, I rarely use it
>
> You may be better off by using print - I have not got your original data so I can only guess
> eg
>
> print(plot2, position = c(0.2,0,0.8,0.5), more = TRUE)
> print(plot1 position = c(0,0.5,1.1), more = FALSE)

In this approach, I get a different size for the height and width of the groups.

> You may have to fiddle with the position values for plot2 to get it right.
>
> If the text of plot2 is too small then you could put a line in to get plot2
> par.settings = list(fontsize = list(text = 12.5, points = 8)),
> this is device dependent and you may need to change it
>
>  Regards
>
> Duncan
>

Thank you for your time

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of R codeplayer
> Sent: Thursday, 25 June 2015 21:01
> To: r-help at r-project.org
> Subject: Re: [R] R lattice : labeling of matrix groups of different size with strips
>
> Hi Duncan,
>
>
> thank you very much for your help.
>
>
> Originally, I thought that it is possible to use a different data
> representation and then to automatically create the plots and strips
> in lattice.
>
> Based on your suggestion, I could write the code for an annotated
> levelplot of the two groups (code is shown below).
>
> An open question is how to display the two groups with the same aspect
> ratio for the rows.
>
>
>> plotMatrix
>> , , group1
>>
>>   a b c d
>> 1 1 0 0 0
>> 2 1 0 0 0
>> 3 1 1 0 0
>> 4 0 1 0 0
>> 5 0 1 1 0
>>
>> , , group2
>>
>>    a  b  c  d
>> 1  0  0  1  0
>> 2  0  0  1  1
>> 3  0  0  0  1
>> 4 NA NA NA NA
>> 5 NA NA NA NA
>
> library(gridExtra)
>
> trellis.device(device = "pdf",file
> ="lattice_annotated_groups.pdf",width=8,height=5)
>
> #The aspect="fill" option was added to coerce the same height of the 2 plots
> #panel.text was used instead of grid.text to avoid using the
> latticeExtra package
>
> plot1 <- levelplot(plotMatrix[,,1],
>              page = function(n)
>              panel.text("group 1",
>                  x = 0.5,
>                  y = 0.96),
>              colorkey = F,
>              xlab = "",
>              ylab="",
>              aspect="fill")
>
> pm <- plotMatrix[1:3,,2]
> colnames(pm) <- rep("",ncol(pm))
>
> plot2 <-levelplot(pm,
>             page = function(n)
>             panel.text(
>                 "group 2",
>                  x = 0.5,
>                  y = 0.96),
>             colorkey = F,
>             xlab = "",
>             ylab="",
>             aspect="fill")
>
>
> grid.arrange(plot1,plot2,ncol=2)
> dev.off()
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From adeela.uaf at gmail.com  Fri Jun 26 08:09:55 2015
From: adeela.uaf at gmail.com (adeela uaf)
Date: Fri, 26 Jun 2015 11:09:55 +0500
Subject: [R] extracting significant response variables
Message-ID: <CABGg3O77Wi0Y3CTfqrC+DO8=S8nWGjRaXrLVWRyhHLmX+ouTNA@mail.gmail.com>

Hi,
My experiment consist of factorial structure with 25 genotypes and 3
salinity levels ( 25 cross 3) each with 3 replications.  14 responses were
taken from the experiment and I applied MANOVA but I am applying
discriminant analysis to know which response variable has significant
impact on the separation of groups. I am doing the following:
MANOVA<-manova(cbind(RL,SL,RFW,SFW,RDW,SDW,R.S..DW.,LA,NL,Na,K,Ca)~geneotype*S.Level,data=data)
For discriminant analysis, I made a group of 1 genotype with one level of
Salinity level hence a total of 75 groups.
group<-paste("g", gl(75,3,length=225))
LDA<-lda(group~RL+SL+RFW+SFW+RDW+SDW+R.S..DW.+LA+NL+Na+K+Ca+K.Na+Ca.Na,data=Sdata)

Is it appropriate way? Moreover when I am plotting discriminant scores
means with the circle of radius r=z/sqrt(replication) but the graph doesn't
make any sense as the circles are too small too see.
Thanks,
Adeela
-------------- next part --------------
A non-text attachment was scrubbed...
Name: lda.pdf
Type: application/pdf
Size: 5835 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150626/15ce5441/attachment.pdf>

From syen04 at gmail.com  Fri Jun 26 08:52:34 2015
From: syen04 at gmail.com (Steven Yen)
Date: Fri, 26 Jun 2015 02:52:34 -0400
Subject: [R] 'class(.) == **' [was 'Call to a function']
In-Reply-To: <AAAB00B7-5474-404B-83E0-9EB8C4AA14E2@comcast.net>
References: <5589D070.4070900@gmail.com> <5589D219.5070001@gmail.com>
	<CAJ4QxaNuMjXbRwDafabHTN1iDT95+ZS0mhdJsrGfRqnskR0JMQ@mail.gmail.com>
	<5589ED9F.7020801@gmail.com>
	<CCE952776B6679469977532BD863C39CB2B11745@Patterson.autuni.aut.ac.nz>
	<21898.23129.223595.340119@stat.math.ethz.ch>
	<558CBD74.7050705@gmail.com>
	<AAAB00B7-5474-404B-83E0-9EB8C4AA14E2@comcast.net>
Message-ID: <558CF6B2.9070200@gmail.com>

Thanks Davis. But actually, the line is legitimate:

    if (inherits(wt,what="character")) wt<-data[,wt]

because, coming down with wt being characters, the part wt<-data[,wt] 
then picks up variables data$wt. The call

    wmean(mydata,wt="weight")

actually goes OK. I was hoping to figure out a way to fix the wmean 
routine some how so that I can call with

    wmean(mydata,wt=weight)

Good to know there is a better way to initialize the vector Mean and and 
a better list command. Thank you!

On 6/26/2015 2:39 AM, David Winsemius wrote:
>
> On Jun 25, 2015, at 7:48 PM, Steven Yen wrote:
>
>> Thanks to all for the help. I have learned much about "inherit" and "class". I like to know about one additional option, and that is to use a calling parameter without the quotation marks, similar to the linear regression syntax:
>>
>> lm(data=mydata,weights=wt)
>>
>> Below is a simple set of codes to calculate weighted means with generated data in data frame "mydata". As annotated below, I like the following call to work (without the quotations):
>>
>> wmean(mydata,wt=weight)
>
> Let's start with the call. If you are to execute this,  then names `mydata` and `weight` each must have a value.
>
>>
>> Thank you!
>> ----
>>
>> mydata<-matrix(1:20,ncol=2)
>
> OK. There is a value having been assigned to `mydata`
>
>> mydata<-cbind(mydata,runif(10,0,1))
>
> And now augmented.
>
>> colnames(mydata)<-c("y","x","weight")
>
> And a names attribute added for its columns.
>
>> mydata<-as.data.frame(mydata)
>>
>> wmean <- function(data,wt){
>>   if (inherits(wt,what="character")) wt<-data[,wt]
>>   wt<-wt/mean(wt)
>
> Here's the problem. If `wt` was of mode "character", then you cannot divide it by a number, since the RHS will be evaluated first. You really should read the error messages!
>
> Perhaps you meant:
>
> wt <-  data[, wt]/mean(data[ , wt]
>
> But if you did, then it's rather confusing (but possible) to assign the value to the same name as the column of the matrix.
>
>
>>   Mean<-NULL
>
> Why do that? If you remove it from the workspace then you cannot assign a value using indexed assignment as you apparently intend to do. Should have been
>
> Mean <- numeric( ncol(data) )
>
>
>>   for (i in 1:ncol(data)){
>>     Mean[i] <- sum(data[,i]*wt)/sum(wt)
>
> There is a bit of a confusion here. `wt` started out as a character value. I guess you could do this.
>
>>   }
>>   list("Mean: ",Mean)
>
> Wrong syntax for lists. Suspect you want 	
>
>     list(Mean=Mean)
>
>
>> }
>> wmean(mydata,wt="weight") # This works
>> wmean(mydata,wt=weight)   # <= Like this to work
>
> So were you planning to execute this first?
>
> weight="weight" #?
>

-- 
Steven Yen
My e-mail alert:
https://youtu.be/9UwEAruhyhY?list=PLpwR3gb9OGHP1BzgVuO9iIDdogVOijCtO


From goran.brostrom at umu.se  Fri Jun 26 08:59:17 2015
From: goran.brostrom at umu.se (=?windows-1252?Q?G=F6ran_Brostr=F6m?=)
Date: Fri, 26 Jun 2015 08:59:17 +0200
Subject: [R] prmatrix and print.matrix
In-Reply-To: <2f3a88$ti78n@ironport10.mayo.edu>
References: <2f3a88$ti78n@ironport10.mayo.edu>
Message-ID: <558CF845.7060901@umu.se>



On 06/25/2015 11:18 PM, Therneau, Terry M., Ph.D. wrote:
> The help page for prmatrix states that it only exists for backwards compatability and
> strongly hints at using print.matrix instead.
>    However, there does not seem to be a print.matrix() function.'

I asked this very same question here 18 months ago, but got no real 
answer (except for a reference to 'write.matrix' (MASS) from David 
Winsemius). However, googling found the following:

--------------------------------
Updating packages for 1.7.0:
....
print.matrix() only exists for backwards compatibility: it is the same
as print.default().  Very likely print.matrix was used for the
right=TRUE argument that S's print.default does not have, but this is
unnecessary.  If you want the call sequence of print.matrix, use 
prmatrix instead.  Also, note that print prints the attributes of the 
matrix whereas prmatrix does not.
------------------------------
http://developer.r-project.org/170update.txt

So, my guess is that print.matrix once existed but is now silently gone. 
Use print.default.

G?ran

>
> The help page for print mentions a zero.print option, but that does not appear to affect
> matrices.  This (or something like it) is what I was looking for.
>
> Am I overlooking something?
>
> Terry Therneau
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mylisttech at gmail.com  Fri Jun 26 09:07:12 2015
From: mylisttech at gmail.com (My List)
Date: Fri, 26 Jun 2015 12:37:12 +0530
Subject: [R] Usage of sink()
Message-ID: <CAFpdVnzhtz8MhmOpjoj7UtqQb5Q2fV2kd-1MYUOOGsdAcLRL_w@mail.gmail.com>

All:

I have the following code segment.

msg <- file("msg.txt", open="wt")
out   <- file("out.txt", open="wt")
sink(msg, type="message")
sink(out, type="output")
write("write() to stderr", stderr())
write("write() to stdout", stdout())

This works fine, when I want the messages to goto mes.txt and output to
out.xt.

My desire is now to get to send both the output and messages( i.e stdout
and stderr) to ONE file.

How do I accomplish this?

Thanks in Advance,
- Harmeet

	[[alternative HTML version deleted]]


From rh at knut-krueger.de  Fri Jun 26 10:09:42 2015
From: rh at knut-krueger.de (Knut Krueger)
Date: Fri, 26 Jun 2015 10:09:42 +0200
Subject: [R] counting similar strings in data.frame
Message-ID: <558D08C6.8030807@knut-krueger.de>

Dear Members,

is there a better solution to count the amounts of occurrence in a row 
with string data than with loops to get the count data.frame?

test =data.frame("first"=c("seven","two","five","four"),
                  "second"=c("three","one","three","one"),
                  "third"=c("four","two","three","four"),
                  "fourth"=c("four","one","one","four"))



count =data.frame("double1"=c("four","two","three","NA"),
                  "double2"=c("NA","one","NA","NA"),
                  "triple"=c("NA","NA","NA","one"))


double1: first double occurrence in row  (NA if triple available)
double2: second double occurrence in row (NA if triple available or if 
there is only one double)
triple: triple occurrence in row (NA if a double available)


Kind regards Knut


From mylisttech at gmail.com  Fri Jun 26 10:14:08 2015
From: mylisttech at gmail.com (My List)
Date: Fri, 26 Jun 2015 13:44:08 +0530
Subject: [R] Usage of sink()
In-Reply-To: <201506261518144083991@163.com>
References: <CAFpdVnzhtz8MhmOpjoj7UtqQb5Q2fV2kd-1MYUOOGsdAcLRL_w@mail.gmail.com>
	<201506261518144083991@163.com>
Message-ID: <CAFpdVnxXoxatOMRQPjpd3C3rAWXaXaSocq+aU0rDumvxXoU02A@mail.gmail.com>

I used the following code -
msg <- file("ABC.txt", open="a")
out <- file("ABC.txt", open="a")
sink(msg, type="message")
sink(out, type="output")
write("write() to stderr", stderr())
write("write() to stdout", stdout())

and it works.

Thanks !!!
-Harmeet

On Fri, Jun 26, 2015 at 12:48 PM, Jianwen Luo <goutyl at 163.com> wrote:

> just use same file handle.
>
> ------------------------------
>
>
> *From:* My List <mylisttech at gmail.com>
> *Date:* 2015-06-26 15:37
> *To:* R-help <R-help at r-project.org>
> *Subject:* [R] Usage of sink()
> All:
>
> I have the following code segment.
>
> msg <- file("msg.txt", open="wt")
> out   <- file("out.txt", open="wt")
> sink(msg, type="message")
> sink(out, type="output")
> write("write() to stderr", stderr())
> write("write() to stdout", stdout())
>
> This works fine, when I want the messages to goto mes.txt and output to
> out.xt.
>
> My desire is now to get to send both the output and messages( i.e stdout
> and stderr) to ONE file.
>
> How do I accomplish this?
>
> Thanks in Advance,
> - Harmeet
>
>  [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Thanks,
Harmeet

	[[alternative HTML version deleted]]


From goutyl at 163.com  Fri Jun 26 09:18:18 2015
From: goutyl at 163.com (Jianwen Luo)
Date: Fri, 26 Jun 2015 15:18:18 +0800
Subject: [R] Usage of sink()
References: <CAFpdVnzhtz8MhmOpjoj7UtqQb5Q2fV2kd-1MYUOOGsdAcLRL_w@mail.gmail.com>
Message-ID: <201506261518144083991@163.com>

just use same file handle.



 
From: My List
Date: 2015-06-26 15:37
To: R-help
Subject: [R] Usage of sink()
All:
 
I have the following code segment.
 
msg <- file("msg.txt", open="wt")
out   <- file("out.txt", open="wt")
sink(msg, type="message")
sink(out, type="output")
write("write() to stderr", stderr())
write("write() to stdout", stdout())
 
This works fine, when I want the messages to goto mes.txt and output to
out.xt.
 
My desire is now to get to send both the output and messages( i.e stdout
and stderr) to ONE file.
 
How do I accomplish this?
 
Thanks in Advance,
- Harmeet
 
[[alternative HTML version deleted]]
 
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Jun 26 10:38:59 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 26 Jun 2015 08:38:59 +0000
Subject: [R] counting similar strings in data.frame
In-Reply-To: <558D08C6.8030807@knut-krueger.de>
References: <558D08C6.8030807@knut-krueger.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3266D@SRVEXCHMBX.precheza.cz>

Hi

I am little bit lost in your logic. Why triple in your fourth line is one. I expected it will be four?

Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Knut
> Krueger
> Sent: Friday, June 26, 2015 10:10 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] counting similar strings in data.frame
>
> Dear Members,
>
> is there a better solution to count the amounts of occurrence in a row
> with string data than with loops to get the count data.frame?
>
> test =data.frame("first"=c("seven","two","five","four"),
>                   "second"=c("three","one","three","one"),
>                   "third"=c("four","two","three","four"),
>                   "fourth"=c("four","one","one","four"))
>
>
>
> count =data.frame("double1"=c("four","two","three","NA"),
>                   "double2"=c("NA","one","NA","NA"),
>                   "triple"=c("NA","NA","NA","one"))
>
>
> double1: first double occurrence in row  (NA if triple available)
> double2: second double occurrence in row (NA if triple available or if
> there is only one double)
> triple: triple occurrence in row (NA if a double available)
>
>
> Kind regards Knut
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Jens.Oehlschlaegel at truecluster.com  Fri Jun 26 12:31:29 2015
From: Jens.Oehlschlaegel at truecluster.com (=?UTF-8?B?SmVucyBPZWhsc2NobMOkZ2Vs?=)
Date: Fri, 26 Jun 2015 12:31:29 +0200
Subject: [R] how to change the "ff" properties of a "ff"-related R
 object after the original "ff" output folder has been moved
In-Reply-To: <1874071689.1386771.1435273459583.JavaMail.yahoo@mail.yahoo.com>
References: <1874071689.1386771.1435273459583.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <558D2A01.1070008@truecluster.com>

Tao,

I do assume that the ff-files are still at some location and not deleted 
by a finalizer. The following explains how to manipulate file locations 
with ff and ffdf objects.

Kind regards
jens

library(ff)
path1 <- "c:/tmp"
path2 <- "c:/tmp2"
# create ffdf,
# using non-standard path sets finalizer to 'close' instead of 'delete'
fdf1 <- as.ffdf(iris, col_args=list(pattern=file.path(path1,"iris")))
# let's copy the old metadata (but not the files, useclone for that)
# using ffs hybrid copying semantics
fdf2 <- fdf1
# note both are open
is.open(fdf1)
is.open(fdf2)
# close the files
close(fdf1)
# and note that
is.open(fdf1)
is.open(fdf2)
# the magic has kept physical metadata in synch even in the copy
# (virtual metadata is not kept in synch
# which allows different virtual views into the same files
# not unlike SQL VIEWs virtualize dastabase TABLEs)

# filename on a ffdf
filename(fdf2)
# is a shortcut for
lapply(physical(fdf2), filename)
# so filename is a physical attribute
# actually moving the files can be done with the filename<- method
lapply(physical(fdf2), function(x)filename(x) <- sub(path1, path2, 
filename(x)))
# check this
filename(fdf1)
filename(fdf2)

# filename on ff
filename(fdf1$Species)
# is a shortcut for
attr(attr(fdf1$Species, "physical"), "filename")
# and if you directly manipulate this attribute
# you circummvent the filename method
# and the file itself will not be moved
attr(attr(fdf1$Species, "physical"), "filename") <- sub(path2, path1, 
filename(fdf1$Species))
# now the metadata points to a different location
filename(fdf1$Species)
# note that this physical attribute was also changed
# for the copy
filename(fdf2$Species)
# of course you can fix the erroneous metadata by
attr(attr(fdf1$Species, "physical"), "filename") <- sub(path1, path2, 
filename(fdf1$Species))
# or for all columns in a ffdf by
lapply(physical(fdf2), function(x)attr(attr(x, "physical"), "filename") 
<- sub(path2, path1, filename(x)))
# now we have your situation with broken metadata
open(fdf2)
# and can fix that by
lapply(physical(fdf2), function(x)attr(attr(x, "physical"), "filename") 
<- sub(path1, path2, filename(x)))
# check
open(fdf2)



Am 26.06.2015 um 01:04 schrieb Shi, Tao:
> Hi all,
>
> I'm new to "ff" package through the using Bioconductor package "crlmm".  Here is my problem:
>
> I've created a few R objects (e.g. an CNSet) using crlmm based on my data and save them in a .RData file.  crlmm heavily uses ff package to store results on a local folder.  For certain reasons, I have moved the ff output folder to somewhere else.  Now when I go back to R, I can't open those CNSet, for example, anymore, as the file has a property still storing the old ff output folder path.
>
> My question is: is there a quick way to change these paths to the new one, so I don't have to re-run the own analysis.
>
> Many thanks!
>
> Tao
>


From rh at knut-krueger.de  Fri Jun 26 12:48:48 2015
From: rh at knut-krueger.de (Knut Krueger)
Date: Fri, 26 Jun 2015 12:48:48 +0200
Subject: [R] counting similar strings in data.frame
In-Reply-To: <558D08C6.8030807@knut-krueger.de>
References: <558D08C6.8030807@knut-krueger.de>
Message-ID: <558D2E10.3080506@knut-krueger.de>

Sorry last count was wrong ...

test =data.frame("first"=c("seven","two","five","four"),
                  "second"=c("three","one","three","one"),
                  "third"=c("four","two","three","four"),
                  "fourth"=c("four","one","one","four"))

count =data.frame("dobule1"=c("four","two","three","NA"),
                  "double2"=c("NA","one","NA","NA"),
                  "triple"=c("NA","NA","NA","four"))


From rh at knut-krueger.de  Fri Jun 26 12:49:52 2015
From: rh at knut-krueger.de (Knut Krueger)
Date: Fri, 26 Jun 2015 12:49:52 +0200
Subject: [R] counting similar strings in data.frame
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3266D@SRVEXCHMBX.precheza.cz>
References: <558D08C6.8030807@knut-krueger.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3266D@SRVEXCHMBX.precheza.cz>
Message-ID: <558D2E50.8030903@knut-krueger.de>

Am 26.06.2015 um 10:38 schrieb PIKAL Petr:
> Hi
>
> I am little bit lost in your logic. Why triple in your fourth line is one. I expected it will be four?
>
> Petr
Sorry yes you are right ...

type mismatch
Knut


From petr.pikal at precheza.cz  Fri Jun 26 13:55:06 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 26 Jun 2015 11:55:06 +0000
Subject: [R] counting similar strings in data.frame
In-Reply-To: <558D2E50.8030903@knut-krueger.de>
References: <558D08C6.8030807@knut-krueger.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3266D@SRVEXCHMBX.precheza.cz>
	<558D2E50.8030903@knut-krueger.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3279C@SRVEXCHMBX.precheza.cz>

OK. I do not have canned solution for you, but

temp <- apply(test,1, table)

gives you number of occurences in each row. From this it shall be possible to extract name info and number info

lapply(temp, function(x) x[x>1])

[[1]]
four
   2

[[2]]

one two
  2   2

[[3]]
three
    2

[[4]]
four
   3

Here you have numbers and strings and you need to combine them. However I am not sure how. If you want to use them for some further computation, maybe list structure is as good as data.frame with namy NAs.

Cheers
Petr


> -----Original Message-----
> From: Knut Krueger [mailto:rh at knut-krueger.de]
> Sent: Friday, June 26, 2015 12:50 PM
> To: PIKAL Petr; r-help at stat.math.ethz.ch
> Subject: Re: [R] counting similar strings in data.frame
>
> Am 26.06.2015 um 10:38 schrieb PIKAL Petr:
> > Hi
> >
> > I am little bit lost in your logic. Why triple in your fourth line is
> one. I expected it will be four?
> >
> > Petr
> Sorry yes you are right ...
>
> type mismatch
> Knut
>
>
>
>


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From bgunter.4567 at gmail.com  Fri Jun 26 15:57:59 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 26 Jun 2015 06:57:59 -0700
Subject: [R] extracting significant response variables
In-Reply-To: <CABGg3O77Wi0Y3CTfqrC+DO8=S8nWGjRaXrLVWRyhHLmX+ouTNA@mail.gmail.com>
References: <CABGg3O77Wi0Y3CTfqrC+DO8=S8nWGjRaXrLVWRyhHLmX+ouTNA@mail.gmail.com>
Message-ID: <CAGxFJbTuyE29LgYQC2dkg1GLnroczUMoA5cZn6RBnhZXR5kChA@mail.gmail.com>

Offtopic. This list is about R programming. Post to a statistics list
like stats.stackexchange.com instead. Better yet, find a local expert
to help you. What you describe sounds confused and likely to produce
nonsense to me. You may not even have the information needed to answer
the question you asked.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Thu, Jun 25, 2015 at 11:09 PM, adeela uaf <adeela.uaf at gmail.com> wrote:
> Hi,
> My experiment consist of factorial structure with 25 genotypes and 3
> salinity levels ( 25 cross 3) each with 3 replications.  14 responses were
> taken from the experiment and I applied MANOVA but I am applying
> discriminant analysis to know which response variable has significant
> impact on the separation of groups. I am doing the following:
> MANOVA<-manova(cbind(RL,SL,RFW,SFW,RDW,SDW,R.S..DW.,LA,NL,Na,K,Ca)~geneotype*S.Level,data=data)
> For discriminant analysis, I made a group of 1 genotype with one level of
> Salinity level hence a total of 75 groups.
> group<-paste("g", gl(75,3,length=225))
> LDA<-lda(group~RL+SL+RFW+SFW+RDW+SDW+R.S..DW.+LA+NL+Na+K+Ca+K.Na+Ca.Na,data=Sdata)
>
> Is it appropriate way? Moreover when I am plotting discriminant scores
> means with the circle of radius r=z/sqrt(replication) but the graph doesn't
> make any sense as the circles are too small too see.
> Thanks,
> Adeela
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From aasdelat at aim.com  Fri Jun 26 16:12:18 2015
From: aasdelat at aim.com (Antonio Serrano)
Date: Fri, 26 Jun 2015 10:12:18 -0400
Subject: [R] Plotting legend outside of chart area
In-Reply-To: <894df63327f4467cbd2d6e8c4eea1464@Tremail.bournemouth.ac.uk>
References: <894df63327f4467cbd2d6e8c4eea1464@Tremail.bournemouth.ac.uk>
Message-ID: <14e30363df2-4519-1e1e1@webprd-a19.mail.aol.com>

First, you have to increase the bottom margin to have enough space for the legend.
 You do it like this:
 par(
     mar = c(6,4,4,2)
 )
 
 From R help:
      ?mar? A numerical vector of the form ?c(bottom, left, top, right)?
           which gives the number of lines of margin to be specified on
           the four sides of the plot.  The default is ?c(5, 4, 4, 2) +
           0.1?.
 So, we have increased the first number from 5 to 6 to have mor space at the bottom.
 
 Then, in the legend(), you have to add the option:
 inset = c(0, -0.2),
 
 From R help:
    inset: inset distance(s) from the margins as a fraction of the plot
           region when legend is placed by keyword.
 Change the -0.2 and the 6 in the par(mar) until you get a nice chart
    
    
   
   
    
 

 

Antonio Serrano
aasdelat at aim.com
?

 

 

-----Original Message-----
From: Samantha Allcock <sallcock at bournemouth.ac.uk>
To: 'r-help at r-project.org' <r-help at r-project.org>
Sent: Wed, Jun 24, 2015 10:08 pm
Subject: [R] Plotting legend outside of chart area


Hello,

I am trying to add a legend to my PCA plot so that it looks neat. I
think plotting this outside of the chart area would be good but I cannot seem to
fathom the correct code for this. I wondered if anyone could help please?

The
code I am using is as follows:

grp<- with(Matan, cut(R_category_no,14,
labels=1:14))
cols <- c("grey0", "wheat", "red", "cyan", "orange",
"darkolivegreen2", "purple3",
"royalblue", "burlywood4", "orchid",
"forestgreen", "green",
"gray", "yellow1")
plot(geopca, display="sites",
scaling=3, type="n")
points(geopca, display="sites", scaling=3, col=cols[grp],
pch=16)

legend("bottomright", col=c("grey0", "wheat", "red", "cyan",
"orange", "darkolivegreen2",
"purple3", "royalblue", "burlywood4", "orchid",
"forestgreen", "green",
"gray", "yellow1"), c("Control type 1", "Control type
2",
"External/Courtyard", "Midden", "Animal Occupation",
"External fire
installations and ashy deposits",
"Internal fire installations and ashy
deposits", "Hearth make-up",
"Floors and surfaces", "Plasters and clay
features", "Storage features",
"Platforms and benches", "Mortars", "Roofs and
roofing materials"), pch=16,
cex=0.75, bty="n")

Thank you for your time in
advance


Dr Samantha Lee Allcock
Faculty of Science and
Technology
Department of Archaeology, Anthropology and Forensic
Science
Christchurch House Rm: C133
Bournemouth University
Talbot
Campus
Poole
BH12 5BB
Tel: 01202
9(62474)

sallcock at bournemouth.ac.uk<mailto:sallcock at bournemouth.ac.uk>
research.bournemouth.ac.uk/2014/07/inea-project-2


BU
is a Disability Two Ticks Employer and has signed up to the Mindful Employer
charter. Information about the accessibility of University buildings can be
found on the BU DisabledGo webpages This email is intended only for the person
to whom it is addressed and may contain confidential information. If you have
received this email in error, please notify the sender and delete this email,
which must not be copied, distributed or disclosed to any other person. Any
views or opinions presented are solely those of the author and do not
necessarily represent those of Bournemouth University or its subsidiary
companies. Nor can any contract be formed on behalf of the University or its
subsidiary companies via email.

	[[alternative HTML version
deleted]]

______________________________________________
R-help at r-project.org
mailing list -- To UNSUBSCRIBE and more,
see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting
guide http://www.R-project.org/posting-guide.html
and provide commented,
minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From peterenos at ymail.com  Fri Jun 26 11:27:38 2015
From: peterenos at ymail.com (Peter Tuju)
Date: Fri, 26 Jun 2015 09:27:38 +0000 (UTC)
Subject: [R] Extracting data from a file containing data
In-Reply-To: <CAAxdm-5N1Ebjy-jysXWPjDuTarCnc2BTEN218zm5Nyd7on1tvA@mail.gmail.com>
References: <CAAxdm-5N1Ebjy-jysXWPjDuTarCnc2BTEN218zm5Nyd7on1tvA@mail.gmail.com>
Message-ID: <1521656228.235174.1435310859067.JavaMail.yahoo@mail.yahoo.com>

Dear Jim Holtman,
Thank you very much for your help. 
Theproblem I'm trying to solve is ?To determine weather the evolutionof ENSO can influence rainfall over Tanzania?. In this study I havetwo types of data, ie Rainfall data (for 23 stations) and Ninoindices data, both spanning a period of 31 years (1982-2012). 
CASEI:1.In ?Nino.indices.txt? data for all columns of the ninoregions (both for anomalies and SST), to calculate the Season means"January & February (JF)", ?March, April and may(MAM)", "June, July & August (JJA)" and "October,November and December (OND" for each year. and have the outputin table form as;
Ninoindices Mean
|  Years  |  JF SST Mean NINO1+2  |  JF ANOM Mean NINO1+2  |  MAM SST Mean NINO3  |  MAM ANOM Mean NINO3  |  JJA SST Mean NINO4  |  JJA ANOM Mean NINO4  |  OND SST Mean NINO3.4  |  OND SST Mean NINO3.4  |
|  1982  |  
   |  
   |  
   |  
   |  
   |  
   |  
   |  
   |
|  1983  |  
   |  
   |  
   |  
   |  
   |  
   |  
   |  
   |
|  - - - -  |  
   |  
   |  
   |  
   |  
   |  
   |  
   |  
   |
|  - - - -    |  
   |  
   |  
   |  
   |  
   |  
   |  
   |  
   |
|   2012  |  
   |  
   |  
   |  
   |  
   |  
   |  
   |  
   |


2.To use the Yearly anomalies for each column in nino regions toclassify the events as;(i). IfANOM Mean>1, then I assign itto ?SE? (Being as Strong El-nino)(ii). If0<ANOMMean<=1 , then Iassign it to ?ME? (Being as Moderate El-nino)(iii). IfANOM==0,then I assign it to ?NT? (Being as NeutralCondition)(iv). If ANOMMean< (-1),then I assign it to ?SL? (Being as Strong La-nina)(v). If-1<=ANOMMean< 0, then I assign it to ?ML? (Being as Moderate La-nina)Theoutput have to be in table form as;
FORNINO1+2
|  Years  |  JF ANOM Mean NINO1+2  |  MAM ANOM Mean NINO1+2  |  JJA ANOM Mean NINO1+2  |  OND SST Mean NINO1+2  |
|  1982    |  SE    |  
   |  
   |  
   |
|  1983  |  
   |  
   |  SL  |  
   |
|  - - - -  |  
   |  
   |  
   |  ML  |
|  - - - -  |  
   |  ME  |  
   |  
   |
|  2012  |  
   |  
   |  
   |   SL  |


FORNINO3
|  Years  |  JF ANOM Mean NINO3  |  MAM ANOM Mean NINO3  |  JJA ANOM Mean NINO3  |  OND SST Mean NINO3  |
|  1982    |  SE    |  
   |  
   |  
   |
|  1983  |  
   |  
   |  
   |  
   |
|  - - - -  |  
   |  
   |  
   |  
   |
|  - - - -  |  
   |  ME  |  
   |  
   |
|  2012  |  
   |  
   |  
   |   SL  |


FORNINO4
|  Years  |  JF ANOM Mean NINO4  |  MAM ANOM Mean NINO4  |  JJA ANOM Mean NINO4  |  OND SST Mean NINO4  |
|  1982    |  SE    |  
   |  
   |  
   |
|  1983  |  
   |  
   |  
   |  
   |
|  - - - -  |  ML  |  
   |  
   |  SL  |
|  - - - -  |  
   |  ME  |  
   |  
   |
|  2012  |  
   |  
   |  
   |   SL  |



FORNINO3.4
|  Years  |  JF ANOM Mean NINO3.4  |  MAM ANOM Mean NINO3.4  |  JJA ANOM Mean NINO3.4  |  OND SST Mean NINO3.4  |
|  1982    |  SE    |  SL  |  
   |  
   |
|  1983  |  
   |  
   |  
   |  
   |
|  - - - -  |  
   |  
   |  ML  |  
   |
|  - - - -  |  
   |  ME  |  
   |  
   |
|  2012  |  
   |  
   |  
   |   SL  |



3.To plot the time series graph for each nino regions using the YearlyAnomalies.

CASEII:Consider the Rainfall station data;1. In some files containing the data there are missing data labeledby variable ?m?. I want to substitute these missing data withlong term mean.2. Find the rowSum and anomalies of each file containing the data.3. To find the cumsum of the rowSum of each file containing the data.4. Plot the single mass curves ie. Plot(Year, cumsum) for each fileand name its title as the name of the corresponding file name.5. Plot the time series graphs for seasons JF, MAM, JJA and OND foreach file and name give its name as ?Time series graph for ?nameof the file??6. To find the seasonal correlations for JF, MAM, JJA and OND usingthe anomalies of the rainfall station data and that of each ninoregion indices, and have the results in table form as;
CORRELATIONSOF RAINFALL AND NINO1+2 ANOMALIES
|  Years  |  JF  |  MAM  |  JJA  |  OND  |
|  1982    |  
   |  
   |  
   |  
   |
|  1983  |  
   |  
   |  
   |  
   |
|  - - - -  |  
   |  
   |  
   |  
   |
|  - - - -  |  
   |  
   |  
   |  
   |
|  2012  |  
   |  
   |  
   |  
   |


CORRELATIONSOF RAINFALL AND NINO3ANOMALIES
|  Years  |  JF  |  MAM  |  JJA  |  OND  |
|  1982    |  
   |  
   |  
   |  
   |
|  1983  |  
   |  
   |  
   |  
   |
|  - - - -  |  
   |  
   |  
   |  
   |
|  - - - -  |  
   |  
   |  
   |  
   |
|  2012  |  
   |  
   |  
   |  
   |


CORRELATIONSOF RAINFALL AND NINO4ANOMALIES
|  Years  |  JF  |  MAM  |  JJA  |  OND  |
|  1982    |  
   |  
   |  
   |  
   |
|  1983  |  
   |  
   |  
   |  
   |
|  - - - -  |  
   |  
   |  
   |  
   |
|  - - - -  |  
   |  
   |  
   |  
   |
|  2012  |  
   |  
   |  
   |  
   |



CORRELATIONSOF RAINFALL AND NINO3.4ANOMALIES
|  Years  |  JF  |  MAM  |  JJA  |  OND  |
|  1982    |  
   |  
   |  
   |  
   |
|  1983  |  
   |  
   |  
   |  
   |
|  - - - -  |  
   |  
   |  
   |  
   |
|  - - - -  |  
   |  
   |  
   |  
   |
|  2012  |  
   |  
   |  
   |  
   |


?Please find attached the data to be used in this analysis. Hopefully you will help.
_____________
Peter? E. Tuju
Dar es Salaam
T A N Z A N I A
----------------------
      From: jim holtman <jholtman at gmail.com>
 To: Peter Tuju <peterenos at ymail.com> 
Cc: "r-help at r-project.org" <r-help at r-project.org> 
 Sent: Thursday, June 25, 2015 10:12 PM
 Subject: Re: [R] Extracting data from a file containing data
   
try this:
> input <- read.table("C:\\Users\\jh52822\\Downloads\\Nino_indices.txt" ??+ ? ? ? ? ? ? ? ? ? ? , header = TRUE+ ? ? ? ? ? ? ? ? ? ? , as.is = TRUE+ ? ? ? ? ? ? ? ? ? ? )> # create factors> input$season <- factor(c(rep("JF", 2), rep("MAM", 3), rep("JJA", 3)+ ? ? ? ? , NA, rep("OND", 3)+ ? ? ? ? )[input$MON], levels = c("JF", "MAM", "JJA", "OND"))> ? ? ? ??> # leave off the MON (-2) column from the data ? ? ? ? ? ?> res <- aggregate(. ~ season + YR, data = input[, -2], FUN = 'mean')> head(res,10)? ?season ? YR ?NINO1.2 ? ? ? ANOM ? ?NINO3 ? ? ANOM.1 ? ?NINO4 ? ? ANOM.2 ?NINO3.4 ? ? ANOM.31 ? ? ?JF 1982 24.89000 -0.3750000 26.12500 ?0.1250000 28.25500 ?0.0550000 26.71000 ?0.06500002 ? ? MAM 1982 24.56000 -0.8366667 27.48333 ?0.2433333 28.94000 ?0.4466667 27.92000 ?0.30333333 ? ? JJA 1982 22.37000 ?0.6800000 26.68333 ?1.0033333 29.39333 ?0.6200000 28.26000 ?1.03000004 ? ? OND 1982 24.55333 ?2.8200000 27.70667 ?2.6933333 29.25333 ?0.6600000 28.88667 ?2.25000005 ? ? ?JF 1983 27.75500 ?2.4900000 28.92000 ?2.9200000 28.89500 ?0.6950000 29.24500 ?2.60000006 ? ? MAM 1983 28.47667 ?3.0800000 29.06333 ?1.8233333 28.89667 ?0.4033333 28.94333 ?1.32666677 ? ? JJA 1983 25.72333 ?4.0333333 26.88000 ?1.2000000 28.63667 -0.1366667 27.28000 ?0.05000008 ? ? OND 1983 22.25667 ?0.5233333 24.40667 -0.6066667 27.77667 -0.8166667 25.68000 -0.95666679 ? ? ?JF 1984 24.68000 -0.5850000 25.52000 -0.4800000 27.44500 -0.7550000 26.01500 -0.630000010 ? ?MAM 1984 24.79667 -0.6000000 26.97333 -0.2666667 27.62000 -0.8733333 27.21333 -0.4033333>?


Jim Holtman
Data Munger Guru
?
What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Thu, Jun 25, 2015 at 11:40 AM, Peter Tuju <peterenos at ymail.com> wrote:

I have the data as attached. For each nino region, I want to get the mean of the seasons January and February (JF), March, April and may (MAM), June, July and August (JJA), and October, November and December (OND) as columns of each nino regions. and have my result as;For example;
For NINO1.2Years???? JF????? MAMA???? JJA????? OND?1982?1983??? .??? .???? .2012
Any guide please!


_____________
Peter? E. Tuju
Dar es Salaam
T A N Z A N I A
----------------------
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




  
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Nino_indices.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150626/975d53c4/attachment.txt>

From dwinsemius at comcast.net  Fri Jun 26 16:31:26 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 26 Jun 2015 07:31:26 -0700
Subject: [R] 'class(.) == **' [was 'Call to a function']
In-Reply-To: <558CF6B2.9070200@gmail.com>
References: <5589D070.4070900@gmail.com> <5589D219.5070001@gmail.com>
	<CAJ4QxaNuMjXbRwDafabHTN1iDT95+ZS0mhdJsrGfRqnskR0JMQ@mail.gmail.com>
	<5589ED9F.7020801@gmail.com>
	<CCE952776B6679469977532BD863C39CB2B11745@Patterson.autuni.aut.ac.nz>
	<21898.23129.223595.340119@stat.math.ethz.ch>
	<558CBD74.7050705@gmail.com>
	<AAAB00B7-5474-404B-83E0-9EB8C4AA14E2@comcast.net>
	<558CF6B2.9070200@gmail.com>
Message-ID: <7CF90089-3A13-419A-85F4-3AE9A3743037@comcast.net>


On Jun 25, 2015, at 11:52 PM, Steven Yen wrote:

> Thanks Davis. But actually, the line is legitimate:

I didn't say it was illegitimate, only confusing.

> 
>   if (inherits(wt,what="character")) wt<-data[,wt]

What you are asking for is known in R as non-standard evaluation. Examples include the library and help functions. About a page and a half down the code for `help`, you see this line, following a tryCatch test to see if the argument is character:

  stopic <- deparse(substitute(topic))

That returns a character value from a symbol. About three pages inside the code for `library` you also see this after a test for 'character'-ness:

  package <- as.character(substitute(package))

-- 
David.


> 
> because, coming down with wt being characters, the part wt<-data[,wt] then picks up variables data$wt. The call
> 
>   wmean(mydata,wt="weight")
> 
> actually goes OK. I was hoping to figure out a way to fix the wmean routine some how so that I can call with
> 
>   wmean(mydata,wt=weight)
> 
> Good to know there is a better way to initialize the vector Mean and and a better list command. Thank you!
> 
> On 6/26/2015 2:39 AM, David Winsemius wrote:
>> 
>> On Jun 25, 2015, at 7:48 PM, Steven Yen wrote:
>> 
>>> Thanks to all for the help. I have learned much about "inherit" and "class". I like to know about one additional option, and that is to use a calling parameter without the quotation marks, similar to the linear regression syntax:
>>> 
>>> lm(data=mydata,weights=wt)
>>> 
>>> Below is a simple set of codes to calculate weighted means with generated data in data frame "mydata". As annotated below, I like the following call to work (without the quotations):
>>> 
>>> wmean(mydata,wt=weight)
>> 
>> Let's start with the call. If you are to execute this,  then names `mydata` and `weight` each must have a value.
>> 
>>> 
>>> Thank you!
>>> ----
>>> 
>>> mydata<-matrix(1:20,ncol=2)
>> 
>> OK. There is a value having been assigned to `mydata`
>> 
>>> mydata<-cbind(mydata,runif(10,0,1))
>> 
>> And now augmented.
>> 
>>> colnames(mydata)<-c("y","x","weight")
>> 
>> And a names attribute added for its columns.
>> 
>>> mydata<-as.data.frame(mydata)
>>> 
>>> wmean <- function(data,wt){
>>>  if (inherits(wt,what="character")) wt<-data[,wt]
>>>  wt<-wt/mean(wt)
>> 
>> Here's the problem. If `wt` was of mode "character", then you cannot divide it by a number, since the RHS will be evaluated first. You really should read the error messages!
>> 
>> Perhaps you meant:
>> 
>> wt <-  data[, wt]/mean(data[ , wt]
>> 
>> But if you did, then it's rather confusing (but possible) to assign the value to the same name as the column of the matrix.
>> 
>> 
>>>  Mean<-NULL
>> 
>> Why do that? If you remove it from the workspace then you cannot assign a value using indexed assignment as you apparently intend to do. Should have been
>> 
>> Mean <- numeric( ncol(data) )
>> 
>> 
>>>  for (i in 1:ncol(data)){
>>>    Mean[i] <- sum(data[,i]*wt)/sum(wt)
>> 
>> There is a bit of a confusion here. `wt` started out as a character value. I guess you could do this.
>> 
>>>  }
>>>  list("Mean: ",Mean)
>> 
>> Wrong syntax for lists. Suspect you want 	
>> 
>>    list(Mean=Mean)
>> 
>> 
>>> }
>>> wmean(mydata,wt="weight") # This works
>>> wmean(mydata,wt=weight)   # <= Like this to work
>> 
>> So were you planning to execute this first?
>> 
>> weight="weight" #?
>> 
> 
> -- 
> Steven Yen
> My e-mail alert:
> https://youtu.be/9UwEAruhyhY?list=PLpwR3gb9OGHP1BzgVuO9iIDdogVOijCtO

David Winsemius
Alameda, CA, USA


From davies.trevor at gmail.com  Fri Jun 26 18:16:57 2015
From: davies.trevor at gmail.com (Trevor Davies)
Date: Fri, 26 Jun 2015 09:16:57 -0700
Subject: [R] Fread: add one to skip string identifier
Message-ID: <CAJhyqVhXDFuhrUrL3LTo4mMC-dLUD-0ObwbK071VtAO1hQMr9w@mail.gmail.com>

I'm trying to read in a file using the function fread.

The file that I'm trying to read in has about 100 lines of information I
don't want prior to getting to my matrix of data that I do want.  On the
line prior to the data I want there is always a string identifier "*end*"

The following fread call:

impcoord <- fread('H:/SBE19plus_01907535_2015_06_17_0093.cnv',skip="*END*")

almost gets me there but it starts reading AT *END* and I'd like to have it
start the line after.  I can't figure out how to make this work.

I know I could have a two step function where I have a function scan the
file to Identify the line that has *END* but I thought I could just do it
with one fread() call.

thanks for the help.
Trevor

	[[alternative HTML version deleted]]


From y.nacht at bluewin.ch  Fri Jun 26 15:09:24 2015
From: y.nacht at bluewin.ch (ritschko)
Date: Fri, 26 Jun 2015 06:09:24 -0700 (PDT)
Subject: [R] large dummy-variable set in R
In-Reply-To: <1418737786635-4700833.post@n4.nabble.com>
References: <1418737786635-4700833.post@n4.nabble.com>
Message-ID: <1435324164933-4709112.post@n4.nabble.com>

Hey! Have you ever found a solution to your problem? I have exactly the same
issue.

Best



--
View this message in context: http://r.789695.n4.nabble.com/large-dummy-variable-set-in-R-tp4700833p4709112.html
Sent from the R help mailing list archive at Nabble.com.


From sarah.goslee at gmail.com  Fri Jun 26 19:14:52 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 26 Jun 2015 13:14:52 -0400
Subject: [R] large dummy-variable set in R
In-Reply-To: <1435324164933-4709112.post@n4.nabble.com>
References: <1418737786635-4700833.post@n4.nabble.com>
	<1435324164933-4709112.post@n4.nabble.com>
Message-ID: <CAM_vjunGzAF5DcgSya77CrrjBv=1yxnwvOshmSjrkrJL5PdHNA@mail.gmail.com>

Guess what?

On Fri, Jun 26, 2015 at 9:09 AM, ritschko <y.nacht at bluewin.ch> wrote:
> Hey! Have you ever found a solution to your problem? I have exactly the same
> issue.
>
> Best
>

The people who read the R-help email list have exactly zero idea what
you're talking about.

The above is all that shows up on the mailing list if you reply on
Nabble without including any context. Nabble has nothing whatsoever
officially to do with the email list. (It's also customary to sign
your emails, so we can call you something besides "hey you".)

So if you'd like help with an R problem, you'd be best served by
subscribing to the email list, and posting a reproducible example that
describes what you did and what you've tried, with sample data for
potential answerers to use.

Without a reproducible example that includes some sample data (fake is
fine), the code you used, and some clear idea of what output you
expect, it's impossible to figure out how to help you. Here are some
suggestions for creating a good reproducible example:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

The R-help posting guide may also be useful:
http://www.r-project.org/posting-guide.html

Sarah
-- 
Sarah Goslee
http://www.functionaldiversity.org


From kate.ignatius at gmail.com  Fri Jun 26 19:32:30 2015
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Fri, 26 Jun 2015 13:32:30 -0400
Subject: [R] Error: unexpected symbol in [with read.table]
Message-ID: <CAE6QMsZCLHSS68TG8j1wS4ujQbTdJwtqwCqjB7zvS_7PyW7UCg@mail.gmail.com>

When reading in a tab delimited file using args I keep getting the error:

Error: unexpected symbol in "Name index"

Execution halted

The code is this:

a <- read.table(args[1],sep="\t",header=T, stringsAsFactors=F)

When inputting the file directly, as follows, this produces no errors:

a <- read.table("/path/to/file/filename.txt", header=T,sep="\t",
stringsAsFactors=F).

The file is such:

Name               index
Bob                  1
George             2
Dave                3
Eric                  4
.
.
.
.
Andrew            20

Is there anything I should be looking out for that might be producing
this error.   Any help will be greatly appreciated.


From bgunter.4567 at gmail.com  Fri Jun 26 19:39:25 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 26 Jun 2015 10:39:25 -0700
Subject: [R] Error: unexpected symbol in [with read.table]
In-Reply-To: <CAE6QMsZCLHSS68TG8j1wS4ujQbTdJwtqwCqjB7zvS_7PyW7UCg@mail.gmail.com>
References: <CAE6QMsZCLHSS68TG8j1wS4ujQbTdJwtqwCqjB7zvS_7PyW7UCg@mail.gmail.com>
Message-ID: <CAGxFJbS03EnYWBkgdNYqppSTx8no9rxr9Z4Nz-FZ3Ewk=1zydw@mail.gmail.com>

??
Are you expecting us to guess what your code was from

"reading in a tab delimited file using args" ?

You've posted here before and should know by now that explicit code
should be provided whenever possible.


Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Fri, Jun 26, 2015 at 10:32 AM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
> When reading in a tab delimited file using args I keep getting the error:
>
> Error: unexpected symbol in "Name index"
>
> Execution halted
>
> The code is this:
>
> a <- read.table(args[1],sep="\t",header=T, stringsAsFactors=F)
>
> When inputting the file directly, as follows, this produces no errors:
>
> a <- read.table("/path/to/file/filename.txt", header=T,sep="\t",
> stringsAsFactors=F).
>
> The file is such:
>
> Name               index
> Bob                  1
> George             2
> Dave                3
> Eric                  4
> .
> .
> .
> .
> Andrew            20
>
> Is there anything I should be looking out for that might be producing
> this error.   Any help will be greatly appreciated.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From shidaxia at yahoo.com  Fri Jun 26 19:55:41 2015
From: shidaxia at yahoo.com (Shi, Tao)
Date: Fri, 26 Jun 2015 17:55:41 +0000 (UTC)
Subject: [R] how to change the "ff" properties of a "ff"-related R
 object after the original "ff" output folder has been moved
In-Reply-To: <100F322A-507D-4417-B0AA-A19A1381FCBE@comcast.net>
References: <100F322A-507D-4417-B0AA-A19A1381FCBE@comcast.net>
Message-ID: <487686033.45186.1435341341473.JavaMail.yahoo@mail.yahoo.com>

Hi David,
Normally, I would have a R code example for this, but since I'm new to this too and just didn't have time to do that. ?Hopefully, Jen's code illustrates the problem.
Tao
 


     On Thursday, June 25, 2015 8:53 PM, David Winsemius <dwinsemius at comcast.net> wrote:
   

 
On Jun 25, 2015, at 4:04 PM, Shi, Tao via R-help wrote:

> Hi all,
> 
> I'm new to "ff" package through the using Bioconductor package "crlmm".? Here is my problem:
> 
> I've created a few R objects (e.g. an CNSet) using crlmm based on my data and save them in a .RData file.? crlmm heavily uses ff package to store results on a local folder.? For certain reasons, I have moved the ff output folder to somewhere else.? Now when I go back to R, I can't open those CNSet, for example, anymore, as the file has a property still storing the old ff output folder path. 
> 
> My question is: is there a quick way to change these paths to the new one, so I don't have to re-run the own analysis.
> 

The way to approach this is to create a small example that illustrates teh problem. In many case all will becove clear, but if not then you will have something that you can then post ... IN R CODE ... that will let us (most of whom are not ff-urers) see the problem.

--
David Winsemius
Alameda, CA, USA


  
	[[alternative HTML version deleted]]


From shidaxia at yahoo.com  Fri Jun 26 20:01:38 2015
From: shidaxia at yahoo.com (Shi, Tao)
Date: Fri, 26 Jun 2015 18:01:38 +0000 (UTC)
Subject: [R] how to change the "ff" properties of a "ff"-related R
 object after the original "ff" output folder has been moved
In-Reply-To: <558D2A01.1070008@truecluster.com>
References: <558D2A01.1070008@truecluster.com>
Message-ID: <361243432.453917.1435341698590.JavaMail.yahoo@mail.yahoo.com>

Hi Jens,
Thanks for the example! ?I can see that you can change the 'filename' attribute for a ff object one-by-one, but is there a way to issue one command that will automatically change the attribute to all the ff objects in your workspace, as you can imagine when I have large number of objects like this, doing one-by-one is cumbersome? ?After all, all it needs to change is the folder path, right?
May be this is a too wishful thinking :-)
Best,
Tao
 


     On Friday, June 26, 2015 3:31 AM, Jens Oehlschl?gel <Jens.Oehlschlaegel at truecluster.com> wrote:
   

 Tao,

I do assume that the ff-files are still at some location and not deleted 
by a finalizer. The following explains how to manipulate file locations 
with ff and ffdf objects.

Kind regards
jens

library(ff)
path1 <- "c:/tmp"
path2 <- "c:/tmp2"
# create ffdf,
# using non-standard path sets finalizer to 'close' instead of 'delete'
fdf1 <- as.ffdf(iris, col_args=list(pattern=file.path(path1,"iris")))
# let's copy the old metadata (but not the files, useclone for that)
# using ffs hybrid copying semantics
fdf2 <- fdf1
# note both are open
is.open(fdf1)
is.open(fdf2)
# close the files
close(fdf1)
# and note that
is.open(fdf1)
is.open(fdf2)
# the magic has kept physical metadata in synch even in the copy
# (virtual metadata is not kept in synch
# which allows different virtual views into the same files
# not unlike SQL VIEWs virtualize dastabase TABLEs)

# filename on a ffdf
filename(fdf2)
# is a shortcut for
lapply(physical(fdf2), filename)
# so filename is a physical attribute
# actually moving the files can be done with the filename<- method
lapply(physical(fdf2), function(x)filename(x) <- sub(path1, path2, 
filename(x)))
# check this
filename(fdf1)
filename(fdf2)

# filename on ff
filename(fdf1$Species)
# is a shortcut for
attr(attr(fdf1$Species, "physical"), "filename")
# and if you directly manipulate this attribute
# you circummvent the filename method
# and the file itself will not be moved
attr(attr(fdf1$Species, "physical"), "filename") <- sub(path2, path1, 
filename(fdf1$Species))
# now the metadata points to a different location
filename(fdf1$Species)
# note that this physical attribute was also changed
# for the copy
filename(fdf2$Species)
# of course you can fix the erroneous metadata by
attr(attr(fdf1$Species, "physical"), "filename") <- sub(path1, path2, 
filename(fdf1$Species))
# or for all columns in a ffdf by
lapply(physical(fdf2), function(x)attr(attr(x, "physical"), "filename") 
<- sub(path2, path1, filename(x)))
# now we have your situation with broken metadata
open(fdf2)
# and can fix that by
lapply(physical(fdf2), function(x)attr(attr(x, "physical"), "filename") 
<- sub(path1, path2, filename(x)))
# check
open(fdf2)



Am 26.06.2015 um 01:04 schrieb Shi, Tao:
> Hi all,
>
> I'm new to "ff" package through the using Bioconductor package "crlmm".? Here is my problem:
>
> I've created a few R objects (e.g. an CNSet) using crlmm based on my data and save them in a .RData file.? crlmm heavily uses ff package to store results on a local folder.? For certain reasons, I have moved the ff output folder to somewhere else.? Now when I go back to R, I can't open those CNSet, for example, anymore, as the file has a property still storing the old ff output folder path.
>
> My question is: is there a quick way to change these paths to the new one, so I don't have to re-run the own analysis.
>
> Many thanks!
>
> Tao
>


  
	[[alternative HTML version deleted]]


From lid.zigh at gmail.com  Fri Jun 26 20:11:20 2015
From: lid.zigh at gmail.com (Lida Zeighami)
Date: Fri, 26 Jun 2015 13:11:20 -0500
Subject: [R] question
Message-ID: <CAMqbV1DwyM3-0MidHu5OAfgA+gRuuUD0eqgLmdf6Ov9VgeMHFw@mail.gmail.com>

Hi there,

I have a matrix (n*m) which rows including 0,1,2
I want to know the frequency of each elements (0 , 1 , 2) separately for
each row!
for example :

     1    2    3   4    5    6     7

A   0     1   1    0     2    2    2
B   1     1   1    2    0    0     2
C   2    1   1    0     0    0    2
D   1     1   0    0    0    2     2
E   0     2   1    1     2    2    2

I want to this output:

     1    2    3   4    5    6     7         fr0
fr1               fr2

A   0     1   1    0     2    2    2           2                  2
     3
B   1     1   1    2    0    0     2           3
2             2
C   2    1   1    0     0    0     2          3                   2
     2
D   1     1   0    0    0    2     2           2                  3
        2
E   0     2   1    1     2    2    2           1
2            4

Thanks

	[[alternative HTML version deleted]]


From rshepard at appl-ecosys.com  Fri Jun 26 20:44:39 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Fri, 26 Jun 2015 11:44:39 -0700 (PDT)
Subject: [R] Formatting YYYY-MM after reading text file
Message-ID: <alpine.LNX.2.11.1506261135450.9979@localhost>

   Data file 'example.dat' has this format:

stream,sampdate,param,quant
B,1992-03,Cl,4
B,1992-03,SO4,33
B,1992-03,pH,8.43
B,1992-04,Cl,4
B,1992-04,SO4,32
B,1992-04,pH,8.46
B,1992-05,Cl,4
B,1992-05,SO4,31
B,1992-05,pH,8.43

   It's read into R with
allchem <- read.table('example.dat', stringsAsFactors=F, header=T, sep=',')

and yields this structure:

str(allchem)
'data.frame':	2226 obs. of  4 variables:
  $ stream  : chr  "B" "B" "B" "B" ...
  $ sampdate: chr  "1992-03" "1992-03" "1992-03" "1992-04" ...
  $ param   : chr  "Cl" "SO4" "pH" "Cl" ...
  $ quant   : num  4 33 8.43 4 32 8.46 4 31 8.43 6 ...

   Because the date field contains year and month but no day, as.Date() does
not work. ?as.Date displays the help file for yearmon in package 'zoo.'
Reading this lead me to try:

allchem$sampdate <- as.yearmon(format(%Y-%m))allchem$sampdate

which produces the error, Error: unexpected SPECIAL in "allchem$sampdate <-
as.yearmon(format(%Y-%".

   I do not see the proper syntax to change the sampdate char string to
year-month dates. Advice appreciated.

Rich


From bgunter.4567 at gmail.com  Fri Jun 26 20:54:44 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 26 Jun 2015 11:54:44 -0700
Subject: [R] Error: unexpected symbol in [with read.table]
In-Reply-To: <CAE6QMsZ1TiNz4twE-Ru0vrpA3cY6J6Jn1_9DVZtvHBGQwduM+A@mail.gmail.com>
References: <CAE6QMsZCLHSS68TG8j1wS4ujQbTdJwtqwCqjB7zvS_7PyW7UCg@mail.gmail.com>
	<CAGxFJbS03EnYWBkgdNYqppSTx8no9rxr9Z4Nz-FZ3Ewk=1zydw@mail.gmail.com>
	<CAE6QMsZ1TiNz4twE-Ru0vrpA3cY6J6Jn1_9DVZtvHBGQwduM+A@mail.gmail.com>
Message-ID: <CAGxFJbQUzS85T8DVi9doCLZg8x0rxScTjD5j-dEnSUENykteRQ@mail.gmail.com>

... and you should also know by now to cc the list and not respond just to me!
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Fri, Jun 26, 2015 at 10:58 AM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
> "reading in a tab delimited file using args"
>
> What I mean by that is that I'm using a bash script to call in an R
> script and using the command: args <- commandArgs(TRUE) in my R
> script.
>
> In my shell script I'm calling the R program as follows:
> /path/to/R/R-3.0.2/bin/Rscript
>
> I'm not sure if that will help - sure you will all know if it doesn't.
>
> K.
>
> On Fri, Jun 26, 2015 at 1:39 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> ??
>> Are you expecting us to guess what your code was from
>>
>> "reading in a tab delimited file using args" ?
>>
>> You've posted here before and should know by now that explicit code
>> should be provided whenever possible.
>>
>>
>> Cheers,
>> Bert
>> Bert Gunter
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>>    -- Clifford Stoll
>>
>>
>> On Fri, Jun 26, 2015 at 10:32 AM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>>> When reading in a tab delimited file using args I keep getting the error:
>>>
>>> Error: unexpected symbol in "Name index"
>>>
>>> Execution halted
>>>
>>> The code is this:
>>>
>>> a <- read.table(args[1],sep="\t",header=T, stringsAsFactors=F)
>>>
>>> When inputting the file directly, as follows, this produces no errors:
>>>
>>> a <- read.table("/path/to/file/filename.txt", header=T,sep="\t",
>>> stringsAsFactors=F).
>>>
>>> The file is such:
>>>
>>> Name               index
>>> Bob                  1
>>> George             2
>>> Dave                3
>>> Eric                  4
>>> .
>>> .
>>> .
>>> .
>>> Andrew            20
>>>
>>> Is there anything I should be looking out for that might be producing
>>> this error.   Any help will be greatly appreciated.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From rshepard at appl-ecosys.com  Fri Jun 26 21:04:06 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Fri, 26 Jun 2015 12:04:06 -0700 (PDT)
Subject: [R] Formatting YYYY-MM after reading text file [RESOLVED]
In-Reply-To: <alpine.LNX.2.11.1506261135450.9979@localhost>
References: <alpine.LNX.2.11.1506261135450.9979@localhost>
Message-ID: <alpine.LNX.2.11.1506261159410.9979@localhost>

On Fri, 26 Jun 2015, Rich Shepard wrote:

> allchem$sampdate <- as.yearmon(format(%Y-%m))allchem$sampdate

   Reading the yearmon help page again led me to try
 	allchem$sampdate <- as.yearmon(allchem$sampdate)
which produces the following structure:

'data.frame':	2226 obs. of  4 variables:
  $ stream  : chr  "B" "B" "B" "B" ...
  $ sampdate:Class 'yearmon'  num [1:2226] 1992 1992 1992 1992 1992 ...
  $ param   : chr  "Cl" "SO4" "pH" "Cl" ...
  $ quant   : num  4 33 8.43 4 32 8.46 4 31 8.43 6 ...

which appears to do what's needed:

allchem
      stream sampdate param    quant
1         B Mar 1992    Cl    4.000
2         B Mar 1992   SO4   33.000
3         B Mar 1992    pH    8.430
4         B Apr 1992    Cl    4.000
5         B Apr 1992   SO4   32.000
6         B Apr 1992    pH    8.460
7         B May 1992    Cl    4.000
8         B May 1992   SO4   31.000
9         B May 1992    pH    8.430
10        B Jun 1992    Cl    6.000

   Not having before worked with dates like this I'll soon see what happens
as the analyses proceed.

Rich


From dcarlson at tamu.edu  Fri Jun 26 21:19:41 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 26 Jun 2015 19:19:41 +0000
Subject: [R] question
In-Reply-To: <CAMqbV1DwyM3-0MidHu5OAfgA+gRuuUD0eqgLmdf6Ov9VgeMHFw@mail.gmail.com>
References: <CAMqbV1DwyM3-0MidHu5OAfgA+gRuuUD0eqgLmdf6Ov9VgeMHFw@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D69EA02@mb02.ads.tamu.edu>

Don't use html formatting in your emails and use dput() to provide data. Assuming your matrix is called mat:

> mat <- structure(c(0L, 1L, 2L, 1L, 0L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 
0L, 1L, 0L, 2L, 0L, 0L, 1L, 2L, 0L, 0L, 0L, 2L, 2L, 0L, 0L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L), .Dim = c(5L, 7L), .Dimnames = list(c("A", 
"B", "C", "D", "E"), c("1", "2", "3", "4", "5", "6", "7")))
> mat
  1 2 3 4 5 6 7
A 0 1 1 0 2 2 2
B 1 1 1 2 0 0 2
C 2 1 1 0 0 0 2
D 1 1 0 0 0 2 2
E 0 2 1 1 2 2 2
> tbl <- t(apply(mat, 1, table))
> colnames(tbl) <- paste0("fre", 0:2)
> tbl
  fre0 fre1 fre2
A    2    2    3
B    2    3    2
C    3    2    2
D    3    2    2
E    1    2    4
> matbl <- cbind(mat, tbl)
> matbl
  1 2 3 4 5 6 7 fre0 fre1 fre2
A 0 1 1 0 2 2 2    2    2    3
B 1 1 1 2 0 0 2    2    3    2
C 2 1 1 0 0 0 2    3    2    2
D 1 1 0 0 0 2 2    3    2    2
E 0 2 1 1 2 2 2    1    2    4

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Lida Zeighami
Sent: Friday, June 26, 2015 1:11 PM
To: r-help at r-project.org
Subject: [R] question

Hi there,

I have a matrix (n*m) which rows including 0,1,2
I want to know the frequency of each elements (0 , 1 , 2) separately for
each row!
for example :

     1    2    3   4    5    6     7

A   0     1   1    0     2    2    2
B   1     1   1    2    0    0     2
C   2    1   1    0     0    0    2
D   1     1   0    0    0    2     2
E   0     2   1    1     2    2    2

I want to this output:

     1    2    3   4    5    6     7         fr0
fr1               fr2

A   0     1   1    0     2    2    2           2                  2
     3
B   1     1   1    2    0    0     2           3
2             2
C   2    1   1    0     0    0     2          3                   2
     2
D   1     1   0    0    0    2     2           2                  3
        2
E   0     2   1    1     2    2    2           1
2            4

Thanks

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dnbarron at gmail.com  Fri Jun 26 21:33:16 2015
From: dnbarron at gmail.com (David Barron)
Date: Fri, 26 Jun 2015 20:33:16 +0100
Subject: [R] Formatting YYYY-MM after reading text file
In-Reply-To: <alpine.LNX.2.11.1506261135450.9979@localhost>
References: <alpine.LNX.2.11.1506261135450.9979@localhost>
Message-ID: <CAHuze_KQ=p0W43McGdEXc1aR72J-G+N3J8RQ3-Ed6VXGW1qzBA@mail.gmail.com>

as.yearmon(allchem$sampdate)

worked for me.

David

On 26 June 2015 at 19:44, Rich Shepard <rshepard at appl-ecosys.com> wrote:
>   Data file 'example.dat' has this format:
>
> stream,sampdate,param,quant
> B,1992-03,Cl,4
> B,1992-03,SO4,33
> B,1992-03,pH,8.43
> B,1992-04,Cl,4
> B,1992-04,SO4,32
> B,1992-04,pH,8.46
> B,1992-05,Cl,4
> B,1992-05,SO4,31
> B,1992-05,pH,8.43
>
>   It's read into R with
> allchem <- read.table('example.dat', stringsAsFactors=F, header=T, sep=',')
>
> and yields this structure:
>
> str(allchem)
> 'data.frame':   2226 obs. of  4 variables:
>  $ stream  : chr  "B" "B" "B" "B" ...
>  $ sampdate: chr  "1992-03" "1992-03" "1992-03" "1992-04" ...
>  $ param   : chr  "Cl" "SO4" "pH" "Cl" ...
>  $ quant   : num  4 33 8.43 4 32 8.46 4 31 8.43 6 ...
>
>   Because the date field contains year and month but no day, as.Date() does
> not work. ?as.Date displays the help file for yearmon in package 'zoo.'
> Reading this lead me to try:
>
> allchem$sampdate <- as.yearmon(format(%Y-%m))allchem$sampdate
>
> which produces the error, Error: unexpected SPECIAL in "allchem$sampdate <-
> as.yearmon(format(%Y-%".
>
>   I do not see the proper syntax to change the sampdate char string to
> year-month dates. Advice appreciated.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Jun 26 21:44:46 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 26 Jun 2015 12:44:46 -0700
Subject: [R] large dummy-variable set in R
In-Reply-To: <CAM_vjunGzAF5DcgSya77CrrjBv=1yxnwvOshmSjrkrJL5PdHNA@mail.gmail.com>
References: <1418737786635-4700833.post@n4.nabble.com>
	<1435324164933-4709112.post@n4.nabble.com>
	<CAM_vjunGzAF5DcgSya77CrrjBv=1yxnwvOshmSjrkrJL5PdHNA@mail.gmail.com>
Message-ID: <948F1456-1403-423B-A208-3D753E9B9DBF@comcast.net>


On Jun 26, 2015, at 10:14 AM, Sarah Goslee wrote:

> Guess what?
> 
> On Fri, Jun 26, 2015 at 9:09 AM, ritschko <y.nacht at bluewin.ch> wrote:
>> Hey! Have you ever found a solution to your problem? I have exactly the same
>> issue.
>> 
>> Best
>> 

Dear ritschko;
 
People on the R-help list generally feel annoyed when you post on Nabble and offer no context for the question (in the body of  the email.) We don't tend to follow the nabble urls in the email to correct that deficiency.


> 
> The people who read the R-help email list have exactly zero idea what
> you're talking about.
> 
> The above is all that shows up on the mailing list if you reply on
> Nabble without including any context. Nabble has nothing whatsoever
> officially to do with the email list. (It's also customary to sign
> your emails, so we can call you something besides "hey you".)

Dear Sarah;

Thank you for all your excellent contributions over the years. Actually this poster did subscribe. I had a hard time as a moderator deciding what to do with this message and eventually decided to let it go through and approve the subscription. My other alternative would have been to reject it with a message along the lines of what you write, but then I would not have also been able to approve the subscription request. The moderation tools a somewhat limited.


> 
> So if you'd like help with an R problem, you'd be best served by
> subscribing to the email list, and posting a reproducible example that
> describes what you did and what you've tried, with sample data for
> potential answerers to use.
> 
> Without a reproducible example that includes some sample data (fake is
> fine), the code you used, and some clear idea of what output you
> expect, it's impossible to figure out how to help you. Here are some
> suggestions for creating a good reproducible example:
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> 
> The R-help posting guide may also be useful:
> http://www.r-project.org/posting-guide.html
> 
> Sarah
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From kate.ignatius at gmail.com  Fri Jun 26 21:48:49 2015
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Fri, 26 Jun 2015 15:48:49 -0400
Subject: [R] Error: unexpected symbol in [with read.table]
In-Reply-To: <CAGxFJbQUzS85T8DVi9doCLZg8x0rxScTjD5j-dEnSUENykteRQ@mail.gmail.com>
References: <CAE6QMsZCLHSS68TG8j1wS4ujQbTdJwtqwCqjB7zvS_7PyW7UCg@mail.gmail.com>
	<CAGxFJbS03EnYWBkgdNYqppSTx8no9rxr9Z4Nz-FZ3Ewk=1zydw@mail.gmail.com>
	<CAE6QMsZ1TiNz4twE-Ru0vrpA3cY6J6Jn1_9DVZtvHBGQwduM+A@mail.gmail.com>
	<CAGxFJbQUzS85T8DVi9doCLZg8x0rxScTjD5j-dEnSUENykteRQ@mail.gmail.com>
Message-ID: <CAE6QMsbum6UEuC+aGHHN-hp2s4gqdzcpyCSWGKFnVDfCEznnug@mail.gmail.com>

Oops - error on my part.  Sorry.

On Fri, Jun 26, 2015 at 2:54 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> ... and you should also know by now to cc the list and not respond just to me!
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
>
>
> On Fri, Jun 26, 2015 at 10:58 AM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>> "reading in a tab delimited file using args"
>>
>> What I mean by that is that I'm using a bash script to call in an R
>> script and using the command: args <- commandArgs(TRUE) in my R
>> script.
>>
>> In my shell script I'm calling the R program as follows:
>> /path/to/R/R-3.0.2/bin/Rscript
>>
>> I'm not sure if that will help - sure you will all know if it doesn't.
>>
>> K.
>>
>> On Fri, Jun 26, 2015 at 1:39 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> ??
>>> Are you expecting us to guess what your code was from
>>>
>>> "reading in a tab delimited file using args" ?
>>>
>>> You've posted here before and should know by now that explicit code
>>> should be provided whenever possible.
>>>
>>>
>>> Cheers,
>>> Bert
>>> Bert Gunter
>>>
>>> "Data is not information. Information is not knowledge. And knowledge
>>> is certainly not wisdom."
>>>    -- Clifford Stoll
>>>
>>>
>>> On Fri, Jun 26, 2015 at 10:32 AM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>>>> When reading in a tab delimited file using args I keep getting the error:
>>>>
>>>> Error: unexpected symbol in "Name index"
>>>>
>>>> Execution halted
>>>>
>>>> The code is this:
>>>>
>>>> a <- read.table(args[1],sep="\t",header=T, stringsAsFactors=F)
>>>>
>>>> When inputting the file directly, as follows, this produces no errors:
>>>>
>>>> a <- read.table("/path/to/file/filename.txt", header=T,sep="\t",
>>>> stringsAsFactors=F).
>>>>
>>>> The file is such:
>>>>
>>>> Name               index
>>>> Bob                  1
>>>> George             2
>>>> Dave                3
>>>> Eric                  4
>>>> .
>>>> .
>>>> .
>>>> .
>>>> Andrew            20
>>>>
>>>> Is there anything I should be looking out for that might be producing
>>>> this error.   Any help will be greatly appreciated.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Fri Jun 26 22:01:42 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 26 Jun 2015 20:01:42 +0000
Subject: [R] question
In-Reply-To: <CAMqbV1BL=k9NA3hv3wxQG+x8ERvi1HcrY1ZM9JyKE5zx=qp8mA@mail.gmail.com>
References: <CAMqbV1DwyM3-0MidHu5OAfgA+gRuuUD0eqgLmdf6Ov9VgeMHFw@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D69EA02@mb02.ads.tamu.edu>
	<CAMqbV1BL=k9NA3hv3wxQG+x8ERvi1HcrY1ZM9JyKE5zx=qp8mA@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D69EA2F@mb02.ads.tamu.edu>

Do not post to the list in html and always copy your message to the list so others can follow the discussion.

That should not matter if the possible values in a row are only 0, 1, 2 as you indicated. No matter how large the matrix is, the table should only have three columns. If more values are possible you need to modify the colnames() statement accordingly. 

David

From: Lida Zeighami [mailto:lid.zigh at gmail.com] 
Sent: Friday, June 26, 2015 2:36 PM
To: David L Carlson
Subject: Re: [R] question

David,

Thank you so much for your help.
just when I inter this line :??? > colnames(tbl) <- paste0("fre", 0:2)
it?gets "Error in `colnames<-`(`*tmp*`, value = c("fre0", "fre1", "fre2")) : 
? length of 'dimnames' [2] not equal to array extent"

I think it because of my matrix is 5718*25761? the name of rows is in this format: A00002......A00045.....
and my colnames are in this format:?? 1:866453????? ........?? 21:878632

so would you please let me know what is the reason of my error and how can I correct it?

Thanks again,
Lida

On Fri, Jun 26, 2015 at 2:19 PM, David L Carlson <dcarlson at tamu.edu> wrote:
Don't use html formatting in your emails and use dput() to provide data. Assuming your matrix is called mat:

> mat <- structure(c(0L, 1L, 2L, 1L, 0L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L,
0L, 1L, 0L, 2L, 0L, 0L, 1L, 2L, 0L, 0L, 0L, 2L, 2L, 0L, 0L, 2L,
2L, 2L, 2L, 2L, 2L, 2L), .Dim = c(5L, 7L), .Dimnames = list(c("A",
"B", "C", "D", "E"), c("1", "2", "3", "4", "5", "6", "7")))
> mat
? 1 2 3 4 5 6 7
A 0 1 1 0 2 2 2
B 1 1 1 2 0 0 2
C 2 1 1 0 0 0 2
D 1 1 0 0 0 2 2
E 0 2 1 1 2 2 2
> tbl <- t(apply(mat, 1, table))
> colnames(tbl) <- paste0("fre", 0:2)
> tbl
? fre0 fre1 fre2
A? ? 2? ? 2? ? 3
B? ? 2? ? 3? ? 2
C? ? 3? ? 2? ? 2
D? ? 3? ? 2? ? 2
E? ? 1? ? 2? ? 4
> matbl <- cbind(mat, tbl)
> matbl
? 1 2 3 4 5 6 7 fre0 fre1 fre2
A 0 1 1 0 2 2 2? ? 2? ? 2? ? 3
B 1 1 1 2 0 0 2? ? 2? ? 3? ? 2
C 2 1 1 0 0 0 2? ? 3? ? 2? ? 2
D 1 1 0 0 0 2 2? ? 3? ? 2? ? 2
E 0 2 1 1 2 2 2? ? 1? ? 2? ? 4

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Lida Zeighami
Sent: Friday, June 26, 2015 1:11 PM
To: r-help at r-project.org
Subject: [R] question

Hi there,

I have a matrix (n*m) which rows including 0,1,2
I want to know the frequency of each elements (0 , 1 , 2) separately for
each row!
for example :

? ? ?1? ? 2? ? 3? ?4? ? 5? ? 6? ? ?7

A? ?0? ? ?1? ?1? ? 0? ? ?2? ? 2? ? 2
B? ?1? ? ?1? ?1? ? 2? ? 0? ? 0? ? ?2
C? ?2? ? 1? ?1? ? 0? ? ?0? ? 0? ? 2
D? ?1? ? ?1? ?0? ? 0? ? 0? ? 2? ? ?2
E? ?0? ? ?2? ?1? ? 1? ? ?2? ? 2? ? 2

I want to this output:

? ? ?1? ? 2? ? 3? ?4? ? 5? ? 6? ? ?7? ? ? ? ?fr0
fr1? ? ? ? ? ? ? ?fr2

A? ?0? ? ?1? ?1? ? 0? ? ?2? ? 2? ? 2? ? ? ? ? ?2? ? ? ? ? ? ? ? ? 2
? ? ?3
B? ?1? ? ?1? ?1? ? 2? ? 0? ? 0? ? ?2? ? ? ? ? ?3
2? ? ? ? ? ? ?2
C? ?2? ? 1? ?1? ? 0? ? ?0? ? 0? ? ?2? ? ? ? ? 3? ? ? ? ? ? ? ? ? ?2
? ? ?2
D? ?1? ? ?1? ?0? ? 0? ? 0? ? 2? ? ?2? ? ? ? ? ?2? ? ? ? ? ? ? ? ? 3
? ? ? ? 2
E? ?0? ? ?2? ?1? ? 1? ? ?2? ? 2? ? 2? ? ? ? ? ?1
2? ? ? ? ? ? 4

Thanks
? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Fri Jun 26 23:24:18 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 26 Jun 2015 21:24:18 +0000
Subject: [R] Formatting YYYY-MM after reading text file [RESOLVED]
In-Reply-To: <alpine.LNX.2.11.1506261159410.9979@localhost>
References: <alpine.LNX.2.11.1506261135450.9979@localhost>
	<alpine.LNX.2.11.1506261159410.9979@localhost>
Message-ID: <D1B30E82.12FE1D%macqueen1@llnl.gov>

I would have just assigned them all to the first day of the month, using
  as.Date( paste0(allchem$sampdate,'-01') )
(or maybe the middle of the month represented by the 15th)
and then had a variable that was of the Date class in the base R (with
which I am familiar, no small consideration).


Depending on what needs to be done with them -- plotting with a date axis?
-- calculating elapsed time between sampling events? -- I suppose one or
the other of 'yearmon' or 'Date' might be more convenient.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/26/15, 12:04 PM, "R-help on behalf of Rich Shepard"
<r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

>On Fri, 26 Jun 2015, Rich Shepard wrote:
>
>> allchem$sampdate <- as.yearmon(format(%Y-%m))allchem$sampdate
>
>   Reading the yearmon help page again led me to try
> 	allchem$sampdate <- as.yearmon(allchem$sampdate)
>which produces the following structure:
>
>'data.frame':	2226 obs. of  4 variables:
>  $ stream  : chr  "B" "B" "B" "B" ...
>  $ sampdate:Class 'yearmon'  num [1:2226] 1992 1992 1992 1992 1992 ...
>  $ param   : chr  "Cl" "SO4" "pH" "Cl" ...
>  $ quant   : num  4 33 8.43 4 32 8.46 4 31 8.43 6 ...
>
>which appears to do what's needed:
>
>allchem
>      stream sampdate param    quant
>1         B Mar 1992    Cl    4.000
>2         B Mar 1992   SO4   33.000
>3         B Mar 1992    pH    8.430
>4         B Apr 1992    Cl    4.000
>5         B Apr 1992   SO4   32.000
>6         B Apr 1992    pH    8.460
>7         B May 1992    Cl    4.000
>8         B May 1992   SO4   31.000
>9         B May 1992    pH    8.430
>10        B Jun 1992    Cl    6.000
>
>   Not having before worked with dates like this I'll soon see what
>happens
>as the analyses proceed.
>
>Rich
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Fri Jun 26 23:37:56 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 26 Jun 2015 21:37:56 +0000
Subject: [R] Error: unexpected symbol in [with read.table]
In-Reply-To: <CAE6QMsbum6UEuC+aGHHN-hp2s4gqdzcpyCSWGKFnVDfCEznnug@mail.gmail.com>
References: <CAE6QMsZCLHSS68TG8j1wS4ujQbTdJwtqwCqjB7zvS_7PyW7UCg@mail.gmail.com>
	<CAGxFJbS03EnYWBkgdNYqppSTx8no9rxr9Z4Nz-FZ3Ewk=1zydw@mail.gmail.com>
	<CAE6QMsZ1TiNz4twE-Ru0vrpA3cY6J6Jn1_9DVZtvHBGQwduM+A@mail.gmail.com>
	<CAGxFJbQUzS85T8DVi9doCLZg8x0rxScTjD5j-dEnSUENykteRQ@mail.gmail.com>
	<CAE6QMsbum6UEuC+aGHHN-hp2s4gqdzcpyCSWGKFnVDfCEznnug@mail.gmail.com>
Message-ID: <D1B3125C.12FE39%macqueen1@llnl.gov>

If

a <- read.table(args[1],sep="\t",header=T, stringsAsFactors=F)


fails but

a <- read.table("/path/to/file/filename.txt", header=T,sep="\t",
stringsAsFactors=F)


succeeds, then since those two commands are otherwise identical, you had
better put

  print(args[1])

before the call to read.table, to find out if it is actually what you
think it is.

Also, obviously, the argument(s) that you supply after
  /path/to/R/R-3.0.2/bin/Rscript
are relevant.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/26/15, 12:48 PM, "R-help on behalf of Kate Ignatius"
<r-help-bounces at r-project.org on behalf of kate.ignatius at gmail.com> wrote:

>Oops - error on my part.  Sorry.
>
>On Fri, Jun 26, 2015 at 2:54 PM, Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>> ... and you should also know by now to cc the list and not respond just
>>to me!
>> Bert Gunter
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>>    -- Clifford Stoll
>>
>>
>> On Fri, Jun 26, 2015 at 10:58 AM, Kate Ignatius
>><kate.ignatius at gmail.com> wrote:
>>> "reading in a tab delimited file using args"
>>>
>>> What I mean by that is that I'm using a bash script to call in an R
>>> script and using the command: args <- commandArgs(TRUE) in my R
>>> script.
>>>
>>> In my shell script I'm calling the R program as follows:
>>> /path/to/R/R-3.0.2/bin/Rscript
>>>
>>> I'm not sure if that will help - sure you will all know if it doesn't.
>>>
>>> K.
>>>
>>> On Fri, Jun 26, 2015 at 1:39 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>>wrote:
>>>> ??
>>>> Are you expecting us to guess what your code was from
>>>>
>>>> "reading in a tab delimited file using args" ?
>>>>
>>>> You've posted here before and should know by now that explicit code
>>>> should be provided whenever possible.
>>>>
>>>>
>>>> Cheers,
>>>> Bert
>>>> Bert Gunter
>>>>
>>>> "Data is not information. Information is not knowledge. And knowledge
>>>> is certainly not wisdom."
>>>>    -- Clifford Stoll
>>>>
>>>>
>>>> On Fri, Jun 26, 2015 at 10:32 AM, Kate Ignatius
>>>><kate.ignatius at gmail.com> wrote:
>>>>> When reading in a tab delimited file using args I keep getting the
>>>>>error:
>>>>>
>>>>> Error: unexpected symbol in "Name index"
>>>>>
>>>>> Execution halted
>>>>>
>>>>> The code is this:
>>>>>
>>>>> a <- read.table(args[1],sep="\t",header=T, stringsAsFactors=F)
>>>>>
>>>>> When inputting the file directly, as follows, this produces no
>>>>>errors:
>>>>>
>>>>> a <- read.table("/path/to/file/filename.txt", header=T,sep="\t",
>>>>> stringsAsFactors=F).
>>>>>
>>>>> The file is such:
>>>>>
>>>>> Name               index
>>>>> Bob                  1
>>>>> George             2
>>>>> Dave                3
>>>>> Eric                  4
>>>>> .
>>>>> .
>>>>> .
>>>>> .
>>>>> Andrew            20
>>>>>
>>>>> Is there anything I should be looking out for that might be producing
>>>>> this error.   Any help will be greatly appreciated.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>>http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rshepard at appl-ecosys.com  Sat Jun 27 00:02:55 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Fri, 26 Jun 2015 15:02:55 -0700 (PDT)
Subject: [R] Formatting YYYY-MM after reading text file [RESOLVED]
In-Reply-To: <D1B30E82.12FE1D%macqueen1@llnl.gov>
References: <alpine.LNX.2.11.1506261135450.9979@localhost>
	<alpine.LNX.2.11.1506261159410.9979@localhost>
	<D1B30E82.12FE1D%macqueen1@llnl.gov>
Message-ID: <alpine.LNX.2.11.1506261501160.9979@localhost>

On Fri, 26 Jun 2015, MacQueen, Don wrote:

> I would have just assigned them all to the first day of the month, using
>  as.Date( paste0(allchem$sampdate,'-01') )
> (or maybe the middle of the month represented by the 15th)
> and then had a variable that was of the Date class in the base R (with
> which I am familiar, no small consideration).

Don,

   The original data had the day of the month, but that's not important. I
suppose I could leave it in and still analyze and plot by month.

> Depending on what needs to be done with them -- plotting with a date axis?
> -- calculating elapsed time between sampling events? -- I suppose one or
> the other of 'yearmon' or 'Date' might be more convenient.

   Simple is better.

Thanks,

Rich


From dwinsemius at comcast.net  Sat Jun 27 01:51:41 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 26 Jun 2015 16:51:41 -0700
Subject: [R] Formatting YYYY-MM after reading text file [RESOLVED]
In-Reply-To: <alpine.LNX.2.11.1506261501160.9979@localhost>
References: <alpine.LNX.2.11.1506261135450.9979@localhost>
	<alpine.LNX.2.11.1506261159410.9979@localhost>
	<D1B30E82.12FE1D%macqueen1@llnl.gov>
	<alpine.LNX.2.11.1506261501160.9979@localhost>
Message-ID: <15F6C20E-D152-47E9-87BA-4807A0877100@comcast.net>


On Jun 26, 2015, at 3:02 PM, Rich Shepard wrote:

> On Fri, 26 Jun 2015, MacQueen, Don wrote:
> 
>> I would have just assigned them all to the first day of the month, using
>> as.Date( paste0(allchem$sampdate,'-01') )
>> (or maybe the middle of the month represented by the 15th)
>> and then had a variable that was of the Date class in the base R (with
>> which I am familiar, no small consideration).
> 
> Don,
> 
>  The original data had the day of the month, but that's not important. I
> suppose I could leave it in and still analyze and plot by month.

I suppose I'm jumping into the middle of a conversation but I'd say it's going to be safe to leave as a Date and then use `format(dt.val , "%Y-%m")` or similar for grouping and axis labels.

My 2 cents.

> 
>> Depending on what needs to be done with them -- plotting with a date axis?
>> -- calculating elapsed time between sampling events? -- I suppose one or
>> the other of 'yearmon' or 'Date' might be more convenient.
> 
>  Simple is better.

Much as I appreciate the value of the yearmon-class, it's not as full featured as class-Date.

-- 

David Winsemius
Alameda, CA, USA


From sarah.goslee at gmail.com  Sat Jun 27 13:50:13 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 27 Jun 2015 07:50:13 -0400
Subject: [R] large dummy-variable set in R
In-Reply-To: <948F1456-1403-423B-A208-3D753E9B9DBF@comcast.net>
References: <1418737786635-4700833.post@n4.nabble.com>
	<1435324164933-4709112.post@n4.nabble.com>
	<CAM_vjunGzAF5DcgSya77CrrjBv=1yxnwvOshmSjrkrJL5PdHNA@mail.gmail.com>
	<948F1456-1403-423B-A208-3D753E9B9DBF@comcast.net>
Message-ID: <CAM_vjumC3-qRqLBWYvCRWZnjyfphzs8gbQNcZrsFW717a54DgA@mail.gmail.com>

Great! I'm glad you subscribed! Those of us who answer questions on the R
lists do so because we like to help people learn R. But we really do need
people with questions to put some effort into it so we can give good and
useful answers.

Sarah

On Friday, June 26, 2015, David Winsemius <dwinsemius at comcast.net> wrote:

>
> On Jun 26, 2015, at 10:14 AM, Sarah Goslee wrote:
>
> > Guess what?
> >
> > On Fri, Jun 26, 2015 at 9:09 AM, ritschko <y.nacht at bluewin.ch
> <javascript:;>> wrote:
> >> Hey! Have you ever found a solution to your problem? I have exactly the
> same
> >> issue.
> >>
> >> Best
> >>
>
> Dear ritschko;
>
> People on the R-help list generally feel annoyed when you post on Nabble
> and offer no context for the question (in the body of  the email.) We don't
> tend to follow the nabble urls in the email to correct that deficiency.
>
>
> >
> > The people who read the R-help email list have exactly zero idea what
> > you're talking about.
> >
> > The above is all that shows up on the mailing list if you reply on
> > Nabble without including any context. Nabble has nothing whatsoever
> > officially to do with the email list. (It's also customary to sign
> > your emails, so we can call you something besides "hey you".)
>
> Dear Sarah;
>
> Thank you for all your excellent contributions over the years. Actually
> this poster did subscribe. I had a hard time as a moderator deciding what
> to do with this message and eventually decided to let it go through and
> approve the subscription. My other alternative would have been to reject it
> with a message along the lines of what you write, but then I would not have
> also been able to approve the subscription request. The moderation tools a
> somewhat limited.
>
>
> >
> > So if you'd like help with an R problem, you'd be best served by
> > subscribing to the email list, and posting a reproducible example that
> > describes what you did and what you've tried, with sample data for
> > potential answerers to use.
> >
> > Without a reproducible example that includes some sample data (fake is
> > fine), the code you used, and some clear idea of what output you
> > expect, it's impossible to figure out how to help you. Here are some
> > suggestions for creating a good reproducible example:
> >
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >
> > The R-help posting guide may also be useful:
> > http://www.r-project.org/posting-guide.html
> >
> > Sarah
> > --
> > Sarah Goslee
> > http://www.functionaldiversity.org
> >
> > ______________________________________________
> > R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Sat Jun 27 16:13:13 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Sat, 27 Jun 2015 14:13:13 +0000
Subject: [R] plm package: error subscript out of bounds
Message-ID: <AEB16B1613D44C4793A7E6B6986B7A12010051DEEF@EX10-LIVE-MBN2.ad.kent.ac.uk>

Hi everybody,

I am trying to run a panel regression on 10 economic sectors with 4 independent variables, respectively. The plm() function works well for all 10 economic sectors together, i.e. the dataframe containing all sectors.
Now, I am trying to run the same regression for each sector individually. My code looks as follows :



pdata.frame(dataplm_regression_BM,row.names=FALSE)->dataBM

> plmregressionBM<-plm(DeltaCoVaR~VaR+SDSVaR+Vola+value.STLFSI,data=dataBM,model="within",effect="individual")


Unfortunately, it does not work and I get the message

Error in uniqval[as.character(effect), , drop = F] :
  subscript out of bounds

I have been looking for a solution in the internet but have not found an answer to fix the problem.

Does anybody have an idea what I am doing wrong and what must be done to fix the problem?

Thanks in advance.


	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Jun 28 02:30:27 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 28 Jun 2015 10:30:27 +1000
Subject: [R] extracting significant response variables
In-Reply-To: <CAGxFJbTuyE29LgYQC2dkg1GLnroczUMoA5cZn6RBnhZXR5kChA@mail.gmail.com>
References: <CABGg3O77Wi0Y3CTfqrC+DO8=S8nWGjRaXrLVWRyhHLmX+ouTNA@mail.gmail.com>
	<CAGxFJbTuyE29LgYQC2dkg1GLnroczUMoA5cZn6RBnhZXR5kChA@mail.gmail.com>
Message-ID: <CA+8X3fUMJ5cUCMqN0H3N3zrogekCJk8G_ojwDtxfv-0C01oODQ@mail.gmail.com>

Hi adeela,
I can't quite get what you want to plot in your example, but using the
iris data set and the example in the "lda" help page, this may give
you some idea of what can be done. I'm using the "z" structure in the
example.

matplot(z$scaling,xlim=c(0,5),ylim=c(-3,3),pch="",axes=FALSE,
 main="LDA scaling and means for iris data",ylab="Scaling",
 xlab="Measurement")
axis(1,at=1:4,labels=c("Sepal.L.","Sepal.W.","Petal.L.","Petal.W."))
axis(2)
box()
library(plotrix)
draw.circle(rep(1:4,2),z$scaling,radius=rep(colMeans(z$means)/10,2),
col=c("azure","lightblue","dodgerblue","turquoise",
 "tomato","red","darkred","indianred"))
text(c(3.5,3.5),c(-0.2,-0.6),c("Blues - LD1","Reds - LD2"))

Jim


On Fri, Jun 26, 2015 at 11:57 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Offtopic. This list is about R programming. Post to a statistics list
> like stats.stackexchange.com instead. Better yet, find a local expert
> to help you. What you describe sounds confused and likely to produce
> nonsense to me. You may not even have the information needed to answer
> the question you asked.
>
> Cheers,
> Bert
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
>
>
> On Thu, Jun 25, 2015 at 11:09 PM, adeela uaf <adeela.uaf at gmail.com> wrote:
>> Hi,
>> My experiment consist of factorial structure with 25 genotypes and 3
>> salinity levels ( 25 cross 3) each with 3 replications.  14 responses were
>> taken from the experiment and I applied MANOVA but I am applying
>> discriminant analysis to know which response variable has significant
>> impact on the separation of groups. I am doing the following:
>> MANOVA<-manova(cbind(RL,SL,RFW,SFW,RDW,SDW,R.S..DW.,LA,NL,Na,K,Ca)~geneotype*S.Level,data=data)
>> For discriminant analysis, I made a group of 1 genotype with one level of
>> Salinity level hence a total of 75 groups.
>> group<-paste("g", gl(75,3,length=225))
>> LDA<-lda(group~RL+SL+RFW+SFW+RDW+SDW+R.S..DW.+LA+NL+Na+K+Ca+K.Na+Ca.Na,data=Sdata)
>>
>> Is it appropriate way? Moreover when I am plotting discriminant scores
>> means with the circle of radius r=z/sqrt(replication) but the graph doesn't
>> make any sense as the circles are too small too see.
>> Thanks,
>> Adeela
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun Jun 28 02:42:47 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 28 Jun 2015 10:42:47 +1000
Subject: [R] Error: unexpected symbol in [with read.table]
In-Reply-To: <D1B3125C.12FE39%macqueen1@llnl.gov>
References: <CAE6QMsZCLHSS68TG8j1wS4ujQbTdJwtqwCqjB7zvS_7PyW7UCg@mail.gmail.com>
	<CAGxFJbS03EnYWBkgdNYqppSTx8no9rxr9Z4Nz-FZ3Ewk=1zydw@mail.gmail.com>
	<CAE6QMsZ1TiNz4twE-Ru0vrpA3cY6J6Jn1_9DVZtvHBGQwduM+A@mail.gmail.com>
	<CAGxFJbQUzS85T8DVi9doCLZg8x0rxScTjD5j-dEnSUENykteRQ@mail.gmail.com>
	<CAE6QMsbum6UEuC+aGHHN-hp2s4gqdzcpyCSWGKFnVDfCEznnug@mail.gmail.com>
	<D1B3125C.12FE39%macqueen1@llnl.gov>
Message-ID: <CA+8X3fUHK+d6z0rPJP52ZykX2ae6GBZ_zOLFtu3FdaUfNutkqg@mail.gmail.com>

Hi Kate,
I could well be wrong, but are you sure that your data file is TAB
delimited and not whitespace delimited?

Jim


On Sat, Jun 27, 2015 at 7:37 AM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> If
>
> a <- read.table(args[1],sep="\t",header=T, stringsAsFactors=F)
>
>
> fails but
>
> a <- read.table("/path/to/file/filename.txt", header=T,sep="\t",
> stringsAsFactors=F)
>
>
> succeeds, then since those two commands are otherwise identical, you had
> better put
>
>   print(args[1])
>
> before the call to read.table, to find out if it is actually what you
> think it is.
>
> Also, obviously, the argument(s) that you supply after
>   /path/to/R/R-3.0.2/bin/Rscript
> are relevant.
>
> -Don
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 6/26/15, 12:48 PM, "R-help on behalf of Kate Ignatius"
> <r-help-bounces at r-project.org on behalf of kate.ignatius at gmail.com> wrote:
>
>>Oops - error on my part.  Sorry.
>>
>>On Fri, Jun 26, 2015 at 2:54 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>wrote:
>>> ... and you should also know by now to cc the list and not respond just
>>>to me!
>>> Bert Gunter
>>>
>>> "Data is not information. Information is not knowledge. And knowledge
>>> is certainly not wisdom."
>>>    -- Clifford Stoll
>>>
>>>
>>> On Fri, Jun 26, 2015 at 10:58 AM, Kate Ignatius
>>><kate.ignatius at gmail.com> wrote:
>>>> "reading in a tab delimited file using args"
>>>>
>>>> What I mean by that is that I'm using a bash script to call in an R
>>>> script and using the command: args <- commandArgs(TRUE) in my R
>>>> script.
>>>>
>>>> In my shell script I'm calling the R program as follows:
>>>> /path/to/R/R-3.0.2/bin/Rscript
>>>>
>>>> I'm not sure if that will help - sure you will all know if it doesn't.
>>>>
>>>> K.
>>>>
>>>> On Fri, Jun 26, 2015 at 1:39 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>wrote:
>>>>> ??
>>>>> Are you expecting us to guess what your code was from
>>>>>
>>>>> "reading in a tab delimited file using args" ?
>>>>>
>>>>> You've posted here before and should know by now that explicit code
>>>>> should be provided whenever possible.
>>>>>
>>>>>
>>>>> Cheers,
>>>>> Bert
>>>>> Bert Gunter
>>>>>
>>>>> "Data is not information. Information is not knowledge. And knowledge
>>>>> is certainly not wisdom."
>>>>>    -- Clifford Stoll
>>>>>
>>>>>
>>>>> On Fri, Jun 26, 2015 at 10:32 AM, Kate Ignatius
>>>>><kate.ignatius at gmail.com> wrote:
>>>>>> When reading in a tab delimited file using args I keep getting the
>>>>>>error:
>>>>>>
>>>>>> Error: unexpected symbol in "Name index"
>>>>>>
>>>>>> Execution halted
>>>>>>
>>>>>> The code is this:
>>>>>>
>>>>>> a <- read.table(args[1],sep="\t",header=T, stringsAsFactors=F)
>>>>>>
>>>>>> When inputting the file directly, as follows, this produces no
>>>>>>errors:
>>>>>>
>>>>>> a <- read.table("/path/to/file/filename.txt", header=T,sep="\t",
>>>>>> stringsAsFactors=F).
>>>>>>
>>>>>> The file is such:
>>>>>>
>>>>>> Name               index
>>>>>> Bob                  1
>>>>>> George             2
>>>>>> Dave                3
>>>>>> Eric                  4
>>>>>> .
>>>>>> .
>>>>>> .
>>>>>> .
>>>>>> Andrew            20
>>>>>>
>>>>>> Is there anything I should be looking out for that might be producing
>>>>>> this error.   Any help will be greatly appreciated.
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>>http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun Jun 28 11:21:02 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 28 Jun 2015 19:21:02 +1000
Subject: [R] Fread: add one to skip string identifier
In-Reply-To: <CAJhyqVhXDFuhrUrL3LTo4mMC-dLUD-0ObwbK071VtAO1hQMr9w@mail.gmail.com>
References: <CAJhyqVhXDFuhrUrL3LTo4mMC-dLUD-0ObwbK071VtAO1hQMr9w@mail.gmail.com>
Message-ID: <CA+8X3fW7XCEq5KmZM8C9p_4Ugi5PLN2X414=P+t+JPMt_gr3tQ@mail.gmail.com>

Hi Trevor,
I couldn't work out how to do it with just fread, but perhaps this will help:

# create a test file
sink("test_fread.dat")
cat("This is the header of a file\n")
cat("that ends with the word *end*\n")
cat("Col1 Col2\n1 2\n3 4\n5 6\n")
sink()
# try to read it
test_con<-file("test_fread.dat","rt")
header_lines<-1
while(header_lines) {
 nextline<-readLines(test_con,1)
 header_lines<-length(grep("*end",nextline,fixed=TRUE))==0
}
fread_dat<-read.table(test_con,header=TRUE)

Jim

On Sat, Jun 27, 2015 at 2:16 AM, Trevor Davies <davies.trevor at gmail.com> wrote:
> I'm trying to read in a file using the function fread.
>
> The file that I'm trying to read in has about 100 lines of information I
> don't want prior to getting to my matrix of data that I do want.  On the
> line prior to the data I want there is always a string identifier "*end*"
>
> The following fread call:
>
> impcoord <- fread('H:/SBE19plus_01907535_2015_06_17_0093.cnv',skip="*END*")
>
> almost gets me there but it starts reading AT *END* and I'd like to have it
> start the line after.  I can't figure out how to make this work.
>
> I know I could have a two step function where I have a function scan the
> file to Identify the line that has *END* but I thought I could just do it
> with one fread() call.
>
> thanks for the help.
> Trevor
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j.bayat194 at gmail.com  Sun Jun 28 05:06:22 2015
From: j.bayat194 at gmail.com (JAVAD BAYAT)
Date: Sun, 28 Jun 2015 07:36:22 +0430
Subject: [R]  correlation matricies: getting p-values?
Message-ID: <000001d0b14f$6bb633a0$43229ae0$@gmail.com>

Dear Bill Venables;

Hi, I am using "cor" command to get the correlation coefficients for my data
frame. I found somthing in the following site: "
<https://stat.ethz.ch/pipermail/r-help/2000-January/009758.html>
https://stat.ethz.ch/pipermail/r-help/2000-January/009758.html" . I used
your functions to get the p-values for each variables. But I want to use
Spearman method for my data frame. 

Please help me to write the right function.

many thanks.

 


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Jun 28 19:03:13 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 28 Jun 2015 10:03:13 -0700
Subject: [R] correlation matricies: getting p-values?
In-Reply-To: <000001d0b14f$6bb633a0$43229ae0$@gmail.com>
References: <000001d0b14f$6bb633a0$43229ae0$@gmail.com>
Message-ID: <11274A77-CD07-45E2-A1CD-D3E7B3353891@comcast.net>


On Jun 27, 2015, at 8:06 PM, JAVAD BAYAT wrote:

> Dear Bill Venables;
> 
> Hi, I am using "cor" command to get the correlation coefficients for my data
> frame. I found somthing in the following site: "
> <https://stat.ethz.ch/pipermail/r-help/2000-January/009758.html>
> https://stat.ethz.ch/pipermail/r-help/2000-January/009758.html" . I used
> your functions to get the p-values for each variables. But I want to use
> Spearman method for my data frame. 

You should read the help page for the `cor` function. The adjustment to that code will be very minor once  you understand the available parameters.

> 
> 	[[alternative HTML version deleted]]
> 

Now that you have subscribed, you should take the time to read the Posting Guide and learn to set you mail-client to plain-text.

> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Sun Jun 28 19:23:18 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 28 Jun 2015 10:23:18 -0700
Subject: [R] correlation matricies: getting p-values?
In-Reply-To: <000001d0b14f$6bb633a0$43229ae0$@gmail.com>
References: <000001d0b14f$6bb633a0$43229ae0$@gmail.com>
Message-ID: <CAGxFJbRPUJiDHiCXD+hmEkNUpORdb-jV_t3kjx=hXiiHA_En2Q@mail.gmail.com>

?cor.test

Please read Help files (for cor, which linked cor.test) before
posting. And, as David says, post in plain text.

-- Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sat, Jun 27, 2015 at 8:06 PM, JAVAD BAYAT <j.bayat194 at gmail.com> wrote:
> Dear Bill Venables;
>
> Hi, I am using "cor" command to get the correlation coefficients for my data
> frame. I found somthing in the following site: "
> <https://stat.ethz.ch/pipermail/r-help/2000-January/009758.html>
> https://stat.ethz.ch/pipermail/r-help/2000-January/009758.html" . I used
> your functions to get the p-values for each variables. But I want to use
> Spearman method for my data frame.
>
> Please help me to write the right function.
>
> many thanks.
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Jun 28 19:28:00 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 28 Jun 2015 10:28:00 -0700
Subject: [R] correlation matricies: getting p-values?
In-Reply-To: <11274A77-CD07-45E2-A1CD-D3E7B3353891@comcast.net>
References: <000001d0b14f$6bb633a0$43229ae0$@gmail.com>
	<11274A77-CD07-45E2-A1CD-D3E7B3353891@comcast.net>
Message-ID: <6D126615-9A87-4981-8CFA-170ABEF95930@comcast.net>


On Jun 28, 2015, at 10:03 AM, David Winsemius wrote:

> 
> On Jun 27, 2015, at 8:06 PM, JAVAD BAYAT wrote:
> 
>> Dear Bill Venables;
>> 
>> Hi, I am using "cor" command to get the correlation coefficients for my data
>> frame. I found somthing in the following site: "
>> <https://stat.ethz.ch/pipermail/r-help/2000-January/009758.html>
>> https://stat.ethz.ch/pipermail/r-help/2000-January/009758.html" . I used
>> your functions to get the p-values for each variables. But I want to use
>> Spearman method for my data frame. 
> 
> You should read the help page for the `cor` function. The adjustment to that code will be very minor once  you understand the available parameters.

I probably should have added a caution about necessarily assuming that the significance probability of the Spearman correlation being different than 0 would be distributed exactly as the Pearson correlation coefficient. There is a cor.test function that includes an option for "spearman". There is also an `rcorr` function in pkg:Hmisc that would do this on one line.

> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
> 
> Now that you have subscribed, you should take the time to read the Posting Guide and learn to set you mail-client to plain-text.
> 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From shaunnamm at email.arizona.edu  Sun Jun 28 18:40:46 2015
From: shaunnamm at email.arizona.edu (Shaunna Morrison)
Date: Sun, 28 Jun 2015 11:40:46 -0500
Subject: [R] Propagate errors with prediction interval
Message-ID: <CANpjChHmO0NKOhpYgnYL6w-KdVRk=m0QOCi2iqruoSjySOEXuQ@mail.gmail.com>

Hello!


I have a linear dataset with known values of X & Y in R. I treat the
dataset as a linear model.

I have a data point with a known value of X and an unknown value of Y. The
X value has an associated instrument error.

Goal: compute the prediction interval (of Y) for the data point, X, and its
associated error.


Commands:

newdata=data.frame(X=###)

predict(g,newdata,interval="prediction",level=0.68)


This allows me to compute the prediction interval for a data point, based
on a known value of X, but does not propagate the error associated with X.

*I need a method in R to include/propagate the error associated with X. *

Note - The X,Y dataset is subject to the same type of associated error as
the input variable, X. *However*, we do not wish to include the dataset's
associated error in this prediction interval.

Thank you!

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Jun 28 22:23:15 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 28 Jun 2015 13:23:15 -0700
Subject: [R] Propagate errors with prediction interval
In-Reply-To: <CANpjChHmO0NKOhpYgnYL6w-KdVRk=m0QOCi2iqruoSjySOEXuQ@mail.gmail.com>
References: <CANpjChHmO0NKOhpYgnYL6w-KdVRk=m0QOCi2iqruoSjySOEXuQ@mail.gmail.com>
Message-ID: <CAGxFJbQsntyPeHrqCHx2ZROc1f+xmFtsCXgHkMWwZU+vNFzXzA@mail.gmail.com>

1. You need to research "errors in variables regression."

2. This is off topic here. This list is about R programming, not
statistics. Post on a statistics list like stats.stackexchange.com
instead.

3. Better yet, consult a local statistical expert.

4. If you post on R issues here, follow the list protocols and post in
plain text, not HTML, please.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sun, Jun 28, 2015 at 9:40 AM, Shaunna Morrison
<shaunnamm at email.arizona.edu> wrote:
> Hello!
>
>
> I have a linear dataset with known values of X & Y in R. I treat the
> dataset as a linear model.
>
> I have a data point with a known value of X and an unknown value of Y. The
> X value has an associated instrument error.
>
> Goal: compute the prediction interval (of Y) for the data point, X, and its
> associated error.
>
>
> Commands:
>
> newdata=data.frame(X=###)
>
> predict(g,newdata,interval="prediction",level=0.68)
>
>
> This allows me to compute the prediction interval for a data point, based
> on a known value of X, but does not propagate the error associated with X.
>
> *I need a method in R to include/propagate the error associated with X. *
>
> Note - The X,Y dataset is subject to the same type of associated error as
> the input variable, X. *However*, we do not wish to include the dataset's
> associated error in this prediction interval.
>
> Thank you!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From navinder.singh at slu.se  Mon Jun 29 00:37:32 2015
From: navinder.singh at slu.se (Navinder)
Date: Sun, 28 Jun 2015 15:37:32 -0700 (PDT)
Subject: [R] convert command not found in movie3d (rgl package) in Mac
	OS X
In-Reply-To: <4F1D69B5.4090604@gmail.com>
References: <CAErHMT3jdPaekWZ95ULEdr9db04vSJo9h5TWuhErHFO=sSxfAQ@mail.gmail.com>
	<4F1D69B5.4090604@gmail.com>
Message-ID: <1435531052565-4709153.post@n4.nabble.com>

Dear Duncan,
I have the same problem but the solution you provided above doesn't really
work for me. I am using mac and have ImageMagick installed. 
Any other suggestions how to fix this problem?
Thanks,
Navi



--
View this message in context: http://r.789695.n4.nabble.com/convert-command-not-found-in-movie3d-rgl-package-in-Mac-OS-X-tp4320734p4709153.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Mon Jun 29 02:50:43 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 28 Jun 2015 17:50:43 -0700
Subject: [R] convert command not found in movie3d (rgl package) in Mac
	OS X
In-Reply-To: <CAErHMT3jdPaekWZ95ULEdr9db04vSJo9h5TWuhErHFO=sSxfAQ@mail.gmail.com>
References: <CAErHMT3jdPaekWZ95ULEdr9db04vSJo9h5TWuhErHFO=sSxfAQ@mail.gmail.com>
Message-ID: <4A59DC05-7DD4-43AD-B849-58C4D6E7E18B@comcast.net>


On Jan 23, 2012, at 5:50 AM, Manabu Sakamoto wrote:

> Dear list,
> 
> I gave up trying to fix my movie3d (rgl library) issue in my PC
> (completely black gif/png file) and went ahead and installed MacPorts
> and ImageMagick onto my iMac (OSX ver 10.6.8). I think ImageMagick is
> successfully installed in its default location (under /opt/local),

I'm not sure it has a default location, but if you are using a package management system, then there might be a default location for all the packages installed in that manner.

> and
> I ran movie3d but I get the following error:
> 
> Error in system("convert --version", intern = TRUE) :
>   error in running command
> sh: convert: command not found
> 
> so I'm guessing R can't find the "convert" executable file, which is
> in "Sys.getenv("PATH")", in its system search path, which I presume is
> "/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin" that I got using
> Sys.getenv("PATH").
> 
> Does anyone know how I can resolve this? For instance, should I move
> or copy the convert executable file to an appropriate directory (which
> I don't really know where exactly, i.e. I can't find a folder "usr" in
> the Macintosh HD),


The /usr/ directory is hidden and not displayed by the default settings of the Finder.app, but you should be able to change those settings if you da a Google search and use Terminal.app to start up a bash shell   or you can use Terminal.app and type these two lines:

cd /
ls

> 
> or can I add "/opt/local/bin" to the R's search
> path?

I'm not sure whether executing:

 Sys.setenv("PATH") <- paste(Sys.getenv("PATH"), ":/opt/local")

... will necessarily cause success with a system()-mediated call, since my fragile understanding is that the system()-calls use the bash shell which has a different PATH variable than does R called from R.app which is what I suspect you are using.

This is probably better addressed to the R-SIG-Mac mailing list and you will need to subscribe:

r-sig-mac R <r-sig-mac at r-project.org>



> best regards,
> Manabu
> 
> -- 
> Manabu Sakamoto, PhD
> School of Earth Sciences
> University of Bristol
> manabu.sakamoto at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From oluola2011 at yahoo.com  Mon Jun 29 05:56:39 2015
From: oluola2011 at yahoo.com (Olu Ola)
Date: Sun, 28 Jun 2015 20:56:39 -0700
Subject: [R] Bootstrapping Standard errors of nonlinear GMM obtained from
	BFGS (Optimx)
Message-ID: <1435550199.74646.YahooMailBasic@web161604.mail.bf1.yahoo.com>

Hello,
I am running a 2 equation system of nonlinear GMM using BFGS in optimx. Using the conventional way of calculating the standard error of the estimates gives NAN's for some of the standard errors. As a result, I want to bootstrap the standard error. 

A way forward on how to bootsrap the standard errors will be greatly appreciated.


From devazresearch at gmail.com  Mon Jun 29 08:28:28 2015
From: devazresearch at gmail.com (deva d)
Date: Mon, 29 Jun 2015 11:58:28 +0530
Subject: [R] Spline Graphs
Message-ID: <CAKuYVCVn4xMcynOeyG31j8ySfHr6Mxsax91W=POrkcE=U6jHjA@mail.gmail.com>

I wish to analyse longitudinal data and fit spline graphs to it looking to
the data pattern.

can someone suggest some starting point, and package in R to be used for
it.

what would be the requirement for structuring the raw data.

*....*

*Deva*

	[[alternative HTML version deleted]]


From devazresearch at gmail.com  Mon Jun 29 08:35:37 2015
From: devazresearch at gmail.com (deva d)
Date: Mon, 29 Jun 2015 12:05:37 +0530
Subject: [R] Simulating data
Message-ID: <CAKuYVCWnF1_3E1uvt0FDZ2N+pN+4aQG=6SnRWkoGic6HzYXm+A@mail.gmail.com>

i wish to simulate data to generate twice the sample size for testing a
model.

the two fields to be simulated are y and x, in the attached file.

as you will see, these represent data of several companies, of different
sizes, for a 11 year period. the distribution is not really fitting into
any known or close approximation thereto.

is it possible for R to simulate additional 1000 points s.t. the resultant
distribution closely matches the distribution of the original data.

kindly advise.

thanks and best,
*....*

*Deva*

From petr.pikal at precheza.cz  Mon Jun 29 09:08:50 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 29 Jun 2015 07:08:50 +0000
Subject: [R] Simulating data
In-Reply-To: <CAKuYVCWnF1_3E1uvt0FDZ2N+pN+4aQG=6SnRWkoGic6HzYXm+A@mail.gmail.com>
References: <CAKuYVCWnF1_3E1uvt0FDZ2N+pN+4aQG=6SnRWkoGic6HzYXm+A@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C32951@SRVEXCHMBX.precheza.cz>

Hi

Attachments are usually discarded.

maybe ?sample

Petr



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of deva d
> Sent: Monday, June 29, 2015 8:36 AM
> To: r-help
> Subject: [R] Simulating data
>
> i wish to simulate data to generate twice the sample size for testing a
> model.
>
> the two fields to be simulated are y and x, in the attached file.
>
> as you will see, these represent data of several companies, of
> different sizes, for a 11 year period. the distribution is not really
> fitting into any known or close approximation thereto.
>
> is it possible for R to simulate additional 1000 points s.t. the
> resultant distribution closely matches the distribution of the original
> data.
>
> kindly advise.
>
> thanks and best,
> *....*
>
> *Deva*
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From devazresearch at gmail.com  Mon Jun 29 09:21:21 2015
From: devazresearch at gmail.com (deva d)
Date: Mon, 29 Jun 2015 12:51:21 +0530
Subject: [R] Simulating data
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C32951@SRVEXCHMBX.precheza.cz>
References: <CAKuYVCWnF1_3E1uvt0FDZ2N+pN+4aQG=6SnRWkoGic6HzYXm+A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C32951@SRVEXCHMBX.precheza.cz>
Message-ID: <CAKuYVCWw=C7cgmF=7-PqZ2A-UJChtrpaFSakD2xg0eYTT_kvOw@mail.gmail.com>

ok. ill just paste the data here ... hope it helps ....

 y x  5721 20175  4285 44441  4327 59426  4964 75536  7899 79432  11140
125735  11843 89411  18146 124805  24712 110859  31993 178038  41217 164212
96 1823  129 3440  151 3860  243 4630  292 4550  336 4775  517 5326  617
6030  1572 8038  1628 8291  2124 6637  0 2151  0 3786  273 5263  209 7246
199 7740  326 7830  410 9146  1171 11895  2219 12332  0 12804  0 5797  179
1046  128 2475  0 2973  0 4711  0 4562  190 4589  373 3920  783 4494  1311
5806  1658 5097  2098 4549  0 2340  0 2273  0 6821  338 6590  449 7630  394
7187  1002 2760  1251 5086  1567 11501  2034 10865  4064 2137  257 1962  235
3716  187 4018  247 5763  326 3507  407 4465  571 5860  745 7583  2741 9302
2407 12138  4932 1921  378 2798  351 5809  338 7997  570 12142  619 8430
846 9081  1238 12803  1747 22020  2232 17520  5892 18345  6021 8517  295
1373  150 4631  153 4584  244 5789  202 6349  201 9901  400 11974  795 15322
1287 11788  2742 15150  2832 9271  1078 253  663 7800  550 16511  774 23709
1002 23080  1002 36550  1671 31784  1897 53641  3443 58701  6844 40808  6834
68820  1204 3223  757 9673  709 9645  947 19942  1365 28360  2100 29433
4162 25581  2908 44605  5401 35737  7380 40534  8811 81366  221 2223  223
1330  275 3408  309 6450  252 6366  369 5005  876 6024  699 6566  876 9179
808 19411  2589 13450  1890 7967  1319 11983  1405 19004  1272 19080  1426
8732  2378 30981  3266 31115  3508 41934  4590 21222  5819 9687  8444 58891
794 552  788 4473  732 10206  807 14312  665 21202  873 12486  1033 19900
1409 24342  6849 17787  5125 24423  7569 5379  227 1861  185 4657  214 5416
269 5987  173 9236  236 9327  477 14690  813 23648  1203 13619  1797 18248
3556 18370  459 976  264 1897  334 2923  534 4072  416 4721  676 5854  630
6584  759 9366  722 11864  1120 9089  2420 11773  76 3074  187 38015  1883
7326  931 9732  954 19742  637 21232  1483 34757  1987 18896  2560 23474
2740 15734  5706 1380  222 1851  228 4254  192 4105  172 6573  444 10781
229 11558  586 10750  954 13104  1880 15074  2893 15319  2832 16566  492
2848  508 4910  476 9551  707 12304  665 13342  2262 14483  3127 4114  2169
32834  3185 28891  5601 19640  6902 15524  527 4004  1878 5618  373 8278
379 10561  580 10427  496 13935  1133 14989  1556 12419  3898 16069  3213
16977  4027 10125  1044 6997  719 13188  903 14215  2061 21969  1953 22905
1731 35201  2838 31898  4337 55505  6672 51668  8647 15021  10810 40473  0
138  0 292  108 2613  76 2786  106 6622  142 6272  208 8024  383 9999  551
3514  1094 5279  1620 5808  428 4342  399 6082  554 9737  740 15204  1265
12381  961 17481  1492 8874  1593 16376  3156 16838  2142 23949  3695 26343
578 4703  598 7029  548 9722  1004 9611  1035 8093  667 13722  1109 13701
2730 16566  2401 16469  5162 12743  3962 21301  678 3407  510 11183  753
13275  750 9006  763 11880  1177 22267  1785 22781  2924 31671  3760 26896
3974 30220  5479 21002  0 612  0 3426  0 4133  406 6634  326 5702  811 7535
980 6936  984 11172  1964 9541  2485 5865  8007 -3141  274 3161  323 3290
384 2328  398 7560  407 7466  667 3778  1208 6054  1362 7197  2057 9185
1601 11862  2174 11738  0 428  0 391  43 406  38 318  38 301  63 370  53 783
108 1753  100 1444  171 1188  390 -144  0 335  0 466  39 537  39 780  59
1208  86 1108  108 1188  121 2422  144 2882  223 3109  456 851  41 58  15
272  25 184  26 243  16 265  37 1094  52 1810  41 4059  92 -307  505 -981
488 159  218 1483  191 1122  159 2914  182 3163  262 4006  575 3487  747
4558  876 5003  695 5803  807 6341  523 -661  163 1325  216 2144  228 1151
204 1745  197 2673  332 2107  410 1751  236 5095  173 5119  194 3051  335
4057  143 1274  150 2232  158 2966  274 2597  228 1803  402 2048  189 2127
289 3136  315 6884  455 6123  411 7184  132 768  52 1620  58 1504  130 1761
138 1289  162 968  300 2626  324 2912  378 3373  413 4487  654 3138  48 679
52 597  52 936  53 1485  77 2381  82 988  121 3037  54 4367  174 6135  201
5531  148 4512


*....*

*Deva*
*F-13*
*iResearch at NITIE*
*my 'research engine' *

...............



*in search of knowledge, everyday something is added ....*

*in search of wisdom, everyday something is dropped  ... an old Chinese
Proverb*
:::::::::::::::::::::::::

On Mon, Jun 29, 2015 at 12:38 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> Attachments are usually discarded.
>
> maybe ?sample
>
> Petr
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of deva d
> > Sent: Monday, June 29, 2015 8:36 AM
> > To: r-help
> > Subject: [R] Simulating data
> >
> > i wish to simulate data to generate twice the sample size for testing a
> > model.
> >
> > the two fields to be simulated are y and x, in the attached file.
> >
> > as you will see, these represent data of several companies, of
> > different sizes, for a 11 year period. the distribution is not really
> > fitting into any known or close approximation thereto.
> >
> > is it possible for R to simulate additional 1000 points s.t. the
> > resultant distribution closely matches the distribution of the original
> > data.
> >
> > kindly advise.
> >
> > thanks and best,
> > *....*
> >
> > *Deva*
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Jun 29 10:33:57 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 29 Jun 2015 08:33:57 +0000
Subject: [R] Simulating data
In-Reply-To: <CAKuYVCWw=C7cgmF=7-PqZ2A-UJChtrpaFSakD2xg0eYTT_kvOw@mail.gmail.com>
References: <CAKuYVCWnF1_3E1uvt0FDZ2N+pN+4aQG=6SnRWkoGic6HzYXm+A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C32951@SRVEXCHMBX.precheza.cz>
	<CAKuYVCWw=C7cgmF=7-PqZ2A-UJChtrpaFSakD2xg0eYTT_kvOw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C32A11@SRVEXCHMBX.precheza.cz>

Hi

Probably quicker would be if you try sample and tell us if the result is what you want or not.

probably something like

ind<-sample(1:nrow(yourdata), 10000, replace=TRUE)
newdata<-yourdata[ind,]

Cheers
Petr

From: devazemail at gmail.com [mailto:devazemail at gmail.com] On Behalf Of deva d
Sent: Monday, June 29, 2015 9:21 AM
To: PIKAL Petr
Cc: r-help
Subject: Re: [R] Simulating data

ok. ill just paste the data here ... hope it helps ....

y

x

5721

20175

4285

44441

4327

59426

4964

75536

7899

79432

11140

125735

11843

89411

18146

124805

24712

110859

31993

178038

41217

164212

96

1823

129

3440

151

3860

243

4630

292

4550

336

4775

517

5326

617

6030

1572

8038

1628

8291

2124

6637

0

2151

0

3786

273

5263

209

7246

199

7740

326

7830

410

9146

1171

11895

2219

12332

0

12804

0

5797

179

1046

128

2475

0

2973

0

4711

0

4562

190

4589

373

3920

783

4494

1311

5806

1658

5097

2098

4549

0

2340

0

2273

0

6821

338

6590

449

7630

394

7187

1002

2760

1251

5086

1567

11501

2034

10865

4064

2137

257

1962

235

3716

187

4018

247

5763

326

3507

407

4465

571

5860

745

7583

2741

9302

2407

12138

4932

1921

378

2798

351

5809

338

7997

570

12142

619

8430

846

9081

1238

12803

1747

22020

2232

17520

5892

18345

6021

8517

295

1373

150

4631

153

4584

244

5789

202

6349

201

9901

400

11974

795

15322

1287

11788

2742

15150

2832

9271

1078

253

663

7800

550

16511

774

23709

1002

23080

1002

36550

1671

31784

1897

53641

3443

58701

6844

40808

6834

68820

1204

3223

757

9673

709

9645

947

19942

1365

28360

2100

29433

4162

25581

2908

44605

5401

35737

7380

40534

8811

81366

221

2223

223

1330

275

3408

309

6450

252

6366

369

5005

876

6024

699

6566

876

9179

808

19411

2589

13450

1890

7967

1319

11983

1405

19004

1272

19080

1426

8732

2378

30981

3266

31115

3508

41934

4590

21222

5819

9687

8444

58891

794

552

788

4473

732

10206

807

14312

665

21202

873

12486

1033

19900

1409

24342

6849

17787

5125

24423

7569

5379

227

1861

185

4657

214

5416

269

5987

173

9236

236

9327

477

14690

813

23648

1203

13619

1797

18248

3556

18370

459

976

264

1897

334

2923

534

4072

416

4721

676

5854

630

6584

759

9366

722

11864

1120

9089

2420

11773

76

3074

187

38015

1883

7326

931

9732

954

19742

637

21232

1483

34757

1987

18896

2560

23474

2740

15734

5706

1380

222

1851

228

4254

192

4105

172

6573

444

10781

229

11558

586

10750

954

13104

1880

15074

2893

15319

2832

16566

492

2848

508

4910

476

9551

707

12304

665

13342

2262

14483

3127

4114

2169

32834

3185

28891

5601

19640

6902

15524

527

4004

1878

5618

373

8278

379

10561

580

10427

496

13935

1133

14989

1556

12419

3898

16069

3213

16977

4027

10125

1044

6997

719

13188

903

14215

2061

21969

1953

22905

1731

35201

2838

31898

4337

55505

6672

51668

8647

15021

10810

40473

0

138

0

292

108

2613

76

2786

106

6622

142

6272

208

8024

383

9999

551

3514

1094

5279

1620

5808

428

4342

399

6082

554

9737

740

15204

1265

12381

961

17481

1492

8874

1593

16376

3156

16838

2142

23949

3695

26343

578

4703

598

7029

548

9722

1004

9611

1035

8093

667

13722

1109

13701

2730

16566

2401

16469

5162

12743

3962

21301

678

3407

510

11183

753

13275

750

9006

763

11880

1177

22267

1785

22781

2924

31671

3760

26896

3974

30220

5479

21002

0

612

0

3426

0

4133

406

6634

326

5702

811

7535

980

6936

984

11172

1964

9541

2485

5865

8007

-3141

274

3161

323

3290

384

2328

398

7560

407

7466

667

3778

1208

6054

1362

7197

2057

9185

1601

11862

2174

11738

0

428

0

391

43

406

38

318

38

301

63

370

53

783

108

1753

100

1444

171

1188

390

-144

0

335

0

466

39

537

39

780

59

1208

86

1108

108

1188

121

2422

144

2882

223

3109

456

851

41

58

15

272

25

184

26

243

16

265

37

1094

52

1810

41

4059

92

-307

505

-981

488

159

218

1483

191

1122

159

2914

182

3163

262

4006

575

3487

747

4558

876

5003

695

5803

807

6341

523

-661

163

1325

216

2144

228

1151

204

1745

197

2673

332

2107

410

1751

236

5095

173

5119

194

3051

335

4057

143

1274

150

2232

158

2966

274

2597

228

1803

402

2048

189

2127

289

3136

315

6884

455

6123

411

7184

132

768

52

1620

58

1504

130

1761

138

1289

162

968

300

2626

324

2912

378

3373

413

4487

654

3138

48

679

52

597

52

936

53

1485

77

2381

82

988

121

3037

54

4367

174

6135

201

5531

148

4512



....

Deva
F-13
iResearch at NITIE
my 'research engine'

...............

in search of knowledge, everyday something is added ....
in search of wisdom, everyday something is dropped  ... an old Chinese Proverb

:::::::::::::::::::::::::

On Mon, Jun 29, 2015 at 12:38 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

Attachments are usually discarded.

maybe ?sample

Petr



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of deva d
> Sent: Monday, June 29, 2015 8:36 AM
> To: r-help
> Subject: [R] Simulating data
>
> i wish to simulate data to generate twice the sample size for testing a
> model.
>
> the two fields to be simulated are y and x, in the attached file.
>
> as you will see, these represent data of several companies, of
> different sizes, for a 11 year period. the distribution is not really
> fitting into any known or close approximation thereto.
>
> is it possible for R to simulate additional 1000 points s.t. the
> resultant distribution closely matches the distribution of the original
> data.
>
> kindly advise.
>
> thanks and best,
> *....*
>
> *Deva*
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________



________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Mon Jun 29 10:49:53 2015
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Mon, 29 Jun 2015 10:49:53 +0200
Subject: [R] Error not reported while checking package "as cran"
Message-ID: <559106B1.2000206@yahoo.fr>

Dear members,

I have submitted to CRAN a new version of a package yesterday after 
checking it "as cran" with the lastest 3.2.1 R version and no error was 
reported.
The command I used was: R CMD check 'xxx/HelpersMG' --as-cran

However, I received reports from CRAN maintainers that I should add 
imports in the NAMESPACE. The missings were some base package (utils, 
graphics, etc), for example:
##############
* checking R code for possible problems ... NOTE
.BinomialConfidence : bc: no visible global function definition for 'qf'
.BinomialConfidence : bc: no visible global function definition for 'qnorm'
.... [I cut here]
##############

I have installed the devel version 3.3.0 but again using : R CMD check 
'xxx/HelpersMG' --as-cran
I don't get any error:

##############
* using log directory ?xxx/HelpersMG.Rcheck?
* using R Under development (unstable) (2015-06-26 r68594)
* using platform: x86_64-apple-darwin13.4.0 (64-bit)
* using session charset: UTF-8
* using option ?--as-cran?
.... [I cut here]
* checking PDF version of manual ... OK
* DONE

Status: OK
##############

How do the same test as the one done when the package is submitted to 
CRAN ? CRAN maintainers are doing a huge work and I would like to make 
their work more simple !

Thanks,

Marc


From henrik.bengtsson at ucsf.edu  Mon Jun 29 13:18:42 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Mon, 29 Jun 2015 04:18:42 -0700
Subject: [R] Error not reported while checking package "as cran"
In-Reply-To: <559106B1.2000206@yahoo.fr>
References: <559106B1.2000206@yahoo.fr>
Message-ID: <CAFDcVCRbSov55vbAUCzrwnj5EgBCet4r3VTcRuc=1MDzxAQGWA@mail.gmail.com>

Seems to be a very very recent update/requirement that hits you.  Your R
devel version might actually be "too old" and you need to install a more
recent one.

Henrik
On Jun 29, 2015 1:49 AM, "Marc Girondot" <marc_grt at yahoo.fr> wrote:

> Dear members,
>
> I have submitted to CRAN a new version of a package yesterday after
> checking it "as cran" with the lastest 3.2.1 R version and no error was
> reported.
> The command I used was: R CMD check 'xxx/HelpersMG' --as-cran
>
> However, I received reports from CRAN maintainers that I should add
> imports in the NAMESPACE. The missings were some base package (utils,
> graphics, etc), for example:
> ##############
> * checking R code for possible problems ... NOTE
> .BinomialConfidence : bc: no visible global function definition for 'qf'
> .BinomialConfidence : bc: no visible global function definition for 'qnorm'
> .... [I cut here]
> ##############
>
> I have installed the devel version 3.3.0 but again using : R CMD check
> 'xxx/HelpersMG' --as-cran
> I don't get any error:
>
> ##############
> * using log directory ?xxx/HelpersMG.Rcheck?
> * using R Under development (unstable) (2015-06-26 r68594)
> * using platform: x86_64-apple-darwin13.4.0 (64-bit)
> * using session charset: UTF-8
> * using option ?--as-cran?
> .... [I cut here]
> * checking PDF version of manual ... OK
> * DONE
>
> Status: OK
> ##############
>
> How do the same test as the one done when the package is submitted to CRAN
> ? CRAN maintainers are doing a huge work and I would like to make their
> work more simple !
>
> Thanks,
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From smaskar at gmail.com  Mon Jun 29 03:23:12 2015
From: smaskar at gmail.com (Santosh Maskar)
Date: Mon, 29 Jun 2015 06:53:12 +0530
Subject: [R] Remote Connection
Message-ID: <55909E00.9080609@gmail.com>

Hello All,

I am having trouble connecting remotely to R. Following is my current setup.

I have windows 8 as a host OS and Ubuntu 14 running in VM inside 
windows. I wanted to connect from windows to R running on Ubuntu VM. I 
cant see any configuration file at /etc/Rserv.conf

Can you point to the document where I can find more details about remote 
connection.

thanks,
Santosh


From bryar-ahmed at hotmail.co.uk  Mon Jun 29 13:38:44 2015
From: bryar-ahmed at hotmail.co.uk (bryar kadir)
Date: Mon, 29 Jun 2015 12:38:44 +0100
Subject: [R] Adding colorbar to polygon plot
Message-ID: <DUB129-W51BD8FAB66422F5446DE04A0AA0@phx.gbl>

Dear members, 
I wish to create many circles and split them into sectors then colour the sectors based on value attributed to the plot, then plot a colormap. 
I have thus far been able to create the polygons, create the colorbar and colour the sectors, but i know for a fact the colour isn't representative of the value inside the sectors. 
Any ideas how to adjust the function(s) so that the colour is representative of the value attributed to the sector? 

## Get circle pointscircs <- function(radii, sectors=4) {  radii <- sort(radii)  rads <- seq(0, 2*pi, length=2*length(radii)*sectors)      # sample at these radians  do.call(rbind, lapply(radii, function(r)                   # points for drawing circles    data.frame(X=r*cos(rads), Y=r*sin(rads),                sector=rep(1:sectors, each=length(rads)/sectors),               theta=rads, radius=r)))}
## Draw figuredrawCirc <- function(radii, sectors, hues=NULL, densities=NULL, ...) {  polys <- circs(radii, sectors)  if (missing(hues)) {    colors <- colorRampPalette(c("green","yellow","red","blue"))(sectors*length(radii))    } else     colors <- heat.colors(n=sectors*length(radii),alpha=hues)  ind=0  plot(polys[,1:2], type="n" ,...)     # blank plot  for (i in seq_along(radii))  {  # add polygons    for (j in 1:sectors) {      ind <- ind+1      color <- colors[ind]      with(polys[polys$sector==j,],           if (i == 1) {             polygon(x=c(0, X[radius==radii[i]], 0), y=c(0, Y[radius==radii[i]], 0),                      col=color, density=densities[ind])           } else             polygon(x=c(X[radius==radii[i-1]], rev(X[radius==radii[i]])),                     y=c(Y[radius==radii[i-1]], rev(Y[radius==radii[i]])),                      col=color, density=densities[ind]))    }  }  cols<-colorRampPalette(c("blue","red","yellow","green"))(sectors*length(radii))  vertical.image.legend(col=cols, zlim=range(c(1,0)))}
drawCirc(radii=1:50, sectors=24, main="Ratio by Colors")
Please note, that the hues allows for the transparency to take into account the values of the sectors but i want the colours to be fully opaque not transparent. As this causes issues with the colorbar on the right hand side. 
Thank you in advance for any suggestion. 
bryar 		 	   		  
	[[alternative HTML version deleted]]


From kasterma.rhelp at gmail.com  Mon Jun 29 14:39:57 2015
From: kasterma.rhelp at gmail.com (Bbb bkbkbk)
Date: Mon, 29 Jun 2015 14:39:57 +0200
Subject: [R] unlisting dplyr do output
In-Reply-To: <D1B071B8.62210%n.l.pace@utah.edu>
References: <D1B071B8.62210%n.l.pace@utah.edu>
Message-ID: <CAOpA3+KLEeaCBvc5xPeqDxdw_EakqBB0ojnXRxdkkkOfzXHcsw@mail.gmail.com>

If I read you code right you have in every loop iteration a reallocation of
memory which gets progressively larger.  If you allocate the whole data
frame
at the beginning and only set the values in the loop it should speed up
lots.

On Wed, Jun 24, 2015 at 10:39 PM, Nathan Pace <n.l.pace at utah.edu> wrote:

> I used the dplyr do function to apply a kernel regression smoother to a 3
> column data table (grouping index, x, y) with about 7 M rows and 45000
> groups.
>
> This runs quickly, about 1-2 minutes.
>
> It creates an data table (44,326 by 2) - grouping index, kernel smoothing
> output.
>
> The kernel smoothing output is a list of two element lists (x, smoothed y).
>
> I used a for loop to unlist this into a data table.
>
>   for (i in 1:nrow(do object)) {
> df <- bind_rows(list(df,
>                                   data.frame(grouping index = do object[i],
>                                              x = do object[[i]]$x,
>                                              y = do object[[i]]$smoothed
> y)))
> }
>
>
> This takes about 100 minutes.
>
> Any guidance for a faster (more elegant?) solution will be appreciated.
>
> Nathan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From abistat at gmail.com  Mon Jun 29 09:12:23 2015
From: abistat at gmail.com (Abinash Adhikari)
Date: Mon, 29 Jun 2015 12:42:23 +0530
Subject: [R] Forecasting and auto.arima issue - Time Series Analysis
	Assistance
Message-ID: <CAPaUdsoviU3A3dBnVPQKWo0x03CJBdbeWWknC0_J5OLDoo_8AA@mail.gmail.com>

Dear Sir,

This is Abinash, a Statistics and Data Science Explorer, based in India. To
inform you, I am currently working on an automated time series forecasting
rule engine where we will build time series models for daily/monthly
internet usage for different customers/segments etc. I was checking a test
case (a specific segment), where we have monthly internet usage values (in
MB) for 13 months starting from April 2014 and ending at April 2015. I
tried to find out a high precision model but ended with confusion about
selecting the best model. Below are the data and my findings. Please assist
me in selecting the right approach/model.

*The Time Series Data is as follows:*

                             TimeValueApr-14412May-14433.3Jun-14446.6Jul-14
468.9Aug-14441.2Sep-14467.2Oct-14480.4Nov-14519Dec-14510.6Jan-15523.7Feb-15
523Mar-15578.7Apr-15655.8

13 months? internet usage values ? the time series data

   1.

   This time series is non-seasonal (having only 13 values with frequency =
   12, monthly data)
   2.

   acf shows ma term as 1
   3.

   pacf shows ar term as 0
   4.

   kpss test shows difference should be of order 1 to make the data
   stationary
   5.

   adf test shows difference should be of order 3 to make the data
   stationary

Hence as per above acf, pacf, adf and kpss tests the final model should be
arima(0,3,1)

but I am getting aic = 106.1298 and mape = 5.900683 if I use the model
arima(0,3,1)

I am getting two better models with the below aic and MAPE

arima(1,3,0) aic = 102.7753, mape = 5.415326

arima(9,3,17) aic = 15.4278, mape = 0.0211097

Also, if I use *auto.arima* I am getting the arima model as *arima(0,1,0)
with drift* where aic = 107.5 and mape = 4.366589

I have finally chosen the model as arima(9,3,17), based on lowest aic
(15.43) and mape (0.0211). But I doubt how one can fit arima with *ar term
9 and ma term 17* when we have only *13 months'* values, and it is coming
as the best fitted model !!!

My questions are

   1.

   Have I fitted the models correctly?
   2.

   Can we fit the model arima(9,3,17) for a series which is having only 13
   month?s values ?
   3.

   Was the approach right?
   4.

   Is there any other better model that can be fitted to this data?
   5.

   Why auto.arima is not giving me the right model? Is there anything wrong
   in selecting model, defining parameters?

Please assist me in fitting a right model (arima or any other suitable
model) for this data which will have a high accuracy and a good logic
behind fitting the model, as the general approach (time series steps and
auto.arima) is failing here, it seems. Awaiting your positive response.
Glad to connect with you. Thanks in advance

Best Regards,
Abinash Adhikari,
Data Scientist (Statistician)
Contact Number: +91 9007654437

	[[alternative HTML version deleted]]


From p.jayashree93 at gmail.com  Mon Jun 29 05:18:39 2015
From: p.jayashree93 at gmail.com (Jayashree Pougajendy)
Date: Mon, 29 Jun 2015 08:48:39 +0530
Subject: [R] Probability distribution on doc-topic in topic modelling using
 package TopicModels
Message-ID: <CANfzT3JasYQ4yx3SMYopTV8eTpALSb9W5A0FCzQktJhjnmkqyw@mail.gmail.com>

I have topic modelled a dataset consisting of 348 documents. The result
that I have obtained from "TopicModels" package is the list of terms under
each topic.

Now, can anyone help me on how to find the probability distribution of a
topic on a doc. To be more precise, I need a matrix with rows as doc and
cols and topics and entries as probabilities. How to perform this in 'R'?
Pls help!


With Regards,
Jayashree P.

	[[alternative HTML version deleted]]


From cscherb1 at gwdg.de  Mon Jun 29 17:23:12 2015
From: cscherb1 at gwdg.de (Christoph Scherber)
Date: Mon, 29 Jun 2015 17:23:12 +0200
Subject: [R] Simulate multinomial data
Message-ID: <559162E0.7090409@gwdg.de>

Dear all,

How do I simulate a dataset where the response variable has 30 classes?

I tried:


##
set.seed(0)
x = sort(runif(1000,1,4))

a = 1.2 
b = 1.2  
y_det= a+b*poly(x,3)

# for a normal distribution, I would use:
ynorm = rnorm(1000,y_det)   

# but how would I do it for a multinomial?

ymult=rmultinom(.....,)


##
Many thanks and best wishes,
Christoph

[using R 3.1.1 on Windows 7 64-Bit]





-- 
PD Dr. Christoph Scherber
Senior Lecturer
DNPW, Agroecology
University of Goettingen
Grisebachstrasse 6
37077 Goettingen
Germany
telephone +49 551 39 8807
facsimile +49 551 39 8806
www.gwdg.de/~cscherb1


From macqueen1 at llnl.gov  Mon Jun 29 17:36:35 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 29 Jun 2015 15:36:35 +0000
Subject: [R] Simulate multinomial data
In-Reply-To: <559162E0.7090409@gwdg.de>
References: <559162E0.7090409@gwdg.de>
Message-ID: <D1B6B3E0.130015%macqueen1@llnl.gov>

See the combinat package:

combinat::rmultinomial
     Generate random samples from multinomial distributions


-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/29/15, 8:23 AM, "R-help on behalf of Christoph Scherber"
<r-help-bounces at r-project.org on behalf of cscherb1 at gwdg.de> wrote:

>Dear all,
>
>How do I simulate a dataset where the response variable has 30 classes?
>
>I tried:
>
>
>##
>set.seed(0)
>x = sort(runif(1000,1,4))
>
>a = 1.2 
>b = 1.2  
>y_det= a+b*poly(x,3)
>
># for a normal distribution, I would use:
>ynorm = rnorm(1000,y_det)
>
># but how would I do it for a multinomial?
>
>ymult=rmultinom(.....,)
>
>
>##
>Many thanks and best wishes,
>Christoph
>
>[using R 3.1.1 on Windows 7 64-Bit]
>
>
>
>
>
>-- 
>PD Dr. Christoph Scherber
>Senior Lecturer
>DNPW, Agroecology
>University of Goettingen
>Grisebachstrasse 6
>37077 Goettingen
>Germany
>telephone +49 551 39 8807
>facsimile +49 551 39 8806
>www.gwdg.de/~cscherb1
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Mon Jun 29 17:44:21 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 29 Jun 2015 11:44:21 -0400
Subject: [R] Spline Graphs
In-Reply-To: <CAKuYVCVn4xMcynOeyG31j8ySfHr6Mxsax91W=POrkcE=U6jHjA@mail.gmail.com>
References: <CAKuYVCVn4xMcynOeyG31j8ySfHr6Mxsax91W=POrkcE=U6jHjA@mail.gmail.com>
Message-ID: <CAM_vjukfjjiQe4Wtu_A0y7rn62FPCN8HDm0+5y-pWhcfmbGthQ@mail.gmail.com>

Hi,

That's not really enough information to help you. Why don't you do
some research on your own, and come back with a better-formulated
question?

A search at http://rseek.org/ for
spline longitudinal data
finds a lot of material that will help you get started.

Sarah

On Mon, Jun 29, 2015 at 2:28 AM, deva d <devazresearch at gmail.com> wrote:
> I wish to analyse longitudinal data and fit spline graphs to it looking to
> the data pattern.
>
> can someone suggest some starting point, and package in R to be used for
> it.
>
> what would be the requirement for structuring the raw data.
>
> *....*
>
> *Deva*

-- 
Sarah Goslee
http://www.functionaldiversity.org


From cscherb1 at gwdg.de  Mon Jun 29 17:50:54 2015
From: cscherb1 at gwdg.de (Christoph Scherber)
Date: Mon, 29 Jun 2015 17:50:54 +0200
Subject: [R] Simulate multinomial data
In-Reply-To: <D1B6B3E0.130015%macqueen1@llnl.gov>
References: <559162E0.7090409@gwdg.de> <D1B6B3E0.130015%macqueen1@llnl.gov>
Message-ID: <5591695E.3030603@gwdg.de>

Dear Don,

True, but what I need is a sample  *for a given explanatory variable*, where class memberships are
defined in response to an underlying variable x (and known regression parameters a, b).

Have you had a look at the code and do you see a way to modify it for rmultinom?

Thanks a lot and best wishes
Christoph

##

##
set.seed(0)
x = sort(runif(1000,1,4))

a = 1.2 
b = 1.2  
y_det= a+b*poly(x,3)

# for a normal distribution, I would use:
ynorm = rnorm(1000,y_det)   

# but how would I do it for a multinomial?

ymult=rmultinom(.....)







Am 29/06/2015 um 17:36 schrieb MacQueen, Don:
> See the combinat package:
>
> combinat::rmultinomial
>      Generate random samples from multinomial distributions
>
>
> -Don
>


-- 
PD Dr. Christoph Scherber
Senior Lecturer
DNPW, Agroecology
University of Goettingen
Grisebachstrasse 6
37077 Goettingen
Germany
telephone +49 551 39 8807
facsimile +49 551 39 8806
www.gwdg.de/~cscherb1


From ggrothendieck at gmail.com  Mon Jun 29 17:57:49 2015
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 29 Jun 2015 11:57:49 -0400
Subject: [R] Spline Graphs
In-Reply-To: <CAKuYVCVn4xMcynOeyG31j8ySfHr6Mxsax91W=POrkcE=U6jHjA@mail.gmail.com>
References: <CAKuYVCVn4xMcynOeyG31j8ySfHr6Mxsax91W=POrkcE=U6jHjA@mail.gmail.com>
Message-ID: <CAP01uR=DxC04iD9LH4hd9eBs2LBUg7UZANj0sK9B6=G647gMsg@mail.gmail.com>

Sorry if this appears twice but I am not sure the first attempt got through.

This is not much to go on but here is a short self contained example which
creates a longitudinal data frame L in long form from the built in data
frame BOD and then plots it as points and splines using lattice:

L <- rbind(cbind(Id = 1, BOD), cbind(Id = 2, BOD))
library(lattice)
xyplot(demand ~ Time | Id, L, type = c("p", "spline"))

On Mon, Jun 29, 2015 at 2:28 AM, deva d <devazresearch at gmail.com> wrote:

> I wish to analyse longitudinal data and fit spline graphs to it looking to
> the data pattern.
>
> can someone suggest some starting point, and package in R to be used for
> it.
>
> what would be the requirement for structuring the raw data.
>
> *....*
>
> *Deva*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Jun 29 18:10:50 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 29 Jun 2015 09:10:50 -0700
Subject: [R] Simulate multinomial data
In-Reply-To: <559162E0.7090409@gwdg.de>
References: <559162E0.7090409@gwdg.de>
Message-ID: <CAGxFJbR1q5d6cy0mTvSWinWwgn_gAnUcs0_v1iLFaUnvNB7gBg@mail.gmail.com>

Ye gods!

R has a search function. Please learn to use it before posting here.

??multinomial


Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Mon, Jun 29, 2015 at 8:23 AM, Christoph Scherber <cscherb1 at gwdg.de> wrote:
> Dear all,
>
> How do I simulate a dataset where the response variable has 30 classes?
>
> I tried:
>
>
> ##
> set.seed(0)
> x = sort(runif(1000,1,4))
>
> a = 1.2
> b = 1.2
> y_det= a+b*poly(x,3)
>
> # for a normal distribution, I would use:
> ynorm = rnorm(1000,y_det)
>
> # but how would I do it for a multinomial?
>
> ymult=rmultinom(.....,)
>
>
> ##
> Many thanks and best wishes,
> Christoph
>
> [using R 3.1.1 on Windows 7 64-Bit]
>
>
>
>
>
> --
> PD Dr. Christoph Scherber
> Senior Lecturer
> DNPW, Agroecology
> University of Goettingen
> Grisebachstrasse 6
> 37077 Goettingen
> Germany
> telephone +49 551 39 8807
> facsimile +49 551 39 8806
> www.gwdg.de/~cscherb1
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Jun 29 18:14:41 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 29 Jun 2015 09:14:41 -0700
Subject: [R] Simulate multinomial data
In-Reply-To: <5591695E.3030603@gwdg.de>
References: <559162E0.7090409@gwdg.de> <D1B6B3E0.130015%macqueen1@llnl.gov>
	<5591695E.3030603@gwdg.de>
Message-ID: <CAGxFJbSXytHg2n_5NSBE5znZKtER_4C5-7P_=TymGf_en1oYQw@mail.gmail.com>

... and presumably the probabilities for class memberships are given
by your function of the explanatory variable. So you just plug in your
(30?) values of x, no?

-- Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Mon, Jun 29, 2015 at 8:50 AM, Christoph Scherber <cscherb1 at gwdg.de> wrote:
> Dear Don,
>
> True, but what I need is a sample  *for a given explanatory variable*, where class memberships are
> defined in response to an underlying variable x (and known regression parameters a, b).
>
> Have you had a look at the code and do you see a way to modify it for rmultinom?
>
> Thanks a lot and best wishes
> Christoph
>
> ##
>
> ##
> set.seed(0)
> x = sort(runif(1000,1,4))
>
> a = 1.2
> b = 1.2
> y_det= a+b*poly(x,3)
>
> # for a normal distribution, I would use:
> ynorm = rnorm(1000,y_det)
>
> # but how would I do it for a multinomial?
>
> ymult=rmultinom(.....)
>
>
>
>
>
>
>
> Am 29/06/2015 um 17:36 schrieb MacQueen, Don:
>> See the combinat package:
>>
>> combinat::rmultinomial
>>      Generate random samples from multinomial distributions
>>
>>
>> -Don
>>
>
>
> --
> PD Dr. Christoph Scherber
> Senior Lecturer
> DNPW, Agroecology
> University of Goettingen
> Grisebachstrasse 6
> 37077 Goettingen
> Germany
> telephone +49 551 39 8807
> facsimile +49 551 39 8806
> www.gwdg.de/~cscherb1
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bryar-ahmed at hotmail.co.uk  Mon Jun 29 17:15:40 2015
From: bryar-ahmed at hotmail.co.uk (bryar kadir)
Date: Mon, 29 Jun 2015 16:15:40 +0100
Subject: [R] Adding colorbar to polygon plot
In-Reply-To: <DUB129-W51BD8FAB66422F5446DE04A0AA0@phx.gbl>
References: <DUB129-W51BD8FAB66422F5446DE04A0AA0@phx.gbl>
Message-ID: <DUB129-W6032E35E99A2CCF53ED038A0AA0@phx.gbl>

Sorry the code is suppose to look as follows:

## Get circle points
circs <- function(radii, sectors=4) {
  radii <- sort(radii)
  rads <- seq(0, 2*pi, length=2*length(radii)*sectors)      # sample at these radians
  do.call(rbind, lapply(radii, function(r)                   # points for drawing circles
    data.frame(X=r*cos(rads), Y=r*sin(rads), 
               sector=rep(1:sectors, each=length(rads)/sectors),
               theta=rads, radius=r)))
}


## Draw figure
drawCirc <- function(radii, sectors, hues=NULL, densities=NULL, ...) {
  polys <- circs(radii, sectors)
  if (missing(hues)) {
    colors <- colorRampPalette(c("green","yellow","red","blue"))(sectors*length(radii))
    } else 
    colors <- heat.colors(n=sectors*length(radii),alpha=hues)
  ind=0
  plot(polys[,1:2], type="n" ,...)     # blank plot
  for (i in seq_along(radii))  {  # add polygons
    for (j in 1:sectors) {
      ind <- ind+1
      color <- colors[ind]
      with(polys[polys$sector==j,],
           if (i == 1) {
             polygon(x=c(0, X[radius==radii[i]], 0), y=c(0, Y[radius==radii[i]], 0), 
                     col=color, density=densities[ind])
           } else
             polygon(x=c(X[radius==radii[i-1]], rev(X[radius==radii[i]])),
                     y=c(Y[radius==radii[i-1]], rev(Y[radius==radii[i]])), 
                     col=color, density=densities[ind]))
    }
  }
  cols<-colorRampPalette(c("blue","red","yellow","green"))(sectors*length(radii))
  vertical.image.legend(col=cols, zlim=range(c(1,0)))
}


drawCirc(radii=1:50, sectors=24, main="Ratio by Colors")


Please note, that the hues allows for the transparency to take into account the values of the sectors but i want the colours to be fully opaque not transparent. As this causes issues with the colorbar on the right hand side. 

Thank you in advance for any suggestion. 
bryar
 		 	   		  
	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Mon Jun 29 21:49:34 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 29 Jun 2015 19:49:34 +0000
Subject: [R] Simulate multinomial data
In-Reply-To: <CAGxFJbSXytHg2n_5NSBE5znZKtER_4C5-7P_=TymGf_en1oYQw@mail.gmail.com>
References: <559162E0.7090409@gwdg.de> <D1B6B3E0.130015%macqueen1@llnl.gov>
	<5591695E.3030603@gwdg.de>
	<CAGxFJbSXytHg2n_5NSBE5znZKtER_4C5-7P_=TymGf_en1oYQw@mail.gmail.com>
Message-ID: <D1B6E7E5.1300A7%macqueen1@llnl.gov>

Christoph,

If I may expand on Bert's suggestion...

Try this sequence of uses of rmultinom().
 rmultinom(5, 1, c(.1, .2, .7))
 rmultinom(5, 10, c(.1, .2, .7))
 rmultinom(5, 100, c(.1, .2, .7))

Hopefully the output will help explain how rmultinom() works.

For your application, I assume you would replace the first argument, 5,
with 1000.

For the second argument you probably want 1, based on your rnorm()
example. 

For the third argument, you need the probabilities of however many classes
your multinomial has (three classes in the above examples, but I don't
know how many classes you want).

How you get those probabilities from your
  y_det= a+b*poly(x,3)
is not obvious.

You said "... class memberships are defined in response to an underlying
variable ...". How are they defined? That should lead you to how to
calculate the class probabilities, I would think.

-Don


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/29/15, 9:14 AM, "Bert Gunter" <bgunter.4567 at gmail.com> wrote:

>... and presumably the probabilities for class memberships are given
>by your function of the explanatory variable. So you just plug in your
>(30?) values of x, no?
>
>-- Bert
>
>
>Bert Gunter
>
>"Data is not information. Information is not knowledge. And knowledge
>is certainly not wisdom."
>   -- Clifford Stoll
>
>
>On Mon, Jun 29, 2015 at 8:50 AM, Christoph Scherber <cscherb1 at gwdg.de>
>wrote:
>> Dear Don,
>>
>> True, but what I need is a sample  *for a given explanatory variable*,
>>where class memberships are
>> defined in response to an underlying variable x (and known regression
>>parameters a, b).
>>
>> Have you had a look at the code and do you see a way to modify it for
>>rmultinom?
>>
>> Thanks a lot and best wishes
>> Christoph
>>
>> ##
>>
>> ##
>> set.seed(0)
>> x = sort(runif(1000,1,4))
>>
>> a = 1.2
>> b = 1.2
>> y_det= a+b*poly(x,3)
>>
>> # for a normal distribution, I would use:
>> ynorm = rnorm(1000,y_det)
>>
>> # but how would I do it for a multinomial?
>>
>> ymult=rmultinom(.....)
>>
>>
>>
>>
>>
>>
>>
>> Am 29/06/2015 um 17:36 schrieb MacQueen, Don:
>>> See the combinat package:
>>>
>>> combinat::rmultinomial
>>>      Generate random samples from multinomial distributions
>>>
>>>
>>> -Don
>>>
>>
>>
>> --
>> PD Dr. Christoph Scherber
>> Senior Lecturer
>> DNPW, Agroecology
>> University of Goettingen
>> Grisebachstrasse 6
>> 37077 Goettingen
>> Germany
>> telephone +49 551 39 8807
>> facsimile +49 551 39 8806
>> www.gwdg.de/~cscherb1
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Mon Jun 29 22:19:37 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 29 Jun 2015 13:19:37 -0700
Subject: [R] Remote Connection
In-Reply-To: <55909E00.9080609@gmail.com>
References: <55909E00.9080609@gmail.com>
Message-ID: <82A8C076-E334-41E9-B5CC-4AFF0240140A@dcn.davis.CA.us>

My preference would be to use the "parallel" package, though offloading computation to a VM on your machine is actually likely to lead to a performance reduction.

Based on the file name you are complaining about, you should probably read the documentation for the Rserv package. Be sure your VM is configured to participate in your local network directly... network address translation that is often used for "local" VM usage will probably not work., but that issue is not on-topic here... that is standard networking setup.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 28, 2015 6:23:12 PM PDT, Santosh Maskar <smaskar at gmail.com> wrote:
>Hello All,
>
>I am having trouble connecting remotely to R. Following is my current
>setup.
>
>I have windows 8 as a host OS and Ubuntu 14 running in VM inside 
>windows. I wanted to connect from windows to R running on Ubuntu VM. I 
>cant see any configuration file at /etc/Rserv.conf
>
>Can you point to the document where I can find more details about
>remote 
>connection.
>
>thanks,
>Santosh
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Jun 29 22:29:29 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 30 Jun 2015 06:29:29 +1000
Subject: [R] Adding colorbar to polygon plot
In-Reply-To: <DUB129-W6032E35E99A2CCF53ED038A0AA0@phx.gbl>
References: <DUB129-W51BD8FAB66422F5446DE04A0AA0@phx.gbl>
	<DUB129-W6032E35E99A2CCF53ED038A0AA0@phx.gbl>
Message-ID: <CA+8X3fWsKdJTAfWv7XQ=_29Af4zbKV1p9_r49eSbEkBObSZrtg@mail.gmail.com>

Hi bryar,
I think your problem is in the distribution of the range of colors.
Look at the examples for the "color.legend" and "barp" functions in
the plotrix package to get this right.

Jim


On Tue, Jun 30, 2015 at 1:15 AM, bryar kadir <bryar-ahmed at hotmail.co.uk> wrote:
> Sorry the code is suppose to look as follows:
>
> ## Get circle points
> circs <- function(radii, sectors=4) {
>   radii <- sort(radii)
>   rads <- seq(0, 2*pi, length=2*length(radii)*sectors)      # sample at these radians
>   do.call(rbind, lapply(radii, function(r)                   # points for drawing circles
>     data.frame(X=r*cos(rads), Y=r*sin(rads),
>                sector=rep(1:sectors, each=length(rads)/sectors),
>                theta=rads, radius=r)))
> }
>
>
> ## Draw figure
> drawCirc <- function(radii, sectors, hues=NULL, densities=NULL, ...) {
>   polys <- circs(radii, sectors)
>   if (missing(hues)) {
>     colors <- colorRampPalette(c("green","yellow","red","blue"))(sectors*length(radii))
>     } else
>     colors <- heat.colors(n=sectors*length(radii),alpha=hues)
>   ind=0
>   plot(polys[,1:2], type="n" ,...)     # blank plot
>   for (i in seq_along(radii))  {  # add polygons
>     for (j in 1:sectors) {
>       ind <- ind+1
>       color <- colors[ind]
>       with(polys[polys$sector==j,],
>            if (i == 1) {
>              polygon(x=c(0, X[radius==radii[i]], 0), y=c(0, Y[radius==radii[i]], 0),
>                      col=color, density=densities[ind])
>            } else
>              polygon(x=c(X[radius==radii[i-1]], rev(X[radius==radii[i]])),
>                      y=c(Y[radius==radii[i-1]], rev(Y[radius==radii[i]])),
>                      col=color, density=densities[ind]))
>     }
>   }
>   cols<-colorRampPalette(c("blue","red","yellow","green"))(sectors*length(radii))
>   vertical.image.legend(col=cols, zlim=range(c(1,0)))
> }
>
>
> drawCirc(radii=1:50, sectors=24, main="Ratio by Colors")
>
>
> Please note, that the hues allows for the transparency to take into account the values of the sectors but i want the colours to be fully opaque not transparent. As this causes issues with the colorbar on the right hand side.
>
> Thank you in advance for any suggestion.
> bryar
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sergio.fonda99 at gmail.com  Mon Jun 29 23:19:42 2015
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Mon, 29 Jun 2015 23:19:42 +0200
Subject: [R] Stream package
In-Reply-To: <CAJRuHornNQBLx5AWFahra9kp6W=Hwgh_QAkTFLcqaC7JG7adhQ@mail.gmail.com>
References: <CAJRuHornNQBLx5AWFahra9kp6W=Hwgh_QAkTFLcqaC7JG7adhQ@mail.gmail.com>
Message-ID: <CAJRuHopeJ0RGRw8E_P9gBEN87Z-XnXgiu_KMMEWsyJMoThi7pg@mail.gmail.com>

"stream" package is devoted to cluster prediction and processing in data
streaming condition.
Is it convenient also for realtime signal processing ( filtering, EMD, etc.)
Thank you for any remark!
Sergio

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Jun 29 23:48:38 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 29 Jun 2015 14:48:38 -0700
Subject: [R] Stream package
In-Reply-To: <CAJRuHopeJ0RGRw8E_P9gBEN87Z-XnXgiu_KMMEWsyJMoThi7pg@mail.gmail.com>
References: <CAJRuHornNQBLx5AWFahra9kp6W=Hwgh_QAkTFLcqaC7JG7adhQ@mail.gmail.com>
	<CAJRuHopeJ0RGRw8E_P9gBEN87Z-XnXgiu_KMMEWsyJMoThi7pg@mail.gmail.com>
Message-ID: <11CEE6C8-5D2F-4A1C-9433-67FBC8CD776C@dcn.davis.CA.us>

"Real time" is a squishy term. Your question is not one that can be answered here, since it is so context dependent.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 29, 2015 2:19:42 PM PDT, Sergio Fonda <sergio.fonda99 at gmail.com> wrote:
>"stream" package is devoted to cluster prediction and processing in
>data
>streaming condition.
>Is it convenient also for realtime signal processing ( filtering, EMD,
>etc.)
>Thank you for any remark!
>Sergio
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sergio.fonda99 at gmail.com  Tue Jun 30 00:08:21 2015
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Tue, 30 Jun 2015 00:08:21 +0200
Subject: [R] Stream package
In-Reply-To: <11CEE6C8-5D2F-4A1C-9433-67FBC8CD776C@dcn.davis.CA.us>
References: <CAJRuHornNQBLx5AWFahra9kp6W=Hwgh_QAkTFLcqaC7JG7adhQ@mail.gmail.com>
	<CAJRuHopeJ0RGRw8E_P9gBEN87Z-XnXgiu_KMMEWsyJMoThi7pg@mail.gmail.com>
	<11CEE6C8-5D2F-4A1C-9433-67FBC8CD776C@dcn.davis.CA.us>
Message-ID: <CAJRuHoqV4efZCxhAzwB5BS-Y7XdQKbMp01u7p11rAPMaWZ0zBg@mail.gmail.com>

Ok you are rigth.  However, suppose for example to have to establish the
performance of a "peak finding" algorithm by means of a simulation using a
signal sampled at 2kHz. I'm not able to decide if stream is an adequate
environment to reach a conclusion about algorithm.
Thanks!
Il 29/giu/2015 23:48, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> ha
scritto:

> "Real time" is a squishy term. Your question is not one that can be
> answered here, since it is so context dependent.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On June 29, 2015 2:19:42 PM PDT, Sergio Fonda <sergio.fonda99 at gmail.com>
> wrote:
> >"stream" package is devoted to cluster prediction and processing in
> >data
> >streaming condition.
> >Is it convenient also for realtime signal processing ( filtering, EMD,
> >etc.)
> >Thank you for any remark!
> >Sergio
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Tue Jun 30 00:18:34 2015
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Tue, 30 Jun 2015 00:18:34 +0200
Subject: [R] Error not reported while checking package "as cran"
In-Reply-To: <CAFDcVCRbSov55vbAUCzrwnj5EgBCet4r3VTcRuc=1MDzxAQGWA@mail.gmail.com>
References: <559106B1.2000206@yahoo.fr>
	<CAFDcVCRbSov55vbAUCzrwnj5EgBCet4r3VTcRuc=1MDzxAQGWA@mail.gmail.com>
Message-ID: <5591C43A.7030305@yahoo.fr>

Hi Henrik (and people in the list !)

Right ! The last daily devel version shows these errors.

Sincerely,

Marc


Le 29/06/2015 13:18, Henrik Bengtsson a ?crit :
>
> Seems to be a very very recent update/requirement that hits you.  Your 
> R devel version might actually be "too old" and you need to install a 
> more recent one.
>
> Henrik
>
> On Jun 29, 2015 1:49 AM, "Marc Girondot" <marc_grt at yahoo.fr 
> <mailto:marc_grt at yahoo.fr>> wrote:
>
>     Dear members,
>
>     I have submitted to CRAN a new version of a package yesterday
>     after checking it "as cran" with the lastest 3.2.1 R version and
>     no error was reported.
>     The command I used was: R CMD check 'xxx/HelpersMG' --as-cran
>
>     However, I received reports from CRAN maintainers that I should
>     add imports in the NAMESPACE. The missings were some base package
>     (utils, graphics, etc), for example:
>     ##############
>     * checking R code for possible problems ... NOTE
>     .BinomialConfidence : bc: no visible global function definition
>     for 'qf'
>     .BinomialConfidence : bc: no visible global function definition
>     for 'qnorm'
>     .... [I cut here]
>     ##############
>
>     I have installed the devel version 3.3.0 but again using : R CMD
>     check 'xxx/HelpersMG' --as-cran
>     I don't get any error:
>
>     ##############
>     * using log directory ?xxx/HelpersMG.Rcheck?
>     * using R Under development (unstable) (2015-06-26 r68594)
>     * using platform: x86_64-apple-darwin13.4.0 (64-bit)
>     * using session charset: UTF-8
>     * using option ?--as-cran?
>     .... [I cut here]
>     * checking PDF version of manual ... OK
>     * DONE
>
>     Status: OK
>     ##############
>
>     How do the same test as the one done when the package is submitted
>     to CRAN ? CRAN maintainers are doing a huge work and I would like
>     to make their work more simple !
>
>     Thanks,
>
>     Marc
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


	[[alternative HTML version deleted]]


From rshepard at appl-ecosys.com  Tue Jun 30 02:03:38 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Mon, 29 Jun 2015 17:03:38 -0700 (PDT)
Subject: [R] Subset() within function: logical error
Message-ID: <alpine.LNX.2.11.1506291655260.12990@localhost>

   Moving from interactive use of R to scripts and functions and have bumped
into what I believe is a problem with variable names. Did not see a solution
in the two R programming books I have or from my Web searches. Inexperience
with ess-tracebug keeps me from refining my bug tracking.

   Here's a test data set (cleverly called 'testset.dput'):

structure(list(stream = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L), .Label = c("B", "J", "S"), class = "factor"),
     sampdate = structure(c(8121, 8121, 8121, 8155, 8155, 8155,
     8185, 8185, 8185, 8205, 8205, 8205, 8236, 8236, 8236, 8257,
     8257, 8257, 8308, 8785, 8785, 8785, 8785, 8785, 8785, 8785,
     8847, 8847, 8847, 8847, 8847, 8847, 8847, 8875, 8875, 8875,
     8875, 8875, 8875, 8875, 8121, 8121, 8121, 8155, 8155, 8155,
     8185, 8185, 8185, 8205, 8205, 8205, 8236, 8236, 8236, 8257,
     8257, 8257, 8301, 8301, 8301), class = "Date"), param = structure(c(2L,
     6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L,
     6L, 7L, 2L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 1L, 2L, 3L, 4L, 5L,
     6L, 7L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L,
     2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L
     ), .Label = c("Ca", "Cl", "K", "Mg", "Na", "SO4", "pH"), class = "factor"),
     quant = c(4, 33, 8.43, 4, 32, 8.46, 4, 31, 8.43, 6, 33, 8.32,
     5, 33, 8.5, 5, 32, 8.5, 5, 59.9, 3.46, 1.48, 29, 7.54, 64.6,
     7.36, 46, 2.95, 1.34, 21.8, 5.76, 48.8, 7.72, 74.2, 5.36,
     2.33, 38.4, 8.27, 141, 7.8, 3, 76, 6.64, 4, 74, 7.46, 2,
     82, 7.58, 5, 106, 7.91, 3, 56, 7.83, 3, 51, 7.6, 6, 149,
     7.73)), .Names = c("stream", "sampdate", "param", "quant"
), row.names = c(NA, -61L), class = "data.frame")

   I want to subset that data.frame on each of the stream names: B, J, and S.
This is the function that has the naming error (eda.R):

extstream = function(alldf) {
     sname = alldf$stream
     sdate = alldf$sampdate
     comp = alldf$param
     value = alldf$quant
     for (i in sname) {
         sname <- subset(alldf, alldf$stream, select = c(sdate, comp, value))
         return(sname)
     }
}

   This is the result of running source('eda.R') followed by

> extstream(testset)
Error in subset.data.frame(alldf, alldf$stream, select = c(sdate, comp,  :
   'subset' must be logical

   I've tried using sname for the rows to select, but that produces a
different error of trying to select undefined columns.

   A pointer to the correct syntax for subset() is needed.

Rich


From steve.taylor at aut.ac.nz  Tue Jun 30 02:26:12 2015
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Tue, 30 Jun 2015 00:26:12 +0000
Subject: [R] Subset() within function: logical error
In-Reply-To: <alpine.LNX.2.11.1506291655260.12990@localhost>
References: <alpine.LNX.2.11.1506291655260.12990@localhost>
Message-ID: <CCE952776B6679469977532BD863C39CB2B16934@Patterson.autuni.aut.ac.nz>

Using return() within a for loop makes no sense: only the first one will be returned.

How about:
alldf.B = subset(alldf, stream=='B')  # etc...

Also, have a look at unique(alldf$stream) or levels(alldf$stream) if you want to use a for loop on each unique value.

cheers,
    Steve

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rich Shepard
Sent: Tuesday, 30 June 2015 12:04p
To: r-help at r-project.org
Subject: [R] Subset() within function: logical error

   Moving from interactive use of R to scripts and functions and have bumped
into what I believe is a problem with variable names. Did not see a solution
in the two R programming books I have or from my Web searches. Inexperience
with ess-tracebug keeps me from refining my bug tracking.

   Here's a test data set (cleverly called 'testset.dput'):

structure(list(stream = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L), .Label = c("B", "J", "S"), class = "factor"),
     sampdate = structure(c(8121, 8121, 8121, 8155, 8155, 8155,
     8185, 8185, 8185, 8205, 8205, 8205, 8236, 8236, 8236, 8257,
     8257, 8257, 8308, 8785, 8785, 8785, 8785, 8785, 8785, 8785,
     8847, 8847, 8847, 8847, 8847, 8847, 8847, 8875, 8875, 8875,
     8875, 8875, 8875, 8875, 8121, 8121, 8121, 8155, 8155, 8155,
     8185, 8185, 8185, 8205, 8205, 8205, 8236, 8236, 8236, 8257,
     8257, 8257, 8301, 8301, 8301), class = "Date"), param = structure(c(2L,
     6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L,
     6L, 7L, 2L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 1L, 2L, 3L, 4L, 5L,
     6L, 7L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L,
     2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L
     ), .Label = c("Ca", "Cl", "K", "Mg", "Na", "SO4", "pH"), class = "factor"),
     quant = c(4, 33, 8.43, 4, 32, 8.46, 4, 31, 8.43, 6, 33, 8.32,
     5, 33, 8.5, 5, 32, 8.5, 5, 59.9, 3.46, 1.48, 29, 7.54, 64.6,
     7.36, 46, 2.95, 1.34, 21.8, 5.76, 48.8, 7.72, 74.2, 5.36,
     2.33, 38.4, 8.27, 141, 7.8, 3, 76, 6.64, 4, 74, 7.46, 2,
     82, 7.58, 5, 106, 7.91, 3, 56, 7.83, 3, 51, 7.6, 6, 149,
     7.73)), .Names = c("stream", "sampdate", "param", "quant"
), row.names = c(NA, -61L), class = "data.frame")

   I want to subset that data.frame on each of the stream names: B, J, and S.
This is the function that has the naming error (eda.R):

extstream = function(alldf) {
     sname = alldf$stream
     sdate = alldf$sampdate
     comp = alldf$param
     value = alldf$quant
     for (i in sname) {
         sname <- subset(alldf, alldf$stream, select = c(sdate, comp, value))
         return(sname)
     }
}

   This is the result of running source('eda.R') followed by

> extstream(testset)
Error in subset.data.frame(alldf, alldf$stream, select = c(sdate, comp,  :
   'subset' must be logical

   I've tried using sname for the rows to select, but that produces a
different error of trying to select undefined columns.

   A pointer to the correct syntax for subset() is needed.

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Jun 30 02:28:16 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 29 Jun 2015 17:28:16 -0700
Subject: [R] Subset() within function: logical error
In-Reply-To: <alpine.LNX.2.11.1506291655260.12990@localhost>
References: <alpine.LNX.2.11.1506291655260.12990@localhost>
Message-ID: <D0133A9A-0F59-4049-A1DE-CDE9CEFAC908@dcn.davis.CA.us>

Well, your code is, ah, too incorrect to convey what you want out of this effort. If I were to guess based on your description, you want all of the data, not a subset. An example data frame containing what you hope to extract might be helpful.

However, extracting subsets is rarely done for just one subset... usually you want to process the data in groups. Base functions such as ave, aggregate, or split work at a higher level than you seem to be thinking. Packages such as plyr and dplyr handle this breaking and recombining more succinctly, leaving you to think more about what you want to do with the pieces and less about making pieces.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 29, 2015 5:03:38 PM PDT, Rich Shepard <rshepard at appl-ecosys.com> wrote:
>Moving from interactive use of R to scripts and functions and have
>bumped
>into what I believe is a problem with variable names. Did not see a
>solution
>in the two R programming books I have or from my Web searches.
>Inexperience
>with ess-tracebug keeps me from refining my bug tracking.
>
>   Here's a test data set (cleverly called 'testset.dput'):
>
>structure(list(stream = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
>2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
>3L, 3L, 3L, 3L, 3L, 3L), .Label = c("B", "J", "S"), class = "factor"),
>     sampdate = structure(c(8121, 8121, 8121, 8155, 8155, 8155,
>     8185, 8185, 8185, 8205, 8205, 8205, 8236, 8236, 8236, 8257,
>     8257, 8257, 8308, 8785, 8785, 8785, 8785, 8785, 8785, 8785,
>     8847, 8847, 8847, 8847, 8847, 8847, 8847, 8875, 8875, 8875,
>     8875, 8875, 8875, 8875, 8121, 8121, 8121, 8155, 8155, 8155,
>     8185, 8185, 8185, 8205, 8205, 8205, 8236, 8236, 8236, 8257,
>8257, 8257, 8301, 8301, 8301), class = "Date"), param = structure(c(2L,
>     6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L,
>     6L, 7L, 2L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 1L, 2L, 3L, 4L, 5L,
>     6L, 7L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L,
>     2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L
>), .Label = c("Ca", "Cl", "K", "Mg", "Na", "SO4", "pH"), class =
>"factor"),
>     quant = c(4, 33, 8.43, 4, 32, 8.46, 4, 31, 8.43, 6, 33, 8.32,
>     5, 33, 8.5, 5, 32, 8.5, 5, 59.9, 3.46, 1.48, 29, 7.54, 64.6,
>     7.36, 46, 2.95, 1.34, 21.8, 5.76, 48.8, 7.72, 74.2, 5.36,
>     2.33, 38.4, 8.27, 141, 7.8, 3, 76, 6.64, 4, 74, 7.46, 2,
>     82, 7.58, 5, 106, 7.91, 3, 56, 7.83, 3, 51, 7.6, 6, 149,
>     7.73)), .Names = c("stream", "sampdate", "param", "quant"
>), row.names = c(NA, -61L), class = "data.frame")
>
>I want to subset that data.frame on each of the stream names: B, J, and
>S.
>This is the function that has the naming error (eda.R):
>
>extstream = function(alldf) {
>     sname = alldf$stream
>     sdate = alldf$sampdate
>     comp = alldf$param
>     value = alldf$quant
>     for (i in sname) {
>   sname <- subset(alldf, alldf$stream, select = c(sdate, comp, value))
>         return(sname)
>     }
>}
>
>   This is the result of running source('eda.R') followed by
>
>> extstream(testset)
>Error in subset.data.frame(alldf, alldf$stream, select = c(sdate, comp,
> :
>   'subset' must be logical
>
>   I've tried using sname for the rows to select, but that produces a
>different error of trying to select undefined columns.
>
>   A pointer to the correct syntax for subset() is needed.
>
>Rich
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Jun 30 02:37:53 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 29 Jun 2015 17:37:53 -0700
Subject: [R] Subset() within function: logical error
In-Reply-To: <alpine.LNX.2.11.1506291655260.12990@localhost>
References: <alpine.LNX.2.11.1506291655260.12990@localhost>
Message-ID: <B7BF50F1-CBD2-42BA-BD5B-B8F3942F28DF@comcast.net>


On Jun 29, 2015, at 5:03 PM, Rich Shepard wrote:

>  Moving from interactive use of R to scripts and functions and have bumped
> into what I believe is a problem with variable names. Did not see a solution
> in the two R programming books I have or from my Web searches. Inexperience
> with ess-tracebug keeps me from refining my bug tracking.
> 
>  Here's a test data set (cleverly called 'testset.dput'):
> 
> structure(list(stream = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label = c("B", "J", "S"), class = "factor"),
>    sampdate = structure(c(8121, 8121, 8121, 8155, 8155, 8155,
>    8185, 8185, 8185, 8205, 8205, 8205, 8236, 8236, 8236, 8257,
>    8257, 8257, 8308, 8785, 8785, 8785, 8785, 8785, 8785, 8785,
>    8847, 8847, 8847, 8847, 8847, 8847, 8847, 8875, 8875, 8875,
>    8875, 8875, 8875, 8875, 8121, 8121, 8121, 8155, 8155, 8155,
>    8185, 8185, 8185, 8205, 8205, 8205, 8236, 8236, 8236, 8257,
>    8257, 8257, 8301, 8301, 8301), class = "Date"), param = structure(c(2L,
>    6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L,
>    6L, 7L, 2L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 1L, 2L, 3L, 4L, 5L,
>    6L, 7L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L,
>    2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L
>    ), .Label = c("Ca", "Cl", "K", "Mg", "Na", "SO4", "pH"), class = "factor"),
>    quant = c(4, 33, 8.43, 4, 32, 8.46, 4, 31, 8.43, 6, 33, 8.32,
>    5, 33, 8.5, 5, 32, 8.5, 5, 59.9, 3.46, 1.48, 29, 7.54, 64.6,
>    7.36, 46, 2.95, 1.34, 21.8, 5.76, 48.8, 7.72, 74.2, 5.36,
>    2.33, 38.4, 8.27, 141, 7.8, 3, 76, 6.64, 4, 74, 7.46, 2,
>    82, 7.58, 5, 106, 7.91, 3, 56, 7.83, 3, 51, 7.6, 6, 149,
>    7.73)), .Names = c("stream", "sampdate", "param", "quant"
> ), row.names = c(NA, -61L), class = "data.frame")
> 
>  I want to subset that data.frame on each of the stream names: B, J, and S.
> This is the function that has the naming error (eda.R):
> 
> extstream = function(alldf) {
>    sname = alldf$stream
>    sdate = alldf$sampdate
>    comp = alldf$param
>    value = alldf$quant
>    for (i in sname) {
>        sname <- subset(alldf, alldf$stream, select = c(sdate, comp, value))


Never use the form dfrm$colname as the argument to the subset argument of subset. You can see that 'stream' is a factor, right? Perhaps 

Furthermore, by inspection you can see that there is no colname =='sdate', so I would guess that would be your next error. Or 'comp' or 'value' for that matter. Oh now I see, you made them outside of `alldf`. Then how is that supposed to work. The subset function is supposed to be looking inside `alldf` to find those column names.


Perhaps:

    subset(alldf, stream %in% c('B', 'J', 'S'),  .... 

....   but have not figured out why you used 'subset' if you wanted: select = c(sdate, comp, value))


Furthermore, it is generally error prone to use `subset` inside functions. The help page warns against the practice. Better to use "[".

>        return(sname)
>    }
> }
> 
>  This is the result of running source('eda.R') followed by
> 
>> extstream(testset)
> Error in subset.data.frame(alldf, alldf$stream, select = c(sdate, comp,  :
>  'subset' must be logical
> 
>  I've tried using sname for the rows to select, but that produces a
> different error of trying to select undefined columns.

Right. Those are not column names in any dataframe.
> 
>  A pointer to the correct syntax for subset() is needed.

No. A pointer to the correct use of "[" is needed.

-- 

David Winsemius
Alameda, CA, USA


From rshepard at appl-ecosys.com  Tue Jun 30 02:38:48 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Mon, 29 Jun 2015 17:38:48 -0700 (PDT)
Subject: [R] Subset() within function: logical error
In-Reply-To: <CCE952776B6679469977532BD863C39CB2B16934@Patterson.autuni.aut.ac.nz>
References: <alpine.LNX.2.11.1506291655260.12990@localhost>
	<CCE952776B6679469977532BD863C39CB2B16934@Patterson.autuni.aut.ac.nz>
Message-ID: <alpine.LNX.2.11.1506291736420.12990@localhost>

On Tue, 30 Jun 2015, Steve Taylor wrote:

> Using return() within a for loop makes no sense: only the first one will be returned.

Steve,

   Mea culpa. Didn't catch that.

> How about:
> alldf.B = subset(alldf, stream=='B')  # etc...

   I used to do each stream manually, like the above, and want to learn how
to loop through all of them ...

> Also, have a look at unique(alldf$stream) or levels(alldf$stream) if you
> want to use a for loop on each unique value.

   ... which unique() and levels() will probably do. Will test these tomorrow
after rading the man pages.

Many thanks,

Rich


From rshepard at appl-ecosys.com  Tue Jun 30 02:41:03 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Mon, 29 Jun 2015 17:41:03 -0700 (PDT)
Subject: [R] Subset() within function: logical error
In-Reply-To: <B7BF50F1-CBD2-42BA-BD5B-B8F3942F28DF@comcast.net>
References: <alpine.LNX.2.11.1506291655260.12990@localhost>
	<B7BF50F1-CBD2-42BA-BD5B-B8F3942F28DF@comcast.net>
Message-ID: <alpine.LNX.2.11.1506291740170.12990@localhost>

On Mon, 29 Jun 2015, David Winsemius wrote:

> No. A pointer to the correct use of "[" is needed.

   Thanks, David. This puts me on the the right path.

Much appreciated,

Rich


From r.turner at auckland.ac.nz  Tue Jun 30 02:52:20 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 30 Jun 2015 12:52:20 +1200
Subject: [R] Subset() within function: logical error
In-Reply-To: <alpine.LNX.2.11.1506291655260.12990@localhost>
References: <alpine.LNX.2.11.1506291655260.12990@localhost>
Message-ID: <5591E844.1030804@auckland.ac.nz>


If you want a pointer to the correct syntax for subset(), try 
help("subset")!!!

The syntax of your "extstream" function is totally screwed up, 
convoluted and over-complicated. Note that even if you had your "subset" 
argument specified correctly, the return() call will give you only the 
result from the *first* pass through the for loop.

That aside, the error message is perfectly clear: 'subset' must be 
logical.  Your "subset" argument is "stream" which is a factor.

You *could* redefine your "extstream" function as follows:

function(alldf) {
     sname <- levels(alldf$stream)
     rslt <- vector("list",length(sname))
     names(rslt) <- sname
     for (i in sname) {
        rslt[[i]] <- subset(alldf, alldf$stream==i, sampdate:quant)
     }
     rslt
}

However you don't need to go through such contortions:

     split(testset,testset$stream)

will give essentially what you want.  If you wish to strip out the 
redundant "stream" column from the data frames in the resulting list, 
you could do that using lapply()

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 30/06/15 12:03, Rich Shepard wrote:
>    Moving from interactive use of R to scripts and functions and have
> bumped
> into what I believe is a problem with variable names. Did not see a
> solution
> in the two R programming books I have or from my Web searches. Inexperience
> with ess-tracebug keeps me from refining my bug tracking.
>
>    Here's a test data set (cleverly called 'testset.dput'):
>
> structure(list(stream = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label
> = c("B", "J", "S"), class = "factor"),
>      sampdate = structure(c(8121, 8121, 8121, 8155, 8155, 8155,
>      8185, 8185, 8185, 8205, 8205, 8205, 8236, 8236, 8236, 8257,
>      8257, 8257, 8308, 8785, 8785, 8785, 8785, 8785, 8785, 8785,
>      8847, 8847, 8847, 8847, 8847, 8847, 8847, 8875, 8875, 8875,
>      8875, 8875, 8875, 8875, 8121, 8121, 8121, 8155, 8155, 8155,
>      8185, 8185, 8185, 8205, 8205, 8205, 8236, 8236, 8236, 8257,
>      8257, 8257, 8301, 8301, 8301), class = "Date"), param =
> structure(c(2L,
>      6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L,
>      6L, 7L, 2L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 1L, 2L, 3L, 4L, 5L,
>      6L, 7L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L,
>      2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L, 2L, 6L, 7L
>      ), .Label = c("Ca", "Cl", "K", "Mg", "Na", "SO4", "pH"), class =
> "factor"),
>      quant = c(4, 33, 8.43, 4, 32, 8.46, 4, 31, 8.43, 6, 33, 8.32,
>      5, 33, 8.5, 5, 32, 8.5, 5, 59.9, 3.46, 1.48, 29, 7.54, 64.6,
>      7.36, 46, 2.95, 1.34, 21.8, 5.76, 48.8, 7.72, 74.2, 5.36,
>      2.33, 38.4, 8.27, 141, 7.8, 3, 76, 6.64, 4, 74, 7.46, 2,
>      82, 7.58, 5, 106, 7.91, 3, 56, 7.83, 3, 51, 7.6, 6, 149,
>      7.73)), .Names = c("stream", "sampdate", "param", "quant"
> ), row.names = c(NA, -61L), class = "data.frame")
>
>    I want to subset that data.frame on each of the stream names: B, J,
> and S.
> This is the function that has the naming error (eda.R):
>
> extstream = function(alldf) {
>      sname = alldf$stream
>      sdate = alldf$sampdate
>      comp = alldf$param
>      value = alldf$quant
>      for (i in sname) {
>          sname <- subset(alldf, alldf$stream, select = c(sdate, comp,
> value))
>          return(sname)
>      }
> }
>
>    This is the result of running source('eda.R') followed by
>
>> extstream(testset)
> Error in subset.data.frame(alldf, alldf$stream, select = c(sdate, comp,  :
>    'subset' must be logical
>
>    I've tried using sname for the rows to select, but that produces a
> different error of trying to select undefined columns.
>
>    A pointer to the correct syntax for subset() is needed.


From rshepard at appl-ecosys.com  Tue Jun 30 04:18:45 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Mon, 29 Jun 2015 19:18:45 -0700 (PDT)
Subject: [R] Subset() within function: logical error
In-Reply-To: <5591E844.1030804@auckland.ac.nz>
References: <alpine.LNX.2.11.1506291655260.12990@localhost>
	<5591E844.1030804@auckland.ac.nz>
Message-ID: <alpine.LNX.2.11.1506291916590.12990@localhost>

On Tue, 30 Jun 2015, Rolf Turner wrote:

> If you want a pointer to the correct syntax for subset(), try 
> help("subset")!!!
>
> The syntax of your "extstream" function is totally screwed up, convoluted and 
> over-complicated. Note that even if you had your "subset" argument specified 
> correctly, the return() call will give you only the result from the *first* 
> pass through the for loop.
>
> That aside, the error message is perfectly clear: 'subset' must be logical. 
> Your "subset" argument is "stream" which is a factor.
>
> You *could* redefine your "extstream" function as follows:
>
> function(alldf) {
>    sname <- levels(alldf$stream)
>    rslt <- vector("list",length(sname))
>    names(rslt) <- sname
>    for (i in sname) {
>       rslt[[i]] <- subset(alldf, alldf$stream==i, sampdate:quant)
>    }
>    rslt
> }
>
> However you don't need to go through such contortions:
>
>    split(testset,testset$stream)
>
> will give essentially what you want.  If you wish to strip out the redundant 
> "stream" column from the data frames in the resulting list, you could do that 
> using lapply()

Rolf,

   I did re-read the subset man page, but did not associate the error message
with the problem.

   Thanks very much for the lesson. I will read the split() man page; simple
is always better.

Regards,

Rich


From cagomezt at uvic.ca  Tue Jun 30 02:02:12 2015
From: cagomezt at uvic.ca (Carlos Gomez)
Date: Mon, 29 Jun 2015 17:02:12 -0700
Subject: [R] Academic studies over R-Help
Message-ID: <422d6126a5a2f05c2babeba62c5aeed7.squirrel@wm3.uvic.ca>

Dear r-help mailing list,

Some colleagues and I are working on a series of research studies related
to mailing list, and Stack Overflow. While I do understand that this email
would be technically off topic - it's about a study that could involve
R-Help users - not about coding in R. I was wondering:

 - to what extent would you be interested in participate in academic studies?

 - under what circumstances would you be willing to participate in
interviews, user surveys, lab experiments or any other activity related
to academic research?

 - Which communication channels do you think are the appropriate to send
these kind of announcements? (if any)

So, before upsetting the entire community (if this email is not doing that
already), I will prefer to ask about it.

Thank you for your consideration!

Best regards,
Carlos Gomez


From kirchman at udel.edu  Mon Jun 29 23:04:27 2015
From: kirchman at udel.edu (kirchman)
Date: Mon, 29 Jun 2015 14:04:27 -0700 (PDT)
Subject: [R] Extracting arrows from CCA plots
Message-ID: <1435611867609-4709190.post@n4.nabble.com>

I would like to extract all of the results from a CCA analysis done in the
vegan package so that I have complete control of how the results are
plotted.  

How can I get the coordinates (the "bipplot scores") for the arrows? I mean
the arrows as they appear in  

     plot(results.cca, display=c("sites", "bp"))     

where "results.cca" is the file resulting from the cca function.

The following extracts the "Biplot scores of constraints", which seems close
to what I want:
     
     scores (results.cca, display="bp")

It gives the ends of the arrows in the right direction (it seems) but the
arrows are not as long. I'm guessing that they have not been scaled, at
least as done with plot(results.cca, display=c("sites", "bp")).

If the arrows in plot(results.cca, display=c("sites", "bp")) cannot be
extracted, how can the biplot scores be scaled to reproduce the arrows?          




--
View this message in context: http://r.789695.n4.nabble.com/Extracting-arrows-from-CCA-plots-tp4709190.html
Sent from the R help mailing list archive at Nabble.com.


From abhinabaroy09 at gmail.com  Tue Jun 30 09:33:46 2015
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Tue, 30 Jun 2015 13:03:46 +0530
Subject: [R] Web crawling amazon website using R
Message-ID: <CANtKHPWx7+T=JnRXa+DoCMsdHS4T6DGof-LW0=zB1mySwtyxMw@mail.gmail.com>

Hi R helpers,

I want to crawl the amazon.in website to extract the customer feedbacks for
a particular product, and then use the texts for word cloud and sentiment
analysis.

For example, if I want to extract the feedback texts from

http://www.amazon.in/Mi-4-White-16GB/product-reviews/B00VEB0F22/ref=dpx_acr_txt?showViewpoints=1

How do I achieve this using R?


Regards,
Abhinaba Roy

	[[alternative HTML version deleted]]


From bob at rudis.net  Tue Jun 30 12:29:19 2015
From: bob at rudis.net (boB Rudis)
Date: Tue, 30 Jun 2015 06:29:19 -0400
Subject: [R] Web crawling amazon website using R
In-Reply-To: <CANtKHPWx7+T=JnRXa+DoCMsdHS4T6DGof-LW0=zB1mySwtyxMw@mail.gmail.com>
References: <CANtKHPWx7+T=JnRXa+DoCMsdHS4T6DGof-LW0=zB1mySwtyxMw@mail.gmail.com>
Message-ID: <CAJ4QxaNdNv_y0EOndGvi4DnC+ARUDccfRSWd++i1HNHSuoG_BQ@mail.gmail.com>

You might want to read Amazon's terms of service before crawling their
site: http://www.amazon.in/gp/help/customer/display.html/ref=footer_cou/276-8549425-3823542?ie=UTF8&nodeId=200545940

On Tue, Jun 30, 2015 at 3:33 AM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
> Hi R helpers,
>
> I want to crawl the amazon.in website to extract the customer feedbacks for
> a particular product, and then use the texts for word cloud and sentiment
> analysis.
>
> For example, if I want to extract the feedback texts from
>
> http://www.amazon.in/Mi-4-White-16GB/product-reviews/B00VEB0F22/ref=dpx_acr_txt?showViewpoints=1
>
> How do I achieve this using R?
>
>
> Regards,
> Abhinaba Roy
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mylisttech at gmail.com  Tue Jun 30 14:20:55 2015
From: mylisttech at gmail.com (My List)
Date: Tue, 30 Jun 2015 17:50:55 +0530
Subject: [R] Fishers test.
Message-ID: <CAFpdVnweg5twh8r9dE94=bXp1_RGmcJpoOP1=4fms54koBEtEA@mail.gmail.com>

All:

I wanted to know if the fishers test can be applied to RxC where and R and
C are greater than 2, by using the

fisher.test() or
fisher.test() with hybrid

please advice. Thanks in advance

-Harmeet

	[[alternative HTML version deleted]]


From pmaclean2011 at yahoo.com  Tue Jun 30 15:04:36 2015
From: pmaclean2011 at yahoo.com (Peter Maclean)
Date: Tue, 30 Jun 2015 13:04:36 +0000 (UTC)
Subject: [R] Double Roop
Message-ID: <1878709709.2391422.1435669476837.JavaMail.yahoo@mail.yahoo.com>

?Hi EverybodyI am trying to make?an object with??length(a) * length(b) element?using a double loop. But I am getting the last part only.??A simple script is
a <- c("A-AA", "B-BB", "C-CC")
b??? <- seq(1, 5)
pre <- NULL
post <- NULL
page <- NULLfor(j in 1:length(a)) {
?? for(i in 1:length(b)){
?????? pre[j]? <- strsplit(a[j],"-")[[1]][1] 
????????? post[j] <- strsplit(a[j],"-")[[1]][2] 
??????????? page[i] <- paste0(pre[j], b[i],post[j])? 
}}Peter Maclean
Department of Economics
UDSM
	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Tue Jun 30 15:19:02 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 30 Jun 2015 14:19:02 +0100
Subject: [R] Fishers test.
In-Reply-To: <CAFpdVnweg5twh8r9dE94=bXp1_RGmcJpoOP1=4fms54koBEtEA@mail.gmail.com>
References: <CAFpdVnweg5twh8r9dE94=bXp1_RGmcJpoOP1=4fms54koBEtEA@mail.gmail.com>
Message-ID: <55929746.9080009@dewey.myzen.co.uk>

Dear Harmeet

Well
1 - why not try it?
2 - what does the help say?

Or do you have some deeper question?

On 30/06/2015 13:20, My List wrote:
> All:
>
> I wanted to know if the fishers test can be applied to RxC where and R and
> C are greater than 2, by using the
>
> fisher.test() or
> fisher.test() with hybrid
>
> please advice. Thanks in advance
>
> -Harmeet
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From sarah.goslee at gmail.com  Tue Jun 30 15:32:58 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 30 Jun 2015 09:32:58 -0400
Subject: [R] Double Roop
In-Reply-To: <1878709709.2391422.1435669476837.JavaMail.yahoo@mail.yahoo.com>
References: <1878709709.2391422.1435669476837.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAM_vjunAk=5rysmT0WVABRwA9y5k_3_U7EjATwMi+6ipT_VCcw@mail.gmail.com>

Hi Peter,

page is indexed by [i], so for each iteration of j you're rewriting
previous results.

You can fix that very simply, with:
a <- c("A-AA", "B-BB", "C-CC")
b    <- seq(1, 5)
pre <- NULL
post <- NULL
page <- NULL

pageno <- 1

for(j in 1:length(a)) {
   for(i in 1:length(b)){
       pre[j]  <- strsplit(a[j],"-")[[1]][1]
       post[j] <- strsplit(a[j],"-")[[1]][2]
       page[pageno] <- paste0(pre[j], b[i],post[j])
       pageno <- pageno + 1
}}

But try instead:

a <- c("A-AA", "B-BB", "C-CC")
b    <- seq(1, 5)

page <- expand.grid(b, a)
apply(page, 1, function(x)sub("-", x[1], x[2]))

Sarah

PS Please don't post in HTML; I had to unmangle your code before
working with it.

On Tue, Jun 30, 2015 at 9:04 AM, Peter Maclean via R-help
<r-help at r-project.org> wrote:
>  Hi EverybodyI am trying to make an object with  length(a) * length(b) element using a double loop. But I am getting the last part only.  A simple script is
> a <- c("A-AA", "B-BB", "C-CC")
> b    <- seq(1, 5)
> pre <- NULL
> post <- NULL
> page <- NULLfor(j in 1:length(a)) {
>    for(i in 1:length(b)){
>        pre[j]  <- strsplit(a[j],"-")[[1]][1]
>           post[j] <- strsplit(a[j],"-")[[1]][2]
>             page[i] <- paste0(pre[j], b[i],post[j])
> }}Peter Maclean
> Department of Economics
> UDSM
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee
http://www.functionaldiversity.org


From ambatnisha at gmail.com  Tue Jun 30 09:01:29 2015
From: ambatnisha at gmail.com (Nisha Simon)
Date: Tue, 30 Jun 2015 00:01:29 -0700
Subject: [R] Problems in installing Ameliaview
Message-ID: <CAAoELcGwFO8fr5w=+GrWAMoWHpKvufToS5+H_dY18V0ddN7tug@mail.gmail.com>

Sir,
I have tried installing R 3.2.1 and then amelia viw setup file. Both are
getting installed but when I open Amelia, I get command prompt screen for 1
sec before it vcloses automatically. typing library(Amelia) has returned
error package ?Rcpp? required by ?Amelia? could not be found. Please help...
Thanks Nisha

	[[alternative HTML version deleted]]


From Phillip.Schermerhorn at austintexas.gov  Tue Jun 30 17:04:02 2015
From: Phillip.Schermerhorn at austintexas.gov (Schermerhorn, Phillip)
Date: Tue, 30 Jun 2015 15:04:02 +0000
Subject: [R] erro during make
Message-ID: <CY1PR09MB04253E6D02C30B0C2DA2FC3F8DA90@CY1PR09MB0425.namprd09.prod.outlook.com>

We are trying to make R on AIX and hit the error below.  We have searched for a fix but have not come up with anything yet on where these functions or macos should be define and how.

Can you help?


        gcc -std=gnu99  -I../../src/extra/bzip2 -I../../src/extra/pcre  -I../../src/extra  -I../../src/extra/xz/api -I. -I../../src/include -I../../src/include   -I/usr/local/include -I../../src/nmath -DHAVE_CONFIG_H  -mno-fp-in-toc    -g -O2  -c complex.c -o complex.o
complex.c: In function 'mycpow':
complex.c:169: error: '__I' undeclared (first use in this function)
complex.c:169: error: (Each undeclared identifier is reported only once
complex.c:169: error: for each function it appears in.)
complex.c: In function 'z_asin':
complex.c:565: error: '__I' undeclared (first use in this function)
complex.c: In function 'z_atan':
complex.c:582: error: '__I' undeclared (first use in this function)
complex.c: In function 'z_acosh':
complex.c:589: error: '__I' undeclared (first use in this function)
complex.c: In function 'z_asinh':
complex.c:594: error: '__I' undeclared (first use in this function)
complex.c: In function 'z_atanh':
complex.c:599: error: '__I' undeclared (first use in this function)
make: 1254-004 The error code from the last command is 1.

Thanks
Phil

Phillip Schermerhorn
Programmer/Analyst
Communication Technology Management -- City of Austin
Office: (512) 974-1433

The latest survey shows that three out of four people make up 75% of the population.




	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Tue Jun 30 17:46:18 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 30 Jun 2015 08:46:18 -0700
Subject: [R] erro during make
In-Reply-To: <CY1PR09MB04253E6D02C30B0C2DA2FC3F8DA90@CY1PR09MB0425.namprd09.prod.outlook.com>
References: <CY1PR09MB04253E6D02C30B0C2DA2FC3F8DA90@CY1PR09MB0425.namprd09.prod.outlook.com>
Message-ID: <F4728D73-C546-4D73-90FC-B4C4DC61ACCE@dcn.davis.CA.us>

My advice to you is to read the Posting Guide, which tells you that this type of question belongs on a different mailing list (which is identified there as well), where discussions and expertise more suited to help you are likely to be found.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On June 30, 2015 8:04:02 AM PDT, "Schermerhorn, Phillip" <Phillip.Schermerhorn at austintexas.gov> wrote:
>We are trying to make R on AIX and hit the error below.  We have
>searched for a fix but have not come up with anything yet on where
>these functions or macos should be define and how.
>
>Can you help?
>
>
>gcc -std=gnu99  -I../../src/extra/bzip2 -I../../src/extra/pcre 
>-I../../src/extra  -I../../src/extra/xz/api -I. -I../../src/include
>-I../../src/include   -I/usr/local/include -I../../src/nmath
>-DHAVE_CONFIG_H  -mno-fp-in-toc    -g -O2  -c complex.c -o complex.o
>complex.c: In function 'mycpow':
>complex.c:169: error: '__I' undeclared (first use in this function)
>complex.c:169: error: (Each undeclared identifier is reported only once
>complex.c:169: error: for each function it appears in.)
>complex.c: In function 'z_asin':
>complex.c:565: error: '__I' undeclared (first use in this function)
>complex.c: In function 'z_atan':
>complex.c:582: error: '__I' undeclared (first use in this function)
>complex.c: In function 'z_acosh':
>complex.c:589: error: '__I' undeclared (first use in this function)
>complex.c: In function 'z_asinh':
>complex.c:594: error: '__I' undeclared (first use in this function)
>complex.c: In function 'z_atanh':
>complex.c:599: error: '__I' undeclared (first use in this function)
>make: 1254-004 The error code from the last command is 1.
>
>Thanks
>Phil
>
>Phillip Schermerhorn
>Programmer/Analyst
>Communication Technology Management -- City of Austin
>Office: (512) 974-1433
>
>The latest survey shows that three out of four people make up 75% of
>the population.
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Tue Jun 30 18:11:22 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 30 Jun 2015 12:11:22 -0400
Subject: [R] Problems in installing Ameliaview
In-Reply-To: <CAAoELcGwFO8fr5w=+GrWAMoWHpKvufToS5+H_dY18V0ddN7tug@mail.gmail.com>
References: <CAAoELcGwFO8fr5w=+GrWAMoWHpKvufToS5+H_dY18V0ddN7tug@mail.gmail.com>
Message-ID: <CAM_vjuka-vd4ujGmXsmiB68b7ocUxeSndRr7k_pEi79WwC3=bw@mail.gmail.com>

It sounds like you should install Rcpp, just as the error message tells you.

You can do this via install.packages() from within R.

Sarah

On Tue, Jun 30, 2015 at 3:01 AM, Nisha Simon <ambatnisha at gmail.com> wrote:
> Sir,
> I have tried installing R 3.2.1 and then amelia viw setup file. Both are
> getting installed but when I open Amelia, I get command prompt screen for 1
> sec before it vcloses automatically. typing library(Amelia) has returned
> error package ?Rcpp? required by ?Amelia? could not be found. Please help...
> Thanks Nisha
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee
http://www.functionaldiversity.org


From dwinsemius at comcast.net  Tue Jun 30 21:42:03 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 30 Jun 2015 12:42:03 -0700
Subject: [R] Double Roop
In-Reply-To: <1878709709.2391422.1435669476837.JavaMail.yahoo@mail.yahoo.com>
References: <1878709709.2391422.1435669476837.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <21A99B87-EAE4-49F5-8C89-BBD0416DDD4D@comcast.net>


On Jun 30, 2015, at 6:04 AM, Peter Maclean via R-help wrote:

>  Hi EverybodyI am trying to make an object with  length(a) * length(b) element using a double loop. But I am getting the last part only.  A simple script is
> a <- c("A-AA", "B-BB", "C-CC")
> b    <- seq(1, 5)
> pre <- NULL
> post <- NULL
> page <- NULLfor(j in 1:length(a)) {
>    for(i in 1:length(b)){
>        pre[j]  <- strsplit(a[j],"-")[[1]][1] 
>           post[j] <- strsplit(a[j],"-")[[1]][2] 
>             page[i] <- paste0(pre[j], b[i],post[j])  
> }}Peter Maclean
> Department of Economics
> UDSM
> 	[[alternative HTML version deleted]]

If you don't want folks here to think you have difficulty with the English language in the posting guide or with managing computer applications, you will set your mail-client to plain-text for communications to r-help. Notice that your code was a bit mangled by the HTML format. This is sometimes much more of a problem than it was in this instance. You've been posting since 2011 so really have no excuse for continuing to flout the mailing list norms:

> page <- paste( rep(a, length(b) ), rep(b, each =length(a) ) )
> 
> page
 [1] "A-AA 1" "B-BB 1" "C-CC 1" "A-AA 2" "B-BB 2" "C-CC 2" "A-AA 3"
 [8] "B-BB 3" "C-CC 3" "A-AA 4" "B-BB 4" "C-CC 4" "A-AA 5" "B-BB 5"
[15] "C-CC 5"

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From cagomezt at uvic.ca  Tue Jun 30 19:33:26 2015
From: cagomezt at uvic.ca (Carlos Gomez)
Date: Tue, 30 Jun 2015 10:33:26 -0700
Subject: [R] Towards understanding communication channels within a community
Message-ID: <f2ea27eb672fed242f605ebce2d6f8d8.squirrel@wm3.uvic.ca>

Dear r-help mailing list,

I would like to invite you to participate in an academic survey namely
"Towards understanding communication channels within a community".

We are Carlos Gomez and Margaret-Anne Storey, researchers from the
Computer Human Interaction and Software Engineering Lab (CHISEL) in the
Department of Computer Science at the University of Victoria, invite you
to participate in the study. We'd be grateful if you could help us
understand the current use of communication tools, the importance of using
an adequate communication tool, and the interplay between tools and the
development process by completing an on-line survey
(http://goo.gl/alZN4t). The survey should take about 10 to 15 minutes

General remarks: This is a purely academic research project with no
commercial interests. We will openly publish the results so everyone can
benefit from them, but will anonymize everything before doing so; your
responses will be handled confidentially. Responses -unless explicitly
stated otherwise- cannot be traced back to individual respondents. Please
note that you are not obligated to participate in the survey.

Target audience: Users and developers of R.

Note:
 - The survey is available in English and Spanish.
 - For an example of related studies from our lab, please visit Lief
Singer's work, How Software Developers Use Twitter (http://goo.gl/OO61Vf)
 - I do understand that this email would be technically off topic - it's
about a study that could involve R-Help users - not about coding in R.
 - This project is based on an open challenge presented by Bogdan
Vasilescu on his dissertation (http://goo.gl/IKsf2e)

Thank you for your consideration!

Best regards,
Carlos Gomez
Contact information: cagomezt(at)uvic(dot)ca
CHISEL Web site: http://thechiselgroup.org
Canada, BC, Victoria


From chichi.shu at hotmail.com  Tue Jun 30 21:43:20 2015
From: chichi.shu at hotmail.com (Chichi Shu)
Date: Tue, 30 Jun 2015 15:43:20 -0400
Subject: [R] ggmap warning
Message-ID: <BLU179-DS105EEEB47BA347236F93478FA90@phx.gbl>

Dear Listers



I??ve been using ggmap package to produce crime Heat map. But I??ve noticed the following warning message when executing my code: 



In loop_apply(n, do.ply) :

  Removed 4945 rows containing non-finite values (stat_density2d).



I??ve googled this message but I couldn??t find any good answers.



Is this related to ggmap package or one of its depending package?



What does it mean?



Thanks!

	[[alternative HTML version deleted]]


